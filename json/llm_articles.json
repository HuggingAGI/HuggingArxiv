[
  {
    "title": "GenArtist: Multimodal LLM as an Agent for Unified Image Generation and Editing",
    "submit_datetime": "2024年07月08日",
    "abstract": "Despite the success achieved by existing image generation and editing methods, current models still struggle with complex problems including intricate text prompts, and the absence of verification and self-correction mechanisms makes the generated images unreliable. Meanwhile, a single model tends to specialize in particular tasks and possess the corresponding capabilities, making it inadequate for fulfilling all user requirements. We propose GenArtist, a unified image generation and editing system, coordinated by a multimodal large language model (MLLM) agent. We integrate a comprehensive range of existing models into the tool library and utilize the agent for tool selection and execution. For a complex problem, the MLLM agent decomposes it into simpler sub-problems and constructs a tree structure to systematically plan the procedure of generation, editing, and self-correction with step-by-step verification. By automatically generating missing position-related inputs and incorporating position information, the appropriate tool can be effectively employed to address each sub-problem. Experiments demonstrate that GenArtist can perform various generation and editing tasks, achieving state-of-the-art performance and surpassing existing models such as SDXL and DALL-E 3, as can be seen in Fig. 1. Project page is https://zhenyuw16.github.io/GenArtist_page.",
    "pdf_link": "https://arxiv.org/abs/2407.05600",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05600v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05600/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05600v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05600/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05600v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05600/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05600v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05600/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05600v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05600/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05600v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05600/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05600v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05600/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05600v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05600/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05600v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05600/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05600v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05600/x10.png"
      }
    ],
    "abstract_cn": "尽管现有图像生成和编辑技术已取得一定成就，但面对复杂文本提示等难题，以及缺乏验证和自校正机制，现有模型仍显不足。此外，单一模型往往局限于特定任务，难以全面满足用户需求。为此，我们推出了GenArtist系统，该系统由多模态大型语言模型（MLLM）代理统一调度，集成了广泛的现有模型工具库。面对复杂任务，MLLM代理能将其拆解为简单子问题，并构建树状结构，系统化地规划生成、编辑及自校正流程，每一步都经过严格验证。通过自动补全位置相关输入并融入位置信息，系统能精准选用工具，高效解决各子问题。实验结果显示，GenArtist在多种生成和编辑任务中表现卓越，性能超越了SDXL和DALL-E 3等现有模型，详情可见图1。项目详情页：https://zhenyuw16.github.io/GenArtist_page。",
    "title_cn": "GenArtist：一款多模态 LLM，作为统一图像生成与编辑的智能代理",
    "tags": [
      "Agent",
      "图像处理",
      "人工智能"
    ]
  },
  {
    "title": "Multi-label Learning with Random Circular Vectors",
    "submit_datetime": "2024年07月08日",
    "abstract": "The extreme multi-label classification~(XMC) task involves learning a classifier that can predict from a large label set the most relevant subset of labels for a data instance. While deep neural networks~(DNNs) have demonstrated remarkable success in XMC problems, the task is still challenging because it must deal with a large number of output labels, which make the DNN training computationally expensive. This paper addresses the issue by exploring the use of random circular vectors, where each vector component is represented as a complex amplitude. In our framework, we can develop an output layer and loss function of DNNs for XMC by representing the final output layer as a fully connected layer that directly predicts a low-dimensional circular vector encoding a set of labels for a data instance. We conducted experiments on synthetic datasets to verify that circular vectors have better label encoding capacity and retrieval ability than normal real-valued vectors. Then, we conducted experiments on actual XMC datasets and found that these appealing properties of circular vectors contribute to significant improvements in task performance compared with a previous model using random real-valued vectors, while reducing the size of the output layers by up to 99%.",
    "pdf_link": "https://arxiv.org/abs/2407.05656",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05656v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05656/Heatmap_HRR.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05656v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05656/Heatmap_CHRR.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05656v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05656/Variance.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05656v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05656/Mean.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05656v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05656/Wiki10_P5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05656v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05656/Wiki10_P10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05656v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05656/Wiki10_P20.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05656v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05656/Wiki10_PSP5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05656v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05656/Wiki10_PSP10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05656v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05656/Wiki10_PSP20.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05656v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05656/d200_P5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05656v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05656/Delicious-200K_P10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05656v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05656/Delicious-200K_P20.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05656v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05656/d200_psp5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05656v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05656/Delicious-200K_PSP10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05656v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05656/Delicious-200K_PSP20.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05656v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05656/Model_type_P1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05656v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05656/Model_type_P10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05656v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05656/Model_type_P20.png"
      }
    ],
    "abstract_cn": "极端多标签分类 (XMC) 任务旨在训练一个分类器，从庞大的标签库中筛选出与特定数据最匹配的标签子集。尽管深度神经网络 (DNNs) 在此领域已取得显著成就，但面对海量输出标签，DNN 的训练成本依然高昂。本文提出了一种创新方法，利用随机圆形向量（每个分量以复数振幅表示）来优化这一难题。在我们的框架下，通过构建一个全连接的最终输出层，直接预测低维圆形向量，该向量编码了数据实例的标签集，从而为 DNN 设计了适用于 XMC 的输出层和损失函数。实验表明，圆形向量在标签编码和检索方面优于传统实值向量。进一步在真实 XMC 数据集上的测试证实，圆形向量的这些优势不仅显著提升了任务性能，还将输出层规模缩减了高达 99%。",
    "title_cn": "随机循环向量在多标签学习中的应用",
    "tags": [
      "LLM应用",
      "机器学习",
      "数据挖掘"
    ]
  },
  {
    "title": "GenFollower: Enhancing Car-Following Prediction with Large Language Models",
    "submit_datetime": "2024年07月08日",
    "abstract": "Accurate modeling of car-following behaviors is essential for various applications in traffic management and autonomous driving systems. However, current approaches often suffer from limitations like high sensitivity to data quality and lack of interpretability. In this study, we propose GenFollower, a novel zero-shot prompting approach that leverages large language models (LLMs) to address these challenges. We reframe car-following behavior as a language modeling problem and integrate heterogeneous inputs into structured prompts for LLMs. This approach achieves improved prediction performance and interpretability compared to traditional baseline models. Experiments on the Waymo Open datasets demonstrate GenFollower's superior performance and ability to provide interpretable insights into factors influencing car-following behavior. This work contributes to advancing the understanding and prediction of car-following behaviors, paving the way for enhanced traffic management and autonomous driving systems.",
    "pdf_link": "https://arxiv.org/abs/2407.05611",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05611v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05611/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05611v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05611/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05611v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05611/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05611v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05611/sm.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05611v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05611/um.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05611v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05611/am.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05611v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05611/out.png"
      }
    ],
    "abstract_cn": "在交通管理和自动驾驶领域，准确模拟跟车行为至关重要。然而，现有方法常受限于对数据质量的敏感和缺乏解释性。为此，我们研发了 GenFollower，一种利用大型语言模型的零-shot 提示技术，将跟车行为转化为语言模型问题，并整合多源输入至结构化提示中。实验表明，GenFollower 不仅提升了预测准确性，还增强了模型的解释力，为理解跟车行为提供了新视角，推动了交通管理与自动驾驶技术的发展。",
    "title_cn": "GenFollower：借助大型语言模型提升车辆跟随预测的精准度",
    "tags": [
      "LLM应用",
      "交通管理",
      "自动驾驶"
    ]
  },
  {
    "title": "Open-world Multi-label Text Classification with Extremely Weak Supervision",
    "submit_datetime": "2024年07月08日",
    "abstract": "We study open-world multi-label text classification under extremely weak supervision (XWS), where the user only provides a brief description for classification objectives without any labels or ground-truth label space. Similar single-label XWS settings have been explored recently, however, these methods cannot be easily adapted for multi-label. We observe that (1) most documents have a dominant class covering the majority of content and (2) long-tail labels would appear in some documents as a dominant class. Therefore, we first utilize the user description to prompt a large language model (LLM) for dominant keyphrases of a subset of raw documents, and then construct a (initial) label space via clustering. We further apply a zero-shot multi-label classifier to locate the documents with small top predicted scores, so we can revisit their dominant keyphrases for more long-tail labels. We iterate this process to discover a comprehensive label space and construct a multi-label classifier as a novel method, X-MLClass. X-MLClass exhibits a remarkable increase in ground-truth label space coverage on various datasets, for example, a 40% improvement on the AAPD dataset over topic modeling and keyword extraction methods. Moreover, X-MLClass achieves the best end-to-end multi-label classification accuracy.",
    "pdf_link": "https://arxiv.org/abs/2407.05609",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05609v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05609/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05609v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05609/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05609v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05609/x3.png"
      }
    ],
    "abstract_cn": "在极弱监督下，我们探索了开放世界的多标签文本分类，用户仅提供简要描述而无需任何标签。我们发现多数文档有一个主导类，而长尾标签偶尔也会成为主导。基于此，我们利用用户描述引导大型语言模型提取关键词，通过聚类构建标签空间，并运用零-shot分类器精确定位文档，以发现更多长尾标签。这一迭代过程最终形成了X-MLClass方法，显著提升了标签空间覆盖率，如在AAPD数据集上提升了40%，并实现了顶尖的多标签分类准确性。",
    "title_cn": "极弱监督下的开放世界多标签文本分类",
    "tags": [
      "LLM应用",
      "文本分类",
      "数据挖掘"
    ]
  },
  {
    "title": "Generative Debunking of Climate Misinformation",
    "submit_datetime": "2024年07月08日",
    "abstract": "Misinformation about climate change causes numerous negative impacts, necessitating corrective responses. Psychological research has offered various strategies for reducing the influence of climate misinformation, such as the fact-myth-fallacy-fact-structure. However, practically implementing corrective interventions at scale represents a challenge. Automatic detection and correction of misinformation offers a solution to the misinformation problem. This study documents the development of large language models that accept as input a climate myth and produce a debunking that adheres to the fact-myth-fallacy-fact (``truth sandwich'') structure, by incorporating contrarian claim classification and fallacy detection into an LLM prompting framework. We combine open (Mixtral, Palm2) and proprietary (GPT-4) LLMs with prompting strategies of varying complexity. Experiments reveal promising performance of GPT-4 and Mixtral if combined with structured prompts. We identify specific challenges of debunking generation and human evaluation, and map out avenues for future work. We release a dataset of high-quality truth-sandwich debunkings, source code and a demo of the debunking system.",
    "pdf_link": "https://arxiv.org/abs/2407.05599",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05599v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05599/x1.png"
      }
    ],
    "abstract_cn": "气候变化错误信息带来的负面影响众多，亟需纠正。心理学研究虽提供了减少其影响的策略，如“事实-神话-谬误-事实”结构，但大规模实施纠正措施仍具挑战。本研究探索了通过自动检测与纠正错误信息来应对这一问题，开发了能接受气候神话输入并按“真相三明治”结构生成反驳的大型语言模型。我们融合了开放与专有LLM，并运用多样的提示策略进行实验，发现结合结构化提示的GPT-4和Mixtral性能显著。同时，我们揭示了反驳生成及评估的难题，并指明了未来研究方向。此外，我们公开了高质量反驳数据集、源码及系统演示，以供进一步探索与应用。",
    "title_cn": "揭秘气候谣言的生成式方法",
    "tags": [
      "LLM应用",
      "气候变化",
      "信息安全"
    ]
  },
  {
    "title": "iLLM-TSC: Integration reinforcement learning and large language model for traffic signal control policy improvement",
    "submit_datetime": "2024年07月08日",
    "abstract": "Urban congestion remains a critical challenge, with traffic signal control (TSC) emerging as a potent solution. TSC is often modeled as a Markov Decision Process problem and then solved using reinforcement learning (RL), which has proven effective. However, the existing RL-based TSC system often overlooks imperfect observations caused by degraded communication, such as packet loss, delays, and noise, as well as rare real-life events not included in the reward function, such as unconsidered emergency vehicles. To address these limitations, we introduce a novel integration framework that combines a large language model (LLM) with RL. This framework is designed to manage overlooked elements in the reward function and gaps in state information, thereby enhancing the policies of RL agents. In our approach, RL initially makes decisions based on observed data. Subsequently, LLMs evaluate these decisions to verify their reasonableness. If a decision is found to be unreasonable, it is adjusted accordingly. Additionally, this integration approach can be seamlessly integrated with existing RL-based TSC systems without necessitating modifications. Extensive testing confirms that our approach reduces the average waiting time by $17.5\\%$ in degraded communication conditions as compared to traditional RL methods, underscoring its potential to advance practical RL applications in intelligent transportation systems. The related code can be found at \\url{https://github.com/Traffic-Alpha/iLLM-TSC}.",
    "pdf_link": "https://arxiv.org/abs/2407.06025",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06025v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06025/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06025v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06025/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06025v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06025/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06025v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06025/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06025v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06025/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06025v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06025/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06025v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06025/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06025v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06025/all_WT.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06025v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06025/EMV_WT.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06025v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06025/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06025v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06025/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06025v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06025/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06025v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06025/x11.png"
      }
    ],
    "abstract_cn": "城市拥堵问题依旧严峻，而交通信号控制（TSC）被视为一种有力对策。尽管RL已被证实有效，但现有基于RL的TSC系统常忽视通信退化导致的不完美观察及奖励函数未涵盖的罕见事件。为此，我们创新性地结合LLM与RL，旨在填补奖励函数中的空白并优化RL策略。在我们的方法中，RL先基于数据做决策，LLM则评估其合理性，必要时进行调整。此集成方法无需修改即可融入现有TSC系统。测试表明，在通信退化环境下，我们的方法使平均等待时间减少了17.5%，凸显了其在智能交通系统中推广RL应用的潜力。相关代码详见\\url{https://github.com/Traffic-Alpha/iLLM-TSC}。",
    "title_cn": "iLLM-TSC：融合强化学习与大型语言模型，优化交通信号控制策略",
    "tags": [
      "LLM应用",
      "",
      "智能交通系统"
    ]
  },
  {
    "title": "ANOLE: An Open, Autoregressive, Native Large Multimodal Models for Interleaved Image-Text Generation",
    "submit_datetime": "2024年07月08日",
    "abstract": "Previous open-source large multimodal models (LMMs) have faced several limitations: (1) they often lack native integration, requiring adapters to align visual representations with pre-trained large language models (LLMs); (2) many are restricted to single-modal generation; (3) while some support multimodal generation, they rely on separate diffusion models for visual modeling and generation. To mitigate these limitations, we present Anole, an open, autoregressive, native large multimodal model for interleaved image-text generation. We build Anole from Meta AI's Chameleon, adopting an innovative fine-tuning strategy that is both data-efficient and parameter-efficient. Anole demonstrates high-quality, coherent multimodal generation capabilities. We have open-sourced our model, training framework, and instruction tuning data.",
    "pdf_link": "https://arxiv.org/abs/2407.06135",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06135v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06135/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06135v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06135/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06135v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06135/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06135v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06135/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06135v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06135/x5.png"
      }
    ],
    "abstract_cn": "先前的开源大型多模态模型存在一些问题，如缺乏原生集成、仅支持单模态生成，以及依赖独立扩散模型进行视觉处理。为此，我们推出了 Anole，这是一个开放、自回归的原生多模态模型，专为图像与文本交错生成设计。基于 Meta AI 的 Chameleon，我们采用了一种创新的微调方法，既高效利用数据又节省参数。Anole 能够生成高质量且连贯的多模态内容。我们已将模型、训练框架及调优数据全部开源。",
    "title_cn": "ANOLE 是一个开放且自回归的原生大型多模态模型，专为交错图像与文本生成而设计。",
    "tags": [
      "LLM应用",
      "人工智能",
      "开源软件"
    ]
  },
  {
    "title": "Cross-domain Few-shot In-context Learning for Enhancing Traffic Sign Recognition",
    "submit_datetime": "2024年07月08日",
    "abstract": "Recent multimodal large language models (MLLM) such as GPT-4o and GPT-4v have shown great potential in autonomous driving. In this paper, we propose a cross-domain few-shot in-context learning method based on the MLLM for enhancing traffic sign recognition (TSR). We first construct a traffic sign detection network based on Vision Transformer Adapter and an extraction module to extract traffic signs from the original road images. To reduce the dependence on training data and improve the performance stability of cross-country TSR, we introduce a cross-domain few-shot in-context learning method based on the MLLM. To enhance MLLM's fine-grained recognition ability of traffic signs, the proposed method generates corresponding description texts using template traffic signs. These description texts contain key information about the shape, color, and composition of traffic signs, which can stimulate the ability of MLLM to perceive fine-grained traffic sign categories. By using the description texts, our method reduces the cross-domain differences between template and real traffic signs. Our approach requires only simple and uniform textual indications, without the need for large-scale traffic sign images and labels. We perform comprehensive evaluations on the German traffic sign recognition benchmark dataset, the Belgium traffic sign dataset, and two real-world datasets taken from Japan. The experimental results show that our method significantly enhances the TSR performance.",
    "pdf_link": "https://arxiv.org/abs/2407.05814",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05814v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05814/1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05814v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05814/2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05814v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05814/5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05814v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05814/6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05814v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05814/3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05814v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05814/4.png"
      }
    ],
    "abstract_cn": "近期，多模态大型语言模型如GPT-4o和GPT-4v在自动驾驶领域展现出显著潜力。本文提出了一种基于MLLM的跨领域少样本上下文学习策略，旨在提升交通标志识别（TSR）能力。我们首先构建了一个基于Vision Transformer Adapter的交通标志检测网络，并设计了一个提取模块，从原始道路图像中精准提取交通标志。为减少对大量训练数据的依赖，并增强跨领域TSR的稳定性，我们创新性地引入了基于MLLM的跨领域少样本上下文学习技术。此外，为进一步提升MLLM对交通标志的细粒度识别能力，我们利用模板交通标志生成富含形状、颜色及构成等关键信息的描述文本，有效激发MLLM对细粒度交通标志类别的感知力。通过这些描述文本，我们成功缩小了模板与实际交通标志间的跨领域差异。值得一提的是，我们的方法仅需简单统一的文本指示，无需庞大的交通标志图像库和标签集。我们在德国、比利时的标准数据集以及日本的真实世界数据集上进行了详尽评估，实验结果表明，我们的方法在TSR性能上取得了显著提升。",
    "title_cn": "通过跨域少样本上下文学习提升交通标志识别能力",
    "tags": [
      "LLM应用",
      "自动驾驶",
      ""
    ]
  },
  {
    "title": "Potential of Multimodal Large Language Models for Data Mining of Medical Images and Free-text Reports",
    "submit_datetime": "2024年07月08日",
    "abstract": "Medical images and radiology reports are crucial for diagnosing medical conditions, highlighting the importance of quantitative analysis for clinical decision-making. However, the diversity and cross-source heterogeneity of these data challenge the generalizability of current data-mining methods. Multimodal large language models (MLLMs) have recently transformed many domains, significantly affecting the medical field. Notably, Gemini-Vision-series (Gemini) and GPT-4-series (GPT-4) models have epitomized a paradigm shift in Artificial General Intelligence (AGI) for computer vision, showcasing their potential in the biomedical domain. In this study, we evaluated the performance of the Gemini, GPT-4, and 4 popular large models for an exhaustive evaluation across 14 medical imaging datasets, including 5 medical imaging categories (dermatology, radiology, dentistry, ophthalmology, and endoscopy), and 3 radiology report datasets. The investigated tasks encompass disease classification, lesion segmentation, anatomical localization, disease diagnosis, report generation, and lesion detection. Our experimental results demonstrated that Gemini-series models excelled in report generation and lesion detection but faces challenges in disease classification and anatomical localization. Conversely, GPT-series models exhibited proficiency in lesion segmentation and anatomical localization but encountered difficulties in disease diagnosis and lesion detection. Additionally, both the Gemini series and GPT series contain models that have demonstrated commendable generation efficiency. While both models hold promise in reducing physician workload, alleviating pressure on limited healthcare resources, and fostering collaboration between clinical practitioners and artificial intelligence technologies, substantial enhancements and comprehensive validations remain imperative before clinical deployment.",
    "pdf_link": "https://arxiv.org/abs/2407.05758",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05758v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05758/x7.png"
      }
    ],
    "abstract_cn": "医学图像与放射报告对诊断至关重要，定量分析在此尤为关键。然而，数据多样性与跨源异质性对现有数据挖掘方法的泛化能力构成挑战。多模态大型语言模型（MLLMs）如Gemini与GPT-4，已在多个领域引发变革，医疗领域亦受其深远影响。本研究全面评估了Gemini、GPT-4及四款流行大型模型在14个医学影像数据集上的表现，涵盖五类影像（皮肤病、放射、牙科、眼科、内窥镜）及三类报告数据集，涉及疾病分类、病变分割、解剖定位、疾病诊断、报告生成与病变检测等多项任务。实验显示，Gemini系列在报告生成与病变检测上表现卓越，但在疾病分类与解剖定位上存在挑战；GPT系列则在病变分割与解剖定位上表现优异，但在疾病诊断与病变检测上遇到难题。此外，Gemini与GPT系列均有模型展现出高效的生成能力。尽管这些模型有望减轻医生负担、缓解医疗资源压力并促进医工合作，但在临床应用前，仍需进行重大改进与全面验证。",
    "title_cn": "多模态大型语言模型在医学图像与自由文本报告数据挖掘中的应用潜力",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Multi-Object Hallucination in Vision-Language Models",
    "submit_datetime": "2024年07月08日",
    "abstract": "Large vision language models (LVLMs) often suffer from object hallucination, producing objects not present in the given images. While current benchmarks for object hallucination primarily concentrate on the presence of a single object class rather than individual entities, this work systematically investigates multi-object hallucination, examining how models misperceive (e.g., invent nonexistent objects or become distracted) when tasked with focusing on multiple objects simultaneously. We introduce Recognition-based Object Probing Evaluation (ROPE), an automated evaluation protocol that considers the distribution of object classes within a single image during testing and uses visual referring prompts to eliminate ambiguity. With comprehensive empirical studies and analysis of potential factors leading to multi-object hallucination, we found that (1) LVLMs suffer more hallucinations when focusing on multiple objects compared to a single object. (2) The tested object class distribution affects hallucination behaviors, indicating that LVLMs may follow shortcuts and spurious correlations.(3) Hallucinatory behaviors are influenced by data-specific factors, salience and frequency, and model intrinsic behaviors. We hope to enable LVLMs to recognize and reason about multiple objects that often occur in realistic visual scenes, provide insights, and quantify our progress towards mitigating the issues.",
    "pdf_link": "https://arxiv.org/abs/2407.06192",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06192v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06192/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06192v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06192/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06192v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06192/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06192v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06192/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06192v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06192/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06192v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06192/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06192v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06192/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06192v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06192/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06192v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06192/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06192v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06192/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06192v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06192/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06192v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06192/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06192v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06192/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06192v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06192/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06192v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06192/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06192v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06192/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06192v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06192/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06192v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06192/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06192v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06192/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06192v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06192/x20.png"
      }
    ],
    "abstract_cn": "大型视觉语言模型 (LVLMs) 常因对象幻觉而产生图像中不存在的对象。本研究深入探讨了多对象幻觉现象，特别是在模型同时处理多个对象时可能出现的误感知问题。为此，我们提出了基于识别的对象探测评估 (ROPE)，一种自动化评估方法，它考虑图像内对象类别的分布，并通过视觉指向提示来减少歧义。实证研究表明：(1) LVLMs 在处理多对象时幻觉更频繁。(2) 对象类别的分布影响幻觉行为，暗示模型可能依赖捷径和虚假相关性。(3) 幻觉行为受数据特性和模型内在因素的影响。我们旨在提升 LVLMs 对现实场景中多对象的识别与推理能力，并量化我们在解决幻觉问题上的进展。",
    "title_cn": "视觉-语言模型中的多对象幻觉现象",
    "tags": [
      "LLM应用",
      "计算机视觉",
      "人工智能"
    ]
  },
  {
    "title": "Video-STaR: Self-Training Enables Video Instruction Tuning with Any Supervision",
    "submit_datetime": "2024年07月08日",
    "abstract": "The performance of Large Vision Language Models (LVLMs) is dependent on the size and quality of their training datasets. Existing video instruction tuning datasets lack diversity as they are derived by prompting large language models with video captions to generate question-answer pairs, and are therefore mostly descriptive. Meanwhile, many labeled video datasets with diverse labels and supervision exist - however, we find that their integration into LVLMs is non-trivial. Herein, we present Video Self-Training with augmented Reasoning (Video-STaR), the first video self-training approach. Video-STaR allows the utilization of any labeled video dataset for video instruction tuning. In Video-STaR, an LVLM cycles between instruction generation and finetuning, which we show (I) improves general video understanding and (II) adapts LVLMs to novel downstream tasks with existing supervision. During generation, an LVLM is prompted to propose an answer. The answers are then filtered only to those that contain the original video labels, and the LVLM is then re-trained on the generated dataset. By only training on generated answers that contain the correct video labels, Video-STaR utilizes these existing video labels as weak supervision for video instruction tuning. Our results demonstrate that Video-STaR-enhanced LVLMs exhibit improved performance in (I) general video QA, where TempCompass performance improved by 10%, and (II) on downstream tasks, where Video-STaR improved Kinetics700-QA accuracy by 20% and action quality assessment on FineDiving by 15%.",
    "pdf_link": "https://arxiv.org/abs/2407.06189",
    "graphs": [],
    "abstract_cn": "大型视觉语言模型 (LVLMs) 的性能受其训练数据集的大小和质量影响。现有视频指令调优数据集因依赖于通过视频字幕生成问答对而缺乏多样性，多为描述性内容。同时，虽有许多标记视频数据集具备多样标签和监督，但其整合至 LVLMs 并非简单任务。为此，我们首创了增强推理的视频自训练方法 (Video-STaR)，它允许利用任何标记视频数据集进行指令调优。Video-STaR 通过在指令生成与微调间循环，不仅提升视频理解能力，还能使模型适应新下游任务。在生成阶段，模型提出答案后，仅保留含原始视频标签的答案进行再训练，以此利用现有视频标签作为弱监督。实验显示，Video-STaR 增强的 LVLMs 在一般视频问答中性能提升显著，如 TempCompass 性能提高 10%，在下游任务如 Kinetics700-QA 准确性提升 20%，FineDiving 动作质量评估提升 15%。",
    "title_cn": "Video-STaR：通过自训练，视频指令调优可利用任意监督方式进行。",
    "tags": [
      "LLM应用",
      "视频处理",
      "人工智能"
    ]
  },
  {
    "title": "CrowdMoGen: Zero-Shot Text-Driven Collective Motion Generation",
    "submit_datetime": "2024年07月08日",
    "abstract": "Crowd Motion Generation is essential in entertainment industries such as animation and games as well as in strategic fields like urban simulation and planning. This new task requires an intricate integration of control and generation to realistically synthesize crowd dynamics under specific spatial and semantic constraints, whose challenges are yet to be fully explored. On the one hand, existing human motion generation models typically focus on individual behaviors, neglecting the complexities of collective behaviors. On the other hand, recent methods for multi-person motion generation depend heavily on pre-defined scenarios and are limited to a fixed, small number of inter-person interactions, thus hampering their practicality. To overcome these challenges, we introduce CrowdMoGen, a zero-shot text-driven framework that harnesses the power of Large Language Model (LLM) to incorporate the collective intelligence into the motion generation framework as guidance, thereby enabling generalizable planning and generation of crowd motions without paired training data. Our framework consists of two key components: 1) Crowd Scene Planner that learns to coordinate motions and dynamics according to specific scene contexts or introduced perturbations, and 2) Collective Motion Generator that efficiently synthesizes the required collective motions based on the holistic plans. Extensive quantitative and qualitative experiments have validated the effectiveness of our framework, which not only fills a critical gap by providing scalable and generalizable solutions for Crowd Motion Generation task but also achieves high levels of realism and flexibility.",
    "pdf_link": "https://arxiv.org/abs/2407.06188",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06188v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06188/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06188v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06188/methodfig1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06188v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06188/micromacro.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06188v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06188/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06188v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06188/x3.png"
      }
    ],
    "abstract_cn": "人群运动生成在娱乐和战略领域至关重要，如动画、游戏、城市模拟和规划。这一新任务要求在特定约束下精细整合控制与生成，以真实合成人群动态，其挑战尚待深入探索。现有模型多关注个体行为，忽视集体复杂性；而多人运动生成方法则依赖预设场景，局限于固定少数互动，实用性受限。为此，我们推出CrowdMoGen框架，借助大型语言模型（LLM），将集体智慧融入生成过程，实现无需配对数据的泛化人群运动规划与生成。框架包含两大核心组件：人群场景规划器，根据场景或扰动协调运动；集体运动生成器，高效合成集体运动。实验证明，该框架不仅填补了关键技术空白，提供可扩展、可泛化解决方案，更实现了高度真实与灵活性。",
    "title_cn": "CrowdMoGen：引领零-Shot 文本驱动的集体运动创新",
    "tags": [
      "LLM应用",
      "",
      "城市规划"
    ]
  },
  {
    "title": "Vision-Language Models under Cultural and Inclusive Considerations",
    "submit_datetime": "2024年07月08日",
    "abstract": "Large vision-language models (VLMs) can assist visually impaired people by describing images from their daily lives. Current evaluation datasets may not reflect diverse cultural user backgrounds or the situational context of this use case. To address this problem, we create a survey to determine caption preferences and propose a culture-centric evaluation benchmark by filtering VizWiz, an existing dataset with images taken by people who are blind. We then evaluate several VLMs, investigating their reliability as visual assistants in a culturally diverse setting. While our results for state-of-the-art models are promising, we identify challenges such as hallucination and misalignment of automatic evaluation metrics with human judgment. We make our survey, data, code, and model outputs publicly available.",
    "pdf_link": "https://arxiv.org/abs/2407.06177",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06177v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06177/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06177v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06177/final_analysis_multi.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06177v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06177/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06177v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06177/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06177v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06177/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06177v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06177/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06177v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06177/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06177v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06177/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06177v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06177/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06177v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06177/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06177v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06177/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06177v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06177/final_curr_error.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06177v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06177/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06177v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06177/x20.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06177v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06177/x21.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06177v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06177/x22.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06177v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06177/marvl_agamas.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06177v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06177/mrvl_buddhish.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06177v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06177/marvl_sambar.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06177v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06177/marvl_doner.png"
      }
    ],
    "abstract_cn": "大型视觉-语言模型（VLMs）能通过描述日常图像辅助视障人士。然而，现有评估数据集未能充分体现多元文化背景和实际使用情境。为此，我们设计了一项调查以了解字幕偏好，并基于VizWiz数据集（由盲人拍摄的图像组成）构建了一个文化导向的评估基准。随后，我们对多个VLMs进行了评估，探究其在多元文化环境中的可靠性。尽管最先进模型的表现令人鼓舞，但我们也发现了幻觉现象和自动评估与人类判断不一致等问题。所有相关资源，包括调查、数据、代码及模型输出，均已公开。",
    "title_cn": "文化与包容视角下的视觉语言模型研究",
    "tags": [
      "LLM应用",
      "辅助技术",
      "多元文化"
    ]
  },
  {
    "title": "On Speeding Up Language Model Evaluation",
    "submit_datetime": "2024年07月08日",
    "abstract": "Large language models (LLMs) currently dominate the field of natural language processing (NLP), representing the state-of-the-art across a diverse array of tasks. Developing a model of this nature, from training to inference, requires making numerous decisions which define a combinatorial search problem. For example, selecting the optimal pre-trained LLM, prompt, or hyperparameters to attain the best performance for a task often requires evaluating multiple candidates on an entire test set. This exhaustive evaluation can be time-consuming and costly, as both inference and metric computation with LLMs are resource-intensive. In this paper, we address the challenge of identifying the best method within a limited budget for evaluating methods on test examples. By leveraging the well-studied multi-armed bandit framework, which sequentially selects the next method-example pair to evaluate, our approach, combining multi-armed bandit algorithms with low-rank factorization, significantly reduces the required resources. Experiments show that our algorithms can identify the top-performing method using only 5-15\\% of the typically needed resources, resulting in an 85-95\\% reduction in cost.",
    "pdf_link": "https://arxiv.org/abs/2407.06172",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06172v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06172/resource_savings_color.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06172v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06172/llm-perf-pred.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06172v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06172/main.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06172v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06172/ablation.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06172v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06172/data_distributions.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLM）在自然语言处理（NLP）领域独领风骚，横扫各类任务的顶尖水平。然而，从训练到推理的每一步，都需精心抉择，构成一场复杂的组合搜索。例如，为求任务之巅，我们常需在全测试集上逐一试炼预训练模型、提示语及超参数。此番全面评估，既耗时又耗资，因LLM的推理与评估皆需大量资源。本文直面这一挑战，旨在有限预算内寻觅最佳评估之道。我们巧妙运用多臂老虎机框架，循序渐进地挑选待评对，结合多臂老虎机算法与低秩分解，大幅削减资源需求。实验证明，我们的算法仅以5-15%的常规资源，便能慧眼识珠，将成本削减至85-95%。",
    "title_cn": "加速语言模型评估之道",
    "tags": [
      "LLM理论",
      "计算机科学",
      "人工智能"
    ]
  },
  {
    "title": "What's Wrong with Your Code Generated by Large Language Models? An Extensive Study",
    "submit_datetime": "2024年07月08日",
    "abstract": "The increasing development of large language models (LLMs) in code generation has drawn significant attention among researchers. To enhance LLM-based code generation ability, current efforts are predominantly directed towards collecting high-quality datasets and leveraging diverse training technologies. However, there is a notable lack of comprehensive studies examining the limitations and boundaries of these existing methods. To bridge this gap, we conducted an extensive empirical study evaluating the performance of three leading closed-source LLMs and four popular open-source LLMs on three commonly used benchmarks. Our investigation, which evaluated the length, cyclomatic complexity and API number of the generated code, revealed that these LLMs face challenges in generating successful code for more complex problems, and tend to produce code that is shorter yet more complicated as compared to canonical solutions. Additionally, we developed a taxonomy of bugs for incorrect codes that includes three categories and 12 sub-categories, and analyze the root cause for common bug types. Furthermore, to better understand the performance of LLMs in real-world projects, we manually created a real-world benchmark comprising 140 code generation tasks. Our analysis highlights distinct differences in bug distributions between actual scenarios and existing benchmarks. Finally, we propose a novel training-free iterative method that introduces self-critique, enabling LLMs to critique and correct their generated code based on bug types and compiler feedback. Experimental results demonstrate that our approach can significantly mitigate bugs and increase the passing rate by 29.2% after two iterations, indicating substantial potential for LLMs to handle more complex problems.",
    "pdf_link": "https://arxiv.org/abs/2407.06153",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06153v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06153/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06153v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06153/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06153v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06153/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06153v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06153/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06153v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06153/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06153v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06153/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06153v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06153/x7.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）在代码生成领域的迅猛发展备受瞩目。为提升其代码生成能力，研究重点多放在高质量数据集的收集与多样化训练技术的应用上。然而，现有方法的局限性却鲜有深入探讨。为此，我们展开了一项全面实证研究，对比了三大闭源与四大开源LLM在常用基准上的表现。研究发现，这些模型在应对复杂问题时，生成的代码虽短却更复杂，且与标准方案存在差距。我们还构建了错误分类体系，深入剖析了常见错误的根源。为更贴近实际应用，我们精心设计了包含140项任务的实战基准，揭示了实际与理论基准间的错误分布差异。最终，我们创新提出了一种无需额外训练的迭代方法，通过自我批判机制，使模型能根据错误类型与编译反馈自我修正。实验显示，该方法能大幅降低错误率，两次迭代后通过率提升29.2%，展现了LLM在处理复杂问题上的广阔前景。",
    "title_cn": "大型语言模型所编代码，问题何在？深入探究。",
    "tags": [
      "LLM应用",
      "软件开发",
      "人工智能"
    ]
  },
  {
    "title": "Using Grammar Masking to Ensure Syntactic Validity in LLM-based Modeling Tasks",
    "submit_datetime": "2024年07月08日",
    "abstract": "We present and evaluate a method called grammar masking, which is used to guide large language models (LLMs) toward producing syntactically correct models for a given context-free grammar. Prompt engineering methods such as few-shot learning or priming can be used to improve the chances of an LLM producing correct syntax, but the more complex the grammar, the more time-consuming and less promising these methods become. Previous work is focused primarily on the usage of either language model training or prompt engineering. In this work, a method is presented that restricts the output to a given grammar using constrained decoding to ensure the output adheres to a valid syntax. We use several DSLs built with MontiCore and task multiple LLMs to produce models with and without constrained decoding. A corresponding parser is used to confirm the syntactic correctness of each model. We show that grammar masking can dramatically improve the modeling capabilities of several LLMs, reducing the need for well-refined prompting while increasing the chance of producing correct models.",
    "pdf_link": "https://arxiv.org/abs/2407.06146",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06146v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06146/FSL.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06146v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06146/GrammarMasking_AD.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06146v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06146/GrammarMasking.png"
      }
    ],
    "abstract_cn": "我们提出了一种名为“语法掩蔽”的方法，旨在引导大型语言模型（LLM）生成符合特定上下文无关语法的正确模型。尽管少样本学习或引导等提示工程方法能提高LLM生成正确语法的几率，但随着语法复杂度的增加，这些方法的效率和效果都会大打折扣。以往研究多聚焦于语言模型训练或提示工程。本研究则通过约束解码，将模型输出限定在特定语法范围内，确保输出语法的正确性。我们利用MontiCore构建的多种DSL，并测试了多个LLM在有无约束解码情况下的表现。通过解析器验证模型语法的正确性，结果显示，语法掩蔽能显著提升LLM的建模能力，降低对精细提示的依赖，并提高生成正确模型的概率。",
    "title_cn": "通过语法掩蔽技术，我们确保了 LLM 建模任务中的句法正确性。",
    "tags": [
      "LLM应用",
      "软件工程",
      "人工智能"
    ]
  },
  {
    "title": "Evaluating the Semantic Profiling Abilities of LLMs for Natural Language Utterances in Data Visualization",
    "submit_datetime": "2024年07月08日",
    "abstract": "Automatically generating data visualizations in response to human utterances on datasets necessitates a deep semantic understanding of the data utterance, including implicit and explicit references to data attributes, visualization tasks, and necessary data preparation steps. Natural Language Interfaces (NLIs) for data visualization have explored ways to infer such information, yet challenges persist due to inherent uncertainty in human speech. Recent advances in Large Language Models (LLMs) provide an avenue to address these challenges, but their ability to extract the relevant semantic information remains unexplored. In this study, we evaluate four publicly available LLMs (GPT-4, Gemini-Pro, Llama3, and Mixtral), investigating their ability to comprehend utterances even in the presence of uncertainty and identify the relevant data context and visual tasks. Our findings reveal that LLMs are sensitive to uncertainties in utterances. Despite this sensitivity, they are able to extract the relevant data context. However, LLMs struggle with inferring visualization tasks. Based on these results, we highlight future research directions on using LLMs for visualization generation.",
    "pdf_link": "https://arxiv.org/abs/2407.06129",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06129v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06129/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06129v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06129/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06129v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06129/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06129v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06129/x4.png"
      }
    ],
    "abstract_cn": "自动生成数据可视化以响应人类对数据集的表述，需要深入理解数据表述的语义，包括对数据属性的隐含和显式引用、可视化任务及数据准备步骤。尽管数据可视化的自然语言接口（NLIs）已探索推断此类信息的方法，但人类语言的不确定性仍带来挑战。大型语言模型（LLMs）的最新进展为解决这些挑战提供了可能，但其提取相关语义信息的能力尚未明确。本研究评估了四个公开可用的LLMs（GPT-4、Gemini-Pro、Llama3和Mixtral），探讨它们在不确定性存在时理解表述的能力，并识别相关数据上下文和可视化任务。研究发现，LLMs对表述中的不确定性敏感，但仍能提取相关数据上下文，而在推断可视化任务方面则面临挑战。基于此，我们提出了利用LLMs进行可视化生成的未来研究方向。",
    "title_cn": "探究 LLM 在数据可视化领域对自然语言表达的语义解析能力",
    "tags": [
      "LLM应用",
      "数据可视化",
      "人工智能"
    ]
  },
  {
    "title": "Depression Detection and Analysis using Large Language Models on Textual and Audio-Visual Modalities",
    "submit_datetime": "2024年07月08日",
    "abstract": "Depression has proven to be a significant public health issue, profoundly affecting the psychological well-being of individuals. If it remains undiagnosed, depression can lead to severe health issues, which can manifest physically and even lead to suicide. Generally, Diagnosing depression or any other mental disorder involves conducting semi-structured interviews alongside supplementary questionnaires, including variants of the Patient Health Questionnaire (PHQ) by Clinicians and mental health professionals. This approach places significant reliance on the experience and judgment of trained physicians, making the diagnosis susceptible to personal biases. Given that the underlying mechanisms causing depression are still being actively researched, physicians often face challenges in diagnosing and treating the condition, particularly in its early stages of clinical presentation. Recently, significant strides have been made in Artificial neural computing to solve problems involving text, image, and speech in various domains. Our analysis has aimed to leverage these state-of-the-art (SOTA) models in our experiments to achieve optimal outcomes leveraging multiple modalities. The experiments were performed on the Extended Distress Analysis Interview Corpus Wizard of Oz dataset (E-DAIC) corpus presented in the Audio/Visual Emotion Challenge (AVEC) 2019 Challenge. The proposed solutions demonstrate better results achieved by Proprietary and Open-source Large Language Models (LLMs), which achieved a Root Mean Square Error (RMSE) score of 3.98 on Textual Modality, beating the AVEC 2019 challenge baseline results and current SOTA regression analysis architectures. Additionally, the proposed solution achieved an accuracy of 71.43% in the classification task. The paper also includes a novel audio-visual multi-modal network that predicts PHQ-8 scores with an RMSE of 6.51.",
    "pdf_link": "https://arxiv.org/abs/2407.06125",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06125v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06125/net_1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06125v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06125/Train_1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06125v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06125/Train_2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06125v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06125/Train_3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06125v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06125/Train_4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06125v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06125/net_2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06125v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06125/Gpt_3.5.jpeg"
      },
      {
        "url": "https://arxiv.org/html/2407.06125v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06125/Gpt_4.jpeg"
      },
      {
        "url": "https://arxiv.org/html/2407.06125v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06125/Llama.jpeg"
      }
    ],
    "abstract_cn": "抑郁症已成为影响深远的公共卫生难题，对个体心理健康造成严重冲击。未被识别的抑郁症可能引发一系列严重健康问题，甚至导致自杀。传统上，抑郁症的诊断依赖于半结构化访谈和补充问卷，如患者健康问卷（PHQ），这些方法高度依赖医生的专业判断，易受个人偏见影响。由于抑郁症的内在机制尚在探索中，医生在早期诊断和治疗时面临诸多挑战。近年来，人工神经计算在处理文本、图像和语音等多领域问题方面取得显著进展。我们利用这些尖端模型进行实验，旨在通过多模态分析实现更优结果。实验基于2019年音频/视觉情感挑战（AVEC）中的扩展困境分析访谈语料库（E-DAIC）。我们的解决方案通过专有和开源大型语言模型（LLMs）在文本模态上实现了3.98的RMSE，超越了AVEC 2019的基线和现有SOTA回归架构。此外，分类任务的准确率达到了71.43%。论文还介绍了一种创新的音频-视觉多模态网络，能够以6.51的RMSE预测PHQ-8分数。",
    "title_cn": "利用大型语言模型，结合文本与视听信息，精准检测与分析抑郁症",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Artificial Intuition: Efficient Classification of Scientific Abstracts",
    "submit_datetime": "2024年07月08日",
    "abstract": "It is desirable to coarsely classify short scientific texts, such as grant or publication abstracts, for strategic insight or research portfolio management. These texts efficiently transmit dense information to experts possessing a rich body of knowledge to aid interpretation. Yet this task is remarkably difficult to automate because of brevity and the absence of context. To address this gap, we have developed a novel approach to generate and appropriately assign coarse domain-specific labels. We show that a Large Language Model (LLM) can provide metadata essential to the task, in a process akin to the augmentation of supplemental knowledge representing human intuition, and propose a workflow. As a pilot study, we use a corpus of award abstracts from the National Aeronautics and Space Administration (NASA). We develop new assessment tools in concert with established performance metrics.",
    "pdf_link": "https://arxiv.org/abs/2407.06093",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06093v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06093/label_gen.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06093v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06093/f1_plot_keywords.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06093v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06093/redundancy_plot.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06093v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06093/Prediction_pipeline.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06093v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06093/coverage_plot.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06093v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06093/cluster_eval.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06093v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06093/F1_score_paper.png"
      }
    ],
    "abstract_cn": "为了战略洞察或研究组合管理，对短科学文本进行粗略分类是理想的。这些文本高效地向专家传递密集信息，但因其简短和缺乏上下文，自动化难度大。为此，我们创新了一种方法，生成并分配领域特定标签。通过LLM，我们模拟了人类直觉的补充知识增强过程，并设计了工作流程。试点研究中，我们采用NASA的资助摘要语料库，并结合传统性能指标，开发了新的评估工具。",
    "title_cn": "人工直觉：科学摘要的高效分类",
    "tags": [
      "LLM应用",
      "科学研究",
      "信息管理"
    ]
  },
  {
    "title": "Merge, Ensemble, and Cooperate! A Survey on Collaborative Strategies in the Era of Large Language Models",
    "submit_datetime": "2024年07月08日",
    "abstract": "The remarkable success of Large Language Models (LLMs) has ushered natural language processing (NLP) research into a new era. Despite their diverse capabilities, LLMs trained on different corpora exhibit varying strengths and weaknesses, leading to challenges in maximizing their overall efficiency and versatility. To address these challenges, recent studies have explored collaborative strategies for LLMs. This paper provides a comprehensive overview of this emerging research area, highlighting the motivation behind such collaborations. Specifically, we categorize collaborative strategies into three primary approaches: Merging, Ensemble, and Cooperation. Merging involves integrating multiple LLMs in the parameter space. Ensemble combines the outputs of various LLMs. Cooperation} leverages different LLMs to allow full play to their diverse capabilities for specific tasks. We provide in-depth introductions to these methods from different perspectives and discuss their potential applications. Additionally, we outline future research directions, hoping this work will catalyze further studies on LLM collaborations and paving the way for advanced NLP applications.",
    "pdf_link": "https://arxiv.org/abs/2407.06089",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06089v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06089/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06089v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06089/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06089v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06089/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06089v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06089/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06089v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06089/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06089v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06089/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06089v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06089/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06089v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06089/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06089v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06089/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06089v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06089/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06089v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06089/x11.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLM）的卓越成就引领自然语言处理（NLP）研究进入新纪元。尽管LLM能力各异，但不同语料库训练的模型各有千秋，这为提升其整体效能和灵活性带来挑战。为此，近期研究聚焦于LLM间的协作策略。本文全面梳理这一前沿领域，阐释协作的深层动机。我们将其策略细分为合并、集成与合作三大类：合并通过参数融合多模型，集成整合各模型输出，合作则让不同模型在特定任务中各展所长。我们深入剖析这些策略，并展望其应用前景。同时，勾勒未来研究蓝图，期望推动LLM协作研究，助力NLP技术飞跃。",
    "title_cn": "融合、集成与协作：大型语言模型时代协同策略探析",
    "tags": [
      "LLM理论",
      "人工智能",
      ""
    ]
  },
  {
    "title": "From Loops to Oops: Fallback Behaviors of Language Models Under Uncertainty",
    "submit_datetime": "2024年07月08日",
    "abstract": "Large language models (LLMs) often exhibit undesirable behaviors, such as hallucinations and sequence repetitions. We propose to view these behaviors as fallbacks that models exhibit under uncertainty, and investigate the connection between them. We categorize fallback behaviors -- sequence repetitions, degenerate text, and hallucinations -- and extensively analyze them in models from the same family that differ by the amount of pretraining tokens, parameter count, or the inclusion of instruction-following training. Our experiments reveal a clear and consistent ordering of fallback behaviors, across all these axes: the more advanced an LLM is (i.e., trained on more tokens, has more parameters, or instruction-tuned), its fallback behavior shifts from sequence repetitions, to degenerate text, and then to hallucinations. Moreover, the same ordering is observed throughout a single generation, even for the best-performing models; as uncertainty increases, models shift from generating hallucinations to producing degenerate text and then sequence repetitions. Lastly, we demonstrate that while common decoding techniques, such as random sampling, might alleviate some unwanted behaviors like sequence repetitions, they increase harder-to-detect hallucinations.",
    "pdf_link": "https://arxiv.org/abs/2407.06071",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x20.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x21.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x22.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x23.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x24.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x25.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x26.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x27.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x28.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x29.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x30.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x31.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x32.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x33.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x34.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x35.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLM）常出现幻觉和序列重复等不良行为。我们将其视为模型在不确定性下的回退，并探究其关联。我们将这些行为分为序列重复、退化文本和幻觉，并在不同预训练程度和参数量的模型中深入分析。实验显示，LLM越先进（训练更多、参数更多、指令调优），其回退行为依次从序列重复转为退化文本，再到幻觉。即使在最佳模型中，随着不确定性上升，生成顺序也从幻觉变为退化文本，最终是序列重复。此外，我们发现随机采样等解码技术虽能减轻序列重复，却可能增加难以察觉的幻觉。",
    "title_cn": "当不确定性来袭，语言模型从循环往复走向“哎呀”时刻，探索其在未知中的回退策略。",
    "tags": [
      "LLM理论",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Vision-Braille: An End-to-End Tool for Chinese Braille Image-to-Text Translation",
    "submit_datetime": "2024年07月08日",
    "abstract": "Visually impaired people are a large group who can only use braille for reading and writing. However, the lack of special educational resources is the bottleneck for educating them. Educational equity is a reflection of the level of social civilization, cultural equality, and individual dignity. Facilitating and improving lifelong learning channels for the visually impaired is of great significance. Their written braille homework or exam papers cannot be understood by sighted teachers, because of the lack of a highly accurate braille translation system, especially in Chinese which has tone marks. braille writers often omit tone marks to save space, leading to confusion when braille with the same consonants and vowels is translated into Chinese. Previous algorithms were insufficient in extracting contextual information, resulting in low accuracy of braille translations into Chinese. This project informatively fine-tuned the mT5 model with an Encoder-decoder architecture for braille to Chinese character conversion. This research created a training set of braille and corresponding Chinese text from the Leipzig Corpora. This project significantly reduced the confusion in braille, achieving $62.4$ and $62.3$ BLEU scores in the validation and test sets, with a curriculum learning fine-tuning method. By incorporating the braille recognition algorithm, this project is the first publicly available braille translation system and can benefit lots of visually impaired students and families who are preparing for the Chinese College Test and help to propel their college dreams in the future. There is a demo on our homepage\\footnote{\\url{https://vision-braille.com/}}.",
    "pdf_link": "https://arxiv.org/abs/2407.06048",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06048v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06048/x1.png"
      }
    ],
    "abstract_cn": "视觉障碍者依赖盲文进行读写，但特殊教育资源的匮乏成为他们教育的瓶颈。教育公平是社会文明与个人尊严的体现，改善他们的学习渠道至关重要。由于缺乏精准的盲文翻译系统，尤其是中文中的声调标记问题，视力正常的教师难以理解他们的盲文作业。过去的算法在提取上下文信息方面表现不佳，导致翻译准确性低下。本项目通过微调mT5模型，成功创建了盲文到中文的转换系统，显著提高了翻译的清晰度，验证集和测试集的BLEU分数分别达到了62.4和62.3。这一创新系统不仅为视觉障碍学生及其家庭提供了便利，助力他们实现大学梦想，也是首个公开可用的盲文翻译工具。我们的主页上提供了演示，欢迎体验。",
    "title_cn": "Vision-Braille：一款端到端的中文盲文图像转文本工具",
    "tags": [
      "LLM应用",
      "特殊教育",
      "辅助技术"
    ]
  },
  {
    "title": "MST5 -- Multilingual Question Answering over Knowledge Graphs",
    "submit_datetime": "2024年07月08日",
    "abstract": "Knowledge Graph Question Answering (KGQA) simplifies querying vast amounts of knowledge stored in a graph-based model using natural language. However, the research has largely concentrated on English, putting non-English speakers at a disadvantage. Meanwhile, existing multilingual KGQA systems face challenges in achieving performance comparable to English systems, highlighting the difficulty of generating SPARQL queries from diverse languages. In this research, we propose a simplified approach to enhance multilingual KGQA systems by incorporating linguistic context and entity information directly into the processing pipeline of a language model. Unlike existing methods that rely on separate encoders for integrating auxiliary information, our strategy leverages a single, pretrained multilingual transformer-based language model to manage both the primary input and the auxiliary data. Our methodology significantly improves the language model's ability to accurately convert a natural language query into a relevant SPARQL query. It demonstrates promising results on the most recent QALD datasets, namely QALD-9-Plus and QALD-10. Furthermore, we introduce and evaluate our approach on Chinese and Japanese, thereby expanding the language diversity of the existing datasets.",
    "pdf_link": "https://arxiv.org/abs/2407.06041",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06041v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06041/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06041v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06041/x2.png"
      }
    ],
    "abstract_cn": "知识图谱问答 (KGQA) 利用自然语言简化了海量知识的查询过程，但研究多聚焦于英语，对非英语使用者不利。现有多语言 KGQA 系统在性能上难以匹敌英语系统，凸显了多语言生成 SPARQL 查询的挑战。本研究提出一种简化方法，通过直接整合语言上下文和实体信息至语言模型处理流程，增强多语言 KGQA 系统。我们采用单一预训练多语言变压器模型，统一处理主输入与辅助数据，显著提升自然语言到 SPARQL 查询的转换准确性。该方法在最新 QALD 数据集上表现优异，并首次在中文和日语上进行评估，拓宽了数据集的语言多样性。",
    "title_cn": "MST5 —— 知识图谱上的多语言问答系统",
    "tags": [
      "LLM应用",
      "知识图谱",
      ""
    ]
  },
  {
    "title": "PAS: Data-Efficient Plug-and-Play Prompt Augmentation System",
    "submit_datetime": "2024年07月08日",
    "abstract": "In recent years, the rise of Large Language Models (LLMs) has spurred a growing demand for plug-and-play AI systems. Among the various AI techniques, prompt engineering stands out as particularly significant. However, users often face challenges in writing prompts due to the steep learning curve and significant time investment, and existing automatic prompt engineering (APE) models can be difficult to use. To address this issue, we propose PAS, an LLM-based plug-and-play APE system. PAS utilizes LLMs trained on high-quality, automatically generated prompt complementary datasets, resulting in exceptional performance. In comprehensive benchmarks, PAS achieves state-of-the-art (SoTA) results compared to previous APE models, with an average improvement of 6.09 points. Moreover, PAS is highly efficient, achieving SoTA performance with only 9000 data points. Additionally, PAS can autonomously generate prompt augmentation data without requiring additional human labor. Its flexibility also allows it to be compatible with all existing LLMs and applicable to a wide range of tasks. PAS excels in human evaluations, underscoring its suitability as a plug-in for users. This combination of high performance, efficiency, and flexibility makes PAS a valuable system for enhancing the usability and effectiveness of LLMs through improved prompt engineering.",
    "pdf_link": "https://arxiv.org/abs/2407.06027",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06027v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06027/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06027v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06027/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06027v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06027/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06027v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06027/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06027v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06027/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06027v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06027/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06027v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06027/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06027v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06027/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06027v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06027/x9.png"
      }
    ],
    "abstract_cn": "随着大型语言模型（LLM）的兴起，即插即用AI系统的需求日益增长。在众多AI技术中，提示工程尤为关键。然而，用户在编写提示时往往面临学习难度大和时间成本高的问题，现有的自动提示工程（APE）模型也难以操作。为此，我们推出了PAS，一个基于LLM的即插即用APE系统。PAS通过在高质量自动生成的提示互补数据集上训练LLM，展现出卓越性能。在全面基准测试中，PAS超越以往APE模型，平均提升6.09分，且仅需9000数据点即可达到顶尖性能。PAS还能自主生成提示增强数据，无需额外人力，并兼容所有LLM，适用于多种任务。在人类评估中，PAS表现优异，凸显其作为用户插件的优越性。PAS集高性能、高效率与灵活性于一身，极大地提升了LLM的可用性与效果，是改进提示工程的宝贵工具。",
    "title_cn": "PAS：一款数据高效、即插即用的提示增强系统",
    "tags": [
      "LLM应用",
      "人工智能",
      "软件开发"
    ]
  },
  {
    "title": "Distilling System 2 into System 1",
    "submit_datetime": "2024年07月08日",
    "abstract": "Large language models (LLMs) can spend extra compute during inference to generate intermediate thoughts, which helps to produce better final responses. Since Chain-of-Thought (Wei et al., 2022), many such System 2 techniques have been proposed such as Rephrase and Respond (Deng et al., 2023a), System 2 Attention (Weston and Sukhbaatar, 2023) and Branch-Solve-Merge (Saha et al., 2023). In this work we investigate self-supervised methods to ``compile'' (distill) higher quality outputs from System 2 techniques back into LLM generations without intermediate reasoning token sequences, as this reasoning has been distilled into System 1. We show that several such techniques can be successfully distilled, resulting in improved results compared to the original System 1 performance, and with less inference cost than System 2. We posit that such System 2 distillation will be an important feature of future continually learning AI systems, enabling them to focus System 2 capabilities on the reasoning tasks that they cannot yet do well.",
    "pdf_link": "https://arxiv.org/abs/2407.06023",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06023v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06023/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06023v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06023/MT_bench_wo_tie.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06023v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06023/x2.png"
      }
    ],
    "abstract_cn": "大型语言模型在推理时通过额外计算生成中间思维，从而提升最终响应质量。自 Chain-of-Thought 提出后，多种 System 2 技术如 Rephrase and Respond、System 2 Attention 和 Branch-Solve-Merge 相继涌现。本研究探索自监督方法，将这些 System 2 技术的高质量输出提炼回 LLM，无需中间推理步骤，因为推理已融入 System 1。实验表明，这些技术提炼后不仅性能提升，且推理成本降低。我们预见，这种 System 2 提炼将成为未来 AI 系统持续学习的关键，使其能更高效地运用 System 2 能力于尚需改进的推理任务。",
    "title_cn": "系统2向系统1的精炼转化",
    "tags": [
      "LLM理论",
      "人工智能",
      "机器学习"
    ]
  },
  {
    "title": "Igea: a Decoder-Only Language Model for Biomedical Text Generation in Italian",
    "submit_datetime": "2024年07月08日",
    "abstract": "The development of domain-specific language models has significantly advanced natural language processing applications in various specialized fields, particularly in biomedicine. However, the focus has largely been on English-language models, leaving a gap for less-resourced languages such as Italian. This paper introduces Igea, the first decoder-only language model designed explicitly for biomedical text generation in Italian. Built on the Minerva model and continually pretrained on a diverse corpus of Italian medical texts, Igea is available in three model sizes: 350 million, 1 billion, and 3 billion parameters. The models aim to balance computational efficiency and performance, addressing the challenges of managing the peculiarities of medical terminology in Italian. We evaluate Igea using a mix of in-domain biomedical corpora and general-purpose benchmarks, highlighting its efficacy and retention of general knowledge even after the domain-specific training. This paper discusses the model's development and evaluation, providing a foundation for future advancements in Italian biomedical NLP.",
    "pdf_link": "https://arxiv.org/abs/2407.06011",
    "graphs": [],
    "abstract_cn": "领域特定语言模型在生物医学等专业领域的自然语言处理应用中取得了显著进展，但多聚焦于英语模型，忽视了资源较少的语言如意大利语。本文引入了Igea，首个专为意大利语生物医学文本生成设计的仅解码器语言模型。基于Minerva模型，并在丰富的意大利医学文本上持续预训练，Igea提供三种规模：3.5亿、10亿和30亿参数，旨在兼顾计算效率与性能，应对意大利语医学术语的独特挑战。我们通过结合专业与通用评估基准，验证了Igea在特定训练后仍能有效保留通用知识。本文详细探讨了Igea的开发与评估，为意大利生物医学NLP的未来发展奠定了基础。",
    "title_cn": "Igea：专为意大利语生物医学文本生成设计的解码器语言模型",
    "tags": [
      "LLM应用",
      "生物医学",
      ""
    ]
  },
  {
    "title": "Perceptions to Beliefs: Exploring Precursory Inferences for Theory of Mind in Large Language Models",
    "submit_datetime": "2024年07月08日",
    "abstract": "While humans naturally develop theory of mind (ToM), the capability to understand other people's mental states and beliefs, state-of-the-art large language models (LLMs) underperform on simple ToM benchmarks. We posit that we can extend our understanding of LLMs' ToM abilities by evaluating key human ToM precursors -- perception inference and perception-to-belief inference -- in LLMs. We introduce two datasets, Percept-ToMi and Percept-FANToM, to evaluate these precursory inferences for ToM in LLMs by annotating characters' perceptions on ToMi and FANToM, respectively. Our evaluation of eight state-of-the-art LLMs reveals that the models generally perform well in perception inference while exhibiting limited capability in perception-to-belief inference (e.g., lack of inhibitory control). Based on these results, we present PercepToM, a novel ToM method leveraging LLMs' strong perception inference capability while supplementing their limited perception-to-belief inference. Experimental results demonstrate that PercepToM significantly enhances LLM's performance, especially in false belief scenarios.",
    "pdf_link": "https://arxiv.org/abs/2407.06004",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06004v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06004/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06004v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06004/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06004v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06004/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06004v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06004/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06004v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06004/x5.png"
      }
    ],
    "abstract_cn": "人类自然地发展出理解他人心理状态和信念的心智理论 (ToM)，但大型语言模型 (LLM) 在这方面表现不佳。我们通过评估 LLM 中的关键 ToM 先驱——感知推理和感知到信念推理，来深化对 LLM 的 ToM 能力的理解。为此，我们创建了两个数据集，Percept-ToMi 和 Percept-FANToM，分别注释角色的感知，以评估这些先驱推理。评估显示，LLM 在感知推理上表现良好，但在感知到信念推理上能力有限。基于此，我们提出了 PercepToM，一种结合 LLM 强大感知推理能力并增强其感知到信念推理的新方法。实验证明，PercepToM 显著提升了 LLM 在错误信念场景中的性能。",
    "title_cn": "从感知到信念：探究大型语言模型中心智理论的先导推断",
    "tags": [
      "LLM理论",
      "人工智能",
      "心理学"
    ]
  },
  {
    "title": "Exploring Human-LLM Conversations: Mental Models and the Originator of Toxicity",
    "submit_datetime": "2024年07月08日",
    "abstract": "This study explores real-world human interactions with large language models (LLMs) in diverse, unconstrained settings in contrast to most prior research focusing on ethically trimmed models like ChatGPT for specific tasks. We aim to understand the originator of toxicity. Our findings show that although LLMs are rightfully accused of providing toxic content, it is mostly demanded or at least provoked by humans who actively seek such content. Our manual analysis of hundreds of conversations judged as toxic by APIs commercial vendors, also raises questions with respect to current practices of what user requests are refused to answer. Furthermore, we conjecture based on multiple empirical indicators that humans exhibit a change of their mental model, switching from the mindset of interacting with a machine more towards interacting with a human.",
    "pdf_link": "https://arxiv.org/abs/2407.05977",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05977v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05977/doesnotAllow2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05977v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05977/gettingMoreHuman.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05977v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05977/histoToxPer.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05977v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05977/mentalmodel.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05977v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05977/turns_WC_please.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05977v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05977/turns_WC_thanks_.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05977v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05977/turns_WC_sorry_a.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05977v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05977/turns_WC_you_you.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05977v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05977/turns_flesch.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05977v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05977/turns_len.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05977v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05977/turns_sexual.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05977v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05977/FirstBig_harassment_exceed_.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05977v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05977/FirstBig_sexual_exceed_.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05977v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05977/distrTox.png"
      }
    ],
    "abstract_cn": "本研究深入探讨了人类在自由多样的环境中与大型语言模型（LLM）的互动，与以往专注于特定任务的道德修剪模型研究形成鲜明对比。我们旨在揭示毒性内容的根源。研究发现，虽然LLM常被指责传播有害信息，但这往往源于人类的需求或至少是他们的挑衅。通过手动分析数百个被标记为有毒的对话，我们质疑了当前拒绝回答用户请求的做法。此外，基于多项实证数据，我们推测人类在与LLM互动时，心理模式正从机器互动转向更接近人类互动。",
    "title_cn": "探究人类与 LLM 对话中的心理模型及毒性源头",
    "tags": [
      "LLM应用",
      "人工智能",
      "社会科学"
    ]
  },
  {
    "title": "LLaMAX: Scaling Linguistic Horizons of LLM by Enhancing Translation Capabilities Beyond 100 Languages",
    "submit_datetime": "2024年07月08日",
    "abstract": "Large Language Models~(LLMs) demonstrate remarkable translation capabilities in high-resource language tasks, yet their performance in low-resource languages is hindered by insufficient multilingual data during pre-training. To address this, we dedicate 35,000 A100-SXM4-80GB GPU hours in conducting extensive multilingual continual pre-training on the LLaMA series models, enabling translation support across more than 100 languages. Through a comprehensive analysis of training strategies, such as vocabulary expansion and data augmentation, we develop LLaMAX. Remarkably, without sacrificing its generalization ability, LLaMAX achieves significantly higher translation performance compared to existing open-source LLMs~(by more than 10 spBLEU points) and performs on-par with specialized translation model~(M2M-100-12B) on the Flores-101 benchmark. Extensive experiments indicate that LLaMAX can serve as a robust multilingual foundation model. The code~\\footnote{\\url{https://github.com/CONE-MT/LLaMAX/.}} and models~\\footnote{\\url{https://huggingface.co/LLaMAX/.}} are publicly available.",
    "pdf_link": "https://arxiv.org/abs/2407.05975",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05975v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05975/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05975v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05975/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05975v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05975/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05975v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05975/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05975v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05975/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05975v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05975/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05975v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05975/x7.png"
      }
    ],
    "abstract_cn": "在高资源语言任务中，大型语言模型（LLMs）的翻译能力令人瞩目，但在低资源语言中，由于预训练数据不足，性能受限。为此，我们投入大量资源，对LLaMA系列模型进行多语言持续预训练，支持百余种语言的翻译。通过优化训练策略，如词汇扩展和数据增强，我们打造了LLaMAX。LLaMAX不仅保持了强大的泛化能力，还在翻译性能上大幅超越现有开源LLMs，与专业翻译模型在Flores-101基准上不相上下。实验证实，LLaMAX可作为稳健的多语言基础模型。相关代码和模型已公开，供公众使用。",
    "title_cn": "LLaMAX：拓展LLM的语言边界，强化超百种语言的翻译实力",
    "tags": [
      "LLM应用",
      "",
      "多语言处理"
    ]
  },
  {
    "title": "Towards Optimizing and Evaluating a Retrieval Augmented QA Chatbot using LLMs with Human in the Loop",
    "submit_datetime": "2024年07月08日",
    "abstract": "Large Language Models have found application in various mundane and repetitive tasks including Human Resource (HR) support. We worked with the domain experts of SAP SE to develop an HR support chatbot as an efficient and effective tool for addressing employee inquiries. We inserted a human-in-the-loop in various parts of the development cycles such as dataset collection, prompt optimization, and evaluation of generated output. By enhancing the LLM-driven chatbot's response quality and exploring alternative retrieval methods, we have created an efficient, scalable, and flexible tool for HR professionals to address employee inquiries effectively. Our experiments and evaluation conclude that GPT-4 outperforms other models and can overcome inconsistencies in data through internal reasoning capabilities. Additionally, through expert analysis, we infer that reference-free evaluation metrics such as G-Eval and Prometheus demonstrate reliability closely aligned with that of human evaluation.",
    "pdf_link": "https://arxiv.org/abs/2407.05925",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05925v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05925/n-tokens-articles.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05925v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05925/workflow.png"
      }
    ],
    "abstract_cn": "我们与SAP SE的专家携手，打造了一款HR支持聊天机器人，旨在高效解决员工疑问。在开发过程中，我们在数据集构建、提示优化及输出评估等环节融入了人工参与。此举不仅提升了聊天机器人的回复质量，还探索了新的检索策略，使之成为HR领域高效、灵活且可扩展的利器。实验表明，GPT-4凭借其卓越性能和内部推理能力，有效应对了数据不一致的挑战。同时，G-Eval和Prometheus等无参考评估指标，经专家验证，其可靠性已接近人类评估水平。",
    "title_cn": "探索优化与评估：结合 LLM 与人工反馈的增强型检索问答聊天机器人",
    "tags": [
      "LLM应用",
      "人力资源",
      "人工智能"
    ]
  },
  {
    "title": "Generation and De-Identification of Indian Clinical Discharge Summaries using LLMs",
    "submit_datetime": "2024年07月08日",
    "abstract": "The consequences of a healthcare data breach can be devastating for the patients, providers, and payers. The average financial impact of a data breach in recent months has been estimated to be close to USD 10 million. This is especially significant for healthcare organizations in India that are managing rapid digitization while still establishing data governance procedures that align with the letter and spirit of the law. Computer-based systems for de-identification of personal information are vulnerable to data drift, often rendering them ineffective in cross-institution settings. Therefore, a rigorous assessment of existing de-identification against local health datasets is imperative to support the safe adoption of digital health initiatives in India. Using a small set of de-identified patient discharge summaries provided by an Indian healthcare institution, in this paper, we report the nominal performance of de-identification algorithms (based on language models) trained on publicly available non-Indian datasets, pointing towards a lack of cross-institutional generalization. Similarly, experimentation with off-the-shelf de-identification systems reveals potential risks associated with the approach. To overcome data scarcity, we explore generating synthetic clinical reports (using publicly available and Indian summaries) by performing in-context learning over Large Language Models (LLMs). Our experiments demonstrate the use of generated reports as an effective strategy for creating high-performing de-identification systems with good generalization capabilities.",
    "pdf_link": "https://arxiv.org/abs/2407.05887",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05887/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05887/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05887/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05887/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05887/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05887/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05887/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05887/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05887/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05887/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05887/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05887/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05887/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05887/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05887/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05887/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05887/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05887/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05887/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05887/x20.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05887/x21.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05887/x22.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05887/x23.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05887/x24.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05887/x25.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05887/x26.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05887/x27.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05887/x28.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05887/x29.png"
      }
    ],
    "abstract_cn": "医疗数据泄露的后果对患者、提供者和支付者都可能是毁灭性的，平均财务影响近1000万美元。在印度，快速数字化与数据治理程序的建立并行，这对医疗机构尤为关键。去标识化系统易受数据漂移影响，跨机构应用时常无效。因此，对现有去标识化系统进行严格评估，以支持印度数字健康举措的安全采用至关重要。本研究利用印度医疗机构提供的去标识化患者出院总结，揭示了基于非印度数据集训练的去标识化算法在跨机构泛化上的不足。同时，现成的去标识化系统也存在潜在风险。为解决数据稀缺问题，我们通过在大语言模型上进行上下文学习，生成合成临床报告，实验证明这是一种有效策略，可创建具有良好泛化能力的高性能去标识化系统。",
    "title_cn": "利用大型语言模型生成并去识别化印度临床出院总结",
    "tags": [
      "LLM应用",
      "",
      "数据安全"
    ]
  },
  {
    "title": "KG-FPQ: Evaluating Factuality Hallucination in LLMs with Knowledge Graph-based False Premise Questions",
    "submit_datetime": "2024年07月08日",
    "abstract": "Recent studies have demonstrated that large language models (LLMs) are susceptible to being misled by false premise questions (FPQs), leading to errors in factual knowledge, know as factuality hallucination. Existing benchmarks that assess this vulnerability primarily rely on manual construction, resulting in limited scale and lack of scalability. In this work, we introduce an automated, scalable pipeline to create FPQs based on knowledge graphs (KGs). The first step is modifying true triplets extracted from KGs to create false premises. Subsequently, utilizing the state-of-the-art capabilities of GPTs, we generate semantically rich FPQs. Based on the proposed method, we present a comprehensive benchmark, the Knowledge Graph-based False Premise Questions (KG-FPQ), which contains approximately 178k FPQs across three knowledge domains, at six levels of confusability, and in two task formats. Using KG-FPQ, we conduct extensive evaluations on several representative LLMs and provide valuable insights. The KG-FPQ dataset and code are available at~https://github.com/yanxuzhu/KG-FPQ.",
    "pdf_link": "https://arxiv.org/abs/2407.05868",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05868v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05868/example.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05868v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05868/data_constructing.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05868v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05868/editing.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05868v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05868/evaluation_procedure.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05868v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05868/NSCvsNNSC.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05868v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05868/fpq6_art_hop.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05868v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05868/NSCvsNDC.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05868v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05868/NNSCvsNNDC.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05868v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05868/NNSRvsNNDR.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05868v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05868/NNSCvsNNSR.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05868v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05868/disvsgen_art.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05868v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05868/tpqvsfpq.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05868v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05868/model_size_fpq.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05868v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05868/fpq6_art_hop.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05868v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05868/fpq6_people_hop.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05868v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05868/fpq6_place_hop.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05868v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05868/fpq5_art_hop.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05868v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05868/fpq5_people_hop.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05868v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05868/fpq5_place_hop.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05868v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05868/disvsgen_people.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05868v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05868/disvsgen_place.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05868v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05868/model_size_tpq.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05868v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05868/models.png"
      }
    ],
    "abstract_cn": "最新研究发现，大型语言模型 (LLMs) 易受错误前提问题 (FPQs) 影响，产生事实幻觉。现有评估方法因手动构建而受限。为此，我们开发了基于知识图谱 (KGs) 的自动化流程，首先修改真实三元组创造错误前提，再利用 GPT 生成语义丰富的 FPQs。我们提出的 KG-FPQ 基准涵盖约 178k 个 FPQs，跨越三个领域，六个混淆级别，两种任务格式。通过 KG-FPQ，我们对多个 LLMs 进行了深入评估，并揭示了关键见解。KG-FPQ 数据集和代码已公开，详见 https://github.com/yanxuzhu/KG-FPQ。",
    "title_cn": "KG-FPQ：通过基于知识图的错误前提问题，评估 LLM 中的事实性幻觉问题。",
    "tags": [
      "LLM应用",
      "知识图谱",
      "人工智能"
    ]
  },
  {
    "title": "Empowering 1000 tokens/second on-device LLM prefilling with mllm-NPU",
    "submit_datetime": "2024年07月08日",
    "abstract": "On-device large language models (LLMs) are catalyzing novel mobile applications such as UI task automation and personalized email auto-reply, without giving away users' private data. However, on-device LLMs still suffer from unacceptably long inference latency, especially the time to first token (prefill stage) due to the need of long context for accurate, personalized content generation, as well as the lack of parallel computing capacity of mobile CPU/GPU.\n  To enable practical on-device LLM, we present mllm-NPU, the first-of-its-kind LLM inference system that efficiently leverages on-device Neural Processing Unit (NPU) offloading. Essentially, mllm-NPU is an algorithm-system co-design that tackles a few semantic gaps between the LLM architecture and contemporary NPU design. Specifically, it re-constructs the prompt and model in three levels: (1) At prompt level, it divides variable-length prompts into multiple fixed-sized chunks while maintaining data dependencies; (2) At tensor level, it identifies and extracts significant outliers to run on the CPU/GPU in parallel with minimal overhead; (3) At block level, it schedules Transformer blocks in an out-of-order manner to the CPU/GPU and NPU based on their hardware affinity and sensitivity to accuracy. Compared to competitive baselines, mllm-NPU achieves 22.4x faster prefill speed and 30.7x energy savings on average, and up to 32.8x speedup in an end-to-end real-world application. For the first time, mllm-NPU achieves more than 1,000 tokens/sec prefilling for a billion-sized model (Qwen1.5-1.8B), paving the way towards practical on-device LLM.",
    "pdf_link": "https://arxiv.org/abs/2407.05858",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05858v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05858/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05858v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05858/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05858v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05858/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05858v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05858/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05858v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05858/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05858v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05858/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05858v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05858/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05858v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05858/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05858v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05858/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05858v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05858/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05858v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05858/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05858v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05858/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05858v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05858/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05858v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05858/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05858v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05858/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05858v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05858/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05858v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05858/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05858v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05858/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05858v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05858/x19.png"
      }
    ],
    "abstract_cn": "设备上的大型语言模型（LLM）正推动着创新的移动应用，如界面任务自动化和个性化邮件自动回复，同时保护用户隐私。然而，这些模型仍受困于过长的推理延迟，尤其是在首次生成令牌时。为了解决这一难题，我们推出了mllm-NPU，这一开创性的LLM推理系统巧妙地利用了设备上的神经处理单元（NPU）。mllm-NPU通过算法与系统的深度融合，有效弥合了LLM架构与现代NPU设计间的语义鸿沟。它通过三个层面的创新重构提示与模型：首先，在提示层面，将可变长度提示分割为固定大小块，保持数据依赖；其次，在张量层面，识别并并行处理关键异常值，降低开销；最后，在块层面，根据硬件特性与准确性需求，灵活调度Transformer块。相较于现有技术，mllm-NPU在预填充速度上提升了22.4倍，能耗节省达30.7倍，实际应用中加速高达32.8倍。这一突破首次实现了十亿级模型每秒预填充超过1,000个令牌，为设备上LLM的实用化开辟了新纪元。",
    "title_cn": "借助mllm-NPU，实现设备上LLM每秒高效预填充1000个令牌。",
    "tags": [
      "LLM应用",
      "移动应用",
      "人工智能"
    ]
  },
  {
    "title": "An Empirical Comparison of Vocabulary Expansion and Initialization Approaches for Language Models",
    "submit_datetime": "2024年07月08日",
    "abstract": "Language Models (LMs) excel in natural language processing tasks for English but show reduced performance in most other languages. This problem is commonly tackled by continually pre-training and fine-tuning these models for said languages. A significant issue in this process is the limited vocabulary coverage in the original model's tokenizer, leading to inadequate representation of new languages and necessitating an expansion of the tokenizer. The initialization of the embeddings corresponding to new vocabulary items presents a further challenge. Current strategies require cross-lingual embeddings and lack a solid theoretical foundation as well as comparisons with strong baselines. In this paper, we first establish theoretically that initializing within the convex hull of existing embeddings is a good initialization, followed by a novel but simple approach, Constrained Word2Vec (CW2V), which does not require cross-lingual embeddings. Our study evaluates different initialization methods for expanding RoBERTa and LLaMA 2 across four languages and five tasks. The results show that CW2V performs equally well or even better than more advanced techniques. Additionally, simpler approaches like multivariate initialization perform on par with these advanced methods indicating that efficient large-scale multilingual continued pretraining can be achieved even with simpler initialization methods.",
    "pdf_link": "https://arxiv.org/abs/2407.05841",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05841v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05841/vocab_expansion_setup.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05841v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05841/roberta_final_plot.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05841v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05841/llama_avg.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05841v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05841/roberta_cpt_en.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05841v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05841/init_ouput.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05841v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05841/roberta_xnli_all_plots.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05841v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05841/roberta_ner_all_plots.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05841v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05841/roberta_qa_all_plots.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05841v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05841/llama_mt_all_plots.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05841v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05841/llama_xnli_all_plots.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05841v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05841/llama_xlsum_all_plots.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05841v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05841/llama_qa_all_plots.png"
      }
    ],
    "abstract_cn": "尽管语言模型在英语处理中表现卓越，但在其他多数语言中性能却有所下降。通常，这一难题通过持续的预训练和微调来解决。然而，原始模型分词器的词汇覆盖不足，导致新语言的表达力受限，进而需要扩展分词器。此外，新词汇的嵌入初始化也是一个挑战。当前方法依赖于跨语言嵌入，且缺乏坚实的理论支撑和强有力的比较基准。本文中，我们首先从理论上论证了在现有嵌入的凸包内进行初始化是有效的，随后提出了一种新颖且简便的方法——约束 Word2Vec (CW2V)，无需跨语言嵌入。我们的研究在四种语言和五项任务中评估了不同的初始化方法，结果表明 CW2V 的表现与高级技术不相上下，甚至更优。同时，简单的多元初始化方法也显示出与这些高级技术相当的性能，这表明即使采用简单的初始化方法，也能实现高效的大规模多语言持续预训练。",
    "title_cn": "语言模型中词汇扩展与初始化方法的实证对比研究",
    "tags": [
      "LLM理论",
      "",
      "机器学习"
    ]
  },
  {
    "title": "HyCIR: Boosting Zero-Shot Composed Image Retrieval with Synthetic Labels",
    "submit_datetime": "2024年07月08日",
    "abstract": "Composed Image Retrieval (CIR) aims to retrieve images based on a query image with text. Current Zero-Shot CIR (ZS-CIR) methods try to solve CIR tasks without using expensive triplet-labeled training datasets. However, the gap between ZS-CIR and triplet-supervised CIR is still large. In this work, we propose Hybrid CIR (HyCIR), which uses synthetic labels to boost the performance of ZS-CIR. A new label Synthesis pipeline for CIR (SynCir) is proposed, in which only unlabeled images are required. First, image pairs are extracted based on visual similarity. Second, query text is generated for each image pair based on vision-language model and LLM. Third, the data is further filtered in language space based on semantic similarity. To improve ZS-CIR performance, we propose a hybrid training strategy to work with both ZS-CIR supervision and synthetic CIR triplets. Two kinds of contrastive learning are adopted. One is to use large-scale unlabeled image dataset to learn an image-to-text mapping with good generalization. The other is to use synthetic CIR triplets to learn a better mapping for CIR tasks. Our approach achieves SOTA zero-shot performance on the common CIR benchmarks: CIRR and CIRCO.",
    "pdf_link": "https://arxiv.org/abs/2407.05795",
    "graphs": [],
    "abstract_cn": "组合图像检索（CIR）旨在根据带有文本的查询图像检索图像。当前的零样本CIR（ZS-CIR）方法试图在不使用昂贵的三元组标记训练数据集的情况下解决CIR任务。然而，ZS-CIR与三元组监督的CIR之间的差距仍然很大。在这项工作中，我们提出了混合CIR（HyCIR），它使用合成标签来提升ZS-CIR的性能。我们提出了一种新的CIR标签合成流程（SynCir），其中仅需要未标记的图像。首先，基于视觉相似性提取图像对。其次，基于视觉-语言模型和LLM为每个图像对生成查询文本。第三，基于语义相似性在语言空间中进一步过滤数据。为了提高ZS-CIR性能，我们提出了一种混合训练策略，结合ZS-CIR监督和合成CIR三元组。采用了两种对比学习方法。一种是使用大规模未标记图像数据集学习具有良好泛化的图像到文本映射。另一种是使用合成CIR三元组学习更适合CIR任务的映射。我们的方法在常见的CIR基准测试（CIRR和CIRCO）上实现了SOTA的零样本性能。",
    "title_cn": "HyCIR 技术通过合成标签，显著提升了零-shot组合图像检索的性能。",
    "tags": [
      "LLM应用",
      "图像检索",
      "机器学习"
    ]
  },
  {
    "title": "Large Language Models for Judicial Entity Extraction: A Comparative Study",
    "submit_datetime": "2024年07月08日",
    "abstract": "Domain-specific Entity Recognition holds significant importance in legal contexts, serving as a fundamental task that supports various applications such as question-answering systems, text summarization, machine translation, sentiment analysis, and information retrieval specifically within case law documents. Recent advancements have highlighted the efficacy of Large Language Models in natural language processing tasks, demonstrating their capability to accurately detect and classify domain-specific facts (entities) from specialized texts like clinical and financial documents. This research investigates the application of Large Language Models in identifying domain-specific entities (e.g., courts, petitioner, judge, lawyer, respondents, FIR nos.) within case law documents, with a specific focus on their aptitude for handling domain-specific language complexity and contextual variations. The study evaluates the performance of state-of-the-art Large Language Model architectures, including Large Language Model Meta AI 3, Mistral, and Gemma, in the context of extracting judicial facts tailored to Indian judicial texts. Mistral and Gemma emerged as the top-performing models, showcasing balanced precision and recall crucial for accurate entity identification. These findings confirm the value of Large Language Models in judicial documents and demonstrate how they can facilitate and quicken scientific research by producing precise, organised data outputs that are appropriate for in-depth examination.",
    "pdf_link": "https://arxiv.org/abs/2407.05786",
    "graphs": [],
    "abstract_cn": "领域特定实体识别在法律领域至关重要，支持多种应用，如问答系统、文本摘要等，特别是在案例法文档中。最新进展显示，大型语言模型在自然语言处理中表现出色，能从专业文本中精准识别和分类特定实体。本研究聚焦于大型语言模型在案例法文档中识别特定实体的能力，特别是处理语言复杂性和上下文变化的能力。研究评估了包括Meta AI 3、Mistral和Gemma在内的先进模型，在提取印度司法文本相关事实方面的表现。Mistral和Gemma表现卓越，精确度和召回率均衡，对实体识别至关重要。这些成果不仅证实了大型语言模型在司法领域的价值，还展示了它们如何通过生成精确、有序的数据，加速科学研究，为深入分析提供支持。",
    "title_cn": "司法实体提取领域的大型语言模型比较研究",
    "tags": [
      "LLM应用",
      "",
      ""
    ]
  },
  {
    "title": "Hecaton: Training and Finetuning Large Language Models with Scalable Chiplet Systems",
    "submit_datetime": "2024年07月08日",
    "abstract": "Large Language Models (LLMs) have achieved remarkable success in various fields, but their training and finetuning require massive computation and memory, necessitating parallelism which introduces heavy communication overheads. Driven by advances in packaging, the chiplet architecture emerges as a potential solution, as it can integrate computing power, as well as utilize on-package links with better signal integrity, higher bandwidth, and lower energy consumption. However, most existing chiplet-related works focus on DNN inference. Directly porting them to LLM training introduces significantly large quantities of DRAM access and network-on-package (NoP) overheads which make state-of-the-art chiplet designs fail, highlighting a research gap.\n  This work proposes Hecaton, a scalable and cost-effective chiplet system for LLM training and finetuning. We first provide a chiplet architecture with tailored scheduling that can largely reduce DRAM accesses. We further design an efficient distributed training method that reduces NoP communication complexity and relieves constraints on SRAM capacity and layout. Theoretical analysis shows that the entire system achieves weak scaling: as the workload and hardware resources grow proportionally, the computation-to-communication ratio remains nearly constant. Experiments with various workloads and hardware configurations verify the property, and Hecaton achieves $4.98\\times$ performance improvement and $2.35\\times$ energy reduction on Llama2-70B, compared to the tensor parallelism in Megatron. To the best of our knowledge, we propose the first chiplet architecture specifically used for LLM training or finetuning, with guaranteed performance regardless of the problem scale.",
    "pdf_link": "https://arxiv.org/abs/2407.05784",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05784v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05784/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05784v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05784/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05784v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05784/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05784v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05784/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05784v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05784/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05784v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05784/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05784v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05784/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05784v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05784/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05784v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05784/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05784v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05784/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05784v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05784/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05784v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05784/x12.png"
      }
    ],
    "abstract_cn": "大型语言模型 (LLM) 在多领域取得显著成就，但其训练与微调对计算和内存需求巨大，导致并行化带来高额通信成本。随着封装技术的发展，chiplet 架构应运而生，它集成了计算能力，并通过优化封装内链接，提供更佳的信号完整性、高带宽和低能耗。然而，现有 chiplet 研究多聚焦于 DNN 推理，直接应用于 LLM 训练则引发大量 DRAM 访问和封装内网络 (NoP) 开销，使先进 chiplet 设计失效，揭示了研究缺口。  本研究提出 Hecaton，一个专为 LLM 训练与微调设计的可扩展、高性价比 chiplet 系统。我们首先构建了一个定制调度的 chiplet 架构，显著减少 DRAM 访问。接着，我们设计了一种高效的分布式训练策略，降低 NoP 通信复杂性，并放宽对 SRAM 容量和布局的限制。理论分析显示，该系统实现了弱扩展：工作负载与硬件资源同比例增长时，计算与通信比率几乎恒定。实验证明，Hecaton 在 Llama2-70B 上相较于 Megatron 的张量并行，实现了 $4.98\\times$ 的性能提升和 $2.35\\times$ 的能耗节省。据我们所知，这是首个专为 LLM 训练或微调设计的 chiplet 架构，确保了性能的稳定性，不受问题规模影响。",
    "title_cn": "Hecaton：借助可扩展的小芯片系统，高效训练与微调大型语言模型。",
    "tags": [
      "LLM理论",
      "半导体",
      "人工智能"
    ]
  },
  {
    "title": "When is the consistent prediction likely to be a correct prediction?",
    "submit_datetime": "2024年07月08日",
    "abstract": "Self-consistency (Wang et al., 2023) suggests that the most consistent answer obtained through large language models (LLMs) is more likely to be correct. In this paper, we challenge this argument and propose a nuanced correction. Our observations indicate that consistent answers derived through more computation i.e. longer reasoning texts, rather than simply the most consistent answer across all outputs, are more likely to be correct. This is predominantly because we demonstrate that LLMs can autonomously produce chain-of-thought (CoT) style reasoning with no custom prompts merely while generating longer responses, which lead to consistent predictions that are more accurate. In the zero-shot setting, by sampling Mixtral-8x7B model multiple times and considering longer responses, we achieve 86% of its self-consistency performance obtained through zero-shot CoT prompting on the GSM8K and MultiArith datasets. Finally, we demonstrate that the probability of LLMs generating a longer response is quite low, highlighting the need for decoding strategies conditioned on output length.",
    "pdf_link": "https://arxiv.org/abs/2407.05778",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05778/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05778/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05778/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05778/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05778/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05778/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05778/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05778/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05778/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05778/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05778/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05778/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05778/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05778/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05778/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05778/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05778/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05778/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05778/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05778/x20.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05778/x21.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05778/x22.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05778/x23.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05778/x24.png"
      }
    ],
    "abstract_cn": "自我一致性理论（Wang et al., 2023）认为，大型语言模型（LLM）中最一致的答案更可能是正确答案。然而，我们对此提出质疑，并进行了细致的修正。我们发现，通过更多计算，即更长的推理文本，而非简单地选择所有输出中最一致的答案，得出的结果更可能正确。这是因为LLM能在无特殊提示下，自主生成链式思维（CoT）风格的推理，尤其是在生成较长响应时，这使得预测更为一致且准确。在零-shot场景下，通过多次采样Mixtral-8x7B模型并关注较长响应，我们在GSM8K和MultiArith数据集上达到了零-shot CoT提示下自我一致性性能的86%。此外，我们指出LLM生成较长响应的概率较低，这凸显了根据输出长度调整解码策略的重要性。",
    "title_cn": "何时一致的预测更可能是正确的？",
    "tags": [
      "LLM理论",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Large Language Models Understand Layouts",
    "submit_datetime": "2024年07月08日",
    "abstract": "Large language models (LLMs) demonstrate extraordinary abilities in a wide range of natural language processing (NLP) tasks. In this paper, we show that, beyond text understanding capability, LLMs are capable of processing text layouts that are denoted by spatial markers. They are able to answer questions that require explicit spatial perceiving and reasoning, while a drastic performance drop is observed when the spatial markers from the original data are excluded. We perform a series of experiments with the GPT-3.5, Baichuan2, Llama2 and ChatGLM3 models on various types of layout-sensitive datasets for further analysis. The experimental results reveal that the layout understanding ability of LLMs is mainly introduced by the coding data for pretraining, which is further enhanced at the instruction-tuning stage. In addition, layout understanding can be enhanced by integrating low-cost, auto-generated data approached by a novel text game. Finally, we show that layout understanding ability is beneficial for building efficient visual question-answering (VQA) systems.",
    "pdf_link": "https://arxiv.org/abs/2407.05750",
    "graphs": [],
    "abstract_cn": "大型语言模型 (LLMs) 在众多 NLP 任务中表现卓越。本文揭示，LLMs 不仅能理解文本，还能处理空间标记指示的文本布局，解答涉及空间感知的问题。然而，去除空间标记会导致性能大幅下降。我们通过 GPT-3.5、Baichuan2、Llama2 和 ChatGLM3 在布局敏感数据集上的实验，发现布局理解能力源自预训练数据，并在指令调优中强化。利用创新文本游戏自动生成数据，可进一步增强布局理解。此外，这种能力对构建高效的视觉问答 (VQA) 系统大有裨益。",
    "title_cn": "大型语言模型具备理解布局的能力。",
    "tags": [
      "LLM应用",
      "人工智能",
      "视觉问答"
    ]
  },
  {
    "title": "Do Multilingual Large Language Models Mitigate Stereotype Bias?",
    "submit_datetime": "2024年07月08日",
    "abstract": "While preliminary findings indicate that multilingual LLMs exhibit reduced bias compared to monolingual ones, a comprehensive understanding of the effect of multilingual training on bias mitigation, is lacking. This study addresses this gap by systematically training six LLMs of identical size (2.6B parameters) and architecture: five monolingual models (English, German, French, Italian, and Spanish) and one multilingual model trained on an equal distribution of data across these languages, all using publicly available data. To ensure robust evaluation, standard bias benchmarks were automatically translated into the five target languages and verified for both translation quality and bias preservation by human annotators. Our results consistently demonstrate that multilingual training effectively mitigates bias. Moreover, we observe that multilingual models achieve not only lower bias but also superior prediction accuracy when compared to monolingual models with the same amount of training data, model architecture, and size.",
    "pdf_link": "https://arxiv.org/abs/2407.05740",
    "graphs": [],
    "abstract_cn": "初步研究表明，多语言大型语言模型（LLMs）的偏差较单语言模型少。然而，关于多语言训练如何有效减少偏差，我们知之甚少。本研究通过训练六个相同规模（2.6B参数）和架构的LLMs，包括五个单语言模型（英语、德语、法语、意大利语和西班牙语）和一个涵盖这些语言的多语言模型，来深入探讨这一问题。为确保评估的准确性，我们将标准偏差测试自动翻译成五种语言，并由专家验证其翻译质量和偏差保留情况。研究结果显示，多语言训练不仅能有效减少偏差，还能提升预测准确性，优于同等条件下的单语言模型。",
    "title_cn": "多语言大型语言模型能否缓解刻板印象偏见？",
    "tags": [
      "LLM理论",
      "人工智能",
      "语言处理"
    ]
  },
  {
    "title": "Empirical Study of Symmetrical Reasoning in Conversational Chatbots",
    "submit_datetime": "2024年07月08日",
    "abstract": "This work explores the capability of conversational chatbots powered by large language models (LLMs), to understand and characterize predicate symmetry, a cognitive linguistic function traditionally believed to be an inherent human trait. Leveraging in-context learning (ICL), a paradigm shift enabling chatbots to learn new tasks from prompts without re-training, we assess the symmetrical reasoning of five chatbots: ChatGPT 4, Huggingface chat AI, Microsoft's Copilot AI, LLaMA through Perplexity, and Gemini Advanced. Using the Symmetry Inference Sentence (SIS) dataset by Tanchip et al. (2020), we compare chatbot responses against human evaluations to gauge their understanding of predicate symmetry. Experiment results reveal varied performance among chatbots, with some approaching human-like reasoning capabilities. Gemini, for example, reaches a correlation of 0.85 with human scores, while providing a sounding justification for each symmetry evaluation. This study underscores the potential and limitations of LLMs in mirroring complex cognitive processes as symmetrical reasoning.",
    "pdf_link": "https://arxiv.org/abs/2407.05734",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05734v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05734/gemini7_cormat.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05734v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05734/sim_scores.png"
      }
    ],
    "abstract_cn": "本研究探索了大型语言模型 (LLM) 驱动的对话聊天机器人在理解谓词对称性方面的能力，这是一种传统上被视为人类独有的认知语言功能。通过利用上下文学习 (ICL) 这一创新方法，我们评估了 ChatGPT 4、Huggingface 聊天 AI、微软 Copilot AI、Perplexity 的 LLaMA 和 Gemini Advanced 这五款聊天机器人的对称推理能力。我们采用 Tanchip 等人 (2020) 的 Symmetry Inference Sentence (SIS) 数据集，对比聊天机器人的响应与人类评估，以检验它们对谓词对称性的理解。实验结果显示，各聊天机器人的表现参差不齐，部分已接近人类推理水平。例如，Gemini 与人类评分相关性高达 0.85，且每次评估均提供合理解释。此研究凸显了 LLM 在模拟对称推理等复杂认知过程中的潜力与局限。",
    "title_cn": "探究对话型聊天机器人中的对称推理实证研究",
    "tags": [
      "LLM应用",
      "人工智能",
      "语言处理"
    ]
  },
  {
    "title": "Is GPT-4 Alone Sufficient for Automated Essay Scoring?: A Comparative Judgment Approach Based on Rater Cognition",
    "submit_datetime": "2024年07月08日",
    "abstract": "Large Language Models (LLMs) have shown promise in Automated Essay Scoring (AES), but their zero-shot and few-shot performance often falls short compared to state-of-the-art models and human raters. However, fine-tuning LLMs for each specific task is impractical due to the variety of essay prompts and rubrics used in real-world educational contexts. This study proposes a novel approach combining LLMs and Comparative Judgment (CJ) for AES, using zero-shot prompting to choose between two essays. We demonstrate that a CJ method surpasses traditional rubric-based scoring in essay scoring using LLMs.",
    "pdf_link": "https://arxiv.org/abs/2407.05733",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05733v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05733/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05733v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05733/x3.png"
      }
    ],
    "abstract_cn": "尽管大型语言模型在自动作文评分领域展现出潜力，但其零-shot 和少-shot 性能仍不及顶尖模型和人类评分者。鉴于实际教育场景中作文题目和评分标准的多样性，逐一微调模型并不现实。为此，本研究创新性地结合了 LLM 与比较判断技术，通过零-shot 提示在两篇作文间做出选择，结果显示，这种方法在 LLM 辅助的作文评分中，显著优于传统评分标准。",
    "title_cn": "GPT-4 能否独立胜任自动作文评分？本研究采用基于评分者认知的比较判断方法，探讨其可行性。",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "PsycoLLM: Enhancing LLM for Psychological Understanding and Evaluation",
    "submit_datetime": "2024年07月08日",
    "abstract": "Mental health has attracted substantial attention in recent years and LLM can be an effective technology for alleviating this problem owing to its capability in text understanding and dialogue. However, existing research in this domain often suffers from limitations, such as training on datasets lacking crucial prior knowledge and evidence, and the absence of comprehensive evaluation methods. In this paper, we propose a specialized psychological large language model (LLM), named PsycoLLM, trained on a proposed high-quality psychological dataset, including single-turn QA, multi-turn dialogues enriched with prior knowledge and knowledge-based QA. Additionally, to compare the performance of PsycoLLM with other LLMs, we develop a comprehensive psychological benchmark based on authoritative psychological counseling examinations in China, which includes assessments of professional ethics, theoretical proficiency, and case analysis. The experimental results on the benchmark illustrates the effectiveness of PsycoLLM, which demonstrates superior performance compared to other LLMs.",
    "pdf_link": "https://arxiv.org/abs/2407.05721",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05721v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05721/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05721v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05721/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05721v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05721/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05721v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05721/x4.png"
      }
    ],
    "abstract_cn": "近年来，心理健康备受瞩目，LLM凭借其出色的文本理解和对话能力，成为缓解这一问题的有力工具。然而，现有研究常因数据集缺乏关键先验知识、评估方法不全面而受限。为此，我们推出了PsycoLLM，一款专为心理学设计的大型语言模型，它基于一个精心构建的高质量心理学数据集进行训练，涵盖单轮问答、多轮对话及富含先验知识的问答。为评估PsycoLLM的性能，我们依据中国权威心理咨询考试，打造了一个全面的心理学基准，包括专业伦理、理论熟练度和案例分析的考核。实验结果表明，PsycoLLM在各项测试中表现卓越，远超其他LLM。",
    "title_cn": "PsycoLLM：提升 LLM 的心理理解和评估能力",
    "tags": [
      "LLM应用",
      "心理健康",
      "人工智能"
    ]
  },
  {
    "title": "InverseCoder: Unleashing the Power of Instruction-Tuned Code LLMs with Inverse-Instruct",
    "submit_datetime": "2024年07月08日",
    "abstract": "Recent advancements in open-source code large language models (LLMs) have demonstrated remarkable coding abilities by fine-tuning on the data generated from powerful closed-source LLMs such as GPT-3.5 and GPT-4 for instruction tuning. This paper explores how to further improve an instruction-tuned code LLM by generating data from itself rather than querying closed-source LLMs. Our key observation is the misalignment between the translation of formal and informal languages: translating formal language (i.e., code) to informal language (i.e., natural language) is more straightforward than the reverse. Based on this observation, we propose INVERSE-INSTRUCT, which summarizes instructions from code snippets instead of the reverse. Specifically, given an instruction tuning corpus for code and the resulting instruction-tuned code LLM, we ask the code LLM to generate additional high-quality instructions for the original corpus through code summarization and self-evaluation. Then, we fine-tune the base LLM on the combination of the original corpus and the self-generated one, which yields a stronger instruction-tuned LLM. We present a series of code LLMs named InverseCoder, which surpasses the performance of the original code LLMs on a wide range of benchmarks, including Python text-to-code generation, multilingual coding, and data-science code generation.",
    "pdf_link": "https://arxiv.org/abs/2407.05700",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05700v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05700/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05700v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05700/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05700v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05700/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05700v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05700/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05700v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05700/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05700v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05700/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05700v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05700/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05700v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05700/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05700v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05700/similarity.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.05700v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05700/scaling.png"
      }
    ],
    "abstract_cn": "近期，开源代码大型语言模型 (LLM) 通过在由 GPT-3.5 和 GPT-4 等闭源 LLM 生成的数据上进行指令调优，展现了卓越的编码能力。本文探讨了如何通过从自身生成数据而非依赖闭源 LLM 来进一步提升指令调优的代码 LLM。我们发现，将代码（正式语言）翻译为自然语言（非正式语言）比反向翻译更为直接。基于此，我们提出 INVERSE-INSTRUCT 方法，从代码片段中提取指令而非相反。具体而言，我们利用代码 LLM 对原始语料库进行代码摘要和自我评估，生成高质量指令，进而结合原始与新生成的语料库对基础 LLM 进行微调，得到更强大的指令调优 LLM。我们推出的 InverseCoder 系列模型，在 Python 文本到代码生成、多语言编码及数据科学代码生成等多项基准测试中，性能超越了原始代码 LLM。",
    "title_cn": "InverseCoder：借助 Inverse-Instruct 技术，释放指令调优代码大型模型（LLM）的潜能。",
    "tags": [
      "LLM应用",
      "软件开发",
      "人工智能"
    ]
  },
  {
    "title": "Sub-SA: Strengthen In-context Learning via Submodular Selective Annotation",
    "submit_datetime": "2024年07月08日",
    "abstract": "In-context learning (ICL) leverages in-context examples as prompts for the predictions of Large Language Models (LLMs). These prompts play a crucial role in achieving strong performance. However, the selection of suitable prompts from a large pool of labeled examples often entails significant annotation costs. To address this challenge, we propose \\textbf{Sub-SA} (\\textbf{Sub}modular \\textbf{S}elective \\textbf{A}nnotation), a submodule-based selective annotation method. The aim of Sub-SA is to reduce annotation costs while improving the quality of in-context examples and minimizing the time consumption of the selection process. In Sub-SA, we design a submodular function that facilitates effective subset selection for annotation and demonstrates the characteristics of monotonically and submodularity from the theoretical perspective. Specifically, we propose \\textbf{RPR} (\\textbf{R}eward and \\textbf{P}enalty \\textbf{R}egularization) to better balance the diversity and representativeness of the unlabeled dataset attributed to a reward term and a penalty term, respectively. Consequently, the selection for annotations can be effectively addressed with a simple yet effective greedy search algorithm based on the submodular function. Finally, we apply the similarity prompt retrieval to get the examples for ICL.",
    "pdf_link": "https://arxiv.org/abs/2407.05693",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05693v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05693/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05693v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05693/x2.png"
      }
    ],
    "abstract_cn": "ICL 通过上下文示例作为 LLM 预测的提示，这些提示对实现高性能至关重要。然而，从众多标记示例中挑选合适提示往往成本高昂。为此，我们引入了 Sub-SA，一种基于子模块的选择性注释方法，旨在降低成本、提升示例质量并简化选择流程。Sub-SA 设计了子模块函数，助力高效注释子集选择，并从理论层面展现其单调与子模块特性。我们进一步提出 RPR，通过奖励与惩罚机制平衡数据多样性与代表性。基于此，我们采用简单高效的贪婪算法进行注释选择。最终，通过相似性提示检索为 ICL 提供示例。",
    "title_cn": "Sub-SA：借助子模块选择性注释强化上下文学习",
    "tags": [
      "LLM应用",
      "人工智能",
      "数据注释"
    ]
  },
  {
    "title": "Pruning Large Language Models to Intra-module Low-rank Architecture with Transitional Activations",
    "submit_datetime": "2024年07月08日",
    "abstract": "Structured pruning fundamentally reduces computational and memory overheads of large language models (LLMs) and offers a feasible solution for end-side LLM deployment. Structurally pruned models remain dense and high-precision, highly compatible with further tuning and compression. However, as the coarse-grained structured pruning poses large damage to the highly interconnected model, achieving a high compression ratio for scaled-up LLMs remains a challenge. In this paper, we introduce a task-agnostic structured pruning approach coupled with a compact Transformer architecture design. The proposed approach, named TransAct, reduces transitional activations inside multi-head attention (MHA) and multi-layer perceptron (MLP) modules, while preserving the inter-module activations that are sensitive to perturbations. Hence, the LLM is pruned into an intra-module low-rank architecture, significantly reducing weights, KV Cache and attention computation. TransAct is implemented on the LLaMA model and evaluated on downstream benchmarks. Results verify the optimality of our approach at high compression with respect to both efficiency and performance. Further, ablation studies reveal the strength of activation-guided iterative pruning and provide experimental analysis on the redundancy of MHA and MLP modules.",
    "pdf_link": "https://arxiv.org/abs/2407.05690",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05690v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05690/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05690v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05690/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05690v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05690/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05690v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05690/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05690v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05690/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05690v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05690/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05690v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05690/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05690v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05690/x8.png"
      }
    ],
    "abstract_cn": "结构化剪枝技术有效降低了大型语言模型的计算和内存负担，为终端部署提供了可行方案。剪枝后的模型保持高密度和高精度，便于后续调优和压缩。然而，粗粒度剪枝对模型的损害较大，实现高压缩比仍具挑战。本文提出了一种任务无关的结构化剪枝方法TransAct，结合紧凑Transformer架构，减少MHA和MLP模块内的激活，同时保护模块间敏感激活。这使得LLM转化为低秩架构，大幅减少权重和计算。在LLaMA模型上的实验表明，TransAct在保持高效性和性能的同时，实现了高压缩比。消融研究进一步证实了激活引导剪枝的有效性，并分析了MHA和MLP模块的冗余。",
    "title_cn": "精简大型语言模型至模块内低秩结构，结合过渡激活技术",
    "tags": [
      "LLM理论",
      "计算机科学",
      "人工智能"
    ]
  },
  {
    "title": "Retrieved In-Context Principles from Previous Mistakes",
    "submit_datetime": "2024年07月08日",
    "abstract": "In-context learning (ICL) has been instrumental in adapting Large Language Models (LLMs) to downstream tasks using correct input-output examples. Recent advances have attempted to improve model performance through principles derived from mistakes, yet these approaches suffer from lack of customization and inadequate error coverage. To address these limitations, we propose Retrieved In-Context Principles (RICP), a novel teacher-student framework. In RICP, the teacher model analyzes mistakes from the student model to generate reasons and insights for preventing similar mistakes. These mistakes are clustered based on their underlying reasons for developing task-level principles, enhancing the error coverage of principles. During inference, the most relevant mistakes for each question are retrieved to create question-level principles, improving the customization of the provided guidance. RICP is orthogonal to existing prompting methods and does not require intervention from the teacher model during inference. Experimental results across seven reasoning benchmarks reveal that RICP effectively enhances performance when applied to various prompting strategies.",
    "pdf_link": "https://arxiv.org/abs/2407.05682",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05682v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05682/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05682v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05682/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05682v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05682/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05682v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05682/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05682v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05682/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05682v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05682/x6.png"
      }
    ],
    "abstract_cn": "In-context learning (ICL) 在 LLM 适应下游任务中扮演关键角色，但现有方法在定制化和错误覆盖上存在不足。为此，我们引入了 Retrieval In-Context Principles (RICP)，一个创新的师生框架。RICP 通过教师模型分析学生模型的错误，生成针对性的改进建议，并根据错误原因进行分类，提升原则的错误覆盖率。在推理时，系统会为每个问题定制相关原则，无需教师模型介入。实验表明，RICP 能有效提升多种提示策略的性能，跨越七个推理基准。",
    "title_cn": "汲取过往失误中的上下文原则",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Collective Innovation in Groups of Large Language Models",
    "submit_datetime": "2024年07月07日",
    "abstract": "Human culture relies on collective innovation: our ability to continuously explore how existing elements in our environment can be combined to create new ones. Language is hypothesized to play a key role in human culture, driving individual cognitive capacities and shaping communication. Yet the majority of models of collective innovation assign no cognitive capacities or language abilities to agents. Here, we contribute a computational study of collective innovation where agents are Large Language Models (LLMs) that play Little Alchemy 2, a creative video game originally developed for humans that, as we argue, captures useful aspects of innovation landscapes not present in previous test-beds. We, first, study an LLM in isolation and discover that it exhibits both useful skills and crucial limitations. We, then, study groups of LLMs that share information related to their behaviour and focus on the effect of social connectivity on collective performance. In agreement with previous human and computational studies, we observe that groups with dynamic connectivity out-compete fully-connected groups. Our work reveals opportunities and challenges for future studies of collective innovation that are becoming increasingly relevant as Generative Artificial Intelligence algorithms and humans innovate alongside each other.",
    "pdf_link": "https://arxiv.org/abs/2407.05377",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05377v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05377/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05377v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05377/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05377v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05377/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05377v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05377/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05377v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05377/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05377v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05377/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05377v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05377/x7.png"
      }
    ],
    "abstract_cn": "人类文化根植于集体创新，即我们不断探索如何将环境中的现有元素重新组合以创造新事物的能力。语言在这一过程中被认为起着核心作用，它不仅推动个体认知发展，还塑造了我们的交流方式。然而，大多数集体创新模型并未考虑代理的认知或语言能力。为此，我们开展了一项计算研究，其中代理是大型语言模型（LLM），它们参与《小炼金术2》这款创意游戏，该游戏能有效模拟创新环境中的关键要素。我们首先单独分析了一个LLM的表现，发现它既有显著技能也存在明显局限。随后，我们考察了共享信息的LLM群体，并深入探讨了社交连接对集体创新表现的影响。研究结果显示，具有动态连接的群体在创新竞赛中超越了完全连接的群体，这与先前的研究相呼应。我们的研究不仅揭示了未来探索集体创新的新机遇，也指出了面临的挑战，特别是在生成式人工智能与人类共同创新的背景下，这些发现显得尤为重要。",
    "title_cn": "大型语言模型群体中的集体创新",
    "tags": [
      "Agent",
      "人工智能",
      "游戏开发"
    ]
  },
  {
    "title": "MINDECHO: Role-Playing Language Agents for Key Opinion Leaders",
    "submit_datetime": "2024年07月07日",
    "abstract": "Large language models~(LLMs) have demonstrated impressive performance in various applications, among which role-playing language agents (RPLAs) have engaged a broad user base. Now, there is a growing demand for RPLAs that represent Key Opinion Leaders (KOLs), \\ie, Internet celebrities who shape the trends and opinions in their domains. However, research in this line remains underexplored. In this paper, we hence introduce MINDECHO, a comprehensive framework for the development and evaluation of KOL RPLAs. MINDECHO collects KOL data from Internet video transcripts in various professional fields, and synthesizes their conversations leveraging GPT-4. Then, the conversations and the transcripts are used for individualized model training and inference-time retrieval, respectively. Our evaluation covers both general dimensions (\\ie, knowledge and tones) and fan-centric dimensions for KOLs. Extensive experiments validate the effectiveness of MINDECHO in developing and evaluating KOL RPLAs.",
    "pdf_link": "https://arxiv.org/abs/2407.05305",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05305v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05305/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05305v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05305/x2.png"
      }
    ],
    "abstract_cn": "大型语言模型在众多应用中表现卓越，尤其是角色扮演语言代理，深受用户喜爱。如今，代表关键意见领袖（即网络红人，他们主导着各自领域的潮流和观点）的 RPLAs 需求日益增长。然而，相关研究尚显不足。为此，我们提出了 MINDECHO 框架，旨在全面支持 KOL RPLAs 的开发与评估。MINDECHO 从多领域网络视频中采集 KOL 数据，并借助 GPT-4 模拟其对话。随后，这些对话与转录文本分别用于定制化模型训练与实时推理。我们的评估体系兼顾通用标准（如知识深度与语调）与粉丝视角。实验结果充分证明了 MINDECHO 在 KOL RPLAs 开发与评估中的高效性。",
    "title_cn": "MINDECHO：专为关键意见领袖打造的角色扮演语言代理",
    "tags": [
      "Agent",
      "社交媒体",
      "网络红人"
    ]
  },
  {
    "title": "WorkArena++: Towards Compositional Planning and Reasoning-based Common Knowledge Work Tasks",
    "submit_datetime": "2024年07月07日",
    "abstract": "The ability of large language models (LLMs) to mimic human-like intelligence has led to a surge in LLM-based autonomous agents. Though recent LLMs seem capable of planning and reasoning given user instructions, their effectiveness in applying these capabilities for autonomous task solving remains underexplored. This is especially true in enterprise settings, where automated agents hold the promise of a high impact. To fill this gap, we propose WorkArena++, a novel benchmark consisting of 682 tasks corresponding to realistic workflows routinely performed by knowledge workers. WorkArena++ is designed to evaluate the planning, problem-solving, logical/arithmetic reasoning, retrieval, and contextual understanding abilities of web agents. Our empirical studies across state-of-the-art LLMs and vision-language models (VLMs), as well as human workers, reveal several challenges for such models to serve as useful assistants in the workplace. In addition to the benchmark, we provide a mechanism to effortlessly generate thousands of ground-truth observation/action traces, which can be used for fine-tuning existing models. Overall, we expect this work to serve as a useful resource to help the community progress toward capable autonomous agents. The benchmark can be found at https://github.com/ServiceNow/WorkArena/tree/workarena-plus-plus.",
    "pdf_link": "https://arxiv.org/abs/2407.05291",
    "graphs": [],
    "abstract_cn": "大型语言模型 (LLM) 模仿人类智能的能力催生了基于 LLM 的自主代理的兴起。尽管这些模型在用户指令下展现出规划和推理的能力，但它们在实际任务解决中的应用效果仍有待深入探索，尤其是在企业环境中。为此，我们推出了 WorkArena++，这是一个包含 682 个真实工作流程任务的基准测试，旨在全面评估网络代理的各项能力。我们的研究发现，这些模型在成为高效工作助手方面仍面临挑战。此外，我们还开发了一种机制，可轻松生成大量真实数据，用于模型的微调。我们期待这项工作能为社区在自主代理领域的发展提供有力支持。基准测试详情请访问：https://github.com/ServiceNow/WorkArena/tree/workarena-plus-plus。",
    "title_cn": "WorkArena++：探索基于组合规划与推理的通用知识工作任务",
    "tags": [
      "Agent",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Multimodal Language Models for Domain-Specific Procedural Video Summarization",
    "submit_datetime": "2024年07月07日",
    "abstract": "Videos serve as a powerful medium to convey ideas, tell stories, and provide detailed instructions, especially through long-format tutorials. Such tutorials are valuable for learning new skills at one's own pace, yet they can be overwhelming due to their length and dense content. Viewers often seek specific information, like precise measurements or step-by-step execution details, making it essential to extract and summarize key segments efficiently. An intelligent, time-sensitive video assistant capable of summarizing and detecting highlights in long videos is highly sought after. Recent advancements in Multimodal Large Language Models offer promising solutions to develop such an assistant. Our research explores the use of multimodal models to enhance video summarization and step-by-step instruction generation within specific domains. These models need to understand temporal events and relationships among actions across video frames. Our approach focuses on fine-tuning TimeChat to improve its performance in specific domains: cooking and medical procedures. By training the model on domain-specific datasets like Tasty for cooking and MedVidQA for medical procedures, we aim to enhance its ability to generate concise, accurate summaries of instructional videos. We curate and restructure these datasets to create high-quality video-centric instruction data. Our findings indicate that when finetuned on domain-specific procedural data, TimeChat can significantly improve the extraction and summarization of key instructional steps in long-format videos. This research demonstrates the potential of specialized multimodal models to assist with practical tasks by providing personalized, step-by-step guidance tailored to the unique aspects of each domain.",
    "pdf_link": "https://arxiv.org/abs/2407.05419",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05419v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05419/timechat.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05419v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05419/arch.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05419v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05419/timechat2.png"
      }
    ],
    "abstract_cn": "视频不仅是传达思想和故事的强大工具，还能通过长教程提供详尽指导。然而，这些教程因其长度和密集内容可能令人望而生畏。观众往往需要特定信息，如精确测量或详细步骤，因此高效提取和总结关键片段至关重要。一个能够总结和检测长视频亮点的智能助手备受追捧。多模态大型语言模型的最新进展为此类助手开发提供了希望。我们研究如何利用这些模型增强视频总结和特定领域内逐步指导生成。这些模型需理解视频帧间的时间事件和动作关系。我们专注于微调TimeChat，以提升其在烹饪和医疗程序等领域的性能。通过在特定领域数据集上训练模型，我们旨在增强其生成简洁、准确教程视频总结的能力。我们精心挑选和重组数据集，创建高质量视频指导数据。研究表明，在特定领域程序数据上微调后，TimeChat能显著提升长视频中关键步骤的提取和总结。这项研究展示了专门多模态模型通过提供个性化、逐步指导来协助实际任务的潜力。",
    "title_cn": "特定领域程序视频摘要的多模态语言模型",
    "tags": [
      "LLM应用",
      "",
      ""
    ]
  },
  {
    "title": "VideoCoT: A Video Chain-of-Thought Dataset with Active Annotation Tool",
    "submit_datetime": "2024年07月07日",
    "abstract": "Multimodal large language models (MLLMs) are flourishing, but mainly focus on images with less attention than videos, especially in sub-fields such as prompt engineering, video chain-of-thought (CoT), and instruction tuning on videos. Therefore, we try to explore the collection of CoT datasets in videos to lead to video OpenQA and improve the reasoning ability of MLLMs. Unfortunately, making such video CoT datasets is not an easy task. Given that human annotation is too cumbersome and expensive, while machine-generated is not reliable due to the hallucination issue, we develop an automatic annotation tool that combines machine and human experts, under the active learning paradigm. Active learning is an interactive strategy between the model and human experts, in this way, the workload of human labeling can be reduced and the quality of the dataset can be guaranteed. With the help of the automatic annotation tool, we strive to contribute three datasets, namely VideoCoT, TopicQA, TopicCoT. Furthermore, we propose a simple but effective benchmark based on the collected datasets, which exploits CoT to maximize the complex reasoning capabilities of MLLMs. Extensive experiments demonstrate the effectiveness our solution.",
    "pdf_link": "https://arxiv.org/abs/2407.05355",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05355v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05355/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05355v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05355/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05355v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05355/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05355v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05355/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05355v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05355/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05355v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05355/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05355v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05355/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05355v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05355/x8.png"
      }
    ],
    "abstract_cn": "多模态大型语言模型 (MLLMs) 正蓬勃发展，但对视频的关注不如图像，尤其是在提示工程、视频链-of-思维 (CoT) 和视频指令调整等领域。为此，我们探索视频中的 CoT 数据集，旨在推动视频 OpenQA 并增强 MLLMs 的推理能力。然而，构建视频 CoT 数据集颇具挑战。考虑到人工标注成本高且繁琐，机器生成又因幻觉问题不可靠，我们开发了结合机器与人类专家的自动标注工具，采用主动学习策略。该策略通过模型与专家的互动，既减轻了人工负担，又确保了数据质量。借助此工具，我们贡献了 VideoCoT、TopicQA 和 TopicCoT 三个数据集。此外，我们基于这些数据集提出了一个简单高效的基准，旨在通过 CoT 最大化 MLLMs 的复杂推理能力。实验结果充分验证了我们方法的有效性。",
    "title_cn": "VideoCoT：一款集成了主动注释工具的视频思维链数据集",
    "tags": [
      "LLM应用",
      "视频处理",
      "人工智能"
    ]
  },
  {
    "title": ": Towards Effective and Efficient Cost Function Design for Safe Reinforcement Learning via Large Language Model",
    "submit_datetime": "2024年07月07日",
    "abstract": "Different classes of safe reinforcement learning algorithms have shown satisfactory performance in various types of safety requirement scenarios. However, the existing methods mainly address one or several classes of specific safety requirement scenario problems and cannot be applied to arbitrary safety requirement scenarios. In addition, the optimization objectives of existing reinforcement learning algorithms are misaligned with the task requirements. Based on the need to address these issues, we propose $\\mathrm{E^{2}CFD}$, an effective and efficient cost function design framework. $\\mathrm{E^{2}CFD}$ leverages the capabilities of a large language model (LLM) to comprehend various safety scenarios and generate corresponding cost functions. It incorporates the \\textit{fast performance evaluation (FPE)} method to facilitate rapid and iterative updates to the generated cost function. Through this iterative process, $\\mathrm{E^{2}CFD}$ aims to obtain the most suitable cost function for policy training, tailored to the specific tasks within the safety scenario. Experiments have proven that the performance of policies trained using this framework is superior to traditional safe reinforcement learning algorithms and policies trained with carefully designed cost functions.",
    "pdf_link": "https://arxiv.org/abs/2407.05580",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05580/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05580/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05580/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05580/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05580/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05580/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05580/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05580/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05580/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05580/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05580/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05580/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05580/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05580/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05580/x15.png"
      }
    ],
    "abstract_cn": "在满足不同安全需求的场景中，各类安全强化学习算法表现出色，但它们通常只能应对特定场景，无法通用。此外，这些算法的优化目标往往与实际任务需求脱节。为此，我们设计了 $\\mathrm{E^{2}CFD}$ 框架，它借助大型语言模型的理解力，针对不同安全场景生成定制的代价函数，并通过快速性能评估方法实现快速迭代优化。实验结果显示，该框架训练出的策略性能超越了传统方法和人工设计的代价函数。",
    "title_cn": "利用大型语言模型，我们致力于设计既安全又高效的强化学习成本函数。",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "LLMBox: A Comprehensive Library for Large Language Models",
    "submit_datetime": "2024年07月07日",
    "abstract": "To facilitate the research on large language models (LLMs), this paper presents a comprehensive and unified library, LLMBox, to ease the development, use, and evaluation of LLMs. This library is featured with three main merits: (1) a unified data interface that supports the flexible implementation of various training strategies, (2) a comprehensive evaluation that covers extensive tasks, datasets, and models, and (3) more practical consideration, especially on user-friendliness and efficiency. With our library, users can easily reproduce existing methods, train new models, and conduct comprehensive performance comparisons. To rigorously test LLMBox, we conduct extensive experiments in a diverse coverage of evaluation settings, and experimental results demonstrate the effectiveness and efficiency of our library in supporting various implementations related to LLMs. The detailed introduction and usage guidance can be found at https://github.com/RUCAIBox/LLMBox.",
    "pdf_link": "https://arxiv.org/abs/2407.05563",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05563v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05563/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05563v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05563/x2.png"
      }
    ],
    "abstract_cn": "本文推出 LLMBox，一个全面且统一的库，旨在简化大型语言模型 (LLM) 的开发、使用和评估。该库三大亮点：(1) 灵活的统一数据接口，(2) 广泛任务、数据集和模型的全面评估，(3) 强调用户友好与效率。借助 LLMBox，用户能轻松复现、训练并比较模型性能。我们通过多样化实验验证了其有效性与效率。详情及指南请访问 https://github.com/RUCAIBox/LLMBox。",
    "title_cn": "LLMBox：大型语言模型的综合库",
    "tags": [
      "LLM应用",
      "软件开发",
      "人工智能"
    ]
  },
  {
    "title": "Faux Polyglot: A Study on Information Disparity in Multilingual Large Language Models",
    "submit_datetime": "2024年07月07日",
    "abstract": "With Retrieval Augmented Generation (RAG), Large Language Models (LLMs) are playing a pivotal role in information search and are being adopted globally. Although the multilingual capability of LLMs offers new opportunities to bridge the language barrier, do these capabilities translate into real-life scenarios where linguistic divide and knowledge conflicts between multilingual sources are known occurrences? In this paper, we studied LLM's linguistic preference in a RAG-based information search setting. We found that LLMs displayed systemic bias towards information in the same language as the query language in both information retrieval and answer generation. Furthermore, in scenarios where there is little information in the language of the query, LLMs prefer documents in high-resource languages, reinforcing the dominant views. Such bias exists for both factual and opinion-based queries. Our results highlight the linguistic divide within multilingual LLMs in information search systems. The seemingly beneficial multilingual capability of LLMs may backfire on information parity by reinforcing language-specific information cocoons or filter bubbles further marginalizing low-resource views.",
    "pdf_link": "https://arxiv.org/abs/2407.05502",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05502v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05502/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05502v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05502/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05502v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05502/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05502v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05502/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05502v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05502/Festival_Aggr_Visual.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05502v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05502/War_Aggr_Visual.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05502v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05502/second-language-preference-aggr.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05502v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05502/query-types-generation.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）通过检索增强生成（RAG）技术，在信息搜索领域发挥着核心作用，并已在全球普及。尽管LLMs的多语言特性为跨越语言障碍带来新希望，但这些特性是否能在多语言环境中有效应对语言隔阂和知识冲突，仍是一个疑问。我们的研究发现，LLMs在基于RAG的信息搜索中，对与查询语言相同的信息表现出系统性偏好，尤其在查询语言信息稀缺时，更倾向于高资源语言的文档，从而强化了主流观点。这种偏见在事实性和观点性查询中均存在。我们的研究揭示了多语言LLMs在信息搜索中的语言隔阂问题，指出其看似有益的多语言能力可能加剧信息不平等，通过强化特定语言的信息茧房或过滤气泡，进一步边缘化低资源观点。",
    "title_cn": "《伪多语者》：探究多语言大型模型中的信息鸿沟",
    "tags": [
      "RAG",
      "信息搜索",
      "多语言处理"
    ]
  },
  {
    "title": "Just read twice: closing the recall gap for recurrent language models",
    "submit_datetime": "2024年07月07日",
    "abstract": "Recurrent large language models that compete with Transformers in language modeling perplexity are emerging at a rapid rate (e.g., Mamba, RWKV). Excitingly, these architectures use a constant amount of memory during inference. However, due to the limited memory, recurrent LMs cannot recall and use all the information in long contexts leading to brittle in-context learning (ICL) quality. A key challenge for efficient LMs is selecting what information to store versus discard. In this work, we observe the order in which information is shown to the LM impacts the selection difficulty. To formalize this, we show that the hardness of information recall reduces to the hardness of a problem called set disjointness (SD), a quintessential problem in communication complexity that requires a streaming algorithm (e.g., recurrent model) to decide whether inputted sets are disjoint. We empirically and theoretically show that the recurrent memory required to solve SD changes with set order, i.e., whether the smaller set appears first in-context. Our analysis suggests, to mitigate the reliance on data order, we can put information in the right order in-context or process prompts non-causally. Towards that end, we propose: (1) JRT-Prompt, where context gets repeated multiple times in the prompt, effectively showing the model all data orders. This gives $11.0 \\pm 1.3$ points of improvement, averaged across $16$ recurrent LMs and the $6$ ICL tasks, with $11.9\\times$ higher throughput than FlashAttention-2 for generation prefill (length $32$k, batch size $16$, NVidia H100). We then propose (2) JRT-RNN, which uses non-causal prefix-linear-attention to process prompts and provides $99\\%$ of Transformer quality at $360$M params., $30$B tokens and $96\\%$ at $1.3$B params., $50$B tokens on average across the tasks, with $19.2\\times$ higher throughput for prefill than FA2.",
    "pdf_link": "https://arxiv.org/abs/2407.05483",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05483v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05483/main_fig_jrt1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05483v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05483/set_dijsointness.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05483v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05483/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05483v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05483/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05483v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05483/x3.png"
      }
    ],
    "abstract_cn": "循环大型语言模型正迅速崛起，与Transformer在语言模型困惑度上展开竞争。这些模型在推理时仅使用固定内存，但受限于此，它们难以充分利用长上下文信息，导致上下文学习质量不稳定。高效语言模型的关键在于精准选择存储与丢弃的信息。我们发现，信息呈现的顺序直接影响选择难度。通过将问题简化为集合不相交问题，我们揭示了循环模型在处理不同顺序集合时的内存需求变化。为减少对数据顺序的依赖，我们提出两种方案：JRT-Prompt重复展示上下文，全面展示数据顺序，平均提升11.0±1.3点，生成预填充吞吐量提升11.9倍；JRT-RNN采用非因果前缀线性注意力处理提示，以360M参数和30B令牌达到99%的Transformer质量，预填充吞吐量提升19.2倍。",
    "title_cn": "双读法：助力循环语言模型提升召回率",
    "tags": [
      "LLM理论",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Biomedical Nested NER with Large Language Model and UMLS Heuristics",
    "submit_datetime": "2024年07月07日",
    "abstract": "In this paper, we present our system for the BioNNE English track, which aims to extract 8 types of biomedical nested named entities from biomedical text. We use a large language model (Mixtral 8x7B instruct) and ScispaCy NER model to identify entities in an article and build custom heuristics based on unified medical language system (UMLS) semantic types to categorize the entities. We discuss the results and limitations of our system and propose future improvements. Our system achieved an F1 score of 0.39 on the BioNNE validation set and 0.348 on the test set.",
    "pdf_link": "https://arxiv.org/abs/2407.05480",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05480v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05480/bionne_design.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05480v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05480/bionne_inout_flow.png"
      }
    ],
    "abstract_cn": "本文介绍了一个专为 BioNNE 英语赛道设计的系统，旨在从生物医学文本中提取 8 种嵌套命名实体。我们结合大型语言模型（Mixtral 8x7B instruct）和 ScispaCy NER 模型进行实体识别，并利用 UMLS 语义类型定制分类策略。文章还探讨了系统的性能与局限，并展望了未来的优化方向。该系统在验证集和测试集上的 F1 分数分别为 0.39 和 0.348。",
    "title_cn": "结合大型语言模型与UMLS启发式方法的生物医学嵌套NER研究",
    "tags": [
      "LLM应用",
      "生物医学",
      ""
    ]
  },
  {
    "title": "Enhancing Hallucination Detection through Perturbation-Based Synthetic Data Generation in System Responses",
    "submit_datetime": "2024年07月07日",
    "abstract": "Detecting hallucinations in large language model (LLM) outputs is pivotal, yet traditional fine-tuning for this classification task is impeded by the expensive and quickly outdated annotation process, especially across numerous vertical domains and in the face of rapid LLM advancements. In this study, we introduce an approach that automatically generates both faithful and hallucinated outputs by rewriting system responses. Experimental findings demonstrate that a T5-base model, fine-tuned on our generated dataset, surpasses state-of-the-art zero-shot detectors and existing synthetic generation methods in both accuracy and latency, indicating efficacy of our approach.",
    "pdf_link": "https://arxiv.org/abs/2407.05474",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05474v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05474/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05474v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05474/newPlot755BoundariesFinal.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05474v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05474/TemplateSnap.png"
      }
    ],
    "abstract_cn": "检测 LLM 输出中的幻觉至关重要，但传统微调方法因昂贵且迅速过时的标注过程而受阻。本研究提出一种新方法，通过重写系统响应自动生成忠实与幻觉输出。实验显示，微调后的 T5-base 模型在准确性与速度上均优于现有技术，证明了我们方法的有效性。",
    "title_cn": "利用基于扰动的合成数据生成技术，提升系统响应中幻觉检测的效能。",
    "tags": [
      "LLM应用",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Experiments with truth using Machine Learning: Spectral analysis and explainable classification of synthetic, false, and genuine information",
    "submit_datetime": "2024年07月07日",
    "abstract": "Misinformation is still a major societal problem and the arrival of Large Language Models (LLMs) only added to it. This paper analyzes synthetic, false, and genuine information in the form of text from spectral analysis, visualization, and explainability perspectives to find the answer to why the problem is still unsolved despite multiple years of research and a plethora of solutions in the literature. Various embedding techniques on multiple datasets are used to represent information for the purpose. The diverse spectral and non-spectral methods used on these embeddings include t-distributed Stochastic Neighbor Embedding (t-SNE), Principal Component Analysis (PCA), and Variational Autoencoders (VAEs). Classification is done using multiple machine learning algorithms. Local Interpretable Model-Agnostic Explanations (LIME), SHapley Additive exPlanations (SHAP), and Integrated Gradients are used for the explanation of the classification. The analysis and the explanations generated show that misinformation is quite closely intertwined with genuine information and the machine learning algorithms are not as effective in separating the two despite the claims in the literature.",
    "pdf_link": "https://arxiv.org/abs/2407.05464",
    "graphs": [],
    "abstract_cn": "错误信息仍是社会难题，大型语言模型 (LLM) 的兴起更使其雪上加霜。本文通过光谱分析、可视化及可解释性视角，深入探讨合成、虚假与真实文本信息的复杂关系，揭示为何多年研究与众多解决方案仍未能彻底解决问题。我们采用多数据集上的多种嵌入技术，运用 t-SNE、PCA 及 VAEs 等方法进行分析，并借助 LIME、SHAP 和集成梯度等工具解释分类结果。研究显示，错误信息与真实信息紧密交织，机器学习算法在分离二者方面效果有限，与文献中的乐观声称相悖。",
    "title_cn": "探索机器学习在真实性实验中的应用：通过光谱分析与可解释分类，揭示合成、虚假与真实信息的奥秘。",
    "tags": [
      "LLM应用",
      "社会科学",
      "信息技术"
    ]
  },
  {
    "title": "Training Task Experts through Retrieval Based Distillation",
    "submit_datetime": "2024年07月07日",
    "abstract": "One of the most reliable ways to create deployable models for specialized tasks is to obtain an adequate amount of high-quality task-specific data. However, for specialized tasks, often such datasets do not exist. Existing methods address this by creating such data from large language models (LLMs) and then distilling such knowledge into smaller models. However, these methods are limited by the quality of the LLMs output, and tend to generate repetitive or incorrect data. In this work, we present Retrieval Based Distillation (ReBase), a method that first retrieves data from rich online sources and then transforms them into domain-specific data. This method greatly enhances data diversity. Moreover, ReBase generates Chain-of-Thought reasoning and distills the reasoning capacity of LLMs. We test our method on 4 benchmarks and results show that our method significantly improves performance by up to 7.8% on SQuAD, 1.37% on MNLI, and 1.94% on BigBench-Hard.",
    "pdf_link": "https://arxiv.org/abs/2407.05463",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05463v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05463/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05463v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05463/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05463v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05463/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05463v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05463/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05463v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05463/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05463v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05463/filtered_rows_percentage.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05463v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05463/config.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05463v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05463/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05463v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05463/x7.png"
      }
    ],
    "abstract_cn": "构建专用任务的可部署模型，最可靠途径之一是获取大量高质量的特定任务数据。然而，这类数据集往往稀缺。现有技术通过从大型语言模型（LLM）中生成数据并提炼至小型模型来应对，但受限于LLM输出质量，常产生重复或错误数据。我们提出的基于检索的提炼（ReBase）方法，首先从丰富在线资源中检索数据，再转化为领域特定数据，极大提升数据多样性。ReBase还能生成思维链推理，提炼LLM的推理能力。在四个基准测试中，我们的方法在SQuAD上性能提升高达7.8%，MNLI上提升1.37%，BigBench-Hard上提升1.94%。",
    "title_cn": "利用基于检索的蒸馏技术培养任务专家",
    "tags": [
      "LLM应用",
      "人工智能",
      "数据科学"
    ]
  },
  {
    "title": "Enhancing Computer Programming Education with LLMs: A Study on Effective Prompt Engineering for Python Code Generation",
    "submit_datetime": "2024年07月07日",
    "abstract": "Large language models (LLMs) and prompt engineering hold significant potential for advancing computer programming education through personalized instruction. This paper explores this potential by investigating three critical research questions: the systematic categorization of prompt engineering strategies tailored to diverse educational needs, the empowerment of LLMs to solve complex problems beyond their inherent capabilities, and the establishment of a robust framework for evaluating and implementing these strategies. Our methodology involves categorizing programming questions based on educational requirements, applying various prompt engineering strategies, and assessing the effectiveness of LLM-generated responses. Experiments with GPT-4, GPT-4o, Llama3-8b, and Mixtral-8x7b models on datasets such as LeetCode and USACO reveal that GPT-4o consistently outperforms others, particularly with the \"multi-step\" prompt strategy. The results show that tailored prompt strategies significantly enhance LLM performance, with specific strategies recommended for foundational learning, competition preparation, and advanced problem-solving. This study underscores the crucial role of prompt engineering in maximizing the educational benefits of LLMs. By systematically categorizing and testing these strategies, we provide a comprehensive framework for both educators and students to optimize LLM-based learning experiences. Future research should focus on refining these strategies and addressing current LLM limitations to further enhance educational outcomes in computer programming instruction.",
    "pdf_link": "https://arxiv.org/abs/2407.05437",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05437v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05437/system.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05437v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05437/model.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05437v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05437/usaco_grading.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05437v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05437/prompt_1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05437v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05437/prompt_2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05437v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05437/prompt_3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05437v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05437/prompt_4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05437v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05437/prompt_5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05437v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05437/prompt_6.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLM）与提示工程相结合，为个性化计算机编程教育开辟了新天地。本文深入探讨了这一领域，聚焦于三个核心问题：如何系统地分类适用于不同教育背景的提示工程策略、如何扩展LLM解决复杂问题的能力，以及如何构建一个稳固的评估与实施框架。我们通过根据教育需求对编程问题进行分类，运用多样化的提示策略，并评估LLM的响应效果，来实施研究。实验结果显示，在LeetCode和USACO等数据集上，GPT-4o模型凭借其“多步骤”提示策略，表现尤为突出。研究证实，量身定制的提示策略能大幅提升LLM的表现，并为不同学习阶段推荐了相应的策略。本研究凸显了提示工程在提升LLM教育价值中的重要性，并提供了一个全面的框架，助力教育者和学生优化基于LLM的学习过程。未来研究应致力于精进这些策略，并克服LLM的现有局限，以期在计算机编程教育领域取得更大突破。",
    "title_cn": "利用 LLM 提升编程教育：探索 Python 代码生成中的高效提示设计",
    "tags": [
      "LLM应用",
      "",
      "计算机编程"
    ]
  },
  {
    "title": "LTLBench: Towards Benchmarks for Evaluating Temporal Logic Reasoning in Large Language Models",
    "submit_datetime": "2024年07月07日",
    "abstract": "Temporal reasoning (TR) is a critical component of artificial intelligence, encompassing understanding and processing temporal information and relationships between events. To discover and study the TR ability in Large Language Models (LLMs), various datasets have been constructed in different ways for evaluating various aspects of TR ability. Our work proposes a novel approach to design and develop a pipeline for constructing datasets to evaluate the TR ability of LLMs by leveraging random directed graph generation, LTL formula, and the NuSMV model checker. Based on the pipeline, we have also constructed a dataset as a benchmark, namely LTLBench, consisting of 2,000 TR challenges and evaluated six LLMs with it. Furthermore, we have conducted additional experiments to discover the impact of increasing the number of events and formula operators on the complexity of TR problems and the performance of LLMs. We have demonstrated that although LLMs exhibit some promise in handling TR challenges, they still struggle with complex TR. We expect this work can offer insights into TR ability in LLMs while also providing a valuable tool for future TR evaluations.",
    "pdf_link": "https://arxiv.org/abs/2407.05434",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05434v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05434/pipeline.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05434v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05434/directed_graph.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05434v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05434/fixed_event_n_accuracy.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05434v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05434/fixed_event_n_auc.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05434v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05434/fixed_operator_n_accuracy.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05434v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05434/fixed_operator_n_auc.png"
      }
    ],
    "abstract_cn": "时间推理（TR）是AI的核心，涉及时间信息与事件关系的理解与处理。为探索LLMs的TR能力，我们创新性地结合随机有向图、LTL公式和NuSMV模型检查器，设计了一套数据集构建流程。据此，我们打造了包含2,000个挑战的LTLBench基准，并测试了六款LLMs。实验揭示，尽管LLMs在TR任务上有所进步，但复杂问题仍令其困扰。此研究不仅深化了对LLMs TR能力的理解，更为未来评估提供了有力工具。",
    "title_cn": "LTLBench：专为评估大型语言模型中的时间逻辑推理而设计的基准测试",
    "tags": [
      "LLM应用",
      "人工智能",
      "时间推理"
    ]
  },
  {
    "title": "SBoRA: Low-Rank Adaptation with Regional Weight Updates",
    "submit_datetime": "2024年07月07日",
    "abstract": 