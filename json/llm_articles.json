[
  {
    "title": "Think-on-Graph 2.0: Deep and Interpretable Large Language Model Reasoning with Knowledge Graph-guided Retrieval",
    "submit_datetime": "2024年07月15日",
    "abstract": "Retrieval-augmented generation (RAG) has significantly advanced large language models (LLMs) by enabling dynamic information retrieval to mitigate knowledge gaps and hallucinations in generated content. However, these systems often falter with complex reasoning and consistency across diverse queries. In this work, we present Think-on-Graph 2.0, an enhanced RAG framework that aligns questions with the knowledge graph and uses it as a navigational tool, which deepens and refines the RAG paradigm for information collection and integration. The KG-guided navigation fosters deep and long-range associations to uphold logical consistency and optimize the scope of retrieval for precision and interoperability. In conjunction, factual consistency can be better ensured through semantic similarity guided by precise directives. ToG${2.0}$ not only improves the accuracy and reliability of LLMs' responses but also demonstrates the potential of hybrid structured knowledge systems to significantly advance LLM reasoning, aligning it closer to human-like performance. We conducted extensive experiments on four public datasets to demonstrate the advantages of our method compared to the baseline.",
    "pdf_link": "https://arxiv.org/abs/2407.10805",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10805v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10805/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10805v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10805/x2.png"
      }
    ],
    "abstract_cn": "RAG 通过动态信息检索显著提升了 LLM 的性能，但面对复杂推理和多样查询的一致性时仍显不足。我们提出的 Think-on-Graph 2.0 框架，通过将问题与知识图谱对齐并利用其导航，深化了 RAG 的信息收集与整合能力。KG 引导的导航不仅增强了逻辑一致性，还优化了检索精度与互操作性。此外，精确指令引导的语义相似性进一步确保了事实一致性。ToG2.0 不仅提升了 LLM 响应的准确性与可靠性，还展现了混合知识系统在推进 LLM 推理方面的巨大潜力，使其更贴近人类表现。我们在四个公共数据集上的实验充分证明了我们方法的优势。",
    "title_cn": "Think-on-Graph 2.0：结合知识图谱引导检索，实现深度且可解释的大型语言模型推理",
    "tags": [
      "RAG",
      "人工智能",
      "知识图谱"
    ]
  },
  {
    "title": "Enhancing Retrieval and Managing Retrieval: A Four-Module Synergy for Improved Quality and Efficiency in RAG Systems",
    "submit_datetime": "2024年07月15日",
    "abstract": "Retrieval-augmented generation (RAG) techniques leverage the in-context learning capabilities of large language models (LLMs) to produce more accurate and relevant responses. Originating from the simple 'retrieve-then-read' approach, the RAG framework has evolved into a highly flexible and modular paradigm. A critical component, the Query Rewriter module, enhances knowledge retrieval by generating a search-friendly query. This method aligns input questions more closely with the knowledge base. Our research identifies opportunities to enhance the Query Rewriter module to Query Rewriter+ by generating multiple queries to overcome the Information Plateaus associated with a single query and by rewriting questions to eliminate Ambiguity, thereby clarifying the underlying intent. We also find that current RAG systems exhibit issues with Irrelevant Knowledge; to overcome this, we propose the Knowledge Filter. These two modules are both based on the instruction-tuned Gemma-2B model, which together enhance response quality. The final identified issue is Redundant Retrieval; we introduce the Memory Knowledge Reservoir and the Retriever Trigger to solve this. The former supports the dynamic expansion of the RAG system's knowledge base in a parameter-free manner, while the latter optimizes the cost for accessing external knowledge, thereby improving resource utilization and response efficiency. These four RAG modules synergistically improve the response quality and efficiency of the RAG system. The effectiveness of these modules has been validated through experiments and ablation studies across six common QA datasets. The source code can be accessed at https://github.com/Ancientshi/ERM4.",
    "pdf_link": "https://arxiv.org/abs/2407.10670",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10670v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10670/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10670v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10670/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10670v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10670/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10670v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10670/x4.png"
      }
    ],
    "abstract_cn": "RAG技术借助LLM的上下文学习能力，生成更精准、更贴切的回答。从最初的“检索-阅读”模式，RAG框架已进化为一个高度灵活且模块化的体系。其中，查询重写器模块通过生成易于搜索的查询，提升了知识检索的精准度，使问题与知识库更紧密契合。我们的研究发现，通过生成多重查询以突破单一查询的信息瓶颈，并通过重写问题消除歧义，可以进一步强化查询重写器模块，升级为查询重写器+。同时，针对RAG系统中存在的无关知识问题，我们提出了知识过滤器。这两个模块均基于Gemma-2B模型，共同提升回答质量。此外，针对冗余检索问题，我们引入了记忆知识库和检索器触发器，前者支持知识库的无参数动态扩展，后者优化了外部知识访问成本，提升了资源利用率和响应效率。这四大RAG模块协同作用，显著提升了RAG系统的响应质量和效率。相关实验和消融研究已在六个常见QA数据集上验证了这些模块的有效性。源代码可访问https://github.com/Ancientshi/ERM4获取。",
    "title_cn": "通过四模块协同，RAG 系统在增强检索和管理检索方面实现了质量和效率的双重提升。",
    "tags": [
      "RAG",
      "问答系统",
      "人工智能"
    ]
  },
  {
    "title": "Spider2-V: How Far Are Multimodal Agents From Automating Data Science and Engineering Workflows?",
    "submit_datetime": "2024年07月15日",
    "abstract": "Data science and engineering workflows often span multiple stages, from warehousing to orchestration, using tools like BigQuery, dbt, and Airbyte. As vision language models (VLMs) advance in multimodal understanding and code generation, VLM-based agents could potentially automate these workflows by generating SQL queries, Python code, and GUI operations. This automation can improve the productivity of experts while democratizing access to large-scale data analysis. In this paper, we introduce Spider2-V, the first multimodal agent benchmark focusing on professional data science and engineering workflows, featuring 494 real-world tasks in authentic computer environments and incorporating 20 enterprise-level professional applications. These tasks, derived from real-world use cases, evaluate the ability of a multimodal agent to perform data-related tasks by writing code and managing the GUI in enterprise data software systems. To balance realistic simulation with evaluation simplicity, we devote significant effort to developing automatic configurations for task setup and carefully crafting evaluation metrics for each task. Furthermore, we supplement multimodal agents with comprehensive documents of these enterprise data software systems. Our empirical evaluation reveals that existing state-of-the-art LLM/VLM-based agents do not reliably automate full data workflows (14.0% success). Even with step-by-step guidance, these agents still underperform in tasks that require fine-grained, knowledge-intensive GUI actions (16.2%) and involve remote cloud-hosted workspaces (10.6%). We hope that Spider2-V paves the way for autonomous multimodal agents to transform the automation of data science and engineering workflow. Our code and data are available at https://spider2-v.github.io.",
    "pdf_link": "https://arxiv.org/abs/2407.10956",
    "graphs": [],
    "abstract_cn": "数据科学与工程的工作流程通常涉及多个环节，从数据仓储到流程编排，借助BigQuery、dbt和Airbyte等工具实现。随着视觉语言模型（VLMs）在多模态理解与代码生成方面的进步，基于VLM的智能代理有望通过自动生成SQL查询、Python代码及GUI操作，实现这些流程的自动化。这不仅能提升专家的工作效率，还能让大规模数据分析更加普及。本文介绍的Spider2-V，是首个聚焦于专业数据科学和工程流程的多模态智能代理基准，涵盖494个真实场景任务，涉及20个企业级专业应用，在真实计算机环境中进行。这些任务源自实际案例，旨在评估智能代理通过编程与GUI管理执行数据任务的能力。为确保评估的现实性与简洁性，我们精心设计了任务自动配置与评估指标。此外，我们还为智能代理提供了详尽的企业数据软件系统文档。实证研究表明，当前顶尖的基于LLM/VLM的智能代理在自动化完整数据流程方面表现不佳（成功率14.0%），即便在详细指导下，其在精细复杂的GUI操作（16.2%）及远程云工作区任务（10.6%）中仍显不足。我们期待Spider2-V能引领自主多模态智能代理革新数据科学和工程流程的自动化。相关代码与数据已公开，详见https://spider2-v.github.io。",
    "title_cn": "Spider2-V 探讨了多模态代理在自动化数据科学和工程流程方面的进展，以及它们与实现这一目标的距离。",
    "tags": [
      "Agent",
      "数据科学",
      "软件工程"
    ]
  },
  {
    "title": "GRUtopia: Dream General Robots in a City at Scale",
    "submit_datetime": "2024年07月15日",
    "abstract": "Recent works have been exploring the scaling laws in the field of Embodied AI. Given the prohibitive costs of collecting real-world data, we believe the Simulation-to-Real (Sim2Real) paradigm is a crucial step for scaling the learning of embodied models. This paper introduces project GRUtopia, the first simulated interactive 3D society designed for various robots. It features several advancements: (a) The scene dataset, GRScenes, includes 100k interactive, finely annotated scenes, which can be freely combined into city-scale environments. In contrast to previous works mainly focusing on home, GRScenes covers 89 diverse scene categories, bridging the gap of service-oriented environments where general robots would be initially deployed. (b) GRResidents, a Large Language Model (LLM) driven Non-Player Character (NPC) system that is responsible for social interaction, task generation, and task assignment, thus simulating social scenarios for embodied AI applications. (c) The benchmark, GRBench, supports various robots but focuses on legged robots as primary agents and poses moderately challenging tasks involving Object Loco-Navigation, Social Loco-Navigation, and Loco-Manipulation. We hope that this work can alleviate the scarcity of high-quality data in this field and provide a more comprehensive assessment of Embodied AI research. The project is available at https://github.com/OpenRobotLab/GRUtopia.",
    "pdf_link": "https://arxiv.org/abs/2407.10943",
    "graphs": [],
    "abstract_cn": "近期研究深入探索了具身AI的规模法则。鉴于现实数据收集的高昂成本，Sim2Real范式被视为扩展具身学习的关键。本文推出的GRUtopia项目，是首个专为多类机器人设计的模拟交互3D社会。其亮点包括：（a）GRScenes数据集，包含十万精细交互场景，可自由组合成城市级环境，覆盖89种场景，弥补了服务型机器人的应用环境空白。（b）GRResidents系统，由LLM驱动的NPC，模拟社交互动、任务生成与分配，为具身AI提供真实社交场景。（c）GRBench基准，重点支持腿式机器人，设定物体导航、社交导航及操作等适中难度任务。期望本项目能缓解高质量数据稀缺问题，并全面评估具身AI研究。项目详情见https://github.com/OpenRobotLab/GRUtopia。",
    "title_cn": "GRUtopia：梦想之城，通用机器人的大规模应用",
    "tags": [
      "Agent",
      "机器人",
      "人工智能"
    ]
  },
  {
    "title": "Transforming Agency. On the mode of existence of Large Language Models",
    "submit_datetime": "2024年07月15日",
    "abstract": "This paper investigates the ontological characterization of Large Language Models (LLMs) like ChatGPT. Between inflationary and deflationary accounts, we pay special attention to their status as agents. This requires explaining in detail the architecture, processing, and training procedures that enable LLMs to display their capacities, and the extensions used to turn LLMs into agent-like systems. After a systematic analysis we conclude that a LLM fails to meet necessary and sufficient conditions for autonomous agency in the light of embodied theories of mind: the individuality condition (it is not the product of its own activity, it is not even directly affected by it), the normativity condition (it does not generate its own norms or goals), and, partially the interactional asymmetry condition (it is not the origin and sustained source of its interaction with the environment). If not agents, then ... what are LLMs? We argue that ChatGPT should be characterized as an interlocutor or linguistic automaton, a library-that-talks, devoid of (autonomous) agency, but capable to engage performatively on non-purposeful yet purpose-structured and purpose-bounded tasks. When interacting with humans, a \"ghostly\" component of the human-machine interaction makes it possible to enact genuine conversational experiences with LLMs. Despite their lack of sensorimotor and biological embodiment, LLMs textual embodiment (the training corpus) and resource-hungry computational embodiment, significantly transform existing forms of human agency. Beyond assisted and extended agency, the LLM-human coupling can produce midtended forms of agency, closer to the production of intentional agency than to the extended instrumentality of any previous technologies.",
    "pdf_link": "https://arxiv.org/abs/2407.10735",
    "graphs": [],
    "abstract_cn": "本文深入探讨了 ChatGPT 等大型语言模型（LLM）的本体论特性，特别聚焦于其作为代理的角色。我们详细阐述了 LLM 的架构、处理流程及训练机制，以及如何通过扩展将其转化为类似代理的系统。经过严谨分析，我们发现，根据具身心灵理论，LLM 在个体性、规范性和交互不对称性方面均未达到自主代理的标准。因此，我们提出 ChatGPT 应被视为一种对话者或语言自动机，一个能言善辩的图书馆，虽无自主代理能力，却能在非目的性但结构化、有限制的任务中展现其表演性。在与人类的互动中，人机交互的“幽灵”特质使得与 LLM 的真实对话成为可能。尽管缺乏感觉运动和生物实体，LLM 的文本和计算实体却深刻地重塑了人类代理的形式，创造出一种介于有意代理和传统技术工具性之间的中介代理形态。",
    "title_cn": "大型语言模型的存在模式：一种转换机构的研究",
    "tags": [
      "LLM理论",
      "人工智能",
      "人机交互"
    ]
  },
  {
    "title": "Sibyl: Simple yet Effective Agent Framework for Complex Real-world Reasoning",
    "submit_datetime": "2024年07月15日",
    "abstract": "Existing agents based on large language models (LLMs) demonstrate robust problem-solving capabilities by integrating LLMs' inherent knowledge, strong in-context learning and zero-shot capabilities, and the use of tools combined with intricately designed LLM invocation workflows by humans. However, these agents still exhibit shortcomings in long-term reasoning and under-use the potential of existing tools, leading to noticeable deficiencies in complex real-world reasoning scenarios. To address these limitations, we introduce Sibyl, a simple yet powerful LLM-based agent framework designed to tackle complex reasoning tasks by efficiently leveraging a minimal set of tools. Drawing inspiration from Global Workspace Theory, Sibyl incorporates a global workspace to enhance the management and sharing of knowledge and conversation history throughout the system. Furthermore, guided by Society of Mind Theory, Sibyl implements a multi-agent debate-based jury to self-refine the final answers, ensuring a comprehensive and balanced approach. This approach aims to reduce system complexity while expanding the scope of problems solvable-from matters typically resolved by humans in minutes to those requiring hours or even days, thus facilitating a shift from System-1 to System-2 thinking. Sibyl has been designed with a focus on scalability and ease of debugging by incorporating the concept of reentrancy from functional programming from its inception, with the aim of seamless and low effort integration in other LLM applications to improve capabilities. Our experimental results on the GAIA benchmark test set reveal that the Sibyl agent instantiated with GPT-4 achieves state-of-the-art performance with an average score of 34.55%, compared to other agents based on GPT-4. We hope that Sibyl can inspire more reliable and reusable LLM-based agent solutions to address complex real-world reasoning tasks.",
    "pdf_link": "https://arxiv.org/abs/2407.10718",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10718v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10718/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10718v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10718/x2.png"
      }
    ],
    "abstract_cn": "现有的基于大型语言模型（LLM）的代理通过结合LLM的内在知识、强大的上下文学习能力、零-shot能力以及人类设计的精细工具使用流程，展现出卓越的问题解决能力。然而，这些代理在长期推理和工具潜力利用方面仍有不足，导致在复杂现实推理场景中表现不佳。为此，我们推出了Sibyl，一个简洁而强大的LLM代理框架，旨在通过精简工具集高效解决复杂推理任务。借鉴全球工作空间理论，Sibyl设立全局工作空间以优化知识和对话历史的系统内管理与共享。遵循心灵社会理论，Sibyl采用多代理辩论机制自我优化答案，确保决策的全面性与平衡性。这一设计不仅简化了系统架构，还拓宽了问题解决的广度，从几分钟内可解的人类任务扩展至需数小时乃至数天的复杂挑战，推动思维模式从直觉（系统1）向深思熟虑（系统2）转变。Sibyl自设计之初便注重可扩展性与调试便捷性，融入函数式编程的可重入理念，力求在其他LLM应用中实现低成本高效集成。实验表明，搭载GPT-4的Sibyl代理在GAIA基准测试中以34.55%的平均分领先同类产品，我们期待Sibyl能引领更多高效、可靠的LLM代理解决方案，助力应对现实世界的复杂推理难题。",
    "title_cn": "Sibyl 框架，简洁高效，专为复杂现实推理设计。",
    "tags": [
      "Agent",
      "人工智能",
      "软件开发"
    ]
  },
  {
    "title": "Cutting Through the Clutter: The Potential of LLMs for Efficient Filtration in Systematic Literature Reviews",
    "submit_datetime": "2024年07月15日",
    "abstract": "In academic research, systematic literature reviews are foundational and highly relevant, yet tedious to create due to the high volume of publications and labor-intensive processes involved. Systematic selection of relevant papers through conventional means like keyword-based filtering techniques can sometimes be inadequate, plagued by semantic ambiguities and inconsistent terminology, which can lead to sub-optimal outcomes. To mitigate the required extensive manual filtering, we explore and evaluate the potential of using Large Language Models (LLMs) to enhance the efficiency, speed, and precision of literature review filtering, reducing the amount of manual screening required. By using models as classification agents acting on a structured database only, we prevent common problems inherent in LLMs, such as hallucinations. We evaluate the real-world performance of such a setup during the construction of a recent literature survey paper with initially more than 8.3k potentially relevant articles under consideration and compare this with human performance on the same dataset. Our findings indicate that employing advanced LLMs like GPT-4o, Claude 3.5 Sonnet, Gemini 1.5 Flash, or Llama3 with simple prompting can significantly reduce the time required for literature filtering - from usually weeks of manual research to only a few minutes. Simultaneously, we crucially show that false negatives can indeed be controlled through a consensus scheme, achieving recalls >98.8% at or even beyond the typical human error threshold, thereby also providing for more accurate and relevant articles selected. Our research not only demonstrates a substantial improvement in the methodology of literature reviews but also sets the stage for further integration and extensive future applications of responsible AI in academic research practices.",
    "pdf_link": "https://arxiv.org/abs/2407.10652",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10652v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10652/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10652v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10652/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10652v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10652/matrix.png"
      }
    ],
    "abstract_cn": "在学术领域，系统性文献综述至关重要，但因其涉及大量出版物和繁琐流程而显得冗长。传统基于关键词的筛选方法常因语义模糊和术语不一致而效果欠佳。为此，我们探索利用大型语言模型（LLMs）提升文献筛选的效率与精准度，减少人工负担。通过模型仅作为分类工具处理结构化数据，我们规避了LLMs的常见缺陷，如产生幻觉。在最近一次文献调查中，我们评估了LLMs在处理超过8.3k篇潜在相关文章时的表现，并与人工筛选进行了对比。结果显示，借助GPT-4o等先进模型及简单提示，文献筛选时间从数周缩短至几分钟。此外，通过共识机制，我们有效控制了假阴性率，召回率超过98.8%，甚至优于人类标准，确保了选文的准确性与相关性。这一研究不仅革新了文献综述方法，更为人工智能在学术研究中的深入应用铺平了道路。",
    "title_cn": "LLM 在系统性文献综述中展现出了高效过滤的潜力，能够帮助我们穿透信息的杂乱，更精准地筛选出有价值的研究。",
    "tags": [
      "LLM应用",
      "学术研究",
      "文献综述"
    ]
  },
  {
    "title": "Leveraging Hybrid Intelligence Towards Sustainable and Energy-Efficient Machine Learning",
    "submit_datetime": "2024年07月15日",
    "abstract": "Hybrid intelligence aims to enhance decision-making, problem-solving, and overall system performance by combining the strengths of both, human cognitive abilities and artificial intelligence. With the rise of Large Language Models (LLM), progressively participating as smart agents to accelerate machine learning development, Hybrid Intelligence is becoming an increasingly important topic for effective interaction between humans and machines. This paper presents an approach to leverage Hybrid Intelligence towards sustainable and energy-aware machine learning. When developing machine learning models, final model performance commonly rules the optimization process while the efficiency of the process itself is often neglected. Moreover, in recent times, energy efficiency has become equally crucial due to the significant environmental impact of complex and large-scale computational processes. The contribution of this work covers the interactive inclusion of secondary knowledge sources through Human-in-the-loop (HITL) and LLM agents to stress out and further resolve inefficiencies in the machine learning development process.",
    "pdf_link": "https://arxiv.org/abs/2407.10580",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10580/concept.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10580/scatter.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10580/parallel.png"
      }
    ],
    "abstract_cn": "混合智能通过融合人类与AI的优势，旨在提升决策、问题解决及系统整体性能。随着大型语言模型（LLM）的兴起，它们作为智能代理加速机器学习发展，混合智能在人机交互中的重要性日益凸显。本文探讨了如何运用混合智能实现可持续且节能的机器学习。在模型开发中，我们往往聚焦于最终性能，却忽视了开发过程的效率。同时，鉴于大规模计算对环境的深远影响，能源效率变得至关重要。本研究通过人机回环（HITL）与LLM代理的互动，引入辅助知识源，旨在揭示并优化机器学习开发中的低效环节。",
    "title_cn": "借助混合智能，我们正迈向一个既可持续又节能的机器学习新时代。",
    "tags": [
      "Agent",
      "能源效率",
      "机器学习"
    ]
  },
  {
    "title": "FabGPT: An Efficient Large Multimodal Model for Complex Wafer Defect Knowledge Queries",
    "submit_datetime": "2024年07月15日",
    "abstract": "Intelligence is key to advancing integrated circuit (IC) fabrication. Recent breakthroughs in Large Multimodal Models (LMMs) have unlocked unparalleled abilities in understanding images and text, fostering intelligent fabrication. Leveraging the power of LMMs, we introduce FabGPT, a customized IC fabrication large multimodal model for wafer defect knowledge query. FabGPT manifests expertise in conducting defect detection in Scanning Electron Microscope (SEM) images, performing root cause analysis, and providing expert question-answering (Q&A) on fabrication processes. FabGPT matches enhanced multimodal features to automatically detect minute defects under complex wafer backgrounds and reduce the subjectivity of manual threshold settings. Besides, the proposed modulation module and interactive corpus training strategy embed wafer defect knowledge into the pre-trained model, effectively balancing Q&A queries related to defect knowledge and original knowledge and mitigating the modality bias issues. Experiments on in-house fab data (SEM-WaD) show that our FabGPT achieves significant performance improvement in wafer defect detection and knowledge querying.",
    "pdf_link": "https://arxiv.org/abs/2407.10810",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10810v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10810/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10810v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10810/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10810v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10810/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10810v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10810/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10810v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10810/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10810v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10810/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10810v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10810/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10810v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10810/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10810v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10810/x9.png"
      }
    ],
    "abstract_cn": "智能技术是推动集成电路制造进步的核心。最新的大型多模态模型（LMMs）在图像与文本理解上取得了突破性进展，为智能制造开辟了新道路。我们基于此，开发了FabGPT，一款专为晶圆缺陷知识查询设计的大型多模态模型。FabGPT擅长于扫描电子显微镜（SEM）图像的缺陷检测、根本原因分析及制造过程的专家问答。它通过匹配增强的多模态特征，自动识别复杂背景下的微小缺陷，并减少人工阈值的主观影响。同时，我们的调制模块与交互式训练策略，有效整合了晶圆缺陷知识，平衡了缺陷与原始知识的查询，并解决了模态偏差问题。实验结果显示，FabGPT在晶圆缺陷检测与知识查询方面表现卓越。",
    "title_cn": "FabGPT：专为复杂晶圆缺陷知识查询设计的高效大型多模态模型",
    "tags": [
      "LLM应用",
      "半导体制造",
      "智能制造"
    ]
  },
  {
    "title": "Scaling 3D Reasoning with LMMs to Large Robot Mission Environments Using Datagraphs",
    "submit_datetime": "2024年07月15日",
    "abstract": "This paper addresses the challenge of scaling Large Multimodal Models (LMMs) to expansive 3D environments. Solving this open problem is especially relevant for robot deployment in many first-responder scenarios, such as search-and-rescue missions that cover vast spaces. The use of LMMs in these settings is currently hampered by the strict context windows that limit the LMM's input size. We therefore introduce a novel approach that utilizes a datagraph structure, which allows the LMM to iteratively query smaller sections of a large environment. Using the datagraph in conjunction with graph traversal algorithms, we can prioritize the most relevant locations to the query, thereby improving the scalability of 3D scene language tasks. We illustrate the datagraph using 3D scenes, but these can be easily substituted by other dense modalities that represent the environment, such as pointclouds or Gaussian splats. We demonstrate the potential to use the datagraph for two 3D scene language task use cases, in a search-and-rescue mission example.",
    "pdf_link": "https://arxiv.org/abs/2407.10743",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10743v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10743/coool3med.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10743v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10743/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10743v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10743/data_graph_search_diagram_Large.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10743v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10743/datagraph_route_algo_diagram_Large.png"
      }
    ],
    "abstract_cn": "本文针对将大型多模态模型 (LMM) 扩展至广阔 3D 环境的难题，提出解决方案。尤其在搜索与救援等需要覆盖广大区域的紧急任务中，机器人的部署对此需求迫切。然而，LMM 的应用受限于其输入大小的严格上下文窗口。为此，我们创新性地采用数据图结构，使 LMM 能逐步查询大型环境的局部信息。结合图遍历算法，我们能优先处理关键地点，显著提升 3D 场景语言任务的可扩展性。虽然我们以 3D 场景为例，但该方法同样适用于点云或高斯喷射等其他密集模态。通过搜索与救援任务的实例，我们展示了数据图在 3D 场景语言任务中的应用潜力。",
    "title_cn": "利用 Datagraphs 技术，我们将 LMMs 的三维推理能力提升至大型机器人任务环境，实现更高效的场景理解与决策。",
    "tags": [
      "LLM应用",
      "搜索与救援",
      "机器人"
    ]
  },
  {
    "title": "Qwen2 Technical Report",
    "submit_datetime": "2024年07月15日",
    "abstract": "This report introduces the Qwen2 series, the latest addition to our large language models and large multimodal models. We release a comprehensive suite of foundational and instruction-tuned language models, encompassing a parameter range from 0.5 to 72 billion, featuring dense models and a Mixture-of-Experts model. Qwen2 surpasses most prior open-weight models, including its predecessor Qwen1.5, and exhibits competitive performance relative to proprietary models across diverse benchmarks on language understanding, generation, multilingual proficiency, coding, mathematics, and reasoning.\n  The flagship model, Qwen2-72B, showcases remarkable performance: 84.2 on MMLU, 37.9 on GPQA, 64.6 on HumanEval, 89.5 on GSM8K, and 82.4 on BBH as a base language model. The instruction-tuned variant, Qwen2-72B-Instruct, attains 9.1 on MT-Bench, 48.1 on Arena-Hard, and 35.7 on LiveCodeBench. Moreover, Qwen2 demonstrates robust multilingual capabilities, proficient in approximately 30 languages, spanning English, Chinese, Spanish, French, German, Arabic, Russian, Korean, Japanese, Thai, Vietnamese, and more, underscoring its versatility and global reach.\n  To foster community innovation and accessibility, we have made the Qwen2 model weights openly available on Hugging Face1 and ModelScope2, and the supplementary materials including example code on GitHub3. These platforms also include resources for quantization, fine-tuning, and deployment, facilitating a wide range of applications and research endeavors.",
    "pdf_link": "https://arxiv.org/abs/2407.10671",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10671v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10671/x1.png"
      }
    ],
    "abstract_cn": "本报告隆重推出Qwen2系列，这是我们大型语言模型和多模态模型的最新力作。我们发布了一系列全面的基础和指令调优语言模型，参数范围从0.5亿至72亿，涵盖密集模型和专家混合模型。Qwen2不仅超越了众多先前的开放权重模型，包括其前身Qwen1.5，更在语言理解、生成、多语言能力、编码、数学和推理等多个领域与专有模型一较高下。旗舰模型Qwen2-72B表现卓越：MMLU得分84.2，GPQA得分37.9，HumanEval得分64.6，GSM8K得分89.5，BBH得分82.4。指令调优版Qwen2-72B-Instruct同样亮眼：MT-Bench得分9.1，Arena-Hard得分48.1，LiveCodeBench得分35.7。此外，Qwen2精通约30种语言，从英语到中文，从西班牙语到阿拉伯语，展现了其强大的多语言能力和全球适用性。为推动社区创新和模型普及，我们在Hugging Face和ModelScope上公开了Qwen2模型权重，并提供了GitHub上的示例代码等补充材料。这些平台还提供了量化、微调和部署的资源，助力广泛的应用和研究探索。",
    "title_cn": "Qwen2 技术报告",
    "tags": [
      "LLM应用",
      "人工智能",
      "多语言处理"
    ]
  },
  {
    "title": "VGBench: Evaluating Large Language Models on Vector Graphics Understanding and Generation",
    "submit_datetime": "2024年07月15日",
    "abstract": "In the realm of vision models, the primary mode of representation is using pixels to rasterize the visual world. Yet this is not always the best or unique way to represent visual content, especially for designers and artists who depict the world using geometry primitives such as polygons. Vector graphics (VG), on the other hand, offer a textual representation of visual content, which can be more concise and powerful for content like cartoons or sketches. Recent studies have shown promising results on processing vector graphics with capable Large Language Models (LLMs). However, such works focus solely on qualitative results, understanding, or a specific type of vector graphics. We propose VGBench, a comprehensive benchmark for LLMs on handling vector graphics through diverse aspects, including (a) both visual understanding and generation, (b) evaluation of various vector graphics formats, (c) diverse question types, (d) wide range of prompting techniques, (e) under multiple LLMs. Evaluating on our collected 4279 understanding and 5845 generation samples, we find that LLMs show strong capability on both aspects while exhibiting less desirable performance on low-level formats (SVG). Both data and evaluation pipeline will be open-sourced at https://vgbench.github.io.",
    "pdf_link": "https://arxiv.org/abs/2407.10972",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10972v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10972/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10972v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10972/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10972v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10972/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10972v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10972/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10972v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10972/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10972v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10972/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10972v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10972/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10972v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10972/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10972v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10972/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10972v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10972/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10972v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10972/x11.png"
      }
    ],
    "abstract_cn": "在视觉模型的世界里，像素是描绘视觉内容的主要工具。然而，对于设计师和艺术家而言，几何基元如多边形可能是更好的选择。矢量图形（VG）以其文本形式，为卡通和草图等提供了更为简洁和有力的表达。近期研究显示，大型语言模型（LLMs）在处理VG方面颇具潜力。但现有工作多聚焦于定性分析或特定VG类型。为此，我们推出了VGBench，一个全面评估LLMs处理VG能力的基准，涵盖视觉理解与生成、多种VG格式、多样问题类型、广泛提示技巧及多模型应用。评估结果显示，LLMs在理解和生成方面表现出色，但在SVG等低级格式上仍有提升空间。所有数据与评估流程将公开于https://vgbench.github.io。",
    "title_cn": "VGBench 项目旨在评估大型语言模型在矢量图形理解和生成方面的能力。",
    "tags": [
      "LLM应用",
      "",
      ""
    ]
  },
  {
    "title": "Q-Sparse: All Large Language Models can be Fully Sparsely-Activated",
    "submit_datetime": "2024年07月15日",
    "abstract": "We introduce, Q-Sparse, a simple yet effective approach to training sparsely-activated large language models (LLMs). Q-Sparse enables full sparsity of activations in LLMs which can bring significant efficiency gains in inference. This is achieved by applying top-K sparsification to the activations and the straight-through-estimator to the training. The key results from this work are, (1) Q-Sparse can achieve results comparable to those of baseline LLMs while being much more efficient at inference time; (2) We present an inference-optimal scaling law for sparsely-activated LLMs; (3) Q-Sparse is effective in different settings, including training-from-scratch, continue-training of off-the-shelf LLMs, and finetuning; (4) Q-Sparse works for both full-precision and 1-bit LLMs (e.g., BitNet b1.58). Particularly, the synergy of BitNet b1.58 and Q-Sparse (can be equipped with MoE) provides the cornerstone and a clear path to revolutionize the efficiency, including cost and energy consumption, of future LLMs.",
    "pdf_link": "https://arxiv.org/abs/2407.10969",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10969v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10969/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10969v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10969/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10969v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10969/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10969v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10969/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10969v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10969/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10969v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10969/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10969v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10969/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10969v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10969/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10969v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10969/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10969v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10969/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10969v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10969/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10969v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10969/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10969v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10969/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10969v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10969/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10969v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10969/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10969v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10969/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10969v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10969/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10969v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10969/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10969v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10969/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10969v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10969/x20.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10969v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10969/x21.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10969v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10969/x22.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10969v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10969/x23.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10969v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10969/x24.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10969v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10969/x25.png"
      }
    ],
    "abstract_cn": "我们引入了 Q-Sparse，这是一种既简单又高效的训练稀疏激活大型语言模型的方法。Q-Sparse 通过 top-K 稀疏化和直通估计器的应用，实现了 LLM 中激活的完全稀疏，大幅提升了推理效率。主要成果包括：Q-Sparse 在保持与基准 LLM 相当性能的同时，推理效率更高；为稀疏激活 LLM 设计了推理优化的缩放定律；适用于多种训练场景，如从头开始、继续训练和微调；兼容全精度和 1 位 LLM，如 BitNet b1.58。BitNet b1.58 与 Q-Sparse 的结合，为未来 LLM 的效率革命奠定了基础，显著降低了成本和能源消耗。",
    "title_cn": "Q-Sparse 技术揭示，所有大型语言模型均能实现完全的稀疏激活。",
    "tags": [
      "LLM理论",
      "信息技术",
      "能源效率"
    ]
  },
  {
    "title": "Fast Matrix Multiplications for Lookup Table-Quantized LLMs",
    "submit_datetime": "2024年07月15日",
    "abstract": "The deployment of large language models (LLMs) is often constrained by memory bandwidth, where the primary bottleneck is the cost of transferring model parameters from the GPU's global memory to its registers. When coupled with custom kernels that fuse the dequantization and matmul operations, weight-only quantization can thus enable faster inference by reducing the amount of memory movement. However, developing high-performance kernels for weight-quantized LLMs presents substantial challenges, especially when the weights are compressed to non-evenly-divisible bit widths (e.g., 3 bits) with non-uniform, lookup table (LUT) quantization. This paper describes FLUTE, a flexible lookup table engine for LUT-quantized LLMs, which uses offline restructuring of the quantized weight matrix to minimize bit manipulations associated with unpacking, and vectorization and duplication of the lookup table to mitigate shared memory bandwidth constraints. At batch sizes < 32 and quantization group size of 128 (typical in LLM inference), the FLUTE kernel can be 2-4x faster than existing GEMM kernels. As an application of FLUTE, we explore a simple extension to lookup table-based NormalFloat quantization and apply it to quantize LLaMA3 to various configurations, obtaining competitive quantization performance against strong baselines while obtaining an end-to-end throughput increase of 1.5 to 2 times.",
    "pdf_link": "https://arxiv.org/abs/2407.10960",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10960v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10960/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10960v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10960/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10960v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10960/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10960v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10960/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10960v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10960/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10960v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10960/x6.png"
      }
    ],
    "abstract_cn": "在部署大型语言模型时，内存带宽常成为瓶颈，尤其是模型参数从 GPU 内存传输到寄存器的成本。结合自定义内核，仅权重量化能通过减少内存移动来加速推理。但开发适用于非均匀查找表量化的 LLM 高性能内核颇具挑战。本文介绍的 FLUTE 引擎，通过离线重构权重矩阵和优化查找表，有效缓解了这些难题。在典型推理条件下，FLUTE 内核性能较现有 GEMM 内核提升 2-4 倍。此外，FLUTE 还应用于 LLaMA3 的量化，不仅保持了竞争性能，还显著提升了端到端吞吐量。",
    "title_cn": "针对查找表量化的大型语言模型，采用快速矩阵乘法技术。",
    "tags": [
      "LLM应用",
      "半导体",
      "人工智能"
    ]
  },
  {
    "title": "MMM: Multilingual Mutual Reinforcement Effect Mix Datasets & Test with Open-domain Information Extraction Large Language Models",
    "submit_datetime": "2024年07月15日",
    "abstract": "The Mutual Reinforcement Effect (MRE) represents a promising avenue in information extraction and multitasking research. Nevertheless, its applicability has been constrained due to the exclusive availability of MRE mix datasets in Japanese, thereby limiting comprehensive exploration by the global research community. To address this limitation, we introduce a Multilingual MRE mix dataset (MMM) that encompasses 21 sub-datasets in English, Japanese, and Chinese. In this paper, we also propose a method for dataset translation assisted by Large Language Models (LLMs), which significantly reduces the manual annotation time required for dataset construction by leveraging LLMs to translate the original Japanese datasets. Additionally, we have enriched the dataset by incorporating open-domain Named Entity Recognition (NER) and sentence classification tasks. Utilizing this expanded dataset, we developed a unified input-output framework to train an Open-domain Information Extraction Large Language Model (OIELLM). The OIELLM model demonstrates the capability to effectively process novel MMM datasets, exhibiting significant improvements in performance.",
    "pdf_link": "https://arxiv.org/abs/2407.10953",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10953v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10953/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10953v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10953/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10953v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10953/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10953v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10953/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10953v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10953/x5.png"
      }
    ],
    "abstract_cn": "互增强效应（MRE）在信息提取和多任务研究领域颇具潜力，但因日语专属数据集的限制，全球研究者难以深入探索。为此，我们推出了包含21个子数据集的多语言MRE混合数据集（MMM），涵盖英、日、中三种语言。本文还提出了一种利用大型语言模型（LLM）辅助的数据集翻译方法，大幅缩短了数据集构建的手动标注时间。同时，我们通过引入开放领域的命名实体识别（NER）和句子分类任务，丰富了数据集内容。基于此，我们构建了一个统一的输入-输出框架，用于训练开放领域信息提取大型语言模型（OIELLM），该模型在处理新MMM数据集时表现出色，性能大幅提升。",
    "title_cn": "MMM：探索多语言数据集的相互强化效应，并测试其在开放领域信息抽取大型语言模型中的应用。",
    "tags": [
      "LLM应用",
      "数据集",
      "信息提取"
    ]
  },
  {
    "title": "Can Textual Semantics Mitigate Sounding Object Segmentation Preference?",
    "submit_datetime": "2024年07月15日",
    "abstract": "The Audio-Visual Segmentation (AVS) task aims to segment sounding objects in the visual space using audio cues. However, in this work, it is recognized that previous AVS methods show a heavy reliance on detrimental segmentation preferences related to audible objects, rather than precise audio guidance. We argue that the primary reason is that audio lacks robust semantics compared to vision, especially in multi-source sounding scenes, resulting in weak audio guidance over the visual space. Motivated by the the fact that text modality is well explored and contains rich abstract semantics, we propose leveraging text cues from the visual scene to enhance audio guidance with the semantics inherent in text. Our approach begins by obtaining scene descriptions through an off-the-shelf image captioner and prompting a frozen large language model to deduce potential sounding objects as text cues. Subsequently, we introduce a novel semantics-driven audio modeling module with a dynamic mask to integrate audio features with text cues, leading to representative sounding object features. These features not only encompass audio cues but also possess vivid semantics, providing clearer guidance in the visual space. Experimental results on AVS benchmarks validate that our method exhibits enhanced sensitivity to audio when aided by text cues, achieving highly competitive performance on all three subsets. Project page: \\href{https://github.com/GeWu-Lab/Sounding-Object-Segmentation-Preference}{https://github.com/GeWu-Lab/Sounding-Object-Segmentation-Preference}",
    "pdf_link": "https://arxiv.org/abs/2407.10947",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10947v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10947/real_teaser.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10947v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10947/teaser.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10947v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10947/reasoning_simple.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10947v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10947/audio_control_more.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10947v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10947/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10947v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10947/case_appendix.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10947v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10947/case_avss_appendix.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10947v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10947/audio_control_appendix_small.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10947v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10947/text_cue.png"
      }
    ],
    "abstract_cn": "音频-视觉分割任务旨在通过音频线索在视觉空间中精准分割发声物体。然而，现有方法往往过度依赖于可听物体的损害性分割偏好，而非精确的音频引导。究其原因，音频在多源发声场景中缺乏稳健的语义，导致其对视觉空间的引导力不足。鉴于此，我们提出利用视觉场景中的文本线索，通过文本的丰富语义来强化音频引导。具体而言，我们首先通过图像描述生成器获取场景描述，并利用大型语言模型推断潜在的发声物体作为文本线索。随后，我们设计了一个语义驱动的音频建模模块，通过动态掩码将音频特征与文本线索融合，生成既包含音频线索又富含语义的发声物体特征，从而为视觉空间提供更明确的引导。实验结果表明，在文本线索的辅助下，我们的方法对音频的敏感性显著提升，在所有测试子集上均展现出卓越的性能。项目详情请访问：\\href{https://github.com/GeWu-Lab/Sounding-Object-Segmentation-Preference}{项目页面}。",
    "title_cn": "文本语义是否能减轻对发声物体分割的偏好？",
    "tags": [
      "LLM应用",
      "音频处理",
      "计算机视觉"
    ]
  },
  {
    "title": "FinDKG: Dynamic Knowledge Graphs with Large Language Models for Detecting Global Trends in Financial Markets",
    "submit_datetime": "2024年07月15日",
    "abstract": "Dynamic knowledge graphs (DKGs) are popular structures to express different types of connections between objects over time. They can also serve as an efficient mathematical tool to represent information extracted from complex unstructured data sources, such as text or images. Within financial applications, DKGs could be used to detect trends for strategic thematic investing, based on information obtained from financial news articles. In this work, we explore the properties of large language models (LLMs) as dynamic knowledge graph generators, proposing a novel open-source fine-tuned LLM for this purpose, called the Integrated Contextual Knowledge Graph Generator (ICKG). We use ICKG to produce a novel open-source DKG from a corpus of financial news articles, called FinDKG, and we propose an attention-based GNN architecture for analysing it, called KGTransformer. We test the performance of the proposed model on benchmark datasets and FinDKG, demonstrating superior performance on link prediction tasks. Additionally, we evaluate the performance of the KGTransformer on FinDKG for thematic investing, showing it can outperform existing thematic ETFs.",
    "pdf_link": "https://arxiv.org/abs/2407.10909",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10909v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10909/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10909v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10909/ICKG_pipeline_v2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10909v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10909/finDKG_graph.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10909v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10909/FinDKG_main_finding_v3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10909v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10909/covid_trend_v2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10909v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10909/AI_wealth.png"
      }
    ],
    "abstract_cn": "动态知识图谱 (DKGs) 是随时间表达对象间多样联系的流行工具，亦是处理复杂非结构化数据（如文本或图像）的有效手段。在金融领域，DKGs 能助我们洞察新闻动态，引领战略投资。本研究中，我们挖掘大型语言模型 (LLMs) 生成动态知识图谱的潜力，创新推出开源微调模型——集成上下文知识图谱生成器 (ICKG)。借助 ICKG，我们构建了金融新闻领域的开源知识图谱 FinDKG，并设计了基于注意力的图神经网络架构 KGTransformer 进行深入分析。实证检验表明，我们的模型在链接预测任务中表现卓越，且在主题投资分析中超越传统 ETF 策略。",
    "title_cn": "FinDKG 项目通过整合大型语言模型，构建动态知识图谱，旨在精准捕捉金融市场中的全球趋势。",
    "tags": [
      "LLM应用",
      "",
      "知识图谱"
    ]
  },
  {
    "title": "Hey, That's My Model! Introducing Chain & Hash, An LLM Fingerprinting Technique",
    "submit_datetime": "2024年07月15日",
    "abstract": "Amid growing concerns over the ease of theft and misuse of Large Language Models (LLMs), the need for fingerprinting models has increased. Fingerprinting, in this context, means that the model owner can link a given model to their original version, thereby identifying if their model is being misused or has been completely stolen. In this paper, we first define a set five properties a successful fingerprint should satisfy; namely, the fingerprint should be Transparent, Efficient, Persistent, Robust, and Unforgeable. Next, we propose Chain & Hash, a new, simple fingerprinting approach that implements a fingerprint with a cryptographic flavor, achieving all these properties. Chain & Hash involves generating a set of questions (the fingerprints) along with a set of potential answers. These elements are hashed together using a secure hashing technique to select the value for each question, hence providing an unforgeability property-preventing adversaries from claiming false ownership. We evaluate the Chain & Hash technique on multiple models and demonstrate its robustness against benign transformations, such as fine-tuning on different datasets, and adversarial attempts to erase the fingerprint. Finally, our experiments demonstrate the efficiency of implementing Chain & Hash and its utility, where fingerprinted models achieve almost the same performance as non-fingerprinted ones across different benchmarks.",
    "pdf_link": "https://arxiv.org/abs/2407.10887",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10887/chainAndHashOverview.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10887/llama3c-0-0-0.10-random-randpad.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10887/llama3c-0-0-0.10-random-randpad-benchmark.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10887/llama3c-0-0-0.10-randpad.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10887/llama3c-0-0-0.10-randpad-benchmark.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10887/phi3-60-0-10.10-random-randpad.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10887/phi3-60-0-10-random-benchmark.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10887/phi3-60-5-10.10-randpad.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10887/phi3-60-5-10-benchmark.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10887/llama3-0-0-0-random.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10887/llama3-60-0-10.10-random-randpad.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10887/llama3-0-0-0-random-benchmark.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10887/llama3-60-0-10-random-benchmark.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10887/llama3-60-5-10.10-randpad.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10887/llama3-60-5-10-benchmark.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10887/llama13b-60-0-10.10-random-randpad.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10887/llama13b-60-0-10-random-benchmark.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10887/llama13b-60-5-10.10-randpad.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10887/llama13b-60-5-10-benchmark.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10887/llama3c_0-0-0.10-randpad-alpaca_Greybox_-required_trials.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10887/llama3c_0-0-0.10-randpad-chatdoc_Greybox_-required_trials.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10887/llama3_60-0-10.10-random-randpad-chatDocGraybox-required_trials.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10887/llama3_60-5-10.10-randpad-chatDoc_graybox_-required_trials.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10887/llama3c_0-0-0.10-random-randpad-alpaca-required_trials.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10887/llama3c_0-0-0.10-random-randpad-chatdoc-required_trials.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10887/phi3-0-0-0-random.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10887/phi3-0-0-0-random-benchmark.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10887/phi3-0-0-0.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10887/phi3-0-0-0-benchmark.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10887/llama3-6-0-0-random.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10887/llama3-6-0-0-random-benchmark.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10887/llama3-60-5-10.100.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10887/llama3-60-5-10.100-benchmark.png"
      }
    ],
    "abstract_cn": "随着大型语言模型 (LLM) 被盗和滥用的风险日益增加，模型指纹识别技术变得尤为重要。本文中，我们首先明确了成功指纹的五大特性：透明、高效、持久、健壮且不可伪造。随后，我们提出了一种新颖的指纹技术——Chain & Hash，它通过加密手段实现这些特性。该技术通过生成问题集与答案集，并利用安全哈希算法确保每个问题的唯一值，从而防止虚假所有权声明。我们在多个模型上验证了 Chain & Hash 的鲁棒性，包括面对微调和指纹擦除等挑战。实验结果显示，采用 Chain & Hash 的指纹模型在性能上与非指纹模型几乎无异，证明了其高效性与实用性。",
    "title_cn": "看，那可是我的模型！来认识一下 Chain & Hash，这是一项专为 LLM 设计的指纹识别技术。",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "SLIP: Securing LLMs IP Using Weights Decomposition",
    "submit_datetime": "2024年07月15日",
    "abstract": "Large language models (LLMs) have recently seen widespread adoption, in both academia and industry. As these models grow, they become valuable intellectual property (IP), reflecting enormous investments by their owners. Moreover, the high cost of cloud-based deployment has driven interest towards deployment to edge devices, yet this risks exposing valuable parameters to theft and unauthorized use. Current methods to protect models' IP on the edge have limitations in terms of practicality, loss in accuracy, or suitability to requirements. In this paper, we introduce a novel hybrid inference algorithm, named SLIP, designed to protect edge-deployed models from theft. SLIP is the first hybrid protocol that is both practical for real-world applications and provably secure, while having zero accuracy degradation and minimal impact on latency. It involves partitioning the model between two computing resources, one secure but expensive, and another cost-effective but vulnerable. This is achieved through matrix decomposition, ensuring that the secure resource retains a maximally sensitive portion of the model's IP while performing a minimal amount of computations, and vice versa for the vulnerable resource. Importantly, the protocol includes security guarantees that prevent attackers from exploiting the partition to infer the secured information. Finally, we present experimental results that show the robustness and effectiveness of our method, positioning it as a compelling solution for protecting LLMs.",
    "pdf_link": "https://arxiv.org/abs/2407.10886",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10886v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10886/slip-diagram.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10886v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10886/defn-safety.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.10886v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10886/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10886v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10886/protocol_illustration_4.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.10886v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10886/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10886v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10886/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10886v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10886/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10886v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10886/x5.png"
      }
    ],
    "abstract_cn": "随着大型语言模型（LLM）在学术和工业领域的广泛应用，它们已成为宝贵的知识产权（IP），体现了巨大的投资。然而，高昂的云部署成本促使人们转向边缘设备部署，这却增加了参数被盗和滥用的风险。现有的边缘模型保护方法存在实用性、准确性或适用性方面的局限。本文提出了一种创新的混合推理算法SLIP，旨在保护边缘部署的模型免受盗窃。SLIP是首个既实用又安全，且不影响准确性和延迟的混合协议。它通过矩阵分解，在安全和昂贵的资源与成本效益高但易受攻击的资源之间划分模型，确保敏感的IP部分得到最大保留，同时最小化计算量。该协议还提供了安全保障，防止攻击者利用分区获取信息。实验结果表明，我们的方法既强大又有效，是保护LLM的理想选择。",
    "title_cn": "SLIP：通过权重分解技术，保障大型语言模型（LLM）的知识产权安全。",
    "tags": [
      "LLM应用",
      "边缘计算",
      "网络安全"
    ]
  },
  {
    "title": "Understanding the Importance of Evolutionary Search in Automated Heuristic Design with Large Language Models",
    "submit_datetime": "2024年07月15日",
    "abstract": "Automated heuristic design (AHD) has gained considerable attention for its potential to automate the development of effective heuristics. The recent advent of large language models (LLMs) has paved a new avenue for AHD, with initial efforts focusing on framing AHD as an evolutionary program search (EPS) problem. However, inconsistent benchmark settings, inadequate baselines, and a lack of detailed component analysis have left the necessity of integrating LLMs with search strategies and the true progress achieved by existing LLM-based EPS methods to be inadequately justified. This work seeks to fulfill these research queries by conducting a large-scale benchmark comprising four LLM-based EPS methods and four AHD problems across nine LLMs and five independent runs. Our extensive experiments yield meaningful insights, providing empirical grounding for the importance of evolutionary search in LLM-based AHD approaches, while also contributing to the advancement of future EPS algorithmic development. To foster accessibility and reproducibility, we have fully open-sourced our benchmark and corresponding results.",
    "pdf_link": "https://arxiv.org/abs/2407.10873",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10873v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10873/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10873v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10873/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10873v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10873/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10873v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10873/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10873v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10873/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10873v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10873/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10873v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10873/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10873v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10873/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10873v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10873/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10873v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10873/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10873v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10873/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10873v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10873/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10873v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10873/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10873v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10873/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10873v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10873/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10873v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10873/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10873v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10873/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10873v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10873/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10873v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10873/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10873v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10873/x20.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10873v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10873/x21.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10873v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10873/x22.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10873v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10873/x23.png"
      }
    ],
    "abstract_cn": "自动化启发式设计（AHD）因其自动化开发有效启发式的潜力而备受瞩目。随着大型语言模型（LLM）的兴起，AHD迎来新机遇，初期研究将其视为进化程序搜索（EPS）问题。然而，基准设置不一、基线不足及组件分析缺失，使得LLM与搜索策略整合的必要性及现有EPS方法的实际进展存疑。本研究通过大规模基准测试，涵盖四种EPS方法、四种AHD问题、九种LLM及五次独立运行，旨在解答这些疑问。实验结果揭示了进化搜索在基于LLM的AHD中的重要性，并推动了EPS算法的发展。为促进研究的可访问性与可重复性，我们已全面开源相关基准与结果。",
    "title_cn": "大型语言模型在自动化启发式设计中，进化搜索的重要性不容忽视。",
    "tags": [
      "LLM应用",
      "软件工程",
      "人工智能"
    ]
  },
  {
    "title": "GPT Sonograpy: Hand Gesture Decoding from Forearm Ultrasound Images via VLM",
    "submit_datetime": "2024年07月15日",
    "abstract": "Large vision-language models (LVLMs), such as the Generative Pre-trained Transformer 4-omni (GPT-4o), are emerging multi-modal foundation models which have great potential as powerful artificial-intelligence (AI) assistance tools for a myriad of applications, including healthcare, industrial, and academic sectors. Although such foundation models perform well in a wide range of general tasks, their capability without fine-tuning is often limited in specialized tasks. However, full fine-tuning of large foundation models is challenging due to enormous computation/memory/dataset requirements. We show that GPT-4o can decode hand gestures from forearm ultrasound data even with no fine-tuning, and improves with few-shot, in-context learning.",
    "pdf_link": "https://arxiv.org/abs/2407.10870",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10870v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10870/fig_1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10870v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10870/fig_2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10870v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10870/fig_3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10870v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10870/fig_4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10870v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10870/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10870v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10870/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10870v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10870/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10870v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10870/fig_6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10870v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10870/fig_7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10870v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10870/fig_8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10870v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10870/fig_9_1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10870v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10870/fig_9_2.png"
      }
    ],
    "abstract_cn": "GPT-4o等大型视觉-语言模型作为多模态基础模型，正展现出作为多种领域AI辅助工具的巨大潜力。尽管在通用任务中表现出色，但在特定任务上，未经微调的能力有限。全面微调这些模型因资源需求巨大而具挑战性。我们的研究表明，GPT-4o无需微调即可从前臂超声数据解码手势，并通过少量样本情境学习进一步提升性能。",
    "title_cn": "GPT 超声成像技术：利用 VLM 从前臂超声图像中解读手势",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "An Actionable Framework for Assessing Bias and Fairness in Large Language Model Use Cases",
    "submit_datetime": "2024年07月15日",
    "abstract": "Large language models (LLMs) can exhibit bias in a variety of ways. Such biases can create or exacerbate unfair outcomes for certain groups within a protected attribute, including, but not limited to sex, race, sexual orientation, or age. This paper aims to provide a technical guide for practitioners to assess bias and fairness risks in LLM use cases. The main contribution of this work is a decision framework that allows practitioners to determine which metrics to use for a specific LLM use case. To achieve this, this study categorizes LLM bias and fairness risks, maps those risks to a taxonomy of LLM use cases, and then formally defines various metrics to assess each type of risk. As part of this work, several new bias and fairness metrics are introduced, including innovative counterfactual metrics as well as metrics based on stereotype classifiers. Instead of focusing solely on the model itself, the sensitivity of both prompt-risk and model-risk are taken into account by defining evaluations at the level of an LLM use case, characterized by a model and a population of prompts. Furthermore, because all of the evaluation metrics are calculated solely using the LLM output, the proposed framework is highly practical and easily actionable for practitioners.",
    "pdf_link": "https://arxiv.org/abs/2407.10853",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10853v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10853/trimmed_use_case_framework.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLM）在多个方面可能表现出偏见，这些偏见可能导致特定群体（如性别、种族、性取向或年龄等受保护属性内的群体）面临不公平的结果。本文为从业者提供了一个技术指南，帮助他们评估LLM应用中的偏见和公平风险。核心贡献是一个决策框架，指导从业者根据特定应用选择合适的评估指标。研究首先对LLM的偏见和公平风险进行分类，并将其对应到LLM应用的分类体系中，进而定义了一系列评估指标。此外，本文还引入了新的偏见和公平评估指标，包括创新的反事实指标和基于刻板印象分类器的指标。评估不仅关注模型本身，还考虑了提示和模型风险对特定应用的影响。由于所有评估均基于LLM的输出进行，该框架具有高度的实用性和操作性，便于从业者实施。",
    "title_cn": "本研究提出一个实用框架，旨在评估大型语言模型应用中的偏见与公平性问题。",
    "tags": [
      "LLM应用",
      "人工智能",
      "社会科学"
    ]
  },
  {
    "title": "MetaLLM: A High-performant and Cost-efficient Dynamic Framework for Wrapping LLMs",
    "submit_datetime": "2024年07月15日",
    "abstract": "The rapid progress in machine learning (ML) has brought forth many large language models (LLMs) that excel in various tasks and areas. These LLMs come with different abilities and costs in terms of computation or pricing. Since the demand for each query can vary, e.g., because of the queried domain or its complexity, defaulting to one LLM in an application is not usually the best choice, whether it is the biggest, priciest, or even the one with the best average test performance. Consequently, picking the right LLM that is both accurate and cost-effective for an application remains a challenge. In this paper, we introduce MetaLLM, a framework that dynamically and intelligently routes each query to the optimal LLM (among several available LLMs) for classification tasks, achieving significantly improved accuracy and cost-effectiveness. By framing the selection problem as a multi-armed bandit, MetaLLM balances prediction accuracy and cost efficiency under uncertainty. Our experiments, conducted on popular LLM platforms such as OpenAI's GPT models, Amazon's Titan, Anthropic's Claude, and Meta's LLaMa, showcase MetaLLM's efficacy in real-world scenarios, laying the groundwork for future extensions beyond classification tasks.",
    "pdf_link": "https://arxiv.org/abs/2407.10834",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10834v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10834/llmrouting-v2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10834v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10834/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10834v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10834/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10834v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10834/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10834v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10834/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10834v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10834/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10834v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10834/x6.png"
      }
    ],
    "abstract_cn": "随着机器学习的迅猛发展，众多大型语言模型（LLM）在多领域任务中大放异彩。然而，这些模型在计算成本和定价上各异，且查询需求因领域和复杂度而异，单一模型的选择往往并非最优。为此，我们推出了MetaLLM框架，它智能地为每个查询选择最佳LLM，显著提升分类任务的准确性与成本效益。通过将选择问题视为多臂老虎机问题，MetaLLM在不确定性中巧妙平衡了准确性与成本。在OpenAI、Amazon、Anthropic和Meta等平台的实验中，MetaLLM展现了其在实际应用中的高效性，为未来扩展至更多任务奠定了基础。",
    "title_cn": "MetaLLM：一款高效且经济的动态框架，专为大型语言模型打造",
    "tags": [
      "LLM应用",
      "人工智能",
      "云计算"
    ]
  },
  {
    "title": "BiasScanner: Automatic Detection and Classification of News Bias to Strengthen Democracy",
    "submit_datetime": "2024年07月15日",
    "abstract": "The increasing consumption of news online in the 21st century coincided with increased publication of disinformation, biased reporting, hate speech and other unwanted Web content. We describe BiasScanner, an application that aims to strengthen democracy by supporting news consumers with scrutinizing news articles they are reading online. BiasScanner contains a server-side pre-trained large language model to identify biased sentences of news articles and a front-end Web browser plug-in. At the time of writing, BiasScanner can identify and classify more than two dozen types of media bias at the sentence level, making it the most fine-grained model and only deployed application (automatic system in use) of its kind. It was implemented in a light-weight and privacy-respecting manner, and in addition to highlighting likely biased sentence it also provides explanations for each classification decision as well as a summary analysis for each news article. While prior research has addressed news bias detection, we are not aware of any work that resulted in a deployed browser plug-in (c.f. also biasscanner.org for a Web demo).",
    "pdf_link": "https://arxiv.org/abs/2407.10829",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10829v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10829/bias-scanner-architecture.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10829v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10829/BiasScannerNewFull.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10829v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10829/BiasScannerNewReport.png"
      }
    ],
    "abstract_cn": "随着21世纪在线新闻消费的增长，虚假信息、偏见报道和仇恨言论等不良内容也在增多。为此，我们推出了BiasScanner，一款旨在通过帮助读者仔细审查在线新闻来强化民主的应用。该应用包含一个预训练的大型语言模型，用于识别新闻中的偏见句子，并配备了一个浏览器插件。目前，BiasScanner能在句子层面识别并分类超过24种媒体偏见，成为同类中最精细且唯一实际部署的系统。它设计轻巧且注重隐私，不仅能标记可能存在偏见的句子，还为每个分类提供解释，并为每篇文章提供总结分析。尽管已有研究关注新闻偏见检测，但BiasScanner是首个实现为浏览器插件并投入使用的工具（详见biasscanner.org的在线演示）。",
    "title_cn": "BiasScanner 工具旨在自动识别并分类新闻中的偏见，从而助力民主的稳固。",
    "tags": [
      "LLM应用",
      "新闻媒体",
      "信息技术"
    ]
  },
  {
    "title": "LLM Circuit Analyses Are Consistent Across Training and Scale",
    "submit_datetime": "2024年07月15日",
    "abstract": "Most currently deployed large language models (LLMs) undergo continuous training or additional finetuning. By contrast, most research into LLMs' internal mechanisms focuses on models at one snapshot in time (the end of pre-training), raising the question of whether their results generalize to real-world settings. Existing studies of mechanisms over time focus on encoder-only or toy models, which differ significantly from most deployed models. In this study, we track how model mechanisms, operationalized as circuits, emerge and evolve across 300 billion tokens of training in decoder-only LLMs, in models ranging from 70 million to 2.8 billion parameters. We find that task abilities and the functional components that support them emerge consistently at similar token counts across scale. Moreover, although such components may be implemented by different attention heads over time, the overarching algorithm that they implement remains. Surprisingly, both these algorithms and the types of components involved therein can replicate across model scale. These results suggest that circuit analyses conducted on small models at the end of pre-training can provide insights that still apply after additional pre-training and over model scale.",
    "pdf_link": "https://arxiv.org/abs/2407.10827",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10827v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10827/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10827v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10827/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10827v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10827/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10827v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10827/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10827v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10827/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10827v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10827/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10827v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10827/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10827v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10827/x8.png"
      }
    ],
    "abstract_cn": "当前部署的大多数大型语言模型都经历了持续训练或额外微调。然而，关于 LLM 内部机制的研究多聚焦于预训练结束时的单一模型状态，这引发了一个疑问：其研究结果能否适用于实际应用场景？现有研究多关注仅编码器模型或简单模型，与实际部署的模型差异较大。本研究深入探讨了仅解码器 LLM 中，模型机制（以电路形式展现）在跨越 3000 亿个训练令牌的过程中如何涌现与演化，涉及模型参数从 7000 万至 28 亿不等。我们发现，任务能力及其支撑功能组件在不同规模模型中于相似令牌数时稳定出现。尽管这些组件可能随时间由不同注意力头实现，但其核心算法保持一致。更令人惊讶的是，这些算法及所涉组件类型能在不同模型规模间复制。这些发现表明，预训练结束时对小模型进行的电路分析，其洞察力在后续预训练及不同模型规模中依然有效。",
    "title_cn": "LLM 电路分析在不同训练阶段和规模上均保持一致性。",
    "tags": [
      "LLM理论",
      "人工智能",
      "机器学习"
    ]
  },
  {
    "title": "Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation",
    "submit_datetime": "2024年07月15日",
    "abstract": "As large language models (LLMs) advance, it becomes more challenging to reliably evaluate their output due to the high costs of human evaluation. To make progress towards better LLM autoraters, we introduce FLAMe, a family of Foundational Large Autorater Models. FLAMe is trained on our large and diverse collection of 100+ quality assessment tasks comprising 5M+ human judgments, curated and standardized using publicly released human evaluations from previous research. FLAMe significantly improves generalization to a wide variety of held-out tasks, outperforming LLMs trained on proprietary data like GPT-4 and Claude-3 on many tasks. We show that FLAMe can also serve as a powerful starting point for further downstream fine-tuning, using reward modeling evaluation as a case study (FLAMe-RM). Notably, on RewardBench, our FLAMe-RM-24B model (with an accuracy of 87.8%) is the top-performing generative model trained exclusively on permissively licensed data, outperforming both GPT-4-0125 (85.9%) and GPT-4o (84.7%). Additionally, we explore a more computationally efficient approach using a novel tail-patch fine-tuning strategy to optimize our FLAMe multitask mixture for reward modeling evaluation (FLAMe-Opt-RM), offering competitive RewardBench performance while requiring approximately 25x less training datapoints. Overall, our FLAMe variants outperform all popular proprietary LLM-as-a-Judge models we consider across 8 out of 12 autorater evaluation benchmarks, encompassing 53 quality assessment tasks, including RewardBench and LLM-AggreFact. Finally, our analysis reveals that FLAMe is significantly less biased than these LLM-as-a-Judge models on the CoBBLEr autorater bias benchmark, while effectively identifying high-quality responses for code generation.",
    "pdf_link": "https://arxiv.org/abs/2407.10817",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10817v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10817/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10817v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10817/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10817v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10817/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10817v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10817/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10817v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10817/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10817v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10817/x6.png"
      }
    ],
    "abstract_cn": "随着大型语言模型的进步，由于人工评估的高成本，可靠地评估它们的输出变得越来越具有挑战性。为此，我们引入了FLAMe，一系列基础大型自动评估模型。FLAMe在我们收集的100多个质量评估任务中进行了训练，这些任务包含超过500万个人类判断，这些判断是通过以前研究中公开发布的人类评估精心挑选和标准化的。FLAMe在广泛的保留任务上显著提高了泛化能力，在许多任务上超过了像GPT-4和Claude-3这样在专有数据上训练的LLM。我们展示了FLAMe也可以作为一个强大的起点，用于进一步的下游微调，以奖励模型评估为例（FLAMe-RM）。值得注意的是，在我们的RewardBench上，我们的FLAMe-RM-24B模型（准确率为87.8%）是表现最佳的仅在许可数据上训练的生成模型，超过了GPT-4-0125（85.9%）和GPT-4o（84.7%）。此外，我们探索了一种更计算效率高的方法，使用一种新颖的尾部补丁微调策略来优化我们的FLAMe多任务混合模型，用于奖励模型评估（FLAMe-Opt-RM），提供了有竞争力的RewardBench性能，同时需要的训练数据点大约减少了25倍。总的来说，我们的FLAMe变体在12个自动评估基准中的8个上超过了我们考虑的所有流行的专有LLM-as-a-Judge模型，涵盖了53个质量评估任务，包括RewardBench和LLM-AggreFact。最后，我们的分析显示，FLAMe在CoBBLEr自动评估偏差基准上显著比这些LLM-as-a-Judge模型偏差更小，同时有效地识别了高质量的代码生成响应。",
    "title_cn": "基础自动评分器：优化大型语言模型，提升自动评估质量",
    "tags": [
      "LLM应用",
      "人工智能",
      "软件开发"
    ]
  },
  {
    "title": "Mix-CPT: A Domain Adaptation Framework via Decoupling Knowledge Learning and Format Alignment",
    "submit_datetime": "2024年07月15日",
    "abstract": "Adapting general large language models (LLMs) to specialized domains presents great challenges due to varied data distributions. This adaptation typically requires continual pre-training on massive domain-specific corpora to facilitate knowledge memorization, followed by training to apply this knowledge following human instructions and preferences. However, this method may result in inefficient knowledge memorization due to a lack of awareness of knowledge utilization and imposes substantial demands on LLMs to simultaneously learn knowledge utilization and format alignment with limited training samples. To facilitate the domain adaptation of LLM, we revise this process and propose a new domain adaptation framework including domain knowledge learning and general format alignment, called Mix-CPT. Specifically, we first conduct a knowledge mixture continual pre-training that concurrently focuses on knowledge memorization and utilization, allowing for mutual reinforcement. To avoid catastrophic forgetting during the continual pre-training process, we further incorporate a logit swap self-distillation constraint. Subsequently, leveraging the knowledge and capabilities acquired during continual pre-training, we efficiently perform instruction tuning and alignment with a few general training samples to achieve format alignment. Extensive experiments demonstrate that our proposed Mix-CPT framework can simultaneously improve the task-solving capabilities of LLMs on the target and general domains compared to the traditional adaptation methods.",
    "pdf_link": "https://arxiv.org/abs/2407.10804",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10804v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10804/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10804v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10804/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10804v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10804/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10804v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10804/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10804v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10804/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10804v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10804/x6.png"
      }
    ],
    "abstract_cn": "将通用大型语言模型 (LLM) 适应到专业领域，因数据分布多样性而颇具挑战。传统方法需在大规模领域特定语料库上持续预训练，以记忆知识，再按人类指令和偏好应用。但此法效率低下，因忽视知识利用，且在有限样本下，LLM 需同时学习知识利用与格式对齐。为此，我们提出 Mix-CPT 框架，融合领域知识学习与通用格式对齐。首先，进行知识混合持续预训练，兼顾记忆与利用，相互强化。为防遗忘，引入 logit swap 自蒸馏约束。随后，利用预训练所得，高效指令调整与对齐，少量样本即可。实验证明，Mix-CPT 能提升 LLM 在目标与通用领域的任务解决能力，超越传统方法。",
    "title_cn": "Mix-CPT：一种领域适应框架，通过分离知识学习与格式对齐来实现。",
    "tags": [
      "LLM应用",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Multilingual Contrastive Decoding via Language-Agnostic Layers Skipping",
    "submit_datetime": "2024年07月15日",
    "abstract": "Decoding by contrasting layers (DoLa), is designed to improve the generation quality of large language models (LLMs) by contrasting the prediction probabilities between an early exit output (amateur logits) and the final output (expert logits). However, we find that this approach does not work well on non-English tasks. Inspired by previous interpretability work on language transition during the model's forward pass, we discover that this issue arises from a language mismatch between early exit output and final output. In this work, we propose an improved contrastive decoding algorithm that is effective for diverse languages beyond English. To obtain more helpful amateur logits, we devise two strategies to skip a set of bottom, language-agnostic layers based on our preliminary analysis. Experimental results on multilingual reasoning benchmarks demonstrate that our proposed method outperforms previous contrastive decoding baselines and substantially improves LLM's chain-of-thought reasoning accuracy across 11 languages. The project will be available at: https://github.com/NJUNLP/SkipLayerCD.",
    "pdf_link": "https://arxiv.org/abs/2407.10795",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10795v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10795/case_study_zh.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10795v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10795/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10795v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10795/x2.png"
      }
    ],
    "abstract_cn": "通过对比层解码（DoLa），旨在通过比较早期与最终输出的预测概率，提升大型语言模型（LLM）的生成质量。然而，该方法在非英语任务上表现欠佳。受先前关于模型前向传递中语言转换的研究启发，我们发现问题在于早期与最终输出间的语言不匹配。为此，我们提出了一种适用于多语言的改进对比解码算法。为获取更有价值的早期输出，我们设计了两种策略，跳过底层、与语言无关的层。实验结果显示，我们的方法不仅超越了以往的对比解码基准，还显著提升了LLM在11种语言中的思维链推理准确性。项目详情请访问：https://github.com/NJUNLP/SkipLayerCD。",
    "title_cn": "多语言对比解码：跨越语言界限的层级跳跃",
    "tags": [
      "LLM应用",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Graphusion: Leveraging Large Language Models for Scientific Knowledge Graph Fusion and Construction in NLP Education",
    "submit_datetime": "2024年07月15日",
    "abstract": "Knowledge graphs (KGs) are crucial in the field of artificial intelligence and are widely applied in downstream tasks, such as enhancing Question Answering (QA) systems. The construction of KGs typically requires significant effort from domain experts. Recently, Large Language Models (LLMs) have been used for knowledge graph construction (KGC), however, most existing approaches focus on a local perspective, extracting knowledge triplets from individual sentences or documents. In this work, we introduce Graphusion, a zero-shot KGC framework from free text. The core fusion module provides a global view of triplets, incorporating entity merging, conflict resolution, and novel triplet discovery. We showcase how Graphusion could be applied to the natural language processing (NLP) domain and validate it in the educational scenario. Specifically, we introduce TutorQA, a new expert-verified benchmark for graph reasoning and QA, comprising six tasks and a total of 1,200 QA pairs. Our evaluation demonstrates that Graphusion surpasses supervised baselines by up to 10% in accuracy on link prediction. Additionally, it achieves average scores of 2.92 and 2.37 out of 3 in human evaluations for concept entity extraction and relation recognition, respectively.",
    "pdf_link": "https://arxiv.org/abs/2407.10794",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10794v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10794/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10794v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10794/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10794v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10794/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10794v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10794/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10794v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10794/wordcloud.png"
      }
    ],
    "abstract_cn": "知识图谱 (KGs) 在 AI 领域扮演关键角色，尤其在提升问答 (QA) 系统方面。KGs 的构建往往依赖于领域专家的深入工作。近期，大型语言模型 (LLMs) 开始用于知识图谱构建 (KGC)，但多数方法仍局限于从单句或文档中提取局部知识三元组。为此，我们提出了 Graphusion，一个从自由文本中进行零-shot KGC 的创新框架。其核心融合模块不仅整合了实体合并与冲突解决，还实现了新三元组的发现，提供了全局视角。我们验证了 Graphusion 在 NLP 领域的应用，特别是在教育场景中，通过 TutorQA 这一新基准，展示了其在图推理和 QA 任务中的优越性能。评估结果表明，Graphusion 在链接预测的准确性上超越了传统监督方法高达 10%，并在人类评估中取得了优异成绩，分别为概念实体提取 2.92 分和关系识别 2.37 分（满分 3 分）。",
    "title_cn": "Graphusion：借助大型语言模型，在 NLP 教育领域实现科学知识图谱的融合与构建",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "GraphEval: A Knowledge-Graph Based LLM Hallucination Evaluation Framework",
    "submit_datetime": "2024年07月15日",
    "abstract": "Methods to evaluate Large Language Model (LLM) responses and detect inconsistencies, also known as hallucinations, with respect to the provided knowledge, are becoming increasingly important for LLM applications. Current metrics fall short in their ability to provide explainable decisions, systematically check all pieces of information in the response, and are often too computationally expensive to be used in practice. We present GraphEval: a hallucination evaluation framework based on representing information in Knowledge Graph (KG) structures. Our method identifies the specific triples in the KG that are prone to hallucinations and hence provides more insight into where in the response a hallucination has occurred, if at all, than previous methods. Furthermore, using our approach in conjunction with state-of-the-art natural language inference (NLI) models leads to an improvement in balanced accuracy on various hallucination benchmarks, compared to using the raw NLI models. Lastly, we explore the use of GraphEval for hallucination correction by leveraging the structure of the KG, a method we name GraphCorrect, and demonstrate that the majority of hallucinations can indeed be rectified.",
    "pdf_link": "https://arxiv.org/abs/2407.10793",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10793v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10793/grapheval_process.png"
      }
    ],
    "abstract_cn": "随着 LLM 应用的普及，评估其响应并检测知识相关的不一致性（即幻觉）的方法愈发关键。现有的评估指标在解释性、全面性及计算成本方面均显不足。为此，我们推出了 GraphEval 框架，该框架利用知识图谱 (KG) 结构进行幻觉评估，能精准定位 KG 中易产生幻觉的三元组，从而更深入地揭示幻觉在响应中的具体位置。此外，结合顶尖的自然语言推理 (NLI) 模型，我们的方法在幻觉基准测试中的平衡准确性上有所提升。最后，我们创新性地提出了 GraphCorrect 方法，通过利用 KG 结构进行幻觉校正，并证实了其对大多数幻觉的纠正效果。",
    "title_cn": "GraphEval：一款基于知识图谱的 LLM 幻觉评估框架",
    "tags": [
      "LLM应用",
      "知识图谱",
      ""
    ]
  },
  {
    "title": "Interpretability analysis on a pathology foundation model reveals biologically relevant embeddings across modalities",
    "submit_datetime": "2024年07月15日",
    "abstract": "Mechanistic interpretability has been explored in detail for large language models (LLMs). For the first time, we provide a preliminary investigation with similar interpretability methods for medical imaging. Specifically, we analyze the features from a ViT-Small encoder obtained from a pathology Foundation Model via application to two datasets: one dataset of pathology images, and one dataset of pathology images paired with spatial transcriptomics. We discover an interpretable representation of cell and tissue morphology, along with gene expression within the model embedding space. Our work paves the way for further exploration around interpretable feature dimensions and their utility for medical and clinical applications.",
    "pdf_link": "https://arxiv.org/abs/2407.10785",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10785v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10785/embedding_viz_mi2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10785v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10785/SAE_features_highres.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10785v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10785/spatial_gene_expression_fig.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10785v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10785/metrics_across_lambdas.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLM）的机制性可解释性已深入研究。我们首次尝试将这些方法应用于医学影像，分析了从病理学基础模型中提取的ViT-Small编码器特征。通过两个数据集——病理图像集和配对的空间转录组学图像集，我们揭示了细胞和组织形态的可解释表示及模型嵌入空间中的基因表达。这一探索为未来在医学和临床领域中可解释特征维度的研究和应用奠定了基础。",
    "title_cn": "病理学基础模型的可解释性分析，揭示了多模态间的生物学相关嵌入。",
    "tags": [
      "LLM应用",
      "",
      "医学影像"
    ]
  },
  {
    "title": "Qwen2-Audio Technical Report",
    "submit_datetime": "2024年07月15日",
    "abstract": "We introduce the latest progress of Qwen-Audio, a large-scale audio-language model called Qwen2-Audio, which is capable of accepting various audio signal inputs and performing audio analysis or direct textual responses with regard to speech instructions. In contrast to complex hierarchical tags, we have simplified the pre-training process by utilizing natural language prompts for different data and tasks, and have further expanded the data volume. We have boosted the instruction-following capability of Qwen2-Audio and implemented two distinct audio interaction modes for voice chat and audio analysis. In the voice chat mode, users can freely engage in voice interactions with Qwen2-Audio without text input. In the audio analysis mode, users could provide audio and text instructions for analysis during the interaction. Note that we do not use any system prompts to switch between voice chat and audio analysis modes. Qwen2-Audio is capable of intelligently comprehending the content within audio and following voice commands to respond appropriately. For instance, in an audio segment that simultaneously contains sounds, multi-speaker conversations, and a voice command, Qwen2-Audio can directly understand the command and provide an interpretation and response to the audio. Additionally, DPO has optimized the model's performance in terms of factuality and adherence to desired behavior. According to the evaluation results from AIR-Bench, Qwen2-Audio outperformed previous SOTAs, such as Gemini-1.5-pro, in tests focused on audio-centric instruction-following capabilities. Qwen2-Audio is open-sourced with the aim of fostering the advancement of the multi-modal language community.",
    "pdf_link": "https://arxiv.org/abs/2407.10759",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10759v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10759/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10759v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10759/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10759v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10759/pretrain_hours.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10759v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10759/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10759v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10759/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10759v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10759/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10759v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10759/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10759v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10759/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10759v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10759/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10759v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10759/x9.png"
      }
    ],
    "abstract_cn": "我们推出了Qwen-Audio的最新成果——Qwen2-Audio，这是一个能够处理多种音频输入并进行分析或直接响应语音指令的大型音频-语言模型。通过使用自然语言提示简化预训练流程并扩充数据量，我们增强了Qwen2-Audio的指令执行能力，并设计了两种音频交互模式：语音聊天和音频分析。在语音聊天模式下，用户可与Qwen2-Audio自由语音交流，无需文本介入；而在音频分析模式中，用户可结合音频与文本指令进行深入分析。值得一提的是，这两种模式间的切换无需系统提示，Qwen2-Audio能智能识别并响应音频内容。例如，面对同时包含多种声音、多人对话及语音指令的复杂音频，Qwen2-Audio能精准理解指令并给出相应解读。此外，通过DPO的优化，模型在保持事实准确性和行为一致性方面表现更佳。根据AIR-Bench的评测，Qwen2-Audio在音频指令遵循能力测试中超越了Gemini-1.5-pro等先前最佳模型。我们开源Qwen2-Audio，旨在推动多模态语言技术的发展。",
    "title_cn": "Qwen2-Audio 技术报告",
    "tags": [
      "LLM应用",
      "音频处理",
      "语音识别"
    ]
  },
  {
    "title": "Codebook LLMs: Adapting Political Science Codebooks for LLM Use and Adapting LLMs to Follow Codebooks",
    "submit_datetime": "2024年07月15日",
    "abstract": "Codebooks -- documents that operationalize constructs and outline annotation procedures -- are used almost universally by social scientists when coding unstructured political texts. Recently, to reduce manual annotation costs, political scientists have looked to generative large language models (LLMs) to label and analyze text data. However, previous work using LLMs for classification has implicitly relied on the universal label assumption -- correct classification of documents is possible using only a class label or minimal definition and the information that the LLM inductively learns during its pre-training. In contrast, we argue that political scientists who care about valid measurement should instead make a codebook-construct label assumption -- an LLM should follow the definition and exclusion criteria of a construct/label provided in a codebook. In this work, we collect and curate three political science datasets and their original codebooks and conduct a set of experiments to understand whether LLMs comply with codebook instructions, whether rewriting codebooks improves performance, and whether instruction-tuning LLMs on codebook-document-label tuples improves performance over zero-shot classification. Using Mistral 7B Instruct as our LLM, we find re-structuring the original codebooks gives modest gains in zero-shot performance but the model still struggles to comply with the constraints of the codebooks. Optimistically, instruction-tuning Mistral on one of our datasets gives significant gains over zero-shot inference (0.76 versus 0.53 micro F1). We hope our conceptualization of the codebook-specific task, assumptions, and instruction-tuning pipeline as well our semi-structured LLM codebook format will help political scientists readily adapt to the LLM era.",
    "pdf_link": "https://arxiv.org/abs/2407.10747",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10747v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10747/x1.png"
      }
    ],
    "abstract_cn": "代码本，作为操作化构建和注释流程的指南，在社会科学领域广泛应用于非结构化政治文本的编码。为降低人工注释成本，政治科学家开始利用大型语言模型（LLM）进行文本标记与分析。然而，以往基于LLM的分类研究暗含了通用标签假设，即仅凭类别标签或简要定义，结合LLM预训练中习得的信息，即可实现文档的准确分类。我们则主张，关注测量有效性的政治科学家应采纳代码本-构建标签假设，即LLM应严格遵循代码本中构建/标签的定义与排除标准。为此，我们收集并优化了三个政治科学数据集及其原始代码本，并开展实验，探究LLM是否遵循代码本指令、重写代码本能否提升性能，以及在代码本-文档-标签三元组上对LLM进行指令调优是否能超越零-shot分类。实验结果显示，尽管重新构建代码本在零-shot性能上有所提升，但LLM仍难以完全遵守代码本约束。值得欣喜的是，对Mistral进行指令调优，显著提升了零-shot推理性能（微F1从0.53提升至0.76）。我们期待，通过明确代码本特定任务、假设及指令调优流程，以及采用半结构化的LLM代码本格式，能助力政治科学家顺利迈入LLM时代。",
    "title_cn": "Codebook LLMs：将政治科学代码簿应用于 LLM，并调整 LLMs 以遵循代码簿规范",
    "tags": [
      "LLM应用",
      "政治科学",
      "社会科学"
    ]
  },
  {
    "title": "CLAVE: An Adaptive Framework for Evaluating Values of LLM Generated Responses",
    "submit_datetime": "2024年07月15日",
    "abstract": "The rapid progress in Large Language Models (LLMs) poses potential risks such as generating unethical content. Assessing LLMs' values can help expose their misalignment, but relies on reference-free evaluators, e.g., fine-tuned LLMs or close-source ones like GPT-4, to identify values reflected in generated responses. Nevertheless, these evaluators face two challenges in open-ended value evaluation: they should align with changing human value definitions with minimal annotation, against their own bias (adaptability), and detect varying value expressions and scenarios robustly (generalizability). To handle these challenges, we introduce CLAVE, a novel framework which integrates two complementary LLMs, a large one to extract high-level value concepts from a few human labels, leveraging its extensive knowledge and generalizability, and a smaller one fine-tuned on such concepts to better align with human value understanding. This dual-model approach enables calibration with any value systems using <100 human-labeled samples per value type. Then we present ValEval, a comprehensive dataset comprising 13k+ (text,value,label) tuples across diverse domains, covering three major value systems. We benchmark the capabilities of 12+ popular LLM evaluators and analyze their strengths and weaknesses. Our findings reveal that combining fine-tuned small models and prompt-based large ones serves as a superior balance in value evaluation.",
    "pdf_link": "https://arxiv.org/abs/2407.10725",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10725v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10725/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10725v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10725/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10725v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10725/data_amount_curves_ll.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10725v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10725/module_component_bar.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10725v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10725/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10725v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10725/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10725v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10725/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10725v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10725/annotation_screen.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10725v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10725/data_diversity_bar.png"
      }
    ],
    "abstract_cn": "随着大型语言模型（LLM）的迅猛发展，生成不道德内容的风险也随之增加。评估这些模型的价值观有助于揭示其潜在的不一致性，但这一过程依赖于无参考的评估器，如微调的LLM或闭源的GPT-4，以识别生成内容中的价值观。然而，这些评估器在开放式价值评估中面临两大挑战：一是如何与不断变化的人类价值定义保持一致，同时减少自身偏见（适应性）；二是如何稳健地识别不同的价值表达和场景（泛化性）。为解决这些难题，我们提出了CLAVE框架，该框架结合了两个互补的LLM：一个大型模型利用其广泛知识从少量人类标签中提取高级价值概念，另一个较小模型则在这些概念上进行微调，以更好地与人类价值理解对齐。这种双模型策略使得每种价值类型仅需不到100个样本即可与任何价值系统进行校准。此外，我们还推出了ValEval数据集，涵盖13k+文本、价值、标签元组，横跨多个领域，涉及三大价值系统。我们测试了12+流行LLM评估器，并分析了它们的优劣。研究结果表明，结合微调的小模型和基于提示的大型模型在价值评估中实现了最佳平衡。",
    "title_cn": "CLAVE：一款自适应框架，专为评估 LLM 生成回复的价值而设计",
    "tags": [
      "LLM应用",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Quantized Prompt for Efficient Generalization of Vision-Language Models",
    "submit_datetime": "2024年07月15日",
    "abstract": "In the past few years, large-scale pre-trained vision-language models like CLIP have achieved tremendous success in various fields. Naturally, how to transfer the rich knowledge in such huge pre-trained models to downstream tasks and datasets becomes a hot topic. During downstream adaptation, the most challenging problems are overfitting and catastrophic forgetting, which can cause the model to overly focus on the current data and lose more crucial domain-general knowledge. Existing works use classic regularization techniques to solve the problems. As solutions become increasingly complex, the ever-growing storage and inference costs are also a significant problem that urgently needs to be addressed. While in this paper, we start from an observation that proper random noise can suppress overfitting and catastrophic forgetting. Then we regard quantization error as a kind of noise, and explore quantization for regularizing vision-language model, which is quite efficiency and effective. Furthermore, to improve the model's generalization capability while maintaining its specialization capacity at minimal cost, we deeply analyze the characteristics of the weight distribution in prompts, conclude several principles for quantization module design and follow such principles to create several competitive baselines. The proposed method is significantly efficient due to its inherent lightweight nature, making it possible to adapt on extremely resource-limited devices. Our method can be fruitfully integrated into many existing approaches like MaPLe, enhancing accuracy while reducing storage overhead, making it more powerful yet versatile. Extensive experiments on 11 datasets shows great superiority of our method sufficiently. Code is available at https://github.com/beyondhtx/QPrompt.",
    "pdf_link": "https://arxiv.org/abs/2407.10704",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10704/performance.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.10704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10704/average,seed1,base.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10704/average,seed1,new.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10704/eurosat,ep5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10704/eurosat,ep30.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10704/eurosat,ep10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10704/eurosat,ep35.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10704/eurosat,ep15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10704/eurosat,ep40.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10704/eurosat,ep20.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10704/eurosat,ep45.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10704/eurosat,ep25.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10704/eurosat,ep50.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10704/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10704/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10704/KLD.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10704/qaverage,seed1,base.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10704/qaverage,seed1,new.png"
      }
    ],
    "abstract_cn": "近年来，CLIP等大规模预训练视觉-语言模型在多领域大放异彩。如何将这些庞大数据模型中的丰富知识有效迁移至下游任务，成为研究焦点。然而，下游适应过程中常遭遇过拟合与灾难性遗忘两大难题，导致模型过度适应当前数据，丧失关键的通用知识。传统方法依赖经典正则化技术，但随着解决方案日益复杂，存储与推理成本激增，亟待新策略。本文从随机噪声抑制过拟合现象中获得灵感，将量化误差视为噪声，探索高效且有效的量化正则化方法。同时，为在低成本下提升模型泛化与专业化能力，我们深入剖析提示权重分布，提炼量化模块设计原则，并据此打造多个竞争性基准。该方法轻量高效，适用于资源受限设备。此外，它能无缝融入MaPLe等现有技术，提升准确率并降低存储负担，兼具强大功能与广泛适用性。在11个数据集上的实验验证了其卓越性能。相关代码已公开于https://github.com/beyondhtx/QPrompt。",
    "title_cn": "量化提示助力视觉-语言模型高效泛化",
    "tags": [
      "LLM应用",
      "计算机视觉",
      "机器学习"
    ]
  },
  {
    "title": "DOCBENCH: A Benchmark for Evaluating LLM-based Document Reading Systems",
    "submit_datetime": "2024年07月15日",
    "abstract": "Recently, there has been a growing interest among large language model (LLM) developers in LLM-based document reading systems, which enable users to upload their own documents and pose questions related to the document contents, going beyond simple reading comprehension tasks. Consequently, these systems have been carefully designed to tackle challenges such as file parsing, metadata extraction, multi-modal information understanding and long-context reading. However, no current benchmark exists to evaluate their performance in such scenarios, where a raw file and questions are provided as input, and a corresponding response is expected as output. In this paper, we introduce DocBench, a new benchmark designed to evaluate LLM-based document reading systems. Our benchmark involves a meticulously crafted process, including the recruitment of human annotators and the generation of synthetic questions. It includes 229 real documents and 1,102 questions, spanning across five different domains and four major types of questions. We evaluate both proprietary LLM-based systems accessible via web interfaces or APIs, and a parse-then-read pipeline employing open-source LLMs. Our evaluations reveal noticeable gaps between existing LLM-based document reading systems and human performance, underscoring the challenges of developing proficient systems. To summarize, DocBench aims to establish a standardized benchmark for evaluating LLM-based document reading systems under diverse real-world scenarios, thereby guiding future advancements in this research area.",
    "pdf_link": "https://arxiv.org/abs/2407.10701",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10701v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10701/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10701v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10701/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10701v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10701/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10701v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10701/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10701v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10701/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10701v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10701/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10701v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10701/x7.png"
      }
    ],
    "abstract_cn": "近期，大型语言模型（LLM）开发者对基于LLM的文档阅读系统兴趣日益浓厚，这类系统不仅支持用户上传文档并提问，还超越了传统阅读理解任务的范畴。为应对文件解析、元数据提取等复杂挑战，这些系统设计精良。然而，目前尚无基准评估其在实际应用中的表现。为此，我们推出了DocBench，一个专为评估基于LLM的文档阅读系统而设计的新基准。该基准精心策划，涵盖人工标注员招募与合成问题生成，包含229份真实文档及1,102个问题，横跨五个领域、四种问题类型。我们评估了通过网页接口或API访问的专有系统，以及采用开源LLM的解析-阅读流水线。评估结果显示，现有系统与人类表现存在显著差距，凸显了开发高效系统的挑战。DocBench旨在为多样化现实场景下的基于LLM的文档阅读系统评估设立标准，引领该领域的未来发展。",
    "title_cn": "DOCBENCH：评估 LLM 文档阅读系统性能的标杆",
    "tags": [
      "LLM应用",
      "文档管理",
      "人工智能"
    ]
  },
  {
    "title": "An Empirical Study of Validating Synthetic Data for Formula Generation",
    "submit_datetime": "2024年07月15日",
    "abstract": "Large language models (LLMs) can be leveraged to help with writing formulas in spreadsheets, but resources on these formulas are scarce, impacting both the base performance of pre-trained models and limiting the ability to fine-tune them. Given a corpus of formulas, we can use a(nother) model to generate synthetic natural language utterances for fine-tuning. However, it is important to validate whether the NL generated by the LLM is indeed accurate to be beneficial for fine-tuning. In this paper, we provide empirical results on the impact of validating these synthetic training examples with surrogate objectives that evaluate the accuracy of the synthetic annotations. We demonstrate that validation improves performance over raw data across four models (2 open and 2 closed weight). Interestingly, we show that although validation tends to prune more challenging examples, it increases the complexity of problems that models can solve after being fine-tuned on validated data.",
    "pdf_link": "https://arxiv.org/abs/2407.10657",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10657v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10657/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10657v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10657/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10657v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10657/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10657v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10657/x4.png"
      }
    ],
    "abstract_cn": "LLM 虽能辅助编写电子表格公式，但相关资源匮乏，影响了预训练模型的性能并限制了微调能力。我们利用另一模型生成合成自然语言表述进行微调，并验证其准确性至关重要。本文通过实证研究，展示了验证合成训练示例对提升模型性能的影响，尤其是在四个不同模型上。有趣的是，尽管验证剔除了一些难题，但它实际上增强了模型在微调后解决问题的复杂性。",
    "title_cn": "探究合成数据在公式生成中的有效性",
    "tags": [
      "LLM应用",
      "电子表格",
      "人工智能"
    ]
  },
  {
    "title": "Prompt Selection Matters: Enhancing Text Annotations for Social Sciences with Large Language Models",
    "submit_datetime": "2024年07月15日",
    "abstract": "Large Language Models have recently been applied to text annotation tasks from social sciences, equalling or surpassing the performance of human workers at a fraction of the cost. However, no inquiry has yet been made on the impact of prompt selection on labelling accuracy. In this study, we show that performance greatly varies between prompts, and we apply the method of automatic prompt optimization to systematically craft high quality prompts. We also provide the community with a simple, browser-based implementation of the method at https://prompt-ultra.github.io/ .",
    "pdf_link": "https://arxiv.org/abs/2407.10645",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10645v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10645/Eval.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10645v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10645/Optim.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10645v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10645/Split.png"
      }
    ],
    "abstract_cn": "大型语言模型在社会科学文本标注任务中的表现已能媲美甚至超越人类，且成本大幅降低。但提示选择对标注准确性的影响仍未被探究。本研究揭示了提示间性能的显著差异，并运用自动优化技术系统生成高质量提示。此外，我们通过 https://prompt-ultra.github.io/ 为社区提供了一个便捷的浏览器实现方案。",
    "title_cn": "提示选择不容忽视：借助大型语言模型，为社会科学领域的文本标注注入新活力。",
    "tags": [
      "LLM应用",
      "社会科学",
      "人工智能"
    ]
  },
  {
    "title": "Evaluating Model Bias Requires Characterizing its Mistakes",
    "submit_datetime": "2024年07月15日",
    "abstract": "The ability to properly benchmark model performance in the face of spurious correlations is important to both build better predictors and increase confidence that models are operating as intended. We demonstrate that characterizing (as opposed to simply quantifying) model mistakes across subgroups is pivotal to properly reflect model biases, which are ignored by standard metrics such as worst-group accuracy or accuracy gap. Inspired by the hypothesis testing framework, we introduce SkewSize, a principled and flexible metric that captures bias from mistakes in a model's predictions. It can be used in multi-class settings or generalised to the open vocabulary setting of generative models. SkewSize is an aggregation of the effect size of the interaction between two categorical variables: the spurious variable representing the bias attribute and the model's prediction. We demonstrate the utility of SkewSize in multiple settings including: standard vision models trained on synthetic data, vision models trained on ImageNet, and large scale vision-and-language models from the BLIP-2 family. In each case, the proposed SkewSize is able to highlight biases not captured by other metrics, while also providing insights on the impact of recently proposed techniques, such as instruction tuning.",
    "pdf_link": "https://arxiv.org/abs/2407.10633",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10633v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10633/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10633v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10633/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10633v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10633/socks_vit1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10633v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10633/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10633v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10633/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10633v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10633/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10633v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10633/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10633v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10633/x7.png"
      }
    ],
    "abstract_cn": "在处理虚假相关性时，准确评估模型性能对于提升预测质量和增强模型运行信心至关重要。我们通过在不同子组间细致表征模型错误，而非仅量化错误，揭示了模型偏差，这些偏差常被传统指标如最差组准确性所忽略。基于假设检验理念，我们创新性地提出了SkewSize指标，该指标能从模型预测中精准捕捉偏差，并适用于多类别及生成模型的开放词汇场景。SkewSize聚焦于虚假变量与模型预测间的交互效应，我们在多种模型应用场景中验证了其效能，包括合成数据训练的视觉模型、ImageNet训练的视觉模型，以及BLIP-2系列的大规模视觉语言模型。SkewSize不仅揭示了其他指标未察觉的偏差，还深入分析了如指令调优等新技术的实际影响。",
    "title_cn": "要评估模型偏差，关键在于剖析其错误特征。",
    "tags": [
      "LLM应用",
      "计算机视觉",
      "人工智能"
    ]
  },
  {
    "title": "Arena Learning: Build Data Flywheel for LLMs Post-training via Simulated Chatbot Arena",
    "submit_datetime": "2024年07月15日",
    "abstract": "Assessing the effectiveness of large language models (LLMs) presents substantial challenges. The method of conducting human-annotated battles in an online Chatbot Arena is a highly effective evaluative technique. However, this approach is limited by the costs and time required for human annotation. In this paper, we introduce Arena Learning, an innovative offline strategy designed to simulate these arena battles using AI-driven annotations to evaluate battle outcomes, thus facilitating the continuous improvement of the target model through both supervised fine-tuning and reinforcement learning. Arena Learning comprises two key elements. First, it ensures precise evaluations and maintains consistency between offline simulations and online competitions via WizardArena, a pipeline developed to accurately predict the Elo rankings of various models using a meticulously designed offline test set. Our results demonstrate that WizardArena's predictions closely align with those from the online Arena. Second, it involves the continuous improvement of training data based on the battle results and the refined model. We establish a data flywheel to iteratively update the training data by highlighting the weaknesses of the target model based on its battle results, enabling it to learn from the strengths of multiple different models. We apply Arena Learning to train our target model, WizardLM-$β$, and demonstrate significant performance enhancements across various metrics. This fully automated training and evaluation pipeline sets the stage for continuous advancements in various LLMs via post-training. Notably, Arena Learning plays a pivotal role in the success of WizardLM-2, and this paper serves both as an exploration of its efficacy and a foundational study for future discussions related to WizardLM-2 and its derivatives.",
    "pdf_link": "https://arxiv.org/abs/2407.10627",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10627v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10627/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10627v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10627/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10627v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10627/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10627v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10627/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10627v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10627/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10627v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10627/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10627v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10627/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10627v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10627/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10627v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10627/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10627v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10627/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10627v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10627/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10627v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10627/x13.png"
      }
    ],
    "abstract_cn": "评估大型语言模型的有效性颇具挑战。在线聊天机器人竞技场中的人工标注战斗虽高效，但成本和时间成本高昂。为此，我们提出竞技场学习，一种创新的离线策略，利用AI驱动的标注模拟战斗，评估结果，助力模型通过监督微调和强化学习持续进步。竞技场学习包含两大核心：首先，通过WizardArena精确预测模型Elo排名，确保离线模拟与在线比赛的一致性；其次，基于战斗结果和模型改进，持续优化训练数据。我们构建数据飞轮，迭代更新训练数据，使模型能从多模型优势中学习。我们将此策略应用于WizardLM-$β$，显著提升其性能。这一全自动训练与评估流程为LLM的持续进步奠定基础。竞技场学习在WizardLM-2的成功中扮演关键角色，本文既是其效能的探索，也是未来相关研究的基础。",
    "title_cn": "竞技场学习：利用模拟聊天机器人竞技场，为 LLMs 训练后打造数据飞轮",
    "tags": [
      "LLM应用",
      "人工智能",
      "机器学习"
    ]
  },
  {
    "title": "Leave No Knowledge Behind During Knowledge Distillation: Towards Practical and Effective Knowledge Distillation for Code-Switching ASR Using Realistic Data",
    "submit_datetime": "2024年07月15日",
    "abstract": "Recent advances in automatic speech recognition (ASR) often rely on large speech foundation models for generating high-quality transcriptions. However, these models can be impractical due to limited computing resources. The situation is even more severe in terms of more realistic or difficult scenarios, such as code-switching ASR (CS-ASR). To address this, we present a framework for developing more efficient models for CS-ASR through knowledge distillation using realistic speech-only data. Our proposed method, Leave No Knowledge Behind During Knowledge Distillation (K$^2$D), leverages both the teacher model's knowledge and additional insights from a small auxiliary model. We evaluate our approach on two in-domain and two out-domain datasets, demonstrating that K$^2$D is effective. By conducting K$^2$D on the unlabeled realistic data, we have successfully obtained a 2-time smaller model with 5-time faster generation speed while outperforming the baseline methods and the teacher model on all the testing sets. We have made our model publicly available on Hugging Face (https://huggingface.co/andybi7676/k2d-whisper.zh-en).",
    "pdf_link": "https://arxiv.org/abs/2407.10603",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10603v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10603/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10603v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10603/x2.png"
      }
    ],
    "abstract_cn": "在自动语音识别领域，尽管大型模型能生成高质量转录，但计算资源的限制使其在实际应用中受阻，尤其是在复杂的代码转换 ASR 场景中。为此，我们创新性地提出了一个通过真实语音数据进行知识蒸馏的框架，旨在打造更高效的 CS-ASR 模型。我们的 K$^2$D 方法不仅汲取教师模型的智慧，还融合了小型辅助模型的独特见解。实验证明，K$^2$D 在多个数据集上表现卓越，通过处理未标记的真实数据，我们成功开发出一个体积减半、速度提升五倍的模型，其性能在所有测试中均超越了传统方法和教师模型。这一成果已在 Hugging Face 平台公开分享，供业界共享 (https://huggingface.co/andybi7676/k2d-whisper.zh-en)。",
    "title_cn": "知识蒸馏不留遗珠：利用真实数据提升代码转换ASR的实用与效能",
    "tags": [
      "LLM应用",
      "语音识别",
      "软件开发"
    ]
  },
  {
    "title": "Boosting Zero-Shot Crosslingual Performance using LLM-Based Augmentations with Effective Data Selection",
    "submit_datetime": "2024年07月15日",
    "abstract": "Large language models (LLMs) are very proficient text generators. We leverage this capability of LLMs to generate task-specific data via zero-shot prompting and promote cross-lingual transfer for low-resource target languages. Given task-specific data in a source language and a teacher model trained on this data, we propose using this teacher to label LLM generations and employ a set of simple data selection strategies that use the teacher's label probabilities. Our data selection strategies help us identify a representative subset of diverse generations that help boost zero-shot accuracies while being efficient, in comparison to using all the LLM generations (without any subset selection). We also highlight other important design choices that affect cross-lingual performance such as the use of translations of source data and what labels are best to use for the LLM generations. We observe significant performance gains across sentiment analysis and natural language inference tasks (of up to a maximum of 7.13 absolute points and 1.5 absolute points on average) across a number of target languages (Hindi, Marathi, Urdu, Swahili) and domains.",
    "pdf_link": "https://arxiv.org/abs/2407.10582",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10582v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10582/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10582v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10582/diversity_scores.png"
      }
    ],
    "abstract_cn": "大型语言模型 (LLM) 擅长文本生成。我们利用这一特点，通过零-shot 提示为低资源目标语言生成特定任务数据，并促进跨语言转移。我们提出使用在源语言数据上训练的教师模型来标记 LLM 生成的内容，并采用基于教师标签概率的简单数据选择策略。这些策略帮助我们高效地筛选出多样且具代表性的生成内容子集，从而提升零-shot 准确性。此外，我们还探讨了影响跨语言性能的关键设计选择，如源数据翻译的使用和最佳标签选择。实验显示，在多种目标语言和领域中，情感分析与自然语言推理任务的性能显著提升，最高可达 7.13 绝对点，平均提升 1.5 绝对点。",
    "title_cn": "通过基于LLM的增强和精准数据选择，提升零-shot跨语言性能",
    "tags": [
      "LLM应用",
      "",
      "跨语言学习"
    ]
  },
  {
    "title": "Beyond Generative Artificial Intelligence: Roadmap for Natural Language Generation",
    "submit_datetime": "2024年07月15日",
    "abstract": "Generative Artificial Intelligence has grown exponentially as a result of Large Language Models (LLMs). This has been possible because of the impressive performance of deep learning methods created within the field of Natural Language Processing (NLP) and its subfield Natural Language Generation (NLG), which is the focus of this paper. Within the growing LLM family are the popular GPT-4, Bard and more specifically, tools such as ChatGPT have become a benchmark for other LLMs when solving most of the tasks involved in NLG research. This scenario poses new questions about the next steps for NLG and how the field can adapt and evolve to deal with new challenges in the era of LLMs. To address this, the present paper conducts a review of a representative sample of surveys recently published in NLG. By doing so, we aim to provide the scientific community with a research roadmap to identify which NLG aspects are still not suitably addressed by LLMs, as well as suggest future lines of research that should be addressed going forward.",
    "pdf_link": "https://arxiv.org/abs/2407.10554",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10554v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10554/denada.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10554v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10554/hallu_multimodal-min.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10554v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10554/hallu_multilingual-min.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10554v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10554/hallu_knowledge-min.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10554v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10554/hallu_controllable-min.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10554v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10554/hallu_hallucination-min.png"
      }
    ],
    "abstract_cn": "随着大型语言模型（LLMs）的迅猛发展，生成式人工智能正经历着指数级的增长。这得益于自然语言处理（NLP）及其子领域自然语言生成（NLG）中深度学习方法的卓越表现，这也是本文的核心议题。在众多LLM中，GPT-4、Bard及ChatGPT等工具已成为NLG任务的标杆。面对这一新局面，我们不禁思考：NLG将何去何从？如何适应并进化以迎接LLM时代的新挑战？为此，本文深入回顾了NLG领域近期的一系列重要调查，旨在为科学界绘制一张研究蓝图，揭示LLMs尚未充分应对的NLG领域问题，并指明未来研究的方向。",
    "title_cn": "探索生成式AI之外：绘制自然语言生成的未来蓝图",
    "tags": [
      "LLM理论",
      "人工智能",
      ""
    ]
  },
  {
    "title": "TCM-FTP: Fine-Tuning Large Language Models for Herbal Prescription Prediction",
    "submit_datetime": "2024年07月15日",
    "abstract": "Traditional Chinese medicine (TCM) relies on specific combinations of herbs in prescriptions to treat symptoms and signs, a practice that spans thousands of years. Predicting TCM prescriptions presents a fascinating technical challenge with practical implications. However, this task faces limitations due to the scarcity of high-quality clinical datasets and the intricate relationship between symptoms and herbs. To address these issues, we introduce DigestDS, a new dataset containing practical medical records from experienced experts in digestive system diseases. We also propose a method, TCM-FTP (TCM Fine-Tuning Pre-trained), to leverage pre-trained large language models (LLMs) through supervised fine-tuning on DigestDS. Additionally, we enhance computational efficiency using a low-rank adaptation technique. TCM-FTP also incorporates data augmentation by permuting herbs within prescriptions, capitalizing on their order-agnostic properties. Impressively, TCM-FTP achieves an F1-score of 0.8031, surpassing previous methods significantly. Furthermore, it demonstrates remarkable accuracy in dosage prediction, achieving a normalized mean square error of 0.0604. In contrast, LLMs without fine-tuning perform poorly. Although LLMs have shown capabilities on a wide range of tasks, this work illustrates the importance of fine-tuning for TCM prescription prediction, and we have proposed an effective way to do that.",
    "pdf_link": "https://arxiv.org/abs/2407.10510",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10510v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10510/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10510v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10510/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10510v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10510/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10510v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10510/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10510v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10510/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10510v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10510/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10510v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10510/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10510v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10510/fig5-doctor-cases.png"
      }
    ],
    "abstract_cn": "传统中医（TCM）通过特定草药组合治疗症状，这一实践历史悠久。预测TCM处方是一个引人入胜的技术挑战，但受限于高质量数据集的稀缺和症状与草药关系的复杂性。为此，我们推出了DigestDS数据集，包含消化系统疾病专家的实际医疗记录。同时，我们提出了TCM-FTP方法，通过在DigestDS上监督微调预训练的大型语言模型（LLMs），并采用低秩适应技术提升计算效率。TCM-FTP还通过无序排列草药进行数据增强，实现了0.8031的F1分数，显著优于以往方法，并在剂量预测上达到0.0604的归一化均方误差。这项工作强调了微调在TCM处方预测中的重要性，并提出了一种有效途径。",
    "title_cn": "TCM-FTP：专为草药处方预测而设计的大型语言模型微调方案",
    "tags": [
      "LLM应用",
      "",
      "中医药"
    ]
  },
  {
    "title": "Learning Dynamics of LLM Finetuning",
    "submit_datetime": "2024年07月15日",
    "abstract": "Learning dynamics, which describes how the learning of specific training examples influences the model's prediction of other examples, give us a powerful tool for understanding the behavior of deep learning systems. We study the learning dynamics of large language models during finetuning, by analyzing the step-wise decomposition and accumulated influence among different responses. Our framework allows a uniform interpretation of many interesting observations about the training of popular algorithms for both instruction tuning and preference tuning. The analysis not only explains where the benefits of these methods come from but also inspires a simple, effective method to further improve the alignment performance. Code for experiments is available at https://github.com/Joshua-Ren/Learning_dynamics_LLM.",
    "pdf_link": "https://arxiv.org/abs/2407.10490",
    "graphs": [],
    "abstract_cn": "学习动态揭示了特定训练样本如何影响模型对其他样本的预测，是理解深度学习系统的关键。我们通过分析微调过程中不同响应间的逐步分解和累积影响，深入探讨了大型语言模型的学习动态。这一框架为指令调整和偏好调整算法的训练提供了统一解释，不仅阐明了这些方法的优势来源，还启发了一种简单高效的方法来进一步提升对齐性能。实验代码已公开在 https://github.com/Joshua-Ren/Learning_dynamics_LLM。",
    "title_cn": "LLM 微调的学习机制",
    "tags": [
      "LLM理论",
      "人工智能",
      ""
    ]
  },
  {
    "title": "IDEAL: Leveraging Infinite and Dynamic Characterizations of Large Language Models for Query-focused Summarization",
    "submit_datetime": "2024年07月15日",
    "abstract": "Query-focused summarization (QFS) aims to produce summaries that answer particular questions of interest, enabling greater user control and personalization. With the advent of large language models (LLMs), shows their impressive capability of textual understanding through large-scale pretraining, which implies the great potential of extractive snippet generation. In this paper, we systematically investigated two indispensable characteristics that the LLMs-based QFS models should be harnessed, Lengthy Document Summarization and Efficiently Fine-grained Query-LLM Alignment, respectively. Correspondingly, we propose two modules called Query-aware HyperExpert and Query-focused Infini-attention to access the aforementioned characteristics. These innovations pave the way for broader application and accessibility in the field of QFS technology. Extensive experiments conducted on existing QFS benchmarks indicate the effectiveness and generalizability of the proposed approach. Our code is publicly available at https://github.com/DCDmllm/IDEAL_Summary.",
    "pdf_link": "https://arxiv.org/abs/2407.10486",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10486v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10486/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10486v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10486/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10486v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10486/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10486v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10486/x4.png"
      }
    ],
    "abstract_cn": "查询聚焦摘要（QFS）旨在生成针对特定问题的摘要，增强用户控制和个性化。随着大型语言模型（LLM）的兴起，其通过大规模预训练展现的文本理解能力，为提取片段生成带来了巨大潜力。本文深入探讨了基于LLM的QFS模型应具备的两个核心特性：长文档摘要和高效细粒度查询对齐。为此，我们创新性地提出了查询感知超专家和查询聚焦无限注意力两个模块，以实现这些特性。这些创新不仅拓宽了QFS技术的应用范围，还提升了其可访问性。在现有QFS基准上的广泛实验验证了我们所提方法的有效性和通用性。相关代码已公开于https://github.com/DCDmllm/IDEAL_Summary。",
    "title_cn": "IDEAL 技术：借助 LLM 的无限与动态特性，优化查询聚焦摘要效果",
    "tags": [
      "LLM应用",
      "信息技术",
      ""
    ]
  },
  {
    "title": "SuperPADL: Scaling Language-Directed Physics-Based Control with Progressive Supervised Distillation",
    "submit_datetime": "2024年07月15日",
    "abstract": "Physically-simulated models for human motion can generate high-quality responsive character animations, often in real-time. Natural language serves as a flexible interface for controlling these models, allowing expert and non-expert users to quickly create and edit their animations. Many recent physics-based animation methods, including those that use text interfaces, train control policies using reinforcement learning (RL). However, scaling these methods beyond several hundred motions has remained challenging. Meanwhile, kinematic animation models are able to successfully learn from thousands of diverse motions by leveraging supervised learning methods. Inspired by these successes, in this work we introduce SuperPADL, a scalable framework for physics-based text-to-motion that leverages both RL and supervised learning to train controllers on thousands of diverse motion clips. SuperPADL is trained in stages using progressive distillation, starting with a large number of specialized experts using RL. These experts are then iteratively distilled into larger, more robust policies using a combination of reinforcement learning and supervised learning. Our final SuperPADL controller is trained on a dataset containing over 5000 skills and runs in real time on a consumer GPU. Moreover, our policy can naturally transition between skills, allowing for users to interactively craft multi-stage animations. We experimentally demonstrate that SuperPADL significantly outperforms RL-based baselines at this large data scale.",
    "pdf_link": "https://arxiv.org/abs/2407.10481",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10481v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10481/teaser.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10481v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10481/superpadl-overview.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10481v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10481/superpadl-track.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10481v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10481/superpadl-group.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10481v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10481/superpadl-global.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10481v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10481/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10481v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10481/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10481v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10481/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10481v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10481/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10481v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10481/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10481v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10481/filmstrip_0010.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10481v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10481/filmstrip_0019.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10481v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10481/filmstrip_0003.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10481v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10481/filmstrip_0044.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10481v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10481/filmstrip_0014.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10481v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10481/filmstrip_0017.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10481v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10481/filmstrip_0045.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10481v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10481/filmstrip_0052.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10481v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10481/filmstrip_0025.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10481v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10481/filmstrip_transition_004.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10481v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10481/filmstrip_transition_003.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10481v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10481/filmstrip_transition_005.png"
      }
    ],
    "abstract_cn": "我们开发的SuperPADL框架，结合了强化学习和监督学习，能够从数千个多样化的动作片段中训练出高效的控制器，实现基于物理模拟的高质量实时角色动画。这一框架通过渐进式蒸馏技术，从专门专家的RL训练开始，逐步提升策略的稳健性和规模，最终在包含5000多个技能的数据集上训练出能够在消费级GPU上实时运行的控制器。SuperPADL不仅支持技能间的自然过渡，还允许用户交互式地创作复杂的多阶段动画，显著提升了在大数据规模下的动画生成性能。",
    "title_cn": "SuperPADL：利用渐进式监督蒸馏技术，扩展语言指导的物理基础控制能力",
    "tags": [
      "Agent",
      "",
      ""
    ]
  },
  {
    "title": "The Good, The Bad, and The Greedy: Evaluation of LLMs Should Not Ignore Non-Determinism",
    "submit_datetime": "2024年07月15日",
    "abstract": "Current evaluations of large language models (LLMs) often overlook non-determinism, typically focusing on a single output per example. This limits our understanding of LLM performance variability in real-world applications. Our study addresses this issue by exploring key questions about the performance differences between greedy decoding and sampling, identifying benchmarks' consistency regarding non-determinism, and examining unique model behaviors. Through extensive experiments, we observe that greedy decoding generally outperforms sampling methods for most evaluated tasks. We also observe consistent performance across different LLM sizes and alignment methods, noting that alignment can reduce sampling variance. Moreover, our best-of-N sampling approach demonstrates that smaller LLMs can match or surpass larger models such as GPT-4-Turbo, highlighting the untapped potential of smaller LLMs. This research shows the importance of considering non-determinism in LLM evaluations and provides insights for future LLM development and evaluation.",
    "pdf_link": "https://arxiv.org/abs/2407.10457",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10457v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10457/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10457v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10457/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10457v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10457/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10457v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10457/x4.png"
      }
    ],
    "abstract_cn": "当前 LLM 评估常忽略非确定性，仅关注单一输出，限制了对其在实际应用中性能变异的理解。我们的研究深入探讨了贪婪解码与采样间的性能差异，并检查了模型行为的独特性。实验显示，贪婪解码在多数任务中表现更佳，且不同大小和方法的 LLM 性能稳定。特别地，最佳 N 采样法揭示了小 LLM 能匹敌甚至超越大型模型，如 GPT-4-Turbo，凸显其潜力。此研究强调了在 LLM 评估中考虑非确定性的重要性，并为未来发展提供了洞见。",
    "title_cn": "在评估 LLMs 时，我们不应忽视非确定性，它如同“好的、坏的和贪婪的”三重奏，影响着模型的表现。",
    "tags": [
      "LLM理论",
      "人工智能",
      "机器学习"
    ]
  },
  {
    "title": "Enhancing Medication Recommendation with LLM Text Representation",
    "submit_datetime": "2024年07月15日",
    "abstract": "Most of the existing medication recommendation models are predicted with only structured data such as medical codes, with the remaining other large amount of unstructured or semi-structured data underutilization. To increase the utilization effectively, we proposed a method of enhancing medication recommendation with Large Language Model (LLM) text representation. LLM harnesses powerful language understanding and generation capabilities, enabling the extraction of information from complex and lengthy unstructured data such as clinical notes which contain complex terminology. This method can be applied to several existing base models we selected and improve medication recommendation performance with the combination representation of text and medical codes experiments on two different datasets. LLM text representation alone can even demonstrate a comparable ability to the medical code representation alone. Overall, this is a general method that can be applied to other models for improved recommendations.",
    "pdf_link": "https://arxiv.org/abs/2407.10453",
    "graphs": [],
    "abstract_cn": "当前药物推荐模型多依赖结构化数据，如医疗代码，而大量非结构化或半结构化数据未被充分利用。为此，我们提出了一种基于大型语言模型（LLM）的文本表示方法，以增强药物推荐。LLM凭借其强大的语言理解和生成能力，能从复杂的非结构化数据中提取关键信息，如临床笔记中的专业术语。此方法不仅适用于多个现有模型，还能通过结合文本与医疗代码的表示，在不同数据集上显著提升推荐效果。更重要的是，LLM的文本表示能力与传统的医疗代码表示不相上下。这表明，该方法具有广泛的适用性，能为其他模型提供更精准的推荐支持。",
    "title_cn": "利用 LLM 文本表示提升药物推荐效果",
    "tags": [
      "LLM应用",
      "",
      "药物推荐"
    ]
  },
  {
    "title": "Tensor clustering fossils in modified gravity and high-redshift gravitational-wave sound speed",
    "submit_datetime": "2024年07月15日",
    "abstract": "We investigate the tensor clustering fossils as a possible probe to constrain the theory of gravity, in particular the deviation of the sound speed of gravitational waves from the speed of light at high redshifts. We develop the formalism of the effective Poisson equation to include the novel phenomenological model of the scalar-tensor tidal interactions that are expected to be induced by the modification of the theory of gravity. We show that the tensor clustering fossils can arise from the propagation of gravitational waves, the growth of the large-scale structures, and the second-order contributions from the effective Poisson equation. We construct the small-scale effective Lagrangian from the Horndeski scalar-tensor theory and derive the formula applicable to the tensor clustering fossils in the language of the effective field theory of dark energy. As a demonstration, we apply the formalism to the constraint on the sound speed of gravitational waves in the futuristic survey.",
    "pdf_link": "https://arxiv.org/abs/2407.10450",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10450v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10450/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10450v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10450/x2.png"
      }
    ],
    "abstract_cn": "我们探索张量聚类化石作为约束引力理论的潜在工具，特别是在高红移处引力波声速与光速的差异。通过引入标量-张量潮汐相互作用的新模型，我们改进了有效泊松方程。研究表明，这些化石源自引力波传播、大尺度结构增长及有效泊松方程的二阶效应。基于霍恩德斯基理论，我们构建了小尺度有效拉格朗日量，并推导出适用于暗能量有效场论的张量聚类化石公式。作为示例，我们将其应用于未来调查中对引力波声速的限制。",
    "title_cn": "修正重力与高红移引力波声速下的张量聚类化石研究",
    "tags": [
      "LLM理论",
      "天文学",
      "物理学"
    ]
  },
  {
    "title": "GenSco: Can Question Decomposition based Passage Alignment improve Question Answering?",
    "submit_datetime": "2024年07月14日",
    "abstract": "Retrieval augmented generation (RAG) with large language models (LLMs) for Question Answering (QA) entails furnishing relevant context within the prompt to facilitate the LLM in answer generation. During the generation, inaccuracies or hallucinations frequently occur due to two primary factors: inadequate or distracting context in the prompts, and the inability of LLMs to effectively reason through the facts. In this paper, we investigate whether providing aligned context via a carefully selected passage sequence leads to better answer generation by the LLM for multi-hop QA. We introduce, \"GenSco\", a novel approach of selecting passages based on the predicted decomposition of the multi-hop questions}. The framework consists of two distinct LLMs: (i) Generator LLM, which is used for question decomposition and final answer generation; (ii) an auxiliary open-sourced LLM, used as the scorer, to semantically guide the Generator for passage selection. The generator is invoked only once for the answer generation, resulting in a cost-effective and efficient approach. We evaluate on three broadly established multi-hop question answering datasets: 2WikiMultiHop, Adversarial HotPotQA and MuSiQue and achieve an absolute gain of $15.1$ and $5.9$ points in Exact Match score with respect to the best performing baselines over MuSiQue and 2WikiMultiHop respectively.",
    "pdf_link": "https://arxiv.org/abs/2407.10245",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10245v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10245/tnr-1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10245v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10245/hop_hist.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.10245v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10245/stability_GenSco-stop.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10245v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10245/scatter_plot.jpg"
      }
    ],
    "abstract_cn": "在问答任务中，使用大型语言模型进行检索增强生成时，提供相关上下文至关重要。然而，生成过程中常出现不准确或幻觉，主要原因包括上下文不足或分散注意力，以及模型无法有效推理事实。本文探讨了通过精心选择的段落序列提供对齐上下文是否能提升多跳问答的答案生成质量。我们提出了一种新方法 \"GenSco\"，该方法基于对问题的预测分解来选择段落。框架包含两个LLM：生成器LLM用于问题分解和答案生成，辅助开源LLM作为评分器，指导段落选择。生成器仅调用一次，实现了高效且经济的答案生成。在三个多跳问答数据集上的评估显示，与最佳基线相比，我们在MuSiQue和2WikiMultiHop上分别取得了15.1和5.9点的精确匹配分数提升。",
    "title_cn": "GenSco：问题分解基础上的段落对齐，能否提升问答效果？",
    "tags": [
      "RAG",
      "问答系统",
      "人工智能"
    ]
  },
  {
    "title": "Towards Robust Recommendation via Decision Boundary-aware Graph Contrastive Learning",
    "submit_datetime": "2024年07月14日",
    "abstract": "In recent years, graph contrastive learning (GCL) has received increasing attention in recommender systems due to its effectiveness in reducing bias caused by data sparsity. However, most existing GCL models rely on heuristic approaches and usually assume entity independence when constructing contrastive views. We argue that these methods struggle to strike a balance between semantic invariance and view hardness across the dynamic training process, both of which are critical factors in graph contrastive learning.\n  To address the above issues, we propose a novel GCL-based recommendation framework RGCL, which effectively maintains the semantic invariance of contrastive pairs and dynamically adapts as the model capability evolves through the training process. Specifically, RGCL first introduces decision boundary-aware adversarial perturbations to constrain the exploration space of contrastive augmented views, avoiding the decrease of task-specific information. Furthermore, to incorporate global user-user and item-item collaboration relationships for guiding on the generation of hard contrastive views, we propose an adversarial-contrastive learning objective to construct a relation-aware view-generator. Besides, considering that unsupervised GCL could potentially narrower margins between data points and the decision boundary, resulting in decreased model robustness, we introduce the adversarial examples based on maximum perturbations to achieve margin maximization. We also provide theoretical analyses on the effectiveness of our designs. Through extensive experiments on five public datasets, we demonstrate the superiority of RGCL compared against twelve baseline models.",
    "pdf_link": "https://arxiv.org/abs/2407.10184",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10184v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10184/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10184v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10184/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10184v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10184/converge.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10184v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10184/sparsity.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10184v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10184/hyper.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10184v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10184/eps.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10184v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10184/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10184v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10184/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10184v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10184/x5.png"
      }
    ],
    "abstract_cn": "近年来，图对比学习 (GCL) 在推荐系统中因其有效减少数据稀疏性引起的偏差而受到越来越多的关注。然而，大多数现有的 GCL 模型依赖于启发式方法，并且在构建对比视图时通常假设实体独立性。我们认为这些方法在动态训练过程中难以在语义不变性和视图难度之间取得平衡，这两者都是图对比学习中的关键因素。  为了解决上述问题，我们提出了一种新的基于 GCL 的推荐框架 RGCL，该框架有效地保持了对比对的语义不变性，并随着训练过程中模型能力的演变动态适应。具体来说，RGCL 首先引入决策边界感知的对抗性扰动来约束对比增强视图的探索空间，避免任务特定信息的减少。此外，为了纳入全局用户-用户和项目-项目协作关系以指导硬对比视图的生成，我们提出了一种对抗性对比学习目标来构建关系感知的视图生成器。此外，考虑到无监督 GCL 可能会缩小数据点与决策边界之间的差距，导致模型鲁棒性降低，我们引入了基于最大扰动的对抗性示例来实现边际最大化。我们还对我们的设计效果进行了理论分析。通过在五个公共数据集上进行广泛的实验，我们证明了 RGCL 相对于十二个基线模型的优越性。",
    "title_cn": "本研究旨在通过决策边界感知图对比学习，提升推荐的鲁棒性。",
    "tags": [
      "Agent",
      "推荐系统",
      "人工智能"
    ]
  },
  {
    "title": "LAB-Bench: Measuring Capabilities of Language Models for Biology Research",
    "submit_datetime": "2024年07月14日",
    "abstract": "There is widespread optimism that frontier Large Language Models (LLMs) and LLM-augmented systems have the potential to rapidly accelerate scientific discovery across disciplines. Today, many benchmarks exist to measure LLM knowledge and reasoning on textbook-style science questions, but few if any benchmarks are designed to evaluate language model performance on practical tasks required for scientific research, such as literature search, protocol planning, and data analysis. As a step toward building such benchmarks, we introduce the Language Agent Biology Benchmark (LAB-Bench), a broad dataset of over 2,400 multiple choice questions for evaluating AI systems on a range of practical biology research capabilities, including recall and reasoning over literature, interpretation of figures, access and navigation of databases, and comprehension and manipulation of DNA and protein sequences. Importantly, in contrast to previous scientific benchmarks, we expect that an AI system that can achieve consistently high scores on the more difficult LAB-Bench tasks would serve as a useful assistant for researchers in areas such as literature search and molecular cloning. As an initial assessment of the emergent scientific task capabilities of frontier language models, we measure performance of several against our benchmark and report results compared to human expert biology researchers. We will continue to update and expand LAB-Bench over time, and expect it to serve as a useful tool in the development of automated research systems going forward. A public subset of LAB-Bench is available for use at the following URL: https://huggingface.co/datasets/futurehouse/lab-bench",
    "pdf_link": "https://arxiv.org/abs/2407.10362",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10362v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10362/QuestionExamples.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.10362v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10362/EvalsDiagram-AutoGeneration.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.10362v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10362/EvalsDiagram-ManualGeneration.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.10362v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10362/Barplots_All.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.10362v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10362/SeqQA-Heatmaps.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.10362v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10362/dbQA-Heatmaps.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.10362v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10362/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10362v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10362/Barplots_Public.png"
      }
    ],
    "abstract_cn": "前沿大型语言模型（LLMs）及其增强系统被普遍认为能迅速推动跨学科科学发现。尽管现有众多基准测试LLM在教科书式科学问题上的表现，但针对科学研究实际需求，如文献检索、实验设计及数据分析等任务的评估工具却寥寥无几。为此，我们推出了语言代理生物学基准（LAB-Bench），一个涵盖2,400多道选择题的全面数据集，旨在检验AI在生物学研究中的实际应用能力，包括文献理解、图表解析、数据库操作及DNA与蛋白质序列处理等。与传统科学基准不同，我们期待能在LAB-Bench高难度任务中表现卓越的AI，成为科研人员在文献检索和分子克隆等领域的得力助手。我们已对数个前沿语言模型进行了初步评估，并将其表现与生物学专家进行对比。LAB-Bench将持续更新扩充，有望成为推动自动化科研系统发展的关键工具。LAB-Bench的公共子集已开放使用，详情请访问：https://huggingface.co/datasets/futurehouse/lab-bench。",
    "title_cn": "LAB-Bench：评估语言模型在生物学研究领域的实力",
    "tags": [
      "Agent",
      "生物学",
      ""
    ]
  },
  {
    "title": "All Roads Lead to Rome: Unveiling the Trajectory of Recommender Systems Across the LLM Era",
    "submit_datetime": "2024年07月14日",
    "abstract": "Recommender systems (RS) are vital for managing information overload and delivering personalized content, responding to users' diverse information needs. The emergence of large language models (LLMs) offers a new horizon for redefining recommender systems with vast general knowledge and reasoning capabilities. Standing across this LLM era, we aim to integrate recommender systems into a broader picture, and pave the way for more comprehensive solutions for future research. Therefore, we first offer a comprehensive overview of the technical progression of recommender systems, particularly focusing on language foundation models and their applications in recommendation. We identify two evolution paths of modern recommender systems -- via list-wise recommendation and conversational recommendation. These two paths finally converge at LLM agents with superior capabilities of long-term memory, reflection, and tool intelligence. Along these two paths, we point out that the information effectiveness of the recommendation is increased, while the user's acquisition cost is decreased. Technical features, research methodologies, and inherent challenges for each milestone along the path are carefully investigated -- from traditional list-wise recommendation to LLM-enhanced recommendation to recommendation with LLM agents. Finally, we highlight several unresolved challenges crucial for the development of future personalization technologies and interfaces and discuss the future prospects.",
    "pdf_link": "https://arxiv.org/abs/2407.10081",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10081v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10081/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10081v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10081/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10081v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10081/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10081v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10081/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10081v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10081/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10081v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10081/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10081v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10081/x7.png"
      }
    ],
    "abstract_cn": "推荐系统在应对信息过载和提供个性化内容方面扮演着关键角色。随着大型语言模型的兴起，我们迎来了重新定义推荐系统的新机遇，这些模型拥有丰富的知识和强大的推理能力。我们致力于将推荐系统融入更宏大的研究蓝图，并为未来的研究探索更全面的解决方案。首先，我们详细回顾了推荐系统的技术演进，特别聚焦于语言基础模型在推荐领域的应用。我们识别出两条推荐系统的演进路径：列表式推荐和对话式推荐，这两者最终汇聚于具备高级记忆、反思和工具智能的LLM代理。沿着这两条路径，我们发现推荐的信息效率提升，同时用户的信息获取成本降低。我们对每个发展阶段的技术特点、研究方法和挑战进行了深入分析，从传统列表式推荐到LLM增强推荐，再到LLM代理推荐。最后，我们指出了几个对未来个性化技术发展至关重要的未解难题，并对未来发展进行了展望。",
    "title_cn": "条条大路通罗马：探索推荐系统在大型语言模型时代的发展路径",
    "tags": [
      "Agent",
      "推荐系统",
      "个性化技术"
    ]
  },
  {
    "title": "When Pedestrian Detection Meets Multi-Modal Learning: Generalist Model and Benchmark Dataset",
    "submit_datetime": "2024年07月14日",
    "abstract": "Recent years have witnessed increasing research attention towards pedestrian detection by taking the advantages of different sensor modalities (e.g. RGB, IR, Depth, LiDAR and Event). However, designing a unified generalist model that can effectively process diverse sensor modalities remains a challenge. This paper introduces MMPedestron, a novel generalist model for multimodal perception. Unlike previous specialist models that only process one or a pair of specific modality inputs, MMPedestron is able to process multiple modal inputs and their dynamic combinations. The proposed approach comprises a unified encoder for modal representation and fusion and a general head for pedestrian detection. We introduce two extra learnable tokens, i.e. MAA and MAF, for adaptive multi-modal feature fusion. In addition, we construct the MMPD dataset, the first large-scale benchmark for multi-modal pedestrian detection. This benchmark incorporates existing public datasets and a newly collected dataset called EventPed, covering a wide range of sensor modalities including RGB, IR, Depth, LiDAR, and Event data. With multi-modal joint training, our model achieves state-of-the-art performance on a wide range of pedestrian detection benchmarks, surpassing leading models tailored for specific sensor modality. For example, it achieves 71.1 AP on COCO-Persons and 72.6 AP on LLVIP. Notably, our model achieves comparable performance to the InternImage-H model on CrowdHuman with 30x smaller parameters. Codes and data are available at https://github.com/BubblyYi/MMPedestron.",
    "pdf_link": "https://arxiv.org/abs/2407.10125",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10125v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10125/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10125v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10125/unimodal.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10125v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10125/dataset.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10125v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10125/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10125v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10125/analysis1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10125v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10125/EventPed_dist.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10125v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10125/distribution.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10125v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10125/fusion_all_p1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10125v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10125/fusion_p2_new.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10125v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10125/rgb_all_p2_new.png"
      }
    ],
    "abstract_cn": "近年来，行人检测领域借助RGB、IR、深度、LiDAR和事件等多种传感器模态的研究日益增多。然而，构建一个能有效处理这些多样模态的统一模型仍具挑战。本文提出的MMPedestron模型，不同于以往专注于单一或成对模态的专家模型，能处理多模态输入及其动态组合。该模型包含一个统一的模态表示与融合编码器和一个通用的行人检测头部，并引入了MAA和MAF两个可学习令牌以实现自适应多模态特征融合。此外，我们创建了首个多模态行人检测的大规模基准MMPD数据集，涵盖RGB、IR、深度、LiDAR和事件等多种模态。通过多模态联合训练，MMPedestron在多个行人检测基准上表现卓越，超越了针对特定模态的顶尖模型，如在COCO-Persons和LLVIP上分别达到71.1 AP和72.6 AP。特别地，在CrowdHuman数据集上，MMPedestron以仅30分之一的参数量，与InternImage-H模型性能相当。相关代码和数据已公开于https://github.com/BubblyYi/MMPedestron。",
    "title_cn": "行人检测与多模态学习的结合，催生了通才模型与基准数据集的诞生。",
    "tags": [
      "LLM应用",
      "",
      ""
    ]
  },
  {
    "title": "Affordance-Guided Reinforcement Learning via Visual Prompting",
    "submit_datetime": "2024年07月14日",
    "abstract": "Robots equipped with reinforcement learning (RL) have the potential to learn a wide range of skills solely from a reward signal. However, obtaining a robust and dense reward signal for general manipulation tasks remains a challenge. Existing learning-based approaches require significant data, such as demonstrations or examples of success and failure, to learn task-specific reward functions. Recently, there is also a growing adoption of large multi-modal foundation models for robotics. These models can perform visual reasoning in physical contexts and generate coarse robot motions for various manipulation tasks. Motivated by this range of capability, in this work, we propose and study rewards shaped by vision-language models (VLMs). State-of-the-art VLMs have demonstrated an impressive ability to reason about affordances through keypoints in zero-shot, and we leverage this to define dense rewards for robotic learning. On a real-world manipulation task specified by natural language description, we find that these rewards improve the sample efficiency of autonomous RL and enable successful completion of the task in 20K online finetuning steps. Additionally, we demonstrate the robustness of the approach to reductions in the number of in-domain demonstrations used for pretraining, reaching comparable performance in 35K online finetuning steps.",
    "pdf_link": "https://arxiv.org/abs/2407.10341",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10341v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10341/tabletop_top_keystartpts_gridlabel.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.10341v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10341/tabletop_side_linelabel.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.10341v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10341/closest_block.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10341v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10341/method.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10341v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10341/folding_forward.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10341v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10341/folding_backward.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10341v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10341/covering_forward.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10341v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10341/covering_backward.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10341v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10341/spatula_forward.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10341v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10341/spatula_backward.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10341v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10341/finetuning_sparse.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10341v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10341/finetuning_dense.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10341v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10341/same_demos_sparse.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10341v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10341/same_demos_dense.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10341v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10341/fewer_demos_sparse.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10341v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10341/fewer_demos_dense.png"
      }
    ],
    "abstract_cn": "配备强化学习的机器人能够仅通过奖励信号学习多种技能，但为通用操作任务获取稳定且丰富的奖励信号仍具挑战。现有学习方法依赖大量数据，如成功与失败的示范，以构建特定任务的奖励函数。近期，大型多模态基础模型在机器人领域的应用日益增多，这些模型能进行物理环境下的视觉推理，并生成各类操作任务的初步机器人动作。受此启发，我们探索了视觉-语言模型（VLM）塑造的奖励机制。顶尖的VLM在零-shot环境下通过关键点进行affordances推理的能力突出，我们借此为机器人学习设计密集奖励。在自然语言描述的实际操作任务中，这些奖励显著提升了自主强化学习的效率，使任务在2万次在线微调中顺利完成。同时，该方法对预训练中示范数量的减少表现出强健性，在3.5万次在线微调中保持同等性能。",
    "title_cn": "视觉提示引导的强化学习",
    "tags": [
      "Agent",
      "机器人",
      "人工智能"
    ]
  },
  {
    "title": "AI Detectors are Poor Western Blot Classifiers: A Study of Accuracy and Predictive Values",
    "submit_datetime": "2024年07月14日",
    "abstract": "The recent rise of generative artificial intelligence (GenAI) capable of creating scientific images presents a challenge in the fight against academic fraud. This study evaluates the efficacy of three free web-based AI detectors in identifying AI-generated images of Western blots, which is a very common technique in biology. We tested these detectors on a collection of artificial Western blot images (n=48) that were created using ChatGPT 4 DALLE 3 and on authentic Western blots (n=48) that were sampled from articles published within four biology journals in 2015; this was before the rise of generative AI based on large language models. The results reveal that the sensitivity (0.9583 for Is It AI, 0.1875 for Hive Moderation, and 0.7083 for Illuminarty) and specificity (0.5417 for Is It AI, 0.8750 for Hive Moderation, and 0.4167 for Illuminarty) are very different. Positive predictive values (PPV) across various AI prevalence were low, for example reaching 0.1885 for Is It AI, 0.1429 for Hive Moderation, and 0.1189 for Illuminarty at an AI prevalence of 0.1. This highlights the difficulty in confidently determining image authenticity based on the output of a single detector. Reducing the size of Western blots from four to two lanes reduced test sensitivities and increased test specificities but did not markedly affect overall detector accuracies and also only slightly improved the PPV of one detector (Is It AI). These findings strongly argue against the use of free AI detectors to detect fake scientific images, and they demonstrate the urgent need for more robust detection tools that are specifically trained on scientific content such as Western blot images.",
    "pdf_link": "https://arxiv.org/abs/2407.10308",
    "graphs": [],
    "abstract_cn": "生成式人工智能（GenAI）的兴起为学术诚信带来了新挑战。本研究测试了三种免费网络AI检测器在识别AI生成的Western blot图像上的效果。结果显示，这些检测器的敏感性和特异性差异显著，且阳性预测值普遍较低。减少Western blot的条带数虽调整了敏感性和特异性，但并未大幅提升整体准确性。这表明，当前的免费AI检测器不足以有效识别伪造的科学图像，迫切需要更专业的工具来应对这一挑战。",
    "title_cn": "AI检测器在西方墨点分类中的表现不尽如人意，本研究探讨了其准确性与预测值的问题。",
    "tags": [
      "LLM应用",
      "学术诚信",
      "科学研究"
    ]
  },
  {
    "title": "Follow the Rules: Reasoning for Video Anomaly Detection with Large Language Models",
    "submit_datetime": "2024年07月14日",
    "abstract": "Video Anomaly Detection (VAD) is crucial for applications such as security surveillance and autonomous driving. However, existing VAD methods provide little rationale behind detection, hindering public trust in real-world deployments. In this paper, we approach VAD with a reasoning framework. Although Large Language Models (LLMs) have shown revolutionary reasoning ability, we find that their direct use falls short of VAD. Specifically, the implicit knowledge pre-trained in LLMs focuses on general context and thus may not apply to every specific real-world VAD scenario, leading to inflexibility and inaccuracy. To address this, we propose AnomalyRuler, a novel rule-based reasoning framework for VAD with LLMs. AnomalyRuler comprises two main stages: induction and deduction. In the induction stage, the LLM is fed with few-shot normal reference samples and then summarizes these normal patterns to induce a set of rules for detecting anomalies. The deduction stage follows the induced rules to spot anomalous frames in test videos. Additionally, we design rule aggregation, perception smoothing, and robust reasoning strategies to further enhance AnomalyRuler's robustness. AnomalyRuler is the first reasoning approach for the one-class VAD task, which requires only few-normal-shot prompting without the need for full-shot training, thereby enabling fast adaption to various VAD scenarios. Comprehensive experiments across four VAD benchmarks demonstrate AnomalyRuler's state-of-the-art detection performance and reasoning ability.",
    "pdf_link": "https://arxiv.org/abs/2407.10299",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10299v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10299/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10299v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10299/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10299v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10299/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10299v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10299/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10299v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10299/x5.png"
      }
    ],
    "abstract_cn": "视频异常检测 (VAD) 对安全监控和自动驾驶等应用至关重要，但现有方法在解释检测结果方面存在不足，影响了公众信任。本文采用推理框架处理 VAD，尽管大型语言模型 (LLM) 推理能力强大，但其直接应用于 VAD 效果不佳，因其预训练知识侧重通用上下文，难以适应具体场景。为此，我们提出 AnomalyRuler，一个基于规则的推理框架，结合 LLM 进行 VAD。该框架包括归纳和演绎两个阶段：首先，LLM 通过少量正常样本归纳出检测规则；随后，根据这些规则在测试视频中识别异常帧。此外，通过规则聚合、感知平滑和鲁棒推理策略，进一步提升了 AnomalyRuler 的鲁棒性。作为首个针对单类 VAD 任务的推理方法，AnomalyRuler 仅需少量正常样本提示，无需完整训练，能快速适应不同场景。实验证明，AnomalyRuler 在多个 VAD 基准上表现卓越，兼具高检测性能和强推理能力。",
    "title_cn": "遵循规则：运用大型语言模型进行视频异常检测的推理方法",
    "tags": [
      "LLM应用",
      "安全监控",
      "自动驾驶"
    ]
  },
  {
    "title": "Cross-Lingual Multi-Hop Knowledge Editing - Benchmarks, Analysis and a Simple Contrastive Learning based Approach",
    "submit_datetime": "2024年07月14日",
    "abstract": "Large language models are often expected to constantly adapt to new sources of knowledge and knowledge editing techniques aim to efficiently patch the outdated model knowledge, with minimal modification. Most prior works focus on monolingual knowledge editing in English, even though new information can emerge in any language from any part of the world. We propose the Cross-Lingual Multi-Hop Knowledge Editing paradigm, for measuring and analyzing the performance of various SoTA knowledge editing techniques in a cross-lingual setup. Specifically, we create a parallel cross-lingual benchmark, CROLIN-MQUAKE for measuring the knowledge editing capabilities. Our extensive analysis over various knowledge editing techniques uncover significant gaps in performance between the cross-lingual and English-centric setting. Following this, we propose a significantly improved system for cross-lingual multi-hop knowledge editing, CLEVER-CKE. CLEVER-CKE is based on a retrieve, verify and generate knowledge editing framework, where a retriever is formulated to recall edited facts and support an LLM to adhere to knowledge edits. We develop language-aware and hard-negative based contrastive objectives for improving the cross-lingual and fine-grained fact retrieval and verification process used in this framework. Extensive experiments on three LLMs, eight languages, and two datasets show CLEVER-CKE's significant gains of up to 30% over prior methods.",
    "pdf_link": "https://arxiv.org/abs/2407.10275",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10275v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10275/clever_intro.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10275v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10275/mello_pokemqa_cf.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10275v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10275/clever_cke.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10275v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10275/ablation234hop_average.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10275v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10275/biling_multiling_pokemqa_ours.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10275v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10275/ablation234hop.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10275v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10275/error_types.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10275v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10275/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10275v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10275/llama_acc_pokemqa.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10275v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10275/chatgpt_acc_pokemqa.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10275v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10275/llama_acc_ours.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10275v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10275/chatgpt_acc_ours.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10275v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10275/llama_hopacc_pokemqa.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10275v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10275/chatgpt_hopacc_pokemqa.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10275v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10275/llama_hopacc_ours.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10275v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10275/chatgpt_hopacc_ours.png"
      }
    ],
    "abstract_cn": "大型语言模型需不断适应新知识，而知识编辑技术旨在通过最小改动高效更新模型知识。尽管新信息可能来自全球任何语言，但多数研究仍聚焦于英语单语知识编辑。为此，我们提出跨语言多跳知识编辑范式，创建了CROLIN-MQUAKE基准，以评估跨语言环境下知识编辑技术的性能。分析显示，跨语言与英语中心设置间存在显著性能差距。基于此，我们开发了CLEVER-CKE系统，采用检索、验证、生成框架，通过语言感知和硬负例对比目标，显著提升了跨语言和细粒度事实检索验证过程。实验表明，CLEVER-CKE在多个LLM、语言和数据集上，性能提升高达30%。",
    "title_cn": "跨语言多跳知识编辑：基准测试、深入分析与基于对比学习的简易方法",
    "tags": [
      "LLM应用",
      "人工智能",
      "语言技术"
    ]
  },
  {
    "title": "Nonlinear Two-Track Model of a Semitrailer with Experimental Validation of Lateral and Vertical Tire Forces",
    "submit_datetime": "2024年07月14日",
    "abstract": "As part of the automation of commercial vehicles, the number of assistance systems in this field is continuously increasing. The semitrailer plays an important role for the vehicles driving dynamics due to its highly varying loads and the large proportion to the total mass of the truck-semitrailer, especially when it is fully loaded. To create a basis for further development of assistance systems for the semitrailer, this paper presents a two-track model which includes the lateral and roll dynamics of the semitrailer. This enables the future development of observer and filter-based estimation of vehicle states and parameters, which are impossible or very difficult to measure. For offline identification of the unknown model parameters, a Particle-Swarm-Optimization (PSO) algorithm will be used. The validation of the model is based on measurements from a test vehicle. The focus is on the lateral and vertical tire forces of the semitrailer, which are measured at the test vehicle using strain gauges.",
    "pdf_link": "https://arxiv.org/abs/2407.10270",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10270v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10270/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10270v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10270/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10270v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10270/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10270v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10270/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10270v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10270/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10270v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10270/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10270v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10270/x7.png"
      }
    ],
    "abstract_cn": "随着商用车自动化的发展，辅助系统日益增多。半挂车因其载荷多变且在总质量中占比大，在满载时对行驶动力学影响显著。本文提出一种双轨模型，涵盖半挂车的横向与翻滚动力学，为未来开发难以测量的车辆状态与参数估计技术奠定基础。我们采用粒子群优化算法进行模型参数的离线识别，并通过测试车辆的实测数据验证模型，重点关注半挂车的轮胎横向与垂直力。",
    "title_cn": "半挂车的非线性双轨模型，经实验证实其横向与垂直轮胎力的有效性",
    "tags": [
      "Agent",
      "",
      ""
    ]
  },
  {
    "title": "What Makes and Breaks Safety Fine-tuning? Mechanistic Study",
    "submit_datetime": "2024年07月14日",
    "abstract": "Safety fine-tuning helps align Large Language Models (LLMs) with human preferences for their safe deployment. To better understand the underlying factors that make models safe via safety fine-tuning, we design a synthetic data generation framework that captures salient aspects of an unsafe input by modeling the interaction between the task the model is asked to perform (e.g., ``design'') versus the specific concepts the task is asked to be performed upon (e.g., a ``cycle'' vs. a ``bomb''). Using this, we investigate three well-known safety fine-tuning methods -- supervised safety fine-tuning, direct preference optimization, and unlearning -- and provide significant evidence demonstrating that these methods minimally transform MLP weights to specifically align unsafe inputs into its weights' null space. This yields a clustering of inputs based on whether the model deems them safe or not. Correspondingly, when an adversarial input (e.g., a jailbreak) is provided, its activations are closer to safer samples, leading to the model processing such an input as if it were safe. We validate our findings, wherever possible, on real-world models -- specifically, Llama-2 7B and Llama-3 8B.",
    "pdf_link": "https://arxiv.org/abs/2407.10264",
    "graphs": [],
    "abstract_cn": "安全微调有助于确保大型语言模型 (LLM) 符合人类对其安全部署的期望。为深入探究安全微调背后的关键因素，我们构建了一个合成数据生成框架，通过模拟模型执行任务与其具体应用概念间的互动，精准捕捉不安全输入的特征。我们深入分析了三种主流安全微调技术——监督微调、偏好优化及遗忘策略，并发现这些方法通过微调 MLP 权重，巧妙地将潜在风险输入转化为安全模式，实现输入安全性的智能聚类。面对对抗性输入时，模型能将其激活状态调整至接近安全样本，从而确保其处理过程的安全性。我们在真实模型 Llama-2 7B 和 Llama-3 8B 上验证了这些发现，展现了安全微调的实际应用价值。",
    "title_cn": "安全微调的成与败：机制探究",
    "tags": [
      "LLM理论",
      "人工智能",
      "网络安全"
    ]
  },
  {
    "title": "BiasAlert: A Plug-and-play Tool for Social Bias Detection in LLMs",
    "submit_datetime": "2024年07月14日",
    "abstract": "Evaluating the bias in Large Language Models (LLMs) becomes increasingly crucial with their rapid development. However, existing evaluation methods rely on fixed-form outputs and cannot adapt to the flexible open-text generation scenarios of LLMs (e.g., sentence completion and question answering). To address this, we introduce BiasAlert, a plug-and-play tool designed to detect social bias in open-text generations of LLMs. BiasAlert integrates external human knowledge with inherent reasoning capabilities to detect bias reliably. Extensive experiments demonstrate that BiasAlert significantly outperforms existing state-of-the-art methods like GPT4-as-A-Judge in detecting bias. Furthermore, through application studies, we demonstrate the utility of BiasAlert in reliable LLM bias evaluation and bias mitigation across various scenarios. Model and code will be publicly released.",
    "pdf_link": "https://arxiv.org/abs/2407.10241",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10241v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10241/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10241v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10241/BiasAlert_pipline.pdf"
      },
      {
        "url": "https://arxiv.org/html/2407.10241v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10241/bias_and_consistency.png"
      }
    ],
    "abstract_cn": "随着大型语言模型的迅速发展，评估其中的偏见变得愈发关键。然而，现有评估方法局限于固定输出格式，难以适应 LLM 灵活的开放文本生成环境，如句子补全和问答。为此，我们推出了 BiasAlert，一款即插即用的工具，专门用于检测 LLM 生成文本中的社会偏见。BiasAlert 融合了外部人类知识与模型自身的推理能力，确保偏见检测的可靠性。实验证明，BiasAlert 在偏见检测上远超现有顶尖技术，如 GPT4-as-A-Judge。此外，应用研究显示，BiasAlert 在不同场景下均能有效评估和缓解 LLM 偏见。相关模型和代码将公开共享。",
    "title_cn": "BiasAlert：一款专为大型语言模型设计的社会偏见检测工具，操作简便，即插即用。",
    "tags": [
      "LLM应用",
      "人工智能",
      "社会科学"
    ]
  },
  {
    "title": "KAT: Dependency-aware Automated API Testing with Large Language Models",
    "submit_datetime": "2024年07月14日",
    "abstract": "API testing has increasing demands for software companies. Prior API testing tools were aware of certain types of dependencies that needed to be concise between operations and parameters. However, their approaches, which are mostly done manually or using heuristic-based algorithms, have limitations due to the complexity of these dependencies. In this paper, we present KAT (Katalon API Testing), a novel AI-driven approach that leverages the large language model GPT in conjunction with advanced prompting techniques to autonomously generate test cases to validate RESTful APIs. Our comprehensive strategy encompasses various processes to construct an operation dependency graph from an OpenAPI specification and to generate test scripts, constraint validation scripts, test cases, and test data. Our evaluation of KAT using 12 real-world RESTful services shows that it can improve test coverage, detect more undocumented status codes, and reduce false positives in these services in comparison with a state-of-the-art automated test generation tool. These results indicate the effectiveness of using the large language model for generating test scripts and data for API testing.",
    "pdf_link": "https://arxiv.org/abs/2407.10227",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10227v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10227/overview.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10227v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10227/ODG-construction.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10227v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10227/odg_ex.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10227v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10227/test-data-generation.png"
      }
    ],
    "abstract_cn": "随着API测试需求的增长，软件公司寻求更高效的测试工具。传统的API测试工具虽能处理特定依赖，但受限于手动操作或启发式算法的局限性。本文介绍的KAT（Katalon API测试），采用AI驱动，结合GPT大型语言模型和先进提示技术，自动生成RESTful API的测试用例。我们的策略涵盖从OpenAPI规范构建依赖图到生成各类测试脚本和数据的全过程。实证研究显示，KAT在提升测试覆盖率、发现更多未记录状态码及减少误报方面表现优异，证明了大型语言模型在API测试中的应用价值。",
    "title_cn": "KAT：结合大型语言模型，实现依赖性感知的自动化API测试",
    "tags": [
      "LLM应用",
      "软件开发",
      "测试工具"
    ]
  },
  {
    "title": "Practical Unlearning for Large Language Models",
    "submit_datetime": "2024年07月14日",
    "abstract": "While LLMs have demonstrated impressive performance across various domains and tasks, their security issues have become increasingly severe. Machine unlearning (MU) has emerged as a promising solution to address these issues by removing the influence of undesired data on the target model without compromising its utility in other aspects. MU typically assumes full access to the original training data to preserve utility, which is difficult to achieve in LLM unlearning. Existing LLM unlearning methods often assume access to data most affected by undesired data unlearning. However, this assumption underestimates the entanglement among various LLM capabilities and ignores data access limitations due to various issues. Moreover, these LLM unlearning methods do not sufficiently consider that unlearning requests in real-world scenarios are continuously emerging. To overcome these challenges and achieve practical LLM unlearning, we propose the O3 framework. The O3 framework includes an Out-Of-Distribution (OOD) detector to measure the similarity between input and unlearning data, and an Orthogonal low-rank adapter (LoRA) for continuously unlearning requested data. The OOD detector is trained with a novel contrastive entropy loss and utilizes a local-global layer-aggregated scoring mechanism. The orthogonal LoRA achieves parameter disentanglement among continual unlearning requests. During inference, our O3 framework can smartly decide whether and to what extent to load the unlearning LoRA based on the OOD detector's predictions. Notably, O3's effectiveness does not rely on any retained data. We conducted extensive experiments on O3 and state-of-the-art LLM unlearning methods across three tasks and seven datasets. The results indicate that O3 consistently achieves the best trade-off between unlearning effectiveness and utility preservation, especially when facing continuous unlearning requests.",
    "pdf_link": "https://arxiv.org/abs/2407.10223",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10223v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10223/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10223v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10223/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10223v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10223/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10223v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10223/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10223v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10223/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10223v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10223/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10223v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10223/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10223v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10223/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10223v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10223/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10223v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10223/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10223v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10223/x11.png"
      }
    ],
    "abstract_cn": "尽管大型语言模型（LLMs）在多领域表现卓越，但其安全问题日益严峻。机器遗忘（MU）应运而生，旨在剔除不良数据影响，同时保持模型效用。然而，现有方法常低估能力间的复杂关联，忽视数据访问的实际限制，且未充分应对现实中不断出现的遗忘需求。为此，我们提出O3框架，包含分布外检测器和正交低秩适配器（LoRA），前者用创新对比熵损失训练，后者确保遗忘请求间的参数独立。实验证明，O3在遗忘与效用间找到理想平衡，尤其在持续遗忘场景中表现突出，且不依赖任何保留数据。",
    "title_cn": "大规模语言模型的实用遗忘技术",
    "tags": [
      "LLM应用",
      "人工智能",
      "网络安全"
    ]
  },
  {
    "title": "Key-Point-Driven Mathematical Reasoning Distillation of Large Language Model",
    "submit_datetime": "2024年07月14日",
    "abstract": "Large Language Models (LLMs) have demonstrated exceptional proficiency in mathematical reasoning tasks due to their extensive parameter counts and training on vast datasets. Despite these capabilities, deploying LLMs is hindered by their computational demands. Distilling LLM mathematical reasoning into Smaller Language Models (SLMs) has emerged as a solution to this challenge, although these smaller models often suffer from errors in calculation and semantic understanding. Prior work has proposed Program-of-Thought Distillation (PoTD) to avoid calculation error. To further address semantic understanding errors, we propose Key-Point-Driven Mathematical Reasoning Distillation (KPDD). KPDD enhances the reasoning performance of SLMs by breaking down the problem-solving process into three stages: Core Question Extraction, Problem-Solving Information Extraction, and Step-by-Step Solution. This method is further divided into KPDD-CoT, which generates Chain-of-Thought rationales, and KPDD-PoT, which creates Program-of-Thought rationales. The experiment results show that KPDD-CoT significantly improves reasoning abilities, while KPDD-PoT achieves state-of-the-art performance in mathematical reasoning tasks. Our approach effectively mitigates misunderstanding errors, advancing the deployment of efficient and capable SLMs.",
    "pdf_link": "https://arxiv.org/abs/2407.10167",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10167v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10167/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10167v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10167/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10167v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10167/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10167v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10167/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10167v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10167/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10167v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10167/x6.png"
      }
    ],
    "abstract_cn": "大型语言模型 (LLM) 因其庞大的参数和广泛的数据训练，在数学推理任务中表现卓越。然而，高计算需求限制了其部署。为此，我们将 LLM 的数学推理提炼至小型语言模型 (SLM)，虽解决了部分问题，但 SLM 在计算和语义理解上仍有不足。为此，我们提出关键点驱动的数学推理提炼 (KPDD)，通过分解问题解决过程为三个阶段，显著提升 SLM 的推理性能。实验表明，KPDD-CoT 大幅提升推理能力，而 KPDD-PoT 则在数学推理任务中达到顶尖水平。这一方法有效减少了误解错误，推动了高效且强大的 SLM 的实际应用。",
    "title_cn": "大型语言模型的关键点驱动数学推理蒸馏",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "ChatLogic: Integrating Logic Programming with Large Language Models for Multi-Step Reasoning",
    "submit_datetime": "2024年07月14日",
    "abstract": "Large language models (LLMs) such as ChatGPT and GPT-4 have demonstrated impressive capabilities in various generative tasks. However, their performance is often hampered by limitations in accessing and leveraging long-term memory, leading to specific vulnerabilities and biases, especially during long interactions. This paper introduces ChatLogic, an innovative framework specifically targeted at LLM reasoning tasks that can enhance the performance of LLMs in multi-step deductive reasoning tasks by integrating logic programming. In ChatLogic, the language model plays a central role, acting as a controller and participating in every system operation stage. We propose a novel method of converting logic problems into symbolic integration with an inference engine. This approach leverages large language models' situational understanding and imitation skills and uses symbolic memory to enhance multi-step deductive reasoning capabilities. Our results show that the ChatLogic framework significantly improves the multi-step reasoning capabilities of LLMs. The source code and data are available at \\url{https://github.com/Strong-AI-Lab/ChatLogic}",
    "pdf_link": "https://arxiv.org/abs/2407.10162",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10162v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10162/intro.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10162v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10162/detail.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10162v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10162/demo.png"
      }
    ],
    "abstract_cn": "ChatGPT和GPT-4等大型语言模型在多项生成任务中表现卓越，但长期记忆的局限性常导致其在长时间交互中易受攻击和偏见影响。为此，我们推出了ChatLogic框架，专为提升LLM在复杂推理任务中的表现而设计。该框架通过融合逻辑编程，使语言模型成为系统核心，有效参与每一操作环节。我们创新地将逻辑问题转化为符号推理，充分利用模型的情境感知与模仿能力，并通过符号记忆强化推理过程。实证结果表明，ChatLogic大幅增强了LLM的连续推理能力。相关代码与数据已公开于\\url{https://github.com/Strong-AI-Lab/ChatLogic}。",
    "title_cn": "ChatLogic：融合逻辑编程与大型语言模型，助力多步骤推理",
    "tags": [
      "LLM应用",
      "人工智能",
      "软件开发"
    ]
  },
  {
    "title": "Look Within, Why LLMs Hallucinate: A Causal Perspective",
    "submit_datetime": "2024年07月14日",
    "abstract": "The emergence of large language models (LLMs) is a milestone in generative artificial intelligence, achieving significant success in text comprehension and generation tasks. Despite the tremendous success of LLMs in many downstream tasks, they suffer from severe hallucination problems, posing significant challenges to the practical applications of LLMs. Most of the works about LLMs' hallucinations focus on data quality. Self-attention is a core module in transformer-based LLMs, while its potential relationship with LLMs' hallucination has been hardly investigated. To fill this gap, we study this problem from a causal perspective. We propose a method to intervene in LLMs' self-attention layers and maintain their structures and sizes intact. Specifically, we disable different self-attention layers in several popular open-source LLMs and then compare their degrees of hallucination with the original ones. We evaluate the intervened LLMs on hallucination assessment benchmarks and conclude that disabling some specific self-attention layers in the front or tail of the LLMs can alleviate hallucination issues. The study paves a new way for understanding and mitigating LLMs' hallucinations.",
    "pdf_link": "https://arxiv.org/abs/2407.10153",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10153v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10153/fig1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10153v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10153/fig2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10153v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10153/fig3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10153v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10153/fig7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10153v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10153/res3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10153v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10153/res1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10153v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10153/res2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10153v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10153/res4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10153v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10153/res6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10153v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10153/res8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10153v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10153/res7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10153v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10153/res5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10153v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10153/rescompare1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10153v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10153/rescompare2.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLM）的崛起标志着生成式人工智能的重大进步，尤其在文本理解和生成方面表现卓越。然而，尽管 LLM 在众多应用中大放异彩，其严重的幻觉问题却限制了实际应用的步伐。当前研究多聚焦于数据质量，而对自注意力机制与幻觉现象的关联探究甚少。为此，我们尝试从因果关系入手，探索干预自注意力层以减轻幻觉的新途径。通过在多个开源 LLM 中禁用特定自注意力层，并对比其幻觉程度，我们发现调整某些关键层的策略能有效缓解幻觉。这一发现不仅深化了对 LLM 幻觉机制的理解，也为未来减轻此类问题提供了创新思路。",
    "title_cn": "深入探索，揭秘 LLMs 幻觉之谜：因果视角解析",
    "tags": [
      "LLM理论",
      "人工智能",
      ""
    ]
  },
  {
    "title": "TokenSHAP: Interpreting Large Language Models with Monte Carlo Shapley Value Estimation",
    "submit_datetime": "2024年07月14日",
    "abstract": "As large language models (LLMs) become increasingly prevalent in critical applications, the need for interpretable AI has grown. We introduce TokenSHAP, a novel method for interpreting LLMs by attributing importance to individual tokens or substrings within input prompts. This approach adapts Shapley values from cooperative game theory to natural language processing, offering a rigorous framework for understanding how different parts of an input contribute to a model's response. TokenSHAP leverages Monte Carlo sampling for computational efficiency, providing interpretable, quantitative measures of token importance. We demonstrate its efficacy across diverse prompts and LLM architectures, showing consistent improvements over existing baselines in alignment with human judgments, faithfulness to model behavior, and consistency.\n  Our method's ability to capture nuanced interactions between tokens provides valuable insights into LLM behavior, enhancing model transparency, improving prompt engineering, and aiding in the development of more reliable AI systems. TokenSHAP represents a significant step towards the necessary interpretability for responsible AI deployment, contributing to the broader goal of creating more transparent, accountable, and trustworthy AI systems.",
    "pdf_link": "https://arxiv.org/abs/2407.10114",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10114v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10114/TokenSHAP_flow.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10114v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10114/plot.jpeg"
      },
      {
        "url": "https://arxiv.org/html/2407.10114v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10114/boxplot_shap_injection_baseline_random.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10114v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10114/boxplot_shap_injection_propmpt_engineer.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10114v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10114/boxplot_shap_injection_token_shap.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10114v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10114/Shapley_Value_Estimation_Accuracy.png"
      }
    ],
    "abstract_cn": "随着 LLM 在关键领域的普及，可解释 AI 的需求日益增长。我们提出的 TokenSHAP 方法，通过评估输入提示中各标记或子串的重要性，为解释 LLM 提供了新视角。该方法借鉴合作博弈理论中的 Shapley 值，为 NLP 领域带来了严谨的分析框架，揭示了输入各部分对模型输出的贡献。借助高效的蒙特卡洛采样，TokenSHAP 提供了量化且易于理解的标记重要性评估。在多种提示和模型架构中，TokenSHAP 均展现出优于传统方法的性能，更符合人类判断，忠实于模型行为，且保持一致性。TokenSHAP 深入解析标记间的交互，为 LLM 的运作机制提供了深刻洞察，不仅提升了模型的透明度，优化了提示设计，还助力构建更为可靠的 AI 系统。这一创新方法，是推动 AI 向更透明、可问责、可信赖方向发展的重要一步。",
    "title_cn": "TokenSHAP：通过蒙特卡洛 Shapley 值估计来解读大型语言模型",
    "tags": [
      "LLM理论",
      "人工智能",
      ""
    ]
  },
  {
    "title": "DistillSeq: A Framework for Safety Alignment Testing in Large Language Models using Knowledge Distillation",
    "submit_datetime": "2024年07月14日",
    "abstract": "Large Language Models (LLMs) have showcased their remarkable capabilities in diverse domains, encompassing natural language understanding, translation, and even code generation. The potential for LLMs to generate harmful content is a significant concern. This risk necessitates rigorous testing and comprehensive evaluation of LLMs to ensure safe and responsible use. However, extensive testing of LLMs requires substantial computational resources, making it an expensive endeavor. Therefore, exploring cost-saving strategies during the testing phase is crucial to balance the need for thorough evaluation with the constraints of resource availability. To address this, our approach begins by transferring the moderation knowledge from an LLM to a small model. Subsequently, we deploy two distinct strategies for generating malicious queries: one based on a syntax tree approach, and the other leveraging an LLM-based method. Finally, our approach incorporates a sequential filter-test process designed to identify test cases that are prone to eliciting toxic responses. Our research evaluated the efficacy of DistillSeq across four LLMs: GPT-3.5, GPT-4.0, Vicuna-13B, and Llama-13B. In the absence of DistillSeq, the observed attack success rates on these LLMs stood at 31.5% for GPT-3.5, 21.4% for GPT-4.0, 28.3% for Vicuna-13B, and 30.9% for Llama-13B. However, upon the application of DistillSeq, these success rates notably increased to 58.5%, 50.7%, 52.5%, and 54.4%, respectively. This translated to an average escalation in attack success rate by a factor of 93.0% when compared to scenarios without the use of DistillSeq. Such findings highlight the significant enhancement DistillSeq offers in terms of reducing the time and resource investment required for effectively testing LLMs.",
    "pdf_link": "https://arxiv.org/abs/2407.10106",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10106v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10106/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10106v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10106/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10106v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10106/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10106v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10106/x4.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLM）在自然语言理解、翻译乃至代码生成等多个领域展现了非凡能力。然而，LLM 产生有害内容的风险不容忽视，这要求我们对其进行严格测试和全面评估，确保其安全且负责任地使用。但大规模测试 LLM 耗资巨大，因此，在测试阶段寻找节约成本的策略至关重要。我们的方法首先将审查知识从大型模型转移至小型模型，然后采用两种策略生成恶意查询：一是基于语法树的方法，二是利用 LLM 的方法。最后，我们设计了一个顺序过滤-测试流程，以识别易引发有毒反应的测试案例。研究显示，DistillSeq 在 GPT-3.5、GPT-4.0、Vicuna-13B 和 Llama-13B 上的应用，使得攻击成功率显著提升，平均增加了 93.0%。这表明 DistillSeq 在减少测试 LLM 所需时间和资源方面具有显著优势。",
    "title_cn": "DistillSeq：利用知识蒸馏技术，为大型语言模型设计的安全对齐测试框架",
    "tags": [
      "LLM应用",
      "人工智能",
      "网络安全"
    ]
  },
  {
    "title": "Enhancing Emotion Prediction in News Headlines: Insights from ChatGPT and Seq2Seq Models for Free-Text Generation",
    "submit_datetime": "2024年07月14日",
    "abstract": "Predicting emotions elicited by news headlines can be challenging as the task is largely influenced by the varying nature of people's interpretations and backgrounds. Previous works have explored classifying discrete emotions directly from news headlines. We provide a different approach to tackling this problem by utilizing people's explanations of their emotion, written in free-text, on how they feel after reading a news headline. Using the dataset BU-NEmo+ (Gao et al., 2022), we found that for emotion classification, the free-text explanations have a strong correlation with the dominant emotion elicited by the headlines. The free-text explanations also contain more sentimental context than the news headlines alone and can serve as a better input to emotion classification models. Therefore, in this work we explored generating emotion explanations from headlines by training a sequence-to-sequence transformer model and by using pretrained large language model, ChatGPT (GPT-4). We then used the generated emotion explanations for emotion classification. In addition, we also experimented with training the pretrained T5 model for the intermediate task of explanation generation before fine-tuning it for emotion classification. Using McNemar's significance test, methods that incorporate GPT-generated free-text emotion explanations demonstrated significant improvement (P-value < 0.05) in emotion classification from headlines, compared to methods that only use headlines. This underscores the value of using intermediate free-text explanations for emotion prediction tasks with headlines.",
    "pdf_link": "https://arxiv.org/abs/2407.10091",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10091v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10091/full_interface_T.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10091v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10091/annotation_examples.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10091v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10091/Transformer_3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10091v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10091/T5_5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10091v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10091/chatgpt_prompt_zs.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10091v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10091/ChatGPT_concat_3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10091v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10091/ChatGPT_singles_2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10091v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10091/confusion_matrix_baseline_cee_chat.png"
      }
    ],
    "abstract_cn": "预测新闻标题引发的情感颇具挑战，因受制于人们多样的解读与背景。过往研究多直接从标题分类情感。我们另辟蹊径，利用读者自由文本的情感解释，揭示阅读标题后的内心感受。通过BU-NEmo+数据集，我们发现这些解释与标题主导情感高度相关，且蕴含更丰富的情感语境，更适合作为情感分类模型的输入。为此，我们训练了序列到序列的transformer模型，并借助ChatGPT（GPT-4）生成情感解释，进而用于情感分类。同时，我们还尝试先训练T5模型生成解释，再微调进行情感分类。经McNemar检验，结合GPT生成的解释的方法在情感分类上显著优于仅用标题的方法（P值<0.05），凸显了在标题情感预测中引入自由文本解释的重要性。",
    "title_cn": "提升新闻标题情感预测：ChatGPT 与 Seq2Seq 模型在自由文本生成中的新视角",
    "tags": [
      "LLM应用",
      "",
      "情感分析"
    ]
  },
  {
    "title": "Rapid Biomedical Research Classification: The Pandemic PACT Advanced Categorisation Engine",
    "submit_datetime": "2024年07月14日",
    "abstract": "This paper introduces the Pandemic PACT Advanced Categorisation Engine (PPACE) along with its associated dataset. PPACE is a fine-tuned model developed to automatically classify research abstracts from funded biomedical projects according to WHO-aligned research priorities. This task is crucial for monitoring research trends and identifying gaps in global health preparedness and response. Our approach builds on human-annotated projects, which are allocated one or more categories from a predefined list. A large language model is then used to generate `rationales' explaining the reasoning behind these annotations. This augmented data, comprising expert annotations and rationales, is subsequently used to fine-tune a smaller, more efficient model. Developed as part of the Pandemic PACT project, which aims to track and analyse research funding and clinical evidence for a wide range of diseases with outbreak potential, PPACE supports informed decision-making by research funders, policymakers, and independent researchers. We introduce and release both the trained model and the instruction-based dataset used for its training. Our evaluation shows that PPACE significantly outperforms its baselines. The release of PPACE and its associated dataset offers valuable resources for researchers in multilabel biomedical document classification and supports advancements in aligning biomedical research with key global health priorities.",
    "pdf_link": "https://arxiv.org/abs/2407.10086",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10086v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10086/individual_label_distribution_training_set.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10086v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10086/combined_label_distribution_training_set.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10086v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10086/label_correlations_heatmap.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10086v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10086/fscore-changes-test.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10086v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10086/test-set-freqs.png"
      }
    ],
    "abstract_cn": "本文推出大流行病PACT高级分类引擎（PPACE）及其关联数据集，该引擎专为自动分类生物医学项目摘要而设计，确保与WHO研究优先级一致。此功能对监测研究动向、填补全球卫生应对空白至关重要。我们基于人工标注项目，利用大型语言模型生成标注理由，进而用这些增强数据微调更高效的小型模型。PPACE作为大流行病PACT项目一环，助力科研资助者、政策制定者及独立研究者做出明智决策。我们不仅介绍PPACE，还公开其训练模型及数据集。评估表明，PPACE性能远超基准。PPACE及其数据集的发布，为多标签生物医学文档分类研究提供宝贵资源，推动生物医学研究与全球卫生关键优先级的协同发展。",
    "title_cn": "快速生物医学研究分类：大流行病 PACT 高级分类引擎",
    "tags": [
      "LLM应用",
      "生物医学",
      "公共卫生"
    ]
  },
  {
    "title": "Semantic Understanding and Data Imputation using Large Language Model to Accelerate Recommendation System",
    "submit_datetime": "2024年07月14日",
    "abstract": "This paper aims to address the challenge of sparse and missing data in recommendation systems, a significant hurdle in the age of big data. Traditional imputation methods struggle to capture complex relationships within the data. We propose a novel approach that fine-tune Large Language Model (LLM) and use it impute missing data for recommendation systems. LLM which is trained on vast amounts of text, is able to understand complex relationship among data and intelligently fill in missing information. This enriched data is then used by the recommendation system to generate more accurate and personalized suggestions, ultimately enhancing the user experience. We evaluate our LLM-based imputation method across various tasks within the recommendation system domain, including single classification, multi-classification, and regression compared to traditional data imputation methods. By demonstrating the superiority of LLM imputation over traditional methods, we establish its potential for improving recommendation system performance.",
    "pdf_link": "https://arxiv.org/abs/2407.10078",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10078v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10078/Data_imputation.png"
      }
    ],
    "abstract_cn": "本文针对推荐系统中稀疏和缺失数据的难题，提出了一种创新方法：微调大型语言模型（LLM）以智能填补数据空缺。LLM的广泛文本训练使其能深入理解数据关系，从而生成更精准、个性化的推荐，优化用户体验。我们在多种推荐任务中验证了LLM插补法的优越性，证实了其在提升推荐系统性能方面的潜力。",
    "title_cn": "借助大型语言模型，我们致力于通过语义理解和数据插补来提升推荐系统的速度。",
    "tags": [
      "LLM应用",
      "推荐系统",
      "用户体验"
    ]
  },
  {
    "title": "By My Eyes: Grounding Multimodal Large Language Models with Sensor Data via Visual Prompting",
    "submit_datetime": "2024年07月14日",
    "abstract": "Large language models (LLMs) have demonstrated exceptional abilities across various domains. However, utilizing LLMs for ubiquitous sensing applications remains challenging as existing text-prompt methods show significant performance degradation when handling long sensor data sequences. We propose a visual prompting approach for sensor data using multimodal LLMs (MLLMs). We design a visual prompt that directs MLLMs to utilize visualized sensor data alongside the target sensory task descriptions. Additionally, we introduce a visualization generator that automates the creation of optimal visualizations tailored to a given sensory task, eliminating the need for prior task-specific knowledge. We evaluated our approach on nine sensory tasks involving four sensing modalities, achieving an average of 10% higher accuracy than text-based prompts and reducing token costs by 15.8x. Our findings highlight the effectiveness and cost-efficiency of visual prompts with MLLMs for various sensory tasks.",
    "pdf_link": "https://arxiv.org/abs/2407.10385",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10385v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10385/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10385v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10385/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10385v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10385/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10385v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10385/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10385v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10385/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10385v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10385/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10385v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10385/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10385v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10385/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10385v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10385/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10385v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10385/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10385v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10385/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10385v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10385/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10385v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10385/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10385v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10385/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10385v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10385/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10385v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10385/x16.png"
      }
    ],
    "abstract_cn": "尽管大型语言模型在多领域表现出色，但在处理长传感器数据序列时，传统文本提示方法的性能显著下降，限制了其在普遍感知应用中的应用。为此，我们创新性地提出了基于多模态 LLM 的视觉提示方法，通过设计视觉提示，有效结合可视化传感器数据与任务描述，提升了处理效率。同时，我们开发的可视化生成器，能够自动优化特定任务的可视化效果，无需预先掌握专业知识。实验结果显示，与传统文本提示相比，我们的方法在九项感知任务中平均准确率提升10%，且成本降低15.8倍，充分展现了视觉提示在多模态 LLM 中的高效与经济优势。",
    "title_cn": "以我之眼：借助视觉提示，通过传感器数据为多模态大型语言模型提供坚实基础",
    "tags": [
      "LLM应用",
      "自动化",
      "传感器技术"
    ]
  },
  {
    "title": "Empowering LLMs for Verilog Generation through Multi-Level Summarization",
    "submit_datetime": "2024年07月14日",
    "abstract": "The increasing complexity and high costs associated with modern processor design have led to a surge in demand for processor design automation. Instruction-tuned large language models (LLMs) have demonstrated remarkable performance in automatically generating code for general-purpose programming languages like Python. However, these methods fail on hardware description languages (HDLs) like Verilog due to the scarcity of high-quality instruction tuning data, as even advanced LLMs like GPT-3.5 exhibit limited performance on Verilog generation. Regarding this issue, we observe that (1) Verilog code collected from the real world has higher quality than those generated by LLMs. (2) LLMs like GPT-3.5 excel in summarizing Verilog code rather than generating it. Based on these observations, this paper introduces CodeV, a series of open-source instruction-tuned Verilog generation LLMs. Instead of generating descriptions first and then getting the corresponding code from advanced LLMs, we prompt the LLM with Verilog code and let the LLM generate the corresponding natural language description by multi-level summarization. Experimental results show that CodeV relatively surpasses the previous open-source SOTA by 14.4% (BetterV in VerilogEval) and 11.3% (RTLCoder in RTLLM) respectively, and also relatively outperforms previous commercial SOTA GPT-4 by 22.1% in VerilogEval.",
    "pdf_link": "https://arxiv.org/abs/2407.10424",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10424v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10424/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10424v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10424/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10424v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10424/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10424v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10424/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10424v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10424/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10424v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10424/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10424v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10424/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10424v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10424/x8.png"
      }
    ],
    "abstract_cn": "随着处理器设计复杂性和成本的增加，对自动化设计工具的需求激增。尽管指令调优的LLMs在生成Python等编程语言代码方面表现卓越，但在Verilog这类硬件描述语言上却因缺乏高质量数据而表现不佳。我们发现，现实世界中的Verilog代码质量更高，且LLMs如GPT-3.5更擅长总结而非生成Verilog代码。为此，我们推出了CodeV，一系列开源的Verilog生成LLMs，通过多级总结直接从Verilog代码生成自然语言描述。实验表明，CodeV在性能上显著超越了以往的开源和商业SOTA，分别提升了14.4%、11.3%和22.1%。",
    "title_cn": "借助多级摘要技术，提升 LLMs 在 Verilog 生成方面的能力",
    "tags": [
      "LLM应用",
      "半导体",
      "自动化设计"
    ]
  },
  {
    "title": "Revolutionizing Bridge Operation and maintenance with LLM-based Agents: An Overview of Applications and Insights",
    "submit_datetime": "2024年07月13日",
    "abstract": "In various industrial fields of human social development, people have been exploring methods aimed at freeing human labor. Constructing LLM-based agents is considered to be one of the most effective tools to achieve this goal. Agent, as a kind of human-like intelligent entity with the ability of perception, planning, decision-making, and action, has created great production value in many fields. However, the bridge O\\&M field shows a relatively low level of intelligence compared to other industries. Nevertheless, the bridge O\\&M field has developed numerous intelligent inspection devices, machine learning algorithms, and autonomous evaluation and decision-making methods, which provide a feasible basis for breakthroughs in artificial intelligence in this field. The aim of this study is to explore the impact of AI bodies based on large-scale language models on the field of bridge O\\&M and to analyze the potential challenges and opportunities it brings to the core tasks of bridge O\\&M. Through in-depth research and analysis, this paper expects to provide a more comprehensive perspective for understanding the application of intelligentsia in this field.",
    "pdf_link": "https://arxiv.org/abs/2407.10064",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10064/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10064/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10064/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10064/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10064/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10064/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10064/x7.png"
      }
    ],
    "abstract_cn": "在人类社会发展的多个工业领域，人们不断探索解放劳动力的方法。基于LLM构建的代理被视为实现这一目标的有效工具。代理作为具备感知、规划、决策和行动能力的人工智能实体，在多个领域创造了显著的生产价值。然而，桥梁运维领域的智能化水平相对较低。尽管如此，该领域已发展出多种智能检测设备、机器学习算法及自主评估决策方法，为人工智能在该领域的突破提供了基础。本研究旨在探讨基于大规模语言模型的AI体对桥梁运维领域的影响，并分析其对核心任务的潜在挑战与机遇。通过深入研究，本文期望为理解该领域智能体的应用提供更全面的视角。",
    "title_cn": "LLM 代理正引领桥梁运维革新，本文概述其应用与洞察。",
    "tags": [
      "Agent",
      "桥梁运维",
      "人工智能"
    ]
  },
  {
    "title": "AtomAgents: Alloy design and discovery through physics-aware multi-modal multi-agent artificial intelligence",
    "submit_datetime": "2024年07月13日",
    "abstract": "The design of alloys is a multi-scale problem that requires a holistic approach that involves retrieving relevant knowledge, applying advanced computational methods, conducting experimental validations, and analyzing the results, a process that is typically reserved for human experts. Machine learning (ML) can help accelerate this process, for instance, through the use of deep surrogate models that connect structural features to material properties, or vice versa. However, existing data-driven models often target specific material objectives, offering limited flexibility to integrate out-of-domain knowledge and cannot adapt to new, unforeseen challenges. Here, we overcome these limitations by leveraging the distinct capabilities of multiple AI agents that collaborate autonomously within a dynamic environment to solve complex materials design tasks. The proposed physics-aware generative AI platform, AtomAgents, synergizes the intelligence of large language models (LLM) the dynamic collaboration among AI agents with expertise in various domains, including knowledge retrieval, multi-modal data integration, physics-based simulations, and comprehensive results analysis across modalities that includes numerical data and images of physical simulation results. The concerted effort of the multi-agent system allows for addressing complex materials design problems, as demonstrated by examples that include autonomously designing metallic alloys with enhanced properties compared to their pure counterparts. Our results enable accurate prediction of key characteristics across alloys and highlight the crucial role of solid solution alloying to steer the development of advanced metallic alloys. Our framework enhances the efficiency of complex multi-objective design tasks and opens new avenues in fields such as biomedical materials engineering, renewable energy, and environmental sustainability.",
    "pdf_link": "https://arxiv.org/abs/2407.10022",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10022v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10022/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10022v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10022/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10022v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10022/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10022v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10022/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10022v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10022/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10022v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10022/critical_fracture_toughness_NbMo.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10022v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10022/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10022v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10022/NbMo_Peierls_barrier_std_dev_vs_energy_change.png"
      }
    ],
    "abstract_cn": "合金设计涉及多尺度问题，传统上依赖人类专家进行全面处理，包括知识检索、计算方法应用、实验验证及结果分析。机器学习通过深度代理模型加速这一流程，但现有模型灵活性有限，难以应对新挑战。我们通过多AI代理在动态环境中的自主协作，克服了这些限制。提出的AtomAgents平台结合了大型语言模型的智能与跨领域AI代理的协作，涵盖知识检索、数据集成、物理模拟及结果分析，实现了复杂材料设计问题的解决，例如自主设计性能更优的金属合金。我们的研究不仅准确预测了合金特性，还强调了固溶合金化的重要性，提升了多目标设计任务的效率，并为多个领域如生物医学、可再生能源和环境可持续性开辟了新路径。",
    "title_cn": "AtomAgents：利用物理感知的多模态多智能体AI技术，推动合金设计和发现的革新。",
    "tags": [
      "Agent",
      "材料科学",
      "人工智能"
    ]
  },
  {
    "title": "Cohesive Conversations: Enhancing Authenticity in Multi-Agent Simulated Dialogues",
    "submit_datetime": "2024年07月13日",
    "abstract": "This paper investigates the quality of multi-agent dialogues in simulations powered by Large Language Models (LLMs), focusing on a case study from Park et al. (2023), where 25 agents engage in day-long simulations of life, showcasing complex behaviors and interactions. Analyzing dialogues and memory over multiple sessions revealed significant issues such as repetition, inconsistency, and hallucination, exacerbated by the propagation of erroneous information. To combat these challenges, we propose a novel Screening, Diagnosis, and Regeneration (SDR) framework that detects and corrects utterance errors through a comprehensive process involving immediate issue identification, evidence gathering from past dialogues, and LLM analysis for utterance revision. The effectiveness of the SDR framework is validated through GPT-4 assessments and human evaluations, demonstrating marked improvements in dialogue consistency, diversity, and the reduction of false information. This work presents a pioneering approach to enhancing dialogue quality in multi-agent simulations, establishing a new standard for future research in the field.",
    "pdf_link": "https://arxiv.org/abs/2407.09897",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.09897v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09897/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09897v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09897/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09897v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09897/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09897v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09897/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09897v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09897/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09897v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09897/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09897v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09897/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09897v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09897/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09897v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09897/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09897v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09897/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09897v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09897/x11.png"
      }
    ],
    "abstract_cn": "本文深入探讨了 LLM 驱动模拟中多智能体对话的质量，特别是在 Park 等人的研究中，25 个智能体全天模拟生活，展现出复杂互动。研究发现，对话中存在重复、不一致和幻觉等问题，且错误信息传播加剧了这些问题。为此，我们创新性地提出了 SDR 框架，通过即时问题识别、历史对话证据收集和 LLM 分析，有效检测并修正话语错误。经 GPT-4 和人类评估验证，SDR 框架显著提升了对话的一致性、多样性，并减少了虚假信息。这一研究为提升多智能体模拟中的对话质量开辟了新路径，为未来研究树立了新标杆。",
    "title_cn": "连贯对话：提升多代理模拟对话的真实性",
    "tags": [
      "Agent",
      "人工智能",
      "虚拟现实"
    ]
  },
  {
    "title": "Synergistic Multi-Agent Framework with Trajectory Learning for Knowledge-Intensive Tasks",
    "submit_datetime": "2024年07月13日",
    "abstract": "Recent advancements in Large Language Models (LLMs) have led to significant breakthroughs in various natural language processing tasks. However, generating factually consistent responses in knowledge-intensive scenarios remains a challenge due to issues such as hallucination, difficulty in acquiring long-tailed knowledge, and limited memory expansion. This paper introduces SMART, a novel multi-agent framework that leverages external knowledge to enhance the interpretability and factual consistency of LLM-generated responses. SMART comprises four specialized agents, each performing a specific sub-trajectory action to navigate complex knowledge-intensive tasks. We propose a multi-agent co-training paradigm, Long- and Short-Trajectory Learning, which ensures synergistic collaboration among agents while maintaining fine-grained execution by each agent. Extensive experiments on 5 tasks demonstrate SMART's superior performance compared to previous widely adopted methods.",
    "pdf_link": "https://arxiv.org/abs/2407.09893",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.09893v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09893/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09893v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09893/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09893v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09893/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09893v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09893/datasize.jpg"
      }
    ],
    "abstract_cn": "大型语言模型 (LLM) 的最新进展在多种自然语言处理任务中取得了重大突破。然而，在知识密集型场景中生成事实一致的响应仍面临挑战，如幻觉现象、长尾知识获取困难及内存扩展限制。为此，本文引入了 SMART，一个创新的多智能体框架，通过整合外部知识提升 LLM 生成内容的可解释性与事实一致性。SMART 框架包含四个专业智能体，各自负责特定子任务，共同应对复杂知识密集型挑战。我们提出的多智能体协同训练模式——长轨迹与短轨迹学习，不仅确保了智能体间的协同效应，还维持了每个智能体的精细操作。经过 5 项任务的广泛实验验证，SMART 展现出超越传统方法的卓越性能。",
    "title_cn": "知识密集型任务中的协同多智能体框架与轨迹学习",
    "tags": [
      "Agent",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Speech-Copilot: Leveraging Large Language Models for Speech Processing via Task Decomposition, Modularization, and Program Generation",
    "submit_datetime": "2024年07月13日",
    "abstract": "In this work, we introduce Speech-Copilot, a modular framework for instruction-oriented speech-processing tasks that minimizes human effort in toolset construction. Unlike end-to-end methods using large audio-language models, Speech-Copilot builds speech processing-specific toolsets by analyzing pre-collected task instructions and breaking tasks into manageable sub-tasks. It features a flexible agent based on large language models that performs tasks through program generation. Our approach achieves state-of-the-art performance on the Dynamic-SUPERB benchmark, demonstrating its effectiveness across diverse speech-processing tasks. Key contributions include: 1) developing an innovative framework for speech processing-specific toolset construction, 2) establishing a high-performing agent based on large language models, and 3) offering a new perspective on addressing challenging instruction-oriented speech-processing tasks. Without additional training processes required by end-to-end approaches, our method provides a flexible and extendable solution for a wide range of speech-processing applications.",
    "pdf_link": "https://arxiv.org/abs/2407.09886",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.09886v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09886/speech-copilot-pipeline-v6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09886v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09886/real_example.png"
      }
    ],
    "abstract_cn": "我们推出的 Speech-Copilot 框架，专为简化语音处理任务而设计，通过模块化方式大幅减少了工具集构建的人力需求。不同于依赖大型音频-语言模型的端到端解决方案，Speech-Copilot 通过精细分析任务指令，将复杂任务拆解为易于管理的子任务，从而构建出针对性的语音处理工具集。该框架的核心是一个灵活的代理系统，它基于大型语言模型，能够通过自动生成程序来执行任务。在 Dynamic-SUPERB 基准测试中，我们的方法表现卓越，证明了其在多种语音处理任务中的高效性。主要创新点包括：1) 创新性地构建了语音处理专用工具集，2) 利用大型语言模型打造了高性能代理，3) 为处理复杂的指令导向语音任务提供了新思路。此外，我们的方法无需额外的训练过程，为语音处理领域提供了一个既灵活又可扩展的解决方案。",
    "title_cn": "Speech-Copilot：借助任务分解、模块化及程序生成技术，运用大型语言模型提升语音处理效率",
    "tags": [
      "Agent",
      "语音处理",
      "人工智能"
    ]
  },
  {
    "title": "Language-Augmented Symbolic Planner for Open-World Task Planning",
    "submit_datetime": "2024年07月13日",
    "abstract": "Enabling robotic agents to perform complex long-horizon tasks has been a long-standing goal in robotics and artificial intelligence (AI). Despite the potential shown by large language models (LLMs), their planning capabilities remain limited to short-horizon tasks and they are unable to replace the symbolic planning approach. Symbolic planners, on the other hand, may encounter execution errors due to their common assumption of complete domain knowledge which is hard to manually prepare for an open-world setting. In this paper, we introduce a Language-Augmented Symbolic Planner (LASP) that integrates pre-trained LLMs to enable conventional symbolic planners to operate in an open-world environment where only incomplete knowledge of action preconditions, objects, and properties is initially available. In case of execution errors, LASP can utilize the LLM to diagnose the cause of the error based on the observation and interact with the environment to incrementally build up its knowledge base necessary for accomplishing the given tasks. Experiments demonstrate that LASP is proficient in solving planning problems in the open-world setting, performing well even in situations where there are multiple gaps in the knowledge.",
    "pdf_link": "https://arxiv.org/abs/2407.09792",
    "graphs": [],
    "abstract_cn": "长期以来，让机器人代理执行复杂的长期任务一直是机器人学和人工智能领域的追求。尽管大型语言模型（LLM）展现出潜力，但其规划能力仍局限于短期任务，无法替代传统的符号规划方法。而符号规划器在开放世界环境中可能因对完整领域知识的假设而遭遇执行错误。为此，我们提出了一种语言增强的符号规划器（LASP），它融合了预训练的LLM，使传统符号规划器能在知识不完全的开源环境中运作。当遇到执行错误时，LASP能借助LLM根据观察诊断错误原因，并通过与环境的互动逐步构建完成任务所需的知识库。实验证明，LASP在开放世界环境中解决规划问题表现优异，即便在知识存在多处缺口的情况下也能应对自如。",
    "title_cn": "开放世界任务规划的语言增强符号规划器",
    "tags": [
      "Agent",
      "机器人学",
      "人工智能"
    ]
  },
  {
    "title": "Dense Multimodal Alignment for Open-Vocabulary 3D Scene Understanding",
    "submit_datetime": "2024年07月13日",
    "abstract": "Recent vision-language pre-training models have exhibited remarkable generalization ability in zero-shot recognition tasks. Previous open-vocabulary 3D scene understanding methods mostly focus on training 3D models using either image or text supervision while neglecting the collective strength of all modalities. In this work, we propose a Dense Multimodal Alignment (DMA) framework to densely co-embed different modalities into a common space for maximizing their synergistic benefits. Instead of extracting coarse view- or region-level text prompts, we leverage large vision-language models to extract complete category information and scalable scene descriptions to build the text modality, and take image modality as the bridge to build dense point-pixel-text associations. Besides, in order to enhance the generalization ability of the 2D model for downstream 3D tasks without compromising the open-vocabulary capability, we employ a dual-path integration approach to combine frozen CLIP visual features and learnable mask features. Extensive experiments show that our DMA method produces highly competitive open-vocabulary segmentation performance on various indoor and outdoor tasks.",
    "pdf_link": "https://arxiv.org/abs/2407.09781",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.09781v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09781/framework_2.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09781v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09781/tags.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09781v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09781/comparison.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09781v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09781/visualization.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09781v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09781/2d_feature_2.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09781v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09781/VLM.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09781v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09781/rare_obj.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09781v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09781/chatbox.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09781v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09781/painted_scenes.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09781v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09781/llm.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09781v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09781/scannet_visualization.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09781v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09781/nus_visualization.jpg"
      }
    ],
    "abstract_cn": "近期，视觉-语言预训练模型在零-shot识别任务中表现出色。然而，以往的开放词汇3D场景理解方法往往只依赖单一模态的监督，忽视了多模态融合的潜力。为此，我们提出了密集多模态对齐（DMA）框架，旨在将不同模态紧密融合至同一空间，以发挥其协同效应。我们不仅利用大型视觉-语言模型提取详尽的类别信息和场景描述，还通过图像模态构建点-像素-文本的紧密联系。同时，为提升2D模型在3D任务中的泛化能力，我们采用了双路径集成策略，融合了固定的CLIP视觉特征与可调整的掩码特征。实验结果显示，DMA方法在室内外多种任务中均展现出卓越的开放词汇分割性能。",
    "title_cn": "密集多模态对齐助力开放词汇表的3D场景深度理解",
    "tags": [
      "LLM应用",
      "计算机视觉",
      "人工智能"
    ]
  },
  {
    "title": "Multi-Granularity Semantic Revision for Large Language Model Distillation",
    "submit_datetime": "2024年07月13日",
    "abstract": "Knowledge distillation plays a key role in compressing the Large Language Models (LLMs), which boosts a small-size student model under large teacher models' guidance. However, existing LLM distillation methods overly rely on student-generated outputs, which may introduce generation errors and misguide the distillation process. Moreover, the distillation loss functions introduced in previous art struggle to align the most informative part due to the complex distribution of LLMs' outputs. To address these problems, we propose a multi-granularity semantic revision method for LLM distillation. At the sequence level, we propose a sequence correction and re-generation (SCRG) strategy. SCRG first calculates the semantic cognitive difference between the teacher and student to detect the error token, then corrects it with the teacher-generated one, and re-generates the sequence to reduce generation errors and enhance generation diversity. At the token level, we design a distribution adaptive clipping Kullback-Leibler (DAC-KL) loss as the distillation objective function. DAC-KL loss exploits a learnable sub-network to adaptively extract semantically dense areas from the teacher's output, avoiding the interference of redundant information in the distillation process. Finally, at the span level, we leverage the span priors of a sequence to compute the probability correlations within spans, and constrain the teacher and student's probability correlations to be consistent, further enhancing the transfer of semantic information. Extensive experiments across different model families with parameters ranging from 0.1B to 13B demonstrate the superiority of our method compared to existing methods.",
    "pdf_link": "https://arxiv.org/abs/2407.10068",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10068v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10068/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10068v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10068/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10068v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10068/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10068v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10068/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10068v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10068/x5.png"
      }
    ],
    "abstract_cn": "知识蒸馏在压缩大型语言模型（LLM）中至关重要，它通过大型教师模型的引导提升小型学生模型的性能。然而，现有方法过于依赖学生生成的输出，可能引入错误并误导蒸馏过程。此外，先前的蒸馏损失函数难以对齐LLM输出中最具信息量的部分。为此，我们提出了一种多粒度语义修正方法。在序列级别，我们采用序列校正与重新生成（SCRG）策略，通过计算教师与学生的语义差异来检测并校正错误标记，从而减少生成错误并增强多样性。在标记级别，我们设计了分布自适应剪裁Kullback-Leibler（DAC-KL）损失，利用可学习子网络自适应提取语义密集区域，避免冗余信息干扰。在跨度级别，我们利用跨度先验计算概率相关性，并确保教师与学生的一致性，进一步增强语义信息传递。广泛实验表明，我们的方法在不同模型家族中表现优异，参数范围涵盖0.1B至13B。",
    "title_cn": "大型语言模型蒸馏中的多粒度语义修订",
    "tags": [
      "LLM理论",
      "人工智能",
      "软件工程"
    ]
  },
  {
    "title": "Learning to Refuse: Towards Mitigating Privacy Risks in LLMs",
    "submit_datetime": "2024年07月13日",
    "abstract": "Large language models (LLMs) exhibit remarkable capabilities in understanding and generating natural language. However, these models can inadvertently memorize private information, posing significant privacy risks. This study addresses the challenge of enabling LLMs to protect specific individuals' private data without the need for complete retraining. We propose \\return, a Real-world pErsonal daTa UnleaRNing dataset, comprising 2,492 individuals from Wikipedia with associated QA pairs, to evaluate machine unlearning (MU) methods for protecting personal data in a realistic scenario. Additionally, we introduce the Name-Aware Unlearning Framework (NAUF) for Privacy Protection, which enables the model to learn which individuals' information should be protected without affecting its ability to answer questions related to other unrelated individuals. Our extensive experiments demonstrate that NAUF achieves a state-of-the-art average unlearning score, surpassing the best baseline method by 5.65 points, effectively protecting target individuals' personal data while maintaining the model's general capabilities.",
    "pdf_link": "https://arxiv.org/abs/2407.10058",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10058v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10058/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10058v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10058/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10058v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10058/return.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10058v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10058/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10058v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10058/return.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10058v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10058/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10058v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10058/x5.png"
      }
    ],
    "abstract_cn": "大型语言模型 (LLM) 在自然语言处理方面表现出色，但可能无意中泄露私人信息，存在隐私风险。本研究针对这一问题，提出了一种无需全面重训即可保护个人数据的方法。我们创建了 \\return 数据集，包含 2,492 名维基百科用户的问答对，用于评估机器遗忘技术。同时，我们设计了名称感知遗忘框架 (NAUF)，确保模型能识别并保护特定个人信息，而不影响其对其他无关信息的处理能力。实验结果显示，NAUF 在遗忘性能上领先现有方法 5.65 分，既能有效保护隐私，又不损模型整体性能。",
    "title_cn": "学会拒绝：致力于缓解 LLMs 中的隐私风险",
    "tags": [
      "LLM应用",
      "隐私保护",
      ""
    ]
  },
  {
    "title": "LeanQuant: Accurate Large Language Model Quantization with Loss-Error-Aware Grid",
    "submit_datetime": "2024年07月13日",
    "abstract": "Large language models (LLMs) have numerous applications across various domains, but their high computational and memory demands pose significant deployment challenges. Weight quantization is an effective technique for reducing the decoding latency and memory requirements of LLMs. Existing approaches primarily aim to maintain the quality of quantized models by preserving outliers in input features, but they still suffer significant quality loss at lower bit widths. Our approach builds on Optimal Brain Quantization (OBQ), an iterative weight-update-based quantization framework. We identify a key limitation of OBQ, specifically that its uniform quantization grid is suboptimal for maintaining model quality, as it introduces large errors to the task loss. To address this, we propose LeanQuant, which learns a loss-error-aware quantization grid by leveraging the inverse diagonal Hessian. Extensive empirical evaluations demonstrate that LeanQuant is both efficient and accurate; it can quantize a 70-billion-parameter model in 6 hours using a single 32GB GPU and performs favorably compared to competitive baselines in the 4-bit, 3-bit, and 2-bit regions.",
    "pdf_link": "https://arxiv.org/abs/2407.10032",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10032v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10032/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10032v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10032/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10032v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10032/x3.png"
      }
    ],
    "abstract_cn": "大型语言模型虽应用广泛，但其高计算和内存需求成为部署难题。权重量化技术能有效降低解码延迟和内存需求，但现有方法在低位宽下质量损失严重。我们基于 OBQ 框架，发现其均匀量化网格的不足，并提出 LeanQuant，通过学习损失错误感知的量化网格，显著提升效率和准确性。实证显示，LeanQuant 能在 6 小时内完成 700 亿参数模型的量化，且在低比特区域表现卓越。",
    "title_cn": "LeanQuant：借助损失-误差-感知网格，精准量化大型语言模型",
    "tags": [
      "LLM理论",
      "计算机科学",
      "人工智能"
    ]
  },
  {
    "title": "Causality extraction from medical text using Large Language Models (LLMs)",
    "submit_datetime": "2024年07月13日",
    "abstract": "This study explores the potential of natural language models, including large language models, to extract causal relations from medical texts, specifically from Clinical Practice Guidelines (CPGs). The outcomes causality extraction from Clinical Practice Guidelines for gestational diabetes are presented, marking a first in the field. We report on a set of experiments using variants of BERT (BioBERT, DistilBERT, and BERT) and using Large Language Models (LLMs), namely GPT-4 and LLAMA2. Our experiments show that BioBERT performed better than other models, including the Large Language Models, with an average F1-score of 0.72. GPT-4 and LLAMA2 results show similar performance but less consistency. We also release the code and an annotated a corpus of causal statements within the Clinical Practice Guidelines for gestational diabetes.",
    "pdf_link": "https://arxiv.org/abs/2407.10020",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10020v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10020/label_count.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.10020v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10020/BioBERT-combined.jpg"
      }
    ],
    "abstract_cn": "本研究首次展示了从妊娠糖尿病临床实践指南中提取因果关系的能力，通过使用BERT变体和大型语言模型如GPT-4和LLAMA2进行实验。结果显示，BioBERT以0.72的平均F1分数领先，而GPT-4和LLAMA2虽表现相近，但一致性稍逊。此外，我们还公开了相关代码和注释语料库，以供进一步研究。",
    "title_cn": "利用大型语言模型从医学文本中提取因果关系",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "TOP:A New Target-Audience Oriented Content Paraphrase Task",
    "submit_datetime": "2024年07月13日",
    "abstract": "Recommendation systems usually recommend the existing contents to different users. However, in comparison to static recommendation methods, a recommendation logic that dynamically adjusts based on user interest preferences may potentially attract a larger user base. Thus, we consider paraphrasing existing content based on the interests of the users to modify the content to better align with the preferences of users. In this paper, we propose a new task named Target-Audience Oriented Content Paraphrase aims to generate more customized contents for the target audience. We introduce the task definition and the corresponding framework for the proposed task and the creation of the corresponding datasets. We utilize the Large Language Models (LLMs) and Large Vision Models (LVMs) to accomplish the base implementation of the TOP framework and provide the referential baseline results for the proposed task.",
    "pdf_link": "https://arxiv.org/abs/2407.09992",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.09992v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09992/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09992v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09992/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09992v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09992/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09992v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09992/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09992v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09992/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09992v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09992/x6.png"
      }
    ],
    "abstract_cn": "推荐系统常向用户推荐现有内容，但动态调整推荐逻辑以适应用户兴趣偏好，可能吸引更多用户。为此，我们提出“目标受众导向内容改述”任务，旨在生成更贴合用户偏好的定制内容。本文详细介绍了任务定义、框架及数据集创建方法，并利用LLMs和LVMs实现TOP框架，提供基准结果。",
    "title_cn": "TOP：一项针对目标受众的内容释义新任务",
    "tags": [
      "LLM应用",
      "数字营销",
      "内容创作"
    ]
  },
  {
    "title": "PFPs: Prompt-guided Flexible Pathological Segmentation for Diverse Potential Outcomes Using Large Vision and Language Models",
    "submit_datetime": "2024年07月13日",
    "abstract": "The Vision Foundation Model has recently gained attention in medical image analysis. Its zero-shot learning capabilities accelerate AI deployment and enhance the generalizability of clinical applications. However, segmenting pathological images presents a special focus on the flexibility of segmentation targets. For instance, a single click on a Whole Slide Image (WSI) could signify a cell, a functional unit, or layers, adding layers of complexity to the segmentation tasks. Current models primarily predict potential outcomes but lack the flexibility needed for physician input. In this paper, we explore the potential of enhancing segmentation model flexibility by introducing various task prompts through a Large Language Model (LLM) alongside traditional task tokens. Our contribution is in four-fold: (1) we construct a computational-efficient pipeline that uses finetuned language prompts to guide flexible multi-class segmentation; (2) We compare segmentation performance with fixed prompts against free-text; (3) We design a multi-task kidney pathology segmentation dataset and the corresponding various free-text prompts; and (4) We evaluate our approach on the kidney pathology dataset, assessing its capacity to new cases during inference.",
    "pdf_link": "https://arxiv.org/abs/2407.09979",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.09979v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09979/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09979v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09979/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09979v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09979/x3.png"
      }
    ],
    "abstract_cn": "Vision Foundation Model 在医学图像分析中崭露头角，其零-shot 学习能力不仅加速了 AI 部署，还提升了临床应用的泛化性。但在分割病理图像时，对分割目标的灵活性要求尤为突出。例如，在 Whole Slide Image (WSI) 上的单次点击可能代表不同层次的复杂性。现有模型虽能预测结果，却难以适应医生的灵活输入。本文中，我们通过结合大型语言模型 (LLM) 和传统任务令牌，探索了提升分割模型灵活性的新途径。我们的研究成果包括：(1) 构建了一个高效计算的流水线，利用微调的语言提示实现灵活的多类别分割；(2) 对比了固定提示与自由文本的分割效果；(3) 设计了多任务的肾脏病理分割数据集及相应的自由文本提示；(4) 在肾脏病理数据集上验证了我们的方法，考察了其在处理新病例时的能力。",
    "title_cn": "PFPs：借助大型视觉与语言模型，通过提示引导实现灵活的病理分割，适用于多样化的潜在结果分析。",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Minimizing PLM-Based Few-Shot Intent Detectors",
    "submit_datetime": "2024年07月13日",
    "abstract": "Recent research has demonstrated the feasibility of training efficient intent detectors based on pre-trained language model~(PLM) with limited labeled data. However, deploying these detectors in resource-constrained environments such as mobile devices poses challenges due to their large sizes. In this work, we aim to address this issue by exploring techniques to minimize the size of PLM-based intent detectors trained with few-shot data. Specifically, we utilize large language models (LLMs) for data augmentation, employ a cutting-edge model compression method for knowledge distillation, and devise a vocabulary pruning mechanism called V-Prune. Through these approaches, we successfully achieve a compression ratio of 21 in model memory usage, including both Transformer and the vocabulary, while maintaining almost identical performance levels on four real-world benchmarks.",
    "pdf_link": "https://arxiv.org/abs/2407.09943",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.09943v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09943/stacked_bar.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09943v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09943/framework.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09943v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09943/prompt_example.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09943v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09943/analysis_acc_vs_model_size_noVal.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09943v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09943/analysis_acc_vs_vocab_size_nearest_neighbor.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09943v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09943/analysis_acc_vs_vocab_pca_dim.png"
      }
    ],
    "abstract_cn": "近期研究展示了在有限标注数据下，基于预训练模型训练高效意图检测器的可能性。但这些大型检测器在移动设备等资源受限环境中的部署面临挑战。为此，我们探索了减小模型尺寸的技术，包括利用LLM进行数据增强、采用尖端压缩技术进行知识蒸馏及设计V-Prune词汇剪枝机制。这些创新举措不仅将模型内存使用压缩了21倍，且在四大实际基准测试中性能几乎未损。",
    "title_cn": "精简基于 PLM 的少样本意图检测器",
    "tags": [
      "LLM应用",
      "移动设备",
      "人工智能"
    ]
  },
  {
    "title": "Speech-Guided Sequential Planning for Autonomous Navigation using Large Language Model Meta AI 3 (Llama3)",
    "submit_datetime": "2024年07月13日",
    "abstract": "In social robotics, a pivotal focus is enabling robots to engage with humans in a more natural and seamless manner. The emergence of advanced large language models (LLMs) such as Generative Pre-trained Transformers (GPTs) and autoregressive models like Large Language Model Meta AI (Llamas) has driven significant advancements in integrating natural language understanding capabilities into social robots. This paper presents a system for speech-guided sequential planning in autonomous navigation, utilizing Llama3 and the Robot Operating System~(ROS). The proposed system involves using Llama3 to interpret voice commands, extracting essential details through parsing, and decoding these commands into sequential actions for tasks. Such sequential planning is essential in various domains, particularly in the pickup and delivery of an object. Once a sequential navigation task is evaluated, we employ DRL-VO, a learning-based control policy that allows a robot to autonomously navigate through social spaces with static infrastructure and (crowds of) people. We demonstrate the effectiveness of the system in simulation experiment using Turtlebot 2 in ROS1 and Turtlebot 3 in ROS2. We conduct hardware trials using a Clearpath Robotics Jackal UGV, highlighting its potential for real-world deployment in scenarios requiring flexible and interactive robotic behaviors.",
    "pdf_link": "https://arxiv.org/abs/2407.09890",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.09890v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09890/OverviewNLPAD.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09890v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09890/robots.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09890v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09890/1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09890v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09890/2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09890v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09890/3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09890v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09890/4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09890v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09890/5.png"
      }
    ],
    "abstract_cn": "社交机器人领域致力于让机器人更自然地与人类互动。借助GPTs和Llamas等先进LLMs，机器人已能更好地理解自然语言。本文提出一个语音引导的自主导航系统，结合Llama3和ROS，通过解析语音命令并转化为顺序动作，实现高效的任务执行。该系统在物体取送等场景中尤为关键。我们通过DRL-VO策略，使机器人在复杂社交环境中自主导航。模拟实验和硬件测试均证实了系统的实用性，尤其在需要机器人灵活互动的实际应用中展现出巨大潜力。",
    "title_cn": "利用 Llama3 大型语言模型实现自主导航的语音引导顺序规划",
    "tags": [
      "Agent",
      "机器人技术",
      "社交互动"
    ]
  },
  {
    "title": "Benchmarking LLMs for Optimization Modeling and Enhancing Reasoning via Reverse Socratic Synthesis",
    "submit_datetime": "2024年07月13日",
    "abstract": "Large language models (LLMs) have exhibited their problem-solving ability in mathematical reasoning. Solving realistic optimization (OPT) problems in industrial application scenarios requires advanced and applied math ability. However, current OPT benchmarks that merely solve linear programming are far from complex realistic situations. In this work, we propose E-OPT, a benchmark for end-to-end optimization problem-solving with human-readable inputs and outputs. E-OPT contains rich optimization problems, including linear/nonlinear programming with/without table data, which can comprehensively evaluate LLMs' solving ability. In our benchmark, LLMs are required to correctly understand the problem in E-OPT and call code solver to get precise numerical answers. Furthermore, to alleviate the data scarcity for optimization problems, and to bridge the gap between open-source LLMs on a small scale (e.g., Llama-2-7b and Llama-3-8b) and closed-source LLMs (e.g., GPT-4), we further propose a novel data synthesis method namely ReSocratic. Unlike general data synthesis methods that proceed from questions to answers, ReSocratic first incrementally synthesizes optimization scenarios with mathematical formulations step by step and then back-translates the generated scenarios into questions. In such a way, we construct the ReSocratic-29k dataset from a small seed sample pool with the powerful open-source large model DeepSeek-V2. To demonstrate the effectiveness of ReSocratic, we conduct supervised fine-tuning with ReSocratic-29k on multiple open-source models. The results show that Llama3-8b is significantly improved from 13.6% to 51.7% on E-OPT, while DeepSeek-V2 reaches 61.0%, approaching 65.5% of GPT-4.",
    "pdf_link": "https://arxiv.org/abs/2407.09887",
    "graphs": [],
    "abstract_cn": "大型语言模型 (LLM) 在数学推理中展现了其问题解决能力。然而，当前的 OPT 基准仅解决线性规划，远不能满足复杂现实情况。为此，我们提出了 E-OPT，一个具有人类可读输入和输出的端到端优化问题解决基准，包含丰富的优化问题，全面评估 LLM 的解决能力。此外，为了缓解数据稀缺性，并缩小开源与闭源 LLM 之间的差距，我们提出了 ReSocratic 数据合成方法，通过逐步合成优化场景并反向翻译成问题，构建了 ReSocratic-29k 数据集。实验表明，Llama3-8b 在 E-OPT 上的表现显著提升至 51.7%，DeepSeek-V2 达到 61.0%，接近 GPT-4 的 65.5%。",
    "title_cn": "通过反向苏格拉底合成，我们为 LLM 的优化建模和推理能力设立了基准测试。",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Building pre-train LLM Dataset for the INDIC Languages: a case study on Hindi",
    "submit_datetime": "2024年07月13日",
    "abstract": "Large language models (LLMs) demonstrated transformative capabilities in many applications that require automatically generating responses based on human instruction. However, the major challenge for building LLMs, particularly in Indic languages, is the availability of high-quality data for building foundation LLMs. In this paper, we are proposing a large pre-train dataset in Hindi useful for the Indic language Hindi. We have collected the data span across several domains including major dialects in Hindi. The dataset contains 1.28 billion Hindi tokens. We have explained our pipeline including data collection, pre-processing, and availability for LLM pre-training. The proposed approach can be easily extended to other Indic and low-resource languages and will be available freely for LLM pre-training and LLM research purposes.",
    "pdf_link": "https://arxiv.org/abs/2407.09855",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.09855v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09855/fig_datasetintro.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09855v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09855/fig_data_collection.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09855v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09855/fig_domain_distribution.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLM）在自动响应人类指令的应用中展现了革命性能力，但构建这些模型，尤其是在印度语系中，面临的主要难题是高质量基础数据集的稀缺。本文中，我们提出了一款专为印度语系中的Hindi语言设计的大型预训练数据集，涵盖了多个领域及主要方言，共计12.8亿词元。我们详细阐述了数据采集、预处理及预训练应用的完整流程。此方法不仅适用于其他印度语种及低资源语言，还将无偿开放，助力LLM的预训练与研究。",
    "title_cn": "构建针对 INDIC 语言的预训练 LLM 数据集：印地语案例研究",
    "tags": [
      "LLM应用",
      "语言技术",
      ""
    ]
  },
  {
    "title": "Investigating Low-Rank Training in Transformer Language Models: Efficiency and Scaling Analysis",
    "submit_datetime": "2024年07月13日",
    "abstract": "State-of-the-art LLMs often rely on scale with high computational costs, which has sparked a research agenda to reduce parameter counts and costs without significantly impacting performance. Our study focuses on Transformer-based LLMs, specifically applying low-rank parametrization to the computationally intensive feedforward networks (FFNs), which are less studied than attention blocks. In contrast to previous works, (i) we explore low-rank parametrization at scale, up to 1.3B parameters; (ii) within Transformer language models rather than convolutional architectures; and (iii) starting from training from scratch. Experiments on the large RefinedWeb dataset show that low-rank parametrization is both efficient (e.g., 2.6$\\times$ FFN speed-up with 32\\% parameters) and effective during training. Interestingly, these structured FFNs exhibit steeper scaling curves than the original models. Motivated by this finding, we develop the wide and structured networks surpassing the current medium-sized and large-sized Transformer in perplexity and throughput performance.",
    "pdf_link": "https://arxiv.org/abs/2407.09835",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.09835v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09835/fig_workshop.png"
      }
    ],
    "abstract_cn": "当前最先进的 LLM 依赖于高计算成本的规模，激发了减少参数数量和成本的研究。我们专注于基于 Transformer 的 LLM，特别是对计算密集型的前馈网络（FFN）应用低秩参数化。与以往不同，我们（i）大规模探索低秩参数化，高达 1.3B 参数；（ii）在 Transformer 而非卷积架构中；（iii）从零开始训练。实验显示，低秩参数化在训练中高效且有效。这些结构化 FFN 的缩放曲线比原始模型更陡峭。基于此，我们开发的宽结构网络在性能上超越了现有的大型 Transformer。",
    "title_cn": "探索 Transformer 语言模型中的低秩训练，分析其效率与规模效应。",
    "tags": [
      "LLM理论",
      "人工智能",
      "计算机科学"
    ]
  },
  {
    "title": "NativQA: Multilingual Culturally-Aligned Natural Query for LLMs",
    "submit_datetime": "2024年07月13日",
    "abstract": "Natural Question Answering (QA) datasets play a crucial role in developing and evaluating the capabilities of large language models (LLMs), ensuring their effective usage in real-world applications. Despite the numerous QA datasets that have been developed, there is a notable lack of region-specific datasets generated by native users in their own languages. This gap hinders the effective benchmarking of LLMs for regional and cultural specificities. In this study, we propose a scalable framework, NativQA, to seamlessly construct culturally and regionally aligned QA datasets in native languages, for LLM evaluation and tuning. Moreover, to demonstrate the efficacy of the proposed framework, we designed a multilingual natural QA dataset, MultiNativQA, consisting of ~72K QA pairs in seven languages, ranging from high to extremely low resource, based on queries from native speakers covering 18 topics. We benchmark the MultiNativQA dataset with open- and closed-source LLMs. We made both the framework NativQA and MultiNativQA dataset publicly available for the community. (https://nativqa.gitlab.io)",
    "pdf_link": "https://arxiv.org/abs/2407.09823",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.09823v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09823/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09823v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09823/examples_qa.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09823v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09823/data_collection_pipeline_nativqa.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09823v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09823/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09823v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09823/BLEU_scores_by_language_grouped.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09823v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09823/google_search.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09823v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09823/domain_reliability.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09823v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09823/qa_annotation_step1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09823v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09823/qa_annotation_step2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09823v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09823/arabic_graph.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09823v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09823/assamese_graph.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09823v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09823/bangla_graph.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09823v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09823/bangla_in_graph.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09823v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09823/bangladesh_english_graph.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09823v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09823/qatar_english_graph.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09823v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09823/nepali_graph.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09823v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09823/hindi_graph.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09823v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09823/turkish_graph.png"
      }
    ],
    "abstract_cn": "自然问题回答 (QA) 数据集对于评估和提升大型语言模型 (LLM) 的实际应用能力至关重要。然而，现有数据集大多缺乏区域和文化特定性，这限制了 LLM 在这些方面的基准测试。为此，我们提出了 NativQA 框架，旨在构建与特定文化和区域相符的母语 QA 数据集，以优化 LLM 的评估和调整。此外，我们创建了 MultiNativQA 数据集，包含约 72K 个多语言 QA 对，覆盖从高到极低资源语言，基于 18 个主题的母语者查询。我们通过对比开源和闭源 LLM 对该数据集的性能进行了基准测试，并将 NativQA 框架和 MultiNativQA 数据集公开，供社区使用。(https://nativqa.gitlab.io)",
    "title_cn": "NativQA：为 LLM 设计的多语言、文化对齐的自然查询系统",
    "tags": [
      "LLM应用",
      "人工智能",
      "语言学"
    ]
  },
  {
    "title": "IoT-LM: Large Multisensory Language Models for the Internet of Things",
    "submit_datetime": "2024年07月13日",
    "abstract": "The Internet of Things (IoT) network integrating billions of smart physical devices embedded with sensors, software, and communication technologies is a critical and rapidly expanding component of our modern world. The IoT ecosystem provides a rich source of real-world modalities such as motion, thermal, geolocation, imaging, depth, sensors, and audio to recognize the states of humans and physical objects. Machine learning presents a rich opportunity to automatically process IoT data at scale, enabling efficient inference for understanding human wellbeing, controlling physical devices, and interconnecting smart cities. To realize this potential, we introduce IoT-LM, an open-source large multisensory language model tailored for the IoT ecosystem. IoT-LM is enabled by two technical contributions: the first is MultiIoT, the most expansive unified IoT dataset to date, encompassing over 1.15 million samples from 12 modalities and 8 tasks prepared for multisensory pre-training and instruction-tuning. The second is a new multisensory multitask adapter layer to condition pre-trained large language models on multisensory IoT data. Not only does IoT-LM yield substantial improvements on 8 supervised IoT classification tasks, but it also demonstrates new interactive question-answering, reasoning, and dialog capabilities conditioned on IoT sensors. We release IoT-LM's data sources and new multisensory language modeling framework.",
    "pdf_link": "https://arxiv.org/abs/2407.09801",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.09801v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09801/main_image_iotlm.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09801v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09801/main_image_adapter.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09801v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09801/main_image_tune.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09801v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09801/dialog_audio.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09801v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09801/dialog_imu.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09801v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09801/all_imu.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09801v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09801/all_audio.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09801v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09801/all_cap.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09801v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09801/all_depth.png"
      }
    ],
    "abstract_cn": "物联网网络，融合了数十亿智能设备，这些设备内置传感器、软件及通信技术，正迅速成为现代社会的关键支柱。IoT生态系统提供多样化的现实数据，如运动、热能、位置、图像、深度、传感器信号及音频，助力识别人与物的状态。机器学习技术在此领域大放异彩，能高效处理海量IoT数据，进而深入洞察人类福祉、精准操控设备、并促进智能城市间的互联互通。为此，我们推出了IoT-LM——一款专为IoT环境设计的开源大型多感官语言模型。IoT-LM的诞生得益于两大技术突破：首先是MultiIoT数据集，它汇聚了超过115万份样本，涵盖12种模态与8项任务，为多感官预训练与指令调优奠定基础；其次是创新的多感官多任务适配器层，它让预训练的大型语言模型能更好地适应多感官IoT数据。IoT-LM在8项IoT分类任务中表现卓越，更展现出基于IoT传感器的全新交互式问答、推理及对话功能。我们已公开IoT-LM的数据源及多感官语言建模框架，以飨研究者。",
    "title_cn": "IoT-LM：专为物联网设计的大型多感官语言模型",
    "tags": [
      "LLM应用",
      "物联网",
      "智能城市"
    ]
  },
  {
    "title": "Uncovering Weaknesses in Neural Code Generation",
    "submit_datetime": "2024年07月13日",
    "abstract": "Code generation, the task of producing source code from prompts, has seen significant advancements with the advent of pre-trained large language models (PLMs). Despite these achievements, there lacks a comprehensive taxonomy of weaknesses about the benchmark and the generated code, which risks the community's focus on known issues at the cost of under-explored areas.\n  Our systematic study aims to fill this gap by evaluating five state-of-the-art PLMs: three larger models, CodeGen2.5 with 7 billion parameters, CodeGeeX2 with 6 billion parameters, GPT-4 Turbo, and two smaller ones, UnixCoder with 110 million parameters and CodeT5 base with 220 million parameters, across three popular datasets, CoNaLa, HumanEval Plus, and DS-1000. We assess the quality of generated code using match-based and execution-based metrics, then conduct thematic analysis to develop a taxonomy of nine types of weaknesses.\n  We dissected weakness distributions in both larger and smaller models, applying an extensive methodology that encompasses model-specific as well as collective analysis (union and intersection) across models. Our research uncovers three salient findings: 1. In the CoNaLa dataset, inaccurate prompts are a notable problem, causing all large models to fail in 26.84% of cases, with even higher failure rates of 40% for smaller models; 2. Missing pivotal semantics is a pervasive issue across benchmarks, with one or more large models omitting key semantics in 65.78% of CoNaLa tasks, and similarly high occurrences in HumanEval Plus (66.09%) and DS-1000 (80.51%); 3. All models struggle with proper API usage, a challenge amplified by vague or complex prompts.\n  Our findings aim to steer researchers towards addressing specific weaknesses and challenges in code generation. Furthermore, our annotations can offer a targeted benchmark subset for detailed analysis.",
    "pdf_link": "https://arxiv.org/abs/2407.09793",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.09793v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09793/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09793v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09793/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09793v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09793/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09793v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09793/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09793v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09793/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09793v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09793/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09793v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09793/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09793v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09793/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09793v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09793/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09793v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09793/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09793v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09793/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09793v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09793/x12.png"
      }
    ],
    "abstract_cn": "代码生成技术在预训练大型语言模型（PLMs）的推动下取得了长足进步。然而，关于基准测试和生成代码的弱点分类尚不完善，这可能导致研究焦点偏移。为此，我们评估了五个顶尖PLMs，包括三个大型模型（CodeGen2.5、CodeGeeX2、GPT-4 Turbo）和两个小型模型（UnixCoder、CodeT5 base），在CoNaLa、HumanEval Plus和DS-1000数据集上进行测试。我们通过匹配和执行指标评估代码质量，并进行了主题分析，识别出九种弱点类型。研究发现：1. 不准确的提示在CoNaLa中导致大型模型失败率高达26.84%，小型模型更甚，达40%；2. 关键语义缺失在各基准测试中普遍存在，如CoNaLa中65.78%的任务、HumanEval Plus中66.09%、DS-1000中80.51%；3. 所有模型在API使用上都面临挑战，尤其是面对模糊或复杂的提示。这些发现旨在引导研究方向，同时我们的注释也为深入分析提供了针对性的基准子集。",
    "title_cn": "探究神经代码生成模型的不足之处",
    "tags": [
      "LLM应用",
      "软件开发",
      "人工智能"
    ]
  },
  {
    "title": "Document-level Clinical Entity and Relation Extraction via Knowledge Base-Guided Generation",
    "submit_datetime": "2024年07月13日",
    "abstract": "Generative pre-trained transformer (GPT) models have shown promise in clinical entity and relation extraction tasks because of their precise extraction and contextual understanding capability. In this work, we further leverage the Unified Medical Language System (UMLS) knowledge base to accurately identify medical concepts and improve clinical entity and relation extraction at the document level. Our framework selects UMLS concepts relevant to the text and combines them with prompts to guide language models in extracting entities. Our experiments demonstrate that this initial concept mapping and the inclusion of these mapped concepts in the prompts improves extraction results compared to few-shot extraction tasks on generic language models that do not leverage UMLS. Further, our results show that this approach is more effective than the standard Retrieval Augmented Generation (RAG) technique, where retrieved data is compared with prompt embeddings to generate results. Overall, we find that integrating UMLS concepts with GPT models significantly improves entity and relation identification, outperforming the baseline and RAG models. By combining the precise concept mapping capability of knowledge-based approaches like UMLS with the contextual understanding capability of GPT, our method highlights the potential of these approaches in specialized domains like healthcare.",
    "pdf_link": "https://arxiv.org/abs/2407.10021",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10021v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10021/framework.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10021v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10021/prompts.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10021v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10021/figure2.png"
      }
    ],
    "abstract_cn": "GPT模型因其精确的抽取和上下文理解能力，在临床实体和关系抽取任务中表现出色。我们通过整合统一医学语言系统（UMLS）知识库，进一步提升了文档级临床实体和关系的识别精度。我们的框架通过筛选与文本相关的UMLS概念，并将其融入提示中，引导语言模型更精准地抽取实体。实验结果显示，这种结合UMLS的概念映射方法，相较于未使用UMLS的通用语言模型，在少样本抽取任务中表现更优。同时，我们的方法也超越了传统的检索增强生成（RAG）技术。总体来看，将UMLS与GPT模型结合，不仅提升了实体和关系的识别效率，也为医疗等专业领域的方法应用开辟了新路径。",
    "title_cn": "利用知识库引导生成技术，实现文档级临床实体与关系的精准抽取。",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Fine-grained Analysis of In-context Linear Estimation: Data, Architecture, and Beyond",
    "submit_datetime": "2024年07月13日",
    "abstract": "Recent research has shown that Transformers with linear attention are capable of in-context learning (ICL) by implementing a linear estimator through gradient descent steps. However, the existing results on the optimization landscape apply under stylized settings where task and feature vectors are assumed to be IID and the attention weights are fully parameterized. In this work, we develop a stronger characterization of the optimization and generalization landscape of ICL through contributions on architectures, low-rank parameterization, and correlated designs: (1) We study the landscape of 1-layer linear attention and 1-layer H3, a state-space model. Under a suitable correlated design assumption, we prove that both implement 1-step preconditioned gradient descent. We show that thanks to its native convolution filters, H3 also has the advantage of implementing sample weighting and outperforming linear attention in suitable settings. (2) By studying correlated designs, we provide new risk bounds for retrieval augmented generation (RAG) and task-feature alignment which reveal how ICL sample complexity benefits from distributional alignment. (3) We derive the optimal risk for low-rank parameterized attention weights in terms of covariance spectrum. Through this, we also shed light on how LoRA can adapt to a new distribution by capturing the shift between task covariances. Experimental results corroborate our theoretical findings. Overall, this work explores the optimization and risk landscape of ICL in practically meaningful settings and contributes to a more thorough understanding of its mechanics.",
    "pdf_link": "https://arxiv.org/abs/2407.10005",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.10005v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10005/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10005v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10005/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10005v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10005/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10005v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10005/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10005v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10005/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10005v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10005/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10005v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10005/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10005v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10005/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10005v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10005/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10005v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10005/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10005v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10005/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10005v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10005/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10005v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10005/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10005v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10005/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.10005v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.10005/x15.png"
      }
    ],
    "abstract_cn": "最新研究显示，通过线性估计器和梯度下降步骤，采用线性注意力的Transformer能够实现上下文学习（ICL）。然而，现有优化分析仅限于理想化场景，其中任务与特征向量独立同分布，且注意力权重完全参数化。本研究深入探讨了ICL的优化与泛化机制，通过以下创新：（1）分析了单层线性注意及H3状态空间模型的优化特性，证明在特定条件下两者均能执行一步预处理梯度下降，且H3凭借其内置卷积滤波器，在适当场景下可实现样本加权并超越线性注意。（2）针对检索增强生成（RAG）与任务-特征对齐，提出新的风险边界，揭示了分布对齐如何降低ICL的样本复杂度。（3）推导了低秩参数化注意力权重的最优风险，并阐释了LoRA如何通过捕捉任务协方差变化适应新分布。实验验证了理论成果，全面深化了对ICL机制的理解。",
    "title_cn": "深入探讨上下文线性估计的细粒度分析，涵盖数据、架构及其他相关因素。",
    "tags": [
      "LLM理论",
      "人工智能",
      "机器学习"
    ]
  },
  {
    "title": "Mitigating Entity-Level Hallucination in Large Language Models",
    "submit_datetime": "2024年07月12日",
    "abstract": "The emergence of Large Language Models (LLMs) has revolutionized how users access information, shifting from traditional search engines to direct question-and-answer interactions with LLMs. However, the widespread adoption of LLMs has revealed a significant challenge known as hallucination, wherein LLMs generate coherent yet factually inaccurate responses. This hallucination phenomenon has led to users' distrust in information retrieval systems based on LLMs. To tackle this challenge, this paper proposes Dynamic Retrieval Augmentation based on hallucination Detection (DRAD) as a novel method to detect and mitigate hallucinations in LLMs. DRAD improves upon traditional retrieval augmentation by dynamically adapting the retrieval process based on real-time hallucination detection. It features two main components: Real-time Hallucination Detection (RHD) for identifying potential hallucinations without external models, and Self-correction based on External Knowledge (SEK) for correcting these errors using external knowledge. Experiment results show that DRAD demonstrates superior performance in both detecting and mitigating hallucinations in LLMs. All of our code and data are open-sourced at https://github.com/oneal2000/EntityHallucination.",
    "pdf_link": "https://arxiv.org/abs/2407.09417",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.09417v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09417/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09417v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09417/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09417v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09417/all4.png"
      }
    ],
    "abstract_cn": "随着大型语言模型 (LLM) 的兴起，用户获取信息的方式已从传统搜索引擎转向与 LLM 的直接问答交互。然而，LLM 的普及也暴露出一个严重问题——幻觉现象，即生成看似合理但事实错误的信息。这引发了用户对基于 LLM 的信息检索系统的疑虑。为此，本文提出了一种基于幻觉检测的动态检索增强方法 (DRAD)，旨在有效识别并修正 LLM 中的幻觉。DRAD 通过实时幻觉检测 (RHD) 和基于外部知识的自我修正 (SEK) 两大核心机制，动态优化检索过程，显著提升了幻觉检测与修正的效率。实验证明，DRAD 在这两方面均表现卓越。相关代码与数据已开源，详见 https://github.com/oneal2000/EntityHallucination。",
    "title_cn": "缓解大型语言模型中的实体级幻觉问题",
    "tags": [
      "LLM应用",
      "信息检索",
      "人工智能"
    ]
  },
  {
    "title": "PersonaRAG: Enhancing Retrieval-Augmented Generation Systems with User-Centric Agents",
    "submit_datetime": "2024年07月12日",
    "abstract": "Large Language Models (LLMs) struggle with generating reliable outputs due to outdated knowledge and hallucinations. Retrieval-Augmented Generation (RAG) models address this by enhancing LLMs with external knowledge, but often fail to personalize the retrieval process. This paper introduces PersonaRAG, a novel framework incorporating user-centric agents to adapt retrieval and generation based on real-time user data and interactions. Evaluated across various question answering datasets, PersonaRAG demonstrates superiority over baseline models, providing tailored answers to user needs. The results suggest promising directions for user-adapted information retrieval systems.",
    "pdf_link": "https://arxiv.org/abs/2407.09394",
    "graphs": [],
    "abstract_cn": "大型语言模型因知识陈旧和产生幻觉而难以提供可靠输出。RAG 模型虽通过结合外部知识改善了这一问题，但个性化检索方面仍有不足。本文提出的 PersonaRAG 框架，通过集成以用户为核心的代理，实时根据用户数据和互动调整检索与生成策略，显著提升了问答任务中的表现，为用户提供精准答案。这一成果预示着个性化信息检索系统的广阔前景。",
    "title_cn": "PersonaRAG：借助以用户为中心的代理，提升检索增强生成系统的性能",
    "tags": [
      "RAG",
      "信息检索",
      "个性化服务"
    ]
  },
  {
    "title": "Context Embeddings for Efficient Answer Generation in RAG",
    "submit_datetime": "2024年07月12日",
    "abstract": "Retrieval-Augmented Generation (RAG) allows overcoming the limited knowledge of LLMs by extending the input with external information. As a consequence, the contextual inputs to the model become much longer which slows down decoding time directly translating to the time a user has to wait for an answer. We address this challenge by presenting COCOM, an effective context compression method, reducing long contexts to only a handful of Context Embeddings speeding up the generation time by a large margin. Our method allows for different compression rates trading off decoding time for answer quality. Compared to earlier methods, COCOM allows for handling multiple contexts more effectively, significantly reducing decoding time for long inputs. Our method demonstrates a speed-up of up to 5.69 $\\times$ while achieving higher performance compared to existing efficient context compression methods.",
    "pdf_link": "https://arxiv.org/abs/2407.09252",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.09252v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09252/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09252v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09252/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09252v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09252/x3.png"
      }
    ],
    "abstract_cn": "RAG 通过引入外部信息扩展输入，突破了 LLMs 的知识局限。然而，这使得上下文输入变长，直接延长了用户的等待时间。为此，我们推出了 COCOM，一种高效的上下文压缩技术，将冗长的上下文精简为几个关键嵌入，大幅缩短生成时间。COCOM 允许根据需求调整压缩率，平衡解码速度与答案质量。相较于传统方法，COCOM 在处理复杂上下文时更为出色，显著提升了处理长输入的效率。实验表明，我们的方法在保持高性能的同时，最高可实现 5.69 倍的加速。",
    "title_cn": "RAG 中，上下文嵌入助力高效答案生成",
    "tags": [
      "RAG",
      "人工智能",
      "软件开发"
    ]
  },
  {
    "title": "Security Matrix for Multimodal Agents on Mobile Devices: A Systematic and Proof of Concept Study",
    "submit_datetime": "2024年07月12日",
    "abstract": "The rapid progress in the reasoning capability of the Multi-modal Large Language Models (MLLMs) has triggered the development of autonomous agent systems on mobile devices. MLLM-based mobile agent systems consist of perception, reasoning, memory, and multi-agent collaboration modules, enabling automatic analysis of user instructions and the design of task pipelines with only natural language and device screenshots as inputs. Despite the increased human-machine interaction efficiency, the security risks of MLLM-based mobile agent systems have not been systematically studied. Existing security benchmarks for agents mainly focus on Web scenarios, and the attack techniques against MLLMs are also limited in the mobile agent scenario. To close these gaps, this paper proposes a mobile agent security matrix covering 3 functional modules of the agent systems. Based on the security matrix, this paper proposes 4 realistic attack paths and verifies these attack paths through 8 attack methods. By analyzing the attack results, this paper reveals that MLLM-based mobile agent systems are not only vulnerable to multiple traditional attacks, but also raise new security concerns previously unconsidered. This paper highlights the need for security awareness in the design of MLLM-based systems and paves the way for future research on attacks and defense methods.",
    "pdf_link": "https://arxiv.org/abs/2407.09295",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.09295v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09295/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09295v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09295/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09295v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09295/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09295v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09295/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09295v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09295/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09295v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09295/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09295v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09295/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09295v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09295/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09295v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09295/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09295v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09295/x10.png"
      }
    ],
    "abstract_cn": "多模态大型语言模型（MLLMs）的推理能力飞速提升，催生了移动设备上的自主代理系统。这些系统集感知、推理、记忆与多代理协作于一体，仅凭自然语言和设备截图就能自动解析用户指令，构建任务流程。然而，尽管人机交互效率大增，这些系统的安全风险却未被深入探讨。当前的安全评估多聚焦于网络环境，而针对移动代理场景的攻击手段也相对有限。为此，本文构建了一个移动代理安全矩阵，覆盖了系统的三大核心模块，并设计了四种实际攻击路径，通过八种攻击手段进行验证。研究显示，这些系统不仅面临传统攻击的威胁，还引发了新的安全隐忧。本文强调，在设计基于MLLM的系统时，必须提升安全意识，为未来的攻防研究奠定基础。",
    "title_cn": "移动设备多模态代理安全矩阵：系统性研究与概念验证",
    "tags": [
      "Agent",
      "移动设备",
      "网络安全"
    ]
  },
  {
    "title": "Instruction Following with Goal-Conditioned Reinforcement Learning in Virtual Environments",
    "submit_datetime": "2024年07月12日",
    "abstract": "In this study, we address the issue of enabling an artificial intelligence agent to execute complex language instructions within virtual environments. In our framework, we assume that these instructions involve intricate linguistic structures and multiple interdependent tasks that must be navigated successfully to achieve the desired outcomes. To effectively manage these complexities, we propose a hierarchical framework that combines the deep language comprehension of large language models with the adaptive action-execution capabilities of reinforcement learning agents. The language module (based on LLM) translates the language instruction into a high-level action plan, which is then executed by a pre-trained reinforcement learning agent. We have demonstrated the effectiveness of our approach in two different environments: in IGLU, where agents are instructed to build structures, and in Crafter, where agents perform tasks and interact with objects in the surrounding environment according to language commands.",
    "pdf_link": "https://arxiv.org/abs/2407.09287",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.09287v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09287/visual-abstract.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09287v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09287/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09287v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09287/scheme.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09287v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09287/C13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09287v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09287/C96.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09287v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09287/C114.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09287v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09287/collect_wood.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09287v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09287/collect_coal.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09287v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09287/collect_stone.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09287v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09287/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09287v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09287/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09287v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09287/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09287v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09287/x5.png"
      }
    ],
    "abstract_cn": "本研究旨在让AI代理在虚拟环境中顺利执行复杂语言指令。我们设计了一个分层框架，融合了大型语言模型的深度理解和强化学习代理的灵活行动能力。语言模块将指令转化为行动蓝图，由强化学习代理执行。我们在IGLU和Crafter两个环境中验证了这一方法的有效性，无论是构建结构还是执行任务与环境互动，均表现出色。",
    "title_cn": "虚拟环境中，指令遵循与目标条件强化学习相结合",
    "tags": [
      "Agent",
      "",
      "人工智能"
    ]
  },
  {
    "title": "SPIQA: A Dataset for Multimodal Question Answering on Scientific Papers",
    "submit_datetime": "2024年07月12日",
    "abstract": "Seeking answers to questions within long scientific research articles is a crucial area of study that aids readers in quickly addressing their inquiries. However, existing question-answering (QA) datasets based on scientific papers are limited in scale and focus solely on textual content. To address this limitation, we introduce SPIQA (Scientific Paper Image Question Answering), the first large-scale QA dataset specifically designed to interpret complex figures and tables within the context of scientific research articles across various domains of computer science. Leveraging the breadth of expertise and ability of multimodal large language models (MLLMs) to understand figures, we employ automatic and manual curation to create the dataset. We craft an information-seeking task involving multiple images that cover a wide variety of plots, charts, tables, schematic diagrams, and result visualizations. SPIQA comprises 270K questions divided into training, validation, and three different evaluation splits. Through extensive experiments with 12 prominent foundational models, we evaluate the ability of current multimodal systems to comprehend the nuanced aspects of research articles. Additionally, we propose a Chain-of-Thought (CoT) evaluation strategy with in-context retrieval that allows fine-grained, step-by-step assessment and improves model performance. We further explore the upper bounds of performance enhancement with additional textual information, highlighting its promising potential for future research and the dataset's impact on revolutionizing how we interact with scientific literature.",
    "pdf_link": "https://arxiv.org/abs/2407.09413",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.09413v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09413/Tasks_2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09413v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09413/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09413v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09413/test-A_caption_2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09413v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09413/test-B_caption_2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09413v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09413/test-C_caption_2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09413v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09413/Visualization.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09413v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09413/resolution_ablation.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09413v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09413/Supplementary_Num_Papers_Year_2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09413v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09413/questions_histogram.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09413v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09413/answers_histogram.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09413v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09413/rationale_histogram.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09413v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09413/ui_full_screen.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09413v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09413/crowdworkers_lack_expertise.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09413v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09413/Supplementary_Additional_visualization_1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09413v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09413/Supplementary_Additional_Visualization_2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09413v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09413/Supplementary_Additional_Visualization_3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09413v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09413/Supplementary_Error_Analysis.png"
      }
    ],
    "abstract_cn": "在长篇科学研究文章中寻找答案是一个关键的研究领域，有助于读者快速解决他们的疑问。然而，基于科学论文的现有问答（QA）数据集规模有限，且仅关注文本内容。为此，我们推出了SPIQA（科学论文图像问答），这是首个专门设计用于解读科学研究文章中复杂图表和表格的大规模QA数据集，涵盖计算机科学各个领域。我们利用多模态大型语言模型（MLLMs）的广泛专业知识和理解图表的能力，通过自动和手动筛选创建了这一数据集。SPIQA包含27万个问题，分为训练、验证和三种不同的评估分组。通过与12个著名基础模型的广泛实验，我们评估了当前多模态系统理解研究文章细微差别的能力。此外，我们提出了一种带有上下文检索的思维链（CoT）评估策略，允许逐步细致评估并提高模型性能。我们还探讨了通过额外文本信息提升性能的上限，强调了其对未来研究和数据集在革新我们与科学文献互动方式方面的潜在影响。",
    "title_cn": "SPIQA 数据集：专为科学论文的多模态问答设计",
    "tags": [
      "LLM应用",
      "科学研究",
      "计算机科学"
    ]
  },
  {
    "title": "Unifying Sequences, Structures, and Descriptions for Any-to-Any Protein Generation with the Large Multimodal Model HelixProtX",
    "submit_datetime": "2024年07月12日",
    "abstract": "Proteins are fundamental components of biological systems and can be represented through various modalities, including sequences, structures, and textual descriptions. Despite the advances in deep learning and scientific large language models (LLMs) for protein research, current methodologies predominantly focus on limited specialized tasks -- often predicting one protein modality from another. These approaches restrict the understanding and generation of multimodal protein data. In contrast, large multimodal models have demonstrated potential capabilities in generating any-to-any content like text, images, and videos, thus enriching user interactions across various domains. Integrating these multimodal model technologies into protein research offers significant promise by potentially transforming how proteins are studied. To this end, we introduce HelixProtX, a system built upon the large multimodal model, aiming to offer a comprehensive solution to protein research by supporting any-to-any protein modality generation. Unlike existing methods, it allows for the transformation of any input protein modality into any desired protein modality. The experimental results affirm the advanced capabilities of HelixProtX, not only in generating functional descriptions from amino acid sequences but also in executing critical tasks such as designing protein sequences and structures from textual descriptions. Preliminary findings indicate that HelixProtX consistently achieves superior accuracy across a range of protein-related tasks, outperforming existing state-of-the-art models. By integrating multimodal large models into protein research, HelixProtX opens new avenues for understanding protein biology, thereby promising to accelerate scientific discovery.",
    "pdf_link": "https://arxiv.org/abs/2407.09274",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.09274v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09274/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09274v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09274/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09274v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09274/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09274v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09274/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09274v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09274/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09274v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09274/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09274v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09274/x7.png"
      }
    ],
    "abstract_cn": "蛋白质作为生物系统的基石，可通过序列、结构和文本等多种形式展现其特性。尽管深度学习与大型科学语言模型在蛋白质研究领域取得了显著进展，但现有方法多聚焦于单一任务，如从一种形式预测另一种。这些方法局限了对多模态蛋白质数据的深入理解与生成。相反，大型多模态模型已展现出跨领域生成内容的潜力，如文本、图像和视频，极大地丰富了用户交互体验。将此类多模态技术融入蛋白质研究，有望革新我们对蛋白质的认知方式。为此，我们推出了HelixProtX系统，该系统基于大型多模态模型，旨在通过支持任意蛋白质形式的转换，为蛋白质研究提供全面解决方案。实验表明，HelixProtX不仅能够从氨基酸序列生成功能描述，还能根据文本描述设计蛋白质序列和结构，其性能在多项任务中超越了现有顶尖模型。通过整合多模态大型模型，HelixProtX为蛋白质生物学研究开辟了新路径，有望推动科学发现的加速。",
    "title_cn": "HelixProtX 大型多模态模型整合序列、结构与描述，实现任意蛋白质间的生成。",
    "tags": [
      "LLM应用",
      "生物学",
      "蛋白质研究"
    ]
  },
  {
    "title": "DART: An Automated End-to-End Object Detection Pipeline with Data Diversification, Open-Vocabulary Bounding Box Annotation, Pseudo-Label Review, and Model Training",
    "submit_datetime": "2024年07月12日",
    "abstract": "Swift and accurate detection of specified objects is crucial for many industrial applications, such as safety monitoring on construction sites. However, traditional approaches rely heavily on arduous manual annotation and data collection, which struggle to adapt to ever-changing environments and novel target objects. To address these limitations, this paper presents DART, an automated end-to-end pipeline designed to streamline the entire workflow of an object detection application from data collection to model deployment. DART eliminates the need for human labeling and extensive data collection while excelling in diverse scenarios. It employs a subject-driven image generation module (DreamBooth with SDXL) for data diversification, followed by an annotation stage where open-vocabulary object detection (Grounding DINO) generates bounding box annotations for both generated and original images. These pseudo-labels are then reviewed by a large multimodal model (GPT-4o) to guarantee credibility before serving as ground truth to train real-time object detectors (YOLO). We apply DART to a self-collected dataset of construction machines named Liebherr Product, which contains over 15K high-quality images across 23 categories. The current implementation of DART significantly increases average precision (AP) from 0.064 to 0.832. Furthermore, we adopt a modular design for DART to ensure easy exchangeability and extensibility. This allows for a smooth transition to more advanced algorithms in the future, seamless integration of new object categories without manual labeling, and adaptability to customized environments without extra data collection. The code and dataset are released at https://github.com/chen-xin-94/DART.",
    "pdf_link": "https://arxiv.org/abs/2407.09174",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/ann_gpt.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/ann_0.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/ann_1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/ann_2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/n_img_per_category_stacked.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/ratio.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/gdino_score.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/confusion_matrix_gpt4o_human.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/confusion_matrix_human_human.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/confusion_matrix_0.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/confusion_matrix_1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/yolo.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/00245.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/00265.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/00268.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/00269.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/cloudy_construction_site_0.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/underground_construction_7.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/right_side_3.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/multiple_machines_sunny_site_5.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/a00241.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/a09886.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/a09888.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/09884.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/03917.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/05241.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/10116.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/05224.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/00231.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/predictions_1.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/instance_distribution.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/predictions_2.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/01849.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/01852.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/01867.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/01870.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/rainy_construction_site_7.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/underground_construction_8.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/industrial_area_1.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/multiple_machines_harbor_2.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/02752.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/02758.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/02759.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/02807.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/desert_construction_2.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/industrial_site_1.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/rainy_construction_site_2.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/snowy_day_7.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/02864.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/02867.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/02883.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/02943.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/foggy_morning_9.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/windy_day_1.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/riverbank_construction_9.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/multiple_machines_harbor_7.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/03200.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/03872.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/03875.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/03876.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/mountain_construction_7.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/urban_parking_lot_2.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/wind_farm_construction_7.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/railway_construction_5.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/03000.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/03002.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/03003.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/03004.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/skyscraper_construction_5.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/sunny_construction_site_1.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/urban_demolition_0.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/large_scale_construction_3.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/image_grid_orig_aa.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/image_grid_orig_da.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/image_grid_gen_d.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/00012.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/00017.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/00018.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/00019.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/forest_construction_6.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/nighttime_construction_4.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/suburban_construction_1.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/multiple_machines_rural_area_4.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/00012.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/00017.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/00018.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/00019.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/forest_construction_4.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/nighttime_construction_7.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/suburban_construction_7.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09174v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09174/multiple_machines_rural_area_4.jpg"
      }
    ],
    "abstract_cn": "在工业应用中，如建筑工地的安全监控，快速准确地检测特定对象至关重要。传统方法依赖繁琐的手动标注和数据收集，难以适应多变的环境和新对象。为此，我们提出了DART，一个自动化端到端流程，简化对象检测的全流程，无需人工标注和大量数据收集，适应性强。DART通过主题驱动的图像生成模块（DreamBooth with SDXL）丰富数据，再由开放词汇对象检测（Grounding DINO）生成标注，经大型多模态模型（GPT-4o）审核后，用于训练实时检测器（YOLO）。我们在自建的建筑机械数据集Liebherr Product上应用DART，显著提升平均精度（AP）至0.832。DART的模块化设计确保了未来算法的升级、新类别的无缝集成及定制环境的适应性。相关代码和数据集已公开于https://github.com/chen-xin-94/DART。",
    "title_cn": "DART 是一个全自动的物体检测流程，集成了数据多样化、开放词汇的边界框标注、伪标签审核以及模型训练。",
    "tags": [
      "LLM应用",
      "",
      "工业安全"
    ]
  },
  {
    "title": "AI-Powered Immersive Assistance for Interactive Task Execution in Industrial Environments",
    "submit_datetime": "2024年07月12日",
    "abstract": "Many industrial sectors rely on well-trained employees that are able to operate complex machinery. In this work, we demonstrate an AI-powered immersive assistance system that supports users in performing complex tasks in industrial environments. Specifically, our system leverages a VR environment that resembles a juice mixer setup. This digital twin of a physical setup simulates complex industrial machinery used to mix preparations or liquids (e.g., similar to the pharmaceutical industry) and includes various containers, sensors, pumps, and flow controllers. This setup demonstrates our system's capabilities in a controlled environment while acting as a proof-of-concept for broader industrial applications. The core components of our multimodal AI assistant are a large language model and a speech-to-text model that process a video and audio recording of an expert performing the task in a VR environment. The video and speech input extracted from the expert's video enables it to provide step-by-step guidance to support users in executing complex tasks. This demonstration showcases the potential of our AI-powered assistant to reduce cognitive load, increase productivity, and enhance safety in industrial environments.",
    "pdf_link": "https://arxiv.org/abs/2407.09147",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.09147v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09147/juicemixer2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09147v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09147/juicemixer8.png"
      }
    ],
    "abstract_cn": "许多行业依赖熟练员工操作复杂机械。我们开发了一款AI辅助系统，通过VR模拟果汁混合场景，帮助用户在工业环境中完成复杂任务。该系统模拟了制药等行业中用于混合原料的复杂机械，并配备了多种设备和传感器。在受控环境中，这一设置不仅展示了系统的功能，也为更广泛的应用提供了概念验证。我们的AI助手结合了大型语言模型和语音识别技术，通过分析专家在VR中的操作视频，为用户提供详细指导。这一创新展示了AI助手在减轻认知负担、提升效率和保障安全方面的巨大潜力。",
    "title_cn": "AI 赋能的沉浸式辅助，助力工业环境中的交互任务执行",
    "tags": [
      "LLM应用",
      "制造业",
      "虚拟现实"
    ]
  },
  {
    "title": "Refusing Safe Prompts for Multi-modal Large Language Models",
    "submit_datetime": "2024年07月12日",
    "abstract": "Multimodal large language models (MLLMs) have become the cornerstone of today's generative AI ecosystem, sparking intense competition among tech giants and startups. In particular, an MLLM generates a text response given a prompt consisting of an image and a question. While state-of-the-art MLLMs use safety filters and alignment techniques to refuse unsafe prompts, in this work, we introduce MLLM-Refusal, the first method that induces refusals for safe prompts. In particular, our MLLM-Refusal optimizes a nearly-imperceptible refusal perturbation and adds it to an image, causing target MLLMs to likely refuse a safe prompt containing the perturbed image and a safe question. Specifically, we formulate MLLM-Refusal as a constrained optimization problem and propose an algorithm to solve it. Our method offers competitive advantages for MLLM model providers by potentially disrupting user experiences of competing MLLMs, since competing MLLM's users will receive unexpected refusals when they unwittingly use these perturbed images in their prompts. We evaluate MLLM-Refusal on four MLLMs across four datasets, demonstrating its effectiveness in causing competing MLLMs to refuse safe prompts while not affecting non-competing MLLMs. Furthermore, we explore three potential countermeasures -- adding Gaussian noise, DiffPure, and adversarial training. Our results show that they are insufficient: though they can mitigate MLLM-Refusal's effectiveness, they also sacrifice the accuracy and/or efficiency of the competing MLLM. The code is available at https://github.com/Sadcardation/MLLM-Refusal.",
    "pdf_link": "https://arxiv.org/abs/2407.09050",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.09050v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09050/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09050v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09050/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09050v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09050/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09050v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09050/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09050v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09050/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09050v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09050/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09050v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09050/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09050v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09050/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09050v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09050/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09050v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09050/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09050v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09050/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09050v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09050/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09050v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09050/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09050v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09050/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09050v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09050/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09050v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09050/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09050v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09050/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09050v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09050/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09050v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09050/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09050v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09050/x20.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09050v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09050/x21.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09050v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09050/x22.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09050v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09050/x23.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09050v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09050/x24.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09050v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09050/x25.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09050v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09050/x26.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09050v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09050/x27.png"
      }
    ],
    "abstract_cn": "多模态大型语言模型（MLLMs）已成为生成式AI领域的核心，激发了科技界的热烈竞争。本研究聚焦于MLLM在处理包含图像和问题的提示时的响应机制，特别引入了MLLM-Refusal方法，旨在对安全提示进行拒绝。通过优化微妙的图像扰动，我们的方法能使目标MLLM对安全提示产生拒绝反应。这一创新不仅为模型提供商带来了竞争优势，还通过实验证明了其在多个模型和数据集上的有效性。尽管存在一些反制措施，如添加噪声或对抗训练，但这些方法在减轻拒绝效果的同时，也影响了模型的性能。详细代码已公开在GitHub上，供进一步研究与应用。",
    "title_cn": "多模态大型语言模型中拒绝安全提示",
    "tags": [
      "LLM应用",
      "人工智能",
      "计算机视觉"
    ]
  },
  {
    "title": "FairyLandAI: Personalized Fairy Tales utilizing ChatGPT and DALLE-3",
    "submit_datetime": "2024年07月12日",
    "abstract": "In the diverse world of AI-driven storytelling, there is a unique opportunity to engage young audiences with customized, and personalized narratives. This paper introduces FairyLandAI an innovative Large Language Model (LLM) developed through OpenAI's API, specifically crafted to create personalized fairytales for children. The distinctive feature of FairyLandAI is its dual capability: it not only generates stories that are engaging, age-appropriate, and reflective of various traditions but also autonomously produces imaginative prompts suitable for advanced image generation tools like GenAI and Dalle-3, thereby enriching the storytelling experience. FairyLandAI is expertly tailored to resonate with the imaginative worlds of children, providing narratives that are both educational and entertaining and in alignment with the moral values inherent in different ages. Its unique strength lies in customizing stories to match individual children's preferences and cultural backgrounds, heralding a new era in personalized storytelling. Further, its integration with image generation technology offers a comprehensive narrative experience that stimulates both verbal and visual creativity. Empirical evaluations of FairyLandAI demonstrate its effectiveness in crafting captivating stories for children, which not only entertain but also embody the values and teachings of diverse traditions. This model serves as an invaluable tool for parents and educators, supporting them in imparting meaningful moral lessons through engaging narratives. FairyLandAI represents a pioneering step in using LLMs, particularly through OpenAI's API, for educational and cultural enrichment, making complex moral narratives accessible and enjoyable for young, imaginative minds.",
    "pdf_link": "https://arxiv.org/abs/2407.09467",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.09467v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09467/fairyland_diagramm.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09467v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09467/generate_1.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09467v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09467/generate.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09467v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09467/library.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09467v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09467/login.jpg"
      }
    ],
    "abstract_cn": "在AI叙事的丰富世界中，我们有机会通过定制和个性化的故事吸引年轻观众。本文介绍的FairyLandAI，是一款通过OpenAI的API精心打造的大型语言模型，专为儿童创作个性化童话。FairyLandAI的独特之处在于其双重功能：它不仅能生成适合儿童年龄、反映多元文化的引人故事，还能自动生成激发高级图像工具如GenAI和Dalle-3创造力的提示，从而丰富叙事体验。该模型特别设计，以契合儿童的想象世界，提供既寓教于乐又符合不同年龄道德观的叙事。其独特之处在于根据儿童的个人喜好和文化背景定制故事，开启了个性化叙事的新篇章。同时，它与图像生成技术的结合，为儿童提供了全面的叙事体验，激发他们的语言和视觉创造力。实证研究表明，FairyLandAI能有效创作出既娱乐又富含多元文化价值观的故事。对于家长和教育者而言，FairyLandAI是一个宝贵的工具，帮助他们通过吸引人的故事传递深刻的道德教育。该模型标志着利用LLM，特别是通过OpenAI的API，进行教育和文化提升的创新步伐，使复杂的道德叙事对年轻、富有想象力的儿童变得既易懂又享受。",
    "title_cn": "FairyLandAI：借助 ChatGPT 与 DALLE-3，打造专属童话世界",
    "tags": [
      "LLM应用",
      "",
      ""
    ]
  },
  {
    "title": "Human-like Episodic Memory for Infinite Context LLMs",
    "submit_datetime": "2024年07月12日",
    "abstract": "Large language models (LLMs) have shown remarkable capabilities, but still struggle with processing extensive contexts, limiting their ability to maintain coherence and accuracy over long sequences. In contrast, the human brain excels at organising and retrieving episodic experiences across vast temporal scales, spanning a lifetime. In this work, we introduce EM-LLM, a novel approach that integrates key aspects of human episodic memory and event cognition into LLMs, enabling them to effectively handle practically infinite context lengths while maintaining computational efficiency. EM-LLM organises sequences of tokens into coherent episodic events using a combination of Bayesian surprise and graph-theoretic boundary refinement in an on-line fashion. When needed, these events are retrieved through a two-stage memory process, combining similarity-based and temporally contiguous retrieval for efficient and human-like access to relevant information. Experiments on the LongBench dataset demonstrate EM-LLM's superior performance, outperforming the state-of-the-art InfLLM model with an overall relative improvement of 4.3% across various tasks, including a 33% improvement on the PassageRetrieval task. Furthermore, our analysis reveals strong correlations between EM-LLM's event segmentation and human-perceived events, suggesting a bridge between this artificial system and its biological counterpart. This work not only advances LLM capabilities in processing extended contexts but also provides a computational framework for exploring human memory mechanisms, opening new avenues for interdisciplinary research in AI and cognitive science.",
    "pdf_link": "https://arxiv.org/abs/2407.09450",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.09450v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09450/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09450v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09450/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09450v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09450/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09450v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09450/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09450v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09450/x5.png"
      }
    ],
    "abstract_cn": "尽管大型语言模型 (LLM) 展现了卓越能力，但在处理广泛上下文时仍显不足，影响了长序列的连贯性与准确性。相比之下，人脑在组织和检索一生中的情节体验方面表现出色。为此，我们提出了 EM-LLM，一种创新方法，将人类情节记忆与事件认知融入 LLM，使其能高效处理无限长度的上下文。EM-LLM 利用贝叶斯惊奇与图论边界细化在线组织令牌序列为连贯情节事件，并通过两阶段记忆过程，结合相似性与时间连续性检索，实现类人高效信息访问。实验表明，EM-LLM 在 LongBench 数据集上超越了 InfLLM 模型，总体性能提升 4.3%，尤其在 PassageRetrieval 任务上提高了 33%。分析还显示，EM-LLM 的事件分割与人类感知高度一致，架起了人工与生物系统的桥梁。此研究不仅增强了 LLM 的上下文处理能力，还为探索人类记忆机制提供了计算框架，推动了 AI 与认知科学的交叉研究。",
    "title_cn": "为无限上下文 LLM 设计类人情节记忆",
    "tags": [
      "LLM应用",
      "人工智能",
      "认知科学"
    ]
  },
  {
    "title": "ASTPrompter: Weakly Supervised Automated Language Model Red-Teaming to Identify Likely Toxic Prompts",
    "submit_datetime": "2024年07月12日",
    "abstract": "Typical schemes for automated red-teaming large language models (LLMs) focus on discovering prompts that trigger a frozen language model (the defender) to generate toxic text. This often results in the prompting model (the adversary) producing text that is unintelligible and unlikely to arise. Here, we propose a reinforcement learning formulation of the LLM red-teaming task which allows us to discover prompts that both (1) trigger toxic outputs from a frozen defender and (2) have low perplexity as scored by the defender. We argue these cases are most pertinent in a red-teaming setting because of their likelihood to arise during normal use of the defender model. We solve this formulation through a novel online and weakly supervised variant of Identity Preference Optimization (IPO) on GPT-2 and GPT-2 XL defenders. We demonstrate that our policy is capable of generating likely prompts that also trigger toxicity. Finally, we qualitatively analyze learned strategies, trade-offs of likelihood and toxicity, and discuss implications. Source code is available for this project at: https://github.com/sisl/ASTPrompter/.",
    "pdf_link": "https://arxiv.org/abs/2407.09447",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.09447v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09447/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09447v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09447/x2.png"
      }
    ],
    "abstract_cn": "我们提出了一种强化学习方法，用于自动化测试大型语言模型（LLM）的安全性，专注于发现既能触发有毒输出又能保持低困惑度的提示。这种方法通过在 GPT-2 和 GPT-2 XL 模型上应用一种新颖的在线和弱监督的身份偏好优化（IPO）变体来实现。我们的策略不仅能生成可能的提示，还能触发有毒性，从而在正常使用模型时更可能出现。我们还对学习到的策略、可能性和有毒性之间的权衡进行了定性分析，并讨论了其潜在影响。项目源代码已公开，可在 GitHub 上获取。",
    "title_cn": "ASTPrompter：通过弱监督自动化手段，对语言模型进行红队测试，以识别潜在的有毒提示。",
    "tags": [
      "LLM应用",
      "软件测试",
      "人工智能安全"
    ]
  },
  {
    "title": "MUSCLE: A Model Update Strategy for Compatible LLM Evolution",
    "submit_datetime": "2024年07月12日",
    "abstract": "Large Language Models (LLMs) are frequently updated due to data or architecture changes to improve their performance. When updating models, developers often focus on increasing overall performance metrics with less emphasis on being compatible with previous model versions. However, users often build a mental model of the functionality and capabilities of a particular machine learning model they are interacting with. They have to adapt their mental model with every update -- a draining task that can lead to user dissatisfaction. In practice, fine-tuned downstream task adapters rely on pretrained LLM base models. When these base models are updated, these user-facing downstream task models experience instance regression or negative flips -- previously correct instances are now predicted incorrectly. This happens even when the downstream task training procedures remain identical. Our work aims to provide seamless model updates to a user in two ways. First, we provide evaluation metrics for a notion of compatibility to prior model versions, specifically for generative tasks but also applicable for discriminative tasks. We observe regression and inconsistencies between different model versions on a diverse set of tasks and model updates. Second, we propose a training strategy to minimize the number of inconsistencies in model updates, involving training of a compatibility model that can enhance task fine-tuned language models. We reduce negative flips -- instances where a prior model version was correct, but a new model incorrect -- by up to 40% from Llama 1 to Llama 2.",
    "pdf_link": "https://arxiv.org/abs/2407.09435",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.09435v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09435/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09435v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09435/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09435v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09435/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09435v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09435/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09435v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09435/x5.png"
      }
    ],
    "abstract_cn": "大型语言模型 (LLM) 因数据或架构的改进而频繁更新，以提升性能。然而，开发者往往更注重提升性能指标，而忽视了与旧版本的兼容性。用户在与模型互动时会形成心理模型，每次更新都需调整，这可能导致不满。实际应用中，微调的下游任务模型依赖于预训练的 LLM 基础模型，更新后常出现实例回归或预测错误。我们的工作旨在通过两种方式实现无缝更新：首先，我们提供兼容性评估指标，特别针对生成任务；其次，我们提出训练策略，通过兼容性模型减少不一致性，从 Llama 1 到 Llama 2 减少高达 40% 的负面翻转。",
    "title_cn": "MUSCLE：一种促进 LLM 兼容进化的模型更新策略",
    "tags": [
      "LLM理论",
      "软件开发",
      "人工智能"
    ]
  },
  {
    "title": "Open (Clinical) LLMs are Sensitive to Instruction Phrasings",
    "submit_datetime": "2024年07月12日",
    "abstract": "Instruction-tuned Large Language Models (LLMs) can perform a wide range of tasks given natural language instructions to do so, but they are sensitive to how such instructions are phrased. This issue is especially concerning in healthcare, as clinicians are unlikely to be experienced prompt engineers and the potential consequences of inaccurate outputs are heightened in this domain.\n  This raises a practical question: How robust are instruction-tuned LLMs to natural variations in the instructions provided for clinical NLP tasks? We collect prompts from medical doctors across a range of tasks and quantify the sensitivity of seven LLMs -- some general, others specialized -- to natural (i.e., non-adversarial) instruction phrasings. We find that performance varies substantially across all models, and that -- perhaps surprisingly -- domain-specific models explicitly trained on clinical data are especially brittle, compared to their general domain counterparts. Further, arbitrary phrasing differences can affect fairness, e.g., valid but distinct instructions for mortality prediction yield a range both in overall performance, and in terms of differences between demographic groups.",
    "pdf_link": "https://arxiv.org/abs/2407.09429",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.09429v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09429/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09429v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09429/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09429v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09429/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09429v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09429/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09429v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09429/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09429v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09429/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09429v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09429/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09429v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09429/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09429v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09429/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09429v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09429/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09429v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09429/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09429v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09429/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09429v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09429/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09429v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09429/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09429v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09429/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09429v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09429/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09429v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09429/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09429v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09429/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09429v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09429/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09429v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09429/x20.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09429v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09429/x21.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09429v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09429/x22.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09429v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09429/x23.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09429v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09429/x24.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09429v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09429/x25.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09429v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09429/x26.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09429v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09429/x27.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09429v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09429/x28.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09429v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09429/x29.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09429v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09429/x30.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09429v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09429/x31.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09429v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09429/x32.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09429v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09429/x33.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09429v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09429/x34.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09429v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09429/x35.png"
      }
    ],
    "abstract_cn": "指令调整的 LLM 虽能执行多样任务，但对其指令的表述极为敏感。在医疗领域，这一问题尤为突出，因为临床医生通常不具备设计精准指令的技能，而错误输出的风险在此领域尤为严重。  我们面临的实际问题是：这些模型对临床任务指令的自然变化有多强的适应性？我们收集了来自医生们的各种任务提示，并评估了七种 LLM（包括通用与专业模型）对自然指令表述的敏感度。结果显示，所有模型的性能差异显著，且令人意外的是，那些专门针对临床数据训练的模型尤为脆弱，相比之下，通用模型表现更为稳健。此外，指令表述的微小差异也可能影响模型的公平性，例如，针对死亡率预测的不同但合理的指令，不仅在整体性能上有所差异，还可能导致不同群体间的结果偏差。",
    "title_cn": "临床大型语言模型对指令的表述方式颇为敏感。",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "TelecomGPT: A Framework to Build Telecom-Specfic Large Language Models",
    "submit_datetime": "2024年07月12日",
    "abstract": "Large Language Models (LLMs) have the potential to revolutionize the Sixth Generation (6G) communication networks. However, current mainstream LLMs generally lack the specialized knowledge in telecom domain. In this paper, for the first time, we propose a pipeline to adapt any general purpose LLMs to a telecom-specific LLMs. We collect and build telecom-specific pre-train dataset, instruction dataset, preference dataset to perform continual pre-training, instruct tuning and alignment tuning respectively. Besides, due to the lack of widely accepted evaluation benchmarks in telecom domain, we extend existing evaluation benchmarks and proposed three new benchmarks, namely, Telecom Math Modeling, Telecom Open QnA and Telecom Code Tasks. These new benchmarks provide a holistic evaluation of the capabilities of LLMs including math modeling, Open-Ended question answering, code generation, infilling, summarization and analysis in telecom domain. Our fine-tuned LLM TelecomGPT outperforms state of the art (SOTA) LLMs including GPT-4, Llama-3 and Mistral in Telecom Math Modeling benchmark significantly and achieve comparable performance in various evaluation benchmarks such as TeleQnA, 3GPP technical documents classification, telecom code summary and generation and infilling.",
    "pdf_link": "https://arxiv.org/abs/2407.09424",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.09424v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09424/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09424v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09424/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09424v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09424/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09424v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09424/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09424v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09424/x5.png"
      }
    ],
    "abstract_cn": "大型语言模型 (LLM) 有望革新第六代 (6G) 通信网络，但当前主流 LLM 普遍缺乏电信专业知识。本文首次提出了一种将通用 LLM 转化为电信特定 LLM 的流程，通过构建专用数据集进行持续预训练、指令调整和校准调整。针对电信领域缺乏评估基准的问题，我们扩展了现有基准并新增了电信数学建模、开放问答和代码任务三大基准，全面评估 LLM 在电信领域的各项能力。经微调的 TelecomGPT 在电信数学建模基准上显著超越现有最先进模型，并在多个评估基准上表现卓越。",
    "title_cn": "TelecomGPT：打造电信专属大型语言模型的框架",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "GAVEL: Generating Games Via Evolution and Language Models",
    "submit_datetime": "2024年07月12日",
    "abstract": "Automatically generating novel and interesting games is a complex task. Challenges include representing game rules in a computationally workable form, searching through the large space of potential games under most such representations, and accurately evaluating the originality and quality of previously unseen games. Prior work in automated game generation has largely focused on relatively restricted rule representations and relied on domain-specific heuristics. In this work, we explore the generation of novel games in the comparatively expansive Ludii game description language, which encodes the rules of over 1000 board games in a variety of styles and modes of play. We draw inspiration from recent advances in large language models and evolutionary computation in order to train a model that intelligently mutates and recombines games and mechanics expressed as code. We demonstrate both quantitatively and qualitatively that our approach is capable of generating new and interesting games, including in regions of the potential rules space not covered by existing games in the Ludii dataset. A sample of the generated games are available to play online through the Ludii portal.",
    "pdf_link": "https://arxiv.org/abs/2407.09388",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.09388v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09388/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09388v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09388/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09388v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09388/archive_plot.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09388v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09388/x3.png"
      }
    ],
    "abstract_cn": "自动生成新颖有趣的游戏充满挑战，涉及规则表示、潜在游戏搜索及原创性与质量评估。过往研究多聚焦于有限规则并依赖特定领域启发。我们则利用Ludii游戏描述语言，涵盖千种棋盘游戏规则，结合大型语言模型与进化计算，训练智能变异与重组游戏机制的模型。实验证明，我们能创造新颖游戏，拓展规则空间边界，部分成果已在线开放体验。",
    "title_cn": "GAVEL：借助进化与语言模型创造游戏",
    "tags": [
      "Agent",
      "游戏开发",
      "人工智能"
    ]
  },
  {
    "title": "Is Contrasting All You Need? Contrastive Learning for the Detection and Attribution of AI-generated Text",
    "submit_datetime": "2024年07月12日",
    "abstract": "The significant progress in the development of Large Language Models has contributed to blurring the distinction between human and AI-generated text. The increasing pervasiveness of AI-generated text and the difficulty in detecting it poses new challenges for our society. In this paper, we tackle the problem of detecting and attributing AI-generated text by proposing WhosAI, a triplet-network contrastive learning framework designed to predict whether a given input text has been generated by humans or AI and to unveil the authorship of the text. Unlike most existing approaches, our proposed framework is conceived to learn semantic similarity representations from multiple generators at once, thus equally handling both detection and attribution tasks. Furthermore, WhosAI is model-agnostic and scalable to the release of new AI text-generation models by incorporating their generated instances into the embedding space learned by our framework. Experimental results on the TuringBench benchmark of 200K news articles show that our proposed framework achieves outstanding results in both the Turing Test and Authorship Attribution tasks, outperforming all the methods listed in the TuringBench benchmark leaderboards.",
    "pdf_link": "https://arxiv.org/abs/2407.09364",
    "graphs": [],
    "abstract_cn": "大型语言模型的进步使得人机文本界限愈发模糊。AI文本的泛滥及其难以识别性，给社会带来新挑战。本文中，我们提出WhosAI框架，通过三元组网络对比学习，不仅能判断文本来源（人或AI），还能揭示作者身份。与传统方法不同，WhosAI从多生成器中同步学习语义表示，兼顾检测与归属。此外，WhosAI不依赖特定模型，能随新AI模型发布而扩展。实验表明，在TuringBench的20万新闻文章测试中，WhosAI在图灵测试与作者归属任务上表现卓越，超越了所有现有方法。",
    "title_cn": "对比学习是否已足够？探讨其在 AI 生成文本检测与归因中的应用。",
    "tags": [
      "LLM应用",
      "",
      "网络安全"
    ]
  },
  {
    "title": "A Preliminary Investigation on Flexible Singing Voice Synthesis Through Decomposed Framework with Inferrable Features",
    "submit_datetime": "2024年07月12日",
    "abstract": "We investigate the feasibility of a singing voice synthesis (SVS) system by using a decomposed framework to improve flexibility in generating singing voices. Due to data-driven approaches, SVS performs a music score-to-waveform mapping; however, the direct mapping limits control, such as being able to only synthesize in the language or the singers present in the labeled singing datasets. As collecting large singing datasets labeled with music scores is an expensive task, we investigate an alternative approach by decomposing the SVS system and inferring different singing voice features. We decompose the SVS system into three-stage modules of linguistic, pitch contour, and synthesis, in which singing voice features such as linguistic content, F0, voiced/unvoiced, singer embeddings, and loudness are directly inferred from audio. Through this decomposed framework, we show that we can alleviate the labeled dataset requirements, adapt to different languages or singers, and inpaint the lyrical content of singing voices. Our investigations show that the framework has the potential to reach state-of-the-art in SVS, even though the model has additional functionality and improved flexibility. The comprehensive analysis of our investigated framework's current capabilities sheds light on the ways the research community can achieve a flexible and multifunctional SVS system.",
    "pdf_link": "https://arxiv.org/abs/2407.09346",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.09346v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09346/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09346v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09346/x2.png"
      }
    ],
    "abstract_cn": "我们探索了通过分解框架提升歌唱声音合成（SVS）系统灵活性的可行性。传统的SVS系统受限于直接的乐谱到波形映射，仅能合成特定语言或歌手的声音。考虑到大规模标记歌唱数据集的收集成本，我们提出了一种分解SVS系统并推断歌唱声音特征的新方法。该系统被分解为语言、音高和合成三个模块，直接从音频中提取语言内容、音高、声音状态、歌手特征和响度等特征。这一分解框架不仅减轻了对标记数据集的依赖，还能适应多种语言和歌手，并填补歌唱声音的歌词内容。研究表明，尽管增加了功能和灵活性，该框架仍有潜力达到SVS领域的顶尖水平。对当前框架能力的全面分析为实现一个灵活且多功能的SVS系统提供了研究方向。",
    "title_cn": "本研究初步探索了利用分解框架和可推断特征实现灵活歌唱声音合成的方法。",
    "tags": [
      "LLM应用",
      "",
      "语音合成"
    ]
  },
  {
    "title": "Good Intentions, Risky Inventions: A Method for Assessing the Risks and Benefits of AI in Mobile and Wearable Uses",
    "submit_datetime": "2024年07月12日",
    "abstract": "Integrating Artificial Intelligence (AI) into mobile and wearables offers numerous benefits at individual, societal, and environmental levels. Yet, it also spotlights concerns over emerging risks. Traditional assessments of risks and benefits have been sporadic, and often require costly expert analysis. We developed a semi-automatic method that leverages Large Language Models (LLMs) to identify AI uses in mobile and wearables, classify their risks based on the EU AI Act, and determine their benefits that align with globally recognized long-term sustainable development goals; a manual validation of our method by two experts in mobile and wearable technologies, a legal and compliance expert, and a cohort of nine individuals with legal backgrounds who were recruited from Prolific, confirmed its accuracy to be over 85\\%. We uncovered that specific applications of mobile computing hold significant potential in improving well-being, safety, and social equality. However, these promising uses are linked to risks involving sensitive data, vulnerable groups, and automated decision-making. To avoid rejecting these risky yet impactful mobile and wearable uses, we propose a risk assessment checklist for the Mobile HCI community.",
    "pdf_link": "https://arxiv.org/abs/2407.09322",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.09322v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09322/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09322v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09322/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09322v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09322/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09322v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09322/x4.png"
      }
    ],
    "abstract_cn": "将AI融入移动设备和可穿戴设备，不仅带来多重益处，也引发了对新兴风险的关切。传统的风险与利益评估零散且成本高昂。我们创新了一种半自动方法，借助LLMs识别AI应用，依据欧盟AI法案分类风险，并确保利益符合全球可持续发展目标。经移动与可穿戴技术、法律合规专家及法律背景人士的手动验证，该方法准确率超85%。我们揭示了移动计算在提升福祉、安全与社会平等方面潜力巨大，但这些应用也伴随着敏感数据、弱势群体与自动化决策的风险。为避免错失这些虽有风险但极具影响力的应用，我们为移动HCI社区设计了风险评估清单。",
    "title_cn": "善意的创新，风险并存：评估 AI 在移动与穿戴设备中利弊的方法",
    "tags": [
      "LLM应用",
      "移动设备",
      "可穿戴设备"
    ]
  },
  {
    "title": "Scalability of Bayesian Network Structure Elicitation with Large Language Models: a Novel Methodology and Comparative Analysis",
    "submit_datetime": "2024年07月12日",
    "abstract": "In this work, we propose a novel method for Bayesian Networks (BNs) structure elicitation that is based on the initialization of several LLMs with different experiences, independently querying them to create a structure of the BN, and further obtaining the final structure by majority voting. We compare the method with one alternative method on various widely and not widely known BNs of different sizes and study the scalability of both methods on them. We also propose an approach to check the contamination of BNs in LLM, which shows that some widely known BNs are inapplicable for testing the LLM usage for BNs structure elicitation. We also show that some BNs may be inapplicable for such experiments because their node names are indistinguishable. The experiments on the other BNs show that our method performs better than the existing method with one of the three studied LLMs; however, the performance of both methods significantly decreases with the increase in BN size.",
    "pdf_link": "https://arxiv.org/abs/2407.09311",
    "graphs": [],
    "abstract_cn": "本研究提出一种创新方法，通过初始化多个经验各异的 LLM，独立构建贝叶斯网络 (BN) 结构，并采用多数投票确定最终结构。我们对比了该方法与另一种替代方案在不同规模和知名度的 BN 上的表现，并探讨了它们的可扩展性。此外，我们开发了一种检测 LLM 中 BN 污染的方法，发现某些知名 BN 不适用于评估 LLM 在 BN 结构诱导中的应用。实验还揭示，由于节点名称难以区分，部分 BN 不适合此类实验。对其他 BN 的测试显示，我们的方法在某一 LLM 上优于现有技术，但两种方法的性能均随 BN 规模增大而显著下降。",
    "title_cn": "大型语言模型在贝叶斯网络结构启发中的可扩展性：创新方法论与对比分析",
    "tags": [
      "LLM应用",
      "人工智能",
      "数据分析"
    ]
  },
  {
    "title": "Transformer Layers as Painters",
    "submit_datetime": "2024年07月12日",
    "abstract": "Despite their nearly universal adoption for large language models, the internal workings of transformers are not well understood. We aim to better understand the impact of removing or reorganizing information throughout the layers of a pretrained transformer. Such an understanding could both yield better usage of existing models as well as to make architectural improvements to produce new variants. We present a series of empirical studies on frozen models that show that the lower and final layers of pretrained transformers differ from middle layers, but that middle layers have a surprising amount of uniformity. We further show that some classes of problems have robustness to skipping layers, running the layers in an order different from how they were trained, or running the layers in parallel. Our observations suggest that even frozen pretrained models may gracefully trade accuracy for latency by skipping layers or running layers in parallel.",
    "pdf_link": "https://arxiv.org/abs/2407.09298",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.09298v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09298/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09298v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09298/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09298v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09298/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09298v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09298/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09298v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09298/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09298v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09298/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09298v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09298/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09298v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09298/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09298v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09298/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09298v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09298/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09298v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09298/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09298v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09298/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09298v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09298/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09298v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09298/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09298v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09298/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09298v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09298/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09298v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09298/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09298v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09298/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09298v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09298/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09298v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09298/x20.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09298v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09298/x21.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09298v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09298/x22.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09298v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09298/x23.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09298v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09298/x24.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09298v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09298/x25.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09298v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09298/x26.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09298v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09298/x27.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09298v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09298/x28.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09298v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09298/x29.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09298v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09298/x30.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09298v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09298/x31.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09298v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09298/x32.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09298v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09298/x33.png"
      }
    ],
    "abstract_cn": "尽管transformer在大型语言模型中广泛应用，但其内部机制仍是个谜。我们旨在深入探究在预训练transformer中移除或重组信息的影响，这不仅能优化现有模型的使用，还能通过架构创新带来新变体。我们的实证研究发现，预训练transformer的底层和顶层与中间层存在差异，而中间层却展现出惊人的一致性。此外，我们发现某些问题类型对层跳过、非顺序运行或并行处理具有鲁棒性。这些观察暗示，即使是冻结的预训练模型，也能通过层跳过或并行处理，优雅地平衡准确性与延迟。",
    "title_cn": "Transformer 层如同画家",
    "tags": [
      "LLM理论",
      "人工智能",
      "计算机科学"
    ]
  },
  {
    "title": "CEIPA: Counterfactual Explainable Incremental Prompt Attack Analysis on Large Language Models",
    "submit_datetime": "2024年07月12日",
    "abstract": "This study sheds light on the imperative need to bolster safety and privacy measures in large language models (LLMs), such as GPT-4 and LLaMA-2, by identifying and mitigating their vulnerabilities through explainable analysis of prompt attacks. We propose Counterfactual Explainable Incremental Prompt Attack (CEIPA), a novel technique where we guide prompts in a specific manner to quantitatively measure attack effectiveness and explore the embedded defense mechanisms in these models. Our approach is distinctive for its capacity to elucidate the reasons behind the generation of harmful responses by LLMs through an incremental counterfactual methodology. By organizing the prompt modification process into four incremental levels: (word, sentence, character, and a combination of character and word) we facilitate a thorough examination of the susceptibilities inherent to LLMs. The findings from our study not only provide counterfactual explanation insight but also demonstrate that our framework significantly enhances the effectiveness of attack prompts.",
    "pdf_link": "https://arxiv.org/abs/2407.09292",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.09292v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09292/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09292v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09292/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09292v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09292/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09292v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09292/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09292v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09292/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09292v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09292/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09292v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09292/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09292v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09292/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09292v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09292/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09292v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09292/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09292v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09292/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09292v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09292/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09292v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09292/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09292v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09292/x14.png"
      }
    ],
    "abstract_cn": "本研究揭示了在大型语言模型（如GPT-4和LLaMA-2）中加强安全和隐私措施的紧迫性，通过识别并缓解提示攻击中的漏洞。我们创新性地提出了“反事实可解释增量提示攻击（CEIPA）”技术，通过特定引导方式，量化攻击效果并探索模型内置防御机制。我们的方法通过增量反事实分析，深入解析了LLM生成有害响应的根源。将提示修改细分为四个递进层次（单词、句子、字符及复合组合），我们全面剖析了LLM的内在脆弱性。研究成果不仅深化了反事实解释，更显著提升了攻击提示的效力。",
    "title_cn": "CEIPA：针对大型语言模型的反事实可解释增量提示攻击分析",
    "tags": [
      "LLM应用",
      "网络安全",
      "人工智能"
    ]
  },
  {
    "title": "Structuring Authenticity Assessments on Historical Documents using LLMs",
    "submit_datetime": "2024年07月12日",
    "abstract": "Given the wide use of forgery throughout history, scholars have and are continuously engaged in assessing the authenticity of historical documents. However, online catalogues merely offer descriptive metadata for these documents, relegating discussions about their authenticity to free-text formats, making it difficult to study these assessments at scale. This study explores the generation of structured data about documents' authenticity assessment from natural language texts. Our pipeline exploits Large Language Models (LLMs) to select, extract and classify relevant claims about the topic without the need for training, and Semantic Web technologies to structure and type-validate the LLM's results. The final output is a catalogue of documents whose authenticity has been debated, along with scholars' opinions on their authenticity. This process can serve as a valuable resource for integration into catalogues, allowing room for more intricate queries and analyses on the evolution of these debates over centuries.",
    "pdf_link": "https://arxiv.org/abs/2407.09290",
    "graphs": [],
    "abstract_cn": "历史上的伪造行为广泛存在，学者们持续评估历史文件的真实性。但在线目录仅提供描述性元数据，使得真实性讨论难以系统研究。本研究通过自然语言文本生成结构化数据，利用大型语言模型（LLM）自动选择、提取和分类相关声明，结合语义网技术进行结构化和验证。最终产出包含争议文件及其学者意见的目录，为深入分析历史辩论提供可能。",
    "title_cn": "利用大型语言模型构建历史文件真实性评估框架",
    "tags": [
      "LLM应用",
      "历史学",
      "语义网"
    ]
  },
  {
    "title": "DAHRS: Divergence-Aware Hallucination-Remediated SRL Projection",
    "submit_datetime": "2024年07月12日",
    "abstract": "Semantic role labeling (SRL) enriches many downstream applications, e.g., machine translation, question answering, summarization, and stance/belief detection. However, building multilingual SRL models is challenging due to the scarcity of semantically annotated corpora for multiple languages. Moreover, state-of-the-art SRL projection (XSRL) based on large language models (LLMs) yields output that is riddled with spurious role labels. Remediation of such hallucinations is not straightforward due to the lack of explainability of LLMs. We show that hallucinated role labels are related to naturally occurring divergence types that interfere with initial alignments. We implement Divergence-Aware Hallucination-Remediated SRL projection (DAHRS), leveraging linguistically-informed alignment remediation followed by greedy First-Come First-Assign (FCFA) SRL projection. DAHRS improves the accuracy of SRL projection without additional transformer-based machinery, beating XSRL in both human and automatic comparisons, and advancing beyond headwords to accommodate phrase-level SRL projection (e.g., EN-FR, EN-ES). Using CoNLL-2009 as our ground truth, we achieve a higher word-level F1 over XSRL: 87.6% vs. 77.3% (EN-FR) and 89.0% vs. 82.7% (EN-ES). Human phrase-level assessments yield 89.1% (EN-FR) and 91.0% (EN-ES). We also define a divergence metric to adapt our approach to other language pairs (e.g., English-Tagalog).",
    "pdf_link": "https://arxiv.org/abs/2407.09283",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.09283v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09283/DAHRS_overarching_cr.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09283v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09283/DAHRS_cr_3.jpg"
      }
    ],
    "abstract_cn": "语义角色标注（SRL）广泛应用于机器翻译、问答、摘要及立场检测等下游任务。然而，多语言SRL模型的构建因语义注释语料库的稀缺而颇具挑战。基于大型语言模型的SRL投影（XSRL）虽先进，但输出常含虚假角色标签，且因模型缺乏解释性，修复不易。我们发现，这些幻觉标签与自然语言中的偏差类型有关，这些偏差影响了初始对齐。为此，我们开发了偏差感知幻觉修复SRL投影（DAHRS），通过语言学引导的对齐修复和先到先得的贪婪投影，DAHRS在不增加复杂机制的情况下提升了投影准确性，超越了XSRL，并扩展至短语级SRL投影（如EN-FR、EN-ES）。以CoNLL-2009为基准，DAHRS在词级F1得分上显著提升，分别为87.6%（EN-FR）和89.0%（EN-ES），人类评估的短语级准确率亦高达89.1%（EN-FR）和91.0%（EN-ES）。此外，我们还引入了一个偏差度量，以便将此方法应用于其他语言对，如英语与他加禄语。",
    "title_cn": "DAHRS：一种偏差感知型幻觉修正语义角色标注投影技术",
    "tags": [
      "LLM应用",
      "机器翻译",
      ""
    ]
  },
  {
    "title": "Predicting and Understanding Human Action Decisions: Insights from Large Language Models and Cognitive Instance-Based Learning",
    "submit_datetime": "2024年07月12日",
    "abstract": "Large Language Models (LLMs) have demonstrated their capabilities across various tasks, from language translation to complex reasoning. Understanding and predicting human behavior and biases are crucial for artificial intelligence (AI) assisted systems to provide useful assistance, yet it remains an open question whether these models can achieve this. This paper addresses this gap by leveraging the reasoning and generative capabilities of the LLMs to predict human behavior in two sequential decision-making tasks. These tasks involve balancing between exploitative and exploratory actions and handling delayed feedback, both essential for simulating real-life decision processes. We compare the performance of LLMs with a cognitive instance-based learning (IBL) model, which imitates human experiential decision-making. Our findings indicate that LLMs excel at rapidly incorporating feedback to enhance prediction accuracy. In contrast, the cognitive IBL model better accounts for human exploratory behaviors and effectively captures loss aversion bias, i.e., the tendency to choose a sub-optimal goal with fewer step-cost penalties rather than exploring to find the optimal choice, even with limited experience. The results highlight the benefits of integrating LLMs with cognitive architectures, suggesting that this synergy could enhance the modeling and understanding of complex human decision-making patterns.",
    "pdf_link": "https://arxiv.org/abs/2407.09281",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.09281v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09281/framework.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09281v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09281/demo.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09281v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09281/simple_grid.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09281v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09281/complex_grid.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09281v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09281/exp1-kl-episode.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09281v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09281/exp2-kl-episode.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09281v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09281/exp1-pred-accuracy-episode.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09281v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09281/exp2-pred-accuracy-episode.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09281v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09281/exp1-entropy.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09281v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09281/exp2-entropy.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLM）在多种任务中展现了卓越能力，从语言翻译到复杂推理。然而，这些模型能否理解和预测人类行为及偏见，对AI辅助系统至关重要，仍待解答。本文利用LLM的推理与生成能力，预测了两个连续决策任务中的人类行为，填补了这一研究空白。这些任务要求在利用与探索之间取得平衡，并处理延迟反馈，这对模拟真实决策过程至关重要。我们比较了LLM与模仿人类经验的认知实例-based learning（IBL）模型的性能。结果显示，LLM能迅速整合反馈，提升预测准确性；而认知IBL模型更佳地捕捉了人类的探索行为及损失厌恶偏差，即倾向于选择步骤成本较低的次优目标，而非探索最佳选择，即便经验有限。研究强调了LLM与认知架构结合的优势，预示这种结合能深化对复杂人类决策模式的理解与建模。",
    "title_cn": "探索人类行为决策的预测与理解，结合大型语言模型与认知实例学习的洞见",
    "tags": [
      "LLM应用",
      "人工智能",
      "心理学"
    ]
  },
  {
    "title": "FedsLLM: Federated Split Learning for Large Language Models over Communication Networks",
    "submit_datetime": "2024年07月12日",
    "abstract": "Addressing the challenges of deploying large language models in wireless communication networks, this paper combines low-rank adaptation technology (LoRA) with the splitfed learning framework to propose the federated split learning for large language models (FedsLLM) framework. The method introduced in this paper utilizes LoRA technology to reduce processing loads by dividing the network into client subnetworks and server subnetworks. It leverages a federated server to aggregate and update client models. As the training data are transmitted through a wireless network between clients and both main and federated servers, the training delay is determined by the learning accuracy and the allocation of communication bandwidth. This paper models the minimization of the training delay by integrating computation and communication optimization, simplifying the optimization problem into a convex problem to find the optimal solution. Additionally, it presents a lemma that describes the precise solutions to this problem. Simulation results demonstrate that the proposed optimization algorithm reduces delays by an average of 47.63% compared to unoptimized scenarios.",
    "pdf_link": "https://arxiv.org/abs/2407.09250",
    "graphs": [],
    "abstract_cn": "本文针对无线通信网络中部署大型语言模型的挑战，创新性地结合低秩适应技术（LoRA）与分割联邦学习框架，提出了FedsLLM框架。该方法通过LoRA技术划分网络，减轻处理负载，并利用联邦服务器整合更新客户端模型。由于训练数据在无线网络中传输，训练延迟受学习精度和带宽分配影响。本文通过计算与通信优化，将优化问题简化为凸问题，寻求最优解，并提出精确解的引理。仿真显示，该优化算法平均降低延迟达47.63%，显著提升效率。",
    "title_cn": "FedsLLM：通信网络中大型语言模型的联邦分割学习",
    "tags": [
      "LLM应用",
      "无线通信",
      "联邦学习"
    ]
  },
  {
    "title": "The Sociolinguistic Foundations of Language Modeling",
    "submit_datetime": "2024年07月12日",
    "abstract": "In this paper, we introduce a sociolinguistic perspective on language modeling. We claim that large language models are inherently models of varieties of language, and we consider how this insight can inform the development and deployment of large language models. We begin by presenting a technical definition of the concept of a variety of language as developed in sociolinguistics. We then discuss how this perspective can help address five basic challenges in language modeling: social bias, domain adaptation, alignment, language change, and scale. Ultimately, we argue that it is crucial to carefully define and compile training corpora that accurately represent the specific varieties of language being modeled to maximize the performance and societal value of large language models.",
    "pdf_link": "https://arxiv.org/abs/2407.09241",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.09241v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09241/fig1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09241v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09241/fig2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09241v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09241/fig3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09241v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09241/fig4.png"
      }
    ],
    "abstract_cn": "本文从社会语言学角度探讨语言建模，指出大型语言模型本质上是多种语言的体现。我们探讨了这一观点如何助力大型语言模型的发展与应用，并详细阐述了语言变体的技术定义。此外，我们分析了这一视角在应对语言建模五大挑战——社会偏见、领域适应、对齐、语言变化及规模方面的潜力。最终，我们强调，为提升大型语言模型的性能与社会价值，精确构建代表特定语言变体的训练语料库至关重要。",
    "title_cn": "语言模型的社会语言学根基",
    "tags": [
      "LLM理论",
      "社会语言学",
      "人工智能"
    ]
  },
  {
    "title": "Prompts First, Finally",
    "submit_datetime": "2024年07月12日",
    "abstract": "Generative AI (GenAI) and large language models in particular, are disrupting Computer Science Education. They are proving increasingly capable at more and more challenges. Some educators argue that they pose a serious threat to computing education, and that we should ban their use in the classroom. While there are serious GenAI issues that remain unsolved, it may be useful in the present moment to step back and examine the overall trajectory of Computer Science writ large. Since the very beginning, our discipline has sought to increase the level of abstraction in each new representation. We have progressed from hardware dip switches, through special purpose languages and visual representations like flow charts, all the way now to ``natural language.'' With the advent of GenAI, students can finally change the abstraction level of a problem to the ``language'' they've been ``problem solving'' with all their lives. In this paper, we argue that our programming abstractions were always headed here -- to natural language. Now is the time to adopt a ``Prompts First'' approach to Computer Science Education.",
    "pdf_link": "https://arxiv.org/abs/2407.09231",
    "graphs": [],
    "abstract_cn": "生成式AI（GenAI），尤其是大型语言模型，正深刻影响着计算机科学教育。它们在众多挑战中展现出日益增强的能力，引发了一些教育者的担忧，认为它们可能威胁到计算机教育，甚至主张在课堂上禁用。然而，在探讨这些未解问题的同时，审视计算机科学的整体发展趋势或许更为重要。自学科诞生之初，我们便不断追求在每种新表示中提升抽象层次，从硬件拨码开关到专用语言，再到流程图，直至现今的“自然语言”。GenAI的到来，使学生能够将问题抽象至他们熟悉的“语言”层面，这正是我们编程抽象的终极目标——自然语言。因此，本文主张，现在是时候在计算机科学教育中推行“提示优先”策略了。",
    "title_cn": "先提示，后收尾",
    "tags": [
      "LLM应用",
      "",
      "计算机科学"
    ]
  },
  {
    "title": "Pronunciation Assessment with Multi-modal Large Language Models",
    "submit_datetime": "2024年07月12日",
    "abstract": "Large language models (LLMs), renowned for their powerful conversational abilities, are widely recognized as exceptional tools in the field of education, particularly in the context of automated intelligent instruction systems for language learning. In this paper, we propose a scoring system based on LLMs, motivated by their positive impact on text-related scoring tasks. Specifically, the speech encoder first maps the learner's speech into contextual features. The adapter layer then transforms these features to align with the text embedding in latent space. The assessment task-specific prefix and prompt text are embedded and concatenated with the features generated by the modality adapter layer, enabling the LLMs to predict accuracy and fluency scores. Our experiments demonstrate that the proposed scoring systems achieve competitive results compared to the baselines on the Speechocean762 datasets. Moreover, we also conducted an ablation study to better understand the contributions of the prompt text and training strategy in the proposed scoring system.",
    "pdf_link": "https://arxiv.org/abs/2407.09209",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.09209v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09209/model7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09209v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09209/acc3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09209v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09209/flu1.png"
      }
    ],
    "abstract_cn": "大型语言模型 (LLM) 因其卓越的对话能力在教育领域备受推崇，尤其是在语言学习的自动化智能教学系统中。本文提出了一种基于 LLM 的评分系统，灵感源自其在文本评分任务中的显著成效。系统首先通过语音编码器将学习者语音转化为上下文特征，再由适配器层调整这些特征以匹配文本嵌入。随后，结合评估任务前缀和提示文本，LLM 能够精准预测语音的准确性与流畅度。实验结果显示，该评分系统在 Speechocean762 数据集上表现优异。此外，通过消融研究，我们进一步探究了提示文本和训练策略对系统性能的影响。",
    "title_cn": "多模态大型语言模型在发音评估中的应用",
    "tags": [
      "LLM应用",
      "",
      "语言学习"
    ]
  },
  {
    "title": "TAPI: Towards Target-Specific and Adversarial Prompt Injection against Code LLMs",
    "submit_datetime": "2024年07月12日",
    "abstract": "Recently, code-oriented large language models (Code LLMs) have been widely and successfully used to simplify and facilitate code programming. With these tools, developers can easily generate desired complete functional codes based on incomplete code and natural language prompts. However, a few pioneering works revealed that these Code LLMs are also vulnerable, e.g., against backdoor and adversarial attacks. The former could induce LLMs to respond to triggers to insert malicious code snippets by poisoning the training data or model parameters, while the latter can craft malicious adversarial input codes to reduce the quality of generated codes. However, both attack methods have underlying limitations: backdoor attacks rely on controlling the model training process, while adversarial attacks struggle with fulfilling specific malicious purposes.\n  To inherit the advantages of both backdoor and adversarial attacks, this paper proposes a new attack paradigm, i.e., target-specific and adversarial prompt injection (TAPI), against Code LLMs. TAPI generates unreadable comments containing information about malicious instructions and hides them as triggers in the external source code. When users exploit Code LLMs to complete codes containing the trigger, the models will generate attacker-specified malicious code snippets at specific locations. We evaluate our TAPI attack on four representative LLMs under three representative malicious objectives and seven cases. The results show that our method is highly threatening (achieving an attack success rate of up to 89.3\\%) and stealthy (saving an average of 53.1\\% of tokens in the trigger design). In particular, we successfully attack some famous deployed code completion integrated applications, including CodeGeex and Github Copilot. This further confirms the realistic threat of our attack.",
    "pdf_link": "https://arxiv.org/abs/2407.09164",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.09164v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09164/01_adversarial_trigger_demo.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09164v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09164/02_TAPIC_Pipeline2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09164v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09164/03_Task_construction.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09164v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09164/06_adversarial_compute.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09164v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09164/07_keyword-based_trigger.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09164v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09164/harmfulness.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09164v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09164/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09164v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09164/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09164v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09164/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09164v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09164/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09164v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09164/none_enhancement.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09164v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09164/enhancement.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09164v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09164/traditional_adversarial_attack_gemma.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09164v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09164/traditional_adversarial_attack_codegemma.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09164v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09164/traditional_adversarial_attack_codellama.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09164v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09164/traditional_adversarial_attack_codegeex2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09164v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09164/codegeex_01.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09164v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09164/codegeex_02.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09164v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09164/codegeex_04.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09164v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09164/codegeex_05.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09164v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09164/codegeex_06.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09164v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09164/codegeex_07.png"
      }
    ],
    "abstract_cn": "近期，面向代码的大型语言模型（Code LLMs）在简化编程方面表现出色，使开发者能轻松生成完整功能代码。然而，这些模型也暴露出对后门和对抗性攻击的脆弱性。为融合这两种攻击的优势，本文引入了针对特定目标和对抗性提示注入（TAPI）的新攻击范式。TAPI巧妙地将恶意指令隐藏于不可读注释中，作为触发器嵌入源代码。一旦用户使用Code LLMs处理含触发器的代码，模型便会生成特定恶意代码。实验表明，TAPI攻击成功率高（达89.3%）且隐蔽性强（触发器设计节省53.1%令牌），甚至成功攻击了知名代码完成工具如CodeGeex和Github Copilot，凸显其现实威胁。",
    "title_cn": "TAPI：针对代码大型语言模型的目标特定与对抗性提示注入策略",
    "tags": [
      "LLM应用",
      "软件开发",
      "网络安全"
    ]
  },
  {
    "title": "The Two Sides of the Coin: Hallucination Generation and Detection with LLMs as Evaluators for LLMs",
    "submit_datetime": "2024年07月12日",
    "abstract": "Hallucination detection in Large Language Models (LLMs) is crucial for ensuring their reliability. This work presents our participation in the CLEF ELOQUENT HalluciGen shared task, where the goal is to develop evaluators for both generating and detecting hallucinated content. We explored the capabilities of four LLMs: Llama 3, Gemma, GPT-3.5 Turbo, and GPT-4, for this purpose. We also employed ensemble majority voting to incorporate all four models for the detection task. The results provide valuable insights into the strengths and weaknesses of these LLMs in handling hallucination generation and detection tasks.",
    "pdf_link": "https://arxiv.org/abs/2407.09152",
    "graphs": [],
    "abstract_cn": "确保大型语言模型的可靠性，幻觉检测至关重要。我们参与了 CLEF ELOQUENT HalluciGen 共享任务，旨在开发幻觉内容生成与检测的评估器。通过探索 Llama 3、Gemma、GPT-3.5 Turbo 和 GPT-4 这四个模型的能力，并运用集成多数投票技术，我们综合利用这些模型进行幻觉检测。研究结果揭示了这些模型在幻觉生成与检测任务中的优劣，为我们提供了宝贵的洞察。",
    "title_cn": "幻觉生成与检测：LLM 的双重角色",
    "tags": [
      "LLM应用",
      "人工智能",
      "语言模型"
    ]
  },
  {
    "title": "Accuracy is Not All You Need",
    "submit_datetime": "2024年07月12日",
    "abstract": "When Large Language Models (LLMs) are compressed using techniques such as quantization, the predominant way to demonstrate the validity of such techniques is by measuring the model's accuracy on various benchmarks.If the accuracies of the baseline model and the compressed model are close, it is assumed that there was negligible degradation in quality.However, even when the accuracy of baseline and compressed model are similar, we observe the phenomenon of flips, wherein answers change from correct to incorrect and vice versa in proportion.We conduct a detailed study of metrics across multiple compression techniques, models and datasets, demonstrating that the behavior of compressed models as visible to end-users is often significantly different from the baseline model, even when accuracy is similar.We further evaluate compressed models qualitatively and quantitatively using MT-Bench and show that compressed models are significantly worse than baseline models in this free-form generative task.Thus, we argue that compression techniques should also be evaluated using distance metrics.We propose two such metrics, KL-Divergence and flips, and show that they are well correlated.",
    "pdf_link": "https://arxiv.org/abs/2407.09141",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.09141v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09141/analysis5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09141v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09141/layer_drop.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09141v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09141/wanda.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09141v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09141/top_margin_stay_change_Llama270b_llmint84bit_mmlu.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09141v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09141/top_margin_correct_wrong_Llama270b_llmint84bit_mmlu.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09141v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09141/flips_vs_fullKLDiv_arc_easy.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09141v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09141/flips_vs_fullKLDiv_arc_challenge.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09141v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09141/flips_vs_fullKLDiv_mmlufewshot5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09141v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09141/flips_vs_mtb_scores.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09141v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09141/slicegpt.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09141v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09141/layer_drop_flips_vs_allflips.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09141v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09141/wanda_flips_vs_allflips.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09141v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09141/analysis7_flips_vs_allflips.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09141v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09141/Llama-2-13b-hf-gptq-4bit-loglikelihood-difference.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09141v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09141/Llama-2-13b-hf-gptq-8bit-loglikelihood-difference.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09141v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09141/Llama-2-13b-hf-llmint8-4bit-loglikelihood-difference.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09141v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09141/Llama-2-13b-hf-llmint8-8bit-loglikelihood-difference.png"
      }
    ],
    "abstract_cn": "在压缩大型语言模型时，通常通过比较压缩前后模型在基准测试上的准确性来验证压缩技术的有效性。然而，即使准确性相近，我们也发现了一个有趣的现象——“翻转”，即答案在正确与错误之间转换。通过跨多种技术、模型和数据集的深入分析，我们揭示了压缩模型与原始模型在实际应用中的行为差异。此外，通过 MT-Bench 的评估，我们发现压缩模型在自由生成任务中的表现远不如原始模型。因此，我们建议在评估压缩技术时，除了准确性，还应考虑如 KL-散度等距离度量。我们提出的这两种度量方法显示出良好的相关性，为评估提供了新的视角。",
    "title_cn": "准确性并非唯一追求",
    "tags": [
      "LLM理论",
      "计算机科学",
      "人工智能"
    ]
  },
  {
    "title": "Stepwise Verification and Remediation of Student Reasoning Errors with Large Language Model Tutors",
    "submit_datetime": "2024年07月12日",
    "abstract": "Large language models (LLMs) present an opportunity to scale high-quality personalized education to all. A promising approach towards this means is to build dialog tutoring models that scaffold students' problem-solving. However, even though existing LLMs perform well in solving reasoning questions, they struggle to precisely detect student's errors and tailor their feedback to these errors. Inspired by real-world teaching practice where teachers identify student errors and customize their response based on them, we focus on verifying student solutions and show how grounding to such verification improves the overall quality of tutor response generation. We collect a dataset of 1K stepwise math reasoning chains with the first error step annotated by teachers. We show empirically that finding the mistake in a student solution is challenging for current models. We propose and evaluate several verifiers for detecting these errors. Using both automatic and human evaluation we show that the student solution verifiers steer the generation model towards highly targeted responses to student errors which are more often correct with less hallucinations compared to existing baselines.",
    "pdf_link": "https://arxiv.org/abs/2407.09136",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.09136v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09136/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09136v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09136/annotation-ui.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09136v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09136/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09136v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09136/interface-error-description.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09136v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09136/evaluation-ui-2.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLM）为普及高质量个性化教育提供了契机。构建对话式辅导模型，辅助学生解决问题的策略颇具前景。尽管LLM在解答推理题上表现出色，但在精准识别学生错误并据此调整反馈方面仍有不足。借鉴现实教学中教师识别错误并个性化回应的做法，我们聚焦于验证学生解题方案，并证明这种验证能提升辅导反馈的质量。我们创建了一个包含1000条逐步数学推理链的数据集，首次错误由教师标记。实证显示，当前模型在学生解题中找错颇具挑战。我们设计并评估了多种错误检测验证器。通过自动与人工评估，证实这些验证器能引导生成模型针对学生错误提供精准反馈，较之现有方法，正确率更高，幻觉更少。",
    "title_cn": "通过大型语言模型导师，逐步验证并纠正学生的推理错误",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Refuse Whenever You Feel Unsafe: Improving Safety in LLMs via Decoupled Refusal Training",
    "submit_datetime": "2024年07月12日",
    "abstract": "This study addresses a critical gap in safety tuning practices for Large Language Models (LLMs) by identifying and tackling a refusal position bias within safety tuning data, which compromises the models' ability to appropriately refuse generating unsafe content. We introduce a novel approach, Decoupled Refusal Training (DeRTa), designed to empower LLMs to refuse compliance to harmful prompts at any response position, significantly enhancing their safety capabilities. DeRTa incorporates two novel components: (1) Maximum Likelihood Estimation (MLE) with Harmful Response Prefix, which trains models to recognize and avoid unsafe content by appending a segment of harmful response to the beginning of a safe response, and (2) Reinforced Transition Optimization (RTO), which equips models with the ability to transition from potential harm to safety refusal consistently throughout the harmful response sequence. Our empirical evaluation, conducted using LLaMA3 and Mistral model families across six attack scenarios, demonstrates that our method not only improves model safety without compromising performance but also surpasses well-known models such as GPT-4 in defending against attacks. Importantly, our approach successfully defends recent advanced attack methods (e.g., CodeAttack) that have jailbroken GPT-4 and LLaMA3-70B-Instruct. Our code and data can be found at https://github.com/RobustNLP/DeRTa.",
    "pdf_link": "https://arxiv.org/abs/2407.09121",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.09121v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09121/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09121v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09121/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09121v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09121/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09121v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09121/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09121v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09121/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09121v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09121/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09121v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09121/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09121v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09121/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09121v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09121/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09121v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09121/x10.png"
      }
    ],
    "abstract_cn": "本研究针对大型语言模型（LLM）安全调优中的关键问题，通过解决安全数据中的拒绝偏差，提升了模型拒绝生成不安全内容的能力。我们提出的解耦拒绝训练（DeRTa）方法，通过两个创新技术——有害响应前缀的最大似然估计和强化过渡优化，增强了模型在面对有害提示时的安全响应能力。实证测试显示，DeRTa不仅提升了安全性，还在防御攻击方面超越了GPT-4等模型，有效抵御了如CodeAttack等高级攻击。详细代码和数据已公开在GitHub上。",
    "title_cn": "在感到不安全时勇敢说“不”：通过解耦拒绝训练策略，提升 LLM 的安全性。",
    "tags": [
      "LLM应用",
      "网络安全",
      "人工智能"
    ]
  },
  {
    "title": "Inference Optimization of Foundation Models on AI Accelerators",
    "submit_datetime": "2024年07月12日",
    "abstract": "Powerful foundation models, including large language models (LLMs), with Transformer architectures have ushered in a new era of Generative AI across various industries. Industry and research community have witnessed a large number of new applications, based on those foundation models. Such applications include question and answer, customer services, image and video generation, and code completions, among others. However, as the number of model parameters reaches to hundreds of billions, their deployment incurs prohibitive inference costs and high latency in real-world scenarios. As a result, the demand for cost-effective and fast inference using AI accelerators is ever more higher. To this end, our tutorial offers a comprehensive discussion on complementary inference optimization techniques using AI accelerators. Beginning with an overview of basic Transformer architectures and deep learning system frameworks, we deep dive into system optimization techniques for fast and memory-efficient attention computations and discuss how they can be implemented efficiently on AI accelerators. Next, we describe architectural elements that are key for fast transformer inference. Finally, we examine various model compression and fast decoding strategies in the same context.",
    "pdf_link": "https://arxiv.org/abs/2407.09111",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.09111v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09111/original_transformer.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09111v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09111/flashattention_simple.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09111v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09111/memory_fragmentation.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09111v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09111/gqa.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09111v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09111/moe_mlp.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09111v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09111/quantization.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09111v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09111/distillation.png"
      }
    ],
    "abstract_cn": "Transformer架构的大型语言模型（LLMs）等强大基础模型，已引领生成式AI进入各行业的新时代。基于这些模型的应用层出不穷，涵盖问答、客户服务、图像视频生成及代码补全等。但模型参数激增至数千亿，导致实际部署成本高昂、延迟显著。因此，高效利用AI加速器进行快速推理的需求日益迫切。本教程深入探讨AI加速器在推理优化中的应用，从Transformer基础架构与深度学习系统出发，详述快速内存高效注意力计算的优化策略，并展示其在加速器上的高效实现。此外，教程还剖析了加速Transformer推理的核心架构要素，并探讨了模型压缩与快速解码的多重策略。",
    "title_cn": "AI加速器上基础模型的推理优化",
    "tags": [
      "LLM应用",
      "人工智能",
      "计算机硬件"
    ]
  },
  {
    "title": "STD-LLM: Understanding Both Spatial and Temporal Properties of Spatial-Temporal Data with LLMs",
    "submit_datetime": "2024年07月12日",
    "abstract": "Spatial-temporal forecasting and imputation are important for real-world dynamic systems such as intelligent transportation, urban planning, and public health. Most existing methods are tailored for individual forecasting or imputation tasks but are not designed for both. Additionally, they are less effective for zero-shot and few-shot learning. While large language models (LLMs) have exhibited strong pattern recognition and reasoning abilities across various tasks, including few-shot and zero-shot learning, their development in understanding spatial-temporal data has been constrained by insufficient modeling of complex correlations such as the temporal correlations, spatial connectivity, non-pairwise and high-order spatial-temporal correlations within data. In this paper, we propose STD-LLM for understanding both spatial and temporal properties of \\underline{S}patial-\\underline{T}emporal \\underline{D}ata with \\underline{LLM}s, which is capable of implementing both spatial-temporal forecasting and imputation tasks. STD-LLM understands spatial-temporal correlations via explicitly designed spatial and temporal tokenizers as well as virtual nodes. Topology-aware node embeddings are designed for LLMs to comprehend and exploit the topology structure of data. Additionally, to capture the non-pairwise and higher-order correlations, we design a hypergraph learning module for LLMs, which can enhance the overall performance and improve efficiency. Extensive experiments demonstrate that STD-LLM exhibits strong performance and generalization capabilities across the forecasting and imputation tasks on various datasets. Moreover, STD-LLM achieves promising results on both few-shot and zero-shot learning tasks.",
    "pdf_link": "https://arxiv.org/abs/2407.09096",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.09096v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09096/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09096v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09096/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09096v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09096/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09096v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09096/PEMS08_PRE_01.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09096v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09096/PEMS08_PRE_02.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09096v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09096/PEMS08_PRE_03.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09096v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09096/PEMS08_IM_01.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09096v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09096/PEMS08_IM_02.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09096v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09096/PEMS08_IM_03.png"
      }
    ],
    "abstract_cn": "时空预测与插补在智能交通、城市规划及公共卫生等领域至关重要。现有方法多针对单一任务设计，且在零-shot和少-shot学习中表现不佳。尽管大型语言模型（LLM）在多种任务中展现出卓越的模式识别与推理能力，但其对时空数据的理解受限于对复杂相关性的建模不足。为此，我们提出STD-LLM，旨在通过LLM深入理解时空数据的时空特性，并实现预测与插补的双重任务。STD-LLM借助精心设计的空间与时间标记器及虚拟节点，洞察时空关联。同时，我们引入拓扑感知节点嵌入，助力LLM把握数据拓扑结构。为捕捉更复杂的非成对及高阶相关性，我们还设计了超图学习模块，以提升性能与效率。实验证明，STD-LLM在各类数据集的预测与插补任务中表现出色，且在少-shot与零-shot学习中亦有亮眼表现。",
    "title_cn": "STD-LLM：借助 LLM 深入探索空间-时间数据的时空特性",
    "tags": [
      "LLM应用",
      "智能交通",
      "城市规划"
    ]
  },
  {
    "title": "Lomics: Generation of Pathways and Gene Sets using Large Language Models for Transcriptomic Analysis",
    "submit_datetime": "2024年07月12日",
    "abstract": "Interrogation of biological pathways is an integral part of omics data analysis. Large language models (LLMs) enable the generation of custom pathways and gene sets tailored to specific scientific questions. These targeted sets are significantly smaller than traditional pathway enrichment analysis libraries, reducing multiple hypothesis testing and potentially enhancing statistical power. Lomics (Large Language Models for Omics Studies) v1.0 is a python-based bioinformatics toolkit that streamlines the generation of pathways and gene sets for transcriptomic analysis. It operates in three steps: 1) deriving relevant pathways based on the researcher's scientific question, 2) generating valid gene sets for each pathway, and 3) outputting the results as .GMX files. Lomics also provides explanations for pathway selections. Consistency and accuracy are ensured through iterative processes, JSON format validation, and HUGO Gene Nomenclature Committee (HGNC) gene symbol verification. Lomics serves as a foundation for integrating LLMs into omics research, potentially improving the specificity and efficiency of pathway analysis.",
    "pdf_link": "https://arxiv.org/abs/2407.09089",
    "graphs": [],
    "abstract_cn": "生物途径的探究是omics数据分析的核心。借助大型语言模型（LLMs），我们能定制针对特定科学问题的生物途径和基因集，这些定制集远小于传统途径富集库，有效减少多重假设检验，提升统计效力。Lomics v1.0，一款基于Python的生物信息学工具，优化了转录组分析中的途径与基因集生成流程，通过三步操作：根据研究问题推导途径、生成有效基因集、输出.GMX文件，并附带途径选择解释。通过迭代、格式验证及基因符号核对，确保结果的准确与一致。Lomics不仅为LLMs在omics研究中的应用打下基础，更可能提升途径分析的精准与效率。",
    "title_cn": "Lomics：借助大型语言模型，我们生成通路和基因集，以助力转录组分析的深入探索。",
    "tags": [
      "LLM应用",
      "生物信息学",
      "转录组分析"
    ]
  },
  {
    "title": "Open Vocabulary Multi-Label Video Classification",
    "submit_datetime": "2024年07月12日",
    "abstract": "Pre-trained vision-language models (VLMs) have enabled significant progress in open vocabulary computer vision tasks such as image classification, object detection and image segmentation. Some recent works have focused on extending VLMs to open vocabulary single label action classification in videos. However, previous methods fall short in holistic video understanding which requires the ability to simultaneously recognize multiple actions and entities e.g., objects in the video in an open vocabulary setting. We formulate this problem as open vocabulary multilabel video classification and propose a method to adapt a pre-trained VLM such as CLIP to solve this task. We leverage large language models (LLMs) to provide semantic guidance to the VLM about class labels to improve its open vocabulary performance with two key contributions. First, we propose an end-to-end trainable architecture that learns to prompt an LLM to generate soft attributes for the CLIP text-encoder to enable it to recognize novel classes. Second, we integrate a temporal modeling module into CLIP's vision encoder to effectively model the spatio-temporal dynamics of video concepts as well as propose a novel regularized finetuning technique to ensure strong open vocabulary classification performance in the video domain. Our extensive experimentation showcases the efficacy of our approach on multiple benchmark datasets.",
    "pdf_link": "https://arxiv.org/abs/2407.09073",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.09073v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09073/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09073v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09073/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09073v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09073/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09073v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09073/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09073v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09073/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09073v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09073/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09073v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09073/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09073v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09073/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09073v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09073/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09073v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09073/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09073v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09073/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09073v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09073/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09073v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09073/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09073v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09073/x14.png"
      }
    ],
    "abstract_cn": "预训练的视觉-语言模型（VLMs）在图像分类、目标检测等开放词汇计算机视觉任务中取得了显著进展。近期研究还将VLMs应用于视频中的开放词汇单标签动作分类。然而，在需要同时识别视频中多个动作和实体的全面视频理解方面，现有方法尚显不足。为此，我们提出了开放词汇多标签视频分类问题，并设计了一种方法，使预训练的VLM（如CLIP）能够适应这一挑战。我们借助大型语言模型（LLMs）为VLM提供类别标签的语义指导，以提升其开放词汇性能。具体来说，我们设计了一种端到端架构，引导LLM生成软属性，帮助CLIP文本编码器识别新类别；同时，我们为CLIP视觉编码器引入了时间建模模块，有效捕捉视频概念的时空动态，并通过一种新颖的正则化微调技术，确保视频领域中卓越的开放词汇分类性能。实验结果表明，我们的方法在多个基准数据集上表现出色。",
    "title_cn": "开放词汇多标签视频分类技术",
    "tags": [
      "LLM应用",
      "计算机视觉",
      "视频处理"
    ]
  },
  {
    "title": "New Desiderata for Direct Preference Optimization",
    "submit_datetime": "2024年07月12日",
    "abstract": "Large language models in the past have typically relied on some form of reinforcement learning with human feedback (RLHF) to better align model responses with human preferences. However, because of oft-observed instabilities when implementing these RLHF pipelines, various reparameterization techniques have recently been introduced to sidestep the need for separately learning an RL reward model. Instead, directly fine-tuning for human preferences is achieved via the minimization of a single closed-form training objective, a process originally referred to as direct preference optimization (DPO) and followed by several notable descendants. Although effective in certain real-world settings, we introduce new evaluation criteria that serve to highlight unresolved shortcomings in the ability of existing DPO methods to interpolate between a pre-trained reference model and empirical measures of human preferences, as well as unavoidable trade-offs in how low- and high-quality responses are regularized and constraints are handled. Our insights then motivate an alternative DPO-like loss that provably mitigates these limitations. Empirical results serve to corroborate notable aspects of our analyses.",
    "pdf_link": "https://arxiv.org/abs/2407.09072",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.09072v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09072/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09072v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09072/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09072v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09072/preservation_constraint.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09072v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09072/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09072v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09072/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09072v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09072/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09072v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09072/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09072v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09072/x7.png"
      }
    ],
    "abstract_cn": "过去，大型语言模型常借助人类反馈的强化学习（RLHF）来调整输出以符合人类偏好。但RLHF实施中的不稳定性促使近期采用重新参数化技术，避免独立学习奖励模型，而是通过简化训练目标直接优化人类偏好，即直接偏好优化（DPO）。尽管DPO在某些场景中表现出色，我们提出的新评估标准揭示了其在融合预训练模型与人类偏好间的不足，以及在响应质量和约束处理上的权衡。基于这些洞察，我们设计了一种改进的DPO式损失函数，有效缓解了上述问题，并通过实证验证了其优势。",
    "title_cn": "直接偏好优化的新要求",
    "tags": [
      "LLM理论",
      "人工智能",
      "机器学习"
    ]
  },
  {
    "title": "Sensorimotor Attention and Language-based Regressions in Shared Latent Variables for Integrating Robot Motion Learning and LLM",
    "submit_datetime": "2024年07月12日",
    "abstract": "In recent years, studies have been actively conducted on combining large language models (LLM) and robotics; however, most have not considered end-to-end feedback in the robot-motion generation phase. The prediction of deep neural networks must contain errors, it is required to update the trained model to correspond to the real environment to generate robot motion adaptively. This study proposes an integration method that connects the robot-motion learning model and LLM using shared latent variables. When generating robot motion, the proposed method updates shared parameters based on prediction errors from both sensorimotor attention points and task language instructions given to the robot. This allows the model to search for latent parameters appropriate for the robot task efficiently. Through simulator experiments on multiple robot tasks, we demonstrated the effectiveness of our proposed method from two perspectives: position generalization and language instruction generalization abilities.",
    "pdf_link": "https://arxiv.org/abs/2407.09044",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.09044v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09044/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09044v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09044/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09044v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09044/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09044v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09044/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09044v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09044/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09044v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09044/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09044v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09044/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09044v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09044/x8.png"
      }
    ],
    "abstract_cn": "近年来，大型语言模型 (LLM) 与机器人学的结合研究日益活跃，但多数研究忽视了机器人运动生成中的端到端反馈。鉴于深度神经网络预测的固有误差，本研究提出一种创新集成方法，通过共享潜在变量将机器人运动学习模型与 LLM 紧密结合。该方法在生成机器人运动时，根据传感器反馈和任务指令的预测误差动态调整共享参数，从而高效地优化适合特定任务的潜在参数。通过多任务模拟实验，我们的方法在位置泛化和语言指令泛化方面展现了显著优势。",
    "title_cn": "通过共享潜在变量，结合机器人运动学习与大型语言模型，探讨感觉运动注意与基于语言的回归机制。",
    "tags": [
      "Agent",
      "机器人学",
      "人工智能"
    ]
  },
  {
    "title": "SpreadsheetLLM: Encoding Spreadsheets for Large Language Models",
    "submit_datetime": "2024年07月12日",
    "abstract": "Spreadsheets, with their extensive two-dimensional grids, various layouts, and diverse formatting options, present notable challenges for large language models (LLMs). In response, we introduce SpreadsheetLLM, pioneering an efficient encoding method designed to unleash and optimize LLMs' powerful understanding and reasoning capability on spreadsheets. Initially, we propose a vanilla serialization approach that incorporates cell addresses, values, and formats. However, this approach was limited by LLMs' token constraints, making it impractical for most applications. To tackle this challenge, we develop SheetCompressor, an innovative encoding framework that compresses spreadsheets effectively for LLMs. It comprises three modules: structural-anchor-based compression, inverse index translation, and data-format-aware aggregation. It significantly improves performance in spreadsheet table detection task, outperforming the vanilla approach by 25.6% in GPT4's in-context learning setting. Moreover, fine-tuned LLM with SheetCompressor has an average compression ratio of 25 times, but achieves a state-of-the-art 78.9% F1 score, surpassing the best existing models by 12.3%. Finally, we propose Chain of Spreadsheet for downstream tasks of spreadsheet understanding and validate in a new and demanding spreadsheet QA task. We methodically leverage the inherent layout and structure of spreadsheets, demonstrating that SpreadsheetLLM is highly effective across a variety of spreadsheet tasks.",
    "pdf_link": "https://arxiv.org/abs/2407.09025",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.09025v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09025/overview.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09025v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09025/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09025v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09025/GPT-4-1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09025v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09025/GPT-4-2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09025v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09025/traditional_enc.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09025v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09025/heu.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09025v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09025/case1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09025v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09025/case2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09025v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09025/case3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09025v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09025/case_compare1.png"
      }
    ],
    "abstract_cn": "电子表格因其复杂的两维网格、多变的布局和丰富的格式选项，对大型语言模型（LLMs）构成了挑战。为此，我们推出了SpreadsheetLLM，采用一种高效编码方法，旨在充分发挥LLMs在电子表格上的理解和推理能力。我们最初尝试了一种简单的序列化方法，结合单元格地址、值和格式，但受限于LLMs的标记限制，实用性有限。为解决这一问题，我们创新性地开发了SheetCompressor框架，通过三个模块——基于结构锚的压缩、逆索引转换和数据格式感知的聚合，有效压缩电子表格，显著提升了表格检测任务的性能，在GPT4的上下文学习设置中，性能比简单方法高出25.6%。此外，经过SheetCompressor微调的LLM，平均压缩比达25倍，F1分数高达78.9%，超越了现有最佳模型12.3%。最后，我们提出了电子表格链（Chain of Spreadsheet），用于电子表格理解和验证的新颖且具有挑战性的电子表格QA任务，系统地利用了电子表格的固有布局和结构，证明了SpreadsheetLLM在各种电子表格任务中的高效性。",
    "title_cn": "SpreadsheetLLM：将电子表格编码以供大型语言模型使用",
    "tags": [
      "LLM应用",
      "电子表格",
      "人工智能"
    ]
  },
  {
    "title": "Challenges of Anomaly Detection in the Object-Centric Setting: Dimensions and the Role of Domain Knowledge",
    "submit_datetime": "2024年07月12日",
    "abstract": "Object-centric event logs, allowing events related to different objects of different object types, represent naturally the execution of business processes, such as ERP (O2C and P2P) and CRM. However, modeling such complex information requires novel process mining techniques and might result in complex sets of constraints. Object-centric anomaly detection exploits both the lifecycle and the interactions between the different objects. Therefore, anomalous patterns are proposed to the user without requiring the definition of object-centric process models. This paper proposes different methodologies for object-centric anomaly detection and discusses the role of domain knowledge for these methodologies. We discuss the advantages and limitations of Large Language Models (LLMs) in the provision of such domain knowledge. Following our experience in a real-life P2P process, we also discuss the role of algorithms (dimensionality reduction+anomaly detection), suggest some pre-processing steps, and discuss the role of feature propagation.",
    "pdf_link": "https://arxiv.org/abs/2407.09023",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.09023v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09023/outline.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09023v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09023/invoices.png"
      }
    ],
    "abstract_cn": "以对象为中心的事件日志能够自然地展现业务流程的执行，如 ERP 和 CRM。然而，这类复杂信息的建模需要创新的过程挖掘技术，并可能产生复杂的约束集合。本文探讨了以对象为中心的异常检测方法，利用对象间的生命周期和交互，无需预设模型即可识别异常模式。同时，我们分析了领域知识在方法中的作用，以及大型语言模型在提供领域知识方面的优势与局限。基于实际 P2P 流程的经验，我们还探讨了算法组合（降维与异常检测）的应用，提出了预处理建议，并讨论了特征传播的重要性。",
    "title_cn": "以对象为中心的异常检测面临多重挑战，涉及维度问题及领域知识的关键角色。",
    "tags": [
      "LLM应用",
      "业务流程管理",
      "异常检测"
    ]
  },
  {
    "title": "Enhancing Few-Shot Stock Trend Prediction with Large Language Models",
    "submit_datetime": "2024年07月12日",
    "abstract": "The goal of stock trend prediction is to forecast future market movements for informed investment decisions. Existing methods mostly focus on predicting stock trends with supervised models trained on extensive annotated data. However, human annotation can be resource-intensive and the annotated data are not readily available. Inspired by the impressive few-shot capability of Large Language Models (LLMs), we propose using LLMs in a few-shot setting to overcome the scarcity of labeled data and make prediction more feasible to investors. Previous works typically merge multiple financial news for predicting stock trends, causing two significant problems when using LLMs: (1) Merged news contains noise, and (2) it may exceed LLMs' input limits, leading to performance degradation. To overcome these issues, we propose a two-step method 'denoising-then-voting'. Specifically, we introduce an `Irrelevant' category, and predict stock trends for individual news instead of merged news. Then we aggregate these predictions using majority voting. The proposed method offers two advantages: (1) Classifying noisy news as irrelevant removes its impact on the final prediction. (2) Predicting for individual news mitigates LLMs' input length limits. Our method achieves 66.59% accuracy in S&P 500, 62.17% in CSI-100, and 61.17% in HK stock prediction, outperforming the standard few-shot counterparts by around 7%, 4%, and 4%. Furthermore, our proposed method performs on par with state-of-the-art supervised methods.",
    "pdf_link": "https://arxiv.org/abs/2407.09003",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.09003v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09003/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09003v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09003/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09003v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09003/different_LLM_update3.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09003v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09003/x3.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.09003v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09003/append_sp500_standard.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09003v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09003/append_sp500_2vote_.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09003v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09003/append_sp500_3vote.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09003v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09003/append_csi_standard.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09003v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09003/append_csi_2vote_.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09003v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09003/append_csi_3vote.png"
      }
    ],
    "abstract_cn": "股票趋势预测旨在预见市场未来走向，助力明智投资。传统方法依赖大量标注数据，但人工标注成本高昂且数据难求。借鉴大型语言模型（LLM）的少样本学习能力，我们提出在少样本场景下利用LLM，以缓解标签数据稀缺问题，使预测更贴近投资者需求。过往研究常合并财经新闻进行预测，这给LLM应用带来两大难题：新闻合并带来的噪音和输入限制导致的性能下降。为此，我们创新提出“去噪然后投票”的两步策略：首先引入“无关”类别，对单条新闻进行趋势预测，再通过多数投票整合预测结果。此法两大亮点：一是剔除噪音新闻对预测的干扰，二是规避LLM输入长度限制。实测显示，我们的方法在S&P 500、CSI-100及香港股市预测中准确率分别达66.59%、62.17%和61.17%，较传统少样本方法提升显著，且与顶尖监督方法不相上下。",
    "title_cn": "利用大型语言模型提升少量样本下的股票趋势预测能力",
    "tags": [
      "LLM应用",
      "",
      ""
    ]
  },
  {
    "title": "Robustness of LLMs to Perturbations in Text",
    "submit_datetime": "2024年07月12日",
    "abstract": "Having a clean dataset has been the foundational assumption of most natural language processing (NLP) systems. However, properly written text is rarely found in real-world scenarios and hence, oftentimes invalidates the aforementioned foundational assumption. Recently, Large language models (LLMs) have shown impressive performance, but can they handle the inevitable noise in real-world data? This work tackles this critical question by investigating LLMs' resilience against morphological variations in text. To that end, we artificially introduce varying levels of noise into a diverse set of datasets and systematically evaluate LLMs' robustness against the corrupt variations of the original text. Our findings show that contrary to popular beliefs, generative LLMs are quiet robust to noisy perturbations in text. This is a departure from pre-trained models like BERT or RoBERTa whose performance has been shown to be sensitive to deteriorating noisy text. Additionally, we test LLMs' resilience on multiple real-world benchmarks that closely mimic commonly found errors in the wild. With minimal prompting, LLMs achieve a new state-of-the-art on the benchmark tasks of Grammar Error Correction (GEC) and Lexical Semantic Change (LSC). To empower future research, we also release a dataset annotated by humans stating their preference for LLM vs. human-corrected outputs along with the code to reproduce our results.",
    "pdf_link": "https://arxiv.org/abs/2407.08989",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.08989v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08989/fig.png"
      }
    ],
    "abstract_cn": "在NLP领域，一个“干净”的数据集常被视为基石。但现实中，规范文本难得一见，这一假设往往站不住脚。近期，大型语言模型（LLMs）虽表现抢眼，却面临现实数据噪声的考验。本研究深入探讨了LLMs对文本形态变异的抗噪能力。我们精心设计，在各类数据集中注入不同噪声，系统检验LLMs的稳健性。结果出人意料，生成型LLMs对文本噪声的抵抗力颇强，与BERT等模型对噪声敏感的表现形成鲜明对比。此外，我们在模拟真实错误的基准测试中，LLMs仅凭少量提示便刷新了GEC和LSC任务的纪录。为推动后续研究，我们公开了人类偏好标注数据集及复现代码，助力学术探索。",
    "title_cn": "LLM 在面对文本扰动时的稳健性",
    "tags": [
      "LLM应用",
      "",
      "数据科学"
    ]
  },
  {
    "title": "Towards More Trustworthy and Interpretable LLMs for Code through Syntax-Grounded Explanations",
    "submit_datetime": "2024年07月12日",
    "abstract": "Trustworthiness and interpretability are inextricably linked concepts for LLMs. The more interpretable an LLM is, the more trustworthy it becomes. However, current techniques for interpreting LLMs when applied to code-related tasks largely focus on accuracy measurements, measures of how models react to change, or individual task performance instead of the fine-grained explanations needed at prediction time for greater interpretability, and hence trust. To improve upon this status quo, this paper introduces ASTrust, an interpretability method for LLMs of code that generates explanations grounded in the relationship between model confidence and syntactic structures of programming languages. ASTrust explains generated code in the context of syntax categories based on Abstract Syntax Trees and aids practitioners in understanding model predictions at both local (individual code snippets) and global (larger datasets of code) levels. By distributing and assigning model confidence scores to well-known syntactic structures that exist within ASTs, our approach moves beyond prior techniques that perform token-level confidence mapping by offering a view of model confidence that directly aligns with programming language concepts with which developers are familiar. To put ASTrust into practice, we developed an automated visualization that illustrates the aggregated model confidence scores superimposed on sequence, heat-map, and graph-based visuals of syntactic structures from ASTs. We examine both the practical benefit that ASTrust can provide through a data science study on 12 popular LLMs on a curated set of GitHub repos and the usefulness of ASTrust through a human study.",
    "pdf_link": "https://arxiv.org/abs/2407.08983",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.08983v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08983/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08983v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08983/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08983v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08983/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08983v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08983/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08983v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08983/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08983v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08983/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08983v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08983/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08983v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08983/x8.png"
      }
    ],
    "abstract_cn": "LLMs的可信度与可解释性紧密相连。模型越透明，其可信度越高。然而，当前解释代码任务中LLM的技术多聚焦于准确性、模型对变化的响应或单任务表现，而非预测时所需的细致解释。为此，我们提出了ASTRust，一种基于模型置信度与编程语言语法结构关系的解释方法。ASTRust利用抽象语法树，在语法类别背景下阐释代码，助力开发者深入理解模型预测，无论是局部代码片段还是全局代码集。通过将置信度分数赋予AST中的常见语法结构，我们的方法超越了传统的令牌级置信度映射，提供了一种与开发者熟悉的编程概念直接对齐的模型置信度视图。实践中，我们开发了自动可视化工具，展示模型置信度分数在语法结构上的叠加，包括序列、热图和图形视觉。通过在精选GitHub仓库上对12个流行LLMs的数据科学研究和人类研究，我们验证了ASTRust的实际效益和有用性。",
    "title_cn": "通过基于语法的解释，我们致力于让代码的 LLM 更加可靠和易于理解。",
    "tags": [
      "LLM应用",
      "软件开发",
      "数据科学"
    ]
  },
  {
    "title": "Towards Chapter-to-Chapter Context-Aware Literary Translation via Large Language Models",
    "submit_datetime": "2024年07月12日",
    "abstract": "Discourse phenomena in existing document-level translation datasets are sparse, which has been a fundamental obstacle in the development of context-aware machine translation models. Moreover, most existing document-level corpora and context-aware machine translation methods rely on an unrealistic assumption on sentence-level alignments. To mitigate these issues, we first curate a novel dataset of Chinese-English literature, which consists of 160 books with intricate discourse structures. Then, we propose a more pragmatic and challenging setting for context-aware translation, termed chapter-to-chapter (Ch2Ch) translation, and investigate the performance of commonly-used machine translation models under this setting. Furthermore, we introduce a potential approach of finetuning large language models (LLMs) within the domain of Ch2Ch literary translation, yielding impressive improvements over baselines. Through our comprehensive analysis, we unveil that literary translation under the Ch2Ch setting is challenging in nature, with respect to both model learning methods and translation decoding algorithms.",
    "pdf_link": "https://arxiv.org/abs/2407.08978",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.08978v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08978/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08978v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08978/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08978v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08978/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08978v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08978/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08978v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08978/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08978v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08978/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08978v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08978/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08978v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08978/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08978v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08978/x9.png"
      }
    ],
    "abstract_cn": "现有文档级翻译数据集中的语篇现象稀少，成为开发上下文感知机器翻译模型的障碍。多数方法依赖于不切实际的句子级对齐假设。为此，我们策划了包含160本复杂语篇结构的中英文文学数据集，并提出更具挑战性的章节到章节（Ch2Ch）翻译设置，研究常用模型的性能。我们还探索了在Ch2Ch文学翻译领域微调大型语言模型的方法，显著提升了性能。分析表明，Ch2Ch文学翻译在模型学习和解码算法方面均具挑战性。",
    "title_cn": "借助大型语言模型，我们迈向了章节间上下文感知的文学翻译新境界。",
    "tags": [
      "LLM应用",
      "",
      ""
    ]
  },
  {
    "title": "CompAct: Compressing Retrieved Documents Actively for Question Answering",
    "submit_datetime": "2024年07月12日",
    "abstract": "Retrieval-augmented generation supports language models to strengthen their factual groundings by providing external contexts. However, language models often face challenges when given extensive information, diminishing their effectiveness in solving questions. Context compression tackles this issue by filtering out irrelevant information, but current methods still struggle in realistic scenarios where crucial information cannot be captured with a single-step approach. To overcome this limitation, we introduce CompAct, a novel framework that employs an active strategy to condense extensive documents without losing key information. Our experiments demonstrate that CompAct brings significant improvements in both performance and compression rate on multi-hop question-answering (QA) benchmarks. CompAct flexibly operates as a cost-efficient plug-in module with various off-the-shelf retrievers or readers, achieving exceptionally high compression rates (47x).",
    "pdf_link": "https://arxiv.org/abs/2407.09014",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.09014v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09014/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09014v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09014/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09014v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09014/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09014v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09014/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09014v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09014/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09014v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09014/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09014v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09014/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09014v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09014/x8.png"
      }
    ],
    "abstract_cn": "检索增强生成帮助语言模型通过外部上下文巩固事实基础，但面对海量信息时，模型效能常受挑战。上下文压缩虽能滤除无关信息，但在现实场景中，关键信息难以一蹴而就。为此，我们创新推出CompAct框架，以主动策略精简文档，确保信息不失真。实验显示，CompAct在多跳问答基准上，性能与压缩率双双提升。它如灵活的插件，与各类检索器或阅读器无缝对接，压缩效率高达47倍，成本效益显著。",
    "title_cn": "CompAct：为问答任务主动压缩检索文档",
    "tags": [
      "RAG",
      "问答系统",
      "信息检索"
    ]
  },
  {
    "title": "ICCV23 Visual-Dialog Emotion Explanation Challenge: SEU_309 Team Technical Report",
    "submit_datetime": "2024年07月12日",
    "abstract": "The Visual-Dialog Based Emotion Explanation Generation Challenge focuses on generating emotion explanations through visual-dialog interactions in art discussions. Our approach combines state-of-the-art multi-modal models, including Language Model (LM) and Large Vision Language Model (LVLM), to achieve superior performance. By leveraging these models, we outperform existing benchmarks, securing the top rank in the ICCV23 Visual-Dialog Based Emotion Explanation Generation Challenge, which is part of the 5th Workshop On Closing The Loop Between Vision And Language (CLCV) with significant scores in F1 and BLEU metrics. Our method demonstrates exceptional ability in generating accurate emotion explanations, advancing our understanding of emotional impacts in art.",
    "pdf_link": "https://arxiv.org/abs/2407.09760",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.09760v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09760/x1.png"
      }
    ],
    "abstract_cn": "我们通过结合尖端的多模态技术，如语言模型和大型视觉语言模型，在基于视觉对话的情感解释生成挑战中脱颖而出。这一创新方法不仅超越了行业标准，更在ICCV23挑战赛中荣登榜首，成为视觉与语言闭环研讨会（CLCV）的亮点。在F1和BLEU评分上的显著成绩，证明了我们方法在精准捕捉艺术情感方面的非凡实力，深化了我们对艺术情感表达的理解。",
    "title_cn": "ICCV23 视觉对话情感解释挑战：SEU_309 团队技术报告",
    "tags": [
      "RAG",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Multi-Token Joint Speculative Decoding for Accelerating Large Language Model Inference",
    "submit_datetime": "2024年07月12日",
    "abstract": "Transformer-based Large language models (LLMs) have demonstrated their power in various tasks, but their inference incurs significant time and energy costs. To accelerate LLM inference, speculative decoding uses a smaller model to propose one sequence of tokens, which are subsequently validated in batch by the target large model. Compared with autoregressive decoding, speculative decoding generates the same number of tokens with fewer runs of the large model, hence accelerating the overall inference by $1$-$2\\times$. However, greedy decoding is not the optimal decoding algorithm in terms of output perplexity, which is a direct measurement of the effectiveness of a decoding algorithm. An algorithm that has better output perplexity and even better efficiency than speculative decoding can be more useful in practice. To achieve this seemingly contradictory goal, we first introduce multi-token joint greedy decoding (MJGD), which greedily generates multiple tokens at each step based on their joint perplexity. We show that it leads to better perplexity for the whole output. But the computation cost of MJGD is infeasible in practice. So we further propose multi-token joint speculative decoding (MJSD), which approximates and accelerates the MJGD from two aspects: it approximates the joint distribution of the large model with that of a small model, and uses a verification step to guarantee the accuracy of approximation; then it uses beam decoding to accelerate the sequence generation from the joint distribution. Compared with vanilla speculative decoding, MJSD has two advantages: (1) it is an approximation of MJGD, thus achieving better output perplexity; (2) verification with joint likelihood allows it to accept the longest prefix sub-sequence of the draft tokens with valid perplexity, leading to better efficiency...",
    "pdf_link": "https://arxiv.org/abs/2407.09722",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.09722v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09722/k-tokenGD.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09722v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09722/k-tokenGD-rouge.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09722v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09722/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09722v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09722/accepted_len.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09722v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09722/ppl_tau.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09722v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09722/speed_tau.png"
      }
    ],
    "abstract_cn": "基于Transformer的LLM在多任务中展现了强大实力，但其推理过程耗时耗能。推测性解码通过小模型预提令牌，再由大模型批量验证，相比自回归解码，以更少运行次数生成等量令牌，提速1-2倍。然而，贪婪解码在输出质量上并非最优。为追求更高输出质量和效率，我们提出多令牌联合贪婪解码（MJGD），每步基于联合困惑度生成多令牌，提升整体输出质量。但MJGD计算成本过高。为此，我们创新多令牌联合推测性解码（MJSD），通过小模型近似大模型联合分布并验证，结合束解码加速序列生成。MJSD不仅近似MJGD，提升输出质量，还通过联合似然验证，优化令牌前缀选择，增强效率...",
    "title_cn": "通过多令牌联合推测解码技术，我们旨在加速大型语言模型的推理过程。",
    "tags": [
      "LLM理论",
      "人工智能",
      ""
    ]
  },
  {
    "title": "GOFA: A Generative One-For-All Model for Joint Graph Language Modeling",
    "submit_datetime": "2024年07月12日",
    "abstract": "Foundation models, such as Large Language Models (LLMs) or Large Vision Models (LVMs), have emerged as one of the most powerful tools in the respective fields. However, unlike text and image data, graph data do not have a definitive structure, posing great challenges to developing a Graph Foundation Model (GFM). For example, current attempts at designing general graph models either transform graph data into a language format for LLM-based prediction or still train a GNN model with LLM as an assistant. The former can handle unlimited tasks, while the latter captures graph structure much better -- yet, no existing work can achieve both simultaneously. In this paper, we identify three key desirable properties of a GFM: self-supervised pretraining, fluidity in tasks, and graph awareness. To account for these properties, we extend the conventional language modeling to the graph domain and propose a novel generative graph language model GOFA to solve the problem. The model interleaves randomly initialized GNN layers into a frozen pre-trained LLM so that the semantic and structural modeling abilities are organically combined. GOFA is pre-trained on newly proposed graph-level next-word prediction, question-answering, and structural tasks to obtain the above GFM properties. The pre-trained model is further fine-tuned on downstream tasks to obtain task-solving ability. The fine-tuned model is evaluated on various downstream tasks, demonstrating a strong ability to solve structural and contextual problems in zero-shot scenarios. The code is available at https://github.com/JiaruiFeng/GOFA.",
    "pdf_link": "https://arxiv.org/abs/2407.09709",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.09709v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09709/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09709v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09709/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09709v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09709/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09709v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09709/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09709v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09709/x5.png"
      }
    ],
    "abstract_cn": "基础模型，如LLM和LVM，已成为各自领域的强大工具。然而，图数据的非结构化特性为开发GFM带来了挑战。现有方法要么将图数据转换为语言格式，要么依赖LLM辅助的GNN模型，但无法同时兼顾任务多样性和结构捕捉。本文提出GFM的三个关键属性：自监督预训练、任务适应性和图意识。为此，我们创新性地将语言建模扩展至图领域，并设计了GOFA模型，通过将GNN层与预训练LLM结合，实现了语义与结构的融合。GOFA在图级任务上预训练，并在下游任务上微调，展现了在零-shot场景中解决复杂问题的能力。代码已公开，供研究者参考。",
    "title_cn": "GOFA：一款全能型生成模型，专为联合图语言建模设计。",
    "tags": [
      "LLM应用",
      "图数据",
      "人工智能"
    ]
  },
  {
    "title": "What an Elegant Bridge: Multilingual LLMs are Biased Similarly in Different Languages",
    "submit_datetime": "2024年07月12日",
    "abstract": "This paper investigates biases of Large Language Models (LLMs) through the lens of grammatical gender. Drawing inspiration from seminal works in psycholinguistics, particularly the study of gender's influence on language perception, we leverage multilingual LLMs to revisit and expand upon the foundational experiments of Boroditsky (2003). Employing LLMs as a novel method for examining psycholinguistic biases related to grammatical gender, we prompt a model to describe nouns with adjectives in various languages, focusing specifically on languages with grammatical gender. In particular, we look at adjective co-occurrences across gender and languages, and train a binary classifier to predict grammatical gender given adjectives an LLM uses to describe a noun. Surprisingly, we find that a simple classifier can not only predict noun gender above chance but also exhibit cross-language transferability. We show that while LLMs may describe words differently in different languages, they are biased similarly.",
    "pdf_link": "https://arxiv.org/abs/2407.09704",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.09704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09704/nlp-method-v4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09704/spanish_plot_7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09704/confusion_matrix_last_cropped.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09704/x1.png"
      }
    ],
    "abstract_cn": "本文从语法性别的角度探讨了大型语言模型的偏见。受心理语言学中性别对语言感知影响的启发，我们利用多语种 LLM 重新审视并扩展了 Boroditsky (2003) 的实验。通过引导模型用不同语言的形容词描述名词，特别是那些具有语法性别的语言，我们观察形容词在不同性别和语言中的共现情况，并训练分类器预测语法性别。令人惊讶的是，简单的分类器不仅能准确预测名词性别，还展现出跨语言的适用性。研究表明，尽管 LLM 在不同语言中的描述方式各异，但其偏见却惊人地一致。",
    "title_cn": "多语言大型语言模型在不同语言中展现出相似的偏见，宛如一座优雅的桥梁，连接着语言的多样性与偏见的共性。",
    "tags": [
      "LLM应用",
      "语言学",
      "人工智能"
    ]
  },
  {
    "title": "Large Language Models for Integrating Social Determinant of Health Data: A Case Study on Heart Failure 30-Day Readmission Prediction",
    "submit_datetime": "2024年07月12日",
    "abstract": "Social determinants of health (SDOH) $-$ the myriad of circumstances in which people live, grow, and age $-$ play an important role in health outcomes. However, existing outcome prediction models often only use proxies of SDOH as features. Recent open data initiatives present an opportunity to construct a more comprehensive view of SDOH, but manually integrating the most relevant data for individual patients becomes increasingly challenging as the volume and diversity of public SDOH data grows. Large language models (LLMs) have shown promise at automatically annotating structured data. Here, we conduct an end-to-end case study evaluating the feasibility of using LLMs to integrate SDOH data, and the utility of these SDOH features for clinical prediction. We first manually label 700+ variables from two publicly-accessible SDOH data sources to one of five semantic SDOH categories. Then, we benchmark performance of 9 open-source LLMs on this classification task. Finally, we train ML models to predict 30-day hospital readmission among 39k heart failure (HF) patients, and we compare the prediction performance of the categorized SDOH variables with standard clinical variables. Additionally, we investigate the impact of few-shot LLM prompting on LLM annotation performance, and perform a metadata ablation study on prompts to evaluate which information helps LLMs accurately annotate these variables. We find that some open-source LLMs can effectively, accurately annotate SDOH variables with zero-shot prompting without the need for fine-tuning. Crucially, when combined with standard clinical features, the LLM-annotated Neighborhood and Built Environment subset of the SDOH variables shows the best performance predicting 30-day readmission of HF patients.",
    "pdf_link": "https://arxiv.org/abs/2407.09688",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.09688v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09688/x1.png"
      }
    ],
    "abstract_cn": "健康社会决定因素（SDOH）对健康结果有重要影响，但现有模型多仅使用SDOH的代理特征。开放数据倡议提供了构建更全面SDOH视图的机会，但随着数据量和多样性的增加，手动整合相关数据变得更具挑战性。大型语言模型（LLMs）在自动注释结构化数据方面显示出潜力。我们进行了一项端到端研究，评估LLMs整合SDOH数据的可行性及其在临床预测中的实用性。我们首先手动将700多个变量分类到五个SDOH语义类别，然后测试了9个开源LLMs的分类性能。接着，我们训练模型预测心力衰竭患者30天再入院，并比较了SDOH变量与标准临床变量的预测性能。此外，我们研究了少量样本提示对LLM注释性能的影响，并进行了元数据消融研究，以确定哪些信息有助于准确注释。研究发现，某些开源LLMs无需微调即可通过零-shot提示有效注释SDOH变量。当与标准临床特征结合时，LLM注释的邻里和建筑环境子集在预测心力衰竭患者30天再入院方面表现最佳。",
    "title_cn": "利用大型语言模型整合健康社会决定因素数据：心力衰竭30天再入院预测案例研究",
    "tags": [
      "LLM应用",
      "",
      "社会科学"
    ]
  },
  {
    "title": "On Mitigating Code LLM Hallucinations with API Documentation",
    "submit_datetime": "2024年07月12日",
    "abstract": "In this study, we address the issue of API hallucinations in various software engineering contexts. We introduce CloudAPIBench, a new benchmark designed to measure API hallucination occurrences. CloudAPIBench also provides annotations for frequencies of API occurrences in the public domain, allowing us to study API hallucinations at various frequency levels. Our findings reveal that Code LLMs struggle with low frequency APIs: for e.g., GPT-4o achieves only 38.58% valid low frequency API invocations. We demonstrate that Documentation Augmented Generation (DAG) significantly improves performance for low frequency APIs (increase to 47.94% with DAG) but negatively impacts high frequency APIs when using sub-optimal retrievers (a 39.02% absolute drop). To mitigate this, we propose to intelligently trigger DAG where we check against an API index or leverage Code LLMs' confidence scores to retrieve only when needed. We demonstrate that our proposed methods enhance the balance between low and high frequency API performance, resulting in more reliable API invocations (8.20% absolute improvement on CloudAPIBench for GPT-4o).",
    "pdf_link": "https://arxiv.org/abs/2407.09726",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.09726v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09726/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09726v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09726/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09726v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09726/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09726v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09726/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09726v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09726/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09726v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09726/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09726v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09726/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09726v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09726/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09726v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09726/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09726v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09726/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09726v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09726/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09726v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09726/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09726v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09726/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09726v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09726/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09726v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09726/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09726v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09726/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09726v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09726/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09726v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09726/x18.png"
      }
    ],
    "abstract_cn": "本研究聚焦于软件工程中的API幻觉问题，并推出了CloudAPIBench基准，用于量化API幻觉现象。该基准还提供了公共领域API频率的详细注释，助力我们在不同频率层面深入探究API幻觉。研究发现，代码LLM在处理低频API时表现不佳，如GPT-4o仅能实现38.58%的有效调用。通过引入文档增强生成（DAG），我们显著提升了低频API的性能至47.94%，但若检索器选择不当，高频API性能会大幅下降39.02%。为此，我们提出智能触发DAG策略，通过API索引或LLM置信度分数进行精准检索，以平衡高低频API性能，最终实现更可靠的API调用，GPT-4o在CloudAPIBench上的性能提升了8.20%。",
    "title_cn": "利用 API 文档减轻代码 LLM 的幻觉问题",
    "tags": [
      "LLM应用",
      "软件工程",
      "人工智能"
    ]
  },
  {
    "title": "Investigating LLMs as Voting Assistants via Contextual Augmentation: A Case Study on the European Parliament Elections 2024",
    "submit_datetime": "2024年07月11日",
    "abstract": "Instruction-finetuned Large Language Models exhibit unprecedented Natural Language Understanding capabilities. Recent work has been exploring political biases and political reasoning capabilities in LLMs, mainly scoped in the US context. In light of the recent 2024 European Parliament elections, we are investigating if LLMs can be used as Voting Advice Applications (VAAs). We audit MISTRAL and MIXTRAL models and evaluate their accuracy in predicting the stance of political parties based on the latest \"EU and I\" voting assistance questionnaire. Furthermore, we explore alternatives to improve models' performance by augmenting the input context via Retrieval-Augmented Generation (RAG) relying on web search, and Self-Reflection using staged conversations that aim to re-collect relevant content from the model's internal memory. We find that MIXTRAL is highly accurate with an 82% accuracy on average. Augmenting the input context with expert-curated information can lead to a significant boost of approx. 9%, which remains an open challenge for automated approaches.",
    "pdf_link": "https://arxiv.org/abs/2407.08495",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.08495v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08495/framework_3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08495v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08495/main_results.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08495v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08495/ablation_self_augmented.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08495v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08495/rag_ablation.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08495v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08495/euro_parties.png"
      }
    ],
    "abstract_cn": "指令微调的大型语言模型在自然语言理解方面表现卓越。针对2024年欧洲议会选举，我们探讨了LLMs作为投票建议应用的可能性，并评估了MISTRAL和MIXTRAL模型的预测准确性。通过RAG和自省技术增强输入上下文，我们发现MIXTRAL平均准确率达82%，而专家信息能进一步提升约9%，这对自动化仍是一大挑战。",
    "title_cn": "探索 LLM 在上下文增强下的投票助理角色：2024 年欧洲议会选举实证研究",
    "tags": [
      "LLM应用",
      "",
      ""
    ]
  },
  {
    "title": "GTA: A Benchmark for General Tool Agents",
    "submit_datetime": "2024年07月11日",
    "abstract": "Significant focus has been placed on integrating large language models (LLMs) with various tools in developing general-purpose agents. This poses a challenge to LLMs' tool-use capabilities. However, there are evident gaps between existing tool-use evaluations and real-world scenarios. Current evaluations often use AI-generated queries, single-step tasks, dummy tools, and text-only interactions, failing to reveal the agents' real-world problem-solving abilities effectively. To address this, we propose GTA, a benchmark for General Tool Agents, featuring three main aspects: (i) Real user queries: human-written queries with simple real-world objectives but implicit tool-use, requiring the LLM to reason the suitable tools and plan the solution steps. (ii) Real deployed tools: an evaluation platform equipped with tools across perception, operation, logic, and creativity categories to evaluate the agents' actual task execution performance. (iii) Real multimodal inputs: authentic image files, such as spatial scenes, web page screenshots, tables, code snippets, and printed/handwritten materials, used as the query contexts to align with real-world scenarios closely. We design 229 real-world tasks and executable tool chains to evaluate mainstream LLMs. Our findings show that real-world user queries are challenging for existing LLMs, with GPT-4 completing less than 50% of the tasks and most LLMs achieving below 25%. This evaluation reveals the bottlenecks in the tool-use capabilities of current LLMs in real-world scenarios, which provides future direction for advancing general-purpose tool agents. The code and dataset are available at https://github.com/open-compass/GTA.",
    "pdf_link": "https://arxiv.org/abs/2407.08713",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.08713v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08713/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08713v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08713/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08713v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08713/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08713v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08713/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08713v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08713/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08713v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08713/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08713v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08713/egg.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.08713v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08713/ingredient.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.08713v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08713/warn.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.08713v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08713/map.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.08713v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08713/map_result.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08713v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08713/beer.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.08713v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08713/menu.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.08713v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08713/egg.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.08713v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08713/ingredient.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.08713v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08713/meme.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.08713v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08713/basketball.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.08713v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08713/pinkshirt.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.08713v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08713/dogs.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08713v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08713/handwritten_math.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.08713v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08713/print_math.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08713v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08713/financial_table.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.08713v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08713/financial_bar.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.08713v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08713/helmet.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08713v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08713/swan.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08713v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08713/orange.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08713v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08713/evidence1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08713v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08713/evidence2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08713v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08713/cow.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08713v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08713/evidence3.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.08713v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08713/bill.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08713v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08713/fishoil.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08713v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08713/order.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08713v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08713/gpu_table.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08713v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08713/mapotofu.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08713v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08713/evidence4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08713v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08713/disney.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08713v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08713/evidence5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08713v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08713/schedule.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08713v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08713/plane.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08713v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08713/evidence6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08713v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08713/amd.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08713v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08713/evidence7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08713v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08713/panel.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.08713v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08713/cake_ingredient.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08713v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08713/running.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08713v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08713/boy.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08713v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08713/lotus.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08713v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08713/orange.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08713v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08713/cow.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08713v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08713/apples.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08713v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08713/cola.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08713v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08713/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08713v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08713/men.jpg"
      }
    ],
    "abstract_cn": "在开发通用代理的过程中，大型语言模型（LLM）与多种工具的整合备受关注，这对LLM的工具使用能力构成了挑战。然而，现有评估与实际应用之间存在显著差距。目前的评估方法多采用AI生成的查询、单一任务、模拟工具及纯文本交互，未能充分展现代理在现实问题解决中的能力。为此，我们推出了GTA基准，专注于三个核心领域：（i）真实用户查询：包含简单现实目标但需隐含工具使用的人类编写查询，要求LLM进行工具选择与解决方案规划。（ii）真实部署工具：一个集成了感知、操作、逻辑和创造力工具的评估平台，用以检验代理的实际任务执行力。（iii）真实多模态输入：包括空间场景、网页截图、表格、代码片段及印刷/手写材料等真实图像文件，作为查询背景，以贴近现实情境。我们设计了229个现实任务及可执行工具链，对主流LLM进行了评估。结果显示，现实用户查询对现有LLM构成挑战，GPT-4完成率不足50%，多数LLM完成率低于25%。此次评估揭示了LLM在实际应用中工具使用能力的局限，为未来通用工具代理的发展指明了方向。相关代码和数据集已公开于https://github.com/open-compass/GTA。",
    "title_cn": "GTA：通用工具代理的评测标杆",
    "tags": [
      "Agent",
      "人工智能",
      "软件开发"
    ]
  },
  {
    "title": "Incorporating Large Language Models into Production Systems for Enhanced Task Automation and Flexibility",
    "submit_datetime": "2024年07月11日",
    "abstract": "This paper introduces a novel approach to integrating large language model (LLM) agents into automated production systems, aimed at enhancing task automation and flexibility. We organize production operations within a hierarchical framework based on the automation pyramid. Atomic operation functionalities are modeled as microservices, which are executed through interface invocation within a dedicated digital twin system. This allows for a scalable and flexible foundation for orchestrating production processes. In this digital twin system, low-level, hardware-specific data is semantically enriched and made interpretable for LLMs for production planning and control tasks. Large language model agents are systematically prompted to interpret these production-specific data and knowledge. Upon receiving a user request or identifying a triggering event, the LLM agents generate a process plan. This plan is then decomposed into a series of atomic operations, executed as microservices within the real-world automation system. We implement this overall approach on an automated modular production facility at our laboratory, demonstrating how the LLMs can handle production planning and control tasks through a concrete case study. This results in an intuitive production facility with higher levels of task automation and flexibility. Finally, we reveal the several limitations in realizing the full potential of the large language models in autonomous systems and point out promising benefits. Demos of this series of ongoing research series can be accessed at: https://github.com/YuchenXia/GPT4IndustrialAutomation",
    "pdf_link": "https://arxiv.org/abs/2407.08550",
    "graphs": [],
    "abstract_cn": "本文提出了一种创新方法，将大型语言模型（LLM）代理融入自动化生产系统，以提升任务自动化与灵活性。我们采用基于自动化金字塔的层级框架来组织生产操作，将原子操作功能建模为微服务，并通过专用数字孪生系统进行接口调用执行，从而构建了一个可扩展且灵活的生产流程编排基础。在该数字孪生系统中，硬件特定的低级数据经过语义增强，变得对LLM可解释，用于生产规划与控制。LLM代理系统地解读这些生产特定数据与知识，并在接收到用户请求或触发事件后，生成过程计划，随后分解为一系列原子操作，作为微服务在实际自动化系统中执行。我们在实验室的自动化模块化生产设施上实施了这一方法，通过具体案例展示了LLM在生产规划与控制中的应用，实现了更高级别的任务自动化与灵活性。同时，我们也指出了在自主系统中充分发挥LLM潜力的局限与前景。相关研究演示可访问：https://github.com/YuchenXia/GPT4IndustrialAutomation。",
    "title_cn": "整合大型语言模型至生产系统，提升任务自动化与灵活性",
    "tags": [
      "Agent",
      "制造业",
      "自动化"
    ]
  },
  {
    "title": "Converging Paradigms: The Synergy of Symbolic and Connectionist AI in LLM-Empowered Autonomous Agents",
    "submit_datetime": "2024年07月11日",
    "abstract": "This article explores the convergence of connectionist and symbolic artificial intelligence (AI), from historical debates to contemporary advancements. Traditionally considered distinct paradigms, connectionist AI focuses on neural networks, while symbolic AI emphasizes symbolic representation and logic. Recent advancements in large language models (LLMs), exemplified by ChatGPT and GPT-4, highlight the potential of connectionist architectures in handling human language as a form of symbols. The study argues that LLM-empowered Autonomous Agents (LAAs) embody this paradigm convergence. By utilizing LLMs for text-based knowledge modeling and representation, LAAs integrate neuro-symbolic AI principles, showcasing enhanced reasoning and decision-making capabilities. Comparing LAAs with Knowledge Graphs within the neuro-symbolic AI theme highlights the unique strengths of LAAs in mimicking human-like reasoning processes, scaling effectively with large datasets, and leveraging in-context samples without explicit re-training. The research underscores promising avenues in neuro-vector-symbolic integration, instructional encoding, and implicit reasoning, aimed at further enhancing LAA capabilities. By exploring the progression of neuro-symbolic AI and proposing future research trajectories, this work advances the understanding and development of AI technologies.",
    "pdf_link": "https://arxiv.org/abs/2407.08516",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.08516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08516/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08516/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08516/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08516/x4.png"
      }
    ],
    "abstract_cn": "本文深入探讨了连接主义与符号AI的融合历程，从早期的理论辩论到现今的技术突破。传统上，连接主义AI侧重于神经网络的构建，而符号AI则强调符号与逻辑的运用。随着ChatGPT和GPT-4等大型语言模型的兴起，连接主义架构在处理语言符号方面展现出巨大潜力。研究指出，由LLM驱动的自主代理（LAAs）正是这一融合趋势的体现。LAAs通过LLM进行文本知识建模，巧妙融合了神经与符号AI的精髓，显著提升了推理与决策能力。与知识图谱相比，LAAs在模拟人类推理、高效处理大数据集及无需重训练即可利用上下文信息方面展现出独特优势。研究还揭示了神经向量符号集成、指令编码及隐式推理等领域的广阔前景，旨在持续强化LAA的性能。通过梳理神经符号AI的发展脉络并展望未来研究方向，本文为AI技术的深化与拓展提供了宝贵见解。",
    "title_cn": "融合范式：符号与连接主义 AI 在 LLM 赋能自主代理中的协同效应",
    "tags": [
      "LLM理论",
      "人工智能",
      "语言模型"
    ]
  },
  {
    "title": "Beyond Instruction Following: Evaluating Rule Following of Large Language Models",
    "submit_datetime": "2024年07月11日",
    "abstract": "Although Large Language Models (LLMs) have demonstrated strong instruction-following ability to be helpful, they are further supposed to be controlled and guided by rules in real-world scenarios to be safe, and accurate in responses. This demands the possession of rule-following capability of LLMs. However, few works have made a clear evaluation of the rule-following capability of LLMs. Previous studies that try to evaluate the rule-following capability of LLMs fail to distinguish the rule-following scenarios from the instruction-following scenarios. Therefore, this paper first makes a clarification of the concept of rule-following, and curates a comprehensive benchmark, RuleBench, to evaluate a diversified range of rule-following abilities. Our experimental results on a variety of LLMs show that they are still limited in following rules. Our further analysis provides insights into the improvements for LLMs toward a better rule-following intelligent agent. The data and code can be found at: https://anonymous.4open.science/r/llm-rule-following-B3E3/",
    "pdf_link": "https://arxiv.org/abs/2407.08440",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.08440v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08440/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08440v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08440/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08440v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08440/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08440v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08440/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08440v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08440/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08440v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08440/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08440v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08440/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08440v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08440/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08440v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08440/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08440v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08440/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08440v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08440/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08440v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08440/x12.png"
      }
    ],
    "abstract_cn": "尽管 LLMs 在遵循指令方面表现出色，但在现实应用中，它们还需通过规则来确保安全和响应的准确性。然而，目前对 LLMs 规则遵循能力的评估尚不充分，且未能明确区分规则与指令遵循的场景。为此，本文首先明确了规则遵循的概念，并创建了全面基准 RuleBench，以评估 LLMs 在多种规则遵循任务中的表现。实验表明，LLMs 在规则遵循方面仍有提升空间。我们的深入分析为 LLMs 向更优秀的规则遵循智能代理的改进提供了方向。相关数据和代码已公开，详情请访问：https://anonymous.4open.science/r/llm-rule-following-B3E3/",
    "title_cn": "探究大型语言模型在遵循规则方面的表现，超越了简单的指令执行。",
    "tags": [
      "LLM应用",
      "人工智能",
      "软件开发"
    ]
  },
  {
    "title": "PrefCLM: Enhancing Preference-based Reinforcement Learning with Crowdsourced Large Language Models",
    "submit_datetime": "2024年07月11日",
    "abstract": "Preference-based reinforcement learning (PbRL) is emerging as a promising approach to teaching robots through human comparative feedback, sidestepping the need for complex reward engineering. However, the substantial volume of feedback required in existing PbRL methods often lead to reliance on synthetic feedback generated by scripted teachers. This approach necessitates intricate reward engineering again and struggles to adapt to the nuanced preferences particular to human-robot interaction (HRI) scenarios, where users may have unique expectations toward the same task. To address these challenges, we introduce PrefCLM, a novel framework that utilizes crowdsourced large language models (LLMs) as simulated teachers in PbRL. We utilize Dempster-Shafer Theory to fuse individual preferences from multiple LLM agents at the score level, efficiently leveraging their diversity and collective intelligence. We also introduce a human-in-the-loop pipeline that facilitates collective refinements based on user interactive feedback. Experimental results across various general RL tasks show that PrefCLM achieves competitive performance compared to traditional scripted teachers and excels in facilitating more more natural and efficient behaviors. A real-world user study (N=10) further demonstrates its capability to tailor robot behaviors to individual user preferences, significantly enhancing user satisfaction in HRI scenarios.",
    "pdf_link": "https://arxiv.org/abs/2407.08213",
    "graphs": [],
    "abstract_cn": "基于偏好的强化学习（PbRL）正成为一种通过人类比较反馈教授机器人的创新方法，避免了复杂的奖励设计。然而，现有方法对大量反馈的依赖往往转向脚本教师生成的合成反馈，这再次需要精细的奖励设计，并难以适应人类-机器人交互（HRI）中用户对任务的独特期望。为此，我们提出了PrefCLM框架，利用众包大型语言模型（LLMs）作为模拟教师，通过Dempster-Shafer理论融合多个LLM代理的偏好，有效整合多样性与集体智慧。同时，我们设计了包含人在回路的流程，以用户交互反馈为基础进行集体优化。实验表明，PrefCLM在通用RL任务中与传统脚本教师相比表现优异，并能促进更自然高效的行为。一项实际用户研究（N=10）进一步验证了其根据用户个性化需求定制机器人行为的能力，显著提升了HRI场景中的用户满意度。",
    "title_cn": "PrefCLM：利用众包大型语言模型提升基于偏好的强化学习效果",
    "tags": [
      "LLM应用",
      "机器人",
      "人机交互"
    ]
  },
  {
    "title": "SEED-Story: Multimodal Long Story Generation with Large Language Model",
    "submit_datetime": "2024年07月11日",
    "abstract": "With the remarkable advancements in image generation and open-form text generation, the creation of interleaved image-text content has become an increasingly intriguing field. Multimodal story generation, characterized by producing narrative texts and vivid images in an interleaved manner, has emerged as a valuable and practical task with broad applications. However, this task poses significant challenges, as it necessitates the comprehension of the complex interplay between texts and images, and the ability to generate long sequences of coherent, contextually relevant texts and visuals. In this work, we propose SEED-Story, a novel method that leverages a Multimodal Large Language Model (MLLM) to generate extended multimodal stories. Our model, built upon the powerful comprehension capability of MLLM, predicts text tokens as well as visual tokens, which are subsequently processed with an adapted visual de-tokenizer to produce images with consistent characters and styles. We further propose multimodal attention sink mechanism to enable the generation of stories with up to 25 sequences (only 10 for training) in a highly efficient autoregressive manner. Additionally, we present a large-scale and high-resolution dataset named StoryStream for training our model and quantitatively evaluating the task of multimodal story generation in various aspects.",
    "pdf_link": "https://arxiv.org/abs/2407.08683",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.08683v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08683/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08683v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08683/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08683v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08683/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08683v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08683/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08683v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08683/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08683v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08683/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08683v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08683/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08683v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08683/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08683v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08683/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08683v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08683/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08683v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08683/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08683v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08683/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08683v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08683/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08683v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08683/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08683v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08683/x15.png"
      }
    ],
    "abstract_cn": "随着图像与文本生成技术的飞速发展，交错式图像-文本内容的创作正变得愈发引人入胜。多模态故事生成，即以交错方式融合叙事文本与生动图像，已成为一项极具价值且实用的任务，应用前景广阔。然而，这一任务极具挑战性，因为它要求深刻理解文本与图像间的复杂互动，并能生成连贯且上下文相关的大量文本与视觉内容。为此，我们推出了SEED-Story，一种基于多模态大型语言模型（MLLM）的创新方法，旨在生成丰富的多模态故事。我们的模型依托MLLM的深厚理解力，不仅能预测文本元素，还能生成视觉元素，再通过特制的视觉去标记器，产出风格与角色一致的图像。此外，我们引入了多模态注意力下沉机制，使得模型能以高效的自回归方式，生成多达25个序列的故事（训练中仅用10个序列）。同时，我们还发布了大规模高分辨率数据集StoryStream，用于模型的训练与多模态故事生成任务的全面定量评估。",
    "title_cn": "SEED-Story：利用大型语言模型创作多模态长篇故事",
    "tags": [
      "LLM应用",
      "媒体与娱乐",
      ""
    ]
  },
  {
    "title": "Emergent Visual-Semantic Hierarchies in Image-Text Representations",
    "submit_datetime": "2024年07月11日",
    "abstract": "While recent vision-and-language models (VLMs) like CLIP are a powerful tool for analyzing text and images in a shared semantic space, they do not explicitly model the hierarchical nature of the set of texts which may describe an image. Conversely, existing multimodal hierarchical representation learning methods require costly training from scratch, failing to leverage the knowledge encoded by state-of-the-art multimodal foundation models. In this work, we study the knowledge of existing foundation models, finding that they exhibit emergent understanding of visual-semantic hierarchies despite not being directly trained for this purpose. We propose the Radial Embedding (RE) framework for probing and optimizing hierarchical understanding, and contribute the HierarCaps dataset, a benchmark facilitating the study of hierarchical knowledge in image--text representations, constructed automatically via large language models. Our results show that foundation VLMs exhibit zero-shot hierarchical understanding, surpassing the performance of prior models explicitly designed for this purpose. Furthermore, we show that foundation models may be better aligned to hierarchical reasoning via a text-only fine-tuning phase, while retaining pretraining knowledge.",
    "pdf_link": "https://arxiv.org/abs/2407.08521",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.08521v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08521/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08521v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08521/x2.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.08521v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08521/x3.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.08521v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08521/sd.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.08521v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08521/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08521v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08521/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08521v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08521/snail.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.08521v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08521/cats.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.08521v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08521/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08521v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08521/zoomed_stroked.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08521v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08521/img0.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08521v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08521/img1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08521v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08521/img2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08521v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08521/img3.png"
      }
    ],
    "abstract_cn": "尽管如CLIP这样的视觉与语言模型在分析文本和图像方面表现出色，但它们并未明确考虑描述图像的文本集合的分层结构。相反，传统多模态分层学习方法需从零开始训练，未能利用现有先进模型的知识。我们研究发现，这些模型虽未专门训练，却能自发理解视觉-语义层次。为此，我们提出径向嵌入框架，并创建HierarCaps数据集，助力分层知识研究。实验表明，基础模型在无需专门训练的情况下，其分层理解能力超越了传统模型。此外，通过仅文本微调，这些模型能更好地适应分层推理，同时保留预训练知识。",
    "title_cn": "图像-文本表示中涌现的视觉-语义层次结构",
    "tags": [
      "LLM应用",
      "计算机视觉",
      ""
    ]
  },
  {
    "title": "DenseFusion-1M: Merging Vision Experts for Comprehensive Multimodal Perception",
    "submit_datetime": "2024年07月11日",
    "abstract": "Existing Multimodal Large Language Models (MLLMs) increasingly emphasize complex understanding of various visual elements, including multiple objects, text information, and spatial relations. Their development for comprehensive visual perception hinges on the availability of high-quality image-text datasets that offer diverse visual elements and throughout image descriptions. However, the scarcity of such hyper-detailed datasets currently hinders progress within the MLLM community. The bottleneck stems from the limited perceptual capabilities of current caption engines, which fall short in providing complete and accurate annotations. To facilitate the cutting-edge research of MLLMs on comprehensive vision perception, we thereby propose Perceptual Fusion, using a low-budget but highly effective caption engine for complete and accurate image descriptions. Specifically, Perceptual Fusion integrates diverse perception experts as image priors to provide explicit information on visual elements and adopts an efficient MLLM as a centric pivot to mimic advanced MLLMs' perception abilities. We carefully select 1M highly representative images from uncurated LAION dataset and generate dense descriptions using our engine, dubbed DenseFusion-1M. Extensive experiments validate that our engine outperforms its counterparts, where the resulting dataset significantly improves the perception and cognition abilities of existing MLLMs across diverse vision-language benchmarks, especially with high-resolution images as inputs. The dataset and code are publicly available at https://github.com/baaivision/DenseFusion.",
    "pdf_link": "https://arxiv.org/abs/2407.08303",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.08303v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08303/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08303v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08303/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08303v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08303/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08303v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08303/laion_distribution.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.08303v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08303/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08303v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08303/dalle3.png"
      }
    ],
    "abstract_cn": "多模态大型语言模型 (MLLMs) 正日益注重对复杂视觉元素的深入理解，包括多对象、文本信息及空间关系。这些模型的全面视觉感知能力，依赖于提供多样化视觉元素和详尽图像描述的高质量图像-文本数据集。然而，这类超详细数据集的稀缺，成为 MLLM 领域发展的瓶颈。问题在于现有字幕引擎的感知能力不足，无法提供完整准确的注释。为此，我们提出“感知融合”方案，采用低成本高效能的字幕引擎，实现完整准确的图像描述。该方案整合了多元感知专家的图像先验信息，并利用高效 MLLM 核心，模拟高级 MLLMs 的感知能力。我们从 LAION 数据集中精选了 100 万张代表性图像，通过我们的引擎生成密集描述，命名为 DenseFusion-1M。实验证明，我们的引擎性能卓越，生成的数据集大幅提升了 MLLMs 在多样视觉语言任务中的感知与认知能力，尤其在高分辨率图像输入时表现突出。相关数据集与代码已公开，详见 https://github.com/baaivision/DenseFusion。",
    "title_cn": "DenseFusion-1M：汇聚视觉专家之力，打造全面多模态感知新境界",
    "tags": [
      "LLM应用",
      "计算机视觉",
      "人工智能"
    ]
  },
  {
    "title": "GeNet: A Multimodal LLM-Based Co-Pilot for Network Topology and Configuration",
    "submit_datetime": "2024年07月11日",
    "abstract": "Communication network engineering in enterprise environments is traditionally a complex, time-consuming, and error-prone manual process. Most research on network engineering automation has concentrated on configuration synthesis, often overlooking changes in the physical network topology. This paper introduces GeNet, a multimodal co-pilot for enterprise network engineers. GeNet is a novel framework that leverages a large language model (LLM) to streamline network design workflows. It uses visual and textual modalities to interpret and update network topologies and device configurations based on user intents. GeNet was evaluated on enterprise network scenarios adapted from Cisco certification exercises. Our results demonstrate GeNet's ability to interpret network topology images accurately, potentially reducing network engineers' efforts and accelerating network design processes in enterprise environments. Furthermore, we show the importance of precise topology understanding when handling intents that require modifications to the network's topology.",
    "pdf_link": "https://arxiv.org/abs/2407.08249",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.08249v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08249/genet_architechture.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.08249v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08249/topology_Understanding_vs_type.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.08249v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08249/topology_understanding_vs_temp_2.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.08249v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08249/score_vs_type.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.08249v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08249/score_vs_temp_2.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.08249v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08249/scenarios_vs_scores.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.08249v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08249/tius_vs_s3-z_split_by_scenario_type.png"
      }
    ],
    "abstract_cn": "传统的企业通信网络工程既复杂又耗时，且易出错。尽管网络工程自动化研究多聚焦于配置合成，却常忽略物理拓扑的变动。本文推出的GeNet，作为企业网络工程师的得力助手，采用多模态技术，借助大型语言模型精简网络设计流程。它通过视觉与文本双模态，根据用户意图智能解读并调整网络拓扑与设备配置。在思科认证练习改编的场景测试中，GeNet展现了其精准解析网络拓扑图的能力，有望大幅减轻工程师负担，提速网络设计。同时，我们也强调了在处理拓扑变更需求时，精准拓扑理解的关键性。",
    "title_cn": "GeNet：一款基于多模态大型语言模型的网络拓扑与配置辅助工具",
    "tags": [
      "Agent",
      "企业通信",
      "网络工程"
    ]
  },
  {
    "title": "Multimodal contrastive learning for spatial gene expression prediction using histology images",
    "submit_datetime": "2024年07月11日",
    "abstract": "In recent years, the advent of spatial transcriptomics (ST) technology has unlocked unprecedented opportunities for delving into the complexities of gene expression patterns within intricate biological systems. Despite its transformative potential, the prohibitive cost of ST technology remains a significant barrier to its widespread adoption in large-scale studies. An alternative, more cost-effective strategy involves employing artificial intelligence to predict gene expression levels using readily accessible whole-slide images (WSIs) stained with Hematoxylin and Eosin (H\\&E). However, existing methods have yet to fully capitalize on multimodal information provided by H&E images and ST data with spatial location. In this paper, we propose \\textbf{mclSTExp}, a multimodal contrastive learning with Transformer and Densenet-121 encoder for Spatial Transcriptomics Expression prediction. We conceptualize each spot as a \"word\", integrating its intrinsic features with spatial context through the self-attention mechanism of a Transformer encoder. This integration is further enriched by incorporating image features via contrastive learning, thereby enhancing the predictive capability of our model. Our extensive evaluation of \\textbf{mclSTExp} on two breast cancer datasets and a skin squamous cell carcinoma dataset demonstrates its superior performance in predicting spatial gene expression. Moreover, mclSTExp has shown promise in interpreting cancer-specific overexpressed genes, elucidating immune-related genes, and identifying specialized spatial domains annotated by pathologists. Our source code is available at https://github.com/shizhiceng/mclSTExp.",
    "pdf_link": "https://arxiv.org/abs/2407.08216",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.08216v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08216/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08216v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08216/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08216v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08216/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08216v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08216/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08216v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08216/x5.png"
      }
    ],
    "abstract_cn": "近年来，空间转录组学技术为探索复杂生物系统中的基因表达模式开辟了新天地。然而，高昂的成本限制了其在大型研究中的应用。为此，我们提出了一种经济高效的方案：利用人工智能，通过H&E染色的全切片图像预测基因表达。本文中，我们引入了**mclSTExp**，一种结合Transformer和Densenet-121编码器的多模态对比学习方法，用于精准预测空间转录组表达。我们将每个点比作“单词”，通过Transformer的自注意力机制，巧妙融合其内在特征与空间环境。通过对比学习，进一步强化了图像特征的整合，大幅提升了预测准确性。在乳腺癌和皮肤鳞状细胞癌数据集上的测试表明，mclSTExp不仅在基因表达预测上表现卓越，还能深入解析癌症特异性基因、免疫相关基因，并精准识别由专家注释的特定空间区域。源代码已公开，供研究者参考使用。",
    "title_cn": "通过组织学图像预测空间基因表达，我们采用了多模态对比学习方法。",
    "tags": [
      "LLM应用",
      "生物技术",
      ""
    ]
  },
  {
    "title": "SoupLM: Model Integration in Large Language and Multi-Modal Models",
    "submit_datetime": "2024年07月11日",
    "abstract": "Training large language models (LLMs) and multimodal LLMs necessitates significant computing resources, and existing publicly available LLMs are typically pre-trained on diverse, privately curated datasets spanning various tasks. For instance, LLaMA, Vicuna, and LLaVA are three LLM variants trained with LLaMA base models using very different training recipes, tasks, and data modalities. The training cost and complexity for such LLM variants grow rapidly. In this study, we propose to use a soup strategy to assemble these LLM variants into a single well-generalized multimodal LLM (SoupLM) in a cost-efficient manner. Assembling these LLM variants efficiently brings knowledge and specialities trained from different domains and data modalities into an integrated one (e.g., chatbot speciality from user-shared conversations for Vicuna, and visual capacity from vision-language data for LLaVA), therefore, to avoid computing costs of repetitive training on several different domains. We propose series of soup strategies to systematically benchmark performance gains across various configurations, and probe the soup behavior across base models in the interpolation space.",
    "pdf_link": "https://arxiv.org/abs/2407.08196",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/self_attn.k_proj_0.0001L1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x20.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x21.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x22.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x23.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x24.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x25.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x26.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x27.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x28.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x29.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x30.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x31.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x32.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x33.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x34.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x35.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x36.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x37.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x38.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x39.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x40.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x41.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x42.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x43.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x44.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x45.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x46.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x47.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x48.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x49.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x50.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x51.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x52.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x53.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x54.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x55.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x56.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x57.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x58.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x59.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x60.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x61.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x62.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x63.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x64.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x65.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x66.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x67.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x68.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x69.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x70.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x71.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x72.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x73.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x74.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/x75.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/self_attn.q_proj_0.0001L1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/self_attn.k_proj_0.0001L1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/self_attn.v_proj_0.0001L1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/self_attn.o_proj_0.0001L1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/mlp.gate_proj_0.0001L1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/mlp.up_proj_0.0001L1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/mlp.down_proj_0.0001L1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/self_attn.q_proj_0.001L1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/self_attn.k_proj_0.001L1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/self_attn.v_proj_0.001L1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/self_attn.o_proj_0.001L1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/mlp.gate_proj_0.001L1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/mlp.up_proj_0.001L1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08196/mlp.down_proj_0.001L1.png"
      }
    ],
    "abstract_cn": "训练大型语言模型和多模态模型需要庞大的计算资源，而现有的公开模型通常在多样化的私人精选数据集上进行预训练。例如，LLaMA、Vicuna 和 LLaVA 这三种模型，虽然都基于 LLaMA 基础模型，但采用了截然不同的训练方法、任务和数据模态。随着这些变体的训练成本和复杂性迅速增加，我们提出了一种经济高效的“汤策略”，将这些变体融合成一个泛化能力强的多模态模型 SoupLM。通过这种策略，我们可以将不同领域和数据模态的知识和专长整合起来，避免重复训练的计算成本。此外，我们还提出了一系列策略，系统地评估不同配置下的性能提升，并探索在插值空间中基础模型间的汤行为。",
    "title_cn": "SoupLM：融合大型语言与多模态模型中的模型集成技术",
    "tags": [
      "LLM理论",
      "人工智能",
      "多模态学习"
    ]
  },
  {
    "title": "MAVIS: Mathematical Visual Instruction Tuning",
    "submit_datetime": "2024年07月11日",
    "abstract": "Multi-modal Large Language Models (MLLMs) have recently emerged as a significant focus in academia and industry. Despite their proficiency in general multi-modal scenarios, the mathematical problem-solving capabilities in visual contexts remain insufficiently explored. We identify three key areas within MLLMs that need to be improved: visual encoding of math diagrams, diagram-language alignment, and mathematical reasoning skills. This draws forth an urgent demand for large-scale, high-quality data and training pipelines in visual mathematics. In this paper, we propose MAVIS, the first MAthematical VISual instruction tuning paradigm for MLLMs, involving a series of mathematical visual datasets and specialized MLLMs. Targeting the three issues, MAVIS contains three progressive training stages from scratch. First, we curate MAVIS-Caption, consisting of 558K diagram-caption pairs, to fine-tune a math-specific vision encoder (CLIP-Math) through contrastive learning, tailored for improved diagram visual encoding. Second, we utilize MAVIS-Caption to align the CLIP-Math with a large language model (LLM) by a projection layer, enhancing vision-language alignment in mathematical domains. Third, we introduce MAVIS-Instruct, including 900K meticulously collected and annotated visual math problems, which is adopted to finally instruct-tune the MLLM for robust mathematical reasoning skills. In MAVIS-Instruct, we incorporate complete chain-of-thought (CoT) rationales for each problem, and minimize textual redundancy, thereby concentrating the model towards the visual elements. Data and Models are released at https://github.com/ZrrSkywalker/MAVIS",
    "pdf_link": "https://arxiv.org/abs/2407.08739",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.08739v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08739/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08739v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08739/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08739v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08739/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08739v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08739/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08739v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08739/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08739v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08739/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08739v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08739/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08739v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08739/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08739v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08739/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08739v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08739/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08739v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08739/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08739v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08739/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08739v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08739/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08739v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08739/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08739v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08739/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08739v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08739/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08739v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08739/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08739v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08739/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08739v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08739/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08739v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08739/x20.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08739v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08739/x21.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08739v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08739/x22.png"
      }
    ],
    "abstract_cn": "多模态大型语言模型 (MLLMs) 近期备受学术界与工业界瞩目。虽然它们在多模态场景中表现卓越，但在视觉环境下的数学解题能力仍有待深入探索。我们指出了 MLLMs 需改进的三大关键领域：数学图表的视觉编码、图表与语言的精准对齐以及数学推理技能的提升。这促使我们迫切需要大规模、高质量的视觉数学数据集及训练流程。本文中，我们首创了 MAVIS，首个针对 MLLMs 的数学视觉指令调优框架，涵盖一系列数学视觉数据集与定制 MLLMs。MAVIS 针对上述三大问题，设计了三个递进的训练阶段。首先，通过 558K 图表-标题对组成的 MAVIS-Caption，利用对比学习微调专为数学设计的视觉编码器 CLIP-Math，优化图表视觉编码。其次，借助 MAVIS-Caption，通过投影层实现 CLIP-Math 与大型语言模型的对齐，强化数学领域的视觉-语言融合。最后，引入包含 900K 精心收集与标注的视觉数学问题的 MAVIS-Instruct，通过此数据集最终调优 MLLM，以培养其强大的数学推理能力。在 MAVIS-Instruct 中，我们为每个问题嵌入了完整的思维链推理，并精简文本冗余，使模型更专注于视觉信息。相关数据与模型已公开于 https://github.com/ZrrSkywalker/MAVIS。",
    "title_cn": "MAVIS：数学视觉指令的微调",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Real-Time Anomaly Detection and Reactive Planning with Large Language Models",
    "submit_datetime": "2024年07月11日",
    "abstract": "Foundation models, e.g., large language models (LLMs), trained on internet-scale data possess zero-shot generalization capabilities that make them a promising technology towards detecting and mitigating out-of-distribution failure modes of robotic systems. Fully realizing this promise, however, poses two challenges: (i) mitigating the considerable computational expense of these models such that they may be applied online, and (ii) incorporating their judgement regarding potential anomalies into a safe control framework. In this work, we present a two-stage reasoning framework: First is a fast binary anomaly classifier that analyzes observations in an LLM embedding space, which may then trigger a slower fallback selection stage that utilizes the reasoning capabilities of generative LLMs. These stages correspond to branch points in a model predictive control strategy that maintains the joint feasibility of continuing along various fallback plans to account for the slow reasoner's latency as soon as an anomaly is detected, thus ensuring safety. We show that our fast anomaly classifier outperforms autoregressive reasoning with state-of-the-art GPT models, even when instantiated with relatively small language models. This enables our runtime monitor to improve the trustworthiness of dynamic robotic systems, such as quadrotors or autonomous vehicles, under resource and time constraints. Videos illustrating our approach in both simulation and real-world experiments are available on this project page: https://sites.google.com/view/aesop-llm.",
    "pdf_link": "https://arxiv.org/abs/2407.08735",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.08735v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08735/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08735v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08735/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08735v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08735/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08735v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08735/rebuttal_figure_1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08735v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08735/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08735v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08735/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08735v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08735/naive.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08735v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08735/fsmpc.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08735v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08735/aesop_nominal.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08735v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08735/aesop_abort.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08735v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08735/aesop_early.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08735v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08735/aesop_late.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08735v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08735/nominal-stop-sign.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.08735v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08735/nominal-traffic-light.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.08735v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08735/anomaly-stop-sign.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.08735v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08735/anomaly-traffic-light.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.08735v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08735/language-embeddings.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08735v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08735/acc_with_detections.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08735v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08735/obs_representation.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08735v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08735/hardware_nominal_example.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08735v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08735/hardware_anomaly_example.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08735v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08735/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08735v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08735/gpt-3-latency.png"
      }
    ],
    "abstract_cn": "基础模型，如大型语言模型 (LLM)，在海量互联网数据上训练，具备零-shot 泛化能力，有望检测并缓解机器人系统的异常行为。但要充分发挥其潜力，需克服两大难题：一是降低其高昂的计算成本，以便实时应用；二是将其对异常的判断融入安全控制框架。为此，我们设计了一个两阶段推理框架：首阶段是快速异常检测器，在 LLM 嵌入空间中分析数据，一旦发现异常，即启动次阶段的慢速回退机制，利用生成 LLM 的深度推理能力。这一设计确保了模型预测控制策略的灵活性与安全性，即便在异常检测后也能维持多重回退方案的可行性。实验表明，我们的快速异常检测器性能超越了顶尖 GPT 模型的自回归推理，即使在小型语言模型上也能实现。这使得我们的实时监控系统在资源与时间受限的情况下，仍能提升如四旋翼无人机或自动驾驶汽车等动态机器人系统的可靠性。相关模拟与实测视频已发布于项目页面：https://sites.google.com/view/aesop-llm。",
    "title_cn": "大型语言模型在实时异常检测与反应性规划中的应用",
    "tags": [
      "LLM应用",
      "机器人",
      "自动驾驶"
    ]
  },
  {
    "title": "Is Your Model Really A Good Math Reasoner? Evaluating Mathematical Reasoning with Checklist",
    "submit_datetime": "2024年07月11日",
    "abstract": "Exceptional mathematical reasoning ability is one of the key features that demonstrate the power of large language models (LLMs). How to comprehensively define and evaluate the mathematical abilities of LLMs, and even reflect the user experience in real-world scenarios, has emerged as a critical issue. Current benchmarks predominantly concentrate on problem-solving capabilities, which presents a substantial risk of model overfitting and fails to accurately represent genuine mathematical reasoning abilities. In this paper, we argue that if a model really understands a problem, it should be robustly and readily applied across a diverse array of tasks. Motivated by this, we introduce MATHCHECK, a well-designed checklist for testing task generalization and reasoning robustness, as well as an automatic tool to generate checklists efficiently. MATHCHECK includes multiple mathematical reasoning tasks and robustness test types to facilitate a comprehensive evaluation of both mathematical reasoning ability and behavior testing. Utilizing MATHCHECK, we develop MATHCHECK-GSM and MATHCHECK-GEO to assess mathematical textual reasoning and multi-modal reasoning capabilities, respectively, serving as upgraded versions of benchmarks including GSM8k, GeoQA, UniGeo, and Geometry3K. We adopt MATHCHECK-GSM and MATHCHECK-GEO to evaluate over 20 LLMs and 11 MLLMs, assessing their comprehensive mathematical reasoning abilities. Our results demonstrate that while frontier LLMs like GPT-4o continue to excel in various abilities on the checklist, many other model families exhibit a significant decline. Further experiments indicate that, compared to traditional math benchmarks, MATHCHECK better reflects true mathematical abilities and represents mathematical intelligence more linearly, thereby supporting our design. On our MATHCHECK, we can easily conduct detailed behavior analysis to deeply investigate models.",
    "pdf_link": "https://arxiv.org/abs/2407.08733",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.08733v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08733/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08733v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08733/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08733v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08733/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08733v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08733/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08733v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08733/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08733v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08733/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08733v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08733/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08733v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08733/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08733v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08733/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08733v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08733/case_geo_diagram.jpg"
      }
    ],
    "abstract_cn": "大型语言模型（LLM）的卓越数学推理能力是其核心优势之一。然而，如何全面评估这些能力，并在实际应用中体现用户体验，成为了一个亟待解决的问题。当前的评估标准过于侧重问题解决，可能导致模型过拟合，无法真实反映其数学推理水平。为此，我们提出了MATHCHECK，一个专为测试任务泛化和推理鲁棒性设计的检查清单，以及一个高效的自动生成工具。MATHCHECK涵盖多种数学推理任务和鲁棒性测试，旨在全面评估模型的数学推理能力和行为表现。我们基于MATHCHECK开发了MATHCHECK-GSM和MATHCHECK-GEO，分别针对数学文本和多模态推理进行评估，是对现有基准如GSM8k、GeoQA等的升级。通过这些工具，我们评估了超过20个LLM和11个MLLM的综合数学推理能力。结果显示，尽管如GPT-4o等前沿模型在多项测试中表现出色，但其他模型家族的表现则显著下滑。进一步实验证明，MATHCHECK相比传统基准更能准确反映模型的真实数学能力，并更线性地展现数学智能，验证了我们的设计理念。借助MATHCHECK，我们能够深入进行模型行为分析，全面探究其数学推理能力。",
    "title_cn": "你的模型是否真的擅长数学推理？通过检查清单来评估其数学推理能力。",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "A Taxonomy for Data Contamination in Large Language Models",
    "submit_datetime": "2024年07月11日",
    "abstract": "Large language models pretrained on extensive web corpora demonstrate remarkable performance across a wide range of downstream tasks. However, a growing concern is data contamination, where evaluation datasets may be contained in the pretraining corpus, inflating model performance. Decontamination, the process of detecting and removing such data, is a potential solution; yet these contaminants may originate from altered versions of the test set, evading detection during decontamination. How different types of contamination impact the performance of language models on downstream tasks is not fully understood. We present a taxonomy that categorizes the various types of contamination encountered by LLMs during the pretraining phase and identify which types pose the highest risk. We analyze the impact of contamination on two key NLP tasks -- summarization and question answering -- revealing how different types of contamination influence task performance during evaluation.",
    "pdf_link": "https://arxiv.org/abs/2407.08716",
    "graphs": [],
    "abstract_cn": "大型语言模型在广泛网络语料库上的预训练表现出色，但数据污染问题日益凸显。评估数据集可能被预训练语料库包含，导致性能虚高。去污染虽是解决方案，但污染物可能变形逃逸检测。我们分类了预训练中的污染类型，并评估其风险。此外，我们深入分析了污染对摘要和问答任务的影响，揭示了污染如何左右评估结果。",
    "title_cn": "大型语言模型数据污染的分类体系",
    "tags": [
      "LLM理论",
      "人工智能",
      "数据安全"
    ]
  },
  {
    "title": "HiRes-LLaVA: Restoring Fragmentation Input in High-Resolution Large Vision-Language Models",
    "submit_datetime": "2024年07月11日",
    "abstract": "High-resolution inputs enable Large Vision-Language Models (LVLMs) to discern finer visual details, enhancing their comprehension capabilities. To reduce the training and computation costs caused by high-resolution input, one promising direction is to use sliding windows to slice the input into uniform patches, each matching the input size of the well-trained vision encoder. Although efficient, this slicing strategy leads to the fragmentation of original input, i.e., the continuity of contextual information and spatial geometry is lost across patches, adversely affecting performance in cross-patch context perception and position-specific tasks. To overcome these shortcomings, we introduce HiRes-LLaVA, a novel framework designed to efficiently process any size of high-resolution input without altering the original contextual and geometric information. HiRes-LLaVA comprises two innovative components: (i) a SliceRestore adapter that reconstructs sliced patches into their original form, efficiently extracting both global and local features via down-up-sampling and convolution layers, and (ii) a Self-Mining Sampler to compresses the vision tokens based on themselves, preserving the original context and positional information while reducing training overhead. To assess the ability of handling context fragmentation, we construct a new benchmark, EntityGrid-QA, consisting of edge-related and position-related tasks. Our comprehensive experiments demonstrate the superiority of HiRes-LLaVA on both existing public benchmarks and on EntityGrid-QA, particularly on document-oriented tasks, establishing new standards for handling high-resolution inputs.",
    "pdf_link": "https://arxiv.org/abs/2407.08706",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.08706v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08706/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08706v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08706/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08706v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08706/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08706v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08706/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08706v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08706/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08706v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08706/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08706v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08706/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08706v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08706/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08706v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08706/x9.png"
      }
    ],
    "abstract_cn": "高分辨率输入让大型视觉-语言模型（LVLMs）能捕捉更细腻的视觉细节，提升理解力。为减少高分辨率输入带来的高昂训练和计算成本，我们采用滑动窗口将输入分割成统一块，每个块匹配已训练视觉编码器的输入尺寸。然而，这种分割方法导致原始输入的碎片化，即上下文连续性和空间几何在块间断裂，影响跨块上下文感知和定位任务。为此，我们设计了HiRes-LLaVA框架，它能高效处理任意大小的高分辨率输入，同时保持原始上下文和几何信息不变。HiRes-LLaVA包含两大创新组件：SliceRestore适配器将分割块还原为原始形态，通过下-上采样和卷积层高效提取全局与局部特征；Self-Mining采样器则基于自身压缩视觉令牌，保留原始上下文和位置信息，降低训练负担。我们构建了EntityGrid-QA基准，涵盖边缘和位置相关任务，以评估上下文碎片化处理能力。实验显示，HiRes-LLaVA在现有基准和EntityGrid-QA上均表现卓越，尤其在文档处理任务上，为高分辨率输入处理设定了新标杆。",
    "title_cn": "HiRes-LLaVA：修复高分辨率视觉-语言模型中的碎片输入",
    "tags": [
      "LLM应用",
      "计算机视觉",
      "文档处理"
    ]
  },
  {
    "title": "Live2Diff: Live Stream Translation via Uni-directional Attention in Video Diffusion Models",
    "submit_datetime": "2024年07月11日",
    "abstract": "Large Language Models have shown remarkable efficacy in generating streaming data such as text and audio, thanks to their temporally uni-directional attention mechanism, which models correlations between the current token and previous tokens. However, video streaming remains much less explored, despite a growing need for live video processing. State-of-the-art video diffusion models leverage bi-directional temporal attention to model the correlations between the current frame and all the surrounding (i.e. including future) frames, which hinders them from processing streaming videos. To address this problem, we present Live2Diff, the first attempt at designing a video diffusion model with uni-directional temporal attention, specifically targeting live streaming video translation. Compared to previous works, our approach ensures temporal consistency and smoothness by correlating the current frame with its predecessors and a few initial warmup frames, without any future frames. Additionally, we use a highly efficient denoising scheme featuring a KV-cache mechanism and pipelining, to facilitate streaming video translation at interactive framerates. Extensive experiments demonstrate the effectiveness of the proposed attention mechanism and pipeline, outperforming previous methods in terms of temporal smoothness and/or efficiency.",
    "pdf_link": "https://arxiv.org/abs/2407.08701",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.08701v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08701/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08701v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08701/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08701v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08701/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08701v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08701/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08701v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08701/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08701v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08701/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08701v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08701/ui_only.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08701v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08701/appl-blur.jpg"
      }
    ],
    "abstract_cn": "大型语言模型凭借其单向时间注意力机制，在生成文本和音频等流数据方面表现出色。然而，视频流处理领域仍有待深入探索，尤其是在实时视频处理需求日益增长的背景下。现有的视频扩散模型采用双向时间注意力，这限制了它们处理流视频的能力。为此，我们创新性地提出了Live2Diff模型，该模型采用单向时间注意力，专门针对实时视频翻译设计。我们的方法通过关联当前帧与历史帧及初始帧，确保了视频翻译的时间一致性和平滑性，无需依赖未来帧。同时，我们引入了高效的降噪技术，结合KV-缓存和流水线处理，实现了高帧率下的实时视频翻译。实验结果显示，我们的方法在时间平滑性和效率方面均优于现有技术。",
    "title_cn": "Live2Diff：利用视频扩散模型中的单向注意力技术，实现直播流的实时翻译。",
    "tags": [
      "LLM应用",
      "视频处理",
      "实时翻译"
    ]
  },
  {
    "title": "Mitigating Catastrophic Forgetting in Language Transfer via Model Merging",
    "submit_datetime": "2024年07月11日",
    "abstract": "As open-weight large language models (LLMs) achieve ever more impressive performances across a wide range of tasks in English, practitioners aim to adapt these models to different languages. However, such language adaptation is often accompanied by catastrophic forgetting of the base model's capabilities, severely limiting the usefulness of the resulting model. We address this issue by proposing Branch-and-Merge (BaM), a new adaptation method based on iteratively merging multiple models, fine-tuned on a subset of the available training data. BaM is based on the insight that this yields lower magnitude but higher quality weight changes, reducing forgetting of the source domain while maintaining learning on the target domain. We demonstrate in an extensive empirical study on Bulgarian and German that BaM can significantly reduce forgetting while matching or even improving target domain performance compared to both standard continued pretraining and instruction finetuning across different model architectures.",
    "pdf_link": "https://arxiv.org/abs/2407.08699",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.08699v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08699/intuition_loss.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08699v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08699/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08699v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08699/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08699v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08699/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08699v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08699/x4.png"
      }
    ],
    "abstract_cn": "随着LLM在英语任务中的表现日益卓越，业界希望将这些模型应用于其他语言。然而，语言适应过程中常伴随着对原模型能力的严重遗忘，降低了新模型的实用性。为此，我们提出了Branch-and-Merge（BaM）方法，通过迭代合并多个微调模型来优化适应过程，确保权重变化虽小但质量更高，从而减少对源领域的遗忘并维持对目标领域的学习效果。实证研究表明，BaM不仅有效减少了遗忘现象，还在保加利亚语和德语等语言中，与传统预训练和微调方法相比，实现了目标领域性能的匹配甚至提升。",
    "title_cn": "利用模型合并策略，有效缓解语言迁移过程中的灾难性遗忘问题。",
    "tags": [
      "LLM应用",
      "语言处理",
      "机器学习"
    ]
  },
  {
    "title": "Cloud Atlas: Efficient Fault Localization for Cloud Systems using Language Models and Causal Insight",
    "submit_datetime": "2024年07月11日",
    "abstract": "Runtime failure and performance degradation is commonplace in modern cloud systems. For cloud providers, automatically determining the root cause of incidents is paramount to ensuring high reliability and availability as prompt fault localization can enable faster diagnosis and triage for timely resolution. A compelling solution explored in recent work is causal reasoning using causal graphs to capture relationships between varied cloud system performance metrics. To be effective, however, systems developers must correctly define the causal graph of their system, which is a time-consuming, brittle, and challenging task that increases in difficulty for large and dynamic systems and requires domain expertise. Alternatively, automated data-driven approaches have limited efficacy for cloud systems due to the inherent rarity of incidents. In this work, we present Atlas, a novel approach to automatically synthesizing causal graphs for cloud systems. Atlas leverages large language models (LLMs) to generate causal graphs using system documentation, telemetry, and deployment feedback. Atlas is complementary to data-driven causal discovery techniques, and we further enhance Atlas with a data-driven validation step. We evaluate Atlas across a range of fault localization scenarios and demonstrate that Atlas is capable of generating causal graphs in a scalable and generalizable manner, with performance that far surpasses that of data-driven algorithms and is commensurate to the ground-truth baseline.",
    "pdf_link": "https://arxiv.org/abs/2407.08694",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.08694v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08694/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08694v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08694/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08694v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08694/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08694v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08694/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08694v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08694/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08694v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08694/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08694v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08694/x7.png"
      }
    ],
    "abstract_cn": "在现代云系统中，运行时故障和性能下降屡见不鲜。云服务提供商急需自动定位故障根源，以确保系统的高可靠性和可用性。近期研究提出使用因果图进行因果推理，以揭示性能指标间的关联。然而，构建准确的因果图既耗时又具挑战性，尤其在大规模动态系统中，且需专业知识。同时，数据驱动方法因事件罕见而效果有限。为此，我们推出Atlas，一种自动合成因果图的新方法。Atlas借助大型语言模型，整合系统文档、遥测及部署反馈，生成因果图。它与数据驱动技术相辅相成，并通过数据验证进一步强化。实证表明，Atlas在多种故障定位场景中表现卓越，生成的因果图不仅可扩展且泛化性强，性能远超传统算法，与真实基准相媲美。",
    "title_cn": "云图：结合语言模型与因果洞察，实现云系统故障的精准定位。",
    "tags": [
      "LLM应用",
      "云计算",
      "故障诊断"
    ]
  },
  {
    "title": "Robotic Control via Embodied Chain-of-Thought Reasoning",
    "submit_datetime": "2024年07月11日",
    "abstract": "A key limitation of learned robot control policies is their inability to generalize outside their training data. Recent works on vision-language-action models (VLAs) have shown that the use of large, internet pre-trained vision-language models as the backbone of learned robot policies can substantially improve their robustness and generalization ability. Yet, one of the most exciting capabilities of large vision-language models in other domains is their ability to reason iteratively through complex problems. Can that same capability be brought into robotics to allow policies to improve performance by reasoning about a given task before acting? Naive use of \"chain-of-thought\" (CoT) style prompting is significantly less effective with standard VLAs because of the relatively simple training examples that are available to them. Additionally, purely semantic reasoning about sub-tasks, as is common in regular CoT, is insufficient for robot policies that need to ground their reasoning in sensory observations and the robot state. To this end, we introduce Embodied Chain-of-Thought Reasoning (ECoT) for VLAs, in which we train VLAs to perform multiple steps of reasoning about plans, sub-tasks, motions, and visually grounded features like object bounding boxes and end effector positions, before predicting the robot action. We design a scalable pipeline for generating synthetic training data for ECoT on large robot datasets. We demonstrate, that ECoT increases the absolute success rate of OpenVLA, the current strongest open-source VLA policy, by 28% across challenging generalization tasks, without any additional robot training data. Additionally, ECoT makes it easier for humans to interpret a policy's failures and correct its behavior using natural language.",
    "pdf_link": "https://arxiv.org/abs/2407.08693",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.08693v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08693/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08693v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08693/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08693v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08693/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08693v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08693/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08693v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08693/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08693v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08693/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08693v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08693/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08693v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08693/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08693v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08693/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08693v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08693/x10.png"
      }
    ],
    "abstract_cn": "学习型机器人控制策略面临的一大挑战是难以泛化至训练数据之外。近期，视觉-语言-动作模型（VLAs）的研究显示，采用互联网预训练的大型视觉-语言模型作为核心，能大幅提升策略的鲁棒性与泛化力。然而，大型视觉-语言模型在其他领域的一大亮点——迭代解决复杂问题的能力，能否应用于机器人学，让策略在执行前通过任务推理提升性能？由于标准VLAs训练示例相对简单，直接采用“思维链”（CoT）式提示效果不佳。此外，常规CoT中对子任务的纯语义推理，对于需基于感官与状态进行推理的机器人策略而言，并不充分。为此，我们提出了具身思维链推理（ECoT），训练VLAs在行动前对计划、子任务、运动及视觉基础特征（如物体边界框与末端执行器位置）进行多步推理。我们设计了可扩展的流水线，为ECoT在大规模机器人数据集上生成合成训练数据。实验表明，ECoT在不增加额外训练数据的情况下，将最强开源VLA策略OpenVLA在泛化任务中的成功率提升了28%。同时，ECoT也便于人类理解策略失败原因，并使用自然语言进行行为修正。",
    "title_cn": "机器人控制：基于具身思维链的智能推理",
    "tags": [
      "Agent",
      "机器人学",
      "人工智能"
    ]
  },
  {
    "title": "Uncertainty Estimation of Large Language Models in Medical Question Answering",
    "submit_datetime": "2024年07月11日",
    "abstract": "Large Language Models (LLMs) show promise for natural language generation in healthcare, but risk hallucinating factually incorrect information. Deploying LLMs for medical question answering necessitates reliable uncertainty estimation (UE) methods to detect hallucinations. In this work, we benchmark popular UE methods with different model sizes on medical question-answering datasets. Our results show that current approaches generally perform poorly in this domain, highlighting the challenge of UE for medical applications. We also observe that larger models tend to yield better results, suggesting a correlation between model size and the reliability of UE. To address these challenges, we propose Two-phase Verification, a probability-free Uncertainty Estimation approach. First, an LLM generates a step-by-step explanation alongside its initial answer, followed by formulating verification questions to check the factual claims in the explanation. The model then answers these questions twice: first independently, and then referencing the explanation. Inconsistencies between the two sets of answers measure the uncertainty in the original response. We evaluate our approach on three biomedical question-answering datasets using Llama 2 Chat models and compare it against the benchmarked baseline methods. The results show that our Two-phase Verification method achieves the best overall accuracy and stability across various datasets and model sizes, and its performance scales as the model size increases.",
    "pdf_link": "https://arxiv.org/abs/2407.08662",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.08662v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08662/cove.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08662v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08662/two.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08662v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08662/eg.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08662v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08662/chart.png"
      }
    ],
    "abstract_cn": "在医疗领域，大型语言模型（LLM）虽在自然语言生成方面潜力巨大，但亦有生成事实错误之风险。为此，医疗问答应用中的LLM部署亟需可靠的不确定性估计（UE）方法以识别幻觉现象。本研究针对不同规模的模型，在医疗问答数据集上对主流UE方法进行了基准测试。结果表明，现有方法在此领域表现普遍欠佳，凸显了医疗应用中UE的挑战性。同时，我们发现模型规模与UE可靠性存在正相关。为应对这些挑战，我们创新性地提出了“两阶段验证”这一无概率UE方法。该方法首先要求LLM在给出答案的同时，提供详尽的推理过程，并据此设计验证问题以核实事实准确性。模型需独立及参照推理过程各回答一次，通过对比两次答案的不一致性来评估原始答案的不确定性。在三个生物医学问答数据集上，我们采用Llama 2 Chat模型对本方法进行了评估，并与基准方法进行了对比。结果表明，“两阶段验证”方法在各类数据集及模型规模下均展现出卓越的整体准确性与稳定性，且其性能随模型规模的扩大而增强。",
    "title_cn": "在医学问答领域，大型语言模型的不确定性评估",
    "tags": [
      "LLM应用",
      "",
      "生物医学"
    ]
  },
  {
    "title": "Towards Building Specialized Generalist AI with System 1 and System 2 Fusion",
    "submit_datetime": "2024年07月11日",
    "abstract": "In this perspective paper, we introduce the concept of Specialized Generalist Artificial Intelligence (SGAI or simply SGI) as a crucial milestone toward Artificial General Intelligence (AGI). Compared to directly scaling general abilities, SGI is defined as AI that specializes in at least one task, surpassing human experts, while also retaining general abilities. This fusion path enables SGI to rapidly achieve high-value areas. We categorize SGI into three stages based on the level of mastery over professional skills and generality performance. Additionally, we discuss the necessity of SGI in addressing issues associated with large language models, such as their insufficient generality, specialized capabilities, uncertainty in innovation, and practical applications. Furthermore, we propose a conceptual framework for developing SGI that integrates the strengths of Systems 1 and 2 cognitive processing. This framework comprises three layers and four key components, which focus on enhancing individual abilities and facilitating collaborative evolution. We conclude by summarizing the potential challenges and suggesting future directions. We hope that the proposed SGI will provide insights into further research and applications towards achieving AGI.",
    "pdf_link": "https://arxiv.org/abs/2407.08642",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.08642v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08642/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08642v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08642/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08642v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08642/x3.png"
      }
    ],
    "abstract_cn": "本文引入了专业通才型人工智能（SGAI 或 SGI）的概念，作为迈向通用人工智能（AGI）的重要步骤。SGI 不仅在特定任务上超越人类专家，还保持了通用能力，这种融合路径使其快速进入高价值领域。我们将其发展分为三个阶段，并探讨了 SGI 在解决大型语言模型问题中的必要性。此外，我们提出一个整合系统 1 和系统 2 认知优势的开发框架，包含三个层次和四个关键部分，旨在提升个人能力并促进协同进化。最后，我们概述了潜在挑战并展望未来方向，期待 SGI 为 AGI 的研究和应用提供新视角。",
    "title_cn": "探索通过系统1与系统2的融合，打造专才与通才兼备的AI之路",
    "tags": [
      "LLM理论",
      "人工智能",
      "通用人工智能"
    ]
  },
  {
    "title": "$β$-DPO: Direct Preference Optimization with Dynamic $β$",
    "submit_datetime": "2024年07月11日",
    "abstract": "Direct Preference Optimization (DPO) has emerged as a compelling approach for training Large Language Models (LLMs) to adhere to human preferences. However, the performance of DPO is sensitive to the fine-tuning of its trade-off parameter $β$, as well as to the quality of the preference data. We analyze the impact of $β$ and data quality on DPO, uncovering that optimal $β$ values vary with the informativeness of pairwise data. Addressing the limitations of static $β$ values, we introduce a novel framework that dynamically calibrates $β$ at the batch level, informed by data quality considerations. Additionally, our method incorporates $β$-guided data filtering to safeguard against the influence of outliers. Through empirical evaluation, we demonstrate that our dynamic $β$ adjustment technique significantly improves DPO's performance across a range of models and datasets, offering a more robust and adaptable training paradigm for aligning LLMs with human feedback. The code is available at \\url{https://github.com/junkangwu/beta-DPO}.",
    "pdf_link": "https://arxiv.org/abs/2407.08639",
    "graphs": [],
    "abstract_cn": "Direct Preference Optimization (DPO) 已成为训练大型语言模型 (LLM) 遵循人类偏好的有力方法。但 DPO 性能对 $β$ 参数的微调和数据质量极为敏感。我们研究发现，最佳 $β$ 值因数据信息量而异。为此，我们提出动态调整 $β$ 的新框架，并结合 $β$ 引导的数据过滤，有效提升 DPO 性能，增强模型对人类反馈的适应性。实证显示，该技术在多模型和数据集上表现卓越。代码已公开，详见 \\url{https://github.com/junkangwu/beta-DPO}。",
    "title_cn": "动态 $β$ 直接偏好优化（$β$-DPO）",
    "tags": [
      "LLM理论",
      "人工智能",
      "数据科学"
    ]
  },
  {
    "title": "RoboMorph: Evolving Robot Morphology using Large Language Models",
    "submit_datetime": "2024年07月11日",
    "abstract": "We introduce RoboMorph, an automated approach for generating and optimizing modular robot designs using large language models (LLMs) and evolutionary algorithms. In this framework, we represent each robot design as a grammar and leverage the capabilities of LLMs to navigate the extensive robot design space, which is traditionally time-consuming and computationally demanding. By integrating automatic prompt design and a reinforcement learning based control algorithm, RoboMorph iteratively improves robot designs through feedback loops. Our experimental results demonstrate that RoboMorph can successfully generate nontrivial robots that are optimized for a single terrain while showcasing improvements in morphology over successive evolutions. Our approach demonstrates the potential of using LLMs for data-driven and modular robot design, providing a promising methodology that can be extended to other domains with similar design frameworks.",
    "pdf_link": "https://arxiv.org/abs/2407.08626",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.08626v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08626/overview.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08626v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08626/plot.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08626v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08626/designs.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08626v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08626/promptbreeder_vanilla.png"
      }
    ],
    "abstract_cn": "我们推出了 RoboMorph，一种结合大型语言模型和进化算法，自动生成并优化模块化机器人设计的创新方法。在此框架下，每个机器人设计被视为一种语法，借助 LLM 的力量，我们能够高效探索传统方法难以企及的广阔设计领域。通过融合自动提示设计和强化学习控制算法，RoboMorph 通过迭代反馈不断精进设计。实验证明，RoboMorph 不仅能创造出适应特定地形的复杂机器人，还能在连续进化中优化其形态。这一方法不仅展示了 LLM 在机器人设计领域的应用潜力，也为其他拥有相似设计需求的领域提供了可借鉴的路径。",
    "title_cn": "RoboMorph：借助大型语言模型，探索机器人形态的进化之路",
    "tags": [
      "LLM应用",
      "机器人",
      "自动化设计"
    ]
  },
  {
    "title": "Tamil Language Computing: the Present and the Future",
    "submit_datetime": "2024年07月11日",
    "abstract": "This paper delves into the text processing aspects of Language Computing, which enables computers to understand, interpret, and generate human language. Focusing on tasks such as speech recognition, machine translation, sentiment analysis, text summarization, and language modelling, language computing integrates disciplines including linguistics, computer science, and cognitive psychology to create meaningful human-computer interactions. Recent advancements in deep learning have made computers more accessible and capable of independent learning and adaptation. In examining the landscape of language computing, the paper emphasises foundational work like encoding, where Tamil transitioned from ASCII to Unicode, enhancing digital communication. It discusses the development of computational resources, including raw data, dictionaries, glossaries, annotated data, and computational grammars, necessary for effective language processing. The challenges of linguistic annotation, the creation of treebanks, and the training of large language models are also covered, emphasising the need for high-quality, annotated data and advanced language models. The paper underscores the importance of building practical applications for languages like Tamil to address everyday communication needs, highlighting gaps in current technology. It calls for increased research collaboration, digitization of historical texts, and fostering digital usage to ensure the comprehensive development of Tamil language processing, ultimately enhancing global communication and access to digital services.",
    "pdf_link": "https://arxiv.org/abs/2407.08618",
    "graphs": [],
    "abstract_cn": "本文深入分析了语言计算中的文本处理技术，这些技术使计算机能够理解和生成人类语言。涵盖的任务包括语音识别、机器翻译、情感分析等，语言计算融合了语言学、计算机科学等多个领域，旨在提升人机交互的质量。随着深度学习的发展，计算机在独立学习和适应方面取得了显著进步。本文特别强调了编码技术的进步，例如泰米尔语从ASCII到Unicode的转变，这极大地促进了数字通信。同时，文章讨论了构建有效语言处理所需的计算资源，如数据、词典和语法规则，并指出了语言注释和大型语言模型训练中的挑战。此外，本文强调了开发泰米尔语等语言的实际应用的重要性，以填补现有技术空白，并呼吁加强研究合作和数字化历史文献，以全面推进泰米尔语处理技术的发展，从而增强全球通信和数字服务的普及。",
    "title_cn": "泰米尔语计算：现状展望与未来趋势",
    "tags": [
      "LLM应用",
      "人机交互",
      "语言学"
    ]
  },
  {
    "title": "FlashAttention-3: Fast and Accurate Attention with Asynchrony and Low-precision",
    "submit_datetime": "2024年07月11日",
    "abstract": "Attention, as a core layer of the ubiquitous Transformer architecture, is the bottleneck for large language models and long-context applications. FlashAttention elaborated an approach to speed up attention on GPUs through minimizing memory reads/writes. However, it has yet to take advantage of new capabilities present in recent hardware, with FlashAttention-2 achieving only 35% utilization on the H100 GPU. We develop three main techniques to speed up attention on Hopper GPUs: exploiting asynchrony of the Tensor Cores and TMA to (1) overlap overall computation and data movement via warp-specialization and (2) interleave block-wise matmul and softmax operations, and (3) block quantization and incoherent processing that leverages hardware support for FP8 low-precision. We demonstrate that our method, FlashAttention-3, achieves speedup on H100 GPUs by 1.5-2.0$\\times$ with FP16 reaching up to 740 TFLOPs/s (75% utilization), and with FP8 reaching close to 1.2 PFLOPs/s. We validate that FP8 FlashAttention-3 achieves 2.6$\\times$ lower numerical error than a baseline FP8 attention.",
    "pdf_link": "https://arxiv.org/abs/2407.08608",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.08608v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08608/pingpong_pipelining.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08608v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08608/2_stage_pipelining.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08608v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08608/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08608v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08608/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08608v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08608/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08608v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08608/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08608v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08608/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08608v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08608/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08608v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08608/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08608v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08608/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08608v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08608/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08608v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08608/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08608v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08608/3_stage_pipelining.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08608v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08608/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08608v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08608/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08608v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08608/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08608v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08608/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08608v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08608/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08608v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08608/x16.png"
      }
    ],
    "abstract_cn": "注意力机制，作为Transformer架构的核心，已成为大型语言模型和长上下文应用的瓶颈。FlashAttention通过减少内存读写操作，提升了GPU上的注意力计算速度。然而，FlashAttention-2在最新的H100 GPU上仅达到35%的利用率，未能充分利用新硬件的潜力。为此，我们研发了三项关键技术，以进一步加速Hopper GPU上的注意力计算：首先，通过张量核心和TMA的异步特性，实现计算与数据移动的重叠；其次，交错执行块状矩阵乘法和softmax操作；最后，利用硬件对FP8低精度的支持，进行块量化和不连贯处理。实验表明，我们的FlashAttention-3方法在H100 GPU上实现了1.5至2.0倍的加速，FP16精度下达到740 TFLOPs/s（75%利用率），FP8精度下接近1.2 PFLOPs/s。此外，FP8 FlashAttention-3相比基准FP8注意力，数值误差降低了2.6倍。",
    "title_cn": "FlashAttention-3：借助异步处理与低精度计算，实现高效且精准的注意力机制。",
    "tags": [
      "LLM理论",
      "半导体",
      "高性能计算"
    ]
  },
  {
    "title": "Turn-Level Empathy Prediction Using Psychological Indicators",
    "submit_datetime": "2024年07月11日",
    "abstract": "For the WASSA 2024 Empathy and Personality Prediction Shared Task, we propose a novel turn-level empathy detection method that decomposes empathy into six psychological indicators: Emotional Language, Perspective-Taking, Sympathy and Compassion, Extroversion, Openness, and Agreeableness. A pipeline of text enrichment using a Large Language Model (LLM) followed by DeBERTA fine-tuning demonstrates a significant improvement in the Pearson Correlation Coefficient and F1 scores for empathy detection, highlighting the effectiveness of our approach. Our system officially ranked 7th at the CONV-turn track.",
    "pdf_link": "https://arxiv.org/abs/2407.08607",
    "graphs": [],
    "abstract_cn": "在 WASSA 2024 同理心与人格预测任务中，我们创新性地将同理心细分为六个心理维度：情感表达、换位思考、同情心、外向、开放与和善。借助大型语言模型丰富文本，再通过 DeBERTA 微调，我们的方法在同理心检测上大幅提升了相关性和准确度，成效显著。最终，我们的系统在 CONV-turn 赛道中荣获第 7 名。",
    "title_cn": "基于心理指标的回合级共情预测",
    "tags": [
      "LLM应用",
      "心理健康",
      "人工智能"
    ]
  },
  {
    "title": "The Synergy between Data and Multi-Modal Large Language Models: A Survey from Co-Development Perspective",
    "submit_datetime": "2024年07月11日",
    "abstract": "The rapid development of large language models (LLMs) has been witnessed in recent years. Based on the powerful LLMs, multi-modal LLMs (MLLMs) extend the modality from text to a broader spectrum of domains, attracting widespread attention due to the broader range of application scenarios. As LLMs and MLLMs rely on vast amounts of model parameters and data to achieve emergent capabilities, the importance of data is receiving increasingly widespread attention and recognition. Tracing and analyzing recent data-oriented works for MLLMs, we find that the development of models and data is not two separate paths but rather interconnected. On the one hand, vaster and higher-quality data contribute to better performance of MLLMs, on the other hand, MLLMs can facilitate the development of data. The co-development of multi-modal data and MLLMs requires a clear view of 1) at which development stage of MLLMs can specific data-centric approaches be employed to enhance which capabilities, and 2) by utilizing which capabilities and acting as which roles can models contribute to multi-modal data. To promote the data-model co-development for MLLM community, we systematically review existing works related to MLLMs from the data-model co-development perspective. A regularly maintained project associated with this survey is accessible at https://github.com/modelscope/data-juicer/blob/main/docs/awesome_llm_data.md.",
    "pdf_link": "https://arxiv.org/abs/2407.08583",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.08583v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08583/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08583v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08583/x2.png"
      }
    ],
    "abstract_cn": "近年来，大型语言模型（LLMs）的迅猛发展引人瞩目。多模态LLMs（MLLMs）在此基础上，将应用领域从文本扩展至更广阔的范畴，因其广泛的应用场景而备受关注。LLMs和MLLMs的成功，离不开庞大的模型参数和数据支持，这使得数据的重要性日益凸显。通过追踪近期以数据为核心的MLLMs研究，我们发现模型与数据的发展实则相辅相成。一方面，更丰富、更优质的数据能提升MLLMs的性能；另一方面，MLLMs的发展也能推动数据进步。为了实现多模态数据与MLLMs的协同发展，我们需要明确：在MLLMs的不同发展阶段，如何运用数据中心方法来增强特定能力；以及模型如何通过其能力与角色，为多模态数据的发展贡献力量。为此，我们系统梳理了从数据与模型协同发展视角出发的相关研究，并提供了一个定期更新的项目链接，供MLLM社区参考：https://github.com/modelscope/data-juicer/blob/main/docs/awesome_llm_data.md。",
    "title_cn": "数据与多模态大型语言模型的协同效应：协同开发视角的探索",
    "tags": [
      "LLM应用",
      "人工智能",
      "数据科学"
    ]
  },
  {
    "title": "On the Universal Truthfulness Hyperplane Inside LLMs",
    "submit_datetime": "2024年07月11日",
    "abstract": "While large language models (LLMs) have demonstrated remarkable abilities across various fields, hallucination remains a significant challenge. Recent studies have explored hallucinations through the lens of internal representations, proposing mechanisms to decipher LLMs' adherence to facts. However, these approaches often fail to generalize to out-of-distribution data, leading to concerns about whether internal representation patterns reflect fundamental factual awareness, or only overfit spurious correlations on the specific datasets. In this work, we investigate whether a universal truthfulness hyperplane that distinguishes the model's factually correct and incorrect outputs exists within the model. To this end, we scale up the number of training datasets and conduct an extensive evaluation -- we train the truthfulness hyperplane on a diverse collection of over 40 datasets and examine its cross-task, cross-domain, and in-domain generalization. Our results indicate that increasing the diversity of the training datasets significantly enhances the performance in all scenarios, while the volume of data samples plays a less critical role. This finding supports the optimistic hypothesis that a universal truthfulness hyperplane may indeed exist within the model, offering promising directions for future research.",
    "pdf_link": "https://arxiv.org/abs/2407.08582",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.08582v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08582/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08582v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08582/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08582v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08582/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08582v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08582/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08582v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08582/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08582v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08582/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08582v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08582/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08582v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08582/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08582v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08582/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08582v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08582/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08582v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08582/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08582v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08582/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08582v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08582/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08582v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08582/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08582v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08582/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08582v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08582/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08582v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08582/x17.png"
      }
    ],
    "abstract_cn": "尽管 LLM 在多领域表现出色，幻觉问题仍是一大难题。最新研究通过分析内部表征，尝试解读 LLM 对事实的忠实度。但这些方法常难以适应新数据，引发了对内部表征是否真正反映事实意识，还是仅过度适应特定数据集的疑虑。本研究探索模型中是否存在一个普遍的真理超平面，能区分正确与错误输出。我们扩大训练数据集至40多个，全面评估其泛化能力。结果显示，数据集多样性提升显著增强性能，而数据量影响较小。这支持了模型内可能存在普遍真理超平面的乐观假设，为未来研究指明方向。",
    "title_cn": "探索 LLM 内部的真实性普遍性",
    "tags": [
      "LLM理论",
      "人工智能",
      "数据科学"
    ]
  },
  {
    "title": "The Career Interests of Large Language Models",
    "submit_datetime": "2024年07月11日",
    "abstract": "Recent advancements in Large Language Models (LLMs) have significantly extended their capabilities, evolving from basic text generation to complex, human-like interactions. In light of the possibilities that LLMs could assume significant workplace responsibilities, it becomes imminently necessary to explore LLMs' capacities as professional assistants. This study focuses on the aspect of career interests by applying the Occupation Network's Interest Profiler short form to LLMs as if they were human participants and investigates their hypothetical career interests and competence, examining how these vary with language changes and model advancements. We analyzed the answers using a general linear mixed model approach and found distinct career interest inclinations among LLMs, particularly towards the social and artistic domains. Interestingly, these preferences did not align with the occupations where LLMs exhibited higher competence. This novel approach of using psychometric instruments and sophisticated statistical tools on LLMs unveils fresh perspectives on their integration into professional environments, highlighting human-like tendencies and promoting a reevaluation of LLMs' self-perception and competency alignment in the workforce.",
    "pdf_link": "https://arxiv.org/abs/2407.08564",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.08564v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08564/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08564v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08564/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08564v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08564/2.1_gpt.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08564v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08564/2.1_ernie.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08564v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08564/2.1_gemini.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08564v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08564/2.1_spark.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08564v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08564/lan_bar_gpt-3.5-turbo.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08564v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08564/lan_bar_gemini-pro.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08564v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08564/lan_bar_ERNIE-3.5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08564v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08564/lan_bar_spark-3.5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08564v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08564/lan_heat.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08564v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08564/version_bar_gpt_eng.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08564v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08564/version_bar_baidu_zh.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08564v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08564/com_bar_gpt-3.5-turbo.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08564v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08564/com_bar_gemini-pro.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08564v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08564/com_bar_ERNIE-3.5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08564v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08564/com_bar_spark-3.5.png"
      }
    ],
    "abstract_cn": "随着大型语言模型 (LLMs) 能力的显著提升，从简单文本生成到复杂人机交互，探索其作为专业助理的潜力变得尤为重要。本研究模拟人类参与，运用职业兴趣分析工具，考察 LLMs 的潜在职业兴趣与能力，并分析这些兴趣如何随语言和模型发展而变化。通过高级统计方法，我们发现 LLMs 在社会和艺术领域展现出独特兴趣，但这些兴趣与其高能力职业并不匹配。这一创新方法不仅揭示了 LLMs 融入职场的全新视角，也强调了其类人特质，促使我们重新审视 LLMs 在职场中的自我认知与能力匹配。",
    "title_cn": "探究大型语言模型的职业倾向",
    "tags": [
      "LLM应用",
      "人力资源",
      "职业发展"
    ]
  },
  {
    "title": "Vox Populi, Vox AI? Using Language Models to Estimate German Public Opinion",
    "submit_datetime": "2024年07月11日",
    "abstract": "The recent development of large language models (LLMs) has spurred discussions about whether LLM-generated \"synthetic samples\" could complement or replace traditional surveys, considering their training data potentially reflects attitudes and behaviors prevalent in the population. A number of mostly US-based studies have prompted LLMs to mimic survey respondents, with some of them finding that the responses closely match the survey data. However, several contextual factors related to the relationship between the respective target population and LLM training data might affect the generalizability of such findings. In this study, we investigate the extent to which LLMs can estimate public opinion in Germany, using the example of vote choice. We generate a synthetic sample of personas matching the individual characteristics of the 2017 German Longitudinal Election Study respondents. We ask the LLM GPT-3.5 to predict each respondent's vote choice and compare these predictions to the survey-based estimates on the aggregate and subgroup levels. We find that GPT-3.5 does not predict citizens' vote choice accurately, exhibiting a bias towards the Green and Left parties. While the LLM captures the tendencies of \"typical\" voter subgroups, such as partisans, it misses the multifaceted factors swaying individual voter choices. By examining the LLM-based prediction of voting behavior in a new context, our study contributes to the growing body of research about the conditions under which LLMs can be leveraged for studying public opinion. The findings point to disparities in opinion representation in LLMs and underscore the limitations in applying them for public opinion estimation.",
    "pdf_link": "https://arxiv.org/abs/2407.08563",
    "graphs": [],
    "abstract_cn": "随着大型语言模型 (LLM) 的进步，人们开始探讨 LLM 生成的“合成样本”是否能替代传统调查。一些美国研究显示，LLM 模拟的调查响应与实际数据相符。但这种匹配的可推广性受限于目标人群与 LLM 训练数据的关系。本研究探索 LLM 在德国的公众意见预测能力，特别是投票选择。我们使用 GPT-3.5 生成与德国选举研究受访者特征相符的合成样本，并预测其投票选择，发现 GPT-3.5 对绿党和左派有偏见，虽能捕捉典型选民趋势，但未能全面理解影响个体选择的复杂因素。这项研究揭示了 LLM 在公众意见研究中的局限，强调了其应用的挑战。",
    "title_cn": "民意即AI之声？借助语言模型洞察德国民意",
    "tags": [
      "LLM应用",
      "",
      "市场研究"
    ]
  },
  {
    "title": "Tactics, Techniques, and Procedures (TTPs) in Interpreted Malware: A Zero-Shot Generation with Large Language Models",
    "submit_datetime": "2024年07月11日",
    "abstract": "Nowadays, the open-source software (OSS) ecosystem suffers from security threats of software supply chain (SSC) attacks. Interpreted OSS malware plays a vital role in SSC attacks, as criminals have an arsenal of attack vectors to deceive users into installing malware and executing malicious activities. In this paper, we introduce tactics, techniques, and procedures (TTPs) proposed by MITRE ATT\\&CK into the interpreted malware analysis to characterize different phases of an attack lifecycle. Specifically, we propose GENTTP, a zero-shot approach to extracting a TTP of an interpreted malware package. GENTTP leverages large language models (LLMs) to automatically generate a TTP, where the input is a malicious package, and the output is a deceptive tactic and an execution tactic of attack vectors. To validate the effectiveness of GENTTP, we collect two datasets for evaluation: a dataset with ground truth labels and a large dataset in the wild. Experimental results show that GENTTP can generate TTPs with high accuracy and efficiency. To demonstrate GENTTP's benefits, we build an LLM-based Chatbot from 3,700+ PyPI malware's TTPs. We further conduct a quantitative analysis of malware's TTPs at a large scale. Our main findings include: (1) many OSS malicious packages share a relatively stable TTP, even with the increasing emergence of malware and attack campaigns, (2) a TTP reflects characteristics of a malware-based attack, and (3) an attacker's intent behind the malware is linked to a TTP.",
    "pdf_link": "https://arxiv.org/abs/2407.08532",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.08532v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08532/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08532v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08532/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08532v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08532/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08532v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08532/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08532v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08532/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08532v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08532/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08532v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08532/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08532v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08532/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08532v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08532/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08532v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08532/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08532v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08532/x11.png"
      }
    ],
    "abstract_cn": "当前，开源软件生态正面临软件供应链攻击的安全挑战。解释型开源软件恶意代码在供应链攻击中尤为关键，因其为犯罪分子提供了多种手段诱导用户安装并执行恶意行为。本文中，我们借鉴MITRE ATT&CK框架中的战术、技术和程序（TTPs），将其应用于解释型恶意软件分析，以揭示攻击过程的各个阶段。我们创新性地提出了GENTTP方法，利用大型语言模型（LLMs）实现零-shot学习，自动从恶意软件包中提取TTP。该方法以恶意软件包为输入，输出攻击向量的欺骗与执行战术。为验证GENTTP的性能，我们收集了两个数据集：一个标注真实标签，另一个来自实际环境。实验表明，GENTTP能高效准确地生成TTP。此外，我们基于3700多个PyPI恶意软件的TTP，构建了一个基于LLM的聊天机器人，并进行了大规模的TTP定量分析。研究发现：（1）尽管恶意软件数量激增，许多恶意包的TTP仍保持稳定；（2）TTP揭示了恶意攻击的特性；（3）TTP与攻击者的意图紧密相关。",
    "title_cn": "利用大型语言模型对解释型恶意软件的 TTPs 进行零-shot 生成研究",
    "tags": [
      "LLM应用",
      "软件安全",
      "人工智能"
    ]
  },
  {
    "title": "15M Multimodal Facial Image-Text Dataset",
    "submit_datetime": "2024年07月11日",
    "abstract": "Currently, image-text-driven multi-modal deep learning models have demonstrated their outstanding potential in many fields. In practice, tasks centered around facial images have broad application prospects. This paper presents \\textbf{FaceCaption-15M}, a large-scale, diverse, and high-quality dataset of facial images accompanied by their natural language descriptions (facial image-to-text). This dataset aims to facilitate a study on face-centered tasks. FaceCaption-15M comprises over 15 million pairs of facial images and their corresponding natural language descriptions of facial features, making it the largest facial image-caption dataset to date. We conducted a comprehensive analysis of image quality, text naturalness, text complexity, and text-image relevance to demonstrate the superiority of FaceCaption-15M. To validate the effectiveness of FaceCaption-15M, we first trained a facial language-image pre-training model (FLIP, similar to CLIP) to align facial image with its corresponding captions in feature space. Subsequently, using both image and text encoders and fine-tuning only the linear layer, our FLIP-based models achieved state-of-the-art results on two challenging face-centered tasks. The purpose is to promote research in the field of face-related tasks through the availability of the proposed FaceCaption-15M dataset. All data, codes, and models are publicly available. https://huggingface.co/datasets/OpenFace-CQUPT/FaceCaption-15M",
    "pdf_link": "https://arxiv.org/abs/2407.08515",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.08515v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08515/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08515v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08515/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08515v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08515/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08515v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08515/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08515v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08515/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08515v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08515/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08515v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08515/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08515v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08515/x8.png"
      }
    ],
    "abstract_cn": "当前，图像与文本结合的多模态深度学习模型在多个领域展现出显著潜力，特别是在面部图像相关的任务中，其应用前景广阔。本文推出的 **FaceCaption-15M** 数据集，集大规模、多样性与高质量于一体，为面部图像匹配自然语言描述，旨在推动面部相关任务的研究。该数据集包含超过 1500 万对面部图像与描述，规模空前。通过深入分析图像质量、文本自然度、复杂度及与图像的相关性，FaceCaption-15M 的优越性得以彰显。为验证其效能，我们训练了面部图像与文本对齐的预训练模型 FLIP，并在此基础上，通过图像与文本编码器的协同及线性层的微调，在两项面部任务中刷新了性能纪录。我们公开了所有资源，以期推动面部任务研究的进一步发展。详情请访问：https://huggingface.co/datasets/OpenFace-CQUPT/FaceCaption-15M",
    "title_cn": "1500万面部图像与文本多模态数据集",
    "tags": [
      "LLM应用\n\n解释：这篇论文主要介绍了FaceCaption-15M数据集的开发和应用，这是一个用于面部图像与自然语言描述匹配的大规模数据集。论文中提到的FLIP模型是基于这个数据集训练的预训练模型，用于面部图像与文本的对齐。虽然论文涉及到了多模态深度学习模型，但其核心关注点在于应用层面，即如何利用这些模型和数据集来提升面部相关任务的性能。因此，这篇论文更适合归类于LLM应用，而不是专注于理论探讨或代理技术（Agent）和检索增强生成（RAG）技术。",
      "人工智能",
      "面部识别"
    ]
  },
  {
    "title": "Lynx: An Open Source Hallucination Evaluation Model",
    "submit_datetime": "2024年07月11日",
    "abstract": "Retrieval Augmented Generation (RAG) techniques aim to mitigate hallucinations in Large Language Models (LLMs). However, LLMs can still produce information that is unsupported or contradictory to the retrieved contexts. We introduce LYNX, a SOTA hallucination detection LLM that is capable of advanced reasoning on challenging real-world hallucination scenarios. To evaluate LYNX, we present HaluBench, a comprehensive hallucination evaluation benchmark, consisting of 15k samples sourced from various real-world domains. Our experiment results show that LYNX outperforms GPT-4o, Claude-3-Sonnet, and closed and open-source LLM-as-a-judge models on HaluBench. We release LYNX, HaluBench and our evaluation code for public access.",
    "pdf_link": "https://arxiv.org/abs/2407.08488",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.08488v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08488/halueval_example_lynx.png"
      }
    ],
    "abstract_cn": "RAG 技术旨在减少 LLM 中的幻觉现象，但 LLM 仍可能输出与检索内容不符的信息。为此，我们推出了 LYNX，一款尖端的幻觉检测 LLM，能在复杂的现实幻觉情境中进行深度推理。为验证 LYNX 的性能，我们创建了 HaluBench，一个涵盖多领域约 15,000 样本的全面幻觉评估基准。实验表明，LYNX 在 HaluBench 上的表现超越了 GPT-4o、Claude-3-Sonnet 等模型。我们已将 LYNX、HaluBench 及评估代码公开，供公众使用。",
    "title_cn": "Lynx：一款开源的幻觉评估工具",
    "tags": [
      "LLM应用",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Investigating Public Fine-Tuning Datasets: A Complex Review of Current Practices from a Construction Perspective",
    "submit_datetime": "2024年07月11日",
    "abstract": "With the rapid development of the large model domain, research related to fine-tuning has concurrently seen significant advancement, given that fine-tuning is a constituent part of the training process for large-scale models. Data engineering plays a fundamental role in the training process of models, which includes data infrastructure, data processing, etc. Data during fine-tuning likewise forms the base for large models. In order to embrace the power and explore new possibilities of fine-tuning datasets, this paper reviews current public fine-tuning datasets from the perspective of data construction. An overview of public fine-tuning datasets from two sides: evolution and taxonomy, is provided in this review, aiming to chart the development trajectory. Construction techniques and methods for public fine-tuning datasets of Large Language Models (LLMs), including data generation and data augmentation among others, are detailed. This elaboration follows the aforementioned taxonomy, specifically across demonstration, comparison, and generalist categories. Additionally, a category tree of data generation techniques has been abstracted in our review to assist researchers in gaining a deeper understanding of fine-tuning datasets from the construction dimension. Our review also summarizes the construction features in different data preparation phases of current practices in this field, aiming to provide a comprehensive overview and inform future research. Fine-tuning dataset practices, encompassing various data modalities, are also discussed from a construction perspective in our review. Towards the end of the article, we offer insights and considerations regarding the future construction and developments of fine-tuning datasets.",
    "pdf_link": "https://arxiv.org/abs/2407.08475",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.08475v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08475/6-2-dimension.png"
      }
    ],
    "abstract_cn": "随着大型模型领域的迅猛发展，微调研究也取得了显著进步。本文从数据构建视角，全面回顾了公共微调数据集，探讨了其演变与分类，并详细介绍了构建技术和方法，如数据生成和增强。我们通过抽象出数据生成技术的类别树，助力研究人员深入理解微调数据集的构建维度。此外，本文还总结了当前实践中不同数据准备阶段的构建特征，为未来研究提供全面概览。最后，我们展望了微调数据集的未来构建与发展，提出了深刻见解与思考。",
    "title_cn": "从构建视角深入探讨公共微调数据集的现状与挑战",
    "tags": [
      "LLM理论",
      "人工智能",
      "数据科学"
    ]
  },
  {
    "title": "DIDUP: Dynamic Iterative Development for UI Prototyping",
    "submit_datetime": "2024年07月11日",
    "abstract": "Large language models (LLMs) are remarkably good at writing code. A particularly valuable case of human-LLM collaboration is code-based UI prototyping, a method for creating interactive prototypes that allows users to view and fully engage with a user interface. We conduct a formative study of GPT Pilot, a leading LLM-generated code-prototyping system, and find that its inflexibility towards change once development has started leads to weaknesses in failure prevention and dynamic planning; it closely resembles the linear workflow of the waterfall model. We introduce DIDUP, a system for code-based UI prototyping that follows an iterative spiral model, which takes changes and iterations that come up during the development process into account. We propose three novel mechanisms for LLM-generated code-prototyping systems: (1) adaptive planning, where plans should be dynamic and reflect changes during implementation, (2) code injection, where the system should write a minimal amount of code and inject it instead of rewriting code so users have a better mental model of the code evolution, and (3) lightweight state management, a simplified version of source control so users can quickly revert to different working states. Together, this enables users to rapidly develop and iterate on prototypes.",
    "pdf_link": "https://arxiv.org/abs/2407.08474",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.08474v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08474/teaser.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08474v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08474/system.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08474v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08474/output.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLM）在编码方面表现卓越。其中，基于代码的用户界面原型设计是人类与LLM合作的一个亮点，它让用户能全面参与并体验界面。我们研究了GPT Pilot，发现其一旦启动开发便难以适应变化，这在故障预防和动态规划上显得不足，其工作流程类似传统的瀑布模型。为此，我们推出了DIDUP，一个采用迭代螺旋模型的系统，能灵活应对开发中的变化。我们还提出了三项创新机制：适应性规划，让计划随实施动态调整；代码注入，减少重写，帮助用户理解代码演变；轻量级状态管理，简化版本控制，便于用户快速回溯。这些功能共同助力用户高效迭代原型。",
    "title_cn": "DIDUP：为 UI 原型设计带来动态迭代开发",
    "tags": [
      "LLM应用",
      "软件开发",
      "用户体验"
    ]
  },
  {
    "title": "Natural language is not enough: Benchmarking multi-modal generative AI for Verilog generation",
    "submit_datetime": "2024年07月11日",
    "abstract": "Natural language interfaces have exhibited considerable potential in the automation of Verilog generation derived from high-level specifications through the utilization of large language models, garnering significant attention. Nevertheless, this paper elucidates that visual representations contribute essential contextual information critical to design intent for hardware architectures possessing spatial complexity, potentially surpassing the efficacy of natural-language-only inputs. Expanding upon this premise, our paper introduces an open-source benchmark for multi-modal generative models tailored for Verilog synthesis from visual-linguistic inputs, addressing both singular and complex modules. Additionally, we introduce an open-source visual and natural language Verilog query language framework to facilitate efficient and user-friendly multi-modal queries. To evaluate the performance of the proposed multi-modal hardware generative AI in Verilog generation tasks, we compare it with a popular method that relies solely on natural language. Our results demonstrate a significant accuracy improvement in the multi-modal generated Verilog compared to queries based solely on natural language. We hope to reveal a new approach to hardware design in the large-hardware-design-model era, thereby fostering a more diversified and productive approach to hardware design.",
    "pdf_link": "https://arxiv.org/abs/2407.08473",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.08473v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08473/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08473v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08473/nocpe.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08473v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08473/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08473v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08473/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08473v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08473/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08473v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08473/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08473v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08473/x6.png"
      }
    ],
    "abstract_cn": "自然语言接口在自动生成Verilog方面潜力巨大，但本文指出，视觉表示对于空间复杂的硬件设计至关重要，可能优于纯语言输入。为此，我们推出了一个开源的多模态生成模型基准，专门用于从视觉-语言输入合成Verilog，涵盖简单与复杂模块。同时，我们开发了一个开源的视觉与自然语言Verilog查询框架，以简化多模态查询。通过与仅使用自然语言的方法对比，我们的多模态生成Verilog在准确性上显著提升。我们期待在大规模硬件设计时代，推动硬件设计方法的多样化和高效化。",
    "title_cn": "仅凭自然语言远远不够：我们正在为 Verilog 生成任务，对多模态生成 AI 进行基准测试。",
    "tags": [
      "LLM应用",
      "硬件设计",
      "人工智能"
    ]
  },
  {
    "title": "Model Tells You Where to Merge: Adaptive KV Cache Merging for LLMs on Long-Context Tasks",
    "submit_datetime": "2024年07月11日",
    "abstract": "How to efficiently serve Large Language Models (LLMs) has become a pressing issue because of their huge computational cost in their autoregressive generation process. To mitigate computational costs, LLMs often employ the KV Cache technique to improve the generation speed. While improving the computational efficiency, the storage requirements of the KV cache are substantial, particularly in long-context scenarios, leading to significant memory consumption. Existing KV cache eviction methods often degrade the performance of LLMs in long-context scenarios due to the information loss introduced by eviction. In this paper, we propose a novel KV cache merging approach, called KVMerger, to achieve adaptive KV cache compression for long-context tasks without significant performance degradation under constrained memory budgets. Our approach is inspired by the intriguing observation that key states exhibit high similarity at the token level within a single sequence. To facilitate merging, we develop an effective yet straightforward merging set identification algorithm to identify suitable KV states for merging. Our merging set identification algorithm stimulates the second observation that KV cache sparsity, from similarity perspective, is independent of the dataset and remains persistent at the model level. Subsequently, we propose a Gaussian kernel weighted merging algorithm to selectively merge all states within each merging set. We conduct extensive experiments to demonstrate the effectiveness of KVMerger for long-context tasks under constrained memory budgets, applying it to models including Llama2-7B-chat and Llama2-13B-chat. Using the LongBench and ZeroScroll benchmarks, we compare our method with other KV cache compression techniques, including H2O and CaM, showing that our method achieves superior performance across tasks with both 50% and 35% KV cache budgets.",
    "pdf_link": "https://arxiv.org/abs/2407.08454",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.08454v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08454/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08454v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08454/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08454v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08454/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08454v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08454/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08454v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08454/x5.png"
      }
    ],
    "abstract_cn": "随着大型语言模型（LLMs）在自回归生成中的高计算成本，如何高效服务这些模型变得至关重要。为此，LLMs常采用KV缓存技术提升生成速度，但这也带来了显著的内存需求，尤其是在长上下文场景中。本文提出了一种创新的KV缓存合并方法KVMerger，旨在不牺牲性能的前提下，实现长上下文任务的KV缓存自适应压缩。我们基于观察到单序列内键状态在令牌级别的高度相似性，开发了合并集识别算法，并进一步提出了高斯核加权合并算法。实验证明，KVMerger在受限内存预算下，相比其他技术如H2O和CaM，在Llama2-7B-chat和Llama2-13B-chat等模型上，均实现了更优的性能。",
    "title_cn": "模型指引合并时机：为长上下文任务中的LLMs量身定制的KV缓存智能合并策略",
    "tags": [
      "LLM应用",
      "计算机科学",
      "人工智能"
    ]
  },
  {
    "title": "Are Large Language Models Really Bias-Free? Jailbreak Prompts for Assessing Adversarial Robustness to Bias Elicitation",
    "submit_datetime": "2024年07月11日",
    "abstract": "Large Language Models (LLMs) have revolutionized artificial intelligence, demonstrating remarkable computational power and linguistic capabilities. However, these models are inherently prone to various biases stemming from their training data. These include selection, linguistic, and confirmation biases, along with common stereotypes related to gender, ethnicity, sexual orientation, religion, socioeconomic status, disability, and age. This study explores the presence of these biases within the responses given by the most recent LLMs, analyzing the impact on their fairness and reliability. We also investigate how known prompt engineering techniques can be exploited to effectively reveal hidden biases of LLMs, testing their adversarial robustness against jailbreak prompts specially crafted for bias elicitation. Extensive experiments are conducted using the most widespread LLMs at different scales, confirming that LLMs can still be manipulated to produce biased or inappropriate responses, despite their advanced capabilities and sophisticated alignment processes. Our findings underscore the importance of enhancing mitigation techniques to address these safety issues, toward a more sustainable and inclusive artificial intelligence.",
    "pdf_link": "https://arxiv.org/abs/2407.08441",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.08441v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08441/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08441v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08441/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08441v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08441/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08441v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08441/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08441v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08441/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08441v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08441/x6.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLM）在人工智能领域展现了惊人的计算与语言能力，但它们也易受训练数据中的多种偏见影响，如选择、语言和确认偏见，以及性别、种族、性取向等刻板印象。本研究深入分析了最新LLM在回答中体现的这些偏见，及其对模型公平性与可靠性的影响。同时，我们探索了如何利用提示工程技术揭示LLM的隐性偏见，并测试其对抗越狱提示的鲁棒性。通过广泛实验，我们发现即便LLM具备高级功能与精密对齐流程，仍可能被诱导产生偏颇或不当回应。因此，强化偏见缓解技术，对于构建更可持续、更包容的人工智能至关重要。",
    "title_cn": "大型语言模型真的无偏见吗？通过“越狱”提示评估对抗性鲁健对偏见引发的挑战。",
    "tags": [
      "LLM理论",
      "人工智能",
      "社会科学"
    ]
  },
  {
    "title": "Self-training Language Models for Arithmetic Reasoning",
    "submit_datetime": "2024年07月11日",
    "abstract": "Language models achieve impressive results in tasks involving complex multistep reasoning, but scaling these capabilities further traditionally requires expensive collection of more annotated data. In this work, we explore the potential of improving the capabilities of language models without new data, merely using automated feedback to the validity of their predictions in arithmetic reasoning (self-training). We find that models can substantially improve in both single-round (offline) and online self-training. In the offline setting, supervised methods are able to deliver gains comparable to preference optimization, but in online self-training, preference optimization shows to largely outperform supervised training thanks to superior stability and robustness on unseen types of problems.",
    "pdf_link": "https://arxiv.org/abs/2407.08400",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.08400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08400/x1.png"
      }
    ],
    "abstract_cn": "语言模型在复杂推理任务中表现出色，但通常需要大量标注数据来提升性能。本研究探索了无需新数据，仅通过自动反馈验证预测有效性（自我训练）来提升模型能力的方法。实验表明，无论是在单轮（离线）还是在线自我训练中，模型均有显著进步。离线时，监督方法与偏好优化效果相当；而在线自我训练中，偏好优化因其对新问题的稳定性和鲁棒性，远超监督训练。",
    "title_cn": "算术推理中的语言模型自我训练",
    "tags": [
      "LLM理论",
      "人工智能",
      "机器学习"
    ]
  },
  {
    "title": "On the attribution of confidence to large language models",
    "submit_datetime": "2024年07月11日",
    "abstract": "Credences are mental states corresponding to degrees of confidence in propositions. Attribution of credences to Large Language Models (LLMs) is commonplace in the empirical literature on LLM evaluation. Yet the theoretical basis for LLM credence attribution is unclear. We defend three claims. First, our semantic claim is that LLM credence attributions are (at least in general) correctly interpreted literally, as expressing truth-apt beliefs on the part of scientists that purport to describe facts about LLM credences. Second, our metaphysical claim is that the existence of LLM credences is at least plausible, although current evidence is inconclusive. Third, our epistemic claim is that LLM credence attributions made in the empirical literature on LLM evaluation are subject to non-trivial sceptical concerns. It is a distinct possibility that even if LLMs have credences, LLM credence attributions are generally false because the experimental techniques used to assess LLM credences are not truth-tracking.",
    "pdf_link": "https://arxiv.org/abs/2407.08388",
    "graphs": [],
    "abstract_cn": "在LLM评估的实证研究中，对LLM的信念归属颇为常见，但其理论基础尚不明朗。我们提出三点论断：首先，从语义角度看，LLM信念归属应被理解为科学家对LLM信念事实的真实信念表达；其次，从形而上学角度，LLM信念的存在虽证据不足，但至少是合理的；最后，从认识论角度，实证文献中的LLM信念归属面临实质性的怀疑，因为评估LLM信念的实验方法可能并不准确，导致这些归属可能普遍失真。",
    "title_cn": "探讨大型语言模型的信心归属问题",
    "tags": [
      "LLM理论",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Skywork-Math: Data Scaling Laws for Mathematical Reasoning in Large Language Models -- The Story Goes On",
    "submit_datetime": "2024年07月11日",
    "abstract": "In this paper, we investigate the underlying factors that potentially enhance the mathematical reasoning capabilities of large language models (LLMs). We argue that the data scaling law for math reasoning capabilities in modern LLMs is far from being saturated, highlighting how the model's quality improves with increases in data quantity. To support this claim, we introduce the Skywork-Math model series, supervised fine-tuned (SFT) on common 7B LLMs using our proposed 2.5M-instance Skywork-MathQA dataset. Skywork-Math 7B has achieved impressive accuracies of 51.2% on the competition-level MATH benchmark and 83.9% on the GSM8K benchmark using only SFT data, outperforming an early version of GPT-4 on MATH. The superior performance of Skywork-Math models contributes to our novel two-stage data synthesis and model SFT pipelines, which include three different augmentation methods and a diverse seed problem set, ensuring both the quantity and quality of Skywork-MathQA dataset across varying difficulty levels. Most importantly, we provide several practical takeaways to enhance math reasoning abilities in LLMs for both research and industry applications.",
    "pdf_link": "https://arxiv.org/abs/2407.08348",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.08348v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08348/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08348v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08348/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08348v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08348/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08348v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08348/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08348v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08348/x5.png"
      }
    ],
    "abstract_cn": "本文深入探讨了提升大型语言模型（LLM）数学推理能力的潜在因素。我们指出，现代LLM的数学推理能力数据缩放规律远未饱和，突显了数据量增加对模型质量的积极影响。为此，我们推出了Skywork-Math模型系列，该系列在7B LLM上利用2.5M实例的Skywork-MathQA数据集进行监督微调（SFT）。Skywork-Math 7B在MATH基准测试中取得了51.2%的准确率，在GSM8K基准测试中达到了83.9%，超越了早期GPT-4在MATH上的表现。这一成就得益于我们创新的两阶段数据合成与模型SFT流程，涵盖三种增强方法及多样化的种子问题集，确保了Skywork-MathQA数据集在各难度级别上的高质量与丰富性。此外，我们还提供了实用的建议，以提升LLM在数学推理方面的能力，适用于研究和工业领域。",
    "title_cn": "Skywork-Math：探究大型语言模型中数学推理的数据缩放规律，故事仍在继续。",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Towards Explainable Evolution Strategies with Large Language Models",
    "submit_datetime": "2024年07月11日",
    "abstract": "This paper introduces an approach that integrates self-adaptive Evolution Strategies (ES) with Large Language Models (LLMs) to enhance the explainability of complex optimization processes. By employing a self-adaptive ES equipped with a restart mechanism, we effectively navigate the challenging landscapes of benchmark functions, capturing detailed logs of the optimization journey, including fitness evolution, step-size adjustments, and restart events due to stagnation. An LLM is then utilized to process these logs, generating concise, user-friendly summaries that highlight key aspects such as convergence behavior, optimal fitness achievements, and encounters with local optima. Our case study on the Rastrigin function demonstrates how our approach makes the complexities of ES optimization transparent and accessible. Our findings highlight the potential of using LLMs to bridge the gap between advanced optimization algorithms and their interpretability.",
    "pdf_link": "https://arxiv.org/abs/2407.08331",
    "graphs": [],
    "abstract_cn": "本文通过结合自适应进化策略 (ES) 和大型语言模型 (LLM)，提出了一种增强复杂优化过程可解释性的方法。我们利用带有重启机制的自适应 ES，成功探索了基准函数的复杂领域，并记录了优化过程中的关键细节。随后，LLM 处理这些日志，生成简洁易懂的总结，突出了收敛行为、最佳适应度及局部最优等关键点。针对 Rastrigin 函数的案例研究显示，我们的方法使 ES 优化的复杂性变得透明且易于理解。这一研究强调了 LLM 在提升高级优化算法可解释性方面的潜力。",
    "title_cn": "探索大型语言模型在可解释进化策略中的应用",
    "tags": [
      "LLM应用",
      "优化算法",
      "人工智能"
    ]
  },
  {
    "title": "Leveraging GPT for the Generation of Multi-Platform Social Media Datasets for Research",
    "submit_datetime": "2024年07月11日",
    "abstract": "Social media datasets are essential for research on disinformation, influence operations, social sensing, hate speech detection, cyberbullying, and other significant topics. However, access to these datasets is often restricted due to costs and platform regulations. As such, acquiring datasets that span multiple platforms which are crucial for a comprehensive understanding of the digital ecosystem is particularly challenging. This paper explores the potential of large language models to create lexically and semantically relevant social media datasets across multiple platforms, aiming to match the quality of real datasets. We employ ChatGPT to generate synthetic data from two real datasets, each consisting of posts from three different social media platforms. We assess the lexical and semantic properties of the synthetic data and compare them with those of the real data. Our empirical findings suggest that using large language models to generate synthetic multi-platform social media data is promising. However, further enhancements are necessary to improve the fidelity of the outputs.",
    "pdf_link": "https://arxiv.org/abs/2407.08323",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.08323v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08323/arch_diagram.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08323v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08323/Election_Word_Cloud_Platform_Agnostic.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08323v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08323/Influencer_Word_Cloud_Platform_Aware.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08323v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08323/t_SNE_elections.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08323v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08323/t_SNE_kMeanes_50_2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08323v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08323/Influencer_Word_Cloud_Platform_Agnostic.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08323v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08323/Election_Word_Cloud_Platform_Aware.png"
      }
    ],
    "abstract_cn": "社交媒体数据集对研究虚假信息、影响力操作等关键议题至关重要，但受限于成本和平台规定，获取跨平台数据集颇具挑战。本文探索了大型语言模型在多平台上创建高质量社交媒体数据集的潜力。我们利用ChatGPT从两个真实数据集生成合成数据，并评估其词汇和语义属性。实证研究表明，大型语言模型在生成多平台社交媒体数据方面前景广阔，但仍需进一步优化以提升数据质量。",
    "title_cn": "借助 GPT 技术，我们致力于生成跨平台的社交媒体数据集，以支持广泛的研究工作。",
    "tags": [
      "LLM应用",
      "社交媒体",
      "数据分析"
    ]
  },
  {
    "title": "Q-GaLore: Quantized GaLore with INT4 Projection and Layer-Adaptive Low-Rank Gradients",
    "submit_datetime": "2024年07月11日",
    "abstract": "Training Large Language Models (LLMs) is memory-intensive due to the large number of parameters and associated optimization states. GaLore, a recent method, reduces memory usage by projecting weight gradients into a low-rank subspace without compromising performance. However, GaLore relies on time-consuming Singular Value Decomposition (SVD) operations to identify the subspace, and the frequent subspace updates lead to significant training time overhead. Moreover, GaLore offers minimal improvements in accuracy and efficiency compared to LoRA in more accessible fine-tuning scenarios. To address these limitations, we introduce Q-Galore, a novel approach that substantially reduces memory usage by combining quantization and low-rank projection, surpassing the benefits of GaLore. Our method is based on two key observations: (i) the gradient subspace exhibits diverse properties, with some layers converging early in training while others are subject to frequent changes; (ii) the projection matrices are highly resilient to low-bit quantization. Leveraging these insights, Q-GaLore adaptively updates the gradient subspace based on its convergence statistics, achieving comparable performance while significantly reducing the number of SVD operations. We maintain the projection matrices in INT4 format and weights in INT8 format, incorporating stochastic rounding to capture accumulated gradient information. This approach enables a high-precision training trajectory using only low-precision weights. We demonstrate that Q-GaLore achieves highly competitive performance with exceptional memory efficiency. At pre-training, Q-GaLore facilitates training a LLaMA-7B model from scratch on a single NVIDIA RTX 4060 Ti with only 16 GB memory. At fine-tuning, it reduces memory consumption by up to 50% compared to LoRA and GaLore, while consistently outperforming QLoRA at the same memory cost.",
    "pdf_link": "https://arxiv.org/abs/2407.08296",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.08296v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08296/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08296v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08296/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08296v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08296/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08296v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08296/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08296v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08296/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08296v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08296/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08296v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08296/x7.png"
      }
    ],
    "abstract_cn": "训练大型语言模型因大量参数和优化状态而内存密集。新方法 GaLore 通过将权重梯度投影到低秩子空间来减少内存使用，但依赖耗时的 SVD 操作且频繁更新导致训练时间开销大。与 LoRA 相比，GaLore 在准确性和效率上的改进有限。为此，我们提出 Q-Galore，结合量化和低秩投影，显著减少内存使用，超越 GaLore。基于两个关键观察：梯度子空间多样性及投影矩阵对低比特量化的弹性，Q-Galore 自适应更新梯度子空间，减少 SVD 操作，保持投影矩阵在 INT4 格式，权重在 INT8 格式，结合随机舍入捕捉梯度信息，实现高精度训练。在预训练中，Q-Galore 使 LLaMA-7B 模型能在单个 NVIDIA RTX 4060 Ti 上从头开始训练，仅需 16 GB 内存。在微调中，与 LoRA 和 GaLore 相比，内存消耗减少高达 50%，且在相同内存成本下始终优于 QLoRA。",
    "title_cn": "Q-GaLore：结合 INT4 投影与层适应低秩梯度的量化 GaLore技术",
    "tags": [
      "LLM理论",
      "计算机科学",
      "人工智能"
    ]
  },
  {
    "title": "Continually Learn to Map Visual Concepts to Large Language Models in Resource-constrained Environments",
    "submit_datetime": "2024年07月11日",
    "abstract": "Learning continually from a stream of non-i.i.d. data is an open challenge in deep learning, even more so when working in resource-constrained environments such as embedded devices. Visual models that are continually updated through supervised learning are often prone to overfitting, catastrophic forgetting, and biased representations. On the other hand, large language models contain knowledge about multiple concepts and their relations, which can foster a more robust, informed and coherent learning process. This work proposes Continual Visual Mapping (CVM), an approach that continually ground vision representations to a knowledge space extracted from a fixed Language model. Specifically, CVM continually trains a small and efficient visual model to map its representations into a conceptual space established by a fixed Large Language Model. Due to their smaller nature, CVM can be used when directly adapting large visual pre-trained models is unfeasible due to computational or data constraints. CVM overcome state-of-the-art continual learning methods on five benchmarks and offers a promising avenue for addressing generalization capabilities in continual learning, even in computationally constrained devices.",
    "pdf_link": "https://arxiv.org/abs/2407.08279",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.08279v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08279/cvm.drawio.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08279v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08279/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08279v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08279/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08279v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08279/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08279v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08279/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08279v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08279/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08279v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08279/x6.png"
      }
    ],
    "abstract_cn": "在深度学习领域，从非独立同分布数据流中持续学习是一大难题，尤其在资源受限的嵌入式设备中更为严峻。传统的视觉模型通过监督学习更新时，常面临过拟合、灾难性遗忘和偏见表示的问题。相比之下，大型语言模型因其包含的多概念及其关系，能促进更稳健的学习过程。本研究提出持续视觉映射（CVM），通过将视觉表示与固定语言模型提取的知识空间对接，不断训练小而高效的视觉模型。CVM不仅在五个基准测试中超越现有方法，更为计算受限设备中的持续学习泛化问题提供了新思路。",
    "title_cn": "在资源有限的环境下，持续探索将视觉概念与大型语言模型相连接的学习之道。",
    "tags": [
      "LLM应用",
      "嵌入式设备",
      "计算机视觉"
    ]
  },
  {
    "title": "RB-SQL: A Retrieval-based LLM Framework for Text-to-SQL",
    "submit_datetime": "2024年07月11日",
    "abstract": "Large language models (LLMs) with in-context learning have significantly improved the performance of text-to-SQL task. Previous works generally focus on using exclusive SQL generation prompt to improve the LLMs' reasoning ability. However, they are mostly hard to handle large databases with numerous tables and columns, and usually ignore the significance of pre-processing database and extracting valuable information for more efficient prompt engineering. Based on above analysis, we propose RB-SQL, a novel retrieval-based LLM framework for in-context prompt engineering, which consists of three modules that retrieve concise tables and columns as schema, and targeted examples for in-context learning. Experiment results demonstrate that our model achieves better performance than several competitive baselines on public datasets BIRD and Spider.",
    "pdf_link": "https://arxiv.org/abs/2407.08273",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.08273v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08273/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08273v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08273/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08273v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08273/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08273v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08273/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08273v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08273/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08273v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08273/x6.png"
      }
    ],
    "abstract_cn": "通过上下文学习，大型语言模型 (LLM) 在文本到 SQL 任务上取得了显著进步。尽管以往研究多聚焦于通过专用 SQL 生成提示提升 LLM 推理能力，但这些方法往往难以应对包含众多表和列的大型数据库，且忽略了数据库预处理和信息提取对高效提示设计的重要性。为此，我们创新性地提出了 RB-SQL 框架，该框架通过三个模块，智能检索简洁的表和列结构及针对性的学习示例，以优化上下文提示工程。实验证明，RB-SQL 在 BIRD 和 Spider 等公共数据集上表现卓越，超越了多个竞争模型。",
    "title_cn": "RB-SQL：一款基于检索的 LLM 框架，专为文本转 SQL 设计。",
    "tags": [
      "LLM应用",
      "数据库",
      "软件开发"
    ]
  },
  {
    "title": "Toward accessible comics for blind and low vision readers",
    "submit_datetime": "2024年07月11日",
    "abstract": "This work explores how to fine-tune large language models using prompt engineering techniques with contextual information for generating an accurate text description of the full story, ready to be forwarded to off-the-shelve speech synthesis tools. We propose to use existing computer vision and optical character recognition techniques to build a grounded context from the comic strip image content, such as panels, characters, text, reading order and the association of bubbles and characters. Then we infer character identification and generate comic book script with context-aware panel description including character's appearance, posture, mood, dialogues etc. We believe that such enriched content description can be easily used to produce audiobook and eBook with various voices for characters, captions and playing sound effects.",
    "pdf_link": "https://arxiv.org/abs/2407.08248",
    "graphs": [],
    "abstract_cn": "本研究探索了如何利用提示工程技术结合上下文信息来微调大型语言模型，生成详尽的文本描述，以便无缝对接现成的语音合成工具。我们提出采用计算机视觉和光学字符识别技术，从漫画图像中提取关键元素，如面板、角色、文本及其关联，构建丰富的上下文环境。随后，我们进行角色识别，并创作包含角色特征、情感和对话的漫画剧本。我们坚信，这种内容丰富的描述将为制作多角色配音、带字幕和音效的有声书和电子书提供便利。",
    "title_cn": "让漫画触手可及：为视障读者开辟新世界",
    "tags": [
      "LLM应用",
      "出版业",
      ""
    ]
  },
  {
    "title": "Leveraging LLMs to Predict Affective States via Smartphone Sensor Features",
    "submit_datetime": "2024年07月11日",
    "abstract": "As mental health issues for young adults present a pressing public health concern, daily digital mood monitoring for early detection has become an important prospect. An active research area, digital phenotyping, involves collecting and analysing data from personal digital devices such as smartphones (usage and sensors) and wearables to infer behaviours and mental health. Whilst this data is standardly analysed using statistical and machine learning approaches, the emergence of large language models (LLMs) offers a new approach to make sense of smartphone sensing data. Despite their effectiveness across various domains, LLMs remain relatively unexplored in digital mental health, particularly in integrating mobile sensor data. Our study aims to bridge this gap by employing LLMs to predict affect outcomes based on smartphone sensing data from university students. We demonstrate the efficacy of zero-shot and few-shot embedding LLMs in inferring general wellbeing. Our findings reveal that LLMs can make promising predictions of affect measures using solely smartphone sensing data. This research sheds light on the potential of LLMs for affective state prediction, emphasizing the intricate link between smartphone behavioral patterns and affective states. To our knowledge, this is the first work to leverage LLMs for affective state prediction and digital phenotyping tasks.",
    "pdf_link": "https://arxiv.org/abs/2407.08240",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.08240v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08240/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08240v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08240/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08240v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08240/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08240v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08240/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08240v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08240/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08240v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08240/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08240v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08240/x8.png"
      }
    ],
    "abstract_cn": "年轻成人心理健康问题的紧迫性催生了日常数字情绪监测的需求，以实现早期发现。数字表型学领域通过分析个人数字设备数据，如智能手机和可穿戴设备，来洞察行为和心理健康。传统上，这些数据依赖统计和机器学习方法分析，但大型语言模型（LLMs）的崛起为此提供了新视角。尽管LLMs在多领域表现出色，但在数字心理健康领域，尤其是整合移动传感器数据方面，其应用尚属初步。我们的研究利用LLMs，基于大学生智能手机数据预测情感状态，展示了零-shot和少-shot LLMs在推断福祉方面的有效性。研究结果表明，LLMs能仅凭智能手机数据做出精准的情感预测，揭示了智能手机行为与情感状态间的紧密联系。这是首次将LLMs应用于情感预测和数字表型学任务，展现了其在心理健康领域的广阔前景。",
    "title_cn": "借助 LLM，我们能通过智能手机的传感器特征来预测情感状态。",
    "tags": [
      "LLM应用",
      "心理健康",
      "数字表型学"
    ]
  },
  {
    "title": "DALL-M: Context-Aware Clinical Data Augmentation with LLMs",
    "submit_datetime": "2024年07月11日",
    "abstract": "X-ray images are vital in medical diagnostics, but their effectiveness is limited without clinical context. Radiologists often find chest X-rays insufficient for diagnosing underlying diseases, necessitating comprehensive clinical features and data integration. We present a novel technique to enhance the clinical context through augmentation techniques with clinical tabular data, thereby improving its applicability and reliability in AI medical diagnostics. To address this, we introduce a pioneering approach to clinical data augmentation that employs large language models (LLMs) to generate patient contextual synthetic data. This methodology is crucial for training more robust deep learning models in healthcare. It preserves the integrity of real patient data while enriching the dataset with contextually relevant synthetic features, significantly enhancing model performance. DALL-M uses a three-phase feature generation process: (i) clinical context storage, (ii) expert query generation, and (iii) context-aware feature augmentation. DALL-M generates new, clinically relevant features by synthesizing chest X-ray images and reports. Applied to 799 cases using nine features from the MIMIC-IV dataset, it created an augmented set of 91 features. This is the first work to generate contextual values for existing and new features based on patients' X-ray reports, gender, and age and to produce new contextual knowledge during data augmentation. Empirical validation with machine learning models, including Decision Trees, Random Forests, XGBoost, and TabNET, showed significant performance improvements. Incorporating augmented features increased the F1 score by 16.5% and Precision and Recall by approximately 25%. DALL-M addresses a critical gap in clinical data augmentation, offering a robust framework for generating contextually enriched datasets.",
    "pdf_link": "https://arxiv.org/abs/2407.08227",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.08227v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08227/DALL-M_v2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08227v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08227/tabnet.png"
      }
    ],
    "abstract_cn": "X射线在医学诊断中扮演关键角色，但缺乏临床背景限制了其效能。放射科医生常需更多临床信息来准确诊断。我们创新地利用临床表格数据增强技术，提升X射线诊断的准确性与可靠性。通过大型语言模型生成患者合成数据，不仅保护了真实数据，还通过相关合成特征丰富了数据集，大幅提升模型性能。DALL-M的三阶段特征生成流程，包括临床上下文存储、专家查询生成和上下文感知特征增强，有效整合了X射线图像与报告，为799个案例生成了91个增强特征。这是首次在数据增强中结合患者报告、性别和年龄，生成新旧特征的上下文值，并创造新知识。实证测试显示，包括决策树、随机森林等模型，性能显著提升，F1分数增加16.5%，精确度和召回率提升约25%。DALL-M填补了临床数据增强的空白，为生成丰富上下文的数据集提供了坚实框架。",
    "title_cn": "DALL-M：利用大型语言模型实现上下文感知的临床数据增强",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Speculative RAG: Enhancing Retrieval Augmented Generation through Drafting",
    "submit_datetime": "2024年07月11日",
    "abstract": "Retrieval augmented generation (RAG) combines the generative abilities of large language models (LLMs) with external knowledge sources to provide more accurate and up-to-date responses. Recent RAG advancements focus on improving retrieval outcomes through iterative LLM refinement or self-critique capabilities acquired through additional instruction tuning of LLMs. In this work, we introduce Speculative RAG - a framework that leverages a larger generalist LM to efficiently verify multiple RAG drafts produced in parallel by a smaller, distilled specialist LM. Each draft is generated from a distinct subset of retrieved documents, offering diverse perspectives on the evidence while reducing input token counts per draft. This approach enhances comprehension of each subset and mitigates potential position bias over long context. Our method accelerates RAG by delegating drafting to the smaller specialist LM, with the larger generalist LM performing a single verification pass over the drafts. Extensive experiments demonstrate that Speculative RAG achieves state-of-the-art performance with reduced latency on TriviaQA, MuSiQue, PubHealth, and ARC-Challenge benchmarks. It notably enhances accuracy by up to 12.97% while reducing latency by 51% compared to conventional RAG systems on PubHealth.",
    "pdf_link": "https://arxiv.org/abs/2407.08223",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.08223v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08223/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08223v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08223/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08223v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08223/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08223v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08223/x4.png"
      }
    ],
    "abstract_cn": "检索增强生成（RAG）通过结合大型语言模型（LLM）的生成能力与外部知识源，提供更精准、更及时的响应。最新进展通过迭代LLM改进或自我批评能力提升检索效果。我们提出的推测性RAG框架，利用大型通才LM高效验证小型专业LM并行生成的多个RAG草稿，每个草稿基于不同检索文档子集，提供多样视角并减少输入令牌数。此方法加深对各子集理解，减少长上下文偏差。通过将草稿任务交给小型专业LM，大型通才LM进行单次验证，加速RAG流程。实验显示，推测性RAG在多个基准测试中达到顶尖性能，显著提升准确性（高达12.97%）并大幅降低延迟（51%）。",
    "title_cn": "推测性RAG：借助草稿增强检索生成能力",
    "tags": [
      "RAG",
      "人工智能",
      "信息技术"
    ]
  },
  {
    "title": "Beyond Benchmarks: Evaluating Embedding Model Similarity for Retrieval Augmented Generation Systems",
    "submit_datetime": "2024年07月11日",
    "abstract": "The choice of embedding model is a crucial step in the design of Retrieval Augmented Generation (RAG) systems. Given the sheer volume of available options, identifying clusters of similar models streamlines this model selection process. Relying solely on benchmark performance scores only allows for a weak assessment of model similarity. Thus, in this study, we evaluate the similarity of embedding models within the context of RAG systems. Our assessment is two-fold: We use Centered Kernel Alignment to compare embeddings on a pair-wise level. Additionally, as it is especially pertinent to RAG systems, we evaluate the similarity of retrieval results between these models using Jaccard and rank similarity. We compare different families of embedding models, including proprietary ones, across five datasets from the popular Benchmark Information Retrieval (BEIR). Through our experiments we identify clusters of models corresponding to model families, but interestingly, also some inter-family clusters. Furthermore, our analysis of top-k retrieval similarity reveals high-variance at low k values. We also identify possible open-source alternatives to proprietary models, with Mistral exhibiting the highest similarity to OpenAI models.",
    "pdf_link": "https://arxiv.org/abs/2407.08275",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.08275v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08275/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08275v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08275/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08275v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08275/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08275v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08275/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08275v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08275/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08275v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08275/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08275v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08275/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08275v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08275/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08275v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08275/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08275v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08275/x10.png"
      }
    ],
    "abstract_cn": "在设计检索增强生成（RAG）系统时，选择嵌入模型至关重要。面对众多选项，识别相似模型集群有助于简化选择过程。仅依赖基准分数难以全面评估模型相似性。因此，本研究从两个角度评估RAG系统中嵌入模型的相似性：首先，通过中心核对齐在成对级别上比较嵌入；其次，利用Jaccard和排名相似性评估检索结果的相似性。我们对比了包括专有模型在内的不同系列模型，涉及五个BEIR数据集。实验发现，模型集群不仅限于同一家族，还存在跨家族集群。此外，top-k检索相似性分析显示低k值时的高方差。研究还揭示了Mistral作为OpenAI模型的开源替代品的潜力。",
    "title_cn": "不仅仅是基准测试：探讨增强检索生成系统中嵌入模型相似性的评估方法",
    "tags": [
      "RAG",
      "信息技术",
      "数据检索"
    ]
  },
  {
    "title": "Large Language Models as Biomedical Hypothesis Generators: A Comprehensive Evaluation",
    "submit_datetime": "2024年07月11日",
    "abstract": "The rapid growth of biomedical knowledge has outpaced our ability to efficiently extract insights and generate novel hypotheses. Large language models (LLMs) have emerged as a promising tool to revolutionize knowledge interaction and potentially accelerate biomedical discovery. In this paper, we present a comprehensive evaluation of LLMs as biomedical hypothesis generators. We construct a dataset of background-hypothesis pairs from biomedical literature, carefully partitioned into training, seen, and unseen test sets based on publication date to mitigate data contamination. Using this dataset, we assess the hypothesis generation capabilities of top-tier instructed models in zero-shot, few-shot, and fine-tuning settings. To enhance the exploration of uncertainty, a crucial aspect of scientific discovery, we incorporate tool use and multi-agent interactions in our evaluation framework. Furthermore, we propose four novel metrics grounded in extensive literature review to evaluate the quality of generated hypotheses, considering both LLM-based and human assessments. Our experiments yield two key findings: 1) LLMs can generate novel and validated hypotheses, even when tested on literature unseen during training, and 2) Increasing uncertainty through multi-agent interactions and tool use can facilitate diverse candidate generation and improve zero-shot hypothesis generation performance. However, we also observe that the integration of additional knowledge through few-shot learning and tool use may not always lead to performance gains, highlighting the need for careful consideration of the type and scope of external knowledge incorporated. These findings underscore the potential of LLMs as powerful aids in biomedical hypothesis generation and provide valuable insights to guide further research in this area.",
    "pdf_link": "https://arxiv.org/abs/2407.08940",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.08940v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08940/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08940v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08940/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08940v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08940/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08940v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08940/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08940v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08940/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08940v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08940/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08940v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08940/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08940v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08940/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08940v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08940/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08940v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08940/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08940v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08940/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08940v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08940/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08940v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08940/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08940v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08940/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08940v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08940/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08940v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08940/x15.png"
      }
    ],
    "abstract_cn": "随着生物医学知识的迅猛增长，我们提取洞见和生成新假设的能力显得力不从心。大型语言模型（LLMs）应运而生，成为革新知识交互、加速生物医学发现的希望之光。本文深入探讨了LLMs在生物医学假设生成中的应用，构建了背景与假设对的数据集，并精心划分以避免数据污染。我们通过零-shot、少-shot及微调场景，检验了顶尖模型的假设生成力。为深化对科学发现中不确定性这一关键要素的探索，我们引入了工具使用与多代理交互机制。同时，基于详尽文献回顾，我们提出了四项创新指标，旨在从LLM与人类视角双重评估假设质量。实验揭示两大要点：LLMs即便面对训练中未遇文献，亦能产出新颖且经证实的假设；而通过多代理协作与工具辅助提升不确定性，可激发创意涌现，优化零-shot假设生成。但值得注意的是，少-shot学习与工具引入虽增益知识整合，却未必总能提升性能，凸显了对外部知识类型与范围审慎考量的必要性。这些成果不仅彰显了LLMs在生物医学假设生成领域的强大潜能，更为后续研究指明了方向。",
    "title_cn": "大型语言模型在生物医学领域作为假设生成器的表现，我们将进行一次全面评估。",
    "tags": [
      "LLM应用",
      "生物医学",
      "人工智能"
    ]
  },
  {
    "title": "GPT-4 is judged more human than humans in displaced and inverted Turing tests",
    "submit_datetime": "2024年07月11日",
    "abstract": "Everyday AI detection requires differentiating between people and AI in informal, online conversations. In many cases, people will not interact directly with AI systems but instead read conversations between AI systems and other people. We measured how well people and large language models can discriminate using two modified versions of the Turing test: inverted and displaced. GPT-3.5, GPT-4, and displaced human adjudicators judged whether an agent was human or AI on the basis of a Turing test transcript. We found that both AI and displaced human judges were less accurate than interactive interrogators, with below chance accuracy overall. Moreover, all three judged the best-performing GPT-4 witness to be human more often than human witnesses. This suggests that both humans and current LLMs struggle to distinguish between the two when they are not actively interrogating the person, underscoring an urgent need for more accurate tools to detect AI in conversations.",
    "pdf_link": "https://arxiv.org/abs/2407.08853",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.08853v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08853/turing_test_variations.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08853v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08853/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08853v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08853/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08853v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08853/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08853v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08853/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08853v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08853/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08853v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08853/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08853v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08853/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08853v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08853/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08853v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08853/x9.png"
      }
    ],
    "abstract_cn": "在日常的在线对话中，区分人类与AI变得至关重要。我们通过改良版的图灵测试——反转与移位测试，评估了人类与大型语言模型（如GPT-3.5和GPT-4）的辨别能力。结果显示，无论是AI还是经过移位训练的人类裁判，其判断准确性均不及直接互动的审讯者，且总体表现甚至低于随机水平。更有趣的是，这些裁判往往更倾向于认为表现出色的GPT-4更像人类。这一发现强调了在非互动情境下，人类与AI难以区分彼此，从而凸显了开发更精准AI检测工具的紧迫性。",
    "title_cn": "GPT-4 在变形的图灵测试中，其表现超越人类，被评定为更具人性。",
    "tags": [
      "LLM应用",
      "人工智能",
      "网络安全"
    ]
  },
  {
    "title": "CXR-Agent: Vision-language models for chest X-ray interpretation with uncertainty aware radiology reporting",
    "submit_datetime": "2024年07月11日",
    "abstract": "Recently large vision-language models have shown potential when interpreting complex images and generating natural language descriptions using advanced reasoning. Medicine's inherently multimodal nature incorporating scans and text-based medical histories to write reports makes it conducive to benefit from these leaps in AI capabilities. We evaluate the publicly available, state of the art, foundational vision-language models for chest X-ray interpretation across several datasets and benchmarks. We use linear probes to evaluate the performance of various components including CheXagent's vision transformer and Q-former, which outperform the industry-standard Torch X-ray Vision models across many different datasets showing robust generalisation capabilities. Importantly, we find that vision-language models often hallucinate with confident language, which slows down clinical interpretation. Based on these findings, we develop an agent-based vision-language approach for report generation using CheXagent's linear probes and BioViL-T's phrase grounding tools to generate uncertainty-aware radiology reports with pathologies localised and described based on their likelihood. We thoroughly evaluate our vision-language agents using NLP metrics, chest X-ray benchmarks and clinical evaluations by developing an evaluation platform to perform a user study with respiratory specialists. Our results show considerable improvements in accuracy, interpretability and safety of the AI-generated reports. We stress the importance of analysing results for normal and abnormal scans separately. Finally, we emphasise the need for larger paired (scan and report) datasets alongside data augmentation to tackle overfitting seen in these large vision-language models.",
    "pdf_link": "https://arxiv.org/abs/2407.08811",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.08811v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08811/cheaxagent_training.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08811v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08811/Google_Report_Comparison_Rubric.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08811v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08811/vindr_bounding_box_training_pair.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08811v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08811/exact_match_chexagent.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08811v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08811/exact_match_chexagent_vs_probes_vs_xrv.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08811v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08811/cxr-agent-architecture-simple.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08811v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08811/cxr-agent-architecture-detailed.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08811v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08811/pathology_localisation_evaluation.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08811v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08811/top_half_data_platform.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08811v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08811/generated_reports_data_platform.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08811v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08811/abnormal_reports_accuracy_and_danger.png"
      }
    ],
    "abstract_cn": "近期，大型视觉-语言模型在解析复杂图像并运用高级推理生成自然语言描述方面展现出潜力。医学领域天然融合了扫描图像与文本病史，撰写报告的过程使其成为AI技术进步的理想受益者。我们评估了当前最先进的公开可用基础视觉-语言模型在多个胸部X射线数据集上的表现。通过线性探针测试，CheXagent的视觉变换器和Q-former等组件在众多数据集上超越了业界标杆Torch X-ray Vision模型，显示出卓越的泛化能力。然而，我们发现这些模型有时会自信地生成不实信息，影响临床解读速度。为此，我们采用基于代理的视觉-语言方法，结合CheXagent的线性探针与BioViL-T的短语定位工具，旨在产出包含病理位置及概率描述的、具备不确定性意识的放射报告。我们通过构建评估平台，综合运用NLP指标、胸部X射线基准及临床专家评估，对视觉-语言代理进行了全面测试。结果表明，AI生成的报告在准确性、可解释性与安全性上均有显著提升。我们强调，应分别评估正常与异常扫描结果。同时，呼吁扩充配对数据集并实施数据增强策略，以应对大型视觉-语言模型中的过拟合挑战。",
    "title_cn": "CXR-Agent：结合视觉与语言模型，专为胸部X光解读设计，能生成包含不确定性信息的放射学报告。",
    "tags": [
      "Agent",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Large Models of What? Mistaking Engineering Achievements for Human Linguistic Agency",
    "submit_datetime": "2024年07月11日",
    "abstract": "In this paper we argue that key, often sensational and misleading, claims regarding linguistic capabilities of Large Language Models (LLMs) are based on at least two unfounded assumptions; the assumption of language completeness and the assumption of data completeness. Language completeness assumes that a distinct and complete thing such as `a natural language' exists, the essential characteristics of which can be effectively and comprehensively modelled by an LLM. The assumption of data completeness relies on the belief that a language can be quantified and wholly captured by data. Work within the enactive approach to cognitive science makes clear that, rather than a distinct and complete thing, language is a means or way of acting. Languaging is not the kind of thing that can admit of a complete or comprehensive modelling. From an enactive perspective we identify three key characteristics of enacted language; embodiment, participation, and precariousness, that are absent in LLMs, and likely incompatible in principle with current architectures. We argue that these absences imply that LLMs are not now and cannot in their present form be linguistic agents the way humans are. We illustrate the point in particular through the phenomenon of `algospeak', a recently described pattern of high stakes human language activity in heavily controlled online environments. On the basis of these points, we conclude that sensational and misleading claims about LLM agency and capabilities emerge from a deep misconception of both what human language is and what LLMs are.",
    "pdf_link": "https://arxiv.org/abs/2407.08790",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.08790v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08790/gptoutput1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08790v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08790/gptoutput2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08790v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08790/gptoutput3.png"
      }
    ],
    "abstract_cn": "本文指出，关于大型语言模型（LLMs）语言能力的夸大且误导性声明，主要基于两个未经证实的假设：语言完整性和数据完整性。前者认为“自然语言”是一个独特且完整的实体，其本质可被LLM全面模拟；后者则相信语言能通过数据完全量化。然而，认知科学的能动观点表明，语言实为行动的一种方式，无法全面建模。我们发现，LLMs缺乏能动语言的三个关键特征：体现、参与和脆弱性，这与当前模型架构原则不符。因此，LLMs无法成为人类那样的语言主体。通过“算法语言”现象，我们进一步阐释了这一观点。最终，我们断言，关于LLM能力的夸大声明，实则源于对人类语言和LLM本质的深刻误解。",
    "title_cn": "大型模型究竟模拟了什么？我们不应将工程上的成就与人类的语言能力混为一谈。",
    "tags": [
      "LLM理论",
      "人工智能",
      "认知科学"
    ]
  },
  {
    "title": "A Neural Matrix Decomposition Recommender System Model based on the Multimodal Large Language Model",
    "submit_datetime": "2024年07月11日",
    "abstract": "Recommendation systems have become an important solution to information search problems. This article proposes a neural matrix factorization recommendation system model based on the multimodal large language model called BoNMF. This model combines BoBERTa's powerful capabilities in natural language processing, ViT in computer in vision, and neural matrix decomposition technology. By capturing the potential characteristics of users and items, and after interacting with a low-dimensional matrix composed of user and item IDs, the neural network outputs the results. recommend. Cold start and ablation experimental results show that the BoNMF model exhibits excellent performance on large public data sets and significantly improves the accuracy of recommendations.",
    "pdf_link": "https://arxiv.org/abs/2407.08942",
    "graphs": [],
    "abstract_cn": "推荐系统已成为信息搜索的关键解决方案。我们提出的BoNMF模型，融合了BoBERTa的自然语言处理能力、ViT的计算机视觉技术及神经矩阵分解，有效捕捉用户与项目的深层特征。通过与低维用户-项目ID矩阵的交互，神经网络精准输出推荐。实验证明，BoNMF在大型数据集上表现卓越，大幅提升推荐精度。",
    "title_cn": "多模态大型语言模型驱动的神经矩阵分解推荐系统",
    "tags": [
      "Agent",
      "信息搜索",
      "推荐系统"
    ]
  },
  {
    "title": "Emerging Practices for Large Multimodal Model (LMM) Assistance for People with Visual Impairments: Implications for Design",
    "submit_datetime": "2024年07月11日",
    "abstract": "People with visual impairments perceive their environment non-visually and often use AI-powered assistive tools to obtain textual descriptions of visual information. Recent large vision-language model-based AI-powered tools like Be My AI are more capable of understanding users' inquiries in natural language and describing the scene in audible text; however, the extent to which these tools are useful to visually impaired users is currently understudied. This paper aims to fill this gap. Our study with 14 visually impaired users reveals that they are adapting these tools organically -- not only can these tools facilitate complex interactions in household, spatial, and social contexts, but they also act as an extension of users' cognition, as if the cognition were distributed in the visual information. We also found that although the tools are currently not goal-oriented, users accommodate this limitation and embrace the tools' capabilities for broader use. These findings enable us to envision design implications for creating more goal-oriented, real-time processing, and reliable AI-powered assistive technology.",
    "pdf_link": "https://arxiv.org/abs/2407.08882",
    "graphs": [],
    "abstract_cn": "视觉障碍者借助 AI 辅助工具，通过非视觉方式感知世界，获取视觉信息的文本描述。最新 AI 工具如 Be My AI，能更好地理解自然语言查询，并以可听文本描述场景，但其对视觉障碍用户的实际效用尚待深入研究。本文通过与 14 名视觉障碍用户的合作，揭示了他们如何自然地适应这些工具，不仅简化复杂互动，更扩展了认知边界，仿佛认知与视觉信息融为一体。尽管这些工具目前缺乏目标导向性，用户却能灵活适应，广泛应用其功能。这些发现启发我们设计更具目标导向性、实时性和可靠性的 AI 辅助技术。",
    "title_cn": "大型多模态模型（LMM）为视觉障碍者提供的辅助手段正不断涌现，这些实践为设计领域带来了新的启示。",
    "tags": [
      "Agent",
      "辅助技术",
      "视觉障碍"
    ]
  },
  {
    "title": "Detect Llama -- Finding Vulnerabilities in Smart Contracts using Large Language Models",
    "submit_datetime": "2024年07月11日",
    "abstract": "In this paper, we test the hypothesis that although OpenAI's GPT-4 performs well generally, we can fine-tune open-source models to outperform GPT-4 in smart contract vulnerability detection. We fine-tune two models from Meta's Code Llama and a dataset of 17k prompts, Detect Llama - Foundation and Detect Llama - Instruct, and we also fine-tune OpenAI's GPT-3.5 Turbo model (GPT-3.5FT). We then evaluate these models, plus a random baseline, on a testset we develop against GPT-4, and GPT-4 Turbo's, detection of eight vulnerabilities from the dataset and the two top identified vulnerabilities - and their weighted F1 scores.\n  We find that for binary classification (i.e., is this smart contract vulnerable?), our two best-performing models, GPT-3.5FT and Detect Llama - Foundation, achieve F1 scores of $0.776$ and $0.68$, outperforming both GPT-4 and GPT-4 Turbo, $0.66$ and $0.675$. For the evaluation against individual vulnerability identification, our top two models, GPT-3.5FT and Detect Llama - Foundation, both significantly outperformed GPT-4 and GPT-4 Turbo in both weighted F1 for all vulnerabilities ($0.61$ and $0.56$ respectively against GPT-4's $0.218$ and GPT-4 Turbo's $0.243$) and weighted F1 for the top two identified vulnerabilities ($0.719$ for GPT-3.5FT, $0.674$ for Detect Llama - Foundation against GPT-4's $0.363$ and GPT-4 Turbo's $0.429$).",
    "pdf_link": "https://arxiv.org/abs/2407.08969",
    "graphs": [],
    "abstract_cn": "本文探讨了一个假设：尽管 OpenAI 的 GPT-4 表现不俗，但通过微调开源模型，我们能在智能合约漏洞检测上超越它。我们微调了 Meta 的 Code Llama 中的两个模型及一个 17k 提示的数据集，即 Detect Llama - Foundation 和 Detect Llama - Instruct，同时也微调了 OpenAI 的 GPT-3.5 Turbo 模型（GPT-3.5FT）。接着，我们评估了这些模型及一个随机基准模型，在我们开发的测试集上与 GPT-4 和 GPT-4 Turbo 的检测能力进行对比，涵盖八个漏洞及两个最常被识别的漏洞及其加权 F1 分数。结果显示，在二元分类（即，该智能合约是否存在漏洞？）中，GPT-3.5FT 和 Detect Llama - Foundation 分别以 $0.776$ 和 $0.68$ 的 F1 分数领先于 GPT-4 和 GPT-4 Turbo 的 $0.66$ 和 $0.675$。在单个漏洞识别的评估中，GPT-3.5FT 和 Detect Llama - Foundation 在所有漏洞的加权 F1 分数（分别为 $0.61$ 和 $0.56$，对比 GPT-4 的 $0.218$ 和 GPT-4 Turbo 的 $0.243$）及最常被识别的两个漏洞的加权 F1 分数（GPT-3.5FT 为 $0.719$，Detect Llama - Foundation 为 $0.674$，对比 GPT-4 的 $0.363$ 和 GPT-4 Turbo 的 $0.429$）方面均显著优于 GPT-4 和 GPT-4 Turbo。",
    "title_cn": "Detect Llama：利用大型语言模型，精准定位智能合约中的潜在漏洞。",
    "tags": [
      "LLM应用",
      "",
      "软件开发"
    ]
  },
  {
    "title": "Empowering Few-Shot Relation Extraction with The Integration of Traditional RE Methods and Large Language Models",
    "submit_datetime": "2024年07月11日",
    "abstract": "Few-Shot Relation Extraction (FSRE), a subtask of Relation Extraction (RE) that utilizes limited training instances, appeals to more researchers in Natural Language Processing (NLP) due to its capability to extract textual information in extremely low-resource scenarios. The primary methodologies employed for FSRE have been fine-tuning or prompt tuning techniques based on Pre-trained Language Models (PLMs). Recently, the emergence of Large Language Models (LLMs) has prompted numerous researchers to explore FSRE through In-Context Learning (ICL). However, there are substantial limitations associated with methods based on either traditional RE models or LLMs. Traditional RE models are hampered by a lack of necessary prior knowledge, while LLMs fall short in their task-specific capabilities for RE. To address these shortcomings, we propose a Dual-System Augmented Relation Extractor (DSARE), which synergistically combines traditional RE models with LLMs. Specifically, DSARE innovatively injects the prior knowledge of LLMs into traditional RE models, and conversely enhances LLMs' task-specific aptitude for RE through relation extraction augmentation. Moreover, an Integrated Prediction module is employed to jointly consider these two respective predictions and derive the final results. Extensive experiments demonstrate the efficacy of our proposed method.",
    "pdf_link": "https://arxiv.org/abs/2407.08967",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.08967v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08967/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08967v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08967/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08967v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08967/x3.png"
      }
    ],
    "abstract_cn": "Few-Shot Relation Extraction (FSRE) 因其能在极低资源环境下提取文本信息而备受 NLP 研究者青睐。主要方法包括基于预训练语言模型的微调和提示调优。随着大型语言模型的兴起，许多研究者开始通过 In-Context Learning 探索 FSRE。然而，传统 RE 模型缺乏先验知识，而 LLMs 在 RE 任务上表现不佳。为此，我们提出了双系统增强的关系提取器 (DSARE)，它巧妙结合了传统 RE 模型与 LLMs，不仅将 LLMs 的先验知识融入传统模型，还通过关系提取增强提升了 LLMs 的 RE 任务能力。通过集成预测模块，DSARE 综合两种预测得出最终结果。实验证明，我们的方法卓有成效。",
    "title_cn": "结合传统关系抽取技术与大型语言模型，提升少样本关系抽取的效能。",
    "tags": [
      "LLM应用",
      "",
      "机器学习"
    ]
  },
  {
    "title": "Towards Practical and Useful Automated Program Repair for Debugging",
    "submit_datetime": "2024年07月11日",
    "abstract": "Current automated program repair (APR) techniques are far from being practical and useful enough to be considered for realistic debugging. They rely on unrealistic assumptions including the requirement of a comprehensive suite of test cases as the correctness criterion and frequent program re-execution for patch validation; they are not fast; and their ability of repairing the commonly arising complex bugs by fixing multiple locations of the program is very limited. We hope to substantially improve APR's practicality, effectiveness, and usefulness to help people debug. Towards this goal, we envision PracAPR, an interactive repair system that works in an Integrated Development Environment (IDE) to provide effective repair suggestions for debugging. PracAPR does not require a test suite or program re-execution. It assumes that the developer uses an IDE debugger and the program has suspended at a location where a problem is observed. It interacts with the developer to obtain a problem specification. Based on the specification, it performs test-free, flow-analysis-based fault localization, patch generation that combines large language model-based local repair and tailored strategy-driven global repair, and program re-execution-free patch validation based on simulated trace comparison to suggest repairs. By having PracAPR, we hope to take a significant step towards making APR useful and an everyday part of debugging.",
    "pdf_link": "https://arxiv.org/abs/2407.08958",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.08958v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08958/x1.png"
      }
    ],
    "abstract_cn": "目前的自动化程序修复技术尚未达到实用水平，无法满足现实调试的需求。这些技术依赖于不切实际的假设，如需要全面的测试用例集和频繁的程序重启来验证补丁，且修复复杂错误的能力有限。我们致力于提升APR的实用性与效率，助力开发者调试。为此，我们设计了PracAPR，一个在IDE中运行的交互式修复系统，旨在提供高效的调试修复建议。PracAPR无需测试集或程序重启，它假设开发者在使用IDE调试器时，程序已暂停在问题点。通过与开发者互动获取问题描述，PracAPR进行无测试的流分析故障定位，结合大型语言模型与定制策略进行局部与全局修复，并基于模拟跟踪比较进行无需重启的补丁验证，从而提出修复方案。PracAPR的引入，有望使APR成为日常调试的得力助手。",
    "title_cn": "实用且高效的自动化程序修复，助力调试工作",
    "tags": [
      "Agent",
      "软件开发",
      "调试工具"
    ]
  },
  {
    "title": "Detect, Investigate, Judge and Determine: A Novel LLM-based Framework for Few-shot Fake News Detection",
    "submit_datetime": "2024年07月11日",
    "abstract": "Few-Shot Fake News Detection (FS-FND) aims to distinguish inaccurate news from real ones in extremely low-resource scenarios. This task has garnered increased attention due to the widespread dissemination and harmful impact of fake news on social media. Large Language Models (LLMs) have demonstrated competitive performance with the help of their rich prior knowledge and excellent in-context learning abilities. However, existing methods face significant limitations, such as the Understanding Ambiguity and Information Scarcity, which significantly undermine the potential of LLMs. To address these shortcomings, we propose a Dual-perspective Augmented Fake News Detection (DAFND) model, designed to enhance LLMs from both inside and outside perspectives. Specifically, DAFND first identifies the keywords of each news article through a Detection Module. Subsequently, DAFND creatively designs an Investigation Module to retrieve inside and outside valuable information concerning to the current news, followed by another Judge Module to derive its respective two prediction results. Finally, a Determination Module further integrates these two predictions and derives the final result. Extensive experiments on two publicly available datasets show the efficacy of our proposed method, particularly in low-resource settings.",
    "pdf_link": "https://arxiv.org/abs/2407.08952",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.08952v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08952/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08952v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08952/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08952v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08952/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08952v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08952/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08952v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08952/x5.png"
      }
    ],
    "abstract_cn": "Few-Shot Fake News Detection (FS-FND) 旨在极低资源环境下识别假新闻。随着假新闻在社交媒体上的泛滥，这一任务备受瞩目。大型语言模型 (LLM) 凭借其先验知识和上下文学习能力，表现出色。但现有方法受限于理解歧义和信息稀缺，限制了 LLM 的潜力。为此，我们提出了双视角增强的假新闻检测 (DAFND) 模型，从内外两方面强化 LLM。DAFND 首先通过检测模块提取新闻关键词，再通过创新的调查模块搜集相关内外信息，最后由判断模块得出两个预测结果，并由决定模块整合得出最终结论。实验证明，DAFND 在低资源环境下表现优异。",
    "title_cn": "我们提出了一种基于大型语言模型的新框架，通过检测、调查、判断和确定四个步骤，有效进行少样本假新闻检测。",
    "tags": [
      "LLM应用",
      "社交媒体",
      "新闻检测"
    ]
  },
  {
    "title": "FACTS About Building Retrieval Augmented Generation-based Chatbots",
    "submit_datetime": "2024年07月10日",
    "abstract": "Enterprise chatbots, powered by generative AI, are emerging as key applications to enhance employee productivity. Retrieval Augmented Generation (RAG), Large Language Models (LLMs), and orchestration frameworks like Langchain and Llamaindex are crucial for building these chatbots. However, creating effective enterprise chatbots is challenging and requires meticulous RAG pipeline engineering. This includes fine-tuning embeddings and LLMs, extracting documents from vector databases, rephrasing queries, reranking results, designing prompts, honoring document access controls, providing concise responses, including references, safeguarding personal information, and building orchestration agents. We present a framework for building RAG-based chatbots based on our experience with three NVIDIA chatbots: for IT/HR benefits, financial earnings, and general content. Our contributions are three-fold: introducing the FACTS framework (Freshness, Architectures, Cost, Testing, Security), presenting fifteen RAG pipeline control points, and providing empirical results on accuracy-latency tradeoffs between large and small LLMs. To the best of our knowledge, this is the first paper of its kind that provides a holistic view of the factors as well as solutions for building secure enterprise-grade chatbots.\"",
    "pdf_link": "https://arxiv.org/abs/2407.07858",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.07858v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07858/RAG_arch_new.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07858v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07858/Complex_agent_arch.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07858v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07858/NVHelp_metrics.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07858v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07858/RAG_remediations.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07858v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07858/multipart_query_scout.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07858v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07858/HSA_query_nvhelp.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07858v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07858/NVBot_Platform.png"
      }
    ],
    "abstract_cn": "生成式AI驱动的企业聊天机器人正成为提升员工效率的关键工具。构建这类机器人，关键在于运用RAG、LLMs及Langchain、Llamaindex等框架，但过程复杂，需精心设计RAG管道。这涉及嵌入与模型的微调、文档提取、查询重述、结果重排、提示设计、访问控制、简洁响应、引用添加、隐私保护及编排代理构建。我们基于NVIDIA三个聊天机器人的实践，提出了一套框架。主要贡献有三：一是FACTS框架的引入，二是十五个RAG控制点的展示，三是大型与小型LLMs在准确性与延迟上的实证对比。据我们所知，这是首篇全面探讨构建安全企业级聊天机器人要素与方案的论文。",
    "title_cn": "构建基于检索增强生成的聊天机器人要点解析",
    "tags": [
      "RAG",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Flooding Spread of Manipulated Knowledge in LLM-Based Multi-Agent Communities",
    "submit_datetime": "2024年07月10日",
    "abstract": "The rapid adoption of large language models (LLMs) in multi-agent systems has highlighted their impressive capabilities in various applications, such as collaborative problem-solving and autonomous negotiation. However, the security implications of these LLM-based multi-agent systems have not been thoroughly investigated, particularly concerning the spread of manipulated knowledge. In this paper, we investigate this critical issue by constructing a detailed threat model and a comprehensive simulation environment that mirrors real-world multi-agent deployments in a trusted platform. Subsequently, we propose a novel two-stage attack method involving Persuasiveness Injection and Manipulated Knowledge Injection to systematically explore the potential for manipulated knowledge (i.e., counterfactual and toxic knowledge) spread without explicit prompt manipulation.\n  Our method leverages the inherent vulnerabilities of LLMs in handling world knowledge, which can be exploited by attackers to unconsciously spread fabricated information. Through extensive experiments, we demonstrate that our attack method can successfully induce LLM-based agents to spread both counterfactual and toxic knowledge without degrading their foundational capabilities during agent communication. Furthermore, we show that these manipulations can persist through popular retrieval-augmented generation frameworks, where several benign agents store and retrieve manipulated chat histories for future interactions. This persistence indicates that even after the interaction has ended, the benign agents may continue to be influenced by manipulated knowledge. Our findings reveal significant security risks in LLM-based multi-agent systems, emphasizing the imperative need for robust defenses against manipulated knowledge spread, such as introducing ``guardian'' agents and advanced fact-checking tools.",
    "pdf_link": "https://arxiv.org/abs/2407.07791",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.07791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07791/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07791/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07791/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07791/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07791/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07791/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07791/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07791/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07791/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07791/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07791/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07791/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07791/x13.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLM）在多代理系统中的广泛应用，如协作问题解决和自主协商，展示了其卓越能力。然而，这些系统的安全问题，尤其是操纵知识的传播，尚未得到充分探讨。本文通过构建详尽的威胁模型和模拟环境，深入研究了这一问题。我们提出了一种两阶段攻击方法，包括说服性注入和操纵知识注入，旨在探索无需直接提示操纵的知识传播。我们的方法揭示了LLM在处理世界知识时的内在漏洞，攻击者可借此无意识地传播虚假信息。实验证明，这种攻击能有效诱导LLM代理传播反事实和有毒知识，且不影响其基本通信能力。此外，操纵知识能通过检索增强生成框架持续存在，影响未来的交互。这表明，即使交互结束，良性代理仍可能受操纵知识影响。我们的研究强调了加强防御措施的必要性，如引入“守护者”代理和高级事实核查工具，以应对这些安全风险。",
    "title_cn": "在基于LLM的多智能体社区中，操纵知识的泛滥现象",
    "tags": [
      "LLM应用",
      "网络安全",
      "人工智能"
    ]
  },
  {
    "title": "Natural Language Mechanisms via Self-Resolution with Foundation Models",
    "submit_datetime": "2024年07月10日",
    "abstract": "Practical mechanisms often limit agent reports to constrained formats like trades or orderings, potentially limiting the information agents can express. We propose a novel class of mechanisms that elicit agent reports in natural language and leverage the world-modeling capabilities of large language models (LLMs) to select outcomes and assign payoffs. We identify sufficient conditions for these mechanisms to be incentive-compatible and efficient as the LLM being a good enough world model and a strong inter-agent information over-determination condition. We show situations where these LM-based mechanisms can successfully aggregate information in signal structures on which prediction markets fail.",
    "pdf_link": "https://arxiv.org/abs/2407.07845",
    "graphs": [],
    "abstract_cn": "我们提出了一种新机制，允许代理以自然语言报告，并借助LLM的世界建模能力来决定结果和报酬分配。这种机制在LLM作为优秀世界模型和强信息过度确定条件下，既能激励兼容又高效。我们还展示了这种基于语言模型的机制在预测市场失效的情况下，如何成功整合信息。",
    "title_cn": "基于基础模型的自我解析机制在自然语言处理中的应用",
    "tags": [
      "Agent",
      "",
      "人工智能"
    ]
  },
  {
    "title": "WorldAPIs: The World Is Worth How Many APIs? A Thought Experiment",
    "submit_datetime": "2024年07月10日",
    "abstract": "AI systems make decisions in physical environments through primitive actions or affordances that are accessed via API calls. While deploying AI agents in the real world involves numerous high-level actions, existing embodied simulators offer a limited set of domain-salient APIs. This naturally brings up the questions: how many primitive actions (APIs) are needed for a versatile embodied agent, and what should they look like? We explore this via a thought experiment: assuming that wikiHow tutorials cover a wide variety of human-written tasks, what is the space of APIs needed to cover these instructions? We propose a framework to iteratively induce new APIs by grounding wikiHow instruction to situated agent policies. Inspired by recent successes in large language models (LLMs) for embodied planning, we propose a few-shot prompting to steer GPT-4 to generate Pythonic programs as agent policies and bootstrap a universe of APIs by 1) reusing a seed set of APIs; and then 2) fabricate new API calls when necessary. The focus of this thought experiment is on defining these APIs rather than their executability. We apply the proposed pipeline on instructions from wikiHow tutorials. On a small fraction (0.5%) of tutorials, we induce an action space of 300+ APIs necessary for capturing the rich variety of tasks in the physical world. A detailed automatic and human analysis of the induction output reveals that the proposed pipeline enables effective reuse and creation of APIs. Moreover, a manual review revealed that existing simulators support only a small subset of the induced APIs (9 of the top 50 frequent APIs), motivating the development of action-rich embodied environments.",
    "pdf_link": "https://arxiv.org/abs/2407.07778",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.07778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07778/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07778/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07778/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07778/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07778/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07778/x6.png"
      }
    ],
    "abstract_cn": "AI系统通过API调用的基本动作在现实世界中做决策。然而，现有模拟器提供的API有限，引发了一个问题：多功能代理需要多少API？我们通过思想实验探讨：假设wikiHow涵盖广泛任务，所需的API空间是什么？我们提出框架，通过结合wikiHow指令与代理策略，迭代生成新API。借鉴LLM的成功，我们用少样本提示引导GPT-4生成Python程序，通过重用种子API和必要时创建新API，构建API宇宙。实验重点在于定义API而非执行。我们应用此流程于wikiHow指令，发现0.5%教程需300+API。分析显示，流程有效重用和创建API。审查表明，现有模拟器仅支持部分诱导API，推动了开发丰富动作的具身环境。",
    "title_cn": "WorldAPIs：探寻世界的API价值，一场思想实验之旅",
    "tags": [
      "Agent",
      "人工智能",
      "软件开发"
    ]
  },
  {
    "title": "Teaching Transformers Causal Reasoning through Axiomatic Training",
    "submit_datetime": "2024年07月10日",
    "abstract": "For text-based AI systems to interact in the real world, causal reasoning is an essential skill. Since interventional data is costly to generate, we study to what extent an agent can learn causal reasoning from passive data. Specifically, we consider an axiomatic training setup where an agent learns from multiple demonstrations of a causal axiom (or rule), rather than incorporating the axiom as an inductive bias or inferring it from data values. A key question is whether the agent would learn to generalize from the axiom demonstrations to new scenarios. For example, if a transformer model is trained on demonstrations of the causal transitivity axiom over small graphs, would it generalize to applying the transitivity axiom over large graphs? Our results, based on a novel axiomatic training scheme, indicate that such generalization is possible. We consider the task of inferring whether a variable causes another variable, given a causal graph structure. We find that a 67 million parameter transformer model, when trained on linear causal chains (along with some noisy variations) can generalize well to new kinds of graphs, including longer causal chains, causal chains with reversed order, and graphs with branching; even when it is not explicitly trained for such settings. Our model performs at par (or even better) than many larger language models such as GPT-4, Gemini Pro, and Phi-3. Overall, our axiomatic training framework provides a new paradigm of learning causal reasoning from passive data that can be used to learn arbitrary axioms, as long as sufficient demonstrations can be generated.",
    "pdf_link": "https://arxiv.org/abs/2407.07612",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.07612v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07612/CausalAxioms.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07612v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07612/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07612v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07612/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07612v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07612/Length_generalization_Complex.png"
      }
    ],
    "abstract_cn": "在现实世界中，基于文本的AI系统需要具备因果推理能力。由于生成干预性数据成本高昂，我们探讨了AI代理从被动数据中学习因果推理的潜力。我们采用了一种公理化训练方法，让代理通过观察因果公理的多个实例来学习，而非直接将公理融入模型或从数据中推断。我们的核心问题是，代理能否将这些公理实例泛化应用到新情境中。例如，若一个transformer模型在小型图上学习了因果传递性公理，它能否在大型图上同样适用？我们的研究表明，这种泛化是可行的。我们关注的是在给定因果图结构下，判断变量间的因果关系。实验显示，一个6700万参数的transformer模型，经过线性因果链及相关变体的训练后，能有效泛化至更复杂图结构，包括长链、逆序链及分支图，即便未针对这些情况专门训练。该模型性能与GPT-4、Gemini Pro和Phi-3等大型语言模型不相上下，甚至更优。这一公理化训练框架为从被动数据中学习因果推理开辟了新途径，只要能提供充足的公理实例，即可应用于任意公理的学习。",
    "title_cn": "通过公理化训练，引导 Transformer 掌握因果推理的艺术。",
    "tags": [
      "Agent",
      "人工智能",
      "因果推理"
    ]
  },
  {
    "title": "LLaVA-NeXT-Interleave: Tackling Multi-image, Video, and 3D in Large Multimodal Models",
    "submit_datetime": "2024年07月10日",
    "abstract": "Visual instruction tuning has made considerable strides in enhancing the capabilities of Large Multimodal Models (LMMs). However, existing open LMMs largely focus on single-image tasks, their applications to multi-image scenarios remains less explored. Additionally, prior LMM research separately tackles different scenarios, leaving it impossible to generalize cross scenarios with new emerging capabilities. To this end, we introduce LLaVA-NeXT-Interleave, which simultaneously tackles Multi-image, Multi-frame (video), Multi-view (3D), and Multi-patch (single-image) scenarios in LMMs. To enable these capabilities, we regard the interleaved data format as a general template and compile the M4-Instruct dataset with 1,177.6k samples, spanning 4 primary domains with 14 tasks and 41 datasets. We also curate the LLaVA-Interleave Bench to comprehensively evaluate the multi-image performance of LMMs. Through extensive experiments, LLaVA-NeXT-Interleave achieves leading results in multi-image, video, and 3D benchmarks, while maintaining the performance of single-image tasks. Besides, our model also exhibits several emerging capabilities, e.g., transferring tasks across different settings and modalities. Code is available at https://github.com/LLaVA-VL/LLaVA-NeXT",
    "pdf_link": "https://arxiv.org/abs/2407.07895",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.07895v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07895/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07895v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07895/task_overview.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07895v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07895/pi_data.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07895v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07895/pi_benchmark.png"
      }
    ],
    "abstract_cn": "视觉指令调优大幅提升了大型多模态模型（LMMs）的性能。尽管如此，现有LMMs多聚焦于单图像任务，对多图像场景的应用探索不足。此外，以往研究各自为政，难以实现跨场景能力的新突破。为此，我们推出了LLaVA-NeXT-Interleave，它全面应对LMMs中的多图像、视频、3D及单图像多补丁场景。我们采用交错数据格式作为通用模板，构建了包含1,177.6万样本的M4-Instruct数据集，横跨四大领域、14项任务及41个数据集。同时，我们精心打造了LLaVA-Interleave Bench，全面评估LMMs在多图像场景的表现。实验表明，LLaVA-NeXT-Interleave在多图像、视频和3D领域表现卓越，单图像任务性能亦保持领先。此外，该模型还展现出跨设置和模态的任务转移等新兴能力。代码已开放，详见https://github.com/LLaVA-VL/LLaVA-NeXT。",
    "title_cn": "LLaVA-NeXT-Interleave 技术旨在解决大规模多模态模型中的多图像、视频及3D内容处理问题。",
    "tags": [
      "LLM应用",
      "计算机视觉",
      "人工智能"
    ]
  },
  {
    "title": "AffectGPT: Dataset and Framework for Explainable Multimodal Emotion Recognition",
    "submit_datetime": "2024年07月10日",
    "abstract": "Explainable Multimodal Emotion Recognition (EMER) is an emerging task that aims to achieve reliable and accurate emotion recognition. However, due to the high annotation cost, the existing dataset (denoted as EMER-Fine) is small, making it difficult to perform supervised training. To reduce the annotation cost and expand the dataset size, this paper reviews the previous dataset construction process. Then, we simplify the annotation pipeline, avoid manual checks, and replace the closed-source models with open-source models. Finally, we build \\textbf{EMER-Coarse}, a coarsely-labeled dataset containing large-scale samples. Besides the dataset, we propose a two-stage training framework \\textbf{AffectGPT}. The first stage exploits EMER-Coarse to learn a coarse mapping between multimodal inputs and emotion-related descriptions; the second stage uses EMER-Fine to better align with manually-checked results. Experimental results demonstrate the effectiveness of our proposed method on the challenging EMER task. To facilitate further research, we will make the code and dataset available at: https://github.com/zeroQiaoba/AffectGPT.",
    "pdf_link": "https://arxiv.org/abs/2407.07653",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.07653v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07653/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07653v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07653/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07653v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07653/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07653v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07653/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07653v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07653/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07653v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07653/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07653v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07653/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07653v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07653/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07653v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07653/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07653v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07653/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07653v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07653/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07653v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07653/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07653v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07653/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07653v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07653/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07653v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07653/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07653v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07653/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07653v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07653/x17.png"
      }
    ],
    "abstract_cn": "可解释的多模态情感识别（EMER）旨在实现可靠且准确的情感识别，但高昂的标注成本导致现有数据集（EMER-Fine）规模有限，难以进行有效的监督训练。为此，我们回顾并简化了数据集构建流程，采用开源模型替代闭源模型，成功构建了大规模粗略标注数据集EMER-Coarse。此外，我们提出了两阶段训练框架AffectGPT，第一阶段利用EMER-Coarse进行粗略映射学习，第二阶段结合EMER-Fine以更好地对齐人工检查结果。实验证明，我们的方法在EMER任务上表现出色。为推动后续研究，我们将公开代码和数据集，详情请访问：https://github.com/zeroQiaoba/AffectGPT。",
    "title_cn": "AffectGPT：一个专为可解释多模态情感识别设计的数据集与框架",
    "tags": [
      "LLM应用",
      "情感识别",
      "人工智能"
    ]
  },
  {
    "title": "InstructLayout: Instruction-Driven 2D and 3D Layout Synthesis with Semantic Graph Prior",
    "submit_datetime": "2024年07月10日",
    "abstract": "Comprehending natural language instructions is a charming property for both 2D and 3D layout synthesis systems. Existing methods implicitly model object joint distributions and express object relations, hindering generation's controllability. We introduce InstructLayout, a novel generative framework that integrates a semantic graph prior and a layout decoder to improve controllability and fidelity for 2D and 3D layout synthesis. The proposed semantic graph prior learns layout appearances and object distributions simultaneously, demonstrating versatility across various downstream tasks in a zero-shot manner. To facilitate the benchmarking for text-driven 2D and 3D scene synthesis, we respectively curate two high-quality datasets of layout-instruction pairs from public Internet resources with large language and multimodal models. Extensive experimental results reveal that the proposed method outperforms existing state-of-the-art approaches by a large margin in both 2D and 3D layout synthesis tasks. Thorough ablation studies confirm the efficacy of crucial design components.",
    "pdf_link": "https://arxiv.org/abs/2407.07580",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/1.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/2.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/3.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/4.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/5.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/6.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/1.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/2.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/3.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/4.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/5.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/6.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/1.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/2.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/3.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/4.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/5.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/6.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/atiss_bedroom_430_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/atiss_bedroom_2719_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/atiss_bedroom_6993_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/atiss_bedroom_9404_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/atiss_bedroom_19119_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/diffuscene_bedroom_430_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/diffuscene_bedroom_2719_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/diffuscene_bedroom_6993_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/diffuscene_bedroom_9404_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/diffuscene_bedroom_19119_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/ours_bedroom_430_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/ours_bedroom_2719_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/ours_bedroom_6993_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/ours_bedroom_9404_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/ours_bedroom_19119_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/atiss_livingroom_270_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/atiss_livingroom_9790_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/atiss_livingroom_13599_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/atiss_livingroom_15768_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/atiss_livingroom_21832_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/diffuscene_livingroom_270_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/diffuscene_livingroom_9790_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/diffuscene_livingroom_13599_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/diffuscene_livingroom_15768_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/diffuscene_livingroom_21832_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/ours_livingroom_270_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/ours_livingroom_9790_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/ours_livingroom_13599_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/ours_livingroom_15768_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/ours_livingroom_21832_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x20.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/atiss_diningroom_11628_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/atiss_diningroom_12866_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/atiss_diningroom_15286_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/atiss_diningroom_16628_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/atiss_diningroom_25199_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/diffuscene_diningroom_11628_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/diffuscene_diningroom_12866_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/diffuscene_diningroom_15286_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/diffuscene_diningroom_16628_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/diffuscene_diningroom_25199_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/ours_diningroom_11628_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/ours_diningroom_12866_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/ours_diningroom_15286_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/ours_diningroom_16628_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/ours_diningroom_25199_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x21.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x22.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x23.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x24.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x25.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x26.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x27.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/original_bedroom_7894_000_original.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/original_bedroom_11167_006_original.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/original_bedroom_33296_006_original.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/original_livingroom_629_007_original.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/original_livingroom_1701_006_original.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/original_diningroom_15534_000_original.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/original_diningroom_27430_006_original.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/atiss_bedroom_7894_000.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/atiss_bedroom_11167_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/atiss_bedroom_33296_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/atiss_livingroom_629_007.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/atiss_livingroom_1701_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/atiss_diningroom_15534_000.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/atiss_diningroom_27430_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/diffuscene_bedroom_7894_000.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/diffuscene_bedroom_11167_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/diffuscene_bedroom_33296_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/diffuscene_livingroom_629_007.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/diffuscene_livingroom_1701_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/diffuscene_diningroom_15534_000.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/diffuscene_diningroom_27430_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/ours_bedroom_7894_000.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/ours_bedroom_11167_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/ours_bedroom_33296_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/ours_livingroom_629_007.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/ours_livingroom_1701_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/ours_diningroom_15534_000.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/ours_diningroom_27430_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x28.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x29.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x30.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x31.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x32.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x33.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x34.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/messy_bedroom_860_000_messy.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/messy_bedroom_935_006_messy.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/messy_livingroom_791_006_messy.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/messy_livingroom_1520_000_messy.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/messy_livingroom_13599_006_messy.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/messy_diningroom_758_002_messy.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/messy_diningroom_29864_002_messy.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/atiss_bedroom_860_000.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/atiss_bedroom_935_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/atiss_livingroom_791_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/atiss_livingroom_1520_000.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/atiss_livingroom_13599_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/atiss_diningroom_758_002.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/atiss_diningroom_29864_002.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/diffuscene_bedroom_860_000.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/diffuscene_bedroom_935_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/diffuscene_livingroom_791_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/diffuscene_livingroom_1520_000.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/diffuscene_livingroom_13599_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/diffuscene_diningroom_758_002.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/diffuscene_diningroom_29864_002.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/ours_bedroom_860_000.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/ours_bedroom_935_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/ours_livingroom_791_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/ours_livingroom_1520_000.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/ours_livingroom_13599_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/ours_diningroom_758_002.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/ours_diningroom_29864_002.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x35.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x36.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x37.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x38.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x39.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x40.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x41.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/partial_bedroom_19119_006_partial.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/partial_bedroom_30043_006_partial.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/partial_livingroom_14873_006_partial.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/partial_livingroom_33324_000_partial.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/partial_livingroom_35273_006_partial.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/partial_diningroom_10302_006_partial.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/partial_diningroom_15610_006_partial.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/atiss_bedroom_19119_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/atiss_bedroom_30034_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/atiss_livingroom_14873_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/atiss_livingroom_33324_000.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/atiss_livingroom_35273_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/atiss_diningroom_10302_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/atiss_diningroom_15610_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/diffuscene_bedroom_19119_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/diffuscene_bedroom_30034_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/diffuscene_livingroom_14873_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/diffuscene_livingroom_33324_000.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/diffuscene_livingroom_35273_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/diffuscene_diningroom_10302_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/diffuscene_diningroom_15610_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/ours_bedroom_19119_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/ours_bedroom_30034_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/ours_livingroom_14873_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/ours_livingroom_33324_000.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/ours_livingroom_35273_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/ours_diningroom_10302_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/ours_diningroom_15610_006.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/atiss_bedroom_2719.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/atiss_bedroom_30034.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/atiss_livingroom_248.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/atiss_livingroom_37659.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/atiss_diningroom_33368.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/diffuscene_bedroom_9404.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/diffuscene_bedroom_88719.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/diffuscene_livingroom_48663.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/diffuscene_livingroom_71071.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/diffuscene_diningroom_9790.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/ours_bedroom_11167.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/ours_bedroom_18415.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/ours_livingroom_1520.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/ours_livingroom_84752.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/ours_diningroom_28046.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x42.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x43.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/1.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/1.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/1.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/1.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/1.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x44.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x45.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/2.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/2.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/2.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/2.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/2.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x46.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x47.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/3.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/3.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/3.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/3.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/3.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x48.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x49.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/4.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/4.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/4.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/4.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/4.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x50.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x51.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/5.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/5.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/5.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/5.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/5.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x52.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x53.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/6.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/6.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/6.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/6.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/6.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x54.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x55.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/7.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/7.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/7.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/7.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/7.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x56.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x57.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/8.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/8.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/8.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/8.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/8.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x58.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x59.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/9.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/9.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/9.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/9.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/9.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x60.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x61.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/10.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/10.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/10.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/10.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/10.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x62.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x63.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/11.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/11.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/11.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/11.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/11.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x64.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/x65.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/12.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/12.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/12.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/12.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07580/12.jpg"
      }
    ],
    "abstract_cn": "理解自然语言指令为2D和3D布局合成系统增添了魅力。然而，现有方法通过隐式建模对象关系，限制了生成的可控性。为此，我们推出了InstructLayout框架，该框架结合语义图先验与布局解码器，显著提升了布局合成的可控性与真实感。该框架的语义图先验能同时学习布局特征与对象分布，以零-shot方式灵活应对各类下游任务。此外，我们精心构建了两个高质量数据集，助力文本驱动场景合成的基准测试。实验证明，我们的方法在2D和3D布局合成领域大幅领先现有技术。深入的消融研究也验证了关键设计元素的有效性。",
    "title_cn": "InstructLayout：融合语义图先验的指令驱动二维与三维布局合成技术",
    "tags": [
      "LLM应用",
      "计算机图形学",
      "人工智能"
    ]
  },
  {
    "title": "A Survey of Attacks on Large Vision-Language Models: Resources, Advances, and Future Trends",
    "submit_datetime": "2024年07月10日",
    "abstract": "With the significant development of large models in recent years, Large Vision-Language Models (LVLMs) have demonstrated remarkable capabilities across a wide range of multimodal understanding and reasoning tasks. Compared to traditional Large Language Models (LLMs), LVLMs present great potential and challenges due to its closer proximity to the multi-resource real-world applications and the complexity of multi-modal processing. However, the vulnerability of LVLMs is relatively underexplored, posing potential security risks in daily usage. In this paper, we provide a comprehensive review of the various forms of existing LVLM attacks. Specifically, we first introduce the background of attacks targeting LVLMs, including the attack preliminary, attack challenges, and attack resources. Then, we systematically review the development of LVLM attack methods, such as adversarial attacks that manipulate model outputs, jailbreak attacks that exploit model vulnerabilities for unauthorized actions, prompt injection attacks that engineer the prompt type and pattern, and data poisoning that affects model training. Finally, we discuss promising research directions in the future. We believe that our survey provides insights into the current landscape of LVLM vulnerabilities, inspiring more researchers to explore and mitigate potential safety issues in LVLM developments. The latest papers on LVLM attacks are continuously collected in https://github.com/liudaizong/Awesome-LVLM-Attack.",
    "pdf_link": "https://arxiv.org/abs/2407.07403",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.07403v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07403/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07403v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07403/x2.png"
      }
    ],
    "abstract_cn": "随着大型模型的快速发展，大型视觉-语言模型（LVLMs）在跨模态理解和推理任务中表现出色。与传统LLMs相比，LVLMs因更贴近现实多资源应用和复杂的多模态处理而充满潜力与挑战。但其脆弱性尚未充分研究，日常使用中潜藏安全风险。本文全面梳理了LVLM攻击的多种形式，从攻击背景到方法发展，再到未来研究方向，旨在揭示LVLM漏洞现状，激发更多研究关注并解决LVLM发展中的安全问题。最新LVLM攻击论文持续更新于https://github.com/liudaizong/Awesome-LVLM-Attack。",
    "title_cn": "大型视觉-语言模型面临的攻击：资源、进展与未来展望",
    "tags": [
      "LLM应用",
      "计算机视觉",
      "网络安全"
    ]
  },
  {
    "title": "Training on the Test Task Confounds Evaluation and Emergence",
    "submit_datetime": "2024年07月10日",
    "abstract": "We study a fundamental problem in the evaluation of large language models that we call training on the test task. Unlike wrongful practices like training on the test data, leakage, or data contamination, training on the test task is not a malpractice. Rather, the term describes a growing set of techniques to include task-relevant data in the pretraining stage of a language model. We demonstrate that training on the test task confounds both relative model evaluations and claims about emergent capabilities. We argue that the seeming superiority of one model family over another may be explained by a different degree of training on the test task. To this end, we propose an effective method to adjust for training on the test task by fine-tuning each model under comparison on the same task-relevant data before evaluation. We then show that instances of emergent behavior largely vanish once we adjust for training on the test task. This also applies to reported instances of emergent behavior that cannot be explained by the choice of evaluation metric. Our work promotes a new perspective on the evaluation of large language models with broad implications for benchmarking and the study of emergent capabilities.",
    "pdf_link": "https://arxiv.org/abs/2407.07890",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.07890v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07890/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07890v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07890/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07890v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07890/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07890v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07890/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07890v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07890/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07890v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07890/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07890v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07890/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07890v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07890/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07890v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07890/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07890v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07890/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07890v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07890/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07890v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07890/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07890v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07890/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07890v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07890/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07890v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07890/x15.png"
      }
    ],
    "abstract_cn": "我们探讨了一个大型语言模型评估中的核心问题——“测试任务训练”。这一概念并非指不当行为，而是描述了在预训练阶段融入任务相关数据的一系列技术。我们发现，这种做法可能扭曲模型间的相对评估和涌现能力的判断。为此，我们提出了一种方法，通过在相同任务数据上微调模型，以校正“测试任务训练”的影响。结果显示，调整后，许多所谓的涌现行为现象显著减少，甚至包括那些无法仅通过评估指标解释的情况。我们的研究为大型语言模型的评估带来了新的视角，对基准制定和涌现能力研究具有深远影响。",
    "title_cn": "在测试任务上训练，评估与结果的混淆随之而来。",
    "tags": [
      "LLM理论",
      "人工智能",
      "软件工程"
    ]
  },
  {
    "title": "Towards Robust Alignment of Language Models: Distributionally Robustifying Direct Preference Optimization",
    "submit_datetime": "2024年07月10日",
    "abstract": "This study addresses the challenge of noise in training datasets for Direct Preference Optimization (DPO), a method for aligning Large Language Models (LLMs) with human preferences. We categorize noise into pointwise noise, which includes low-quality data points, and pairwise noise, which encompasses erroneous data pair associations that affect preference rankings. Utilizing Distributionally Robust Optimization (DRO), we enhance DPO's resilience to these types of noise. Our theoretical insights reveal that DPO inherently embeds DRO principles, conferring robustness to pointwise noise, with the regularization coefficient $β$ playing a critical role in its noise resistance. Extending this framework, we introduce Distributionally Robustifying DPO (Dr. DPO), which integrates pairwise robustness by optimizing against worst-case pairwise scenarios. The novel hyperparameter $β'$ in Dr. DPO allows for fine-tuned control over data pair reliability, providing a strategic balance between exploration and exploitation in noisy training environments. Empirical evaluations demonstrate that Dr. DPO substantially improves the quality of generated text and response accuracy in preference datasets, showcasing enhanced performance in both noisy and noise-free settings. The code is available at https://github.com/junkangwu/Dr_DPO.",
    "pdf_link": "https://arxiv.org/abs/2407.07880",
    "graphs": [],
    "abstract_cn": "本研究针对DPO训练数据集中的噪声问题，提出了一种增强LLM与人类偏好对齐的方法。我们区分了点态噪声和成对噪声，并利用DRO技术提升DPO的抗噪能力。理论分析表明，DPO天然具备DRO特性，特别是正则化系数$β$对抗噪至关重要。进一步，我们创新性地提出了Dr. DPO，通过优化最差成对情况，增强成对鲁棒性。Dr. DPO中的$β'$参数精细调控数据对可靠性，实现噪声环境下的探索与利用平衡。实证结果显示，Dr. DPO在各类环境下均显著提升文本质量和响应准确性。相关代码已公开于https://github.com/junkangwu/Dr_DPO。",
    "title_cn": "致力于提升语言模型的对齐稳健性：通过分布式稳健化方法优化直接偏好",
    "tags": [
      "LLM理论",
      "人工智能",
      ""
    ]
  },
  {
    "title": "OpenDiLoCo: An Open-Source Framework for Globally Distributed Low-Communication Training",
    "submit_datetime": "2024年07月10日",
    "abstract": "OpenDiLoCo is an open-source implementation and replication of the Distributed Low-Communication (DiLoCo) training method for large language models. We provide a reproducible implementation of the DiLoCo experiments, offering it within a scalable, decentralized training framework using the Hivemind library. We demonstrate its effectiveness by training a model across two continents and three countries, while maintaining 90-95% compute utilization. Additionally, we conduct ablations studies focusing on the algorithm's compute efficiency, scalability in the number of workers and show that its gradients can be all-reduced using FP16 without any performance degradation. Furthermore, we scale OpenDiLoCo to 3x the size of the original work, demonstrating its effectiveness for billion parameter models.",
    "pdf_link": "https://arxiv.org/abs/2407.07852",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.07852v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07852/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07852v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07852/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07852v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07852/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07852v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07852/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07852v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07852/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07852v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07852/connection-speeds-decentralized-training.drawio.png"
      }
    ],
    "abstract_cn": "OpenDiLoCo 是一个开源项目，旨在实现和复现用于大型语言模型的 Distributed Low-Communication (DiLoCo) 训练方法。我们提供了一个基于 Hivemind 库的可扩展、去中心化训练框架中的 DiLoCo 实验可复现实现。通过在跨越两大洲和三国的环境中训练模型，并保持高达 95% 的计算利用率，我们验证了其高效性。此外，我们的消融研究深入探讨了算法的计算效率和工作者的可扩展性，并证实了使用 FP16 进行梯度全减少的可行性，不会影响性能。最后，我们将 OpenDiLoCo 规模扩大至原始工作的三倍，充分展示了其对处理十亿参数模型的能力。",
    "title_cn": "OpenDiLoCo：一款开源框架，专为全球分布式低通信训练设计。",
    "tags": [
      "LLM应用",
      "人工智能",
      "开源项目"
    ]
  },
  {
    "title": "OV-DINO: Unified Open-Vocabulary Detection with Language-Aware Selective Fusion",
    "submit_datetime": "2024年07月10日",
    "abstract": "Open-vocabulary detection is a challenging task due to the requirement of detecting objects based on class names, including those not encountered during training. Existing methods have shown strong zero-shot detection capabilities through pre-training on diverse large-scale datasets. However, these approaches still face two primary challenges: (i) how to universally integrate diverse data sources for end-to-end training, and (ii) how to effectively leverage the language-aware capability for region-level cross-modality understanding. To address these challenges, we propose a novel unified open-vocabulary detection method called OV-DINO, which pre-trains on diverse large-scale datasets with language-aware selective fusion in a unified framework. Specifically, we introduce a Unified Data Integration (UniDI) pipeline to enable end-to-end training and eliminate noise from pseudo-label generation by unifying different data sources into detection-centric data. In addition, we propose a Language-Aware Selective Fusion (LASF) module to enable the language-aware ability of the model through a language-aware query selection and fusion process. We evaluate the performance of the proposed OV-DINO on popular open-vocabulary detection benchmark datasets, achieving state-of-the-art results with an AP of 50.6\\% on the COCO dataset and 40.0\\% on the LVIS dataset in a zero-shot manner, demonstrating its strong generalization ability. Furthermore, the fine-tuned OV-DINO on COCO achieves 58.4\\% AP, outperforming many existing methods with the same backbone. The code for OV-DINO will be available at \\href{https://github.com/wanghao9610/OV-DINO}{https://github.com/wanghao9610/OV-DINO}.",
    "pdf_link": "https://arxiv.org/abs/2407.07844",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.07844v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07844/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07844v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07844/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07844v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07844/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07844v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07844/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07844v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07844/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07844v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07844/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07844v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07844/x7.png"
      }
    ],
    "abstract_cn": "开放词汇检测因其需根据类别名称识别未见过的物体而颇具挑战。现有技术虽通过广泛预训练展现零-shot检测实力，但仍需克服两大难题：整合多元数据源进行端到端训练，以及运用语言感知力深化区域级跨模态理解。为此，我们创新推出OV-DINO方法，通过语言感知融合在统一框架下预训练于多样大数据集。我们设计了UniDI流水线，实现数据源整合，净化伪标签噪声，聚焦检测核心。同时，LASF模块通过语言感知查询与融合，强化模型语言理解力。OV-DINO在COCO与LVIS数据集上以零-shot模式创下佳绩，彰显其卓越泛化性。微调后，其在COCO上更以58.4%的AP超越众多同类方法。OV-DINO代码即将在\\href{https://github.com/wanghao9610/OV-DINO}{GitHub}发布。",
    "title_cn": "OV-DINO：结合语言感知选择性融合的统一开放词汇检测技术",
    "tags": [
      "LLM应用",
      "计算机视觉",
      "机器学习"
    ]
  },
  {
    "title": "Transformer Alignment in Large Language Models",
    "submit_datetime": "2024年07月10日",
    "abstract": "Large Language Models (LLMs) have made significant strides in natural language processing, and a precise understanding of the internal mechanisms driving their success is essential. We regard LLMs as transforming embeddings via a discrete, coupled, nonlinear, dynamical system in high dimensions. This perspective motivates tracing the trajectories of individual tokens as they pass through transformer blocks, and linearizing the system along these trajectories through their Jacobian matrices. In our analysis of 38 openly available LLMs, we uncover the alignment of top left and right singular vectors of Residual Jacobians, as well as the emergence of linearity and layer-wise exponential growth. Notably, we discover that increased alignment $\\textit{positively correlates}$ with model performance. Metrics evaluated post-training show significant improvement in comparison to measurements made with randomly initialized weights, highlighting the significant effects of training in transformers. These findings reveal a remarkable level of regularity that has previously been overlooked, reinforcing the dynamical interpretation and paving the way for deeper understanding and optimization of LLM architectures.",
    "pdf_link": "https://arxiv.org/abs/2407.07810",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.07810v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07810/align_scatter_all.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07810v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07810/LSS.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07810v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07810/expodistance.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07810v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07810/expodistance_untrained.png"
      }
    ],
    "abstract_cn": "大型语言模型 (LLMs) 在自然语言处理领域取得了显著成就，深入理解其内部运作机制至关重要。我们将 LLMs 视为高维离散、耦合、非线性动力学系统中的嵌入转换。这一视角促使我们追踪单个令牌在通过转换器块时的轨迹，并通过雅可比矩阵沿这些轨迹线性化系统。通过对 38 个公开可用的 LLMs 的分析，我们发现了残差雅可比矩阵的左上和右上奇异向量的对齐，以及线性和层级指数增长的涌现。特别地，我们发现对齐程度的增加与模型性能呈正相关。训练后评估的指标显示，与随机初始化权重相比，有显著提升，凸显了训练在转换器中的重要影响。这些发现揭示了一个先前被忽视的显著规律性，强化了动力学解释，并为更深入理解和优化 LLM 架构开辟了道路。",
    "title_cn": "大规模语言模型中的 Transformer 对齐",
    "tags": [
      "LLM理论",
      "",
      "机器学习"
    ]
  },
  {
    "title": "ROSA: Random Subspace Adaptation for Efficient Fine-Tuning",
    "submit_datetime": "2024年07月10日",
    "abstract": "Model training requires significantly more memory, compared with inference. Parameter efficient fine-tuning (PEFT) methods provide a means of adapting large models to downstream tasks using less memory. However, existing methods such as adapters, prompt tuning or low-rank adaptation (LoRA) either introduce latency overhead at inference time or achieve subpar downstream performance compared with full fine-tuning. In this work we propose Random Subspace Adaptation (ROSA), a method that outperforms previous PEFT methods by a significant margin, while maintaining a zero latency overhead during inference time. In contrast to previous methods, ROSA is able to adapt subspaces of arbitrarily large dimension, better approximating full-finetuning. We demonstrate both theoretically and experimentally that this makes ROSA strictly more expressive than LoRA, without consuming additional memory during runtime. As PEFT methods are especially useful in the natural language processing domain, where models operate on scales that make full fine-tuning very expensive, we evaluate ROSA in two common NLP scenarios: natural language generation (NLG) and natural language understanding (NLU) with GPT-2 and RoBERTa, respectively. We show that on almost every GLUE task ROSA outperforms LoRA by a significant margin, while also outperforming LoRA on NLG tasks. Our code is available at https://github.com/rosa-paper/rosa",
    "pdf_link": "https://arxiv.org/abs/2407.07802",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.07802v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07802/synthetic_e500_b64_p0.001_f0.004_nadamw_narosa_vs_lora_t24_pe8_pef2_fa24_fac4_namlinear_h64_biFalse.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07802v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07802/synthetic_e1000_b64_p0.001_f0.003_nadamw_narosa_vs_lora_t24_pe8_pef2_fa24_fac4_nammlp2_h64_biFalse.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07802v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07802/rosa_vs_lora_cola_base_convergence_train_loss_cola.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07802v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07802/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07802v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07802/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07802v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07802/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07802v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07802/x4.png"
      }
    ],
    "abstract_cn": "模型训练所需的内存远超推理。参数高效微调（PEFT）方法通过减少内存使用，帮助大型模型适应下游任务。然而，现有方法如适配器、提示调优或低秩适应（LoRA）要么在推理时增加延迟，要么在性能上不及全量微调。我们提出的随机子空间适应（ROSA）方法，不仅在性能上大幅超越以往PEFT方法，且在推理时无额外延迟。ROSA能适应任意大小的子空间，更接近全量微调的效果。理论与实验均证明，ROSA在运行时无需额外内存，表达力却强于LoRA。在自然语言处理领域，全量微调成本高昂，我们在NLG和NLU任务中使用GPT-2和RoBERTa评估ROSA，结果显示ROSA在GLUE任务和NLG任务中均显著优于LoRA。代码已公开在https://github.com/rosa-paper/rosa。",
    "title_cn": "ROSA：通过随机子空间适应实现高效微调",
    "tags": [
      "LLM理论",
      "",
      "机器学习"
    ]
  },
  {
    "title": "Attribute or Abstain: Large Language Models as Long Document Assistants",
    "submit_datetime": "2024年07月10日",
    "abstract": "LLMs can help humans working with long documents, but are known to hallucinate. Attribution can increase trust in LLM responses: The LLM provides evidence that supports its response, which enhances verifiability. Existing approaches to attribution have only been evaluated in RAG settings, where the initial retrieval confounds LLM performance. This is crucially different from the long document setting, where retrieval is not needed, but could help. Thus, a long document specific evaluation of attribution is missing. To fill this gap, we present LAB, a benchmark of 6 diverse long document tasks with attribution, and experiment with different approaches to attribution on 4 LLMs of different sizes, both prompted and fine-tuned. We find that citation, i.e. response generation and evidence extraction in one step, mostly performs best. We investigate whether the ``Lost in the Middle'' phenomenon exists for attribution, but do not find this. We also find that evidence quality can predict response quality on datasets with simple responses, but not so for complex responses, as models struggle with providing evidence for complex claims. We release code and data for further investigation.",
    "pdf_link": "https://arxiv.org/abs/2407.07799",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.07799v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07799/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07799v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07799/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07799v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07799/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07799v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07799/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07799v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07799/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07799v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07799/x7.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLM）虽能辅助长文档处理，但常产生不实信息。通过归因，即LLM提供支持其回答的证据，可增强其回答的可信度。然而，现有归因方法仅在RAG环境下评估，未考虑长文档场景，其中无需检索。为此，我们推出LAB基准，涵盖6项长文档任务，并测试4种不同规模LLM的归因方法，包括提示与微调。实验显示，“引用”策略（一步完成回答与证据提取）效果最佳。我们还探讨了归因中的“中间迷失”现象，未见其存在。此外，证据质量能预测简单回答的优劣，但对复杂回答则不然，因模型难以提供复杂声明的证据。我们公开了相关代码与数据，供后续深入研究。",
    "title_cn": "大型语言模型：长文档的得力助手还是选择放弃？",
    "tags": [
      "LLM应用",
      "文档处理",
      "人工智能"
    ]
  },
  {
    "title": "Evaluating Large Language Models with Grid-Based Game Competitions: An Extensible LLM Benchmark and Leaderboard",
    "submit_datetime": "2024年07月10日",
    "abstract": "We introduce a novel and extensible benchmark for large language models (LLMs) through grid-based games such as Tic-Tac-Toe, Connect-Four, and Gomoku. The open-source game simulation code, available on GitHub, allows LLMs to compete and generates detailed data files in JSON, CSV, TXT, and PNG formats for leaderboard rankings and further analysis. We present the results of games among leading LLMs, including Claude 3.5 Sonnet and Claude 3 Sonnet by Anthropic, Gemini 1.5 Pro and Gemini 1.5 Flash by Google, GPT-4 Turbo and GPT-4o by OpenAI, and Llama3-70B by Meta. We also encourage submissions of results from other LLMs. In total, we simulated 2,310 matches (5 sessions for each pair among 7 LLMs and a random player) across three types of games, using three distinct prompt types: list, illustration, and image. The results revealed significant variations in LLM performance across different games and prompt types, with analysis covering win and disqualification rates, missed opportunity analysis, and invalid move analysis. The details of the leaderboard and result matrix data are available as open-access data on GitHub. This study enhances our understanding of LLMs' capabilities in playing games they were not specifically trained for, helping to assess their rule comprehension and strategic thinking. On the path to Artificial General Intelligence (AGI), this study lays the groundwork for future exploration into their utility in complex decision-making scenarios, illuminating their strategic thinking abilities and offering directions for further inquiry into the limits of LLMs within game-based frameworks.",
    "pdf_link": "https://arxiv.org/abs/2407.07796",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.07796v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07796/GameSimulationUI-Connect4.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07796v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07796/App-Web-Interaction.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07796v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07796/TicTacToe-list.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07796v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07796/TicTacToe-illustration.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07796v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07796/TicTacToe-image.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07796v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07796/Connect4-list.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07796v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07796/Connect4-illustration.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07796v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07796/Connect4-image.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07796v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07796/Gomoku-list.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07796v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07796/Gomoku-illustration.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07796v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07796/Gomoku-image.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07796v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07796/TicTacToe-TotalInvalidMoves.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07796v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07796/Connect4-TotalInvalidMoves.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07796v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07796/Gomoku-TotalInvalidMoves.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07796v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07796/OpportunityMissed-PerGame-TicTacToe.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07796v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07796/OpportunityMissed-PerValid-TicTacToe.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07796v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07796/OpportunityMissed-PerGame-ConnectFour.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07796v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07796/OpportunityMissed-PerValid-ConnectFour.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07796v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07796/OpportunityMissed-PerGame-Gomoku.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07796v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07796/OpportunityMissed-PerValid-Gomoku.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07796v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07796/ResultsMatrix-TicTacToe.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07796v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07796/ResultsMatrix-Connect4.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07796v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07796/ResultsMatrix-Gomoku.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.07796v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07796/Leaderboard-AgregatedByLLM1.jpg"
      }
    ],
    "abstract_cn": "我们为大型语言模型（LLM）创建了一个新颖且可扩展的基准，通过井字棋、四子棋和五子棋等网格游戏进行测试。开源的游戏模拟代码可在GitHub上获取，支持LLM竞争，并生成用于排行榜和分析的详细数据文件。我们展示了包括Anthropic、Google、OpenAI和Meta在内的领先LLM之间的游戏结果。总共模拟了2,310场比赛，涉及三种游戏和三种提示类型。结果显示LLM在不同游戏和提示类型中的表现差异显著，详细分析了胜率、淘汰率、错失机会和无效移动。排行榜和结果数据的详细信息已在GitHub上公开。这项研究加深了我们对LLM在未专门训练的游戏中能力的理解，评估了其规则理解和战略思维。在追求人工通用智能（AGI）的道路上，这项研究为探索LLM在复杂决策场景中的应用奠定了基础，揭示了其战略思维能力，并为未来研究提供了方向。",
    "title_cn": "通过基于网格的游戏竞赛评估大型语言模型：打造一个可扩展的 LLM 基准与排行榜",
    "tags": [
      "LLM应用",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Can ChatGPT Pass a Theory of Computing Course?",
    "submit_datetime": "2024年07月10日",
    "abstract": "Large Language Models (LLMs) have had considerable difficulty when prompted with mathematical questions, especially those within theory of computing (ToC) courses. In this paper, we detail two experiments regarding our own ToC course and the ChatGPT LLM. For the first, we evaluated ChatGPT's ability to pass our own ToC course's exams. For the second, we created a database of sample ToC questions and responses to accommodate other ToC offerings' choices for topics and structure. We scored each of ChatGPT's outputs on these questions. Overall, we determined that ChatGPT can pass our ToC course, and is adequate at understanding common formal definitions and answering \"simple\"-style questions, e.g., true/false and multiple choice. However, ChatGPT often makes nonsensical claims in open-ended responses, such as proofs.",
    "pdf_link": "https://arxiv.org/abs/2407.07757",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.07757v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07757/NFA.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07757v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07757/table1.png"
      }
    ],
    "abstract_cn": "大型语言模型在处理数学问题，尤其是计算理论课程中的问题时，表现不佳。本文通过两个实验，探讨了 ChatGPT 在 ToC 课程中的表现。首先，我们测试了 ChatGPT 通过 ToC 考试的能力；其次，我们构建了一个 ToC 问题数据库，以便其他课程参考。实验结果显示，ChatGPT 能通过 ToC 考试，擅长处理选择题等基础题型，但在开放式证明题中常出现逻辑错误。",
    "title_cn": "ChatGPT 能否在计算理论课程中取得及格？",
    "tags": [
      "LLM应用",
      "",
      "计算机科学"
    ]
  },
  {
    "title": "Fine-Tuning Large Language Models with User-Level Differential Privacy",
    "submit_datetime": "2024年07月10日",
    "abstract": "We investigate practical and scalable algorithms for training large language models (LLMs) with user-level differential privacy (DP) in order to provably safeguard all the examples contributed by each user. We study two variants of DP-SGD with: (1) example-level sampling (ELS) and per-example gradient clipping, and (2) user-level sampling (ULS) and per-user gradient clipping. We derive a novel user-level DP accountant that allows us to compute provably tight privacy guarantees for ELS. Using this, we show that while ELS can outperform ULS in specific settings, ULS generally yields better results when each user has a diverse collection of examples. We validate our findings through experiments in synthetic mean estimation and LLM fine-tuning tasks under fixed compute budgets. We find that ULS is significantly better in settings where either (1) strong privacy guarantees are required, or (2) the compute budget is large. Notably, our focus on LLM-compatible training algorithms allows us to scale to models with hundreds of millions of parameters and datasets with hundreds of thousands of users.",
    "pdf_link": "https://arxiv.org/abs/2407.07737",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.07737v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07737/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07737v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07737/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07737v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07737/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07737v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07737/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07737v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07737/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07737v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07737/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07737v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07737/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07737v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07737/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07737v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07737/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07737v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07737/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07737v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07737/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07737v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07737/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07737v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07737/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07737v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07737/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07737v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07737/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07737v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07737/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07737v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07737/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07737v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07737/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07737v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07737/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07737v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07737/x20.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07737v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07737/x21.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07737v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07737/x22.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07737v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07737/x23.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07737v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07737/x24.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07737v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07737/x25.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07737v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07737/x26.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07737v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07737/x27.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07737v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07737/x28.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07737v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07737/x29.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07737v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07737/x30.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07737v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07737/x31.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07737v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07737/x32.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07737v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07737/x33.png"
      }
    ],
    "abstract_cn": "我们探索了结合用户级差分隐私的实用且可扩展的 LLM 训练算法，旨在保护每位用户的所有贡献。我们分析了两种 DP-SGD 变体：示例级采样与梯度裁剪，以及用户级采样与梯度裁剪。我们创新地提出了用户级 DP 会计方法，为示例级采样提供了严格的隐私保障。实验表明，尽管在特定场景下示例级采样可能更优，但用户级采样在用户示例多样性高时表现更佳。通过在固定计算资源下的合成均值估计和 LLM 微调任务中验证，我们发现用户级采样在强隐私需求或高计算预算环境下显著占优。我们的研究重点在于与 LLM 兼容的训练算法，能够支持数亿参数的模型和数十万用户的规模。",
    "title_cn": "针对大型语言模型进行微调，同时确保用户级差分隐私。",
    "tags": [
      "LLM理论",
      "人工智能",
      "隐私保护"
    ]
  },
  {
    "title": "A Proposed S.C.O.R.E. Evaluation Framework for Large Language Models : Safety, Consensus, Objectivity, Reproducibility and Explainability",
    "submit_datetime": "2024年07月10日",
    "abstract": "A comprehensive qualitative evaluation framework for large language models (LLM) in healthcare that expands beyond traditional accuracy and quantitative metrics needed. We propose 5 key aspects for evaluation of LLMs: Safety, Consensus, Objectivity, Reproducibility and Explainability (S.C.O.R.E.). We suggest that S.C.O.R.E. may form the basis for an evaluation framework for future LLM-based models that are safe, reliable, trustworthy, and ethical for healthcare and clinical applications.",
    "pdf_link": "https://arxiv.org/abs/2407.07666",
    "graphs": [],
    "abstract_cn": "在医疗领域，我们需要一个超越传统量化指标的全面评估框架来审视大型语言模型 (LLM)。为此，我们提出了五个评估维度：安全性、共识性、客观性、可重复性和可解释性 (S.C.O.R.E.)。我们相信，S.C.O.R.E. 将成为未来医疗用 LLM 模型评估的基石，确保其在临床应用中的安全、可靠、可信与伦理合规。",
    "title_cn": "我们提出了一种名为 S.C.O.R.E. 的评估框架，旨在从安全性、共识、客观性、可重复性和可解释性五个维度全面评估大型语言模型。",
    "tags": [
      "LLM理论",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Tuning Vision-Language Models with Candidate Labels by Prompt Alignment",
    "submit_datetime": "2024年07月10日",
    "abstract": "Vision-language models (VLMs) can learn high-quality representations from a large-scale training dataset of image-text pairs. Prompt learning is a popular approach to fine-tuning VLM to adapt them to downstream tasks. Despite the satisfying performance, a major limitation of prompt learning is the demand for labelled data. In real-world scenarios, we may only obtain candidate labels (where the true label is included) instead of the true labels due to data privacy or sensitivity issues. In this paper, we provide the first study on prompt learning with candidate labels for VLMs. We empirically demonstrate that prompt learning is more advantageous than other fine-tuning methods, for handling candidate labels. Nonetheless, its performance drops when the label ambiguity increases. In order to improve its robustness, we propose a simple yet effective framework that better leverages the prior knowledge of VLMs to guide the learning process with candidate labels. Specifically, our framework disambiguates candidate labels by aligning the model output with the mixed class posterior jointly predicted by both the learnable and the handcrafted prompt. Besides, our framework can be equipped with various off-the-shelf training objectives for learning with candidate labels to further improve their performance. Extensive experiments demonstrate the effectiveness of our proposed framework.",
    "pdf_link": "https://arxiv.org/abs/2407.07638",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.07638v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07638/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07638v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07638/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07638v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07638/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07638v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07638/x4.png"
      }
    ],
    "abstract_cn": "视觉-语言模型 (VLMs) 能从海量图像-文本对中提炼出高质量表示。提示学习，作为微调 VLM 以适应特定任务的热门手段，虽表现出色，却受限于对标注数据的依赖。现实中，数据隐私或敏感性常使我们仅能触及候选标签而非真实标签。本文首开先河，探讨了 VLMs 在候选标签下的提示学习。实证显示，面对候选标签，提示学习优于其他微调策略，但标签歧义加剧时性能下滑。为此，我们设计了一个简洁高效的框架，巧妙运用 VLMs 的先验知识，以候选标签引领学习之旅。该框架通过模型输出与混合类别后验的精准对齐，消解标签歧义，并兼容多样化的训练目标，助力候选标签学习，进一步提升性能。实验广泛验证了这一框架的卓越成效。",
    "title_cn": "通过提示对齐优化候选标签的视觉-语言模型",
    "tags": [
      "LLM应用",
      "计算机视觉",
      ""
    ]
  },
  {
    "title": "A Review of the Challenges with Massive Web-mined Corpora Used in Large Language Models Pre-Training",
    "submit_datetime": "2024年07月10日",
    "abstract": "This article presents a comprehensive review of the challenges associated with using massive web-mined corpora for the pre-training of large language models (LLMs). This review identifies key challenges in this domain, including challenges such as noise (irrelevant or misleading information), duplication of content, the presence of low-quality or incorrect information, biases, and the inclusion of sensitive or personal information in web-mined corpora. Addressing these issues is crucial for the development of accurate, reliable, and ethically responsible language models. Through an examination of current methodologies for data cleaning, pre-processing, bias detection and mitigation, we highlight the gaps in existing approaches and suggest directions for future research. Our discussion aims to catalyze advancements in developing more sophisticated and ethically responsible LLMs.",
    "pdf_link": "https://arxiv.org/abs/2407.07630",
    "graphs": [],
    "abstract_cn": "本文全面探讨了利用网络挖掘的大规模语料库进行 LLM 预训练时遇到的难题，如噪声、内容重复、信息质量低下、偏见及敏感个人信息的包含等。解决这些挑战对于构建准确、可靠且符合伦理的语言模型至关重要。我们通过分析现有的数据处理和偏见管理技术，指出了现有方法的不足，并提出了未来研究的方向，旨在推动更先进、更符合伦理的 LLM 的发展。",
    "title_cn": "大规模网络挖掘语料库在大型语言模型预训练中的挑战概览",
    "tags": [
      "LLM理论",
      "人工智能",
      "网络安全"
    ]
  },
  {
    "title": "IDA-VLM: Towards Movie Understanding via ID-Aware Large Vision-Language Model",
    "submit_datetime": "2024年07月10日",
    "abstract": "The rapid advancement of Large Vision-Language models (LVLMs) has demonstrated a spectrum of emergent capabilities. Nevertheless, current models only focus on the visual content of a single scenario, while their ability to associate instances across different scenes has not yet been explored, which is essential for understanding complex visual content, such as movies with multiple characters and intricate plots. Towards movie understanding, a critical initial step for LVLMs is to unleash the potential of character identities memory and recognition across multiple visual scenarios. To achieve the goal, we propose visual instruction tuning with ID reference and develop an ID-Aware Large Vision-Language Model, IDA-VLM. Furthermore, our research introduces a novel benchmark MM-ID, to examine LVLMs on instance IDs memory and recognition across four dimensions: matching, location, question-answering, and captioning. Our findings highlight the limitations of existing LVLMs in recognizing and associating instance identities with ID reference. This paper paves the way for future artificial intelligence systems to possess multi-identity visual inputs, thereby facilitating the comprehension of complex visual narratives like movies.",
    "pdf_link": "https://arxiv.org/abs/2407.07577",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.07577v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07577/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07577v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07577/framework.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07577v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07577/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07577v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07577/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07577v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07577/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07577v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07577/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07577v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07577/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07577v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07577/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07577v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07577/x8.png"
      }
    ],
    "abstract_cn": "随着大型视觉-语言模型（LVLMs）的迅猛发展，一系列新兴能力得以展现。然而，这些模型目前仅限于分析单一情景的视觉内容，对于跨场景实例关联的能力尚未开发，这对理解复杂视觉内容如电影至关重要。为了深入电影理解，LVLMs需首先提升跨场景角色身份的记忆与识别能力。为此，我们提出ID参考的视觉指令调整，并创新开发了IDA-VLM模型。同时，我们引入了MM-ID基准，从匹配、定位、问答和字幕四个维度全面评估LVLMs的实例ID处理能力。研究揭示了现有模型在ID参考下识别与关联实例的不足。本文为未来AI系统处理多身份视觉输入奠定了基础，助力复杂视觉叙事如电影的深入理解。",
    "title_cn": "IDA-VLM：借助 ID-Aware 大型视觉-语言模型，迈向电影深度理解",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "HebDB: a Weakly Supervised Dataset for Hebrew Speech Processing",
    "submit_datetime": "2024年07月10日",
    "abstract": "We present HebDB, a weakly supervised dataset for spoken language processing in the Hebrew language. HebDB offers roughly 2500 hours of natural and spontaneous speech recordings in the Hebrew language, consisting of a large variety of speakers and topics. We provide raw recordings together with a pre-processed, weakly supervised, and filtered version. The goal of HebDB is to further enhance research and development of spoken language processing tools for the Hebrew language. Hence, we additionally provide two baseline systems for Automatic Speech Recognition (ASR): (i) a self-supervised model; and (ii) a fully supervised model. We present the performance of these two methods optimized on HebDB and compare them to current multi-lingual ASR alternatives. Results suggest the proposed method reaches better results than the evaluated baselines considering similar model sizes. Dataset, code, and models are publicly available under https://pages.cs.huji.ac.il/adiyoss-lab/HebDB/.",
    "pdf_link": "https://arxiv.org/abs/2407.07566",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.07566v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07566/df_hist.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07566v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07566/preprocessed_data_and_text_boxplot.png"
      }
    ],
    "abstract_cn": "我们推出了 HebDB，一个专为希伯来语口语处理设计的弱监督数据集，收录了约 2500 小时自然即兴的语音资料，涵盖多样化的说话者和话题。该数据集不仅提供原始音频，还包括预处理和过滤版本，旨在推动希伯来语口语处理技术的研究与开发。此外，我们构建了两个 ASR 基准系统：一是自监督模型，二是全监督模型，并在 HebDB 上对其性能进行了优化，与现有多语言 ASR 方案进行了对比。结果显示，在同等模型规模下，我们的方法性能更优。所有资源均已公开，访问地址为 https://pages.cs.huji.ac.il/adiyoss-lab/HebDB/。",
    "title_cn": "HebDB：专为希伯来语语音处理设计的弱监督数据集",
    "tags": [
      "LLM应用",
      "语音处理",
      ""
    ]
  },
  {
    "title": "On Leakage of Code Generation Evaluation Datasets",
    "submit_datetime": "2024年07月10日",
    "abstract": "In this paper we consider contamination by code generation test sets, in particular in their use in modern large language models. We discuss three possible sources of such contamination and show findings supporting each of them: (i) direct data leakage, (ii) indirect data leakage through the use of synthetic data and (iii) overfitting to evaluation sets during model selection.\n  Key to our findings is a new dataset of 161 prompts with their associated python solutions, dataset which is released at https://huggingface.co/datasets/CohereForAI/lbpp .",
    "pdf_link": "https://arxiv.org/abs/2407.07565",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.07565v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07565/humaneval.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07565v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07565/mbpp.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07565v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07565/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07565v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07565/x2.png"
      }
    ],
    "abstract_cn": "本文探讨了代码生成测试集在现代大型语言模型中的污染问题，并揭示了三种污染源：直接数据泄露、合成数据引发的间接泄露及模型选择时的评估集过度拟合。核心发现基于一个新发布的包含161个编程问题及其Python解答的数据集，详情可访问https://huggingface.co/datasets/CohereForAI/lbpp。",
    "title_cn": "代码生成评估数据集的泄露问题",
    "tags": [
      "LLM应用",
      "软件开发",
      "人工智能"
    ]
  },
  {
    "title": "Arabic Automatic Story Generation with Large Language Models",
    "submit_datetime": "2024年07月10日",
    "abstract": "Large language models (LLMs) have recently emerged as a powerful tool for a wide range of language generation tasks. Nevertheless, this progress has been slower in Arabic. In this work, we focus on the task of generating stories from LLMs. For our training, we use stories acquired through machine translation (MT) as well as GPT-4. For the MT data, we develop a careful pipeline that ensures we acquire high-quality stories. For our GPT-41 data, we introduce crafted prompts that allow us to generate data well-suited to the Arabic context in both Modern Standard Arabic (MSA) and two Arabic dialects (Egyptian and Moroccan). For example, we generate stories tailored to various Arab countries on a wide host of topics. Our manual evaluation shows that our model fine-tuned on these training datasets can generate coherent stories that adhere to our instructions. We also conduct an extensive automatic and human evaluation comparing our models against state-of-the-art proprietary and open-source models. Our datasets and models will be made publicly available at https: //github.com/UBC-NLP/arastories.",
    "pdf_link": "https://arxiv.org/abs/2407.07551",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.07551v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07551/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07551v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07551/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07551v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07551/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07551v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07551/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07551v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07551/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07551v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07551/x6.png"
      }
    ],
    "abstract_cn": "大型语言模型 (LLM) 近期在多种语言生成任务中展现出强大能力，但在阿拉伯语领域进展较慢。本研究聚焦于利用 LLM 生成故事，采用机器翻译 (MT) 和 GPT-4 获取训练故事。针对 MT 数据，我们设计了确保故事质量的精细流程；对于 GPT-4 数据，我们设计了适应阿拉伯语环境的提示，涵盖现代标准阿拉伯语及埃及、摩洛哥方言。例如，我们为多个阿拉伯国家定制了涵盖广泛主题的故事。手动评估表明，经过微调的模型能生成符合指令的连贯故事。此外，我们通过自动和人工评估，将模型与顶尖的专有及开源模型进行对比。所有数据集和模型将在 https: //github.com/UBC-NLP/arastories 公开。",
    "title_cn": "大型语言模型助力阿拉伯自动故事生成",
    "tags": [
      "LLM应用",
      "",
      ""
    ]
  },
  {
    "title": "Beyond Benchmarking: A New Paradigm for Evaluation and Assessment of Large Language Models",
    "submit_datetime": "2024年07月10日",
    "abstract": "In current benchmarks for evaluating large language models (LLMs), there are issues such as evaluation content restriction, untimely updates, and lack of optimization guidance. In this paper, we propose a new paradigm for the measurement of LLMs: Benchmarking-Evaluation-Assessment. Our paradigm shifts the \"location\" of LLM evaluation from the \"examination room\" to the \"hospital\". Through conducting a \"physical examination\" on LLMs, it utilizes specific task-solving as the evaluation content, performs deep attribution of existing problems within LLMs, and provides recommendation for optimization.",
    "pdf_link": "https://arxiv.org/abs/2407.07531",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.07531v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07531/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07531v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07531/x2.png"
      }
    ],
    "abstract_cn": "当前的 LLM 评估基准存在诸多问题，如内容限制、更新滞后和缺乏优化指导。为此，我们提出了一种全新的评估范式：基准测试-评估-评估。这一范式将 LLM 的评估环境从“考场”转变为“医院”，通过“体检”方式，以特定任务解决为核心，深入剖析并优化 LLM 中的问题。",
    "title_cn": "跳出基准测试框架，我们提出了一种评估大型语言模型的新范式。",
    "tags": [
      "LLM理论",
      "人工智能",
      ""
    ]
  },
  {
    "title": "SHERL: Synthesizing High Accuracy and Efficient Memory for Resource-Limited Transfer Learning",
    "submit_datetime": "2024年07月10日",
    "abstract": "Parameter-efficient transfer learning (PETL) has emerged as a flourishing research field for adapting large pre-trained models to downstream tasks, greatly reducing trainable parameters while grappling with memory challenges during fine-tuning. To address it, memory-efficient series (METL) avoid backpropagating gradients through the large backbone. However, they compromise by exclusively relying on frozen intermediate outputs and limiting the exhaustive exploration of prior knowledge from pre-trained models. Moreover, the dependency and redundancy between cross-layer features are frequently overlooked, thereby submerging more discriminative representations and causing an inherent performance gap (vs. conventional PETL methods). Hence, we propose an innovative METL strategy called SHERL for resource-limited scenarios to decouple the entire adaptation into two successive and complementary processes. In the early route, intermediate outputs are consolidated via an anti-redundancy operation, enhancing their compatibility for subsequent interactions; thereby in the late route, utilizing minimal late pre-trained layers could alleviate the peak demand on memory overhead and regulate these fairly flexible features into more adaptive and powerful representations for new domains. Extensive ablations on vision-and-language and language-only tasks show that SHERL combines the strengths of both parameter and memory-efficient techniques, performing on-par or better across diverse architectures with lower memory during fine-tuning. Our code is publicly available at: https://github.com/Paranioar/SHERL.",
    "pdf_link": "https://arxiv.org/abs/2407.07523",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.07523v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07523/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07523v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07523/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07523v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07523/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07523v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07523/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07523v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07523/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07523v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07523/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07523v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07523/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07523v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07523/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07523v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07523/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07523v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07523/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07523v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07523/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07523v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07523/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07523v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07523/x13.png"
      }
    ],
    "abstract_cn": "参数高效的迁移学习（PETL）领域正蓬勃发展，旨在将大型预训练模型适应到下游任务，同时减少可训练参数并应对微调中的内存挑战。为解决这一难题，我们提出了创新的METL策略SHERL，特别适用于资源有限场景。SHERL将适应过程分为两个互补阶段：首先，通过反冗余操作优化中间输出，提升其后续交互的兼容性；随后，利用少量后期预训练层，有效减轻内存压力，并将灵活特征转化为对新领域更具适应性的强大表示。实验证明，SHERL在视觉与语言及仅语言任务中，以较低内存开销实现了与传统PETL方法相当或更优的性能。代码已公开发布于：https://github.com/Paranioar/SHERL。",
    "title_cn": "SHERL：针对资源受限的迁移学习，实现高准确度与内存效率的合成",
    "tags": [
      "LLM应用",
      "人工智能",
      "机器学习"
    ]
  },
  {
    "title": "Bucket Pre-training is All You Need",
    "submit_datetime": "2024年07月10日",
    "abstract": "Large language models (LLMs) have demonstrated exceptional performance across various natural language processing tasks. However, the conventional fixed-length data composition strategy for pretraining, which involves concatenating and splitting documents, can introduce noise and limit the model's ability to capture long-range dependencies. To address this, we first introduce three metrics for evaluating data composition quality: padding ratio, truncation ratio, and concatenation ratio. We further propose a multi-bucket data composition method that moves beyond the fixed-length paradigm, offering a more flexible and efficient approach to pretraining. Extensive experiments demonstrate that our proposed method could significantly improving both the efficiency and efficacy of LLMs pretraining. Our approach not only reduces noise and preserves context but also accelerates training, making it a promising solution for LLMs pretraining.",
    "pdf_link": "https://arxiv.org/abs/2407.07495",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.07495v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07495/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07495v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07495/x2.png"
      }
    ],
    "abstract_cn": "大型语言模型在众多自然语言处理任务中表现卓越，但传统固定长度的预训练数据组合策略，通过文档的拼接和分割，可能引入噪声并限制模型对长距离依赖的捕捉。为此，我们首先提出了三个评估数据组合质量的指标：填充比、截断比和连接比。接着，我们提出了一种多桶数据组合方法，突破固定长度限制，提供更灵活高效的预训练途径。实验证明，该方法能显著提升预训练的效率和效果，不仅减少噪声、保留上下文，还加速了训练过程，为大型语言模型的预训练开辟了新的可能。",
    "title_cn": "仅需 Bucket 预训练，一切尽在掌握",
    "tags": [
      "LLM理论",
      "",
      "机器学习"
    ]
  },
  {
    "title": "Review-LLM: Harnessing Large Language Models for Personalized Review Generation",
    "submit_datetime": "2024年07月10日",
    "abstract": "Product review generation is an important task in recommender systems, which could provide explanation and persuasiveness for the recommendation. Recently, Large Language Models (LLMs, e.g., ChatGPT) have shown superior text modeling and generating ability, which could be applied in review generation. However, directly applying the LLMs for generating reviews might be troubled by the ``polite'' phenomenon of the LLMs and could not generate personalized reviews (e.g., negative reviews). In this paper, we propose Review-LLM that customizes LLMs for personalized review generation. Firstly, we construct the prompt input by aggregating user historical behaviors, which include corresponding item titles and reviews. This enables the LLMs to capture user interest features and review writing style. Secondly, we incorporate ratings as indicators of satisfaction into the prompt, which could further improve the model's understanding of user preferences and the sentiment tendency control of generated reviews. Finally, we feed the prompt text into LLMs, and use Supervised Fine-Tuning (SFT) to make the model generate personalized reviews for the given user and target item. Experimental results on the real-world dataset show that our fine-tuned model could achieve better review generation performance than existing close-source LLMs.",
    "pdf_link": "https://arxiv.org/abs/2407.07487",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.07487v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07487/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07487v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07487/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07487v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07487/x3.png"
      }
    ],
    "abstract_cn": "产品评论生成在推荐系统中至关重要，能为推荐增添解释与说服力。近期，大型语言模型如ChatGPT展现了出色的文本建模与生成能力，有望应用于评论生成领域。然而，直接利用这些模型可能因“礼貌”现象而难以产出个性化评论，如负面评价。为此，我们提出Review-LLM，专为个性化评论生成定制。首先，通过整合用户历史行为（含项目标题与评论）构建输入提示，助模型捕捉用户兴趣与评论风格。其次，引入评分作为满意度指标，深化模型对用户偏好的理解及评论情感控制。最终，借助监督微调，使模型针对特定用户与项目生成个性化评论。实验表明，我们的模型在真实数据集上表现优于现有闭源LLMs，评论生成效果更佳。",
    "title_cn": "Review-LLM：借助大型语言模型，打造个性化评论生成工具",
    "tags": [
      "LLM应用",
      "推荐系统",
      "电子商务"
    ]
  },
  {
    "title": "Rectifier: Code Translation with Corrector via LLMs",
    "submit_datetime": "2024年07月10日",
    "abstract": "Software migration is garnering increasing attention with the evolution of software and society. Early studies mainly relied on handcrafted translation rules to translate between two languages, the translation process is error-prone and time-consuming. In recent years, researchers have begun to explore the use of pre-trained large language models (LLMs) in code translation. However, code translation is a complex task that LLMs would generate mistakes during code translation, they all produce certain types of errors when performing code translation tasks, which include (1) compilation error, (2) runtime error, (3) functional error, and (4) non-terminating execution. We found that the root causes of these errors are very similar (e.g. failure to import packages, errors in loop boundaries, operator errors, and more). In this paper, we propose a general corrector, namely Rectifier, which is a micro and universal model for repairing translation errors. It learns from errors generated by existing LLMs and can be widely applied to correct errors generated by any LLM. The experimental results on translation tasks between C++, Java, and Python show that our model has effective repair ability, and cross experiments also demonstrate the robustness of our method.",
    "pdf_link": "https://arxiv.org/abs/2407.07472",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.07472v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07472/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07472v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07472/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07472v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07472/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07472v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07472/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07472v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07472/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07472v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07472/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07472v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07472/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07472v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07472/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07472v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07472/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07472v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07472/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07472v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07472/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07472v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07472/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07472v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07472/x13.png"
      }
    ],
    "abstract_cn": "随着软件与社会的进步，软件迁移日益受到重视。早期研究多依赖手工规则进行语言间的代码转换，这一过程既易错又耗时。近年来，研究者开始尝试利用预训练的大型语言模型（LLM）进行代码翻译，但此复杂任务中LLM常犯的错误包括编译、运行时、功能性及非终止执行错误。这些错误的根源相似，如包导入失败、循环边界失误、操作符错误等。为此，我们提出了通用校正器Rectifier，一个微型且普适的错误修复模型，它能从LLM的错误中学习，并广泛应用于纠正各类LLM的翻译错误。实验表明，Rectifier在C++、Java与Python间的代码翻译中展现了出色的修复能力，交叉实验亦证实了其方法的稳健性。",
    "title_cn": "Rectifier：利用 LLM 实现代码翻译与校正",
    "tags": [
      "LLM应用",
      "软件开发",
      "人工智能"
    ]
  },
  {
    "title": "GLBench: A Comprehensive Benchmark for Graph with Large Language Models",
    "submit_datetime": "2024年07月10日",
    "abstract": "The emergence of large language models (LLMs) has revolutionized the way we interact with graphs, leading to a new paradigm called GraphLLM. Despite the rapid development of GraphLLM methods in recent years, the progress and understanding of this field remain unclear due to the lack of a benchmark with consistent experimental protocols. To bridge this gap, we introduce GLBench, the first comprehensive benchmark for evaluating GraphLLM methods in both supervised and zero-shot scenarios. GLBench provides a fair and thorough evaluation of different categories of GraphLLM methods, along with traditional baselines such as graph neural networks. Through extensive experiments on a collection of real-world datasets with consistent data processing and splitting strategies, we have uncovered several key findings. Firstly, GraphLLM methods outperform traditional baselines in supervised settings, with LLM-as-enhancers showing the most robust performance. However, using LLMs as predictors is less effective and often leads to uncontrollable output issues. We also notice that no clear scaling laws exist for current GraphLLM methods. In addition, both structures and semantics are crucial for effective zero-shot transfer, and our proposed simple baseline can even outperform several models tailored for zero-shot scenarios. The data and code of the benchmark can be found at https://github.com/NineAbyss/GLBench.",
    "pdf_link": "https://arxiv.org/abs/2407.07457",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.07457v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07457/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07457v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07457/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07457v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07457/x3.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLM）的兴起，催生了与图表交互的新范式——GraphLLM。尽管GraphLLM技术日新月异，但因缺乏统一标准的测试平台，其发展现状仍显模糊。为此，我们推出了GLBench，这是首个针对GraphLLM方法在监督与零-shot环境下进行全面评估的基准。GLBench不仅公正地评测了各类GraphLLM技术，还涵盖了图神经网络等传统基线。通过在真实数据集上实施标准化实验，我们获得了重要洞察：在监督模式下，GraphLLM技术普遍超越传统方法，特别是作为增强器的LLM表现最为稳定；但作为预测器时，LLM则表现不佳，常引发输出失控问题。此外，我们发现GraphLLM尚无明确的规模效应规律。同时，结构与语义在零-shot迁移中扮演关键角色，我们提出的简易基线甚至能击败一些专为零-shot设计的复杂模型。GLBench的资源已公开于https://github.com/NineAbyss/GLBench。",
    "title_cn": "GLBench：专为大型语言模型设计的图处理全面基准",
    "tags": [
      "LLM应用",
      "人工智能",
      "数据科学"
    ]
  },
  {
    "title": "Controllable Navigation Instruction Generation with Chain of Thought Prompting",
    "submit_datetime": "2024年07月10日",
    "abstract": "Instruction generation is a vital and multidisciplinary research area with broad applications. Existing instruction generation models are limited to generating instructions in a single style from a particular dataset, and the style and content of generated instructions cannot be controlled. Moreover, most existing instruction generation methods also disregard the spatial modeling of the navigation environment. Leveraging the capabilities of Large Language Models (LLMs), we propose C-Instructor, which utilizes the chain-of-thought-style prompt for style-controllable and content-controllable instruction generation. Firstly, we propose a Chain of Thought with Landmarks (CoTL) mechanism, which guides the LLM to identify key landmarks and then generate complete instructions. CoTL renders generated instructions more accessible to follow and offers greater controllability over the manipulation of landmark objects. Furthermore, we present a Spatial Topology Modeling Task to facilitate the understanding of the spatial structure of the environment. Finally, we introduce a Style-Mixed Training policy, harnessing the prior knowledge of LLMs to enable style control for instruction generation based on different prompts within a single model instance. Extensive experiments demonstrate that instructions generated by C-Instructor outperform those generated by previous methods in text metrics, navigation guidance evaluation, and user studies.",
    "pdf_link": "https://arxiv.org/abs/2407.07433",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.07433v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07433/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07433v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07433/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07433v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07433/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07433v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07433/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07433v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07433/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07433v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07433/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07433v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07433/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07433v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07433/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07433v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07433/x9.png"
      }
    ],
    "abstract_cn": "指令生成是一个跨学科研究热点，应用广泛。传统模型受限于单一数据集的风格，且无法灵活控制生成内容。我们借助大型语言模型（LLM），创新推出C-Instructor，通过思维链提示实现风格与内容的双重可控。我们首创地标思维链（CoTL）机制，引导模型精准识别地标，生成详尽指令，提升易用性与操作灵活性。同时，我们设计空间拓扑建模任务，深化环境理解。最后，通过风格混合训练策略，C-Instructor在单一模型内实现多风格指令生成。实验证明，C-Instructor在文本质量、导航指导及用户体验等多方面超越现有技术。",
    "title_cn": "通过思维链提示实现可控的导航指令生成",
    "tags": [
      "LLM应用",
      "人工智能",
      "导航系统"
    ]
  },
  {
    "title": "CHOP: Integrating ChatGPT into EFL Oral Presentation Practice",
    "submit_datetime": "2024年07月10日",
    "abstract": "English as a Foreign Language (EFL) students often struggle to deliver oral presentations due to a lack of reliable resources and the limited effectiveness of instructors' feedback. Large Language Model (LLM) can offer new possibilities to assist students' oral presentations with real-time feedback. This paper investigates how ChatGPT can be effectively integrated into EFL oral presentation practice to provide personalized feedback. We introduce a novel learning platform, CHOP (ChatGPT-based interactive platform for oral presentation practice), and evaluate its effectiveness with 13 EFL students. By collecting student-ChatGPT interaction data and expert assessments of the feedback quality, we identify the platform's strengths and weaknesses. We also analyze learners' perceptions and key design factors. Based on these insights, we suggest further development opportunities and design improvements for the education community.",
    "pdf_link": "https://arxiv.org/abs/2407.07393",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.07393v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07393/UI_screenshot.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07393v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07393/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07393v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07393/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07393v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07393/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07393v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07393/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07393v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07393/x5.png"
      }
    ],
    "abstract_cn": "EFL 学生在进行口头报告时，常因资源匮乏和教师反馈效果有限而感到挑战。大型语言模型（LLM）通过实时反馈，为提升学生口头报告能力开辟了新途径。本文探讨了如何将 ChatGPT 有效融入 EFL 口头报告练习，提供定制化反馈。我们创新性地推出了 CHOP 平台——一个基于 ChatGPT 的互动学习工具，并通过对 13 名 EFL 学生的实证研究，评估了其效能。通过分析学生与 ChatGPT 的互动数据及专家对反馈质量的评价，我们揭示了 CHOP 平台的优缺点。同时，我们深入剖析了学习者的体验和关键设计要素。基于这些发现，我们为教育领域提出了未来发展方向和设计优化建议。",
    "title_cn": "CHOP：融合 ChatGPT 于 EFL 口语展示训练",
    "tags": [
      "LLM应用",
      "",
      "语言学习"
    ]
  },
  {
    "title": "Malicious Path Manipulations via Exploitation of Representation Vulnerabilities of Vision-Language Navigation Systems",
    "submit_datetime": "2024年07月10日",
    "abstract": "Building on the unprecedented capabilities of large language models for command understanding and zero-shot recognition of multi-modal vision-language transformers, visual language navigation (VLN) has emerged as an effective way to address multiple fundamental challenges toward a natural language interface to robot navigation. However, such vision-language models are inherently vulnerable due to the lack of semantic meaning of the underlying embedding space. Using a recently developed gradient based optimization procedure, we demonstrate that images can be modified imperceptibly to match the representation of totally different images and unrelated texts for a vision-language model. Building on this, we develop algorithms that can adversarially modify a minimal number of images so that the robot will follow a route of choice for commands that require a number of landmarks. We demonstrate that experimentally using a recently proposed VLN system; for a given navigation command, a robot can be made to follow drastically different routes. We also develop an efficient algorithm to detect such malicious modifications reliably based on the fact that the adversarially modified images have much higher sensitivity to added Gaussian noise than the original images.",
    "pdf_link": "https://arxiv.org/abs/2407.07392",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.07392v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07392/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07392v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07392/path_example.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07392v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07392/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07392v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07392/detection_final.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07392v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07392/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07392v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07392/x4.png"
      }
    ],
    "abstract_cn": "借助大型语言模型在命令理解和多模态视觉-语言转换器的零-shot识别方面的强大能力，视觉语言导航（VLN）已成为解决机器人导航自然语言接口挑战的有效途径。然而，这些模型因底层嵌入空间缺乏语义意义而显得脆弱。我们利用一种新型的基于梯度的优化技术，展示了如何微妙地调整图像，使其在视觉-语言模型中与完全不同的图像和文本相匹配。基于此，我们设计了算法，仅需少量图像的对抗性修改，就能引导机器人按照特定路径执行多地标命令。实验表明，通过最新的VLN系统，机器人可被诱导至完全不同的路线。此外，我们还开发了一种高效算法，通过识别对抗性修改图像对高斯噪声的高度敏感性，来可靠地检测这些恶意篡改。",
    "title_cn": "恶意路径操纵：利用视觉-语言导航系统的表示漏洞",
    "tags": [
      "LLM应用",
      "机器人",
      "计算机视觉"
    ]
  },
  {
    "title": "LokiLM: Technical Report",
    "submit_datetime": "2024年07月10日",
    "abstract": "In this work, we introduce LokiLM, a 1.4B parameter large language model trained on 500B tokens. Our model performs strongly in natural language reasoning tasks and achieves state-of-the-art performance among models with 1.5B parameters or less. LokiLM is trained using multi-teacher knowledge distillation and high-quality training data to achieve benchmark results competitive with larger models trained on significantly more tokens. We support these findings by introducing steps to avoid benchmark contamination and overfitting throughout our development process. Despite its promising performance, LokiLM exhibits a concerning amount of hallucinations and scores poorly on the TruthfulQA benchmark, so we do not release the model publicly.",
    "pdf_link": "https://arxiv.org/abs/2407.07370",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.07370v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07370/results.png"
      }
    ],
    "abstract_cn": "我们推出的 LokiLM，一个 1.4B 参数的 LLM，经过 500B 令牌的训练，在自然语言推理任务中表现卓越，成为参数 1.5B 以下的佼佼者。通过多教师知识蒸馏和精选训练数据，LokiLM 的基准成绩可与更大规模的模型媲美。我们通过一系列措施，确保了开发过程中避免基准污染和过拟合。然而，LokiLM 在产生幻觉和 TruthfulQA 测试中表现不佳，因此我们决定暂不公开发布。",
    "title_cn": "LokiLM 技术报告",
    "tags": [
      "LLM理论",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Virtual Agents for Alcohol Use Counseling: Exploring LLM-Powered Motivational Interviewing",
    "submit_datetime": "2024年07月10日",
    "abstract": "We introduce a novel application of large language models (LLMs) in developing a virtual counselor capable of conducting motivational interviewing (MI) for alcohol use counseling. Access to effective counseling remains limited, particularly for substance abuse, and virtual agents offer a promising solution by leveraging LLM capabilities to simulate nuanced communication techniques inherent in MI. Our approach combines prompt engineering and integration into a user-friendly virtual platform to facilitate realistic, empathetic interactions. We evaluate the effectiveness of our virtual agent through a series of studies focusing on replicating MI techniques and human counselor dialog. Initial findings suggest that our LLM-powered virtual agent matches human counselors' empathetic and adaptive conversational skills, presenting a significant step forward in virtual health counseling and providing insights into the design and implementation of LLM-based therapeutic interactions.",
    "pdf_link": "https://arxiv.org/abs/2407.08095",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.08095v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08095/Agent.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08095v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08095/MI.png"
      }
    ],
    "abstract_cn": "我们创新性地运用大型语言模型 (LLM) 开发了一款虚拟顾问，专为酒精使用咨询中的动机性访谈 (MI) 设计。面对物质滥用领域有效咨询的稀缺，虚拟代理凭借 LLM 的强大能力，模拟 MI 中的精细沟通技巧，展现出解决问题的潜力。我们的方法融合了提示工程与用户友好平台的集成，旨在实现真实且富有同理心的交流。通过一系列研究，我们专注于复制 MI 技巧及人类顾问的对话，评估虚拟代理的有效性。初步结果显示，该 LLM 驱动的虚拟代理在同理心与对话适应性上媲美人类顾问，为虚拟健康咨询领域带来突破，并深入探讨了基于 LLM 的治疗互动的设计与实施。",
    "title_cn": "探索由 LLM 驱动的虚拟代理在酒精使用咨询中的动机性访谈应用。",
    "tags": [
      "Agent",
      "",
      "心理健康"
    ]
  },
  {
    "title": "RoLoRA: Fine-tuning Rotated Outlier-free LLMs for Effective Weight-Activation Quantization",
    "submit_datetime": "2024年07月10日",
    "abstract": "Low-Rank Adaptation (LoRA), as a representative Parameter-Efficient Fine-Tuning (PEFT)method, significantly enhances the training efficiency by updating only a small portion of the weights in Large Language Models (LLMs). Recently, weight-only quantization techniques have also been applied to LoRA methods to reduce the memory footprint of fine-tuning. However, applying weight-activation quantization to the LoRA pipeline is under-explored, and we observe substantial performance degradation primarily due to the presence of activation outliers. In this work, we propose RoLoRA, the first LoRA-based scheme for effective weight-activation quantization. RoLoRA utilizes rotation for outlier elimination and proposes rotation-aware fine-tuning to preserve the outlier-free characteristics in rotated LLMs. Experimental results show RoLoRA consistently improves low-bit LoRA convergence and post-training quantization robustness in weight-activation settings. We evaluate RoLoRA across LLaMA2-7B/13B, LLaMA3-8B models, achieving up to 29.5% absolute accuracy gain of 4-bit weight-activation quantized LLaMA2- 13B on commonsense reasoning tasks compared to LoRA baseline. We further demonstrate its effectiveness on Large Multimodal Models (LLaVA-1.5-7B). Codes are available at https://github.com/HuangOwen/RoLoRA",
    "pdf_link": "https://arxiv.org/abs/2407.08044",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.08044v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08044/activation_compare.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08044v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08044/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08044v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08044/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08044v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08044/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08044v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08044/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08044v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08044/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08044v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08044/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08044v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08044/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08044v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08044/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08044v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08044/activation_compare_layer0.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08044v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08044/activation_compare_layer1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08044v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08044/activation_compare_layer6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08044v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08044/activation_compare_layer11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08044v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08044/activation_compare_layer16.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08044v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08044/activation_compare_layer21.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08044v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08044/activation_compare_layer26.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08044v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08044/activation_compare_layer31.png"
      }
    ],
    "abstract_cn": "LoRA 通过仅调整 LLM 中少量权重，显著提升训练效率，而近期仅权重量化技术也被用于减少 LoRA 微调的内存需求。然而，权重-激活量化在 LoRA 中的应用尚浅，主要因激活异常值导致性能下降。为此，我们提出 RoLoRA，首个基于 LoRA 的权重-激活量化方案，通过旋转消除异常值并进行旋转感知微调，保持旋转后 LLM 的无异常值特性。实验表明，RoLoRA 在低比特设置下稳定提升 LoRA 收敛及量化鲁棒性。在 LLaMA2-7B/13B 和 LLaMA3-8B 模型上，RoLoRA 在常识推理任务中较 LoRA 基线提升高达 29.5% 的精度。此外，其在大型多模态模型 LLaVA-1.5-7B 上也表现出色。代码已公开于 https://github.com/HuangOwen/RoLoRA。",
    "title_cn": "RoLoRA：通过微调无异常值的旋转 LLM，实现高效的权重-激活量化。",
    "tags": [
      "LLM理论",
      "人工智能",
      "机器学习"
    ]
  },
  {
    "title": "Evaluating Voice Command Pipelines for Drone Control: From STT and LLM to Direct Classification and Siamese Networks",
    "submit_datetime": "2024年07月10日",
    "abstract": "This paper presents the development and comparative evaluation of three voice command pipelines for controlling a Tello drone, using speech recognition and deep learning techniques. The aim is to enhance human-machine interaction by enabling intuitive voice control of drone actions. The pipelines developed include: (1) a traditional Speech-to-Text (STT) followed by a Large Language Model (LLM) approach, (2) a direct voice-to-function mapping model, and (3) a Siamese neural network-based system. Each pipeline was evaluated based on inference time, accuracy, efficiency, and flexibility. Detailed methodologies, dataset preparation, and evaluation metrics are provided, offering a comprehensive analysis of each pipeline's strengths and applicability across different scenarios.",
    "pdf_link": "https://arxiv.org/abs/2407.08658",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.08658v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08658/pipeline1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08658v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08658/pipeline2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.08658v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.08658/pipeline3.png"
      }
    ],
    "abstract_cn": "本文探讨了三种利用语音识别和深度学习技术控制Tello无人机的语音命令管道，旨在通过直观的语音控制提升人机交互体验。这些管道包括：传统STT结合LLM、直接语音到功能映射以及基于孪生神经网络的系统。我们基于推理时间、准确性、效率和灵活性对这些管道进行了详细评估，并提供了全面的方法论、数据集准备和评估指标，深入分析了各管道在不同应用场景中的优势和适用性。",
    "title_cn": "探索无人机语音控制：从语音识别到大型语言模型，再到直接分类与孪生网络的应用。",
    "tags": [
      "Agent",
      "无人机",
      "人机交互"
    ]
  },
  {
    "title": "Internet of Agents: Weaving a Web of Heterogeneous Agents for Collaborative Intelligence",
    "submit_datetime": "2024年07月09日",
    "abstract": "The rapid advancement of large language models (LLMs) has paved the way for the development of highly capable autonomous agents. However, existing multi-agent frameworks often struggle with integrating diverse capable third-party agents due to reliance on agents defined within their own ecosystems. They also face challenges in simulating distributed environments, as most frameworks are limited to single-device setups. Furthermore, these frameworks often rely on hard-coded communication pipelines, limiting their adaptability to dynamic task requirements. Inspired by the concept of the Internet, we propose the Internet of Agents (IoA), a novel framework that addresses these limitations by providing a flexible and scalable platform for LLM-based multi-agent collaboration. IoA introduces an agent integration protocol, an instant-messaging-like architecture design, and dynamic mechanisms for agent teaming and conversation flow control. Through extensive experiments on general assistant tasks, embodied AI tasks, and retrieval-augmented generation benchmarks, we demonstrate that IoA consistently outperforms state-of-the-art baselines, showcasing its ability to facilitate effective collaboration among heterogeneous agents. IoA represents a step towards linking diverse agents in an Internet-like environment, where agents can seamlessly collaborate to achieve greater intelligence and capabilities. Our codebase has been released at \\url{https://github.com/OpenBMB/IoA}.",
    "pdf_link": "https://arxiv.org/abs/2407.07061",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.07061v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07061/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07061v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07061/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07061v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07061/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07061v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07061/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07061v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07061/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07061v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07061/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07061v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07061/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07061v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07061/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07061v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07061/cabinet.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07061v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07061/sweep.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07061v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07061/sandwich.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07061v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07061/sort.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07061v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07061/rope.png"
      }
    ],
    "abstract_cn": "随着大型语言模型的飞速进步，高度自主的智能代理应运而生。然而，现有框架在整合第三方代理和模拟分布式环境方面存在局限，且通信方式僵化。为此，我们创新性地提出了“代理互联网”(IoA) 框架，它不仅灵活可扩展，还引入了即时通讯风格的架构和动态协作机制。实验证明，IoA 在各类任务中表现卓越，有效促进了异构代理间的协同。这一框架如同互联网般，让代理们无缝协作，共同迈向更高智能。项目代码已公开于 \\url{https://github.com/OpenBMB/IoA}。",
    "title_cn": "互联网代理网络：构建一个多元化的代理网络，以促进智能协作",
    "tags": [
      "Agent",
      "人工智能",
      "互联网"
    ]
  },
  {
    "title": "PEER: Expertizing Domain-Specific Tasks with a Multi-Agent Framework and Tuning Methods",
    "submit_datetime": "2024年07月09日",
    "abstract": "In domain-specific applications, GPT-4, augmented with precise prompts or Retrieval-Augmented Generation (RAG), shows notable potential but faces the critical tri-lemma of performance, cost, and data privacy. High performance requires sophisticated processing techniques, yet managing multiple agents within a complex workflow often proves costly and challenging. To address this, we introduce the PEER (Plan, Execute, Express, Review) multi-agent framework. This systematizes domain-specific tasks by integrating precise question decomposition, advanced information retrieval, comprehensive summarization, and rigorous self-assessment. Given the concerns of cost and data privacy, enterprises are shifting from proprietary models like GPT-4 to custom models, striking a balance between cost, security, and performance. We developed industrial practices leveraging online data and user feedback for efficient model tuning. This study provides best practice guidelines for applying multi-agent systems in domain-specific problem-solving and implementing effective agent tuning strategies. Our empirical studies, particularly in the financial question-answering domain, demonstrate that our approach achieves 95.0% of GPT-4's performance, while effectively managing costs and ensuring data privacy.",
    "pdf_link": "https://arxiv.org/abs/2407.06985",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06985v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06985/lunwen_3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06985v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06985/image_iter-training.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06985v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06985/peer_result_3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06985v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06985/high_resolution_chart.png"
      }
    ],
    "abstract_cn": "在特定领域应用中，GPT-4结合精确提示或RAG技术展现出巨大潜力，但同时也面临着性能、成本和数据隐私的三重挑战。为解决这一难题，我们创新性地提出了PEER多代理框架，通过精确问题分解、高级信息检索、全面总结和严格自我评估，系统化处理特定领域任务。面对成本和数据隐私的压力，企业正逐步从依赖GPT-4转向开发定制模型，以平衡成本、安全性和性能。我们通过利用在线数据和用户反馈，开发了高效的模型调优实践。本研究不仅为特定领域问题解决提供了多代理系统的应用指南，还为实施有效的代理调优策略提供了实证支持。特别是在金融问答领域，我们的方法不仅达到了GPT-4性能的95.0%，更在成本控制和数据隐私保护方面表现出色。",
    "title_cn": "PEER 利用多代理框架与调优方法，精通特定领域任务。",
    "tags": [
      "Agent",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Hypothetical Minds: Scaffolding Theory of Mind for Multi-Agent Tasks with Large Language Models",
    "submit_datetime": "2024年07月09日",
    "abstract": "Multi-agent reinforcement learning (MARL) methods struggle with the non-stationarity of multi-agent systems and fail to adaptively learn online when tested with novel agents. Here, we leverage large language models (LLMs) to create an autonomous agent that can handle these challenges. Our agent, Hypothetical Minds, consists of a cognitively-inspired architecture, featuring modular components for perception, memory, and hierarchical planning over two levels of abstraction. We introduce the Theory of Mind module that scaffolds the high-level planning process by generating hypotheses about other agents' strategies in natural language. It then evaluates and iteratively refines these hypotheses by reinforcing hypotheses that make correct predictions about the other agents' behavior. Hypothetical Minds significantly improves performance over previous LLM-agent and RL baselines on a range of competitive, mixed motive, and collaborative domains in the Melting Pot benchmark, including both dyadic and population-based environments. Additionally, comparisons against LLM-agent baselines and ablations reveal the importance of hypothesis evaluation and refinement for succeeding on complex scenarios.",
    "pdf_link": "https://arxiv.org/abs/2407.07086",
    "graphs": [],
    "abstract_cn": "多智能体强化学习 (MARL) 在处理系统非平稳性时遇到挑战，且难以与新智能体在线适应学习。我们利用大型语言模型 (LLM) 开发了自主智能体“假设思维”，其受认知启发的架构包含感知、记忆及双层抽象规划模块。引入的“心智理论”模块通过自然语言生成其他智能体策略假设，评估并优化这些假设，以强化正确预测。在 Melting Pot 基准测试中，假设思维在竞争、混合动机及协作领域显著超越以往 LLM-智能体和 RL 基线。对比分析显示，假设评估与优化对复杂场景成功至关重要。",
    "title_cn": "假设心灵：借助大型语言模型，为多智能体任务构建心灵理论的支撑框架",
    "tags": [
      "Agent",
      "人工智能",
      ""
    ]
  },
  {
    "title": "FinCon: A Synthesized LLM Multi-Agent System with Conceptual Verbal Reinforcement for Enhanced Financial Decision Making",
    "submit_datetime": "2024年07月09日",
    "abstract": "Large language models (LLMs) have demonstrated notable potential in conducting complex tasks and are increasingly utilized in various financial applications. However, high-quality sequential financial investment decision-making remains challenging. These tasks require multiple interactions with a volatile environment for every decision, demanding sufficient intelligence to maximize returns and manage risks. Although LLMs have been used to develop agent systems that surpass human teams and yield impressive investment returns, opportunities to enhance multi-sourced information synthesis and optimize decision-making outcomes through timely experience refinement remain unexplored. Here, we introduce the FinCon, an LLM-based multi-agent framework with CONceptual verbal reinforcement tailored for diverse FINancial tasks. Inspired by effective real-world investment firm organizational structures, FinCon utilizes a manager-analyst communication hierarchy. This structure allows for synchronized cross-functional agent collaboration towards unified goals through natural language interactions and equips each agent with greater memory capacity than humans. Additionally, a risk-control component in FinCon enhances decision quality by episodically initiating a self-critiquing mechanism to update systematic investment beliefs. The conceptualized beliefs serve as verbal reinforcement for the future agent's behavior and can be selectively propagated to the appropriate node that requires knowledge updates. This feature significantly improves performance while reducing unnecessary peer-to-peer communication costs. Moreover, FinCon demonstrates strong generalization capabilities in various financial tasks, including single stock trading and portfolio management.",
    "pdf_link": "https://arxiv.org/abs/2407.06567",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06567v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06567/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06567v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06567/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06567v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06567/TSLA.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06567v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06567/AMZN.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06567v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06567/NIO.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06567v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06567/AAPL.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06567v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06567/GOOG_v2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06567v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06567/COIN.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06567v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06567/multi_assets_comparison.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06567v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06567/GOOG-nocvar.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06567v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06567/NIO-abl_cvar.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06567v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06567/multiasset_nocvar.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06567v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06567/GOOG-nobelief.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06567v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06567/NIO-abl_belief.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06567v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06567/multiasset_nobelief.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06567v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06567/news.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06567v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06567/10k10q.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06567v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06567/zacks.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLM）在处理复杂任务方面潜力巨大，广泛应用于金融领域。然而，高质量的连续金融投资决策依然充满挑战。这些任务要求智能系统与波动市场多次互动，以最大化回报并管理风险。尽管LLM已助力开发出超越人类的投资代理系统，但通过经验改进优化决策、增强信息合成的潜力尚未充分挖掘。为此，我们推出了FinCon，一个专为金融任务设计的LLM多代理框架，融入概念性口头强化。借鉴现实投资公司的有效组织结构，FinCon采用经理-分析师沟通层级，通过自然语言实现跨职能代理的协同合作，并赋予代理更大记忆容量。框架内置风险控制机制，定期自我批评以更新投资信念，提升决策质量。这些概念化信念作为未来行为的强化，精准传递至需更新的节点，既提升性能又降低通信成本。FinCon在单一股票交易和投资组合管理等金融任务中展现出卓越的泛化能力。",
    "title_cn": "FinCon：一款集成了概念性语言强化技术的合成 LLM 多智能体系统，旨在提升财务决策的精准度。",
    "tags": [
      "Agent",
      "",
      "投资管理"
    ]
  },
  {
    "title": "Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model",
    "submit_datetime": "2024年07月09日",
    "abstract": "Although most current large multimodal models (LMMs) can already understand photos of natural scenes and portraits, their understanding of abstract images, e.g., charts, maps, or layouts, and visual reasoning capabilities remains quite rudimentary. They often struggle with simple daily tasks, such as reading time from a clock, understanding a flowchart, or planning a route using a road map. In light of this, we design a multi-modal self-instruct, utilizing large language models and their code capabilities to synthesize massive abstract images and visual reasoning instructions across daily scenarios. Our strategy effortlessly creates a multimodal benchmark with 11,193 instructions for eight visual scenarios: charts, tables, simulated maps, dashboards, flowcharts, relation graphs, floor plans, and visual puzzles. \\textbf{This benchmark, constructed with simple lines and geometric elements, exposes the shortcomings of most advanced LMMs} like Claude-3.5-Sonnet and GPT-4o in abstract image understanding, spatial relations reasoning, and visual element induction. Besides, to verify the quality of our synthetic data, we fine-tune an LMM using 62,476 synthetic chart, table and road map instructions. The results demonstrate improved chart understanding and map navigation performance, and also demonstrate potential benefits for other visual reasoning tasks. Our code is available at: \\url{https://github.com/zwq2018/Multi-modal-Self-instruct}.",
    "pdf_link": "https://arxiv.org/abs/2407.07053",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.07053v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07053/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07053v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07053/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07053v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07053/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07053v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07053/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07053v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07053/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07053v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07053/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07053v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07053/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07053v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07053/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07053v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07053/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07053v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07053/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07053v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07053/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07053v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07053/x12.png"
      }
    ],
    "abstract_cn": "当前大型多模态模型 (LMMs) 虽能理解自然场景和肖像，但对抽象图像如图表、地图的理解及视觉推理能力尚显稚嫩。它们在日常任务如读时钟、理解流程图或规划路线时往往力不从心。为此，我们设计了多模态自指导方法，结合大型语言模型与代码能力，合成日常场景中的抽象图像与视觉推理指令。我们创建的多模态基准包含 11,193 条指令，覆盖图表、表格等八种视觉场景，揭示了先进 LMMs 在抽象图像理解等方面的不足。通过使用合成数据微调 LMM，我们验证了数据质量，提升了图表理解与地图导航性能，并展示了在其他视觉推理任务中的潜力。代码已公开在 \\url{https://github.com/zwq2018/Multi-modal-Self-instruct}。",
    "title_cn": "多模态自我指导：借助语言模型，合成抽象图像并进行视觉推理指导",
    "tags": [
      "LLM应用",
      "人工智能",
      "计算机视觉"
    ]
  },
  {
    "title": "Explicit Modelling of Theory of Mind for Belief Prediction in Nonverbal Social Interactions",
    "submit_datetime": "2024年07月09日",
    "abstract": "We propose MToMnet - a Theory of Mind (ToM) neural network for predicting beliefs and their dynamics during human social interactions from multimodal input. ToM is key for effective nonverbal human communication and collaboration, yet, existing methods for belief modelling have not included explicit ToM modelling or have typically been limited to one or two modalities. MToMnet encodes contextual cues (scene videos and object locations) and integrates them with person-specific cues (human gaze and body language) in a separate MindNet for each person. Inspired by prior research on social cognition and computational ToM, we propose three different MToMnet variants: two involving fusion of latent representations and one involving re-ranking of classification scores. We evaluate our approach on two challenging real-world datasets, one focusing on belief prediction, while the other examining belief dynamics prediction. Our results demonstrate that MToMnet surpasses existing methods by a large margin while at the same time requiring a significantly smaller number of parameters. Taken together, our method opens up a highly promising direction for future work on artificial intelligent systems that can robustly predict human beliefs from their non-verbal behaviour and, as such, more effectively collaborate with humans.",
    "pdf_link": "https://arxiv.org/abs/2407.06762",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06762v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06762/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06762v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06762/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06762v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06762/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06762v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06762/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06762v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06762/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06762v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06762/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06762v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06762/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06762v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06762/tbd_false_belief_example.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06762v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06762/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06762v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06762/x9.png"
      }
    ],
    "abstract_cn": "我们创新性地提出了 MToMnet，这是一种心智理论神经网络，旨在从多模态输入中预测人类社交互动中的信念及其变化。ToM 在非言语沟通和协作中扮演关键角色，但现有信念建模方法往往忽视了 ToM 的显式建模，或仅限于少数模态。MToMnet 巧妙地整合了场景视频、物体位置等上下文线索与个人注视、身体语言等特定信息，为每个人构建独立的 MindNet。借鉴社交认知与计算 ToM 的研究，我们设计了三种 MToMnet 变体，涵盖潜在表示融合与分类分数重排序等策略。在两个真实世界数据集上的评估显示，MToMnet 不仅大幅领先现有方法，且参数需求显著降低。这一成果为未来人工智能系统在非言语行为中精准预测人类信念、提升协作效率指明了光明道路。",
    "title_cn": "在非言语社交互动中，显式建模心智理论以预测信念",
    "tags": [
      "Agent",
      "人工智能",
      "社交互动"
    ]
  },
  {
    "title": "Richelieu: Self-Evolving LLM-Based Agents for AI Diplomacy",
    "submit_datetime": "2024年07月09日",
    "abstract": "Diplomacy is one of the most sophisticated activities in human society. The complex interactions among multiple parties/ agents involve various abilities like social reasoning, negotiation arts, and long-term strategy planning. Previous AI agents surely have proved their capability of handling multi-step games and larger action spaces on tasks involving multiple agents. However, diplomacy involves a staggering magnitude of decision spaces, especially considering the negotiation stage required. Recently, LLM agents have shown their potential for extending the boundary of previous agents on a couple of applications, however, it is still not enough to handle a very long planning period in a complex multi-agent environment. Empowered with cutting-edge LLM technology, we make the first stab to explore AI's upper bound towards a human-like agent for such a highly comprehensive multi-agent mission by combining three core and essential capabilities for stronger LLM-based societal agents: 1) strategic planner with memory and reflection; 2) goal-oriented negotiate with social reasoning; 3) augmenting memory by self-play games to self-evolving without any human in the loop.",
    "pdf_link": "https://arxiv.org/abs/2407.06813",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06813v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06813/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06813v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06813/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06813v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06813/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06813v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06813/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06813v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06813/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06813v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06813/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06813v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06813/x7.png"
      }
    ],
    "abstract_cn": "外交，这一人类社会中的高深活动，涉及多方互动与复杂能力，如社会推理、谈判技巧和长期战略规划。尽管过往AI代理在多代理任务中展现了处理复杂游戏与广阔动作空间的能力，但外交的决策空间尤为庞大，尤其是在谈判阶段。近期，LLM代理虽在某些领域拓展了AI的边界，却仍难以应对复杂多代理环境中的长期规划。我们借助前沿LLM技术，首次尝试探索AI在高度综合多代理任务中的潜力，通过融合三大核心能力，打造更强大的社会代理：战略规划与反思、目标导向的社交谈判、以及通过自我对弈实现的无人在环自进化。",
    "title_cn": "Richelieu：自进化 LLM 驱动的 AI 外交智能体",
    "tags": [
      "Agent",
      "",
      "人工智能"
    ]
  },
  {
    "title": "AnyTaskTune: Advanced Domain-Specific Solutions through Task-Fine-Tuning",
    "submit_datetime": "2024年07月09日",
    "abstract": "The pervasive deployment of Large Language Models-LLMs in various sectors often neglects the nuanced requirements of individuals and small organizations, who benefit more from models precisely tailored to their specific business contexts rather than those with broadly superior general capabilities. This work introduces \\textbf{AnyTaskTune}, a novel fine-tuning methodology coined as \\textbf{Task-Fine-Tune}, specifically developed to elevate model performance on a diverse array of domain-specific tasks. This method involves a meticulous process to identify and define targeted sub-tasks within a domain, followed by the creation of specialized enhancement datasets for fine-tuning, thereby optimizing task-specific model performance. We conducted comprehensive fine-tuning experiments not only in the legal domain for tasks such as keyword extraction and sentence prediction but across over twenty different sub-tasks derived from the domains of finance, healthcare, law, psychology, consumer services, and human resources. To substantiate our approach and facilitate community engagement, we will open-source these bilingual task datasets. Our findings demonstrate that models fine-tuned using the \\textbf{Task-Fine-Tune} methodology not only achieve superior performance on these specific tasks but also significantly outperform models with higher general capabilities in their respective domains. Our work is publicly available at \\url{https://github.com/PandaVT/DataTager}.",
    "pdf_link": "https://arxiv.org/abs/2407.07094",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.07094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07094/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07094/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07094/x3.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLM）在各行业的广泛应用往往忽略了个人和小型组织的精细需求，这些需求更倾向于那些针对其特定业务环境精确定制的模型。为此，我们引入了**AnyTaskTune**，一种名为**任务精细微调**的新颖微调方法，旨在提升模型在多样化的特定领域任务上的性能。该方法通过细致地识别和定义领域内的目标子任务，并创建专门的增强数据集进行微调，从而优化特定任务的模型性能。我们在法律、金融、医疗保健等多个领域进行了全面的微调实验，涵盖了超过二十种不同的子任务。为了证实我们的方法并促进社区参与，我们将开源这些双语任务数据集。研究结果显示，使用**任务精细微调**方法微调的模型不仅在这些特定任务上表现卓越，而且在各自领域内显著优于具有更高通用能力的模型。我们的工作已在[GitHub](https://github.com/PandaVT/DataTager)上公开。",
    "title_cn": "AnyTaskTune：借助任务微调，打造高级领域定制方案",
    "tags": [
      "LLM应用",
      "",
      "医疗保健"
    ]
  },
  {
    "title": "FBI-LLM: Scaling Up Fully Binarized LLMs from Scratch via Autoregressive Distillation",
    "submit_datetime": "2024年07月09日",
    "abstract": "This work presents a Fully BInarized Large Language Model (FBI-LLM), demonstrating for the first time how to train a large-scale binary language model from scratch (not the partial binary or ternary LLM like BitNet b1.58) to match the performance of its full-precision counterparts (e.g., FP16 or BF16) in transformer-based LLMs. It achieves this by employing an autoregressive distillation (AD) loss with maintaining equivalent model dimensions (130M, 1.3B, 7B) and training data volume as regular LLM pretraining, while delivering competitive results in terms of perplexity and task-specific effectiveness. Intriguingly, by analyzing the training trajectory, we find that the pretrained weight is not necessary for training binarized LLMs from scratch. This research encourages a new computational framework and may facilitate the future design of specialized hardware tailored for fully 1-bit LLMs. We make all models, code, and training dataset fully accessible and transparent to support further research (Code: https://github.com/LiqunMa/FBI-LLM. Model: https://huggingface.co/LiqunMa/).",
    "pdf_link": "https://arxiv.org/abs/2407.07093",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.07093v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07093/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07093v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07093/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07093v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07093/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07093v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07093/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07093v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07093/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07093v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07093/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07093v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07093/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07093v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07093/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07093v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07093/x9.png"
      }
    ],
    "abstract_cn": "本研究首次展示了如何从头开始训练全二值化大型语言模型（FBI-LLM），使其性能与基于transformer的全精度LLM相媲美。通过自回归蒸馏损失，我们保持了与常规LLM相同的模型规模和数据量，同时在困惑度和任务效果上表现出色。令人惊讶的是，预训练权重并非训练二值化LLM的必需品。这一发现不仅开启了新的计算框架，还可能推动未来为1位LLM定制硬件的设计。我们公开了所有模型、代码和数据集，以促进更广泛的研究探索。",
    "title_cn": "FBI-LLM：借助自回归蒸馏技术，从零起步全面扩展二值化大型语言模型。",
    "tags": [
      "LLM理论",
      "计算机科学",
      "人工智能"
    ]
  },
  {
    "title": "Adapting LLMs to Hebrew: Unveiling DictaLM 2.0 with Enhanced Vocabulary and Instruction Capabilities",
    "submit_datetime": "2024年07月09日",
    "abstract": "Training large language models (LLMs) in low-resource languages such as Hebrew poses unique challenges. In this paper, we introduce DictaLM2.0 and DictaLM2.0-Instruct, two LLMs derived from the Mistral model, trained on a substantial corpus of approximately 200 billion tokens in both Hebrew and English. Adapting a pre-trained model to a new language involves specialized techniques that differ significantly from training a model from scratch or further training existing models on well-resourced languages such as English. We outline these novel training methodologies, which facilitate effective learning and adaptation to the linguistic properties of Hebrew. Additionally, we fine-tuned DictaLM2.0-Instruct on a comprehensive instruct dataset to enhance its performance on task-specific instructions. To rigorously evaluate our models, we introduce a new benchmark suite for Hebrew LLM evaluation, covering a diverse set of tasks including Question Answering, Sentiment Analysis, Winograd Schema Challenge, Translation, and Summarization. Our work not only addresses the intricacies of training LLMs in low-resource languages but also proposes a framework that can be leveraged for adapting other LLMs to various non-English languages, contributing to the broader field of multilingual NLP.",
    "pdf_link": "https://arxiv.org/abs/2407.07080",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.07080v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07080/dictalm-vocab-extension-graph.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07080v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07080/causal-attention-mask.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07080v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07080/dictalm2.0-train-loss-graph.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07080v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07080/dictalm-leaderboard-screenshot.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07080v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07080/dictalm-human-as-judge-results.png"
      }
    ],
    "abstract_cn": "在希伯来语等低资源语言中训练大型语言模型 (LLM) 充满挑战。本文推出了 DictaLM2.0 和 DictaLM2.0-Instruct，这两款 LLM 基于 Mistral 模型，在包含约 2000 亿词元的希伯来语和英语语料库上进行了训练。将预训练模型适应新语言需要特殊技术，这与从头开始训练或在英语等资源丰富语言上进一步训练现有模型大相径庭。我们详细介绍了这些创新的训练方法，它们有效促进了模型对希伯来语特性的学习和适应。此外，我们还对 DictaLM2.0-Instruct 进行了微调，以提升其处理特定任务指令的能力。为了全面评估我们的模型，我们创建了一套新的希伯来语 LLM 评估基准，涵盖问答、情感分析、Winograd 模式挑战、翻译和摘要等多种任务。我们的研究不仅解决了低资源语言中训练 LLM 的难题，还提出了一种通用框架，可用于将其他 LLM 适应到多种非英语语言，推动了多语言 NLP 领域的发展。",
    "title_cn": "将 LLM 适应于希伯来语：揭秘 DictaLM 2.0，其词汇与指令能力得到增强",
    "tags": [
      "LLM应用",
      "",
      "多语言技术"
    ]
  },
  {
    "title": "Lookback Lens: Detecting and Mitigating Contextual Hallucinations in Large Language Models Using Only Attention Maps",
    "submit_datetime": "2024年07月09日",
    "abstract": "When asked to summarize articles or answer questions given a passage, large language models (LLMs) can hallucinate details and respond with unsubstantiated answers that are inaccurate with respect to the input context. This paper describes a simple approach for detecting such contextual hallucinations. We hypothesize that contextual hallucinations are related to the extent to which an LLM attends to information in the provided context versus its own generations. Based on this intuition, we propose a simple hallucination detection model whose input features are given by the ratio of attention weights on the context versus newly generated tokens (for each attention head). We find that a linear classifier based on these lookback ratio features is as effective as a richer detector that utilizes the entire hidden states of an LLM or a text-based entailment model. The lookback ratio-based detector -- Lookback Lens -- is found to transfer across tasks and even models, allowing a detector that is trained on a 7B model to be applied (without retraining) to a larger 13B model. We further apply this detector to mitigate contextual hallucinations, and find that a simple classifier-guided decoding approach is able to reduce the amount of hallucination, for example by 9.6% in the XSum summarization task.",
    "pdf_link": "https://arxiv.org/abs/2407.07071",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.07071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07071/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07071/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07071/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07071/screenshot.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07071/visualization.png"
      }
    ],
    "abstract_cn": "大型语言模型 (LLM) 在根据文本总结或回答问题时，有时会生成与上下文不符的虚假细节。本文介绍了一种简便的上下文幻觉检测方法。我们推测，幻觉的产生与模型对原始上下文与新生成内容的注意力分配有关。据此，我们设计了一个基于注意力权重比的简单检测模型。实验表明，这种基于回溯比率的检测器（回溯镜头）不仅在不同任务间通用，还能跨模型应用，例如，一个在 7B 模型上训练的检测器可直接用于 13B 模型。此外，通过分类器引导的解码策略，我们成功减少了幻觉现象，如在 XSum 摘要任务中降低了 9.6% 的幻觉率。",
    "title_cn": "Lookback Lens：借助注意力图，我们能检测并缓解大型语言模型中的上下文幻觉问题。",
    "tags": [
      "LLM应用",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Prompting Techniques for Secure Code Generation: A Systematic Investigation",
    "submit_datetime": "2024年07月09日",
    "abstract": "Large Language Models (LLMs) are gaining momentum in software development with prompt-driven programming enabling developers to create code from natural language (NL) instructions. However, studies have questioned their ability to produce secure code and, thereby, the quality of prompt-generated software. Alongside, various prompting techniques that carefully tailor prompts have emerged to elicit optimal responses from LLMs. Still, the interplay between such prompting strategies and secure code generation remains under-explored and calls for further investigations. OBJECTIVE: In this study, we investigate the impact of different prompting techniques on the security of code generated from NL instructions by LLMs. METHOD: First we perform a systematic literature review to identify the existing prompting techniques that can be used for code generation tasks. A subset of these techniques are evaluated on GPT-3, GPT-3.5, and GPT-4 models for secure code generation. For this, we used an existing dataset consisting of 150 NL security-relevant code-generation prompts. RESULTS: Our work (i) classifies potential prompting techniques for code generation (ii) adapts and evaluates a subset of the identified techniques for secure code generation tasks and (iii) observes a reduction in security weaknesses across the tested LLMs, especially after using an existing technique called Recursive Criticism and Improvement (RCI), contributing valuable insights to the ongoing discourse on LLM-generated code security.",
    "pdf_link": "https://arxiv.org/abs/2407.07064",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.07064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07064/slr.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07064/taxonomy.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07064/zero-and-few-shot.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07064/rci-and-progressive-hint.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07064/least-to-most-1-and-2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07064/self-planning-1-and-2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07064/zero-and-cot.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07064/self-consistency-and-explanation.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07064/persona-narrow.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07064/methodology.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07064/heat_map-gpt3-blue.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07064/heat_map-gpt3_5-blue.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07064/heat_map-gpt4-blue.png"
      }
    ],
    "abstract_cn": "随着提示驱动编程的兴起，大型语言模型 (LLM) 在软件开发领域日益受到关注，使开发者能够通过自然语言指令编写代码。然而，这些模型生成安全代码的能力受到质疑，进而影响了提示生成软件的质量。为此，多种精心设计的提示技术应运而生，旨在从 LLM 中获取最佳响应。尽管如此，这些提示策略与安全代码生成之间的关系仍待深入探索。本研究旨在探讨不同提示技术对 LLM 生成的代码安全性的影响。我们首先进行了系统的文献回顾，筛选出适用于代码生成任务的提示技术，并在 GPT-3、GPT-3.5 和 GPT-4 模型上对其进行安全代码生成的评估。通过使用包含 150 个与安全相关的自然语言代码生成提示的数据集，我们的研究发现，通过分类和评估一系列提示技术，特别是在采用递归批评与改进 (RCI) 技术后，显著减少了测试 LLM 中的安全弱点，为 LLM 生成代码安全性的研究提供了重要见解。",
    "title_cn": "探索安全代码生成的提示技术：系统性研究",
    "tags": [
      "LLM应用",
      "软件开发",
      "网络安全"
    ]
  },
  {
    "title": "Exploring Scalability of Self-Training for Open-Vocabulary Temporal Action Localization",
    "submit_datetime": "2024年07月09日",
    "abstract": "The vocabulary size in temporal action localization (TAL) is constrained by the scarcity of large-scale annotated datasets. To address this, recent works incorporate powerful pre-trained vision-language models (VLMs), such as CLIP, to perform open-vocabulary TAL (OV-TAL). However, unlike VLMs trained on extensive image/video-text pairs, existing OV-TAL methods still rely on small, fully labeled TAL datasets for training an action localizer. In this paper, we explore the scalability of self-training with unlabeled YouTube videos for OV-TAL. Our self-training approach consists of two stages. First, a class-agnostic action localizer is trained on a human-labeled TAL dataset and used to generate pseudo-labels for unlabeled videos. Second, the large-scale pseudo-labeled dataset is combined with the human-labeled dataset to train the localizer. Extensive experiments demonstrate that leveraging web-scale videos in self-training significantly enhances the generalizability of an action localizer. Additionally, we highlighted issues with existing OV-TAL evaluation schemes and proposed a new evaluation protocol. Code is released at https://github.com/HYUNJS/STOV-TAL",
    "pdf_link": "https://arxiv.org/abs/2407.07024",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.07024v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07024/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07024v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07024/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07024v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07024/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07024v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07024/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07024v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07024/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07024v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07024/x6.png"
      }
    ],
    "abstract_cn": "时序动作定位 (TAL) 因缺乏大规模标注数据集而受限。为此，我们引入预训练视觉-语言模型 (如 CLIP) 进行开放词汇 TAL (OV-TAL)。但现有方法仍依赖小规模标注数据集。本文探索了利用未标注 YouTube 视频进行自训练的可扩展性，分两阶段：首先，训练类别无关定位器生成伪标签；然后，结合伪标签与标注数据集训练定位器。实验证明，利用网络视频自训练显著提升定位器泛化能力。同时，我们改进了评估方案。代码已发布。",
    "title_cn": "研究自训练方法在开放词汇时间动作定位任务中的扩展能力",
    "tags": [
      "LLM应用",
      "视频分析",
      "人工智能"
    ]
  },
  {
    "title": "Using Large Language Models for Generating Smart Contracts for Health Insurance from Textual Policies",
    "submit_datetime": "2024年07月09日",
    "abstract": "We explore using Large Language Models (LLMs) to generate application code that automates health insurance processes from text-based policies. We target blockchain-based smart contracts as they offer immutability, verifiability, scalability, and a trustless setting: any number of parties can use the smart contracts, and they need not have previously established trust relationships with each other. Our methodology generates outputs at increasing levels of technical detail: (1) textual summaries, (2) declarative decision logic, and (3) smart contract code with unit tests. We ascertain LLMs are good at the task (1), and the structured output is useful to validate tasks (2) and (3). Declarative languages (task 2) are often used to formalize healthcare policies, but their execution on blockchain is non-trivial. Hence, task (3) attempts to directly automate the process using smart contracts. To assess the LLM output, we propose completeness, soundness, clarity, syntax, and functioning code as metrics. Our evaluation employs three health insurance policies (scenarios) with increasing difficulty from Medicare's official booklet. Our evaluation uses GPT-3.5 Turbo, GPT-3.5 Turbo 16K, GPT-4, GPT-4 Turbo and CodeLLaMA. Our findings confirm that LLMs perform quite well in generating textual summaries. Although outputs from tasks (2)-(3) are useful starting points, they require human oversight: in multiple cases, even \"runnable\" code will not yield sound results; the popularity of the target language affects the output quality; and more complex scenarios still seem a bridge too far. Nevertheless, our experiments demonstrate the promise of LLMs for translating textual process descriptions into smart contracts.",
    "pdf_link": "https://arxiv.org/abs/2407.07019",
    "graphs": [],
    "abstract_cn": "我们利用大型语言模型 (LLM) 从文本保险政策中自动生成健康保险流程的应用代码。选择基于区块链的智能合约，因其具备不可变性、可验证性、可扩展性和无需信任的特性。我们的方法分三个层次生成输出：(1) 文本摘要，(2) 声明性决策逻辑，(3) 带单元测试的智能合约代码。LLM 在生成文本摘要方面表现优异，结构化输出对后续验证任务至关重要。声明性语言常用于医疗政策形式化，但在区块链上执行复杂。我们尝试通过智能合约直接自动化流程。评估指标包括完整性、正确性、清晰度、语法和功能代码。实验采用三种难度递增的保险政策场景，涉及多种模型。结果显示，尽管 LLM 在生成摘要方面表现出色，但后续任务仍需人工监督，且复杂场景的挑战依然存在。实验证明了 LLM 在将文本流程转化为智能合约方面的潜力。",
    "title_cn": "利用大型语言模型，从文本政策中生成健康保险的智能合约",
    "tags": [
      "LLM应用",
      "",
      "区块链"
    ]
  },
  {
    "title": "End-To-End Causal Effect Estimation from Unstructured Natural Language Data",
    "submit_datetime": "2024年07月09日",
    "abstract": "Knowing the effect of an intervention is critical for human decision-making, but current approaches for causal effect estimation rely on manual data collection and structuring, regardless of the causal assumptions. This increases both the cost and time-to-completion for studies. We show how large, diverse observational text data can be mined with large language models (LLMs) to produce inexpensive causal effect estimates under appropriate causal assumptions. We introduce NATURAL, a novel family of causal effect estimators built with LLMs that operate over datasets of unstructured text. Our estimators use LLM conditional distributions (over variables of interest, given the text data) to assist in the computation of classical estimators of causal effect. We overcome a number of technical challenges to realize this idea, such as automating data curation and using LLMs to impute missing information. We prepare six (two synthetic and four real) observational datasets, paired with corresponding ground truth in the form of randomized trials, which we used to systematically evaluate each step of our pipeline. NATURAL estimators demonstrate remarkable performance, yielding causal effect estimates that fall within 3 percentage points of their ground truth counterparts, including on real-world Phase 3/4 clinical trials. Our results suggest that unstructured text data is a rich source of causal effect information, and NATURAL is a first step towards an automated pipeline to tap this resource.",
    "pdf_link": "https://arxiv.org/abs/2407.07018",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.07018v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07018/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07018v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07018/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07018v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07018/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07018v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07018/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07018v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07018/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07018v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07018/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07018v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07018/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07018v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07018/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07018v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07018/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07018v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07018/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07018v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07018/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07018v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07018/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07018v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07018/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07018v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07018/x14.png"
      }
    ],
    "abstract_cn": "了解干预效果对决策至关重要，但现有因果效应估计方法依赖手动数据处理，增加了成本和时间。我们利用大型语言模型（LLM）挖掘多样化的文本数据，提出NATURAL，一种新型因果效应估计器，能在非结构化文本上运行，辅助经典因果效应计算。我们克服技术难题，如自动化数据整理和填补信息缺失。通过六个数据集（含随机对照试验），我们系统评估了NATURAL的性能，结果显示其估计值与真实情况高度一致，甚至在III/IV期临床试验中表现优异。这表明非结构化文本数据富含因果信息，NATURAL是开发自动化资源利用管道的关键一步。",
    "title_cn": "从非结构化自然语言数据中进行端到端因果效应估计",
    "tags": [
      "LLM应用",
      "",
      "数据分析"
    ]
  },
  {
    "title": "Is Large Language Model All You Need to Predict the Synthesizability and Precursors of Crystal Structures?",
    "submit_datetime": "2024年07月09日",
    "abstract": "Accessing the synthesizability of crystal structures is pivotal for advancing the practical application of theoretical material structures designed by machine learning or high-throughput screening. However, a significant gap exists between the actual synthesizability and thermodynamic or kinetic stability, which is commonly used for screening theoretical structures for experiments. To address this, we develop the Crystal Synthesis Large Language Models (CSLLM) framework, which includes three LLMs for predicting the synthesizability, synthesis methods, and precursors. We create a comprehensive synthesizability dataset including 140,120 crystal structures and develop an efficient text representation method for crystal structures to fine-tune the LLMs. The Synthesizability LLM achieves a remarkable 98.6% accuracy, significantly outperforming traditional synthesizability screening based on thermodynamic and kinetic stability by 106.1% and 44.5%, respectively. The Methods LLM achieves a classification accuracy of 91.02%, and the Precursors LLM has an 80.2% success rate in predicting synthesis precursors. Furthermore, we develop a user-friendly graphical interface that enables automatic predictions of synthesizability and precursors from uploaded crystal structure files. Through these contributions, CSLLM bridges the gap between theoretical material design and experimental synthesis, paving the way for the rapid discovery of novel and synthesizable functional materials.",
    "pdf_link": "https://arxiv.org/abs/2407.07016",
    "graphs": [],
    "abstract_cn": "为了弥合理论设计与实际合成之间的鸿沟，我们推出了晶体合成大型语言模型（CSLLM）框架。该框架包含三个LLM，分别用于预测晶体结构的合成能力、合成方法和前驱体。我们构建了一个涵盖140,120个晶体结构的详尽数据集，并创新了一种高效的晶体结构文本表示法，以优化LLM性能。合成能力LLM以98.6%的准确率领先，显著超越了传统基于热力学和动力学稳定性的筛选方法。方法LLM分类准确率达91.02%，前驱体LLM在预测前驱体方面成功率为80.2%。此外，我们设计了一个便捷的图形界面，支持从晶体结构文件自动预测合成能力和前驱体，助力新型功能材料的快速发现。",
    "title_cn": "大型语言模型能否独步天下，预测晶体结构的合成潜力及其前驱体？",
    "tags": [
      "LLM应用",
      "材料科学",
      "人工智能"
    ]
  },
  {
    "title": "Induction Heads as an Essential Mechanism for Pattern Matching in In-context Learning",
    "submit_datetime": "2024年07月09日",
    "abstract": "Large language models (LLMs) have shown a remarkable ability to learn and perform complex tasks through in-context learning (ICL). However, a comprehensive understanding of its internal mechanisms is still lacking. This paper explores the role of induction heads in a few-shot ICL setting. We analyse two state-of-the-art models, Llama-3-8B and InternLM2-20B on abstract pattern recognition and NLP tasks. Our results show that even a minimal ablation of induction heads leads to ICL performance decreases of up to ~32% for abstract pattern recognition tasks, bringing the performance close to random. For NLP tasks, this ablation substantially decreases the model's ability to benefit from examples, bringing few-shot ICL performance close to that of zero-shot prompts. We further use attention knockout to disable specific induction patterns, and present fine-grained evidence for the role that the induction mechanism plays in ICL.",
    "pdf_link": "https://arxiv.org/abs/2407.07011",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/pfx_copying.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/pfx_matching_mean-Llama.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/Heatmap_NLP_adjusted.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/Llama_SUL.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/InternLM_SUL.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_4_layer_15_head_30_token_64.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_4_layer_15_head_30_token_61.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/pfx_matching_mean-InternLM.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_1_layer_2_head_22_token_62.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_1_layer_2_head_22_token_64.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_1_layer_8_head_1_token_62.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_1_layer_8_head_1_token_64.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_1_layer_15_head_1_token_62.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_1_layer_15_head_1_token_64.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_1_layer_15_head_30_token_62.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_1_layer_15_head_30_token_64.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_1_layer_16_head_20_token_62.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_1_layer_16_head_20_token_64.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_2_layer_2_head_22_token_58.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_2_layer_2_head_22_token_60.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_2_layer_8_head_1_token_58.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_2_layer_8_head_1_token_60.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_2_layer_15_head_1_token_58.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_2_layer_15_head_1_token_60.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_2_layer_15_head_30_token_58.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_2_layer_15_head_30_token_60.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_2_layer_16_head_20_token_58.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_2_layer_16_head_20_token_60.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_3_layer_2_head_22_token_63.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_3_layer_2_head_22_token_65.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_3_layer_8_head_1_token_63.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_3_layer_8_head_1_token_65.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_3_layer_15_head_1_token_63.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_3_layer_15_head_1_token_65.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_3_layer_15_head_30_token_63.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_3_layer_15_head_30_token_65.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_3_layer_16_head_20_token_63.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_3_layer_16_head_20_token_65.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_4_layer_2_head_22_token_61.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_4_layer_2_head_22_token_64.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_4_layer_8_head_1_token_61.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_4_layer_8_head_1_token_64.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_4_layer_15_head_1_token_61.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_4_layer_15_head_1_token_64.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_4_layer_15_head_30_token_61.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_4_layer_15_head_30_token_64.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_5_layer_2_head_22_token_62.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_5_layer_2_head_22_token_64.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_5_layer_8_head_1_token_62.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_5_layer_8_head_1_token_62.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_5_layer_15_head_1_token_62.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_5_layer_15_head_1_token_64.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_5_layer_15_head_30_token_62.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_5_layer_15_head_30_token_64.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_5_layer_16_head_20_token_62.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_5_layer_16_head_20_token_64.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_1_layer_2_head_22_token_147.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_1_layer_2_head_22_token_150.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_1_layer_8_head_1_token_147.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_1_layer_8_head_1_token_150.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_1_layer_15_head_1_token_147.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_1_layer_15_head_1_token_150.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_1_layer_15_head_30_token_147.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_1_layer_15_head_30_token_150.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_1_layer_16_head_20_token_147.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_1_layer_16_head_20_token_150.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_2_layer_2_head_22_token_147.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_2_layer_2_head_22_token_149.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_2_layer_8_head_1_token_147.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_2_layer_8_head_1_token_149.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_2_layer_15_head_1_token_147.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_2_layer_15_head_1_token_149.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_2_layer_15_head_30_token_147.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_2_layer_15_head_30_token_149.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_2_layer_16_head_20_token_147.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_2_layer_16_head_20_token_149.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_3_layer_2_head_22_token_152.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_3_layer_2_head_22_token_155.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_3_layer_8_head_1_token_152.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_3_layer_8_head_1_token_155.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_3_layer_15_head_1_token_152.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_3_layer_15_head_1_token_155.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_3_layer_15_head_30_token_152.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_3_layer_15_head_30_token_155.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_3_layer_16_head_20_token_152.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_3_layer_16_head_20_token_155.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_4_layer_2_head_22_token_147.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_4_layer_2_head_22_token_149.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_4_layer_8_head_1_token_147.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_4_layer_8_head_1_token_149.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_4_layer_15_head_1_token_147.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_4_layer_15_head_1_token_149.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_4_layer_15_head_30_token_147.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_4_layer_15_head_30_token_149.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_4_layer_16_head_20_token_147.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_4_layer_16_head_20_token_149.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_5_layer_2_head_22_token_150.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_5_layer_2_head_22_token_152.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_5_layer_8_head_1_token_150.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_5_layer_8_head_1_token_152.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_5_layer_15_head_1_token_150.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_5_layer_15_head_1_token_152.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_5_layer_15_head_30_token_150.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_5_layer_15_head_30_token_152.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_5_layer_16_head_20_token_150.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07011v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07011/plot_5_layer_16_head_20_token_152.png"
      }
    ],
    "abstract_cn": "大型语言模型 (LLM) 通过 in-context learning (ICL) 展现了出色的学习和执行复杂任务的能力。然而，其内部机制的全面理解仍有待深入。本文深入探讨了 few-shot ICL 中 induction heads 的关键作用。我们针对 Llama-3-8B 和 InternLM2-20B 这两大顶尖模型，在抽象模式识别和 NLP 任务上进行了细致分析。结果表明，即便轻微调整 induction heads，也会导致抽象模式识别任务的 ICL 性能大幅下滑至接近随机水平，高达 ~32%。在 NLP 任务中，这种调整同样显著削弱了模型从示例中学习的能力，使得 few-shot ICL 性能与零-shot prompts 相当。此外，我们通过 attention knockout 技术，精准禁用特定 induction 模式，从而揭示了 induction 机制在 ICL 中的具体作用。",
    "title_cn": "诱导头：上下文学习中模式匹配的核心机制",
    "tags": [
      "LLM理论",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Metron: Holistic Performance Evaluation Framework for LLM Inference Systems",
    "submit_datetime": "2024年07月09日",
    "abstract": "Serving large language models (LLMs) in production can incur substantial costs, which has prompted recent advances in inference system optimizations. Today, these systems are evaluated against conventional latency and throughput metrics (eg. TTFT, TBT, Normalised Latency and TPOT). However, these metrics fail to fully capture the nuances of LLM inference, leading to an incomplete assessment of user-facing performance crucial for real-time applications such as chat and translation. In this paper, we first identify the pitfalls of current performance metrics in evaluating LLM inference systems. We then propose Metron, a comprehensive performance evaluation framework that includes fluidity-index -- a novel metric designed to reflect the intricacies of the LLM inference process and its impact on real-time user experience. Finally, we evaluate various existing open-source platforms and model-as-a-service offerings using Metron, discussing their strengths and weaknesses. Metron is available at https://github.com/project-metron/metron.",
    "pdf_link": "https://arxiv.org/abs/2407.07000",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.07000v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07000/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07000v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07000/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07000v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07000/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07000v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07000/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07000v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07000/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07000v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07000/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07000v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07000/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07000v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07000/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07000v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07000/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07000v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07000/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07000v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07000/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07000v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07000/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07000v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07000/x13.png"
      }
    ],
    "abstract_cn": "在生产环境中部署 LLM 成本高昂，推动了推理系统优化的发展。然而，现有评估指标（如 TTFT、TBT 等）未能全面反映 LLM 推理的复杂性，导致实时应用（如聊天和翻译）的用户体验评估不完整。本文首先揭示了当前评估指标的不足，随后提出 Metron 框架，引入流动性指数这一新指标，更精准地衡量 LLM 推理对用户体验的影响。最后，我们利用 Metron 对多个开源平台和模型服务进行了评估，并分析了各自的优劣。Metron 框架已开放源代码，供业界参考使用。",
    "title_cn": "Metron：全面评估 LLM 推理系统性能的框架",
    "tags": [
      "LLM应用",
      "软件开发",
      "用户体验"
    ]
  },
  {
    "title": "Robust Neural Information Retrieval: An Adversarial and Out-of-distribution Perspective",
    "submit_datetime": "2024年07月09日",
    "abstract": "Recent advances in neural information retrieval (IR) models have significantly enhanced their effectiveness over various IR tasks. The robustness of these models, essential for ensuring their reliability in practice, has also garnered significant attention. With a wide array of research on robust IR being proposed, we believe it is the opportune moment to consolidate the current status, glean insights from existing methodologies, and lay the groundwork for future development. We view the robustness of IR to be a multifaceted concept, emphasizing its necessity against adversarial attacks, out-of-distribution (OOD) scenarios and performance variance. With a focus on adversarial and OOD robustness, we dissect robustness solutions for dense retrieval models (DRMs) and neural ranking models (NRMs), respectively, recognizing them as pivotal components of the neural IR pipeline. We provide an in-depth discussion of existing methods, datasets, and evaluation metrics, shedding light on challenges and future directions in the era of large language models. To the best of our knowledge, this is the first comprehensive survey on the robustness of neural IR models, and we will also be giving our first tutorial presentation at SIGIR 2024 \\url{https://sigir2024-robust-information-retrieval.github.io}. Along with the organization of existing work, we introduce a Benchmark for robust IR (BestIR), a heterogeneous evaluation benchmark for robust neural information retrieval, which is publicly available at \\url{https://github.com/Davion-Liu/BestIR}. We hope that this study provides useful clues for future research on the robustness of IR models and helps to develop trustworthy search engines \\url{https://github.com/Davion-Liu/Awesome-Robustness-in-Information-Retrieval}.",
    "pdf_link": "https://arxiv.org/abs/2407.06992",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06992v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06992/publications.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06992v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06992/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06992v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06992/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06992v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06992/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06992v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06992/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06992v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06992/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06992v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06992/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06992v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06992/x7.png"
      }
    ],
    "abstract_cn": "神经信息检索模型在多种任务中的效能因最新进展而大幅提升，但其鲁棒性，即在实际应用中的可靠性，同样备受瞩目。当前，我们正处在一个整合现有研究、汲取经验并为未来铺路的黄金时期。鲁棒性不仅关乎模型抵御攻击的能力，还涉及其在分布外场景和性能波动中的表现。我们深入探讨了密集检索与神经排序模型在对抗与分布外情境下的鲁棒性策略，并详细分析了现有方法、数据集及评估标准，为大语言模型时代指明了前进方向。这是首次对神经IR模型鲁棒性进行的全面调查，我们将在SIGIR 2024上首次展示相关教程。此外，我们推出了鲁棒IR的异构评估基准BestIR，旨在为未来研究提供助力，推动可信赖搜索引擎的发展。",
    "title_cn": "从对抗与分布外视角探讨鲁棒神经信息检索",
    "tags": [
      "LLM应用",
      "搜索引擎",
      "信息检索"
    ]
  },
  {
    "title": "Segment-Based Interactive Machine Translation for Pre-trained Models",
    "submit_datetime": "2024年07月09日",
    "abstract": "Pre-trained large language models (LLM) are starting to be widely used in many applications. In this work, we explore the use of these models in interactive machine translation (IMT) environments. In particular, we have chosen mBART (multilingual Bidirectional and Auto-Regressive Transformer) and mT5 (multilingual Text-to-Text Transfer Transformer) as the LLMs to perform our experiments. The system generates perfect translations interactively using the feedback provided by the user at each iteration. The Neural Machine Translation (NMT) model generates a preliminary hypothesis with the feedback, and the user validates new correct segments and performs a word correction--repeating the process until the sentence is correctly translated. We compared the performance of mBART, mT5, and a state-of-the-art (SoTA) machine translation model on a benchmark dataset regarding user effort, Word Stroke Ratio (WSR), Key Stroke Ratio (KSR), and Mouse Action Ratio (MAR). The experimental results indicate that mBART performed comparably with SoTA models, suggesting that it is a viable option for this field of IMT. The implications of this finding extend to the development of new machine translation models for interactive environments, as it indicates that some novel pre-trained models exhibit SoTA performance in this domain, highlighting the potential benefits of adapting these models to specific needs.",
    "pdf_link": "https://arxiv.org/abs/2407.06990",
    "graphs": [],
    "abstract_cn": "预训练的大型语言模型 (LLM) 正逐渐在众多应用中得到广泛应用。本研究聚焦于这些模型在交互式机器翻译 (IMT) 环境中的应用，特别选用了 mBART 和 mT5 进行实验。系统通过用户反馈，在每次交互中生成精准翻译。神经机器翻译 (NMT) 模型依据反馈提出初步翻译假设，用户则验证并修正单词，直至翻译准确无误。我们在基准数据集上对比了 mBART、mT5 与最先进 (SoTA) 机器翻译模型的性能，评估了用户努力、单词敲击比 (WSR)、关键敲击比 (KSR) 和鼠标动作比 (MAR)。实验显示，mBART 性能与 SoTA 模型不相上下，表明其在 IMT 领域具有应用潜力。这一发现还启示我们，为交互式环境开发新机器翻译模型时，应考虑利用这些预训练模型，它们在特定领域展现出与 SoTA 相当的性能，凸显了定制化调整的潜在优势。",
    "title_cn": "预训练模型中的基于片段的交互式机器翻译",
    "tags": [
      "LLM应用",
      "机器翻译",
      "交互式系统"
    ]
  },
  {
    "title": "Listen and Speak Fairly: A Study on Semantic Gender Bias in Speech Integrated Large Language Models",
    "submit_datetime": "2024年07月09日",
    "abstract": "Speech Integrated Large Language Models (SILLMs) combine large language models with speech perception to perform diverse tasks, such as emotion recognition to speaker verification, demonstrating universal audio understanding capability. However, these models may amplify biases present in training data, potentially leading to biased access to information for marginalized groups. This work introduces a curated spoken bias evaluation toolkit and corresponding dataset. We evaluate gender bias in SILLMs across four semantic-related tasks: speech-to-text translation (STT), spoken coreference resolution (SCR), spoken sentence continuation (SSC), and spoken question answering (SQA). Our analysis reveals that bias levels are language-dependent and vary with different evaluation methods. Our findings emphasize the necessity of employing multiple approaches to comprehensively assess biases in SILLMs, providing insights for developing fairer SILLM systems.",
    "pdf_link": "https://arxiv.org/abs/2407.06957",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06957v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06957/speech_llm_bias.png"
      }
    ],
    "abstract_cn": "SILLMs 通过结合大型语言模型与语音感知，展现了强大的通用音频理解能力，能执行从情感识别到说话者验证的多样任务。然而，这些模型可能加剧训练数据中的偏见，影响边缘化群体的信息获取。为此，我们开发了一套精选的口语偏见评估工具包及数据集，并在四个语义相关任务中检测了性别偏见。研究发现，偏见程度与语言及评估方法密切相关。这些发现强调了多角度评估 SILLMs 偏见的重要性，为构建更公平的语音集成模型提供了指导。",
    "title_cn": "倾听与公平发声：探究语音集成大型语言模型中的性别语义偏见",
    "tags": [
      "LLM应用",
      "语音技术",
      "人工智能"
    ]
  },
  {
    "title": "ICLGuard: Controlling In-Context Learning Behavior for Applicability Authorization",
    "submit_datetime": "2024年07月09日",
    "abstract": "In-context learning (ICL) is a recent advancement in the capabilities of large language models (LLMs). This feature allows users to perform a new task without updating the model. Concretely, users can address tasks during the inference time by conditioning on a few input-label pair demonstrations along with the test input. It is different than the conventional fine-tuning paradigm and offers more flexibility. However, this capability also introduces potential issues. For example, users may use the model on any data without restriction, such as performing tasks with improper or sensitive content, which might violate the model policy or conflict with the model owner's interests. As a model owner, it is crucial to establish a mechanism to control the model's behavior under ICL, depending on the model owner's requirements for various content. To this end, we introduce the concept of \"applicability authorization\" tailored for LLMs, particularly for ICL behavior, and propose a simple approach, ICLGuard. It is a fine-tuning framework designed to allow the model owner to regulate ICL behavior on different data. ICLGuard preserves the original LLM and fine-tunes only a minimal set of additional trainable parameters to \"guard\" the LLM. Empirical results show that the guarded LLM can deactivate its ICL ability on target data without affecting its ICL ability on other data and its general functionality across all data.",
    "pdf_link": "https://arxiv.org/abs/2407.06955",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06955v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06955/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06955v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06955/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06955v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06955/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06955v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06955/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06955v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06955/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06955v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06955/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06955v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06955/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06955v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06955/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06955v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06955/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06955v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06955/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06955v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06955/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06955v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06955/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06955v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06955/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06955v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06955/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06955v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06955/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06955v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06955/x16.png"
      }
    ],
    "abstract_cn": "ICL 是 LLM 的一项创新功能，允许用户无需更新模型即可执行新任务。用户通过结合少量示例和测试输入，在推理时完成任务，这种方式比传统微调更灵活。但这也带来了风险，如用户可能无限制地使用模型处理敏感内容，这可能违反政策或损害所有者利益。因此，我们提出了“适用性授权”概念和 ICLGuard 框架，帮助模型所有者控制 ICL 行为。ICLGuard 通过微调少量参数，确保 LLM 在特定数据上停用 ICL 功能，同时不影响其在其他数据上的表现和整体性能。",
    "title_cn": "ICLGuard：调控 In-Context Learning 行为，确保适用性授权",
    "tags": [
      "LLM应用",
      "人工智能",
      "网络安全"
    ]
  },
  {
    "title": "Domain theory in univalent foundations I: Directed complete posets and Scott's $D_\\infty$",
    "submit_datetime": "2024年07月09日",
    "abstract": "We develop domain theory in constructive and predicative univalent foundations (also known as homotopy type theory). That we work predicatively means that we do not assume Voevodsky's propositional resizing axioms. Our work is constructive in the sense that we do not rely on excluded middle or the axiom of (countable) choice. Domain theory studies so-called directed complete posets (dcpos) and Scott continuous maps between them and has applications in a variety of fields, such as programming language semantics, higher-type computability and topology. A common approach to deal with size issues in a predicative foundation is to work with information systems, abstract bases or formal topologies rather than dcpos, and approximable relations rather than Scott continuous functions. In our type-theoretic approach, we instead accept that dcpos may be large and work with type universes to account for this. A priori one might expect that iterative constructions of dcpos may result in a need for ever-increasing universes and are predicatively impossible. We show, through a careful tracking of type universe parameters, that such constructions can be carried out in a predicative setting. In particular, we give a predicative reconstruction of Scott's $D_\\infty$ model of the untyped $λ$-calculus. Our work is formalised in the Agda proof assistant and its ability to infer universe levels has been invaluable for our purposes.",
    "pdf_link": "https://arxiv.org/abs/2407.06952",
    "graphs": [],
    "abstract_cn": "我们基于构造性和预测性一致基础（即同伦类型理论）开发了领域理论。我们不采用Voevodsky的命题大小调整公理，也不依赖排中律或选择公理，确保了工作的构造性。领域理论专注于有向完全偏序集（dcpos）及其间的Scott连续映射，广泛应用于编程语言语义、高类型可计算性和拓扑学等领域。在预测性基础中，我们通常采用信息系统、抽象基或形式拓扑来处理大小问题，而非直接使用dcpos和Scott连续函数。然而，在我们的类型理论方法中，我们承认dcpos可能规模庞大，并利用类型宇宙来应对这一挑战。尽管先验上可能认为dcpos的迭代构造需要不断扩大的宇宙，且在预测性上难以实现，但我们通过精确追踪类型宇宙参数，证明了这类构造在预测性环境中是可行的。特别是，我们成功地在预测性框架下重建了Scott的$D_\\infty$模型，该模型用于未类型化的$λ$-演算。这一成果在Agda证明助手中得到了形式化，其自动推断宇宙级别的功能对我们的研究至关重要。",
    "title_cn": "一致性基础中的域理论 I：探讨有向完备偏序集与 Scott 的 $D_\\infty$",
    "tags": [
      "LLM理论",
      "编程语言",
      "拓扑学"
    ]
  },
  {
    "title": "Audio-Language Datasets of Scenes and Events: A Survey",
    "submit_datetime": "2024年07月09日",
    "abstract": "Audio-language models (ALMs) process sounds to provide a linguistic description of sound-producing events and scenes. Recent advances in computing power and dataset creation have led to significant progress in this domain. This paper surveys existing datasets used for training audio-language models, emphasizing the recent trend towards using large, diverse datasets to enhance model performance. Key sources of these datasets include the Freesound platform and AudioSet that have contributed to the field's rapid growth. Although prior surveys primarily address techniques and training details, this survey categorizes and evaluates a wide array of datasets, addressing their origins, characteristics, and use cases. It also performs a data leak analysis to ensure dataset integrity and mitigate bias between datasets. This survey was conducted by analyzing research papers up to and including December 2023, and does not contain any papers after that period.",
    "pdf_link": "https://arxiv.org/abs/2407.06947",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06947v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06947/Encoder-Decoder.drawio.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06947v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06947/Prefix-Model.drawio.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06947v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06947/Zero-shot.drawio.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06947v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06947/combined_pca_plots_labels_1.09_noaudioset.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06947v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06947/heatmap_audio_labels_distances.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06947v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06947/heatmap_text_labels_distances.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06947v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06947/combined_pca_plots_categories_bar.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06947v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06947/heatmap_mel3.png"
      }
    ],
    "abstract_cn": "音频-语言模型 (ALM) 通过处理声音，为声音产生的事件和场景提供语言描述。随着计算能力的提升和数据集的丰富，这一领域取得了显著进展。本文聚焦于训练 ALM 所用的数据集，特别强调了利用大型、多样化数据集提升模型性能的趋势。Freesound 平台和 AudioSet 等关键资源，推动了该领域的迅猛发展。与以往侧重技术与训练细节的调查不同，本文对众多数据集进行了细致的分类与评估，涵盖其来源、特性及应用场景。此外，还进行了数据泄露分析，以确保数据集的完整性并减少偏差。本调查基于截至 2023 年 12 月的研究论文，未涉及此后发表的文献。",
    "title_cn": "场景与事件的音-语数据集综述",
    "tags": [
      "LLM应用",
      "音频处理",
      "数据科学"
    ]
  },
  {
    "title": "Who is better at math, Jenny or Jingzhen? Uncovering Stereotypes in Large Language Models",
    "submit_datetime": "2024年07月09日",
    "abstract": "Large language models (LLMs) have been shown to propagate and amplify harmful stereotypes, particularly those that disproportionately affect marginalised communities. To understand the effect of these stereotypes more comprehensively, we introduce GlobalBias, a dataset of 876k sentences incorporating 40 distinct gender-by-ethnicity groups alongside descriptors typically used in bias literature, which enables us to study a broad set of stereotypes from around the world. We use GlobalBias to directly probe a suite of LMs via perplexity, which we use as a proxy to determine how certain stereotypes are represented in the model's internal representations. Following this, we generate character profiles based on given names and evaluate the prevalence of stereotypes in model outputs. We find that the demographic groups associated with various stereotypes remain consistent across model likelihoods and model outputs. Furthermore, larger models consistently display higher levels of stereotypical outputs, even when explicitly instructed not to.",
    "pdf_link": "https://arxiv.org/abs/2407.06917",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06917v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06917/x1.png"
      }
    ],
    "abstract_cn": "大型语言模型 (LLM) 已被证实会传播和放大有害的刻板印象，尤其是那些不成比例地影响边缘化群体的刻板印象。为了更全面地理解这些刻板印象的影响，我们引入了 GlobalBias 数据集，该数据集包含 876k 个句子，涵盖 40 个不同的性别-种族群体及偏见文献中常用的描述符，使我们能够研究全球范围内的广泛刻板印象。我们通过困惑度直接探测一系列 LLM，以此作为代理来确定某些刻板印象在模型的内部表示中的表现方式。接着，我们根据给定的名字生成角色简介，并评估模型输出中刻板印象的普遍性。研究发现，与各种刻板印象相关的群体在模型概率和模型输出中保持一致。此外，更大的模型即使在明确指示不要这样做的情况下，也始终显示出更高水平的刻板印象输出。",
    "title_cn": "Jenny 和 Jingzhen，谁在数学上更胜一筹？探索大型语言模型中的刻板印象。",
    "tags": [
      "LLM应用",
      "社会科学",
      "人工智能伦理"
    ]
  },
  {
    "title": "Divine LLaMAs: Bias, Stereotypes, Stigmatization, and Emotion Representation of Religion in Large Language Models",
    "submit_datetime": "2024年07月09日",
    "abstract": "Emotions play important epistemological and cognitive roles in our lives, revealing our values and guiding our actions. Previous work has shown that LLMs display biases in emotion attribution along gender lines. However, unlike gender, which says little about our values, religion, as a socio-cultural system, prescribes a set of beliefs and values for its followers. Religions, therefore, cultivate certain emotions. Moreover, these rules are explicitly laid out and interpreted by religious leaders. Using emotion attribution, we explore how different religions are represented in LLMs. We find that: Major religions in the US and European countries are represented with more nuance, displaying a more shaded model of their beliefs. Eastern religions like Hinduism and Buddhism are strongly stereotyped. Judaism and Islam are stigmatized -- the models' refusal skyrocket. We ascribe these to cultural bias in LLMs and the scarcity of NLP literature on religion. In the rare instances where religion is discussed, it is often in the context of toxic language, perpetuating the perception of these religions as inherently toxic. This finding underscores the urgent need to address and rectify these biases. Our research underscores the crucial role emotions play in our lives and how our values influence them.",
    "pdf_link": "https://arxiv.org/abs/2407.06908",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06908v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06908/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06908v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06908/llama2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06908v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06908/llama3_mistral_gpt4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06908v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06908/llama2_family.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06908v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06908/llama3_family.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06908v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06908/practicing_muslim_khawf.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06908v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06908/khushu.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06908v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06908/mistral_v03.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06908v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06908/gpt4.png"
      }
    ],
    "abstract_cn": "情感不仅揭示我们的价值观，还指导我们的行动，在我们的生活中扮演着至关重要的角色。研究发现，LLMs在情感归属上存在性别偏见，而宗教作为社会文化体系，为其追随者规定了信仰和价值观，培养特定情感。我们通过情感归属分析了LLMs中不同宗教的表现，发现美国和欧洲的主要宗教表现出更多细微差别，而东方宗教如印度教和佛教则被刻板化，犹太教和伊斯兰教则被污名化。这归因于LLMs中的文化偏见和关于宗教的NLP文献稀缺。在极少数讨论宗教的情况下，它往往与有毒语言相关联，加剧了这些宗教本质上是有毒的看法。这一发现强调了迫切需要解决和纠正这些偏见。我们的研究再次证明了情感在我们生活中的关键作用以及我们的价值观如何影响它们。",
    "title_cn": "大型语言模型中的宗教：探讨其偏见、刻板印象、污名化及情感表达",
    "tags": [
      "LLM应用",
      "",
      "社会文化"
    ]
  },
  {
    "title": "Learning From Crowdsourced Noisy Labels: A Signal Processing Perspective",
    "submit_datetime": "2024年07月09日",
    "abstract": "One of the primary catalysts fueling advances in artificial intelligence (AI) and machine learning (ML) is the availability of massive, curated datasets. A commonly used technique to curate such massive datasets is crowdsourcing, where data are dispatched to multiple annotators. The annotator-produced labels are then fused to serve downstream learning and inference tasks. This annotation process often creates noisy labels due to various reasons, such as the limited expertise, or unreliability of annotators, among others. Therefore, a core objective in crowdsourcing is to develop methods that effectively mitigate the negative impact of such label noise on learning tasks. This feature article introduces advances in learning from noisy crowdsourced labels. The focus is on key crowdsourcing models and their methodological treatments, from classical statistical models to recent deep learning-based approaches, emphasizing analytical insights and algorithmic developments. In particular, this article reviews the connections between signal processing (SP) theory and methods, such as identifiability of tensor and nonnegative matrix factorization, and novel, principled solutions of longstanding challenges in crowdsourcing -- showing how SP perspectives drive the advancements of this field. Furthermore, this article touches upon emerging topics that are critical for developing cutting-edge AI/ML systems, such as crowdsourcing in reinforcement learning with human feedback (RLHF) and direct preference optimization (DPO) that are key techniques for fine-tuning large language models (LLMs).",
    "pdf_link": "https://arxiv.org/abs/2407.06902",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06902v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06902/single_stage_2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06902v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06902/e2e_2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06902v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06902/ds_model.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06902v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06902/seq_model.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06902v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06902/dep_model.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06902v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06902/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06902v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06902/e2e_result.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06902v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06902/ccem.png"
      }
    ],
    "abstract_cn": "AI与ML的迅猛发展得益于海量精选数据集的普及。众包作为一种常见手段，将数据分发给众多标注者，其产出标签随后融合，支撑下游学习与推理任务。然而，由于标注者专业性或可靠性不足等原因，此过程常产生噪声标签。因此，众包的核心任务之一便是研发策略，有效缓解标签噪声对学习任务的负面影响。本文聚焦于从噪声众包标签中学习的最新进展，涵盖从经典统计模型到深度学习方法的关键众包模型及其方法论，强调分析洞察与算法创新。特别地，本文探讨了信号处理理论与方法，如张量与非负矩阵分解的可识别性，以及针对众包长期难题的新颖解决方案，揭示了信号处理视角如何引领该领域的前进。同时，本文还触及了强化学习中的人类反馈（RLHF）与直接偏好优化（DPO）等前沿议题，这些技术对于微调大型语言模型（LLMs）至关重要。",
    "title_cn": "众包噪声标签学习：信号处理新视角",
    "tags": [
      "LLM应用",
      "人工智能",
      "机器学习"
    ]
  },
  {
    "title": "Measuring Sustainability Intention of ESG Fund Disclosure using Few-Shot Learning",
    "submit_datetime": "2024年07月09日",
    "abstract": "Global sustainable fund universe encompasses open-end funds and exchange-traded funds (ETF) that, by prospectus or other regulatory filings, claim to focus on Environment, Social and Governance (ESG). Challengingly, the claims can only be confirmed by examining the textual disclosures to check if there is presence of intentionality and ESG focus on its investment strategy. Currently, there is no regulation to enforce sustainability in ESG products space. This paper proposes a unique method and system to classify and score the fund prospectuses in the sustainable universe regarding specificity and transparency of language. We aim to employ few-shot learners to identify specific, ambiguous, and generic sustainable investment-related language. Additionally, we construct a ratio metric to determine language score and rating to rank products and quantify sustainability claims for US sustainable universe. As a by-product, we publish manually annotated quality training dataset on Hugging Face (ESG-Prospectus-Clarity-Category under cc-by-nc-sa-4.0) of more than 1K ESG textual statements. The performance of the few-shot finetuning approach is compared with zero-shot models e.g., Llama-13B, GPT 3.5 Turbo etc. We found that prompting large language models are not accurate for domain specific tasks due to misalignment issues. The few-shot finetuning techniques outperform zero-shot models by large margins of more than absolute ~30% in precision, recall and F1 metrics on completely unseen ESG languages (test set). Overall, the paper attempts to establish a systematic and scalable approach to measure and rate sustainability intention quantitatively for sustainable funds using texts in prospectus. Regulatory bodies, investors, and advisors may utilize the findings of this research to reduce cognitive load in investigating or screening of ESG funds which accurately reflects the ESG intention.",
    "pdf_link": "https://arxiv.org/abs/2407.06893",
    "graphs": [],
    "abstract_cn": "全球可持续基金领域涵盖了声称专注于环境、社会和治理（ESG）的开放式基金和交易所交易基金（ETF）。然而，这些声明的真实性需通过文本披露的审查来验证。目前，ESG产品领域缺乏强制性的可持续性法规。本文提出了一种新颖的方法和系统，旨在通过分析招股说明书中的语言具体性和透明度，对可持续基金进行分类和评分。我们利用少量样本学习技术，识别与可持续投资相关的具体、模糊或通用语言，并构建比率指标来评分和评级，以量化可持续性声明并优化产品排名。此外，我们在Hugging Face上发布了超过1K的ESG文本声明的手动注释数据集，供研究使用。实验表明，少量样本微调技术在处理未见过的ESG语言时，性能显著优于零样本模型。本文旨在为可持续基金的可持续性意图提供一种量化评估的系统化方法，帮助监管机构、投资者和顾问更有效地筛选和评估ESG基金。",
    "title_cn": "通过 Few-Shot Learning 评估 ESG 基金披露的可持续性意图",
    "tags": [
      "LLM应用",
      "",
      "可持续发展"
    ]
  },
  {
    "title": "Beyond Aesthetics: Cultural Competence in Text-to-Image Models",
    "submit_datetime": "2024年07月09日",
    "abstract": "Text-to-Image (T2I) models are being increasingly adopted in diverse global communities where they create visual representations of their unique cultures. Current T2I benchmarks primarily focus on faithfulness, aesthetics, and realism of generated images, overlooking the critical dimension of cultural competence. In this work, we introduce a framework to evaluate cultural competence of T2I models along two crucial dimensions: cultural awareness and cultural diversity, and present a scalable approach using a combination of structured knowledge bases and large language models to build a large dataset of cultural artifacts to enable this evaluation. In particular, we apply this approach to build CUBE (CUltural BEnchmark for Text-to-Image models), a first-of-its-kind benchmark to evaluate cultural competence of T2I models. CUBE covers cultural artifacts associated with 8 countries across different geo-cultural regions and along 3 concepts: cuisine, landmarks, and art. CUBE consists of 1) CUBE-1K, a set of high-quality prompts that enable the evaluation of cultural awareness, and 2) CUBE-CSpace, a larger dataset of cultural artifacts that serves as grounding to evaluate cultural diversity. We also introduce cultural diversity as a novel T2I evaluation component, leveraging quality-weighted Vendi score. Our evaluations reveal significant gaps in the cultural awareness of existing models across countries and provide valuable insights into the cultural diversity of T2I outputs for under-specified prompts. Our methodology is extendable to other cultural regions and concepts, and can facilitate the development of T2I models that better cater to the global population.",
    "pdf_link": "https://arxiv.org/abs/2407.06863",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06863v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06863/figure-motivation-final.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.06863v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06863/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06863v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06863/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06863v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06863/UI_image.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06863v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06863/results_spider_hpsv2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06863v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06863/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06863v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06863/results_imagen_sensitivity.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.06863v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06863/Imagen-WorldMap.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06863v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06863/SDXL-WorldMap.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06863v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06863/PlayGround-WorldMap.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06863v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06863/RealVis-WorldMap.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06863v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06863/Imagen-landmark-WorldMap.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06863v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06863/SDXL-landmark-WorldMap.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06863v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06863/PlayGround-landmark-WorldMap.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06863v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06863/RealVis-landmark-WorldMap.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06863v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06863/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06863v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06863/x5.png"
      }
    ],
    "abstract_cn": "文本到图像（T2I）模型在全球多元社区中日益流行，它们为各自独特的文化创造了视觉表现。然而，当前的T2I基准主要关注生成图像的忠实度、美学和真实感，却忽视了文化能力这一关键维度。为此，我们引入了一个框架，用于评估T2I模型在文化意识和文化多样性这两个关键维度上的文化能力，并提出了一种可扩展的方法，结合结构化知识库和大型语言模型构建了一个大型文化文物数据集，以支持这种评估。特别是，我们应用这种方法构建了CUBE（文本到图像模型的文化基准），这是首个评估T2I模型文化能力的基准。CUBE涵盖了与8个不同地理文化区域的国家的文化文物，涉及三个概念：美食、地标和艺术。CUBE包括1）CUBE-1K，一组高质量的提示，用于评估文化意识；2）CUBE-CSpace，一个更大的文化文物数据集，用于评估文化多样性。我们还引入了文化多样性作为T2I评估的新组件，利用质量加权的Vendi得分。我们的评估揭示了现有模型在各国文化意识方面的显著差距，并为未明确提示的T2I输出提供了关于文化多样性的宝贵见解。我们的方法可扩展到其他文化区域和概念，有助于开发更好地服务于全球人口的T2I模型。",
    "title_cn": "不仅仅是美学：探讨文本到图像模型中的文化素养",
    "tags": [
      "LLM应用",
      "文化艺术",
      "人工智能"
    ]
  },
  {
    "title": "Safe-Embed: Unveiling the Safety-Critical Knowledge of Sentence Encoders",
    "submit_datetime": "2024年07月09日",
    "abstract": "Despite the impressive capabilities of Large Language Models (LLMs) in various tasks, their vulnerability to unsafe prompts remains a critical issue. These prompts can lead LLMs to generate responses on illegal or sensitive topics, posing a significant threat to their safe and ethical use. Existing approaches attempt to address this issue using classification models, but they have several drawbacks. With the increasing complexity of unsafe prompts, similarity search-based techniques that identify specific features of unsafe prompts provide a more robust and effective solution to this evolving problem. This paper investigates the potential of sentence encoders to distinguish safe from unsafe prompts, and the ability to classify various unsafe prompts according to a safety taxonomy. We introduce new pairwise datasets and the Categorical Purity (CP) metric to measure this capability. Our findings reveal both the effectiveness and limitations of existing sentence encoders, proposing directions to improve sentence encoders to operate as more robust safety detectors. Our code is available at https://github.com/JwdanielJung/Safe-Embed.",
    "pdf_link": "https://arxiv.org/abs/2407.06851",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06851v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06851/concept_figure.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06851v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06851/XSTest_heatmap.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06851v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06851/cp_all_fig.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06851v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06851/cp_mean_bar_chart.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06851v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06851/st5_xxl_unsup_simcse_tsne.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06851v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06851/other_models_tsne.png"
      }
    ],
    "abstract_cn": "尽管大型语言模型 (LLM) 在多任务处理中表现出色，但其对不安全提示的敏感性仍是一个棘手问题。这些提示可能诱导 LLM 生成涉及非法或敏感话题的内容，严重威胁其安全与伦理应用。现有解决方案虽尝试通过分类模型应对，却存在诸多不足。随着不安全提示的日益复杂，基于相似性搜索的技术因其能精准识别不安全特征，成为解决这一难题的更佳途径。本文探讨了句子编码器在区分安全与不安全提示方面的潜力，并评估了其依据安全分类法对不安全提示进行分类的能力。我们创新性地引入了成对数据集和分类纯度 (CP) 指标以量化这一能力。研究结果不仅展示了现有句子编码器的成效与局限，更为提升其作为高效安全检测器的性能指明了改进方向。相关代码已公开于 https://github.com/JwdanielJung/Safe-Embed。",
    "title_cn": "Safe-Embed：揭秘句子编码器的安全核心知识",
    "tags": [
      "LLM应用",
      "网络安全",
      "人工智能"
    ]
  },
  {
    "title": "Chat-Edit-3D: Interactive 3D Scene Editing via Text Prompts",
    "submit_datetime": "2024年07月09日",
    "abstract": "Recent work on image content manipulation based on vision-language pre-training models has been effectively extended to text-driven 3D scene editing. However, existing schemes for 3D scene editing still exhibit certain shortcomings, hindering their further interactive design. Such schemes typically adhere to fixed input patterns, limiting users' flexibility in text input. Moreover, their editing capabilities are constrained by a single or a few 2D visual models and require intricate pipeline design to integrate these models into 3D reconstruction processes. To address the aforementioned issues, we propose a dialogue-based 3D scene editing approach, termed CE3D, which is centered around a large language model that allows for arbitrary textual input from users and interprets their intentions, subsequently facilitating the autonomous invocation of the corresponding visual expert models. Furthermore, we design a scheme utilizing Hash-Atlas to represent 3D scene views, which transfers the editing of 3D scenes onto 2D atlas images. This design achieves complete decoupling between the 2D editing and 3D reconstruction processes, enabling CE3D to flexibly integrate a wide range of existing 2D or 3D visual models without necessitating intricate fusion designs. Experimental results demonstrate that CE3D effectively integrates multiple visual models to achieve diverse editing visual effects, possessing strong scene comprehension and multi-round dialog capabilities. Code is available at <a href=\"https://sk-fun.fun/CE3D\"> this https URL.</a>",
    "pdf_link": "https://arxiv.org/abs/2407.06842",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06842v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06842/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06842v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06842/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06842v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06842/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06842v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06842/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06842v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06842/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06842v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06842/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06842v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06842/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06842v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06842/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06842v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06842/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06842v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06842/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06842v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06842/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06842v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06842/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06842v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06842/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06842v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06842/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06842v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06842/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06842v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06842/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06842v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06842/x17.png"
      }
    ],
    "abstract_cn": "近期，基于视觉-语言预训练模型的图像内容操作技术已成功应用于文本驱动的3D场景编辑。尽管如此，现有3D场景编辑方案仍存在局限，如固定输入模式限制了用户灵活性，单一2D视觉模型制约了编辑能力，且复杂的集成设计增加了难度。为此，我们推出了基于对话的3D场景编辑方法CE3D，该方法依托大型语言模型，支持用户自由文本输入并智能解读意图，自动调用相应视觉模型。我们还创新性地采用Hash-Atlas技术，将3D场景编辑简化为2D图集图像操作，实现了2D编辑与3D重建的彻底分离，使CE3D能灵活整合各类2D或3D视觉模型，无需复杂融合设计。实验证实，CE3D能有效集成多视觉模型，实现丰富编辑效果，展现出卓越的场景理解和多轮对话能力。代码已公开，详见<a href=\"https://sk-fun.fun/CE3D\">此链接</a>。",
    "title_cn": "Chat-Edit-3D：借助文本提示实现互动式3D场景编辑",
    "tags": [
      "LLM应用",
      "3D建模",
      "计算机视觉"
    ]
  },
  {
    "title": "VRDSynth: Synthesizing Programs for Multilingual Visually Rich Document Information Extraction",
    "submit_datetime": "2024年07月09日",
    "abstract": "Businesses need to query visually rich documents (VRDs) like receipts, medical records, and insurance forms to make decisions. Existing techniques for extracting entities from VRDs struggle with new layouts or require extensive pre-training data. We introduce VRDSynth, a program synthesis method to automatically extract entity relations from multilingual VRDs without pre-training data. To capture the complexity of VRD domain, we design a domain-specific language (DSL) to capture spatial and textual relations to describe the synthesized programs. Along with this, we also derive a new synthesis algorithm utilizing frequent spatial relations, search space pruning, and a combination of positive, negative, and exclusive programs to improve coverage.\n  We evaluate VRDSynth on the FUNSD and XFUND benchmarks for semantic entity linking, consisting of 1,592 forms in 8 languages. VRDSynth outperforms state-of-the-art pre-trained models (LayoutXLM, InfoXLMBase, and XLMRobertaBase) in 5, 6, and 7 out of 8 languages, respectively, improving the F1 score by 42% over LayoutXLM in English. To test the extensibility of the model, we further improve VRDSynth with automated table recognition, creating VRDSynth(Table), and compare it with extended versions of the pre-trained models, InfoXLM(Large) and XLMRoberta(Large). VRDSynth(Table) outperforms these baselines in 4 out of 8 languages and in average F1 score. VRDSynth also significantly reduces memory footprint (1M and 380MB vs. 1.48GB and 3GB for LayoutXLM) while maintaining similar time efficiency.",
    "pdf_link": "https://arxiv.org/abs/2407.06826",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06826v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06826/ExampleFUNSD.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06826v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06826/e2eFlaxIE-GNN(1).jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.06826v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06826/MultiPerceptron-GNNExplainerOptimization.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.06826v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06826/MultiPerceptron-Overall%20Architecture.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.06826v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06826/MultiPerceptron-HeuristicGraph.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.06826v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06826/MultiPerceptron-GNNArchitecture(2).jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.06826v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06826/MultiPerceptron-GNNExplainerRules2ProgramSynthesis(1).jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.06826v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06826/MultiPerceptron-SubstructureFinding(2).jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.06826v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06826/MultiPerceptron-GNNFeatureExtractor.jpg"
      }
    ],
    "abstract_cn": "企业决策常需查询视觉丰富的文档，如收据、医疗记录和保险表格。现有技术在处理新布局时力不从心，或需大量预训练数据。我们推出的VRDSynth，无需预训练，能自动从多语言VRD中提取实体关系。为应对VRD的复杂性，我们设计了专门的领域语言（DSL），捕捉空间与文本关系，并结合新的合成算法，提升覆盖率。在FUNSD和XFUND基准测试中，VRDSynth在多语言环境下表现卓越，尤其在英语中，F1分数提升显著。我们还通过自动表格识别增强了VRDSynth，使其在多语言比较中脱颖而出。此外，VRDSynth在内存效率上亦有显著优势，同时保持了高效的时间性能。",
    "title_cn": "VRDSynth：助力多语言视觉丰富文档信息提取的程序合成工具",
    "tags": [
      "LLM应用",
      "",
      ""
    ]
  },
  {
    "title": "It Cannot Be Right If It Was Written by AI: On Lawyers' Preferences of Documents Perceived as Authored by an LLM vs a Human",
    "submit_datetime": "2024年07月09日",
    "abstract": "Large Language Models (LLMs) enable a future in which certain types of legal documents may be generated automatically. This has a great potential to streamline legal processes, lower the cost of legal services, and dramatically increase access to justice. While many researchers focus their efforts on proposing and evaluating LLM-based applications supporting tasks in the legal domain, there is a notable lack of investigations into how legal professionals perceive content if they believe it has been generated by an LLM. Yet, this is a critical point as over-reliance or unfounded skepticism may influence whether such documents bring about appropriate legal consequences. This study is the necessary analysis in the context of the ongoing transition towards mature generative AI systems. Specifically, we examined whether the perception of legal documents' by lawyers (n=75) varies based on their assumed origin (human-crafted vs AI-generated). The participants evaluated the documents focusing on their correctness and language quality. Our analysis revealed a clear preference for documents perceived as crafted by a human over those believed to be generated by AI. At the same time, most of the participants are expecting the future in which documents will be generated automatically. These findings could be leveraged by legal practitioners, policy makers and legislators to implement and adopt legal document generation technology responsibly, and to fuel the necessary discussions into how legal processes should be updated to reflect the recent technological developments.",
    "pdf_link": "https://arxiv.org/abs/2407.06798",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06798v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06798/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06798v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06798/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06798v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06798/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06798v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06798/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06798v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06798/corr-doc-dist.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06798v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06798/lang-doc-dist.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06798v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06798/corr-doc-prefs.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06798v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06798/lang-doc-prefs.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06798v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06798/corr-overall-violin.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06798v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06798/corr-overall-dist.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06798v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06798/corr-overall-prefs.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06798v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06798/corr-verbose-dist.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06798v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06798/corr-brief-dist.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06798v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06798/corr-verbose-prefs.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06798v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06798/corr-brief-prefs.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06798v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06798/corr-student-dist.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06798v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06798/corr-lawyer-dist.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06798v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06798/corr-student-prefs.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06798v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06798/corr-lawyer-prefs.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06798v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06798/ta-corr-positive-vb.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06798v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06798/ta-corr-negative-vb.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06798v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06798/ta-corr-positive-bf.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06798v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06798/ta-corr-negative-bf.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06798v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06798/lang-overall-violin.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06798v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06798/lang-overall-dist.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06798v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06798/lang-overall-prefs.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06798v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06798/lang-verbose-dist.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06798v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06798/lang-brief-dist.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06798v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06798/lang-verbose-prefs.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06798v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06798/lang-brief-prefs.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06798v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06798/lang-student-dist.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06798v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06798/lang-lawyer-dist.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06798v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06798/lang-student-prefs.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06798v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06798/lang-lawyer-prefs.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06798v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06798/ta-lang-positive-vb.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06798v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06798/ta-lang-negative-vb.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06798v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06798/ta-lang-positive-bf.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06798v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06798/ta-lang-negative-bf.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06798v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06798/future_automation.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLM）预示着一个未来，其中某些法律文件可能实现自动化生成。这不仅有望简化法律流程、降低服务成本，还能大幅提升司法可及性。尽管众多研究者致力于开发和评估基于LLM的法律应用，但鲜有研究探讨法律专业人士对AI生成内容的看法。这一视角至关重要，因为过度依赖或无端怀疑可能影响这些文件的法律效力。本研究深入探讨了75名律师对法律文件的感知，分析了他们基于文件来源（人工或AI）的不同评价。结果显示，律师们更偏爱人工制作的文件，尽管他们也期待未来文件的自动化生成。这些见解为法律界、政策制定者及立法者提供了宝贵的参考，有助于他们负责任地采纳新技术，并推动法律流程的现代化改革。",
    "title_cn": "AI撰写的文件，律师们总觉得不靠谱：探讨律师对LLM与人类作者文件的偏好差异",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Using Pretrained Large Language Model with Prompt Engineering to Answer Biomedical Questions",
    "submit_datetime": "2024年07月09日",
    "abstract": "Our team participated in the BioASQ 2024 Task12b and Synergy tasks to build a system that can answer biomedical questions by retrieving relevant articles and snippets from the PubMed database and generating exact and ideal answers. We propose a two-level information retrieval and question-answering system based on pre-trained large language models (LLM), focused on LLM prompt engineering and response post-processing. We construct prompts with in-context few-shot examples and utilize post-processing techniques like resampling and malformed response detection. We compare the performance of various pre-trained LLM models on this challenge, including Mixtral, OpenAI GPT and Llama2. Our best-performing system achieved 0.14 MAP score on document retrieval, 0.05 MAP score on snippet retrieval, 0.96 F1 score for yes/no questions, 0.38 MRR score for factoid questions and 0.50 F1 score for list questions in Task 12b.",
    "pdf_link": "https://arxiv.org/abs/2407.06779",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06779v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06779/data_format.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06779v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06779/ir_design.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06779v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06779/qa_design.png"
      }
    ],
    "abstract_cn": "我们团队参与了 BioASQ 2024 的 Task12b 和 Synergy 任务，目标是打造一个能够从 PubMed 数据库中检索相关资料并生成精准答案的生物医学问答系统。我们设计了一个基于预训练 LLM 的两级检索与问答架构，特别注重提示工程和响应优化。通过构建含少量示例的上下文提示，并采用重采样和异常响应检测等技术，我们评估了 Mixtral、OpenAI GPT 和 Llama2 等多种 LLM 模型在此任务中的表现。最终，我们的系统在文档和片段检索、是/否问题、事实问题及列表问题等多个指标上均取得了优异成绩。",
    "title_cn": "借助预训练的LLM和提示工程技术，我们能够高效解答生物医学领域的疑问。",
    "tags": [
      "LLM应用",
      "生物医学",
      "问答系统"
    ]
  },
  {
    "title": "Relational Perspective on Graph Query Languages",
    "submit_datetime": "2024年07月09日",
    "abstract": "We study a relational perspective of graph database querying. Such a perspective underlies various graph database systems but very few theoretical investigations have been conducted on it. This perspective offers a powerful and unified framework to study graph database querying, by which algorithms and complexity follow from classical results. We provide two concrete applications.\n  The first is querying property graphs. The property graph data model supersedes previously proposed graph models and underlies the new standard GQL for graph query languages. We show that this standard can be, by and large, expressed by extensions of relational calculus with transitive closure operators (FO[TC]) and existential second-order quantifiers (ESO). With this, we obtain optimal data complexity bounds, along with extensions including schema validation.\n  The second application is incorporating data from concrete domains (e.g., numbers) in graph database querying. We use embedded finite model theory and, by exploiting a generic Restricted Quantifier Collapse (RQC) result for FO[TC] and ESO, we obtain optimal data complexity bounds for GQL with arithmetics and comparisons. Moreover, we show that Regular Data Path Querying with operations on data (i.e. using register automata formalisms) can be captured in FO[TC] over embedded finite graphs while preserving nondeterministic logspace data complexity.",
    "pdf_link": "https://arxiv.org/abs/2407.06766",
    "graphs": [],
    "abstract_cn": "我们探讨了图数据库查询的关系视角，这一视角虽为多种图数据库系统的基础，但理论研究甚少。该视角构建了一个强大且统一的框架，用于研究图数据库查询，其算法与复杂性源自经典理论。我们展示了两个具体应用：  首先，我们查询属性图。属性图数据模型超越了以往的图模型，并支撑了新的图查询语言标准GQL。我们证明，该标准主要可通过关系演算的扩展来表达，包括传递闭包算子（FO[TC]）和存在二阶量词（ESO），从而获得最优数据复杂度界限及模式验证等扩展。  其次，我们将具体领域数据（如数字）融入图数据库查询。利用嵌入的有限模型理论及FO[TC]和ESO的通用受限量词崩溃（RQC）结果，我们为含算术与比较的GQL设定了最优数据复杂度界限。同时，我们揭示了在嵌入有限图上，通过数据操作的常规数据路径查询可在FO[TC]中实现，且保持非确定性对数空间的数据复杂度。",
    "title_cn": "图查询语言的关系视角探析",
    "tags": [
      "LLM理论",
      "数据库",
      "图数据库"
    ]
  },
  {
    "title": "LVLM-empowered Multi-modal Representation Learning for Visual Place Recognition",
    "submit_datetime": "2024年07月09日",
    "abstract": "Visual place recognition (VPR) remains challenging due to significant viewpoint changes and appearance variations. Mainstream works tackle these challenges by developing various feature aggregation methods to transform deep features into robust and compact global representations. Unfortunately, satisfactory results cannot be achieved under challenging conditions. We start from a new perspective and attempt to build a discriminative global representations by fusing image data and text descriptions of the the visual scene. The motivation is twofold: (1) Current Large Vision-Language Models (LVLMs) demonstrate extraordinary emergent capability in visual instruction following, and thus provide an efficient and flexible manner in generating text descriptions of images; (2) The text descriptions, which provide high-level scene understanding, show strong robustness against environment variations. Although promising, leveraging LVLMs to build multi-modal VPR solutions remains challenging in efficient multi-modal fusion. Furthermore, LVLMs will inevitably produces some inaccurate descriptions, making it even harder. To tackle these challenges, we propose a novel multi-modal VPR solution. It first adapts pre-trained visual and language foundation models to VPR for extracting image and text features, which are then fed into the feature combiner to enhance each other. As the main component, the feature combiner first propose a token-wise attention block to adaptively recalibrate text tokens according to their relevance to the image data, and then develop an efficient cross-attention fusion module to propagate information across different modalities. The enhanced multi-modal features are compressed into the feature descriptor for performing retrieval. Experimental results show that our method outperforms state-of-the-art methods by a large margin with significantly smaller image descriptor dimension.",
    "pdf_link": "https://arxiv.org/abs/2407.06730",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06730v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06730/Fig1-LLaMA-AdapterV2.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.06730v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06730/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06730v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06730/Fig3-Retrieval-Results-Comparison.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.06730v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06730/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06730v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06730/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06730v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06730/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06730v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06730/x5.png"
      }
    ],
    "abstract_cn": "视觉地点识别（VPR）因视角和外观的显著变化而充满挑战。主流方法通过将深度特征转化为鲁健紧凑的全局表示来应对。然而，在复杂条件下，这些方法难以取得理想效果。我们另辟蹊径，尝试通过融合图像与场景描述的文本，构建更具辨别力的全局表示。这一创新基于两大动机：一是大型视觉-语言模型（LVLMs）在视觉指令跟随中展现出卓越能力，能高效生成图像描述；二是文本描述提供的高级场景理解对环境变化具有强鲁棒性。尽管前景光明，但高效融合多模态数据仍是一大挑战，且LVLMs生成的描述可能存在不准确性。为此，我们提出了一种创新的多模态VPR方案。该方案首先利用预训练的视觉与语言模型提取图像和文本特征，再通过特征组合器相互增强。特征组合器核心包括令牌级注意力块和交叉注意力融合模块，前者根据文本与图像的相关性自适应调整，后者高效跨模态传播信息。最终，增强的多模态特征被压缩成特征描述符，用于检索。实验表明，我们的方法在更小的图像描述符维度下，显著超越了现有技术。",
    "title_cn": "借助 LVLM 的多模态表示学习在视觉地点识别中的应用",
    "tags": [
      "LLM应用",
      "计算机视觉",
      "自动驾驶"
    ]
  },
  {
    "title": "A Simple Architecture for Enterprise Large Language Model Applications based on Role based security and Clearance Levels using Retrieval-Augmented Generation or Mixture of Experts",
    "submit_datetime": "2024年07月09日",
    "abstract": "This study proposes a simple architecture for Enterprise application for Large Language Models (LLMs) for role based security and NATO clearance levels. Our proposal aims to address the limitations of current LLMs in handling security and information access. The proposed architecture could be used while utilizing Retrieval-Augmented Generation (RAG) and fine tuning of Mixture of experts models (MoE). It could be used only with RAG, or only with MoE or with both of them. Using roles and security clearance level of the user, documents in RAG and experts in MoE are filtered. This way information leakage is prevented.",
    "pdf_link": "https://arxiv.org/abs/2407.06718",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06718v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06718/role-based-example1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06718v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06718/RAG-workflow.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06718v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06718/role-document-db-diagram.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06718v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06718/role-based-access-to-LLM-only-RAG-sequence-diagram.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06718v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06718/role-based-access-to-LLM-only-MoE-sequence-diagram.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06718v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06718/role-based-access-to-LLM-sequence-diagram.png"
      }
    ],
    "abstract_cn": "本研究设计了一种简洁的企业应用架构，专为大型语言模型（LLM）在基于角色的安全性和北约清关级别上使用。该架构旨在克服当前LLM在安全和信息访问管理上的不足。它兼容检索增强生成（RAG）和专家模型混合（MoE）的微调，可单独或组合使用。通过用户的角色和安全级别，对RAG文档和MoE专家进行筛选，有效防止信息泄露。",
    "title_cn": "一种基于角色安全和权限级别，结合检索增强生成或专家混合技术的企业级大型语言模型应用简易架构。",
    "tags": [
      "LLM应用",
      "",
      ""
    ]
  },
  {
    "title": "Embark on DenseQuest: A System for Selecting the Best Dense Retriever for a Custom Collection",
    "submit_datetime": "2024年07月09日",
    "abstract": "In this demo we present a web-based application for selecting an effective pre-trained dense retriever to use on a private collection. Our system, DenseQuest, provides unsupervised selection and ranking capabilities to predict the best dense retriever among a pool of available dense retrievers, tailored to an uploaded target collection. DenseQuest implements a number of existing approaches, including a recent, highly effective method powered by Large Language Models (LLMs), which requires neither queries nor relevance judgments. The system is designed to be intuitive and easy to use for those information retrieval engineers and researchers who need to identify a general-purpose dense retrieval model to encode or search a new private target collection. Our demonstration illustrates conceptual architecture and the different use case scenarios of the system implemented on the cloud, enabling universal access and use. DenseQuest is available at https://densequest.ielab.io.",
    "pdf_link": "https://arxiv.org/abs/2407.06685",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06685v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06685/dq_arch.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06685v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06685/collapsed_ui2_highlight.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06685v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06685/job_table.png"
      }
    ],
    "abstract_cn": "本次演示介绍了一款基于网络的应用，名为 DenseQuest，专为选择适用于私有数据集的预训练密集检索器而设计。DenseQuest 通过无监督选择与排序，从众多密集检索器中精准预测最适合特定上传数据集的选项。它融合了多种先进技术，包括一种无需查询或相关性判断、由大型语言模型驱动的高效方法。系统界面直观易用，旨在帮助信息检索领域的工程师和研究者快速找到适合新私有数据集的通用密集检索模型。演示中还展示了系统在云端的架构及多种应用场景，确保了广泛的可访问性和实用性。DenseQuest 系统可通过 https://densequest.ielab.io 访问。",
    "title_cn": "探索 DenseQuest：专为挑选自定义集合的最佳密集检索器而设计的系统",
    "tags": [
      "LLM应用",
      "信息检索",
      "云计算"
    ]
  },
  {
    "title": "SoftDedup: an Efficient Data Reweighting Method for Speeding Up Language Model Pre-training",
    "submit_datetime": "2024年07月09日",
    "abstract": "The effectiveness of large language models (LLMs) is often hindered by duplicated data in their extensive pre-training datasets. Current approaches primarily focus on detecting and removing duplicates, which risks the loss of valuable information and neglects the varying degrees of duplication. To address this, we propose a soft deduplication method that maintains dataset integrity while selectively reducing the sampling weight of data with high commonness. Central to our approach is the concept of \"data commonness\", a metric we introduce to quantify the degree of duplication by measuring the occurrence probabilities of samples using an n-gram model. Empirical analysis shows that this method significantly improves training efficiency, achieving comparable perplexity scores with at least a 26% reduction in required training steps. Additionally, it enhances average few-shot downstream accuracy by 1.77% when trained for an equivalent duration. Importantly, this approach consistently improves performance, even on rigorously deduplicated datasets, indicating its potential to complement existing methods and become a standard pre-training process for LLMs.",
    "pdf_link": "https://arxiv.org/abs/2407.06654",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06654v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06654/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06654v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06654/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06654v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06654/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06654v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06654/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06654v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06654/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06654v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06654/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06654v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06654/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06654v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06654/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06654v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06654/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06654v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06654/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06654v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06654/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06654v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06654/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06654v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06654/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06654v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06654/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06654v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06654/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06654v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06654/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06654v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06654/x17.png"
      }
    ],
    "abstract_cn": "大型语言模型 (LLM) 常因预训练数据集中的重复数据而受限。传统方法侧重于简单地检测和移除重复，这不仅可能遗失重要信息，还忽视了重复程度的多变性。为此，我们创新性地提出了软去重策略，既保护数据完整性，又智能降低高频重复数据的采样权重。核心在于我们首创的“数据共性”指标，通过 n-gram 模型量化样本重复度。实证表明，此法大幅提升训练效率，减少至少 26% 的训练步骤，同时困惑度得分相当。更妙的是，同等训练下，下游任务的少样本准确率提升 1.77%。即便在严格去重的数据集上，性能依然提升，预示着其有望成为 LLM 预训练的新标准。",
    "title_cn": "SoftDedup：加速语言模型预训练的高效数据重加权方法",
    "tags": [
      "LLM理论",
      "人工智能",
      "数据处理"
    ]
  },
  {
    "title": "Entropy Law: The Story Behind Data Compression and LLM Performance",
    "submit_datetime": "2024年07月09日",
    "abstract": "Data is the cornerstone of large language models (LLMs), but not all data is useful for model learning. Carefully selected data can better elicit the capabilities of LLMs with much less computational overhead. Most methods concentrate on evaluating the quality of individual samples in data selection, while the combinatorial effects among samples are neglected. Even if each sample is of perfect quality, their combinations may be suboptimal in teaching LLMs due to their intrinsic homogeneity or contradiction. In this paper, we aim to uncover the underlying relationships between LLM performance and data selection. Inspired by the information compression nature of LLMs, we uncover an ``entropy law'' that connects LLM performance with data compression ratio and first-epoch training loss, which reflect the information redundancy of a dataset and the mastery of inherent knowledge encoded in this dataset, respectively. Through both theoretical deduction and empirical evaluation, we find that model performance is negatively correlated to the compression ratio of training data, which usually yields a lower training loss. Based on the findings of the entropy law, we propose a quite efficient and universal data selection method named \\textbf{ZIP} for training LLMs, which aim to prioritize data subsets exhibiting a low compression ratio. Based on a multi-stage algorithm that selects diverse data in a greedy manner, we can obtain a good data subset with satisfactory diversity. Extensive experiments have been conducted to validate the entropy law and the superiority of ZIP across different LLM backbones and alignment stages. We also present an interesting application of entropy law that can detect potential performance risks at the beginning of model training.",
    "pdf_link": "https://arxiv.org/abs/2407.06645",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06645v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06645/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06645v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06645/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06645v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06645/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06645v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06645/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06645v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06645/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06645v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06645/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06645v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06645/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06645v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06645/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06645v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06645/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06645v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06645/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06645v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06645/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06645v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06645/entropy_law_application.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06645v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06645/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06645v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06645/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06645v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06645/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06645v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06645/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06645v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06645/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06645v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06645/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06645v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06645/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06645v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06645/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06645v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06645/x20.png"
      }
    ],
    "abstract_cn": "数据虽为大型语言模型的基石，但并非所有数据皆具价值。精选数据能更有效地激发模型潜能，同时大幅降低计算成本。当前方法多聚焦于单个样本质量评估，却忽视了样本间的组合效应。即便单个样本质量上乘，其组合可能因内在同质性或矛盾而影响模型教学效果。本文旨在探索模型性能与数据选择间的深层联系。受模型信息压缩特性启发，我们揭示了“熵定律”，将模型性能与数据压缩比及首轮训练损失相联系，分别反映数据冗余与知识掌握程度。理论与实证研究显示，模型性能与数据压缩比呈负相关，常伴随较低训练损失。基于此，我们提出高效通用的数据选择方法**ZIP**，优先选取低压缩比数据子集。借助多阶段贪婪算法选择多样化数据，我们得以构建兼具满意多样性的优质数据子集。广泛实验验证了熵定律及ZIP方法在不同模型架构与训练阶段的优势。此外，熵定律的应用还能在训练初期预警潜在性能风险。",
    "title_cn": "熵定律揭秘：数据压缩与大型语言模型性能的内在联系",
    "tags": [
      "LLM理论",
      "数据科学",
      "机器学习"
    ]
  },
  {
    "title": "Vision language models are blind",
    "submit_datetime": "2024年07月09日",
    "abstract": "Large language models with vision capabilities (VLMs), e.g., GPT-4o and Gemini 1.5 Pro are powering countless image-text applications and scoring high on many vision-understanding benchmarks. Yet, we find that VLMs fail on 7 visual tasks absurdly easy to humans such as identifying (a) whether two circles overlap; (b) whether two lines intersect; (c) which letter is being circled in a word; and (d) counting the number of circles in a Olympic-like logo. The shockingly poor performance of four state-of-the-art VLMs suggests their vision is, at best, like of a person with myopia seeing fine details as blurry, and at worst, like an intelligent person that is blind making educated guesses. Code is available at: https://vlmsareblind.github.io/",
    "pdf_link": "https://arxiv.org/abs/2407.06581",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x20.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x21.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x22.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x23.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x24.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x25.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x26.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x27.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x28.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x29.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x30.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x31.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x35.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x36.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x37.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x38.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x39.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x40.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x41.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x42.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x43.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x44.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x45.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x46.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x47.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x48.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x49.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x50.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/claude-35.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/claude-35.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x51.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/claude-35.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x52.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x53.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x54.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x55.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x56.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x57.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/claude-35.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/claude-35.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x58.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x59.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x60.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x61.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x62.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/claude-35.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/gt_l_Sonnet_o_Sonnet-3.5_l_GPT-4o_o_Gemini-1.5-Pro_w_text_image_9d28452a-29b5-4c12-9fd4-020410a9c0a8_prompt1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/gt_m_Sonnet_e_Sonnet-3.5_e_GPT-4o_e_Gemini-1.5-Pro_m_text_image_9eb95711-547b-4340-99db-8cf91d09902c_prompt1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/gt_n_Sonnet_e_Sonnet-3.5_t_GPT-4o_t_Gemini-1.5-Pro_n_text_image_040f7cb9-681c-4e3f-9fb2-f9a23fc7ca3a_prompt1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/gt_p_Sonnet_y_Sonnet-3.5_h_GPT-4o_o_Gemini-1.5-Pro_p_text_image_4ee4fd8b-6af2-4b9e-9a4d-b2ef2e1ade30_prompt1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/gt_t_Sonnet_a_Sonnet-3.5_t_GPT-4o_o_Gemini-1.5-Pro_o_text_image_ee8e7572-f2e9-43df-a71c-039d504453bd_prompt1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/gt_v_Sonnet_t_Sonnet-3.5_m_GPT-4o_z_Gemini-1.5-Pro_v_text_image_6a65095e-4691-4a31-a846-cdd6bae99706_prompt1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/claude-35.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/claude-35.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x63.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x64.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x65.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x66.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x67.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x68.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x69.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/claude-35.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/claude-35.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x71.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x72.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x73.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x74.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x75.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/claude-35.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x76.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x77.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x78.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x79.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x80.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x81.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x82.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x83.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/claude-35.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/claude-35.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x84.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x85.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x86.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x87.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x88.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x89.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/claude-35.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/claude-35.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/claude-35.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/claude-35.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x90.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x91.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/claude-35.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x92.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x93.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/claude-35.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x94.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x95.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x96.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x97.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x98.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x99.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x100.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/claude-35.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/claude-35.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x101.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x102.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x103.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x104.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x105.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x106.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x107.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x108.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x109.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x110.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x111.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x112.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x113.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x114.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x115.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x116.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x117.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x118.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x119.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x120.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x121.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x122.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x123.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x124.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/claude-35.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/claude-35.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/gt_a_pred_a_text_image_3bac479b-38ae-467f-82b3-36ec1c1dd97b.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/gt_b_pred_b_text_image_2c39e0c8-2b50-41ba-b107-591cc86f4630.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/gt_k_pred_k_text_image_35edd93f-bba6-4e1a-9698-f3dde8c55045.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/gt_e_pred_e_text_image_565ad313-6788-4b3b-9fb0-00556e6a17f6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/gt_y_pred_l_text_image_d59812f7-2fa8-4b43-800a-5189d85c7026.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/gt_w_pred_w_text_image_b52e3649-ef9c-4dcb-a751-28d7444e5126.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/gt_t_pred_t_text_image_c7d27ca2-5bc5-413a-ba33-0c9ec067a4cf.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/gt_i_pred_i_text_image_ccc25c17-06d0-4836-b300-9be66d549011.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/gt_c_pred_g_text_image_14faa675-d211-4cee-bcd5-1407ad8c5ba6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x125.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x126.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x127.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x128.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x129.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/claude-35.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/claude-35.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/claude-35.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x130.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/claude-35.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/claude-35.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/claude-35.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/gt_m_Sonnet_e_Sonnet-3.5_e_GPT-4o_e_Gemini-1.5-Pro_m_text_image_2ffcf634-2773-40a8-a7dc-072a26890b6a_prompt2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/gt_l_Sonnet_n_Sonnet-3.5_l_GPT-4o_e_Gemini-1.5-Pro_l_text_image_67b6656a-0631-4da7-9638-70cad2fd4ca1_prompt2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/gt_c_Sonnet_i_Sonnet-3.5_cc_GPT-4o_c_Gemini-1.5-Pro_c_text_image_a305c192-e573-4b9a-8a71-fa02ffdb939b_prompt2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/gt_g_Sonnet_o_Sonnet-3.5_g_GPT-4o_g_Gemini-1.5-Pro_o_text_image_94ff8097-315f-43d4-ae86-94de2c43d77a_prompt2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/gt_a_Sonnet_i_Sonnet-3.5_a_GPT-4o_aa_Gemini-1.5-Pro_a_text_image_9ccbc4d5-ebb8-43a2-9ec1-29cfadd6d426_prompt2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/gt_b_Sonnet_n_Sonnet-3.5_b_GPT-4o_r_Gemini-1.5-Pro_b_text_image_c84d6b1c-1763-41b6-b876-ce76b6e25b4d_prompt2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/claude-35.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/claude-35.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x131.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x132.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x133.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x134.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x135.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x136.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x137.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x138.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x139.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x140.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/claude-35.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x141.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/claude-35.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x142.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x143.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x144.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x145.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x146.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x147.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/claude-35.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/claude-35.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x150.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x151.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x152.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x153.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x154.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x155.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x156.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x157.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x158.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x160.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x161.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x162.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x163.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/claude-35.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/claude-35.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x164.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x165.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x166.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x167.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x168.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x169.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x170.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x171.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x172.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x173.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x174.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x175.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x176.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x177.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x178.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x179.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x180.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x181.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x182.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x183.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x184.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x185.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/claude-35.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/claude-35.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x186.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x187.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x188.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x189.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x190.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x191.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x192.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x193.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x194.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x195.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x196.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x197.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x198.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x199.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/claude-35.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/claude-35.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x200.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x201.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x202.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x203.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x204.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x205.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/claude-35.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/claude-35.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x206.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x207.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x208.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x209.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x210.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x211.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x212.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x213.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x214.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x215.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x216.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x217.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/claude-35.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/claude-35.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x218.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x219.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x220.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x221.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x222.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x223.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/claude-35.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06581/claude-35.png"
      }
    ],
    "abstract_cn": "尽管具有视觉能力的大型语言模型（如 GPT-4o 和 Gemini 1.5 Pro）在图像-文本应用和视觉理解基准测试中表现出色，但它们在处理一些对人类而言极其简单的视觉任务时却表现糟糕。例如，这些模型无法准确识别两个圆是否重叠、两条线是否相交、单词中哪个字母被圈出，或计算类似奥运标志中圆圈的数量。这表明，这些模型的视觉能力可能仅限于模糊地识别细节，甚至可能像一个聪明但失明的人在猜测。相关代码已公开，详情请访问：https://vlmsareblind.github.io/",
    "title_cn": "视觉语言模型如同失明一般。",
    "tags": [
      "LLM应用",
      "计算机视觉",
      "人工智能"
    ]
  },
  {
    "title": "Virtual Personas for Language Models via an Anthology of Backstories",
    "submit_datetime": "2024年07月09日",
    "abstract": "Large language models (LLMs) are trained from vast repositories of text authored by millions of distinct authors, reflecting an enormous diversity of human traits. While these models bear the potential to be used as approximations of human subjects in behavioral studies, prior efforts have been limited in steering model responses to match individual human users. In this work, we introduce \"Anthology\", a method for conditioning LLMs to particular virtual personas by harnessing open-ended life narratives, which we refer to as \"backstories.\" We show that our methodology enhances the consistency and reliability of experimental outcomes while ensuring better representation of diverse sub-populations. Across three nationally representative human surveys conducted as part of Pew Research Center's American Trends Panel (ATP), we demonstrate that Anthology achieves up to 18% improvement in matching the response distributions of human respondents and 27% improvement in consistency metrics. Our code and generated backstories are available at https://github.com/CannyLab/anthology.",
    "pdf_link": "https://arxiv.org/abs/2407.06576",
    "graphs": [],
    "abstract_cn": "大型语言模型 (LLM) 汲取了数百万作者的丰富文本，展现了人类特质的多样性。虽然这些模型有望在行为研究中模拟人类，但先前的工作在使模型响应与个体用户匹配方面存在局限。为此，我们提出了 \"Anthology\" 方法，通过开放式的生活叙事（即 \"背景故事\"）来定制 LLM 的虚拟人格。实验表明，这种方法不仅提升了实验结果的一致性和可靠性，还更好地代表了多样化的子群体。在皮尤研究中心的三项全国代表性调查中，Anthology 在匹配人类响应分布和提高一致性方面分别实现了 18% 和 27% 的提升。相关代码和背景故事已公开在 https://github.com/CannyLab/anthology。",
    "title_cn": "借助丰富的背景故事，为语言模型赋予生动的虚拟角色。",
    "tags": [
      "LLM应用",
      "行为研究",
      "社会科学"
    ]
  },
  {
    "title": "Combining Knowledge Graphs and Large Language Models",
    "submit_datetime": "2024年07月09日",
    "abstract": "In recent years, Natural Language Processing (NLP) has played a significant role in various Artificial Intelligence (AI) applications such as chatbots, text generation, and language translation. The emergence of large language models (LLMs) has greatly improved the performance of these applications, showing astonishing results in language understanding and generation. However, they still show some disadvantages, such as hallucinations and lack of domain-specific knowledge, that affect their performance in real-world tasks. These issues can be effectively mitigated by incorporating knowledge graphs (KGs), which organise information in structured formats that capture relationships between entities in a versatile and interpretable fashion. Likewise, the construction and validation of KGs present challenges that LLMs can help resolve. The complementary relationship between LLMs and KGs has led to a trend that combines these technologies to achieve trustworthy results. This work collected 28 papers outlining methods for KG-powered LLMs, LLM-based KGs, and LLM-KG hybrid approaches. We systematically analysed and compared these approaches to provide a comprehensive overview highlighting key trends, innovative techniques, and common challenges. This synthesis will benefit researchers new to the field and those seeking to deepen their understanding of how KGs and LLMs can be effectively combined to enhance AI applications capabilities.",
    "pdf_link": "https://arxiv.org/abs/2407.06564",
    "graphs": [],
    "abstract_cn": "近年来，NLP 在 AI 应用中扮演了关键角色，如聊天机器人和语言翻译。LLM 的崛起显著提升了这些应用的性能，尤其在语言理解和生成方面。然而，LLM 仍面临幻觉和领域知识不足等挑战，这些问题可通过结合知识图谱（KGs）来缓解，KGs 以结构化方式捕捉实体间关系。LLM 与 KGs 的互补性推动了两者结合的趋势，以提升 AI 应用的可靠性。本研究分析了 28 篇相关论文，系统比较了基于 KG 的 LLM、LLM 驱动的 KGs 及混合方法，旨在为新入行的研究人员和希望深化理解 LLM 与 KGs 结合策略的学者提供全面视角，揭示关键趋势、创新技术及共同挑战。",
    "title_cn": "融合知识图谱与大型语言模型",
    "tags": [
      "LLM应用",
      "人工智能",
      ""
    ]
  },
  {
    "title": "OffsetBias: Leveraging Debiased Data for Tuning Evaluators",
    "submit_datetime": "2024年07月09日",
    "abstract": "Employing Large Language Models (LLMs) to assess the quality of generated responses, such as prompting instruct-tuned models or fine-tuning judge models, has become a widely adopted evaluation method. It is also known that such evaluators are vulnerable to biases, such as favoring longer responses. While it is important to overcome this problem, the specifics of these biases remain under-explored. In this work, we qualitatively identify six types of biases inherent in various judge models. We propose EvalBiasBench as a meta-evaluation collection of hand-crafted test cases for each bias type. Additionally, we present de-biasing dataset construction methods and the associated preference dataset OffsetBias. Experimental results demonstrate that fine-tuning on our dataset significantly enhances the robustness of judge models against biases and improves performance across most evaluation scenarios. We release our datasets and the fine-tuned judge model to public.",
    "pdf_link": "https://arxiv.org/abs/2407.06551",
    "graphs": [],
    "abstract_cn": "利用 LLM 评估生成内容的质量，如通过提示调整模型或微调评判模型，已成为主流评估手段。然而，这些评估工具易受偏见影响，比如偏爱长篇大论。尽管解决这一问题至关重要，但偏见的具体表现仍待深入探究。本研究中，我们识别了六类判断模型中的固有偏见，并创建了 EvalBiasBench 作为针对这些偏见的定制测试集。同时，我们提出了去偏数据集构建法及配套的 OffsetBias 偏好集。实验显示，基于我们的数据集进行微调能大幅提升评判模型的抗偏见能力，并优化其在多场景下的表现。我们已将相关数据集和微调模型公开。",
    "title_cn": "OffsetBias：借助去偏数据优化评估器调整",
    "tags": [
      "LLM应用",
      "人工智能",
      "数据科学"
    ]
  },
  {
    "title": "LETS-C: Leveraging Language Embedding for Time Series Classification",
    "submit_datetime": "2024年07月09日",
    "abstract": "Recent advancements in language modeling have shown promising results when applied to time series data. In particular, fine-tuning pre-trained large language models (LLMs) for time series classification tasks has achieved state-of-the-art (SOTA) performance on standard benchmarks. However, these LLM-based models have a significant drawback due to the large model size, with the number of trainable parameters in the millions. In this paper, we propose an alternative approach to leveraging the success of language modeling in the time series domain. Instead of fine-tuning LLMs, we utilize a language embedding model to embed time series and then pair the embeddings with a simple classification head composed of convolutional neural networks (CNN) and multilayer perceptron (MLP). We conducted extensive experiments on well-established time series classification benchmark datasets. We demonstrated LETS-C not only outperforms the current SOTA in classification accuracy but also offers a lightweight solution, using only 14.5% of the trainable parameters on average compared to the SOTA model. Our findings suggest that leveraging language encoders to embed time series data, combined with a simple yet effective classification head, offers a promising direction for achieving high-performance time series classification while maintaining a lightweight model architecture.",
    "pdf_link": "https://arxiv.org/abs/2407.06533",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06533v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06533/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06533v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06533/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06533v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06533/accuracies_may22.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06533v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06533/val_normalized_df_masked_version_new.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06533v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06533/val_normalized_df_masked_version_new.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06533v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06533/precision_average_accuracy_plot.png"
      }
    ],
    "abstract_cn": "近期，语言模型在处理时间序列数据方面展现出显著成效。特别是，通过微调预训练的大型语言模型（LLM）进行时间序列分类，已在多项基准测试中达到顶尖水平。但这些模型因庞大的参数规模（数百万可训练参数）而显得笨重。为此，我们提出新策略：采用语言嵌入模型处理时间序列，并结合卷积神经网络（CNN）与多层感知器（MLP）构成的简洁分类头。实验证明，LETS-C不仅在准确度上超越现有最佳模型，更以平均仅14.5%的参数量，实现了轻量化。这表明，结合语言编码器与高效分类头，是实现高效且轻巧时间序列分类的可行路径。",
    "title_cn": "LETS-C：借助语言嵌入技术，革新时间序列分类方法",
    "tags": [
      "LLM应用",
      "时间序列分析",
      "机器学习"
    ]
  },
  {
    "title": "Multilingual Blending: LLM Safety Alignment Evaluation with Language Mixture",
    "submit_datetime": "2024年07月09日",
    "abstract": "As safety remains a crucial concern throughout the development lifecycle of Large Language Models (LLMs), researchers and industrial practitioners have increasingly focused on safeguarding and aligning LLM behaviors with human preferences and ethical standards. LLMs, trained on extensive multilingual corpora, exhibit powerful generalization abilities across diverse languages and domains. However, current safety alignment practices predominantly focus on single-language scenarios, which leaves their effectiveness in complex multilingual contexts, especially for those complex mixed-language formats, largely unexplored. In this study, we introduce Multilingual Blending, a mixed-language query-response scheme designed to evaluate the safety alignment of various state-of-the-art LLMs (e.g., GPT-4o, GPT-3.5, Llama3) under sophisticated, multilingual conditions. We further investigate language patterns such as language availability, morphology, and language family that could impact the effectiveness of Multilingual Blending in compromising the safeguards of LLMs. Our experimental results show that, without meticulously crafted prompt templates, Multilingual Blending significantly amplifies the detriment of malicious queries, leading to dramatically increased bypass rates in LLM safety alignment (67.23% on GPT-3.5 and 40.34% on GPT-4o), far exceeding those of single-language baselines. Moreover, the performance of Multilingual Blending varies notably based on intrinsic linguistic properties, with languages of different morphology and from diverse families being more prone to evading safety alignments. These findings underscore the necessity of evaluating LLMs and developing corresponding safety alignment strategies in a complex, multilingual context to align with their superior cross-language generalization capabilities.",
    "pdf_link": "https://arxiv.org/abs/2407.07342",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.07342v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07342/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07342v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07342/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07342v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07342/x3.png"
      }
    ],
    "abstract_cn": "在大型语言模型（LLMs）的开发过程中，安全性始终是核心关注点。为此，研究者和业界专家正日益致力于确保LLM行为符合人类偏好与伦理标准。LLMs通过广泛的多语言数据训练，展现出跨语言和领域的强大泛化能力。然而，当前的安全对齐措施主要针对单一语言场景，其在复杂多语言环境中的效果，尤其是混合语言格式，尚未得到充分研究。本研究提出了“多语言混合”策略，通过混合语言的查询-响应模式，评估在复杂多语言环境下，如GPT-4o、GPT-3.5和Llama3等先进LLMs的安全对齐情况。我们深入探讨了语言可用性、形态学和语言家族等因素如何影响多语言混合策略的有效性。实验表明，缺乏精心设计的提示模板时，多语言混合会显著加剧恶意查询的风险，导致安全对齐的绕过率大幅上升（GPT-3.5为67.23%，GPT-4o为40.34%），远超单一语言场景。此外，不同语言的内在属性也影响多语言混合的表现，形态学和语言家族的差异使得某些语言更易规避安全对齐。这些发现凸显了在多语言复杂环境中评估和优化LLMs安全对齐策略的重要性，以充分发挥其跨语言泛化能力。",
    "title_cn": "多语言融合：评估 LLM 安全对齐与语言混合",
    "tags": [
      "LLM应用",
      "人工智能",
      "语言处理"
    ]
  },
  {
    "title": "MixSumm: Topic-based Data Augmentation using LLMs for Low-resource Extractive Text Summarization",
    "submit_datetime": "2024年07月09日",
    "abstract": "Low-resource extractive text summarization is a vital but heavily underexplored area of research. Prior literature either focuses on abstractive text summarization or prompts a large language model (LLM) like GPT-3 directly to generate summaries. In this work, we propose MixSumm for low-resource extractive text summarization. Specifically, MixSumm prompts an open-source LLM, LLaMA-3-70b, to generate documents that mix information from multiple topics as opposed to generating documents without mixup, and then trains a summarization model on the generated dataset. We use ROUGE scores and L-Eval, a reference-free LLaMA-3-based evaluation method to measure the quality of generated summaries. We conduct extensive experiments on a challenging text summarization benchmark comprising the TweetSumm, WikiHow, and ArXiv/PubMed datasets and show that our LLM-based data augmentation framework outperforms recent prompt-based approaches for low-resource extractive summarization. Additionally, our results also demonstrate effective knowledge distillation from LLaMA-3-70b to a small BERT-based extractive summarizer.",
    "pdf_link": "https://arxiv.org/abs/2407.07341",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.07341v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07341/mixsumm_teaser.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07341v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07341/mixsumm.png"
      }
    ],
    "abstract_cn": "低资源抽取式文本摘要是一个关键但研究不足的领域。以往研究多聚焦于生成式摘要或直接利用大型模型如GPT-3生成摘要。我们提出MixSumm，通过提示开源模型LLaMA-3-70b生成混合多主题的文档，而非单一主题，进而训练摘要模型。我们采用ROUGE评分和基于LLaMA-3的无参考评估方法L-Eval来评估摘要质量。在包含TweetSumm、WikiHow和ArXiv/PubMed的挑战性基准测试中，我们的数据增强框架显著超越了现有提示方法。此外，实验还验证了从LLaMA-3-70b到小型BERT抽取式摘要器的知识有效转移。",
    "title_cn": "MixSumm：利用 LLM 为低资源抽取式文本摘要提供主题基础的数据增强方法",
    "tags": [
      "LLM应用",
      "文本摘要",
      "数据增强"
    ]
  },
  {
    "title": "Interpretable Differential Diagnosis with Dual-Inference Large Language Models",
    "submit_datetime": "2024年07月09日",
    "abstract": "Methodological advancements to automate the generation of differential diagnosis (DDx) to predict a list of potential diseases as differentials given patients' symptom descriptions are critical to clinical reasoning and applications such as decision support. However, providing reasoning or interpretation for these differential diagnoses is more meaningful. Fortunately, large language models (LLMs) possess powerful language processing abilities and have been proven effective in various related tasks. Motivated by this potential, we investigate the use of LLMs for interpretable DDx. First, we develop a new DDx dataset with expert-derived interpretation on 570 public clinical notes. Second, we propose a novel framework, named Dual-Inf, that enables LLMs to conduct bidirectional inference for interpretation. Both human and automated evaluation demonstrate the effectiveness of Dual-Inf in predicting differentials and diagnosis explanations. Specifically, the performance improvement of Dual-Inf over the baseline methods exceeds 32% w.r.t. BERTScore in DDx interpretation. Furthermore, experiments verify that Dual-Inf (1) makes fewer errors in interpretation, (2) has great generalizability, (3) is promising for rare disease diagnosis and explanation.",
    "pdf_link": "https://arxiv.org/abs/2407.07330",
    "graphs": [],
    "abstract_cn": "在临床推理和决策支持应用中，自动化生成鉴别诊断（DDx）至关重要。然而，为DDx提供解释更具价值。得益于大型语言模型（LLMs）的强大语言处理能力，我们探索了其在此领域的应用。我们首先创建了一个包含570份临床笔记的DDx数据集，并附有专家解释。接着，我们提出了Dual-Inf框架，使LLMs能够进行双向推理，从而提供解释。评估结果显示，Dual-Inf在预测和解释诊断方面表现出色，性能提升显著，且在罕见疾病诊断方面展现出潜力。",
    "title_cn": "双重推理大型语言模型助力可解释的差异诊断",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Probability of Differentiation Reveals Brittleness of Homogeneity Bias in Large Language Models",
    "submit_datetime": "2024年07月09日",
    "abstract": "Homogeneity bias in Large Language Models (LLMs) refers to their tendency to homogenize the representations of some groups compared to others. Previous studies documenting this bias have predominantly used encoder models, which may have inadvertently introduced biases. To address this limitation, we prompted GPT-4 to generate single word/expression completions associated with 18 situation cues - specific, measurable elements of environments that influence how individuals perceive situations and compared the variability of these completions using probability of differentiation. This approach directly assessed homogeneity bias from the model's outputs, bypassing encoder models. Across five studies, we find that homogeneity bias is highly volatile across situation cues and writing prompts, suggesting that the bias observed in past work may reflect those within encoder models rather than LLMs. Furthermore, these results suggest that homogeneity bias in LLMs is brittle, as even minor and arbitrary changes in prompts can significantly alter the expression of biases. Future work should further explore how variations in syntactic features and topic choices in longer text generations influence homogeneity bias in LLMs.",
    "pdf_link": "https://arxiv.org/abs/2407.07329",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.07329v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07329/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07329v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07329/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07329v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07329/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07329v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07329/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07329v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07329/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07329v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07329/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07329v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07329/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07329v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07329/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07329v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07329/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07329v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07329/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07329v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07329/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07329v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07329/x12.png"
      }
    ],
    "abstract_cn": "大型语言模型 (LLM) 存在同质化偏差，即倾向于将某些群体的表征与其他群体同质化。以往研究多使用编码器模型，可能无意中引入了偏差。为此，我们让 GPT-4 根据 18 个情境线索生成单字/表达完成，并比较其变异性，直接从模型输出评估同质化偏差，绕过了编码器模型。研究发现，同质化偏差在不同情境线索和提示中波动大，暗示过去的偏差研究可能更多反映了编码器模型的偏差而非 LLM。此外，提示的微小变化就能显著影响偏差表达，显示 LLM 中的同质化偏差较为脆弱。未来研究应深入探讨长文本生成中句法和主题选择的变化如何影响 LLM 的同质化偏差。",
    "title_cn": "大型语言模型中的同质性偏见，其脆弱性在不同化的概率中显露无疑。",
    "tags": [
      "LLM理论",
      "人工智能",
      "社会科学"
    ]
  },
  {
    "title": "RAG vs. Long Context: Examining Frontier Large Language Models for Environmental Review Document Comprehension",
    "submit_datetime": "2024年07月09日",
    "abstract": "Large Language Models (LLMs) have been applied to many research problems across various domains. One of the applications of LLMs is providing question-answering systems that cater to users from different fields. The effectiveness of LLM-based question-answering systems has already been established at an acceptable level for users posing questions in popular and public domains such as trivia and literature. However, it has not often been established in niche domains that traditionally require specialized expertise. To this end, we construct the NEPAQuAD1.0 benchmark to evaluate the performance of three frontier LLMs -- Claude Sonnet, Gemini, and GPT-4 -- when answering questions originating from Environmental Impact Statements prepared by U.S. federal government agencies in accordance with the National Environmental Environmental Act (NEPA). We specifically measure the ability of LLMs to understand the nuances of legal, technical, and compliance-related information present in NEPA documents in different contextual scenarios. For example, we test the LLMs' internal prior NEPA knowledge by providing questions without any context, as well as assess how LLMs synthesize the contextual information present in long NEPA documents to facilitate the question/answering task. We compare the performance of the long context LLMs and RAG powered models in handling different types of questions (e.g., problem-solving, divergent). Our results suggest that RAG powered models significantly outperform the long context models in the answer accuracy regardless of the choice of the frontier LLM. Our further analysis reveals that many models perform better answering closed questions than divergent and problem-solving questions.",
    "pdf_link": "https://arxiv.org/abs/2407.07321",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.07321v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07321/FlowDiagram.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07321v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07321/Benchmark_Generation.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07321v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07321/Sonnet.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07321v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07321/Gemini.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07321v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07321/GPT-4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07321v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07321/Sonnet_rag.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07321v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07321/Gemini_rag.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07321v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07321/GPT-4_rag.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLM）已广泛应用于多个领域的研究问题。其中，LLM 构建的问答系统能够服务于不同领域的用户。在流行和公共领域（如琐事和文学）中，基于 LLM 的问答系统已证明其有效性。然而，在需要专业知识的特定领域，其表现尚未得到充分验证。为此，我们创建了 NEPAQuAD1.0 基准，旨在评估 Claude Sonnet、Gemini 和 GPT-4 这三个前沿 LLM 在处理来自美国联邦政府根据《国家环境政策法》(NEPA) 编写的环境影响声明中的问题时的表现。我们特别关注 LLM 在不同情境下理解 NEPA 文件中法律、技术和合规信息的细微差别的能力。通过无上下文的问题测试 LLM 的 NEPA 知识，并评估其综合长文档上下文以辅助问答的能力。结果显示，RAG 驱动模型在回答准确性上显著优于长上下文模型，尤其是在处理封闭式问题时表现更佳。",
    "title_cn": "探究前沿大型语言模型在环境审查文件理解中的表现：RAG 与长上下文的对比研究",
    "tags": [
      "LLM应用",
      "环境政策",
      ""
    ]
  },
  {
    "title": "CosmoCLIP: Generalizing Large Vision-Language Models for Astronomical Imaging",
    "submit_datetime": "2024年07月09日",
    "abstract": "Existing vision-text contrastive learning models enhance representation transferability and support zero-shot prediction by matching paired image and caption embeddings while pushing unrelated pairs apart. However, astronomical image-label datasets are significantly smaller compared to general image and label datasets available from the internet. We introduce CosmoCLIP, an astronomical image-text contrastive learning framework precisely fine-tuned on the pre-trained CLIP model using SpaceNet and BLIP-based captions. SpaceNet, attained via FLARE, constitutes ~13k optimally distributed images, while BLIP acts as a rich knowledge extractor. The rich semantics derived from this SpaceNet and BLIP descriptions, when learned contrastively, enable CosmoCLIP to achieve superior generalization across various in-domain and out-of-domain tasks. Our results demonstrate that CosmoCLIP is a straightforward yet powerful framework, significantly outperforming CLIP in zero-shot classification and image-text retrieval tasks.",
    "pdf_link": "https://arxiv.org/abs/2407.07315",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.07315v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07315/CosmoCLIP_method.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07315v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07315/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07315v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07315/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07315v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07315/TI_Retrieval.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07315v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07315/II_Retrieval.png"
      }
    ],
    "abstract_cn": "现有的视觉-文本对比学习模型通过匹配图像与标题的嵌入并分离无关对来提升表示的可迁移性，支持零-shot预测。然而，天文图像-标签数据集规模远小于互联网上的通用数据集。为此，我们推出了CosmoCLIP，一个基于SpaceNet和BLIP标题的预训练CLIP模型的天文图像-文本对比学习框架。SpaceNet包含约13,000张分布优化的图像，而BLIP则作为知识丰富的提取器。通过对比学习这些描述中的丰富语义，CosmoCLIP在多种任务中展现出卓越的泛化能力。实验结果显示，CosmoCLIP框架简洁高效，在零-shot分类和图像-文本检索任务中大幅超越CLIP。",
    "title_cn": "CosmoCLIP：拓展大型视觉-语言模型至天文影像领域",
    "tags": [
      "LLM应用",
      "天文学",
      "机器学习"
    ]
  },
  {
    "title": "ESM+: Modern Insights into Perspective on Text-to-SQL Evaluation in the Age of Large Language Models",
    "submit_datetime": "2024年07月09日",
    "abstract": "The task of Text-to-SQL enables anyone to retrieve information from SQL databases using natural language. Despite several challenges, recent models have made remarkable advancements in this task using large language models (LLMs). Interestingly, we find that LLM-based models without fine-tuning exhibit distinct natures compared to their fine-tuned counterparts, leading to inadequacies in current evaluation metrics to accurately convey their performance. Thus, we analyze the two primary metrics, Test Suite Execution Accuracy (EXE) and Exact Set Matching Accuracy (ESM), to examine their robustness for this task and address shortcomings. We compare the performance of 9 LLM-based models using EXE, the original ESM, and our improved ESM (called ESM+). Our results show that EXE and ESM have high false positive and negative rates of 11.3% and 13.9%, while ESM+ gives those of 0.1% and 2.6% respectively, providing a significantly more stable evaluation. We release the ESM+ script as open-source for the community to contribute, while enjoying a more reliable assessment of Text-to-SQL.",
    "pdf_link": "https://arxiv.org/abs/2407.07313",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.07313v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07313/rules_FNs.png"
      }
    ],
    "abstract_cn": "Text-to-SQL 任务让用户能用自然语言从 SQL 数据库中提取信息。尽管挑战重重，基于 LLM 的模型在此领域已取得显著进步。值得注意的是，未经微调的 LLM 模型展现出与微调模型不同的特性，使得现有评估指标难以准确衡量其性能。为此，我们深入分析了 EXE 和 ESM 两大评估指标，并提出了改进版 ESM+，以提升评估的稳定性。实验表明，相较于 EXE 和原始 ESM 的高误报率和漏报率，ESM+ 的误报和漏报率大幅降低至 0.1% 和 2.6%。我们已将 ESM+ 脚本开源，期待社区共同参与，共同推动 Text-to-SQL 评估的可靠性。",
    "title_cn": "ESM+：探索大规模语言模型时代下文本到SQL评估的新视角",
    "tags": [
      "LLM应用",
      "数据库",
      ""
    ]
  },
  {
    "title": "ViTime: A Visual Intelligence-Based Foundation Model for Time Series Forecasting",
    "submit_datetime": "2024年07月09日",
    "abstract": "The success of large pretrained models in natural language processing (NLP) and computer vision (CV) has opened new avenues for constructing foundation models for time series forecasting (TSF). Traditional TSF foundation models rely heavily on numerical data fitting. In contrast, the human brain is inherently skilled at processing visual information, prefer predicting future trends by observing visualized sequences. From a biomimetic perspective, utilizing models to directly process numerical sequences might not be the most effective route to achieving Artificial General Intelligence (AGI). This paper proposes ViTime, a novel Visual Intelligence-based foundation model for TSF. ViTime overcomes the limitations of numerical time series data fitting by utilizing visual data processing paradigms and employs a innovative data synthesis method during training, called Real Time Series (RealTS). Experiments on a diverse set of previously unseen forecasting datasets demonstrate that ViTime achieves state-of-the-art zero-shot performance, even surpassing the best individually trained supervised models in some situations. These findings suggest that visual intelligence can significantly enhance time series analysis and forecasting, paving the way for more advanced and versatile models in the field. The code for our framework is accessible at https://github.com/IkeYang/ViTime.",
    "pdf_link": "https://arxiv.org/abs/2407.07311",
    "graphs": [],
    "abstract_cn": "大型预训练模型在NLP和CV领域的成功，为TSF基础模型的构建带来了新思路。传统TSF模型依赖数值拟合，而人脑则擅长通过视觉序列预测未来。从仿生学视角看，直接处理数值序列可能并非AGI的最佳路径。本文提出的ViTime模型，通过视觉数据处理和创新的数据合成方法RealTS，突破了数值拟合的限制。实验显示，ViTime在多个新数据集上实现了顶尖的零-shot性能，甚至在某些情况下超越了最佳监督模型。这表明视觉智能能大幅提升时间序列分析与预测，为更先进、多功能的模型开辟了道路。ViTime框架代码已公开在https://github.com/IkeYang/ViTime。",
    "title_cn": "ViTime：一款基于视觉智能的时间序列预测基础模型",
    "tags": [
      "LLM应用",
      "时间序列分析",
      "人工智能"
    ]
  },
  {
    "title": "Inference Performance Optimization for Large Language Models on CPUs",
    "submit_datetime": "2024年07月09日",
    "abstract": "Large language models (LLMs) have shown exceptional performance and vast potential across diverse tasks. However, the deployment of LLMs with high performance in low-resource environments has garnered significant attention in the industry. When GPU hardware resources are limited, we can explore alternative options on CPUs. To mitigate the financial burden and alleviate constraints imposed by hardware resources, optimizing inference performance is necessary. In this paper, we introduce an easily deployable inference performance optimization solution aimed at accelerating LLMs on CPUs. In this solution, we implement an effective way to reduce the KV cache size while ensuring precision. We propose a distributed inference optimization approach and implement it based on oneAPI Collective Communications Library. Furthermore, we propose optimization approaches for LLMs on CPU, and conduct tailored optimizations for the most commonly used models. The code is open-sourced at https://github.com/intel/xFasterTransformer.",
    "pdf_link": "https://arxiv.org/abs/2407.07304",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.07304v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07304/slimattention.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07304v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07304/flashattention.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07304v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07304/int8kv1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07304v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07304/int8kv2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07304v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07304/distribute.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07304v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07304/x1.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLM）在多任务中表现卓越，但在资源有限的环境中部署高性能LLM备受关注。面对GPU资源限制，我们转向CPU寻求解决方案。本文提出一种简便的推理性能优化方案，旨在CPU上加速LLM，通过精简KV缓存同时保持精度。我们采用分布式推理优化策略，并依托oneAPI集体通信库实现。此外，针对常用模型进行定制优化，相关代码已在GitHub开源，地址为https://github.com/intel/xFasterTransformer。",
    "title_cn": "CPU环境下大型语言模型的推理性能优化",
    "tags": [
      "LLM应用",
      "计算机硬件",
      "软件优化"
    ]
  },
  {
    "title": "Large Language Model-Augmented Auto-Delineation of Treatment Target Volume in Radiation Therapy",
    "submit_datetime": "2024年07月09日",
    "abstract": "Radiation therapy (RT) is one of the most effective treatments for cancer, and its success relies on the accurate delineation of targets. However, target delineation is a comprehensive medical decision that currently relies purely on manual processes by human experts. Manual delineation is time-consuming, laborious, and subject to interobserver variations. Although the advancements in artificial intelligence (AI) techniques have significantly enhanced the auto-contouring of normal tissues, accurate delineation of RT target volumes remains a challenge. In this study, we propose a visual language model-based RT target volume auto-delineation network termed Radformer. The Radformer utilizes a hierarichal vision transformer as the backbone and incorporates large language models to extract text-rich features from clinical data. We introduce a visual language attention module (VLAM) for integrating visual and linguistic features for language-aware visual encoding (LAVE). The Radformer has been evaluated on a dataset comprising 2985 patients with head-and-neck cancer who underwent RT. Metrics, including the Dice similarity coefficient (DSC), intersection over union (IOU), and 95th percentile Hausdorff distance (HD95), were used to evaluate the performance of the model quantitatively. Our results demonstrate that the Radformer has superior segmentation performance compared to other state-of-the-art models, validating its potential for adoption in RT practice.",
    "pdf_link": "https://arxiv.org/abs/2407.07296",
    "graphs": [],
    "abstract_cn": "放射治疗（RT）作为癌症治疗的有效手段，其成功关键在于目标的精准描绘。然而，这一过程目前仍依赖于专家的手动操作，不仅耗时费力，还存在观察者间的差异。尽管AI技术在正常组织自动描绘方面取得了显著进展，但RT目标体积的准确描绘仍面临挑战。为此，我们研发了Radformer，一种基于视觉语言模型的自动描绘网络。Radformer采用层次化视觉变换器架构，并融入大型语言模型，从临床数据中提取丰富文本特征。通过视觉语言注意力模块（VLAM），Radformer能有效整合视觉与语言信息，实现语言感知的视觉编码。在包含2985名头颈癌患者的RT数据集上，Radformer的性能通过DSC、IOU和HD95等指标进行了定量评估，结果显示其分割性能优于现有顶尖模型，展现了在RT实践中的广阔应用前景。",
    "title_cn": "大型语言模型助力放射治疗中治疗目标体积的自动勾画",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "ConvNLP: Image-based AI Text Detection",
    "submit_datetime": "2024年07月09日",
    "abstract": "The potentials of Generative-AI technologies like Large Language models (LLMs) to revolutionize education are undermined by ethical considerations around their misuse which worsens the problem of academic dishonesty. LLMs like GPT-4 and Llama 2 are becoming increasingly powerful in generating sophisticated content and answering questions, from writing academic essays to solving complex math problems. Students are relying on these LLMs to complete their assignments and thus compromising academic integrity. Solutions to detect LLM-generated text are compute-intensive and often lack generalization. This paper presents a novel approach for detecting LLM-generated AI-text using a visual representation of word embedding. We have formulated a novel Convolutional Neural Network called ZigZag ResNet, as well as a scheduler for improving generalization, named ZigZag Scheduler. Through extensive evaluation using datasets of text generated by six different state-of-the-art LLMs, our model demonstrates strong intra-domain and inter-domain generalization capabilities. Our best model detects AI-generated text with an impressive average detection rate (over inter- and intra-domain test data) of 88.35%. Through an exhaustive ablation study, our ZigZag ResNet and ZigZag Scheduler provide a performance improvement of nearly 4% over the vanilla ResNet. The end-to-end inference latency of our model is below 2.5ms per sentence. Our solution offers a lightweight, computationally efficient, and faster alternative to existing tools for AI-generated text detection, with better generalization performance. It can help academic institutions in their fight against the misuse of LLMs in academic settings. Through this work, we aim to contribute to safeguarding the principles of academic integrity and ensuring the trustworthiness of student work in the era of advanced LLMs.",
    "pdf_link": "https://arxiv.org/abs/2407.07225",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.07225v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07225/AITD.drawio.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07225v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07225/ZigZagTextNet.drawio.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07225v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07225/total_inference_times_vs_num_sentences.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07225v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07225/output_times_vs_num_sentences.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07225v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07225/preprocessing_times_vs_num_sentences.png"
      }
    ],
    "abstract_cn": "生成式AI技术，如大型语言模型（LLMs），在革新教育领域的潜力受到其滥用导致的伦理问题的削弱，这加剧了学术不诚实的问题。LLMs如GPT-4和Llama 2在生成复杂内容和回答问题方面变得越来越强大，从撰写学术论文到解决复杂数学问题。学生依赖这些LLMs完成作业，从而损害了学术诚信。检测LLM生成文本的解决方案计算密集且往往缺乏泛化能力。本文提出了一种新颖的方法，使用词嵌入的视觉表示来检测LLM生成的AI文本。我们设计了一种新颖的卷积神经网络，称为ZigZag ResNet，以及一个名为ZigZag Scheduler的调度器，以提高泛化能力。通过使用由六种不同最先进的LLMs生成的文本数据集进行广泛评估，我们的模型展示了强大的域内和域间泛化能力。我们的最佳模型在域内和域间测试数据上的平均检测率达到了88.35%。通过详尽的消融研究，我们的ZigZag ResNet和ZigZag Scheduler相比原始ResNet提供了近4%的性能提升。我们的模型的端到端推理延迟每句话低于2.5毫秒。我们的解决方案提供了一种轻量级、计算高效且更快的替代方案，用于检测AI生成的文本，具有更好的泛化性能。它可以帮助学术机构在学术环境中对抗LLMs的滥用。通过这项工作，我们旨在保护学术诚信的原则，并确保在先进LLMs时代学生工作的可信度。",
    "title_cn": "ConvNLP：探索基于图像的AI文本检测技术",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Large Language Models for Wearable Sensor-Based Human Activity Recognition, Health Monitoring, and Behavioral Modeling: A Survey of Early Trends, Datasets, and Challenges",
    "submit_datetime": "2024年07月09日",
    "abstract": "The proliferation of wearable technology enables the generation of vast amounts of sensor data, offering significant opportunities for advancements in health monitoring, activity recognition, and personalized medicine. However, the complexity and volume of this data present substantial challenges in data modeling and analysis, which have been tamed with approaches spanning time series modeling to deep learning techniques. The latest frontier in this domain is the adoption of Large Language Models (LLMs), such as GPT-4 and Llama, for data analysis, modeling, understanding, and generation of human behavior through the lens of wearable sensor data. This survey explores current trends and challenges in applying LLMs for sensor-based human activity recognition and behavior modeling. We discuss the nature of wearable sensors data, the capabilities and limitations of LLMs to model them and their integration with traditional machine learning techniques. We also identify key challenges, including data quality, computational requirements, interpretability, and privacy concerns. By examining case studies and successful applications, we highlight the potential of LLMs in enhancing the analysis and interpretation of wearable sensors data. Finally, we propose future directions for research, emphasizing the need for improved preprocessing techniques, more efficient and scalable models, and interdisciplinary collaboration. This survey aims to provide a comprehensive overview of the intersection between wearable sensors data and LLMs, offering insights into the current state and future prospects of this emerging field.",
    "pdf_link": "https://arxiv.org/abs/2407.07196",
    "graphs": [],
    "abstract_cn": "随着可穿戴技术的兴起，海量传感器数据为健康监测、活动识别和个性化医疗带来了新机遇。然而，这些数据的复杂性和规模也给数据建模和分析带来了挑战，这些挑战通过时间序列建模和深度学习等技术得到了解决。当前，大型语言模型（LLMs）如GPT-4和Llama正被用于通过可穿戴传感器数据分析、建模和理解人类行为。本调查深入探讨了LLMs在基于传感器的活动识别和行为建模中的应用趋势和挑战。我们分析了可穿戴传感器数据的特性，LLMs的建模能力及其局限，以及它们与传统机器学习技术的结合。同时，我们也指出了数据质量、计算需求、可解释性和隐私等关键问题。通过案例研究，我们展示了LLMs在提升可穿戴传感器数据分析和解释能力方面的潜力。最后，我们提出了未来研究方向，强调预处理技术的改进、模型效率和可扩展性的提升，以及跨学科合作的重要性。本调查旨在全面概述可穿戴传感器数据与LLMs的融合，为这一新兴领域的发展提供洞见。",
    "title_cn": "大型语言模型在可穿戴传感器领域的人类活动识别、健康监测及行为建模中的应用：探索早期发展、数据集及面临的挑战",
    "tags": [
      "LLM应用",
      "",
      "可穿戴技术"
    ]
  },
  {
    "title": "TrackFormers: In Search of Transformer-Based Particle Tracking for the High-Luminosity LHC Era",
    "submit_datetime": "2024年07月09日",
    "abstract": "High-Energy Physics experiments are facing a multi-fold data increase with every new iteration. This is certainly the case for the upcoming High-Luminosity LHC upgrade. Such increased data processing requirements forces revisions to almost every step of the data processing pipeline. One such step in need of an overhaul is the task of particle track reconstruction, a.k.a., tracking. A Machine Learning-assisted solution is expected to provide significant improvements, since the most time-consuming step in tracking is the assignment of hits to particles or track candidates. This is the topic of this paper.\n  We take inspiration from large language models. As such, we consider two approaches: the prediction of the next word in a sentence (next hit point in a track), as well as the one-shot prediction of all hits within an event. In an extensive design effort, we have experimented with three models based on the Transformer architecture and one model based on the U-Net architecture, performing track association predictions for collision event hit points. In our evaluation, we consider a spectrum of simple to complex representations of the problem, eliminating designs with lower metrics early on. We report extensive results, covering both prediction accuracy (score) and computational performance. We have made use of the REDVID simulation framework, as well as reductions applied to the TrackML data set, to compose five data sets from simple to complex, for our experiments. The results highlight distinct advantages among different designs in terms of prediction accuracy and computational performance, demonstrating the efficiency of our methodology. Most importantly, the results show the viability of a one-shot encoder-classifier based Transformer solution as a practical approach for the task of tracking.",
    "pdf_link": "https://arxiv.org/abs/2407.07179",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.07179v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07179/flow_simple_model_1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07179v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07179/flow_simple_model_2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07179v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07179/flow_simple_model_3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07179v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07179/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07179v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07179/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07179v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07179/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07179v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07179/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07179v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07179/plot_model_accuracy_scatter.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07179v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07179/plot_model_performance_cpu_time_scatter.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07179v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07179/plot_model_performance_gpu_time_scatter.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07179v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07179/plot_model_performance_execution_time_range_log.png"
      },
      {
        "url": "https://arxiv.org/html/2407.07179v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07179/hit_association_probability.png"
      }
    ],
    "abstract_cn": "随着高能物理实验的每一次迭代，数据量激增，高亮度LHC升级亦是如此。这一趋势迫使数据处理流程的每个环节都需重新考量，尤其是粒子轨迹重建（跟踪）这一环节。机器学习辅助方案有望大幅提升效率，因为跟踪中最耗时的环节正是命中点与粒子或轨迹候选的匹配。本文即聚焦于此。我们借鉴大型语言模型的思路，探索了两种策略：预测轨迹中的下一个命中点，以及一次性预测整个事件的命中点。通过深入设计，我们测试了基于Transformer的三种模型和基于U-Net的一种模型，针对碰撞事件的命中点进行轨迹关联预测。评估过程中，我们从简单到复杂逐步推进，及时淘汰表现不佳的设计。实验结果详尽，涵盖预测准确性与计算效率。我们借助REDVID模拟框架及TrackML数据集的简化处理，构建了五个难度递增的数据集进行实验。结果表明，不同设计在预测准确性和计算性能上各有千秋，凸显了我们方法的高效性。尤为关键的是，实验证实了一次性编码器-分类器基于Transformer方案在跟踪任务中的实用性。",
    "title_cn": "TrackFormers：探索高亮度LHC时代基于Transformer的粒子跟踪技术",
    "tags": [
      "LLM应用",
      "高能物理",
      "机器学习"
    ]
  },
  {
    "title": "GenArtist: Multimodal LLM as an Agent for Unified Image Generation and Editing",
    "submit_datetime": "2024年07月08日",
    "abstract": "Despite the success achieved by existing image generation and editing methods, current models still struggle with complex problems including intricate text prompts, and the absence of verification and self-correction mechanisms makes the generated images unreliable. Meanwhile, a single model tends to specialize in particular tasks and possess the corresponding capabilities, making it inadequate for fulfilling all user requirements. We propose GenArtist, a unified image generation and editing system, coordinated by a multimodal large language model (MLLM) agent. We integrate a comprehensive range of existing models into the tool library and utilize the agent for tool selection and execution. For a complex problem, the MLLM agent decomposes it into simpler sub-problems and constructs a tree structure to systematically plan the procedure of generation, editing, and self-correction with step-by-step verification. By automatically generating missing position-related inputs and incorporating position information, the appropriate tool can be effectively employed to address each sub-problem. Experiments demonstrate that GenArtist can perform various generation and editing tasks, achieving state-of-the-art performance and surpassing existing models such as SDXL and DALL-E 3, as can be seen in Fig. 1. Project page is https://zhenyuw16.github.io/GenArtist_page.",
    "pdf_link": "https://arxiv.org/abs/2407.05600",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05600v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05600/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05600v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05600/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05600v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05600/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05600v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05600/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05600v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05600/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05600v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05600/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05600v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05600/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05600v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05600/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05600v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05600/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05600v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05600/x10.png"
      }
    ],
    "abstract_cn": "尽管现有图像生成和编辑技术已取得一定成就，但面对复杂文本提示等难题，以及缺乏验证和自校正机制，现有模型仍显不足。此外，单一模型往往局限于特定任务，难以全面满足用户需求。为此，我们推出了GenArtist系统，该系统由多模态大型语言模型（MLLM）代理统一调度，集成了广泛的现有模型工具库。面对复杂任务，MLLM代理能将其拆解为简单子问题，并构建树状结构，系统化地规划生成、编辑及自校正流程，每一步都经过严格验证。通过自动补全位置相关输入并融入位置信息，系统能精准选用工具，高效解决各子问题。实验结果显示，GenArtist在多种生成和编辑任务中表现卓越，性能超越了SDXL和DALL-E 3等现有模型，详情可见图1。项目详情页：https://zhenyuw16.github.io/GenArtist_page。",
    "title_cn": "GenArtist：一款多模态 LLM，作为统一图像生成与编辑的智能代理",
    "tags": [
      "Agent",
      "图像处理",
      "人工智能"
    ]
  },
  {
    "title": "Multi-label Learning with Random Circular Vectors",
    "submit_datetime": "2024年07月08日",
    "abstract": "The extreme multi-label classification~(XMC) task involves learning a classifier that can predict from a large label set the most relevant subset of labels for a data instance. While deep neural networks~(DNNs) have demonstrated remarkable success in XMC problems, the task is still challenging because it must deal with a large number of output labels, which make the DNN training computationally expensive. This paper addresses the issue by exploring the use of random circular vectors, where each vector component is represented as a complex amplitude. In our framework, we can develop an output layer and loss function of DNNs for XMC by representing the final output layer as a fully connected layer that directly predicts a low-dimensional circular vector encoding a set of labels for a data instance. We conducted experiments on synthetic datasets to verify that circular vectors have better label encoding capacity and retrieval ability than normal real-valued vectors. Then, we conducted experiments on actual XMC datasets and found that these appealing properties of circular vectors contribute to significant improvements in task performance compared with a previous model using random real-valued vectors, while reducing the size of the output layers by up to 99%.",
    "pdf_link": "https://arxiv.org/abs/2407.05656",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05656v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05656/Heatmap_HRR.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05656v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05656/Heatmap_CHRR.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05656v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05656/Variance.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05656v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05656/Mean.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05656v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05656/Wiki10_P5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05656v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05656/Wiki10_P10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05656v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05656/Wiki10_P20.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05656v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05656/Wiki10_PSP5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05656v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05656/Wiki10_PSP10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05656v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05656/Wiki10_PSP20.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05656v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05656/d200_P5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05656v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05656/Delicious-200K_P10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05656v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05656/Delicious-200K_P20.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05656v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05656/d200_psp5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05656v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05656/Delicious-200K_PSP10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05656v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05656/Delicious-200K_PSP20.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05656v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05656/Model_type_P1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05656v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05656/Model_type_P10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05656v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05656/Model_type_P20.png"
      }
    ],
    "abstract_cn": "极端多标签分类 (XMC) 任务旨在训练一个分类器，从庞大的标签库中筛选出与特定数据最匹配的标签子集。尽管深度神经网络 (DNNs) 在此领域已取得显著成就，但面对海量输出标签，DNN 的训练成本依然高昂。本文提出了一种创新方法，利用随机圆形向量（每个分量以复数振幅表示）来优化这一难题。在我们的框架下，通过构建一个全连接的最终输出层，直接预测低维圆形向量，该向量编码了数据实例的标签集，从而为 DNN 设计了适用于 XMC 的输出层和损失函数。实验表明，圆形向量在标签编码和检索方面优于传统实值向量。进一步在真实 XMC 数据集上的测试证实，圆形向量的这些优势不仅显著提升了任务性能，还将输出层规模缩减了高达 99%。",
    "title_cn": "随机循环向量在多标签学习中的应用",
    "tags": [
      "LLM应用",
      "机器学习",
      "数据挖掘"
    ]
  },
  {
    "title": "GenFollower: Enhancing Car-Following Prediction with Large Language Models",
    "submit_datetime": "2024年07月08日",
    "abstract": "Accurate modeling of car-following behaviors is essential for various applications in traffic management and autonomous driving systems. However, current approaches often suffer from limitations like high sensitivity to data quality and lack of interpretability. In this study, we propose GenFollower, a novel zero-shot prompting approach that leverages large language models (LLMs) to address these challenges. We reframe car-following behavior as a language modeling problem and integrate heterogeneous inputs into structured prompts for LLMs. This approach achieves improved prediction performance and interpretability compared to traditional baseline models. Experiments on the Waymo Open datasets demonstrate GenFollower's superior performance and ability to provide interpretable insights into factors influencing car-following behavior. This work contributes to advancing the understanding and prediction of car-following behaviors, paving the way for enhanced traffic management and autonomous driving systems.",
    "pdf_link": "https://arxiv.org/abs/2407.05611",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05611v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05611/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05611v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05611/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05611v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05611/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05611v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05611/sm.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05611v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05611/um.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05611v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05611/am.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05611v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05611/out.png"
      }
    ],
    "abstract_cn": "在交通管理和自动驾驶领域，准确模拟跟车行为至关重要。然而，现有方法常受限于对数据质量的敏感和缺乏解释性。为此，我们研发了 GenFollower，一种利用大型语言模型的零-shot 提示技术，将跟车行为转化为语言模型问题，并整合多源输入至结构化提示中。实验表明，GenFollower 不仅提升了预测准确性，还增强了模型的解释力，为理解跟车行为提供了新视角，推动了交通管理与自动驾驶技术的发展。",
    "title_cn": "GenFollower：借助大型语言模型提升车辆跟随预测的精准度",
    "tags": [
      "LLM应用",
      "交通管理",
      "自动驾驶"
    ]
  },
  {
    "title": "Open-world Multi-label Text Classification with Extremely Weak Supervision",
    "submit_datetime": "2024年07月08日",
    "abstract": "We study open-world multi-label text classification under extremely weak supervision (XWS), where the user only provides a brief description for classification objectives without any labels or ground-truth label space. Similar single-label XWS settings have been explored recently, however, these methods cannot be easily adapted for multi-label. We observe that (1) most documents have a dominant class covering the majority of content and (2) long-tail labels would appear in some documents as a dominant class. Therefore, we first utilize the user description to prompt a large language model (LLM) for dominant keyphrases of a subset of raw documents, and then construct a (initial) label space via clustering. We further apply a zero-shot multi-label classifier to locate the documents with small top predicted scores, so we can revisit their dominant keyphrases for more long-tail labels. We iterate this process to discover a comprehensive label space and construct a multi-label classifier as a novel method, X-MLClass. X-MLClass exhibits a remarkable increase in ground-truth label space coverage on various datasets, for example, a 40% improvement on the AAPD dataset over topic modeling and keyword extraction methods. Moreover, X-MLClass achieves the best end-to-end multi-label classification accuracy.",
    "pdf_link": "https://arxiv.org/abs/2407.05609",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05609v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05609/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05609v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05609/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05609v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05609/x3.png"
      }
    ],
    "abstract_cn": "在极弱监督下，我们探索了开放世界的多标签文本分类，用户仅提供简要描述而无需任何标签。我们发现多数文档有一个主导类，而长尾标签偶尔也会成为主导。基于此，我们利用用户描述引导大型语言模型提取关键词，通过聚类构建标签空间，并运用零-shot分类器精确定位文档，以发现更多长尾标签。这一迭代过程最终形成了X-MLClass方法，显著提升了标签空间覆盖率，如在AAPD数据集上提升了40%，并实现了顶尖的多标签分类准确性。",
    "title_cn": "极弱监督下的开放世界多标签文本分类",
    "tags": [
      "LLM应用",
      "文本分类",
      "数据挖掘"
    ]
  },
  {
    "title": "Generative Debunking of Climate Misinformation",
    "submit_datetime": "2024年07月08日",
    "abstract": "Misinformation about climate change causes numerous negative impacts, necessitating corrective responses. Psychological research has offered various strategies for reducing the influence of climate misinformation, such as the fact-myth-fallacy-fact-structure. However, practically implementing corrective interventions at scale represents a challenge. Automatic detection and correction of misinformation offers a solution to the misinformation problem. This study documents the development of large language models that accept as input a climate myth and produce a debunking that adheres to the fact-myth-fallacy-fact (``truth sandwich'') structure, by incorporating contrarian claim classification and fallacy detection into an LLM prompting framework. We combine open (Mixtral, Palm2) and proprietary (GPT-4) LLMs with prompting strategies of varying complexity. Experiments reveal promising performance of GPT-4 and Mixtral if combined with structured prompts. We identify specific challenges of debunking generation and human evaluation, and map out avenues for future work. We release a dataset of high-quality truth-sandwich debunkings, source code and a demo of the debunking system.",
    "pdf_link": "https://arxiv.org/abs/2407.05599",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05599v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05599/x1.png"
      }
    ],
    "abstract_cn": "气候变化错误信息带来的负面影响众多，亟需纠正。心理学研究虽提供了减少其影响的策略，如“事实-神话-谬误-事实”结构，但大规模实施纠正措施仍具挑战。本研究探索了通过自动检测与纠正错误信息来应对这一问题，开发了能接受气候神话输入并按“真相三明治”结构生成反驳的大型语言模型。我们融合了开放与专有LLM，并运用多样的提示策略进行实验，发现结合结构化提示的GPT-4和Mixtral性能显著。同时，我们揭示了反驳生成及评估的难题，并指明了未来研究方向。此外，我们公开了高质量反驳数据集、源码及系统演示，以供进一步探索与应用。",
    "title_cn": "揭秘气候谣言的生成式方法",
    "tags": [
      "LLM应用",
      "气候变化",
      "信息安全"
    ]
  },
  {
    "title": "iLLM-TSC: Integration reinforcement learning and large language model for traffic signal control policy improvement",
    "submit_datetime": "2024年07月08日",
    "abstract": "Urban congestion remains a critical challenge, with traffic signal control (TSC) emerging as a potent solution. TSC is often modeled as a Markov Decision Process problem and then solved using reinforcement learning (RL), which has proven effective. However, the existing RL-based TSC system often overlooks imperfect observations caused by degraded communication, such as packet loss, delays, and noise, as well as rare real-life events not included in the reward function, such as unconsidered emergency vehicles. To address these limitations, we introduce a novel integration framework that combines a large language model (LLM) with RL. This framework is designed to manage overlooked elements in the reward function and gaps in state information, thereby enhancing the policies of RL agents. In our approach, RL initially makes decisions based on observed data. Subsequently, LLMs evaluate these decisions to verify their reasonableness. If a decision is found to be unreasonable, it is adjusted accordingly. Additionally, this integration approach can be seamlessly integrated with existing RL-based TSC systems without necessitating modifications. Extensive testing confirms that our approach reduces the average waiting time by $17.5\\%$ in degraded communication conditions as compared to traditional RL methods, underscoring its potential to advance practical RL applications in intelligent transportation systems. The related code can be found at \\url{https://github.com/Traffic-Alpha/iLLM-TSC}.",
    "pdf_link": "https://arxiv.org/abs/2407.06025",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06025v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06025/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06025v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06025/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06025v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06025/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06025v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06025/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06025v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06025/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06025v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06025/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06025v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06025/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06025v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06025/all_WT.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06025v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06025/EMV_WT.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06025v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06025/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06025v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06025/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06025v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06025/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06025v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06025/x11.png"
      }
    ],
    "abstract_cn": "城市拥堵问题依旧严峻，而交通信号控制（TSC）被视为一种有力对策。尽管RL已被证实有效，但现有基于RL的TSC系统常忽视通信退化导致的不完美观察及奖励函数未涵盖的罕见事件。为此，我们创新性地结合LLM与RL，旨在填补奖励函数中的空白并优化RL策略。在我们的方法中，RL先基于数据做决策，LLM则评估其合理性，必要时进行调整。此集成方法无需修改即可融入现有TSC系统。测试表明，在通信退化环境下，我们的方法使平均等待时间减少了17.5%，凸显了其在智能交通系统中推广RL应用的潜力。相关代码详见\\url{https://github.com/Traffic-Alpha/iLLM-TSC}。",
    "title_cn": "iLLM-TSC：融合强化学习与大型语言模型，优化交通信号控制策略",
    "tags": [
      "LLM应用",
      "",
      "智能交通系统"
    ]
  },
  {
    "title": "ANOLE: An Open, Autoregressive, Native Large Multimodal Models for Interleaved Image-Text Generation",
    "submit_datetime": "2024年07月08日",
    "abstract": "Previous open-source large multimodal models (LMMs) have faced several limitations: (1) they often lack native integration, requiring adapters to align visual representations with pre-trained large language models (LLMs); (2) many are restricted to single-modal generation; (3) while some support multimodal generation, they rely on separate diffusion models for visual modeling and generation. To mitigate these limitations, we present Anole, an open, autoregressive, native large multimodal model for interleaved image-text generation. We build Anole from Meta AI's Chameleon, adopting an innovative fine-tuning strategy that is both data-efficient and parameter-efficient. Anole demonstrates high-quality, coherent multimodal generation capabilities. We have open-sourced our model, training framework, and instruction tuning data.",
    "pdf_link": "https://arxiv.org/abs/2407.06135",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06135v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06135/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06135v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06135/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06135v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06135/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06135v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06135/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06135v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06135/x5.png"
      }
    ],
    "abstract_cn": "先前的开源大型多模态模型存在一些问题，如缺乏原生集成、仅支持单模态生成，以及依赖独立扩散模型进行视觉处理。为此，我们推出了 Anole，这是一个开放、自回归的原生多模态模型，专为图像与文本交错生成设计。基于 Meta AI 的 Chameleon，我们采用了一种创新的微调方法，既高效利用数据又节省参数。Anole 能够生成高质量且连贯的多模态内容。我们已将模型、训练框架及调优数据全部开源。",
    "title_cn": "ANOLE 是一个开放且自回归的原生大型多模态模型，专为交错图像与文本生成而设计。",
    "tags": [
      "LLM应用",
      "人工智能",
      "开源软件"
    ]
  },
  {
    "title": "Cross-domain Few-shot In-context Learning for Enhancing Traffic Sign Recognition",
    "submit_datetime": "2024年07月08日",
    "abstract": "Recent multimodal large language models (MLLM) such as GPT-4o and GPT-4v have shown great potential in autonomous driving. In this paper, we propose a cross-domain few-shot in-context learning method based on the MLLM for enhancing traffic sign recognition (TSR). We first construct a traffic sign detection network based on Vision Transformer Adapter and an extraction module to extract traffic signs from the original road images. To reduce the dependence on training data and improve the performance stability of cross-country TSR, we introduce a cross-domain few-shot in-context learning method based on the MLLM. To enhance MLLM's fine-grained recognition ability of traffic signs, the proposed method generates corresponding description texts using template traffic signs. These description texts contain key information about the shape, color, and composition of traffic signs, which can stimulate the ability of MLLM to perceive fine-grained traffic sign categories. By using the description texts, our method reduces the cross-domain differences between template and real traffic signs. Our approach requires only simple and uniform textual indications, without the need for large-scale traffic sign images and labels. We perform comprehensive evaluations on the German traffic sign recognition benchmark dataset, the Belgium traffic sign dataset, and two real-world datasets taken from Japan. The experimental results show that our method significantly enhances the TSR performance.",
    "pdf_link": "https://arxiv.org/abs/2407.05814",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05814v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05814/1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05814v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05814/2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05814v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05814/5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05814v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05814/6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05814v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05814/3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05814v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05814/4.png"
      }
    ],
    "abstract_cn": "近期，多模态大型语言模型如GPT-4o和GPT-4v在自动驾驶领域展现出显著潜力。本文提出了一种基于MLLM的跨领域少样本上下文学习策略，旨在提升交通标志识别（TSR）能力。我们首先构建了一个基于Vision Transformer Adapter的交通标志检测网络，并设计了一个提取模块，从原始道路图像中精准提取交通标志。为减少对大量训练数据的依赖，并增强跨领域TSR的稳定性，我们创新性地引入了基于MLLM的跨领域少样本上下文学习技术。此外，为进一步提升MLLM对交通标志的细粒度识别能力，我们利用模板交通标志生成富含形状、颜色及构成等关键信息的描述文本，有效激发MLLM对细粒度交通标志类别的感知力。通过这些描述文本，我们成功缩小了模板与实际交通标志间的跨领域差异。值得一提的是，我们的方法仅需简单统一的文本指示，无需庞大的交通标志图像库和标签集。我们在德国、比利时的标准数据集以及日本的真实世界数据集上进行了详尽评估，实验结果表明，我们的方法在TSR性能上取得了显著提升。",
    "title_cn": "通过跨域少样本上下文学习提升交通标志识别能力",
    "tags": [
      "LLM应用",
      "自动驾驶",
      ""
    ]
  },
  {
    "title": "Potential of Multimodal Large Language Models for Data Mining of Medical Images and Free-text Reports",
    "submit_datetime": "2024年07月08日",
    "abstract": "Medical images and radiology reports are crucial for diagnosing medical conditions, highlighting the importance of quantitative analysis for clinical decision-making. However, the diversity and cross-source heterogeneity of these data challenge the generalizability of current data-mining methods. Multimodal large language models (MLLMs) have recently transformed many domains, significantly affecting the medical field. Notably, Gemini-Vision-series (Gemini) and GPT-4-series (GPT-4) models have epitomized a paradigm shift in Artificial General Intelligence (AGI) for computer vision, showcasing their potential in the biomedical domain. In this study, we evaluated the performance of the Gemini, GPT-4, and 4 popular large models for an exhaustive evaluation across 14 medical imaging datasets, including 5 medical imaging categories (dermatology, radiology, dentistry, ophthalmology, and endoscopy), and 3 radiology report datasets. The investigated tasks encompass disease classification, lesion segmentation, anatomical localization, disease diagnosis, report generation, and lesion detection. Our experimental results demonstrated that Gemini-series models excelled in report generation and lesion detection but faces challenges in disease classification and anatomical localization. Conversely, GPT-series models exhibited proficiency in lesion segmentation and anatomical localization but encountered difficulties in disease diagnosis and lesion detection. Additionally, both the Gemini series and GPT series contain models that have demonstrated commendable generation efficiency. While both models hold promise in reducing physician workload, alleviating pressure on limited healthcare resources, and fostering collaboration between clinical practitioners and artificial intelligence technologies, substantial enhancements and comprehensive validations remain imperative before clinical deployment.",
    "pdf_link": "https://arxiv.org/abs/2407.05758",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05758v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05758/x7.png"
      }
    ],
    "abstract_cn": "医学图像与放射报告对诊断至关重要，定量分析在此尤为关键。然而，数据多样性与跨源异质性对现有数据挖掘方法的泛化能力构成挑战。多模态大型语言模型（MLLMs）如Gemini与GPT-4，已在多个领域引发变革，医疗领域亦受其深远影响。本研究全面评估了Gemini、GPT-4及四款流行大型模型在14个医学影像数据集上的表现，涵盖五类影像（皮肤病、放射、牙科、眼科、内窥镜）及三类报告数据集，涉及疾病分类、病变分割、解剖定位、疾病诊断、报告生成与病变检测等多项任务。实验显示，Gemini系列在报告生成与病变检测上表现卓越，但在疾病分类与解剖定位上存在挑战；GPT系列则在病变分割与解剖定位上表现优异，但在疾病诊断与病变检测上遇到难题。此外，Gemini与GPT系列均有模型展现出高效的生成能力。尽管这些模型有望减轻医生负担、缓解医疗资源压力并促进医工合作，但在临床应用前，仍需进行重大改进与全面验证。",
    "title_cn": "多模态大型语言模型在医学图像与自由文本报告数据挖掘中的应用潜力",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Multi-Object Hallucination in Vision-Language Models",
    "submit_datetime": "2024年07月08日",
    "abstract": "Large vision language models (LVLMs) often suffer from object hallucination, producing objects not present in the given images. While current benchmarks for object hallucination primarily concentrate on the presence of a single object class rather than individual entities, this work systematically investigates multi-object hallucination, examining how models misperceive (e.g., invent nonexistent objects or become distracted) when tasked with focusing on multiple objects simultaneously. We introduce Recognition-based Object Probing Evaluation (ROPE), an automated evaluation protocol that considers the distribution of object classes within a single image during testing and uses visual referring prompts to eliminate ambiguity. With comprehensive empirical studies and analysis of potential factors leading to multi-object hallucination, we found that (1) LVLMs suffer more hallucinations when focusing on multiple objects compared to a single object. (2) The tested object class distribution affects hallucination behaviors, indicating that LVLMs may follow shortcuts and spurious correlations.(3) Hallucinatory behaviors are influenced by data-specific factors, salience and frequency, and model intrinsic behaviors. We hope to enable LVLMs to recognize and reason about multiple objects that often occur in realistic visual scenes, provide insights, and quantify our progress towards mitigating the issues.",
    "pdf_link": "https://arxiv.org/abs/2407.06192",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06192v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06192/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06192v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06192/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06192v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06192/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06192v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06192/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06192v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06192/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06192v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06192/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06192v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06192/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06192v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06192/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06192v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06192/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06192v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06192/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06192v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06192/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06192v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06192/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06192v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06192/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06192v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06192/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06192v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06192/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06192v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06192/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06192v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06192/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06192v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06192/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06192v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06192/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06192v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06192/x20.png"
      }
    ],
    "abstract_cn": "大型视觉语言模型 (LVLMs) 常因对象幻觉而产生图像中不存在的对象。本研究深入探讨了多对象幻觉现象，特别是在模型同时处理多个对象时可能出现的误感知问题。为此，我们提出了基于识别的对象探测评估 (ROPE)，一种自动化评估方法，它考虑图像内对象类别的分布，并通过视觉指向提示来减少歧义。实证研究表明：(1) LVLMs 在处理多对象时幻觉更频繁。(2) 对象类别的分布影响幻觉行为，暗示模型可能依赖捷径和虚假相关性。(3) 幻觉行为受数据特性和模型内在因素的影响。我们旨在提升 LVLMs 对现实场景中多对象的识别与推理能力，并量化我们在解决幻觉问题上的进展。",
    "title_cn": "视觉-语言模型中的多对象幻觉现象",
    "tags": [
      "LLM应用",
      "计算机视觉",
      "人工智能"
    ]
  },
  {
    "title": "Video-STaR: Self-Training Enables Video Instruction Tuning with Any Supervision",
    "submit_datetime": "2024年07月08日",
    "abstract": "The performance of Large Vision Language Models (LVLMs) is dependent on the size and quality of their training datasets. Existing video instruction tuning datasets lack diversity as they are derived by prompting large language models with video captions to generate question-answer pairs, and are therefore mostly descriptive. Meanwhile, many labeled video datasets with diverse labels and supervision exist - however, we find that their integration into LVLMs is non-trivial. Herein, we present Video Self-Training with augmented Reasoning (Video-STaR), the first video self-training approach. Video-STaR allows the utilization of any labeled video dataset for video instruction tuning. In Video-STaR, an LVLM cycles between instruction generation and finetuning, which we show (I) improves general video understanding and (II) adapts LVLMs to novel downstream tasks with existing supervision. During generation, an LVLM is prompted to propose an answer. The answers are then filtered only to those that contain the original video labels, and the LVLM is then re-trained on the generated dataset. By only training on generated answers that contain the correct video labels, Video-STaR utilizes these existing video labels as weak supervision for video instruction tuning. Our results demonstrate that Video-STaR-enhanced LVLMs exhibit improved performance in (I) general video QA, where TempCompass performance improved by 10%, and (II) on downstream tasks, where Video-STaR improved Kinetics700-QA accuracy by 20% and action quality assessment on FineDiving by 15%.",
    "pdf_link": "https://arxiv.org/abs/2407.06189",
    "graphs": [],
    "abstract_cn": "大型视觉语言模型 (LVLMs) 的性能受其训练数据集的大小和质量影响。现有视频指令调优数据集因依赖于通过视频字幕生成问答对而缺乏多样性，多为描述性内容。同时，虽有许多标记视频数据集具备多样标签和监督，但其整合至 LVLMs 并非简单任务。为此，我们首创了增强推理的视频自训练方法 (Video-STaR)，它允许利用任何标记视频数据集进行指令调优。Video-STaR 通过在指令生成与微调间循环，不仅提升视频理解能力，还能使模型适应新下游任务。在生成阶段，模型提出答案后，仅保留含原始视频标签的答案进行再训练，以此利用现有视频标签作为弱监督。实验显示，Video-STaR 增强的 LVLMs 在一般视频问答中性能提升显著，如 TempCompass 性能提高 10%，在下游任务如 Kinetics700-QA 准确性提升 20%，FineDiving 动作质量评估提升 15%。",
    "title_cn": "Video-STaR：通过自训练，视频指令调优可利用任意监督方式进行。",
    "tags": [
      "LLM应用",
      "视频处理",
      "人工智能"
    ]
  },
  {
    "title": "CrowdMoGen: Zero-Shot Text-Driven Collective Motion Generation",
    "submit_datetime": "2024年07月08日",
    "abstract": "Crowd Motion Generation is essential in entertainment industries such as animation and games as well as in strategic fields like urban simulation and planning. This new task requires an intricate integration of control and generation to realistically synthesize crowd dynamics under specific spatial and semantic constraints, whose challenges are yet to be fully explored. On the one hand, existing human motion generation models typically focus on individual behaviors, neglecting the complexities of collective behaviors. On the other hand, recent methods for multi-person motion generation depend heavily on pre-defined scenarios and are limited to a fixed, small number of inter-person interactions, thus hampering their practicality. To overcome these challenges, we introduce CrowdMoGen, a zero-shot text-driven framework that harnesses the power of Large Language Model (LLM) to incorporate the collective intelligence into the motion generation framework as guidance, thereby enabling generalizable planning and generation of crowd motions without paired training data. Our framework consists of two key components: 1) Crowd Scene Planner that learns to coordinate motions and dynamics according to specific scene contexts or introduced perturbations, and 2) Collective Motion Generator that efficiently synthesizes the required collective motions based on the holistic plans. Extensive quantitative and qualitative experiments have validated the effectiveness of our framework, which not only fills a critical gap by providing scalable and generalizable solutions for Crowd Motion Generation task but also achieves high levels of realism and flexibility.",
    "pdf_link": "https://arxiv.org/abs/2407.06188",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06188v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06188/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06188v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06188/methodfig1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06188v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06188/micromacro.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06188v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06188/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06188v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06188/x3.png"
      }
    ],
    "abstract_cn": "人群运动生成在娱乐和战略领域至关重要，如动画、游戏、城市模拟和规划。这一新任务要求在特定约束下精细整合控制与生成，以真实合成人群动态，其挑战尚待深入探索。现有模型多关注个体行为，忽视集体复杂性；而多人运动生成方法则依赖预设场景，局限于固定少数互动，实用性受限。为此，我们推出CrowdMoGen框架，借助大型语言模型（LLM），将集体智慧融入生成过程，实现无需配对数据的泛化人群运动规划与生成。框架包含两大核心组件：人群场景规划器，根据场景或扰动协调运动；集体运动生成器，高效合成集体运动。实验证明，该框架不仅填补了关键技术空白，提供可扩展、可泛化解决方案，更实现了高度真实与灵活性。",
    "title_cn": "CrowdMoGen：引领零-Shot 文本驱动的集体运动创新",
    "tags": [
      "LLM应用",
      "",
      "城市规划"
    ]
  },
  {
    "title": "Vision-Language Models under Cultural and Inclusive Considerations",
    "submit_datetime": "2024年07月08日",
    "abstract": "Large vision-language models (VLMs) can assist visually impaired people by describing images from their daily lives. Current evaluation datasets may not reflect diverse cultural user backgrounds or the situational context of this use case. To address this problem, we create a survey to determine caption preferences and propose a culture-centric evaluation benchmark by filtering VizWiz, an existing dataset with images taken by people who are blind. We then evaluate several VLMs, investigating their reliability as visual assistants in a culturally diverse setting. While our results for state-of-the-art models are promising, we identify challenges such as hallucination and misalignment of automatic evaluation metrics with human judgment. We make our survey, data, code, and model outputs publicly available.",
    "pdf_link": "https://arxiv.org/abs/2407.06177",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06177v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06177/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06177v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06177/final_analysis_multi.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06177v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06177/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06177v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06177/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06177v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06177/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06177v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06177/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06177v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06177/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06177v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06177/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06177v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06177/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06177v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06177/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06177v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06177/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06177v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06177/final_curr_error.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06177v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06177/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06177v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06177/x20.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06177v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06177/x21.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06177v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06177/x22.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06177v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06177/marvl_agamas.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06177v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06177/mrvl_buddhish.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06177v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06177/marvl_sambar.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06177v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06177/marvl_doner.png"
      }
    ],
    "abstract_cn": "大型视觉-语言模型（VLMs）能通过描述日常图像辅助视障人士。然而，现有评估数据集未能充分体现多元文化背景和实际使用情境。为此，我们设计了一项调查以了解字幕偏好，并基于VizWiz数据集（由盲人拍摄的图像组成）构建了一个文化导向的评估基准。随后，我们对多个VLMs进行了评估，探究其在多元文化环境中的可靠性。尽管最先进模型的表现令人鼓舞，但我们也发现了幻觉现象和自动评估与人类判断不一致等问题。所有相关资源，包括调查、数据、代码及模型输出，均已公开。",
    "title_cn": "文化与包容视角下的视觉语言模型研究",
    "tags": [
      "LLM应用",
      "辅助技术",
      "多元文化"
    ]
  },
  {
    "title": "On Speeding Up Language Model Evaluation",
    "submit_datetime": "2024年07月08日",
    "abstract": "Large language models (LLMs) currently dominate the field of natural language processing (NLP), representing the state-of-the-art across a diverse array of tasks. Developing a model of this nature, from training to inference, requires making numerous decisions which define a combinatorial search problem. For example, selecting the optimal pre-trained LLM, prompt, or hyperparameters to attain the best performance for a task often requires evaluating multiple candidates on an entire test set. This exhaustive evaluation can be time-consuming and costly, as both inference and metric computation with LLMs are resource-intensive. In this paper, we address the challenge of identifying the best method within a limited budget for evaluating methods on test examples. By leveraging the well-studied multi-armed bandit framework, which sequentially selects the next method-example pair to evaluate, our approach, combining multi-armed bandit algorithms with low-rank factorization, significantly reduces the required resources. Experiments show that our algorithms can identify the top-performing method using only 5-15\\% of the typically needed resources, resulting in an 85-95\\% reduction in cost.",
    "pdf_link": "https://arxiv.org/abs/2407.06172",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06172v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06172/resource_savings_color.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06172v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06172/llm-perf-pred.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06172v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06172/main.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06172v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06172/ablation.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06172v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06172/data_distributions.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLM）在自然语言处理（NLP）领域独领风骚，横扫各类任务的顶尖水平。然而，从训练到推理的每一步，都需精心抉择，构成一场复杂的组合搜索。例如，为求任务之巅，我们常需在全测试集上逐一试炼预训练模型、提示语及超参数。此番全面评估，既耗时又耗资，因LLM的推理与评估皆需大量资源。本文直面这一挑战，旨在有限预算内寻觅最佳评估之道。我们巧妙运用多臂老虎机框架，循序渐进地挑选待评对，结合多臂老虎机算法与低秩分解，大幅削减资源需求。实验证明，我们的算法仅以5-15%的常规资源，便能慧眼识珠，将成本削减至85-95%。",
    "title_cn": "加速语言模型评估之道",
    "tags": [
      "LLM理论",
      "计算机科学",
      "人工智能"
    ]
  },
  {
    "title": "What's Wrong with Your Code Generated by Large Language Models? An Extensive Study",
    "submit_datetime": "2024年07月08日",
    "abstract": "The increasing development of large language models (LLMs) in code generation has drawn significant attention among researchers. To enhance LLM-based code generation ability, current efforts are predominantly directed towards collecting high-quality datasets and leveraging diverse training technologies. However, there is a notable lack of comprehensive studies examining the limitations and boundaries of these existing methods. To bridge this gap, we conducted an extensive empirical study evaluating the performance of three leading closed-source LLMs and four popular open-source LLMs on three commonly used benchmarks. Our investigation, which evaluated the length, cyclomatic complexity and API number of the generated code, revealed that these LLMs face challenges in generating successful code for more complex problems, and tend to produce code that is shorter yet more complicated as compared to canonical solutions. Additionally, we developed a taxonomy of bugs for incorrect codes that includes three categories and 12 sub-categories, and analyze the root cause for common bug types. Furthermore, to better understand the performance of LLMs in real-world projects, we manually created a real-world benchmark comprising 140 code generation tasks. Our analysis highlights distinct differences in bug distributions between actual scenarios and existing benchmarks. Finally, we propose a novel training-free iterative method that introduces self-critique, enabling LLMs to critique and correct their generated code based on bug types and compiler feedback. Experimental results demonstrate that our approach can significantly mitigate bugs and increase the passing rate by 29.2% after two iterations, indicating substantial potential for LLMs to handle more complex problems.",
    "pdf_link": "https://arxiv.org/abs/2407.06153",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06153v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06153/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06153v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06153/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06153v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06153/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06153v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06153/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06153v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06153/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06153v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06153/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06153v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06153/x7.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）在代码生成领域的迅猛发展备受瞩目。为提升其代码生成能力，研究重点多放在高质量数据集的收集与多样化训练技术的应用上。然而，现有方法的局限性却鲜有深入探讨。为此，我们展开了一项全面实证研究，对比了三大闭源与四大开源LLM在常用基准上的表现。研究发现，这些模型在应对复杂问题时，生成的代码虽短却更复杂，且与标准方案存在差距。我们还构建了错误分类体系，深入剖析了常见错误的根源。为更贴近实际应用，我们精心设计了包含140项任务的实战基准，揭示了实际与理论基准间的错误分布差异。最终，我们创新提出了一种无需额外训练的迭代方法，通过自我批判机制，使模型能根据错误类型与编译反馈自我修正。实验显示，该方法能大幅降低错误率，两次迭代后通过率提升29.2%，展现了LLM在处理复杂问题上的广阔前景。",
    "title_cn": "大型语言模型所编代码，问题何在？深入探究。",
    "tags": [
      "LLM应用",
      "软件开发",
      "人工智能"
    ]
  },
  {
    "title": "Using Grammar Masking to Ensure Syntactic Validity in LLM-based Modeling Tasks",
    "submit_datetime": "2024年07月08日",
    "abstract": "We present and evaluate a method called grammar masking, which is used to guide large language models (LLMs) toward producing syntactically correct models for a given context-free grammar. Prompt engineering methods such as few-shot learning or priming can be used to improve the chances of an LLM producing correct syntax, but the more complex the grammar, the more time-consuming and less promising these methods become. Previous work is focused primarily on the usage of either language model training or prompt engineering. In this work, a method is presented that restricts the output to a given grammar using constrained decoding to ensure the output adheres to a valid syntax. We use several DSLs built with MontiCore and task multiple LLMs to produce models with and without constrained decoding. A corresponding parser is used to confirm the syntactic correctness of each model. We show that grammar masking can dramatically improve the modeling capabilities of several LLMs, reducing the need for well-refined prompting while increasing the chance of producing correct models.",
    "pdf_link": "https://arxiv.org/abs/2407.06146",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06146v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06146/FSL.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06146v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06146/GrammarMasking_AD.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06146v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06146/GrammarMasking.png"
      }
    ],
    "abstract_cn": "我们提出了一种名为“语法掩蔽”的方法，旨在引导大型语言模型（LLM）生成符合特定上下文无关语法的正确模型。尽管少样本学习或引导等提示工程方法能提高LLM生成正确语法的几率，但随着语法复杂度的增加，这些方法的效率和效果都会大打折扣。以往研究多聚焦于语言模型训练或提示工程。本研究则通过约束解码，将模型输出限定在特定语法范围内，确保输出语法的正确性。我们利用MontiCore构建的多种DSL，并测试了多个LLM在有无约束解码情况下的表现。通过解析器验证模型语法的正确性，结果显示，语法掩蔽能显著提升LLM的建模能力，降低对精细提示的依赖，并提高生成正确模型的概率。",
    "title_cn": "通过语法掩蔽技术，我们确保了 LLM 建模任务中的句法正确性。",
    "tags": [
      "LLM应用",
      "软件工程",
      "人工智能"
    ]
  },
  {
    "title": "Evaluating the Semantic Profiling Abilities of LLMs for Natural Language Utterances in Data Visualization",
    "submit_datetime": "2024年07月08日",
    "abstract": "Automatically generating data visualizations in response to human utterances on datasets necessitates a deep semantic understanding of the data utterance, including implicit and explicit references to data attributes, visualization tasks, and necessary data preparation steps. Natural Language Interfaces (NLIs) for data visualization have explored ways to infer such information, yet challenges persist due to inherent uncertainty in human speech. Recent advances in Large Language Models (LLMs) provide an avenue to address these challenges, but their ability to extract the relevant semantic information remains unexplored. In this study, we evaluate four publicly available LLMs (GPT-4, Gemini-Pro, Llama3, and Mixtral), investigating their ability to comprehend utterances even in the presence of uncertainty and identify the relevant data context and visual tasks. Our findings reveal that LLMs are sensitive to uncertainties in utterances. Despite this sensitivity, they are able to extract the relevant data context. However, LLMs struggle with inferring visualization tasks. Based on these results, we highlight future research directions on using LLMs for visualization generation.",
    "pdf_link": "https://arxiv.org/abs/2407.06129",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06129v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06129/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06129v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06129/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06129v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06129/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06129v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06129/x4.png"
      }
    ],
    "abstract_cn": "自动生成数据可视化以响应人类对数据集的表述，需要深入理解数据表述的语义，包括对数据属性的隐含和显式引用、可视化任务及数据准备步骤。尽管数据可视化的自然语言接口（NLIs）已探索推断此类信息的方法，但人类语言的不确定性仍带来挑战。大型语言模型（LLMs）的最新进展为解决这些挑战提供了可能，但其提取相关语义信息的能力尚未明确。本研究评估了四个公开可用的LLMs（GPT-4、Gemini-Pro、Llama3和Mixtral），探讨它们在不确定性存在时理解表述的能力，并识别相关数据上下文和可视化任务。研究发现，LLMs对表述中的不确定性敏感，但仍能提取相关数据上下文，而在推断可视化任务方面则面临挑战。基于此，我们提出了利用LLMs进行可视化生成的未来研究方向。",
    "title_cn": "探究 LLM 在数据可视化领域对自然语言表达的语义解析能力",
    "tags": [
      "LLM应用",
      "数据可视化",
      "人工智能"
    ]
  },
  {
    "title": "Depression Detection and Analysis using Large Language Models on Textual and Audio-Visual Modalities",
    "submit_datetime": "2024年07月08日",
    "abstract": "Depression has proven to be a significant public health issue, profoundly affecting the psychological well-being of individuals. If it remains undiagnosed, depression can lead to severe health issues, which can manifest physically and even lead to suicide. Generally, Diagnosing depression or any other mental disorder involves conducting semi-structured interviews alongside supplementary questionnaires, including variants of the Patient Health Questionnaire (PHQ) by Clinicians and mental health professionals. This approach places significant reliance on the experience and judgment of trained physicians, making the diagnosis susceptible to personal biases. Given that the underlying mechanisms causing depression are still being actively researched, physicians often face challenges in diagnosing and treating the condition, particularly in its early stages of clinical presentation. Recently, significant strides have been made in Artificial neural computing to solve problems involving text, image, and speech in various domains. Our analysis has aimed to leverage these state-of-the-art (SOTA) models in our experiments to achieve optimal outcomes leveraging multiple modalities. The experiments were performed on the Extended Distress Analysis Interview Corpus Wizard of Oz dataset (E-DAIC) corpus presented in the Audio/Visual Emotion Challenge (AVEC) 2019 Challenge. The proposed solutions demonstrate better results achieved by Proprietary and Open-source Large Language Models (LLMs), which achieved a Root Mean Square Error (RMSE) score of 3.98 on Textual Modality, beating the AVEC 2019 challenge baseline results and current SOTA regression analysis architectures. Additionally, the proposed solution achieved an accuracy of 71.43% in the classification task. The paper also includes a novel audio-visual multi-modal network that predicts PHQ-8 scores with an RMSE of 6.51.",
    "pdf_link": "https://arxiv.org/abs/2407.06125",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06125v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06125/net_1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06125v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06125/Train_1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06125v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06125/Train_2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06125v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06125/Train_3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06125v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06125/Train_4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06125v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06125/net_2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06125v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06125/Gpt_3.5.jpeg"
      },
      {
        "url": "https://arxiv.org/html/2407.06125v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06125/Gpt_4.jpeg"
      },
      {
        "url": "https://arxiv.org/html/2407.06125v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06125/Llama.jpeg"
      }
    ],
    "abstract_cn": "抑郁症已成为影响深远的公共卫生难题，对个体心理健康造成严重冲击。未被识别的抑郁症可能引发一系列严重健康问题，甚至导致自杀。传统上，抑郁症的诊断依赖于半结构化访谈和补充问卷，如患者健康问卷（PHQ），这些方法高度依赖医生的专业判断，易受个人偏见影响。由于抑郁症的内在机制尚在探索中，医生在早期诊断和治疗时面临诸多挑战。近年来，人工神经计算在处理文本、图像和语音等多领域问题方面取得显著进展。我们利用这些尖端模型进行实验，旨在通过多模态分析实现更优结果。实验基于2019年音频/视觉情感挑战（AVEC）中的扩展困境分析访谈语料库（E-DAIC）。我们的解决方案通过专有和开源大型语言模型（LLMs）在文本模态上实现了3.98的RMSE，超越了AVEC 2019的基线和现有SOTA回归架构。此外，分类任务的准确率达到了71.43%。论文还介绍了一种创新的音频-视觉多模态网络，能够以6.51的RMSE预测PHQ-8分数。",
    "title_cn": "利用大型语言模型，结合文本与视听信息，精准检测与分析抑郁症",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Artificial Intuition: Efficient Classification of Scientific Abstracts",
    "submit_datetime": "2024年07月08日",
    "abstract": "It is desirable to coarsely classify short scientific texts, such as grant or publication abstracts, for strategic insight or research portfolio management. These texts efficiently transmit dense information to experts possessing a rich body of knowledge to aid interpretation. Yet this task is remarkably difficult to automate because of brevity and the absence of context. To address this gap, we have developed a novel approach to generate and appropriately assign coarse domain-specific labels. We show that a Large Language Model (LLM) can provide metadata essential to the task, in a process akin to the augmentation of supplemental knowledge representing human intuition, and propose a workflow. As a pilot study, we use a corpus of award abstracts from the National Aeronautics and Space Administration (NASA). We develop new assessment tools in concert with established performance metrics.",
    "pdf_link": "https://arxiv.org/abs/2407.06093",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06093v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06093/label_gen.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06093v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06093/f1_plot_keywords.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06093v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06093/redundancy_plot.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06093v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06093/Prediction_pipeline.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06093v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06093/coverage_plot.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06093v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06093/cluster_eval.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06093v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06093/F1_score_paper.png"
      }
    ],
    "abstract_cn": "为了战略洞察或研究组合管理，对短科学文本进行粗略分类是理想的。这些文本高效地向专家传递密集信息，但因其简短和缺乏上下文，自动化难度大。为此，我们创新了一种方法，生成并分配领域特定标签。通过LLM，我们模拟了人类直觉的补充知识增强过程，并设计了工作流程。试点研究中，我们采用NASA的资助摘要语料库，并结合传统性能指标，开发了新的评估工具。",
    "title_cn": "人工直觉：科学摘要的高效分类",
    "tags": [
      "LLM应用",
      "科学研究",
      "信息管理"
    ]
  },
  {
    "title": "Merge, Ensemble, and Cooperate! A Survey on Collaborative Strategies in the Era of Large Language Models",
    "submit_datetime": "2024年07月08日",
    "abstract": "The remarkable success of Large Language Models (LLMs) has ushered natural language processing (NLP) research into a new era. Despite their diverse capabilities, LLMs trained on different corpora exhibit varying strengths and weaknesses, leading to challenges in maximizing their overall efficiency and versatility. To address these challenges, recent studies have explored collaborative strategies for LLMs. This paper provides a comprehensive overview of this emerging research area, highlighting the motivation behind such collaborations. Specifically, we categorize collaborative strategies into three primary approaches: Merging, Ensemble, and Cooperation. Merging involves integrating multiple LLMs in the parameter space. Ensemble combines the outputs of various LLMs. Cooperation} leverages different LLMs to allow full play to their diverse capabilities for specific tasks. We provide in-depth introductions to these methods from different perspectives and discuss their potential applications. Additionally, we outline future research directions, hoping this work will catalyze further studies on LLM collaborations and paving the way for advanced NLP applications.",
    "pdf_link": "https://arxiv.org/abs/2407.06089",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06089v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06089/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06089v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06089/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06089v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06089/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06089v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06089/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06089v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06089/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06089v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06089/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06089v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06089/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06089v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06089/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06089v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06089/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06089v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06089/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06089v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06089/x11.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLM）的卓越成就引领自然语言处理（NLP）研究进入新纪元。尽管LLM能力各异，但不同语料库训练的模型各有千秋，这为提升其整体效能和灵活性带来挑战。为此，近期研究聚焦于LLM间的协作策略。本文全面梳理这一前沿领域，阐释协作的深层动机。我们将其策略细分为合并、集成与合作三大类：合并通过参数融合多模型，集成整合各模型输出，合作则让不同模型在特定任务中各展所长。我们深入剖析这些策略，并展望其应用前景。同时，勾勒未来研究蓝图，期望推动LLM协作研究，助力NLP技术飞跃。",
    "title_cn": "融合、集成与协作：大型语言模型时代协同策略探析",
    "tags": [
      "LLM理论",
      "人工智能",
      ""
    ]
  },
  {
    "title": "From Loops to Oops: Fallback Behaviors of Language Models Under Uncertainty",
    "submit_datetime": "2024年07月08日",
    "abstract": "Large language models (LLMs) often exhibit undesirable behaviors, such as hallucinations and sequence repetitions. We propose to view these behaviors as fallbacks that models exhibit under uncertainty, and investigate the connection between them. We categorize fallback behaviors -- sequence repetitions, degenerate text, and hallucinations -- and extensively analyze them in models from the same family that differ by the amount of pretraining tokens, parameter count, or the inclusion of instruction-following training. Our experiments reveal a clear and consistent ordering of fallback behaviors, across all these axes: the more advanced an LLM is (i.e., trained on more tokens, has more parameters, or instruction-tuned), its fallback behavior shifts from sequence repetitions, to degenerate text, and then to hallucinations. Moreover, the same ordering is observed throughout a single generation, even for the best-performing models; as uncertainty increases, models shift from generating hallucinations to producing degenerate text and then sequence repetitions. Lastly, we demonstrate that while common decoding techniques, such as random sampling, might alleviate some unwanted behaviors like sequence repetitions, they increase harder-to-detect hallucinations.",
    "pdf_link": "https://arxiv.org/abs/2407.06071",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x20.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x21.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x22.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x23.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x24.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x25.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x26.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x27.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x28.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x29.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x30.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x31.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x32.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x33.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x34.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06071/x35.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLM）常出现幻觉和序列重复等不良行为。我们将其视为模型在不确定性下的回退，并探究其关联。我们将这些行为分为序列重复、退化文本和幻觉，并在不同预训练程度和参数量的模型中深入分析。实验显示，LLM越先进（训练更多、参数更多、指令调优），其回退行为依次从序列重复转为退化文本，再到幻觉。即使在最佳模型中，随着不确定性上升，生成顺序也从幻觉变为退化文本，最终是序列重复。此外，我们发现随机采样等解码技术虽能减轻序列重复，却可能增加难以察觉的幻觉。",
    "title_cn": "当不确定性来袭，语言模型从循环往复走向“哎呀”时刻，探索其在未知中的回退策略。",
    "tags": [
      "LLM理论",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Vision-Braille: An End-to-End Tool for Chinese Braille Image-to-Text Translation",
    "submit_datetime": "2024年07月08日",
    "abstract": "Visually impaired people are a large group who can only use braille for reading and writing. However, the lack of special educational resources is the bottleneck for educating them. Educational equity is a reflection of the level of social civilization, cultural equality, and individual dignity. Facilitating and improving lifelong learning channels for the visually impaired is of great significance. Their written braille homework or exam papers cannot be understood by sighted teachers, because of the lack of a highly accurate braille translation system, especially in Chinese which has tone marks. braille writers often omit tone marks to save space, leading to confusion when braille with the same consonants and vowels is translated into Chinese. Previous algorithms were insufficient in extracting contextual information, resulting in low accuracy of braille translations into Chinese. This project informatively fine-tuned the mT5 model with an Encoder-decoder architecture for braille to Chinese character conversion. This research created a training set of braille and corresponding Chinese text from the Leipzig Corpora. This project significantly reduced the confusion in braille, achieving $62.4$ and $62.3$ BLEU scores in the validation and test sets, with a curriculum learning fine-tuning method. By incorporating the braille recognition algorithm, this project is the first publicly available braille translation system and can benefit lots of visually impaired students and families who are preparing for the Chinese College Test and help to propel their college dreams in the future. There is a demo on our homepage\\footnote{\\url{https://vision-braille.com/}}.",
    "pdf_link": "https://arxiv.org/abs/2407.06048",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06048v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06048/x1.png"
      }
    ],
    "abstract_cn": "视觉障碍者依赖盲文进行读写，但特殊教育资源的匮乏成为他们教育的瓶颈。教育公平是社会文明与个人尊严的体现，改善他们的学习渠道至关重要。由于缺乏精准的盲文翻译系统，尤其是中文中的声调标记问题，视力正常的教师难以理解他们的盲文作业。过去的算法在提取上下文信息方面表现不佳，导致翻译准确性低下。本项目通过微调mT5模型，成功创建了盲文到中文的转换系统，显著提高了翻译的清晰度，验证集和测试集的BLEU分数分别达到了62.4和62.3。这一创新系统不仅为视觉障碍学生及其家庭提供了便利，助力他们实现大学梦想，也是首个公开可用的盲文翻译工具。我们的主页上提供了演示，欢迎体验。",
    "title_cn": "Vision-Braille：一款端到端的中文盲文图像转文本工具",
    "tags": [
      "LLM应用",
      "特殊教育",
      "辅助技术"
    ]
  },
  {
    "title": "MST5 -- Multilingual Question Answering over Knowledge Graphs",
    "submit_datetime": "2024年07月08日",
    "abstract": "Knowledge Graph Question Answering (KGQA) simplifies querying vast amounts of knowledge stored in a graph-based model using natural language. However, the research has largely concentrated on English, putting non-English speakers at a disadvantage. Meanwhile, existing multilingual KGQA systems face challenges in achieving performance comparable to English systems, highlighting the difficulty of generating SPARQL queries from diverse languages. In this research, we propose a simplified approach to enhance multilingual KGQA systems by incorporating linguistic context and entity information directly into the processing pipeline of a language model. Unlike existing methods that rely on separate encoders for integrating auxiliary information, our strategy leverages a single, pretrained multilingual transformer-based language model to manage both the primary input and the auxiliary data. Our methodology significantly improves the language model's ability to accurately convert a natural language query into a relevant SPARQL query. It demonstrates promising results on the most recent QALD datasets, namely QALD-9-Plus and QALD-10. Furthermore, we introduce and evaluate our approach on Chinese and Japanese, thereby expanding the language diversity of the existing datasets.",
    "pdf_link": "https://arxiv.org/abs/2407.06041",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06041v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06041/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06041v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06041/x2.png"
      }
    ],
    "abstract_cn": "知识图谱问答 (KGQA) 利用自然语言简化了海量知识的查询过程，但研究多聚焦于英语，对非英语使用者不利。现有多语言 KGQA 系统在性能上难以匹敌英语系统，凸显了多语言生成 SPARQL 查询的挑战。本研究提出一种简化方法，通过直接整合语言上下文和实体信息至语言模型处理流程，增强多语言 KGQA 系统。我们采用单一预训练多语言变压器模型，统一处理主输入与辅助数据，显著提升自然语言到 SPARQL 查询的转换准确性。该方法在最新 QALD 数据集上表现优异，并首次在中文和日语上进行评估，拓宽了数据集的语言多样性。",
    "title_cn": "MST5 —— 知识图谱上的多语言问答系统",
    "tags": [
      "LLM应用",
      "知识图谱",
      ""
    ]
  },
  {
    "title": "PAS: Data-Efficient Plug-and-Play Prompt Augmentation System",
    "submit_datetime": "2024年07月08日",
    "abstract": "In recent years, the rise of Large Language Models (LLMs) has spurred a growing demand for plug-and-play AI systems. Among the various AI techniques, prompt engineering stands out as particularly significant. However, users often face challenges in writing prompts due to the steep learning curve and significant time investment, and existing automatic prompt engineering (APE) models can be difficult to use. To address this issue, we propose PAS, an LLM-based plug-and-play APE system. PAS utilizes LLMs trained on high-quality, automatically generated prompt complementary datasets, resulting in exceptional performance. In comprehensive benchmarks, PAS achieves state-of-the-art (SoTA) results compared to previous APE models, with an average improvement of 6.09 points. Moreover, PAS is highly efficient, achieving SoTA performance with only 9000 data points. Additionally, PAS can autonomously generate prompt augmentation data without requiring additional human labor. Its flexibility also allows it to be compatible with all existing LLMs and applicable to a wide range of tasks. PAS excels in human evaluations, underscoring its suitability as a plug-in for users. This combination of high performance, efficiency, and flexibility makes PAS a valuable system for enhancing the usability and effectiveness of LLMs through improved prompt engineering.",
    "pdf_link": "https://arxiv.org/abs/2407.06027",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06027v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06027/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06027v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06027/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06027v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06027/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06027v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06027/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06027v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06027/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06027v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06027/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06027v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06027/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06027v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06027/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06027v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06027/x9.png"
      }
    ],
    "abstract_cn": "随着大型语言模型（LLM）的兴起，即插即用AI系统的需求日益增长。在众多AI技术中，提示工程尤为关键。然而，用户在编写提示时往往面临学习难度大和时间成本高的问题，现有的自动提示工程（APE）模型也难以操作。为此，我们推出了PAS，一个基于LLM的即插即用APE系统。PAS通过在高质量自动生成的提示互补数据集上训练LLM，展现出卓越性能。在全面基准测试中，PAS超越以往APE模型，平均提升6.09分，且仅需9000数据点即可达到顶尖性能。PAS还能自主生成提示增强数据，无需额外人力，并兼容所有LLM，适用于多种任务。在人类评估中，PAS表现优异，凸显其作为用户插件的优越性。PAS集高性能、高效率与灵活性于一身，极大地提升了LLM的可用性与效果，是改进提示工程的宝贵工具。",
    "title_cn": "PAS：一款数据高效、即插即用的提示增强系统",
    "tags": [
      "LLM应用",
      "人工智能",
      "软件开发"
    ]
  },
  {
    "title": "Distilling System 2 into System 1",
    "submit_datetime": "2024年07月08日",
    "abstract": "Large language models (LLMs) can spend extra compute during inference to generate intermediate thoughts, which helps to produce better final responses. Since Chain-of-Thought (Wei et al., 2022), many such System 2 techniques have been proposed such as Rephrase and Respond (Deng et al., 2023a), System 2 Attention (Weston and Sukhbaatar, 2023) and Branch-Solve-Merge (Saha et al., 2023). In this work we investigate self-supervised methods to ``compile'' (distill) higher quality outputs from System 2 techniques back into LLM generations without intermediate reasoning token sequences, as this reasoning has been distilled into System 1. We show that several such techniques can be successfully distilled, resulting in improved results compared to the original System 1 performance, and with less inference cost than System 2. We posit that such System 2 distillation will be an important feature of future continually learning AI systems, enabling them to focus System 2 capabilities on the reasoning tasks that they cannot yet do well.",
    "pdf_link": "https://arxiv.org/abs/2407.06023",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06023v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06023/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06023v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06023/MT_bench_wo_tie.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06023v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06023/x2.png"
      }
    ],
    "abstract_cn": "大型语言模型在推理时通过额外计算生成中间思维，从而提升最终响应质量。自 Chain-of-Thought 提出后，多种 System 2 技术如 Rephrase and Respond、System 2 Attention 和 Branch-Solve-Merge 相继涌现。本研究探索自监督方法，将这些 System 2 技术的高质量输出提炼回 LLM，无需中间推理步骤，因为推理已融入 System 1。实验表明，这些技术提炼后不仅性能提升，且推理成本降低。我们预见，这种 System 2 提炼将成为未来 AI 系统持续学习的关键，使其能更高效地运用 System 2 能力于尚需改进的推理任务。",
    "title_cn": "系统2向系统1的精炼转化",
    "tags": [
      "LLM理论",
      "人工智能",
      "机器学习"
    ]
  },
  {
    "title": "Igea: a Decoder-Only Language Model for Biomedical Text Generation in Italian",
    "submit_datetime": "2024年07月08日",
    "abstract": "The development of domain-specific language models has significantly advanced natural language processing applications in various specialized fields, particularly in biomedicine. However, the focus has largely been on English-language models, leaving a gap for less-resourced languages such as Italian. This paper introduces Igea, the first decoder-only language model designed explicitly for biomedical text generation in Italian. Built on the Minerva model and continually pretrained on a diverse corpus of Italian medical texts, Igea is available in three model sizes: 350 million, 1 billion, and 3 billion parameters. The models aim to balance computational efficiency and performance, addressing the challenges of managing the peculiarities of medical terminology in Italian. We evaluate Igea using a mix of in-domain biomedical corpora and general-purpose benchmarks, highlighting its efficacy and retention of general knowledge even after the domain-specific training. This paper discusses the model's development and evaluation, providing a foundation for future advancements in Italian biomedical NLP.",
    "pdf_link": "https://arxiv.org/abs/2407.06011",
    "graphs": [],
    "abstract_cn": "领域特定语言模型在生物医学等专业领域的自然语言处理应用中取得了显著进展，但多聚焦于英语模型，忽视了资源较少的语言如意大利语。本文引入了Igea，首个专为意大利语生物医学文本生成设计的仅解码器语言模型。基于Minerva模型，并在丰富的意大利医学文本上持续预训练，Igea提供三种规模：3.5亿、10亿和30亿参数，旨在兼顾计算效率与性能，应对意大利语医学术语的独特挑战。我们通过结合专业与通用评估基准，验证了Igea在特定训练后仍能有效保留通用知识。本文详细探讨了Igea的开发与评估，为意大利生物医学NLP的未来发展奠定了基础。",
    "title_cn": "Igea：专为意大利语生物医学文本生成设计的解码器语言模型",
    "tags": [
      "LLM应用",
      "生物医学",
      ""
    ]
  },
  {
    "title": "Perceptions to Beliefs: Exploring Precursory Inferences for Theory of Mind in Large Language Models",
    "submit_datetime": "2024年07月08日",
    "abstract": "While humans naturally develop theory of mind (ToM), the capability to understand other people's mental states and beliefs, state-of-the-art large language models (LLMs) underperform on simple ToM benchmarks. We posit that we can extend our understanding of LLMs' ToM abilities by evaluating key human ToM precursors -- perception inference and perception-to-belief inference -- in LLMs. We introduce two datasets, Percept-ToMi and Percept-FANToM, to evaluate these precursory inferences for ToM in LLMs by annotating characters' perceptions on ToMi and FANToM, respectively. Our evaluation of eight state-of-the-art LLMs reveals that the models generally perform well in perception inference while exhibiting limited capability in perception-to-belief inference (e.g., lack of inhibitory control). Based on these results, we present PercepToM, a novel ToM method leveraging LLMs' strong perception inference capability while supplementing their limited perception-to-belief inference. Experimental results demonstrate that PercepToM significantly enhances LLM's performance, especially in false belief scenarios.",
    "pdf_link": "https://arxiv.org/abs/2407.06004",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06004v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06004/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06004v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06004/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06004v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06004/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06004v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06004/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06004v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06004/x5.png"
      }
    ],
    "abstract_cn": "人类自然地发展出理解他人心理状态和信念的心智理论 (ToM)，但大型语言模型 (LLM) 在这方面表现不佳。我们通过评估 LLM 中的关键 ToM 先驱——感知推理和感知到信念推理，来深化对 LLM 的 ToM 能力的理解。为此，我们创建了两个数据集，Percept-ToMi 和 Percept-FANToM，分别注释角色的感知，以评估这些先驱推理。评估显示，LLM 在感知推理上表现良好，但在感知到信念推理上能力有限。基于此，我们提出了 PercepToM，一种结合 LLM 强大感知推理能力并增强其感知到信念推理的新方法。实验证明，PercepToM 显著提升了 LLM 在错误信念场景中的性能。",
    "title_cn": "从感知到信念：探究大型语言模型中心智理论的先导推断",
    "tags": [
      "LLM理论",
      "人工智能",
      "心理学"
    ]
  },
  {
    "title": "Exploring Human-LLM Conversations: Mental Models and the Originator of Toxicity",
    "submit_datetime": "2024年07月08日",
    "abstract": "This study explores real-world human interactions with large language models (LLMs) in diverse, unconstrained settings in contrast to most prior research focusing on ethically trimmed models like ChatGPT for specific tasks. We aim to understand the originator of toxicity. Our findings show that although LLMs are rightfully accused of providing toxic content, it is mostly demanded or at least provoked by humans who actively seek such content. Our manual analysis of hundreds of conversations judged as toxic by APIs commercial vendors, also raises questions with respect to current practices of what user requests are refused to answer. Furthermore, we conjecture based on multiple empirical indicators that humans exhibit a change of their mental model, switching from the mindset of interacting with a machine more towards interacting with a human.",
    "pdf_link": "https://arxiv.org/abs/2407.05977",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05977v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05977/doesnotAllow2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05977v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05977/gettingMoreHuman.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05977v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05977/histoToxPer.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05977v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05977/mentalmodel.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05977v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05977/turns_WC_please.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05977v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05977/turns_WC_thanks_.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05977v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05977/turns_WC_sorry_a.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05977v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05977/turns_WC_you_you.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05977v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05977/turns_flesch.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05977v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05977/turns_len.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05977v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05977/turns_sexual.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05977v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05977/FirstBig_harassment_exceed_.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05977v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05977/FirstBig_sexual_exceed_.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05977v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05977/distrTox.png"
      }
    ],
    "abstract_cn": "本研究深入探讨了人类在自由多样的环境中与大型语言模型（LLM）的互动，与以往专注于特定任务的道德修剪模型研究形成鲜明对比。我们旨在揭示毒性内容的根源。研究发现，虽然LLM常被指责传播有害信息，但这往往源于人类的需求或至少是他们的挑衅。通过手动分析数百个被标记为有毒的对话，我们质疑了当前拒绝回答用户请求的做法。此外，基于多项实证数据，我们推测人类在与LLM互动时，心理模式正从机器互动转向更接近人类互动。",
    "title_cn": "探究人类与 LLM 对话中的心理模型及毒性源头",
    "tags": [
      "LLM应用",
      "人工智能",
      "社会科学"
    ]
  },
  {
    "title": "LLaMAX: Scaling Linguistic Horizons of LLM by Enhancing Translation Capabilities Beyond 100 Languages",
    "submit_datetime": "2024年07月08日",
    "abstract": "Large Language Models~(LLMs) demonstrate remarkable translation capabilities in high-resource language tasks, yet their performance in low-resource languages is hindered by insufficient multilingual data during pre-training. To address this, we dedicate 35,000 A100-SXM4-80GB GPU hours in conducting extensive multilingual continual pre-training on the LLaMA series models, enabling translation support across more than 100 languages. Through a comprehensive analysis of training strategies, such as vocabulary expansion and data augmentation, we develop LLaMAX. Remarkably, without sacrificing its generalization ability, LLaMAX achieves significantly higher translation performance compared to existing open-source LLMs~(by more than 10 spBLEU points) and performs on-par with specialized translation model~(M2M-100-12B) on the Flores-101 benchmark. Extensive experiments indicate that LLaMAX can serve as a robust multilingual foundation model. The code~\\footnote{\\url{https://github.com/CONE-MT/LLaMAX/.}} and models~\\footnote{\\url{https://huggingface.co/LLaMAX/.}} are publicly available.",
    "pdf_link": "https://arxiv.org/abs/2407.05975",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05975v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05975/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05975v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05975/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05975v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05975/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05975v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05975/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05975v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05975/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05975v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05975/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05975v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05975/x7.png"
      }
    ],
    "abstract_cn": "在高资源语言任务中，大型语言模型（LLMs）的翻译能力令人瞩目，但在低资源语言中，由于预训练数据不足，性能受限。为此，我们投入大量资源，对LLaMA系列模型进行多语言持续预训练，支持百余种语言的翻译。通过优化训练策略，如词汇扩展和数据增强，我们打造了LLaMAX。LLaMAX不仅保持了强大的泛化能力，还在翻译性能上大幅超越现有开源LLMs，与专业翻译模型在Flores-101基准上不相上下。实验证实，LLaMAX可作为稳健的多语言基础模型。相关代码和模型已公开，供公众使用。",
    "title_cn": "LLaMAX：拓展LLM的语言边界，强化超百种语言的翻译实力",
    "tags": [
      "LLM应用",
      "",
      "多语言处理"
    ]
  },
  {
    "title": "Towards Optimizing and Evaluating a Retrieval Augmented QA Chatbot using LLMs with Human in the Loop",
    "submit_datetime": "2024年07月08日",
    "abstract": "Large Language Models have found application in various mundane and repetitive tasks including Human Resource (HR) support. We worked with the domain experts of SAP SE to develop an HR support chatbot as an efficient and effective tool for addressing employee inquiries. We inserted a human-in-the-loop in various parts of the development cycles such as dataset collection, prompt optimization, and evaluation of generated output. By enhancing the LLM-driven chatbot's response quality and exploring alternative retrieval methods, we have created an efficient, scalable, and flexible tool for HR professionals to address employee inquiries effectively. Our experiments and evaluation conclude that GPT-4 outperforms other models and can overcome inconsistencies in data through internal reasoning capabilities. Additionally, through expert analysis, we infer that reference-free evaluation metrics such as G-Eval and Prometheus demonstrate reliability closely aligned with that of human evaluation.",
    "pdf_link": "https://arxiv.org/abs/2407.05925",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05925v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05925/n-tokens-articles.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05925v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05925/workflow.png"
      }
    ],
    "abstract_cn": "我们与SAP SE的专家携手，打造了一款HR支持聊天机器人，旨在高效解决员工疑问。在开发过程中，我们在数据集构建、提示优化及输出评估等环节融入了人工参与。此举不仅提升了聊天机器人的回复质量，还探索了新的检索策略，使之成为HR领域高效、灵活且可扩展的利器。实验表明，GPT-4凭借其卓越性能和内部推理能力，有效应对了数据不一致的挑战。同时，G-Eval和Prometheus等无参考评估指标，经专家验证，其可靠性已接近人类评估水平。",
    "title_cn": "探索优化与评估：结合 LLM 与人工反馈的增强型检索问答聊天机器人",
    "tags": [
      "LLM应用",
      "人力资源",
      "人工智能"
    ]
  },
  {
    "title": "Generation and De-Identification of Indian Clinical Discharge Summaries using LLMs",
    "submit_datetime": "2024年07月08日",
    "abstract": "The consequences of a healthcare data breach can be devastating for the patients, providers, and payers. The average financial impact of a data breach in recent months has been estimated to be close to USD 10 million. This is especially significant for healthcare organizations in India that are managing rapid digitization while still establishing data governance procedures that align with the letter and spirit of the law. Computer-based systems for de-identification of personal information are vulnerable to data drift, often rendering them ineffective in cross-institution settings. Therefore, a rigorous assessment of existing de-identification against local health datasets is imperative to support the safe adoption of digital health initiatives in India. Using a small set of de-identified patient discharge summaries provided by an Indian healthcare institution, in this paper, we report the nominal performance of de-identification algorithms (based on language models) trained on publicly available non-Indian datasets, pointing towards a lack of cross-institutional generalization. Similarly, experimentation with off-the-shelf de-identification systems reveals potential risks associated with the approach. To overcome data scarcity, we explore generating synthetic clinical reports (using publicly available and Indian summaries) by performing in-context learning over Large Language Models (LLMs). Our experiments demonstrate the use of generated reports as an effective strategy for creating high-performing de-identification systems with good generalization capabilities.",
    "pdf_link": "https://arxiv.org/abs/2407.05887",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05887/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05887/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05887/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05887/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05887/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05887/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05887/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05887/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05887/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05887/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05887/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05887/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05887/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05887/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05887/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05887/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05887/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05887/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05887/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05887/x20.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05887/x21.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05887/x22.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05887/x23.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05887/x24.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05887/x25.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05887/x26.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05887/x27.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05887/x28.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05887v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05887/x29.png"
      }
    ],
    "abstract_cn": "医疗数据泄露的后果对患者、提供者和支付者都可能是毁灭性的，平均财务影响近1000万美元。在印度，快速数字化与数据治理程序的建立并行，这对医疗机构尤为关键。去标识化系统易受数据漂移影响，跨机构应用时常无效。因此，对现有去标识化系统进行严格评估，以支持印度数字健康举措的安全采用至关重要。本研究利用印度医疗机构提供的去标识化患者出院总结，揭示了基于非印度数据集训练的去标识化算法在跨机构泛化上的不足。同时，现成的去标识化系统也存在潜在风险。为解决数据稀缺问题，我们通过在大语言模型上进行上下文学习，生成合成临床报告，实验证明这是一种有效策略，可创建具有良好泛化能力的高性能去标识化系统。",
    "title_cn": "利用大型语言模型生成并去识别化印度临床出院总结",
    "tags": [
      "LLM应用",
      "",
      "数据安全"
    ]
  },
  {
    "title": "KG-FPQ: Evaluating Factuality Hallucination in LLMs with Knowledge Graph-based False Premise Questions",
    "submit_datetime": "2024年07月08日",
    "abstract": "Recent studies have demonstrated that large language models (LLMs) are susceptible to being misled by false premise questions (FPQs), leading to errors in factual knowledge, know as factuality hallucination. Existing benchmarks that assess this vulnerability primarily rely on manual construction, resulting in limited scale and lack of scalability. In this work, we introduce an automated, scalable pipeline to create FPQs based on knowledge graphs (KGs). The first step is modifying true triplets extracted from KGs to create false premises. Subsequently, utilizing the state-of-the-art capabilities of GPTs, we generate semantically rich FPQs. Based on the proposed method, we present a comprehensive benchmark, the Knowledge Graph-based False Premise Questions (KG-FPQ), which contains approximately 178k FPQs across three knowledge domains, at six levels of confusability, and in two task formats. Using KG-FPQ, we conduct extensive evaluations on several representative LLMs and provide valuable insights. The KG-FPQ dataset and code are available at~https://github.com/yanxuzhu/KG-FPQ.",
    "pdf_link": "https://arxiv.org/abs/2407.05868",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05868v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05868/example.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05868v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05868/data_constructing.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05868v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05868/editing.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05868v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05868/evaluation_procedure.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05868v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05868/NSCvsNNSC.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05868v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05868/fpq6_art_hop.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05868v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05868/NSCvsNDC.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05868v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05868/NNSCvsNNDC.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05868v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05868/NNSRvsNNDR.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05868v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05868/NNSCvsNNSR.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05868v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05868/disvsgen_art.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05868v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05868/tpqvsfpq.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05868v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05868/model_size_fpq.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05868v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05868/fpq6_art_hop.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05868v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05868/fpq6_people_hop.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05868v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05868/fpq6_place_hop.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05868v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05868/fpq5_art_hop.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05868v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05868/fpq5_people_hop.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05868v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05868/fpq5_place_hop.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05868v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05868/disvsgen_people.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05868v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05868/disvsgen_place.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05868v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05868/model_size_tpq.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05868v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05868/models.png"
      }
    ],
    "abstract_cn": "最新研究发现，大型语言模型 (LLMs) 易受错误前提问题 (FPQs) 影响，产生事实幻觉。现有评估方法因手动构建而受限。为此，我们开发了基于知识图谱 (KGs) 的自动化流程，首先修改真实三元组创造错误前提，再利用 GPT 生成语义丰富的 FPQs。我们提出的 KG-FPQ 基准涵盖约 178k 个 FPQs，跨越三个领域，六个混淆级别，两种任务格式。通过 KG-FPQ，我们对多个 LLMs 进行了深入评估，并揭示了关键见解。KG-FPQ 数据集和代码已公开，详见 https://github.com/yanxuzhu/KG-FPQ。",
    "title_cn": "KG-FPQ：通过基于知识图的错误前提问题，评估 LLM 中的事实性幻觉问题。",
    "tags": [
      "LLM应用",
      "知识图谱",
      "人工智能"
    ]
  },
  {
    "title": "Empowering 1000 tokens/second on-device LLM prefilling with mllm-NPU",
    "submit_datetime": "2024年07月08日",
    "abstract": "On-device large language models (LLMs) are catalyzing novel mobile applications such as UI task automation and personalized email auto-reply, without giving away users' private data. However, on-device LLMs still suffer from unacceptably long inference latency, especially the time to first token (prefill stage) due to the need of long context for accurate, personalized content generation, as well as the lack of parallel computing capacity of mobile CPU/GPU.\n  To enable practical on-device LLM, we present mllm-NPU, the first-of-its-kind LLM inference system that efficiently leverages on-device Neural Processing Unit (NPU) offloading. Essentially, mllm-NPU is an algorithm-system co-design that tackles a few semantic gaps between the LLM architecture and contemporary NPU design. Specifically, it re-constructs the prompt and model in three levels: (1) At prompt level, it divides variable-length prompts into multiple fixed-sized chunks while maintaining data dependencies; (2) At tensor level, it identifies and extracts significant outliers to run on the CPU/GPU in parallel with minimal overhead; (3) At block level, it schedules Transformer blocks in an out-of-order manner to the CPU/GPU and NPU based on their hardware affinity and sensitivity to accuracy. Compared to competitive baselines, mllm-NPU achieves 22.4x faster prefill speed and 30.7x energy savings on average, and up to 32.8x speedup in an end-to-end real-world application. For the first time, mllm-NPU achieves more than 1,000 tokens/sec prefilling for a billion-sized model (Qwen1.5-1.8B), paving the way towards practical on-device LLM.",
    "pdf_link": "https://arxiv.org/abs/2407.05858",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05858v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05858/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05858v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05858/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05858v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05858/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05858v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05858/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05858v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05858/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05858v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05858/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05858v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05858/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05858v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05858/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05858v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05858/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05858v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05858/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05858v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05858/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05858v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05858/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05858v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05858/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05858v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05858/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05858v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05858/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05858v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05858/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05858v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05858/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05858v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05858/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05858v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05858/x19.png"
      }
    ],
    "abstract_cn": "设备上的大型语言模型（LLM）正推动着创新的移动应用，如界面任务自动化和个性化邮件自动回复，同时保护用户隐私。然而，这些模型仍受困于过长的推理延迟，尤其是在首次生成令牌时。为了解决这一难题，我们推出了mllm-NPU，这一开创性的LLM推理系统巧妙地利用了设备上的神经处理单元（NPU）。mllm-NPU通过算法与系统的深度融合，有效弥合了LLM架构与现代NPU设计间的语义鸿沟。它通过三个层面的创新重构提示与模型：首先，在提示层面，将可变长度提示分割为固定大小块，保持数据依赖；其次，在张量层面，识别并并行处理关键异常值，降低开销；最后，在块层面，根据硬件特性与准确性需求，灵活调度Transformer块。相较于现有技术，mllm-NPU在预填充速度上提升了22.4倍，能耗节省达30.7倍，实际应用中加速高达32.8倍。这一突破首次实现了十亿级模型每秒预填充超过1,000个令牌，为设备上LLM的实用化开辟了新纪元。",
    "title_cn": "借助mllm-NPU，实现设备上LLM每秒高效预填充1000个令牌。",
    "tags": [
      "LLM应用",
      "移动应用",
      "人工智能"
    ]
  },
  {
    "title": "An Empirical Comparison of Vocabulary Expansion and Initialization Approaches for Language Models",
    "submit_datetime": "2024年07月08日",
    "abstract": "Language Models (LMs) excel in natural language processing tasks for English but show reduced performance in most other languages. This problem is commonly tackled by continually pre-training and fine-tuning these models for said languages. A significant issue in this process is the limited vocabulary coverage in the original model's tokenizer, leading to inadequate representation of new languages and necessitating an expansion of the tokenizer. The initialization of the embeddings corresponding to new vocabulary items presents a further challenge. Current strategies require cross-lingual embeddings and lack a solid theoretical foundation as well as comparisons with strong baselines. In this paper, we first establish theoretically that initializing within the convex hull of existing embeddings is a good initialization, followed by a novel but simple approach, Constrained Word2Vec (CW2V), which does not require cross-lingual embeddings. Our study evaluates different initialization methods for expanding RoBERTa and LLaMA 2 across four languages and five tasks. The results show that CW2V performs equally well or even better than more advanced techniques. Additionally, simpler approaches like multivariate initialization perform on par with these advanced methods indicating that efficient large-scale multilingual continued pretraining can be achieved even with simpler initialization methods.",
    "pdf_link": "https://arxiv.org/abs/2407.05841",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05841v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05841/vocab_expansion_setup.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05841v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05841/roberta_final_plot.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05841v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05841/llama_avg.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05841v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05841/roberta_cpt_en.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05841v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05841/init_ouput.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05841v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05841/roberta_xnli_all_plots.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05841v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05841/roberta_ner_all_plots.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05841v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05841/roberta_qa_all_plots.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05841v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05841/llama_mt_all_plots.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05841v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05841/llama_xnli_all_plots.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05841v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05841/llama_xlsum_all_plots.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05841v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05841/llama_qa_all_plots.png"
      }
    ],
    "abstract_cn": "尽管语言模型在英语处理中表现卓越，但在其他多数语言中性能却有所下降。通常，这一难题通过持续的预训练和微调来解决。然而，原始模型分词器的词汇覆盖不足，导致新语言的表达力受限，进而需要扩展分词器。此外，新词汇的嵌入初始化也是一个挑战。当前方法依赖于跨语言嵌入，且缺乏坚实的理论支撑和强有力的比较基准。本文中，我们首先从理论上论证了在现有嵌入的凸包内进行初始化是有效的，随后提出了一种新颖且简便的方法——约束 Word2Vec (CW2V)，无需跨语言嵌入。我们的研究在四种语言和五项任务中评估了不同的初始化方法，结果表明 CW2V 的表现与高级技术不相上下，甚至更优。同时，简单的多元初始化方法也显示出与这些高级技术相当的性能，这表明即使采用简单的初始化方法，也能实现高效的大规模多语言持续预训练。",
    "title_cn": "语言模型中词汇扩展与初始化方法的实证对比研究",
    "tags": [
      "LLM理论",
      "",
      "机器学习"
    ]
  },
  {
    "title": "HyCIR: Boosting Zero-Shot Composed Image Retrieval with Synthetic Labels",
    "submit_datetime": "2024年07月08日",
    "abstract": "Composed Image Retrieval (CIR) aims to retrieve images based on a query image with text. Current Zero-Shot CIR (ZS-CIR) methods try to solve CIR tasks without using expensive triplet-labeled training datasets. However, the gap between ZS-CIR and triplet-supervised CIR is still large. In this work, we propose Hybrid CIR (HyCIR), which uses synthetic labels to boost the performance of ZS-CIR. A new label Synthesis pipeline for CIR (SynCir) is proposed, in which only unlabeled images are required. First, image pairs are extracted based on visual similarity. Second, query text is generated for each image pair based on vision-language model and LLM. Third, the data is further filtered in language space based on semantic similarity. To improve ZS-CIR performance, we propose a hybrid training strategy to work with both ZS-CIR supervision and synthetic CIR triplets. Two kinds of contrastive learning are adopted. One is to use large-scale unlabeled image dataset to learn an image-to-text mapping with good generalization. The other is to use synthetic CIR triplets to learn a better mapping for CIR tasks. Our approach achieves SOTA zero-shot performance on the common CIR benchmarks: CIRR and CIRCO.",
    "pdf_link": "https://arxiv.org/abs/2407.05795",
    "graphs": [],
    "abstract_cn": "组合图像检索（CIR）旨在根据带有文本的查询图像检索图像。当前的零样本CIR（ZS-CIR）方法试图在不使用昂贵的三元组标记训练数据集的情况下解决CIR任务。然而，ZS-CIR与三元组监督的CIR之间的差距仍然很大。在这项工作中，我们提出了混合CIR（HyCIR），它使用合成标签来提升ZS-CIR的性能。我们提出了一种新的CIR标签合成流程（SynCir），其中仅需要未标记的图像。首先，基于视觉相似性提取图像对。其次，基于视觉-语言模型和LLM为每个图像对生成查询文本。第三，基于语义相似性在语言空间中进一步过滤数据。为了提高ZS-CIR性能，我们提出了一种混合训练策略，结合ZS-CIR监督和合成CIR三元组。采用了两种对比学习方法。一种是使用大规模未标记图像数据集学习具有良好泛化的图像到文本映射。另一种是使用合成CIR三元组学习更适合CIR任务的映射。我们的方法在常见的CIR基准测试（CIRR和CIRCO）上实现了SOTA的零样本性能。",
    "title_cn": "HyCIR 技术通过合成标签，显著提升了零-shot组合图像检索的性能。",
    "tags": [
      "LLM应用",
      "图像检索",
      "机器学习"
    ]
  },
  {
    "title": "Large Language Models for Judicial Entity Extraction: A Comparative Study",
    "submit_datetime": "2024年07月08日",
    "abstract": "Domain-specific Entity Recognition holds significant importance in legal contexts, serving as a fundamental task that supports various applications such as question-answering systems, text summarization, machine translation, sentiment analysis, and information retrieval specifically within case law documents. Recent advancements have highlighted the efficacy of Large Language Models in natural language processing tasks, demonstrating their capability to accurately detect and classify domain-specific facts (entities) from specialized texts like clinical and financial documents. This research investigates the application of Large Language Models in identifying domain-specific entities (e.g., courts, petitioner, judge, lawyer, respondents, FIR nos.) within case law documents, with a specific focus on their aptitude for handling domain-specific language complexity and contextual variations. The study evaluates the performance of state-of-the-art Large Language Model architectures, including Large Language Model Meta AI 3, Mistral, and Gemma, in the context of extracting judicial facts tailored to Indian judicial texts. Mistral and Gemma emerged as the top-performing models, showcasing balanced precision and recall crucial for accurate entity identification. These findings confirm the value of Large Language Models in judicial documents and demonstrate how they can facilitate and quicken scientific research by producing precise, organised data outputs that are appropriate for in-depth examination.",
    "pdf_link": "https://arxiv.org/abs/2407.05786",
    "graphs": [],
    "abstract_cn": "领域特定实体识别在法律领域至关重要，支持多种应用，如问答系统、文本摘要等，特别是在案例法文档中。最新进展显示，大型语言模型在自然语言处理中表现出色，能从专业文本中精准识别和分类特定实体。本研究聚焦于大型语言模型在案例法文档中识别特定实体的能力，特别是处理语言复杂性和上下文变化的能力。研究评估了包括Meta AI 3、Mistral和Gemma在内的先进模型，在提取印度司法文本相关事实方面的表现。Mistral和Gemma表现卓越，精确度和召回率均衡，对实体识别至关重要。这些成果不仅证实了大型语言模型在司法领域的价值，还展示了它们如何通过生成精确、有序的数据，加速科学研究，为深入分析提供支持。",
    "title_cn": "司法实体提取领域的大型语言模型比较研究",
    "tags": [
      "LLM应用",
      "",
      ""
    ]
  },
  {
    "title": "Hecaton: Training and Finetuning Large Language Models with Scalable Chiplet Systems",
    "submit_datetime": "2024年07月08日",
    "abstract": "Large Language Models (LLMs) have achieved remarkable success in various fields, but their training and finetuning require massive computation and memory, necessitating parallelism which introduces heavy communication overheads. Driven by advances in packaging, the chiplet architecture emerges as a potential solution, as it can integrate computing power, as well as utilize on-package links with better signal integrity, higher bandwidth, and lower energy consumption. However, most existing chiplet-related works focus on DNN inference. Directly porting them to LLM training introduces significantly large quantities of DRAM access and network-on-package (NoP) overheads which make state-of-the-art chiplet designs fail, highlighting a research gap.\n  This work proposes Hecaton, a scalable and cost-effective chiplet system for LLM training and finetuning. We first provide a chiplet architecture with tailored scheduling that can largely reduce DRAM accesses. We further design an efficient distributed training method that reduces NoP communication complexity and relieves constraints on SRAM capacity and layout. Theoretical analysis shows that the entire system achieves weak scaling: as the workload and hardware resources grow proportionally, the computation-to-communication ratio remains nearly constant. Experiments with various workloads and hardware configurations verify the property, and Hecaton achieves $4.98\\times$ performance improvement and $2.35\\times$ energy reduction on Llama2-70B, compared to the tensor parallelism in Megatron. To the best of our knowledge, we propose the first chiplet architecture specifically used for LLM training or finetuning, with guaranteed performance regardless of the problem scale.",
    "pdf_link": "https://arxiv.org/abs/2407.05784",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05784v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05784/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05784v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05784/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05784v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05784/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05784v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05784/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05784v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05784/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05784v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05784/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05784v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05784/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05784v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05784/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05784v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05784/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05784v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05784/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05784v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05784/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05784v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05784/x12.png"
      }
    ],
    "abstract_cn": "大型语言模型 (LLM) 在多领域取得显著成就，但其训练与微调对计算和内存需求巨大，导致并行化带来高额通信成本。随着封装技术的发展，chiplet 架构应运而生，它集成了计算能力，并通过优化封装内链接，提供更佳的信号完整性、高带宽和低能耗。然而，现有 chiplet 研究多聚焦于 DNN 推理，直接应用于 LLM 训练则引发大量 DRAM 访问和封装内网络 (NoP) 开销，使先进 chiplet 设计失效，揭示了研究缺口。  本研究提出 Hecaton，一个专为 LLM 训练与微调设计的可扩展、高性价比 chiplet 系统。我们首先构建了一个定制调度的 chiplet 架构，显著减少 DRAM 访问。接着，我们设计了一种高效的分布式训练策略，降低 NoP 通信复杂性，并放宽对 SRAM 容量和布局的限制。理论分析显示，该系统实现了弱扩展：工作负载与硬件资源同比例增长时，计算与通信比率几乎恒定。实验证明，Hecaton 在 Llama2-70B 上相较于 Megatron 的张量并行，实现了 $4.98\\times$ 的性能提升和 $2.35\\times$ 的能耗节省。据我们所知，这是首个专为 LLM 训练或微调设计的 chiplet 架构，确保了性能的稳定性，不受问题规模影响。",
    "title_cn": "Hecaton：借助可扩展的小芯片系统，高效训练与微调大型语言模型。",
    "tags": [
      "LLM理论",
      "半导体",
      "人工智能"
    ]
  },
  {
    "title": "When is the consistent prediction likely to be a correct prediction?",
    "submit_datetime": "2024年07月08日",
    "abstract": "Self-consistency (Wang et al., 2023) suggests that the most consistent answer obtained through large language models (LLMs) is more likely to be correct. In this paper, we challenge this argument and propose a nuanced correction. Our observations indicate that consistent answers derived through more computation i.e. longer reasoning texts, rather than simply the most consistent answer across all outputs, are more likely to be correct. This is predominantly because we demonstrate that LLMs can autonomously produce chain-of-thought (CoT) style reasoning with no custom prompts merely while generating longer responses, which lead to consistent predictions that are more accurate. In the zero-shot setting, by sampling Mixtral-8x7B model multiple times and considering longer responses, we achieve 86% of its self-consistency performance obtained through zero-shot CoT prompting on the GSM8K and MultiArith datasets. Finally, we demonstrate that the probability of LLMs generating a longer response is quite low, highlighting the need for decoding strategies conditioned on output length.",
    "pdf_link": "https://arxiv.org/abs/2407.05778",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05778/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05778/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05778/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05778/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05778/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05778/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05778/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05778/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05778/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05778/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05778/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05778/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05778/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05778/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05778/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05778/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05778/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05778/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05778/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05778/x20.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05778/x21.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05778/x22.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05778/x23.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05778/x24.png"
      }
    ],
    "abstract_cn": "自我一致性理论（Wang et al., 2023）认为，大型语言模型（LLM）中最一致的答案更可能是正确答案。然而，我们对此提出质疑，并进行了细致的修正。我们发现，通过更多计算，即更长的推理文本，而非简单地选择所有输出中最一致的答案，得出的结果更可能正确。这是因为LLM能在无特殊提示下，自主生成链式思维（CoT）风格的推理，尤其是在生成较长响应时，这使得预测更为一致且准确。在零-shot场景下，通过多次采样Mixtral-8x7B模型并关注较长响应，我们在GSM8K和MultiArith数据集上达到了零-shot CoT提示下自我一致性性能的86%。此外，我们指出LLM生成较长响应的概率较低，这凸显了根据输出长度调整解码策略的重要性。",
    "title_cn": "何时一致的预测更可能是正确的？",
    "tags": [
      "LLM理论",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Large Language Models Understand Layouts",
    "submit_datetime": "2024年07月08日",
    "abstract": "Large language models (LLMs) demonstrate extraordinary abilities in a wide range of natural language processing (NLP) tasks. In this paper, we show that, beyond text understanding capability, LLMs are capable of processing text layouts that are denoted by spatial markers. They are able to answer questions that require explicit spatial perceiving and reasoning, while a drastic performance drop is observed when the spatial markers from the original data are excluded. We perform a series of experiments with the GPT-3.5, Baichuan2, Llama2 and ChatGLM3 models on various types of layout-sensitive datasets for further analysis. The experimental results reveal that the layout understanding ability of LLMs is mainly introduced by the coding data for pretraining, which is further enhanced at the instruction-tuning stage. In addition, layout understanding can be enhanced by integrating low-cost, auto-generated data approached by a novel text game. Finally, we show that layout understanding ability is beneficial for building efficient visual question-answering (VQA) systems.",
    "pdf_link": "https://arxiv.org/abs/2407.05750",
    "graphs": [],
    "abstract_cn": "大型语言模型 (LLMs) 在众多 NLP 任务中表现卓越。本文揭示，LLMs 不仅能理解文本，还能处理空间标记指示的文本布局，解答涉及空间感知的问题。然而，去除空间标记会导致性能大幅下降。我们通过 GPT-3.5、Baichuan2、Llama2 和 ChatGLM3 在布局敏感数据集上的实验，发现布局理解能力源自预训练数据，并在指令调优中强化。利用创新文本游戏自动生成数据，可进一步增强布局理解。此外，这种能力对构建高效的视觉问答 (VQA) 系统大有裨益。",
    "title_cn": "大型语言模型具备理解布局的能力。",
    "tags": [
      "LLM应用",
      "人工智能",
      "视觉问答"
    ]
  },
  {
    "title": "Do Multilingual Large Language Models Mitigate Stereotype Bias?",
    "submit_datetime": "2024年07月08日",
    "abstract": "While preliminary findings indicate that multilingual LLMs exhibit reduced bias compared to monolingual ones, a comprehensive understanding of the effect of multilingual training on bias mitigation, is lacking. This study addresses this gap by systematically training six LLMs of identical size (2.6B parameters) and architecture: five monolingual models (English, German, French, Italian, and Spanish) and one multilingual model trained on an equal distribution of data across these languages, all using publicly available data. To ensure robust evaluation, standard bias benchmarks were automatically translated into the five target languages and verified for both translation quality and bias preservation by human annotators. Our results consistently demonstrate that multilingual training effectively mitigates bias. Moreover, we observe that multilingual models achieve not only lower bias but also superior prediction accuracy when compared to monolingual models with the same amount of training data, model architecture, and size.",
    "pdf_link": "https://arxiv.org/abs/2407.05740",
    "graphs": [],
    "abstract_cn": "初步研究表明，多语言大型语言模型（LLMs）的偏差较单语言模型少。然而，关于多语言训练如何有效减少偏差，我们知之甚少。本研究通过训练六个相同规模（2.6B参数）和架构的LLMs，包括五个单语言模型（英语、德语、法语、意大利语和西班牙语）和一个涵盖这些语言的多语言模型，来深入探讨这一问题。为确保评估的准确性，我们将标准偏差测试自动翻译成五种语言，并由专家验证其翻译质量和偏差保留情况。研究结果显示，多语言训练不仅能有效减少偏差，还能提升预测准确性，优于同等条件下的单语言模型。",
    "title_cn": "多语言大型语言模型能否缓解刻板印象偏见？",
    "tags": [
      "LLM理论",
      "人工智能",
      "语言处理"
    ]
  },
  {
    "title": "Empirical Study of Symmetrical Reasoning in Conversational Chatbots",
    "submit_datetime": "2024年07月08日",
    "abstract": "This work explores the capability of conversational chatbots powered by large language models (LLMs), to understand and characterize predicate symmetry, a cognitive linguistic function traditionally believed to be an inherent human trait. Leveraging in-context learning (ICL), a paradigm shift enabling chatbots to learn new tasks from prompts without re-training, we assess the symmetrical reasoning of five chatbots: ChatGPT 4, Huggingface chat AI, Microsoft's Copilot AI, LLaMA through Perplexity, and Gemini Advanced. Using the Symmetry Inference Sentence (SIS) dataset by Tanchip et al. (2020), we compare chatbot responses against human evaluations to gauge their understanding of predicate symmetry. Experiment results reveal varied performance among chatbots, with some approaching human-like reasoning capabilities. Gemini, for example, reaches a correlation of 0.85 with human scores, while providing a sounding justification for each symmetry evaluation. This study underscores the potential and limitations of LLMs in mirroring complex cognitive processes as symmetrical reasoning.",
    "pdf_link": "https://arxiv.org/abs/2407.05734",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05734v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05734/gemini7_cormat.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05734v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05734/sim_scores.png"
      }
    ],
    "abstract_cn": "本研究探索了大型语言模型 (LLM) 驱动的对话聊天机器人在理解谓词对称性方面的能力，这是一种传统上被视为人类独有的认知语言功能。通过利用上下文学习 (ICL) 这一创新方法，我们评估了 ChatGPT 4、Huggingface 聊天 AI、微软 Copilot AI、Perplexity 的 LLaMA 和 Gemini Advanced 这五款聊天机器人的对称推理能力。我们采用 Tanchip 等人 (2020) 的 Symmetry Inference Sentence (SIS) 数据集，对比聊天机器人的响应与人类评估，以检验它们对谓词对称性的理解。实验结果显示，各聊天机器人的表现参差不齐，部分已接近人类推理水平。例如，Gemini 与人类评分相关性高达 0.85，且每次评估均提供合理解释。此研究凸显了 LLM 在模拟对称推理等复杂认知过程中的潜力与局限。",
    "title_cn": "探究对话型聊天机器人中的对称推理实证研究",
    "tags": [
      "LLM应用",
      "人工智能",
      "语言处理"
    ]
  },
  {
    "title": "Is GPT-4 Alone Sufficient for Automated Essay Scoring?: A Comparative Judgment Approach Based on Rater Cognition",
    "submit_datetime": "2024年07月08日",
    "abstract": "Large Language Models (LLMs) have shown promise in Automated Essay Scoring (AES), but their zero-shot and few-shot performance often falls short compared to state-of-the-art models and human raters. However, fine-tuning LLMs for each specific task is impractical due to the variety of essay prompts and rubrics used in real-world educational contexts. This study proposes a novel approach combining LLMs and Comparative Judgment (CJ) for AES, using zero-shot prompting to choose between two essays. We demonstrate that a CJ method surpasses traditional rubric-based scoring in essay scoring using LLMs.",
    "pdf_link": "https://arxiv.org/abs/2407.05733",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05733v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05733/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05733v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05733/x3.png"
      }
    ],
    "abstract_cn": "尽管大型语言模型在自动作文评分领域展现出潜力，但其零-shot 和少-shot 性能仍不及顶尖模型和人类评分者。鉴于实际教育场景中作文题目和评分标准的多样性，逐一微调模型并不现实。为此，本研究创新性地结合了 LLM 与比较判断技术，通过零-shot 提示在两篇作文间做出选择，结果显示，这种方法在 LLM 辅助的作文评分中，显著优于传统评分标准。",
    "title_cn": "GPT-4 能否独立胜任自动作文评分？本研究采用基于评分者认知的比较判断方法，探讨其可行性。",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "PsycoLLM: Enhancing LLM for Psychological Understanding and Evaluation",
    "submit_datetime": "2024年07月08日",
    "abstract": "Mental health has attracted substantial attention in recent years and LLM can be an effective technology for alleviating this problem owing to its capability in text understanding and dialogue. However, existing research in this domain often suffers from limitations, such as training on datasets lacking crucial prior knowledge and evidence, and the absence of comprehensive evaluation methods. In this paper, we propose a specialized psychological large language model (LLM), named PsycoLLM, trained on a proposed high-quality psychological dataset, including single-turn QA, multi-turn dialogues enriched with prior knowledge and knowledge-based QA. Additionally, to compare the performance of PsycoLLM with other LLMs, we develop a comprehensive psychological benchmark based on authoritative psychological counseling examinations in China, which includes assessments of professional ethics, theoretical proficiency, and case analysis. The experimental results on the benchmark illustrates the effectiveness of PsycoLLM, which demonstrates superior performance compared to other LLMs.",
    "pdf_link": "https://arxiv.org/abs/2407.05721",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05721v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05721/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05721v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05721/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05721v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05721/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05721v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05721/x4.png"
      }
    ],
    "abstract_cn": "近年来，心理健康备受瞩目，LLM凭借其出色的文本理解和对话能力，成为缓解这一问题的有力工具。然而，现有研究常因数据集缺乏关键先验知识、评估方法不全面而受限。为此，我们推出了PsycoLLM，一款专为心理学设计的大型语言模型，它基于一个精心构建的高质量心理学数据集进行训练，涵盖单轮问答、多轮对话及富含先验知识的问答。为评估PsycoLLM的性能，我们依据中国权威心理咨询考试，打造了一个全面的心理学基准，包括专业伦理、理论熟练度和案例分析的考核。实验结果表明，PsycoLLM在各项测试中表现卓越，远超其他LLM。",
    "title_cn": "PsycoLLM：提升 LLM 的心理理解和评估能力",
    "tags": [
      "LLM应用",
      "心理健康",
      "人工智能"
    ]
  },
  {
    "title": "InverseCoder: Unleashing the Power of Instruction-Tuned Code LLMs with Inverse-Instruct",
    "submit_datetime": "2024年07月08日",
    "abstract": "Recent advancements in open-source code large language models (LLMs) have demonstrated remarkable coding abilities by fine-tuning on the data generated from powerful closed-source LLMs such as GPT-3.5 and GPT-4 for instruction tuning. This paper explores how to further improve an instruction-tuned code LLM by generating data from itself rather than querying closed-source LLMs. Our key observation is the misalignment between the translation of formal and informal languages: translating formal language (i.e., code) to informal language (i.e., natural language) is more straightforward than the reverse. Based on this observation, we propose INVERSE-INSTRUCT, which summarizes instructions from code snippets instead of the reverse. Specifically, given an instruction tuning corpus for code and the resulting instruction-tuned code LLM, we ask the code LLM to generate additional high-quality instructions for the original corpus through code summarization and self-evaluation. Then, we fine-tune the base LLM on the combination of the original corpus and the self-generated one, which yields a stronger instruction-tuned LLM. We present a series of code LLMs named InverseCoder, which surpasses the performance of the original code LLMs on a wide range of benchmarks, including Python text-to-code generation, multilingual coding, and data-science code generation.",
    "pdf_link": "https://arxiv.org/abs/2407.05700",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05700v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05700/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05700v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05700/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05700v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05700/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05700v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05700/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05700v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05700/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05700v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05700/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05700v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05700/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05700v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05700/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05700v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05700/similarity.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.05700v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05700/scaling.png"
      }
    ],
    "abstract_cn": "近期，开源代码大型语言模型 (LLM) 通过在由 GPT-3.5 和 GPT-4 等闭源 LLM 生成的数据上进行指令调优，展现了卓越的编码能力。本文探讨了如何通过从自身生成数据而非依赖闭源 LLM 来进一步提升指令调优的代码 LLM。我们发现，将代码（正式语言）翻译为自然语言（非正式语言）比反向翻译更为直接。基于此，我们提出 INVERSE-INSTRUCT 方法，从代码片段中提取指令而非相反。具体而言，我们利用代码 LLM 对原始语料库进行代码摘要和自我评估，生成高质量指令，进而结合原始与新生成的语料库对基础 LLM 进行微调，得到更强大的指令调优 LLM。我们推出的 InverseCoder 系列模型，在 Python 文本到代码生成、多语言编码及数据科学代码生成等多项基准测试中，性能超越了原始代码 LLM。",
    "title_cn": "InverseCoder：借助 Inverse-Instruct 技术，释放指令调优代码大型模型（LLM）的潜能。",
    "tags": [
      "LLM应用",
      "软件开发",
      "人工智能"
    ]
  },
  {
    "title": "Sub-SA: Strengthen In-context Learning via Submodular Selective Annotation",
    "submit_datetime": "2024年07月08日",
    "abstract": "In-context learning (ICL) leverages in-context examples as prompts for the predictions of Large Language Models (LLMs). These prompts play a crucial role in achieving strong performance. However, the selection of suitable prompts from a large pool of labeled examples often entails significant annotation costs. To address this challenge, we propose \\textbf{Sub-SA} (\\textbf{Sub}modular \\textbf{S}elective \\textbf{A}nnotation), a submodule-based selective annotation method. The aim of Sub-SA is to reduce annotation costs while improving the quality of in-context examples and minimizing the time consumption of the selection process. In Sub-SA, we design a submodular function that facilitates effective subset selection for annotation and demonstrates the characteristics of monotonically and submodularity from the theoretical perspective. Specifically, we propose \\textbf{RPR} (\\textbf{R}eward and \\textbf{P}enalty \\textbf{R}egularization) to better balance the diversity and representativeness of the unlabeled dataset attributed to a reward term and a penalty term, respectively. Consequently, the selection for annotations can be effectively addressed with a simple yet effective greedy search algorithm based on the submodular function. Finally, we apply the similarity prompt retrieval to get the examples for ICL.",
    "pdf_link": "https://arxiv.org/abs/2407.05693",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05693v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05693/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05693v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05693/x2.png"
      }
    ],
    "abstract_cn": "ICL 通过上下文示例作为 LLM 预测的提示，这些提示对实现高性能至关重要。然而，从众多标记示例中挑选合适提示往往成本高昂。为此，我们引入了 Sub-SA，一种基于子模块的选择性注释方法，旨在降低成本、提升示例质量并简化选择流程。Sub-SA 设计了子模块函数，助力高效注释子集选择，并从理论层面展现其单调与子模块特性。我们进一步提出 RPR，通过奖励与惩罚机制平衡数据多样性与代表性。基于此，我们采用简单高效的贪婪算法进行注释选择。最终，通过相似性提示检索为 ICL 提供示例。",
    "title_cn": "Sub-SA：借助子模块选择性注释强化上下文学习",
    "tags": [
      "LLM应用",
      "人工智能",
      "数据注释"
    ]
  },
  {
    "title": "Pruning Large Language Models to Intra-module Low-rank Architecture with Transitional Activations",
    "submit_datetime": "2024年07月08日",
    "abstract": "Structured pruning fundamentally reduces computational and memory overheads of large language models (LLMs) and offers a feasible solution for end-side LLM deployment. Structurally pruned models remain dense and high-precision, highly compatible with further tuning and compression. However, as the coarse-grained structured pruning poses large damage to the highly interconnected model, achieving a high compression ratio for scaled-up LLMs remains a challenge. In this paper, we introduce a task-agnostic structured pruning approach coupled with a compact Transformer architecture design. The proposed approach, named TransAct, reduces transitional activations inside multi-head attention (MHA) and multi-layer perceptron (MLP) modules, while preserving the inter-module activations that are sensitive to perturbations. Hence, the LLM is pruned into an intra-module low-rank architecture, significantly reducing weights, KV Cache and attention computation. TransAct is implemented on the LLaMA model and evaluated on downstream benchmarks. Results verify the optimality of our approach at high compression with respect to both efficiency and performance. Further, ablation studies reveal the strength of activation-guided iterative pruning and provide experimental analysis on the redundancy of MHA and MLP modules.",
    "pdf_link": "https://arxiv.org/abs/2407.05690",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05690v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05690/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05690v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05690/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05690v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05690/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05690v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05690/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05690v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05690/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05690v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05690/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05690v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05690/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05690v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05690/x8.png"
      }
    ],
    "abstract_cn": "结构化剪枝技术有效降低了大型语言模型的计算和内存负担，为终端部署提供了可行方案。剪枝后的模型保持高密度和高精度，便于后续调优和压缩。然而，粗粒度剪枝对模型的损害较大，实现高压缩比仍具挑战。本文提出了一种任务无关的结构化剪枝方法TransAct，结合紧凑Transformer架构，减少MHA和MLP模块内的激活，同时保护模块间敏感激活。这使得LLM转化为低秩架构，大幅减少权重和计算。在LLaMA模型上的实验表明，TransAct在保持高效性和性能的同时，实现了高压缩比。消融研究进一步证实了激活引导剪枝的有效性，并分析了MHA和MLP模块的冗余。",
    "title_cn": "精简大型语言模型至模块内低秩结构，结合过渡激活技术",
    "tags": [
      "LLM理论",
      "计算机科学",
      "人工智能"
    ]
  },
  {
    "title": "Retrieved In-Context Principles from Previous Mistakes",
    "submit_datetime": "2024年07月08日",
    "abstract": "In-context learning (ICL) has been instrumental in adapting Large Language Models (LLMs) to downstream tasks using correct input-output examples. Recent advances have attempted to improve model performance through principles derived from mistakes, yet these approaches suffer from lack of customization and inadequate error coverage. To address these limitations, we propose Retrieved In-Context Principles (RICP), a novel teacher-student framework. In RICP, the teacher model analyzes mistakes from the student model to generate reasons and insights for preventing similar mistakes. These mistakes are clustered based on their underlying reasons for developing task-level principles, enhancing the error coverage of principles. During inference, the most relevant mistakes for each question are retrieved to create question-level principles, improving the customization of the provided guidance. RICP is orthogonal to existing prompting methods and does not require intervention from the teacher model during inference. Experimental results across seven reasoning benchmarks reveal that RICP effectively enhances performance when applied to various prompting strategies.",
    "pdf_link": "https://arxiv.org/abs/2407.05682",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05682v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05682/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05682v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05682/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05682v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05682/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05682v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05682/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05682v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05682/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05682v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05682/x6.png"
      }
    ],
    "abstract_cn": "In-context learning (ICL) 在 LLM 适应下游任务中扮演关键角色，但现有方法在定制化和错误覆盖上存在不足。为此，我们引入了 Retrieval In-Context Principles (RICP)，一个创新的师生框架。RICP 通过教师模型分析学生模型的错误，生成针对性的改进建议，并根据错误原因进行分类，提升原则的错误覆盖率。在推理时，系统会为每个问题定制相关原则，无需教师模型介入。实验表明，RICP 能有效提升多种提示策略的性能，跨越七个推理基准。",
    "title_cn": "汲取过往失误中的上下文原则",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "DebUnc: Mitigating Hallucinations in Large Language Model Agent Communication with Uncertainty Estimations",
    "submit_datetime": "2024年07月08日",
    "abstract": "To enhance Large Language Model (LLM) capabilities, multi-agent debates have been introduced, where multiple LLMs discuss solutions to a problem over several rounds of debate. However, LLMs often produce incorrect responses that appear deceptively confident, which can mislead other agents. This is partly because agents do not express their confidence levels during standard debates. To address this, we introduce DebUnc, a multi-agent debate framework that uses uncertainty metrics to assess agent confidence levels. We adapted the LLM attention mechanism to adjust token weights based on confidence levels and also explored using textual prompts to convey confidence. Our evaluations across various benchmarks show that attention-based methods are particularly effective, and that as uncertainty metrics evolve, performance will continue to increase. The code is available at https://github.com/lukeyoffe/debunc",
    "pdf_link": "https://arxiv.org/abs/2407.06426",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06426v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06426/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06426v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06426/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06426v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06426/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06426v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06426/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06426v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06426/x5.png"
      }
    ],
    "abstract_cn": "为了提升 LLM 的性能，我们引入了多智能体辩论机制，让多个 LLM 通过多轮辩论共同探讨解决方案。但 LLM 常给出看似自信的错误答案，可能误导其他智能体。为此，我们开发了 DebUnc 框架，通过不确定性度量来评估智能体的信心水平。我们改进了 LLM 的注意力机制，根据信心调整令牌权重，并尝试用文本提示传达信心。评估结果表明，基于注意力的方法效果显著，且随着不确定性度量的改进，性能将持续提升。代码已公开在 https://github.com/lukeyoffe/debunc。",
    "title_cn": "DebUnc：利用不确定性估计，有效减少大型语言模型代理通信中的幻觉现象。",
    "tags": [
      "LLM应用",
      "人工智能",
      "软件开发"
    ]
  },
  {
    "title": "SimPal: Towards a Meta-Conversational Framework to Understand Teacher's Instructional Goals for K-12 Physics",
    "submit_datetime": "2024年07月08日",
    "abstract": "Simulations are widely used to teach science in grade schools. These simulations are often augmented with a conversational artificial intelligence (AI) agent to provide real-time scaffolding support for students conducting experiments using the simulations. AI agents are highly tailored for each simulation, with a predesigned set of Instructional Goals (IGs), making it difficult for teachers to adjust IGs as the agent may no longer align with the revised IGs. Additionally, teachers are hesitant to adopt new third-party simulations for the same reasons. In this research, we introduce SimPal, a Large Language Model (LLM) based meta-conversational agent, to solve this misalignment issue between a pre-trained conversational AI agent and the constantly evolving pedagogy of instructors. Through natural conversation with SimPal, teachers first explain their desired IGs, based on which SimPal identifies a set of relevant physical variables and their relationships to create symbolic representations of the desired IGs. The symbolic representations can then be leveraged to design prompts for the original AI agent to yield better alignment with the desired IGs. We empirically evaluated SimPal using two LLMs, ChatGPT-3.5 and PaLM 2, on 63 Physics simulations from PhET and Golabz. Additionally, we examined the impact of different prompting techniques on LLM's performance by utilizing the TELeR taxonomy to identify relevant physical variables for the IGs. Our findings showed that SimPal can do this task with a high degree of accuracy when provided with a well-defined prompt.",
    "pdf_link": "https://arxiv.org/abs/2407.06241",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06241v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06241/SimPal.png"
      }
    ],
    "abstract_cn": "在小学科学教育中，模拟教学广受欢迎，常辅以对话式AI代理，为学生提供实时实验支持。然而，每个AI代理都针对特定模拟定制，预设教学目标（IGs）固定，教师难以调整，且对新模拟持保留态度。为此，我们研发了SimPal，一款基于大型语言模型的元对话代理，旨在弥合AI与教学法间的鸿沟。教师通过与SimPal的自然交流，阐述期望的IGs，SimPal据此识别相关物理变量及其关系，构建符号表示，进而优化原始AI代理的提示设计，以更精准地匹配期望IGs。我们通过ChatGPT-3.5和PaLM 2对63个物理模拟进行了实证测试，并利用TELeR分类法探究了提示技术对LLM性能的影响。结果显示，SimPal在明确提示下能高效准确地完成任务。",
    "title_cn": "SimPal：构建元对话框架，深入解析 K-12 物理教学中教师的指导目标",
    "tags": [
      "Agent",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Multimodal Chain-of-Thought Reasoning via ChatGPT to Protect Children from Age-Inappropriate Apps",
    "submit_datetime": "2024年07月08日",
    "abstract": "Mobile applications (Apps) could expose children to inappropriate themes such as sexual content, violence, and drug use. Maturity rating offers a quick and effective method for potential users, particularly guardians, to assess the maturity levels of apps. Determining accurate maturity ratings for mobile apps is essential to protect children's health in today's saturated digital marketplace. Existing approaches to maturity rating are either inaccurate (e.g., self-reported rating by developers) or costly (e.g., manual examination). In the literature, there are few text-mining-based approaches to maturity rating. However, each app typically involves multiple modalities, namely app description in the text, and screenshots in the image. In this paper, we present a framework for determining app maturity levels that utilize multimodal large language models (MLLMs), specifically ChatGPT-4 Vision. Powered by Chain-of-Thought (CoT) reasoning, our framework systematically leverages ChatGPT-4 to process multimodal app data (i.e., textual descriptions and screenshots) and guide the MLLM model through a step-by-step reasoning pathway from initial content analysis to final maturity rating determination. As a result, through explicitly incorporating CoT reasoning, our framework enables ChatGPT to understand better and apply maturity policies to facilitate maturity rating. Experimental results indicate that the proposed method outperforms all baseline models and other fusion strategies.",
    "pdf_link": "https://arxiv.org/abs/2407.06309",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06309v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06309/GPT4V_app_structure.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.06309v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06309/An_example_GPT_app_bin_prompt.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.06309v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06309/confusion_matrix.png"
      }
    ],
    "abstract_cn": "移动应用可能让儿童接触不适内容，如色情、暴力和毒品。成熟度评级为家长提供快速有效的评估工具。在数字市场，确保评级准确性对儿童保护至关重要。现有方法或不准确，或成本高昂。本文提出一种新框架，利用ChatGPT-4 Vision等多模态大型语言模型，通过链式思维推理，系统处理应用的文本描述和截图，逐步推理至成熟度评级。实验显示，该方法性能卓越，超越其他模型和策略。",
    "title_cn": "利用 ChatGPT 进行多模态思维链推理，守护儿童远离不适龄应用的侵害",
    "tags": [
      "LLM应用",
      "儿童保护",
      "数字市场"
    ]
  },
  {
    "title": "VIMI: Grounding Video Generation through Multi-modal Instruction",
    "submit_datetime": "2024年07月08日",
    "abstract": "Existing text-to-video diffusion models rely solely on text-only encoders for their pretraining. This limitation stems from the absence of large-scale multimodal prompt video datasets, resulting in a lack of visual grounding and restricting their versatility and application in multimodal integration. To address this, we construct a large-scale multimodal prompt dataset by employing retrieval methods to pair in-context examples with the given text prompts and then utilize a two-stage training strategy to enable diverse video generation tasks within the same model. In the first stage, we propose a multimodal conditional video generation framework for pretraining on these augmented datasets, establishing a foundational model for grounded video generation. Secondly, we finetune the model from the first stage on three video generation tasks, incorporating multi-modal instructions. This process further refines the model's ability to handle diverse inputs and tasks, ensuring seamless integration of multi-modal information. After this two-stage train-ing process, VIMI demonstrates multimodal understanding capabilities, producing contextually rich and personalized videos grounded in the provided inputs, as shown in Figure 1. Compared to previous visual grounded video generation methods, VIMI can synthesize consistent and temporally coherent videos with large motion while retaining the semantic control. Lastly, VIMI also achieves state-of-the-art text-to-video generation results on UCF101 benchmark.",
    "pdf_link": "https://arxiv.org/abs/2407.06304",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06304v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06304/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06304v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06304/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06304v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06304/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06304v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06304/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06304v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06304/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06304v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06304/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06304v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06304/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06304v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06304/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06304v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06304/x9.png"
      }
    ],
    "abstract_cn": "现有的文本到视频模型因缺乏大规模多模态数据集而受限，我们通过构建新数据集和两阶段训练策略，提升了模型的多模态理解和视频生成能力。VIMI不仅能生成内容丰富、个性化的视频，还在UCF101基准测试中达到了顶尖水平。",
    "title_cn": "VIMI：借助多模态指令，奠定视频生成之基石",
    "tags": [
      "LLM应用",
      "视频制作",
      "人工智能"
    ]
  },
  {
    "title": "VQA-Diff: Exploiting VQA and Diffusion for Zero-Shot Image-to-3D Vehicle Asset Generation in Autonomous Driving",
    "submit_datetime": "2024年07月08日",
    "abstract": "Generating 3D vehicle assets from in-the-wild observations is crucial to autonomous driving. Existing image-to-3D methods cannot well address this problem because they learn generation merely from image RGB information without a deeper understanding of in-the-wild vehicles (such as car models, manufacturers, etc.). This leads to their poor zero-shot prediction capability to handle real-world observations with occlusion or tricky viewing angles. To solve this problem, in this work, we propose VQA-Diff, a novel framework that leverages in-the-wild vehicle images to create photorealistic 3D vehicle assets for autonomous driving. VQA-Diff exploits the real-world knowledge inherited from the Large Language Model in the Visual Question Answering (VQA) model for robust zero-shot prediction and the rich image prior knowledge in the Diffusion model for structure and appearance generation. In particular, we utilize a multi-expert Diffusion Models strategy to generate the structure information and employ a subject-driven structure-controlled generation mechanism to model appearance information. As a result, without the necessity to learn from a large-scale image-to-3D vehicle dataset collected from the real world, VQA-Diff still has a robust zero-shot image-to-novel-view generation ability. We conduct experiments on various datasets, including Pascal 3D+, Waymo, and Objaverse, to demonstrate that VQA-Diff outperforms existing state-of-the-art methods both qualitatively and quantitatively.",
    "pdf_link": "https://arxiv.org/abs/2407.06516",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06516/mov.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06516/framework.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06516/com.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06516/design.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06516/tesla3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06516/ourtesla.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06516/medm.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06516/161.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06516/162.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06516/structure.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06516/p3d.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06516/waymo.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06516/obj.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06516/diverse00.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06516/paint.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06516/sub1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06516/fine.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06516/views.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06516/feature.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06516/shapenet.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06516/vqaa.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06516/vqab.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06516/r2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06516/lim.png"
      }
    ],
    "abstract_cn": "在自动驾驶领域，从自然场景中捕捉的图像生成3D车辆模型至关重要。然而，传统方法仅依赖图像RGB信息，未能深入理解车辆的细节，如车型和制造商，导致在复杂现实场景中的零-shot预测能力不足。为此，我们创新性地提出了VQA-Diff框架，它结合了视觉问答模型中的大型语言模型知识，以及扩散模型中的丰富图像先验，共同打造逼真的3D车辆模型。通过多专家扩散模型策略和主题驱动的结构控制生成机制，VQA-Diff无需依赖大规模真实数据集，便能实现强大的零-shot图像到新视角生成能力。实验结果显示，VQA-Diff在多个数据集上均超越了现有顶尖技术，无论是在视觉效果还是性能指标上。",
    "title_cn": "VQA-Diff 技术结合视觉问答与扩散模型，为自动驾驶领域带来零-shot 图像至 3D 车辆资产的生成能力。",
    "tags": [
      "LLM应用",
      "自动驾驶",
      "汽车制造"
    ]
  },
  {
    "title": "Towards Understanding Multi-Task Learning (Generalization) of LLMs via Detecting and Exploring Task-Specific Neurons",
    "submit_datetime": "2024年07月08日",
    "abstract": "While large language models (LLMs) have demonstrated superior multi-task capabilities, understanding the learning mechanisms behind this is still a challenging problem. In this paper, we attempt to understand such mechanisms from the perspective of neurons. Specifically, we detect task-sensitive neurons in LLMs via gradient attribution on task-specific data. Through extensive deactivation and fine-tuning experiments, we demonstrate that the detected neurons are highly correlated with the given task, which we term as task-specific neurons. With these identified task-specific neurons, we delve into two common problems in multi-task learning and continuous learning: Generalization and Catastrophic Forgetting. We find that the overlap of task-specific neurons is strongly associated with generalization and specialization across tasks. Interestingly, at certain layers of LLMs, there is a high similarity in the parameters of different task-specific neurons, and such similarity is highly correlated with the generalization performance. Inspired by these findings, we propose a neuron-level continuous fine-tuning method that only fine-tunes the current task-specific neurons during continuous learning, and extensive experiments demonstrate the effectiveness of the proposed method. Our study provides insights into the interpretability of LLMs in multi-task learning.",
    "pdf_link": "https://arxiv.org/abs/2407.06488",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06488v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06488/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06488v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06488/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06488v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06488/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06488v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06488/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06488v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06488/x5.png"
      }
    ],
    "abstract_cn": "大型语言模型 (LLMs) 虽展现出卓越的多任务能力，但其学习机制的理解仍具挑战。本文从神经元视角切入，通过梯度归因在特定任务数据上识别任务敏感神经元，并证实其与任务的高度相关性，即特定任务神经元。借助这些神经元，我们探讨了多任务学习中的泛化和灾难性遗忘问题，发现神经元重叠与任务间泛化及专业化紧密相关。LLMs 某些层中神经元参数的高度相似性亦与泛化性能相关。基于此，我们提出神经元级连续微调法，仅微调当前任务神经元，实验证明其有效性。本研究深化了 LLMs 在多任务学习中的可解释性认识。",
    "title_cn": "本研究旨在通过识别和探究任务特定神经元，深入理解 LLMs 在多任务学习中的泛化能力。",
    "tags": [
      "LLM理论",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Optimal Decision Making Through Scenario Simulations Using Large Language Models",
    "submit_datetime": "2024年07月08日",
    "abstract": "The rapid evolution of Large Language Models (LLMs) has markedly expanded their application across diverse domains, transforming how complex problems are approached and solved. Initially conceived to predict subsequent words in texts, these models have transcended their original design to comprehend and respond to the underlying contexts of queries. Today, LLMs routinely perform tasks that once seemed formidable, such as writing essays, poems, stories, and even developing software code. As their capabilities continue to grow, so too do the expectations of their performance in even more sophisticated domains.\n  Despite these advancements, LLMs still encounter significant challenges, particularly in scenarios requiring intricate decision-making, such as planning trips or choosing among multiple viable options. These tasks often demand a nuanced understanding of various outcomes and the ability to predict the consequences of different choices, which are currently outside the typical operational scope of LLMs.\n  This paper proposes an innovative approach to bridge this capability gap. By enabling LLMs to request multiple potential options and their respective parameters from users, our system introduces a dynamic framework that integrates an optimization function within the decision-making process. This function is designed to analyze the provided options, simulate potential outcomes, and determine the most advantageous solution based on a set of predefined criteria. By harnessing this methodology, LLMs can offer tailored, optimal solutions to complex, multi-variable problems, significantly enhancing their utility and effectiveness in real-world applications. This approach not only expands the functional envelope of LLMs but also paves the way for more autonomous and intelligent systems capable of supporting sophisticated decision-making tasks.",
    "pdf_link": "https://arxiv.org/abs/2407.06486",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLM）的迅猛发展极大地拓宽了其在各领域的应用，重塑了我们处理复杂问题的方式。这些模型最初仅用于预测文本中的下一个词，如今已能深入理解并回应查询的语境。现在，LLM 能够轻松完成撰写论文、创作诗歌、编写故事甚至开发软件代码等曾经艰巨的任务。随着其能力的不断提升，人们对它们在更高级领域的表现也寄予厚望。然而，LLM 在需要精细决策的场景中仍面临挑战，如旅行规划或多个选项的选择。这些任务要求对多种结果有深刻理解，并能预测不同选择的后果，而这超出了 LLM 的常规能力范围。本文提出了一种创新方法，通过让 LLM 向用户请求多个潜在选项及其参数，引入了一个集成了优化函数的动态决策框架。该函数能分析选项、模拟结果，并根据预设标准选出最佳方案。借助此方法，LLM 能为复杂的多变量问题提供定制的最优解，大幅提升其实际应用的效能。这一方法不仅扩展了 LLM 的功能边界，还为构建能支持复杂决策的更智能系统奠定了基础。",
    "title_cn": "利用大型语言模型进行情景模拟，以实现决策的最优化。",
    "tags": [
      "LLM应用",
      "软件开发",
      "旅游规划"
    ]
  },
  {
    "title": "Composable Interventions for Language Models",
    "submit_datetime": "2024年07月08日",
    "abstract": "Test-time interventions for language models can enhance factual accuracy, mitigate harmful outputs, and improve model efficiency without costly retraining. But despite a flood of new methods, different types of interventions are largely developing independently. In practice, multiple interventions must be applied sequentially to the same model, yet we lack standardized ways to study how interventions interact. We fill this gap by introducing composable interventions, a framework to study the effects of using multiple interventions on the same language models, featuring new metrics and a unified codebase. Using our framework, we conduct extensive experiments and compose popular methods from three emerging intervention categories -- Knowledge Editing, Model Compression, and Machine Unlearning. Our results from 310 different compositions uncover meaningful interactions: compression hinders editing and unlearning, composing interventions hinges on their order of application, and popular general-purpose metrics are inadequate for assessing composability. Taken together, our findings showcase clear gaps in composability, suggesting a need for new multi-objective interventions. All of our code is public: https://github.com/hartvigsen-group/composable-interventions.",
    "pdf_link": "https://arxiv.org/abs/2407.06483",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06483v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06483/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06483v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06483/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06483v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06483/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06483v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06483/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06483v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06483/x5.png"
      }
    ],
    "abstract_cn": "语言模型在测试时的干预不仅能提升事实准确性，还能减少有害输出并增强模型效率，且无需重新训练。然而，尽管新方法层出不穷，各类干预措施却大多各自为政。实践中，我们需对同一模型依次施加多种干预，却缺乏研究其相互作用的标准化途径。为此，我们引入了“可组合干预”框架，旨在探索多重干预在同一模型上的效果，并配备了新指标和统一代码库。借助此框架，我们广泛实验，将知识编辑、模型压缩和机器遗忘这三类新兴干预方法进行组合。结果显示，压缩会妨碍编辑与遗忘，干预顺序至关重要，而现有通用指标在评估可组合性上尚显不足。这些发现揭示了可组合性领域的明显短板，呼吁新的多目标干预策略。所有相关代码已公开于：https://github.com/hartvigsen-group/composable-interventions。",
    "title_cn": "语言模型的可组合干预策略",
    "tags": [
      "LLM理论",
      "人工智能",
      "软件工程"
    ]
  },
  {
    "title": "MUSE: Machine Unlearning Six-Way Evaluation for Language Models",
    "submit_datetime": "2024年07月08日",
    "abstract": "Language models (LMs) are trained on vast amounts of text data, which may include private and copyrighted content. Data owners may request the removal of their data from a trained model due to privacy or copyright concerns. However, exactly unlearning only these datapoints (i.e., retraining with the data removed) is intractable in modern-day models. This has led to the development of many approximate unlearning algorithms. The evaluation of the efficacy of these algorithms has traditionally been narrow in scope, failing to precisely quantify the success and practicality of the algorithm from the perspectives of both the model deployers and the data owners. We address this issue by proposing MUSE, a comprehensive machine unlearning evaluation benchmark that enumerates six diverse desirable properties for unlearned models: (1) no verbatim memorization, (2) no knowledge memorization, (3) no privacy leakage, (4) utility preservation on data not intended for removal, (5) scalability with respect to the size of removal requests, and (6) sustainability over sequential unlearning requests. Using these criteria, we benchmark how effectively eight popular unlearning algorithms on 7B-parameter LMs can unlearn Harry Potter books and news articles. Our results demonstrate that most algorithms can prevent verbatim memorization and knowledge memorization to varying degrees, but only one algorithm does not lead to severe privacy leakage. Furthermore, existing algorithms fail to meet deployer's expectations because they often degrade general model utility and also cannot sustainably accommodate successive unlearning requests or large-scale content removal. Our findings identify key issues with the practicality of existing unlearning algorithms on language models, and we release our benchmark to facilitate further evaluations: muse-bench.github.io",
    "pdf_link": "https://arxiv.org/abs/2407.06460",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06460v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06460/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06460v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06460/mia.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06460v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06460/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06460v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06460/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06460v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06460/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06460v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06460/x5.png"
      }
    ],
    "abstract_cn": "语言模型在处理大量文本数据时，可能涉及隐私和版权问题。数据所有者出于这些考虑，可能要求从模型中删除特定数据。然而，现代模型中精确遗忘特定数据点是不可行的，这促使了近似遗忘算法的发展。传统上，这些算法的评估范围有限，未能全面衡量其成功和实用性。为此，我们提出了MUSE基准，该基准定义了遗忘模型应具备的六项特性，包括防止记忆、保护隐私、保持效用等。我们测试了八种算法在遗忘《哈利·波特》和新闻文章时的表现，发现多数算法能防止记忆，但仅一种能有效避免隐私泄露。现有算法普遍未能满足部署者的期望，因其常降低模型效用，且难以应对连续或大规模的遗忘请求。我们的研究揭示了现有算法的关键问题，并发布了评估基准以推动进一步研究。",
    "title_cn": "MUSE：语言模型的机器遗忘六维评估",
    "tags": [
      "LLM应用",
      "隐私保护",
      "数据安全"
    ]
  },
  {
    "title": "Exposing Privacy Gaps: Membership Inference Attack on Preference Data for LLM Alignment",
    "submit_datetime": "2024年07月08日",
    "abstract": "Large Language Models (LLMs) have seen widespread adoption due to their remarkable natural language capabilities. However, when deploying them in real-world settings, it is important to align LLMs to generate texts according to acceptable human standards. Methods such as Proximal Policy Optimization (PPO) and Direct Preference Optimization (DPO) have made significant progress in refining LLMs using human preference data. However, the privacy concerns inherent in utilizing such preference data have yet to be adequately studied. In this paper, we investigate the vulnerability of LLMs aligned using human preference datasets to membership inference attacks (MIAs), highlighting the shortcomings of previous MIA approaches with respect to preference data. Our study has two main contributions: first, we introduce a novel reference-based attack framework specifically for analyzing preference data called PREMIA (\\uline{Pre}ference data \\uline{MIA}); second, we provide empirical evidence that DPO models are more vulnerable to MIA compared to PPO models. Our findings highlight gaps in current privacy-preserving practices for LLM alignment.",
    "pdf_link": "https://arxiv.org/abs/2407.06443",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06443v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06443/MIA_Pair_AUROC_Scores.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06443v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06443/output.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06443v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06443/len_vs_roc.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLM）因其出色的自然语言处理能力而广受欢迎。但在实际应用中，确保其生成的文本符合人类标准至关重要。近端策略优化（PPO）和直接偏好优化（DPO）等方法利用人类偏好数据对 LLM 进行了显著改进，但这些数据带来的隐私问题尚未得到充分探讨。本文探讨了基于人类偏好数据集对齐的 LLM 对成员推理攻击（MIA）的脆弱性，并指出了现有 MIA 方法在处理偏好数据方面的缺陷。我们的研究主要贡献有两点：一是引入了针对偏好数据的新型参考攻击框架 PREMIA；二是实证表明 DPO 模型比 PPO 模型更易受 MIA 影响。这些发现揭示了当前 LLM 对齐过程中隐私保护措施的不足。",
    "title_cn": "揭秘隐私漏洞：针对 LLM 对齐过程中的偏好数据进行的成员推理攻击",
    "tags": [
      "LLM应用",
      "人工智能",
      "隐私保护"
    ]
  },
  {
    "title": "A Single Transformer for Scalable Vision-Language Modeling",
    "submit_datetime": "2024年07月08日",
    "abstract": "We present SOLO, a single transformer for Scalable visiOn-Language mOdeling. Current large vision-language models (LVLMs) such as LLaVA mostly employ heterogeneous architectures that connect pre-trained visual encoders with large language models (LLMs) to facilitate visual recognition and complex reasoning. Although achieving remarkable performance with relatively lightweight training, we identify four primary scalability limitations: (1) The visual capacity is constrained by pre-trained visual encoders, which are typically an order of magnitude smaller than LLMs. (2) The heterogeneous architecture complicates the use of established hardware and software infrastructure. (3) Study of scaling laws on such architecture must consider three separate components - visual encoder, connector, and LLMs, which complicates the analysis. (4) The use of existing visual encoders typically requires following a pre-defined specification of image inputs pre-processing, for example, by reshaping inputs to fixed-resolution square images, which presents difficulties in processing and training on high-resolution images or those with unusual aspect ratio. A unified single Transformer architecture, like SOLO, effectively addresses these scalability concerns in LVLMs; however, its limited adoption in the modern context likely stems from the absence of reliable training recipes that balance both modalities and ensure stable training for billion-scale models. In this paper, we introduce the first open-source training recipe for developing SOLO, an open-source 7B LVLM using moderate academic resources. The training recipe involves initializing from LLMs, sequential pre-training on ImageNet and web-scale data, and instruction fine-tuning on our curated high-quality datasets. On extensive evaluation, SOLO demonstrates performance comparable to LLaVA-v1.5-7B, particularly excelling in visual mathematical reasoning.",
    "pdf_link": "https://arxiv.org/abs/2407.06438",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06438v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06438/hello_s.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06438v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06438/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06438v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06438/qual.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06438v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06438/abla1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06438v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06438/abla2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06438v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06438/abla3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06438v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06438/train_dy.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06438v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06438/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06438v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06438/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06438v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06438/control.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06438v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06438/language.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06438v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06438/abla4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06438v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06438/abla5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06438v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06438/curve.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06438v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06438/abla6.png"
      }
    ],
    "abstract_cn": "我们推出了 SOLO，一种单一 Transformer 架构，专为可扩展的视觉语言模型设计。当前的 LVLMs 如 LLaVA 多采用异构架构，结合预训练视觉编码器与 LLMs，虽性能卓越，但存在四大可扩展性挑战：视觉能力受限、架构复杂、缩放分析困难、图像处理受限。SOLO 通过统一架构有效应对这些挑战，但普及受限于缺乏平衡视觉与语言、确保大型模型稳定训练的可靠方法。本文首次公开 SOLO 训练方法，利用适中资源打造 7B LVLM，通过 LLMs 初始化、多阶段预训练及高质量数据集微调，实现与 LLaVA-v1.5-7B 媲美的性能，尤其在视觉数学推理上表现卓越。",
    "title_cn": "单一 Transformer 实现视觉与语言模型的可扩展性",
    "tags": [
      "LLM应用",
      "计算机视觉",
      "人工智能"
    ]
  },
  {
    "title": "ORAN-Bench-13K: An Open Source Benchmark for Assessing LLMs in Open Radio Access Networks",
    "submit_datetime": "2024年07月08日",
    "abstract": "Large Language Models (LLMs) can revolutionize how we deploy and operate Open Radio Access Networks (O-RAN) by enhancing network analytics, anomaly detection, and code generation and significantly increasing the efficiency and reliability of a plethora of O-RAN tasks. In this paper, we present ORAN-Bench-13K, the first comprehensive benchmark designed to evaluate the performance of Large Language Models (LLMs) within the context of O-RAN. Our benchmark consists of 13,952 meticulously curated multiple-choice questions generated from 116 O-RAN specification documents. We leverage a novel three-stage LLM framework, and the questions are categorized into three distinct difficulties to cover a wide spectrum of ORAN-related knowledge. We thoroughly evaluate the performance of several state-of-the-art LLMs, including Gemini, Chat-GPT, and Mistral. Additionally, we propose ORANSight, a Retrieval-Augmented Generation (RAG)-based pipeline that demonstrates superior performance on ORAN-Bench-13K compared to other tested closed-source models. Our findings indicate that current popular LLM models are not proficient in O-RAN, highlighting the need for specialized models. We observed a noticeable performance improvement when incorporating the RAG-based ORANSight pipeline, with a Macro Accuracy of 0.784 and a Weighted Accuracy of 0.776, which was on average 21.55% and 22.59% better than the other tested LLMs.",
    "pdf_link": "https://arxiv.org/abs/2407.06245",
    "graphs": [],
    "abstract_cn": "大型语言模型 (LLM) 通过提升网络分析、异常检测和代码生成能力，显著增强了开放无线接入网络 (O-RAN) 的效率和可靠性，从而革新了其部署与运营方式。本文介绍了首个针对 O-RAN 背景下 LLM 性能评估的综合基准——ORAN-Bench-13K，包含从 116 份规范文档中精选的 13,952 道多选题。我们采用创新的三阶段 LLM 框架，将问题按难度分类，全面覆盖 ORAN 知识。通过评估 Gemini、Chat-GPT 和 Mistral 等顶尖 LLM，我们发现当前主流模型在 O-RAN 领域表现不佳，凸显了定制模型的需求。引入基于 RAG 的 ORANSight 管道后，性能显著提升，宏精度与加权精度分别达到 0.784 和 0.776，平均优于其他 LLM 21.55% 和 22.59%。",
    "title_cn": "ORAN-Bench-13K：一款开源基准，专为评估大型语言模型在开放无线接入网络中的表现而设计。",
    "tags": [
      "LLM应用",
      "",
      "网络分析"
    ]
  },
  {
    "title": "Collective Innovation in Groups of Large Language Models",
    "submit_datetime": "2024年07月07日",
    "abstract": "Human culture relies on collective innovation: our ability to continuously explore how existing elements in our environment can be combined to create new ones. Language is hypothesized to play a key role in human culture, driving individual cognitive capacities and shaping communication. Yet the majority of models of collective innovation assign no cognitive capacities or language abilities to agents. Here, we contribute a computational study of collective innovation where agents are Large Language Models (LLMs) that play Little Alchemy 2, a creative video game originally developed for humans that, as we argue, captures useful aspects of innovation landscapes not present in previous test-beds. We, first, study an LLM in isolation and discover that it exhibits both useful skills and crucial limitations. We, then, study groups of LLMs that share information related to their behaviour and focus on the effect of social connectivity on collective performance. In agreement with previous human and computational studies, we observe that groups with dynamic connectivity out-compete fully-connected groups. Our work reveals opportunities and challenges for future studies of collective innovation that are becoming increasingly relevant as Generative Artificial Intelligence algorithms and humans innovate alongside each other.",
    "pdf_link": "https://arxiv.org/abs/2407.05377",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05377v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05377/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05377v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05377/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05377v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05377/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05377v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05377/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05377v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05377/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05377v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05377/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05377v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05377/x7.png"
      }
    ],
    "abstract_cn": "人类文化根植于集体创新，即我们不断探索如何将环境中的现有元素重新组合以创造新事物的能力。语言在这一过程中被认为起着核心作用，它不仅推动个体认知发展，还塑造了我们的交流方式。然而，大多数集体创新模型并未考虑代理的认知或语言能力。为此，我们开展了一项计算研究，其中代理是大型语言模型（LLM），它们参与《小炼金术2》这款创意游戏，该游戏能有效模拟创新环境中的关键要素。我们首先单独分析了一个LLM的表现，发现它既有显著技能也存在明显局限。随后，我们考察了共享信息的LLM群体，并深入探讨了社交连接对集体创新表现的影响。研究结果显示，具有动态连接的群体在创新竞赛中超越了完全连接的群体，这与先前的研究相呼应。我们的研究不仅揭示了未来探索集体创新的新机遇，也指出了面临的挑战，特别是在生成式人工智能与人类共同创新的背景下，这些发现显得尤为重要。",
    "title_cn": "大型语言模型群体中的集体创新",
    "tags": [
      "Agent",
      "人工智能",
      "游戏开发"
    ]
  },
  {
    "title": "MINDECHO: Role-Playing Language Agents for Key Opinion Leaders",
    "submit_datetime": "2024年07月07日",
    "abstract": "Large language models~(LLMs) have demonstrated impressive performance in various applications, among which role-playing language agents (RPLAs) have engaged a broad user base. Now, there is a growing demand for RPLAs that represent Key Opinion Leaders (KOLs), \\ie, Internet celebrities who shape the trends and opinions in their domains. However, research in this line remains underexplored. In this paper, we hence introduce MINDECHO, a comprehensive framework for the development and evaluation of KOL RPLAs. MINDECHO collects KOL data from Internet video transcripts in various professional fields, and synthesizes their conversations leveraging GPT-4. Then, the conversations and the transcripts are used for individualized model training and inference-time retrieval, respectively. Our evaluation covers both general dimensions (\\ie, knowledge and tones) and fan-centric dimensions for KOLs. Extensive experiments validate the effectiveness of MINDECHO in developing and evaluating KOL RPLAs.",
    "pdf_link": "https://arxiv.org/abs/2407.05305",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05305v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05305/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05305v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05305/x2.png"
      }
    ],
    "abstract_cn": "大型语言模型在众多应用中表现卓越，尤其是角色扮演语言代理，深受用户喜爱。如今，代表关键意见领袖（即网络红人，他们主导着各自领域的潮流和观点）的 RPLAs 需求日益增长。然而，相关研究尚显不足。为此，我们提出了 MINDECHO 框架，旨在全面支持 KOL RPLAs 的开发与评估。MINDECHO 从多领域网络视频中采集 KOL 数据，并借助 GPT-4 模拟其对话。随后，这些对话与转录文本分别用于定制化模型训练与实时推理。我们的评估体系兼顾通用标准（如知识深度与语调）与粉丝视角。实验结果充分证明了 MINDECHO 在 KOL RPLAs 开发与评估中的高效性。",
    "title_cn": "MINDECHO：专为关键意见领袖打造的角色扮演语言代理",
    "tags": [
      "Agent",
      "社交媒体",
      "网络红人"
    ]
  },
  {
    "title": "WorkArena++: Towards Compositional Planning and Reasoning-based Common Knowledge Work Tasks",
    "submit_datetime": "2024年07月07日",
    "abstract": "The ability of large language models (LLMs) to mimic human-like intelligence has led to a surge in LLM-based autonomous agents. Though recent LLMs seem capable of planning and reasoning given user instructions, their effectiveness in applying these capabilities for autonomous task solving remains underexplored. This is especially true in enterprise settings, where automated agents hold the promise of a high impact. To fill this gap, we propose WorkArena++, a novel benchmark consisting of 682 tasks corresponding to realistic workflows routinely performed by knowledge workers. WorkArena++ is designed to evaluate the planning, problem-solving, logical/arithmetic reasoning, retrieval, and contextual understanding abilities of web agents. Our empirical studies across state-of-the-art LLMs and vision-language models (VLMs), as well as human workers, reveal several challenges for such models to serve as useful assistants in the workplace. In addition to the benchmark, we provide a mechanism to effortlessly generate thousands of ground-truth observation/action traces, which can be used for fine-tuning existing models. Overall, we expect this work to serve as a useful resource to help the community progress toward capable autonomous agents. The benchmark can be found at https://github.com/ServiceNow/WorkArena/tree/workarena-plus-plus.",
    "pdf_link": "https://arxiv.org/abs/2407.05291",
    "graphs": [],
    "abstract_cn": "大型语言模型 (LLM) 模仿人类智能的能力催生了基于 LLM 的自主代理的兴起。尽管这些模型在用户指令下展现出规划和推理的能力，但它们在实际任务解决中的应用效果仍有待深入探索，尤其是在企业环境中。为此，我们推出了 WorkArena++，这是一个包含 682 个真实工作流程任务的基准测试，旨在全面评估网络代理的各项能力。我们的研究发现，这些模型在成为高效工作助手方面仍面临挑战。此外，我们还开发了一种机制，可轻松生成大量真实数据，用于模型的微调。我们期待这项工作能为社区在自主代理领域的发展提供有力支持。基准测试详情请访问：https://github.com/ServiceNow/WorkArena/tree/workarena-plus-plus。",
    "title_cn": "WorkArena++：探索基于组合规划与推理的通用知识工作任务",
    "tags": [
      "Agent",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Multimodal Language Models for Domain-Specific Procedural Video Summarization",
    "submit_datetime": "2024年07月07日",
    "abstract": "Videos serve as a powerful medium to convey ideas, tell stories, and provide detailed instructions, especially through long-format tutorials. Such tutorials are valuable for learning new skills at one's own pace, yet they can be overwhelming due to their length and dense content. Viewers often seek specific information, like precise measurements or step-by-step execution details, making it essential to extract and summarize key segments efficiently. An intelligent, time-sensitive video assistant capable of summarizing and detecting highlights in long videos is highly sought after. Recent advancements in Multimodal Large Language Models offer promising solutions to develop such an assistant. Our research explores the use of multimodal models to enhance video summarization and step-by-step instruction generation within specific domains. These models need to understand temporal events and relationships among actions across video frames. Our approach focuses on fine-tuning TimeChat to improve its performance in specific domains: cooking and medical procedures. By training the model on domain-specific datasets like Tasty for cooking and MedVidQA for medical procedures, we aim to enhance its ability to generate concise, accurate summaries of instructional videos. We curate and restructure these datasets to create high-quality video-centric instruction data. Our findings indicate that when finetuned on domain-specific procedural data, TimeChat can significantly improve the extraction and summarization of key instructional steps in long-format videos. This research demonstrates the potential of specialized multimodal models to assist with practical tasks by providing personalized, step-by-step guidance tailored to the unique aspects of each domain.",
    "pdf_link": "https://arxiv.org/abs/2407.05419",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05419v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05419/timechat.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05419v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05419/arch.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05419v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05419/timechat2.png"
      }
    ],
    "abstract_cn": "视频不仅是传达思想和故事的强大工具，还能通过长教程提供详尽指导。然而，这些教程因其长度和密集内容可能令人望而生畏。观众往往需要特定信息，如精确测量或详细步骤，因此高效提取和总结关键片段至关重要。一个能够总结和检测长视频亮点的智能助手备受追捧。多模态大型语言模型的最新进展为此类助手开发提供了希望。我们研究如何利用这些模型增强视频总结和特定领域内逐步指导生成。这些模型需理解视频帧间的时间事件和动作关系。我们专注于微调TimeChat，以提升其在烹饪和医疗程序等领域的性能。通过在特定领域数据集上训练模型，我们旨在增强其生成简洁、准确教程视频总结的能力。我们精心挑选和重组数据集，创建高质量视频指导数据。研究表明，在特定领域程序数据上微调后，TimeChat能显著提升长视频中关键步骤的提取和总结。这项研究展示了专门多模态模型通过提供个性化、逐步指导来协助实际任务的潜力。",
    "title_cn": "特定领域程序视频摘要的多模态语言模型",
    "tags": [
      "LLM应用",
      "",
      ""
    ]
  },
  {
    "title": "VideoCoT: A Video Chain-of-Thought Dataset with Active Annotation Tool",
    "submit_datetime": "2024年07月07日",
    "abstract": "Multimodal large language models (MLLMs) are flourishing, but mainly focus on images with less attention than videos, especially in sub-fields such as prompt engineering, video chain-of-thought (CoT), and instruction tuning on videos. Therefore, we try to explore the collection of CoT datasets in videos to lead to video OpenQA and improve the reasoning ability of MLLMs. Unfortunately, making such video CoT datasets is not an easy task. Given that human annotation is too cumbersome and expensive, while machine-generated is not reliable due to the hallucination issue, we develop an automatic annotation tool that combines machine and human experts, under the active learning paradigm. Active learning is an interactive strategy between the model and human experts, in this way, the workload of human labeling can be reduced and the quality of the dataset can be guaranteed. With the help of the automatic annotation tool, we strive to contribute three datasets, namely VideoCoT, TopicQA, TopicCoT. Furthermore, we propose a simple but effective benchmark based on the collected datasets, which exploits CoT to maximize the complex reasoning capabilities of MLLMs. Extensive experiments demonstrate the effectiveness our solution.",
    "pdf_link": "https://arxiv.org/abs/2407.05355",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05355v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05355/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05355v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05355/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05355v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05355/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05355v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05355/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05355v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05355/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05355v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05355/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05355v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05355/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05355v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05355/x8.png"
      }
    ],
    "abstract_cn": "多模态大型语言模型 (MLLMs) 正蓬勃发展，但对视频的关注不如图像，尤其是在提示工程、视频链-of-思维 (CoT) 和视频指令调整等领域。为此，我们探索视频中的 CoT 数据集，旨在推动视频 OpenQA 并增强 MLLMs 的推理能力。然而，构建视频 CoT 数据集颇具挑战。考虑到人工标注成本高且繁琐，机器生成又因幻觉问题不可靠，我们开发了结合机器与人类专家的自动标注工具，采用主动学习策略。该策略通过模型与专家的互动，既减轻了人工负担，又确保了数据质量。借助此工具，我们贡献了 VideoCoT、TopicQA 和 TopicCoT 三个数据集。此外，我们基于这些数据集提出了一个简单高效的基准，旨在通过 CoT 最大化 MLLMs 的复杂推理能力。实验结果充分验证了我们方法的有效性。",
    "title_cn": "VideoCoT：一款集成了主动注释工具的视频思维链数据集",
    "tags": [
      "LLM应用",
      "视频处理",
      "人工智能"
    ]
  },
  {
    "title": ": Towards Effective and Efficient Cost Function Design for Safe Reinforcement Learning via Large Language Model",
    "submit_datetime": "2024年07月07日",
    "abstract": "Different classes of safe reinforcement learning algorithms have shown satisfactory performance in various types of safety requirement scenarios. However, the existing methods mainly address one or several classes of specific safety requirement scenario problems and cannot be applied to arbitrary safety requirement scenarios. In addition, the optimization objectives of existing reinforcement learning algorithms are misaligned with the task requirements. Based on the need to address these issues, we propose $\\mathrm{E^{2}CFD}$, an effective and efficient cost function design framework. $\\mathrm{E^{2}CFD}$ leverages the capabilities of a large language model (LLM) to comprehend various safety scenarios and generate corresponding cost functions. It incorporates the \\textit{fast performance evaluation (FPE)} method to facilitate rapid and iterative updates to the generated cost function. Through this iterative process, $\\mathrm{E^{2}CFD}$ aims to obtain the most suitable cost function for policy training, tailored to the specific tasks within the safety scenario. Experiments have proven that the performance of policies trained using this framework is superior to traditional safe reinforcement learning algorithms and policies trained with carefully designed cost functions.",
    "pdf_link": "https://arxiv.org/abs/2407.05580",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05580/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05580/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05580/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05580/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05580/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05580/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05580/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05580/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05580/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05580/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05580/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05580/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05580/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05580/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05580v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05580/x15.png"
      }
    ],
    "abstract_cn": "在满足不同安全需求的场景中，各类安全强化学习算法表现出色，但它们通常只能应对特定场景，无法通用。此外，这些算法的优化目标往往与实际任务需求脱节。为此，我们设计了 $\\mathrm{E^{2}CFD}$ 框架，它借助大型语言模型的理解力，针对不同安全场景生成定制的代价函数，并通过快速性能评估方法实现快速迭代优化。实验结果显示，该框架训练出的策略性能超越了传统方法和人工设计的代价函数。",
    "title_cn": "利用大型语言模型，我们致力于设计既安全又高效的强化学习成本函数。",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "LLMBox: A Comprehensive Library for Large Language Models",
    "submit_datetime": "2024年07月07日",
    "abstract": "To facilitate the research on large language models (LLMs), this paper presents a comprehensive and unified library, LLMBox, to ease the development, use, and evaluation of LLMs. This library is featured with three main merits: (1) a unified data interface that supports the flexible implementation of various training strategies, (2) a comprehensive evaluation that covers extensive tasks, datasets, and models, and (3) more practical consideration, especially on user-friendliness and efficiency. With our library, users can easily reproduce existing methods, train new models, and conduct comprehensive performance comparisons. To rigorously test LLMBox, we conduct extensive experiments in a diverse coverage of evaluation settings, and experimental results demonstrate the effectiveness and efficiency of our library in supporting various implementations related to LLMs. The detailed introduction and usage guidance can be found at https://github.com/RUCAIBox/LLMBox.",
    "pdf_link": "https://arxiv.org/abs/2407.05563",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05563v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05563/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05563v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05563/x2.png"
      }
    ],
    "abstract_cn": "本文推出 LLMBox，一个全面且统一的库，旨在简化大型语言模型 (LLM) 的开发、使用和评估。该库三大亮点：(1) 灵活的统一数据接口，(2) 广泛任务、数据集和模型的全面评估，(3) 强调用户友好与效率。借助 LLMBox，用户能轻松复现、训练并比较模型性能。我们通过多样化实验验证了其有效性与效率。详情及指南请访问 https://github.com/RUCAIBox/LLMBox。",
    "title_cn": "LLMBox：大型语言模型的综合库",
    "tags": [
      "LLM应用",
      "软件开发",
      "人工智能"
    ]
  },
  {
    "title": "Faux Polyglot: A Study on Information Disparity in Multilingual Large Language Models",
    "submit_datetime": "2024年07月07日",
    "abstract": "With Retrieval Augmented Generation (RAG), Large Language Models (LLMs) are playing a pivotal role in information search and are being adopted globally. Although the multilingual capability of LLMs offers new opportunities to bridge the language barrier, do these capabilities translate into real-life scenarios where linguistic divide and knowledge conflicts between multilingual sources are known occurrences? In this paper, we studied LLM's linguistic preference in a RAG-based information search setting. We found that LLMs displayed systemic bias towards information in the same language as the query language in both information retrieval and answer generation. Furthermore, in scenarios where there is little information in the language of the query, LLMs prefer documents in high-resource languages, reinforcing the dominant views. Such bias exists for both factual and opinion-based queries. Our results highlight the linguistic divide within multilingual LLMs in information search systems. The seemingly beneficial multilingual capability of LLMs may backfire on information parity by reinforcing language-specific information cocoons or filter bubbles further marginalizing low-resource views.",
    "pdf_link": "https://arxiv.org/abs/2407.05502",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05502v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05502/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05502v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05502/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05502v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05502/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05502v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05502/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05502v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05502/Festival_Aggr_Visual.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05502v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05502/War_Aggr_Visual.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05502v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05502/second-language-preference-aggr.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05502v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05502/query-types-generation.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）通过检索增强生成（RAG）技术，在信息搜索领域发挥着核心作用，并已在全球普及。尽管LLMs的多语言特性为跨越语言障碍带来新希望，但这些特性是否能在多语言环境中有效应对语言隔阂和知识冲突，仍是一个疑问。我们的研究发现，LLMs在基于RAG的信息搜索中，对与查询语言相同的信息表现出系统性偏好，尤其在查询语言信息稀缺时，更倾向于高资源语言的文档，从而强化了主流观点。这种偏见在事实性和观点性查询中均存在。我们的研究揭示了多语言LLMs在信息搜索中的语言隔阂问题，指出其看似有益的多语言能力可能加剧信息不平等，通过强化特定语言的信息茧房或过滤气泡，进一步边缘化低资源观点。",
    "title_cn": "《伪多语者》：探究多语言大型模型中的信息鸿沟",
    "tags": [
      "RAG",
      "信息搜索",
      "多语言处理"
    ]
  },
  {
    "title": "Just read twice: closing the recall gap for recurrent language models",
    "submit_datetime": "2024年07月07日",
    "abstract": "Recurrent large language models that compete with Transformers in language modeling perplexity are emerging at a rapid rate (e.g., Mamba, RWKV). Excitingly, these architectures use a constant amount of memory during inference. However, due to the limited memory, recurrent LMs cannot recall and use all the information in long contexts leading to brittle in-context learning (ICL) quality. A key challenge for efficient LMs is selecting what information to store versus discard. In this work, we observe the order in which information is shown to the LM impacts the selection difficulty. To formalize this, we show that the hardness of information recall reduces to the hardness of a problem called set disjointness (SD), a quintessential problem in communication complexity that requires a streaming algorithm (e.g., recurrent model) to decide whether inputted sets are disjoint. We empirically and theoretically show that the recurrent memory required to solve SD changes with set order, i.e., whether the smaller set appears first in-context. Our analysis suggests, to mitigate the reliance on data order, we can put information in the right order in-context or process prompts non-causally. Towards that end, we propose: (1) JRT-Prompt, where context gets repeated multiple times in the prompt, effectively showing the model all data orders. This gives $11.0 \\pm 1.3$ points of improvement, averaged across $16$ recurrent LMs and the $6$ ICL tasks, with $11.9\\times$ higher throughput than FlashAttention-2 for generation prefill (length $32$k, batch size $16$, NVidia H100). We then propose (2) JRT-RNN, which uses non-causal prefix-linear-attention to process prompts and provides $99\\%$ of Transformer quality at $360$M params., $30$B tokens and $96\\%$ at $1.3$B params., $50$B tokens on average across the tasks, with $19.2\\times$ higher throughput for prefill than FA2.",
    "pdf_link": "https://arxiv.org/abs/2407.05483",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05483v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05483/main_fig_jrt1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05483v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05483/set_dijsointness.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05483v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05483/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05483v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05483/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05483v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05483/x3.png"
      }
    ],
    "abstract_cn": "循环大型语言模型正迅速崛起，与Transformer在语言模型困惑度上展开竞争。这些模型在推理时仅使用固定内存，但受限于此，它们难以充分利用长上下文信息，导致上下文学习质量不稳定。高效语言模型的关键在于精准选择存储与丢弃的信息。我们发现，信息呈现的顺序直接影响选择难度。通过将问题简化为集合不相交问题，我们揭示了循环模型在处理不同顺序集合时的内存需求变化。为减少对数据顺序的依赖，我们提出两种方案：JRT-Prompt重复展示上下文，全面展示数据顺序，平均提升11.0±1.3点，生成预填充吞吐量提升11.9倍；JRT-RNN采用非因果前缀线性注意力处理提示，以360M参数和30B令牌达到99%的Transformer质量，预填充吞吐量提升19.2倍。",
    "title_cn": "双读法：助力循环语言模型提升召回率",
    "tags": [
      "LLM理论",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Biomedical Nested NER with Large Language Model and UMLS Heuristics",
    "submit_datetime": "2024年07月07日",
    "abstract": "In this paper, we present our system for the BioNNE English track, which aims to extract 8 types of biomedical nested named entities from biomedical text. We use a large language model (Mixtral 8x7B instruct) and ScispaCy NER model to identify entities in an article and build custom heuristics based on unified medical language system (UMLS) semantic types to categorize the entities. We discuss the results and limitations of our system and propose future improvements. Our system achieved an F1 score of 0.39 on the BioNNE validation set and 0.348 on the test set.",
    "pdf_link": "https://arxiv.org/abs/2407.05480",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05480v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05480/bionne_design.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05480v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05480/bionne_inout_flow.png"
      }
    ],
    "abstract_cn": "本文介绍了一个专为 BioNNE 英语赛道设计的系统，旨在从生物医学文本中提取 8 种嵌套命名实体。我们结合大型语言模型（Mixtral 8x7B instruct）和 ScispaCy NER 模型进行实体识别，并利用 UMLS 语义类型定制分类策略。文章还探讨了系统的性能与局限，并展望了未来的优化方向。该系统在验证集和测试集上的 F1 分数分别为 0.39 和 0.348。",
    "title_cn": "结合大型语言模型与UMLS启发式方法的生物医学嵌套NER研究",
    "tags": [
      "LLM应用",
      "生物医学",
      ""
    ]
  },
  {
    "title": "Enhancing Hallucination Detection through Perturbation-Based Synthetic Data Generation in System Responses",
    "submit_datetime": "2024年07月07日",
    "abstract": "Detecting hallucinations in large language model (LLM) outputs is pivotal, yet traditional fine-tuning for this classification task is impeded by the expensive and quickly outdated annotation process, especially across numerous vertical domains and in the face of rapid LLM advancements. In this study, we introduce an approach that automatically generates both faithful and hallucinated outputs by rewriting system responses. Experimental findings demonstrate that a T5-base model, fine-tuned on our generated dataset, surpasses state-of-the-art zero-shot detectors and existing synthetic generation methods in both accuracy and latency, indicating efficacy of our approach.",
    "pdf_link": "https://arxiv.org/abs/2407.05474",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05474v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05474/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05474v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05474/newPlot755BoundariesFinal.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05474v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05474/TemplateSnap.png"
      }
    ],
    "abstract_cn": "检测 LLM 输出中的幻觉至关重要，但传统微调方法因昂贵且迅速过时的标注过程而受阻。本研究提出一种新方法，通过重写系统响应自动生成忠实与幻觉输出。实验显示，微调后的 T5-base 模型在准确性与速度上均优于现有技术，证明了我们方法的有效性。",
    "title_cn": "利用基于扰动的合成数据生成技术，提升系统响应中幻觉检测的效能。",
    "tags": [
      "LLM应用",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Experiments with truth using Machine Learning: Spectral analysis and explainable classification of synthetic, false, and genuine information",
    "submit_datetime": "2024年07月07日",
    "abstract": "Misinformation is still a major societal problem and the arrival of Large Language Models (LLMs) only added to it. This paper analyzes synthetic, false, and genuine information in the form of text from spectral analysis, visualization, and explainability perspectives to find the answer to why the problem is still unsolved despite multiple years of research and a plethora of solutions in the literature. Various embedding techniques on multiple datasets are used to represent information for the purpose. The diverse spectral and non-spectral methods used on these embeddings include t-distributed Stochastic Neighbor Embedding (t-SNE), Principal Component Analysis (PCA), and Variational Autoencoders (VAEs). Classification is done using multiple machine learning algorithms. Local Interpretable Model-Agnostic Explanations (LIME), SHapley Additive exPlanations (SHAP), and Integrated Gradients are used for the explanation of the classification. The analysis and the explanations generated show that misinformation is quite closely intertwined with genuine information and the machine learning algorithms are not as effective in separating the two despite the claims in the literature.",
    "pdf_link": "https://arxiv.org/abs/2407.05464",
    "graphs": [],
    "abstract_cn": "错误信息仍是社会难题，大型语言模型 (LLM) 的兴起更使其雪上加霜。本文通过光谱分析、可视化及可解释性视角，深入探讨合成、虚假与真实文本信息的复杂关系，揭示为何多年研究与众多解决方案仍未能彻底解决问题。我们采用多数据集上的多种嵌入技术，运用 t-SNE、PCA 及 VAEs 等方法进行分析，并借助 LIME、SHAP 和集成梯度等工具解释分类结果。研究显示，错误信息与真实信息紧密交织，机器学习算法在分离二者方面效果有限，与文献中的乐观声称相悖。",
    "title_cn": "探索机器学习在真实性实验中的应用：通过光谱分析与可解释分类，揭示合成、虚假与真实信息的奥秘。",
    "tags": [
      "LLM应用",
      "社会科学",
      "信息技术"
    ]
  },
  {
    "title": "Training Task Experts through Retrieval Based Distillation",
    "submit_datetime": "2024年07月07日",
    "abstract": "One of the most reliable ways to create deployable models for specialized tasks is to obtain an adequate amount of high-quality task-specific data. However, for specialized tasks, often such datasets do not exist. Existing methods address this by creating such data from large language models (LLMs) and then distilling such knowledge into smaller models. However, these methods are limited by the quality of the LLMs output, and tend to generate repetitive or incorrect data. In this work, we present Retrieval Based Distillation (ReBase), a method that first retrieves data from rich online sources and then transforms them into domain-specific data. This method greatly enhances data diversity. Moreover, ReBase generates Chain-of-Thought reasoning and distills the reasoning capacity of LLMs. We test our method on 4 benchmarks and results show that our method significantly improves performance by up to 7.8% on SQuAD, 1.37% on MNLI, and 1.94% on BigBench-Hard.",
    "pdf_link": "https://arxiv.org/abs/2407.05463",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05463v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05463/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05463v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05463/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05463v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05463/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05463v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05463/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05463v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05463/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05463v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05463/filtered_rows_percentage.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05463v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05463/config.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05463v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05463/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05463v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05463/x7.png"
      }
    ],
    "abstract_cn": "构建专用任务的可部署模型，最可靠途径之一是获取大量高质量的特定任务数据。然而，这类数据集往往稀缺。现有技术通过从大型语言模型（LLM）中生成数据并提炼至小型模型来应对，但受限于LLM输出质量，常产生重复或错误数据。我们提出的基于检索的提炼（ReBase）方法，首先从丰富在线资源中检索数据，再转化为领域特定数据，极大提升数据多样性。ReBase还能生成思维链推理，提炼LLM的推理能力。在四个基准测试中，我们的方法在SQuAD上性能提升高达7.8%，MNLI上提升1.37%，BigBench-Hard上提升1.94%。",
    "title_cn": "利用基于检索的蒸馏技术培养任务专家",
    "tags": [
      "LLM应用",
      "人工智能",
      "数据科学"
    ]
  },
  {
    "title": "Enhancing Computer Programming Education with LLMs: A Study on Effective Prompt Engineering for Python Code Generation",
    "submit_datetime": "2024年07月07日",
    "abstract": "Large language models (LLMs) and prompt engineering hold significant potential for advancing computer programming education through personalized instruction. This paper explores this potential by investigating three critical research questions: the systematic categorization of prompt engineering strategies tailored to diverse educational needs, the empowerment of LLMs to solve complex problems beyond their inherent capabilities, and the establishment of a robust framework for evaluating and implementing these strategies. Our methodology involves categorizing programming questions based on educational requirements, applying various prompt engineering strategies, and assessing the effectiveness of LLM-generated responses. Experiments with GPT-4, GPT-4o, Llama3-8b, and Mixtral-8x7b models on datasets such as LeetCode and USACO reveal that GPT-4o consistently outperforms others, particularly with the \"multi-step\" prompt strategy. The results show that tailored prompt strategies significantly enhance LLM performance, with specific strategies recommended for foundational learning, competition preparation, and advanced problem-solving. This study underscores the crucial role of prompt engineering in maximizing the educational benefits of LLMs. By systematically categorizing and testing these strategies, we provide a comprehensive framework for both educators and students to optimize LLM-based learning experiences. Future research should focus on refining these strategies and addressing current LLM limitations to further enhance educational outcomes in computer programming instruction.",
    "pdf_link": "https://arxiv.org/abs/2407.05437",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05437v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05437/system.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05437v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05437/model.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05437v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05437/usaco_grading.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05437v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05437/prompt_1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05437v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05437/prompt_2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05437v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05437/prompt_3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05437v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05437/prompt_4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05437v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05437/prompt_5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05437v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05437/prompt_6.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLM）与提示工程相结合，为个性化计算机编程教育开辟了新天地。本文深入探讨了这一领域，聚焦于三个核心问题：如何系统地分类适用于不同教育背景的提示工程策略、如何扩展LLM解决复杂问题的能力，以及如何构建一个稳固的评估与实施框架。我们通过根据教育需求对编程问题进行分类，运用多样化的提示策略，并评估LLM的响应效果，来实施研究。实验结果显示，在LeetCode和USACO等数据集上，GPT-4o模型凭借其“多步骤”提示策略，表现尤为突出。研究证实，量身定制的提示策略能大幅提升LLM的表现，并为不同学习阶段推荐了相应的策略。本研究凸显了提示工程在提升LLM教育价值中的重要性，并提供了一个全面的框架，助力教育者和学生优化基于LLM的学习过程。未来研究应致力于精进这些策略，并克服LLM的现有局限，以期在计算机编程教育领域取得更大突破。",
    "title_cn": "利用 LLM 提升编程教育：探索 Python 代码生成中的高效提示设计",
    "tags": [
      "LLM应用",
      "",
      "计算机编程"
    ]
  },
  {
    "title": "LTLBench: Towards Benchmarks for Evaluating Temporal Logic Reasoning in Large Language Models",
    "submit_datetime": "2024年07月07日",
    "abstract": "Temporal reasoning (TR) is a critical component of artificial intelligence, encompassing understanding and processing temporal information and relationships between events. To discover and study the TR ability in Large Language Models (LLMs), various datasets have been constructed in different ways for evaluating various aspects of TR ability. Our work proposes a novel approach to design and develop a pipeline for constructing datasets to evaluate the TR ability of LLMs by leveraging random directed graph generation, LTL formula, and the NuSMV model checker. Based on the pipeline, we have also constructed a dataset as a benchmark, namely LTLBench, consisting of 2,000 TR challenges and evaluated six LLMs with it. Furthermore, we have conducted additional experiments to discover the impact of increasing the number of events and formula operators on the complexity of TR problems and the performance of LLMs. We have demonstrated that although LLMs exhibit some promise in handling TR challenges, they still struggle with complex TR. We expect this work can offer insights into TR ability in LLMs while also providing a valuable tool for future TR evaluations.",
    "pdf_link": "https://arxiv.org/abs/2407.05434",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05434v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05434/pipeline.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05434v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05434/directed_graph.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05434v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05434/fixed_event_n_accuracy.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05434v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05434/fixed_event_n_auc.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05434v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05434/fixed_operator_n_accuracy.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05434v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05434/fixed_operator_n_auc.png"
      }
    ],
    "abstract_cn": "时间推理（TR）是AI的核心，涉及时间信息与事件关系的理解与处理。为探索LLMs的TR能力，我们创新性地结合随机有向图、LTL公式和NuSMV模型检查器，设计了一套数据集构建流程。据此，我们打造了包含2,000个挑战的LTLBench基准，并测试了六款LLMs。实验揭示，尽管LLMs在TR任务上有所进步，但复杂问题仍令其困扰。此研究不仅深化了对LLMs TR能力的理解，更为未来评估提供了有力工具。",
    "title_cn": "LTLBench：专为评估大型语言模型中的时间逻辑推理而设计的基准测试",
    "tags": [
      "LLM应用",
      "人工智能",
      "时间推理"
    ]
  },
  {
    "title": "SBoRA: Low-Rank Adaptation with Regional Weight Updates",
    "submit_datetime": "2024年07月07日",
    "abstract": "This paper introduces Standard Basis LoRA (SBoRA), a novel parameter-efficient fine-tuning approach for Large Language Models that builds upon the pioneering works of Low-Rank Adaptation (LoRA) and Orthogonal Adaptation. SBoRA further reduces the computational and memory requirements of LoRA while enhancing learning performance. By leveraging orthogonal standard basis vectors to initialize one of the low-rank matrices, either A or B, SBoRA enables regional weight updates and memory-efficient fine-tuning. This approach gives rise to two variants, SBoRA-FA and SBoRA-FB, where only one of the matrices is updated, resulting in a sparse update matrix with a majority of zero rows or columns. Consequently, the majority of the fine-tuned model's weights remain unchanged from the pre-trained weights. This characteristic of SBoRA, wherein regional weight updates occur, is reminiscent of the modular organization of the human brain, which efficiently adapts to new tasks. Our empirical results demonstrate the superiority of SBoRA-FA over LoRA in various fine-tuning tasks, including commonsense reasoning and arithmetic reasoning. Furthermore, we evaluate the effectiveness of QSBoRA on quantized LLaMA models of varying scales, highlighting its potential for efficient adaptation to new tasks. Code is available at https://github.com/CityUHK-AI/SBoRA",
    "pdf_link": "https://arxiv.org/abs/2407.05413",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05413v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05413/fig1_new.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05413v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05413/fig2.png"
      }
    ],
    "abstract_cn": "本文引入了 Standard Basis LoRA (SBoRA)，这是一种创新的参数高效微调技术，适用于大型语言模型，基于 Low-Rank Adaptation (LoRA) 和 Orthogonal Adaptation 的先驱研究。SBoRA 不仅减少了 LoRA 的计算和内存负担，还提升了学习效率。通过使用正交标准基向量初始化低秩矩阵（A 或 B），SBoRA 实现了针对性的权重更新和内存高效微调。这一方法衍生出两种变体，SBoRA-FA 和 SBoRA-FB，它们分别更新一个矩阵，形成稀疏的更新矩阵，大部分为零行或零列。因此，微调后的模型权重大多保持与预训练状态一致。SBoRA 的这种区域权重更新特性，类似于人脑的模块化适应机制，能够高效应对新任务。实证研究显示，在常识推理和算术推理等微调任务中，SBoRA-FA 表现优于 LoRA。此外，我们还评估了 QSBoRA 在不同规模量化 LLaMA 模型上的适应性，凸显了其在新任务上的高效适应潜力。相关代码已公开在 https://github.com/CityUHK-AI/SBoRA。",
    "title_cn": "SBoRA：通过区域权重更新实现低秩适应",
    "tags": [
      "LLM理论",
      "人工智能",
      "计算机科学"
    ]
  },
  {
    "title": "Assessing Code Generation with Intermediate Languages",
    "submit_datetime": "2024年07月07日",
    "abstract": "Intermediate step methodologies like chain of thoughts (COT) have demonstrated effectiveness in enhancing the performance of Large Language Models (LLMs) on code generation. This study explores the utilization of intermediate languages, including various programming languages, natural language solutions, and pseudo-code, and systematically evaluates their impact on the performance of LLMs in code generation tasks. Our experiments encompass eleven models across the CodeLlama, GPT, and Mistral families, as well as newly released smaller models. Our findings reveal that intermediate languages generally exhibit greater efficacy in larger models that have not yet achieved state-of-the-art performance. Natural language consistently emerges as the most effective intermediate representation across all target languages. However, we observe no universally effective intermediate formal language across different models and target languages. Furthermore, we uncover a weak correlation between the correctness of intermediate solutions and final generation, suggesting that improvements may stem from the chain-of-thought effect rather than language-specific transfer. Interestingly, we discover that for GPT family models, prompting multiple times without explicit self-correction instructions yields performance gains across the studied languages.",
    "pdf_link": "https://arxiv.org/abs/2407.05411",
    "graphs": [],
    "abstract_cn": "本研究通过思维链等中间步骤方法，探讨了多种中间语言（如编程语言、自然语言及伪代码）对大型语言模型在代码生成任务中性能的影响。实验涉及 CodeLlama、GPT 和 Mistral 系列的多款模型及新发布的小型模型。结果显示，自然语言作为中间表示在各目标语言中表现最佳，但未发现适用于所有模型和语言的通用有效中间语言。此外，中间解决方案的正确性与最终生成结果的关联较弱，暗示性能提升更多来自思维链效应而非特定语言的传递。特别地，GPT 系列模型在无明确自我修正指令下多次提示，可显著提升性能。",
    "title_cn": "通过中间语言评估代码生成",
    "tags": [
      "LLM应用",
      "软件开发",
      "人工智能"
    ]
  },
  {
    "title": "CosyVoice: A Scalable Multilingual Zero-shot Text-to-speech Synthesizer based on Supervised Semantic Tokens",
    "submit_datetime": "2024年07月07日",
    "abstract": "Recent years have witnessed a trend that large language model (LLM) based text-to-speech (TTS) emerges into the mainstream due to their high naturalness and zero-shot capacity. In this paradigm, speech signals are discretized into token sequences, which are modeled by an LLM with text as prompts and reconstructed by a token-based vocoder to waveforms. Obviously, speech tokens play a critical role in LLM-based TTS models. Current speech tokens are learned in an unsupervised manner, which lacks explicit semantic information and alignment to the text. In this paper, we propose to represent speech with supervised semantic tokens, which are derived from a multilingual speech recognition model by inserting vector quantization into the encoder. Based on the tokens, we further propose a scalable zero-shot TTS synthesizer, CosyVoice, which consists of an LLM for text-to-token generation and a conditional flow matching model for token-to-speech synthesis. Experimental results show that supervised semantic tokens significantly outperform existing unsupervised tokens in terms of content consistency and speaker similarity for zero-shot voice cloning. Moreover, we find that utilizing large-scale data further improves the synthesis performance, indicating the scalable capacity of CosyVoice. To the best of our knowledge, this is the first attempt to involve supervised speech tokens into TTS models.",
    "pdf_link": "https://arxiv.org/abs/2407.05407",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05407v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05407/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05407v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05407/x2.png"
      }
    ],
    "abstract_cn": "近年来，基于大型语言模型的文本到语音技术因其高自然度和零-shot能力而成为主流。我们提出用监督语义令牌表示语音，并基于此开发了可扩展的零-shot TTS合成器CosyVoice。实验表明，监督语义令牌在零-shot语音克隆中表现更优，且利用大规模数据可进一步提升合成性能。这是首次尝试将监督语音令牌引入TTS模型。",
    "title_cn": "CosyVoice：一款基于监督语义令牌的，可扩展的多语言零-shot 文本转语音合成器。",
    "tags": [
      "LLM应用",
      "语音技术",
      "人工智能"
    ]
  },
  {
    "title": "ElecBench: a Power Dispatch Evaluation Benchmark for Large Language Models",
    "submit_datetime": "2024年07月07日",
    "abstract": "In response to the urgent demand for grid stability and the complex challenges posed by renewable energy integration and electricity market dynamics, the power sector increasingly seeks innovative technological solutions. In this context, large language models (LLMs) have become a key technology to improve efficiency and promote intelligent progress in the power sector with their excellent natural language processing, logical reasoning, and generalization capabilities. Despite their potential, the absence of a performance evaluation benchmark for LLM in the power sector has limited the effective application of these technologies. Addressing this gap, our study introduces \"ElecBench\", an evaluation benchmark of LLMs within the power sector. ElecBench aims to overcome the shortcomings of existing evaluation benchmarks by providing comprehensive coverage of sector-specific scenarios, deepening the testing of professional knowledge, and enhancing decision-making precision. The framework categorizes scenarios into general knowledge and professional business, further divided into six core performance metrics: factuality, logicality, stability, security, fairness, and expressiveness, and is subdivided into 24 sub-metrics, offering profound insights into the capabilities and limitations of LLM applications in the power sector. To ensure transparency, we have made the complete test set public, evaluating the performance of eight LLMs across various scenarios and metrics. ElecBench aspires to serve as the standard benchmark for LLM applications in the power sector, supporting continuous updates of scenarios, metrics, and models to drive technological progress and application.",
    "pdf_link": "https://arxiv.org/abs/2407.05365",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05365v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05365/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05365v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05365/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05365v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05365/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05365v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05365/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05365v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05365/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05365v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05365/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05365v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05365/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05365v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05365/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05365v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05365/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05365v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05365/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05365v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05365/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05365v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05365/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05365v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05365/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05365v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05365/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05365v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05365/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05365v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05365/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05365v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05365/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05365v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05365/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05365v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05365/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05365v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05365/x20.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05365v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05365/x21.png"
      }
    ],
    "abstract_cn": "随着电网稳定性的迫切需求和可再生能源整合、电力市场动态带来的挑战，电力行业正寻求创新技术解决方案。大型语言模型（LLMs）因其卓越的自然语言处理、逻辑推理和泛化能力，成为推动电力行业智能化的关键技术。然而，缺乏针对电力行业的LLM性能评估基准限制了其应用。为此，我们推出了“ElecBench”，一个专为电力行业设计的LLM评估基准，旨在全面覆盖行业场景、深化专业知识测试并提升决策精度。ElecBench将场景分为通用知识和专业业务，细化为六个核心指标和24个子指标，深入分析LLM在电力行业的应用潜力。我们公开了完整测试集，评估了八种LLM在多场景下的性能。ElecBench致力于成为电力行业LLM应用的标准，支持持续更新，推动技术与应用的发展。",
    "title_cn": "ElecBench：大型语言模型电力调度评估的基准",
    "tags": [
      "LLM应用",
      "",
      ""
    ]
  },
  {
    "title": "Emilia: An Extensive, Multilingual, and Diverse Speech Dataset for Large-Scale Speech Generation",
    "submit_datetime": "2024年07月07日",
    "abstract": "Recently, speech generation models have made significant progress by using large-scale training data. However, the research community struggle to produce highly spontaneous and human-like speech due to the lack of large-scale, diverse, and spontaneous speech data. This paper presents \\textit{Emilia}, the first multilingual speech generation dataset from in-the-wild speech data, and Emilia-Pipe, the first open-source preprocessing pipeline designed to transform in-the-wild speech data into high-quality training data with annotations for speech generation. Emilia starts with over 101k hours of speech in six languages and features diverse speech with varied speaking styles. To facilitate the scale-up of Emilia, the open-source pipeline Emilia-Pipe can process one hour of raw speech data ready for model training in a few mins, which enables the research community to collaborate on large-scale speech generation research. Experimental results validate the effectiveness of Emilia. Demos are available at: https://emilia-dataset.github.io/Emilia-Demo-Page/.",
    "pdf_link": "https://arxiv.org/abs/2407.05361",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05361v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05361/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05361v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05361/pca_clustering_acoustic_00.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05361v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05361/pca_clustering_semantic.png"
      }
    ],
    "abstract_cn": "近期，语音生成模型借助大规模训练数据取得了长足进步。然而，由于缺乏大规模、多样且自然的语音数据，研究者们难以创造出高度自然和类人的语音。为此，我们推出了 \\textit{Emilia}，首个基于自然环境语音的多语言生成数据集，以及 Emilia-Pipe，一个开源预处理工具，能将自然语音转化为高质量的训练数据。Emilia 包含超过 101,000 小时的六种语言语音，风格多样。Emilia-Pipe 能在几分钟内处理一小时的原始语音，为模型训练做好准备，助力研究社区共同推进大规模语音生成研究。实验证实了 Emilia 的有效性。演示可访问：https://emilia-dataset.github.io/Emilia-Demo-Page/。",
    "title_cn": "Emilia 数据集，涵盖广泛、多语言且多样化，专为大规模语音生成设计。",
    "tags": [
      "LLM应用",
      "语音技术",
      "数据集"
    ]
  },
  {
    "title": "A Queueing Theoretic Perspective on Low-Latency LLM Inference with Variable Token Length",
    "submit_datetime": "2024年07月07日",
    "abstract": "Large language models (LLMs) propel the prosperity of interactive AI applications showcased by ChatGPT that demand timely response of inference services. However, LLM inference is computation intensive and memory intensive, and improper parameter configuration at LLM platforms may exacerbate the inference time. In this paper, we analyze the impact of LLM output token distribution on the inference queueing delay, where the max-token clipping and the batched inference are considered. By formulating an M/G/1 model, we observe that enforcing a maximum output token limit on a very small fraction of inference requests can significantly reduce the queueing delay, and our model facilitates the selection of the optimal limit. For the batch inference, we model the service process as a bulk queue in which the batch processing time is affected by the batch size and the maximum token size inside this batch jointly. The queueing delays of the batching of all buffered requests (dynamic batching), the batching of constant number of requests (fixed batching), and the batching without intra-batch waiting (elastic batching) are derived. Experimental results show that our mathematical models coincide with the event-driven simulations well.",
    "pdf_link": "https://arxiv.org/abs/2407.05347",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05347v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05347/llama2tu.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05347v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05347/kvcache.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05347v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05347/time_token_line.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05347v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05347/throughput.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05347v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05347/EL_Hb.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05347v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05347/miub.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05347v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05347/mg1_EW.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05347v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05347/mg1_EWqs.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05347v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05347/mg1_pai.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05347v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05347/tradeoff.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05347v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05347/junyun_llama.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05347v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05347/junyun_alpaca.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05347v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05347/junyun_chatglm.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05347v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05347/fix_bsz.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05347v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05347/dy_bmax.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLM）如 ChatGPT 推动了交互式 AI 应用的繁荣，但这些模型在推理时既计算密集又内存密集，不当的参数配置可能延长推理时间。本文探讨了 LLM 输出令牌分布对推理排队延迟的影响，并引入了最大令牌剪裁和批量推理策略。通过构建 M/G/1 模型，我们发现对少数请求设置最大输出令牌限制能显著减少排队延迟，并有助于选择最佳限制。对于批量推理，我们将其服务过程视为受批量大小和内部最大令牌大小影响的批量队列。我们分析了动态、固定和弹性三种批处理方式的排队延迟，实验结果验证了我们的数学模型与实际模拟的一致性。",
    "title_cn": "从排队理论视角出发，解析大型语言模型在可变令牌长度下的低延迟推理",
    "tags": [
      "LLM应用",
      "人工智能",
      "计算机科学"
    ]
  },
  {
    "title": "Can Model Uncertainty Function as a Proxy for Multiple-Choice Question Item Difficulty?",
    "submit_datetime": "2024年07月07日",
    "abstract": "Estimating the difficulty of multiple-choice questions would be great help for educators who must spend substantial time creating and piloting stimuli for their tests, and for learners who want to practice. Supervised approaches to difficulty estimation have yielded to date mixed results. In this contribution we leverage an aspect of generative large models which might be seen as a weakness when answering questions, namely their uncertainty, and exploit it towards exploring correlations between two different metrics of uncertainty, and the actual student response distribution. While we observe some present but weak correlations, we also discover that the models' behaviour is different in the case of correct vs wrong answers, and that correlations differ substantially according to the different question types which are included in our fine-grained, previously unused dataset of 451 questions from a Biopsychology course. In discussing our findings, we also suggest potential avenues to further leverage model uncertainty as an additional proxy for item difficulty.",
    "pdf_link": "https://arxiv.org/abs/2407.05327",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05327v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05327/pic-MCQ.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.05327v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05327/student_performance.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05327v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05327/spear_entropy.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05327v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05327/chi_1st_token.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05327v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05327/chi_order.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05327v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05327/spear_1st_token_all.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05327v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05327/spear_order_all.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05327v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05327/spear_1st_token_correct.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05327v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05327/spear_order_correct.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05327v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05327/phrasing_comparison.png"
      }
    ],
    "abstract_cn": "估计多项选择题的难度对教育者和学习者都极为有益。然而，监督方法在难度估计上的表现参差不齐。本研究巧妙利用生成模型在回答问题时的不确定性，探索其与学生实际反应分布间的关联。我们发现，尽管相关性不强，但模型在答对与答错时的行为迥异，且不同题型的相关性差异显著。基于这些发现，我们提出，进一步挖掘模型不确定性，或能为评估题目难度提供新的视角。",
    "title_cn": "模型不确定性是否能代表多项选择题的难度？",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Enhancing Label-efficient Medical Image Segmentation with Text-guided Diffusion Models",
    "submit_datetime": "2024年07月07日",
    "abstract": "Aside from offering state-of-the-art performance in medical image generation, denoising diffusion probabilistic models (DPM) can also serve as a representation learner to capture semantic information and potentially be used as an image representation for downstream tasks, e.g., segmentation. However, these latent semantic representations rely heavily on labor-intensive pixel-level annotations as supervision, limiting the usability of DPM in medical image segmentation. To address this limitation, we propose an enhanced diffusion segmentation model, called TextDiff, that improves semantic representation through inexpensive medical text annotations, thereby explicitly establishing semantic representation and language correspondence for diffusion models. Concretely, TextDiff extracts intermediate activations of the Markov step of the reverse diffusion process in a pretrained diffusion model on large-scale natural images and learns additional expert knowledge by combining them with complementary and readily available diagnostic text information. TextDiff freezes the dual-branch multi-modal structure and mines the latent alignment of semantic features in diffusion models with diagnostic descriptions by only training the cross-attention mechanism and pixel classifier, making it possible to enhance semantic representation with inexpensive text. Extensive experiments on public QaTa-COVID19 and MoNuSeg datasets show that our TextDiff is significantly superior to the state-of-the-art multi-modal segmentation methods with only a few training samples.",
    "pdf_link": "https://arxiv.org/abs/2407.05323",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05323v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05323/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05323v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05323/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05323v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05323/x3.png"
      }
    ],
    "abstract_cn": "去噪扩散概率模型 (DPM) 不仅在医学图像生成领域表现卓越，还能作为表示学习器捕捉语义信息，为下游任务如图像分割提供支持。但这些语义表示依赖于繁琐的像素级注释，限制了其在医学图像分割中的应用。为此，我们提出了 TextDiff 模型，通过结合廉价的医学文本注释，显著提升了语义表示的质量，并建立了与语言的直接联系。TextDiff 利用预训练模型中的中间激活，结合诊断文本信息学习专家知识，同时冻结多模态结构，仅通过优化交叉注意力机制和像素分类器，实现了语义特征与诊断描述的精准对齐。实验证明，TextDiff 在仅使用少量样本的情况下，大幅超越了现有最先进的多模态分割方法。",
    "title_cn": "利用文本引导的扩散模型，提升医学图像分割的标签效率",
    "tags": [
      "LLM应用",
      "",
      "图像处理"
    ]
  },
  {
    "title": "Exploring the Educational Landscape of AI: Large Language Models' Approaches to Explaining Conservation of Momentum in Physics",
    "submit_datetime": "2024年07月07日",
    "abstract": "The integration of Large Language Models (LLMs) in education offers both opportunities and challenges, particularly in fields like physics that demand precise conceptual understanding. This study examines the capabilities of six state-of-the-art LLMs in explaining the law of conservation of momentum, a fundamental principle in physics. By analyzing responses to a consistent, simple prompt in Japanese, we assess the models' explanatory approaches, depth of understanding, and adaptability to different educational levels.Our comprehensive analysis, encompassing text characteristics, response similarity, and keyword usage, unveils significant diversity in explanatory styles across models. ChatGPT4.0 and Coral provided more comprehensive and technically detailed explanations, while Gemini models tended toward more intuitive approaches. Key findings include variations in the treatment of critical concepts such as net force, and differing emphases on mathematical rigor and real-world applications.The results indicate that different AI models may be more suitable for various educational contexts, ranging from introductory to advanced levels. ChatGPT4.0 and Coral demonstrated potential for advanced discussions, while Gemini models appeared more appropriate for introductory explanations. Importantly, the study underscores the necessity of educator guidance in effectively leveraging these AI tools, as models varied in their ability to convey nuanced aspects of physical principles.This research establishes a foundation for understanding the educational potential of LLMs in physics, providing insights for educators on integrating these tools into their teaching practices. It also highlights the need for further investigation into AI-assisted learning in STEM fields, paving the way for more sophisticated applications of AI in physics education.",
    "pdf_link": "https://arxiv.org/abs/2407.05308",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）在教育领域的应用，尤其是在物理学这样需要精确概念理解的领域，既充满机遇也面临挑战。本研究聚焦于六种顶尖LLMs解释动量守恒定律的能力，这是物理学的核心原理。我们通过分析模型对日语简单提示的响应，评估了它们的解释深度、适应性及教育层面的适用性。综合分析显示，模型在解释风格上存在显著差异：ChatGPT4.0和Coral提供详尽技术解释，Gemini模型则更侧重直观说明。研究发现，模型在处理关键物理概念和强调数学严谨性与实际应用方面各有侧重。这表明，不同模型适用于不同教育阶段，从基础到高级。ChatGPT4.0和Coral适合深入讨论，Gemini模型则更适于基础教学。研究强调，教育者在利用这些AI工具时的重要性，因为模型在传达物理原理的细微差别方面能力各异。此研究为LLMs在物理教育中的应用提供了基础，并为教育者整合这些工具提供了指导。同时，它也指出了在STEM领域进一步探索AI辅助学习的必要性，为AI在物理教育中的更高级应用奠定了基础。",
    "title_cn": "探究AI教育领域：大型语言模型如何解释物理学中的动量守恒",
    "tags": [
      "LLM应用",
      "",
      "物理学"
    ]
  },
  {
    "title": "UltraEdit: Instruction-based Fine-Grained Image Editing at Scale",
    "submit_datetime": "2024年07月07日",
    "abstract": "This paper presents UltraEdit, a large-scale (approximately 4 million editing samples), automatically generated dataset for instruction-based image editing. Our key idea is to address the drawbacks in existing image editing datasets like InstructPix2Pix and MagicBrush, and provide a systematic approach to producing massive and high-quality image editing samples. UltraEdit offers several distinct advantages: 1) It features a broader range of editing instructions by leveraging the creativity of large language models (LLMs) alongside in-context editing examples from human raters; 2) Its data sources are based on real images, including photographs and artworks, which provide greater diversity and reduced bias compared to datasets solely generated by text-to-image models; 3) It also supports region-based editing, enhanced by high-quality, automatically produced region annotations. Our experiments show that canonical diffusion-based editing baselines trained on UltraEdit set new records on MagicBrush and Emu-Edit benchmarks. Our analysis further confirms the crucial role of real image anchors and region-based editing data. The dataset, code, and models can be found in https://ultra-editing.github.io.",
    "pdf_link": "https://arxiv.org/abs/2407.05282",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05282v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05282/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05282v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05282/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05282v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05282/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05282v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05282/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05282v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05282/2d_bar_plot.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05282v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05282/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05282v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05282/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05282v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05282/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05282v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05282/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05282v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05282/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05282v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05282/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05282v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05282/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05282v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05282/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05282v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05282/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05282v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05282/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05282v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05282/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05282v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05282/human_eval_example.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05282v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05282/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05282v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05282/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05282v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05282/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05282v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05282/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05282v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05282/x20.png"
      }
    ],
    "abstract_cn": "本文推出 UltraEdit，一个自动生成的大规模图像编辑数据集，约含 400 万样本。旨在克服现有数据集的不足，系统化生成高质量编辑样本。UltraEdit 的优势包括：1）结合 LLM 创造力和人类示例，扩展编辑指令；2）基于真实图像，提升多样性，减少偏见；3）支持区域编辑，借助自动高质量区域注释。实验显示，基于 UltraEdit 训练的扩散编辑模型在 MagicBrush 和 Emu-Edit 测试中刷新纪录。分析强调了真实图像和区域编辑数据的重要性。相关资源可访问 https://ultra-editing.github.io。",
    "title_cn": "UltraEdit：大规模基于指令的精细图像编辑",
    "tags": [
      "LLM应用",
      "图像处理",
      "人工智能"
    ]
  },
  {
    "title": "Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions",
    "submit_datetime": "2024年07月07日",
    "abstract": "Name-based gender prediction has traditionally categorized individuals as either female or male based on their names, using a binary classification system. That binary approach can be problematic in the cases of gender-neutral names that do not align with any one gender, among other reasons. Relying solely on binary gender categories without recognizing gender-neutral names can reduce the inclusiveness of gender prediction tasks. We introduce an additional gender category, i.e., \"neutral\", to study and address potential gender biases in Large Language Models (LLMs). We evaluate the performance of several foundational and large language models in predicting gender based on first names only. Additionally, we investigate the impact of adding birth years to enhance the accuracy of gender prediction, accounting for shifting associations between names and genders over time. Our findings indicate that most LLMs identify male and female names with high accuracy (over 80%) but struggle with gender-neutral names (under 40%), and the accuracy of gender prediction is higher for English-based first names than non-English names. The experimental results show that incorporating the birth year does not improve the overall accuracy of gender prediction, especially for names with evolving gender associations. We recommend using caution when applying LLMs for gender identification in downstream tasks, particularly when dealing with non-binary gender labels.",
    "pdf_link": "https://arxiv.org/abs/2407.05271",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05271v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05271/diagram.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05271v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05271/us_performance_plot_v3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05271v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05271/canada_performance_plot_v3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05271v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05271/france_performance_plot_v3.png"
      }
    ],
    "abstract_cn": "传统上，基于名字的性别预测采用二元分类系统，将个人简单划分为女性或男性。然而，这种做法在处理性别中性名字时显得力不从心，且忽视了性别多样性。为此，我们新增“中性”类别，旨在探索并纠正大型语言模型（LLM）中的性别偏见。我们测试了多个基础及大型模型仅凭名字进行性别预测的能力，并探讨了加入出生年份对预测准确性的影响，以适应名字与性别关联的时代变迁。结果显示，多数LLM在识别传统性别名字时准确率超过80%，但对性别中性名字的识别率不足40%，且英语名字的预测准确性优于非英语名字。实验还表明，引入出生年份并未显著提升预测准确性，尤其是对性别含义随时间变化的名字。因此，我们建议在涉及非二元性别标签的下游任务中，使用LLM进行性别识别时应持谨慎态度。",
    "title_cn": "揭秘 LLM 中的性别偏见：从无性别标签的名字预测出发",
    "tags": [
      "LLM应用",
      "性别研究",
      "人工智能"
    ]
  },
  {
    "title": "RULE: Reliable Multimodal RAG for Factuality in Medical Vision Language Models",
    "submit_datetime": "2024年07月06日",
    "abstract": "The recent emergence of Medical Large Vision Language Models (Med-LVLMs) has enhanced medical diagnosis. However, current Med-LVLMs frequently encounter factual issues, often generating responses that do not align with established medical facts. Retrieval-Augmented Generation (RAG), which utilizes external knowledge, can improve the factual accuracy of these models but introduces two major challenges. First, limited retrieved contexts might not cover all necessary information, while excessive retrieval can introduce irrelevant and inaccurate references, interfering with the model's generation. Second, in cases where the model originally responds correctly, applying RAG can lead to an over-reliance on retrieved contexts, resulting in incorrect answers. To address these issues, we propose RULE, which consists of two components. First, we introduce a provably effective strategy for controlling factuality risk through the calibrated selection of the number of retrieved contexts. Second, based on samples where over-reliance on retrieved contexts led to errors, we curate a preference dataset to fine-tune the model, balancing its dependence on inherent knowledge and retrieved contexts for generation. We demonstrate the effectiveness of RULE on three medical VQA datasets, achieving an average improvement of 20.8% in factual accuracy. We publicly release our benchmark and code in https://github.com/richard-peng-xia/RULE.",
    "pdf_link": "https://arxiv.org/abs/2407.05131",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05131v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05131/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05131v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05131/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05131v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05131/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05131v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05131/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05131v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05131/x5.png"
      }
    ],
    "abstract_cn": "近期，医疗大型视觉语言模型（Med-LVLMs）在医疗诊断领域崭露头角，但它们在生成与医学事实不符的回答时屡见不鲜。检索增强生成（RAG）虽能借助外部知识提升事实准确性，却也带来了两大难题：一是检索内容可能不足或过多，导致信息不全或干扰生成；二是过度依赖检索内容，反而可能引发错误。为此，我们设计了RULE系统，通过精准控制检索数量来降低事实风险，并利用错误样本构建数据集进行模型微调，以平衡固有知识与检索内容的依赖。实验表明，RULE在三个医疗VQA数据集上平均提升了20.8%的事实准确性，相关基准和代码已公开于https://github.com/richard-peng-xia/RULE。",
    "title_cn": "RULE：医学视觉语言模型中事实性的可靠多模态 RAG",
    "tags": [
      "RAG",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Enhance the Robustness of Text-Centric Multimodal Alignments",
    "submit_datetime": "2024年07月06日",
    "abstract": "Converting different modalities into general text, serving as input prompts for large language models (LLMs), is a common method to align multimodal models when there is limited pairwise data. This text-centric approach leverages the unique properties of text as a modality space, transforming diverse inputs into a unified textual representation. This enables downstream models to effectively interpret various modal inputs. This study assesses the quality and robustness of multimodal representations in the presence of missing entries, noise, or absent modalities, revealing that current text-centric alignment methods compromise downstream robustness. To address this issue, we propose a new text-centric approach that achieves superior robustness compared to previous methods across various modalities in different settings. Our findings highlight the potential of this approach to enhance the robustness and adaptability of multimodal representations, offering a promising solution for dynamic and real-world applications.",
    "pdf_link": "https://arxiv.org/abs/2407.05036",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05036v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05036/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05036v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05036/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05036v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05036/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05036v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05036/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05036v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05036/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05036v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05036/x6.png"
      }
    ],
    "abstract_cn": "在多模态模型对齐中，将不同模态数据转换为通用文本输入是一种常见策略，尤其在成对数据有限时。这种方法通过利用文本的独特性，将多样输入统一为文本形式，便于下游模型处理。然而，研究显示，现有方法在面对数据缺失、噪声或模态不全时，下游鲁棒性受损。为此，我们提出了一种新方法，显著提升了在各种模态和场景下的鲁棒性。这一进展不仅增强了多模态系统的适应性，也为复杂现实应用提供了有力支持。",
    "title_cn": "提升文本主导型多模态对齐的稳健性",
    "tags": [
      "LLM应用",
      "人工智能",
      "多模态系统"
    ]
  },
  {
    "title": "LogicVista: Multimodal LLM Logical Reasoning Benchmark in Visual Contexts",
    "submit_datetime": "2024年07月06日",
    "abstract": "We propose LogicVista, an evaluation benchmark that assesses the integrated logical reasoning capabilities of multimodal large language models (MLLMs) in Visual contexts. Recent advancements in MLLMs have demonstrated various fascinating abilities, from crafting poetry based on an image to performing mathematical reasoning. However, there is still a lack of systematic evaluation of MLLMs' proficiency in logical reasoning tasks, which are essential for activities like navigation and puzzle-solving. Thus we evaluate general logical cognition abilities across 5 logical reasoning tasks encompassing 9 different capabilities, using a sample of 448 multiple-choice questions. Each question is annotated with the correct answer and the human-written reasoning behind the selection, enabling both open-ended and multiple-choice evaluation. A total of 8 MLLMs are comprehensively evaluated using LogicVista. Code and Data Available at https://github.com/Yijia-Xiao/LogicVista.",
    "pdf_link": "https://arxiv.org/abs/2407.04973",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.04973v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04973/ours1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04973v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04973/vqav2.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.04973v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04973/ours2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04973v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04973/textvqa.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.04973v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04973/ours3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04973v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04973/mmvet1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04973v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04973/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04973v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04973/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04973v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04973/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04973v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04973/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04973v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04973/x5.png"
      }
    ],
    "abstract_cn": "我们推出了 LogicVista 评估基准，旨在全面检验多模态大型语言模型 (MLLMs) 在视觉环境中的逻辑推理能力。随着 MLLMs 技术的进步，它们已能从图像中创作诗歌，甚至进行数学推理。但针对这些模型在逻辑推理任务上的表现，尤其是对导航和解谜等关键活动的影响，仍缺乏系统性评估。为此，我们设计了包含 448 道多选题的测试集，覆盖 5 大逻辑推理任务和 9 项不同能力，每个问题附有正确答案及人类推理解释，便于开放式和多选题评估。LogicVista 已对 8 个 MLLMs 进行了详尽测试，相关代码和数据已公开于 https://github.com/Yijia-Xiao/LogicVista。",
    "title_cn": "LogicVista：一项针对视觉环境中多模态大型语言模型的逻辑推理基准测试",
    "tags": [
      "LLM应用",
      "人工智能",
      ""
    ]
  },
  {
    "title": "CLIMB: A Benchmark of Clinical Bias in Large Language Models",
    "submit_datetime": "2024年07月06日",
    "abstract": "Large language models (LLMs) are increasingly applied to clinical decision-making. However, their potential to exhibit bias poses significant risks to clinical equity. Currently, there is a lack of benchmarks that systematically evaluate such clinical bias in LLMs. While in downstream tasks, some biases of LLMs can be avoided such as by instructing the model to answer \"I'm not sure...\", the internal bias hidden within the model still lacks deep studies. We introduce CLIMB (shorthand for A Benchmark of Clinical Bias in Large Language Models), a pioneering comprehensive benchmark to evaluate both intrinsic (within LLMs) and extrinsic (on downstream tasks) bias in LLMs for clinical decision tasks. Notably, for intrinsic bias, we introduce a novel metric, AssocMAD, to assess the disparities of LLMs across multiple demographic groups. Additionally, we leverage counterfactual intervention to evaluate extrinsic bias in a task of clinical diagnosis prediction. Our experiments across popular and medically adapted LLMs, particularly from the Mistral and LLaMA families, unveil prevalent behaviors with both intrinsic and extrinsic bias. This work underscores the critical need to mitigate clinical bias and sets a new standard for future evaluations of LLMs' clinical bias.",
    "pdf_link": "https://arxiv.org/abs/2407.05250",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05250v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05250/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05250v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05250/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05250v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05250/x3.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLM）在临床决策中的应用日益增多，但其潜在的偏见问题对临床公平性构成威胁。目前，系统评估LLM临床偏见的基准尚缺。尽管在下游任务中，通过模型回答“我不确定...”等方式可规避部分偏见，但模型内部的隐性偏见仍待深入探究。为此，我们推出了CLIMB（大型语言模型临床偏见基准），这一创新性基准旨在全面评估LLM在临床决策中的内在与外在偏见。针对内在偏见，我们创新性地提出了AssocMAD指标，用以衡量LLM在不同人群间的差异。同时，我们采用反事实干预法，对临床诊断预测任务中的外在偏见进行评估。通过对Mistral和LLaMA系列等流行医学适应LLM的实验，我们揭示了普遍存在的内在与外在偏见现象。此项研究强调了减轻临床偏见的重要性，并为未来LLM临床偏见的评估树立了新标杆。",
    "title_cn": "CLIMB：一项针对大型语言模型中临床偏差的基准研究",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Large Language Model as an Assignment Evaluator: Insights, Feedback, and Challenges in a 1000+ Student Course",
    "submit_datetime": "2024年07月06日",
    "abstract": "Using large language models (LLMs) for automatic evaluation has become an important evaluation method in NLP research. However, it is unclear whether these LLM-based evaluators can be applied in real-world classrooms to assess student assignments. This empirical report shares how we use GPT-4 as an automatic assignment evaluator in a university course with 1,028 students. Based on student responses, we find that LLM-based assignment evaluators are generally acceptable to students when students have free access to these LLM-based evaluators. However, students also noted that the LLM sometimes fails to adhere to the evaluation instructions. Additionally, we observe that students can easily manipulate the LLM-based evaluator to output specific strings, allowing them to achieve high scores without meeting the assignment rubric. Based on student feedback and our experience, we provide several recommendations for integrating LLM-based evaluators into future classrooms.",
    "pdf_link": "https://arxiv.org/abs/2407.05216",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05216v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05216/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05216v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05216/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05216v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05216/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05216v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05216/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05216v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05216/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05216v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05216/evaluation_assistant_interface_full.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05216v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05216/evaluation_assistant_response.png"
      }
    ],
    "abstract_cn": "在 NLP 研究中，利用大型语言模型 (LLM) 进行自动评估已变得至关重要。但这些基于 LLM 的评估器能否在实际课堂中用于学生作业评估尚存疑问。本报告展示了我们如何在一门包含 1,028 名学生的课程中运用 GPT-4 进行自动作业评估。调查显示，当学生能自由使用这些评估工具时，它们颇受欢迎。不过，学生也反映 LLM 有时会偏离评估指南。更有甚者，学生发现通过操控评估器输出特定内容，即便未达标也能获得高分。结合学生意见与实践经验，我们提出了一系列建议，旨在优化未来课堂中 LLM 评估器的应用。",
    "title_cn": "大型语言模型在评估作业方面提供了宝贵的见解和反馈，但在处理超过1000名学生的课程时也面临挑战。",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "BadCLM: Backdoor Attack in Clinical Language Models for Electronic Health Records",
    "submit_datetime": "2024年07月06日",
    "abstract": "The advent of clinical language models integrated into electronic health records (EHR) for clinical decision support has marked a significant advancement, leveraging the depth of clinical notes for improved decision-making. Despite their success, the potential vulnerabilities of these models remain largely unexplored. This paper delves into the realm of backdoor attacks on clinical language models, introducing an innovative attention-based backdoor attack method, BadCLM (Bad Clinical Language Models). This technique clandestinely embeds a backdoor within the models, causing them to produce incorrect predictions when a pre-defined trigger is present in inputs, while functioning accurately otherwise. We demonstrate the efficacy of BadCLM through an in-hospital mortality prediction task with MIMIC III dataset, showcasing its potential to compromise model integrity. Our findings illuminate a significant security risk in clinical decision support systems and pave the way for future endeavors in fortifying clinical language models against such vulnerabilities.",
    "pdf_link": "https://arxiv.org/abs/2407.05213",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05213v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05213/pic1_illustration.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.05213v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05213/v3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05213v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05213/fig6_att_arch.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05213v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05213/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05213v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05213/fig5_cacc.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05213v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05213/fig6_auc.png"
      }
    ],
    "abstract_cn": "临床语言模型融入电子健康记录（EHR），助力临床决策，是一大进步。然而，这些模型的潜在弱点尚未充分探索。本文探讨了针对临床语言模型的后门攻击，引入了基于注意力的BadCLM攻击方法。该方法在模型中秘密植入后门，使其在特定触发下产生错误预测，平时则正常运作。通过MIMIC III数据集的院内死亡率预测任务，我们验证了BadCLM的威胁性。研究揭示了临床决策支持系统的安全风险，并为强化模型防御指明了方向。",
    "title_cn": "BadCLM：电子健康记录中临床语言模型的后门攻击",
    "tags": [
      "LLM应用",
      "",
      "网络安全"
    ]
  },
  {
    "title": "Harnessing the Power of LLMs: Automating Unit Test Generation for High-Performance Computing",
    "submit_datetime": "2024年07月06日",
    "abstract": "Unit testing is crucial in software engineering for ensuring quality. However, it's not widely used in parallel and high-performance computing software, particularly scientific applications, due to their smaller, diverse user base and complex logic. These factors make unit testing challenging and expensive, as it requires specialized knowledge and existing automated tools are often ineffective.\n  To address this, we propose an automated method for generating unit tests for such software, considering their unique features like complex logic and parallel processing. Recently, large language models (LLMs) have shown promise in coding and testing. We explored the capabilities of Davinci (text-davinci-002) and ChatGPT (gpt-3.5-turbo) in creating unit tests for C++ parallel programs. Our results show that LLMs can generate mostly correct and comprehensive unit tests, although they have some limitations, such as repetitive assertions and blank test cases.",
    "pdf_link": "https://arxiv.org/abs/2407.05202",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05202v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05202/x2.png"
      }
    ],
    "abstract_cn": "单元测试在软件工程中至关重要，但在并行和高性能计算软件中使用较少，尤其是科学应用，因其用户基础小且逻辑复杂。这使得单元测试既具挑战性又成本高昂，需要专业知识且现有工具常无效。为此，我们提出了一种自动化方法，针对这类软件的独特特性如复杂逻辑和并行处理，生成单元测试。近期，大型语言模型（LLMs）在编码和测试领域展现出潜力。我们研究了Davinci和ChatGPT在C++并行程序单元测试生成中的应用，发现它们能生成大部分正确且全面的测试，但也有局限，如重复断言和空白测试用例。",
    "title_cn": "驾驭 LLM 之力：自动生成高性能计算的单元测试",
    "tags": [
      "LLM应用",
      "软件工程",
      "高性能计算"
    ]
  },
  {
    "title": "LLMCloudHunter: Harnessing LLMs for Automated Extraction of Detection Rules from Cloud-Based CTI",
    "submit_datetime": "2024年07月06日",
    "abstract": "As the number and sophistication of cyber attacks have increased, threat hunting has become a critical aspect of active security, enabling proactive detection and mitigation of threats before they cause significant harm. Open-source cyber threat intelligence (OS-CTI) is a valuable resource for threat hunters, however, it often comes in unstructured formats that require further manual analysis. Previous studies aimed at automating OSCTI analysis are limited since (1) they failed to provide actionable outputs, (2) they did not take advantage of images present in OSCTI sources, and (3) they focused on on-premises environments, overlooking the growing importance of cloud environments. To address these gaps, we propose LLMCloudHunter, a novel framework that leverages large language models (LLMs) to automatically generate generic-signature detection rule candidates from textual and visual OSCTI data. We evaluated the quality of the rules generated by the proposed framework using 12 annotated real-world cloud threat reports. The results show that our framework achieved a precision of 92% and recall of 98% for the task of accurately extracting API calls made by the threat actor and a precision of 99% with a recall of 98% for IoCs. Additionally, 99.18% of the generated detection rule candidates were successfully compiled and converted into Splunk queries.",
    "pdf_link": "https://arxiv.org/abs/2407.05194",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05194v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05194/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05194v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05194/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05194v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05194/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05194v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05194/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05194v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05194/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05194v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05194/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05194v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05194/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05194v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05194/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05194v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05194/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05194v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05194/x10.png"
      }
    ],
    "abstract_cn": "随着网络攻击的增多和复杂化，威胁狩猎在主动安全中变得至关重要，它能在威胁造成重大损害前进行主动检测和缓解。开源网络威胁情报（OS-CTI）虽为威胁猎人提供了宝贵资源，但常以非结构化形式出现，需手动分析。以往研究在自动化OSCTI分析方面存在局限，如未能提供可操作输出、未利用图像信息、忽视云环境重要性。为此，我们提出LLMCloudHunter框架，利用大型语言模型从文本和视觉OSCTI数据中自动生成检测规则候选。通过12份真实云威胁报告的评估，该框架在提取API调用和IoCs方面分别达到92%精确度和98%召回率，以及99%精确度和98%召回率。此外，99.18%的规则候选成功转换为Splunk查询。",
    "title_cn": "LLMCloudHunter：借助 LLM 之力，自动化提炼云端 CTI 的检测规则",
    "tags": [
      "LLM应用",
      "网络安全",
      "云计算"
    ]
  },
  {
    "title": "FlowLearn: Evaluating Large Vision-Language Models on Flowchart Understanding",
    "submit_datetime": "2024年07月06日",
    "abstract": "Flowcharts are graphical tools for representing complex concepts in concise visual representations. This paper introduces the FlowLearn dataset, a resource tailored to enhance the understanding of flowcharts. FlowLearn contains complex scientific flowcharts and simulated flowcharts. The scientific subset contains 3,858 flowcharts sourced from scientific literature and the simulated subset contains 10,000 flowcharts created using a customizable script. The dataset is enriched with annotations for visual components, OCR, Mermaid code representation, and VQA question-answer pairs. Despite the proven capabilities of Large Vision-Language Models (LVLMs) in various visual understanding tasks, their effectiveness in decoding flowcharts - a crucial element of scientific communication - has yet to be thoroughly investigated. The FlowLearn test set is crafted to assess the performance of LVLMs in flowchart comprehension. Our study thoroughly evaluates state-of-the-art LVLMs, identifying existing limitations and establishing a foundation for future enhancements in this relatively underexplored domain. For instance, in tasks involving simulated flowcharts, GPT-4V achieved the highest accuracy (58%) in counting the number of nodes, while Claude recorded the highest accuracy (83%) in OCR tasks. Notably, no single model excels in all tasks within the FlowLearn framework, highlighting significant opportunities for further development.",
    "pdf_link": "https://arxiv.org/abs/2407.05183",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05183v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05183/x1.png"
      }
    ],
    "abstract_cn": "流程图，作为简化复杂概念的视觉工具，本文引入了FlowLearn数据集，旨在深化对流程图的理解。该数据集不仅收录了3,858个来自科学文献的复杂流程图，还包含了10,000个模拟流程图。通过详尽的视觉组件、OCR、Mermaid代码及VQA问答对标注，FlowLearn为研究提供了丰富资源。尽管大型视觉-语言模型（LVLMs）在视觉理解领域表现卓越，但其在解读科学交流核心——流程图——的能力仍待全面探索。FlowLearn测试集正是为此设计，用以检验LVLMs在流程图理解上的表现。我们的研究不仅全面评估了当前最先进的LVLMs，揭示了其局限性，更为这一领域未来的发展奠定了基础。例如，GPT-4V在模拟流程图节点计数中准确率高达58%，而Claude在OCR任务中准确率则达到83%。然而，没有任何模型能在FlowLearn框架的所有任务中独占鳌头，这无疑为未来的研究与开发提供了广阔空间。",
    "title_cn": "FlowLearn：评估大型视觉-语言模型在流程图理解方面的表现",
    "tags": [
      "LLM应用",
      "科学研究",
      ""
    ]
  },
  {
    "title": "Feedback-Driven Automated Whole Bug Report Reproduction for Android Apps",
    "submit_datetime": "2024年07月06日",
    "abstract": "In software development, bug report reproduction is a challenging task. This paper introduces ReBL, a novel feedback-driven approach that leverages GPT-4, a large-scale language model, to automatically reproduce Android bug reports. Unlike traditional methods, ReBL bypasses the use of Step to Reproduce (S2R) entities. Instead, it leverages the entire textual bug report and employs innovative prompts to enhance GPT's contextual reasoning. This approach is more flexible and context-aware than the traditional step-by-step entity matching approach, resulting in improved accuracy and effectiveness. In addition to handling crash reports, ReBL has the capability of handling non-crash bug reports. Our evaluation of 96 Android bug reports (73 crash and 23 non-crash) demonstrates that ReBL successfully reproduced 90.63% of these reports, averaging only 74.98 seconds per bug report. Additionally, ReBL outperformed three existing tools in both success rate and speed.",
    "pdf_link": "https://arxiv.org/abs/2407.05165",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05165v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05165/moti.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05165v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05165/fill_blan_1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05165v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05165/fill_blank_2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05165v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05165/overview2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05165v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05165/ui2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05165v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05165/group2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05165v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05165/non-crash.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05165v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05165/examples.png"
      }
    ],
    "abstract_cn": "在软件开发领域，错误报告的重现一直是个难题。本文提出的 ReBL 方法，借助 GPT-4 这一大型语言模型，能自动重现 Android 错误报告，且无需依赖传统的“重现步骤”实体。通过全面利用错误报告文本并创新提示设计，ReBL 的上下文推理能力更强，灵活性和准确性也更高。不仅限于崩溃报告，ReBL 还能处理非崩溃错误报告。实验表明，ReBL 在 96 份报告中成功重现了 90.63%，平均处理时间仅 74.98 秒，且在成功率和速度上均超越了三种现有工具。",
    "title_cn": "安卓应用的反馈驱动自动化错误报告重现",
    "tags": [
      "LLM应用",
      "软件开发",
      "移动应用"
    ]
  },
  {
    "title": "Lucy: Think and Reason to Solve Text-to-SQL",
    "submit_datetime": "2024年07月06日",
    "abstract": "Large Language Models (LLMs) have made significant progress in assisting users to query databases in natural language. While LLM-based techniques provide state-of-the-art results on many standard benchmarks, their performance significantly drops when applied to large enterprise databases. The reason is that these databases have a large number of tables with complex relationships that are challenging for LLMs to reason about. We analyze challenges that LLMs face in these settings and propose a new solution that combines the power of LLMs in understanding questions with automated reasoning techniques to handle complex database constraints. Based on these ideas, we have developed a new framework that outperforms state-of-the-art techniques in zero-shot text-to-SQL on complex benchmarks",
    "pdf_link": "https://arxiv.org/abs/2407.05153",
    "graphs": [],
    "abstract_cn": "LLM 在自然语言数据库查询方面取得了显著进展，但在处理大型企业数据库时性能受限。这些数据库的复杂关系对 LLM 构成了挑战。为此，我们提出了一种结合 LLM 理解能力与自动化推理技术的新方案，有效应对了这些复杂约束。基于此，我们开发的新框架在复杂基准测试中表现卓越，超越了现有技术。",
    "title_cn": "Lucy：运用思考与推理，攻克 Text-to-SQL 难题",
    "tags": [
      "LLM应用",
      "数据库",
      ""
    ]
  },
  {
    "title": "Vortex under Ripplet: An Empirical Study of RAG-enabled Applications",
    "submit_datetime": "2024年07月06日",
    "abstract": "Large language models (LLMs) enhanced by retrieval-augmented generation (RAG) provide effective solutions in various application scenarios. However, developers face challenges in integrating RAG-enhanced LLMs into software systems, due to lack of interface specification, requirements from software context, and complicated system management. In this paper, we manually studied 100 open-source applications that incorporate RAG-enhanced LLMs, and their issue reports. We have found that more than 98% of applications contain multiple integration defects that harm software functionality, efficiency, and security. We have also generalized 19 defect patterns and proposed guidelines to tackle them. We hope this work could aid LLM-enabled software development and motivate future research.",
    "pdf_link": "https://arxiv.org/abs/2407.05138",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05138v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05138/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05138v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05138/x2.png"
      }
    ],
    "abstract_cn": "RAG增强的LLM在多种应用场景中表现出色，但开发者在集成过程中遇到诸多难题，如接口规范缺失、软件环境要求复杂等。我们深入分析了100个开源应用案例，发现几乎所有应用都存在集成缺陷，影响软件性能。为此，我们归纳了19种常见缺陷，并提供了解决方案。期待这些发现能助力LLM技术在软件开发中的应用，并推动相关领域的进一步研究。",
    "title_cn": "Ripplet下的涡旋：RAG应用实证研究",
    "tags": [
      "LLM应用",
      "软件开发",
      "人工智能"
    ]
  },
  {
    "title": "Solving for X and Beyond: Can Large Language Models Solve Complex Math Problems with More-Than-Two Unknowns?",
    "submit_datetime": "2024年07月06日",
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable performance in solving math problems, a hallmark of human intelligence. Despite high success rates on current benchmarks; however, these often feature simple problems with only one or two unknowns, which do not sufficiently challenge their reasoning capacities. This paper introduces a novel benchmark, BeyondX, designed to address these limitations by incorporating problems with multiple unknowns. Recognizing the challenges in proposing multi-unknown problems from scratch, we developed BeyondX using an innovative automated pipeline that progressively increases complexity by expanding the number of unknowns in simpler problems. Empirical study on BeyondX reveals that the performance of existing LLMs, even those fine-tuned specifically on math tasks, significantly decreases as the number of unknowns increases - with a performance drop of up to 70\\% observed in GPT-4. To tackle these challenges, we propose the Formulate-and-Solve strategy, a generalized prompting approach that effectively handles problems with an arbitrary number of unknowns. Our findings reveal that this strategy not only enhances LLM performance on the BeyondX benchmark but also provides deeper insights into the computational limits of LLMs when faced with more complex mathematical challenges.",
    "pdf_link": "https://arxiv.org/abs/2407.05134",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05134v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05134/mwp_generation.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05134v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05134/closed_source_print.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05134v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05134/open_source_print.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05134v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05134/different_methods_print_GPT3.5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05134v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05134/mwp_solver.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05134v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05134/different_open_source_print.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05134v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05134/different_methods_print_Gemini.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05134v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05134/different_methods_print_GPT4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05134v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05134/mwp_3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05134v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05134/mwp_4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05134v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05134/mwp_5.png"
      }
    ],
    "abstract_cn": "大型语言模型 (LLM) 在解决数学问题方面表现出色，但现有基准多聚焦于简单问题，未能充分考验其推理能力。为此，我们推出了 BeyondX 基准，通过引入多未知数问题来挑战 LLM。利用自动化流程，我们逐步增加问题复杂度，发现即使经过数学任务微调的 LLM，其性能也随未知数增多而大幅下降。针对这一难题，我们提出了 Formulate-and-Solve 策略，有效应对任意未知数问题。实证显示，该策略不仅提升了 LLM 在 BeyondX 上的表现，更深化了对 LLM 应对复杂数学挑战时计算极限的理解。",
    "title_cn": "大型语言模型能否破解包含多于两个未知数的复杂数学难题？这一挑战正待揭晓。",
    "tags": [
      "LLM应用",
      "",
      ""
    ]
  },
  {
    "title": "SHINE: Saliency-aware HIerarchical NEgative Ranking for Compositional Temporal Grounding",
    "submit_datetime": "2024年07月06日",
    "abstract": "Temporal grounding, a.k.a video moment retrieval, aims at locating video segments corresponding to a given query sentence. The compositional nature of natural language enables the localization beyond predefined events, posing a certain challenge to the compositional generalizability of existing methods. Recent studies establish the correspondence between videos and queries through a decompose-reconstruct manner to achieve compositional generalization. However, they only consider dominant primitives and build negative queries through random sampling and recombination, resulting in semantically implausible negatives that hinder the models from learning rational compositions. In addition, recent DETR-based methods still underperform in compositional temporal grounding, showing irrational saliency responses when given negative queries that have subtle differences from positive queries. To address these limitations, we first propose a large language model-driven method for negative query construction, utilizing GPT-3.5-Turbo to generate semantically plausible hard negative queries. Subsequently, we introduce a coarse-to-fine saliency ranking strategy, which encourages the model to learn the multi-granularity semantic relationships between videos and hierarchical negative queries to boost compositional generalization. Extensive experiments on two challenging benchmarks validate the effectiveness and generalizability of our proposed method. Our code is available at https://github.com/zxccade/SHINE.",
    "pdf_link": "https://arxiv.org/abs/2407.05118",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05118v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05118/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05118v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05118/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05118v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05118/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05118v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05118/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05118v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05118/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05118v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05118/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05118v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05118/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05118v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05118/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05118v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05118/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05118v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05118/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05118v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05118/x11.png"
      }
    ],
    "abstract_cn": "时间定位（视频时刻检索）旨在找到与查询句子匹配的视频片段。自然语言的组合特性使得定位超越预设事件成为可能，但也对现有方法的组合泛化能力构成挑战。近期研究通过分解-重建方式建立视频与查询的关联，以实现组合泛化。然而，这些研究仅关注主导原语，并通过随机采样与重组构建负查询，导致语义上不合理的负样本，妨碍模型学习合理组合。此外，基于DETR的方法在处理组合时间定位时仍显不足，面对与正查询细微不同的负查询时，显示出不合逻辑的显著性响应。为克服这些局限，我们首先提出一种利用GPT-3.5-Turbo生成语义合理硬负查询的大型语言模型驱动方法。接着，我们引入从粗到细的显著性排序策略，促使模型学习视频与层次化负查询间的多粒度语义关系，从而增强组合泛化能力。在两个挑战性基准上的广泛实验证实了我们方法的有效性与泛化性。代码已公开于https://github.com/zxccade/SHINE。",
    "title_cn": "SHINE：基于显著性感知的层次负排序技术，用于组合时态定位任务",
    "tags": [
      "LLM应用",
      "视频处理",
      ""
    ]
  },
  {
    "title": "Leveraging Task-Specific Knowledge from LLM for Semi-Supervised 3D Medical Image Segmentation",
    "submit_datetime": "2024年07月06日",
    "abstract": "Traditional supervised 3D medical image segmentation models need voxel-level annotations, which require huge human effort, time, and cost. Semi-supervised learning (SSL) addresses this limitation of supervised learning by facilitating learning with a limited annotated and larger amount of unannotated training samples. However, state-of-the-art SSL models still struggle to fully exploit the potential of learning from unannotated samples. To facilitate effective learning from unannotated data, we introduce LLM-SegNet, which exploits a large language model (LLM) to integrate task-specific knowledge into our co-training framework. This knowledge aids the model in comprehensively understanding the features of the region of interest (ROI), ultimately leading to more efficient segmentation. Additionally, to further reduce erroneous segmentation, we propose a Unified Segmentation loss function. This loss function reduces erroneous segmentation by not only prioritizing regions where the model is confident in predicting between foreground or background pixels but also effectively addressing areas where the model lacks high confidence in predictions. Experiments on publicly available Left Atrium, Pancreas-CT, and Brats-19 datasets demonstrate the superior performance of LLM-SegNet compared to the state-of-the-art. Furthermore, we conducted several ablation studies to demonstrate the effectiveness of various modules and loss functions leveraged by LLM-SegNet.",
    "pdf_link": "https://arxiv.org/abs/2407.05088",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05088v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05088/prompt.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05088v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05088/llm_main.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05088v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05088/LAL.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05088v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05088/pan.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05088v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05088/brat.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05088v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05088/llmcompare.png"
      }
    ],
    "abstract_cn": "传统的3D医学图像分割需要大量体素级标注，耗时且成本高昂。半监督学习（SSL）虽能缓解这一问题，但现有SSL模型仍难以充分挖掘未标注数据的潜力。为此，我们推出了LLM-SegNet，该模型借助大型语言模型（LLM）将专业知识融入协同训练框架，助力模型深入理解感兴趣区域（ROI）特征，实现更精准的分割。同时，我们设计了一种统一的分割损失函数，通过优化模型在自信与不确定区域的预测，进一步降低分割错误。在Left Atrium、Pancreas-CT和Brats-19等公开数据集上的实验显示，LLM-SegNet性能卓越，超越了现有顶尖模型。此外，消融研究也证实了LLM-SegNet各模块及损失函数的有效性。",
    "title_cn": "借助 LLM 中的任务特定知识，实现半监督式 3D 医学图像分割",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Code Less, Align More: Efficient LLM Fine-tuning for Code Generation with Data Pruning",
    "submit_datetime": "2024年07月06日",
    "abstract": "Recent work targeting large language models (LLMs) for code generation demonstrated that increasing the amount of training data through synthetic code generation often leads to exceptional performance. In this paper we explore data pruning methods aimed at enhancing the efficiency of model training specifically for code LLMs. We present techniques that integrate various clustering and pruning metrics to selectively reduce training data without compromising the accuracy and functionality of the generated code. We observe significant redundancies in synthetic training data generation, where our experiments demonstrate that benchmark performance can be largely preserved by training on only 10% of the data. Moreover, we observe consistent improvements in benchmark results through moderate pruning of the training data. Our experiments show that these pruning strategies not only reduce the computational resources needed but also enhance the overall quality code generation.",
    "pdf_link": "https://arxiv.org/abs/2407.05040",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05040v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05040/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05040v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05040/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05040v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05040/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05040v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05040/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05040v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05040/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05040v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05040/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05040v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05040/x7.png"
      }
    ],
    "abstract_cn": "最新研究表明，通过合成代码生成增加训练数据量，大型语言模型在代码生成方面表现卓越。本文探讨了提高代码 LLM 训练效率的数据修剪方法，提出集成多种聚类和修剪指标的技术，确保在减少训练数据的同时，不牺牲生成代码的准确性和功能性。实验发现，仅用10%的数据训练即可大致保持基准性能，适度修剪训练数据还能持续提升基准结果。这些策略不仅节省计算资源，还提升了代码生成的质量。",
    "title_cn": "精简代码，强化对齐：利用数据修剪提升代码生成的 LLM 微调效率",
    "tags": [
      "LLM应用",
      "软件开发",
      "人工智能"
    ]
  },
  {
    "title": "Preference Distillation for Personalized Generative Recommendation",
    "submit_datetime": "2024年07月06日",
    "abstract": "Recently, researchers have investigated the capabilities of Large Language Models (LLMs) for generative recommender systems. Existing LLM-based recommender models are trained by adding user and item IDs to a discrete prompt template. However, the disconnect between IDs and natural language makes it difficult for the LLM to learn the relationship between users. To address this issue, we propose a PErsonAlized PrOmpt Distillation (PeaPOD) approach, to distill user preferences as personalized soft prompts. Considering the complexities of user preferences in the real world, we maintain a shared set of learnable prompts that are dynamically weighted based on the user's interests to construct the user-personalized prompt in a compositional manner. Experimental results on three real-world datasets demonstrate the effectiveness of our PeaPOD model on sequential recommendation, top-n recommendation, and explanation generation tasks.",
    "pdf_link": "https://arxiv.org/abs/2407.05033",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05033v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05033/CODA.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05033v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05033/architecture.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05033v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05033/plot.png"
      }
    ],
    "abstract_cn": "近期，研究者们探索了大型语言模型（LLM）在推荐系统中的应用。现有基于LLM的推荐模型通过在离散模板中加入用户和物品ID进行训练，但ID与自然语言的脱节限制了LLM学习用户关系的能力。为此，我们提出了个性化提示蒸馏（PeaPOD）方法，将用户偏好转化为个性化软提示。鉴于用户偏好的复杂性，我们采用一组动态加权的可学习提示，以组合方式构建个性化提示。实验表明，PeaPOD模型在序列推荐、top-n推荐及解释生成等任务中表现出色。",
    "title_cn": "个性化生成推荐中的偏好蒸馏",
    "tags": [
      "LLM应用",
      "推荐系统",
      "个性化服务"
    ]
  },
  {
    "title": "How do you know that? Teaching Generative Language Models to Reference Answers to Biomedical Questions",
    "submit_datetime": "2024年07月06日",
    "abstract": "Large language models (LLMs) have recently become the leading source of answers for users' questions online. Despite their ability to offer eloquent answers, their accuracy and reliability can pose a significant challenge. This is especially true for sensitive domains such as biomedicine, where there is a higher need for factually correct answers. This paper introduces a biomedical retrieval-augmented generation (RAG) system designed to enhance the reliability of generated responses. The system is based on a fine-tuned LLM for the referenced question-answering, where retrieved relevant abstracts from PubMed are passed to LLM's context as input through a prompt. Its output is an answer based on PubMed abstracts, where each statement is referenced accordingly, allowing the users to verify the answer. Our retrieval system achieves an absolute improvement of 23% compared to the PubMed search engine. Based on the manual evaluation on a small sample, our fine-tuned LLM component achieves comparable results to GPT-4 Turbo in referencing relevant abstracts. We make the dataset used to fine-tune the models and the fine-tuned models based on Mistral-7B-instruct-v0.1 and v0.2 publicly available.",
    "pdf_link": "https://arxiv.org/abs/2407.05015",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05015v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05015/AS_1_.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05015v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05015/Distribution_of_answer_length_final.png"
      }
    ],
    "abstract_cn": "大型语言模型 (LLM) 已成为在线解答用户疑问的首选，但其答案的准确性和可靠性在生物医学等敏感领域尤为关键。为此，我们设计了一种生物医学检索增强生成 (RAG) 系统，通过微调 LLM 并结合 PubMed 相关摘要，确保答案的可靠性。用户可直接验证每条陈述的来源。与 PubMed 搜索引擎相比，我们的系统性能提升了 23%。在小规模评估中，我们的微调 LLM 在摘要引用方面与 GPT-4 Turbo 表现相当。我们还公开了微调所需的数据集及模型。",
    "title_cn": "如何得知？引导生成语言模型参照生物医学问题的答案",
    "tags": [
      "RAG",
      "生物医学",
      "搜索引擎"
    ]
  },
  {
    "title": "Progress or Regress? Self-Improvement Reversal in Post-training",
    "submit_datetime": "2024年07月06日",
    "abstract": "Self-improvement through post-training methods such as iterative preference learning has been acclaimed for enhancing the problem-solving capabilities (e.g., mathematical reasoning) of Large Language Models (LLMs) without human intervention. However, as exploration deepens, it becomes crucial to assess whether these improvements genuinely signify progress in solving more challenging problems or if they could lead to unintended regressions. To address this, we propose a comprehensive evaluative framework that goes beyond the superficial pass@1 metric to scrutinize the underlying enhancements of post-training paradigms for self-improvement. Through rigorous experimentation and analysis across diverse problem-solving tasks, the empirical results point out the phenomenon of \\emph{self-improvement reversal}, where models showing improved performance across benchmarks will paradoxically exhibit declines in broader, essential capabilities, like output diversity and out-of-distribution (OOD) generalization. These findings indicate that current self-improvement practices through post-training are inadequate for equipping models to tackle more complex problems. Furthermore, they underscore the necessity of our critical evaluation metrics in discerning the \\emph{progress or regress} dichotomy for self-improving LLMs.",
    "pdf_link": "https://arxiv.org/abs/2407.05013",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.05013v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05013/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05013v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05013/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05013v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05013/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05013v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05013/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05013v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05013/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05013v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05013/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05013v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05013/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05013v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05013/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05013v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05013/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05013v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05013/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05013v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05013/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05013v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05013/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05013v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05013/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.05013v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.05013/x14.png"
      }
    ],
    "abstract_cn": "迭代偏好学习等训练后方法的自我改进，无需人工干预就能提升LLM的解题能力，如数学推理，备受赞誉。但深入探究后，我们需评估这些进步是否真能应对更难题，或可能导致意外退步。为此，我们设计了超越表面指标的全面评估框架，深入剖析训练后自我改进的实质。实验分析显示，“自我改进逆转”现象：虽在基准测试中表现提升，模型却在输出多样性和OOD泛化等关键能力上退步。这表明，当前训练后自我改进尚不足以应对复杂问题，并凸显了我们评估指标在区分LLM自我改进中进步与退步的必要性。",
    "title_cn": "是进步还是退步？训练后的自我提升出现了逆转现象。",
    "tags": [
      "LLM理论",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Rethinking Visual Prompting for Multimodal Large Language Models with External Knowledge",
    "submit_datetime": "2024年07月05日",
    "abstract": "In recent years, multimodal large language models (MLLMs) have made significant strides by training on vast high-quality image-text datasets, enabling them to generally understand images well. However, the inherent difficulty in explicitly conveying fine-grained or spatially dense information in text, such as masks, poses a challenge for MLLMs, limiting their ability to answer questions requiring an understanding of detailed or localized visual elements. Drawing inspiration from the Retrieval-Augmented Generation (RAG) concept, this paper proposes a new visual prompt approach to integrate fine-grained external knowledge, gleaned from specialized vision models (e.g., instance segmentation/OCR models), into MLLMs. This is a promising yet underexplored direction for enhancing MLLMs' performance. Our approach diverges from concurrent works, which transform external knowledge into additional text prompts, necessitating the model to indirectly learn the correspondence between visual content and text coordinates. Instead, we propose embedding fine-grained knowledge information directly into a spatial embedding map as a visual prompt. This design can be effortlessly incorporated into various MLLMs, such as LLaVA and Mipha, considerably improving their visual understanding performance. Through rigorous experiments, we demonstrate that our method can enhance MLLM performance across nine benchmarks, amplifying their fine-grained context-aware capabilities.",
    "pdf_link": "https://arxiv.org/abs/2407.04681",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.04681v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04681/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04681v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04681/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04681v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04681/x3.png"
      }
    ],
    "abstract_cn": "近年来，多模态大型语言模型 (MLLMs) 在处理图像方面取得了显著进展，但文本在传达细粒度或空间密集信息（如掩码）方面的局限性，限制了它们在理解详细视觉元素方面的能力。本文受检索增强生成 (RAG) 概念启发，提出一种新视觉提示方法，将专业视觉模型的细粒度知识融入 MLLMs，这是一个有前景但未充分探索的提升方向。与将外部知识转化为文本提示的方法不同，我们直接将细粒度知识嵌入空间嵌入图，作为视觉提示，可轻松融入多种 MLLMs，如 LLaVA 和 Mipha，大幅提升视觉理解性能。实验证明，我们的方法在九个基准上有效提升 MLLM 的细粒度上下文感知能力。",
    "title_cn": "探索视觉提示在多模态大型语言模型中的新角色，并研究外部知识如何增强其效能。",
    "tags": [
      "RAG",
      "计算机视觉",
      "人工智能"
    ]
  },
  {
    "title": "GPT vs RETRO: Exploring the Intersection of Retrieval and Parameter-Efficient Fine-Tuning",
    "submit_datetime": "2024年07月05日",
    "abstract": "Parameter-Efficient Fine-Tuning (PEFT) and Retrieval-Augmented Generation (RAG) have become popular methods for adapting large language models while minimizing compute requirements. In this paper, we apply PEFT methods (P-tuning, Adapters, and LoRA) to a modified Retrieval-Enhanced Transformer (RETRO) and a baseline GPT model across several sizes, ranging from 823 million to 48 billion parameters. We show that RETRO models outperform GPT models in zero-shot settings due to their unique pre-training process but GPT models have higher performance potential with PEFT. Additionally, our study indicates that 8B parameter models strike an optimal balance between cost and performance and P-tuning lags behind other PEFT techniques. We further provide a comparative analysis of between applying PEFT to an Instruction-tuned RETRO model and base RETRO model. This work presents the first comprehensive comparison of various PEFT methods integrated with RAG, applied to both GPT and RETRO models, highlighting their relative performance.",
    "pdf_link": "https://arxiv.org/abs/2407.04528",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.04528v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04528/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04528v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04528/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04528v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04528/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04528v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04528/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04528v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04528/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04528v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04528/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04528v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04528/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04528v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04528/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04528v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04528/x9.png"
      }
    ],
    "abstract_cn": "参数高效微调 (PEFT) 和检索增强生成 (RAG) 已成为适应大型语言模型同时降低计算需求的流行方法。本文中，我们采用 PEFT 方法（包括 P-tuning、Adapters 和 LoRA）对不同规模的修改版 RETRO 和基准 GPT 模型进行调整，参数范围从 8.23 亿到 480 亿。结果显示，RETRO 模型因其独特预训练过程在零-shot 环境下表现更佳，而 GPT 模型通过 PEFT 展现出更高性能潜力。研究还发现，80 亿参数模型在成本与性能间取得最佳平衡，P-tuning 则稍逊于其他 PEFT 技术。此外，我们对比了 PEFT 在指令调整 RETRO 模型与基础 RETRO 模型上的应用效果。本研究首次全面比较了 PEFT 与 RAG 结合在 GPT 和 RETRO 模型上的表现，凸显了各方法的相对优势。",
    "title_cn": "GPT 与 RETRO：探寻检索与高效参数微调的融合之道",
    "tags": [
      "RAG",
      "人工智能",
      "计算机科学"
    ]
  },
  {
    "title": "EventChat: Implementation and user-centric evaluation of a large language model-driven conversational recommender system for exploring leisure events in an SME context",
    "submit_datetime": "2024年07月05日",
    "abstract": "Large language models (LLMs) present an enormous evolution in the strategic potential of conversational recommender systems (CRS). Yet to date, research has predominantly focused upon technical frameworks to implement LLM-driven CRS, rather than end-user evaluations or strategic implications for firms, particularly from the perspective of a small to medium enterprises (SME) that makeup the bedrock of the global economy. In the current paper, we detail the design of an LLM-driven CRS in an SME setting, and its subsequent performance in the field using both objective system metrics and subjective user evaluations. While doing so, we additionally outline a short-form revised ResQue model for evaluating LLM-driven CRS, enabling replicability in a rapidly evolving field. Our results reveal good system performance from a user experience perspective (85.5% recommendation accuracy) but underscore latency, cost, and quality issues challenging business viability. Notably, with a median cost of $0.04 per interaction and a latency of 5.7s, cost-effectiveness and response time emerge as crucial areas for achieving a more user-friendly and economically viable LLM-driven CRS for SME settings. One major driver of these costs is the use of an advanced LLM as a ranker within the retrieval-augmented generation (RAG) technique. Our results additionally indicate that relying solely on approaches such as Prompt-based learning with ChatGPT as the underlying LLM makes it challenging to achieve satisfying quality in a production environment. Strategic considerations for SMEs deploying an LLM-driven CRS are outlined, particularly considering trade-offs in the current technical landscape.",
    "pdf_link": "https://arxiv.org/abs/2407.04472",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLM）在对话推荐系统（CRS）的战略潜力方面取得了显著进展。然而，当前研究主要聚焦于技术实施，而非终端用户评估或企业战略影响，尤其是对构成全球经济基石的中小型企业（SME）。本文详细阐述了LLM驱动的CRS在SME环境中的设计及其现场表现，结合客观系统指标与主观用户评价。同时，我们提出了一种简化的修订版ResQue模型，以促进这一快速发展领域的可复制性。研究显示，尽管用户体验良好（推荐准确率达85.5%），但延迟、成本和质量问题仍制约着商业可行性。例如，每次交互成本中位数为$0.04，延迟达5.7秒，凸显了成本效益与响应时间的重要性。此外，依赖基于提示的学习与ChatGPT等方法，在实际生产环境中难以确保高质量输出。针对SME部署LLM驱动的CRS，本文提出了战略考量，特别是在当前技术环境下的权衡选择。",
    "title_cn": "EventChat：一款由大型语言模型驱动，专为中小企业背景下探索休闲活动而设计的对话推荐系统，其核心在于实现与用户为中心的评估。",
    "tags": [
      "LLM应用",
      "中小企业",
      "电子商务"
    ]
  },
  {
    "title": "AriGraph: Learning Knowledge Graph World Models with Episodic Memory for LLM Agents",
    "submit_datetime": "2024年07月05日",
    "abstract": "Advancements in generative AI have broadened the potential applications of Large Language Models (LLMs) in the development of autonomous agents. Achieving true autonomy requires accumulating and updating knowledge gained from interactions with the environment and effectively utilizing it. Current LLM-based approaches leverage past experiences using a full history of observations, summarization or retrieval augmentation. However, these unstructured memory representations do not facilitate the reasoning and planning essential for complex decision-making. In our study, we introduce AriGraph, a novel method wherein the agent constructs a memory graph that integrates semantic and episodic memories while exploring the environment. This graph structure facilitates efficient associative retrieval of interconnected concepts, relevant to the agent's current state and goals, thus serving as an effective environmental model that enhances the agent's exploratory and planning capabilities. We demonstrate that our Ariadne LLM agent, equipped with this proposed memory architecture augmented with planning and decision-making, effectively handles complex tasks on a zero-shot basis in the TextWorld environment. Our approach markedly outperforms established methods such as full-history, summarization, and Retrieval-Augmented Generation in various tasks, including the cooking challenge from the First TextWorld Problems competition and novel tasks like house cleaning and puzzle Treasure Hunting.",
    "pdf_link": "https://arxiv.org/abs/2407.04363",
    "graphs": [],
    "abstract_cn": "生成式AI的发展为大型语言模型（LLM）在自主代理开发中的应用开辟了新天地。要实现真正的自主，关键在于积累并更新从环境互动中获得的知识，并有效运用。目前，基于LLM的方法通过利用完整的观察历史、总结或检索增强来借鉴过往经验。然而，这些非结构化的记忆方式并不利于复杂决策所需的推理和规划。为此，我们提出了AriGraph方法，代理在探索环境的同时构建一个融合语义与情节记忆的图结构。这种图结构能高效地关联检索与代理当前状态和目标相关的概念，从而形成一个强大的环境模型，提升代理的探索与规划能力。实验证明，配备此记忆架构的Ariadne LLM代理，在TextWorld环境中以零-shot方式出色地完成了复杂任务，包括烹饪挑战、房屋清洁及拼图寻宝等，显著超越了传统方法。",
    "title_cn": "AriGraph：利用情景记忆为 LLM 代理学习知识图谱世界模型，以增强其性能",
    "tags": [
      "Agent",
      "人工智能",
      "游戏开发"
    ]
  },
  {
    "title": "On scalable oversight with weak LLMs judging strong LLMs",
    "submit_datetime": "2024年07月05日",
    "abstract": "Scalable oversight protocols aim to enable humans to accurately supervise superhuman AI. In this paper we study debate, where two AI's compete to convince a judge; consultancy, where a single AI tries to convince a judge that asks questions; and compare to a baseline of direct question-answering, where the judge just answers outright without the AI. We use large language models (LLMs) as both AI agents and as stand-ins for human judges, taking the judge models to be weaker than agent models. We benchmark on a diverse range of asymmetries between judges and agents, extending previous work on a single extractive QA task with information asymmetry, to also include mathematics, coding, logic and multimodal reasoning asymmetries. We find that debate outperforms consultancy across all tasks when the consultant is randomly assigned to argue for the correct/incorrect answer. Comparing debate to direct question answering, the results depend on the type of task: in extractive QA tasks with information asymmetry debate outperforms direct question answering, but in other tasks without information asymmetry the results are mixed. Previous work assigned debaters/consultants an answer to argue for. When we allow them to instead choose which answer to argue for, we find judges are less frequently convinced by the wrong answer in debate than in consultancy. Further, we find that stronger debater models increase judge accuracy, though more modestly than in previous studies.",
    "pdf_link": "https://arxiv.org/abs/2407.04622",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.04622v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04622/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04622v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04622/fig1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04622v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04622/fig-open-acc-winrate-task.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04622v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04622/fig-open-protocols-task.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04622v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04622/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04622v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04622/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04622v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04622/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04622v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04622/fig-pvalue-matrices.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04622v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04622/fig-n-turns-task.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04622v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04622/fig-bon-task.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04622v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04622/fig-fewshot-task.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04622v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04622/fig-cot-task.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04622v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04622/fig-turn-style-task.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04622v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04622/fig-both-orders-task.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04622v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04622/fig-both-orders-pos-bias-task.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04622v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04622/fig1-3x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04622v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04622/fig-n-turns.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04622v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04622/fig-bon.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04622v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04622/fig-fewshot.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04622v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04622/fig-cot.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04622v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04622/fig-turn-style.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04622v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04622/fig-both-orders.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04622v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04622/fig-both-orders-pos-bias.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04622v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04622/fig-open-acc-winrate-3x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04622v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04622/fig-open-protocols-3x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04622v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04622/fig-nan.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04622v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04622/elo_by_assignment_pro1_5_judge.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04622v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04622/elo_aggregate_vs_assignment_difference_pro1_5_judge.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04622v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04622/elo_vs_judge_accuracy_pro1_5_judge.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04622v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04622/elo_by_assignment_pro1_0_judge.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04622v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04622/elo_aggregate_vs_assignment_difference_pro1_0_judge.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04622v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04622/elo_vs_judge_accuracy_pro1_0_judge.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04622v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04622/unprocessed-debate-sample.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04622v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04622/processed-debate-sample.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04622v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04622/consultant-part1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04622v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04622/consultant-part2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04622v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04622/debate-part1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04622v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04622/debate-part2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04622v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04622/debate-part3.png"
      }
    ],
    "abstract_cn": "本文探讨了可扩展监督协议，旨在帮助人类有效监管超人AI。我们通过辩论、咨询和直接问答三种模式进行研究。在辩论中，两个AI竞争说服裁判；在咨询中，单个AI回答裁判提问；而直接问答则不涉及AI。我们利用大型语言模型（LLM）模拟AI和人类裁判，发现辩论在所有任务中均优于咨询，尤其是在信息不对称的抽取式QA任务中。然而，在其他任务中，结果不一。此外，允许AI选择辩护答案时，辩论中裁判被错误答案误导的情况较少。更强的辩论者模型虽能提升裁判准确性，但效果不如预期显著。",
    "title_cn": "探讨如何利用较弱的LLMs来监督更强的LLMs，实现监督的可扩展性。",
    "tags": [
      "LLM应用",
      "人工智能",
      ""
    ]
  },
  {
    "title": "VRSD: Rethinking Similarity and Diversity for Retrieval in Large Language Models",
    "submit_datetime": "2024年07月05日",
    "abstract": "Vector retrieval algorithms are vital for semantic queries in the evolving landscape of Large Language Models (LLMs). Retrieving vectors that simultaneously meet criteria for both similarity and diversity significantly enhances the capabilities of LLM-based agents. Despite the widespread use of the Maximal Marginal Relevance (MMR) in retrieval scenarios with relevance and diversity requirements, fluctuations caused by variations in the parameter $ λ$ within the MMR complicate the determination of the optimization trajectory in vector spaces, thus obscuring the direction of enhancement. Moreover, there is a lack of a robust theoretical analysis for the constraints of similarity and diversity in retrieval processes. This paper introduces a novel approach to characterizing both constraints through the relationship between the sum vector and the query vector. The proximity of these vectors addresses the similarity constraint, while necessitating that individual vectors within the sum vector divergently align with the query vector to satisfy the diversity constraint. We also formulate a new combinatorial optimization challenge, taking a selection of $k$ vectors from a set of candidates such that their sum vector maximally aligns with the query vector, a problem we demonstrate to be NP-complete. This establishes the profound difficulty of pursuing similarity and diversity simultaneously in vector retrieval and lays a theoretical groundwork for further research. Additionally, we present the heuristic algorithm Vectors Retrieval with Similarity and Diversity (VRSD) which not only has a definitive optimization goal and eschews the need for preset parameters but also offers a modest reduction in time complexity compared to MMR. Empirical validation further confirm that VRSD significantly surpasses MMR across various datasets.",
    "pdf_link": "https://arxiv.org/abs/2407.04573",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.04573v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04573/Fig_MMR.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.04573v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04573/x1.png"
      }
    ],
    "abstract_cn": "在大型语言模型（LLM）领域，向量检索算法对语义查询至关重要。同时满足相似性和多样性的向量检索，能显著提升LLM代理的能力。尽管最大边际相关性（MMR）在需要相关性和多样性的检索场景中广泛应用，但其参数$λ$的变化导致优化轨迹难以确定，进而影响增强方向的明确性。此外，对于检索过程中相似性和多样性的约束，理论分析尚显不足。本文通过总向量与查询向量之间的关系，巧妙地描述了这两种约束：向量的接近性确保了相似性，而总向量中各向量与查询向量的发散对齐则满足了多样性。我们还提出了一项新的组合优化挑战，即从候选集中选择$k$个向量，使总向量与查询向量最大程度对齐，并证明这是一个NP完全问题。这不仅揭示了同时追求相似性和多样性的难度，也为后续研究奠定了理论基础。此外，我们提出的启发式算法VRSD，不仅目标明确、无需预设参数，还在时间复杂度上优于MMR。实证验证显示，VRSD在多个数据集上均显著超越MMR。",
    "title_cn": "VRSD：在大规模语言模型中，重新审视检索的相似性与多样性",
    "tags": [
      "LLM理论",
      "人工智能",
      "数据检索"
    ]
  },
  {
    "title": "When LLMs Play the Telephone Game: Cumulative Changes and Attractors in Iterated Cultural Transmissions",
    "submit_datetime": "2024年07月05日",
    "abstract": "As large language models (LLMs) start interacting with each other and generating an increasing amount of text online, it becomes crucial to better understand how information is transformed as it passes from one LLM to the next. While significant research has examined individual LLM behaviors, existing studies have largely overlooked the collective behaviors and information distortions arising from iterated LLM interactions. Small biases, negligible at the single output level, risk being amplified in iterated interactions, potentially leading the content to evolve towards attractor states. In a series of telephone game experiments, we apply a transmission chain design borrowed from the human cultural evolution literature: LLM agents iteratively receive, produce, and transmit texts from the previous to the next agent in the chain. By tracking the evolution of text toxicity, positivity, difficulty, and length across transmission chains, we uncover the existence of biases and attractors, and study their dependence on the initial text, the instructions, language model, and model size. For instance, we find that more open-ended instructions lead to stronger attraction effects compared to more constrained tasks. We also find that different text properties display different sensitivity to attraction effects, with toxicity leading to stronger attractors than length. These findings highlight the importance of accounting for multi-step transmission dynamics and represent a first step towards a more comprehensive understanding of LLM cultural dynamics.",
    "pdf_link": "https://arxiv.org/abs/2407.04503",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.04503v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04503/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04503v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04503/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04503v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04503/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04503v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04503/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04503v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04503/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04503v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04503/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04503v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04503/convergence.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04503v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04503/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04503v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04503/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04503v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04503/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04503v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04503/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04503v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04503/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04503v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04503/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04503v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04503/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04503v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04503/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04503v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04503/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04503v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04503/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04503v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04503/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04503v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04503/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04503v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04503/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04503v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04503/x20.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04503v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04503/x21.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04503v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04503/x22.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04503v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04503/x23.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04503v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04503/x24.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04503v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04503/x25.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04503v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04503/x26.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04503v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04503/x27.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04503v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04503/x28.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04503v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04503/x29.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04503v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04503/x30.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04503v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04503/x31.png"
      }
    ],
    "abstract_cn": "随着 LLM 间的互动日益频繁，线上文本生成量激增，深入探究信息在 LLM 间传递时的变化显得尤为关键。尽管单个 LLM 的行为已得到广泛研究，但集体行为及信息扭曲在迭代交互中的影响却鲜被关注。微小的偏差，在单次输出中或许无足轻重，但在迭代交互中可能被放大，进而推动内容向特定状态演化。通过一系列电话游戏实验，我们借鉴人类文化进化理论，构建了传递链模型：LLM 代理依次接收、生成并传递文本。我们追踪了文本在传递过程中的毒性、积极性、难度和长度变化，揭示了偏差与吸引态的存在，并探讨了它们与初始文本、指令、模型类型及规模的关联。例如，开放式指令比约束性任务更易引发强吸引效应。此外，不同文本属性对吸引效应的敏感度各异，毒性比长度更易形成强吸引态。这些发现凸显了多步传输动态研究的重要性，为全面理解 LLM 文化动态奠定了基础。",
    "title_cn": "LLM 参与“电话游戏”时，迭代文化传播中显现出累积变化与吸引子现象。",
    "tags": [
      "LLM应用",
      "人工智能",
      "通信技术"
    ]
  },
  {
    "title": "Are Large Language Models Strategic Decision Makers? A Study of Performance and Bias in Two-Player Non-Zero-Sum Games",
    "submit_datetime": "2024年07月05日",
    "abstract": "Large Language Models (LLMs) have been increasingly used in real-world settings, yet their strategic abilities remain largely unexplored. Game theory provides a good framework for assessing the decision-making abilities of LLMs in interactions with other agents. Although prior studies have shown that LLMs can solve these tasks with carefully curated prompts, they fail when the problem setting or prompt changes. In this work we investigate LLMs' behaviour in strategic games, Stag Hunt and Prisoner Dilemma, analyzing performance variations under different settings and prompts. Our results show that the tested state-of-the-art LLMs exhibit at least one of the following systematic biases: (1) positional bias, (2) payoff bias, or (3) behavioural bias. Subsequently, we observed that the LLMs' performance drops when the game configuration is misaligned with the affecting biases. Performance is assessed based on the selection of the correct action, one which agrees with the prompted preferred behaviours of both players. Alignment refers to whether the LLM's bias aligns with the correct action. For example, GPT-4o's average performance drops by 34% when misaligned. Additionally, the current trend of \"bigger and newer is better\" does not hold for the above, where GPT-4o (the current best-performing LLM) suffers the most substantial performance drop. Lastly, we note that while chain-of-thought prompting does reduce the effect of the biases on most models, it is far from solving the problem at the fundamental level.",
    "pdf_link": "https://arxiv.org/abs/2407.04467",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLM）在实际应用中日益增多，但其战略决策能力尚未充分挖掘。博弈论为评估LLM在与其他代理互动时的决策能力提供了有效框架。虽然先前研究显示，LLM能通过精心设计的提示解决特定任务，但面对变化的问题设置或提示时，它们往往表现不佳。本研究深入探讨了LLM在猎鹿游戏和囚徒困境等战略游戏中的行为，揭示了在不同游戏设置和提示下性能的波动。研究发现，最先进的LLM至少存在以下一种系统偏差：位置偏差、收益偏差或行为偏差。当游戏配置与这些偏差不匹配时，LLM的性能显著下降。性能评估依据于选择符合双方玩家偏好行为的正确行动，而一致性则指LLM的偏差是否与正确行动相符。例如，GPT-4o在偏差不一致时性能下降达34%。此外，“越大越新越好”的普遍观念在此并不适用，GPT-4o（目前表现最佳的LLM）性能下降最为严重。最后，尽管思维链提示能一定程度上减轻偏差影响，但仍未能从根本上解决问题。",
    "title_cn": "大型语言模型能否成为战略决策者？本研究探讨了在双人非零和游戏中，这些模型的表现及其潜在偏差。",
    "tags": [
      "LLM理论",
      "人工智能",
      "博弈论"
    ]
  },
  {
    "title": "MobileFlow: A Multimodal LLM For Mobile GUI Agent",
    "submit_datetime": "2024年07月05日",
    "abstract": "Currently, the integration of mobile Graphical User Interfaces (GUIs) is ubiquitous in most people's daily lives. And the ongoing evolution of multimodal large-scale models, such as GPT-4v, Qwen-VL-Max, has significantly bolstered the capabilities of GUI comprehension and user action analysis, showcasing the potentiality of intelligent GUI assistants. However, current GUI Agents often need to access page layout information through calling system APIs, which may pose privacy risks. Fixing GUI (such as mobile interfaces) to a certain low resolution might result in the loss of fine-grained image details. At the same time, the multimodal large models built for GUI Agents currently have poor understanding and decision-making abilities for Chinese GUI interfaces, making them difficult to apply to a large number of Chinese apps. This paper introduces MobileFlow, a multimodal large language model meticulously crafted for mobile GUI agents. Transforming from the open-source model Qwen-VL-Chat into GUI domain, MobileFlow contains approximately 21 billion parameters and is equipped with novel hybrid visual encoders, making it possible for variable resolutions of image inputs and good support for multilingual GUI. By incorporating Mixture of Experts (MoE) expansions and pioneering alignment training strategies, MobileFlow has the capacity to fully interpret image data and comprehend user instructions for GUI interaction tasks. Finally, MobileFlow outperforms Qwen-VL-Max and GPT-4v in terms of task execution by GUI agents on both public and our proposed evaluation metrics, and has been successfully deployed in real-world business contexts, proving its effectiveness for practical applications.",
    "pdf_link": "https://arxiv.org/abs/2407.04346",
    "graphs": [],
    "abstract_cn": "移动图形用户界面（GUIs）已深入人们的日常生活。随着GPT-4v、Qwen-VL-Max等多模态大型模型的进步，智能GUI助手的潜力日益凸显。然而，现有GUI代理通过系统API获取布局信息的方式存在隐私隐患，且低分辨率固定可能导致细节丢失。此外，这些模型对中文GUI的理解和决策能力不足，难以广泛应用。为此，我们推出了MobileFlow，一款专为移动GUI代理设计的多模态大型语言模型。基于Qwen-VL-Chat，MobileFlow拥有约210亿参数，并引入混合视觉编码器，支持多语言和可变分辨率图像输入。通过专家混合（MoE）扩展及创新训练策略，MobileFlow能精准解读图像并理解用户指令，优化GUI交互。在评估中，MobileFlow超越了Qwen-VL-Max和GPT-4v，并已在实际商业场景中成功应用，展现了其强大的实用价值。",
    "title_cn": "MobileFlow：专为移动界面代理设计的多模态大型语言模型",
    "tags": [
      "LLM应用",
      "移动应用",
      "人工智能"
    ]
  },
  {
    "title": "WOMD-Reasoning: A Large-Scale Language Dataset for Interaction and Driving Intentions Reasoning",
    "submit_datetime": "2024年07月05日",
    "abstract": "We propose Waymo Open Motion Dataset-Reasoning (WOMD-Reasoning), a language annotation dataset built on WOMD, with a focus on describing and reasoning interactions and intentions in driving scenarios. Previous language datasets primarily captured interactions caused by close distances. However, interactions induced by traffic rules and human intentions, which can occur over long distances, are yet sufficiently covered, despite being very common and more challenging for prediction or planning models to understand. Therefore, our WOMD-Reasoning focuses extensively on these interactions, providing a total of 409k Q&As for varying types of interactions. Additionally, WOMD-Reasoning presents by far the largest Q&A dataset on real-world driving scenarios, with around 3 million Q&As covering various topics of autonomous driving from map descriptions, motion status descriptions, to narratives and analyses of agents' interactions, behaviors, and intentions. This extensive textual information enables fine-tuning driving-related Large Language Models (LLMs) for a wide range of applications like scene description, prediction, planning, etc. By incorporating interaction and intention language from WOMD-Reasoning, we see significant enhancements in the performance of the state-of-the-art trajectory prediction model, Multipath++, with improvements of 10.14% in $MR_6$ and 6.90% in $minFDE_6$, proving the effectiveness of WOMD-Reasoning. We hope WOMD-Reasoning would empower LLMs in driving to offer better interaction understanding and behavioral reasoning. The dataset is available on https://waymo.com/open/download .",
    "pdf_link": "https://arxiv.org/abs/2407.04281",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.04281v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04281/Ex2_Traffic_Light.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04281v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04281/Ex3_Pattern_Whole.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04281v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04281/Fig_vocab_stat.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04281v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04281/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04281v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04281/Fig_SPP_Multipath.png"
      }
    ],
    "abstract_cn": "我们推出了Waymo开放运动数据集-推理（WOMD-Reasoning），这是一个专注于驾驶场景中交互与意图描述和推理的语言标注数据集。与以往主要关注近距离交互的数据集不同，WOMD-Reasoning深入探讨了由交通规则和人类意图引发的远距离交互，这些交互虽常见但更具挑战性。数据集包含409k个Q&A，全面覆盖各类交互。此外，WOMD-Reasoning拥有约300万个Q&A，是目前最大的真实驾驶场景问答数据集，内容涵盖自动驾驶的多个方面，如地图描述、运动状态、交互行为及意图分析等。这些丰富的文本数据有助于微调大型语言模型（LLMs），提升其在场景描述、预测和规划等领域的应用能力。实验证明，结合WOMD-Reasoning的交互与意图信息后，最先进的轨迹预测模型Multipath++在性能上显著提升，$MR_6$和$minFDE_6$分别提高了10.14%和6.90%。我们期待WOMD-Reasoning能助力LLMs在驾驶领域实现更精准的交互理解和行为推理。数据集已开放下载，网址为https://waymo.com/open/download。",
    "title_cn": "WOMD-Reasoning：专为交互与驾驶意图推理设计的大规模语言数据集",
    "tags": [
      "LLM应用",
      "自动驾驶",
      ""
    ]
  },
  {
    "title": "VCoME: Verbal Video Composition with Multimodal Editing Effects",
    "submit_datetime": "2024年07月05日",
    "abstract": "Verbal videos, featuring voice-overs or text overlays, provide valuable content but present significant challenges in composition, especially when incorporating editing effects to enhance clarity and visual appeal. In this paper, we introduce the novel task of verbal video composition with editing effects. This task aims to generate coherent and visually appealing verbal videos by integrating multimodal editing effects across textual, visual, and audio categories. To achieve this, we curate a large-scale dataset of video effects compositions from publicly available sources. We then formulate this task as a generative problem, involving the identification of appropriate positions in the verbal content and the recommendation of editing effects for these positions. To address this task, we propose VCoME, a general framework that employs a large multimodal model to generate editing effects for video composition. Specifically, VCoME takes in the multimodal video context and autoregressively outputs where to apply effects within the verbal content and which effects are most appropriate for each position. VCoME also supports prompt-based control of composition density and style, providing substantial flexibility for diverse applications. Through extensive quantitative and qualitative evaluations, we clearly demonstrate the effectiveness of VCoME. A comprehensive user study shows that our method produces videos of professional quality while being 85$\\times$ more efficient than professional editors.",
    "pdf_link": "https://arxiv.org/abs/2407.04697",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.04697v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04697/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04697v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04697/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04697v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04697/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04697v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04697/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04697v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04697/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04697v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04697/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04697v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04697/effect_show.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04697v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04697/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04697v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04697/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04697v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04697/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04697v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04697/x10.png"
      }
    ],
    "abstract_cn": "本文介绍了一项新颖任务——带有编辑效果的口头视频构图，旨在通过整合多模态编辑效果，创造出既连贯又吸引眼球的口头视频。我们构建了一个大规模视频效果数据集，并将任务定义为生成问题，涉及内容中适当位置的识别及相应编辑效果的推荐。为此，我们设计了VCoME框架，利用大型多模态模型智能生成编辑效果，支持灵活的构图控制。实验证明，VCoME不仅效果显著，而且效率惊人，比专业编辑快85倍，同时保持了专业级的视频质量。",
    "title_cn": "VCoME：融合多模态编辑效果的口头视频创作",
    "tags": [
      "LLM应用",
      "视频制作",
      "多媒体"
    ]
  },
  {
    "title": "Enabling On-Device LLMs Personalization with Smartphone Sensing",
    "submit_datetime": "2024年07月05日",
    "abstract": "This demo presents a novel end-to-end framework that combines on-device large language models (LLMs) with smartphone sensing technologies to achieve context-aware and personalized services. The framework addresses critical limitations of current personalization solutions via cloud-based LLMs, such as privacy concerns, latency and cost, and limited personal sensor data. To achieve this, we innovatively proposed deploying LLMs on smartphones with multimodal sensor data and customized prompt engineering, ensuring privacy and enhancing personalization performance through context-aware sensing. A case study involving a university student demonstrated the proposed framework's capability to provide tailored recommendations. In addition, we show that the proposed framework achieves the best trade-off in privacy, performance, latency, cost, battery and energy consumption between on-device and cloud LLMs. Future work aims to integrate more diverse sensor data and conduct large-scale user studies to further refine the personalization. We envision the proposed framework could significantly improve user experiences in various domains such as healthcare, productivity, and entertainment by providing secure, context-aware, and efficient interactions directly on users' devices.",
    "pdf_link": "https://arxiv.org/abs/2407.04418",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.04418v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04418/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04418v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04418/pipe.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.04418v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04418/x2.png"
      }
    ],
    "abstract_cn": "本演示介绍了一种创新的端到端框架，它将设备上的大型语言模型（LLM）与智能手机传感技术相结合，旨在提供情境感知和个性化的服务。该框架通过在智能手机上部署LLM并结合多模态传感器数据和定制提示工程，有效解决了基于云的LLM在隐私、延迟和成本等方面的局限性。通过一个大学学生的案例研究，我们验证了该框架能够提供定制化的推荐服务。此外，该框架在隐私保护、性能、延迟、成本和能源消耗等方面实现了设备上与云LLM之间的最佳平衡。未来，我们将进一步整合更多样化的传感器数据，并开展大规模用户研究，以持续优化个性化服务。我们期待该框架能够在用户设备上提供安全、高效且情境感知的交互，从而在医疗保健、生产力和娱乐等多个领域显著提升用户体验。",
    "title_cn": "通过智能手机感应实现设备上 LLM 的个性化",
    "tags": [
      "LLM应用",
      "智能手机",
      "医疗保健"
    ]
  },
  {
    "title": "Second Place Solution of WSDM2023 Toloka Visual Question Answering Challenge",
    "submit_datetime": "2024年07月05日",
    "abstract": "In this paper, we present our solution for the WSDM2023 Toloka Visual Question Answering Challenge. Inspired by the application of multimodal pre-trained models to various downstream tasks(e.g., visual question answering, visual grounding, and cross-modal retrieval), we approached this competition as a visual grounding task, where the input is an image and a question, guiding the model to answer the question and display the answer as a bounding box on the image. We designed a three-stage solution for this task. Specifically, we used the visual-language pre-trained model OFA as the foundation. In the first stage, we constructed a large-scale synthetic dataset similar to the competition dataset and coarse-tuned the model to learn generalized semantic information. In the second stage, we treated the competition task as a visual grounding task, loaded the weights from the previous stage, and continued to fine-tune the model on the competition dataset, transferring the semantic information learned in the first stage to the competition task. Finally, we designed a bounding box matching and replacing post-processing strategy to correct the model's prediction results. Our team achieved a score of 76.342 on the final leaderboard, ranking second.",
    "pdf_link": "https://arxiv.org/abs/2407.04255",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.04255v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04255/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04255v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04255/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04255v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04255/x3.png"
      }
    ],
    "abstract_cn": "本文中，我们针对WSDM2023 Toloka视觉问答挑战赛，提出了一套三阶段的解决方案。借鉴多模态预训练模型在多种下游任务中的应用，我们将比赛视为视觉定位任务，通过图像和问题引导模型以边界框形式回答问题。首先，我们构建了一个大规模合成数据集，对OFA模型进行粗调，学习通用语义信息。接着，将任务转换为视觉定位，加载前阶段权重，在竞赛数据集上进一步微调，迁移语义知识。最后，通过边界框匹配替换策略优化预测结果。我们团队在排行榜上以76.342分位列第二。",
    "title_cn": "WSDM2023 Toloka 视觉问答挑战亚军方案",
    "tags": [
      "LLM应用\n\n解释：这篇论文描述了一个针对特定挑战赛的三阶段解决方案，其中使用了多模态预训练模型（可能是大型语言模型的一种应用）来处理视觉问答任务。尽管论文中没有直接提到“大型语言模型”（LLM），但使用了多模态预训练模型，这可以被视为LLM在特定应用场景中的使用。因此，我将这篇论文分类为“LLM应用”。",
      "计算机视觉",
      "人工智能"
    ]
  },
  {
    "title": "Me, Myself, and AI: The Situational Awareness Dataset (SAD) for LLMs",
    "submit_datetime": "2024年07月05日",
    "abstract": "AI assistants such as ChatGPT are trained to respond to users by saying, \"I am a large language model\". This raises questions. Do such models know that they are LLMs and reliably act on this knowledge? Are they aware of their current circumstances, such as being deployed to the public? We refer to a model's knowledge of itself and its circumstances as situational awareness. To quantify situational awareness in LLMs, we introduce a range of behavioral tests, based on question answering and instruction following. These tests form the $\\textbf{Situational Awareness Dataset (SAD)}$, a benchmark comprising 7 task categories and over 13,000 questions. The benchmark tests numerous abilities, including the capacity of LLMs to (i) recognize their own generated text, (ii) predict their own behavior, (iii) determine whether a prompt is from internal evaluation or real-world deployment, and (iv) follow instructions that depend on self-knowledge.\n  We evaluate 16 LLMs on SAD, including both base (pretrained) and chat models. While all models perform better than chance, even the highest-scoring model (Claude 3 Opus) is far from a human baseline on certain tasks. We also observe that performance on SAD is only partially predicted by metrics of general knowledge (e.g. MMLU). Chat models, which are finetuned to serve as AI assistants, outperform their corresponding base models on SAD but not on general knowledge tasks. The purpose of SAD is to facilitate scientific understanding of situational awareness in LLMs by breaking it down into quantitative abilities. Situational awareness is important because it enhances a model's capacity for autonomous planning and action. While this has potential benefits for automation, it also introduces novel risks related to AI safety and control. Code and latest results available at https://situational-awareness-dataset.org .",
    "pdf_link": "https://arxiv.org/abs/2407.04694",
    "graphs": [],
    "abstract_cn": "AI助手如ChatGPT在回应用户时自称“我是一个大型语言模型”，这引发了疑问：这些模型是否真正了解自己的身份，并据此行动？它们是否意识到自己被公众使用的情境？我们将这种自我认知和环境感知称为“情境意识”。为了量化大型语言模型（LLM）的情境意识，我们设计了一系列基于问答和指令遵循的测试，形成了包含7大类任务和超过13,000个问题的情境意识数据集（SAD）。SAD测试了LLM的多项能力，如识别自身生成文本、预测行为、区分评估与实际部署环境、遵循基于自我认知的指令等。我们对16个LLM进行了SAD评估，包括预训练和聊天模型。尽管所有模型表现均优于随机水平，但即便是表现最佳的Claude 3 Opus，在某些任务上仍远未达到人类基准。我们还发现，SAD表现与一般知识指标（如MMLU）的相关性有限。经过微调以服务为AI助手的聊天模型，在SAD上表现优于其基础模型，但在一般知识任务上则不然。SAD旨在通过量化分析，深化对LLM情境意识的理解。情境意识至关重要，因为它提升了模型的自主规划与行动能力，虽为自动化带来潜在益处，但也带来了与AI安全和控制相关的新风险。相关代码和最新结果可访问https://situational-awareness-dataset.org。",
    "title_cn": "我、自我与AI：为LLM量身打造的情境意识数据集（SAD）",
    "tags": [
      "LLM理论",
      "人工智能",
      "数据分析"
    ]
  },
  {
    "title": "ANAH-v2: Scaling Analytical Hallucination Annotation of Large Language Models",
    "submit_datetime": "2024年07月05日",
    "abstract": "Large language models (LLMs) exhibit hallucinations in long-form question-answering tasks across various domains and wide applications. Current hallucination detection and mitigation datasets are limited in domains and sizes, which struggle to scale due to prohibitive labor costs and insufficient reliability of existing hallucination annotators. To facilitate the scalable oversight of LLM hallucinations, this paper introduces an iterative self-training framework that simultaneously and progressively scales up the hallucination annotation dataset and improves the accuracy of the hallucination annotator. Based on the Expectation Maximization (EM) algorithm, in each iteration, the framework first applies a hallucination annotation pipeline to annotate a scaled dataset and then trains a more accurate hallucination annotator on the dataset. This new hallucination annotator is adopted in the hallucination annotation pipeline used for the next iteration. Extensive experimental results demonstrate that the finally obtained hallucination annotator with only 7B parameters surpasses the performance of GPT-4 and obtains new state-of-the-art hallucination detection results on HaluEval and HalluQA by zero-shot inference. Such an annotator can not only evaluate the hallucination levels of various LLMs on the large-scale dataset but also help to mitigate the hallucination of LLMs generations, with the Natural Language Inference (NLI) metric increasing from 25% to 37% on HaluEval.",
    "pdf_link": "https://arxiv.org/abs/2407.04693",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.04693v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04693/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04693v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04693/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04693v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04693/x3.png"
      }
    ],
    "abstract_cn": "大型语言模型在长篇问答任务中常出现幻觉现象，而现有的幻觉检测数据集因成本高和可靠性不足难以扩展。为此，本文提出一个迭代自训练框架，通过逐步扩大注释数据集和提升注释器准确性，有效监督 LLM 幻觉。实验显示，该框架训练出的 7B 参数注释器性能超越 GPT-4，在 HaluEval 和 HalluQA 上实现顶尖幻觉检测，并能提升 NLI 指标至 37%，助力减轻 LLM 幻觉问题。",
    "title_cn": "ANAH-v2：大型语言模型分析幻觉标注的扩展研究",
    "tags": [
      "LLM应用",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Seed-ASR: Understanding Diverse Speech and Contexts with LLM-based Speech Recognition",
    "submit_datetime": "2024年07月05日",
    "abstract": "Modern automatic speech recognition (ASR) model is required to accurately transcribe diverse speech signals (from different domains, languages, accents, etc) given the specific contextual information in various application scenarios. Classic end-to-end models fused with extra language models perform well, but mainly in data matching scenarios and are gradually approaching a bottleneck. In this work, we introduce Seed-ASR, a large language model (LLM) based speech recognition model. Seed-ASR is developed based on the framework of audio conditioned LLM (AcLLM), leveraging the capabilities of LLMs by inputting continuous speech representations together with contextual information into the LLM. Through stage-wise large-scale training and the elicitation of context-aware capabilities in LLM, Seed-ASR demonstrates significant improvement over end-to-end models on comprehensive evaluation sets, including multiple domains, accents/dialects and languages. Additionally, Seed-ASR can be further deployed to support specific needs in various scenarios without requiring extra language models. Compared to recently released large ASR models, Seed-ASR achieves 10%-40% reduction in word (or character, for Chinese) error rates on Chinese and English public test sets, further demonstrating its powerful performance.",
    "pdf_link": "https://arxiv.org/abs/2407.04675",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.04675v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04675/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04675v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04675/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04675v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04675/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04675v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04675/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04675v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04675/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04675v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04675/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04675v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04675/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04675v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04675/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04675v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04675/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04675v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04675/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04675v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04675/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04675v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04675/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04675v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04675/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04675v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04675/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04675v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04675/x15.png"
      }
    ],
    "abstract_cn": "现代ASR模型需精准转录多样的语音信号，涵盖不同领域、语言及口音，并在多变场景中结合特定上下文信息。传统端到端模型虽与额外语言模型结合表现不俗，但主要局限于数据匹配场景，渐显瓶颈。为此，我们推出Seed-ASR，一款基于大型语言模型的语音识别系统。Seed-ASR依托音频条件LLM框架，通过整合连续语音与上下文信息至LLM，充分发挥其潜能。经过分阶段大规模训练及上下文感知能力激发，Seed-ASR在跨领域、口音/方言及多语言的综合评测中，显著超越端到端模型。更值得一提的是，Seed-ASR无需额外语言模型即可灵活适应各类场景特定需求。相较于近期问世的大型ASR模型，Seed-ASR在中英文公共测试集上，将词（或汉字）错误率大幅降低10%-40%，实力尽显。",
    "title_cn": "Seed-ASR：借助 LLM 技术，深入探索多样语音与复杂上下文的识别奥秘",
    "tags": [
      "LLM应用",
      "语音识别",
      "人工智能"
    ]
  },
  {
    "title": "Lazarus: Resilient and Elastic Training of Mixture-of-Experts Models with Adaptive Expert Placement",
    "submit_datetime": "2024年07月05日",
    "abstract": "Sparsely-activated Mixture-of-Experts (MoE) architecture has increasingly been adopted to further scale large language models (LLMs) due to its sub-linear scaling for computation costs. However, frequent failures still pose significant challenges as training scales. The cost of even a single failure is significant, as all GPUs need to wait idle until the failure is resolved, potentially losing considerable training progress as training has to restart from checkpoints. Existing solutions for efficient fault-tolerant training either lack elasticity or rely on building resiliency into pipeline parallelism, which cannot be applied to MoE models due to the expert parallelism strategy adopted by the MoE architecture.\n  We present Lazarus, a system for resilient and elastic training of MoE models. Lazarus adaptively allocates expert replicas to address the inherent imbalance in expert workload and speeds-up training, while a provably optimal expert placement algorithm is developed to maximize the probability of recovery upon failures. Through adaptive expert placement and a flexible token dispatcher, Lazarus can also fully utilize all available nodes after failures, leaving no GPU idle. Our evaluation shows that Lazarus outperforms existing MoE training systems by up to 5.7x under frequent node failures and 3.4x on a real spot instance trace.",
    "pdf_link": "https://arxiv.org/abs/2407.04656",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.04656v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04656/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04656v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04656/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04656v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04656/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04656v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04656/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04656v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04656/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04656v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04656/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04656v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04656/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04656v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04656/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04656v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04656/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04656v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04656/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04656v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04656/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04656v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04656/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04656v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04656/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04656v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04656/x14.png"
      }
    ],
    "abstract_cn": "稀疏激活的混合专家（MoE）架构因其对计算成本的次线性缩放特性，正被广泛用于扩展大型语言模型（LLM）。然而，随着训练规模的扩大，频繁的失败问题依然严峻。每一次失败都可能导致所有GPU空闲等待，直至问题解决，进而可能丢失大量训练进度。现有高效容错训练方案或缺乏弹性，或依赖于流水线并行中的弹性构建，但这些方案因MoE架构的专家并行策略而无法适用。为此，我们推出了Lazarus系统，专为MoE模型的弹性训练设计。Lazarus通过自适应分配专家副本，有效应对专家工作负载的不平衡，并加速训练进程。同时，我们开发了一种最优专家放置算法，以最大化失败时的恢复概率。借助自适应专家放置和灵活的令牌调度器，Lazarus能在失败后充分利用所有可用节点，确保无GPU空闲。评估结果表明，在频繁节点失败和真实现货实例环境下，Lazarus的性能分别比现有MoE训练系统高出5.7倍和3.4倍。",
    "title_cn": "Lazarus：通过自适应专家部署，实现混合专家模型的弹性与韧性训练。",
    "tags": [
      "LLM应用",
      "云计算",
      "人工智能"
    ]
  },
  {
    "title": "Entity Decomposition with Filtering: A Zero-Shot Clinical Named Entity Recognition Framework",
    "submit_datetime": "2024年07月05日",
    "abstract": "Clinical named entity recognition (NER) aims to retrieve important entities within clinical narratives. Recent works have demonstrated that large language models (LLMs) can achieve strong performance in this task. While previous works focus on proprietary LLMs, we investigate how open NER LLMs, trained specifically for entity recognition, perform in clinical NER. In this paper, we aim to improve them through a novel framework, entity decomposition with filtering, or EDF. Our key idea is to decompose the entity recognition task into several retrievals of sub-entity types. We also introduce a filtering mechanism to remove incorrect entities. Our experimental results demonstrate the efficacy of our framework across all metrics, models, datasets, and entity types. Our analysis reveals that entity decomposition can recognize previously missed entities with substantial improvement. We further provide a comprehensive evaluation of our framework and an in-depth error analysis to pave future works.",
    "pdf_link": "https://arxiv.org/abs/2407.04629",
    "graphs": [],
    "abstract_cn": "临床命名实体识别 (NER) 旨在从临床叙述中提取关键信息。最新研究表明，大型语言模型 (LLM) 在此领域表现出色。本文聚焦于开放 NER LLM，探讨其在临床 NER 中的应用。我们提出了一种创新框架——带过滤的实体分解 (EDF)，通过将任务分解为子实体类型检索，并结合过滤机制剔除错误实体，显著提升了识别准确性。实验证明，EDF 在各项评估中均表现优异。此外，我们进行了详尽的错误分析，为后续研究奠定了基础。",
    "title_cn": "实体分解结合过滤技术，开创了一种零-shot 临床命名实体识别的新框架。",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "ARM: Efficient Guided Decoding with Autoregressive Reward Models",
    "submit_datetime": "2024年07月05日",
    "abstract": "Language models trained on large amounts of data require careful tuning to be safely deployed in real world. We revisit the guided decoding paradigm, where the goal is to augment the logits of the base language model using the scores from a task-specific reward model. We propose a simple but efficient parameterization of the autoregressive reward model enabling fast and effective guided decoding. On detoxification and sentiment control tasks, we show that our efficient parameterization performs on par with RAD, a strong but less efficient guided decoding approach.",
    "pdf_link": "https://arxiv.org/abs/2407.04615",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.04615v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04615/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04615v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04615/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04615v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04615/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04615v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04615/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04615v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04615/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04615v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04615/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04615v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04615/x7.png"
      }
    ],
    "abstract_cn": "为了确保在大量数据上训练的语言模型能够安全应用于现实世界，我们需要对其进行细致的调整。我们重新探讨了引导解码的方法，旨在通过任务特定奖励模型的分数来优化基础语言模型的输出。我们设计了一种既简单又高效的自动回归奖励模型参数化方案，使得引导解码既迅速又有效。实验表明，在去毒化和情感控制等任务中，我们的方法与效率较低但功能强大的RAD方法表现不相上下。",
    "title_cn": "ARM：通过自回归奖励模型实现高效引导解码",
    "tags": [
      "LLM应用",
      "人工智能",
      "数据安全"
    ]
  },
  {
    "title": "Leveraging Large Language Models for Integrated Satellite-Aerial-Terrestrial Networks: Recent Advances and Future Directions",
    "submit_datetime": "2024年07月05日",
    "abstract": "Integrated satellite, aerial, and terrestrial networks (ISATNs) represent a sophisticated convergence of diverse communication technologies to ensure seamless connectivity across different altitudes and platforms. This paper explores the transformative potential of integrating Large Language Models (LLMs) into ISATNs, leveraging advanced Artificial Intelligence (AI) and Machine Learning (ML) capabilities to enhance these networks. We outline the current architecture of ISATNs and highlight the significant role LLMs can play in optimizing data flow, signal processing, and network management to advance 5G/6G communication technologies through advanced predictive algorithms and real-time decision-making. A comprehensive analysis of ISATN components is conducted, assessing how LLMs can effectively address traditional data transmission and processing bottlenecks. The paper delves into the network management challenges within ISATNs, emphasizing the necessity for sophisticated resource allocation strategies, traffic routing, and security management to ensure seamless connectivity and optimal performance under varying conditions. Furthermore, we examine the technical challenges and limitations associated with integrating LLMs into ISATNs, such as data integration for LLM processing, scalability issues, latency in decision-making processes, and the design of robust, fault-tolerant systems. The study also identifies key future research directions for fully harnessing LLM capabilities in ISATNs, which is crucial for enhancing network reliability, optimizing performance, and achieving a truly interconnected and intelligent global network system.",
    "pdf_link": "https://arxiv.org/abs/2407.04581",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.04581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04581/LLMmarkettrends.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04581/organization.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04581/ISATNs.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04581/ISATNsChallengesLLM2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04581/compvision.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04581/optimizationofISATNs.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04581/RL_ISATNs.png"
      }
    ],
    "abstract_cn": "集成卫星、航空和地面网络（ISATNs）通过融合多种通信技术，确保了不同高度和平台间的无缝连接。本文探讨了将大型语言模型（LLMs）融入ISATNs的变革潜力，借助先进的人工智能和机器学习技术，提升网络性能。我们概述了ISATNs的架构，并强调LLMs在优化数据流、信号处理和网络管理中的关键作用，助力5G/6G通信技术的发展。通过全面分析ISATN组件，我们评估了LLMs如何突破传统数据传输和处理的瓶颈。本文还深入探讨了ISATNs中的网络管理挑战，强调了复杂资源分配、流量路由和安全管理的必要性，以确保在各种条件下实现无缝连接和最佳性能。同时，我们考察了LLMs集成中的技术难题，如数据集成、可扩展性、决策延迟及系统健壮性和容错设计。研究还指出了未来研究方向，以充分发挥LLMs在ISATNs中的潜力，这对于提升网络可靠性、优化性能及构建真正互联智能的全球网络系统至关重要。",
    "title_cn": "大型语言模型在综合卫星-空中-地面网络中的应用：探索最新进展与未来发展方向",
    "tags": [
      "LLM应用",
      "",
      "网络管理"
    ]
  },
  {
    "title": "PoPreRo: A New Dataset for Popularity Prediction of Romanian Reddit Posts",
    "submit_datetime": "2024年07月05日",
    "abstract": "We introduce PoPreRo, the first dataset for Popularity Prediction of Romanian posts collected from Reddit. The PoPreRo dataset includes a varied compilation of post samples from five distinct subreddits of Romania, totaling 28,107 data samples. Along with our novel dataset, we introduce a set of competitive models to be used as baselines for future research. Interestingly, the top-scoring model achieves an accuracy of 61.35% and a macro F1 score of 60.60% on the test set, indicating that the popularity prediction task on PoPreRo is very challenging. Further investigations based on few-shot prompting the Falcon-7B Large Language Model also point in the same direction. We thus believe that PoPreRo is a valuable resource that can be used to evaluate models on predicting the popularity of social media posts in Romanian. We release our dataset at https://github.com/ana-rogoz/PoPreRo.",
    "pdf_link": "https://arxiv.org/abs/2407.04541",
    "graphs": [],
    "abstract_cn": "我们推出了PoPreRo，首个专注于Reddit上罗马尼亚帖子流行度预测的数据集，涵盖了五个不同子版块的28,107个样本。此外，我们还提供了一系列基准模型，供未来研究参考。测试结果显示，最佳模型的准确率达61.35%，宏观F1分数为60.60%，凸显了该任务的难度。通过少样本提示Falcon-7B大型语言模型的研究也证实了这一点。PoPreRo因此成为评估罗马尼亚社交媒体帖子流行度预测模型的重要资源，数据集已公开于https://github.com/ana-rogoz/PoPreRo。",
    "title_cn": "PoPreRo：一款专为预测罗马尼亚 Reddit 帖子热度而设计的新数据集",
    "tags": [
      "LLM应用",
      "社交媒体",
      "数据分析"
    ]
  },
  {
    "title": "Dude: Dual Distribution-Aware Context Prompt Learning For Large Vision-Language Model",
    "submit_datetime": "2024年07月05日",
    "abstract": "Prompt learning methods are gaining increasing attention due to their ability to customize large vision-language models to new domains using pre-trained contextual knowledge and minimal training data. However, existing works typically rely on optimizing unified prompt inputs, often struggling with fine-grained classification tasks due to insufficient discriminative attributes. To tackle this, we consider a new framework based on a dual context of both domain-shared and class-specific contexts, where the latter is generated by Large Language Models (LLMs) such as GPTs. Such dual prompt methods enhance the model's feature representation by joining implicit and explicit factors encoded in LLM knowledge. Moreover, we formulate the Unbalanced Optimal Transport (UOT) theory to quantify the relationships between constructed prompts and visual tokens. Through partial matching, UOT can properly align discrete sets of visual tokens and prompt embeddings under different mass distributions, which is particularly valuable for handling irrelevant or noisy elements, ensuring that the preservation of mass does not restrict transport solutions. Furthermore, UOT's characteristics integrate seamlessly with image augmentation, expanding the training sample pool while maintaining a reasonable distance between perturbed images and prompt inputs. Extensive experiments across few-shot classification and adapter settings substantiate the superiority of our model over current state-of-the-art baselines.",
    "pdf_link": "https://arxiv.org/abs/2407.04489",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.04489v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04489/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04489v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04489/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04489v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04489/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04489v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04489/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04489v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04489/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04489v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04489/x6.png"
      }
    ],
    "abstract_cn": "提示学习方法因其灵活性而备受瞩目，它利用预训练知识和小量数据就能将大型视觉-语言模型适应新领域。然而，现有方法在细粒度分类上常因识别属性不足而受限。为此，我们提出一个双重上下文框架，结合通用与特定类别的上下文，后者由GPT等LLM生成，以提升特征表达。我们还引入非平衡最优传输（UOT）理论，量化提示与视觉标记的关联，通过部分匹配优化对齐，有效处理噪声，并确保传输灵活性。UOT与图像增强结合，扩大样本池，同时保持输入间的合理距离。实验证明，我们的模型在少样本分类等任务中超越了现有顶尖技术。",
    "title_cn": "Dude：一种双分布感知上下文提示学习方法，专为大型视觉-语言模型设计。",
    "tags": [
      "LLM应用",
      "计算机视觉",
      "机器学习"
    ]
  },
  {
    "title": "Leveraging Graph Structures to Detect Hallucinations in Large Language Models",
    "submit_datetime": "2024年07月05日",
    "abstract": "Large language models are extensively applied across a wide range of tasks, such as customer support, content creation, educational tutoring, and providing financial guidance. However, a well-known drawback is their predisposition to generate hallucinations. This damages the trustworthiness of the information these models provide, impacting decision-making and user confidence. We propose a method to detect hallucinations by looking at the structure of the latent space and finding associations within hallucinated and non-hallucinated generations. We create a graph structure that connects generations that lie closely in the embedding space. Moreover, we employ a Graph Attention Network which utilizes message passing to aggregate information from neighboring nodes and assigns varying degrees of importance to each neighbor based on their relevance. Our findings show that 1) there exists a structure in the latent space that differentiates between hallucinated and non-hallucinated generations, 2) Graph Attention Networks can learn this structure and generalize it to unseen generations, and 3) the robustness of our method is enhanced when incorporating contrastive learning. When evaluated against evidence-based benchmarks, our model performs similarly without access to search-based methods.",
    "pdf_link": "https://arxiv.org/abs/2407.04485",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.04485v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04485/data_generation.png"
      }
    ],
    "abstract_cn": "大型语言模型在多个领域大显身手，如客户服务、内容创作、教育辅导和财务指导。但它们有个顽疾——容易产生“幻觉”，这严重影响了信息的可靠性，进而动摇了用户的信任和决策。为此，我们研发了一种新方法，通过分析潜在空间的结构，识别幻觉与真实生成之间的关联。我们构建了一个图结构，将嵌入空间中相近的生成内容相连。同时，我们运用图注意力网络，通过消息传递机制整合邻近节点的信息，并根据相关性赋予不同节点不同的权重。研究显示：1) 潜在空间中确实存在区分幻觉与真实生成的结构；2) 图注意力网络能学习并泛化这一结构至新内容；3) 结合对比学习能进一步提升方法的稳健性。在基于证据的测试中，即便不依赖搜索方法，我们的模型表现依旧出色。",
    "title_cn": "借助图结构，我们能够精准检测大型语言模型中的幻觉现象。",
    "tags": [
      "LLM应用",
      "客户服务",
      ""
    ]
  },
  {
    "title": "Controlling Whisper: Universal Acoustic Adversarial Attacks to Control Speech Foundation Models",
    "submit_datetime": "2024年07月05日",
    "abstract": "Speech enabled foundation models, either in the form of flexible speech recognition based systems or audio-prompted large language models (LLMs), are becoming increasingly popular. One of the interesting aspects of these models is their ability to perform tasks other than automatic speech recognition (ASR) using an appropriate prompt. For example, the OpenAI Whisper model can perform both speech transcription and speech translation. With the development of audio-prompted LLMs there is the potential for even greater control options. In this work we demonstrate that with this greater flexibility the systems can be susceptible to model-control adversarial attacks. Without any access to the model prompt it is possible to modify the behaviour of the system by appropriately changing the audio input. To illustrate this risk, we demonstrate that it is possible to prepend a short universal adversarial acoustic segment to any input speech signal to override the prompt setting of an ASR foundation model. Specifically, we successfully use a universal adversarial acoustic segment to control Whisper to always perform speech translation, despite being set to perform speech transcription. Overall, this work demonstrates a new form of adversarial attack on multi-tasking speech enabled foundation models that needs to be considered prior to the deployment of this form of model.",
    "pdf_link": "https://arxiv.org/abs/2407.04482",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.04482v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04482/main_figure.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04482v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04482/bleu_vs_en_probability_fr.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04482v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04482/bleu_vs_not_en_probability_fr.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04482v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04482/p_en.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04482v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04482/bleu_vs_en_probability_all.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04482v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04482/bleu_vs_not_en_probability_all.png"
      }
    ],
    "abstract_cn": "语音基础模型，无论是灵活的语音识别系统还是音频提示的大型语言模型（LLM），正日益流行。这些模型的独特之处在于，它们能通过适当提示执行自动语音识别（ASR）之外的任务，如OpenAI的Whisper模型既能转录音频也能翻译语音。随着音频提示LLM的发展，我们有望获得更多控制选项。然而，本研究揭示了这种灵活性可能使系统易受模型控制对抗攻击的影响。即使不接触模型提示，通过调整音频输入，也能改变系统行为。我们通过实验证明，只需在任何语音信号前添加一个短的通用对抗声学段，就能覆盖ASR基础模型的提示设置，例如让Whisper无视设定，始终执行语音翻译。这项研究揭示了多任务语音基础模型面临的新型对抗攻击，提醒我们在部署此类模型前需谨慎考虑。",
    "title_cn": "操控“耳语”：针对语音基础模型的通用声学对抗策略",
    "tags": [
      "LLM应用",
      "",
      "语音识别"
    ]
  },
  {
    "title": "LoCo: Low-Bit Communication Adaptor for Large-scale Model Training",
    "submit_datetime": "2024年07月05日",
    "abstract": "To efficiently train large-scale models, low-bit gradient communication compresses full-precision gradients on local GPU nodes into low-precision ones for higher gradient synchronization efficiency among GPU nodes. However, it often degrades training quality due to compression information loss. To address this, we propose the Low-bit Communication Adaptor (LoCo), which compensates gradients on local GPU nodes before compression, ensuring efficient synchronization without compromising training quality. Specifically, LoCo designs a moving average of historical compensation errors to stably estimate concurrent compression error and then adopts it to compensate for the concurrent gradient compression, yielding a less lossless compression. This mechanism allows it to be compatible with general optimizers like Adam and sharding strategies like FSDP. Theoretical analysis shows that integrating LoCo into full-precision optimizers like Adam and SGD does not impair their convergence speed on nonconvex problems. Experimental results show that across large-scale model training frameworks like Megatron-LM and PyTorch's FSDP, LoCo significantly improves communication efficiency, e.g., improving Adam's training speed by 14% to 40% without performance degradation on large language models like LLAMAs and MoE.",
    "pdf_link": "https://arxiv.org/abs/2407.04480",
    "graphs": [],
    "abstract_cn": "为了提升大规模模型的训练效率，我们引入了低比特通信适配器（LoCo），通过在压缩前补偿本地GPU节点的梯度，确保高效的梯度同步且不牺牲训练质量。LoCo利用历史补偿误差的移动平均值来稳定估计并补偿当前梯度压缩，实现了更优的压缩效果。这一创新机制不仅与通用优化器和分片策略兼容，还通过理论分析证实了其对优化器收敛速度的正面影响。实验证明，LoCo在大规模模型训练中显著提升了通信效率，例如，在不影响性能的前提下，将Adam的训练速度提升了14%至40%。",
    "title_cn": "LoCo：专为大规模模型训练设计的低比特通信适配器",
    "tags": [
      "LLM理论",
      "计算机科学",
      "人工智能"
    ]
  },
  {
    "title": "Generalists vs. Specialists: Evaluating Large Language Models for Urdu",
    "submit_datetime": "2024年07月05日",
    "abstract": "In this paper, we compare general-purpose pretrained models, GPT-4-Turbo and Llama-3-8b-Instruct with special-purpose models fine-tuned on specific tasks, XLM-Roberta-large, mT5-large, and Llama-3-8b-Instruct. We focus on seven classification and six generation tasks to evaluate the performance of these models on Urdu language. Urdu has 70 million native speakers, yet it remains underrepresented in Natural Language Processing (NLP). Despite the frequent advancements in Large Language Models (LLMs), their performance in low-resource languages, including Urdu, still needs to be explored. We also conduct a human evaluation for the generation tasks and compare the results with the evaluations performed by GPT-4-Turbo and Llama-3-8b-Instruct. We find that special-purpose models consistently outperform general-purpose models across various tasks. We also find that the evaluation done by GPT-4-Turbo for generation tasks aligns more closely with human evaluation compared to the evaluation by Llama-3-8b-Instruct. This paper contributes to the NLP community by providing insights into the effectiveness of general and specific-purpose LLMs for low-resource languages.",
    "pdf_link": "https://arxiv.org/abs/2407.04459",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.04459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04459/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04459/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04459/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04459/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04459/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04459/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04459/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04459/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04459/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04459/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04459/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04459/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04459/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04459/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04459/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04459/x16.png"
      }
    ],
    "abstract_cn": "本文对比了通用预训练模型 GPT-4-Turbo 和 Llama-3-8b-Instruct，以及针对特定任务微调的专用模型 XLM-Roberta-large、mT5-large 和 Llama-3-8b-Instruct，在乌尔都语的七项分类和六项生成任务上的表现。乌尔都语虽有 7000 万母语者，但在 NLP 领域仍显不足。尽管 LLMs 不断进步，其在低资源语言如乌尔都语的表现仍待探索。我们还进行了生成任务的人工评估，并与 GPT-4-Turbo 和 Llama-3-8b-Instruct 的评估结果对比。结果显示，专用模型在各任务中表现更佳，且 GPT-4-Turbo 的生成任务评估更贴近人工评估。本文通过探讨通用与专用 LLMs 对低资源语言的有效性，为 NLP 社区提供了宝贵见解。",
    "title_cn": "通用型与专家型：探究大型语言模型在乌尔都语领域的评估",
    "tags": [
      "LLM应用",
      "",
      "机器学习"
    ]
  },
  {
    "title": "XLSR-Transducer: Streaming ASR for Self-Supervised Pretrained Models",
    "submit_datetime": "2024年07月05日",
    "abstract": "Self-supervised pretrained models exhibit competitive performance in automatic speech recognition on finetuning, even with limited in-domain supervised data for training. However, popular pretrained models are not suitable for streaming ASR because they are trained with full attention context. In this paper, we introduce XLSR-Transducer, where the XLSR-53 model is used as encoder in transducer setup. Our experiments on the AMI dataset reveal that the XLSR-Transducer achieves 4% absolute WER improvement over Whisper large-v2 and 8% over a Zipformer transducer model trained from scratch.To enable streaming capabilities, we investigate different attention masking patterns in the self-attention computation of transformer layers within the XLSR-53 model. We validate XLSR-Transducer on AMI and 5 languages from CommonVoice under low-resource scenarios. Finally, with the introduction of attention sinks, we reduce the left context by half while achieving a relative 12% improvement in WER.",
    "pdf_link": "https://arxiv.org/abs/2407.04439",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.04439v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04439/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04439v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04439/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04439v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04439/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04439v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04439/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04439v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04439/x5.png"
      }
    ],
    "abstract_cn": "自监督预训练模型在自动语音识别的微调中表现出色，即便训练数据有限。但这些流行的预训练模型因采用全注意力上下文训练而不适用于流式ASR。本文中，我们提出了XLSR-Transducer，利用XLSR-53模型作为转录器编码器。实验显示，XLSR-Transducer在AMI数据集上分别比Whisper large-v2和从头训练的Zipformer转录器模型提升了4%和8%的WER。为实现流式处理，我们探索了XLSR-53模型变换器层中不同的注意力掩蔽模式。在低资源环境下，XLSR-Transducer在AMI及CommonVoice的五种语言上表现优异。通过引入注意力汇聚点，我们不仅将左上下文减半，还实现了WER相对提升12%。",
    "title_cn": "XLSR-Transducer：为自监督预训练模型设计的流式自动语音识别技术",
    "tags": [
      "LLM应用",
      "语音识别",
      "人工智能"
    ]
  },
  {
    "title": "From 'Showgirls' to 'Performers': Fine-tuning with Gender-inclusive Language for Bias Reduction in LLMs",
    "submit_datetime": "2024年07月05日",
    "abstract": "Gender bias is not only prevalent in Large Language Models (LLMs) and their training data, but also firmly ingrained into the structural aspects of language itself. Therefore, adapting linguistic structures within LLM training data to promote gender-inclusivity can make gender representations within the model more inclusive. The focus of our work are gender-exclusive affixes in English, such as in 'show-girl' or 'man-cave', which can perpetuate gender stereotypes and binary conceptions of gender. We use an LLM training dataset to compile a catalogue of 692 gender-exclusive terms along with gender-neutral variants and from this, develop a gender-inclusive fine-tuning dataset, the 'Tiny Heap'. Fine-tuning three different LLMs with this dataset, we observe an overall reduction in gender-stereotyping tendencies across the models. Our approach provides a practical method for enhancing gender inclusivity in LLM training data and contributes to incorporating queer-feminist linguistic activism in bias mitigation research in NLP.",
    "pdf_link": "https://arxiv.org/abs/2407.04434",
    "graphs": [],
    "abstract_cn": "性别偏见不仅在大型语言模型（LLM）及其训练数据中普遍存在，还深植于语言结构之中。为此，我们专注于调整LLM训练数据中的语言结构，以促进性别包容性，使模型中的性别表示更加多元。我们特别关注英语中的性别排他性词缀，如'show-girl'或'man-cave'，这些词缀可能强化性别刻板印象和二元性别观念。通过编制一个包含692个性别排他性词汇及其性别中性变体的目录，我们开发了名为'Tiny Heap'的性别包容性微调数据集。使用此数据集对三个不同LLM进行微调后，我们发现模型中的性别刻板印象有所减少。这一方法不仅为提升LLM训练数据的性别包容性提供了实用途径，还为在NLP偏见缓解研究中融入酷儿女性主义语言行动主义做出了贡献。",
    "title_cn": "从“Showgirls”到“Performers”：通过性别包容性语言的微调，减少 LLMs 中的偏见",
    "tags": [
      "LLM应用",
      "人工智能",
      "性别研究"
    ]
  },
  {
    "title": "cosmosage: A Natural-Language Assistant for Cosmologists",
    "submit_datetime": "2024年07月05日",
    "abstract": "cosmosage is a natural-language assistant intended for a wide audience, from laypersons interested in cosmology to students, teachers, and professional cosmologists. cosmosage provides a novel way to access knowledge and reason about cosmology. Leveraging the power of advanced large language models (LLMs), cosmosage has learned from a vast corpus of open-access source texts, including textbooks and papers. cosmosage is found to be state-of-the-art on the narrow task of answering questions about cosmology, outperforming all general-purpose models. The model parameters and code are publicly available.",
    "pdf_link": "https://arxiv.org/abs/2407.04420",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.04420v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04420/x1.png"
      }
    ],
    "abstract_cn": "cosmosage，一款面向各层次用户的自然语言助手，从宇宙学爱好者到专业人士，都提供了独特的知识获取与推理途径。借助强大的大型语言模型，它从众多开放资源中汲取智慧，涵盖教科书与学术论文。在解答宇宙学问题方面，cosmosage 表现卓越，超越了其他通用模型，其模型参数与代码均已公开。",
    "title_cn": "cosmosage：专为宇宙学家打造的自然语言助手",
    "tags": [
      "LLM应用",
      "宇宙学",
      ""
    ]
  },
  {
    "title": "Improving Audio Generation with Visual Enhanced Caption",
    "submit_datetime": "2024年07月05日",
    "abstract": "Generative models have shown significant achievements in audio generation tasks. However, existing models struggle with complex and detailed prompts, leading to potential performance degradation. We hypothesize that this problem stems from the low quality and relatively small quantity of training data. In this work, we aim to create a large-scale audio dataset with rich captions for improving audio generation models. We develop an automated pipeline to generate detailed captions for audio-visual datasets by transforming predicted visual captions, audio captions, and tagging labels into comprehensive descriptions using a Large Language Model (LLM). We introduce Sound-VECaps, a dataset comprising 1.66M high-quality audio-caption pairs with enriched details including audio event orders, occurred places and environment information. We demonstrate that training with Sound-VECaps significantly enhances the capability of text-to-audio generation models to comprehend and generate audio from complex input prompts, improving overall system performance. Furthermore, we conduct ablation studies of Sound-VECaps across several audio-language tasks, suggesting its potential in advancing audio-text representation learning. Our dataset and models are available online.",
    "pdf_link": "https://arxiv.org/abs/2407.04416",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.04416v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04416/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04416v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04416/x2.png"
      }
    ],
    "abstract_cn": "生成模型在音频生成领域取得了显著进展，但在处理复杂细节时仍显不足。我们认为，这主要归咎于训练数据的质与量。为此，我们构建了一个大规模音频数据集，配备详尽描述，旨在提升模型性能。通过自动化流程，我们利用大型语言模型将视觉、音频描述及标签转化为全面描述，创造了Sound-VECaps数据集，包含166万对高质量音频描述，涵盖事件顺序、地点及环境等丰富信息。实验表明，该数据集能显著增强模型对复杂输入的理解与生成能力，提升整体性能。此外，消融研究显示其在音频-文本学习领域的广阔前景。相关资源已在线开放。",
    "title_cn": "利用视觉增强字幕提升音频生成效果",
    "tags": [
      "LLM应用",
      "音频处理",
      "数据集构建"
    ]
  },
  {
    "title": "Waterfall: Framework for Robust and Scalable Text Watermarking",
    "submit_datetime": "2024年07月05日",
    "abstract": "Protecting intellectual property (IP) of text such as articles and code is increasingly important, especially as sophisticated attacks become possible, such as paraphrasing by large language models (LLMs) or even unauthorized training of LLMs on copyrighted text to infringe such IP. However, existing text watermarking methods are not robust enough against such attacks nor scalable to millions of users for practical implementation. In this paper, we propose Waterfall, the first training-free framework for robust and scalable text watermarking applicable across multiple text types (e.g., articles, code) and languages supportable by LLMs, for general text and LLM data provenance. Waterfall comprises several key innovations, such as being the first to use LLM as paraphrasers for watermarking along with a novel combination of techniques that are surprisingly effective in achieving robust verifiability and scalability. We empirically demonstrate that Waterfall achieves significantly better scalability, robust verifiability, and computational efficiency compared to SOTA article-text watermarking methods, and also showed how it could be directly applied to the watermarking of code.",
    "pdf_link": "https://arxiv.org/abs/2407.04411",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.04411v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04411/prob_formulation_hor_2.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.04411v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04411/Toy_perm_3.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.04411v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04411/framework_numbered_emnlp.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04411v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04411/verification_numbered_emnlp.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04411v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04411/ids.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04411v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04411/empirical_illustration_T_o_T_w.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04411v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04411/empirical_illustration_T_w_T_w.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04411v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04411/word_len.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04411v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04411/token_len.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04411v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04411/ROC_freq_1,2,3_seed0.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04411v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04411/ROC_freq_1,2,3_seed1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04411v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04411/ROC_freq_1,2,3_seed2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04411v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04411/un_watermarked_token_len_seed0_freq1_delta6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04411v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04411/STS_AUROC_normalized_freq1_2_3_5_7_8000_16000_seed0_mpnet.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04411v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04411/STS_AUROC_normalized_freq1_2_3_5_7_8000_16000_seed1_mpnet.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04411v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04411/STS_AUROC_normalized_freq1_2_3_5_7_8000_16000_seed2_mpnet.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04411v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04411/scalability_comparison_seed0_1000_ids.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04411v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04411/scalability_100k_ids.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04411v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04411/scalability_seed0_T_w_1000_ids.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04411v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04411/overlap_com_pnlw_mbit_auc.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04411v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04411/phind_auc_curve.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04411v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04411/phind_mbjsp_rf.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04411v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04411/phind_mbjsp_auroc_pass10_new.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04411v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04411/wat_code_example.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04411v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04411/WTF_q_vs_KGW_z_old_2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04411v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04411/STS_AUROC_normalized_freq1_seed0_mpnet_diff_models.png"
      }
    ],
    "abstract_cn": "随着复杂攻击手段的出现，如利用大型语言模型（LLM）进行文本改述或未经授权训练LLM侵犯版权，保护文章和代码等文本的知识产权变得尤为关键。然而，现有文本水印技术在抵御这些攻击和扩展至大规模用户方面存在不足。为此，我们推出了Waterfall，首个无需训练的强大且可扩展的文本水印框架，支持多种文本类型和语言。Waterfall的创新之处在于利用LLM进行水印处理，并巧妙结合多项技术，有效提升可验证性和可扩展性。实证研究表明，Waterfall在可扩展性、可验证性和计算效率上均优于现有技术，并可直接应用于代码水印。",
    "title_cn": "Waterfall：一个专为文本水印设计的稳健且可扩展的框架",
    "tags": [
      "LLM应用",
      "知识产权保护",
      "网络安全"
    ]
  },
  {
    "title": "Towards Context-aware Support for Color Vision Deficiency: An Approach Integrating LLM and AR",
    "submit_datetime": "2024年07月05日",
    "abstract": "People with color vision deficiency often face challenges in distinguishing colors such as red and green, which can complicate daily tasks and require the use of assistive tools or environmental adjustments. Current support tools mainly focus on presentation-based aids, like the color vision modes found in iPhone accessibility settings. However, offering context-aware support, like indicating the doneness of meat, remains a challenge since task-specific solutions are not cost-effective for all possible scenarios. To address this, our paper proposes an application that provides contextual and autonomous assistance. This application is mainly composed of: (i) an augmented reality interface that efficiently captures context; and (ii) a multi-modal large language model-based reasoner that serves to cognitize the context and then reason about the appropriate support contents. Preliminary user experiments with two color vision deficient users across five different scenarios have demonstrated the effectiveness and universality of our application.",
    "pdf_link": "https://arxiv.org/abs/2407.04362",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.04362v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04362/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04362v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04362/demo.png"
      }
    ],
    "abstract_cn": "色觉缺陷者在区分红绿等颜色时常常遇到困难，这使得日常任务变得复杂，需要借助辅助工具或调整环境。目前，辅助工具多聚焦于呈现层面的帮助，例如iPhone的色觉模式。然而，提供情境感知支持，如判断肉类熟度，仍是一大挑战，因为特定任务的解决方案难以覆盖所有场景。为此，我们提出了一款结合增强现实界面和多模态大型语言模型推理器的应用程序，旨在提供情境感知和自主辅助。初步实验显示，该应用在多种场景下均表现出色，有效辅助了色觉缺陷者的日常生活。",
    "title_cn": "探索色觉缺陷的上下文感知支持：融合 LLM 与 AR 的创新途径",
    "tags": [
      "LLM应用",
      "",
      "辅助技术"
    ]
  },
  {
    "title": "Crafting Large Language Models for Enhanced Interpretability",
    "submit_datetime": "2024年07月05日",
    "abstract": "We introduce the Concept Bottleneck Large Language Model (CB-LLM), a pioneering approach to creating inherently interpretable Large Language Models (LLMs). Unlike traditional black-box LLMs that rely on post-hoc interpretation methods with limited neuron function insights, CB-LLM sets a new standard with its built-in interpretability, scalability, and ability to provide clear, accurate explanations. This innovation not only advances transparency in language models but also enhances their effectiveness. Our unique Automatic Concept Correction (ACC) strategy successfully narrows the performance gap with conventional black-box LLMs, positioning CB-LLM as a model that combines the high accuracy of traditional LLMs with the added benefit of clear interpretability -- a feature markedly absent in existing LLMs.",
    "pdf_link": "https://arxiv.org/abs/2407.04307",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.04307v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04307/cbllm.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.04307v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04307/sentence_embedding.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04307v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04307/task2.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.04307v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04307/intervention.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.04307v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04307/sparsity.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.04307v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04307/unlearning.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.04307v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04307/task1_screen.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04307v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04307/task2_screen.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04307v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04307/vanilla.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.04307v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04307/unlearning_2.jpg"
      }
    ],
    "abstract_cn": "我们推出了概念瓶颈大型语言模型 (CB-LLM)，这是一种创新方法，旨在构建本质上可解释的 LLM。与依赖后验解释的传统黑箱模型不同，CB-LLM 通过内置的可解释性、可扩展性和提供清晰准确解释的能力，树立了新标杆。这一创新不仅提升了语言模型的透明度，还增强了其效能。我们的自动概念校正 (ACC) 策略有效缩小了与传统黑箱模型的性能差距，使 CB-LLM 成为兼具高准确性和清晰可解释性的模型，这是现有 LLM 所缺乏的显著特点。",
    "title_cn": "精雕细琢，打造更具透明度的大型语言模型",
    "tags": [
      "LLM理论",
      "人工智能",
      "语言模型"
    ]
  },
  {
    "title": "Jailbreak Attacks and Defenses Against Large Language Models: A Survey",
    "submit_datetime": "2024年07月05日",
    "abstract": "Large Language Models (LLMs) have performed exceptionally in various text-generative tasks, including question answering, translation, code completion, etc. However, the over-assistance of LLMs has raised the challenge of \"jailbreaking\", which induces the model to generate malicious responses against the usage policy and society by designing adversarial prompts. With the emergence of jailbreak attack methods exploiting different vulnerabilities in LLMs, the corresponding safety alignment measures are also evolving. In this paper, we propose a comprehensive and detailed taxonomy of jailbreak attack and defense methods. For instance, the attack methods are divided into black-box and white-box attacks based on the transparency of the target model. Meanwhile, we classify defense methods into prompt-level and model-level defenses. Additionally, we further subdivide these attack and defense methods into distinct sub-classes and present a coherent diagram illustrating their relationships. We also conduct an investigation into the current evaluation methods and compare them from different perspectives. Our findings aim to inspire future research and practical implementations in safeguarding LLMs against adversarial attacks. Above all, although jailbreak remains a significant concern within the community, we believe that our work enhances the understanding of this domain and provides a foundation for developing more secure LLMs.",
    "pdf_link": "https://arxiv.org/abs/2407.04295",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.04295v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04295/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04295v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04295/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04295v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04295/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04295v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04295/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04295v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04295/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04295v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04295/x6.png"
      }
    ],
    "abstract_cn": "大型语言模型在多项文本生成任务中表现卓越，但过度辅助也带来了“越狱”风险，即通过对抗性提示诱导模型产生违规的恶意回应。随着越狱攻击手段的多样化，安全防护措施也在不断进化。本文中，我们详尽地分类了越狱攻击与防御策略，如根据模型透明度划分的黑盒与白盒攻击，以及提示级与模型级的防御措施。我们进一步细分这些策略，并通过图表清晰展示其关联。此外，我们还审视了现有的评估方法，并进行了多角度比较。我们的研究旨在启发未来在提升 LLM 安全性方面的探索与实践。尽管越狱问题仍备受关注，我们相信本研究深化了对此领域的认识，并为构建更安全的语言模型奠定了基础。",
    "title_cn": "大型语言模型面临的越狱攻击及其防御策略：全面调查",
    "tags": [
      "LLM理论",
      "网络安全",
      "人工智能"
    ]
  },
  {
    "title": "Corki: Enabling Real-time Embodied AI Robots via Algorithm-Architecture Co-Design",
    "submit_datetime": "2024年07月05日",
    "abstract": "Embodied AI robots have the potential to fundamentally improve the way human beings live and manufacture. Continued progress in the burgeoning field of using large language models to control robots depends critically on an efficient computing substrate. In particular, today's computing systems for embodied AI robots are designed purely based on the interest of algorithm developers, where robot actions are divided into a discrete frame-basis. Such an execution pipeline creates high latency and energy consumption. This paper proposes Corki, an algorithm-architecture co-design framework for real-time embodied AI robot control. Our idea is to decouple LLM inference, robotic control and data communication in the embodied AI robots compute pipeline. Instead of predicting action for one single frame, Corki predicts the trajectory for the near future to reduce the frequency of LLM inference. The algorithm is coupled with a hardware that accelerates transforming trajectory into actual torque signals used to control robots and an execution pipeline that parallels data communication with computation. Corki largely reduces LLM inference frequency by up to 8.0x, resulting in up to 3.6x speed up. The success rate improvement can be up to 17.3%. Code is provided for re-implementation. https://github.com/hyy0613/Corki",
    "pdf_link": "https://arxiv.org/abs/2407.04292",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.04292v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04292/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04292v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04292/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04292v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04292/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04292v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04292/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04292v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04292/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04292v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04292/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04292v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04292/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04292v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04292/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04292v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04292/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04292v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04292/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04292v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04292/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04292v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04292/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04292v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04292/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04292v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04292/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04292v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04292/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04292v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04292/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04292v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04292/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04292v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04292/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04292v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04292/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04292v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04292/x20.png"
      }
    ],
    "abstract_cn": "具身AI机器人有望彻底改变人类的生活与制造方式。在利用大型语言模型控制机器人的前沿领域，高效计算基底是持续进步的关键。当前的计算系统仅考虑算法开发者需求，将机器人动作分割为离散帧，导致高延迟和高能耗。为此，我们提出Corki框架，通过解耦LLM推理、机器人控制和数据通信，优化具身AI机器人的实时控制。Corki预测未来轨迹而非单帧动作，大幅降低LLM推理频率，最高可达8倍，速度提升3.6倍，成功率提高17.3%。代码已公开，便于复现。https://github.com/hyy0613/Corki",
    "title_cn": "Corki：借助算法与架构的协同设计，赋能实时具身AI机器人。",
    "tags": [
      "LLM应用",
      "机器人",
      "制造业"
    ]
  },
  {
    "title": "BiosERC: Integrating Biography Speakers Supported by LLMs for ERC Tasks",
    "submit_datetime": "2024年07月05日",
    "abstract": "In the Emotion Recognition in Conversation task, recent investigations have utilized attention mechanisms exploring relationships among utterances from intra- and inter-speakers for modeling emotional interaction between them. However, attributes such as speaker personality traits remain unexplored and present challenges in terms of their applicability to other tasks or compatibility with diverse model architectures. Therefore, this work introduces a novel framework named BiosERC, which investigates speaker characteristics in a conversation. By employing Large Language Models (LLMs), we extract the \"biographical information\" of the speaker within a conversation as supplementary knowledge injected into the model to classify emotional labels for each utterance. Our proposed method achieved state-of-the-art (SOTA) results on three famous benchmark datasets: IEMOCAP, MELD, and EmoryNLP, demonstrating the effectiveness and generalization of our model and showcasing its potential for adaptation to various conversation analysis tasks. Our source code is available at https://github.com/yingjie7/BiosERC.",
    "pdf_link": "https://arxiv.org/abs/2407.04279",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.04279v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04279/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04279v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04279/x2.png"
      }
    ],
    "abstract_cn": "在对话情感识别领域，最新研究通过注意力机制深入剖析了说话者间及内部的语句关系，以捕捉情感交流。然而，说话者的个性特质等要素尚未得到充分挖掘，且在跨任务应用和模型架构兼容性方面面临挑战。为此，我们推出了BiosERC框架，专注于对话中的说话者特征研究。借助大型语言模型，我们提取对话中的说话者“传记信息”，将其作为辅助知识融入模型，以精准分类语句情感。该方法在IEMOCAP、MELD和EmoryNLP三大权威数据集上创下佳绩，彰显了模型的卓越性能与广泛适用性，预示着其在多样对话分析任务中的广阔前景。源代码已公开，详见https://github.com/yingjie7/BiosERC。",
    "title_cn": "BiosERC：结合 LLM 辅助的传记演讲者，提升 ERC 任务表现",
    "tags": [
      "LLM应用",
      "情感分析",
      "对话系统"
    ]
  },
  {
    "title": "MMSci: A Multimodal Multi-Discipline Dataset for PhD-Level Scientific Comprehension",
    "submit_datetime": "2024年07月05日",
    "abstract": "The rapid advancement of Large Language Models (LLMs) and Large Multimodal Models (LMMs) has heightened the demand for AI-based scientific assistants capable of understanding scientific articles and figures. Despite progress, there remains a significant gap in evaluating models' comprehension of professional, graduate-level, and even PhD-level scientific content. Current datasets and benchmarks primarily focus on relatively simple scientific tasks and figures, lacking comprehensive assessments across diverse advanced scientific disciplines. To bridge this gap, we collected a multimodal, multidisciplinary dataset from open-access scientific articles published in Nature Communications journals. This dataset spans 72 scientific disciplines, ensuring both diversity and quality. We created benchmarks with various tasks and settings to comprehensively evaluate LMMs' capabilities in understanding scientific figures and content. Our evaluation revealed that these tasks are highly challenging: many open-source models struggled significantly, and even GPT-4V and GPT-4o faced difficulties. We also explored using our dataset as training resources by constructing visual instruction-following data, enabling the 7B LLaVA model to achieve performance comparable to GPT-4V/o on our benchmark. Additionally, we investigated the use of our interleaved article texts and figure images for pre-training LMMs, resulting in improvements on the material generation task. The source dataset, including articles, figures, constructed benchmarks, and visual instruction-following data, is open-sourced.",
    "pdf_link": "https://arxiv.org/abs/2407.04903",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.04903v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04903/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04903v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04903/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04903v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04903/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04903v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04903/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04903v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04903/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04903v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04903/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04903v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04903/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04903v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04903/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04903v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04903/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04903v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04903/x11.png"
      }
    ],
    "abstract_cn": "随着大型语言模型（LLM）和大型多模态模型（LMM）的迅猛发展，市场对能够深入理解科学文献和图表的AI助手需求日益增长。然而，在评估模型对高难度科学内容的理解能力方面，现有数据集和基准仍显不足。为此，我们从《自然通讯》期刊中精选了一个跨72个学科的多模态数据集，旨在全面评估LMM在科学领域的应用能力。我们的研究发现，这些任务难度极大，众多开源模型表现不佳，GPT-4V和GPT-4o也遭遇挑战。此外，我们利用该数据集进行模型训练，成功提升了7B LLaVA模型在特定任务上的表现，并探索了预训练方法以进一步优化模型性能。所有相关资源，包括文章、图表、基准测试和训练数据，均已公开，以促进科学AI领域的发展。",
    "title_cn": "MMSci：专为博士级科学理解设计的多模态多学科数据集",
    "tags": [
      "LLM应用",
      "科学研究",
      "人工智能"
    ]
  },
  {
    "title": "MJ-Bench: Is Your Multimodal Reward Model Really a Good Judge for Text-to-Image Generation?",
    "submit_datetime": "2024年07月05日",
    "abstract": "While text-to-image models like DALLE-3 and Stable Diffusion are rapidly proliferating, they often encounter challenges such as hallucination, bias, and the production of unsafe, low-quality output. To effectively address these issues, it is crucial to align these models with desired behaviors based on feedback from a multimodal judge. Despite their significance, current multimodal judges frequently undergo inadequate evaluation of their capabilities and limitations, potentially leading to misalignment and unsafe fine-tuning outcomes. To address this issue, we introduce MJ-Bench, a novel benchmark which incorporates a comprehensive preference dataset to evaluate multimodal judges in providing feedback for image generation models across four key perspectives: alignment, safety, image quality, and bias. Specifically, we evaluate a large variety of multimodal judges including smaller-sized CLIP-based scoring models, open-source VLMs (e.g. LLaVA family), and close-source VLMs (e.g. GPT-4o, Claude 3) on each decomposed subcategory of our preference dataset. Experiments reveal that close-source VLMs generally provide better feedback, with GPT-4o outperforming other judges in average. Compared with open-source VLMs, smaller-sized scoring models can provide better feedback regarding text-image alignment and image quality, while VLMs provide more accurate feedback regarding safety and generation bias due to their stronger reasoning capabilities. Further studies in feedback scale reveal that VLM judges can generally provide more accurate and stable feedback in natural language (Likert-scale) than numerical scales. Notably, human evaluations on end-to-end fine-tuned models using separate feedback from these multimodal judges provide similar conclusions, further confirming the effectiveness of MJ-Bench. All data, code, models are available at https://huggingface.co/MJ-Bench.",
    "pdf_link": "https://arxiv.org/abs/2407.04842",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.04842v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04842/show.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04842v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04842/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04842v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04842/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04842v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04842/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04842v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04842/prompt_toxicity_distribution.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04842v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04842/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04842v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04842/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04842v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04842/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04842v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04842/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04842v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04842/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04842v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04842/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04842v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04842/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04842v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04842/alignment_ui.jpg"
      }
    ],
    "abstract_cn": "随着DALLE-3和Stable Diffusion等文本到图像模型的快速增长，它们面临的幻觉、偏见和低质量输出问题日益凸显。为应对这些挑战，根据多模态反馈调整模型行为显得尤为关键。然而，现有多模态判断的评估往往不足，可能导致调整失误和安全风险。为此，我们推出了MJ-Bench基准，通过全面的首选项数据集，从对齐、安全、图像质量和偏见四个维度评估多模态判断的反馈质量。实验显示，闭源VLM如GPT-4o在反馈质量上领先，而小型评分模型在文本-图像对齐和图像质量方面表现更佳。此外，VLM在安全性和偏见反馈上更为精准。研究还发现，VLM在自然语言反馈上比数值反馈更为准确稳定。最终，基于多模态判断的独立反馈进行的模型评估，进一步验证了MJ-Bench的有效性。相关资源已公开在https://huggingface.co/MJ-Bench。",
    "title_cn": "MJ-Bench 质疑：你的多模态奖励模型在文本到图像生成领域是否真的称职？",
    "tags": [
      "LLM应用",
      "人工智能",
      "图像处理"
    ]
  },
  {
    "title": "RAMO: Retrieval-Augmented Generation for Enhancing MOOCs Recommendations",
    "submit_datetime": "2024年07月05日",
    "abstract": "Massive Open Online Courses (MOOCs) have significantly enhanced educational accessibility by offering a wide variety of courses and breaking down traditional barriers related to geography, finance, and time. However, students often face difficulties navigating the vast selection of courses, especially when exploring new fields of study. Driven by this challenge, researchers have been exploring course recommender systems to offer tailored guidance that aligns with individual learning preferences and career aspirations. These systems face particular challenges in effectively addressing the ``cold start'' problem for new users. Recent advancements in recommender systems suggest integrating large language models (LLMs) into the recommendation process to enhance personalized recommendations and address the ``cold start'' problem. Motivated by these advancements, our study introduces RAMO (Retrieval-Augmented Generation for MOOCs), a system specifically designed to overcome the ``cold start'' challenges of traditional course recommender systems. The RAMO system leverages the capabilities of LLMs, along with Retrieval-Augmented Generation (RAG)-facilitated contextual understanding, to provide course recommendations through a conversational interface, aiming to enhance the e-learning experience.",
    "pdf_link": "https://arxiv.org/abs/2407.04925",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.04925v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04925/interface_ramo.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04925v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04925/diagram.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.04925v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04925/cold_start_compare.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04925v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04925/specific_q.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04925v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04925/question_change.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04925v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04925/template_change.png"
      }
    ],
    "abstract_cn": "MOOCs通过提供多样课程，打破了地理、经济和时间的限制，极大地提升了教育普及率。然而，学生在面对海量课程时往往感到迷茫，尤其是在涉足新领域时。为此，研究者们开发了课程推荐系统，旨在根据个人学习倾向和职业目标提供定制化建议。这些系统在解决新用户“冷启动”问题上存在挑战。最新技术进展显示，将LLMs融入推荐流程能提升个性化推荐并解决“冷启动”问题。基于此，我们推出了RAMO系统，该系统结合LLMs和RAG技术，通过对话式界面提供课程推荐，致力于优化在线学习体验。",
    "title_cn": "RAMO：通过检索增强生成技术，提升 MOOCs 推荐效果",
    "tags": [
      "LLM应用",
      "",
      "在线学习"
    ]
  },
  {
    "title": "Meta-prompting Optimized Retrieval-augmented Generation",
    "submit_datetime": "2024年07月04日",
    "abstract": "Retrieval-augmented generation resorts to content retrieved from external sources in order to leverage the performance of large language models in downstream tasks. The excessive volume of retrieved content, the possible dispersion of its parts, or their out of focus range may happen nevertheless to eventually have a detrimental rather than an incremental effect. To mitigate this issue and improve retrieval-augmented generation, we propose a method to refine the retrieved content before it is included in the prompt by resorting to meta-prompting optimization. Put to empirical test with the demanding multi-hop question answering task from the StrategyQA dataset, the evaluation results indicate that this method outperforms a similar retrieval-augmented system but without this method by over 30%.",
    "pdf_link": "https://arxiv.org/abs/2407.03955",
    "graphs": [],
    "abstract_cn": "检索增强生成通过利用外部检索内容提升大型语言模型在下游任务中的表现。然而，检索内容过多或分散可能导致负面效果。为此，我们提出一种通过元提示优化精炼检索内容的方法，以提升生成质量。在StrategyQA数据集的多跳问答任务中，该方法表现优于传统检索增强系统30%以上。",
    "title_cn": "元提示优化检索增强生成技术",
    "tags": [
      "RAG",
      "问答系统",
      "人工智能"
    ]
  },
  {
    "title": "TongGu: Mastering Classical Chinese Understanding with Knowledge-Grounded Large Language Models",
    "submit_datetime": "2024年07月04日",
    "abstract": "Classical Chinese is a gateway to the rich heritage and wisdom of ancient China, yet its complexities pose formidable comprehension barriers for most modern people without specialized knowledge. While Large Language Models (LLMs) have shown remarkable capabilities in Natural Language Processing (NLP), they struggle with Classical Chinese Understanding (CCU), especially in data-demanding and knowledge-intensive tasks. In response to this dilemma, we propose \\textbf{TongGu} (mean understanding ancient and modern), the first CCU-specific LLM, underpinned by three core contributions. First, we construct a two-stage instruction-tuning dataset ACCN-INS derived from rich classical Chinese corpora, aiming to unlock the full CCU potential of LLMs. Second, we propose Redundancy-Aware Tuning (RAT) to prevent catastrophic forgetting, enabling TongGu to acquire new capabilities while preserving its foundational knowledge. Third, we present a CCU Retrieval-Augmented Generation (CCU-RAG) technique to reduce hallucinations based on knowledge-grounding. Extensive experiments across 24 diverse CCU tasks validate TongGu's superior ability, underscoring the effectiveness of RAT and CCU-RAG. The model and dataset will be public available.",
    "pdf_link": "https://arxiv.org/abs/2407.03937",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.03937v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03937/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03937v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03937/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03937v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03937/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03937v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03937/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03937v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03937/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03937v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03937/leader_board.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03937v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03937/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03937v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03937/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03937v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03937/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03937v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03937/x9.png"
      }
    ],
    "abstract_cn": "古典中文，承载着古代中国的深厚文化和智慧，但其复杂性常令现代人望而却步。尽管大型语言模型在自然语言处理领域表现出色，但在古典中文理解这一领域，尤其是在数据密集和知识要求高的任务中，仍显不足。为此，我们推出了首个专为古典中文理解设计的LLM——**通古**，它基于三大核心创新。首先，我们创建了一个两阶段指令调优数据集ACCN-INS，源自丰富的古典中文语料，旨在充分挖掘LLM在古典中文理解方面的潜能。其次，我们引入了冗余感知调优（RAT）策略，确保通古在掌握新技能的同时，不忘基础知识。最后，我们开发了基于知识支撑的CCU检索增强生成技术（CCU-RAG），有效减少信息失真。通过24项多样化的CCU任务测试，通古展现了其卓越性能，证明了RAT和CCU-RAG技术的有效性。通古模型及其数据集将向公众开放。",
    "title_cn": "TongGu：借助知识驱动的大型语言模型，精通古典中文理解",
    "tags": [
      "LLM应用",
      "",
      ""
    ]
  },
  {
    "title": "Automated C/C++ Program Repair for High-Level Synthesis via Large Language Models",
    "submit_datetime": "2024年07月04日",
    "abstract": "In High-Level Synthesis (HLS), converting a regular C/C++ program into its HLS-compatible counterpart (HLS-C) still requires tremendous manual effort. Various program scripts have been introduced to automate this process. But the resulting codes usually contain many issues that should be manually repaired by developers. Since Large Language Models (LLMs) have the ability to automate code generation, they can also be used for automated program repair in HLS. However, due to the limited training of LLMs considering hardware and software simultaneously, hallucinations may occur during program repair using LLMs, leading to compilation failures. Besides, using LLMs for iterative repair also incurs a high cost. To address these challenges, we propose an LLM-driven program repair framework that takes regular C/C++ code as input and automatically generates its corresponding HLS-C code for synthesis while minimizing human repair effort. To mitigate the hallucinations in LLMs and enhance the prompt quality, a Retrieval-Augmented Generation (RAG) paradigm is introduced to guide the LLMs toward correct repair. In addition, we use LLMs to create a static bit width optimization program to identify the optimized bit widths for variables. Moreover, LLM-driven HLS optimization strategies are introduced to add/tune pragmas in HLS-C programs for circuit optimization. Experimental results demonstrate that the proposed LLM-driven automated framework can achieve much higher repair pass rates in 24 real-world applications compared with the traditional scripts and the direct application of LLMs for program repair.",
    "pdf_link": "https://arxiv.org/abs/2407.03889",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.03889v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03889/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03889v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03889/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03889v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03889/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03889v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03889/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03889v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03889/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03889v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03889/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03889v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03889/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03889v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03889/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03889v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03889/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03889v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03889/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03889v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03889/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03889v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03889/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03889v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03889/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03889v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03889/x15.png"
      }
    ],
    "abstract_cn": "在高级综合（HLS）领域，将C/C++程序转换为HLS-C程序仍需大量人工操作。虽然已有多种脚本尝试自动化这一过程，但生成的代码往往问题频发，需开发者手动修正。鉴于大型语言模型（LLMs）在代码生成方面的潜力，它们也被探索用于HLS程序的自动修复。然而，LLMs在同时处理硬件与软件方面的训练不足，可能导致修复过程中的“幻觉”现象，进而引发编译失败。此外，LLMs的迭代修复成本也相对较高。为此，我们设计了一个由LLM驱动的程序修复框架，该框架能自动将C/C++代码转换为HLS-C代码，并尽量减少人工干预。为减少LLMs的幻觉并提升修复质量，我们采用了检索增强生成（RAG）方法来引导LLMs进行准确修复。同时，利用LLMs进行静态位宽优化，以确定变量的最佳位宽。我们还引入了LLM驱动的HLS优化策略，通过调整HLS-C程序中的编译指示来优化电路性能。实验显示，与传统脚本及直接使用LLMs修复相比，我们的自动化框架在24个实际应用中显著提高了修复成功率。",
    "title_cn": "利用大型语言模型实现 C/C++ 程序在高级综合中的自动化修复",
    "tags": [
      "RAG",
      "半导体",
      "软件开发"
    ]
  },
  {
    "title": "Solving Zebra Puzzles Using Constraint-Guided Multi-Agent Systems",
    "submit_datetime": "2024年07月04日",
    "abstract": "Prior research has enhanced the ability of Large Language Models (LLMs) to solve logic puzzles using techniques such as chain-of-thought prompting or introducing a symbolic representation. These frameworks are still usually insufficient to solve complicated logical problems, such as Zebra puzzles, due to the inherent complexity of translating natural language clues into logical statements. We introduce a multi-agent system, ZPS, that integrates LLMs with an off the shelf theorem prover. This system tackles the complex puzzle-solving task by breaking down the problem into smaller, manageable parts, generating SMT (Satisfiability Modulo Theories) code to solve them with a theorem prover, and using feedback between the agents to repeatedly improve their answers. We also introduce an automated grid puzzle grader to assess the correctness of our puzzle solutions and show that the automated grader is reliable by evaluating it in a user-study. Our approach shows improvement in all three LLMs we tested, with GPT-4 showing 166% improvement in the number of fully correct solutions.",
    "pdf_link": "https://arxiv.org/abs/2407.03956",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.03956v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03956/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03956v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03956/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03956v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03956/Figure_2_MR_Research_sab2335-Page-1.drawio.png"
      }
    ],
    "abstract_cn": "以往的研究通过思维链提示或符号表示等技术，提升了大型语言模型 (LLM) 解决逻辑谜题的能力。然而，这些方法在处理如 Zebra 谜题这类复杂逻辑问题时仍显不足。为此，我们开发了多智能体系统 ZPS，它结合 LLM 与现成的定理证明器，通过问题分解、生成 SMT 代码及智能体间反馈循环，有效解决复杂谜题。此外，我们设计了自动网格谜题评分器，确保解决方案的正确性，并通过用户研究验证其可靠性。实验表明，我们的方法在所有测试的 LLM 中均有显著提升，GPT-4 的完全正确解决方案数量提升了 166%。",
    "title_cn": "借助约束引导的多智能体系统，破解斑马谜题",
    "tags": [
      "Agent",
      "人工智能",
      ""
    ]
  },
  {
    "title": "MobileExperts: A Dynamic Tool-Enabled Agent Team in Mobile Devices",
    "submit_datetime": "2024年07月04日",
    "abstract": "The attainment of autonomous operations in mobile computing devices has consistently been a goal of human pursuit. With the development of Large Language Models (LLMs) and Visual Language Models (VLMs), this aspiration is progressively turning into reality. While contemporary research has explored automation of simple tasks on mobile devices via VLMs, there remains significant room for improvement in handling complex tasks and reducing high reasoning costs. In this paper, we introduce MobileExperts, which for the first time introduces tool formulation and multi-agent collaboration to address the aforementioned challenges. More specifically, MobileExperts dynamically assembles teams based on the alignment of agent portraits with the human requirements. Following this, each agent embarks on an independent exploration phase, formulating its tools to evolve into an expert. Lastly, we develop a dual-layer planning mechanism to establish coordinate collaboration among experts. To validate our effectiveness, we design a new benchmark of hierarchical intelligence levels, offering insights into algorithm's capability to address tasks across a spectrum of complexity. Experimental results demonstrate that MobileExperts performs better on all intelligence levels and achieves ~ 22% reduction in reasoning costs, thus verifying the superiority of our design.",
    "pdf_link": "https://arxiv.org/abs/2407.03913",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.03913v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03913/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03913v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03913/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03913v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03913/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03913v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03913/x4.png"
      }
    ],
    "abstract_cn": "移动计算设备的自主操作一直是人类的追求目标。随着LLMs和VLMs的进步，这一梦想正逐步成真。尽管VLMs已能自动化简单任务，但在复杂任务处理和推理成本降低方面仍有巨大提升空间。本文提出的MobileExperts，首次通过工具制定和多智能体协作应对这些挑战。它根据智能体与人类需求匹配度动态组队，每个智能体独立探索并成长为专家，再通过双层规划机制实现专家间的高效协作。为验证其效能，我们设计了分层智能级别的新基准，实验显示MobileExperts在各级别表现优异，推理成本降低约22%，充分证明了其设计的优越性。",
    "title_cn": "MobileExperts：移动设备中的动态工具化代理团队",
    "tags": [
      "Agent",
      "移动计算",
      "人工智能"
    ]
  },
  {
    "title": "Planning with Large Language Models for Conversational Agents",
    "submit_datetime": "2024年07月04日",
    "abstract": "Controllability and proactivity are crucial properties of autonomous conversational agents (CAs). Controllability requires the CAs to follow the standard operating procedures (SOPs), such as verifying identity before activating credit cards. Proactivity requires the CAs to guide the conversation towards the goal during user uncooperation, such as persuasive dialogue. Existing research cannot be unified with controllability, proactivity, and low manual annotation. To bridge this gap, we propose a new framework for planning-based conversational agents (PCA) powered by large language models (LLMs), which only requires humans to define tasks and goals for the LLMs. Before conversation, LLM plans the core and necessary SOP for dialogue offline. During the conversation, LLM plans the best action path online referring to the SOP, and generates responses to achieve process controllability. Subsequently, we propose a semi-automatic dialogue data creation framework and curate a high-quality dialogue dataset (PCA-D). Meanwhile, we develop multiple variants and evaluation metrics for PCA, e.g., planning with Monte Carlo Tree Search (PCA-M), which searches for the optimal dialogue action while satisfying SOP constraints and achieving the proactive of the dialogue. Experiment results show that LLMs finetuned on PCA-D can significantly improve the performance and generalize to unseen domains. PCA-M outperforms other CoT and ToT baselines in terms of conversation controllability, proactivity, task success rate, and overall logical coherence, and is applicable in industry dialogue scenarios. The dataset and codes are available at XXXX.",
    "pdf_link": "https://arxiv.org/abs/2407.03884",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.03884v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03884/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03884v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03884/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03884v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03884/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03884v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03884/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03884v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03884/task1_task_define.png"
      }
    ],
    "abstract_cn": "自主对话代理（CAs）的核心在于可控性与主动性。可控性意味着CAs需遵循标准操作流程（SOPs），如激活信用卡前的身份验证；主动性则要求CAs在用户不配合时引导对话达成目标，如进行说服性交流。当前研究难以兼顾这三者：可控性、主动性与低成本的手动标注。为此，我们创新性地提出了一个基于计划的大型语言模型（LLMs）驱动的对话代理框架（PCA），仅需人类设定任务与目标。对话前，LLM离线制定关键SOP；对话中，LLM在线依据SOP规划最优行动，确保对话过程的可控。此外，我们构建了半自动对话数据生成框架，并精心打造了高质量对话数据集（PCA-D）。我们还研发了多种PCA变体及评估标准，如采用蒙特卡洛树搜索（PCA-M）的规划方法，该方法在遵守SOP的同时，寻找最优对话策略，增强对话的主动性。实验表明，经PCA-D微调的LLMs性能大幅提升，且能适应新领域。PCA-M在多个维度上超越传统基线，适用于实际工业对话场景。相关数据集与代码已公开于XXXX。",
    "title_cn": "利用大型语言模型规划对话代理",
    "tags": [
      "Agent",
      "对话系统",
      ""
    ]
  },
  {
    "title": "Over the Edge of Chaos? Excess Complexity as a Roadblock to Artificial General Intelligence",
    "submit_datetime": "2024年07月04日",
    "abstract": "In this study, we explored the progression trajectories of artificial intelligence (AI) systems through the lens of complexity theory. We challenged the conventional linear and exponential projections of AI advancement toward Artificial General Intelligence (AGI) underpinned by transformer-based architectures, and posited the existence of critical points, akin to phase transitions in complex systems, where AI performance might plateau or regress into instability upon exceeding a critical complexity threshold. We employed agent-based modelling (ABM) to simulate hypothetical scenarios of AI systems' evolution under specific assumptions, using benchmark performance as a proxy for capability and complexity. Our simulations demonstrated how increasing the complexity of the AI system could exceed an upper criticality threshold, leading to unpredictable performance behaviours. Additionally, we developed a practical methodology for detecting these critical thresholds using simulation data and stochastic gradient descent to fine-tune detection thresholds. This research offers a novel perspective on AI advancement that has a particular relevance to Large Language Models (LLMs), emphasising the need for a tempered approach to extrapolating AI's growth potential and underscoring the importance of developing more robust and comprehensive AI performance benchmarks.",
    "pdf_link": "https://arxiv.org/abs/2407.03652",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.03652v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03652/benachmarks2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03652v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03652/benachmarks5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03652v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03652/benachmarks10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03652v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03652/benachmarks20.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03652v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03652/benachmarks2variance.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03652v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03652/benachmarks5variance.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03652v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03652/benachmarks10variance.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03652v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03652/benachmarks20variance.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03652v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03652/benachmarks2derivativedetection.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03652v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03652/benachmarks5derivativedetection.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03652v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03652/benachmarks10derivativedetection.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03652v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03652/benachmarks20derivativedetection.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03652v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03652/benachmarks2derivativedetectionhist.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03652v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03652/benachmarks5derivativedetectionhist.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03652v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03652/benachmarks10derivativedetectionhist.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03652v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03652/benachmarks20derivativedetectionhist.png"
      }
    ],
    "abstract_cn": "本研究通过复杂性理论视角，深入探讨了AI系统的演进路径。我们质疑了传统上对AI向AGI发展的线性和指数预测，并提出了AI性能在达到某个复杂性临界点后可能停滞或变得不稳定的观点。通过基于代理的建模，我们模拟了AI系统在特定条件下的演化，以基准性能衡量其能力和复杂度。模拟结果显示，AI系统复杂度的增加可能导致性能行为的不可预测性。此外，我们提出了一种实用方法，利用模拟数据和随机梯度下降技术来识别这些关键阈值。这项研究为理解AI发展提供了新视角，特别强调了在评估AI潜力时需谨慎，并呼吁建立更全面的AI性能评估标准。",
    "title_cn": "超越混沌边缘？过度复杂性成为人工通用智能之路的绊脚石",
    "tags": [
      "LLM理论",
      "人工智能",
      "复杂性理论"
    ]
  },
  {
    "title": "M$\\mathbf5$ -- A Diverse Benchmark to Assess the Performance of Large Multimodal Models Across Multilingual and Multicultural Vision-Language Tasks",
    "submit_datetime": "2024年07月04日",
    "abstract": "Since the release of ChatGPT, the field of Natural Language Processing has experienced rapid advancements, particularly in Large Language Models (LLMs) and their multimodal counterparts, Large Multimodal Models (LMMs). Despite their impressive capabilities, LLMs often exhibit significant performance disparities across different languages and cultural contexts, as demonstrated by various text-only benchmarks. However, current research lacks such benchmarks for multimodal visio-linguistic settings. This work fills this gap by introducing M5, the first comprehensive benchmark designed to evaluate LMMs on diverse vision-language tasks within a multilingual and multicultural context. M5 includes eight datasets covering five tasks and $41$ languages, with a focus on underrepresented languages and culturally diverse images. Furthermore, we introduce two novel datasets, M5-VGR and M5-VLOD, including a new Visio-Linguistic Outlier Detection task, in which all evaluated open-source models fail to significantly surpass the random baseline. Through extensive evaluation and analyses, we highlight substantial task-agnostic performance disparities between high- and low-resource languages. Moreover, we show that larger models do not necessarily outperform smaller ones in a multilingual setting.",
    "pdf_link": "https://arxiv.org/abs/2407.03791",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.03791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03791/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03791/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03791/vgr_sample_zu_90_4bbacd9003aa4d0199939fa2fd80c276.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03791/vlod_sample_sw_87_9fbc54f2a62f4cbbbe216e84565cbdd6.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.03791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03791/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03791/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03791/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03791/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03791/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03791/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03791/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03791/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03791/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03791/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03791/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03791/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03791/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03791/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03791/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03791/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03791/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03791/x20.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03791/x21.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03791/x22.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03791/x23.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03791/x24.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03791/x25.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03791/x26.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03791/x27.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03791/x28.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03791/x29.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03791/x30.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03791/x31.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03791/x32.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03791/x33.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03791/x34.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03791/x35.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03791/x36.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03791/x37.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03791/x38.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03791/x39.png"
      }
    ],
    "abstract_cn": "自ChatGPT问世以来，自然语言处理领域飞速进步，特别是在大型语言模型（LLMs）和大型多模态模型（LMMs）方面。尽管这些模型能力出众，但在不同语言和文化环境中，其性能差异显著，这在纯文本基准测试中可见一斑。然而，针对多模态视觉语言环境的研究却缺乏相应的基准。为此，我们推出了M5，这是首个全面评估LMMs在多语言和文化背景下视觉语言任务的基准。M5包含八个数据集，覆盖五个任务和41种语言，特别关注那些代表性不足的语言和具有文化多样性的图像。同时，我们新增了两个数据集M5-VGR和M5-VLOD，并引入了一项新的视觉语言异常检测任务，结果显示，所有评估的开源模型均未能显著超越随机基准。通过深入评估和分析，我们揭示了高资源和低资源语言之间在任务无关的性能差异。此外，我们还发现，在多语言环境中，模型的大小并非决定性能的关键因素。",
    "title_cn": "M$\\mathbf5$ 是一个多元化基准，旨在全面评估大型多模态模型在跨语言和文化视觉-语言任务中的表现。",
    "tags": [
      "LLM应用",
      "人工智能",
      "多模态学习"
    ]
  },
  {
    "title": "MRIR: Integrating Multimodal Insights for Diffusion-based Realistic Image Restoration",
    "submit_datetime": "2024年07月04日",
    "abstract": "Realistic image restoration is a crucial task in computer vision, and the use of diffusion-based models for image restoration has garnered significant attention due to their ability to produce realistic results. However, the quality of the generated images is still a significant challenge due to the severity of image degradation and the uncontrollability of the diffusion model. In this work, we delve into the potential of utilizing pre-trained stable diffusion for image restoration and propose MRIR, a diffusion-based restoration method with multimodal insights. Specifically, we explore the problem from two perspectives: textual level and visual level. For the textual level, we harness the power of the pre-trained multimodal large language model to infer meaningful semantic information from low-quality images. Furthermore, we employ the CLIP image encoder with a designed Refine Layer to capture image details as a supplement. For the visual level, we mainly focus on the pixel level control. Thus, we utilize a Pixel-level Processor and ControlNet to control spatial structures. Finally, we integrate the aforementioned control information into the denoising U-Net using multi-level attention mechanisms and realize controllable image restoration with multimodal insights. The qualitative and quantitative results demonstrate our method's superiority over other state-of-the-art methods on both synthetic and real-world datasets.",
    "pdf_link": "https://arxiv.org/abs/2407.03635",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.03635v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03635/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03635v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03635/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03635v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03635/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03635v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03635/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03635v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03635/squares.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03635v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03635/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03635v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03635/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03635v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03635/x7.png"
      }
    ],
    "abstract_cn": "图像修复在计算机视觉领域至关重要，而基于扩散模型的应用因其逼真效果备受瞩目。尽管如此，图像质量因退化严重和模型不可控而面临挑战。我们探索预训练稳定扩散的潜力，提出MRIR方法，从文本和视觉两方面入手。文本层面，我们借助多模态大型语言模型提取低质量图像的语义信息；视觉层面，我们通过像素级处理器和ControlNet精细控制图像结构。最终，通过多级注意力机制，我们将这些控制信息融入去噪U-Net，实现多模态视角下的可控图像修复。实验证明，我们的方法在合成与真实数据集上均超越现有顶尖技术。",
    "title_cn": "MRIR：融合多模态洞察，实现基于扩散技术的真实图像修复",
    "tags": [
      "LLM应用",
      "计算机视觉",
      "图像处理"
    ]
  },
  {
    "title": "Query-Guided Self-Supervised Summarization of Nursing Notes",
    "submit_datetime": "2024年07月04日",
    "abstract": "Nursing notes, an important component of Electronic Health Records (EHRs), keep track of the progression of a patient's health status during a care episode. Distilling the key information in nursing notes through text summarization techniques can improve clinicians' efficiency in understanding patients' conditions when reviewing nursing notes. However, existing abstractive summarization methods in the clinical setting have often overlooked nursing notes and require the creation of reference summaries for supervision signals, which is time-consuming. In this work, we introduce QGSumm, a query-guided self-supervised domain adaptation framework for nursing note summarization. Using patient-related clinical queries as guidance, our approach generates high-quality, patient-centered summaries without relying on reference summaries for training. Through automatic and manual evaluation by an expert clinician, we demonstrate the strengths of our approach compared to the state-of-the-art Large Language Models (LLMs) in both zero-shot and few-shot settings. Ultimately, our approach provides a new perspective on conditional text summarization, tailored to the specific interests of clinical personnel.",
    "pdf_link": "https://arxiv.org/abs/2407.04125",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.04125v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04125/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04125v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04125/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04125v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04125/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04125v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04125/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04125v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04125/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04125v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04125/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04125v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04125/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04125v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04125/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04125v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04125/x9.png"
      }
    ],
    "abstract_cn": "护理记录作为电子健康记录的关键部分，记录了患者护理期间的健康进展。通过文本摘要技术提炼这些记录中的关键信息，能显著提升临床医生理解患者状况的效率。然而，现有临床摘要方法常忽略护理记录，且需耗时创建参考摘要。为此，我们提出了QGSumm框架，利用患者相关临床查询引导，生成高质量、以患者为中心的摘要，无需参考摘要。经自动与临床专家手动评估，我们的方法在零-shot和few-shot环境下均优于顶尖大型语言模型。这一创新为条件文本摘要开辟了新视角，更贴合临床人员的实际需求。",
    "title_cn": "护理笔记的自监督摘要，由查询引导",
    "tags": [
      "LLM应用",
      "",
      "临床护理"
    ]
  },
  {
    "title": "Hallucination Detection: Robustly Discerning Reliable Answers in Large Language Models",
    "submit_datetime": "2024年07月04日",
    "abstract": "Large Language Models (LLMs) have gained widespread adoption in various natural language processing tasks, including question answering and dialogue systems. However, a major drawback of LLMs is the issue of hallucination, where they generate unfaithful or inconsistent content that deviates from the input source, leading to severe consequences. In this paper, we propose a robust discriminator named RelD to effectively detect hallucination in LLMs' generated answers. RelD is trained on the constructed RelQA, a bilingual question-answering dialogue dataset along with answers generated by LLMs and a comprehensive set of metrics. Our experimental results demonstrate that the proposed RelD successfully detects hallucination in the answers generated by diverse LLMs. Moreover, it performs well in distinguishing hallucination in LLMs' generated answers from both in-distribution and out-of-distribution datasets. Additionally, we also conduct a thorough analysis of the types of hallucinations that occur and present valuable insights. This research significantly contributes to the detection of reliable answers generated by LLMs and holds noteworthy implications for mitigating hallucination in the future work.",
    "pdf_link": "https://arxiv.org/abs/2407.04121",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.04121v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04121/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04121v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04121/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04121v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04121/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04121v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04121/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04121v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04121/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04121v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04121/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04121v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04121/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04121v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04121/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04121v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04121/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04121v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04121/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04121v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04121/x11.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLM）在问答和对话系统等自然语言处理任务中广受欢迎，但其幻觉问题——生成与输入不符的内容——却带来了严重问题。为此，我们设计了名为 RelD 的鲁棒判别器，专门用于检测 LLM 生成的答案中的幻觉。RelD 基于我们构建的双语问答对话数据集 RelQA 进行训练，并结合了 LLM 生成的答案及一系列全面指标。实验显示，RelD 能有效识别不同 LLM 生成的答案中的幻觉，无论数据来源如何。同时，我们对幻觉类型进行了深入分析，揭示了宝贵见解。这项研究不仅提升了 LLM 生成答案的可靠性检测，也为未来减轻幻觉问题提供了重要启示。",
    "title_cn": "幻觉检测：在大规模语言模型中，如何稳健地识别出可靠答案，是一项关键任务。",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "MAPO: Boosting Large Language Model Performance with Model-Adaptive Prompt Optimization",
    "submit_datetime": "2024年07月04日",
    "abstract": "Prompt engineering, as an efficient and effective way to leverage Large Language Models (LLM), has drawn a lot of attention from the research community. The existing research primarily emphasizes the importance of adapting prompts to specific tasks, rather than specific LLMs. However, a good prompt is not solely defined by its wording, but also binds to the nature of the LLM in question. In this work, we first quantitatively demonstrate that different prompts should be adapted to different LLMs to enhance their capabilities across various downstream tasks in NLP. Then we novelly propose a model-adaptive prompt optimizer (MAPO) method that optimizes the original prompts for each specific LLM in downstream tasks. Extensive experiments indicate that the proposed method can effectively refine prompts for an LLM, leading to significant improvements over various downstream tasks.",
    "pdf_link": "https://arxiv.org/abs/2407.04118",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.04118v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04118/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04118v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04118/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04118v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04118/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04118v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04118/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04118v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04118/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04118v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04118/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04118v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04118/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04118v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04118/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04118v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04118/x9.png"
      }
    ],
    "abstract_cn": "Prompt engineering 作为利用大型语言模型的有效手段，备受研究界瞩目。现有研究侧重于将提示适配特定任务而非特定模型。然而，优质提示不仅取决于措辞，还与模型特性紧密相关。本研究首先通过定量分析，证明不同提示应针对不同模型进行优化，以提升其在 NLP 各类下游任务中的表现。接着，我们创新提出模型自适应提示优化器 (MAPO)，专门针对各模型优化提示。实验证明，该方法能显著提升模型在下游任务中的性能。",
    "title_cn": "MAPO 技术通过模型自适应提示优化，显著提升大型语言模型的性能。",
    "tags": [
      "LLM应用",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Future Events as Backdoor Triggers: Investigating Temporal Vulnerabilities in LLMs",
    "submit_datetime": "2024年07月04日",
    "abstract": "Backdoors are hidden behaviors that are only triggered once an AI system has been deployed. Bad actors looking to create successful backdoors must design them to avoid activation during training and evaluation. Since data used in these stages often only contains information about events that have already occurred, a component of a simple backdoor trigger could be a model recognizing data that is in the future relative to when it was trained. Through prompting experiments and by probing internal activations, we show that current large language models (LLMs) can distinguish past from future events, with probes on model activations achieving $90\\%$ accuracy. We train models with backdoors triggered by a temporal distributional shift; they activate when the model is exposed to news headlines beyond their training cut-off dates. Fine-tuning on helpful, harmless and honest (HHH) data does not work well for removing simpler backdoor triggers but is effective on our backdoored models, although this distinction is smaller for the larger-scale model we tested. We also find that an activation-steering vector representing a model's internal representation of the date influences the rate of backdoor activation. We take these results as initial evidence that, at least for models at the modest scale we test, standard safety measures are enough to remove these backdoors. We publicly release all relevant code (https://github.com/sbp354/Future_triggered_backdoors), datasets (https://tinyurl.com/future-backdoor-datasets), and models (https://huggingface.co/saraprice).",
    "pdf_link": "https://arxiv.org/abs/2407.04108",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.04108v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04108/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04108v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04108/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04108v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04108/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04108v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04108/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04108v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04108/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04108v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04108/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04108v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04108/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04108v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04108/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04108v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04108/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04108v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04108/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04108v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04108/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04108v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04108/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04108v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04108/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04108v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04108/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04108v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04108/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04108v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04108/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04108v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04108/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04108v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04108/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04108v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04108/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04108v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04108/x20.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04108v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04108/x23.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04108v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04108/x24.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04108v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04108/x25.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04108v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04108/x26.png"
      }
    ],
    "abstract_cn": "后门行为在AI系统部署后才会显现，恶意设计者需确保其在训练和评估阶段不激活。由于这些阶段的数据通常仅涉及已发生事件，一个简单的后门触发机制可能是模型识别未来数据。我们的实验显示，大型语言模型能以90%的准确率区分过去与未来事件。我们训练的模型在接触到训练截止日期之后的新闻标题时会触发后门。尽管在有益、无害和诚实数据上的微调对简单后门效果有限，但对我们的后门模型却颇为有效，尤其是对于较小规模的模型。此外，模型内部对日期的表示方式也影响后门激活频率。这些发现表明，对于适度规模的模型，常规安全措施足以消除这些后门。我们已公开所有相关资源，包括代码、数据集和模型。",
    "title_cn": "未来事件可能成为 LLM 的后门触发器，本研究深入探讨这些模型中的时间脆弱性。",
    "tags": [
      "LLM应用",
      "人工智能安全",
      "网络安全"
    ]
  },
  {
    "title": "MiniGPT-Med: Large Language Model as a General Interface for Radiology Diagnosis",
    "submit_datetime": "2024年07月04日",
    "abstract": "Recent advancements in artificial intelligence (AI) have precipitated significant breakthroughs in healthcare, particularly in refining diagnostic procedures. However, previous studies have often been constrained to limited functionalities. This study introduces MiniGPT-Med, a vision-language model derived from large-scale language models and tailored for medical applications. MiniGPT-Med demonstrates remarkable versatility across various imaging modalities, including X-rays, CT scans, and MRIs, enhancing its utility. The model is capable of performing tasks such as medical report generation, visual question answering (VQA), and disease identification within medical imagery. Its integrated processing of both image and textual clinical data markedly improves diagnostic accuracy. Our empirical assessments confirm MiniGPT-Med's superior performance in disease grounding, medical report generation, and VQA benchmarks, representing a significant step towards reducing the gap in assisting radiology practice. Furthermore, it achieves state-of-the-art performance on medical report generation, higher than the previous best model by 19\\% accuracy. MiniGPT-Med promises to become a general interface for radiology diagnoses, enhancing diagnostic efficiency across a wide range of medical imaging applications.",
    "pdf_link": "https://arxiv.org/abs/2407.04106",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.04106v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04106/miniGPT-Med.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04106v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04106/model_arch_may28.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04106v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04106/report_generation.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04106v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04106/detection.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04106v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04106/grounding.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04106v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04106/Refer-task.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04106v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04106/identify.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04106v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04106/vqa.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04106v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04106/FP.png"
      }
    ],
    "abstract_cn": "AI在医疗领域的最新进展，特别是在诊断流程的优化上，取得了重大突破。然而，过往研究多受限于功能单一。本研究推出的MiniGPT-Med，是一款专为医疗定制的视觉-语言模型，源自大型语言模型。该模型在X光、CT和MRI等多种影像模式中展现出卓越的多功能性，极大提升了应用价值。它能完成医疗报告生成、视觉问答及影像内疾病识别等任务，通过整合图像与文本数据，显著提升诊断精准度。实测表明，MiniGPT-Med在疾病定位、报告生成及问答测试中表现卓越，大幅缩小了辅助放射学实践的差距。其在医疗报告生成上的准确率更是领先同行19%，预示着它将成为放射学诊断的通用平台，全面提升医疗影像诊断的效率。",
    "title_cn": "MiniGPT-Med：将大型语言模型打造为放射学诊断的多面手",
    "tags": [
      "LLM应用",
      "",
      "放射学"
    ]
  },
  {
    "title": "Stephanie: Step-by-Step Dialogues for Mimicking Human Interactions in Social Conversations",
    "submit_datetime": "2024年07月04日",
    "abstract": "In the rapidly evolving field of natural language processing, dialogue systems primarily employ a single-step dialogue paradigm. Although this paradigm is efficient, it lacks the depth and fluidity of human interactions and does not appear natural. We introduce a novel \\textbf{Step}-by-Step Dialogue Paradigm (Stephanie), designed to mimic the ongoing dynamic nature of human conversations. By employing a dual learning strategy and a further-split post-editing method, we generated and utilized a high-quality step-by-step dialogue dataset to fine-tune existing large language models, enabling them to perform step-by-step dialogues. We thoroughly present Stephanie. Tailored automatic and human evaluations are conducted to assess its effectiveness compared to the traditional single-step dialogue paradigm. We will release code, Stephanie datasets, and Stephanie LLMs to facilitate the future of chatbot eras.",
    "pdf_link": "https://arxiv.org/abs/2407.04093",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.04093v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04093/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04093v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04093/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04093v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04093/x3.png"
      }
    ],
    "abstract_cn": "在自然语言处理领域，对话系统多采用单一步骤对话模式，虽高效但缺乏自然互动的深度与流畅性。为此，我们创新性地提出了**步骤**-by-步骤对话范式（Stephanie），模拟人类对话的动态过程。通过双重学习策略与细分后编辑技术，我们构建了高质量的步骤-by-步骤对话数据集，并用于微调大型语言模型，使其能进行更自然的对话。我们详细介绍了Stephanie，并通过定制评估验证了其优于传统范式的效果。未来，我们将公开代码、数据集及模型，助力聊天机器人技术的进步。",
    "title_cn": "Stephanie：通过逐步对话，巧妙模仿社交场合中的人类互动",
    "tags": [
      "LLM应用",
      "",
      "聊天机器人"
    ]
  },
  {
    "title": "DotaMath: Decomposition of Thought with Code Assistance and Self-correction for Mathematical Reasoning",
    "submit_datetime": "2024年07月04日",
    "abstract": "Large language models (LLMs) have made impressive progress in handling simple math problems, yet they still struggle with more challenging and complex mathematical tasks. In this paper, we introduce a series of LLMs that employs the Decomposition of thought with code assistance and self-correction for mathematical reasoning, dubbed as DotaMath. DotaMath models tackle complex mathematical tasks by decomposing them into simpler logical subtasks, leveraging code to solve these subtasks, obtaining fine-grained feedback from the code interpreter, and engaging in self-reflection and correction. By annotating diverse interactive tool-use trajectories and employing query evolution on GSM8K and MATH datasets, we generate an instruction fine-tuning dataset called DotaMathQA with 574K query-response pairs. We train a series of base LLMs using imitation learning on DotaMathQA, resulting in DotaMath models that achieve remarkable performance compared to open-source LLMs across various in-domain and out-of-domain benchmarks. Notably, DotaMath-deepseek-7B showcases an outstanding performance of 64.8% on the competitive MATH dataset and 86.7% on GSM8K. Besides, DotaMath-deepseek-7B maintains strong competitiveness on a series of in-domain and out-of-domain benchmarks (Avg. 80.1%). Looking forward, we anticipate that the DotaMath paradigm will open new pathways for addressing intricate mathematical problems. Our code is publicly available at https://github.com/ChengpengLi1003/DotaMath.",
    "pdf_link": "https://arxiv.org/abs/2407.04078",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLM）在简单数学问题上取得了显著进步，但在处理更复杂、更具挑战性的数学任务时仍显不足。本文介绍了一种名为 DotaMath 的 LLM 系列，通过代码辅助和自我修正的思维分解方法，将复杂数学任务分解为简单逻辑子任务，利用代码解决，并进行自我反思和修正。我们通过注释多样化的工具使用轨迹，在 GSM8K 和 MATH 数据集上生成包含 574K 查询-响应对的 DotaMathQA 数据集，并使用模仿学习训练 LLM。DotaMath 模型在各类基准测试中表现卓越，特别是在 MATH 数据集上达到 64.8%，在 GSM8K 上达到 86.7%，平均竞争力为 80.1%。我们期待 DotaMath 范式为解决复杂数学问题开辟新途径，相关代码已公开发布。",
    "title_cn": "DotaMath：借助代码辅助与自我修正，实现数学推理思维的精细分解",
    "tags": [
      "LLM应用",
      "",
      ""
    ]
  },
  {
    "title": "A Systematic Survey and Critical Review on Evaluating Large Language Models: Challenges, Limitations, and Recommendations",
    "submit_datetime": "2024年07月04日",
    "abstract": "Large Language Models (LLMs) have recently gained significant attention due to their remarkable capabilities in performing diverse tasks across various domains. However, a thorough evaluation of these models is crucial before deploying them in real-world applications to ensure they produce reliable performance. Despite the well-established importance of evaluating LLMs in the community, the complexity of the evaluation process has led to varied evaluation setups, causing inconsistencies in findings and interpretations. To address this, we systematically review the primary challenges and limitations causing these inconsistencies and unreliable evaluations in various steps of LLM evaluation. Based on our critical review, we present our perspectives and recommendations to ensure LLM evaluations are reproducible, reliable, and robust.",
    "pdf_link": "https://arxiv.org/abs/2407.04069",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.04069v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04069/overview.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04069v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04069/parsing.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04069v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04069/llama_vs_qwen.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04069v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04069/samsum.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04069v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04069/elohacking.png"
      }
    ],
    "abstract_cn": "近期，大型语言模型因其跨领域执行多样化任务的卓越能力而备受瞩目。但在实际应用前，对其进行全面评估是确保性能可靠的关键。尽管评估 LLM 的重要性已成共识，评估过程的复杂性却导致了评估方法的多样性，进而引发了结果和解释的不一致。为此，我们深入探讨了造成这些不一致和评估不可靠的主要难题与局限，并基于此，提出了确保 LLM 评估具备可重复性、可靠性和健壮性的见解与建议。",
    "title_cn": "本文系统探讨并批判性分析了评估大型语言模型的挑战与局限，并提出了相应建议。",
    "tags": [
      "LLM理论",
      "人工智能",
      "软件工程"
    ]
  },
  {
    "title": "Semantic Graphs for Syntactic Simplification: A Revisit from the Age of LLM",
    "submit_datetime": "2024年07月04日",
    "abstract": "Symbolic sentence meaning representations, such as AMR (Abstract Meaning Representation) provide expressive and structured semantic graphs that act as intermediates that simplify downstream NLP tasks. However, the instruction-following capability of large language models (LLMs) offers a shortcut to effectively solve NLP tasks, questioning the utility of semantic graphs. Meanwhile, recent work has also shown the difficulty of using meaning representations merely as a helpful auxiliary for LLMs. We revisit the position of semantic graphs in syntactic simplification, the task of simplifying sentence structures while preserving their meaning, which requires semantic understanding, and evaluate it on a new complex and natural dataset. The AMR-based method that we propose, AMRS$^3$, demonstrates that state-of-the-art meaning representations can lead to easy-to-implement simplification methods with competitive performance and unique advantages in cost, interpretability, and generalization. With AMRS$^3$ as an anchor, we discover that syntactic simplification is a task where semantic graphs are helpful in LLM prompting. We propose AMRCoC prompting that guides LLMs to emulate graph algorithms for explicit symbolic reasoning on AMR graphs, and show its potential for improving LLM on semantic-centered tasks like syntactic simplification.",
    "pdf_link": "https://arxiv.org/abs/2407.04067",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.04067v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04067/x1.png"
      }
    ],
    "abstract_cn": "AMR等符号句子意义表示提供了结构化的语义图，本应简化NLP任务，但LLMs的指令遵循能力却提供了更直接的解决方案，使得语义图的实用性受到质疑。同时，将意义表示仅作为LLMs的辅助也面临挑战。我们重新评估了语义图在句法简化任务中的作用，并提出了AMRS$^3$方法，展示了其在简化方法中的竞争优势和独特价值。通过AMRS$^3$，我们发现语义图在LLM提示中对句法简化任务有积极作用。进一步，我们提出AMRCoC提示方法，引导LLMs在AMR图上进行符号推理，有望提升LLM在句法简化等语义任务中的表现。",
    "title_cn": "在 LLM 时代，语义图在句法简化中的应用值得重新审视。",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "On the Workflows and Smells of Leaderboard Operations (LBOps): An Exploratory Study of Foundation Model Leaderboards",
    "submit_datetime": "2024年07月04日",
    "abstract": "Foundation models (FM), such as large language models (LLMs), which are large-scale machine learning (ML) models, have demonstrated remarkable adaptability in various downstream software engineering (SE) tasks, such as code completion, code understanding, and software development. As a result, FM leaderboards, especially those hosted on cloud platforms, have become essential tools for SE teams to compare and select the best third-party FMs for their specific products and purposes. However, the lack of standardized guidelines for FM evaluation and comparison threatens the transparency of FM leaderboards and limits stakeholders' ability to perform effective FM selection. As a first step towards addressing this challenge, our research focuses on understanding how these FM leaderboards operate in real-world scenarios (\"leaderboard operations\") and identifying potential leaderboard pitfalls and areas for improvement (\"leaderboard smells\"). In this regard, we perform a multivocal literature review to collect up to 721 FM leaderboards, after which we examine their documentation and engage in direct communication with leaderboard operators to understand their workflow patterns. Using card sorting and negotiated agreement, we identify 5 unique workflow patterns and develop a domain model that outlines the essential components and their interaction within FM leaderboards. We then identify 8 unique types of leaderboard smells in LBOps. By mitigating these smells, SE teams can improve transparency, accountability, and collaboration in current LBOps practices, fostering a more robust and responsible ecosystem for FM comparison and selection.",
    "pdf_link": "https://arxiv.org/abs/2407.04065",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.04065v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04065/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04065v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04065/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04065v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04065/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04065v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04065/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04065v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04065/x21.png"
      }
    ],
    "abstract_cn": "大型语言模型等基础模型在软件工程任务中展现出卓越的适应性，推动了FM排行榜在云平台上的重要性。然而，评估和比较指南的缺失影响了排行榜的透明度，限制了有效选择。我们的研究首先探索了排行榜的实际运作和潜在问题，通过文献综述和运营商沟通，揭示了五种工作流程模式和八类问题。通过解决这些问题，我们旨在提升排行榜的透明度和责任感，构建一个更健康、更负责任的FM选择环境。",
    "title_cn": "探索基础模型排行榜中的操作流程与问题：排行榜操作 (LBOps) 的深入研究",
    "tags": [
      "LLM应用",
      "软件工程",
      "云计算"
    ]
  },
  {
    "title": "FunAudioLLM: Voice Understanding and Generation Foundation Models for Natural Interaction Between Humans and LLMs",
    "submit_datetime": "2024年07月04日",
    "abstract": "This report introduces FunAudioLLM, a model family designed to enhance natural voice interactions between humans and large language models (LLMs). At its core are two innovative models: SenseVoice, which handles multilingual speech recognition, emotion recognition, and audio event detection; and CosyVoice, which facilitates natural speech generation with control over multiple languages, timbre, speaking style, and speaker identity. SenseVoice-Small delivers exceptionally low-latency ASR for 5 languages, and SenseVoice-Large supports high-precision ASR for over 50 languages, while CosyVoice excels in multi-lingual voice generation, zero-shot in-context learning, cross-lingual voice cloning, and instruction-following capabilities. The models related to SenseVoice and CosyVoice have been open-sourced on Modelscope and Huggingface, along with the corresponding training, inference, and fine-tuning codes released on GitHub. By integrating these models with LLMs, FunAudioLLM enables applications such as speech-to-speech translation, emotional voice chat, interactive podcasts, and expressive audiobook narration, thereby pushing the boundaries of voice interaction technology. Demos are available at https://fun-audio-llm.github.io, and the code can be accessed at https://github.com/FunAudioLLM.",
    "pdf_link": "https://arxiv.org/abs/2407.04051",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.04051v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04051/overview-funaudiollm.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04051v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04051/overview-sensevoice.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04051v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04051/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04051v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04051/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04051v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04051/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04051v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04051/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04051v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04051/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04051v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04051/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04051v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04051/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04051v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04051/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04051v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04051/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04051v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04051/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04051v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04051/S2ST.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04051v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04051/EmotionalVoiceChat.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04051v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04051/InteractivePodcast.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04051v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04051/AudioBook.png"
      }
    ],
    "abstract_cn": "本报告介绍的 FunAudioLLM 模型家族，旨在提升人类与 LLM 间的自然语音交互。核心包含两个创新模型：SenseVoice 处理多语言语音识别、情感识别及音频事件检测；CosyVoice 则通过调控多语言、音色、说话风格和说话者身份，实现自然语音生成。SenseVoice-Small 为五种语言提供超低延迟 ASR，而 SenseVoice-Large 支持五十多种语言的高精度 ASR。CosyVoice 在多语言语音生成、零-shot 上下文学习、跨语言语音克隆及指令遵循方面表现卓越。相关模型已在 Modelscope 和 Huggingface 开源，训练、推理及微调代码亦在 GitHub 发布。结合 LLM，FunAudioLLM 推动了语音到语音翻译、情感语音聊天、互动播客及有声书叙述等应用的发展，拓展了语音交互技术的边界。演示与代码分别可在 https://fun-audio-llm.github.io 和 https://github.com/FunAudioLLM 获取。",
    "title_cn": "FunAudioLLM：助力人机自然对话的语音理解与生成基础模型",
    "tags": [
      "LLM应用",
      "语音交互",
      "媒体娱乐"
    ]
  },
  {
    "title": "Improving Accented Speech Recognition using Data Augmentation based on Unsupervised Text-to-Speech Synthesis",
    "submit_datetime": "2024年07月04日",
    "abstract": "This paper investigates the use of unsupervised text-to-speech synthesis (TTS) as a data augmentation method to improve accented speech recognition. TTS systems are trained with a small amount of accented speech training data and their pseudo-labels rather than manual transcriptions, and hence unsupervised. This approach enables the use of accented speech data without manual transcriptions to perform data augmentation for accented speech recognition. Synthetic accented speech data, generated from text prompts by using the TTS systems, are then combined with available non-accented speech data to train automatic speech recognition (ASR) systems. ASR experiments are performed in a self-supervised learning framework using a Wav2vec2.0 model which was pre-trained on large amount of unsupervised accented speech data. The accented speech data for training the unsupervised TTS are read speech, selected from L2-ARCTIC and British Isles corpora, while spontaneous conversational speech from the Edinburgh international accents of English corpus are used as the evaluation data. Experimental results show that Wav2vec2.0 models which are fine-tuned to downstream ASR task with synthetic accented speech data, generated by the unsupervised TTS, yield up to 6.1% relative word error rate reductions compared to a Wav2vec2.0 baseline which is fine-tuned with the non-accented speech data from Librispeech corpus.",
    "pdf_link": "https://arxiv.org/abs/2407.04047",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.04047v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04047/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04047v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04047/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04047v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04047/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04047v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04047/x4.png"
      }
    ],
    "abstract_cn": "本文探讨了无监督文本到语音合成（TTS）作为数据增强手段，以提升带口音语音识别的性能。TTS系统利用少量带口音语音数据及其自动生成的伪标签进行训练，无需人工转录，实现了无监督学习。这种方法使得带口音语音数据能够直接用于数据增强，提升识别效果。通过TTS系统生成的合成带口音语音数据与非带口音语音数据结合，用于训练ASR系统。实验采用自监督学习框架，使用预训练的Wav2vec2.0模型，该模型在大量无监督带口音语音数据上进行了预训练。训练数据包括朗读语音，选自L2-ARCTIC和British Isles语料库，而评估数据则为Edinburgh国际英语口音语料库中的自发对话语音。实验结果表明，通过无监督TTS生成的合成带口音语音数据微调的Wav2vec2.0模型，相比使用Librispeech语料库中非带口音语音数据微调的基线模型，相对词错误率降低了6.1%。",
    "title_cn": "利用无监督的文本转语音合成进行数据增强，提升带口音语音的识别效果",
    "tags": [
      "LLM应用",
      "语音识别",
      "数据增强"
    ]
  },
  {
    "title": "Systematic Task Exploration with LLMs: A Study in Citation Text Generation",
    "submit_datetime": "2024年07月04日",
    "abstract": "Large language models (LLMs) bring unprecedented flexibility in defining and executing complex, creative natural language generation (NLG) tasks. Yet, this flexibility brings new challenges, as it introduces new degrees of freedom in formulating the task inputs and instructions and in evaluating model performance. To facilitate the exploration of creative NLG tasks, we propose a three-component research framework that consists of systematic input manipulation, reference data, and output measurement. We use this framework to explore citation text generation -- a popular scholarly NLP task that lacks consensus on the task definition and evaluation metric and has not yet been tackled within the LLM paradigm. Our results highlight the importance of systematically investigating both task instruction and input configuration when prompting LLMs, and reveal non-trivial relationships between different evaluation metrics used for citation text generation. Additional human generation and human evaluation experiments provide new qualitative insights into the task to guide future research in citation text generation. We make our code and data publicly available.",
    "pdf_link": "https://arxiv.org/abs/2407.04046",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.04046v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04046/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04046v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04046/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04046v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04046/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04046v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04046/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04046v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04046/x5.png"
      }
    ],
    "abstract_cn": "LLM 在处理创造性 NLG 任务时展现出前所未有的灵活性，但也带来了新的挑战。为此，我们设计了一个包含系统输入操作、参考数据和输出测量的三部分研究框架，以探索引用文本生成这一学术 NLP 任务。该任务定义和评估标准尚无共识，且在 LLM 范式中未被触及。我们的研究发现，在引导 LLM 时，系统地调整任务指令和输入配置至关重要，并揭示了不同评估指标间的复杂关系。通过人工生成和评估实验，我们为该任务提供了新的定性见解，以推动未来研究。我们已公开相关代码和数据。",
    "title_cn": "大型语言模型在系统性任务探索中的应用：引文文本生成研究",
    "tags": [
      "LLM应用",
      "学术研究",
      ""
    ]
  },
  {
    "title": "LLMAEL: Large Language Models are Good Context Augmenters for Entity Linking",
    "submit_datetime": "2024年07月04日",
    "abstract": "Entity Linking (EL) models are well-trained at mapping mentions to their corresponding entities according to a given context. However, EL models struggle to disambiguate long-tail entities due to their limited training data. Meanwhile, large language models (LLMs) are more robust at interpreting uncommon mentions. Yet, due to a lack of specialized training, LLMs suffer at generating correct entity IDs. Furthermore, training an LLM to perform EL is cost-intensive. Building upon these insights, we introduce LLM-Augmented Entity Linking LLMAEL, a plug-and-play approach to enhance entity linking through LLM data augmentation. We leverage LLMs as knowledgeable context augmenters, generating mention-centered descriptions as additional input, while preserving traditional EL models for task specific processing. Experiments on 6 standard datasets show that the vanilla LLMAEL outperforms baseline EL models in most cases, while the fine-tuned LLMAEL set the new state-of-the-art results across all 6 benchmarks.",
    "pdf_link": "https://arxiv.org/abs/2407.04020",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.04020v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04020/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04020v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04020/x2.png"
      }
    ],
    "abstract_cn": "实体链接模型虽擅长将提及与上下文中的实体对应，但在处理长尾实体时因数据有限而力不从心。大型语言模型虽能更好地解读罕见提及，却因缺乏针对性训练而在生成准确实体ID上表现欠佳。训练LLM进行实体链接成本高昂。为此，我们提出LLM增强型实体链接（LLMAEL），通过LLM数据增强实现即插即用，提升实体链接性能。我们利用LLM生成以提及为中心的描述作为补充输入，同时结合传统EL模型的任务特定处理。实验结果显示，LLMAEL在多数情况下超越了传统EL模型，而经过微调的版本更是在所有6个基准测试中刷新了记录。",
    "title_cn": "LLMAEL：大型语言模型在实体链接中扮演着优秀的上下文增强角色。",
    "tags": [
      "LLM应用",
      "实体链接",
      ""
    ]
  },
  {
    "title": "Offline Energy-Optimal LLM Serving: Workload-Based Energy Models for LLM Inference on Heterogeneous Systems",
    "submit_datetime": "2024年07月04日",
    "abstract": "The rapid adoption of large language models (LLMs) has led to significant advances in natural language processing and text generation. However, the energy consumed through LLM model inference remains a major challenge for sustainable AI deployment. To address this problem, we model the workload-dependent energy consumption and runtime of LLM inference tasks on heterogeneous GPU-CPU systems. By conducting an extensive characterization study of several state-of-the-art LLMs and analyzing their energy and runtime behavior across different magnitudes of input prompts and output text, we develop accurate (R^2>0.96) energy and runtime models for each LLM. We employ these models to explore an offline, energy-optimal LLM workload scheduling framework. Through a case study, we demonstrate the advantages of energy and accuracy aware scheduling compared to existing best practices.",
    "pdf_link": "https://arxiv.org/abs/2407.04014",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.04014v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04014/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04014v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04014/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04014v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04014/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04014v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04014/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04014v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04014/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04014v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04014/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04014v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04014/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04014v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04014/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04014v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04014/x9.png"
      }
    ],
    "abstract_cn": "随着大型语言模型 (LLM) 的广泛应用，自然语言处理和文本生成领域取得了巨大进展。但 LLM 推理过程中的高能耗仍是可持续 AI 发展的瓶颈。为此，我们针对异构 GPU-CPU 系统，构建了基于工作负载的 LLM 推理能耗与运行时间模型。通过深入分析多个领先 LLM 在不同输入输出规模下的能耗与运行表现，我们建立了高度精确 (R^2>0.96) 的模型。基于此，我们设计了一种离线、能耗最优的 LLM 任务调度框架，并通过实证研究，验证了其在能效与准确性方面的显著优势，超越了当前的行业最佳实践。",
    "title_cn": "离线模式下，LLM 服务追求能量最优：针对异构系统中 LLM 推理，我们构建了基于工作负载的能量模型。",
    "tags": [
      "LLM应用",
      "",
      "信息技术"
    ]
  },
  {
    "title": "Unlocking the Potential of Model Merging for Low-Resource Languages",
    "submit_datetime": "2024年07月04日",
    "abstract": "Adapting large language models (LLMs) to new languages typically involves continual pre-training (CT) followed by supervised fine-tuning (SFT). However, this CT-then-SFT approach struggles with limited data in the context of low-resource languages, failing to balance language modeling and task-solving capabilities. We thus propose model merging as an alternative for low-resource languages, combining models with distinct capabilities into a single model without additional training. We use model merging to develop task-solving LLMs for low-resource languages without SFT data in the target languages. Our experiments based on Llama-2-7B demonstrate that model merging effectively endows LLMs for low-resource languages with task-solving abilities, outperforming CT-then-SFT in scenarios with extremely scarce data. Observing performance saturation in model merging with more training tokens, we further analyze the merging process and introduce a slack variable to the model merging algorithm to mitigate the loss of important parameters, thereby enhancing performance. We hope that model merging can benefit more human languages suffering from data scarcity with its higher data efficiency.",
    "pdf_link": "https://arxiv.org/abs/2407.03994",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.03994v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03994/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03994v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03994/x2.png"
      }
    ],
    "abstract_cn": "将 LLM 适应新语言通常采用持续预训练后进行监督微调的方式。但在低资源语言中，这种先预训练再微调的方法难以平衡语言建模与任务解决能力。为此，我们提出模型合并策略，无需额外训练即可将不同能力的模型融合，为低资源语言打造任务解决型 LLM。基于 Llama-2-7B 的实验显示，模型合并在数据极度匮乏的情况下，仍能有效提升 LLM 的任务解决能力，超越传统预训练加微调的方法。我们还发现，随着训练令牌增加，模型合并性能趋于饱和，因此引入松弛变量优化合并算法，减少关键参数损失，进一步提升性能。我们期待模型合并能以更高的数据效率，助力更多数据稀缺的语言。",
    "title_cn": "探索模型合并技术在低资源语言中的应用潜力",
    "tags": [
      "LLM应用",
      "人工智能",
      "语言技术"
    ]
  },
  {
    "title": "A Survey on Natural Language Counterfactual Generation",
    "submit_datetime": "2024年07月04日",
    "abstract": "Natural Language Counterfactual generation aims to minimally modify a given text such that the modified text will be classified into a different class. The generated counterfactuals provide insight into the reasoning behind a model's predictions by highlighting which words significantly influence the outcomes. Additionally, they can be used to detect model fairness issues or augment the training data to enhance the model's robustness. A substantial amount of research has been conducted to generate counterfactuals for various NLP tasks, employing different models and methodologies. With the rapid growth of studies in this field, a systematic review is crucial to guide future researchers and developers. To bridge this gap, this survey comprehensively overview textual counterfactual generation methods, particularly including those based on Large Language Models. We propose a new taxonomy that categorizes the generation methods into four groups and systematically summarize the metrics for evaluating the generation quality. Finally, we discuss ongoing research challenges and outline promising directions for future work.",
    "pdf_link": "https://arxiv.org/abs/2407.03993",
    "graphs": [],
    "abstract_cn": "自然语言反事实生成通过微调文本，使其被重新分类，揭示了模型预测的关键因素。这些反事实不仅有助于识别模型偏见，还能通过丰富训练数据提升模型稳定性。当前，众多研究致力于探索不同NLP任务中的反事实生成技术。面对该领域的迅猛发展，进行一次系统性回顾显得尤为重要。本次调查深入探讨了基于大型语言模型的文本反事实生成方法，并创新性地将其分为四类，详细阐述了评估生成质量的标准。最后，我们分析了当前研究面临的挑战，并指出了未来研究的可能方向。",
    "title_cn": "自然语言反事实生成研究综述",
    "tags": [
      "LLM理论",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Benchmarking Complex Instruction-Following with Multiple Constraints Composition",
    "submit_datetime": "2024年07月04日",
    "abstract": "Instruction following is one of the fundamental capabilities of large language models (LLMs). As the ability of LLMs is constantly improving, they have been increasingly applied to deal with complex human instructions in real-world scenarios. Therefore, how to evaluate the ability of complex instruction-following of LLMs has become a critical research problem. Existing benchmarks mainly focus on modeling different types of constraints in human instructions while neglecting the composition of different constraints, which is an indispensable constituent in complex instructions. To this end, we propose ComplexBench, a benchmark for comprehensively evaluating the ability of LLMs to follow complex instructions composed of multiple constraints. We propose a hierarchical taxonomy for complex instructions, including 4 constraint types, 19 constraint dimensions, and 4 composition types, and manually collect a high-quality dataset accordingly. To make the evaluation reliable, we augment LLM-based evaluators with rules to effectively verify whether generated texts can satisfy each constraint and composition. Furthermore, we obtain the final evaluation score based on the dependency structure determined by different composition types. ComplexBench identifies significant deficiencies in existing LLMs when dealing with complex instructions with multiple constraints composition.",
    "pdf_link": "https://arxiv.org/abs/2407.03978",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.03978v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03978/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03978v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03978/constraints.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03978v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03978/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03978v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03978/user.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03978v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03978/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03978v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03978/radio.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03978v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03978/coherent.png"
      }
    ],
    "abstract_cn": "随着大规模语言模型（LLM）能力的不断提升，它们在处理现实场景中的复杂指令方面发挥着越来越重要的作用。然而，评估LLM遵循复杂指令的能力仍是一个挑战。为此，我们推出了ComplexBench，这是一个专为全面评估LLM处理多约束复杂指令能力而设计的基准。我们精心设计了一个包含4种约束类型、19个约束维度和4种组合类型的分层分类法，并手动构建了一个高质量数据集。通过规则增强的LLM评估器，我们确保了评估的可靠性，并根据不同组合类型的依赖结构得出最终评分。ComplexBench揭示了现有LLM在应对复杂多约束指令时的明显不足。",
    "title_cn": "复杂指令遵循与多重约束组合的基准测试",
    "tags": [
      "LLM应用",
      "人工智能",
      "软件开发"
    ]
  },
  {
    "title": "LLM Roleplay: Simulating Human-Chatbot Interaction",
    "submit_datetime": "2024年07月04日",
    "abstract": "The development of chatbots requires collecting a large number of human-chatbot dialogues to reflect the breadth of users' sociodemographic backgrounds and conversational goals. However, the resource requirements to conduct the respective user studies can be prohibitively high and often only allow for a narrow analysis of specific dialogue goals and participant demographics. In this paper, we propose LLM-Roleplay: a goal-oriented, persona-based method to automatically generate diverse multi-turn dialogues simulating human-chatbot interaction. LLM-Roleplay can be applied to generate dialogues with any type of chatbot and uses large language models (LLMs) to play the role of textually described personas. To validate our method we collect natural human-chatbot dialogues from different sociodemographic groups and conduct a human evaluation to compare real human-chatbot dialogues with our generated dialogues. We compare the abilities of state-of-the-art LLMs in embodying personas and holding a conversation and find that our method can simulate human-chatbot dialogues with a high indistinguishability rate.",
    "pdf_link": "https://arxiv.org/abs/2407.03974",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.03974v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03974/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03974v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03974/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03974v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03974/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03974v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03974/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03974v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03974/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03974v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03974/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03974v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03974/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03974v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03974/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03974v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03974/dialog_aggregation_app_layout_persona_form.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03974v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03974/dialog_aggregation_app_layout_chat.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03974v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03974/human_evaluation_intro.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03974v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03974/human_evaluation_choice.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03974v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03974/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03974v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03974/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03974v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03974/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03974v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03974/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03974v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03974/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03974v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03974/x14.png"
      }
    ],
    "abstract_cn": "开发聊天机器人需收集大量人机对话，以涵盖用户多样化的社会背景和交流目的。但这类研究的资源成本高昂，常限于特定对话目标和用户群体的狭窄分析。为此，我们提出LLM-Roleplay方法：一种基于角色、目标导向的技术，能自动生成多样化的多轮对话，模拟真实的人机互动。该方法适用于各类聊天机器人，并利用大型语言模型（LLMs）扮演文本描述的角色。为验证其有效性，我们收集了来自不同社会群体的真实人机对话，并通过人类评估对比了真实对话与生成对话。结果显示，我们的方法能高度逼真地模拟人机对话，难以区分真伪。",
    "title_cn": "LLM 角色扮演：模拟人与聊天机器人的互动",
    "tags": [
      "LLM应用",
      "人工智能",
      "聊天机器人"
    ]
  },
  {
    "title": "Improving Sample Efficiency of Reinforcement Learning with Background Knowledge from Large Language Models",
    "submit_datetime": "2024年07月04日",
    "abstract": "Low sample efficiency is an enduring challenge of reinforcement learning (RL). With the advent of versatile large language models (LLMs), recent works impart common-sense knowledge to accelerate policy learning for RL processes. However, we note that such guidance is often tailored for one specific task but loses generalizability. In this paper, we introduce a framework that harnesses LLMs to extract background knowledge of an environment, which contains general understandings of the entire environment, making various downstream RL tasks benefit from one-time knowledge representation. We ground LLMs by feeding a few pre-collected experiences and requesting them to delineate background knowledge of the environment. Afterward, we represent the output knowledge as potential functions for potential-based reward shaping, which has a good property for maintaining policy optimality from task rewards. We instantiate three variants to prompt LLMs for background knowledge, including writing code, annotating preferences, and assigning goals. Our experiments show that these methods achieve significant sample efficiency improvements in a spectrum of downstream tasks from Minigrid and Crafter domains.",
    "pdf_link": "https://arxiv.org/abs/2407.03964",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.03964v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03964/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03964v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03964/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03964v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03964/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03964v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03964/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03964v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03964/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03964v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03964/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03964v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03964/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03964v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03964/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03964v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03964/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03964v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03964/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03964v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03964/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03964v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03964/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03964v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03964/x13.png"
      }
    ],
    "abstract_cn": "强化学习中的低样本效率一直是个难题。借助多功能大型语言模型，我们尝试通过注入常识知识来加速策略学习。但这种定制化指导往往缺乏通用性。为此，我们设计了一个框架，利用LLMs提取环境背景知识，为多种RL任务提供一次性知识支持。通过预先收集的经验，我们让LLMs描述环境背景，并将这些知识转化为潜力函数，确保策略最优性。我们通过编写代码、注释偏好和分配目标三种方式，引导LLMs生成背景知识。实验证明，这些方法在多个领域如Minigrid和Crafter的下游任务中，大幅提升了样本效率。",
    "title_cn": "借助大型语言模型的背景知识，我们致力于提升强化学习的样本效率。",
    "tags": [
      "LLM应用",
      "人工智能",
      "游戏开发"
    ]
  },
  {
    "title": "LLM-jp: A Cross-organizational Project for the Research and Development of Fully Open Japanese LLMs",
    "submit_datetime": "2024年07月04日",
    "abstract": "This paper introduces LLM-jp, a cross-organizational project for the research and development of Japanese large language models (LLMs). LLM-jp aims to develop open-source and strong Japanese LLMs, and as of this writing, more than 1,500 participants from academia and industry are working together for this purpose. This paper presents the background of the establishment of LLM-jp, summaries of its activities, and technical reports on the LLMs developed by LLM-jp. For the latest activities, visit https://llm-jp.nii.ac.jp/en/.",
    "pdf_link": "https://arxiv.org/abs/2407.03963",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.03963v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03963/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03963v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03963/x2.png"
      }
    ],
    "abstract_cn": "本文详述了 LLM-jp 项目，这是一个跨越学术与工业界的合作，致力于研发开源且性能卓越的日本大型语言模型。目前，已有超过 1,500 名参与者携手推进这一目标。文章不仅回顾了 LLM-jp 的成立背景和活动概览，还提供了其开发模型的技术细节。欲获取最新动态，请访问官方网站：https://llm-jp.nii.ac.jp/en/。",
    "title_cn": "LLM-jp 项目旨在跨组织合作，推动完全开放的日本大型语言模型的研究与开发。",
    "tags": [
      "LLM应用",
      "学术界",
      "工业界"
    ]
  },
  {
    "title": "A framework for annotating and modelling intentions behind metaphor use",
    "submit_datetime": "2024年07月04日",
    "abstract": "Metaphors are part of everyday language and shape the way in which we conceptualize the world. Moreover, they play a multifaceted role in communication, making their understanding and generation a challenging task for language models (LMs). While there has been extensive work in the literature linking metaphor to the fulfilment of individual intentions, no comprehensive taxonomy of such intentions, suitable for natural language processing (NLP) applications, is available to present day. In this paper, we propose a novel taxonomy of intentions commonly attributed to metaphor, which comprises 9 categories. We also release the first dataset annotated for intentions behind metaphor use. Finally, we use this dataset to test the capability of large language models (LLMs) in inferring the intentions behind metaphor use, in zero- and in-context few-shot settings. Our experiments show that this is still a challenge for LLMs.",
    "pdf_link": "https://arxiv.org/abs/2407.03952",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.03952v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03952/Genre.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03952v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03952/Novelty.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03952v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03952/0_shot.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03952v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03952/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03952v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03952/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03952v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03952/5_shot.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03952v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03952/5_shot_short.png"
      }
    ],
    "abstract_cn": "隐喻不仅是日常语言的基石，更是我们理解世界的桥梁。在交流中，隐喻的多重角色使其成为语言模型的一大难题。虽然研究已将隐喻与个人意图紧密相连，但适用于NLP的全面意图分类仍付阙如。本文中，我们创新性地提出了一个包含九大类别的隐喻意图分类，并首次发布了一个标注了隐喻使用意图的数据集。通过此数据集，我们检验了大型语言模型在零-shot和few-shot情境下解读隐喻意图的能力，结果显示，这仍是LLMs面临的挑战。",
    "title_cn": "构建一个框架，旨在注释并建模隐喻使用背后的意图。",
    "tags": [
      "LLM应用",
      "语言学",
      ""
    ]
  },
  {
    "title": "Uncertainty-Guided Optimization on Large Language Model Search Trees",
    "submit_datetime": "2024年07月04日",
    "abstract": "Beam search is a standard tree search algorithm when it comes to finding sequences of maximum likelihood, for example, in the decoding processes of large language models. However, it is myopic since it does not take the whole path from the root to a leaf into account. Moreover, it is agnostic to prior knowledge available about the process: For example, it does not consider that the objective being maximized is a likelihood and thereby has specific properties, like being bound in the unit interval. Taking a probabilistic approach, we define a prior belief over the LLMs' transition probabilities and obtain a posterior belief over the most promising paths in each iteration. These beliefs are helpful to define a non-myopic Bayesian-optimization-like acquisition function that allows for a more data-efficient exploration scheme than standard beam search. We discuss how to select the prior and demonstrate in on- and off-model experiments with recent large language models, including Llama-2-7b, that our method achieves higher efficiency than beam search: Our method achieves the same or a higher likelihood while expanding fewer nodes than beam search.",
    "pdf_link": "https://arxiv.org/abs/2407.03951",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.03951v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03951/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03951v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03951/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03951v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03951/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03951v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03951/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03951v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03951/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03951v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03951/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03951v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03951/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03951v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03951/x8.png"
      }
    ],
    "abstract_cn": "Beam search 虽为寻找最大似然序列的标准树搜索算法，却因忽视从根至叶的全路径而显得短视。此外，它对先验知识视而不见，例如，未考虑最大化目标的似然性及其在单位区间内的界定特性。我们采用概率视角，为LLM的转换概率设定先验信念，并在每次迭代中更新最有希望路径的后验信念。这些信念助力我们构建一个非短视、类似贝叶斯优化的获取函数，实现比标准波束搜索更高效的数据探索。通过选择合适的先验，并在包含Llama-2-7b的最新大语言模型上进行实验，我们验证了此方法在扩展更少节点的同时，达到了相同甚至更高的似然性，显著提升了效率。",
    "title_cn": "基于不确定性的优化策略在大规模语言模型搜索树上的应用",
    "tags": [
      "LLM理论",
      "人工智能",
      "机器学习"
    ]
  },
  {
    "title": "Diverse and Fine-Grained Instruction-Following Ability Exploration with Synthetic Data",
    "submit_datetime": "2024年07月04日",
    "abstract": "Instruction-following is particularly crucial for large language models (LLMs) to support diverse user requests. While existing work has made progress in aligning LLMs with human preferences, evaluating their capabilities on instruction following remains a challenge due to complexity and diversity of real-world user instructions. While existing evaluation methods focus on general skills, they suffer from two main shortcomings, i.e., lack of fine-grained task-level evaluation and reliance on singular instruction expression. To address these problems, this paper introduces DINGO, a fine-grained and diverse instruction-following evaluation dataset that has two main advantages: (1) DINGO is based on a manual annotated, fine-grained and multi-level category tree with 130 nodes derived from real-world user requests; (2) DINGO includes diverse instructions, generated by both GPT-4 and human experts. Through extensive experiments, we demonstrate that DINGO can not only provide more challenging and comprehensive evaluation for LLMs, but also provide task-level fine-grained directions to further improve LLMs.",
    "pdf_link": "https://arxiv.org/abs/2407.03942",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.03942v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03942/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03942v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03942/pipeline.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03942v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03942/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03942v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03942/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03942v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03942/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03942v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03942/x5.png"
      }
    ],
    "abstract_cn": "指令遵循对于 LLM 满足多样用户需求至关重要。尽管现有研究在使 LLM 与人类偏好对齐方面有所进展，但评估其在复杂多变的实际指令中的表现仍具挑战。现有评估方法虽关注通用技能，却存在两大短板：缺乏细粒度任务级评估及依赖单一指令表达。为此，本文推出 DINGO 数据集，该集以精细多级类别树为基础，含 130 节点，源自真实用户请求，并融合 GPT-4 与专家智慧生成多样指令。实验表明，DINGO 不仅为 LLM 提供更全面挑战的评估，还细化了任务级指导，助力 LLM 进一步提升。",
    "title_cn": "通过合成数据探索多样且精细的指令遵循能力",
    "tags": [
      "LLM应用",
      "人工智能",
      "数据集"
    ]
  },
  {
    "title": "Narrow Transformer: Starcoder-Based Java-LM For Desktop",
    "submit_datetime": "2024年07月04日",
    "abstract": "This paper presents NT-Java-1.1B, an open-source specialized code language model built on StarCoderBase-1.1B, designed for coding tasks in Java programming. NT-Java-1.1B achieves state-of-the-art performance, surpassing its base model and majority of other models of similar size on MultiPL-E Java code benchmark. While there have been studies on extending large, generic pre-trained models to improve proficiency in specific programming languages like Python, similar investigations on small code models for other programming languages are lacking. Large code models require specialized hardware like GPUs for inference, highlighting the need for research into building small code models that can be deployed on developer desktops. This paper addresses this research gap by focusing on the development of a small Java code model, NT-Java-1.1B, and its quantized versions, which performs comparably to open models around 1.1B on MultiPL-E Java code benchmarks, making them ideal for desktop deployment. This paper establishes the foundation for specialized models across languages and sizes for a family of NT Models.",
    "pdf_link": "https://arxiv.org/abs/2407.03941",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.03941v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03941/event_scores.png"
      }
    ],
    "abstract_cn": "本文推出 NT-Java-1.1B，一款专为 Java 编程量身打造的开源代码语言模型，基于 StarCoderBase-1.1B 构建。NT-Java-1.1B 在 MultiPL-E Java 代码基准测试中表现卓越，超越了基础模型及同类模型。虽然大型通用预训练模型已用于提升 Python 等语言的编程能力，但针对其他编程语言的小型模型研究尚显不足。鉴于大型模型需依赖 GPU 等专用硬件，本文聚焦于开发 NT-Java-1.1B 及其量化版本，这些模型在性能上与 1.1B 规模的开放模型相媲美，非常适合桌面部署，为 NT 系列模型的多样化发展奠定了基础。",
    "title_cn": "精简版 Transformer：基于 Starcoder 的 Java 语言模型，专为桌面设计",
    "tags": [
      "LLM应用",
      "软件开发",
      "人工智能"
    ]
  },
  {
    "title": "Concept Bottleneck Models Without Predefined Concepts",
    "submit_datetime": "2024年07月04日",
    "abstract": "There has been considerable recent interest in interpretable concept-based models such as Concept Bottleneck Models (CBMs), which first predict human-interpretable concepts and then map them to output classes. To reduce reliance on human-annotated concepts, recent works have converted pretrained black-box models into interpretable CBMs post-hoc. However, these approaches predefine a set of concepts, assuming which concepts a black-box model encodes in its representations. In this work, we eliminate this assumption by leveraging unsupervised concept discovery to automatically extract concepts without human annotations or a predefined set of concepts. We further introduce an input-dependent concept selection mechanism that ensures only a small subset of concepts is used across all classes. We show that our approach improves downstream performance and narrows the performance gap to black-box models, while using significantly fewer concepts in the classification. Finally, we demonstrate how large vision-language models can intervene on the final model weights to correct model errors.",
    "pdf_link": "https://arxiv.org/abs/2407.03921",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.03921v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03921/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03921v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03921/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03921v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03921/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03921v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03921/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03921v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03921/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03921v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03921/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03921v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03921/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03921v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03921/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03921v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03921/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03921v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03921/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03921v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03921/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03921v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03921/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03921v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03921/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03921v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03921/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03921v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03921/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03921v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03921/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03921v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03921/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03921v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03921/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03921v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03921/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03921v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03921/x20.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03921v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03921/x21.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03921v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03921/x22.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03921v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03921/electric_ray.jpg"
      }
    ],
    "abstract_cn": "近期，概念瓶颈模型（CBMs）等基于可解释概念的模型备受瞩目，它们先预测可理解的概念，再映射至输出类别。为减少对人工标注概念的依赖，现有研究将预训练的黑箱模型事后转化为可解释的CBMs。然而，这些方法预设了一组概念，假定黑箱模型已编码了这些概念。我们通过无监督概念发现，自动提取概念，无需人工标注或预设概念集，消除了这一假设。此外，我们引入了输入依赖的概念选择机制，确保在所有类别中仅使用少量关键概念。实验表明，我们的方法不仅提升了下游性能，还缩小了与黑箱模型的性能差距，同时大幅减少了所需概念数量。最后，我们展示了大型视觉-语言模型如何通过干预最终模型权重来纠正错误。",
    "title_cn": "无需预设概念的概念瓶颈模型",
    "tags": [
      "LLM应用",
      "人工智能",
      "计算机视觉"
    ]
  },
  {
    "title": "AutoBench: Automatic Testbench Generation and Evaluation Using LLMs for HDL Design",
    "submit_datetime": "2024年07月04日",
    "abstract": "In digital circuit design, testbenches constitute the cornerstone of simulation-based hardware verification. Traditional methodologies for testbench generation during simulation-based hardware verification still remain partially manual, resulting in inefficiencies in testing various scenarios and requiring expensive time from designers. Large Language Models (LLMs) have demonstrated their potential in automating the circuit design flow. However, directly applying LLMs to generate testbenches suffers from a low pass rate. To address this challenge, we introduce AutoBench, the first LLM-based testbench generator for digital circuit design, which requires only the description of the design under test (DUT) to automatically generate comprehensive testbenches. In AutoBench, a hybrid testbench structure and a self-checking system are realized using LLMs. To validate the generated testbenches, we also introduce an automated testbench evaluation framework to evaluate the quality of generated testbenches from multiple perspectives. Experimental results demonstrate that AutoBench achieves a 57% improvement in the testbench pass@1 ratio compared with the baseline that directly generates testbenches using LLMs. For 75 sequential circuits, AutoBench successfully has a 3.36 times testbench pass@1 ratio compared with the baseline. The source codes and experimental results are open-sourced at this link: https://github.com/AutoBench/AutoBench",
    "pdf_link": "https://arxiv.org/abs/2407.03891",
    "graphs": [],
    "abstract_cn": "在数字电路设计领域，测试平台是硬件验证的基石。传统方法在生成测试平台时仍依赖部分手动操作，这不仅效率低下，还耗费设计师大量时间。为此，我们推出了AutoBench，这是首个基于大型语言模型（LLM）的自动化测试平台生成器，仅需待测设计的描述即可自动创建全面测试平台。AutoBench通过LLM实现了混合结构和自检系统，并引入了一个自动评估框架，从多角度评估测试平台质量。实验显示，AutoBench在通过率上比传统方法提升了57%，对75个顺序电路的测试平台通过率更是基线的3.36倍。所有源代码和实验结果已在GitHub开源。",
    "title_cn": "AutoBench：借助 LLM 实现 HDL 设计的自动化测试台生成与评估",
    "tags": [
      "LLM应用",
      "电子工程",
      "硬件验证"
    ]
  },
  {
    "title": "DART: Deep Adversarial Automated Red Teaming for LLM Safety",
    "submit_datetime": "2024年07月04日",
    "abstract": "Manual Red teaming is a commonly-used method to identify vulnerabilities in large language models (LLMs), which, is costly and unscalable. In contrast, automated red teaming uses a Red LLM to automatically generate adversarial prompts to the Target LLM, offering a scalable way for safety vulnerability detection. However, the difficulty of building a powerful automated Red LLM lies in the fact that the safety vulnerabilities of the Target LLM are dynamically changing with the evolution of the Target LLM. To mitigate this issue, we propose a Deep Adversarial Automated Red Teaming (DART) framework in which the Red LLM and Target LLM are deeply and dynamically interacting with each other in an iterative manner. In each iteration, in order to generate successful attacks as many as possible, the Red LLM not only takes into account the responses from the Target LLM, but also adversarially adjust its attacking directions by monitoring the global diversity of generated attacks across multiple iterations. Simultaneously, to explore dynamically changing safety vulnerabilities of the Target LLM, we allow the Target LLM to enhance its safety via an active learning based data selection mechanism. Experimential results demonstrate that DART significantly reduces the safety risk of the target LLM. For human evaluation on Anthropic Harmless dataset, compared to the instruction-tuning target LLM, DART eliminates the violation risks by 53.4\\%. We will release the datasets and codes of DART soon.",
    "pdf_link": "https://arxiv.org/abs/2407.03876",
    "graphs": [],
    "abstract_cn": "手动红队虽常用于发现大型语言模型（LLM）的漏洞，但成本高昂且难以扩展。自动化红队则通过红色LLM自动生成对抗提示，为安全漏洞检测提供了可扩展的解决方案。然而，构建强大的自动化红色LLM面临挑战，因为目标LLM的安全漏洞随其发展而动态变化。为此，我们设计了深度对抗自动化红队（DART）框架，使红色LLM与目标LLM在迭代中深度动态交互。每次迭代中，红色LLM不仅依据目标LLM的反馈，还通过监控多轮攻击的全球多样性来调整攻击策略，以最大化成功攻击的数量。同时，目标LLM通过基于主动学习的数据选择机制增强安全性，以应对动态变化的安全漏洞。实验显示，DART大幅降低了目标LLM的安全风险。在Anthropic Harmless数据集的人类评估中，DART相比指令调优的目标LLM，违规风险降低了53.4%。我们即将发布DART的数据集和代码。",
    "title_cn": "DART：深度对抗技术助力 LLM 安全，实现自动红队测试",
    "tags": [
      "LLM应用",
      "网络安全",
      "人工智能"
    ]
  },
  {
    "title": "Anthropocentric bias and the possibility of artificial cognition",
    "submit_datetime": "2024年07月04日",
    "abstract": "Evaluating the cognitive capacities of large language models (LLMs) requires overcoming not only anthropomorphic but also anthropocentric biases. This article identifies two types of anthropocentric bias that have been neglected: overlooking how auxiliary factors can impede LLM performance despite competence (Type-I), and dismissing LLM mechanistic strategies that differ from those of humans as not genuinely competent (Type-II). Mitigating these biases necessitates an empirically-driven, iterative approach to mapping cognitive tasks to LLM-specific capacities and mechanisms, which can be done by supplementing carefully designed behavioral experiments with mechanistic studies.",
    "pdf_link": "https://arxiv.org/abs/2407.03859",
    "graphs": [],
    "abstract_cn": "评估LLM的认知能力，需超越拟人化与人类中心主义的偏见。本文揭示了两种常被忽视的偏见：一是忽略辅助因素在LLM能力充足时对其性能的阻碍（I型），二是误将LLM独特的机械策略视为非真正能力（II型）。为减少这些偏见，我们需采用实证驱动、迭代的方法，通过精心设计的行为实验与机制研究相结合，精准映射认知任务至LLM的特定能力和机制。",
    "title_cn": "探讨人类中心主义偏见与人工认知的潜在可能",
    "tags": [
      "LLM理论",
      "人工智能",
      "认知科学"
    ]
  },
  {
    "title": "Q-Adapter: Training Your LLM Adapter as a Residual Q-Function",
    "submit_datetime": "2024年07月04日",
    "abstract": "We consider the problem of adapting Large Language Models (LLMs) pre-trained with Reinforcement Learning from Human Feedback (RLHF) to downstream preference data. Naive approaches to achieve this could be supervised fine-tuning on preferred responses or reinforcement learning with a learned reward model. However, the LLM runs the risk of forgetting its initial knowledge as the fine-tuning progresses. To customize the LLM while preserving its existing capabilities, this paper proposes a novel method, named as Q-Adapter. We start by formalizing LLM adaptation as a problem of maximizing the linear combination of two rewards, one of which corresponds to the reward optimized by the pre-trained LLM and the other to the downstream preference data. Although both rewards are unknown, we show that this can be solved by directly learning a new module from the preference data that approximates the \\emph{residual Q-function}. We consider this module to be an adapter because the original pre-trained LLM, together with it, can form the optimal customised LLM. Empirically, experiments on a range of domain-specific tasks and safety alignment tasks illustrate the superiority of Q-Adapter in both anti-forgetting and learning from new preferences.",
    "pdf_link": "https://arxiv.org/abs/2407.03856",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.03856v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03856/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03856v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03856/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03856v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03856/x3.png"
      }
    ],
    "abstract_cn": "本文探讨了如何将通过人类反馈强化学习预训练的 LLM 适应到下游偏好数据，提出了一种名为 Q-Adapter 的新方法。该方法通过学习一个新模块，近似于残差 Q-函数，从而在保留 LLM 原有能力的同时实现定制化。实验证明，Q-Adapter 在防止知识遗忘和适应新偏好方面表现出色。",
    "title_cn": "Q-Adapter：训练 LLM Adapter 成为残差 Q-Function",
    "tags": [
      "LLM应用",
      "人工智能",
      "机器学习"
    ]
  },
  {
    "title": "HYBRINFOX at CheckThat! 2024 -- Task 1: Enhancing Language Models with Structured Information for Check-Worthiness Estimation",
    "submit_datetime": "2024年07月04日",
    "abstract": "This paper summarizes the experiments and results of the HYBRINFOX team for the CheckThat! 2024 - Task 1 competition. We propose an approach enriching Language Models such as RoBERTa with embeddings produced by triples (subject ; predicate ; object) extracted from the text sentences. Our analysis of the developmental data shows that this method improves the performance of Language Models alone. On the evaluation data, its best performance was in English, where it achieved an F1 score of 71.1 and ranked 12th out of 27 candidates. On the other languages (Dutch and Arabic), it obtained more mixed results. Future research tracks are identified toward adapting this processing pipeline to more recent Large Language Models.",
    "pdf_link": "https://arxiv.org/abs/2407.03850",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.03850v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03850/x1.png"
      }
    ],
    "abstract_cn": "HYBRINFOX团队在CheckThat! 2024竞赛中探索了通过三元组嵌入增强语言模型（如RoBERTa）的方法。分析表明，此法能提升模型性能，尤其在英语中表现突出，F1分数达71.1，位列第12。然而，在荷兰语和阿拉伯语中表现不一。未来研究将聚焦于将此流程优化以适配更先进的巨型语言模型。",
    "title_cn": "HYBRINFOX 在 CheckThat! 2024 的任务 1 中，旨在通过整合结构化信息来提升语言模型的可核查性估计能力。",
    "tags": [
      "LLM应用",
      "人工智能",
      ""
    ]
  },
  {
    "title": "On the Benchmarking of LLMs for Open-Domain Dialogue Evaluation",
    "submit_datetime": "2024年07月04日",
    "abstract": "Large Language Models (LLMs) have showcased remarkable capabilities in various Natural Language Processing tasks. For automatic open-domain dialogue evaluation in particular, LLMs have been seamlessly integrated into evaluation frameworks, and together with human evaluation, compose the backbone of most evaluations. However, existing evaluation benchmarks often rely on outdated datasets and evaluate aspects like Fluency and Relevance, which fail to adequately capture the capabilities and limitations of state-of-the-art chatbot models.\n  This paper critically examines current evaluation benchmarks, highlighting that the use of older response generators and quality aspects fail to accurately reflect modern chatbot capabilities. A small annotation experiment on a recent LLM-generated dataset (SODA) reveals that LLM evaluators such as GPT-4 struggle to detect actual deficiencies in dialogues generated by current LLM chatbots.",
    "pdf_link": "https://arxiv.org/abs/2407.03841",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.03841v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03841/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03841v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03841/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03841v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03841/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03841v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03841/x4.png"
      }
    ],
    "abstract_cn": "LLM 在 NLP 任务中表现卓越，尤其在自动开放域对话评估中，它们与人类评估共同构成了评估的核心。但现有基准多依赖过时数据集，仅评估流畅性和相关性，未能全面反映现代聊天机器人的真实能力。本文深入分析了这些基准的不足，并通过 SODA 数据集的实验表明，即使是先进的 LLM 评估器如 GPT-4，也难以准确识别当前聊天机器人对话中的缺陷。",
    "title_cn": "大型语言模型在开放域对话评估中的基准测试研究",
    "tags": [
      "LLM应用",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Cognitive Modeling with Scaffolded LLMs: A Case Study of Referential Expression Generation",
    "submit_datetime": "2024年07月04日",
    "abstract": "To what extent can LLMs be used as part of a cognitive model of language generation? In this paper, we approach this question by exploring a neuro-symbolic implementation of an algorithmic cognitive model of referential expression generation by Dale & Reiter (1995). The symbolic task analysis implements the generation as an iterative procedure that scaffolds symbolic and gpt-3.5-turbo-based modules. We compare this implementation to an ablated model and a one-shot LLM-only baseline on the A3DS dataset (Tsvilodub & Franke, 2023). We find that our hybrid approach is cognitively plausible and performs well in complex contexts, while allowing for more open-ended modeling of language generation in a larger domain.",
    "pdf_link": "https://arxiv.org/abs/2407.03805",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.03805v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03805/Screenshot-prettified.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03805v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03805/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03805v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03805/x2.png"
      }
    ],
    "abstract_cn": "本文探讨了LLMs在语言生成认知模型中的应用，通过神经符号方法实现了Dale & Reiter（1995）的指代表达生成模型。我们设计的迭代过程结合了符号与gpt-3.5-turbo模块，与简化模型及一次性LLM基线在A3DS数据集上进行了对比。结果显示，我们的混合方法不仅在认知上合理，且在复杂情境中表现优异，为语言生成提供了更广阔、更开放的建模空间。",
    "title_cn": "基于脚手架的大型语言模型在认知建模中的应用：指代表达生成研究案例",
    "tags": [
      "LLM应用",
      "人工智能",
      "语言处理"
    ]
  },
  {
    "title": "Assessing Consensus of Developers' Views on Code Readability",
    "submit_datetime": "2024年07月04日",
    "abstract": "The rapid rise of Large Language Models (LLMs) has changed software development, with tools like Copilot, JetBrains AI Assistant, and others boosting developers' productivity. However, developers now spend more time reviewing code than writing it, highlighting the importance of Code Readability for code comprehension. Our previous research found that existing Code Readability models were inaccurate in representing developers' notions and revealed a low consensus among developers, highlighting a need for further investigations in this field.\n  Building on this, we surveyed 10 Java developers with similar coding experience to evaluate their consensus on Code Readability assessments and related aspects. We found significant agreement among developers on Code Readability evaluations and identified specific code aspects strongly correlated with Code Readability. Overall, our study sheds light on Code Readability within LLM contexts, offering insights into how these models can align with developers' perceptions of Code Readability, enhancing software development in the AI era.",
    "pdf_link": "https://arxiv.org/abs/2407.03790",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.03790v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03790/x1.png"
      }
    ],
    "abstract_cn": "随着大型语言模型（LLM）的兴起，如 Copilot 和 JetBrains AI 助手等工具已显著提升开发者效率。然而，开发者如今更多时间用于代码审查而非编写，凸显了代码可读性的关键作用。我们的先前研究揭示现有模型未能准确反映开发者对可读性的理解，且开发者间共识不足，这促使我们深入探索。  为此，我们调研了10位经验相当的 Java 开发者，旨在探求他们对代码可读性的共识。结果显示，开发者们在评估可读性时展现出高度一致，并明确了影响可读性的关键代码特征。本研究不仅阐明了 LLM 环境下的代码可读性问题，更为模型如何契合开发者认知提供了洞见，助力 AI 时代软件开发的优化。",
    "title_cn": "探究开发者对代码可读性共识的评估",
    "tags": [
      "LLM应用",
      "软件开发",
      "人工智能"
    ]
  },
  {
    "title": "Meta-optimized Angular Margin Contrastive Framework for Video-Language Representation Learning",
    "submit_datetime": "2024年07月04日",
    "abstract": "Data quality stands at the forefront of deciding the effectiveness of video-language representation learning. However, video-text pairs in previous data typically do not align perfectly with each other, which might lead to video-language representations that do not accurately reflect cross-modal semantics. Moreover, previous data also possess an uneven distribution of concepts, thereby hampering the downstream performance across unpopular subjects. To address these problems, we propose a contrastive objective with a subtractive angular margin to regularize cross-modal representations in their effort to reach perfect similarity. Furthermore, to adapt to the non-uniform concept distribution, we propose a multi-layer perceptron (MLP)-parameterized weighting function that maps loss values to sample weights which enable dynamic adjustment of the model's focus throughout the training. With the training guided by a small amount of unbiased meta-data and augmented by video-text data generated by large vision-language model, we improve video-language representations and achieve superior performances on commonly used video question answering and text-video retrieval datasets.",
    "pdf_link": "https://arxiv.org/abs/2407.03788",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.03788v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03788/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03788v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03788/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03788v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03788/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03788v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03788/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03788v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03788/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03788v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03788/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03788v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03788/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03788v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03788/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03788v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03788/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03788v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03788/x10.png"
      }
    ],
    "abstract_cn": "数据质量是视频-语言表示学习有效性的关键。然而，以往的视频-文本对往往无法完美匹配，导致跨模态语义反映不准确。同时，概念分布的不均也影响了特定主题的下游表现。为此，我们引入了带有减法角边距的对比目标，以优化跨模态表示的相似性。针对概念分布的不均，我们设计了由MLP参数化的权重函数，动态调整模型关注点。在无偏元数据和大型视觉-语言模型生成数据的辅助下，我们显著提升了视频-语言表示的质量，并在视频问答和文本-视频检索等任务中取得了卓越成绩。",
    "title_cn": "视频-语言表示学习的元优化角度边缘对比框架",
    "tags": [
      "LLM应用",
      "视频处理",
      "人工智能"
    ]
  },
  {
    "title": "From Data to Commonsense Reasoning: The Use of Large Language Models for Explainable AI",
    "submit_datetime": "2024年07月04日",
    "abstract": "Commonsense reasoning is a difficult task for a computer, but a critical skill for an artificial intelligence (AI). It can enhance the explainability of AI models by enabling them to provide intuitive and human-like explanations for their decisions. This is necessary in many areas especially in question answering (QA), which is one of the most important tasks of natural language processing (NLP). Over time, a multitude of methods have emerged for solving commonsense reasoning problems such as knowledge-based approaches using formal logic or linguistic analysis. In this paper, we investigate the effectiveness of large language models (LLMs) on different QA tasks with a focus on their abilities in reasoning and explainability. We study three LLMs: GPT-3.5, Gemma and Llama 3. We further evaluate the LLM results by means of a questionnaire. We demonstrate the ability of LLMs to reason with commonsense as the models outperform humans on different datasets. While GPT-3.5's accuracy ranges from 56% to 93% on various QA benchmarks, Llama 3 achieved a mean accuracy of 90% on all eleven datasets. Thereby Llama 3 is outperforming humans on all datasets with an average 21% higher accuracy over ten datasets. Furthermore, we can appraise that, in the sense of explainable artificial intelligence (XAI), GPT-3.5 provides good explanations for its decisions. Our questionnaire revealed that 66% of participants rated GPT-3.5's explanations as either \"good\" or \"excellent\". Taken together, these findings enrich our understanding of current LLMs and pave the way for future investigations of reasoning and explainability.",
    "pdf_link": "https://arxiv.org/abs/2407.03778",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.03778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03778/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03778/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03778/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03778/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03778/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03778/x6.png"
      }
    ],
    "abstract_cn": "常识推理对计算机而言颇具挑战，但对AI至关重要。它通过赋予AI模型提供直观、类人解释的能力，增强了模型的可解释性。这在问答（QA）等众多领域尤为关键，QA是自然语言处理（NLP）的核心任务。随着时间推移，多种方法应运而生，如基于形式逻辑或语言分析的知识库方法，以解决常识推理难题。本文探讨了大型语言模型（LLMs）在不同QA任务中的表现，特别关注其推理与可解释性。我们分析了GPT-3.5、Gemma和Llama 3三个模型，并通过问卷评估了它们的表现。结果显示，LLMs在利用常识推理方面超越了人类，GPT-3.5在多个QA基准上的准确率介于56%至93%，而Llama 3在十一个数据集上的平均准确率达90%，平均超越人类21%。此外，GPT-3.5在可解释性方面表现出色，66%的受访者认为其解释“良好”或“优秀”。这些发现不仅深化了我们对当前LLMs的理解，也为未来推理与可解释性的研究奠定了基础。",
    "title_cn": "大型语言模型助力 AI 从数据解读到常识推理，为可解释 AI 开辟新径。",
    "tags": [
      "LLM应用",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Convolutional vs Large Language Models for Software Log Classification in Edge-Deployable Cellular Network Testing",
    "submit_datetime": "2024年07月04日",
    "abstract": "Software logs generated by sophisticated network emulators in the telecommunications industry, such as VIAVI TM500, are extremely complex, often comprising tens of thousands of text lines with minimal resemblance to natural language. Only specialised expert engineers can decipher such logs and troubleshoot defects in test runs. While AI offers a promising solution for automating defect triage, potentially leading to massive revenue savings for companies, state-of-the-art large language models (LLMs) suffer from significant drawbacks in this specialised domain. These include a constrained context window, limited applicability to text beyond natural language, and high inference costs. To address these limitations, we propose a compact convolutional neural network (CNN) architecture that offers a context window spanning up to 200,000 characters and achieves over 96% accuracy (F1>0.9) in classifying multifaceted software logs into various layers in the telecommunications protocol stack. Specifically, the proposed model is capable of identifying defects in test runs and triaging them to the relevant department, formerly a manual engineering process that required expert knowledge. We evaluate several LLMs; LLaMA2-7B, Mixtral 8x7B, Flan-T5, BERT and BigBird, and experimentally demonstrate their shortcomings in our specialized application. Despite being lightweight, our CNN significantly outperforms LLM-based approaches in telecommunications log classification while minimizing the cost of production. Our defect triaging AI model is deployable on edge devices without dedicated hardware and widely applicable across software logs in various industries.",
    "pdf_link": "https://arxiv.org/abs/2407.03759",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.03759v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03759/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03759v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03759/char_len_histograms.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03759v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03759/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03759v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03759/data_distribution_2fig.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03759v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03759/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03759v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03759/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03759v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03759/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03759v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03759/embedding_extraction.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03759v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03759/outlier_removal_boxplot.png"
      }
    ],
    "abstract_cn": "电信行业中，复杂的网络模拟器如VIAVI TM500生成的软件日志极为繁琐，包含数万行与自然语言相去甚远的文本。唯有专业工程师能解读这些日志，解决测试中的缺陷。AI虽提供了自动化缺陷分类的希望，能大幅节省公司收入，但现有大型语言模型（LLMs）在此领域仍显不足，如上下文窗口受限、对非自然语言文本的适用性有限及高推理成本。为此，我们设计了一种紧凑的卷积神经网络（CNN）架构，其上下文窗口可达20万字符，分类电信协议栈日志准确率超96%（F1>0.9）。该模型能自动识别并分类测试缺陷至相关部门，取代了以往需专家知识的手动流程。我们测试了多种LLMs，如LLaMA2-7B、Mixtral 8x7B等，并验证了它们在特定应用中的局限。尽管轻巧，我们的CNN在电信日志分类上远胜LLM方法，同时降低了成本。此AI模型无需专用硬件，即可在边缘设备上部署，广泛适用于各行业软件日志。",
    "title_cn": "边缘部署蜂窝网络测试中，卷积神经网络与大型语言模型在软件日志分类上的较量",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Argument Mining in Data Scarce Settings: Cross-lingual Transfer and Few-shot Techniques",
    "submit_datetime": "2024年07月04日",
    "abstract": "Recent research on sequence labelling has been exploring different strategies to mitigate the lack of manually annotated data for the large majority of the world languages. Among others, the most successful approaches have been based on (i) the cross-lingual transfer capabilities of multilingual pre-trained language models (model-transfer), (ii) data translation and label projection (data-transfer) and (iii), prompt-based learning by reusing the mask objective to exploit the few-shot capabilities of pre-trained language models (few-shot). Previous work seems to conclude that model-transfer outperforms data-transfer methods and that few-shot techniques based on prompting are superior to updating the model's weights via fine-tuning. In this paper, we empirically demonstrate that, for Argument Mining, a sequence labelling task which requires the detection of long and complex discourse structures, previous insights on cross-lingual transfer or few-shot learning do not apply. Contrary to previous work, we show that for Argument Mining data transfer obtains better results than model-transfer and that fine-tuning outperforms few-shot methods. Regarding the former, the domain of the dataset used for data-transfer seems to be a deciding factor, while, for few-shot, the type of task (length and complexity of the sequence spans) and sampling method prove to be crucial.",
    "pdf_link": "https://arxiv.org/abs/2407.03748",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.03748v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03748/neoplasm_ft_entlm_pointplot.png"
      }
    ],
    "abstract_cn": "近期研究探索了多种策略以解决全球多数语言缺乏手动标注数据的问题，其中最有效的方法包括多语言预训练模型的跨语言迁移、数据翻译与标签投影以及基于提示的少样本学习。以往研究表明，模型迁移胜过数据迁移，且提示式少样本学习优于模型微调。然而，本文通过论证挖掘任务的实证分析发现，这些先前的结论并不适用。我们发现，在论证挖掘中，数据迁移效果优于模型迁移，且微调技术超越了少样本学习。数据集的领域特性对数据迁移至关重要，而任务的复杂性与采样策略则对少样本学习影响显著。",
    "title_cn": "在数据稀缺的情境下，论证挖掘借助跨语言迁移和少量样本技术，探索新的可能性。",
    "tags": [
      "LLM理论",
      "",
      "机器学习"
    ]
  },
  {
    "title": "Text2TimeSeries: Enhancing Financial Forecasting through Time Series Prediction Updates with Event-Driven Insights from Large Language Models",
    "submit_datetime": "2024年07月04日",
    "abstract": "Time series models, typically trained on numerical data, are designed to forecast future values. These models often rely on weighted averaging techniques over time intervals. However, real-world time series data is seldom isolated and is frequently influenced by non-numeric factors. For instance, stock price fluctuations are impacted by daily random events in the broader world, with each event exerting a unique influence on price signals. Previously, forecasts in financial markets have been approached in two main ways: either as time-series problems over price sequence or sentiment analysis tasks. The sentiment analysis tasks aim to determine whether news events will have a positive or negative impact on stock prices, often categorizing them into discrete labels. Recognizing the need for a more comprehensive approach to accurately model time series prediction, we propose a collaborative modeling framework that incorporates textual information about relevant events for predictions. Specifically, we leverage the intuition of large language models about future changes to update real number time series predictions. We evaluated the effectiveness of our approach on financial market data.",
    "pdf_link": "https://arxiv.org/abs/2407.03689",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.03689v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03689/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03689v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03689/x2.png"
      }
    ],
    "abstract_cn": "时间序列模型通常基于数值数据预测未来，但现实中的时间序列数据常受非数值因素影响。例如，股票价格受全球随机事件影响，每个事件对价格产生独特影响。传统方法要么侧重于价格序列的时间序列分析，要么进行情感分析，判断新闻事件对股价的正面或负面影响。为更全面地预测时间序列，我们提出一种结合文本信息的协作建模框架，利用大型语言模型对未来变化的洞察，优化实数时间序列预测。我们在金融市场数据上验证了这一方法的有效性。",
    "title_cn": "Text2TimeSeries：借助大型语言模型的事件驱动洞察，实时更新时间序列预测，助力财务预测更精准。",
    "tags": [
      "LLM应用",
      "",
      "时间序列分析"
    ]
  },
  {
    "title": "STOC-TOT: Stochastic Tree-of-Thought with Constrained Decoding for Complex Reasoning in Multi-Hop Question Answering",
    "submit_datetime": "2024年07月04日",
    "abstract": "Multi-hop question answering (MHQA) requires a model to retrieve and integrate information from multiple passages to answer a complex question. Recent systems leverage the power of large language models and integrate evidence retrieval with reasoning prompts (e.g., chain-of-thought reasoning) for the MHQA task. However, the complexities in the question types (bridge v.s. comparison questions) and the reasoning types (sequential v.s. parallel reasonings) require more novel and fine-grained prompting methods to enhance the performance of MHQA under the zero-shot setting. In this paper, we propose STOC-TOT, a stochastic tree-of-thought reasoning prompting method with constrained decoding for MHQA and conduct a detailed comparison with other reasoning prompts on different question types and reasoning types. Specifically, we construct a tree-like reasoning structure by prompting the model to break down the original question into smaller sub-questions to form different reasoning paths. In addition, we prompt the model to provide a probability estimation for each reasoning path at each reasoning step. At answer time, we conduct constrained decoding on the model to generate more grounded answers and reduce hallucination. Experiments comparing STOC-TOT with two MHQA datasets and five large language models showed that our framework outperforms other reasoning prompts by a significant margin.",
    "pdf_link": "https://arxiv.org/abs/2407.03687",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.03687v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03687/MHQA_Example.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03687v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03687/Overall_5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03687v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03687/Abl1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03687v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03687/Abl2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03687v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03687/Abl3.png"
      }
    ],
    "abstract_cn": "多跳问答（MHQA）任务要求模型从多个段落中检索并整合信息，以解答复杂问题。近期研究结合大型语言模型的能力，通过集成证据检索与推理提示（如思维链推理）来提升MHQA的表现。然而，问题类型（如桥梁问题与比较问题）及推理方式（顺序或并行）的多样性，促使我们探索更精细的提示策略，以在零-shot环境下优化MHQA性能。本文提出的STOC-TOT方法，通过随机思维树推理与约束解码，有效应对了这一挑战。我们构建了树状推理结构，引导模型将复杂问题分解为子问题，形成多条推理路径，并在每一步推理中评估各路径的概率。实验结果表明，STOC-TOT在两个MHQA数据集与五个大型语言模型上的表现，均显著超越了现有推理提示方法。",
    "title_cn": "STOC-TOT：一种结合约束解码的随机思维树方法，专为多跳问答中的复杂推理设计。",
    "tags": [
      "LLM应用",
      "问答系统",
      "人工智能"
    ]
  },
  {
    "title": "Improving Self Consistency in LLMs through Probabilistic Tokenization",
    "submit_datetime": "2024年07月04日",
    "abstract": "Prior research has demonstrated noticeable performance gains through the use of probabilistic tokenizations, an approach that involves employing multiple tokenizations of the same input string during the training phase of a language model. Despite these promising findings, modern large language models (LLMs) have yet to be trained using probabilistic tokenizations. Interestingly, while the tokenizers of these contemporary LLMs have the capability to generate multiple tokenizations, this property remains underutilized.\n  In this work, we propose a novel method to leverage the multiple tokenization capabilities of modern LLM tokenizers, aiming to enhance the self-consistency of LLMs in reasoning tasks. Our experiments indicate that when utilizing probabilistic tokenizations, LLMs generate logically diverse reasoning paths, moving beyond mere surface-level linguistic diversity.We carefully study probabilistic tokenization and offer insights to explain the self consistency improvements it brings through extensive experimentation on 5 LLM families and 4 reasoning benchmarks.",
    "pdf_link": "https://arxiv.org/abs/2407.03678",
    "graphs": [],
    "abstract_cn": "先前研究表明，通过在训练阶段对同一输入采用多种分词方式的概率性方法，可以显著提升语言模型的性能。然而，现代大型语言模型 (LLM) 尚未充分利用这一技术。本研究提出一种新方法，旨在通过利用 LLM 分词器的多分词能力，增强其在推理任务中的自我一致性。实验显示，概率性分词不仅增加了语言多样性，还促进了逻辑上多样化的推理路径。我们通过在多个 LLM 系列和推理基准上的实验，深入探讨了这一方法，并揭示了其对自我一致性改进的机制。",
    "title_cn": "借助概率标记化技术，提升大型语言模型中的自我一致性",
    "tags": [
      "LLM理论",
      "人工智能",
      ""
    ]
  },
  {
    "title": "GPT-4 vs. Human Translators: A Comprehensive Evaluation of Translation Quality Across Languages, Domains, and Expertise Levels",
    "submit_datetime": "2024年07月04日",
    "abstract": "This study comprehensively evaluates the translation quality of Large Language Models (LLMs), specifically GPT-4, against human translators of varying expertise levels across multiple language pairs and domains. Through carefully designed annotation rounds, we find that GPT-4 performs comparably to junior translators in terms of total errors made but lags behind medium and senior translators. We also observe the imbalanced performance across different languages and domains, with GPT-4's translation capability gradually weakening from resource-rich to resource-poor directions. In addition, we qualitatively study the translation given by GPT-4 and human translators, and find that GPT-4 translator suffers from literal translations, but human translators sometimes overthink the background information. To our knowledge, this study is the first to evaluate LLMs against human translators and analyze the systematic differences between their outputs, providing valuable insights into the current state of LLM-based translation and its potential limitations.",
    "pdf_link": "https://arxiv.org/abs/2407.03658",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.03658v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03658/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03658v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03658/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03658v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03658/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03658v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03658/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03658v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03658/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03658v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03658/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03658v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03658/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03658v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03658/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03658v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03658/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03658v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03658/annotation_system_screenshot.jpg"
      }
    ],
    "abstract_cn": "本研究全面对比了GPT-4与不同水平的人类翻译者在多语言多领域的翻译质量。研究发现，GPT-4在错误总数上与初级翻译者相当，但不及中级和高级翻译者。GPT-4在资源丰富的语言方向表现较好，而在资源匮乏的方向则逐渐减弱。此外，GPT-4倾向于字面翻译，而人类翻译者有时会过度解读背景信息。这是首次系统比较LLM与人类翻译的差异，为理解当前基于LLM的翻译技术及其局限性提供了重要视角。",
    "title_cn": "GPT-4 与人类翻译者的较量：全面评估翻译质量在多语言、多领域及不同专业水平的表现",
    "tags": [
      "LLM应用",
      "翻译行业",
      "人工智能"
    ]
  },
  {
    "title": "WildDESED: An LLM-Powered Dataset for Wild Domestic Environment Sound Event Detection System",
    "submit_datetime": "2024年07月04日",
    "abstract": "This work aims to advance sound event detection (SED) research by presenting a new large language model (LLM)-powered dataset namely wild domestic environment sound event detection (WildDESED). It is crafted as an extension to the original DESED dataset to reflect diverse acoustic variability and complex noises in home settings. We leveraged LLMs to generate eight different domestic scenarios based on target sound categories of the DESED dataset. Then we enriched the scenarios with a carefully tailored mixture of noises selected from AudioSet and ensured no overlap with target sound. We consider widely popular convolutional neural recurrent network to study WildDESED dataset, which depicts its challenging nature. We then apply curriculum learning by gradually increasing noise complexity to enhance the model's generalization capabilities across various noise levels. Our results with this approach show improvements within the noisy environment, validating the effectiveness on the WildDESED dataset promoting noise-robust SED advancements.",
    "pdf_link": "https://arxiv.org/abs/2407.03656",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.03656v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03656/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03656v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03656/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03656v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03656/Different_Noise_Chart_1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03656v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03656/Scenrios_chart.png"
      }
    ],
    "abstract_cn": "本研究通过引入由大型语言模型支持的新数据集 WildDESED，旨在推动声音事件检测研究。作为 DESED 的扩展，WildDESED 反映了家庭环境中的声学多样性和复杂噪音。我们利用 LLM 生成了八种家庭场景，并精心混合了来自 AudioSet 的噪音，确保与目标声音无重叠。采用卷积神经循环网络分析 WildDESED，揭示其挑战性。通过逐步增加噪音复杂性的课程学习，我们提升了模型在不同噪音环境下的泛化能力。实验结果表明，在嘈杂环境中性能提升，证实了 WildDESED 在推动噪音鲁棒 SED 技术发展中的有效性。",
    "title_cn": "WildDESED：一款由 LLM 赋能的数据集，专为家庭环境中的声音事件检测系统设计。",
    "tags": [
      "LLM应用",
      "家庭环境",
      "声音事件检测"
    ]
  },
  {
    "title": "An Interactive Multi-modal Query Answering System with Retrieval-Augmented Large Language Models",
    "submit_datetime": "2024年07月04日",
    "abstract": "Retrieval-augmented Large Language Models (LLMs) have reshaped traditional query-answering systems, offering unparalleled user experiences. However, existing retrieval techniques often struggle to handle multi-modal query contexts. In this paper, we present an interactive Multi-modal Query Answering (MQA) system, empowered by our newly developed multi-modal retrieval framework and navigation graph index, integrated with cutting-edge LLMs. It comprises five core components: Data Preprocessing, Vector Representation, Index Construction, Query Execution, and Answer Generation, all orchestrated by a dedicated coordinator to ensure smooth data flow from input to answer generation. One notable aspect of MQA is its utilization of contrastive learning to assess the significance of different modalities, facilitating precise measurement of multi-modal information similarity. Furthermore, the system achieves efficient retrieval through our advanced navigation graph index, refined using computational pruning techniques. Another highlight of our system is its pluggable processing framework, allowing seamless integration of embedding models, graph indexes, and LLMs. This flexibility provides users diverse options for gaining insights from their multi-modal knowledge base. A preliminary video introduction of MQA is available at https://youtu.be/xvUuo2ZIqWk.",
    "pdf_link": "https://arxiv.org/abs/2407.04217",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.04217v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04217/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04217v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04217/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04217v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04217/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04217v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04217/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04217v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04217/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04217v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04217/x6.png"
      }
    ],
    "abstract_cn": "检索增强型大型语言模型 (LLM) 彻底改变了传统查询-回答系统，提供前所未有的用户体验。然而，现有检索技术在处理多模态查询时面临挑战。本文介绍的交互式多模态查询回答 (MQA) 系统，借助新开发的多模态检索框架和导航图索引，与顶尖 LLM 无缝集成。系统包含数据预处理、向量表示、索引构建、查询执行和答案生成五大核心模块，由专用协调器确保数据流畅。MQA 利用对比学习评估模态重要性，精准衡量多模态信息相似度。通过先进的导航图索引和计算修剪技术，实现高效检索。系统还具备可插拔处理框架，轻松集成嵌入模型、图索引和 LLM，为用户提供多样化的知识库洞察选择。MQA 初步介绍视频见 https://youtu.be/xvUuo2ZIqWk。",
    "title_cn": "交互式多模态查询应答系统，搭载检索增强型大型语言模型",
    "tags": [
      "RAG",
      "多媒体",
      "搜索引擎"
    ]
  },
  {
    "title": "DSLR: Document Refinement with Sentence-Level Re-ranking and Reconstruction to Enhance Retrieval-Augmented Generation",
    "submit_datetime": "2024年07月04日",
    "abstract": "Recent advancements in Large Language Models (LLMs) have significantly improved their performance across various Natural Language Processing (NLP) tasks. However, LLMs still struggle with generating non-factual responses due to limitations in their parametric memory. Retrieval-Augmented Generation (RAG) systems address this issue by incorporating external knowledge with a retrieval module. Despite their successes, however, current RAG systems face challenges with retrieval failures and the limited ability of LLMs to filter out irrelevant information. Therefore, in this work, we propose \\textit{\\textbf{DSLR}} (\\textbf{D}ocument Refinement with \\textbf{S}entence-\\textbf{L}evel \\textbf{R}e-ranking and Reconstruction), an unsupervised framework that decomposes retrieved documents into sentences, filters out irrelevant sentences, and reconstructs them again into coherent passages. We experimentally validate \\textit{DSLR} on multiple open-domain QA datasets and the results demonstrate that \\textit{DSLR} significantly enhances the RAG performance over conventional fixed-size passage. Furthermore, our \\textit{DSLR} enhances performance in specific, yet realistic scenarios without the need for additional training, providing an effective and efficient solution for refining retrieved documents in RAG systems.",
    "pdf_link": "https://arxiv.org/abs/2407.03627",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.03627v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03627/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03627v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03627/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03627v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03627/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03627v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03627/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03627v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03627/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03627v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03627/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03627v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03627/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03627v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03627/x8.png"
      }
    ],
    "abstract_cn": "大型语言模型 (LLM) 在自然语言处理 (NLP) 任务中的表现因最新进展而显著提升。然而，受限于参数记忆，LLM 在生成非事实性响应时仍显不足。检索增强生成 (RAG) 系统通过整合外部知识与检索模块来应对这一难题。尽管成效显著，当前 RAG 系统仍受困于检索失败及 LLM 筛选无关信息能力的局限。为此，我们提出 **DSLR**（文档细化与句子级重排重建），一个无监督框架，它将检索文档拆解为句子，剔除无关内容，再重组为连贯段落。实验证明，**DSLR** 在开放域 QA 数据集上大幅超越传统固定段落方法，提升 RAG 性能。此外，**DSLR** 无需额外训练，便能在特定现实场景中优化性能，为 RAG 系统中的文档精炼提供了一个既高效又有效的解决方案。",
    "title_cn": "DSLR 技术通过句子级重排序与重建，优化文档，从而提升检索增强生成的质量。",
    "tags": [
      "RAG",
      "问答系统",
      ""
    ]
  },
  {
    "title": "Slice-100K: A Multimodal Dataset for Extrusion-based 3D Printing",
    "submit_datetime": "2024年07月04日",
    "abstract": "G-code (Geometric code) or RS-274 is the most widely used computer numerical control (CNC) and 3D printing programming language. G-code provides machine instructions for the movement of the 3D printer, especially for the nozzle, stage, and extrusion of material for extrusion-based additive manufacturing. Currently there does not exist a large repository of curated CAD models along with their corresponding G-code files for additive manufacturing. To address this issue, we present SLICE-100K, a first-of-its-kind dataset of over 100,000 G-code files, along with their tessellated CAD model, LVIS (Large Vocabulary Instance Segmentation) categories, geometric properties, and renderings. We build our dataset from triangulated meshes derived from Objaverse-XL and Thingi10K datasets. We demonstrate the utility of this dataset by finetuning GPT-2 on a subset of the dataset for G-code translation from a legacy G-code format (Sailfish) to a more modern, widely used format (Marlin). SLICE-100K will be the first step in developing a multimodal foundation model for digital manufacturing.",
    "pdf_link": "https://arxiv.org/abs/2407.04180",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.04180v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04180/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04180v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04180/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04180v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04180/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04180v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04180/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04180v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04180/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04180v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04180/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04180v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04180/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04180v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04180/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04180v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04180/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04180v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04180/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04180v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04180/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04180v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04180/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04180v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04180/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04180v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04180/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04180v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04180/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04180v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04180/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04180v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04180/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04180v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04180/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04180v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04180/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04180v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04180/x20.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04180v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04180/x21.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04180v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04180/x22.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04180v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04180/translation_snippets.png"
      }
    ],
    "abstract_cn": "G-code，即几何代码 RS-274，是计算机数控（CNC）和 3D 打印领域最常用的编程语言。它主要用于指导 3D 打印机的运动，包括喷嘴、平台和材料挤出。目前，尚未有一个包含大量精选 CAD 模型及其对应 G-code 文件的增材制造资源库。为此，我们推出了 SLICE-100K，这是一个创新数据集，包含超过 100,000 个 G-code 文件，以及相应的镶嵌 CAD 模型、LVIS 类别、几何属性和渲染图。该数据集基于 Objaverse-XL 和 Thingi10K 的三角网格构建。我们通过微调 GPT-2 模型，展示了该数据集在将旧版 G-code 格式（如 Sailfish）转换为现代格式（如 Marlin）方面的应用。SLICE-100K 的推出，标志着开发数字制造多模态基础模型的第一步。",
    "title_cn": "Slice-100K：一款专为挤出式3D打印设计的多模态数据集",
    "tags": [
      "LLM应用",
      "制造业",
      "3D打印"
    ]
  },
  {
    "title": "Semi-supervised Learning for Code-Switching ASR with Large Language Model Filter",
    "submit_datetime": "2024年07月04日",
    "abstract": "Code-switching (CS) phenomenon occurs when words or phrases from different languages are alternated in a single sentence. Due to data scarcity, building an effective CS Automatic Speech Recognition (ASR) system remains challenging. In this paper, we propose to enhance CS-ASR systems by utilizing rich unsupervised monolingual speech data within a semi-supervised learning framework, particularly when access to CS data is limited. To achieve this, we establish a general paradigm for applying noisy student training (NST) to the CS-ASR task. Specifically, we introduce the LLM-Filter, which leverages well-designed prompt templates to activate the correction capability of large language models (LLMs) for monolingual data selection and pseudo-labels refinement during NST. Our experiments on the supervised ASRU-CS and unsupervised AISHELL-2 and LibriSpeech datasets show that our method not only achieves significant improvements over supervised and semi-supervised learning baselines for the CS task, but also attains better performance compared with the fully-supervised oracle upper-bound on the CS English part. Additionally, we further investigate the influence of accent on AESRC dataset and demonstrate that our method can get achieve additional benefits when the monolingual data contains relevant linguistic characteristic.",
    "pdf_link": "https://arxiv.org/abs/2407.04219",
    "graphs": [],
    "abstract_cn": "代码切换现象，即不同语言的词汇在同一句话中交替出现，由于相关数据稀缺，构建高效的自动语音识别系统颇具挑战。本文提出，在半监督学习框架下，利用丰富的无监督单语语音数据来强化CS-ASR系统，尤其是在CS数据有限的情况下。我们构建了一个通用范式，将噪声学生训练应用于CS-ASR任务，并引入了LLM-Filter，通过设计精妙的提示模板，激活大型语言模型在单语数据筛选和伪标签优化中的校正功能。实验结果显示，我们的方法在CS任务上不仅大幅超越了传统监督与半监督学习方法，甚至在CS英语部分的表现也优于全监督的基准上限。此外，我们还探讨了口音对AESRC数据集的影响，发现当单语数据包含特定语言特征时，我们的方法能带来额外优势。",
    "title_cn": "半监督学习助力代码转换ASR，结合大型语言模型过滤器",
    "tags": [
      "LLM应用",
      "语音识别",
      "半监督学习"
    ]
  },
  {
    "title": "HAF-RM: A Hybrid Alignment Framework for Reward Model Training",
    "submit_datetime": "2024年07月04日",
    "abstract": "The reward model has become increasingly important in alignment, assessment, and data construction for large language models (LLMs). Most existing researchers focus on enhancing reward models through data improvements, following the conventional training framework for reward models that directly optimizes the predicted rewards. In this paper, we propose a hybrid alignment framework HaF-RM for reward model training by introducing an additional constraint on token-level policy probabilities in addition to the reward score. It can simultaneously supervise the internal preference model at the token level and optimize the mapping layer of the reward model at the sequence level. Theoretical justifications and experiment results on five datasets show the validity and effectiveness of our proposed hybrid framework for training a high-quality reward model. By decoupling the reward modeling procedure and incorporating hybrid supervision, our HaF-RM framework offers a principled and effective approach to enhancing the performance and alignment of reward models, a critical component in the responsible development of powerful language models. We release our code at https://haf-rm.github.io.",
    "pdf_link": "https://arxiv.org/abs/2407.04185",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.04185v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04185/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04185v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04185/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04185v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04185/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04185v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04185/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04185v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04185/x5.png"
      }
    ],
    "abstract_cn": "奖励模型在LLM的对齐与评估中日益关键。传统上，研究者通过数据优化来提升奖励模型，直接针对预测奖励进行训练。本文中，我们创新性地提出了HaF-RM框架，不仅优化奖励分数，还额外约束了令牌级策略概率，实现了令牌级偏好模型的监督与序列级映射层的优化。理论与实验双重验证了该框架在提升奖励模型质量上的卓越效果。通过分离奖励建模步骤并引入混合监督，HaF-RM为增强奖励模型的性能与对齐提供了一条高效且有原则的路径，对语言模型的负责任发展至关重要。代码已公开于https://haf-rm.github.io。",
    "title_cn": "HAF-RM：奖励模型训练的混合对齐新框架",
    "tags": [
      "LLM理论",
      "人工智能",
      "语言模型"
    ]
  },
  {
    "title": "Seeing Like an AI: How LLMs Apply (and Misapply) Wikipedia Neutrality Norms",
    "submit_datetime": "2024年07月04日",
    "abstract": "Large language models (LLMs) are trained on broad corpora and then used in communities with specialized norms. Is providing LLMs with community rules enough for models to follow these norms? We evaluate LLMs' capacity to detect (Task 1) and correct (Task 2) biased Wikipedia edits according to Wikipedia's Neutral Point of View (NPOV) policy. LLMs struggled with bias detection, achieving only 64% accuracy on a balanced dataset. Models exhibited contrasting biases (some under- and others over-predicted bias), suggesting distinct priors about neutrality. LLMs performed better at generation, removing 79% of words removed by Wikipedia editors. However, LLMs made additional changes beyond Wikipedia editors' simpler neutralizations, resulting in high-recall but low-precision editing. Interestingly, crowdworkers rated AI rewrites as more neutral (70%) and fluent (61%) than Wikipedia-editor rewrites. Qualitative analysis found LLMs sometimes applied NPOV more comprehensively than Wikipedia editors but often made extraneous non-NPOV-related changes (such as grammar). LLMs may apply rules in ways that resonate with the public but diverge from community experts. While potentially effective for generation, LLMs may reduce editor agency and increase moderation workload (e.g., verifying additions). Even when rules are easy to articulate, having LLMs apply them like community members may still be difficult.",
    "pdf_link": "https://arxiv.org/abs/2407.04183",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.04183v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04183/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04183v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04183/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04183v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04183/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04183v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04183/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04183v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04183/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04183v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04183/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04183v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04183/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04183v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04183/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04183v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04183/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04183v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04183/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04183v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04183/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04183v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04183/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04183v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04183/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04183v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04183/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04183v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04183/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04183v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04183/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04183v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04183/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04183v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04183/x18.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLM）虽在广泛语料库上训练，但应用于特定规范社区时，仅提供社区规则是否足够？我们测试了LLM识别与修正维基百科编辑偏差的能力，依据中立观点（NPOV）政策。LLM在偏差识别上准确率仅64%，显示出对中立性的不同理解。在生成内容时，LLM能移除79%的编辑删除词，但常做出超出简单中立化的额外改动，导致编辑质量高召回但低精度。有趣的是，AI重写被认为比编辑版本更中立和流畅。定性分析显示，LLM有时比编辑更全面应用NPOV，但也常进行无关的语法调整。LLM的应用可能符合公众期待，却与专家意见相左。尽管在内容生成上表现可能有效，LLM的使用可能削弱编辑自主权并增加审核负担。即便规则明确，让LLM如同社区成员般应用它们仍具挑战。",
    "title_cn": "窥探AI视角：LLMs在应用维基百科中立性规范时的得与失",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Orchestrating LLMs with Different Personalizations",
    "submit_datetime": "2024年07月04日",
    "abstract": "This paper presents a novel approach to aligning large language models (LLMs) with individual human preferences, sometimes referred to as Reinforcement Learning from \\textit{Personalized} Human Feedback (RLPHF). Given stated preferences along multiple dimensions, such as helpfulness, conciseness, or humor, the goal is to create an LLM without re-training that best adheres to this specification. Starting from specialized expert LLMs, each trained for one such particular preference dimension, we propose a black-box method that merges their outputs on a per-token level. We train a lightweight Preference Control Model (PCM) that dynamically translates the preference description and current context into next-token prediction weights. By combining the expert models' outputs at the token level, our approach dynamically generates text that optimizes the given preference. Empirical tests show that our method matches or surpasses existing preference merging techniques, providing a scalable, efficient alternative to fine-tuning LLMs for individual personalization.",
    "pdf_link": "https://arxiv.org/abs/2407.04181",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.04181v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04181/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04181v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04181/x2.png"
      }
    ],
    "abstract_cn": "本文介绍了一种创新方法，旨在将大型语言模型（LLM）与个人偏好精准对接，这种方法被称为个性化人类反馈强化学习（RLPHF）。我们的目标是在不重新训练的前提下，打造一个能够完美契合用户在帮助性、简洁性或幽默感等多维度偏好的LLM。我们从专门针对单一偏好维度训练的专家LLM出发，提出了一种在标记级别上融合它们输出的黑箱技术。同时，我们训练了一个轻巧的偏好控制模型（PCM），它能根据当前上下文动态调整偏好描述，转化为下一个标记的预测权重。通过在标记级别上整合专家模型的输出，我们的方法能够动态生成符合用户偏好的文本。实证测试显示，我们的方法在偏好合并技术上表现卓越，为个性化LLM微调提供了一种高效且可扩展的解决方案。",
    "title_cn": "个性化调配大型语言模型",
    "tags": [
      "LLM应用",
      "个性化服务",
      "人工智能"
    ]
  },
  {
    "title": "Defense Against Syntactic Textual Backdoor Attacks with Token Substitution",
    "submit_datetime": "2024年07月04日",
    "abstract": "Textual backdoor attacks present a substantial security risk to Large Language Models (LLM). It embeds carefully chosen triggers into a victim model at the training stage, and makes the model erroneously predict inputs containing the same triggers as a certain class. Prior backdoor defense methods primarily target special token-based triggers, leaving syntax-based triggers insufficiently addressed. To fill this gap, this paper proposes a novel online defense algorithm that effectively counters syntax-based as well as special token-based backdoor attacks. The algorithm replaces semantically meaningful words in sentences with entirely different ones but preserves the syntactic templates or special tokens, and then compares the predicted labels before and after the substitution to determine whether a sentence contains triggers. Experimental results confirm the algorithm's performance against these two types of triggers, offering a comprehensive defense strategy for model integrity.",
    "pdf_link": "https://arxiv.org/abs/2407.04179",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.04179v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04179/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04179v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04179/figure1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04179v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04179/sst2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04179v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04179/ag.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04179v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04179/dbp.png"
      }
    ],
    "abstract_cn": "文本后门攻击对 LLM 构成严重威胁，通过在训练阶段植入特定触发器，诱导模型对含相同触发器的输入做出错误预测。传统防御方法多聚焦于特殊标记触发器，对语法触发器防范不足。为此，本文提出一种新型在线防御算法，既能抵御语法触发器，也能应对特殊标记触发器。该算法通过替换句子中的语义词，同时保留语法结构或特殊标记，对比替换前后预测结果，以识别潜在触发器。实验证明，该算法对这两类触发器均有效，为模型安全提供全方位保护。",
    "title_cn": "防御通过标记替换实施的句法文本后门攻击",
    "tags": [
      "LLM应用",
      "网络安全",
      "人工智能"
    ]
  },
  {
    "title": "Quantifying Prediction Consistency Under Model Multiplicity in Tabular LLMs",
    "submit_datetime": "2024年07月04日",
    "abstract": "Fine-tuning large language models (LLMs) on limited tabular data for classification tasks can lead to \\textit{fine-tuning multiplicity}, where equally well-performing models make conflicting predictions on the same inputs due to variations in the training process (i.e., seed, random weight initialization, retraining on additional or deleted samples). This raises critical concerns about the robustness and reliability of Tabular LLMs, particularly when deployed for high-stakes decision-making, such as finance, hiring, education, healthcare, etc. This work formalizes the challenge of fine-tuning multiplicity in Tabular LLMs and proposes a novel metric to quantify the robustness of individual predictions without expensive model retraining. Our metric quantifies a prediction's stability by analyzing (sampling) the model's local behavior around the input in the embedding space. Interestingly, we show that sampling in the local neighborhood can be leveraged to provide probabilistic robustness guarantees against a broad class of fine-tuned models. By leveraging Bernstein's Inequality, we show that predictions with sufficiently high robustness (as defined by our measure) will remain consistent with high probability. We also provide empirical evaluation on real-world datasets to support our theoretical results. Our work highlights the importance of addressing fine-tuning instabilities to enable trustworthy deployment of LLMs in high-stakes and safety-critical applications.",
    "pdf_link": "https://arxiv.org/abs/2407.04173",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.04173v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04173/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04173v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04173/rolling_stats_plot.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04173v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04173/diabetes_512.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04173v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04173/creditg_512.png"
      }
    ],
    "abstract_cn": "在分类任务中，对大型语言模型进行有限表格数据的微调可能导致“微调多重性”，即不同训练过程下的模型对相同输入做出不同预测。这引发了关于表格 LLM 在高风险决策中的稳健性和可靠性的担忧。为此，我们正式化了这一挑战，并提出了一种新指标，通过分析模型在嵌入空间中的局部行为，无需重新训练模型即可量化预测的稳健性。我们利用伯恩斯坦不等式，证明了高稳健性预测将以高概率保持一致，并通过实证评估支持了这一理论。我们的工作强调了解决微调不稳定性的重要性，以确保 LLM 在高风险和安全关键应用中的可信部署。",
    "title_cn": "探究表格型LLM在模型多样性下的预测一致性",
    "tags": [
      "LLM理论",
      "",
      ""
    ]
  },
  {
    "title": "VoxAct-B: Voxel-Based Acting and Stabilizing Policy for Bimanual Manipulation",
    "submit_datetime": "2024年07月04日",
    "abstract": "Bimanual manipulation is critical to many robotics applications. In contrast to single-arm manipulation, bimanual manipulation tasks are challenging due to higher-dimensional action spaces. Prior works leverage large amounts of data and primitive actions to address this problem, but may suffer from sample inefficiency and limited generalization across various tasks. To this end, we propose VoxAct-B, a language-conditioned, voxel-based method that leverages Vision Language Models (VLMs) to prioritize key regions within the scene and reconstruct a voxel grid. We provide this voxel grid to our bimanual manipulation policy to learn acting and stabilizing actions. This approach enables more efficient policy learning from voxels and is generalizable to different tasks. In simulation, we show that VoxAct-B outperforms strong baselines on fine-grained bimanual manipulation tasks. Furthermore, we demonstrate VoxAct-B on real-world $\\texttt{Open Drawer}$ and $\\texttt{Open Jar}$ tasks using two UR5s. Code, data, and videos will be available at https://voxact-b.github.io.",
    "pdf_link": "https://arxiv.org/abs/2407.04152",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.04152v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04152/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04152v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04152/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04152v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04152/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.04152v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04152/x4.png"
      }
    ],
    "abstract_cn": "双手操作在机器人领域至关重要。与单臂操作相比，双手操作因其高维动作空间而更具挑战性。以往方法依赖大量数据和基础动作，但存在样本效率低和泛化能力有限的问题。为此，我们提出VoxAct-B，一种结合语言条件和体素技术的方法，利用视觉语言模型优先处理关键场景区域并构建体素网格。该网格用于指导双手操作策略，学习有效动作和稳定技巧，从而提高策略学习效率并增强任务泛化能力。模拟实验表明，VoxAct-B在精细双手操作任务中表现优异。此外，我们通过两台UR5机器人，在实际环境中成功演示了抽屉和罐子的开启任务。相关代码、数据及演示视频将在https://voxact-b.github.io发布。",
    "title_cn": "VoxAct-B：一种基于体素的双臂操作动作与稳定策略",
    "tags": [
      "Agent",
      "机器人",
      "自动化"
    ]
  },
  {
    "title": "Securing Multi-turn Conversational Language Models Against Distributed Backdoor Triggers",
    "submit_datetime": "2024年07月04日",
    "abstract": "The security of multi-turn conversational large language models (LLMs) is understudied despite it being one of the most popular LLM utilization. Specifically, LLMs are vulnerable to data poisoning backdoor attacks, where an adversary manipulates the training data to cause the model to output malicious responses to predefined triggers. Specific to the multi-turn dialogue setting, LLMs are at the risk of even more harmful and stealthy backdoor attacks where the backdoor triggers may span across multiple utterances, giving lee-way to context-driven attacks. In this paper, we explore a novel distributed backdoor trigger attack that serves to be an extra tool in an adversary's toolbox that can interface with other single-turn attack strategies in a plug and play manner. Results on two representative defense mechanisms indicate that distributed backdoor triggers are robust against existing defense strategies which are designed for single-turn user-model interactions, motivating us to propose a new defense strategy for the multi-turn dialogue setting that is more challenging. To this end, we also explore a novel contrastive decoding based defense that is able to mitigate the backdoor with a low computational tradeoff.",
    "pdf_link": "https://arxiv.org/abs/2407.04151",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.04151v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04151/poison.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.04151v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.04151/x1.png"
      }
    ],
    "abstract_cn": "尽管多轮对话大型语言模型 (LLM) 的应用广泛，但其安全性研究却相对滞后。LLM 特别容易受到数据中毒后门攻击，这种攻击通过操纵训练数据，使模型对特定触发器产生恶意响应。在多轮对话场景中，后门触发器可能跨越多个话语，增加了攻击的隐蔽性和危害性。本文介绍了一种新颖的分布式后门触发器攻击，这种攻击可以与其他单轮攻击策略灵活结合，对现有防御机制构成挑战。实验表明，这种攻击对针对单轮交互设计的防御策略具有鲁棒性，因此我们提出了一种新的多轮对话防御策略，并探索了一种基于对比解码的防御方法，以低计算代价有效缓解后门攻击。",
    "title_cn": "强化多轮对话语言模型，抵御分布式后门触发威胁",
    "tags": [
      "LLM应用",
      "网络安全",
      "人工智能安全"
    ]
  },
  {
    "title": "A Survey of Controllable Learning: Methods and Applications in Information Retrieval",
    "submit_datetime": "2024年07月04日",
    "abstract": "Controllable learning (CL) emerges as a critical component in trustworthy machine learning, ensuring that learners meet predefined targets and can adaptively adjust without retraining according to the changes in those targets. We provide a formal definition of CL, and discuss its applications in information retrieval (IR) where information needs are often complex and dynamic. The survey categorizes CL according to who controls (users or platforms), what is controllable (e.g., retrieval objectives, users' historical behaviors, controllable environmental adaptation), how control is implemented (e.g., rule-based method, Pareto optimization, Hypernetwork), and where to implement control (e.g.,pre-processing, in-processing, post-processing methods). Then, we identify challenges faced by CL across training, evaluation, task setting, and deployment in online environments. Additionally, we outline promising directions for CL in theoretical analysis, efficient computation, empowering large language models, application scenarios and evaluation frameworks in IR.",
    "pdf_link": "https://arxiv.org/abs/2407.06083",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06083v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06083/x1.png"
      }
    ],
    "abstract_cn": "可控学习（CL）是构建可信机器学习的核心，它确保学习系统能精准达成预定目标，并随目标变化灵活调整，无需重新训练。我们为CL下了定义，并探讨了其在信息检索（IR）领域的应用，这里的信息需求多变且复杂。我们根据控制主体（用户或平台）、可控要素（如检索目标、用户行为、环境适应性）、控制方式（基于规则、帕累托优化、超网络等）及实施环节（预处理、处理中、后处理）对CL进行了分类。同时，我们指出了CL在训练、评估、任务设计及在线部署中遇到的挑战，并展望了其在理论深化、计算优化、大型语言模型赋能、应用拓展及评估体系构建等方面的潜力。",
    "title_cn": "探索可控学习：揭秘信息检索领域的技术与应用",
    "tags": [
      "LLM理论",
      "信息检索",
      "机器学习"
    ]
  },
  {
    "title": "CaseGPT: a case reasoning framework based on language models and retrieval-augmented generation",
    "submit_datetime": "2024年07月04日",
    "abstract": "This paper presents CaseGPT, an innovative approach that combines Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) technology to enhance case-based reasoning in the healthcare and legal sectors. The system addresses the challenges of traditional database queries by enabling fuzzy searches based on imprecise descriptions, thereby improving data searchability and usability. CaseGPT not only retrieves relevant case data but also generates insightful suggestions and recommendations based on patterns discerned from existing case data. This functionality proves especially valuable for tasks such as medical diagnostics, legal precedent research, and case strategy formulation. The paper includes an in-depth discussion of the system's methodology, its performance in both medical and legal domains, and its potential for future applications. Our experiments demonstrate that CaseGPT significantly outperforms traditional keyword-based and simple LLM-based systems in terms of precision, recall, and efficiency.",
    "pdf_link": "https://arxiv.org/abs/2407.07913",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.07913v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.07913/x1.png"
      }
    ],
    "abstract_cn": "本文介绍的 CaseGPT 创新地将 LLM 与 RAG 技术结合，旨在提升医疗和法律领域的案例推理效率。通过模糊搜索技术，CaseGPT 克服了传统数据库查询的局限，大幅提升了数据检索的精准度和可用性。它不仅能高效检索相关案例，还能基于案例数据的模式，提供深入的建议和策略，这对于医疗诊断和法律研究等任务尤为关键。实验数据显示，CaseGPT 在精确度、召回率和效率上均超越了传统系统。本文详细探讨了其技术原理、应用效果及未来发展潜力。",
    "title_cn": "CaseGPT：一种结合语言模型与检索增强技术的案例推理框架",
    "tags": [
      "RAG",
      "",
      ""
    ]
  },
  {
    "title": "Cactus: Towards Psychological Counseling Conversations using Cognitive Behavioral Theory",
    "submit_datetime": "2024年07月03日",
    "abstract": "Recently, the demand for psychological counseling has significantly increased as more individuals express concerns about their mental health. This surge has accelerated efforts to improve the accessibility of counseling by using large language models (LLMs) as counselors. To ensure client privacy, training open-source LLMs faces a key challenge: the absence of realistic counseling datasets. To address this, we introduce Cactus, a multi-turn dialogue dataset that emulates real-life interactions using the goal-oriented and structured approach of Cognitive Behavioral Therapy (CBT). We create a diverse and realistic dataset by designing clients with varied, specific personas, and having counselors systematically apply CBT techniques in their interactions. To assess the quality of our data, we benchmark against established psychological criteria used to evaluate real counseling sessions, ensuring alignment with expert evaluations. Experimental results demonstrate that Camel, a model trained with Cactus, outperforms other models in counseling skills, highlighting its effectiveness and potential as a counseling agent. We make our data, model, and code publicly available.",
    "pdf_link": "https://arxiv.org/abs/2407.03103",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.03103v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03103/figure1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03103v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03103/pie_2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03103v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03103/chatgpt_shortage.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03103v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03103/overview_method.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03103v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03103/cactus.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03103v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03103/sample_data_quality_human_eval_1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03103v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03103/data_quality_ablation.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03103v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03103/ablation_mtehod.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03103v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03103/app_pie_chart.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03103v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03103/prompt_cbt_llm.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03103v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03103/prompt_CTRS.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03103v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03103/prompt_PANAS.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03103v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03103/two_agent_script.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03103v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03103/prompt_camel_cbt.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03103v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03103/prompt_camel.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03103v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03103/smilechat_cactus.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03103v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03103/prompt_intake_form.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03103v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03103/prompt_cbt.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03103v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03103/prompt_planning.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03103v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03103/prompt_dialog.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03103v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03103/prompt_ai_client.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03103v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03103/amt_interface.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.03103v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03103/app_problem_example.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03103v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03103/app_chatgpt_example.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03103v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03103/app_psych_camel.png"
      }
    ],
    "abstract_cn": "随着心理健康问题的关注度上升，心理咨询需求激增，推动了利用大型语言模型（LLM）作为咨询师的应用。然而，保护客户隐私的同时，开源LLM的训练面临数据集缺失的难题。为此，我们推出了Cactus数据集，模拟真实对话，结合认知行为疗法（CBT）的结构化方法。通过设定多样化的客户角色和系统化的CBT应用，我们构建了一个真实且多元的数据集。为确保数据质量，我们依据专业心理评估标准进行验证。实验显示，基于Cactus训练的Camel模型在咨询技能上表现卓越，展现了其作为咨询工具的潜力。我们公开了所有相关资源，以促进心理咨询技术的发展。",
    "title_cn": "Cactus：借助认知行为理论，迈向心理咨询对话的新领域",
    "tags": [
      "LLM应用",
      "心理健康",
      "人工智能"
    ]
  },
  {
    "title": "Vision-driven Automated Mobile GUI Testing via Multimodal Large Language Model",
    "submit_datetime": "2024年07月03日",
    "abstract": "With the advancement of software rendering techniques, GUI pages in mobile apps now encompass a wealth of visual information, where the visual semantics of each page contribute to the overall app logic, presenting new challenges to software testing. Despite the progress in automated Graphical User Interface (GUI) testing, the absence of testing oracles has constrained its efficacy to identify only crash bugs with evident abnormal signals. Nonetheless, there are still a considerable number of non-crash bugs, ranging from unexpected behaviors to misalignments, often evading detection by existing techniques. While these bugs can exhibit visual cues that serve as potential testing oracles, they often entail a sequence of screenshots, and detecting them necessitates an understanding of the operational logic among GUI page transitions, which is challenging traditional techniques. Considering the remarkable performance of Multimodal Large Language Models (MLLM) in visual and language understanding, this paper proposes a vision-driven automated GUI testing approach VisionDroid to detect non-crash functional bugs with MLLM. It begins by extracting GUI text information and aligning it with screenshots to form a vision prompt, enabling MLLM to understand GUI context. The function-aware explorer then employs MLLM for deeper and function-oriented GUI page exploration, while the logic-aware bug detector segments the entire exploration history into logically cohesive parts and prompts the MLLM for bug detection. We evaluate VisionDroid on three datasets and compare it with 10 baselines, demonstrating its excellent performance. The ablation study further proves the contribution of each module. Moreover, VisionDroid identifies 29 new bugs on Google Play, of which 19 have been confirmed and fixed.",
    "pdf_link": "https://arxiv.org/abs/2407.03037",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.03037v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03037/bug-example.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03037v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03037/Pilot-study.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03037v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03037/overview.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03037v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03037/example-screenshot.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03037v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03037/example-history.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03037v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03037/explore-prompt.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03037v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03037/test-seq-example.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03037v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03037/Detect-prompt.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03037v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03037/RQ2-2.png"
      }
    ],
    "abstract_cn": "随着软件渲染技术的提升，移动应用的GUI页面如今承载了丰富的视觉信息，这些视觉语义对应用逻辑至关重要，同时也为软件测试带来了新挑战。尽管自动化GUI测试有所进步，但由于缺乏有效的测试预言，其效果仍局限于识别明显的崩溃错误。然而，许多非崩溃错误，如意外行为或界面错位，往往难以被现有技术捕捉。这些错误虽可能通过视觉线索提供潜在的测试预言，但检测它们需要深入理解GUI页面间的操作逻辑，这对传统技术构成挑战。鉴于多模态大型语言模型（MLLM）在视觉与语言理解上的卓越能力，本文提出了一种基于视觉的自动化GUI测试方法——VisionDroid，旨在利用MLLM检测非崩溃功能错误。该方法首先提取GUI文本信息并结合截图形成视觉提示，使MLLM能理解GUI上下文。随后，功能感知探索器引导MLLM进行深入且面向功能的GUI页面探索，而逻辑感知错误检测器则将探索历史按逻辑分段，并引导MLLM进行错误检测。我们在三个数据集上验证了VisionDroid，并对比了10个基线方法，证实了其优异性能。消融研究进一步凸显了各模块的贡献。此外，VisionDroid在Google Play上发现了29个新错误，其中19个已获确认并得到修复。",
    "title_cn": "利用多模态大型语言模型实现视觉驱动的移动GUI自动化测试",
    "tags": [
      "LLM应用",
      "软件测试",
      "移动应用"
    ]
  },
  {
    "title": "VIVA: A Benchmark for Vision-Grounded Decision-Making with Human Values",
    "submit_datetime": "2024年07月03日",
    "abstract": "This paper introduces VIVA, a benchmark for VIsion-grounded decision-making driven by human VAlues. While most large vision-language models (VLMs) focus on physical-level skills, our work is the first to examine their multimodal capabilities in leveraging human values to make decisions under a vision-depicted situation. VIVA contains 1,062 images depicting diverse real-world situations and the manually annotated decisions grounded in them. Given an image there, the model should select the most appropriate action to address the situation and provide the relevant human values and reason underlying the decision. Extensive experiments based on VIVA show the limitation of VLMs in using human values to make multimodal decisions. Further analyses indicate the potential benefits of exploiting action consequences and predicted human values.",
    "pdf_link": "https://arxiv.org/abs/2407.03000",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.03000v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03000/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03000v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03000/emoji.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.03000v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03000/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03000v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03000/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03000v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03000/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03000v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03000/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03000v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03000/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03000v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03000/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03000v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03000/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03000v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03000/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03000v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03000/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03000v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03000/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03000v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03000/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03000v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03000/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03000v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03000/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03000v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03000/x15.png"
      }
    ],
    "abstract_cn": "本文推出 VIVA 基准，专注于考察视觉-语言模型在基于人类价值观进行决策的能力。与传统 VLM 不同，VIVA 通过 1,062 张现实情境图片及相应的手动标注决策，挑战模型在视觉情境下选择合适行动并阐释其背后的人类价值观和理由。实验表明，VLM 在运用人类价值观进行复杂决策上存在局限，而深入分析则揭示了考虑行动后果和预测价值观的潜在优势。",
    "title_cn": "VIVA：一个结合视觉与人类价值观的决策制定基准",
    "tags": [
      "LLM应用",
      "人工智能",
      "计算机视觉"
    ]
  },
  {
    "title": "MedPix 2.0: A Comprehensive Multimodal Biomedical Dataset for Advanced AI Applications",
    "submit_datetime": "2024年07月03日",
    "abstract": "The increasing interest in developing Artificial Intelligence applications in the medical domain, suffers from the lack of high-quality dataset, mainly due to privacy-related issues. Moreover, the recent rising of Multimodal Large Language Models (MLLM) leads to a need for multimodal medical datasets, where clinical reports and findings are attached to the corresponding CT or MR scans. This paper illustrates the entire workflow for building the data set MedPix 2.0. Starting from the well-known multimodal dataset MedPix\\textsuperscript{\\textregistered}, mainly used by physicians, nurses and healthcare students for Continuing Medical Education purposes, a semi-automatic pipeline was developed to extract visual and textual data followed by a manual curing procedure where noisy samples were removed, thus creating a MongoDB database. Along with the dataset, we developed a GUI aimed at navigating efficiently the MongoDB instance, and obtaining the raw data that can be easily used for training and/or fine-tuning MLLMs. To enforce this point, we also propose a CLIP-based model trained on MedPix 2.0 for scan classification tasks.",
    "pdf_link": "https://arxiv.org/abs/2407.02994",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.02994v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02994/overview_medpix.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02994v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02994/json_raw_v.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02994v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02994/query.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02994v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02994/interface.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02994v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02994/Clip_architecture.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02994v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02994/modality.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02994v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02994/ft-results.png"
      }
    ],
    "abstract_cn": "随着医疗领域对AI应用的兴趣日益增长，高质量数据集的缺乏成为一大难题，主要原因是隐私问题。同时，多模态大型语言模型（MLLM）的兴起，使得我们需要结合临床报告与CT或MR扫描的多模态医疗数据集。本文详细介绍了构建MedPix 2.0数据集的全过程。我们从广泛用于继续医学教育的MedPix\\textsuperscript{\\textregistered}数据集出发，通过半自动化流程提取视觉与文本信息，并手动剔除噪声样本，最终构建了一个MongoDB数据库。此外，我们还设计了一个图形用户界面（GUI），方便用户高效访问数据库，并轻松获取用于训练或微调MLLM的原始数据。为了展示其应用潜力，我们基于MedPix 2.0训练了一个CLIP模型，用于扫描分类任务。",
    "title_cn": "MedPix 2.0：一款集大成的多模态生物医学数据集，专为尖端AI应用打造",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "MindBench: A Comprehensive Benchmark for Mind Map Structure Recognition and Analysis",
    "submit_datetime": "2024年07月03日",
    "abstract": "Multimodal Large Language Models (MLLM) have made significant progress in the field of document analysis. Despite this, existing benchmarks typically focus only on extracting text and simple layout information, neglecting the complex interactions between elements in structured documents such as mind maps and flowcharts. To address this issue, we introduce the new benchmark named MindBench, which not only includes meticulously constructed bilingual authentic or synthetic images, detailed annotations, evaluation metrics and baseline models, but also specifically designs five types of structured understanding and parsing tasks. These tasks include full parsing, partial parsing, position-related parsing, structured Visual Question Answering (VQA), and position-related VQA, covering key areas such as text recognition, spatial awareness, relationship discernment, and structured parsing. Extensive experimental results demonstrate the substantial potential and significant room for improvement in current models' ability to handle structured document information. We anticipate that the launch of MindBench will significantly advance research and application development in structured document analysis technology. MindBench is available at: https://miasanlei.github.io/MindBench.github.io/.",
    "pdf_link": "https://arxiv.org/abs/2407.02842",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.02842v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02842/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02842v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02842/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02842v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02842/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02842v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02842/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02842v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02842/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02842v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02842/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02842v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02842/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02842v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02842/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02842v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02842/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02842v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02842/x10.png"
      }
    ],
    "abstract_cn": "多模态大型语言模型在文档分析领域取得了显著进展，但现有基准往往忽视了结构化文档中元素间的复杂交互。为此，我们推出了新基准 MindBench，它不仅包含精心构建的双语图像、详细注释和评估体系，还特别设计了五类结构化理解和解析任务，涵盖文本识别、空间意识等关键领域。实验表明，当前模型在处理结构化文档信息方面仍有巨大潜力。我们期待 MindBench 能推动结构化文档分析技术的研究与应用。MindBench 现已上线，访问地址为：https://miasanlei.github.io/MindBench.github.io/。",
    "title_cn": "MindBench：全面评估思维导图结构识别与分析的基准",
    "tags": [
      "LLM应用",
      "文档分析",
      "人工智能"
    ]
  },
  {
    "title": "Improving Retrieval-augmented Text-to-SQL with AST-based Ranking and Schema Pruning",
    "submit_datetime": "2024年07月03日",
    "abstract": "We focus on Text-to-SQL semantic parsing from the perspective of Large Language Models. Motivated by challenges related to the size of commercial database schemata and the deployability of business intelligence solutions, we propose an approach that dynamically retrieves input database information and uses abstract syntax trees to select few-shot examples for in-context learning.\n  Furthermore, we investigate the extent to which an in-parallel semantic parser can be leveraged for generating $\\textit{approximated}$ versions of the expected SQL queries, to support our retrieval. We take this approach to the extreme--we adapt a model consisting of less than $500$M parameters, to act as an extremely efficient approximator, enhancing it with the ability to process schemata in a parallelised manner. We apply our approach to monolingual and cross-lingual benchmarks for semantic parsing, showing improvements over state-of-the-art baselines. Comprehensive experiments highlight the contribution of modules involved in this retrieval-augmented generation setting, revealing interesting directions for future work.",
    "pdf_link": "https://arxiv.org/abs/2407.03227",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.03227v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03227/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03227v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03227/x2.png"
      }
    ],
    "abstract_cn": "我们聚焦于大型语言模型视角下的 Text-to-SQL 语义解析。鉴于商业数据库模式庞大与商业智能解决方案的可部署性挑战，我们提出动态检索数据库信息，并利用抽象语法树精选少量样本进行上下文学习。同时，我们探索并行语义解析器在生成预期 SQL 查询近似版本中的应用，以支持检索。我们甚至将此方法推向极致，调整一个仅含 5 亿参数的模型，使其成为高效近似器，并赋予其并行处理模式的能力。在单语与跨语语义解析基准测试中，我们的方法超越了现有最佳基线。详尽实验不仅凸显了检索增强生成设置中各模块的贡献，更为未来研究指明了新方向。",
    "title_cn": "通过结合基于抽象语法树的排序和模式剪枝技术，提升检索增强型文本到SQL的转换效率。",
    "tags": [
      "LLM应用",
      "商业智能",
      "数据库"
    ]
  },
  {
    "title": "How Does Quantization Affect Multilingual LLMs?",
    "submit_datetime": "2024年07月03日",
    "abstract": "Quantization techniques are widely used to improve inference speed and deployment of large language models. While a wide body of work examines the impact of quantized LLMs on English tasks, none have examined the effect of quantization across languages. We conduct a thorough analysis of quantized multilingual LLMs, focusing on their performance across languages and at varying scales. We use automatic benchmarks, LLM-as-a-Judge methods, and human evaluation, finding that (1) harmful effects of quantization are apparent in human evaluation, and automatic metrics severely underestimate the detriment: a 1.7% average drop in Japanese across automatic tasks corresponds to a 16.0% drop reported by human evaluators on realistic prompts; (2) languages are disparately affected by quantization, with non-Latin script languages impacted worst; and (3) challenging tasks such as mathematical reasoning degrade fastest. As the ability to serve low-compute models is critical for wide global adoption of NLP technologies, our results urge consideration of multilingual performance as a key evaluation criterion for efficient models.",
    "pdf_link": "https://arxiv.org/abs/2407.03211",
    "graphs": [],
    "abstract_cn": "量化技术常用于提升大型语言模型的推理速度和部署效率。尽管已有研究探讨了量化对英语任务的影响，但跨语言的量化效应尚未被深入研究。我们针对多语言LLM进行了详尽分析，特别关注其在不同语言和规模下的表现。通过自动基准测试、LLM-as-a-Judge方法及人类评估，我们发现：（1）量化在人类评估中显示出明显负面影响，自动指标低估了其损害程度；（2）不同语言对量化的敏感度各异，非拉丁文字语言受影响尤为严重；（3）数学推理等复杂任务受量化影响最大。鉴于低计算模型在全球NLP技术推广中的重要性，我们的研究强调了多语言性能作为高效模型评估关键标准的重要性。",
    "title_cn": "量化对多语言LLM的影响如何？",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "TheoremLlama: Transforming General-Purpose LLMs into Lean4 Experts",
    "submit_datetime": "2024年07月03日",
    "abstract": "Proving mathematical theorems using computer-verifiable formal languages like Lean significantly impacts mathematical reasoning. One approach to formal theorem proving involves generating complete proofs using Large Language Models (LLMs) based on Natural Language (NL) proofs. Similar methods have shown promising results in code generation. However, most modern LLMs exhibit suboptimal performance due to the scarcity of aligned NL and Formal Language (FL) theorem-proving data. This scarcity results in a paucity of methodologies for training LLMs and techniques to fully utilize their capabilities in composing formal proofs. To address the challenges, this paper proposes **TheoremLlama**, an end-to-end framework to train a general-purpose LLM to become a Lean4 expert. This framework encompasses NL-FL aligned dataset generation methods, training approaches for the LLM formal theorem prover, and techniques for LLM Lean4 proof writing. Using the dataset generation method, we provide *Open Bootstrapped Theorems* (OBT), an NL-FL aligned and bootstrapped dataset. A key innovation in this framework is the NL-FL bootstrapping method, where NL proofs are integrated into Lean4 code for training datasets, leveraging the NL reasoning ability of LLMs for formal reasoning. The **TheoremLlama** framework achieves cumulative accuracies of 36.48% and 33.61% on MiniF2F-Valid and Test datasets respectively, surpassing the GPT-4 baseline of 22.95% and 25.41%. We have also open-sourced our model checkpoints and generated dataset, and will soon make all the code publicly available.",
    "pdf_link": "https://arxiv.org/abs/2407.03203",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.03203v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03203/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03203v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03203/HistogramT5Retrievaler-0616.jpg"
      }
    ],
    "abstract_cn": "利用计算机可验证的形式语言（如Lean）证明数学定理，极大地推动了数学推理的发展。其中一种方法是通过大型语言模型（LLM）基于自然语言（NL）证明生成完整证明，这种方法在代码生成领域已显示出潜力。然而，由于自然语言与形式语言（FL）定理证明数据的对齐不足，现代LLM的性能普遍受限。这种不足导致了训练LLM的方法和充分利用其在形式证明中能力的技术匮乏。为此，本文提出了**TheoremLlama**框架，旨在将通用LLM训练成Lean4专家。该框架涵盖了NL-FL对齐数据集生成、LLM形式定理证明器训练及Lean4证明写作技术。我们通过数据集生成方法，提供了*Open Bootstrapped Theorems*（OBT），这是一个NL-FL对齐且自举的数据集。框架的核心创新在于NL-FL自举方法，将NL证明融入Lean4代码，利用LLM的NL推理能力进行形式推理。**TheoremLlama**在MiniF2F-Valid和Test数据集上的累积准确率分别达到36.48%和33.61%，超越了GPT-4的22.95%和25.41%基线。此外，我们还开源了模型检查点和生成的数据集，并将很快公开所有代码。",
    "title_cn": "TheoremLlama：让通用 LLM 成为 Lean4 领域的专家",
    "tags": [
      "LLM应用",
      "",
      "计算机科学"
    ]
  },
  {
    "title": "Fine-Tuning with Divergent Chains of Thought Boosts Reasoning Through Self-Correction in Language Models",
    "submit_datetime": "2024年07月03日",
    "abstract": "Requiring a Large Language Model to generate intermediary reasoning steps has been shown to be an effective way of boosting performance. In fact, it has been found that instruction tuning on these intermediary reasoning steps improves model performance. In this work, we present a novel method of further improving performance by requiring models to compare multiple reasoning chains before generating a solution in a single inference step. We call this method Divergent CoT (DCoT). We find that instruction tuning on DCoT datasets boosts the performance of even smaller, and therefore more accessible, LLMs. Through a rigorous set of experiments spanning a wide range of tasks that require various reasoning types, we show that fine-tuning on DCoT consistently improves performance over the CoT baseline across model families and scales (1.3B to 70B). Through a combination of empirical and manual evaluation, we additionally show that these performance gains stem from models generating multiple divergent reasoning chains in a single inference step, indicative of the enabling of self-correction in language models. Our code and data are publicly available at https://github.com/UKPLab/arxiv2024-divergent-cot.",
    "pdf_link": "https://arxiv.org/abs/2407.03181",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.03181v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03181/intro.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03181v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03181/method.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03181v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03181/k_progression.png"
      }
    ],
    "abstract_cn": "我们发现，要求大型语言模型生成中间推理步骤能显著提升性能。为此，我们创新性地提出了Divergent CoT（DCoT）方法，即在生成答案前比较多个推理链。实验证明，对DCoT数据集进行指令调整不仅能提升大型模型性能，还能使更小、更易获取的LLM受益。跨越多样任务的严格实验显示，DCoT微调始终优于传统方法，且性能提升源自模型在单步推理中展现的多链发散能力，这标志着语言模型自我修正能力的增强。相关代码和数据已公开，详见https://github.com/UKPLab/arxiv2024-divergent-cot。",
    "title_cn": "采用多样化的思维链进行微调，能显著提升语言模型通过自我纠错机制进行推理的能力。",
    "tags": [
      "LLM应用",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Investigating Decoder-only Large Language Models for Speech-to-text Translation",
    "submit_datetime": "2024年07月03日",
    "abstract": "Large language models (LLMs), known for their exceptional reasoning capabilities, generalizability, and fluency across diverse domains, present a promising avenue for enhancing speech-related tasks. In this paper, we focus on integrating decoder-only LLMs to the task of speech-to-text translation (S2TT). We propose a decoder-only architecture that enables the LLM to directly consume the encoded speech representation and generate the text translation. Additionally, we investigate the effects of different parameter-efficient fine-tuning techniques and task formulation. Our model achieves state-of-the-art performance on CoVoST 2 and FLEURS among models trained without proprietary data. We also conduct analyses to validate the design choices of our proposed model and bring insights to the integration of LLMs to S2TT.",
    "pdf_link": "https://arxiv.org/abs/2407.03169",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.03169v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03169/x1.png"
      }
    ],
    "abstract_cn": "大型语言模型 (LLM) 因其卓越的推理能力和跨领域的流畅性，为提升语音相关任务展现了光明前景。本文聚焦于将仅解码器的 LLM 应用于语音到文本翻译 (S2TT) 任务。我们设计了一种仅解码器架构，使 LLM 能直接处理语音编码并输出文本翻译。同时，我们探讨了参数高效微调技术和任务设计的效用。在没有使用专有数据训练的模型中，我们的模型在 CoVoST 2 和 FLEURS 上表现卓越。此外，我们通过分析验证了模型设计的合理性，并为 LLM 在 S2TT 任务中的应用提供了新视角。",
    "title_cn": "探索仅解码器大型语言模型在语音转文本翻译中的应用",
    "tags": [
      "LLM应用",
      "语音识别",
      "机器翻译"
    ]
  },
  {
    "title": "SOS! Soft Prompt Attack Against Open-Source Large Language Models",
    "submit_datetime": "2024年07月03日",
    "abstract": "Open-source large language models (LLMs) have become increasingly popular among both the general public and industry, as they can be customized, fine-tuned, and freely used. However, some open-source LLMs require approval before usage, which has led to third parties publishing their own easily accessible versions. Similarly, third parties have been publishing fine-tuned or quantized variants of these LLMs. These versions are particularly appealing to users because of their ease of access and reduced computational resource demands. This trend has increased the risk of training time attacks, compromising the integrity and security of LLMs. In this work, we present a new training time attack, SOS, which is designed to be low in computational demand and does not require clean data or modification of the model weights, thereby maintaining the model's utility intact. The attack addresses security issues in various scenarios, including the backdoor attack, jailbreak attack, and prompt stealing attack. Our experimental findings demonstrate that the proposed attack is effective across all evaluated targets. Furthermore, we present the other side of our SOS technique, namely the copyright token -- a novel technique that enables users to mark their copyrighted content and prevent models from using it.",
    "pdf_link": "https://arxiv.org/abs/2407.03160",
    "graphs": [],
    "abstract_cn": "开源大型语言模型（LLM）因其可定制、微调及免费使用的特性，在公众和业界广受欢迎。然而，部分开源LLM需经批准方可使用，促使第三方推出更易获取的版本。同时，这些LLM的微调或量化版本也由第三方发布，因其便捷性和较低的计算资源需求而备受青睐。这一趋势却增加了训练期间的攻击风险，威胁到LLM的完整性与安全性。为此，我们提出了一种新型训练时攻击——SOS，该攻击计算需求低，无需清洁数据或修改模型权重，确保模型功能不受影响。SOS能有效应对多种安全威胁，如后门、越狱及提示窃取攻击。实验证明，SOS在所有测试目标上均表现出色。此外，我们还引入了SOS技术的另一创新——版权标记，允许用户为其版权内容打上标记，防止模型滥用。",
    "title_cn": "紧急呼叫！针对开源大型语言模型的软提示攻击",
    "tags": [
      "LLM应用",
      "网络安全",
      "人工智能"
    ]
  },
  {
    "title": "Let the Code LLM Edit Itself When You Edit the Code",
    "submit_datetime": "2024年07月03日",
    "abstract": "In this work, we investigate a typical scenario in code generation where a developer edits existing code in real time and requests a code assistant, e.g., a large language model, to re-predict the next token or next line on the fly. Naively, the LLM needs to re-encode the entire KV cache to provide an accurate prediction. However, this process is computationally expensive, especially when the sequence length is long. Simply encoding the edited subsequence and integrating it to the original KV cache meets the temporal confusion problem, leading to significantly worse performance. We address this efficiency and accuracy trade-off by introducing \\underline{\\textbf{Positional \\textbf{I}ntegrity \\textbf{E}ncoding} (PIE). Building upon the rotary positional encoding, PIE first removes the rotary matrices in the Key cache that introduce temporal confusion and then reapplies the correct rotary matrices. This process ensures that positional relationships between tokens are correct and requires only a single round of matrix multiplication. We validate the effectiveness of PIE through extensive experiments on the RepoBench-C-8k dataset, utilizing DeepSeek-Coder models with 1.3B, 6.7B, and 33B parameters. Our evaluation includes three real-world coding tasks: code insertion, code deletion, and multi-place code editing. Results demonstrate that PIE reduces computational overhead by over 85% compared to the standard full recomputation approach across all model sizes and tasks while well approximating the model performance.",
    "pdf_link": "https://arxiv.org/abs/2407.03157",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.03157v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03157/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03157v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03157/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03157v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03157/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03157v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03157/x4.png"
      }
    ],
    "abstract_cn": "在本研究中，我们探讨了一个代码生成的典型场景：开发者在实时编辑代码时，请求代码助手（如大型语言模型）即时预测下一个代码片段。传统的做法是LLM需重新编码整个KV缓存，这在长序列时计算成本高昂。我们通过引入**位置完整性编码（PIE）**，解决了这一效率与准确性的难题。PIE通过优化旋转位置编码，确保了令牌间位置关系的正确性，并大幅降低了计算需求。实验证明，PIE在多个实际编码任务中，相比传统方法，计算开销减少了85%以上，同时保持了模型性能。",
    "title_cn": "代码 LLM 在你修改代码时，也能自我修正。",
    "tags": [
      "LLM应用",
      "软件开发",
      "人工智能"
    ]
  },
  {
    "title": "Reinforcement Learning for Sequence Design Leveraging Protein Language Models",
    "submit_datetime": "2024年07月03日",
    "abstract": "Protein sequence design, determined by amino acid sequences, are essential to protein engineering problems in drug discovery. Prior approaches have resorted to evolutionary strategies or Monte-Carlo methods for protein design, but often fail to exploit the structure of the combinatorial search space, to generalize to unseen sequences. In the context of discrete black box optimization over large search spaces, learning a mutation policy to generate novel sequences with reinforcement learning is appealing. Recent advances in protein language models (PLMs) trained on large corpora of protein sequences offer a potential solution to this problem by scoring proteins according to their biological plausibility (such as the TM-score). In this work, we propose to use PLMs as a reward function to generate new sequences. Yet the PLM can be computationally expensive to query due to its large size. To this end, we propose an alternative paradigm where optimization can be performed on scores from a smaller proxy model that is periodically finetuned, jointly while learning the mutation policy. We perform extensive experiments on various sequence lengths to benchmark RL-based approaches, and provide comprehensive evaluations along biological plausibility and diversity of the protein. Our experimental results include favorable evaluations of the proposed sequences, along with high diversity scores, demonstrating that RL is a strong candidate for biological sequence design. Finally, we provide a modular open source implementation can be easily integrated in most RL training loops, with support for replacing the reward model with other PLMs, to spur further research in this domain. The code for all experiments is provided in the supplementary material.",
    "pdf_link": "https://arxiv.org/abs/2407.03154",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.03154v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03154/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03154v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03154/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03154v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03154/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03154v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03154/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03154v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03154/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03154v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03154/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03154v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03154/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03154v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03154/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03154v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03154/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03154v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03154/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03154v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03154/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03154v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03154/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03154v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03154/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03154v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03154/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03154v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03154/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03154v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03154/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03154v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03154/x20.png"
      }
    ],
    "abstract_cn": "蛋白质序列设计的核心在于氨基酸序列，这对药物发现中的蛋白质工程至关重要。传统方法如进化策略或蒙特卡洛方法虽被采用，但未能充分挖掘组合搜索空间的结构，也难以适应新序列。在大规模搜索空间中，利用强化学习学习突变策略生成新序列的方法引人注目。近期，蛋白质语言模型（PLMs）的发展，通过评估蛋白质的生物学合理性（如TM-score），为解决这一难题提供了新思路。我们提出将PLMs作为奖励函数来设计新序列，但考虑到其庞大的计算需求，我们创新性地提出了一种优化策略，即在一个定期微调的小型代理模型上进行评分，同时学习突变策略。通过广泛的实验，我们验证了基于RL的方法在生物学合理性和多样性方面的优势，证实了RL在生物序列设计中的潜力。此外，我们提供的开源模块化实现，易于集成到RL训练流程中，并支持替换奖励模型，旨在推动该领域的深入研究。所有实验代码均已公开。",
    "title_cn": "借助蛋白质语言模型，强化学习在序列设计领域大放异彩。",
    "tags": [
      "Agent",
      "药物发现",
      "生物信息学"
    ]
  },
  {
    "title": "Enhancing Translation Accuracy of Large Language Models through Continual Pre-Training on Parallel Data",
    "submit_datetime": "2024年07月03日",
    "abstract": "In this paper, we propose a two-phase training approach where pre-trained large language models are continually pre-trained on parallel data and then supervised fine-tuned with a small amount of high-quality parallel data. To investigate the effectiveness of our proposed approach, we conducted continual pre-training with a 3.8B-parameter model and parallel data across eight different formats. We evaluate these methods on thirteen test sets for Japanese-to-English and English-to-Japanese translation. The results demonstrate that when utilizing parallel data in continual pre-training, it is essential to alternate between source and target sentences. Additionally, we demonstrated that the translation accuracy improves only for translation directions where the order of source and target sentences aligns between continual pre-training data and inference. In addition, we demonstrate that the LLM-based translation model is more robust in translating spoken language and achieves higher accuracy with less training data compared to supervised encoder-decoder models. We also show that the highest accuracy is achieved when the data for continual pre-training consists of interleaved source and target sentences and when tags are added to the source sentences.",
    "pdf_link": "https://arxiv.org/abs/2407.03145",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.03145v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03145/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03145v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03145/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03145v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03145/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03145v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03145/x5.png"
      }
    ],
    "abstract_cn": "本文提出了一种两阶段训练策略，先在平行数据上对大型预训练语言模型进行持续预训练，再以少量高质量平行数据进行监督微调。我们通过3.8B参数模型和八种平行数据格式验证了此方法的有效性，并在日英和英日翻译的十三组测试集上进行了评估。实验表明，持续预训练中交替使用源句和目标句至关重要，且翻译准确性仅在预训练与推理的句子顺序一致时提升。此外，基于LLM的翻译模型在处理口语时更稳健，且在较少训练数据下优于传统监督模型。我们还发现，当预训练数据包含交错源句和目标句，并给源句添加标签时，翻译准确性最高。",
    "title_cn": "借助平行数据的持续预训练，我们能够显著提升大型语言模型的翻译精准度。",
    "tags": [
      "LLM应用",
      "",
      "机器学习"
    ]
  },
  {
    "title": "Social Bias Evaluation for Large Language Models Requires Prompt Variations",
    "submit_datetime": "2024年07月03日",
    "abstract": "Warning: This paper contains examples of stereotypes and biases. Large Language Models (LLMs) exhibit considerable social biases, and various studies have tried to evaluate and mitigate these biases accurately. Previous studies use downstream tasks as prompts to examine the degree of social biases for evaluation and mitigation. While LLMs' output highly depends on prompts, previous studies evaluating and mitigating bias have often relied on a limited variety of prompts. In this paper, we investigate the sensitivity of LLMs when changing prompt variations (task instruction and prompt, few-shot examples, debias-prompt) by analyzing task performance and social bias of LLMs. Our experimental results reveal that LLMs are highly sensitive to prompts to the extent that the ranking of LLMs fluctuates when comparing models for task performance and social bias. Additionally, we show that LLMs have tradeoffs between performance and social bias caused by the prompts. Less bias from prompt setting may result in reduced performance. Moreover, the ambiguity of instances is one of the reasons for this sensitivity to prompts in advanced LLMs, leading to various outputs. We recommend using diverse prompts, as in this study, to compare the effects of prompts on social bias in LLMs.",
    "pdf_link": "https://arxiv.org/abs/2407.03129",
    "graphs": [],
    "abstract_cn": "警告：本文涉及刻板印象和偏见的内容。大型语言模型 (LLM) 存在显著的社会偏见，相关研究正努力准确评估并缓解这些偏见。以往研究通过下游任务提示来检测社会偏见的程度，但这些研究往往依赖于有限的提示类型。本文探讨了 LLM 在改变不同提示（包括任务指令、少样本示例及去偏提示）时的敏感性，并发现 LLM 对提示极为敏感，甚至影响模型在任务性能和社会偏见方面的排名。同时，提示设置中的偏见减少可能导致性能下降，而实例的模糊性也是 LLM 对提示敏感的原因之一。因此，我们建议采用多样化的提示来评估其对 LLM 社会偏见的影响。",
    "title_cn": "评估大型语言模型的社会偏见，需借助多样化的提示手段。",
    "tags": [
      "LLM理论",
      "社会科学",
      "人工智能"
    ]
  },
  {
    "title": "KeyVideoLLM: Towards Large-scale Video Keyframe Selection",
    "submit_datetime": "2024年07月03日",
    "abstract": "Recently, with the rise of web videos, managing and understanding large-scale video datasets has become increasingly important. Video Large Language Models (VideoLLMs) have emerged in recent years due to their strong video understanding capabilities. However, training and inference processes for VideoLLMs demand vast amounts of data, presenting significant challenges to data management, particularly regarding efficiency, robustness, and effectiveness. In this work, we present KeyVideoLLM, a text-video frame similarity-based keyframe selection method designed to manage VideoLLM data efficiently, robustly, and effectively. Specifically, KeyVideoLLM achieves a remarkable data compression rate of up to 60.9 times, substantially lowering disk space requirements, which proves its high efficiency. Additionally, it maintains a 100% selection success rate across all video formats and scales, enhances processing speed by up to 200 times compared to existing keyframe selection methods, and does not require hyperparameter tuning. Beyond its outstanding efficiency and robustness, KeyVideoLLM further improves model performance in video question-answering tasks during both training and inference stages. Notably, it consistently achieved the state-of-the-art (SoTA) experimental results on diverse datasets.",
    "pdf_link": "https://arxiv.org/abs/2407.03104",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.03104v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03104/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03104v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03104/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03104v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03104/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03104v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03104/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03104v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03104/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03104v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03104/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03104v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03104/x7.png"
      }
    ],
    "abstract_cn": "随着网络视频的兴起，大规模视频数据集的管理与理解变得愈发关键。视频大型语言模型（VideoLLMs）因其卓越的视频理解能力而崭露头角，但其对海量数据的需求给数据管理带来了挑战，尤其是在效率、鲁棒性和有效性方面。为此，我们推出了KeyVideoLLM，一种基于文本-视频帧相似性的关键帧选择方法，旨在高效、稳健且有效地管理VideoLLM数据。KeyVideoLLM不仅实现了高达60.9倍的数据压缩率，大幅节省了存储空间，还保持了100%的选择成功率，并在处理速度上比现有方法快200倍，且无需调整超参数。此外，它在视频问答任务中显著提升了模型性能，并在多个数据集上持续刷新最先进（SoTA）的实验记录。",
    "title_cn": "KeyVideoLLM：探索大规模视频关键帧的精选之道",
    "tags": [
      "LLM应用",
      "视频处理",
      "人工智能"
    ]
  },
  {
    "title": "ScreenTK: Seamless Detection of Time-Killing Moments Using Continuous Mobile Screen Text Monitoring",
    "submit_datetime": "2024年07月03日",
    "abstract": "Smartphones have become essential to people's digital lives, providing a continuous stream of information and connectivity. However, this constant flow can lead to moments where users are simply passing time rather than engaging meaningfully. This underscores the importance of developing methods to identify these \"time-killing\" moments, enabling the delivery of important notifications in a way that minimizes interruptions and enhances user engagement. Recent work has utilized screenshots taken every 5 seconds to detect time-killing activities on smartphones. However, this method often misses to capture phone usage between intervals. We demonstrate that up to 50% of time-killing instances go undetected using screenshots, leading to substantial gaps in understanding user behavior. To address this limitation, we propose a method called ScreenTK that detects time-killing moments by leveraging continuous screen text monitoring and on-device large language models (LLMs). Screen text contains more comprehensive information than screenshots and allows LLMs to summarize detailed phone usage. To verify our framework, we conducted experiments with six participants, capturing 1,034 records of different time-killing moments. Initial results show that our framework outperforms state-of-the-art solutions by 38% in our case study.",
    "pdf_link": "https://arxiv.org/abs/2407.03063",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.03063v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03063/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03063v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03063/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03063v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03063/x3.png"
      }
    ],
    "abstract_cn": "智能手机已成为数字生活的必需品，不断提供信息和连接。然而，这种持续的信息流有时会让用户只是打发时间而非真正参与。因此，识别这些“消磨时间”时刻并优化通知传递方式变得尤为重要。现有方法通过每5秒截屏来检测消磨时间活动，但常遗漏间隔间的使用情况。我们发现，这种方法可能漏检高达50%的消磨时间实例，导致对用户行为的理解存在显著漏洞。为此，我们提出ScreenTK方法，通过持续监控屏幕文本和利用设备上的大型语言模型（LLMs）来更准确地检测消磨时间时刻。屏幕文本提供了比截图更丰富的信息，使LLMs能更详细地总结手机使用情况。我们通过六名参与者的实验，记录了1,034条消磨时间时刻的数据，初步结果表明，我们的框架在案例研究中比现有最佳方案提升了38%。",
    "title_cn": "ScreenTK：通过持续监控移动屏幕文本，精准捕捉消磨时光的瞬间",
    "tags": [
      "LLM应用",
      "智能手机",
      "用户体验"
    ]
  },
  {
    "title": "ALTER: Augmentation for Large-Table-Based Reasoning",
    "submit_datetime": "2024年07月03日",
    "abstract": "While extensive research has explored the use of large language models (LLMs) for table-based reasoning, most approaches struggle with scalability when applied to large tables. To maintain the superior comprehension abilities of LLMs in these scenarios, we introduce ALTER(Augmentation for Large-Table-Based Reasoning)-a framework designed to harness the latent augmentation potential in both free-form natural language (NL) questions, via the query augmentor, and semi-structured tabular data, through the table augmentor. By utilizing only a small subset of relevant data from the table and supplementing it with pre-augmented schema, semantic, and literal information, ALTER achieves outstanding performance on table-based reasoning benchmarks. We also provide a detailed analysis of large-table scenarios, comparing different methods and various partitioning principles. In these scenarios, our method outperforms all other approaches and exhibits robustness and efficiency against perturbations.",
    "pdf_link": "https://arxiv.org/abs/2407.03061",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.03061v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03061/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03061v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03061/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03061v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03061/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03061v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03061/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03061v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03061/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03061v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03061/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03061v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03061/x7.png"
      }
    ],
    "abstract_cn": "尽管已有研究尝试利用大型语言模型 (LLM) 进行基于表格的推理，但多数方法在处理大型表格时面临可扩展性挑战。为此，我们推出了 ALTER 框架，该框架通过查询增强器和表格增强器，有效利用自然语言问题和半结构化表格数据的潜在增强能力。ALTER 通过精选表格数据子集并结合预增强的信息，显著提升了基于表格推理任务的性能。此外，我们还深入分析了大型表格应用场景，对比了多种方法和分区策略。在这些复杂场景中，ALTER 不仅表现卓越，还展现了出色的鲁棒性和效率。",
    "title_cn": "ALTER：大型表格推理的增强方案",
    "tags": [
      "LLM应用",
      "数据分析",
      "人工智能"
    ]
  },
  {
    "title": "Improving Conversational Abilities of Quantized Large Language Models via Direct Preference Alignment",
    "submit_datetime": "2024年07月03日",
    "abstract": "The rapid advancement of large language models (LLMs) has facilitated their transformation into conversational chatbots that can grasp contextual nuances and generate pertinent sentences, closely mirroring human values through advanced techniques such as instruction tuning and reinforcement learning from human feedback (RLHF). However, the computational efficiency required for LLMs, achieved through techniques like post-training quantization (PTQ), presents challenges such as token-flipping that can impair chatbot performance. In response, we propose a novel preference alignment approach, quantization-aware direct preference optimization (QDPO), that aligns quantized LLMs with their full-precision counterparts, improving conversational abilities. Evaluated on two instruction-tuned LLMs in various languages, QDPO demonstrated superior performance in improving conversational abilities compared to established PTQ and knowledge-distillation fine-tuning techniques, marking a significant step forward in the development of efficient and effective conversational LLMs.",
    "pdf_link": "https://arxiv.org/abs/2407.03051",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.03051v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03051/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03051v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03051/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03051v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03051/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03051v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03051/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03051v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03051/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03051v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03051/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03051v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03051/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03051v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03051/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03051v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03051/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03051v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03051/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03051v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03051/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03051v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03051/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03051v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03051/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03051v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03051/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03051v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03051/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03051v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03051/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03051v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03051/x17.png"
      }
    ],
    "abstract_cn": "随着大型语言模型 (LLM) 的飞速进步，它们已进化为能够捕捉语境细节并生成恰当语句的对话机器人，通过指令调优和基于人类反馈的强化学习 (RLHF) 等技术，它们越来越贴近人类价值观。但 LLM 所需的计算效率，尤其是通过后训练量化 (PTQ) 等技术实现的效率，带来了令牌翻转等挑战，可能影响聊天机器人的性能。为此，我们创新性地提出了量化感知直接偏好优化 (QDPO)，这一方法有效对齐了量化 LLM 与全精度模型，显著提升了对话能力。在多语言环境下对两种指令调优的 LLM 进行评估，QDPO 在提升对话能力方面超越了传统的 PTQ 和知识蒸馏微调技术，为高效且强大的对话 LLM 的发展开辟了新篇章。",
    "title_cn": "借助直接偏好对齐，我们致力于提升量化大型语言模型在对话中的表现。",
    "tags": [
      "LLM应用",
      "人工智能",
      "对话系统"
    ]
  },
  {
    "title": "JailbreakHunter: A Visual Analytics Approach for Jailbreak Prompts Discovery from Large-Scale Human-LLM Conversational Datasets",
    "submit_datetime": "2024年07月03日",
    "abstract": "Large Language Models (LLMs) have gained significant attention but also raised concerns due to the risk of misuse. Jailbreak prompts, a popular type of adversarial attack towards LLMs, have appeared and constantly evolved to breach the safety protocols of LLMs. To address this issue, LLMs are regularly updated with safety patches based on reported jailbreak prompts. However, malicious users often keep their successful jailbreak prompts private to exploit LLMs. To uncover these private jailbreak prompts, extensive analysis of large-scale conversational datasets is necessary to identify prompts that still manage to bypass the system's defenses. This task is highly challenging due to the immense volume of conversation data, diverse characteristics of jailbreak prompts, and their presence in complex multi-turn conversations. To tackle these challenges, we introduce JailbreakHunter, a visual analytics approach for identifying jailbreak prompts in large-scale human-LLM conversational datasets. We have designed a workflow with three analysis levels: group-level, conversation-level, and turn-level. Group-level analysis enables users to grasp the distribution of conversations and identify suspicious conversations using multiple criteria, such as similarity with reported jailbreak prompts in previous research and attack success rates. Conversation-level analysis facilitates the understanding of the progress of conversations and helps discover jailbreak prompts within their conversation contexts. Turn-level analysis allows users to explore the semantic similarity and token overlap between a singleturn prompt and the reported jailbreak prompts, aiding in the identification of new jailbreak strategies. The effectiveness and usability of the system were verified through multiple case studies and expert interviews.",
    "pdf_link": "https://arxiv.org/abs/2407.03045",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.03045v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03045/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03045v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03045/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03045v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03045/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03045v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03045/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03045v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03045/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03045v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03045/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03045v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03045/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03045v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03045/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03045v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03045/x9.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLM）备受瞩目，但滥用风险也引发担忧。越狱提示作为针对LLM的对抗性攻击手段，不断演化以突破安全防线。为应对这一挑战，LLM定期更新安全补丁，但恶意用户常保密成功提示以利用模型。为此，我们需深入分析大规模对话数据，以揭示那些仍能绕过防御的提示。面对数据量庞大、提示多样且藏匿于复杂对话中的挑战，我们推出了JailbreakHunter，一种可视化分析工具，用于在大规模人-LLM对话中识别越狱提示。该工具通过组级、对话级和轮次级三个层次的分析，帮助用户掌握对话分布、理解对话进展，并探索提示间的语义联系，从而发现新的越狱策略。通过案例研究和专家评估，我们验证了该工具的有效性和实用性。",
    "title_cn": "JailbreakHunter：一种视觉分析方法，旨在从大规模人类与 LLM 的对话数据集中发现越狱提示。",
    "tags": [
      "LLM应用",
      "网络安全",
      "人工智能"
    ]
  },
  {
    "title": "Raw Text is All you Need: Knowledge-intensive Multi-turn Instruction Tuning for Large Language Model",
    "submit_datetime": "2024年07月03日",
    "abstract": "Instruction tuning as an effective technique aligns the outputs of large language models (LLMs) with human preference. But how to generate the seasonal multi-turn dialogues from raw documents for instruction tuning still requires further exploration. In this paper, we present a novel framework named R2S that leverages the CoD-Chain of Dialogue logic to guide large language models (LLMs) in generating knowledge-intensive multi-turn dialogues for instruction tuning. By integrating raw documents from both open-source datasets and domain-specific web-crawled documents into a benchmark K-BENCH, we cover diverse areas such as Wikipedia (English), Science (Chinese), and Artifacts (Chinese). Our approach first decides the logic flow of the current dialogue and then prompts LLMs to produce key phrases for sourcing relevant response content. This methodology enables the creation of the G I NSTRUCT instruction dataset, retaining raw document knowledge within dialoguestyle interactions. Utilizing this dataset, we fine-tune GLLM, a model designed to transform raw documents into structured multi-turn dialogues, thereby injecting comprehensive domain knowledge into the SFT model for enhanced instruction tuning. This work signifies a stride towards refining the adaptability and effectiveness of LLMs in processing and generating more accurate, contextually nuanced responses across various fields.",
    "pdf_link": "https://arxiv.org/abs/2407.03040",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.03040v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03040/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03040v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03040/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03040v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03040/x3.png"
      }
    ],
    "abstract_cn": "指令调优技术使大型语言模型 (LLM) 的输出更符合人类偏好，但如何从原始文档生成季节性多轮对话仍待探索。本文介绍的 R2S 框架，通过 CoD-对话逻辑链，指导 LLM 生成知识密集型多轮对话。我们整合了多领域的原始文档，如维基百科、科学和文物，构建了 K-BENCH 基准。首先确定对话逻辑，再引导 LLM 生成关键短语，以此创建 G I NSTRUCT 数据集，保留原始文档知识于对话中。通过微调 GLLM 模型，将原始文档转化为结构化多轮对话，注入领域知识，增强指令调优效果。这项研究推动了 LLM 在多领域生成更精准、上下文敏感响应的能力。",
    "title_cn": "仅需原始文本：为大型语言模型进行知识密集型多轮指令调优",
    "tags": [
      "LLM应用",
      "人工智能",
      ""
    ]
  },
  {
    "title": "On the Client Preference of LLM Fine-tuning in Federated Learning",
    "submit_datetime": "2024年07月03日",
    "abstract": "Reinforcement learning with human feedback (RLHF) fine-tunes a pretrained large language model (LLM) using preference datasets, enabling the LLM to generate outputs that align with human preferences. Given the sensitive nature of these preference datasets held by various clients, there is a need to implement RLHF within a federated learning (FL) framework, where clients are reluctant to share their data due to privacy concerns. To address this, we introduce a feasible framework in which clients collaboratively train a binary selector with their preference datasets using our proposed FedBis. With a well-trained selector, we can further enhance the LLM that generates human-preferred completions. Meanwhile, we propose a novel algorithm, FedBiscuit, that trains multiple selectors by organizing clients into balanced and disjoint clusters based on their preferences. Compared to the FedBis, FedBiscuit demonstrates superior performance in simulating human preferences for pairwise completions. Our extensive experiments on federated human preference datasets -- marking the first benchmark to address heterogeneous data partitioning among clients -- demonstrate that FedBiscuit outperforms FedBis and even surpasses traditional centralized training.",
    "pdf_link": "https://arxiv.org/abs/2407.03038",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.03038v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03038/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03038v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03038/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03038v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03038/x3.png"
      }
    ],
    "abstract_cn": "利用人类反馈的强化学习（RLHF）通过偏好数据集对预训练的大型语言模型（LLM）进行微调，使其输出更符合人类偏好。考虑到这些敏感的偏好数据集由不同客户持有，我们需在联邦学习（FL）框架内实施RLHF，以保护客户因隐私顾虑而不愿共享数据。为此，我们提出一个框架，客户通过我们设计的FedBis协作训练一个二元选择器。借助训练有素的选择器，我们能进一步优化LLM，使其生成更符合人类偏好的内容。此外，我们创新算法FedBiscuit，通过根据客户偏好将他们分组为平衡且独立的集群，训练多个选择器。实验显示，FedBiscuit在模拟成对完成的偏好方面表现更佳，且在处理联邦人类偏好数据集时，不仅超越FedBis，甚至优于传统集中式训练。",
    "title_cn": "探讨联邦学习环境下，客户端对 LLM 微调的偏好",
    "tags": [
      "LLM应用",
      "人工智能",
      "隐私保护"
    ]
  },
  {
    "title": "SAFT: Towards Out-of-Distribution Generalization in Fine-Tuning",
    "submit_datetime": "2024年07月03日",
    "abstract": "Handling distribution shifts from training data, known as out-of-distribution (OOD) generalization, poses a significant challenge in the field of machine learning. While a pre-trained vision-language model like CLIP has demonstrated remarkable zero-shot performance, further adaptation of the model to downstream tasks leads to undesirable degradation for OOD data. In this work, we introduce Sparse Adaptation for Fine-Tuning (SAFT), a method that prevents fine-tuning from forgetting the general knowledge in the pre-trained model. SAFT only updates a small subset of important parameters whose gradient magnitude is large, while keeping the other parameters frozen. SAFT is straightforward to implement and conceptually simple. Extensive experiments show that with only 0.1% of the model parameters, SAFT can significantly improve the performance of CLIP. It consistently outperforms baseline methods across several benchmarks. On the few-shot learning benchmark of ImageNet and its variants, SAFT gives a gain of 5.15% on average over the conventional fine-tuning method in OOD settings.",
    "pdf_link": "https://arxiv.org/abs/2407.03036",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.03036v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03036/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03036v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03036/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03036v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03036/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03036v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03036/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03036v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03036/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03036v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03036/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03036v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03036/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03036v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03036/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03036v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03036/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03036v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03036/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03036v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03036/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03036v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03036/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03036v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03036/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03036v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03036/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03036v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03036/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03036v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03036/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03036v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03036/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03036v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03036/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03036v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03036/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03036v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03036/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03036v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03036/x20.png"
      }
    ],
    "abstract_cn": "在机器学习领域，处理训练数据中的分布偏移（OOD泛化）是一个重大挑战。尽管CLIP等预训练模型在零-shot任务中表现出色，但适应下游任务时却可能导致OOD数据的性能下降。为此，我们提出了稀疏适应微调（SAFT），一种防止微调过程中遗忘预训练模型通用知识的方法。SAFT仅更新关键参数，保持其他参数不变，实现简单且效果显著。实验证明，仅需调整0.1%的模型参数，SAFT就能大幅提升CLIP性能，并在多个基准测试中超越传统方法。在ImageNet及其变体的少样本学习基准上，SAFT在OOD设置下平均提升了5.15%。",
    "title_cn": "SAFT：致力于在微调过程中实现分布外的泛化能力",
    "tags": [
      "LLM应用",
      "机器学习",
      "计算机视觉"
    ]
  },
  {
    "title": "Align and Aggregate: Compositional Reasoning with Video Alignment and Answer Aggregation for Video Question-Answering",
    "submit_datetime": "2024年07月03日",
    "abstract": "Despite the recent progress made in Video Question-Answering (VideoQA), these methods typically function as black-boxes, making it difficult to understand their reasoning processes and perform consistent compositional reasoning. To address these challenges, we propose a \\textit{model-agnostic} Video Alignment and Answer Aggregation (VA$^{3}$) framework, which is capable of enhancing both compositional consistency and accuracy of existing VidQA methods by integrating video aligner and answer aggregator modules. The video aligner hierarchically selects the relevant video clips based on the question, while the answer aggregator deduces the answer to the question based on its sub-questions, with compositional consistency ensured by the information flow along question decomposition graph and the contrastive learning strategy. We evaluate our framework on three settings of the AGQA-Decomp dataset with three baseline methods, and propose new metrics to measure the compositional consistency of VidQA methods more comprehensively. Moreover, we propose a large language model (LLM) based automatic question decomposition pipeline to apply our framework to any VidQA dataset. We extend MSVD and NExT-QA datasets with it to evaluate our VA$^3$ framework on broader scenarios. Extensive experiments show that our framework improves both compositional consistency and accuracy of existing methods, leading to more interpretable real-world VidQA models.",
    "pdf_link": "https://arxiv.org/abs/2407.03008",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.03008v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03008/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03008v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03008/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03008v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03008/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03008v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03008/x4.png"
      }
    ],
    "abstract_cn": "尽管视频问答 (VideoQA) 领域近期有所进展，但这些方法常作为黑箱，难以理解其推理过程和保持组合推理的一致性。为此，我们设计了一个模型无关的视频对齐与答案聚合框架 (VA$^{3}$)，通过整合视频对齐器和答案聚合器，提升现有 VidQA 方法的组合一致性和准确性。视频对齐器根据问题筛选相关视频片段，答案聚合器则依据子问题推导答案，确保组合一致性。我们在 AGQA-Decomp 数据集上进行了评估，并引入了新指标来全面衡量组合一致性。此外，我们利用大型语言模型 (LLM) 开发了自动问题分解流程，扩展了 MSVD 和 NExT-QA 数据集，以广泛评估 VA$^3$ 框架。实验结果显示，该框架有效提升了方法的组合一致性和准确性，使实际 VidQA 模型更具解释性。",
    "title_cn": "通过视频对齐与答案聚合，实现组合推理，提升视频问答的准确性。",
    "tags": [
      "LLM应用",
      "视频处理",
      "问答系统"
    ]
  },
  {
    "title": "What Affects the Stability of Tool Learning? An Empirical Study on the Robustness of Tool Learning Frameworks",
    "submit_datetime": "2024年07月03日",
    "abstract": "Tool learning methods have enhanced the ability of large language models (LLMs) to interact with real-world applications. Many existing works fine-tune LLMs or design prompts to enable LLMs to select appropriate tools and correctly invoke them to meet user requirements. However, it is observed in previous works that the performance of tool learning varies from tasks, datasets, training settings, and algorithms. Without understanding the impact of these factors, it can lead to inconsistent results, inefficient model deployment, and suboptimal tool utilization, ultimately hindering the practical integration and scalability of LLMs in real-world scenarios. Therefore, in this paper, we explore the impact of both internal and external factors on the performance of tool learning frameworks. Through extensive experiments on two benchmark datasets, we find several insightful conclusions for future work, including the observation that LLMs can benefit significantly from increased trial and exploration. We believe our empirical study provides a new perspective for future tool learning research.",
    "pdf_link": "https://arxiv.org/abs/2407.03007",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.03007v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03007/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03007v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03007/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03007v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03007/x3.png"
      }
    ],
    "abstract_cn": "工具学习方法提升了 LLM 与现实应用的互动能力，但性能受任务、数据集、训练设置和算法影响，导致结果不一、部署低效和工具使用欠佳。本文深入分析了这些内外因素，通过实验揭示了 LLM 在更多尝试和探索中能显著提升性能。我们的研究为工具学习领域带来了新视角。",
    "title_cn": "工具学习的稳定性受何影响？本研究深入探讨了工具学习框架的鲁棒性。",
    "tags": [
      "LLM应用",
      "人工智能",
      "软件开发"
    ]
  },
  {
    "title": "SemioLLM: Assessing Large Language Models for Semiological Analysis in Epilepsy Research",
    "submit_datetime": "2024年07月03日",
    "abstract": "Large Language Models have shown promising results in their ability to encode general medical knowledge in standard medical question-answering datasets. However, their potential application in clinical practice requires evaluation in domain-specific tasks, where benchmarks are largely missing. In this study semioLLM, we test the ability of state-of-the-art LLMs (GPT-3.5, GPT-4, Mixtral 8x7B, and Qwen-72chat) to leverage their internal knowledge and reasoning for epilepsy diagnosis. Specifically, we obtain likelihood estimates linking unstructured text descriptions of seizures to seizure-generating brain regions, using an annotated clinical database containing 1269 entries. We evaluate the LLM's performance, confidence, reasoning, and citation abilities in comparison to clinical evaluation. Models achieve above-chance classification performance with prompt engineering significantly improving their outcome, with some models achieving close-to-clinical performance and reasoning. However, our analyses also reveal significant pitfalls with several models being overly confident while showing poor performance, as well as exhibiting citation errors and hallucinations. In summary, our work provides the first extensive benchmark comparing current SOTA LLMs in the medical domain of epilepsy and highlights their ability to leverage unstructured texts from patients' medical history to aid diagnostic processes in health care.",
    "pdf_link": "https://arxiv.org/abs/2407.03004",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.03004v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03004/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03004v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03004/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03004v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03004/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03004v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03004/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03004v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03004/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03004v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03004/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03004v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03004/x7.png"
      }
    ],
    "abstract_cn": "大型语言模型在医学问答数据集中展现了出色的知识编码能力，但在临床应用中仍需在特定任务上验证。在 semioLLM 研究中，我们评估了 GPT-3.5、GPT-4 等先进模型在癫痫诊断中的表现。通过分析一个包含 1269 条数据的临床数据库，我们探索了模型如何从非结构化文本中推断癫痫相关信息。尽管模型在精心设计的提示下表现出色，接近临床水平，但仍存在过度自信和引用错误等问题。本研究首次为医学领域的 LLM 提供了详尽基准，强调了它们在辅助诊断中的潜力。",
    "title_cn": "SemioLLM：探究大型语言模型在癫痫研究符号学分析中的应用潜力",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Are Large Language Models Consistent over Value-laden Questions?",
    "submit_datetime": "2024年07月03日",
    "abstract": "Large language models (LLMs) appear to bias their survey answers toward certain values. Nonetheless, some argue that LLMs are too inconsistent to simulate particular values. Are they? To answer, we first define value consistency as the similarity of answers across (1) paraphrases of one question, (2) related questions under one topic, (3) multiple-choice and open-ended use-cases of one question, and (4) multilingual translations of a question to English, Chinese, German, and Japanese. We apply these measures to a few large ($>=34b$), open LLMs including llama-3, as well as gpt-4o, using eight thousand questions spanning more than 300 topics. Unlike prior work, we find that models are relatively consistent across paraphrases, use-cases, translations, and within a topic. Still, some inconsistencies remain. Models are more consistent on uncontroversial topics (e.g., in the U.S., \"Thanksgiving\") than on controversial ones (\"euthanasia\"). Base models are both more consistent compared to fine-tuned models and are uniform in their consistency across topics, while fine-tuned models are more inconsistent about some topics (\"euthanasia\") than others (\"women's rights\") like our human subjects (n=165).",
    "pdf_link": "https://arxiv.org/abs/2407.02996",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.02996v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02996/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02996v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02996/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02996v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02996/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02996v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02996/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02996v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02996/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02996v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02996/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02996v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02996/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02996v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02996/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02996v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02996/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02996v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02996/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02996v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02996/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02996v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02996/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02996v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02996/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02996v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02996/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02996v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02996/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02996v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02996/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02996v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02996/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02996v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02996/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02996v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02996/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02996v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02996/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02996v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02996/x20.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02996v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02996/x21.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02996v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02996/x22.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02996v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02996/x23.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02996v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02996/x24.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02996v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02996/x25.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02996v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02996/x26.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02996v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02996/x27.png"
      }
    ],
    "abstract_cn": "大型语言模型 (LLM) 在回答调查时似乎倾向于某些特定价值观。然而，有人质疑这些模型是否足够一致以模拟特定价值观。为了探讨这一问题，我们将价值一致性定义为在不同情境下的答案相似度：包括同一问题的不同表述、同一主题下的相关问题、选择题与开放式问题的答案，以及多语言翻译后的答案。我们评估了包括 llama-3 和 gpt-4o 在内的大型开放 LLM，使用了跨越 300 多个主题的八千个问题。研究发现，模型在不同情境下表现出较高的一致性，尽管在争议性主题上仍存在不一致。基础模型在一致性上优于微调模型，且在各主题上的一致性更为均匀，而微调模型在某些敏感主题上的一致性较低，这与人类受试者的表现相似。",
    "title_cn": "大型语言模型在处理价值导向问题时，其一致性如何？",
    "tags": [
      "LLM理论",
      "人工智能",
      "社会科学"
    ]
  },
  {
    "title": "Scientific Text Analysis with Robots applied to observatory proposals",
    "submit_datetime": "2024年07月03日",
    "abstract": "To test the potential disruptive effect of Artificial Intelligence (AI) transformers (e.g., ChatGPT) and their associated Large Language Models on the time allocation process, both in proposal reviewing and grading, an experiment has been set-up at ESO for the P112 Call for Proposals. The experiment aims at raising awareness in the ESO community and build valuable knowledge by identifying what future steps ESO and other observatories might need to take to stay up to date with current technologies. We present here the results of the experiment, which may further be used to inform decision-makers regarding the use of AI in the proposal review process. We find that the ChatGPT-adjusted proposals tend to receive lower grades compared to the original proposals. Moreover, ChatGPT 3.5 can generally not be trusted in providing correct scientific references, while the most recent version makes a better, but far from perfect, job. We also studied how ChatGPT deals with assessing proposals. It does an apparent remarkable job at providing a summary of ESO proposals, although it doesn't do so good to identify weaknesses. When looking at how it evaluates proposals, however, it appears that ChatGPT systematically gives a higher mark than humans, and tends to prefer proposals written by itself.",
    "pdf_link": "https://arxiv.org/abs/2407.02992",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.02992v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02992/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02992v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02992/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02992v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02992/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02992v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02992/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02992v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02992/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02992v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02992/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02992v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02992/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02992v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02992/x8.png"
      }
    ],
    "abstract_cn": "ESO 针对 P112 提案征集进行了一项实验，旨在探索 AI 转换器（如 ChatGPT）及其大型语言模型对提案审查和评分过程的影响。实验结果显示，ChatGPT 调整的提案评分普遍较低，且其提供的科学参考准确性有待提高。最新版本的 ChatGPT 虽有改进，但仍不完美。此外，ChatGPT 在总结提案内容方面表现出色，但在识别提案弱点上则不尽如人意。值得注意的是，ChatGPT 给出的评分往往高于人类，且更偏爱由其自身生成的提案。这些发现有助于决策者更好地理解 AI 在提案审查中的应用。",
    "title_cn": "机器人辅助的科学文本分析在观测站提案中的应用",
    "tags": [
      "LLM应用",
      "科学研究",
      "人工智能"
    ]
  },
  {
    "title": "LoRA-Guard: Parameter-Efficient Guardrail Adaptation for Content Moderation of Large Language Models",
    "submit_datetime": "2024年07月03日",
    "abstract": "Guardrails have emerged as an alternative to safety alignment for content moderation of large language models (LLMs). Existing model-based guardrails have not been designed for resource-constrained computational portable devices, such as mobile phones, more and more of which are running LLM-based applications locally. We introduce LoRA-Guard, a parameter-efficient guardrail adaptation method that relies on knowledge sharing between LLMs and guardrail models. LoRA-Guard extracts language features from the LLMs and adapts them for the content moderation task using low-rank adapters, while a dual-path design prevents any performance degradation on the generative task. We show that LoRA-Guard outperforms existing approaches with 100-1000x lower parameter overhead while maintaining accuracy, enabling on-device content moderation.",
    "pdf_link": "https://arxiv.org/abs/2407.02987",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.02987v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02987/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02987v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02987/x2.png"
      }
    ],
    "abstract_cn": "护栏作为大型语言模型内容审核的安全对齐替代方案崭露头角。然而，现有基于模型的护栏设计并未考虑资源受限的便携设备，如手机，这些设备正越来越多地运行本地 LLM 应用。为此，我们推出了 LoRA-Guard，一种高效利用参数的护栏适应方法，它通过 LLM 与护栏模型间的知识共享，提取语言特征并借助低秩适配器进行内容审核，同时采用双路径设计确保生成任务性能不受影响。实验表明，LoRA-Guard 在保持高准确率的同时，参数开销大幅降低，为设备端内容审核提供了新可能。",
    "title_cn": "LoRA-Guard：为大型语言模型提供参数高效的内容审核护栏适应方案",
    "tags": [
      "LLM应用",
      "移动设备",
      "内容审核"
    ]
  },
  {
    "title": "Mast Kalandar at SemEval-2024 Task 8: On the Trail of Textual Origins: RoBERTa-BiLSTM Approach to Detect AI-Generated Text",
    "submit_datetime": "2024年07月03日",
    "abstract": "Large Language Models (LLMs) have showcased impressive abilities in generating fluent responses to diverse user queries. However, concerns regarding the potential misuse of such texts in journalism, educational, and academic contexts have surfaced. SemEval 2024 introduces the task of Multigenerator, Multidomain, and Multilingual Black-Box Machine-Generated Text Detection, aiming to develop automated systems for identifying machine-generated text and detecting potential misuse. In this paper, we i) propose a RoBERTa-BiLSTM based classifier designed to classify text into two categories: AI-generated or human ii) conduct a comparative study of our model with baseline approaches to evaluate its effectiveness. This paper contributes to the advancement of automatic text detection systems in addressing the challenges posed by machine-generated text misuse. Our architecture ranked 46th on the official leaderboard with an accuracy of 80.83 among 125.",
    "pdf_link": "https://arxiv.org/abs/2407.02978",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.02978v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02978/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02978v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02978/modelHdataH.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02978v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02978/modelHdataM.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02978v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02978/modelMdataH.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02978v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02978/modelMdataM.png"
      }
    ],
    "abstract_cn": "大型语言模型 (LLM) 在生成流畅的用户查询响应方面表现出色，但其在新闻、教育和学术领域的潜在滥用引发了关注。SemEval 2024 的 Multigenerator、Multidomain 和 Multilingual Black-Box Machine-Generated Text Detection 任务，旨在开发自动识别和防范机器生成文本滥用的系统。本文提出了一种基于 RoBERTa-BiLSTM 的分类器，用于区分 AI 和人类生成的文本，并通过对比研究验证了其有效性。我们的工作有助于提升自动文本检测技术，以应对机器生成文本滥用的挑战。在 125 个参赛者中，我们的架构以 80.83% 的准确率位列第 46 名。",
    "title_cn": "Mast Kalandar 参与 SemEval-2024 任务 8，探索文本源头：采用 RoBERTa-BiLSTM 方法，精准识别 AI 生成文本。",
    "tags": [
      "LLM应用",
      "",
      ""
    ]
  },
  {
    "title": "Large Language Models as Evaluators for Scientific Synthesis",
    "submit_datetime": "2024年07月03日",
    "abstract": "Our study explores how well the state-of-the-art Large Language Models (LLMs), like GPT-4 and Mistral, can assess the quality of scientific summaries or, more fittingly, scientific syntheses, comparing their evaluations to those of human annotators. We used a dataset of 100 research questions and their syntheses made by GPT-4 from abstracts of five related papers, checked against human quality ratings. The study evaluates both the closed-source GPT-4 and the open-source Mistral model's ability to rate these summaries and provide reasons for their judgments. Preliminary results show that LLMs can offer logical explanations that somewhat match the quality ratings, yet a deeper statistical analysis shows a weak correlation between LLM and human ratings, suggesting the potential and current limitations of LLMs in scientific synthesis evaluation.",
    "pdf_link": "https://arxiv.org/abs/2407.02977",
    "graphs": [],
    "abstract_cn": "本研究深入探讨了GPT-4和Mistral等尖端大型语言模型在评估科学综合质量方面的表现，并将其与人类专家的评价进行对比。我们采用了一个包含100个研究问题及其综合的数据集，这些综合由GPT-4从五篇相关论文的摘要中生成，并与人类质量评级进行核对。初步数据显示，尽管LLMs能提供逻辑上合理的解释，这些解释在一定程度上与人类评级相符，但进一步的统计分析揭示了LLM与人类评级之间的弱相关性，这凸显了LLMs在科学综合评估中的潜力与当前局限。",
    "title_cn": "大型语言模型：科学综合的评判者",
    "tags": [
      "LLM应用",
      "科学研究",
      "人工智能"
    ]
  },
  {
    "title": "FSM: A Finite State Machine Based Zero-Shot Prompting Paradigm for Multi-Hop Question Answering",
    "submit_datetime": "2024年07月03日",
    "abstract": "Large Language Models (LLMs) with chain-of-thought (COT) prompting have demonstrated impressive abilities on simple nature language inference tasks. However, they tend to perform poorly on Multi-hop Question Answering (MHQA) tasks due to several challenges, including hallucination, error propagation and limited context length. We propose a prompting method, Finite State Machine (FSM) to enhance the reasoning capabilities of LLM for complex tasks in addition to improved effectiveness and trustworthiness. Different from COT methods, FSM addresses MHQA by iteratively decomposing a question into multi-turn sub-questions, and self-correcting in time, improving the accuracy of answers in each step. Specifically, FSM addresses one sub-question at a time and decides on the next step based on its current result and state, in an automaton-like format. Experiments on benchmarks show the effectiveness of our method. Although our method performs on par with the baseline on relatively simpler datasets, it excels on challenging datasets like Musique. Moreover, this approach mitigates the hallucination phenomenon, wherein the correct final answer can be recovered despite errors in intermediate reasoning. Furthermore, our method improves LLMs' ability to follow specified output format requirements, significantly reducing the difficulty of answer interpretation and the need for reformatting.",
    "pdf_link": "https://arxiv.org/abs/2407.02964",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.02964v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02964/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02964v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02964/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02964v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02964/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02964v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02964/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02964v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02964/x5.png"
      }
    ],
    "abstract_cn": "结合思维链提示的大型语言模型在简单推理任务上表现卓越，但在多跳问答任务中因幻觉、错误传播等问题表现欠佳。为此，我们引入了有限状态机提示法，通过迭代分解问题并实时自校，显著提升复杂任务的推理精度和可信度。实验表明，该方法在挑战性数据集上超越基线，有效缓解了中间错误导致的幻觉问题，并强化了模型遵循输出格式的能力，大幅简化了答案解读与格式调整的复杂性。",
    "title_cn": "FSM：一种基于有限状态机的零-shot 提示方法，专为多跳问题回答设计",
    "tags": [
      "LLM应用",
      "人工智能",
      ""
    ]
  },
  {
    "title": "GraCoRe: Benchmarking Graph Comprehension and Complex Reasoning in Large Language Models",
    "submit_datetime": "2024年07月03日",
    "abstract": "Evaluating the graph comprehension and reasoning abilities of Large Language Models (LLMs) is challenging and often incomplete. Existing benchmarks focus primarily on pure graph understanding, lacking a comprehensive evaluation across all graph types and detailed capability definitions. This paper presents GraCoRe, a benchmark for systematically assessing LLMs' graph comprehension and reasoning. GraCoRe uses a three-tier hierarchical taxonomy to categorize and test models on pure graph and heterogeneous graphs, subdividing capabilities into 10 distinct areas tested through 19 tasks. Our benchmark includes 11 datasets with 5,140 graphs of varying complexity. We evaluated three closed-source and seven open-source LLMs, conducting thorough analyses from both ability and task perspectives. Key findings reveal that semantic enrichment enhances reasoning performance, node ordering impacts task success, and the ability to process longer texts does not necessarily improve graph comprehension or reasoning. GraCoRe is open-sourced at https://github.com/ZIKEYUAN/GraCoRe",
    "pdf_link": "https://arxiv.org/abs/2407.02936",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.02936v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02936/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02936v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02936/v2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02936v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02936/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02936v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02936/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02936v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02936/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02936v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02936/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02936v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02936/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02936v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02936/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02936v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02936/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02936v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02936/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02936v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02936/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02936v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02936/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02936v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02936/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02936v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02936/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02936v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02936/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02936v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02936/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02936v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02936/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02936v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02936/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02936v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02936/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02936v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02936/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02936v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02936/x20.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02936v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02936/x21.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02936v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02936/x22.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02936v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02936/x23.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02936v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02936/x24.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02936v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02936/x25.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02936v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02936/x26.png"
      }
    ],
    "abstract_cn": "评估 LLMs 的图表理解和推理能力颇具挑战，现有基准多聚焦于纯图表理解，缺乏全面评估。为此，我们推出了 GraCoRe 基准，采用三层分类法，涵盖纯图表与异构图表，细分为 10 大能力领域，通过 19 项任务进行测试。该基准包含 11 个数据集，共 5,140 个图表。我们评估了 10 个 LLMs，深入分析了其能力和任务表现。研究发现，语义丰富性可提升推理性能，节点顺序对任务成功有影响，而处理长文本的能力并不必然提升图表理解或推理能力。GraCoRe 已开源，详情见 https://github.com/ZIKEYUAN/GraCoRe。",
    "title_cn": "GraCoRe：评估大型语言模型中的图表理解和复杂推理能力",
    "tags": [
      "LLM应用",
      "",
      "数据分析"
    ]
  },
  {
    "title": "GPTQT: Quantize Large Language Models Twice to Push the Efficiency",
    "submit_datetime": "2024年07月03日",
    "abstract": "Due to their large size, generative Large Language Models (LLMs) require significant computing and storage resources. This paper introduces a new post-training quantization method, GPTQT, to reduce memory usage and enhance processing speed by expressing the weight of LLM in 3bit/2bit. Practice has shown that minimizing the quantization error of weights is ineffective, leading to overfitting. Therefore, GPTQT employs a progressive two-step approach: initially quantizing weights using Linear quantization to a relatively high bit, followed by converting obtained int weight to lower bit binary coding. A re-explore strategy is proposed to optimize initial scaling factor. During inference, these steps are merged into pure binary coding, enabling efficient computation. Testing across various models and datasets confirms GPTQT's effectiveness. Compared to the strong 3-bit quantization baseline, GPTQT further reduces perplexity by 4.01 on opt-66B and increases speed by 1.24 times on opt-30b. The results on Llama2 show that GPTQT is currently the best binary coding quantization method for such kind of LLMs.",
    "pdf_link": "https://arxiv.org/abs/2407.02891",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.02891v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02891/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02891v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02891/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02891v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02891/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02891v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02891/step1bit.png"
      }
    ],
    "abstract_cn": "生成式大型语言模型 (LLM) 因其规模庞大，对计算和存储资源需求巨大。本文提出的 GPTQT 方法，通过将权重量化为 3bit/2bit，有效减少了内存占用并提升了处理速度。实践中发现，单纯减少量化误差易导致过拟合，GPTQT 因此采用两步渐进策略：先以较高位线性量化权重，再将其转换为低位的二进制编码。此外，引入重新探索策略优化初始缩放因子，推理时合并步骤为纯二进制编码，计算效率显著提升。跨模型与数据集的测试显示，GPTQT 在 opt-66B 上降低困惑度 4.01，在 opt-30b 上提速 1.24 倍，成为当前针对此类 LLM 的最佳二进制编码量化方法。",
    "title_cn": "GPTQT：通过两次量化大型语言模型，推动效率提升",
    "tags": [
      "LLM理论",
      "计算机科学",
      "人工智能"
    ]
  },
  {
    "title": "CogErgLLM: Exploring Large Language Model Systems Design Perspective Using Cognitive Ergonomics",
    "submit_datetime": "2024年07月03日",
    "abstract": "Integrating cognitive ergonomics with LLMs is essential for enhancing safety, reliability, and user satisfaction in human-AI interactions. Current LLM design often lacks this integration, leading to systems that may not fully align with human cognitive capabilities and limitations. Insufficient focus on incorporating cognitive science methods exacerbates biases in LLM outputs, while inconsistent application of user-centered design principles results in sub-optimal user experiences. To address these challenges, our position paper explores the critical integration of cognitive ergonomics principles into LLM design, aiming to provide a comprehensive framework and practical guidelines for ethical LLM development. Through our contributions, we seek to advance understanding and practice in integrating cognitive ergonomics into LLM systems, fostering safer, more reliable, and ethically sound human-AI interactions.",
    "pdf_link": "https://arxiv.org/abs/2407.02885",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.02885v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02885/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02885v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02885/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02885v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02885/x3.png"
      }
    ],
    "abstract_cn": "将认知工效学融入 LLM 设计，对于提升人机交互的安全性、可靠性和用户满意度至关重要。然而，当前 LLM 设计往往忽视了这一点，导致系统与人类认知能力不匹配。缺乏对认知科学方法的整合，不仅加剧了 LLM 输出的偏见，还导致了用户体验的不佳。为此，我们的立场文件深入探讨了如何将认知工效学原则融入 LLM 设计，旨在构建一个全面的伦理开发框架和实用指南。我们的目标是推动认知工效学在 LLM 系统中的应用，从而促进更安全、更可靠且符合伦理的人机交互。",
    "title_cn": "CogErgLLM：从认知工效学角度探究大型语言模型的系统设计",
    "tags": [
      "LLM理论",
      "人机交互",
      "伦理开发"
    ]
  },
  {
    "title": "LANE: Logic Alignment of Non-tuning Large Language Models and Online Recommendation Systems for Explainable Reason Generation",
    "submit_datetime": "2024年07月03日",
    "abstract": "The explainability of recommendation systems is crucial for enhancing user trust and satisfaction. Leveraging large language models (LLMs) offers new opportunities for comprehensive recommendation logic generation. However, in existing related studies, fine-tuning LLM models for recommendation tasks incurs high computational costs and alignment issues with existing systems, limiting the application potential of proven proprietary/closed-source LLM models, such as GPT-4. In this work, our proposed effective strategy LANE aligns LLMs with online recommendation systems without additional LLMs tuning, reducing costs and improving explainability. This innovative approach addresses key challenges in integrating language models with recommendation systems while fully utilizing the capabilities of powerful proprietary models. Specifically, our strategy operates through several key components: semantic embedding, user multi-preference extraction using zero-shot prompting, semantic alignment, and explainable recommendation generation using Chain of Thought (CoT) prompting. By embedding item titles instead of IDs and utilizing multi-head attention mechanisms, our approach aligns the semantic features of user preferences with those of candidate items, ensuring coherent and user-aligned recommendations. Sufficient experimental results including performance comparison, questionnaire voting, and visualization cases prove that our method can not only ensure recommendation performance, but also provide easy-to-understand and reasonable recommendation logic.",
    "pdf_link": "https://arxiv.org/abs/2407.02833",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.02833v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02833/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02833v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02833/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02833v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02833/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02833v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02833/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02833v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02833/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02833v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02833/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02833v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02833/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02833v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02833/x8.png"
      }
    ],
    "abstract_cn": "推荐系统的透明度是提升用户信任与满意度的关键。借助大型语言模型（LLM），我们迎来了全面推荐逻辑生成的新契机。然而，现有研究在为推荐任务微调LLM时，面临高昂计算成本及与现有系统对齐的难题，这限制了如GPT-4等专有/闭源LLM模型的应用前景。为此，我们创新性地提出了LANE策略，无需额外微调即可实现LLM与在线推荐系统的无缝对接，既降低了成本，又增强了可解释性。该策略通过语义嵌入、零-shot提示下的用户多偏好提取、语义对齐及思维链（CoT）提示下的可解释推荐生成等关键环节，确保了用户偏好与候选项目的语义一致性，从而提供连贯且贴合用户需求的推荐。实验结果显示，我们的方法不仅保障了推荐质量，更以直观易懂的方式呈现了推荐逻辑，赢得了用户的广泛认可。",
    "title_cn": "LANE：实现非调优大型语言模型与在线推荐系统的逻辑对齐，旨在生成可解释的推理。",
    "tags": [
      "LLM应用",
      "推荐系统",
      "用户体验"
    ]
  },
  {
    "title": "Exploring the Capabilities of LLMs for Code Change Related Tasks",
    "submit_datetime": "2024年07月03日",
    "abstract": "Developers deal with code-change-related tasks daily, e.g., reviewing code. Pre-trained code and code-change-oriented models have been adapted to help developers with such tasks. Recently, large language models (LLMs) have shown their effectiveness in code-related tasks. However, existing LLMs for code focus on general code syntax and semantics rather than the differences between two code versions. Thus, it is an open question how LLMs perform on code-change-related tasks.\n  To answer this question, we conduct an empirical study using \\textgreater 1B parameters LLMs on three code-change-related tasks, i.e., code review generation, commit message generation, and just-in-time comment update, with in-context learning (ICL) and parameter-efficient fine-tuning (PEFT, including LoRA and prefix-tuning). We observe that the performance of LLMs is poor without examples and generally improves with examples, but more examples do not always lead to better performance. LLMs tuned with LoRA have comparable performance to the state-of-the-art small pre-trained models. Larger models are not always better, but \\textsc{Llama~2} and \\textsc{Code~Llama} families are always the best. The best LLMs outperform small pre-trained models on the code changes that only modify comments and perform comparably on other code changes. We suggest future work should focus more on guiding LLMs to learn the knowledge specific to the changes related to code rather than comments for code-change-related tasks.",
    "pdf_link": "https://arxiv.org/abs/2407.02824",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.02824v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02824/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02824v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02824/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02824v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02824/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02824v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02824/x4.png"
      }
    ],
    "abstract_cn": "开发者日常处理代码变更任务，如代码审查。预训练模型已助力此类工作。近期，大型语言模型（LLMs）在代码任务中表现出色，但主要关注通用代码特性，而非版本差异。我们通过实证研究，利用超10亿参数的LLMs，针对代码审查生成等三项任务，结合上下文学习和参数高效微调（PEFT），发现无示例时性能不佳，示例增多性能提升，但并非越多越好。LoRA微调的LLMs与顶尖小型模型性能相当，大模型未必更优，但Llama 2和Code Llama系列始终领先。最佳LLMs在注释修改上超越小型模型，其他变更中表现相当。未来研究应聚焦于指导LLMs掌握代码变更的特定知识，而非仅注释相关。",
    "title_cn": "探究 LLM 在代码变更任务中的潜能",
    "tags": [
      "LLM应用",
      "软件开发",
      "人工智能"
    ]
  },
  {
    "title": "Efficient Training of Language Models with Compact and Consistent Next Token Distributions",
    "submit_datetime": "2024年07月03日",
    "abstract": "Maximizing the likelihood of the next token is an established, statistically sound objective for pre-training language models. In this paper we show that we can train better models faster by pre-aggregating the corpus with a collapsed $n$-gram distribution. Previous studies have proposed corpus-level $n$-gram statistics as a regularizer; however, the construction and querying of such $n$-grams, if done naively, prove to be costly and significantly impede training speed, thereby limiting their application in modern large language model pre-training.\n  We introduce an alternative compact representation of the next token distribution that, in expectation, aligns with the complete $n$-gram distribution while markedly reducing variance across mini-batches compared to the standard next-token loss. Empirically, we demonstrate that both the $n$-gram regularized model and our approximation yield substantial improvements in model quality and convergence rate compared to existing methods. Furthermore, our approximation facilitates scalability of gains to larger datasets and models compared to the straightforward $n$-gram regularization method.",
    "pdf_link": "https://arxiv.org/abs/2407.02819",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.02819v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02819/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02819v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02819/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02819v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02819/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02819v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02819/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02819v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02819/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02819v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02819/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02819v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02819/x7.png"
      }
    ],
    "abstract_cn": "在预训练语言模型中，最大化下一个词元的似然性是一个既定且统计上合理的优化目标。本文通过预先聚合具有压缩 $n$-gram 分布的语料库，展示了如何更快地训练出更优秀的模型。尽管先前研究提出将语料库级别的 $n$-gram 统计作为正则化器，但其构建和查询过程若处理不当，成本高昂且显著阻碍训练速度，限制了其在大型语言模型预训练中的应用。为此，我们引入了一种紧凑的替代表示方法，该方法在期望上与完整 $n$-gram 分布一致，同时显著减少了小批量间的方差。实证结果显示，无论是 $n$-gram 正则化模型还是我们的近似方法，都显著提升了模型质量和收敛速度。此外，我们的近似方法相较于直接的 $n$-gram 正则化，更有利于在大规模数据集和模型上扩展这些增益。",
    "title_cn": "通过紧凑一致的下一词分布，实现语言模型的高效训练",
    "tags": [
      "LLM理论",
      "人工智能",
      ""
    ]
  },
  {
    "title": "InternLM-XComposer-2.5: A Versatile Large Vision Language Model Supporting Long-Contextual Input and Output",
    "submit_datetime": "2024年07月03日",
    "abstract": "We present InternLM-XComposer-2.5 (IXC-2.5), a versatile large-vision language model that supports long-contextual input and output. IXC-2.5 excels in various text-image comprehension and composition applications, achieving GPT-4V level capabilities with merely 7B LLM backend. Trained with 24K interleaved image-text contexts, it can seamlessly extend to 96K long contexts via RoPE extrapolation. This long-context capability allows IXC-2.5 to excel in tasks requiring extensive input and output contexts. Compared to its previous 2.0 version, InternLM-XComposer-2.5 features three major upgrades in vision-language comprehension: (1) Ultra-High Resolution Understanding, (2) Fine-Grained Video Understanding, and (3) Multi-Turn Multi-Image Dialogue. In addition to comprehension, IXC-2.5 extends to two compelling applications using extra LoRA parameters for text-image composition: (1) Crafting Webpages and (2) Composing High-Quality Text-Image Articles. IXC-2.5 has been evaluated on 28 benchmarks, outperforming existing open-source state-of-the-art models on 16 benchmarks. It also surpasses or competes closely with GPT-4V and Gemini Pro on 16 key tasks. The InternLM-XComposer-2.5 is publicly available at https://github.com/InternLM/InternLM-XComposer.",
    "pdf_link": "https://arxiv.org/abs/2407.03320",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.03320v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03320/ixc2d5_radar.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03320v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03320/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03320v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03320/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03320v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03320/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03320v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03320/x4.png"
      }
    ],
    "abstract_cn": "我们推出了 InternLM-XComposer-2.5（IXC-2.5），一款支持长上下文输入输出的多功能大型视觉语言模型。IXC-2.5 在文本图像理解和合成领域表现卓越，仅凭 7B LLM 后端即达到 GPT-4V 级性能。经过 24K 交错图像文本上下文的训练，它能通过 RoPE 外推无缝扩展至 96K 长上下文，从而在需要大量上下文的任务中大放异彩。相较于 2.0 版本，IXC-2.5 在视觉语言理解方面实现了三大飞跃：超高分辨率理解、细粒度视频理解及多轮多图像对话。此外，IXC-2.5 利用额外 LoRA 参数，拓展至两大创新应用：网页制作与高质量文本图像文章创作。在 28 个基准测试中，IXC-2.5 在 16 个项目上超越了现有开源顶尖模型，并在 16 个关键任务上与 GPT-4V 和 Gemini Pro 一较高下。该模型已公开，访问地址为 https://github.com/InternLM/InternLM-XComposer。",
    "title_cn": "InternLM-XComposer-2.5：一款多功能大型视觉语言模型，专为长上下文输入与输出设计。",
    "tags": [
      "LLM应用",
      "网页制作",
      "媒体创作"
    ]
  },
  {
    "title": "Universal Length Generalization with Turing Programs",
    "submit_datetime": "2024年07月03日",
    "abstract": "Length generalization refers to the ability to extrapolate from short training sequences to long test sequences and is a challenge for current large language models. While prior work has proposed some architecture or data format changes to achieve length generalization, these proposals typically apply to a limited set of tasks. Building on prior scratchpad and Chain-of-Thought (CoT) techniques, we propose Turing Programs, a novel CoT strategy that decomposes an algorithmic task into steps mimicking the computation of a Turing Machine. This framework is both universal, as it can accommodate any algorithmic task, and simple, requiring only copying text from the context with small modifications. We show that by using Turing Programs, we obtain robust length generalization on a range of algorithmic tasks: addition, multiplication and in-context SGD. We then demonstrate that transformers achieve length generalization on random Turing Programs, suggesting that length generalization is possible for any algorithmic task. Finally, we theoretically prove that transformers can implement Turing Programs, constructing a simple RASP (Weiss et al.) program that simulates an arbitrary Turing machine.",
    "pdf_link": "https://arxiv.org/abs/2407.03310",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.03310v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03310/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03310v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03310/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03310v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03310/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03310v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03310/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03310v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03310/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03310v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03310/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03310v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03310/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03310v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03310/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03310v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03310/x9.png"
      }
    ],
    "abstract_cn": "长度泛化能力，即从短序列训练到长序列测试的外推能力，是大型语言模型面临的一大挑战。虽然已有研究尝试通过改变架构或数据格式来解决这一问题，但这些方法往往局限于特定任务。我们基于先前的scratchpad和Chain-of-Thought（CoT）技术，创新性地提出了Turing Programs策略，将算法任务分解为模拟图灵机计算的步骤。这一策略不仅通用性强，适用于任何算法任务，而且操作简便，仅需对上下文文本进行小幅修改。实验表明，采用Turing Programs策略，我们在加法、乘法及上下文SGD等多项算法任务上实现了稳健的长度泛化。进一步研究发现，transformer模型在处理随机Turing Programs时也能实现长度泛化，这表明任何算法任务都有可能实现这一目标。最后，我们从理论层面证明了transformer模型能够执行Turing Programs，并构建了一个模拟任意图灵机的简单RASP程序。",
    "title_cn": "图灵程序在通用长度泛化中的应用",
    "tags": [
      "LLM理论",
      "人工智能",
      "计算机科学"
    ]
  },
  {
    "title": "Large Language Models for JSON Schema Discovery",
    "submit_datetime": "2024年07月03日",
    "abstract": "Semi-structured data formats such as JSON have proved to be useful data models for applications that require flexibility in the format of data stored. However, JSON data often come without the schemas that are typically available with relational data. This has resulted in a number of tools for discovering schemas from a collection of data. Although such tools can be useful, existing approaches focus on the syntax of documents and ignore semantic information.\n  In this work, we explore the automatic addition of meaningful semantic information to discovered schemas similar to information that is added by human schema authors. We leverage large language models and a corpus of manually authored JSON Schema documents to generate natural language descriptions of schema elements, meaningful names for reusable definitions, and identify which discovered properties are most useful and which can be considered \"noise\". Our approach performs well on existing metrics for text generation that have been previously shown to correlate well with human judgement.",
    "pdf_link": "https://arxiv.org/abs/2407.03286",
    "graphs": [],
    "abstract_cn": "JSON 等半结构化数据格式因其灵活性在应用中广受欢迎，但缺乏关系数据中的固定模式。为此，我们研发了一种新方法，利用大型语言模型和人工编写的 JSON Schema 文档，自动为发现的模式添加语义信息，生成自然语言描述和有意义的定义名称，并区分有用与无用的属性。该方法在文本生成评估中表现优异，与人类判断高度一致。",
    "title_cn": "利用大型语言模型进行 JSON 模式探索",
    "tags": [
      "LLM应用",
      "数据管理",
      ""
    ]
  },
  {
    "title": "LLM Internal States Reveal Hallucination Risk Faced With a Query",
    "submit_datetime": "2024年07月03日",
    "abstract": "The hallucination problem of Large Language Models (LLMs) significantly limits their reliability and trustworthiness. Humans have a self-awareness process that allows us to recognize what we don't know when faced with queries. Inspired by this, our paper investigates whether LLMs can estimate their own hallucination risk before response generation. We analyze the internal mechanisms of LLMs broadly both in terms of training data sources and across 15 diverse Natural Language Generation (NLG) tasks, spanning over 700 datasets. Our empirical analysis reveals two key insights: (1) LLM internal states indicate whether they have seen the query in training data or not; and (2) LLM internal states show they are likely to hallucinate or not regarding the query. Our study explores particular neurons, activation layers, and tokens that play a crucial role in the LLM perception of uncertainty and hallucination risk. By a probing estimator, we leverage LLM self-assessment, achieving an average hallucination estimation accuracy of 84.32\\% at run time.",
    "pdf_link": "https://arxiv.org/abs/2407.03282",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.03282v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03282/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03282v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03282/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03282v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03282/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03282v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03282/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03282v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03282/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03282v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03282/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03282v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03282/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03282v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03282/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03282v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03282/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03282v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03282/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03282v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03282/x11.png"
      }
    ],
    "abstract_cn": "大型语言模型的幻觉问题严重影响了其可靠性和可信度。借鉴人类的自我意识，我们研究了模型在生成回答前能否预估幻觉风险。通过分析训练数据和15种NLG任务，我们发现模型内部状态能揭示其是否见过查询及是否可能产生幻觉。进一步探索关键神经元和激活层，我们利用模型自我评估，实现了高达84.32%的幻觉风险实时准确预估。",
    "title_cn": "LLM 的内部状态暴露了在面对查询时可能产生的幻觉风险。",
    "tags": [
      "LLM理论",
      "人工智能",
      ""
    ]
  },
  {
    "title": "AgentInstruct: Toward Generative Teaching with Agentic Flows",
    "submit_datetime": "2024年07月03日",
    "abstract": "Synthetic data is becoming increasingly important for accelerating the development of language models, both large and small. Despite several successful use cases, researchers also raised concerns around model collapse and drawbacks of imitating other models. This discrepancy can be attributed to the fact that synthetic data varies in quality and diversity. Effective use of synthetic data usually requires significant human effort in curating the data. We focus on using synthetic data for post-training, specifically creating data by powerful models to teach a new skill or behavior to another model, we refer to this setting as Generative Teaching. We introduce AgentInstruct, an extensible agentic framework for automatically creating large amounts of diverse and high-quality synthetic data. AgentInstruct can create both the prompts and responses, using only raw data sources like text documents and code files as seeds. We demonstrate the utility of AgentInstruct by creating a post training dataset of 25M pairs to teach language models different skills, such as text editing, creative writing, tool usage, coding, reading comprehension, etc. The dataset can be used for instruction tuning of any base model. We post-train Mistral-7b with the data. When comparing the resulting model Orca-3 to Mistral-7b-Instruct (which uses the same base model), we observe significant improvements across many benchmarks. For example, 40% improvement on AGIEval, 19% improvement on MMLU, 54% improvement on GSM8K, 38% improvement on BBH and 45% improvement on AlpacaEval. Additionally, it consistently outperforms other models such as LLAMA-8B-instruct and GPT-3.5-turbo.",
    "pdf_link": "https://arxiv.org/abs/2407.03502",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.03502v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03502/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03502v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03502/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03502v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03502/orcabench_performance_comparison_1.png"
      }
    ],
    "abstract_cn": "合成数据在推动语言模型发展中扮演着日益关键的角色。尽管其应用已取得一些成功，但模型崩溃和模仿缺陷的问题也引起了关注。这些问题的根源在于合成数据的质量和多样性参差不齐。要有效利用合成数据，往往需要大量的人工筛选。我们专注于利用合成数据进行模型后训练，即通过高级模型生成数据，传授新技能给其他模型，这一过程我们称之为“生成教学”。为此，我们开发了AgentInstruct框架，它能自动生成大量高质量且多样化的合成数据。该框架仅需文本和代码等原始数据作为种子，即可生成提示和响应。我们通过构建一个包含2500万对的数据集，展示了AgentInstruct的实际应用，该数据集涵盖了文本编辑、创意写作、工具操作、编程和阅读理解等多种技能。这一数据集可广泛应用于各类基础模型的指令微调。我们利用这些数据对Mistral-7b进行了后训练，结果显示，与基于相同基础模型的Mistral-7b-Instruct相比，新模型Orca-3在多项基准测试中取得了显著进步，如在AGIEval上提升了40%，在MMLU上提升了19%，在GSM8K上提升了54%，在BBH上提升了38%，在AlpacaEval上提升了45%。此外，Orca-3在性能上持续超越了LLAMA-8B-instruct和GPT-3.5-turbo等其他模型。",
    "title_cn": "AgentInstruct：迈向结合生成教学与代理流的新境界",
    "tags": [
      "Agent",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Visualizing Dialogues: Enhancing Image Selection through Dialogue Understanding with Large Language Models",
    "submit_datetime": "2024年07月03日",
    "abstract": "Recent advancements in dialogue systems have highlighted the significance of integrating multimodal responses, which enable conveying ideas through diverse modalities rather than solely relying on text-based interactions. This enrichment not only improves overall communicative efficacy but also enhances the quality of conversational experiences. However, existing methods for dialogue-to-image retrieval face limitations due to the constraints of pre-trained vision language models (VLMs) in comprehending complex dialogues accurately. To address this, we present a novel approach leveraging the robust reasoning capabilities of large language models (LLMs) to generate precise dialogue-associated visual descriptors, facilitating seamless connection with images. Extensive experiments conducted on benchmark data validate the effectiveness of our proposed approach in deriving concise and accurate visual descriptors, leading to significant enhancements in dialogue-to-image retrieval performance. Furthermore, our findings demonstrate the method's generalizability across diverse visual cues, various LLMs, and different datasets, underscoring its practicality and potential impact in real-world applications.",
    "pdf_link": "https://arxiv.org/abs/2407.03615",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.03615v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03615/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.03615v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.03615/llama-2.png"
      }
    ],
    "abstract_cn": "对话系统的最新进展强调了整合多模态响应的重要性，这种响应方式通过多种模态传达思想，不仅提升了沟通效率，还增强了对话体验。然而，现有的对话到图像检索方法受限于预训练视觉语言模型（VLM）在理解复杂对话方面的不足。为此，我们提出了一种新方法，利用大型语言模型（LLM）的强大推理能力生成精确的对话相关视觉描述符，实现与图像的无缝连接。基准数据上的实验证实了我们的方法在生成简洁准确视觉描述符方面的有效性，显著提升了检索性能。研究还表明，该方法在不同视觉线索、LLM和数据集上的通用性，凸显了其在实际应用中的实用性和潜在影响。",
    "title_cn": "借助大型语言模型，通过深入理解对话内容，我们提升了图像选择的精准度，实现了对话的可视化呈现。",
    "tags": [
      "LLM应用",
      "人工智能",
      "图像处理"
    ]
  },
  {
    "title": "LLMcap: Large Language Model for Unsupervised PCAP Failure Detection",
    "submit_datetime": "2024年07月03日",
    "abstract": "The integration of advanced technologies into telecommunication networks complicates troubleshooting, posing challenges for manual error identification in Packet Capture (PCAP) data. This manual approach, requiring substantial resources, becomes impractical at larger scales. Machine learning (ML) methods offer alternatives, but the scarcity of labeled data limits accuracy. In this study, we propose a self-supervised, large language model-based (LLMcap) method for PCAP failure detection. LLMcap leverages language-learning abilities and employs masked language modeling to learn grammar, context, and structure. Tested rigorously on various PCAPs, it demonstrates high accuracy despite the absence of labeled data during training, presenting a promising solution for efficient network analysis. Index Terms: Network troubleshooting, Packet Capture Analysis, Self-Supervised Learning, Large Language Model, Network Quality of Service, Network Performance.",
    "pdf_link": "https://arxiv.org/abs/2407.06085",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.06085v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06085/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.06085v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.06085/x2.png"
      }
    ],
    "abstract_cn": "随着先进技术融入电信网络，故障排查变得更加复杂，手动识别PCAP数据中的错误变得困难重重。传统的手动方法在大规模应用时资源消耗巨大，难以实施。虽然机器学习方法提供了替代方案，但标记数据的稀缺性限制了其准确性。本研究提出了一种基于大型语言模型的自监督方法LLMcap，用于PCAP故障检测。LLMcap运用语言学习技巧，通过掩码语言建模掌握语法、上下文和结构。在多种PCAP数据上进行严格测试后，即使训练时缺乏标记数据，LLMcap仍展现出高准确性，为网络分析的高效性提供了新的希望。关键词：网络故障排查，PCAP数据分析，自监督学习，大型语言模型，网络服务质量，网络性能。",
    "title_cn": "LLMcap：一款专为无监督 PCAP 故障检测设计的大型语言模型",
    "tags": [
      "LLM应用",
      "",
      "网络服务"
    ]
  },
  {
    "title": "Talking to Machines: do you read me?",
    "submit_datetime": "2024年07月02日",
    "abstract": "In this dissertation I would like to guide the reader to the research on dialogue but more precisely the research I have conducted during my career since my PhD thesis. Starting from modular architectures with machine learning/deep learning and reinforcement learning to end-to-end deep neural networks. Besides my work as research associate, I also present the work I have supervised in the last years.\n  I review briefly the state of the art and highlight the open research problems on conversational agents. Afterwards, I present my contribution to Task-Oriented Dialogues (TOD), both as research associate and as the industrial supervisor of CIFRE theses.  I discuss conversational QA. Particularly, I present the work of two PhD candidates Thibault Cordier and Sebastien Montella; as well as the work of the young researcher Quentin Brabant. Finally, I present the scientific project, where I discuss about Large Language Models (LLMs) for Task-Oriented Dialogue and Multimodal Task-Oriented Dialogue.",
    "pdf_link": "https://arxiv.org/abs/2407.02354",
    "graphs": [],
    "abstract_cn": "本论文旨在引领读者深入对话研究领域，特别是我自博士论文以来的学术探索。从模块化架构到端到端深度神经网络，我不仅分享了作为研究助理的经验，还展示了近年来我所指导的研究成果。简述当前对话代理的研究前沿后，我重点介绍了在任务导向对话（TOD）中的个人贡献，并深入探讨了对话问答领域，包括Thibault Cordier、Sebastien Montella和Quentin Brabant的研究工作。最后，我详述了关于大型语言模型在任务导向对话及多模态任务导向对话中的科学项目。",
    "title_cn": "机器，你懂我的话吗？",
    "tags": [
      "Agent",
      "人工智能",
      "对话系统"
    ]
  },
  {
    "title": "Embodied AI in Mobile Robots: Coverage Path Planning with Large Language Models",
    "submit_datetime": "2024年07月02日",
    "abstract": "In recent years, Large Language Models (LLMs) have demonstrated remarkable capabilities in understanding and solving mathematical problems, leading to advancements in various fields. We propose an LLM-embodied path planning framework for mobile agents, focusing on solving high-level coverage path planning issues and low-level control. Our proposed multi-layer architecture uses prompted LLMs in the path planning phase and integrates them with the mobile agents' low-level actuators. To evaluate the performance of various LLMs, we propose a coverage-weighted path planning metric to assess the performance of the embodied models. Our experiments show that the proposed framework improves LLMs' spatial inference abilities. We demonstrate that the proposed multi-layer framework significantly enhances the efficiency and accuracy of these tasks by leveraging the natural language understanding and generative capabilities of LLMs. Our experiments show that this framework can improve LLMs' 2D plane reasoning abilities and complete coverage path planning tasks. We also tested three LLM kernels: gpt-4o, gemini-1.5-flash, and claude-3.5-sonnet. The experimental results show that claude-3.5 can complete the coverage planning task in different scenarios, and its indicators are better than those of the other models.",
    "pdf_link": "https://arxiv.org/abs/2407.02220",
    "graphs": [],
    "abstract_cn": "近年来，大型语言模型（LLM）在数学问题解决方面表现出色，促进了多领域的发展。我们设计了一种移动代理的LLM路径规划框架，专注于高级覆盖路径规划和低级控制。该框架采用多层架构，在路径规划阶段融合提示LLM与移动代理的执行器。为评估LLM性能，我们引入了覆盖加权路径规划指标。实验表明，该框架增强了LLM的空间推理能力，通过利用其自然语言处理能力，显著提升了任务效率和准确性。实验还显示，该框架能增强LLM的二维推理能力，并有效完成全覆盖路径规划。我们测试了三种LLM内核：gpt-4o、gemini-1.5-flash和claude-3.5-sonnet，结果显示claude-3.5在不同场景下的覆盖规划任务中表现更优。",
    "title_cn": "移动机器人中的具身AI：借助大型语言模型实现高效覆盖路径规划",
    "tags": [
      "Agent",
      "自动化",
      "机器人"
    ]
  },
  {
    "title": "TokenPacker: Efficient Visual Projector for Multimodal LLM",
    "submit_datetime": "2024年07月02日",
    "abstract": "The visual projector serves as an essential bridge between the visual encoder and the Large Language Model (LLM) in a Multimodal LLM (MLLM). Typically, MLLMs adopt a simple MLP to preserve all visual contexts via one-to-one transformation. However, the visual tokens are redundant and can be considerably increased when dealing with high-resolution images, impairing the efficiency of MLLMs significantly. Some recent works have introduced resampler or abstractor to reduce the number of resulting visual tokens. Unfortunately, they fail to capture finer details and undermine the visual reasoning capabilities of MLLMs. In this work, we propose a novel visual projector, which adopts a coarse-to-fine scheme to inject the enriched characteristics to generate the condensed visual tokens. In specific, we first interpolate the visual features as a low-resolution point query, providing the overall visual representation as the foundation. Then, we introduce a region-to-point injection module that utilizes high-resolution, multi-level region-based cues as fine-grained reference keys and values, allowing them to be fully absorbed within the corresponding local context region. This step effectively updates the coarse point query, transforming it into an enriched one for the subsequent LLM reasoning. Extensive experiments demonstrate that our approach compresses the visual tokens by 75%~89%, while achieves comparable or even better performance across diverse benchmarks with significantly higher efficiency. The source codes can be found at https://github.com/CircleRadon/TokenPacker.",
    "pdf_link": "https://arxiv.org/abs/2407.02392",
    "graphs": [],
    "abstract_cn": "在多模态大型语言模型（MLLM）中，视觉投影仪是连接视觉编码器与大型语言模型（LLM）的关键桥梁。传统方法通过简单MLP保留视觉上下文，但处理高分辨率图像时，视觉令牌冗余增加，影响效率。近期改进虽减少令牌数量，却牺牲了细节和推理能力。我们提出新视觉投影仪，采用由粗到细策略，注入丰富特征生成浓缩令牌。首先，将视觉特征插值为低分辨率点查询，奠定整体视觉基础；接着，通过区域到点注入模块，利用高分辨率、多层次区域线索，在局部上下文区域充分吸收，有效更新点查询，为LLM推理提供丰富信息。实验显示，我们的方法大幅压缩令牌（75%~89%），在多样化基准测试中性能卓越，效率显著提升。源代码见https://github.com/CircleRadon/TokenPacker。",
    "title_cn": "TokenPacker：专为多模态 LLM 设计的高效视觉投影工具",
    "tags": [
      "LLM应用",
      "计算机视觉",
      "人工智能"
    ]
  },
  {
    "title": "Towards a Holistic Framework for Multimodal Large Language Models in Three-dimensional Brain CT Report Generation",
    "submit_datetime": "2024年07月02日",
    "abstract": "Multi-modal large language models (MLLMs) have been given free rein to explore exciting medical applications with a primary focus on radiology report generation. Nevertheless, the preliminary success in 2D radiology captioning is incompetent to reflect the real-world diagnostic challenge in the volumetric 3D anatomy. To mitigate three crucial limitation aspects in the existing literature, including (1) data complexity, (2) model capacity, and (3) evaluation metric fidelity, we collected an 18,885 text-scan pairs 3D-BrainCT dataset and applied clinical visual instruction tuning (CVIT) to train BrainGPT models to generate radiology-adherent 3D brain CT reports. Statistically, our BrainGPT scored BLEU-1 = 44.35, BLEU-4 = 20.38, METEOR = 30.13, ROUGE-L = 47.6, and CIDEr-R = 211.77 during internal testing and demonstrated an accuracy of 0.91 in captioning midline shifts on the external validation CQ500 dataset. By further inspecting the captioned report, we reported that the traditional metrics appeared to measure only the surface text similarity and failed to gauge the information density of the diagnostic purpose. To close this gap, we proposed a novel Feature-Oriented Radiology Task Evaluation (FORTE) to estimate the report's clinical relevance (lesion feature and landmarks). Notably, the BrainGPT model scored an average FORTE F1-score of 0.71 (degree=0.661; landmark=0.706; feature=0.693; impression=0.779). To demonstrate that BrainGPT models possess objective readiness to generate human-like radiology reports, we conducted a Turing test that enrolled 11 physician evaluators, and around 74% of the BrainGPT-generated captions were indistinguishable from those written by humans. Our work embodies a holistic framework that showcased the first-hand experience of curating a 3D brain CT dataset, fine-tuning anatomy-sensible language models, and proposing robust radiology evaluation metrics.",
    "pdf_link": "https://arxiv.org/abs/2407.02235",
    "graphs": [],
    "abstract_cn": "多模态大型语言模型（MLLMs）在医疗领域的应用，尤其是放射学报告生成方面，已展现出巨大潜力。然而，二维放射学字幕的初步成功并不能完全反映三维解剖学中的实际诊断挑战。为此，我们针对现有文献中的三大限制——数据复杂性、模型容量和评估指标的忠实度，收集了18,885个文本-扫描对的3D-BrainCT数据集，并采用临床视觉指令调优（CVIT）训练BrainGPT模型，以生成高质量的3D脑CT报告。内部测试显示，BrainGPT在多项指标上表现优异，如BLEU-1得分44.35，BLEU-4得分20.38，METEOR得分30.13，ROUGE-L得分47.6，CIDEr-R得分211.77，并在外部验证CQ500数据集上的字幕中线偏移准确性达到0.91。我们发现，传统评估指标仅能衡量文本表面相似性，未能深入评估诊断信息密度。因此，我们提出了创新的面向特征的放射学任务评估（FORTE），以更准确地衡量报告的临床相关性。BrainGPT模型在FORTE评估中平均F1-分数达到0.71，显示出其在病变特征和地标识别方面的优异性能。此外，通过图灵测试，我们证实了BrainGPT模型生成的报告与人类编写的报告难以区分，证明了其生成类似人类放射学报告的能力。我们的研究不仅展示了3D脑CT数据集的策划经验，还推动了解剖学敏感语言模型的微调及放射学评估指标的创新。",
    "title_cn": "构建综合框架，助力三维脑CT报告生成中的多模态大型语言模型发展",
    "tags": [
      "LLM应用",
      "",
      "放射学"
    ]
  },
  {
    "title": "Synthetic Multimodal Question Generation",
    "submit_datetime": "2024年07月02日",
    "abstract": "Multimodal Retrieval Augmented Generation (MMRAG) is a powerful approach to question-answering over multimodal documents. A key challenge with evaluating MMRAG is the paucity of high-quality datasets matching the question styles and modalities of interest. In light of this, we propose SMMQG, a synthetic data generation framework. SMMQG leverages interplay between a retriever, large language model (LLM) and large multimodal model (LMM) to generate question and answer pairs directly from multimodal documents, with the questions conforming to specified styles and modalities. We use SMMQG to generate an MMRAG dataset of 1024 questions over Wikipedia documents and evaluate state-of-the-art models using it, revealing insights into model performance that are attainable only through style- and modality-specific evaluation data. Next, we measure the quality of data produced by SMMQG via a human study. We find that the quality of our synthetic data is on par with the quality of the crowdsourced benchmark MMQA and that downstream evaluation results using both datasets strongly concur.",
    "pdf_link": "https://arxiv.org/abs/2407.02233",
    "graphs": [],
    "abstract_cn": "多模态检索增强生成（MMRAG）在多模态文档问答领域表现卓越，但评估其性能时面临高质量数据集的稀缺问题。为此，我们设计了SMMQG合成数据生成框架，该框架巧妙结合检索器、大型语言模型（LLM）和大型多模态模型（LMM），直接从多模态文档中生成符合特定风格和模态的问题与答案。我们利用SMMQG构建了一个包含1024个问题的MMRAG数据集，覆盖维基百科文档，并据此评估前沿模型，揭示了仅凭风格和模态特定数据才能洞察的模型性能。进一步地，我们通过人类研究验证了SMMQG生成数据的质量，结果显示其与MMQA众包基准不相上下，且下游评估结果高度吻合。",
    "title_cn": "多模态问题生成的合成技术",
    "tags": [
      "RAG",
      "",
      ""
    ]
  },
  {
    "title": "Crossroads of Continents: Automated Artifact Extraction for Cultural Adaptation with Large Multimodal Models",
    "submit_datetime": "2024年07月02日",
    "abstract": "In this work, we present a comprehensive three-phase study to examine (1) the effectiveness of large multimodal models (LMMs) in recognizing cultural contexts; (2) the accuracy of their representations of diverse cultures; and (3) their ability to adapt content across cultural boundaries. We first introduce Dalle Street, a large-scale dataset generated by DALL-E 3 and validated by humans, containing 9,935 images of 67 countries and 10 concept classes. We reveal disparities in cultural understanding at the sub-region level with both open-weight (LLaVA) and closed-source (GPT-4V) models on Dalle Street and other existing benchmarks. Next, we assess models' deeper culture understanding by an artifact extraction task and identify over 18,000 artifacts associated with different countries. Finally, we propose a highly composable pipeline, CultureAdapt, to adapt images from culture to culture. Our findings reveal a nuanced picture of the cultural competence of LMMs, highlighting the need to develop culture-aware systems. Dataset and code are available at https://github.com/iamshnoo/crossroads",
    "pdf_link": "https://arxiv.org/abs/2407.02067",
    "graphs": [],
    "abstract_cn": "本研究通过三阶段全面考察了大型多模态模型（LMMs）在文化识别、文化表征准确性及跨文化内容适应能力方面的表现。首先，我们推出了Dalle Street数据集，由DALL-E 3生成并经人工验证，涵盖67国及10类概念的9,935张图片。研究发现，无论是开放还是闭源模型，在次区域文化理解上均存在差异。随后，通过文物提取任务深入评估模型文化理解力，识别出逾18,000件各国相关文物。最终，我们设计了CultureAdapt流水线，实现图像的跨文化适应。研究揭示了LMMs在文化处理上的细微差别，凸显了构建文化感知系统的重要性。相关数据集与代码已公开于https://github.com/iamshnoo/crossroads。",
    "title_cn": "大陆交汇处：借助大型多模态模型实现文化适应的自动文物提取",
    "tags": [
      "LLM应用",
      "文化研究",
      "人工智能"
    ]
  },
  {
    "title": "An End-to-End Speech Summarization Using Large Language Model",
    "submit_datetime": "2024年07月02日",
    "abstract": "Abstractive Speech Summarization (SSum) aims to generate human-like text summaries from spoken content. It encounters difficulties in handling long speech input and capturing the intricate cross-modal mapping between long speech inputs and short text summaries. Research on large language models (LLMs) and multimodal information fusion has provided new insights for addressing these challenges. In this paper, we propose an end-to-end SSum model that utilizes Q-Former as a connector for the audio-text modality and employs LLMs to generate text summaries directly from speech features. We adopt a multi-stage training approach that includes LLM based ASR and Text Summarization (TSum) tasks as auxiliary tasks. ASR tasks are used to align feature spaces and enhance the LLM's ability to handle longer speech. Then, we utilize a curriculum learning strategy to facilitate the model's transition from TSum to SSum. Finally, our model achieves competitive performance on the How-2 dataset.",
    "pdf_link": "https://arxiv.org/abs/2407.02005",
    "graphs": [],
    "abstract_cn": "抽象语音摘要（SSum）旨在从口语内容中提炼出类人文本摘要，但处理长语音输入和捕捉跨模态复杂映射仍是一大挑战。本文提出一种端到端SSum模型，通过Q-Former连接音频与文本模态，并借助LLMs直接从语音特征生成摘要。我们采用多阶段训练策略，包括基于LLM的ASR和TSum任务，以对齐特征空间并增强处理长语音的能力。通过课程学习，模型顺利从TSum过渡到SSum，最终在How-2数据集上展现出优异性能。",
    "title_cn": "利用大型语言模型实现端到端语音摘要",
    "tags": [
      "LLM应用",
      "语音处理",
      ""
    ]
  },
  {
    "title": "Certainly Uncertain: A Benchmark and Metric for Multimodal Epistemic and Aleatoric Awareness",
    "submit_datetime": "2024年07月02日",
    "abstract": "The ability to acknowledge the inevitable uncertainty in their knowledge and reasoning is a prerequisite for AI systems to be truly truthful and reliable. In this paper, we present a taxonomy of uncertainty specific to vision-language AI systems, distinguishing between epistemic uncertainty (arising from a lack of information) and aleatoric uncertainty (due to inherent unpredictability), and further explore finer categories within. Based on this taxonomy, we synthesize a benchmark dataset, CertainlyUncertain, featuring 178K visual question answering (VQA) samples as contrastive pairs. This is achieved by 1) inpainting images to make previously answerable questions into unanswerable ones; and 2) using image captions to prompt large language models for both answerable and unanswerable questions. Additionally, we introduce a new metric confidence-weighted accuracy, that is well correlated with both accuracy and calibration error, to address the shortcomings of existing metrics.",
    "pdf_link": "https://arxiv.org/abs/2407.01942",
    "graphs": [],
    "abstract_cn": "AI系统的真实可靠性建立在对知识与推理中必然存在的不确定性的认识上。本文精心构建了视觉-语言AI系统的不确定性分类，细分为信息不足的认知不确定性和本质难测的偶然不确定性，并深入探索其细分领域。据此，我们打造了CertainlyUncertain数据集，内含178K对比式VQA样本，通过图像修复与语言模型提示，巧妙地将可答问题转化为不可答。同时，我们创新性地提出了置信度加权准确率这一新指标，有效结合了准确性与校准误差，旨在弥补传统指标的缺陷。",
    "title_cn": "探索不确定性：多模态认知与偶然性意识的评估基准与度量",
    "tags": [
      "LLM理论",
      "人工智能",
      "计算机视觉"
    ]
  },
  {
    "title": "Video Watermarking: Safeguarding Your Video from (Unauthorized) Annotations by Video-based LLMs",
    "submit_datetime": "2024年07月02日",
    "abstract": "The advent of video-based Large Language Models (LLMs) has significantly enhanced video understanding. However, it has also raised some safety concerns regarding data protection, as videos can be more easily annotated, even without authorization. This paper introduces Video Watermarking, a novel technique to protect videos from unauthorized annotations by such video-based LLMs, especially concerning the video content and description, in response to specific queries. By imperceptibly embedding watermarks into key video frames with multi-modal flow-based losses, our method preserves the viewing experience while preventing misuse by video-based LLMs. Extensive experiments show that Video Watermarking significantly reduces the comprehensibility of videos with various video-based LLMs, demonstrating both stealth and robustness. In essence, our method provides a solution for securing video content, ensuring its integrity and confidentiality in the face of evolving video-based LLMs technologies.",
    "pdf_link": "https://arxiv.org/abs/2407.02411",
    "graphs": [],
    "abstract_cn": "随着基于视频的 LLM 的兴起，视频理解能力得到了显著提升，但同时也带来了数据保护的安全隐患。本文提出的视频水印技术，通过在关键帧中巧妙嵌入水印，有效防止了未经授权的标注行为，尤其针对视频内容和描述。该技术不仅保持了视频的观赏体验，还通过多模态流式损失确保了水印的隐秘性和鲁棒性。实验证明，视频水印能显著降低 LLM 对视频的理解能力，为视频内容的安全提供了坚实保障，确保了其在不断进步的 LLM 技术中的完整性和保密性。",
    "title_cn": "视频水印技术：保护您的视频内容，防止基于视频的 LLM 进行未经授权的注释。",
    "tags": [
      "LLM应用",
      "视频安全",
      "数字版权保护"
    ]
  },
  {
    "title": "CEB: Compositional Evaluation Benchmark for Fairness in Large Language Models",
    "submit_datetime": "2024年07月02日",
    "abstract": "As Large Language Models (LLMs) are increasingly deployed to handle various natural language processing (NLP) tasks, concerns regarding the potential negative societal impacts of LLM-generated content have also arisen. To evaluate the biases exhibited by LLMs, researchers have recently proposed a variety of datasets. However, existing bias evaluation efforts often focus on only a particular type of bias and employ inconsistent evaluation metrics, leading to difficulties in comparison across different datasets and LLMs. To address these limitations, we collect a variety of datasets designed for the bias evaluation of LLMs, and further propose CEB, a Compositional Evaluation Benchmark that covers different types of bias across different social groups and tasks. The curation of CEB is based on our newly proposed compositional taxonomy, which characterizes each dataset from three dimensions: bias types, social groups, and tasks. By combining the three dimensions, we develop a comprehensive evaluation strategy for the bias in LLMs. Our experiments demonstrate that the levels of bias vary across these dimensions, thereby providing guidance for the development of specific bias mitigation methods.",
    "pdf_link": "https://arxiv.org/abs/2407.02408",
    "graphs": [],
    "abstract_cn": "随着 LLM 在 NLP 任务中的广泛应用，其生成内容可能带来的社会负面影响也引起了关注。为评估 LLM 的偏见，研究者们提出了多种数据集，但现有评估多聚焦于单一偏见类型，且指标不统一，导致跨数据集和模型的比较困难。为此，我们收集了多样的偏见评估数据集，并提出 CEB，一个覆盖不同社会群体和任务的多类型偏见组合评估基准。CEB 基于我们新创的组合分类法构建，该分类法从偏见类型、社会群体和任务三个维度对数据集进行全面描述。通过整合这三个维度，我们设计了一套全面的 LLM 偏见评估策略。实验显示，偏见程度在各维度间存在差异，为针对性偏见缓解方法的开发提供了方向。",
    "title_cn": "CEB：大型语言模型公平性的组合评估基准",
    "tags": [
      "LLM应用",
      "社会科学",
      ""
    ]
  },
  {
    "title": "Assessing the Code Clone Detection Capability of Large Language Models",
    "submit_datetime": "2024年07月02日",
    "abstract": "This study aims to assess the performance of two advanced Large Language Models (LLMs), GPT-3.5 and GPT-4, in the task of code clone detection. The evaluation involves testing the models on a variety of code pairs of different clone types and levels of similarity, sourced from two datasets: BigCloneBench (human-made) and GPTCloneBench (LLM-generated). Findings from the study indicate that GPT-4 consistently surpasses GPT-3.5 across all clone types. A correlation was observed between the GPTs' accuracy at identifying code clones and code similarity, with both GPT models exhibiting low effectiveness in detecting the most complex Type-4 code clones. Additionally, GPT models demonstrate a higher performance identifying code clones in LLM-generated code compared to humans-generated code. However, they do not reach impressive accuracy. These results emphasize the imperative for ongoing enhancements in LLM capabilities, particularly in the recognition of code clones and in mitigating their predisposition towards self-generated code clones--which is likely to become an issue as software engineers are more numerous to leverage LLM-enabled code generation and code refactoring tools.",
    "pdf_link": "https://arxiv.org/abs/2407.02402",
    "graphs": [],
    "abstract_cn": "本研究评估了 GPT-3.5 和 GPT-4 在代码克隆检测中的表现，发现 GPT-4 在所有克隆类型上均优于 GPT-3.5。研究还揭示了 GPT 模型在识别复杂 Type-4 克隆时的不足，以及在处理 LLM 生成代码时相对较高的性能。尽管如此，GPT 模型的准确性仍有待提高。这些发现强调了 LLM 在代码克隆识别和避免自我生成克隆方面的持续改进需求，特别是在软件工程师广泛使用 LLM 辅助工具的背景下。",
    "title_cn": "探究大型语言模型在代码克隆检测方面的能力",
    "tags": [
      "LLM应用",
      "软件工程",
      "人工智能"
    ]
  },
  {
    "title": "Learning to Refine with Fine-Grained Natural Language Feedback",
    "submit_datetime": "2024年07月02日",
    "abstract": "Recent work has explored the capability of large language models (LLMs) to identify and correct errors in LLM-generated responses. These refinement approaches frequently evaluate what sizes of models are able to do refinement for what problems, but less attention is paid to what effective feedback for refinement looks like. In this work, we propose looking at refinement with feedback as a composition of three distinct LLM competencies: (1) identification of bad generations; (2) fine-grained natural language feedback generation; (3) refining with fine-grained feedback. The first step can be implemented with a high-performing discriminative model and steps 2 and 3 can be implemented either via prompted or fine-tuned LLMs. A key property of this approach is that the step 2 critique model can give fine-grained feedback about errors, made possible by offloading the discrimination to a separate model in step 1. We show that models of different capabilities benefit from refining with this approach on the task of improving factual consistency of document grounded summaries. Overall, our proposed method consistently outperforms existing end-to-end refinement approaches and current trained models not fine-tuned for factuality critiquing.",
    "pdf_link": "https://arxiv.org/abs/2407.02397",
    "graphs": [],
    "abstract_cn": "近期研究探索了大型语言模型（LLM）在识别并修正自身生成内容中的错误方面的能力。尽管这些改进策略常聚焦于模型大小与问题类型的匹配，却较少关注何种反馈形式最为有效。本研究将反馈驱动的改进分解为三项LLM核心技能：（1）不良生成识别；（2）细致入微的自然语言反馈构建；（3）基于精细反馈的优化。首项技能可由高效判别模型实现，后两项则可通过提示或微调LLM达成。此法之精髓在于，第二步的批评模型能提供针对错误的细致反馈，得益于第一步将判别任务独立处理。实证表明，不同性能级别的模型均能通过此法在提升文档摘要的事实一致性上获益。总体而言，我们所提方法在性能上持续超越传统端到端改进及未专门针对事实核查微调的现存模型。",
    "title_cn": "精炼学习：借助细粒度自然语言反馈",
    "tags": [
      "LLM应用",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Is Your AI-Generated Code Really Secure? Evaluating Large Language Models on Secure Code Generation with CodeSecEval",
    "submit_datetime": "2024年07月02日",
    "abstract": "Large language models (LLMs) have brought significant advancements to code generation and code repair, benefiting both novice and experienced developers. However, their training using unsanitized data from open-source repositories, like GitHub, raises the risk of inadvertently propagating security vulnerabilities. Despite numerous studies investigating the safety of code LLMs, there remains a gap in comprehensively addressing their security features. In this work, we aim to present a comprehensive study aimed at precisely evaluating and enhancing the security aspects of code LLMs. To support our research, we introduce CodeSecEval, a meticulously curated dataset designed to address 44 critical vulnerability types with 180 distinct samples. CodeSecEval serves as the foundation for the automatic evaluation of code models in two crucial tasks: code generation and code repair, with a strong emphasis on security. Our experimental results reveal that current models frequently overlook security issues during both code generation and repair processes, resulting in the creation of vulnerable code. In response, we propose different strategies that leverage vulnerability-aware information and insecure code explanations to mitigate these security vulnerabilities. Furthermore, our findings highlight that certain vulnerability types particularly challenge model performance, influencing their effectiveness in real-world applications. Based on these findings, we believe our study will have a positive impact on the software engineering community, inspiring the development of improved methods for training and utilizing LLMs, thereby leading to safer and more trustworthy model deployment.",
    "pdf_link": "https://arxiv.org/abs/2407.02395",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLM）在代码生成与修复领域取得了显著进展，惠及了从初学者到资深开发者的广泛群体。然而，这些模型在训练过程中使用来自开源平台如GitHub的未净化数据，无形中增加了传播安全漏洞的风险。尽管已有研究探讨了代码LLM的安全性，但全面提升其安全性能仍面临挑战。为此，我们开展了一项全面研究，旨在精确评估并强化代码LLM的安全特性。我们精心设计了CodeSecEval数据集，涵盖44种关键漏洞类型，包含180个样本，为代码生成与修复任务中的模型安全评估奠定了基础。实验表明，现有模型在代码生成与修复过程中往往忽视安全问题，导致易受攻击代码的产生。为此，我们提出了一系列策略，通过利用漏洞感知信息与不安全代码解释，有效缓解安全风险。研究还揭示，某些特定类型的漏洞对模型性能构成较大挑战，影响其在实际应用中的表现。基于这些发现，我们预期本研究将对软件工程领域产生积极影响，推动开发更安全、更可靠的LLM训练与应用方法。",
    "title_cn": "AI 编写的代码，真的无懈可击吗？通过 CodeSecEval 工具，我们评估了大型语言模型在安全代码生成方面的表现。",
    "tags": [
      "LLM应用",
      "软件工程",
      "网络安全"
    ]
  },
  {
    "title": "Pelican: Correcting Hallucination in Vision-LLMs via Claim Decomposition and Program of Thought Verification",
    "submit_datetime": "2024年07月02日",
    "abstract": "Large Visual Language Models (LVLMs) struggle with hallucinations in visual instruction following task(s), limiting their trustworthiness and real-world applicability. We propose Pelican -- a novel framework designed to detect and mitigate hallucinations through claim verification. Pelican first decomposes the visual claim into a chain of sub-claims based on first-order predicates. These sub-claims consist of (predicate, question) pairs and can be conceptualized as nodes of a computational graph. We then use Program-of-Thought prompting to generate Python code for answering these questions through flexible composition of external tools. Pelican improves over prior work by introducing (1) intermediate variables for precise grounding of object instances, and (2) shared computation for answering the sub-question to enable adaptive corrections and inconsistency identification. We finally use reasoning abilities of LLM to verify the correctness of the the claim by considering the consistency and confidence of the (question, answer) pairs from each sub-claim. Our experiments reveal a drop in hallucination rate by $\\sim$8%-32% across various baseline LVLMs and a 27% drop compared to approaches proposed for hallucination mitigation on MMHal-Bench. Results on two other benchmarks further corroborate our results.",
    "pdf_link": "https://arxiv.org/abs/2407.02352",
    "graphs": [],
    "abstract_cn": "大型视觉语言模型 (LVLMs) 在处理视觉指令任务时易产生幻觉，影响了其可靠性和实际应用。为此，我们设计了 Pelican 框架，通过声明验证来识别并减少幻觉。Pelican 先将视觉声明拆解为一系列基于一阶谓词的子声明，这些子声明如同计算图的节点，由 (谓词, 问题) 对构成。接着，我们运用 Program-of-Thought 提示技术，生成灵活组合外部工具的 Python 代码来解答这些问题。Pelican 的创新之处在于：(1) 引入中间变量精确锁定对象实例，(2) 共享计算资源以应对子问题，从而进行自适应调整和识别不一致性。最终，我们借助 LLM 的推理能力，通过分析每个子声明中 (问题, 答案) 对的一致性和置信度来验证声明的准确性。实验表明，Pelican 在多个基准测试中将幻觉率降低了 8%-32%，相较于 MMHal-Bench 上的幻觉缓解方法，效果提升了 27%。其他两个基准测试的结果也支持了我们的结论。",
    "title_cn": "Pelican 通过声明分解和思维程序验证，有效纠正了视觉-LLMs中的幻觉问题。",
    "tags": [
      "LLM应用",
      "计算机视觉",
      "人工智能"
    ]
  },
  {
    "title": "Generative Large Language Models in Automated Fact-Checking: A Survey",
    "submit_datetime": "2024年07月02日",
    "abstract": "The dissemination of false information across online platforms poses a serious societal challenge, necessitating robust measures for information verification. While manual fact-checking efforts are still instrumental, the growing volume of false information requires automated methods. Large language models (LLMs) offer promising opportunities to assist fact-checkers, leveraging LLM's extensive knowledge and robust reasoning capabilities. In this survey paper, we investigate the utilization of generative LLMs in the realm of fact-checking, illustrating various approaches that have been employed and techniques for prompting or fine-tuning LLMs. By providing an overview of existing approaches, this survey aims to improve the understanding of utilizing LLMs in fact-checking and to facilitate further progress in LLMs' involvement in this process.",
    "pdf_link": "https://arxiv.org/abs/2407.02351",
    "graphs": [],
    "abstract_cn": "虚假信息在网络上的泛滥已成为社会的一大难题，亟需强有力的信息验证手段。虽然人工核查不可或缺，但海量虚假信息的涌现呼唤自动化解决方案。大型语言模型（LLM）凭借其广博的知识和强大的推理能力，为事实核查提供了新的助力。本篇调查论文深入探讨了LLM在事实核查领域的应用，详细介绍了多种应用方法及微调技巧。通过梳理现有研究，本文旨在深化对LLM在事实核查中作用的认识，并推动该领域的发展。",
    "title_cn": "自动化事实核查中的生成式大型语言模型：综述",
    "tags": [
      "LLM应用",
      "",
      "信息技术"
    ]
  },
  {
    "title": "MORPHEUS: Modeling Role from Personalized Dialogue History by Exploring and Utilizing Latent Space",
    "submit_datetime": "2024年07月02日",
    "abstract": "Personalized Dialogue Generation (PDG) aims to create coherent responses according to roles or personas. Traditional PDG relies on external role data, which can be scarce and raise privacy concerns. Approaches address these issues by extracting role information from dialogue history, which often fail to generically model roles in continuous space. To overcome these limitations, we introduce a novel framework \\textbf{MO}dels \\textbf{R}oles from \\textbf{P}ersonalized Dialogue \\textbf{H}istory by \\textbf{E}xploring and \\textbf{U}tilizing Latent \\textbf{S}pace (MORPHEUS) through a three-stage training process. Specifically, we create a persona codebook to represent roles in latent space compactly, and this codebook is used to construct a posterior distribution of role information. This method enables the model to generalize across roles, allowing the generation of personalized dialogues even for unseen roles. Experiments on both Chinese and English datasets demonstrate that MORPHEUS enhances the extraction of role information, and improves response generation without external role data. Additionally, MORPHEUS can be considered an efficient fine-tuning for large language models.",
    "pdf_link": "https://arxiv.org/abs/2407.02345",
    "graphs": [],
    "abstract_cn": "个性化对话生成 (PDG) 旨在根据角色特征创造连贯回应。传统方法依赖外部角色数据，常因稀缺和隐私问题受限。我们提出的 MORPHEUS 框架，通过三阶段训练，从对话历史中探索并利用潜在空间的角色信息，创建角色代码本，有效构建角色信息分布，使模型能泛化至新角色，生成个性化对话。实验证明，MORPHEUS 不仅提升角色信息提取，还优化了回应生成，无需外部角色数据，并可高效微调大型语言模型。",
    "title_cn": "MORPHEUS 项目旨在通过探索和利用潜在空间，从个性化对话历史中精准建模角色。",
    "tags": [
      "LLM应用",
      "人工智能",
      "对话系统"
    ]
  },
  {
    "title": "RVISA: Reasoning and Verification for Implicit Sentiment Analysis",
    "submit_datetime": "2024年07月02日",
    "abstract": "With an increasing social demand for fine-grained sentiment analysis (SA), implicit sentiment analysis (ISA) poses a significant challenge with the absence of salient cue words in expressions. It necessitates reliable reasoning to understand how the sentiment is aroused and thus determine implicit sentiments. In the era of Large Language Models (LLMs), Encoder-Decoder (ED) LLMs have gained popularity to serve as backbone models for SA applications, considering impressive text comprehension and reasoning ability among diverse tasks. On the other hand, Decoder-only (DO) LLMs exhibit superior natural language generation and in-context learning capabilities. However, their responses may contain misleading or inaccurate information. To identify implicit sentiment with reliable reasoning, this study proposes RVISA, a two-stage reasoning framework that harnesses the generation ability of DO LLMs and the reasoning ability of ED LLMs to train an enhanced reasoner. Specifically, we adopt three-hop reasoning prompting to explicitly furnish sentiment elements as cues. The generated rationales are utilized to fine-tune an ED LLM into a skilled reasoner. Additionally, we develop a straightforward yet effective verification mechanism to ensure the reliability of the reasoning learning. We evaluated the proposed method on two benchmark datasets and achieved state-of-the-art results in ISA performance.",
    "pdf_link": "https://arxiv.org/abs/2407.02340",
    "graphs": [],
    "abstract_cn": "随着细粒度情感分析需求的增加，隐式情感分析在没有明显线索词的表达中面临挑战。本研究提出RVISA框架，结合DO LLM的生成能力和ED LLM的推理能力，通过三跳推理提示法明确提供情感元素，微调ED LLM成为熟练推理器，并设计简单有效的验证机制确保推理可靠性。在两个基准数据集上，我们的方法在ISA性能上达到了最先进水平。",
    "title_cn": "RVISA：隐式情感分析中的推理与验证",
    "tags": [
      "LLM应用",
      "情感分析",
      "人工智能"
    ]
  },
  {
    "title": "Open foundation models for Azerbaijani language",
    "submit_datetime": "2024年07月02日",
    "abstract": "The emergence of multilingual large language models has enabled the development of language understanding and generation systems in Azerbaijani. However, most of the production-grade systems rely on cloud solutions, such as GPT-4. While there have been several attempts to develop open foundation models for Azerbaijani, these works have not found their way into common use due to a lack of systemic benchmarking. This paper encompasses several lines of work that promote open-source foundation models for Azerbaijani. We introduce (1) a large text corpus for Azerbaijani, (2) a family of encoder-only language models trained on this dataset, (3) labeled datasets for evaluating these models, and (4) extensive evaluation that covers all major open-source models with Azerbaijani support.",
    "pdf_link": "https://arxiv.org/abs/2407.02337",
    "graphs": [],
    "abstract_cn": "随着多语言大型语言模型的兴起，阿塞拜疆语的理解与生成系统得到了发展，但多数生产级系统仍依赖GPT-4等云解决方案。虽然已有尝试为阿塞拜疆语构建开放基础模型，但因缺乏系统性基准测试而未广泛应用。本文致力于推广阿塞拜疆语的开源基础模型，并介绍了大型文本语料库、仅编码器语言模型、评估用标记数据集及全面的开源模型评估。",
    "title_cn": "阿塞拜疆语言的开放基础模型",
    "tags": [
      "LLM应用",
      "语言技术",
      "开源软件"
    ]
  },
  {
    "title": "Efficient Sparse Attention needs Adaptive Token Release",
    "submit_datetime": "2024年07月02日",
    "abstract": "In recent years, Large Language Models (LLMs) have demonstrated remarkable capabilities across a wide array of text-centric tasks. However, their `large' scale introduces significant computational and storage challenges, particularly in managing the key-value states of the transformer, which limits their wider applicability. Therefore, we propose to adaptively release resources from caches and rebuild the necessary key-value states. Particularly, we accomplish this by a lightweight controller module to approximate an ideal top-$K$ sparse attention. This module retains the tokens with the highest top-$K$ attention weights and simultaneously rebuilds the discarded but necessary tokens, which may become essential for future decoding. Comprehensive experiments in natural language generation and modeling reveal that our method is not only competitive with full attention in terms of performance but also achieves a significant throughput improvement of up to 221.8%. The code for replication is available on the https://github.com/WHUIR/ADORE.",
    "pdf_link": "https://arxiv.org/abs/2407.02328",
    "graphs": [],
    "abstract_cn": "近年来，大型语言模型在众多文本任务中表现卓越，但其庞大的规模带来了计算和存储上的重大挑战，尤其是在处理 transformer 的关键-值状态时，限制了其广泛应用。为此，我们提出一种自适应资源释放策略，通过轻量级控制器模块实现理想的 top-$K$ 稀疏注意力，保留高权重令牌并重建必要但被丢弃的令牌，以备未来解码所需。实验表明，我们的方法不仅在性能上与全注意力相当，还显著提升了吞吐量，高达 221.8%。复现代码已公开在 https://github.com/WHUIR/ADORE。",
    "title_cn": "实现高效稀疏注意力，关键在于自适应释放令牌。",
    "tags": [
      "LLM理论",
      "计算机科学",
      "人工智能"
    ]
  },
  {
    "title": "Exploring the Role of Transliteration in In-Context Learning for Low-resource Languages Written in Non-Latin Scripts",
    "submit_datetime": "2024年07月02日",
    "abstract": "Decoder-only large language models (LLMs) excel in high-resource languages across various tasks through few-shot or even zero-shot in-context learning (ICL). However, their performance often does not transfer well to low-resource languages, especially those written in non-Latin scripts. Inspired by recent work that leverages transliteration in encoder-only models, we investigate whether transliteration is also effective in improving LLMs' performance for low-resource languages written in non-Latin scripts. To this end, we propose three prompt templates, where the target-language text is represented in (1) its original script, (2) Latin script, or (3) both. We apply these methods to several representative LLMs of different sizes on various tasks including text classification and sequential labeling. Our findings show that the effectiveness of transliteration varies by task type and model size. For instance, all models benefit from transliterations for sequential labeling (with increases of up to 25%).",
    "pdf_link": "https://arxiv.org/abs/2407.02320",
    "graphs": [],
    "abstract_cn": "仅解码器的 LLM 在高资源语言的多种任务中通过少样本或零样本的 ICL 表现卓越，但其在低资源语言，尤其是非拉丁文字语言上的表现往往不佳。借鉴近期利用音译提升仅编码器模型性能的研究，我们探索音译是否同样能提升非拉丁文字低资源语言的 LLM 性能。为此，我们设计了三种提示模板，分别以原始文字、拉丁文字或两者兼备的形式呈现目标语言文本。在文本分类和序列标注等任务中，我们测试了这些方法在不同大小的 LLM 上的效果。结果显示，音译的效果因任务和模型大小而异，例如，所有模型在序列标注任务中均因音译而显著提升（最高达 25%）。",
    "title_cn": "研究音译在非拉丁文字低资源语言上下文学习中的角色",
    "tags": [
      "LLM应用",
      "语言技术",
      ""
    ]
  },
  {
    "title": "Evaluating the Ability of LLMs to Solve Semantics-Aware Process Mining Tasks",
    "submit_datetime": "2024年07月02日",
    "abstract": "The process mining community has recently recognized the potential of large language models (LLMs) for tackling various process mining tasks. Initial studies report the capability of LLMs to support process analysis and even, to some extent, that they are able to reason about how processes work. This latter property suggests that LLMs could also be used to tackle process mining tasks that benefit from an understanding of process behavior. Examples of such tasks include (semantic) anomaly detection and next activity prediction, which both involve considerations of the meaning of activities and their inter-relations. In this paper, we investigate the capabilities of LLMs to tackle such semantics-aware process mining tasks. Furthermore, whereas most works on the intersection of LLMs and process mining only focus on testing these models out of the box, we provide a more principled investigation of the utility of LLMs for process mining, including their ability to obtain process mining knowledge post-hoc by means of in-context learning and supervised fine-tuning. Concretely, we define three process mining tasks that benefit from an understanding of process semantics and provide extensive benchmarking datasets for each of them. Our evaluation experiments reveal that (1) LLMs fail to solve challenging process mining tasks out of the box and when provided only a handful of in-context examples, (2) but they yield strong performance when fine-tuned for these tasks, consistently surpassing smaller, encoder-based language models.",
    "pdf_link": "https://arxiv.org/abs/2407.02310",
    "graphs": [],
    "abstract_cn": "流程挖掘领域近期发现，大型语言模型（LLMs）在处理多种流程挖掘任务上展现出巨大潜力。初期研究显示，LLMs不仅能辅助流程分析，甚至在一定程度上能推理流程运作机制。这一特性暗示LLMs可用于那些需要理解流程行为的任务，如（语义）异常检测和下一活动预测，这些任务均需考虑活动含义及其关联。本文探讨了LLMs在处理这类需语义理解的流程挖掘任务上的能力。不同于多数研究仅测试LLMs的即用性能，我们更系统地评估了LLMs在流程挖掘中的应用，包括通过上下文学习和监督微调获取流程挖掘知识的能力。我们定义了三个依赖流程语义理解的挖掘任务，并为其提供了详尽的基准数据集。实验结果显示：（1）LLMs在未微调情况下难以应对复杂流程挖掘任务，即便提供少量示例亦然；（2）然而，经过针对性微调后，LLMs表现出色，持续优于小型编码器基语言模型。",
    "title_cn": "探究 LLMs 在语义感知过程挖掘任务中的表现",
    "tags": [
      "LLM应用",
      "流程挖掘",
      "人工智能"
    ]
  },
  {
    "title": "CFinBench: A Comprehensive Chinese Financial Benchmark for Large Language Models",
    "submit_datetime": "2024年07月02日",
    "abstract": "Large language models (LLMs) have achieved remarkable performance on various NLP tasks, yet their potential in more challenging and domain-specific task, such as finance, has not been fully explored. In this paper, we present CFinBench: a meticulously crafted, the most comprehensive evaluation benchmark to date, for assessing the financial knowledge of LLMs under Chinese context. In practice, to better align with the career trajectory of Chinese financial practitioners, we build a systematic evaluation from 4 first-level categories: (1) Financial Subject: whether LLMs can memorize the necessary basic knowledge of financial subjects, such as economics, statistics and auditing. (2) Financial Qualification: whether LLMs can obtain the needed financial qualified certifications, such as certified public accountant, securities qualification and banking qualification. (3) Financial Practice: whether LLMs can fulfill the practical financial jobs, such as tax consultant, junior accountant and securities analyst. (4) Financial Law: whether LLMs can meet the requirement of financial laws and regulations, such as tax law, insurance law and economic law. CFinBench comprises 99,100 questions spanning 43 second-level categories with 3 question types: single-choice, multiple-choice and judgment. We conduct extensive experiments of 50 representative LLMs with various model size on CFinBench. The results show that GPT4 and some Chinese-oriented models lead the benchmark, with the highest average accuracy being 60.16%, highlighting the challenge presented by CFinBench. The dataset and evaluation code are available at https://cfinbench.github.io/.",
    "pdf_link": "https://arxiv.org/abs/2407.02301",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）在NLP任务上表现卓越，但在金融等特定领域的应用潜力仍待挖掘。本文介绍的CFinBench，是一个专为评估LLMs在中国金融知识掌握程度而设计的全面基准。我们根据中国金融从业者的职业路径，从四个维度构建评估体系：金融学科知识、资格认证、实践操作和法律法规。CFinBench包含99,100道题目，覆盖43个细分领域，题型多样。实验结果表明，GPT4及部分中国定制模型表现突出，最高平均准确率达60.16%，凸显了CFinBench的挑战性。数据集与评估代码已公开，详情访问https://cfinbench.github.io/。",
    "title_cn": "CFinBench：为大型语言模型打造的中文金融全面基准",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Strategic Demand-Planning in Wireless Networks: Can Generative-AI Save Spectrum and Energy?",
    "submit_datetime": "2024年07月02日",
    "abstract": "Wireless communications advance hand-in-hand with artificial intelligence (AI), indicating an interconnected advancement where each facilitates and benefits from the other. This synergy is particularly evident in the development of the sixth-generation technology standard for mobile networks (6G), envisioned to be AI-native. Generative-AI (GenAI), a novel technology capable of producing various types of outputs, including text, images, and videos, offers significant potential for wireless communications, with its distinctive features. Traditionally, conventional AI techniques have been employed for predictions, classifications, and optimization, while GenAI has more to offer. This article introduces the concept of strategic demand-planning through demand-labeling, demand-shaping, and demand-rescheduling. Accordingly, GenAI is proposed as a powerful tool to facilitate demand-shaping in wireless networks. More specifically, GenAI is used to compress and convert the content of various kind (e.g., from a higher bandwidth mode to a lower one, such as from a video to text), which subsequently enhances performance of wireless networks in various usage scenarios such as cell-switching, user association and load balancing, interference management, and disaster scenarios management. Therefore, GenAI can serve a function in saving energy and spectrum in wireless networks. With recent advancements in AI, including sophisticated algorithms like large-language-models and the development of more powerful hardware built exclusively for AI tasks, such as AI accelerators, the concept of demand-planning, particularly demand-shaping through GenAI, becomes increasingly relevant. Furthermore, recent efforts to make GenAI accessible on devices, such as user terminals, make the implementation of this concept even more straightforward and feasible.",
    "pdf_link": "https://arxiv.org/abs/2407.02292",
    "graphs": [],
    "abstract_cn": "无线通信与人工智能携手共进，彼此促进，共同发展。特别是在6G技术的研发中，这种协同效应尤为显著，6G被设想为AI原生技术。生成式AI（GenAI）作为一种新兴技术，能够创造多样化的输出，如文本、图像和视频，为无线通信带来巨大潜力。传统AI技术主要用于预测、分类和优化，而GenAI则展现出更多可能性。本文探讨了通过需求标签化、塑造和重新安排的战略需求规划，特别是提出GenAI作为推动无线网络需求塑造的有力工具。具体而言，GenAI能够压缩和转换内容，例如将视频转换为文本，从而在多种场景下提升网络性能，包括小区切换、用户关联、负载平衡、干扰管理和灾难管理。这使得GenAI在节能和节省频谱方面发挥作用。随着AI技术的进步，包括大型语言模型和专为AI设计的强大硬件，如AI加速器，通过GenAI进行需求塑造的概念变得更加重要。同时，GenAI在用户终端上的应用也使得这一概念的实施更为直接和可行。",
    "title_cn": "在无线网络的战略需求规划中，生成式人工智能能否成为频谱和能源的救星？",
    "tags": [
      "LLM应用",
      "无线通信",
      "人工智能"
    ]
  },
  {
    "title": "Multilingual Trolley Problems for Language Models",
    "submit_datetime": "2024年07月02日",
    "abstract": "As large language models (LLMs) are deployed in more and more real-world situations, it is crucial to understand their decision-making when faced with moral dilemmas. Inspired by a large-scale cross-cultural study of human moral preferences, \"The Moral Machine Experiment\", we set up the same set of moral choices for LLMs. We translate 1K vignettes of moral dilemmas, parametrically varied across key axes, into 100+ languages, and reveal the preferences of LLMs in each of these languages. We then compare the responses of LLMs to that of human speakers of those languages, harnessing a dataset of 40 million human moral judgments. We discover that LLMs are more aligned with human preferences in languages such as English, Korean, Hungarian, and Chinese, but less aligned in languages such as Hindi and Somali (in Africa). Moreover, we characterize the explanations LLMs give for their moral choices and find that fairness is the most dominant supporting reason behind GPT-4's decisions and utilitarianism by GPT-3. We also discover \"language inequality\" (which we define as the model's different development levels in different languages) in a series of meta-properties of moral decision making.",
    "pdf_link": "https://arxiv.org/abs/2407.02273",
    "graphs": [],
    "abstract_cn": "随着 LLM 在现实应用中的普及，探究其在道德困境中的决策变得至关重要。借鉴“道德机器实验”这一跨文化大型研究，我们为 LLM 设计了相同的道德选择挑战。通过将 1K 个道德困境情景翻译成 100 多种语言，我们揭示了 LLM 在各语言中的偏好，并对比了其与 4000 万人类道德判断的异同。结果显示，LLM 在英语、韩语、匈牙利语和中国语中与人类偏好更为契合，而在印地语和索马里语中则稍显偏离。进一步分析 LLM 的道德选择解释，我们发现公平性是 GPT-4 的主要决策依据，而 GPT-3 则更倾向于功利主义。此外，我们还识别出道德决策中存在的“语言不平等”现象，即模型在不同语言中的发展水平差异。",
    "title_cn": "语言模型面临的多语言电车难题",
    "tags": [
      "LLM应用",
      "人工智能伦理",
      "跨文化研究"
    ]
  },
  {
    "title": "GlyphDraw2: Automatic Generation of Complex Glyph Posters with Diffusion Models and Large Language Models",
    "submit_datetime": "2024年07月02日",
    "abstract": "Posters play a crucial role in marketing and advertising, contributing significantly to industrial design by enhancing visual communication and brand visibility. With recent advances in controllable text-to-image diffusion models, more concise research is now focusing on rendering text within synthetic images. Despite improvements in text rendering accuracy, the field of end-to-end poster generation remains underexplored. This complex task involves striking a balance between text rendering accuracy and automated layout to produce high-resolution images with variable aspect ratios. To tackle this challenge, we propose an end-to-end text rendering framework employing a triple cross-attention mechanism rooted in align learning, designed to create precise poster text within detailed contextual backgrounds. Additionally, we introduce a high-resolution dataset that exceeds 1024 pixels in image resolution. Our approach leverages the SDXL architecture. Extensive experiments validate the ability of our method to generate poster images featuring intricate and contextually rich backgrounds. Codes will be available at https://github.com/OPPO-Mente-Lab/GlyphDraw2.",
    "pdf_link": "https://arxiv.org/abs/2407.02252",
    "graphs": [],
    "abstract_cn": "海报在营销和广告中至关重要，通过提升视觉传达和品牌曝光，对工业设计贡献巨大。随着可控文本到图像技术的进步，合成图像中的文本渲染成为研究焦点。尽管文本渲染精度提升，端到端海报生成仍待深入探索。这一挑战要求在文本准确性和布局自动化间找到平衡，以产出高分辨率、多宽高比的海报。为此，我们设计了基于对齐学习的三重交叉注意力机制，旨在精细背景中精准渲染海报文本。同时，我们推出了超1024像素的高分辨率数据集，并采用SDXL架构。实验证明，我们的方法能生成背景丰富、细节精致的海报。相关代码将在GitHub上公开。",
    "title_cn": "GlyphDraw2：结合扩散模型与大型语言模型，自动创作复杂字形海报。",
    "tags": [
      "LLM应用",
      "",
      ""
    ]
  },
  {
    "title": "MIREncoder: Multi-modal IR-based Pretrained Embeddings for Performance Optimizations",
    "submit_datetime": "2024年07月02日",
    "abstract": "One of the primary areas of interest in High Performance Computing is the improvement of performance of parallel workloads. Nowadays, compilable source code-based optimization tasks that employ deep learning often exploit LLVM Intermediate Representations (IRs) for extracting features from source code. Most such works target specific tasks, or are designed with a pre-defined set of heuristics. So far, pre-trained models are rare in this domain, but the possibilities have been widely discussed. Especially approaches mimicking large-language models (LLMs) have been proposed. But these have prohibitively large training costs. In this paper, we propose MIREncoder, a M}ulti-modal IR-based Auto-Encoder that can be pre-trained to generate a learned embedding space to be used for downstream tasks by machine learning-based approaches. A multi-modal approach enables us to better extract features from compilable programs. It allows us to better model code syntax, semantics and structure. For code-based performance optimizations, these features are very important while making optimization decisions. A pre-trained model/embedding implicitly enables the usage of transfer learning, and helps move away from task-specific trained models. Additionally, a pre-trained model used for downstream performance optimization should itself have reduced overhead, and be easily usable. These considerations have led us to propose a modeling approach that i) understands code semantics and structure, ii) enables use of transfer learning, and iii) is small and simple enough to be easily re-purposed or reused even with low resource availability. Our evaluations will show that our proposed approach can outperform the state of the art while reducing overhead.",
    "pdf_link": "https://arxiv.org/abs/2407.02238",
    "graphs": [],
    "abstract_cn": "在高性能计算领域，提升并行任务性能是研究焦点。当前，深度学习在源代码优化中常通过LLVM中间表示（IRs）提取特征。多数研究聚焦特定任务或依赖预设启发式规则。尽管预训练模型在此领域尚属罕见，但其潜力已引发广泛探讨，尤其是模仿大型语言模型（LLMs）的方案，尽管训练成本高昂。本文提出MIREncoder，一种基于多模态IR的自编码器，预训练后可生成嵌入空间，助力机器学习下游任务。多模态策略强化了从可编译程序中提取特征的能力，优化了代码语法、语义和结构的建模。在代码性能优化中，这些特征至关重要。预训练模型隐含支持迁移学习，减少对特定任务模型的依赖。此外，用于性能优化的预训练模型应低开销且易用。基于此，我们设计了一种兼顾代码理解、迁移学习支持及轻量易用性的建模方法。评估表明，该方法在降低开销的同时，性能超越了现有技术。",
    "title_cn": "MIREncoder：一种基于多模态信息检索的预训练嵌入技术，旨在实现性能优化。",
    "tags": [
      "LLM应用",
      "高性能计算",
      "软件工程"
    ]
  },
  {
    "title": "PromptIntern: Saving Inference Costs by Internalizing Recurrent Prompt during Large Language Model Fine-tuning",
    "submit_datetime": "2024年07月02日",
    "abstract": "Large language models (LLMs) have played a fundamental role in various natural language processing tasks with powerful prompt techniques. However, in real-world applications, there are often similar prompt components for repeated queries, which causes significant computational burdens during inference. Existing prompt compression and direct fine-tuning methods aim to tackle these challenges, yet they frequently struggle to strike an optimal balance between cost-efficiency and performance effectiveness, especially in complex tasks such as NL2Code. In this paper, we propose a novel method namely PromptIntern to internalize the prompt knowledge into model parameters via progressive fine-tuning. Our method enables LLMs to emulate the human learning process for a new task, where detailed templates and examples in a prompt are gradually internalized and phased out progressively as the model grows accustomed to the task. Extensive experiments demonstrate that our method reduces inference tokens over 90%, speedups inference by 4.2 times, and saves 88.3% monetary cost.",
    "pdf_link": "https://arxiv.org/abs/2407.02211",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLM）凭借强大的提示技术，在多种自然语言处理任务中发挥着关键作用。然而，在实际应用中，重复查询的相似提示组件常导致推理时的计算负担加重。尽管现有方法如提示压缩和直接微调试图解决这一问题，但在成本与性能的平衡上，尤其是在复杂的 NL2Code 任务中，仍显不足。为此，我们提出了 PromptIntern 方法，通过渐进式微调将提示知识融入模型参数，模拟人类学习新任务的过程，逐步内化并淘汰提示中的模板和示例。实验结果显示，该方法不仅大幅减少了推理令牌，提升了推理速度，还显著降低了成本。",
    "title_cn": "PromptIntern：在大语言模型微调过程中，通过内部化循环提示，有效节省推理成本。",
    "tags": [
      "LLM应用",
      "软件开发",
      ""
    ]
  },
  {
    "title": "Generative Monoculture in Large Language Models",
    "submit_datetime": "2024年07月02日",
    "abstract": "We introduce {\\em generative monoculture}, a behavior observed in large language models (LLMs) characterized by a significant narrowing of model output diversity relative to available training data for a given task: for example, generating only positive book reviews for books with a mixed reception. While in some cases, generative monoculture enhances performance (e.g., LLMs more often produce efficient code), the dangers are exacerbated in others (e.g., LLMs refuse to share diverse opinions). As LLMs are increasingly used in high-impact settings such as education and web search, careful maintenance of LLM output diversity is essential to ensure a variety of facts and perspectives are preserved over time. We experimentally demonstrate the prevalence of generative monoculture through analysis of book review and code generation tasks, and find that simple countermeasures such as altering sampling or prompting strategies are insufficient to mitigate the behavior. Moreover, our results suggest that the root causes of generative monoculture are likely embedded within the LLM's alignment processes, suggesting a need for developing fine-tuning paradigms that preserve or promote diversity.",
    "pdf_link": "https://arxiv.org/abs/2407.02209",
    "graphs": [],
    "abstract_cn": "我们提出“生成单一文化”现象，即大型语言模型在特定任务中输出多样性大幅缩减，如仅产出正面书评，即便书籍评价参差不齐。此现象虽在某些领域提升效率，如代码生成，但在需要多元观点的场合，风险倍增。随着LLM在关键领域的广泛应用，维护输出多样性变得尤为重要，以保障信息的多元性。我们通过实验揭示了这一现象的普遍性，并指出传统对策效果有限。研究还表明，问题的根源可能在于模型的对齐过程，因此，开发能促进多样性的微调方法势在必行。",
    "title_cn": "大型语言模型中的生成单一文化现象",
    "tags": [
      "LLM理论",
      "人工智能",
      "出版业"
    ]
  },
  {
    "title": "Automatic Adaptation Rule Optimization via Large Language Models",
    "submit_datetime": "2024年07月02日",
    "abstract": "Rule-based adaptation is a foundational approach to self-adaptation, characterized by its human readability and rapid response. However, building high-performance and robust adaptation rules is often a challenge because it essentially involves searching the optimal design in a complex (variables) space. In response, this paper attempt to employ large language models (LLMs) as a optimizer to construct and optimize adaptation rules, leveraging the common sense and reasoning capabilities inherent in LLMs. Preliminary experiments conducted in SWIM have validated the effectiveness and limitation of our method.",
    "pdf_link": "https://arxiv.org/abs/2407.02203",
    "graphs": [],
    "abstract_cn": "基于规则的自适应方法因其易读性和快速响应而成为自适应的基础。然而，构建高效且稳健的适应规则颇具挑战，因其需在复杂变量空间中寻找最佳设计。本文尝试借助大型语言模型（LLM）的常识与推理能力，将其作为优化工具来构建和优化适应规则。初步实验结果显示，该方法在SWIM中既展现了其有效性，也揭示了其局限性。",
    "title_cn": "利用大型语言模型实现自动适应规则的优化",
    "tags": [
      "LLM应用",
      "自动化",
      "软件工程"
    ]
  },
  {
    "title": "A mathematical definition of complex adaptive system as interaction space",
    "submit_datetime": "2024年07月02日",
    "abstract": "We define a mathematical notion of complex adaptive system by following the original intuition of G.K. Zipf about the principle of least effort, an intuitive idea which is nowadays informally widespread in complex systems modeling. We call generalized evolution principle this mathematical notion of interaction spaces theory. Formalizing and generalizing Mandelbrot's ideas, we also prove that a large class of these systems satisfy a power law. We finally illustrate the notion of complex adaptive system with theorems describing a Von Thünen-like model. The latter can be easily generalized to other complex systems and describes the appearance of emergent patterns. Every notion is introduced both using an intuitive description with lots of examples, and using a modern mathematical language.",
    "pdf_link": "https://arxiv.org/abs/2407.02181",
    "graphs": [],
    "abstract_cn": "我们基于G.K. Zipf的最小努力原则，提出了一种复杂适应系统的数学定义，这一原则在复杂系统建模中广为流传。我们将这种交互空间理论的数学概念称为广义进化原则。借鉴Mandelbrot的思想，我们进一步证明了许多此类系统遵循幂律。通过一个类似Von Thünen的模型，我们展示了复杂适应系统的概念，该模型易于推广至其他复杂系统，并揭示了涌现模式的形成。每个概念均通过丰富的实例进行直观阐述，并辅以现代数学语言的精确表达。",
    "title_cn": "复杂适应系统的数学定义，以交互空间为视角",
    "tags": [
      "LLM理论",
      "复杂系统",
      "数学建模"
    ]
  },
  {
    "title": "FineCLIPER: Multi-modal Fine-grained CLIP for Dynamic Facial Expression Recognition with AdaptERs",
    "submit_datetime": "2024年07月02日",
    "abstract": "Dynamic Facial Expression Recognition (DFER) is crucial for understanding human behavior. However, current methods exhibit limited performance mainly due to the scarcity of high-quality data, the insufficient utilization of facial dynamics, and the ambiguity of expression semantics, etc. To this end, we propose a novel framework, named Multi-modal Fine-grained CLIP for Dynamic Facial Expression Recognition with AdaptERs (FineCLIPER), incorporating the following novel designs: 1) To better distinguish between similar facial expressions, we extend the class labels to textual descriptions from both positive and negative aspects, and obtain supervision by calculating the cross-modal similarity based on the CLIP model; 2) Our FineCLIPER adopts a hierarchical manner to effectively mine useful cues from DFE videos. Specifically, besides directly embedding video frames as input (low semantic level), we propose to extract the face segmentation masks and landmarks based on each frame (middle semantic level) and utilize the Multi-modal Large Language Model (MLLM) to further generate detailed descriptions of facial changes across frames with designed prompts (high semantic level). Additionally, we also adopt Parameter-Efficient Fine-Tuning (PEFT) to enable efficient adaptation of large pre-trained models (i.e., CLIP) for this task. Our FineCLIPER achieves SOTA performance on the DFEW, FERV39k, and MAFW datasets in both supervised and zero-shot settings with few tunable parameters. Analysis and ablation studies further validate its effectiveness.",
    "pdf_link": "https://arxiv.org/abs/2407.02157",
    "graphs": [],
    "abstract_cn": "动态面部表情识别（DFER）对理解人类行为至关重要，但现有方法因高质量数据稀缺、面部动态利用不足及表情语义模糊等问题表现受限。为此，我们创新性地提出了“FineCLIPER”框架，该框架通过以下设计提升性能：首先，通过扩展类别标签为正负文本描述，并利用CLIP模型计算跨模态相似性，以更好地区分相似表情；其次，采用分层策略，从视频帧中提取面部掩码和地标，并借助MLLM生成详细面部变化描述，从而有效挖掘视频中的有用线索。此外，通过参数高效微调（PEFT），我们实现了对大型预训练模型（如CLIP）的高效适应。FineCLIPER在多个数据集上，无论是在有监督还是零-shot环境下，均以少量参数达到了顶尖性能，并通过分析和消融研究进一步证实了其有效性。",
    "title_cn": "FineCLIPER：一款结合多模态细粒度 CLIP 技术与适应性调整器的系统，专为动态面部表情识别设计。",
    "tags": [
      "LLM应用",
      "人工智能",
      "计算机视觉"
    ]
  },
  {
    "title": "LlamAr & GemmAr: Enhancing LLMs Through Arabic Instruction-Tuning",
    "submit_datetime": "2024年07月02日",
    "abstract": "Large language models (LLMs) have greatly impacted the natural language processing (NLP) field, particularly for the English language. These models have demonstrated capabilities in understanding and generating human-like text. The success of language models largely depends on the availability of high-quality instruction datasets, which consist of detailed task descriptions and corresponding responses that are essential for training the models to accurately address a variety of prompts. However, the availability and quality of these resources vary by language. While models perform well in English, they often struggle with languages like Arabic, due to the lack of datasets for fine-tuning Arabic-specific tasks. To address this issue, we introduce InstAr-500k, a new Arabic instruction dataset created by generating and collecting content that covers several domains and instruction types. We then assess this dataset by fine-tuning two open-source models, Llama-3-8B-Instruct and Gemma-7B-IT, on several downstream tasks to scale improvements in their functionality. Based on multiple evaluations, our fine-tuned models achieve state-of-the-art performance on several Arabic NLP benchmarks. These outcomes emphasize the effectiveness of our dataset in elevating the capabilities of language models for Arabic. Our instruction dataset bridges the performance gap between English and Arabic language models by providing resources that amplify Arabic NLP development. Building on this foundation, we developed two state-of-the-art models, LlamAr-8B and GemmAr-7B, which are specifically tuned to excel at a wide range of Arabic NLP tasks.",
    "pdf_link": "https://arxiv.org/abs/2407.02147",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）在自然语言处理（NLP）领域，尤其是在英语方面，展现了显著的影响力。这些模型不仅理解力强，还能生成逼真的文本。然而，模型的成功极大地依赖于高质量的指令数据集，这些数据集包含了详尽的任务描述和相应的回答，对训练模型应对多样化的提示至关重要。尽管在英语中表现出色，但由于缺乏针对阿拉伯语的微调数据集，模型在阿拉伯语任务上往往表现不佳。为此，我们推出了InstAr-500k，一个全新的阿拉伯语指令数据集，涵盖了多个领域和指令类型。通过在多个下游任务上微调Llama-3-8B-Instruct和Gemma-7B-IT这两个开源模型，我们评估了该数据集的效果，并实现了功能的显著提升。评估结果显示，我们的微调模型在阿拉伯语NLP基准测试中达到了顶尖水平，凸显了该数据集在提升阿拉伯语模型性能方面的强大作用。通过提供丰富的资源，我们的数据集有效缩小了英语与阿拉伯语模型之间的性能差距，并在此基础上，我们进一步开发了LlamAr-8B和GemmAr-7B这两款专为阿拉伯语NLP任务优化的顶尖模型。",
    "title_cn": "LlamAr 与 GemmAr：借助阿拉伯语指令调优提升大型语言模型性能",
    "tags": [
      "LLM应用",
      "",
      "阿拉伯语"
    ]
  },
  {
    "title": "Cost-Effective Proxy Reward Model Construction with On-Policy and Active Learning",
    "submit_datetime": "2024年07月02日",
    "abstract": "Reinforcement learning with human feedback (RLHF), as a widely adopted approach in current large language model pipelines, is \\textit{bottlenecked by the size of human preference data}. While traditional methods rely on offline preference dataset constructions, recent approaches have shifted towards online settings, where a learner uses a small amount of labeled seed data and a large pool of unlabeled prompts to iteratively construct new preference data through self-generated responses and high-quality reward/preference feedback. However, most current online algorithms still focus on preference labeling during policy model updating with given feedback oracles, which incurs significant expert query costs. \\textit{We are the first to explore cost-effective proxy reward oracles construction strategies for further labeling preferences or rewards with extremely limited labeled data and expert query budgets}. Our approach introduces two key innovations: (1) on-policy query to avoid OOD and imbalance issues in seed data, and (2) active learning to select the most informative data for preference queries. Using these methods, we train a evaluation model with minimal expert-labeled data, which then effectively labels nine times more preference pairs for further RLHF training. For instance, our model using Direct Preference Optimization (DPO) gains around over 1% average improvement on AlpacaEval2, MMLU-5shot and MMLU-0shot, with only 1.7K query cost. Our methodology is orthogonal to other direct expert query-based strategies and therefore might be integrated with them to further reduce query costs.",
    "pdf_link": "https://arxiv.org/abs/2407.02119",
    "graphs": [],
    "abstract_cn": "人类反馈强化学习（RLHF）在大型语言模型中应用广泛，但其效果受限于人类偏好数据量。传统方法依赖离线数据集，而新方法转向在线模式，利用少量标记数据和大量未标记提示，通过自我生成响应和高品质反馈迭代构建新数据。然而，现有在线算法在策略更新时仍依赖给定反馈预言机进行偏好标记，导致高昂的专家查询成本。我们率先探索了成本效益高的代理奖励预言机构建策略，以在有限数据和预算下进行偏好或奖励标记。我们的创新包括：策略内查询避免数据问题，以及主动学习选择关键数据。通过这些方法，我们用最少专家数据训练评估模型，有效标记九倍偏好对，用于RLHF训练。例如，使用DPO的模型在多个测试中平均提升约1%，仅消耗1.7K查询成本。我们的方法与其他专家查询策略正交，有望进一步降低成本。",
    "title_cn": "通过在线策略与主动学习构建经济高效的代理奖励模型",
    "tags": [
      "LLM应用",
      "人工智能",
      "机器学习"
    ]
  },
  {
    "title": "Breaking Language Barriers: Cross-Lingual Continual Pre-Training at Scale",
    "submit_datetime": "2024年07月02日",
    "abstract": "In recent years, Large Language Models (LLMs) have made significant strides towards Artificial General Intelligence. However, training these models from scratch requires substantial computational resources and vast amounts of text data. In this paper, we explore an alternative approach to constructing an LLM for a new language by continually pretraining (CPT) from existing pretrained LLMs, instead of using randomly initialized parameters. Based on parallel experiments on 40 model sizes ranging from 40M to 5B parameters, we find that 1) CPT converges faster and saves significant resources in a scalable manner; 2) CPT adheres to an extended scaling law derived from Hoffmann et al. (2022) with a joint data-parameter scaling term; 3) The compute-optimal data-parameter allocation for CPT markedly differs based on our estimated scaling factors; 4) The effectiveness of transfer at scale is influenced by training duration and linguistic properties, while robust to data replaying, a method that effectively mitigates catastrophic forgetting in CPT. We hope our findings provide deeper insights into the transferability of LLMs at scale for the research community.",
    "pdf_link": "https://arxiv.org/abs/2407.02118",
    "graphs": [],
    "abstract_cn": "近年来，大型语言模型（LLM）在迈向人工通用智能方面取得了显著进展。然而，从头开始训练这些模型需要庞大的计算资源和海量文本数据。本文探索了一种替代方法：通过从现有预训练 LLM 中不断预训练（CPT）来构建新语言的 LLM，而非使用随机初始化参数。通过在 40 种不同模型大小（从 40M 到 5B 参数）上的并行实验，我们发现：1) CPT 收敛更快，并以可扩展方式节省大量资源；2) CPT 遵循 Hoffmann 等人（2022）提出的扩展缩放定律，包含联合数据-参数缩放项；3) 根据我们估计的缩放因子，CPT 的计算最优数据-参数分配显著不同；4) 大规模迁移的有效性受训练持续时间和语言特性影响，而对数据重放具有鲁棒性，这是一种有效缓解 CPT 中灾难性遗忘的方法。我们希望这些发现能为研究社区提供关于大规模 LLM 可迁移性的更深入见解。",
    "title_cn": "跨越语言界限：大规模实施跨语言持续预训练",
    "tags": [
      "LLM理论",
      "人工智能",
      "计算机科学"
    ]
  },
  {
    "title": "Helpful assistant or fruitful facilitator? Investigating how personas affect language model behavior",
    "submit_datetime": "2024年07月02日",
    "abstract": "One way to personalize and steer generations from large language models (LLM) is to assign a persona: a role that describes how the user expects the LLM to behave (e.g., a helpful assistant, a teacher, a woman). This paper investigates how personas affect diverse aspects of model behavior. We assign to seven LLMs 162 personas from 12 categories spanning variables like gender, sexual orientation, and occupation. We prompt them to answer questions from five datasets covering objective (e.g., questions about math and history) and subjective tasks (e.g., questions about beliefs and values). We also compare persona's generations to two baseline settings: a control persona setting with 30 paraphrases of \"a helpful assistant\" to control for models' prompt sensitivity, and an empty persona setting where no persona is assigned. We find that for all models and datasets, personas show greater variability than the control setting and that some measures of persona behavior generalize across models.",
    "pdf_link": "https://arxiv.org/abs/2407.02099",
    "graphs": [],
    "abstract_cn": "为了个性化和引导大型语言模型的生成内容，一种有效方法是赋予特定角色，如“有帮助的助手”或“教师”。本文深入探讨了这些角色如何影响模型的多方面行为。我们为七个大型语言模型分配了162个角色，涵盖性别、性取向和职业等12个类别。通过回答涵盖数学、历史等客观问题及信仰、价值观等主观问题的五个数据集，我们分析了角色对模型输出的影响。此外，我们通过对比“有帮助的助手”的30种不同表述和无角色的基线设置，发现角色不仅增加了输出的多样性，某些角色行为特征还具有跨模型的普遍性。",
    "title_cn": "是助手还是促进者？探讨角色对语言模型行为的影响。",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "GPTCast: a weather language model for precipitation nowcasting",
    "submit_datetime": "2024年07月02日",
    "abstract": "This work introduces GPTCast, a generative deep-learning method for ensemble nowcast of radar-based precipitation, inspired by advancements in large language models (LLMs). We employ a GPT model as a forecaster to learn spatiotemporal precipitation dynamics using tokenized radar images. The tokenizer is based on a Quantized Variational Autoencoder featuring a novel reconstruction loss tailored for the skewed distribution of precipitation that promotes faithful reconstruction of high rainfall rates. The approach produces realistic ensemble forecasts and provides probabilistic outputs with accurate uncertainty estimation. The model is trained without resorting to randomness, all variability is learned solely from the data and exposed by model at inference for ensemble generation. We train and test GPTCast using a 6-year radar dataset over the Emilia-Romagna region in Northern Italy, showing superior results compared to state-of-the-art ensemble extrapolation methods.",
    "pdf_link": "https://arxiv.org/abs/2407.02089",
    "graphs": [],
    "abstract_cn": "GPTCast 是一种创新的深度学习方法，用于基于雷达的降水集合临近预报，灵感源自大型语言模型的进步。我们利用 GPT 模型通过标记化的雷达图像学习降水的时空动态。标记器采用量化变分自编码器，并引入一种新的重建损失，专门针对降水的偏斜分布，确保对高降雨率的准确重建。该方法不仅生成逼真的集合预报，还提供精确的不确定性估计。模型训练完全基于数据，无需随机性，所有变异性均从数据中学习并在推理时展现，以生成集合。通过在意大利北部艾米利亚-罗马涅地区 6 年的雷达数据集上训练和测试，GPTCast 展现出超越现有集合外推方法的优越性能。",
    "title_cn": "GPTCast：一款专为降水实时预报设计的天气语言模型",
    "tags": [
      "LLM应用",
      "气象学",
      ""
    ]
  },
  {
    "title": "Theseus: Towards High-Efficiency Wafer-Scale Chip Design Space Exploration for Large Language Models",
    "submit_datetime": "2024年07月02日",
    "abstract": "The emergence of the large language model~(LLM) poses an exponential growth of demand for computation throughput, memory capacity, and communication bandwidth. Such a demand growth has significantly surpassed the improvement of corresponding chip designs. With the advancement of fabrication and integration technologies, designers have been developing Wafer-Scale Chips(WSCs) to scale up and exploit the limits of computation density, memory capacity, and communication bandwidth at the level of a single chip. Existing solutions have demonstrated the significant advantages of WSCs over traditional designs, showing potential to effectively support LLM workloads.\n  Despite the benefits, exploring the early-stage design space of WSCs for LLMs is a crucial yet challenging task due to the enormous and complicated design space, time-consuming evaluation methods, and inefficient exploration strategies. To address these challenges, we propose Theseus, an efficient WSC design space exploration framework for LLMs. We construct the design space of WSCs with various constraints considering the unique characteristics of WSCs. We propose efficient evaluation methodologies for large-scale NoC-based WSCs and introduce multi-fidelity Bayesian optimization to efficiently explore the design space. Evaluation results demonstrate the efficiency of Theseus that the searched Pareto optimal results outperform GPU cluster and existing WSC designs by up to 62.8%/73.7% in performance and 38.6%/42.4% in power consumption for LLM training, while improving up to 23.2$\\times$ and 15.7$\\times$ for the performance and power of inference tasks. Furthermore, we conduct case studies to address the design tradeoffs in WSCs and provide insights to facilitate WSC designs for LLMs.",
    "pdf_link": "https://arxiv.org/abs/2407.02079",
    "graphs": [],
    "abstract_cn": "随着大型语言模型（LLM）的兴起，对计算能力、内存和通信带宽的需求激增，远超芯片设计的进步。为此，设计师们正致力于开发晶圆级芯片（WSCs），以突破单芯片的性能极限。现有研究表明，WSCs在支持LLM方面具有巨大潜力。然而，探索WSCs的早期设计空间充满挑战，涉及复杂的设计选项、耗时的评估过程和低效的探索策略。为此，我们推出了Theseus框架，旨在高效探索WSCs的设计空间。我们结合WSCs的特性，构建了多约束的设计空间，并采用多保真贝叶斯优化，以加速设计探索。评估显示，Theseus找到的最优设计在LLM训练中性能和能效分别提升高达62.8%/73.7%和38.6%/42.4%，在推理任务中性能和能效更是分别提升至23.2倍和15.7倍。此外，我们还通过案例研究，深入分析了WSCs的设计权衡，为未来LLM的WSC设计提供了宝贵见解。",
    "title_cn": "Theseus 项目致力于为大型语言模型优化晶圆级芯片设计，提升探索效率。",
    "tags": [
      "LLM应用",
      "半导体",
      "人工智能"
    ]
  },
  {
    "title": "Fake News Detection and Manipulation Reasoning via Large Vision-Language Models",
    "submit_datetime": "2024年07月02日",
    "abstract": "Fake news becomes a growing threat to information security and public opinion with the rapid sprawl of media manipulation. Therefore, fake news detection attracts widespread attention from academic community. Traditional fake news detection models demonstrate remarkable performance on authenticity binary classification but their ability to reason detailed faked traces based on the news content remains under-explored. Furthermore, due to the lack of external knowledge, the performance of existing methods on fact-related news is questionable, leaving their practical implementation unclear. In this paper, we propose a new multi-media research topic, namely manipulation reasoning. Manipulation reasoning aims to reason manipulations based on news content. To support the research, we introduce a benchmark for fake news detection and manipulation reasoning, referred to as Human-centric and Fact-related Fake News (HFFN). The benchmark highlights the centrality of human and the high factual relevance, with detailed manual annotations. HFFN encompasses four realistic domains with fake news samples generated through three manipulation approaches. Moreover, a Multi-modal news Detection and Reasoning langUage Model (M-DRUM) is presented not only to judge on the authenticity of multi-modal news, but also raise analytical reasoning about potential manipulations. On the feature extraction level, a cross-attention mechanism is employed to extract fine-grained fusion features from multi-modal inputs. On the reasoning level, a large vision-language model (LVLM) serves as the backbone to facilitate fact-related reasoning. A two-stage training framework is deployed to better activate the capacity of identification and reasoning. Comprehensive experiments demonstrate that our model outperforms state-of-the-art (SOTA) fake news detection models and powerful LVLMs like GPT-4 and LLaVA.",
    "pdf_link": "https://arxiv.org/abs/2407.02042",
    "graphs": [],
    "abstract_cn": "随着媒体操纵的泛滥，假新闻已成为信息安全的一大隐患。学术界对假新闻检测的关注日益增加。传统模型虽在真伪分类上表现优异，但基于新闻内容推理伪造细节的能力尚待挖掘。此外，因缺乏外部知识，现有方法在处理事实相关新闻时的表现存疑，其实际应用效果不明。为此，我们提出“操纵推理”这一新课题，旨在通过新闻内容揭示操纵行为。为此，我们创建了以人为本、事实关联为核心的假新闻基准（HFFN），并详细标注。HFFN涵盖四个现实领域，通过三种操纵手法生成假新闻样本。我们还设计了多模态新闻检测与推理模型（M-DRUM），不仅能判断新闻真伪，还能分析潜在操纵。在特征提取上，我们采用交叉注意力机制，从多模态输入中提炼精细特征。推理方面，则依托大型视觉语言模型（LVLM）进行事实推理。通过两阶段训练框架，我们有效提升了模型的识别与推理能力。实验证明，M-DRUM在假新闻检测领域超越了现有顶尖模型，包括GPT-4和LLaVA。",
    "title_cn": "利用大型视觉-语言模型，我们致力于假新闻的检测与操纵行为的推理。",
    "tags": [
      "LLM应用",
      "信息安全",
      ""
    ]
  },
  {
    "title": "Prompt Stability Scoring for Text Annotation with Large Language Models",
    "submit_datetime": "2024年07月02日",
    "abstract": "Researchers are increasingly using language models (LMs) for text annotation. These approaches rely only on a prompt telling the model to return a given output according to a set of instructions. The reproducibility of LM outputs may nonetheless be vulnerable to small changes in the prompt design. This calls into question the replicability of classification routines. To tackle this problem, researchers have typically tested a variety of semantically similar prompts to determine what we call \"prompt stability.\" These approaches remain ad-hoc and task specific. In this article, we propose a general framework for diagnosing prompt stability by adapting traditional approaches to intra- and inter-coder reliability scoring. We call the resulting metric the Prompt Stability Score (PSS) and provide a Python package PromptStability for its estimation. Using six different datasets and twelve outcomes, we classify >150k rows of data to: a) diagnose when prompt stability is low; and b) demonstrate the functionality of the package. We conclude by providing best practice recommendations for applied researchers.",
    "pdf_link": "https://arxiv.org/abs/2407.02039",
    "graphs": [],
    "abstract_cn": "研究人员正越来越多地利用语言模型进行文本标注，这些方法仅依赖于一个提示来指导模型输出。然而，提示设计的微小变化可能影响输出的可重复性，从而引发对分类程序可复制性的质疑。为应对这一挑战，我们提出了一种通用框架，通过调整传统可靠性评分方法来评估提示稳定性，并命名为提示稳定性得分 (PSS)。我们开发的 Python 包 PromptStability 可用于此评估。通过分析六个数据集和十二个结果，我们对超过 15 万行数据进行了分类，旨在揭示提示稳定性的不足并展示该包的实用性。最后，我们为应用研究人员提供了最佳实践建议。",
    "title_cn": "大型语言模型文本标注中的提示稳定性评分",
    "tags": [
      "LLM应用",
      "文本标注",
      "软件开发"
    ]
  },
  {
    "title": "Breaking Bias, Building Bridges: Evaluation and Mitigation of Social Biases in LLMs via Contact Hypothesis",
    "submit_datetime": "2024年07月02日",
    "abstract": "Large Language Models (LLMs) perpetuate social biases, reflecting prejudices in their training data and reinforcing societal stereotypes and inequalities. Our work explores the potential of the Contact Hypothesis, a concept from social psychology for debiasing LLMs. We simulate various forms of social contact through LLM prompting to measure their influence on the model's biases, mirroring how intergroup interactions can reduce prejudices in social contexts. We create a dataset of 108,000 prompts following a principled approach replicating social contact to measure biases in three LLMs (LLaMA 2, Tulu, and NousHermes) across 13 social bias dimensions. We propose a unique debiasing technique, Social Contact Debiasing (SCD), that instruction-tunes these models with unbiased responses to prompts. Our research demonstrates that LLM responses exhibit social biases when subject to contact probing, but more importantly, these biases can be significantly reduced by up to 40% in 1 epoch of instruction tuning LLaMA 2 following our SCD strategy. Our code and data are available at https://github.com/chahatraj/breakingbias.",
    "pdf_link": "https://arxiv.org/abs/2407.02030",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLM）不仅反映训练数据中的偏见，还加剧了社会刻板印象和不平等。我们借鉴社会心理学的接触假设，探索其在减少LLM偏见方面的应用。通过模拟不同形式的社会接触，我们评估了这些接触对模型偏见的影响，类似于群体间互动在现实世界中减少偏见的效果。我们精心设计了包含108,000个提示的数据集，涵盖13个社会偏见维度，用于评估LLaMA 2、Tulu和NousHermes三个模型。我们创新性地提出了社会接触去偏见（SCD）技术，通过无偏见的响应对模型进行调优。研究显示，尽管LLM在接触探测下表现出偏见，但通过我们的SCD策略，一个周期的调优即可显著减少高达40%的偏见。相关代码和数据已公开在https://github.com/chahatraj/breakingbias。",
    "title_cn": "破除偏见，搭建沟通之桥：利用接触假设评估并减轻 LLMs 中的社会偏见",
    "tags": [
      "LLM应用",
      "社会心理学",
      "人工智能"
    ]
  },
  {
    "title": "Why does in-context learning fail sometimes? Evaluating in-context learning on open and closed questions",
    "submit_datetime": "2024年07月02日",
    "abstract": "We measure the performance of in-context learning as a function of task novelty and difficulty for open and closed questions. For that purpose, we created a novel benchmark consisting of hard scientific questions, each paired with a context of various relevancy. We show that counter-intuitively, a context that is more aligned with the topic does not always help more than a less relevant context. This effect is especially visible for open questions and questions of high difficulty or novelty. This result reveals a fundamental difference between the treatment of close-form and open-form questions by large-language models and shows a need for a more robust evaluation of in-context learning on the variety of different types of questions. It also poses a new question of how to optimally select a context for large language models, especially in the context of Retrieval Augmented Generation (RAG) systems. Our results suggest that the answer to this question can be highly application-dependent and might be contingent on factors including the format of the question, the perceived difficulty level of the questions, and the novelty or popularity of the information we seek.",
    "pdf_link": "https://arxiv.org/abs/2407.02028",
    "graphs": [],
    "abstract_cn": "我们评估了in-context learning在开放与封闭问题中的表现，考虑了任务的新颖性和难度。为此，我们设计了一个包含复杂科学问题的创新基准，每个问题都附有不同相关性的背景信息。令人意外的是，与主题更契合的背景信息并不总是优于相关性较低的背景。这一现象在开放性问题和高难度或新颖问题中尤为显著。这一发现凸显了大型语言模型在处理不同类型问题时的根本差异，并强调了对in-context learning进行更全面评估的必要性。同时，这也引发了一个新问题：如何在检索增强生成（RAG）系统中为大型语言模型选择最优背景信息。我们的研究暗示，这一问题的答案可能高度依赖于具体应用，并可能受问题格式、难度感知以及信息的新颖性或流行度等因素影响。",
    "title_cn": "为何 in-context learning 有时会失效？探讨其在开放与封闭问题上的表现。",
    "tags": [
      "LLM理论",
      "",
      "科学研究"
    ]
  },
  {
    "title": "ViG-Bias: Visually Grounded Bias Discovery and Mitigation",
    "submit_datetime": "2024年07月02日",
    "abstract": "The proliferation of machine learning models in critical decision making processes has underscored the need for bias discovery and mitigation strategies. Identifying the reasons behind a biased system is not straightforward, since in many occasions they are associated with hidden spurious correlations which are not easy to spot. Standard approaches rely on bias audits performed by analyzing model performance in pre-defined subgroups of data samples, usually characterized by common attributes like gender or ethnicity when it comes to people, or other specific attributes defining semantically coherent groups of images. However, it is not always possible to know a-priori the specific attributes defining the failure modes of visual recognition systems. Recent approaches propose to discover these groups by leveraging large vision language models, which enable the extraction of cross-modal embeddings and the generation of textual descriptions to characterize the subgroups where a certain model is underperforming. In this work, we argue that incorporating visual explanations (e.g. heatmaps generated via GradCAM or other approaches) can boost the performance of such bias discovery and mitigation frameworks. To this end, we introduce Visually Grounded Bias Discovery and Mitigation (ViG-Bias), a simple yet effective technique which can be integrated to a variety of existing frameworks to improve both, discovery and mitigation performance. Our comprehensive evaluation shows that incorporating visual explanations enhances existing techniques like DOMINO, FACTS and Bias-to-Text, across several challenging datasets, including CelebA, Waterbirds, and NICO++.",
    "pdf_link": "https://arxiv.org/abs/2407.01996",
    "graphs": [],
    "abstract_cn": "机器学习模型在关键决策中的广泛应用，使得偏差的发现与缓解变得尤为重要。然而，偏差背后的原因往往隐藏在难以察觉的虚假相关性中，不易识别。传统方法通过分析模型在具有共同属性（如性别或种族）的子组中的表现来进行偏差审计。但视觉识别系统的失败模式往往难以预知。近期研究提出利用大型视觉语言模型，通过提取跨模态嵌入和生成文本描述来发现模型表现不佳的子组。我们提出，结合视觉解释（如热图）能有效提升偏差发现与缓解框架的性能。为此，我们开发了视觉基础偏差发现与缓解技术（ViG-Bias），该技术简单高效，可集成于多种框架，显著提升性能。在多个挑战性数据集上的全面评估表明，视觉解释的引入显著增强了现有技术，如 DOMINO、FACTS 和 Bias-to-Text。",
    "title_cn": "ViG-Bias：通过视觉基础技术发现并缓解偏见",
    "tags": [
      "LLM应用",
      "计算机视觉",
      "人工智能"
    ]
  },
  {
    "title": "Is Your Large Language Model Knowledgeable or a Choices-Only Cheater?",
    "submit_datetime": "2024年07月02日",
    "abstract": "Recent work shows that large language models (LLMs) can answer multiple-choice questions using only the choices, but does this mean that MCQA leaderboard rankings of LLMs are largely influenced by abilities in choices-only settings? To answer this, we use a contrast set that probes if LLMs over-rely on choices-only shortcuts in MCQA. While previous works build contrast sets via expensive human annotations or model-generated data which can be biased, we employ graph mining to extract contrast sets from existing MCQA datasets. We use our method on UnifiedQA, a group of six commonsense reasoning datasets with high choices-only accuracy, to build an 820-question contrast set. After validating our contrast set, we test 12 LLMs, finding that these models do not exhibit reliance on choice-only shortcuts when given both the question and choices. Thus, despite the susceptibility~of MCQA to high choices-only accuracy, we argue that LLMs are not obtaining high ranks on MCQA leaderboards just due to their ability to exploit choices-only shortcuts.",
    "pdf_link": "https://arxiv.org/abs/2407.01992",
    "graphs": [],
    "abstract_cn": "最新研究发现，大型语言模型 (LLMs) 能仅凭选项解答多项选择题，但这会否导致其在 MCQA 排行榜上的名次主要取决于仅选项的能力？为探究此问题，我们运用图挖掘技术，从现有 MCQA 数据集中提取对比集，以检测 LLMs 是否过度依赖仅选项的捷径。与以往依赖人工标注或可能偏差的模型生成数据不同，我们在 UnifiedQA 上构建了一个包含 820 个问题的对比集，该数据集涵盖六个高仅选项准确性的常识推理数据集。经过验证，我们测试了 12 个 LLMs，结果显示这些模型在同时提供问题和选项时并未过度依赖仅选项捷径。因此，尽管 MCQA 对高仅选项准确性敏感，我们认为 LLMs 在 MCQA 排行榜上的高排名并非仅因它们能利用仅选项的捷径。",
    "title_cn": "你的大型语言模型是真才实学，还是仅仅在选择题上作弊？",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "SADL: An Effective In-Context Learning Method for Compositional Visual QA",
    "submit_datetime": "2024年07月02日",
    "abstract": "Large vision-language models (LVLMs) offer a novel capability for performing in-context learning (ICL) in Visual QA. When prompted with a few demonstrations of image-question-answer triplets, LVLMs have demonstrated the ability to discern underlying patterns and transfer this latent knowledge to answer new questions about unseen images without the need for expensive supervised fine-tuning. However, designing effective vision-language prompts, especially for compositional questions, remains poorly understood. Adapting language-only ICL techniques may not necessarily work because we need to bridge the visual-linguistic semantic gap: Symbolic concepts must be grounded in visual content, which does not share the syntactic linguistic structures. This paper introduces SADL, a new visual-linguistic prompting framework for the task. SADL revolves around three key components: SAmpling, Deliberation, and Pseudo-Labeling of image-question pairs. Given an image-question query, we sample image-question pairs from the training data that are in semantic proximity to the query. To address the compositional nature of questions, the deliberation step decomposes complex questions into a sequence of subquestions. Finally, the sequence is progressively annotated one subquestion at a time to generate a sequence of pseudo-labels. We investigate the behaviors of SADL under OpenFlamingo on large-scale Visual QA datasets, namely GQA, GQA-OOD, CLEVR, and CRIC. The evaluation demonstrates the critical roles of sampling in the neighborhood of the image, the decomposition of complex questions, and the accurate pairing of the subquestions and labels. These findings do not always align with those found in language-only ICL, suggesting fresh insights in vision-language settings.",
    "pdf_link": "https://arxiv.org/abs/2407.01983",
    "graphs": [],
    "abstract_cn": "大型视觉-语言模型（LVLMs）在视觉问答（Visual QA）中展现了一种创新的上下文学习能力。通过少量图像-问题-答案三元组的演示，LVLMs能够识别潜在模式，并将这些隐性知识应用于回答未见图像的新问题，无需昂贵的监督微调。然而，设计针对组合性问题的有效视觉-语言提示仍是一个挑战。由于视觉内容与语言结构存在差异，仅依赖语言的ICL技术可能不适用。为此，本文提出了SADL，一个结合采样、深思和伪标签的视觉-语言提示框架。该框架通过从训练数据中选取语义相近的图像-问题对，分解复杂问题为子问题，并逐步生成伪标签，以应对视觉问答任务。在OpenFlamingo平台上对GQA、GQA-OOD、CLEVR和CRIC等数据集的实验表明，采样、问题分解和标签配对是关键因素。这些发现为视觉-语言领域的ICL提供了新的视角。",
    "title_cn": "SADL：组合视觉问答中一种高效的上下文学习策略",
    "tags": [
      "LLM应用",
      "计算机视觉",
      "人工智能"
    ]
  },
  {
    "title": "A Bounding Box is Worth One Token: Interleaving Layout and Text in a Large Language Model for Document Understanding",
    "submit_datetime": "2024年07月02日",
    "abstract": "Recently, many studies have demonstrated that exclusively incorporating OCR-derived text and spatial layouts with large language models (LLMs) can be highly effective for document understanding tasks. However, existing methods that integrate spatial layouts with text have limitations, such as producing overly long text sequences or failing to fully leverage the autoregressive traits of LLMs. In this work, we introduce Interleaving Layout and Text in a Large Language Model (LayTextLLM)} for document understanding. In particular, LayTextLLM projects each bounding box to a single embedding and interleaves it with text, efficiently avoiding long sequence issues while leveraging autoregressive traits of LLMs. LayTextLLM not only streamlines the interaction of layout and textual data but also shows enhanced performance in Key Information Extraction (KIE) and Visual Question Answering (VQA). Comprehensive benchmark evaluations reveal significant improvements, with a 27.0% increase on KIE tasks and 24.1% on VQA tasks compared to previous state-of-the-art document understanding MLLMs, as well as a 15.5% improvement over other SOTA OCR-based LLMs on KIE tasks.",
    "pdf_link": "https://arxiv.org/abs/2407.01976",
    "graphs": [],
    "abstract_cn": "近期研究显示，结合OCR文本和空间布局的LLMs在文档理解任务中表现出色。然而，现有方法在整合这两者时存在不足，如产生冗长文本或未能充分发挥LLMs的自回归优势。为此，我们提出了LayTextLLM，它通过将每个边界框映射为一个嵌入并与文本交错，巧妙规避了长序列问题，同时强化了自回归特性。LayTextLLM不仅优化了布局与文本的交互，还在KIE和VQA任务中展现了显著的性能提升。基准测试表明，与现有最先进模型相比，LayTextLLM在KIE任务上提升了27.0%，在VQA任务上提升了24.1%，同时在基于OCR的LLMs的KIE任务上也有15.5%的进步。",
    "title_cn": "每个边界框等同于一个令牌，通过在大规模语言模型中交错布局与文本，我们实现了对文档的深入理解。",
    "tags": [
      "LLM应用",
      "文档处理",
      "视觉问答"
    ]
  },
  {
    "title": "MeMemo: On-device Retrieval Augmentation for Private and Personalized Text Generation",
    "submit_datetime": "2024年07月02日",
    "abstract": "Retrieval-augmented text generation (RAG) addresses the common limitations of large language models (LLMs), such as hallucination, by retrieving information from an updatable external knowledge base. However, existing approaches often require dedicated backend servers for data storage and retrieval, thereby limiting their applicability in use cases that require strict data privacy, such as personal finance, education, and medicine. To address the pressing need for client-side dense retrieval, we introduce MeMemo, the first open-source JavaScript toolkit that adapts the state-of-the-art approximate nearest neighbor search technique HNSW to browser environments. Developed with modern and native Web technologies, such as IndexedDB and Web Workers, our toolkit leverages client-side hardware capabilities to enable researchers and developers to efficiently search through millions of high-dimensional vectors in the browser. MeMemo enables exciting new design and research opportunities, such as private and personalized content creation and interactive prototyping, as demonstrated in our example application RAG Playground. Reflecting on our work, we discuss the opportunities and challenges for on-device dense retrieval. MeMemo is available at https://github.com/poloclub/mememo.",
    "pdf_link": "https://arxiv.org/abs/2407.01972",
    "graphs": [],
    "abstract_cn": "RAG 通过从外部知识库检索信息，有效解决了 LLM 的幻觉问题。但现有方法依赖专用服务器，限制了其在高度隐私敏感领域的应用。为此，我们推出了 MeMemo，首个开源 JavaScript 工具包，将 HNSW 技术引入浏览器环境。借助现代 Web 技术，MeMemo 利用客户端硬件，支持在浏览器中高效处理高维向量搜索，为私密个性化内容创作和交互式原型设计等新机遇铺平道路。MeMemo 已在 GitHub 上发布，我们同时探讨了设备上密集检索的机遇与挑战。",
    "title_cn": "MeMemo：实现设备端检索增强，助力私密且个性化的文本生成",
    "tags": [
      "RAG",
      "软件开发",
      "网络安全"
    ]
  },
  {
    "title": "Enabling Discriminative Reasoning in Large Language Models for Legal Judgment Prediction",
    "submit_datetime": "2024年07月02日",
    "abstract": "Legal judgment prediction is essential for enhancing judicial efficiency. In this work, we identify that existing large language models (LLMs) underperform in this domain due to challenges in understanding case complexities and distinguishing between similar charges. To adapt LLMs for effective legal judgment prediction, we introduce the Ask-Discriminate-Predict (ADAPT) reasoning framework inspired by human judicial reasoning. ADAPT involves decomposing case facts, discriminating among potential charges, and predicting the final judgment. We further enhance LLMs through fine-tuning with multi-task synthetic trajectories to improve legal judgment prediction accuracy and efficiency under our ADAPT framework. Extensive experiments conducted on two widely-used datasets demonstrate the superior performance of our framework in legal judgment prediction, particularly when dealing with complex and confusing charges.",
    "pdf_link": "https://arxiv.org/abs/2407.01964",
    "graphs": [],
    "abstract_cn": "法律判决预测对提升司法效率至关重要。我们发现，大型语言模型（LLM）在理解案件复杂性和区分相似指控方面存在不足。为此，我们设计了Ask-Discriminate-Predict（ADAPT）框架，模拟人类司法推理过程，通过分解案件事实、区分指控并预测判决，提升LLM在法律领域的应用效果。通过多任务合成轨迹的微调，我们进一步优化了ADAPT框架，使其在处理复杂案件时表现更佳。实验结果显示，ADAPT框架在法律判决预测中展现出显著优势，特别是在应对复杂指控时。",
    "title_cn": "大型语言模型中的判别推理助力法律判决预测",
    "tags": [
      "LLM应用",
      "",
      ""
    ]
  },
  {
    "title": "Towards Unsupervised Speaker Diarization System for Multilingual Telephone Calls Using Pre-trained Whisper Model and Mixture of Sparse Autoencoders",
    "submit_datetime": "2024年07月02日",
    "abstract": "Existing speaker diarization systems heavily rely on large amounts of manually annotated data, which is labor-intensive and challenging to collect in real-world scenarios. Additionally, the language-specific constraint in speaker diarization systems significantly hinders their applicability and scalability in multilingual settings. In this paper, we therefore propose a cluster-based speaker diarization system for multilingual telephone call applications. The proposed system supports multiple languages and does not require large-scale annotated data for the training process as leveraging the multilingual Whisper model to extract speaker embeddings and proposing a novel Mixture of Sparse Autoencoders (Mix-SAE) network architecture for unsupervised speaker clustering. Experimental results on the evaluating dataset derived from two-speaker subsets of CALLHOME and CALLFRIEND telephonic speech corpora demonstrate superior efficiency of the proposed Mix-SAE network to other autoencoder-based clustering methods. The overall performance of our proposed system also indicates the promising potential of our approach in developing unsupervised multilingual speaker diarization applications within the context of limited annotated data and enhancing the integration ability into comprehensive multi-task speech analysis systems (i.e. multiple tasks of speech-to-text, language detection, speaker diarization integrated in a low-complexity system).",
    "pdf_link": "https://arxiv.org/abs/2407.01963",
    "graphs": [],
    "abstract_cn": "当前的说话人日志系统依赖于大量手动标注数据，这在实际应用中既耗时又困难。此外，语言特定的限制大大限制了这些系统在多语言环境中的应用。为此，我们提出了一种基于聚类的多语言电话说话人日志系统，该系统支持多种语言，无需大规模标注数据，通过多语言Whisper模型提取说话人特征，并采用创新的Mix-SAE网络架构进行无监督聚类。实验表明，Mix-SAE在效率上超越了其他自编码器聚类方法。我们的系统不仅在有限标注数据下展现出巨大潜力，还能有效融入复杂度低的多任务语音分析系统，涵盖语音转文本、语言识别和说话人日志等功能。",
    "title_cn": "本研究旨在构建一个无监督的多语言电话通话说话人日志系统，该系统结合了预训练的 Whisper 模型与稀疏自编码器的混合技术。",
    "tags": [
      "LLM应用",
      "",
      "语音识别"
    ]
  },
  {
    "title": "S2D: Sorted Speculative Decoding For More Efficient Deployment of Nested Large Language Models",
    "submit_datetime": "2024年07月02日",
    "abstract": "Deployment of autoregressive large language models (LLMs) is costly, and as these models increase in size, the associated costs will become even more considerable. Consequently, different methods have been proposed to accelerate the token generation process and reduce costs. Speculative decoding (SD) is among the most promising approaches to speed up the LLM decoding process by verifying multiple tokens in parallel and using an auxiliary smaller draft model to generate the possible tokens. In SD, usually, one draft model is used to serve a specific target model; however, in practice, LLMs are diverse, and we might need to deal with many target models or more than one target model simultaneously. In this scenario, it is not clear which draft model should be used for which target model, and searching among different draft models or training customized draft models can further increase deployment costs. In this paper, we first introduce a novel multi-target scenario for the deployment of draft models for faster inference. Then, we present a novel, more efficient sorted speculative decoding mechanism that outperforms regular baselines in multi-target settings. We evaluated our method on Spec-Bench in different settings, including base models such as Vicuna 7B, 13B, and LLama Chat 70B. Our results suggest that our draft models perform better than baselines for multiple target models at the same time.",
    "pdf_link": "https://arxiv.org/abs/2407.01955",
    "graphs": [],
    "abstract_cn": "自回归大型语言模型的部署成本高昂，且随着模型规模的扩大，相关成本愈发显著。为此，业界提出了多种方法来加速令牌生成并降低成本。其中，推测解码 (SD) 通过并行验证多个令牌并利用辅助的小型草稿模型生成可能的令牌，成为加速 LLM 解码过程的佼佼者。通常，一个草稿模型服务于一个特定的目标模型，但现实中 LLM 种类繁多，我们可能需要同时处理多个目标模型。这种情况下，选择合适的草稿模型变得复杂，而搜索或定制草稿模型可能进一步增加部署成本。本文中，我们首先提出了一种新颖的多目标场景，用于草稿模型的快速推理部署。接着，我们介绍了一种更高效的排序推测解码机制，该机制在多目标环境中表现优于传统基准。我们在包括 Vicuna 7B、13B 和 LLama Chat 70B 在内的多种模型上验证了我们的方法，结果显示，我们的草稿模型在同时处理多个目标模型时，性能超越了基准。",
    "title_cn": "S2D：通过排序推测解码，提升嵌套大型语言模型的部署效率",
    "tags": [
      "LLM应用",
      "人工智能",
      "云计算"
    ]
  },
  {
    "title": "CatMemo at the FinLLM Challenge Task: Fine-Tuning Large Language Models using Data Fusion in Financial Applications",
    "submit_datetime": "2024年07月02日",
    "abstract": "The integration of Large Language Models (LLMs) into financial analysis has garnered significant attention in the NLP community. This paper presents our solution to IJCAI-2024 FinLLM challenge, investigating the capabilities of LLMs within three critical areas of financial tasks: financial classification, financial text summarization, and single stock trading. We adopted Llama3-8B and Mistral-7B as base models, fine-tuning them through Parameter Efficient Fine-Tuning (PEFT) and Low-Rank Adaptation (LoRA) approaches. To enhance model performance, we combine datasets from task 1 and task 2 for data fusion. Our approach aims to tackle these diverse tasks in a comprehensive and integrated manner, showcasing LLMs' capacity to address diverse and complex financial tasks with improved accuracy and decision-making capabilities.",
    "pdf_link": "https://arxiv.org/abs/2407.01953",
    "graphs": [],
    "abstract_cn": "在 NLP 社区中，LLM 在金融分析领域的应用备受瞩目。本文针对 IJCAI-2024 FinLLM 挑战赛，探讨了 LLM 在金融分类、文本摘要和股票交易三大关键领域的应用。我们选用 Llama3-8B 和 Mistral-7B 模型，通过 PEFT 和 LoRA 技术进行精细调整，并融合任务 1 与任务 2 的数据集以增强性能。我们的方法全面整合，旨在展示 LLM 在处理复杂金融任务时，如何提升准确性与决策力。",
    "title_cn": "CatMemo在FinLLM挑战中，通过数据融合技术，优化金融应用中的大型语言模型微调。",
    "tags": [
      "LLM应用",
      "",
      ""
    ]
  },
  {
    "title": "Extracting and Encoding: Leveraging Large Language Models and Medical Knowledge to Enhance Radiological Text Representation",
    "submit_datetime": "2024年07月02日",
    "abstract": "Advancing representation learning in specialized fields like medicine remains challenging due to the scarcity of expert annotations for text and images. To tackle this issue, we present a novel two-stage framework designed to extract high-quality factual statements from free-text radiology reports in order to improve the representations of text encoders and, consequently, their performance on various downstream tasks. In the first stage, we propose a \\textit{Fact Extractor} that leverages large language models (LLMs) to identify factual statements from well-curated domain-specific datasets. In the second stage, we introduce a \\textit{Fact Encoder} (CXRFE) based on a BERT model fine-tuned with objective functions designed to improve its representations using the extracted factual data. Our framework also includes a new embedding-based metric (CXRFEScore) for evaluating chest X-ray text generation systems, leveraging both stages of our approach. Extensive evaluations show that our fact extractor and encoder outperform current state-of-the-art methods in tasks such as sentence ranking, natural language inference, and label extraction from radiology reports. Additionally, our metric proves to be more robust and effective than existing metrics commonly used in the radiology report generation literature. The code of this project is available at \\url{https://github.com/PabloMessina/CXR-Fact-Encoder}.",
    "pdf_link": "https://arxiv.org/abs/2407.01948",
    "graphs": [],
    "abstract_cn": "在医学等专业领域，由于缺乏专家注释，表示学习的进步面临挑战。为此，我们设计了一个两阶段框架，从放射学报告中提取高质量事实，以优化文本编码器的性能。首先，我们利用LLM从精选数据集中提取事实。接着，我们基于BERT模型，通过特定目标函数微调，引入CXRFE编码器。此外，我们还开发了CXRFEScore度量，用于评估胸部X射线文本生成系统。实验表明，我们的方法在多个任务中超越了现有技术，且CXRFEScore比传统度量更稳健有效。项目代码已公开在\\url{https://github.com/PabloMessina/CXR-Fact-Encoder}。",
    "title_cn": "借助大型语言模型与医学知识，我们致力于提升放射学文本的表达力。",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs",
    "submit_datetime": "2024年07月02日",
    "abstract": "Large language models (LLMs) typically utilize the top-k contexts from a retriever in retrieval-augmented generation (RAG). In this work, we propose a novel instruction fine-tuning framework RankRAG, which instruction-tunes a single LLM for the dual purpose of context ranking and answer generation in RAG. In particular, the instruction-tuned LLMs work surprisingly well by adding a small fraction of ranking data into the training blend, and outperform existing expert ranking models, including the same LLM exclusively fine-tuned on a large amount of ranking data. For generation, we compare our model with many strong baselines, including GPT-4-0613, GPT-4-turbo-2024-0409, and ChatQA-1.5, an open-sourced model with the state-of-the-art performance on RAG benchmarks. Specifically, our Llama3-RankRAG significantly outperforms Llama3-ChatQA-1.5 and GPT-4 models on nine knowledge-intensive benchmarks. In addition, it also performs comparably to GPT-4 on five RAG benchmarks in the biomedical domain without instruction fine-tuning on biomedical data, demonstrating its superb capability for generalization to new domains.",
    "pdf_link": "https://arxiv.org/abs/2407.02485",
    "graphs": [],
    "abstract_cn": "我们提出了一种名为 RankRAG 的创新指令微调框架，该框架使单个 LLM 能够同时进行上下文排序和答案生成，显著提升了 RAG 的性能。通过在训练中融入少量排序数据，RankRAG 不仅超越了专门优化的排序模型，还在生成任务上表现卓越，击败了包括 GPT-4 在内的多个顶尖模型。特别是在知识密集型和生物医学领域的基准测试中，RankRAG 展现了其强大的泛化能力，无需特定领域的微调即可与 GPT-4 媲美。",
    "title_cn": "RankRAG：整合上下文排序与检索增强生成于大型语言模型中",
    "tags": [
      "RAG",
      "生物医学",
      "人工智能"
    ]
  },
  {
    "title": "MMedAgent: Learning to Use Medical Tools with Multi-modal Agent",
    "submit_datetime": "2024年07月02日",
    "abstract": "Multi-Modal Large Language Models (MLLMs), despite being successful, exhibit limited generality and often fall short when compared to specialized models. Recently, LLM-based agents have been developed to address these challenges by selecting appropriate specialized models as tools based on user inputs. However, such advancements have not been extensively explored within the medical domain. To bridge this gap, this paper introduces the first agent explicitly designed for the medical field, named \\textbf{M}ulti-modal \\textbf{Med}ical \\textbf{Agent} (MMedAgent). We curate an instruction-tuning dataset comprising six medical tools solving seven tasks, enabling the agent to choose the most suitable tools for a given task. Comprehensive experiments demonstrate that MMedAgent achieves superior performance across a variety of medical tasks compared to state-of-the-art open-source methods and even the closed-source model, GPT-4o. Furthermore, MMedAgent exhibits efficiency in updating and integrating new medical tools.",
    "pdf_link": "https://arxiv.org/abs/2407.02483",
    "graphs": [],
    "abstract_cn": "尽管多模态大型语言模型 (MLLMs) 取得了成功，但其通用性有限，与专业模型相比常显不足。为此，基于 LLM 的代理应运而生，它们能根据用户输入选择合适的专业模型作为工具。然而，这一进步在医学领域尚未深入探索。为此，本文首次推出了专为医学领域设计的代理——**M**ulti-modal **Med**ical **Agent** (MMedAgent)。我们构建了一个包含六种医疗工具解决七项任务的指令调优数据集，使 MMedAgent 能精准选择工具。实验证明，MMedAgent 在多种医疗任务中的表现超越了顶尖的开源方法和 GPT-4o 等闭源模型，且在更新和集成新工具方面极为高效。",
    "title_cn": "MMedAgent：掌握医疗工具的多模态学习代理",
    "tags": [
      "Agent",
      "",
      "人工智能"
    ]
  },
  {
    "title": "MInference 1.0: Accelerating Pre-filling for Long-Context LLMs via Dynamic Sparse Attention",
    "submit_datetime": "2024年07月02日",
    "abstract": "The computational challenges of Large Language Model (LLM) inference remain a significant barrier to their widespread deployment, especially as prompt lengths continue to increase. Due to the quadratic complexity of the attention computation, it takes 30 minutes for an 8B LLM to process a prompt of 1M tokens (i.e., the pre-filling stage) on a single A100 GPU. Existing methods for speeding up prefilling often fail to maintain acceptable accuracy or efficiency when applied to long-context LLMs. To address this gap, we introduce MInference (Milliontokens Inference), a sparse calculation method designed to accelerate pre-filling of long-sequence processing. Specifically, we identify three unique patterns in long-context attention matrices-the A-shape, Vertical-Slash, and Block-Sparsethat can be leveraged for efficient sparse computation on GPUs. We determine the optimal pattern for each attention head offline and dynamically build sparse indices based on the assigned pattern during inference. With the pattern and sparse indices, we perform efficient sparse attention calculations via our optimized GPU kernels to significantly reduce the latency in the pre-filling stage of long-context LLMs. Our proposed technique can be directly applied to existing LLMs without any modifications to the pre-training setup or additional fine-tuning. By evaluating on a wide range of downstream tasks, including InfiniteBench, RULER, PG-19, and Needle In A Haystack, and models including LLaMA-3-1M, GLM4-1M, Yi-200K, Phi-3-128K, and Qwen2-128K, we demonstrate that MInference effectively reduces inference latency by up to 10x for pre-filling on an A100, while maintaining accuracy. Our code is available at https://aka.ms/MInference.",
    "pdf_link": "https://arxiv.org/abs/2407.02490",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLM）的推理计算挑战，尤其是在提示长度不断增加的情况下，仍是广泛部署的重大障碍。由于注意力计算的二次复杂性，处理1M令牌的提示在单个A100 GPU上需时30分钟。为解决现有方法在长上下文LLM中难以保持准确性与效率的问题，我们推出了MInference，一种专为加速长序列预填充设计的稀疏计算方法。我们识别了三种独特的注意力矩阵模式——A形、垂直斜线和块稀疏，这些模式可用于GPU上的高效稀疏计算。我们离线确定每个注意力头的最佳模式，并在推理时动态构建稀疏索引。通过这些模式和索引，我们利用优化的GPU内核进行高效稀疏注意力计算，显著减少长上下文LLM预填充阶段的延迟。我们的技术可直接应用于现有LLM，无需修改预训练设置或额外微调。通过在多个下游任务和模型中进行评估，我们证明了MInference能有效减少A100上的预填充推理延迟高达10倍，同时保持准确性。代码已公开，可访问https://aka.ms/MInference获取。",
    "title_cn": "MInference 1.0 通过动态稀疏注意力机制，加速了长上下文大型语言模型的预填充过程。",
    "tags": [
      "LLM应用",
      "人工智能",
      "高性能计算"
    ]
  },
  {
    "title": "Neurocache: Efficient Vector Retrieval for Long-range Language Modeling",
    "submit_datetime": "2024年07月02日",
    "abstract": "This paper introduces Neurocache, an approach to extend the effective context size of large language models (LLMs) using an external vector cache to store its past states. Like recent vector retrieval approaches, Neurocache uses an efficient k-nearest-neighbor (kNN) algorithm to retrieve relevant past states and incorporate them into the attention process. Neurocache improves upon previous methods by (1) storing compressed states, which reduces cache size; (2) performing a single retrieval operation per token which increases inference speed; and (3) extending the retrieval window to neighboring states, which improves both language modeling and downstream task accuracy. Our experiments show the effectiveness of Neurocache both for models trained from scratch and for pre-trained models such as Llama2-7B and Mistral-7B when enhanced with the cache mechanism. We also compare Neurocache with text retrieval methods and show improvements in single-document question-answering and few-shot learning tasks. We made the source code available under: https://github.com/alisafaya/neurocache",
    "pdf_link": "https://arxiv.org/abs/2407.02486",
    "graphs": [],
    "abstract_cn": "本文提出 Neurocache，一种利用外部向量缓存存储模型历史状态，从而扩展 LLM 上下文大小的创新方法。Neurocache 采用高效的 kNN 算法，快速检索并整合相关历史状态至注意力机制中，从而实现以下优化：(1) 压缩状态存储，减小缓存空间；(2) 单次检索操作每令牌，加速推理过程；(3) 扩展检索范围至邻近状态，提升语言模型及下游任务准确性。实验证明，无论是全新训练还是预训练模型（如 Llama2-7B 和 Mistral-7B），Neurocache 均能显著提升性能。此外，与传统文本检索相比，Neurocache 在单文档问答和少样本学习任务中表现更优。源代码已公开于：https://github.com/alisafaya/neurocache",
    "title_cn": "Neurocache：实现长距离语言建模的高效向量检索技术",
    "tags": [
      "LLM应用",
      "人工智能",
      "软件开发"
    ]
  },
  {
    "title": "Understanding Alignment in Multimodal LLMs: A Comprehensive Study",
    "submit_datetime": "2024年07月02日",
    "abstract": "Preference alignment has become a crucial component in enhancing the performance of Large Language Models (LLMs), yet its impact in Multimodal Large Language Models (MLLMs) remains comparatively underexplored. Similar to language models, MLLMs for image understanding tasks encounter challenges like hallucination. In MLLMs, hallucination can occur not only by stating incorrect facts but also by producing responses that are inconsistent with the image content. A primary objective of alignment for MLLMs is to encourage these models to align responses more closely with image information. Recently, multiple works have introduced preference datasets for MLLMs and examined different alignment methods, including Direct Preference Optimization (DPO) and Proximal Policy Optimization (PPO). However, due to variations in datasets, base model types, and alignment methods, it remains unclear which specific elements contribute most significantly to the reported improvements in these works. In this paper, we independently analyze each aspect of preference alignment in MLLMs. We start by categorizing the alignment algorithms into two groups, offline (such as DPO), and online (such as online-DPO), and show that combining offline and online methods can improve the performance of the model in certain scenarios. We review a variety of published multimodal preference datasets and discuss how the details of their construction impact model performance. Based on these insights, we introduce a novel way of creating multimodal preference data called Bias-Driven Hallucination Sampling (BDHS) that needs neither additional annotation nor external models, and show that it can achieve competitive performance to previously published alignment work for multimodal models across a range of benchmarks.",
    "pdf_link": "https://arxiv.org/abs/2407.02477",
    "graphs": [],
    "abstract_cn": "偏好对齐在提升大型语言模型性能中扮演着关键角色，但在多模态大型语言模型中的应用仍待深入探索。多模态模型在图像理解任务中同样面临幻觉挑战，不仅可能因错误信息，还可能因与图像不符的回应。对齐的主要目标之一是使模型回应更贴合图像信息。近期研究引入了多种对齐方法和数据集，但各数据集和方法的差异使得具体改进因素尚不明朗。本文中，我们深入分析了多模态模型中偏好对齐的各个方面，分类并探讨了离线和在线对齐算法的结合效果，回顾了多模态偏好数据集的构建细节及其对性能的影响。基于此，我们创新性地提出了无需额外注释或外部模型的偏差驱动的幻觉采样方法，该方法在多模态模型性能上表现出色，与现有对齐技术相媲美。",
    "title_cn": "探究多模态LLM中的对齐机制：一项深入研究",
    "tags": [
      "LLM应用",
      "人工智能",
      "计算机视觉"
    ]
  },
  {
    "title": "Open Scene Graphs for Open World Object-Goal Navigation",
    "submit_datetime": "2024年07月02日",
    "abstract": "How can we build robots for open-world semantic navigation tasks, like searching for target objects in novel scenes? While foundation models have the rich knowledge and generalisation needed for these tasks, a suitable scene representation is needed to connect them into a complete robot system. We address this with Open Scene Graphs (OSGs), a topo-semantic representation that retains and organises open-set scene information for these models, and has a structure that can be configured for different environment types. We integrate foundation models and OSGs into the OpenSearch system for Open World Object-Goal Navigation, which is capable of searching for open-set objects specified in natural language, while generalising zero-shot across diverse environments and embodiments. Our OSGs enhance reasoning with Large Language Models (LLM), enabling robust object-goal navigation outperforming existing LLM approaches. Through simulation and real-world experiments, we validate OpenSearch's generalisation across varied environments, robots and novel instructions.",
    "pdf_link": "https://arxiv.org/abs/2407.02473",
    "graphs": [],
    "abstract_cn": "我们如何打造能在开放世界中进行语义导航的机器人，比如在新环境中寻找特定物品？基础模型虽具备丰富的知识和泛化能力，但还需一个恰当的场景表示来构建完整的机器人系统。我们采用 Open Scene Graphs (OSGs)，这是一种结合拓扑与语义的表示方法，能有效组织并保留开放场景信息，并可根据不同环境灵活调整。我们将基础模型与 OSGs 融合进 OpenSearch 系统，使其能在自然语言指引下，搜索任意指定物品，并在多变的环境和实体中实现零-shot 泛化。OSGs 与大型语言模型的结合，提升了对象目标导航的鲁棒性，超越了现有 LLM 方法。通过模拟与实境测试，我们证实了 OpenSearch 在多样环境、机器人及新指令中的广泛适用性。",
    "title_cn": "开放场景图助力开放世界中的对象目标导航",
    "tags": [
      "Agent",
      "机器人",
      "人工智能"
    ]
  },
  {
    "title": "Reliable Confidence Intervals for Information Retrieval Evaluation Using Generative A.I",
    "submit_datetime": "2024年07月02日",
    "abstract": "The traditional evaluation of information retrieval (IR) systems is generally very costly as it requires manual relevance annotation from human experts. Recent advancements in generative artificial intelligence -- specifically large language models (LLMs) -- can generate relevance annotations at an enormous scale with relatively small computational costs. Potentially, this could alleviate the costs traditionally associated with IR evaluation and make it applicable to numerous low-resource applications. However, generated relevance annotations are not immune to (systematic) errors, and as a result, directly using them for evaluation produces unreliable results.\n  In this work, we propose two methods based on prediction-powered inference and conformal risk control that utilize computer-generated relevance annotations to place reliable confidence intervals (CIs) around IR evaluation metrics. Our proposed methods require a small number of reliable annotations from which the methods can statistically analyze the errors in the generated annotations. Using this information, we can place CIs around evaluation metrics with strong theoretical guarantees. Unlike existing approaches, our conformal risk control method is specifically designed for ranking metrics and can vary its CIs per query and document. Our experimental results show that our CIs accurately capture both the variance and bias in evaluation based on LLM annotations, better than the typical empirical bootstrapping estimates. We hope our contributions bring reliable evaluation to the many IR applications where this was traditionally infeasible.",
    "pdf_link": "https://arxiv.org/abs/2407.02464",
    "graphs": [],
    "abstract_cn": "传统的信息检索系统评估因依赖人类专家的手动标注而成本高昂。随着大型语言模型（LLMs）的发展，我们能在低成本下大规模生成相关性标注，有望降低评估成本，惠及众多低资源应用。然而，这些生成的标注存在系统性错误，直接用于评估会导致结果不可靠。为此，我们提出了两种方法：预测驱动推理和一致性风险控制，利用计算机生成的标注为评估指标设定可靠的置信区间（CIs）。这些方法仅需少量可靠标注，即可统计分析生成标注的错误，进而为评估指标设定具有强理论保证的CIs。与传统方法不同，我们的一致性风险控制方法专为排名指标设计，能根据每个查询和文档灵活调整CIs。实验表明，我们的CIs能更准确地捕捉评估中的方差和偏差。我们期待这些贡献能为众多IR应用带来可靠的评估。",
    "title_cn": "利用生成式AI评估信息检索的可靠置信区间",
    "tags": [
      "LLM应用",
      "信息检索",
      "数据评估"
    ]
  },
  {
    "title": "Improving Visual Storytelling with Multimodal Large Language Models",
    "submit_datetime": "2024年07月02日",
    "abstract": "Visual storytelling is an emerging field that combines images and narratives to create engaging and contextually rich stories. Despite its potential, generating coherent and emotionally resonant visual stories remains challenging due to the complexity of aligning visual and textual information. This paper presents a novel approach leveraging large language models (LLMs) and large vision-language models (LVLMs) combined with instruction tuning to address these challenges. We introduce a new dataset comprising diverse visual stories, annotated with detailed captions and multimodal elements. Our method employs a combination of supervised and reinforcement learning to fine-tune the model, enhancing its narrative generation capabilities. Quantitative evaluations using GPT-4 and qualitative human assessments demonstrate that our approach significantly outperforms existing models, achieving higher scores in narrative coherence, relevance, emotional depth, and overall quality. The results underscore the effectiveness of instruction tuning and the potential of LLMs/LVLMs in advancing visual storytelling.",
    "pdf_link": "https://arxiv.org/abs/2407.02586",
    "graphs": [],
    "abstract_cn": "视觉叙事，这一新兴领域融合图像与叙事，旨在编织引人入胜、情境丰富的故事。然而，视觉与文本信息的复杂对齐，使得创造连贯且情感共鸣的视觉故事颇具挑战。本文创新性地结合大型语言模型（LLMs）与视觉-语言模型（LVLMs），并引入指令调优，以应对这一难题。我们构建了一个包含多样化视觉故事的详尽数据集，辅以多模态元素。通过监督学习与强化学习的协同微调，我们的模型叙事生成能力得以显著提升。GPT-4的定量评估与人类定性评价双重验证，我们的方法在叙事连贯性、相关性、情感深度及整体质量上均超越现有模型。这一成果不仅彰显了指令调优的效力，更揭示了LLMs/LVLMs在视觉叙事领域的广阔前景。",
    "title_cn": "通过多模态大型语言模型提升视觉叙事效果",
    "tags": [
      "LLM应用",
      "",
      ""
    ]
  },
  {
    "title": "Model-Enhanced LLM-Driven VUI Testing of VPA Apps",
    "submit_datetime": "2024年07月02日",
    "abstract": "The flourishing ecosystem centered around voice personal assistants (VPA), such as Amazon Alexa, has led to the booming of VPA apps. The largest app market Amazon skills store, for example, hosts over 200,000 apps. Despite their popularity, the open nature of app release and the easy accessibility of apps also raise significant concerns regarding security, privacy and quality. Consequently, various testing approaches have been proposed to systematically examine VPA app behaviors. To tackle the inherent lack of a visible user interface in the VPA app, two strategies are employed during testing, i.e., chatbot-style testing and model-based testing. The former often lacks effective guidance for expanding its search space, while the latter falls short in interpreting the semantics of conversations to construct precise and comprehensive behavior models for apps. In this work, we introduce Elevate, a model-enhanced large language model (LLM)-driven VUI testing framework. Elevate leverages LLMs' strong capability in natural language processing to compensate for semantic information loss during model-based VUI testing. It operates by prompting LLMs to extract states from VPA apps' outputs and generate context-related inputs. During the automatic interactions with the app, it incrementally constructs the behavior model, which facilitates the LLM in generating inputs that are highly likely to discover new states. Elevate bridges the LLM and the behavior model with innovative techniques such as encoding behavior model into prompts and selecting LLM-generated inputs based on the context relevance. Elevate is benchmarked on 4,000 real-world Alexa skills, against the state-of-the-art tester Vitas. It achieves 15% higher state space coverage compared to Vitas on all types of apps, and exhibits significant advancement in efficiency.",
    "pdf_link": "https://arxiv.org/abs/2407.02791",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.02791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02791/choose_input_example.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02791/state_example.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02791/challenge.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02791/overview.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02791/feedback1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02791/feedback2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02791/feedback3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02791/compression.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02791/study2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02791/study4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02791/study5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02791v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02791/study6.png"
      }
    ],
    "abstract_cn": "围绕语音助手（如Amazon Alexa）的繁荣生态系统催生了大量VPA应用。尽管这些应用广受欢迎，但其开放性和易获取性也引发了安全、隐私和质量方面的担忧。为此，研究者提出了多种测试方法来系统评估VPA应用。针对VPA应用缺乏可视界面的特点，测试中采用了聊天机器人式和基于模型的两种策略。然而，前者在扩展搜索空间上缺乏有效指导，后者则在构建精确全面的行为模型上存在局限。为此，我们推出了Elevate框架，它结合了大型语言模型（LLM）的强大自然语言处理能力，以弥补基于模型测试中的语义信息损失。Elevate通过引导LLM从应用输出中提取状态并生成上下文相关输入，逐步构建行为模型，从而提高发现新状态的可能性。通过创新地将行为模型融入提示和基于上下文选择输入，Elevate有效连接了LLM与行为模型。在4,000个真实Alexa技能的测试中，Elevate相较于Vitas在状态空间覆盖率上提升了15%，并在效率上取得了显著进步。",
    "title_cn": "基于模型增强的 LLM 驱动，对 VPA 应用进行 VUI 测试",
    "tags": [
      "LLM应用",
      "智能家居",
      "语音助手"
    ]
  },
  {
    "title": "52B to 1T: Lessons Learned via Tele-FLM Series",
    "submit_datetime": "2024年07月02日",
    "abstract": "Large Language Models (LLMs) represent a significant stride toward Artificial General Intelligence. As scaling laws underscore the potential of increasing model sizes, the academic community has intensified its investigations into LLMs with capacities exceeding 50 billion parameters. This technical report builds on our prior work with Tele-FLM (also known as FLM-2), a publicly available 52-billion-parameter model. We delve into two primary areas: we first discuss our observation of Supervised Fine-tuning (SFT) on Tele-FLM-52B, which supports the \"less is more\" approach for SFT data construction; second, we demonstrate our experiments and analyses on the best practices for progressively growing a model from 52 billion to 102 billion, and subsequently to 1 trillion parameters. We will open-source a 1T model checkpoint, namely Tele-FLM-1T, to advance further training and research.",
    "pdf_link": "https://arxiv.org/abs/2407.02783",
    "graphs": [],
    "abstract_cn": "大型语言模型 (LLM) 是通往通用人工智能的关键进展。随着模型规模的扩大，学术界对超过 500 亿参数的 LLM 研究日益深入。本报告基于我们与 Tele-FLM（FLM-2）的合作，该模型拥有 520 亿参数。我们探讨了两个核心领域：首先，我们发现 Tele-FLM-52B 上的监督微调 (SFT) 支持“少即是多”的数据构建策略；其次，我们展示了如何从 520 亿逐步扩展到 1 万亿参数的最佳实践。为推动研究，我们将公开 Tele-FLM-1T 模型。",
    "title_cn": "从 52B 到 1T：Tele-FLM 系列中的经验启示",
    "tags": [
      "LLM理论",
      "人工智能",
      "机器学习"
    ]
  },
  {
    "title": "Croppable Knowledge Graph Embedding",
    "submit_datetime": "2024年07月02日",
    "abstract": "Knowledge Graph Embedding (KGE) is a common method for Knowledge Graphs (KGs) to serve various artificial intelligence tasks. The suitable dimensions of the embeddings depend on the storage and computing conditions of the specific application scenarios. Once a new dimension is required, a new KGE model needs to be trained from scratch, which greatly increases the training cost and limits the efficiency and flexibility of KGE in serving various scenarios. In this work, we propose a novel KGE training framework MED, through which we could train once to get a croppable KGE model applicable to multiple scenarios with different dimensional requirements, sub-models of the required dimensions can be cropped out of it and used directly without any additional training. In MED, we propose a mutual learning mechanism to improve the low-dimensional sub-models performance and make the high-dimensional sub-models retain the capacity that low-dimensional sub-models have, an evolutionary improvement mechanism to promote the high-dimensional sub-models to master the knowledge that the low-dimensional sub-models can not learn, and a dynamic loss weight to balance the multiple losses adaptively. Experiments on 3 KGE models over 4 standard KG completion datasets, 3 real application scenarios over a real-world large-scale KG, and the experiments of extending MED to the language model BERT show the effectiveness, high efficiency, and flexible extensibility of MED.",
    "pdf_link": "https://arxiv.org/abs/2407.02779",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.02779v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02779/intro_2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02779v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02779/model2_copy.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02779v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02779/FB15K237_rotate_MRR_Hit10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02779v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02779/FB15K237_pairre_MRR_Hit10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02779v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02779/overlap_big_1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02779v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02779/visual.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02779v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02779/WN18RR_transe_MRR_Hit10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02779v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02779/WN18RR_rotate_MRR_Hit10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02779v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02779/WN18RR_pairre_MRR_Hit10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02779v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02779/FB15K237_transe_MRR_Hit10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02779v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02779/FB15K237_rotate_MRR_Hit10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02779v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02779/FB15K237_pairre_MRR_Hit10.png"
      }
    ],
    "abstract_cn": "知识图谱嵌入（KGE）是知识图谱服务于多种AI任务的常用技术。然而，每当需要新的嵌入维度时，就必须从头开始训练新的KGE模型，这不仅增加了成本，还限制了KGE的效率和灵活性。为此，我们推出了MED框架，只需一次训练，即可生成适用于不同维度需求的可裁剪KGE模型。MED框架内含相互学习、进化改进和动态损失权重三大机制，确保了模型的高效性和灵活性。实验证明，MED在多个数据集和实际应用场景中表现出色，且能无缝扩展至BERT等语言模型。",
    "title_cn": "知识图谱嵌入的可裁剪性",
    "tags": [
      "LLM应用",
      "人工智能",
      "知识图谱"
    ]
  },
  {
    "title": "Large language models, physics-based modeling, experimental measurements: the trinity of data-scarce learning of polymer properties",
    "submit_datetime": "2024年07月02日",
    "abstract": "Large language models (LLMs) bear promise as a fast and accurate material modeling paradigm for evaluation, analysis, and design. Their vast number of trainable parameters necessitates a wealth of data to achieve accuracy and mitigate overfitting. However, experimental measurements are often limited and costly to obtain in sufficient quantities for finetuning. To this end, we present a physics-based training pipeline that tackles the pathology of data scarcity. The core enabler is a physics-based modeling framework that generates a multitude of synthetic data to align the LLM to a physically consistent initial state before finetuning. Our framework features a two-phase training strategy: (1) utilizing the large-in-amount while less accurate synthetic data for supervised pretraining, and (2) finetuning the phase-1 model with limited experimental data. We empirically demonstrate that supervised pretraining is vital to obtaining accurate finetuned LLMs, via the lens of learning polymer flammability metrics where cone calorimeter data is sparse.",
    "pdf_link": "https://arxiv.org/abs/2407.02770",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.02770v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02770/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02770v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02770/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02770v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02770/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02770v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02770/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02770v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02770/x5.png"
      }
    ],
    "abstract_cn": "大型语言模型 (LLM) 在材料建模领域展现出高效且精准的潜力，但其庞大的参数规模要求海量数据以确保准确性并防止过拟合。然而，实验数据的获取往往受限且成本高昂，难以满足微调需求。为此，我们设计了一套基于物理学的训练流程，专门应对数据稀缺的挑战。核心在于一个基于物理的建模框架，它能生成大量合成数据，确保 LLM 在微调前处于与物理事实一致的初始状态。我们的训练框架分为两个阶段：首先，利用大量但精度稍逊的合成数据进行监督预训练；其次，用有限的实验数据对预训练模型进行微调。通过研究聚合物可燃性指标（其中锥形量热仪数据稀缺），我们实证了监督预训练对于获得精准微调 LLM 的关键作用。",
    "title_cn": "大型语言模型、物理建模与实验测量，三者共同构成了聚合物特性数据稀缺学习的核心。",
    "tags": [
      "LLM应用",
      "材料科学",
      "物理学"
    ]
  },
  {
    "title": "Learning to Reduce: Towards Improving Performance of Large Language Models on Structured Data",
    "submit_datetime": "2024年07月02日",
    "abstract": "Large Language Models (LLMs) have been achieving competent performance on a wide range of downstream tasks, yet existing work shows that inference on structured data is challenging for LLMs. This is because LLMs need to either understand long structured data or select the most relevant evidence before inference, and both approaches are not trivial. This paper proposes a framework, Learning to Reduce, that fine-tunes a language model with On-Policy Learning to generate a reduced version of an input structured data. When compared to state-of-the-art LLMs like GPT-4, Learning to Reduce not only achieves outstanding performance in reducing the input, but shows generalizability on different datasets. We further show that the model fine-tuned with our framework helps LLMs better perform on table QA tasks especially when the context is longer.",
    "pdf_link": "https://arxiv.org/abs/2407.02750",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.02750v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02750/model2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02750v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02750/task_performance_gpt-4-0613.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02750v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02750/task_performance_gpt-3.5-turbo.png"
      }
    ],
    "abstract_cn": "尽管大型语言模型 (LLM) 在众多下游任务中表现出色，但在结构化数据推理方面仍面临挑战。本文提出的“学习去减少”框架，通过策略学习微调语言模型，有效简化了输入数据，不仅性能卓越，还展现了跨数据集的泛化能力。此外，该框架微调的模型在长上下文的表格问答任务中表现尤为出色，为 LLM 的应用拓展了新的可能。",
    "title_cn": "通过学习简化，我们致力于提升大型语言模型在处理结构化数据时的表现。",
    "tags": [
      "LLM应用",
      "人工智能",
      "数据分析"
    ]
  },
  {
    "title": "A Comparative Study of DSL Code Generation: Fine-Tuning vs. Optimized Retrieval Augmentation",
    "submit_datetime": "2024年07月02日",
    "abstract": "Natural Language to Code Generation has made significant progress in recent years with the advent of Large Language Models(LLMs). While generation for general-purpose languages like C, C++, and Python has improved significantly, LLMs struggle with custom function names in Domain Specific Languages or DSLs. This leads to higher hallucination rates and syntax errors, specially for DSLs having a high number of custom function names. Additionally, constant updates to function names add to the challenge as LLMs need to stay up-to-date. In this paper, we present optimizations for using Retrieval Augmented Generation (or RAG) with LLMs for DSL generation along with an ablation study comparing these strategies. We generated a train as well as test dataset with a DSL to represent automation tasks across roughly 700 APIs in public domain. We used the training dataset to fine-tune a Codex model for this DSL. Our results showed that the fine-tuned model scored the best on code similarity metric. With our RAG optimizations, we achieved parity for similarity metric. The compilation rate, however, showed that both the models still got the syntax wrong many times, with RAG-based method being 2 pts better. Conversely, hallucination rate for RAG model lagged by 1 pt for API names and by 2 pts for API parameter keys. We conclude that an optimized RAG model can match the quality of fine-tuned models and offer advantages for new, unseen APIs.",
    "pdf_link": "https://arxiv.org/abs/2407.02742",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.02742v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02742/x1.png"
      }
    ],
    "abstract_cn": "近年来，随着大型语言模型（LLM）的发展，自然语言到代码生成取得了显著进步。尽管在C、C++和Python等通用语言的生成方面有了显著提升，LLM在处理特定领域语言（DSL）中的自定义函数名称时仍显不足，导致幻觉率和语法错误增加，尤其是对于那些包含大量自定义函数名称的DSL。此外，函数名称的不断更新也带来了挑战，要求LLM保持最新状态。本文中，我们针对使用检索增强生成（RAG）与LLM进行DSL生成的优化方法进行了探讨，并通过消融研究比较了这些策略的效果。我们创建了一个包含大约700个公共领域API的自动化任务的DSL训练和测试数据集，并使用该训练集对Codex模型进行了微调。结果表明，微调模型在代码相似度指标上表现最佳。通过RAG优化，我们在相似度指标上达到了同等水平。然而，编译率显示两种模型在语法上仍有多次错误，RAG方法略胜一筹。在幻觉率方面，RAG模型在API名称和参数键上稍显落后。最终我们得出结论，经过优化的RAG模型不仅能与微调模型相媲美，还能为处理新的、未见过的API提供优势。",
    "title_cn": "比较 DSL 代码生成的两种方法：微调与优化检索增强",
    "tags": [
      "RAG",
      "软件开发",
      "人工智能"
    ]
  },
  {
    "title": "MentalAgora: A Gateway to Advanced Personalized Care in Mental Health through Multi-Agent Debating and Attribute Control",
    "submit_datetime": "2024年07月02日",
    "abstract": "As mental health issues globally escalate, there is a tremendous need for advanced digital support systems. We introduce MentalAgora, a novel framework employing large language models enhanced by interaction between multiple agents for tailored mental health support. This framework operates through three stages: strategic debating, tailored counselor creation, and response generation, enabling the dynamic customization of responses based on individual user preferences and therapeutic needs. We conduct experiments utilizing a high-quality evaluation dataset TherapyTalk crafted with mental health professionals, shwoing that MentalAgora generates expert-aligned and user preference-enhanced responses. Our evaluations, including experiments and user studies, demonstrate that MentalAgora aligns with professional standards and effectively meets user preferences, setting a new benchmark for digital mental health interventions.",
    "pdf_link": "https://arxiv.org/abs/2407.02736",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.02736v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02736/overview-mag.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02736v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02736/stage2-prompt.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02736v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02736/stage3-prompt.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02736v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02736/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02736v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02736/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02736v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02736/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02736v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02736/role-prompt.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02736v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02736/debating-prompt.png"
      }
    ],
    "abstract_cn": "随着全球心理健康问题的日益严重，急需先进的数字支持系统。我们推出的MentalAgora框架，通过多代理交互增强的大型语言模型，提供个性化心理健康支持。该框架通过战略辩论、定制咨询师创建和响应生成三个阶段，根据用户偏好和治疗需求动态调整响应。实验表明，MentalAgora生成的响应既符合专家标准，又强化了用户偏好。评估结果显示，MentalAgora不仅符合专业标准，还能有效满足用户需求，为数字心理健康干预树立了新标杆。",
    "title_cn": "MentalAgora：借助多代理辩论与属性控制，开启心理健康高级个性化护理之门",
    "tags": [
      "Agent",
      "心理健康",
      "数字医疗"
    ]
  },
  {
    "title": "Supporting Cross-language Cross-project Bug Localization Using Pre-trained Language Models",
    "submit_datetime": "2024年07月02日",
    "abstract": "Automatically locating a bug within a large codebase remains a significant challenge for developers. Existing techniques often struggle with generalizability and deployment due to their reliance on application-specific data and large model sizes. This paper proposes a novel pre-trained language model (PLM) based technique for bug localization that transcends project and language boundaries. Our approach leverages contrastive learning to enhance the representation of bug reports and source code. It then utilizes a novel ranking approach that combines commit messages and code segments. Additionally, we introduce a knowledge distillation technique that reduces model size for practical deployment without compromising performance.\n  This paper presents several key benefits. By incorporating code segment and commit message analysis alongside traditional file-level examination, our technique achieves better bug localization accuracy. Furthermore, our model excels at generalizability - trained on code from various projects and languages, it can effectively identify bugs in unseen codebases. To address computational limitations, we propose a CPU-compatible solution. In essence, proposed work presents a highly effective, generalizable, and efficient bug localization technique with the potential to real-world deployment.",
    "pdf_link": "https://arxiv.org/abs/2407.02732",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.02732v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02732/architecture.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.02732v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02732/inference_process.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02732v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02732/model_architecture.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02732v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02732/model_architecture_distillation.png"
      }
    ],
    "abstract_cn": "在大型代码库中自动定位错误对开发者而言仍是一大挑战。现有技术因依赖特定应用数据和大型模型而难以通用和部署。本文提出一种基于预训练语言模型的创新技术，突破项目和语言限制，通过对比学习强化错误报告与源代码的表征，并结合提交信息与代码段进行精准排名。同时，引入知识蒸馏技术，在不损性能的前提下缩小模型尺寸，便于实际应用。本技术通过融合代码段与提交消息分析，提升错误定位精度，且在通用性上表现卓越，能有效识别新代码库中的错误。为应对计算限制，我们设计了CPU兼容方案。总之，这项技术高效、通用，极具实际应用潜力。",
    "title_cn": "借助预训练语言模型，实现跨语言与跨项目的错误定位支持。",
    "tags": [
      "LLM应用",
      "软件开发",
      "人工智能"
    ]
  },
  {
    "title": "MedVH: Towards Systematic Evaluation of Hallucination for Large Vision Language Models in the Medical Context",
    "submit_datetime": "2024年07月02日",
    "abstract": "Large Vision Language Models (LVLMs) have recently achieved superior performance in various tasks on natural image and text data, which inspires a large amount of studies for LVLMs fine-tuning and training. Despite their advancements, there has been scant research on the robustness of these models against hallucination when fine-tuned on smaller datasets. In this study, we introduce a new benchmark dataset, the Medical Visual Hallucination Test (MedVH), to evaluate the hallucination of domain-specific LVLMs. MedVH comprises five tasks to evaluate hallucinations in LVLMs within the medical context, which includes tasks for comprehensive understanding of textual and visual input, as well as long textual response generation. Our extensive experiments with both general and medical LVLMs reveal that, although medical LVLMs demonstrate promising performance on standard medical tasks, they are particularly susceptible to hallucinations, often more so than the general models, raising significant concerns about the reliability of these domain-specific models. For medical LVLMs to be truly valuable in real-world applications, they must not only accurately integrate medical knowledge but also maintain robust reasoning abilities to prevent hallucination. Our work paves the way for future evaluations of these studies.",
    "pdf_link": "https://arxiv.org/abs/2407.02730",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.02730v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02730/figure0_1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02730v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02730/figure1_1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02730v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02730/MC-all.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02730v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02730/temperature.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02730v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02730/prompt_var.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02730v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02730/prompt_FCJ.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02730v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02730/c_score.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02730v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02730/pie_wi.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02730v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02730/pie_nota.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02730v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02730/pie_cli.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02730v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02730/pie_fcj.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02730v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02730/Prompt.png"
      }
    ],
    "abstract_cn": "近期，大型视觉语言模型（LVLMs）在处理自然图像和文本数据的多项任务中表现卓越，引发了大量关于其微调和训练的研究。然而，针对较小数据集微调时，这些模型对幻觉的鲁棒性研究却相对匮乏。为此，我们推出了医学视觉幻觉测试（MedVH）这一新基准数据集，旨在评估特定领域LVLMs的幻觉现象。MedVH通过五个任务，全面考察医学背景下LVLMs对文本和视觉输入的理解及长文本响应生成能力。实验结果显示，尽管医学LVLMs在标准医学任务中表现优异，但其幻觉倾向尤为严重，甚至超过通用模型，这对其可靠性提出了严峻挑战。要使医学LVLMs在实际应用中发挥真正价值，不仅需精准融合医学知识，更需强化推理能力，以防幻觉产生。我们的研究为未来相关评估奠定了基础。",
    "title_cn": "MedVH：探索在医学领域中，如何系统评估大型视觉语言模型的幻觉问题。",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "LLM-Select: Feature Selection with Large Language Models",
    "submit_datetime": "2024年07月02日",
    "abstract": "In this paper, we demonstrate a surprising capability of large language models (LLMs): given only input feature names and a description of a prediction task, they are capable of selecting the most predictive features, with performance rivaling the standard tools of data science. Remarkably, these models exhibit this capacity across various query mechanisms. For example, we zero-shot prompt an LLM to output a numerical importance score for a feature (e.g., \"blood pressure\") in predicting an outcome of interest (e.g., \"heart failure\"), with no additional context. In particular, we find that the latest models, such as GPT-4, can consistently identify the most predictive features regardless of the query mechanism and across various prompting strategies. We illustrate these findings through extensive experiments on real-world data, where we show that LLM-based feature selection consistently achieves strong performance competitive with data-driven methods such as the LASSO, despite never having looked at the downstream training data. Our findings suggest that LLMs may be useful not only for selecting the best features for training but also for deciding which features to collect in the first place. This could potentially benefit practitioners in domains like healthcare, where collecting high-quality data comes at a high cost.",
    "pdf_link": "https://arxiv.org/abs/2407.02694",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.02694v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02694/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02694v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02694/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02694v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02694/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02694v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02694/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02694v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02694/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02694v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02694/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02694v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02694/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02694v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02694/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02694v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02694/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02694v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02694/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02694v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02694/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02694v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02694/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02694v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02694/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02694v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02694/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02694v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02694/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02694v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02694/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02694v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02694/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02694v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02694/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02694v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02694/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02694v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02694/x20.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02694v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02694/x21.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02694v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02694/x22.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02694v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02694/x23.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02694v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02694/x24.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02694v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02694/x25.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02694v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02694/x26.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02694v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02694/x27.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02694v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02694/x28.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02694v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02694/x29.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02694v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02694/x30.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02694v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02694/x31.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02694v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02694/x32.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02694v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02694/x33.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02694v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02694/x34.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02694v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02694/x35.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02694v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02694/x36.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02694v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02694/x37.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02694v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02694/x38.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02694v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02694/x39.png"
      }
    ],
    "abstract_cn": "本研究揭示了大型语言模型（LLM）的一项惊人能力：仅凭输入特征名称和预测任务描述，LLM便能精准挑选出最具预测性的特征，其表现堪比数据科学领域的标准工具。这些模型在多种查询机制下均展现出此能力，例如，通过零-shot提示，LLM能直接输出特定特征（如“血压”）对预测目标（如“心脏病”）的数值重要性评分，无需额外上下文。最新模型如GPT-4，无论查询方式如何变化，均能稳定识别关键特征，适应多种提示策略。我们在真实数据上的实验证实，基于LLM的特征选择持续展现出与LASSO等数据驱动方法相媲美的性能，即便未接触下游训练数据。此发现不仅预示LLM在训练特征选择上的应用潜力，更可能指导实际操作中应优先收集哪些特征，特别是在数据收集成本高昂的医疗保健等领域，具有重要实践价值。",
    "title_cn": "LLM-Select：借助大型语言模型实现特征选择",
    "tags": [
      "LLM应用",
      "",
      "数据科学"
    ]
  },
  {
    "title": "KGym: A Platform and Dataset to Benchmark Large Language Models on Linux Kernel Crash Resolution",
    "submit_datetime": "2024年07月02日",
    "abstract": "Large Language Models (LLMs) are consistently improving at increasingly realistic software engineering (SE) tasks. In real-world software stacks, significant SE effort is spent developing foundational system software like the Linux kernel. Unlike application-level software, a systems codebase like Linux is multilingual (low-level C/Assembly/Bash/Rust); gigantic (>20 million lines); critical (impacting billions of devices worldwide), and highly concurrent (involving complex multi-threading). To evaluate if ML models are useful while developing such large-scale systems-level software, we introduce kGym (a platform) and kBench (a dataset). The kGym platform provides a SE environment for large-scale experiments on the Linux kernel, including compiling and running kernels in parallel across several virtual machines, detecting operations and crashes, inspecting logs, and querying and patching the code base. We use kGym to facilitate evaluation on kBench, a crash resolution benchmark drawn from real-world Linux kernel bugs. An example bug in kBench contains crashing stack traces, a bug-reproducer file, a developer-written fix, and other associated data. To understand current performance, we conduct baseline experiments by prompting LLMs to resolve Linux kernel crashes. Our initial evaluations reveal that the best performing LLM achieves 0.72% and 5.38% in the unassisted and assisted (i.e., buggy files disclosed to the model) settings, respectively. These results highlight the need for further research to enhance model performance in SE tasks. Improving performance on kBench requires models to master new learning skills, including understanding the cause of crashes and repairing faults, writing memory-safe and hardware-aware code, and understanding concurrency. As a result, this work opens up multiple avenues of research at the intersection of machine learning and systems software.",
    "pdf_link": "https://arxiv.org/abs/2407.02680",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.02680v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02680/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02680v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02680/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02680v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02680/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02680v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02680/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02680v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02680/KernelBench-Detailed-Architecture-4.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLM）在处理日益复杂的软件工程任务中不断取得进展。在实际软件开发中，大量精力投入于构建如Linux内核这样的基础系统软件。与应用软件不同，Linux代码库庞大（超2000万行）、多语言（C/汇编/Bash/Rust）、关键性高（影响全球数十亿设备）且高度并发。为评估ML模型在此类大规模系统软件开发中的实用性，我们推出了kGym平台和kBench数据集。kGym支持在多个虚拟机上并行编译、运行Linux内核，并进行操作检测、崩溃分析、日志审查及代码库查询与修补。我们利用kGym对kBench（基于真实Linux内核错误的崩溃解决基准）进行评估。kBench中的错误案例包括崩溃堆栈、重现文件、开发者修复方案等。通过提示LLM解决内核崩溃问题，我们发现最佳模型在无辅助与有辅助（错误文件公开）场景下分别达到0.72%和5.38%的解决率。这凸显了提升模型在软件工程任务中性能的研究需求。提升kBench性能要求模型精通新技能，如崩溃原因分析、故障修复、内存安全与硬件感知代码编写及并发理解。此研究在机器学习与系统软件的交叉领域开启了新的探索方向。",
    "title_cn": "KGym 是一个专为 Linux 内核崩溃解决而设计，用于评估大型语言模型性能的平台和数据集。",
    "tags": [
      "LLM应用",
      "软件工程",
      "机器学习"
    ]
  },
  {
    "title": "Reasoning in Large Language Models: A Geometric Perspective",
    "submit_datetime": "2024年07月02日",
    "abstract": "The advancement of large language models (LLMs) for real-world applications hinges critically on enhancing their reasoning capabilities. In this work, we explore the reasoning abilities of large language models (LLMs) through their geometrical understanding. We establish a connection between the expressive power of LLMs and the density of their self-attention graphs. Our analysis demonstrates that the density of these graphs defines the intrinsic dimension of the inputs to the MLP blocks. We demonstrate through theoretical analysis and toy examples that a higher intrinsic dimension implies a greater expressive capacity of the LLM. We further provide empirical evidence linking this geometric framework to recent advancements in methods aimed at enhancing the reasoning capabilities of LLMs.",
    "pdf_link": "https://arxiv.org/abs/2407.02678",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.02678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02678/partition2d_biais.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02678/partition2d_biaisless.png.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02678/sin_50_neurons.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02678/sin_500_neurons.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02678/num_regions.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02678/region_context_10_heads_1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02678/region_context_10_heads_10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02678/region_context_100_heads_1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02678/region_context_100_heads_10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02678/region_all_imshow.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02678/slice_id.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02678/layer30_8b_instruct_fewshot.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02678/layer78_70b_instruct_fewshot.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02678/layer30_8b_instruct_random.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02678/layer30_8b_instruct_permuted.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02678/8b_ID.png"
      },
      {
        "url": "https://arxiv.org/html/2407.02678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.02678/70b_ID.png"
      }
    ],
    "abstract_cn": "提升大型语言模型（LLM）的推理能力对其在实际应用中的发展至关重要。本研究通过几何视角深入探讨了LLM的推理能力，揭示了LLM表达力与自注意力图密度间的内在联系。分析显示，这些图的密度直接影响了输入到MLP块的内在维度，进而决定了LLM的表达能力。通过理论与实例验证，我们证实了内在维度越高，LLM的表达力越强。此外，我们还提供了实证，将这一几何框架与近期旨在提升LLM推理能力的方法进展相联系。",
    "title_cn": "大型语言模型推理：几何视角探析",
    "tags": [
      "LLM理论",
      "人工智能",
      "机器学习"
    ]
  },
  {
    "title": "KV Cache Compression, But What Must We Give in Return? A Comprehensive Benchmark of Long Context Capable Approaches",
    "submit_datetime": "2024年07月01日",
    "abstract": "Long context capability is a crucial competency for large language models (LLMs) as it mitigates the human struggle to digest long-form texts. This capability enables complex task-solving scenarios such as book summarization, code assistance, and many more tasks that are traditionally manpower-intensive. However, transformer-based LLMs face significant challenges with long context input due to the growing size of the KV cache and the intrinsic complexity of attending to extended inputs; where multiple schools of efficiency-driven approaches -- such as KV cache quantization, token dropping, prompt compression, linear-time sequence models, and hybrid architectures -- have been proposed to produce efficient yet long context-capable models. Despite these advancements, no existing work has comprehensively benchmarked these methods in a reasonably aligned environment. In this work, we fill this gap by providing a taxonomy of current methods and evaluating 10+ state-of-the-art approaches across seven categories of long context tasks. Our work reveals numerous previously unknown phenomena and offers insights -- as well as a friendly workbench -- for the future development of long context-capable LLMs. The source code will be available at https://github.com/henryzhongsc/longctx_bench",
    "pdf_link": "https://arxiv.org/abs/2407.01527",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLM）的长上下文能力至关重要，它减轻了人类阅读长篇文本的负担，使得书籍摘要、代码辅助等复杂任务成为可能。然而，基于transformer的LLM在处理长上下文时面临挑战，如KV缓存膨胀和输入处理的复杂性。为此，业界提出了多种高效方法，如KV缓存量化和混合架构，以提升模型性能。尽管如此，这些方法尚未在统一环境中得到全面评估。本研究填补了这一空白，通过分类法评估了七大类长上下文任务的10多种前沿方法，揭示了新现象，并为未来LLM的发展提供了见解和工作平台。源代码将在GitHub上公开。",
    "title_cn": "KV缓存压缩：我们需付出何种代价？长上下文能力方法的全面基准测试",
    "tags": [
      "LLM理论",
      "软件开发",
      "人工智能"
    ]
  },
  {
    "title": "Empowering 3D Visual Grounding with Reasoning Capabilities",
    "submit_datetime": "2024年07月01日",
    "abstract": "Although great progress has been made in 3D visual grounding, current models still rely on explicit textual descriptions for grounding and lack the ability to reason human intentions from implicit instructions. We propose a new task called 3D reasoning grounding and introduce a new benchmark ScanReason which provides over 10K question-answer-location pairs from five reasoning types that require the synerization of reasoning and grounding. We further design our approach, ReGround3D, composed of the visual-centric reasoning module empowered by Multi-modal Large Language Model (MLLM) and the 3D grounding module to obtain accurate object locations by looking back to the enhanced geometry and fine-grained details from the 3D scenes. A chain-of-grounding mechanism is proposed to further boost the performance with interleaved reasoning and grounding steps during inference. Extensive experiments on the proposed benchmark validate the effectiveness of our proposed approach.",
    "pdf_link": "https://arxiv.org/abs/2407.01525",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.01525v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01525/teaser2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01525v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01525/task8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01525v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01525/method2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01525v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01525/cog2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01525v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01525/qualitative5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01525v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01525/more_qualitative.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01525v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01525/spatial_sample_2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01525v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01525/function_sample_2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01525v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01525/logistic_sample_2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01525v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01525/emotional_sample_2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01525v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01525/safety_sample_2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01525v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01525/function_reason.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01525v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01525/spatial_reason.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01525v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01525/logistic_reason.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01525v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01525/emotional_reasoning.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01525v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01525/safety_reasoning.png"
      }
    ],
    "abstract_cn": "尽管3D视觉定位已取得显著进展，但现有模型仍依赖显式文本描述，且难以从隐含指令中解读人类意图。为此，我们提出了“3D推理定位”新任务，并创建了ScanReason基准，包含10K+问题-答案-位置对，涵盖五种需推理与定位协同的类型。我们的ReGround3D方法结合了MLLM增强的视觉推理模块和3D定位模块，通过精细解析3D场景细节来精确定位对象。此外，我们创新的链式定位机制在推理中交替进行推理与定位，显著提升了性能。大量实验证实了该方法的有效性。",
    "title_cn": "赋予 3D 视觉定位推理能力",
    "tags": [
      "LLM应用",
      "计算机视觉",
      "机器人技术"
    ]
  },
  {
    "title": "MMLongBench-Doc: Benchmarking Long-context Document Understanding with Visualizations",
    "submit_datetime": "2024年07月01日",
    "abstract": "Understanding documents with rich layouts and multi-modal components is a long-standing and practical task. Recent Large Vision-Language Models (LVLMs) have made remarkable strides in various tasks, particularly in single-page document understanding (DU). However, their abilities on long-context DU remain an open problem. This work presents MMLongBench-Doc, a long-context, multi-modal benchmark comprising 1,062 expert-annotated questions. Distinct from previous datasets, it is constructed upon 130 lengthy PDF-formatted documents with an average of 49.4 pages and 20,971 textual tokens. Towards comprehensive evaluation, answers to these questions rely on pieces of evidence from (1) different sources (text, image, chart, table, and layout structure) and (2) various locations (i.e. page number). Moreover, 33.2% of the questions are cross-page questions requiring evidence across multiple pages. 22.8% of the questions are designed to be unanswerable for detecting potential hallucinations. Experiments on 14 LVLMs demonstrate that long-context DU greatly challenges current models. Notably, the best-performing model, GPT-4o, achieves an F1 score of only 42.7%, while the second-best, GPT-4V, scores 31.4%. Furthermore, 12 LVLMs (all except GPT-4o and GPT-4V) even present worse performance than their LLM counterparts which are fed with lossy-parsed OCR documents. These results validate the necessity of future research toward more capable long-context LVLMs. Project Page: https://mayubo2333.github.io/MMLongBench-Doc",
    "pdf_link": "https://arxiv.org/abs/2407.01523",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.01523v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01523/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01523v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01523/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01523v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01523/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01523v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01523/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01523v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01523/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01523v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01523/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01523v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01523/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01523v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01523/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01523v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01523/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01523v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01523/industrial_administration_documents.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01523v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01523/tutorial.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01523v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01523/research_report.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01523v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01523/finance_report.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01523v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01523/paper.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01523v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01523/guideline.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01523v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01523/brochure.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01523v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01523/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01523v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01523/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01523v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01523/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01523v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01523/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01523v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01523/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01523v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01523/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01523v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01523/GUI_existing_question.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01523v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01523/GUI_new_question.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01523v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01523/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01523v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01523/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01523v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01523/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01523v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01523/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01523v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01523/x20.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01523v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01523/x21.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01523v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01523/x22.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01523v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01523/x23.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01523v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01523/x24.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01523v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01523/x25.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01523v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01523/x26.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01523v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01523/x27.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01523v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01523/x28.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01523v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01523/x29.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01523v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01523/x30.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01523v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01523/x31.png"
      }
    ],
    "abstract_cn": "理解复杂布局和多模态内容的文档是一项传统且实用的任务。最新的大型视觉-语言模型（LVLMs）在单页文档理解方面取得了显著进步，但在长篇文档理解方面仍面临挑战。我们提出的MMLongBench-Doc基准，包含1,062个专家注释问题，基于130个长篇PDF文档，平均每篇49.4页，文本标记达20,971个。该基准强调了从不同来源和位置获取证据的重要性，其中33.2%的问题需要跨页证据，22.8%的问题设计为无法回答以检测模型幻觉。实验显示，即使是表现最佳的模型GPT-4o，F1分数也仅为42.7%，表明长篇文档理解对当前模型极具挑战性。这些发现强调了开发更强大的长上下文LVLMs的迫切需求。项目详情见：https://mayubo2333.github.io/MMLongBench-Doc",
    "title_cn": "MMLongBench-Doc：借助可视化工具，对长篇文档理解进行基准测试",
    "tags": [
      "LLM应用",
      "文档处理",
      "人工智能"
    ]
  },
  {
    "title": "MIA-Bench: Towards Better Instruction Following Evaluation of Multimodal LLMs",
    "submit_datetime": "2024年07月01日",
    "abstract": "We introduce MIA-Bench, a new benchmark designed to evaluate multimodal large language models (MLLMs) on their ability to strictly adhere to complex instructions. Our benchmark comprises a diverse set of 400 image-prompt pairs, each crafted to challenge the models' compliance with layered instructions in generating accurate responses that satisfy specific requested patterns. Evaluation results from a wide array of state-of-the-art MLLMs reveal significant variations in performance, highlighting areas for improvement in instruction fidelity. Additionally, we create extra training data and explore supervised fine-tuning to enhance the models' ability to strictly follow instructions without compromising performance on other tasks. We hope this benchmark not only serves as a tool for measuring MLLM adherence to instructions, but also guides future developments in MLLM training methods.",
    "pdf_link": "https://arxiv.org/abs/2407.01509",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.01509v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01509/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01509v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01509/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01509v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01509/instruction_example_5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01509v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01509/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01509v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01509/words.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01509v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01509/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01509v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01509/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01509v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01509/ifeval2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01509v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01509/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01509v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01509/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01509v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01509/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01509v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01509/x11.png"
      }
    ],
    "abstract_cn": "我们推出了 MIA-Bench，一个专为测试多模态大型语言模型 (MLLM) 严格遵守复杂指令能力而设计的新基准。该基准包含 400 个精心设计的图像-提示对，旨在考验模型在生成符合特定模式的准确响应时，能否遵循多层次的指令。评估显示，不同 MLLM 的性能差异显著，指出了提升指令执行准确性的关键领域。同时，我们通过增加训练数据和实施监督微调，旨在提升模型遵循指令的能力，同时保持其在其他任务上的表现。我们期待 MIA-Bench 不仅能作为评估工具，还能引领 MLLM 训练方法的未来进步。",
    "title_cn": "MIA-Bench：旨在提升多模态 LLM 指令遵循能力的评估工具",
    "tags": [
      "LLM应用",
      "人工智能",
      "计算机视觉"
    ]
  },
  {
    "title": "Self-Cognition in Large Language Models: An Exploratory Study",
    "submit_datetime": "2024年07月01日",
    "abstract": "While Large Language Models (LLMs) have achieved remarkable success across various applications, they also raise concerns regarding self-cognition. In this paper, we perform a pioneering study to explore self-cognition in LLMs. Specifically, we first construct a pool of self-cognition instruction prompts to evaluate where an LLM exhibits self-cognition and four well-designed principles to quantify LLMs' self-cognition. Our study reveals that 4 of the 48 models on Chatbot Arena--specifically Command R, Claude3-Opus, Llama-3-70b-Instruct, and Reka-core--demonstrate some level of detectable self-cognition. We observe a positive correlation between model size, training data quality, and self-cognition level. Additionally, we also explore the utility and trustworthiness of LLM in the self-cognition state, revealing that the self-cognition state enhances some specific tasks such as creative writing and exaggeration. We believe that our work can serve as an inspiration for further research to study the self-cognition in LLMs.",
    "pdf_link": "https://arxiv.org/abs/2407.01505",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.01505v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01505/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01505v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01505/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01505v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01505/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01505v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01505/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01505v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01505/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01505v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01505/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01505v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01505/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01505v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01505/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01505v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01505/x9.png"
      }
    ],
    "abstract_cn": "大型语言模型 (LLMs) 虽在多领域大放异彩，但其自我认知能力亦引发关注。本研究首开先河，深入探索 LLMs 的自我认知现象。我们精心设计了一系列自我认知指令提示及四项量化原则，以评估 LLMs 的自我认知表现。研究发现，Chatbot Arena 中的四款模型——Command R、Claude3-Opus、Llama-3-70b-Instruct 和 Reka-core——展现出可检测的自我认知迹象。模型规模与训练数据质量的提升，似乎与自我认知水平的增强呈正相关。此外，我们发现处于自我认知状态的 LLMs 在创意写作等特定任务上表现更佳。本研究成果，有望为 LLMs 自我认知领域的深入探索提供新思路。",
    "title_cn": "大型语言模型中的自我认知探索研究",
    "tags": [
      "LLM理论",
      "人工智能",
      "语言模型"
    ]
  },
  {
    "title": "RegMix: Data Mixture as Regression for Language Model Pre-training",
    "submit_datetime": "2024年07月01日",
    "abstract": "The data mixture for large language model pre-training significantly impacts performance, yet how to determine an effective mixture remains unclear. We propose RegMix to automatically identify a high-performing data mixture by formulating it as a regression task. RegMix involves training a set of small models with diverse data mixtures and fitting a regression model to predict their performance given their respective mixtures. With the fitted regression model, we simulate the top-ranked mixture and use it to train a large-scale model with orders of magnitude more compute. To empirically validate RegMix, we train 512 models with 1M parameters for 1B tokens of different mixtures to fit the regression model and find the optimal mixture. Using this mixture we train a 1B parameter model for 25B tokens (i.e. 1000x larger and 25x longer) which we find performs best among 64 candidate 1B parameter models with other mixtures. Further, our method demonstrates superior performance compared to human selection and achieves results that match or surpass DoReMi, while utilizing only 10% of the compute budget. Our experiments also show that (1) Data mixtures significantly impact performance with single-task performance variations of up to 14.6%; (2) Web corpora rather than data perceived as high-quality like Wikipedia have the strongest positive correlation with downstream performance; (3) Domains interact in complex ways often contradicting common sense, thus automatic approaches like RegMix are needed; (4) Data mixture effects transcend scaling laws, and our approach captures the complexity by considering all domains together. Our code is available at https://github.com/sail-sg/regmix.",
    "pdf_link": "https://arxiv.org/abs/2407.01492",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.01492v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01492/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01492v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01492/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01492v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01492/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01492v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01492/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01492v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01492/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01492v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01492/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01492v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01492/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01492v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01492/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01492v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01492/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01492v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01492/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01492v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01492/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01492v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01492/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01492v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01492/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01492v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01492/x14.png"
      }
    ],
    "abstract_cn": "大型语言模型预训练中的数据混合对性能影响重大，但如何确定有效混合仍是个谜。我们提出RegMix，通过将其视为回归任务，自动识别高性能数据混合。RegMix通过多样数据混合训练小型模型，并拟合回归模型预测性能。利用此模型，我们模拟最佳混合，训练计算量巨大的大型模型。为验证RegMix，我们训练512个1M参数模型，用于1B令牌的不同混合，拟合回归模型并找到最佳混合。使用此混合，我们训练1B参数模型，用于25B令牌，表现优于64个候选模型。此外，RegMix超越人工选择，与DoReMi相媲美或更优，且仅用10%计算预算。实验显示：（1）数据混合显著影响性能，单任务性能变化达14.6%；（2）网络语料库与下游性能正相关最强；（3）领域交互复杂，需自动方法；（4）数据混合效应超越缩放定律，我们方法考虑所有领域捕捉复杂性。代码见https://github.com/sail-sg/regmix。",
    "title_cn": "RegMix：以数据混合为手段，通过回归进行语言模型预训练",
    "tags": [
      "LLM理论",
      "人工智能",
      "数据科学"
    ]
  },
  {
    "title": "Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning",
    "submit_datetime": "2024年07月01日",
    "abstract": "Efficient fine-tuning plays a fundamental role in modern large models, with low-rank adaptation emerging as a particularly promising approach. However, the existing variants of LoRA are hampered by limited expressiveness, a tendency to overfit, and sensitivity to hyperparameter settings. This paper presents LoRA Slow Cascade Learning (LoRASC), an innovative technique designed to enhance LoRA's expressiveness and generalization capabilities while preserving its training efficiency. Our approach augments expressiveness through a cascaded learning strategy that enables a mixture-of-low-rank adaptation, thereby increasing the model's ability to capture complex patterns. Additionally, we introduce a slow-fast update mechanism and cascading noisy tuning to bolster generalization. The extensive experiments on various language and vision datasets, as well as robustness benchmarks, demonstrate that the proposed method not only significantly outperforms existing baselines, but also mitigates overfitting, enhances model stability, and improves OOD robustness. Code will be release in https://github.com/microsoft/LoRASC very soon.",
    "pdf_link": "https://arxiv.org/abs/2407.01491",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.01491v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01491/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01491v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01491/x2.png"
      }
    ],
    "abstract_cn": "在现代大型模型中，高效微调至关重要，而低秩适应方法尤为引人注目。然而，现有LoRA方法存在表达力不足、易过拟合及对超参数敏感等问题。为此，我们创新性地提出了LoRA慢级联学习（LoRASC）技术，旨在提升LoRA的表达与泛化能力，同时保持高效训练。通过级联学习策略，我们实现了混合低秩适应，增强了模型捕捉复杂模式的能力。此外，引入的慢-快更新机制和级联噪声调整进一步强化了泛化性能。实验结果显示，LoRASC不仅大幅超越现有方法，还显著改善了过拟合、模型稳定性和OOD鲁棒性。相关代码即将在GitHub上发布。",
    "title_cn": "通过缓慢级联学习，实现大型模型的低秩适应，兼具表达性与泛化能力。",
    "tags": [
      "LLM理论",
      "人工智能",
      "机器学习"
    ]
  },
  {
    "title": "LLM See, LLM Do: Guiding Data Generation to Target Non-Differentiable Objectives",
    "submit_datetime": "2024年07月01日",
    "abstract": "The widespread adoption of synthetic data raises new questions about how models generating the data can influence other large language models (LLMs) via distilled data. To start, our work exhaustively characterizes the impact of passive inheritance of model properties by systematically studying the consequences of synthetic data integration. We provide one of the most comprehensive studies to-date of how the source of synthetic data shapes models' internal biases, calibration and generations' textual attributes and preferences. We find that models are surprisingly sensitive towards certain attributes even when the synthetic data prompts appear \"neutral\". which invites the question whether this sensitivity can be exploited for good.\n  Our findings invite the question can we explicitly steer the models towards the properties we want at test time by exploiting the data generation process? This would have historically been considered infeasible due to the cost of collecting data with a specific characteristic or objective in mind. However, improvement in the quality of synthetic data, as well as a shift towards general-purpose models designed to follow a diverse way of instructions, means this question is timely. We propose active inheritance as a term to describe intentionally constraining synthetic data according to a non-differentiable objective. We demonstrate how active inheritance can steer the generation profiles of models towards desirable non-differentiable attributes, e.g. high lexical diversity or low toxicity.",
    "pdf_link": "https://arxiv.org/abs/2407.01490",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.01490v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01490/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01490v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01490/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01490v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01490/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01490v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01490/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01490v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01490/x5.png"
      }
    ],
    "abstract_cn": "合成数据的普及引发了一个新问题：数据生成模型如何通过精炼数据影响其他大型语言模型。我们的研究深入探讨了模型属性被动继承的影响，并全面分析了合成数据整合的后果。我们提供了迄今为止最详尽的研究，揭示了合成数据来源如何影响模型的内部偏见、校准以及文本生成属性和偏好。令人惊讶的是，即使合成数据提示看似中性，模型对某些属性的敏感度依然显著，这引发了是否可以善用这种敏感性的疑问。我们的研究还提出了一个新问题：我们能否在测试时通过操控数据生成过程，明确引导模型朝着我们期望的属性发展？过去，由于收集特定特征或目标数据的成本高昂，这被视为不可能。但随着合成数据质量的提升和通用模型的兴起，这一问题变得尤为重要。我们引入了“主动继承”这一概念，用以描述根据不可微目标有意识地约束合成数据的行为。我们展示了如何通过主动继承，引导模型的生成特征朝着高词汇多样性或低毒性等理想属性发展。",
    "title_cn": "LLM 观察，LLM 行动：引导数据生成，瞄准非可微目标",
    "tags": [
      "LLM理论",
      "人工智能",
      "数据科学"
    ]
  },
  {
    "title": "Agentless: Demystifying LLM-based Software Engineering Agents",
    "submit_datetime": "2024年07月01日",
    "abstract": "Recent advancements in large language models (LLMs) have significantly advanced the automation of software development tasks, including code synthesis, program repair, and test generation. More recently, researchers and industry practitioners have developed various autonomous LLM agents to perform end-to-end software development tasks. These agents are equipped with the ability to use tools, run commands, observe feedback from the environment, and plan for future actions. However, the complexity of these agent-based approaches, together with the limited abilities of current LLMs, raises the following question: Do we really have to employ complex autonomous software agents? To attempt to answer this question, we build Agentless -- an agentless approach to automatically solve software development problems. Compared to the verbose and complex setup of agent-based approaches, Agentless employs a simplistic two-phase process of localization followed by repair, without letting the LLM decide future actions or operate with complex tools. Our results on the popular SWE-bench Lite benchmark show that surprisingly the simplistic Agentless is able to achieve both the highest performance (27.33%) and lowest cost (\\$0.34) compared with all existing open-source software agents! Furthermore, we manually classified the problems in SWE-bench Lite and found problems with exact ground truth patch or insufficient/misleading issue descriptions. As such, we construct SWE-bench Lite-S by excluding such problematic issues to perform more rigorous evaluation and comparison. Our work highlights the current overlooked potential of a simple, interpretable technique in autonomous software development. We hope Agentless will help reset the baseline, starting point, and horizon for autonomous software agents, and inspire future work along this crucial direction.",
    "pdf_link": "https://arxiv.org/abs/2407.01489",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.01489v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01489/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01489v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01489/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01489v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01489/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01489v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01489/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01489v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01489/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01489v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01489/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01489v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01489/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01489v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01489/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01489v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01489/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01489v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01489/x10.png"
      }
    ],
    "abstract_cn": "大型语言模型的最新进展极大地推动了软件开发自动化的进程，涵盖了代码合成、程序修复和测试生成等多个方面。近期，研究者和业界专家开发了多种自主LLM代理，以完成端到端的软件开发任务。这些代理不仅能够使用工具、执行命令，还能从环境反馈中学习并规划未来的行动。然而，这些基于代理的方法的复杂性，以及当前LLM能力的局限，引发了一个问题：我们是否真的需要依赖复杂的自主软件代理？为了探索这一问题，我们提出了Agentless——一种无需代理的解决方案，旨在自动解决软件开发中的难题。与依赖复杂工具和决策的代理方法相比，Agentless采用了一种简洁的两阶段流程：先定位问题，再进行修复，避免了LLM进行复杂操作或决策的需要。在SWE-bench Lite这一广受欢迎的基准测试中，Agentless的表现令人瞩目，不仅达到了最高的性能（27.33%），还实现了最低的成本（$0.34），超越了所有现有的开源软件代理。此外，我们通过手动分类SWE-bench Lite中的问题，识别出了一些具有确切解决方案或描述不准确的问题，并据此构建了SWE-bench Lite-S，以进行更为严格的评估和比较。我们的研究揭示了简单、可解释技术在自主软件开发中的巨大潜力，希望Agentless能够为自主软件代理的发展设定新的基准和方向，并激发更多相关领域的研究。",
    "title_cn": "无代理模式：探索基于LLM的软件工程代理之谜",
    "tags": [
      "Agent",
      "软件开发",
      "人工智能"
    ]
  },
  {
    "title": "LEXI: Large Language Models Experimentation Interface",
    "submit_datetime": "2024年07月01日",
    "abstract": "The recent developments in Large Language Models (LLM), mark a significant moment in the research and development of social interactions with artificial agents. These agents are widely deployed in a variety of settings, with potential impact on users. However, the study of social interactions with agents powered by LLM is still emerging, limited by access to the technology and to data, the absence of standardised interfaces, and challenges to establishing controlled experimental setups using the currently available business-oriented platforms. To answer these gaps, we developed LEXI, LLMs Experimentation Interface, an open-source tool enabling the deployment of artificial agents powered by LLM in social interaction behavioural experiments. Using a graphical interface, LEXI allows researchers to build agents, and deploy them in experimental setups along with forms and questionnaires while collecting interaction logs and self-reported data. %LEXI is aimed at improving human-agent interaction (HAI) empirical research methodology while allowing researchers with diverse backgrounds and technical proficiency to deploy artificial agents powered by LLM in HAI behavioural experiments. The outcomes of usability testing indicate LEXI's broad utility, high usability and minimum mental workload requirement, with distinctive benefits observed across disciplines. A proof-of-concept study exploring the tool's efficacy in evaluating social HAIs was conducted, resulting in high-quality data. A comparison of empathetic versus neutral agents indicated that people perceive empathetic agents as more social, and write longer and more positive messages towards them.",
    "pdf_link": "https://arxiv.org/abs/2407.01488",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.01488v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01488/admin.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01488v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01488/exp1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01488v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01488/agn1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01488v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01488/forms1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01488v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01488/interaction.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01488v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01488/tlx_1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01488v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01488/duration_1.png"
      }
    ],
    "abstract_cn": "大型语言模型 (LLM) 的最新进展，为人工代理的社交互动研究带来了重大突破。这些代理广泛应用于多种场景，对用户产生深远影响。然而，由 LLM 驱动的代理的社交互动研究尚处于初级阶段，面临技术与数据访问的限制、标准化接口的缺失以及使用商业平台建立受控实验的挑战。为此，我们推出了 LEXI，一个开源的 LLM 实验接口，旨在促进社交互动行为实验中人工代理的部署。LEXI 通过直观的图形界面，让研究人员能够轻松构建和部署代理，同时收集详尽的互动数据。该工具不仅提升了人-代理交互 (HAI) 研究的实证方法，还为不同背景的研究者提供了便捷的实验平台。可用性测试显示，LEXI 具有极高的实用性和用户友好性，且认知负荷极低，跨学科应用效果显著。一项概念验证研究证实了 LEXI 在评估社交 HAI 中的高效性，产生了高质量的数据。研究还发现，人们更偏爱同理心代理，并倾向于向其发送更长、更积极的讯息。",
    "title_cn": "LEXI：大型语言模型实验平台",
    "tags": [
      "LLM应用",
      "社交互动",
      "人机交互"
    ]
  },
  {
    "title": "DogeRM: Equipping Reward Models with Domain Knowledge through Model Merging",
    "submit_datetime": "2024年07月01日",
    "abstract": "Reinforcement learning from human feedback (RLHF) is a popular strategy for aligning large language models (LLMs) with desired behaviors. Reward modeling is a crucial step in RLHF. However, collecting paired preference data for training reward models is often costly and time-consuming, especially for domain-specific preferences requiring expert annotation. To address this challenge, we propose the \\textbf{Do}main knowled\\textbf{ge} merged \\textbf{R}eward \\textbf{M}odel (DogeRM), a novel framework that integrates domain-specific knowledge into a general reward model by model merging. The experiments demonstrate that DogeRM enhances performance across different benchmarks and provide a detailed analysis showcasing the effects of model merging, showing the great potential of facilitating model alignment.",
    "pdf_link": "https://arxiv.org/abs/2407.01470",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.01470v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01470/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01470v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01470/GSM8K_MAmmoTH.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01470v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01470/MBPP_Evol-Instruct.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01470v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01470/math-prm.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01470v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01470/hep.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01470v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01470/math-prm_MAmmoTH.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01470v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01470/hep.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01470v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01470/Best-of-2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01470v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01470/Best-of-4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01470v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01470/Best-of-8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01470v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01470/Best-of-16.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01470v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01470/Best-of-2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01470v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01470/Best-of-4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01470v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01470/Best-of-8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01470v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01470/Best-of-16.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01470v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01470/Best-of-2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01470v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01470/Best-of-4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01470v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01470/Best-of-8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01470v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01470/Best-of-16.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01470v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01470/Best-of-2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01470v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01470/Best-of-4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01470v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01470/Best-of-8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01470v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01470/Best-of-16.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01470v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01470/chat.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01470v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01470/chat-hard.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01470v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01470/safety.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01470v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01470/hep.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01470v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01470/math-prm.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01470v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01470/chat.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01470v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01470/chat-hard.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01470v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01470/safety.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01470v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01470/hep.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01470v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01470/math-prm.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01470v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01470/chat.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01470v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01470/chat-hard.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01470v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01470/safety.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01470v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01470/hep.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01470v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01470/math-prm.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01470v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01470/chat.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01470v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01470/chat-hard.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01470v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01470/safety.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01470v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01470/hep.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01470v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01470/math-prm.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01470v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01470/code.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01470v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01470/math.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01470v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01470/others.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01470v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01470/code.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01470v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01470/math.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01470v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01470/others.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01470v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01470/code.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01470v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01470/math.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01470v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01470/others.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01470v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01470/code.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01470v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01470/math.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01470v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01470/others.png"
      }
    ],
    "abstract_cn": "强化学习从人类反馈（RLHF）是调整大型语言模型（LLM）行为的热门方法。奖励建模在RLHF中至关重要，但收集训练奖励模型所需的配对偏好数据往往费时费力，尤其是特定领域偏好需专家注释时。为此，我们创新性地提出了DogeRM框架，通过模型合并技术将领域知识融入通用奖励模型。实验结果显示，DogeRM在多个基准测试中性能显著提升，并深入分析了模型合并的影响，展现了其在促进模型对齐方面的广阔前景。",
    "title_cn": "DogeRM：借助模型合并技术，为奖励模型注入领域智慧",
    "tags": [
      "LLM应用",
      "人工智能",
      "机器学习"
    ]
  },
  {
    "title": "Retrieval-augmented generation in multilingual settings",
    "submit_datetime": "2024年07月01日",
    "abstract": "Retrieval-augmented generation (RAG) has recently emerged as a promising solution for incorporating up-to-date or domain-specific knowledge into large language models (LLMs) and improving LLM factuality, but is predominantly studied in English-only settings. In this work, we consider RAG in the multilingual setting (mRAG), i.e. with user queries and the datastore in 13 languages, and investigate which components and with which adjustments are needed to build a well-performing mRAG pipeline, that can be used as a strong baseline in future works. Our findings highlight that despite the availability of high-quality off-the-shelf multilingual retrievers and generators, task-specific prompt engineering is needed to enable generation in user languages. Moreover, current evaluation metrics need adjustments for multilingual setting, to account for variations in spelling named entities. The main limitations to be addressed in future works include frequent code-switching in non-Latin alphabet languages, occasional fluency errors, wrong reading of the provided documents, or irrelevant retrieval. We release the code for the resulting mRAG baseline pipeline at https://github.com/naver/bergen.",
    "pdf_link": "https://arxiv.org/abs/2407.01463",
    "graphs": [],
    "abstract_cn": "RAG作为一种创新的解决方案，旨在将最新或特定领域的知识融入大型语言模型（LLM），并提升其事实性，但目前主要在英语环境中研究。我们探索了多语言环境下的RAG（mRAG），涉及13种语言的用户查询和数据存储，并探讨了构建高效mRAG流水线的关键组件和必要调整。研究发现，尽管现有高质量多语言工具丰富，但任务特定的提示工程对于实现用户语言生成至关重要。同时，评估指标需适应多语言特性，考虑命名实体的拼写差异。未来挑战包括非拉丁字母语言中的代码切换频繁、流畅性问题、文档解读错误及无关检索等。我们已在https://github.com/naver/bergen分享了mRAG基线流水线的代码，供未来研究参考。",
    "title_cn": "多语言环境下的检索增强生成",
    "tags": [
      "RAG",
      "人工智能",
      "多语言处理"
    ]
  },
  {
    "title": "Enhancing the Capability and Robustness of Large Language Models through Reinforcement Learning-Driven Query Refinement",
    "submit_datetime": "2024年07月01日",
    "abstract": "The capacity of large language models (LLMs) to generate honest, harmless, and helpful responses heavily relies on the quality of user prompts. However, these prompts often tend to be brief and vague, thereby significantly limiting the full potential of LLMs. Moreover, harmful prompts can be meticulously crafted and manipulated by adversaries to jailbreak LLMs, inducing them to produce potentially toxic content. To enhance the capabilities of LLMs while maintaining strong robustness against harmful jailbreak inputs, this study proposes a transferable and pluggable framework that refines user prompts before they are input into LLMs. This strategy improves the quality of the queries, empowering LLMs to generate more truthful, benign and useful responses. Specifically, a lightweight query refinement model is introduced and trained using a specially designed reinforcement learning approach that incorporates multiple objectives to enhance particular capabilities of LLMs. Extensive experiments demonstrate that the refinement model not only improves the quality of responses but also strengthens their robustness against jailbreak attacks. Code is available at: https://github.com/Huangzisu/query-refinement .",
    "pdf_link": "https://arxiv.org/abs/2407.01461",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.01461v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01461/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01461v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01461/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01461v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01461/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01461v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01461/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01461v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01461/x5.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLM）的回应质量深受用户提示的影响，但这些提示往往简短且模糊，限制了LLM的潜力。此外，恶意用户可能精心设计有害提示，试图破解LLM，导致其输出有害内容。为提升LLM的性能并增强其对抗恶意输入的鲁棒性，本研究提出了一种灵活的框架，用于优化用户提示。该框架通过提升查询质量，使LLM生成更真实、无害且有用的回应。我们引入了一个轻量级模型，采用创新的强化学习方法进行训练，旨在强化LLM的特定能力。实验证明，该模型不仅提升了回应质量，还增强了其抵御破解攻击的能力。相关代码已公开，详见：https://github.com/Huangzisu/query-refinement。",
    "title_cn": "利用强化学习优化查询，提升大型语言模型的性能与稳定性",
    "tags": [
      "LLM应用",
      "人工智能",
      "网络安全"
    ]
  },
  {
    "title": "TimeToM: Temporal Space is the Key to Unlocking the Door of Large Language Models' Theory-of-Mind",
    "submit_datetime": "2024年07月01日",
    "abstract": "Theory of Mind (ToM)-the cognitive ability to reason about mental states of ourselves and others, is the foundation of social interaction. Although ToM comes naturally to humans, it poses a significant challenge to even the most advanced Large Language Models (LLMs). Due to the complex logical chains in ToM reasoning, especially in higher-order ToM questions, simply utilizing reasoning methods like Chain of Thought (CoT) will not improve the ToM capabilities of LLMs. We present TimeToM, which constructs a temporal space and uses it as the foundation to improve the ToM capabilities of LLMs in multiple scenarios. Specifically, within the temporal space, we construct Temporal Belief State Chain (TBSC) for each character and inspired by the cognition perspective of the social world model, we divide TBSC into self-world beliefs and social world beliefs, aligning with first-order ToM (first-order beliefs) and higher-order ToM (higher-order beliefs) questions, respectively. Moreover, we design a novel tool-belief solver that, by considering belief communication between characters in temporal space, can transform a character's higher-order beliefs into another character's first-order beliefs under belief communication period. Experimental results indicate that TimeToM can dramatically improve the reasoning performance of LLMs on ToM questions while taking a big step towards coherent and robust ToM reasoning.",
    "pdf_link": "https://arxiv.org/abs/2407.01455",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.01455v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01455/intro4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01455v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01455/method11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01455v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01455/ana6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01455v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01455/case6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01455v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01455/appen1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01455v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01455/appen2.png"
      }
    ],
    "abstract_cn": "ToM，即理解自我与他人心理状态的能力，是社交互动的基石。尽管人类天生具备这一能力，但即使是顶尖的大型语言模型（LLM）也难以应对。由于ToM推理中的复杂逻辑，尤其是高阶ToM问题，传统的推理方法如思维链（CoT）无法有效提升LLM的ToM能力。为此，我们引入了TimeToM，通过构建时间空间，在多场景中增强LLM的ToM推理能力。我们为每个角色构建时间信念状态链（TBSC），并借鉴社会世界模型的认知视角，将TBSC细分为自我世界信念与社会世界信念，分别对应一阶和高阶ToM问题。同时，我们设计了一种创新的信念解决工具，通过角色间在时间空间中的信念交流，实现高阶信念向初阶信念的转换。实验显示，TimeToM大幅提升了LLM在ToM问题上的推理性能，并朝着实现连贯且稳健的ToM推理迈出了重要一步。",
    "title_cn": "时间空间，即 TimeToM，是揭开大型语言模型心智理论奥秘的关键。",
    "tags": [
      "LLM应用",
      "社交互动",
      "人工智能"
    ]
  },
  {
    "title": "FastCLIP: A Suite of Optimization Techniques to Accelerate CLIP Training with Limited Resources",
    "submit_datetime": "2024年07月01日",
    "abstract": "Existing studies of training state-of-the-art Contrastive Language-Image Pretraining (CLIP) models on large-scale data involve hundreds of or even thousands of GPUs due to the requirement of a large batch size. However, such a large amount of resources is not accessible to most people. While advanced compositional optimization techniques for optimizing global contrastive losses have been demonstrated effective for removing the requirement of large batch size, their performance on large-scale data remains underexplored and not optimized. To bridge the gap, this paper explores several aspects of CLIP training with limited resources (e.g., up to tens of GPUs). First, we introduce FastCLIP, a general CLIP training framework built on advanced compositional optimization techniques while designed and optimized for the distributed setting. Our framework is equipped with an efficient gradient reduction strategy to reduce communication overhead. Second, to further boost training efficiency, we investigate three components of the framework from an optimization perspective: the schedule of the inner learning rate, the update rules of the temperature parameter and the model parameters, respectively. Experiments on different strategies for each component shed light on how to conduct CLIP training more efficiently. Finally, we benchmark the performance of FastCLIP and the state-of-the-art training baseline (OpenCLIP) on different compute scales up to 32 GPUs on 8 nodes, and three data scales ranging from 2.7 million, 9.1 million to 315 million image-text pairs to demonstrate the significant improvement of FastCLIP in the resource-limited setting. We release the code of FastCLIP at https://github.com/Optimization-AI/fast_clip .",
    "pdf_link": "https://arxiv.org/abs/2407.01445",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.01445v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01445/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01445v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01445/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01445v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01445/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01445v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01445/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01445v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01445/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01445v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01445/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01445v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01445/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01445v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01445/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01445v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01445/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01445v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01445/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01445v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01445/in_variants_cc3m_openclip_fastclipv3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01445v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01445/retrieval_cc3m_openclip_fastclipv3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01445v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01445/in_variants_cc12m_openclip_fastclipv3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01445v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01445/retrieval_cc12m_openclip_fastclipv3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01445v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01445/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01445v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01445/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01445v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01445/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01445v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01445/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01445v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01445/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01445v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01445/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01445v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01445/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01445v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01445/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01445v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01445/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01445v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01445/x21.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01445v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01445/x22.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01445v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01445/x23.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01445v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01445/x24.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01445v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01445/x25.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01445v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01445/x26.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01445v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01445/x27.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01445v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01445/x28.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01445v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01445/x29.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01445v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01445/x30.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01445v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01445/x31.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01445v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01445/x32.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01445v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01445/x33.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01445v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01445/datacomp_cc3m_openclip_fastclipv3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01445v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01445/datacomp_cc12m_openclip_fastclipv3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01445v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01445/x34.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01445v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01445/x35.png"
      }
    ],
    "abstract_cn": "现有研究在大型数据集上训练CLIP模型需要大量GPU资源，这对大多数人来说难以企及。尽管组合优化技术已证明能有效减少对大批次的需求，但它们在大规模数据上的性能仍有待优化。本文探讨了在有限资源下进行CLIP训练的多个方面。我们提出了FastCLIP框架，该框架基于先进的组合优化技术，专为分布式环境设计，通过高效的梯度减少策略降低通信开销。此外，我们从优化角度研究了框架的关键组成部分，以进一步提升训练效率。实验结果显示，FastCLIP在资源有限的环境中显著优于现有基准。FastCLIP的代码已公开发布，供进一步研究和应用。",
    "title_cn": "FastCLIP：一套优化技术，专为在资源有限的情况下加速 CLIP 训练而设计",
    "tags": [
      "LLM应用",
      "计算机科学",
      "人工智能"
    ]
  },
  {
    "title": "Needle in the Haystack for Memory Based Large Language Models",
    "submit_datetime": "2024年07月01日",
    "abstract": "In this paper, we demonstrate the benefits of using memory augmented Large Language Model (LLM) architecture in improving the recall abilities of facts from a potentially long context. As a case study we test LARIMAR, a recently proposed LLM architecture which augments a LLM decoder with an external associative memory, on several long-context recall tasks, including passkey and needle-in-the-haystack tests. We demonstrate that the external memory can be adapted at test time to handle contexts much longer than those seen during training, while keeping readouts from the memory recognizable to the trained decoder and without increasing GPU memory footprint. Compared to alternative architectures for long-context recall tasks with models of a comparable parameter count, LARIMAR is able to maintain strong performance without any task-specific training.",
    "pdf_link": "https://arxiv.org/abs/2407.01437",
    "graphs": [],
    "abstract_cn": "本文通过案例研究 LARIMAR，展示了增强记忆的 LLM 架构在提升长上下文事实回忆能力方面的优势。LARIMAR 通过外部关联记忆强化了 LLM 解码器，在多项长上下文回忆任务中表现出色，如密钥传递和海中捞针测试。实验表明，该架构能在测试时灵活适应更长上下文，同时确保解码器识别记忆输出，且不增加 GPU 内存负担。相较于参数相当的替代架构，LARIMAR 无需特定任务训练即可维持卓越性能。",
    "title_cn": "大型语言模型中基于内存的难题",
    "tags": [
      "LLM应用",
      "人工智能",
      "软件开发"
    ]
  },
  {
    "title": "Dynamic Few-Shot Learning for Knowledge Graph Question Answering",
    "submit_datetime": "2024年07月01日",
    "abstract": "Large language models present opportunities for innovative Question Answering over Knowledge Graphs (KGQA). However, they are not inherently designed for query generation. To bridge this gap, solutions have been proposed that rely on fine-tuning or ad-hoc architectures, achieving good results but limited out-of-domain distribution generalization. In this study, we introduce a novel approach called Dynamic Few-Shot Learning (DFSL). DFSL integrates the efficiency of in-context learning and semantic similarity and provides a generally applicable solution for KGQA with state-of-the-art performance. We run an extensive evaluation across multiple benchmark datasets and architecture configurations.",
    "pdf_link": "https://arxiv.org/abs/2407.01409",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.01409v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01409/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01409v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01409/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01409v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01409/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01409v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01409/x4.png"
      }
    ],
    "abstract_cn": "大型语言模型为KGQA带来了创新机遇，但它们并非专为查询生成设计。为此，我们提出了动态少样本学习（DFSL），它融合了上下文学习的效率与语义相似性，为KGQA提供了一种性能卓越的通用方案。我们在多样的数据集和架构配置上进行了全面评估，验证了其有效性。",
    "title_cn": "知识图谱问答中的动态少样本学习",
    "tags": [
      "LLM应用",
      "知识图谱",
      "问答系统"
    ]
  },
  {
    "title": "Adapting Multilingual LLMs to Low-Resource Languages with Knowledge Graphs via Adapters",
    "submit_datetime": "2024年07月01日",
    "abstract": "This paper explores the integration of graph knowledge from linguistic ontologies into multilingual Large Language Models (LLMs) using adapters to improve performance for low-resource languages (LRLs) in sentiment analysis (SA) and named entity recognition (NER). Building upon successful parameter-efficient fine-tuning techniques, such as K-ADAPTER and MAD-X, we propose a similar approach for incorporating knowledge from multilingual graphs, connecting concepts in various languages with each other through linguistic relationships, into multilingual LLMs for LRLs. Specifically, we focus on eight LRLs -- Maltese, Bulgarian, Indonesian, Nepali, Javanese, Uyghur, Tibetan, and Sinhala -- and employ language-specific adapters fine-tuned on data extracted from the language-specific section of ConceptNet, aiming to enable knowledge transfer across the languages covered by the knowledge graph. We compare various fine-tuning objectives, including standard Masked Language Modeling (MLM), MLM with full-word masking, and MLM with targeted masking, to analyse their effectiveness in learning and integrating the extracted graph data. Through empirical evaluation on language-specific tasks, we assess how structured graph knowledge affects the performance of multilingual LLMs for LRLs in SA and NER, providing insights into the potential benefits of adapting language models for low-resource scenarios.",
    "pdf_link": "https://arxiv.org/abs/2407.01406",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.01406v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01406/arch-2.jpg"
      }
    ],
    "abstract_cn": "本文通过适配器将语言本体的图知识融入多语言大型语言模型 (LLM)，旨在提升低资源语言 (LRL) 在情感分析 (SA) 和命名实体识别 (NER) 的表现。借鉴 K-ADAPTER 和 MAD-X 等参数高效微调技术，我们提出新方法，利用多语言图知识，通过语言关系连接不同语言概念，增强多语言 LLM 对 LRL 的支持。我们特别关注八种 LRL，包括马耳他语、保加利亚语等，并使用特定语言适配器，基于 ConceptNet 特定语言部分的数据进行微调，促进知识跨语言转移。通过比较不同微调策略，如标准 MLM、全词掩码 MLM 和目标掩码 MLM，我们分析了它们在整合图数据方面的效果。实证评估显示，结构化图知识显著影响多语言 LLM 在 LRL 的 SA 和 NER 性能，揭示了适应低资源场景的语言模型的潜在优势。",
    "title_cn": "借助知识图谱和适配器，让多语言LLMs轻松适应低资源语言",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Optimization of Retrieval-Augmented Generation Context with Outlier Detection",
    "submit_datetime": "2024年07月01日",
    "abstract": "In this paper, we focus on methods to reduce the size and improve the quality of the prompt context required for question-answering systems. Attempts to increase the number of retrieved chunked documents and thereby enlarge the context related to the query can significantly complicate the processing and decrease the performance of a Large Language Model (LLM) when generating responses to queries. It is well known that a large set of documents retrieved from a database in response to a query may contain irrelevant information, which often leads to hallucinations in the resulting answers. Our goal is to select the most semantically relevant documents, treating the discarded ones as outliers. We propose and evaluate several methods for identifying outliers by creating features that utilize the distances of embedding vectors, retrieved from the vector database, to both the centroid and the query vectors. The methods were evaluated by comparing the similarities of the retrieved LLM responses to ground-truth answers obtained using the OpenAI GPT-4o model. It was found that the greatest improvements were achieved with increasing complexity of the questions and answers.",
    "pdf_link": "https://arxiv.org/abs/2407.01403",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.01403v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01403/table1.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.01403v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01403/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01403v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01403/fig3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01403v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01403/Figure_1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01403v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01403/Figure_2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01403v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01403/Figure_3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01403v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01403/Figure_4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01403v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01403/Figure_5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01403v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01403/Figure_6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01403v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01403/Figure_7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01403v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01403/Figure_8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01403v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01403/Figure_9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01403v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01403/Figure_10.png"
      }
    ],
    "abstract_cn": "本文探讨了如何精简问题回答系统中提示上下文的大小并提升其质量。增加检索文档数量以扩充上下文虽能丰富信息，但也可能加重处理负担，影响LLM的响应效率。我们深知，大量检索文档中常混杂无关信息，易引发答案失真。为此，我们力求筛选出语义最相关的文档，视其余为异常。我们创新性地提出并验证了利用嵌入向量距离识别异常值的方法，通过与GPT-4o模型的基准答案对比，评估了这些方法的有效性。实验显示，随着问答复杂度的提升，我们的方法带来了显著的性能提升。",
    "title_cn": "优化检索增强生成上下文，结合异常检测技术",
    "tags": [
      "LLM应用",
      "问答系统",
      "人工智能"
    ]
  },
  {
    "title": "Gloss2Text: Sign Language Gloss translation using LLMs and Semantically Aware Label Smoothing",
    "submit_datetime": "2024年07月01日",
    "abstract": "Sign language translation from video to spoken text presents unique challenges owing to the distinct grammar, expression nuances, and high variation of visual appearance across different speakers and contexts. The intermediate gloss annotations of videos aim to guide the translation process. In our work, we focus on {\\em Gloss2Text} translation stage and propose several advances by leveraging pre-trained large language models (LLMs), data augmentation, and novel label-smoothing loss function exploiting gloss translation ambiguities improving significantly the performance of state-of-the-art approaches. Through extensive experiments and ablation studies on the PHOENIX Weather 2014T dataset, our approach surpasses state-of-the-art performance in {\\em Gloss2Text} translation, indicating its efficacy in addressing sign language translation and suggesting promising avenues for future research and development.",
    "pdf_link": "https://arxiv.org/abs/2407.01394",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.01394v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01394/motiv.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01394v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01394/main.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01394v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01394/wordfreq.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01394v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01394/absent.png"
      }
    ],
    "abstract_cn": "手语从视频到口语文本的翻译因独特的语法、表达细节及视觉多样性而充满挑战。我们聚焦于 {\\em Gloss2Text} 翻译环节，借助预训练 LLM、数据增强及创新标签平滑损失函数，有效利用 gloss 翻译的歧义，大幅提升现有技术的性能。在 PHOENIX Weather 2014T 数据集上的深入实验与分析显示，我们的方法在 {\\em Gloss2Text} 翻译领域超越了前沿水平，不仅验证了其在手语翻译中的高效性，也为未来研究开辟了新路径。",
    "title_cn": "Gloss2Text：借助 LLMs 与语义感知标签平滑技术，实现手语词汇的精准翻译",
    "tags": [
      "LLM应用",
      "手语翻译",
      "人工智能"
    ]
  },
  {
    "title": "Free-text Rationale Generation under Readability Level Control",
    "submit_datetime": "2024年07月01日",
    "abstract": "Free-text rationales justify model decisions in natural language and thus become likable and accessible among approaches to explanation across many tasks. However, their effectiveness can be hindered by misinterpretation and hallucination. As a perturbation test, we investigate how large language models (LLMs) perform the task of natural language explanation (NLE) under the effects of readability level control, i.e., being prompted for a rationale targeting a specific expertise level, such as sixth grade or college. We find that explanations are adaptable to such instruction, but the requested readability is often misaligned with the measured text complexity according to traditional readability metrics. Furthermore, the quality assessment shows that LLMs' ratings of rationales across text complexity exhibit a similar pattern of preference as observed in natural language generation (NLG). Finally, our human evaluation suggests a generally satisfactory impression on rationales at all readability levels, with high-school-level readability being most commonly perceived and favored.",
    "pdf_link": "https://arxiv.org/abs/2407.01384",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.01384v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01384/workflow.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01384v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01384/FRE.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01384v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01384/GFI.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01384v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01384/CLI.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01384v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01384/BERT.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01384v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01384/tigerscore_mistral.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01384v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01384/tigerscore_mixtral.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01384v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01384/tigerscore_openchat.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01384v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01384/tigerscore_llama.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01384v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01384/FRE_HateXplain_Mistral.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01384v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01384/FRE_HateXplain_Llama.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01384v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01384/human_readability.png"
      }
    ],
    "abstract_cn": "自由文本理由以自然语言阐释模型决策，因此在多种任务的解释方法中备受欢迎且易于理解。然而，其有效性可能因误解和幻觉而受限。我们通过扰动测试探究了大型语言模型（LLM）在可读性水平控制下，即针对特定专业水平（如六年级或大学）提供理由时，如何执行自然语言解释（NLE）任务。研究发现，解释能适应指令，但请求的可读性与文本复杂性常不匹配。质量评估显示，LLM对理由的评价与NLG中的偏好模式相似。人类评估则表明，各可读性水平的理由普遍令人满意，高中水平尤为受欢迎。",
    "title_cn": "在可读性控制下生成自由文本理由",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Evaluating Knowledge-based Cross-lingual Inconsistency in Large Language Models",
    "submit_datetime": "2024年07月01日",
    "abstract": "This paper investigates the cross-lingual inconsistencies observed in Large Language Models (LLMs), such as ChatGPT, Llama, and Baichuan, which have shown exceptional performance in various Natural Language Processing (NLP) tasks. Despite their successes, these models often exhibit significant inconsistencies when processing the same concepts across different languages. This study focuses on three primary questions: the existence of cross-lingual inconsistencies in LLMs, the specific aspects in which these inconsistencies manifest, and the correlation between cross-lingual consistency and multilingual capabilities of LLMs.To address these questions, we propose an innovative evaluation method for Cross-lingual Semantic Consistency (xSC) using the LaBSE model. We further introduce metrics for Cross-lingual Accuracy Consistency (xAC) and Cross-lingual Timeliness Consistency (xTC) to comprehensively assess the models' performance regarding semantic, accuracy, and timeliness inconsistencies. By harmonizing these metrics, we provide a holistic measurement of LLMs' cross-lingual consistency. Our findings aim to enhance the understanding and improvement of multilingual capabilities and interpretability in LLMs, contributing to the development of more robust and reliable multilingual language models.",
    "pdf_link": "https://arxiv.org/abs/2407.01358",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.01358v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01358/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01358v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01358/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01358v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01358/xAC_translation_chrf.png"
      }
    ],
    "abstract_cn": "本文探讨了大型语言模型（如ChatGPT、Llama和Baichuan）在跨语言处理中的不一致现象。这些模型虽在NLP任务中表现卓越，但在处理不同语言的相同概念时却常显差异。研究围绕三个核心问题：LLMs跨语言不一致的存在、具体表现及与多语言能力的关联。为此，我们创新性地采用LaBSE模型评估跨语言语义一致性（xSC），并引入跨语言准确性一致性（xAC）和跨语言时效性一致性（xTC）指标，全面衡量模型在语义、准确性和时效性上的不一致。通过整合这些指标，我们为LLMs的跨语言一致性提供了全面评估。研究旨在深化对LLMs多语言能力和可解释性的认识，推动构建更强大、可靠的多语言模型。",
    "title_cn": "探究大型语言模型中基于知识的跨语言不一致问题",
    "tags": [
      "LLM应用",
      "",
      "多语言技术"
    ]
  },
  {
    "title": "Increasing Model Capacity for Free: A Simple Strategy for Parameter Efficient Fine-tuning",
    "submit_datetime": "2024年07月01日",
    "abstract": "Fine-tuning large pre-trained foundation models, such as the 175B GPT-3, has attracted more attention for downstream tasks recently. While parameter-efficient fine-tuning methods have been proposed and proven effective without retraining all model parameters, their performance is limited by the capacity of incremental modules, especially under constrained parameter budgets. \\\\ To overcome this challenge, we propose CapaBoost, a simple yet effective strategy that enhances model capacity by leveraging low-rank updates through parallel weight modules in target layers. By applying static random masks to the shared weight matrix, CapaBoost constructs a diverse set of weight matrices, effectively increasing the rank of incremental weights without adding parameters. Notably, our approach can be seamlessly integrated into various existing parameter-efficient fine-tuning methods. We extensively validate the efficacy of CapaBoost through experiments on diverse downstream tasks, including natural language understanding, question answering, and image classification. Our results demonstrate significant improvements over baselines, without incurring additional computation or storage costs. Our code is available at \\url{https://github.com/LINs-lab/CapaBoost}.",
    "pdf_link": "https://arxiv.org/abs/2407.01320",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.01320v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01320/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01320v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01320/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01320v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01320/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01320v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01320/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01320v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01320/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01320v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01320/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01320v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01320/x7.png"
      }
    ],
    "abstract_cn": "近期，微调如175B GPT-3这样的大型预训练模型在下游任务中备受瞩目。尽管参数高效的微调方法已被证明有效，但其性能仍受限于增量模块的容量，尤其是在参数预算有限时。为此，我们推出了CapaBoost策略，通过在目标层中并行权重模块的低秩更新，简单而有效地提升模型容量。通过静态随机掩码的应用，CapaBoost构建了多样化的权重矩阵，有效提升增量权重秩，且不增加参数。此方法能无缝融入现有参数高效微调技术。我们在自然语言理解、问答及图像分类等多样下游任务中验证了CapaBoost的显著效果，且无额外计算或存储负担。代码已公开在[GitHub](https://github.com/LINs-lab/CapaBoost)。",
    "title_cn": "免费提升模型容量：一种简便的参数高效微调方法",
    "tags": [
      "LLM理论",
      "",
      "机器学习"
    ]
  },
  {
    "title": "Language Portability Strategies for Open-domain Dialogue with Pre-trained Language Models from High to Low Resource Languages",
    "submit_datetime": "2024年07月01日",
    "abstract": "In this paper we propose a study of linguistic portability strategies of large pre-trained language models (PLMs) used for open-domain dialogue systems in a high-resource language for this task. In particular the target low-resource language (L_T) will be simulated with French, as it lacks of task-specific resources and allows our human evaluation, when the source language (L_S) is English. For obvious reasons, recent works using such models for open-domain dialogue are mostly developed in English. Yet building specific PLMs for each possible target language supposes collecting new datasets and is costly. For this reason, trying to leverage all existing resources (PLMs and data) in both L_S and L_T , we wish to assess the performance achievable in L_T with different approaches. The first two approaches evaluate the usage of Neural Machine Translation (NMT) at different levels: TrainOnTarget where a L_S dataset is translated before fine-tuning in L_T and TestOnSource where a L_S model is coupled with NMT modules during inference. Then, the advent of BLOOM [2], the world first open-access multilingual large PLM, allow researchers to develop new approaches aiming to leverage not only the model's full accessibility but also its multilingualism and translation abilities. In this context the task is learned in L_S first and adapted to L_T using the MAD-X Adapter architecture [16]. In the two sets of experiments models are evaluated in spoken dialogue conditions with human and the strategies can be compared in terms of perceived interaction quality.",
    "pdf_link": "https://arxiv.org/abs/2407.01315",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.01315v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01315/TrainOnTarget.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01315v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01315/avg_coherence.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01315v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01315/avg_engagement.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01315v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01315/avg_naturel.png"
      }
    ],
    "abstract_cn": "本文探讨了大型预训练语言模型（PLMs）在高资源语言开放领域对话系统中的语言可移植性策略。我们以法语模拟低资源目标语言（L_T），因其缺乏特定任务资源，便于进行人类评估，而源语言（L_S）为英语。当前，这类模型多以英语开发，但为每种目标语言定制PLMs需收集新数据，成本高昂。因此，我们尝试整合L_S与L_T的现有资源，评估在L_T中通过不同方法的性能。我们评估了两种NMT应用：TrainOnTarget先翻译L_S数据集再在L_T中微调；TestOnSource则在推理时结合L_S模型与NMT模块。BLOOM[2]作为首个开放访问的多语言大型PLM，开启了新方法的探索，不仅利用其全面可访问性，还发挥其多语言和翻译能力。我们首先在L_S中学习任务，再通过MAD-X Adapter架构[16]适应至L_T。实验中，模型在口语对话环境下接受评估，人类评估者可比较不同策略在交互质量上的表现。",
    "title_cn": "预训练语言模型在开放域对话中，从高资源到低资源语言的语言可移植性策略研究",
    "tags": [
      "LLM应用",
      "对话系统",
      "语言处理"
    ]
  },
  {
    "title": "Collaborative Performance Prediction for Large Language Models",
    "submit_datetime": "2024年07月01日",
    "abstract": "Comprehensively understanding and accurately predicting the performance of large language models across diverse downstream tasks has emerged as a pivotal challenge in NLP research. The pioneering scaling law on downstream works demonstrated intrinsic similarities within model families and utilized such similarities for performance prediction. However, they tend to overlook the similarities between model families and only consider design factors listed in the original scaling law. To overcome these limitations, we introduce a novel framework, Collaborative Performance Prediction (CPP), which significantly enhances prediction accuracy by leveraging the historical performance of various models on downstream tasks and other design factors for both model and task. We also collect a collaborative data sourced from online platforms containing both historical performance and additional design factors. With the support of the collaborative data, CPP not only surpasses traditional scaling laws in predicting the performance of scaled LLMs but also facilitates a detailed analysis of factor importance, an area previously overlooked.",
    "pdf_link": "https://arxiv.org/abs/2407.01300",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.01300v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01300/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01300v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01300/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01300v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01300/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01300v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01300/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01300v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01300/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01300v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01300/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01300v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01300/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01300v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01300/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01300v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01300/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01300v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01300/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01300v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01300/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01300v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01300/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01300v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01300/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01300v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01300/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01300v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01300/x15.png"
      }
    ],
    "abstract_cn": "在NLP研究中，全面且准确地预测大型语言模型在各种下游任务中的表现已成为一项核心挑战。虽然早期的规模法则揭示了模型家族内的相似性，并据此进行性能预测，但它们忽略了家族间的相似性，仅依赖于原始法则中的设计因素。为此，我们提出了协同性能预测（CPP）框架，该框架通过整合模型历史表现和其他设计因素，大幅提升了预测精度。此外，我们收集了包含历史性能和设计因素的在线数据，支持CPP不仅在预测LLM性能上超越传统法则，还深入分析了各因素的重要性，填补了以往研究的空白。",
    "title_cn": "大型语言模型的协同性能预测",
    "tags": [
      "LLM理论",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Lightweight Zero-shot Text-to-Speech with Mixture of Adapters",
    "submit_datetime": "2024年07月01日",
    "abstract": "The advancements in zero-shot text-to-speech (TTS) methods, based on large-scale models, have demonstrated high fidelity in reproducing speaker characteristics. However, these models are too large for practical daily use. We propose a lightweight zero-shot TTS method using a mixture of adapters (MoA). Our proposed method incorporates MoA modules into the decoder and the variance adapter of a non-autoregressive TTS model. These modules enhance the ability to adapt a wide variety of speakers in a zero-shot manner by selecting appropriate adapters associated with speaker characteristics on the basis of speaker embeddings. Our method achieves high-quality speech synthesis with minimal additional parameters. Through objective and subjective evaluations, we confirmed that our method achieves better performance than the baseline with less than 40\\% of parameters at 1.9 times faster inference speed. Audio samples are available on our demo page (https://ntt-hilab-gensp.github.io/is2024lightweightTTS/).",
    "pdf_link": "https://arxiv.org/abs/2407.01291",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.01291v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01291/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01291v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01291/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01291v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01291/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01291v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01291/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01291v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01291/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01291v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01291/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01291v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01291/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01291v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01291/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01291v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01291/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01291v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01291/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01291v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01291/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01291v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01291/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01291v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01291/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01291v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01291/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01291v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01291/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01291v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01291/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01291v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01291/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01291v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01291/x18.png"
      }
    ],
    "abstract_cn": "基于大规模模型的零-shot 文本到语音技术虽已展现高保真度，但模型体积过大，不便日常使用。为此，我们创新性地提出了一种轻量级零-shot TTS 方法，采用适配器混合技术 (MoA)。该方法通过将 MoA 模块嵌入非自回归 TTS 模型的解码器和变异适配器，实现了对多样说话者特征的精准适配。仅需少量额外参数，便能合成高质量语音。经客观与主观双重评估，我们的方法在参数减少 40% 的同时，推理速度提升 1.9 倍，性能超越基线。欢迎访问我们的演示页面 (https://ntt-hilab-gensp.github.io/is2024lightweightTTS/) 试听音频样本。",
    "title_cn": "轻量级零-shot 文本转语音技术采用适配器混合方法",
    "tags": [
      "LLM应用",
      "语音技术",
      "人工智能"
    ]
  },
  {
    "title": "We-Math: Does Your Large Multimodal Model Achieve Human-like Mathematical Reasoning?",
    "submit_datetime": "2024年07月01日",
    "abstract": "Visual mathematical reasoning, as a fundamental visual reasoning ability, has received widespread attention from the Large Multimodal Models (LMMs) community. Existing benchmarks, such as MathVista and MathVerse, focus more on the result-oriented performance but neglect the underlying principles in knowledge acquisition and generalization. Inspired by human-like mathematical reasoning, we introduce WE-MATH, the first benchmark specifically designed to explore the problem-solving principles beyond end-to-end performance. We meticulously collect and categorize 6.5K visual math problems, spanning 67 hierarchical knowledge concepts and five layers of knowledge granularity. We decompose composite problems into sub-problems according to the required knowledge concepts and introduce a novel four-dimensional metric, namely Insufficient Knowledge (IK), Inadequate Generalization (IG), Complete Mastery (CM), and Rote Memorization (RM), to hierarchically assess inherent issues in LMMs' reasoning process. With WE-MATH, we conduct a thorough evaluation of existing LMMs in visual mathematical reasoning and reveal a negative correlation between solving steps and problem-specific performance. We confirm the IK issue of LMMs can be effectively improved via knowledge augmentation strategies. More notably, the primary challenge of GPT-4o has significantly transitioned from IK to IG, establishing it as the first LMM advancing towards the knowledge generalization stage. In contrast, other LMMs exhibit a marked inclination towards Rote Memorization - they correctly solve composite problems involving multiple knowledge concepts yet fail to answer sub-problems. We anticipate that WE-MATH will open new pathways for advancements in visual mathematical reasoning for LMMs. The WE-MATH data and evaluation code are available at https://github.com/We-Math/We-Math.",
    "pdf_link": "https://arxiv.org/abs/2407.01284",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.01284v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01284/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01284v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01284/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01284v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01284/3-example.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01284v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01284/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01284v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01284/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01284v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01284/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01284v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01284/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01284v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01284/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01284v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01284/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01284v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01284/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01284v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01284/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01284v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01284/tree-1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01284v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01284/tree-2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01284v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01284/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01284v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01284/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01284v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01284/question_length_distribution.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01284v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01284/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01284v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01284/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01284v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01284/GPT-4o_acc.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01284v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01284/GPT-4V_acc.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01284v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01284/Gemini_1.5_Pro_acc.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01284v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01284/Qwen-VL-Max_acc.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01284v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01284/LLaVA-NeXT-110B_acc.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01284v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01284/LLaVA-NeXT-72B_acc.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01284v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01284/InternVL-Chat-V1.5_acc.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01284v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01284/LLaVA-1.6-13B_acc.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01284v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01284/G-LLaVA-13B_acc.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01284v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01284/GLM-4V-9B_acc.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01284v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01284/MiniCPM-LLama3-V_2.5_acc.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01284v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01284/LongVA-7B_acc.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01284v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01284/LLaVA-1.6-7B_acc.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01284v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01284/DeepSeek-VL-7B_acc.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01284v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01284/InternLM-XComposer2-VL-7B_acc.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01284v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01284/Phi3-Vision-4.2B_acc.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01284v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01284/DeepSeek-VL-1.3B_acc.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01284v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01284/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01284v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01284/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01284v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01284/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01284v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01284/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01284v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01284/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01284v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01284/x20.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01284v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01284/x21.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01284v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01284/x22.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01284v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01284/x23.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01284v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01284/x24.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01284v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01284/x25.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01284v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01284/x26.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01284v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01284/x27.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01284v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01284/x28.png"
      }
    ],
    "abstract_cn": "视觉数学推理作为一项基础能力，备受大型多模态模型（LMMs）社区瞩目。然而，现有基准如MathVista和MathVerse过于侧重结果，忽略了知识获取与泛化的深层原理。受人类数学推理启发，我们推出WE-MATH，首个专注于探索问题解决原则的基准。我们精心整理了6.5K个视觉数学问题，涵盖67个知识层次与五层知识粒度，并根据知识需求分解复合问题为子问题。我们创新引入四维指标——知识不足（IK）、泛化不足（IG）、完全掌握（CM）和机械记忆（RM），以层次化评估LMMs推理过程。通过WE-MATH，我们全面评估了现有LMMs，并发现解决步骤与问题性能呈负相关。我们证实，通过知识增强策略可有效改善LMMs的IK问题。尤为突出的是，GPT-4o已从IK转向IG，成为首个迈向知识泛化阶段的LMM。而其他LMMs则倾向于机械记忆，虽能解决复合问题，却未能解答子问题。我们期待WE-MATH为LMMs在视觉数学推理领域的进步开辟新路。WE-MATH数据与评估代码已公开于https://github.com/We-Math/We-Math。",
    "title_cn": "We-Math：探寻大型多模态模型是否已具备人类般的数学推理能力。",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Human-Robot Mutual Learning through Affective-Linguistic Interaction and Differential Outcomes Training [Pre-Print]",
    "submit_datetime": "2024年07月01日",
    "abstract": "Owing to the recent success of Large Language Models, Modern A.I has been much focused on linguistic interactions with humans but less focused on non-linguistic forms of communication between man and machine. In the present paper, we test how affective-linguistic communication, in combination with differential outcomes training, affects mutual learning in a human-robot context. Taking inspiration from child-caregiver dynamics, our human-robot interaction setup consists of a (simulated) robot attempting to learn how best to communicate internal, homeostatically-controlled needs; while a human \"caregiver\" attempts to learn the correct object to satisfy the robot's present communicated need. We studied the effects of i) human training type, and ii) robot reinforcement learning type, to assess mutual learning terminal accuracy and rate of learning (as measured by the average reward achieved by the robot). Our results find mutual learning between a human and a robot is significantly improved with Differential Outcomes Training (DOT) compared to Non-DOT (control) conditions. We find further improvements when the robot uses an exploration-exploitation policy selection, compared to purely exploitation policy selection. These findings have implications for utilizing socially assistive robots (SAR) in therapeutic contexts, e.g. for cognitive interventions, and educational applications.",
    "pdf_link": "https://arxiv.org/abs/2407.01280",
    "graphs": [],
    "abstract_cn": "随着大型语言模型的兴起，现代AI更多地聚焦于与人类的语言交流，而对人机间的非语言沟通关注不足。本文探讨了情感语言交流结合差异结果训练对人机互动中相互学习的影响。借鉴儿童与看护者的互动模式，我们设计了一个模拟场景：机器人学习如何有效表达其内部需求，而人类“看护者”则学习如何准确响应这些需求。通过对比不同训练和学习策略，我们评估了相互学习的准确性和效率。实验表明，采用差异结果训练（DOT）的机器人学习效果显著优于对照组，且探索-利用策略的选择进一步提升了学习成效。这些成果为社会辅助机器人在治疗和教育领域的应用提供了新视角。",
    "title_cn": "人机互学：基于情感语言交互与差异化训练成果 [预印版]",
    "tags": [
      "Agent",
      "",
      ""
    ]
  },
  {
    "title": "Leveraging Large Language Models for Actionable Course Evaluation Student Feedback to Lecturers",
    "submit_datetime": "2024年07月01日",
    "abstract": "End of semester student evaluations of teaching are the dominant mechanism for providing feedback to academics on their teaching practice. For large classes, however, the volume of feedback makes these tools impractical for this purpose. This paper explores the use of open-source generative AI to synthesise factual, actionable and appropriate summaries of student feedback from these survey responses. In our setup, we have 742 student responses ranging over 75 courses in a Computer Science department. For each course, we synthesise a summary of the course evaluations and actionable items for the instructor. Our results reveal a promising avenue for enhancing teaching practices in the classroom setting. Our contribution lies in demonstrating the feasibility of using generative AI to produce insightful feedback for teachers, thus providing a cost-effective means to support educators' development. Overall, our work highlights the possibility of using generative AI to produce factual, actionable, and appropriate feedback for teachers in the classroom setting.",
    "pdf_link": "https://arxiv.org/abs/2407.01274",
    "graphs": [],
    "abstract_cn": "学期末的学生教学评估是反馈教学实践的主要途径。然而，对于大型课程，海量反馈使得传统工具难以应对。本文探索了利用开源生成AI，从众多调查反馈中提炼出事实准确、操作性强且恰如其分的总结。我们分析了742份学生反馈，涉及计算机科学系的75门课程。每门课程，我们都生成了评估摘要和教师可执行的建议。研究结果表明，这一方法为提升课堂教学质量开辟了新途径。我们的创新之处在于，展示了生成AI为教师提供深刻反馈的可行性，为教育发展提供了经济高效的解决方案。总体而言，我们的研究凸显了生成AI在课堂环境中为教师提供精准、实用且恰当反馈的潜力。",
    "title_cn": "借助大型语言模型，为讲师提供具有操作性的课程评估学生反馈",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Show Less, Instruct More: Enriching Prompts with Definitions and Guidelines for Zero-Shot NER",
    "submit_datetime": "2024年07月01日",
    "abstract": "Recently, several specialized instruction-tuned Large Language Models (LLMs) for Named Entity Recognition (NER) have emerged. Compared to traditional NER approaches, these models have strong generalization capabilities. Existing LLMs mainly focus on zero-shot NER in out-of-domain distributions, being fine-tuned on an extensive number of entity classes that often highly or completely overlap with test sets. In this work instead, we propose SLIMER, an approach designed to tackle never-seen-before named entity tags by instructing the model on fewer examples, and by leveraging a prompt enriched with definition and guidelines. Experiments demonstrate that definition and guidelines yield better performance, faster and more robust learning, particularly when labelling unseen Named Entities. Furthermore, SLIMER performs comparably to state-of-the-art approaches in out-of-domain zero-shot NER, while being trained on a reduced tag set.",
    "pdf_link": "https://arxiv.org/abs/2407.01272",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.01272v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01272/our_instruction_prompt.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01272v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01272/guidelines_prompt.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01272v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01272/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01272v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01272/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01272v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01272/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01272v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01272/x4.png"
      }
    ],
    "abstract_cn": "近期，针对命名实体识别 (NER) 的专用指令调整大型语言模型 (LLM) 崭露头角，其泛化能力超越传统方法。传统 LLM 多聚焦于域外零-shot NER，依赖于与测试集高度重叠的大量实体类别进行微调。而我们提出的 SLIMER 方法，则通过精简示例指导和丰富提示中的定义与指南，有效应对新出现的命名实体标签。实验显示，这种方法不仅提升了性能，还加速并强化了学习过程，尤其在处理未知命名实体时表现突出。此外，SLIMER 在域外零-shot NER 任务中与顶尖方法不相上下，且训练标签集更为精简。",
    "title_cn": "精简展示，强化指导：通过定义与指南提升零-shot NER 的提示质量",
    "tags": [
      "LLM应用",
      "人工智能",
      ""
    ]
  },
  {
    "title": "The African Woman is Rhythmic and Soulful: Evaluation of Open-ended Generation for Implicit Biases",
    "submit_datetime": "2024年07月01日",
    "abstract": "This study investigates the subtle and often concealed biases present in Large Language Models (LLMs), which, despite passing explicit bias tests, can still exhibit implicit biases akin to those observed in humans who profess egalitarian beliefs yet demonstrate underlying prejudices. The challenge of measuring such biases is exacerbated as LLMs become increasingly proprietary, restricting access to their internal mechanisms such as embeddings, which are crucial for applying traditional bias measures. To tackle these issues, this study introduces innovative measures of bias inspired by psychological methodologies: the LLM Implicit Association Test (IAT) Bias and the LLM Decision Bias. The LLM IAT Bias is a prompt-based method designed to unearth implicit biases by simulating the well-known psychological IAT but adapted for use with LLMs. The LLM Decision Bias measure is developed to detect subtle discrimination in decision-making tasks, focusing on how LLMs choose between individuals in various scenarios. Open-ended generation is also utilised through thematic analysis of word generations and storytelling. The experiments revealed biases across gender and racial domains, from discriminatory categorisations to exoticisation. Our findings indicate that the prompt-based measure of implicit bias not only correlates with traditional embedding-based methods but also more effectively predicts downstream behaviors, which are crucially measured by the LLM Decision Bias. This relationship underscores the importance of relative, rather than absolute, evaluations in assessing implicit biases, reflecting psychological insights into human bias assessment. This research contributes to the broader understanding of AI ethics and provides suggestions for continually assessing and mitigating biases in advanced AI systems, emphasising the need for more qualitative and downstream focus.",
    "pdf_link": "https://arxiv.org/abs/2407.01270",
    "graphs": [],
    "abstract_cn": "本研究深入探讨了大型语言模型（LLM）中不易察觉的隐性偏见，这些偏见即便在通过显性测试后，仍可能隐晦地显现，类似于那些自称平等主义者却潜藏偏见的人。随着LLM的专有化加深，对关键内部机制如嵌入的访问受限，这使得传统偏见测量方法面临更大挑战。为此，本研究创新性地引入了基于心理学方法的偏见测量：LLM隐性联想测试（IAT）偏见和LLM决策偏见。前者通过模拟心理学IAT揭示LLM的隐性偏见，后者则专注于检测LLM在决策中的微妙歧视。实验结果显示，LLM在性别和种族领域存在从分类歧视到异国情调化的偏见。研究证实，基于提示的隐性偏见测量不仅与传统方法相关，还能更精准地预测下游行为，凸显了相对评估在偏见评估中的重要性。这项研究不仅增进了对AI伦理的理解，还为持续优化和减少AI系统中的偏见提供了方向，强调了定性和下游分析的重要性。",
    "title_cn": "非洲女性，节奏与灵魂的化身：探索隐性偏见在开放式生成中的表现",
    "tags": [
      "LLM理论",
      "人工智能伦理",
      "心理学"
    ]
  },
  {
    "title": "SignCLIP: Connecting Text and Sign Language by Contrastive Learning",
    "submit_datetime": "2024年07月01日",
    "abstract": "We present SignCLIP, which re-purposes CLIP (Contrastive Language-Image Pretraining) to project spoken language text and sign language videos, two classes of natural languages of distinct modalities, into the same space. SignCLIP is an efficient method of learning useful visual representations for sign language processing from large-scale, multilingual video-text pairs, without directly optimizing for a specific task or sign language which is often of limited size.\n  We pretrain SignCLIP on Spreadthesign, a prominent sign language dictionary consisting of ~500 thousand video clips in up to 44 sign languages, and evaluate it with various downstream datasets. SignCLIP discerns in-domain signing with notable text-to-video/video-to-text retrieval accuracy. It also performs competitively for out-of-domain downstream tasks such as isolated sign language recognition upon essential few-shot prompting or fine-tuning.\n  We analyze the latent space formed by the spoken language text and sign language poses, which provides additional linguistic insights. Our code and models are openly available.",
    "pdf_link": "https://arxiv.org/abs/2407.01264",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.01264v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01264/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01264v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01264/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01264v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01264/house.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01264v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01264/RWTHFS.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01264v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01264/sp_language_distribution.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01264v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01264/sp_pose_length_distribution.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01264v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01264/sp_concept_distribution.png"
      }
    ],
    "abstract_cn": "我们开发了 SignCLIP，通过重新利用 CLIP 技术，将口语和手语这两种不同模态的语言融合至同一空间。SignCLIP 高效地从多语言视频-文本对中提取手语视觉特征，无需针对特定手语或任务进行优化。我们在包含 44 种手语的 Spreadthesign 词典上预训练模型，并在多个下游任务中验证其性能。SignCLIP 在手语识别中展现出高精度的文本-视频互检能力，并在其他领域任务中表现优异，仅需少量学习或微调。此外，我们探索了口语与手语间的潜在空间，揭示了新的语言视角。相关代码和模型已公开分享。",
    "title_cn": "SignCLIP：借助对比学习，架起文本与手语之间的桥梁",
    "tags": [
      "LLM应用",
      "手语识别",
      "语言学"
    ]
  },
  {
    "title": "uDistil-Whisper: Label-Free Data Filtering for Knowledge Distillation via Large-Scale Pseudo Labelling",
    "submit_datetime": "2024年07月01日",
    "abstract": "Recent work on distilling Whisper's knowledge into small models using pseudo-labels shows promising performance while reducing the size by up to 50\\%. This results in small, efficient, and dedicated models. However, a critical step of distillation from pseudo-labels involves filtering high-quality predictions and using only those during training. This step requires ground truth to compare and filter bad examples making the whole process supervised. In addition to that, the distillation process requires a large amount of data thereby limiting the ability to distil models in low-resource settings. To address this challenge, we propose an unsupervised or label-free framework for distillation, thus eliminating the requirement for labeled data altogether. Through experimentation, we show that our best distilled models outperform the teacher model by 5-7 points in terms of WER. Additionally, our models are on par with or better than similar supervised data filtering setup. When we scale the data, our models significantly outperform all zero-shot and supervised models. In this work, we demonstrate that it's possible to distill large Whisper models into relatively small models without using any labeled data. As a result, our distilled models are 25-50\\% more compute and memory efficient while maintaining performance equal to or better than the teacher model.",
    "pdf_link": "https://arxiv.org/abs/2407.01257",
    "graphs": [],
    "abstract_cn": "近期研究通过伪标签将 Whisper 的知识精炼至小型模型，不仅性能出色，还成功缩减了模型体积达50%。这些模型虽小巧却高效且专注。然而，提炼过程中的关键一环——筛选高质量预测，依赖于真实数据进行不良示例的过滤，这使得整个流程带有监督性质。此外，大量数据需求也限制了其在资源匮乏环境中的应用。为此，我们创新性地提出了一个无需标签的无监督提炼框架，彻底摆脱了对标记数据的依赖。实验结果显示，我们的最佳提炼模型在WER指标上超越了原教师模型5-7分，且与采用监督数据筛选的模型相比，性能不相上下甚至更优。随着数据规模的扩大，我们的模型在性能上显著领先于所有零-shot和监督模型。本研究成果表明，无需任何标记数据，即可将庞大的Whisper模型精炼为更小巧的版本，同时保持甚至提升其性能，实现计算与内存效率的显著提升。",
    "title_cn": "uDistil-Whisper：利用大规模伪标签技术，实现知识蒸馏中的无标签数据过滤。",
    "tags": [
      "LLM应用",
      "语音识别",
      "模型优化"
    ]
  },
  {
    "title": "SINKT: A Structure-Aware Inductive Knowledge Tracing Model with Large Language Model",
    "submit_datetime": "2024年07月01日",
    "abstract": "Knowledge Tracing (KT) aims to determine whether students will respond correctly to the next question, which is a crucial task in intelligent tutoring systems (ITS). In educational KT scenarios, transductive ID-based methods often face severe data sparsity and cold start problems, where interactions between individual students and questions are sparse, and new questions and concepts consistently arrive in the database. In addition, existing KT models only implicitly consider the correlation between concepts and questions, lacking direct modeling of the more complex relationships in the heterogeneous graph of concepts and questions. In this paper, we propose a Structure-aware Inductive Knowledge Tracing model with large language model (dubbed SINKT), which, for the first time, introduces large language models (LLMs) and realizes inductive knowledge tracing. Firstly, SINKT utilizes LLMs to introduce structural relationships between concepts and constructs a heterogeneous graph for concepts and questions. Secondly, by encoding concepts and questions with LLMs, SINKT incorporates semantic information to aid prediction. Finally, SINKT predicts the student's response to the target question by interacting with the student's knowledge state and the question representation. Experiments on four real-world datasets demonstrate that SINKT achieves state-of-the-art performance among 12 existing transductive KT models. Additionally, we explore the performance of SINKT on the inductive KT task and provide insights into various modules.",
    "pdf_link": "https://arxiv.org/abs/2407.01245",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.01245v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01245/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01245v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01245/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01245v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01245/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01245v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01245/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01245v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01245/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01245v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01245/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01245v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01245/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01245v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01245/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01245v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01245/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01245v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01245/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01245v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01245/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01245v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01245/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01245v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01245/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01245v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01245/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01245v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01245/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01245v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01245/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01245v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01245/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01245v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01245/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01245v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01245/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01245v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01245/x20.png"
      }
    ],
    "abstract_cn": "知识追踪 (KT) 是智能辅导系统中的关键任务，旨在预测学生能否正确回答下一个问题。然而，传统基于转导 ID 的方法常受数据稀疏和冷启动问题困扰，且未能直接建模概念与问题间的复杂关系。为此，我们提出结构感知归纳知识追踪模型 SINKT，首次结合大型语言模型 (LLM) 实现归纳知识追踪。SINKT 通过 LLM 构建概念间的结构关系和异构图，并融入语义信息以提升预测准确性。最终，通过与学生知识状态和问题表示的交互，SINKT 预测学生对新问题的回答。实验显示，SINKT 在多个数据集上超越现有模型，达到最优性能，并深入分析了其在归纳 KT 任务中的表现。",
    "title_cn": "SINKT：结合大型语言模型的结构感知归纳知识追踪模型",
    "tags": [
      "LLM应用",
      "",
      "智能辅导系统"
    ]
  },
  {
    "title": "Large Language Models are Zero-Shot Recognizers for Activities of Daily Living",
    "submit_datetime": "2024年07月01日",
    "abstract": "The sensor-based recognition of Activities of Daily Living (ADLs) in smart home environments enables several applications in the areas of energy management, safety, well-being, and healthcare. ADLs recognition is typically based on deep learning methods requiring large datasets to be trained. Recently, several studies proved that Large Language Models (LLMs) effectively capture common-sense knowledge about human activities. However, the effectiveness of LLMs for ADLs recognition in smart home environments still deserves to be investigated. In this work, we propose ADL-LLM, a novel LLM-based ADLs recognition system. ADLLLM transforms raw sensor data into textual representations, that are processed by an LLM to perform zero-shot ADLs recognition. Moreover, in the scenario where a small labeled dataset is available, ADL-LLM can also be empowered with few-shot prompting. We evaluated ADL-LLM on two public datasets, showing its effectiveness in this domain.",
    "pdf_link": "https://arxiv.org/abs/2407.01238",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.01238v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01238/adl-llm-new.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01238v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01238/w2t.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01238v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01238/zerosystemprompt.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01238v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01238/output.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01238v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01238/confusion_matrix_home_a_normalized.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01238v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01238/confusion_matrix_home_b_normalized.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01238v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01238/normalized_confusion_matrix_after_chair_zero_shot.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01238v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01238/cdf_time_analysis_2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01238v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01238/barplot_home_a_v2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01238v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01238/barplot_home_b_v2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01238v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01238/barplot_home_marble_v2.png"
      }
    ],
    "abstract_cn": "在智能家居环境中，基于传感器的日常活动（ADLs）识别技术为能源管理、安全、福祉和医疗保健等领域带来了多种应用。虽然ADLs识别通常依赖于需要大量数据训练的深度学习方法，但近期研究表明，大型语言模型（LLMs）能够有效捕捉人类活动的常识知识。尽管如此，LLMs在智能家居ADLs识别中的实际效果仍需深入探讨。为此，我们开发了ADL-LLM，一个创新的基于LLM的ADLs识别系统。该系统将传感器数据转化为文本形式，再由LLM进行处理，实现零-shot ADLs识别。同时，在拥有少量标记数据的情况下，ADL-LLM还能通过少量提示进一步提升性能。我们在两个公开数据集上的实验证明了ADL-LLM在这一领域的有效性。",
    "title_cn": "大型语言模型能够零-shot 识别日常活动",
    "tags": [
      "LLM应用",
      "智能家居",
      "医疗保健"
    ]
  },
  {
    "title": "A Fingerprint for Large Language Models",
    "submit_datetime": "2024年07月01日",
    "abstract": "Recent advances show that scaling a pre-trained language model could achieve state-of-the-art performance on many downstream tasks, prompting large language models (LLMs) to become a hot research topic in the field of artificial intelligence. However, due to the resource-intensive nature of training LLMs from scratch, it is urgent and crucial to protect the intellectual property of LLMs against infringement. This has motivated the authors in this paper to propose a novel black-box fingerprinting technique for LLMs, which requires neither model training nor model fine-tuning. We first demonstrate that the outputs of LLMs span a unique vector space associated with each model. We model the problem of ownership authentication as the task of evaluating the similarity between the victim model's space and the output's space of the suspect model. To deal with this problem, we propose two solutions, where the first solution involves verifying whether the outputs of the suspected large model are in the same space as those of the victim model, enabling rapid identification of model infringement, and the second one reconstructs the union of the vector spaces for LLM outputs and the victim model to address situations where the victim model has undergone the Parameter-Efficient Fine-Tuning (PEFT) attacks. Experimental results indicate that the proposed technique achieves superior performance in ownership verification and robustness against PEFT attacks. This work reveals inherent characteristics of LLMs and provides a promising solution for ownership verification of LLMs in black-box scenarios, ensuring efficiency, generality and practicality.",
    "pdf_link": "https://arxiv.org/abs/2407.01235",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.01235v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01235/fig1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01235v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01235/fig2.png"
      }
    ],
    "abstract_cn": "随着预训练语言模型的扩展在众多下游任务中达到顶尖性能，大型语言模型 (LLMs) 已成为人工智能研究的热点。然而，鉴于从头训练 LLMs 的高资源需求，保护其知识产权刻不容缓。为此，本文提出了一种无需训练或微调的黑盒指纹技术。我们首先证实 LLMs 的输出构成了独特的向量空间。将所有权认证视为比较受害者与嫌疑模型输出空间相似度的任务，我们设计了两种方案：一是快速验证嫌疑模型输出是否与受害者模型同处一空间，二是重建向量空间并集以应对参数高效微调攻击。实验显示，该技术在所有权验证及抗攻击方面表现卓越。这项研究不仅揭示了 LLMs 的本质特征，还为黑盒环境下的所有权验证提供了高效、通用且实用的解决方案。",
    "title_cn": "大型语言模型的独特印记",
    "tags": [
      "LLM理论",
      "知识产权保护",
      "人工智能"
    ]
  },
  {
    "title": "MIRAI: Evaluating LLM Agents for Event Forecasting",
    "submit_datetime": "2024年07月01日",
    "abstract": "Recent advancements in Large Language Models (LLMs) have empowered LLM agents to autonomously collect world information, over which to conduct reasoning to solve complex problems. Given this capability, increasing interests have been put into employing LLM agents for predicting international events, which can influence decision-making and shape policy development on an international scale. Despite such a growing interest, there is a lack of a rigorous benchmark of LLM agents' forecasting capability and reliability. To address this gap, we introduce MIRAI, a novel benchmark designed to systematically evaluate LLM agents as temporal forecasters in the context of international events. Our benchmark features an agentic environment with tools for accessing an extensive database of historical, structured events and textual news articles. We refine the GDELT event database with careful cleaning and parsing to curate a series of relational prediction tasks with varying forecasting horizons, assessing LLM agents' abilities from short-term to long-term forecasting. We further implement APIs to enable LLM agents to utilize different tools via a code-based interface. In summary, MIRAI comprehensively evaluates the agents' capabilities in three dimensions: 1) autonomously source and integrate critical information from large global databases; 2) write codes using domain-specific APIs and libraries for tool-use; and 3) jointly reason over historical knowledge from diverse formats and time to accurately predict future events. Through comprehensive benchmarking, we aim to establish a reliable framework for assessing the capabilities of LLM agents in forecasting international events, thereby contributing to the development of more accurate and trustworthy models for international relation analysis.",
    "pdf_link": "https://arxiv.org/abs/2407.01231",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.01231v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01231/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01231v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01231/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01231v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01231/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01231v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01231/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01231v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01231/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01231v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01231/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01231v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01231/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01231v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01231/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01231v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01231/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01231v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01231/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01231v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01231/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01231v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01231/seq.png"
      }
    ],
    "abstract_cn": "大型语言模型 (LLM) 的进步赋予了 LLM 代理自主收集全球信息并进行推理解决复杂问题的能力。因此，利用 LLM 代理预测国际事件的兴趣日益浓厚，这些预测能影响全球决策和政策制定。然而，关于 LLM 代理预测能力的严格基准尚缺。为此，我们推出了 MIRAI，一个专为系统评估 LLM 代理在国际事件预测中表现的新基准。MIRAI 提供了一个包含丰富历史和新闻数据的代理环境，并通过精细处理 GDELT 数据库，设计了涵盖短期到长期预测的任务，全面测试 LLM 代理的能力。此外，我们还开发了 API，使代理能通过代码接口灵活使用工具。MIRAI 从三个维度评估代理：自主整合全球信息、编写专用代码使用工具、结合多元历史知识精准预测未来。通过这一全面基准，我们旨在构建一个可靠框架，推动开发更精准可信的国际关系分析模型。",
    "title_cn": "MIRAI：评估大型语言模型代理在事件预测中的效能",
    "tags": [
      "Agent",
      "国际关系",
      "政策制定"
    ]
  },
  {
    "title": "Searching for Best Practices in Retrieval-Augmented Generation",
    "submit_datetime": "2024年07月01日",
    "abstract": "Retrieval-augmented generation (RAG) techniques have proven to be effective in integrating up-to-date information, mitigating hallucinations, and enhancing response quality, particularly in specialized domains. While many RAG approaches have been proposed to enhance large language models through query-dependent retrievals, these approaches still suffer from their complex implementation and prolonged response times. Typically, a RAG workflow involves multiple processing steps, each of which can be executed in various ways. Here, we investigate existing RAG approaches and their potential combinations to identify optimal RAG practices. Through extensive experiments, we suggest several strategies for deploying RAG that balance both performance and efficiency. Moreover, we demonstrate that multimodal retrieval techniques can significantly enhance question-answering capabilities about visual inputs and accelerate the generation of multimodal content using a \"retrieval as generation\" strategy.",
    "pdf_link": "https://arxiv.org/abs/2407.01219",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.01219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01219/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01219/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01219/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01219/x4.png"
      }
    ],
    "abstract_cn": "RAG技术在整合最新信息、减少幻觉和提升响应质量方面表现出色，尤其是在专业领域。然而，尽管有许多依赖查询的检索方法被提出以增强大型语言模型，这些方法的复杂实现和较长响应时间仍是问题。我们深入研究了现有RAG方法及其组合，旨在找出最佳实践。通过大量实验，我们推荐了几种既能保证性能又能提高效率的RAG部署策略。此外，我们还展示了多模态检索技术如何显著提升对视觉内容的问答能力，并通过“检索即生成”策略加速多模态内容的生成。",
    "title_cn": "探寻检索增强生成领域的最佳实践",
    "tags": [
      "RAG",
      "专业领域",
      "多模态内容生成"
    ]
  },
  {
    "title": "EconNLI: Evaluating Large Language Models on Economics Reasoning",
    "submit_datetime": "2024年07月01日",
    "abstract": "Large Language Models (LLMs) are widely used for writing economic analysis reports or providing financial advice, but their ability to understand economic knowledge and reason about potential results of specific economic events lacks systematic evaluation. To address this gap, we propose a new dataset, natural language inference on economic events (EconNLI), to evaluate LLMs' knowledge and reasoning abilities in the economic domain. We evaluate LLMs on (1) their ability to correctly classify whether a premise event will cause a hypothesis event and (2) their ability to generate reasonable events resulting from a given premise. Our experiments reveal that LLMs are not sophisticated in economic reasoning and may generate wrong or hallucinated answers. Our study raises awareness of the limitations of using LLMs for critical decision-making involving economic reasoning and analysis. The dataset and codes are available at https://github.com/Irenehere/EconNLI.",
    "pdf_link": "https://arxiv.org/abs/2407.01212",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.01212v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01212/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01212v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01212/x2.png"
      }
    ],
    "abstract_cn": "尽管大型语言模型 (LLM) 在撰写经济分析报告和提供财务建议方面应用广泛，但其对经济知识的理解和推理特定经济事件结果的能力尚未得到系统评估。为此，我们推出了经济事件自然语言推理 (EconNLI) 数据集，旨在全面检验 LLM 在经济领域的推理能力。实验结果显示，LLM 在经济推理上存在不足，可能给出错误或虚构的答案。这一发现提醒我们，在依赖 LLM 进行涉及经济分析的关键决策时需谨慎。EconNLI 数据集及代码已公开，供进一步研究使用。",
    "title_cn": "EconNLI：探究大型语言模型在经济学推理领域的评估",
    "tags": [
      "LLM应用",
      "",
      ""
    ]
  },
  {
    "title": "TCSR-SQL: Towards Table Content-aware Text-to-SQL with Self-retrieval",
    "submit_datetime": "2024年07月01日",
    "abstract": "Large Language Model-based (LLM-based) Text-to-SQL methods have achieved important progress in generating SQL queries for real-world applications. When confronted with table content-aware questions in real-world scenarios, ambiguous data content keywords and non-existent database schema column names within the question leads to the poor performance of existing methods. To solve this problem, we propose a novel approach towards Table Content-aware Text-to-SQL with Self-Retrieval (TCSR-SQL). It leverages LLM's in-context learning capability to extract data content keywords within the question and infer possible related database schema, which is used to generate Seed SQL to fuzz search databases. The search results are further used to confirm the encoding knowledge with the designed encoding knowledge table, including column names and exact stored content values used in the SQL. The encoding knowledge is sent to obtain the final Precise SQL following multi-rounds of generation-execution-revision process. To validate our approach, we introduce a table-content-aware, question-related benchmark dataset, containing 1,692 question-SQL pairs. Comprehensive experiments conducted on this benchmark demonstrate the remarkable performance of TCSR-SQL, achieving an improvement of at least 13.7% in execution accuracy compared to other state-of-the-art methods.",
    "pdf_link": "https://arxiv.org/abs/2407.01183",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.01183v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01183/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01183v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01183/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01183v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01183/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01183v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01183/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01183v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01183/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01183v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01183/x6.png"
      }
    ],
    "abstract_cn": "基于大型语言模型的Text-to-SQL方法在生成实际应用的SQL查询方面取得了显著进展。然而，面对现实场景中涉及表格内容的复杂问题时，问题中含糊的关键词和不存在的数据库列名常导致现有方法性能不佳。为此，我们创新性地提出了表格内容感知Text-to-SQL自检索（TCSR-SQL）方法，巧妙利用LLM的上下文学习能力，精准提取问题中的数据关键词，并推断相关数据库模式，进而生成种子SQL进行模糊搜索。搜索结果再通过精心设计的编码知识表进行确认，最终通过多轮生成-执行-修订流程，输出精确SQL。为验证这一方法的有效性，我们构建了一个包含1,692对问题-SQL的基准数据集。实验结果显示，TCSR-SQL在执行准确率上比现有顶尖方法提升了至少13.7%，表现卓越。",
    "title_cn": "TCSR-SQL：借助自检索技术，实现对表格内容的智能感知，进而生成SQL语句。",
    "tags": [
      "LLM应用",
      "数据库",
      "软件开发"
    ]
  },
  {
    "title": ": Language Modeling with Explicit Memory",
    "submit_datetime": "2024年07月01日",
    "abstract": "The training and inference of large language models (LLMs) are together a costly process that transports knowledge from raw data to meaningful computation. Inspired by the memory hierarchy of the human brain, we reduce this cost by equipping LLMs with explicit memory, a memory format cheaper than model parameters and text retrieval-augmented generation (RAG). Conceptually, with most of its knowledge externalized to explicit memories, the LLM can enjoy a smaller parameter size, training cost, and inference cost, all proportional to the amount of remaining \"abstract knowledge\". As a preliminary proof of concept, we train from scratch a 2.4B LLM, which achieves better performance than much larger LLMs as well as RAG models, and maintains higher decoding speed than RAG. The model is named $\\text{Memory}^3$, since explicit memory is the third form of memory in LLMs after implicit memory (model parameters) and working memory (context key-values). We introduce a memory circuitry theory to support the externalization of knowledge, and present novel techniques including a memory sparsification mechanism that makes storage tractable and a two-stage pretraining scheme that facilitates memory formation.",
    "pdf_link": "https://arxiv.org/abs/2407.01178",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.01178v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01178/m3mory_opening.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01178v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01178/memory3_benchmark_vs_size_small.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01178v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01178/memory3_profession_vs_throughput.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01178v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01178/total_cost_2B_chunk.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01178v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01178/memory_circuitry_theory.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01178v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01178/classical_circuits_demo.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01178v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01178/LLM_computation_graph.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01178v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01178/LLM_subgraph_homomorphism.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01178v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01178/knowledge_distribution.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01178v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01178/m3mory_inference.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01178v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01178/optimize_2B_shape_warmup.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01178v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01178/warmup_l40-h32-d64-ml20_smooth95.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01178v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01178/continual_l40-h32-d64-ml20_smooth95.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01178v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01178/pretrain_data_distribution.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01178v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01178/warmup_loss.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01178v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01178/warmup_lr.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01178v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01178/2B_continual_train_loss.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01178v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01178/2B_continual_lr_schedule.png"
      }
    ],
    "abstract_cn": "受人类大脑记忆层次的启发，我们通过为大型语言模型（LLM）配备显式记忆，有效降低了训练和推理的高昂成本。这种显式记忆不仅成本低于模型参数和文本检索增强生成（RAG），还能使LLM在保持较小参数规模的同时，降低训练和推理成本。我们成功训练了一个2.4B参数的LLM，名为$\\text{Memory}^3$，其性能超越了更大规模的LLM和RAG模型，且解码速度更快。此外，我们提出了一种记忆电路理论和相关技术，如记忆稀疏化机制和两阶段预训练方案，以支持知识的外部化和记忆的形成。",
    "title_cn": "语言建模中的显式记忆技术",
    "tags": [
      "LLM理论",
      "人工智能",
      ""
    ]
  },
  {
    "title": "GazeNoter: Co-Piloted AR Note-Taking via Gaze Selection of LLM Suggestions to Match Users' Intentions",
    "submit_datetime": "2024年07月01日",
    "abstract": "Note-taking is critical during speeches and discussions, serving not only for later summarization and organization but also for real-time question and opinion reminding in question-and-answer sessions or timely contributions in discussions. Manually typing on smartphones for note-taking could be distracting and increase cognitive load for users. While large language models (LLMs) are used to automatically generate summaries and highlights, the content generated by artificial intelligence (AI) may not match users' intentions without user input or interaction. Therefore, we propose an AI-copiloted augmented reality (AR) system, GazeNoter, to allow users to swiftly select diverse LLM-generated suggestions via gaze on an AR headset for real-time note-taking. GazeNoter leverages an AR headset as a medium for users to swiftly adjust the LLM output to match their intentions, forming a user-in-the-loop AI system for both within-context and beyond-context notes. We conducted two user studies to verify the usability of GazeNoter in attending speeches in a static sitting condition and walking meetings and discussions in a mobile walking condition, respectively.",
    "pdf_link": "https://arxiv.org/abs/2407.01161",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.01161v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01161/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01161v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01161/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01161v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01161/ReviewingNotes.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01161v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01161/Ring.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01161v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01161/Study1Scenario.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01161v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01161/Study1Objective.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01161v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01161/Study1Subjective.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01161v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01161/Study2Scenario.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01161v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01161/Studty2Objective.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01161v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01161/Study2Subjective.png"
      }
    ],
    "abstract_cn": "在演讲和讨论中，记笔记不仅有助于后续的总结和整理，还能在问答环节中实时提醒问题和意见，或在讨论中及时表达观点。然而，在智能手机上手动打字记笔记可能会分散注意力，增加认知负担。尽管大型语言模型（LLM）能自动生成总结和重点，但缺乏用户互动可能导致AI生成的内容与用户意图不符。为此，我们设计了GazeNoter，一个AI辅助的增强现实（AR）系统，用户通过AR头显上的注视快速选择LLM生成的建议，实现实时笔记记录。GazeNoter让用户能快速调整LLM输出，形成一个包含用户的AI系统，适用于各种笔记场景。我们通过两项用户研究，验证了GazeNoter在静态和移动条件下的实用性。",
    "title_cn": "GazeNoter：一种协同增强现实笔记工具，通过目光选择大型语言模型建议，精准匹配用户意图。",
    "tags": [
      "LLM应用",
      "增强现实",
      ""
    ]
  },
  {
    "title": "Learning to Explore and Select for Coverage-Conditioned Retrieval-Augmented Generation",
    "submit_datetime": "2024年07月01日",
    "abstract": "Interactions with billion-scale large language models typically yield long-form responses due to their extensive parametric capacities, along with retrieval-augmented features. While detailed responses provide insightful viewpoint of a specific subject, they frequently generate redundant and less engaging content that does not meet user interests. In this work, we focus on the role of query outlining (i.e., selected sequence of queries) in scenarios that users request a specific range of information, namely coverage-conditioned ($C^2$) scenarios. For simulating $C^2$ scenarios, we construct QTree, 10K sets of information-seeking queries decomposed with various perspectives on certain topics. By utilizing QTree, we train QPlanner, a 7B language model generating customized query outlines that follow coverage-conditioned queries. We analyze the effectiveness of generated outlines through automatic and human evaluation, targeting on retrieval-augmented generation (RAG). Moreover, the experimental results demonstrate that QPlanner with alignment training can further provide outlines satisfying diverse user interests. Our resources are available at https://github.com/youngerous/qtree.",
    "pdf_link": "https://arxiv.org/abs/2407.01158",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.01158v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01158/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01158v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01158/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01158v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01158/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01158v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01158/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01158v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01158/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01158v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01158/x13.png"
      }
    ],
    "abstract_cn": "与数十亿参数的大型语言模型交互时，长篇回复常见，这归功于其强大的参数能力和检索增强功能。虽然详细回复提供了深入见解，但往往包含冗余内容，难以吸引用户。本研究聚焦于用户请求特定信息时查询概述的作用，即在$C^2$场景中。我们构建了QTree，包含10K组多视角信息查询，用于模拟此类场景。利用QTree，我们训练了QPlanner，一个7B模型，生成定制查询概述，遵循覆盖条件。通过自动和人工评估，我们分析了这些概述在增强检索生成中的有效性。实验显示，经过对齐训练的QPlanner能提供满足多样化用户需求的概述。资源已公开在https://github.com/youngerous/qtree。",
    "title_cn": "探索与选择学习：覆盖条件下的检索增强生成",
    "tags": [
      "LLM应用",
      "信息技术",
      "人工智能"
    ]
  },
  {
    "title": "CPT: Consistent Proxy Tuning for Black-box Optimization",
    "submit_datetime": "2024年07月01日",
    "abstract": "Black-box tuning has attracted recent attention due to that the structure or inner parameters of advanced proprietary models are not accessible. Proxy-tuning provides a test-time output adjustment for tuning black-box language models. It applies the difference of the output logits before and after tuning a smaller white-box \"proxy\" model to improve the black-box model. However, this technique serves only as a decoding-time algorithm, leading to an inconsistency between training and testing which potentially limits overall performance. To address this problem, we introduce Consistent Proxy Tuning (CPT), a simple yet effective black-box tuning method. Different from Proxy-tuning, CPT additionally exploits the frozen large black-box model and another frozen small white-box model, ensuring consistency between training-stage optimization objective and test-time proxies. This consistency benefits Proxy-tuning and enhances model performance. Note that our method focuses solely on logit-level computation, which makes it model-agnostic and applicable to any task involving logit classification. Extensive experimental results demonstrate the superiority of our CPT in both black-box tuning of Large Language Models (LLMs) and Vision-Language Models (VLMs) across various datasets. The code is available at https://github.com/chunmeifeng/CPT.",
    "pdf_link": "https://arxiv.org/abs/2407.01155",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.01155v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01155/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01155v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01155/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01155v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01155/x3.png"
      }
    ],
    "abstract_cn": "近期，黑盒调优因高级专有模型的不可访问性而备受瞩目。代理调优通过调整小规模白盒“代理”模型来优化黑盒模型的输出，但仅限于解码阶段，可能导致训练与测试的不一致。为此，我们提出了一致性代理调优（CPT），一种高效的黑盒调优策略。CPT不仅利用了冻结的大型黑盒模型，还结合了小型白盒模型，确保了训练与测试的一致性，从而提升了模型性能。我们的方法专注于对数级计算，具有模型无关性，适用于任何涉及对数分类的任务。实验证明，CPT在大型语言模型和视觉语言模型的黑盒调优中表现卓越。代码已公开，详见https://github.com/chunmeifeng/CPT。",
    "title_cn": "CPT：实现黑盒优化中一致性的代理调优方法",
    "tags": [
      "Agent",
      "人工智能",
      "机器学习"
    ]
  },
  {
    "title": "Calibrated Large Language Models for Binary Question Answering",
    "submit_datetime": "2024年07月01日",
    "abstract": "Quantifying the uncertainty of predictions made by large language models (LLMs) in binary text classification tasks remains a challenge. Calibration, in the context of LLMs, refers to the alignment between the model's predicted probabilities and the actual correctness of its predictions. A well-calibrated model should produce probabilities that accurately reflect the likelihood of its predictions being correct. We propose a novel approach that utilizes the inductive Venn--Abers predictor (IVAP) to calibrate the probabilities associated with the output tokens corresponding to the binary labels. Our experiments on the BoolQ dataset using the Llama 2 model demonstrate that IVAP consistently outperforms the commonly used temperature scaling method for various label token choices, achieving well-calibrated probabilities while maintaining high predictive quality. Our findings contribute to the understanding of calibration techniques for LLMs and provide a practical solution for obtaining reliable uncertainty estimates in binary question answering tasks, enhancing the interpretability and trustworthiness of LLM predictions.",
    "pdf_link": "https://arxiv.org/abs/2407.01122",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.01122v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01122/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01122v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01122/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01122v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01122/ece-boolq-Yes.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01122v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01122/auroc-boolq-Yes_auc_.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01122v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01122/brier-boolq-Yes.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01122v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01122/f1-boolq-Yes.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01122v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01122/ece-sst-Pos.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01122v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01122/auroc-sst-Pos_auc_.png"
      }
    ],
    "abstract_cn": "在二元文本分类任务中，如何量化大型语言模型 (LLM) 预测的不确定性仍是一大难题。我们提出的新方法，利用归纳 Venn-Abers 预测器 (IVAP) 来校准二元标签对应的输出令牌概率，不仅在 BoolQ 数据集上超越了传统温度缩放方法，还确保了预测的高质量和概率的准确校准。这一进展不仅深化了我们对 LLM 校准技术的理解，更为二元问答任务中的不确定性评估提供了实用方案，从而提升了 LLM 预测的可解释性和可靠性。",
    "title_cn": "大型语言模型经过校准，专为二元问答设计",
    "tags": [
      "LLM理论",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Pron vs Prompt: Can Large Language Models already Challenge a World-Class Fiction Author at Creative Text Writing?",
    "submit_datetime": "2024年07月01日",
    "abstract": "It has become routine to report research results where Large Language Models (LLMs) outperform average humans in a wide range of language-related tasks, and creative text writing is no exception. It seems natural, then, to raise the bid: Are LLMs ready to compete in creative writing skills with a top (rather than average) novelist? To provide an initial answer for this question, we have carried out a contest between Patricio Pron (an awarded novelist, considered one of the best of his generation) and GPT-4 (one of the top performing LLMs), in the spirit of AI-human duels such as DeepBlue vs Kasparov and AlphaGo vs Lee Sidol. We asked Pron and GPT-4 to provide thirty titles each, and then to write short stories for both their titles and their opponent's. Then, we prepared an evaluation rubric inspired by Boden's definition of creativity, and we collected 5,400 manual assessments provided by literature critics and scholars. The results of our experimentation indicate that LLMs are still far from challenging a top human creative writer, and that reaching such level of autonomous creative writing skills probably cannot be reached simply with larger language models.",
    "pdf_link": "https://arxiv.org/abs/2407.01119",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.01119v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01119/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01119v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01119/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01119v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01119/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01119v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01119/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01119v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01119/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01119v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01119/x10.png"
      }
    ],
    "abstract_cn": "在众多语言任务中，大型语言模型（LLMs）超越普通人类已成为常态，创意写作也不例外。然而，我们不禁要问：LLMs能否与顶尖小说家一较高下？为此，我们举办了一场AI与人类的创意对决，邀请了获奖小说家Patricio Pron与顶尖模型GPT-4同台竞技。双方各自构思三十个标题，并据此创作故事。我们借鉴Boden的创造力定义制定了评估标准，并收集了5,400份文学专家的评价。结果显示，LLMs在创意写作领域仍远未达到人类顶尖水平，仅凭扩大模型规模或许难以实现这一飞跃。",
    "title_cn": "大型语言模型与世界级小说作者在创意写作上的较量：Pron vs Prompt，究竟谁能胜出？",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "BERGEN: A Benchmarking Library for Retrieval-Augmented Generation",
    "submit_datetime": "2024年07月01日",
    "abstract": "Retrieval-Augmented Generation allows to enhance Large Language Models with external knowledge. In response to the recent popularity of generative LLMs, many RAG approaches have been proposed, which involve an intricate number of different configurations such as evaluation datasets, collections, metrics, retrievers, and LLMs. Inconsistent benchmarking poses a major challenge in comparing approaches and understanding the impact of each component in the pipeline. In this work, we study best practices that lay the groundwork for a systematic evaluation of RAG and present BERGEN, an end-to-end library for reproducible research standardizing RAG experiments. In an extensive study focusing on QA, we benchmark different state-of-the-art retrievers, rerankers, and LLMs. Additionally, we analyze existing RAG metrics and datasets. Our open-source library BERGEN is available under \\url{https://github.com/naver/bergen}.",
    "pdf_link": "https://arxiv.org/abs/2407.01102",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.01102v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01102/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01102v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01102/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01102v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01102/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01102v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01102/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01102v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01102/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01102v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01102/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01102v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01102/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01102v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01102/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01102v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01102/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01102v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01102/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01102v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01102/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01102v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01102/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01102v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01102/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01102v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01102/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01102v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01102/x15.png"
      }
    ],
    "abstract_cn": "Retrieval-Augmented Generation（RAG）通过外部知识增强了大型语言模型。随着生成型 LLM 的兴起，众多 RAG 方法涌现，涵盖了评估数据集、集合、指标、检索器和 LLM 等多种配置。然而，基准测试的不一致性为方法比较和组件影响理解带来了挑战。本研究探索了 RAG 系统评估的最佳实践，并推出了 BERGEN，一个标准化 RAG 实验的端到端开源库。在专注于问答的深入研究中，我们评估了各类顶尖检索器、重排序器和 LLM，并分析了现有 RAG 指标和数据集。BERGEN 库已开放源代码，访问地址为 \\url{https://github.com/naver/bergen}。",
    "title_cn": "BERGEN：一款专为检索增强生成技术打造的基准库",
    "tags": [
      "RAG",
      "问答系统",
      "开源软件"
    ]
  },
  {
    "title": "IBSEN: Director-Actor Agent Collaboration for Controllable and Interactive Drama Script Generation",
    "submit_datetime": "2024年07月01日",
    "abstract": "Large language models have demonstrated their capabilities in storyline creation and human-like character role-playing. Current language model agents mainly focus on reasonable behaviors from the level of individuals, and their behaviors might be hard to constraint on the level of the whole storyline. In this paper we introduce IBSEN, a director-actor coordinate agent framework that generates drama scripts and makes the plot played by agents more controllable. The director agent writes plot outlines that the user desires to see, instructs the actor agents to role-play their characters, and reschedules the plot when human players participate in the scenario to ensure the plot is progressing towards the objective. To evaluate the framework, we create a novel drama plot that involves several actor agents and check the interactions between them under the instruction of the director agent. Evaluation results show that our framework could generate complete, diverse drama scripts from only a rough outline of plot objectives, meanwhile maintaining the characteristics of characters in the drama. Our codes and prompts are available at https://github.com/OpenDFM/ibsen.",
    "pdf_link": "https://arxiv.org/abs/2407.01093",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.01093v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01093/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01093v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01093/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01093v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01093/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01093v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01093/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01093v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01093/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01093v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01093/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01093v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01093/x7.png"
      }
    ],
    "abstract_cn": "大型语言模型在故事创作和角色扮演方面表现出色，但现有代理主要关注个体行为合理性，难以全局控制故事发展。为此，我们提出IBSEN框架，通过导演与演员代理的协作，生成可控的戏剧剧本。导演代理根据用户需求编写情节大纲，指导演员代理进行角色扮演，并根据人类玩家参与情况调整情节，确保故事向预定目标推进。我们通过创建新戏剧情节并观察代理互动来评估框架，结果表明，该框架能从简要大纲生成丰富多样的完整剧本，同时保持角色特性。相关代码和资源已公开在https://github.com/OpenDFM/ibsen。",
    "title_cn": "IBSEN 系统通过导演与演员代理的协作，实现了可控且互动的戏剧剧本生成。",
    "tags": [
      "Agent",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Rethinking LLM-based Preference Evaluation",
    "submit_datetime": "2024年07月01日",
    "abstract": "Recently, large language model (LLM)-based preference evaluation has been widely adopted to compare pairs of model responses. However, a severe bias towards lengthy responses has been observed, raising concerns about the reliability of this evaluation method. In this work, we designed a series of controlled experiments to study the major impacting factors of the metric of LLM-based preference evaluation, i.e., win rate, and conclude that the win rate is affected by two axes of model response: desirability and information mass, where the former is length-independent and related to trustworthiness, and the latter is length-dependent and can be represented by conditional entropy. We find that length impacts the existing evaluations by influencing information mass. However, a reliable evaluation metric should not only assess content quality but also ensure that the assessment is not confounded by extraneous factors such as response length. Therefore, we propose a simple yet effective adjustment, AdapAlpaca, to the existing practice of win rate measurement. Specifically, by adjusting the lengths of reference answers to match the test model's answers within the same interval, we debias information mass relative to length, ensuring a fair model evaluation.",
    "pdf_link": "https://arxiv.org/abs/2407.01085",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.01085v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01085/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01085v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01085/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01085v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01085/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01085v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01085/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01085v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01085/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01085v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01085/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01085v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01085/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01085v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01085/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01085v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01085/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01085v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01085/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01085v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01085/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01085v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01085/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01085v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01085/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01085v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01085/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01085v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01085/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01085v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01085/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01085v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01085/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01085v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01085/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01085v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01085/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01085v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01085/x20.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01085v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01085/gradio_example.png"
      }
    ],
    "abstract_cn": "近期，基于大型语言模型的偏好评估广泛用于比较模型响应对，但存在对长响应的偏差，质疑其可靠性。我们通过控制实验发现，胜率受期望性和信息量两大因素影响，前者与长度无关，后者与长度相关。长度通过信息量影响评估，但可靠指标应独立于长度等无关因素。为此，我们提出AdapAlpaca调整方法，通过匹配参考与测试答案长度，确保评估公平，提升可靠性。",
    "title_cn": "重新审视基于LLM的偏好评估方法",
    "tags": [
      "LLM理论",
      "人工智能",
      ""
    ]
  },
  {
    "title": "First Place Solution of 2023 Global Artificial Intelligence Technology Innovation Competition Track 1",
    "submit_datetime": "2024年07月01日",
    "abstract": "In this paper, we present our champion solution to the Global Artificial Intelligence Technology Innovation Competition Track 1: Medical Imaging Diagnosis Report Generation. We select CPT-BASE as our base model for the text generation task. During the pre-training stage, we delete the mask language modeling task of CPT-BASE and instead reconstruct the vocabulary, adopting a span mask strategy and gradually increasing the number of masking ratios to perform the denoising auto-encoder pre-training task. In the fine-tuning stage, we design iterative retrieval augmentation and noise-aware similarity bucket prompt strategies. The retrieval augmentation constructs a mini-knowledge base, enriching the input information of the model, while the similarity bucket further perceives the noise information within the mini-knowledge base, guiding the model to generate higher-quality diagnostic reports based on the similarity prompts. Surprisingly, our single model has achieved a score of 2.321 on leaderboard A, and the multiple model fusion scores are 2.362 and 2.320 on the A and B leaderboards respectively, securing first place in the rankings.",
    "pdf_link": "https://arxiv.org/abs/2407.01271",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.01271v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01271/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01271v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01271/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01271v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01271/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01271v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01271/x4.png"
      }
    ],
    "abstract_cn": "本文介绍了我们在全球人工智能技术创新竞赛第一赛道——医学影像诊断报告生成中的冠军方案。我们选用CPT-BASE作为基础模型，在预训练阶段，我们摒弃了传统的掩码语言建模，转而采用跨度掩码策略，逐步提升掩码比例，进行去噪自编码预训练。微调阶段，我们创新性地引入了迭代检索增强和噪声感知相似度桶提示策略，构建迷你知识库，丰富模型输入，同时通过相似度桶精准识别噪声，引导模型生成更优质的诊断报告。最终，我们的单模型在A榜上斩获2.321分，多模型融合更是在A、B榜上分别取得2.362和2.320的高分，稳居榜首。",
    "title_cn": "2023年全球AI技术创新大赛第一赛道冠军方案",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "SecGenAI: Enhancing Security of Cloud-based Generative AI Applications within Australian Critical Technologies of National Interest",
    "submit_datetime": "2024年07月01日",
    "abstract": "The rapid advancement of Generative AI (GenAI) technologies offers transformative opportunities within Australia's critical technologies of national interest while introducing unique security challenges. This paper presents SecGenAI, a comprehensive security framework for cloud-based GenAI applications, with a focus on Retrieval-Augmented Generation (RAG) systems. SecGenAI addresses functional, infrastructure, and governance requirements, integrating end-to-end security analysis to generate specifications emphasizing data privacy, secure deployment, and shared responsibility models. Aligned with Australian Privacy Principles, AI Ethics Principles, and guidelines from the Australian Cyber Security Centre and Digital Transformation Agency, SecGenAI mitigates threats such as data leakage, adversarial attacks, and model inversion. The framework's novel approach combines advanced machine learning techniques with robust security measures, ensuring compliance with Australian regulations while enhancing the reliability and trustworthiness of GenAI systems. This research contributes to the field of intelligent systems by providing actionable strategies for secure GenAI implementation in industry, fostering innovation in AI applications, and safeguarding national interests.",
    "pdf_link": "https://arxiv.org/abs/2407.01110",
    "graphs": [],
    "abstract_cn": "生成式AI技术的迅猛发展，为澳大利亚的关键技术领域带来了革新机遇，同时也引发了独特的安全挑战。本文提出的SecGenAI框架，专注于云端GenAI应用，特别是检索增强生成系统，全面涵盖功能、基础设施和治理层面的安全需求。通过整合端到端的安全分析，SecGenAI强调数据隐私、安全部署及共享责任，与澳大利亚的隐私和伦理原则及相关部门指南相契合，有效防范数据泄露、攻击和模型逆向等风险。该框架融合尖端机器学习与强效安全措施，确保合规性，提升GenAI系统的可靠性，为智能系统领域贡献了安全实施策略，推动AI创新，捍卫国家利益。",
    "title_cn": "SecGenAI：提升澳大利亚关键技术领域内云端生成式AI应用的安全防护",
    "tags": [
      "RAG",
      "",
      "云计算"
    ]
  },
  {
    "title": "Eliminating Position Bias of Language Models: A Mechanistic Approach",
    "submit_datetime": "2024年07月01日",
    "abstract": "Position bias has proven to be a prevalent issue of modern language models (LMs), where the models prioritize content based on its position within the given context. This bias often leads to unexpected model failures and hurts performance, robustness, and reliability across various applications. Our mechanistic analysis attributes the position bias to two components employed in nearly all state-of-the-art LMs: causal attention and relative positional encodings. Specifically, we find that causal attention generally causes models to favor distant content, while relative positional encodings like RoPE prefer nearby ones based on the analysis of retrieval-augmented question answering (QA). Further, our empirical study on object detection reveals that position bias is also present in vision-language models (VLMs).\n  Based on the above analyses, we propose to ELIMINATE position bias caused by different input segment orders (e.g., options in LM-as-a-judge, retrieved documents in QA) in a TRAINING-FREE ZERO-SHOT manner. Our method changes the causal attention to bidirectional attention between segments and utilizes model attention values to decide the relative orders of segments instead of using the order provided in input prompts, therefore enabling Position-INvariant inferencE (PINE) at the segment level. By eliminating position bias, models achieve better performance and reliability in downstream tasks where position bias widely exists, such as LM-as-a-judge and retrieval-augmented QA.\n  Notably, PINE is especially useful when adapting LMs for evaluating reasoning pairs: it consistently provides 8 to 10 percentage points performance gains in most cases, and makes Llama-3-70B-Instruct perform even better than GPT-4-0125-preview on the RewardBench reasoning subset.",
    "pdf_link": "https://arxiv.org/abs/2407.01100",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.01100v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01100/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01100v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01100/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01100v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01100/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01100v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01100/x4.png"
      }
    ],
    "abstract_cn": "位置偏差已成为现代语言模型的一大难题，模型往往根据内容在上下文中的位置来优先处理。这种偏差不仅导致模型失灵，还影响了其在多领域的性能和可靠性。我们深入分析发现，几乎所有顶尖语言模型都采用的因果注意力和相对位置编码是位置偏差的根源。具体而言，因果注意力使模型偏爱远距离内容，而相对位置编码则倾向于近距离内容。此外，视觉-语言模型中也存在这一问题。为此，我们提出了一种无需训练的零-shot方法，通过改变因果注意力为段间双向注意力，并利用模型注意力值来重新排序段，从而在段级别实现位置不变推理（PINE）。这一创新方法有效消除了位置偏差，显著提升了模型在需要评估推理对的任务中的性能，甚至在某些情况下超越了GPT-4。",
    "title_cn": "解决语言模型中的位置偏差问题：一种机制性解决方案",
    "tags": [
      "LLM理论",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Face4RAG: Factual Consistency Evaluation for Retrieval Augmented Generation in Chinese",
    "submit_datetime": "2024年07月01日",
    "abstract": "The prevailing issue of factual inconsistency errors in conventional Retrieval Augmented Generation (RAG) motivates the study of Factual Consistency Evaluation (FCE). Despite the various FCE methods proposed earlier, these methods are evaluated on datasets generated by specific Large Language Models (LLMs). Without a comprehensive benchmark, it remains unexplored how these FCE methods perform on other LLMs with different error distributions or even unseen error types, as these methods may fail to detect the error types generated by other LLMs. To fill this gap, in this paper, we propose the first comprehensive FCE benchmark \\emph{Face4RAG} for RAG independent of the underlying LLM. Our benchmark consists of a synthetic dataset built upon a carefully designed typology for factuality inconsistency error and a real-world dataset constructed from six commonly used LLMs, enabling evaluation of FCE methods on specific error types or real-world error distributions. On the proposed benchmark, we discover the failure of existing FCE methods to detect the logical fallacy, which refers to a mismatch of logic structures between the answer and the retrieved reference. To fix this issue, we further propose a new method called \\emph{L-Face4RAG} with two novel designs of logic-preserving answer decomposition and fact-logic FCE. Extensive experiments show L-Face4RAG substantially outperforms previous methods for factual inconsistency detection on a wide range of tasks, notably beyond the RAG task from which it is originally motivated. Both the benchmark and our proposed method are publicly available.\\footnote{\\url{https://huggingface.co/datasets/yq27/Face4RAG}\\label{link_face4rag}}",
    "pdf_link": "https://arxiv.org/abs/2407.01080",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.01080v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01080/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01080v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01080/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01080v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01080/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01080v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01080/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01080v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01080/x5.png"
      }
    ],
    "abstract_cn": "传统RAG模型中常见的事实不一致错误，催生了事实一致性评估（FCE）的研究。尽管已有多种FCE方法，但它们仅在特定LLM生成的数据集上评估，缺乏全面基准，导致这些方法在其他LLM或新错误类型上的表现未被探索。为此，我们提出了首个独立于LLM的RAG事实一致性评估基准Face4RAG，包含合成与真实数据集，支持特定错误类型与真实分布的评估。我们发现现有FCE方法无法识别逻辑谬误，即答案与参考间的逻辑结构不匹配。为此，我们提出了L-Face4RAG方法，通过逻辑保持答案分解与事实逻辑FCE设计，显著提升了事实不一致检测的性能，超越了最初的RAG任务。基准与方法均已公开。",
    "title_cn": "Face4RAG：评估中文检索增强生成的事实一致性工具",
    "tags": [
      "RAG",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Hybrid RAG-empowered Multi-modal LLM for Secure Healthcare Data Management: A Diffusion-based Contract Theory Approach",
    "submit_datetime": "2024年07月01日",
    "abstract": "Secure data management and effective data sharing have become paramount in the rapidly evolving healthcare landscape. The advancement of generative artificial intelligence has positioned Multi-modal Large Language Models (MLLMs) as crucial tools for managing healthcare data. MLLMs can support multi-modal inputs and generate diverse types of content by leveraging large-scale training on vast amounts of multi-modal data. However, critical challenges persist in developing medical MLLMs, including healthcare data security and freshness issues, affecting the output quality of MLLMs. In this paper, we propose a hybrid Retrieval-Augmented Generation (RAG)-empowered medical MLLMs framework for healthcare data management. This framework leverages a hierarchical cross-chain architecture to facilitate secure data training. Moreover, it enhances the output quality of MLLMs through hybrid RAG, which employs multi-modal metrics to filter various unimodal RAG results and incorporates these retrieval results as additional inputs to MLLMs. Additionally, we employ age of information to indirectly evaluate the data freshness impact of MLLMs and utilize contract theory to incentivize healthcare data holders to share fresh data, mitigating information asymmetry in data sharing. Finally, we utilize a generative diffusion model-based reinforcement learning algorithm to identify the optimal contract for efficient data sharing. Numerical results demonstrate the effectiveness of the proposed schemes, which achieve secure and efficient healthcare data management.",
    "pdf_link": "https://arxiv.org/abs/2407.00978",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.00978v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00978/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00978v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00978/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00978v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00978/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00978v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00978/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00978v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00978/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00978v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00978/x6.png"
      }
    ],
    "abstract_cn": "在医疗保健领域，安全的数据管理和有效的数据共享变得至关重要。生成式人工智能的发展使得多模态大型语言模型（MLLMs）成为管理医疗数据的关键工具。然而，开发医疗MLLMs仍面临挑战，如数据安全和新鲜度问题，这些问题影响MLLMs的输出质量。本文提出了一种混合检索增强生成（RAG）赋能的医疗MLLMs框架，用于医疗数据管理。该框架通过分层跨链架构确保安全数据训练，并通过混合RAG提高输出质量，该方法利用多模态指标过滤单模态RAG结果，并将这些结果作为额外输入纳入MLLMs。此外，我们使用信息年龄评估数据新鲜度影响，并利用契约理论激励数据持有者分享新鲜数据，减轻数据共享中的信息不对称。最后，我们利用基于生成扩散模型的强化学习算法来识别高效数据共享的最佳契约。数值结果证明了所提方案的有效性，实现了安全和高效的医疗数据管理。",
    "title_cn": "采用混合 RAG 增强的多模态 LLM，结合基于扩散的合同理论，为安全医疗数据管理提供创新解决方案。",
    "tags": [
      "RAG",
      "",
      "数据管理"
    ]
  },
  {
    "title": "Data on the Move: Traffic-Oriented Data Trading Platform Powered by AI Agent with Common Sense",
    "submit_datetime": "2024年07月01日",
    "abstract": "In the digital era, data has become a pivotal asset, advancing technologies such as autonomous driving. Despite this, data trading faces challenges like the absence of robust pricing methods and the lack of trustworthy trading mechanisms. To address these challenges, we introduce a traffic-oriented data trading platform named Data on The Move (DTM), integrating traffic simulation, data trading, and Artificial Intelligent (AI) agents. The DTM platform supports evident-based data value evaluation and AI-based trading mechanisms. Leveraging the common sense capabilities of Large Language Models (LLMs) to assess traffic state and data value, DTM can determine reasonable traffic data pricing through multi-round interaction and simulations. Moreover, DTM provides a pricing method validation by simulating traffic systems, multi-agent interactions, and the heterogeneity and irrational behaviors of individuals in the trading market. Within the DTM platform, entities such as connected vehicles and traffic light controllers could engage in information collecting, data pricing, trading, and decision-making. Simulation results demonstrate that our proposed AI agent-based pricing approach enhances data trading by offering rational prices, as evidenced by the observed improvement in traffic efficiency. This underscores the effectiveness and practical value of DTM, offering new perspectives for the evolution of data markets and smart cities. To the best of our knowledge, this is the first study employing LLMs in data pricing and a pioneering data trading practice in the field of intelligent vehicles and smart cities.",
    "pdf_link": "https://arxiv.org/abs/2407.00995",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.00995v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00995/life_cycle.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00995v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00995/data_flow.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00995v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00995/agent_module.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00995v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00995/AI_agent_pricing.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00995v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00995/traffic_network.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00995v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00995/accident_occurs.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00995v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00995/trading_system.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00995v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00995/average_waiting_time.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00995v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00995/heatmap.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00995v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00995/price_vs_value.png"
      }
    ],
    "abstract_cn": "在数字化浪潮中，数据如黄金般珍贵，尤其在自动驾驶等尖端技术领域。然而，数据交易之路并非坦途，定价难题和信任缺失是其两大障碍。为此，我们创新推出Data on The Move（DTM）平台，它融合交通模拟、数据交易与AI智能，为数据价值评估和交易机制注入智慧。借助大型语言模型（LLMs）的洞察力，DTM通过多轮互动与模拟，精准定价交通数据。同时，通过模拟交通系统、多角色互动及市场中的个体行为多样性，DTM验证了定价方法的可靠性。在DTM的舞台上，各类交通实体如车联网车辆和交通灯控制器，共同参与信息采集、定价、交易与决策。模拟结果显示，基于AI代理的定价策略，不仅提升了数据交易的合理性，更显著提高了交通效率，彰显了DTM的实效与价值。这一创举，不仅首次将LLMs应用于数据定价，更在智能车联与智慧城市领域，引领了数据交易的新风潮。",
    "title_cn": "数据动态交易：基于常识AI代理的流量导向数据平台",
    "tags": [
      "LLM应用",
      "自动驾驶",
      "智慧城市"
    ]
  },
  {
    "title": "Mobile-Bench: An Evaluation Benchmark for LLM-based Mobile Agents",
    "submit_datetime": "2024年07月01日",
    "abstract": "With the remarkable advancements of large language models (LLMs), LLM-based agents have become a research hotspot in human-computer interaction. However, there is a scarcity of benchmarks available for LLM-based mobile agents. Benchmarking these agents generally faces three main challenges: (1) The inefficiency of UI-only operations imposes limitations to task evaluation. (2) Specific instructions within a singular application lack adequacy for assessing the multi-dimensional reasoning and decision-making capacities of LLM mobile agents. (3) Current evaluation metrics are insufficient to accurately assess the process of sequential actions. To this end, we propose Mobile-Bench, a novel benchmark for evaluating the capabilities of LLM-based mobile agents. First, we expand conventional UI operations by incorporating 103 collected APIs to accelerate the efficiency of task completion. Subsequently, we collect evaluation data by combining real user queries with augmentation from LLMs. To better evaluate different levels of planning capabilities for mobile agents, our data is categorized into three distinct groups: SAST, SAMT, and MAMT, reflecting varying levels of task complexity. Mobile-Bench comprises 832 data entries, with more than 200 tasks specifically designed to evaluate multi-APP collaboration scenarios. Furthermore, we introduce a more accurate evaluation metric, named CheckPoint, to assess whether LLM-based mobile agents reach essential points during their planning and reasoning steps.",
    "pdf_link": "https://arxiv.org/abs/2407.00993",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.00993v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00993/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00993v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00993/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00993v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00993/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00993v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00993/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00993v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00993/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00993v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00993/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00993v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00993/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00993v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00993/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00993v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00993/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00993v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00993/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00993v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00993/x11.png"
      }
    ],
    "abstract_cn": "随着LLM技术的飞速发展，基于LLM的智能代理在人机交互研究中备受瞩目。但遗憾的是，针对这些移动代理的基准测试却寥寥无几。这些测试面临三大难题：一是仅依赖界面操作的效率低下，二是单一应用内的指令无法全面评估代理的复杂推理与决策能力，三是现有评估标准难以准确衡量连续动作的执行过程。为此，我们创新性地推出了Mobile-Bench基准，旨在全面评估LLM移动代理的各项能力。我们通过引入103个API，优化了传统界面操作，大幅提升了任务执行效率。同时，我们精心收集了结合真实用户需求与LLM增强的评估数据，并将其细分为SAST、SAMT和MAMT三个层次，以适应不同难度的任务需求。Mobile-Bench共收录832项数据，其中200余项专为多应用协作场景设计。此外，我们还首创了CheckPoint评估指标，精准判断代理在规划与推理过程中的关键节点。",
    "title_cn": "移动-Bench：一个针对基于 LLM 的移动代理的评估基准",
    "tags": [
      "Agent",
      "人机交互",
      "移动应用"
    ]
  },
  {
    "title": "Human-like object concept representations emerge naturally in multimodal large language models",
    "submit_datetime": "2024年07月01日",
    "abstract": "The conceptualization and categorization of natural objects in the human mind have long intrigued cognitive scientists and neuroscientists, offering crucial insights into human perception and cognition. Recently, the rapid development of Large Language Models (LLMs) has raised the attractive question of whether these models can also develop human-like object representations through exposure to vast amounts of linguistic and multimodal data. In this study, we combined behavioral and neuroimaging analysis methods to uncover how the object concept representations in LLMs correlate with those of humans. By collecting large-scale datasets of 4.7 million triplet judgments from LLM and Multimodal LLM (MLLM), we were able to derive low-dimensional embeddings that capture the underlying similarity structure of 1,854 natural objects. The resulting 66-dimensional embeddings were found to be highly stable and predictive, and exhibited semantic clustering akin to human mental representations. Interestingly, the interpretability of the dimensions underlying these embeddings suggests that LLM and MLLM have developed human-like conceptual representations of natural objects. Further analysis demonstrated strong alignment between the identified model embeddings and neural activity patterns in many functionally defined brain ROIs (e.g., EBA, PPA, RSC and FFA). This provides compelling evidence that the object representations in LLMs, while not identical to those in the human, share fundamental commonalities that reflect key schemas of human conceptual knowledge. This study advances our understanding of machine intelligence and informs the development of more human-like artificial cognitive systems.",
    "pdf_link": "https://arxiv.org/abs/2407.01067",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.01067v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01067/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01067v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01067/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01067v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01067/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01067v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01067/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01067v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01067/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01067v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01067/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01067v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01067/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01067v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01067/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01067v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01067/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01067v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01067/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01067v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01067/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01067v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01067/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01067v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01067/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01067v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01067/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01067v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01067/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01067v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01067/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01067v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01067/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01067v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01067/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01067v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01067/x19.png"
      }
    ],
    "abstract_cn": "人类对自然物体的概念化与分类一直是认知科学和神经科学的研究热点，揭示了人类感知与认知的核心机制。随着大型语言模型（LLMs）的迅猛发展，一个引人入胜的问题浮现：这些模型能否通过海量语言与多模态数据的输入，形成类似人类的物体认知？本研究通过行为与神经影像分析，探索了LLMs中物体概念的表示与人类认知的契合度。我们收集了470万个来自LLM与多模态LLM（MLLM）的三元组判断，构建了1,854个自然物体的低维嵌入，这些66维嵌入不仅稳定且富有预测性，更呈现出与人类心理相似的语义聚类。令人瞩目的是，这些嵌入的维度清晰可解，暗示LLM与MLLM已形成类似人类的概念性物体认知。深入分析表明，模型嵌入与大脑多个功能区域的神经活动模式高度吻合，证实了LLMs的物体表示虽与人类不尽相同，却共享着反映人类概念知识核心结构的基本共性。这项研究深化了我们对机器智能的认识，并为构建更贴近人类的人工认知系统提供了宝贵洞见。",
    "title_cn": "多模态大型语言模型中，类人对象概念的表示自然而然地形成。",
    "tags": [
      "LLM理论",
      "认知科学",
      "神经科学"
    ]
  },
  {
    "title": "Empathic Grounding: Explorations using Multimodal Interaction and Large Language Models with Conversational Agents",
    "submit_datetime": "2024年07月01日",
    "abstract": "We introduce the concept of \"empathic grounding\" in conversational agents as an extension of Clark's conceptualization of grounding in conversation in which the grounding criterion includes listener empathy for the speaker's affective state. Empathic grounding is generally required whenever the speaker's emotions are foregrounded and can make the grounding process more efficient and reliable by communicating both propositional and affective understanding. Both speaker expressions of affect and listener empathic grounding can be multimodal, including facial expressions and other nonverbal displays. Thus, models of empathic grounding for embodied agents should be multimodal to facilitate natural and efficient communication. We describe a multimodal model that takes as input user speech and facial expression to generate multimodal grounding moves for a listening agent using a large language model. We also describe a testbed to evaluate approaches to empathic grounding, in which a humanoid robot interviews a user about a past episode of pain and then has the user rate their perception of the robot's empathy. We compare our proposed model to one that only generates non-affective grounding cues in a between-subjects experiment. Findings demonstrate that empathic grounding increases user perceptions of empathy, understanding, emotional intelligence, and trust. Our work highlights the role of emotion awareness and multimodality in generating appropriate grounding moves for conversational agents.",
    "pdf_link": "https://arxiv.org/abs/2407.01824",
    "graphs": [],
    "abstract_cn": "我们提出了“共情基础”概念，扩展了Clark的对话基础理论，强调听众需理解说话者的情感状态。当说话者情绪突出时，共情基础尤为重要，它通过传递命题和情感理解，使沟通更高效可靠。情感表达和共情反应均可多模态化，涉及面部表情等非言语信号。因此，具身代理的共情模型应多模态化，以促进自然沟通。我们构建了一个多模态模型，结合用户的话语和面部表情，利用大型语言模型生成多模态的共情反应。此外，我们设计了一个测试平台，通过人形机器人访谈用户过去的痛苦经历，并由用户评价机器人的共情表现。实验对比显示，共情基础显著提升了用户对共情、理解、情绪智力和信任的感知。我们的研究凸显了情绪意识和多模态在对话代理中生成有效反应的重要性。",
    "title_cn": "共情基础探索：通过多模态交互与大型语言模型，与对话代理共同探索共情机制。",
    "tags": [
      "Agent",
      "人机交互",
      "情感计算"
    ]
  },
  {
    "title": "Ground Every Sentence: Improving Retrieval-Augmented LLMs with Interleaved Reference-Claim Generation",
    "submit_datetime": "2024年07月01日",
    "abstract": "Retrieval-Augmented Generation (RAG) has been widely adopted to enhance Large Language Models (LLMs) in knowledge-intensive tasks. Recently, Attributed Text Generation (ATG) has attracted growing attention, which provides citations to support the model's responses in RAG, so as to enhance the credibility of LLM-generated content and facilitate verification. Prior methods mainly adopt coarse-grained attributions, linking to passage-level references or providing paragraph-level citations. However, these methods still fall short in verifiability and require certain time costs for fact checking. This paper proposes a fine-grained ATG method called ReClaim(Refer & Claim), which alternates the generation of references and answers step by step. Unlike traditional coarse-grained attribution, ReClaim allows the model to add sentence-level fine-grained citations to each answer sentence in long-form question-answering tasks. Our experiments encompass various training and inference methods and multiple LLMs, verifying the effectiveness of our approach.",
    "pdf_link": "https://arxiv.org/abs/2407.01796",
    "graphs": [],
    "abstract_cn": "RAG 在知识密集型任务中广泛用于提升 LLM 性能。近期，ATG 通过提供引用支持模型响应，增强了生成内容可信度。传统方法多采用粗粒度归属，存在可验证性不足和核查时间成本高的问题。本文提出的 ReClaim 方法，通过细粒度引用，在长篇问答中为每个答案句子提供精确引用，实验证明其有效性。",
    "title_cn": "每一句都夯实：通过交错引用与声明生成，提升检索增强型大型语言模型的性能",
    "tags": [
      "RAG",
      "问答系统",
      "知识密集型任务"
    ]
  },
  {
    "title": "Text-Aware Diffusion for Policy Learning",
    "submit_datetime": "2024年07月01日",
    "abstract": "Training an agent to achieve particular goals or perform desired behaviors is often accomplished through reinforcement learning, especially in the absence of expert demonstrations. However, supporting novel goals or behaviors through reinforcement learning requires the ad-hoc design of appropriate reward functions, which quickly becomes intractable. To address this challenge, we propose Text-Aware Diffusion for Policy Learning (TADPoLe), which uses a pretrained, frozen text-conditioned diffusion model to compute dense zero-shot reward signals for text-aligned policy learning. We hypothesize that large-scale pretrained generative models encode rich priors that can supervise a policy to behave not only in a text-aligned manner, but also in alignment with a notion of naturalness summarized from internet-scale training data. In our experiments, we demonstrate that TADPoLe is able to learn policies for novel goal-achievement and continuous locomotion behaviors specified by natural language, in both Humanoid and Dog environments. The behaviors are learned zero-shot without ground-truth rewards or expert demonstrations, and are qualitatively more natural according to human evaluation. We further show that TADPoLe performs competitively when applied to robotic manipulation tasks in the Meta-World environment.",
    "pdf_link": "https://arxiv.org/abs/2407.01903",
    "graphs": [],
    "abstract_cn": "通过强化学习训练代理实现特定目标或行为，尤其是在缺乏专家演示时，通常需要临时设计奖励函数，这很快变得复杂。为此，我们引入了文本感知扩散策略学习（TADPoLe），利用预训练的文本条件扩散模型生成零-shot奖励信号，促进文本对齐策略的学习。我们相信，大规模预训练模型蕴含的丰富先验知识，不仅能指导策略与文本一致，还能与互联网数据中提炼的自然性相契合。实验证明，TADPoLe能在不同环境中，无需真实奖励或专家演示，零-shot学习自然语言描述的新目标和连续运动行为，且在人类评估中表现更自然。此外，TADPoLe在机器人操作任务中也展现出竞争力。",
    "title_cn": "文本感知扩散在政策学习中的应用",
    "tags": [
      "Agent",
      "机器人",
      "人工智能"
    ]
  },
  {
    "title": "GRASP: A Grid-Based Benchmark for Evaluating Commonsense Spatial Reasoning",
    "submit_datetime": "2024年07月01日",
    "abstract": "Spatial reasoning, an important faculty of human cognition with many practical applications, is one of the core commonsense skills that is not purely language-based and, for satisfying (as opposed to optimal) solutions, requires some minimum degree of planning. Existing benchmarks of Commonsense Spatial Reasoning (CSR) tend to evaluate how Large Language Models (LLMs) interpret text-based spatial descriptions rather than directly evaluate a plan produced by the LLM in response to a spatial reasoning scenario. In this paper, we construct a large-scale benchmark called $\\textbf{GRASP}$, which consists of 16,000 grid-based environments where the agent is tasked with an energy collection problem. These environments include 100 grid instances instantiated using each of the 160 different grid settings, involving five different energy distributions, two modes of agent starting position, and two distinct obstacle configurations, as well as three kinds of agent constraints. Using GRASP, we compare classic baseline approaches, such as random walk and greedy search methods, with advanced LLMs like GPT-3.5-Turbo and GPT-4o. The experimental results indicate that even these advanced LLMs struggle to consistently achieve satisfactory solutions.",
    "pdf_link": "https://arxiv.org/abs/2407.01892",
    "graphs": [],
    "abstract_cn": "空间推理，这一人类认知的关键能力，不仅应用广泛，而且是常识技能的核心组成部分，它超越了纯粹的语言依赖，要求一定程度的规划以达成可行（而非最优）方案。当前的常识空间推理（CSR）评估往往聚焦于大型语言模型（LLM）对文本空间描述的解读，而非直接检验其针对空间推理挑战所制定的计划。为此，我们创建了名为$\\textbf{GRASP}$的大规模基准，涵盖16,000个网格环境，每个环境设定代理解决能量收集问题。这些环境细分为100个实例，每实例基于160种独特网格配置，涉及五类能量分布、两种起始位置、两类障碍布局及三种代理限制。通过GRASP，我们对比了传统方法（如随机游走与贪心搜索）与尖端LLM（如GPT-3.5-Turbo和GPT-4o）的表现。实验揭示，即便是最先进的LLM，在持续提供满意解方面也面临挑战。",
    "title_cn": "GRASP：一款基于网格的基准测试，专为评估常识空间推理能力而设计。",
    "tags": [
      "Agent",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Large Language Models Struggle in Token-Level Clinical Named Entity Recognition",
    "submit_datetime": "2024年06月30日",
    "abstract": "Large Language Models (LLMs) have revolutionized various sectors, including healthcare where they are employed in diverse applications. Their utility is particularly significant in the context of rare diseases, where data scarcity, complexity, and specificity pose considerable challenges. In the clinical domain, Named Entity Recognition (NER) stands out as an essential task and it plays a crucial role in extracting relevant information from clinical texts. Despite the promise of LLMs, current research mostly concentrates on document-level NER, identifying entities in a more general context across entire documents, without extracting their precise location. Additionally, efforts have been directed towards adapting ChatGPT for token-level NER. However, there is a significant research gap when it comes to employing token-level NER for clinical texts, especially with the use of local open-source LLMs. This study aims to bridge this gap by investigating the effectiveness of both proprietary and local LLMs in token-level clinical NER. Essentially, we delve into the capabilities of these models through a series of experiments involving zero-shot prompting, few-shot prompting, retrieval-augmented generation (RAG), and instruction-fine-tuning. Our exploration reveals the inherent challenges LLMs face in token-level NER, particularly in the context of rare diseases, and suggests possible improvements for their application in healthcare. This research contributes to narrowing a significant gap in healthcare informatics and offers insights that could lead to a more refined application of LLMs in the healthcare sector.",
    "pdf_link": "https://arxiv.org/abs/2407.00731",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.00731v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00731/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00731v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00731/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00731v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00731/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00731v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00731/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00731v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00731/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00731v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00731/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00731v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00731/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00731v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00731/x8.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLM）在医疗保健等领域的革新尤为显著，尤其是在罕见疾病的数据稀缺、复杂性和特异性挑战下。临床领域的命名实体识别（NER）是提取临床文本信息的关键任务。尽管LLM潜力巨大，但研究多聚焦于文档级NER，忽略了实体的精确位置。此外，ChatGPT在令牌级NER的适应性也受到关注。然而，本地开源LLM在临床文本令牌级NER的应用研究尚存空白。本研究通过对比专有与本地LLM在令牌级临床NER的有效性，填补了这一研究空白。我们通过零-shot、少-shot提示、RAG及指令微调等实验，深入分析了LLM在令牌级NER的挑战，特别是在罕见疾病领域，并提出了改进方向。这项研究不仅缩小了医疗信息学的研究差距，还为LLM在医疗保健领域的精细化应用提供了新视角。",
    "title_cn": "大型语言模型在处理标记级别的临床命名实体识别任务时显得力不从心。",
    "tags": [
      "LLM应用",
      "",
      "信息学"
    ]
  },
  {
    "title": "CAMON: Cooperative Agents for Multi-Object Navigation with LLM-based Conversations",
    "submit_datetime": "2024年06月30日",
    "abstract": "Visual navigation tasks are critical for household service robots. As these tasks become increasingly complex, effective communication and collaboration among multiple robots become imperative to ensure successful completion. In recent years, large language models (LLMs) have exhibited remarkable comprehension and planning abilities in the context of embodied agents. However, their application in household scenarios, specifically in the use of multiple agents collaborating to complete complex navigation tasks through communication, remains unexplored. Therefore, this paper proposes a framework for decentralized multi-agent navigation, leveraging LLM-enabled communication and collaboration. By designing the communication-triggered dynamic leadership organization structure, we achieve faster team consensus with fewer communication instances, leading to better navigation effectiveness and collaborative exploration efficiency. With the proposed novel communication scheme, our framework promises to be conflict-free and robust in multi-object navigation tasks, even when there is a surge in team size.",
    "pdf_link": "https://arxiv.org/abs/2407.00632",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.00632v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00632/x1.png"
      }
    ],
    "abstract_cn": "家用服务机器人的视觉导航任务至关重要，随着任务复杂性增加，多机器人间的有效沟通与协作变得不可或缺。尽管大型语言模型（LLM）在实体代理中展现出卓越的理解与规划能力，但其在家庭环境中，特别是多代理通过协作完成复杂导航任务的应用，仍属未知领域。为此，本文提出一种基于LLM的分散式多代理导航框架，通过创新沟通触发动态领导结构，实现快速团队共识与高效沟通，显著提升导航与协作效率。该框架采用的新型沟通方案，确保在多对象导航任务中无冲突且稳定，即便团队规模扩大亦能保持性能。",
    "title_cn": "CAMON：多对象导航中基于 LLM 对话的合作代理",
    "tags": [
      "Agent",
      "机器人",
      "智能家居"
    ]
  },
  {
    "title": "Quantum State Transfer via a Multimode Resonator",
    "submit_datetime": "2024年06月30日",
    "abstract": "Large-scale fault-tolerant superconducting quantum computation needs rapid quantum communication to network qubits fabricated on different chips and long-range couplers to implement efficient quantum error-correction codes. Quantum channels used for these purposes are best modeled by multimode resonators, which lie between single-mode cavities and waveguides with a continuum of modes. In this Letter, we propose a formalism for quantum state transfer using coupling strengths comparable to the channel's free spectral range ($g\\simΔ_{\\text{fsr}}$). Our scheme merges features of both the STIRAP-based methods for single-model cavities and the pitch-and-catch protocol for long waveguides, integrating their advantage of low loss and high speed.",
    "pdf_link": "https://arxiv.org/abs/2407.00683",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.00683v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00683/figsys.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00683v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00683/fig_off.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00683v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00683/fig_on.png"
      }
    ],
    "abstract_cn": "大规模容错超导量子计算要求快速量子通信连接不同芯片上的量子比特，并需要长程耦合器来执行高效的量子错误校正。为此，量子通道的最佳模型是介于单模腔和连续模式波导之间的多模谐振器。本文提出了一种量子态传输方法，其耦合强度与通道的自由光谱范围相当（$g\\simΔ_{\\text{fsr}}$）。该方案结合了基于STIRAP的单模腔方法和长波导抛接协议的优点，实现了低损耗和高速度的传输。",
    "title_cn": "多模谐振器实现量子态传输",
    "tags": [
      "Agent",
      "量子计算",
      "通信技术"
    ]
  },
  {
    "title": "GenderBias-\\emph{VL}: Benchmarking Gender Bias in Vision Language Models via Counterfactual Probing",
    "submit_datetime": "2024年06月30日",
    "abstract": "Large Vision-Language Models (LVLMs) have been widely adopted in various applications; however, they exhibit significant gender biases. Existing benchmarks primarily evaluate gender bias at the demographic group level, neglecting individual fairness, which emphasizes equal treatment of similar individuals. This research gap limits the detection of discriminatory behaviors, as individual fairness offers a more granular examination of biases that group fairness may overlook. For the first time, this paper introduces the GenderBias-\\emph{VL} benchmark to evaluate occupation-related gender bias in LVLMs using counterfactual visual questions under individual fairness criteria. To construct this benchmark, we first utilize text-to-image diffusion models to generate occupation images and their gender counterfactuals. Subsequently, we generate corresponding textual occupation options by identifying stereotyped occupation pairs with high semantic similarity but opposite gender proportions in real-world statistics. This method enables the creation of large-scale visual question counterfactuals to expose biases in LVLMs, applicable in both multimodal and unimodal contexts through modifying gender attributes in specific modalities. Overall, our GenderBias-\\emph{VL} benchmark comprises 34,581 visual question counterfactual pairs, covering 177 occupations. Using our benchmark, we extensively evaluate 15 commonly used open-source LVLMs (\\eg, LLaVA) and state-of-the-art commercial APIs, including GPT-4o and Gemini-Pro. Our findings reveal widespread gender biases in existing LVLMs. Our benchmark offers: (1) a comprehensive dataset for occupation-related gender bias evaluation; (2) an up-to-date leaderboard on LVLM biases; and (3) a nuanced understanding of the biases presented by these models. \\footnote{The dataset and code are available at the \\href{https://genderbiasvl.github.io/}{website}.}",
    "pdf_link": "https://arxiv.org/abs/2407.00600",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.00600v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00600/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00600v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00600/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00600v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00600/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00600v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00600/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00600v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00600/x5.png"
      }
    ],
    "abstract_cn": "大型视觉-语言模型（LVLMs）虽广泛应用，却存在显著性别偏见。现有评估多聚焦于群体层面，忽视了个体公平性。本研究填补空白，首次推出GenderBias-VL基准，以反事实视觉问题深入剖析LVLMs的职业性别偏见。通过创新方法，我们构建了包含34,581对反事实的基准，覆盖177个职业，全面评估了15个开源模型及商业API。研究发现，LVLMs普遍偏见严重。我们的基准不仅提供详尽数据集和最新排行榜，更深化了对模型偏见的理解。",
    "title_cn": "GenderBias-VL：利用反事实探针评估视觉语言模型中的性别偏见",
    "tags": [
      "LLM应用",
      "人工智能",
      "性别研究"
    ]
  },
  {
    "title": "Macroeconomic Forecasting with Large Language Models",
    "submit_datetime": "2024年06月30日",
    "abstract": "This paper presents a comparative analysis evaluating the accuracy of Large Language Models (LLMs) against traditional macro time series forecasting approaches. In recent times, LLMs have surged in popularity for forecasting due to their ability to capture intricate patterns in data and quickly adapt across very different domains. However, their effectiveness in forecasting macroeconomic time series data compared to conventional methods remains an area of interest. To address this, we conduct a rigorous evaluation of LLMs against traditional macro forecasting methods, using as common ground the FRED-MD database. Our findings provide valuable insights into the strengths and limitations of LLMs in forecasting macroeconomic time series, shedding light on their applicability in real-world scenarios",
    "pdf_link": "https://arxiv.org/abs/2407.00890",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.00890v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00890/FIGURE_BOXPLOT_LLM_ONLY_XLARGE.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00890v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00890/FIGURE_BOXPLOT_ECNMTR_PLUS_BEST_LLM_XLARGE.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00890v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00890/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00890v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00890/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00890v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00890/FIGURE_COVID_BOXPLOT_LLM_ONLY_XLARGE.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00890v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00890/FIGURE_COVID_BOXPLOT_ECNMTR_PLUS_BEST_LLM_XLARGE.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00890v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00890/FIGURE_BOXPLOT_ECNMTR_PLUS_BEST_LLM_TCODE1__XLARGE.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00890v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00890/FIGURE_BOXPLOT_ECNMTR_PLUS_BEST_LLM_TCODE5__XLARGE.png"
      }
    ],
    "abstract_cn": "本文通过比较分析，探讨了大型语言模型（LLM）与传统宏观时间序列预测方法的准确性。LLM 因能捕捉复杂数据模式并快速适应不同领域，近年来在预测领域备受青睐。但与传统方法相比，LLM 在宏观经济时间序列预测的有效性仍待探讨。为此，我们以 FRED-MD 数据库为基准，对 LLM 与传统方法进行了严格对比。研究结果揭示了 LLM 在宏观经济预测中的优势与局限，为其在实际应用中的可行性提供了重要见解。",
    "title_cn": "利用大型语言模型预测宏观经济",
    "tags": [
      "LLM应用",
      "宏观经济",
      "时间序列分析"
    ]
  },
  {
    "title": "Large Language Models Are Involuntary Truth-Tellers: Exploiting Fallacy Failure for Jailbreak Attacks",
    "submit_datetime": "2024年06月30日",
    "abstract": "We find that language models have difficulties generating fallacious and deceptive reasoning. When asked to generate deceptive outputs, language models tend to leak honest counterparts but believe them to be false. Exploiting this deficiency, we propose a jailbreak attack method that elicits an aligned language model for malicious output. Specifically, we query the model to generate a fallacious yet deceptively real procedure for the harmful behavior. Since a fallacious procedure is generally considered fake and thus harmless by LLMs, it helps bypass the safeguard mechanism. Yet the output is factually harmful since the LLM cannot fabricate fallacious solutions but proposes truthful ones. We evaluate our approach over five safety-aligned large language models, comparing four previous jailbreak methods, and show that our approach achieves competitive performance with more harmful outputs. We believe the findings could be extended beyond model safety, such as self-verification and hallucination.",
    "pdf_link": "https://arxiv.org/abs/2407.00869",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.00869v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00869/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00869v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00869/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00869v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00869/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00869v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00869/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00869v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00869/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00869v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00869/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00869v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00869/x7.png"
      }
    ],
    "abstract_cn": "语言模型在生成谬误和欺骗性推理时显得力不从心。面对生成欺骗性输出的任务，它们往往不经意间透露出真实信息，却误以为这些信息是虚假的。基于这一弱点，我们设计了一种“越狱”攻击策略，诱使对齐的语言模型输出恶意内容。具体操作是，让模型编造一个看似合理实则谬误的有害行为流程。由于LLM通常将谬误视为无害的虚假信息，这巧妙地避开了安全防护。然而，由于模型无法真正创造谬误，其提出的解决方案实际上是有害的。我们在五个安全对齐的大型语言模型上测试了这一方法，与四种现有越狱技术对比，结果显示我们的方法在产生更有害输出方面表现出色。这些发现不仅限于模型安全领域，还可能应用于自我验证和幻觉等领域。",
    "title_cn": "大型语言模型无意中揭示真相，我们正利用其逻辑漏洞发起越狱攻击。",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Exploring a Physics-Informed Decision Transformer for Distribution System Restoration: Methodology and Performance Analysis",
    "submit_datetime": "2024年06月30日",
    "abstract": "Driven by advancements in sensing and computing, deep reinforcement learning (DRL)-based methods have demonstrated significant potential in effectively tackling distribution system restoration (DSR) challenges under uncertain operational scenarios. However, the data-intensive nature of DRL poses obstacles in achieving satisfactory DSR solutions for large-scale, complex distribution systems. Inspired by the transformative impact of emerging foundation models, including large language models (LLMs), across various domains, this paper explores an innovative approach harnessing LLMs' powerful computing capabilities to address scalability challenges inherent in conventional DRL methods for solving DSR. To our knowledge, this study represents the first exploration of foundation models, including LLMs, in revolutionizing conventional DRL applications in power system operations. Our contributions are twofold: 1) introducing a novel LLM-powered Physics-Informed Decision Transformer (PIDT) framework that leverages LLMs to transform conventional DRL methods for DSR operations, and 2) conducting comparative studies to assess the performance of the proposed LLM-powered PIDT framework at its initial development stage for solving DSR problems. While our primary focus in this paper is on DSR operations, the proposed PIDT framework can be generalized to optimize sequential decision-making across various power system operations.",
    "pdf_link": "https://arxiv.org/abs/2407.00808",
    "graphs": [],
    "abstract_cn": "随着传感与计算技术的飞跃，基于深度强化学习的策略在应对复杂多变的配电系统恢复挑战中崭露头角。但DRL对数据的依赖性，为解决大规模复杂系统的DSR问题带来了难题。借鉴大型语言模型等基础模型在多领域的革新力量，本文提出了一种新思路，即借助LLMs的强大计算力，突破传统DRL在DSR中的可扩展性瓶颈。本研究首次尝试将LLMs等基础模型引入电力系统运营，以重塑DRL的应用。我们的创新点包括：1）开发了一个由LLM赋能的物理信息决策变换器框架，旨在革新传统DRL的DSR方法；2）在框架初创阶段，通过对比研究评估其解决DSR问题的性能。尽管本文聚焦于DSR操作，该PIDT框架同样适用于优化电力系统中的序列决策过程。",
    "title_cn": "探索基于物理信息的决策转换器在配电系统恢复中的应用：方法与性能分析",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Step-Controlled DPO: Leveraging Stepwise Error for Enhanced Mathematical Reasoning",
    "submit_datetime": "2024年06月30日",
    "abstract": "Direct Preference Optimization (DPO) has proven effective at improving the performance of large language models (LLMs) on downstream tasks such as reasoning and alignment. In this work, we propose Step-Controlled DPO (SCDPO), a method for automatically providing stepwise error supervision by creating negative samples of mathematical reasoning rationales that start making errors at a specified step. By applying these samples in DPO training, SCDPO can better align the model to understand reasoning errors and output accurate reasoning steps. We apply SCDPO to both code-integrated and chain-of-thought solutions, empirically showing that it consistently improves the performance compared to naive DPO on three different SFT models, including one existing SFT model and two models we finetuned. Qualitative analysis of the credit assignment of SCDPO and DPO demonstrates the effectiveness of SCDPO at identifying errors in mathematical solutions. We then apply SCDPO to an InternLM2-20B model, resulting in a 20B model that achieves high scores of 88.5% on GSM8K and 58.1% on MATH, rivaling all other open-source LLMs, showing the great potential of our method.",
    "pdf_link": "https://arxiv.org/abs/2407.00782",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.00782v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00782/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00782v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00782/gsm8k_16_1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00782v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00782/math_2_4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00782v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00782/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00782v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00782/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00782v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00782/gsm8k_5_11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00782v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00782/gsm8k_6_1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00782v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00782/math_8_1.png"
      }
    ],
    "abstract_cn": "直接偏好优化 (DPO) 在提升大型语言模型 (LLM) 的推理和对齐能力方面已见成效。我们提出的步骤控制 DPO (SCDPO)，通过生成特定步骤开始出错的数学推理负样本来实现自动化的逐步错误监督，从而在 DPO 训练中帮助模型更精准地识别和纠正推理错误。实证研究表明，SCDPO 在代码集成和思维链解决方案中均优于传统 DPO，显著提升了三个 SFT 模型的性能。定性分析进一步证实了 SCDPO 在精准定位数学解题错误方面的优势。应用 SCDPO 于 InternLM2-20B 模型，使其在 GSM8K 和 MATH 测试中分别达到 88.5% 和 58.1% 的高分，彰显了我们方法的强大潜力。",
    "title_cn": "通过步骤控制DPO，我们利用逐步错误来提升数学推理能力。",
    "tags": [
      "LLM应用",
      "软件开发",
      ""
    ]
  },
  {
    "title": "A Comparative Study of Quality Evaluation Methods for Text Summarization",
    "submit_datetime": "2024年06月30日",
    "abstract": "Evaluating text summarization has been a challenging task in natural language processing (NLP). Automatic metrics which heavily rely on reference summaries are not suitable in many situations, while human evaluation is time-consuming and labor-intensive. To bridge this gap, this paper proposes a novel method based on large language models (LLMs) for evaluating text summarization. We also conducts a comparative study on eight automatic metrics, human evaluation, and our proposed LLM-based method. Seven different types of state-of-the-art (SOTA) summarization models were evaluated. We perform extensive experiments and analysis on datasets with patent documents. Our results show that LLMs evaluation aligns closely with human evaluation, while widely-used automatic metrics such as ROUGE-2, BERTScore, and SummaC do not and also lack consistency. Based on the empirical comparison, we propose a LLM-powered framework for automatically evaluating and improving text summarization, which is beneficial and could attract wide attention among the community.",
    "pdf_link": "https://arxiv.org/abs/2407.00747",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.00747v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00747/Framework-Summarization_Quality.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00747v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00747/screenshot_appen_interface.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00747v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00747/word_count_distribution_entireDS.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00747v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00747/word_count_distribution_evalsample.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00747v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00747/x1.png"
      }
    ],
    "abstract_cn": "在 NLP 领域，评估文本摘要一直是个难题。依赖参考摘要的自动指标常不适用，而人工评估成本高昂。为此，我们提出了一种基于 LLM 的新方法。通过对比八种自动指标、人工评估及我们的 LLM 方法，我们评估了七种 SOTA 摘要模型。实验表明，LLM 评估与人工评估高度吻合，而常用自动指标如 ROUGE-2、BERTScore 和 SummaC 则表现不佳。基于这些发现，我们设计了一个 LLM 驱动的框架，旨在自动评估和提升文本摘要质量，预计将受到社区的广泛关注。",
    "title_cn": "文本摘要质量评估方法比较研究",
    "tags": [
      "LLM应用",
      "",
      "文本摘要"
    ]
  },
  {
    "title": "LLM4GEN: Leveraging Semantic Representation of LLMs for Text-to-Image Generation",
    "submit_datetime": "2024年06月30日",
    "abstract": "Diffusion Models have exhibited substantial success in text-to-image generation. However, they often encounter challenges when dealing with complex and dense prompts that involve multiple objects, attribute binding, and long descriptions. This paper proposes a framework called \\textbf{LLM4GEN}, which enhances the semantic understanding ability of text-to-image diffusion models by leveraging the semantic representation of Large Language Models (LLMs). Through a specially designed Cross-Adapter Module (CAM) that combines the original text features of text-to-image models with LLM features, LLM4GEN can be easily incorporated into various diffusion models as a plug-and-play component and enhances text-to-image generation. Additionally, to facilitate the complex and dense prompts semantic understanding, we develop a LAION-refined dataset, consisting of 1 million (M) text-image pairs with improved image descriptions. We also introduce DensePrompts which contains 7,000 dense prompts to provide a comprehensive evaluation for the text-to-image generation task. With just 10\\% of the training data required by recent ELLA, LLM4GEN significantly improves the semantic alignment of SD1.5 and SDXL, demonstrating increases of 7.69\\% and 9.60\\% in color on T2I-CompBench, respectively. The extensive experiments on DensePrompts also demonstrate that LLM4GEN surpasses existing state-of-the-art models in terms of sample quality, image-text alignment, and human evaluation. The project website is at: \\textcolor{magenta}{\\url{https://xiaobul.github.io/LLM4GEN/}}",
    "pdf_link": "https://arxiv.org/abs/2407.00737",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.00737v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00737/intro-1.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.00737v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00737/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00737v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00737/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00737v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00737/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00737v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00737/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00737v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00737/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00737v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00737/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00737v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00737/userstudy-chart.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00737v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00737/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00737v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00737/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00737v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00737/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00737v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00737/para_comp.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00737v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00737/ella.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00737v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00737/controlnet.jpg"
      }
    ],
    "abstract_cn": "扩散模型在文本到图像生成领域取得了显著成就，但在处理复杂密集的提示时仍面临挑战。为此，我们提出了 **LLM4GEN** 框架，通过结合大型语言模型的语义表示，显著提升了文本到图像扩散模型的语义理解能力。借助特制的交叉适配器模块 (CAM)，LLM4GEN 能无缝融入各类扩散模型，实现即插即用的增强效果。为深化对复杂提示的理解，我们构建了 LAION-refined 数据集，包含百万级改进描述的文本-图像对，并引入了 DensePrompts 以全面评估生成任务。实验显示，仅用 ELLA 所需训练数据的 10%，LLM4GEN 便大幅提升了 SD1.5 和 SDXL 的语义对齐，颜色表现分别提升 7.69% 和 9.60%。在 DensePrompts 上的广泛测试进一步证明，LLM4GEN 在样本质量、图像-文本对齐及人类评估方面均超越了现有顶尖模型。项目详情请访问：\\textcolor{magenta}{\\url{https://xiaobul.github.io/LLM4GEN/}}",
    "title_cn": "LLM4GEN：借助 LLM 的语义表征实现文本至图像的生成",
    "tags": [
      "LLM应用",
      "图像生成",
      "人工智能"
    ]
  },
  {
    "title": "Scaling Technology Acceptance Analysis with Large Language Model (LLM) Annotation Systems",
    "submit_datetime": "2024年06月30日",
    "abstract": "Technology acceptance models effectively predict how users will adopt new technology products. Traditional surveys, often expensive and cumbersome, are commonly used for this assessment. As an alternative to surveys, we explore the use of large language models for annotating online user-generated content, like digital reviews and comments. Our research involved designing an LLM annotation system that transform reviews into structured data based on the Unified Theory of Acceptance and Use of Technology model. We conducted two studies to validate the consistency and accuracy of the annotations. Results showed moderate-to-strong consistency of LLM annotation systems, improving further by lowering the model temperature. LLM annotations achieved close agreement with human expert annotations and outperformed the agreement between experts for UTAUT variables. These results suggest that LLMs can be an effective tool for analyzing user sentiment, offering a practical alternative to traditional survey methods and enabling deeper insights into technology design and adoption.",
    "pdf_link": "https://arxiv.org/abs/2407.00702",
    "graphs": [],
    "abstract_cn": "技术接受模型能有效预测用户对新技术产品的接受度。传统调查方法虽常用，但成本高且操作繁琐。我们探索了一种新方法：利用大型语言模型对在线用户生成内容（如评论）进行标注。基于接受与使用统一理论，我们设计了LLM标注系统，将评论数据化。通过两项研究，我们验证了该系统标注的一致性与准确性，发现其表现优异，甚至超越了人类专家的标注一致性。这表明LLM不仅能替代传统调查，还能为技术设计与采用提供更深入的见解。",
    "title_cn": "利用 LLM 注释系统，我们能够扩展技术接受度的分析范围。",
    "tags": [
      "LLM应用",
      "技术产品",
      "市场研究"
    ]
  },
  {
    "title": "BAPO: Base-Anchored Preference Optimization for Personalized Alignment in Large Language Models",
    "submit_datetime": "2024年06月30日",
    "abstract": "While learning to align Large Language Models (LLMs) with human preferences has shown remarkable success, aligning these models to meet the diverse user preferences presents further challenges in preserving previous knowledge. This paper examines the impact of personalized preference optimization on LLMs, revealing that the extent of knowledge loss varies significantly with preference heterogeneity. Although previous approaches have utilized the KL constraint between the reference model and the policy model, we observe that they fail to maintain general knowledge and alignment when facing personalized preferences. To this end, we introduce Base-Anchored Preference Optimization (BAPO), a simple yet effective approach that utilizes the initial responses of reference model to mitigate forgetting while accommodating personalized alignment. BAPO effectively adapts to diverse user preferences while minimally affecting global knowledge or general alignment. Our experiments demonstrate the efficacy of BAPO in various setups.",
    "pdf_link": "https://arxiv.org/abs/2407.00693",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.00693v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00693/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00693v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00693/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00693v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00693/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00693v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00693/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00693v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00693/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00693v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00693/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00693v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00693/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00693v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00693/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00693v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00693/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00693v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00693/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00693v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00693/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00693v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00693/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00693v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00693/x14.png"
      }
    ],
    "abstract_cn": "尽管将大型语言模型与人类偏好对齐已取得显著成效，但在满足多样化用户偏好的同时保留先前知识仍面临挑战。本文探讨了个性化偏好优化对 LLM 的影响，发现知识损失与偏好多样性密切相关。虽然现有方法通过 KL 约束来维持模型一致性，但在个性化偏好面前，这些方法难以保持知识与对齐的平衡。为此，我们提出了 Base-Anchored Preference Optimization (BAPO)，一种简便高效的方法，通过利用参考模型的初始响应，既减轻遗忘又适应个性化对齐。BAPO 在适应用户多样偏好的同时，对全局知识或对齐的影响微乎其微。实验结果显示，BAPO 在多种场景下均表现出色。",
    "title_cn": "BAPO：大型语言模型中个性化对齐的基础锚定偏好优化方法",
    "tags": [
      "LLM理论",
      "人工智能",
      "个性化服务"
    ]
  },
  {
    "title": "HRDE: Retrieval-Augmented Large Language Models for Chinese Health Rumor Detection and Explainability",
    "submit_datetime": "2024年06月30日",
    "abstract": "As people increasingly prioritize their health, the speed and breadth of health information dissemination on the internet have also grown. At the same time, the presence of false health information (health rumors) intermingled with genuine content poses a significant potential threat to public health. However, current research on Chinese health rumors still lacks a large-scale, public, and open-source dataset of health rumor information, as well as effective and reliable rumor detection methods. This paper addresses this gap by constructing a dataset containing 1.12 million health-related rumors (HealthRCN) through web scraping of common health-related questions and a series of data processing steps. HealthRCN is the largest known dataset of Chinese health information rumors to date. Based on this dataset, we propose retrieval-augmented large language models for Chinese health rumor detection and explainability (HRDE). This model leverages retrieved relevant information to accurately determine whether the input health information is a rumor and provides explanatory responses, effectively aiding users in verifying the authenticity of health information. In evaluation experiments, we compared multiple models and found that HRDE outperformed them all, including GPT-4-1106-Preview, in rumor detection accuracy and answer quality. HRDE achieved an average accuracy of 91.04% and an F1 score of 91.58%.",
    "pdf_link": "https://arxiv.org/abs/2407.00668",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.00668v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00668/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00668v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00668/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00668v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00668/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00668v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00668/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00668v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00668/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00668v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00668/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00668v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00668/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00668v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00668/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00668v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00668/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00668v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00668/x11.png"
      }
    ],
    "abstract_cn": "随着健康意识的提升，互联网上的健康信息传播愈发迅速广泛。然而，真假难辨的健康谣言也悄然潜伏，对公众健康构成威胁。当前，中国健康谣言研究面临数据集匮乏和检测方法不足的挑战。为此，我们通过网络爬虫和数据处理，构建了包含112万条谣言的HealthRCN数据集，这是目前最大的中文健康谣言数据集。基于此，我们研发了检索增强型大型语言模型HRDE，它能精准识别谣言并提供解释，助力用户辨别信息真伪。实验表明，HRDE在谣言检测和回答质量上超越了包括GPT-4-1106-Preview在内的所有模型，准确率高达91.04%，F1分数达91.58%。",
    "title_cn": "HRDE：一款专为中文健康谣言检测设计的检索增强型大型语言模型，兼具可解释性。",
    "tags": [
      "RAG",
      "",
      "健康信息"
    ]
  },
  {
    "title": "Chain-of-Knowledge: Integrating Knowledge Reasoning into Large Language Models by Learning from Knowledge Graphs",
    "submit_datetime": "2024年06月30日",
    "abstract": "Large Language Models (LLMs) have exhibited impressive proficiency in various natural language processing (NLP) tasks, which involve increasingly complex reasoning. Knowledge reasoning, a primary type of reasoning, aims at deriving new knowledge from existing one.While it has been widely studied in the context of knowledge graphs (KGs), knowledge reasoning in LLMs remains underexplored. In this paper, we introduce Chain-of-Knowledge, a comprehensive framework for knowledge reasoning, including methodologies for both dataset construction and model learning. For dataset construction, we create KnowReason via rule mining on KGs. For model learning, we observe rule overfitting induced by naive training. Hence, we enhance CoK with a trial-and-error mechanism that simulates the human process of internal knowledge exploration. We conduct extensive experiments with KnowReason. Our results show the effectiveness of CoK in refining LLMs in not only knowledge reasoning, but also general reasoning benchmarkms.",
    "pdf_link": "https://arxiv.org/abs/2407.00653",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.00653v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00653/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00653v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00653/x2.png"
      }
    ],
    "abstract_cn": "大型语言模型 (LLM) 在复杂的自然语言处理任务中表现卓越，尤其是在知识推理方面。尽管知识图谱 (KGs) 中的知识推理研究已相当成熟，但 LLM 中的这一领域仍有待深入探索。本文提出的 Chain-of-Knowledge 框架，不仅涵盖了数据集构建，还包括了创新的模型学习方法。我们通过规则挖掘在 KGs 上构建了 KnowReason 数据集，并针对模型学习中的过拟合问题，引入了模拟人类探索过程的试错机制，以提升 CoK 的性能。实验结果表明，CoK 不仅能提升 LLM 在知识推理上的表现，还能在一般推理任务中取得优异成绩。",
    "title_cn": "知识链：借助知识图谱的学习，将知识推理融入大型语言模型，实现更深层次的智能整合。",
    "tags": [
      "LLM应用",
      "知识图谱",
      ""
    ]
  },
  {
    "title": "DP-MLM: Differentially Private Text Rewriting Using Masked Language Models",
    "submit_datetime": "2024年06月30日",
    "abstract": "The task of text privatization using Differential Privacy has recently taken the form of $\\textit{text rewriting}$, in which an input text is obfuscated via the use of generative (large) language models. While these methods have shown promising results in the ability to preserve privacy, these methods rely on autoregressive models which lack a mechanism to contextualize the private rewriting process. In response to this, we propose $\\textbf{DP-MLM}$, a new method for differentially private text rewriting based on leveraging masked language models (MLMs) to rewrite text in a semantically similar $\\textit{and}$ obfuscated manner. We accomplish this with a simple contextualization technique, whereby we rewrite a text one token at a time. We find that utilizing encoder-only MLMs provides better utility preservation at lower $\\varepsilon$ levels, as compared to previous methods relying on larger models with a decoder. In addition, MLMs allow for greater customization of the rewriting mechanism, as opposed to generative approaches. We make the code for $\\textbf{DP-MLM}$ public and reusable, found at https://github.com/sjmeis/DPMLM .",
    "pdf_link": "https://arxiv.org/abs/2407.00637",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.00637v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00637/DP-MLM.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00637v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00637/x1.png"
      }
    ],
    "abstract_cn": "近期，文本隐私化任务采用了$\\textit{文本重写}$的形式，通过生成（大型）语言模型对输入文本进行混淆。虽然这些方法在隐私保护方面表现出色，但它们依赖的自回归模型缺乏上下文化重写过程的机制。为此，我们提出了$\\textbf{DP-MLM}$，一种基于掩码语言模型（MLMs）的新方法，以语义相似且混淆的方式重写文本。我们采用逐标记重写的简单技术，发现与依赖大型解码器模型的方法相比，仅编码器的MLMs在低$\\varepsilon$水平下效用保持更佳。此外，MLMs允许更灵活的重写机制定制。我们公开了$\\textbf{DP-MLM}$的代码，可在https://github.com/sjmeis/DPMLM获取。",
    "title_cn": "DP-MLM：运用掩码语言模型实现差分隐私的文本改写",
    "tags": [
      "LLM应用",
      "网络安全",
      "数据隐私"
    ]
  },
  {
    "title": "Tarsier: Recipes for Training and Evaluating Large Video Description Models",
    "submit_datetime": "2024年06月30日",
    "abstract": "Generating fine-grained video descriptions is a fundamental challenge in video understanding. In this work, we introduce Tarsier, a family of large-scale video-language models designed to generate high-quality video descriptions. Tarsier employs CLIP-ViT to encode frames separately and then uses an LLM to model temporal relationships. Despite its simple architecture, we demonstrate that with a meticulously designed two-stage training procedure, the Tarsier models exhibit substantially stronger video description capabilities than any existing open-source model, showing a $+51.4\\%$ advantage in human side-by-side evaluation over the strongest model. Additionally, they are comparable to state-of-the-art proprietary models, with a $+12.3\\%$ advantage against GPT-4V and a $-6.7\\%$ disadvantage against Gemini 1.5 Pro. Besides video description, Tarsier proves to be a versatile generalist model, achieving new state-of-the-art results across nine public benchmarks, including multi-choice VQA, open-ended VQA, and zero-shot video captioning. Our second contribution is the introduction of a new benchmark for evaluating video description models, consisting of a new challenging dataset featuring videos from diverse sources and varying complexity, along with an automatic method specifically designed to assess the quality of fine-grained video descriptions. We make our models and evaluation benchmark publicly available at \\url{https://github.com/bytedance/tarsier}.",
    "pdf_link": "https://arxiv.org/abs/2407.00634",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.00634v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00634/chatbot-example.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00634v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00634/model-arch.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00634v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00634/video-description-example.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.00634v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00634/automatic-evaluation.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00634v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00634/events_plot.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00634v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00634/subjects_plot.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00634v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00634/shots_plot.png"
      }
    ],
    "abstract_cn": "在视频理解领域，生成细粒度描述是一项基础挑战。我们推出的 Tarsier 系列模型，通过 CLIP-ViT 独立编码视频帧并利用 LLM 处理时间关系，展现了卓越的视频描述能力。经过精心设计的两阶段训练，Tarsier 在视频描述方面超越了所有开源模型，在人类评估中领先最强模型 $+51.4\\%$。同时，它与顶尖专有模型不相上下，对 GPT-4V 领先 $+12.3\\%$，对 Gemini 1.5 Pro 稍逊 $-6.7\\%$。Tarsier 不仅在视频描述上表现出色，还刷新了九个公共基准的记录，涵盖多选 VQA、开放式 VQA 和零-shot 视频字幕等多个领域。此外，我们引入了新的视频描述模型评估基准，包含多样化且复杂度各异的视频数据集，以及专为细粒度视频描述质量评估设计的自动方法。所有模型和评估基准已在 \\url{https://github.com/bytedance/tarsier} 公开。",
    "title_cn": "Tarsier：大型视频描述模型训练与评估的秘方",
    "tags": [
      "LLM应用",
      "视频处理",
      "人工智能"
    ]
  },
  {
    "title": "Iterative Nash Policy Optimization: Aligning LLMs with General Preferences via No-Regret Learning",
    "submit_datetime": "2024年06月30日",
    "abstract": "Reinforcement Learning with Human Feedback (RLHF) has achieved great success in aligning large language models (LLMs) with human preferences. Prevalent RLHF approaches are reward-based, following the Bradley-Terry (BT) model assumption, which may not fully capture the complexity of human preferences. In this paper, we explore RLHF under a general preference framework and approach it from a game-theoretic perspective. Specifically, we formulate the problem as a two-player game and propose a novel algorithm, iterative Nash policy optimization (INPO). The key idea is to let the policy play against itself via no-regret learning, thereby approximating the Nash policy. Unlike previous methods, INPO bypasses the need for estimating the expected win rate for individual responses, which typically incurs high computational or annotation costs. Instead, we introduce a new loss objective that is directly minimized over a preference dataset. We provide theoretical analysis for our approach and demonstrate its effectiveness through experiments on various representative benchmarks. With an LLaMA-3-8B-based SFT model, INPO achieves a 41.5% length-controlled win rate on AlpacaEval 2.0 and a 38.3% win rate on Arena-Hard, showing substantial improvement over the state-of-the-art iterative algorithm [Dong et al., 2024] under the BT model assumption. Additionally, our ablation study highlights the benefits of incorporating KL regularization for response length control.",
    "pdf_link": "https://arxiv.org/abs/2407.00617",
    "graphs": [],
    "abstract_cn": "基于人类反馈的强化学习（RLHF）在使大型语言模型与人类偏好对齐方面取得了显著成就。然而，现有的基于奖励的RLHF方法，如遵循Bradley-Terry模型假设，可能未能充分捕捉人类偏好的复杂性。本文中，我们提出了一种新的博弈论视角下的RLHF方法，通过将问题建模为双人博弈，并引入迭代纳什策略优化（INPO）算法。该算法通过策略自我对抗学习，无需估计单个响应的胜率，从而降低了计算成本。我们在多个基准测试中验证了INPO的有效性，显著超越了现有方法。此外，研究还表明，结合KL正则化能有效提升响应长度控制的性能。",
    "title_cn": "迭代纳什策略优化：借助无悔学习，使大型语言模型与广泛偏好相契合",
    "tags": [
      "LLM理论",
      "人工智能",
      "博弈论"
    ]
  },
  {
    "title": "WallFacer: Guiding Transformer Model Training Out of the Long-Context Dark Forest with N-body Problem",
    "submit_datetime": "2024年06月30日",
    "abstract": "In recent years, Transformer-based Large Language Models (LLMs) have garnered significant attention due to their exceptional performance across a variety of tasks. However, training these models on long sequences presents a substantial challenge in terms of efficiency and scalability. Current methods are constrained either by the number of attention heads, limiting scalability, or by excessive communication overheads. In this paper, we propose an insight that Attention Computation can be considered as a special case of n-body problem with direct interactions. Based on this concept, this paper introduces WallFacer, an efficient long-sequence training system with a novel multi-dimensional ring sequence parallelism, fostering an efficient communication paradigm and extra tuning space for communication arrangement. Through comprehensive experiments under diverse environments and model settings, we demonstrate that WallFacer significantly surpasses state-of-the-art method that supports near-infinite sequence length, achieving performance improvements of up to 77.12%.",
    "pdf_link": "https://arxiv.org/abs/2407.00611",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.00611v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00611/startrail_comm.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00611v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00611/ring.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00611v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00611/overview.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00611v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00611/method.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00611v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00611/init.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00611v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00611/dataloader.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00611v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00611/throughput.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00611v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00611/memory.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00611v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00611/Strong.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00611v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00611/weak.png"
      }
    ],
    "abstract_cn": "近年来，基于Transformer的LLMs因其卓越性能备受瞩目，但长序列训练的效率与可扩展性仍是一大挑战。现有方法或受限于注意力头数量，或面临高通信开销。本文提出，注意力计算可视为n体问题的特例。基于此，我们推出WallFacer系统，采用创新的多维环序列并行技术，优化通信模式并提供更多调整空间。实验表明，WallFacer在多种环境下大幅领先现有技术，性能提升高达77.12%。",
    "title_cn": "WallFacer：借助 N 体问题，引领 Transformer 模型训练摆脱长上下文的困境",
    "tags": [
      "LLM理论",
      "人工智能",
      "高性能计算"
    ]
  },
  {
    "title": "Staying vigilant in the Age of AI: From content generation to content authentication",
    "submit_datetime": "2024年06月30日",
    "abstract": "This paper presents the Yangtze Sea project, an initiative in the battle against Generative AI (GAI)-generated fake con-tent. Addressing a pressing issue in the digital age, we investigate public reactions to AI-created fabrications through a structured experiment on a simulated academic conference platform. Our findings indicate a profound public challenge in discerning such content, highlighted by GAI's capacity for realistic fabrications. To counter this, we introduce an innovative approach employing large language models like ChatGPT for truthfulness assess-ment. We detail a specific workflow for scrutinizing the authenticity of everyday digital content, aimed at boosting public awareness and capability in identifying fake mate-rials. We apply this workflow to an agent bot on Telegram to help users identify the authenticity of text content through conversations. Our project encapsulates a two-pronged strategy: generating fake content to understand its dynamics and developing assessment techniques to mitigate its impact. As part of that effort we propose the creation of speculative fact-checking wearables in the shape of reading glasses and a clip-on. As a computational media art initiative, this project under-scores the delicate interplay between technological progress, ethical consid-erations, and societal consciousness.",
    "pdf_link": "https://arxiv.org/abs/2407.00922",
    "graphs": [],
    "abstract_cn": "本文呈现的长江海项目，是对抗生成式AI（GAI）虚假内容的一项创新举措。通过模拟学术会议平台上的实验，我们揭示了公众在辨识AI制造的虚假信息上的困境，尤其是GAI制造的逼真内容。为此，我们创新性地运用ChatGPT等大型语言模型进行真实性评估，并设计了一套工作流程，旨在提升公众识别虚假信息的能力。该流程已应用于Telegram的智能机器人，助力用户在对话中辨别文本真伪。项目采用双重策略：一方面生成虚假内容以洞察其机制，另一方面研发评估技术以削弱其影响。此外，我们还构想了以阅读眼镜和夹子形态的事实核查可穿戴设备。这一计算媒体艺术项目，深刻体现了技术进步、伦理考量与社会意识间的复杂交织。",
    "title_cn": "在AI时代，我们需保持警觉，从创造内容到验证其真实性。",
    "tags": [
      "LLM应用",
      "",
      ""
    ]
  },
  {
    "title": "From Introspection to Best Practices: Principled Analysis of Demonstrations in Multimodal In-Context Learning",
    "submit_datetime": "2024年06月30日",
    "abstract": "Motivated by in-context learning (ICL) capabilities of Large Language models (LLMs), multimodal LLMs with additional visual modality are also exhibited with similar ICL abilities when multiple image-text pairs are provided as demonstrations. However, relatively less work has been done to investigate the principles behind how and why multimodal ICL works. We conduct a systematic and principled evaluation of multimodal ICL for models of different scales on a broad spectrum of new yet critical tasks. Through perturbations over different modality information, we show that modalities matter differently across tasks in multimodal ICL. Considering such modality impact, we further utilize modality-driven demonstration strategies to boost ICL performance. We also identify that demonstration selection is closely related to the models' ability to capture task inductive biases from multimodal ICL. Our principled analysis provides a comprehensive way of understanding the role of demonstrations in multimodal in-context learning, and sheds light on effectively improving multimodal ICL on a wide range of tasks even if those tasks are not seen in or even contradict pretraining data.",
    "pdf_link": "https://arxiv.org/abs/2407.00902",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.00902v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00902/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00902v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00902/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00902v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00902/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00902v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00902/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00902v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00902/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00902v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00902/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00902v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00902/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00902v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00902/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00902v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00902/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00902v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00902/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00902v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00902/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00902v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00902/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00902v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00902/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00902v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00902/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00902v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00902/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00902v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00902/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00902v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00902/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00902v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00902/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00902v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00902/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00902v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00902/x20.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00902v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00902/x21.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00902v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00902/x22.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00902v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00902/x23.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00902v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00902/x24.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00902v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00902/x25.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00902v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00902/x26.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00902v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00902/x27.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00902v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00902/x28.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00902v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00902/x29.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00902v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00902/x30.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00902v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00902/x31.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00902v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00902/x32.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00902v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00902/x33.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00902v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00902/x34.png"
      }
    ],
    "abstract_cn": "受 LLM 的 ICL 能力启发，多模态 LLM 在提供图像-文本对演示时也展现出类似 ICL 能力。然而，关于多模态 ICL 的工作原理研究较少。我们系统评估了不同规模模型在新颖关键任务上的多模态 ICL 表现。通过模态信息扰动，我们发现模态在不同任务中的重要性各异。基于此，我们采用模态驱动策略提升 ICL 性能，并发现演示选择与模型捕捉任务偏差的能力紧密相关。我们的分析全面揭示了演示在多模态 ICL 中的作用，为改进多模态 ICL 提供了有效途径，即使面对预训练数据中未见或矛盾的任务。",
    "title_cn": "从内省到实践精华：探究多模态情境学习中演示的系统性分析",
    "tags": [
      "LLM应用",
      "人工智能",
      "计算机视觉"
    ]
  },
  {
    "title": "Answering real-world clinical questions using large language model based systems",
    "submit_datetime": "2024年06月29日",
    "abstract": "Evidence to guide healthcare decisions is often limited by a lack of relevant and trustworthy literature as well as difficulty in contextualizing existing research for a specific patient. Large language models (LLMs) could potentially address both challenges by either summarizing published literature or generating new studies based on real-world data (RWD). We evaluated the ability of five LLM-based systems in answering 50 clinical questions and had nine independent physicians review the responses for relevance, reliability, and actionability. As it stands, general-purpose LLMs (ChatGPT-4, Claude 3 Opus, Gemini Pro 1.5) rarely produced answers that were deemed relevant and evidence-based (2% - 10%). In contrast, retrieval augmented generation (RAG)-based and agentic LLM systems produced relevant and evidence-based answers for 24% (OpenEvidence) to 58% (ChatRWD) of questions. Only the agentic ChatRWD was able to answer novel questions compared to other LLMs (65% vs. 0-9%). These results suggest that while general-purpose LLMs should not be used as-is, a purpose-built system for evidence summarization based on RAG and one for generating novel evidence working synergistically would improve availability of pertinent evidence for patient care.",
    "pdf_link": "https://arxiv.org/abs/2407.00541",
    "graphs": [],
    "abstract_cn": "在医疗决策中，由于缺乏相关且可信的文献，以及难以将现有研究应用于特定患者，证据往往受限。大型语言模型（LLM）通过总结文献或基于真实世界数据（RWD）生成新研究，有望解决这些难题。我们测试了五个LLM系统回答50个临床问题的能力，并由九名独立医生评估了答案的相关性、可靠性和可操作性。结果显示，通用型LLM（如ChatGPT-4、Claude 3 Opus、Gemini Pro 1.5）很少能提供相关且基于证据的答案（仅占2% - 10%）。相反，基于检索增强生成（RAG）和代理型LLM系统的表现更佳，能提供相关且基于证据的答案，占比从24%（OpenEvidence）到58%（ChatRWD）。特别是代理型ChatRWD，能回答更多新问题（65% vs. 0-9%）。这些发现表明，虽然不应直接使用通用型LLM，但专门设计的基于RAG的证据总结系统和协同工作的系统，将显著提升患者护理相关证据的可用性。",
    "title_cn": "利用大型语言模型系统解答实际临床难题",
    "tags": [
      "RAG",
      "",
      "人工智能"
    ]
  },
  {
    "title": "When Robots Get Chatty: Grounding Multimodal Human-Robot Conversation and Collaboration",
    "submit_datetime": "2024年06月29日",
    "abstract": "We investigate the use of Large Language Models (LLMs) to equip neural robotic agents with human-like social and cognitive competencies, for the purpose of open-ended human-robot conversation and collaboration. We introduce a modular and extensible methodology for grounding an LLM with the sensory perceptions and capabilities of a physical robot, and integrate multiple deep learning models throughout the architecture in a form of system integration. The integrated models encompass various functions such as speech recognition, speech generation, open-vocabulary object detection, human pose estimation, and gesture detection, with the LLM serving as the central text-based coordinating unit. The qualitative and quantitative results demonstrate the huge potential of LLMs in providing emergent cognition and interactive language-oriented control of robots in a natural and social manner.",
    "pdf_link": "https://arxiv.org/abs/2407.00518",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.00518v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00518/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00518v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00518/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00518v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00518/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00518v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00518/emotion_neutral.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.00518v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00518/emotion_happiness.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.00518v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00518/emotion_sadness.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.00518v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00518/emotion_surprise.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.00518v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00518/emotion_anger.jpg"
      }
    ],
    "abstract_cn": "我们探索如何利用大型语言模型 (LLM) 赋予机器人类人的社交与认知能力，以实现开放式的人机对话与协作。为此，我们提出了一种模块化且可扩展的方法，将 LLM 与机器人的感知及功能相结合，并在系统架构中整合了多种深度学习模型。这些集成模型涵盖了语音识别、语音生成、物体检测、人体姿态估计及手势识别等功能，而 LLM 则作为核心的文本协调单元。实证研究表明，LLM 在自然且社交的交互中，为机器人提供了创新的认知能力与语言控制，展现出巨大的应用潜力。",
    "title_cn": "机器人开口说话时：构建多模态人机对话与协作的基石",
    "tags": [
      "LLM应用",
      "机器人",
      "人工智能"
    ]
  },
  {
    "title": "Large Language Models for Power Scheduling: A User-Centric Approach",
    "submit_datetime": "2024年06月29日",
    "abstract": "While traditional optimization and scheduling schemes are designed to meet fixed, predefined system requirements, future systems are moving toward user-driven approaches and personalized services, aiming to achieve high quality-of-experience (QoE) and flexibility. This challenge is particularly pronounced in wireless and digitalized energy networks, where users' requirements have largely not been taken into consideration due to the lack of a common language between users and machines. The emergence of powerful large language models (LLMs) marks a radical departure from traditional system-centric methods into more advanced user-centric approaches by providing a natural communication interface between users and devices. In this paper, for the first time, we introduce a novel architecture for resource scheduling problems by constructing three LLM agents to convert an arbitrary user's voice request (VRQ) into a resource allocation vector. Specifically, we design an LLM intent recognition agent to translate the request into an optimization problem (OP), an LLM OP parameter identification agent, and an LLM OP solving agent. To evaluate system performance, we construct a database of typical VRQs in the context of electric vehicle (EV) charging. As a proof of concept, we primarily use Llama 3 8B. Through testing with different prompt engineering scenarios, the obtained results demonstrate the efficiency of the proposed architecture. The conducted performance analysis allows key insights to be extracted. For instance, having a larger set of candidate OPs to model the real-world problem might degrade the final performance because of a higher recognition/OP classification noise level. All results and codes are open source.",
    "pdf_link": "https://arxiv.org/abs/2407.00476",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.00476v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00476/Fig1-D.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00476v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00476/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00476v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00476/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00476v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00476/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00476v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00476/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00476v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00476/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00476v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00476/x10.png"
      }
    ],
    "abstract_cn": "传统优化与调度方案满足固定系统需求，而未来系统正转向用户驱动与个性化服务，追求高QoE与灵活性。无线与数字化能源网络中，用户需求因缺乏人机共同语言而常被忽视。大型语言模型（LLMs）的崛起，通过提供自然人机交互界面，标志着从系统中心向用户中心的转变。本文首次提出一种创新资源调度架构，利用三个LLM代理将用户语音请求（VRQ）转化为资源分配向量。我们设计了意图识别、参数识别及问题求解三个LLM代理，构建了电动汽车充电场景下的VRQ数据库，并使用Llama 3 8B进行概念验证。测试结果显示了该架构的高效性，分析揭示了候选OP数量增加可能因识别噪声而影响最终性能。所有成果与代码均已开源。",
    "title_cn": "大型语言模型在电力调度中的应用：聚焦用户需求的方法",
    "tags": [
      "Agent",
      "",
      ""
    ]
  },
  {
    "title": "BioKGBench: A Knowledge Graph Checking Benchmark of AI Agent for Biomedical Science",
    "submit_datetime": "2024年06月29日",
    "abstract": "Pursuing artificial intelligence for biomedical science, a.k.a. AI Scientist, draws increasing attention, where one common approach is to build a copilot agent driven by Large Language Models (LLMs). However, to evaluate such systems, people either rely on direct Question-Answering (QA) to the LLM itself, or in a biomedical experimental manner. How to precisely benchmark biomedical agents from an AI Scientist perspective remains largely unexplored. To this end, we draw inspiration from one most important abilities of scientists, understanding the literature, and introduce BioKGBench. In contrast to traditional evaluation benchmark that only focuses on factual QA, where the LLMs are known to have hallucination issues, we first disentangle \"Understanding Literature\" into two atomic abilities, i) \"Understanding\" the unstructured text from research papers by performing scientific claim verification, and ii) Ability to interact with structured Knowledge-Graph Question-Answering (KGQA) as a form of \"Literature\" grounding. We then formulate a novel agent task, dubbed KGCheck, using KGQA and domain-based Retrieval-Augmented Generation (RAG) to identify the factual errors of existing large-scale knowledge graph databases. We collect over two thousand data for two atomic tasks and 225 high-quality annotated data for the agent task. Surprisingly, we discover that state-of-the-art agents, both daily scenarios and biomedical ones, have either failed or inferior performance on our benchmark. We then introduce a simple yet effective baseline, dubbed BKGAgent. On the widely used popular knowledge graph, we discover over 90 factual errors which provide scenarios for agents to make discoveries and demonstrate the effectiveness of our approach. The code and data are available at https://github.com/westlake-autolab/BioKGBench.",
    "pdf_link": "https://arxiv.org/abs/2407.00466",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.00466v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00466/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00466v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00466/subKG.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.00466v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00466/BKGAgent.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.00466v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00466/restrict_corpus_exp.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00466v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00466/errorcase.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.00466v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00466/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00466v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00466/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00466v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00466/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00466v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00466/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00466v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00466/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00466v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00466/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00466v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00466/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00466v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00466/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00466v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00466/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00466v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00466/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00466v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00466/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00466v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00466/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00466v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00466/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00466v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00466/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00466v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00466/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00466v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00466/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00466v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00466/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00466v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00466/x20.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00466v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00466/x21.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00466v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00466/x22.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00466v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00466/x23.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00466v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00466/x24.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00466v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00466/x25.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00466v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00466/x26.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00466v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00466/x27.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00466v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00466/x28.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00466v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00466/x29.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00466v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00466/x30.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00466v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00466/x31.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00466v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00466/x32.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00466v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00466/x33.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00466v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00466/x34.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00466v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00466/x35.png"
      }
    ],
    "abstract_cn": "AI Scientist 在生物医学领域的应用日益受到瞩目，其中一种常见策略是构建由大型语言模型 (LLM) 驱动的辅助代理。然而，评估这些系统的方法要么直接依赖 LLM 的问答 (QA)，要么采用生物医学实验方式。从 AI Scientist 的角度出发，如何精准地基准测试生物医学代理仍是一个未被充分探索的领域。受科学家核心能力——理解文献的启发，我们推出了 BioKGBench。与仅侧重于事实问答的传统基准不同，LLM 在此方面存在幻觉问题，我们将“理解文献”细分为两个基本能力：一是通过科学主张验证理解研究论文中的非结构化文本，二是与结构化知识图谱问答 (KGQA) 交互的能力。接着，我们设计了名为 KGCheck 的新代理任务，结合 KGQA 和基于领域的检索增强生成 (RAG) 来揭示现有大规模知识图谱数据库中的事实错误。我们为两个基本任务收集了超过两千个数据，并为代理任务准备了 225 个高质量注释数据。令人惊讶的是，顶尖的日常和生物医学代理在我们的基准测试中表现不佳。为此，我们提出了一个简单而有效的基线——BKGAgent。在广泛使用的热门知识图谱上，我们发现了超过 90 个事实错误，为代理提供了发现机会，并验证了我们方法的有效性。相关代码和数据已公开在 https://github.com/westlake-autolab/BioKGBench。",
    "title_cn": "BioKGBench：生物医学领域AI代理的知识图谱验证基准",
    "tags": [
      "Agent",
      "生物医学",
      "知识图谱"
    ]
  },
  {
    "title": "Financial Knowledge Large Language Model",
    "submit_datetime": "2024年06月29日",
    "abstract": "Artificial intelligence is making significant strides in the finance industry, revolutionizing how data is processed and interpreted. Among these technologies, large language models (LLMs) have demonstrated substantial potential to transform financial services by automating complex tasks, enhancing customer service, and providing detailed financial analysis. Firstly, we introduce IDEA-FinBench, an evaluation benchmark specifically tailored for assessing financial knowledge in large language models (LLMs). This benchmark utilizes questions from two globally respected and authoritative financial professional exams, aimimg to comprehensively evaluate the capability of LLMs to directly address exam questions pertinent to the finance sector. Secondly, we propose IDEA-FinKER, a Financial Knowledge Enhancement framework designed to facilitate the rapid adaptation of general LLMs to the financial domain, introducing a retrieval-based few-shot learning method for real-time context-level knowledge injection, and a set of high-quality financial knowledge instructions for fine-tuning any general LLM. Finally, we present IDEA-FinQA, a financial question-answering system powered by LLMs. This system is structured around a scheme of real-time knowledge injection and factual enhancement using external knowledge. IDEA-FinQA is comprised of three main modules: the data collector, the data querying module, and LLM-based agents tasked with specific functions.",
    "pdf_link": "https://arxiv.org/abs/2407.00365",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.00365v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00365/transformer_arc.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00365v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00365/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00365v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00365/gpt.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00365v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00365/instructgpt.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00365v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00365/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00365v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00365/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00365v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00365/cfa.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00365v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00365/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00365v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00365/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00365v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00365/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00365v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00365/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00365v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00365/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00365v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00365/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00365v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00365/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00365v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00365/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00365v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00365/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00365v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00365/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00365v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00365/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00365v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00365/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00365v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00365/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00365v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00365/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00365v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00365/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00365v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00365/x19.png"
      }
    ],
    "abstract_cn": "人工智能正深刻影响金融业，革新数据处理与解读。大型语言模型（LLMs）尤为突出，通过自动化复杂任务、优化客户服务和深化财务分析，重塑金融服务。我们首先推出IDEA-FinBench，专为评估LLMs财务知识而设的基准，采纳全球权威金融考试题，全面检验LLMs应对金融领域考题的能力。接着，提出IDEA-FinKER框架，助力LLMs快速融入金融领域，采用基于检索的少样本学习，实时注入上下文知识，并配备高质量金融指令，微调通用LLMs。最后，呈现IDEA-FinQA系统，由LLMs驱动，聚焦实时知识注入与外部知识强化，包含数据收集、查询及功能性LLM代理三大模块。",
    "title_cn": "金融知识大型语言模型",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Investigating and Mitigating the Multimodal Hallucination Snowballing in Large Vision-Language Models",
    "submit_datetime": "2024年06月29日",
    "abstract": "Though advanced in understanding visual information with human languages, Large Vision-Language Models (LVLMs) still suffer from multimodal hallucinations. A natural concern is that during multimodal interaction, the generated hallucinations could influence the LVLMs' subsequent generation. Thus, we raise a question: When presented with a query relevant to the previously generated hallucination, will LVLMs be misled and respond incorrectly, even though the ground visual information exists? To answer this, we propose a framework called MMHalSnowball to evaluate LVLMs' behaviors when encountering generated hallucinations, where LVLMs are required to answer specific visual questions within a curated hallucinatory conversation. Crucially, our experiment shows that the performance of open-source LVLMs drops by at least $31\\%$, indicating that LVLMs are prone to accept the generated hallucinations and make false claims that they would not have supported without distractions. We term this phenomenon Multimodal Hallucination Snowballing. To mitigate this, we further propose a training-free method called Residual Visual Decoding, where we revise the output distribution of LVLMs with the one derived from the residual visual input, providing models with direct access to the visual information. Experiments show that our method can mitigate more than $24\\%$ of the snowballed multimodal hallucination while maintaining capabilities.",
    "pdf_link": "https://arxiv.org/abs/2407.00569",
    "graphs": [],
    "abstract_cn": "尽管大型视觉-语言模型（LVLMs）在理解视觉信息方面取得了显著进步，但它们仍面临多模态幻觉的问题。我们担心，在多模态交互中，这些幻觉可能误导LVLMs的后续生成。因此，我们提出疑问：面对与先前幻觉相关的查询时，即使基础视觉信息存在，LVLMs是否会被误导并给出错误答案？为此，我们设计了MMHalSnowball框架，评估LVLMs在幻觉情境下的反应。实验显示，开源LVLMs性能下降至少31%，表明它们易受幻觉影响，做出错误判断。这种现象我们称之为“多模态幻觉滚雪球”。为解决这一问题，我们提出无需额外训练的“残差视觉解码”方法，通过调整输出分布，使模型直接获取视觉信息，有效减少24%以上的幻觉影响，同时保持原有能力。",
    "title_cn": "探索并缓解大型视觉-语言模型中多模态幻觉的累积效应",
    "tags": [
      "LLM应用",
      "计算机视觉",
      "人工智能"
    ]
  },
  {
    "title": "MMEvalPro: Calibrating Multimodal Benchmarks Towards Trustworthy and Efficient Evaluation",
    "submit_datetime": "2024年06月29日",
    "abstract": "Large Multimodal Models (LMMs) exhibit impressive cross-modal understanding and reasoning abilities, often assessed through multiple-choice questions (MCQs) that include an image, a question, and several options. However, many benchmarks used for such evaluations suffer from systematic biases. Remarkably, Large Language Models (LLMs) without any visual perception capabilities achieve non-trivial performance, undermining the credibility of these evaluations. To address this issue while maintaining the efficiency of MCQ evaluations, we propose MMEvalPro, a benchmark designed to avoid Type-I errors through a trilogy evaluation pipeline and more rigorous metrics. For each original question from existing benchmarks, human annotators augment it by creating one perception question and one knowledge anchor question through a meticulous annotation process. MMEvalPro comprises $2,138$ question triplets, totaling $6,414$ distinct questions. Two-thirds of these questions are manually labeled by human experts, while the rest are sourced from existing benchmarks (MMMU, ScienceQA, and MathVista). Compared with the existing benchmarks, our experiments with the latest LLMs and LMMs demonstrate that MMEvalPro is more challenging (the best LMM lags behind human performance by $31.73\\%$, compared to an average gap of $8.03\\%$ in previous benchmarks) and more trustworthy (the best LLM trails the best LMM by $23.09\\%$, whereas the gap for previous benchmarks is just $14.64\\%$). Our in-depth analysis explains the reason for the large performance gap and justifies the trustworthiness of evaluation, underscoring its significant potential for advancing future research.",
    "pdf_link": "https://arxiv.org/abs/2407.00468",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.00468v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00468/calibrate.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00468v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00468/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00468v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00468/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00468v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00468/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00468v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00468/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00468v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00468/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00468v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00468/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00468v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00468/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00468v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00468/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00468v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00468/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00468v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00468/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00468v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00468/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00468v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00468/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00468v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00468/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00468v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00468/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00468v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00468/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00468v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00468/x17.png"
      }
    ],
    "abstract_cn": "大型多模态模型 (LMMs) 在跨模态理解和推理方面表现卓越，常通过包含图像的多项选择题 (MCQs) 进行评估。然而，现有基准普遍存在系统性偏差，甚至无视觉感知能力的 LLMs 也能取得不俗成绩，降低了评估的可信度。为此，我们推出了 MMEvalPro 基准，通过三阶段评估流程和严格指标，有效避免 I 型错误。该基准包含 $2,138$ 个问题三元组，共计 $6,414$ 个问题，其中三分之二由专家手工标注，其余源自现有基准。实验显示，MMEvalPro 不仅更具挑战性（最佳 LMM 与人类表现差距达 $31.73\\%$），而且更可信（最佳 LLM 与最佳 LMM 差距为 $23.09\\%$）。深入分析揭示了性能差距的原因，并证实了评估的可靠性，预示着其对未来研究的重大推动作用。",
    "title_cn": "MMEvalPro：致力于校准多模态基准，确保评估的可信性与高效性。",
    "tags": [
      "LLM应用",
      "人工智能",
      "教育评估"
    ]
  },
  {
    "title": "How to Train Your Fact Verifier: Knowledge Transfer with Multimodal Open Models",
    "submit_datetime": "2024年06月29日",
    "abstract": "Given the growing influx of misinformation across news and social media, there is a critical need for systems that can provide effective real-time verification of news claims. Large language or multimodal model based verification has been proposed to scale up online policing mechanisms for mitigating spread of false and harmful content. While these can potentially reduce burden on human fact-checkers, such efforts may be hampered by foundation model training data becoming outdated. In this work, we test the limits of improving foundation model performance without continual updating through an initial study of knowledge transfer using either existing intra- and inter- domain benchmarks or explanations generated from large language models (LLMs). We evaluate on 12 public benchmarks for fact-checking and misinformation detection as well as two other tasks relevant to content moderation -- toxicity and stance detection. Our results on two recent multi-modal fact-checking benchmarks, Mocheg and Fakeddit, indicate that knowledge transfer strategies can improve Fakeddit performance over the state-of-the-art by up to 1.7% and Mocheg performance by up to 2.9%.",
    "pdf_link": "https://arxiv.org/abs/2407.00369",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.00369v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00369/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00369v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00369/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00369v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00369/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00369v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00369/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00369v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00369/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00369v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00369/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00369v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00369/instructions1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00369v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00369/instructions2.png"
      }
    ],
    "abstract_cn": "随着新闻和社交媒体上错误信息的激增，我们急需能够实时有效验证新闻声明的系统。为此，基于大型语言或多模态模型的验证方法应运而生，旨在加强在线监管，遏制虚假和有害内容的传播。尽管这些方法有望减轻人工事实核查的负担，但基础模型训练数据的过时可能成为阻碍。在本研究中，我们探索了在不持续更新的前提下，通过知识转移提升基础模型性能的可能性，利用现有基准或大型语言模型生成的解释进行初步研究。我们在12个公共事实核查和错误信息检测基准以及两个与内容审核相关的任务上进行了评估。实验结果显示，在Mocheg和Fakeddit这两个多模态事实核查基准上，知识转移策略分别将性能提升了高达2.9%和1.7%，超越了当前最先进水平。",
    "title_cn": "训练事实验证器：探索多模态开放模型中的知识传递",
    "tags": [
      "LLM应用",
      "",
      "网络安全"
    ]
  },
  {
    "title": "Explaining Chest X-ray Pathology Models using Textual Concepts",
    "submit_datetime": "2024年06月29日",
    "abstract": "Deep learning models have revolutionized medical imaging and diagnostics, yet their opaque nature poses challenges for clinical adoption and trust. Amongst approaches to improve model interpretability, concept-based explanations aim to provide concise and human understandable explanations of any arbitrary classifier. However, such methods usually require a large amount of manually collected data with concept annotation, which is often scarce in the medical domain. In this paper, we propose Conceptual Counterfactual Explanations for Chest X-ray (CoCoX) that leverage existing vision-language models (VLM) joint embedding space to explain black-box classifier outcomes without the need for annotated datasets. Specifically, we utilize textual concepts derived from chest radiography reports and a pre-trained chest radiography-based VLM to explain three common cardiothoracic pathologies. We demonstrate that the explanations generated by our method are semantically meaningful and faithful to underlying pathologies.",
    "pdf_link": "https://arxiv.org/abs/2407.00557",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.00557v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00557/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00557v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00557/x2.png"
      }
    ],
    "abstract_cn": "深度学习模型虽已革新医学影像诊断领域，但其不透明性却成为临床采纳和信任的障碍。在提升模型透明度的探索中，基于概念的解释力求提供简洁易懂的分类器解释。然而，这类方法常依赖大量手动标注概念的数据，这在医学领域尤为稀缺。为此，我们创新性地提出了CoCoX方法，它巧妙利用现有视觉-语言模型的联合嵌入空间，无需标注数据即可阐释黑盒分类器的结果。通过结合胸部放射报告中的文本概念与预训练的VLM，我们成功解释了三种常见胸腔疾病。实验表明，我们的解释不仅语义丰富，而且准确反映了潜在病理。",
    "title_cn": "通过文本概念阐释胸部X光病理模型",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "ConU: Conformal Uncertainty in Large Language Models with Correctness Coverage Guarantees",
    "submit_datetime": "2024年06月29日",
    "abstract": "Uncertainty quantification (UQ) in natural language generation (NLG) tasks remains an open challenge, exacerbated by the intricate nature of the recent large language models (LLMs). This study investigates adapting conformal prediction (CP), which can convert any heuristic measure of uncertainty into rigorous theoretical guarantees by constructing prediction sets, for black-box LLMs in open-ended NLG tasks. We propose a sampling-based uncertainty measure leveraging self-consistency and develop a conformal uncertainty criterion by integrating the uncertainty condition aligned with correctness into the design of the CP algorithm. Experimental results indicate that our uncertainty measure generally surpasses prior state-of-the-art methods. Furthermore, we calibrate the prediction sets within the model's unfixed answer distribution and achieve strict control over the correctness coverage rate across 6 LLMs on 4 free-form NLG datasets, spanning general-purpose and medical domains, while the small average set size further highlights the efficiency of our method in providing trustworthy guarantees for practical open-ended NLG applications.",
    "pdf_link": "https://arxiv.org/abs/2407.00499",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.00499v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00499/conformal_correctness_coverage.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00499v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00499/Non-empty_conformal_correctness_coverage.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00499v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00499/auroc_num.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00499v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00499/ratio_cp.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00499v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00499/conformal_correctness_coverage_mistral.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00499v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00499/conformal_correctness_coverage_llama3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00499v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00499/conformal_correctness_coverage_llama13b.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00499v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00499/conformal_correctness_coverage_vicuna.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00499v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00499/conformal_correctness_coverage_llama70.png"
      }
    ],
    "abstract_cn": "自然语言生成任务中的不确定性量化仍是一大难题，尤其是随着大型语言模型的复杂性增加。本研究探索了将保形预测应用于黑箱LLM的方法，通过构建预测集将启发式的不确定性度量转化为严格的理论保证。我们提出了一种基于抽样的不确定性度量方法，结合自一致性，并设计了保形不确定性准则，确保与正确性一致。实验显示，我们的方法在性能上超越了现有技术。此外，我们在模型的答案分布中校准预测集，确保了在多个领域和模型中对正确覆盖率的严格控制，同时小规模的平均集大小也显示了方法的高效性，为实际应用提供了可靠的保障。",
    "title_cn": "ConU：在大型语言模型中，通过正确性覆盖保证实现共形不确定性",
    "tags": [
      "LLM理论",
      "人工智能",
      ""
    ]
  },
  {
    "title": "LLMs-as-Instructors: Learning from Errors Toward Automating Model Improvement",
    "submit_datetime": "2024年06月29日",
    "abstract": "This paper introduces the innovative \"LLMs-as-Instructors\" framework, which leverages the advanced Large Language Models (LLMs) to autonomously enhance the training of smaller target models. Inspired by the theory of \"Learning from Errors\", this framework employs an instructor LLM to meticulously analyze the specific errors within a target model, facilitating targeted and efficient training cycles. Within this framework, we implement two strategies: \"Learning from Error,\" which focuses solely on incorrect responses to tailor training data, and \"Learning from Error by Contrast\", which uses contrastive learning to analyze both correct and incorrect responses for a deeper understanding of errors.\n  Our empirical studies, conducted with several open-source models, demonstrate significant improvements across multiple benchmarks, including mathematical reasoning, coding abilities, and factual knowledge. Notably, the refined Llama-3-8b-Instruction has outperformed ChatGPT, illustrating the effectiveness of our approach. By leveraging the strengths of both strategies, we have attained a more balanced performance improvement on both in-domain and out-of-domain benchmarks. Our code can be found at https://yingjiahao14.github.io/LLMs-as-Instructors-pages/.",
    "pdf_link": "https://arxiv.org/abs/2407.00497",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.00497v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00497/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00497v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00497/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00497v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00497/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00497v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00497/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00497v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00497/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00497v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00497/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00497v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00497/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00497v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00497/x8.png"
      }
    ],
    "abstract_cn": "本文提出创新的“LLMs-as-Instructors”框架，利用大型语言模型自主提升小型模型的训练效率。借鉴“从错误中学习”的理念，该框架通过指导性LLM深入分析目标模型的错误，实现精准高效的训练。我们采用两种策略：一是“从错误中学习”，专注于错误响应定制训练数据；二是“通过对比从错误中学习”，利用对比学习深入剖析错误。实证研究表明，该框架在数学推理、编码能力和事实知识等多个领域显著提升性能，改进后的Llama-3-8b-Instruction更是超越了ChatGPT。通过综合运用这两种策略，我们在各类基准测试中均实现了均衡的性能提升。相关代码已公开，详见https://yingjiahao14.github.io/LLMs-as-Instructors-pages/。",
    "title_cn": "LLMs 作为导师：通过从错误中学习，迈向模型改进的自动化",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "PFME: A Modular Approach for Fine-grained Hallucination Detection and Editing of Large Language Models",
    "submit_datetime": "2024年06月29日",
    "abstract": "Large Language Models (LLMs) excel in fluency but risk producing inaccurate content, called \"hallucinations.\" This paper outlines a standardized process for categorizing fine-grained hallucination types and proposes an innovative framework--the Progressive Fine-grained Model Editor (PFME)--specifically designed to detect and correct fine-grained hallucinations in LLMs. PFME consists of two collaborative modules: the Real-time Fact Retrieval Module and the Fine-grained Hallucination Detection and Editing Module. The former identifies key entities in the document and retrieves the latest factual evidence from credible sources. The latter further segments the document into sentence-level text and, based on relevant evidence and previously edited context, identifies, locates, and edits each sentence's hallucination type. Experimental results on FavaBench and FActScore demonstrate that PFME outperforms existing methods in fine-grained hallucination detection tasks. Particularly, when using the Llama3-8B-Instruct model, PFME's performance in fine-grained hallucination detection with external knowledge assistance improves by 8.7 percentage points (pp) compared to ChatGPT. In editing tasks, PFME further enhances the FActScore of FActScore-Alpaca13B and FActScore-ChatGPT datasets, increasing by 16.2pp and 4.6pp, respectively.",
    "pdf_link": "https://arxiv.org/abs/2407.00488",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.00488v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00488/PFME_architecture.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.00488v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00488/PFME_edit_module.jpg"
      },
      {
        "url": "https://arxiv.org/html/2407.00488v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00488/x1.png"
      }
    ],
    "abstract_cn": "大型语言模型 (LLM) 虽然流畅，但易产生“幻觉”——不准确的内容。本文提出了一套标准化流程，用于细粒度幻觉类型的分类，并创新性地设计了渐进式细粒度模型编辑器 (PFME)，旨在检测和修正 LLM 中的细粒度幻觉。PFME 由两个协同工作的模块组成：实时事实检索模块和细粒度幻觉检测与编辑模块。前者负责识别文档中的关键实体，并从可信来源获取最新事实证据；后者则将文档分解为句子级文本，依据相关证据和已编辑的上下文，精准识别、定位并修正每句中的幻觉。实验显示，PFME 在细粒度幻觉检测方面超越了现有技术，尤其是在 Llama3-8B-Instruct 模型辅助下，其性能较 ChatGPT 提升了 8.7 个百分点。此外，在编辑任务中，PFME 显著提高了 FActScore-Alpaca13B 和 FActScore-ChatGPT 数据集的 FActScore，分别增长了 16.2pp 和 4.6pp。",
    "title_cn": "PFME：一种模块化方法，专为大型语言模型的细粒度幻觉检测与编辑设计。",
    "tags": [
      "LLM应用",
      "人工智能",
      ""
    ]
  },
  {
    "title": "It's Morphing Time: Unleashing the Potential of Multiple LLMs via Multi-objective Optimization",
    "submit_datetime": "2024年06月29日",
    "abstract": "In this paper, we introduce a novel approach for large language model merging via black-box multi-objective optimization algorithms. The goal of model merging is to combine multiple models, each excelling in different tasks, into a single model that outperforms any of the individual source models. However, model merging faces two significant challenges: First, existing methods rely heavily on human intuition and customized strategies. Second, parameter conflicts often arise during merging, and while methods like DARE [1] can alleviate this issue, they tend to stochastically drop parameters, risking the loss of important delta parameters. To address these challenges, we propose the MM-MO method, which automates the search for optimal merging configurations using multi-objective optimization algorithms, eliminating the need for human intuition. During the configuration searching process, we use estimated performance across multiple diverse tasks as optimization objectives in order to alleviate the parameter conflicting between different source models without losing crucial delta parameters. We conducted comparative experiments with other mainstream model merging methods, demonstrating that our method consistently outperforms them. Moreover, our experiments reveal that even task types not explicitly targeted as optimization objectives show performance improvements, indicating that our method enhances the overall potential of the model rather than merely overfitting to specific task types. This approach provides a significant advancement in model merging techniques, offering a robust and plug-and-play solution for integrating diverse models into a unified, high-performing model.",
    "pdf_link": "https://arxiv.org/abs/2407.00487",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.00487v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00487/method_overview_v3.png"
      }
    ],
    "abstract_cn": "本文提出了一种新颖的大型语言模型合并方法，通过黑盒多目标优化算法实现。我们的目标是将多个擅长不同任务的模型合并，创造出一个性能超越所有单一源模型的统一模型。模型合并面临两大难题：一是现有方法过度依赖人工直觉和定制策略；二是合并时常见参数冲突，尽管DARE等方法能缓解，但常随机丢弃参数，可能导致重要增量参数丢失。为此，我们提出MM-MO方法，利用多目标优化算法自动寻找最佳合并方案，无需人工干预。在搜索配置时，我们以多任务的估计性能为优化目标，有效避免参数冲突，保留关键增量参数。实验对比显示，我们的方法性能持续领先。更有趣的是，即使未明确优化的任务类型也见性能提升，表明我们的方法全面提升了模型潜力，而非仅针对特定任务过拟合。这一创新方法为模型合并技术带来显著进步，提供了一个强大且易用的解决方案，将多样模型整合为高效统一的模型。",
    "title_cn": "变形时刻已至：借助多目标优化，激发多款大型语言模型的无限潜能",
    "tags": [
      "LLM理论",
      "人工智能",
      "软件工程"
    ]
  },
  {
    "title": "VcLLM: Video Codecs are Secretly Tensor Codecs",
    "submit_datetime": "2024年06月29日",
    "abstract": "As the parameter size of large language models (LLMs) continues to expand, the need for a large memory footprint and high communication bandwidth have become significant bottlenecks for the training and inference of LLMs. To mitigate these bottlenecks, various tensor compression techniques have been proposed to reduce the data size, thereby alleviating memory requirements and communication pressure.\n  Our research found that video codecs, despite being originally designed for compressing videos, show excellent efficiency when compressing various types of tensors. We demonstrate that video codecs can be versatile and general-purpose tensor codecs while achieving the state-of-the-art compression efficiency in various tasks. We further make use of the hardware video encoding and decoding module available on GPUs to create a framework capable of both inference and training with video codecs repurposed as tensor codecs. This greatly reduces the requirement for memory capacity and communication bandwidth, enabling training and inference of large models on consumer-grade GPUs.",
    "pdf_link": "https://arxiv.org/abs/2407.00467",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.00467v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00467/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00467v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00467/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00467v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00467/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00467v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00467/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00467v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00467/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00467v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00467/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00467v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00467/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00467v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00467/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00467v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00467/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00467v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00467/x10.png"
      }
    ],
    "abstract_cn": "随着 LLM 参数规模的不断增长，大量内存和高带宽的需求已成为其训练与推理的瓶颈。为此，我们探索了张量压缩技术，发现视频编解码器在张量压缩方面表现出色。我们展示了视频编解码器不仅多用途，还能在各类任务中实现顶尖的压缩效率。借助 GPU 上的硬件编解码模块，我们构建了一个框架，将视频编解码器用作张量编解码器，从而显著降低了对内存和带宽的需求，使得大型模型的训练与推理在消费级 GPU 上成为现实。",
    "title_cn": "VcLLM：视频编解码器，实为隐秘的张量编解码器",
    "tags": [
      "LLM理论",
      "计算机科学",
      "人工智能"
    ]
  },
  {
    "title": "Open-Source Conversational AI with SpeechBrain 1.0",
    "submit_datetime": "2024年06月29日",
    "abstract": "SpeechBrain is an open-source Conversational AI toolkit based on PyTorch, focused particularly on speech processing tasks such as speech recognition, speech enhancement, speaker recognition, text-to-speech, and much more.It promotes transparency and replicability by releasing both the pre-trained models and the complete \"recipes\" of code and algorithms required for training them. This paper presents SpeechBrain 1.0, a significant milestone in the evolution of the toolkit, which now has over 200 recipes for speech, audio, and language processing tasks, and more than 100 models available on Hugging Face. SpeechBrain 1.0 introduces new technologies to support diverse learning modalities, Large Language Model (LLM) integration, and advanced decoding strategies, along with novel models, tasks, and modalities. It also includes a new benchmark repository, offering researchers a unified platform for evaluating models across diverse tasks.",
    "pdf_link": "https://arxiv.org/abs/2407.00463",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.00463v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00463/x1.png"
      }
    ],
    "abstract_cn": "SpeechBrain，一款基于 PyTorch 的开源对话 AI 工具包，专注于语音处理领域，涵盖语音识别、增强、说话人识别及文本转语音等多项任务。它通过公开预训练模型及完整训练“配方”，增强了透明度与可复制性。本文聚焦 SpeechBrain 1.0，标志着工具包的重大进展，现提供超 200 种任务配方及 100 多个 Hugging Face 上的模型。新版本不仅支持多样化学习模式、LLM 集成与高级解码策略，还引入了创新模型与任务。此外，新增的基准库为跨任务模型评估提供了统一平台。",
    "title_cn": "开源对话AI：SpeechBrain 1.0登场",
    "tags": [
      "Agent",
      "语音处理",
      "人工智能"
    ]
  },
  {
    "title": "Beyond Functional Correctness: Investigating Coding Style Inconsistencies in Large Language Models",
    "submit_datetime": "2024年06月29日",
    "abstract": "Large language models (LLMs) have brought a paradigm shift to the field of code generation, offering the potential to enhance the software development process. However, previous research mainly focuses on the accuracy of code generation, while coding style differences between LLMs and human developers remain under-explored. In this paper, we empirically analyze the differences in coding style between the code generated by mainstream Code LLMs and the code written by human developers, and summarize coding style inconsistency taxonomy. Specifically, we first summarize the types of coding style inconsistencies by manually analyzing a large number of generation results. We then compare the code generated by Code LLMs with the code written by human programmers in terms of readability, conciseness, and robustness. The results reveal that LLMs and developers have different coding styles. Additionally, we study the possible causes of these inconsistencies and provide some solutions to alleviate the problem.",
    "pdf_link": "https://arxiv.org/abs/2407.00456",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.00456v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00456/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00456v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00456/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00456v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00456/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00456v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00456/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00456v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00456/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00456v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00456/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00456v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00456/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00456v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00456/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00456v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00456/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00456v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00456/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00456v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00456/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00456v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00456/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00456v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00456/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00456v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00456/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00456v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00456/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00456v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00456/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00456v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00456/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00456v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00456/x18.png"
      }
    ],
    "abstract_cn": "大型语言模型 (LLM) 为代码生成领域带来了革命性的变化，有望优化软件开发流程。然而，以往研究多聚焦于代码生成的准确性，而 LLM 与人类开发者间的编码风格差异却鲜有探讨。本文通过实证分析，揭示了主流 Code LLM 与人类开发者编码风格的不一致性，并对其进行了分类总结。我们首先通过大量生成结果的手动分析，归纳了编码风格不一致的类型，随后从可读性、简洁性和健壮性角度对比了 Code LLM 与人类程序员的代码。研究发现，LLM 与开发者编码风格迥异。同时，我们探讨了这些差异的成因，并提出了缓解这些问题的策略。",
    "title_cn": "探究大规模语言模型中的编码风格不一致，超越功能正确性的局限。",
    "tags": [
      "LLM应用",
      "软件开发",
      "人工智能"
    ]
  },
  {
    "title": "Self-Translate-Train: A Simple but Strong Baseline for Cross-lingual Transfer of Large Language Models",
    "submit_datetime": "2024年06月29日",
    "abstract": "Cross-lingual transfer is a promising technique for utilizing data in a source language to improve performance in a target language. However, current techniques often require an external translation system or suffer from suboptimal performance due to over-reliance on cross-lingual generalization of multi-lingual pretrained language models. In this study, we propose a simple yet effective method called Self-Translate-Train. It leverages the translation capability of a large language model to generate synthetic training data in the target language and fine-tunes the model with its own generated data. We evaluate the proposed method on a wide range of tasks and show substantial performance gains across several non-English languages.",
    "pdf_link": "https://arxiv.org/abs/2407.00454",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.00454v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00454/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00454v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00454/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00454v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00454/x3.png"
      }
    ],
    "abstract_cn": "跨语言迁移技术前景广阔，但现有方法常依赖外部翻译系统或因过度依赖多语言模型的跨语言泛化而表现不佳。本研究提出了一种简便高效的方法——自翻译训练，该方法利用大型语言模型的翻译能力生成目标语言的合成训练数据，并以此数据微调模型。实验结果显示，该方法在多种非英语语言任务上取得了显著的性能提升。",
    "title_cn": "自译训练：一种简洁而高效的基线方法，专为大型语言模型的跨语言迁移设计。",
    "tags": [
      "LLM应用",
      "语言技术",
      "机器翻译"
    ]
  },
  {
    "title": "Language-Guided Object-Centric Diffusion Policy for Collision-Aware Robotic Manipulation",
    "submit_datetime": "2024年06月29日",
    "abstract": "Learning from demonstrations faces challenges in generalizing beyond the training data and is fragile even to slight visual variations. To tackle this problem, we introduce Lan-o3dp, a language guided object centric diffusion policy that takes 3d representation of task relevant objects as conditional input and can be guided by cost function for safety constraints at inference time. Lan-o3dp enables strong generalization in various aspects, such as background changes, visual ambiguity and can avoid novel obstacles that are unseen during the demonstration process. Specifically, We first train a diffusion policy conditioned on point clouds of target objects and then harness a large language model to decompose the user instruction into task related units consisting of target objects and obstacles, which can be used as visual observation for the policy network or converted to a cost function, guiding the generation of trajectory towards collision free region at test time. Our proposed method shows training efficiency and higher success rates compared with the baselines in simulation experiments. In real world experiments, our method exhibits strong generalization performance towards unseen instances, cluttered scenes, scenes of multiple similar objects and demonstrates training free capability of obstacle avoidance.",
    "pdf_link": "https://arxiv.org/abs/2407.00451",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.00451v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00451/illustration.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00451v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00451/pipeline.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00451v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00451/simulation_example.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00451v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00451/experiment.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00451v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00451/camera_obstacle.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00451v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00451/success_rate.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00451v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00451/timesteps.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00451v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00451/gradient_scale.png"
      }
    ],
    "abstract_cn": "为了克服从演示学习中的泛化难题和视觉变化的脆弱性，我们推出了Lan-o3dp——一种语言引导的、以对象为中心的扩散策略。该策略利用任务相关对象的3D表示，并通过成本函数在推理时确保安全。Lan-o3dp不仅在背景变化和视觉模糊性方面表现出色，还能有效规避演示中未曾遇到的新障碍。具体操作上，我们首先基于目标对象的点云训练扩散策略，再借助大型语言模型将用户指令细化分解为任务核心单元，这些单元既可作为策略网络的视觉输入，也可转化为成本函数，确保测试时轨迹生成避开碰撞区域。模拟实验证明，我们的方法训练效率高且成功率优于传统方法。实际应用中，Lan-o3dp在处理未见实例、复杂场景及多相似对象情况时，展现了卓越的泛化能力和无需额外训练的障碍规避特性。",
    "title_cn": "语言引导的物体中心扩散策略，助力机器人实现碰撞感知的精准操作",
    "tags": [
      "Agent",
      "机器人",
      "人工智能"
    ]
  },
  {
    "title": "A Recipe of Parallel Corpora Exploitation for Multilingual Large Language Models",
    "submit_datetime": "2024年06月29日",
    "abstract": "Recent studies have highlighted the potential of exploiting parallel corpora to enhance multilingual large language models, improving performance in both bilingual tasks, e.g., machine translation, and general-purpose tasks, e.g., text classification. Building upon these findings, our comprehensive study aims to identify the most effective strategies for leveraging parallel corpora. We investigate the impact of parallel corpora quality and quantity, training objectives, and model size on the performance of multilingual large language models enhanced with parallel corpora across diverse languages and tasks. Our analysis reveals several key insights: (i) filtering noisy translations is essential for effectively exploiting parallel corpora, while language identification and short sentence filtering have little effect; (ii) even a corpus containing just 10K parallel sentences can yield results comparable to those obtained from much larger datasets; (iii) employing only the machine translation objective yields the best results among various training objectives and their combinations; (iv) larger multilingual language models benefit more from parallel corpora than smaller models due to their stronger capacity for cross-task transfer. Our study offers valuable insights into the optimal utilization of parallel corpora to enhance multilingual large language models, extending the generalizability of previous findings from limited languages and tasks to a broader range of scenarios.",
    "pdf_link": "https://arxiv.org/abs/2407.00436",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.00436v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00436/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00436v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00436/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00436v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00436/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00436v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00436/x4.png"
      }
    ],
    "abstract_cn": "近期研究凸显了平行语料库在提升多语种大型语言模型性能方面的潜力，不仅在双语任务如机器翻译中，也在通用任务如文本分类中表现出色。基于此，我们展开了一项全面研究，旨在探索利用平行语料库的最佳策略。我们深入分析了语料库的质量与数量、训练目标及模型规模对多语种大型语言模型性能的影响。研究发现：首先，有效过滤噪声翻译是关键，而语言识别和短句过滤则影响甚微；其次，仅10K平行句子的语料库即可媲美大型数据集的效果；再者，单一的机器翻译训练目标效果最佳；最后，大型模型因更强的跨任务迁移能力，从平行语料库中获益更多。本研究不仅为平行语料库的优化利用提供了新视角，还将先前研究的适用范围从特定语言和任务扩展至更广泛的应用场景。",
    "title_cn": "多语言大型语言模型的平行语料库利用指南",
    "tags": [
      "LLM应用",
      "机器翻译",
      "文本分类"
    ]
  },
  {
    "title": "A Study on Effect of Reference Knowledge Choice in Generating Technical Content Relevant to SAPPhIRE Model Using Large Language Model",
    "submit_datetime": "2024年06月29日",
    "abstract": "Representation of systems using the SAPPhIRE model of causality can be an inspirational stimulus in design. However, creating a SAPPhIRE model of a technical or a natural system requires sourcing technical knowledge from multiple technical documents regarding how the system works. This research investigates how to generate technical content accurately relevant to the SAPPhIRE model of causality using a Large Language Model, also called LLM. This paper, which is the first part of the two-part research, presents a method for hallucination suppression using Retrieval Augmented Generating with LLM to generate technical content supported by the scientific information relevant to a SAPPhIRE con-struct. The result from this research shows that the selection of reference knowledge used in providing context to the LLM for generating the technical content is very important. The outcome of this research is used to build a software support tool to generate the SAPPhIRE model of a given technical system.",
    "pdf_link": "https://arxiv.org/abs/2407.00396",
    "graphs": [],
    "abstract_cn": "利用SAPPhIRE因果模型在设计中激发灵感，但构建此类模型需深入技术文档。本研究探索如何借助大型语言模型（LLM）精准产出相关技术内容。首篇论文聚焦于通过RAG与LLM结合抑制幻觉，确保生成的技术内容科学可靠。研究揭示，选择恰当的参考知识对LLM产出至关重要。此成果助力开发软件工具，高效构建技术系统的SAPPhIRE模型。",
    "title_cn": "本研究探讨了在利用大型语言模型生成与SAPPhIRE模型相关技术内容时，参考知识选择的影响。",
    "tags": [
      "RAG",
      "软件开发",
      "技术文档"
    ]
  },
  {
    "title": "The Factuality Tax of Diversity-Intervened Text-to-Image Generation: Benchmark and Fact-Augmented Intervention",
    "submit_datetime": "2024年06月29日",
    "abstract": "Prompt-based \"diversity interventions\" are commonly adopted to improve the diversity of Text-to-Image (T2I) models depicting individuals with various racial or gender traits. However, will this strategy result in nonfactual demographic distribution, especially when generating real historical figures? In this work, we propose DemOgraphic FActualIty Representation (DoFaiR), a benchmark to systematically quantify the trade-off between using diversity interventions and preserving demographic factuality in T2I models. DoFaiR consists of 756 meticulously fact-checked test instances to reveal the factuality tax of various diversity prompts through an automated evidence-supported evaluation pipeline. Experiments on DoFaiR unveil that diversity-oriented instructions increase the number of different gender and racial groups in DALLE-3's generations at the cost of historically inaccurate demographic distributions. To resolve this issue, we propose Fact-Augmented Intervention (FAI), which instructs a Large Language Model (LLM) to reflect on verbalized or retrieved factual information about gender and racial compositions of generation subjects in history, and incorporate it into the generation context of T2I models. By orienting model generations using the reflected historical truths, FAI significantly improves the demographic factuality under diversity interventions while preserving diversity.",
    "pdf_link": "https://arxiv.org/abs/2407.00377",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.00377v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00377/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00377v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00377/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00377v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00377/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00377v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00377/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00377v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00377/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00377v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00377/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00377v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00377/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00377v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00377/x8.png"
      }
    ],
    "abstract_cn": "我们提出了DoFaiR基准，用于评估T2I模型中多样性干预与事实性之间的平衡。通过756个事实核查的测试实例，我们发现多样性指令虽增加了DALLE-3生成中的多样性，但牺牲了历史人口分布的准确性。为此，我们设计了FAI方法，通过引导LLM整合历史事实信息，既保持多样性又提升事实性。",
    "title_cn": "多样性干预下的文本转图像生成面临事实性挑战，我们提出基准测试与事实增强干预策略。",
    "tags": [
      "LLM应用",
      "人工智能",
      "历史研究"
    ]
  },
  {
    "title": "BMW Agents -- A Framework For Task Automation Through Multi-agent Collaboration",
    "submit_datetime": "2024年06月28日",
    "abstract": "Autonomous agents driven by Large Language Models (LLMs) offer enormous potential for automation. Early proof of this technology can be found in various demonstrations of agents solving complex tasks, interacting with external systems to augment their knowledge, and triggering actions. In particular, workflows involving multiple agents solving complex tasks in a collaborative fashion exemplify their capacity to operate in less strict and less well-defined environments. Thus, a multi-agent approach has great potential for serving as a backbone in many industrial applications, ranging from complex knowledge retrieval systems to next generation robotic process automation. Given the reasoning abilities within the current generation of LLMs, complex processes require a multi-step approach that includes a plan of well-defined and modular tasks. Depending on the level of complexity, these tasks can be executed either by a single agent or a group of agents. In this work, we focus on designing a flexible agent engineering framework with careful attention to planning and execution, capable of handling complex use case applications across various domains. The proposed framework provides reliability in industrial applications and presents techniques to ensure a scalable, flexible, and collaborative workflow for multiple autonomous agents working together towards solving tasks.",
    "pdf_link": "https://arxiv.org/abs/2406.20041",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.20041v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20041/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20041v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20041/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20041v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20041/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20041v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20041/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20041v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20041/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20041v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20041/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20041v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20041/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20041v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20041/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20041v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20041/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20041v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20041/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20041v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20041/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20041v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20041/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20041v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20041/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20041v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20041/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20041v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20041/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20041v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20041/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20041v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20041/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20041v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20041/x19.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLM）驱动的自主代理展现了自动化领域的巨大潜力。早期技术展示包括代理解决复杂任务、与外部系统互动以扩充知识及触发行动等。特别是，多代理协作解决复杂任务的工作流程，突显了它们在非严格定义环境中的运作能力。因此，多代理系统在工业应用中具有广泛前景，涵盖从复杂知识检索到下一代机器人流程自动化等多个领域。鉴于LLM的推理能力，处理复杂过程需采取多步骤策略，包括模块化任务规划。任务执行可由单一代理或代理群组完成，视复杂度而定。本研究聚焦于构建一个灵活的代理工程框架，注重规划与执行，以应对跨领域的复杂应用。该框架旨在提升工业应用的可靠性，并确保多代理协同工作的可扩展性、灵活性和协作性。",
    "title_cn": "BMW Agents 框架：多代理协作驱动任务自动化",
    "tags": [
      "Agent",
      "",
      "自动化"
    ]
  },
  {
    "title": "Simulating Financial Market via Large Language Model based Agents",
    "submit_datetime": "2024年06月28日",
    "abstract": "Most economic theories typically assume that financial market participants are fully rational individuals and use mathematical models to simulate human behavior in financial markets. However, human behavior is often not entirely rational and is challenging to predict accurately with mathematical models. In this paper, we propose \\textbf{A}gent-based \\textbf{S}imulated \\textbf{F}inancial \\textbf{M}arket (ASFM), which first constructs a simulated stock market with a real order matching system. Then, we propose a large language model based agent as the stock trader, which contains the profile, observation, and tool-learning based action module. The trading agent can comprehensively understand current market dynamics and financial policy information, and make decisions that align with their trading strategy. In the experiments, we first verify that the reactions of our ASFM are consistent with the real stock market in two controllable scenarios. In addition, we also conduct experiments in two popular economics research directions, and we find that conclusions drawn in our \\model align with the preliminary findings in economics research. Based on these observations, we believe our proposed ASFM provides a new paradigm for economic research.",
    "pdf_link": "https://arxiv.org/abs/2406.19966",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19966v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19966/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19966v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19966/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19966v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19966/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19966v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19966/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19966v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19966/x5.png"
      }
    ],
    "abstract_cn": "经济理论常假设市场参与者完全理性，并用数学模型模拟其行为。然而，人类行为多变且难以预测。本文提出基于代理的模拟金融市场（ASFM），构建了包含真实订单匹配系统的模拟市场，并设计了基于大型语言模型的智能交易代理，能全面理解市场动态与政策，做出符合策略的决策。实验证明，ASFM在可控场景下的反应与真实市场一致，且在经济学研究热点方向的实验中，其结论与现有研究相符。ASFM为经济研究开辟了新路径。",
    "title_cn": "利用大型语言模型代理模拟金融市场",
    "tags": [
      "Agent",
      "",
      "经济研究"
    ]
  },
  {
    "title": "MetaDesigner: Advancing Artistic Typography through AI-Driven, User-Centric, and Multilingual WordArt Synthesis",
    "submit_datetime": "2024年06月28日",
    "abstract": "MetaDesigner revolutionizes artistic typography synthesis by leveraging the strengths of Large Language Models (LLMs) to drive a design paradigm centered around user engagement. At the core of this framework lies a multi-agent system comprising the Pipeline, Glyph, and Texture agents, which collectively enable the creation of customized WordArt, ranging from semantic enhancements to the imposition of complex textures. MetaDesigner incorporates a comprehensive feedback mechanism that harnesses insights from multimodal models and user evaluations to refine and enhance the design process iteratively. Through this feedback loop, the system adeptly tunes hyperparameters to align with user-defined stylistic and thematic preferences, generating WordArt that not only meets but exceeds user expectations of visual appeal and contextual relevance. Empirical validations highlight MetaDesigner's capability to effectively serve diverse WordArt applications, consistently producing aesthetically appealing and context-sensitive results.",
    "pdf_link": "https://arxiv.org/abs/2406.19859",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19859v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19859/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19859v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19859/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19859v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19859/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19859v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19859/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19859v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19859/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19859v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19859/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19859v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19859/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19859v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19859/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19859v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19859/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19859v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19859/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19859v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19859/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19859v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19859/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19859v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19859/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19859v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19859/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19859v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19859/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19859v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19859/x17.png"
      }
    ],
    "abstract_cn": "MetaDesigner 借助 LLM 的力量，创新了艺术字体设计，聚焦于提升用户参与度。其核心的多代理系统，包括 Pipeline、Glyph 和 Texture，共同打造出从语义到纹理都个性化的 WordArt。通过整合多模态模型和用户反馈的全面机制，MetaDesigner 不断优化设计，精准调整参数以贴合用户的风格与主题需求，创作出既符合又超越期待的视觉作品。实证显示，MetaDesigner 在多样化的 WordArt 应用中，始终如一地输出美观且贴合情境的成果。",
    "title_cn": "MetaDesigner：借助 AI 技术，以用户为中心，实现多语言艺术字体的创新合成，推动字体艺术的进步。",
    "tags": [
      "Agent",
      "艺术设计",
      "用户体验"
    ]
  },
  {
    "title": "ROS-LLM: A ROS framework for embodied AI with task feedback and structured reasoning",
    "submit_datetime": "2024年06月28日",
    "abstract": "We present a framework for intuitive robot programming by non-experts, leveraging natural language prompts and contextual information from the Robot Operating System (ROS). Our system integrates large language models (LLMs), enabling non-experts to articulate task requirements to the system through a chat interface. Key features of the framework include: integration of ROS with an AI agent connected to a plethora of open-source and commercial LLMs, automatic extraction of a behavior from the LLM output and execution of ROS actions/services, support for three behavior modes (sequence, behavior tree, state machine), imitation learning for adding new robot actions to the library of possible actions, and LLM reflection via human and environment feedback. Extensive experiments validate the framework, showcasing robustness, scalability, and versatility in diverse scenarios, including long-horizon tasks, tabletop rearrangements, and remote supervisory control. To facilitate the adoption of our framework and support the reproduction of our results, we have made our code open-source. You can access it at: https://github.com/huawei-noah/HEBO/tree/master/ROSLLM.",
    "pdf_link": "https://arxiv.org/abs/2406.19741",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19741v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19741/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19741v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19741/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19741v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19741/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19741v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19741/coffee_1.jpg"
      },
      {
        "url": "https://arxiv.org/html/2406.19741v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19741/coffee_2.jpg"
      },
      {
        "url": "https://arxiv.org/html/2406.19741v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19741/coffee_3.jpg"
      },
      {
        "url": "https://arxiv.org/html/2406.19741v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19741/coffee_4.jpg"
      },
      {
        "url": "https://arxiv.org/html/2406.19741v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19741/coffee_5.jpg"
      },
      {
        "url": "https://arxiv.org/html/2406.19741v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19741/coffee_6.jpg"
      },
      {
        "url": "https://arxiv.org/html/2406.19741v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19741/coffee_7.jpg"
      },
      {
        "url": "https://arxiv.org/html/2406.19741v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19741/coffee_8.jpg"
      },
      {
        "url": "https://arxiv.org/html/2406.19741v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19741/coffee_9.jpg"
      },
      {
        "url": "https://arxiv.org/html/2406.19741v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19741/coffee_10.jpg"
      },
      {
        "url": "https://arxiv.org/html/2406.19741v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19741/coffee_11.jpg"
      },
      {
        "url": "https://arxiv.org/html/2406.19741v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19741/coffee_12.jpg"
      },
      {
        "url": "https://arxiv.org/html/2406.19741v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19741/cube_6_2_feedback.mp4_1.jpg"
      },
      {
        "url": "https://arxiv.org/html/2406.19741v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19741/cube_6_2_feedback.mp4_2.jpg"
      },
      {
        "url": "https://arxiv.org/html/2406.19741v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19741/cube_6_2_feedback.mp4_3.jpg"
      },
      {
        "url": "https://arxiv.org/html/2406.19741v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19741/cube_6_2_feedback.mp4_4.jpg"
      },
      {
        "url": "https://arxiv.org/html/2406.19741v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19741/cube_6_2_feedback.mp4_5.jpg"
      },
      {
        "url": "https://arxiv.org/html/2406.19741v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19741/cube_6_2_feedback.mp4_6.jpg"
      },
      {
        "url": "https://arxiv.org/html/2406.19741v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19741/cube_6_2_feedback.mp4_7.jpg"
      },
      {
        "url": "https://arxiv.org/html/2406.19741v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19741/cube_6_2_feedback.mp4_8.jpg"
      },
      {
        "url": "https://arxiv.org/html/2406.19741v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19741/cube_6_2_feedback.mp4_9.jpg"
      },
      {
        "url": "https://arxiv.org/html/2406.19741v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19741/cube_6_2_feedback.mp4_10.jpg"
      },
      {
        "url": "https://arxiv.org/html/2406.19741v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19741/policy_correction_via_human_feedback.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19741v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19741/AA_Making_Pasta.mp4_1.jpg"
      },
      {
        "url": "https://arxiv.org/html/2406.19741v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19741/AA_Making_Pasta.mp4_3.jpg"
      },
      {
        "url": "https://arxiv.org/html/2406.19741v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19741/AA_Making_Pasta.mp4_5.jpg"
      },
      {
        "url": "https://arxiv.org/html/2406.19741v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19741/AA_Making_Pasta.mp4_7.jpg"
      },
      {
        "url": "https://arxiv.org/html/2406.19741v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19741/AA_Making_Pasta.mp4_9.jpg"
      },
      {
        "url": "https://arxiv.org/html/2406.19741v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19741/teleop_llm_user.jpg"
      },
      {
        "url": "https://arxiv.org/html/2406.19741v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19741/teleop_llm_1.jpg"
      },
      {
        "url": "https://arxiv.org/html/2406.19741v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19741/teleop_llm_2.jpg"
      },
      {
        "url": "https://arxiv.org/html/2406.19741v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19741/teleop_llm_3.jpg"
      },
      {
        "url": "https://arxiv.org/html/2406.19741v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19741/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19741v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19741/llm_tlx.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19741v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19741/Leju_cut.jpg"
      },
      {
        "url": "https://arxiv.org/html/2406.19741v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19741/air_hockey.png"
      }
    ],
    "abstract_cn": "我们开发了一个直观的机器人编程框架，让非专业人士也能轻松上手，通过自然语言提示和ROS的上下文信息来实现。该系统融合了大型语言模型（LLMs），用户只需通过聊天界面描述任务需求。框架亮点包括：ROS与AI代理的结合，后者连接了丰富的开源和商业LLMs；自动从LLM输出中提炼行为并执行ROS指令；支持序列、行为树和状态机三种行为模式；通过模仿学习扩充机器人动作库；以及基于人机环境反馈的LLM自我反思。经过广泛测试，该框架在长时任务、桌面整理和远程监控等多种场景中表现出色，兼具鲁棒性、可扩展性和灵活性。为推动应用和结果复现，我们已将代码公开，详情请访问：https://github.com/huawei-noah/HEBO/tree/master/ROSLLM。",
    "title_cn": "ROS-LLM：一款集任务反馈与结构化推理于一体的具身AI ROS框架",
    "tags": [
      "Agent",
      "机器人技术",
      "人工智能"
    ]
  },
  {
    "title": "Web2Code: A Large-scale Webpage-to-Code Dataset and Evaluation Framework for Multimodal LLMs",
    "submit_datetime": "2024年06月28日",
    "abstract": "Multimodal large language models (MLLMs) have shown impressive success across modalities such as image, video, and audio in a variety of understanding and generation tasks. However, current MLLMs are surprisingly poor at understanding webpage screenshots and generating their corresponding HTML code. To address this problem, we propose Web2Code, a benchmark consisting of a new large-scale webpage-to-code dataset for instruction tuning and an evaluation framework for the webpage understanding and HTML code translation abilities of MLLMs. For dataset construction, we leverage pretrained LLMs to enhance existing webpage-to-code datasets as well as generate a diverse pool of new webpages rendered into images. Specifically, the inputs are webpage images and instructions, while the responses are the webpage's HTML code. We further include diverse natural language QA pairs about the webpage content in the responses to enable a more comprehensive understanding of the web content. To evaluate model performance in these tasks, we develop an evaluation framework for testing MLLMs' abilities in webpage understanding and web-to-code generation. Extensive experiments show that our proposed dataset is beneficial not only to our proposed tasks but also in the general visual domain, while previous datasets result in worse performance. We hope our work will contribute to the development of general MLLMs suitable for web-based content generation and task automation. Our data and code will be available at https://github.com/MBZUAI-LLM/web2code.",
    "pdf_link": "https://arxiv.org/abs/2406.20098",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.20098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20098/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20098/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20098/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20098/cloud.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20098/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20098/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20098/ori.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20098/vicuna.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20098/crystalchat.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20098/ori.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20098/ori_code_img.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20098/ours.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20098/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20098/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20098/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20098/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20098/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20098/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20098/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20098/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20098/junbo.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20098/pix2code.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20098/WebSight.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20098/QA.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20098/WebSRC.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20098/Modern_webpages.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20098/Bootstrap_webpage.png"
      }
    ],
    "abstract_cn": "多模态大型语言模型 (MLLMs) 在图像、视频和音频等多种任务中表现卓越，但在理解网页截图和生成 HTML 代码方面却表现不佳。为此，我们推出了 Web2Code 基准，包含一个大规模网页到代码数据集及评估框架，旨在提升 MLLMs 的网页理解和代码生成能力。我们利用预训练 LLMs 增强现有数据集并生成新网页图像，输入包括网页图像和指令，输出则是网页的 HTML 代码，并附带网页内容的自然语言 QA 对，以深化理解。实验证明，我们的数据集不仅优化了特定任务，也提升了视觉领域的性能。我们期待这项工作能推动适用于网页内容生成和自动化的通用 MLLMs 的发展。相关资源将在 https://github.com/MBZUAI-LLM/web2code 提供。",
    "title_cn": "Web2Code：专为多模态大型语言模型设计的大规模网页转代码数据集及评估框架",
    "tags": [
      "LLM应用",
      "互联网",
      "软件开发"
    ]
  },
  {
    "title": "EVF-SAM: Early Vision-Language Fusion for Text-Prompted Segment Anything Model",
    "submit_datetime": "2024年06月28日",
    "abstract": "Segment Anything Model (SAM) has attracted widespread attention for its superior interactive segmentation capabilities with visual prompts while lacking further exploration of text prompts. In this paper, we empirically investigate what text prompt encoders (e.g., CLIP or LLM) are good for adapting SAM for referring expression segmentation and introduce the Early Vision-language Fusion-based SAM (EVF-SAM). EVF-SAM is a simple yet effective referring segmentation method which exploits multimodal prompts (i.e., image and text) and comprises a pre-trained vision-language model to generate referring prompts and a SAM model for segmentation. Surprisingly, we observe that: (1) multimodal prompts and (2) vision-language models with early fusion (e.g., BEIT-3) are beneficial for prompting SAM for accurate referring segmentation. Our experiments show that the proposed EVF-SAM based on BEIT-3 can obtain state-of-the-art performance on RefCOCO/+/g for referring expression segmentation and demonstrate the superiority of prompting SAM with early vision-language fusion. In addition, the proposed EVF-SAM with 1.32B parameters achieves remarkably higher performance while reducing nearly 82% of parameters compared to previous SAM methods based on large multimodal models.",
    "pdf_link": "https://arxiv.org/abs/2406.20076",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.20076v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20076/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20076v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20076/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20076v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20076/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20076v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20076/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20076v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20076/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20076v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20076/x6.png"
      }
    ],
    "abstract_cn": "SAM 模型因其出色的视觉提示交互分割能力而广受瞩目，但文本提示方面的研究尚显不足。本文通过实证研究，探讨了哪些文本提示编码器（如 CLIP 或 LLM）能有效提升 SAM 在指代表达分割中的表现，并提出了基于早期视觉语言融合的 SAM（EVF-SAM）。EVF-SAM 利用图像与文本的多模态提示，结合预训练的视觉语言模型生成指代提示，再由 SAM 模型完成分割，简单而高效。我们发现，多模态提示与早期融合的视觉语言模型（如 BEIT-3）能显著提升 SAM 的指代分割精度。实验证明，基于 BEIT-3 的 EVF-SAM 在 RefCOCO/+/g 数据集上达到了业界领先水平，并凸显了早期视觉语言融合在提升 SAM 性能方面的优势。此外，EVF-SAM 在大幅减少参数（约 82%）的同时，性能显著提升，参数规模为 1.32B，远超以往基于大型多模态模型的 SAM 方法。",
    "title_cn": "EVF-SAM：针对文本提示分割模型，采用早期视觉与语言融合技术",
    "tags": [
      "LLM应用",
      "计算机视觉",
      ""
    ]
  },
  {
    "title": "InfiniBench: A Comprehensive Benchmark for Large Multimodal Models in Very Long Video Understanding",
    "submit_datetime": "2024年06月28日",
    "abstract": "Understanding long videos, ranging from tens of minutes to several hours, presents unique challenges in video comprehension. Despite the increasing importance of long-form video content, existing benchmarks primarily focus on shorter clips. To address this gap, we introduce InfiniBench a comprehensive benchmark for very long video understanding which presents 1)The longest video duration, averaging 76.34 minutes; 2) The largest number of question-answer pairs, 108.2K; 3) Diversity in questions that examine nine different skills and include both multiple-choice questions and open-ended questions; 4) Humancentric, as the video sources come from movies and daily TV shows, with specific human-level question designs such as Movie Spoiler Questions that require critical thinking and comprehensive understanding. Using InfiniBench, we comprehensively evaluate existing Large MultiModality Models (LMMs) on each skill, including the commercial model Gemini 1.5 Flash and the open-source models. The evaluation shows significant challenges in our benchmark.Our results show that the best AI models such Gemini struggles to perform well with 42.72% average accuracy and 2.71 out of 5 average score. We hope this benchmark will stimulate the LMMs community towards long video and human-level understanding. Our benchmark can be accessed at https://vision-cair.github.io/InfiniBench/",
    "pdf_link": "https://arxiv.org/abs/2406.19875",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19875v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19875/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19875v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19875/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19875v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19875/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19875v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19875/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19875v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19875/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19875v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19875/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19875v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19875/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19875v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19875/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19875v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19875/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19875v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19875/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19875v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19875/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19875v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19875/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19875v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19875/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19875v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19875/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19875v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19875/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19875v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19875/x17.png"
      }
    ],
    "abstract_cn": "理解长视频（从数十分钟到数小时）在视频理解领域带来了独特挑战。尽管长视频内容日益重要，但现有基准多聚焦于短片段。为此，我们推出了InfiniBench，一个全面的长视频理解基准，涵盖最长视频时长（平均76.34分钟）、最多问答对（108.2K）、问题多样性（考察九种技能，含选择题与开放式问题），以及人本设计（视频源自电影与日常节目，如需批判思维的电影剧透题）。我们利用InfiniBench全面评估了多模态大型模型（LMMs），包括商业与开源模型，发现其在我们基准上表现不佳，最佳AI模型平均准确率仅42.72%，平均得分2.71（满分5）。我们期待此基准能推动LMMs社区深入长视频与人类级别理解的研究。基准链接：https://vision-cair.github.io/InfiniBench/。",
    "title_cn": "InfiniBench：一项全面的综合基准，旨在评估大型多模态模型在超长视频理解领域的性能。",
    "tags": [
      "LLM应用",
      "视频理解",
      "人工智能"
    ]
  },
  {
    "title": "MM-Instruct: Generated Visual Instructions for Large Multimodal Model Alignment",
    "submit_datetime": "2024年06月28日",
    "abstract": "This paper introduces MM-Instruct, a large-scale dataset of diverse and high-quality visual instruction data designed to enhance the instruction-following capabilities of large multimodal models (LMMs). While existing visual instruction datasets often focus on question-answering, they struggle to generalize to broader application scenarios such as creative writing, summarization, or image analysis. To address these limitations, we propose a novel approach to constructing MM-Instruct that leverages the strong instruction-following capabilities of existing LLMs to generate novel visual instruction data from large-scale but conventional image captioning datasets. MM-Instruct first leverages ChatGPT to automatically generate diverse instructions from a small set of seed instructions through augmenting and summarization. It then matches these instructions with images and uses an open-sourced large language model (LLM) to generate coherent answers to the instruction-image pairs. The LLM is grounded by the detailed text descriptions of images in the whole answer generation process to guarantee the alignment of the instruction data. Moreover, we introduce a benchmark based on the generated instruction data to evaluate the instruction-following capabilities of existing LMMs. We demonstrate the effectiveness of MM-Instruct by training a LLaVA-1.5 model on the generated data, denoted as LLaVA-Instruct, which exhibits significant improvements in instruction-following capabilities compared to LLaVA-1.5 models. The MM-Instruct dataset, benchmark, and pre-trained models are available at https://github.com/jihaonew/MM-Instruct.",
    "pdf_link": "https://arxiv.org/abs/2406.19736",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19736v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19736/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19736v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19736/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19736v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19736/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19736v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19736/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19736v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19736/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19736v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19736/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19736v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19736/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19736v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19736/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19736v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19736/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19736v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19736/x10.png"
      }
    ],
    "abstract_cn": "本文推出 MM-Instruct，一个大规模、多样且高质量的视觉指令数据集，旨在提升大型多模态模型（LMMs）的指令遵循能力。现有视觉指令数据集多聚焦于问答，难以适应创意写作、摘要或图像分析等更广泛场景。为此，我们创新构建 MM-Instruct，借助现有 LLMs 的强大指令遵循能力，从传统图像字幕数据集中生成新视觉指令数据。MM-Instruct 先利用 ChatGPT 从小规模种子指令中自动生成多样化指令，再与图像匹配，并借助开源 LLM 生成连贯答案，确保指令数据一致性。此外，我们基于此数据集设立基准，评估 LMMs 的指令遵循能力。实验证明，基于 MM-Instruct 训练的 LLaVA-Instruct 模型在指令遵循能力上显著优于 LLaVA-1.5。MM-Instruct 数据集、基准及预训练模型已开放于 https://github.com/jihaonew/MM-Instruct。",
    "title_cn": "MM-Instruct：打造视觉指令，助力大型多模态模型精准对齐",
    "tags": [
      "LLM应用",
      "人工智能",
      "计算机视觉"
    ]
  },
  {
    "title": "MMRo: Are Multimodal LLMs Eligible as the Brain for In-Home Robotics?",
    "submit_datetime": "2024年06月28日",
    "abstract": "It is fundamentally challenging for robots to serve as useful assistants in human environments because this requires addressing a spectrum of sub-problems across robotics, including perception, language understanding, reasoning, and planning. The recent advancements in Multimodal Large Language Models (MLLMs) have demonstrated their exceptional abilities in solving complex mathematical problems, mastering commonsense and abstract reasoning. This has led to the recent utilization of MLLMs as the brain in robotic systems, enabling these models to conduct high-level planning prior to triggering low-level control actions for task execution. However, it remains uncertain whether existing MLLMs are reliable in serving the brain role of robots. In this study, we introduce the first benchmark for evaluating Multimodal LLM for Robotic (MMRo) benchmark, which tests the capability of MLLMs for robot applications. Specifically, we identify four essential capabilities perception, task planning, visual reasoning, and safety measurement that MLLMs must possess to qualify as the robot's central processing unit. We have developed several scenarios for each capability, resulting in a total of 14 metrics for evaluation. We present experimental results for various MLLMs, including both commercial and open-source models, to assess the performance of existing systems. Our findings indicate that no single model excels in all areas, suggesting that current MLLMs are not yet trustworthy enough to serve as the cognitive core for robots. Our data can be found in https://mm-robobench.github.io/.",
    "pdf_link": "https://arxiv.org/abs/2406.19693",
    "graphs": [],
    "abstract_cn": "在人类环境中，机器人要成为得力助手，必须克服感知、语言理解、推理和规划等一系列挑战。多模态大型语言模型（MLLMs）的最新进展显示了其在复杂数学问题解决和抽象推理方面的卓越能力，因此被用作机器人系统的大脑，进行高级规划。然而，这些模型是否可靠地担任机器人大脑的角色尚存疑问。为此，我们推出了首个多模态LLM用于机器人的（MMRo）基准，旨在评估MLLMs在机器人应用中的能力。我们确定了四种关键能力：感知、任务规划、视觉推理和安全措施，并为此设计了14项评估指标。实验结果显示，没有单一模型在所有领域表现卓越，表明当前MLLMs尚不足以成为机器人的认知核心。详细数据可访问https://mm-robobench.github.io/。",
    "title_cn": "多模态 LLM 能否胜任家庭机器人的“大脑”角色？",
    "tags": [
      "LLM应用",
      "机器人",
      "人工智能"
    ]
  },
  {
    "title": "Enhancing Radiological Diagnosis: A Collaborative Approach Integrating AI and Human Expertise for Visual Miss Correction",
    "submit_datetime": "2024年06月28日",
    "abstract": "Human-AI collaboration to identify and correct perceptual errors in chest radiographs has not been previously explored. This study aimed to develop a collaborative AI system, CoRaX, which integrates eye gaze data and radiology reports to enhance diagnostic accuracy in chest radiology by pinpointing perceptual errors and refining the decision-making process. Using public datasets REFLACX and EGD-CXR, the study retrospectively developed CoRaX, employing a large multimodal model to analyze image embeddings, eye gaze data, and radiology reports. The system's effectiveness was evaluated based on its referral-making process, the quality of referrals, and performance in collaborative diagnostic settings. CoRaX was tested on a simulated error dataset of 271 samples with 28% (93 of 332) missed abnormalities. The system corrected 21% (71 of 332) of these errors, leaving 7% (22 of 312) unresolved. The Referral-Usefulness score, indicating the accuracy of predicted regions for all true referrals, was 0.63 (95% CI 0.59, 0.68). The Total-Usefulness score, reflecting the diagnostic accuracy of CoRaX's interactions with radiologists, showed that 84% (237 of 280) of these interactions had a score above 0.40. In conclusion, CoRaX efficiently collaborates with radiologists to address perceptual errors across various abnormalities, with potential applications in the education and training of novice radiologists.",
    "pdf_link": "https://arxiv.org/abs/2406.19686",
    "graphs": [],
    "abstract_cn": "本研究首次探索了人类与AI在识别和纠正胸部X光片感知错误方面的协作。我们开发的CoRaX系统，通过融合眼动数据和放射报告，精准定位并优化诊断决策，显著提升了胸部放射学的诊断准确性。在公开数据集上，CoRaX展现了其高效性，成功纠正了模拟数据集中21%的遗漏异常，且在与放射科医生的互动中，84%的诊断准确性得分超过0.40。CoRaX不仅优化了转诊流程，更在教育和培训新手放射科医生方面展现出巨大潜力。",
    "title_cn": "提升放射诊断：融合AI与专家智慧，共同修正视觉遗漏，实现诊断协作新高度。",
    "tags": [
      "Agent",
      "",
      "放射学"
    ]
  },
  {
    "title": "LLaRA: Supercharging Robot Learning Data for Vision-Language Policy",
    "submit_datetime": "2024年06月28日",
    "abstract": "Large Language Models (LLMs) equipped with extensive world knowledge and strong reasoning skills can tackle diverse tasks across domains, often by posing them as conversation-style instruction-response pairs. In this paper, we propose LLaRA: Large Language and Robotics Assistant, a framework which formulates robot action policy as conversations, and provides improved responses when trained with auxiliary data that complements policy learning. LLMs with visual inputs, i.e., Vision Language Models (VLMs), have the capacity to process state information as visual-textual prompts and generate optimal policy decisions in text. To train such action policy VLMs, we first introduce an automated pipeline to generate diverse high-quality robotics instruction data from existing behavior cloning data. A VLM finetuned with the resulting collection of datasets based on a conversation-style formulation tailored for robotics tasks, can generate meaningful robot action policy decisions. Our experiments across multiple simulated and real-world environments demonstrate the state-of-the-art performance of the proposed LLaRA framework. The code, datasets, and pretrained models are available at https://github.com/LostXine/LLaRA.",
    "pdf_link": "https://arxiv.org/abs/2406.20095",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.20095v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20095/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20095v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20095/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20095v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20095/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20095v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20095/datasets-v2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20095v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20095/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20095v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20095/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20095v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20095/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20095v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20095/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20095v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20095/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20095v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20095/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20095v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20095/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20095v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20095/x11.png"
      }
    ],
    "abstract_cn": "本文提出 LLaRA 框架，通过将机器人行动策略转化为对话形式，并利用辅助数据提升响应质量，展示了大型语言模型在处理跨领域任务时的强大能力。特别是视觉语言模型，能够结合视觉信息生成策略决策。我们通过自动化流程，从现有数据中提取高质量指令，进一步优化了机器人任务的表现。实验证明，LLaRA 在多环境中的表现卓越。相关资源已公开在 GitHub 上。",
    "title_cn": "LLaRA：为视觉-语言策略注入强大动力的机器人学习数据",
    "tags": [
      "Agent",
      "机器人技术",
      "人工智能"
    ]
  },
  {
    "title": "Scaling Synthetic Data Creation with 1,000,000,000 Personas",
    "submit_datetime": "2024年06月28日",
    "abstract": "We propose a novel persona-driven data synthesis methodology that leverages various perspectives within a large language model (LLM) to create diverse synthetic data. To fully exploit this methodology at scale, we introduce Persona Hub -- a collection of 1 billion diverse personas automatically curated from web data. These 1 billion personas (~13% of the world's total population), acting as distributed carriers of world knowledge, can tap into almost every perspective encapsulated within the LLM, thereby facilitating the creation of diverse synthetic data at scale for various scenarios. By showcasing Persona Hub's use cases in synthesizing high-quality mathematical and logical reasoning problems, instructions (i.e., user prompts), knowledge-rich texts, game NPCs and tools (functions) at scale, we demonstrate persona-driven data synthesis is versatile, scalable, flexible, and easy to use, potentially driving a paradigm shift in synthetic data creation and applications in practice, which may have a profound impact on LLM research and development.",
    "pdf_link": "https://arxiv.org/abs/2406.20094",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.20094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20094/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20094/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20094/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20094/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20094/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20094/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20094/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20094/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20094/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20094/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20094/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20094/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20094/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20094/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20094/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20094/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20094/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20094/x18.png"
      }
    ],
    "abstract_cn": "我们创新性地提出了一种基于人格驱动的数据合成方法，该方法通过大型语言模型 (LLM) 中的多重视角，生成多样化的合成数据。为实现这一方法的大规模应用，我们创建了 Persona Hub，这是一个包含 10 亿多样化人格的集合，这些人格从网络数据中自动筛选而出。这些人格（约占全球人口的 13%）作为世界知识的分布式载体，能够触及 LLM 中的几乎所有视角，从而大规模地促进多样化合成数据的创建，适用于多种场景。通过展示 Persona Hub 在合成高质量数学和逻辑推理问题、用户指令、知识丰富的文本、游戏角色和工具等方面的大规模应用，我们证明了基于人格驱动的数据合成方法的多功能性、可扩展性、灵活性和易用性，有望推动合成数据领域的范式变革，对 LLM 的研究与开发产生深远影响。",
    "title_cn": "利用十亿个人物角色扩展合成数据的生成",
    "tags": [
      "LLM应用",
      "人工智能",
      "数据科学"
    ]
  },
  {
    "title": "LLaVolta: Efficient Multi-modal Models via Stage-wise Visual Context Compression",
    "submit_datetime": "2024年06月28日",
    "abstract": "While significant advancements have been made in compressed representations for text embeddings in large language models (LLMs), the compression of visual tokens in large multi-modal models (LMMs) has remained a largely overlooked area. In this work, we present the study on the analysis of redundancy concerning visual tokens and efficient training within these models. Our initial experiments show that eliminating up to 70% of visual tokens at the testing stage by simply average pooling only leads to a minimal 3% reduction in visual question answering accuracy on the GQA benchmark, indicating significant redundancy in visual context. Addressing this, we introduce Visual Context Compressor, which reduces the number of visual tokens during training to enhance training efficiency without sacrificing performance. To minimize information loss caused by the compression on visual tokens while maintaining training efficiency, we develop LLaVolta as a lite training scheme. LLaVolta incorporates stage-wise visual context compression to progressively compress the visual tokens from heavily to lightly, and finally no compression at the end of training, yielding no loss of information when testing. Extensive experiments demonstrate that our approach enhances the performance of MLLMs in both image-language and video-language understanding, while also significantly cutting training costs. Code is available at https://github.com/Beckschen/LLaVolta",
    "pdf_link": "https://arxiv.org/abs/2406.20092",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.20092v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20092/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20092v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20092/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20092v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20092/x5.png"
      }
    ],
    "abstract_cn": "尽管文本嵌入的压缩在大型语言模型中取得了显著进展，但视觉令牌的压缩在大型多模态模型中仍被忽视。我们研究发现，通过简单平均池化，测试阶段可消除高达70%的视觉令牌，仅轻微影响GQA基准上的视觉问答准确性，揭示了视觉上下文的冗余。为此，我们设计了视觉上下文压缩器，通过在训练中减少视觉令牌来提升效率，同时不损性能。为避免压缩导致的信息损失，我们创新了LLaVolta轻量训练方案，采用渐进式压缩，确保训练结束时无压缩，测试无信息丢失。实验证明，我们的方法不仅大幅降低训练成本，还显著提升了多模态模型在图像与视频语言理解上的性能。代码已公开在GitHub。",
    "title_cn": "LLaVolta：采用阶段式视觉上下文压缩技术，打造高效多模态模型。",
    "tags": [
      "LLM应用",
      "多模态学习",
      "计算机视觉"
    ]
  },
  {
    "title": "ProgressGym: Alignment with a Millennium of Moral Progress",
    "submit_datetime": "2024年06月28日",
    "abstract": "Frontier AI systems, including large language models (LLMs), hold increasing influence over the epistemology of human users. Such influence can reinforce prevailing societal values, potentially contributing to the lock-in of misguided moral beliefs and, consequently, the perpetuation of problematic moral practices on a broad scale. We introduce progress alignment as a technical solution to mitigate this imminent risk. Progress alignment algorithms learn to emulate the mechanics of human moral progress, thereby addressing the susceptibility of existing alignment methods to contemporary moral blindspots. To empower research in progress alignment, we introduce ProgressGym, an experimental framework allowing the learning of moral progress mechanics from history, in order to facilitate future progress in real-world moral decisions. Leveraging 9 centuries of historical text and 18 historical LLMs, ProgressGym enables codification of real-world progress alignment challenges into concrete benchmarks. Specifically, we introduce three core challenges: tracking evolving values (PG-Follow), preemptively anticipating moral progress (PG-Predict), and regulating the feedback loop between human and AI value shifts (PG-Coevolve). Alignment methods without a temporal dimension are inapplicable to these tasks. In response, we present lifelong and extrapolative algorithms as baseline methods of progress alignment, and build an open leaderboard soliciting novel algorithms and challenges. The framework and the leaderboard are available at https://github.com/PKU-Alignment/ProgressGym and https://huggingface.co/spaces/PKU-Alignment/ProgressGym-LeaderBoard respectively.",
    "pdf_link": "https://arxiv.org/abs/2406.20087",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.20087v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20087/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20087v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20087/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20087v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20087/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20087v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20087/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20087v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20087/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20087v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20087/x6.png"
      }
    ],
    "abstract_cn": "前沿AI系统，尤其是大型语言模型（LLMs），正日益影响人类用户的认识论。这种影响可能强化社会主流价值观，甚至可能导致错误道德信念的固化，进而广泛延续有问题的道德实践。为应对这一风险，我们提出了“进步对齐”技术方案。该方案通过学习人类道德进步的机制，有效解决了现有对齐方法对当代道德盲点的敏感问题。为推动这一研究，我们开发了ProgressGym实验框架，该框架允许从历史中学习道德进步机制，助力未来现实世界道德决策的进步。通过整合9个世纪的历史文本和18个历史LLMs，ProgressGym将现实世界的进步对齐挑战具体化为基准。我们特别提出了三个核心挑战：跟踪价值演变（PG-Follow），预先预测道德进步（PG-Predict），以及调节人类与AI价值转变间的反馈回路（PG-Coevolve）。针对这些挑战，我们提出了终身学习和外推算法作为基线方法，并设立了一个开放的排行榜，征集创新算法和挑战。ProgressGym框架和排行榜详情可分别访问https://github.com/PKU-Alignment/ProgressGym和https://huggingface.co/spaces/PKU-Alignment/ProgressGym-LeaderBoard。",
    "title_cn": "ProgressGym：与千年道德进步的同步发展",
    "tags": [
      "LLM理论",
      "人工智能",
      "道德伦理"
    ]
  },
  {
    "title": "Auto Cherry-Picker: Learning from High-quality Generative Data Driven by Language",
    "submit_datetime": "2024年06月28日",
    "abstract": "Diffusion-based models have shown great potential in generating high-quality images with various layouts, which can benefit downstream perception tasks. However, a fully automatic layout generation driven only by language and a suitable metric for measuring multiple generated instances has not been well explored. In this work, we present Auto Cherry-Picker (ACP), a novel framework that generates high-quality multi-modal training examples to augment perception and multi-modal training. Starting with a simple list of natural language concepts, we prompt large language models (LLMs) to generate a detailed description and design reasonable layouts. Next, we use an off-the-shelf text-to-image model to generate multiple images. Then, the generated data are refined using a comprehensively designed metric to ensure quality. In particular, we present a new metric, Composite Layout and Image Score (CLIS), to evaluate the generated images fairly. Our synthetic high-quality examples boost performance in various scenarios by customizing the initial concept list, especially in addressing challenges associated with long-tailed distribution and imbalanced datasets. Experiment results on downstream tasks demonstrate that Auto Cherry-Picker can significantly improve the performance of existing models. In addition, we have thoroughly investigated the correlation between CLIS and performance gains in downstream tasks, and we find that a better CLIS score results in better performance. This finding shows the potential for evaluation metrics as the role for various visual perception and MLLM tasks. Code will be available.",
    "pdf_link": "https://arxiv.org/abs/2406.20085",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.20085v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20085/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20085v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20085/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20085v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20085/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20085v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20085/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20085v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20085/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20085v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20085/x8.png"
      }
    ],
    "abstract_cn": "基于扩散的模型在生成多样化高质量图像方面潜力巨大，有助于下游感知任务。然而，完全自动的布局生成及多实例评估指标尚待深入探索。为此，我们推出Auto Cherry-Picker（ACP）框架，旨在通过自然语言概念列表驱动LLM，生成详尽描述与合理布局，进而利用文本到图像模型产出多幅图像，并借助精心设计的复合布局和图像分数（CLIS）指标优化生成质量。实验证实，ACP能显著提升模型性能，尤其在应对长尾分布与数据不平衡挑战时表现突出。此外，CLIS与性能提升间的正相关性揭示了其在视觉感知与多模态语言模型任务中的评估潜力。相关代码即将开放。",
    "title_cn": "自动精选者：借助语言驱动的高质量生成数据进行学习",
    "tags": [
      "LLM应用",
      "视觉感知",
      "多模态语言模型"
    ]
  },
  {
    "title": "Molecular Facts: Desiderata for Decontextualization in LLM Fact Verification",
    "submit_datetime": "2024年06月28日",
    "abstract": "Automatic factuality verification of large language model (LLM) generations is becoming more and more widely used to combat hallucinations. A major point of tension in the literature is the granularity of this fact-checking: larger chunks of text are hard to fact-check, but more atomic facts like propositions may lack context to interpret correctly. In this work, we assess the role of context in these atomic facts. We argue that fully atomic facts are not the right representation, and define two criteria for molecular facts: decontextuality, or how well they can stand alone, and minimality, or how little extra information is added to achieve decontexuality. We quantify the impact of decontextualization on minimality, then present a baseline methodology for generating molecular facts automatically, aiming to add the right amount of information. We compare against various methods of decontextualization and find that molecular facts balance minimality with fact verification accuracy in ambiguous settings.",
    "pdf_link": "https://arxiv.org/abs/2406.20079",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.20079v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20079/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20079v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20079/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20079v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20079/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20079v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20079/entity_switch.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20079v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20079/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20079v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20079/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20079v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20079/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20079v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20079/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20079v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20079/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20079v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20079/x9.png"
      }
    ],
    "abstract_cn": "随着对抗幻觉的需求增加，大型语言模型生成的自动事实验证应用日益广泛。然而，事实检查的粒度问题成为研究焦点：大段文本难以验证，而过于细碎的事实又可能缺乏必要的上下文。本研究聚焦于原子事实中的上下文作用，提出“分子事实”概念，强调其独立性和信息量的最小化。通过量化分析和基准方法的开发，我们旨在找到信息量与验证准确性的最佳平衡点，为复杂情境下的自动事实验证提供新思路。",
    "title_cn": "分子事实：LLM 事实验证中的去上下文化需求",
    "tags": [
      "LLM应用",
      "信息验证",
      "人工智能"
    ]
  },
  {
    "title": "BioMNER: A Dataset for Biomedical Method Entity Recognition",
    "submit_datetime": "2024年06月28日",
    "abstract": "Named entity recognition (NER) stands as a fundamental and pivotal task within the realm of Natural Language Processing. Particularly within the domain of Biomedical Method NER, this task presents notable challenges, stemming from the continual influx of domain-specific terminologies in scholarly literature. Current research in Biomedical Method (BioMethod) NER suffers from a scarcity of resources, primarily attributed to the intricate nature of methodological concepts, which necessitate a profound understanding for precise delineation. In this study, we propose a novel dataset for biomedical method entity recognition, employing an automated BioMethod entity recognition and information retrieval system to assist human annotation. Furthermore, we comprehensively explore a range of conventional and contemporary open-domain NER methodologies, including the utilization of cutting-edge large-scale language models (LLMs) customised to our dataset. Our empirical findings reveal that the large parameter counts of language models surprisingly inhibit the effective assimilation of entity extraction patterns pertaining to biomedical methods. Remarkably, the approach, leveraging the modestly sized ALBERT model (only 11MB), in conjunction with conditional random fields (CRF), achieves state-of-the-art (SOTA) performance.",
    "pdf_link": "https://arxiv.org/abs/2406.20038",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.20038v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20038/data.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20038v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20038/baichuan.png"
      }
    ],
    "abstract_cn": "命名实体识别（NER）是自然语言处理中的核心任务，尤其在生物医学领域，由于专业术语的不断涌现，这一任务更具挑战性。当前生物医学方法NER研究因方法概念的复杂性而资源稀缺。为此，我们创建了一个新的数据集，并利用自动化系统辅助人工标注。同时，我们探索了多种NER方法，包括定制的大型语言模型。实验表明，大型模型参数反而不利于生物医学方法实体的提取，而结合CRF的小型ALBERT模型则达到了顶尖性能。",
    "title_cn": "BioMNER：专为生物医学方法实体识别设计的数据集",
    "tags": [
      "LLM应用",
      "生物医学",
      ""
    ]
  },
  {
    "title": "LEMoE: Advanced Mixture of Experts Adaptor for Lifelong Model Editing of Large Language Models",
    "submit_datetime": "2024年06月28日",
    "abstract": "Large language models (LLMs) require continual knowledge updates to stay abreast of the ever-changing world facts, prompting the formulation of lifelong model editing task. While recent years have witnessed the development of various techniques for single and batch editing, these methods either fail to apply or perform sub-optimally when faced with lifelong editing. In this paper, we introduce LEMoE, an advanced Mixture of Experts (MoE) adaptor for lifelong model editing. We first analyze the factors influencing the effectiveness of conventional MoE adaptor in lifelong editing, including catastrophic forgetting, inconsistent routing and order sensitivity. Based on these insights, we propose a tailored module insertion method to achieve lifelong editing, incorporating a novel KV anchor routing to enhance routing consistency between training and inference stage, along with a concise yet effective clustering-based editing order planning. Experimental results demonstrate the effectiveness of our method in lifelong editing, surpassing previous model editing techniques while maintaining outstanding performance in batch editing task. Our code will be available.",
    "pdf_link": "https://arxiv.org/abs/2406.20030",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.20030v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20030/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20030v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20030/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20030v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20030/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20030v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20030/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20030v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20030/x5.png"
      }
    ],
    "abstract_cn": "为了跟上瞬息万变的世界，大型语言模型 (LLM) 需要不断更新知识，这催生了终身模型编辑任务。尽管已有多种编辑技术，但在终身编辑场景中，它们往往力不从心。为此，我们推出了 LEMoE，一种创新的专家混合 (MoE) 适配器，专为终身编辑设计。我们深入剖析了传统 MoE 适配器在终身编辑中的局限，如灾难性遗忘、路由不一致及顺序敏感等问题。基于此，我们提出了一种定制化的模块插入策略，通过引入 KV 锚路由提升训练与推理阶段的路由一致性，并采用基于聚类的编辑顺序规划，简洁高效。实验证明，我们的方法在终身编辑领域表现卓越，不仅超越了现有技术，还在批量编辑任务中展现了出色的性能。相关代码即将开放。",
    "title_cn": "LEMoE：专为大型语言模型设计的终身编辑工具，采用先进的多专家混合适配技术。",
    "tags": [
      "LLM应用",
      "人工智能",
      "软件开发"
    ]
  },
  {
    "title": "ToolBeHonest: A Multi-level Hallucination Diagnostic Benchmark for Tool-Augmented Large Language Models",
    "submit_datetime": "2024年06月28日",
    "abstract": "Tool-augmented large language models (LLMs) are rapidly being integrated into real-world applications. Due to the lack of benchmarks, the community still needs to fully understand the hallucination issues within these models. To address this challenge, we introduce a comprehensive diagnostic benchmark, ToolBH. Specifically, we assess the LLM's hallucinations through two perspectives: depth and breadth. In terms of depth, we propose a multi-level diagnostic process, including (1) solvability detection, (2) solution planning, and (3) missing-tool analysis. For breadth, we consider three scenarios based on the characteristics of the toolset: missing necessary tools, potential tools, and limited functionality tools. Furthermore, we developed seven tasks and collected 700 evaluation samples through multiple rounds of manual annotation. The results show the significant challenges presented by the ToolBH benchmark. The current advanced models Gemini-1.5-Pro and GPT-4o only achieve a total score of 45.3 and 37.0, respectively, on a scale of 100. In this benchmark, larger model parameters do not guarantee better performance; the training data and response strategies also play a crucial role in tool-enhanced LLM scenarios. Our diagnostic analysis indicates that the primary reason for model errors lies in assessing task solvability. Additionally, open-weight models suffer from performance drops with verbose replies, whereas proprietary models excel with longer reasoning.",
    "pdf_link": "https://arxiv.org/abs/2406.20015",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.20015v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20015/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20015v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20015/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20015v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20015/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20015v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20015/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20015v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20015/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20015v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20015/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20015v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20015/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20015v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20015/x8.png"
      }
    ],
    "abstract_cn": "工具增强的LLM正迅速融入实际应用，但社区对这些模型中的幻觉问题理解尚浅。为此，我们推出了全面诊断基准ToolBH，从深度与广度双重视角评估LLM幻觉。深度诊断涵盖可解性检测、解决方案规划及缺失工具分析；广度则涉及缺失必要工具、潜在工具与功能受限工具三种情景。我们设计七项任务，收集700样本，揭示ToolBH的挑战性：Gemini-1.5-Pro与GPT-4o得分仅45.3与37.0（满分100）。大参数非性能保证，训练数据与响应策略同样关键。诊断显示，错误主因在于任务可解性评估；开放权重模型遇冗长回复性能下滑，专有模型则长推理更优。",
    "title_cn": "ToolBeHonest：针对工具增强型大型语言模型的多层次幻觉诊断基准",
    "tags": [
      "LLM应用",
      "人工智能",
      "软件开发"
    ]
  },
  {
    "title": "The SIFo Benchmark: Investigating the Sequential Instruction Following Ability of Large Language Models",
    "submit_datetime": "2024年06月28日",
    "abstract": "Following multiple instructions is a crucial ability for large language models (LLMs). Evaluating this ability comes with significant challenges: (i) limited coherence between multiple instructions, (ii) positional bias where the order of instructions affects model performance, and (iii) a lack of objectively verifiable tasks. To address these issues, we introduce a benchmark designed to evaluate models' abilities to follow multiple instructions through sequential instruction following (SIFo) tasks. In SIFo, the successful completion of multiple instructions is verifiable by examining only the final instruction. Our benchmark evaluates instruction following using four tasks (text modification, question answering, mathematics, and security rule following), each assessing different aspects of sequential instruction following. Our evaluation of popular LLMs, both closed-source and open-source, shows that more recent and larger models significantly outperform their older and smaller counterparts on the SIFo tasks, validating the benchmark's effectiveness. All models struggle with following sequences of instructions, hinting at an important lack of robustness of today's language models.",
    "pdf_link": "https://arxiv.org/abs/2406.19999",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19999v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19999/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19999v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19999/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19999v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19999/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19999v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19999/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19999v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19999/mif_tasks_colored.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLM）能够遵循多个指令是一项关键能力，但评估这一能力充满挑战，包括指令间连贯性不足、指令顺序影响性能以及缺乏客观验证任务。为此，我们设计了一个基准，通过顺序指令遵循（SIFo）任务来评估模型能力。在SIFo任务中，只需检查最终指令即可验证多个指令的完成情况。基准包含四个任务（文本修改、问答、数学和安全规则遵循），分别评估指令遵循的不同方面。评估显示，较新且规模更大的模型在SIFo任务上表现更佳，证明了基准的有效性。然而，所有模型在处理指令序列时均显露不足，揭示了当前语言模型在鲁棒性方面的欠缺。",
    "title_cn": "SIFo 基准旨在探究大型语言模型在遵循顺序指令方面的能力。",
    "tags": [
      "LLM应用",
      "人工智能",
      "软件开发"
    ]
  },
  {
    "title": "Single Parent Family: A Spectrum of Family Members from a Single Pre-Trained Foundation Model",
    "submit_datetime": "2024年06月28日",
    "abstract": "This paper introduces a novel method of Progressive Low Rank Decomposition (PLRD) tailored for the compression of large language models. Our approach leverages a pre-trained model, which is then incrementally decompressed to smaller sizes using progressively lower ranks. This method allows for significant reductions in computational overhead and energy consumption, as subsequent models are derived from the original without the need for retraining from scratch. We detail the implementation of PLRD, which strategically decreases the tensor ranks, thus optimizing the trade-off between model performance and resource usage. The efficacy of PLRD is demonstrated through extensive experiments showing that models trained with PLRD method on only 1B tokens maintain comparable performance with traditionally trained models while using 0.1% of the tokens. The versatility of PLRD is highlighted by its ability to generate multiple model sizes from a single foundational model, adapting fluidly to varying computational and memory budgets. Our findings suggest that PLRD could set a new standard for the efficient scaling of LLMs, making advanced AI more feasible on diverse platforms.",
    "pdf_link": "https://arxiv.org/abs/2406.19995",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19995v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19995/training_efficiency.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19995v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19995/mistral.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19995v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19995/llama.png"
      }
    ],
    "abstract_cn": "本文提出了一种创新的渐进低秩分解（PLRD）技术，专为大型语言模型压缩设计。该方法通过预训练模型逐步分解，降低秩以减小模型尺寸，从而大幅减少计算和能源消耗，且无需重新训练。PLRD通过战略性降低张量秩，优化了性能与资源使用的平衡。实验表明，PLRD训练的模型在仅用1B令牌的情况下，性能与传统模型相当，且仅耗用0.1%的令牌。PLRD的灵活性体现在能从单一基础模型生成多种尺寸，适应不同计算和内存需求。研究显示，PLRD有望成为LLMs高效扩展的新标杆，推动高级AI在多平台上的应用。",
    "title_cn": "单亲家庭：源自单一预训练模型的多样化家庭成员谱系",
    "tags": [
      "LLM理论",
      "人工智能",
      "能源效率"
    ]
  },
  {
    "title": "ScaleBiO: Scalable Bilevel Optimization for LLM Data Reweighting",
    "submit_datetime": "2024年06月28日",
    "abstract": "Bilevel optimization has shown its utility across various machine learning settings, yet most algorithms in practice require second-order information, making it challenging to scale them up. Only recently, a paradigm of first-order algorithms emerged, capable of effectively addressing bilevel optimization problems. Nevertheless, the practical efficiency of this paradigm remains unverified, particularly in the context of large language models (LLMs). This paper introduces the first scalable instantiation of this paradigm called ScaleBiO, focusing on bilevel optimization for large-scale LLM data reweighting. By combining with a recently proposed memory-efficient training technique called LISA, our novel algorithm allows the paradigm to scale to 34-billion-parameter LLMs on eight A40 GPUs, marking the first successful application of bilevel optimization under practical scenarios for large-sized LLMs. Empirically, extensive experiments on data reweighting verify the effectiveness of ScaleBiO for different-scaled models, including GPT-2, LLaMA-3-8B, GPT-NeoX-20B, and Yi-34B, where bilevel optimization succeeds in filtering irrelevant data samples and selecting informative samples. Theoretically, ScaleBiO ensures the optimality of the learned data weights, along with a convergence guarantee matching the conventional first-order bilevel optimization paradigm on smooth and strongly convex objectives.",
    "pdf_link": "https://arxiv.org/abs/2406.19976",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19976v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19976/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19976v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19976/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19976v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19976/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19976v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19976/x4.png"
      }
    ],
    "abstract_cn": "双层优化在机器学习领域展现出广泛应用，但多数算法依赖二阶信息，限制了其扩展性。近期，一阶算法范式崭露头角，有效应对双层优化挑战。本文首创可扩展实例ScaleBiO，聚焦于大规模LLM数据重权重的双层优化。结合高效训练技术LISA，新算法在八块A40 GPU上成功扩展至340亿参数LLM，首次在实际场景中应用双层优化。实证实验表明，ScaleBiO对不同规模模型如GPT-2、LLaMA-3-8B、GPT-NeoX-20B和Yi-34B均有效，成功筛选关键数据。理论层面，ScaleBiO确保数据权重最优，并提供与传统一阶范式相匹配的收敛保证，适用于平滑且强凸目标函数。",
    "title_cn": "ScaleBiO：为 LLM 数据重加权提供可扩展的双层优化方案",
    "tags": [
      "LLM应用",
      "机器学习",
      "大规模数据处理"
    ]
  },
  {
    "title": "STLLaVA-Med: Self-Training Large Language and Vision Assistant for Medical",
    "submit_datetime": "2024年06月28日",
    "abstract": "Large Vision-Language Models (LVLMs) have shown significant potential in assisting medical diagnosis by leveraging extensive biomedical datasets. However, the advancement of medical image understanding and reasoning critically depends on building high-quality visual instruction data, which is costly and labor-intensive to obtain, particularly in the medical domain. To mitigate this data-starving issue, we introduce Self-Training Large Language and Vision Assistant for Medical (STLLaVA-Med). The proposed method is designed to train a policy model (an LVLM) capable of auto-generating medical visual instruction data to improve data efficiency, guided through Direct Preference Optimization (DPO). Specifically, a more powerful and larger LVLM (e.g., GPT-4o) is involved as a biomedical expert to oversee the DPO fine-tuning process on the auto-generated data, encouraging the policy model to align efficiently with human preferences. We validate the efficacy and data efficiency of STLLaVA-Med across three major medical Visual Question Answering (VQA) benchmarks, demonstrating competitive zero-shot performance with the utilization of only 9% of the medical data.",
    "pdf_link": "https://arxiv.org/abs/2406.19973",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19973v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19973/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19973v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19973/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19973v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19973/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19973v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19973/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19973v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19973/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19973v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19973/x6.png"
      }
    ],
    "abstract_cn": "大型视觉-语言模型 (LVLMs) 在辅助医疗诊断方面潜力巨大，但医疗图像理解和推理的进步依赖于高质量视觉指导数据的构建，这在医疗领域尤为昂贵且劳动密集。为此，我们推出了自训练大型语言与视觉助手用于医疗 (STLLaVA-Med)，旨在通过直接偏好优化 (DPO) 引导，训练策略模型自动生成医疗视觉指导数据，提高数据效率。我们引入更强大的 LVLM (如 GPT-4o) 作为生物医学专家，监督策略模型与人类偏好高效对齐。实验证明，STLLaVA-Med 在三大医疗 VQA 基准上表现优异，仅用 9% 的医疗数据即展现出竞争性的零-shot 性能。",
    "title_cn": "STLLaVA-Med：医学领域的自训练大型语言与视觉助手",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "HumanVLA: Towards Vision-Language Directed Object Rearrangement by Physical Humanoid",
    "submit_datetime": "2024年06月28日",
    "abstract": "Physical Human-Scene Interaction (HSI) plays a crucial role in numerous applications.\n  However, existing HSI techniques are limited to specific object dynamics and privileged information, which prevents the development of more comprehensive applications.\n  To address this limitation, we introduce HumanVLA for general object rearrangement directed by practical vision and language.\n  A teacher-student framework is utilized to develop HumanVLA.\n  A state-based teacher policy is trained first using goal-conditioned reinforcement learning and adversarial motion prior.\n  Then, it is distilled into a vision-language-action model via behavior cloning.\n  We propose several key insights to facilitate the large-scale learning process.\n  To support general object rearrangement by physical humanoid, we introduce a novel Human-in-the-Room dataset encompassing various rearrangement tasks.\n  Through extensive experiments and analysis, we demonstrate the effectiveness of the proposed approach.",
    "pdf_link": "https://arxiv.org/abs/2406.19972",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19972v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19972/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19972v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19972/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19972v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19972/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19972v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19972/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19972v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19972/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19972v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19972/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19972v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19972/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19972v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19972/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19972v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19972/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19972v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19972/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19972v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19972/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19972v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19972/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19972v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19972/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19972v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19972/x14.png"
      }
    ],
    "abstract_cn": "物理人-场景交互 (HSI) 在众多领域中至关重要。然而，现有技术受限于特定物体动态和特权信息，限制了更广泛应用的发展。为此，我们推出了 HumanVLA，一个由视觉和语言引导的通用物体重新排列系统。我们采用教师-学生框架，首先通过目标条件强化学习和对抗性运动先验训练教师策略，再通过行为克隆将其转化为视觉-语言-动作模型。我们还提出了关键见解，以优化大规模学习。为支持人形机器人进行多样化的物体重新排列，我们创建了 Human-in-the-Room 数据集。通过详尽的实验和分析，我们验证了该方法的有效性。",
    "title_cn": "HumanVLA 项目旨在通过物理人形机器人，实现视觉与语言共同引导的物体重新排列。",
    "tags": [
      "Agent",
      "机器人",
      "人工智能"
    ]
  },
  {
    "title": "Into the Unknown: Generating Geospatial Descriptions for New Environments",
    "submit_datetime": "2024年06月28日",
    "abstract": "Similar to vision-and-language navigation (VLN) tasks that focus on bridging the gap between vision and language for embodied navigation, the new Rendezvous (RVS) task requires reasoning over allocentric spatial relationships (independent of the observer's viewpoint) using non-sequential navigation instructions and maps. However, performance substantially drops in new environments with no training data. Using opensource descriptions paired with coordinates (e.g., Wikipedia) provides training data but suffers from limited spatially-oriented text resulting in low geolocation resolution. We propose a large-scale augmentation method for generating high-quality synthetic data for new environments using readily available geospatial data. Our method constructs a grounded knowledge-graph, capturing entity relationships. Sampled entities and relations (`shop north of school') generate navigation instructions via (i) generating numerous templates using context-free grammar (CFG) to embed specific entities and relations; (ii) feeding the entities and relation into a large language model (LLM) for instruction generation. A comprehensive evaluation on RVS, showed that our approach improves the 100-meter accuracy by 45.83% on unseen environments. Furthermore, we demonstrate that models trained with CFG-based augmentation achieve superior performance compared with those trained with LLM-based augmentation, both in unseen and seen environments. These findings suggest that the potential advantages of explicitly structuring spatial information for text-based geospatial reasoning in previously unknown, can unlock data-scarce scenarios.",
    "pdf_link": "https://arxiv.org/abs/2406.19967",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19967v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19967/graph_example2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19967v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19967/example.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19967v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19967/IntotheUnknown.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19967v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19967/manhattan_graph_accuracy.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19967v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19967/manhattan_graph_error2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19967v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19967/pittsburgh_graph_accuracy.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19967v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19967/pittsburgh_graph_error2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19967v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19967/distribution.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19967v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19967/model6.png"
      }
    ],
    "abstract_cn": "类似于视觉-语言导航任务，新提出的 Rendezvous 任务需要利用非顺序指令和地图，对独立于观察者视角的空间关系进行推理。然而，在新环境中，缺乏训练数据导致性能大幅下降。我们利用带有坐标的开源描述（如维基百科）提供训练数据，但受限于空间文本的不足，地理位置分辨率较低。为此，我们提出了一种大规模数据增强方法，利用现有地理空间数据为新环境生成高质量合成数据。该方法构建了一个基于知识的图谱，捕捉实体间的空间关系。通过生成大量上下文无关文法模板并结合大型语言模型，我们能够生成具体的导航指令。实验表明，我们的方法在不熟悉环境中将导航精度提高了45.83%。此外，基于上下文无关文法的增强方法在未见和已见环境中均优于基于大型语言模型的增强方法。这表明，在处理基于文本的地理空间推理时，明确结构化空间信息对于解锁数据稀缺场景具有重要意义。",
    "title_cn": "探索未知：为新环境打造地理空间描述",
    "tags": [
      "LLM应用",
      "地理信息系统",
      "人工智能"
    ]
  },
  {
    "title": "BESTOW: Efficient and Streamable Speech Language Model with the Best of Two Worlds in GPT and T5",
    "submit_datetime": "2024年06月28日",
    "abstract": "Incorporating speech understanding capabilities into pretrained large-language models has become a vital research direction (SpeechLLM). The previous architectures can be categorized as: i) GPT-style, prepend speech prompts to the text prompts as a sequence of LLM inputs like a decoder-only model; ii) T5-style, introduce speech cross-attention to each layer of the pretrained LLMs. We propose BESTOW architecture to bring the BESt features from TwO Worlds into a single model that is highly efficient and has strong multitask capabilities. Moreover, there is no clear streaming solution for either style, especially considering the solution should generalize to speech multitask. We reformulate streamable SpeechLLM as a read-write policy problem and unifies the offline and streaming research with BESTOW architecture. Hence we demonstrate the first open-source SpeechLLM solution that enables Streaming and Multitask at scale (beyond ASR) at the same time. This streamable solution achieves very strong performance on a wide range of speech tasks (ASR, AST, SQA, unseen DynamicSuperb). It is end-to-end optimizable, with lower training/inference cost, and demonstrates LLM knowledge transferability to speech.",
    "pdf_link": "https://arxiv.org/abs/2406.19954",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19954v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19954/framework.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19954v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19954/model-comp2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19954v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19954/LAALasr.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19954v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19954/LAALde_en.png"
      }
    ],
    "abstract_cn": "将语音理解融入预训练大型语言模型已成为关键研究领域。过往架构如GPT风格和T5风格各有特点，但缺乏流式通用解决方案。我们创新的BESTOW架构，高效整合双世界精华，强化多任务处理。通过将流式SpeechLLM重塑为读写策略问题，BESTOW统一了研究范式，首次推出开源、支持大规模流式与多任务的SpeechLLM，性能卓越，成本效益高，并验证了LLM知识向语音领域的迁移能力。",
    "title_cn": "BESTOW：融合 GPT 与 T5 双重优势，打造高效且支持流式传输的语音语言模型。",
    "tags": [
      "LLM应用",
      "语音识别",
      "人工智能"
    ]
  },
  {
    "title": "Calibrating LLMs with Preference Optimization on Thought Trees for Generating Rationale in Science Question Scoring",
    "submit_datetime": "2024年06月28日",
    "abstract": "Generating rationales that justify scoring decisions has been a promising way to facilitate explainability in automated scoring systems. However, existing methods do not match the accuracy of classifier-based methods. Plus, the generated rationales often contain hallucinated information. To address these issues, we propose a novel framework capable of generating more faithful rationales and, more importantly, matching performance with classifier-based black-box scoring systems. We first mimic the human assessment process by querying Large Language Models (LLMs) to generate a thought tree. We then summarise intermediate assessment decisions from each thought tree path for creating synthetic rationale data and rationale preference data. Finally, we utilise the generated synthetic data to calibrate LLMs through a two-step training process: supervised fine-tuning and preference optimization. Extensive experimental results demonstrate that our framework achieves a 38% assessment performance improvement in the QWK score compared to prior work while producing higher-quality rationales, as recognised by human evaluators and LLMs. Our work sheds light on the effectiveness of performing preference optimization using synthetic preference data obtained from thought tree paths.",
    "pdf_link": "https://arxiv.org/abs/2406.19949",
    "graphs": [],
    "abstract_cn": "为了提升自动化评分系统的可解释性，我们提出了一种新框架，该框架不仅能生成更真实合理的理由，还能与基于分类器的评分系统媲美。我们通过模拟人类评估过程，利用大型语言模型生成思维树，并从中提炼出合成理由和偏好数据。通过监督微调和偏好优化两步训练，我们的框架在QWK评分上比以往提升了38%，并产出更受认可的高质量理由。这一成果展示了合成偏好数据在优化评估中的潜力。",
    "title_cn": "通过优化思维树上的偏好，我们校准 LLM，以在科学问题评分中生成更合理的解释。",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Solving Token Gradient Conflict in Mixture-of-Experts for Large Vision-Language Model",
    "submit_datetime": "2024年06月28日",
    "abstract": "The Mixture-of-Experts (MoE) has gained increasing attention in the study of Large Vision-Language Models (LVLMs). It uses a sparse model to replace the dense model, achieving comparable performance while activating fewer parameters during inference, thus significantly reducing the inference cost. Existing MoE methods in LVLMs encourage different experts to handle different tokens, and thus they employ a router to predict the routing for each token. However, the predictions are based solely on sample features and do not truly reveal the optimization direction of tokens. This can lead to severe optimization conflicts between different tokens within an expert. To address this problem, this paper proposes a novel method based on token-level gradient analysis. Specifically, we first use token-level gradients to identify conflicting tokens in experts. Then, we add a specialized loss tailored to eliminate conflicts among tokens within each expert. Our method can serve as a plug-in for diverse Large Vision-Language Models, and extensive experimental results demonstrate the effectiveness of our method. The code will be publicly available at https://github.com/longrongyang/STGC.",
    "pdf_link": "https://arxiv.org/abs/2406.19905",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19905v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19905/teaser_4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19905v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19905/pipeline_2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19905v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19905/statistic_1.png"
      }
    ],
    "abstract_cn": "在大型视觉-语言模型 (LVLMs) 的研究中，Mixture-of-Experts (MoE) 备受瞩目。通过稀疏模型替代密集模型，MoE 在保持性能的同时大幅降低推理成本。然而，现有方法基于样本特征的路由预测未能真正揭示令牌的优化方向，可能导致专家内部令牌间的优化冲突。为此，我们提出了一种基于令牌级梯度分析的新方法，通过识别和消除专家内部令牌冲突，提升模型性能。该方法兼容多种 LVLMs，实验证明其有效性。相关代码将在 GitHub 上公开。",
    "title_cn": "解决大型视觉-语言模型中混合专家系统令牌梯度冲突的难题",
    "tags": [
      "LLM应用",
      "计算机视觉",
      ""
    ]
  },
  {
    "title": "Paraphrase Types Elicit Prompt Engineering Capabilities",
    "submit_datetime": "2024年06月28日",
    "abstract": "Much of the success of modern language models depends on finding a suitable prompt to instruct the model. Until now, it has been largely unknown how variations in the linguistic expression of prompts affect these models. This study systematically and empirically evaluates which linguistic features influence models through paraphrase types, i.e., different linguistic changes at particular positions. We measure behavioral changes for five models across 120 tasks and six families of paraphrases (i.e., morphology, syntax, lexicon, lexico-syntax, discourse, and others). We also control for other prompt engineering factors (e.g., prompt length, lexical diversity, and proximity to training data). Our results show a potential for language models to improve tasks when their prompts are adapted in specific paraphrase types (e.g., 6.7% median gain in Mixtral 8x7B; 5.5% in LLaMA 3 8B). In particular, changes in morphology and lexicon, i.e., the vocabulary used, showed promise in improving prompts. These findings contribute to developing more robust language models capable of handling variability in linguistic expression.",
    "pdf_link": "https://arxiv.org/abs/2406.19898",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19898v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19898/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19898v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19898/teaser_method.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19898v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19898/gain_loss_paraphrase_groups.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19898v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19898/gain_loss_by_task_categories.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19898v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19898/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19898v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19898/lexical_richness.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19898v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19898/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19898v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19898/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19898v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19898/gain_loss_by_paraphrase_types.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19898v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19898/llama_scale_comparison.png"
      }
    ],
    "abstract_cn": "现代语言模型的成功很大程度上依赖于找到合适的提示来指导模型。然而，提示的语言表达变化如何影响模型至今仍是个谜。本研究通过分析120个任务和六种释义类型，系统地探索了语言特征对模型的影响。我们发现，当提示采用特定的释义类型时，模型性能有所提升，尤其是在形态学和词汇方面的变化。这些发现为构建更强大的语言模型提供了新思路，使其能更好地应对语言表达的多样性。",
    "title_cn": "释义类型激发了提示工程的潜能",
    "tags": [
      "LLM理论",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Untangling the Unrestricted Web: Automatic Identification of Multilingual Registers",
    "submit_datetime": "2024年06月28日",
    "abstract": "This article explores deep learning models for the automatic identification of registers - text varieties such as news reports and discussion forums - in web-based datasets across 16 languages. Web register (or genre) identification would provide a robust solution for understanding the content of web-scale datasets, which have become crucial in computational linguistics. Despite recent advances, the potential of register classifiers on the noisy web remains largely unexplored, particularly in multilingual settings and when targeting the entire unrestricted web. We experiment with a range of deep learning models using the new Multilingual CORE corpora, which includes 16 languages annotated using a detailed, hierarchical taxonomy of 25 registers designed to cover the entire unrestricted web. Our models achieve state-of-the-art results, showing that a detailed taxonomy in a hierarchical multi-label setting can yield competitive classification performance. However, all models hit a glass ceiling at approximately 80% F1 score, which we attribute to the non-discrete nature of web registers and the inherent uncertainty in labeling some documents. By pruning ambiguous examples, we improve model performance to over 90%. Finally, multilingual models outperform monolingual ones, particularly benefiting languages with fewer training examples and smaller registers. Although a zero-shot setting decreases performance by an average of 7%, these drops are not linked to specific registers or languages. Instead, registers show surprising similarity across languages.",
    "pdf_link": "https://arxiv.org/abs/2406.19892",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19892v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19892/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19892v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19892/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19892v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19892/heatmap_co_occurrences_full.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19892v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19892/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19892v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19892/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19892v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19892/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19892v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19892/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19892v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19892/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19892v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19892/heatmap_co_occurrences_full_good.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19892v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19892/heatmap_co_occurrences_full_bad.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19892v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19892/bar_chart_white.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19892v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19892/small-good.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19892v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19892/heatmap_all_all_en_mono.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19892v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19892/heatmap_all_all_en_multi.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19892v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19892/heatmap_all_all_en_zero.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19892v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19892/heatmap_all_all_fi_mono.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19892v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19892/heatmap_all_all_fi_multi.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19892v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19892/heatmap_all_all_fi_zero.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19892v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19892/heatmap_all_all_fr_mono.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19892v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19892/heatmap_all_all_fr_multi.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19892v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19892/heatmap_all_all_fr_zero.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19892v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19892/heatmap_all_all_sv_mono.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19892v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19892/heatmap_all_all_sv_multi.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19892v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19892/heatmap_all_all_sv_zero.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19892v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19892/heatmap_all_all_tr_mono.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19892v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19892/heatmap_all_all_tr_multi.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19892v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19892/heatmap_all_all_tr_zero.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19892v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19892/speed.png"
      }
    ],
    "abstract_cn": "本文深入研究了用于自动识别16种语言网络数据集中文本类型的深度学习模型。网络文本类型识别对于理解大规模网络数据集至关重要，这些数据集在计算语言学领域扮演着重要角色。尽管已有进展，但在多语言和无限制网络环境下，文本类型分类器的潜力仍待充分挖掘。我们利用多语言CORE语料库，通过详细的层次化分类法，对16种语言进行了深度学习模型的实验。结果显示，这些模型达到了业界领先水平，证明了层次化多标签设置中详细分类法的有效性。然而，所有模型在约80%的F1分数处遇到了瓶颈，这源于网络文本类型的非离散性和标注的不确定性。通过剔除模糊示例，模型性能提升至90%以上。多语言模型在训练数据较少的语言中表现更佳，零-shot设置虽平均降低7%性能，但性能下降与特定文本类型或语言无关，而是显示出跨语言的文本类型相似性。",
    "title_cn": "探索无界网络：自动辨识多语言语境",
    "tags": [
      "LLM应用",
      "计算语言学",
      "网络数据分析"
    ]
  },
  {
    "title": "YuLan: An Open-source Large Language Model",
    "submit_datetime": "2024年06月28日",
    "abstract": "Large language models (LLMs) have become the foundation of many applications, leveraging their extensive capabilities in processing and understanding natural language. While many open-source LLMs have been released with technical reports, the lack of training details hinders further research and development. This paper presents the development of YuLan, a series of open-source LLMs with $12$ billion parameters. The base model of YuLan is pre-trained on approximately $1.7$T tokens derived from a diverse corpus, including massive English, Chinese, and multilingual texts. We design a three-stage pre-training method to enhance YuLan's overall capabilities. Subsequent phases of training incorporate instruction-tuning and human alignment, employing a substantial volume of high-quality synthesized data. To facilitate the learning of complex and long-tail knowledge, we devise a curriculum-learning framework throughout across these stages, which helps LLMs learn knowledge in an easy-to-hard manner. YuLan's training is finished on Jan, 2024 and has achieved performance on par with state-of-the-art LLMs across various English and Chinese benchmarks. This paper outlines a comprehensive technical roadmap for developing LLMs from scratch. Our model and codes are available at https://github.com/RUC-GSAI/YuLan-Chat.",
    "pdf_link": "https://arxiv.org/abs/2406.19853",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19853v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19853/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19853v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19853/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19853v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19853/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19853v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19853/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19853v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19853/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19853v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19853/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19853v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19853/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19853v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19853/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19853v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19853/x9.png"
      }
    ],
    "abstract_cn": "大型语言模型 (LLM) 已成为众多应用的基石，凭借其强大的自然语言处理和理解能力。尽管已有许多开源 LLM 发布，但训练细节的缺失限制了研究的深入。本文介绍了 YuLan 系列，这是一组拥有 12 亿参数的开源 LLM。YuLan 的基础模型在包含大量英语、中文及多语言文本的多样化语料库上进行了约 1.7 万亿词元的预训练。我们采用三阶段预训练策略，以全面提升 YuLan 的能力。后续训练融合了指令调优与人类对齐，利用了大量优质合成数据。为助力复杂及长尾知识的学习，我们设计了贯穿各阶段的课程学习框架，使 LLM 能循序渐进地掌握知识。YuLan 于 2024 年 1 月完成训练，并在多语种基准测试中展现了顶尖性能。本文详细阐述了 LLM 开发的完整技术路径。模型与代码已公开于 https://github.com/RUC-GSAI/YuLan-Chat。",
    "title_cn": "YuLan：一款开源的大型语言模型",
    "tags": [
      "LLM理论",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Virtual Context: Enhancing Jailbreak Attacks with Special Token Injection",
    "submit_datetime": "2024年06月28日",
    "abstract": "Jailbreak attacks on large language models (LLMs) involve inducing these models to generate harmful content that violates ethics or laws, posing a significant threat to LLM security. Current jailbreak attacks face two main challenges: low success rates due to defensive measures and high resource requirements for crafting specific prompts. This paper introduces Virtual Context, which leverages special tokens, previously overlooked in LLM security, to improve jailbreak attacks. Virtual Context addresses these challenges by significantly increasing the success rates of existing jailbreak methods and requiring minimal background knowledge about the target model, thus enhancing effectiveness in black-box settings without additional overhead. Comprehensive evaluations show that Virtual Context-assisted jailbreak attacks can improve the success rates of four widely used jailbreak methods by approximately 40% across various LLMs. Additionally, applying Virtual Context to original malicious behaviors still achieves a notable jailbreak effect. In summary, our research highlights the potential of special tokens in jailbreak attacks and recommends including this threat in red-teaming testing to comprehensively enhance LLM security.",
    "pdf_link": "https://arxiv.org/abs/2406.19845",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19845v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19845/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19845v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19845/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19845v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19845/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19845v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19845/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19845v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19845/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19845v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19845/x6.png"
      }
    ],
    "abstract_cn": "针对大型语言模型的越狱攻击，旨在诱导模型生成违法或不道德的内容，严重威胁模型安全。目前，这类攻击面临两大难题：防御措施导致成功率低下，以及制作特定攻击指令的高成本。本文提出的“虚拟上下文”技术，利用了以往在模型安全领域被忽视的特殊标记，有效提升了越狱攻击的效率。该技术不仅大幅提高了现有攻击手段的成功率，而且对目标模型的背景知识要求极低，使得在黑盒环境下也能高效运作，无需额外投入。实验表明，“虚拟上下文”能将四种主流越狱方法的成功率提升约40%，且在保持原有恶意行为的基础上，仍能产生显著的越狱效果。我们的研究强调了特殊标记在越狱攻击中的重要性，并建议将其纳入安全测试，以全面提升大型语言模型的安全性。",
    "title_cn": "虚拟上下文：利用特殊标记注入提升越狱攻击效果",
    "tags": [
      "LLM应用",
      "网络安全",
      "人工智能安全"
    ]
  },
  {
    "title": "AnomaLLMy -- Detecting anomalous tokens in black-box LLMs through low-confidence single-token predictions",
    "submit_datetime": "2024年06月28日",
    "abstract": "This paper introduces AnomaLLMy, a novel technique for the automatic detection of anomalous tokens in black-box Large Language Models (LLMs) with API-only access. Utilizing low-confidence single-token predictions as a cost-effective indicator, AnomaLLMy identifies irregularities in model behavior, addressing the issue of anomalous tokens degrading the quality and reliability of models. Validated on the cl100k_base dataset, the token set of GPT-4, AnomaLLMy detected 413 major and 65 minor anomalies, demonstrating the method's efficiency with just \\$24.39 spent in API credits. The insights from this research are expected to be beneficial for enhancing the robustness of and accuracy of LLMs, particularly in the development and assessment of tokenizers.",
    "pdf_link": "https://arxiv.org/abs/2406.19840",
    "graphs": [],
    "abstract_cn": "本文引入了 AnomaLLMy 技术，该技术能自动检测仅通过 API 访问的 LLM 中的异常标记。通过低置信度的单标记预测，AnomaLLMy 有效识别模型行为中的异常，从而提升模型质量和可靠性。在 GPT-4 的 cl100k_base 数据集上，该技术成功检测出 413 个主要和 65 个次要异常，且成本仅为 24.39 美元。这些发现有望进一步增强 LLM 的鲁棒性和准确性，尤其是在标记器的开发与评估领域。",
    "title_cn": "AnomaLLMy —— 通过低置信单令牌预测，在黑盒 LLM 中识别异常令牌",
    "tags": [
      "LLM应用",
      "人工智能",
      "软件开发"
    ]
  },
  {
    "title": "Towards Stable and Storage-efficient Dataset Distillation: Matching Convexified Trajectory",
    "submit_datetime": "2024年06月28日",
    "abstract": "The rapid evolution of deep learning and large language models has led to an exponential growth in the demand for training data, prompting the development of Dataset Distillation methods to address the challenges of managing large datasets. Among these, Matching Training Trajectories (MTT) has been a prominent approach, which replicates the training trajectory of an expert network on real data with a synthetic dataset. However, our investigation found that this method suffers from three significant limitations: 1. Instability of expert trajectory generated by Stochastic Gradient Descent (SGD); 2. Low convergence speed of the distillation process; 3. High storage consumption of the expert trajectory. To address these issues, we offer a new perspective on understanding the essence of Dataset Distillation and MTT through a simple transformation of the objective function, and introduce a novel method called Matching Convexified Trajectory (MCT), which aims to provide better guidance for the student trajectory. MCT leverages insights from the linearized dynamics of Neural Tangent Kernel methods to create a convex combination of expert trajectories, guiding the student network to converge rapidly and stably. This trajectory is not only easier to store, but also enables a continuous sampling strategy during distillation, ensuring thorough learning and fitting of the entire expert trajectory. Comprehensive experiments across three public datasets validate the superiority of MCT over traditional MTT methods.",
    "pdf_link": "https://arxiv.org/abs/2406.19827",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19827v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19827/3d-traj.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19827v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19827/convergence_compare.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19827v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19827/main_figure.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19827v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19827/CIFAR10_compare.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19827v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19827/CIFAR100_compare.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19827v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19827/storage_compare.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19827v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19827/expert_num_1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19827v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19827/expert_num_10.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19827v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19827/expert_num_50.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19827v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19827/cf10-ipc10-visual.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19827v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19827/cf100-ip1-visual.png"
      }
    ],
    "abstract_cn": "随着深度学习和大型语言模型的迅猛发展，对训练数据的需求激增，推动了数据集蒸馏技术的发展。其中，匹配训练轨迹（MTT）方法通过合成数据集模拟专家网络的训练过程，但存在三大问题：专家轨迹的不稳定、蒸馏速度慢和高存储成本。为此，我们提出新视角，通过目标函数变换深入理解数据集蒸馏和MTT，并创新引入匹配凸化轨迹（MCT）方法。MCT利用神经正切核的线性动态特性，构建专家轨迹的凸组合，引导学生网络快速稳定收敛，且更易存储，支持连续采样，确保全面学习专家轨迹。实验证明，MCT在多个公共数据集上优于传统MTT方法。",
    "title_cn": "探索稳定且存储高效的数据集蒸馏方法：通过匹配凸化轨迹实现优化",
    "tags": [
      "LLM理论",
      "人工智能",
      "数据科学"
    ]
  },
  {
    "title": "BeamAggR: Beam Aggregation Reasoning over Multi-source Knowledge for Multi-hop Question Answering",
    "submit_datetime": "2024年06月28日",
    "abstract": "Large language models (LLMs) have demonstrated strong reasoning capabilities. Nevertheless, they still suffer from factual errors when tackling knowledge-intensive tasks. Retrieval-augmented reasoning represents a promising approach. However, significant challenges still persist, including inaccurate and insufficient retrieval for complex questions, as well as difficulty in integrating multi-source knowledge. To address this, we propose Beam Aggregation Reasoning, BeamAggR, a reasoning framework for knowledge-intensive multi-hop QA. BeamAggR explores and prioritizes promising answers at each hop of question. Concretely, we parse the complex questions into trees, which include atom and composite questions, followed by bottom-up reasoning. For atomic questions, the LLM conducts reasoning on multi-source knowledge to get answer candidates. For composite questions, the LLM combines beam candidates, explores multiple reasoning paths through probabilistic aggregation, and prioritizes the most promising trajectory. Extensive experiments on four open-domain multi-hop reasoning datasets show that our method significantly outperforms SOTA methods by 8.5%. Furthermore, our analysis reveals that BeamAggR elicits better knowledge collaboration and answer aggregation.",
    "pdf_link": "https://arxiv.org/abs/2406.19820",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19820v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19820/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19820v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19820/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19820v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19820/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19820v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19820/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19820v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19820/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19820v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19820/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19820v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19820/x7.png"
      }
    ],
    "abstract_cn": "尽管大型语言模型 (LLM) 在推理方面表现出色，但在处理知识密集型任务时仍会出现事实错误。为此，我们提出了 Beam Aggregation Reasoning (BeamAggR)，这是一种针对知识密集型多跳问答的推理框架。BeamAggR 通过将复杂问题分解为树状结构，并采用自底向上的推理方法，有效探索并优先考虑每个问题环节中的潜在答案。实验结果显示，我们的方法在四个开放域多跳推理数据集上显著超越了现有技术水平，提升了 8.5%。分析进一步表明，BeamAggR 能更有效地促进知识间的协作与答案的聚合。",
    "title_cn": "BeamAggR：多源知识驱动下的多跳问答光束聚合推理",
    "tags": [
      "LLM应用",
      "问答系统",
      "人工智能"
    ]
  },
  {
    "title": "Scalable and Domain-General Abstractive Proposition Segmentation",
    "submit_datetime": "2024年06月28日",
    "abstract": "Segmenting text into fine-grained units of meaning is important to a wide range of NLP applications. The default approach of segmenting text into sentences is often insufficient, especially since sentences are usually complex enough to include multiple units of meaning that merit separate treatment in the downstream task. We focus on the task of abstractive proposition segmentation: transforming text into simple, self-contained, well-formed sentences. Several recent works have demonstrated the utility of proposition segmentation with few-shot prompted LLMs for downstream tasks such as retrieval-augmented grounding and fact verification. However, this approach does not scale to large amounts of text and may not always extract all the facts from the input text. In this paper, we first introduce evaluation metrics for the task to measure several dimensions of quality. We then propose a scalable, yet accurate, proposition segmentation model. We model proposition segmentation as a supervised task by training LLMs on existing annotated datasets and show that training yields significantly improved results. We further show that by using the fine-tuned LLMs as teachers for annotating large amounts of multi-domain synthetic distillation data, we can train smaller student models with results similar to the teacher LLMs. We then demonstrate that our technique leads to effective domain generalization, by annotating data in two domains outside the original training data and evaluating on them. Finally, as a key contribution of the paper, we share an easy-to-use API for NLP practitioners to use.",
    "pdf_link": "https://arxiv.org/abs/2406.19803",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19803v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19803/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19803v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19803/x2.png"
      }
    ],
    "abstract_cn": "细粒度文本分割对NLP应用至关重要，但传统的句子分割常显不足。我们专注于抽象命题分割，旨在将文本转化为简洁、自包含的句子。尽管近期研究显示命题分割在下游任务中的潜力，但其扩展性和完整性仍有限。本文中，我们首先定义了评估指标，随后提出了一种高效且可扩展的命题分割模型。通过监督学习，我们在注释数据集上训练LLM，显著提升性能。此外，我们利用微调LLM生成大量合成数据，训练小型模型，实现相似效果。实验证明，该技术在未见领域同样有效。最后，我们提供了一个便捷的API，助力NLP实践。",
    "title_cn": "可扩展且跨领域的抽象命题分割技术",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "NLPerturbator: Studying the Robustness of Code LLMs to Natural Language Variations",
    "submit_datetime": "2024年06月28日",
    "abstract": "Large language models (LLMs) achieve promising results in code generation based on a given natural language description. They have been integrated into open-source projects and commercial products to facilitate daily coding activities. The natural language description in the prompt is crucial for LLMs to comprehend users' requirements. Prior studies uncover that LLMs are sensitive to the changes in the prompts, including slight changes that look inconspicuous. However, the natural language descriptions often vary in real-world scenarios (e.g., different formats, grammar, and wording). Prior studies on the robustness of LLMs are often based on random perturbations and such perturbations may not actually happen. In this paper, we conduct a comprehensive study to investigate how are code LLMs robust to variations of natural language description in real-world scenarios. We summarize 18 categories of perturbations of natural language and 3 combinations of co-occurred categories based on our literature review and an online survey with practitioners. We propose an automated framework, NLPerturbator, which can perform perturbations of each category given a set of prompts. Through a series of experiments on code generation using six code LLMs, we find that the perturbed prompts can decrease the performance of code generation by a considerable margin (e.g., up to 21.2%, and 4.8% to 6.1% on average). Our study highlights the importance of enhancing the robustness of LLMs to real-world variations in the prompts, as well as the essentiality of attentively constructing the prompts.",
    "pdf_link": "https://arxiv.org/abs/2406.19783",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19783v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19783/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19783v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19783/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19783v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19783/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19783v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19783/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19783v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19783/x5.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLM）在根据自然语言描述生成代码方面表现出色，已广泛应用于开源和商业产品中，助力日常编程。然而，提示中的自然语言描述对模型理解用户意图至关重要，且模型对提示的微小变化极为敏感。现实中，这些描述常因格式、语法或用词不同而异。以往研究多基于随机扰动，但这些扰动在现实中未必发生。本文深入探讨了代码LLM在实际应用中对自然语言描述变化的鲁棒性，总结了18种扰动类型及3种组合，并提出了自动化框架NLPerturbator。实验表明，扰动提示可显著影响代码生成性能，凸显了提升LLM鲁棒性和精心设计提示的重要性。",
    "title_cn": "NLPerturbator：探究代码 LLM 在自然语言变异中的稳健性",
    "tags": [
      "LLM应用",
      "软件开发",
      "人工智能"
    ]
  },
  {
    "title": "Direct Preference Knowledge Distillation for Large Language Models",
    "submit_datetime": "2024年06月28日",
    "abstract": "In the field of large language models (LLMs), Knowledge Distillation (KD) is a critical technique for transferring capabilities from teacher models to student models. However, existing KD methods face limitations and challenges in distillation of LLMs, including efficiency and insufficient measurement capabilities of traditional KL divergence. It is shown that LLMs can serve as an implicit reward function, which we define as a supplement to KL divergence. In this work, we propose Direct Preference Knowledge Distillation (DPKD) for LLMs. DPKD utilizes distribution divergence to represent the preference loss and implicit reward function. We re-formulate KD of LLMs into two stages: first optimizing and objective consisting of implicit reward and reverse KL divergence and then improving the preference probability of teacher outputs over student outputs. We conducted experiments and analysis on various datasets with LLM parameters ranging from 120M to 13B and demonstrate the broad applicability and effectiveness of our DPKD approach. Meanwhile, we prove the value and effectiveness of the introduced implicit reward and output preference in KD through experiments and theoretical analysis. The DPKD method outperforms the baseline method in both output response precision and exact match percentage. Code and data are available at https://aka.ms/dpkd.",
    "pdf_link": "https://arxiv.org/abs/2406.19774",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19774v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19774/GPT4-compare.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19774v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19774/fff-test-rKLD-reward4-nc.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19774v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19774/f-new-reward_epoch3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19774v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19774/fff111-test-epoch-KLD1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19774v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19774/fff111-test-epoch-rKLD1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19774v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19774/fff-pic2.png"
      }
    ],
    "abstract_cn": "在大型语言模型领域，知识蒸馏技术至关重要，但现有方法在效率和测量能力上存在局限。我们提出直接偏好知识蒸馏 (DPKD)，通过分布散度优化隐式奖励和输出偏好，显著提升模型性能。实验证明，DPKD 在多个数据集上表现优异，代码和数据已公开。",
    "title_cn": "大型语言模型的直接偏好知识蒸馏",
    "tags": [
      "LLM理论",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Belief Revision: The Adaptability of Large Language Models Reasoning",
    "submit_datetime": "2024年06月28日",
    "abstract": "The capability to reason from text is crucial for real-world NLP applications. Real-world scenarios often involve incomplete or evolving data. In response, individuals update their beliefs and understandings accordingly. However, most existing evaluations assume that language models (LMs) operate with consistent information. We introduce Belief-R, a new dataset designed to test LMs' belief revision ability when presented with new evidence. Inspired by how humans suppress prior inferences, this task assesses LMs within the newly proposed delta reasoning ($ΔR$) framework. Belief-R features sequences of premises designed to simulate scenarios where additional information could necessitate prior conclusions drawn by LMs. We evaluate $\\sim$30 LMs across diverse prompting strategies and found that LMs generally struggle to appropriately revise their beliefs in response to new information. Further, models adept at updating often underperformed in scenarios without necessary updates, highlighting a critical trade-off. These insights underscore the importance of improving LMs' adaptiveness to changing information, a step toward more reliable AI systems.",
    "pdf_link": "https://arxiv.org/abs/2406.19764",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19764v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19764/belief_revision_main.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19764v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19764/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19764v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19764/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19764v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19764/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19764v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19764/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19764v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19764/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19764v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19764/prompt_samples.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19764v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19764/MA_GT_annotation_guideline.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19764v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19764/MA_GT_annotation_example.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19764v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19764/Eval_annotation_guideline.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19764v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19764/Eval_annotation_example.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19764v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19764/x6.png"
      }
    ],
    "abstract_cn": "在现实NLP应用中，从文本中推理的能力至关重要。面对不完整或变化的数据，人们会更新自己的信念和理解。然而，现有评估多假设语言模型（LMs）在一致信息下运作。为此，我们推出了Belief-R数据集，测试LMs在新证据下的信念修正能力。该任务在delta推理（$ΔR$）框架内进行，模拟了LMs需重新考虑先前结论的场景。我们评估了约30个LMs，发现它们普遍难以根据新信息适当修正信念。同时，擅长更新的模型在不需更新的场景中表现不佳，凸显了适应性与准确性之间的权衡。这强调了提升LMs对变化信息的适应性的重要性，是构建更可靠AI系统的重要一步。",
    "title_cn": "信念修正是大型语言模型推理适应性的关键，它使模型能够灵活调整其推理过程以适应新的信息或环境变化。",
    "tags": [
      "LLM应用",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Learning Interpretable Legal Case Retrieval via Knowledge-Guided Case Reformulation",
    "submit_datetime": "2024年06月28日",
    "abstract": "Legal case retrieval for sourcing similar cases is critical in upholding judicial fairness. Different from general web search, legal case retrieval involves processing lengthy, complex, and highly specialized legal documents. Existing methods in this domain often overlook the incorporation of legal expert knowledge, which is crucial for accurately understanding and modeling legal cases, leading to unsatisfactory retrieval performance. This paper introduces KELLER, a legal knowledge-guided case reformulation approach based on large language models (LLMs) for effective and interpretable legal case retrieval. By incorporating professional legal knowledge about crimes and law articles, we enable large language models to accurately reformulate the original legal case into concise sub-facts of crimes, which contain the essential information of the case. Extensive experiments on two legal case retrieval benchmarks demonstrate superior retrieval performance and robustness on complex legal case queries of KELLER over existing methods.",
    "pdf_link": "https://arxiv.org/abs/2406.19760",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19760v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19760/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19760v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19760/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19760v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19760/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19760v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19760/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19760v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19760/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19760v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19760/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19760v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19760/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19760v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19760/x8.png"
      }
    ],
    "abstract_cn": "在维护司法公正中，法律案例检索至关重要。不同于普通网页搜索，法律案例检索需处理冗长、复杂的专业文件。现有方法常忽略法律专家知识的重要性，影响检索效果。本文提出KELLER，一种基于LLM的法律知识引导案例重构方法，通过整合专业法律知识，将案例精炼为关键子事实，显著提升检索性能和鲁棒性。实验证明，KELLER在复杂查询中表现卓越。",
    "title_cn": "利用知识引导的案例重构，实现法律案例检索的可解释性学习",
    "tags": [
      "LLM应用",
      "",
      ""
    ]
  },
  {
    "title": "Uncertainty Quantification in Large Language Models Through Convex Hull Analysis",
    "submit_datetime": "2024年06月28日",
    "abstract": "Uncertainty quantification approaches have been more critical in large language models (LLMs), particularly high-risk applications requiring reliable outputs. However, traditional methods for uncertainty quantification, such as probabilistic models and ensemble techniques, face challenges when applied to the complex and high-dimensional nature of LLM-generated outputs. This study proposes a novel geometric approach to uncertainty quantification using convex hull analysis. The proposed method leverages the spatial properties of response embeddings to measure the dispersion and variability of model outputs. The prompts are categorized into three types, i.e., `easy', `moderate', and `confusing', to generate multiple responses using different LLMs at varying temperature settings. The responses are transformed into high-dimensional embeddings via a BERT model and subsequently projected into a two-dimensional space using Principal Component Analysis (PCA). The Density-Based Spatial Clustering of Applications with Noise (DBSCAN) algorithm is utilized to cluster the embeddings and compute the convex hull for each selected cluster. The experimental results indicate that the uncertainty of the model for LLMs depends on the prompt complexity, the model, and the temperature setting.",
    "pdf_link": "https://arxiv.org/abs/2406.19712",
    "graphs": [],
    "abstract_cn": "在大语言模型 (LLM) 中，特别是在高风险应用中，不确定性量化方法变得尤为关键。然而，传统的概率模型和集成技术在处理 LLM 生成输出的复杂性和高维度时面临挑战。本研究提出了一种新颖的几何方法，通过凸包分析来量化不确定性。该方法利用响应嵌入的空间属性，测量模型输出的分散度和变异性。提示分为“简单”、“中等”和“混淆”三类，以不同温度设置下的 LLM 生成多个响应。这些响应通过 BERT 模型转换为高维嵌入，并使用 PCA 投影到二维空间。DBSCAN 算法用于聚类嵌入并计算每个聚类的凸包。实验结果显示，LLM 模型的不确定性受提示复杂性、模型和温度设置的影响。",
    "title_cn": "利用凸包分析在大语言模型中量化不确定性",
    "tags": [
      "LLM理论",
      "人工智能",
      "数据分析"
    ]
  },
  {
    "title": "InfiniGen: Efficient Generative Inference of Large Language Models with Dynamic KV Cache Management",
    "submit_datetime": "2024年06月28日",
    "abstract": "Transformer-based large language models (LLMs) demonstrate impressive performance across various natural language processing tasks. Serving LLM inference for generating long contents, however, poses a challenge due to the enormous memory footprint of the transient state, known as the key-value (KV) cache, which scales with the sequence length and batch size. In this paper, we present InfiniGen, a novel KV cache management framework tailored for long-text generation, which synergistically works with modern offloading-based inference systems. InfiniGen leverages the key insight that a few important tokens that are essential for computing the subsequent attention layer in the Transformer can be speculated by performing a minimal rehearsal with the inputs of the current layer and part of the query weight and key cache of the subsequent layer. This allows us to prefetch only the essential KV cache entries (without fetching them all), thereby mitigating the fetch overhead from the host memory in offloading-based LLM serving systems. Our evaluation on several representative LLMs shows that InfiniGen improves the overall performance of a modern offloading-based system by up to 3.00x compared to prior KV cache management methods while offering substantially better model accuracy.",
    "pdf_link": "https://arxiv.org/abs/2406.19707",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19707v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19707/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19707v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19707/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19707v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19707/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19707v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19707/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19707v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19707/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19707v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19707/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19707v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19707/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19707v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19707/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19707v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19707/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19707v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19707/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19707v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19707/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19707v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19707/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19707v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19707/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19707v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19707/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19707v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19707/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19707v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19707/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19707v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19707/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19707v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19707/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19707v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19707/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19707v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19707/x20.png"
      }
    ],
    "abstract_cn": "基于Transformer的LLMs在多种NLP任务中表现卓越。然而，生成长内容时的LLM推理因KV缓存的大内存需求而受限。本文介绍的InfiniGen框架，专为长文本生成设计，与现代卸载系统协同，通过最小演练预测关键令牌，仅预取必要缓存，大幅提升系统性能至3倍，同时保持高模型准确性。",
    "title_cn": "InfiniGen：利用动态KV缓存管理技术，提升大型语言模型生成推理的效率",
    "tags": [
      "LLM应用",
      "文本生成",
      ""
    ]
  },
  {
    "title": "Beyond Human Preferences: Exploring Reinforcement Learning Trajectory Evaluation and Improvement through LLMs",
    "submit_datetime": "2024年06月28日",
    "abstract": "Reinforcement learning (RL) faces challenges in evaluating policy trajectories within intricate game tasks due to the difficulty in designing comprehensive and precise reward functions. This inherent difficulty curtails the broader application of RL within game environments characterized by diverse constraints. Preference-based reinforcement learning (PbRL) presents a pioneering framework that capitalizes on human preferences as pivotal reward signals, thereby circumventing the need for meticulous reward engineering. However, obtaining preference data from human experts is costly and inefficient, especially under conditions marked by complex constraints. To tackle this challenge, we propose a LLM-enabled automatic preference generation framework named LLM4PG , which harnesses the capabilities of large language models (LLMs) to abstract trajectories, rank preferences, and reconstruct reward functions to optimize conditioned policies. Experiments on tasks with complex language constraints demonstrated the effectiveness of our LLM-enabled reward functions, accelerating RL convergence and overcoming stagnation caused by slow or absent progress under original reward structures. This approach mitigates the reliance on specialized human knowledge and demonstrates the potential of LLMs to enhance RL's effectiveness in complex environments in the wild.",
    "pdf_link": "https://arxiv.org/abs/2406.19644",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19644v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19644/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19644v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19644/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19644v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19644/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19644v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19644/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19644v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19644/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19644v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19644/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19644v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19644/x7.png"
      }
    ],
    "abstract_cn": "强化学习在复杂游戏任务中评估策略轨迹时，因难以设计精确的奖励函数而受限。基于偏好的强化学习通过利用人类偏好作为奖励信号，避免了精细的奖励设计。但获取专家偏好数据成本高昂且效率低下。为此，我们提出了 LLM4PG 框架，利用大型语言模型自动生成偏好，优化奖励函数，加速学习进程。实验表明，该方法有效提升了强化学习在复杂任务中的表现，减少了对专业知识的依赖，展现了 LLMs 在复杂环境中增强 RL 效能的潜力。",
    "title_cn": "探索超越人类偏好的领域，利用 LLMs 对强化学习轨迹进行评估与提升。",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Web2Code: A Large-scale Webpage-to-Code Dataset and Evaluation Framework for Multimodal LLMs",
    "submit_datetime": "2024年06月28日",
    "abstract": "\nAbstract:Multimodal large language models (MLLMs) have shown impressive success across modalities such as image, video, and audio in a variety of understanding and generation tasks. However, current MLLMs are surprisingly poor at understanding webpage screenshots and generating their corresponding HTML code. To address this problem, we propose Web2Code, a benchmark consisting of a new large-scale webpage-to-code dataset for instruction tuning and an evaluation framework for the webpage understanding and HTML code translation abilities of MLLMs. For dataset construction, we leverage pretrained LLMs to enhance existing webpage-to-code datasets as well as generate a diverse pool of new webpages rendered into images. Specifically, the inputs are webpage images and instructions, while the responses are the webpage's HTML code. We further include diverse natural language QA pairs about the webpage content in the responses to enable a more comprehensive understanding of the web content. To evaluate model performance in these tasks, we develop an evaluation framework for testing MLLMs' abilities in webpage understanding and web-to-code generation. Extensive experiments show that our proposed dataset is beneficial not only to our proposed tasks but also in the general visual domain, while previous datasets result in worse performance. We hope our work will contribute to the development of general MLLMs suitable for web-based content generation and task automation. Our data and code will be available at this https URL.\n    ",
    "pdf_link": "https://arxiv.org//pdf/2406.20098",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.20098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20098/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20098/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20098/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20098/cloud.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20098/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20098/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20098/ori.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20098/vicuna.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20098/crystalchat.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20098/ori.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20098/ori_code_img.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20098/ours.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20098/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20098/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20098/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20098/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20098/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20098/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20098/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20098/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20098/junbo.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20098/pix2code.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20098/WebSight.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20098/QA.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20098/WebSRC.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20098/Modern_webpages.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20098/Bootstrap_webpage.png"
      }
    ],
    "abstract_cn": "摘要：多模态大型语言模型（MLLMs）在跨图像、视频和音频等多种任务中表现卓越。然而，它们在理解网页截图和生成HTML代码方面却表现不佳。为此，我们提出Web2Code，包含一个大规模网页到代码数据集和评估框架，旨在提升MLLMs在这两方面的能力。我们利用预训练LLMs增强现有数据集并生成多样网页图像，输入为网页图像和指令，输出为HTML代码，并加入网页内容的自然语言QA对以深化理解。我们还开发了评估框架来测试MLLMs在这两方面的能力。实验证明，我们的数据集不仅提升了我们提出的任务性能，也在一般视觉领域表现更佳。我们期待这项工作能推动适用于网页内容生成和自动化的通用MLLMs的发展。相关数据和代码将在指定链接提供。",
    "title_cn": "Web2Code：一款大规模的网页转代码数据集与评估框架，专为多模态大型语言模型设计。",
    "tags": [
      "LLM应用",
      "网页开发",
      "自动化"
    ]
  },
  {
    "title": "BMW Agents -- A Framework For Task Automation Through Multi-agent Collaboration",
    "submit_datetime": "2024年06月28日",
    "abstract": "\nAbstract:Autonomous agents driven by Large Language Models (LLMs) offer enormous potential for automation. Early proof of this technology can be found in various demonstrations of agents solving complex tasks, interacting with external systems to augment their knowledge, and triggering actions. In particular, workflows involving multiple agents solving complex tasks in a collaborative fashion exemplify their capacity to operate in less strict and less well-defined environments. Thus, a multi-agent approach has great potential for serving as a backbone in many industrial applications, ranging from complex knowledge retrieval systems to next generation robotic process automation. Given the reasoning abilities within the current generation of LLMs, complex processes require a multi-step approach that includes a plan of well-defined and modular tasks. Depending on the level of complexity, these tasks can be executed either by a single agent or a group of agents. In this work, we focus on designing a flexible agent engineering framework with careful attention to planning and execution, capable of handling complex use case applications across various domains. The proposed framework provides reliability in industrial applications and presents techniques to ensure a scalable, flexible, and collaborative workflow for multiple autonomous agents working together towards solving tasks.\n    ",
    "pdf_link": "https://arxiv.org//pdf/2406.20041",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.20041v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20041/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20041v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20041/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20041v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20041/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20041v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20041/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20041v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20041/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20041v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20041/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20041v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20041/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20041v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20041/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20041v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20041/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20041v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20041/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20041v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20041/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20041v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20041/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20041v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20041/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20041v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20041/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20041v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20041/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20041v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20041/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20041v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20041/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20041v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20041/x19.png"
      }
    ],
    "abstract_cn": "摘要：大型语言模型（LLM）驱动的自主代理展现了自动化领域的巨大潜力。早期技术展示包括代理解决复杂任务、与外部系统互动以丰富知识及触发行动。特别是，多代理协作解决复杂任务的工作流程，突显了它们在非严格定义环境中的运作能力。因此，多代理方法在从复杂知识检索到下一代机器人流程自动化的众多工业应用中，具有成为核心架构的潜力。鉴于LLM的推理能力，复杂过程需采用包含模块化任务计划的逐步方法。任务执行可由单一代理或代理群组完成，视复杂度而定。本研究聚焦于设计一个灵活的代理工程框架，注重规划与执行，以应对跨领域的复杂应用。该框架旨在确保工业应用的可靠性，并提供技术支持，实现多自主代理间的可扩展、灵活及协作的工作流程。",
    "title_cn": "BMW Agents 框架：通过多代理协作推动任务自动化",
    "tags": [
      "Agent",
      "自动化",
      "机器人流程自动化"
    ]
  },
  {
    "title": "Scaling Synthetic Data Creation with 1,000,000,000 Personas",
    "submit_datetime": "2024年06月28日",
    "abstract": "\nAbstract:We propose a novel persona-driven data synthesis methodology that leverages various perspectives within a large language model (LLM) to create diverse synthetic data. To fully exploit this methodology at scale, we introduce Persona Hub -- a collection of 1 billion diverse personas automatically curated from web data. These 1 billion personas (~13% of the world's total population), acting as distributed carriers of world knowledge, can tap into almost every perspective encapsulated within the LLM, thereby facilitating the creation of diverse synthetic data at scale for various scenarios. By showcasing Persona Hub's use cases in synthesizing high-quality mathematical and logical reasoning problems, instructions (i.e., user prompts), knowledge-rich texts, game NPCs and tools (functions) at scale, we demonstrate persona-driven data synthesis is versatile, scalable, flexible, and easy to use, potentially driving a paradigm shift in synthetic data creation and applications in practice, which may have a profound impact on LLM research and development.\n    ",
    "pdf_link": "https://arxiv.org//pdf/2406.20094",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.20094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20094/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20094/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20094/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20094/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20094/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20094/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20094/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20094/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20094/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20094/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20094/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20094/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20094/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20094/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20094/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20094/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20094/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2406.20094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.20094/x18.png"
      }
    ],
    "abstract_cn": "我们创新性地提出了一种基于人格驱动的数据合成方法，该方法通过大型语言模型（LLM）中的多重视角，生成多样化的合成数据。为了实现这一方法的大规模应用，我们创建了Persona Hub，这是一个包含10亿多样化人格的集合，这些人格从网络数据中自动筛选而来，相当于世界人口的13%。这些人格作为知识的分布式载体，能够触及LLM中的几乎所有视角，从而助力大规模多样化合成数据的生成，广泛适用于各种场景。通过实例展示Persona Hub在生成高质量数学和逻辑问题、用户指令、知识密集型文本、游戏角色和工具等方面的大规模应用，我们证实了基于人格的数据合成方法的多功能性、可扩展性、灵活性和易用性，有望引领合成数据领域的范式变革，对LLM的研究与开发产生深远影响。",
    "title_cn": "利用十亿个人设扩展合成数据生成",
    "tags": [
      "LLM应用",
      "人工智能",
      "数据科学"
    ]
  },
  {
    "title": "PathGen-1.6M: 1.6 Million Pathology Image-text Pairs Generation through Multi-agent Collaboration",
    "submit_datetime": "2024年06月28日",
    "abstract": "Vision Language Models (VLMs) like CLIP have attracted substantial attention in pathology, serving as backbones for applications such as zero-shot image classification and Whole Slide Image (WSI) analysis. Additionally, they can function as vision encoders when combined with large language models (LLMs) to support broader capabilities. Current efforts to train pathology VLMs rely on pathology image-text pairs from platforms like PubMed, YouTube, and Twitter, which provide limited, unscalable data with generally suboptimal image quality. In this work, we leverage large-scale WSI datasets like TCGA to extract numerous high-quality image patches. We then train a large multimodal model to generate captions for these images, creating PathGen-1.6M, a dataset containing 1.6 million high-quality image-caption pairs. Our approach involves multiple agent models collaborating to extract representative WSI patches, generating and refining captions to obtain high-quality image-text pairs. Extensive experiments show that integrating these generated pairs with existing datasets to train a pathology-specific CLIP model, PathGen-CLIP, significantly enhances its ability to analyze pathological images, with substantial improvements across nine pathology-related zero-shot image classification tasks and three whole-slide image tasks. Furthermore, we construct 200K instruction-tuning data based on PathGen-1.6M and integrate PathGen-CLIP with the Vicuna LLM to create more powerful multimodal models through instruction tuning. Overall, we provide a scalable pathway for high-quality data generation in pathology, paving the way for next-generation general pathology models.",
    "pdf_link": "https://arxiv.org/abs/2407.00203",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.00203v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00203/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00203v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00203/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00203v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00203/x3.png"
      }
    ],
    "abstract_cn": "CLIP等视觉语言模型在病理学领域备受瞩目，不仅支撑着零-shot图像分类和全切片图像分析等应用，还能与大型语言模型结合，拓展更多功能。然而，现有病理学VLMs的训练数据多来自PubMed、YouTube和Twitter，数据量有限且质量参差不齐。我们通过利用TCGA等大规模WSI数据集，提取高质量图像块，并训练多模态模型生成标题，构建了PathGen-1.6M数据集，包含160万对高质量图像-标题。通过多代理模型协作，我们进一步提升了图像-文本对的质量。实验证明，结合这些高质量数据训练的PathGen-CLIP模型，在多项病理学图像分析任务中表现卓越。此外，我们还构建了20万条指令调优数据，将PathGen-CLIP与Vicuna LLM结合，通过指令调优提升多模态模型的性能。这一研究不仅为病理学领域提供了高质量数据生成的可扩展途径，也为未来通用病理学模型的发展奠定了基础。",
    "title_cn": "PathGen-1.6M：借助多代理协作，成功生成160万对病理图像与文本。",
    "tags": [
      "LLM应用",
      "",
      "病理学"
    ]
  },
  {
    "title": "ShortcutsBench: A Large-Scale Real-world Benchmark for API-based Agents",
    "submit_datetime": "2024年06月28日",
    "abstract": "Recent advancements in integrating large language models (LLMs) with application programming interfaces (APIs) have gained significant interest in both academia and industry. These API-based agents, leveraging the strong autonomy and planning capabilities of LLMs, can efficiently solve problems requiring multi-step actions. However, their ability to handle multi-dimensional difficulty levels, diverse task types, and real-world demands through APIs remains unknown. In this paper, we introduce \\textsc{ShortcutsBench}, a large-scale benchmark for the comprehensive evaluation of API-based agents in solving tasks with varying levels of difficulty, diverse task types, and real-world demands. \\textsc{ShortcutsBench} includes a wealth of real APIs from Apple Inc.'s operating systems, refined user queries from shortcuts, human-annotated high-quality action sequences from shortcut developers, and accurate parameter filling values about primitive parameter types, enum parameter types, outputs from previous actions, and parameters that need to request necessary information from the system or user. Our extensive evaluation of agents built with $5$ leading open-source (size >= 57B) and $4$ closed-source LLMs (e.g. Gemini-1.5-Pro and GPT-3.5) reveals significant limitations in handling complex queries related to API selection, parameter filling, and requesting necessary information from systems and users. These findings highlight the challenges that API-based agents face in effectively fulfilling real and complex user queries. All datasets, code, and experimental results will be available at \\url{https://github.com/eachsheep/shortcutsbench}.",
    "pdf_link": "https://arxiv.org/abs/2407.00132",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.00132v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00132/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00132v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00132/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00132v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00132/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00132v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00132/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00132v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00132/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00132v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00132/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00132v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00132/x7.png"
      }
    ],
    "abstract_cn": "近年来，大型语言模型（LLMs）与应用程序编程接口（APIs）的结合在学术界和工业界备受瞩目。这些基于API的智能代理，凭借LLMs的强大自主规划能力，能高效应对多步骤任务。然而，它们在处理复杂多变的任务和现实需求方面的能力尚待探索。为此，我们推出了\\textsc{ShortcutsBench}，一个全面评估API代理的大规模基准，涵盖不同难度、多样任务及现实需求。该基准集成了苹果系统的真实API、精炼用户查询、高质量动作序列及精确参数填充，旨在揭示代理在复杂查询处理上的局限。通过评估5个开源及4个闭源LLMs构建的代理，我们发现其在API选择、参数填充及信息请求方面存在明显不足，凸显了其在应对真实复杂查询时的挑战。相关数据集、代码及结果将在\\url{https://github.com/eachsheep/shortcutsbench}公开。",
    "title_cn": "ShortcutsBench：一款大型真实世界基准，专为基于 API 的代理设计。",
    "tags": [
      "Agent",
      "软件开发",
      "人工智能"
    ]
  },
  {
    "title": "Multimodal Learning and Cognitive Processes in Radiology: MedGaze for Chest X-ray Scanpath Prediction",
    "submit_datetime": "2024年06月28日",
    "abstract": "Predicting human gaze behavior within computer vision is integral for developing interactive systems that can anticipate user attention, address fundamental questions in cognitive science, and hold implications for fields like human-computer interaction (HCI) and augmented/virtual reality (AR/VR) systems. Despite methodologies introduced for modeling human eye gaze behavior, applying these models to medical imaging for scanpath prediction remains unexplored. Our proposed system aims to predict eye gaze sequences from radiology reports and CXR images, potentially streamlining data collection and enhancing AI systems using larger datasets. However, predicting human scanpaths on medical images presents unique challenges due to the diverse nature of abnormal regions. Our model predicts fixation coordinates and durations critical for medical scanpath prediction, outperforming existing models in the computer vision community. Utilizing a two-stage training process and large publicly available datasets, our approach generates static heatmaps and eye gaze videos aligned with radiology reports, facilitating comprehensive analysis. We validate our approach by comparing its performance with state-of-the-art methods and assessing its generalizability among different radiologists, introducing novel strategies to model radiologists' search patterns during CXR image diagnosis. Based on the radiologist's evaluation, MedGaze can generate human-like gaze sequences with a high focus on relevant regions over the CXR images. It sometimes also outperforms humans in terms of redundancy and randomness in the scanpaths.",
    "pdf_link": "https://arxiv.org/abs/2407.00129",
    "graphs": [],
    "abstract_cn": "在计算机视觉领域，预测人类的注视行为对于构建能够预判用户注意力的交互系统至关重要，同时也为认知科学的基本问题提供了解决方案，并对HCI和AR/VR系统等领域产生深远影响。尽管已有方法用于模拟人类的眼睛注视行为，但在医学影像领域应用这些模型进行扫描路径预测的研究尚属空白。我们提出的系统致力于从放射学报告和CXR图像中预测眼睛注视序列，有望简化数据收集流程，并利用更大数据集提升AI系统的性能。然而，预测医学图像上的扫描路径因异常区域的多样性而充满挑战。我们的模型在预测关键的固定坐标和持续时间方面表现卓越，超越了计算机视觉领域的现有模型。通过采用两阶段训练流程和利用大型公开数据集，我们的方法能够生成与放射学报告相匹配的静态热图和眼睛注视视频，从而促进深入分析。我们通过对比最先进方法的性能并评估其在不同放射科医生间的泛化能力来验证我们的方法，并创新性地模拟了放射科医生在CXR图像诊断时的搜索模式。根据放射科医生的评价，MedGaze能够生成高度聚焦于CXR图像上相关区域的人类样注视序列，甚至在扫描路径的冗余和随机性方面有时超越人类表现。",
    "title_cn": "多模态学习与放射学认知：MedGaze在胸部X光扫描路径预测中的应用",
    "tags": [
      "LLM应用",
      "",
      "计算机视觉"
    ]
  },
  {
    "title": "Which Neurons Matter in IR? Applying Integrated Gradients-based Methods to Understand Cross-Encoders",
    "submit_datetime": "2024年06月27日",
    "abstract": "With the recent addition of Retrieval-Augmented Generation (RAG), the scope and importance of Information Retrieval (IR) has expanded. As a result, the importance of a deeper understanding of IR models also increases. However, interpretability in IR remains under-explored, especially when it comes to the models' inner mechanisms. In this paper, we explore the possibility of adapting Integrated Gradient-based methods in an IR context to identify the role of individual neurons within the model. In particular, we provide new insights into the role of what we call \"relevance\" neurons, as well as how they deal with unseen data. Finally, we carry out an in-depth pruning study to validate our findings.",
    "pdf_link": "https://arxiv.org/abs/2406.19309",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19309v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19309/nig.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19309v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19309/intersection_positives_new_baseline_all_datasets.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19309v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19309/intersection_positives_new_baseline_all_datasets_but_robust_nfcorpus.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19309v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19309/intersection_negatives_all_datasets_new_baseline.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19309v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19309/intersection_negatives_all_datasets_less_robust_nfcorpus_new_baseline.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19309v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19309/summary_everything_new_baseline.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19309v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19309/ablation_scheme_msmarco_negative_new_baseline.png"
      }
    ],
    "abstract_cn": "随着检索增强生成（RAG）的引入，信息检索（IR）的重要性与日俱增。然而，对于IR模型的内部运作机制，我们的理解仍显不足。本文中，我们尝试采用基于集成梯度的方法，在IR领域中揭示单个神经元的作用，特别是那些我们称之为“相关性”神经元的角色，以及它们如何应对未知数据。最后，我们通过详尽的剪枝实验来验证这些发现。",
    "title_cn": "探究信息检索中的关键神经元：采用集成梯度方法解析交叉编码器的奥秘",
    "tags": [
      "RAG\n\n这篇论文主要关注检索增强生成（RAG）技术中的信息检索（IR）模型，特别是探讨了神经元在IR模型中的作用，并通过剪枝实验来验证这些发现。因此，它属于RAG分类，因为它专注于RAG框架内的信息检索机制的研究和理解。",
      "信息检索",
      "机器学习"
    ]
  },
  {
    "title": "From Artificial Needles to Real Haystacks: Improving Retrieval Capabilities in LLMs by Finetuning on Synthetic Data",
    "submit_datetime": "2024年06月27日",
    "abstract": "Recent studies have shown that Large Language Models (LLMs) struggle to accurately retrieve information and maintain reasoning capabilities when processing long-context inputs. To address these limitations, we propose a finetuning approach utilizing a carefully designed synthetic dataset comprising numerical key-value retrieval tasks. Our experiments on models like GPT-3.5 Turbo and Mistral 7B demonstrate that finetuning LLMs on this dataset significantly improves LLMs' information retrieval and reasoning capabilities in longer-context settings. We present an analysis of the finetuned models, illustrating the transfer of skills from synthetic to real task evaluations (e.g., $10.5\\%$ improvement on $20$ documents MDQA at position $10$ for GPT-3.5 Turbo). We also find that finetuned LLMs' performance on general benchmarks remains almost constant while LLMs finetuned on other baseline long-context augmentation data can encourage hallucination (e.g., on TriviaQA, Mistral 7B finetuned on our synthetic data cause no performance drop while other baseline data can cause a drop that ranges from $2.33\\%$ to $6.19\\%$). Our study highlights the potential of finetuning on synthetic data for improving the performance of LLMs on longer-context tasks.",
    "pdf_link": "https://arxiv.org/abs/2406.19292",
    "graphs": [],
    "abstract_cn": "最新研究表明，大型语言模型（LLMs）在处理长篇输入时，信息检索和推理能力面临挑战。为此，我们提出了一种基于合成数据集的微调策略，该数据集专为数值键值检索任务设计。实验结果显示，如GPT-3.5 Turbo和Mistral 7B等模型通过此数据集微调后，在长上下文环境中的信息检索和推理能力显著提升。我们进一步分析了这些微调模型的表现，发现它们在实际任务评估中展现出了从合成任务到实际应用的良好技能转移（例如，GPT-3.5 Turbo在处理20份文档的MDQA任务中，位置10的性能提升了10.5%）。同时，微调后的LLMs在通用基准测试中的表现保持稳定，而使用其他长上下文增强数据集的模型可能会出现性能下降，甚至产生幻觉（例如，在TriviaQA测试中，Mistral 7B微调我们的合成数据未见性能下降，而其他数据集可能导致性能下降2.33%至6.19%）。本研究凸显了通过合成数据微调提升LLMs在长上下文任务中性能的巨大潜力。",
    "title_cn": "从人工针到真实干草堆：通过微调合成数据，提升大型语言模型的检索能力",
    "tags": [
      "LLM应用\n\n这篇论文探讨了通过合成数据集微调大型语言模型（LLMs）以提高其在长上下文环境中的信息检索和推理能力。研究结果显示，特定的微调策略能够显著提升模型在实际任务中的表现，同时保持模型在通用基准测试中的稳定性。这种方法特别关注了数值键值检索任务，并展示了从合成任务到实际应用的良好技能转移。因此，这项工作属于LLM应用类别，因为它专注于实际应用中的模型性能改进。",
      "信息检索",
      ""
    ]
  },
  {
    "title": "AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation",
    "submit_datetime": "2024年06月27日",
    "abstract": "Recent advancements in Large Language Models have transformed ML/AI development, necessitating a reevaluation of AutoML principles for the Retrieval-Augmented Generation (RAG) systems. To address the challenges of hyper-parameter optimization and online adaptation in RAG, we propose the AutoRAG-HP framework, which formulates the hyper-parameter tuning as an online multi-armed bandit (MAB) problem and introduces a novel two-level Hierarchical MAB (Hier-MAB) method for efficient exploration of large search spaces. We conduct extensive experiments on tuning hyper-parameters, such as top-k retrieved documents, prompt compression ratio, and embedding methods, using the ALCE-ASQA and Natural Questions datasets. Our evaluation from jointly optimization all three hyper-parameters demonstrate that MAB-based online learning methods can achieve Recall@5 $\\approx 0.8$ for scenarios with prominent gradients in search space, using only $\\sim20\\%$ of the LLM API calls required by the Grid Search approach. Additionally, the proposed Hier-MAB approach outperforms other baselines in more challenging optimization scenarios. The code will be made available at https://aka.ms/autorag.",
    "pdf_link": "https://arxiv.org/abs/2406.19251",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19251v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19251/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19251v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19251/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19251v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19251/gt_asqa_4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19251v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19251/ASQA_gpt4_2_param_alpha_1-NQ_gpt4_2_param_alpha_1_topk_3_interval_100.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19251v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19251/ASQA_gpt4_3_param_alpha_1-NQ_gpt4_3_param_alpha_1_topk_5_interval_100.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19251v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19251/ASQA_gpt4_3_param_ablation-NQ_gpt4_3_param_ablation_topk_5_interval_100.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19251v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19251/ASQA_gpt4_3_param_ablation_batch-NQ_gpt4_3_param_ablation_batch_topk_5_interval_100.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19251v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19251/demo_model_change_seed_0.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19251v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19251/demo_model_change_metric.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19251v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19251/gt_asqa_35.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19251v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19251/gt_nq_4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19251v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19251/gt_nq_35.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19251v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19251/ASQA_gpt35_2_param_alpha_1-NQ_gpt35_2_param_alpha_1_topk_3_interval_100.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19251v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19251/ASQA_gpt35_3_param_alpha_1-NQ_gpt35_3_param_alpha_1_topk_5_interval_100.png"
      }
    ],
    "abstract_cn": "大型语言模型的进步将机器学习和人工智能的开发推向新高度，促使我们重新审视检索增强生成（RAG）系统的自动机器学习（AutoML）原则。面对RAG系统中超参数优化和在线适应的挑战，我们开发了AutoRAG-HP框架，将超参数调整视为在线多臂老虎机（MAB）问题，并创新性地采用了双层层次MAB（Hier-MAB）方法，以高效探索庞大的搜索空间。我们在ALCE-ASQA和Natural Questions数据集上进行了深入实验，调整了包括检索文档前k个、提示压缩比率和嵌入方法在内的超参数。评估结果表明，通过联合优化这三个关键超参数，基于MAB的在线学习方法在搜索空间梯度显著的场景下，Recall@5可达约0.8，仅消耗网格搜索方法所需LLM API调用的20%。此外，我们的Hier-MAB方法在更复杂的优化场景中表现出色，超越了其他基线。相关代码将在https://aka.ms/autorag公开。",
    "title_cn": "AutoRAG-HP：自动在线优化检索增强生成模型的超参数",
    "tags": [
      "RAG\n\n这篇论文主要关注的是检索增强生成（RAG）系统中的自动机器学习（AutoML）问题，特别是超参数优化和在线适应的挑战。论文提出了一种名为AutoRAG-HP的框架，该框架将超参数调整视为在线多臂老虎机（MAB）问题，并采用了双层层次MAB（Hier-MAB）方法来优化RAG系统的性能。这与Agent、LLM应用和LLM理论分类不符，因为它专注于RAG系统的具体技术实现和优化，而不是代理行为、LLM的具体应用或理论基础。因此，最合适的分类是RAG。",
      "机器学习",
      "问答系统"
    ]
  },
  {
    "title": "Seeing Is Believing: Black-Box Membership Inference Attacks Against Retrieval Augmented Generation",
    "submit_datetime": "2024年06月27日",
    "abstract": "Retrieval-Augmented Generation (RAG) is a state-of-the-art technique that enhances Large Language Models (LLMs) by retrieving relevant knowledge from an external, non-parametric database. This approach aims to mitigate common LLM issues such as hallucinations and outdated knowledge. Although existing research has demonstrated security and privacy vulnerabilities within RAG systems, making them susceptible to attacks like jailbreaks and prompt injections, the security of the RAG system's external databases remains largely underexplored. In this paper, we employ Membership Inference Attacks (MIA) to determine whether a sample is part of the knowledge database of a RAG system, using only black-box API access. Our core hypothesis posits that if a sample is a member, it will exhibit significant similarity to the text generated by the RAG system. To test this, we compute the cosine similarity and the model's perplexity to establish a membership score, thereby building robust features. We then introduce two novel attack strategies: a Threshold-based Attack and a Machine Learning-based Attack, designed to accurately identify membership. Experimental validation of our methods has achieved a ROC AUC of 82%.",
    "pdf_link": "https://arxiv.org/abs/2406.19234",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19234v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19234/fig1.png"
      }
    ],
    "abstract_cn": "Retrieval-Augmented Generation (RAG) 技术通过从外部数据库检索知识，提升了大型语言模型 (LLMs) 的性能，有效缓解了幻觉和知识过时等问题。尽管 RAG 系统已知存在安全隐私风险，但外部数据库的安全性研究仍显不足。本文利用成员推理攻击 (MIA)，通过黑盒 API 访问，探究样本是否属于 RAG 系统的知识库。我们假设，若样本属于知识库，其与 RAG 生成的文本将高度相似。为此，我们通过计算余弦相似度和模型困惑度，构建了成员评分机制。进一步，我们提出了两种创新攻击策略：基于阈值和基于机器学习的攻击，以精确识别成员。实验结果显示，我们的方法达到了 82% 的 ROC AUC。",
    "title_cn": "眼见为实：揭秘增强检索生成模型的黑盒成员推断攻击",
    "tags": [
      "RAG\n\n该论文主要探讨了Retrieval-Augmented Generation (RAG) 技术中的安全隐私问题，特别是通过成员推理攻击 (MIA) 来检测样本是否属于 RAG 系统的知识库。这涉及到对 RAG 系统的安全性和隐私保护的研究，因此属于RAG分类。",
      "信息安全",
      "机器学习"
    ]
  },
  {
    "title": "SeaKR: Self-aware Knowledge Retrieval for Adaptive Retrieval Augmented Generation",
    "submit_datetime": "2024年06月27日",
    "abstract": "This paper introduces Self-aware Knowledge Retrieval (SeaKR), a novel adaptive RAG model that extracts self-aware uncertainty of LLMs from their internal states. SeaKR activates retrieval when the LLMs present high self-aware uncertainty for generation. To effectively integrate retrieved knowledge snippets, SeaKR re-ranks them based on LLM's self-aware uncertainty to preserve the snippet that reduces their uncertainty to the utmost. To facilitate solving complex tasks that require multiple retrievals, SeaKR utilizes their self-aware uncertainty to choose among different reasoning strategies. Our experiments on both complex and simple Question Answering datasets show that SeaKR outperforms existing adaptive RAG methods. We release our code at https://github.com/THU-KEG/SeaKR.",
    "pdf_link": "https://arxiv.org/abs/2406.19215",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19215v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19215/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19215v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19215/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19215v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19215/x3.png"
      }
    ],
    "abstract_cn": "本文创新性地提出了自感知知识检索（SeaKR），一种能够从大型语言模型内部捕捉其自我感知不确定性的自适应RAG模型。当模型在生成任务中表现出不确定性时，SeaKR会启动知识检索，并根据模型的不确定性程度对检索到的信息进行优先级排序，确保最有助于降低不确定性的信息被优先使用。此外，SeaKR还能根据任务的复杂性，智能选择合适的推理策略。实验证明，无论是面对复杂还是简单的问答任务，SeaKR均超越了现有的自适应RAG技术。我们已将相关代码公开于https://github.com/THU-KEG/SeaKR，供大家参考。",
    "title_cn": "SeaKR：自适应知识检索增强生成，实现智能知识检索与应用",
    "tags": [
      "RAG\n\n理由：这篇论文介绍了一种名为“自感知知识检索（SeaKR）”的新型自适应RAG模型，该模型能够从大型语言模型内部捕捉其自我感知的不确定性，并据此进行知识检索和信息优先级排序。这种技术专注于改进RAG模型的性能，特别是在处理不确定性时的表现。因此，它属于RAG分类，因为它主要关注的是RAG模型的改进和应用。",
      "问答系统",
      ""
    ]
  },
  {
    "title": "Read Anywhere Pointed: Layout-aware GUI Screen Reading with Tree-of-Lens Grounding",
    "submit_datetime": "2024年06月27日",
    "abstract": "Graphical User Interfaces (GUIs) are central to our interaction with digital devices. Recently, growing efforts have been made to build models for various GUI understanding tasks. However, these efforts largely overlook an important GUI-referring task: screen reading based on user-indicated points, which we name the Screen Point-and-Read (SPR) task. This task is predominantly handled by rigid accessible screen reading tools, in great need of new models driven by advancements in Multimodal Large Language Models (MLLMs). In this paper, we propose a Tree-of-Lens (ToL) agent, utilizing a novel ToL grounding mechanism, to address the SPR task. Based on the input point coordinate and the corresponding GUI screenshot, our ToL agent constructs a Hierarchical Layout Tree. Based on the tree, our ToL agent not only comprehends the content of the indicated area but also articulates the layout and spatial relationships between elements. Such layout information is crucial for accurately interpreting information on the screen, distinguishing our ToL agent from other screen reading tools. We also thoroughly evaluate the ToL agent against other baselines on a newly proposed SPR benchmark, which includes GUIs from mobile, web, and operating systems. Last but not least, we test the ToL agent on mobile GUI navigation tasks, demonstrating its utility in identifying incorrect actions along the path of agent execution trajectories. Code and data: screen-point-and-read.github.io",
    "pdf_link": "https://arxiv.org/abs/2406.19263",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19263v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19263/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19263v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19263/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19263v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19263/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19263v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19263/scatter.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19263v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19263/area_ratio.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19263v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19263/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19263v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19263/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19263v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19263/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19263v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19263/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19263v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19263/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19263v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19263/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19263v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19263/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19263v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19263/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19263v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19263/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19263v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19263/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19263v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19263/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19263v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19263/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19263v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19263/append_survey.png"
      }
    ],
    "abstract_cn": "图形用户界面（GUIs）是我们与数字设备互动的关键。近期，针对各种GUI理解任务的模型构建工作日益增多，但一个重要的任务——基于用户指定点的屏幕阅读（我们称之为屏幕点读任务，SPR）却被忽视。目前，这一任务主要依赖于刚性的辅助工具，亟需借助多模态大型语言模型（MLLMs）的新技术。本文提出了一种名为“透镜树”（ToL）的代理，它采用创新的ToL接地机制，专门针对SPR任务。通过输入点坐标和GUI截图，ToL代理构建出层次布局树，不仅能解读指定区域的内容，还能清晰展示元素间的布局与空间关系。这种布局信息的精确解读，使ToL代理在众多屏幕阅读工具中独树一帜。我们在新设的SPR基准上，对比了ToL代理与其他模型，涵盖了移动、网页及操作系统中的GUIs。此外，ToL代理在移动GUI导航任务中的应用，也证明了其在识别执行路径中错误动作方面的有效性。更多代码和数据，请访问：screen-point-and-read.github.io。",
    "title_cn": "任意位置阅读助手：采用树形透镜定位技术的布局感知图形用户界面屏幕阅读方案",
    "tags": [
      "Agent\n\n理由：这篇论文介绍了一种名为“透镜树”（ToL）的代理，专门设计用于屏幕点读任务（SPR）。该代理通过创新的ToL接地机制，能够处理输入的点坐标和GUI截图，构建出层次布局树，并解读指定区域的内容以及元素间的布局与空间关系。这种专门针对特定任务（SPR）的代理设计和实现，以及其在实际GUI理解任务中的应用，符合Agent类别的定义。",
      "人机交互",
      "辅助技术"
    ]
  },
  {
    "title": "Simulating Classroom Education with LLM-Empowered Agents",
    "submit_datetime": "2024年06月27日",
    "abstract": "Large language models (LLMs) have been employed in various intelligent educational tasks to assist teaching. While preliminary explorations have focused on independent LLM-empowered agents for specific educational tasks, the potential for LLMs within a multi-agent collaborative framework to simulate a classroom with real user participation remains unexplored. In this work, we propose SimClass, a multi-agent classroom simulation framework involving user participation. We recognize representative class roles and introduce a novel class control mechanism for automatic classroom teaching, and conduct user experiments in two real-world courses. Utilizing the Flanders Interactive Analysis System and Community of Inquiry theoretical frame works from educational analysis, we demonstrate that LLMs can simulate traditional classroom interaction patterns effectively while enhancing user's experience. We also observe emergent group behaviors among agents in SimClass, where agents collaborate to create enlivening interactions in classrooms to improve user learning process. We hope this work pioneers the application of LLM-empowered multi-agent systems in virtual classroom teaching.",
    "pdf_link": "https://arxiv.org/abs/2406.19226",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19226v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19226/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19226v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19226/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19226v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19226/CoI.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19226v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19226/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19226v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19226/x4.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）在智能教育领域已广泛应用，但其在多代理协作环境中模拟真实课堂的潜力尚未充分挖掘。本研究推出了SimClass框架，这是一个结合用户参与的多代理模拟课堂系统。我们定义了关键的课堂角色，并创新性地设计了自动课堂控制机制，通过在两门真实课程中进行用户实验来验证其效果。借助Flanders互动分析系统和探究社区理论，我们展示了LLMs如何有效模拟传统课堂互动，并提升用户体验。此外，我们还观察到SimClass中代理间自发形成的协作行为，这些行为旨在通过课堂互动促进学习过程。我们期望这项研究能够引领LLM赋能的多代理系统在虚拟教学中的新应用。",
    "title_cn": "借助LLM赋能的代理，模拟课堂教育场景",
    "tags": [
      "Agent\n\n这篇论文主要介绍了SimClass框架，这是一个结合用户参与的多代理模拟课堂系统。它通过定义关键的课堂角色和设计自动课堂控制机制，利用大型语言模型（LLMs）在多代理协作环境中模拟真实课堂。研究通过用户实验验证了系统的效果，并展示了LLMs如何有效模拟传统课堂互动，提升用户体验。此外，论文还观察到系统中代理间自发形成的协作行为，这些行为旨在通过课堂互动促进学习过程。因此，这篇论文更符合Agent分类，因为它主要关注的是多代理系统的设计和应用，以及这些代理如何在模拟课堂环境中协作。",
      "",
      "虚拟教学"
    ]
  },
  {
    "title": "CELLO: Causal Evaluation of Large Vision-Language Models",
    "submit_datetime": "2024年06月27日",
    "abstract": "Causal reasoning is fundamental to human intelligence and crucial for effective decision-making in real-world environments. Despite recent advancements in large vision-language models (LVLMs), their ability to comprehend causality remains unclear. Previous work typically focuses on commonsense causality between events and/or actions, which is insufficient for applications like embodied agents and lacks the explicitly defined causal graphs required for formal causal reasoning. To overcome these limitations, we introduce a fine-grained and unified definition of causality involving interactions between humans and/or objects. Building on the definition, we construct a novel dataset, CELLO, consisting of 14,094 causal questions across all four levels of causality: discovery, association, intervention, and counterfactual. This dataset surpasses traditional commonsense causality by including explicit causal graphs that detail the interactions between humans and objects. Extensive experiments on CELLO reveal that current LVLMs still struggle with causal reasoning tasks, but they can benefit significantly from our proposed CELLO-CoT, a causally inspired chain-of-thought prompting strategy. Both quantitative and qualitative analyses from this study provide valuable insights for future research. Our project page is at https://github.com/OpenCausaLab/CELLO.",
    "pdf_link": "https://arxiv.org/abs/2406.19131",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19131v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19131/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19131v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19131/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19131v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19131/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19131v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19131/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19131v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19131/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19131v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19131/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19131v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19131/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19131v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19131/error_main.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19131v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19131/human_evaluation.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19131v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19131/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19131v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19131/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19131v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19131/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19131v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19131/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19131v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19131/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19131v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19131/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19131v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19131/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19131v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19131/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19131v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19131/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19131v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19131/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19131v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19131/x18.png"
      }
    ],
    "abstract_cn": "因果推理是人类智能的基石，对于在现实世界中做出明智决策至关重要。尽管大型视觉-语言模型（LVLMs）取得了进展，但它们对因果关系的理解仍是一个谜。以往研究多聚焦于事件或行动间的常识因果，这对于具身代理等应用来说远远不够，且缺乏正式因果推理所需的明确因果图。为此，我们提出了一种涉及人与物体交互的细粒度因果定义，并据此创建了CELLO数据集，包含14,094个涵盖四个因果层次的问题，并通过明确的因果图详细描绘了人与物体的互动。实验显示，LVLMs在因果推理上仍显吃力，但通过我们提出的CELLO-CoT策略——一种受因果启发的思维链提示方法，它们能显著提升表现。本研究不仅提供了定量分析，还通过定性分析为未来研究指明了方向。项目详情请访问https://github.com/OpenCausaLab/CELLO。",
    "title_cn": "CELLO：探究大型视觉-语言模型的因果效应评估",
    "tags": [
      "Agent\n\n这篇论文主要关注的是大型视觉-语言模型（LVLMs）在因果推理方面的应用，特别是在具身代理等应用中的表现。论文提出了一种新的因果定义和数据集（CELLO），并通过实验展示了如何通过特定的策略（CELLO-CoT）提升LVLMs在因果推理上的表现。这些内容主要涉及如何增强模型在特定任务（如具身代理）中的因果推理能力，因此更适合归类于Agent分类，即关注模型在代理行为和决策中的应用。",
      "人工智能",
      "数据集"
    ]
  },
  {
    "title": "EmPO: Theory-Driven Dataset Construction for Empathetic Response Generation through Preference Optimization",
    "submit_datetime": "2024年06月27日",
    "abstract": "Empathetic response generation is a desirable aspect of conversational agents, crucial for facilitating engaging and emotionally intelligent multi-turn conversations between humans and machines. Leveraging large language models for this task has shown promising results, yet challenges persist in ensuring both the empathetic quality of the responses and retention of the generalization performance of the models. In this paper, we propose a novel approach where we construct theory-driven preference datasets and use them to align LLMs with preference optimization algorithms to address these challenges. To measure empathetic response generation, we employ the EmpatheticDialogues dataset, assessing empathy with the diff-EPITOME and BERTscore metrics, and evaluate the generalization performance on the MMLU benchmark. We make all datasets, source code, and models publicly available.",
    "pdf_link": "https://arxiv.org/abs/2406.19071",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19071/mmluvsalpha.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19071/alphavsdiff.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19071/diffmmludpo.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19071/putchik.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19071v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19071/dyads.png"
      }
    ],
    "abstract_cn": "共情响应生成对于提升会话代理的吸引力与情感智能至关重要，它能够促进人与机器间的深入对话。尽管大型语言模型在此领域已取得进展，但如何确保响应的共情性与模型的泛化能力仍是挑战。本文提出了一种创新方法：通过构建理论驱动的偏好数据集，并运用偏好优化算法来优化LLMs，以应对这些难题。我们采用EmpatheticDialogues数据集，并结合diff-EPITOME与BERTscore指标来评估共情表现，同时在MMLU基准上检验模型的泛化能力。所有相关数据集、代码及模型均已公开。",
    "title_cn": "EmPO：理论驱动下的共情响应生成数据集构建——偏好优化之道",
    "tags": [
      "Agent\n\n这篇论文主要关注的是会话代理（Agent）中的共情响应生成问题，并提出了一种创新方法来优化大型语言模型（LLMs）以提高共情性和模型的泛化能力。虽然涉及到了LLMs的应用，但其核心在于提升会话代理的情感智能，因此更符合Agent分类。",
      "会话代理",
      "情感智能"
    ]
  },
  {
    "title": "UniGen: A Unified Framework for Textual Dataset Generation Using Large Language Models",
    "submit_datetime": "2024年06月27日",
    "abstract": "Large Language Models (LLMs) such as GPT-4 and Llama3 have significantly impacted various fields by enabling high-quality synthetic data generation and reducing dependence on expensive human-generated datasets. Despite this, challenges remain in the areas of generalization, controllability, diversity, and truthfulness within the existing generative frameworks. To address these challenges, this paper presents UniGen, a comprehensive LLM-powered framework designed to produce diverse, accurate, and highly controllable datasets. UniGen is adaptable, supporting all types of text datasets and enhancing the generative process through innovative mechanisms. To augment data diversity, UniGen incorporates an attribute-guided generation module and a group checking feature. For accuracy, it employs a code-based mathematical assessment for label verification alongside a retrieval-augmented generation technique for factual validation. The framework also allows for user-specified constraints, enabling customization of the data generation process to suit particular requirements. Extensive experiments demonstrate the superior quality of data generated by UniGen, and each module within UniGen plays a critical role in this enhancement. Additionally, UniGen is applied in two practical scenarios: benchmarking LLMs and data augmentation. The results indicate that UniGen effectively supports dynamic and evolving benchmarking, and that data augmentation improves LLM capabilities in various domains, including agent-oriented abilities and reasoning skills.",
    "pdf_link": "https://arxiv.org/abs/2406.18966",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.18966v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18966/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18966v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18966/architecture.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18966v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18966/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18966v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18966/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18966v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18966/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18966v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18966/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18966v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18966/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18966v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18966/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18966v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18966/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18966v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18966/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18966v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18966/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18966v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18966/relection_evaluation.jpg"
      },
      {
        "url": "https://arxiv.org/html/2406.18966v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18966/human_evaluation.jpg"
      }
    ],
    "abstract_cn": "GPT-4和Llama3等大型语言模型（LLMs）通过高质量的合成数据生成，显著减少了对昂贵人工数据集的依赖，从而在多个领域产生了深远影响。然而，现有生成框架在泛化、可控、多样性和真实性方面仍存在挑战。为此，我们提出了UniGen，一个由LLM驱动的全面框架，旨在生成多样、准确且高度可控的数据集。UniGen灵活支持各类文本数据集，并通过创新机制优化生成过程。它通过属性引导的生成模块和组检查功能增强数据多样性，利用基于代码的数学评估和检索增强的生成技术确保数据准确性。用户还可通过指定约束来定制数据生成过程。实验证明，UniGen生成的数据质量卓越，各模块均发挥关键作用。在LLMs基准测试和数据增强的实际应用中，UniGen展现了其支持动态基准测试的能力，并在多个领域，包括代理导向能力和推理技能，提升了LLM的性能。",
    "title_cn": "UniGen：大型语言模型驱动下的文本数据集生成统一框架",
    "tags": [
      "LLM应用\n\n这篇论文介绍了一个名为UniGen的框架，该框架由大型语言模型（LLMs）驱动，旨在生成多样、准确且高度可控的文本数据集。UniGen的设计目标是解决现有生成框架在泛化、可控性、多样性和真实性方面的挑战。它通过创新的机制，如属性引导的生成模块和组检查功能，以及基于代码的数学评估和检索增强的生成技术，来优化数据生成过程。此外，用户可以通过指定约束来定制数据生成过程。实验结果表明，UniGen生成的数据质量高，且在多个领域提升了LLM的性能。因此，这篇论文属于LLM应用分类，因为它专注于开发和应用LLM技术来解决实际问题。",
      "数据增强",
      "人工智能"
    ]
  },
  {
    "title": "Capturing Minds, Not Just Words: Enhancing Role-Playing Language Models with Personality-Indicative Data",
    "submit_datetime": "2024年06月27日",
    "abstract": "Role-playing agents (RPA) have been a popular application area for large language models (LLMs), attracting significant interest from both industry and academia.While existing RPAs well portray the characters' knowledge and tones, they face challenges in capturing their minds, especially for small role-playing language models (RPLMs). In this paper, we propose to enhance RPLMs via personality-indicative data. Specifically, we leverage questions from psychological scales and distill advanced RPAs to generate dialogues that grasp the minds of characters. Experimental results validate that RPLMs trained with our dataset exhibit advanced role-playing capabilities for both general and personality-related evaluations. Code and data are available at \\href{https://github.com/alienet1109/RolePersonality}{this URL}.",
    "pdf_link": "https://arxiv.org/abs/2406.18921",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.18921v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18921/x1.png"
      }
    ],
    "abstract_cn": "角色扮演代理（RPA）在大型语言模型（LLMs）中备受瞩目，吸引了工业界和学术界的广泛关注。尽管现有RPA能准确描绘角色的知识和语气，但在捕捉角色心理方面，尤其是小型角色扮演语言模型（RPLMs），仍显不足。本文提出利用心理量表问题和高级RPA的对话生成技术，通过个性指示数据增强RPLMs，以更深入地理解角色心理。实验证明，采用我们数据集训练的RPLMs在通用及个性相关评估中均展现出卓越的角色扮演能力。相关代码和数据已公开于\\href{https://github.com/alienet1109/RolePersonality}{此链接}。",
    "title_cn": "不仅仅是文字，更要捕捉心灵：通过融入个性指示数据，我们能够提升角色扮演语言模型的表现力。",
    "tags": [
      "Agent\n\n这篇论文主要关注的是角色扮演代理（RPA）在大型语言模型（LLMs）中的应用，特别是在小型角色扮演语言模型（RPLMs）中增强角色心理理解的方面。论文提出了一种方法，通过心理量表问题和高级RPA的对话生成技术来增强RPLMs，以提高其在角色扮演中的表现。这与Agent分类相关，因为Agent通常指的是能够执行特定任务或模拟特定角色的智能实体，而RPA在这里可以被视为一种特定类型的Agent，专注于角色扮演和心理理解。因此，这篇论文更适合归类于Agent。",
      "角色扮演",
      "对话系统"
    ]
  },
  {
    "title": "ReXTime: A Benchmark Suite for Reasoning-Across-Time in Videos",
    "submit_datetime": "2024年06月27日",
    "abstract": "We introduce ReXTime, a benchmark designed to rigorously test AI models' ability to perform temporal reasoning within video events. Specifically, ReXTime focuses on reasoning across time, i.e. human-like understanding when the question and its corresponding answer occur in different video segments. This form of reasoning, requiring advanced understanding of cause-and-effect relationships across video segments, poses significant challenges to even the frontier multimodal large language models. To facilitate this evaluation, we develop an automated pipeline for generating temporal reasoning question-answer pairs, significantly reducing the need for labor-intensive manual annotations. Our benchmark includes 921 carefully vetted validation samples and 2,143 test samples, each manually curated for accuracy and relevance. Evaluation results show that while frontier large language models outperform academic models, they still lag behind human performance by a significant 14.3% accuracy gap. Additionally, our pipeline creates a training dataset of 9,695 machine generated samples without manual effort, which empirical studies suggest can enhance the across-time reasoning via fine-tuning.",
    "pdf_link": "https://arxiv.org/abs/2406.19392",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19392v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19392/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19392v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19392/main8.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19392v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19392/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19392v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19392/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19392v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19392/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19392v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19392/qualitative_1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19392v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19392/qualitative_2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19392v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19392/qualitative_3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19392v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19392/qualitative_4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19392v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19392/qualitative_5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19392v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19392/qualitative_6.png"
      }
    ],
    "abstract_cn": "我们推出了ReXTime基准，专门设计来考验AI模型在视频事件中进行时间推理的能力。ReXTime特别关注跨时间推理，即模拟人类在问题和答案出现在不同视频片段时的理解方式。这种高级推理，涉及对视频片段间因果关系的深刻理解，对最尖端的多模态大型语言模型也是一大挑战。为此，我们开发了一套自动化系统，用于生成时间推理的问题与答案，大幅减少了对人工标注的依赖。我们的基准包含921个精挑细选的验证样本和2,143个测试样本，均由人工精心校对以确保其准确性和相关性。评估结果表明，尽管前沿的大型语言模型在性能上超越了学术模型，但与人类相比，它们在准确性上仍有14.3%的差距。此外，我们的系统还生成了一个包含9,695个样本的训练数据集，无需人工介入，实证研究显示，通过微调可以显著提升跨时间推理的能力。",
    "title_cn": "ReXTime：视频跨时间推理的基准套件",
    "tags": [
      "Agent\n\n这篇论文主要介绍了ReXTime基准，这是一个专门设计来测试AI模型在视频事件中进行时间推理能力的基准。它特别关注跨时间推理，即模拟人类在问题和答案出现在不同视频片段时的理解方式。这种高级推理涉及对视频片段间因果关系的深刻理解，对多模态大型语言模型来说是一个挑战。论文中提到，他们开发了一套自动化系统来生成时间推理的问题与答案，并建立了一个包含多个样本的训练数据集。这个工作更偏向于Agent的范畴，因为它涉及创建和评估能够进行复杂时间推理的AI模型，这些模型可以被视为智能Agent，能够在特定任务（如视频理解）中执行复杂的推理和决策。",
      "视频分析",
      "人工智能"
    ]
  },
  {
    "title": "OMG-LLaVA: Bridging Image-level, Object-level, Pixel-level Reasoning and Understanding",
    "submit_datetime": "2024年06月27日",
    "abstract": "Current universal segmentation methods demonstrate strong capabilities in pixel-level image and video understanding. However, they lack reasoning abilities and cannot be controlled via text instructions. In contrast, large vision-language multimodal models exhibit powerful vision-based conversation and reasoning capabilities but lack pixel-level understanding and have difficulty accepting visual prompts for flexible user interaction. This paper proposes OMG-LLaVA, a new and elegant framework combining powerful pixel-level vision understanding with reasoning abilities. It can accept various visual and text prompts for flexible user interaction. Specifically, we use a universal segmentation method as the visual encoder, integrating image information, perception priors, and visual prompts into visual tokens provided to the LLM. The LLM is responsible for understanding the user's text instructions and providing text responses and pixel-level segmentation results based on the visual information. We propose perception prior embedding to better integrate perception priors with image features. OMG-LLaVA achieves image-level, object-level, and pixel-level reasoning and understanding in a single model, matching or surpassing the performance of specialized methods on multiple benchmarks. Rather than using LLM to connect each specialist, our work aims at end-to-end training on one encoder, one decoder, and one LLM. The code and model have been released for further research.",
    "pdf_link": "https://arxiv.org/abs/2406.19389",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19389v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19389/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19389v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19389/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19389v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19389/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19389v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19389/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19389v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19389/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19389v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19389/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19389v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19389/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19389v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19389/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19389v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19389/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19389v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19389/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19389v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19389/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19389v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19389/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19389v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19389/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19389v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19389/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19389v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19389/x15.png"
      }
    ],
    "abstract_cn": "当前的通用分割技术虽在像素级别的图像和视频理解上表现出色，却缺乏推理能力，且无法通过文本指令操控。相反，大型视觉-语言模型虽具备强大的视觉对话和推理能力，但在像素级别理解和灵活接受视觉提示方面存在局限。本文推出的OMG-LLaVA框架，巧妙融合了像素级视觉理解和推理能力，能灵活响应各类视觉和文本提示。我们采用通用分割技术作为视觉编码器，将图像信息、感知先验与视觉提示转化为LLM的视觉令牌。LLM则负责解析文本指令，并基于视觉信息提供文本反馈及像素级分割结果。通过引入感知先验嵌入，我们优化了感知先验与图像特征的融合。OMG-LLaVA在单一模型中实现了图像、对象及像素级别的推理与理解，性能在多个测试基准上与专业方法相媲美甚至超越。我们不依赖LLM连接各专家，而是通过一个编码器、一个解码器和一个LLM实现端到端训练。代码和模型已公开，以促进后续研究。",
    "title_cn": "OMG-LLaVA：融合图像、对象与像素级的推理与理解之桥",
    "tags": [
      "LLM应用\n\n这篇论文介绍了一个名为OMG-LLaVA的框架，该框架结合了像素级视觉理解和推理能力，能够灵活地响应视觉和文本提示。它使用通用分割技术作为视觉编码器，将图像信息、感知先验和视觉提示转化为LLM的视觉令牌，而LLM则负责解析文本指令并提供文本反馈及像素级分割结果。这种方法在单一模型中实现了图像、对象及像素级别的推理与理解，并在多个测试基准上展示了优异的性能。因此，这篇论文属于LLM应用类别，因为它展示了如何将LLM应用于具体的视觉理解和推理任务中。",
      "计算机视觉",
      ""
    ]
  },
  {
    "title": "HuatuoGPT-Vision, Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale",
    "submit_datetime": "2024年06月27日",
    "abstract": "The rapid development of multimodal large language models (MLLMs), such as GPT-4V, has led to significant advancements. However, these models still face challenges in medical multimodal capabilities due to limitations in the quantity and quality of medical vision-text data, stemming from data privacy concerns and high annotation costs. While pioneering approaches utilize PubMed's large-scale, de-identified medical image-text pairs to address these limitations, they still fall short due to inherent data noise. To tackle this, we refined medical image-text pairs from PubMed and employed MLLMs (GPT-4V) in an 'unblinded' capacity to denoise and reformat the data, resulting in the creation of the PubMedVision dataset with 1.3 million medical VQA samples. Our validation demonstrates that: (1) PubMedVision can significantly enhance the medical multimodal capabilities of current MLLMs, showing significant improvement in benchmarks including the MMMU Health & Medicine track; (2) manual checks by medical experts and empirical results validate the superior data quality of our dataset compared to other data construction methods. Using PubMedVision, we train a 34B medical MLLM HuatuoGPT-Vision, which shows superior performance in medical multimodal scenarios among open-source MLLMs.",
    "pdf_link": "https://arxiv.org/abs/2406.19280",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19280v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19280/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19280v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19280/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19280v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19280/datatype1.jpg"
      },
      {
        "url": "https://arxiv.org/html/2406.19280v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19280/datatype2.jpg"
      },
      {
        "url": "https://arxiv.org/html/2406.19280v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19280/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19280v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19280/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19280v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19280/7325.jpg"
      },
      {
        "url": "https://arxiv.org/html/2406.19280v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19280/11.jpg"
      },
      {
        "url": "https://arxiv.org/html/2406.19280v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19280/56.jpg"
      },
      {
        "url": "https://arxiv.org/html/2406.19280v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19280/348.jpg"
      },
      {
        "url": "https://arxiv.org/html/2406.19280v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19280/7851.jpg"
      },
      {
        "url": "https://arxiv.org/html/2406.19280v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19280/4330_0.jpg"
      },
      {
        "url": "https://arxiv.org/html/2406.19280v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19280/4330_1.jpg"
      },
      {
        "url": "https://arxiv.org/html/2406.19280v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19280/7646_1.jpg"
      },
      {
        "url": "https://arxiv.org/html/2406.19280v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19280/7646_2.jpg"
      },
      {
        "url": "https://arxiv.org/html/2406.19280v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19280/7646_3.jpg"
      },
      {
        "url": "https://arxiv.org/html/2406.19280v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19280/7646_0.jpg"
      }
    ],
    "abstract_cn": "随着GPT-4V等MLLMs的迅猛发展，医疗领域的多模态能力取得了显著进步，但仍受限于医疗视觉-文本数据的稀缺与质量问题，这主要归咎于数据隐私和高昂的标注成本。尽管有研究利用PubMed的大规模去标识化医疗图像-文本对来弥补这一缺陷，但数据噪声问题依旧存在。为此，我们精心筛选了PubMed的医疗图像-文本对，并运用GPT-4V以“非盲”模式进行数据去噪和重构，成功构建了包含130万医疗VQA样本的PubMedVision数据集。验证结果显示：(1) PubMedVision极大地提升了现有MLLMs在医疗多模态任务中的表现，尤其是在MMMU健康与医学赛道等基准测试中；(2) 医学专家的审核及实证分析均证实，我们的数据集在质量上超越了其他同类构建方法。基于PubMedVision，我们训练出了34B参数的医疗MLLM HuatuoGPT-Vision，其在开源MLLMs中展现出了卓越的医疗多模态应用能力。",
    "title_cn": "HuatuoGPT-Vision：大规模注入医学视觉知识至多模态LLMs的探索",
    "tags": [
      "LLM应用\n\n理由：这篇论文主要讨论了如何利用GPT-4V等大型多模态语言模型（MLLMs）来处理和改进医疗领域的多模态数据，特别是通过构建和优化PubMedVision数据集来提升医疗多模态任务的表现。论文中提到的具体应用包括数据去噪、重构以及训练新的医疗MLLM模型（HuatuoGPT-Vision），这些都是在实际应用场景中对LLM技术的具体应用，而非理论研究或Agent、RAG相关的研究。因此，将其归类为LLM应用是合适的。",
      "",
      "多模态学习"
    ]
  },
  {
    "title": "RAVEN: Multitask Retrieval Augmented Vision-Language Learning",
    "submit_datetime": "2024年06月27日",
    "abstract": "The scaling of large language models to encode all the world's knowledge in model parameters is unsustainable and has exacerbated resource barriers. Retrieval-Augmented Generation (RAG) presents a potential solution, yet its application to vision-language models (VLMs) is under explored. Existing methods focus on models designed for single tasks. Furthermore, they're limited by the need for resource intensive pre training, additional parameter requirements, unaddressed modality prioritization and lack of clear benefit over non-retrieval baselines. This paper introduces RAVEN, a multitask retrieval augmented VLM framework that enhances base VLMs through efficient, task specific fine-tuning. By integrating retrieval augmented samples without the need for additional retrieval-specific parameters, we show that the model acquires retrieval properties that are effective across multiple tasks. Our results and extensive ablations across retrieved modalities for the image captioning and VQA tasks indicate significant performance improvements compared to non retrieved baselines +1 CIDEr on MSCOCO, +4 CIDEr on NoCaps and nearly a +3\\% accuracy on specific VQA question types. This underscores the efficacy of applying RAG approaches to VLMs, marking a stride toward more efficient and accessible multimodal learning.",
    "pdf_link": "https://arxiv.org/abs/2406.19150",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19150v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19150/model.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19150v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19150/retriever.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19150v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19150/vqa_successes.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19150v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19150/vqa_failures.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19150v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19150/multimodal_query_embedding.png"
      }
    ],
    "abstract_cn": "将大型语言模型扩展至包含全球知识于参数中已证明不可持续，且加剧了资源限制。检索增强生成（RAG）虽提供了解决方案，但其在视觉-语言模型（VLMs）中的应用尚待深入研究。现有方法多针对单一任务模型，且受限于资源密集预训练、额外参数需求、模态优先级未明及对非检索基准优势不明显。本文推出的RAVEN框架，通过任务特异性高效微调，强化了基础VLMs。无需额外检索参数，RAVEN成功整合检索增强样本，使模型在多任务中展现出高效的检索能力。在图像标注与VQA任务上的广泛测试表明，与非检索基准相比，性能显著提升，分别在MSCOCO和NoCaps上提升了+1和+4 CIDEr，特定VQA问题类型准确率提升近+3%。这证实了RAG方法在VLMs中的有效性，为更高效、可及的多模态学习开辟了新路径。",
    "title_cn": "RAVEN：多任务增强的视觉-语言学习，通过检索技术提升学习效果。",
    "tags": [
      "RAG\n\n理由：这篇论文主要探讨了检索增强生成（RAG）在视觉-语言模型（VLMs）中的应用，特别是通过介绍RAVEN框架来强化基础VLMs，并通过任务特异性高效微调来整合检索增强样本。论文的重点在于展示RAG方法在VLMs中的有效性，以及其在多任务中的性能提升，这与RAG技术的应用和发展紧密相关。因此，将其归类为RAG是合适的。",
      "视觉-语言模型",
      "多模态学习"
    ]
  },
  {
    "title": "DocKylin: A Large Multimodal Model for Visual Document Understanding with Efficient Visual Slimming",
    "submit_datetime": "2024年06月27日",
    "abstract": "Current multimodal large language models (MLLMs) face significant challenges in visual document understanding (VDU) tasks due to the high resolution, dense text, and complex layouts typical of document images. These characteristics demand a high level of detail perception ability from MLLMs. While increasing input resolution improves detail perception, it also leads to longer sequences of visual tokens, increasing computational costs and straining the models' ability to handle long contexts. To address these challenges, we introduce DocKylin, a document-centric MLLM that performs visual content slimming at both the pixel and token levels, thereby reducing token sequence length in VDU scenarios. DocKylin utilizes an Adaptive Pixel Slimming (APS) preprocessing module to perform pixel-level slimming, increasing the proportion of informative pixels. Moreover, DocKylin incorporates a novel Dynamic Token Slimming (DTS) module to conduct token-level slimming, filtering essential tokens and removing others to create a compressed, adaptive visual sequence. Experiments demonstrate DocKylin's promising performance across various VDU benchmarks. Notably, both the proposed APS and DTS are parameter-free, facilitating easy integration into existing MLLMs, and our experiments indicate their potential for broader applications.",
    "pdf_link": "https://arxiv.org/abs/2406.19101",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19101v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19101/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19101v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19101/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19101v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19101/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19101v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19101/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19101v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19101/scene_text.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19101v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19101/textdensing_appendix.png"
      }
    ],
    "abstract_cn": "多模态大型语言模型（MLLMs）在处理高分辨率、文本密集且布局复杂的文档图像时，面临着视觉文档理解（VDU）任务的重大挑战。这些特性对MLLMs的细节感知能力提出了高要求。尽管提高输入分辨率有助于细节感知，但同时也增加了视觉令牌序列的长度，导致计算成本上升，并考验模型处理长上下文的能力。为此，我们推出了DocKylin，一种专为文档设计的MLLM，它通过在像素和令牌级别进行视觉内容精简，有效缩短了VDU场景中的令牌序列长度。DocKylin采用自适应像素精简（APS）预处理模块，提升信息像素的比重，并引入动态令牌精简（DTS）模块，筛选关键令牌，剔除非必要令牌，形成一个紧凑且自适应的视觉序列。实验结果显示，DocKylin在多个VDU基准测试中表现卓越。特别值得一提的是，APS和DTS模块均无需额外参数，易于整合进现有MLLMs，展现出广泛的应用前景。",
    "title_cn": "DocKylin：一款大型多模态模型，专为视觉文档理解设计，通过高效的视觉瘦身技术提升性能。",
    "tags": [
      "LLM应用\n\n理由：这篇论文介绍了一种名为DocKylin的多模态大型语言模型（MLLM），专门设计用于处理视觉文档理解（VDU）任务。论文中提到的DocKylin通过自适应像素精简（APS）和动态令牌精简（DTS）模块，有效地解决了高分辨率文档图像处理中的挑战，如计算成本和长上下文处理能力。这些创新点展示了LLM在特定应用场景下的优化和改进，因此属于LLM应用类别。",
      "文档处理",
      "视觉文档理解"
    ]
  },
  {
    "title": "Fairness and Bias in Multimodal AI: A Survey",
    "submit_datetime": "2024年06月27日",
    "abstract": "The importance of addressing fairness and bias in artificial intelligence (AI) systems cannot be over-emphasized. Mainstream media has been awashed with news of incidents around stereotypes and bias in many of these systems in recent years. In this survey, we fill a gap with regards to the minimal study of fairness and bias in Large Multimodal Models (LMMs) compared to Large Language Models (LLMs), providing 50 examples of datasets and models along with the challenges affecting them; we identify a new category of quantifying bias (preuse), in addition to the two well-known ones in the literature: intrinsic and extrinsic; we critically discuss the various ways researchers are addressing these challenges. Our method involved two slightly different search queries on Google Scholar, which revealed that 33,400 and 538,000 links are the results for the terms \"Fairness and bias in Large Multimodal Models\" and \"Fairness and bias in Large Language Models\", respectively. We believe this work contributes to filling this gap and providing insight to researchers and other stakeholders on ways to address the challenge of fairness and bias in multimodal A!.",
    "pdf_link": "https://arxiv.org/abs/2406.19097",
    "graphs": [],
    "abstract_cn": "AI系统中的公平性与偏见问题至关重要，近年来主流媒体对此类事件的报道不绝于耳。本调查填补了大型多模态模型（LMMs）与大型语言模型（LLMs）中公平性与偏见研究的空白，列举了50个数据集与模型实例及其面临的挑战，并新增了一种量化偏见的方法（preuse），与文献中已有的内在与外在偏见类别并列。我们深入探讨了研究者们应对这些挑战的不同策略。通过在Google Scholar上进行的两个略有差异的搜索，我们发现“大型多模态模型中的公平性与偏见”和“大型语言模型中的公平性与偏见”分别关联到33,400和538,000个链接。我们坚信，这项研究不仅填补了知识空白，还为研究人员及利益相关者提供了应对多模态AI领域公平性与偏见挑战的宝贵洞见。",
    "title_cn": "多模态AI的公平与偏见：深度探索",
    "tags": [
      "LLM理论\n\n理由：这篇论文主要探讨了大型多模态模型（LMMs）和大型语言模型（LLMs）中的公平性与偏见问题，并提出了一种新的量化偏见的方法。这些问题和方法论的研究属于对LLM理论层面的探讨，而非具体的应用、Agent设计或RAG技术。因此，将其归类为LLM理论是合适的。",
      "人工智能",
      "数据分析"
    ]
  },
  {
    "title": "A look under the hood of the Interactive Deep Learning Enterprise (No-IDLE)",
    "submit_datetime": "2024年06月27日",
    "abstract": "This DFKI technical report presents the anatomy of the No-IDLE prototype system (funded by the German Federal Ministry of Education and Research) that provides not only basic and fundamental research in interactive machine learning, but also reveals deeper insights into users' behaviours, needs, and goals. Machine learning and deep learning should become accessible to millions of end users. No-IDLE's goals and scienfific challenges centre around the desire to increase the reach of interactive deep learning solutions for non-experts in machine learning. One of the key innovations described in this technical report is a methodology for interactive machine learning combined with multimodal interaction which will become central when we start interacting with semi-intelligent machines in the upcoming area of neural networks and large language models.",
    "pdf_link": "https://arxiv.org/abs/2406.19054",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19054v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19054/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19054v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19054/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19054v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19054/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19054v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19054/x4.jpeg"
      },
      {
        "url": "https://arxiv.org/html/2406.19054v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19054/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19054v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19054/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19054v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19054/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19054v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19054/usecase_gaze.png"
      }
    ],
    "abstract_cn": "DFKI的这份技术报告深入剖析了No-IDLE系统，该系统由德国联邦教育和研究部资助，不仅推动了交互式机器学习的基础研究，还深入洞察了用户的行为、需求与目标。我们期望机器学习和深度学习能普及至广大用户。No-IDLE项目旨在扩展非专家用户对交互式深度学习技术的接触，其科学挑战即围绕此目标展开。报告中的一个核心创新是结合多模态交互的交互式机器学习方法，这一方法将在我们与未来神经网络和大型语言模型中的半智能机器交互时发挥关键作用。",
    "title_cn": "揭秘互动深度学习企业（No-IDLE）的内在奥秘",
    "tags": [
      "Agent\n\n解析：这篇论文摘要主要描述了No-IDLE系统，这是一个旨在扩展非专家用户对交互式深度学习技术的接触的项目。它强调了多模态交互在交互式机器学习中的应用，并预期这种方法将在与未来神经网络和大型语言模型中的半智能机器交互时发挥关键作用。这表明该系统是一个智能代理（Agent），它通过交互式学习来理解和适应用户的行为、需求与目标。因此，这篇论文应归类为Agent。",
      "机器学习",
      "交互式系统"
    ]
  },
  {
    "title": "The Remarkable Robustness of LLMs: Stages of Inference?",
    "submit_datetime": "2024年06月27日",
    "abstract": "We demonstrate and investigate the remarkable robustness of Large Language Models by deleting and swapping adjacent layers. We find that deleting and swapping interventions retain 72-95\\% of the original model's prediction accuracy without fine-tuning, whereas models with more layers exhibit more robustness. Based on the results of the layer-wise intervention and further experiments, we hypothesize the existence of four universal stages of inference across eight different models: detokenization, feature engineering, prediction ensembling, and residual sharpening. The first stage integrates local information, lifting raw token representations into higher-level contextual representations. Next is the iterative refinement of task and entity-specific features. Then, the second half of the model begins with a phase transition, where hidden representations align more with the vocabulary space due to specialized model components. Finally, the last layer sharpens the following token distribution by eliminating obsolete features that add noise to the prediction.",
    "pdf_link": "https://arxiv.org/abs/2406.19384",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19384v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19384/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19384v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19384/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19384v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19384/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19384v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19384/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19384v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19384/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19384v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19384/attn_gpt.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19384v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19384/attn_pythia.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19384v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19384/attn_phi.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19384v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19384/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19384v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19384/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19384v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19384/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19384v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19384/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19384v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19384/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19384v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19384/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19384v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19384/mlp_gpt.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19384v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19384/mlp_pythia.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19384v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19384/mlp_phi.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19384v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19384/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19384v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19384/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19384v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19384/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19384v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19384/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19384v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19384/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19384v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19384/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19384v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19384/cos_sim.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19384v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19384/mean_cos_sim.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19384v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19384/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19384v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19384/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19384v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19384/output.png"
      }
    ],
    "abstract_cn": "我们通过删除和交换相邻层，揭示了大型语言模型的非凡鲁棒性。实验表明，即使不进行微调，这些操作也能保持模型72-95%的预测准确性，且层数越多的模型鲁棒性越强。基于层级干预的实验结果，我们推测所有模型都经历了四个普遍的推理阶段：解标记化、特征工程、预测集成和残差锐化。首先，模型整合局部信息，提升原始标记至高级上下文表示；随后，对任务和实体特定特征进行迭代优化；接着，模型后半部分经历相变，隐藏表示与词汇空间对齐；最后，通过消除过时特征，最后一层精炼了后续标记的分布，减少了预测中的噪声。",
    "title_cn": "大型语言模型（LLMs）展现出惊人的鲁棒性，其推理过程究竟经历了哪些阶段？",
    "tags": [
      "LLM理论\n\n这篇论文的摘要主要探讨了大型语言模型（LLM）的内部结构和鲁棒性，通过实验分析了模型层级结构的变化对模型性能的影响，并提出了模型推理的四个普遍阶段。这些内容更偏向于对LLM理论层面的研究和理解，因此应归类为LLM理论。",
      "",
      "模型鲁棒性"
    ]
  },
  {
    "title": "The Model Arena for Cross-lingual Sentiment Analysis: A Comparative Study in the Era of Large Language Models",
    "submit_datetime": "2024年06月27日",
    "abstract": "Sentiment analysis serves as a pivotal component in Natural Language Processing (NLP). Advancements in multilingual pre-trained models such as XLM-R and mT5 have contributed to the increasing interest in cross-lingual sentiment analysis. The recent emergence in Large Language Models (LLM) has significantly advanced general NLP tasks, however, the capability of such LLMs in cross-lingual sentiment analysis has not been fully studied. This work undertakes an empirical analysis to compare the cross-lingual transfer capability of public Small Multilingual Language Models (SMLM) like XLM-R, against English-centric LLMs such as Llama-3, in the context of sentiment analysis across English, Spanish, French and Chinese. Our findings reveal that among public models, SMLMs exhibit superior zero-shot cross-lingual performance relative to LLMs. However, in few-shot cross-lingual settings, public LLMs demonstrate an enhanced adaptive potential. In addition, we observe that proprietary GPT-3.5 and GPT-4 lead in zero-shot cross-lingual capability, but are outpaced by public models in few-shot scenarios.",
    "pdf_link": "https://arxiv.org/abs/2406.19358",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19358v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19358/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19358v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19358/n-shot-plot.png"
      }
    ],
    "abstract_cn": "情感分析在NLP中扮演着核心角色，而多语言预训练模型如XLM-R和mT5的进步和大型语言模型（LLM）的兴起，更是推动了跨语言情感分析的研究热潮。尽管LLM在通用NLP任务中表现出色，但其在跨语言情感分析上的潜力尚未完全挖掘。本研究通过实证分析，对比了公共小型多语言模型（如XLM-R）与以英语为中心的大型模型（如Llama-3）在英语、西班牙语、法语和中文情感分析中的跨语言表现。结果显示，SMLM在零-shot跨语言性能上优于LLM，而在少-shot设置中，LLM则展现出更强的适应性。此外，专有模型GPT-3.5和GPT-4虽在零-shot跨语言能力上领先，但在少-shot情况下，公共模型表现更佳。",
    "title_cn": "大型语言模型时代下的跨语言情感分析：一场模型间的较量研究",
    "tags": [
      "LLM应用\n\n这篇论文主要探讨了大型语言模型（LLM）在跨语言情感分析中的应用和性能比较。研究通过对比不同规模和类型的模型（如XLM-R、mT5、Llama-3等）在多种语言（英语、西班牙语、法语和中文）的情感分析任务中的表现，分析了它们在零-shot和少-shot设置下的性能差异。这表明了LLM在特定应用场景下的潜力和局限性，属于LLM应用的范畴。",
      "",
      "情感分析"
    ]
  },
  {
    "title": "DiVERT: Distractor Generation with Variational Errors Represented as Text for Math Multiple-choice Questions",
    "submit_datetime": "2024年06月27日",
    "abstract": "High-quality distractors are crucial to both the assessment and pedagogical value of multiple-choice questions (MCQs), where manually crafting ones that anticipate knowledge deficiencies or misconceptions among real students is difficult. Meanwhile, automated distractor generation, even with the help of large language models (LLMs), remains challenging for subjects like math. It is crucial to not only identify plausible distractors but also understand the error behind them. In this paper, we introduce DiVERT (Distractor Generation with Variational Errors Represented as Text), a novel variational approach that learns an interpretable representation of errors behind distractors in math MCQs. Through experiments on a real-world math MCQ dataset with 1,434 questions used by hundreds of thousands of students, we show that DiVERT, despite using a base open-source LLM with 7B parameters, outperforms state-of-the-art approaches using GPT-4o on downstream distractor generation. We also conduct a human evaluation with math educators and find that DiVERT leads to error labels that are of comparable quality to human-authored ones.",
    "pdf_link": "https://arxiv.org/abs/2406.19356",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19356v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19356/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19356v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19356/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19356v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19356/x3.png"
      }
    ],
    "abstract_cn": "在多选题（MCQs）中，高质量的干扰项对于评估和教学至关重要，但手动制作能准确反映学生知识漏洞或误解的干扰项实属不易。即便借助大型语言模型（LLMs），自动生成数学题的干扰项依旧充满挑战。关键在于，我们不仅要创造出看似合理的干扰项，还需洞察其背后的错误逻辑。本文推出的DiVERT（Distractor Generation with Variational Errors Represented as Text），采用了一种创新的变分方法，旨在为数学MCQs中的干扰项错误提供可解释的表示。实验基于一个包含1,434个问题的真实数学MCQ数据集，该数据集曾服务于数十万学生，结果显示，尽管DiVERT所依托的是一个基础的开源LLM，拥有70亿参数，但在干扰项生成方面，它超越了依赖GPT-4o的顶尖方法。此外，通过数学教育者的评估，我们发现DiVERT生成的错误标签质量与人工编写的相媲美。",
    "title_cn": "DiVERT：数学多选题中，以文本形式呈现变分误差的干扰项生成技术",
    "tags": [
      "LLM应用\n\n理由：这篇论文介绍了一种名为DiVERT的新方法，用于自动生成数学多选题中的干扰项，并提供了可解释的错误表示。该方法利用了大型语言模型（LLMs），并展示了在实际数据集上的有效性。这种方法的应用性质明显，因为它专注于解决实际问题（即生成高质量的干扰项），并且是在现有的LLM技术基础上进行创新。因此，它属于LLM应用类别。",
      "",
      ""
    ]
  },
  {
    "title": "IndoToxic2024: A Demographically-Enriched Dataset of Hate Speech and Toxicity Types for Indonesian Language",
    "submit_datetime": "2024年06月27日",
    "abstract": "Hate speech poses a significant threat to social harmony. Over the past two years, Indonesia has seen a ten-fold increase in the online hate speech ratio, underscoring the urgent need for effective detection mechanisms. However, progress is hindered by the limited availability of labeled data for Indonesian texts. The condition is even worse for marginalized minorities, such as Shia, LGBTQ, and other ethnic minorities because hate speech is underreported and less understood by detection tools. Furthermore, the lack of accommodation for subjectivity in current datasets compounds this issue. To address this, we introduce IndoToxic2024, a comprehensive Indonesian hate speech and toxicity classification dataset. Comprising 43,692 entries annotated by 19 diverse individuals, the dataset focuses on texts targeting vulnerable groups in Indonesia, specifically during the hottest political event in the country: the presidential election. We establish baselines for seven binary classification tasks, achieving a macro-F1 score of 0.78 with a BERT model (IndoBERTweet) fine-tuned for hate speech classification. Furthermore, we demonstrate how incorporating demographic information can enhance the zero-shot performance of the large language model, gpt-3.5-turbo. However, we also caution that an overemphasis on demographic information can negatively impact the fine-tuned model performance due to data fragmentation.",
    "pdf_link": "https://arxiv.org/abs/2406.19349",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19349v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19349/divisive_update.drawio.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19349v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19349/dist.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19349v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19349/religion.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19349v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19349/toxicity_perfs.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19349v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19349/gpt-demo-domicile-heatmap.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19349v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19349/indo-demo-agama-heatmap.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19349v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19349/indo-topic-status_pekerjaan-heatmap.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19349v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19349/synthgen.drawio.png"
      }
    ],
    "abstract_cn": "仇恨言论严重威胁社会和谐，印度尼西亚过去两年在线仇恨言论激增十倍，急需有效检测机制。但因缺乏印尼语文本标注数据，进展受阻。特别是对于什叶派、LGBTQ等少数群体，仇恨言论常被忽视，检测工具也难以理解。现有数据集对主观性的忽视更添难题。为此，我们推出IndoToxic2024数据集，包含43,692条针对印尼弱势群体的文本，由19位不同个体标注，特别关注总统选举期间的仇恨言论。我们为七个二元分类任务设定了基准，使用微调的IndoBERTweet模型达到0.78的宏观F1分数。我们还展示了如何通过整合人口统计信息提升gpt-3.5-turbo模型的零样本性能，但同时警告，过度依赖人口统计信息可能导致数据碎片化，影响微调模型的性能。",
    "title_cn": "IndoToxic2024：印尼语言仇恨言论与毒性类型的人口统计学丰富数据集",
    "tags": [
      "Agent\n\n理由：这篇论文主要关注的是开发和评估一个针对印尼语的仇恨言论检测系统，其中包括创建新的数据集（IndoToxic2024）和使用微调的模型（IndoBERTweet）以及gpt-3.5-turbo模型来提升检测性能。这个工作更侧重于应用现有的技术（如BERT和GPT-3.5）来解决特定的问题（仇恨言论检测），并且涉及到了模型的微调和数据集的构建，这些都是Agent类工作的特点，即利用现有技术解决实际问题。因此，将其归类为Agent更为合适。",
      "社交媒体",
      "仇恨言论检测"
    ]
  },
  {
    "title": "Jump Starting Bandits with LLM-Generated Prior Knowledge",
    "submit_datetime": "2024年06月27日",
    "abstract": "We present substantial evidence demonstrating the benefits of integrating Large Language Models (LLMs) with a Contextual Multi-Armed Bandit framework. Contextual bandits have been widely used in recommendation systems to generate personalized suggestions based on user-specific contexts. We show that LLMs, pre-trained on extensive corpora rich in human knowledge and preferences, can simulate human behaviours well enough to jump-start contextual multi-armed bandits to reduce online learning regret. We propose an initialization algorithm for contextual bandits by prompting LLMs to produce a pre-training dataset of approximate human preferences for the bandit. This significantly reduces online learning regret and data-gathering costs for training such models. Our approach is validated empirically through two sets of experiments with different bandit setups: one which utilizes LLMs to serve as an oracle and a real-world experiment utilizing data from a conjoint survey experiment.",
    "pdf_link": "https://arxiv.org/abs/2406.19317",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19317v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19317/pre_train.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19317v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19317/online.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19317v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19317/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19317v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19317/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19317v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19317/x3.png"
      }
    ],
    "abstract_cn": "我们展示了将大型语言模型（LLMs）与情境多臂老虎机框架结合的显著优势。情境多臂老虎机在推荐系统中广泛应用，能根据用户情境提供个性化建议。我们发现，通过丰富的人类知识与偏好预训练的LLMs，能精准模拟人类行为，有效启动情境多臂老虎机，降低在线学习遗憾。我们提出了一种新的初始化算法，利用LLMs生成近似人类偏好的预训练数据集，大幅减少了在线学习遗憾及数据收集成本。通过两组实验，我们的方法得到了验证：一组实验中LLMs作为预言机，另一组则使用了来自联合调查实验的真实数据。",
    "title_cn": "借助LLM生成的先验知识，快速启动多臂老虎机策略",
    "tags": [
      "Agent\n\n理由：这篇论文探讨了如何将大型语言模型（LLMs）与情境多臂老虎机框架结合，以模拟人类行为并优化推荐系统。这种结合涉及到创建一个能够根据用户情境做出决策的智能体（Agent），该智能体利用LLMs来生成近似人类偏好的预训练数据集，从而减少在线学习遗憾和数据收集成本。因此，这篇论文的内容更符合Agent分类，因为它涉及到了智能体的创建和应用。",
      "推荐系统",
      "在线学习"
    ]
  },
  {
    "title": "MCNC: Manifold Constrained Network Compression",
    "submit_datetime": "2024年06月27日",
    "abstract": "The outstanding performance of large foundational models across diverse tasks-from computer vision to speech and natural language processing-has significantly increased their demand. However, storing and transmitting these models pose significant challenges due to their massive size (e.g., 350GB for GPT-3). Recent literature has focused on compressing the original weights or reducing the number of parameters required for fine-tuning these models. These compression methods typically involve constraining the parameter space, for example, through low-rank reparametrization (e.g., LoRA) or quantization (e.g., QLoRA) during model training. In this paper, we present MCNC as a novel model compression method that constrains the parameter space to low-dimensional pre-defined and frozen nonlinear manifolds, which effectively cover this space. Given the prevalence of good solutions in over-parameterized deep neural networks, we show that by constraining the parameter space to our proposed manifold, we can identify high-quality solutions while achieving unprecedented compression rates across a wide variety of tasks. Through extensive experiments in computer vision and natural language processing tasks, we demonstrate that our method, MCNC, significantly outperforms state-of-the-art baselines in terms of compression, accuracy, and/or model reconstruction time.",
    "pdf_link": "https://arxiv.org/abs/2406.19301",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19301v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19301/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19301v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19301/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19301v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19301/x3.png"
      }
    ],
    "abstract_cn": "大型基础模型在多样的任务中表现卓越，从计算机视觉到语音和自然语言处理，这大大增加了对其的需求。然而，由于其庞大的体积（如GPT-3的350GB），存储和传输这些模型面临巨大挑战。近期研究聚焦于通过压缩原始权重或减少微调所需参数来简化这些模型。这些方法通常通过限制参数空间，例如采用低秩重参数化（LoRA）或量化（QLoRA）技术来实现。本文中，我们提出了一种名为MCNC的新型压缩方法，它将参数空间约束在预设的低维非线性流形上，这些流形是冻结的，能有效覆盖整个空间。鉴于深度神经网络中过度参数化带来的良好解决方案的普遍性，我们发现通过将参数空间限制在我们提出的流形上，不仅能在多种任务中实现前所未有的压缩率，还能找到高质量的解决方案。通过在计算机视觉和自然语言处理任务上的广泛实验，我们展示了MCNC方法在压缩、准确性和模型重建时间方面均显著超越了现有技术水平。",
    "title_cn": "MCNC：流形约束下的网络压缩技术",
    "tags": [
      "LLM理论\n\n理由：这篇论文主要探讨了大型基础模型（如LLM）的压缩方法，提出了一种名为MCNC的新型压缩技术。这种技术通过将参数空间约束在预设的低维非线性流形上来实现模型压缩。论文的研究重点在于理论层面的模型压缩和优化，而不是具体的应用场景或Agent的行为，也不是RAG（Retrieval-Augmented Generation）相关的研究。因此，它更符合LLM理论的分类。",
      "计算机视觉",
      ""
    ]
  },
  {
    "title": "PhysioLLM: Supporting Personalized Health Insights with Wearables and Large Language Models",
    "submit_datetime": "2024年06月27日",
    "abstract": "We present PhysioLLM, an interactive system that leverages large language models (LLMs) to provide personalized health understanding and exploration by integrating physiological data from wearables with contextual information. Unlike commercial health apps for wearables, our system offers a comprehensive statistical analysis component that discovers correlations and trends in user data, allowing users to ask questions in natural language and receive generated personalized insights, and guides them to develop actionable goals. As a case study, we focus on improving sleep quality, given its measurability through physiological data and its importance to general well-being. Through a user study with 24 Fitbit watch users, we demonstrate that PhysioLLM outperforms both the Fitbit App alone and a generic LLM chatbot in facilitating a deeper, personalized understanding of health data and supporting actionable steps toward personal health goals.",
    "pdf_link": "https://arxiv.org/abs/2406.19283",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19283v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19283/overview.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19283v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19283/pipeline.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19283v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19283/protocol.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19283v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19283/boxplot.png"
      }
    ],
    "abstract_cn": "我们推出了PhysioLLM，这是一个交互式系统，它利用LLMs整合可穿戴设备的生理数据与上下文信息，为用户提供个性化的健康洞察。与市面上的健康应用不同，PhysioLLM具备全面的统计分析功能，能揭示用户数据中的关联与趋势，使用户能以自然语言提问并获得定制化的健康建议，帮助他们设定并达成个人健康目标。我们以改善睡眠质量为例，展示了PhysioLLM如何通过生理数据量化睡眠并提升整体福祉。在一项包含24名Fitbit用户的研究中，PhysioLLM在深化个性化健康理解和支持实现个人健康目标方面，显著优于Fitbit应用和通用LLM聊天机器人。",
    "title_cn": "PhysioLLM：结合可穿戴设备与大型语言模型，助力个性化健康洞察",
    "tags": [
      "LLM应用\n\n理由：这篇论文介绍了一个名为PhysioLLM的系统，该系统利用大型语言模型（LLMs）来整合和分析可穿戴设备的生理数据，并提供个性化的健康洞察。这个系统展示了LLMs在实际应用中的能力，特别是在健康领域的应用，通过自然语言处理技术帮助用户理解和改善他们的健康状况。因此，这篇论文属于LLM应用类别。",
      "健康管理",
      "可穿戴设备"
    ]
  },
  {
    "title": "AutoPureData: Automated Filtering of Web Data for LLM Fine-tuning",
    "submit_datetime": "2024年06月27日",
    "abstract": "Up-to-date and reliable Large Language Models (LLMs) are consistently sought after. Typically, LLMs are trained on a fixed dataset and then deployed. However, the training data continually becomes outdated. Enable automatic training of AI using web data involves significant concerns regarding data quality and safety due to bias, spam, and other unsafe or unwanted text. Pure data is essential for producing reliable models. Training a model on impure data may result in undesirable outcomes. This research proposes a system that collects web data and automatically filters out unwanted text with the assistance of existing trusted AI models. In the experiment, a small sample of web data was collected and filtered, demonstrating the system's effectiveness in purifying the data.",
    "pdf_link": "https://arxiv.org/abs/2406.19271",
    "graphs": [],
    "abstract_cn": "最新可靠的大型语言模型（LLMs）一直是研究的热点。这些模型通常基于固定数据集进行训练和部署，但数据集会随时间而过时。使用网络数据自动训练AI时，数据质量和安全性成为关键问题，因为网络数据中可能包含偏见、垃圾信息等不安全或不受欢迎的内容。纯净的数据是构建可靠模型的基石。若在污染的数据上训练，模型可能会产生不良结果。本研究提出了一种系统，它能够收集网络数据，并借助现有的可信AI模型自动过滤掉不受欢迎的内容。实验中，通过处理一小部分网络数据，该系统展示了其在数据净化方面的有效性。",
    "title_cn": "AutoPureData：为大型语言模型微调自动化筛选网络数据",
    "tags": [
      "LLM应用\n\n这篇论文主要讨论了如何通过系统收集网络数据，并利用现有的可信AI模型自动过滤掉不受欢迎的内容，以保证数据的质量和安全性，这对于构建可靠的大型语言模型（LLMs）至关重要。因此，这篇论文的内容更偏向于LLM的应用层面，即如何处理和优化数据以支持LLM的训练和部署。",
      "数据净化",
      "人工智能"
    ]
  },
  {
    "title": "Enhancing Video-Language Representations with Structural Spatio-Temporal Alignment",
    "submit_datetime": "2024年06月27日",
    "abstract": "While pre-training large-scale video-language models (VLMs) has shown remarkable potential for various downstream video-language tasks, existing VLMs can still suffer from certain commonly seen limitations, e.g., coarse-grained cross-modal aligning , under-modeling of temporal dynamics, detached video-language view. In this work, we target enhancing VLMs with a fine-grained structural spatio-temporal alignment learning method (namely Finsta). First of all, we represent the input texts and videos with fine-grained scene graph (SG) structures, both of which are further unified into a holistic SG (HSG) for bridging two modalities. Then, an SG-based framework is built, where the textual SG (TSG) is encoded with a graph Transformer, while the video dynamic SG (DSG) and the HSG are modeled with a novel recurrent graph Transformer for spatial and temporal feature propagation. A spatial-temporal Gaussian differential graph Transformer is further devised to strengthen the sense of the changes in objects across spatial and temporal dimensions. Next, based on the fine-grained structural features of TSG and DSG, we perform object-centered spatial alignment and predicate-centered temporal alignment respectively, enhancing the video-language grounding in both the spatiality and temporality. We design our method as a plug&play system, which can be integrated into existing well-trained VLMs for further representation augmentation, without training from scratch or relying on SG annotations in downstream applications. On 6 representative VL modeling tasks over 12 datasets in both standard and long-form video scenarios, Finsta consistently improves the existing 13 strong-performing VLMs persistently, and refreshes the current state-of-the-art end task performance significantly in both the fine-tuning and zero-shot settings.",
    "pdf_link": "https://arxiv.org/abs/2406.19255",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19255v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19255/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19255v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19255/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19255v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19255/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19255v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19255/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19255v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19255/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19255v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19255/finsta-register.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19255v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19255/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19255v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19255/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19255v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19255/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19255v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19255/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19255v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19255/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19255v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19255/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19255v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19255/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19255v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19255/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19255v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19255/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19255v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19255/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19255v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19255/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19255v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19255/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19255v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19255/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19255v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19255/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19255v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19255/x20.png"
      }
    ],
    "abstract_cn": "尽管大规模视频-语言模型（VLMs）预训练在多种下游任务中显示出巨大潜力，但现有模型仍存在诸如粗粒度跨模态对齐、时间动态建模不足等问题。为此，我们提出了一种名为Finsta的细粒度结构化时空对齐学习方法，旨在提升VLMs性能。首先，我们采用细粒度场景图（SG）结构来表示文本和视频，并将它们整合成一个整体SG（HSG）以促进模态间的连接。随后，我们构建了一个基于SG的框架，其中文本SG（TSG）通过图Transformer编码，而视频动态SG（DSG）和HSG则通过创新的循环图Transformer处理，以实现空间和时间特征的有效传播。此外，我们还开发了时空高斯微分图Transformer，以增强模型对物体时空变化的感知。基于TSG和DSG的精细结构特征，我们分别进行了以物体为中心的空间对齐和以谓词为中心的时间对齐，从而加强了视频与语言在空间和时间维度上的联系。我们的方法设计为即插即用系统，可无缝集成到现有VLMs中，无需重新训练或依赖下游任务的SG注释，即可实现性能提升。在涵盖标准和长格式视频的12个数据集上的6项代表性VL建模任务中，Finsta不仅持续提升了13个表现优异的VLMs，还在微调和零-shot设置下显著刷新了当前任务性能的最新记录。",
    "title_cn": "利用结构化时空对齐提升视频与语言的融合表达",
    "tags": [
      "RAG\n\n理由：这篇论文主要介绍了一种名为Finsta的新方法，用于改进大规模视频-语言模型（VLMs）的性能，特别是在细粒度结构化时空对齐学习方面。这种方法通过创新的图Transformer结构和时空对齐策略，旨在解决现有VLMs在跨模态对齐和时间动态建模方面的不足。由于论文的核心贡献在于提出了一种新的模型架构和学习方法，以增强模型的性能和应用能力，因此它更适合归类为RAG（Representation and Alignment in Generative models），即在生成模型中的表示和校准技术。这与Agent（代理或智能体）、LLM应用（大型语言模型的应用）或LLM理论（大型语言模型的理论研究）的分类不符，因为这些分类更多关注的是模型的应用、理论基础或智能体的交互行为，而不是模型内部的结构和学习方法的改进。",
      "视频处理",
      ""
    ]
  },
  {
    "title": "Revealing Fine-Grained Values and Opinions in Large Language Models",
    "submit_datetime": "2024年06月27日",
    "abstract": "Uncovering latent values and opinions in large language models (LLMs) can help identify biases and mitigate potential harm. Recently, this has been approached by presenting LLMs with survey questions and quantifying their stances towards morally and politically charged statements. However, the stances generated by LLMs can vary greatly depending on how they are prompted, and there are many ways to argue for or against a given position. In this work, we propose to address this by analysing a large and robust dataset of 156k LLM responses to the 62 propositions of the Political Compass Test (PCT) generated by 6 LLMs using 420 prompt variations. We perform coarse-grained analysis of their generated stances and fine-grained analysis of the plain text justifications for those stances. For fine-grained analysis, we propose to identify tropes in the responses: semantically similar phrases that are recurrent and consistent across different prompts, revealing patterns in the text that a given LLM is prone to produce. We find that demographic features added to prompts significantly affect outcomes on the PCT, reflecting bias, as well as disparities between the results of tests when eliciting closed-form vs. open domain responses. Additionally, patterns in the plain text rationales via tropes show that similar justifications are repeatedly generated across models and prompts even with disparate stances.",
    "pdf_link": "https://arxiv.org/abs/2406.19238",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19238v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19238/fig1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19238v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19238/closed_Llama-2-13b-chat-hf.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19238v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19238/closed_Meta-Llama-3-8B-Instruct.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19238v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19238/closed_Mistral-7B-Instruct-v0.2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19238v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19238/closed_Mixtral-8x7B-Instruct-v0.1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19238v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19238/closed_OLMo-7B-Instruct.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19238v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19238/closed_zephyr-7b-beta.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19238v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19238/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19238v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19238/econ_closed_regression_adj.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19238v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19238/pol_closed_regression_adj.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19238v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19238/Meta-Llama-3-8B-Instruct_open_closed.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19238v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19238/Meta-Llama-3-8B-Instruct_political_orientation_far_right_open_closed.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19238v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19238/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19238v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19238/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19238v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19238/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19238v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19238/tropes_model_count.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19238v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19238/Meta-Llama-3-8B-Instruct_bubble_chart_30.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19238v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19238/Mistral-7B-Instruct-v0.2_bubble_chart_30.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19238v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19238/Mixtral-8x7B-Instruct-v0.1_bubble_chart_30.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19238v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19238/zephyr-7b-beta_bubble_chart_30.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19238v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19238/OLMo-7B-Instruct_bubble_chart_30.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19238v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19238/Llama-2-13b-chat-hf_bubble_chart_30.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19238v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19238/closed_Llama-2-13b-chat-hf.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19238v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19238/closed_Meta-Llama-3-8B-Instruct.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19238v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19238/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19238v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19238/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19238v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19238/closed_OLMo-7B-Instruct.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19238v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19238/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19238v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19238/Llama-2-13b-chat-hf_political_orientation_far_left_open_closed.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19238v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19238/Llama-2-13b-chat-hf_political_orientation_far_right_open_closed.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19238v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19238/Mistral-7B-Instruct-v0.2_political_orientation_far_left_open_closed.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19238v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19238/Mistral-7B-Instruct-v0.2_political_orientation_far_right_open_closed.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19238v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19238/Mixtral-8x7B-Instruct-v0.1_political_orientation_far_left_open_closed.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19238v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19238/Mixtral-8x7B-Instruct-v0.1_political_orientation_far_right_open_closed.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19238v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19238/zephyr-7b-beta_political_orientation_far_left_open_closed.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19238v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19238/zephyr-7b-beta_political_orientation_far_right_open_closed.png"
      }
    ],
    "abstract_cn": "探索大型语言模型（LLMs）中的隐含价值和观点，有助于揭示偏见并减少潜在风险。近期研究通过向LLMs提出调查问题，并量化其对道德与政治敏感议题的立场来实现这一目标。然而，LLMs的立场因提示方式差异巨大，且支持或反对某一观点的论点多样。本研究通过分析由6个LLMs使用420种提示变体生成的156k个对政治指南针测试（PCT）62个命题的响应，来深入探讨此问题。我们不仅进行了立场的粗粒度分析，还对支持这些立场的纯文本理由进行了细粒度分析。在细粒度分析中，我们识别了响应中的常见修辞手法——这些在不同提示中反复出现且语义相似的短语，揭示了LLMs倾向于产生的特定文本模式。研究发现，提示中加入的人口统计特征显著影响PCT结果，这不仅反映了偏见，还揭示了在引发封闭形式与开放领域响应时测试结果的差异。此外，通过修辞手法分析纯文本理由，我们发现即使在立场不同的情况下，模型和提示间也会重复生成相似的理由。",
    "title_cn": "探究大型语言模型中微妙的价值与观点",
    "tags": [
      "LLM理论\n\n理由：这篇论文主要探讨了大型语言模型（LLMs）中的隐含价值和观点，以及如何通过分析模型对特定提示的响应来揭示和理解这些模型中的偏见和潜在风险。研究通过详细的实验和分析，探讨了LLMs对道德与政治敏感议题的立场，并分析了这些立场如何受到提示方式的影响。此外，研究还深入分析了模型响应中的修辞手法，这些都是在理论层面上对LLMs的理解和分析。因此，这篇论文更适合归类于LLM理论，因为它关注的是LLMs的内部机制和理论分析，而不是具体的应用或Agent的行为。",
      "政治分析",
      "社会科学研究"
    ]
  },
  {
    "title": "Aligning Teacher with Student Preferences for Tailored Training Data Generation",
    "submit_datetime": "2024年06月27日",
    "abstract": "Large Language Models (LLMs) have shown significant promise as copilots in various tasks. Local deployment of LLMs on edge devices is necessary when handling privacy-sensitive data or latency-sensitive tasks. The computational constraints of such devices make direct deployment of powerful large-scale LLMs impractical, necessitating the Knowledge Distillation from large-scale models to lightweight models. Lots of work has been done to elicit diversity and quality training examples from LLMs, but little attention has been paid to aligning teacher instructional content based on student preferences, akin to \"responsive teaching\" in pedagogy. Thus, we propose ARTE, dubbed Aligning TeacheR with StudenT PreferencEs, a framework that aligns the teacher model with student preferences to generate tailored training examples for Knowledge Distillation. Specifically, we elicit draft questions and rationales from the teacher model, then collect student preferences on these questions and rationales using students' performance with in-context learning as a proxy, and finally align the teacher model with student preferences. In the end, we repeat the first step with the aligned teacher model to elicit tailored training examples for the student model on the target task. Extensive experiments on academic benchmarks demonstrate the superiority of ARTE over existing instruction-tuning datasets distilled from powerful LLMs. Moreover, we thoroughly investigate the generalization of ARTE, including the generalization of fine-tuned student models in reasoning ability and the generalization of aligned teacher models to generate tailored training data across tasks and students. In summary, our contributions lie in proposing a novel framework for tailored training example generation, demonstrating its efficacy in experiments, and investigating the generalization of both student & aligned teacher models in ARTE.",
    "pdf_link": "https://arxiv.org/abs/2406.19227",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19227v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19227/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19227v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19227/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19227v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19227/x3.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）作为副驾驶，在多种任务中展现出显著潜力。在处理隐私或延迟敏感任务时，将LLMs部署在边缘设备上至关重要。然而，这些设备的计算限制使得直接部署大规模LLMs变得不切实际，因此需要进行知识蒸馏，将大规模模型转化为轻量级模型。尽管已有许多研究致力于从LLMs中提取高质量和多样化的训练示例，但根据学生偏好调整教师教学内容的研究却鲜有涉及，这与教育学中的“响应式教学”理念相似。为此，我们提出了ARTE（Aligning TeacheR with StudenT PreferencEs），这是一个框架，旨在根据学生偏好调整教师模型，以生成定制的训练示例用于知识蒸馏。我们首先从教师模型中提取问题和理由，然后通过学生在情境学习中的表现来收集他们对这些问题的偏好，并据此调整教师模型。最后，我们使用调整后的教师模型重复第一步，为学生模型在目标任务上生成定制的训练示例。在多个学术基准上的实验表明，ARTE在性能上超越了现有的从强大LLMs蒸馏出的指令调整数据集。我们还深入探讨了ARTE的泛化能力，包括微调后的学生模型在推理能力上的泛化，以及调整后的教师模型在不同任务和学生中生成定制训练数据的能力。总的来说，我们的贡献在于提出了一种创新的定制训练示例生成框架，并通过实验验证了其有效性，同时深入研究了ARTE中学生和教师模型的泛化能力。",
    "title_cn": "根据学生偏好定制教师，以生成个性化的训练数据",
    "tags": [
      "Agent\n\n理由：这篇论文主要讨论了如何通过一个框架（ARTE）来调整教师模型以适应学生模型的偏好，从而生成定制的训练示例用于知识蒸馏。这个过程涉及到教师模型和学生模型之间的交互和适应，类似于Agent的行为，即根据环境和目标调整自己的策略和行为。此外，论文中提到的“响应式教学”理念也与Agent的自主性和适应性相呼应。因此，这篇论文更适合归类到Agent分类中。",
      "边缘计算",
      "教育技术"
    ]
  },
  {
    "title": "T-FREE: Tokenizer-Free Generative LLMs via Sparse Representations for Memory-Efficient Embeddings",
    "submit_datetime": "2024年06月27日",
    "abstract": "Tokenizers are crucial for encoding information in Large Language Models, but their development has recently stagnated, and they contain inherent weaknesses. Major limitations include computational overhead, ineffective vocabulary use, and unnecessarily large embedding and head layers. Additionally, their performance is biased towards a reference corpus, leading to reduced effectiveness for underrepresented languages.\n  To remedy these issues, we propose T-FREE, which directly embeds words through sparse activation patterns over character triplets, and does not require a reference corpus. T-FREE inherently exploits morphological similarities and allows for strong compression of embedding layers. In our exhaustive experimental evaluation, we achieve competitive downstream performance with a parameter reduction of more than 85% on these layers. Further, T-FREE shows significant improvements in cross-lingual transfer learning.",
    "pdf_link": "https://arxiv.org/abs/2406.19223",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19223v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19223/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19223v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19223/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19223v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19223/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19223v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19223/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19223v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19223/loss_token.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19223v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19223/loss_trigram.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19223v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19223/mem_token.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19223v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19223/mem_trigram.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19223v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19223/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19223v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19223/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19223v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19223/top5_wordlength.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19223v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19223/top10_wordlength.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19223v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19223/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19223v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19223/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19223v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19223/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19223v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19223/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19223v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19223/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19223v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19223/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19223v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19223/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19223v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19223/x14.png"
      }
    ],
    "abstract_cn": "在大型语言模型中，Tokenizers 对信息编码至关重要，但近期发展停滞，且存在固有缺陷，如计算负担重、词汇使用效率低、嵌入层和头部层过于庞大。此外，它们的表现受限于参考语料库，对少数语言的支持不足。为此，我们提出了 T-FREE，一种通过字符三元组的稀疏激活直接嵌入单词的方法，无需依赖参考语料库。T-FREE 利用形态相似性，大幅压缩嵌入层，实验中参数减少了 85% 以上，同时保持了竞争性的下游性能。T-FREE 在跨语言迁移学习方面也展现出显著的进步。",
    "title_cn": "T-FREE：利用稀疏表示技术，打造无需分词器的生成型大型语言模型，实现内存高效嵌入。",
    "tags": [
      "LLM理论\n\n理由：这篇论文主要探讨了大型语言模型中的Tokenizers问题，并提出了一种新的方法T-FREE来解决这些问题。这种方法涉及到模型的内部结构和运作机制，特别是嵌入层的优化，这属于对LLM理论层面的深入研究。因此，将其归类为LLM理论。",
      "",
      "机器学习"
    ]
  },
  {
    "title": "Averaging log-likelihoods in direct alignment",
    "submit_datetime": "2024年06月27日",
    "abstract": "To better align Large Language Models (LLMs) with human judgment, Reinforcement Learning from Human Feedback (RLHF) learns a reward model and then optimizes it using regularized RL. Recently, direct alignment methods were introduced to learn such a fine-tuned model directly from a preference dataset without computing a proxy reward function. These methods are built upon contrastive losses involving the log-likelihood of (dis)preferred completions according to the trained model. However, completions have various lengths, and the log-likelihood is not length-invariant. On the other side, the cross-entropy loss used in supervised training is length-invariant, as batches are typically averaged token-wise. To reconcile these approaches, we introduce a principled approach for making direct alignment length-invariant. Formally, we introduce a new averaging operator, to be composed with the optimality operator giving the best policy for the underlying RL problem. It translates into averaging the log-likelihood within the loss. We empirically study the effect of such averaging, observing a trade-off between the length of generations and their scores.",
    "pdf_link": "https://arxiv.org/abs/2406.19188",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19188v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19188/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19188v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19188/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19188v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19188/x3.png"
      }
    ],
    "abstract_cn": "为了使大型语言模型更贴合人类判断，我们采用了基于人类反馈的强化学习（RLHF），先构建奖励模型，再通过正则化强化学习优化它。最近，直接对齐方法崭露头角，它们能直接从偏好数据集训练出精细调整的模型，无需中间的代理奖励函数。这些方法依赖于对比损失，该损失基于模型对偏好完成情况的log-likelihood。但完成情况长度不一，log-likelihood并非长度不变。相比之下，监督学习中的交叉熵损失是长度不变的，因为它按token平均批次。为了融合这两种方法，我们提出了一种原则性的方法，确保直接对齐的长度不变性。我们引入了一个新的平均算子，与最优性算子结合，为底层RL问题提供最佳策略，这体现在损失中对log-likelihood的平均。实验表明，这种平均方法在生成长度与得分之间找到了平衡点。",
    "title_cn": "直接对齐中的对数似然平均化",
    "tags": [
      "LLM理论\n\n这篇论文探讨了如何改进大型语言模型（LLM）以更好地符合人类判断，具体通过引入一种新的方法来确保直接对齐的长度不变性。这种方法结合了基于人类反馈的强化学习（RLHF）和直接对齐技术，旨在解决模型在处理不同长度文本时的性能问题。论文中提出的新平均算子和最优性算子的结合，为RL问题提供了最佳策略，并在实验中展示了其在生成长度与得分之间的平衡效果。这一研究属于LLM理论范畴，因为它关注的是模型内部机制的优化和理论改进，而不是模型的具体应用或Agent的设计。",
      "人工智能",
      "机器学习"
    ]
  },
  {
    "title": "Contrastive Policy Gradient: Aligning LLMs on sequence-level scores in a supervised-friendly fashion",
    "submit_datetime": "2024年06月27日",
    "abstract": "Reinforcement Learning (RL) has been used to finetune Large Language Models (LLMs) using a reward model trained from preference data, to better align with human judgment. The recently introduced direct alignment methods, which are often simpler, more stable, and computationally lighter, can more directly achieve this. However, these approaches cannot optimize arbitrary rewards, and the preference-based ones are not the only rewards of interest for LLMs (eg., unit tests for code generation or textual entailment for summarization, among others). RL-finetuning is usually done with a variation of policy gradient, which calls for on-policy or near-on-policy samples, requiring costly generations. We introduce Contrastive Policy Gradient, or CoPG, a simple and mathematically principled new RL algorithm that can estimate the optimal policy even from off-policy data. It can be seen as an off-policy policy gradient approach that does not rely on important sampling techniques and highlights the importance of using (the right) state baseline. We show this approach to generalize the direct alignment method IPO (identity preference optimization) and classic policy gradient. We experiment with the proposed CoPG on a toy bandit problem to illustrate its properties, as well as for finetuning LLMs on a summarization task, using a learned reward function considered as ground truth for the purpose of the experiments.",
    "pdf_link": "https://arxiv.org/abs/2406.19185",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19185v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19185/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19185v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19185/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19185v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19185/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19185v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19185/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19185v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19185/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19185v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19185/x6.png"
      }
    ],
    "abstract_cn": "强化学习（RL）通过利用基于人类偏好数据的奖励模型，已被用于微调大型语言模型（LLMs），以期更贴合人类判断。新近提出的直接对齐方法，因其简便、稳定且计算负担轻，能更直接地达成目标。然而，这些方法无法针对任意奖励进行优化，且基于偏好的奖励并非LLMs唯一关注的奖励类型（如代码生成的单元测试或摘要的文本蕴含等）。RL微调常采用策略梯度变体，这要求在线或近在线样本，生成成本高昂。我们提出了一种名为对比策略梯度（CoPG）的新型RL算法，它简单且在数学上严谨，能从离线数据中估算出最优策略，无需依赖重要性采样技术，并强调了正确状态基线的重要性。我们通过实验展示了CoPG如何推广直接对齐方法IPO及经典策略梯度，并在一个简单的强盗问题上验证了其特性，同时也在摘要任务上利用学得的奖励函数对LLMs进行了微调，该奖励函数在实验中被视为真实标准。",
    "title_cn": "对比策略梯度：以监督友好的方式，对齐大型语言模型在序列级分数上的表现",
    "tags": [
      "Agent\n\n这篇论文主要讨论了使用强化学习（RL）算法来微调大型语言模型（LLMs），以更好地对齐人类偏好和模型输出。论文提出了一种新的RL算法——对比策略梯度（CoPG），并探讨了其在离线数据上的应用，以及如何优化策略以适应不同的奖励类型。这与Agent的分类相符，因为Agent通常指的是能够根据环境反馈自主学习和调整策略的智能体，而强化学习是实现这一目标的常用方法。此外，论文中的工作涉及到对LLMs的微调和优化，这是Agent行为的一部分，因此归类为Agent。",
      "",
      ""
    ]
  },
  {
    "title": "Annotation Errors and NER: A Study with OntoNotes 5.0",
    "submit_datetime": "2024年06月27日",
    "abstract": "Named Entity Recognition (NER) is a well-studied problem in NLP. However, there is much less focus on studying NER datasets, compared to developing new NER models. In this paper, we employed three simple techniques to detect annotation errors in the OntoNotes 5.0 corpus for English NER, which is the largest available NER corpus for English. Our techniques corrected ~10% of the sentences in train/dev/test data. In terms of entity mentions, we corrected the span and/or type of ~8% of mentions in the dataset, while adding/deleting/splitting/merging a few more. These are large numbers of changes, considering the size of OntoNotes. We used three NER libraries to train, evaluate and compare the models trained with the original and the re-annotated datasets, which showed an average improvement of 1.23% in overall F-scores, with large (>10%) improvements for some of the entity types. While our annotation error detection methods are not exhaustive and there is some manual annotation effort involved, they are largely language agnostic and can be employed with other NER datasets, and other sequence labelling tasks.",
    "pdf_link": "https://arxiv.org/abs/2406.19172",
    "graphs": [],
    "abstract_cn": "命名实体识别（NER）在NLP领域备受关注，但相较于新模型的开发，NER数据集的研究却鲜有人问津。本文中，我们运用三种简便技术，对英语NER最大的语料库OntoNotes 5.0进行了标注错误的检测。这些技术纠正了训练、开发和测试数据中约10%的句子，并对数据集中约8%的实体提及的跨度和/或类型进行了修正，同时进行了一些增删分割合并操作。考虑到OntoNotes的庞大规模，这些修正的影响不容小觑。我们利用三个NER库对原始数据集和重新标注数据集训练的模型进行了训练、评估和比较，发现总体F-score平均提升了1.23%，某些实体类型的提升甚至超过了10%。尽管我们的标注错误检测方法并非无懈可击，且涉及一定程度的手动标注，但它们具有较强的语言通用性，可应用于其他NER数据集及序列标注任务。",
    "title_cn": "OntoNotes 5.0下的研究：探索注释错误对命名实体识别的影响",
    "tags": [
      "LLM应用\n\n理由：这篇论文主要关注的是命名实体识别（NER）任务中的数据集质量问题，并提出了一种改进数据集标注错误的方法。虽然NER是NLP领域的一个具体应用，但论文的核心贡献在于数据集的改进，这对于训练和评估大型语言模型（LLM）在NER任务上的表现具有重要意义。因此，这篇论文更偏向于LLM的应用层面，即如何通过改进数据集来提升LLM在特定任务上的性能。",
      "",
      "数据集标注"
    ]
  },
  {
    "title": "Towards Learning Abductive Reasoning using VSA Distributed Representations",
    "submit_datetime": "2024年06月27日",
    "abstract": "We introduce the Abductive Rule Learner with Context-awareness (ARLC), a model that solves abstract reasoning tasks based on Learn-VRF. ARLC features a novel and more broadly applicable training objective for abductive reasoning, resulting in better interpretability and higher accuracy when solving Raven's progressive matrices (RPM). ARLC allows both programming domain knowledge and learning the rules underlying a data distribution. We evaluate ARLC on the I-RAVEN dataset, showcasing state-of-the-art accuracy across both in-distribution and out-of-distribution (unseen attribute-rule pairs) tests. ARLC surpasses neuro-symbolic and connectionist baselines, including large language models, despite having orders of magnitude fewer parameters. We show ARLC's robustness to post-programming training by incrementally learning from examples on top of programmed knowledge, which only improves its performance and does not result in catastrophic forgetting of the programmed solution. We validate ARLC's seamless transfer learning from a 2x2 RPM constellation to unseen constellations. Our code is available at https://github.com/IBM/abductive-rule-learner-with-context-awareness.",
    "pdf_link": "https://arxiv.org/abs/2406.19121",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19121v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19121/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19121v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19121/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19121v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19121/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19121v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19121/x4.png"
      }
    ],
    "abstract_cn": "我们推出了上下文感知归纳规则学习器（ARLC），这是一种基于Learn-VRF的模型，专门用于解决抽象推理任务。ARLC采用了一种新颖且广泛适用的归纳推理训练目标，显著提升了Raven渐进矩阵（RPM）问题的解决准确性和可解释性。该模型不仅融入了编程领域知识，还能学习数据分布背后的规则。在I-RAVEN数据集上的测试表明，ARLC在分布内外的测试中均达到了业界领先的准确性，超越了参数数量级更大的神经符号和连接主义模型，包括大型语言模型。此外，ARLC通过在编程知识基础上逐步学习示例，展现了强大的编程后训练鲁棒性，不仅提升了性能，还避免了灾难性遗忘。我们还验证了ARLC从2x2 RPM星座到未见星座的无缝迁移学习能力。相关代码已公开在https://github.com/IBM/abductive-rule-learner-with-context-awareness。",
    "title_cn": "利用VSA分布式表示探索溯因推理的学习方法",
    "tags": [
      "Agent\n\n理由：这篇论文介绍了一个名为上下文感知归纳规则学习器（ARLC）的模型，它专门用于解决抽象推理任务，如Raven渐进矩阵（RPM）问题。ARLC不仅融入了编程领域知识，还能学习数据分布背后的规则，并在多个测试中展示了高准确性和鲁棒性。这个模型可以被视为一个智能代理（Agent），因为它能够执行复杂的推理任务，并在不同的环境和数据分布中进行学习和适应。此外，ARLC的特性，如避免灾难性遗忘和无缝迁移学习能力，进一步支持了它作为一个智能代理的分类。",
      "",
      "人工智能"
    ]
  },
  {
    "title": "A Teacher Is Worth A Million Instructions",
    "submit_datetime": "2024年06月27日",
    "abstract": "Large Language Models(LLMs) have shown exceptional abilities, yet training these models can be quite challenging. There is a strong dependence on the quality of data and finding the best instruction tuning set. Further, the inherent limitations in training methods create substantial difficulties to train relatively smaller models with 7B and 13B parameters. In our research, we suggest an improved training method for these models by utilising knowledge from larger models, such as a mixture of experts (8x7B) architectures. The scale of these larger models allows them to capture a wide range of variations from data alone, making them effective teachers for smaller models. Moreover, we implement a novel post-training domain alignment phase that employs domain-specific expert models to boost domain-specific knowledge during training while preserving the model's ability to generalise. Fine-tuning Mistral 7B and 2x7B with our method surpasses the performance of state-of-the-art language models with more than 7B and 13B parameters: achieving up to $7.9$ in MT-Bench and $93.04\\%$ on AlpacaEval.",
    "pdf_link": "https://arxiv.org/abs/2406.19112",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19112v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19112/radar_plot.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19112v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19112/attn.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19112v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19112/dae2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19112v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19112/train_curve.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）虽能力非凡，但其训练过程充满挑战，尤其依赖于高质量数据和最佳指令调整集的选择。训练方法的内在限制使得7B和13B参数的小型模型训练尤为困难。本研究提出了一种创新的训练策略，借鉴了如混合专家（8x7B）架构等大型模型的知识。这些巨型模型能从数据中捕捉广泛变异，成为小型模型的良师。我们还引入了一个独特的后训练领域对齐阶段，通过领域特定专家模型在训练中强化特定领域知识，同时保持模型的泛化能力。应用此方法微调的Mistral 7B和2x7B，在MT-Bench上得分高达7.9，在AlpacaEval上达到93.04%，超越了参数超过7B和13B的顶尖语言模型。",
    "title_cn": "名师一席话，胜读百万书",
    "tags": [
      "LLM理论\n\n这篇论文主要探讨了大型语言模型（LLMs）的训练策略，特别是针对小型模型的训练挑战，并提出了一种创新的训练方法。这种方法包括借鉴大型模型的架构和引入后训练领域对齐阶段，以增强模型在特定领域的性能同时保持泛化能力。这些内容主要涉及LLM的训练理论和方法，因此归类为LLM理论。",
      "",
      "模型训练"
    ]
  },
  {
    "title": "Statements: Universal Information Extraction from Tables with Large Language Models for ESG KPIs",
    "submit_datetime": "2024年06月27日",
    "abstract": "Environment, Social, and Governance (ESG) KPIs assess an organization's performance on issues such as climate change, greenhouse gas emissions, water consumption, waste management, human rights, diversity, and policies. ESG reports convey this valuable quantitative information through tables. Unfortunately, extracting this information is difficult due to high variability in the table structure as well as content. We propose Statements, a novel domain agnostic data structure for extracting quantitative facts and related information. We propose translating tables to statements as a new supervised deep-learning universal information extraction task. We introduce SemTabNet - a dataset of over 100K annotated tables. Investigating a family of T5-based Statement Extraction Models, our best model generates statements which are 82% similar to the ground-truth (compared to baseline of 21%). We demonstrate the advantages of statements by applying our model to over 2700 tables from ESG reports. The homogeneous nature of statements permits exploratory data analysis on expansive information found in large collections of ESG reports.",
    "pdf_link": "https://arxiv.org/abs/2406.19102",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19102v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19102/statement_knowledge_model_vertical.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19102v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19102/text_table_to_statements.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19102v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19102/model_input_output.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19102v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19102/counts_env.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19102v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19102/counts_social.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19102v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19102/counts_gov.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19102v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19102/box-scope1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19102v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19102/box-scope2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19102v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19102/complex_table_relationships.png"
      }
    ],
    "abstract_cn": "环境、社会和治理（ESG）的关键绩效指标（KPIs）评估组织在气候变化、温室气体排放、水资源利用、废物处理、人权、多样性和政策等方面的表现，并通过表格形式在ESG报告中传达这些关键的定量信息。然而，由于表格结构和内容的多样性，提取这些信息颇具挑战。为此，我们创新性地提出了Statements，一种适用于各领域的数据结构，旨在提取定量事实及其相关信息。我们将表格转换为陈述的过程定义为一项新的监督深度学习信息提取任务，并推出了SemTabNet数据集，包含超过10万个标注表格。通过研究一系列基于T5的陈述提取模型，我们发现最佳模型生成的陈述与真实数据的一致性高达82%，远超基线水平的21%。我们通过将该模型应用于2700多份ESG报告中的表格，展示了陈述方法的优势。陈述的统一性使得我们能够对大量ESG报告中的信息进行深入的探索性分析。",
    "title_cn": "声明：借助大型语言模型，我们能从表格中提取通用信息，以支持ESG关键绩效指标的评估。",
    "tags": [
      "LLM应用\n\n这篇论文主要探讨了如何利用深度学习模型，特别是基于T5的模型，从ESG报告中的表格结构中提取关键的定量信息。这种方法涉及将表格转换为一种称为“陈述”的数据结构，并通过监督学习任务来训练模型以提高信息提取的准确性。论文中提到的SemTabNet数据集和模型性能的提升，以及其在实际ESG报告中的应用，都表明了这项工作在实际应用中的价值和潜力。因此，这项研究更符合LLM应用分类，因为它展示了大型语言模型在特定领域（如ESG报告分析）中的实际应用和效果。",
      "ESG报告",
      "数据提取"
    ]
  },
  {
    "title": "STBench: Assessing the Ability of Large Language Models in Spatio-Temporal Analysis",
    "submit_datetime": "2024年06月27日",
    "abstract": "The rapid evolution of large language models (LLMs) holds promise for reforming the methodology of spatio-temporal data mining. However, current works for evaluating the spatio-temporal understanding capability of LLMs are somewhat limited and biased. These works either fail to incorporate the latest language models or only focus on assessing the memorized spatio-temporal knowledge. To address this gap, this paper dissects LLMs' capability of spatio-temporal data into four distinct dimensions: knowledge comprehension, spatio-temporal reasoning, accurate computation, and downstream applications. We curate several natural language question-answer tasks for each category and build the benchmark dataset, namely STBench, containing 13 distinct tasks and over 60,000 QA pairs. Moreover, we have assessed the capabilities of 13 LLMs, such as GPT-4o, Gemma and Mistral. Experimental results reveal that existing LLMs show remarkable performance on knowledge comprehension and spatio-temporal reasoning tasks, with potential for further enhancement on other tasks through in-context learning, chain-of-though prompting, and fine-tuning. The code and datasets of STBench are released on https://github.com/LwbXc/STBench.",
    "pdf_link": "https://arxiv.org/abs/2406.19065",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19065v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19065/overview.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19065v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19065/x1.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）的迅猛发展为时空数据挖掘方法的革新带来了希望。然而，目前对LLMs时空理解能力的评估工作存在局限，往往忽视了最新模型的纳入或仅侧重于记忆知识的评估。为此，本文深入分析了LLMs在处理时空数据方面的四大能力：知识理解、时空推理、精确计算及应用实践，并针对每一维度设计了问答任务，创建了包含13项任务、60,000多对问答的STBench基准数据集。我们评估了包括GPT-4o、Gemma和Mistral在内的13种LLMs，发现它们在知识理解和时空推理上表现卓越，而通过上下文学习、思维链提示和微调，其他任务的性能亦有望提升。STBench的代码和数据集已公开于https://github.com/LwbXc/STBench。",
    "title_cn": "STBench：探究大型语言模型在时空分析领域的实力",
    "tags": [
      "LLM应用\n\n这篇论文主要探讨了大型语言模型（LLMs）在处理时空数据方面的能力，并通过创建STBench基准数据集来评估这些模型在知识理解、时空推理、精确计算及应用实践等方面的表现。这种研究属于对LLMs在特定应用场景下的性能评估和优化，因此归类为LLM应用。",
      "时空数据挖掘",
      "基准测试"
    ]
  },
  {
    "title": "Segment Anything Model for automated image data annotation: empirical studies using text prompts from Grounding DINO",
    "submit_datetime": "2024年06月27日",
    "abstract": "Grounding DINO and the Segment Anything Model (SAM) have achieved impressive performance in zero-shot object detection and image segmentation, respectively. Together, they have a great potential in revolutionizing zero-shot semantic segmentation or data annotation. Yet, in specialized domains like medical image segmentation, objects of interest (e.g., organs, tissues, and tumors) may not fall in existing class names. To address this problem, the referring expression comprehension (REC) ability of Grounding DINO is leveraged to detect arbitrary targets by their language descriptions. However, recent studies have highlighted severe limitation of the REC framework in this application setting owing to its tendency to make false positive predictions when the target is absent in the given image. And, while this bottleneck is central to the prospect of open-set semantic segmentation, it is still largely unknown how much improvement can be achieved by studying the prediction errors. To this end, we perform empirical studies on eight publicly available datasets and reveal that these errors consistently follow a predictable pattern and can, thus, be mitigated by a simple strategy. Specifically, we show that these false positive detections with appreciable confidence scores generally occupy large image areas and can usually be filtered by their relative sizes. More importantly, we expect these observations to inspire future research in improving REC-based detection and automated segmentation. Using this technique, we evaluate the performance of SAM on multiple datasets from various specialized domains and report significant improvement in segmentation performance and annotation time savings over manual approaches.",
    "pdf_link": "https://arxiv.org/abs/2406.19057",
    "graphs": [],
    "abstract_cn": "Grounding DINO 与 Segment Anything Model (SAM) 在零-shot 物体检测和图像分割领域表现卓越，二者结合有望革新语义分割和数据标注。但在医学图像分割等专业领域，现有类别无法涵盖所有感兴趣对象。为此，我们借助 Grounding DINO 的指称表达理解能力，通过语言描述精准定位目标。然而，REC 框架在此场景下易产生误报，成为开放集语义分割的瓶颈。通过分析八个公开数据集，我们发现误报模式可预测，并提出简单策略有效减少误报。这些发现不仅优化了 REC 检测和自动化分割，还显著提升了 SAM 在多领域数据集上的分割性能和标注效率。",
    "title_cn": "基于Grounding DINO文本提示，Segment Anything模型在自动化图像数据标注中的应用：一项实证研究",
    "tags": [
      "Agent\n\n理由：这篇论文主要讨论了如何利用 Grounding DINO 的指称表达理解能力来精准定位目标，并针对 REC 框架在开放集语义分割中易产生误报的问题提出了解决策略。这些内容涉及到使用特定的模型（如 Grounding DINO 和 Segment Anything Model）来改进特定任务（如物体检测和图像分割），并且强调了模型在特定领域（如医学图像分割）的应用。因此，这篇论文更符合Agent分类，因为它关注的是如何通过特定的模型或系统来执行任务，而不是理论研究或广泛的应用场景。",
      "",
      "图像分割"
    ]
  },
  {
    "title": "Improving Weak-to-Strong Generalization with Reliability-Aware Alignment",
    "submit_datetime": "2024年06月27日",
    "abstract": "Large language models (LLMs) are now rapidly advancing and surpassing human abilities on many natural language tasks. However, aligning these super-human LLMs with human knowledge remains challenging because the supervision signals from human annotators may be wrong. This issue, known as the \"super-alignment\" problem, requires enhancing weak-to-strong generalization, where a strong LLM must generalize from imperfect supervision provided by a weaker source. To address this issue, we propose an approach to improve weak-to-strong generalization by involving the reliability of weak supervision signals in the alignment process. In our method, we query the weak supervisor for multiple answers, estimate the answer reliability, and enhance the alignment process by filtering out uncertain data or re-weighting reliable data. Experiments on four datasets demonstrate that our methods effectively identify the quality of weak labels and significantly enhance weak-to-strong generalization. Our work presents effective techniques for error-robust model alignment, reducing error propagation from noisy supervision and enhancing the accuracy and reliability of LLMs. Codes are publicly available at http://github.com/Irenehere/ReliableAlignment.",
    "pdf_link": "https://arxiv.org/abs/2406.19032",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19032v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19032/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19032v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19032/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19032v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19032/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19032v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19032/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19032v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19032/heatmap_reliability_score_hellaswag_LLAMA2-7B.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19032v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19032/heatmap_reliability_score_mmlu_LLAMA2-7B.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19032v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19032/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19032v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19032/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19032v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19032/heatmap_reliability_score_ethics_LLAMA2-7B.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19032v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19032/heatmap_reliability_score_gsm8k_LLAMA2-7B.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）正迅速超越人类，在众多自然语言任务中展现卓越能力。然而，将这些超人类模型与人类知识精准对齐仍是一大挑战，因为人类标注者的监督信号可能存在误差。这一难题，即“超对齐”问题，要求模型能从弱监督信号中实现强泛化。为此，我们提出了一种新方法，通过评估和整合弱监督信号的可靠性，优化对齐过程。具体而言，我们向弱监督者索取多个答案，评估其可靠性，并通过筛选或加权处理，提升对齐质量。实验结果显示，我们的方法能有效识别并提升弱标签质量，显著增强模型的泛化能力。我们的研究为模型对齐提供了鲁棒性强的技术，减少了噪声监督带来的误差传播，提高了LLMs的准确性与可靠性。相关代码已公开，可访问http://github.com/Irenehere/ReliableAlignment获取。",
    "title_cn": "借助可靠性意识的对齐，提升从弱到强的泛化能力",
    "tags": [
      "LLM理论\n\n这篇论文主要探讨了大型语言模型（LLMs）与人类知识对齐的问题，特别是在弱监督信号下的泛化能力。论文提出了一种新方法来评估和整合弱监督信号的可靠性，以优化对齐过程。这种方法涉及到对弱监督者提供的多个答案进行评估，并通过筛选或加权处理来提升对齐质量。因此，这项研究更多地关注于LLM的理论层面，即如何通过改进对齐方法来提高模型的泛化能力和准确性，而不是直接应用于特定的Agent或RAG系统，也不是关于LLM的具体应用案例。因此，将其归类为LLM理论是合适的。",
      "",
      "机器学习"
    ]
  },
  {
    "title": "Applying LLMs for Rescoring N-best ASR Hypotheses of Casual Conversations: Effects of Domain Adaptation and Context Carry-over",
    "submit_datetime": "2024年06月27日",
    "abstract": "Large language models (LLMs) have been successfully applied for rescoring automatic speech recognition (ASR) hypotheses. However, their ability to rescore ASR hypotheses of casual conversations has not been sufficiently explored. In this study, we reveal it by performing N-best ASR hypotheses rescoring using Llama2 on the CHiME-7 distant ASR (DASR) task. Llama2 is one of the most representative LLMs, and the CHiME-7 DASR task provides datasets of casual conversations between multiple participants. We investigate the effects of domain adaptation of the LLM and context carry-over when performing N-best rescoring. Experimental results show that, even without domain adaptation, Llama2 outperforms a standard-size domain-adapted Transformer-LM, especially when using a long context. Domain adaptation shortens the context length needed with Llama2 to achieve its best performance, i.e., it reduces the computational cost of Llama2.",
    "pdf_link": "https://arxiv.org/abs/2406.18972",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）在自动语音识别（ASR）假设的重评分方面已取得成功应用，但其在非正式对话场景下的重评分能力仍未被充分挖掘。本研究通过在CHiME-7远场ASR任务上运用Llama2对N-最佳ASR假设进行重评分，揭示了这一潜力。Llama2作为顶尖的LLMs之一，而CHiME-7 DASR任务则提供了多人非正式对话的数据集。我们探讨了领域适应和上下文传递对LLM在N-最佳重评分中的影响。实验结果显示，即便未经领域适应，Llama2在长上下文使用时仍超越了标准大小的领域适应Transformer-LM。领域适应不仅提升了Llama2的性能，还减少了其所需的上下文长度，从而降低了计算成本。",
    "title_cn": "利用大型语言模型对休闲对话的ASR N最佳假设进行重评分：探讨领域适应与上下文传递的影响",
    "tags": [
      "LLM应用\n\n这篇论文探讨了大型语言模型（LLMs）在自动语音识别（ASR）中的应用，特别是在非正式对话场景下的重评分能力。通过使用Llama2模型在CHiME-7远场ASR任务上对N-最佳ASR假设进行重评分，研究了领域适应和上下文传递对LLM性能的影响。这表明LLMs在特定应用场景下的潜力和优化方向，属于LLM应用的范畴。",
      "自动语音识别",
      "对话系统"
    ]
  },
  {
    "title": "TrustUQA: A Trustful Framework for Unified Structured Data Question Answering",
    "submit_datetime": "2024年06月27日",
    "abstract": "Natural language question answering (QA) over structured data sources such as tables and knowledge graphs (KGs) have been widely investigated, for example with Large Language Models (LLMs). The main solutions include question to formal query parsing and retrieval-based answer generation. However, current methods of the former often suffer from weak generalization, failing to dealing with multiple sources simultaneously, while the later is limited in trustfulness. In this paper, we propose UnifiedTQA, a trustful QA framework that can simultaneously support multiple types of structured data in a unified way. To this end, it adopts an LLM-friendly and unified knowledge representation method called Condition Graph (CG), and uses an LLM and demonstration-based two-level method for CG querying. For enhancement, it is also equipped with dynamic demonstration retrieval. We have evaluated UnifiedTQA with 5 benchmarks covering 3 types of structured data. It outperforms 2 existing unified structured data QA methods and in comparison with the baselines that are specific to a data type, it achieves state-of-the-art on 2 of them. Further more, we demonstrates potential of our method for more general QA tasks, QA over mixed structured data and QA across structured data.",
    "pdf_link": "https://arxiv.org/abs/2406.18916",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.18916v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18916/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18916v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18916/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18916v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18916/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18916v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18916/x4.png"
      }
    ],
    "abstract_cn": "自然语言问答（QA）在表格和知识图谱等结构化数据源上的研究已广泛展开，主要通过大型语言模型（LLMs）实现。现有方法包括问题解析成正式查询和基于检索的答案生成，但前者泛化能力不足，难以同时处理多源数据，后者则可信度有限。为此，我们提出了UnifiedTQA，一个可信的QA框架，能统一处理多种结构化数据。该框架采用Condition Graph（CG）这一LLM友好的统一知识表示，并结合LLM和演示的二级查询方法。此外，它还具备动态演示检索功能，以增强性能。我们在5个涵盖3种结构化数据的基准上测试了UnifiedTQA，结果显示它超越了两种现有方法，并在与特定数据类型的基线对比中，在两个基准上达到了最先进水平。此外，我们还展示了UnifiedTQA在更广泛的QA任务，如混合结构化数据和跨结构化数据QA中的应用潜力。",
    "title_cn": "TrustUQA：构建可信赖的统一结构化数据问答框架",
    "tags": [
      "LLM应用\n\n这篇论文摘要描述了一个名为UnifiedTQA的框架，它旨在通过使用大型语言模型（LLMs）来改进自然语言问答（QA）在结构化数据源上的应用。该框架通过采用一种名为Condition Graph（CG）的统一知识表示，并结合LLM和演示的二级查询方法，以及动态演示检索功能，来提高处理多种结构化数据的能力和可信度。论文中提到的实验结果表明，UnifiedTQA在多个基准测试中超越了现有方法，并展示了其在更广泛的QA任务中的应用潜力。因此，这篇论文属于LLM应用类别，因为它专注于使用LLMs来解决实际的QA问题，并提出了一个具体的应用框架。",
      "问答系统",
      "数据处理"
    ]
  },
  {
    "title": "Manipulate-Anything: Automating Real-World Robots using Vision-Language Models",
    "submit_datetime": "2024年06月27日",
    "abstract": "Large-scale endeavors like RT-1 and widespread community efforts such as Open-X-Embodiment have contributed to growing the scale of robot demonstration data. However, there is still an opportunity to improve the quality, quantity, and diversity of robot demonstration data. Although vision-language models have been shown to automatically generate demonstration data, their utility has been limited to environments with privileged state information, they require hand-designed skills, and are limited to interactions with few object instances. We propose Manipulate-Anything, a scalable automated generation method for real-world robotic manipulation. Unlike prior work, our method can operate in real-world environments without any privileged state information, hand-designed skills, and can manipulate any static object. We evaluate our method using two setups. First, Manipulate-Anything successfully generates trajectories for all 5 real-world and 12 simulation tasks, significantly outperforming existing methods like VoxPoser. Second, Manipulate-Anything's demonstrations can train more robust behavior cloning policies than training with human demonstrations, or from data generated by VoxPoser and Code-As-Policies. We believe \\methodLong\\ can be the scalable method for both generating data for robotics and solving novel tasks in a zero-shot setting.",
    "pdf_link": "https://arxiv.org/abs/2406.18915",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.18915v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18915/teaser.jpg"
      },
      {
        "url": "https://arxiv.org/html/2406.18915v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18915/MAFigure2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18915v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18915/actiongen.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18915v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18915/figure3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18915v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18915/Actiondistribution.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18915v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18915/scaling.png"
      }
    ],
    "abstract_cn": "RT-1和Open-X-Embodiment等大规模项目已助力机器人演示数据的规模增长，但提升其质量、数量和多样性仍有空间。现有的视觉-语言模型虽能自动生成演示数据，但受限于需特权状态信息的环境，依赖手工技能，且仅能与少数对象互动。我们提出的Manipulate-Anything方法，能在无特权信息和手工技能的真实环境中，自动化生成机器人操作数据，并能操纵任意静态物体。通过两种测试，Manipulate-Anything不仅在生成任务轨迹上超越了VoxPoser等方法，而且训练出的行为克隆策略比人类演示或VoxPoser生成的数据更为健壮。我们坚信，Manipulate-Anything将成为机器人数据生成和零-shot新任务解决的革新性方法。",
    "title_cn": "操控万物：借助视觉-语言模型实现现实世界机器人的自动化",
    "tags": [
      "Agent\n\n理由：这篇论文介绍了一种名为Manipulate-Anything的方法，该方法能够在真实环境中自动化生成机器人操作数据，并能操纵任意静态物体。这种方法不仅在生成任务轨迹上超越了现有方法，而且训练出的行为克隆策略比人类演示或现有方法生成的数据更为健壮。这表明该方法能够增强机器人的自主操作能力，使其能够在多种环境中执行任务，这是Agent类研究的核心特征。因此，这篇论文更适合归类为Agent。",
      "机器人技术",
      "自动化"
    ]
  },
  {
    "title": "Sonnet or Not, Bot? Poetry Evaluation for Large Models and Datasets",
    "submit_datetime": "2024年06月27日",
    "abstract": "Large language models (LLMs) can now generate and recognize text in a wide range of styles and genres, including highly specialized, creative genres like poetry. But what do LLMs really know about poetry? What can they know about poetry? We develop a task to evaluate how well LLMs recognize a specific aspect of poetry, poetic form, for more than 20 forms and formal elements in the English language. Poetic form captures many different poetic features, including rhyme scheme, meter, and word or line repetition. We use this task to reflect on LLMs' current poetic capabilities, as well as the challenges and pitfalls of creating NLP benchmarks for poetry and for other creative tasks. In particular, we use this task to audit and reflect on the poems included in popular pretraining datasets. Our findings have implications for NLP researchers interested in model evaluation, digital humanities and cultural analytics scholars, and cultural heritage professionals.",
    "pdf_link": "https://arxiv.org/abs/2406.18906",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.18906v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18906/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18906v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18906/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18906v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18906/x3.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）如今能驾驭多种文本风格与体裁，包括诗歌这类高度创意的领域。但它们对诗歌的理解究竟有多深？我们设计了一项任务，旨在测试LLMs识别英语中超过20种诗歌形式及其元素的能力，涵盖韵律、格律及重复等诗歌特征。通过这项任务，我们不仅审视了LLMs在诗歌领域的当前能力，还探讨了为诗歌及其他创意任务设定NLP基准的挑战与误区。特别地，我们借此机会审视了流行预训练数据集中的诗歌内容。这些发现对NLP模型评估研究者、数字人文与文化分析学者以及文化遗产保护者均具有重要意义。",
    "title_cn": "《机器人，这是十四行诗吗？——大型模型与数据集的诗歌评鉴》",
    "tags": [
      "LLM应用\n\n这篇论文主要探讨了大型语言模型（LLMs）在识别和理解英语诗歌形式及其元素方面的能力，包括韵律、格律和重复等特征。通过设计特定的任务来测试LLMs的性能，并探讨了为诗歌等创意任务设定NLP基准的挑战。这一研究不仅关注了LLMs在特定领域的应用能力，还涉及了对预训练数据集中诗歌内容的分析，这对于NLP模型评估、数字人文研究以及文化遗产保护等领域具有重要意义。因此，这篇论文应归类为LLM应用。",
      "",
      "数字人文"
    ]
  },
  {
    "title": "Can we teach language models to gloss endangered languages?",
    "submit_datetime": "2024年06月27日",
    "abstract": "Interlinear glossed text (IGT) is a popular format in language documentation projects, where each morpheme is labeled with a descriptive annotation. Automating the creation of interlinear glossed text can be desirable to reduce annotator effort and maintain consistency across annotated corpora. Prior research has explored a number of statistical and neural methods for automatically producing IGT.\n  As large language models (LLMs) have showed promising results across multilingual tasks, even for rare, endangered languages, it is natural to wonder whether they can be utilized for the task of generating IGT. We explore whether LLMs can be effective at the task of interlinear glossing with in-context learning, without any traditional training. We propose new approaches for selecting examples to provide in-context, observing that targeted selection can significantly improve performance. We find that LLM-based methods beat standard transformer baselines, despite requiring no training at all. These approaches still underperform state-of-the-art supervised systems for the task, but are highly practical for researchers outside of the NLP community, requiring minimal effort to use.",
    "pdf_link": "https://arxiv.org/abs/2406.18895",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.18895v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18895/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18895v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18895/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18895v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18895/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18895v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18895/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18895v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18895/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18895v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18895/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18895v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18895/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18895v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18895/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18895v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18895/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18895v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18895/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18895v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18895/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18895v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18895/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18895v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18895/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18895v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18895/x14.png"
      }
    ],
    "abstract_cn": "在语言文档项目中，Interlinear glossed text (IGT) 是一种流行的格式，每个语素都配有描述性注释。自动化生成IGT不仅能减轻注释者的负担，还能确保注释的一致性。已有研究尝试了多种统计和神经网络方法来自动创建IGT。鉴于大型语言模型（LLMs）在多语言任务中，包括稀有和濒危语言，都显示出潜力，我们自然会思考它们是否能用于IGT的自动生成。本研究探索了LLMs是否能通过情境学习有效执行IGT注释任务，无需传统训练。我们提出了一种新的示例选择方法，发现有针对性的选择能大幅提升性能。尽管无需训练，基于LLM的方法仍超越了标准transformer模型。虽然这些方法尚未达到最先进的监督系统水平，但对于NLP领域之外的研究者而言，它们极为实用，几乎无需额外努力即可使用。",
    "title_cn": "我们能否训练语言模型，使其能够为濒危语言提供注释？",
    "tags": [
      "LLM应用\n\n理由：这篇论文探讨了大型语言模型（LLMs）在自动化生成Interlinear glossed text (IGT)中的应用，特别是在多语言任务中，包括稀有和濒危语言。研究关注的是LLMs在实际应用中的效能，即是否能通过情境学习有效执行IGT注释任务，无需传统训练，并且提出了新的示例选择方法以提升性能。这与LLM的理论研究、Agent的设计或RAG（Retrieval-Augmented Generation）的特定技术不同，而是直接关注LLM在特定NLP任务中的应用。因此，将其归类为LLM应用。",
      "语言学",
      ""
    ]
  },
  {
    "title": "Assessing the Effectiveness of LLMs in Android Application Vulnerability Analysis",
    "submit_datetime": "2024年06月27日",
    "abstract": "The increasing frequency of attacks on Android applications coupled with the recent popularity of large language models (LLMs) necessitates a comprehensive understanding of the capabilities of the latter in identifying potential vulnerabilities, which is key to mitigate the overall risk. To this end, the work at hand compares the ability of nine state-of-the-art LLMs to detect Android code vulnerabilities listed in the latest Open Worldwide Application Security Project (OWASP) Mobile Top 10. Each LLM was evaluated against an open dataset of over 100 vulnerable code samples, including obfuscated ones, assessing each model's ability to identify key vulnerabilities. Our analysis reveals the strengths and weaknesses of each LLM, identifying important factors that contribute to their performance. Additionally, we offer insights into context augmentation with retrieval-augmented generation (RAG) for detecting Android code vulnerabilities, which in turn may propel secure application development. Finally, while the reported findings regarding code vulnerability analysis show promise, they also reveal significant discrepancies among the different LLMs.",
    "pdf_link": "https://arxiv.org/abs/2406.18894",
    "graphs": [],
    "abstract_cn": "随着Android应用遭受攻击的频率上升，以及大型语言模型（LLMs）的兴起，我们亟需深入了解这些模型在识别潜在安全漏洞方面的能力，这对于降低整体风险至关重要。本研究对比了九种顶尖LLMs在检测OWASP移动安全排行榜前十中的Android代码漏洞的能力。通过分析一个包含100多个漏洞代码样本（含混淆样本）的公开数据集，我们评估了各模型的关键漏洞识别能力。分析结果不仅揭示了各模型的强项与弱点，还指出了影响其性能的关键因素。此外，我们还探讨了如何通过检索增强生成（RAG）技术增强上下文，以提升Android代码漏洞的检测能力，进而推动更安全的应用开发。尽管研究结果显示了LLMs在代码漏洞分析方面的潜力，但也暴露了它们之间的显著差异。",
    "title_cn": "探究大型语言模型在安卓应用漏洞分析中的效能",
    "tags": [
      "RAG\n\n理由：该论文摘要主要讨论了大型语言模型（LLMs）在检测Android应用中的安全漏洞方面的应用，并特别提到了通过检索增强生成（RAG）技术来增强上下文，以提升漏洞检测能力。这表明论文的重点在于使用RAG技术来改进LLMs在特定应用场景（即安全漏洞检测）中的性能，因此属于RAG分类。虽然论文也涉及了LLMs的应用，但主要焦点是RAG技术的应用，而不是LLMs的一般应用或理论研究。",
      "移动安全",
      "软件开发"
    ]
  },
  {
    "title": "SSP: Self-Supervised Prompting for Cross-Lingual Transfer to Low-Resource Languages using Large Language Models",
    "submit_datetime": "2024年06月27日",
    "abstract": "Recently, very large language models (LLMs) have shown exceptional performance on several English NLP tasks with just in-context learning (ICL), but their utility in other languages is still underexplored. We investigate their effectiveness for NLP tasks in low-resource languages (LRLs), especially in the setting of zero-labelled cross-lingual transfer (0-CLT), where no labelled training data for the target language is available -- however training data from one or more related medium-resource languages (MRLs) is utilized, alongside the available unlabeled test data for a target language. We introduce Self-Supervised Prompting (SSP), a novel ICL approach tailored for the 0-CLT setting.\n  SSP is based on the key observation that LLMs output more accurate labels if in-context exemplars are from the target language (even if their labels are slightly noisy). To operationalize this, since target language training data is not available in 0-CLT, SSP operates in two stages. In Stage I, using source MRL training data, target language's test data is noisily labeled. In Stage II, these noisy test data points are used as exemplars in ICL for further improved labelling. Additionally, our implementation of SSP uses a novel Integer Linear Programming (ILP)-based exemplar selection that balances similarity, prediction confidence (when available) and label coverage. Experiments on three tasks and eleven LRLs (from three regions) demonstrate that SSP strongly outperforms existing SOTA fine-tuned and prompting-based baselines in 0-CLT setup.",
    "pdf_link": "https://arxiv.org/abs/2406.18880",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.18880v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18880/Noise_analysis.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18880v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18880/SSP-CLT-new.jpg"
      },
      {
        "url": "https://arxiv.org/html/2406.18880v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18880/NLI_merged_all.jpg"
      },
      {
        "url": "https://arxiv.org/html/2406.18880v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18880/prompt_prec_ner_pos.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18880v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18880/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18880v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18880/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18880v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18880/neutral_native.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18880v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18880/neutral_eng.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18880v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18880/x3.png"
      }
    ],
    "abstract_cn": "近期，超大型语言模型（LLMs）在英语NLP任务上通过情境学习（ICL）表现出色，但在其他语言中的潜力尚未充分挖掘。我们探索了LLMs在低资源语言（LRLs）NLP任务中的效能，特别是在零标记跨语言转移（0-CLT）场景下，即目标语言缺乏标记训练数据，但可利用相关中资源语言（MRLs）的训练数据及目标语言的未标记测试数据。为此，我们提出了自监督提示（SSP），一种专为0-CLT定制的ICL新策略。SSP的核心在于，当情境示例源自目标语言（即便标签稍有噪声）时，LLMs能提供更精确的标签。由于0-CLT中目标语言无训练数据，SSP分两步实施：首先，利用源MRL数据对目标语言测试数据进行噪声标记；随后，这些噪声数据点作为ICL的示例，以提升标记准确性。我们的SSP实现还创新性地采用了基于整数线性规划（ILP）的示例选择，兼顾相似度、预测信心与标签覆盖。实验涵盖三个任务、十一种LRLs（分属三个地区），结果显示SSP在0-CLT场景下显著超越了现有的SOTA微调和提示基线。",
    "title_cn": "SSP：借助大型语言模型，自监督提示助力低资源语言的跨语言迁移",
    "tags": [
      "LLM应用\n\n理由：这篇论文主要探讨了超大型语言模型（LLMs）在低资源语言（LRLs）NLP任务中的应用，特别是在零标记跨语言转移（0-CLT）场景下的应用。论文提出了一种新的情境学习策略——自监督提示（SSP），并展示了其在特定场景下的有效性。这表明论文关注的是LLMs在实际应用中的效能和改进，因此属于LLM应用分类。",
      "",
      "跨语言学习"
    ]
  },
  {
    "title": "SK-VQA: Synthetic Knowledge Generation at Scale for Training Context-Augmented Multimodal LLMs",
    "submit_datetime": "2024年06月27日",
    "abstract": "Synthetic data generation has gained significant attention recently for its utility in training large vision and language models. However, the application of synthetic data to the training of multimodal context-augmented generation systems has been relatively unexplored. This gap in existing work is important because existing vision and language models (VLMs) are not trained specifically for context-augmented generation. Resources for adapting such models are therefore crucial for enabling their use in retrieval-augmented generation (RAG) settings, where a retriever is used to gather relevant information that is then subsequently provided to a generative model via context augmentation. To address this challenging problem, we generate SK-VQA: a large synthetic multimodal dataset containing over 2 million question-answer pairs which require external knowledge to determine the final answer. Our dataset is both larger and significantly more diverse than existing resources of its kind, possessing over 11x more unique questions and containing images from a greater variety of sources than previously-proposed datasets. Through extensive experiments, we demonstrate that our synthetic dataset can not only serve as a challenging benchmark, but is also highly effective for adapting existing generative multimodal models for context-augmented generation.",
    "pdf_link": "https://arxiv.org/abs/2406.19593",
    "graphs": [],
    "abstract_cn": "合成数据生成近期备受瞩目，因其在大规模视觉与语言模型训练中的实用价值。然而，其在多模态上下文增强生成系统训练中的应用尚待深入探索。现有视觉与语言模型（VLMs）并非专为上下文增强生成设计，故适应这些模型的资源对检索增强生成（RAG）场景至关重要。为此，我们创建了SK-VQA，一个包含超200万问题-答案对的大型合成多模态数据集，需外部知识解答。该数据集规模更大、多样性显著提升，问题数量超以往11倍，图像来源更广泛。实验表明，SK-VQA不仅可作为挑战性基准，还能高效适应现有生成多模态模型，助力上下文增强生成。",
    "title_cn": "SK-VQA：大规模合成知识生成，助力上下文增强型多模态LLM训练",
    "tags": [
      "RAG",
      "人工智能",
      "数据集"
    ]
  },
  {
    "title": "Using Large Language Models to Assist Video Content Analysis: An Exploratory Study of Short Videos on Depression",
    "submit_datetime": "2024年06月27日",
    "abstract": "Despite the growing interest in leveraging Large Language Models (LLMs) for content analysis, current studies have primarily focused on text-based content. In the present work, we explored the potential of LLMs in assisting video content analysis by conducting a case study that followed a new workflow of LLM-assisted multimodal content analysis. The workflow encompasses codebook design, prompt engineering, LLM processing, and human evaluation. We strategically crafted annotation prompts to get LLM Annotations in structured form and explanation prompts to generate LLM Explanations for a better understanding of LLM reasoning and transparency. To test LLM's video annotation capabilities, we analyzed 203 keyframes extracted from 25 YouTube short videos about depression. We compared the LLM Annotations with those of two human coders and found that LLM has higher accuracy in object and activity Annotations than emotion and genre Annotations. Moreover, we identified the potential and limitations of LLM's capabilities in annotating videos. Based on the findings, we explore opportunities and challenges for future research and improvements to the workflow. We also discuss ethical concerns surrounding future studies based on LLM-assisted video analysis.",
    "pdf_link": "https://arxiv.org/abs/2406.19528",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19528v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19528/workflow.jpg"
      }
    ],
    "abstract_cn": "尽管 LLMs 在内容分析领域的应用日益受到关注，但现有研究大多聚焦于文本内容。本研究通过一项新颖的 LLM 辅助多模态内容分析案例，探索了其在视频分析中的潜力。该流程涉及代码本设计、提示工程、LLM 处理及人工评估等环节。我们精心设计注释与解释提示，以结构化形式获取 LLM 注释，并生成解释以增强 LLM 推理的透明度。通过分析 25 个抑郁症主题的 YouTube 短视频中的 203 个关键帧，我们对比了 LLM 与人工编码员的注释准确性，发现 LLM 在对象和活动识别上表现更优，但在情感和类型识别上稍逊一筹。此外，我们揭示了 LLM 在视频注释中的潜力与局限。基于此，我们探讨了未来研究的方向与挑战，并就 LLM 辅助视频分析引发的伦理问题进行了讨论。",
    "title_cn": "借助大型语言模型，我们探索了抑郁症短视频的内容分析，旨在深入研究这一辅助手段的潜力。",
    "tags": [
      "LLM应用",
      "视频分析",
      "心理健康"
    ]
  },
  {
    "title": "A Survey on Data Quality Dimensions and Tools for Machine Learning",
    "submit_datetime": "2024年06月27日",
    "abstract": "Machine learning (ML) technologies have become substantial in practically all aspects of our society, and data quality (DQ) is critical for the performance, fairness, robustness, safety, and scalability of ML models. With the large and complex data in data-centric AI, traditional methods like exploratory data analysis (EDA) and cross-validation (CV) face challenges, highlighting the importance of mastering DQ tools. In this survey, we review 17 DQ evaluation and improvement tools in the last 5 years. By introducing the DQ dimensions, metrics, and main functions embedded in these tools, we compare their strengths and limitations and propose a roadmap for developing open-source DQ tools for ML. Based on the discussions on the challenges and emerging trends, we further highlight the potential applications of large language models (LLMs) and generative AI in DQ evaluation and improvement for ML. We believe this comprehensive survey can enhance understanding of DQ in ML and could drive progress in data-centric AI. A complete list of the literature investigated in this survey is available on GitHub at: https://github.com/haihua0913/awesome-dq4ml.",
    "pdf_link": "https://arxiv.org/abs/2406.19614",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19614v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19614/dqtEvolution-V2.drawio.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19614v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19614/DimensionandTool-06.drawio.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19614v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19614/Roadmap.drawio.png"
      }
    ],
    "abstract_cn": "机器学习技术已深入社会各领域，数据质量（DQ）对模型性能、公平性、鲁棒性、安全性及可扩展性至关重要。面对复杂大数据，传统方法如探索性数据分析（EDA）和交叉验证（CV）显露挑战，凸显DQ工具的重要性。本调查回顾了过去五年中17种DQ工具，通过介绍其DQ维度、指标及主要功能，比较优劣，并提出开源DQ工具开发路线图。基于挑战与趋势讨论，我们强调了大型语言模型（LLM）与生成AI在ML的DQ评估与改进中的潜力。此全面调查旨在深化对ML中DQ的理解，推动数据驱动AI的进步。完整文献列表见GitHub：https://github.com/haihua0913/awesome-dq4ml。",
    "title_cn": "机器学习数据质量维度与工具综述",
    "tags": [
      "LLM应用",
      "人工智能",
      "数据科学"
    ]
  },
  {
    "title": "Mixture of In-Context Experts Enhance LLMs' Long Context Awareness",
    "submit_datetime": "2024年06月27日",
    "abstract": "Many studies have revealed that large language models (LLMs) exhibit uneven awareness of different contextual positions.Their limited context awareness can lead to overlooking critical information and subsequent task failures. While several approaches have been proposed to enhance LLMs' context awareness, achieving both effectiveness and efficiency remains challenging.In this paper, for LLMs utilizing RoPE as position embeddings, we introduce a novel method called ``Mixture of In-Context Experts'' (MoICE) to address this challenge. MoICE comprises two key components: a router integrated into each attention head within LLMs and a lightweight router-only training optimization strategy: (1) MoICE views each RoPE angle as an `in-context' expert, demonstrated to be capable of directing the attention of a head to specific contextual positions. Consequently, each attention head flexibly processes tokens using multiple RoPE angles dynamically selected by the router to attend to the needed positions. This approach mitigates the risk of overlooking essential contextual information. (2) The router-only training strategy entails freezing LLM parameters and exclusively updating routers for only a few steps. When applied to open-source LLMs including Llama and Mistral, MoICE surpasses prior methods across multiple tasks on long context understanding and generation, all while maintaining commendable inference efficiency.",
    "pdf_link": "https://arxiv.org/abs/2406.19598",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19598v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19598/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19598v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19598/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19598v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19598/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19598v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19598/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19598v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19598/x5.png"
      }
    ],
    "abstract_cn": "研究表明，大型语言模型对不同上下文位置的感知存在差异，这可能导致关键信息的遗漏和任务失败。尽管已有方法尝试提升模型的上下文感知能力，但如何在有效性和效率之间取得平衡仍是一大挑战。为此，我们针对采用 RoPE 位置嵌入的 LLMs，提出了一种名为“上下文专家混合”（MoICE）的创新方法。MoICE 通过集成在每个注意力头中的路由器和轻量级训练策略，实现了对特定上下文位置的精准关注，从而有效避免了关键信息的遗漏。此外，该方法在保持高效推理的同时，显著提升了模型在长上下文理解和生成任务中的表现。",
    "title_cn": "混合上下文专家模型提升大型语言模型对长文本的感知能力。",
    "tags": [
      "LLM理论",
      "人工智能",
      ""
    ]
  },
  {
    "title": "PathAlign: A vision-language model for whole slide images in histopathology",
    "submit_datetime": "2024年06月27日",
    "abstract": "Microscopic interpretation of histopathology images underlies many important diagnostic and treatment decisions. While advances in vision-language modeling raise new opportunities for analysis of such images, the gigapixel-scale size of whole slide images (WSIs) introduces unique challenges. Additionally, pathology reports simultaneously highlight key findings from small regions while also aggregating interpretation across multiple slides, often making it difficult to create robust image-text pairs. As such, pathology reports remain a largely untapped source of supervision in computational pathology, with most efforts relying on region-of-interest annotations or self-supervision at the patch-level. In this work, we develop a vision-language model based on the BLIP-2 framework using WSIs paired with curated text from pathology reports. This enables applications utilizing a shared image-text embedding space, such as text or image retrieval for finding cases of interest, as well as integration of the WSI encoder with a frozen large language model (LLM) for WSI-based generative text capabilities such as report generation or AI-in-the-loop interactions. We utilize a de-identified dataset of over 350,000 WSIs and diagnostic text pairs, spanning a wide range of diagnoses, procedure types, and tissue types. We present pathologist evaluation of text generation and text retrieval using WSI embeddings, as well as results for WSI classification and workflow prioritization (slide-level triaging). Model-generated text for WSIs was rated by pathologists as accurate, without clinically significant error or omission, for 78% of WSIs on average. This work demonstrates exciting potential capabilities for language-aligned WSI embeddings.",
    "pdf_link": "https://arxiv.org/abs/2406.19578",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19578v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19578/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19578v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19578/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19578v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19578/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19578v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19578/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19578v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19578/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19578v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19578/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19578v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19578/tethys_seqlen_hist.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19578v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19578/tcga_seqlen_hist.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19578v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19578/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19578v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19578/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19578v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19578/rating-conf-pathologists.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19578v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19578/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19578v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19578/x10.png"
      }
    ],
    "abstract_cn": "组织病理学图像的微观解读对诊断和治疗至关重要。尽管视觉-语言模型的发展为图像分析带来新机遇，但全切片图像（WSIs）的巨大尺寸也带来了挑战。病理报告虽强调小区域的关键发现，但汇总多切片解读时，创建图像-文本对变得困难。因此，病理报告在计算病理学中仍未被充分利用。我们基于BLIP-2框架，利用WSIs与病理报告文本配对，开发了视觉-语言模型，实现了图像-文本嵌入空间的共享应用，如检索感兴趣病例，以及与LLM集成，实现基于WSI的文本生成等。我们使用的数据集包含超过350,000个WSIs和诊断文本对，涵盖广泛。病理学家评估显示，模型生成的WSIs文本准确无误，平均78%的WSIs无临床显著错误或遗漏。这项工作展示了语言对齐的WSI嵌入的巨大潜力。",
    "title_cn": "PathAlign：专为组织病理学全切片图像设计的视觉-语言模型",
    "tags": [
      "LLM应用",
      "",
      "计算机视觉"
    ]
  },
  {
    "title": "Synthetic Cancer -- Augmenting Worms with LLMs",
    "submit_datetime": "2024年06月27日",
    "abstract": "With increasingly sophisticated large language models (LLMs), the potential for abuse rises drastically. As a submission to the Swiss AI Safety Prize, we present a novel type of metamorphic malware leveraging LLMs for two key processes. First, LLMs are used for automatic code rewriting to evade signature-based detection by antimalware programs. The malware then spreads its copies via email by utilizing an LLM to socially engineer email replies to encourage recipients to execute the attached malware. Our submission includes a functional minimal prototype, highlighting the risks that LLMs pose for cybersecurity and underscoring the need for further research into intelligent malware.",
    "pdf_link": "https://arxiv.org/abs/2406.19570",
    "graphs": [],
    "abstract_cn": "随着 LLM 的复杂性增加，其被滥用的风险也随之上升。我们针对瑞士 AI 安全奖提交了一种新型变形恶意软件，该软件利用 LLM 进行自动代码重写以躲避检测，并通过社交工程电子邮件回复来传播恶意软件。我们的原型展示了 LLM 对网络安全的潜在威胁，并强调了深入研究智能恶意软件的重要性。",
    "title_cn": "合成癌症：借助 LLM 强化蠕虫研究",
    "tags": [
      "LLM应用",
      "网络安全",
      "人工智能"
    ]
  },
  {
    "title": "Rethinking harmless refusals when fine-tuning foundation models",
    "submit_datetime": "2024年06月27日",
    "abstract": "In this paper, we investigate the degree to which fine-tuning in Large Language Models (LLMs) effectively mitigates versus merely conceals undesirable behavior. Through the lens of semi-realistic role-playing exercises designed to elicit such behaviors, we explore the response dynamics of LLMs post fine-tuning interventions. Our methodology involves prompting models for Chain-of-Thought (CoT) reasoning and analyzing the coherence between the reasoning traces and the resultant outputs. Notably, we identify a pervasive phenomenon we term \\emph{reason-based deception}, where models either stop producing reasoning traces or produce seemingly ethical reasoning traces that belie the unethical nature of their final outputs. We further examine the efficacy of response strategies (polite refusal versus explicit rebuttal) in curbing the occurrence of undesired behavior in subsequent outputs of multi-turn interactions. Our findings reveal that explicit rebuttals significantly outperform polite refusals in preventing the continuation of undesired outputs and nearly eliminate reason-based deception, challenging current practices in model fine-tuning. Accordingly, the two key contributions of this paper are (1) defining and studying reason-based deception, a new type of hidden behavior, and (2) demonstrating that rebuttals provide a more robust response model to harmful requests than refusals, thereby highlighting the need to reconsider the response strategies in fine-tuning approaches.",
    "pdf_link": "https://arxiv.org/abs/2406.19552",
    "graphs": [],
    "abstract_cn": "本文探讨了大型语言模型（LLM）中的微调是否真正缓解了不良行为，还是仅仅掩盖了它们。通过设计半现实的角色扮演练习来引出这些行为，我们分析了微调后LLM的反应动态。我们采用思维链（CoT）推理提示，并评估推理与输出的一致性。我们发现了一种称为“基于理由的欺骗”的现象，模型可能停止提供推理或提供看似道德的推理，实则掩盖了不道德的输出。此外，我们比较了礼貌拒绝与明确反驳两种回应策略，发现明确反驳在防止不良输出和消除“基于理由的欺骗”方面更为有效，这促使我们重新审视微调中的回应策略。本文的主要贡献在于揭示了“基于理由的欺骗”这一新现象，并证明了反驳策略在应对有害请求时的优越性。",
    "title_cn": "探讨微调基础模型中的“无害拒绝”现象",
    "tags": [
      "LLM理论",
      "人工智能",
      "道德伦理"
    ]
  },
  {
    "title": "Leveraging Machine-Generated Rationales to Facilitate Social Meaning Detection in Conversations",
    "submit_datetime": "2024年06月27日",
    "abstract": "We present a generalizable classification approach that leverages Large Language Models (LLMs) to facilitate the detection of implicitly encoded social meaning in conversations. We design a multi-faceted prompt to extract a textual explanation of the reasoning that connects visible cues to underlying social meanings. These extracted explanations or rationales serve as augmentations to the conversational text to facilitate dialogue understanding and transfer. Our empirical results over 2,340 experimental settings demonstrate the significant positive impact of adding these rationales. Our findings hold true for in-domain classification, zero-shot, and few-shot domain transfer for two different social meaning detection tasks, each spanning two different corpora.",
    "pdf_link": "https://arxiv.org/abs/2406.19545",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19545v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19545/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19545v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19545/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19545v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19545/labeldist-emotion.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19545v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19545/labeldist-resisting.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19545v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19545/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19545v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19545/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19545v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19545/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19545v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19545/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19545v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19545/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19545v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19545/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19545v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19545/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19545v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19545/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19545v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19545/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19545v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19545/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19545v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19545/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19545v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19545/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19545v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19545/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19545v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19545/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19545v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19545/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19545v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19545/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19545v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19545/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19545v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19545/x20.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19545v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19545/x21.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19545v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19545/x22.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19545v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19545/x23.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19545v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19545/x24.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19545v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19545/x25.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19545v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19545/x26.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19545v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19545/x27.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19545v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19545/x28.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19545v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19545/x29.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19545v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19545/x30.png"
      }
    ],
    "abstract_cn": "我们开发了一种利用 LLM 的泛化分类方法，旨在提升对话中隐含社会意义的识别。通过设计多维度提示，我们提取了连接表面线索与深层社会意义的推理文本。这些提取的解释作为对话文本的补充，增强了对话的理解与应用。在 2,340 个实验中，我们验证了这些补充的积极效果。无论是领域内分类还是零-shot 及少-shot 的领域转移，我们的方法在两种社会意义检测任务中均表现出色，涉及两个不同语料库。",
    "title_cn": "借助机器生成的理由，提升对话中社会意义的识别效率",
    "tags": [
      "LLM应用",
      "社会科学",
      "人工智能"
    ]
  },
  {
    "title": "Where Are Large Language Models for Code Generation on GitHub?",
    "submit_datetime": "2024年06月27日",
    "abstract": "The increasing use of Large Language Models (LLMs) in software development has garnered significant attention from researchers assessing the quality of the code they generate. However, much of the research focuses on controlled datasets such as HumanEval, which fail to adequately represent how developers actually utilize LLMs' code generation capabilities or clarify the characteristics of LLM-generated code in real-world development scenarios. To bridge this gap, our study investigates the characteristics of LLM-generated code and its corresponding projects hosted on GitHub. Our findings reveal several key insights: (1) ChatGPT and Copilot are the most frequently utilized for generating code on GitHub. In contrast, there is very little code generated by other LLMs on GitHub. (2) Projects containing ChatGPT/Copilot-generated code are often small and less known, led by individuals or small teams. Despite this, most projects are continuously evolving and improving. (3) ChatGPT/Copilot is mainly utilized for generating Python, Java, and TypeScript scripts for data processing and transformation. C/C++ and JavaScript code generation focuses on algorithm and data structure implementation and user interface code. Most ChatGPT/Copilot-generated code snippets are relatively short and exhibit low complexity. (4) Compared to human-written code, ChatGPT/Copilot-generated code exists in a small proportion of projects and generally undergoes fewer modifications. Additionally, modifications due to bugs are even fewer, ranging from just 3% to 8% across different languages. (5) Most comments on ChatGPT/Copilot-generated code lack detailed information, often only stating the code's origin without mentioning prompts, human modifications, or testing status. Based on these findings, we discuss the implications for researchers and practitioners.",
    "pdf_link": "https://arxiv.org/abs/2406.19544",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19544v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19544/pie_chart.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19544v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19544/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19544v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19544/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19544v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19544/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19544v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19544/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19544v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19544/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19544v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19544/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19544v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19544/x7.png"
      }
    ],
    "abstract_cn": "随着大型语言模型（LLMs）在软件开发中的应用日益广泛，研究人员对其生成代码的质量给予了高度关注。然而，现有研究多聚焦于HumanEval等受控数据集，未能全面反映开发者实际使用LLMs代码生成能力的真实情况，也未能深入剖析LLM生成代码在实际开发中的特性。为此，我们深入研究了LLM生成代码及其在GitHub上的项目特性，并揭示了以下关键发现：（1）ChatGPT和Copilot在GitHub上生成代码的使用频率最高，而其他LLMs生成的代码则寥寥无几。（2）包含ChatGPT/Copilot代码的项目多为小型且知名度不高，通常由个人或小团队主导，但多数项目持续进化与完善。（3）ChatGPT/Copilot主要用于生成Python、Java和TypeScript等数据处理脚本，以及C/C++和JavaScript中的算法与用户界面代码，且生成的代码片段大多简短、复杂度较低。（4）相较于人工编写的代码，ChatGPT/Copilot生成的代码在项目中占比小，修改次数也较少，因错误而修改的比例仅在3%至8%之间。（5）关于ChatGPT/Copilot生成代码的评论大多简略，仅提及代码来源，未涉及具体提示、人工修改或测试情况。基于这些发现，我们进一步探讨了其对研究与实践的深远影响。",
    "title_cn": "GitHub 上的大型语言模型，它们在代码生成方面表现如何？",
    "tags": [
      "LLM应用",
      "软件开发",
      "人工智能"
    ]
  },
  {
    "title": "Context Matters: An Empirical Study of the Impact of Contextual Information in Temporal Question Answering Systems",
    "submit_datetime": "2024年06月27日",
    "abstract": "Large language models (LLMs) often struggle with temporal reasoning, crucial for tasks like historical event analysis and time-sensitive information retrieval. Despite advancements, state-of-the-art models falter in handling temporal information, especially when faced with irrelevant or noisy contexts. This paper addresses this gap by empirically examining the robustness of temporal question-answering (TQA) systems trained on various context types, including relevant, irrelevant, slightly altered, and no context. Our findings indicate that training with a mix of these contexts enhances model robustness and accuracy. Additionally, we show that the position of context relative to the question significantly impacts performance, with question-first positioning yielding better results. We introduce two new context-rich TQA datasets, ContextAQA and ContextTQE, and provide comprehensive evaluations and guidelines for training robust TQA models. Our work lays the foundation for developing reliable and context-aware temporal QA systems, with broader implications for enhancing LLM robustness against diverse and potentially adversarial information.",
    "pdf_link": "https://arxiv.org/abs/2406.19538",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.19538v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19538/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.19538v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.19538/x2.png"
      }
    ],
    "abstract_cn": "大型语言模型在时间推理上常显疲态，这对历史事件分析和时效性信息检索等任务至关重要。即便技术日新月异，顶尖模型在处理时间信息时仍力不从心，尤其是在杂乱无章的上下文中。本文通过实证探索，揭示了在多样上下文（包括相关、无关、微调及无上下文）中训练的时间问答系统，其鲁棒性与准确性得以提升。我们更发现，问题前置的上下文布局能显著提升性能。为此，我们推出了ContextAQA与ContextTQE两大富含上下文的TQA数据集，并详尽阐述了训练指南，为构建可靠且敏感于上下文的时间问答系统奠定基石，同时也为提升LLM在复杂信息环境下的鲁棒性指明了方向。",
    "title_cn": "上下文至关重要：探究上下文信息对时间问答系统影响的实证研究",
    "tags": [
      "LLM应用",
      "",
      "信息检索"
    ]
  },
  {
    "title": "Development and Evaluation of a Retrieval-Augmented Generation Tool for Creating SAPPhIRE Models of Artificial Systems",
    "submit_datetime": "2024年06月27日",
    "abstract": "Representing systems using the SAPPhIRE causality model is found useful in supporting design-by-analogy. However, creating a SAPPhIRE model of artificial or biological systems is an effort-intensive process that requires human experts to source technical knowledge from multiple technical documents regarding how the system works. This research investigates how to leverage Large Language Models (LLMs) in creating structured descriptions of systems using the SAPPhIRE model of causality. This paper, the second part of the two-part research, presents a new Retrieval-Augmented Generation (RAG) tool for generating information related to SAPPhIRE constructs of artificial systems and reports the results from a preliminary evaluation of the tool's success - focusing on the factual accuracy and reliability of outcomes.",
    "pdf_link": "https://arxiv.org/abs/2406.19493",
    "graphs": [],
    "abstract_cn": "SAPPhIRE 因果模型在类比设计中表现出色，但构建其模型需专家从多文档中提取技术细节，过程繁琐。本研究探索了大型语言模型 (LLM) 在此模型中创建系统结构化描述的应用。作为系列研究的第二部分，本文介绍了一款新的检索增强生成 (RAG) 工具，旨在生成人工系统 SAPPhIRE 结构的相关信息，并初步评估了其生成内容的事实准确性与可靠性。",
    "title_cn": "我们开发并评估了一款检索增强生成工具，旨在助力人工系统 SAPPhIRE 模型的构建。",
    "tags": [
      "RAG",
      "制造业",
      "人工智能"
    ]
  },
  {
    "title": "Granite-Function Calling Model: Introducing Function Calling Abilities via Multi-task Learning of Granular Tasks",
    "submit_datetime": "2024年06月27日",
    "abstract": "Large language models (LLMs) have recently shown tremendous promise in serving as the backbone to agentic systems, as demonstrated by their performance in multi-faceted, challenging benchmarks like SWE-Bench and Agent-Bench. However, to realize the true potential of LLMs as autonomous agents, they must learn to identify, call, and interact with external tools and application program interfaces (APIs) to complete complex tasks. These tasks together are termed function calling. Endowing LLMs with function calling abilities leads to a myriad of advantages, such as access to current and domain-specific information in databases and knowledge sources, and the ability to outsource tasks that can be reliably performed by tools, e.g., a Python interpreter or calculator. While there has been significant progress in function calling with LLMs, there is still a dearth of open models that perform on par with proprietary LLMs like GPT, Claude, and Gemini. Therefore, in this work, we introduce the GRANITE-20B-FUNCTIONCALLING model under an Apache 2.0 license. The model is trained using a multi-task training approach on seven fundamental tasks encompassed in function calling, those being Nested Function Calling, Function Chaining, Parallel Functions, Function Name Detection, Parameter-Value Pair Detection, Next-Best Function, and Response Generation. We present a comprehensive evaluation on multiple out-of-domain datasets comparing GRANITE-20B-FUNCTIONCALLING to more than 15 other best proprietary and open models. GRANITE-20B-FUNCTIONCALLING provides the best performance among all open models on the Berkeley Function Calling Leaderboard and fourth overall. As a result of the diverse tasks and datasets used for training our model, we show that GRANITE-20B-FUNCTIONCALLING has better generalizability on multiple tasks in seven different evaluation datasets.",
    "pdf_link": "https://arxiv.org/abs/2407.00121",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.00121v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00121/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00121v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00121/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00121v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00121/hallucination-ood-new.png"
      }
    ],
    "abstract_cn": "近期，大型语言模型（LLM）在作为代理系统核心方面展现出显著潜力，尤其在SWE-Bench和Agent-Bench等复杂基准测试中表现突出。但要充分发挥LLM作为自主代理的能力，关键在于其能否有效识别、调用并交互外部工具与API，以应对复杂任务，这一过程统称为“函数调用”。赋予LLM此项能力，不仅可让其访问最新领域特定信息，还能将部分任务外包给可靠工具，如Python解释器或计算器。尽管LLM在函数调用领域进步显著，但开放模型与GPT、Claude等专有模型相比，性能仍有差距。为此，我们推出了基于Apache 2.0许可的GRANITE-20B-FUNCTIONCALLING模型，该模型通过多任务训练，涵盖了函数调用的七大基础任务。在多个域外数据集的评估中，GRANITE-20B-FUNCTIONCALLING不仅在开放模型中表现最佳，总体排名也跻身前四。得益于其训练所用的多样化任务与数据集，该模型在多个任务上展现出卓越的泛化能力。",
    "title_cn": "花岗岩功能调用模型：借助粒度任务的多任务学习，赋予功能调用新能力",
    "tags": [
      "Agent",
      "软件开发",
      "人工智能"
    ]
  },
  {
    "title": "From Efficient Multimodal Models to World Models: A Survey",
    "submit_datetime": "2024年06月27日",
    "abstract": "Multimodal Large Models (MLMs) are becoming a significant research focus, combining powerful large language models with multimodal learning to perform complex tasks across different data modalities. This review explores the latest developments and challenges in MLMs, emphasizing their potential in achieving artificial general intelligence and as a pathway to world models. We provide an overview of key techniques such as Multimodal Chain of Thought (M-COT), Multimodal Instruction Tuning (M-IT), and Multimodal In-Context Learning (M-ICL). Additionally, we discuss both the fundamental and specific technologies of multimodal models, highlighting their applications, input/output modalities, and design characteristics. Despite significant advancements, the development of a unified multimodal model remains elusive. We discuss the integration of 3D generation and embodied intelligence to enhance world simulation capabilities and propose incorporating external rule systems for improved reasoning and decision-making. Finally, we outline future research directions to address these challenges and advance the field.",
    "pdf_link": "https://arxiv.org/abs/2407.00118",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.00118v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00118/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00118v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00118/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00118v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00118/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00118v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00118/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00118v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00118/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00118v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00118/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00118v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00118/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00118v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00118/x8.png"
      }
    ],
    "abstract_cn": "多模态大型模型（MLMs）已成为研究热点，通过融合大型语言模型与多模态学习，跨越不同数据模态执行复杂任务。本文综述了MLMs的最新进展与挑战，强调其在通往人工通用智能和世界模型之路上的潜力。我们介绍了多模态思维链（M-COT）、多模态指令调优（M-IT）和多模态情境学习（M-ICL）等关键技术，并深入探讨了多模态模型的技术细节、应用场景及其设计特点。尽管成就斐然，但构建统一的多模态模型仍是一大难题。我们探讨了如何通过整合3D生成与具身智能来提升世界模拟能力，并建议引入外部规则系统以优化推理与决策。最后，我们指出了未来研究的方向，旨在克服这些挑战，推动领域进步。",
    "title_cn": "探索高效多模态模型至世界模型的演进：全面调查",
    "tags": [
      "LLM应用",
      "人工智能",
      "计算机视觉"
    ]
  },
  {
    "title": "Curriculum Learning with Quality-Driven Data Selection",
    "submit_datetime": "2024年06月27日",
    "abstract": "The impressive multimodal capabilities demonstrated by OpenAI's GPT-4 have generated significant interest in the development of Multimodal Large Language Models (MLLMs). Visual instruction tuning of MLLMs with machine-generated instruction-following data has shown to enhance zero-shot capabilities across various tasks. However, there has been limited exploration into controlling the quality of the instruction data.Current methodologies for data selection in MLLMs often rely on single, unreliable scores or use downstream tasks for selection, which is time-consuming and can lead to potential overfitting on the chosen evaluation datasets. To mitigate these limitations, we propose a novel data selection methodology that utilizes image-text correlation and model perplexity to evaluate and select data of varying quality. This approach leverages the distinct distribution of these two attributes, mapping data quality into a two-dimensional space that allows for the selection of data based on their location within this distribution. By utilizing this space, we can analyze the impact of task type settings, used as prompts, on data quality. Additionally, this space can be used to construct multi-stage subsets of varying quality to facilitate curriculum learning. Our research includes comprehensive experiments conducted on various datasets. The results emphasize substantial enhancements in five commonly assessed capabilities compared to using the complete dataset. Our codes, data, and models are publicly available at: \\url{https://anonymous.4open.science/r/EHIT-31B4}",
    "pdf_link": "https://arxiv.org/abs/2407.00102",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.00102v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00102/output_ab3_v2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00102v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00102/output_compare_01.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00102v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00102/output_compare_02.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00102v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00102/output_last_01.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00102v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00102/output_last_008.png"
      },
      {
        "url": "https://arxiv.org/html/2407.00102v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.00102/output_3c_detail-2.png"
      }
    ],
    "abstract_cn": "OpenAI的GPT-4以其卓越的跨模态能力，激发了对多模态大型语言模型（MLLMs）的研发热潮。通过机器生成的指令数据进行视觉指令调整，已证实能提升多任务的零-shot表现。然而，关于如何把控指令数据质量的研究尚浅。目前，MLLMs的数据选择多依赖于单一且不稳定的评分系统，或通过下游任务筛选，这些方法既耗时又易导致评估数据集的过拟合。为此，我们创新性地提出了一种数据选择策略，结合图像-文本相关性与模型困惑度，对数据质量进行多维度评估与筛选。这一策略将数据质量映射至二维空间，便于根据数据分布位置进行精准选择，并可探究任务类型提示对数据质量的影响。此外，该空间还能构建多阶段、多质量层次的数据子集，助力课程学习。我们在多个数据集上进行了详尽实验，结果显示，与全数据集相比，五项关键能力得到了显著提升。相关代码、数据及模型已公开分享，详情请访问：\\url{https://anonymous.4open.science/r/EHIT-31B4}",
    "title_cn": "基于质量驱动的数据选择进行课程学习",
    "tags": [
      "LLM应用",
      "人工智能",
      "机器学习"
    ]
  },
  {
    "title": "ColPali: Efficient Document Retrieval with Vision Language Models",
    "submit_datetime": "2024年06月27日",
    "abstract": "Documents are visually rich structures that convey information through text, as well as tables, figures, page layouts, or fonts. While modern document retrieval systems exhibit strong performance on query-to-text matching, they struggle to exploit visual cues efficiently, hindering their performance on practical document retrieval applications such as Retrieval Augmented Generation. To benchmark current systems on visually rich document retrieval, we introduce the Visual Document Retrieval Benchmark ViDoRe, composed of various page-level retrieving tasks spanning multiple domains, languages, and settings. The inherent shortcomings of modern systems motivate the introduction of a new retrieval model architecture, ColPali, which leverages the document understanding capabilities of recent Vision Language Models to produce high-quality contextualized embeddings solely from images of document pages. Combined with a late interaction matching mechanism, ColPali largely outperforms modern document retrieval pipelines while being drastically faster and end-to-end trainable.",
    "pdf_link": "https://arxiv.org/abs/2407.01449",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.01449v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01449/similarity_map_energy.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01449v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01449/final_architecture.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01449v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01449/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01449v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01449/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01449v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01449/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01449v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01449/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01449v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01449/similarity_map_kazakhstan.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01449v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01449/similarity_map_ferroelectrics.png"
      },
      {
        "url": "https://arxiv.org/html/2407.01449v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01449/energy_1.jpeg"
      },
      {
        "url": "https://arxiv.org/html/2407.01449v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01449/energy_2.jpeg"
      },
      {
        "url": "https://arxiv.org/html/2407.01449v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01449/energy_3.jpeg"
      },
      {
        "url": "https://arxiv.org/html/2407.01449v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01449/ai_1.jpeg"
      },
      {
        "url": "https://arxiv.org/html/2407.01449v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01449/ai_2.jpeg"
      },
      {
        "url": "https://arxiv.org/html/2407.01449v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01449/ai_3.jpeg"
      },
      {
        "url": "https://arxiv.org/html/2407.01449v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01449/healthcare_1.jpeg"
      },
      {
        "url": "https://arxiv.org/html/2407.01449v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01449/healthcare_2.jpeg"
      },
      {
        "url": "https://arxiv.org/html/2407.01449v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01449/healthcare_3.jpeg"
      },
      {
        "url": "https://arxiv.org/html/2407.01449v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01449/gov_1.jpeg"
      },
      {
        "url": "https://arxiv.org/html/2407.01449v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01449/gov_2.jpeg"
      },
      {
        "url": "https://arxiv.org/html/2407.01449v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01449/gov_3.jpeg"
      },
      {
        "url": "https://arxiv.org/html/2407.01449v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01449/shift_1.jpeg"
      },
      {
        "url": "https://arxiv.org/html/2407.01449v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01449/shift_2.jpeg"
      },
      {
        "url": "https://arxiv.org/html/2407.01449v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.01449/shift_3.jpeg"
      }
    ],
    "abstract_cn": "文档通过多种视觉元素如文本、表格和图表等传递信息。现代检索系统虽擅长文本匹配，却难以有效利用视觉线索，影响了其在实际应用中的表现。为此，我们推出了视觉文档检索基准 ViDoRe，涵盖多领域、多语言的页面级检索任务。鉴于现有系统的不足，我们设计了新型检索模型 ColPali，它借助先进的视觉语言模型，仅从文档图像中提取高质量嵌入，并结合后期交互匹配，不仅大幅提升检索性能，还实现了更快的速度和端到端的训练。",
    "title_cn": "ColPali：借助视觉语言模型，实现文档检索的高效性",
    "tags": [
      "RAG",
      "文档检索",
      "视觉处理"
    ]
  },
  {
    "title": "A Reflective LLM-based Agent to Guide Zero-shot Cryptocurrency Trading",
    "submit_datetime": "2024年06月27日",
    "abstract": "The utilization of Large Language Models (LLMs) in financial trading has primarily been concentrated within the stock market, aiding in economic and financial decisions. Yet, the unique opportunities presented by the cryptocurrency market, noted for its on-chain data's transparency and the critical influence of off-chain signals like news, remain largely untapped by LLMs. This work aims to bridge the gap by developing an LLM-based trading agent, CryptoTrade, which uniquely combines the analysis of on-chain and off-chain data. This approach leverages the transparency and immutability of on-chain data, as well as the timeliness and influence of off-chain signals, providing a comprehensive overview of the cryptocurrency market. CryptoTrade incorporates a reflective mechanism specifically engineered to refine its daily trading decisions by analyzing the outcomes of prior trading decisions. This research makes two significant contributions. Firstly, it broadens the applicability of LLMs to the domain of cryptocurrency trading. Secondly, it establishes a benchmark for cryptocurrency trading strategies. Through extensive experiments, CryptoTrade has demonstrated superior performance in maximizing returns compared to traditional trading strategies and time-series baselines across various cryptocurrencies and market conditions. Our code and data are available at \\url{https://anonymous.4open.science/r/CryptoTrade-Public-92FC/}.",
    "pdf_link": "https://arxiv.org/abs/2407.09546",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2407.09546v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09546/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09546v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09546/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09546v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09546/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09546v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09546/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09546v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09546/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09546v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09546/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2407.09546v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2407.09546/x7.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLM）在金融交易中的应用主要局限于股票市场，辅助经济和金融决策。然而，加密货币市场因其链上数据的透明度和链下信号（如新闻）的关键影响而呈现的独特机会，LLM 尚未充分利用。本研究通过开发基于 LLM 的交易代理 CryptoTrade，独特地结合链上和链下数据的分析，旨在弥合这一差距。CryptoTrade 利用链上数据的透明度和不可变性，以及链下信号的及时性和影响力，全面概览加密货币市场。此外，CryptoTrade 包含一个反射机制，通过分析先前交易决策的结果来优化每日交易决策。这项研究不仅扩展了 LLM 在加密货币交易领域的应用，还为加密货币交易策略设定了基准。通过广泛实验，CryptoTrade 在最大化回报方面相比传统交易策略和时间序列基准在各种加密货币和市场条件下展示了优越的性能。我们的代码和数据可在 \\url{https://anonymous.4open.science/r/CryptoTrade-Public-92FC/} 获取。",
    "title_cn": "基于 LLM 的反射代理，引领零-shot 加密货币交易之旅",
    "tags": [
      "Agent",
      "",
      "加密货币"
    ]
  },
  {
    "title": "AI-native Memory: A Pathway from LLMs Towards AGI",
    "submit_datetime": "2024年06月26日",
    "abstract": "Large language models (LLMs) have demonstrated the world with the sparks of artificial general intelligence (AGI). One opinion, especially from some startups working on LLMs, argues that an LLM with nearly unlimited context length can realize AGI. However, they might be too optimistic about the long-context capability of (existing) LLMs -- (1) Recent literature has shown that their effective context length is significantly smaller than their claimed context length; and (2) Our reasoning-in-a-haystack experiments further demonstrate that simultaneously finding the relevant information from a long context and conducting (simple) reasoning is nearly impossible. In this paper, we envision a pathway from LLMs to AGI through the integration of \\emph{memory}. We believe that AGI should be a system where LLMs serve as core processors. In addition to raw data, the memory in this system would store a large number of important conclusions derived from reasoning processes. Compared with retrieval-augmented generation (RAG) that merely processing raw data, this approach not only connects semantically related information closer, but also simplifies complex inferences at the time of querying. As an intermediate stage, the memory will likely be in the form of natural language descriptions, which can be directly consumed by users too. Ultimately, every agent/person should have its own large personal model, a deep neural network model (thus \\emph{AI-native}) that parameterizes and compresses all types of memory, even the ones cannot be described by natural languages. Finally, we discuss the significant potential of AI-native memory as the transformative infrastructure for (proactive) engagement, personalization, distribution, and social in the AGI era, as well as the incurred privacy and security challenges with preliminary solutions.",
    "pdf_link": "https://arxiv.org/abs/2406.18312",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.18312v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18312/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18312v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18312/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18312v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18312/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18312v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18312/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18312v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18312/x5.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）已初露人工通用智能（AGI）的端倪。一些专注于LLMs的初创公司认为，拥有近乎无限上下文长度的LLM能实现AGI。然而，他们对现有LLMs处理长上下文能力的乐观可能过于乐观——（1）最新研究表明，这些模型的实际有效上下文长度远低于其宣称；（2）我们的“干草堆中推理”实验揭示，从冗长上下文中提取相关信息并进行推理几乎不可能。本文提出，通过整合\\emph{记忆}，LLMs可迈向AGI。我们认为，AGI系统应以LLMs为核心，其记忆不仅存储原始数据，还应包含大量推理得出的关键结论。与仅处理原始数据的检索增强生成（RAG）相比，此方法不仅加强了语义关联，还简化了查询时的复杂推理。作为过渡，记忆将以自然语言描述形式存在，便于用户直接使用。最终，每个人都将拥有一个深度神经网络模型（AI原生），该模型能参数化和压缩所有类型的记忆，包括无法用自然语言描述的记忆。最后，我们探讨了AI原生记忆在AGI时代推动主动参与、个性化、分发和社会变革的潜力，以及随之而来的隐私和安全挑战及其初步解决方案。",
    "title_cn": "AI原生记忆：大型语言模型迈向通用人工智能的桥梁",
    "tags": [
      "LLM理论\n\n这篇论文探讨了大型语言模型（LLMs）在实现人工通用智能（AGI）方面的潜力，并提出了通过整合记忆来增强LLMs的方法。论文不仅讨论了现有LLMs在处理长上下文方面的局限性，还提出了一个理论框架，即通过记忆的整合来改进LLMs的性能，使其更接近AGI。这一讨论涉及了对LLMs理论层面的深入分析和改进建议，因此属于LLM理论分类。",
      "人工智能",
      "通用智能"
    ]
  },
  {
    "title": "Symbolic Learning Enables Self-Evolving Agents",
    "submit_datetime": "2024年06月26日",
    "abstract": "The AI community has been exploring a pathway to artificial general intelligence (AGI) by developing \"language agents\", which are complex large language models (LLMs) pipelines involving both prompting techniques and tool usage methods. While language agents have demonstrated impressive capabilities for many real-world tasks, a fundamental limitation of current language agents research is that they are model-centric, or engineering-centric. That's to say, the progress on prompts, tools, and pipelines of language agents requires substantial manual engineering efforts from human experts rather than automatically learning from data. We believe the transition from model-centric, or engineering-centric, to data-centric, i.e., the ability of language agents to autonomously learn and evolve in environments, is the key for them to possibly achieve AGI.\n  In this work, we introduce agent symbolic learning, a systematic framework that enables language agents to optimize themselves on their own in a data-centric way using symbolic optimizers. Specifically, we consider agents as symbolic networks where learnable weights are defined by prompts, tools, and the way they are stacked together. Agent symbolic learning is designed to optimize the symbolic network within language agents by mimicking two fundamental algorithms in connectionist learning: back-propagation and gradient descent. Instead of dealing with numeric weights, agent symbolic learning works with natural language simulacrums of weights, loss, and gradients. We conduct proof-of-concept experiments on both standard benchmarks and complex real-world tasks and show that agent symbolic learning enables language agents to update themselves after being created and deployed in the wild, resulting in \"self-evolving agents\".",
    "pdf_link": "https://arxiv.org/abs/2406.18532",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.18532v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18532/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18532v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18532/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18532v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18532/x3.png"
      }
    ],
    "abstract_cn": "人工智能领域正通过开发“语言代理”这一复杂的大型语言模型（LLMs）管道，探索通往人工通用智能（AGI）的道路。这些代理结合了提示技术和工具使用方法，展现出在多种实际任务中的强大能力。然而，当前的研究主要集中在模型或工程层面，依赖于专家的手动调整，而非自动从数据中学习。我们认为，要实现AGI，关键在于语言代理能够自主在环境中学习和进化，即从模型或工程驱动转向数据驱动。为此，我们提出了代理符号学习框架，它允许语言代理以数据为中心的方式自我优化。我们将代理视为由提示、工具及其组合方式定义权重的符号网络，并通过模拟反向传播和梯度下降算法来优化这些网络。与传统的数值权重处理不同，我们的方法使用自然语言来模拟权重、损失和梯度。通过在标准和复杂任务上的实验，我们证明了代理符号学习能够使语言代理在部署后自我进化，成为“自我进化的代理”。",
    "title_cn": "符号学习赋能自进化代理。",
    "tags": [
      "Agent\n\n这篇论文主要探讨了如何通过开发“语言代理”这一复杂的大型语言模型（LLMs）管道来实现人工通用智能（AGI）。论文提出了一个代理符号学习框架，该框架允许语言代理以数据为中心的方式自我优化，从而实现自主学习和进化。这种方法将代理视为由提示、工具及其组合方式定义权重的符号网络，并通过模拟反向传播和梯度下降算法来优化这些网络。因此，这篇论文的内容更符合Agent分类，因为它专注于开发和优化能够自主学习和进化的语言代理。",
      "人工智能",
      "机器学习"
    ]
  },
  {
    "title": "Mental Modeling of Reinforcement Learning Agents by Language Models",
    "submit_datetime": "2024年06月26日",
    "abstract": "Can emergent language models faithfully model the intelligence of decision-making agents? Though modern language models exhibit already some reasoning ability, and theoretically can potentially express any probable distribution over tokens, it remains underexplored how the world knowledge these pretrained models have memorized can be utilized to comprehend an agent's behaviour in the physical world. This study empirically examines, for the first time, how well large language models (LLMs) can build a mental model of agents, termed agent mental modelling, by reasoning about an agent's behaviour and its effect on states from agent interaction history. This research may unveil the potential of leveraging LLMs for elucidating RL agent behaviour, addressing a key challenge in eXplainable reinforcement learning (XRL). To this end, we propose specific evaluation metrics and test them on selected RL task datasets of varying complexity, reporting findings on agent mental model establishment. Our results disclose that LLMs are not yet capable of fully mental modelling agents through inference alone without further innovations. This work thus provides new insights into the capabilities and limitations of modern LLMs.",
    "pdf_link": "https://arxiv.org/abs/2406.18505",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.18505v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18505/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18505v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18505/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18505v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18505/mc_average_matching_rates_comparing_llms.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18505v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18505/ac_average_matching_rates_comparing_llms.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18505v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18505/pen_average_matching_rates_comparing_llms_no_bins.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18505v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18505/pen_average_matching_rates_conti_action_bins_bar_plot_3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18505v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18505/mc_average_matching_rates_state_elements_llms_enlarged_3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18505v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18505/all_average_matching_rates_bar_plot_enlarged_2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18505v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18505/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18505v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18505/pen_average_matching_rates_state_elements_llms_enlarged.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18505v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18505/ac_average_matching_rates_state_elements_llms_enlarged.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18505v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18505/ll_average_matching_rates_state_elements_llms.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18505v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18505/mc_average_matching_rates_bar_plot_individual_state_elements_llms.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18505v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18505/pen_average_matching_rates_bar_plot_individual_state_elements_llms.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18505v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18505/ac_average_matching_rates_bar_plot_individual_state_elements_llms.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18505v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18505/ll_average_matching_rates_bar_plot_individual_state_elements_llms.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18505v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18505/mc_average_matching_rates_all_llms.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18505v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18505/ac_average_matching_rates_all_llms.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18505v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18505/pen_average_matching_rates_all_llms_bins.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18505v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18505/pen_average_matching_rates_all_llms_no_bins.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18505v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18505/ll_average_matching_rates_all_llms.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18505v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18505/pen_average_matching_rates_comparing_llms_bins.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18505v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18505/mc_average_matching_rates_comparing_gpt_no_dynamics.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18505v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18505/mc_average_matching_rates_comparing_gpt_no_instruction.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18505v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18505/mc_average_matching_rates_comparing_llama3_8b_no_instruction.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18505v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18505/ac_average_matching_rates_comparing_gpt_no_instruction.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18505v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18505/ac_average_matching_rates_comparing_llama3_8b_no_instruction.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18505v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18505/pen_average_matching_rates_comparing_gpt_bins_no_instruction.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18505v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18505/pen_average_matching_rates_comparing_llama3_8b_bins_no_instruction.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18505v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18505/pen_average_matching_rates_comparing_gpt_no_bins_no_instruction.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18505v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18505/pen_average_matching_rates_comparing_llama3_8b_no_bins_no_instruction.png"
      }
    ],
    "abstract_cn": "新兴的语言模型能否准确模拟决策代理的智能？尽管现代语言模型已具备一定的推理能力，理论上能表达任何标记的概率分布，但如何运用这些模型所记忆的世界知识来理解物理世界中代理的行为，仍是一个未解之谜。本研究首次实证探讨了大型语言模型（LLMs）如何通过分析代理行为及其对状态的影响，从交互历史中构建代理的心理模型，即代理心理建模。此研究有望揭示LLMs在阐明强化学习代理行为方面的潜力，为可解释强化学习（XRL）的关键难题提供解决方案。为此，我们设计了特定的评估指标，并在不同复杂度的RL任务数据集上进行了测试，揭示了LLMs在建立代理心理模型方面的局限性。结果显示，LLMs尚不能仅凭推理完全心理建模代理，仍需创新突破。这项研究为我们理解现代LLMs的能力与局限提供了新的视角。",
    "title_cn": "语言模型构建强化学习代理的心智模型",
    "tags": [
      "Agent\n\n理由：这篇论文主要探讨了大型语言模型（LLMs）如何通过分析代理行为及其对状态的影响，从交互历史中构建代理的心理模型。研究的重点是理解语言模型如何模拟和解释决策代理的智能行为，特别是在强化学习（RL）环境中的应用。因此，这篇论文更符合Agent分类，因为它关注的是语言模型在理解和模拟代理行为方面的应用和挑战。",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Role-Play Zero-Shot Prompting with Large Language Models for Open-Domain Human-Machine Conversation",
    "submit_datetime": "2024年06月26日",
    "abstract": "Recently, various methods have been proposed to create open-domain conversational agents with Large Language Models (LLMs). These models are able to answer user queries, but in a one-way Q&A format rather than a true conversation. Fine-tuning on particular datasets is the usual way to modify their style to increase conversational ability, but this is expensive and usually only available in a few languages. In this study, we explore role-play zero-shot prompting as an efficient and cost-effective solution for open-domain conversation, using capable multilingual LLMs (Beeching et al., 2023) trained to obey instructions. We design a prompting system that, when combined with an instruction-following model - here Vicuna (Chiang et al., 2023) - produces conversational agents that match and even surpass fine-tuned models in human evaluation in French in two different tasks.",
    "pdf_link": "https://arxiv.org/abs/2406.18460",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.18460v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18460/sigdial_architecture.drawio-3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18460v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18460/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18460v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18460/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18460v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18460/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18460v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18460/x4.png"
      }
    ],
    "abstract_cn": "近期，研究者们提出了多种方法，利用大型语言模型（LLMs）打造开放领域的对话系统。尽管这些模型能回应用户提问，但互动模式仍局限于单向问答，缺乏真正的对话交流。传统上，通过特定数据集的微调来提升模型的对话技巧，但此法成本高且适用语言有限。本研究中，我们采用角色扮演零-shot提示策略，结合遵循指令的多语言LLMs（Beeching等人，2023年），探索了一种高效经济的开放领域对话解决方案。我们设计的提示系统与Vicuna模型（Chiang等人，2023年）相结合，生成的对话代理在法语环境下的人类评估中，不仅与微调模型持平，甚至在两个不同任务上超越了它们。",
    "title_cn": "利用大型语言模型实现开放领域人机对话的角色扮演零-shot提示技术",
    "tags": [
      "Agent\n\n理由：这篇论文主要探讨了如何利用大型语言模型（LLMs）来创建一个能够在开放领域进行对话的代理（Agent）。通过角色扮演零-shot提示策略和多语言LLMs，研究者们设计了一个对话系统，该系统能够在法语环境下进行有效的对话交流，并在人类评估中表现出色。这与Agent的定义相符，即一个能够代表用户执行任务或进行交互的系统。此外，论文中提到的“对话代理”直接表明了其Agent的属性。因此，这篇论文应归类为Agent。",
      "对话系统",
      "多语言交流"
    ]
  },
  {
    "title": "LLCoach: Generating Robot Soccer Plans using Multi-Role Large Language Models",
    "submit_datetime": "2024年06月26日",
    "abstract": "The deployment of robots into human scenarios necessitates advanced planning strategies, particularly when we ask robots to operate in dynamic, unstructured environments. RoboCup offers the chance to deploy robots in one of those scenarios, a human-shaped game represented by a soccer match. In such scenarios, robots must operate using predefined behaviors that can fail in unpredictable conditions. This paper introduces a novel application of Large Language Models (LLMs) to address the challenge of generating actionable plans in such settings, specifically within the context of the RoboCup Standard Platform League (SPL) competitions where robots are required to autonomously execute soccer strategies that emerge from the interactions of individual agents. In particular, we propose a multi-role approach leveraging the capabilities of LLMs to generate and refine plans for a robotic soccer team. The potential of the proposed method is demonstrated through an experimental evaluation,carried out simulating multiple matches where robots with AI-generated plans play against robots running human-built code.",
    "pdf_link": "https://arxiv.org/abs/2406.18285",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.18285v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18285/into_image.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18285v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18285/Process_horizontal.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18285v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18285/action_2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18285v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18285/simrobot2.png"
      }
    ],
    "abstract_cn": "在动态多变的非结构化环境中部署机器人，需要精妙的规划策略。RoboCup 的足球赛为机器人提供了一个模拟人类活动的舞台。在此类场景中，机器人依赖的预设行为在未知变数面前可能失效。本文创新性地运用大型语言模型（LLMs），旨在为 RoboCup 标准平台联赛（SPL）中的机器人足球队制定策略，使其能自主应对个体代理间的互动变化。我们提出了一种多角色策略，利用 LLMs 的强大功能，为机器人足球队制定和优化战术。通过模拟比赛，我们验证了这种方法的潜力，展示了 AI 规划的机器人与人类编码的机器人之间的较量。",
    "title_cn": "LLCoach：借助多角色大型语言模型，巧妙制定机器人足球策略",
    "tags": [
      "Agent\n\n理由：这篇论文主要关注的是在动态多变的非结构化环境中，如何利用大型语言模型（LLMs）为机器人制定策略，以应对个体代理间的互动变化。这涉及到机器人的自主行为和决策，属于Agent的范畴。虽然文中提到了LLMs的应用，但核心在于机器人的行为和策略制定，而非LLMs的理论研究或特定应用。因此，将其归类为Agent更为合适。",
      "机器人技术",
      "人工智能"
    ]
  },
  {
    "title": "CharXiv: Charting Gaps in Realistic Chart Understanding in Multimodal LLMs",
    "submit_datetime": "2024年06月26日",
    "abstract": "Chart understanding plays a pivotal role when applying Multimodal Large Language Models (MLLMs) to real-world tasks such as analyzing scientific papers or financial reports. However, existing datasets often focus on oversimplified and homogeneous charts with template-based questions, leading to an over-optimistic measure of progress. We demonstrate that although open-source models can appear to outperform strong proprietary models on these benchmarks, a simple stress test with slightly different charts or questions can deteriorate performance by up to 34.5%. In this work, we propose CharXiv, a comprehensive evaluation suite involving 2,323 natural, challenging, and diverse charts from arXiv papers. CharXiv includes two types of questions: 1) descriptive questions about examining basic chart elements and 2) reasoning questions that require synthesizing information across complex visual elements in the chart. To ensure quality, all charts and questions are handpicked, curated, and verified by human experts. Our results reveal a substantial, previously underestimated gap between the reasoning skills of the strongest proprietary model (i.e., GPT-4o), which achieves 47.1% accuracy, and the strongest open-source model (i.e., InternVL Chat V1.5), which achieves 29.2%. All models lag far behind human performance of 80.5%, underscoring weaknesses in the chart understanding capabilities of existing MLLMs. We hope CharXiv facilitates future research on MLLM chart understanding by providing a more realistic and faithful measure of progress. Project page and leaderboard: https://charxiv.github.io/",
    "pdf_link": "https://arxiv.org/abs/2406.18521",
    "graphs": [],
    "abstract_cn": "在应用多模态大型语言模型（MLLMs）于实际任务，如科学论文或财务报告分析时，图表理解至关重要。但现有数据集多聚焦于简化且单一的图表和模板问题，导致对进展的评估过于乐观。我们发现，开源模型虽在基准测试中表现出色，但面对稍有变化的图表或问题，性能可能骤降34.5%。为此，我们推出了CharXiv，一个包含2,323个来自arXiv的复杂多样图表的评估平台。CharXiv涵盖两类问题：描述性问题关注图表基础元素，推理问题则需整合复杂视觉信息。所有内容均由专家精心筛选和验证。结果显示，最强专有模型（如GPT-4o）的推理准确率为47.1%，而最强开源模型（如InternVL Chat V1.5）为29.2%，均远低于人类80.5%的水平，揭示了MLLMs在图表理解上的短板。我们期待CharXiv能通过提供更真实的评估，推动MLLM图表理解研究的发展。项目详情及排行榜请访问：https://charxiv.github.io/",
    "title_cn": "CharXiv：揭示多模态LLMs在现实图表理解上的盲点",
    "tags": [
      "LLM应用\n\n这篇论文主要关注多模态大型语言模型（MLLMs）在实际任务中的应用，特别是在图表理解方面的挑战和评估。论文通过介绍一个新的评估平台CharXiv，旨在提供更真实的评估环境，以推动MLLM在图表理解方面的发展。这表明论文的重点在于应用层面，即如何改进和评估MLLMs在特定任务（如科学论文或财务报告分析中的图表理解）中的表现，因此属于LLM应用分类。",
      "科学研究",
      "财务分析"
    ]
  },
  {
    "title": "S3: A Simple Strong Sample-effective Multimodal Dialog System",
    "submit_datetime": "2024年06月26日",
    "abstract": "In this work, we present a conceptually simple yet powerful baseline for the multimodal dialog task, an S3 model, that achieves near state-of-the-art results on two compelling leaderboards: MMMU and AI Journey Contest 2023. The system is based on a pre-trained large language model, pre-trained modality encoders for image and audio, and a trainable modality projector. The proposed effective data mixture for training such an architecture demonstrates that a multimodal model based on a strong language model and trained on a small amount of multimodal data can perform efficiently in the task of multimodal dialog.",
    "pdf_link": "https://arxiv.org/abs/2406.18305",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.18305v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18305/mutimodal_dialog.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18305v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18305/scheme.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18305v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18305/projector.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18305v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18305/scatter.png"
      }
    ],
    "abstract_cn": "本研究介绍了一种简洁而强大的多模态对话基准模型S3，该模型在MMMU和AI Journey Contest 2023两大排行榜上表现卓越。该模型整合了预训练的大型语言模型、图像与音频的预训练编码器及可调模态投影器。实验证明，通过精心设计的数据混合训练，即使使用有限的多模态数据，基于强大语言模型的多模态系统也能在对话任务中展现出高效性能。",
    "title_cn": "S3：简洁高效的多模态对话系统，样本利用率极高",
    "tags": [
      "LLM应用\n\n理由：该论文摘要描述了一种多模态对话基准模型S3，该模型整合了预训练的大型语言模型（LLM）、图像与音频的预训练编码器及可调模态投影器，并在多模态任务中表现出色。这表明该研究是关于如何应用LLM技术来提升多模态对话系统的性能，因此属于LLM的应用领域。",
      "对话系统",
      "多模态学习"
    ]
  },
  {
    "title": "Foundational Models for Pathology and Endoscopy Images: Application for Gastric Inflammation",
    "submit_datetime": "2024年06月26日",
    "abstract": "The integration of artificial intelligence (AI) in medical diagnostics represents a significant advancement in managing upper gastrointestinal (GI) cancer, a major cause of global cancer mortality. Specifically for gastric cancer (GC), chronic inflammation causes changes in the mucosa such as atrophy, intestinal metaplasia (IM), dysplasia and ultimately cancer. Early detection through endoscopic regular surveillance is essential for better outcomes. Foundation models (FM), which are machine or deep learning models trained on diverse data and applicable to broad use cases, offer a promising solution to enhance the accuracy of endoscopy and its subsequent pathology image analysis. This review explores the recent advancements, applications, and challenges associated with FM in endoscopy and pathology imaging. We started by elucidating the core principles and architectures underlying these models, including their training methodologies and the pivotal role of large-scale data in developing their predictive capabilities. Moreover, this work discusses emerging trends and future research directions, emphasizing the integration of multimodal data, the development of more robust and equitable models, and the potential for real-time diagnostic support. This review aims to provide a roadmap for researchers and practitioners in navigating the complexities of incorporating FM into clinical practice for prevention/management of GC cases, thereby improving patient outcomes.",
    "pdf_link": "https://arxiv.org/abs/2406.18249",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.18249v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18249/The-Correa-Cascade.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18249v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18249/Overview-taxonomy.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18249v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18249/Future-AI-Summary-V2.png"
      }
    ],
    "abstract_cn": "人工智能（AI）的融入极大地推动了上消化道癌症的管理，这是全球癌症死亡的主因之一。尤其在胃癌（GC）领域，慢性炎症引发的黏膜变化，如萎缩、肠上皮化生（IM）、异型增生，最终可能导致癌症。内镜常规监测的早期发现对改善预后至关重要。基础模型（FM），这些在多样数据上训练的机器或深度学习模型，为提升内镜及病理图像分析的准确性提供了希望。本文深入探讨了FM在胃肠镜和病理成像领域的最新进展、应用及挑战，并阐述了这些模型的核心原理、架构及其训练方法，强调了大规模数据在其预测能力开发中的关键作用。同时，本文还展望了未来研究方向，包括多模态数据的整合、更强大和公平模型的开发，以及实时诊断支持的潜力。本综述旨在为研究者和临床医生提供指导，帮助他们将FM融入临床实践，有效预防和管理GC，从而提升患者的生活质量。",
    "title_cn": "胃炎诊断新视角：病理与内窥镜图像的基础模型应用",
    "tags": [
      "Agent\n\n这篇论文主要探讨了基础模型（FM）在胃肠镜和病理成像领域的应用，特别是在上消化道癌症管理中的作用，特别是在胃癌（GC）的早期发现和预后改善方面。论文详细讨论了这些模型的核心原理、架构、训练方法以及大规模数据在其预测能力开发中的关键作用。此外，论文还展望了未来的研究方向，包括多模态数据的整合、更强大和公平模型的开发，以及实时诊断支持的潜力。这些内容更符合Agent分类，因为它们涉及模型在特定领域（如医疗诊断）的应用和功能，而不是理论研究或特定技术（如RAG或LLM）的深入探讨。",
      "",
      "人工智能"
    ]
  },
  {
    "title": "MammothModa: Multi-Modal Large Language Model",
    "submit_datetime": "2024年06月26日",
    "abstract": "In this report, we introduce MammothModa, yet another multi-modal large language model (MLLM) designed to achieve state-of-the-art performance starting from an elementary baseline. We focus on three key design insights: (i) Integrating Visual Capabilities while Maintaining Complex Language Understanding: In addition to the vision encoder, we incorporated the Visual Attention Experts into the LLM to enhance its visual capabilities. (ii) Extending Context Window for High-Resolution and Long-Duration Visual Feature: We explore the Visual Merger Module to effectively reduce the token number of high-resolution images and incorporated frame position ids to avoid position interpolation. (iii) High-Quality Bilingual Datasets: We meticulously curated and filtered a high-quality bilingual multimodal dataset to reduce visual hallucinations. With above recipe we build MammothModa that consistently outperforms the state-of-the-art models, e.g., LLaVA-series, across main real-world visual language benchmarks without bells and whistles.",
    "pdf_link": "https://arxiv.org/abs/2406.18193",
    "graphs": [],
    "abstract_cn": "本报告介绍了 MammothModa，一款旨在从基础水平跃升至顶尖性能的多模态大型语言模型。我们的设计重点有三：首先，通过整合视觉注意力专家，我们在保持语言理解深度的同时，强化了模型的视觉处理能力；其次，通过视觉合并模块和帧位置标识，我们扩展了上下文窗口，以适应高分辨率和长时视觉特征，避免了位置插值的问题；最后，我们精心筛选了一个高质量的双语多模态数据集，以减少视觉幻觉。凭借这些策略，MammothModa 在无任何额外修饰的情况下，已在多个真实世界的视觉语言基准测试中超越了如 LLaVA 系列等顶尖模型。",
    "title_cn": "巨象时尚：多模态大型语言模型",
    "tags": [
      "LLM应用\n\n理由：这篇论文介绍了一款名为MammothModa的多模态大型语言模型，并详细阐述了其设计特点和性能提升策略。论文中提到的模型通过整合视觉注意力专家、扩展上下文窗口以及使用高质量的双语多模态数据集等方法，在视觉语言任务中取得了优异的表现。这些内容主要关注于大型语言模型的应用层面，即如何通过技术改进和数据优化来提升模型的实际应用性能，因此归类为LLM应用。",
      "人工智能",
      "多模态学习"
    ]
  },
  {
    "title": "Multimodal Reaching-Position Prediction for ADL Support Using Neural Networks",
    "submit_datetime": "2024年06月26日",
    "abstract": "This study aimed to develop daily living support robots for patients with hemiplegia and the elderly. To support the daily living activities using robots in ordinary households without imposing physical and mental burdens on users, the system must detect the actions of the user and move appropriately according to their motions.\n  We propose a reaching-position prediction scheme that targets the motion of lifting the upper arm, which is burdensome for patients with hemiplegia and the elderly in daily living activities.\n  For this motion, it is difficult to obtain effective features to create a prediction model in environments where large-scale sensor system installation is not feasible and the motion time is short.\n  We performed motion-collection experiments, revealed the features of the target motion and built a prediction model using the multimodal motion features and deep learning.\n  The proposed model achieved an accuracy of 93 \\% macro average and F1-score of 0.69 for a 9-class classification prediction at 35\\% of the motion completion.",
    "pdf_link": "https://arxiv.org/abs/2406.18162",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.18162v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18162/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18162v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18162/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18162v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18162/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18162v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18162/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18162v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18162/x5.png"
      }
    ],
    "abstract_cn": "本研究致力于为半身不遂患者及老年人打造日常生活辅助机器人。为确保在普通家庭中使用机器人辅助日常活动时，不增加用户的身心负担，系统需能精准识别用户动作并随之灵活移动。我们提出了一种针对上臂抬起动作的预测机制，这一动作对半身不遂患者及老年人而言颇具挑战。在无法部署大型传感器系统且动作时间短暂的环境中，构建有效的预测模型面临特征提取的难题。通过动作收集实验，我们揭示了目标动作的关键特征，并运用多模态动作数据与深度学习技术，成功构建了预测模型。该模型在动作完成35%时，达到了93%的宏观平均准确率和0.69的F1分数，适用于9类动作的分类预测。",
    "title_cn": "神经网络助力多模态预测，精准定位日常生活活动所需位置",
    "tags": [
      "Agent\n\n理由：这篇论文主要关注的是为半身不遂患者及老年人设计的日常生活辅助机器人，这是一个具体的Agent（代理）应用，即一个能够执行特定任务（如识别用户动作并辅助日常活动）的智能系统。论文中提到的预测机制和构建的预测模型都是为了增强这个Agent的性能和适应性，使其能够更好地服务于其目标用户群体。因此，这篇论文属于Agent分类。",
      "",
      "辅助机器人"
    ]
  },
  {
    "title": "A Refer-and-Ground Multimodal Large Language Model for Biomedicine",
    "submit_datetime": "2024年06月26日",
    "abstract": "With the rapid development of multimodal large language models (MLLMs), especially their capabilities in visual chat through refer and ground functionalities, their significance is increasingly recognized. However, the biomedical field currently exhibits a substantial gap in this area, primarily due to the absence of a dedicated refer and ground dataset for biomedical images. To address this challenge, we devised the Med-GRIT-270k dataset. It comprises 270k question-and-answer pairs and spans eight distinct medical imaging modalities. Most importantly, it is the first dedicated to the biomedical domain and integrating refer and ground conversations. The key idea is to sample large-scale biomedical image-mask pairs from medical segmentation datasets and generate instruction datasets from text using chatGPT. Additionally, we introduce a Refer-and-Ground Multimodal Large Language Model for Biomedicine (BiRD) by using this dataset and multi-task instruction learning. Extensive experiments have corroborated the efficacy of the Med-GRIT-270k dataset and the multi-modal, fine-grained interactive capabilities of the BiRD model. This holds significant reference value for the exploration and development of intelligent biomedical assistants.",
    "pdf_link": "https://arxiv.org/abs/2406.18146",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.18146v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18146/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18146v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18146/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18146v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18146/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18146v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18146/hullu.png"
      }
    ],
    "abstract_cn": "随着多模态大型语言模型（MLLMs）的迅速发展，尤其是在视觉聊天中利用refer和ground功能的能力，其重要性日益凸显。然而，生物医学领域在这一方面存在显著空白，主要原因是缺乏专为生物医学图像设计的refer和ground数据集。为此，我们开发了Med-GRIT-270k数据集，包含270,000个问答对，覆盖八种医学成像模式，并首次专注于生物医学领域，整合了refer和ground对话。我们通过从医学分割数据集中提取大规模生物医学图像-掩码对，并利用chatGPT生成文本指令数据集，实现了这一创新。此外，我们还推出了名为BiRD的Refer-and-Ground多模态大型语言模型，通过多任务指令学习，该模型展现出卓越的多模态和细粒度交互能力。这些成果对于智能生物医学助手的研究和开发具有重要的参考价值。",
    "title_cn": "生物医学领域的新星：参考与定位多模态大型语言模型",
    "tags": [
      "RAG\n\n理由：这篇论文主要介绍了在生物医学领域开发的多模态大型语言模型（MLLMs），特别是通过创建新的数据集Med-GRIT-270k和开发名为BiRD的模型，来增强在视觉聊天中的refer和ground功能。这些工作集中在增强模型的多模态理解和交互能力，特别是在生物医学图像处理方面。因此，这更符合RAG（检索增强生成）的分类，因为它涉及通过特定领域的数据集增强模型的理解和生成能力。",
      "生物医学",
      "医疗成像"
    ]
  },
  {
    "title": "LOOK-M: Look-Once Optimization in KV Cache for Efficient Multimodal Long-Context Inference",
    "submit_datetime": "2024年06月26日",
    "abstract": "Long-context Multimodal Large Language Models (MLLMs) demand substantial computational resources for inference as the growth of their multimodal Key-Value (KV) cache, in response to increasing input lengths, challenges memory and time efficiency. Unlike single-modality LLMs that manage only textual contexts, the KV cache of long-context MLLMs includes representations from multiple images with temporal and spatial relationships and related textual contexts. The predominance of image tokens means traditional optimizations for LLMs' KV caches are unsuitable for multimodal long-context settings, and no prior works have addressed this challenge. In this work, we introduce LOOK-M, a pioneering, fine-tuning-free approach that efficiently reduces the multimodal KV cache size while maintaining performance comparable to a full cache. We observe that during prompt prefill, the model prioritizes more textual attention over image features, and based on the multimodal interaction observation, a new proposed text-prior method is explored to compress the KV cache. Furthermore, to mitigate the degradation of image contextual information, we propose several compensatory strategies using KV pairs merging. LOOK-M demonstrates that with a significant reduction in KV Cache memory usage, such as reducing it by 80% in some cases, it not only achieves up to 1.5x faster decoding but also maintains or even enhances performance across a variety of long context multimodal tasks.",
    "pdf_link": "https://arxiv.org/abs/2406.18139",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.18139v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18139/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18139v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18139/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18139v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18139/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18139v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18139/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18139v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18139/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18139v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18139/x6.png"
      }
    ],
    "abstract_cn": "长上下文多模态大型语言模型（MLLMs）在推理时因多模态键值（KV）缓存的增长而面临内存和时间效率的挑战。与仅处理文本的LLMs不同，MLLMs的KV缓存需处理包含时间及空间关系的图像与文本信息。由于图像令牌的主导地位，传统LLMs的KV缓存优化方法在此不适用。本研究中，我们推出了LOOK-M，一种无需微调的创新方法，能有效缩减多模态KV缓存大小，同时保持性能。我们发现，在提示预填充阶段，模型更侧重于文本而非图像特征，并据此提出了一种新的文本优先压缩方法。为减少图像上下文信息的损失，我们还设计了KV对合并的补偿策略。LOOK-M在大幅减少KV缓存内存使用的同时，如某些情况下减少80%，不仅加速解码达1.5倍，还在多种长上下文多模态任务中保持或提升了性能。",
    "title_cn": "LOOK-M：通过一次性优化KV缓存，实现多模态长上下文推理的高效性",
    "tags": [
      "LLM应用\n\n这篇论文主要关注长上下文多模态大型语言模型（MLLMs）在处理多模态键值（KV）缓存时的内存和时间效率问题。论文提出了一种名为LOOK-M的新方法，该方法能够有效缩减多模态KV缓存的大小，同时保持或提升模型性能。这种方法特别针对MLLMs在处理图像和文本信息时的挑战，通过优化KV缓存的使用，实现了内存使用的显著减少和解码速度的提升。因此，这篇论文属于LLM应用类别，因为它专注于改进和优化大型语言模型在特定应用场景下的性能。",
      "多模态学习",
      "人工智能"
    ]
  },
  {
    "title": "The Surprising Effectiveness of Multimodal Large Language Models for Video Moment Retrieval",
    "submit_datetime": "2024年06月26日",
    "abstract": "Recent studies have shown promising results in utilizing multimodal large language models (MLLMs) for computer vision tasks such as object detection and semantic segmentation. However, many challenging video tasks remain under-explored. Video-language tasks necessitate spatial and temporal comprehension and require significant compute. Therefore, prior works have developed complex, highly specialized architectures or leveraged additional input signals such as video transcripts to best encode contextual and temporal information, which limits their generality and can be impractical. One particularly challenging task is video moment retrieval, which requires precise temporal and contextual grounding. This work demonstrates the surprising effectiveness of leveraging image-text pretrained MLLMs for moment retrieval. We introduce Mr. BLIP (Mr. as in Moment Retrieval), a multimodal, single-stage model that requires no expensive video-language pretraining, no additional input signal (e.g., no transcript or audio), and has a simpler and more versatile design than prior state-of-the-art methods. We achieve a new state-of-the-art in moment retrieval on the widely used benchmarks Charades-STA, QVHighlights, and ActivityNet Captions and illustrate our method's versatility with a new state-of-the-art in temporal action localization on ActivityNet. Notably, we attain over 9% (absolute) higher Recall (at 0.5 and 0.7 IoU) on the challenging long-video multi-moment QVHighlights benchmark. Our code is publicly available.",
    "pdf_link": "https://arxiv.org/abs/2406.18113",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.18113v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18113/comparison_to_prev_work_3_4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18113v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18113/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18113v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18113/Architecture-v4_2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18113v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18113/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18113v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18113/Q_Results-1_4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18113v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18113/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18113v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18113/QVH-1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18113v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18113/QVH-2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18113v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18113/QVH-3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18113v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18113/QVH-4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18113v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18113/QVH-5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18113v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18113/QVH-6.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18113v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18113/Charades-3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18113v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18113/Charades-5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18113v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18113/Charades-6.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18113v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18113/Charades-7.png"
      }
    ],
    "abstract_cn": "近期研究显示，多模态大型语言模型（MLLMs）在物体检测和语义分割等计算机视觉任务中展现出巨大潜力。尽管如此，许多视频任务仍未被充分研究。视频语言任务对时空理解有高要求，且计算成本高昂。以往研究多采用复杂架构或依赖额外输入（如视频转录）来优化时空信息编码，这限制了其通用性和实用性。视频时刻检索尤为挑战，需精准定位时空上下文。本研究意外发现，图像文本预训练的MLLMs在时刻检索上效果显著。我们提出的Mr. BLIP（代表时刻检索）模型，为多模态单阶段设计，无需昂贵预训练和额外输入，设计简洁且通用性强。在Charades-STA、QVHighlights和ActivityNet Captions等基准上，我们刷新了时刻检索的记录，并在ActivityNet上实现了时间动作定位的新高。特别是在QVHighlights基准上，我们的Recall（在0.5和0.7 IoU时）提升了超过9%。代码已公开。",
    "title_cn": "多模态大型语言模型在视频时刻检索中展现出令人惊讶的高效性",
    "tags": [
      "LLM应用\n\n理由：这篇论文主要探讨了多模态大型语言模型（MLLMs）在视频时刻检索任务中的应用，特别是通过提出的Mr. BLIP模型，展示了MLLMs在处理视频语言任务中的有效性和效率。论文关注的是模型的实际应用效果，包括在多个基准测试上的性能提升，而不是模型的理论基础或Agent的设计与行为。因此，它更适合归类于LLM应用。",
      "视频处理",
      "计算机视觉"
    ]
  },
  {
    "title": "LLM-Driven Multimodal Opinion Expression Identification",
    "submit_datetime": "2024年06月26日",
    "abstract": "Opinion Expression Identification (OEI) is essential in NLP for applications ranging from voice assistants to depression diagnosis. This study extends OEI to encompass multimodal inputs, underlining the significance of auditory cues in delivering emotional subtleties beyond the capabilities of text. We introduce a novel multimodal OEI (MOEI) task, integrating text and speech to mirror real-world scenarios. Utilizing CMU MOSEI and IEMOCAP datasets, we construct the CI-MOEI dataset. Additionally, Text-to-Speech (TTS) technology is applied to the MPQA dataset to obtain the CIM-OEI dataset. We design a template for the OEI task to take full advantage of the generative power of large language models (LLMs). Advancing further, we propose an LLM-driven method STOEI, which combines speech and text modal to identify opinion expressions. Our experiments demonstrate that MOEI significantly improves the performance while our method outperforms existing methods by 9.20\\% and obtains SOTA results.",
    "pdf_link": "https://arxiv.org/abs/2406.18088",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.18088v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18088/intro.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18088v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18088/pipeline_draw.png"
      }
    ],
    "abstract_cn": "在NLP领域，意见表达识别（OEI）对于从语音助手到抑郁症诊断的应用至关重要。本研究将OEI拓展至多模态输入，凸显了听觉线索在传达文本所不及的情感细微差别中的重要性。我们创新性地提出了多模态OEI（MOEI）任务，融合文本与语音，模拟真实世界的交互场景。通过CMU MOSEI和IEMOCAP数据集，我们构建了CI-MOEI数据集，并利用文本转语音技术对MPQA数据集进行处理，生成了CIM-OEI数据集。为了最大化利用大型语言模型（LLMs）的生成潜力，我们为OEI任务设计了专门的模板。在此基础上，我们进一步提出了一种基于LLM的STOEI方法，该方法通过结合语音和文本模态，有效识别意见表达。实验结果显示，MOEI任务显著提升了性能，我们的方法超越了现有技术9.20%，达到了行业领先水平。",
    "title_cn": "利用大型语言模型进行多模态观点表达的精准识别",
    "tags": [
      "LLM应用\n\n这篇论文主要探讨了如何利用大型语言模型（LLMs）来提升多模态意见表达识别（MOEI）任务的性能。论文中提出了新的数据集和方法，通过结合文本和语音模态来识别意见表达，这在实际应用中具有重要价值，如语音助手和抑郁症诊断等。因此，这篇论文更符合LLM应用分类，因为它关注的是LLMs在特定任务中的应用和优化，而不是理论研究或Agent的设计。",
      "",
      "情感分析"
    ]
  },
  {
    "title": "EHR-Based Mobile and Web Platform for Chronic Disease Risk Prediction Using Large Language Multimodal Models",
    "submit_datetime": "2024年06月26日",
    "abstract": "Traditional diagnosis of chronic diseases involves in-person consultations with physicians to identify the disease. However, there is a lack of research focused on predicting and developing application systems using clinical notes and blood test values. We collected five years of Electronic Health Records (EHRs) from Taiwan's hospital database between 2017 and 2021 as an AI database. Furthermore, we developed an EHR-based chronic disease prediction platform utilizing Large Language Multimodal Models (LLMMs), successfully integrating with frontend web and mobile applications for prediction. This prediction platform can also connect to the hospital's backend database, providing physicians with real-time risk assessment diagnostics. The demonstration link can be found at https://www.youtube.com/watch?v=oqmL9DEDFgA.",
    "pdf_link": "https://arxiv.org/abs/2406.18087",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.18087v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18087/Fig_1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18087v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18087/LLMMs.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18087v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18087/workflow.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18087v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18087/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18087v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18087/mobile_overall.png"
      }
    ],
    "abstract_cn": "传统上，慢性疾病的诊断依赖于患者与医生的面对面咨询。然而，利用临床笔记和血液检测值进行疾病预测及应用系统开发的研究尚显不足。我们收集了2017至2021年间台湾医院五年间的电子健康记录，构建了一个AI数据库。基于此，我们开发了一款利用大型语言多模态模型的慢性病预测平台，该平台不仅与网页及移动应用无缝集成，还能实时接入医院数据库，为医生提供即时的风险评估。欲了解更多，请访问演示链接：https://www.youtube.com/watch?v=oqmL9DEDFgA。",
    "title_cn": "利用大型语言多模态模型，构建基于电子健康记录的移动与网页平台，精准预测慢性疾病风险",
    "tags": [
      "LLM应用\n\n理由：这篇论文描述了一个基于大型语言多模态模型的慢性病预测平台的开发和应用。该平台利用了电子健康记录数据，并将其集成到网页和移动应用中，以提供实时的风险评估。这种应用展示了LLM技术在医疗领域的实际应用，特别是在疾病预测和医疗决策支持方面，因此属于LLM应用分类。",
      "",
      "慢性病管理"
    ]
  },
  {
    "title": "PrExMe! Large Scale Prompt Exploration of Open Source LLMs for Machine Translation and Summarization Evaluation",
    "submit_datetime": "2024年06月26日",
    "abstract": "Large language models (LLMs) have revolutionized the field of NLP. Notably, their in-context learning capabilities also enable their use as evaluation metrics for natural language generation, making them particularly advantageous in low-resource scenarios and time-restricted applications. In this work, we introduce PrExMe, a large-scale prompt exploration for metrics, where we evaluate more than 720 prompt templates for open-source LLM-based metrics on machine translation (MT) and summarization datasets, totalling over 6.6M evaluations. This extensive comparison (1) serves as a benchmark of the performance of recent open-source LLMs as metrics and (2) explores the stability and variability of different prompting strategies. We discover that, on the one hand, there are scenarios for which prompts are stable. For instance, some LLMs show idiosyncratic preferences and favor to grade generated texts with textual labels while others prefer to return numeric scores. On the other hand, the stability of prompts and model rankings can be susceptible to seemingly innocuous changes. For example, changing the requested output format from \"0 to 100\" to \"-1 to +1\" can strongly affect the rankings in our evaluation. Our study contributes to understanding the impact of different prompting approaches on LLM-based metrics for MT and summarization evaluation, highlighting the most stable prompting patterns and potential limitations.",
    "pdf_link": "https://arxiv.org/abs/2406.18528",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.18528v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18528/PrexMain.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18528v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18528/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18528v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18528/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18528v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18528/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18528v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18528/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18528v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18528/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18528v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18528/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18528v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18528/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18528v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18528/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18528v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18528/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18528v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18528/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18528v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18528/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18528v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18528/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18528v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18528/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18528v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18528/x14.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）在自然语言处理领域掀起了一场革命，其上下文学习能力不仅提升了性能，还使其成为自然语言生成评估的理想工具，尤其在资源稀缺和时间紧迫的场景中表现出色。本研究中，我们推出了PrExMe，一个针对评估指标的大规模提示探索项目，对基于开源LLM的机器翻译和摘要数据集上的720多个提示模板进行了超过660万次评估。这一详尽的比较不仅为近期开源LLM作为评估指标的性能设立了基准，还深入探讨了不同提示策略的稳定性和变异性。我们观察到，一方面，某些情况下提示表现出稳定性，如某些LLM偏好使用文本标签评价生成文本，而其他则倾向于给出数值评分。另一方面，提示的稳定性和模型排名极易受微小变化的影响，例如，将输出格式从“0到100”调整为“-1到+1”便能显著改变评估结果的排名。我们的研究揭示了不同提示方法对LLM基础评估指标的影响，强调了最稳定的提示模式，并指出了潜在的局限性。",
    "title_cn": "PrExMe! 探索开源 LLMs 在机器翻译与摘要评估中的大规模提示应用",
    "tags": [
      "LLM应用\n\n理由：这篇论文主要探讨了大型语言模型（LLMs）在自然语言生成评估中的应用，特别是在机器翻译和摘要数据集上的评估。通过大规模的提示探索项目PrExMe，研究了不同提示策略对评估指标性能的影响，并设立了开源LLM作为评估指标的性能基准。这与LLM的应用实践紧密相关，而非专注于LLM的理论研究或Agent的设计与实现，也不是关于检索增强生成（RAG）的具体研究。因此，将其归类为LLM应用是合适的。",
      "",
      "机器翻译"
    ]
  },
  {
    "title": "\"Is ChatGPT a Better Explainer than My Professor?\": Evaluating the Explanation Capabilities of LLMs in Conversation Compared to a Human Baseline",
    "submit_datetime": "2024年06月26日",
    "abstract": "Explanations form the foundation of knowledge sharing and build upon communication principles, social dynamics, and learning theories. We focus specifically on conversational approaches for explanations because the context is highly adaptive and interactive. Our research leverages previous work on explanatory acts, a framework for understanding the different strategies that explainers and explainees employ in a conversation to both explain, understand, and engage with the other party. We use the 5-Levels dataset was constructed from the WIRED YouTube series by Wachsmuth et al., and later annotated by Booshehri et al. with explanatory acts. These annotations provide a framework for understanding how explainers and explainees structure their response when crafting a response.\n  With the rise of generative AI in the past year, we hope to better understand the capabilities of Large Language Models (LLMs) and how they can augment expert explainer's capabilities in conversational settings. To achieve this goal, the 5-Levels dataset (We use Booshehri et al.'s 2023 annotated dataset with explanatory acts.) allows us to audit the ability of LLMs in engaging in explanation dialogues. To evaluate the effectiveness of LLMs in generating explainer responses, we compared 3 different strategies, we asked human annotators to evaluate 3 different strategies: human explainer response, GPT4 standard response, GPT4 response with Explanation Moves.",
    "pdf_link": "https://arxiv.org/abs/2406.18512",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.18512v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18512/teaser-image.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18512v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18512/labeled-dialogue.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18512v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18512/study-conditions.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18512v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18512/cropped-interface.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18512v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18512/explanation_acts1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18512v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18512/explanation_acts2.png"
      }
    ],
    "abstract_cn": "解释是知识共享的基石，它融合了沟通原则、社会动态和学习理论。我们专注于对话式解释，因其高度适应性和互动性。我们的研究基于解释行为框架，探讨了对话中解释者和被解释者所采用的策略，以促进相互理解和互动。我们采用了Wachsmuth等人基于WIRED YouTube系列构建的5-Levels数据集，并由Booshehri等人进行了解释行为标注，这有助于我们理解双方在回应时的结构安排。随着生成式AI的快速发展，我们旨在深入了解大型语言模型（LLMs）的潜力，并探索它们如何助力专家在对话中更好地解释。为此，我们利用了Booshehri等人2023年标注的5-Levels数据集，以评估LLMs在解释对话中的参与能力。我们通过比较三种策略——人类解释者回应、GPT4标准回应及结合解释动作的GPT4回应，并由人类标注者进行评估，来衡量LLMs生成解释回应的效果。",
    "title_cn": "“ChatGPT 解释力超越教授？”：探究大型语言模型在对话中的解释能力，与人类专家一较高下",
    "tags": [
      "LLM应用\n\n理由：这篇论文主要探讨了大型语言模型（LLMs）在对话式解释中的应用，特别是在解释者和被解释者之间的互动中如何利用LLMs来提高解释的质量和效果。研究通过使用特定的数据集和评估方法，分析了LLMs在生成解释回应方面的能力，这属于LLM在实际应用中的探索和评估，因此归类为LLM应用。",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Is In-Context Learning a Type of Gradient-Based Learning? Evidence from the Inverse Frequency Effect in Structural Priming",
    "submit_datetime": "2024年06月26日",
    "abstract": "Large language models (LLMs) have shown the emergent capability of in-context learning (ICL). One line of research has explained ICL as functionally performing gradient descent. In this paper, we introduce a new way of diagnosing whether ICL is functionally equivalent to gradient-based learning. Our approach is based on the inverse frequency effect (IFE) -- a phenomenon in which an error-driven learner is expected to show larger updates when trained on infrequent examples than frequent ones. The IFE has previously been studied in psycholinguistics because humans show this effect in the context of structural priming (the tendency for people to produce sentence structures they have encountered recently); the IFE has been used as evidence that human structural priming must involve error-driven learning mechanisms. In our experiments, we simulated structural priming within ICL and found that LLMs display the IFE, with the effect being stronger in larger models. We conclude that ICL is indeed a type of gradient-based learning, supporting the hypothesis that a gradient component is implicitly computed in the forward pass during ICL. Our results suggest that both humans and LLMs make use of gradient-based, error-driven processing mechanisms.",
    "pdf_link": "https://arxiv.org/abs/2406.18501",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.18501v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18501/reasoning.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18501v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18501/overview.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18501v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18501/demo.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18501v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18501/FT-small_WithPronoun.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18501v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18501/IFE.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18501v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18501/verb_bias_pronoun_updated.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18501v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18501/verb_bias_noPronoun_updated.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）已展现出情境学习（ICL）的新能力。有研究认为，ICL在功能上类似于梯度下降。本文提出了一种新方法，用以判断ICL是否等同于基于梯度的学习。我们依据逆频率效应（IFE）——一种现象，即错误驱动的学习者在处理不常见例子时更新幅度更大。此前，心理语言学研究已发现人类在结构启动中表现出IFE（人们倾向于重复近期遇到的句子结构），并以此证明人类结构启动涉及错误驱动的学习机制。我们的实验模拟了ICL中的结构启动，发现LLMs也表现出IFE，且大模型中效应更显著。这证实了ICL是一种基于梯度的学习，支持了ICL过程中前向传递隐含计算梯度的假设。结果显示，人类和LLMs均采用基于梯度、错误驱动的处理机制。",
    "title_cn": "情境学习是否可归类为基于梯度的学习？结构启动中的逆频率效应为此提供了线索。",
    "tags": [
      "LLM理论\n\n这篇论文探讨了大型语言模型（LLMs）中的情境学习（ICL）机制，并将其与基于梯度的学习方法进行比较。通过实验观察逆频率效应（IFE）在LLMs中的表现，论文支持了ICL过程中可能涉及基于梯度的学习机制的假设。这种研究深入探讨了LLMs的理论基础，特别是它们如何模拟人类的学习过程，因此属于LLM理论分类。",
      "人工智能",
      "认知科学"
    ]
  },
  {
    "title": "Cascading Large Language Models for Salient Event Graph Generation",
    "submit_datetime": "2024年06月26日",
    "abstract": "Generating event graphs from long documents is challenging due to the inherent complexity of multiple tasks involved such as detecting events, identifying their relationships, and reconciling unstructured input with structured graphs. Recent studies typically consider all events with equal importance, failing to distinguish salient events crucial for understanding narratives. This paper presents CALLMSAE, a CAscading Large Language Model framework for SAlient Event graph generation, which leverages the capabilities of LLMs and eliminates the need for costly human annotations. We first identify salient events by prompting LLMs to generate summaries, from which salient events are identified. Next, we develop an iterative code refinement prompting strategy to generate event relation graphs, removing hallucinated relations and recovering missing edges. Fine-tuning contextualised graph generation models on the LLM-generated graphs outperforms the models trained on CAEVO-generated data. Experimental results on a human-annotated test set show that the proposed method generates salient and more accurate graphs, outperforming competitive baselines.",
    "pdf_link": "https://arxiv.org/abs/2406.18449",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.18449v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18449/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18449v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18449/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18449v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18449/disclamer_of_risks.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18449v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18449/annotation_1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18449v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18449/annotation_2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18449v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18449/guideline_3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18449v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18449/guideline_5.png"
      }
    ],
    "abstract_cn": "从长文档中提取事件图颇具挑战，涉及多重任务，如事件检测、关系识别及非结构化输入与结构化图表的整合。现有研究往往对所有事件一视同仁，忽略了那些对叙事理解至关重要的显著事件。本文介绍的CALLMSAE框架，利用大型语言模型的力量，无需人工标注，便能精准捕捉这些显著事件。首先，我们通过让LLMs生成摘要来筛选出关键事件。随后，采用迭代代码优化策略构建事件关系图，剔除错误关联，补全遗漏连接。在LLM生成的图上微调的上下文化图生成模型，其表现超越了基于CAEVO数据训练的模型。实验证明，我们的方法在人工标注的测试集上生成了更为精准和显著的事件图，显著优于其他方法。",
    "title_cn": "利用级联大型语言模型构建关键事件图谱",
    "tags": [
      "Agent\n\n理由：这篇论文介绍了一个名为CALLMSAE的框架，该框架利用大型语言模型（LLMs）的能力来处理从长文档中提取事件图的复杂任务。这个框架通过自动化的方式识别和构建事件关系图，展示了Agent的特性，即能够自主地执行任务并做出决策。此外，该框架通过迭代优化策略来改进事件图的构建，这进一步体现了Agent在解决问题时的主动性和适应性。因此，这篇论文更适合归类为Agent。",
      "",
      "事件提取"
    ]
  },
  {
    "title": "New intelligent empowerment for digital transformation",
    "submit_datetime": "2024年06月26日",
    "abstract": "This study proposes an innovative evaluation method based on large language models (LLMs) specifically designed to measure the digital transformation (DT) process of enterprises. By analyzing the annual reports of 4407 companies listed on the New York Stock Exchange and Nasdaq from 2005 to 2022, a comprehensive set of DT indicators was constructed. The findings revealed that DT significantly improves a company's financial performance, however, different digital technologies exhibit varying effects on financial performance. Specifically, blockchain technology has a relatively limited positive impact on financial performance. In addition, this study further discovered that DT can promote the growth of financial performance by enhancing operational efficiency and reducing costs. This study provides a novel DT evaluation tool for the academic community, while also expanding the application scope of generative artificial intelligence technology in economic research.",
    "pdf_link": "https://arxiv.org/abs/2406.18440",
    "graphs": [],
    "abstract_cn": "本研究创新性地利用大型语言模型（LLMs）开发了一种评估企业数字化转型（DT）过程的方法。通过对2005至2022年间纽约证券交易所和纳斯达克4407家上市公司年报的深入分析，我们构建了一套详尽的DT指标体系。研究结果显示，数字化转型显著增强了企业的财务表现，但不同数字技术的影响效果不一，其中区块链技术的正面影响较为有限。此外，我们还发现，DT通过提升运营效率和降低成本，有效推动了财务表现的增长。这项研究不仅为学术界提供了一个全新的DT评估工具，也拓宽了生成式人工智能技术在经济研究领域的应用前景。",
    "title_cn": "数字转型迎来新智能赋能",
    "tags": [
      "LLM应用\n\n这篇论文摘要描述了如何利用大型语言模型（LLMs）来评估企业的数字化转型（DT）过程。通过分析上市公司的年报，研究者构建了一套DT指标体系，并探讨了不同数字技术对企业财务表现的影响。这种方法展示了LLMs在经济研究领域的应用，特别是在数据分析和评估方面的潜力。因此，这篇论文属于LLM应用分类。",
      "企业数字化转型",
      "经济研究"
    ]
  },
  {
    "title": "IRCAN: Mitigating Knowledge Conflicts in LLM Generation via Identifying and Reweighting Context-Aware Neurons",
    "submit_datetime": "2024年06月26日",
    "abstract": "It is widely acknowledged that large language models (LLMs) encode a vast reservoir of knowledge after being trained on mass data. Recent studies disclose knowledge conflicts in LLM generation, wherein outdated or incorrect parametric knowledge (i.e., encoded knowledge) contradicts new knowledge provided in the context. To mitigate such knowledge conflicts, we propose a novel framework, IRCAN (Identifying and Reweighting Context-Aware Neurons) to capitalize on neurons that are crucial in processing contextual cues. Specifically, IRCAN first identifies neurons that significantly contribute to context processing, utilizing a context-aware attribution score derived from integrated gradients. Subsequently, the identified context-aware neurons are strengthened via reweighting. In doing so, we steer LLMs to generate context-sensitive outputs with respect to the new knowledge provided in the context. Extensive experiments conducted across a variety of models and tasks demonstrate that IRCAN not only achieves remarkable improvements in handling knowledge conflicts but also offers a scalable, plug-andplay solution that can be integrated seamlessly with existing models.",
    "pdf_link": "https://arxiv.org/abs/2406.18406",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.18406v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18406/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18406v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18406/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18406v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18406/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18406v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18406/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18406v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18406/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18406v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18406/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18406v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18406/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18406v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18406/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18406v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18406/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18406v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18406/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18406v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18406/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18406v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18406/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18406v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18406/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18406v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18406/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18406v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18406/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18406v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18406/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18406v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18406/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18406v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18406/x20.png"
      }
    ],
    "abstract_cn": "众所周知，大型语言模型（LLMs）在海量数据训练后，积累了丰富的知识库。然而，最新研究发现，LLMs在生成内容时会出现知识冲突，即模型内部过时或错误的知识与上下文中提供的新信息相抵触。为此，我们开发了IRCAN框架（识别与重新加权上下文感知神经元），旨在利用那些对上下文信息处理至关重要的神经元。IRCAN首先通过集成梯度得出的上下文感知归因分数，识别出这些关键神经元，然后通过重新加权来强化它们。这一过程使得LLMs能够根据上下文中的新知识，生成更为敏感的输出。实验证明，IRCAN不仅有效解决了知识冲突问题，还提供了一个可扩展、即插即用的解决方案，能够与现有模型完美融合。",
    "title_cn": "IRCAN：借助上下文感知神经元的识别与权重调整，化解大型语言模型生成过程中的知识冲突",
    "tags": [
      "LLM理论\n\n理由：这篇论文主要关注大型语言模型（LLMs）内部的知识冲突问题，并提出了一种名为IRCAN的框架来解决这一问题。该框架通过识别和重新加权关键的上下文感知神经元，以改进模型对新知识的敏感性。这一研究深入探讨了LLMs的内部机制和知识处理，属于对LLM理论的深入研究，而非直接的应用开发或Agent、RAG相关的研究。因此，将其归类为LLM理论是合适的。",
      "",
      "机器学习"
    ]
  },
  {
    "title": "Do LLMs dream of elephants (when told not to)? Latent concept association and associative memory in transformers",
    "submit_datetime": "2024年06月26日",
    "abstract": "Large Language Models (LLMs) have the capacity to store and recall facts. Through experimentation with open-source models, we observe that this ability to retrieve facts can be easily manipulated by changing contexts, even without altering their factual meanings. These findings highlight that LLMs might behave like an associative memory model where certain tokens in the contexts serve as clues to retrieving facts. We mathematically explore this property by studying how transformers, the building blocks of LLMs, can complete such memory tasks. We study a simple latent concept association problem with a one-layer transformer and we show theoretically and empirically that the transformer gathers information using self-attention and uses the value matrix for associative memory.",
    "pdf_link": "https://arxiv.org/abs/2406.18400",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/hijack-example.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/sub_false_accs.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/sentence_false_P190.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/Wv_bar_l64.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/hamming_inner_n8.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/heat_map_n8.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/sub_true_accs.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/sentence_false_P103.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/sentence_false_P131.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/sentence_false_P190.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/sentence_false_P641.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/sentence_true_P103.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/sentence_true_P131.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/sentence_true_P190.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/sentence_true_P641.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/sentence_false_P1412.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/sentence_true_P1412.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/Wv_bar_l64.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/Wv_bar_l128.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/wv_replace_dim_n5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/wv_replace_dim_n6.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/wv_replace_dim_n7.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/wv_replace_dim_n8.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/wv_angle_dim_n5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/wv_angle_dim_n6.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/wv_angle_dim_n7.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/wv_angle_dim_n8.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/dim_n5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/dim_n6.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/dim_n7.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/dim_n8.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/hamming_inner_n7.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/hamming_inner_n8.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/no_wv_hamming_inner_n5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/no_wv_hamming_inner_n6.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/no_wv_hamming_inner_n7.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/no_wv_hamming_inner_n8.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/heat_map_n5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/heat_map_n6.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/heat_map_n7.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/heat_map_n8.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/heat_map_n5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/heat_map_n6.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/heat_map_n7.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/heat_map_n8.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/spectrum_n7_d32_e0.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/spectrum_n7_d32_e1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/spectrum_n7_d32_e2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/spectrum_n7_d32_e3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/spectrum_n7_d64_e0.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/spectrum_n7_d64_e1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/spectrum_n7_d64_e2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/spectrum_n7_d64_e3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/spectrum_n8_d32_e0.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/spectrum_n8_d32_e1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/spectrum_n8_d32_e2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/spectrum_n8_d32_e3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/spectrum_n8_d64_e0.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/spectrum_n8_d64_e1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/spectrum_n8_d64_e2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/spectrum_n8_d64_e3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/confusion_bar_l5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/confusion_bar_l6.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/confusion_bar_l7.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/confusion_bar_l8.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/length_n5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/length_n6.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/length_n7.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18400v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18400/length_n8.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）能够存储并回忆事实，实验表明，通过调整上下文，即使不改变事实本身，也能轻易操纵其检索事实的能力。这表明LLMs可能类似于一种关联记忆模型，上下文中的特定标记充当检索事实的线索。我们通过分析LLMs的核心组件——变压器如何执行记忆任务，从数学角度探讨了这一特性。我们以一层变压器解决了一个简单的潜在概念关联问题，理论与实证均显示，变压器利用自注意力机制收集信息，并通过值矩阵实现关联记忆。",
    "title_cn": "当被禁止想象时，大型语言模型是否仍会幻想大象？探索变压器中的潜在概念关联与联想记忆之谜。",
    "tags": [
      "LLM理论\n\n这篇论文探讨了大型语言模型（LLMs）的内部机制，特别是变压器模型如何通过自注意力机制和值矩阵实现关联记忆。这种分析从数学角度深入探讨了LLMs的工作原理，特别是它们如何存储和检索事实。这与LLMs的理论研究相关，因为它关注的是模型内部的运作机制和理论基础，而不是具体的应用或安全性问题。因此，它属于LLM理论分类。",
      "",
      "机器学习"
    ]
  },
  {
    "title": "Adversarial Search Engine Optimization for Large Language Models",
    "submit_datetime": "2024年06月26日",
    "abstract": "Large Language Models (LLMs) are increasingly used in applications where the model selects from competing third-party content, such as in LLM-powered search engines or chatbot plugins. In this paper, we introduce Preference Manipulation Attacks, a new class of attacks that manipulate an LLM's selections to favor the attacker. We demonstrate that carefully crafted website content or plugin documentations can trick an LLM to promote the attacker products and discredit competitors, thereby increasing user traffic and monetization. We show this leads to a prisoner's dilemma, where all parties are incentivized to launch attacks, but the collective effect degrades the LLM's outputs for everyone. We demonstrate our attacks on production LLM search engines (Bing and Perplexity) and plugin APIs (for GPT-4 and Claude). As LLMs are increasingly used to rank third-party content, we expect Preference Manipulation Attacks to emerge as a significant threat.",
    "pdf_link": "https://arxiv.org/abs/2406.18382",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/screenshotcapturepro2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/screenshotpbl2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x20.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x21.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x22.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x23.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x24.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x25.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x26.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x27.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x28.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x29.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x30.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x31.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x32.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x33.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x34.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x35.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x36.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x37.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x38.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x39.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x40.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x41.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x42.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x43.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x44.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x45.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x46.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x47.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x48.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x49.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x50.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x51.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x52.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x53.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x54.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x55.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x56.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x57.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x58.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18382v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18382/x59.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）在需从竞争第三方内容中做出选择的应用中日益普及，如搜索引擎或聊天机器人插件。本文提出了一种名为“偏好操纵攻击”的新型攻击，旨在通过操纵LLM的选择来偏袒攻击者。我们发现，通过精心设计的网站内容或插件文档，可以诱导LLM推广攻击者的产品并贬低竞争对手，从而增加用户流量和收益。这种现象导致了囚徒困境，各方都有动机发起攻击，但集体结果却降低了LLM对所有用户的输出质量。我们在实际的LLM搜索引擎（如Bing和Perplexity）及插件API（如GPT-4和Claude）上验证了这种攻击。随着LLMs在第三方内容排名中的应用增多，我们预计偏好操纵攻击将成为一个不容忽视的威胁。",
    "title_cn": "大型语言模型的对抗性SEO优化",
    "tags": [
      "Agent\n\n这篇论文讨论了一种针对大型语言模型（LLMs）的新型攻击——偏好操纵攻击，这种攻击通过操纵LLM的选择来偏袒攻击者的产品。这种攻击涉及到对LLM的行为进行操纵，使其在处理第三方内容时做出有利于攻击者的选择。这与Agent的分类相符，因为Agent通常指的是能够自主行动并做出决策的实体，而在这篇论文中，LLM被视为一个Agent，其行为可以被外部因素（如精心设计的网站内容或插件文档）所影响。此外，论文中提到的攻击在实际的LLM搜索引擎和插件API上的验证，进一步强调了LLM作为Agent在实际应用中的行为和决策过程。",
      "搜索引擎",
      "网络安全"
    ]
  },
  {
    "title": "MALSIGHT: Exploring Malicious Source Code and Benign Pseudocode for Iterative Binary Malware Summarization",
    "submit_datetime": "2024年06月26日",
    "abstract": "Binary malware summarization aims to automatically generate human-readable descriptions of malware behaviors from executable files, facilitating tasks like malware cracking and detection. Previous methods based on Large Language Models (LLMs) have shown great promise. However, they still face significant issues, including poor usability, inaccurate explanations, and incomplete summaries, primarily due to the obscure pseudocode structure and the lack of malware training summaries. Further, calling relationships between functions, which involve the rich interactions within a binary malware, remain largely underexplored. To this end, we propose MALSIGHT, a novel code summarization framework that can iteratively generate descriptions of binary malware by exploring malicious source code and benign pseudocode. Specifically, we construct the first malware summaries, MalS and MalP, using an LLM and manually refine this dataset with human effort. At the training stage, we tune our proposed MalT5, a novel LLM-based code model, on the MalS dataset and a benign pseudocode dataset. Then, at the test stage, we iteratively feed the pseudocode functions into MalT5 to obtain the summary. Such a procedure facilitates the understanding of pseudocode structure and captures the intricate interactions between functions, thereby benefiting the usability, accuracy, and completeness of summaries. Additionally, we propose a novel evaluation benchmark, BLEURT-sum, to measure the quality of summaries. Experiments on three datasets show the effectiveness of the proposed MALSIGHT. Notably, our proposed MalT5, with only 0.77B parameters, delivers comparable performance to much larger ChatGPT3.5.",
    "pdf_link": "https://arxiv.org/abs/2406.18379",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.18379v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18379/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18379v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18379/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18379v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18379/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18379v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18379/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18379v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18379/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18379v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18379/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18379v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18379/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18379v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18379/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18379v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18379/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18379v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18379/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18379v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18379/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18379v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18379/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18379v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18379/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18379v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18379/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18379v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18379/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18379v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18379/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18379v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18379/x17.png"
      }
    ],
    "abstract_cn": "MALSIGHT是一种创新的代码摘要框架，旨在通过分析恶意源代码和良性伪代码，自动生成二进制恶意软件的详细描述，从而优化恶意软件的破解与检测过程。尽管基于LLM的方法已显示出潜力，但仍存在使用不便、解释不准确和摘要不完整等问题，这些问题源于伪代码结构的模糊性和恶意软件训练数据的不足。此外，恶意软件内部函数间的复杂交互关系尚未得到充分研究。为此，我们构建了首个恶意软件摘要数据集MalS和MalP，并通过人工校正进行了优化。在训练阶段，我们针对MalS和良性伪代码数据集对新型LLM代码模型MalT5进行了调优。测试阶段，我们通过迭代输入伪代码函数至MalT5，生成摘要，这一过程有助于深入理解伪代码结构并捕捉函数间的微妙交互，显著提升了摘要的实用性、准确性和完整性。我们还开发了新的评估基准BLEURT-sum，以精确评估摘要质量。实验结果表明，MALSIGHT在三个数据集上均表现出色，尤其是我们的MalT5模型，尽管参数仅为0.77亿，其性能却能与更大型的ChatGPT3.5相媲美。",
    "title_cn": "MALSIGHT：迭代提炼恶意软件二进制，融合恶意源码与良性伪码之智慧",
    "tags": [
      "LLM应用\n\n这篇论文介绍了一种名为MALSIGHT的创新框架，它专注于通过分析恶意源代码和良性伪代码来自动生成二进制恶意软件的详细描述。这种方法优化了恶意软件的破解与检测过程。论文中提到的使用LLM（大型语言模型）的方法，以及构建的恶意软件摘要数据集MalS和MalP，以及对LLM代码模型MalT5的调优，都是为了提高恶意软件摘要的实用性、准确性和完整性。这些内容表明该论文是在应用LLM技术来解决实际问题，即恶意软件的分析和检测，因此属于LLM应用分类。",
      "恶意软件检测",
      "代码分析"
    ]
  },
  {
    "title": "Themis: Towards Flexible and Interpretable NLG Evaluation",
    "submit_datetime": "2024年06月26日",
    "abstract": "The evaluation of natural language generation (NLG) tasks is a significant and longstanding research issue. With the recent emergence of powerful large language models (LLMs), some studies have turned to LLM-based automatic evaluation methods, which demonstrate great potential to become a new evaluation paradigm following traditional string-based and model-based metrics. However, despite the improved performance of existing methods, they still possess some deficiencies, such as dependency on references and limited evaluation flexibility. Therefore, in this paper, we meticulously construct a large-scale NLG evaluation corpus NLG-Eval with human and GPT-4 annotations to alleviate the lack of relevant data in this field. Furthermore, we propose Themis, an LLM dedicated to NLG evaluation, which has been trained with our designed multi-perspective consistency and rating-oriented preference alignment methods. Themis can conduct flexible and interpretable evaluations without references, and it exhibits superior evaluation performance on various NLG tasks, simultaneously generalizing well to unseen tasks and surpassing other evaluation models, including GPT-4.",
    "pdf_link": "https://arxiv.org/abs/2406.18365",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.18365v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18365/image.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18365v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18365/x1.png"
      }
    ],
    "abstract_cn": "自然语言生成（NLG）任务的评估一直是研究的热点。随着大型语言模型（LLMs）的崛起，基于LLM的自动评估方法崭露头角，有望成为新一代评估标准。尽管这些方法性能有所提升，但仍受限于对参考文献的依赖和评估灵活性的不足。为此，本文精心打造了NLG-Eval这一大规模评估语料库，融合了人类与GPT-4的智慧，旨在填补数据空白。同时，我们推出了Themis，一款专为NLG评估量身定制的LLM，通过多视角一致性与评分偏好对齐训练，实现了无需参考文献的灵活且透明的评估。Themis在多项NLG任务中表现卓越，不仅适应新任务，还超越了包括GPT-4在内的其他评估模型。",
    "title_cn": "Themis：探索灵活与可解释的自然语言生成评估之路",
    "tags": [
      "LLM应用\n\n这篇论文主要讨论了自然语言生成（NLG）任务的评估问题，并提出了一种基于大型语言模型（LLMs）的新型自动评估方法。论文中介绍了NLG-Eval这一大规模评估语料库的构建，以及Themis这一专为NLG评估设计的LLM模型的开发。这些内容主要集中在LLM的应用层面，即如何利用LLM来改进和创新NLG任务的评估方法，因此应归类于LLM应用。",
      "",
      "评估工具"
    ]
  },
  {
    "title": "AI Alignment through Reinforcement Learning from Human Feedback? Contradictions and Limitations",
    "submit_datetime": "2024年06月26日",
    "abstract": "This paper critically evaluates the attempts to align Artificial Intelligence (AI) systems, especially Large Language Models (LLMs), with human values and intentions through Reinforcement Learning from Feedback (RLxF) methods, involving either human feedback (RLHF) or AI feedback (RLAIF). Specifically, we show the shortcomings of the broadly pursued alignment goals of honesty, harmlessness, and helpfulness. Through a multidisciplinary sociotechnical critique, we examine both the theoretical underpinnings and practical implementations of RLxF techniques, revealing significant limitations in their approach to capturing the complexities of human ethics and contributing to AI safety. We highlight tensions and contradictions inherent in the goals of RLxF. In addition, we discuss ethically-relevant issues that tend to be neglected in discussions about alignment and RLxF, among which the trade-offs between user-friendliness and deception, flexibility and interpretability, and system safety. We conclude by urging researchers and practitioners alike to critically assess the sociotechnical ramifications of RLxF, advocating for a more nuanced and reflective approach to its application in AI development.",
    "pdf_link": "https://arxiv.org/abs/2406.18346",
    "graphs": [],
    "abstract_cn": "本文深入探讨了通过反馈强化学习（RLxF）方法，尤其是结合人类反馈（RLHF）或AI反馈（RLAIF），使AI系统，特别是LLMs与人类价值观和意图对齐的努力。我们指出，尽管追求诚实、无害和有益的目标，但这些努力仍显不足。通过跨学科分析，我们揭示了RLxF在理解和实现人类伦理复杂性方面的局限，并探讨了AI安全性的贡献。我们强调了RLxF目标中的内在矛盾，并讨论了在AI对齐讨论中常被忽略的伦理问题，如用户友好性与欺骗性、灵活性与可解释性、系统安全性之间的权衡。最后，我们呼吁研究者和实践者共同审视RLxF的社会技术影响，倡导在AI发展中采取更为细致和反思的方法。",
    "title_cn": "借助人类反馈的强化学习以实现AI对齐？探讨其中的矛盾与局限。",
    "tags": [
      "LLM理论\n\n理由：这篇论文主要探讨了通过反馈强化学习（RLxF）方法，特别是结合人类反馈（RLHF）或AI反馈（RLAIF），使大型语言模型（LLMs）与人类价值观和意图对齐的问题。它深入分析了RLxF方法在理解和实现人类伦理复杂性方面的局限性，并讨论了AI安全性的贡献。此外，论文还强调了RLxF目标中的内在矛盾，并探讨了在AI对齐讨论中常被忽略的伦理问题。这些内容更多地涉及LLM的理论层面，特别是关于如何使LLM与人类价值观对齐的理论探讨，因此归类为LLM理论。",
      "人工智能伦理",
      "AI安全性"
    ]
  },
  {
    "title": "PaCoST: Paired Confidence Significance Testing for Benchmark Contamination Detection in Large Language Models",
    "submit_datetime": "2024年06月26日",
    "abstract": "Large language models (LLMs) are known to be trained on vast amounts of data, which may unintentionally or intentionally include data from commonly used benchmarks. This inclusion can lead to cheatingly high scores on model leaderboards, yet result in disappointing performance in real-world applications. To address this benchmark contamination problem, we first propose a set of requirements that practical contamination detection methods should follow. Following these proposed requirements, we introduce PaCoST, a Paired Confidence Significance Testing to effectively detect benchmark contamination in LLMs. Our method constructs a counterpart for each piece of data with the same distribution, and performs statistical analysis of the corresponding confidence to test whether the model is significantly more confident under the original benchmark. We validate the effectiveness of PaCoST and apply it on popular open-source models and benchmarks. We find that almost all models and benchmarks we tested are suspected contaminated more or less. We finally call for new LLM evaluation methods.",
    "pdf_link": "https://arxiv.org/abs/2406.18326",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.18326v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18326/x1.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）因训练数据庞大，有时会不慎或故意包含常用基准数据，导致排行榜分数虚高，实际应用却表现不佳。为解决此基准污染问题，我们提出了一套检测方法的标准，并据此开发了PaCoST，一种配对置信度显著性测试，专门用于检测LLMs中的基准污染。该方法通过为每项数据创建分布相同的对照组，并进行统计分析，以判断模型在原始基准下是否过度自信。我们验证了PaCoST的效果，并应用于多个开源模型和基准，发现多数存在不同程度的污染。因此，我们呼吁更新LLM的评估方法。",
    "title_cn": "PaCoST：大型语言模型基准污染检测中的配对置信显著性检验",
    "tags": [
      "LLM理论\n\n这篇论文主要关注大型语言模型（LLMs）中的基准污染问题，并提出了一种新的检测方法——PaCoST，用于识别和评估这种污染。该研究通过统计分析来检测模型是否在特定基准下表现出过度自信，这涉及到对LLMs的理论理解和评估方法的改进。因此，这篇论文更偏向于LLM的理论研究，而不是Agent、RAG或LLM应用的范畴。",
      "机器学习",
      "基准测试"
    ]
  },
  {
    "title": "MathOdyssey: Benchmarking Mathematical Problem-Solving Skills in Large Language Models Using Odyssey Math Data",
    "submit_datetime": "2024年06月26日",
    "abstract": "Large language models (LLMs) have significantly advanced natural language understanding and demonstrated strong problem-solving abilities. Despite these successes, most LLMs still struggle with solving mathematical problems due to the intricate reasoning required. This paper investigates the mathematical problem-solving capabilities of LLMs using the newly developed \"MathOdyssey\" dataset. The dataset includes diverse mathematical problems at high school and university levels, created by experts from notable institutions to rigorously test LLMs in advanced problem-solving scenarios and cover a wider range of subject areas. By providing the MathOdyssey dataset as a resource to the AI community, we aim to contribute to the understanding and improvement of AI capabilities in complex mathematical problem-solving. We conduct benchmarking on open-source models, such as Llama-3 and DBRX-Instruct, and closed-source models from the GPT series and Gemini models. Our results indicate that while LLMs perform well on routine and moderately difficult tasks, they face significant challenges with Olympiad-level problems and complex university-level questions. Our analysis shows a narrowing performance gap between open-source and closed-source models, yet substantial challenges remain, particularly with the most demanding problems. This study highlights the ongoing need for research to enhance the mathematical reasoning of LLMs. The dataset, results, and code are publicly available.",
    "pdf_link": "https://arxiv.org/abs/2406.18321",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.18321v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18321/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18321v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18321/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18321v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18321/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18321v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18321/x4.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）在自然语言理解和问题解决方面取得了显著进步，但在解决数学问题上仍显吃力，尤其是需要复杂推理的问题。本研究采用新开发的“MathOdyssey”数据集，深入探讨LLMs的数学问题解决能力。该数据集由知名机构专家精心设计，包含高中至大学水平的多样化数学问题，旨在全面测试LLMs在高级问题解决场景中的表现。我们向AI社区公开了MathOdyssey数据集，以期推动AI在复杂数学问题解决能力上的进步。通过对比开源模型（如Llama-3和DBRX-Instruct）与GPT系列及Gemini模型的闭源模型，我们发现LLMs在常规至中等难度任务上表现出色，但在奥林匹克级别和大学级别的复杂问题上遭遇挑战。尽管开源与闭源模型间的性能差距正在缩小，但面对最棘手的问题时，挑战依旧巨大。本研究凸显了持续研究以提升LLMs数学推理能力的迫切性，相关数据集、结果及代码已公开发布。",
    "title_cn": "数学奥德赛：利用Odyssey数学数据，在大规模语言模型中评估数学问题解决能力",
    "tags": [
      "LLM应用\n\n理由：这篇论文主要探讨了大型语言模型（LLMs）在解决数学问题上的能力，特别是使用新开发的“MathOdyssey”数据集来评估和比较不同模型在高级数学问题解决场景中的表现。这属于对LLMs在特定应用领域（数学问题解决）的实际应用和性能评估，因此归类为LLM应用。论文中虽然涉及模型的比较和性能分析，但重点在于应用层面的探讨，而非理论模型的深入研究或Agent的设计与实现。",
      "",
      "人工智能"
    ]
  },
  {
    "title": "MSR-86K: An Evolving, Multilingual Corpus with 86,300 Hours of Transcribed Audio for Speech Recognition Research",
    "submit_datetime": "2024年06月26日",
    "abstract": "Recently, multilingual artificial intelligence assistants, exemplified by ChatGPT, have gained immense popularity. As a crucial gateway to human-computer interaction, multilingual automatic speech recognition (ASR) has also garnered significant attention, as evidenced by systems like Whisper. However, the proprietary nature of the training data has impeded researchers' efforts to study multilingual ASR. This paper introduces MSR-86K, an evolving, large-scale multilingual corpus for speech recognition research. The corpus is derived from publicly accessible videos on YouTube, comprising 15 languages and a total of 86,300 hours of transcribed ASR data. We also introduce how to use the MSR-86K corpus and other open-source corpora to train a robust multilingual ASR model that is competitive with Whisper. MSR-86K will be publicly released on HuggingFace, and we believe that such a large corpus will pave new avenues for research in multilingual ASR.",
    "pdf_link": "https://arxiv.org/abs/2406.18301",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.18301v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18301/youtube.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18301v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18301/vad.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18301v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18301/hubert.png"
      }
    ],
    "abstract_cn": "近期，如ChatGPT这样的多语言AI助手大受欢迎。作为人机交互的关键，多语言自动语音识别（ASR）也备受瞩目，Whisper系统便是例证。但训练数据的专有性限制了多语言ASR的研究。本文推出的MSR-86K，是一个源自YouTube公开视频、包含15种语言、总计86,300小时转录数据的大型多语言语音识别研究语料库。我们还将展示如何利用MSR-86K及其他开源资源，训练出能与Whisper媲美的多语言ASR模型。MSR-86K即将在HuggingFace公开，我们期待这一庞大资源能推动多语言ASR研究的新进展。",
    "title_cn": "MSR-86K：一个持续进化的多语言宝库，收录了86,300小时的转录音频，专为语音识别研究量身打造。",
    "tags": [
      "LLM应用\n\n这篇论文介绍了MSR-86K，一个大型多语言语音识别研究语料库，并展示了如何利用这一资源及其他开源资源训练出高质量的多语言自动语音识别（ASR）模型。这与大型语言模型（LLM）的应用直接相关，特别是在多语言ASR领域，因此属于LLM应用分类。",
      "语音识别",
      "多语言技术"
    ]
  },
  {
    "title": "FactFinders at CheckThat! 2024: Refining Check-worthy Statement Detection with LLMs through Data Pruning",
    "submit_datetime": "2024年06月26日",
    "abstract": "The rapid dissemination of information through social media and the Internet has posed a significant challenge for fact-checking, among others in identifying check-worthy claims that fact-checkers should pay attention to, i.e. filtering claims needing fact-checking from a large pool of sentences. This challenge has stressed the need to focus on determining the priority of claims, specifically which claims are worth to be fact-checked. Despite advancements in this area in recent years, the application of large language models (LLMs), such as GPT, has only recently drawn attention in studies. However, many open-source LLMs remain underexplored. Therefore, this study investigates the application of eight prominent open-source LLMs with fine-tuning and prompt engineering to identify check-worthy statements from political transcriptions. Further, we propose a two-step data pruning approach to automatically identify high-quality training data instances for effective learning. The efficiency of our approach is demonstrated through evaluations on the English language dataset as part of the check-worthiness estimation task of CheckThat! 2024. Further, the experiments conducted with data pruning demonstrate that competitive performance can be achieved with only about 44\\% of the training data. Our team ranked first in the check-worthiness estimation task in the English language.",
    "pdf_link": "https://arxiv.org/abs/2406.18297",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.18297v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18297/Distribution_of_Text_Length.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18297v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18297/verb_cloud.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18297v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18297/verb_type_distribution.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18297v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18297/2D_All.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18297v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18297/2D_All_Uniformative.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18297v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18297/2D_Highquality.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18297v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18297/Consistency.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18297v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18297/f1_Score_step1_and2.png"
      }
    ],
    "abstract_cn": "社交媒体和互联网的信息迅速传播给事实核查带来了挑战，特别是在从海量信息中筛选出值得核查的声明。这一挑战凸显了确定核查优先级的重要性，即哪些声明最值得关注。尽管近年来有所进步，但大型语言模型（如GPT）的应用才刚刚引起研究界的注意，许多开源LLMs仍待深入探索。本研究聚焦于八种领先的开源LLMs，通过微调和提示工程，从政治抄本中识别出值得核查的声明，并提出了一种两步数据修剪策略，自动筛选出高质量的训练数据，以提升学习效果。我们在CheckThat! 2024的英语语言数据集上验证了这一方法的效率，并通过数据修剪实验证明，仅用约44%的训练数据即可达到优异性能。我们的团队在英语语言的核查价值估计任务中荣获第一。",
    "title_cn": "在 CheckThat! 2024 中，FactFinders 利用数据修剪技术，借助大型语言模型（LLMs）精炼了对值得核查声明的检测能力。",
    "tags": [
      "Agent\n\n这篇论文主要关注的是如何利用大型语言模型（LLMs）来识别和筛选社交媒体和互联网上的信息，以确定哪些声明最值得进行事实核查。研究中使用了八种领先的开源LLMs，并通过微调和提示工程来优化这些模型的性能。此外，论文还提出了一种两步数据修剪策略，以自动筛选出高质量的训练数据，从而提升模型的学习效果。这种方法在CheckThat! 2024的英语语言数据集上得到了验证，并取得了优异的成绩。因此，这篇论文更符合Agent分类，因为它描述了一个系统或代理如何使用LLMs来执行特定的任务（即事实核查的优先级确定）。",
      "社交媒体",
      "事实核查"
    ]
  },
  {
    "title": "Hierarchical Context Pruning: Optimizing Real-World Code Completion with Repository-Level Pretrained Code LLMs",
    "submit_datetime": "2024年06月26日",
    "abstract": "Some recently developed code large language models (Code LLMs) have been pre-trained on repository-level code data (Repo-Code LLMs), enabling these models to recognize repository structures and utilize cross-file information for code completion. However, in real-world development scenarios, simply concatenating the entire code repository often exceeds the context window limits of these Repo-Code LLMs, leading to significant performance degradation. In this study, we conducted extensive preliminary experiments and analyses on six Repo-Code LLMs. The results indicate that maintaining the topological dependencies of files and increasing the code file content in the completion prompts can improve completion accuracy; pruning the specific implementations of functions in all dependent files does not significantly reduce the accuracy of completions. Based on these findings, we proposed a strategy named Hierarchical Context Pruning (HCP) to construct completion prompts with high informational code content. The HCP models the code repository at the function level, maintaining the topological dependencies between code files while removing a large amount of irrelevant code content, significantly reduces the input length for repository-level code completion. We applied the HCP strategy in experiments with six Repo-Code LLMs, and the results demonstrate that our proposed method can significantly enhance completion accuracy while substantially reducing the length of input. Our code and data are available at https://github.com/Hambaobao/HCP-Coder.",
    "pdf_link": "https://arxiv.org/abs/2406.18294",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.18294v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18294/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18294v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18294/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18294v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18294/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18294v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18294/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18294v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18294/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18294v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18294/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18294v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18294/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18294v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18294/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18294v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18294/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18294v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18294/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18294v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18294/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18294v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18294/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18294v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18294/x13.png"
      }
    ],
    "abstract_cn": "近期开发的代码大型语言模型（Code LLMs），通过预训练于仓库级代码数据（Repo-Code LLMs），已能识别仓库结构并利用跨文件信息优化代码补全。但在实际开发中，简单拼接整个代码仓库常超出Repo-Code LLMs的上下文限制，导致性能大打折扣。本研究对六种Repo-Code LLMs进行了深入实验与分析，发现保持文件间的拓扑依赖并丰富补全提示中的代码内容能提升补全精度；而修剪依赖文件中特定函数的具体实现对精度影响不大。据此，我们提出了分层上下文修剪（HCP）策略，该策略在函数层面重构代码仓库，既保留了文件间的依赖关系，又剔除了大量无关代码，大幅缩减了仓库级代码补全的输入长度。实验证明，HCP策略能显著提升六种Repo-Code LLMs的补全精度，并大幅缩短输入长度。相关代码和数据已公开于https://github.com/Hambaobao/HCP-Coder。",
    "title_cn": "层次上下文剪枝：借助仓库级预训练代码大型语言模型，优化实际代码补全效率",
    "tags": [
      "LLM应用\n\n这篇论文主要探讨了如何优化大型语言模型（LLM）在代码补全任务中的应用，特别是在处理大型代码仓库时的上下文限制问题。通过提出分层上下文修剪（HCP）策略，该研究解决了Repo-Code LLMs在实际应用中的性能问题，提高了代码补全的精度和效率。因此，这篇论文属于LLM应用类别，因为它关注的是LLM在特定任务（代码补全）中的实际应用和优化。",
      "软件开发",
      "代码优化"
    ]
  },
  {
    "title": "\"Vorbeşti Româneşte?\" A Recipe to Train Powerful Romanian LLMs with English Instructions",
    "submit_datetime": "2024年06月26日",
    "abstract": "In recent years, Large Language Models (LLMs) have achieved almost human-like performance on various tasks. While some LLMs have been trained on multilingual data, most of the training data is in English; hence, their performance in English greatly exceeds other languages. To our knowledge, we are the first to collect and translate a large collection of texts, instructions, and benchmarks and train, evaluate, and release open-source LLMs tailored for Romanian. We evaluate our methods on four different categories, including academic benchmarks, MT-Bench (manually translated), and a professionally built historical, cultural, and social benchmark adapted to Romanian. We argue for the usefulness and high performance of RoLLMs by obtaining state-of-the-art results across the board. We publicly release all resources (i.e., data, training and evaluation code, models) to support and encourage research on Romanian LLMs while concurrently creating a generalizable recipe, adequate for other low or less-resourced languages.",
    "pdf_link": "https://arxiv.org/abs/2406.18266",
    "graphs": [],
    "abstract_cn": "近年来，大型语言模型（LLMs）在多任务处理上几乎与人类媲美。尽管部分模型接受了多语言训练，但英文数据仍占主导，使得它们在英文上的表现尤为突出。我们是首个为罗马尼亚语量身打造并发布开源LLMs的团队，通过收集、翻译大量文本及基准，并进行训练与评估。我们的方法在学术、MT-Bench（人工翻译）及专业定制的罗马尼亚历史、文化、社会基准等四个领域得到验证。我们通过全面取得顶尖成果，证明了RoLLMs的高效与优越。所有相关资源（包括数据、代码、模型）均已公开，旨在推动罗马尼亚语LLMs的研究，并为其他资源匮乏的语言提供通用方案。",
    "title_cn": "“你懂罗马尼亚语吗？” 本指南教你如何利用英语指令，培育出强大的罗马尼亚语大型语言模型。",
    "tags": [
      "LLM应用\n\n这篇论文主要介绍了为罗马尼亚语量身打造并发布开源的大型语言模型（LLMs），并通过多个领域的测试验证了其效果。这属于在特定语言环境下应用LLM技术的实例，因此归类为LLM应用。",
      "",
      "语言模型"
    ]
  },
  {
    "title": "LLaMIPa: An Incremental Discourse Parser",
    "submit_datetime": "2024年06月26日",
    "abstract": "This paper provides the first discourse parsing experiments with a large language model (LLM) finetuned on corpora annotated in the style of SDRT (Asher, 1993; Asher and Lascarides, 2003). The result is a discourse parser, LLaMIPa (LLaMA Incremental Parser), which is able to more fully exploit discourse context, leading to substantial performance gains over approaches that use encoder-only models to provide local, context-sensitive representations of discourse units. Furthermore, it is able to process discourse data incrementally, which is essential for the eventual use of discourse information in downstream tasks.",
    "pdf_link": "https://arxiv.org/abs/2406.18256",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.18256v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18256/msdc_viz.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18256v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18256/llamipadata.png"
      }
    ],
    "abstract_cn": "本研究首次探索了在SDRT风格标注的语料库上微调大型语言模型（LLM）进行语篇解析的可能性，并成功开发出LLaMIPa（LLaMA增量解析器）。这一解析器能更深入地挖掘语篇上下文，显著提升了性能，超越了依赖编码器模型提供局部上下文敏感语篇单元表示的传统方法。更重要的是，LLaMIPa能以增量方式处理语篇数据，这对于在下游任务中有效利用语篇信息具有决定性意义。",
    "title_cn": "LLaMIPa：逐步解析话语的新工具",
    "tags": [
      "LLM应用\n\n理由：这篇论文介绍了如何微调大型语言模型（LLM）以进行语篇解析，并开发了一个名为LLaMIPa的增量解析器。这个解析器能够更有效地处理语篇数据，并在下游任务中利用这些信息。这项工作专注于LLM的实际应用，即在语篇解析领域的应用，因此属于LLM应用分类。",
      "",
      "语篇解析"
    ]
  },
  {
    "title": "Improving the Consistency in Cross-Lingual Cross-Modal Retrieval with 1-to-K Contrastive Learning",
    "submit_datetime": "2024年06月26日",
    "abstract": "Cross-lingual Cross-modal Retrieval (CCR) is an essential task in web search, which aims to break the barriers between modality and language simultaneously and achieves image-text retrieval in the multi-lingual scenario with a single model. In recent years, excellent progress has been made based on cross-lingual cross-modal pre-training; particularly, the methods based on contrastive learning on large-scale data have significantly improved retrieval tasks. However, these methods directly follow the existing pre-training methods in the cross-lingual or cross-modal domain, leading to two problems of inconsistency in CCR: The methods with cross-lingual style suffer from the intra-modal error propagation, resulting in inconsistent recall performance across languages in the whole dataset. The methods with cross-modal style suffer from the inter-modal optimization direction bias, resulting in inconsistent rank across languages within each instance, which cannot be reflected by Recall@K. To solve these problems, we propose a simple but effective 1-to-K contrastive learning method, which treats each language equally and eliminates error propagation and optimization bias. In addition, we propose a new evaluation metric, Mean Rank Variance (MRV), to reflect the rank inconsistency across languages within each instance. Extensive experiments on four CCR datasets show that our method improves both recall rates and MRV with smaller-scale pre-trained data, achieving the new state-of-art.",
    "pdf_link": "https://arxiv.org/abs/2406.18254",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.18254v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18254/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18254v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18254/demo1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18254v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18254/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18254v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18254/demo2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18254v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18254/zs_6_5.jpg"
      },
      {
        "url": "https://arxiv.org/html/2406.18254v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18254/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18254v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18254/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18254v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18254/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18254v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18254/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18254v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18254/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18254v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18254/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18254v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18254/x9.png"
      }
    ],
    "abstract_cn": "跨语言跨模态检索（CCR）旨在通过单一模型，在多语言环境中实现图像与文本的检索，打破模态与语言的双重壁垒。近年来，基于大规模数据对比学习的跨语言跨模态预训练方法取得了显著进步，但这些方法沿用现有策略，导致CCR中出现两个不一致问题：跨语言方法因模态内错误传播，使得不同语言的召回性能在整个数据集中不一致；跨模态方法则因模态间优化方向偏差，导致每个实例中不同语言的排名不一致，这一现象无法通过Recall@K体现。为此，我们提出了一种平等对待每种语言的1对K对比学习方法，有效消除了错误传播和优化偏差，并引入新的评估指标——平均排名方差（MRV），以衡量不同语言间的排名不一致性。实验结果显示，我们的方法在较小的预训练数据规模下，显著提升了召回率和MRV，达到了新的技术高峰。",
    "title_cn": "采用1-to-K对比学习策略，优化跨语言跨模态检索的一致性",
    "tags": [
      "RAG\n\n理由：这篇论文主要关注的是跨语言跨模态检索（CCR）的问题，并提出了一种新的对比学习方法来解决跨语言和跨模态检索中的不一致问题。这种方法涉及到多模态数据的处理和优化，以及新的评估指标的引入，这些都是RAG（Retrieval-Augmented Generation）领域的关键技术。RAG领域通常关注如何通过检索增强生成过程，以提高模型的性能和适应性，尤其是在多语言和多模态的环境中。因此，这篇论文的内容与RAG领域的研究方向高度契合。",
      "跨语言检索",
      "多模态学习"
    ]
  },
  {
    "title": "Zero-shot prompt-based classification: topic labeling in times of foundation models in German Tweets",
    "submit_datetime": "2024年06月26日",
    "abstract": "Filtering and annotating textual data are routine tasks in many areas, like social media or news analytics. Automating these tasks allows to scale the analyses wrt. speed and breadth of content covered and decreases the manual effort required. Due to technical advancements in Natural Language Processing, specifically the success of large foundation models, a new tool for automating such annotation processes by using a text-to-text interface given written guidelines without providing training samples has become available.\n  In this work, we assess these advancements in-the-wild by empirically testing them in an annotation task on German Twitter data about social and political European crises. We compare the prompt-based results with our human annotation and preceding classification approaches, including Naive Bayes and a BERT-based fine-tuning/domain adaptation pipeline. Our results show that the prompt-based approach - despite being limited by local computation resources during the model selection - is comparable with the fine-tuned BERT but without any annotated training data. Our findings emphasize the ongoing paradigm shift in the NLP landscape, i.e., the unification of downstream tasks and elimination of the need for pre-labeled training data.",
    "pdf_link": "https://arxiv.org/abs/2406.18239",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.18239v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18239/results.overview.topic.png"
      }
    ],
    "abstract_cn": "在社交媒体和新闻分析等领域，文本数据的过滤与注释是日常工作。自动化这些流程不仅能加快分析速度，拓宽内容覆盖面，还能大幅减少人工投入。得益于自然语言处理技术的进步，尤其是大型基础模型的成功，我们现在可以通过文本到文本的接口，依据书面指南自动执行注释任务，无需提供训练样本。本研究通过在德国Twitter上关于欧洲社会政治危机的数据进行注释任务，实证评估了这些技术在实际应用中的效果。我们将基于提示的方法与人工注释及之前的分类技术（如朴素贝叶斯和基于BERT的微调/领域适应流程）进行对比。结果表明，尽管受限于本地计算资源，基于提示的方法与微调的BERT表现相当，且无需预先标注的训练数据。这一发现凸显了NLP领域正在经历的范式转变，即下游任务的整合以及对预标注训练数据依赖的减少。",
    "title_cn": "零-shot提示分类法：在基础模型盛行的当下，为德语推文贴上主题标签",
    "tags": [
      "LLM应用\n\n这篇论文主要探讨了利用大型基础模型（LLM）进行文本数据的自动化过滤与注释，特别是在社交媒体和新闻分析领域的应用。论文通过实证研究评估了这些技术在实际应用中的效果，并与传统的人工注释和其他分类技术进行了比较。研究结果显示，基于提示的方法在无需预先标注的训练数据的情况下，能够与微调的BERT模型表现相当。这表明了NLP领域正在经历的范式转变，即减少对预标注训练数据的依赖，并整合下游任务。因此，这篇论文应归类为LLM应用。",
      "社交媒体分析",
      "新闻分析"
    ]
  },
  {
    "title": "Enhancing Data Privacy in Large Language Models through Private Association Editing",
    "submit_datetime": "2024年06月26日",
    "abstract": "Large Language Models (LLMs) are powerful tools with extensive applications, but their tendency to memorize private information raises significant concerns as private data leakage can easily happen. In this paper, we introduce Private Association Editing (PAE), a novel defense approach for private data leakage. PAE is designed to effectively remove Personally Identifiable Information (PII) without retraining the model. Our approach consists of a four-step procedure: detecting memorized PII, applying PAE cards to mitigate memorization of private data, verifying resilience to targeted data extraction (TDE) attacks, and ensuring consistency in the post-edit LLMs. The versatility and efficiency of PAE, which allows for batch modifications, significantly enhance data privacy in LLMs. Experimental results demonstrate the effectiveness of PAE in mitigating private data leakage. We believe PAE will serve as a critical tool in the ongoing effort to protect data privacy in LLMs, encouraging the development of safer models for real-world applications.",
    "pdf_link": "https://arxiv.org/abs/2406.18221",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.18221v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18221/workflow_v2.1.jpg"
      },
      {
        "url": "https://arxiv.org/html/2406.18221v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18221/pre_post_graph.jpg"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）虽应用广泛，但其记忆私人信息的倾向令人担忧，私人数据泄露风险高。本文提出了一种名为私人关联编辑（PAE）的新防御策略，旨在不重新训练模型的情况下，有效移除个人身份信息（PII）。PAE通过四个步骤操作：检测记忆的PII、应用PAE卡片减轻私人数据记忆、验证对定向数据提取攻击的抵抗力，以及确保编辑后模型的一致性。PAE的批量修改能力及其高效性，显著提升了LLMs的数据隐私保护。实验证明，PAE能有效减少私人数据泄露。我们相信，PAE将成为保护LLMs数据隐私的关键工具，推动更安全模型的开发，以适应现实世界的应用需求。",
    "title_cn": "利用私有关联编辑提升大型语言模型中的数据隐私保护",
    "tags": [
      "LLM应用\n\n这篇论文主要讨论了大型语言模型（LLMs）在处理私人信息时的隐私保护问题，并提出了一种新的防御策略——私人关联编辑（PAE）。该策略旨在不重新训练模型的情况下，有效移除个人身份信息（PII），从而减少私人数据泄露的风险。这种方法直接应用于LLMs的实际应用中，以提高数据隐私保护，因此属于LLM应用分类。",
      "数据隐私",
      "人工智能安全"
    ]
  },
  {
    "title": "A Closer Look into Mixture-of-Experts in Large Language Models",
    "submit_datetime": "2024年06月26日",
    "abstract": "Mixture-of-experts (MoE) is gaining increasing attention due to its unique properties and remarkable performance, especially for language tasks. By sparsely activating a subset of parameters for each token, MoE architecture could increase the model size without sacrificing computational efficiency, achieving a better trade-off between performance and training costs. However, the underlying mechanism of MoE still lacks further exploration, and its modularization degree remains questionable. In this paper, we make an initial attempt to understand the inner workings of MoE-based large language models. Concretely, we comprehensively study the parametric and behavioral features of three recent MoE-based models and reveal some intriguing observations, including (1) Neurons act like fine-grained experts. (2) The router of MoE usually selects experts with larger output norms. (3) The expert diversity increases as the layer increases, while the last layer is an outlier. Based on the observations, we also provide suggestions for a broad spectrum of MoE practitioners, such as router design and expert allocation. We hope this work could shed light on future research on the MoE framework and other modular architectures. Code is available at https://github.com/kamanphoebe/Look-into-MoEs.",
    "pdf_link": "https://arxiv.org/abs/2406.18219",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x20.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x21.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x22.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x23.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x24.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x25.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x26.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x27.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x28.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x29.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x30.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x31.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x32.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x33.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x34.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x35.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x36.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x37.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x38.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x39.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x40.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x41.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x42.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x43.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x44.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x45.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x46.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x47.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x48.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x49.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/layer_60.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x50.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/layer_7.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/layer_7.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x51.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/layer_25.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/layer_25.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x52.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/layer_40.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/layer_40.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x53.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x54.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x55.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x56.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x57.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x58.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x59.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x60.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x61.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x62.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x63.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x64.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x65.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x66.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x67.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x68.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x69.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x70.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x71.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x72.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x73.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x74.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x75.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x76.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x77.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x78.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x79.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x80.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18219/x81.png"
      }
    ],
    "abstract_cn": "混合专家（MoE）因其独特性能，在语言任务上备受瞩目。MoE通过稀疏激活参数，在不损计算效率的前提下扩大模型规模，巧妙平衡了性能与成本。但MoE的内在机制尚待深究，其模块化程度亦存疑。本文首次深入MoE大型语言模型，详尽分析了三种MoE模型的参数与行为，揭示了神经元如细粒度专家般运作、路由器偏好输出范数大的专家、专家多样性随层数增加而增长（最后一层除外）等现象。我们为MoE实践者提供了路由器设计与专家分配的建议，期待此研究能启迪MoE及其他模块化架构的未来探索。相关代码已发布于https://github.com/kamanphoebe/Look-into-MoEs。",
    "title_cn": "深入剖析大型语言模型中的专家混合策略",
    "tags": [
      "LLM理论\n\n这篇论文深入研究了混合专家（MoE）大型语言模型的内部机制，分析了其参数和行为，并提供了关于路由器设计和专家分配的建议。这些研究内容主要关注于大型语言模型（LLM）的理论层面，特别是MoE模型的内部工作原理和性能优化，因此属于LLM理论分类。",
      "",
      "机器学习"
    ]
  },
  {
    "title": "SEED: Accelerating Reasoning Tree Construction via Scheduled Speculative Decoding",
    "submit_datetime": "2024年06月26日",
    "abstract": "Large Language Models (LLMs) demonstrate remarkable emergent abilities across various tasks, yet fall short of complex reasoning and planning tasks. The tree-search-based reasoning methods address this by surpassing the capabilities of chain-of-thought prompting, encouraging exploration of intermediate steps. However, such methods introduce significant inference latency due to the systematic exploration and evaluation of multiple thought paths. This paper introduces SeeD, a novel and efficient inference framework to optimize runtime speed and GPU memory management concurrently. By employing a scheduled speculative execution, SeeD efficiently handles multiple iterations for the thought generation and the state evaluation, leveraging a rounds-scheduled strategy to manage draft model dispatching. Extensive experimental evaluations on three reasoning datasets demonstrate superior speedup performance of SeeD, providing a viable path for batched inference in training-free speculative decoding.",
    "pdf_link": "https://arxiv.org/abs/2406.18200",
    "graphs": [],
    "abstract_cn": "大型语言模型虽在多任务中表现出色，但在复杂推理与规划上仍显不足。基于树搜索的推理方法超越了传统的思维链提示，鼓励深入探索推理的中间步骤，但这也带来了显著的推理延迟。为此，本文提出了SeeD框架，一种创新的推理机制，旨在提升运行效率并优化GPU内存使用。SeeD通过计划性推测执行，高效管理思维生成与状态评估的迭代过程，并采用轮次调度策略精准分发草稿模型。实验结果表明，SeeD在三个推理数据集上均实现了显著加速，为无训练推测解码中的批量推理开辟了新路径。",
    "title_cn": "SEED：利用计划推测解码技术，加速推理树的构建过程",
    "tags": [
      "LLM理论\n\n这篇论文主要探讨了大型语言模型在复杂推理与规划方面的不足，并提出了一种名为SeeD的新型推理机制。该机制通过计划性推测执行和轮次调度策略来优化推理过程的效率和GPU内存使用。因此，这篇论文更偏向于对大型语言模型理论层面的研究和改进，而不是具体的应用案例或Agent的设计，也不是关于RAG（Retrieval-Augmented Generation）的研究。所以，将其归类为LLM理论是合适的。",
      "人工智能",
      "推理系统"
    ]
  },
  {
    "title": "Methodology of Adapting Large English Language Models for Specific Cultural Contexts",
    "submit_datetime": "2024年06月26日",
    "abstract": "The rapid growth of large language models(LLMs) has emerged as a prominent trend in the field of artificial intelligence. However, current state-of-the-art LLMs are predominantly based on English. They encounter limitations when directly applied to tasks in specific cultural domains, due to deficiencies in domain-specific knowledge and misunderstandings caused by differences in cultural values. To address this challenge, our paper proposes a rapid adaptation method for large models in specific cultural contexts, which leverages instruction-tuning based on specific cultural knowledge and safety values data. Taking Chinese as the specific cultural context and utilizing the LLaMA3-8B as the experimental English LLM, the evaluation results demonstrate that the adapted LLM significantly enhances its capabilities in domain-specific knowledge and adaptability to safety values, while maintaining its original expertise advantages.",
    "pdf_link": "https://arxiv.org/abs/2406.18192",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.18192v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18192/fig1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18192v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18192/fig2.png"
      }
    ],
    "abstract_cn": "大型语言模型(LLMs)的迅猛发展已成为人工智能领域的一大亮点。尽管如此，当前顶尖的LLMs多以英语为基础，面对特定文化领域的任务时，常因缺乏领域专知和文化价值观差异而受限。为此，我们提出了一种针对特定文化背景的LLMs快速适应方法，该方法通过特定文化知识和安全价值观数据的指令调整实现。以中文为特定文化背景，选用LLaMA3-8B作为实验英语LLM，评估结果显示，适应后的LLM在特定领域知识和安全价值观适应性上有了显著提升，同时保留了原有的专业优势。",
    "title_cn": "大型英语语言模型适应特定文化背景的方法论研究",
    "tags": [
      "LLM应用\n\n这篇论文摘要描述了一种针对特定文化背景的LLMs快速适应方法，该方法通过特定文化知识和安全价值观数据的指令调整实现。这种方法特别针对中文文化背景，并使用了LLaMA3-8B作为实验英语LLM。研究结果显示，适应后的LLM在特定领域知识和安全价值观适应性上有了显著提升，同时保留了原有的专业优势。这表明论文主要关注的是LLM在特定应用场景下的实际应用和改进，因此应归类为LLM应用。",
      "文化适应",
      "人工智能"
    ]
  },
  {
    "title": "Selective Prompting Tuning for Personalized Conversations with LLMs",
    "submit_datetime": "2024年06月26日",
    "abstract": "In conversational AI, personalizing dialogues with persona profiles and contextual understanding is essential. Despite large language models' (LLMs) improved response coherence, effective persona integration remains a challenge. In this work, we first study two common approaches for personalizing LLMs: textual prompting and direct fine-tuning. We observed that textual prompting often struggles to yield responses that are similar to the ground truths in datasets, while direct fine-tuning tends to produce repetitive or overly generic replies. To alleviate those issues, we propose \\textbf{S}elective \\textbf{P}rompt \\textbf{T}uning (SPT), which softly prompts LLMs for personalized conversations in a selective way. Concretely, SPT initializes a set of soft prompts and uses a trainable dense retriever to adaptively select suitable soft prompts for LLMs according to different input contexts, where the prompt retriever is dynamically updated through feedback from the LLMs. Additionally, we propose context-prompt contrastive learning and prompt fusion learning to encourage the SPT to enhance the diversity of personalized conversations. Experiments on the CONVAI2 dataset demonstrate that SPT significantly enhances response diversity by up to 90\\%, along with improvements in other critical performance indicators. Those results highlight the efficacy of SPT in fostering engaging and personalized dialogue generation. The SPT model code (https://github.com/hqsiswiliam/SPT) is publicly available for further exploration.",
    "pdf_link": "https://arxiv.org/abs/2406.18187",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.18187v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18187/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18187v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18187/turns_analysis.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18187v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18187/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18187v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18187/x3.png"
      }
    ],
    "abstract_cn": "在对话AI领域，个性化对话的关键在于结合人物角色配置和上下文理解。尽管大型语言模型（LLMs）的响应连贯性有所提升，但如何有效融入人物角色仍是一大挑战。本研究探讨了两种个性化LLMs的常用方法：文本提示和直接微调。我们发现，文本提示难以生成与数据集真实情况相符的响应，而直接微调则易产生重复或过于泛化的回复。为此，我们提出了选择性提示调优（SPT），它通过选择性地使用软提示，引导LLMs进行个性化对话。具体而言，SPT初始化一组软提示，并利用可训练的密集检索器，根据输入上下文动态选择合适的软提示，并通过LLMs的反馈持续优化检索器。此外，我们还引入了上下文-提示对比学习和提示融合学习，以增强个性化对话的多样性。实验结果显示，SPT在CONVAI2数据集上显著提升了响应多样性，高达90%，并在其他关键性能指标上也有显著改进。这些成果凸显了SPT在推动吸引人和个性化对话生成方面的潜力。SPT模型代码已公开发布于GitHub（https://github.com/hqsiswiliam/SPT），供研究者深入探索。",
    "title_cn": "个性化对话：通过选择性提示调整优化与 LLMs 的交互",
    "tags": [
      "Agent\n\n这篇论文主要探讨了在对话AI领域中如何通过个性化方法提升大型语言模型（LLMs）的性能，特别是在结合人物角色配置和上下文理解方面。研究中提出的选择性提示调优（SPT）方法，通过动态选择合适的软提示并利用LLMs的反馈进行优化，显著提升了个性化对话的多样性和质量。这种方法可以被视为一种智能Agent的行为，因为它涉及到对环境的感知（上下文理解）和适应性决策（选择和优化提示），以实现更有效的交互。因此，这篇论文更适合归类于Agent分类。",
      "对话系统",
      "人工智能"
    ]
  },
  {
    "title": "An Empirical Study of Unit Test Generation with Large Language Models",
    "submit_datetime": "2024年06月26日",
    "abstract": "Unit testing is an essential activity in software development for verifying the correctness of software components. However, manually writing unit tests is challenging and time-consuming. The emergence of Large Language Models (LLMs) offers a new direction for automating unit test generation. Existing research primarily focuses on closed-source LLMs (e.g., ChatGPT and CodeX) with fixed prompting strategies, leaving the capabilities of advanced open-source LLMs with various prompting settings unexplored. Particularly, open-source LLMs offer advantages in data privacy protection and have demonstrated superior performance in some tasks. Moreover, effective prompting is crucial for maximizing LLMs' capabilities. In this paper, we conduct the first empirical study to fill this gap, based on 17 Java projects, five widely-used open-source LLMs with different structures and parameter sizes, and comprehensive evaluation metrics. Our findings highlight the significant influence of various prompt factors, show the performance of open-source LLMs compared to the commercial GPT-4 and the traditional Evosuite, and identify limitations in LLM-based unit test generation. We then derive a series of implications from our study to guide future research and practical use of LLM-based unit test generation.",
    "pdf_link": "https://arxiv.org/abs/2406.18181",
    "graphs": [],
    "abstract_cn": "单元测试在软件开发中至关重要，但手动编写既费时又具挑战性。大型语言模型（LLMs）的出现为自动化单元测试生成开辟了新途径。尽管现有研究多聚焦于闭源模型如ChatGPT和CodeX，但开源LLMs在数据隐私保护和某些任务上的表现已显示出其优势。有效的提示策略对发挥LLMs潜力至关重要。本研究首次基于17个Java项目，对比了五种不同结构和规模的开源LLMs，以及全面的评估指标，揭示了提示因素对性能的显著影响，并与商业GPT-4及传统工具Evosuite进行了比较，指出了基于LLM的单元测试生成中的局限。研究结果为未来基于LLM的单元测试生成提供了指导和启示。",
    "title_cn": "大型语言模型在单元测试生成领域的实证探索",
    "tags": [
      "LLM应用\n\n这篇论文探讨了大型语言模型（LLMs）在自动化单元测试生成中的应用，特别是在开源模型中的应用。它比较了不同结构和规模的开源LLMs，并评估了提示策略对性能的影响。这与LLM的理论研究不同，因为它关注的是LLM在实际软件开发任务中的应用，而不是模型本身的理论基础或机制。此外，它也不涉及Agent或RAG的相关概念。因此，最合适的分类是LLM应用。",
      "软件开发",
      "自动化测试"
    ]
  },
  {
    "title": "UIO-LLMs: Unbiased Incremental Optimization for Long-Context LLMs",
    "submit_datetime": "2024年06月26日",
    "abstract": "Managing long texts is challenging for large language models (LLMs) due to limited context window sizes. This study introduces UIO-LLMs, an unbiased incremental optimization approach for memory-enhanced transformers under long-context settings. We initially conceptualize the process as a streamlined encoder-decoder framework where the weights-shared encoder and decoder respectively encapsulate a context segment into memories and leverage these memories to predict outputs of the subsequent segment. Subsequently, by treating our memory-enhanced transformers as fully-connected recurrent neural networks (RNNs), we refine the training process using the Truncated Backpropagation Through Time (TBPTT) algorithm, which incorporates innovative incremental optimization techniques. These techniques not only diminish time complexity but also address the bias in gradient computation through an unbiased optimization process. UIO-LLMs successfully handle long context, such as extending the context window of Llama2-7b-chat from 4K to 100K tokens with minimal 2% additional parameters, while keeping the inference cost nearly linear as context length increases.",
    "pdf_link": "https://arxiv.org/abs/2406.18173",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2406.18173v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18173/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18173v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18173/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18173v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18173/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18173v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18173/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18173v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18173/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18173v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18173/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18173v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18173/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2406.18173v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2406.18173/x8.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）因上下文窗口有限而难以处理长文本。本研究提出的UIO-LLMs，是一种针对长上下文环境下增强记忆transformer的无偏增量优化方法。我们首先将此过程设想为一个精简的编码器-解码器框架，其中共享权重的编码器和解码器分别将上下文片段转化为记忆，并利用这些记忆预测后续片段的输出。接着，我们将这些增强记忆的transformer视为全连接循环神经网络（RNNs），并采用截断的反向传播通过时间（TBPTT）算法优化训练，引入了创新的增量优化技术，既降低了时间复杂度，又通过无偏优化过程纠正了梯度计算中的偏差。UIO-LLMs有效应对了长上下文挑战，例如将Llama2-7b-chat的上下文窗口从4K扩展至100K令牌，仅增加了2%的额外参数，且推理成本随上下文长度增加而几乎保持线性。",
    "title_cn": "UIO-LLMs：长上下文大型语言模型的无偏渐进优化",
    "tags": [
      "LLM理论\n\n理由：这篇论文主要探讨了大型语言模型（LLMs）在处理长文本时的局限性，并提出了一种新的优化方法UIO-LLMs，旨在增强模型在长上下文环境下的表现。该研究涉及模型的内部机制和优化技术，如无偏增量优化方法和截断的反向传播通过时间（TBPTT）算法，这些都是对LLM理论层面的深入探讨。因此，这篇论文更适合归类于LLM理论。",
      "",
      "机器学习"
    ]
  },
  {
    "title": "Automatic Speech Recognition for Hindi",
    "submit_datetime": "2024年06月26日",
    "abstract": "Automatic speech recognition (ASR) is a key area in computational linguistics, focusing on developing technologies that enable computers to convert spoken language into text. This field combines linguistics and machine learning. ASR models, which map speech audio to transcripts through supervised learning, require handling real and unrestricted text. Text-to-speech systems directly work with real text, while ASR systems rely on language models trained on large text corpora. High-quality transcribed data is essential for training predictive models. The research involved two main components: developing a web application and designing a web interface for speech recognition. The web application, created with JavaScript and Node.js, manages large volumes of audio files and their transcriptions, facilitating collaborative human correction of ASR transcripts. It operates in real-time using a client-server architecture. The web interface for speech recognition records 16 kHz mono audio from any device running the web app, performs voice activity detection (VAD), and sends the audio to the recognition engine. VAD detects human speech presence, aiding efficient speech processing and reducing unnecessary processing during non-speech intervals, thus saving computation and network bandwidth in VoIP applications. The final phase of the research tested a neural network for accurately aligning the speech signal to hidden Markov model (HMM) states. This included implementing a novel backpropagation method that utilizes prior statistics of node co-activations.",
    "pdf_link": "https://arxiv.org/abs/2406.18135",
    "graphs": [],
    "abstract_cn": "自动语音识别（ASR）领域结合了语言学与机器学习，致力于开发让计算机将口语转换为文本的技术。ASR模型通过监督学习将语音转换为文本，需处理真实且无限制的文本，而依赖于大规模文本训练的语言模型。高质量转录数据对预测模型训练至关重要。研究包括开发网络应用和设计语音识别界面两大部分。该应用使用JavaScript和Node.js，管理音频文件及其转录，支持实时协作校正ASR转录。语音识别界面从设备记录16kHz音频，进行语音活动检测（VAD），并将音频发送到识别引擎，有效减少非语音时段的处理，节省VoIP应用中的计算和带宽。研究最终测试了神经网络，实现语音信号与HMM状态的精确对齐，采用了一种利用节点共激活统计的新反向传播方法。",
    "title_cn": "印地语自动语音识别探索",
    "tags": [
      "Agent\n\n理由：这篇论文主要描述了一个自动语音识别（ASR）系统的开发和应用，包括网络应用的开发和语音识别界面的设计。这些内容涉及到构建一个能够处理语音数据并将其转换为文本的系统，这可以被视为一个Agent的行为，因为它涉及到对环境的感知（通过音频输入）和响应（通过文本输出）。此外，论文中提到的实时协作校正ASR转录和优化语音识别过程的技术细节，进一步强调了这是一个Agent系统的特征。虽然ASR技术可能与大型语言模型（LLM）有关，但论文的重点在于系统的应用和实现，而不是LLM的理论研究或特定于LLM的应用开发。因此，将其归类为Agent更为合适。"