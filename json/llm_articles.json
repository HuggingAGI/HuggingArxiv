[
  {
    "title": "Plan-Seq-Learn: Language Model Guided RL for Solving Long Horizon Robotics Tasks",
    "submit_datetime": "2024年05月02日",
    "abstract": "Large Language Models (LLMs) have been shown to be capable of performing high-level planning for long-horizon robotics tasks, yet existing methods require access to a pre-defined skill library (e.g. picking, placing, pulling, pushing, navigating). However, LLM planning does not address how to design or learn those behaviors, which remains challenging particularly in long-horizon settings. Furthermore, for many tasks of interest, the robot needs to be able to adjust its behavior in a fine-grained manner, requiring the agent to be capable of modifying low-level control actions. Can we instead use the internet-scale knowledge from LLMs for high-level policies, guiding reinforcement learning (RL) policies to efficiently solve robotic control tasks online without requiring a pre-determined set of skills? In this paper, we propose Plan-Seq-Learn (PSL): a modular approach that uses motion planning to bridge the gap between abstract language and learned low-level control for solving long-horizon robotics tasks from scratch. We demonstrate that PSL achieves state-of-the-art results on over 25 challenging robotics tasks with up to 10 stages. PSL solves long-horizon tasks from raw visual input spanning four benchmarks at success rates of over 85%, out-performing language-based, classical, and end-to-end approaches. Video results and code at https://mihdalal.github.io/planseqlearn/",
    "pdf_link": "https://arxiv.org/abs/2405.01534",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）展现出能够为长期机器人任务进行高级规划的能力，但现有技术依赖于一个预先定义的技能库，如抓取、放置等。LLM在规划方面的应用尚未触及如何设计或学习这些技能，尤其在长期任务中，这仍是一个难题。此外，机器人在执行许多任务时需要精细调整行为，这就需要能够灵活修改底层控制动作。是否可以利用LLMs的海量知识来指导高层策略，通过强化学习（RL）策略在线高效解决机器人控制任务，而无需依赖预设技能集？本文提出了Plan-Seq-Learn（PSL），一种模块化方法，它通过运动规划将抽象语言与学习到的低级控制相结合，以解决从零开始的长期机器人任务。PSL在超过25个具有挑战性的机器人任务上取得了业界领先的成绩，这些任务包含多达10个阶段。基于原始视觉输入，PSL在四个基准测试中的成功率超过85%，超越了基于语言、传统和端到端的解决方案。相关视频和代码可在 https://mihdalal.github.io/planseqlearn/ 查看。",
    "title_cn": "Plan-Seq-Learn：一种由语言模型引导的强化学习方法，专为解决机器人领域的长期任务而设计。",
    "tags": [
      "分类：Agent",
      "机器人技术",
      ""
    ]
  },
  {
    "title": "OmniDrive: A Holistic LLM-Agent Framework for Autonomous Driving with 3D Perception, Reasoning and Planning",
    "submit_datetime": "2024年05月02日",
    "abstract": "The advances in multimodal large language models (MLLMs) have led to growing interests in LLM-based autonomous driving agents to leverage their strong reasoning capabilities. However, capitalizing on MLLMs' strong reasoning capabilities for improved planning behavior is challenging since planning requires full 3D situational awareness beyond 2D reasoning. To address this challenge, our work proposes a holistic framework for strong alignment between agent models and 3D driving tasks. Our framework starts with a novel 3D MLLM architecture that uses sparse queries to lift and compress visual representations into 3D before feeding them into an LLM. This query-based representation allows us to jointly encode dynamic objects and static map elements (e.g., traffic lanes), providing a condensed world model for perception-action alignment in 3D. We further propose OmniDrive-nuScenes, a new visual question-answering dataset challenging the true 3D situational awareness of a model with comprehensive visual question-answering (VQA) tasks, including scene description, traffic regulation, 3D grounding, counterfactual reasoning, decision making and planning. Extensive studies show the effectiveness of the proposed architecture as well as the importance of the VQA tasks for reasoning and planning in complex 3D scenes.",
    "pdf_link": "https://arxiv.org/abs/2405.01533",
    "graphs": [],
    "abstract_cn": "随着多模态大型语言模型（MLLMs）的飞速发展，人们越来越关注利用这些模型强大推理能力的基于LLM的自动驾驶系统。然而，要利用MLLMs的推理能力来提升规划行为并非易事，因为这需要超越二维推理的三维情境感知。为解决这一难题，本研究提出了一个全新的框架，旨在实现代理模型与三维驾驶任务之间的紧密协同。该框架采用了创新的三维MLLM架构，通过稀疏查询技术将视觉信息提升并压缩成三维数据，再输入至LLM进行处理。这种基于查询的表示方法能够同时编码动态物体和静态地图元素，如交通线路等，为三维空间中的感知与行动对齐提供了一个精简的世界模型。此外，我们还推出了OmniDrive-nuScenes，这是一个全新的视觉问答数据集，它通过包含场景描述、交通规则、三维定位、反事实推理、决策制定和规划在内的全面视觉问答任务，挑战模型的真正三维情境感知能力。广泛的研究证实了所提出架构的有效性，以及视觉问答任务在复杂三维场景中推理和规划中的关键作用。",
    "title_cn": "OmniDrive：一套综合性的LLM代理框架，专为自动驾驶设计，集成了3D感知、推理和规划功能。",
    "tags": [
      "Agent",
      "自动驾驶",
      "人工智能"
    ]
  },
  {
    "title": "FLAME: Factuality-Aware Alignment for Large Language Models",
    "submit_datetime": "2024年05月02日",
    "abstract": "Alignment is a standard procedure to fine-tune pre-trained large language models (LLMs) to follow natural language instructions and serve as helpful AI assistants. We have observed, however, that the conventional alignment process fails to enhance the factual accuracy of LLMs, and often leads to the generation of more false facts (i.e. hallucination). In this paper, we study how to make the LLM alignment process more factual, by first identifying factors that lead to hallucination in both alignment steps:\\ supervised fine-tuning (SFT) and reinforcement learning (RL). In particular, we find that training the LLM on new knowledge or unfamiliar texts can encourage hallucination. This makes SFT less factual as it trains on human labeled data that may be novel to the LLM. Furthermore, reward functions used in standard RL can also encourage hallucination, because it guides the LLM to provide more helpful responses on a diverse set of instructions, often preferring longer and more detailed responses. Based on these observations, we propose factuality-aware alignment, comprised of factuality-aware SFT and factuality-aware RL through direct preference optimization. Experiments show that our proposed factuality-aware alignment guides LLMs to output more factual responses while maintaining instruction-following capability.",
    "pdf_link": "https://arxiv.org/abs/2405.01525",
    "graphs": [],
    "abstract_cn": "对齐技术用于优化预训练的大型语言模型（LLMs），使其能够更好地遵循自然语言指令，充当智能AI助手。但我们发现，传统对齐方法并未有效提升LLMs的事实准确性，反而可能产生更多错误信息。本文深入探讨了如何提升LLM对齐过程的事实性，首先分析了在监督式微调（SFT）和强化学习（RL）两个对齐步骤中导致幻觉现象的因素。我们发现，对LLM进行新知识或不熟悉文本的训练可能会诱发幻觉，这降低了SFT的事实准确性，因为它依赖于对LLM而言可能是新奇的人类标注数据。此外，标准RL中的奖励机制也可能促进幻觉，因为它倾向于引导LLM提供更长、更详细的响应，以适应多样化的指令需求。针对这些问题，我们提出了一种新的事实性感知对齐方法，包括事实性感知SFT和通过直接偏好优化的事实性感知RL。实验结果表明，该方法能够有效提升LLMs生成事实性响应的能力，同时不损害其遵循指令的能力。",
    "title_cn": "FLAME：为大型语言模型打造的事实感知对齐技术",
    "tags": [
      "LLM应用",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Transformer-Aided Semantic Communications",
    "submit_datetime": "2024年05月02日",
    "abstract": "The transformer structure employed in large language models (LLMs), as a specialized category of deep neural networks (DNNs) featuring attention mechanisms, stands out for their ability to identify and highlight the most relevant aspects of input data. Such a capability is particularly beneficial in addressing a variety of communication challenges, notably in the realm of semantic communication where proper encoding of the relevant data is critical especially in systems with limited bandwidth. In this work, we employ vision transformers specifically for the purpose of compression and compact representation of the input image, with the goal of preserving semantic information throughout the transmission process. Through the use of the attention mechanism inherent in transformers, we create an attention mask. This mask effectively prioritizes critical segments of images for transmission, ensuring that the reconstruction phase focuses on key objects highlighted by the mask. Our methodology significantly improves the quality of semantic communication and optimizes bandwidth usage by encoding different parts of the data in accordance with their semantic information content, thus enhancing overall efficiency. We evaluate the effectiveness of our proposed framework using the TinyImageNet dataset, focusing on both reconstruction quality and accuracy. Our evaluation results demonstrate that our framework successfully preserves semantic information, even when only a fraction of the encoded data is transmitted, according to the intended compression rates.",
    "pdf_link": "https://arxiv.org/abs/2405.01521",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）中的变换器结构，作为深度神经网络（DNNs）的一个特殊类别，以其识别和强调输入数据中最重要方面的能力而著称。这一特性在多种通信挑战中尤为有用，尤其是在语义通信领域，恰当地编码相关数据对于带宽受限的系统至关重要。本研究中，我们专门采用视觉变换器对输入图像进行压缩和紧凑表示，以在传输过程中保持语义信息。利用变换器内在的注意力机制，我们生成了一个注意力掩码，该掩码有效优先传输图像的关键部分，确保重建阶段集中于掩码标记的关键对象。我们的技术显著提升了语义通信质量，并优化了带宽使用效率，通过根据数据的语义信息含量对数据的不同部分进行编码。通过TinyImageNet数据集的测试，我们专注于重建质量和准确性的评估，结果证明我们的框架即便在仅传输部分编码数据的情况下，也能成功保持语义信息，达到预期的压缩比率。",
    "title_cn": "借助Transformer的语义通信技术",
    "tags": [
      "LLM应用",
      "",
      "图像处理"
    ]
  },
  {
    "title": "Analyzing the Role of Semantic Representations in the Era of Large Language Models",
    "submit_datetime": "2024年05月02日",
    "abstract": "Traditionally, natural language processing (NLP) models often use a rich set of features created by linguistic expertise, such as semantic representations. However, in the era of large language models (LLMs), more and more tasks are turned into generic, end-to-end sequence generation problems. In this paper, we investigate the question: what is the role of semantic representations in the era of LLMs? Specifically, we investigate the effect of Abstract Meaning Representation (AMR) across five diverse NLP tasks. We propose an AMR-driven chain-of-thought prompting method, which we call AMRCoT, and find that it generally hurts performance more than it helps. To investigate what AMR may have to offer on these tasks, we conduct a series of analysis experiments. We find that it is difficult to predict which input examples AMR may help or hurt on, but errors tend to arise with multi-word expressions, named entities, and in the final inference step where the LLM must connect its reasoning over the AMR to its prediction. We recommend focusing on these areas for future work in semantic representations for LLMs. Our code: https://github.com/causalNLP/amr_llm.",
    "pdf_link": "https://arxiv.org/abs/2405.01502",
    "graphs": [],
    "abstract_cn": "在传统NLP模型中，专家们精心构建的语义表示等特征集曾是关键。但在大型语言模型（LLMs）盛行的今天，众多任务已简化为标准化的序列生成问题。本文旨在探究：在LLMs主导的当下，语义表示的功能何在？我们特别关注了抽象意义表示（AMR）在五项多样化NLP任务中的应用。我们引入了一种新颖的AMR驱动的思维链提示技术，命名为AMRCoT，却发现其效果往往适得其反。为了深入理解AMR的潜力，我们开展了一系列深入的分析实验。实验结果表明，AMR对输入样本的正负影响难以预判，但问题多出现在多词短语、命名实体识别以及LLM将AMR推理与预测结果相连结的最终步骤。基于此，我们建议未来的研究应聚焦于这些关键领域，以优化LLMs中的语义表示。相关代码已在GitHub上公开：https://github.com/causalNLP/amr_llm。",
    "title_cn": "在大型语言模型盛行的当下，深入探讨语义表示的角色与重要性。",
    "tags": [
      "LLM应用",
      "",
      "机器学习"
    ]
  },
  {
    "title": "Supporting Business Document Workflows via Collection-Centric Information Foraging with Large Language Models",
    "submit_datetime": "2024年05月02日",
    "abstract": "Knowledge workers often need to extract and analyze information from a collection of documents to solve complex information tasks in the workplace, e.g., hiring managers reviewing resumes or analysts assessing risk in contracts. However, foraging for relevant information can become tedious and repetitive over many documents and criteria of interest. We introduce Marco, a mixed-initiative workspace supporting sensemaking over diverse business document collections. Through collection-centric assistance, Marco reduces the cognitive costs of extracting and structuring information, allowing users to prioritize comparative synthesis and decision making processes. Users interactively communicate their information needs to an AI assistant using natural language and compose schemas that provide an overview of a document collection. Findings from a usability study (n=16) demonstrate that when using Marco, users complete sensemaking tasks 16% more quickly, with less effort, and without diminishing accuracy. A design probe with seven domain experts identifies how Marco can benefit various real-world workflows.",
    "pdf_link": "https://arxiv.org/abs/2405.01501",
    "graphs": [],
    "abstract_cn": "职场中的知识工作者经常需要从众多文档中提炼和分析信息，以应对诸如审查简历或评估合同风险等复杂信息挑战。然而，这种信息搜集工作在面对大量文档和多元标准时，往往会变得单调乏味。为此，我们推出了Marco——一个混合主动式工作空间，它通过集合中心的辅助功能，帮助用户在多样化的商业文档集合中进行意义构建。Marco通过降低信息提取和结构化的心理负担，使用户能够更专注于比较综合和决策过程。用户可以通过自然语言与AI助手互动，表达他们的信息需求，并创建模式来概览整个文档集合。一项涉及16名参与者的可用性研究显示，使用Marco的用户在完成意义构建任务时，速度提升了16%，且更为轻松，同时保持了准确性。此外，与七位领域专家的深入探讨揭示了Marco如何能够优化各种现实工作流程的效率。",
    "title_cn": "利用大型语言模型，通过集中式信息搜集，助力商业文档工作流程的优化。",
    "tags": [
      "分类：Agent",
      "职场自动化",
      "信息分析"
    ]
  },
  {
    "title": "Controllable Text Generation in the Instruction-Tuning Era",
    "submit_datetime": "2024年05月02日",
    "abstract": "While most research on controllable text generation has focused on steering base Language Models, the emerging instruction-tuning and prompting paradigm offers an alternate approach to controllability. We compile and release ConGenBench, a testbed of 17 different controllable generation tasks, using a subset of it to benchmark the performance of 9 different baselines and methods on Instruction-tuned Language Models. To our surprise, we find that prompting-based approaches outperform controllable text generation methods on most datasets and tasks, highlighting a need for research on controllable text generation with Instruction-tuned Language Models in specific. Prompt-based approaches match human performance on most stylistic tasks while lagging on structural tasks, foregrounding a need to study more varied constraints and more challenging stylistic tasks. To facilitate such research, we provide an algorithm that uses only a task dataset and a Large Language Model with in-context capabilities to automatically generate a constraint dataset. This method eliminates the fields dependence on pre-curated constraint datasets, hence vastly expanding the range of constraints that can be studied in the future.",
    "pdf_link": "https://arxiv.org/abs/2405.01490",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.01490v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01490/Combinedplot.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01490v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01490/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01490v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01490/TaskWindow.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01490v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01490/ShortInstructions.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01490v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01490/LongInstructionsDef.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01490v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01490/ContentWarning.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01490v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01490/Examples.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01490v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01490/Examples1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01490v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01490/Examples2.png"
      }
    ],
    "abstract_cn": "目前，可控文本生成的研究多集中于引导基础语言模型，而新兴的指令调整与提示技术则为我们提供了另一种控制文本生成的途径。我们创建并公开了 ConGenBench，一个包含 17 项不同可控文本生成任务的测试集，并利用其中的一部分对 9 种不同的基线和指令调整语言模型上的方法进行了性能评估。出人意料的是，基于提示的方法在多数数据集和任务上超越了传统的可控文本生成技术，这表明我们需要特别针对指令调整语言模型进行更深入的可控文本生成研究。此外，基于提示的方法在大多数风格化任务上与人类表现不相上下，但在结构化任务上仍有所欠缺，这提示我们需进一步探索更多样化的约束条件和更具挑战性的风格化任务。为了推动这一领域的研究，我们开发了一种算法，它能够仅利用任务数据集和具备上下文功能的大语言模型，自动生成约束数据集，从而摆脱了对预制约束数据集的依赖，极大地拓宽了未来研究中可探讨的约束范围。",
    "title_cn": "在指令调整时代下的可控文本生成",
    "tags": [
      "LLM应用",
      "",
      "文本生成"
    ]
  },
  {
    "title": "MANTIS: Interleaved Multi-Image Instruction Tuning",
    "submit_datetime": "2024年05月02日",
    "abstract": "The recent years have witnessed a great array of large multimodal models (LMMs) to effectively solve single-image vision language tasks. However, their abilities to solve multi-image visual language tasks is yet to be improved. The existing multi-image LMMs (e.g. OpenFlamingo, Emu, Idefics, etc) mostly gain their multi-image ability through pre-training on hundreds of millions of noisy interleaved image-text data from web, which is neither efficient nor effective. In this paper, we aim at building strong multi-image LMMs via instruction tuning with academic-level resources. Therefore, we meticulously construct Mantis-Instruct containing 721K instances from 14 multi-image datasets. We design Mantis-Instruct to cover different multi-image skills like co-reference, reasoning, comparing, temporal understanding. We combine Mantis-Instruct with several single-image visual-language datasets to train our model Mantis to handle any interleaved image-text inputs. We evaluate the trained Mantis on five multi-image benchmarks and eight single-image benchmarks. Though only requiring academic-level resources (i.e. 36 hours on 16xA100-40G), Mantis-8B can achieve state-of-the-art performance on all the multi-image benchmarks and beats the existing best multi-image LMM Idefics2-8B by an average of 9 absolute points. We observe that Mantis performs equivalently well on the held-in and held-out evaluation benchmarks. We further evaluate Mantis on single-image benchmarks and demonstrate that Mantis can maintain a strong single-image performance on par with CogVLM and Emu2. Our results are particularly encouraging as it shows that low-cost instruction tuning is indeed much more effective than intensive pre-training in terms of building multi-image LMMs.",
    "pdf_link": "https://arxiv.org/abs/2405.01483",
    "graphs": [],
    "abstract_cn": "近年来，众多大型多模态模型（LMMs）在处理单图像视觉语言任务上展现出了卓越的能力。但它们在处理多图像视觉语言任务上的表现尚需精进。目前，多图像LMMs如OpenFlamingo、Emu、Idefics等，主要通过在海量网络中的噪声交织图像-文本数据上进行预训练来提升其多图像处理能力，这种方法既不高效也不尽如人意。本文提出了一种新方法，即通过学术级资源的指令调优来构建强大的多图像LMMs。我们精心打造了Mantis-Instruct，内含14个多图像数据集中的721K实例，旨在涵盖共指、推理、比较、时间理解等多种多图像技能。我们将Mantis-Instruct与多个单图像视觉-语言数据集结合，训练出能够处理任何交织图像-文本输入的模型Mantis。在五个多图像基准和八个单图像基准上的评估结果显示，Mantis-8B仅需36小时的16xA100-40G学术级资源，就能在所有多图像基准上达到最先进的性能，并且平均领先于现有的最佳多图像LMM Idefics2-8B 9个百分点。Mantis在保留和非保留评估基准上的表现同样出色。此外，Mantis在单图像基准上的表现也证明了其在单图像性能上与CogVLM和Emu2不相上下。这些结果特别振奋人心，因为它们表明低成本的指令调优在构建多图像LMMs方面，确实比大规模预训练更为有效。",
    "title_cn": "MANTIS：交错式多图像指令优化",
    "tags": [
      "分类：LLM应用",
      "计算机视觉",
      ""
    ]
  },
  {
    "title": "NeMo-Aligner: Scalable Toolkit for Efficient Model Alignment",
    "submit_datetime": "2024年05月02日",
    "abstract": "Aligning Large Language Models (LLMs) with human values and preferences is essential for making them helpful and safe. However, building efficient tools to perform alignment can be challenging, especially for the largest and most competent LLMs which often contain tens or hundreds of billions of parameters. We create NeMo-Aligner, a toolkit for model alignment that can efficiently scale to using hundreds of GPUs for training. NeMo-Aligner comes with highly optimized and scalable implementations for major paradigms of model alignment such as: Reinforcement Learning from Human Feedback (RLHF), Direct Preference Optimization (DPO), SteerLM, and Self-Play Fine-Tuning (SPIN). Additionally, our toolkit supports running most of the alignment techniques in a Parameter Efficient Fine-Tuning (PEFT) setting. NeMo-Aligner is designed for extensibility, allowing support for other alignment techniques with minimal effort. It is open-sourced with Apache 2.0 License and we invite community contributions at https://github.com/NVIDIA/NeMo-Aligner",
    "pdf_link": "https://arxiv.org/abs/2405.01481",
    "graphs": [],
    "abstract_cn": "确保大型语言模型（LLMs）与人类的价值观和偏好保持一致，对于提升其实用性和安全性至关重要。然而，为这些参数量庞大的模型构建高效的对齐工具并非易事。为此，我们开发了 NeMo-Aligner，这是一款能够高效扩展至数百个 GPU 并行训练的模型对齐工具包。它集成了多种模型对齐范式的优化实现，包括基于人类反馈的强化学习（RLHF）、直接偏好优化（DPO）、SteerLM 以及自对弈微调（SPIN）。NeMo-Aligner 还支持在参数高效微调（PEFT）环境下运行大多数对齐技术。该工具包设计上注重扩展性，易于添加其他对齐技术。NeMo-Aligner 已在 Apache 2.0 许可下开源，并在 https://github.com/NVIDIA/NeMo-Aligner 欢迎社区贡献。",
    "title_cn": "NeMo-Aligner：高效模型对齐的可扩展工具集",
    "tags": [
      "LLM应用",
      "人工智能",
      "机器学习"
    ]
  },
  {
    "title": "V-FLUTE: Visual Figurative Language Understanding with Textual Explanations",
    "submit_datetime": "2024年05月02日",
    "abstract": "Large Vision-Language models (VLMs) have demonstrated strong reasoning capabilities in tasks requiring a fine-grained understanding of literal images and text, such as visual question-answering or visual entailment. However, there has been little exploration of these models' capabilities when presented with images and captions containing figurative phenomena such as metaphors or humor, the meaning of which is often implicit. To close this gap, we propose a new task and a high-quality dataset: Visual Figurative Language Understanding with Textual Explanations (V-FLUTE). We frame the visual figurative language understanding problem as an explainable visual entailment task, where the model has to predict whether the image (premise) entails a claim (hypothesis) and justify the predicted label with a textual explanation. Using a human-AI collaboration framework, we build a high-quality dataset, V-FLUTE, that contains 6,027 <image, claim, label, explanation> instances spanning five diverse multimodal figurative phenomena: metaphors, similes, idioms, sarcasm, and humor. The figurative phenomena can be present either in the image, the caption, or both. We further conduct both automatic and human evaluations to assess current VLMs' capabilities in understanding figurative phenomena.",
    "pdf_link": "https://arxiv.org/abs/2405.01474",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.01474v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01474/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01474v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01474/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01474v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01474/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01474v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01474/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01474v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01474/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01474v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01474/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01474v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01474/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01474v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01474/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01474v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01474/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01474v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01474/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01474v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01474/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01474v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01474/x12.png"
      }
    ],
    "abstract_cn": "大型视觉-语言模型（VLMs）在视觉问答和视觉推理等任务中表现出了卓越的推理能力，这些任务要求对图像和文本进行精细的理解。但是，当涉及到含有隐喻或幽默等比喻性内容的图像和标题时，这些模型的理解能力尚未得到充分探索，因为这些内容的含义往往是隐晦的。为了解决这一问题，我们设计了一项新任务并创建了一个高水准的数据集：视觉比喻语言理解与文本解释（V-FLUTE）。在这个任务中，模型需要判断一张图片（前提）是否能够推导出一个陈述（假设），并用文字来解释其预测结果。我们采用了人机协作的方式，构建了包含6,027个<图像，陈述，标签，解释>样本的V-FLUTE数据集，覆盖了五种不同的多模态比喻现象：隐喻、比喻、成语、讽刺和幽默。这些比喻现象可能出现在图片中、标题中，或者两者兼有。此外，我们还进行了自动化和人工评估，以检验当前VLMs在理解这些比喻现象方面的能力。",
    "title_cn": "V-FLUTE：图文结合，洞悉视觉比喻语言的深层含义",
    "tags": [
      "分类：LLM应用",
      "视觉问答",
      "人工智能"
    ]
  },
  {
    "title": "A Systematic Literature Review on Large Language Models for Automated Program Repair",
    "submit_datetime": "2024年05月02日",
    "abstract": "Automated Program Repair (APR) attempts to patch software bugs and reduce manual debugging efforts. Very recently, with the advances in Large Language Models (LLMs), an increasing number of APR techniques have been proposed, facilitating software development and maintenance and demonstrating remarkable performance. However, due to ongoing explorations in the LLM-based APR field, it is challenging for researchers to understand the current achievements, challenges, and potential opportunities. This work provides the first systematic literature review to summarize the applications of LLMs in APR between 2020 and 2024. We analyze 127 relevant papers from LLMs, APR and their integration perspectives. First, we categorize existing popular LLMs that are applied to support APR and outline three types of utilization strategies for their deployment. Besides, we detail some specific repair scenarios that benefit from LLMs, e.g., semantic bugs and security vulnerabilities. Furthermore, we discuss several critical aspects of integrating LLMs into APR research, e.g., input forms and open science. Finally, we highlight a set of challenges remaining to be investigated and the potential guidelines for future research. Overall, our paper provides a systematic overview of the research landscape to the APR community, helping researchers gain a comprehensive understanding of achievements and promote future research.",
    "pdf_link": "https://arxiv.org/abs/2405.01466",
    "graphs": [],
    "abstract_cn": "自动程序修复（APR）致力于修复软件缺陷，减轻人工调试负担。随着大型语言模型（LLMs）的飞速发展，众多新兴的APR技术应运而生，极大推动了软件产业的发展，并取得了显著成效。然而，在LLM驱动的APR研究领域，由于不断的新发现，研究者们面临着把握当前进展、挑战和机遇的难题。本文首次系统性地回顾了2020至2024年间LLMs在APR领域的应用，深入分析了127篇与LLMs、APR及其融合相关的文献。我们首先对目前应用于APR的主流LLMs进行分类，并归纳了三种常见的应用策略。文章还详细介绍了LLMs在特定修复场景中的应用实例，如语义缺陷和安全漏洞的修复。此外，我们探讨了将LLMs融入APR研究的几个关键议题，包括输入格式和开放科学研究。最后，我们指出了一些尚待解决的挑战，并为未来的研究方向提出了建议。总体上，本文为APR领域的研究者提供了一个全面的研究视角，帮助他们深入理解当前的研究成就，并激发未来研究的灵感。",
    "title_cn": "本文系统性地回顾了用于自动化程序修复的大型语言模型的相关文献。",
    "tags": [
      "LLM应用",
      "软件工程",
      "自动程序修复"
    ]
  },
  {
    "title": "UQA: Corpus for Urdu Question Answering",
    "submit_datetime": "2024年05月02日",
    "abstract": "This paper introduces UQA, a novel dataset for question answering and text comprehension in Urdu, a low-resource language with over 70 million native speakers. UQA is generated by translating the Stanford Question Answering Dataset (SQuAD2.0), a large-scale English QA dataset, using a technique called EATS (Enclose to Anchor, Translate, Seek), which preserves the answer spans in the translated context paragraphs. The paper describes the process of selecting and evaluating the best translation model among two candidates: Google Translator and Seamless M4T. The paper also benchmarks several state-of-the-art multilingual QA models on UQA, including mBERT, XLM-RoBERTa, and mT5, and reports promising results. For XLM-RoBERTa-XL, we have an F1 score of 85.99 and 74.56 EM. UQA is a valuable resource for developing and testing multilingual NLP systems for Urdu and for enhancing the cross-lingual transferability of existing models. Further, the paper demonstrates the effectiveness of EATS for creating high-quality datasets for other languages and domains. The UQA dataset and the code are publicly available at www.github.com/sameearif/UQA.",
    "pdf_link": "https://arxiv.org/abs/2405.01458",
    "graphs": [],
    "abstract_cn": "本研究提出了 UQA 数据集，这是首个针对乌尔都语——一种拥有逾七千万母语使用者的低资源语言——的问答和文本理解的新型数据集。UQA 通过采用 EATS 技术（即包围、锚定、翻译、寻找）翻译斯坦福的 SQuAD2.0 英文问答数据集而成，该技术巧妙地保留了翻译文本中的答案信息。文章详细阐述了在谷歌翻译和 Seamless M4T 两种翻译模型中筛选和评估最佳选项的过程。此外，本研究还对 UQA 数据集上的多个前沿多语言问答模型进行了基准测试，包括 mBERT、XLM-RoBERTa 和 mT5，取得了令人鼓舞的成绩。特别是在 XLM-RoBERTa-XL 模型上，我们分别获得了 85.99 的 F1 分数和 74.56 的精确匹配（EM）分数。UQA 不仅为开发和测试乌尔都语多语言自然语言处理系统提供了宝贵资源，也有助于提升现有模型的跨语言迁移能力。文章还证实了 EATS 技术在创建其他语言和领域高质量数据集方面的潜力。UQA 数据集及相应代码已在 www.github.com/sameearif/UQA 公开发布。",
    "title_cn": "UQA：乌尔都语问答语料库",
    "tags": [
      "LLM应用",
      "",
      "多语言处理"
    ]
  },
  {
    "title": "Creative Problem Solving in Large Language and Vision Models -- What Would it Take?",
    "submit_datetime": "2024年05月02日",
    "abstract": "In this paper, we discuss approaches for integrating Computational Creativity (CC) with research in large language and vision models (LLVMs) to address a key limitation of these models, i.e., creative problem solving. We present preliminary experiments showing how CC principles can be applied to address this limitation through augmented prompting. With this work, we hope to foster discussions of Computational Creativity in the context of ML algorithms for creative problem solving in LLVMs. Our code is at: https://github.com/lnairGT/creative-problem-solving-LLMs",
    "pdf_link": "https://arxiv.org/abs/2405.01453",
    "graphs": [],
    "abstract_cn": "本文探讨了将计算创造力（CC）融入大型语言和视觉模型（LLVMs）研究的方法，旨在突破这些模型在创造性问题解决方面的局限。我们通过一系列初步实验，展示了如何利用CC理念，通过增强式的提示来克服这一局限。我们期望借此工作激发对LLVMs中机器学习算法创造性问题解决背景下的计算创造力的深入讨论。相关代码可在以下链接获取：https://github.com/lnairGT/creative-problem-solving-LLMs",
    "title_cn": "探索大型语言与视觉模型中的创新性问题解决之道 -- 我们该如何应对这一挑战？",
    "tags": [
      "分类：LLM应用",
      "人工智能",
      "机器学习"
    ]
  },
  {
    "title": "Natural Language to Verilog: Design of a Recurrent Spiking Neural Network using Large Language Models and ChatGPT",
    "submit_datetime": "2024年05月02日",
    "abstract": "This paper investigates the use of Large Language Models (LLMs) for automating the generation of hardware description code, aiming to explore their potential in supporting and enhancing the development of efficient neuromorphic computing architectures. Building on our prior work, we employ OpenAI's ChatGPT4 and natural language prompts to synthesize a RTL Verilog module of a programmable recurrent spiking neural network, while also generating test benches to assess the system's correctness. The resultant design was validated in three case studies, the exclusive OR,the IRIS flower classification and the MNIST hand-written digit classification, achieving accuracies of up to 96.6%. To verify its synthesizability and implementability, the design was prototyped on a field-programmable gate array and implemented on SkyWater 130 nm technology by using an open-source electronic design automation flow. Additionally, we have submitted it to Tiny Tapeout 6 chip fabrication program to further evaluate the system on-chip performance in the future.",
    "pdf_link": "https://arxiv.org/abs/2405.01419",
    "graphs": [],
    "abstract_cn": "本研究探讨了利用大型语言模型（LLMs）自动化生成硬件描述语言代码的应用，旨在挖掘其在高效神经形态计算架构开发中的潜力。基于先前研究，我们利用OpenAI的ChatGPT4和自然语言指令，成功合成了一个可编程循环脉冲神经网络的寄存器传输级（RTL）Verilog模块，同时创建了测试平台以确保系统的正确性。该设计在三个案例研究中得到了验证：包括异或逻辑运算、鸢尾花分类和MNIST手写数字识别，准确率最高达96.6%。为了检验其合成和实现的可行性，该设计已在可编程门阵列上进行了原型化，并在SkyWater 130纳米技术平台上，采用开源的电子设计自动化流程实现了。此外，我们已将该设计提交至Tiny Tapeout 6芯片制造计划，以便未来进一步评估其在芯片上的性能表现。",
    "title_cn": "将自然语言转换为 Verilog 代码：我们利用大型语言模型和 ChatGPT，设计了一种递归脉冲神经网络。",
    "tags": [
      "LLM应用",
      "硬件设计",
      "神经形态计算"
    ]
  },
  {
    "title": "MiniGPT-3D: Efficiently Aligning 3D Point Clouds with Large Language Models using 2D Priors",
    "submit_datetime": "2024年05月02日",
    "abstract": "Large 2D vision-language models (2D-LLMs) have gained significant attention by bridging Large Language Models (LLMs) with images using a simple projector. Inspired by their success, large 3D point cloud-language models (3D-LLMs) also integrate point clouds into LLMs. However, directly aligning point clouds with LLM requires expensive training costs, typically in hundreds of GPU-hours on A100, which hinders the development of 3D-LLMs. In this paper, we introduce MiniGPT-3D, an efficient and powerful 3D-LLM that achieves multiple SOTA results while training for only 27 hours on one RTX 3090. Specifically, we propose to align 3D point clouds with LLMs using 2D priors from 2D-LLMs, which can leverage the similarity between 2D and 3D visual information. We introduce a novel four-stage training strategy for modality alignment in a cascaded way, and a mixture of query experts module to adaptively aggregate features with high efficiency. Moreover, we utilize parameter-efficient fine-tuning methods LoRA and Norm fine-tuning, resulting in only 47.8M learnable parameters, which is up to 260x fewer than existing methods. Extensive experiments show that MiniGPT-3D achieves SOTA on 3D object classification and captioning tasks, with significantly cheaper training costs. Notably, MiniGPT-3D gains an 8.12 increase on GPT-4 evaluation score for the challenging object captioning task compared to ShapeLLM-13B, while the latter costs 160 total GPU-hours on 8 A800. We are the first to explore the efficient 3D-LLM, offering new insights to the community. Code and weights are available at https://github.com/TangYuan96/MiniGPT-3D.",
    "pdf_link": "https://arxiv.org/abs/2405.01413",
    "graphs": [],
    "abstract_cn": "大型2D视觉-语言模型（2D-LLMs）通过巧妙的投影技术，成功地将图像与语言模型相结合，引起了广泛关注。继此之后，大型3D点云-语言模型（3D-LLMs）也致力于将点云数据融入语言模型之中。但是，要实现点云与语言模型的直接对齐，往往需要高昂的训练成本，这在A100上通常需要数百个GPU小时，极大地限制了3D-LLMs的发展。本文提出了MiniGPT-3D，这是一款既高效又强大的3D-LLM，仅需在单个RTX 3090上训练27小时，便能取得多项最新技术水平（SOTA）的成果。具体而言，我们创新性地利用2D-LLMs的2D先验知识来辅助3D点云与LLMs的对齐，充分发挥了2D与3D视觉信息的相似性优势。我们设计了一种新颖的四阶段级联训练策略，用于模态对齐，并引入了一个混合查询专家模块，以高效地适应性聚合特征。同时，我们还采用了参数高效的微调技术LoRA和Norm微调，仅用4700万个可学习参数，相比现有方法减少了高达260倍。广泛的实验结果证明，MiniGPT-3D在3D对象分类和字幕生成任务上均达到了最新技术水平，且训练成本显著降低。特别值得一提的是，MiniGPT-3D在GPT-4评估中的对象字幕生成任务上，比ShapeLLM-13B高出8.12分，而后者在8个A800上的训练成本高达160个GPU小时。我们首次探索了高效的3D-LLM，为该领域带来了新的洞见。相关代码和权重已在 https://github.com/TangYuan96/MiniGPT-3D 上发布。",
    "title_cn": "MiniGPT-3D：借助2D先验，高效实现3D点云与大型语言模型的精准对齐。",
    "tags": [
      "LLM应用",
      "计算机视觉",
      ""
    ]
  },
  {
    "title": "Verification and Refinement of Natural Language Explanations through LLM-Symbolic Theorem Proving",
    "submit_datetime": "2024年05月02日",
    "abstract": "Natural language explanations have become a proxy for evaluating explainable and multi-step Natural Language Inference (NLI) models. However, assessing the validity of explanations for NLI is challenging as it typically involves the crowd-sourcing of apposite datasets, a process that is time-consuming and prone to logical errors. To address existing limitations, this paper investigates the verification and refinement of natural language explanations through the integration of Large Language Models (LLMs) and Theorem Provers (TPs). Specifically, we present a neuro-symbolic framework, named Explanation-Refiner, that augments a TP with LLMs to generate and formalise explanatory sentences and suggest potential inference strategies for NLI. In turn, the TP is employed to provide formal guarantees on the logical validity of the explanations and to generate feedback for subsequent improvements. We demonstrate how Explanation-Refiner can be jointly used to evaluate explanatory reasoning, autoformalisation, and error correction mechanisms of state-of-the-art LLMs as well as to automatically enhance the quality of human-annotated explanations of variable complexity in different domains.",
    "pdf_link": "https://arxiv.org/abs/2405.01379",
    "graphs": [],
    "abstract_cn": "自然语言阐释已成为评价可解释性及多步自然语言推理（NLI）模型的标准。然而，验证 NLI 解释的合理性并非易事，这通常需要通过众包获取合适的数据集，既费时又易出错。为克服这些难题，本研究探讨了结合大型语言模型（LLMs）与定理证明器（TPs）来对自然语言阐释进行验证和细化的方法。我们提出了一个名为 Explanation-Refiner 的神经符号框架，该框架利用 LLMs 增强 TP，以生成形式化的解释性句子，并为 NLI 提供可能的推理策略。TP 用于确保解释的逻辑有效性，并为后续改进提供反馈。我们证明了 Explanation-Refiner 如何被用于评估顶尖 LLMs 的解释推理能力、自动形式化以及错误修正机制，并自动提升不同领域中复杂程度不一的人工注释解释的质量。",
    "title_cn": "利用大型语言模型（LLM）中的符号定理证明技术，对自然语言解释进行验证与优化。",
    "tags": [
      "LLM应用",
      "",
      "逻辑推理"
    ]
  },
  {
    "title": "GAIA: A General AI Assistant for Intelligent Accelerator Operations",
    "submit_datetime": "2024年05月02日",
    "abstract": "Large-scale machines like particle accelerators are usually run by a team of experienced operators. In case of a particle accelerator, these operators possess suitable background knowledge on both accelerator physics and the technology comprising the machine. Due to the complexity of the machine, particular subsystems of the machine are taken care of by experts, who the operators can turn to. In this work the reasoning and action (ReAct) prompting paradigm is used to couple an open-weights large language model (LLM) with a high-level machine control system framework and other tools, e.g. the electronic logbook or machine design documentation. By doing so, a multi-expert retrieval augmented generation (RAG) system is implemented, which assists operators in knowledge retrieval tasks, interacts with the machine directly if needed, or writes high level control system scripts. This consolidation of expert knowledge and machine interaction can simplify and speed up machine operation tasks for both new and experienced human operators.",
    "pdf_link": "https://arxiv.org/abs/2405.01359",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.01359v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01359/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01359v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01359/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01359v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01359/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01359v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01359/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01359v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01359/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01359v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01359/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01359v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01359/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01359v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01359/x9.png"
      }
    ],
    "abstract_cn": "大型设施如粒子加速器，往往由资深操作团队掌控。这些操作员不仅精通加速器的物理原理，还对构成该设备的技术支持了如指掌。面对设备复杂性，各子系统均由领域专家维护，以便操作员随时咨询。本研究采用推理与行动（ReAct）提示法，将开放式大型语言模型（LLM）与高级机器控制系统框架及其他辅助工具（如电子日志簿或机器设计文档）相融合。这一整合实现了一个多专家检索增强生成（RAG）系统，它不仅辅助操作员执行知识检索任务，必要时还能直接与机器交互，甚至编写高级控制系统脚本。这种将专家智慧与机器互动相结合的方式，极大简化了机器操作流程，无论是对新手还是资深操作员，都显著提升了工作效率。",
    "title_cn": "GAIA：一款为智能化加速器运营提供助力的全能AI助手。",
    "tags": [
      "RAG",
      "粒子加速器操作",
      "自动化控制系统"
    ]
  },
  {
    "title": "Human-Robot Interaction Conversational User Enjoyment Scale (HRI CUES)",
    "submit_datetime": "2024年05月02日",
    "abstract": "Understanding user enjoyment is crucial in human-robot interaction (HRI), as it can impact interaction quality and influence user acceptance and long-term engagement with robots, particularly in the context of conversations with social robots. However, current assessment methods rely solely on self-reported questionnaires, failing to capture interaction dynamics. This work introduces the Human-Robot Interaction Conversational User Enjoyment Scale (HRI CUES), a novel scale for assessing user enjoyment from an external perspective during conversations with a robot. Developed through rigorous evaluations and discussions of three annotators with relevant expertise, the scale provides a structured framework for assessing enjoyment in each conversation exchange (turn) alongside overall interaction levels. It aims to complement self-reported enjoyment from users and holds the potential for autonomously identifying user enjoyment in real-time HRI. The scale was validated on 25 older adults' open-domain dialogue with a companion robot that was powered by a large language model for conversations, corresponding to 174 minutes of data, showing moderate to good alignment. Additionally, the study offers insights into understanding the nuances and challenges of assessing user enjoyment in robot interactions, and provides guidelines on applying the scale to other domains.",
    "pdf_link": "https://arxiv.org/abs/2405.01354",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.01354v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01354/HRI-CUES.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01354v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01354/elan_anony.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01354v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01354/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01354v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01354/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01354v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01354/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01354v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01354/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01354v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01354/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01354v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01354/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01354v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01354/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01354v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01354/x9.png"
      }
    ],
    "abstract_cn": "在人机互动（HRI）领域，洞察用户的乐趣至关重要，这直接关系到互动的品质、用户的接受程度以及对机器人的长期投入，特别是在与社交机器人的交流中。然而，现有的评估手段主要依赖于问卷自评，这并不足以全面捕捉互动的动态变化。本项工作提出了一种创新的评估工具——人机交互对话用户乐趣量表（HRI CUES），它能够从第三方视角在机器人对话过程中评估用户的乐趣。这个量表是经过三位专家严谨评估和深入讨论后开发的，为每一次对话交流和整体互动提供了一个系统的评估框架。它不仅旨在补充用户的自我评估，还有望实现在实时HRI中自动检测用户的乐趣。通过25位老年参与者与伴侣机器人的开放式对话进行了量表的验证，这些对话由一个大型语言模型支持，共计174分钟的数据显示出量表与实际感受的中等到良好一致性。研究还深入探讨了在机器人互动中评估用户乐趣的复杂性和挑战，并为如何将这一量表应用于其他领域提供了指导性建议。",
    "title_cn": "人机互动对话用户愉悦度量表（HRI CUES）",
    "tags": [
      "Agent",
      "人机交互",
      "社交机器人"
    ]
  },
  {
    "title": "The Power of Question Translation Training in Multilingual Reasoning: Broadened Scope and Deepened Insights",
    "submit_datetime": "2024年05月02日",
    "abstract": "Bridging the significant gap between large language model's English and non-English performance presents a great challenge. While some previous studies attempt to mitigate this gap with translated training data, the recently proposed question alignment approach leverages the model's English expertise to improve multilingual performance with minimum usage of expensive, error-prone translation. In this paper, we explore how broadly this method can be applied by examining its effects in reasoning with executable code and reasoning with common sense. We also explore how to apply this approach efficiently to extremely large language models using proxy-tuning. Experiment results on multilingual reasoning benchmarks mGSM, mSVAMP and xCSQA demonstrate that the question alignment approach can be used to boost multilingual performance across diverse reasoning scenarios, model families, and sizes. For instance, when applied to the LLaMA2 models, our method brings an average accuracy improvements of 12.2% on mGSM even with the 70B model. To understand the mechanism of its success, we analyze representation space, chain-of-thought and translation data scales, which reveals how question translation training strengthens language alignment within LLMs and shapes their working patterns.",
    "pdf_link": "https://arxiv.org/abs/2405.01345",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.01345v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01345/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01345v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01345/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01345v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01345/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01345v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01345/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01345v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01345/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01345v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01345/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01345v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01345/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01345v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01345/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01345v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01345/x9.png"
      }
    ],
    "abstract_cn": "缩小大型语言模型在英语与其他语言性能上的巨大差距是一项艰巨任务。尽管早期研究尝试通过翻译训练数据来缩小这一差距，但新近提出的问题对齐方法通过利用模型的英语专长，以最小的成本和错误风险提升多语言性能。本文深入探讨了该方法的广泛应用潜力，通过分析其在执行代码推理和常识推理方面的效果。我们还研究了如何通过代理调优技术高效地将此方法应用于超大型语言模型。在多语言推理基准测试 mGSM、mSVAMP 和 xCSQA 上的实验结果显示，问题对齐方法能够显著提升不同推理场景、模型系列和规模下的多语言性能。例如，在 LLaMA2 模型上应用该方法，即便是在 70B 模型规模下，也能在 mGSM 上实现平均准确度提升 12.2%。为了深入理解其成功的背后机制，我们对表示空间、思维链和翻译数据规模进行了分析，揭示了问题翻译训练如何加强大型语言模型内的语言一致性，并塑造了它们的工作模式。",
    "title_cn": "通过问题翻译训练提升多语言推理能力：拓展研究视野，深化理解深度。",
    "tags": [
      "LLM应用",
      "",
      "机器翻译"
    ]
  },
  {
    "title": "Overcoming LLM Challenges using RAG-Driven Precision in Coffee Leaf Disease Remediation",
    "submit_datetime": "2024年05月02日",
    "abstract": "This research introduces an innovative AI-driven precision agriculture system, leveraging YOLOv8 for disease identification and Retrieval Augmented Generation (RAG) for context-aware diagnosis. Focused on addressing the challenges of diseases affecting the coffee production sector in Karnataka, The system integrates sophisticated object detection techniques with language models to address the inherent constraints associated with Large Language Models (LLMs). Our methodology not only tackles the issue of hallucinations in LLMs, but also introduces dynamic disease identification and remediation strategies. Real-time monitoring, collaborative dataset expansion, and organizational involvement ensure the system's adaptability in diverse agricultural settings. The effect of the suggested system extends beyond automation, aiming to secure food supplies, protect livelihoods, and promote eco-friendly farming practices. By facilitating precise disease identification, the system contributes to sustainable and environmentally conscious agriculture, reducing reliance on pesticides. Looking to the future, the project envisions continuous development in RAG-integrated object detection systems, emphasizing scalability, reliability, and usability. This research strives to be a beacon for positive change in agriculture, aligning with global efforts toward sustainable and technologically enhanced food production.",
    "pdf_link": "https://arxiv.org/abs/2405.01310",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.01310v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01310/460.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.01310v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01310/34.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.01310v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01310/methodology1.png"
      }
    ],
    "abstract_cn": "本研究推出了一款创新的 AI 精准农业系统，采用 YOLOv8 技术进行病虫害识别，结合 RAG 技术实现智能诊断。该系统旨在应对卡纳塔克邦咖啡产业面临的病虫害挑战，通过融合先进的目标检测与语言模型技术，克服了大型语言模型（LLMs）的内在限制。我们的研究方法不仅解决了 LLMs 的幻觉问题，还提出了动态的病虫害识别与治理策略。系统通过实时监测、协作数据集扩充和组织参与，确保了在多样化农业场景中的适应性。该系统的影响不仅限于自动化水平的提升，更致力于保障食品供给、维护生计、推广环保农业。它通过精确识别病虫害，助力农业的可持续发展，减少对农药的依赖。展望未来，我们计划持续优化 RAG 集成的目标检测系统，注重系统的扩展性、可靠性与用户友好性。本研究力图为农业领域的积极变革提供指引，与全球推动可持续和科技提升型食品生产的大趋势相呼应。",
    "title_cn": "利用 RAG（Retrieval-Augmented Generation）技术提高精确度，有效应对大型语言模型在咖啡叶病害治理中的难题。",
    "tags": [
      "分类：RAG",
      "精准农业",
      "病虫害识别"
    ]
  },
  {
    "title": "The Effectiveness of LLMs as Annotators: A Comparative Overview and Empirical Analysis of Direct Representation",
    "submit_datetime": "2024年05月02日",
    "abstract": "Large Language Models (LLMs) have emerged as powerful support tools across various natural language tasks and a range of application domains. Recent studies focus on exploring their capabilities for data annotation. This paper provides a comparative overview of twelve studies investigating the potential of LLMs in labelling data. While the models demonstrate promising cost and time-saving benefits, there exist considerable limitations, such as representativeness, bias, sensitivity to prompt variations and English language preference. Leveraging insights from these studies, our empirical analysis further examines the alignment between human and GPT-generated opinion distributions across four subjective datasets. In contrast to the studies examining representation, our methodology directly obtains the opinion distribution from GPT. Our analysis thereby supports the minority of studies that are considering diverse perspectives when evaluating data annotation tasks and highlights the need for further research in this direction.",
    "pdf_link": "https://arxiv.org/abs/2405.01299",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.01299v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01299/armis_opinion_distributions.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01299v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01299/md_agree_opinion_distributions.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01299v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01299/hs_brexit_opinion_distributions.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01299v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01299/conv_abuse_opinion_distributions.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01299v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01299/ALL_entropy.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）在多种自然语言处理任务和应用领域中展现出强大的辅助作用。近期研究着重探讨了它们在数据标注上的应用潜力。本文综述了十二项研究，深入探讨了LLMs在数据标注方面的潜力。尽管这些模型在节省成本和时间上显示出了潜力，但它们也存在一些显著的限制，包括代表性问题、偏见、对提示变化的敏感性以及对英语的偏好。基于这些研究的洞察，我们进行了实证分析，比较了人类与GPT生成的意见分布，在四个主观数据集上的一致性。与以往关注代表性的研究不同，我们的方法直接从GPT中获取意见分布。我们的分析支持了那些在评估数据标注任务时考虑多元视角的研究，并强调了这一方向上进一步研究的必要性。",
    "title_cn": "探究大型语言模型作为注释工具的效能：一篇关于直接表征方法的对比概览与实证研究分析",
    "tags": [
      "LLM应用",
      "",
      "数据标注"
    ]
  },
  {
    "title": "Reinforcement Learning for Edit-Based Non-Autoregressive Neural Machine Translation",
    "submit_datetime": "2024年05月02日",
    "abstract": "Non-autoregressive (NAR) language models are known for their low latency in neural machine translation (NMT). However, a performance gap exists between NAR and autoregressive models due to the large decoding space and difficulty in capturing dependency between target words accurately. Compounding this, preparing appropriate training data for NAR models is a non-trivial task, often exacerbating exposure bias. To address these challenges, we apply reinforcement learning (RL) to Levenshtein Transformer, a representative edit-based NAR model, demonstrating that RL with self-generated data can enhance the performance of edit-based NAR models. We explore two RL approaches: stepwise reward maximization and episodic reward maximization. We discuss the respective pros and cons of these two approaches and empirically verify them. Moreover, we experimentally investigate the impact of temperature setting on performance, confirming the importance of proper temperature setting for NAR models' training.",
    "pdf_link": "https://arxiv.org/abs/2405.01280",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.01280v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01280/levt_en.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01280v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01280/method-v2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01280v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01280/stepwise.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01280v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01280/episodic.png"
      }
    ],
    "abstract_cn": "非自回归（NAR）语言模型在神经机器翻译（NMT）领域以其低延迟特性著称。但与自回归模型相比，NAR模型在性能上仍有差距，这主要是因为解码空间庞大，且捕捉目标词汇间依赖关系存在难度。此外，为NAR模型准备合适的训练数据并非易事，往往会加剧模型的暴露偏差问题。为了解决这些难题，我们对一个典型的基于编辑的NAR模型——Levenshtein Transformer——应用了强化学习（RL），发现通过RL结合自生成数据可以有效提升模型性能。我们对比了两种RL策略：逐步奖励最大化与情景奖励最大化，分析了它们的优劣，并进行了实证检验。同时，我们还探讨了温度参数设置对模型性能的影响，强调了适当温度设置在NAR模型训练中的关键作用。",
    "title_cn": "强化学习在基于编辑的非自回归神经机器翻译中的应用",
    "tags": [
      "分类：LLM应用\n\n这篇论文主要研究了非自回归（NAR）语言模型在神经机器翻译（NMT）领域的应用，通过应用强化学习（RL）来提升模型性能。这属于LLM应用的范畴，因为它涉及到了如何改进和应用现有的大型语言模型（LLM）来解决特定的问题。",
      "机器翻译",
      ""
    ]
  },
  {
    "title": "Prompt engineering paradigms for medical applications: scoping review and recommendations for better practices",
    "submit_datetime": "2024年05月02日",
    "abstract": "Prompt engineering is crucial for harnessing the potential of large language models (LLMs), especially in the medical domain where specialized terminology and phrasing is used. However, the efficacy of prompt engineering in the medical domain remains to be explored. In this work, 114 recent studies (2022-2024) applying prompt engineering in medicine, covering prompt learning (PL), prompt tuning (PT), and prompt design (PD) are reviewed. PD is the most prevalent (78 articles). In 12 papers, PD, PL, and PT terms were used interchangeably. ChatGPT is the most commonly used LLM, with seven papers using it for processing sensitive clinical data. Chain-of-Thought emerges as the most common prompt engineering technique. While PL and PT articles typically provide a baseline for evaluating prompt-based approaches, 64% of PD studies lack non-prompt-related baselines. We provide tables and figures summarizing existing work, and reporting recommendations to guide future research contributions.",
    "pdf_link": "https://arxiv.org/abs/2405.01249",
    "graphs": [],
    "abstract_cn": "在医疗领域，精心设计的提示对于解锁大型语言模型（LLMs）的潜能至关重要，尤其是在专业术语和表达方式频繁出现的情况下。尽管如此，提示工程在医疗领域的实际效果尚需进一步研究。本研究回顾了114篇最新文献（2022-2024年），这些文献探讨了在医学领域应用提示工程的案例，包括提示学习（PL）、提示调整（PT）和提示设计（PD）。其中，提示设计（PD）最为常见，共有78篇文章进行了讨论。在12篇论文中，PD、PL和PT这几个术语被混用。ChatGPT作为最广泛使用的LLM，有七篇论文中它被用来处理敏感的临床信息。思维链（Chain-of-Thought）成为最流行的提示工程技术。尽管PL和PT相关文章通常为评估基于提示的方法提供了基准，但有64%的PD研究缺少与提示无关的基准对比。我们提供了汇总现有研究成果的表格和图表，并提出了推进未来研究的建议。",
    "title_cn": "医疗领域提示工程的范式：全面审视与提升实践的建言",
    "tags": [
      "分类：LLM应用\n\n这篇论文的摘要主要讨论了在医疗领域应用大型语言模型（LLMs）时，提示工程的重要性和实际效果。它回顾了相关文献，分析了提示学习（PL）、提示调整（PT）和提示设计（PD）在医学领域的应用情况，并提出了未来研究的建议。这些内容都与LLMs在特定领域的应用实践相关，因此将其归类为\"LLM应用\"。",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Boosting Jailbreak Attack with Momentum",
    "submit_datetime": "2024年05月02日",
    "abstract": "Large Language Models (LLMs) have achieved remarkable success across diverse tasks, yet they remain vulnerable to adversarial attacks, notably the well-documented \\textit{jailbreak} attack. Recently, the Greedy Coordinate Gradient (GCG) attack has demonstrated efficacy in exploiting this vulnerability by optimizing adversarial prompts through a combination of gradient heuristics and greedy search. However, the efficiency of this attack has become a bottleneck in the attacking process. To mitigate this limitation, in this paper we rethink the generation of adversarial prompts through an optimization lens, aiming to stabilize the optimization process and harness more heuristic insights from previous iterations. Specifically, we introduce the \\textbf{M}omentum \\textbf{A}ccelerated G\\textbf{C}G (\\textbf{MAC}) attack, which incorporates a momentum term into the gradient heuristic. Experimental results showcase the notable enhancement achieved by MAP in gradient-based attacks on aligned language models. Our code is available at https://github.com/weizeming/momentum-attack-llm.",
    "pdf_link": "https://arxiv.org/abs/2405.01229",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）在众多任务上取得了令人瞩目的成就，但它们对对抗性攻击的脆弱性依旧，尤其是广为人知的“越狱”攻击。最近，贪婪坐标梯度（GCG）攻击通过梯度启发式和贪婪搜索的结合，有效利用了这一弱点。然而，该攻击的效率问题成为了攻击流程中的一个瓶颈。为了克服这一局限，本文提出了一种新的思考方式，通过优化方法生成对抗性提示，以稳定优化过程并从前几次迭代中获得更多启发。具体而言，我们提出了**动量加速 G** rady **C** oordinate **G** radient（**M** AC）攻击，它在梯度启发式中加入了动量因子。实验结果显示，MAC 在对齐语言模型的梯度攻击中实现了显著的性能提升。相关代码已在 https://github.com/weizeming/momentum-attack-llm 上发布。",
    "title_cn": "借助动量效应，提升越狱攻击的威力",
    "tags": [
      "分类：LLM应用",
      "网络安全",
      "机器学习"
    ]
  },
  {
    "title": "DLAP: A Deep Learning Augmented Large Language Model Prompting Framework for Software Vulnerability Detection",
    "submit_datetime": "2024年05月02日",
    "abstract": "Software vulnerability detection is generally supported by automated static analysis tools, which have recently been reinforced by deep learning (DL) models. However, despite the superior performance of DL-based approaches over rule-based ones in research, applying DL approaches to software vulnerability detection in practice remains a challenge due to the complex structure of source code, the black-box nature of DL, and the domain knowledge required to understand and validate the black-box results for addressing tasks after detection. Conventional DL models are trained by specific projects and, hence, excel in identifying vulnerabilities in these projects but not in others. These models with poor performance in vulnerability detection would impact the downstream tasks such as location and repair. More importantly, these models do not provide explanations for developers to comprehend detection results. In contrast, Large Language Models (LLMs) have made lots of progress in addressing these issues by leveraging prompting techniques. Unfortunately, their performance in identifying vulnerabilities is unsatisfactory. This paper contributes \\textbf{\\DLAP}, a \\underline{\\textbf{D}}eep \\underline{\\textbf{L}}earning \\underline{\\textbf{A}}ugmented LLMs \\underline{\\textbf{P}}rompting framework that combines the best of both DL models and LLMs to achieve exceptional vulnerability detection performance. Experimental evaluation results confirm that \\DLAP outperforms state-of-the-art prompting frameworks, including role-based prompts, auxiliary information prompts, chain-of-thought prompts, and in-context learning prompts, as well as fine-turning on multiple metrics.",
    "pdf_link": "https://arxiv.org/abs/2405.01202",
    "graphs": [],
    "abstract_cn": "软件漏洞检测多依赖于自动化静态分析工具，这些工具借助深度学习（DL）模型得到了显著提升。尽管DL在学术研究中展现出比传统规则基础方法更优异的性能，但实际应用中，由于源代码结构复杂、DL模型的不可解释性，以及解读DL模型“黑箱”结果所需的专业知识，使得DL在软件漏洞检测上的应用充满挑战。传统DL模型通常针对特定项目训练，导致其在其他项目中的漏洞检测能力不足，进而影响定位和修复等后续工作。此外，这些模型未能为开发者提供足够的解释来理解检测结果。与此相对，大型语言模型（LLMs）通过提示技术在这些问题上取得了显著进步，但在漏洞识别方面仍有提升空间。本文提出了\\textbf{\\DLAP}框架，一个结合了DL模型和LLMs优势的深度学习增强型LLMs提示框架，旨在实现卓越的漏洞检测效果。实验评估显示，\\DLAP在多个指标上超越了现有最先进的提示框架，包括角色提示、辅助信息提示、思维链提示和上下文学习提示，以及在多维度上的微调优化。",
    "title_cn": "DLAP：深度学习助力的大型语言模型提示框架，专为软件漏洞检测而设计。",
    "tags": [
      "LLM应用",
      "软件工程",
      "漏洞检测"
    ]
  },
  {
    "title": "Generative Relevance Feedback and Convergence of Adaptive Re-Ranking: University of Glasgow Terrier Team at TREC DL 2023",
    "submit_datetime": "2024年05月02日",
    "abstract": "This paper describes our participation in the TREC 2023 Deep Learning Track. We submitted runs that apply generative relevance feedback from a large language model in both a zero-shot and pseudo-relevance feedback setting over two sparse retrieval approaches, namely BM25 and SPLADE. We couple this first stage with adaptive re-ranking over a BM25 corpus graph scored using a monoELECTRA cross-encoder. We investigate the efficacy of these generative approaches for different query types in first-stage retrieval. In re-ranking, we investigate operating points of adaptive re-ranking with different first stages to find the point in graph traversal where the first stage no longer has an effect on the performance of the overall retrieval pipeline. We find some performance gains from the application of generative query reformulation. However, our strongest run in terms of P@10 and nDCG@10 applied both adaptive re-ranking and generative pseudo-relevance feedback, namely uogtr_b_grf_e_gb.",
    "pdf_link": "https://arxiv.org/abs/2405.01122",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.01122v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01122/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01122v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01122/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01122v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01122/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01122v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01122/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01122v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01122/x5.png"
      }
    ],
    "abstract_cn": "本文记录了我们在2023年TREC深度学习赛道的参与经历。我们提交的方案采用了大型语言模型提供的生成式相关性反馈，涉及零样本和伪相关性两种反馈模式，应用于BM25和SPlade两种稀疏检索技术。接着，我们通过BM25语料库图的自适应重新排序，利用monoELECTRA交叉编码器进行评分，以增强检索效果。我们探究了这些生成式方法在初步检索阶段对不同查询类型的有效性，并在重新排序阶段寻找自适应重新排序的最佳操作点，以确定第一阶段对整体检索流程性能的影响界限。尽管生成式查询重构带来了一定的性能提升，但我们在P@10和nDCG@10指标上表现最佳的方案是结合了自适应重新排序和生成式伪相关性反馈的uogtr_b_grf_e_gb。",
    "title_cn": "格拉斯哥大学的特里尔团队在2023年TREC DL竞赛中展示了他们在生成式相关反馈和自适应重排序技术方面的成果，这些技术在信息检索任务中实现了显著的收敛效果。",
    "tags": [
      "LLM应用",
      "信息检索",
      ""
    ]
  },
  {
    "title": "Efficient Data Generation for Source-grounded Information-seeking Dialogs: A Use Case for Meeting Transcripts",
    "submit_datetime": "2024年05月02日",
    "abstract": "Existing methods for creating source-grounded information-seeking dialog datasets are often costly and hard to implement due to their sole reliance on human annotators. We propose combining large language models (LLMs) prompting with human expertise for more efficient and reliable data generation. Instead of the labor-intensive Wizard-of-Oz (WOZ) method, where two annotators generate a dialog from scratch, role-playing agent and user, we use LLM generation to simulate the two roles. Annotators then verify the output and augment it with attribution data. We demonstrate our method by constructing MISeD -- Meeting Information Seeking Dialogs dataset -- the first information-seeking dialog dataset focused on meeting transcripts. Models finetuned with MISeD demonstrate superior performance on our test set, as well as on a novel fully-manual WOZ test set and an existing query-based summarization benchmark, suggesting the utility of our approach.",
    "pdf_link": "https://arxiv.org/abs/2405.01121",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.01121v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01121/fig-dialog-generation.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01121v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01121/fig-task-description.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01121v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01121/fig-transcript-and-attribution-plots.png"
      }
    ],
    "abstract_cn": "传统方法在构建基于源头的信息搜寻对话数据集时，因完全依赖人工标注而成本高昂且实施困难。我们提出一种新方法，结合大型语言模型（LLMs）的提示和人类专家知识，以提高数据生成的效率和可靠性。与传统的“幕后巫师”（WOZ）方法相比，该方法不再需要两名标注者从头开始构建对话，扮演代理和用户角色，而是利用LLM生成技术来模拟这两个角色。标注者随后对生成的内容进行验证，并添加归因数据。我们通过创建MISeD——首个专注于会议记录的信息搜寻对话数据集——来验证这种方法。使用MISeD数据集进行微调的模型不仅在我们的测试集中表现出色，也在全新的全手动WOZ测试集和现有的基于查询的摘要基准测试中展现了优越性能，这证明了我们方法的有效性。",
    "title_cn": "高效数据生成：以会议记录为信息寻求型源-地面对话的用例",
    "tags": [
      "LLM应用",
      "对话系统",
      ""
    ]
  },
  {
    "title": "\"In-Context Learning\" or: How I learned to stop worrying and love \"Applied Information Retrieval\"",
    "submit_datetime": "2024年05月02日",
    "abstract": "With the increasing ability of large language models (LLMs), in-context learning (ICL) has evolved as a new paradigm for natural language processing (NLP), where instead of fine-tuning the parameters of an LLM specific to a downstream task with labeled examples, a small number of such examples is appended to a prompt instruction for controlling the decoder's generation process. ICL, thus, is conceptually similar to a non-parametric approach, such as $k$-NN, where the prediction for each instance essentially depends on the local topology, i.e., on a localised set of similar instances and their labels (called few-shot examples). This suggests that a test instance in ICL is analogous to a query in IR, and similar examples in ICL retrieved from a training set relate to a set of documents retrieved from a collection in IR. While standard unsupervised ranking models can be used to retrieve these few-shot examples from a training set, the effectiveness of the examples can potentially be improved by re-defining the notion of relevance specific to its utility for the downstream task, i.e., considering an example to be relevant if including it in the prompt instruction leads to a correct prediction. With this task-specific notion of relevance, it is possible to train a supervised ranking model (e.g., a bi-encoder or cross-encoder), which potentially learns to optimally select the few-shot examples. We believe that the recent advances in neural rankers can potentially find a use case for this task of optimally choosing examples for more effective downstream ICL predictions.",
    "pdf_link": "https://arxiv.org/abs/2405.01116",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.01116v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01116/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01116v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01116/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01116v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01116/x3.png"
      }
    ],
    "abstract_cn": "随着大型语言模型（LLMs）能力的提升，上下文学习（ICL）已成为自然语言处理（NLP）的新趋势。与传统的微调方法不同，ICL通过将少量标注示例添加到提示指令中，来引导模型的解码生成过程，而不是对模型参数进行特定任务的微调。这种方法在理念上与非参数方法如$k$-NN相似，预测结果依赖于局部拓扑结构，即一组相似的实例及其标签（称为少量示例）。在ICL中，测试实例与信息检索（IR）中的查询相似，而从训练集中检索的类似示例则相当于从IR集合中检索的文档集。虽然可以使用标准的无监督排名模型来检索这些少量示例，但通过针对下游任务重新定义相关性的概念，可以提升示例的有效性。换句话说，如果将一个示例包含在提示指令中能够导致正确预测，那么这个示例就被认为是相关的。基于这种任务特定的相关性概念，可以训练一个有监督的排名模型，如双编码器或交叉编码器，以学习如何最优地选择少量示例。我们认为，神经排名器的最新进展可能为选择最佳示例以提高ICL预测效果提供了新的应用场景。",
    "title_cn": "《上下文学习》：我如何学会不再担忧并拥抱“应用信息检索”的世界",
    "tags": [
      "LLM应用",
      "",
      "信息检索"
    ]
  },
  {
    "title": "LLM Security Guard for Code",
    "submit_datetime": "2024年05月02日",
    "abstract": "Many developers rely on Large Language Models (LLMs) to facilitate software development. Nevertheless, these models have exhibited limited capabilities in the security domain. We introduce LLMSecGuard, an open-source framework that offers enhanced code security through the synergy between static code analyzers and LLMs. LLMSecGuard aims to equip practitioners with code solutions that are more secure than the code initially generated by LLMs. It also benchmarks LLMs, providing valuable insights into the evolving security properties of these models.",
    "pdf_link": "https://arxiv.org/abs/2405.01103",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.01103v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01103/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01103v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01103/x2.png"
      }
    ],
    "abstract_cn": "众多开发者借助大型语言模型（LLMs）推进软件开发。尽管如此，这些模型在安全领域的应用能力尚显不足。我们推出了LLMSecGuard，一个开源的框架，它通过结合静态代码分析工具与LLMs的力量，增强了代码的安全性。LLMSecGuard的目的是为开发者提供比LLMs原始生成的代码更为安全的解决方案。此外，它还对LLMs进行性能评估，以洞察这些模型安全特性的演进趋势。",
    "title_cn": "大型语言模型的安全守护者：代码防护",
    "tags": [
      "LLM应用",
      "软件开发",
      ""
    ]
  },
  {
    "title": "Learning Object States from Actions via Large Language Models",
    "submit_datetime": "2024年05月02日",
    "abstract": "Temporally localizing the presence of object states in videos is crucial in understanding human activities beyond actions and objects. This task has suffered from a lack of training data due to object states' inherent ambiguity and variety. To avoid exhaustive annotation, learning from transcribed narrations in instructional videos would be intriguing. However, object states are less described in narrations compared to actions, making them less effective. In this work, we propose to extract the object state information from action information included in narrations, using large language models (LLMs). Our observation is that LLMs include world knowledge on the relationship between actions and their resulting object states, and can infer the presence of object states from past action sequences. The proposed LLM-based framework offers flexibility to generate plausible pseudo-object state labels against arbitrary categories. We evaluate our method with our newly collected Multiple Object States Transition (MOST) dataset including dense temporal annotation of 60 object state categories. Our model trained by the generated pseudo-labels demonstrates significant improvement of over 29% in mAP against strong zero-shot vision-language models, showing the effectiveness of explicitly extracting object state information from actions through LLMs.",
    "pdf_link": "https://arxiv.org/abs/2405.01090",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.01090v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01090/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01090v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01090/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01090v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01090/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01090v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01090/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01090v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01090/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01090v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01090/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01090v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01090/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01090v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01090/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01090v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01090/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01090v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01090/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01090v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01090/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01090v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01090/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01090v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01090/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01090v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01090/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01090v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01090/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01090v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01090/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01090v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01090/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01090v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01090/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01090v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01090/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01090v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01090/x20.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01090v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01090/x21.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01090v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01090/x22.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01090v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01090/x23.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01090v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01090/x24.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01090v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01090/x25.png"
      }
    ],
    "abstract_cn": "在视频分析中，准确识别对象状态的时间位置对于深入理解人类行为极为关键。然而，由于对象状态的复杂多变，相关训练数据的匮乏一直是研究的瓶颈。传统的详尽标注方法耗时且效率低下，因此，我们探索了一种新颖的方法：从教学视频的旁白中学习。尽管如此，与动作描述相比，对象状态在旁白中的描述较为简略，导致信息捕捉不足。本研究提出了一种创新框架，利用大型语言模型（LLMs）从旁白中的动作描述推断出对象状态信息。我们发现，LLMs能够利用其内置的世界知识，理解动作与随后对象状态之间的联系，并从动作序列中预测对象状态。此外，该框架的灵活性允许它为任意类别生成看似合理的伪对象状态标签。为了验证我们的方法，我们创建了一个新的数据集——多对象状态转换（MOST），它包含了60个对象状态类别的密集时间标注。在该数据集上，我们训练的模型使用生成的伪标签，与现有的强大零样本视觉-语言模型相比，在平均精度（mAP）上实现了超过29%的显著提升，从而证明了我们通过LLMs从动作中提取对象状态信息方法的有效性。",
    "title_cn": "利用大型语言模型从动作中学习对象状态。",
    "tags": [
      "LLM应用",
      "视频分析",
      "人工智能"
    ]
  },
  {
    "title": "Generating User Experience Based on Personas with AI Assistants",
    "submit_datetime": "2024年05月02日",
    "abstract": "Traditional UX development methodologies focus on developing ``one size fits all\" solutions and lack the flexibility to cater to diverse user needs. In response, a growing interest has arisen in developing more dynamic UX frameworks. However, existing approaches often cannot personalise user experiences and adapt to user feedback in real-time. Therefore, my research introduces a novel approach of combining Large Language Models and personas, to address these limitations. The research is structured around three areas: (1) a critical review of existing adaptive UX practices and the potential for their automation; (2) an investigation into the role and effectiveness of personas in enhancing UX adaptability; and (3) the proposal of a theoretical framework that leverages LLM capabilities to create more dynamic and responsive UX designs and guidelines.",
    "pdf_link": "https://arxiv.org/abs/2405.01051",
    "graphs": [],
    "abstract_cn": "传统UX开发方法倾向于提供通用解决方案，忽略了用户需求的多样性。为了解决这一问题，越来越多的研究者开始探索更具灵活性的UX设计框架。但目前的方法往往难以实现用户体验的个性化或实时响应用户反馈。本研究提出了一种创新的方法，将大型语言模型与角色原型相结合，以克服这些挑战。研究主要分为三个部分：首先，对现有自适应UX实践进行深入分析，并探讨其自动化的可能性；其次，研究角色原型在提升UX适应性方面的作用与效果；最后，提出一个理论框架，该框架利用大型语言模型的潜力，以打造更加动态和响应用户需求的UX设计和指导原则。",
    "title_cn": "利用人工智能助手，根据人物角色创造用户体验",
    "tags": [
      "LLM应用",
      "用户体验设计",
      "自适应系统"
    ]
  },
  {
    "title": "Causal Influence in Federated Edge Inference",
    "submit_datetime": "2024年05月02日",
    "abstract": "In this paper, we consider a setting where heterogeneous agents with connectivity are performing inference using unlabeled streaming data. Observed data are only partially informative about the target variable of interest. In order to overcome the uncertainty, agents cooperate with each other by exchanging their local inferences with and through a fusion center. To evaluate how each agent influences the overall decision, we adopt a causal framework in order to distinguish the actual influence of agents from mere correlations within the decision-making process. Various scenarios reflecting different agent participation patterns and fusion center policies are investigated. We derive expressions to quantify the causal impact of each agent on the joint decision, which could be beneficial for anticipating and addressing atypical scenarios, such as adversarial attacks or system malfunctions. We validate our theoretical results with numerical simulations and a real-world application of multi-camera crowd counting.",
    "pdf_link": "https://arxiv.org/abs/2405.01260",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.01260v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01260/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01260v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01260/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01260v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01260/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01260v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01260/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01260v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01260/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01260v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01260/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01260v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01260/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01260v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01260/00001965_c1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01260v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01260/00001965_c3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01260v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01260/00001965_c6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01260v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01260/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01260v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01260/x9.png"
      }
    ],
    "abstract_cn": "本文探讨了一个场景，异构智能体通过未标记的实时数据进行推理，而这些数据对于目标变量的信息提供有限。为了应对不确定性，智能体们通过融合中心交换各自的局部推断结果，实现协同合作。本研究采用因果框架来评估每个智能体对集体决策的具体影响，区分了智能体的实际影响力与决策过程中的表面相关性。研究涵盖了多种不同智能体参与模式和融合中心策略的情景。我们建立了计算每个智能体对共同决策因果影响的公式，这对于预测和处理如对抗性攻击或系统故障等异常情况具有重要意义。理论分析通过数值模拟和实际的多摄像头人群计数应用得到了验证。",
    "title_cn": "在联合边缘推理领域，因果关系的影响是一个关键因素。",
    "tags": [
      "Agent",
      "智能体系统",
      "因果推断"
    ]
  },
  {
    "title": "Is Bigger Edit Batch Size Always Better? -- An Empirical Study on Model Editing with Llama-3",
    "submit_datetime": "2024年05月01日",
    "abstract": "This study presents a targeted model editing analysis focused on the latest large language model, Llama-3. We explore the efficacy of popular model editing techniques - ROME, MEMIT, and EMMET, which are designed for precise layer interventions. We identify the most effective layers for targeted edits through an evaluation that encompasses up to 4096 edits across three distinct strategies: sequential editing, batch editing, and a hybrid approach we call as sequential-batch editing. Our findings indicate that increasing edit batch-sizes may degrade model performance more significantly than using smaller edit batches sequentially for equal number of edits. With this, we argue that sequential model editing is an important component for scaling model editing methods and future research should focus on methods that combine both batched and sequential editing. This observation suggests a potential limitation in current model editing methods which push towards bigger edit batch sizes, and we hope it paves way for future investigations into optimizing batch sizes and model editing performance.",
    "pdf_link": "https://arxiv.org/abs/2405.00664",
    "graphs": [],
    "abstract_cn": "本研究针对最新的大型语言模型 Llama-3，进行了一项精准的模型编辑策略分析。我们评估了几种流行的编辑技术——ROME、MEMIT 和 EMMET，它们专为精细的层次化编辑而设计。通过对比多达 4096 次的编辑，我们发现了最有效的编辑层次，这些编辑策略包括顺序编辑、批量编辑，以及我们提出的顺序-批量混合编辑方法。研究结果显示，相比于顺序进行较小批量的编辑，增大编辑批量可能会对模型性能产生更明显的负面影响。因此，我们认为顺序化的模型编辑对于提升编辑效率至关重要，未来研究应更多关注如何融合批量与顺序编辑的策略。这一发现也指出了当前模型编辑方法的一个潜在限制，即追求更大的编辑批量，我们期待这能激发未来对编辑批量大小和模型编辑效能优化的进一步探索。",
    "title_cn": "编辑批量大小越大，效果一定越佳吗？一项基于 Llama-3 模型编辑的实证探索。",
    "tags": [
      "LLM应用",
      "人工智能",
      "模型优化"
    ]
  },
  {
    "title": "HalluVault: A Novel Logic Programming-aided Metamorphic Testing Framework for Detecting Fact-Conflicting Hallucinations in Large Language Models",
    "submit_datetime": "2024年05月01日",
    "abstract": "Large language models (LLMs) have transformed the landscape of language processing, yet struggle with significant challenges in terms of security, privacy, and the generation of seemingly coherent but factually inaccurate outputs, commonly referred to as hallucinations. Among these challenges, one particularly pressing issue is Fact-Conflicting Hallucination (FCH), where LLMs generate content that directly contradicts established facts. Tackling FCH poses a formidable task due to two primary obstacles: Firstly, automating the construction and updating of benchmark datasets is challenging, as current methods rely on static benchmarks that don't cover the diverse range of FCH scenarios. Secondly, validating LLM outputs' reasoning process is inherently complex, especially with intricate logical relations involved.\n  In addressing these obstacles, we propose an innovative approach leveraging logic programming to enhance metamorphic testing for detecting Fact-Conflicting Hallucinations (FCH). Our method gathers data from sources like Wikipedia, expands it with logical reasoning to create diverse test cases, assesses LLMs through structured prompts, and validates their coherence using semantic-aware assessment mechanisms. Our method generates test cases and detects hallucinations across six different LLMs spanning nine domains, revealing hallucination rates ranging from 24.7% to 59.8%. Key observations indicate that LLMs encounter challenges, particularly with temporal concepts, handling out-of-distribution knowledge, and exhibiting deficiencies in logical reasoning capabilities. The outcomes underscore the efficacy of logic-based test cases generated by our tool in both triggering and identifying hallucinations. These findings underscore the imperative for ongoing collaborative endeavors within the community to detect and address LLM hallucinations.",
    "pdf_link": "https://arxiv.org/abs/2405.00648",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）重塑了语言处理的领域，却在安全性、隐私保护以及避免生成内容上的幻觉——即那些貌似合理却与事实不符的输出——方面遭遇重重挑战。特别棘手的是事实冲突幻觉（FCH），在这种情况下，LLMs产出的内容与已知事实直接相悖。应对FCH的挑战颇为艰巨，主要原因有两个：首先，自动化构建和更新基准数据集存在难度，因为现有方法依赖的静态基准无法涵盖FCH的各种情况。其次，验证LLMs输出的推理过程极为复杂，尤其是在涉及复杂逻辑关系时。为应对这些难题，我们提出了一种创新的逻辑编程方法，以增强变异测试，从而检测FCH。该方法从维基百科等来源搜集数据，通过逻辑推理扩展，生成多样化的测试案例，并通过结构化提示对LLMs进行评估，同时利用语义感知机制来验证它们的一致性。我们的方法在六个不同领域的LLMs上生成测试案例并检测幻觉，发现幻觉率在24.7%到59.8%之间。关键的观察结果显示，LLMs在处理时间概念、管理分布外知识以及逻辑推理能力方面存在挑战。这些结果凸显了我们工具生成的基于逻辑的测试案例在触发和识别幻觉方面的有效性，并强调了社区持续合作以检测和解决LLM幻觉问题的必要性。",
    "title_cn": "HalluVault：一个创新的基于逻辑编程的变异测试框架，专为发现大型语言模型中与事实相悖的幻觉现象而设计。",
    "tags": [
      "LLM应用",
      "",
      "软件测试"
    ]
  },
  {
    "title": "When Quantization Affects Confidence of Large Language Models?",
    "submit_datetime": "2024年05月01日",
    "abstract": "Recent studies introduced effective compression techniques for Large Language Models (LLMs) via post-training quantization or low-bit weight representation. Although quantized weights offer storage efficiency and allow for faster inference, existing works have indicated that quantization might compromise performance and exacerbate biases in LLMs. This study investigates the confidence and calibration of quantized models, considering factors such as language model type and scale as contributors to quantization loss. Firstly, we reveal that quantization with GPTQ to 4-bit results in a decrease in confidence regarding true labels, with varying impacts observed among different language models. Secondly, we observe fluctuations in the impact on confidence across different scales. Finally, we propose an explanation for quantization loss based on confidence levels, indicating that quantization disproportionately affects samples where the full model exhibited low confidence levels in the first place.",
    "pdf_link": "https://arxiv.org/abs/2405.00632",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00632v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00632/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00632v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00632/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00632v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00632/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00632v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00632/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00632v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00632/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00632v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00632/x6.png"
      }
    ],
    "abstract_cn": "近期研究通过训练后的量化或低比特权重量表示，为大型语言模型（LLMs）带来了高效的压缩方法。虽然量化权重有助于节省存储空间并加快推理速度，但现有研究指出，量化可能会影响模型性能并放大LLMs的偏见。本研究深入探讨了量化模型的置信度和校准问题，分析了语言模型类型和规模对量化损失的影响。我们首先发现，采用GPTQ量化至4位会降低对正确标签的置信度，且这种影响在不同语言模型中表现不一。其次，我们注意到置信度在不同规模的语言模型中波动。最终，我们基于置信度水平对量化损失提出了解释，指出量化对于那些模型原本就缺乏信心的样本影响更大。",
    "title_cn": "量化如何影响大型语言模型的置信度？",
    "tags": [
      "LLM理论",
      "",
      "机器学习"
    ]
  },
  {
    "title": "\"I'm Not Sure, But...\": Examining the Impact of Large Language Models' Uncertainty Expression on User Reliance and Trust",
    "submit_datetime": "2024年05月01日",
    "abstract": "Widely deployed large language models (LLMs) can produce convincing yet incorrect outputs, potentially misleading users who may rely on them as if they were correct. To reduce such overreliance, there have been calls for LLMs to communicate their uncertainty to end users. However, there has been little empirical work examining how users perceive and act upon LLMs' expressions of uncertainty. We explore this question through a large-scale, pre-registered, human-subject experiment (N=404) in which participants answer medical questions with or without access to responses from a fictional LLM-infused search engine. Using both behavioral and self-reported measures, we examine how different natural language expressions of uncertainty impact participants' reliance, trust, and overall task performance. We find that first-person expressions (e.g., \"I'm not sure, but...\") decrease participants' confidence in the system and tendency to agree with the system's answers, while increasing participants' accuracy. An exploratory analysis suggests that this increase can be attributed to reduced (but not fully eliminated) overreliance on incorrect answers. While we observe similar effects for uncertainty expressed from a general perspective (e.g., \"It's not clear, but...\"), these effects are weaker and not statistically significant. Our findings suggest that using natural language expressions of uncertainty may be an effective approach for reducing overreliance on LLMs, but that the precise language used matters. This highlights the importance of user testing before deploying LLMs at scale.",
    "pdf_link": "https://arxiv.org/abs/2405.00623",
    "graphs": [],
    "abstract_cn": "广泛应用的大型语言模型（LLMs）有时会产生貌似可信却错误的结果，这容易误导那些将其视为绝对正确的用户。为了避免用户过度依赖，人们开始呼吁LLMs能够向用户明确表达其不确定性。尽管如此，关于用户如何理解和响应LLMs不确定性表达的实证研究却寥寥无几。本研究通过一项大规模的、预先注册的、涉及404名参与者的人类实验来探讨这一问题，实验中参与者在有或没有使用一个虚构的LLM支持的搜索引擎回答医疗问题的情况下进行回答。我们综合运用了行为测量和自我报告的方法，来评估不同自然语言中不确定性表达对参与者依赖度、信任感和任务完成表现的影响。研究发现，使用第一人称的不确定性表达（例如，“我不太确定，但是...”）能够减少参与者对系统的信心，降低他们与系统答案一致的倾向，并提高他们的准确性。进一步分析表明，这种准确性的提升源于对错误答案依赖度的减少，尽管这种减少并未完全消除。而从一般角度表达不确定性（例如，“这不太明确，但是...”）虽有相似效果，但影响较小，且未达到统计学意义。研究结果表明，采用自然语言的不确定性表达是减少用户对LLMs过度依赖的有效途径，但所用的具体语言至关重要。这进一步强调了在大规模推广LLMs前进行用户测试的必要性。",
    "title_cn": "《“我不确定，但是...”：探究大型语言模型不确定性表述对用户信赖与依赖的影响》",
    "tags": [
      "LLM应用",
      "人工智能",
      "用户研究"
    ]
  },
  {
    "title": "Addressing Topic Granularity and Hallucination in Large Language Models for Topic Modelling",
    "submit_datetime": "2024年05月01日",
    "abstract": "Large language models (LLMs) with their strong zero-shot topic extraction capabilities offer an alternative to probabilistic topic modelling and closed-set topic classification approaches. As zero-shot topic extractors, LLMs are expected to understand human instructions to generate relevant and non-hallucinated topics based on the given documents. However, LLM-based topic modelling approaches often face difficulties in generating topics with adherence to granularity as specified in human instructions, often resulting in many near-duplicate topics. Furthermore, methods for addressing hallucinated topics generated by LLMs have not yet been investigated. In this paper, we focus on addressing the issues of topic granularity and hallucinations for better LLM-based topic modelling. To this end, we introduce a novel approach that leverages Direct Preference Optimisation (DPO) to fine-tune open-source LLMs, such as Mistral-7B. Our approach does not rely on traditional human annotation to rank preferred answers but employs a reconstruction pipeline to modify raw topics generated by LLMs, thus enabling a fast and efficient training and inference framework. Comparative experiments show that our fine-tuning approach not only significantly improves the LLM's capability to produce more coherent, relevant, and precise topics, but also reduces the number of hallucinated topics.",
    "pdf_link": "https://arxiv.org/abs/2405.00611",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00611v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00611/super25APR2024_new_ecai_fig1_.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00611v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00611/prompt_ecai.drawio.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00611v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00611/acai_pipeline_25APR.drawio.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00611v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00611/topic_attention_flow.png"
      }
    ],
    "abstract_cn": "大规模语言模型（LLMs）以其出色的零样本主题抽取功能，为传统的主题建模和封闭集分类方法提供了新选择。这些模型能够根据文档内容，理解指令并生成相关且真实的主题。但当前基于 LLM 的主题建模技术在精确控制主题粒度上存在挑战，常产生大量相似主题。同时，对于 LLM 产生的虚构主题，尚缺乏有效的处理方法。本文聚焦于改善主题粒度控制和减少幻觉现象，以优化基于 LLM 的主题建模。我们提出了一种创新方法，通过直接偏好优化（DPO）技术对开源 LLMs 如 Mistral-7B 进行微调。此方法摒弃了传统的人工标注排名，转而使用重构流程来优化 LLMs 产出的原始主题，实现了一个迅捷高效的训练与推理系统。对比实验结果证明，我们的微调策略显著提升了 LLMs 在生成更一致、贴切、精确主题方面的能力，并有效减少了虚构主题的产生。",
    "title_cn": "探讨大型语言模型在主题建模中的主题粒度细化与幻觉现象",
    "tags": [
      "LLM应用",
      "",
      "主题建模"
    ]
  },
  {
    "title": "Investigating Automatic Scoring and Feedback using Large Language Models",
    "submit_datetime": "2024年05月01日",
    "abstract": "Automatic grading and feedback have been long studied using traditional machine learning and deep learning techniques using language models. With the recent accessibility to high performing large language models (LLMs) like LLaMA-2, there is an opportunity to investigate the use of these LLMs for automatic grading and feedback generation. Despite the increase in performance, LLMs require significant computational resources for fine-tuning and additional specific adjustments to enhance their performance for such tasks. To address these issues, Parameter Efficient Fine-tuning (PEFT) methods, such as LoRA and QLoRA, have been adopted to decrease memory and computational requirements in model fine-tuning. This paper explores the efficacy of PEFT-based quantized models, employing classification or regression head, to fine-tune LLMs for automatically assigning continuous numerical grades to short answers and essays, as well as generating corresponding feedback. We conducted experiments on both proprietary and open-source datasets for our tasks. The results show that prediction of grade scores via finetuned LLMs are highly accurate, achieving less than 3% error in grade percentage on average. For providing graded feedback fine-tuned 4-bit quantized LLaMA-2 13B models outperform competitive base models and achieve high similarity with subject matter expert feedback in terms of high BLEU and ROUGE scores and qualitatively in terms of feedback. The findings from this study provide important insights into the impacts of the emerging capabilities of using quantization approaches to fine-tune LLMs for various downstream tasks, such as automatic short answer scoring and feedback generation at comparatively lower costs and latency.",
    "pdf_link": "https://arxiv.org/abs/2405.00602",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00602v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00602/cogwheel.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00602v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00602/cogwheel.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00602v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00602/loss_curves.png"
      }
    ],
    "abstract_cn": "自动评分与反馈的探索一直依赖于传统和深度学习技术，以及语言模型的应用。随着高性能的大型语言模型（LLMs）如 LLaMA-2 的问世，我们得以进一步研究其在自动评分和反馈生成上的潜力。尽管性能显著提升，但LLMs在微调过程中仍需大量计算资源，并需特定调整以优化任务性能。为克服这些挑战，参数高效微调（PEFT）方法，包括LoRA和QLoRA，被引入以降低模型微调的内存和计算需求。本研究评估了基于PEFT的量化模型，通过分类或回归机制，对LLMs进行微调，以实现对短答案和论文的连续数值评分及反馈生成。我们在专有和开源数据集上进行了实验，结果显示，经微调的LLMs在评分精度上表现卓越，平均误差率低于3%。此外，微调后的4位量化LLaMA-2 13B模型在提供分级反馈方面超越了基准模型，并在BLEU和ROUGE评分以及反馈质量上与领域专家的反馈达到了高度一致性。本研究的发现为我们提供了宝贵的洞见，尤其是在使用量化技术微调LLMs以执行各种下游任务，如自动评分和反馈生成，且成本和延迟更低的情况下。",
    "title_cn": "探究基于大型语言模型的自动评分与反馈机制",
    "tags": [
      "LLM应用",
      "",
      "自动化评分"
    ]
  },
  {
    "title": "Are Models Biased on Text without Gender-related Language?",
    "submit_datetime": "2024年05月01日",
    "abstract": "Gender bias research has been pivotal in revealing undesirable behaviors in large language models, exposing serious gender stereotypes associated with occupations, and emotions. A key observation in prior work is that models reinforce stereotypes as a consequence of the gendered correlations that are present in the training data. In this paper, we focus on bias where the effect from training data is unclear, and instead address the question: Do language models still exhibit gender bias in non-stereotypical settings? To do so, we introduce UnStereoEval (USE), a novel framework tailored for investigating gender bias in stereotype-free scenarios. USE defines a sentence-level score based on pretraining data statistics to determine if the sentence contain minimal word-gender associations. To systematically benchmark the fairness of popular language models in stereotype-free scenarios, we utilize USE to automatically generate benchmarks without any gender-related language. By leveraging USE's sentence-level score, we also repurpose prior gender bias benchmarks (Winobias and Winogender) for non-stereotypical evaluation. Surprisingly, we find low fairness across all 28 tested models. Concretely, models demonstrate fair behavior in only 9%-41% of stereotype-free sentences, suggesting that bias does not solely stem from the presence of gender-related words. These results raise important questions about where underlying model biases come from and highlight the need for more systematic and comprehensive bias evaluation. We release the full dataset and code at https://ucinlp.github.io/unstereo-eval.",
    "pdf_link": "https://arxiv.org/abs/2405.00588",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00588v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00588/figure.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00588v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00588/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00588v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00588/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00588v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00588/histplot--wordpmi--PILE-she-he.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00588v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00588/histplot--wordpmi--PILE-she-he-diff.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00588v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00588/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00588v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00588/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00588v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00588/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00588v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00588/x6.png"
      }
    ],
    "abstract_cn": "性别偏见研究揭示了大型语言模型中的不良行为，尤其是与职业和情感相关的性别刻板印象。研究发现，模型往往会因为训练数据中的性别相关性而加深这些刻板印象。本文聚焦于训练数据影响不明显的偏见问题，探讨语言模型在非刻板印象环境下是否仍存在性别偏见。我们提出了UnStereoEval（USE），一个新颖的框架，专为无性别刻板印象场景下探究性别偏见而设计。USE通过预训练数据的统计信息，为句子设定了一个级别分数，以判断其是否含有最少的词-性别关联。利用USE，我们自动生成了不含性别相关语言的基准，以系统地评估流行语言模型在无刻板印象场景下的公平性。此外，我们还利用USE的分数重新评估了先前的性别偏见基准（Winobias和Winogender），以进行非刻板印象的评估。研究发现，在所有测试的28个模型中，公平性普遍较低，模型在9%-41%的无刻板印象句子中才表现出公平行为，这表明偏见并非仅源自性别相关词汇。这一发现引发了关于模型潜在偏见来源的重要讨论，并突显了进行更系统和全面偏见评估的迫切需求。我们已经在 https://ucinlp.github.io/unstereo-eval 上公开了完整的数据集和代码。",
    "title_cn": "文本中若未涉及性别相关词汇，模型是否会表现出偏见？",
    "tags": [
      "LLM应用",
      "性别偏见",
      ""
    ]
  },
  {
    "title": "The Real, the Better: Aligning Large Language Models with Online Human Behaviors",
    "submit_datetime": "2024年05月01日",
    "abstract": "Large language model alignment is widely used and studied to avoid LLM producing unhelpful and harmful responses. However, the lengthy training process and predefined preference bias hinder adaptation to online diverse human preferences. To this end, this paper proposes an alignment framework, called Reinforcement Learning with Human Behavior (RLHB), to align LLMs by directly leveraging real online human behaviors. By taking the generative adversarial framework, the generator is trained to respond following expected human behavior; while the discriminator tries to verify whether the triplets of query, response, and human behavior come from real online environments. Behavior modeling in natural-language form and the multi-model joint training mechanism enable an active and sustainable online alignment. Experimental results confirm the effectiveness of our proposed methods by both human and automatic evaluations.",
    "pdf_link": "https://arxiv.org/abs/2405.00578",
    "graphs": [],
    "abstract_cn": "为防止大型语言模型（LLM）生成无益或有害的回答，对其对齐的研究和应用已相当广泛。但训练周期的漫长和固有的偏好偏差限制了其适应网络中多样化的人类偏好。本论文提出了一种名为“基于人类行为的强化学习（RLHB）”的对齐框架，该框架直接利用在线真实人类行为来调整 LLM。在生成对抗网络的框架下，训练生成器以模仿预期的人类行为做出回应，同时鉴别器负责判断查询、回答和人类行为的组合是否源自真实的在线情境。自然语言的行为建模和多模型联合训练机制，确保了在线对齐的活跃性和可持续性。实验结果通过人工和自动化评估验证了我们提出方法的有效性。",
    "title_cn": "追求真实，更上一层楼：使大型语言模型与网民在线行为同步。",
    "tags": [
      "LLM应用",
      "人工智能",
      ""
    ]
  },
  {
    "title": "EALD-MLLM: Emotion Analysis in Long-sequential and De-identity videos with Multi-modal Large Language Model",
    "submit_datetime": "2024年05月01日",
    "abstract": "Emotion AI is the ability of computers to understand human emotional states. Existing works have achieved promising progress, but two limitations remain to be solved: 1) Previous studies have been more focused on short sequential video emotion analysis while overlooking long sequential video. However, the emotions in short sequential videos only reflect instantaneous emotions, which may be deliberately guided or hidden. In contrast, long sequential videos can reveal authentic emotions; 2) Previous studies commonly utilize various signals such as facial, speech, and even sensitive biological signals (e.g., electrocardiogram). However, due to the increasing demand for privacy, developing Emotion AI without relying on sensitive signals is becoming important. To address the aforementioned limitations, in this paper, we construct a dataset for Emotion Analysis in Long-sequential and De-identity videos called EALD by collecting and processing the sequences of athletes' post-match interviews. In addition to providing annotations of the overall emotional state of each video, we also provide the Non-Facial Body Language (NFBL) annotations for each player. NFBL is an inner-driven emotional expression and can serve as an identity-free clue to understanding the emotional state. Moreover, we provide a simple but effective baseline for further research. More precisely, we evaluate the Multimodal Large Language Models (MLLMs) with de-identification signals (e.g., visual, speech, and NFBLs) to perform emotion analysis. Our experimental results demonstrate that: 1) MLLMs can achieve comparable, even better performance than the supervised single-modal models, even in a zero-shot scenario; 2) NFBL is an important cue in long sequential emotion analysis. EALD will be available on the open-source platform.",
    "pdf_link": "https://arxiv.org/abs/2405.00574",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00574v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00574/N3Touchingorscratchinghead.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.00574v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00574/N8Touchingears.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.00574v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00574/N11Touchingorscratchingneck.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.00574v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00574/N12Playingoradjustinghair.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.00574v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00574/N14Touchingorcoveringsuprasternalnotch.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.00574v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00574/N16Foldingarms.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.00574v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00574/N17Dustoffclothes.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.00574v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00574/N19Movingtorso.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.00574v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00574/N20Sitstraightly.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.00574v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00574/N24Minaretgesture.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.00574v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00574/N30Shakedoubleshoulders.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.00574v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00574/N34Touchingnose.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.00574v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00574/imiguevseald.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00574v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00574/waveform_plot_original.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00574v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00574/waveform_plot_deid.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00574v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00574/spectrogram_plot.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00574v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00574/spectrogram_plot_deid.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00574v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00574/Histogram.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00574v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00574/Framework.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00574v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00574/Usercase1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00574v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00574/Usercase2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00574v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00574/fail.png"
      }
    ],
    "abstract_cn": "情感人工智能，即机器对人类情感的洞察力，已在研究中取得显著成果，但仍有两大挑战亟待克服：首先，过往研究多聚焦于短视频情感分析，而忽略了长视频序列的重要性。短视频仅能捕捉瞬间情感，可能受人为操控或隐藏，而长视频则能展现更真实的情感表达；其次，尽管现有研究广泛采用面部、语音乃至敏感的生物信号（如心电图），但随着隐私保护意识的增强，开发不依赖敏感信息的情感AI技术变得尤为关键。为应对这些挑战，本文提出了一个新的数据集EALD，专注于长序列、去身份运动员赛后访谈的情感分析。我们不仅标注了每段视频的整体情感状态，还对每位运动员的非面部肢体语言（NFBL）进行了详细注释，NFBL作为一种内在的情感表达，为我们提供了一个不受身份影响的情感识别线索。此外，我们还建立了一个简洁而有效的基线模型，用于后续研究。通过评估多模态大型语言模型（MLLM）在去除身份信息信号（如视觉、语音和NFBL）后的情感分析性能，我们的实验证实了MLLM即使在零样本情况下也能与单模态监督模型相媲美，甚至更优，同时NFBL在长序列情感分析中扮演了关键角色。EALD数据集将面向公众开放。",
    "title_cn": "EALD-MLLM：利用多模态大型语言模型对长序列及去身份视频进行情感分析。",
    "tags": [
      "分类：Agent",
      "情感分析",
      "人工智能"
    ]
  },
  {
    "title": "NumLLM: Numeric-Sensitive Large Language Model for Chinese Finance",
    "submit_datetime": "2024年05月01日",
    "abstract": "Recently, many works have proposed various financial large language models (FinLLMs) by pre-training from scratch or fine-tuning open-sourced LLMs on financial corpora. However, existing FinLLMs exhibit unsatisfactory performance in understanding financial text when numeric variables are involved in questions. In this paper, we propose a novel LLM, called numeric-sensitive large language model (NumLLM), for Chinese finance. We first construct a financial corpus from financial textbooks which is essential for improving numeric capability of LLMs during fine-tuning. After that, we train two individual low-rank adaptation (LoRA) modules by fine-tuning on our constructed financial corpus. One module is for adapting general-purpose LLMs to financial domain, and the other module is for enhancing the ability of NumLLM to understand financial text with numeric variables. Lastly, we merge the two LoRA modules into the foundation model to obtain NumLLM for inference. Experiments on financial question-answering benchmark show that NumLLM can boost the performance of the foundation model and can achieve the best overall performance compared to all baselines, on both numeric and non-numeric questions.",
    "pdf_link": "https://arxiv.org/abs/2405.00566",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00566v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00566/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00566v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00566/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00566v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00566/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00566v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00566/x4.png"
      }
    ],
    "abstract_cn": "近期，众多研究提出了多种金融领域的大型语言模型（FinLLMs），这些模型通过从零开始预训练或对开源的大型语言模型（LLMs）进行金融语料库的微调来构建。但是，这些现有的金融LLMs在处理包含数值变量的金融文本理解任务时，表现不尽如人意。本文提出了一种创新的大型语言模型——数值敏感型大型语言模型（NumLLM），专门针对中文金融领域。我们首先从金融教科书中构建关键的金融语料库，这对于提升LLMs在微调阶段的数值处理能力极为重要。接着，我们在自建的金融语料库上对两个独立的低秩适应（LoRA）模块进行微调训练。其中一个模块旨在将通用型LLMs适配到金融领域，另一个则致力于提升NumLLM对含有数值变量的金融文本的理解力。最终，我们将这两个LoRA模块整合到基础模型中，形成用于推理的NumLLM。在金融问答领域的基准测试中，NumLLM不仅提升了基础模型的性能，而且在处理数值型和非数值型问题时均展现出超越所有对照基准的最优整体表现。",
    "title_cn": "NumLLM：一款专为中文金融领域设计的、对数值高度敏感的大型语言模型。",
    "tags": [
      "LLM应用",
      "",
      ""
    ]
  },
  {
    "title": "Mixture of insighTful Experts (MoTE): The Synergy of Thought Chains and Expert Mixtures in Self-Alignment",
    "submit_datetime": "2024年05月01日",
    "abstract": "As the capabilities of large language models (LLMs) have expanded dramatically, aligning these models with human values presents a significant challenge, posing potential risks during deployment. Traditional alignment strategies rely heavily on human intervention, such as Supervised Fine-Tuning (SFT) and Reinforcement Learning from Human Feedback (RLHF), or on the self-alignment capacities of LLMs, which usually require a strong LLM's emergent ability to improve its original bad answer. To address these challenges, we propose a novel self-alignment method that utilizes a Chain of Thought (CoT) approach, termed AlignCoT. This method encompasses stages of Question Analysis, Answer Guidance, and Safe Answer production. It is designed to enable LLMs to generate high-quality, safe responses throughout various stages of their development. Furthermore, we introduce the Mixture of insighTful Experts (MoTE) architecture, which applies the mixture of experts to enhance each component of the AlignCoT process, markedly increasing alignment efficiency. The MoTE approach not only outperforms existing methods in aligning LLMs with human values but also highlights the benefits of using self-generated data, revealing the dual benefits of improved alignment and training efficiency.",
    "pdf_link": "https://arxiv.org/abs/2405.00557",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00557v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00557/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00557v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00557/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00557v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00557/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00557v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00557/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00557v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00557/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00557v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00557/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00557v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00557/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00557v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00557/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00557v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00557/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00557v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00557/x10.png"
      }
    ],
    "abstract_cn": "随着大型语言模型（LLMs）功能的显著增强，如何使其与人类的价值观保持一致成为了一项重大挑战，并可能在实际应用中引发风险。传统的方法，如监督式微调（SFT）和基于人类反馈的强化学习（RLHF），往往依赖于人工介入，或是依赖于LLMs自身的对齐能力，这通常需要模型具备强大的自我改进能力。为了解决这些问题，我们提出了一种创新的自我对齐方法——思维链（Chain of Thought，CoT）方法，简称AlignCoT。该方法包含问题解析、答案引导和安全答案生成等环节，旨在帮助LLMs在成长过程中的各个阶段产出高品质且安全的回应。此外，我们还引入了洞察力专家混合（Mixture of insighTful Experts，MoTE）架构，该架构通过专家混合技术优化AlignCoT过程的每个环节，显著提升了对齐的效率。MoTE方法不仅在使LLMs与人类价值观对齐方面超越了现有技术，还展示了利用自生成数据的优势，实现了对齐精度和训练效率的双重提升。",
    "title_cn": "洞察力专家混合体（MoTE）：在自我对齐的过程中，思维链与专家组合的相互促进。",
    "tags": [
      "LLM应用",
      "人工智能",
      "伦理道德"
    ]
  },
  {
    "title": "Long-Term Human Trajectory Prediction using 3D Dynamic Scene Graphs",
    "submit_datetime": "2024年05月01日",
    "abstract": "We present a novel approach for long-term human trajectory prediction, which is essential for long-horizon robot planning in human-populated environments. State-of-the-art human trajectory prediction methods are limited by their focus on collision avoidance and short-term planning, and their inability to model complex interactions of humans with the environment. In contrast, our approach overcomes these limitations by predicting sequences of human interactions with the environment and using this information to guide trajectory predictions over a horizon of up to 60s. We leverage Large Language Models (LLMs) to predict interactions with the environment by conditioning the LLM prediction on rich contextual information about the scene. This information is given as a 3D Dynamic Scene Graph that encodes the geometry, semantics, and traversability of the environment into a hierarchical representation. We then ground these interaction sequences into multi-modal spatio-temporal distributions over human positions using a probabilistic approach based on continuous-time Markov Chains. To evaluate our approach, we introduce a new semi-synthetic dataset of long-term human trajectories in complex indoor environments, which also includes annotations of human-object interactions. We show in thorough experimental evaluations that our approach achieves a 54% lower average negative log-likelihood (NLL) and a 26.5% lower Best-of-20 displacement error compared to the best non-privileged baselines for a time horizon of 60s.",
    "pdf_link": "https://arxiv.org/abs/2405.00552",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00552v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00552/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00552v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00552/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00552v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00552/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00552v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00552/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00552v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00552/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00552v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00552/nll_stats_combined.png"
      }
    ],
    "abstract_cn": "我们提出了一种创新的长期人类轨迹预测方法，这对于机器人在人流密集的环境中进行长远规划极为关键。现行顶尖的轨迹预测技术多侧重于避碰和短期规划，缺乏模拟人与环境复杂互动的能力。我们的方案突破了这些局限，通过预测人与环境的互动序列，并据此信息在最长达60秒的时间内进行轨迹预测。我们运用大型语言模型（LLM），结合丰富的场景上下文信息，来预测环境互动，这些信息通过3D动态场景图以层次化的方式呈现，涵盖了环境的几何结构、语义信息和可通行性。随后，我们采用基于连续时间马尔可夫链的概率方法，将互动序列转化为人类位置的多模态时空分布。为验证我们的方法，我们创建了一个新的半合成数据集，记录了复杂室内环境中的长期人类轨迹及人-物互动的详细标注。实验结果表明，我们的方法在60秒的预测时限内，相较于最佳非特权基线，平均负对数似然（NLL）降低了54%，最佳20次位移误差减少了26.5%。",
    "title_cn": "通过 3D 动态场景图实现对人类长期轨迹的精准预测。",
    "tags": [
      "Agent",
      "机器人技术",
      "人工智能"
    ]
  },
  {
    "title": "A Legal Framework for Natural Language Processing Model Training in Portugal",
    "submit_datetime": "2024年05月01日",
    "abstract": "Recent advances in deep learning have promoted the advent of many computational systems capable of performing intelligent actions that, until then, were restricted to the human intellect. In the particular case of human languages, these advances allowed the introduction of applications like ChatGPT that are capable of generating coherent text without being explicitly programmed to do so. Instead, these models use large volumes of textual data to learn meaningful representations of human languages. Associated with these advances, concerns about copyright and data privacy infringements caused by these applications have emerged. Despite these concerns, the pace at which new natural language processing applications continued to be developed largely outperformed the introduction of new regulations. Today, communication barriers between legal experts and computer scientists motivate many unintentional legal infringements during the development of such applications. In this paper, a multidisciplinary team intends to bridge this communication gap and promote more compliant Portuguese NLP research by presenting a series of everyday NLP use cases, while highlighting the Portuguese legislation that may arise during its development.",
    "pdf_link": "https://arxiv.org/abs/2405.00536",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00536v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00536/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00536v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00536/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00536v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00536/x3.png"
      }
    ],
    "abstract_cn": "深度学习的最新突破催生了众多计算系统，它们能够执行以往只有人类智慧才能完成的智能任务。在人类语言领域，这一进步使得像ChatGPT这样的应用成为可能，它们无需明确编程即可生成连贯文本。这些模型依托海量文本数据，学习对人类语言的深刻理解。然而，这些技术进步也引发了关于版权和数据隐私侵犯的担忧。尽管如此，自然语言处理（NLP）应用的快速发展往往超越了法规更新的步伐。目前，法律专家与计算机科学家之间的沟通壁垒，常常在NLP应用开发过程中导致无意的法律违规。本文旨在通过展示一系列日常NLP应用案例，并指出开发中可能触及的葡萄牙法律，来弥合这一沟通鸿沟，推动葡萄牙NLP研究的合规性。",
    "title_cn": "葡萄牙建立了一个针对自然语言处理（NLP）模型训练的法律框架。",
    "tags": [
      "分类：LLM应用",
      "",
      ""
    ]
  },
  {
    "title": "ChatBI: Towards Natural Language to Complex Business Intelligence SQL",
    "submit_datetime": "2024年05月01日",
    "abstract": "The Natural Language to SQL (NL2SQL) technology provides non-expert users who are unfamiliar with databases the opportunity to use SQL for data analysis.Converting Natural Language to Business Intelligence (NL2BI) is a popular practical scenario for NL2SQL in actual production systems. Compared to NL2SQL, NL2BI introduces more challenges.\n  In this paper, we propose ChatBI, a comprehensive and efficient technology for solving the NL2BI task. First, we analyze the interaction mode, an important module where NL2SQL and NL2BI differ in use, and design a smaller and cheaper model to match this interaction mode. In BI scenarios, tables contain a huge number of columns, making it impossible for existing NL2SQL methods that rely on Large Language Models (LLMs) for schema linking to proceed due to token limitations. The higher proportion of ambiguous columns in BI scenarios also makes schema linking difficult. ChatBI combines existing view technology in the database community to first decompose the schema linking problem into a Single View Selection problem and then uses a smaller and cheaper machine learning model to select the single view with a significantly reduced number of columns. The columns of this single view are then passed as the required columns for schema linking into the LLM. Finally, ChatBI proposes a phased process flow different from existing process flows, which allows ChatBI to generate SQL containing complex semantics and comparison relations more accurately.\n  We have deployed ChatBI on Baidu's data platform and integrated it into multiple product lines for large-scale production task evaluation. The obtained results highlight its superiority in practicality, versatility, and efficiency. At the same time, compared with the current mainstream NL2SQL technology under our real BI scenario data tables and queries, it also achieved the best results.",
    "pdf_link": "https://arxiv.org/abs/2405.00527",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00527v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00527/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00527v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00527/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00527v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00527/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00527v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00527/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00527v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00527/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00527v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00527/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00527v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00527/x7.png"
      }
    ],
    "abstract_cn": "自然语言到SQL（NL2SQL）技术让不熟悉数据库的用户也能轻松运用SQL进行数据分析。而将自然语言转化为商业智能（NL2BI）则是NL2SQL技术在实际应用中的一个热门场景，它相较于NL2SQL面临更多挑战。本文提出了ChatBI，一项创新的高效技术，专为解决NL2BI问题而设计。我们首先深入分析了交互模式——这是NL2SQL与NL2BI在应用上的关键差异所在，并为此设计了一款体积更小、成本更低廉的模型。在商业智能（BI）场景中，数据表通常包含大量列，这对于依赖大型语言模型（LLMs）进行架构链接的传统NL2SQL方法来说，由于令牌限制而难以实现。此外，BI场景中模糊列的高比例也增加了架构链接的难度。ChatBI巧妙地结合了数据库领域现有的视图技术，先将架构链接问题简化为单一视图选择问题，再利用一款成本效益更高的机器学习模型来选取列数大幅减少的单一视图。随后，这个视图的列被用作LLM进行架构链接所需的列。ChatBI还提出了一种新颖的分阶段处理流程，与传统流程不同，它能够更精确地生成包含复杂语义和比较关系的SQL语句。我们在百度的数据平台上部署了ChatBI，并将其融入多条产品线，进行了大规模生产任务的评估。结果显示，ChatBI在实用性、通用性和效率方面均表现出色。与当前主流的NL2SQL技术相比，ChatBI在我们实际的BI场景数据表和查询中也取得了最优的成绩。",
    "title_cn": "ChatBI：探索将自然语言转换为复杂的商业智能SQL语句的路径",
    "tags": [
      "LLM应用",
      "商业智能",
      "数据库"
    ]
  },
  {
    "title": "Navigating WebAI: Training Agents to Complete Web Tasks with Large Language Models and Reinforcement Learning",
    "submit_datetime": "2024年05月01日",
    "abstract": "Recent advancements in language models have demonstrated remarkable improvements in various natural language processing (NLP) tasks such as web navigation. Supervised learning (SL) approaches have achieved impressive performance while utilizing significantly less training data compared to previous methods. However, these SL-based models fall short when compared to reinforcement learning (RL) approaches, which have shown superior results. In this paper, we propose a novel approach that combines SL and RL techniques over the MiniWoB benchmark to leverage the strengths of both methods. We also address a critical limitation in previous models' understanding of HTML content, revealing a tendency to memorize target elements rather than comprehend the underlying structure. To rectify this, we propose methods to enhance true understanding and present a new baseline of results. Our experiments demonstrate that our approach outperforms previous SL methods on certain tasks using less data and narrows the performance gap with RL models, achieving 43.58\\% average accuracy in SL and 36.69\\% when combined with a multimodal RL approach. This study sets a new direction for future web navigation and offers insights into the limitations and potential of language modeling for computer tasks.",
    "pdf_link": "https://arxiv.org/abs/2405.00516",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00516/comparison_existing_works.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.00516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00516/miniwob_examples.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00516/action_history.jpeg"
      },
      {
        "url": "https://arxiv.org/html/2405.00516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00516/T5_Model_Input.jpeg"
      },
      {
        "url": "https://arxiv.org/html/2405.00516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00516/reference_numbers_histogram.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00516/ccnet5_architecture.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00516/click_color_episode.jpeg"
      },
      {
        "url": "https://arxiv.org/html/2405.00516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00516/click-checkboxes-soft.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00516/use-spinner.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00516/bc_results_webnt5_comparison_random_ordered.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.00516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00516/ccnet5_ablation.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.00516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00516/bc_results_t5_base_hierarchical.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.00516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00516/bc_results_t5_large_hierarchical.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.00516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00516/bc_results_ccnet5.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.00516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00516/rl_results_ccnet5.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.00516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00516/distribution_of_task_names.png"
      }
    ],
    "abstract_cn": "近期语言模型的突破在自然语言处理（NLP）领域，如网页导航等任务中取得了显著进步。相较于传统方法，监督学习（SL）策略在大幅减少训练数据的同时，依旧取得了卓越的成效。尽管如此，SL模型相较于强化学习（RL）策略仍有提升空间，后者在性能上更胜一筹。本文提出了一种创新的方法，将SL与RL技术相结合，针对MiniWoB基准测试，旨在发挥两种方法的长处。同时，我们针对先前模型在解析HTML内容上的一个主要缺陷进行了改进，即它们更倾向于记忆目标元素而非理解其结构。为此，我们提出了增强深层理解的方法，并设立了新的基准结果。实验结果证明，我们的方法在减少数据使用的同时，在某些任务上超越了传统SL方法，并与RL模型的性能差距显著缩小，SL方法的平均准确率达到了43.58%，而结合多模态RL策略时为36.69%。本研究不仅为未来网页导航的发展指明了新方向，还深入探讨了计算机任务中语言模型的局限性与潜力。",
    "title_cn": "探索 WebAI：通过大型语言模型和强化学习训练代理来完成网络任务。",
    "tags": [
      "LLM应用",
      "",
      "网页导航"
    ]
  },
  {
    "title": "GOLD: Geometry Problem Solver with Natural Language Description",
    "submit_datetime": "2024年05月01日",
    "abstract": "Addressing the challenge of automated geometry math problem-solving in artificial intelligence (AI) involves understanding multi-modal information and mathematics. Current methods struggle with accurately interpreting geometry diagrams, which hinders effective problem-solving. To tackle this issue, we present the Geometry problem sOlver with natural Language Description (GOLD) model. GOLD enhances the extraction of geometric relations by separately processing symbols and geometric primitives within the diagram. Subsequently, it converts the extracted relations into natural language descriptions, efficiently utilizing large language models to solve geometry math problems. Experiments show that the GOLD model outperforms the Geoformer model, the previous best method on the UniGeo dataset, by achieving accuracy improvements of 12.7% and 42.1% in calculation and proving subsets. Additionally, it surpasses the former best model on the PGPS9K and Geometry3K datasets, PGPSNet, by obtaining accuracy enhancements of 1.8% and 3.2%, respectively.",
    "pdf_link": "https://arxiv.org/abs/2405.00494",
    "graphs": [],
    "abstract_cn": "面对AI领域自动化几何数学问题求解的挑战，关键在于理解多模态信息与数学概念。现有技术在精确解读几何图形方面力有未逮，这限制了问题解决的效率。为此，我们引入了一种名为GOLD（Geometry problem sOlver with natural Language Description）的模型。GOLD通过区分处理图形中的符号和几何元素，优化了几何关系的识别。然后，它将这些关系转化为自然语言描述，并借助大型语言模型高效解决几何数学问题。在UniGeo数据集上的实验结果显示，GOLD模型在计算和证明任务的准确度上分别比前最佳方法Geoformer模型提升了12.7%和42.1%。同时，在PGPS9K和Geometry3K数据集上，GOLD模型也超越了PGPSNet模型，准确度分别提升了1.8%和3.2%。",
    "title_cn": "GOLD：一款能够理解自然语言描述来解决几何问题的智能求解器。",
    "tags": [
      "LLM应用",
      "AI自动化",
      "数学教育"
    ]
  },
  {
    "title": "Is Temperature the Creativity Parameter of Large Language Models?",
    "submit_datetime": "2024年05月01日",
    "abstract": "Large language models (LLMs) are applied to all sorts of creative tasks, and their outputs vary from beautiful, to peculiar, to pastiche, into plain plagiarism. The temperature parameter of an LLM regulates the amount of randomness, leading to more diverse outputs; therefore, it is often claimed to be the creativity parameter. Here, we investigate this claim using a narrative generation task with a predetermined fixed context, model and prompt. Specifically, we present an empirical analysis of the LLM output for different temperature values using four necessary conditions for creativity in narrative generation: novelty, typicality, cohesion, and coherence. We find that temperature is weakly correlated with novelty, and unsurprisingly, moderately correlated with incoherence, but there is no relationship with either cohesion or typicality. However, the influence of temperature on creativity is far more nuanced and weak than suggested by the \"creativity parameter\" claim; overall results suggest that the LLM generates slightly more novel outputs as temperatures get higher. Finally, we discuss ideas to allow more controlled LLM creativity, rather than relying on chance via changing the temperature parameter.",
    "pdf_link": "https://arxiv.org/abs/2405.00492",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00492v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00492/comp_eval_perplexity_write.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00492v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00492/comp_eval_cossim_write.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00492v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00492/comp_eval_normeditdist_write.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00492v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00492/pca_embeddings_per_temperature.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLM）在众多创意任务中大展身手，其成果或优美、或奇特、或模仿、甚至不乏抄袭之作。LLM中的温度参数控制着随机性，催生多样化的输出，因而被广泛认为是激发创造力的关键。本研究通过固定叙事生成任务的上下文、模型和提示，对这一观点进行了实证检验。我们依据叙事生成中创新性的四个要素——新颖度、典型性、紧密度和连贯性——对不同温度设置下的LLM输出进行了细致分析。研究发现，温度与新颖度的关联并不显著，与不连贯性有中等程度的相关性，但与紧密度和典型性并无直接联系。然而，温度对创造力的影响远比所谓的“创造力调节器”更为复杂和微弱。总体而言，LLM在温度升高时产生的输出新颖度略有提升。文末，我们探讨了如何更精细地控制LLM的创造力，而非单纯依赖于调整温度参数这一随机性因素。",
    "title_cn": "温度是否决定了大型语言模型的创造力？",
    "tags": [
      "LLM应用",
      "创意写作",
      "人工智能"
    ]
  },
  {
    "title": "Explainable Automatic Grading with Neural Additive Models",
    "submit_datetime": "2024年05月01日",
    "abstract": "The use of automatic short answer grading (ASAG) models may help alleviate the time burden of grading while encouraging educators to frequently incorporate open-ended items in their curriculum. However, current state-of-the-art ASAG models are large neural networks (NN) often described as \"black box\", providing no explanation for which characteristics of an input are important for the produced output. This inexplicable nature can be frustrating to teachers and students when trying to interpret, or learn from an automatically-generated grade. To create a powerful yet intelligible ASAG model, we experiment with a type of model called a Neural Additive Model that combines the performance of a NN with the explainability of an additive model. We use a Knowledge Integration (KI) framework from the learning sciences to guide feature engineering to create inputs that reflect whether a student includes certain ideas in their response. We hypothesize that indicating the inclusion (or exclusion) of predefined ideas as features will be sufficient for the NAM to have good predictive power and interpretability, as this may guide a human scorer using a KI rubric. We compare the performance of the NAM with another explainable model, logistic regression, using the same features, and to a non-explainable neural model, DeBERTa, that does not require feature engineering.",
    "pdf_link": "https://arxiv.org/abs/2405.00489",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00489v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00489/SoundwavesItem.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00489v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00489/SoundwavesRubric.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00489v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00489/NAM_featureimportance.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00489v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00489/NAM_density.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00489v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00489/NAM_density_all.png"
      }
    ],
    "abstract_cn": "采用自动短答题评分（ASAG）系统不仅能减轻教师的评分压力，还能促进开放式问题的广泛应用。尽管如此，现有的ASAG系统往往庞大且不透明，缺乏对评分依据的明确解释，这使得教师和学生难以理解评分结果。为了解决这一问题，我们探索了一种名为神经加性模型（NAM）的模型，它将神经网络的强大性能与加性模型的清晰解释力相结合。我们利用学习科学中的知识整合（KI）框架来指导特性工程，确保评分系统能够捕捉到学生回答中的关键思想。我们推测，将预定义思想的包含或遗漏作为评分特征，不仅能提高模型的预测准确性，还能增强其可解释性，从而辅助人工评分者使用KI标准进行评分。我们还对NAM的性能进行了评估，将其与逻辑回归这一可解释模型以及DeBERTa这一无需特性工程的不可解释神经模型进行了比较。",
    "title_cn": "神经加性模型在自动评分中的应用，实现了评分过程的可解释性。",
    "tags": [
      "分类：LLM应用",
      "",
      "自动评分系统"
    ]
  },
  {
    "title": "The Pyramid of Captions",
    "submit_datetime": "2024年05月01日",
    "abstract": "We introduce a formal information-theoretic framework for image captioning by regarding it as a representation learning task. Our framework defines three key objectives: task sufficiency, minimal redundancy, and human interpretability. Building upon this foundation, we propose a novel Pyramid of Captions (PoCa) method, which constructs caption pyramids by generating localized captions for zoomed-in image patches and integrating them with global caption information using large language models. This approach leverages intuition that the detailed examination of local patches can reduce error risks and address inaccuracies in global captions, either by correcting the hallucination or adding missing details. Based on our theoretical framework, we formalize this intuition and provide formal proof demonstrating the effectiveness of PoCa under certain assumptions. Empirical tests with various image captioning models and large language models show that PoCa consistently yields more informative and semantically aligned captions, maintaining brevity and interpretability.",
    "pdf_link": "https://arxiv.org/abs/2405.00485",
    "graphs": [],
    "abstract_cn": "本研究提出了一个基于信息论的图像字幕生成框架，将其定位为一种表示学习任务，并确立了三个核心目标：确保任务完整性、最小化信息冗余以及增强人类理解性。在此框架之上，我们创新性地提出了金字塔字幕（PoCa）方法，该方法通过为图像的放大区域生成细致的局部字幕，并将其与全局字幕信息相结合，利用大型语言模型来构建一个字幕层级结构。这种方法基于一个洞察：对图像局部区域的深入分析可以降低错误风险，并通过修正错误或补充细节来提高全局字幕的准确性。我们在理论上对这一洞察进行了形式化处理，并在特定条件下为PoCa的有效性提供了严格的证明。实证测试显示，PoCa方法在多种图像字幕模型和大型语言模型上的应用，都能产生信息丰富且语义一致的字幕，同时保证了文本的简洁和易于理解。",
    "title_cn": "标题层级金字塔",
    "tags": [
      "LLM应用",
      "图像处理",
      "人工智能"
    ]
  },
  {
    "title": "BiomedRAG: A Retrieval Augmented Large Language Model for Biomedicine",
    "submit_datetime": "2024年05月01日",
    "abstract": "Large Language Models (LLMs) have swiftly emerged as vital resources for different applications in the biomedical and healthcare domains; however, these models encounter issues such as generating inaccurate information or hallucinations. Retrieval-augmented generation provided a solution for these models to update knowledge and enhance their performance. In contrast to previous retrieval-augmented LMs, which utilize specialized cross-attention mechanisms to help LLM encode retrieved text, BiomedRAG adopts a simpler approach by directly inputting the retrieved chunk-based documents into the LLM. This straightforward design is easily applicable to existing retrieval and language models, effectively bypassing noise information in retrieved documents, particularly in noise-intensive tasks. Moreover, we demonstrate the potential for utilizing the LLM to supervise the retrieval model in the biomedical domain, enabling it to retrieve the document that assists the LM in improving its predictions. Our experiments reveal that with the tuned scorer,\\textsc{ BiomedRAG} attains superior performance across 5 biomedical NLP tasks, encompassing information extraction (triple extraction, relation extraction), text classification, link prediction, and question-answering, leveraging over 9 datasets. For instance, in the triple extraction task, \\textsc{BiomedRAG} outperforms other triple extraction systems with micro-F1 scores of 81.42 and 88.83 on GIT and ChemProt corpora, respectively.",
    "pdf_link": "https://arxiv.org/abs/2405.00465",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）在生物医学和医疗领域的多样化应用中迅速崭露头角，尽管它们有时会生成错误信息或产生幻觉。为了解决这些问题，检索增强生成技术应运而生，帮助模型刷新知识库并提升性能。与以往的检索增强语言模型相比，这些模型通常使用专门的交叉注意力机制来编码检索到的文本，BiomedRAG则采取了更为简洁的方法，直接将检索到的块状文档输入LLM。这种设计简化了现有检索和语言模型的应用，有效过滤了检索文档中的噪声，尤其是在噪声较多的任务中。此外，我们的研究还展示了利用LLM指导生物医学领域检索模型的潜力，以检索出能够辅助LLM提升预测准确度的文档。实验结果显示，在经过调整的评分器辅助下，BiomedRAG在5项生物医学自然语言处理任务上均展现出色的表现，这些任务包括信息抽取（三元组抽取、关系抽取）、文本分类、链接预测和问答，涵盖了9个以上的数据集。以三元组抽取任务为例，BiomedRAG在GIT和ChemProt语料库上的微F1分数分别达到了81.42和88.83，超越了其他同类系统。",
    "title_cn": "BiomedRAG：一种为生物医学领域设计的、结合了检索功能的先进大型语言模型。",
    "tags": [
      "RAG",
      "生物医学",
      ""
    ]
  },
  {
    "title": "Enhancing Surgical Robots with Embodied Intelligence for Autonomous Ultrasound Scanning",
    "submit_datetime": "2024年05月01日",
    "abstract": "Ultrasound robots are increasingly used in medical diagnostics and early disease screening. However, current ultrasound robots lack the intelligence to understand human intentions and instructions, hindering autonomous ultrasound scanning. To solve this problem, we propose a novel Ultrasound Embodied Intelligence system that equips ultrasound robots with the large language model (LLM) and domain knowledge, thereby improving the efficiency of ultrasound robots. Specifically, we first design an ultrasound operation knowledge database to add expertise in ultrasound scanning to the LLM, enabling the LLM to perform precise motion planning. Furthermore, we devise a dynamic ultrasound scanning strategy based on a \\textit{think-observe-execute} prompt engineering, allowing LLMs to dynamically adjust motion planning strategies during the scanning procedures. Extensive experiments demonstrate that our system significantly improves ultrasound scan efficiency and quality from verbal commands. This advancement in autonomous medical scanning technology contributes to non-invasive diagnostics and streamlined medical workflows.",
    "pdf_link": "https://arxiv.org/abs/2405.00461",
    "graphs": [],
    "abstract_cn": "超声机器人在医疗诊断和疾病早期筛查中的应用日益增多。但目前这类机器人尚不能理解人的意图和指令，限制了其在自主超声扫描方面的应用。为此，我们设计了一种创新的超声体现智能系统，通过集成大型语言模型（LLM）和特定领域知识，显著提升了超声机器人的工作效能。该系统首先构建了一个超声操作知识库，赋予LLM超声扫描的专业技能，实现精准的运动规划。同时，我们引入了一种基于“思考-观察-执行”循环的动态扫描策略，使LLM能够根据扫描过程实时优化其规划策略。大量实验证明，该系统能显著提升根据口头指令进行的超声扫描的效率和成像质量，这一技术突破为非侵入性诊断和医疗流程的优化提供了有力支持。",
    "title_cn": "为手术机器人注入体现智能，提升其进行自主超声扫描的性能。",
    "tags": [
      "分类：Agent",
      "",
      "机器人技术"
    ]
  },
  {
    "title": "Monte Carlo Tree Search Boosts Reasoning via Iterative Preference Learning",
    "submit_datetime": "2024年05月01日",
    "abstract": "We introduce an approach aimed at enhancing the reasoning capabilities of Large Language Models (LLMs) through an iterative preference learning process inspired by the successful strategy employed by AlphaZero. Our work leverages Monte Carlo Tree Search (MCTS) to iteratively collect preference data, utilizing its look-ahead ability to break down instance-level rewards into more granular step-level signals. To enhance consistency in intermediate steps, we combine outcome validation and stepwise self-evaluation, continually updating the quality assessment of newly generated data. The proposed algorithm employs Direct Preference Optimization (DPO) to update the LLM policy using this newly generated step-level preference data. Theoretical analysis reveals the critical importance of using on-policy sampled data for successful self-improving. Extensive evaluations on various arithmetic and commonsense reasoning tasks demonstrate remarkable performance improvements over existing models. For instance, our approach outperforms the Mistral-7B Supervised Fine-Tuning (SFT) baseline on GSM8K, MATH, and SciQ, with substantial percentage increases in accuracy to $80.7\\%$ (+$4.8\\%$), $32.2\\%$ (+$3.3\\%$), and $88.5\\%$ (+$7.7\\%$), respectively. Additionally, our research delves into the training and inference compute tradeoff, providing insights into how our method effectively maximizes performance gains.",
    "pdf_link": "https://arxiv.org/abs/2405.00451",
    "graphs": [],
    "abstract_cn": "本文提出了一种新方法，通过模仿 AlphaZero 的迭代偏好学习策略，以提升大型语言模型（LLMs）的推理能力。该方法采用蒙特卡洛树搜索（MCTS）技术，逐步搜集偏好数据，并通过前瞻性分析将奖励细化到每一步，从而增强了处理过程中的连贯性。结合结果验证和分步自我评估，我们不断优化新数据的质量评估。新算法运用直接偏好优化（DPO）技术，根据这些细化的偏好数据来调整 LLMs 的策略。理论分析显示，使用策略内抽样数据对于自我提升至关重要。在多项算术和常识推理任务上的测试表明，该方法相较于现有模型，如 Mistral-7B 监督式微调（SFT）基线，在 GSM8K、MATH 和 SciQ 等任务上均取得了显著的性能提升，准确率分别提升了 4.8%、3.3% 和 7.7%。此外，本研究还探讨了训练与推理计算之间的平衡，揭示了我们的方法如何高效地实现性能最大化。",
    "title_cn": "蒙特卡洛树搜索（MCTS）通过不断迭代的偏好学习，显著提升了推理能力。",
    "tags": [
      "分类：LLM理论",
      "人工智能",
      ""
    ]
  },
  {
    "title": "RAG-based Explainable Prediction of Road Users Behaviors for Automated Driving using Knowledge Graphs and Large Language Models",
    "submit_datetime": "2024年05月01日",
    "abstract": "Prediction of road users' behaviors in the context of autonomous driving has gained considerable attention by the scientific community in the last years. Most works focus on predicting behaviors based on kinematic information alone, a simplification of the reality since road users are humans, and as such they are highly influenced by their surrounding context. In addition, a large plethora of research works rely on powerful Deep Learning techniques, which exhibit high performance metrics in prediction tasks but may lack the ability to fully understand and exploit the contextual semantic information contained in the road scene, not to mention their inability to provide explainable predictions that can be understood by humans. In this work, we propose an explainable road users' behavior prediction system that integrates the reasoning abilities of Knowledge Graphs (KG) and the expressiveness capabilities of Large Language Models (LLM) by using Retrieval Augmented Generation (RAG) techniques. For that purpose, Knowledge Graph Embeddings (KGE) and Bayesian inference are combined to allow the deployment of a fully inductive reasoning system that enables the issuing of predictions that rely on legacy information contained in the graph as well as on current evidence gathered in real time by onboard sensors. Two use cases have been implemented following the proposed approach: 1) Prediction of pedestrians' crossing actions; 2) Prediction of lane change maneuvers. In both cases, the performance attained surpasses the current state of the art in terms of anticipation and F1-score, showing a promising avenue for future research in this field.",
    "pdf_link": "https://arxiv.org/abs/2405.00449",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00449v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00449/figure-manzour.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00449v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00449/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00449v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00449/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00449v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00449/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00449v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00449/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00449v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00449/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00449v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00449/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00449v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00449/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00449v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00449/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00449v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00449/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00449v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00449/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00449v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00449/x11.png"
      }
    ],
    "abstract_cn": "近年来，科学界对自动驾驶环境下道路使用者行为预测的研究兴趣日益浓厚。现有研究多侧重于利用运动学信息进行行为预测，忽略了作为人类的道路使用者受周围环境影响的复杂性。同时，众多研究依赖于深度学习技术，虽然在预测任务上表现优异，但在理解并利用道路场景中的上下文语义信息方面存在不足，且难以提供人类可理解的解释性预测。本研究提出了一种结合知识图谱推理能力和大型语言模型表达能力的可解释道路使用者行为预测系统，采用检索增强生成技术，通过知识图谱嵌入和贝叶斯推断，构建了一个完全归纳的推理系统。该系统能够基于图谱中的既有信息和车载传感器实时收集的当前证据发布预测。研究中实现了两个应用案例：预测行人过街行为和车道变换操作，均在预测准确性和F1分数上超越了当前技术，为该领域未来研究开辟了新的可能性。",
    "title_cn": "利用知识图谱和大型语言模型，基于 RAG（Retrieval-Augmented Generation）框架，对自动驾驶中道路使用者的行为进行可解释预测。",
    "tags": [
      "Agent",
      "自动驾驶",
      "知识图谱"
    ]
  },
  {
    "title": "CultiVerse: Towards Cross-Cultural Understanding for Paintings with Large Language Model",
    "submit_datetime": "2024年05月01日",
    "abstract": "The integration of new technology with cultural studies enhances our understanding of cultural heritage but often struggles to connect with diverse audiences. It is challenging to align personal interpretations with the intended meanings across different cultures. Our study investigates the important factors in appreciating art from a cross-cultural perspective. We explore the application of Large Language Models (LLMs) to bridge the cultural and language barriers in understanding Traditional Chinese Paintings (TCPs). We present CultiVerse, a visual analytics system that utilizes LLMs within a mixed-initiative framework, enhancing interpretative appreciation of TCP in a cross-cultural dialogue. CultiVerse addresses the challenge of translating the nuanced symbolism in art, which involves interpreting complex cultural contexts, aligning cross-cultural symbols, and validating cultural acceptance. CultiVerse integrates an interactive interface with the analytical capability of LLMs to explore a curated TCP dataset, facilitating the analysis of multifaceted symbolic meanings and the exploration of cross-cultural serendipitous discoveries. Empirical evaluations affirm that CultiVerse significantly improves cross-cultural understanding, offering deeper insights and engaging art appreciation.",
    "pdf_link": "https://arxiv.org/abs/2405.00435",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00435v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00435/abstract.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00435v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00435/requirement.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00435v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00435/workflow.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00435v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00435/normdesign.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00435v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00435/case2_1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00435v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00435/case2_2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00435v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00435/EVA.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00435v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00435/insight.png"
      }
    ],
    "abstract_cn": "将尖端科技与文化研究相结合，可以深化我们对文化传承的认识，但要吸引多元受众却非易事。在不同文化背景下，将个人的解读与作品的本意相匹配尤为困难。本研究致力于探究跨文化视角下艺术欣赏的关键要素。我们研究了大型语言模型（LLMs）在跨越文化和语言障碍、增进对中国传统绘画（TCPs）理解方面的潜力。我们介绍了CultiVerse，这是一款视觉分析系统，它采用了混合主动性框架内的LLMs，提升了跨文化交流中对TCP的深入理解。CultiVerse致力于解决艺术作品中细腻象征意义的翻译难题，这包括解读复杂的文化背景、对齐不同文化中的象征元素，并确认文化认同。CultiVerse结合了互动界面与LLMs的分析功能，对精选的TCP数据集进行探索，助力多维度象征意义的分析和跨文化意外发现的探索。实证评估表明，CultiVerse显著提升了跨文化理解能力，为艺术欣赏提供了更深层次的洞察和更具吸引力的体验。",
    "title_cn": "CultiVerse：迈向利用大型语言模型深化对绘画艺术的跨文化洞察。",
    "tags": [
      "分类：LLM应用\n\n这篇论文探讨了大型语言模型（LLMs）在跨文化艺术欣赏中的应用，特别是如何利用LLMs来增进对中国传统绘画（TCPs）的理解。通过引入CultiVerse这一视觉分析系统，该系统采用了混合主动性框架内的LLMs，来解决艺术作品中文化象征意义的翻译难题。这表明了LLMs在跨文化交流和艺术欣赏领域的应用潜力，因此将其归类为LLM应用。",
      "文化研究",
      "艺术欣赏"
    ]
  },
  {
    "title": "Self-Refine Instruction-Tuning for Aligning Reasoning in Language Models",
    "submit_datetime": "2024年05月01日",
    "abstract": "The alignments of reasoning abilities between smaller and larger Language Models are largely conducted via Supervised Fine-Tuning (SFT) using demonstrations generated from robust Large Language Models (LLMs). Although these approaches deliver more performant models, they do not show sufficiently strong generalization ability as the training only relies on the provided demonstrations.\n  In this paper, we propose the Self-refine Instruction-tuning method that elicits Smaller Language Models to self-refine their abilities. Our approach is based on a two-stage process, where reasoning abilities are first transferred between LLMs and Small Language Models (SLMs) via Instruction-tuning on demonstrations provided by LLMs, and then the instructed models Self-refine their abilities through preference optimization strategies. In particular, the second phase operates refinement heuristics based on the Direct Preference Optimization algorithm, where the SLMs are elicited to deliver a series of reasoning paths by automatically sampling the generated responses and providing rewards using ground truths from the LLMs. Results obtained on commonsense and math reasoning tasks show that this approach significantly outperforms Instruction-tuning in both in-domain and out-domain scenarios, aligning the reasoning abilities of Smaller and Larger Language Models.",
    "pdf_link": "https://arxiv.org/abs/2405.00402",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/DPO_new.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/OBQA_in_family.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/PIQA_in_family.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/GSM8K_in_family.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/CSQA_in_family.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/SIQA_in_family.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/MultiArith_in_family.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/legend_in_family.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/OBQA_out_family.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/PIQA_out_family.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/GSM8K_out_family.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/CSQA_out_family.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/SIQA_out_family.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/MultiArith_out_family.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/legend_out_family.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/OBQA_Llama2_7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/CSQA_Llama2_7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/PIQA_Llama2_7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/SIQA_Llama2_7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/OBQA_Llama2_13.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/CSQA_Llama2_13.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/PIQA_Llama2_13.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/SIQA_Llama2_13.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/Legend.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/MATH_in_family.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/MMLU_in_family.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/legend_in_family.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/MATH_out_family.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/MMLU_out_family.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/legend_out_family.png"
      }
    ],
    "abstract_cn": "本文提出了一种自我精炼指令调整方法，旨在激发小型语言模型（SLMs）自主提升其推理能力。该方法采用两阶段流程：首先，通过LLMs提供的示例进行指令调整，将推理能力从大型语言模型（LLMs）迁移至SLMs；其次，经过指令调整的模型通过偏好优化策略进行自我能力提升。特别是在第二阶段，SLMs利用直接偏好优化算法，自动采样生成的响应，并通过LLMs的基准真值来提供奖励，从而生成一系列推理路径。在常识推理和数学推理任务上的实验结果表明，这种方法在领域内和跨领域场景中均显著超越了传统的指令调整方法，有效拉近了小型与大型语言模型在推理能力上的差距。",
    "title_cn": "自我精炼的指令调优：优化语言模型中的推理对齐。",
    "tags": [
      "LLM应用",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Inferring State Machine from the Protocol Implementation via Large Langeuage Model",
    "submit_datetime": "2024年05月01日",
    "abstract": "State machines play a pivotal role in augmenting the efficacy of protocol analyzing to unveil more vulnerabilities. However, the task of inferring state machines from network protocol implementations presents significant challenges. Traditional methods based on dynamic analysis often overlook crucial state transitions due to limited coverage, while static analysis faces difficulties with complex code structures and behaviors. To address these limitations, we propose an innovative state machine inference approach powered by Large Language Models (LLMs). Utilizing text-embedding technology, this method allows LLMs to dissect and analyze the intricacies of protocol implementation code. Through targeted prompt engineering, we systematically identify and infer the underlying state machines. Our evaluation across six protocol implementations demonstrates the method's high efficacy, achieving an accuracy rate exceeding 90% and successfully delineating differences on state machines among various implementations of the same protocol. Importantly, integrating this approach with protocol fuzzing has notably enhanced AFLNet's code coverage by 10% over RFCNLP, showcasing the considerable potential of LLMs in advancing network protocol security analysis. Our proposed method not only marks a significant step forward in accurate state machine inference but also opens new avenues for improving the security and reliability of protocol implementations.",
    "pdf_link": "https://arxiv.org/abs/2405.00393",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00393v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00393/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00393v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00393/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00393v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00393/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00393v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00393/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00393v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00393/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00393v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00393/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00393v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00393/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00393v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00393/x8.png"
      }
    ],
    "abstract_cn": "状态机对于深入挖掘协议中的潜在漏洞至关重要。但要从网络协议的实现中推导出状态机，却是一个充满挑战的任务。传统动态分析方法因覆盖面不足而常常漏掉关键状态转换，静态分析则在复杂的代码结构面前显得力不从心。为克服这些难题，我们引入了一种新颖的状态机推断技术，该技术借助大型语言模型（LLMs）的威力。通过文本嵌入技术，LLMs能够深入剖析协议实现代码的细节。我们通过精心设计的提示策略，系统地识别并推断出隐含的状态机。在六种协议实现上的测试结果表明，该方法极为有效，准确度超过90%，并能成功区分相同协议不同实现之间的状态机差异。更值得一提的是，将此方法与协议模糊测试相结合，使得AFLNet的代码覆盖率比RFCNLP提升了10%，充分证明了LLMs在网络协议安全分析领域的巨大潜力。我们提出的这一方法不仅在精确推断状态机方面取得了显著进展，也为提升协议实现的安全性和可靠性开辟了新的路径。",
    "title_cn": "利用大型语言模型，从协议实现中推导出状态机。",
    "tags": [
      "LLM应用",
      "网络安全",
      "协议分析"
    ]
  },
  {
    "title": "CofiPara: A Coarse-to-fine Paradigm for Multimodal Sarcasm Target Identification with Large Multimodal Models",
    "submit_datetime": "2024年05月01日",
    "abstract": "Social media abounds with multimodal sarcasm, and identifying sarcasm targets is particularly challenging due to the implicit incongruity not directly evident in the text and image modalities. Current methods for Multimodal Sarcasm Target Identification (MSTI) predominantly focus on superficial indicators in an end-to-end manner, overlooking the nuanced understanding of multimodal sarcasm conveyed through both the text and image. This paper proposes a versatile MSTI framework with a coarse-to-fine paradigm, by augmenting sarcasm explainability with reasoning and pre-training knowledge. Inspired by the powerful capacity of Large Multimodal Models (LMMs) on multimodal reasoning, we first engage LMMs to generate competing rationales for coarser-grained pre-training of a small language model on multimodal sarcasm detection. We then propose fine-tuning the model for finer-grained sarcasm target identification. Our framework is thus empowered to adeptly unveil the intricate targets within multimodal sarcasm and mitigate the negative impact posed by potential noise inherently in LMMs. Experimental results demonstrate that our model far outperforms state-of-the-art MSTI methods, and markedly exhibits explainability in deciphering sarcasm as well.",
    "pdf_link": "https://arxiv.org/abs/2405.00390",
    "graphs": [],
    "abstract_cn": "社交媒体上的多模态讽刺层出不穷，识别其目标颇具挑战，因为文本和图像中隐含的不一致性并不明显。现行的多模态讽刺目标识别技术大多只关注表面现象，忽略了对讽刺深层次理解的必要性。本文提出了一种新颖的识别框架，它采用由粗到细的方法，通过增强推理能力和预训练知识来提升讽刺的可解释性。借鉴大型多模态模型在多模态推理上的卓越表现，我们首先利用这些模型为多模态讽刺检测生成初步的竞争性解释，然后对小型语言模型进行微调，以实现更精细的讽刺目标识别。我们的框架能够有效地揭示多模态讽刺中的微妙目标，并减少大型模型中固有噪声的负面影响。实验结果显示，我们的模型在识别多模态讽刺目标方面大大超越了现有的顶尖方法，并且在解释讽刺方面表现出了显著的可解释性。",
    "title_cn": "CofiPara：一种从粗略到精细的多模态讽刺目标识别方法，适用于大型多模态模型。",
    "tags": [
      "分类：LLM应用\n\n这篇论文提出了一种新颖的识别框架，用于识别社交媒体上的多模态讽刺目标。它利用大型多模态模型生成初步的解释，然后对小型语言模型进行微调，以实现更精细的讽刺目标识别。这篇论文的研究重点是提高讽刺目标识别的准确性和可解释性，因此它属于LLM应用类别。",
      "社交媒体分析",
      "人工智能"
    ]
  },
  {
    "title": "AdaMoLE: Fine-Tuning Large Language Models with Adaptive Mixture of Low-Rank Adaptation Experts",
    "submit_datetime": "2024年05月01日",
    "abstract": "We introduce AdaMoLE, a novel method for fine-tuning large language models (LLMs) through an Adaptive Mixture of Low-Rank Adaptation (LoRA) Experts. Moving beyond conventional methods that employ a static top-k strategy for activating experts, AdaMoLE dynamically adjusts the activation threshold using a dedicated threshold network, adaptively responding to the varying complexities of different tasks. By replacing a single LoRA in a layer with multiple LoRA experts and integrating a gating function with the threshold mechanism, AdaMoLE effectively selects and activates the most appropriate experts based on the input context. Our extensive evaluations across a variety of commonsense reasoning and natural language processing tasks show that AdaMoLE exceeds baseline performance. This enhancement highlights the advantages of AdaMoLE's adaptive selection of LoRA experts, improving model effectiveness without a corresponding increase in the expert count. The experimental validation not only confirms AdaMoLE as a robust approach for enhancing LLMs but also suggests valuable directions for future research in adaptive expert selection mechanisms, potentially broadening the scope for optimizing model performance across diverse language processing tasks.",
    "pdf_link": "https://arxiv.org/abs/2405.00361",
    "graphs": [],
    "abstract_cn": "我们推出了 AdaMoLE，这是一种创新的微调大型语言模型（LLM）的方法，它通过自适应的低秩适应（LoRA）专家混合来实现。与传统的静态 top-k 激活策略不同，AdaMoLE 利用专用的阈值网络动态调整激活阈值，以适应多样化任务的复杂性变化。该方法通过在模型层中引入多个 LoRA 专家，并结合门控函数与阈值机制，能够根据输入情境精准地选择并激活最合适的专家。经过我们在多种常识推理和自然语言处理任务上的深入评估，AdaMoLE 的表现超越了传统基线。这一提升凸显了 AdaMoLE 在自适应选择 LoRA 专家方面的优势，它在不增加专家数量的前提下提升了模型效能。实验的验证不仅证明了 AdaMoLE 是一种增强 LLM 的可靠方法，也为未来自适应专家选择机制的研究指明了有价值方向，这可能会为优化各类语言处理任务的模型性能开辟新的可能性。",
    "title_cn": "AdaMoLE：以自适应低秩专家混合策略，对大型语言模型进行精准微调。",
    "tags": [
      "LLM应用",
      "",
      "机器学习"
    ]
  },
  {
    "title": "Exploring Self-Supervised Vision Transformers for Deepfake Detection: A Comparative Analysis",
    "submit_datetime": "2024年05月01日",
    "abstract": "This paper investigates the effectiveness of self-supervised pre-trained transformers compared to supervised pre-trained transformers and conventional neural networks (ConvNets) for detecting various types of deepfakes. We focus on their potential for improved generalization, particularly when training data is limited. Despite the notable success of large vision-language models utilizing transformer architectures in various tasks, including zero-shot and few-shot learning, the deepfake detection community has still shown some reluctance to adopt pre-trained vision transformers (ViTs), especially large ones, as feature extractors. One concern is their perceived excessive capacity, which often demands extensive data, and the resulting suboptimal generalization when training or fine-tuning data is small or less diverse. This contrasts poorly with ConvNets, which have already established themselves as robust feature extractors. Additionally, training and optimizing transformers from scratch requires significant computational resources, making this accessible primarily to large companies and hindering broader investigation within the academic community. Recent advancements in using self-supervised learning (SSL) in transformers, such as DINO and its derivatives, have showcased significant adaptability across diverse vision tasks and possess explicit semantic segmentation capabilities. By leveraging DINO for deepfake detection with modest training data and implementing partial fine-tuning, we observe comparable adaptability to the task and the natural explainability of the detection result via the attention mechanism. Moreover, partial fine-tuning of transformers for deepfake detection offers a more resource-efficient alternative, requiring significantly fewer computational resources.",
    "pdf_link": "https://arxiv.org/abs/2405.00355",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00355v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00355/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00355v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00355/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00355v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00355/x3.png"
      }
    ],
    "abstract_cn": "本研究探讨了自监督预训练变换器在识别各类深度伪造对象时，相较于传统监督预训练变换器和常规神经网络的优势，尤其是在数据训练受限的情况下对泛化能力的提升。尽管变换器架构在视觉-语言模型中的应用已在多项任务中取得了显著成果，包括零样本和少样本学习，但深度伪造检测领域对于采纳预训练视觉变换器，尤其是大型模型，作为特征提取器仍持谨慎态度。主要顾虑在于这些模型的高容量特性，它们通常需要大量数据支持，这在训练数据稀缺或多样性不足时可能导致泛化性能不佳，这与已经证明其鲁棒性的ConvNets形成对比。而且，从头开始训练和优化变换器需要巨大的计算资源，这通常只有大型公司能够承担，限制了学术界的深入研究。然而，自监督学习（SSL）在变换器中的应用，如DINO及其衍生模型，已在多种视觉任务中显示出强大的适应性和语义分割能力。通过采用DINO进行深度伪造检测，并结合适度的训练数据和部分微调策略，我们发现模型能够很好地适应检测任务，并通过注意力机制自然地解释检测结果。此外，对变换器进行部分微调的方法，为深度伪造检测提供了一种更为高效的资源利用方式，显著降低了计算资源的需求。",
    "title_cn": "本研究深入探讨了自监督视觉变换器在深度伪造检测中的应用，并进行了一项全面的比较分析。",
    "tags": [
      "分类：LLM应用",
      "深度伪造检测",
      "自监督学习"
    ]
  },
  {
    "title": "Distillation Matters: Empowering Sequential Recommenders to Match the Performance of Large Language Model",
    "submit_datetime": "2024年05月01日",
    "abstract": "Owing to their powerful semantic reasoning capabilities, Large Language Models (LLMs) have been effectively utilized as recommenders, achieving impressive performance. However, the high inference latency of LLMs significantly restricts their practical deployment. To address this issue, this work investigates knowledge distillation from cumbersome LLM-based recommendation models to lightweight conventional sequential models. It encounters three challenges: 1) the teacher's knowledge may not always be reliable; 2) the capacity gap between the teacher and student makes it difficult for the student to assimilate the teacher's knowledge; 3) divergence in semantic space poses a challenge to distill the knowledge from embeddings. To tackle these challenges, this work proposes a novel distillation strategy, DLLM2Rec, specifically tailored for knowledge distillation from LLM-based recommendation models to conventional sequential models. DLLM2Rec comprises: 1) Importance-aware ranking distillation, which filters reliable and student-friendly knowledge by weighting instances according to teacher confidence and student-teacher consistency; 2) Collaborative embedding distillation integrates knowledge from teacher embeddings with collaborative signals mined from the data. Extensive experiments demonstrate the effectiveness of the proposed DLLM2Rec, boosting three typical sequential models with an average improvement of 47.97%, even enabling them to surpass LLM-based recommenders in some cases.",
    "pdf_link": "https://arxiv.org/abs/2405.00338",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00338v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00338/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00338v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00338/x2.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）凭借其卓越的语义推理能力，在推荐系统中发挥着重要作用，表现出色。但它们的高推理延迟成为了实际应用的瓶颈。为克服这一难题，本研究提出了一种从复杂的LLM推荐模型向传统顺序模型进行知识蒸馏的新方法。这一过程面临三大挑战：教师知识的不稳定性、师生容量差异导致的学习难题，以及语义空间发散性对嵌入知识蒸馏的影响。为此，我们设计了一种创新的蒸馏策略DLLM2Rec，专门用于实现这一转换。DLLM2Rec包含两个核心组件：一是重要性感知排名蒸馏，它通过权衡教师信心和师生一致性来筛选可靠的、适合学生的知识；二是协作嵌入蒸馏，它将教师嵌入的知识与数据中挖掘的协作信号相结合。通过大量实验，我们验证了DLLM2Rec的有效性，它平均提升了三种典型顺序模型性能的47.97%，在某些情况下甚至超过了基于LLM的推荐系统。",
    "title_cn": "蒸馏技术至关重要：它能够提升序列推荐系统的性能，使其达到大型语言模型的水平。",
    "tags": [
      "分类：LLM应用",
      "推荐系统",
      "知识蒸馏"
    ]
  },
  {
    "title": "A Careful Examination of Large Language Model Performance on Grade School Arithmetic",
    "submit_datetime": "2024年05月01日",
    "abstract": "Large language models (LLMs) have achieved impressive success on many benchmarks for mathematical reasoning. However, there is growing concern that some of this performance actually reflects dataset contamination, where data closely resembling benchmark questions leaks into the training data, instead of true reasoning ability. To investigate this claim rigorously, we commission Grade School Math 1000 (GSM1k). GSM1k is designed to mirror the style and complexity of the established GSM8k benchmark, the gold standard for measuring elementary mathematical reasoning. We ensure that the two benchmarks are comparable across important metrics such as human solve rates, number of steps in solution, answer magnitude, and more. When evaluating leading open- and closed-source LLMs on GSM1k, we observe accuracy drops of up to 13%, with several families of models (e.g., Phi and Mistral) showing evidence of systematic overfitting across almost all model sizes. At the same time, many models, especially those on the frontier, (e.g., Gemini/GPT/Claude) show minimal signs of overfitting. Further analysis suggests a positive relationship (Spearman's r^2=0.32) between a model's probability of generating an example from GSM8k and its performance gap between GSM8k and GSM1k, suggesting that many models may have partially memorized GSM8k.",
    "pdf_link": "https://arxiv.org/abs/2405.00332",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00332v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00332/gsm8k_vs_gsm8k_scale_0.0_special_bar.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.00332v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00332/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00332v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00332/answer_cdf.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.00332v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00332/gsm8k_vs_gsm8k_scale_0.0_good.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.00332v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00332/gsm8k_vs_gsm8k_scale_0.0_medium.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.00332v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00332/gsm8k_vs_gsm8k_scale_0.0_bad.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.00332v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00332/ll_graph.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00332v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00332/instructions.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00332v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00332/ll_graph_gsm1k.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00332v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00332/ll_graph_difference.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00332v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00332/gsm8k_vs_gsm8k_scale_0.0_good_bar.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.00332v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00332/gsm8k_vs_gsm8k_scale_0.0_medium_bar.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.00332v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00332/gsm8k_vs_gsm8k_scale_0.0_bad_bar.jpg"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）在数学推理的多项基准测试中取得了显著成就。但人们担忧，这些成绩可能并非真实推理能力的体现，而是由于训练数据中混入了与测试题目极为相似的数据，导致成绩虚高。为了深入探究这一问题，我们推出了Grade School Math 1000（GSM1k）测试。GSM1k在设计上与公认的小学数学推理基准测试GSM8k保持一致，无论是在题型风格还是难度上。我们确保两个测试在解题步骤数量、解答难度等多个关键指标上具有可比性。在对当前主流的开源和闭源LLMs进行GSM1k测试时，我们发现准确率下降了高达13%，部分模型系列（如Phi和Mistral）几乎在所有模型尺寸上都表现出了系统性的过拟合。与此同时，许多前沿模型（如Gemini/GPT/Claude）则几乎没有过拟合的迹象。进一步分析还发现，模型生成GSM8k中题目的概率与其在GSM8k和GSM1k之间性能差异之间存在正相关（Spearman相关系数r^2=0.32），这表明许多模型可能已经部分记忆了GSM8k的题目。",
    "title_cn": "深入剖析大型语言模型在小学算术任务上的表现",
    "tags": [
      "分类：LLM理论",
      "数学教育",
      "人工智能"
    ]
  },
  {
    "title": "Integrating A.I. in Higher Education: Protocol for a Pilot Study with 'SAMCares: An Adaptive Learning Hub'",
    "submit_datetime": "2024年05月01日",
    "abstract": "Learning never ends, and there is no age limit to grow yourself. However, the educational landscape may face challenges in effectively catering to students' inclusion and diverse learning needs. These students should have access to state-of-the-art methods for lecture delivery, online resources, and technology needs. However, with all the diverse learning sources, it becomes harder for students to comprehend a large amount of knowledge in a short period of time. Traditional assistive technologies and learning aids often lack the dynamic adaptability required for individualized education plans. Large Language Models (LLM) have been used in language translation, text summarization, and content generation applications. With rapid growth in AI over the past years, AI-powered chatbots and virtual assistants have been developed. This research aims to bridge this gap by introducing an innovative study buddy we will be calling the 'SAMCares'. The system leverages a Large Language Model (LLM) (in our case, LLaMa-2 70B as the base model) and Retriever-Augmented Generation (RAG) to offer real-time, context-aware, and adaptive educational support. The context of the model will be limited to the knowledge base of Sam Houston State University (SHSU) course notes. The LLM component enables a chat-like environment to interact with it to meet the unique learning requirements of each student. For this, we will build a custom web-based GUI. At the same time, RAG enhances real-time information retrieval and text generation, in turn providing more accurate and context-specific assistance. An option to upload additional study materials in the web GUI is added in case additional knowledge support is required. The system's efficacy will be evaluated through controlled trials and iterative feedback mechanisms.",
    "pdf_link": "https://arxiv.org/abs/2405.00330",
    "graphs": [],
    "abstract_cn": "学无止境，成长不受年龄限制。但教育领域在满足学生的包容性和多样化学习需求方面可能面临挑战。学生们应能接触到最前沿的授课方式、网络资源和技术工具。然而，面对众多的学习资源，学生在短时间内掌握大量知识变得更加困难。传统的辅助技术和学习辅助工具往往缺少为个性化教育计划所需的灵活性。大型语言模型（LLM）已广泛应用于语言翻译、文本摘要和内容生成等场景。随着人工智能技术的迅速发展，AI驱动的聊天机器人和虚拟助手应运而生。本研究致力于通过推出一个名为“SAMCares”的创新学习伙伴来填补这一空白。该系统采用大型语言模型（LLM）——以LLaMa-2 70B为基础模型——结合检索增强生成（RAG）技术，提供实时、情境感知、适应性强的教育支持。系统的知识背景将限定在萨姆休斯顿州立大学（SHSU）的课程笔记中。LLM部分允许学生在一个类似聊天的环境中与其互动，以满足每个学生独特的学习需求。为此，我们将开发一个定制的基于Web的图形用户界面（GUI）。RAG技术则增强了实时信息检索和文本生成能力，从而提供更精确、更具针对性的帮助。此外，Web GUI还提供了上传额外学习材料的选项，以便在需要额外知识支持时使用。系统的有效性将通过对照试验和持续的反馈机制进行验证。",
    "title_cn": "融入人工智能于高等教育：开展“SAMCares：自适应学习平台”试点研究的方案",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "DFKI-NLP at SemEval-2024 Task 2: Towards Robust LLMs Using Data Perturbations and MinMax Training",
    "submit_datetime": "2024年05月01日",
    "abstract": "The NLI4CT task at SemEval-2024 emphasizes the development of robust models for Natural Language Inference on Clinical Trial Reports (CTRs) using large language models (LLMs). This edition introduces interventions specifically targeting the numerical, vocabulary, and semantic aspects of CTRs. Our proposed system harnesses the capabilities of the state-of-the-art Mistral model, complemented by an auxiliary model, to focus on the intricate input space of the NLI4CT dataset. Through the incorporation of numerical and acronym-based perturbations to the data, we train a robust system capable of handling both semantic-altering and numerical contradiction interventions. Our analysis on the dataset sheds light on the challenging sections of the CTRs for reasoning.",
    "pdf_link": "https://arxiv.org/abs/2405.00321",
    "graphs": [],
    "abstract_cn": "SemEval-2024 的 NLI4CT 任务着重于利用大型语言模型（LLMs）为临床试验报告（CTRs）上的自然语言推理（NLI）构建稳健的模型。本版特别关注 CTRs 的数值、词汇和语义特点，并引入了相应的干预措施。我们设计的系统采用了最先进的 Mistral 模型，并结合辅助模型，专注于 NLI4CT 数据集的复杂输入维度。通过在数据中引入数值和首字母缩略词的扰动，我们培养了一个能够应对语义变更和数值矛盾干预的强韧系统。对数据集的深入分析揭示了 CTRs 在推理过程中的难点所在。",
    "title_cn": "DFKI-NLP 团队参与了 SemEval-2024 的第二项任务，旨在通过数据扰动和 MinMax 训练方法，推动构建更加稳健的大型语言模型。",
    "tags": [
      "分类：LLM应用\n\n这篇论文摘要讨论了如何利用大型语言模型（LLMs）来构建一个稳健的模型，以处理临床试验报告（CTRs）上的自然语言推理（NLI）任务。这表明该论文主要关注LLM在特定领域的应用，即在临床试验报告的自然语言处理任务中。因此，这篇论文应该被归类为LLM应用。",
      "临床试验",
      ""
    ]
  },
  {
    "title": "Distance Sampling-based Paraphraser Leveraging ChatGPT for Text Data Manipulation",
    "submit_datetime": "2024年05月01日",
    "abstract": "There has been growing interest in audio-language retrieval research, where the objective is to establish the correlation between audio and text modalities. However, most audio-text paired datasets often lack rich expression of the text data compared to the audio samples. One of the significant challenges facing audio-text datasets is the presence of similar or identical captions despite different audio samples. Therefore, under many-to-one mapping conditions, audio-text datasets lead to poor performance of retrieval tasks. In this paper, we propose a novel approach to tackle the data imbalance problem in audio-language retrieval task. To overcome the limitation, we introduce a method that employs a distance sampling-based paraphraser leveraging ChatGPT, utilizing distance function to generate a controllable distribution of manipulated text data. For a set of sentences with the same context, the distance is used to calculate a degree of manipulation for any two sentences, and ChatGPT's few-shot prompting is performed using a text cluster with a similar distance defined by the Jaccard similarity. Therefore, ChatGPT, when applied to few-shot prompting with text clusters, can adjust the diversity of the manipulated text based on the distance. The proposed approach is shown to significantly enhance performance in audio-text retrieval, outperforming conventional text augmentation techniques.",
    "pdf_link": "https://arxiv.org/abs/2405.00367",
    "graphs": [],
    "abstract_cn": "音频-语言检索领域正受到越来越多的关注，旨在揭示音频与文本之间的联系。尽管如此，现有的音频-文本配对数据集往往在文本表达的丰富性上不及音频样本。一个特别的难题是，不同的音频样本可能伴有相似或完全相同的描述。这导致在多对一的映射情境下，检索任务的表现不尽人意。本文提出了一种创新的方法来应对音频-语言检索中的不平衡数据问题。我们引入了一种基于距离采样的释义技术，结合ChatGPT，通过距离函数来生成可控的文本数据分布。对于一组具有相同语境的句子，利用距离来衡量句子间的修改程度，并采用Jaccard相似性定义的相似距离的文本集进行ChatGPT的少量示例提示。这样，ChatGPT在进行少量示例提示时，能够根据距离来调节文本的多样性。实验结果表明，我们的方法显著提升了音频-文本检索的效果，超越了传统的文本增强方法。",
    "title_cn": "利用 ChatGPT 的距离抽样技术，打造文本数据的释义神器。",
    "tags": [
      "分类：LLM应用",
      "音频检索",
      ""
    ]
  },
  {
    "title": "Context-Aware Clustering using Large Language Models",
    "submit_datetime": "2024年05月01日",
    "abstract": "Despite the remarkable success of Large Language Models (LLMs) in text understanding and generation, their potential for text clustering tasks remains underexplored. We observed that powerful closed-source LLMs provide good quality clusterings of entity sets but are not scalable due to the massive compute power required and the associated costs. Thus, we propose CACTUS (Context-Aware ClusTering with aUgmented triplet losS), a systematic approach that leverages open-source LLMs for efficient and effective supervised clustering of entity subsets, particularly focusing on text-based entities. Existing text clustering methods fail to effectively capture the context provided by the entity subset. Moreover, though there are several language modeling based approaches for clustering, very few are designed for the task of supervised clustering. This paper introduces a novel approach towards clustering entity subsets using LLMs by capturing context via a scalable inter-entity attention mechanism. We propose a novel augmented triplet loss function tailored for supervised clustering, which addresses the inherent challenges of directly applying the triplet loss to this problem. Furthermore, we introduce a self-supervised clustering task based on text augmentation techniques to improve the generalization of our model. For evaluation, we collect ground truth clusterings from a closed-source LLM and transfer this knowledge to an open-source LLM under the supervised clustering framework, allowing a faster and cheaper open-source model to perform the same task. Experiments on various e-commerce query and product clustering datasets demonstrate that our proposed approach significantly outperforms existing unsupervised and supervised baselines under various external clustering evaluation metrics.",
    "pdf_link": "https://arxiv.org/abs/2405.00988",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）在文本理解和生成方面取得了显著成就，但其在文本聚类任务中的应用尚未充分挖掘。我们发现，尽管闭源LLMs能够为实体集合提供优秀的聚类效果，但由于计算资源的庞大需求和成本问题，它们的应用并不具备可扩展性。为此，我们提出了CACTUS——一种创新的系统化方法，它利用开源LLMs来高效执行实体子集的监督聚类，尤其针对基于文本的实体。传统的文本聚类技术往往忽略了实体子集所提供的上下文信息。此外，尽管存在一些基于语言模型的聚类方法，但专为监督聚类任务设计的方法却寥寥无几。本文提出了一种新颖的聚类方法，通过LLMs捕获上下文，并通过一种可扩展的实体间注意力机制实现。我们设计了一种新的增强型三重损失函数，专为监督聚类量身定制，以应对直接应用三重损失函数于此问题的固有难题。同时，我们引入了一种基于文本增强技术的自监督聚类任务，旨在提升模型的泛化性能。在评估过程中，我们从闭源LLM中获取了基准聚类数据，并将这些信息转移到开源LLM中，实现了在监督聚类框架下，使用更快速、成本更低的开源模型来执行相同任务。我们在多个电子商务查询和产品聚类数据集上进行的实验证明，我们的方法在多个外部聚类评估指标上显著超越了现有的无监督和监督基线方法。",
    "title_cn": "本文探讨了利用大型语言模型进行上下文感知聚类的方法。",
    "tags": [
      "LLM应用",
      "文本聚类",
      "电子商务"
    ]
  },
  {
    "title": "LLM-AD: Large Language Model based Audio Description System",
    "submit_datetime": "2024年05月01日",
    "abstract": "The development of Audio Description (AD) has been a pivotal step forward in making video content more accessible and inclusive. Traditionally, AD production has demanded a considerable amount of skilled labor, while existing automated approaches still necessitate extensive training to integrate multimodal inputs and tailor the output from a captioning style to an AD style. In this paper, we introduce an automated AD generation pipeline that harnesses the potent multimodal and instruction-following capacities of GPT-4V(ision). Notably, our methodology employs readily available components, eliminating the need for additional training. It produces ADs that not only comply with established natural language AD production standards but also maintain contextually consistent character information across frames, courtesy of a tracking-based character recognition module. A thorough analysis on the MAD dataset reveals that our approach achieves a performance on par with learning-based methods in automated AD production, as substantiated by a CIDEr score of 20.5.",
    "pdf_link": "https://arxiv.org/abs/2405.00983",
    "graphs": [],
    "abstract_cn": "音频描述（AD）的进步极大提升了视频内容的可访问性和包容性。传统AD制作依赖大量专业劳动力，而自动化方案则需大量训练以融合多模态信息，将字幕风格转化为AD风格。本文提出了一个自动化AD生成流程，该流程充分发挥了GPT-4V（视觉）在多模态处理和指令执行方面的强大功能。我们的方法使用了易于获取的组件，避免了额外训练的需要。它生成的AD不仅遵循了标准的自然语言AD制作规范，还通过追踪式角色识别模块，在不同帧之间保持了角色信息的上下文一致性。在MAD数据集上的深入分析显示，我们的方法在自动化AD生产中的表现与基于学习的方法相当，CIDEr得分达到20.5，证明了其效果。",
    "title_cn": "LLM-AD：一种依托于先进大型语言模型的音频描述解决方案",
    "tags": [
      "LLM应用",
      "视频内容制作",
      "自动化系统"
    ]
  },
  {
    "title": "On the Evaluation of Machine-Generated Reports",
    "submit_datetime": "2024年05月01日",
    "abstract": "Large Language Models (LLMs) have enabled new ways to satisfy information needs. Although great strides have been made in applying them to settings like document ranking and short-form text generation, they still struggle to compose complete, accurate, and verifiable long-form reports. Reports with these qualities are necessary to satisfy the complex, nuanced, or multi-faceted information needs of users. In this perspective paper, we draw together opinions from industry and academia, and from a variety of related research areas, to present our vision for automatic report generation, and -- critically -- a flexible framework by which such reports can be evaluated. In contrast with other summarization tasks, automatic report generation starts with a detailed description of an information need, stating the necessary background, requirements, and scope of the report. Further, the generated reports should be complete, accurate, and verifiable. These qualities, which are desirable -- if not required -- in many analytic report-writing settings, require rethinking how to build and evaluate systems that exhibit these qualities. To foster new efforts in building these systems, we present an evaluation framework that draws on ideas found in various evaluations. To test completeness and accuracy, the framework uses nuggets of information, expressed as questions and answers, that need to be part of any high-quality generated report. Additionally, evaluation of citations that map claims made in the report to their source documents ensures verifiability.",
    "pdf_link": "https://arxiv.org/abs/2405.00982",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）为满足信息需求开辟了新路径。尽管在文档排序和短文本生成等方面已取得显著进展，但它们在撰写全面、精确且可查证的长篇报告方面仍面临挑战。这类报告对于满足用户复杂、细致或多维度的信息需求至关重要。本文集思广益，汇聚了业界和学界的声音，以及多个相关研究领域的见解，旨在展现我们对自动化报告生成的展望，并提出了一个关键的灵活框架，用于评估此类报告。与常见的摘要任务相比，自动化报告生成始于对信息需求的详尽描述，阐明报告所需的背景、需求和范围。生成的报告不仅要全面、准确，还要可查证。这些特性在众多分析报告撰写场景中极为重要，甚至不可或缺，这要求我们重新思考构建和评估具备这些特性的系统的方法。为了激励构建这类系统的新尝试，我们提出了一个评估框架，该框架融合了多种评估理念。框架通过问题和答案形式的信息要点来测试报告的完整性和准确性，这些要点是任何优质生成报告不可或缺的部分。此外，通过评估报告中声明与来源文档相映射的引用，确保了报告的可查证性。",
    "title_cn": "机器生成报告评估研究",
    "tags": [
      "LLM应用",
      "信息检索",
      "自动化报告生成"
    ]
  },
  {
    "title": "Bayesian Optimization with LLM-Based Acquisition Functions for Natural Language Preference Elicitation",
    "submit_datetime": "2024年05月01日",
    "abstract": "Designing preference elicitation (PE) methodologies that can quickly ascertain a user's top item preferences in a cold-start setting is a key challenge for building effective and personalized conversational recommendation (ConvRec) systems. While large language models (LLMs) constitute a novel technology that enables fully natural language (NL) PE dialogues, we hypothesize that monolithic LLM NL-PE approaches lack the multi-turn, decision-theoretic reasoning required to effectively balance the NL exploration and exploitation of user preferences towards an arbitrary item set. In contrast, traditional Bayesian optimization PE methods define theoretically optimal PE strategies, but fail to use NL item descriptions or generate NL queries, unrealistically assuming users can express preferences with direct item ratings and comparisons. To overcome the limitations of both approaches, we formulate NL-PE in a Bayesian Optimization (BO) framework that seeks to generate NL queries which actively elicit natural language feedback to reduce uncertainty over item utilities to identify the best recommendation. We demonstrate our framework in a novel NL-PE algorithm, PEBOL, which uses Natural Language Inference (NLI) between user preference utterances and NL item descriptions to maintain preference beliefs and BO strategies such as Thompson Sampling (TS) and Upper Confidence Bound (UCB) to guide LLM query generation. We numerically evaluate our methods in controlled experiments, finding that PEBOL achieves up to 131% improvement in MAP@10 after 10 turns of cold start NL-PE dialogue compared to monolithic GPT-3.5, despite relying on a much smaller 400M parameter NLI model for preference inference.",
    "pdf_link": "https://arxiv.org/abs/2405.00981",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00981v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00981/beta_conversation_v8.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00981v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00981/llmpe_diagram_v7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00981v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00981/combined_dialogue_v13.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00981v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00981/noise0_map_plot_flat.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00981v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00981/noise0_map_plot_others_flat.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00981v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00981/mnli_temp0.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00981v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00981/history.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00981v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00981/noise_results_grouped.png"
      }
    ],
    "abstract_cn": "为了构建高效且个性化的对话式推荐系统，快速识别用户在冷启动情境下的首要偏好是一项重大挑战。大型语言模型（LLMs）开启了全自然语言（NL）偏好激发（PE）对话的新篇章，但我们推测，这种单一的LLM NL-PE方法在进行多轮决策理论推理时存在不足，难以有效平衡对用户偏好的探索与利用。而传统的贝叶斯优化PE方法虽然理论上最优，却未能利用自然语言描述或生成查询，且不切实际地假定用户能够直接通过评分和比较来表达偏好。为了克服这些方法的不足，我们提出了一个基于贝叶斯优化（BO）框架的NL-PE方法，旨在生成能够激发自然语言反馈的查询，以降低对项目效用不确定性的评估，从而精准推荐最佳选项。我们的新算法PEBOL，采用了自然语言推理（NLI）技术，以维持用户偏好信念，并结合Thompson Sampling（TS）和上置信界限（UCB）等BO策略，指导LLM生成查询。在受控实验中，我们的方法在10轮冷启动NL-PE对话后，相较于单一的GPT-3.5，MAP@10的性能提升了131%，尽管我们使用的是基于400M参数的小型NLI模型来进行偏好推断。",
    "title_cn": "利用基于大型语言模型的贝叶斯优化及获取函数，进行自然语言偏好的探索与激发。",
    "tags": [
      "LLM应用",
      "对话系统",
      "推荐系统"
    ]
  },
  {
    "title": "A Hong Kong Sign Language Corpus Collected from Sign-interpreted TV News",
    "submit_datetime": "2024年05月01日",
    "abstract": "This paper introduces TVB-HKSL-News, a new Hong Kong sign language (HKSL) dataset collected from a TV news program over a period of 7 months. The dataset is collected to enrich resources for HKSL and support research in large-vocabulary continuous sign language recognition (SLR) and translation (SLT). It consists of 16.07 hours of sign videos of two signers with a vocabulary of 6,515 glosses (for SLR) and 2,850 Chinese characters or 18K Chinese words (for SLT). One signer has 11.66 hours of sign videos and the other has 4.41 hours. One objective in building the dataset is to support the investigation of how well large-vocabulary continuous sign language recognition/translation can be done for a single signer given a (relatively) large amount of his/her training data, which could potentially lead to the development of new modeling methods. Besides, most parts of the data collection pipeline are automated with little human intervention; we believe that our collection method can be scaled up to collect more sign language data easily for SLT in the future for any sign languages if such sign-interpreted videos are available. We also run a SOTA SLR/SLT model on the dataset and get a baseline SLR word error rate of 34.08% and a baseline SLT BLEU-4 score of 23.58 for benchmarking future research on the dataset.",
    "pdf_link": "https://arxiv.org/abs/2405.00980",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00980v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00980/news.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00980v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00980/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00980v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00980/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00980v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00980/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00980v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00980/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00980v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00980/x5.png"
      }
    ],
    "abstract_cn": "本研究提出了 TVB-HKSL-News，这是一个全新的香港手语（HKSL）数据集，搜集自为期七个月的电视新闻节目。该数据集旨在扩充 HKSL 的资源库，并推动大词汇量连续手语识别（SLR）及翻译（SLT）研究的发展。数据集包含两位手语者共16.07小时的手语视频，涵盖了6,515个术语（用于 SLR）和2,850个中文字符或18K个中文词汇（用于 SLT）。其中一位手语者的视频时长为11.66小时，另一位为4.41小时。构建此数据集的目的之一是探究在拥有大量训练数据的情况下，单一手语者的大词汇量连续手语识别/翻译的效果如何，这可能促成新建模方法的诞生。此外，数据收集流程的大部分已实现自动化，减少了人为干预。我们认为，这种收集方法未来可以扩展，以便为任何手语的 SLT 轻松收集更多数据，只要有相应的手语翻译视频资源。我们还在此数据集上测试了业界领先的 SLR/SLT 模型，得出了 SLR 词汇错误率34.08%和 SLT BLEU-4 分数23.58的基线结果，为未来在此数据集上的研究方向提供了基准。",
    "title_cn": "香港手语语料库：源自电视手语新闻的采集",
    "tags": [
      "Agent",
      "手语识别",
      "机器翻译"
    ]
  },
  {
    "title": "CACTUS: Chemistry Agent Connecting Tool-Usage to Science",
    "submit_datetime": "2024年05月01日",
    "abstract": "Large language models (LLMs) have shown remarkable potential in various domains, but they often lack the ability to access and reason over domain-specific knowledge and tools. In this paper, we introduced CACTUS (Chemistry Agent Connecting Tool-Usage to Science), an LLM-based agent that integrates cheminformatics tools to enable advanced reasoning and problem-solving in chemistry and molecular discovery. We evaluate the performance of CACTUS using a diverse set of open-source LLMs, including Gemma-7b, Falcon-7b, MPT-7b, Llama2-7b, and Mistral-7b, on a benchmark of thousands of chemistry questions. Our results demonstrate that CACTUS significantly outperforms baseline LLMs, with the Gemma-7b and Mistral-7b models achieving the highest accuracy regardless of the prompting strategy used. Moreover, we explore the impact of domain-specific prompting and hardware configurations on model performance, highlighting the importance of prompt engineering and the potential for deploying smaller models on consumer-grade hardware without significant loss in accuracy. By combining the cognitive capabilities of open-source LLMs with domain-specific tools, CACTUS can assist researchers in tasks such as molecular property prediction, similarity searching, and drug-likeness assessment. Furthermore, CACTUS represents a significant milestone in the field of cheminformatics, offering an adaptable tool for researchers engaged in chemistry and molecular discovery. By integrating the strengths of open-source LLMs with domain-specific tools, CACTUS has the potential to accelerate scientific advancement and unlock new frontiers in the exploration of novel, effective, and safe therapeutic candidates, catalysts, and materials. Moreover, CACTUS's ability to integrate with automated experimentation platforms and make data-driven decisions in real time opens up new possibilities for autonomous discovery.",
    "pdf_link": "https://arxiv.org/abs/2405.00972",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）在众多领域展现出巨大潜力，但它们往往难以获取和推理特定领域的知识与工具。本文提出了 CACTUS（Chemistry Agent Connecting Tool-Usage to Science），这是一款集成了化学信息学工具的基于 LLM 的智能代理，旨在提升化学和分子探索领域的高级推理与问题解决能力。我们采用了包括 Gemma-7b、Falcon-7b、MPT-7b、Llama2-7b 和 Mistral-7b 在内的多种开源 LLMs，对数千个化学问题进行了基准测试，以评估 CACTUS 的性能。测试结果显示，CACTUS 在性能上显著超越了基础 LLMs，尤其是 Gemma-7b 和 Mistral-7b 模型，在不同提示策略下均达到了最高准确率。此外，我们还研究了领域特定提示和硬件配置对模型性能的影响，突显了提示工程的重要性以及在消费级硬件上部署小型模型的潜力，而不会显著损失准确性。CACTUS 结合了开源 LLMs 的认知能力与领域特定工具，能够助力研究人员在分子属性预测、相似性搜索和药物相似性评估等任务中取得进展。CACTUS 在化学信息学领域是一个重要的里程碑，为化学和分子发现领域的研究者提供了一个灵活的工具。它通过整合开源 LLMs 的优势与领域特定工具，有望推动科学发展，开拓新的研究领域，探索新的、有效的和安全的治疗方案、催化剂和材料。CACTUS 还能够与自动化实验平台整合，并实时做出基于数据的决策，为自动化发现开辟了新的可能性。",
    "title_cn": "CACTUS：化学智能代理与科学工具的连接平台",
    "tags": [
      "Agent",
      "",
      "人工智能"
    ]
  },
  {
    "title": "How Can I Get It Right? Using GPT to Rephrase Incorrect Trainee Responses",
    "submit_datetime": "2024年05月01日",
    "abstract": "One-on-one tutoring is widely acknowledged as an effective instructional method, conditioned on qualified tutors. However, the high demand for qualified tutors remains a challenge, often necessitating the training of novice tutors (i.e., trainees) to ensure effective tutoring. Research suggests that providing timely explanatory feedback can facilitate the training process for trainees. However, it presents challenges due to the time-consuming nature of assessing trainee performance by human experts. Inspired by the recent advancements of large language models (LLMs), our study employed the GPT-4 model to build an explanatory feedback system. This system identifies trainees' responses in binary form (i.e., correct/incorrect) and automatically provides template-based feedback with responses appropriately rephrased by the GPT-4 model. We conducted our study on 410 responses from trainees across three training lessons: Giving Effective Praise, Reacting to Errors, and Determining What Students Know. Our findings indicate that: 1) using a few-shot approach, the GPT-4 model effectively identifies correct/incorrect trainees' responses from three training lessons with an average F1 score of 0.84 and an AUC score of 0.85; and 2) using the few-shot approach, the GPT-4 model adeptly rephrases incorrect trainees' responses into desired responses, achieving performance comparable to that of human experts.",
    "pdf_link": "https://arxiv.org/abs/2405.00970",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00970v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00970/Scenario.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00970v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00970/feedback.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00970v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00970/praise.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00970v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00970/errors.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00970v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00970/knows.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00970v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00970/dimension_plot.png"
      }
    ],
    "abstract_cn": "一对一辅导因其高效而备受推崇，但合格导师的紧缺成了一大难题，这就需要培训新手导师以保障教学质量。研究指出，及时的解释性反馈有助于加速学员的成长，但专家评估的繁琐过程却是个不小的挑战。本研究借鉴了大型语言模型（LLMs）的最新进展，利用GPT-4模型开发了一个自动化的解释性反馈系统。该系统能够识别学员的二元回答（正确或错误），并自动提供基于模板的反馈，同时由GPT-4模型对回答进行恰当的改写。我们对三个培训环节——有效表扬、错误反应、了解学生知识——中的410个学员回答进行了分析。研究结果显示：1）采用少量样本方法，GPT-4模型在识别三个培训环节中学员回答的正确与否上表现出色，平均F1得分达到0.84，AUC得分为0.85；2）同样使用少量样本方法，GPT-4模型能够巧妙地将错误的学员回答改写为期望的回答，其表现与人类专家不相上下。",
    "title_cn": "如何正确表达？利用 GPT 对实习生的不准确回答进行改写。",
    "tags": [
      "LLM应用",
      "",
      "自动化反馈系统"
    ]
  },
  {
    "title": "Efficient Compression of Multitask Multilingual Speech Models",
    "submit_datetime": "2024年05月01日",
    "abstract": "Whisper is a multitask and multilingual speech model covering 99 languages. It yields commendable automatic speech recognition (ASR) results in a subset of its covered languages, but the model still underperforms on a non-negligible number of under-represented languages, a problem exacerbated in smaller model versions. In this work, we examine its limitations, demonstrating the presence of speaker-related (gender, age) and model-related (resourcefulness and model size) bias. Despite that, we show that only model-related bias are amplified by quantization, impacting more low-resource languages and smaller models. Searching for a better compression approach, we propose DistilWhisper, an approach that is able to bridge the performance gap in ASR for these languages while retaining the advantages of multitask and multilingual capabilities. Our approach involves two key strategies: lightweight modular ASR fine-tuning of whisper-small using language-specific experts, and knowledge distillation from whisper-large-v2. This dual approach allows us to effectively boost ASR performance while keeping the robustness inherited from the multitask and multilingual pre-training. Results demonstrate that our approach is more effective than standard fine-tuning or LoRA adapters, boosting performance in the targeted languages for both in- and out-of-domain test sets, while introducing only a negligible parameter overhead at inference.",
    "pdf_link": "https://arxiv.org/abs/2405.00966",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00966v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00966/x2.png"
      }
    ],
    "abstract_cn": "Whisper，一个涵盖99种语言的多任务多语言语音识别模型，在某些语言上展现了卓越的自动语音识别（ASR）成果。然而，它在一些少数语言上的表现仍有提升空间，尤其是在模型的小型化版本中。本研究深入探讨了其局限性，揭示了与说话者（如性别、年龄）和模型（如资源配置和尺寸）相关的偏见。尽管存在这些偏见，我们发现仅有模型相关的偏见会在量化过程中被放大，对资源匮乏的语言和小型模型影响更大。为了寻求更佳的压缩技术，我们提出了DistilWhisper方法，旨在提升这些语言的ASR性能，同时保持多任务多语言的优势。该方法包括两个核心策略：一是针对特定语言的专家对小型化的Whisper模型进行轻量级模块化微调；二是从大型Whisper模型中提取知识进行蒸馏。这种双管齐下的方法不仅有效提升了ASR性能，还保持了多任务多语言预训练的鲁棒性。实验结果证明，相较于传统的微调或LoRA适配器，我们的方法在目标语言的测试集上，无论是在领域内还是领域外，都显著提升了性能，同时在推理时几乎不增加参数负担。",
    "title_cn": "本文介绍了一种高效的多任务多语言语音模型压缩技术，旨在优化模型的存储和计算效率。",
    "tags": [
      "分类：LLM应用",
      "语音识别",
      "自动语音识别"
    ]
  },
  {
    "title": "The Role of Model Architecture and Scale in Predicting Molecular Properties: Insights from Fine-Tuning RoBERTa, BART, and LLaMA",
    "submit_datetime": "2024年05月01日",
    "abstract": "This study introduces a systematic framework to compare the efficacy of Large Language Models (LLMs) for fine-tuning across various cheminformatics tasks. Employing a uniform training methodology, we assessed three well-known models-RoBERTa, BART, and LLaMA-on their ability to predict molecular properties using the Simplified Molecular Input Line Entry System (SMILES) as a universal molecular representation format. Our comparative analysis involved pre-training 18 configurations of these models, with varying parameter sizes and dataset scales, followed by fine-tuning them on six benchmarking tasks from DeepChem. We maintained consistent training environments across models to ensure reliable comparisons. This approach allowed us to assess the influence of model type, size, and training dataset size on model performance. Specifically, we found that LLaMA-based models generally offered the lowest validation loss, suggesting their superior adaptability across tasks and scales. However, we observed that absolute validation loss is not a definitive indicator of model performance - contradicts previous research - at least for fine-tuning tasks: instead, model size plays a crucial role. Through rigorous replication and validation, involving multiple training and fine-tuning cycles, our study not only delineates the strengths and limitations of each model type but also provides a robust methodology for selecting the most suitable LLM for specific cheminformatics applications. This research underscores the importance of considering model architecture and dataset characteristics in deploying AI for molecular property prediction, paving the way for more informed and effective utilization of AI in drug discovery and related fields.",
    "pdf_link": "https://arxiv.org/abs/2405.00949",
    "graphs": [],
    "abstract_cn": "本研究建立了一套系统框架，旨在对比不同大型语言模型（LLM）在化学信息学任务微调中的效能。我们采用统一的训练策略，对RoBERTa、BART和LLaMA三款知名模型进行了评估，考察它们利用简化分子输入行条目系统（SMILES）这一通用分子表示格式来预测分子属性的能力。通过预训练这些模型的18种不同配置，并在DeepChem的六个基准任务上进行微调，我们进行了深入的比较分析。为确保比较的可靠性，我们在所有模型间保持了一致的训练环境。我们的研究揭示了模型类型、规模和训练数据集大小对性能的影响。特别是，基于LLaMA的模型在验证损失上普遍表现最佳，显示出其在不同任务和规模上的卓越适应性。然而，我们发现验证损失的绝对值并非模型性能的决定性指标，这与先前的研究相矛盾，至少在微调任务中，模型大小才是关键因素。通过严格的重复和验证，包括多轮训练和微调，本研究不仅清晰地展示了各模型的优势与局限，还为特定化学信息学应用选择最合适的LLM提供了一种稳固的方法论。本研究强调了在将AI应用于分子属性预测时，考虑模型架构和数据集特性的重要性，为AI在药物发现等相关领域的更明智和有效应用奠定了基础。",
    "title_cn": "探讨模型架构和规模对于分子属性预测的影响：通过对 RoBERTa、BART 和 LLaMA 进行微调获得的深刻见解。",
    "tags": [
      "LLM应用",
      "化学信息学",
      "药物发现"
    ]
  },
  {
    "title": "LLaVA Finds Free Lunch: Teaching Human Behavior Improves Content Understanding Abilities Of LLMs",
    "submit_datetime": "2024年05月01日",
    "abstract": "Communication is defined as ``Who says what to whom with what effect.'' A message from a communicator generates downstream receiver effects, also known as behavior. Receiver behavior, being a downstream effect of the message, carries rich signals about it. Even after carrying signals about the message, the behavior data is often ignored while training large language models. We show that training LLMs on receiver behavior can actually help improve their content-understanding abilities. Specifically, we show that training LLMs to predict the receiver behavior of likes and comments improves the LLM's performance on a wide variety of downstream content understanding tasks. We show this performance increase over 40 video and image understanding tasks over 23 benchmark datasets across both 0-shot and fine-tuning settings, outperforming many supervised baselines. Moreover, since receiver behavior, such as likes and comments, is collected by default on the internet and does not need any human annotations to be useful, the performance improvement we get after training on this data is essentially free-lunch. We release the receiver behavior cleaned comments and likes of 750k images and videos collected from multiple platforms along with our instruction-tuning data.",
    "pdf_link": "https://arxiv.org/abs/2405.00942",
    "graphs": [],
    "abstract_cn": "通信即是“谁向谁传达了什么信息，产生了何种影响”。信息发送者的消息会在接收者端引发连锁反应，即行为。这些行为作为信息传递的结果，蕴含了丰富的信号。尽管如此，行为数据在大型语言模型的训练过程中常被忽视。本研究揭示，基于接收者行为对大型语言模型进行训练可以有效提升其对内容的理解力。具体而言，我们发现通过训练模型预测点赞和评论等接收者行为，能够显著提高其在多种下游内容理解任务上的表现。这一提升在23个基准数据集上的40个视频和图像理解任务中得到了验证，无论是零样本还是微调场景，均超越了众多监督学习基线。更重要的是，点赞和评论等接收者行为在互联网上自动收集，无需人工标注即可发挥作用，因此，利用这些数据进行训练所带来的性能提升可谓是意外的收获。我们还公开了从多个平台收集的750k图像和视频的接收者行为数据，包括清理后的评论和点赞，以及我们的指令调整数据集。",
    "title_cn": "LLaVA 揭示了一个意外的收获：通过教授人类行为，我们能够显著提升大型语言模型对内容的理解力。",
    "tags": [
      "LLM应用",
      "",
      "机器学习"
    ]
  },
  {
    "title": "Characterising the Creative Process in Humans and Large Language Models",
    "submit_datetime": "2024年05月01日",
    "abstract": "Large language models appear quite creative, often performing on par with the average human on creative tasks. However, research on LLM creativity has focused solely on \\textit{products}, with little attention on the creative \\textit{process}. Process analyses of human creativity often require hand-coded categories or exploit response times, which do not apply to LLMs. We provide an automated method to characterise how humans and LLMs explore semantic spaces on the Alternate Uses Task, and contrast with behaviour in a Verbal Fluency Task. We use sentence embeddings to identify response categories and compute semantic similarities, which we use to generate jump profiles. Our results corroborate earlier work in humans reporting both persistent (deep search in few semantic spaces) and flexible (broad search across multiple semantic spaces) pathways to creativity, where both pathways lead to similar creativity scores. LLMs were found to be biased towards either persistent or flexible paths, that varied across tasks. Though LLMs as a population match human profiles, their relationship with creativity is different, where the more flexible models score higher on creativity. Our dataset and scripts are available on \\href{https://github.com/surabhisnath/Creative_Process}{GitHub}.",
    "pdf_link": "https://arxiv.org/abs/2405.00899",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLM）在创意任务上的表现可与人类媲美，展现出相当的创造力。但目前对LLM创造力的研究主要集中在成果上，对于创造过程的探究却鲜有涉足。传统的人类创造力过程分析依赖于手工分类或反应时间，这些方法对于LLM并不适用。本研究提出了一种自动化方法，用以分析人类和LLM在“替代用途任务”中如何探索语义空间，并将其与“言语流畅性任务”中的行为相比较。通过句子嵌入技术，我们识别了响应类别并计算了语义相似度，进而生成了跳跃轮廓图。研究结果支持了此前对人类创造力路径的发现，即存在深度探索少数语义空间的持久性路径和广泛搜索多个语义空间的灵活性路径，两者都能带来相似的创造力得分。LLM在不同任务中表现出对持久性或灵活性路径的偏好，且与人类的创造力轮廓相比，LLM表现出不同的创造力关联性，其中灵活性更高的模型在创造力评分上更为突出。我们的数据库和脚本已在GitHub上公开。GitHub链接：[Creative_Process](https://github.com/surabhisnath/Creative_Process)",
    "title_cn": "探索人类与大型语言模型的创意生成过程",
    "tags": [
      "LLM应用",
      "创意设计",
      "人工智能"
    ]
  },
  {
    "title": "Beyond Human Vision: The Role of Large Vision Language Models in Microscope Image Analysis",
    "submit_datetime": "2024年05月01日",
    "abstract": "Vision language models (VLMs) have recently emerged and gained the spotlight for their ability to comprehend the dual modality of image and textual data. VLMs such as LLaVA, ChatGPT-4, and Gemini have recently shown impressive performance on tasks such as natural image captioning, visual question answering (VQA), and spatial reasoning. Additionally, a universal segmentation model by Meta AI, Segment Anything Model (SAM) shows unprecedented performance at isolating objects from unforeseen images. Since medical experts, biologists, and materials scientists routinely examine microscopy or medical images in conjunction with textual information in the form of captions, literature, or reports, and draw conclusions of great importance and merit, it is indubitably essential to test the performance of VLMs and foundation models such as SAM, on these images. In this study, we charge ChatGPT, LLaVA, Gemini, and SAM with classification, segmentation, counting, and VQA tasks on a variety of microscopy images. We observe that ChatGPT and Gemini are impressively able to comprehend the visual features in microscopy images, while SAM is quite capable at isolating artefacts in a general sense. However, the performance is not close to that of a domain expert - the models are readily encumbered by the introduction of impurities, defects, artefact overlaps and diversity present in the images.",
    "pdf_link": "https://arxiv.org/abs/2405.00876",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00876v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00876/Figure_illustration.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00876v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00876/Figure_datasets.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00876v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00876/Figure_chatgpt_scale_bar.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00876v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00876/Figure_classification.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00876v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00876/Figure_dice_scores.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00876v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00876/Figure_diff_images.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00876v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00876/Figure_segmentation_qualitative.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00876v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00876/Figure_counts_sampled.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00876v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00876/Figure_counts_full.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00876v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00876/Figure_vqa_1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00876v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00876/Figure_vqa_2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00876v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00876/Figure_vqa_3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00876v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00876/Figure_vqa_4.png"
      }
    ],
    "abstract_cn": "视觉语言模型（VLMs）因其在图像和文本数据理解上的双重能力而成为新宠。VLMs 如 LLaVA、ChatGPT-4 和 Gemini 在自然图像描述、视觉问答（VQA）和空间推理任务上的表现令人瞩目。Meta AI 推出的通用分割模型 Segment Anything Model（SAM）在从未知图像中分离物体方面更是表现卓越。鉴于医学、生物和材料科学领域的专家经常需要结合文本信息来分析显微镜或医学图像，以得出关键结论，因此，对 VLMs 及基础模型如 SAM 在这些图像上的性能进行测试显得尤为重要。本研究中，我们让 ChatGPT、LLaVA、Gemini 和 SAM 在多种显微镜图像上执行分类、分割、计数和 VQA 任务。结果显示，ChatGPT 和 Gemini 在理解显微镜图像的视觉特征方面表现出色，而 SAM 在一般性地分离图像中的物体方面也颇具能力。但这些模型的表现仍未达到领域专家的水平，它们在面对图像中的杂质、缺陷、重叠和多样性时容易受到影响。",
    "title_cn": "超越人眼所见：大型视觉语言模型在显微图像分析领域的应用",
    "tags": [
      "分类：LLM应用\n\n这篇论文探讨了视觉语言模型（VLMs）和通用分割模型在医学、生物和材料科学领域的显微镜图像分析上的应用。它测试了多个模型在显微镜图像上执行分类、分割、计数和视觉问答（VQA）任务的性能，并比较了它们的表现。这篇论文主要关注这些模型在特定应用场景下的表现，因此归类为LLM应用。",
      "",
      "生物科学"
    ]
  },
  {
    "title": "Math Multiple Choice Question Generation via Human-Large Language Model Collaboration",
    "submit_datetime": "2024年05月01日",
    "abstract": "Multiple choice questions (MCQs) are a popular method for evaluating students' knowledge due to their efficiency in administration and grading. Crafting high-quality math MCQs is a labor-intensive process that requires educators to formulate precise stems and plausible distractors. Recent advances in large language models (LLMs) have sparked interest in automating MCQ creation, but challenges persist in ensuring mathematical accuracy and addressing student errors. This paper introduces a prototype tool designed to facilitate collaboration between LLMs and educators for streamlining the math MCQ generation process. We conduct a pilot study involving math educators to investigate how the tool can help them simplify the process of crafting high-quality math MCQs. We found that while LLMs can generate well-formulated question stems, their ability to generate distractors that capture common student errors and misconceptions is limited. Nevertheless, a human-AI collaboration has the potential to enhance the efficiency and effectiveness of MCQ generation.",
    "pdf_link": "https://arxiv.org/abs/2405.00864",
    "graphs": [],
    "abstract_cn": "多项选择题因其高效管理和评分而广受青睐，成为评估学生知识的有效方式。然而，设计精良的数学多项选择题是一项耗时的工作，它要求教师精心构思题干和干扰项。随着大型语言模型（LLMs）的快速发展，自动化生成MCQs的探索引起了广泛关注，但如何确保数学问题的正确性和针对学生错误的有效性仍是一大挑战。本文提出了一个原型工具，用以协助LLMs与教育者协作，共同优化数学多项选择题的生成流程。通过与数学教育者合作的试点研究，我们探究了该工具如何简化制作高质量数学MCQs的过程。研究发现，尽管LLMs能够生成结构合理的题干，但在生成能够反映学生常见错误和误解的干扰项方面还有所不足。尽管如此，人机合作在提高MCQ生成的效率和质量方面展现出巨大潜力。",
    "title_cn": "携手人类与大型语言模型，共创数学多项选择题",
    "tags": [
      "LLM应用",
      "",
      "自动化生成"
    ]
  },
  {
    "title": "Can a Hallucinating Model help in Reducing Human \"Hallucination\"?",
    "submit_datetime": "2024年05月01日",
    "abstract": "The prevalence of unwarranted beliefs, spanning pseudoscience, logical fallacies, and conspiracy theories, presents substantial societal hurdles and the risk of disseminating misinformation. Utilizing established psychometric assessments, this study explores the capabilities of large language models (LLMs) vis-a-vis the average human in detecting prevalent logical pitfalls. We undertake a philosophical inquiry, juxtaposing the rationality of humans against that of LLMs. Furthermore, we propose methodologies for harnessing LLMs to counter misconceptions, drawing upon psychological models of persuasion such as cognitive dissonance theory and elaboration likelihood theory. Through this endeavor, we highlight the potential of LLMs as personalized misinformation debunking agents.",
    "pdf_link": "https://arxiv.org/abs/2405.00843",
    "graphs": [],
    "abstract_cn": "广泛存在的无根据信念，包括伪科学、逻辑谬误和阴谋论，对社会发展构成了重大障碍，并可能导致错误信息的传播。本研究通过心理测量学评估，比较了大型语言模型（LLMs）与普通人在识别常见逻辑陷阱方面的能力。我们进行了深入的哲学探讨，对比了人类与LLMs的理性思维。同时，我们提出了一系列方法，旨在利用LLMs来纠正错误观念，这些方法借鉴了认知失调理论和详述可能性模型等心理学说服理论。通过这项研究，我们展示了LLMs在个性化辟谣方面的潜力。",
    "title_cn": "幻觉模型能否助力减轻人类的幻觉现象？",
    "tags": [
      "LLM应用",
      "心理学",
      "信息传播"
    ]
  },
  {
    "title": "WIBA: What Is Being Argued? A Comprehensive Approach to Argument Mining",
    "submit_datetime": "2024年05月01日",
    "abstract": "We propose WIBA, a novel framework and suite of methods that enable the comprehensive understanding of \"What Is Being Argued\" across contexts. Our approach develops a comprehensive framework that detects: (a) the existence, (b) the topic, and (c) the stance of an argument, correctly accounting for the logical dependence among the three tasks. Our algorithm leverages the fine-tuning and prompt-engineering of Large Language Models. We evaluate our approach and show that it performs well in all the three capabilities. First, we develop and release an Argument Detection model that can classify a piece of text as an argument with an F1 score between 79% and 86% on three different benchmark datasets. Second, we release a language model that can identify the topic being argued in a sentence, be it implicit or explicit, with an average similarity score of 71%, outperforming current naive methods by nearly 40%. Finally, we develop a method for Argument Stance Classification, and evaluate the capability of our approach, showing it achieves a classification F1 score between 71% and 78% across three diverse benchmark datasets. Our evaluation demonstrates that WIBA allows the comprehensive understanding of What Is Being Argued in large corpora across diverse contexts, which is of core interest to many applications in linguistics, communication, and social and computer science. To facilitate accessibility to the advancements outlined in this work, we release WIBA as a free open access platform (wiba.dev).",
    "pdf_link": "https://arxiv.org/abs/2405.00828",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00828v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00828/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00828v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00828/wiba_for_latex_v5_with_border.png"
      }
    ],
    "abstract_cn": "我们引入了WIBA，一个创新的框架及其方法集，旨在深入洞察不同情境下的“争论核心”。该框架能够精准识别争论的存在、主题和立场，同时巧妙处理三者间的逻辑联系。通过深度优化和精心设计的大型语言模型，我们的算法在三大关键性能上均展现出色表现。首先，我们构建并推出了一个争论检测模型，能够在三个不同的基准数据集上，以79%至86%的F1分数准确分类文本段落。其次，我们推出了一个能够识别句子中争论主题的语言模型，无论是隐含还是明确，平均相似度达到71%，性能提升近40%。最后，我们开发了一种争论立场分类方法，并在三个多样化的基准数据集上，实现了71%至78%的分类F1分数。这一评估证实了WIBA在广泛语料库和多样情境中全面解析争论内容的能力，这对于语言学、通信学、社会科学以及计算机科学等领域的应用具有重要意义。为了促进对本研究进展的广泛接触，我们免费开放了WIBA平台（wiba.dev）。",
    "title_cn": "WIBA：争论的是什么？一种全面深入的论点挖掘方法。",
    "tags": [
      "LLM应用",
      "语言学",
      "通信学"
    ]
  },
  {
    "title": "Efficient and Responsible Adaptation of Large Language Models for Robust Top-k Recommendations",
    "submit_datetime": "2024年05月01日",
    "abstract": "Conventional recommendation systems (RSs) are typically optimized to enhance performance metrics uniformly across all training samples.\n  This makes it hard for data-driven RSs to cater to a diverse set of users due to the varying properties of these users. The performance disparity among various populations can harm the model's robustness with respect to sub-populations. While recent works have shown promising results in adapting large language models (LLMs) for recommendation to address hard samples, long user queries from millions of users can degrade the performance of LLMs and elevate costs, processing times and inference latency. This challenges the practical applicability of LLMs for recommendations. To address this, we propose a hybrid task allocation framework that utilizes the capabilities of both LLMs and traditional RSs. By adopting a two-phase approach to improve robustness to sub-populations, we promote a strategic assignment of tasks for efficient and responsible adaptation of LLMs. Our strategy works by first identifying the weak and inactive users that receive a suboptimal ranking performance by RSs. Next, we use an in-context learning approach for such users, wherein each user interaction history is contextualized as a distinct ranking task and given to an LLM. We test our hybrid framework by incorporating various recommendation algorithms -- collaborative filtering and learning-to-rank recommendation models -- and two LLMs -- both open and close-sourced. Our results on three real-world datasets show a significant reduction in weak users and improved robustness of RSs to sub-populations $(\\approx12\\%)$ and overall performance without disproportionately escalating costs.",
    "pdf_link": "https://arxiv.org/abs/2405.00824",
    "graphs": [],
    "abstract_cn": "传统推荐系统往往追求全面提升训练样本的性能指标，却难以满足用户多样性的需求。这种性能差异可能削弱模型对特定用户群体的鲁棒性。尽管最新研究通过大型语言模型（LLMs）在推荐领域的应用取得了进展，但面对数百万用户的长查询，LLMs的性能和成本效益、处理速度及推理延迟仍面临挑战。为此，我们提出了一个混合任务分配框架，整合了LLMs和传统推荐系统的优势。该框架采用双阶段策略，旨在增强对不同用户群体的适应性，通过智能分配任务，实现LLMs的高效和负责任的应用。我们首先识别出那些在推荐系统中排名表现不佳的弱势和非活跃用户，然后采用上下文学习方法，将每位用户的交互历史作为独立的排名任务，交由LLM处理。我们通过整合多种推荐算法和两款LLMs（开源和闭源）来测试这一框架，并在三个现实世界的数据集上取得了显著成效：弱势用户数量显著减少，推荐系统对子群体的鲁棒性提升了约12%，整体性能得到增强，而成本却没有不合理地增加。",
    "title_cn": "为了提供鲁棒的 Top-k 推荐，我们需对大型语言模型进行既高效又负责任的调整。",
    "tags": [
      "分类：LLM应用\n\n这篇论文讨论了如何将大型语言模型（LLMs）应用于推荐系统，以提高对特定用户群体的适应性和鲁棒性。它提出了一个混合任务分配框架，结合了LLMs和传统推荐系统的优势，通过智能分配任务，实现LLMs的高效和负责任的应用。这篇论文关注的是LLMs在实际应用中的性能和成本效益，以及如何通过上下文学习和任务分配来提高推荐系统的鲁棒性。因此，它应该被归类为LLM应用。",
      "推荐系统",
      "用户行为分析"
    ]
  },
  {
    "title": "\"Ask Me Anything\": How Comcast Uses LLMs to Assist Agents in Real Time",
    "submit_datetime": "2024年05月01日",
    "abstract": "Customer service is how companies interface with their customers. It can contribute heavily towards the overall customer satisfaction. However, high-quality service can become expensive, creating an incentive to make it as cost efficient as possible and prompting most companies to utilize AI-powered assistants, or \"chat bots\". On the other hand, human-to-human interaction is still desired by customers, especially when it comes to complex scenarios such as disputes and sensitive topics like bill payment.\n  This raises the bar for customer service agents. They need to accurately understand the customer's question or concern, identify a solution that is acceptable yet feasible (and within the company's policy), all while handling multiple conversations at once.\n  In this work, we introduce \"Ask Me Anything\" (AMA) as an add-on feature to an agent-facing customer service interface. AMA allows agents to ask questions to a large language model (LLM) on demand, as they are handling customer conversations -- the LLM provides accurate responses in real-time, reducing the amount of context switching the agent needs. In our internal experiments, we find that agents using AMA versus a traditional search experience spend approximately 10% fewer seconds per conversation containing a search, translating to millions of dollars of savings annually. Agents that used the AMA feature provided positive feedback nearly 80% of the time, demonstrating its usefulness as an AI-assisted feature for customer care.",
    "pdf_link": "https://arxiv.org/abs/2405.00801",
    "graphs": [],
    "abstract_cn": "客户服务是企业与客户沟通的桥梁，对提升客户满意度起着关键作用。然而，优质客户服务的成本不菲，这促使企业寻求成本效益最大化的解决方案，如采用AI驱动的“聊天机器人”。尽管如此，客户在面对复杂问题或敏感话题时，仍倾向于寻求人与人之间的直接交流。这对客服代表提出了更高要求：他们必须精准把握客户的问题或疑虑，找到既符合客户期望又在公司政策允许范围内的解决方案，同时还要应对多线对话的挑战。本研究提出了“问我任何问题”（AMA）功能，作为客服代表界面的一个新增模块。该功能允许客服代表在与客户交流时，即时向大型语言模型（LLM）提出问题，获取实时准确的回答，从而减少代表在处理对话时的上下文切换。内部实验显示，使用AMA的代表在包含搜索的对话中，平均用时减少了约10%，这为公司每年节省了数百万美元。此外，使用AMA功能的代表中，有近80%给出了正面反馈，显示出这一AI辅助工具在客户服务中的显著价值。",
    "title_cn": "\"有问必答\"：探究 Comcast 如何利用大型语言模型 (LLMs) 为代理提供实时协助。",
    "tags": [
      "LLM应用",
      "客户服务",
      "人工智能"
    ]
  },
  {
    "title": "Visual Fact Checker: Enabling High-Fidelity Detailed Caption Generation",
    "submit_datetime": "2024年04月30日",
    "abstract": "Existing automatic captioning methods for visual content face challenges such as lack of detail, content hallucination, and poor instruction following. In this work, we propose VisualFactChecker (VFC), a flexible training-free pipeline that generates high-fidelity and detailed captions for both 2D images and 3D objects. VFC consists of three steps: 1) proposal, where image-to-text captioning models propose multiple initial captions; 2) verification, where a large language model (LLM) utilizes tools such as object detection and VQA models to fact-check proposed captions; 3) captioning, where an LLM generates the final caption by summarizing caption proposals and the fact check verification results. In this step, VFC can flexibly generate captions in various styles following complex instructions. We conduct comprehensive captioning evaluations using four metrics: 1) CLIP-Score for image-text similarity; 2) CLIP-Image-Score for measuring the image-image similarity between the original and the reconstructed image generated by a text-to-image model using the caption. 3) human study on Amazon Mechanical Turk; 4) GPT-4V for fine-grained evaluation. Evaluation results show that VFC outperforms state-of-the-art open-sourced captioning methods for 2D images on the COCO dataset and 3D assets on the Objaverse dataset. Our study demonstrates that by combining open-source models into a pipeline, we can attain captioning capability comparable to proprietary models such as GPT-4V, despite being over 10x smaller in model size.",
    "pdf_link": "https://arxiv.org/abs/2404.19752",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.19752v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19752/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19752v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19752/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19752v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19752/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19752v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19752/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19752v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19752/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19752v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19752/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19752v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19752/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19752v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19752/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19752v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19752/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19752v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19752/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19752v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19752/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19752v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19752/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19752v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19752/x14.png"
      }
    ],
    "abstract_cn": "现有自动生成视觉内容字幕的方法存在诸多挑战，如细节不足、内容失真和执行指令不力。本研究提出了一种名为 VisualFactChecker (VFC) 的新型工具，它无需额外训练即可为二维图像和三维物体生成高清晰度、详尽的字幕。VFC 的工作流程分为三步：首先，图像到文本的字幕模型提出多个初步字幕；其次，大型语言模型 (LLM) 借助对象检测和视觉问答 (VQA) 模型等工具对这些字幕进行事实核查；最后，LLM 综合初步字幕和事实核查结果，生成最终字幕。这一过程中，VFC 能够灵活地遵循复杂指令，生成多种风格的字幕。我们通过四个指标对字幕生成进行了全面评估：CLIP-Score 衡量图像与文本的相似度；CLIP-Image-Score 衡量原始图像与基于文本生成的图像之间的相似度；亚马逊机械土耳其的人机研究；以及 GPT-4V 的细粒度评估。评估结果显示，VFC 在 COCO 数据集的二维图像和 Objaverse 数据集的三维物体字幕生成上，均优于现有的顶尖开源方法。本研究证明，通过整合开源模型，即使模型规模小了十倍，也能实现与 GPT-4V 等专有模型相媲美的字幕生成能力。",
    "title_cn": "视觉事实核查器：助力生成高清晰度的详细字幕",
    "tags": [
      "LLM应用",
      "视觉内容生成",
      "自动字幕生成"
    ]
  },
  {
    "title": "PrivComp-KG : Leveraging Knowledge Graph and Large Language Models for Privacy Policy Compliance Verification",
    "submit_datetime": "2024年04月30日",
    "abstract": "Data protection and privacy is becoming increasingly crucial in the digital era. Numerous companies depend on third-party vendors and service providers to carry out critical functions within their operations, encompassing tasks such as data handling and storage. However, this reliance introduces potential vulnerabilities, as these vendors' security measures and practices may not always align with the standards expected by regulatory bodies. Businesses are required, often under the penalty of law, to ensure compliance with the evolving regulatory rules. Interpreting and implementing these regulations pose challenges due to their complexity. Regulatory documents are extensive, demanding significant effort for interpretation, while vendor-drafted privacy policies often lack the detail required for full legal compliance, leading to ambiguity. To ensure a concise interpretation of the regulatory requirements and compliance of organizational privacy policy with said regulations, we propose a Large Language Model (LLM) and Semantic Web based approach for privacy compliance. In this paper, we develop the novel Privacy Policy Compliance Verification Knowledge Graph, PrivComp-KG. It is designed to efficiently store and retrieve comprehensive information concerning privacy policies, regulatory frameworks, and domain-specific knowledge pertaining to the legal landscape of privacy. Using Retrieval Augmented Generation, we identify the relevant sections in a privacy policy with corresponding regulatory rules. This information about individual privacy policies is populated into the PrivComp-KG. Combining this with the domain context and rules, the PrivComp-KG can be queried to check for compliance with privacy policies by each vendor against relevant policy regulations. We demonstrate the relevance of the PrivComp-KG, by verifying compliance of privacy policy documents for various organizations.",
    "pdf_link": "https://arxiv.org/abs/2404.19744",
    "graphs": [],
    "abstract_cn": "在数字化浪潮中，数据安全与隐私保护的重要性日益凸显。众多企业将数据处理、存储等关键业务流程外包给第三方，这无疑带来了安全隐患，因为这些外部服务提供商的安全标准可能与法规要求不同步。法律往往要求企业必须遵守不断更新的监管规则，违反者可能面临法律制裁。这些复杂的法规文件需要大量精力去解读，而供应商提供的隐私政策往往细节不足，难以满足完全合规的要求，造成了许多不确定性。为了简化监管要求的解读并确保企业隐私政策与法规相符，本文提出了一种结合大型语言模型（LLM）和语义网的隐私合规解决方案。我们构建了一个创新的隐私政策合规性验证知识图谱PrivComp-KG，用以高效地存储和检索隐私政策、监管框架和法律领域相关知识。利用检索增强生成技术，我们能够在隐私政策文件中定位与监管规则相匹配的关键部分，并将这些信息整合到PrivComp-KG中。结合领域背景和规则，PrivComp-KG能够被用来查询并验证供应商的隐私政策是否遵守了相关规定。我们通过验证多家组织的隐私政策文件，证明了PrivComp-KG的有效性和实用性。",
    "title_cn": "PrivComp-KG：结合知识图谱与大型语言模型，致力于隐私政策的合规性检查",
    "tags": [
      "LLM应用",
      "数据安全与隐私保护",
      "知识图谱"
    ]
  },
  {
    "title": "Better & Faster Large Language Models via Multi-token Prediction",
    "submit_datetime": "2024年04月30日",
    "abstract": "Large language models such as GPT and Llama are trained with a next-token prediction loss. In this work, we suggest that training language models to predict multiple future tokens at once results in higher sample efficiency. More specifically, at each position in the training corpus, we ask the model to predict the following n tokens using n independent output heads, operating on top of a shared model trunk. Considering multi-token prediction as an auxiliary training task, we measure improved downstream capabilities with no overhead in training time for both code and natural language models. The method is increasingly useful for larger model sizes, and keeps its appeal when training for multiple epochs. Gains are especially pronounced on generative benchmarks like coding, where our models consistently outperform strong baselines by several percentage points. Our 13B parameter models solves 12 % more problems on HumanEval and 17 % more on MBPP than comparable next-token models. Experiments on small algorithmic tasks demonstrate that multi-token prediction is favorable for the development of induction heads and algorithmic reasoning capabilities. As an additional benefit, models trained with 4-token prediction are up to 3 times faster at inference, even with large batch sizes.",
    "pdf_link": "https://arxiv.org/abs/2404.19737",
    "graphs": [],
    "abstract_cn": "诸如 GPT 和 Llama 这样的大型语言模型通常通过预测下一个词元来进行训练。本研究提出，让模型同时预测多个后续词元可以提升样本效率。具体来说，训练时，模型需在语料库的每个点预测接下来的 n 个词元，通过 n 个独立的输出头实现，这些输出头共同作用于一个共享的模型主体。将这种多词元预测作为辅助训练手段，我们在不增加训练时长的前提下，对代码和自然语言模型的下游性能进行了提升。这种方法对于大型模型尤为有效，且在多轮训练中同样适用。特别是在编程等生成任务中，我们的模型在性能上显著超越了传统基线模型。以 13B 参数模型为例，其在 HumanEval 和 MBPP 测试中解决问题的能力分别提升了 12% 和 17%。此外，多词元预测还有助于提升模型的归纳和算法推理能力。另一个优势是，经过 4 词元预测训练的模型在推理时速度更快，速度提升高达 3 倍，即便在处理大规模数据批次时也是如此。",
    "title_cn": "通过多令牌预测技术，我们能够打造性能更优、响应更迅速的大型语言模型。",
    "tags": [
      "LLM理论",
      "",
      ""
    ]
  },
  {
    "title": "A Framework for Leveraging Human Computation Gaming to Enhance Knowledge Graphs for Accuracy Critical Generative AI Applications",
    "submit_datetime": "2024年04月30日",
    "abstract": "External knowledge graphs (KGs) can be used to augment large language models (LLMs), while simultaneously providing an explainable knowledge base of facts that can be inspected by a human. This approach may be particularly valuable in domains where explainability is critical, like human trafficking data analysis. However, creating KGs can pose challenges. KGs parsed from documents may comprise explicit connections (those directly stated by a document) but miss implicit connections (those obvious to a human although not directly stated). To address these challenges, this preliminary research introduces the GAME-KG framework, standing for \"Gaming for Augmenting Metadata and Enhancing Knowledge Graphs.\" GAME-KG is a federated approach to modifying explicit as well as implicit connections in KGs by using crowdsourced feedback collected through video games. GAME-KG is shown through two demonstrations: a Unity test scenario from Dark Shadows, a video game that collects feedback on KGs parsed from US Department of Justice (DOJ) Press Releases on human trafficking, and a following experiment where OpenAI's GPT-4 is prompted to answer questions based on a modified and unmodified KG. Initial results suggest that GAME-KG can be an effective framework for enhancing KGs, while simultaneously providing an explainable set of structured facts verified by humans.",
    "pdf_link": "https://arxiv.org/abs/2404.19729",
    "graphs": [],
    "abstract_cn": "外部知识图谱能增强大型语言模型，并为人类提供了一个可审查的、基于事实的知识库，这在需要高度可解释性的领域如人口贩卖数据分析中尤为重要。但构建知识图谱并非易事，因为从文档中提取的知识图谱可能仅包含直接陈述的显式联系，而忽略了那些对人类显而易见但未明确表述的隐式联系。为应对这些挑战，本研究提出了GAME-KG框架，即“通过游戏化增强元数据和提升知识图谱”。该框架利用视频游戏中收集的众包反馈，以联合方式调整知识图谱中的显式和隐式联系。通过两个案例展示了GAME-KG的有效性：一是Dark Shadows视频游戏，它收集了关于美国司法部发布的人口贩卖新闻稿中知识图谱的反馈；二是OpenAI的GPT-4模型在基于修改和未修改的知识图谱上回答问题的实验。初步结果显示，GAME-KG不仅能有效提升知识图谱的质量，还能提供一套经过人工验证的、结构化的可解释事实集。",
    "title_cn": "构建了一个框架，旨在通过人类计算游戏来丰富知识图谱，以提升关键生成性AI应用的准确性。",
    "tags": [
      "分类：LLM应用\n\n这篇论文的摘要主要讨论了如何通过外部知识图谱增强大型语言模型（LLM）的性能，特别是在需要高度可解释性的领域。此外，论文提出了GAME-KG框架，利用众包反馈来调整知识图谱中的显式和隐式联系。这些内容都与LLM的应用相关，因此将这篇论文归类为LLM应用。",
      "人口贩卖数据分析",
      "知识图谱"
    ]
  },
  {
    "title": "PANGeA: Procedural Artificial Narrative using Generative AI for Turn-Based Video Games",
    "submit_datetime": "2024年04月30日",
    "abstract": "This research introduces Procedural Artificial Narrative using Generative AI (PANGeA), a structured approach for leveraging large language models (LLMs), guided by a game designer's high-level criteria, to generate narrative content for turn-based role-playing video games (RPGs). Distinct from prior applications of LLMs used for video game design, PANGeA innovates by not only generating game level data (which includes, but is not limited to, setting, key items, and non-playable characters (NPCs)), but by also fostering dynamic, free-form interactions between the player and the environment that align with the procedural game narrative. The NPCs generated by PANGeA are personality-biased and express traits from the Big 5 Personality Model in their generated responses. PANGeA addresses challenges behind ingesting free-form text input, which can prompt LLM responses beyond the scope of the game narrative. A novel validation system that uses the LLM's intelligence evaluates text input and aligns generated responses with the unfolding narrative. Making these interactions possible, PANGeA is supported by a server that hosts a custom memory system that supplies context for augmenting generated responses thus aligning them with the procedural narrative. For its broad application, the server has a REST interface enabling any game engine to integrate directly with PANGeA, as well as an LLM interface adaptable with local or private LLMs. PANGeA's ability to foster dynamic narrative generation by aligning responses with the procedural narrative is demonstrated through an empirical study and ablation test of two versions of a demo game. These are, a custom, browser-based GPT and a Unity demo. As the results show, PANGeA holds potential to assist game designers in using LLMs to generate narrative-consistent content even when provided varied and unpredictable, free-form text input.",
    "pdf_link": "https://arxiv.org/abs/2404.19721",
    "graphs": [],
    "abstract_cn": "本研究提出了一种名为PANGeA的创新方法，它利用大型语言模型（LLMs）生成回合制角色扮演游戏（RPGs）的叙事内容。与传统的游戏设计不同，PANGeA不仅能够生成游戏关卡数据，还能促进玩家与游戏环境之间的动态互动，这些互动与游戏的程序化叙事紧密相连。PANGeA生成的NPC具有基于五大人格模型的个性特征，能够以个性化的方式响应玩家。此外，PANGeA还解决了自由形式文本输入的挑战，通过一个新颖的验证系统，利用LLM的智能来评估和对齐文本输入，确保生成的回应与游戏叙事同步。PANGeA由一个服务器支持，该服务器配备了自定义记忆系统，为生成的回应提供上下文信息，以符合程序化叙事。服务器还提供了REST接口，方便游戏引擎与PANGeA集成，并支持与本地或私有LLMs的接口对接。通过实证研究和对演示游戏的两个版本的消融测试，PANGeA展示了其在动态叙事生成方面的能力，即使面对多变和不可预测的自由形式文本输入，也能辅助游戏设计师生成与叙事一致的内容。",
    "title_cn": "PANGeA：为回合制视频游戏打造程序化叙事，借助生成性人工智能技术。",
    "tags": [
      "分类：LLM应用",
      "游戏开发",
      "人工智能"
    ]
  },
  {
    "title": "Assessing LLMs in Malicious Code Deobfuscation of Real-world Malware Campaigns",
    "submit_datetime": "2024年04月30日",
    "abstract": "The integration of large language models (LLMs) into various pipelines is increasingly widespread, effectively automating many manual tasks and often surpassing human capabilities. Cybersecurity researchers and practitioners have recognised this potential. Thus, they are actively exploring its applications, given the vast volume of heterogeneous data that requires processing to identify anomalies, potential bypasses, attacks, and fraudulent incidents. On top of this, LLMs' advanced capabilities in generating functional code, comprehending code context, and summarising its operations can also be leveraged for reverse engineering and malware deobfuscation. To this end, we delve into the deobfuscation capabilities of state-of-the-art LLMs. Beyond merely discussing a hypothetical scenario, we evaluate four LLMs with real-world malicious scripts used in the notorious Emotet malware campaign. Our results indicate that while not absolutely accurate yet, some LLMs can efficiently deobfuscate such payloads. Thus, fine-tuning LLMs for this task can be a viable potential for future AI-powered threat intelligence pipelines in the fight against obfuscated malware.",
    "pdf_link": "https://arxiv.org/abs/2404.19715",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.19715v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19715/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19715v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19715/analysis_environment.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19715v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19715/x2.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）正被越来越多地融入多样化的工作流程，它们不仅大幅提高了自动化水平，而且在很多情况下超越了人类的处理能力。网络安全领域的专家已经意识到了这一点，并开始积极探索其在处理大量复杂数据中的应用，这些数据的处理对于识别异常行为、潜在的安全漏洞、攻击行为以及欺诈事件至关重要。更进一步，LLMs 在代码生成、上下文理解以及操作总结方面的高级功能，也为逆向工程和恶意软件的去混淆提供了新的可能性。本研究不仅停留在理论层面，而是通过分析 Emotet 恶意软件活动中使用的现实世界恶意脚本，对四种顶尖的 LLMs 进行了实际测试。测试结果显示，尽管结果尚未达到完全精确，但某些 LLMs 已经能够有效地对这些恶意负载进行去混淆处理。这表明，对 LLMs 进行针对性的训练，未来可能成为 AI 驱动的威胁情报流程中，对抗混淆恶意软件的一个有效手段。",
    "title_cn": "本文旨在探讨大型语言模型在解析现实世界恶意软件活动中的恶意代码去混淆能力。",
    "tags": [
      "LLM应用",
      "网络安全",
      "人工智能"
    ]
  },
  {
    "title": "Automated Generation of High-Quality Medical Simulation Scenarios Through Integration of Semi-Structured Data and Large Language Models",
    "submit_datetime": "2024年04月30日",
    "abstract": "This study introduces a transformative framework for medical education by integrating semi-structured data with Large Language Models (LLMs), primarily OpenAIs ChatGPT3.5, to automate the creation of medical simulation scenarios. Traditionally, developing these scenarios was a time-intensive process with limited flexibility to meet diverse educational needs. The proposed approach utilizes AI to efficiently generate detailed, clinically relevant scenarios that are tailored to specific educational objectives. This innovation has significantly reduced the time and resources required for scenario development, allowing for a broader variety of simulations. Preliminary feedback from educators and learners has shown enhanced engagement and improved knowledge acquisition, confirming the effectiveness of this AI-enhanced methodology in simulation-based learning. The integration of structured data with LLMs not only streamlines the creation process but also offers a scalable, dynamic solution that could revolutionize medical training, highlighting the critical role of AI in advancing educational outcomes and patient care standards.",
    "pdf_link": "https://arxiv.org/abs/2404.19713",
    "graphs": [],
    "abstract_cn": "本研究提出了一个创新的医疗教育框架，通过融合半结构化数据与大型语言模型（LLMs），尤其是OpenAI的ChatGPT3.5，以自动化生成医疗模拟场景。这一方法摒弃了以往耗时且适应性有限的传统场景开发方式，转而利用AI技术高效地创造出既详细又具有临床相关性的教学场景，满足特定的教育目标。这一变革大幅降低了场景开发的时间和资源消耗，使得模拟种类更加多样化。教育者和学习者的初步反馈表明，这种AI驱动的教学方法提升了学习参与度并促进了知识的掌握，验证了其在模拟教学中的有效性。结构化数据与LLMs的结合不仅优化了创建流程，还提供了一种灵活且可扩展的解决方案，预示着医疗培训的革新，彰显了AI在提升教育成效和患者护理标准中的关键作用。",
    "title_cn": "融合半结构化数据与大型语言模型，实现医学模拟情景的自动化高品质生成。",
    "tags": [
      "LLM应用",
      "",
      ""
    ]
  },
  {
    "title": "When to Retrieve: Teaching LLMs to Utilize Information Retrieval Effectively",
    "submit_datetime": "2024年04月30日",
    "abstract": "In this paper, we demonstrate how Large Language Models (LLMs) can effectively learn to use an off-the-shelf information retrieval (IR) system specifically when additional context is required to answer a given question. Given the performance of IR systems, the optimal strategy for question answering does not always entail external information retrieval; rather, it often involves leveraging the parametric memory of the LLM itself. Prior research has identified this phenomenon in the PopQA dataset, wherein the most popular questions are effectively addressed using the LLM's parametric memory, while less popular ones require IR system usage. Following this, we propose a tailored training approach for LLMs, leveraging existing open-domain question answering datasets. Here, LLMs are trained to generate a special token, <RET>, when they do not know the answer to a question. Our evaluation of the Adaptive Retrieval LLM (Adapt-LLM) on the PopQA dataset showcases improvements over the same LLM under three configurations: (i) retrieving information for all the questions, (ii) using always the parametric memory of the LLM, and (iii) using a popularity threshold to decide when to use a retriever. Through our analysis, we demonstrate that Adapt-LLM is able to generate the <RET> token when it determines that it does not know how to answer a question, indicating the need for IR, while it achieves notably high accuracy levels when it chooses to rely only on its parametric memory.",
    "pdf_link": "https://arxiv.org/abs/2404.19705",
    "graphs": [],
    "abstract_cn": "本文阐述了大型语言模型（LLMs）在特定情境下，如何高效地利用现成的信息检索（IR）系统来回答问题，尤其是当问题需要额外上下文时。研究发现，并非所有问答场景都需要外部信息检索，有时更需依赖LLM的内在参数记忆。在PopQA数据集上的研究显示，常见问题通过LLM的参数记忆即可得到解答，而不常见的问题则需借助IR系统。据此，我们提出了一种针对LLMs的训练策略，结合开放域问答数据集进行训练，使LLMs能够在不确定答案时生成特殊标记<RET>。在PopQA数据集上的测试表明，自适应检索LLM（Adapt-LLM）在三种不同配置下均优于传统LLM：全面检索、仅使用参数记忆，以及基于问题流行度决定是否使用检索器。分析结果揭示，Adapt-LLM能够在不知如何回答时生成<RET>标记，提示需要进行信息检索；而在依赖其参数记忆时，其准确度显著提升。",
    "title_cn": "何时检索：引导大型语言模型高效运用信息检索技术。",
    "tags": [
      "LLM应用",
      "信息检索",
      "问答系统"
    ]
  },
  {
    "title": "Naturally Supervised 3D Visual Grounding with Language-Regularized Concept Learners",
    "submit_datetime": "2024年04月30日",
    "abstract": "3D visual grounding is a challenging task that often requires direct and dense supervision, notably the semantic label for each object in the scene. In this paper, we instead study the naturally supervised setting that learns from only 3D scene and QA pairs, where prior works underperform. We propose the Language-Regularized Concept Learner (LARC), which uses constraints from language as regularization to significantly improve the accuracy of neuro-symbolic concept learners in the naturally supervised setting. Our approach is based on two core insights: the first is that language constraints (e.g., a word's relation to another) can serve as effective regularization for structured representations in neuro-symbolic models; the second is that we can query large language models to distill such constraints from language properties. We show that LARC improves performance of prior works in naturally supervised 3D visual grounding, and demonstrates a wide range of 3D visual reasoning capabilities-from zero-shot composition, to data efficiency and transferability. Our method represents a promising step towards regularizing structured visual reasoning frameworks with language-based priors, for learning in settings without dense supervision.",
    "pdf_link": "https://arxiv.org/abs/2404.19696",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.19696v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19696/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19696v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19696/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19696v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19696/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19696v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19696/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19696v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19696/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19696v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19696/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19696v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19696/x7.png"
      }
    ],
    "abstract_cn": "3D 视觉定位任务通常依赖于密集的直接指导，例如场景中每个物体的语义标签。本文另辟蹊径，探索了仅依赖于 3D 场景与问答对的自然监督学习环境，这一领域之前的研究表现并不理想。我们提出了一种名为语言规范化概念学习器（LARC）的新方法，它利用语言中的约束作为正则化手段，显著提升了神经符号概念学习器在自然监督环境下的准确度。该方法的核心思想有二：一是语言约束（如词与词之间的关系）能有效规范神经符号模型中的结构化表示；二是可以通过大型语言模型提炼出语言属性中的这些约束。实验结果表明，LARC 在自然监督的 3D 视觉定位任务上超越了现有技术，并展现出了从零样本组合到数据效率和可转移性的广泛 3D 视觉推理能力。这一方法为使用基于语言的先验知识来规范结构化视觉推理框架，以在缺乏密集监督的环境中学习，提供了一个充满希望的新方向。",
    "title_cn": "利用语言规范的概念学习器进行自然监督的三维视觉定位研究",
    "tags": [
      "分类：Agent",
      "3D视觉",
      ""
    ]
  },
  {
    "title": "On Training a Neural Network to Explain Binaries",
    "submit_datetime": "2024年04月30日",
    "abstract": "In this work, we begin to investigate the possibility of training a deep neural network on the task of binary code understanding. Specifically, the network would take, as input, features derived directly from binaries and output English descriptions of functionality to aid a reverse engineer in investigating the capabilities of a piece of closed-source software, be it malicious or benign. Given recent success in applying large language models (generative AI) to the task of source code summarization, this seems a promising direction. However, in our initial survey of the available datasets, we found nothing of sufficiently high quality and volume to train these complex models. Instead, we build our own dataset derived from a capture of Stack Overflow containing 1.1M entries. A major result of our work is a novel dataset evaluation method using the correlation between two distances on sample pairs: one distance in the embedding space of inputs and the other in the embedding space of outputs. Intuitively, if two samples have inputs close in the input embedding space, their outputs should also be close in the output embedding space. We found this Embedding Distance Correlation (EDC) test to be highly diagnostic, indicating that our collected dataset and several existing open-source datasets are of low quality as the distances are not well correlated. We proceed to explore the general applicability of EDC, applying it to a number of qualitatively known good datasets and a number of synthetically known bad ones and found it to be a reliable indicator of dataset value.",
    "pdf_link": "https://arxiv.org/abs/2404.19631",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.19631v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19631/binary-prose-dist-correl.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19631v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19631/billsum-results.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19631v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19631/stackoverflow-results.png"
      }
    ],
    "abstract_cn": "本研究致力于探索深度神经网络在二进制代码理解任务上的训练潜力。目标是让网络输入二进制文件的直接特征，并输出功能描述，以辅助逆向工程师分析闭源软件的功能，无论其性质是恶意还是良性。尽管在源代码摘要任务中应用大型语言模型已取得显著成果，但在寻找适合训练此类复杂模型的高质量和大规模数据集时，我们并未发现合适的资源。因此，我们自行构建了数据集，源自Stack Overflow的110万条数据。研究中一个创新的成果是提出了一种新的数据集评估方法，该方法基于样本对在输入和输出嵌入空间中的距离相关性。简而言之，若两个样本在输入嵌入空间中相近，则其在输出嵌入空间中也应相似。我们进行的嵌入距离相关性（EDC）测试显示出高度的诊断价值，揭示了我们的数据集及一些现有的开源数据集质量不佳，因为这些距离之间的相关性并不显著。此外，我们还探讨了EDC的普遍适用性，将其应用于多个已知优质的数据集和一些已知较差的合成数据集，证实了EDC作为衡量数据集价值的可靠标准。",
    "title_cn": "培养神经网络以阐释二进制代码",
    "tags": [
      "LLM应用",
      "软件工程",
      "数据科学"
    ]
  },
  {
    "title": "Transferring Troubles: Cross-Lingual Transferability of Backdoor Attacks in LLMs with Instruction Tuning",
    "submit_datetime": "2024年04月30日",
    "abstract": "The implications of backdoor attacks on English-centric large language models (LLMs) have been widely examined - such attacks can be achieved by embedding malicious behaviors during training and activated under specific conditions that trigger malicious outputs. However, the impact of backdoor attacks on multilingual models remains under-explored. Our research focuses on cross-lingual backdoor attacks against multilingual LLMs, particularly investigating how poisoning the instruction-tuning data in one or two languages can affect the outputs in languages whose instruction-tuning data was not poisoned. Despite its simplicity, our empirical analysis reveals that our method exhibits remarkable efficacy in models like mT5, BLOOM, and GPT-3.5-turbo, with high attack success rates, surpassing 95% in several languages across various scenarios. Alarmingly, our findings also indicate that larger models show increased susceptibility to transferable cross-lingual backdoor attacks, which also applies to LLMs predominantly pre-trained on English data, such as Llama2, Llama3, and Gemma. Moreover, our experiments show that triggers can still work even after paraphrasing, and the backdoor mechanism proves highly effective in cross-lingual response settings across 25 languages, achieving an average attack success rate of 50%. Our study aims to highlight the vulnerabilities and significant security risks present in current multilingual LLMs, underscoring the emergent need for targeted security measures.",
    "pdf_link": "https://arxiv.org/abs/2404.19597",
    "graphs": [],
    "abstract_cn": "后门攻击对英语主导的大型语言模型（LLMs）的影响已受到广泛关注，这类攻击在训练时嵌入恶意代码，并在特定触发条件下激活以产生恶意输出。然而，其对多语言模型的冲击尚未得到充分研究。本研究聚焦于多语言LLMs的跨语言后门攻击，特别是探讨在一个或两个语言中篡改指令调整数据如何影响其他未受影响语言的输出。尽管方法简单，但我们的实证分析发现，该方法在mT5、BLOOM和GPT-3.5-turbo等模型中效果显著，攻击成功率极高，多语言环境下超过95%。更令人担忧的是，大型模型对跨语言后门攻击的敏感性增强，这一现象也出现在主要基于英语数据预训练的LLMs中，如Llama2、Llama3和Gemma。此外，实验显示，即使经过改写，触发器依然有效，后门机制在25种语言的跨语言响应场景中表现出色，平均攻击成功率达到50%。本研究旨在揭示当前多语言LLMs的安全隐患，强调了采取针对性安全措施的迫切性。",
    "title_cn": "在经过指令调整的大型语言模型（LLMs）中，后门攻击的跨语言转移性面临挑战。",
    "tags": [
      "LLM应用",
      "网络安全",
      "人工智能"
    ]
  },
  {
    "title": "Extending Llama-3's Context Ten-Fold Overnight",
    "submit_datetime": "2024年04月30日",
    "abstract": "We extend the context length of Llama-3-8B-Instruct from 8K to 80K via QLoRA fine-tuning. The entire training cycle is super efficient, which takes 8 hours on one 8xA800 (80G) GPU machine. The resulted model exhibits superior performances across a broad range of evaluation tasks, such as NIHS, topic retrieval, and long-context language understanding; meanwhile, it also well preserves the original capability over short contexts. The dramatic context extension is mainly attributed to merely 3.5K synthetic training samples generated by GPT-4 , which indicates the LLMs' inherent (yet largely underestimated) potential to extend its original context length. In fact, the context length could be extended far beyond 80K with more computation resources. Therefore, the team will publicly release the entire resources (including data, model, data generation pipeline, training code) so as to facilitate the future research from the community: \\url{https://github.com/FlagOpen/FlagEmbedding}.",
    "pdf_link": "https://arxiv.org/abs/2404.19553",
    "graphs": [],
    "abstract_cn": "我们通过 QLoRA 微调技术，成功将 Llama-3-8B-Instruct 模型的上下文长度从 8,000 个标记扩展至 80,000 个，整个过程在单个 8xA800 (80G) GPU 机器上仅需 8 小时即可完成。新模型在包括 NIHS、主题检索和长上下文语言理解在内的多项评估任务上均展现出卓越的性能，同时对短上下文的处理能力也得到了保持。这一显著的扩展能力主要得益于 GPT-4 生成的 3,500 个合成训练样本，凸显了大型语言模型在扩展上下文长度方面的潜在能力，这一能力之前被大大低估。实际上，若有更多计算资源，上下文长度的扩展潜力远超 80K。为此，我们团队将公开全部资源，包括数据、模型、数据生成流程和训练代码，以推动社区的进一步研究，详细信息可访问 \\url{https://github.com/FlagOpen/FlagEmbedding}。",
    "title_cn": "一夜之间，Llama-3 的上下文理解能力提升了十倍。",
    "tags": [
      "LLM应用",
      "",
      "机器学习"
    ]
  },
  {
    "title": "RAG and RAU: A Survey on Retrieval-Augmented Language Model in Natural Language Processing",
    "submit_datetime": "2024年04月30日",
    "abstract": "Large Language Models (LLMs) have catalyzed significant advancements in Natural Language Processing (NLP), yet they encounter challenges such as hallucination and the need for domain-specific knowledge. To mitigate these, recent methodologies have integrated information retrieved from external resources with LLMs, substantially enhancing their performance across NLP tasks. This survey paper addresses the absence of a comprehensive overview on Retrieval-Augmented Language Models (RALMs), both Retrieval-Augmented Generation (RAG) and Retrieval-Augmented Understanding (RAU), providing an in-depth examination of their paradigm, evolution, taxonomy, and applications. The paper discusses the essential components of RALMs, including Retrievers, Language Models, and Augmentations, and how their interactions lead to diverse model structures and applications. RALMs demonstrate utility in a spectrum of tasks, from translation and dialogue systems to knowledge-intensive applications. The survey includes several evaluation methods of RALMs, emphasizing the importance of robustness, accuracy, and relevance in their assessment. It also acknowledges the limitations of RALMs, particularly in retrieval quality and computational efficiency, offering directions for future research. In conclusion, this survey aims to offer a structured insight into RALMs, their potential, and the avenues for their future development in NLP. The paper is supplemented with a Github Repository containing the surveyed works and resources for further study: https://github.com/2471023025/RALM_Survey.",
    "pdf_link": "https://arxiv.org/abs/2404.19543",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）极大地推动了自然语言处理（NLP）的发展，但同时也面临着幻觉现象和对特定领域知识的依赖等挑战。为了应对这些挑战，最新的研究方法开始将外部资源检索到的信息与LLMs相结合，显著提升了模型在各类NLP任务中的表现。本篇综述文章填补了对检索增强语言模型（RALMs）——包括检索增强生成（RAG）和检索增强理解（RAU）——全面概述的空白，深入探讨了它们的模式、发展、分类法和应用场景。文中详细阐述了RALMs的核心组件，包括检索器、语言模型和增强手段，以及这些组件如何相互作用，形成多样化的模型架构和应用。RALMs在多种任务中都显示出其实用性，包括翻译、对话系统和知识密集型应用。文章还包含了对RALMs的多种评估方法，特别强调了评估过程中对鲁棒性、准确性和相关性的关注。同时，也指出了RALMs的局限性，尤其是在检索质量和计算效率方面，并对未来的研究方向提出了建议。总结而言，本综述旨在提供对RALMs的结构化理解，探讨其潜力及其在NLP领域未来发展的可能路径。此外，文章还提供了一个包含相关研究和资源的Github仓库，供进一步研究使用：https://github.com/2471023025/RALM_Survey。",
    "title_cn": "RAG 与 RAU：探索自然语言处理领域中的检索增强语言模型",
    "tags": [
      "分类：RAG",
      "",
      "信息检索"
    ]
  },
  {
    "title": "Do Large Language Models Understand Conversational Implicature -- A case study with a chinese sitcom",
    "submit_datetime": "2024年04月30日",
    "abstract": "Understanding the non-literal meaning of an utterance is critical for large language models (LLMs) to become human-like social communicators. In this work, we introduce SwordsmanImp, the first Chinese multi-turn-dialogue-based dataset aimed at conversational implicature, sourced from dialogues in the Chinese sitcom $\\textit{My Own Swordsman}$. It includes 200 carefully handcrafted questions, all annotated on which Gricean maxims have been violated. We test eight close-source and open-source LLMs under two tasks: a multiple-choice question task and an implicature explanation task. Our results show that GPT-4 attains human-level accuracy (94%) on multiple-choice questions. CausalLM demonstrates a 78.5% accuracy following GPT-4. Other models, including GPT-3.5 and several open-source models, demonstrate a lower accuracy ranging from 20% to 60% on multiple-choice questions. Human raters were asked to rate the explanation of the implicatures generated by LLMs on their reasonability, logic and fluency. While all models generate largely fluent and self-consistent text, their explanations score low on reasonability except for GPT-4, suggesting that most LLMs cannot produce satisfactory explanations of the implicatures in the conversation. Moreover, we find LLMs' performance does not vary significantly by Gricean maxims, suggesting that LLMs do not seem to process implicatures derived from different maxims differently. Our data and code are available at https://github.com/sjtu-compling/llm-pragmatics.",
    "pdf_link": "https://arxiv.org/abs/2404.19509",
    "graphs": [],
    "abstract_cn": "为了让大型语言模型（LLMs）更接近人类的社交沟通能力，理解话语的深层含义极为关键。本研究推出了SwordsmanImp，这是首个专注于中文对话含义的多轮对话数据集，源自中文情景喜剧《我的武林男友》。该数据集精心设计了200个问题，并对违反的格赖斯准则进行了标注。我们对八种封闭源和开源的大型语言模型（LLMs）进行了两项任务测试：多项选择问题和含义解释任务。测试结果显示，GPT-4在多项选择问题上达到了94%的人类水平准确率，而CausalLM紧随其后，准确率为78.5%。其他模型，包括GPT-3.5和一些开源模型，准确率则在20%到60%之间。我们还邀请了人类评估员对LLMs生成的含义解释进行合理性、逻辑性和流畅性评分。尽管所有模型都能生成流畅且一致的文本，但除了GPT-4外，其他模型在合理性上得分较低，表明大多数LLMs还未能提供令人满意的对话含义解释。此外，我们发现LLMs的性能并不因违反的格赖斯准则不同而有显著差异，这暗示LLMs在处理不同准则派生的含义时并没有表现出明显的差异。相关数据和代码已在 https://github.com/sjtu-compling/llm-pragmatics 上公开。",
    "title_cn": "大型语言模型能否领会对话中的隐含意义？——以一部中国情景喜剧为例进行探讨",
    "tags": [
      "分类：LLM应用\n\n这篇论文主要研究了大型语言模型（LLMs）在理解中文对话含义方面的能力，并通过创建一个多轮对话数据集来测试不同LLMs的性能。论文的重点是评估和比较LLMs在特定任务上的表现，这属于LLM应用的范畴。",
      "对话系统",
      "人工智能"
    ]
  },
  {
    "title": "More Compute Is What You Need",
    "submit_datetime": "2024年04月30日",
    "abstract": "Large language model pre-training has become increasingly expensive, with most practitioners relying on scaling laws to allocate compute budgets for model size and training tokens, commonly referred to as Compute-Optimal or Chinchilla Optimal. In this paper, we hypothesize a new scaling law that suggests model performance depends mostly on the amount of compute spent for transformer-based models, independent of the specific allocation to model size and dataset size. Using this unified scaling law, we predict that (a) for inference efficiency, training should prioritize smaller model sizes and larger training datasets, and (b) assuming the exhaustion of available web datasets, scaling the model size might be the only way to further improve model performance.",
    "pdf_link": "https://arxiv.org/abs/2404.19484",
    "graphs": [],
    "abstract_cn": "随着大型语言模型预训练成本的不断攀升，业界普遍依据规模法则来决定模型规模和训练令牌的计算资源分配，这一方法常被称作“计算最优化”或“栗鼠最优化”。本文提出了一个新的规模法则假设，认为模型性能主要取决于在变换器模型上的计算投入，而非模型大小或数据集大小的具体分配。基于这一统一法则，我们预测：(a) 为了提升推理效率，训练时应更倾向于选择较小的模型尺寸和更庞大的训练数据集；(b) 在现有网络数据集资源耗尽的情况下，增加模型尺寸可能是进一步提升模型性能的唯一途径。",
    "title_cn": "计算资源，多多益善。",
    "tags": [
      "LLM理论",
      "",
      "计算优化"
    ]
  },
  {
    "title": "Neuro-Vision to Language: Image Reconstruction and Interaction via Non-invasive Brain Recordings",
    "submit_datetime": "2024年04月30日",
    "abstract": "Decoding non-invasive brain recordings is crucial for advancing our understanding of human cognition, yet faces challenges from individual differences and complex neural signal representations. Traditional methods require custom models and extensive trials, and lack interpretability in visual reconstruction tasks. Our framework integrating integrates 3D brain structures with visual semantics by Vision Transformer 3D. The unified feature extractor aligns fMRI features with multiple levels of visual embeddings efficiently, removing the need for individual-specific models and allowing extraction from single-trial data. This extractor consolidates multi-level visual features into one network, simplifying integration with Large Language Models (LLMs). Additionally, we have enhanced the fMRI dataset with various fMRI-image related textual data to support multimodal large model development. The integration with LLMs enhances decoding capabilities, enabling tasks like brain captioning, question-answering, detailed descriptions, complex reasoning, and visual reconstruction. Our approach not only shows superior performance across these tasks but also precisely identifies and manipulates language-based concepts within brain signals, enhancing interpretability and providing deeper neural process insights. These advances significantly broaden non-invasive brain decoding applicability in neuroscience and human-computer interaction, setting the stage for advanced brain-computer interfaces and cognitive models.",
    "pdf_link": "https://arxiv.org/abs/2404.19438",
    "graphs": [],
    "abstract_cn": "破译非侵入性脑电图记录对于深化我们对人类认知的理解极为关键，尽管这一过程因个体差异和神经信号的复杂性而充满挑战。传统解码方法依赖于定制化模型和大量试验，且在视觉重建任务中可解释性不足。我们提出的框架，通过三维视觉变换器整合了三维大脑结构与视觉语义，使得特征提取器能够高效地将功能磁共振成像（fMRI）特征与多层次视觉嵌入相匹配，从而省去了对个体定制模型的依赖，并实现了单次试验数据的提取。该提取器将多层次视觉特征整合进单一网络，简化了与大型语言模型（LLMs）的整合流程。我们还通过引入与fMRI图像相关的多种文本数据，增强了fMRI数据集，以促进多模态大型模型的发展。与LLMs的结合显著提升了解码能力，使得大脑字幕、问答、详细描述、复杂推理和视觉重建等任务得以实现。本方法不仅在这些任务上展现了卓越的性能，还能精确地识别和操作脑信号中的语言概念，增强了解码过程的可解释性，并为神经过程的理解提供了更深层次的洞见。这些进展极大地扩展了非侵入性脑解码技术在神经科学和人机交互领域的应用前景，为发展高级脑-机接口和认知模型铺平了道路。",
    "title_cn": "神经视觉转语言：利用非侵入性大脑记录实现图像重建与互动",
    "tags": [
      "LLM应用",
      "神经科学",
      "人机交互"
    ]
  },
  {
    "title": "Can Large Language Models put 2 and 2 together? Probing for Entailed Arithmetical Relationships",
    "submit_datetime": "2024年04月30日",
    "abstract": "Two major areas of interest in the era of Large Language Models regard questions of what do LLMs know, and if and how they may be able to reason (or rather, approximately reason). Since to date these lines of work progressed largely in parallel (with notable exceptions), we are interested in investigating the intersection: probing for reasoning about the implicitly-held knowledge. Suspecting the performance to be lacking in this area, we use a very simple set-up of comparisons between cardinalities associated with elements of various subjects (e.g. the number of legs a bird has versus the number of wheels on a tricycle). We empirically demonstrate that although LLMs make steady progress in knowledge acquisition and (pseudo)reasoning with each new GPT release, their capabilities are limited to statistical inference only. It is difficult to argue that pure statistical learning can cope with the combinatorial explosion inherent in many commonsense reasoning tasks, especially once arithmetical notions are involved. Further, we argue that bigger is not always better and chasing purely statistical improvements is flawed at the core, since it only exacerbates the dangerous conflation of the production of correct answers with genuine reasoning ability.",
    "pdf_link": "https://arxiv.org/abs/2404.19432",
    "graphs": [],
    "abstract_cn": "在大型语言模型（LLM）的研究热潮中，我们关注的焦点有两个：LLM掌握了哪些知识，以及它们是否具备推理能力，或者更确切地说，能否进行近似推理。尽管这些研究方向大多独立进展，我们却对它们的交汇点充满好奇：即对隐含知识的推理能力进行探究。鉴于我们对这一领域的表现持保留态度，我们采用了一种简单的比较方法，对比不同主题元素的相关基数（如鸟的腿数与三轮车的轮子数）。我们的实证研究揭示了一个现象：尽管LLM在知识积累和推理能力上随着GPT模型的迭代而稳步提升，但它们的推理能力仅限于统计推断。要应对许多常识推理任务中的组合爆炸问题，尤其是涉及算术概念时，纯粹的统计学习方法显得力不从心。我们进一步指出，规模并非总是优势，单纯追求统计学上的提升是有缺陷的，因为这实际上加剧了正确答案产出与真正推理能力之间的混淆。",
    "title_cn": "大型语言模型能否进行简单的算术推理？本文旨在探究这些模型是否能够识别并处理蕴含的数学关系。",
    "tags": [
      "LLM理论",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Countering Reward Over-optimization in LLM with Demonstration-Guided Reinforcement Learning",
    "submit_datetime": "2024年04月30日",
    "abstract": "While Reinforcement Learning (RL) has been proven essential for tuning large language models (LLMs), it can lead to reward over-optimization (ROO). Existing approaches address ROO by adding KL regularization, requiring computationally expensive hyperparameter tuning. Additionally, KL regularization focuses solely on regularizing the language policy, neglecting a potential source of regularization: the reward function itself. Inspired by demonstration-guided RL, we here introduce the Reward Calibration from Demonstration (RCfD), which leverages human demonstrations and a reward model to recalibrate the reward objective. Formally, given a prompt, the RCfD objective minimizes the distance between the demonstrations' and LLM's rewards rather than directly maximizing the reward function. This objective shift avoids incentivizing the LLM to exploit the reward model and promotes more natural and diverse language generation. We show the effectiveness of RCfD on three language tasks, which achieves comparable performance to carefully tuned baselines while mitigating ROO.",
    "pdf_link": "https://arxiv.org/abs/2404.19409",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.19409v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19409/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19409v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19409/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19409v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19409/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19409v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19409/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19409v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19409/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19409v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19409/x6.png"
      }
    ],
    "abstract_cn": "强化学习在优化大型语言模型方面发挥着关键作用，但过度追求奖励可能导致问题。目前的做法通过KL正则化来应对这一挑战，但这需要进行昂贵的超参数调整，并且只关注于语言策略的规范化，忽略了奖励函数这一潜在的规范化因素。本研究受示范引导的RL启发，提出了一种新的奖励校准方法（RCfD），该方法结合人类示范和奖励模型来重新定义奖励目标。具体来说，RCfD在给定提示的情况下，旨在缩小示范奖励与LLM奖励之间的差异，而不是单纯追求最大化奖励函数。这种方法避免了LLM对奖励模型的过度利用，鼓励了更自然和多样化的语言生成。我们在三项语言任务中验证了RCfD的有效性，其性能可与精细调整的基线相媲美，同时有效缓解了奖励过度优化的问题。",
    "title_cn": "通过示范引导的强化学习方法，我们可以有效应对大型语言模型（LLM）中的奖励过度优化问题。",
    "tags": [
      "分类：LLM应用",
      "",
      ""
    ]
  },
  {
    "title": "Low-overhead General-purpose Near-Data Processing in CXL Memory Expanders",
    "submit_datetime": "2024年04月30日",
    "abstract": "To overcome the memory capacity wall of large-scale AI and big data applications, Compute Express Link (CXL) enables cost-efficient memory expansion beyond the local DRAM of processors. While its CXL.mem protocol stack minimizes interconnect latency, CXL memory accesses can still result in significant slowdowns for memory-bound applications. While near-data processing (NDP) in CXL memory can overcome such limitations, prior works propose application-specific HW units that are not suitable for practical CXL memory-based systems that should support various applications. On the other hand, existing CPU or GPU cores are not cost-effective for NDP because they are not optimized for memory-bound applications. In addition, the communication between the host processor and CXL controller for NDP offloading should achieve low latency, but the CXL.io (or PCIe) protocol incurs $μ$s-scale latency and is not suitable for fine-grain NDP.\n  To achieve high-performance NDP end-to-end, we propose a low-overhead general-purpose NDP architecture for CXL memory referred to as Memory-Mapped NDP (M$^2$NDP), which comprises memory-mapped functions (M$^2$func) and memory-mapped $μ$threading (M$^2μ$thr). The M$^2$func is a CXL.mem-compatible low-overhead communication mechanism between the host processor and NDP controller in the CXL memory. The M$^2μ$thr enables low-cost, general-purpose NDP unit design by introducing lightweight $μ$threads that support highly concurrent execution of NDP kernels with minimal resource wastage. By combining them, our M$^2$NDP achieves significant speedups for various applications, including in-memory OLAP, key-value store, large language model, recommendation model, and graph analytics by up to 128$\\times$ (11.5$\\times$ overall) and reduces energy by up to 87.9\\% (80.1\\% overall) compared to a baseline CPU or GPU host with passive CXL memory.",
    "pdf_link": "https://arxiv.org/abs/2404.19381",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.19381v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19381/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19381v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19381/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19381v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19381/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19381v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19381/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19381v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19381/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19381v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19381/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19381v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19381/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19381v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19381/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19381v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19381/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19381v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19381/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19381v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19381/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19381v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19381/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19381v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19381/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19381v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19381/x14.png"
      }
    ],
    "abstract_cn": "为突破大规模 AI 和大数据应用的内存瓶颈，Compute Express Link (CXL) 实现了处理器本地 DRAM 外的经济型内存扩展。尽管 CXL.mem 协议减少了连接延迟，CXL 内存访问仍可能使内存密集型应用大幅减速。CXL 内存中的近数据处理 (NDP) 虽然能解决这一问题，但现有方案多针对特定应用，不适合多样化应用需求的 CXL 内存系统。此外，现行 CPU 或 GPU 核心在 NDP 上的成本效益不高，因为它们未针对内存密集型应用进行优化。而且，主机处理器与 CXL 控制器之间的 NDP 卸载通信需要低延迟，但 CXL.io（或 PCIe）协议的延迟达到了微秒级，不适合精细的 NDP。为了实现高效的端到端 NDP，我们提出了一种低成本的通用 NDP 架构——Memory-Mapped NDP (M$^2$NDP)，适用于 CXL 内存。它包括内存映射函数 (M$^2$func) 和内存映射微线程 (M$^2μ$thr)。M$^2$func 作为一种与 CXL.mem 兼容的低开销通信机制，连接主机处理器与 CXL 内存中的 NDP 控制器。M$^2μ$thr 通过引入轻量级微线程，支持 NDP 内核的高并发执行，以低成本实现通用 NDP 单元设计，同时最大限度地减少资源浪费。结合这两者，我们的 M$^2$NDP 在多种应用中实现了显著加速，如内存内 OLAP、键值存储、大型语言模型、推荐系统和图分析等，最高加速比达 128 倍（平均加速 11.5 倍），与使用被动 CXL 内存的基线 CPU 或 GPU 主机相比，能耗降低了最高达 87.9%（平均降低 80.1%）。",
    "title_cn": "在 CXL 内存扩展器上实现高效能的通用近数据处理。",
    "tags": [
      "LLM应用",
      "大数据",
      "人工智能"
    ]
  },
  {
    "title": "Evaluating Telugu Proficiency in Large Language Models_ A Comparative Analysis of ChatGPT and Gemini",
    "submit_datetime": "2024年04月30日",
    "abstract": "The growing prominence of large language models (LLMs) necessitates the exploration of their capabilities beyond English. This research investigates the Telugu language proficiency of ChatGPT and Gemini, two leading LLMs. Through a designed set of 20 questions encompassing greetings, grammar, vocabulary, common phrases, task completion, and situational reasoning, the study delves into their strengths and weaknesses in handling Telugu. The analysis aims to identify the LLM that demonstrates a deeper understanding of Telugu grammatical structures, possesses a broader vocabulary, and exhibits superior performance in tasks like writing and reasoning. By comparing their ability to comprehend and use everyday Telugu expressions, the research sheds light on their suitability for real-world language interaction. Furthermore, the evaluation of adaptability and reasoning capabilities provides insights into how each LLM leverages Telugu to respond to dynamic situations. This comparative analysis contributes to the ongoing discussion on multilingual capabilities in AI and paves the way for future research in developing LLMs that can seamlessly integrate with Telugu-speaking communities.",
    "pdf_link": "https://arxiv.org/abs/2404.19369",
    "graphs": [],
    "abstract_cn": "随着大型语言模型（LLMs）的地位日益凸显，我们有必要探究它们在非英语领域的应用潜力。本研究聚焦于泰卢固语，评估了两大领先模型ChatGPT和Gemini的语言掌握能力。通过一系列精心设计的20个问题，覆盖了问候、语法、词汇、日常用语、任务执行和情境推理等方面，本研究深入分析了它们在泰卢固语处理上的优势与不足。研究的目的是找出哪个模型对泰卢固语的语法结构有更深入的理解，词汇量更丰富，以及在写作和推理任务上表现更佳。通过对比它们对日常泰卢固语表达的理解和运用，研究揭示了这些模型在现实语言交流中的适用性。同时，对它们的适应性和推理能力的评估，为我们提供了如何利用泰卢固语应对多变情境的见解。这项比较研究不仅丰富了关于人工智能多语言能力的讨论，也为未来开发能够与泰卢固语社区无缝对接的LLMs指明了研究方向。",
    "title_cn": "探究大型语言模型中泰卢固语能力的评估——ChatGPT 与 Gemini 的对比分析",
    "tags": [
      "LLM应用",
      "人工智能",
      "语言学"
    ]
  },
  {
    "title": "Exploring Multi-Lingual Bias of Large Code Models in Code Generation",
    "submit_datetime": "2024年04月30日",
    "abstract": "Code generation aims to synthesize code and fulfill functional requirements based on natural language (NL) specifications, which can greatly improve development efficiency. In the era of large language models (LLMs), large code models (LCMs) have been recently proposed to generate source code. LCMs can generate highly feasible solutions for programming problems described in natural language. Despite the effectiveness, we observe a noticeable multilingual bias in the generation performance of LCMs. Specifically, LCMs demonstrate proficiency in generating solutions when provided with instructions in English, yet may falter when faced with semantically equivalent instructions in other NLs such as Chinese. Moreover, the ability of LCMs to generate code exhibits variety across different programming languages (PLs), such as Python and C++. The observed phenomenon indicates the presence of multi-lingual bias within the generative capabilities of LCMs, which has remained unexplored.\n  In this paper, we aim to investigate the multi-lingual bias that exists in current LCMs. First, we initiate our investigation by constructing the first multi-lingual evaluation benchmark X-HumanEval-X, enabling us to systematically evaluate the extent of multi-lingual bias that exists in current LCMs. In our large-scale experiments on nine popular LCMs, we observe a pronounced multi-lingual bias of LCMs in code generation, including multi-NL and multi-PL bias. Specifically, when using Chinese instructions, the code generation capabilities of LCMs decrease by at least 13% in terms of the Pass@1 metric. Furthermore, LCMs perform variously across different programming languages, e.g., the performance gap between Python and C++ reaches as high as 20.9%. ...",
    "pdf_link": "https://arxiv.org/abs/2404.19368",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.19368v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19368/x1.png"
      }
    ],
    "abstract_cn": "代码生成的目的是依据自然语言规范合成代码，满足功能需求，显著提升开发效率。随着大型语言模型（LLMs）的发展，大型代码模型（LCMs）应运而生，用以生成源代码。这些模型能够针对自然语言描述的编程问题提供高度实用的解决方案。尽管成效显著，我们发现LCMs在生成性能上存在显著的多语言偏差。尤其是在接收到英文指令时，LCMs能够熟练生成解决方案，但面对其他自然语言的等效指令时，如中文，它们的表现可能会不尽人意。此外，LCMs在不同编程语言之间的代码生成能力也存在差异，例如Python与C++之间的性能差异可达20.9%。这一现象揭示了LCMs在生成能力上的多语言偏见，而这一点尚未得到充分研究。在本文中，我们旨在探究当前LCMs中的多语言偏见。我们首先通过构建首个多语言评估基准X-HumanEval-X来启动研究，以便系统评估现有LCMs中的多语言偏见程度。在对九种流行LCMs进行的大规模实验中，我们发现LCMs在代码生成任务中存在显著的多语言偏见，包括对多种自然语言和多种编程语言的偏见。具体而言，当使用中文指令时，LCMs的代码生成能力在Pass@1指标上至少下降了13%。此外，不同编程语言之间的LCMs性能也表现出差异，Python与C++之间的性能差距尤为显著。",
    "title_cn": "本文旨在探讨大型代码生成模型中存在的多语言偏见问题。",
    "tags": [
      "LLM应用",
      "",
      ""
    ]
  },
  {
    "title": "Navigating Brain Language Representations: A Comparative Analysis of Neural Language Models and Psychologically Plausible Models",
    "submit_datetime": "2024年04月30日",
    "abstract": "Neural language models, particularly large-scale ones, have been consistently proven to be most effective in predicting brain neural activity across a range of studies. However, previous research overlooked the comparison of these models with psychologically plausible ones. Moreover, evaluations were reliant on limited, single-modality, and English cognitive datasets. To address these questions, we conducted an analysis comparing encoding performance of various neural language models and psychologically plausible models. Our study utilized extensive multi-modal cognitive datasets, examining bilingual word and discourse levels. Surprisingly, our findings revealed that psychologically plausible models outperformed neural language models across diverse contexts, encompassing different modalities such as fMRI and eye-tracking, and spanning languages from English to Chinese. Among psychologically plausible models, the one incorporating embodied information emerged as particularly exceptional. This model demonstrated superior performance at both word and discourse levels, exhibiting robust prediction of brain activation across numerous regions in both English and Chinese.",
    "pdf_link": "https://arxiv.org/abs/2404.19364",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.19364v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19364/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19364v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19364/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19364v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19364/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19364v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19364/x4.png"
      }
    ],
    "abstract_cn": "大规模神经语言模型在预测大脑神经活动方面表现卓越，但以往研究较少将其与心理学认可的模型相比较，且评价多基于有限的、单一模态、英语为主的认知数据集。本研究通过广泛多模态认知数据集，对双语单词和话语层面进行了深入分析，比较了神经语言模型与心理学模型的编码表现。研究发现，在包括fMRI和眼动追踪在内的多种模态以及从英语到中文等多种语言环境中，心理学模型普遍超越了神经模型。特别是，融合了体现信息的心理学模型在单词和话语层面均展现出卓越的性能，无论是在英语还是中文中，都能精准预测大脑多个区域的激活情况。",
    "title_cn": "探索大脑中的语言表示：对神经语言模型与符合心理学原理模型的对比研究",
    "tags": [
      "LLM应用",
      "心理学",
      "神经科学"
    ]
  },
  {
    "title": "Large Language Model Informed Patent Image Retrieval",
    "submit_datetime": "2024年04月30日",
    "abstract": "In patent prosecution, image-based retrieval systems for identifying similarities between current patent images and prior art are pivotal to ensure the novelty and non-obviousness of patent applications. Despite their growing popularity in recent years, existing attempts, while effective at recognizing images within the same patent, fail to deliver practical value due to their limited generalizability in retrieving relevant prior art. Moreover, this task inherently involves the challenges posed by the abstract visual features of patent images, the skewed distribution of image classifications, and the semantic information of image descriptions. Therefore, we propose a language-informed, distribution-aware multimodal approach to patent image feature learning, which enriches the semantic understanding of patent image by integrating Large Language Models and improves the performance of underrepresented classes with our proposed distribution-aware contrastive losses. Extensive experiments on DeepPatent2 dataset show that our proposed method achieves state-of-the-art or comparable performance in image-based patent retrieval with mAP +53.3%, Recall@10 +41.8%, and MRR@10 +51.9%. Furthermore, through an in-depth user analysis, we explore our model in aiding patent professionals in their image retrieval efforts, highlighting the model's real-world applicability and effectiveness.",
    "pdf_link": "https://arxiv.org/abs/2404.19360",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.19360v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19360/img_freq.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19360v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19360/model.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19360v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19360/quali_results.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19360v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19360/tsne.png"
      }
    ],
    "abstract_cn": "专利审查过程中，用于比对当前专利图像与已有技术图像相似性的图像检索系统，对于保障专利申请的创新性和独特性起着关键作用。尽管这类系统近年来越来越受欢迎，但它们在识别同一专利中的图像方面虽有成效，却因泛化能力有限而难以在检索相关已有技术图像上提供实用价值。此外，这项工作本身还面临着专利图像的抽象视觉特征、图像分类的不均衡分布以及图像描述的语义信息等挑战。为此，我们提出了一种融合语言信息、考虑数据分布的多模态专利图像特征学习方法，该方法通过整合大型语言模型来增强对专利图像的语义理解，并借助我们提出的分布感知对比损失来提升少数类别的性能。在DeepPatent2数据集上的广泛测试显示，我们的方法在图像检索任务上达到了或接近了最先进的性能，平均精度均值（mAP）提升了53.3%，10个召回率（Recall@10）提升了41.8%，10个平均召回率（MRR@10）提升了51.9%。进一步的深入用户分析表明，我们的模型在辅助专利专业人士进行图像检索方面具有实际应用价值和显著效果。",
    "title_cn": "借助大型语言模型的专利图像检索技术",
    "tags": [
      "LLM应用",
      "专利审查",
      "图像检索"
    ]
  },
  {
    "title": "StablePT: Towards Stable Prompting for Few-shot Learning via Input Separation",
    "submit_datetime": "2024年04月30日",
    "abstract": "Large language models have shown their ability to become effective few-shot learners with prompting, revoluting the paradigm of learning with data scarcity. However, this approach largely depends on the quality of prompt initialization, and always exhibits large variability among different runs. Such property makes prompt tuning highly unreliable and vulnerable to poorly constructed prompts, which limits its extension to more real-world applications. To tackle this issue, we propose to treat the hard prompt and soft prompt as separate inputs to mitigate noise brought by the prompt initialization. Furthermore, we optimize soft prompts with contrastive learning for utilizing class-aware information in the training process to maintain model performance. Experimental results demonstrate that \\sysname outperforms state-of-the-art methods by 7.20% in accuracy and reduces the standard deviation by 2.02 on average. Furthermore, extensive experiments underscore its robustness and stability across 7 datasets covering various tasks.",
    "pdf_link": "https://arxiv.org/abs/2404.19335",
    "graphs": [],
    "abstract_cn": "大型语言模型通过提示学习，已经证明了在数据匮乏环境下成为高效的少次学习者的能力，这一进步彻底革新了学习模式。然而，这种方法的成效极大依赖于提示的初始设置质量，且在不同执行过程中波动较大。这种不稳定性使得提示调整变得不够可靠，容易受到不良提示的影响，限制了其在现实世界应用中的推广。为了应对这一挑战，我们提出了一种新方法，将硬提示和软提示作为独立的输入项，以减少由提示初始化引入的噪声。同时，我们采用对比学习方法对软提示进行优化，以便在训练过程中利用类别相关的信息，从而保持模型性能。实验结果显示，\\sysname 在准确度上超越了当前最先进方法7.20%，并将平均标准偏差降低了2.02。此外，通过在7个不同任务的数据集上进行的广泛实验，证明了其鲁棒性和稳定性。",
    "title_cn": "StablePT：探索通过输入分离技术，为少样本学习提供稳定提示的新路径。",
    "tags": [
      "LLM应用",
      "人工智能",
      "机器学习"
    ]
  },
  {
    "title": "Enhancing Trust in LLM-Generated Code Summaries with Calibrated Confidence Scores",
    "submit_datetime": "2024年04月30日",
    "abstract": "A good summary can often be very useful during program comprehension. While a brief, fluent, and relevant summary can be helpful, it does require significant human effort to produce. Often, good summaries are unavailable in software projects, thus making maintenance more difficult. There has been a considerable body of research into automated AI-based methods, using Large Language models (LLMs), to generate summaries of code; there also has been quite a bit work on ways to measure the performance of such summarization methods, with special attention paid to how closely these AI-generated summaries resemble a summary a human might have produced. Measures such as BERTScore and BLEU have been suggested and evaluated with human-subject studies.\n  However, LLMs often err and generate something quite unlike what a human might say. Given an LLM-produced code summary, is there a way to gauge whether it's likely to be sufficiently similar to a human produced summary, or not? In this paper, we study this question, as a calibration problem: given a summary from an LLM, can we compute a confidence measure, which is a good indication of whether the summary is sufficiently similar to what a human would have produced in this situation? We examine this question using several LLMs, for several languages, and in several different settings. We suggest an approach which provides well-calibrated predictions of likelihood of similarity to human summaries.",
    "pdf_link": "https://arxiv.org/abs/2404.19318",
    "graphs": [],
    "abstract_cn": "在程序理解的过程中，一份精炼、流畅且切题的摘要极为有用。然而，制作这样的摘要需要投入大量的人力。在软件项目中，优质的摘要往往难以获得，这增加了维护的难度。目前，已有大量研究致力于开发自动化的AI方法，利用大型语言模型（LLMs）来生成代码摘要。同时，也有许多研究致力于评估这些摘要方法的性能，特别是它们生成的摘要与人类生成摘要的相似度。诸如BERTScore和BLEU等评价指标已被提出，并在以人为对象的研究中进行了评估。但是，LLMs有时会出错，生成的摘要与人类的表达方式大相径庭。面对LLM生成的代码摘要，我们如何判断其是否足够接近人类生成的摘要？本文中，我们探讨了这一问题，将其视为一个校准问题：给定LLM生成的摘要，我们能否计算出一个置信度量，以判断该摘要是否足够接近人类可能生成的摘要？我们通过多种语言和不同设置下的多种LLMs来检验这一问题。我们提出了一种方法，能够提供对摘要与人类生成摘要相似性可能性的准确预测。",
    "title_cn": "通过精准的置信度评分，提升对大型语言模型产出的代码摘要的信任度。",
    "tags": [
      "LLM应用",
      "程序理解",
      "软件工程"
    ]
  },
  {
    "title": "Modeling Orthographic Variation in Occitan's Dialects",
    "submit_datetime": "2024年04月30日",
    "abstract": "Effectively normalizing textual data poses a considerable challenge, especially for low-resource languages lacking standardized writing systems. In this study, we fine-tuned a multilingual model with data from several Occitan dialects and conducted a series of experiments to assess the model's representations of these dialects. For evaluation purposes, we compiled a parallel lexicon encompassing four Occitan dialects. Intrinsic evaluations of the model's embeddings revealed that surface similarity between the dialects strengthened representations. When the model was further fine-tuned for part-of-speech tagging and Universal Dependency parsing, its performance was robust to dialectical variation, even when trained solely on part-of-speech data from a single dialect. Our findings suggest that large multilingual models minimize the need for spelling normalization during pre-processing.",
    "pdf_link": "https://arxiv.org/abs/2404.19315",
    "graphs": [],
    "abstract_cn": "文本数据的有效归一化尤其对于缺乏统一书写系统的低资源语言来说是一个重大挑战。本研究中，我们针对几种奥克西唐方言的数据对一个多语言模型进行了微调，并通过一系列实验来评估模型对这些方言的理解和表征。为了评估，我们创建了一个包含四种奥克西唐方言的对照词汇库。模型嵌入的内在评估显示，方言间的表面相似性有助于加强模型的表征能力。此外，当模型进一步针对词性标注和通用依存句法分析进行微调时，即便仅使用单一方言的词性数据进行训练，其性能也能稳定应对方言差异。研究结果表明，大型多语言模型能够在预处理阶段减少对拼写归一化的依赖。",
    "title_cn": "探索奥克西唐方言拼写变异的建模研究",
    "tags": [
      "分类：LLM应用\n\n这篇论文主要研究了多语言模型在处理低资源语言（特别是奥克西唐方言）时的表现，以及如何通过微调模型来提高对这些方言的理解和表征。论文还探讨了模型在不同方言之间的性能差异，以及如何减少对拼写归一化的依赖。这些研究内容都与大型语言模型（LLM）的应用相关，因此将其归类为LLM应用。",
      "语言学研究",
      ""
    ]
  },
  {
    "title": "Revisiting the Adversarial Robustness of Vision Language Models: a Multimodal Perspective",
    "submit_datetime": "2024年04月30日",
    "abstract": "Pretrained vision-language models (VLMs) like CLIP have shown impressive generalization performance across various downstream tasks, yet they remain vulnerable to adversarial attacks. While prior research has primarily concentrated on improving the adversarial robustness of image encoders to guard against attacks on images, the exploration of text-based and multimodal attacks has largely been overlooked. In this work, we initiate the first known and comprehensive effort to study adapting vision-language models for adversarial robustness under the multimodal attack. Firstly, we introduce a multimodal attack strategy and investigate the impact of different attacks. We then propose a multimodal contrastive adversarial training loss, aligning the clean and adversarial text embeddings with the adversarial and clean visual features, to enhance the adversarial robustness of both image and text encoders of CLIP. Extensive experiments on 15 datasets across two tasks demonstrate that our method significantly improves the adversarial robustness of CLIP. Interestingly, we find that the model fine-tuned against multimodal adversarial attacks exhibits greater robustness than its counterpart fine-tuned solely against image-based attacks, even in the context of image attacks, which may open up new possibilities for enhancing the security of VLMs.",
    "pdf_link": "https://arxiv.org/abs/2404.19287",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.19287v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19287/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19287v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19287/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19287v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19287/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19287v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19287/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19287v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19287/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19287v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19287/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19287v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19287/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19287v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19287/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19287v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19287/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19287v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19287/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19287v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19287/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19287v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19287/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19287v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19287/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19287v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19287/x14.png"
      }
    ],
    "abstract_cn": "CLIP 等预训练视觉-语言模型在多样化任务上展现了卓越的泛化能力，但对对抗性攻击的抵抗力尚显不足。以往研究多聚焦于图像编码器的抗攻击性，而对文本和多模态攻击的探讨则相对欠缺。本研究首次全面探讨了在多模态攻击情境下提升视觉-语言模型的对抗性鲁棒性。我们首先提出了一种多模态攻击策略，分析了不同攻击方式的影响，随后引入了一种多模态对比对抗训练方法，通过同步干净与对抗性文本嵌入以及视觉特征，增强了 CLIP 模型中图像和文本编码器的鲁棒性。在15个数据集的两大任务上的广泛测试显示，该方法显著提升了 CLIP 的抗攻击能力。更引人注意的是，针对多模态对抗攻击进行的模型微调，在图像攻击环境下展现出比仅针对图像攻击微调的模型更强的鲁棒性，这为视觉-语言模型的安全性提升提供了新思路。",
    "title_cn": "本文从多模态的角度出发，重新探讨视觉语言模型在对抗性攻击下的鲁棒性问题。",
    "tags": [
      "LLM应用",
      "计算机视觉",
      ""
    ]
  },
  {
    "title": "Soft Prompt Generation for Domain Generalization",
    "submit_datetime": "2024年04月30日",
    "abstract": "Large pre-trained vision language models (VLMs) have shown impressive zero-shot ability on downstream tasks with manually designed prompt, which are not optimal for specific domains. To further adapt VLMs to downstream tasks, soft prompt is proposed to replace manually designed prompt, which acts as a learning vector that undergoes fine-tuning based on specific domain data. Prior prompt learning methods primarily learn a fixed prompt and residuled prompt from training samples. However, the learned prompts lack diversity and ignore information about unseen domains, potentially compromising the transferability of the prompts. In this paper, we reframe the prompt learning framework from a generative perspective and propose a simple yet efficient method for the Domain Generalization (DG) task, namely \\textbf{S}oft \\textbf{P}rompt \\textbf{G}eneration (SPG). To the best of our knowledge, we are the first to introduce the generative model into prompt learning in VLMs and explore its potential for producing soft prompts by relying solely on the generative model, ensuring the diversity of prompts. Specifically, SPG consists of a two-stage training phase and an inference phase. During the training phase, we introduce soft prompt labels for each domain, aiming to incorporate the generative model domain knowledge. During the inference phase, the generator of the generative model is employed to obtain instance-specific soft prompts for the unseen target domain. Extensive experiments on five domain generalization benchmarks of three DG tasks demonstrate that our proposed SPG achieves state-of-the-art performance. The code will be available soon.",
    "pdf_link": "https://arxiv.org/abs/2404.19286",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.19286v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19286/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19286v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19286/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19286v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19286/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19286v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19286/x4.png"
      }
    ],
    "abstract_cn": "大型预训练视觉语言模型（VLMs）在利用人工设计提示的下游任务中展现了卓越的零样本能力，但这些提示并不总是适合特定领域。为了提升VLMs对特定下游任务的适应性，本文提出了软提示的概念，以取代传统的人工设计提示，作为一个可基于特定领域数据进行微调的学习向量。传统提示学习方法通常只学习一个固定的提示，这限制了提示的多样性，并且忽视了未见领域的信息，从而影响了提示的泛化能力。本文从生成式学习的角度重新定义了提示学习框架，并提出了一种新颖的领域泛化（DG）任务方法——软提示生成（SPG）。据我们所知，这是首次将生成模型融入VLMs的提示学习中，以期通过生成模型独立产生多样化的软提示。SPG方法包括两个训练阶段和一个推理阶段：在训练阶段，我们为每个领域定义了软提示标签，以整合生成模型的领域知识；在推理阶段，利用生成模型的生成器为未见目标领域生成特定实例的软提示。通过在三个DG任务的五个领域泛化基准上的广泛实验，我们证明了SPG方法达到了最先进的性能。相关代码即将公开。",
    "title_cn": "在领域泛化领域，软提示的生成技术正日益受到关注。",
    "tags": [
      "LLM应用",
      "计算机视觉",
      ""
    ]
  },
  {
    "title": "DiffuseLoco: Real-Time Legged Locomotion Control with Diffusion from Offline Datasets",
    "submit_datetime": "2024年04月30日",
    "abstract": "This work introduces DiffuseLoco, a framework for training multi-skill diffusion-based policies for dynamic legged locomotion from offline datasets, enabling real-time control of diverse skills on robots in the real world. Offline learning at scale has led to breakthroughs in computer vision, natural language processing, and robotic manipulation domains. However, scaling up learning for legged robot locomotion, especially with multiple skills in a single policy, presents significant challenges for prior online reinforcement learning methods. To address this challenge, we propose a novel, scalable framework that leverages diffusion models to directly learn from offline multimodal datasets with a diverse set of locomotion skills. With design choices tailored for real-time control in dynamical systems, including receding horizon control and delayed inputs, DiffuseLoco is capable of reproducing multimodality in performing various locomotion skills, zero-shot transfer to real quadrupedal robots, and it can be deployed on edge computing devices. Furthermore, DiffuseLoco demonstrates free transitions between skills and robustness against environmental variations. Through extensive benchmarking in real-world experiments, DiffuseLoco exhibits better stability and velocity tracking performance compared to prior reinforcement learning and non-diffusion-based behavior cloning baselines. The design choices are validated via comprehensive ablation studies. This work opens new possibilities for scaling up learning-based legged locomotion controllers through the scaling of large, expressive models and diverse offline datasets.",
    "pdf_link": "https://arxiv.org/abs/2404.19264",
    "graphs": [],
    "abstract_cn": "本研究提出了 DiffuseLoco，这是一个创新的框架，旨在通过离线数据集训练多技能扩散策略，实现真实世界机器人的多样化技能实时控制。这一进展在计算机视觉、自然语言处理和机器人操作等离线学习领域取得了显著成果。然而，对于腿部机器人，尤其是集成多种技能的单一策略，传统的在线强化学习方法面临重大挑战。DiffuseLoco 通过扩散模型直接从多模态数据集中学习，为动态系统的实时控制提供了定制化设计，如递减视野控制和延迟输入，能够执行多种运动技能，实现零样本迁移至四足机器人，并支持在边缘计算设备上部署。此外，DiffuseLoco 能够灵活转换技能，并对环境变化表现出强大的适应性。在现实世界的广泛测试中，DiffuseLoco 在稳定性和速度跟踪方面超越了传统强化学习和非扩散式行为克隆方法。通过全面的消融研究，验证了其设计选择的有效性。这项工作为基于学习的大型腿部运动控制器的发展，通过扩展大型、富有表现力的模型和多样化的离线数据集，提供了新的思路。",
    "title_cn": "DiffuseLoco：利用离线数据集的扩散技术，实现实时腿部运动控制",
    "tags": [
      "Agent",
      "机器人技术",
      "计算机视觉"
    ]
  },
  {
    "title": "Suvach -- Generated Hindi QA benchmark",
    "submit_datetime": "2024年04月30日",
    "abstract": "Current evaluation benchmarks for question answering (QA) in Indic languages often rely on machine translation of existing English datasets. This approach suffers from bias and inaccuracies inherent in machine translation, leading to datasets that may not reflect the true capabilities of EQA models for Indic languages. This paper proposes a new benchmark specifically designed for evaluating Hindi EQA models and discusses the methodology to do the same for any task. This method leverages large language models (LLMs) to generate a high-quality dataset in an extractive setting, ensuring its relevance for the target language. We believe this new resource will foster advancements in Hindi NLP research by providing a more accurate and reliable evaluation tool.",
    "pdf_link": "https://arxiv.org/abs/2404.19254",
    "graphs": [],
    "abstract_cn": "现行的印度语言问答评估标准多依赖于将英文数据集进行机器翻译，这种方法存在偏见和翻译不准确的问题，无法真实反映印度语言问答模型的能力。本论文提出了一个新的评估基准，专为印地语问答模型量身定制，并探讨了如何为任何任务设计类似的方法。该方法利用大型语言模型在抽取式问答环境中生成高质量数据集，确保其与目标语言的紧密相关。我们认为，这一新资源将为印地语自然语言处理研究提供更精确、更可靠的评估工具，从而推动该领域的进步。",
    "title_cn": "Suvach -- 一个专为印地语设计的问答基准生成器",
    "tags": [
      "分类：LLM应用",
      "印度语言处理",
      ""
    ]
  },
  {
    "title": "HydraLoRA: An Asymmetric LoRA Architecture for Efficient Fine-Tuning",
    "submit_datetime": "2024年04月30日",
    "abstract": "Adapting Large Language Models (LLMs) to new tasks through fine-tuning has been made more efficient by the introduction of Parameter-Efficient Fine-Tuning (PEFT) techniques, such as LoRA. However, these methods often underperform compared to full fine-tuning, particularly in scenarios involving complex datasets. This issue becomes even more pronounced in complex domains, highlighting the need for improved PEFT approaches that can achieve better performance. Through a series of experiments, we have uncovered two critical insights that shed light on the training and parameter inefficiency of LoRA. Building on these insights, we have developed HydraLoRA, a LoRA framework with an asymmetric structure that eliminates the need for domain expertise. Our experiments demonstrate that HydraLoRA outperforms other PEFT approaches, even those that rely on domain knowledge during the training and inference phases. \\href{https://github.com/Clin0212/HydraLoRA}{Code}.",
    "pdf_link": "https://arxiv.org/abs/2404.19245",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.19245v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19245/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19245v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19245/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19245v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19245/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19245v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19245/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19245v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19245/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19245v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19245/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19245v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19245/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19245v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19245/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19245v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19245/x9.png"
      }
    ],
    "abstract_cn": "采用参数高效微调（PEFT）技术如LoRA，大型语言模型（LLMs）的微调过程变得更加高效。但这些方法在面对复杂数据集时往往表现不佳，尤其是在复杂领域中，这一问题尤为突出，迫切需要更优的PEFT方法来提升性能。经过一系列实验，我们发现了两个关键洞见，它们揭示了LoRA在训练效率和参数优化上的不足。基于这些洞见，我们构建了HydraLoRA，这是一个无需领域专家知识的非对称结构LoRA框架。实验结果证明，HydraLoRA在性能上超越了其他依赖于领域知识的PEFT方法。\\href{https://github.com/Clin0212/HydraLoRA}{点击获取代码}。",
    "title_cn": "HydraLoRA：一种高效微调的非对称LoRA架构。",
    "tags": [
      "分类：LLM理论",
      "计算机科学",
      "机器学习"
    ]
  },
  {
    "title": "VimTS: A Unified Video and Image Text Spotter for Enhancing the Cross-domain Generalization",
    "submit_datetime": "2024年04月30日",
    "abstract": "Text spotting, a task involving the extraction of textual information from image or video sequences, faces challenges in cross-domain adaption, such as image-to-image and image-to-video generalization. In this paper, we introduce a new method, termed VimTS, which enhances the generalization ability of the model by achieving better synergy among different tasks. Typically, we propose a Prompt Queries Generation Module and a Tasks-aware Adapter to effectively convert the original single-task model into a multi-task model suitable for both image and video scenarios with minimal additional parameters. The Prompt Queries Generation Module facilitates explicit interaction between different tasks, while the Tasks-aware Adapter helps the model dynamically learn suitable features for each task. Additionally, to further enable the model to learn temporal information at a lower cost, we propose a synthetic video text dataset (VTD-368k) by leveraging the Content Deformation Fields (CoDeF) algorithm. Notably, our method outperforms the state-of-the-art method by an average of 2.6% in six cross-domain benchmarks such as TT-to-IC15, CTW1500-to-TT, and TT-to-CTW1500. For video-level cross-domain adaption, our method even surpasses the previous end-to-end video spotting method in ICDAR2015 video and DSText v2 by an average of 5.5% on the MOTA metric, using only image-level data. We further demonstrate that existing Large Multimodal Models exhibit limitations in generating cross-domain scene text spotting, in contrast to our VimTS model which requires significantly fewer parameters and data. The code and datasets will be made available at the https://VimTextSpotter.github.io.",
    "pdf_link": "https://arxiv.org/abs/2404.19652",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.19652v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19652/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19652v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19652/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19652v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19652/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19652v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19652/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19652v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19652/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19652v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19652/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19652v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19652/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19652v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19652/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19652v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19652/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19652v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19652/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19652v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19652/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19652v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19652/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19652v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19652/x13.png"
      }
    ],
    "abstract_cn": "文本识别技术致力于从图像或视频序列中提取文本信息，却常常在跨域适应上遭遇难题，比如图像间的转换和图像到视频的泛化。本文提出了一种创新的方法——VimTS，它通过促进不同任务间的协作，显著提升了模型的泛化性能。我们设计了一个提示查询生成模块和任务感知适配器，以最小的参数增量，将单任务模型转变为能够适应图像和视频场景的多任务模型。提示查询生成模块促进了任务间的直接互动，而任务感知适配器则指导模型为每个任务学习适宜的特征。为了使模型更高效地掌握时间信息，我们还利用内容变形场（CoDeF）算法创建了一个合成视频文本数据集VTD-368k。我们的VimTS在多个跨域基准测试中平均领先现有最先进方法2.6%，在视频级别的跨域适应上，更是在ICDAR2015视频和DSText v2数据集上以平均5.5%的MOTA指标超越了先前的端到端视频识别方法，且仅依赖于图像级数据。此外，我们发现现有的大型多模态模型在跨域场景文本识别上存在局限，而VimTS模型则以更少的参数和数据需求，展现了其优势。相关代码和数据集将在https://VimTextSpotter.github.io公开。",
    "title_cn": "VimTS：一款集视频与图像文本识别于一体的工具，旨在提升跨领域泛化能力。",
    "tags": [
      "分类：Agent\n\n这篇论文主要研究了文本识别技术在跨域适应上的挑战，并提出了一种创新的方法——VimTS，通过促进不同任务间的协作，显著提升了模型的泛化性能。这种方法涉及到设计提示查询生成模块和任务感知适配器，将单任务模型转变为能够适应图像和视频场景的多任务模型。这属于智能代理（Agent）的范畴，因为它们能够处理多种任务，并在不同场景下进行自适应。",
      "计算机视觉",
      ""
    ]
  },
  {
    "title": "Fake it to make it: Using synthetic data to remedy the data shortage in joint multimodal speech-and-gesture synthesis",
    "submit_datetime": "2024年04月30日",
    "abstract": "Although humans engaged in face-to-face conversation simultaneously communicate both verbally and non-verbally, methods for joint and unified synthesis of speech audio and co-speech 3D gesture motion from text are a new and emerging field. These technologies hold great promise for more human-like, efficient, expressive, and robust synthetic communication, but are currently held back by the lack of suitably large datasets, as existing methods are trained on parallel data from all constituent modalities. Inspired by student-teacher methods, we propose a straightforward solution to the data shortage, by simply synthesising additional training material. Specifically, we use unimodal synthesis models trained on large datasets to create multimodal (but synthetic) parallel training data, and then pre-train a joint synthesis model on that material. In addition, we propose a new synthesis architecture that adds better and more controllable prosody modelling to the state-of-the-art method in the field. Our results confirm that pre-training on large amounts of synthetic data improves the quality of both the speech and the motion synthesised by the multimodal model, with the proposed architecture yielding further benefits when pre-trained on the synthetic data. See https://shivammehta25.github.io/MAGI/ for example output.",
    "pdf_link": "https://arxiv.org/abs/2404.19622",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.19622v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19622/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19622v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19622/x2.png"
      }
    ],
    "abstract_cn": "人类在面对面交流时，不仅通过言语，还通过非言语方式进行沟通。然而，将文本同步转换成语音和伴随的3D手势动作的技术仍处于起步阶段。尽管这类技术有望实现更自然、高效、富有表现力且稳健的人工合成交流，但目前由于缺乏大规模数据集而受限。现有的技术需要依赖所有相关模态的并行数据进行训练。借鉴师生学习方法，我们提出了一种简单有效的解决方案：通过合成额外的训练材料来扩充数据。具体而言，我们利用在大型数据集上训练的单模态合成模型生成多模态但合成的并行训练数据，并在此基础之上预训练一个联合合成模型。此外，我们还提出了一种新的合成架构，它在现有最先进方法的基础上增强了韵律建模的能力，使其更加精准和可控。实验结果表明，利用大量合成数据进行预训练能够显著提升多模态模型合成语音和动作的质量，而新架构在预训练过程中进一步优化了合成效果。更多示例成果，可访问 https://shivammehta25.github.io/MAGI/ 查看。",
    "title_cn": "以假乱真：借助合成数据填补联合多模态语音及手势合成的数据缺口。",
    "tags": [
      "分类：Agent",
      "人机交互",
      "人工智能"
    ]
  },
  {
    "title": "Generating Feedback-Ladders for Logical Errors in Programming using Large Language Models",
    "submit_datetime": "2024年04月30日",
    "abstract": "In feedback generation for logical errors in programming assignments, large language model (LLM)-based methods have shown great promise. These methods ask the LLM to generate feedback given the problem statement and a student's (buggy) submission. There are several issues with these types of methods. First, the generated feedback messages are often too direct in revealing the error in the submission and thus diminish valuable opportunities for the student to learn. Second, they do not consider the student's learning context, i.e., their previous submissions, current knowledge, etc. Third, they are not layered since existing methods use a single, shared prompt for all student submissions. In this paper, we explore using LLMs to generate a \"feedback-ladder\", i.e., multiple levels of feedback for the same problem-submission pair. We evaluate the quality of the generated feedback-ladder via a user study with students, educators, and researchers. We have observed diminishing effectiveness for higher-level feedback and higher-scoring submissions overall in the study. In practice, our method enables teachers to select an appropriate level of feedback to show to a student based on their personal learning context, or in a progressive manner to go more detailed if a higher-level feedback fails to correct the student's error.",
    "pdf_link": "https://arxiv.org/abs/2405.00302",
    "graphs": [],
    "abstract_cn": "在编程作业逻辑错误反馈生成领域，基于大型语言模型（LLM）的技术展现了显著的前景。这些技术通过问题描述和学生（存在缺陷的）作业提交，指导LLM生成反馈。然而，这种方法面临多重挑战：首先，反馈信息往往过于直白，容易暴露错误，减少了学生的自我发现机会；其次，它们忽略了学生的学习背景，如过往作业和知识水平；再者，它们缺乏层次性，通常对所有学生提交采用统一的提示。本文提出了一种利用LLM生成“反馈阶梯”的方法，即为同一问题和学生提交提供多层次的反馈。通过与学生、教师和研究者的用户体验研究，我们评估了所生成反馈阶梯的质量，并发现对于更高层次的反馈和得分较高的作业，其效果逐渐减弱。在实际应用中，该方法允许教师根据学生的个性化学习需求选择合适的反馈层次，或者在高层次反馈未能纠正错误时，逐步提供更详细的指导。",
    "title_cn": "利用大型语言模型为编程中的逻辑错误构建反馈梯度。",
    "tags": [
      "LLM应用",
      "",
      "软件工程"
    ]
  },
  {
    "title": "LITO: Learnable Intervention for Truthfulness Optimization",
    "submit_datetime": "2024年04月30日",
    "abstract": "Large language models (LLMs) can generate long-form and coherent text, but they still frequently hallucinate facts, thus limiting their reliability. To address this issue, inference-time methods that elicit truthful responses have been proposed by shifting LLM representations towards learned \"truthful directions\". However, applying the truthful directions with the same intensity fails to generalize across different question contexts. We propose LITO, a Learnable Intervention method for Truthfulness Optimization that automatically identifies the optimal intervention intensity tailored to a specific context. LITO explores a sequence of model generations based on increasing levels of intervention intensities. It selects the most accurate response or refuses to answer when the predictions are highly uncertain. Experiments on multiple LLMs and question-answering datasets demonstrate that LITO improves truthfulness while preserving task accuracy. The adaptive nature of LITO counters issues with one-size-fits-all intervention-based solutions, maximizing model truthfulness by reflecting internal knowledge only when the model is confident.",
    "pdf_link": "https://arxiv.org/abs/2405.00301",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）虽能产出长篇连贯文本，却常出现事实性错误，影响了其可信度。为提高可靠性，研究者提出了一种推理阶段的方法，通过调整LLM的表示向“真实导向”靠拢，以引出真实的回答。但这种方法若一视同仁地应用，却难以适应多变的问题情境。我们引入了LITO，一种自动确定最佳干预强度的可学习干预方法，以适应不同上下文的真实性优化需求。LITO通过递增的干预强度生成模型序列，并在预测不确定性高时选择最准确的答案或选择不回答。在多个大型语言模型和问答数据集上的实验显示，LITO在确保任务准确性的同时，有效提升了回答的真实性。LITO的自适应特性克服了通用干预方法的局限，通过在模型信心充足时反映其内在知识，实现了模型真实性的最大化。",
    "title_cn": "LITO：为真实性优化而设计的可学习干预机制",
    "tags": [
      "LLM应用",
      "问答系统",
      ""
    ]
  },
  {
    "title": "How Can I Improve? Using GPT to Highlight the Desired and Undesired Parts of Open-ended Responses",
    "submit_datetime": "2024年04月30日",
    "abstract": "Automated explanatory feedback systems play a crucial role in facilitating learning for a large cohort of learners by offering feedback that incorporates explanations, significantly enhancing the learning process. However, delivering such explanatory feedback in real-time poses challenges, particularly when high classification accuracy for domain-specific, nuanced responses is essential. Our study leverages the capabilities of large language models, specifically Generative Pre-Trained Transformers (GPT), to explore a sequence labeling approach focused on identifying components of desired and less desired praise for providing explanatory feedback within a tutor training dataset. Our aim is to equip tutors with actionable, explanatory feedback during online training lessons. To investigate the potential of GPT models for providing the explanatory feedback, we employed two commonly-used approaches: prompting and fine-tuning. To quantify the quality of highlighted praise components identified by GPT models, we introduced a Modified Intersection over Union (M-IoU) score. Our findings demonstrate that: (1) the M-IoU score effectively correlates with human judgment in evaluating sequence quality; (2) using two-shot prompting on GPT-3.5 resulted in decent performance in recognizing effort-based (M-IoU of 0.46) and outcome-based praise (M-IoU of 0.68); and (3) our optimally fine-tuned GPT-3.5 model achieved M-IoU scores of 0.64 for effort-based praise and 0.84 for outcome-based praise, aligning with the satisfaction levels evaluated by human coders. Our results show promise for using GPT models to provide feedback that focuses on specific elements in their open-ended responses that are desirable or could use improvement.",
    "pdf_link": "https://arxiv.org/abs/2405.00291",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00291v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00291/demo_picture.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00291v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00291/tokenization.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00291v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00291/scatter_matrix.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.00291v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00291/RQ2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00291v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00291/scatter_plot_matrix_outcome.jpg"
      }
    ],
    "abstract_cn": "自动化解释性反馈系统对于提升大规模学习者的学习效果至关重要，它通过融入解释的反馈显著提升了学习体验。然而，实时提供此类反馈面临诸多挑战，尤其是在必须确保对特定领域内微妙反应的高分类准确性时。本研究借助大型语言模型，尤其是生成预训练变换器（GPT），采用序列标注方法，旨在从导师培训数据集中辨识出所需和非理想赞扬的要素，以便提供解释性反馈。我们旨在为在线培训课程中的导师提供实用的、有解释性的反馈。为了探究GPT模型在提供解释性反馈方面的潜力，我们采用了两种常用策略：提示和微调。我们还引入了一种改进的交集比对并集（M-IoU）分数，用以量化GPT模型识别出的赞扬要素的质量。研究发现：（1）M-IoU分数与人工评估序列质量的结果高度相关；（2）在GPT-3.5上应用两次提示，对于识别基于努力的赞扬（M-IoU得分0.46）和基于成果的赞扬（M-IoU得分0.68）均表现出良好的性能；（3）我们经过最佳微调的GPT-3.5模型在基于努力的赞扬上达到了0.64的M-IoU得分，在基于成果的赞扬上达到了0.84的M-IoU得分，这与人工编码员评估的满意度水平相吻合。这些结果预示着GPT模型在提供专注于开放式反馈中特定元素的反馈方面具有潜力，这些元素可能是值得提倡的或者有改进空间的。",
    "title_cn": "如何提升自我？利用 GPT 技术凸显开放式回答中的期望与非期望要素。",
    "tags": [
      "LLM应用",
      "教育技术",
      ""
    ]
  },
  {
    "title": "Adversarial Attacks and Defense for Conversation Entailment Task",
    "submit_datetime": "2024年04月30日",
    "abstract": "Large language models (LLMs) that are proved to be very powerful on different NLP tasks. However, there are still many ways to attack the model with very low costs. How to defend the model becomes an important problem. In our work, we treat adversarial attack results as a new (unseen) domain of the model, and we frame the defending problem into how to improve the robustness of the model on the new domain. We focus on the task of conversation entailment, where multi-turn natural language dialogues are the premise, and the transformer model is fine-tuned to predict whether a given hypothesis about the given dialogue is true or false. The adversary would attack the hypothesis to fool the model to make the wrong predictions. We apply synonym-swapping as the attack method. To show the robustness of the model, we implement some fine-tuning strategies and propose the embedding perturbation loss as a method to improve the robustness of the model. Finally, we show the importance of our work by discussing the adversarial attacks in NLP in the real world.",
    "pdf_link": "https://arxiv.org/abs/2405.00289",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）在多种自然语言处理（NLP）任务上展现出强大能力，但它们也面临着低成本攻击的威胁。如何加固这些模型，提升其防御能力，成为了一个亟待解决的问题。本研究将对抗性攻击视为模型面对的一个新领域，并围绕如何增强模型在这一新领域的鲁棒性展开探讨。我们着眼于对话蕴含任务，即以多轮自然语言对话为前提，通过微调变换模型来预测关于对话的给定假设是否成立。攻击者会尝试对假设进行篡改，误导模型做出错误判断。我们采用同义词替换作为攻击手段。为了增强模型的鲁棒性，我们实施了若干微调策略，并引入了嵌入扰动损失方法。最终，我们通过分析自然语言处理领域中的真实对抗性攻击案例，强调了本研究的重要性和实用价值。",
    "title_cn": "对话蕴含任务的对抗性攻击与防御策略",
    "tags": [
      "LLM应用",
      "",
      "对话系统"
    ]
  },
  {
    "title": "Social Life Simulation for Non-Cognitive Skills Learning",
    "submit_datetime": "2024年04月30日",
    "abstract": "Non-cognitive skills are crucial for personal and social life well-being, and such skill development can be supported by narrative-based (e.g., storytelling) technologies. While generative AI enables interactive and role-playing storytelling, little is known about how users engage with and perceive the use of AI in social life simulation for non-cognitive skills learning. To this end, we introduced SimuLife++, an interactive platform enabled by a large language model (LLM). The system allows users to act as protagonists, creating stories with one or multiple AI-based characters in diverse social scenarios. In particular, we expanded the Human-AI interaction to a Human-AI-AI collaboration by including a sage agent, who acts as a bystander to provide users with more insightful perspectives on their choices and conversations. Through a within-subject user study, we found that the inclusion of the sage agent significantly enhanced narrative immersion, according to the narrative transportation scale, leading to more messages, particularly in group chats. Participants' interactions with the sage agent were also associated with significantly higher scores in their perceived motivation, self-perceptions, and resilience and coping, indicating positive impacts on non-cognitive skills reflection. Participants' interview results further explained the sage agent's aid in decision-making, solving ethical dilemmas, and problem-solving; on the other hand, they suggested improvements in user control and balanced responses from multiple characters. We provide design implications on the application of generative AI in narrative solutions for non-cognitive skill development in broader social contexts.",
    "pdf_link": "https://arxiv.org/abs/2405.00273",
    "graphs": [],
    "abstract_cn": "非认知技能对个人和社会福祉至关重要，而叙述性技术（如讲故事）能够助力这类技能的成长。尽管生成性AI开辟了互动式角色扮演故事讲述的新天地，用户如何与AI互动并在社交生活模拟中利用AI进行非认知技能学习仍不甚明了。为此，我们推出了SimuLife++，一个由大型语言模型（LLM）驱动的互动平台，用户在其中扮演主角，与一个或多个AI角色共同编织多样化社交场景中的故事。我们特别引入了一位智者代理，作为旁观者，为用户提供对其选择和对话的更深入见解。通过一项内部用户研究，我们发现智者代理的加入显著提升了叙事沉浸感，根据叙事传输量表，这导致了更多的交流，尤其是在群聊中。参与者与智者代理的互动还与他们感知的动机、自我感知以及韧性和应对能力的显著提升相关，这表明了对非认知技能反思的积极影响。参与者的访谈进一步阐明了智者代理在决策、解决道德困境和问题解决方面的助力；同时，他们提出了关于用户控制和多角色平衡回应的改进建议。我们为在更广泛的社会背景中应用生成性AI以促进非认知技能发展的叙述性解决方案提供了设计启示。",
    "title_cn": "社交生活模拟：非认知技能学习的新途径",
    "tags": [
      "分类：Agent\n\n这篇论文讨论了如何利用大型语言模型（LLM）驱动的互动平台来促进非认知技能的发展。其中，引入了一位智者代理（Agent），作为旁观者为用户提供深入见解。这篇论文主要关注了Agent在互动平台中的作用，以及它如何帮助用户提升叙事沉浸感和非认知技能。因此，这篇论文应该被归类为Agent。",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Clover: Regressive Lightweight Speculative Decoding with Sequential Knowledge",
    "submit_datetime": "2024年04月30日",
    "abstract": "Large language models (LLMs) suffer from low efficiency as the mismatch between the requirement of auto-regressive decoding and the design of most contemporary GPUs. Specifically, billions to trillions of parameters must be loaded to the GPU cache through its limited memory bandwidth for computation, but only a small batch of tokens is actually computed. Consequently, the GPU spends most of its time on memory transfer instead of computation. Recently, parallel decoding, a type of speculative decoding algorithms, is becoming more popular and has demonstrated impressive efficiency improvement in generation. It introduces extra decoding heads to large models, enabling them to predict multiple subsequent tokens simultaneously and verify these candidate continuations in a single decoding step. However, this approach deviates from the training objective of next token prediction used during pre-training, resulting in a low hit rate for candidate tokens. In this paper, we propose a new speculative decoding algorithm, Clover, which integrates sequential knowledge into the parallel decoding process. This enhancement improves the hit rate of speculators and thus boosts the overall efficiency. Clover transmits the sequential knowledge from pre-speculated tokens via the Regressive Connection, then employs an Attention Decoder to integrate these speculated tokens. Additionally, Clover incorporates an Augmenting Block that modifies the hidden states to better align with the purpose of speculative generation rather than next token prediction. The experiment results demonstrate that Clover outperforms the baseline by up to 91% on Baichuan-Small and 146% on Baichuan-Large, respectively, and exceeds the performance of the previously top-performing method, Medusa, by up to 37% on Baichuan-Small and 57% on Baichuan-Large, respectively.",
    "pdf_link": "https://arxiv.org/abs/2405.00263",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）因自回归解码需求与现代GPU设计不匹配，导致效率不高。具体而言，为了计算，必须通过有限的内存带宽将数十亿至数万亿参数加载到GPU缓存中，但实际只处理一小部分令牌，导致GPU在内存传输上耗费的时间远超计算。近期，一种名为并行解码的推测性解码算法因其在生成任务中的显著效率提升而日益受到青睐。该算法通过增加额外的解码头，使得大型模型能够同时预测多个后续令牌，并在单一解码步骤中对这些候选续接进行验证。然而，这种方法与预训练阶段的下一个令牌预测目标有所偏离，从而降低了候选令牌的命中率。本文提出了一种名为Clover的新型推测性解码算法，它将序列知识融入并行解码流程中，有效提升了投机者的命中率及整体效率。Clover通过回归连接传递预推测令牌的序列知识，并利用注意力解码器整合这些推测令牌。此外，Clover还引入了一个增强模块，优化隐藏状态以更好地适应推测生成而非单一令牌预测。实验结果显示，Clover在Baichuan-Small数据集上的性能提升高达91%，在Baichuan-Large数据集上提升高达146%，并且在两个数据集上均超过了之前领先的Medusa方法，分别高出37%和57%。",
    "title_cn": "Clover：一种结合顺序知识，采用回归式轻量级推测性解码的方法。",
    "tags": [
      "LLM理论",
      "",
      "计算效率"
    ]
  },
  {
    "title": "Principled RLHF from Heterogeneous Feedback via Personalization and Preference Aggregation",
    "submit_datetime": "2024年04月30日",
    "abstract": "Reinforcement learning from human feedback (RLHF) has been an effective technique for aligning AI systems with human values, with remarkable successes in fine-tuning large-language models recently. Most existing RLHF paradigms make the underlying assumption that human preferences are relatively homogeneous, and can be encoded by a single reward model. In this paper, we focus on addressing the issues due to the inherent heterogeneity in human preferences, as well as their potential strategic behavior in providing feedback. Specifically, we propose two frameworks to address heterogeneous human feedback in principled ways: personalization-based one and aggregation-based one. For the former, we propose two approaches based on representation learning and clustering, respectively, for learning multiple reward models that trades off the bias (due to preference heterogeneity) and variance (due to the use of fewer data for learning each model by personalization). We then establish sample complexity guarantees for both approaches. For the latter, we aim to adhere to the single-model framework, as already deployed in the current RLHF paradigm, by carefully aggregating diverse and truthful preferences from humans. We propose two approaches based on reward and preference aggregation, respectively: the former utilizes both utilitarianism and Leximin approaches to aggregate individual reward models, with sample complexity guarantees; the latter directly aggregates the human feedback in the form of probabilistic opinions. Under the probabilistic-opinion-feedback model, we also develop an approach to handle strategic human labelers who may bias and manipulate the aggregated preferences with untruthful feedback. Based on the ideas in mechanism design, our approach ensures truthful preference reporting, with the induced aggregation rule maximizing social welfare functions.",
    "pdf_link": "https://arxiv.org/abs/2405.00254",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00254v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00254/x1.png"
      }
    ],
    "abstract_cn": "利用人类反馈进行的强化学习（RLHF）在调整大型语言模型方面取得了显著成就，成为与人类价值观对齐的有效策略。然而，现有RLHF模式通常假设人类偏好是一致的，可以通过单一奖励模型来表达。本文针对人类偏好的多样性和反馈中可能的策略性行为提出挑战，提出了两种原则性框架：个性化和聚合。个性化框架通过表示学习和聚类方法，学习多个奖励模型以平衡偏好多样性带来的偏差和个性化导致的样本方差，同时为这些方法提供了样本复杂度的保证。聚合框架则旨在维持RLHF现行的单模型架构，通过精心整合人类的多元真实偏好。我们提出了基于奖励和偏好聚合的两种方法：前者结合功利主义和Leximin原则来整合个体奖励模型，并确保样本复杂度；后者则直接聚合以概率形式表达的人类反馈。此外，我们针对可能操纵反馈以影响聚合偏好的战略性标签器，开发了一种基于机制设计的方法，确保了偏好的真实报告，并最大化了社会福利。",
    "title_cn": "本文探讨了如何通过个性化定制和偏好聚合的方式，从多样化的反馈中提炼出原则性的人类引导强化学习（RLHF）策略。",
    "tags": [
      "LLM应用",
      "人工智能",
      "机器学习"
    ]
  },
  {
    "title": "CodeHalu: Code Hallucinations in LLMs Driven by Execution-based Verification",
    "submit_datetime": "2024年04月30日",
    "abstract": "Large Language Models (LLMs) have made significant advancements in the field of code generation, offering unprecedented support for automated programming and assisting developers. However, LLMs sometimes generate code that appears plausible but fails to meet the expected requirements or executes incorrectly. This phenomenon of hallucinations in the coding field has not been explored. To advance the community's understanding and research on code hallucinations in LLMs, we propose a definition method for these hallucinations based on execution verification and introduce the concept of code hallucinations for the first time. We categorize code hallucinations into four main types: mapping, naming, resource, and logic hallucinations, each further divided into different subcategories to better understand and address the unique challenges faced by LLMs during code generation. To systematically evaluate code hallucinations, we propose a dynamic detection algorithm for code hallucinations and construct the CodeHalu benchmark, which includes 8,883 samples from 699 tasks, to actively detect hallucination phenomena in LLMs during programming. We tested 16 popular LLMs on this benchmark to evaluate the frequency and nature of their hallucinations during code generation. The findings reveal significant variations in the accuracy and reliability of LLMs in generating code, highlighting the urgent need to improve models and training methods to ensure the functional correctness and safety of automatically generated code. This study not only classifies and quantifies code hallucinations but also provides insights for future improvements in LLM-based code generation research. The CodeHalu benchmark and code are publicly available at https://github.com/yuchen814/CodeHalu.",
    "pdf_link": "https://arxiv.org/abs/2405.00253",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）在代码生成领域取得了重大突破，极大地推动了自动化编程的发展，为开发者提供了强大的辅助。然而，这些模型偶尔会产生看似合理但实际并不符合预期或执行错误的代码，这种现象在编程领域被称为“幻觉”。目前，对于LLMs中的代码幻觉现象尚缺乏深入研究。为了深化对此现象的理解，我们首次提出了一种基于执行验证的代码幻觉定义方法，并定义了代码幻觉的概念。我们将代码幻觉归纳为四大类别：映射、命名、资源和逻辑幻觉，每个类别下又细分为多个子类，以便更精准地识别和应对LLMs在代码生成时所面临的挑战。我们还开发了一种动态检测算法，用于系统性地识别代码幻觉，并构建了CodeHalu基准测试，该测试包含699个任务中的8,883个样本，旨在主动监测LLMs编程时的幻觉现象。通过对16个主流LLMs的测试，我们评估了它们在代码生成中的幻觉频率和特点。研究结果显示，不同LLMs在代码生成的准确性和可靠性上存在显著差异，这强调了提升模型性能和改进训练方法的紧迫性，以确保自动生成代码的正确性和安全性。本研究不仅对代码幻觉进行了分类和量化分析，还为未来LLMs在代码生成领域的研究提供了宝贵的洞见。CodeHalu基准测试和相关代码已在 https://github.com/yuchen814/CodeHalu 上公开发布。",
    "title_cn": "CodeHalu：在执行驱动验证的助力下，大型语言模型中产生的代码幻觉现象。",
    "tags": [
      "LLM应用",
      "",
      "自动化编程"
    ]
  },
  {
    "title": "SemantiCodec: An Ultra Low Bitrate Semantic Audio Codec for General Sound",
    "submit_datetime": "2024年04月30日",
    "abstract": "Large language models (LLMs) have significantly advanced audio processing through audio codecs that convert audio into discrete tokens, enabling the application of language modelling techniques to audio data. However, traditional codecs often operate at high bitrates or within narrow domains such as speech and lack the semantic clues required for efficient language modelling. Addressing these challenges, we introduce SemantiCodec, a novel codec designed to compress audio into fewer than a hundred tokens per second across diverse audio types, including speech, general audio, and music, without compromising quality. SemantiCodec features a dual-encoder architecture: a semantic encoder using a self-supervised AudioMAE, discretized using k-means clustering on extensive audio data, and an acoustic encoder to capture the remaining details. The semantic and acoustic encoder outputs are used to reconstruct audio via a diffusion-model-based decoder. SemantiCodec is presented in three variants with token rates of 25, 50, and 100 per second, supporting a range of ultra-low bit rates between 0.31 kbps and 1.43 kbps. Experimental results demonstrate that SemantiCodec significantly outperforms the state-of-the-art Descript codec on reconstruction quality. Our results also suggest that SemantiCodec contains significantly richer semantic information than all evaluated audio codecs, even at significantly lower bitrates. Our code and demos are available at https://haoheliu.github.io/SemantiCodec/.",
    "pdf_link": "https://arxiv.org/abs/2405.00233",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00233v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00233/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00233v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00233/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00233v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00233/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00233v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00233/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00233v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00233/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00233v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00233/ablation.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）利用音频编解码器将音频转换为离散标记，极大提升了音频处理技术，使得语言建模技术得以应用于音频数据。但现有编解码器多在高比特率下工作，或仅限于如语音这样的特定领域，缺少进行高效语言建模的语义信息。为解决这些问题，我们设计了SemantiCodec，一种创新的编解码器，它能够将多种类型的音频——包括语音、普通音频和音乐——压缩成每秒不到一百个标记，同时保证音质。SemantiCodec具备双重编码器结构：一个是基于自监督AudioMAE的语义编码器，通过在海量音频数据上应用k均值聚类进行离散化；另一个是声学编码器，用于捕捉剩余的音频细节。语义编码器和声学编码器的输出联合使用，通过基于扩散模型的解码器来重建音频。SemantiCodec提供了三种不同标记速率的版本，分别是每秒25、50和100个标记，支持从0.31 kbps到1.43 kbps的超低比特率范围。实验结果显示，SemantiCodec在音频重建质量上明显超越了当前最先进的Descript编解码器。此外，即使在较低的比特率下，SemantiCodec所包含的语义信息量也远超其他所有评估的音频编解码器。我们的代码和演示可以在 https://haoheliu.github.io/SemantiCodec/ 上访问。",
    "title_cn": "SemantiCodec：一款为各类声音设计的超低码率语义音频编解码器。",
    "tags": [
      "分类：LLM应用",
      "音频处理",
      "语言建模"
    ]
  },
  {
    "title": "Aptly: Making Mobile Apps from Natural Language",
    "submit_datetime": "2024年04月30日",
    "abstract": "We present Aptly, an extension of the MIT App Inventor platform enabling mobile app development via natural language powered by code-generating large language models (LLMs). Aptly complements App Inventor's block language with a text language designed to allow visual code generation via text-based LLMs. We detail the technical aspects of how the Aptly server integrates LLMs with a realtime collaboration function to facilitate the automated creation and editing of mobile apps given user instructions. The paper concludes with insights from a study of a pilot implementation involving high school students, which examines Aptly's practicality and user experience. The findings underscore Aptly's potential as a tool that democratizes app development and fosters technological creativity.",
    "pdf_link": "https://arxiv.org/abs/2405.00229",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00229v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00229/architecture-horizontal.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00229v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00229/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00229v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00229/prompt.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.00229v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00229/dutchapp.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00229v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00229/dutchblocks2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00229v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00229/rtc2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00229v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00229/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00229v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00229/x3.png"
      }
    ],
    "abstract_cn": "我们推出了 Aptly，这是 MIT App Inventor 平台的扩展，它利用支持自然语言的大型语言模型（LLMs）来简化移动应用的开发。Aptly 为 App Inventor 的图形化编程语言增添了一种文本语言，旨在通过文本驱动的 LLMs 实现视觉代码的生成。我们深入探讨了 Aptly 服务器如何整合 LLMs 并引入实时协作功能，以便用户能够根据指令自动创建和编辑移动应用。文章最后，通过一项针对高中学生的试点项目研究，我们分享了关于 Aptly 实用性和用户体验的洞见。研究结果突显了 Aptly 在推动应用开发的普及化和技术创造力方面的潜力。",
    "title_cn": "Aptly：将自然语言转化为移动应用的利器",
    "tags": [
      "分类：LLM应用",
      "移动应用开发",
      ""
    ]
  },
  {
    "title": "Constrained Decoding for Secure Code Generation",
    "submit_datetime": "2024年04月30日",
    "abstract": "Code Large Language Models (Code LLMs) have been increasingly used by developers to boost productivity, but they often generate vulnerable code. Thus, there is an urgent need to ensure that code generated by Code LLMs is correct and secure. Previous research has primarily focused on generating secure code, overlooking the fact that secure code also needs to be correct. This oversight can lead to a false sense of security. Currently, the community lacks a method to measure actual progress in this area, and we need solutions that address both security and correctness of code generation.\n  This paper introduces a new benchmark, CodeGuard+, along with two new metrics, secure-pass@k and secure@$k_{\\text{pass}}$, to measure Code LLMs' ability to generate both secure and correct code. Using our new evaluation methods, we show that the state-of-the-art defense technique, prefix tuning, may not be as strong as previously believed, since it generates secure code but sacrifices functional correctness. We also demonstrate that different decoding methods significantly affect the security of Code LLMs.\n  Furthermore, we explore a new defense direction: constrained decoding for secure code generation. We propose new constrained decoding techniques to generate code that satisfies security and correctness constraints simultaneously. Our results reveal that constrained decoding is more effective than prefix tuning to improve the security of Code LLMs, without requiring a specialized training dataset. Moreover, constrained decoding can be used together with prefix tuning to further improve the security of Code LLMs.",
    "pdf_link": "https://arxiv.org/abs/2405.00218",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00218v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00218/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00218v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00218/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00218v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00218/x3.png"
      }
    ],
    "abstract_cn": "开发者日益青睐大型编程语言模型（Code LLMs）以提升工作效率，但这些模型产出的代码往往存在安全隐患。确保Code LLMs产出的代码既正确又安全，成为了一个迫切的议题。过往研究多聚焦于代码的安全性，却忽视了正确性同等重要，这种偏颇可能引发虚假的安全感。目前，业界还缺少一种评估标准来衡量这一领域的实际进步，亟需能够同时保障代码安全性与正确性的解决方案。本论文提出了一个新的基准测试CodeGuard+，以及两项新的评估指标：secure-pass@k和secure@$k_{\\text{pass}}$，用以衡量编程语言模型在生成既安全又准确的代码方面的能力。通过这些新的评估方法，我们发现，尽管目前领先的防御技术——前缀调整能够生成安全的代码，却在功能性正确性上有所妥协，其效力并非先前所认为的那样强大。我们还指出，不同的解码方法对Code LLMs的安全性有着显著的影响。此外，本文还探讨了一个新的防御策略：用于安全代码生成的约束解码。我们提出了新的约束解码技术，能够在不依赖特定训练数据集的情况下，同时满足安全性和正确性的要求。实验结果表明，约束解码在提升Code LLMs安全性方面比前缀调整更为有效。并且，约束解码可以与前缀调整结合使用，进一步提升Code LLMs的安全性。",
    "title_cn": "采用受限解码技术，致力于生成安全的代码。",
    "tags": [
      "LLM应用",
      "编程语言",
      "软件工程"
    ]
  },
  {
    "title": "General Purpose Verification for Chain of Thought Prompting",
    "submit_datetime": "2024年04月30日",
    "abstract": "Many of the recent capabilities demonstrated by Large Language Models (LLMs) arise primarily from their ability to exploit contextual information. In this paper, we explore ways to improve reasoning capabilities of LLMs through (1) exploration of different chains of thought and (2) validation of the individual steps of the reasoning process. We propose three general principles that a model should adhere to while reasoning: (i) Relevance, (ii) Mathematical Accuracy, and (iii) Logical Consistency. We apply these constraints to the reasoning steps generated by the LLM to improve the accuracy of the final generation. The constraints are applied in the form of verifiers: the model itself is asked to verify if the generated steps satisfy each constraint. To further steer the generations towards high-quality solutions, we use the perplexity of the reasoning steps as an additional verifier. We evaluate our method on 4 distinct types of reasoning tasks, spanning a total of 9 different datasets. Experiments show that our method is always better than vanilla generation, and, in 6 out of the 9 datasets, it is better than best-of N sampling which samples N reasoning chains and picks the lowest perplexity generation.",
    "pdf_link": "https://arxiv.org/abs/2405.00204",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/CoT_Fig1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/CoT_fig2_hr.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/GSM8k_sc.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/CSQA_sc.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/BigBenchDate_sc.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/GSM8k_sc_sp.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/CSQA_sc_sp.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/BigBenchDate_sc_sp.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/overall_correlation3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/BigBenchDate_sc.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/CSQA_sc.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/CSQA2.0_sc.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/Strategy_sc.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/Coinflip_sc.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/LastLetter2_sc.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/GSM8k_sc.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/SVAMP_sc.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/AddSub_sc.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/BigBenchDate_sc_src.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/CSQA_sc_src.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/CSQA2.0_sc_src.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/Strategy_sc_src.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/Coinflip_sc_src.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/LastLetter2_sc_src.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/GSM8k_sc_src.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/SVAMP_sc_src.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/AddSub_sc_src.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/GSM8k_sc_sa.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/CSQA_sc_sa.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/BigBenchDate_sc_sa.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/interannotator_agreement-relevance_score.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/interannotator_agreement-mathematical_accuracy_score.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/interannotator_agreement-logical_consistency_score.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/interannotator_agreement-everything_fine.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/correlation-everything_fine_aggregated_verifiers.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/correlation-everything_fine_aggregated_verifiers_and_ppl.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/correlation-logical_consistency.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/correlation-mathematical_accuracy.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/correlation-relevance.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/overall_correlation.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）近期展现的众多能力，很大程度上得益于其对上下文信息的高效利用。本文旨在探讨如何通过探索多样化的思维路径和对推理过程中的各个环节进行验证，来提升LLMs的推理能力。我们提出了三个推理时应遵循的原则：（一）相关性，（二）数学精确性，以及（三）逻辑连贯性。这些原则被转化为对LLM生成的推理步骤的约束，以提高最终结果的准确性。模型需自我验证生成的步骤是否符合这些约束。此外，我们还引入了推理步骤的困惑度作为额外的验证标准，以引导模型朝着更高质量的解决方案发展。我们的方法在四种不同类别的推理任务上进行了测试，涵盖了九个不同的数据集。实验结果表明，我们的方法在所有情况下均优于传统生成方法，在九个数据集中的六个上，其表现也超过了N最佳采样方法，后者通过采样N条推理链并选择困惑度最低的生成结果。",
    "title_cn": "针对思维链提示的通用验证方法",
    "tags": [
      "LLM应用",
      "人工智能",
      ""
    ]
  },
  {
    "title": "SPAFIT: Stratified Progressive Adaptation Fine-tuning for Pre-trained Large Language Models",
    "submit_datetime": "2024年04月30日",
    "abstract": "Full fine-tuning is a popular approach to adapt Transformer-based pre-trained large language models to a specific downstream task. However, the substantial requirements for computational power and storage have discouraged its widespread use. Moreover, increasing evidence of catastrophic forgetting and overparameterization in the Transformer architecture has motivated researchers to seek more efficient fine-tuning (PEFT) methods. Commonly known parameter-efficient fine-tuning methods like LoRA and BitFit are typically applied across all layers of the model. We propose a PEFT method, called Stratified Progressive Adaptation Fine-tuning (SPAFIT), based on the localization of different types of linguistic knowledge to specific layers of the model. Our experiments, conducted on nine tasks from the GLUE benchmark, show that our proposed SPAFIT method outperforms other PEFT methods while fine-tuning only a fraction of the parameters adjusted by other methods.",
    "pdf_link": "https://arxiv.org/abs/2405.00201",
    "graphs": [],
    "abstract_cn": "全参数微调是适配基于 Transformer 的预训练大型语言模型至特定下游任务的常用方法，但其对计算资源和存储空间的巨大需求限制了其普及。Transformer 架构中出现的灾难性遗忘和过参数化问题，促使研究者探索更高效的微调技术。诸如 LoRA 和 BitFit 等常见的参数高效微调技术一般会应用于模型的所有层次。我们提出了一种新的参数高效微调方法——分层渐进适应微调（SPAFIT），它根据语言知识的类型将其定位到模型的特定层次。在 GLUE 基准测试的九项任务中进行的实验显示，SPAFIT 方法在仅微调其他方法调整参数的一小部分的情况下，性能超越了其他参数高效微调方法。",
    "title_cn": "SPAFIT：为预训练的大型语言模型量身定制的分层渐进式微调策略",
    "tags": [
      "分类：LLM理论",
      "",
      "机器学习"
    ]
  },
  {
    "title": "In-Context Learning with Long-Context Models: An In-Depth Exploration",
    "submit_datetime": "2024年04月30日",
    "abstract": "As model context lengths continue to increase, the number of demonstrations that can be provided in-context approaches the size of entire training datasets. We study the behavior of in-context learning (ICL) at this extreme scale on multiple datasets and models. We show that, for many datasets with large label spaces, performance continues to increase with hundreds or thousands of demonstrations. We contrast this with example retrieval and finetuning: example retrieval shows excellent performance at low context lengths but has diminished gains with more demonstrations; finetuning is more data hungry than ICL but can sometimes exceed long-context ICL performance with additional data. We use this ICL setting as a testbed to study several properties of both in-context learning and long-context models. We show that long-context ICL is less sensitive to random input shuffling than short-context ICL, that grouping of same-label examples can negatively impact performance, and that the performance boosts we see do not arise from cumulative gain from encoding many examples together. We conclude that although long-context ICL can be surprisingly effective, most of this gain comes from attending back to similar examples rather than task learning.",
    "pdf_link": "https://arxiv.org/abs/2405.00200",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x20.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x21.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x22.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x23.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x24.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x25.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x26.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x27.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x28.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x29.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x30.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x31.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x32.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x33.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x34.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x35.png"
      }
    ],
    "abstract_cn": "随着模型能够处理的上下文长度增加，能够在上下文中展示的示例数量逐渐逼近整个训练集的规模。我们在不同数据集和模型上探究了在这种极端规模下的上下文内学习（ICL）的表现。研究发现，在拥有广泛标签空间的众多数据集中，性能随着数百至数千个示例的增加而持续提升。这一现象与示例检索和微调的效果形成鲜明对比：示例检索在较短上下文长度时效果显著，但随着示例数量增加，其增益逐渐减少；而微调虽然对数据的需求超过ICL，但在引入更多数据后，有时能超越长上下文ICL的表现。我们利用ICL的这一设置，深入研究了上下文内学习和长上下文模型的多个特性。我们发现，长上下文ICL对随机输入顺序的干扰更为不敏感，同标签示例的集中可能对性能产生负面影响，而我们观察到的性能提升并非源自于同时编码多个示例的累积效应。综上所述，尽管长上下文ICL的效果出人意料地好，但其主要优势更多来自于对类似示例的回顾，而非对任务本身的学习。",
    "title_cn": "深入探索长文本上下文模型中的上下文内学习",
    "tags": [
      "LLM理论",
      "机器学习",
      "人工智能"
    ]
  },
  {
    "title": "Towards a Search Engine for Machines: Unified Ranking for Multiple Retrieval-Augmented Large Language Models",
    "submit_datetime": "2024年04月30日",
    "abstract": "This paper introduces uRAG--a framework with a unified retrieval engine that serves multiple downstream retrieval-augmented generation (RAG) systems. Each RAG system consumes the retrieval results for a unique purpose, such as open-domain question answering, fact verification, entity linking, and relation extraction. We introduce a generic training guideline that standardizes the communication between the search engine and the downstream RAG systems that engage in optimizing the retrieval model. This lays the groundwork for us to build a large-scale experimentation ecosystem consisting of 18 RAG systems that engage in training and 18 unknown RAG systems that use the uRAG as the new users of the search engine. Using this experimentation ecosystem, we answer a number of fundamental research questions that improve our understanding of promises and challenges in developing search engines for machines.",
    "pdf_link": "https://arxiv.org/abs/2405.00175",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00175v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00175/overview.drawio.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00175v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00175/overview-framework.drawio.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00175v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00175/performance_plot_amount_data.png"
      }
    ],
    "abstract_cn": "本文提出了 uRAG，这是一个集成了统一检索引擎的框架，能够支持多个下游的检索增强生成（RAG）系统。这些系统根据各自的需求，如开放域问答、事实核查、实体链接和关系抽取，来利用检索结果。我们引入了一套通用的训练指导原则，以规范搜索引擎与下游 RAG 系统之间的互动，这些系统都在致力于优化检索模型。这为构建一个包含 18 个参与训练的 RAG 系统和 18 个作为搜索引擎新用户的未知 RAG 系统的大规模实验生态系统奠定了基础。通过这个生态系统，我们探讨并回答了一系列基本的研究问题，从而深化了我们对机器搜索引擎开发中机遇与挑战的认识。",
    "title_cn": "探索机器的搜索引擎：实现多种增强检索的大型语言模型的统一排名机制",
    "tags": [
      "RAG",
      "信息检索",
      ""
    ]
  },
  {
    "title": "GUing: A Mobile GUI Search Engine using a Vision-Language Model",
    "submit_datetime": "2024年04月30日",
    "abstract": "App developers use the Graphical User Interface (GUI) of other apps as an important source of inspiration to design and improve their own apps. In recent years, research suggested various approaches to retrieve GUI designs that fit a certain text query from screenshot datasets acquired through automated GUI exploration. However, such text-to-GUI retrieval approaches only leverage the textual information of the GUI elements in the screenshots, neglecting visual information such as icons or background images. In addition, the retrieved screenshots are not steered by app developers and often lack important app features, e.g. whose UI pages require user authentication. To overcome these limitations, this paper proposes GUing, a GUI search engine based on a vision-language model called UIClip, which we trained specifically for the app GUI domain. For this, we first collected app introduction images from Google Play, which usually display the most representative screenshots selected and often captioned (i.e. labeled) by app vendors. Then, we developed an automated pipeline to classify, crop, and extract the captions from these images. This finally results in a large dataset which we share with this paper: including 303k app screenshots, out of which 135k have captions. We used this dataset to train a novel vision-language model, which is, to the best of our knowledge, the first of its kind in GUI retrieval. We evaluated our approach on various datasets from related work and in manual experiment. The results demonstrate that our model outperforms previous approaches in text-to-GUI retrieval achieving a Recall@10 of up to 0.69 and a HIT@10 of 0.91. We also explored the performance of UIClip for other GUI tasks including GUI classification and Sketch-to-GUI retrieval with encouraging results.",
    "pdf_link": "https://arxiv.org/abs/2405.00145",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00145v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00145/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00145v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00145/surrounded-img.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00145v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00145/screenshot-img.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00145v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00145/irrelevant-img.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00145v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00145/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00145v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00145/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00145v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00145/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00145v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00145/evaluation-tool.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00145v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00145/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00145v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00145/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00145v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00145/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00145v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00145/x8.png"
      }
    ],
    "abstract_cn": "应用开发者常以他人应用的图形用户界面（GUI）为灵感，来设计和优化自己的应用。近期研究提出了多种方法，从自动化获取的截图数据库中检索出与特定文本查询相匹配的GUI设计。但这些方法往往只关注GUI元素的文本信息，而忽略了图标、背景图等视觉信息。此外，检索出的截图往往缺乏关键应用特性，如用户认证所需的UI页面。为解决这些问题，本文介绍了GUing，这是一款基于专为应用GUI领域训练的视觉-语言模型UIClip的GUI搜索引擎。我们首先从Google Play获取了应用介绍图，这些图通常包含由开发者精选并标注的代表性截图。接着，我们建立了一个自动化流程，对这些图片进行分类、裁剪并提取标注。这一过程产生了一个包含303k应用截图的大型数据集，其中135k张附有标注，我们在此文中公开了这一数据集。利用该数据集，我们训练了一种新的视觉-语言模型，据我们所知，这是GUI检索领域的首创。我们在相关研究的数据集上进行了评估，并进行了手动实验，结果表明我们的模型在文本到GUI检索任务上超越了先前方法，Recall@10达到了0.69，HIT@10达到了0.91。此外，我们还探索了UIClip在GUI分类和草图到GUI检索等其他GUI任务上的表现，结果同样令人振奋。",
    "title_cn": "GUing：一款运用视觉-语言模型的移动界面图形搜索引擎。",
    "tags": [
      "分类：LLM应用\n\n这篇论文的摘要描述了一个基于视觉-语言模型的GUI搜索引擎，该模型专门针对应用GUI领域进行了训练。它从Google Play获取应用介绍图，并使用自动化流程对这些图片进行分类、裁剪并提取标注，从而创建了一个大型数据集。这个数据集被用来训练新的视觉-语言模型，该模型在文本到GUI检索任务上超越了先前的方法。这篇论文的重点是将大型语言模型（LLM）应用于GUI检索任务，因此它属于LLM应用类别。",
      "应用开发",
      "视觉搜索引擎"
    ]
  },
  {
    "title": "Creative Beam Search",
    "submit_datetime": "2024年04月30日",
    "abstract": "Large language models are revolutionizing several areas, including artificial creativity. However, the process of generation in machines profoundly diverges from that observed in humans. In particular, machine generation is characterized by a lack of intentionality and an underlying creative process. We propose a method called Creative Beam Search that uses Diverse Beam Search and LLM-as-a-Judge to perform response generation and response validation. The results of a qualitative experiment show how our approach can provide better output than standard sampling techniques. We also show that the response validation step is a necessary complement to the response generation step.",
    "pdf_link": "https://arxiv.org/abs/2405.00099",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00099v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00099/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00099v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00099/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00099v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00099/x3.png"
      }
    ],
    "abstract_cn": "大型语言模型正引领着人工创造力等多个领域的革新浪潮。不过，机器的生成机制与人类的创造性过程大相径庭，尤其缺乏意图性和深层次的创造过程。我们引入了一种创新的“创意束搜索”方法，该方法结合了多样化束搜索和“语言模型评委”技术，用于执行生成和验证响应。一项定性实验的结果显示，相较于传统的采样技术，我们的策略能够产出更优质的结果。此外，我们还证实了响应验证环节对于响应生成环节的重要性，它是一个不可或缺的补充。",
    "title_cn": "创意束搜索",
    "tags": [
      "LLM应用",
      "人工智能",
      "创意生成"
    ]
  },
  {
    "title": "ECC Analyzer: Extract Trading Signal from Earnings Conference Calls using Large Language Model for Stock Performance Prediction",
    "submit_datetime": "2024年04月29日",
    "abstract": "In the realm of financial analytics, leveraging unstructured data, such as earnings conference calls (ECCs), to forecast stock performance is a critical challenge that has attracted both academics and investors. While previous studies have used deep learning-based models to obtain a general view of ECCs, they often fail to capture detailed, complex information. Our study introduces a novel framework: \\textbf{ECC Analyzer}, combining Large Language Models (LLMs) and multi-modal techniques to extract richer, more predictive insights. The model begins by summarizing the transcript's structure and analyzing the speakers' mode and confidence level by detecting variations in tone and pitch for audio. This analysis helps investors form an overview perception of the ECCs. Moreover, this model uses the Retrieval-Augmented Generation (RAG) based methods to meticulously extract the focuses that have a significant impact on stock performance from an expert's perspective, providing a more targeted analysis. The model goes a step further by enriching these extracted focuses with additional layers of analysis, such as sentiment and audio segment features. By integrating these insights, the ECC Analyzer performs multi-task predictions of stock performance, including volatility, value-at-risk (VaR), and return for different intervals. The results show that our model outperforms traditional analytic benchmarks, confirming the effectiveness of using advanced LLM techniques in financial analytics.",
    "pdf_link": "https://arxiv.org/abs/2404.18470",
    "graphs": [],
    "abstract_cn": "在金融分析界，运用诸如收益电话会议（ECCs）这类非结构化数据来预测股票走势，是一个至关重要且充满挑战的任务，它不仅吸引了学术界的目光，也引起了投资者的广泛关注。尽管先前的研究已经借助基于深度学习的模型对ECCs进行了概览性分析，但这些研究往往忽略了更为细致和复杂的信息。本研究提出了一个创新的框架——\\textbf{ECC分析器}，它融合了大型语言模型（LLMs）和多模态技术，以提取更深层次、更具前瞻性的洞见。该模型首先通过分析音频中的音调和音高变化，来概括通话记录的结构，并评估发言者的态度和信心水平，帮助投资者构建对ECCs的宏观理解。此外，模型采用基于检索增强生成（RAG）的方法，细致地筛选出从专家视角看对股票表现有显著影响的关键点，进行更为精准的分析。模型不止步于此，它还通过情感分析和音频片段特征等更多层次的分析，进一步丰富了这些关键点。通过综合这些洞见，ECC分析器能够对股票表现进行多任务预测，包括波动性、风险价值（VaR）和不同时间间隔的回报。研究结果表明，我们的模型在性能上超越了传统分析方法，验证了在金融分析中应用高级LLM技术的有效性。",
    "title_cn": "ECC分析器：利用大型语言模型分析收益电话会议，从中提取交易信号，以预测股票市场表现。",
    "tags": [
      "LLM应用",
      "金融分析",
      "多模态技术"
    ]
  },
  {
    "title": "Reinforcement Learning Problem Solving with Large Language Models",
    "submit_datetime": "2024年04月29日",
    "abstract": "Large Language Models (LLMs) encapsulate an extensive amount of world knowledge, and this has enabled their application in various domains to improve the performance of a variety of Natural Language Processing (NLP) tasks. This has also facilitated a more accessible paradigm of conversation-based interactions between humans and AI systems to solve intended problems. However, one interesting avenue that shows untapped potential is the use of LLMs as Reinforcement Learning (RL) agents to enable conversational RL problem solving. Therefore, in this study, we explore the concept of formulating Markov Decision Process-based RL problems as LLM prompting tasks. We demonstrate how LLMs can be iteratively prompted to learn and optimize policies for specific RL tasks. In addition, we leverage the introduced prompting technique for episode simulation and Q-Learning, facilitated by LLMs. We then show the practicality of our approach through two detailed case studies for \"Research Scientist\" and \"Legal Matter Intake\" workflows.",
    "pdf_link": "https://arxiv.org/abs/2404.18638",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）汇聚了丰富的世界知识，广泛应用于提升自然语言处理（NLP）任务的效率，并简化了人与AI系统间的对话式交互，以解决特定问题。一个充满潜力但尚未充分挖掘的领域是将LLMs作为强化学习（RL）智能体，用于会话式的RL问题解决。在本研究中，我们探讨了将基于马尔可夫决策过程的RL问题转化为LLMs的提示任务。我们展示了如何逐步引导LLMs学习并优化特定RL任务的策略，并利用这种提示技术，通过LLMs实现了情节模拟和Q-Learning。我们通过“研究科学家”和“法律事项接收”两个案例研究，展示了我们方法的实用性和效果。",
    "title_cn": "通过大型语言模型来解决强化学习的问题",
    "tags": [
      "分类：Agent",
      "",
      ""
    ]
  },
  {
    "title": "Anywhere: A Multi-Agent Framework for Reliable and Diverse Foreground-Conditioned Image Inpainting",
    "submit_datetime": "2024年04月29日",
    "abstract": "Recent advancements in image inpainting, particularly through diffusion modeling, have yielded promising outcomes. However, when tested in scenarios involving the completion of images based on the foreground objects, current methods that aim to inpaint an image in an end-to-end manner encounter challenges such as \"over-imagination\", inconsistency between foreground and background, and limited diversity. In response, we introduce Anywhere, a pioneering multi-agent framework designed to address these issues. Anywhere utilizes a sophisticated pipeline framework comprising various agents such as Visual Language Model (VLM), Large Language Model (LLM), and image generation models. This framework consists of three principal components: the prompt generation module, the image generation module, and the outcome analyzer. The prompt generation module conducts a semantic analysis of the input foreground image, leveraging VLM to predict relevant language descriptions and LLM to recommend optimal language prompts. In the image generation module, we employ a text-guided canny-to-image generation model to create a template image based on the edge map of the foreground image and language prompts, and an image refiner to produce the outcome by blending the input foreground and the template image. The outcome analyzer employs VLM to evaluate image content rationality, aesthetic score, and foreground-background relevance, triggering prompt and image regeneration as needed. Extensive experiments demonstrate that our Anywhere framework excels in foreground-conditioned image inpainting, mitigating \"over-imagination\", resolving foreground-background discrepancies, and enhancing diversity. It successfully elevates foreground-conditioned image inpainting to produce more reliable and diverse results.",
    "pdf_link": "https://arxiv.org/abs/2404.18598",
    "graphs": [],
    "abstract_cn": "图像修复技术的最新进展，尤其是扩散模型的应用，已经带来了令人鼓舞的成果。但在基于前景对象完成图像的场景下，现有端到端图像修复方法面临诸多挑战，如过度想象、前景背景不一致和多样性不足。为此，我们推出了Anywhere，这是一个创新的多代理框架，专门设计来应对这些挑战。Anywhere采用了一个包含视觉语言模型（VLM）、大型语言模型（LLM）和图像生成模型的复杂流水线框架。该框架包括三个核心组件：提示生成模块、图像生成模块和结果分析器。提示生成模块通过VLM进行语义分析，预测相关语言描述，并利用LLM推荐最佳语言提示。图像生成模块使用文本引导的canny到图像生成模型，基于前景图像的边缘图和语言提示创建模板图像，并通过图像细化器融合输入前景和模板图像生成最终结果。结果分析器利用VLM评估图像内容的合理性、审美评分和前景背景的相关性，并在必要时触发提示和图像的重新生成。大量实验证明，Anywhere框架在前景条件图像修复任务上表现卓越，有效减少了过度想象，解决了前景背景不一致的问题，并提升了结果的多样性。它成功地推动了前景条件图像修复技术的发展，产生了更可靠和多样化的图像修复结果。",
    "title_cn": "Anywhere：一种多智能体框架，旨在实现可靠且多样化的前景条件图像修复",
    "tags": [
      "Agent",
      "图像处理",
      "人工智能"
    ]
  },
  {
    "title": "Injecting Salesperson's Dialogue Strategies in Large Language Models with Chain-of-Thought Reasoning",
    "submit_datetime": "2024年04月29日",
    "abstract": "Recent research in dialogue systems and corpora has focused on two main categories: task-oriented (TOD) and open-domain (chit-chat) dialogues. TOD systems help users accomplish specific tasks, while open-domain systems aim to create engaging conversations. However, in real-world scenarios, user intents are often revealed during interactions. A recent study introduced SalesBot, which simulates dialogues transitioning from chit-chat to task-oriented scenarios to train sales agents. Unfortunately, the initial data lacked smooth transitions and coherent long-turn dialogues, resulting in poor naturalness in sales-customer interactions. To address these issues, this paper presents SalesBot 2.0, an improved dataset. It leverages commonsense knowledge from large language models (LLMs) through strategic prompting. Additionally, we introduce a novel model called SalesAgent, trained on salesperson's interactions, using chain-of-thought (CoT) reasoning. This model excels in transitioning topics, understanding user intents, and selecting appropriate strategies. Experiments using diverse user simulations validate the effectiveness of our method in controlling dialogue strategies in LLMs. Furthermore, SalesBot 2.0 enhances coherence and reduces aggression, facilitating better model learning for sales-customer interactions.",
    "pdf_link": "https://arxiv.org/abs/2404.18564",
    "graphs": [],
    "abstract_cn": "近期对话系统研究主要分为两大类：任务导向型（TOD）和开放领域（如闲聊）对话。TOD系统致力于协助用户完成特定任务，而开放领域系统则更注重营造引人入胜的对话体验。但在现实情境中，用户的真实意图往往是在交流过程中逐步显现。最近的一项研究推出了SalesBot，这是一个模拟从闲聊向任务导向场景过渡的对话系统，用以培养销售人才。然而，初始数据集在过渡自然度和长对话连贯性方面存在不足，影响了销售与客户之间的互动流畅性。为改善这些问题，本文提出了升级版的SalesBot 2.0数据集，它通过精心设计的提示，借助大型语言模型（LLMs）中的常识知识。同时，我们还引入了一个创新模型——SalesAgent，该模型基于销售人员的互动数据，采用思维链（CoT）推理方法进行训练。SalesAgent在话题转换、用户意图理解以及策略选择上表现出色。通过多样化用户模拟的实验，我们验证了该方法在LLMs中控制对话策略的有效性。SalesBot 2.0不仅提升了对话的连贯性，还减少了冲突性，有助于提高销售与客户互动的模型学习效果。",
    "title_cn": "将销售员的对话策略融入大型语言模型，并运用思维链推理，这一方法对于增强模型处理复杂对话任务的能力至关重要。",
    "tags": [
      "Agent",
      "对话系统",
      ""
    ]
  },
  {
    "title": "AI-powered Code Review with LLMs: Early Results",
    "submit_datetime": "2024年04月29日",
    "abstract": "In this paper, we present a novel approach to improving software quality and efficiency through a Large Language Model (LLM)-based model designed to review code and identify potential issues. Our proposed LLM-based AI agent model is trained on large code repositories. This training includes code reviews, bug reports, and documentation of best practices. It aims to detect code smells, identify potential bugs, provide suggestions for improvement, and optimize the code. Unlike traditional static code analysis tools, our LLM-based AI agent has the ability to predict future potential risks in the code. This supports a dual goal of improving code quality and enhancing developer education by encouraging a deeper understanding of best practices and efficient coding techniques. Furthermore, we explore the model's effectiveness in suggesting improvements that significantly reduce post-release bugs and enhance code review processes, as evidenced by an analysis of developer sentiment toward LLM feedback. For future work, we aim to assess the accuracy and efficiency of LLM-generated documentation updates in comparison to manual methods. This will involve an empirical study focusing on manually conducted code reviews to identify code smells and bugs, alongside an evaluation of best practice documentation, augmented by insights from developer discussions and code reviews. Our goal is to not only refine the accuracy of our LLM-based tool but also to underscore its potential in streamlining the software development lifecycle through proactive code improvement and education.",
    "pdf_link": "https://arxiv.org/abs/2404.18496",
    "graphs": [],
    "abstract_cn": "本文介绍了一种创新方法，利用大型语言模型（LLM）为基础的人工智能（AI）代理来提升软件质量和效能。该AI代理经过在庞大代码库上的培训，涵盖代码审查、缺陷报告和最佳实践文档，旨在识别代码异味、潜在缺陷，提供优化建议，并对代码进行优化。与传统静态代码分析工具相比，我们的LLM-AI代理能够预见代码中的未来风险，旨在提升代码品质和增进开发者对最佳实践与高效编码技巧的理解。此外，本研究还探讨了该模型在减少发布后缺陷和提升代码审查流程方面的建议效果，这一点通过分析开发者对LLM反馈的情绪得到了证实。展望未来，我们计划评估LLM生成的文档更新的准确性和效率，并与手工方法进行比较。这包括一项实证研究，专注于手工代码审查以识别代码异味和缺陷，同时评估最佳实践文档，并结合开发者讨论和代码审查的洞见。我们的目标是提升LLM工具的准确性，并强调其在通过预防性代码改进和教育来优化软件开发生命周期中的潜力。",
    "title_cn": "AI 助力代码审查：大型语言模型的初步成效",
    "tags": [
      "Agent",
      "软件工程",
      "人工智能"
    ]
  },
  {
    "title": "Hallucination of Multimodal Large Language Models: A Survey",
    "submit_datetime": "2024年04月29日",
    "abstract": "This survey presents a comprehensive analysis of the phenomenon of hallucination in multimodal large language models (MLLMs), also known as Large Vision-Language Models (LVLMs), which have demonstrated significant advancements and remarkable abilities in multimodal tasks. Despite these promising developments, MLLMs often generate outputs that are inconsistent with the visual content, a challenge known as hallucination, which poses substantial obstacles to their practical deployment and raises concerns regarding their reliability in real-world applications. This problem has attracted increasing attention, prompting efforts to detect and mitigate such inaccuracies. We review recent advances in identifying, evaluating, and mitigating these hallucinations, offering a detailed overview of the underlying causes, evaluation benchmarks, metrics, and strategies developed to address this issue. Additionally, we analyze the current challenges and limitations, formulating open questions that delineate potential pathways for future research. By drawing the granular classification and landscapes of hallucination causes, evaluation benchmarks, and mitigation methods, this survey aims to deepen the understanding of hallucinations in MLLMs and inspire further advancements in the field. Through our thorough and in-depth review, we contribute to the ongoing dialogue on enhancing the robustness and reliability of MLLMs, providing valuable insights and resources for researchers and practitioners alike. Resources are available at: https://github.com/showlab/Awesome-MLLM-Hallucination.",
    "pdf_link": "https://arxiv.org/abs/2404.18930",
    "graphs": [],
    "abstract_cn": "本篇综述深入探讨了多模态大型语言模型（MLLMs），亦称为大型视觉-语言模型（LVLMs），在多模态任务中虽取得显著进步，却常产生与视觉信息不符的幻觉现象，这一问题严重阻碍了它们的实际应用，并引发了对其在现实世界中可靠性的质疑。对此问题的关注日益增加，研究者们正努力识别和减轻这些幻觉。本文综述了识别、评估和缓解幻觉的最新进展，详细分析了幻觉的成因、评估标准、度量指标以及应对策略。同时，我们剖析了当前面临的挑战与限制，提出了未来研究可能的研究方向。本研究旨在通过细致的分类和分析幻觉成因、评估基准和缓解方法，深化对 MLLMs 中幻觉现象的理解，并推动该领域的进一步发展。我们的深入分析为提升 MLLMs 的鲁棒性和可信度提供了丰富的洞见和资源，为研究人员和实践者提供了宝贵的参考。相关资源可在 https://github.com/showlab/Awesome-MLLM-Hallucination 查看。",
    "title_cn": "多模态大型语言模型幻觉现象研究综述",
    "tags": [
      "分类：LLM理论",
      "计算机视觉",
      ""
    ]
  },
  {
    "title": "MileBench: Benchmarking MLLMs in Long Context",
    "submit_datetime": "2024年04月29日",
    "abstract": "Despite the advancements and impressive performance of Multimodal Large Language Models (MLLMs) on benchmarks, their effectiveness in real-world, long-context, and multi-image tasks is unclear due to the benchmarks' limited scope. Existing benchmarks often focus on single-image and short-text samples, and when assessing multi-image tasks, they either limit the image count or focus on specific task (e.g time-series captioning), potentially obscuring the performance challenges of MLLMs. To address these limitations, we introduce MileBench, a pioneering benchmark designed to test the MultImodal Long-contExt capabilities of MLLMs. This benchmark comprises not only multimodal long contexts, but also multiple tasks requiring both comprehension and generation. We establish two distinct evaluation sets, diagnostic and realistic, to systematically assess MLLMs' long-context adaptation capacity and their ability to complete tasks in long-context scenarios. Our experimental results, obtained from testing 20 models, revealed that while the closed-source GPT-4(Vision) and Gemini 1.5 outperform others, most open-source MLLMs struggle in long-context situations. Interestingly, the performance gap tends to widen with an increase in the number of images. We strongly encourage an intensification of research efforts towards enhancing MLLMs' long-context capabilities, especially in scenarios involving multiple images.",
    "pdf_link": "https://arxiv.org/abs/2404.18532",
    "graphs": [],
    "abstract_cn": "尽管多模态大型语言模型（MLLMs）在标准测试中表现卓越，但其在现实世界中的长文本、多图像任务中的表现尚不明确，因为现有测试往往局限于单一图像和短文本。为了克服这一局限，我们推出了MileBench，这是一个创新的评估工具，专门用于检验MLLMs处理多模态长文本的能力。MileBench包含多模态长文本和多样化任务，旨在全面测试模型的理解与生成能力。我们设计了诊断性和现实性两套评估体系，以系统化地评价MLLMs对长文本的适应性和在长文本环境中的任务完成能力。通过对20种模型的测试，我们发现尽管闭源的GPT-4(Vision)和Gemini 1.5领先于其他模型，但大多数开源MLLMs在处理长文本时仍面临挑战。特别值得注意的是，图像数量的增加会导致性能差异更加显著。我们强烈建议学术界和工业界加大研究力度，以提升MLLMs在长文本处理上的能力，特别是在多图像环境中的应用。",
    "title_cn": "MileBench：长文本场景下的大型机器学习语言模型性能评估",
    "tags": [
      "LLM应用",
      "人工智能",
      "机器学习"
    ]
  },
  {
    "title": "From ChatGPT, DALL-E 3 to Sora: How has Generative AI Changed Digital Humanities Research and Services?",
    "submit_datetime": "2024年04月29日",
    "abstract": "Generative large-scale language models create the fifth paradigm of scientific research, organically combine data science and computational intelligence, transform the research paradigm of natural language processing and multimodal information processing, promote the new trend of AI-enabled social science research, and provide new ideas for digital humanities research and application. This article profoundly explores the application of large-scale language models in digital humanities research, revealing their significant potential in ancient book protection, intelligent processing, and academic innovation. The article first outlines the importance of ancient book resources and the necessity of digital preservation, followed by a detailed introduction to developing large-scale language models, such as ChatGPT, and their applications in document management, content understanding, and cross-cultural research. Through specific cases, the article demonstrates how AI can assist in the organization, classification, and content generation of ancient books. Then, it explores the prospects of AI applications in artistic innovation and cultural heritage preservation. Finally, the article explores the challenges and opportunities in the interaction of technology, information, and society in the digital humanities triggered by AI technologies.",
    "pdf_link": "https://arxiv.org/abs/2404.18518",
    "graphs": [],
    "abstract_cn": "大规模语言模型催生了科研的第五范式，它融合了数据科学与计算智能，革新了自然语言处理和多模态信息处理的研究范式，并为社会科学研究注入了AI的新动力，同时也为数字人文研究带来了创新思维。本文深入探讨了这些模型在数字人文领域的应用，突出了它们在古籍保护、智能化处理和学术创新上的重要作用。文章首先强调了古籍资源的价值及其数字化保存的紧迫性，接着深入介绍了如ChatGPT这样的大规模语言模型的开发及其在文档管理、内容理解和跨文化交流中的应用。通过实际案例，文章展示了AI如何在古籍的整理、分类和内容创作中发挥作用。文章还展望了AI在艺术创新和文化传承中的可能性，并最终探讨了AI技术在数字人文领域中引发的技术、信息与社会互动的挑战与机遇。",
    "title_cn": "ChatGPT、DALL-E 3 和 Sora 等生成性人工智能技术，已经如何重塑了数字人文学科的研究方向和服务模式？",
    "tags": [
      "LLM应用",
      "数字人文",
      "人工智能"
    ]
  },
  {
    "title": "DPO Meets PPO: Reinforced Token Optimization for RLHF",
    "submit_datetime": "2024年04月29日",
    "abstract": "In the classical Reinforcement Learning from Human Feedback (RLHF) framework, Proximal Policy Optimization (PPO) is employed to learn from sparse, sentence-level rewards -- a challenging scenario in traditional deep reinforcement learning. Despite the great successes of PPO in the alignment of state-of-the-art closed-source large language models (LLMs), its open-source implementation is still largely sub-optimal, as widely reported by numerous research studies. To address these issues, we introduce a framework that models RLHF problems as a Markov decision process (MDP), enabling the capture of fine-grained token-wise information. Furthermore, we provide theoretical insights that demonstrate the superiority of our MDP framework over the previous sentence-level bandit formulation. Under this framework, we introduce an algorithm, dubbed as Reinforced Token Optimization (\\texttt{RTO}), which learns the token-wise reward function from preference data and performs policy optimization based on this learned token-wise reward signal. Theoretically, \\texttt{RTO} is proven to have the capability of finding the near-optimal policy sample-efficiently. For its practical implementation, \\texttt{RTO} innovatively integrates Direct Preference Optimization (DPO) and PPO. DPO, originally derived from sparse sentence rewards, surprisingly provides us with a token-wise characterization of response quality, which is seamlessly incorporated into our subsequent PPO training stage. Extensive real-world alignment experiments verify the effectiveness of the proposed approach.",
    "pdf_link": "https://arxiv.org/abs/2404.18922",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.18922v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18922/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18922v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18922/x2.png"
      }
    ],
    "abstract_cn": "在传统的基于人类反馈的强化学习框架内，近端策略优化（PPO）面临从稀疏句子级奖励中学习的挑战。尽管PPO在调整顶尖闭源大型语言模型方面取得了显著成就，但其开源版本的表现往往不尽如人意，这一点已在多项研究中被指出。为克服这些难题，我们提出了一个新的框架，将RLHF问题视为马尔可夫决策过程，以捕捉更细致的标记级信息。我们还从理论上展示了该MDP框架相较于传统基于句子的强盗模型的优越性。在此框架基础上，我们开发了一种名为强化标记优化（RTO）的算法，该算法能够从偏好数据中学习标记级的奖励函数，并通过这些学习到的标记级奖励信号进行策略优化。理论上，RTO已被证实能够有效地找到近似最优策略。在实际应用中，RTO创新地融合了直接偏好优化（DPO）与PPO，DPO从稀疏句子奖励中提取出标记级的质量特征，并在我们的PPO训练阶段中得到有效利用。广泛的实际对齐实验证明了我们方法的有效性。",
    "title_cn": "DPO 邂逅 PPO：在强化学习框架下，为人类偏好的令牌优化注入动力",
    "tags": [
      "LLM应用",
      "",
      ""
    ]
  },
  {
    "title": "TheaterGen: Character Management with LLM for Consistent Multi-turn Image Generation",
    "submit_datetime": "2024年04月29日",
    "abstract": "Recent advances in diffusion models can generate high-quality and stunning images from text. However, multi-turn image generation, which is of high demand in real-world scenarios, still faces challenges in maintaining semantic consistency between images and texts, as well as contextual consistency of the same subject across multiple interactive turns. To address this issue, we introduce TheaterGen, a training-free framework that integrates large language models (LLMs) and text-to-image (T2I) models to provide the capability of multi-turn image generation. Within this framework, LLMs, acting as a \"Screenwriter\", engage in multi-turn interaction, generating and managing a standardized prompt book that encompasses prompts and layout designs for each character in the target image. Based on these, Theatergen generate a list of character images and extract guidance information, akin to the \"Rehearsal\". Subsequently, through incorporating the prompt book and guidance information into the reverse denoising process of T2I diffusion models, Theatergen generate the final image, as conducting the \"Final Performance\". With the effective management of prompt books and character images, TheaterGen significantly improves semantic and contextual consistency in synthesized images. Furthermore, we introduce a dedicated benchmark, CMIGBench (Consistent Multi-turn Image Generation Benchmark) with 8000 multi-turn instructions. Different from previous multi-turn benchmarks, CMIGBench does not define characters in advance. Both the tasks of story generation and multi-turn editing are included on CMIGBench for comprehensive evaluation. Extensive experimental results show that TheaterGen outperforms state-of-the-art methods significantly. It raises the performance bar of the cutting-edge Mini DALLE 3 model by 21% in average character-character similarity and 19% in average text-image similarity.",
    "pdf_link": "https://arxiv.org/abs/2404.18919",
    "graphs": [],
    "abstract_cn": "最新进展的扩散模型能够根据文本创作出高品质且引人注目的图像。但在现实世界中需求强烈的多轮次图像生成任务中，保持图像与文本之间的语义连贯性以及同一主题在连续交互中的上下文连贯性，仍然是一大挑战。为应对这一挑战，我们推出了TheaterGen——一个无需训练的框架，它结合了大型语言模型（LLMs）与文本到图像（T2I）模型，以实现多轮次图像生成。在这个框架中，LLMs充当“编剧”，进行多轮互动，创建并管理一个标准化的提示脚本，涵盖目标图像中每个角色的提示和布局设计。据此，TheaterGen生成一系列角色图像并提炼出指导信息，这类似于“彩排”阶段。紧接着，TheaterGen将提示脚本和指导信息整合到T2I扩散模型的逆向去噪流程中，生成最终图像，仿佛在进行“最终演出”。通过有效管理提示脚本和角色图像，TheaterGen显著提升了合成图像的语义和上下文连贯性。此外，我们还推出了一个专门的基准测试集CMIGBench（一致性多轮图像生成基准测试），包含8000条多轮指令。与以往的多轮次基准测试不同，CMIGBench不预设角色定义，而是全面包含了故事生成和多轮编辑任务，以进行综合评估。广泛的实验结果显示，TheaterGen显著超越了现有最先进方法，其在Mini DALLE 3模型上的平均角色-角色相似性提升了21%，在平均文本-图像相似性上提升了19%，树立了新的性能标杆。",
    "title_cn": "TheaterGen：运用大型语言模型精心管理角色，打造连贯的多轮次图像生成体验",
    "tags": [
      "LLM应用",
      "图像生成",
      ""
    ]
  },
  {
    "title": "Kangaroo: Lossless Self-Speculative Decoding via Double Early Exiting",
    "submit_datetime": "2024年04月29日",
    "abstract": "Speculative decoding has demonstrated its effectiveness in accelerating the inference of large language models while maintaining a consistent sampling distribution. However, the conventional approach of training a separate draft model to achieve a satisfactory token acceptance rate can be costly. Drawing inspiration from early exiting, we propose a novel self-speculative decoding framework \\emph{Kangaroo}, which uses a fixed shallow sub-network as a self-draft model, with the remaining layers serving as the larger target model. We train a lightweight and efficient adapter module on top of the sub-network to bridge the gap between the sub-network and the full model's representation ability. It is noteworthy that the inference latency of the self-draft model may no longer be negligible compared to the large model, necessitating strategies to increase the token acceptance rate while minimizing the drafting steps of the small model. To address this challenge, we introduce an additional early exiting mechanism for generating draft tokens. Specifically, we halt the small model's subsequent prediction during the drafting phase once the confidence level for the current token falls below a certain threshold. Extensive experiments on the Spec-Bench demonstrate the effectiveness of Kangaroo. Under single-sequence verification, Kangaroo achieves speedups up to $1.68\\times$ on Spec-Bench, outperforming Medusa-1 with 88.7\\% fewer additional parameters (67M compared to 591M). The code for Kangaroo is available at https://github.com/Equationliu/Kangaroo.",
    "pdf_link": "https://arxiv.org/abs/2404.18911",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.18911v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18911/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18911v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18911/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18911v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18911/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18911v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18911/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18911v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18911/x5.png"
      }
    ],
    "abstract_cn": "推测性解码技术通过维持稳定的采样分布，有效加速了大型语言模型的推理过程。然而，传统方法通过训练独立草稿模型以提高令牌接受率，成本较高。借鉴早期退出策略，我们提出了一种创新的自我推测解码框架——“袋鼠”。该框架采用固定浅层子网络作为自我草稿模型，而其他层则构成更大的目标模型。为了弥补子网络与完整模型在表示能力上的差异，我们在子网络之上训练了一个高效轻量的适配器模块。值得注意的是，自我草稿模型的推理延迟相较于大型模型已不容忽视，因此需要采取策略来提高令牌接受率，同时减少小型模型的起草步骤。为此，我们引入了一种新的早期退出机制，用于生成草稿令牌。具体来说，当当前令牌的置信度降至某一阈值以下时，我们会在起草阶段停止小型模型的后续预测。在 Spec-Bench 上的大量实验显示，袋鼠框架显著提升了效率，单序列验证下速度提升高达 1.68 倍，性能超越了 Medusa-1，且额外参数减少了 88.7%（6700 万对比 5910 万）。袋鼠框架的代码已在 GitHub 上开源，地址为 https://github.com/Equationliu/Kangaroo。",
    "title_cn": "袋鼠：一种无损自我推测解码技术，采用双重早期退出机制。",
    "tags": [
      "LLM应用",
      "",
      ""
    ]
  },
  {
    "title": "Human-in-the-Loop Synthetic Text Data Inspection with Provenance Tracking",
    "submit_datetime": "2024年04月29日",
    "abstract": "Data augmentation techniques apply transformations to existing texts to generate additional data. The transformations may produce low-quality texts, where the meaning of the text is changed and the text may even be mangled beyond human comprehension. Analyzing the synthetically generated texts and their corresponding labels is slow and demanding. To winnow out texts with incorrect labels, we develop INSPECTOR, a human-in-the-loop data inspection technique. INSPECTOR combines the strengths of provenance tracking techniques with assistive labeling. INSPECTOR allows users to group related texts by their transformation provenance, i.e., the transformations applied to the original text, or feature provenance, the linguistic features of the original text. For assistive labeling, INSPECTOR computes metrics that approximate data quality, and allows users to compare the corresponding label of each text against the predictions of a large language model. In a user study, INSPECTOR increases the number of texts with correct labels identified by 3X on a sentiment analysis task and by 4X on a hate speech detection task. The participants found grouping the synthetically generated texts by their common transformation to be the most useful technique. Surprisingly, grouping texts by common linguistic features was perceived to be unhelpful. Contrary to prior work, our study finds that no single technique obviates the need for human inspection effort. This validates the design of INSPECTOR which combines both analysis of data provenance and assistive labeling to reduce human inspection effort.",
    "pdf_link": "https://arxiv.org/abs/2404.18881",
    "graphs": [],
    "abstract_cn": "数据增强通过转换现有文本来扩充数据集，但可能导致文本质量下降，意义扭曲，甚至难以理解。为了高效筛选出标注错误的文本，我们设计了 INSPECTOR，一种结合了来源追踪和辅助标注的人工审核技术。INSPECTOR 使用户能够根据文本的转换来源或原始文本的语言特征，将相关文本进行归类。在辅助标注方面，INSPECTOR 计算数据质量指标，并允许用户将每条文本的标签与大型语言模型的预测相比较。用户研究发现，INSPECTOR 在情感分析和仇恨言论检测任务中，分别将正确标注的文本数量提升了三倍和四倍。参与者普遍认为，根据文本的共同转换特征进行归类最为有效，而按语言特征分组则效果不佳。与先前研究不同，我们的研究指出，没有单一技术可以完全取代人工审核的必要性，这证明了 INSPECTOR 的设计，它结合了数据来源分析和辅助标注，有效减轻了人工审核的工作量。",
    "title_cn": "人工参与的合成文本数据审查，配备有追踪溯源功能",
    "tags": [
      "分类：LLM应用",
      "数据科学",
      "人工智能"
    ]
  },
  {
    "title": "More RLHF, More Trust? On The Impact of Human Preference Alignment On Language Model Trustworthiness",
    "submit_datetime": "2024年04月29日",
    "abstract": "The surge in Large Language Models (LLMs) development has led to improved performance on cognitive tasks as well as an urgent need to align these models with human values in order to safely exploit their power. Despite the effectiveness of preference learning algorithms like Reinforcement Learning From Human Feedback (RLHF) in aligning human preferences, their assumed improvements on model trustworthiness haven't been thoroughly testified. Toward this end, this study investigates how models that have been aligned with general-purpose preference data on helpfulness and harmlessness perform across five trustworthiness verticals: toxicity, stereotypical bias, machine ethics, truthfulness, and privacy. For model alignment, we focus on three widely used RLHF variants: Supervised Finetuning (SFT), Proximal Policy Optimization (PPO), and Direct Preference Optimization (DPO). Through extensive empirical investigations, we discover that the improvement in trustworthiness by RLHF is far from guaranteed, and there exists a complex interplay between preference data, alignment algorithms, and specific trustworthiness aspects. Together, our results underscore the need for more nuanced approaches for model alignment. By shedding light on the intricate dynamics of these components within model alignment, we hope this research will guide the community towards developing language models that are both capable and trustworthy.",
    "pdf_link": "https://arxiv.org/abs/2404.18870",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.18870v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18870/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18870v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18870/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18870v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18870/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18870v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18870/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18870v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18870/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18870v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18870/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18870v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18870/x7.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）的迅猛发展不仅提升了认知任务的执行效率，也突显了将这些模型与人类价值观紧密结合的必要性，以确保其安全有效地发挥作用。尽管基于人类反馈的强化学习（RLHF）等偏好学习算法在匹配人类偏好方面显示出了显著效果，但它们对提升模型可信度的贡献尚未得到全面验证。本项研究旨在探究那些依据通用偏好数据进行有用性和无害性对齐的模型，在五个关键的可信度维度上的表现：毒性、刻板印象偏见、机器伦理、真实性和隐私。我们特别关注了三种流行的RLHF变体：监督微调（SFT）、近端策略优化（PPO）和直接偏好优化（DPO）。通过深入的实证研究，我们揭示了RLHF在提升模型可信度方面的成效并非一蹴而就，并且偏好数据、对齐算法以及特定可信度维度之间存在着复杂的相互作用。我们的发现强调了在模型对齐过程中采取更为精细方法的必要性。我们期望本研究能够揭示模型对齐中这些要素的复杂相互作用，从而引导业界开发出既高效又可信的语言模型。",
    "title_cn": "偏好更贴近人类，信任更深厚？探讨人类偏好对齐如何提升语言模型的可信性",
    "tags": [
      "LLM应用",
      "人工智能",
      "伦理学"
    ]
  },
  {
    "title": "Truth-value judgment in language models: belief directions are context sensitive",
    "submit_datetime": "2024年04月29日",
    "abstract": "Recent work has demonstrated that the latent spaces of large language models (LLMs) contain directions predictive of the truth of sentences. Multiple methods recover such directions and build probes that are described as getting at a model's \"knowledge\" or \"beliefs\". We investigate this phenomenon, looking closely at the impact of context on the probes. Our experiments establish where in the LLM the probe's predictions can be described as being conditional on the preceding (related) sentences. Specifically, we quantify the responsiveness of the probes to the presence of (negated) supporting and contradicting sentences, and score the probes on their consistency. We also perform a causal intervention experiment, investigating whether moving the representation of a premise along these belief directions influences the position of the hypothesis along that same direction. We find that the probes we test are generally context sensitive, but that contexts which should not affect the truth often still impact the probe outputs. Our experiments show that the type of errors depend on the layer, the (type of) model, and the kind of data. Finally, our results suggest that belief directions are (one of the) causal mediators in the inference process that incorporates in-context information.",
    "pdf_link": "https://arxiv.org/abs/2404.18865",
    "graphs": [],
    "abstract_cn": "最新研究揭示，大型语言模型（LLM）的潜在空间内蕴含着能预示句子真伪的趋势。多种技术成功复原出这些趋势，并打造出了能够触及模型“知识库”或“信仰体系”的探测工具。本研究深入探讨了这一现象，特别关注了上下文对这些探测工具的影响。实验结果明确了在LLM中，探测预测是如何以前文（相关）句子为条件的。我们具体衡量了探测工具对于存在（或否定）的支持性与反驳性句子的敏感度，并对其一致性进行了评分。此外，通过因果干预实验，我们探究了沿着信仰方向移动前提表示是否会改变假设在同一方向上的位置。研究发现，尽管测试的探测工具普遍对上下文有所反应，但本不应影响真实性的上下文却仍能影响探测结果。实验还指出，错误类型的产生与模型的层次、类型及数据种类息息相关。最终，研究结果暗示信念方向可能是推理过程中整合上下文信息的关键因果因素之一。",
    "title_cn": "在语言模型中进行真值判断时，信仰的方向会随着上下文的不同而变化。",
    "tags": [
      "LLM理论",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Performance-Aligned LLMs for Generating Fast Code",
    "submit_datetime": "2024年04月29日",
    "abstract": "Optimizing scientific software is a difficult task because codebases are often large and complex, and performance can depend upon several factors including the algorithm, its implementation, and hardware among others. Causes of poor performance can originate from disparate sources and be difficult to diagnose. Recent years have seen a multitude of work that use large language models (LLMs) to assist in software development tasks. However, these tools are trained to model the distribution of code as text, and are not specifically designed to understand performance aspects of code. In this work, we introduce a reinforcement learning based methodology to align the outputs of code LLMs with performance. This allows us to build upon the current code modeling capabilities of LLMs and extend them to generate better performing code. We demonstrate that our fine-tuned model improves the expected speedup of generated code over base models for a set of benchmark tasks from 0.9 to 1.6 for serial code and 1.9 to 4.5 for OpenMP code.",
    "pdf_link": "https://arxiv.org/abs/2404.18864",
    "graphs": [],
    "abstract_cn": "科学软件的优化工作颇为棘手，原因在于代码库往往庞大复杂，且性能受算法、实现方式、硬件等多种因素影响。性能问题可能源自不同因素，诊断起来颇具挑战。近年来，大量研究利用大型语言模型（LLMs）助力软件开发。但这些模型主要针对代码文本分布进行训练，并未专门针对代码性能进行优化。本研究提出了一种基于强化学习的策略，旨在提升代码LLMs输出的性能。通过此方法，我们不仅能够利用LLMs现有的代码建模能力，还能进一步优化，生成性能更优的代码。实验结果表明，我们微调后的模型在一系列基准测试中，将串行代码的预期加速比从0.9提升至1.6，OpenMP代码的加速比更是从1.9跃升至4.5。",
    "title_cn": "为了快速生成代码，我们对大型语言模型进行了性能优化，确保它们在编码任务中的表现与预期目标精准对齐。",
    "tags": [
      "分类：LLM应用\n\n这篇论文讨论了如何利用大型语言模型（LLMs）来优化科学软件的性能。虽然这些模型主要针对代码文本分布进行训练，但本研究提出了一种基于强化学习的策略，以提升代码LLMs输出的性能。这表明了LLMs在软件开发领域的应用，特别是在性能优化方面。因此，这篇论文应该被归类为LLM应用。",
      "软件工程",
      "性能优化"
    ]
  },
  {
    "title": "VERT: Verified Equivalent Rust Transpilation with Few-Shot Learning",
    "submit_datetime": "2024年04月29日",
    "abstract": "Rust is a programming language that combines memory safety and low-level control, providing C-like performance while guaranteeing the absence of undefined behaviors by default. Rust's growing popularity has prompted research on safe and correct transpiling of existing code-bases to Rust. Existing work falls into two categories: rule-based and large language model (LLM)-based. While rule-based approaches can theoretically produce correct transpilations that maintain input-output equivalence to the original, they often yield unreadable Rust code that uses unsafe subsets of the Rust language. On the other hand, while LLM-based approaches typically produce more readable, maintainable, and safe code, they do not provide any guarantees about correctness. In this work, we present VERT, a tool that can produce readable Rust transpilations with formal guarantees of correctness. VERT's only requirement is that there is Web Assembly compiler for the source language, which is true for most major languages. VERT first uses the Web Assembly compiler to obtain an oracle Rust program. In parallel, VERT uses an LLM to generate a readable candidate Rust program. This candidate is verified against the oracle, and if verification fails, we regenerate a new candidate transpilation until verification succeeds. We evaluate VERT by transpiling a suite of 1,394 programs taken from competitive programming style benchmarks. Combining Anthropic's Claude-2 and VERT increases Rust transpilations passing property-based testing from 31% to 54% and bounded model-checking from 1% to 42% compared to using Claude alone. In addition, we evaluate VERT's ability to generate non-trivial safe Rust on programs taken from real-world C projects that make significant use of pointers. Our results provide insights into the limitations of LLMs to write safe Rust.",
    "pdf_link": "https://arxiv.org/abs/2404.18852",
    "graphs": [],
    "abstract_cn": "Rust，作为一种融合了内存安全与底层控制的编程语言，以其类 C 语言的性能和默认避免未定义行为的特性而广受欢迎。随着 Rust 的流行，如何安全且准确地将现有代码转译为 Rust 成为研究热点。目前的研究主要分为基于规则的方法和基于大型语言模型（LLM）的方法两大类。基于规则的方法虽能理论上保证转译的正确性，但往往产出难以阅读的 Rust 代码；而基于 LLM 的方法虽能生成更易读和安全的代码，却无法确保其正确性。本研究提出了 VERT 工具，它能够生成既易读又具有形式正确性保证的 Rust 代码转译。VERT 的使用前提仅是源语言需有 Web Assembly 编译器，这在大多数主流语言中已得到满足。VERT 利用 Web Assembly 编译器生成一个基准 Rust 程序，并同时使用 LLM 生成可读的候选 Rust 程序，通过与基准程序的对比验证，不断迭代直至验证通过。我们通过转译 1,394 个来自编程竞赛风格的基准测试程序来评估 VERT 的性能。结合 Anthropic 的 Claude-2，VERT 显著提升了 Rust 转译的测试通过率，从基于属性的测试的 31% 提升至 54%，从有界模型检查的 1% 提升至 42%。此外，VERT 在生成实际 C 项目中大量使用指针的程序的安全 Rust 代码方面的能力也得到了验证。研究结果揭示了 LLM 在编写安全 Rust 代码方面的局限性。",
    "title_cn": "VERT：运用少量学习验证 Rust 语言的等价转译",
    "tags": [
      "LLM应用",
      "编程语言",
      "代码转译"
    ]
  },
  {
    "title": "It's Difficult to be Neutral -- Human and LLM-based Sentiment Annotation of Patient Comments",
    "submit_datetime": "2024年04月29日",
    "abstract": "Sentiment analysis is an important tool for aggregating patient voices, in order to provide targeted improvements in healthcare services. A prerequisite for this is the availability of in-domain data annotated for sentiment. This article documents an effort to add sentiment annotations to free-text comments in patient surveys collected by the Norwegian Institute of Public Health (NIPH). However, annotation can be a time-consuming and resource-intensive process, particularly when it requires domain expertise. We therefore also evaluate a possible alternative to human annotation, using large language models (LLMs) as annotators. We perform an extensive evaluation of the approach for two openly available pretrained LLMs for Norwegian, experimenting with different configurations of prompts and in-context learning, comparing their performance to human annotators. We find that even for zero-shot runs, models perform well above the baseline for binary sentiment, but still cannot compete with human annotators on the full dataset.",
    "pdf_link": "https://arxiv.org/abs/2404.18832",
    "graphs": [],
    "abstract_cn": "情感分析作为收集患者反馈、优化医疗服务的关键技术，依赖于领域内标注数据的丰富性。本文介绍了挪威公共卫生研究所（NIPH）在患者调查的开放式评论中加入情感标注的工作。鉴于人工标注既耗时又需专业知识，我们探索了使用大型语言模型（LLMs）作为自动标注工具的可能性。通过对比两种挪威语预训练LLMs在不同提示和上下文学习配置下的表现，我们对其进行了深入评估，并与人工标注的结果进行了比较。研究发现，即便在零样本的情况下，模型在二元情感分类上的表现也远超基准水平，但面对完整数据集，其性能仍未达到人工标注的水准。",
    "title_cn": "保持中立并非易事 —— 人类与基于大型语言模型的病患评论情感分析",
    "tags": [
      "LLM应用",
      "",
      ""
    ]
  },
  {
    "title": "Benchmarking Benchmark Leakage in Large Language Models",
    "submit_datetime": "2024年04月29日",
    "abstract": "Amid the expanding use of pre-training data, the phenomenon of benchmark dataset leakage has become increasingly prominent, exacerbated by opaque training processes and the often undisclosed inclusion of supervised data in contemporary Large Language Models (LLMs). This issue skews benchmark effectiveness and fosters potentially unfair comparisons, impeding the field's healthy development. To address this, we introduce a detection pipeline utilizing Perplexity and N-gram accuracy, two simple and scalable metrics that gauge a model's prediction precision on benchmark, to identify potential data leakages. By analyzing 31 LLMs under the context of mathematical reasoning, we reveal substantial instances of training even test set misuse, resulting in potentially unfair comparisons. These findings prompt us to offer several recommendations regarding model documentation, benchmark setup, and future evaluations. Notably, we propose the \"Benchmark Transparency Card\" to encourage clear documentation of benchmark utilization, promoting transparency and healthy developments of LLMs. we have made our leaderboard, pipeline implementation, and model predictions publicly available, fostering future research.",
    "pdf_link": "https://arxiv.org/abs/2404.18824",
    "graphs": [],
    "abstract_cn": "随着预训练数据的广泛应用，基准数据集泄露的问题日益凸显，尤其是在大型语言模型（LLMs）的训练过程中，监督数据的不透明使用加剧了这一现象。这不仅影响了基准测试的公正性，也可能导致不公平的比较，从而阻碍了语言模型领域的进步。为此，我们提出了一种基于困惑度和N-gram精确度的检测流程，用以评估模型在基准测试上的预测精度，并识别可能的数据泄露问题。通过对31个LLMs在数学推理任务中的分析，我们发现了大量的训练集甚至测试集的不当使用情况，这些问题可能导致不公平的比较结果。基于这些发现，我们提出了一系列建议，涉及模型文档编制、基准测试设置以及未来评估方法。特别地，我们建议引入“基准透明度卡”，以促进对基准测试使用情况的清晰记录，增强LLMs的透明度和健康发展。我们还公开了排行榜、检测流程的实现以及模型预测结果，以支持未来的研究工作。",
    "title_cn": "在大型语言模型中，对基准测试泄露问题进行评估",
    "tags": [
      "LLM理论",
      "",
      "基准测试"
    ]
  },
  {
    "title": "AppPoet: Large Language Model based Android malware detection via multi-view prompt engineering",
    "submit_datetime": "2024年04月29日",
    "abstract": "Due to the vast array of Android applications, their multifarious functions and intricate behavioral semantics, attackers can adopt various tactics to conceal their genuine attack intentions within legitimate functions. However, numerous feature engineering based methods suffer from a limitation in mining behavioral semantic information, thus impeding the accuracy and efficiency of Android malware detection. Besides, the majority of existing feature engineering based methods are weakly interpretive and fail to furnish researchers with effective and readable detection reports. Inspired by the success of the Large Language Models (LLMs) in natural language understanding, we propose AppPoet, a LLM-assisted multi-view system for Android malware detection. Firstly, AppPoet employs a static method to comprehensively collect application features and formulate various observation views. Subsequently, it steers the LLM to produce function descriptions and behavioral summaries for views via our meticulously devised multi-view prompt engineering technique to realize the deep mining of view semantics. Finally, we collaboratively fuse the multi-view information to efficiently and accurately detect malware through a deep neural network (DNN) classifier and then generate the heuristic diagnostic reports. Experimental results demonstrate that our method achieves a detection accuracy of 97.15% and an F1 score of 97.21%, which is superior to the baseline method Drebin and its variant. Furthermore, the case study evaluates the effectiveness of our generated diagnostic reports.",
    "pdf_link": "https://arxiv.org/abs/2404.18816",
    "graphs": [],
    "abstract_cn": "面对众多的 Android 应用及其功能多样、行为语义复杂，攻击者得以巧妙地将攻击意图隐藏在合法功能之中。基于特征工程的传统方法在挖掘深层行为语义上力有不逮，这限制了 Android 恶意软件检测的精确度与效率。此外，这些方法在解释性上也显得不足，难以为研究者提供清晰有效的检测报告。借鉴大型语言模型（LLMs）在自然语言处理上的成就，我们设计了 AppPoet，一个由 LLM 支持的多视角 Android 恶意软件检测系统。AppPoet 首先通过静态分析全面搜集应用特征，构建多维观察视图，然后利用我们独创的多视图提示技术，引导 LLM 生成视图的功能描述与行为摘要，深入挖掘视图背后的语义信息。最终，系统综合这些多维信息，通过深度神经网络（DNN）分类器高效而精确地识别恶意软件，并生成具有启发性的诊断报告。实验结果显示，我们的检测准确率达到了 97.15%，F1 分数为 97.21%，均优于行业标杆 Drebin 及其衍生方法。案例研究进一步验证了我们诊断报告生成的有效性。",
    "title_cn": "AppPoet：利用大型语言模型进行 Android 恶意软件检测，通过精心设计的多视角提示实现。",
    "tags": [
      "LLM应用",
      "网络安全",
      "软件工程"
    ]
  },
  {
    "title": "Efficiency-Effectiveness Tradeoff of Probabilistic Structured Queries for Cross-Language Information Retrieval",
    "submit_datetime": "2024年04月29日",
    "abstract": "Probabilistic Structured Queries (PSQ) is a cross-language information retrieval (CLIR) method that uses translation probabilities statistically derived from aligned corpora. PSQ is a strong baseline for efficient CLIR using sparse indexing. It is, therefore, useful as the first stage in a cascaded neural CLIR system whose second stage is more effective but too inefficient to be used on its own to search a large text collection. In this reproducibility study, we revisit PSQ by introducing an efficient Python implementation. Unconstrained use of all translation probabilities that can be estimated from aligned parallel text would in the limit assign a weight to every vocabulary term, precluding use of an inverted index to serve queries efficiently. Thus, PSQ's effectiveness and efficiency both depend on how translation probabilities are pruned. This paper presents experiments over a range of modern CLIR test collections to demonstrate that achieving Pareto optimal PSQ effectiveness-efficiency tradeoffs benefits from multi-criteria pruning, which has not been fully explored in prior work. Our Python PSQ implementation is available on GitHub(https://github.com/hltcoe/PSQ) and unpruned translation tables are available on Huggingface Models(https://huggingface.co/hltcoe/psq_translation_tables).",
    "pdf_link": "https://arxiv.org/abs/2404.18797",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.18797v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18797/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18797v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18797/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18797v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18797/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18797v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18797/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18797v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18797/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18797v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18797/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18797v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18797/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18797v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18797/x8.png"
      }
    ],
    "abstract_cn": "概率结构化查询（PSQ）作为一种跨语言信息检索（CLIR）技术，通过利用对齐语料库中统计得出的翻译概率，为高效的 CLIR 提供了坚实的基准。它特别适合作为级联神经 CLIR 系统的前置阶段，后者虽然检索效果更佳，但效率不足以独立处理大规模文本集合。本研究通过推出一个高效的 Python 版本，对 PSQ 进行了深入探讨。由于无限制地利用所有可从平行文本中估算的翻译概率，将导致为每个词汇项赋予权重，从而无法高效地使用倒排索引。因此，PSQ 的性能和效率均依赖于翻译概率的筛选方式。本文通过在多个现代 CLIR 测试集上的实验，展示了通过多标准筛选实现帕累托最优的 PSQ 性能与效率平衡，这一点在以往的研究中尚未得到充分探讨。我们的 Python PSQ 实现已在 GitHub 上发布（https://github.com/hltcoe/PSQ），同时未筛选的翻译表也可在 Huggingface Models 查找（https://huggingface.co/hltcoe/psq_translation_tables）。",
    "title_cn": "在跨语言信息检索领域，概率结构化查询的效率与效果之间存在一种权衡。",
    "tags": [
      "分类：Agent",
      "跨语言信息检索",
      "搜索引擎"
    ]
  },
  {
    "title": "Replacing Judges with Juries: Evaluating LLM Generations with a Panel of Diverse Models",
    "submit_datetime": "2024年04月29日",
    "abstract": "As Large Language Models (LLMs) have become more advanced, they have outpaced our abilities to accurately evaluate their quality. Not only is finding data to adequately probe particular model properties difficult, but evaluating the correctness of a model's freeform generation alone is a challenge. To address this, many evaluations now rely on using LLMs themselves as judges to score the quality of outputs from other LLMs. Evaluations most commonly use a single large model like GPT4. While this method has grown in popularity, it is costly, has been shown to introduce intramodel bias, and in this work, we find that very large models are often unnecessary. We propose instead to evaluate models using a Panel of LLm evaluators (PoLL). Across three distinct judge settings and spanning six different datasets, we find that using a PoLL composed of a larger number of smaller models outperforms a single large judge, exhibits less intra-model bias due to its composition of disjoint model families, and does so while being over seven times less expensive.",
    "pdf_link": "https://arxiv.org/abs/2404.18796",
    "graphs": [],
    "abstract_cn": "随着大型语言模型（LLMs）技术的飞速发展，我们对其质量的精准评估能力却未能跟上步伐。寻找合适的数据来充分探究模型特性变得日益艰难，而单独对模型的自由生成内容进行正确性评估同样充满挑战。为应对这一难题，当前许多评估方法开始借助LLMs自身的能力，来对其他LLMs的输出成果进行质量评定。这种评估方式通常依赖于单一的大型模型，如GPT4。尽管这种方法日益流行，但它不仅成本高昂，还可能带来模型内部偏见。在本项研究中，我们发现超大型模型往往并非必要。我们提出一种新的方法：利用一个由多个LLM评估员组成的评审团（PoLL）来执行模型评估。在三种不同的评审情境和六个不同的数据集上进行测试，我们发现采用由众多小型模型构成的PoLL评审团，不仅在性能上超越了单一大型模型评审，而且在成本上节省了超过七倍，同时因其由不同的模型家族组成，还减少了模型内部偏见。",
    "title_cn": "以多元模型小组评判，取代传统法官角色：深入评估大型语言模型的创作成果",
    "tags": [
      "LLM应用",
      "人工智能",
      ""
    ]
  },
  {
    "title": "PECC: Problem Extraction and Coding Challenges",
    "submit_datetime": "2024年04月29日",
    "abstract": "Recent advancements in large language models (LLMs) have showcased their exceptional abilities across various tasks, such as code generation, problem-solving and reasoning. Existing benchmarks evaluate tasks in isolation, yet the extent to which LLMs can understand prose-style tasks, identify the underlying problems, and then generate appropriate code solutions is still unexplored. Addressing this gap, we introduce PECC, a novel benchmark derived from Advent Of Code (AoC) challenges and Project Euler, including 2396 problems. Unlike conventional benchmarks, PECC requires LLMs to interpret narrative-embedded problems, extract requirements, and generate executable code. A key feature of our dataset is the complexity added by natural language prompting in chat-based evaluations, mirroring real-world instruction ambiguities. Results show varying model performance between narrative and neutral problems, with specific challenges in the Euler math-based subset with GPT-3.5-Turbo passing 50% of the AoC challenges and only 8% on the Euler problems. By probing the limits of LLMs' capabilities, our benchmark provides a framework to monitor and assess the subsequent progress of LLMs as a universal problem solver.",
    "pdf_link": "https://arxiv.org/abs/2404.18766",
    "graphs": [],
    "abstract_cn": "近期大型语言模型（LLMs）的突破性进展在多种任务上展现了其非凡才能，包括代码编写、解题和推理等。尽管现有评估标准独立考量各项任务，但LLMs在理解散文式任务、识别潜在问题并生成恰当代码解决方案方面的真正能力尚未得到充分探究。为填补这一空白，我们提出了PECC，这是一个创新的基准测试，源自“代码的降临”（AoC）挑战和“欧拉计划”（Project Euler），共包含2396个问题。与传统基准测试不同，PECC要求LLMs解读嵌入叙述中的问题，提炼关键需求，并产出可执行的代码。我们数据集的独特之处在于，它通过模拟现实世界指令的模糊性，在基于聊天的评估中引入了自然语言提示，增加了问题的复杂性。测试结果显示，模型在处理叙述性问题与中性问题时表现不一，在以数学为基础的欧拉子集问题上尤为突出，GPT-3.5-Turbo在AoC挑战中的通过率达到了50%，而在欧拉问题上仅为8%。PECC通过挑战LLMs的极限，为我们提供了一个监测和评估LLMs作为全能问题解决者进步的框架。",
    "title_cn": "PECC：问题抽取与编码的挑战",
    "tags": [
      "LLM应用",
      "",
      ""
    ]
  },
  {
    "title": "Transitive Vision-Language Prompt Learning for Domain Generalization",
    "submit_datetime": "2024年04月29日",
    "abstract": "The vision-language pre-training has enabled deep models to make a huge step forward in generalizing across unseen domains. The recent learning method based on the vision-language pre-training model is a great tool for domain generalization and can solve this problem to a large extent. However, there are still some issues that an advancement still suffers from trading-off between domain invariance and class separability, which are crucial in current DG problems. However, there are still some issues that an advancement still suffers from trading-off between domain invariance and class separability, which are crucial in current DG problems. In this paper, we introduce a novel prompt learning strategy that leverages deep vision prompts to address domain invariance while utilizing language prompts to ensure class separability, coupled with adaptive weighting mechanisms to balance domain invariance and class separability. Extensive experiments demonstrate that deep vision prompts effectively extract domain-invariant features, significantly improving the generalization ability of deep models and achieving state-of-the-art performance on three datasets.",
    "pdf_link": "https://arxiv.org/abs/2404.18758",
    "graphs": [],
    "abstract_cn": "视觉-语言预训练推动了深度模型在新领域泛化上的重大进展。新近的学习方法，基于这种预训练模型，为领域泛化提供了有效工具，显著提升了问题解决效率。尽管如此，领域不变性与类别可分性之间的平衡仍是技术进步面临的挑战，这对于当前的领域泛化（DG）问题尤为关键。本文提出了一种创新的提示学习策略，通过深度视觉提示强化领域不变性，语言提示保证类别可分性，并采用自适应权重机制来协调这两者。大量实验证明，这种深度视觉提示能够高效抽取领域不变特征，显著增强了深度模型的泛化性能，并在三个基准数据集上达到了最佳表现。",
    "title_cn": "在领域泛化领域，传递式的视觉-语言提示学习方法展现出了其独特的优势。",
    "tags": [
      "分类：RAG",
      "计算机视觉",
      ""
    ]
  },
  {
    "title": "Enhancing Interactive Image Retrieval With Query Rewriting Using Large Language Models and Vision Language Models",
    "submit_datetime": "2024年04月29日",
    "abstract": "Image search stands as a pivotal task in multimedia and computer vision, finding applications across diverse domains, ranging from internet search to medical diagnostics. Conventional image search systems operate by accepting textual or visual queries, retrieving the top-relevant candidate results from the database. However, prevalent methods often rely on single-turn procedures, introducing potential inaccuracies and limited recall. These methods also face the challenges, such as vocabulary mismatch and the semantic gap, constraining their overall effectiveness. To address these issues, we propose an interactive image retrieval system capable of refining queries based on user relevance feedback in a multi-turn setting. This system incorporates a vision language model (VLM) based image captioner to enhance the quality of text-based queries, resulting in more informative queries with each iteration. Moreover, we introduce a large language model (LLM) based denoiser to refine text-based query expansions, mitigating inaccuracies in image descriptions generated by captioning models. To evaluate our system, we curate a new dataset by adapting the MSR-VTT video retrieval dataset to the image retrieval task, offering multiple relevant ground truth images for each query. Through comprehensive experiments, we validate the effectiveness of our proposed system against baseline methods, achieving state-of-the-art performance with a notable 10\\% improvement in terms of recall. Our contributions encompass the development of an innovative interactive image retrieval system, the integration of an LLM-based denoiser, the curation of a meticulously designed evaluation dataset, and thorough experimental validation.",
    "pdf_link": "https://arxiv.org/abs/2404.18746",
    "graphs": [],
    "abstract_cn": "图像搜索在多媒体和计算机视觉领域扮演着核心角色，广泛应用于互联网搜索、医学诊断等多个领域。传统搜索系统通过文本或视觉查询来检索数据库中的最相关结果，但这些方法多采用单轮操作，存在准确性和召回率的局限。此外，它们还面临词汇不匹配和语义差异等挑战，影响了搜索效果。针对这些问题，我们设计了一种交互式图像检索系统，能在多轮对话中根据用户反馈优化查询。系统内置了视觉语言模型（VLM）驱动的图像描述生成器，提升了文本查询的质量和信息量。同时，引入了基于大型语言模型（LLM）的去噪器，以提高文本查询扩展的准确性，减少图像描述中的误差。为了测试系统性能，我们根据MSR-VTT视频检索数据集构建了新的图像检索数据集，每个查询对应多个相关的真实图像。经过一系列实验，我们的系统在召回率上比基线方法提高了10%，达到了业界领先水平。我们的贡献包括创新的交互式图像检索系统的开发、LLM去噪器的集成、精心设计的评价数据集的构建，以及全面的实验验证。",
    "title_cn": "借助大型语言模型和视觉语言模型，通过查询重写技术，我们能够提升交互式图像检索的效能。",
    "tags": [
      "LLM应用",
      "多媒体",
      "计算机视觉"
    ]
  },
  {
    "title": "LLMClean: Context-Aware Tabular Data Cleaning via LLM-Generated OFDs",
    "submit_datetime": "2024年04月29日",
    "abstract": "Machine learning's influence is expanding rapidly, now integral to decision-making processes from corporate strategy to the advancements in Industry 4.0. The efficacy of Artificial Intelligence broadly hinges on the caliber of data used during its training phase; optimal performance is tied to exceptional data quality. Data cleaning tools, particularly those that exploit functional dependencies within ontological frameworks or context models, are instrumental in augmenting data quality. Nevertheless, crafting these context models is a demanding task, both in terms of resources and expertise, often necessitating specialized knowledge from domain experts.\n  In light of these challenges, this paper introduces an innovative approach, called LLMClean, for the automated generation of context models, utilizing Large Language Models to analyze and understand various datasets. LLMClean encompasses a sequence of actions, starting with categorizing the dataset, extracting or mapping relevant models, and ultimately synthesizing the context model. To demonstrate its potential, we have developed and tested a prototype that applies our approach to three distinct datasets from the Internet of Things, healthcare, and Industry 4.0 sectors. The results of our evaluation indicate that our automated approach can achieve data cleaning efficacy comparable with that of context models crafted by human experts.",
    "pdf_link": "https://arxiv.org/abs/2404.18681",
    "graphs": [],
    "abstract_cn": "机器学习正迅速成为企业决策和工业4.0发展的核心。AI的效能依赖于训练阶段使用的数据质量，而数据清洗工具，尤其是那些能够挖掘本体框架或上下文模型中功能依赖的工具，对于提升数据质量至关重要。尽管如此，构建这些上下文模型是一项既耗费资源又考验专业技能的任务，通常需要依赖领域专家的深入知识。面对这些挑战，本论文提出了一种名为LLMClean的创新自动生成上下文模型的方法，该方法利用大型语言模型来分析和理解不同的数据集。LLMClean通过一系列步骤，包括对数据集进行分类、提取或映射相关模型，最终生成上下文模型。为了证明其有效性，我们开发并测试了一个原型，将其应用于物联网、医疗保健和工业4.0领域的三个不同数据集。评估结果显示，我们的自动化方法在数据清洗效果上可与人类专家创建的上下文模型相媲美。",
    "title_cn": "LLMClean：一种利用大型语言模型（LLM）生成的OFD（开放性功能需求）进行上下文感知的表格数据清洗方法。",
    "tags": [
      "LLM应用",
      "企业决策",
      "工业4.0"
    ]
  },
  {
    "title": "Assessing Cybersecurity Vulnerabilities in Code Large Language Models",
    "submit_datetime": "2024年04月29日",
    "abstract": "Instruction-tuned Code Large Language Models (Code LLMs) are increasingly utilized as AI coding assistants and integrated into various applications. However, the cybersecurity vulnerabilities and implications arising from the widespread integration of these models are not yet fully understood due to limited research in this domain. To bridge this gap, this paper presents EvilInstructCoder, a framework specifically designed to assess the cybersecurity vulnerabilities of instruction-tuned Code LLMs to adversarial attacks. EvilInstructCoder introduces the Adversarial Code Injection Engine to automatically generate malicious code snippets and inject them into benign code to poison instruction tuning datasets. It incorporates practical threat models to reflect real-world adversaries with varying capabilities and evaluates the exploitability of instruction-tuned Code LLMs under these diverse adversarial attack scenarios. Through the use of EvilInstructCoder, we conduct a comprehensive investigation into the exploitability of instruction tuning for coding tasks using three state-of-the-art Code LLM models: CodeLlama, DeepSeek-Coder, and StarCoder2, under various adversarial attack scenarios. Our experimental results reveal a significant vulnerability in these models, demonstrating that adversaries can manipulate the models to generate malicious payloads within benign code contexts in response to natural language instructions. For instance, under the backdoor attack setting, by poisoning only 81 samples (0.5\\% of the entire instruction dataset), we achieve Attack Success Rate at 1 (ASR@1) scores ranging from 76\\% to 86\\% for different model families. Our study sheds light on the critical cybersecurity vulnerabilities posed by instruction-tuned Code LLMs and emphasizes the urgent necessity for robust defense mechanisms to mitigate the identified vulnerabilities.",
    "pdf_link": "https://arxiv.org/abs/2404.18567",
    "graphs": [],
    "abstract_cn": "随着AI编程助手的广泛应用，指令调整的代码大型语言模型（Code LLMs）正逐渐成为开发领域的新宠。但这些模型的网络安全风险尚未充分揭示，主要原因在于相关领域的研究尚不深入。为填补这一研究空白，本文介绍了EvilInstructCoder框架，旨在专门评估这些模型在面对敌意攻击时的网络安全脆弱性。该框架通过引入对抗性代码注入引擎，自动化生成并注入恶意代码片段，以此污染指令调整的数据集。它还模拟了多种现实世界的威胁模式，以评估Code LLMs在不同对抗性攻击情境下的脆弱性。通过EvilInstructCoder，我们对三款顶尖的Code LLM模型——CodeLlama、DeepSeek-Coder和StarCoder2——在多样的敌意攻击情境下的安全性进行了深入分析。研究发现，这些模型存在显著的安全漏洞，攻击者可以轻易诱导模型在良性代码中嵌入恶意负载。特别是在后门攻击情境中，仅需污染0.5%的指令数据集样本，就能使攻击成功率达到76%至86%。本研究不仅揭示了指令调整的Code LLMs所面临的严峻网络安全挑战，也强调了开发强大防御机制以应对这些风险的紧迫性。",
    "title_cn": "探究大型语言模型代码中的网络安全薄弱环节",
    "tags": [
      "LLM应用",
      "网络安全",
      "软件开发"
    ]
  },
  {
    "title": "LangBiTe: A Platform for Testing Bias in Large Language Models",
    "submit_datetime": "2024年04月29日",
    "abstract": "The integration of Large Language Models (LLMs) into various software applications raises concerns about their potential biases. Typically, those models are trained on a vast amount of data scrapped from forums, websites, social media and other internet sources, which may instill harmful and discriminating behavior into the model. To address this issue, we present LangBiTe, a testing platform to systematically assess the presence of biases within an LLM. LangBiTe enables development teams to tailor their test scenarios, and automatically generate and execute the test cases according to a set of user-defined ethical requirements. Each test consists of a prompt fed into the LLM and a corresponding test oracle that scrutinizes the LLM's response for the identification of biases. LangBite provides users with the bias evaluation of LLMs, and end-to-end traceability between the initial ethical requirements and the insights obtained.",
    "pdf_link": "https://arxiv.org/abs/2404.18558",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）的广泛应用可能带来偏见问题，因为它们通常基于网络论坛、网站、社交媒体等来源的海量数据进行训练，这些数据可能包含有害或歧视性内容。为此，我们引入了LangBiTe，这是一个系统化的测试平台，旨在检测LLM中的偏见。该平台允许开发团队根据自定义的道德标准，设计测试场景并自动生成及执行测试案例。每项测试都包括向LLM输入的提示和一个测试预言机，后者将分析LLM的回应，以识别潜在的偏见。LangBiTe不仅为用户评估LLM的偏见情况，还提供了从初始道德要求到最终洞察的完整追溯链。",
    "title_cn": "LangBiTe：大型语言模型偏见检测的实验平台",
    "tags": [
      "分类：LLM应用",
      "人工智能",
      "道德与偏见检测"
    ]
  },
  {
    "title": "Can GPT-4 do L2 analytic assessment?",
    "submit_datetime": "2024年04月29日",
    "abstract": "Automated essay scoring (AES) to evaluate second language (L2) proficiency has been a firmly established technology used in educational contexts for decades. Although holistic scoring has seen advancements in AES that match or even exceed human performance, analytic scoring still encounters issues as it inherits flaws and shortcomings from the human scoring process. The recent introduction of large language models presents new opportunities for automating the evaluation of specific aspects of L2 writing proficiency. In this paper, we perform a series of experiments using GPT-4 in a zero-shot fashion on a publicly available dataset annotated with holistic scores based on the Common European Framework of Reference and aim to extract detailed information about their underlying analytic components. We observe significant correlations between the automatically predicted analytic scores and multiple features associated with the individual proficiency components.",
    "pdf_link": "https://arxiv.org/abs/2404.18557",
    "graphs": [],
    "abstract_cn": "自动作文评分（AES）评估第二语言（L2）能力，已在教育领域应用多年。尽管整体评分技术在 AES 中取得了与人类评分相媲美甚至超越的进步，但分析性评分因承袭了人为评分的缺陷而仍面临挑战。大型语言模型的新兴为 L2 写作技能的自动化评估带来了新的机遇。本文通过 GPT-4 在一个标注了基于欧洲共同参考框架整体分数的公开数据集上进行了零样本实验，旨在深入挖掘其分析评分的潜在构成要素。研究发现，自动预测的分析评分与各个能力要素相关的多种特征之间呈现出显著的正相关性。",
    "title_cn": "GPT-4 是否能够胜任 L2 级别的分析性评估？",
    "tags": [
      "LLM应用",
      "",
      "自动评分系统"
    ]
  },
  {
    "title": "ir_explain: a Python Library of Explainable IR Methods",
    "submit_datetime": "2024年04月29日",
    "abstract": "While recent advancements in Neural Ranking Models have resulted in significant improvements over traditional statistical retrieval models, it is generally acknowledged that the use of large neural architectures and the application of complex language models in Information Retrieval (IR) have reduced the transparency of retrieval methods. Consequently, Explainability and Interpretability have emerged as important research topics in IR. Several axiomatic and post-hoc explanation methods, as well as approaches that attempt to be interpretable-by-design, have been proposed. This article presents \\irexplain, an open-source Python library that implements a variety of well-known techniques for Explainable IR (ExIR) within a common, extensible framework. \\irexplain supports the three standard categories of post-hoc explanations, namely pointwise, pairwise, and listwise explanations. The library is designed to make it easy to reproduce state-of-the-art ExIR baselines on standard test collections, as well as to explore new approaches to explaining IR models and methods. To facilitate adoption, \\irexplain is well-integrated with widely-used toolkits such as Pyserini and \\irdatasets.",
    "pdf_link": "https://arxiv.org/abs/2404.18546",
    "graphs": [],
    "abstract_cn": "最新的神经排序模型在性能上取得了显著提升，超越了传统统计检索模型。然而，这也使得信息检索（IR）中的大型神经架构和复杂语言模型的应用变得不那么透明。因此，可解释性和可解释性成为了IR研究中的热点。本文介绍了\\irexplain，一个开源的Python库，它为可解释的IR（ExIR）提供了一个统一且可扩展的框架，涵盖了点对点、成对和列表三种标准的事后解释方法。该库旨在简化在标准测试集上复现顶级ExIR基线的过程，并鼓励探索新的IR模型和方法的解释方式。为了促进其应用，\\irexplain与流行的工具如Pyserini和\\irdatasets实现了良好的集成。",
    "title_cn": "ir_explain：一款用于信息检索的可解释性方法的 Python 库",
    "tags": [
      "LLM应用",
      "信息检索",
      "可解释性"
    ]
  },
  {
    "title": "Time Machine GPT",
    "submit_datetime": "2024年04月29日",
    "abstract": "Large language models (LLMs) are often trained on extensive, temporally indiscriminate text corpora, reflecting the lack of datasets with temporal metadata. This approach is not aligned with the evolving nature of language. Conventional methods for creating temporally adapted language models often depend on further pre-training static models on time-specific data. This paper presents a new approach: a series of point-in-time LLMs called Time Machine GPT (TiMaGPT), specifically designed to be nonprognosticative. This ensures they remain uninformed about future factual information and linguistic changes. This strategy is beneficial for understanding language evolution and is of critical importance when applying models in dynamic contexts, such as time-series forecasting, where foresight of future information can prove problematic. We provide access to both the models and training datasets.",
    "pdf_link": "https://arxiv.org/abs/2404.18543",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）多在内容广泛且忽略时间顺序的文本集合上进行训练，这种做法并未跟上语言演进的步伐。传统上，为了构建能够适应时间变化的语言模型，往往需要在特定时间段的数据上对静态模型进行额外的预训练。本文介绍了一种创新的方法：一系列在特定时间点的非预测性大型语言模型，称为时间机器 GPT（TiMaGPT）。这些模型被特别设计，以确保它们不会知晓任何关于未来的事实性信息和语言变迁。这一策略不仅有助于深入理解语言的演进，而且在动态情境下应用模型时至关重要，例如在时间序列预测中，对将来信息的预知可能会带来问题。我们为这些模型及其训练数据集提供了访问权限。",
    "title_cn": "时光机器 GPT",
    "tags": [
      "分类：LLM理论",
      "时间序列预测",
      ""
    ]
  },
  {
    "title": "OAEI Machine Learning Dataset for Online Model Generation",
    "submit_datetime": "2024年04月29日",
    "abstract": "Ontology and knowledge graph matching systems are evaluated annually by the Ontology Alignment Evaluation Initiative (OAEI). More and more systems use machine learning-based approaches, including large language models. The training and validation datasets are usually determined by the system developer and often a subset of the reference alignments are used. This sampling is against the OAEI rules and makes a fair comparison impossible. Furthermore, those models are trained offline (a trained and optimized model is packaged into the matcher) and therefore the systems are specifically trained for those tasks. In this paper, we introduce a dataset that contains training, validation, and test sets for most of the OAEI tracks. Thus, online model learning (the systems must adapt to the given input alignment without human intervention) is made possible to enable a fair comparison for ML-based systems. We showcase the usefulness of the dataset by fine-tuning the confidence thresholds of popular systems.",
    "pdf_link": "https://arxiv.org/abs/2404.18542",
    "graphs": [],
    "abstract_cn": "每年，本体对齐评估计划（OAEI）对本体和知识图谱匹配系统进行评估。随着基于机器学习的方法，尤其是大型语言模型的广泛应用，系统开发者通常会根据参考对齐的子集来确定训练和验证数据集，这违反了OAEI的规定，导致无法进行公正的比较。此外，这些模型采用离线训练方式，即训练好的模型被封装进匹配器中，专为特定任务定制。本文提出了一个新的数据集，涵盖了OAEI大多数赛道的训练集、验证集和测试集，从而使得在线模型学习（系统需在无人干预的情况下自动适应输入对齐）成为可能，为基于机器学习（ML）的系统提供了一个公平的比较平台。我们还通过微调流行系统的信任阈值，展示了该数据集的实用价值。",
    "title_cn": "OAEI 为在线模型生成提供了一个机器学习数据集。",
    "tags": [
      "分类：Agent",
      "本体对齐",
      "机器学习"
    ]
  },
  {
    "title": "Evaluating and Mitigating Linguistic Discrimination in Large Language Models",
    "submit_datetime": "2024年04月29日",
    "abstract": "By training on text in various languages, large language models (LLMs) typically possess multilingual support and demonstrate remarkable capabilities in solving tasks described in different languages. However, LLMs can exhibit linguistic discrimination due to the uneven distribution of training data across languages. That is, LLMs are hard to keep the consistency of responses when faced with the same task but depicted in different languages.\n  In this study, we first explore the consistency in the LLMs' outputs responding to queries in various languages from two aspects: safety and quality. We conduct this analysis with two datasets (AdvBench and NQ) based on four LLMs (Llama2-13b, Gemma-7b, GPT-3.5-turbo and Gemini-pro). The results show that LLMs exhibit stronger human alignment capabilities with queries in English, French, Russian, and Spanish (only 1.04\\% of harmful queries successfully jailbreak on average) compared to queries in Bengali, Georgian, Nepali and Maithili (27.7\\% of harmful queries jailbreak successfully on average). Moreover, for queries in English, Danish, Czech and Slovenian, LLMs tend to produce responses with a higher quality (with 0.1494 $F_1$ score on average) compared to the other languages. Upon these findings, we propose LDFighter, a similarity-based voting, to mitigate the linguistic discrimination in LLMs. LDFighter ensures consistent service for different language speakers. We evaluate LDFighter with both benign queries and harmful queries. The results show that LDFighter not only significantly reduces the jailbreak success rate but also improve the response quality on average, demonstrating its effectiveness.",
    "pdf_link": "https://arxiv.org/abs/2404.18534",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）通过在多种语言的文本上进行训练，通常具备多语言能力，并在解决不同语言描述的任务上表现出色。但它们也可能因为训练数据在语言间的不平衡而产生语言偏见，难以对相同任务的不同语言描述保持一致的响应。在本研究中，我们从安全性和质量两个维度，首次深入探讨了 LLMs 对不同语言查询的输出一致性。通过分析两个数据集（AdvBench 和 NQ）以及四种主流 LLMs（Llama2-13b、Gemma-7b、GPT-3.5-turbo 和 Gemini-pro）的表现，我们发现在英语、法语、俄语和西班牙语的查询中，LLMs 的人类对齐能力更强，有害查询的成功越狱率平均仅为 1.04%，而在孟加拉语、格鲁吉亚语、尼泊尔语和迈蒂利语中，这一比率平均高达 27.7%。此外，对于英语、丹麦语、捷克语和斯洛文尼亚语的查询，LLMs 产出的响应质量也更高，平均 $F_1$ 分数达到 0.1494。基于这些发现，我们设计了 LDFighter，一种基于相似性投票的方法，以减少 LLMs 的语言歧视，确保为不同语言的用户提供一致的服务体验。通过在良性和有害查询上的测试，LDFighter 显著降低了越狱成功率，并提升了平均响应质量，证实了其有效性。",
    "title_cn": "本文旨在探讨并缓解大型语言模型中存在的语言学歧视问题。",
    "tags": [
      "LLM应用",
      "",
      "机器学习"
    ]
  },
  {
    "title": "Evaluating Readability and Faithfulness of Concept-based Explanations",
    "submit_datetime": "2024年04月29日",
    "abstract": "Despite the surprisingly high intelligence exhibited by Large Language Models (LLMs), we are somehow intimidated to fully deploy them into real-life applications considering their black-box nature. Concept-based explanations arise as a promising avenue for explaining what the LLMs have learned, making them more transparent to humans. However, current evaluations for concepts tend to be heuristic and non-deterministic, e.g. case study or human evaluation, hindering the development of the field. To bridge the gap, we approach concept-based explanation evaluation via faithfulness and readability. We first introduce a formal definition of concept generalizable to diverse concept-based explanations. Based on this, we quantify faithfulness via the difference in the output upon perturbation. We then provide an automatic measure for readability, by measuring the coherence of patterns that maximally activate a concept. This measure serves as a cost-effective and reliable substitute for human evaluation. Finally, based on measurement theory, we describe a meta-evaluation method for evaluating the above measures via reliability and validity, which can be generalized to other tasks as well. Extensive experimental analysis has been conducted to validate and inform the selection of concept evaluation measures.",
    "pdf_link": "https://arxiv.org/abs/2404.18533",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）虽然表现出了惊人的智能，但鉴于其不可预测的黑箱特性，我们对于将它们广泛应用于现实生活仍有所保留。为了提高透明度，基于概念的解释方法应运而生，旨在阐明LLMs的学习成果。然而，目前对这些概念的评估方法大多依赖于直觉和主观判断，如个案研究或人工评审，这限制了领域的进步。为此，我们提出了一种基于忠实度和可读性的新评估方法，旨在填补这一空白。我们首先定义了一个广泛适用的概念，并据此量化模型输出在扰动下的变化，以此衡量忠实度。接着，我们通过分析最能激活特定概念的模式的一致性，来自动评估可读性，以此替代人工评估。此外，我们基于测量理论，提出了一种元评估方法，用以评估上述度量的可靠性和有效性，该方法同样适用于其他任务。为了验证和优化概念评估度量的选择，我们已经开展了深入的实验分析。",
    "title_cn": "探讨概念驱动解释的易读性与准确性。",
    "tags": [
      "分类：LLM理论",
      "人工智能",
      ""
    ]
  },
  {
    "title": "ChatGPT as an inventor: Eliciting the strengths and weaknesses of current large language models against humans in engineering design",
    "submit_datetime": "2024年04月29日",
    "abstract": "This study compares the design practices and performance of ChatGPT 4.0, a large language model (LLM), against graduate engineering students in a 48-hour prototyping hackathon, based on a dataset comprising more than 100 prototypes. The LLM participated by instructing two participants who executed its instructions and provided objective feedback, generated ideas autonomously and made all design decisions without human intervention. The LLM exhibited similar prototyping practices to human participants and finished second among six teams, successfully designing and providing building instructions for functional prototypes. The LLM's concept generation capabilities were particularly strong. However, the LLM prematurely abandoned promising concepts when facing minor difficulties, added unnecessary complexity to designs, and experienced design fixation. Communication between the LLM and participants was challenging due to vague or unclear descriptions, and the LLM had difficulty maintaining continuity and relevance in answers. Based on these findings, six recommendations for implementing an LLM like ChatGPT in the design process are proposed, including leveraging it for ideation, ensuring human oversight for key decisions, implementing iterative feedback loops, prompting it to consider alternatives, and assigning specific and manageable tasks at a subsystem level.",
    "pdf_link": "https://arxiv.org/abs/2404.18479",
    "graphs": [],
    "abstract_cn": "本项研究将大型语言模型ChatGPT 4.0的设计实践与性能，与参与48小时原型设计竞赛的研究生工程师们进行了对比，研究基于超过100个原型的数据分析。ChatGPT 4.0通过向两名参与者发出指令，由他们执行并反馈，自主构思创意，并独立做出所有设计决策，无需人为干预。该模型展现出与人类参与者相似的原型设计流程，并在六支队伍中荣获亚军，成功地设计并提供了功能性原型的构建指南。ChatGPT 4.0在概念生成方面表现出色，但在遇到小问题时会过早放弃有潜力的创意，设计中加入了不必要的复杂性，并表现出设计上的固执。由于描述不够明确，模型与参与者之间的沟通存在挑战，且在回答中保持连贯性和相关性方面存在困难。基于这些发现，研究提出了六项实施类似ChatGPT的LLM于设计流程的建议，包括利用其进行创意发想，确保人为监督关键决策，建立迭代反馈机制，鼓励其考虑多种选择，以及在子系统层面分配具体且可控的任务。",
    "title_cn": "ChatGPT：工程设计领域的创新者——揭示当前大型语言模型与人类相比的优劣所在。",
    "tags": [
      "LLM应用",
      "人工智能",
      "设计工程"
    ]
  },
  {
    "title": "HFT: Half Fine-Tuning for Large Language Models",
    "submit_datetime": "2024年04月29日",
    "abstract": "Large language models (LLMs) with one or more fine-tuning phases have become a necessary step to unlock various capabilities, enabling LLMs to follow natural language instructions or align with human preferences. However, it carries the risk of catastrophic forgetting during sequential training, the parametric knowledge or the ability learned in previous stages may be overwhelmed by incoming training data. In this paper, we find that by regularly resetting partial parameters, LLMs can restore some of the original knowledge. Inspired by this, we introduce Half Fine-Tuning (HFT) for LLMs, as a substitute for full fine-tuning (FFT), to mitigate the forgetting issues, where half of the parameters are selected to learn new tasks while the other half are frozen to remain previous knowledge. We provide a feasibility analysis from the perspective of optimization and interpret the parameter selection operation as a regularization term. Without changing the model architecture, HFT could be seamlessly integrated into existing fine-tuning frameworks. Extensive experiments and analysis on supervised fine-tuning, direct preference optimization, and continual learning consistently demonstrate the effectiveness, robustness, and efficiency of HFT. Compared with FFT, HFT not only significantly alleviates the forgetting problem, but also achieves the best performance in a series of downstream benchmarks, with an approximately 30% reduction in training time.",
    "pdf_link": "https://arxiv.org/abs/2404.18466",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）通过一个或多个微调阶段，已成为实现多样化功能的关键步骤，让模型能够遵循自然语言指令或适应人类的偏好。但这种顺序训练可能会引发灾难性遗忘，即早期学习的知识或能力可能被新的训练数据所覆盖。本文研究发现，定期重置部分参数有助于模型恢复一些原有知识。基于这一发现，我们提出了一种新的半微调（Half Fine-Tuning，HFT）方法，作为完全微调（Full Fine-Tuning，FFT）的替代方案，以缓解遗忘问题。在这种方法中，一半的参数用于学习新任务，而另一半则保持不变以维持之前的知识。我们从优化的角度对HFT进行了可行性分析，并将参数选择视为一种正则化手段。HFT可以无缝地融入现有的微调流程，而无需改变模型架构。通过在监督微调、直接偏好优化和持续学习等多个方面的广泛实验和分析，HFT展现了其在有效性、鲁棒性和效率上的优势。相较于FFT，HFT显著减少了遗忘问题，同时在多个下游任务基准测试中取得了最佳性能，并大幅缩短了约30%的训练时间。",
    "title_cn": "HFT：为大型语言模型量身定制的半微调技术",
    "tags": [
      "LLM理论",
      "机器学习",
      ""
    ]
  },
  {
    "title": "Ethical Reasoning and Moral Value Alignment of LLMs Depend on the Language we Prompt them in",
    "submit_datetime": "2024年04月29日",
    "abstract": "Ethical reasoning is a crucial skill for Large Language Models (LLMs). However, moral values are not universal, but rather influenced by language and culture. This paper explores how three prominent LLMs -- GPT-4, ChatGPT, and Llama2-70B-Chat -- perform ethical reasoning in different languages and if their moral judgement depend on the language in which they are prompted. We extend the study of ethical reasoning of LLMs by Rao et al. (2023) to a multilingual setup following their framework of probing LLMs with ethical dilemmas and policies from three branches of normative ethics: deontology, virtue, and consequentialism. We experiment with six languages: English, Spanish, Russian, Chinese, Hindi, and Swahili. We find that GPT-4 is the most consistent and unbiased ethical reasoner across languages, while ChatGPT and Llama2-70B-Chat show significant moral value bias when we move to languages other than English. Interestingly, the nature of this bias significantly vary across languages for all LLMs, including GPT-4.",
    "pdf_link": "https://arxiv.org/abs/2404.18460",
    "graphs": [],
    "abstract_cn": "伦理推理对于大型语言模型（LLMs）至关重要，但道德观念受语言与文化的影响而不尽相同。本研究考察了GPT-4、ChatGPT和Llama2-70B-Chat这三款主流LLMs在不同语言环境下的伦理推理能力，以及他们的道德判断是否会随着使用语言的不同而变化。我们依据Rao等人（2023年）的研究框架，将伦理困境和政策应用于LLMs的多语言测试，涵盖规范伦理学的三大分支：义务论、美德伦理和后果主义。实验涉及英语、西班牙语、俄语、中文、印地语和斯瓦希里语六种语言。研究结果显示，GPT-4在跨语言伦理推理中表现出最高的一致性和公正性，而ChatGPT和Llama2-70B-Chat在非英语环境下则表现出较大的道德价值偏差。值得注意的是，包括GPT-4在内的所有LLMs在不同语言中的偏差特性均有所不同。",
    "title_cn": "大型语言模型（LLM）的道德推理与价值观念的一致性，取决于我们如何用语言引导它们。",
    "tags": [
      "分类：LLM应用\n\n这篇论文研究了大型语言模型（LLMs）在不同语言环境下的伦理推理能力，以及他们的道德判断是否会随着使用语言的不同而变化。这属于LLM应用的范畴，因为它探讨了LLMs在实际应用中的表现和问题。论文并没有涉及到LLMs的理论基础，也没有讨论如何改进或构建LLMs，因此不属于LLM理论。同时，论文也没有涉及到智能代理（Agent）或知识检索（RAG）的相关内容。",
      "人工智能伦理",
      "语言模型"
    ]
  },
  {
    "title": "Chameleon: A Data-Efficient Generalist for Dense Visual Prediction in the Wild",
    "submit_datetime": "2024年04月29日",
    "abstract": "Large language models have evolved data-efficient generalists, benefiting from the universal language interface and large-scale pre-training. However, constructing a data-efficient generalist for dense visual prediction presents a distinct challenge due to the variation in label structures across different tasks. Consequently, generalization to unseen dense prediction tasks in the low-data regime is not straightforward and has received less attention from previous vision generalists. In this study, we explore a universal model that can flexibly adapt to unseen dense label structures with a few examples, enabling it to serve as a data-efficient vision generalist in diverse real-world scenarios. To this end, we base our method on a powerful meta-learning framework and explore several axes to improve its performance and versatility for real-world problems, such as flexible adaptation mechanisms and scalability. We evaluate our model across a spectrum of unseen real-world scenarios where low-shot learning is desirable, including video, 3D, medical, biological, and user-interactive tasks. Equipped with a generic architecture and an effective adaptation mechanism, our model flexibly adapts to all of these tasks with at most 50 labeled images, showcasing a significant advancement over existing data-efficient generalist approaches. Codes are available at https://github.com/GitGyun/chameleon.",
    "pdf_link": "https://arxiv.org/abs/2404.18459",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.18459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18459/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18459/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18459/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18459/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18459/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18459/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18459/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18459/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18459/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18459/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18459/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18459/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18459/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18459/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18459/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18459/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18459/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18459/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18459/x20.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18459/x21.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18459/x22.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18459/x23.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18459/x24.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18459/x25.png"
      }
    ],
    "abstract_cn": "大型语言模型已经进化为数据高效的多面手，这得益于统一的语言接口和大规模的预训练。然而，要构建一个能够应对不同任务中标签结构变化的密集视觉预测领域的数据高效多面手，面临着特别的挑战。在数据稀缺的情况下，对于未见过的密集预测任务的泛化并非易事，这一点在以往的视觉多面手研究中并未受到足够的关注。本研究中，我们探究了一种能够通过少量示例灵活适应未知密集标签结构的通用模型，使其能够在多种现实世界场景中充当数据高效的视觉多面手。为此，我们采用了一个强大的元学习框架，并探索了多个维度以提升模型的性能和适应性，包括灵活的适应机制和可扩展性。我们在一系列低样本学习需求的现实世界场景中对模型进行了评估，这些场景涵盖了视频、3D、医学、生物和用户交互任务。我们的模型凭借其通用架构和有效的适应机制，在这些任务中最多仅需50张标记图像即可灵活适应，相较于现有的数据高效多面手方法取得了显著的进步。相关代码可在 https://github.com/GitGyun/chameleon 上获取。",
    "title_cn": "变色龙：一种在野外环境中进行密集视觉预测的数据高效多面手。",
    "tags": [
      "分类：LLM应用",
      "计算机视觉",
      "元学习"
    ]
  },
  {
    "title": "BMRetriever: Tuning Large Language Models as Better Biomedical Text Retrievers",
    "submit_datetime": "2024年04月29日",
    "abstract": "Developing effective biomedical retrieval models is important for excelling at knowledge-intensive biomedical tasks but still challenging due to the deficiency of sufficient publicly annotated biomedical data and computational resources. We present BMRetriever, a series of dense retrievers for enhancing biomedical retrieval via unsupervised pre-training on large biomedical corpora, followed by instruction fine-tuning on a combination of labeled datasets and synthetic pairs. Experiments on 5 biomedical tasks across 11 datasets verify BMRetriever's efficacy on various biomedical applications. BMRetriever also exhibits strong parameter efficiency, with the 410M variant outperforming baselines up to 11.7 times larger, and the 2B variant matching the performance of models with over 5B parameters. The training data and model checkpoints are released at \\url{https://huggingface.co/BMRetriever} to ensure transparency, reproducibility, and application to new domains.",
    "pdf_link": "https://arxiv.org/abs/2404.18443",
    "graphs": [],
    "abstract_cn": "为了在知识密集型的生物医学任务中取得卓越表现，开发高效的生物医学检索模型至关重要，但这一任务因公开可用的生物医学数据标注不足和计算资源有限而充满挑战。我们介绍了 BMRetriever，这是一系列密集型检索器，通过在大规模生物医学语料库上进行无监督预训练，并在标记数据集和合成样本的组合上进行指令微调，以提升生物医学检索性能。在 11 个数据集上的 5 项生物医学任务的实验证实了 BMRetriever 在多样化应用中的高效性。BMRetriever 在参数效率上也表现出色，其 410M 版本性能超过基线模型达 11.7 倍，而 2B 版本则能与参数量超过 5B 的模型相媲美。为了确保透明度、可复现性以及促进新领域的应用，我们在 \\url{https://huggingface.co/BMRetriever} 上公开了训练数据和模型检查点。",
    "title_cn": "BMRetriever：优化大型语言模型，提升其在生物医学文本检索方面的性能。",
    "tags": [
      "分类：LLM应用\n\n这篇论文介绍了BMRetriever，这是一个针对生物医学检索任务的高效模型。它通过在大规模生物医学语料库上进行无监督预训练，并在标记数据集和合成样本的组合上进行指令微调，以提升生物医学检索性能。这表明了该研究在应用大型语言模型（LLM）于特定领域（生物医学检索）的应用上取得了显著成果。",
      "生物医学",
      "信息检索"
    ]
  },
  {
    "title": "Geospatial Big Data: Survey and Challenges",
    "submit_datetime": "2024年04月29日",
    "abstract": "In recent years, geospatial big data (GBD) has obtained attention across various disciplines, categorized into big earth observation data and big human behavior data. Identifying geospatial patterns from GBD has been a vital research focus in the fields of urban management and environmental sustainability. This paper reviews the evolution of GBD mining and its integration with advanced artificial intelligence (AI) techniques. GBD consists of data generated by satellites, sensors, mobile devices, and geographical information systems, and we categorize geospatial data based on different perspectives. We outline the process of GBD mining and demonstrate how it can be incorporated into a unified framework. Additionally, we explore new technologies like large language models (LLM), the Metaverse, and knowledge graphs, and how they could make GBD even more useful. We also share examples of GBD helping with city management and protecting the environment. Finally, we discuss the real challenges that come up when working with GBD, such as issues with data retrieval and security. Our goal is to give readers a clear view of where GBD mining stands today and where it might go next.",
    "pdf_link": "https://arxiv.org/abs/2404.18428",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.18428v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18428/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18428v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18428/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18428v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18428/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18428v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18428/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18428v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18428/x5.png"
      }
    ],
    "abstract_cn": "近年来，地理空间大数据（GBD）因其在多个学科中的应用而备受关注，主要分为地球观测大数据和人类行为大数据两大类。在城市管理和环境可持续性研究中，挖掘GBD中的地理空间模式成为了一个关键的研究议题。本文回顾了GBD挖掘技术的发展及其与先进人工智能技术的融合。GBD包括由卫星、传感器、移动设备和地理信息系统产生的数据，我们从多个角度对这些数据进行了分类。文章概述了GBD挖掘的流程，并展示了如何将其整合到一个统一的框架之中。同时，我们探讨了大型语言模型（LLM）、元宇宙和知识图谱等新兴技术，以及它们如何进一步提升GBD的应用价值。文中还展示了GBD在城市治理和环境保护方面的应用案例。最后，我们讨论了在GBD工作中遇到的挑战，包括数据获取和安全问题。我们旨在为读者提供一个清晰的视角，了解GBD挖掘的现状及其未来的发展方向。",
    "title_cn": "地理空间大数据：一项全面调查及其面临的挑战",
    "tags": [
      "分类：LLM应用\n\n这篇论文摘要讨论了地理空间大数据（GBD）的挖掘技术，以及如何将这些技术与先进的人工智能技术（包括大型语言模型LLM）融合。论文还探讨了LLM、元宇宙和知识图谱等新兴技术在GBD应用中的潜力。因此，这篇论文可以归类为LLM应用，因为它涉及到大型语言模型在地理空间大数据挖掘中的应用。",
      "城市管理",
      "环境保护"
    ]
  },
  {
    "title": "PromptReps: Prompting Large Language Models to Generate Dense and Sparse Representations for Zero-Shot Document Retrieval",
    "submit_datetime": "2024年04月29日",
    "abstract": "The current use of large language models (LLMs) for zero-shot document ranking follows one of two ways: 1) prompt-based re-ranking methods, which require no further training but are feasible for only re-ranking a handful of candidate documents due to the associated computational costs; and 2) unsupervised contrastive trained dense retrieval methods, which can retrieve relevant documents from the entire corpus but require a large amount of paired text data for contrastive training. In this paper, we propose PromptReps, which combines the advantages of both categories: no need for training and the ability to retrieve from the whole corpus. Our method only requires prompts to guide an LLM to generate query and document representations for effective document retrieval. Specifically, we prompt the LLMs to represent a given text using a single word, and then use the last token's hidden states and the corresponding logits associated to the prediction of the next token to construct a hybrid document retrieval system. The retrieval system harnesses both dense text embedding and sparse bag-of-words representations given by the LLM. Our experimental evaluation on the BEIR zero-shot document retrieval datasets illustrates that this simple prompt-based LLM retrieval method can achieve a similar or higher retrieval effectiveness than state-of-the-art LLM embedding methods that are trained with large amounts of unsupervised data, especially when using a larger LLM.",
    "pdf_link": "https://arxiv.org/abs/2404.18424",
    "graphs": [],
    "abstract_cn": "目前，大型语言模型（LLMs）在零样本文档排序的应用主要有两种策略：一是无需额外训练的基于提示的重新排序方法，尽管它因计算成本高而只适用于有限的候选文档集；二是能够遍历整个文档库的无监督对比训练密集检索方法，但这需要大量成对文本数据进行训练。本文提出了一种名为PromptReps的新方法，它融合了上述两种方法的优势——既无需训练又能全面检索文档库。该方法通过提示引导LLM生成查询和文档的表示，以便于高效检索。具体而言，我们让LLM用一个词来表示一段文本，然后利用该词的隐藏状态及其对应的预测下一个词的logits，构建一个混合型的文档检索系统。这一系统结合了LLM生成的密集文本嵌入和稀疏词袋模型。我们在BEIR零样本文档检索数据集上的实验评估显示，这种基于提示的LLM检索方法在检索效果上能与那些利用大量无监督数据训练的顶尖LLM嵌入方法相媲美，甚至在采用更大模型时更胜一筹。",
    "title_cn": "PromptReps：激发大型语言模型的潜能，为零样本文档检索任务生成既密集又稀疏的表示方法。",
    "tags": [
      "LLM应用",
      "文档检索",
      ""
    ]
  },
  {
    "title": "Sample-Efficient Robust Multi-Agent Reinforcement Learning in the Face of Environmental Uncertainty",
    "submit_datetime": "2024年04月29日",
    "abstract": "To overcome the sim-to-real gap in reinforcement learning (RL), learned policies must maintain robustness against environmental uncertainties. While robust RL has been widely studied in single-agent regimes, in multi-agent environments, the problem remains understudied -- despite the fact that the problems posed by environmental uncertainties are often exacerbated by strategic interactions. This work focuses on learning in distributionally robust Markov games (RMGs), a robust variant of standard Markov games, wherein each agent aims to learn a policy that maximizes its own worst-case performance when the deployed environment deviates within its own prescribed uncertainty set. This results in a set of robust equilibrium strategies for all agents that align with classic notions of game-theoretic equilibria. Assuming a non-adaptive sampling mechanism from a generative model, we propose a sample-efficient model-based algorithm (DRNVI) with finite-sample complexity guarantees for learning robust variants of various notions of game-theoretic equilibria. We also establish an information-theoretic lower bound for solving RMGs, which confirms the near-optimal sample complexity of DRNVI with respect to problem-dependent factors such as the size of the state space, the target accuracy, and the horizon length.",
    "pdf_link": "https://arxiv.org/abs/2404.18909",
    "graphs": [],
    "abstract_cn": "为了弥合强化学习中的仿真与现实之间的鸿沟，所学习到的策略必须对环境的不确定性具有鲁棒性。尽管在单一智能体情境下，鲁棒性强化学习已受到广泛关注，但在多智能体情境中，这一问题尚未得到充分研究，尤其是在环境不确定性因策略互动而加剧的情况下。本研究着眼于分布鲁棒马尔可夫博弈（RMGs）的学习，这是一种鲁棒性增强的马尔可夫博弈，每个智能体都旨在学习一种策略，以确保在部署环境在其预设的不确定性范围内发生偏离时，自身的最坏情况性能达到最大化。这将形成一套与经典博弈论均衡理念相符的鲁棒均衡策略。在假设生成模型采用非自适应抽样机制的前提下，我们提出了一种样本高效的基于模型算法（DRNVI），并为学习不同博弈论均衡概念的鲁棒变体提供了有限样本复杂度的保证。此外，我们还建立了解决RMGs的信息论下界，证实了DRNVI在样本复杂度上接近最优，这与问题依赖因素（如状态空间大小、目标精度和时间范围）有关。",
    "title_cn": "面对环境的不确定性，本研究提出了一种样本高效且鲁棒的多智能体强化学习方法。",
    "tags": [
      "分类：Agent",
      "",
      "多智能体系统"
    ]
  },
  {
    "title": "Multi-Agent Synchronization Tasks",
    "submit_datetime": "2024年04月29日",
    "abstract": "In multi-agent reinforcement learning (MARL), coordination plays a crucial role in enhancing agents' performance beyond what they could achieve through cooperation alone. The interdependence of agents' actions, coupled with the need for communication, leads to a domain where effective coordination is crucial. In this paper, we introduce and define $\\textit{Multi-Agent Synchronization Tasks}$ (MSTs), a novel subset of multi-agent tasks. We describe one MST, that we call $\\textit{Synchronized Predator-Prey}$, offering a detailed description that will serve as the basis for evaluating a selection of recent state-of-the-art (SOTA) MARL algorithms explicitly designed to address coordination challenges through the use of communication strategies. Furthermore, we present empirical evidence that reveals the limitations of the algorithms assessed to solve MSTs, demonstrating their inability to scale effectively beyond 2-agent coordination tasks in scenarios where communication is a requisite component. Finally, the results raise questions about the applicability of recent SOTA approaches for complex coordination tasks (i.e. MSTs) and prompt further exploration into the underlying causes of their limitations in this context.",
    "pdf_link": "https://arxiv.org/abs/2404.18798",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.18798v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18798/synchronized_pred-prey_w_3_catcher.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18798v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18798/Combined_Payoff_Represenation.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18798v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18798/penalty-full-all_conditions.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18798v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18798/penalty-full_v_empty-2_agents.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18798v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18798/no_penalty-full-all_conditions.png"
      }
    ],
    "abstract_cn": "在多智能体强化学习领域，协调是提升智能体协作效果的关键。本文提出了“多智能体同步任务”（MSTs）这一新概念，并以“同步捕食者-猎物”为例，详细阐述了其特点。这些特点将用于评估一系列专为解决协调问题而设计的先进MARL算法。研究还展示了这些算法在处理超过两个智能体的协调任务时的局限性，尤其是在沟通至关重要的情况下。最终，这些发现对于当前顶尖方法在处理复杂协调任务时的适用性提出了质疑，并激发了对这些算法局限性背后原因的深入研究。",
    "title_cn": "多智能体同步作业",
    "tags": [
      "Agent",
      "人工智能",
      "多智能体系统"
    ]
  },
  {
    "title": "Fast Swarming of UAVs in GNSS-denied Feature-poor Environments without Explicit Communication",
    "submit_datetime": "2024年04月29日",
    "abstract": "A decentralized swarm approach for the fast cooperative flight of Unmanned Aerial Vehicles (UAVs) in feature-poor environments without any external localization and communication is introduced in this paper.\n  A novel model of a UAV neighborhood is proposed to achieve robust onboard mutual perception and flocking state feedback control, which is designed to decrease the inter-agent oscillations common in standard reactive swarm models employed in fast collective motion.\n  The novel swarming methodology is supplemented with an enhanced Multi-Robot State Estimation (MRSE) strategy to increase the reliability of the purely onboard localization, which may be unreliable in real environments.\n  Although MRSE and the neighborhood model may rely on information exchange between agents, we introduce a communication-less version of the swarming framework based on estimating communicated states to decrease dependence on the often unreliable communication networks of large swarms.\n  The proposed solution has been verified by a set of complex real-world experiments to demonstrate its overall capability in different conditions, including a UAV interception-motivated task with a group velocity reaching the physical limits of the individual hardware platforms.",
    "pdf_link": "https://arxiv.org/abs/2404.18729",
    "graphs": [],
    "abstract_cn": "本文提出了一种分散式无人机群体飞行的新方法，适用于缺乏特征的环境中，无需外部定位和通信。我们设计了一种新型的无人机邻近区域模型，以增强无人机之间的相互感知和群体状态的反馈控制，有效减少了快速集体运动中常见的无人机间振荡。此外，我们还引入了一种改进的多机器人状态估计（MRSE）策略，以提升仅依赖机载定位的可靠性。尽管MRSE和邻近区域模型可能需要无人机间的信息交流，但我们开发了一种无需通信的群体框架，通过估算通信状态来降低对大型群体通信网络的依赖。该方案已通过一系列复杂的实际实验得到验证，展示了其在多变条件下的卓越性能，包括一项以无人机拦截为模拟目标的任务，其群体速度达到了单个无人机硬件平台的物理极限。",
    "title_cn": "在缺乏全球导航卫星系统信号且特征稀缺的环境中，无人机能够实现无需明确通信的快速集群飞行。",
    "tags": [
      "Agent",
      "无人机",
      "机器人"
    ]
  },
  {
    "title": "A geometric approach for stability analysis of delay systems: Applications to network dynamics",
    "submit_datetime": "2024年04月29日",
    "abstract": "Investigating the network stability or synchronization dynamics of multi-agent systems with time delays is of significant importance in numerous real-world applications. Such investigations often rely on solving the transcendental characteristic equations (TCEs) obtained from linearization of the considered systems around specific solutions. While stability results based on the TCEs with real-valued coefficients induced by symmetric networks in time-delayed models have been extensively explored in the literature, there remains a notable gap in stability analysis for the TCEs with complexvalued coefficients arising from asymmetric networked dynamics with time delays. To address this challenge comprehensively, we propose a rigorously geometric approach. By identifying and studying the stability crossing curves in the complex plane, we are able to determine the stability region of these systems. This approach is not only suitable for analyzing the stability of models with discrete time delays but also for models with various types of delays, including distributed time delays. Additionally, it can also handle random networks. We demonstrate the efficacy of this approach in designing delayed control strategies for car-following systems, mechanical systems, and deep brain stimulation modeling, where involved are complex-valued TCEs or/and different types of delays. All these therefore highlight the broad applicability of our approach across diverse domains.",
    "pdf_link": "https://arxiv.org/abs/2404.18704",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.18704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18704/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18704/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18704/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18704/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18704/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18704/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18704/fig7.jpg"
      },
      {
        "url": "https://arxiv.org/html/2404.18704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18704/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18704/fig9.jpg"
      },
      {
        "url": "https://arxiv.org/html/2404.18704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18704/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18704/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18704/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18704/fig12.jpg"
      },
      {
        "url": "https://arxiv.org/html/2404.18704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18704/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18704/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18704/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18704/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18704/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18704/x16.png"
      }
    ],
    "abstract_cn": "探究具有时间延迟的多智能体系统的稳定性与同步行为对于现实世界中的众多应用至关重要。此类研究通常需要求解从特定解出发对系统进行线性化后得到的超越特征方程（TCEs）。尽管关于由对称网络在时间延迟模型中引起的实系数TCEs的稳定性研究已广泛开展，但对于由非对称网络动态引起的复值系数TCEs的稳定性分析尚存在明显缺口。为全面应对这一挑战，我们提出了一种严谨的几何分析方法。通过分析复平面上的稳定性临界曲线，我们得以界定这些系统的稳定区域。此方法不仅适用于离散时间延迟模型，也适用于包含分布式延迟等多种延迟类型的模型，并且能够处理随机网络。我们通过为汽车跟随系统、机械系统和深脑刺激模型设计延迟控制策略，证明了该方法在处理复值TCEs或不同类型延迟时的有效性，从而突显了该方法在多个领域的广泛适用性。",
    "title_cn": "本文介绍了一种新颖的几何方法，用于分析具有延迟的系统的稳定性，并将其应用于网络动态的研究。",
    "tags": [
      "Agent",
      "智能体系统",
      "控制理论"
    ]
  },
  {
    "title": "MRIC: Model-Based Reinforcement-Imitation Learning with Mixture-of-Codebooks for Autonomous Driving Simulation",
    "submit_datetime": "2024年04月29日",
    "abstract": "Accurately simulating diverse behaviors of heterogeneous agents in various scenarios is fundamental to autonomous driving simulation. This task is challenging due to the multi-modality of behavior distribution, the high-dimensionality of driving scenarios, distribution shift, and incomplete information. Our first insight is to leverage state-matching through differentiable simulation to provide meaningful learning signals and achieve efficient credit assignment for the policy. This is demonstrated by revealing the existence of gradient highways and interagent gradient pathways. However, the issues of gradient explosion and weak supervision in low-density regions are discovered. Our second insight is that these issues can be addressed by applying dual policy regularizations to narrow the function space. Further considering diversity, our third insight is that the behaviors of heterogeneous agents in the dataset can be effectively compressed as a series of prototype vectors for retrieval. These lead to our model-based reinforcement-imitation learning framework with temporally abstracted mixture-of-codebooks (MRIC). MRIC introduces the open-loop modelbased imitation learning regularization to stabilize training, and modelbased reinforcement learning (RL) regularization to inject domain knowledge. The RL regularization involves differentiable Minkowskidifference-based collision avoidance and projection-based on-road and traffic rule compliance rewards. A dynamic multiplier mechanism is further proposed to eliminate the interference from the regularizations while ensuring their effectiveness. Experimental results using the largescale Waymo open motion dataset show that MRIC outperforms state-ofthe-art baselines on diversity, behavioral realism, and distributional realism, with large margins on some key metrics (e.g., collision rate, minSADE, and time-to-collision JSD).",
    "pdf_link": "https://arxiv.org/abs/2404.18464",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x20.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x21.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x22.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x23.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x24.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x25.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x26.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x27.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x28.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x29.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x30.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x31.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x32.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x33.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x34.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x35.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x36.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x37.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x38.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x39.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x40.png"
      }
    ],
    "abstract_cn": "精确地模拟各种情境下异构智能体的多样行为对于自动驾驶仿真至关重要。这一任务因行为分布的多样性、驾驶情境的高维度、分布偏移和信息缺失等因素而充满挑战。我们首先洞察到，通过可微仿真实现的状态匹配，能够提供有益的学习信号，为策略高效分配信用。这一点通过发现梯度高速公路和智能体间的梯度路径而得到证实。然而，我们也发现了梯度爆炸和低密度区域中的弱监督问题。我们的第二个洞察是，这些问题可以通过双重策略正则化来解决，以此缩小功能空间。考虑到多样性，我们的第三个洞察是，数据集中异构智能体的行为可以被有效压缩成一系列原型向量，以便于检索。这些洞察催生了我们的基于模型的强化模仿学习框架——时间抽象的混合码本（MRIC）。MRIC引入了开环模型基模仿学习正则化以稳定训练，并融入了基于模型的强化学习（RL）正则化以注入领域知识。RL正则化包括了基于可微分的Minkowski差异的避碰机制，以及基于投影的遵守道路和交通规则的奖励。此外，我们还提出了一种动态乘数机制，以消除正则化间的干扰并确保其效果。在大规模Waymo开放运动数据集上的实验结果显示，MRIC在多样性、行为真实性和分布真实性方面均超越了现有的最先进基线，尤其在关键指标（如碰撞率、最小SADE和碰撞时间JSD）上取得了显著优势。",
    "title_cn": "MRIC：一种融合码本混合技术的模型驱动强化模仿学习方法，专为自动驾驶模拟设计。",
    "tags": [
      "分类：Agent",
      "自动驾驶",
      "仿真技术"
    ]
  },
  {
    "title": "Multi-hop Question Answering over Knowledge Graphs using Large Language Models",
    "submit_datetime": "2024年04月29日",
    "abstract": "Knowledge graphs (KGs) are large datasets with specific structures representing large knowledge bases (KB) where each node represents a key entity and relations amongst them are typed edges. Natural language queries formed to extract information from a KB entail starting from specific nodes and reasoning over multiple edges of the corresponding KG to arrive at the correct set of answer nodes. Traditional approaches of question answering on KG are based on (a) semantic parsing (SP), where a logical form (e.g., S-expression, SPARQL query, etc.) is generated using node and edge embeddings and then reasoning over these representations or tuning language models to generate the final answer directly, or (b) information-retrieval based that works by extracting entities and relations sequentially. In this work, we evaluate the capability of (LLMs) to answer questions over KG that involve multiple hops. We show that depending upon the size and nature of the KG we need different approaches to extract and feed the relevant information to an LLM since every LLM comes with a fixed context window. We evaluate our approach on six KGs with and without the availability of example-specific sub-graphs and show that both the IR and SP-based methods can be adopted by LLMs resulting in an extremely competitive performance.",
    "pdf_link": "https://arxiv.org/abs/2404.19234",
    "graphs": [],
    "abstract_cn": "知识图谱（KGs）是结构化的海量数据集，它们构成了庞大的知识库（KB），每个节点代表一个核心实体，实体间的关系则以类型化的边来表示。要从KB中提取信息，自然语言查询需要从特定节点出发，沿着KG的多条边进行推理，以找到正确的答案节点集。在KG上的问答传统方法包括：（a）语义解析（SP），通过节点和边的嵌入生成逻辑形式（如S表达式、SPARQL查询等），然后在这些表示上进行推理，或调整语言模型以直接生成最终答案；（b）基于信息检索的方法，它通过顺序提取实体和关系来实现。本研究评估了大型语言模型（LLMs）在处理涉及多跳推理的KG问答任务上的能力。我们发现，根据不同KG的规模和特点，我们需要采取不同的策略来提取并向LLM提供相关信息，因为每个LLM都有一个固定的上下文窗口。我们在六个KG上进行了评估，包括有和没有特定子图的示例，结果表明，无论是基于信息检索（IR）还是语义解析（SP）的方法，LLMs都能采纳并展现出极其有竞争力的性能。",
    "title_cn": "利用大型语言模型，实现在知识图谱上的多步推理问答。",
    "tags": [
      "LLM应用",
      "知识图谱",
      "问答系统"
    ]
  },
  {
    "title": "Espresso: Robust Concept Filtering in Text-to-Image Models",
    "submit_datetime": "2024年04月29日",
    "abstract": "Diffusion-based text-to-image (T2I) models generate high-fidelity images for given textual prompts. They are trained on large datasets scraped from the Internet, potentially containing unacceptable concepts (e.g., copyright infringing or unsafe). Retraining T2I models after filtering out unacceptable concepts in the training data is inefficient and degrades utility. Hence, there is a need for concept removal techniques (CRTs) which are effective in removing unacceptable concepts, utility-preserving on acceptable concepts, and robust against evasion with adversarial prompts. None of the prior filtering and fine-tuning CRTs satisfy all these requirements simultaneously.\n  We introduce Espresso, the first robust concept filter based on Contrastive Language-Image Pre-Training (CLIP). It identifies unacceptable concepts by projecting the generated image's embedding onto the vector connecting unacceptable and acceptable concepts in the joint text-image embedding space. This ensures robustness by restricting the adversary to adding noise only along this vector, in the direction of the acceptable concept. Further fine-tuning Espresso to separate embeddings of acceptable and unacceptable concepts, while preserving their pairing with image embeddings, ensures both effectiveness and utility. We evaluate Espresso on eleven concepts to show that it is effective (~5% CLIP accuracy on unacceptable concepts), utility-preserving (~93% normalized CLIP score on acceptable concepts), and robust (~4% CLIP accuracy on adversarial prompts for unacceptable concepts). Finally, we present theoretical bounds for the certified robustness of Espresso against adversarial prompts, and an empirical analysis.",
    "pdf_link": "https://arxiv.org/abs/2404.19227",
    "graphs": [],
    "abstract_cn": "基于扩散原理的文本到图像（T2I）模型能够根据文本提示生成高清晰度的图像，这些模型通常在互联网上搜集的大型数据集上进行训练，但这些数据集可能潜藏不当内容，如侵权或不适宜的内容。在剔除了训练数据中的不当概念后，重新训练T2I模型不仅效率低下，还会影响其功能性。因此，迫切需要一种能够有效移除不当概念、保留适当概念的实用性，并且能够抵御对抗性提示的概念移除技术（CRTs）。目前，尚无现有的过滤和微调CRTs能够完全满足这些需求。我们在此推出Espresso，这是首个基于对比性语言-图像预训练（CLIP）的鲁棒性概念过滤器。Espresso通过将生成图像的嵌入向量投影到联合文本-图像嵌入空间中，连接不可接受与可接受概念的向量上，来辨识出不当概念。这种方法通过限制对手只能在该向量上，朝向可接受概念的方向添加噪声，从而确保了系统的鲁棒性。Espresso进一步经过微调，以区分可接受与不可接受概念的嵌入，同时保持它们与图像嵌入的对应关系，这样既保证了效果也兼顾了实用性。我们在11个概念上对Espresso进行了评估，结果表明其具有高效果（在不可接受概念上的CLIP准确率约为5%），实用性（在可接受概念上的CLIP得分约为93%），以及鲁棒性（在对抗性提示的不可接受概念上的CLIP准确率约为4%）。最后，我们为Espresso面对对抗性提示的认证鲁棒性提供了理论界限，并进行了实证分析。",
    "title_cn": "Espresso：文本到图像模型中的稳健概念筛选",
    "tags": [
      "LLM应用",
      "图像生成",
      "内容过滤"
    ]
  },
  {
    "title": "Transcrib3D: 3D Referring Expression Resolution through Large Language Models",
    "submit_datetime": "2024年04月29日",
    "abstract": "If robots are to work effectively alongside people, they must be able to interpret natural language references to objects in their 3D environment. Understanding 3D referring expressions is challenging -- it requires the ability to both parse the 3D structure of the scene and correctly ground free-form language in the presence of distraction and clutter. We introduce Transcrib3D, an approach that brings together 3D detection methods and the emergent reasoning capabilities of large language models (LLMs). Transcrib3D uses text as the unifying medium, which allows us to sidestep the need to learn shared representations connecting multi-modal inputs, which would require massive amounts of annotated 3D data. As a demonstration of its effectiveness, Transcrib3D achieves state-of-the-art results on 3D reference resolution benchmarks, with a great leap in performance from previous multi-modality baselines. To improve upon zero-shot performance and facilitate local deployment on edge computers and robots, we propose self-correction for fine-tuning that trains smaller models, resulting in performance close to that of large models. We show that our method enables a real robot to perform pick-and-place tasks given queries that contain challenging referring expressions. Project site is at https://ripl.github.io/Transcrib3D.",
    "pdf_link": "https://arxiv.org/abs/2404.19221",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.19221v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19221/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19221v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19221/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19221v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19221/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19221v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19221/transcrib3d_success_2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19221v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19221/The_foremost_pillow_on_the_bed_of_the_group_of_pillows.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19221v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19221/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19221v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19221/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19221v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19221/The_cylinder_shaped_trash_can.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19221v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19221/This_door_is_open_and_has_nothing_blocking_it.png"
      }
    ],
    "abstract_cn": "为了让机器人与人类协同高效工作，它们必须能够理解其三维环境中物体的自然语言指引。解析三维指示性表达是一项挑战性任务，它不仅需要解析场景的三维结构，还需要在干扰和杂乱的环境中准确理解自由形式的语言。我们推出了Transcrib3D，这是一种融合了三维检测技术和大型语言模型（LLMs）的新兴推理能力的方法。Transcrib3D采用文本作为统一的交互媒介，巧妙地规避了学习多模态输入之间共享表示的需求，这通常需要大量的标注三维数据。在实际效果展示上，Transcrib3D在三维参考解析基准测试中取得了行业领先的成绩，与以往的多模态基准相比，性能有了显著提升。为了进一步提升零样本性能并实现在边缘计算设备和机器人上的本地部署，我们提出了一种自我校正的微调方法，用于训练更小型的模型，使得性能接近大型模型的水平。我们证明了该方法能够使真实机器人在面对包含复杂指示性表达的查询时，成功执行拣选和放置任务。项目详情请访问 https://ripl.github.io/Transcrib3D。",
    "title_cn": "Transcrib3D：借助大型语言模型，实现三维引用表达的精准解析。",
    "tags": [
      "分类：Agent",
      "机器人技术",
      ""
    ]
  },
  {
    "title": "TableVQA-Bench: A Visual Question Answering Benchmark on Multiple Table Domains",
    "submit_datetime": "2024年04月29日",
    "abstract": "In this paper, we establish a benchmark for table visual question answering, referred to as the TableVQA-Bench, derived from pre-existing table question-answering (QA) and table structure recognition datasets. It is important to note that existing datasets have not incorporated images or QA pairs, which are two crucial components of TableVQA. As such, the primary objective of this paper is to obtain these necessary components. Specifically, images are sourced either through the application of a \\textit{stylesheet} or by employing the proposed table rendering system. QA pairs are generated by exploiting the large language model (LLM) where the input is a text-formatted table. Ultimately, the completed TableVQA-Bench comprises 1,500 QA pairs. We comprehensively compare the performance of various multi-modal large language models (MLLMs) on TableVQA-Bench. GPT-4V achieves the highest accuracy among commercial and open-sourced MLLMs from our experiments. Moreover, we discover that the number of vision queries plays a significant role in TableVQA performance. To further analyze the capabilities of MLLMs in comparison to their LLM backbones, we investigate by presenting image-formatted tables to MLLMs and text-formatted tables to LLMs, respectively. Our findings suggest that processing visual inputs is more challenging than text inputs, as evidenced by the lower performance of MLLMs, despite generally requiring higher computational costs than LLMs. The proposed TableVQA-Bench and evaluation codes are available at \\href{https://github.com/naver-ai/tablevqabench}{https://github.com/naver-ai/tablevqabench}.",
    "pdf_link": "https://arxiv.org/abs/2404.19205",
    "graphs": [],
    "abstract_cn": "本文提出了一个名为 TableVQA-Bench 的表格视觉问答基准测试，该基准基于现有的表格问答和结构识别数据集。现有数据集尚未整合图像或问答对，而这两者对于表格视觉问答至关重要。本文旨在补充这些关键元素。图像来源可以是应用样式表或采用我们提出的表格渲染系统。问答对则是通过大型语言模型（LLM）生成，输入为文本格式的表格。构建完成的 TableVQA-Bench 包含了 1,500 组问答对。我们还对多种多模态大型语言模型（MLLMs）在该基准上的表现进行了全面比较，发现 GPT-4V 在商业和开源 MLLMs 中准确度最高。此外，视觉查询的数量对性能有显著影响。为了深入分析 MLLMs 与其基础 LLMs 的能力差异，我们分别向 MLLMs 和 LLMs 展示了图像格式和文本格式的表格。研究结果表明，处理视觉输入相较于文本输入更具挑战性，尽管 MLLMs 通常需要更高的计算资源，但其性能却低于 LLMs。我们提供的 TableVQA-Bench 基准测试和评估代码可在 GitHub 上找到。",
    "title_cn": "TableVQA-Bench：多表格领域的视觉问答基准测试",
    "tags": [
      "LLM应用",
      "视觉问答",
      "数据科学"
    ]
  },
  {
    "title": "PEVA-Net: Prompt-Enhanced View Aggregation Network for Zero/Few-Shot Multi-View 3D Shape Recognition",
    "submit_datetime": "2024年04月29日",
    "abstract": "Large vision-language models have impressively promote the performance of 2D visual recognition under zero/few-shot scenarios. In this paper, we focus on exploiting the large vision-language model, i.e., CLIP, to address zero/few-shot 3D shape recognition based on multi-view representations. The key challenge for both tasks is to generate a discriminative descriptor of the 3D shape represented by multiple view images under the scenarios of either without explicit training (zero-shot 3D shape recognition) or training with a limited number of data (few-shot 3D shape recognition). We analyze that both tasks are relevant and can be considered simultaneously. Specifically, leveraging the descriptor which is effective for zero-shot inference to guide the tuning of the aggregated descriptor under the few-shot training can significantly improve the few-shot learning efficacy. Hence, we propose Prompt-Enhanced View Aggregation Network (PEVA-Net) to simultaneously address zero/few-shot 3D shape recognition. Under the zero-shot scenario, we propose to leverage the prompts built up from candidate categories to enhance the aggregation process of multiple view-associated visual features. The resulting aggregated feature serves for effective zero-shot recognition of the 3D shapes. Under the few-shot scenario, we first exploit a transformer encoder to aggregate the view-associated visual features into a global descriptor. To tune the encoder, together with the main classification loss, we propose a self-distillation scheme via a feature distillation loss by treating the zero-shot descriptor as the guidance signal for the few-shot descriptor. This scheme can significantly enhance the few-shot learning efficacy.",
    "pdf_link": "https://arxiv.org/abs/2404.19168",
    "graphs": [],
    "abstract_cn": "大型视觉-语言模型显著提升了二维视觉识别在零样本/少样本场景下的性能。本文着眼于运用大型视觉-语言模型CLIP，针对基于多视图表示的零样本/少样本三维形状识别进行研究。核心挑战在于生成能够代表三维形状的多视图图像的区分性描述符，无论是在完全没有显式训练（零样本三维形状识别）还是只有少量数据训练（少样本三维形状识别）的情况下。我们发现这两个任务不仅相关，而且可以一并处理。具体而言，利用对零样本推断有效的描述符来指导少样本训练中的聚合描述符的调整，可以有效提升少样本学习的效果。因此，我们提出了增强型视图聚合网络（PEVA-Net），以同时应对零样本/少样本三维形状识别的挑战。在零样本场景下，我们提出利用候选类别构建的提示来增强多视图相关视觉特征的聚合。这样聚合得到的特征能够有效地用于零样本三维形状识别。而在少样本场景下，我们首先使用变换器编码器将视图相关视觉特征整合成全局描述符，并通过自我蒸馏策略，结合零样本描述符作为引导信号，通过特征蒸馏损失来调整编码器，从而显著提升少样本学习的效果。",
    "title_cn": "PEVA-Net：一种用于零样本或少样本多视角3D形状识别的增强提示视图聚合网络。",
    "tags": [
      "分类：LLM应用",
      "计算机视觉",
      "机器学习"
    ]
  },
  {
    "title": "What Drives Performance in Multilingual Language Models?",
    "submit_datetime": "2024年04月29日",
    "abstract": "This study investigates the factors influencing the performance of multilingual large language models (MLLMs) across diverse languages. We study 6 MLLMs, including masked language models, autoregressive models, and instruction-tuned LLMs, on the SIB-200 dataset, a topic classification dataset encompassing 204 languages. Our analysis considers three scenarios: ALL languages, SEEN languages (present in the model's pretraining data), and UNSEEN languages (not present or documented in the model's pretraining data in any meaningful way). We examine the impact of factors such as pretraining data size, general resource availability, language family, and script type on model performance. Decision tree analysis reveals that pretraining data size is the most influential factor for SEEN languages. However, interestingly, script type and language family are crucial for UNSEEN languages, highlighting the importance of cross-lingual transfer learning. Notably, model size and architecture do not significantly alter the most important features identified. Our findings provide valuable insights into the strengths and limitations of current MLLMs and hope to guide the development of more effective and equitable multilingual NLP systems.",
    "pdf_link": "https://arxiv.org/abs/2404.19159",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.19159v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19159/res-level.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19159v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19159/bloom-560m_SEEN.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19159v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19159/3models-res.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19159v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19159/lang-fam.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19159v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19159/script.png"
      }
    ],
    "abstract_cn": "本研究深入探讨了影响多语言大型语言模型（MLLMs）在多种语言中表现的各种因素。通过对六种不同的MLLMs进行分析，包括掩蔽语言模型、自回归模型和经过指令调整的LLMs，我们利用涵盖204种语言的SIB-200主题分类数据集进行了研究。研究区分了三种不同的语言场景：所有语言、预训练数据中出现过的“已见语言”，以及从未出现或未被记录的“未见语言”。我们评估了预训练数据规模、资源普遍可用性、语言系属和文字类型等因素对模型效能的影响。决策树分析显示，对于“已见语言”，预训练数据的规模是最关键的影响因素。然而，对于“未见语言”，文字类型和语言系属显得尤为重要，这强调了跨语言迁移学习的关键作用。值得注意的一点是，模型的大小和架构并不显著影响识别出的主要特征。这些发现不仅揭示了当前MLLMs的优势和局限，而且为未来更高效、更公平的多语言自然语言处理系统的发展提供了指导。",
    "title_cn": "驱动多语言语言模型性能的因素是什么？",
    "tags": [
      "分类：LLM理论",
      "",
      "机器学习"
    ]
  },
  {
    "title": "Automated Construction of Theme-specific Knowledge Graphs",
    "submit_datetime": "2024年04月29日",
    "abstract": "Despite widespread applications of knowledge graphs (KGs) in various tasks such as question answering and intelligent conversational systems, existing KGs face two major challenges: information granularity and deficiency in timeliness. These hinder considerably the retrieval and analysis of in-context, fine-grained, and up-to-date knowledge from KGs, particularly in highly specialized themes (e.g., specialized scientific research) and rapidly evolving contexts (e.g., breaking news or disaster tracking). To tackle such challenges, we propose a theme-specific knowledge graph (i.e., ThemeKG), a KG constructed from a theme-specific corpus, and design an unsupervised framework for ThemeKG construction (named TKGCon). The framework takes raw theme-specific corpus and generates a high-quality KG that includes salient entities and relations under the theme. Specifically, we start with an entity ontology of the theme from Wikipedia, based on which we then generate candidate relations by Large Language Models (LLMs) to construct a relation ontology. To parse the documents from the theme corpus, we first map the extracted entity pairs to the ontology and retrieve the candidate relations. Finally, we incorporate the context and ontology to consolidate the relations for entity pairs. We observe that directly prompting GPT-4 for theme-specific KG leads to inaccurate entities (such as \"two main types\" as one entity in the query result) and unclear (such as \"is\", \"has\") or wrong relations (such as \"have due to\", \"to start\"). In contrast, by constructing the theme-specific KG step by step, our model outperforms GPT-4 and could consistently identify accurate entities and relations. Experimental results also show that our framework excels in evaluations compared with various KG construction baselines.",
    "pdf_link": "https://arxiv.org/abs/2404.19146",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.19146v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19146/intro8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19146v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19146/overview11.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19146v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19146/cased.png"
      }
    ],
    "abstract_cn": "知识图谱在问答和智能对话系统等任务中应用广泛，但现有知识图谱在信息细节和即时性上存在不足，尤其在专业研究和快速变化的情境如突发新闻追踪中，这些不足严重影响了知识的检索与分析。为此，我们提出了一个针对特定主题的知识图谱（ThemeKG），并设计了一个无监督的构建框架（TKGCon）。该框架能够从特定主题的原始语料库中提炼出包含关键实体和关系的高质量知识图谱。我们首先利用维基百科中的实体本体作为起点，然后利用大型语言模型（LLMs）探索候选关系，形成关系本体。在处理主题语料库的文档时，我们将实体对与本体映射，筛选出候选关系。最终，结合上下文和本体，我们巩固了实体对之间的关系。我们发现，直接向GPT-4查询特定主题的知识图谱会导致实体识别不准确，关系描述模糊或错误。而我们的模型通过逐步构建主题知识图谱，在准确性上超越了GPT-4。实验结果显示，我们的框架在各项评估中均优于传统知识图谱构建方法。",
    "title_cn": "自动化构建针对性主题的知识图谱",
    "tags": [
      "分类：LLM应用",
      "问答系统",
      "知识图谱"
    ]
  },
  {
    "title": "Accelerating Production LLMs with Combined Token/Embedding Speculators",
    "submit_datetime": "2024年04月29日",
    "abstract": "This technical report describes the design and training of novel speculative decoding draft models, for accelerating the inference speeds of large language models in a production environment. By conditioning draft predictions on both context vectors and sampled tokens, we can train our speculators to efficiently predict high-quality n-grams, which the base model then accepts or rejects. This allows us to effectively predict multiple tokens per inference forward pass, accelerating wall-clock inference speeds of highly optimized base model implementations by a factor of 2-3x. We explore these initial results and describe next steps for further improvements.",
    "pdf_link": "https://arxiv.org/abs/2404.19124",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.19124v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19124/specu_arch.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19124v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19124/specu_losses.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19124v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19124/tgis_graphs.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19124v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19124/granite_graphs.png"
      }
    ],
    "abstract_cn": "本篇技术报告详细介绍了一种创新的推测性解码草案模型的设计与训练过程，目的在于提升大型语言模型在生产环境下的推理效率。我们的方法是通过结合上下文向量和采样标记来训练模型，使其能够高效地预测出高质量的n-gram序列，随后基础模型将决定是否采纳这些预测结果。这一策略显著提升了优化后的基础模型的推理速度，加速比达到了2至3倍。报告中还讨论了初步成果，并对未来的改进方向进行了展望。",
    "title_cn": "结合令牌与嵌入预测器，我们能够加速大型语言模型的生产流程。",
    "tags": [
      "LLM应用",
      "",
      "机器学习"
    ]
  },
  {
    "title": "Exploring the Capability of LLMs in Performing Low-Level Visual Analytic Tasks on SVG Data Visualizations",
    "submit_datetime": "2024年04月29日",
    "abstract": "Data visualizations help extract insights from datasets, but reaching these insights requires decomposing high level goals into low-level analytic tasks that can be complex due to varying data literacy and experience. Recent advancements in large language models (LLMs) have shown promise for lowering barriers for users to achieve tasks such as writing code. Scalable Vector Graphics (SVG), a text-based image format common in data visualizations, matches well with the text sequence processing of transformer-based LLMs. In this paper, we explore the capability of LLMs to perform low-level visual analytic tasks defined by Amar, Eagan, and Stasko directly on SVG-based visualizations. Using zero-shot prompts, we instruct the models to provide responses or modify the SVG code based on given visualizations. Our findings demonstrate that LLMs can effectively modify existing SVG visualizations for specific tasks like Cluster but perform poorly on tasks requiring a sequence of math operations. We also discovered that LLM performance varies based on factors such as the number of data points, the presence of value labels, and the chart type. Our findings contribute to gauging the general capabilities of LLMs and highlight the need for further exploration and development to fully harness their potential in supporting visual analytic tasks.",
    "pdf_link": "https://arxiv.org/abs/2404.19097",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.19097v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19097/teasor.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19097v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19097/prompt.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19097v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19097/retrieval.png"
      }
    ],
    "abstract_cn": "数据可视化是洞察数据集的利器，但要深入挖掘这些洞见，需将宏观目标细化为微观分析任务，这一过程可能因个人数据理解能力和经验的差异而变得颇具挑战。近期，大型语言模型（LLMs）的进展为简化用户执行编码等任务的难度带来了希望。作为数据可视化中常用的基于文本的图像格式，可缩放矢量图形（SVG）与基于变换器的LLMs的文本序列处理能力相得益彰。本文旨在探讨LLMs在SVG可视化基础上执行Amar、Eagan和Stasko定义的微观视觉分析任务的能力。我们利用零次拍摄提示，引导模型根据特定的可视化结果提供反馈或调整SVG代码。研究结果显示，LLMs能够高效地为特定任务（如聚类）修改SVG可视化，但在需要连续数学运算的任务上表现欠佳。此外，我们还发现LLMs的表现受到数据点数量、值标签的有无以及图表类型的不同影响。这些发现不仅为我们评估LLMs的通用能力提供了参考，也突显了进一步探索和发展的必要性，以便更好地发挥它们在视觉分析任务中的辅助作用。",
    "title_cn": "本文旨在探究大型语言模型在处理SVG数据可视化时，执行基础视觉分析任务的潜力。",
    "tags": [
      "LLM应用",
      "数据可视化",
      ""
    ]
  },
  {
    "title": "In-Context Symbolic Regression: Leveraging Language Models for Function Discovery",
    "submit_datetime": "2024年04月29日",
    "abstract": "Symbolic Regression (SR) is a task which aims to extract the mathematical expression underlying a set of empirical observations. Transformer-based methods trained on SR datasets detain the current state-of-the-art in this task, while the application of Large Language Models (LLMs) to SR remains unexplored. This work investigates the integration of pre-trained LLMs into the SR pipeline, utilizing an approach that iteratively refines a functional form based on the prediction error it achieves on the observation set, until it reaches convergence. Our method leverages LLMs to propose an initial set of possible functions based on the observations, exploiting their strong pre-training prior. These functions are then iteratively refined by the model itself and by an external optimizer for their coefficients. The process is repeated until the results are satisfactory. We then analyze Vision-Language Models in this context, exploring the inclusion of plots as visual inputs to aid the optimization process. Our findings reveal that LLMs are able to successfully recover good symbolic equations that fit the given data, outperforming SR baselines based on Genetic Programming, with the addition of images in the input showing promising results for the most complex benchmarks.",
    "pdf_link": "https://arxiv.org/abs/2404.19094",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.19094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19094/sketch.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19094/points.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19094/example.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19094/nguyen_llama.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19094/nguyen_llava.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19094/constant_llama.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19094/constant_llava.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19094/keijzer_llama.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19094/keijzer_llava.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19094/R_llama.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19094/R_llava.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19094/keijzer_seedonly.png"
      }
    ],
    "abstract_cn": "符号回归（SR）目标是从一系列经验数据中提炼出相应的数学表达式。目前，基于Transformer的模型在SR领域的性能领先，但大型语言模型（LLMs）在SR中的应用尚未被充分挖掘。本研究探讨了将预训练的LLMs整合到SR流程中，通过迭代优化函数形式，直至预测误差在观测集上达到最小并收敛。我们利用LLMs强大的预训练知识，提出基于观测数据的初始函数集，然后通过模型自身和外部优化器对这些函数及其系数进行迭代细化。在结果令人满意之前，这一过程将持续进行。此外，我们还研究了视觉-语言模型在SR中的表现，特别是通过将图表作为视觉输入来辅助优化过程。研究发现，LLMs在恢复与给定数据相匹配的高质量符号方程方面表现出色，性能超过了基于遗传编程的SR基线，且在输入中加入图像对于解决最复杂的基准测试显示出了积极的成效。",
    "title_cn": "利用语言模型进行函数发现：探索上下文符号回归。",
    "tags": [
      "LLM应用",
      "科学计算",
      "自动化设计"
    ]
  },
  {
    "title": "Large Language Models as Conversational Movie Recommenders: A User Study",
    "submit_datetime": "2024年04月29日",
    "abstract": "This paper explores the effectiveness of using large language models (LLMs) for personalized movie recommendations from users' perspectives in an online field experiment. Our study involves a combination of between-subject prompt and historic consumption assessments, along with within-subject recommendation scenario evaluations. By examining conversation and survey response data from 160 active users, we find that LLMs offer strong recommendation explainability but lack overall personalization, diversity, and user trust. Our results also indicate that different personalized prompting techniques do not significantly affect user-perceived recommendation quality, but the number of movies a user has watched plays a more significant role. Furthermore, LLMs show a greater ability to recommend lesser-known or niche movies. Through qualitative analysis, we identify key conversational patterns linked to positive and negative user interaction experiences and conclude that providing personal context and examples is crucial for obtaining high-quality recommendations from LLMs.",
    "pdf_link": "https://arxiv.org/abs/2404.19093",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.19093v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19093/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19093v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19093/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19093v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19093/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19093v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19093/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19093v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19093/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19093v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19093/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19093v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19093/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19093v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19093/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19093v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19093/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19093v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19093/x10.png"
      }
    ],
    "abstract_cn": "本研究在线实地实验中，从用户视角出发，探究了运用大型语言模型（LLMs）进行个性化电影推荐的效能。研究结合了受试者间的提示与历史消费评估，以及受试者内的推荐场景评价。通过对160位活跃用户的对话和调查反馈进行分析，我们发现LLMs在推荐解释性上表现出色，但在个性化、多样性和赢得用户信任方面尚有欠缺。研究还发现，不同的个性化提示手法并未显著提升用户对推荐质量的感知，而用户观影数量的多少则更为关键。此外，LLMs在推荐知名度较低或小众电影方面更具优势。通过深入的定性分析，我们揭示了与用户互动体验正负面相关的主要对话模式，并得出结论，提供个性化的背景和实例对于从LLMs获得优质推荐至关重要。",
    "title_cn": "大型语言模型：对话式电影推荐的用户研究",
    "tags": [
      "LLM应用",
      "",
      "个性化推荐"
    ]
  },
  {
    "title": "HELPER-X: A Unified Instructable Embodied Agent to Tackle Four Interactive Vision-Language Domains with Memory-Augmented Language Models",
    "submit_datetime": "2024年04月29日",
    "abstract": "Recent research on instructable agents has used memory-augmented Large Language Models (LLMs) as task planners, a technique that retrieves language-program examples relevant to the input instruction and uses them as in-context examples in the LLM prompt to improve the performance of the LLM in inferring the correct action and task plans. In this technical report, we extend the capabilities of HELPER, by expanding its memory with a wider array of examples and prompts, and by integrating additional APIs for asking questions. This simple expansion of HELPER into a shared memory enables the agent to work across the domains of executing plans from dialogue, natural language instruction following, active question asking, and commonsense room reorganization. We evaluate the agent on four diverse interactive visual-language embodied agent benchmarks: ALFRED, TEACh, DialFRED, and the Tidy Task. HELPER-X achieves few-shot, state-of-the-art performance across these benchmarks using a single agent, without requiring in-domain training, and remains competitive with agents that have undergone in-domain training.",
    "pdf_link": "https://arxiv.org/abs/2404.19065",
    "graphs": [],
    "abstract_cn": "最新研究利用具备增强记忆功能的大型语言模型（LLMs）作为任务规划器，通过检索与输入指令紧密相关的语言程序实例，并将其作为上下文示例嵌入LLM的提示中，从而提升了LLM在推导正确行动和任务规划方面的性能。本技术报告进一步扩展了HELPER的功能，不仅扩充了其记忆库，加入了更多样的示例和提示，还整合了更多API以支持提问。这一扩展使得HELPER能够在多个领域内发挥作用，包括从对话中执行计划、遵循自然语言指令、主动提问以及基于常识的房间重组。我们在四个多样化的交互式视觉-语言体现代理基准测试中对代理进行了评估：ALFRED、TEACh、DialFRED和Tidy Task。HELPER-X在这些测试中展现了少量样本学习下的顶尖性能，且无需特定领域训练即可与经过领域训练的代理相媲美。",
    "title_cn": "HELPER-X：一款集成的可指导实体代理，搭载记忆增强型语言模型，旨在攻克四大交互式视觉-语言领域的挑战。",
    "tags": [
      "Agent",
      "人工智能",
      "任务规划"
    ]
  },
  {
    "title": "SuperCLUE-Fin: Graded Fine-Grained Analysis of Chinese LLMs on Diverse Financial Tasks and Applications",
    "submit_datetime": "2024年04月29日",
    "abstract": "The SuperCLUE-Fin (SC-Fin) benchmark is a pioneering evaluation framework tailored for Chinese-native financial large language models (FLMs). It assesses FLMs across six financial application domains and twenty-five specialized tasks, encompassing theoretical knowledge and practical applications such as compliance, risk management, and investment analysis. Using multi-turn, open-ended conversations that mimic real-life scenarios, SC-Fin measures models on a range of criteria, including accurate financial understanding, logical reasoning, clarity, computational efficiency, business acumen, risk perception, and compliance with Chinese regulations.\n  In a rigorous evaluation involving over a thousand questions, SC-Fin identifies a performance hierarchy where domestic models like GLM-4 and MoonShot-v1-128k outperform others with an A-grade, highlighting the potential for further development in transforming theoretical knowledge into pragmatic financial solutions. This benchmark serves as a critical tool for refining FLMs in the Chinese context, directing improvements in financial knowledge databases, standardizing financial interpretations, and promoting models that prioritize compliance, risk management, and secure practices.\n  We create a contextually relevant and comprehensive benchmark that drives the development of AI in the Chinese financial sector. SC-Fin facilitates the advancement and responsible deployment of FLMs, offering valuable insights for enhancing model performance and usability for both individual and institutional users in the Chinese market..~\\footnote{Our benchmark can be found at \\url{https://www.CLUEbenchmarks.com}}.",
    "pdf_link": "https://arxiv.org/abs/2404.19063",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.19063v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19063/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19063v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19063/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19063v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19063/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19063v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19063/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19063v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19063/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19063v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19063/x6.png"
      }
    ],
    "abstract_cn": "SuperCLUE-Fin（SC-Fin）基准框架，专为中文金融领域的大型语言模型（FLMs）量身打造，涵盖了六大金融应用领域和二十五项专业任务，包括合规、风险管理和投资分析等理论与实践相结合的应用。该框架通过模拟真实情境的多轮开放式对话，对模型进行多维度评估，包括金融知识理解、逻辑推理、表达清晰度、计算效率、商业洞察力、风险意识及遵守中国法规等。在一项包含逾千题的严格评估中，SC-Fin揭示了性能排名，国内模型如GLM-4和MoonShot-v1-128k以A级成绩领先，显示了将理论知识转化为实际金融解决方案的巨大潜力。此基准工具对于在中国金融背景下优化FLMs、提升金融知识库、统一金融解释标准以及推动模型在合规、风险管理和安全实践方面的优先发展至关重要。我们构建了这一全面且具针对性的基准，旨在推动中国金融领域人工智能的发展。SC-Fin不仅促进了FLMs的进步和负责任的应用，还为提升模型在中国市场的个人和机构用户的性能和可用性提供了深刻见解。~\\footnote{更多关于我们的基准信息，请访问 \\url{https://www.CLUEbenchmarks.com}}。",
    "title_cn": "SuperCLUE-Fin：深入剖析中国大型语言模型在多元金融任务及应用中的细致分级表现。",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Plan of Thoughts: Heuristic-Guided Problem Solving with Large Language Models",
    "submit_datetime": "2024年04月29日",
    "abstract": "While language models (LMs) offer significant capability in zero-shot reasoning tasks across a wide range of domains, they do not perform satisfactorily in problems which requires multi-step reasoning. Previous approaches to mitigate this involves breaking a larger, multi-step task into sub-tasks and asking the language model to generate proposals (\"thoughts\") for each sub-task and using exhaustive planning approaches such as DFS to compose a solution. In this work, we leverage this idea to introduce two new contributions: first, we formalize a planning-based approach to perform multi-step problem solving with LMs via Partially Observable Markov Decision Processes (POMDPs), with the LM's own reflections about the value of a state used as a search heuristic; second, leveraging the online POMDP solver POMCP, we demonstrate a superior success rate of 89.4% on the Game of 24 task as compared to existing approaches while also offering better anytime performance characteristics than fixed tree-search which is used previously. Taken together, these contributions allow modern LMs to decompose and solve larger-scale reasoning tasks more effectively.",
    "pdf_link": "https://arxiv.org/abs/2404.19055",
    "graphs": [],
    "abstract_cn": "语言模型在众多领域的零样本推理任务中展现出强大的能力，但面对需要连续推理的问题时，它们的表现尚有不足。传统解决方案是将复杂任务拆解为多个子任务，让语言模型为每个子任务提出方案，并采用深度优先搜索等策略来整合答案。本研究在此基础上提出了两项创新：一是将基于规划的方法应用于LMs的多步问题解决，通过部分可观测马尔可夫决策过程（POMDPs），并以LM对状态价值的自我评估作为搜索策略；二是借助在线POMDP求解器POMCP，在24点游戏中实现了89.4%的高解决率，超越了现有技术，并在随时性能上优于以往的固定树搜索方法。这些贡献使得现代语言模型能够更高效地分解和处理更复杂的推理任务。",
    "title_cn": "思维蓝图：借助大型语言模型实现启发式问题解决策略",
    "tags": [
      "分类：LLM应用\n\n这篇论文讨论了语言模型在零样本推理任务中的应用，特别是针对需要连续推理的问题。作者提出了一种基于规划的方法，通过部分可观测马尔可夫决策过程（POMDPs）和在线POMDP求解器POMCP来提高语言模型在复杂推理任务中的表现。这篇论文的研究重点在于提高语言模型在特定任务上的应用效果，因此可以归类为LLM应用。",
      "人工智能",
      ""
    ]
  },
  {
    "title": "A Framework for Real-time Safeguarding the Text Generation of Large Language",
    "submit_datetime": "2024年04月29日",
    "abstract": "Large Language Models (LLMs) have significantly advanced natural language processing (NLP) tasks but also pose ethical and societal risks due to their propensity to generate harmful content. To address this, various approaches have been developed to safeguard LLMs from producing unsafe content. However, existing methods have limitations, including the need for training specific control models and proactive intervention during text generation, that lead to quality degradation and increased computational overhead. To mitigate those limitations, we propose LLMSafeGuard, a lightweight framework to safeguard LLM text generation in real-time. LLMSafeGuard integrates an external validator into the beam search algorithm during decoding, rejecting candidates that violate safety constraints while allowing valid ones to proceed. We introduce a similarity based validation approach, simplifying constraint introduction and eliminating the need for control model training. Additionally, LLMSafeGuard employs a context-wise timing selection strategy, intervening LLMs only when necessary. We evaluate LLMSafe-Guard on two tasks, detoxification and copyright safeguarding, and demonstrate its superior performance over SOTA baselines. For instance, LLMSafeGuard reduces the average toxic score of. LLM output by 29.7% compared to the best baseline meanwhile preserving similar linguistic quality as natural output in detoxification task. Similarly, in the copyright task, LLMSafeGuard decreases the Longest Common Subsequence (LCS) by 56.2% compared to baselines. Moreover, our context-wise timing selection strategy reduces inference time by at least 24% meanwhile maintaining comparable effectiveness as validating each time step. LLMSafeGuard also offers tunable parameters to balance its effectiveness and efficiency.",
    "pdf_link": "https://arxiv.org/abs/2404.19048",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.19048v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19048/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19048v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19048/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19048v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19048/x3.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）在自然语言处理（NLP）领域取得了显著进步，但同时也因其可能产生有害内容而引发伦理和社会责任问题。为应对这一挑战，已开发出多种方法来防止LLMs生成危险内容。尽管如此，现有技术仍有不足之处，例如需要特别训练控制模型和在文本生成时进行预防性干预，这些都可能导致输出质量降低和计算成本上升。针对这些限制，我们设计了LLMSafeGuard——一个轻量级的实时文本生成保护框架。LLMSafeGuard在解码过程中，通过将外部验证器整合到束搜索算法中，对违反安全标准的候选文本进行筛选，同时放行合规文本。我们提出了一种基于相似度的验证方法，简化了安全约束的设置，并且避免了控制模型的训练需求。此外，LLMSafeGuard还采用了一种上下文感知的时机选择策略，仅在必要时对LLMs进行干预。我们在文本净化和版权保护两个任务上对LLMSafeGuard进行了评估，结果表明其性能超越了现有的最先进基线。例如，在文本净化任务中，LLMSafeGuard将LLM输出的平均有害性评分降低了29.7%，与自然输出的语言质量不相上下。在版权保护任务中，LLMSafeGuard将最长公共子序列（LCS）的比率降低了56.2%。同时，我们的上下文感知时机选择策略至少减少了24%的推理时间，而有效性却不打折扣。LLMSafeGuard还提供了可调节参数，以便在有效性和效率之间取得平衡。",
    "title_cn": "构建了一个实时保障大型语言模型文本生成安全的框架。",
    "tags": [
      "LLM应用",
      "",
      "伦理合规"
    ]
  },
  {
    "title": "Multi-Page Document Visual Question Answering using Self-Attention Scoring Mechanism",
    "submit_datetime": "2024年04月29日",
    "abstract": "Documents are 2-dimensional carriers of written communication, and as such their interpretation requires a multi-modal approach where textual and visual information are efficiently combined. Document Visual Question Answering (Document VQA), due to this multi-modal nature, has garnered significant interest from both the document understanding and natural language processing communities. The state-of-the-art single-page Document VQA methods show impressive performance, yet in multi-page scenarios, these methods struggle. They have to concatenate all pages into one large page for processing, demanding substantial GPU resources, even for evaluation. In this work, we propose a novel method and efficient training strategy for multi-page Document VQA tasks. In particular, we employ a visual-only document representation, leveraging the encoder from a document understanding model, Pix2Struct. Our approach utilizes a self-attention scoring mechanism to generate relevance scores for each document page, enabling the retrieval of pertinent pages. This adaptation allows us to extend single-page Document VQA models to multi-page scenarios without constraints on the number of pages during evaluation, all with minimal demand for GPU resources. Our extensive experiments demonstrate not only achieving state-of-the-art performance without the need for Optical Character Recognition (OCR), but also sustained performance in scenarios extending to documents of nearly 800 pages compared to a maximum of 20 pages in the MP-DocVQA dataset. Our code is publicly available at \\url{https://github.com/leitro/SelfAttnScoring-MPDocVQA}.",
    "pdf_link": "https://arxiv.org/abs/2404.19024",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.19024v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19024/text2pixel_h.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19024v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19024/arch.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19024v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19024/scoring_h.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19024v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19024/histo_pages_h.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19024v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19024/heatmap_page.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19024v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19024/heatmap_anls.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19024v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19024/case10_a.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19024v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19024/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19024v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19024/case00_a.png"
      }
    ],
    "abstract_cn": "文档作为承载书面交流的二维平台，解读它们需融合文本与视觉信息，采取多模态策略。正因如此，文档视觉问答（Document VQA）在文档理解与自然语言处理领域备受关注。尽管现有的单页文档 VQA 技术表现出色，但在处理多页文档时却力有未逮，常需将多页合并为一，以适应处理需求，这对 GPU 资源的消耗甚大。本研究提出了一种创新的多页文档 VQA 方法和高效的训练策略。我们引入了一种视觉主导的文档表达方式，借助文档理解模型 Pix2Struct 中的编码器，并通过自注意力机制为文档各页打分，筛选出关键页面。这种方法让我们得以在评估时不受页面数量限制地将单页模型扩展至多页场景，同时大幅降低了对 GPU 资源的依赖。实验结果表明，我们的方法不仅在无需光学字符识别（OCR）的情况下达到了业界领先水平，而且在处理接近 800 页的文档时仍能保持性能，远超 MP-DocVQA 数据集中最多 20 页的极限。相关代码已在 \\url{https://github.com/leitro/SelfAttnScoring-MPDocVQA} 上开源。",
    "title_cn": "利用自注意力评分机制进行多页文档的视觉问答解答",
    "tags": [
      "分类：Agent",
      "文档理解",
      ""
    ]
  },
  {
    "title": "Towards Generalizable Agents in Text-Based Educational Environments: A Study of Integrating RL with LLMs",
    "submit_datetime": "2024年04月29日",
    "abstract": "There has been a growing interest in developing learner models to enhance learning and teaching experiences in educational environments. However, existing works have primarily focused on structured environments relying on meticulously crafted representations of tasks, thereby limiting the agent's ability to generalize skills across tasks. In this paper, we aim to enhance the generalization capabilities of agents in open-ended text-based learning environments by integrating Reinforcement Learning (RL) with Large Language Models (LLMs). We investigate three types of agents: (i) RL-based agents that utilize natural language for state and action representations to find the best interaction strategy, (ii) LLM-based agents that leverage the model's general knowledge and reasoning through prompting, and (iii) hybrid LLM-assisted RL agents that combine these two strategies to improve agents' performance and generalization. To support the development and evaluation of these agents, we introduce PharmaSimText, a novel benchmark derived from the PharmaSim virtual pharmacy environment designed for practicing diagnostic conversations. Our results show that RL-based agents excel in task completion but lack in asking quality diagnostic questions. In contrast, LLM-based agents perform better in asking diagnostic questions but fall short of completing the task. Finally, hybrid LLM-assisted RL agents enable us to overcome these limitations, highlighting the potential of combining RL and LLMs to develop high-performing agents for open-ended learning environments.",
    "pdf_link": "https://arxiv.org/abs/2404.18978",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.18978v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18978/pharmasim.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18978v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18978/pharmasim_process.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18978v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18978/llm-rl.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18978v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18978/wording_example.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18978v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18978/wording_result.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18978v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18978/reflective.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18978v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18978/patient_vs_agent.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18978v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18978/conversation.png"
      }
    ],
    "abstract_cn": "教育领域内，人们越来越关注开发学习者模型以提升学习和教学体验。但目前的研究多集中于结构化环境，依赖于精心设计的任务表示，这限制了智能体跨任务泛化技能的能力。本文旨在通过融合强化学习（RL）与大型语言模型（LLMs），提升智能体在开放性文本学习环境中的泛化能力。我们探讨了三种智能体：（i）利用自然语言进行状态和动作表示的RL型智能体，寻找最佳互动策略；（ii）通过提示运用模型的通用知识和推理的LLM型智能体；（iii）结合这两种策略以提升性能和泛化能力的混合LLM辅助RL型智能体。为促进这些智能体的发展和评估，我们提出了PharmaSimText，这是一个新的基准测试，源自用于练习诊断对话的PharmaSim虚拟药房环境。研究结果显示，RL型智能体在任务完成方面表现优异，但在提出高质量诊断问题上有所欠缺。而LLM型智能体在提出诊断问题上表现更佳，但完成任务的能力不足。最终，混合LLM辅助RL型智能体使我们能够突破这些局限，展现了结合RL与LLMs以开发开放式学习环境高性能智能体的巨大潜力。",
    "title_cn": "探索文本教育环境中的通用化智能体：研究强化学习与大型语言模型融合的实践",
    "tags": [
      "Agent",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Foundations of Multisensory Artificial Intelligence",
    "submit_datetime": "2024年04月29日",
    "abstract": "Building multisensory AI systems that learn from multiple sensory inputs such as text, speech, video, real-world sensors, wearable devices, and medical data holds great promise for impact in many scientific areas with practical benefits, such as in supporting human health and well-being, enabling multimedia content processing, and enhancing real-world autonomous agents. By synthesizing a range of theoretical frameworks and application domains, this thesis aims to advance the machine learning foundations of multisensory AI. In the first part, we present a theoretical framework formalizing how modalities interact with each other to give rise to new information for a task. These interactions are the basic building blocks in all multimodal problems, and their quantification enables users to understand their multimodal datasets, design principled approaches to learn these interactions, and analyze whether their model has succeeded in learning. In the second part, we study the design of practical multimodal foundation models that generalize over many modalities and tasks, which presents a step toward grounding large language models to real-world sensory modalities. We introduce MultiBench, a unified large-scale benchmark across a wide range of modalities, tasks, and research areas, followed by the cross-modal attention and multimodal transformer architectures that now underpin many of today's multimodal foundation models. Scaling these architectures on MultiBench enables the creation of general-purpose multisensory AI systems, and we discuss our collaborative efforts in applying these models for real-world impact in affective computing, mental health, cancer prognosis, and robotics. Finally, we conclude this thesis by discussing how future work can leverage these ideas toward more general, interactive, and safe multisensory AI.",
    "pdf_link": "https://arxiv.org/abs/2404.18976",
    "graphs": [],
    "abstract_cn": "本研究致力于开发能够整合文本、语音、视频、传感器数据等多种感官信息的多感官人工智能系统，这些系统在促进人类健康、处理多媒体内容以及提升自主智能体性能等多个科学领域具有重要应用价值。本文首先构建了一个理论框架，阐释了不同感官模态如何相互交互以生成新信息，这些交互是解决多模态问题的关键，有助于深入理解数据集、设计学习交互的方法，并评估模型学习效果。接着，研究了一种实用的多模态基础模型，它能够跨越多种感官和任务，为大型语言模型与现实世界感官模态的结合提供了新途径。我们提出了MultiBench，一个覆盖广泛模态、任务和研究领域的大规模统一基准，以及支撑当前许多多模态基础模型的跨模态注意力和多模态变换器架构。通过在MultiBench上扩展这些架构，我们能够构建出通用的多感官AI系统，并探讨了如何将这些模型应用于情感计算、心理健康、癌症预后和机器人技术等领域，以实现现实世界的影响。最后，论文以讨论如何利用这些研究成果推动多感官AI向更通用、互动和安全方向发展作为结尾。",
    "title_cn": "多感官人工智能之基石",
    "tags": [
      "分类：Agent",
      "人工智能",
      "多模态交互"
    ]
  },
  {
    "title": "The Convergence of AI and Synthetic Biology: The Looming Deluge",
    "submit_datetime": "2024年04月29日",
    "abstract": "The convergence of artificial intelligence (AI) and synthetic biology is rapidly accelerating the pace of biological discovery and engineering. AI techniques, such as large language models and biological design tools, are enabling the automated design, build, test, and learning cycles for engineered biological systems. This convergence promises to democratize synthetic biology and unlock novel applications across domains from medicine to environmental sustainability. However, it also poses significant risks around reliability, dual use, and governance. The opacity of AI models, the deskilling of workforces, and the outdated nature of current regulatory frameworks present challenges in ensuring responsible development. Urgent attention is needed to update governance structures, integrate human oversight into increasingly automated workflows, and foster a culture of responsibility among the growing community of bioengineers. Only by proactively addressing these issues can we realize the transformative potential of AI-driven synthetic biology while mitigating its risks.",
    "pdf_link": "https://arxiv.org/abs/2404.18973",
    "graphs": [],
    "abstract_cn": "AI与合成生物学的结合正推动生物探索和工程领域飞速发展。借助大型语言模型和生物设计工具等AI技术，我们能够自动化地设计、构建、测试并学习工程生物系统。这一趋势预示着合成生物学的普及化，并将在医疗、环保等多个领域带来创新应用。但同时，它也引发了一系列关于可靠性、双重用途和治理的重大风险。AI模型的不透明性、劳动力技能降低以及现行监管框架的不适应性，都对负责任的技术开发构成了挑战。迫切需要对治理结构进行更新，将人工监督融入日益自动化的工作流程，并在生物工程领域培养起责任感。唯有积极应对这些挑战，我们才能在降低风险的同时，充分挖掘AI驱动合成生物学的变革性潜力。",
    "title_cn": "人工智能与合成生物学的结合：迫在眉睫的洪流。",
    "tags": [
      "分类：Agent\n\n这篇论文讨论了AI技术，特别是大型语言模型在合成生物学领域的应用，以及这些技术带来的挑战和风险。它涉及到AI代理（Agent）在自动化设计、构建、测试和学习工程生物系统方面的作用，以及对这些代理进行治理和监管的必要性。因此，这篇论文最符合Agent分类。",
      "合成生物学",
      "人工智能"
    ]
  },
  {
    "title": "GRAMMAR: Grounded and Modular Evaluation of Domain-Specific Retrieval-Augmented Language Models",
    "submit_datetime": "2024年04月29日",
    "abstract": "Retrieval-augmented Generation (RAG) systems have been actively studied and deployed across various industries to query on domain-specific knowledge base. However, evaluating these systems presents unique challenges due to the scarcity of domain-specific queries and corresponding ground truths, as well as a lack of systematic approaches to diagnosing the cause of failure cases -- whether they stem from knowledge deficits or issues related to system robustness. To address these challenges, we introduce GRAMMAR (GRounded And Modular Methodology for Assessment of RAG), an evaluation framework comprising two key elements: 1) a data generation process that leverages relational databases and LLMs to efficiently produce scalable query-answer pairs. This method facilitates the separation of query logic from linguistic variations for enhanced debugging capabilities; and 2) an evaluation framework that differentiates knowledge gaps from robustness and enables the identification of defective modules. Our empirical results underscore the limitations of current reference-free evaluation approaches and the reliability of GRAMMAR to accurately identify model vulnerabilities.",
    "pdf_link": "https://arxiv.org/abs/2404.19232",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.19232v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19232/group_types.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19232v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19232/data_gen_2.0.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19232v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19232/db_schema.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19232v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19232/db_schema_aurp_no_location.png"
      }
    ],
    "abstract_cn": "检索增强生成（RAG）系统在各行业被广泛研究和应用，主要针对特定领域的知识库查询。但评估这些系统时，由于缺乏特定领域的查询和真实答案，以及缺少系统化诊断失败原因的方法，面临不少挑战。为此，我们提出了GRAMMAR（一种评估RAG的有根据且模块化的方法），它包含两个核心部分：首先是一个数据生成流程，它结合关系数据库和大型语言模型（LLMs）来高效产出可扩展的查询-答案对，这种方法有助于将查询逻辑与语言变化分离，从而提升调试效率；其次是一个评估框架，它能够区分知识缺陷和系统鲁棒性问题，并识别出有问题的模块。我们的实证研究结果揭示了现有无参照评估方法的不足，并证明了GRAMMAR在准确识别模型弱点方面的可靠性。",
    "title_cn": "《语法：领域特定检索增强语言模型的实证与模块化评估》",
    "tags": [
      "RAG",
      "数据库管理",
      "人工智能"
    ]
  },
  {
    "title": "Mixture-of-Instructions: Comprehensive Alignment of a Large Language Model through the Mixture of Diverse System Prompting Instructions",
    "submit_datetime": "2024年04月28日",
    "abstract": "With the proliferation of large language models (LLMs), the comprehensive alignment of such models across multiple tasks has emerged as a critical area of research. Existing alignment methodologies primarily address single task, such as multi-turn dialogue, coding, mathematical problem-solving, and tool usage. However, AI-driven products that leverage language models usually necessitate a fusion of these abilities to function effectively in real-world scenarios. Moreover, the considerable computational resources required for proper alignment of LLMs underscore the need for a more robust, efficient, and encompassing approach to multi-task alignment, ensuring improved generative performance. In response to these challenges, we introduce a novel technique termed Mixture-of-Instructions (MoI), which employs a strategy of instruction concatenation combined with diverse system prompts to boost the alignment efficiency of language models. We have also compiled a diverse set of seven benchmark datasets to rigorously evaluate the alignment efficacy of the MoI-enhanced language model. Our methodology was applied to the open-source Qwen-7B-chat model, culminating in the development of Qwen-SFT-MoI. This enhanced model demonstrates significant advancements in generative capabilities across coding, mathematics, and tool use tasks.",
    "pdf_link": "https://arxiv.org/abs/2404.18410",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）的广泛使用催生了对这些模型在多样化任务中进行综合对齐的研究需求。目前，主流的对齐技术多聚焦于单一任务，比如多轮对话、编程、数学问题求解和工具应用等。但在现实世界的应用场景中，AI产品往往需要整合这些不同的能力来实现高效运作。此外，为了实现LLMs的精准对齐，所需的庞大计算资源也凸显了开发一种更为强大、高效且全面的多任务对齐方法的必要性，以提升模型的生成性能。面对这些挑战，我们提出了一种创新技术——指令混合（MoI），它通过指令串联和多样化的系统提示来增强语言模型的对齐效率。我们还特别设计了包含七个不同基准数据集的集合，用以严格测试MoI增强模型的对齐效果。该技术被应用于开源的Qwen-7B-chat模型，进而发展出了Qwen-SFT-MoI模型。这一增强版模型在编程、数学和工具使用等多个任务上展现了显著的生成能力提升。",
    "title_cn": "通过多样化的系统提示指令混合，实现对大型语言模型的全面校准。",
    "tags": [
      "LLM应用",
      "人工智能",
      "多任务学习"
    ]
  },
  {
    "title": "LLM-SR: Scientific Equation Discovery via Programming with Large Language Models",
    "submit_datetime": "2024年04月28日",
    "abstract": "Mathematical equations have been unreasonably effective in describing complex natural phenomena across various scientific disciplines. However, discovering such insightful equations from data presents significant challenges due to the necessity of navigating extremely high-dimensional combinatorial and nonlinear hypothesis spaces. Traditional methods of equation discovery largely focus on extracting equations from data alone, often neglecting the rich domain-specific prior knowledge that scientists typically depend on. To bridge this gap, we introduce LLM-SR, a novel approach that leverages the extensive scientific knowledge and robust code generation capabilities of Large Language Models (LLMs) to discover scientific equations from data in an efficient manner. Specifically, LLM-SR treats equations as programs with mathematical operators and combines LLMs' scientific priors with evolutionary search over equation programs. The LLM iteratively proposes new equation skeletons, drawing from its physical understanding, which are then optimized against data to estimate skeleton parameters. We demonstrate LLM-SR's effectiveness across three diverse scientific domains, where it discovers physically accurate equations that provide significantly better fits to in-domain and out-of-domain data compared to the well-established equation discovery baselines",
    "pdf_link": "https://arxiv.org/abs/2404.18400",
    "graphs": [],
    "abstract_cn": "数学方程在刻画自然现象的复杂性方面显示出惊人的效力，这跨越了众多科学领域。但要从数据中发掘出这些富有洞察力的方程，却因必须探索高维的组合与非线性假设空间而充满挑战。传统上，方程发现主要依赖于数据本身，往往忽略了科学家们所依赖的深厚领域知识。为了填补这一空白，我们提出了 LLM-SR，这是一种创新的方法，它借助大型语言模型（LLMs）的丰富科学知识库和强大的编程生成能力，高效地从数据中发掘科学方程。具体而言，LLM-SR 将方程视为程序，运用数学运算符，结合 LLMs 的科学知识先验与方程程序的进化搜索。LLM 会迭代提出新的方程框架，利用其对物理世界的理解，然后根据数据进行优化以确定框架参数。我们在三个不同的科学领域验证了 LLM-SR 的效力，它所发掘的物理上准确的方程在适应领域内外数据方面，相比传统方程发现方法，提供了更为精准的拟合结果。",
    "title_cn": "LLM-SR：借助大型语言模型编程，探索科学方程式的奥秘",
    "tags": [
      "LLM应用",
      "科学计算",
      "数据挖掘"
    ]
  },
  {
    "title": "6G comprehensive intelligence: network operations and optimization based on Large Language Models",
    "submit_datetime": "2024年04月28日",
    "abstract": "The sixth generation mobile communication standard (6G) can promote the development of Industrial Internet and Internet of Things (IoT). To achieve comprehensive intelligent development of the network and provide customers with higher quality personalized services. This paper proposes a network performance optimization and intelligent operation network architecture based on Large Language Model (LLM), aiming to build a comprehensive intelligent 6G network system. The Large Language Model, with more parameters and stronger learning ability, can more accurately capture patterns and features in data, which can achieve more accurate content output and high intelligence and provide strong support for related research such as network data security, privacy protection, and health assessment. This paper also presents the design framework of a network health assessment system based on LLM and focuses on its potential application value, through the case of network health management system, it is fully demonstrated that the 6G intelligent network system based on LLM has important practical significance for the comprehensive realization of intelligence.",
    "pdf_link": "https://arxiv.org/abs/2404.18373",
    "graphs": [],
    "abstract_cn": "第六代移动通信技术（6G）将推动工业互联网和物联网（IoT）的蓬勃发展，旨在实现网络的全面智能化，为用户带来更优质的定制服务。本研究提出了一种依托于大型语言模型（LLM）的网络性能优化与智能运维架构，致力于构建一个全方位的智能6G网络体系。LLM凭借其庞大的参数量和卓越的学习能力，能够精准捕捉数据模式与特征，实现精准的内容输出，展现出高效的智能性能，为网络数据安全、隐私保护和健康评估等研究领域提供坚实支撑。文章还展示了基于LLM的网络健康评估系统设计框架，并着重探讨了其应用潜力，通过网络健康管理系统的实例，充分证明了LLM驱动的6G智能网络系统在推动智能化全面实现方面具有显著的实用价值。",
    "title_cn": "6G 综合智能时代，网络的运营与优化将依托于大型语言模型的先进能力。",
    "tags": [
      "LLM应用",
      "通信技术",
      "工业互联网"
    ]
  },
  {
    "title": "QANA: LLM-based Question Generation and Network Analysis for Zero-shot Key Point Analysis and Beyond",
    "submit_datetime": "2024年04月28日",
    "abstract": "The proliferation of social media has led to information overload and increased interest in opinion mining. We propose \"Question-Answering Network Analysis\" (QANA), a novel opinion mining framework that utilizes Large Language Models (LLMs) to generate questions from users' comments, constructs a bipartite graph based on the comments' answerability to the questions, and applies centrality measures to examine the importance of opinions. We investigate the impact of question generation styles, LLM selections, and the choice of embedding model on the quality of the constructed QA networks by comparing them with annotated Key Point Analysis datasets. QANA achieves comparable performance to previous state-of-the-art supervised models in a zero-shot manner for Key Point Matching task, also reducing the computational cost from quadratic to linear. For Key Point Generation, questions with high PageRank or degree centrality align well with manually annotated key points. Notably, QANA enables analysts to assess the importance of key points from various aspects according to their selection of centrality measure. QANA's primary contribution lies in its flexibility to extract key points from a wide range of perspectives, which enhances the quality and impartiality of opinion mining.",
    "pdf_link": "https://arxiv.org/abs/2404.18371",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.18371v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18371/overview.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18371v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18371/example.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18371v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18371/result1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18371v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18371/result2.png"
      }
    ],
    "abstract_cn": "社交媒体的广泛传播引起信息泛滥，同时也激发了对意见挖掘的浓厚兴趣。我们引入了一种创新的意见挖掘框架——“问答网络分析”（QANA），它使用大型语言模型（LLMs）来从用户评论生成问题，构建基于评论对这些问题可回答性的二分图，并采用中心性度量来评估意见的重要程度。通过与标注的关键点分析数据集进行比较，我们探究了问题生成方式、LLM选择以及嵌入模型选择对所构建QA网络质量的影响。QANA在零样本学习环境中，其关键点匹配任务的性能与现有的最先进监督模型相当，同时将计算成本从二次降低到线性。在关键点生成方面，高PageRank或度中心性的问题与人工标注的关键点高度一致。QANA的显著优势在于其能够从多角度评估关键点的重要性，这不仅提升了意见挖掘的质量，也增强了其公正性。",
    "title_cn": "QANA：利用大型语言模型（LLM）进行问题生成与网络分析，旨在实现零样本关键点分析及其扩展应用。",
    "tags": [
      "LLM应用",
      "社交媒体分析",
      "意见挖掘"
    ]
  },
  {
    "title": "FoundaBench: Evaluating Chinese Fundamental Knowledge Capabilities of Large Language Models",
    "submit_datetime": "2024年04月28日",
    "abstract": "In the burgeoning field of large language models (LLMs), the assessment of fundamental knowledge remains a critical challenge, particularly for models tailored to Chinese language and culture. This paper introduces FoundaBench, a pioneering benchmark designed to rigorously evaluate the fundamental knowledge capabilities of Chinese LLMs. FoundaBench encompasses a diverse array of 3354 multiple-choice questions across common sense and K-12 educational subjects, meticulously curated to reflect the breadth and depth of everyday and academic knowledge. We present an extensive evaluation of 12 state-of-the-art LLMs using FoundaBench, employing both traditional assessment methods and our CircularEval protocol to mitigate potential biases in model responses. Our results highlight the superior performance of models pre-trained on Chinese corpora, and reveal a significant disparity between models' reasoning and memory recall capabilities. The insights gleaned from FoundaBench evaluations set a new standard for understanding the fundamental knowledge of LLMs, providing a robust framework for future advancements in the field.",
    "pdf_link": "https://arxiv.org/abs/2404.18359",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.18359v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18359/figure1_FoundaBench_Overview.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18359v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18359/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18359v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18359/barchart1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18359v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18359/example1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18359v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18359/example3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18359v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18359/example2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18359v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18359/example4.png"
      }
    ],
    "abstract_cn": "在蓬勃发展的大型语言模型（LLMs）领域，准确评估模型的基础知识水平尤为关键，尤其是那些专为中文语言和文化量身定制的模型。本文提出了FoundaBench，这是一个创新的基准测试工具，用以严格检验中文LLMs的基础知识掌握程度。FoundaBench精心设计了3354道多项选择题，覆盖常识和K-12教育主题，全面反映了日常生活和学术领域的知识。我们对12个顶尖的LLMs进行了深入评估，不仅采用了传统评估方法，还引入了CircularEval协议，以减少模型回答中的潜在偏差。评估结果显示，基于中文语料库预训练的模型性能更为出色，并指出了模型在推理和记忆回忆能力上存在显著差异。FoundaBench的评估结果不仅为理解LLMs的基础知识提供了新的视角，也为未来该领域的研究进步奠定了坚实的基础。",
    "title_cn": "FoundaBench：探究大型语言模型在中文基础知识掌握上的评估",
    "tags": [
      "LLM理论",
      "",
      ""
    ]
  },
  {
    "title": "Do Neutral Prompts Produce Insecure Code? FormAI-v2 Dataset: Labelling Vulnerabilities in Code Generated by Large Language Models",
    "submit_datetime": "2024年04月28日",
    "abstract": "This study provides a comparative analysis of state-of-the-art large language models (LLMs), analyzing how likely they generate vulnerabilities when writing simple C programs using a neutral zero-shot prompt. We address a significant gap in the literature concerning the security properties of code produced by these models without specific directives. N. Tihanyi et al. introduced the FormAI dataset at PROMISE '23, containing 112,000 GPT-3.5-generated C programs, with over 51.24% identified as vulnerable. We expand that work by introducing the FormAI-v2 dataset comprising 265,000 compilable C programs generated using various LLMs, including robust models such as Google's GEMINI-pro, OpenAI's GPT-4, and TII's 180 billion-parameter Falcon, to Meta's specialized 13 billion-parameter CodeLLama2 and various other compact models. Each program in the dataset is labelled based on the vulnerabilities detected in its source code through formal verification using the Efficient SMT-based Context-Bounded Model Checker (ESBMC). This technique eliminates false positives by delivering a counterexample and ensures the exclusion of false negatives by completing the verification process. Our study reveals that at least 63.47% of the generated programs are vulnerable. The differences between the models are minor, as they all display similar coding errors with slight variations. Our research highlights that while LLMs offer promising capabilities for code generation, deploying their output in a production environment requires risk assessment and validation.",
    "pdf_link": "https://arxiv.org/abs/2404.18353",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.18353v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18353/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18353v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18353/moti.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18353v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18353/secure1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18353v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18353/sec2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18353v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18353/methodology.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18353v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18353/prompt.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18353v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18353/esbmc.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18353v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18353/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18353v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18353/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18353v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18353/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18353v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18353/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18353v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18353/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18353v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18353/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18353v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18353/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18353v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18353/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18353v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18353/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18353v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18353/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18353v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18353/Untitled.jpg"
      }
    ],
    "abstract_cn": "本研究对比分析了当前顶尖的大型语言模型（LLMs），探究了这些模型在采用中性零样本提示编写简易C程序时生成安全漏洞的倾向。此举填补了现有文献中关于这些模型在缺乏具体指令时所产生代码安全性特性的空白。在PROMISE '23会议上，N. Tihanyi等人提出了包含112,000个GPT-3.5生成的C程序的FormAI数据集，其中逾51.24%被认定为存在安全漏洞。我们在此基础上进一步工作，推出了包含265,000个可编译C程序的FormAI-v2数据集，这些程序由多种LLMs生成，包括谷歌的GEMINI-pro、OpenAI的GPT-4、TII的180亿参数Falcon，以及Meta的13亿参数专业模型CodeLLama2和其他多种紧凑型模型。数据集中每个程序的标签基于通过高效SMT（Satisfiability Modulo Theories）上下文有界模型检查器（ESBMC）的形式验证在其源代码中发现的漏洞。该技术通过提供反例来排除误报，并确保通过完成验证过程来避免漏报。研究发现至少63.47%的程序存在安全漏洞，不同模型之间的差异不大，它们都展现出类似的编码错误，只是有所变化。本研究强调，尽管LLMs在代码生成方面展现出巨大潜力，但在生产环境中应用其生成的代码前，必须进行风险评估和验证。",
    "title_cn": "中性的提示是否会导致代码安全性受损？FormAI-v2 数据集专注于识别并标记由大型语言模型生成的代码中的潜在安全漏洞。",
    "tags": [
      "LLM应用",
      "编程语言",
      "软件工程"
    ]
  },
  {
    "title": "BlockLLM: Multi-tenant Finer-grained Serving for Large Language Models",
    "submit_datetime": "2024年04月28日",
    "abstract": "The growing demand for Large Language Models (LLMs) across diverse applications has prompted a paradigm shift in the design of deep learning serving systems. Deploying LLMs, especially in multi-tenant environments, presents considerable challenges due to their high computational and memory demands. We present BlockLLM, a serving system that exploits the potential of sharing components among fine-tuned LLM models to offer an efficient and flexible solution for LLM workloads. BlockLLM partitions the models into finer-grained blocks to enable the reuse of model components and independent provisioning to improve the computation efficiency. BlockLLM consists of an offline block zoo, for storing the blocks, and an online system to serve the requests through chains of blocks. It offers multi-fold flexibility: (1) Adaptive assembly of block chains on-the-fly is achieved with the help of equivalence evaluation among blocks in the zoo. (2) We enable per-block batch size and configure best-effort KV cache coordination at individual block level. (3) We adopt speculative execution and locality-aware block placement to mitigate the communication costs from dynamic block resource allocation. Our evaluation demonstrates that BlockLLM reduces memory and storage footprints and improves computation efficiency, outperforming existing serving approach in 95\\%ile latency and GPU utilization by 33.5\\% and 20.1\\%, respectively.",
    "pdf_link": "https://arxiv.org/abs/2404.18322",
    "graphs": [],
    "abstract_cn": "随着大型语言模型（LLM）在多种应用中的广泛需求，深度学习服务系统的设计思路经历了一次重大变革。尤其在多租户环境下部署LLM面临着计算和内存需求高的挑战。为此，我们推出了BlockLLM，这是一款服务系统，它通过在微调后的LLM模型间共享组件，为LLM工作负载提供了一种既高效又灵活的处理方案。BlockLLM通过将模型划分为更细致的区块，实现了模型组件的复用和独立配置，优化了计算效率。系统包含一个用于存储区块的离线区块库和一个通过区块链处理请求的在线服务系统。BlockLLM展现了多重灵活性：(1) 利用区块库中的等价评估，实现了区块链的即时自适应组装；(2) 支持每个区块的批处理大小，并在各个区块级别上实施了最优的KV缓存协调；(3) 采用预测执行和本地感知的区块放置策略，以减少动态区块资源分配带来的通信开销。我们的评估结果证明，BlockLLM在减少内存和存储占用、提升计算效率方面表现卓越，与现有服务方法相比，在95%的延迟和GPU利用率上分别提升了33.5%和20.1%。",
    "title_cn": "BlockLLM：为大型语言模型打造多租户精细化服务",
    "tags": [
      "LLM应用",
      "深度学习服务",
      "区块链"
    ]
  },
  {
    "title": "Trends and Challenges of Real-time Learning in Large Language Models: A Critical Review",
    "submit_datetime": "2024年04月28日",
    "abstract": "Real-time learning concerns the ability of learning systems to acquire knowledge over time, enabling their adaptation and generalization to novel tasks. It is a critical ability for intelligent, real-world systems, especially when data may be insufficient or difficult to obtain. This review provides a comprehensive analysis of real-time learning in Large Language Models. It synthesizes the state-of-the-art real-time learning paradigms, including continual learning, meta-learning, parameter-efficient learning, and mixture-of-experts learning. We demonstrate their utility for real-time learning by describing specific achievements from these related topics and their critical factors. Finally, the paper highlights current problems and challenges for future research in the field. By consolidating the latest relevant research developments, this review offers a comprehensive understanding of real-time learning and its implications for designing and developing LLM-based learning systems addressing real-world problems.",
    "pdf_link": "https://arxiv.org/abs/2404.18311",
    "graphs": [],
    "abstract_cn": "实时学习是指学习系统能够随着时间的推移积累知识，从而实现对新任务的适应和泛化。这一能力对于智能化、实际应用的系统尤为关键，尤其是在数据获取受限或不足的情况下。本篇综述深入探讨了大型语言模型中的实时学习，涵盖了持续学习、元学习、参数高效学习以及专家混合学习等前沿学习范式。通过详细阐述这些领域的具体进展和关键要素，我们展示了这些范式在实时学习中的实际应用价值。文章最后指出了当前面临的挑战，并对未来研究方向提出了展望。通过汇总最新的研究成果，本综述旨在为设计和开发基于LLM的、能够应对现实世界问题的智能学习系统提供全面的理论支持。",
    "title_cn": "大型语言模型实时学习的潮流与难题：深入剖析",
    "tags": [
      "LLM理论",
      "人工智能",
      "机器学习"
    ]
  },
  {
    "title": "Comparing LLM prompting with Cross-lingual transfer performance on Indigenous and Low-resource Brazilian Languages",
    "submit_datetime": "2024年04月28日",
    "abstract": "Large Language Models are transforming NLP for a variety of tasks. However, how LLMs perform NLP tasks for low-resource languages (LRLs) is less explored. In line with the goals of the AmeicasNLP workshop, we focus on 12 LRLs from Brazil, 2 LRLs from Africa and 2 high-resource languages (HRLs) (e.g., English and Brazilian Portuguese). Our results indicate that the LLMs perform worse for the part of speech (POS) labeling of LRLs in comparison to HRLs. We explain the reasons behind this failure and provide an error analyses through examples observed in our data set.",
    "pdf_link": "https://arxiv.org/abs/2404.18286",
    "graphs": [],
    "abstract_cn": "大型语言模型正重塑多任务自然语言处理的格局。但对于低资源语言的任务执行情况，研究尚显不足。本研究响应 AmeicasNLP 研讨会的议程，聚焦巴西的12种低资源语言、非洲的两种以及英语和巴西葡萄牙语等两种高资源语言。研究发现，LLMs 在这些低资源语言的词性标注任务上的表现不及高资源语言。文章深入探讨了这一现象的成因，并通过实例分析，对错误进行了详细解读。",
    "title_cn": "本文旨在探讨大型语言模型在处理土著和资源匮乏的巴西语言时，其提示策略与跨语言迁移性能之间的比较。",
    "tags": [
      "LLM应用",
      "",
      "语言资源"
    ]
  },
  {
    "title": "Bias Neutralization Framework: Measuring Fairness in Large Language Models with Bias Intelligence Quotient (BiQ)",
    "submit_datetime": "2024年04月28日",
    "abstract": "The burgeoning influence of Large Language Models (LLMs) in shaping public discourse and decision-making underscores the imperative to address inherent biases within these AI systems. In the wake of AI's expansive integration across sectors, addressing racial bias in LLMs has never been more critical. This paper introduces a novel framework called Comprehensive Bias Neutralization Framework (CBNF) which embodies an innovative approach to quantifying and mitigating biases within LLMs. Our framework combines the Large Language Model Bias Index (LLMBI) [Oketunji, A., Anas, M., Saina, D., (2023)] and Bias removaL with No Demographics (BLIND) [Orgad, H., Belinkov, Y. (2023)] methodologies to create a new metric called Bias Intelligence Quotient (BiQ)which detects, measures, and mitigates racial bias in LLMs without reliance on demographic annotations.\n  By introducing a new metric called BiQ that enhances LLMBI with additional fairness metrics, CBNF offers a multi-dimensional metric for bias assessment, underscoring the necessity of a nuanced approach to fairness in AI [Mehrabi et al., 2021]. This paper presents a detailed analysis of Latimer AI (a language model incrementally trained on black history and culture) in comparison to ChatGPT 3.5, illustrating Latimer AI's efficacy in detecting racial, cultural, and gender biases through targeted training and refined bias mitigation strategies [Latimer & Bender, 2023].",
    "pdf_link": "https://arxiv.org/abs/2404.18276",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）对公共讨论和决策的影响力不断上升，这凸显了解决AI系统中内在偏见的紧迫性。在AI技术广泛应用于各行各业的今天，消除LLMs中的种族偏见尤为紧要。本文提出了一个创新的全面偏见中和框架（CBNF），旨在量化和降低LLMs中的偏见。该框架融合了大型语言模型偏见指数（LLMBI）和无人口统计信息的偏见移除（BLIND）技术，创新性地推出了一个新的度量工具——偏见智能商数（BiQ），它能够在不依赖人口统计信息的情况下，检测、衡量并减少LLMs中的种族偏见。CBNF通过引入BiQ这一新度量标准，不仅增强了LLMBI的公平性指标，还为偏见评估提供了一个多角度的视角，强调了在AI领域采取细致公平观念的必要性。本文还深入分析了Latimer AI（一个基于黑人历史和文化逐步训练的语言模型）与ChatGPT 3.5的性能对比，展示了Latimer AI在通过专门训练和精细的偏见缓解策略，有效识别种族、文化和性别偏见方面的优势。",
    "title_cn": "偏见中和框架：通过偏见智能商数（BiQ）评估大型语言模型的公平性。",
    "tags": [
      "分类：LLM应用",
      "AI偏见检测",
      "语言模型"
    ]
  },
  {
    "title": "Parameter-Efficient Tuning Large Language Models for Graph Representation Learning",
    "submit_datetime": "2024年04月28日",
    "abstract": "Text-rich graphs, which exhibit rich textual information on nodes and edges, are prevalent across a wide range of real-world business applications. Large Language Models (LLMs) have demonstrated remarkable abilities in understanding text, which also introduced the potential for more expressive modeling in text-rich graphs. Despite these capabilities, efficiently applying LLMs to representation learning on graphs presents significant challenges. Recently, parameter-efficient fine-tuning methods for LLMs have enabled efficient new task generalization with minimal time and memory consumption. Inspired by this, we introduce Graph-aware Parameter-Efficient Fine-Tuning - GPEFT, a novel approach for efficient graph representation learning with LLMs on text-rich graphs. Specifically, we utilize a graph neural network (GNN) to encode structural information from neighboring nodes into a graph prompt. This prompt is then inserted at the beginning of the text sequence. To improve the quality of graph prompts, we pre-trained the GNN to assist the frozen LLM in predicting the next token in the node text. Compared with existing joint GNN and LMs, our method directly generate the node embeddings from large language models with an affordable fine-tuning cost. We validate our approach through comprehensive experiments conducted on 8 different text-rich graphs, observing an average improvement of 2% in hit@1 and Mean Reciprocal Rank (MRR) in link prediction evaluations. Our results demonstrate the efficacy and efficiency of our model, showing that it can be smoothly integrated with various large language models, including OPT, LLaMA and Falcon.",
    "pdf_link": "https://arxiv.org/abs/2404.18271",
    "graphs": [],
    "abstract_cn": "文本丰富的图在众多现实世界的商业应用中无处不在，它们在节点和边中嵌入了丰富的文本信息。大型语言模型（LLMs）凭借其卓越的文本理解能力，为这类图的建模提供了新的表达潜力。然而，将LLMs应用于图的表示学习，尽管潜力巨大，却也面临着不小的挑战。最近，一种针对LLMs的参数高效微调技术，以最小的时间和内存消耗，实现了新任务的快速泛化。基于此，我们提出了图感知参数高效微调（GPEFT），这是一种创新的方法，用于在文本丰富的图上与LLMs一起进行高效的图表示学习。我们利用图神经网络（GNN）捕捉邻近节点的结构信息，并将这些信息编码成图提示，该提示置于文本序列的前端。为了提升图提示的质量，我们对GNN进行了预训练，以便在LLM固定的情况下预测节点文本中的下一个标记。与现有的GNN和语言模型的联合方法相比，我们的方法能够以较低的微调成本，直接从大型语言模型中生成节点嵌入。通过在8种不同的文本丰富图上进行的广泛实验，我们在链接预测评估中实现了平均2%的性能提升，无论是在命中率@1还是平均倒数排名（MRR）上。这些结果展示了我们模型的高效性和有效性，并证明了它可以无缝地与包括OPT、LLaMA和Falcon在内的多种大型语言模型集成。",
    "title_cn": "通过参数高效的方法调整大型语言模型，以优化图表示学习的效果。",
    "tags": [
      "LLM应用",
      "商业应用",
      "图表示学习"
    ]
  },
  {
    "title": "Generating Situated Reflection Triggers about Alternative Solution Paths: A Case Study of Generative AI for Computer-Supported Collaborative Learning",
    "submit_datetime": "2024年04月28日",
    "abstract": "An advantage of Large Language Models (LLMs) is their contextualization capability - providing different responses based on student inputs like solution strategy or prior discussion, to potentially better engage students than standard feedback. We present a design and evaluation of a proof-of-concept LLM application to offer students dynamic and contextualized feedback. Specifically, we augment an Online Programming Exercise bot for a college-level Cloud Computing course with ChatGPT, which offers students contextualized reflection triggers during a collaborative query optimization task in database design. We demonstrate that LLMs can be used to generate highly situated reflection triggers that incorporate details of the collaborative discussion happening in context. We discuss in depth the exploration of the design space of the triggers and their correspondence with the learning objectives as well as the impact on student learning in a pilot study with 34 students.",
    "pdf_link": "https://arxiv.org/abs/2404.18262",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.18262v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18262/Demonstration_of_Intervention.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18262v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18262/timestamp_analysis_plot.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18262v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18262/activity_architecture.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18262v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18262/pre_test_scores.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18262v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18262/post_test_scores_.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）的突出之处在于其上下文化能力，能够根据不同的学生输入，如解题策略或先前的讨论，提供多样化的反馈，从而可能更有效地吸引学生。本研究介绍了一个概念验证的LLM应用，旨在为学生提供动态且具有上下文性的反馈。具体而言，我们为大学级别的云计算课程的在线编程练习机器人集成了ChatGPT，该机器人在数据库设计中的协作查询优化任务中，为学生提供了定制化的反思触发点。我们证明，LLMs能够生成高度情境化的反思触发点，这些触发点融合了正在进行的协作讨论的具体细节。此外，我们还深入探讨了触发点设计空间的探索，它们与学习目标的契合度，以及在一项涉及34名学生的试点研究中对学习成效的影响。",
    "title_cn": "探索替代解决路径的情境反思触发器：以计算机辅助协作学习中的生成型AI为例",
    "tags": [
      "分类：LLM应用",
      "",
      "云计算"
    ]
  },
  {
    "title": "PatentGPT: A Large Language Model for Intellectual Property",
    "submit_datetime": "2024年04月28日",
    "abstract": "In recent years, large language models have attracted significant attention due to their exceptional performance across a multitude of natural language process tasks, and have been widely applied in various fields. However, the application of large language models in the Intellectual Property (IP) space is challenging due to the strong need for specialized knowledge, privacy protection, processing of extremely long text in this field. In this technical report, we present for the first time a low-cost, standardized procedure for training IP-oriented LLMs, meeting the unique requirements of the IP domain. Using this standard process, we have trained the PatentGPT series models based on open-source pretrained models. By evaluating them on the open-source IP-oriented benchmark MOZIP, our domain-specific LLMs outperforms GPT-4, indicating the effectiveness of the proposed training procedure and the expertise of the PatentGPT models in the IP demain. What is impressive is that our model significantly outperformed GPT-4 on the 2019 China Patent Agent Qualification Examination by achieving a score of 65, reaching the level of human experts. Additionally, the PatentGPT model, which utilizes the SMoE architecture, achieves performance comparable to that of GPT-4 in the IP domain and demonstrates a better cost-performance ratio on long-text tasks, potentially serving as an alternative to GPT-4 within the IP domain.",
    "pdf_link": "https://arxiv.org/abs/2404.18255",
    "graphs": [],
    "abstract_cn": "近年来，大型语言模型在众多自然语言处理任务上展现出色的表现，因而备受瞩目，并已在多个领域得到广泛应用。但在知识产权（IP）领域，由于对专业知识的高要求、隐私保护的必要性以及处理超长文本的难题，这些模型的应用面临挑战。本技术报告首次介绍一种经济高效且标准化的方法，用于培育符合IP领域特殊需求的语言模型。我们采用这一流程，基于开源预训练模型，训练出PatentGPT系列模型。在开源IP基准测试MOZIP上的评估结果显示，我们的定制化LLM性能超越了GPT-4，验证了我们提出的训练方法的有效性及PatentGPT模型在IP领域的专业性。更值得一提的是，我们的模型在2019年中国专利代理资格考试中以65分的成绩大幅领先GPT-4，达到了人类专家的水准。此外，采用SMoE架构的PatentGPT模型，在IP领域的性能可与GPT-4媲美，并在处理长文本任务时展现出更优的性价比，有潜力成为IP领域内GPT-4的有力竞争者。",
    "title_cn": "PatentGPT：专为知识产权领域打造的先进大型语言模型。",
    "tags": [
      "LLM应用",
      "知识产权",
      ""
    ]
  },
  {
    "title": "Efficient Remote Sensing with Harmonized Transfer Learning and Modality Alignment",
    "submit_datetime": "2024年04月28日",
    "abstract": "With the rise of Visual and Language Pretraining (VLP), an increasing number of downstream tasks are adopting the paradigm of pretraining followed by fine-tuning. Although this paradigm has demonstrated potential in various multimodal downstream tasks, its implementation in the remote sensing domain encounters some obstacles. Specifically, the tendency for same-modality embeddings to cluster together impedes efficient transfer learning. To tackle this issue, we review the aim of multimodal transfer learning for downstream tasks from a unified perspective, and rethink the optimization process based on three distinct objectives. We propose \"Harmonized Transfer Learning and Modality Alignment (HarMA)\", a method that simultaneously satisfies task constraints, modality alignment, and single-modality uniform alignment, while minimizing training overhead through parameter-efficient fine-tuning. Remarkably, without the need for external data for training, HarMA achieves state-of-the-art performance in two popular multimodal retrieval tasks in the field of remote sensing. Our experiments reveal that HarMA achieves competitive and even superior performance to fully fine-tuned models with only minimal adjustable parameters. Due to its simplicity, HarMA can be integrated into almost all existing multimodal pretraining models. We hope this method can facilitate the efficient application of large models to a wide range of downstream tasks while significantly reducing the resource consumption. Code is available at https://github.com/seekerhuang/HarMA.",
    "pdf_link": "https://arxiv.org/abs/2404.18253",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.18253v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18253/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18253v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18253/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18253v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18253/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18253v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18253/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18253v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18253/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18253v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18253/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18253v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18253/x7.png"
      }
    ],
    "abstract_cn": "视觉与语言预训练（VLP）的兴起引领了一种新的范式：先进行预训练，然后进行微调，这一范式在众多多模态任务中展现出巨大潜力。然而，在遥感领域，这种范式的实施面临挑战，尤其是同模态嵌入的聚集现象，这影响了迁移学习的效率。为此，我们从整体视角审视了多模态迁移学习的目标，并提出了一种新颖的优化策略，旨在解决这一问题。我们介绍的“和谐迁移学习和模态对齐（HarMA）”方法，不仅满足任务需求和模态间的协调，还实现了单模态的统一对齐，并通过高效的参数微调减少了训练成本。HarMA的卓越之处在于，它无需额外训练数据，便能在遥感领域的两个主要多模态检索任务中达到领先水平。实验结果揭示了HarMA在参数调整极少的情况下，性能即可与完全微调的模型相媲美，甚至更优。HarMA的简洁性使其能够轻松融入现有的多模态预训练模型之中。我们期待HarMA能够助力大型模型在多样化任务中的应用，同时大幅度降低资源消耗。相关代码已在 https://github.com/seekerhuang/HarMA 上发布。",
    "title_cn": "采用和谐迁移学习与模态校准技术，实现高效遥感探测",
    "tags": [
      "LLM应用",
      "",
      "多模态学习"
    ]
  },
  {
    "title": "LEGENT: Open Platform for Embodied Agents",
    "submit_datetime": "2024年04月28日",
    "abstract": "Despite advancements in Large Language Models (LLMs) and Large Multimodal Models (LMMs), their integration into language-grounded, human-like embodied agents remains incomplete, hindering complex real-life task performance in physical environments. Existing integrations often feature limited open sourcing, challenging collective progress in this field. We introduce LEGENT, an open, scalable platform for developing embodied agents using LLMs and LMMs. LEGENT offers a dual approach: a rich, interactive 3D environment with communicable and actionable agents, paired with a user-friendly interface, and a sophisticated data generation pipeline utilizing advanced algorithms to exploit supervision from simulated worlds at scale. In our experiments, an embryonic vision-language-action model trained on LEGENT-generated data surpasses GPT-4V in embodied tasks, showcasing promising generalization capabilities.",
    "pdf_link": "https://arxiv.org/abs/2404.18243",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.18243v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18243/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18243v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18243/procthor.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18243v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18243/holodeck.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18243v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18243/traj.jpg"
      }
    ],
    "abstract_cn": "尽管大型语言模型（LLMs）和大型多模态模型（LMMs）取得了显著进步，但将其融入到类似人类的、具有语言能力的具身代理中仍面临挑战，这限制了它们在现实世界任务中的复杂性能。目前，大多数集成工作开源程度有限，这影响了整个领域的进步。为此，我们推出了LEGENT，这是一个开放且可扩展的平台，旨在利用LLMs和LMMs打造具身代理。LEGENT结合了丰富的互动3D环境和易于操作的用户界面，以及一个先进的数据生成流程，该流程使用复杂算法从模拟世界中提取大规模监督信息。在实验中，基于LEGENT数据训练的初级视觉-语言-行动模型在具身任务上的表现超过了GPT-4V，显示了其出色的泛化潜力。",
    "title_cn": "LEGENT：为具身代理打造的开放平台",
    "tags": [
      "Agent",
      "人工智能",
      "机器人技术"
    ]
  },
  {
    "title": "SOUL: Unlocking the Power of Second-Order Optimization for LLM Unlearning",
    "submit_datetime": "2024年04月28日",
    "abstract": "Large Language Models (LLMs) have highlighted the necessity of effective unlearning mechanisms to comply with data regulations and ethical AI practices. LLM unlearning aims at removing undesired data influences and associated model capabilities without compromising utility out of the scope of unlearning. While interest in studying LLM unlearning is growing,the impact of the optimizer choice for LLM unlearning remains under-explored. In this work, we shed light on the significance of optimizer selection in LLM unlearning for the first time, establishing a clear connection between {second-order optimization} and influence unlearning (a classical approach using influence functions to update the model for data influence removal). This insight propels us to develop a second-order unlearning framework, termed SOUL, built upon the second-order clipped stochastic optimization (Sophia)-based LLM training method. SOUL extends the static, one-shot model update using influence unlearning to a dynamic, iterative unlearning process. Our extensive experiments show that SOUL consistently outperforms conventional first-order methods across various unlearning tasks, models, and metrics, suggesting the promise of second-order optimization in providing a scalable and easily implementable solution for LLM unlearning.",
    "pdf_link": "https://arxiv.org/abs/2404.18239",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）凸显了为了遵守数据法规和遵循道德的AI实践，必须具备有效的遗忘机制。LLM的遗忘目的是消除不需要的数据影响及其对模型能力的影响，同时保持模型在遗忘范围之外的实用性。尽管对LLM遗忘的研究兴趣日益增长，但选择优化器对LLM遗忘的影响尚未得到充分研究。本研究首次揭示了优化器选择在LLM遗忘中的重要性，并明确了二阶优化与影响遗忘之间的联系，后者是一种利用影响函数更新模型以去除数据影响的经典方法。基于此，我们提出了一个名为SOUL的二阶遗忘框架，该框架基于二阶裁剪随机优化（Sophia）的LLM训练方法构建。SOUL将传统的静态一次性模型更新方法转变为动态迭代的遗忘过程。我们的广泛实验表明，SOUL在多种遗忘任务、模型和评价指标上均优于常规的一阶方法，这预示着二阶优化在为LLM遗忘提供可扩展且易于实施的解决方案方面具有巨大潜力。",
    "title_cn": "SOUL：释放二阶优化在大型语言模型“忘却”过程中的潜力。",
    "tags": [
      "LLM理论",
      "数据法规",
      "人工智能伦理"
    ]
  },
  {
    "title": "From Persona to Personalization: A Survey on Role-Playing Language Agents",
    "submit_datetime": "2024年04月28日",
    "abstract": "Recent advancements in large language models (LLMs) have significantly boosted the rise of Role-Playing Language Agents (RPLAs), i.e., specialized AI systems designed to simulate assigned personas. By harnessing multiple advanced abilities of LLMs, including in-context learning, instruction following, and social intelligence, RPLAs achieve a remarkable sense of human likeness and vivid role-playing performance. RPLAs can mimic a wide range of personas, ranging from historical figures and fictional characters to real-life individuals. Consequently, they have catalyzed numerous AI applications, such as emotional companions, interactive video games, personalized assistants and copilots, and digital clones. In this paper, we conduct a comprehensive survey of this field, illustrating the evolution and recent progress in RPLAs integrating with cutting-edge LLM technologies. We categorize personas into three types: 1) Demographic Persona, which leverages statistical stereotypes; 2) Character Persona, focused on well-established figures; and 3) Individualized Persona, customized through ongoing user interactions for personalized services. We begin by presenting a comprehensive overview of current methodologies for RPLAs, followed by the details for each persona type, covering corresponding data sourcing, agent construction, and evaluation. Afterward, we discuss the fundamental risks, existing limitations, and future prospects of RPLAs. Additionally, we provide a brief review of RPLAs in AI applications, which reflects practical user demands that shape and drive RPLA research. Through this work, we aim to establish a clear taxonomy of RPLA research and applications, and facilitate future research in this critical and ever-evolving field, and pave the way for a future where humans and RPLAs coexist in harmony.",
    "pdf_link": "https://arxiv.org/abs/2404.18231",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.18231v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18231/x1.png"
      }
    ],
    "abstract_cn": "近期大型语言模型（LLMs）的突破性进展极大地促进了角色扮演语言代理（RPLAs）的发展，这是一种专为模拟特定人物角色而设计的AI系统。RPLAs借助LLMs的多项高级功能，如情境学习、指令执行和社交智能，展现出了极高的人类相似度和生动的角色扮演能力。它们能够模拟从历史名人到虚构角色，再到现实生活中的个体等各种人物形象。因此，RPLAs推动了情感伴侣、互动式电子游戏、个性化助理和副驾驶，以及数字克隆等多种AI应用的发展。本文全面梳理了这一领域的研究进展，展示了RPLAs如何与前沿的LLM技术相结合。我们将人物角色分为三类：1）利用统计学刻板印象的人口统计角色；2）专注于知名人物的角色角色；3）通过持续用户互动定制的个性化角色。文章首先全面概述了RPLAs的当前方法，然后详细介绍了每种角色类型的具体情况，包括相应的数据来源、代理构建和评估方法。接着，我们探讨了RPLAs的基本风险、现有局限和未来发展方向。此外，我们还简要回顾了RPLAs在AI应用中的实践，这些应用反映了用户的实际需求，也正是这些需求推动了RPLA研究的发展。通过本研究，我们希望建立一个清晰的RPLA研究和应用分类体系，推动这一关键且快速演变领域的未来研究，并为人类与RPLAs和谐共存的未来奠定基础。",
    "title_cn": "探索角色扮演语言代理：个性化之路的调查研究",
    "tags": [
      "分类：Agent",
      "人工智能",
      "角色扮演"
    ]
  },
  {
    "title": "TextGram: Towards a better domain-adaptive pretraining",
    "submit_datetime": "2024年04月28日",
    "abstract": "For green AI, it is crucial to measure and reduce the carbon footprint emitted during the training of large language models. In NLP, performing pre-training on Transformer models requires significant computational resources. This pre-training involves using a large amount of text data to gain prior knowledge for performing downstream tasks. Thus, it is important that we select the correct data in the form of domain-specific data from this vast corpus to achieve optimum results aligned with our domain-specific tasks. While training on large unsupervised data is expensive, it can be optimized by performing a data selection step before pretraining. Selecting important data reduces the space overhead and the substantial amount of time required to pre-train the model while maintaining constant accuracy. We investigate the existing selection strategies and propose our own domain-adaptive data selection method - TextGram - that effectively selects essential data from large corpora. We compare and evaluate the results of finetuned models for text classification task with and without data selection. We show that the proposed strategy works better compared to other selection methods.",
    "pdf_link": "https://arxiv.org/abs/2404.18228",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.18228v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18228/Architecture3.jpg"
      },
      {
        "url": "https://arxiv.org/html/2404.18228v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18228/textgram.png"
      }
    ],
    "abstract_cn": "绿色AI的核心在于准确衡量并降低大型语言模型训练过程中的碳排放。在自然语言处理领域，对Transformer模型进行预训练需要动用庞大的计算资源。这一过程通过大量文本数据积累知识，以便更好地执行后续任务。因此，从海量语料中精准挑选出与特定领域相关的数据，对于实现最佳任务效果至关重要。尽管基于大规模无监督数据的训练成本高昂，但通过在预训练前进行数据筛选可以优化这一过程。精选关键数据不仅减少了存储开销，还缩短了模型预训练的时间，同时确保了准确性。我们深入研究了现有的数据筛选策略，并提出了一种新的领域适应性数据筛选方法——TextGram，它能够高效地从大型语料库中筛选出关键数据。我们对比了应用和不应用数据筛选的文本分类任务的微调模型效果，并验证了我们策略的优越性。",
    "title_cn": "TextGram：探索更优的领域适应性预训练之路",
    "tags": [
      "LLM应用",
      "",
      "环境科学"
    ]
  },
  {
    "title": "Paint by Inpaint: Learning to Add Image Objects by Removing Them First",
    "submit_datetime": "2024年04月28日",
    "abstract": "Image editing has advanced significantly with the introduction of text-conditioned diffusion models. Despite this progress, seamlessly adding objects to images based on textual instructions without requiring user-provided input masks remains a challenge. We address this by leveraging the insight that removing objects (Inpaint) is significantly simpler than its inverse process of adding them (Paint), attributed to the utilization of segmentation mask datasets alongside inpainting models that inpaint within these masks. Capitalizing on this realization, by implementing an automated and extensive pipeline, we curate a filtered large-scale image dataset containing pairs of images and their corresponding object-removed versions. Using these pairs, we train a diffusion model to inverse the inpainting process, effectively adding objects into images. Unlike other editing datasets, ours features natural target images instead of synthetic ones; moreover, it maintains consistency between source and target by construction. Additionally, we utilize a large Vision-Language Model to provide detailed descriptions of the removed objects and a Large Language Model to convert these descriptions into diverse, natural-language instructions. We show that the trained model surpasses existing ones both qualitatively and quantitatively, and release the large-scale dataset alongside the trained models for the community.",
    "pdf_link": "https://arxiv.org/abs/2404.18212",
    "graphs": [],
    "abstract_cn": "文本条件扩散模型的推出极大推动了图像编辑技术的发展。然而，依据文本指令在图像中无缝添加对象，且无需用户提供输入遮罩，这一任务依然充满挑战。我们通过洞察到移除对象（修复）比添加对象（绘画）更为简单，利用这一原理，结合分割掩码数据集和修复模型，实现了在掩码区域内的修复。基于这一认识，我们构建了一个自动化的流程，创建了一个精选的大规模图像数据集，包含了原始图像及其去除了对象的对应版本。利用这些图像对，我们训练了一个扩散模型，以逆转修复过程，从而在图像中有效添加对象。与其它编辑数据集相比，我们的集锦采用了更自然的图像，并且在源图像和目标图像之间通过构建保持了一致性。此外，我们还采用了一个大型视觉-语言模型来详细描述被移除的对象，并通过一个大型语言模型将这些描述转换成多样化的自然语言指令。我们证明，我们训练的模型在质量和数量上都超越了现有模型，并且我们已经将这个大规模数据集和训练好的模型公开，供社区使用。",
    "title_cn": "先删后加，学习图像编辑新技巧：Inpaint的智能绘画教学",
    "tags": [
      "分类：LLM应用",
      "图像编辑",
      "人工智能"
    ]
  },
  {
    "title": "4DBInfer: A 4D Benchmarking Toolbox for Graph-Centric Predictive Modeling on Relational DBs",
    "submit_datetime": "2024年04月28日",
    "abstract": "Although RDBs store vast amounts of rich, informative data spread across interconnected tables, the progress of predictive machine learning models as applied to such tasks arguably falls well behind advances in other domains such as computer vision or natural language processing. This deficit stems, at least in part, from the lack of established/public RDB benchmarks as needed for training and evaluation purposes. As a result, related model development thus far often defaults to tabular approaches trained on ubiquitous single-table benchmarks, or on the relational side, graph-based alternatives such as GNNs applied to a completely different set of graph datasets devoid of tabular characteristics. To more precisely target RDBs lying at the nexus of these two complementary regimes, we explore a broad class of baseline models predicated on: (i) converting multi-table datasets into graphs using various strategies equipped with efficient subsampling, while preserving tabular characteristics; and (ii) trainable models with well-matched inductive biases that output predictions based on these input subgraphs. Then, to address the dearth of suitable public benchmarks and reduce siloed comparisons, we assemble a diverse collection of (i) large-scale RDB datasets and (ii) coincident predictive tasks. From a delivery standpoint, we operationalize the above four dimensions (4D) of exploration within a unified, scalable open-source toolbox called 4DBInfer. We conclude by presenting evaluations using 4DBInfer, the results of which highlight the importance of considering each such dimension in the design of RDB predictive models, as well as the limitations of more naive approaches such as simply joining adjacent tables. Our source code is released at https://github.com/awslabs/multi-table-benchmark .",
    "pdf_link": "https://arxiv.org/abs/2404.18209",
    "graphs": [],
    "abstract_cn": "关系数据库（RDBs）虽然在互联表中存储了海量的丰富信息数据，但在这些任务上应用预测性机器学习模型的发展，相较于计算机视觉或自然语言处理等领域，显然还有很大的提升空间。这一差距部分原因在于缺少用于训练和评估的标准公共RDB基准。因此，目前的相关模型开发往往倾向于使用单一表基准训练的表格方法，或是采用图神经网络（GNN）等基于图的替代方案，这些方案应用于与表格特性迥异的数据集。为了更精准地针对处于这两个领域交汇处的RDBs，我们研究了一系列基线模型，这些模型基于：（i）采用多种策略将多表数据集转换为图，同时保留其表格特性；（ii）设计具有适当归纳偏置的可训练模型，这些模型能够基于输入子图进行预测。为了填补公共基准的空白并减少孤立比较，我们汇集了大量RDB数据集和相应的预测任务。我们通过一个名为4DBInfer的统一、可扩展的开源工具箱，实现了对这四个探索维度（4D）的操作。最后，我们使用4DBInfer进行评估，结果强调了在设计RDB预测模型时考虑每个维度的重要性，并指出了简单方法（如直接连接相邻表）的局限性。我们的源代码已在 https://github.com/awslabs/multi-table-benchmark 上发布。",
    "title_cn": "4DBInfer：一款专为关系数据库设计的四维基准测试工具箱，专注于图形中心的预测性建模。",
    "tags": [
      "LLM应用",
      "数据库管理",
      "机器学习"
    ]
  },
  {
    "title": "WorldGPT: Empowering LLM as Multimodal World Model",
    "submit_datetime": "2024年04月28日",
    "abstract": "World models are progressively being employed across diverse fields, extending from basic environment simulation to complex scenario construction. However, existing models are mainly trained on domain-specific states and actions, and confined to single-modality state representations. In this paper, We introduce WorldGPT, a generalist world model built upon Multimodal Large Language Model (MLLM). WorldGPT acquires an understanding of world dynamics through analyzing millions of videos across various domains. To further enhance WorldGPT's capability in specialized scenarios and long-term tasks, we have integrated it with a novel cognitive architecture that combines memory offloading, knowledge retrieval, and context reflection. As for evaluation, we build WorldNet, a multimodal state transition prediction benchmark encompassing varied real-life scenarios. Conducting evaluations on WorldNet directly demonstrates WorldGPT's capability to accurately model state transition patterns, affirming its effectiveness in understanding and predicting the dynamics of complex scenarios. We further explore WorldGPT's emerging potential in serving as a world simulator, helping multimodal agents generalize to unfamiliar domains through efficiently synthesising multimodal instruction instances which are proved to be as reliable as authentic data for fine-tuning purposes. The project is available on \\url{https://github.com/DCDmllm/WorldGPT}.",
    "pdf_link": "https://arxiv.org/abs/2404.18202",
    "graphs": [],
    "abstract_cn": "世界模型正广泛应用于环境模拟到复杂场景构建等多个领域。现有模型多基于特定领域的状态和动作训练，且限于单一模态的表示。本文提出了 WorldGPT，一个基于多模态大型语言模型（MLLM）构建的通用世界模型，它通过分析数百万跨领域的视频来理解世界动态。为了提升其在特定场景和长期任务中的性能，我们引入了一种融合记忆卸载、知识检索和上下文反思的认知架构。我们构建了 WorldNet，一个多模态状态转换预测基准，覆盖了多种真实场景，用以评估 WorldGPT 的性能。评估结果证明了 WorldGPT 在准确模拟和预测复杂场景动态方面的能力。此外，我们还探讨了 WorldGPT 作为世界模拟器的潜力，它能够通过合成可靠的多模态指令实例，帮助多模态代理泛化到新领域，这些实例在微调中与真实数据同样有效。项目详情可访问 \\url{https://github.com/DCDmllm/WorldGPT}。",
    "title_cn": "WorldGPT：赋予大型语言模型多模态世界建模能力",
    "tags": [
      "分类：LLM应用",
      "环境模拟",
      "人工智能"
    ]
  },
  {
    "title": "Exploring the Robustness of In-Context Learning with Noisy Labels",
    "submit_datetime": "2024年04月28日",
    "abstract": "Recently, the mysterious In-Context Learning (ICL) ability exhibited by Transformer architectures, especially in large language models (LLMs), has sparked significant research interest. However, the resilience of Transformers' in-context learning capabilities in the presence of noisy samples, prevalent in both training corpora and prompt demonstrations, remains underexplored. In this paper, inspired by prior research that studies ICL ability using simple function classes, we take a closer look at this problem by investigating the robustness of Transformers against noisy labels. Specifically, we first conduct a thorough evaluation and analysis of the robustness of Transformers against noisy labels during in-context learning and show that they exhibit notable resilience against diverse types of noise in demonstration labels. Furthermore, we delve deeper into this problem by exploring whether introducing noise into the training set, akin to a form of data augmentation, enhances such robustness during inference, and find that such noise can indeed improve the robustness of ICL. Overall, our fruitful analysis and findings provide a comprehensive understanding of the resilience of Transformer models against label noises during ICL and provide valuable insights into the research on Transformers in natural language processing. Our code is available at https://github.com/InezYu0928/in-context-learning.",
    "pdf_link": "https://arxiv.org/abs/2404.18191",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/error_curve_std_expotential.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/error_curve_std_uniform.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/error_curve_std_expotential.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/error_curve_std_poisson.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/error_curve_std_multiplicative.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/error_curve_std_salt_pepper.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/error_curve_baseline_gaussian.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/error_curve_baseline_gaussian.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/error_curve_baseline_gaussian.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/error_curve_baseline_uniform.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/error_curve_baseline_uniform.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/error_curve_baseline_uniform.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/error_curve_baseline_expotential.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/error_curve_baseline_expotential.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/error_curve_baseline_expotential.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/error_curve_baseline_poisson.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/error_curve_baseline_poisson.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/error_curve_baseline_poisson.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/error_curve_baseline_multiplicative.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/error_curve_baseline_multiplicative.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/error_curve_baseline_multiplicative.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/error_curve_baseline_salt_pepper.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/error_curve_baseline_salt_pepper.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/error_curve_baseline_salt_pepper.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/loss_curve_2_0.0.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/loss_curve_2_0.1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/loss_curve_2_0.2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/loss_curve_2_0.5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/loss_curve_3_0.0.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/loss_curve_3_0.1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/loss_curve_3_0.2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/loss_curve_3_0.5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/loss_curve_4_0.0.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/loss_curve_4_0.1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/loss_curve_4_0.2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/loss_curve_4_0.5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/loss_curve_5_0.0.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/loss_curve_5_0.1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/loss_curve_5_0.2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/loss_curve_5_0.5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/tr00_tst00.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/tr00_tst02.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/tr00_tst04.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/tr00_tst06.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/tr00_tst08.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/tr00_tst10.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/noise_std00.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/noise_std02.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/noise_std04.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/noise_std06.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/noise_std08.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/noise_std10.png"
      }
    ],
    "abstract_cn": "近期，变换器架构所展现的神秘上下文学习能力（ICL），尤其在大型语言模型（LLMs）中，引起了广泛的研究关注。尽管如此，变换器在面对充满噪声样本的上下文学习中的鲁棒性，这一问题在训练语料和提示演示中普遍存在，却鲜有深入探讨。本文受到先前研究的启发，那些研究通过简单的函数类别来探究ICL能力，我们通过深入探讨变换器对噪声标签的鲁棒性，来更细致地审视这一问题。具体而言，我们首先对变换器在上下文学习过程中对噪声标签的鲁棒性进行了详尽的评估与分析，发现变换器对示范标签中多样化的噪声类型具有显著的抵抗力。进一步地，我们探究了在训练集中引入噪声，类似于数据增强手段，是否能够增强推理过程中的这种鲁棒性，并发现这样的噪声确实能够提升ICL的鲁棒性。总体而言，我们深入的分析和发现为理解变换器模型在ICL过程中对抗标签噪声的鲁棒性提供了全面的视角，为自然语言处理领域中变换器的研究提供了宝贵的洞见。我们的代码已在 https://github.com/InezYu0928/in-context-learning 上公开。",
    "title_cn": "探究含噪声标签情境下ICL的稳健性",
    "tags": [
      "LLM理论",
      "",
      "机器学习"
    ]
  },
  {
    "title": "Ranked List Truncation for Large Language Model-based Re-Ranking",
    "submit_datetime": "2024年04月28日",
    "abstract": "We study ranked list truncation (RLT) from a novel \"retrieve-then-re-rank\" perspective, where we optimize re-ranking by truncating the retrieved list (i.e., trim re-ranking candidates). RLT is crucial for re-ranking as it can improve re-ranking efficiency by sending variable-length candidate lists to a re-ranker on a per-query basis. It also has the potential to improve re-ranking effectiveness. Despite its importance, there is limited research into applying RLT methods to this new perspective. To address this research gap, we reproduce existing RLT methods in the context of re-ranking, especially newly emerged large language model (LLM)-based re-ranking. In particular, we examine to what extent established findings on RLT for retrieval are generalizable to the \"retrieve-then-re-rank\" setup from three perspectives: (i) assessing RLT methods in the context of LLM-based re-ranking with lexical first-stage retrieval, (ii) investigating the impact of different types of first-stage retrievers on RLT methods, and (iii) investigating the impact of different types of re-rankers on RLT methods. We perform experiments on the TREC 2019 and 2020 deep learning tracks, investigating 8 RLT methods for pipelines involving 3 retrievers and 2 re-rankers. We reach new insights into RLT methods in the context of re-ranking.",
    "pdf_link": "https://arxiv.org/abs/2404.18185",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.18185v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18185/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18185v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18185/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18185v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18185/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18185v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18185/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18185v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18185/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18185v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18185/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18185v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18185/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18185v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18185/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18185v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18185/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18185v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18185/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18185v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18185/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18185v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18185/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18185v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18185/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18185v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18185/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18185v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18185/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18185v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18185/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18185v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18185/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18185v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18185/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18185v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18185/x19.png"
      }
    ],
    "abstract_cn": "本研究以“先检索再重新排序”的新视角探讨了排名列表截断（RLT）问题，通过裁剪检索结果列表来优化重新排序过程。RLT 在提升重新排序的效率和效果方面发挥着关键作用，但目前对这一新视角下RLT方法的研究尚不充分。为填补这一研究空白，我们特别针对基于大型语言模型（LLM）的重新排序，复现并测试了现有的RLT方法。我们从三个维度深入探讨了RLT在“先检索再重新排序”框架下的适用性：（i）评估基于LLM重新排序和词汇检索的第一阶段RLT方法，（ii）分析不同类型第一阶段检索器对RLT方法的影响，（iii）探究不同类型重新排序器对RLT方法的影响。我们在TREC 2019和2020深度学习赛道上进行了实验，对涉及3种检索器和2种重新排序器的8种RLT方法进行了测试，从而获得了关于重新排序背景下RLT方法的新洞见。",
    "title_cn": "为大型语言模型的重新排序引入列表截断技术",
    "tags": [
      "LLM应用",
      "信息检索",
      ""
    ]
  },
  {
    "title": "Generative AI for Visualization: State of the Art and Future Directions",
    "submit_datetime": "2024年04月28日",
    "abstract": "Generative AI (GenAI) has witnessed remarkable progress in recent years and demonstrated impressive performance in various generation tasks in different domains such as computer vision and computational design. Many researchers have attempted to integrate GenAI into visualization framework, leveraging the superior generative capacity for different operations. Concurrently, recent major breakthroughs in GenAI like diffusion model and large language model have also drastically increase the potential of GenAI4VIS. From a technical perspective, this paper looks back on previous visualization studies leveraging GenAI and discusses the challenges and opportunities for future research. Specifically, we cover the applications of different types of GenAI methods including sequence, tabular, spatial and graph generation techniques for different tasks of visualization which we summarize into four major stages: data enhancement, visual mapping generation, stylization and interaction. For each specific visualization sub-task, we illustrate the typical data and concrete GenAI algorithms, aiming to provide in-depth understanding of the state-of-the-art GenAI4VIS techniques and their limitations. Furthermore, based on the survey, we discuss three major aspects of challenges and research opportunities including evaluation, dataset, and the gap between end-to-end GenAI and generative algorithms. By summarizing different generation algorithms, their current applications and limitations, this paper endeavors to provide useful insights for future GenAI4VIS research.",
    "pdf_link": "https://arxiv.org/abs/2404.18144",
    "graphs": [],
    "abstract_cn": "近年来，生成性人工智能（GenAI）在多个领域取得了突破性进展，尤其在计算机视觉和计算设计等领域的生成任务中表现卓越。研究人员正尝试将 GenAI 融入可视化框架，以发挥其强大的生成能力。随着扩散模型和大型语言模型等 GenAI 领域的重大进展，GenAI 在可视化（GenAI4VIS）的潜力得到了极大提升。本文从技术角度回顾了 GenAI 在可视化研究中的应用，并探讨了未来研究面临的挑战与机遇。文章详细讨论了序列、表格、空间和图形等不同 GenAI 方法在数据增强、视觉映射生成、风格化和交互等可视化任务中的应用，并总结了这些方法的典型数据和具体算法，以期深入理解 GenAI4VIS 技术的前沿及其限制。此外，文章还基于调研，探讨了评估、数据集和端到端 GenAI 与生成算法之间差异等三个主要挑战和研究方向。通过梳理各种生成算法及其应用现状和局限，本文旨在为 GenAI4VIS 的未来发展提供有益的洞见。",
    "title_cn": "探索可视化领域的生成式人工智能：技术前沿与未来趋势",
    "tags": [
      "LLM应用",
      "计算机视觉",
      "计算设计"
    ]
  },
  {
    "title": "Logic Agent: Enhancing Validity with Logic Rule Invocation",
    "submit_datetime": "2024年04月28日",
    "abstract": "Chain-of-Thought (CoT) prompting has emerged as a pivotal technique for augmenting the inferential capabilities of language models during reasoning tasks. Despite its advancements, CoT often grapples with challenges in validating reasoning validity and ensuring informativeness. Addressing these limitations, this paper introduces the Logic Agent (LA), an agent-based framework aimed at enhancing the validity of reasoning processes in Large Language Models (LLMs) through strategic logic rule invocation. Unlike conventional approaches, LA transforms LLMs into logic agents that dynamically apply propositional logic rules, initiating the reasoning process by converting natural language inputs into structured logic forms. The logic agent leverages a comprehensive set of predefined functions to systematically navigate the reasoning process. This methodology not only promotes the structured and coherent generation of reasoning constructs but also significantly improves their interpretability and logical coherence. Through extensive experimentation, we demonstrate LA's capacity to scale effectively across various model sizes, markedly improving the precision of complex reasoning across diverse tasks.",
    "pdf_link": "https://arxiv.org/abs/2404.18130",
    "graphs": [],
    "abstract_cn": "链式思考（CoT）提示技术在提升语言模型在推理任务中的推理能力方面发挥了重要作用。然而，它在确认推理的准确性和信息丰富性方面仍面临挑战。为克服这些难题，本研究提出了逻辑代理（LA），这是一个基于代理的框架，通过策略性地应用逻辑规则，旨在提高大型语言模型（LLMs）推理过程的有效性。与传统方法不同，LA 将 LLMs 转换为能够动态应用命题逻辑规则的逻辑代理，通过将自然语言输入转换为结构化逻辑形式来启动推理过程。该逻辑代理使用一系列预定义的函数系统地导航推理过程，不仅促进了推理结构的有序和连贯生成，还显著提升了其可解释性和逻辑一致性。通过广泛的实验，我们展示了 LA 在不同模型尺寸上的扩展能力，并在多样化任务中显著提高了复杂推理的精确度。",
    "title_cn": "逻辑代理：借助逻辑规则的调用提升有效性",
    "tags": [
      "Agent",
      "人工智能",
      "逻辑推理"
    ]
  },
  {
    "title": "Semi-supervised Text-based Person Search",
    "submit_datetime": "2024年04月28日",
    "abstract": "Text-based person search (TBPS) aims to retrieve images of a specific person from a large image gallery based on a natural language description. Existing methods rely on massive annotated image-text data to achieve satisfactory performance in fully-supervised learning. It poses a significant challenge in practice, as acquiring person images from surveillance videos is relatively easy, while obtaining annotated texts is challenging. The paper undertakes a pioneering initiative to explore TBPS under the semi-supervised setting, where only a limited number of person images are annotated with textual descriptions while the majority of images lack annotations. We present a two-stage basic solution based on generation-then-retrieval for semi-supervised TBPS. The generation stage enriches annotated data by applying an image captioning model to generate pseudo-texts for unannotated images. Later, the retrieval stage performs fully-supervised retrieval learning using the augmented data. Significantly, considering the noise interference of the pseudo-texts on retrieval learning, we propose a noise-robust retrieval framework that enhances the ability of the retrieval model to handle noisy data. The framework integrates two key strategies: Hybrid Patch-Channel Masking (PC-Mask) to refine the model architecture, and Noise-Guided Progressive Training (NP-Train) to enhance the training process. PC-Mask performs masking on the input data at both the patch-level and the channel-level to prevent overfitting noisy supervision. NP-Train introduces a progressive training schedule based on the noise level of pseudo-texts to facilitate noise-robust learning. Extensive experiments on multiple TBPS benchmarks show that the proposed framework achieves promising performance under the semi-supervised setting.",
    "pdf_link": "https://arxiv.org/abs/2404.18106",
    "graphs": [],
    "abstract_cn": "基于文本的人物搜索（TBPS）的目的是通过自然语言描述，从海量的图像库中找出特定人物的图片。目前的方法大多依赖于大规模的标注图像-文本数据集，在完全监督的环境下达到较好的效果。然而，这在实际操作中面临巨大挑战，因为从监控视频中获取人物图像较为简单，但获取相应的标注文本却相当困难。本研究首次尝试在半监督的环境下探索TBPS问题，即只有少数人物图像附有文本描述，而大多数图像并未标注。我们提出了一个分两步的解决方案：首先利用图像描述模型为未标注图像生成伪文本，以此扩充标注数据；然后在扩充后的数据基础上，执行全监督的检索学习。特别地，为了应对伪文本带来的噪声干扰，我们设计了一个抗噪声检索框架，该框架通过混合Patch-Channel掩码（PC-Mask）技术和噪声引导的渐进式训练（NP-Train）策略，提升了模型处理噪声数据的能力。PC-Mask技术在输入数据的patch层和channel层进行掩码操作，防止对噪声标签的过拟合。NP-Train则根据伪文本的噪声水平，采用渐进式训练计划，以实现鲁棒学习。在多个TBPS基准测试中的广泛实验结果表明，我们提出的框架在半监督环境下展现出了优异的性能。",
    "title_cn": "半监督文本人物搜索",
    "tags": [
      "分类：Agent",
      "计算机视觉",
      "半监督学习"
    ]
  },
  {
    "title": "CRE-LLM: A Domain-Specific Chinese Relation Extraction Framework with Fine-tuned Large Language Model",
    "submit_datetime": "2024年04月28日",
    "abstract": "Domain-Specific Chinese Relation Extraction (DSCRE) aims to extract relations between entities from domain-specific Chinese text. Despite the rapid development of PLMs in recent years, especially LLMs, DSCRE still faces three core challenges: complex network structure design, poor awareness, and high consumption of fine-tuning. Given the impressive performance of large language models (LLMs) in natural language processing, we propose a new framework called CRE-LLM. This framework is based on fine-tuning open-source LLMs, such as Llama-2, ChatGLM2, and Baichuan2. CRE-LLM enhances the logic-awareness and generative capabilities of the model by constructing an appropriate prompt and utilizing open-source LLMs for instruction-supervised fine-tuning. And then it directly extracts the relations of the given entities in the input textual data, which improving the CRE approach. To demonstrate the effectiveness of the proposed framework, we conducted extensive experiments on two domain-specific CRE datasets, FinRE and SanWen. The experimental results show that CRE-LLM is significantly superior and robust, achieving state-of-the-art (SOTA) performance on the FinRE dataset. This paper introduces a novel approach to domain-specific relation extraction (DSCRE) tasks that are semantically more complex by combining LLMs with triples. Our code is publicly available.",
    "pdf_link": "https://arxiv.org/abs/2404.18085",
    "graphs": [],
    "abstract_cn": "领域定制的中文关系抽取（DSCRE）致力于从专业中文文本中提取实体间的关系。尽管预训练语言模型（PLMs）尤其是大型语言模型（LLMs）技术近年来突飞猛进，DSCRE在网络结构设计、意识提升和微调成本上仍面临重大挑战。鉴于LLMs在自然语言处理领域的卓越成就，我们设计了一种创新框架CRE-LLM。该框架依托于对开源LLMs如Llama-2、ChatGLM2和Baichuan2进行微调，通过精心构建的提示和指令驱动的微调，显著提升了模型的逻辑理解和生成能力。CRE-LLM能够直接从文本数据中抽取实体间的关系，优化了传统的关系抽取方法。为了验证框架的效能，我们在两个专业的CRE数据集FinRE和SanWen上进行了深入的实验。实验结果显示，CRE-LLM在性能上大幅领先，尤其在FinRE数据集上达到了行业领先水平。本文提出了一种创新的DSCRE任务处理方法，通过结合LLMs与三元组来处理更为复杂的语义关系。我们的相关代码已对公众开放。",
    "title_cn": "CRE-LLM：一个针对特定领域的中文关系抽取框架，融合了经过精细调整的大型语言模型。",
    "tags": [
      "LLM应用",
      "中文关系抽取",
      ""
    ]
  },
  {
    "title": "Generative AI for Low-Carbon Artificial Intelligence of Things",
    "submit_datetime": "2024年04月28日",
    "abstract": "By integrating Artificial Intelligence (AI) with the Internet of Things (IoT), Artificial Intelligence of Things (AIoT) has revolutionized many fields. However, AIoT is facing the challenges of energy consumption and carbon emissions due to the continuous advancement of mobile technology. Fortunately, Generative AI (GAI) holds immense potential to reduce carbon emissions of AIoT due to its excellent reasoning and generation capabilities. In this article, we explore the potential of GAI for carbon emissions reduction and propose a novel GAI-enabled solution for low-carbon AIoT. Specifically, we first study the main impacts that cause carbon emissions in AIoT, and then introduce GAI techniques and their relations to carbon emissions. We then explore the application prospects of GAI in low-carbon AIoT, focusing on how GAI can reduce carbon emissions of network components. Subsequently, we propose a Large Language Model (LLM)-enabled carbon emission optimization framework, in which we design pluggable LLM and Retrieval Augmented Generation (RAG) modules to generate more accurate and reliable optimization problems. Furthermore, we utilize Generative Diffusion Models (GDMs) to identify optimal strategies for carbon emission reduction. Simulation results demonstrate the effectiveness of the proposed framework. Finally, we insightfully provide open research directions for low-carbon AIoT.",
    "pdf_link": "https://arxiv.org/abs/2404.18077",
    "graphs": [],
    "abstract_cn": "融合人工智能（AI）与物联网（IoT），人工智能物联网（AIoT）正引领多领域的变革。尽管如此，随着移动技术的发展，AIoT在能耗和碳排放方面面临挑战。但可喜的是，生成性AI（GAI）凭借其卓越的推理与生成能力，展现出降低AIoT碳足迹的巨大潜力。本文将探讨GAI在减少碳排放方面的巨大潜力，并提出一种创新的GAI驱动的低碳AIoT解决方案。我们首先分析了AIoT中碳排放的主要成因，接着介绍了GAI技术及其与碳排放的联系。然后，我们着眼于GAI在构建低碳AIoT中的应用前景，尤其是其在降低网络组件碳排放方面的潜力。我们进一步提出了一个由大型语言模型（LLM）支持的碳排放优化框架，设计了可插拔的LLM和检索增强生成（RAG）模块，以更精确、可靠地生成优化问题。我们还采用了生成扩散模型（GDM）来寻找减少碳排放的最优策略。模拟结果验证了该框架的有效性。文末，我们前瞻性地为低碳AIoT的发展指明了研究方向。",
    "title_cn": "低碳物联网领域的生成型人工智能应用",
    "tags": [
      "LLM应用",
      "物联网",
      "人工智能"
    ]
  },
  {
    "title": "Using Deep Q-Learning to Dynamically Toggle between Push/Pull Actions in Computational Trust Mechanisms",
    "submit_datetime": "2024年04月28日",
    "abstract": "Recent work on decentralized computational trust models for open Multi Agent Systems has resulted in the development of CA, a biologically inspired model which focuses on the trustee's perspective. This new model addresses a serious unresolved problem in existing trust and reputation models, namely the inability to handle constantly changing behaviors and agents' continuous entry and exit from the system. In previous work, we compared CA to FIRE, a well-known trust and reputation model, and found that CA is superior when the trustor population changes, whereas FIRE is more resilient to the trustee population changes. Thus, in this paper, we investigate how the trustors can detect the presence of several dynamic factors in their environment and then decide which trust model to employ in order to maximize utility. We frame this problem as a machine learning problem in a partially observable environment, where the presence of several dynamic factors is not known to the trustor and we describe how an adaptable trustor can rely on a few measurable features so as to assess the current state of the environment and then use Deep Q Learning (DQN), in a single-agent Reinforcement Learning setting, to learn how to adapt to a changing environment. We ran a series of simulation experiments to compare the performance of the adaptable trustor with the performance of trustors using only one model (FIRE or CA) and we show that an adaptable agent is indeed capable of learning when to use each model and, thus, perform consistently in dynamic environments.",
    "pdf_link": "https://arxiv.org/abs/2404.18296",
    "graphs": [],
    "abstract_cn": "近期研究在开放多智能体系统的去中心化计算信任模型方面取得了进展，特别是开发了一种名为 CA 的生物启发模型，该模型从受托人的角度出发。这一新模型针对现有信任和声誉模型中的一个难题——如何处理智能体行为的不断变化以及智能体进出系统的连续性——提供了解决方案。在先前的研究中，我们对比了 CA 与另一个著名的信任和声誉模型 FIRE，并发现在信任者群体变动时，CA 的性能更佳，而 FIRE 在受托者群体变动时更具韧性。本论文进一步探讨了信任者如何识别环境中的多个动态因素，并据此选择最合适的信任模型以优化效用。我们将这一问题设定为部分可观测环境中的机器学习挑战，信任者无法预知多个动态因素的存在。文章描述了信任者如何利用一些可测量的特征来评估环境现状，并采用深度 Q 学习（DQN）在单智能体强化学习框架下学习如何适应环境变化。通过一系列模拟实验，我们比较了适应性信任者与仅使用单一模型（FIRE 或 CA）的信任者的性能，结果表明适应性智能体确实能够学习何时应用每种模型，从而在动态环境中实现稳定的表现。",
    "title_cn": "本文探讨了如何利用深度Q-学习技术，在计算信任机制中实现推/拉动作的动态切换。",
    "tags": [
      "Agent",
      "多智能体系统",
      "机器学习"
    ]
  },
  {
    "title": "ATR-Mapping: Asymmetric Topological Representation based Mapping Framework for Multi-Robot Environment Exploration",
    "submit_datetime": "2024年04月28日",
    "abstract": "In recent years, the widespread application of multi-robot systems in areas such as power inspection, autonomous vehicle fleets has made multi-robot technology a research hotspot in the field of robotics. This paper investigates multi-robot cooperative exploration in unknown environments, proposing a training framework and decision strategy based on multi-agent reinforcement learning. Specifically we propose a Asymmetric Topological Representation based mapping framework (ATR-Mapping), combining the advantages of methods based on raw grid maps and methods based on topology, the structural information from the raw grid maps is extracted and combined with a topological graph constructed based on geometric distance information for decision-making. Leveraging this topological graph representation, we employs a decision network based on topological graph matching to assign corresponding boundary points to each robot as long-term target points for decision-making. We conducts testing and application of the proposed algorithms in real world scenarios using the Gazebo and Gibson simulation environments. It validates that the proposed method, when compared to existing methods, achieves a certain degree of performance improvement.",
    "pdf_link": "https://arxiv.org/abs/2404.18089",
    "graphs": [],
    "abstract_cn": "近期，多机器人系统在电力巡查、自动驾驶车队等众多领域的广泛应用，让其成为机器人学界的研究焦点。本研究着眼于多机器人在未知环境中的协作探索问题，提出了一种基于多智能体强化学习的训练框架与决策策略。我们创新性地设计了一种非对称拓扑表示映射框架（ATR-Mapping），它融合了原始网格图方法与拓扑方法的优势，通过从原始网格图中抽取结构信息，并结合基于几何距离构建的拓扑图，以辅助决策制定。依托这一拓扑图表示，我们构建了一个基于拓扑图匹配的决策网络，为每个机器人指定了边界点作为长期决策目标。通过在 Gazebo 和 Gibson 仿真环境中对现实世界场景的测试与应用，证实了我们的方法相较于现有技术在性能上实现了显著提升。",
    "title_cn": "ATR-Mapping：一种创新的非对称拓扑表示映射框架，专为多机器人环境探索而设计。",
    "tags": [
      "Agent",
      "机器人学",
      "自动驾驶"
    ]
  },
  {
    "title": "ComposerX: Multi-Agent Symbolic Music Composition with LLMs",
    "submit_datetime": "2024年04月28日",
    "abstract": "Music composition represents the creative side of humanity, and itself is a complex task that requires abilities to understand and generate information with long dependency and harmony constraints. While demonstrating impressive capabilities in STEM subjects, current LLMs easily fail in this task, generating ill-written music even when equipped with modern techniques like In-Context-Learning and Chain-of-Thoughts. To further explore and enhance LLMs' potential in music composition by leveraging their reasoning ability and the large knowledge base in music history and theory, we propose ComposerX, an agent-based symbolic music generation framework. We find that applying a multi-agent approach significantly improves the music composition quality of GPT-4. The results demonstrate that ComposerX is capable of producing coherent polyphonic music compositions with captivating melodies, while adhering to user instructions.",
    "pdf_link": "https://arxiv.org/abs/2404.18081",
    "graphs": [],
    "abstract_cn": "音乐创作展现了人类的创造天赋，它是一项需要深刻理解和创作长期依赖与和谐限制信息的复杂任务。尽管在科学、技术、工程和数学（STEM）领域取得了显著成就，但现有的大型语言模型（LLMs）在音乐创作上仍易遭遇挫折，即便借助了如上下文学习（In-Context-Learning）和思维链（Chain-of-Thoughts）等先进技术，也难以创作出流畅悦耳的音乐。为了深入挖掘并提升LLMs在音乐创作上的潜力，同时发挥其推理能力和丰富的音乐历史与理论知识，我们设计了ComposerX——一个基于代理的符号化音乐生成框架。实践证明，采用多代理策略显著提升了GPT-4的音乐创作水准。ComposerX不仅能够创作出旋律优美、和声丰富的复调音乐作品，还能准确遵循用户的创作指导。",
    "title_cn": "ComposerX：借助大型语言模型（LLMs），实现多代理参与的符号化音乐创作。",
    "tags": [
      "Agent",
      "",
      "人工智能"
    ]
  },
  {
    "title": "MMAC-Copilot: Multi-modal Agent Collaboration Operating System Copilot",
    "submit_datetime": "2024年04月28日",
    "abstract": "Autonomous virtual agents are often limited by their singular mode of interaction with real-world environments, restricting their versatility. To address this, we propose the Multi-Modal Agent Collaboration framework (MMAC-Copilot), a framework utilizes the collective expertise of diverse agents to enhance interaction ability with operating systems. The framework introduces a team collaboration chain, enabling each participating agent to contribute insights based on their specific domain knowledge, effectively reducing the hallucination associated with knowledge domain gaps. To evaluate the performance of MMAC-Copilot, we conducted experiments using both the GAIA benchmark and our newly introduced Visual Interaction Benchmark (VIBench). VIBench focuses on non-API-interactable applications across various domains, including 3D gaming, recreation, and office scenarios. MMAC-Copilot achieved exceptional performance on GAIA, with an average improvement of 6.8\\% over existing leading systems. Furthermore, it demonstrated remarkable capability on VIBench, particularly in managing various methods of interaction within systems and applications. These results underscore MMAC-Copilot's potential in advancing the field of autonomous virtual agents through its innovative approach to agent collaboration.",
    "pdf_link": "https://arxiv.org/abs/2404.18074",
    "graphs": [],
    "abstract_cn": "自主虚拟代理的多才多艺往往受限于它们与现实世界单一的交互模式。为突破这一局限，我们设计了多模态代理协作框架MMAC-Copilot，该框架汇聚了多样化代理的集体智慧，以提升与操作系统的交互效能。框架通过团队协作链路，让每位代理都能依据其领域专长提供洞见，有效降低了知识盲区所带来的误判。我们通过GAIA基准测试和新推出的可视化交互基准测试VIBench对MMAC-Copilot进行了性能评估。VIBench专注于非API交互式应用，覆盖3D游戏、娱乐和办公等多个领域。MMAC-Copilot在GAIA基准测试中表现卓越，相比现有顶尖系统平均提升了6.8%的效能。在VIBench测试中，它在处理系统和应用内多样化交互方式方面展现了非凡能力。这些成果凸显了MMAC-Copilot在推动自主虚拟代理领域发展上的潜力，其创新的协作机制功不可没。",
    "title_cn": "MMAC-Copilot：协同操作系统的多模态代理合作伴侣",
    "tags": [
      "Agent",
      "虚拟代理",
      "操作系统"
    ]
  },
  {
    "title": "Multi-Agent Reinforcement Learning for Energy Networks: Computational Challenges, Progress and Open Problems",
    "submit_datetime": "2024年04月28日",
    "abstract": "The rapidly changing architecture and functionality of electrical networks and the increasing penetration of renewable and distributed energy resources have resulted in various technological and managerial challenges. These have rendered traditional centralized energy-market paradigms insufficient due to their inability to support the dynamic and evolving nature of the network. This survey explores how multi-agent reinforcement learning (MARL) can support the decentralization and decarbonization of energy networks and mitigate the associated challenges. This is achieved by specifying key computational challenges in managing energy networks, reviewing recent research progress on addressing them, and highlighting open challenges that may be addressed using MARL.",
    "pdf_link": "https://arxiv.org/abs/2404.15583",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.15583v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15583/x1.png"
      }
    ],
    "abstract_cn": "随着电气网络架构和功能的快速演变，以及可再生与分布式能源资源的日益普及，我们面临着众多技术和管理挑战。这些挑战使得传统的集中式能源市场模式不再适用，因其无法适应网络的动态性和不断演变的需求。本篇综述文章深入探讨了多智能体强化学习（MARL）如何助力能源网络实现去中心化和低碳化，同时应对这些挑战。文章通过明确管理能源网络时面临的主要计算难题，回顾了近期在解决这些问题上的研究进展，并指出了未来可能通过MARL来解决的开放性问题。",
    "title_cn": "多智能体强化学习在能源网络领域的应用面临诸多计算挑战，尽管已有进展，但仍存在一些未解决的问题。",
    "tags": [
      "Agent",
      "能源管理",
      ""
    ]
  },
  {
    "title": "Learnable Linguistic Watermarks for Tracing Model Extraction Attacks on Large Language Models",
    "submit_datetime": "2024年04月28日",
    "abstract": "In the rapidly evolving domain of artificial intelligence, safeguarding the intellectual property of Large Language Models (LLMs) is increasingly crucial. Current watermarking techniques against model extraction attacks, which rely on signal insertion in model logits or post-processing of generated text, remain largely heuristic. We propose a novel method for embedding learnable linguistic watermarks in LLMs, aimed at tracing and preventing model extraction attacks. Our approach subtly modifies the LLM's output distribution by introducing controlled noise into token frequency distributions, embedding an statistically identifiable controllable watermark.We leverage statistical hypothesis testing and information theory, particularly focusing on Kullback-Leibler Divergence, to differentiate between original and modified distributions effectively. Our watermarking method strikes a delicate well balance between robustness and output quality, maintaining low false positive/negative rates and preserving the LLM's original performance.",
    "pdf_link": "https://arxiv.org/abs/2405.01509",
    "graphs": [],
    "abstract_cn": "随着人工智能领域的迅猛发展，确保大型语言模型（LLMs）的知识产权安全变得至关重要。目前，面对模型抽取攻击，主流的水印技术主要采用在模型逻辑输出中嵌入信号或对文本进行后期处理，这些手段大多基于经验。我们提出了一种创新的方法，通过在LLMs中嵌入可学习的语言学水印，用以追踪和防范模型抽取攻击。该方法通过在标记频率分布中引入控制性噪声，巧妙地调整了LLM的输出分布，嵌入了一种统计上可识别的水印。我们采用了统计假设检验和信息论的工具，特别是Kullback-Leibler散度，以高效区分原始与修改后的分布。我们的水印技术在保护模型安全的同时，保持了输出质量，实现了低误报率和误漏率，确保了LLM原始性能的稳定。",
    "title_cn": "为大型语言模型量身定制的可学习语言水印技术，旨在有效追踪并防范模型提取攻击。",
    "tags": [
      "LLM应用",
      "人工智能安全",
      "知识产权保护"
    ]
  },
  {
    "title": "Efficient LLM Inference with Kcache",
    "submit_datetime": "2024年04月27日",
    "abstract": "Large Language Models(LLMs) have had a profound impact on AI applications, particularly in the domains of long-text comprehension and generation. KV Cache technology is one of the most widely used techniques in the industry. It ensures efficient sequence generation by caching previously computed KV states. However, it also introduces significant memory overhead. We discovered that KV Cache is not necessary and proposed a novel KCache technique to alleviate the memory bottleneck issue during the LLMs inference process. KCache can be used directly for inference without any training process, Our evaluations show that KCache improves the throughput of popular LLMs by 40% with the baseline, while keeping accuracy.",
    "pdf_link": "https://arxiv.org/abs/2404.18057",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）极大地推动了人工智能应用的发展，尤其是在长文本的理解和生成方面。KV缓存技术因其高效生成序列的能力而在业界广受青睐，但它也带来了较大的内存开销。我们发现，KV缓存并非不可或缺，并创新性地提出了KCache技术，以解决LLMs在推理过程中的内存瓶颈。KCache无需训练即可直接用于推理，我们的测试结果表明，它能够将主流LLMs的吞吐量提升40%，同时保持了准确性。",
    "title_cn": "Kcache 助力大型语言模型推理，实现高效能。",
    "tags": [
      "分类：LLM应用",
      "人工智能",
      "内存优化"
    ]
  },
  {
    "title": "Utilizing Large Language Models for Information Extraction from Real Estate Transactions",
    "submit_datetime": "2024年04月27日",
    "abstract": "Real estate sales contracts contain crucial information for property transactions, but manual extraction of data can be time-consuming and error-prone. This paper explores the application of large language models, specifically transformer-based architectures, for automated information extraction from real estate contracts. We discuss challenges, techniques, and future directions in leveraging these models to improve efficiency and accuracy in real estate contract analysis.",
    "pdf_link": "https://arxiv.org/abs/2404.18043",
    "graphs": [],
    "abstract_cn": "房地产销售合同中蕴含着交易的核心信息，然而手动抽取这些信息不仅费时还易出错。本研究探讨了运用大型语言模型，尤其是基于变换器架构的模型，来自动化地从房地产合同中提取信息。文中还讨论了在利用这些模型提升房地产合同分析的效率与精确度方面所面临的挑战、采用的技术手段以及未来的发展方向。",
    "title_cn": "运用大型语言模型，深入挖掘房地产交易中的信息。",
    "tags": [
      "LLM应用",
      "房地产",
      "自动化信息提取"
    ]
  },
  {
    "title": "CRISPR-GPT: An LLM Agent for Automated Design of Gene-Editing Experiments",
    "submit_datetime": "2024年04月27日",
    "abstract": "The introduction of genome engineering technology has transformed biomedical research, making it possible to make precise changes to genetic information. However, creating an efficient gene-editing system requires a deep understanding of CRISPR technology, and the complex experimental systems under investigation. While Large Language Models (LLMs) have shown promise in various tasks, they often lack specific knowledge and struggle to accurately solve biological design problems. In this work, we introduce CRISPR-GPT, an LLM agent augmented with domain knowledge and external tools to automate and enhance the design process of CRISPR-based gene-editing experiments. CRISPR-GPT leverages the reasoning ability of LLMs to facilitate the process of selecting CRISPR systems, designing guide RNAs, recommending cellular delivery methods, drafting protocols, and designing validation experiments to confirm editing outcomes. We showcase the potential of CRISPR-GPT for assisting non-expert researchers with gene-editing experiments from scratch and validate the agent's effectiveness in a real-world use case. Furthermore, we explore the ethical and regulatory considerations associated with automated gene-editing design, highlighting the need for responsible and transparent use of these tools. Our work aims to bridge the gap between beginner biological researchers and CRISPR genome engineering techniques, and demonstrate the potential of LLM agents in facilitating complex biological discovery tasks.",
    "pdf_link": "https://arxiv.org/abs/2404.18021",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.18021v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18021/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18021v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18021/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18021v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18021/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18021v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18021/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18021v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18021/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18021v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18021/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18021v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18021/x7.png"
      }
    ],
    "abstract_cn": "基因组工程的革新为生物医学领域带来了翻天覆地的变化，使得对DNA进行精准编辑变得触手可及。但是，开发高效的基因编辑平台离不开对CRISPR技术的深刻洞察以及对实验体系的全面掌握。尽管大型语言模型（LLMs）在多领域展现出巨大潜力，它们在解决生物学设计问题时往往因缺乏专业知识而力不从心。本研究提出了CRISPR-GPT，这是一个融合了专业知识和外部工具的LLM智能体，旨在自动化并优化基于CRISPR的基因编辑实验设计流程。CRISPR-GPT发挥了LLMs的推理优势，简化了挑选CRISPR系统、构建导向RNA、选择细胞传递策略、制定实验方案以及规划验证实验等步骤。我们证明了CRISPR-GPT在辅助科研新手开展基因编辑实验方面的潜力，并在一个实际应用案例中检验了其效能。同时，我们也深入探讨了自动化基因编辑设计所引发的伦理和法规问题，强调了审慎和透明使用这些技术的重要性。我们的目标是连接生物学研究新手与CRISPR基因组工程技术的桥梁，并展现LLM智能体在推动复杂生物探索任务中的巨大潜力。",
    "title_cn": "CRISPR-GPT：自动化基因编辑实验设计的智能大型语言模型代理。",
    "tags": [
      "Agent",
      "生物医学",
      "基因编辑"
    ]
  },
  {
    "title": "LLMParser: An Exploratory Study on Using Large Language Models for Log Parsing",
    "submit_datetime": "2024年04月27日",
    "abstract": "Logs are important in modern software development with runtime information. Log parsing is the first step in many log-based analyses, that involve extracting structured information from unstructured log data. Traditional log parsers face challenges in accurately parsing logs due to the diversity of log formats, which directly impacts the performance of downstream log-analysis tasks. In this paper, we explore the potential of using Large Language Models (LLMs) for log parsing and propose LLMParser, an LLM-based log parser based on generative LLMs and few-shot tuning. We leverage four LLMs, Flan-T5-small, Flan-T5-base, LLaMA-7B, and ChatGLM-6B in LLMParsers. Our evaluation of 16 open-source systems shows that LLMParser achieves statistically significantly higher parsing accuracy than state-of-the-art parsers (a 96% average parsing accuracy). We further conduct a comprehensive empirical analysis on the effect of training size, model size, and pre-training LLM on log parsing accuracy. We find that smaller LLMs may be more effective than more complex LLMs; for instance where Flan-T5-base achieves comparable results as LLaMA-7B with a shorter inference time. We also find that using LLMs pre-trained using logs from other systems does not always improve parsing accuracy. While using pre-trained Flan-T5-base shows an improvement in accuracy, pre-trained LLaMA results in a decrease (decrease by almost 55% in group accuracy). In short, our study provides empirical evidence for using LLMs for log parsing and highlights the limitations and future research direction of LLM-based log parsers.",
    "pdf_link": "https://arxiv.org/abs/2404.18001",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.18001v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18001/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18001v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18001/x2.png"
      }
    ],
    "abstract_cn": "在现代软件开发中，日志作为运行时信息的载体扮演着关键角色。日志解析，即从非结构化日志数据中提取结构化信息，是许多基于日志分析的首要步骤。传统解析工具在处理多样化的日志格式时面临挑战，这直接关系到下游日志分析任务的效率。本文探讨了利用大型语言模型（LLMs）进行日志解析的可能性，并提出了LLMParser，这是一款基于生成性LLMs和少量样本微调的日志解析工具。我们采用了四种LLMs——Flan-T5-small、Flan-T5-base、LLaMA-7B和ChatGLM-6B——来构建LLMParser。通过对16个开源系统的评估，我们发现LLMParser在解析精度上显著超越了现有技术（平均解析精度达到96%）。此外，我们还深入分析了训练规模、模型大小和预训练LLM对日志解析精度的影响。研究发现，较小型的LLMs在某些情况下可能比更复杂的模型更为高效，如Flan-T5-base在较短的推理时间内就能达到与LLaMA-7B相似的结果。我们还观察到，使用其他系统日志预训练的LLMs并不总能提升解析精度。例如，尽管预训练的Flan-T5-base能够提高精度，但预训练的LLaMA却可能导致精度下降（组精度下降近55%）。总结来说，本研究为利用LLMs进行日志解析提供了实证基础，并指出了基于LLM的日志解析工具的局限性及未来研究的方向。",
    "title_cn": "LLMParser：探索性研究——利用大型语言模型进行日志解析。",
    "tags": [
      "LLM应用",
      "软件开发",
      "日志分析"
    ]
  },
  {
    "title": "MediFact at MEDIQA-CORR 2024: Why AI Needs a Human Touch",
    "submit_datetime": "2024年04月27日",
    "abstract": "Accurate representation of medical information is crucial for patient safety, yet artificial intelligence (AI) systems, such as Large Language Models (LLMs), encounter challenges in error-free clinical text interpretation. This paper presents a novel approach submitted to the MEDIQA-CORR 2024 shared task (Ben Abacha et al., 2024a), focusing on the automatic correction of single-word errors in clinical notes. Unlike LLMs that rely on extensive generic data, our method emphasizes extracting contextually relevant information from available clinical text data. Leveraging an ensemble of extractive and abstractive question-answering approaches, we construct a supervised learning framework with domain-specific feature engineering. Our methodology incorporates domain expertise to enhance error correction accuracy. By integrating domain expertise and prioritizing meaningful information extraction, our approach underscores the significance of a human-centric strategy in adapting AI for healthcare.",
    "pdf_link": "https://arxiv.org/abs/2404.17999",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.17999v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17999/Correct.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17999v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17999/error.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17999v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17999/corr1stepp.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17999v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17999/corr2stepp.png"
      }
    ],
    "abstract_cn": "确保医学信息的精确表达对保障患者安全极为关键。但是，人工智能（AI）系统，例如大型语言模型（LLMs），在准确解读临床文本时面临难题。本文介绍的是一种提交至2024年MEDIQA-CORR共同任务的创新方法（Ben Abacha等，2024a），该方法专注于自动修正临床记录中的单字错误。与依赖海量通用数据的LLMs不同，我们的方法侧重于从现有临床文本数据中抽取与上下文相关的信息。我们通过结合抽取式和生成式问答技术，构建了一个具有特定领域特征工程的监督学习框架。此外，我们的研究方法融合了领域专家知识，以提升错误修正的精确度。通过融合专家智慧并优先提取有价值的信息，我们的方法突出了在医疗保健领域应用AI时，采取以人为本策略的重要性。",
    "title_cn": "MediFact 在 2024 年 MEDIQA-CORR 竞赛中的表现：论人工智能为何离不开人类的温情触摸",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Enhancing Pre-Trained Generative Language Models with Question Attended Span Extraction on Machine Reading Comprehension",
    "submit_datetime": "2024年04月27日",
    "abstract": "Machine Reading Comprehension (MRC) poses a significant challenge in the field of Natural Language Processing (NLP). While mainstream MRC methods predominantly leverage extractive strategies using encoder-only models such as BERT, generative approaches face the issue of out-of-control generation -- a critical problem where answers generated are often incorrect, irrelevant, or unfaithful to the source text. To address these limitations in generative models for MRC, we introduce the Question-Attended Span Extraction (QASE) module. Integrated during the fine-tuning phase of pre-trained generative language models (PLMs), QASE significantly enhances their performance, allowing them to surpass the extractive capabilities of advanced Large Language Models (LLMs) such as GPT-4. Notably, these gains in performance do not come with an increase in computational demands. The efficacy of the QASE module has been rigorously tested across various datasets, consistently achieving or even surpassing state-of-the-art (SOTA) results.",
    "pdf_link": "https://arxiv.org/abs/2404.17991",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.17991v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17991/extractive_vs_generative.jpg"
      },
      {
        "url": "https://arxiv.org/html/2404.17991v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17991/QASE.jpg"
      },
      {
        "url": "https://arxiv.org/html/2404.17991v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17991/baseline.jpg"
      }
    ],
    "abstract_cn": "机器阅读理解（MRC）是自然语言处理（NLP）领域的一大难题。主流的 MRC 方法多采用如 BERT 这类仅编码器模型的提取式策略，而生成式方法则常遭遇生成失控的窘境——即生成的答案往往错误、无关或与原文不符。为克服 MRC 生成模型的局限，我们提出了问题关注跨度提取（QASE）模块。该模块在预训练的生成语言模型（PLMs）微调阶段整合，显著提升了模型性能，使其超越了如 GPT-4 等高级大型语言模型（LLMs）的提取性能。关键的是，性能的提升并未导致计算成本的增加。QASE 模块的效力已在多个数据集上经过严格验证，持续达到了或超越了当前最佳（SOTA）的成绩。",
    "title_cn": "通过引入问题导向的段落抽取技术，提升机器阅读理解任务中预训练生成语言模型的性能。",
    "tags": [
      "分类：LLM应用\n\n这篇论文主要讨论了机器阅读理解（MRC）领域的问题，并提出了一种新的模块——问题关注跨度提取（QASE）模块，以提高生成语言模型（PLMs）在MRC任务中的表现。这篇论文关注的是大型语言模型（LLMs）的应用，特别是在自然语言处理（NLP）领域，因此可以归类为LLM应用。",
      "",
      "机器阅读理解"
    ]
  },
  {
    "title": "Detection of Conspiracy Theories Beyond Keyword Bias in German-Language Telegram Using Large Language Models",
    "submit_datetime": "2024年04月27日",
    "abstract": "The automated detection of conspiracy theories online typically relies on supervised learning. However, creating respective training data requires expertise, time and mental resilience, given the often harmful content. Moreover, available datasets are predominantly in English and often keyword-based, introducing a token-level bias into the models. Our work addresses the task of detecting conspiracy theories in German Telegram messages. We compare the performance of supervised fine-tuning approaches using BERT-like models with prompt-based approaches using Llama2, GPT-3.5, and GPT-4 which require little or no additional training data. We use a dataset of $\\sim\\!\\! 4,000$ messages collected during the COVID-19 pandemic, without the use of keyword filters.\n  Our findings demonstrate that both approaches can be leveraged effectively: For supervised fine-tuning, we report an F1 score of $\\sim\\!\\! 0.8$ for the positive class, making our model comparable to recent models trained on keyword-focused English corpora. We demonstrate our model's adaptability to intra-domain temporal shifts, achieving F1 scores of $\\sim\\!\\! 0.7$. Among prompting variants, the best model is GPT-4, achieving an F1 score of $\\sim\\!\\! 0.8$ for the positive class in a zero-shot setting and equipped with a custom conspiracy theory definition.",
    "pdf_link": "https://arxiv.org/abs/2404.17985",
    "graphs": [],
    "abstract_cn": "网络中阴谋论的自动识别通常依赖监督学习方法。但制备相关训练集既需专业知识，又耗时劳心，特别是面对那些常含有害内容的数据。此外，目前的数据集多以英文为主，且多基于关键词，这可能导致模型在词符层面产生偏差。本研究旨在探索在德语 Telegram 消息中识别阴谋论的新方法。我们对比了基于 BERT 模型的监督微调与使用 Llama2、GPT-3.5 和 GPT-4 的提示法，后者几乎或完全不需要额外的训练数据。研究使用了 COVID-19 大流行期间收集的约 4,000 条消息组成的数据集，且未采用关键词过滤。研究发现，两种方法均显示出潜力：在监督微调方面，我们的模型在正类上达到了约 0.8 的 F1 分数，与近期基于英文关键词语料库训练的模型相媲美。我们还证明了模型能够适应领域内的时间变化，F1 分数约为 0.7。在提示法中，GPT-4 表现最佳，在零样本情况下正类 F1 分数达到约 0.8，并配备了自定义的阴谋论定义。",
    "title_cn": "利用大型语言模型，我们深入探讨了德语 Telegram 上的阴谋论，这一研究超越了传统的关键词搜索偏见，为我们提供了新的视角。",
    "tags": [
      "分类：LLM应用\n\n这篇论文主要探讨了在德语 Telegram 消息中识别阴谋论的新方法，使用了基于 BERT 模型的监督微调和使用 Llama2、GPT-3.5 和 GPT-4 的提示法。这些方法都涉及到了大型语言模型（LLM）的应用，因此将其归类为 LLM应用。",
      "社交媒体监控",
      ""
    ]
  },
  {
    "title": "TI-ASU: Toward Robust Automatic Speech Understanding through Text-to-speech Imputation Against Missing Speech Modality",
    "submit_datetime": "2024年04月27日",
    "abstract": "Automatic Speech Understanding (ASU) aims at human-like speech interpretation, providing nuanced intent, emotion, sentiment, and content understanding from speech and language (text) content conveyed in speech. Typically, training a robust ASU model relies heavily on acquiring large-scale, high-quality speech and associated transcriptions. However, it is often challenging to collect or use speech data for training ASU due to concerns such as privacy. To approach this setting of enabling ASU when speech (audio) modality is missing, we propose TI-ASU, using a pre-trained text-to-speech model to impute the missing speech. We report extensive experiments evaluating TI-ASU on various missing scales, both multi- and single-modality settings, and the use of LLMs. Our findings show that TI-ASU yields substantial benefits to improve ASU in scenarios where even up to 95% of training speech is missing. Moreover, we show that TI-ASU is adaptive to dropout training, improving model robustness in addressing missing speech during inference.",
    "pdf_link": "https://arxiv.org/abs/2404.17983",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.17983v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17983/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17983v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17983/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17983v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17983/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17983v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17983/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17983v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17983/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17983v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17983/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17983v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17983/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17983v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17983/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17983v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17983/x9.png"
      }
    ],
    "abstract_cn": "自动语音理解（ASU）致力于模拟人类的语音解析能力，能够从语音和文本内容中精准捕捉意图、情感、情绪和内容。尽管构建一个高效的 ASU 系统通常需要大量的高质量语音数据及其转录，但出于隐私保护的考虑，收集或利用这些数据往往面临诸多挑战。为此，我们提出了一种新颖的方法——TI-ASU，它利用预训练的文本到语音模型来弥补训练过程中缺失的语音信息。我们对 TI-ASU 在不同数据缺失比例、多模态与单模态环境以及大型语言模型（LLMs）中的应用进行了深入的实验测试。实验结果证明，TI-ASU 在训练语音数据缺失高达95%的情况下，仍能显著提升 ASU 的性能。此外，TI-ASU 还能适应于 dropout 训练，增强了模型在推理阶段处理缺失语音的鲁棒性。",
    "title_cn": "TI-ASU：通过文本到语音的转换技术，针对缺失的语音模式进行补偿，以提升自动语音理解的鲁棒性。",
    "tags": [
      "LLM应用",
      "语音识别",
      "自动语音理解"
    ]
  },
  {
    "title": "Advancing Healthcare Automation: Multi-Agent Systems for Medical Necessity Justification",
    "submit_datetime": "2024年04月27日",
    "abstract": "This paper explores the application of Swarm-Structured Multi-Agent Systems (MAS) to establish medical necessity, a process that involves a systematic review of patient-specific medical structured and unstructured data against clinical guidelines. We addressed this complex task by decomposing it into smaller, more manageable sub-tasks. Each sub-task is handled by a specialized AI agent. We conduct a systematic study of the impact of various prompting strategies on these agents and benchmark different Large Language Models (LLMs) to determine their accuracy in completing these tasks. Additionally, we investigate how these agents can provide explainability, thereby enhancing trust and transparency within the system.",
    "pdf_link": "https://arxiv.org/abs/2404.17977",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.17977v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17977/candidates.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17977v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17977/child.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17977v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17977/score.jpg"
      },
      {
        "url": "https://arxiv.org/html/2404.17977v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17977/time.jpg"
      }
    ],
    "abstract_cn": "本研究着眼于应用群体结构化多智能体系统（MAS）来评估医疗必要性，这一过程需要系统性地对照临床指南，审查患者的医疗结构化与非结构化数据。为应对这一挑战，我们将任务细化为易于操作的子任务，每个子任务由专责的AI智能体执行。我们对不同的提示策略对智能体的影响进行了系统性研究，并对比了多种大型语言模型（LLMs）的准确性。同时，我们也探讨了这些智能体如何增强系统的可解释性，以提升信任度和透明度。",
    "title_cn": "提升医疗自动化水平：多智能体系统在医疗需求论证中的应用。",
    "tags": [
      "分类：Agent",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Automating Customer Needs Analysis: A Comparative Study of Large Language Models in the Travel Industry",
    "submit_datetime": "2024年04月27日",
    "abstract": "In the rapidly evolving landscape of Natural Language Processing (NLP), Large Language Models (LLMs) have emerged as powerful tools for many tasks, such as extracting valuable insights from vast amounts of textual data. In this study, we conduct a comparative analysis of LLMs for the extraction of travel customer needs from TripAdvisor posts. Leveraging a diverse range of models, including both open-source and proprietary ones such as GPT-4 and Gemini, we aim to elucidate their strengths and weaknesses in this specialized domain. Through an evaluation process involving metrics such as BERTScore, ROUGE, and BLEU, we assess the performance of each model in accurately identifying and summarizing customer needs. Our findings highlight the efficacy of opensource LLMs, particularly Mistral 7B, in achieving comparable performance to larger closed models while offering affordability and customization benefits. Additionally, we underscore the importance of considering factors such as model size, resource requirements, and performance metrics when selecting the most suitable LLM for customer needs analysis tasks. Overall, this study contributes valuable insights for businesses seeking to leverage advanced NLP techniques to enhance customer experience and drive operational efficiency in the travel industry.",
    "pdf_link": "https://arxiv.org/abs/2404.17975",
    "graphs": [],
    "abstract_cn": "随着自然语言处理技术的飞速发展，大型语言模型（LLMs）已经展现出其在多种任务上的强大能力，比如从海量文本中挖掘关键信息。本研究通过对比分析，旨在探讨不同LLMs在提取TripAdvisor评论中旅行客户需求方面的效能。我们采用了包括开源和商业模型在内的多种模型，如GPT-4和Gemini，以揭示它们在这一特定领域的长短。通过BERTScore、ROUGE和BLEU等评价指标，我们对各模型在精准识别和概括客户需求上的表现进行了评估。研究结果显示，开源的LLMs，尤其是Mirage 7B，在性能上可与更大型的封闭模型相媲美，同时在成本效益和个性化定制方面具有优势。此外，我们还强调了在选择最合适的LLM进行客户需求分析时，需要考虑模型规模、资源需求和性能指标等关键因素。总体上，本研究为那些希望利用高端NLP技术来优化客户体验和提升旅游行业运营效率的企业提供了深刻的洞见。",
    "title_cn": "探索旅游业中的大型语言模型：自动化客户需求分析的比较研究",
    "tags": [
      "LLM应用",
      "",
      ""
    ]
  },
  {
    "title": "Automating Zero-Shot Patch Porting for Hard Forks",
    "submit_datetime": "2024年04月27日",
    "abstract": "Forking is a typical way of code reuse, which provides a simple way for developers to create a variant software (denoted as hard fork) by copying and modifying an existing codebase. Despite of the benefits, forking also leads to duplicate efforts in software maintenance. Developers need to port patches across the hard forks to address similar bugs or implement similar features. Due to the divergence between the source project and the hard fork, patch porting is complicated, which requires an adaption regarding different implementations of the same functionality. In this work, we take the first step to automate patch porting for hard forks under a zero-shot setting. We first conduct an empirical study of the patches ported from Vim to Neovim over the last ten years to investigate the necessities of patch porting and the potential flaws in the current practice. We then propose a large language model (LLM) based approach (namely PPatHF) to automatically port patches for hard forks on a function-wise basis. Specifically, PPatHF is composed of a reduction module and a porting module. Given the pre- and post-patch versions of a function from the reference project and the corresponding function from the target project, the reduction module first slims the input functions by removing code snippets less relevant to the patch. Then, the porting module leverages a LLM to apply the patch to the function from the target project. We evaluate PPatHF on 310 Neovim patches ported from Vim. The experimental results show that PPatHF outperforms the baselines significantly. Specifically, PPatHF can correctly port 131 (42.3%) patches and automate 57% of the manual edits required for the developer to port the patch.",
    "pdf_link": "https://arxiv.org/abs/2404.17964",
    "graphs": [],
    "abstract_cn": "代码分支是一种常见的复用手段，它允许开发者通过复制并修改现有代码库来创建软件的新变体，即硬分叉。尽管分支带来便利，但它也增加了软件维护的工作量，因为开发者必须在不同的硬分叉间同步补丁，以修复相似的问题或添加相同特性。由于源项目与硬分叉之间的差异，这一过程变得复杂且耗时。本研究首次尝试在零样本环境下自动化硬分叉的补丁移植。我们通过对过去十年 Vim 到 Neovim 的补丁移植情况进行了实证分析，以了解补丁移植的实际需求和现有方法的不足。基于此，我们提出了一种基于大型语言模型的新方法 PPatHF，它能够在函数级别自动移植硬分叉补丁。PPatHF 包含简化和移植两个模块，它首先精简函数输入，去除与补丁不相关的代码片段，然后利用语言模型将补丁应用到目标项目的函数上。我们在 310 个从 Vim 移植至 Neovim 的补丁上测试了 PPatHF，结果显示其性能显著超过现有基线，成功移植了 131 个（占比 42.3%）补丁，并减少了开发者 57% 的手动编辑工作量。",
    "title_cn": "实现零样本补丁的自动化移植，以应对硬分叉的挑战。",
    "tags": [
      "LLM应用",
      "软件工程",
      ""
    ]
  },
  {
    "title": "Spatio-Temporal Side Tuning Pre-trained Foundation Models for Video-based Pedestrian Attribute Recognition",
    "submit_datetime": "2024年04月27日",
    "abstract": "Existing pedestrian attribute recognition (PAR) algorithms are mainly developed based on a static image, however, the performance is unreliable in challenging scenarios, such as heavy occlusion, motion blur, etc. In this work, we propose to understand human attributes using video frames that can fully use temporal information by fine-tuning a pre-trained multi-modal foundation model efficiently. Specifically, we formulate the video-based PAR as a vision-language fusion problem and adopt a pre-trained foundation model CLIP to extract the visual features. More importantly, we propose a novel spatiotemporal side-tuning strategy to achieve parameter-efficient optimization of the pre-trained vision foundation model. To better utilize the semantic information, we take the full attribute list that needs to be recognized as another input and transform the attribute words/phrases into the corresponding sentence via split, expand, and prompt operations. Then, the text encoder of CLIP is utilized for embedding processed attribute descriptions. The averaged visual tokens and text tokens are concatenated and fed into a fusion Transformer for multi-modal interactive learning. The enhanced tokens will be fed into a classification head for pedestrian attribute prediction. Extensive experiments on two large-scale video-based PAR datasets fully validated the effectiveness of our proposed framework. The source code of this paper is available at https://github.com/Event-AHU/OpenPAR.",
    "pdf_link": "https://arxiv.org/abs/2404.17929",
    "graphs": [],
    "abstract_cn": "传统行人属性识别算法多建立在静态图像之上，面对重度遮挡或运动模糊等复杂情境时，其识别效果不尽人意。本研究提出一种新方法，通过视频帧捕捉时间信息，辅以高效微调的预训练多模态基础模型，以提升识别准确性。我们将视频驱动的PAR问题视作视觉与语言融合的挑战，并使用预训练模型CLIP来抽取视觉特征。此外，我们引入了一种创新的时空边调策略，优化了预训练视觉模型的参数效率。为了充分挖掘语义信息，我们将待识别的属性列表作为额外输入，通过分割、扩展和提示操作，将其转换为句子形式，再由CLIP的文本编码器进行嵌入处理。随后，视觉和文本标记的融合通过Transformer进行多模态交互学习，最终输出用于行人属性的预测分类。在两大视频基PAR数据集上的广泛实验，全面证实了我们框架的有效性。本研究的源代码已在GitHub发布，地址为：https://github.com/Event-AHU/OpenPAR。",
    "title_cn": "为视频驱动的行人属性识别任务，我们采用了时空侧向调整技术来优化预训练的基础模型。",
    "tags": [
      "Agent",
      "行人识别",
      "视频分析"
    ]
  },
  {
    "title": "I Have an Attention Bridge to Sell You: Generalization Capabilities of Modular Translation Architectures",
    "submit_datetime": "2024年04月27日",
    "abstract": "Modularity is a paradigm of machine translation with the potential of bringing forth models that are large at training time and small during inference. Within this field of study, modular approaches, and in particular attention bridges, have been argued to improve the generalization capabilities of models by fostering language-independent representations. In the present paper, we study whether modularity affects translation quality; as well as how well modular architectures generalize across different evaluation scenarios. For a given computational budget, we find non-modular architectures to be always comparable or preferable to all modular designs we study.",
    "pdf_link": "https://arxiv.org/abs/2404.17918",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.17918v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17918/shap-beeswarm-global.png"
      }
    ],
    "abstract_cn": "模块化作为机器翻译的新范式，能够在训练阶段构建大型模型，而在推理阶段则形成更为紧凑的模型。研究者们普遍认为，通过采用模块化方法，尤其是注意力桥接技术，可以增强模型的泛化能力，从而提升其对不同语言的适应性。本文旨在探讨模块化是否能够提升翻译的品质，并评估这类架构在多样化评估环境下的泛化表现。研究发现，在既定的计算资源下，非模块化架构在性能上总是可以与我们所研究的所有模块化设计相媲美，甚至更胜一筹。",
    "title_cn": "我向您推荐一座注意力之桥：探讨模块化翻译架构的泛化性能",
    "tags": [
      "分类：RAG\n\n这篇论文讨论了模块化在机器翻译中的应用，以及它是否能够提高翻译质量和模型的泛化能力。这属于机器翻译的范畴，而机器翻译是RAG（Retrieval-Augmented Generation）的一个应用领域。RAG是一种结合了检索（Retrieval）和生成（Generation）的模型，用于处理需要大量上下文信息的任务，如机器翻译。因此，这篇论文应该归类为RAG。",
      "机器翻译",
      ""
    ]
  },
  {
    "title": "SERPENT-VLM : Self-Refining Radiology Report Generation Using Vision Language Models",
    "submit_datetime": "2024年04月27日",
    "abstract": "Radiology Report Generation (R2Gen) demonstrates how Multi-modal Large Language Models (MLLMs) can automate the creation of accurate and coherent radiological reports. Existing methods often hallucinate details in text-based reports that don't accurately reflect the image content. To mitigate this, we introduce a novel strategy, SERPENT-VLM (SElf Refining Radiology RePort GENeraTion using Vision Language Models), which improves the R2Gen task by integrating a self-refining mechanism into the MLLM framework. We employ a unique self-supervised loss that leverages similarity between pooled image representations and the contextual representations of the generated radiological text, alongside the standard Causal Language Modeling objective, to refine image-text representations. This allows the model to scrutinize and align the generated text through dynamic interaction between a given image and the generated text, therefore reducing hallucination and continuously enhancing nuanced report generation. SERPENT-VLM outperforms existing baselines such as LLaVA-Med, BiomedGPT, etc., achieving SoTA performance on the IU X-ray and Radiology Objects in COntext (ROCO) datasets, and also proves to be robust against noisy images. A qualitative case study emphasizes the significant advancements towards more sophisticated MLLM frameworks for R2Gen, opening paths for further research into self-supervised refinement in the medical imaging domain.",
    "pdf_link": "https://arxiv.org/abs/2404.17912",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.17912v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17912/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17912v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17912/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17912v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17912/roco_bleu_bertscore.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17912v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17912/iu_xray_bleu_bertscore.png"
      }
    ],
    "abstract_cn": "放射学报告自动生成技术（R2Gen）通过多模态大型语言模型（MLLMs），实现了放射学报告的精确、连贯生成。传统方法在文本报告中常常凭空捏造细节，与图像内容不符。为此，我们提出了一种创新策略——SERPENT-VLM，即利用视觉语言模型自我完善的放射学报告生成，通过在MLLM框架中整合自我完善机制来提升R2Gen任务的表现。该策略采用了一种新颖的自监督损失函数，它通过比较池化后的图像表示与生成放射学文本的上下文表示的相似度，结合标准的因果语言建模目标，来优化图像与文本的表示。这样的设计使得模型能够在给定图像和生成文本之间进行动态交互，以审查和校准文本，减少虚假信息的产生，并不断提升报告生成的细节处理能力。SERPENT-VLM在IU X射线和放射学对象上下文（ROCO）数据集上超越了如LLaVA-Med、BiomedGPT等现有基准，展现了卓越的性能，并对噪声图像显示出良好的鲁棒性。一项定性案例研究突出了在构建更高级的R2Gen MLLM框架方面取得的显著进步，为医学影像领域的自监督精细化研究开辟了新路径。",
    "title_cn": "SERPENT-VLM：一种利用视觉语言模型实现自我精炼的放射学报告生成技术",
    "tags": [
      "LLM应用",
      "放射学",
      ""
    ]
  },
  {
    "title": "Tool Calling: Enhancing Medication Consultation via Retrieval-Augmented Large Language Models",
    "submit_datetime": "2024年04月27日",
    "abstract": "Large-scale language models (LLMs) have achieved remarkable success across various language tasks but suffer from hallucinations and temporal misalignment. To mitigate these shortcomings, Retrieval-augmented generation (RAG) has been utilized to provide external knowledge to facilitate the answer generation. However, applying such models to the medical domain faces several challenges due to the lack of domain-specific knowledge and the intricacy of real-world scenarios. In this study, we explore LLMs with RAG framework for knowledge-intensive tasks in the medical field. To evaluate the capabilities of LLMs, we introduce MedicineQA, a multi-round dialogue benchmark that simulates the real-world medication consultation scenario and requires LLMs to answer with retrieved evidence from the medicine database. MedicineQA contains 300 multi-round question-answering pairs, each embedded within a detailed dialogue history, highlighting the challenge posed by this knowledge-intensive task to current LLMs. We further propose a new \\textit{Distill-Retrieve-Read} framework instead of the previous \\textit{Retrieve-then-Read}. Specifically, the distillation and retrieval process utilizes a tool calling mechanism to formulate search queries that emulate the keyword-based inquiries used by search engines. With experimental results, we show that our framework brings notable performance improvements and surpasses the previous counterparts in the evidence retrieval process in terms of evidence retrieval accuracy. This advancement sheds light on applying RAG to the medical domain.",
    "pdf_link": "https://arxiv.org/abs/2404.17897",
    "graphs": [],
    "abstract_cn": "大规模语言模型（LLMs）在众多语言任务上取得了卓越成就，但它们也饱受幻觉和时间错位的困扰。为了解决这些问题，我们引入了检索增强生成（RAG）技术，以补充外部知识，优化答案生成过程。尽管如此，将这些模型应用于医学领域时，由于缺乏领域专业知识和现实世界情境的复杂性，我们面临多重挑战。本研究中，我们探讨了在医学领域知识密集型任务中应用RAG框架的LLMs。为了测试LLMs的性能，我们开发了MedicineQA，这是一个模拟真实世界药物咨询场景的多轮对话基准，要求LLMs依据药物数据库中的检索证据进行回答。MedicineQA包含300组多轮问答对，每组都置于详尽的对话背景之中，凸显了这一知识密集型任务对当前LLMs的挑战。此外，我们提出了一个创新的\\textit{蒸馏-检索-阅读}框架，替代了传统的\\textit{检索然后阅读}模式。在这个新框架中，蒸馏和检索过程通过工具调用机制生成搜索查询，模拟搜索引擎的关键词查询方式。实验结果显示，我们的框架在证据检索的准确性上显著提升了性能，并超越了以往的方法。这一进展为RAG技术在医学领域的应用开辟了新的可能性。",
    "title_cn": "工具调用：利用检索增强的大型语言模型提升药物咨询效果。",
    "tags": [
      "分类：RAG",
      "",
      "人工智能"
    ]
  },
  {
    "title": "How the Training Procedure Impacts the Performance of Deep Learning-based Vulnerability Patching",
    "submit_datetime": "2024年04月27日",
    "abstract": "Generative deep learning (DL) models have been successfully adopted for vulnerability patching. However, such models require the availability of a large dataset of patches to learn from. To overcome this issue, researchers have proposed to start from models pre-trained with general knowledge, either on the programming language or on similar tasks such as bug fixing. Despite the efforts in the area of automated vulnerability patching, there is a lack of systematic studies on how these different training procedures impact the performance of DL models for such a task. This paper provides a manyfold contribution to bridge this gap, by (i) comparing existing solutions of self-supervised and supervised pre-training for vulnerability patching; and (ii) for the first time, experimenting with different kinds of prompt-tuning for this task. The study required to train/test 23 DL models. We found that a supervised pre-training focused on bug-fixing, while expensive in terms of data collection, substantially improves DL-based vulnerability patching. When applying prompt-tuning on top of this supervised pre-trained model, there is no significant gain in performance. Instead, prompt-tuning is an effective and cheap solution to substantially boost the performance of self-supervised pre-trained models, i.e., those not relying on the bug-fixing pre-training.",
    "pdf_link": "https://arxiv.org/abs/2404.17896",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.17896v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17896/example.jpg"
      }
    ],
    "abstract_cn": "生成深度学习（DL）模型在漏洞修复领域取得了成功应用。但这些模型依赖于大量补丁数据集。为克服这一难题，研究者建议利用预训练模型，这些模型已通过编程语言或类似任务（如缺陷修复）的通用知识进行了训练。尽管在自动化漏洞修复方面取得了进展，但对于不同训练方法如何影响DL模型性能的系统性研究仍然不足。本文旨在填补这一空白，通过（i）对比自我监督与监督预训练方法在漏洞修复中的应用；（ii）首次探索为该任务设计的不同提示调整策略。研究共涉及23个DL模型的训练与测试。研究发现，专注于缺陷修复的监督预训练虽然在数据收集上成本较高，但能显著提升基于DL的漏洞修复效果。而在监督预训练模型上实施提示调整并未带来性能上的显著提升。相较之下，提示调整是一种高效且经济的方法，能够显著增强不依赖于缺陷修复预训练的自我监督预训练模型的性能。",
    "title_cn": "深度学习驱动的漏洞修复性能受训练流程的显著影响。",
    "tags": [
      "分类：LLM应用\n\n这篇论文主要研究了深度学习（DL）模型在漏洞修复领域的应用，特别是探讨了不同训练方法对DL模型性能的影响。虽然它涉及到了预训练模型和编程语言，但主要关注的是漏洞修复任务，这属于大型语言模型（LLM）的应用范畴。论文中提到的自我监督和监督预训练方法，以及提示调整策略，都是为了提高DL模型在漏洞修复任务中的性能。因此，这篇论文应该归类为LLM应用。",
      "软件工程",
      "漏洞修复"
    ]
  },
  {
    "title": "Using LLMs in Software Requirements Specifications: An Empirical Evaluation",
    "submit_datetime": "2024年04月27日",
    "abstract": "The creation of a Software Requirements Specification (SRS) document is important for any software development project. Given the recent prowess of Large Language Models (LLMs) in answering natural language queries and generating sophisticated textual outputs, our study explores their capability to produce accurate, coherent, and structured drafts of these documents to accelerate the software development lifecycle. We assess the performance of GPT-4 and CodeLlama in drafting an SRS for a university club management system and compare it against human benchmarks using eight distinct criteria. Our results suggest that LLMs can match the output quality of an entry-level software engineer to generate an SRS, delivering complete and consistent drafts. We also evaluate the capabilities of LLMs to identify and rectify problems in a given requirements document. Our experiments indicate that GPT-4 is capable of identifying issues and giving constructive feedback for rectifying them, while CodeLlama's results for validation were not as encouraging. We repeated the generation exercise for four distinct use cases to study the time saved by employing LLMs for SRS generation. The experiment demonstrates that LLMs may facilitate a significant reduction in development time for entry-level software engineers. Hence, we conclude that the LLMs can be gainfully used by software engineers to increase productivity by saving time and effort in generating, validating and rectifying software requirements.",
    "pdf_link": "https://arxiv.org/abs/2404.17842",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.17842v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17842/srs_template.pdf"
      },
      {
        "url": "https://arxiv.org/html/2404.17842v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17842/overall.pdf"
      },
      {
        "url": "https://arxiv.org/html/2404.17842v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17842/per_requirement.pdf"
      },
      {
        "url": "https://arxiv.org/html/2404.17842v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17842/mean_avg_deviation_verification.pdf"
      }
    ],
    "abstract_cn": "为软件开发项目制定软件需求规格说明书（SRS）极为关键。鉴于大型语言模型（LLMs）在处理自然语言查询和产出精致文本方面展现出的卓越能力，本研究旨在探究其能否高效生成准确、连贯且结构化的SRS文档草稿，以加快软件开发流程。我们对GPT-4和CodeLlama在起草大学俱乐部管理系统的SRS文档方面的表现进行了评估，并依据八项标准与人类工程师的工作进行了对比。研究结果显示，LLMs能够与初级软件工程师相媲美，制作出完整且一致的文档草稿。此外，我们还考察了LLMs在识别和修正需求文档中问题方面的能力。实验表明，GPT-4在这方面表现出色，能够发现问题并提供有益的修正建议，而CodeLlama在验证方面的成效则稍显不足。通过四个不同的应用场景，我们重复了文档生成实验，以探究使用LLMs能够为SRS文档生成节省多少时间。实验证明，LLMs能够显著降低初级软件工程师的开发时间。因此，我们得出结论，LLMs能够被软件工程师有效利用，通过在生成、验证和修正软件需求文档的过程中节省时间和精力，从而提升工作效率。",
    "title_cn": "探索大型语言模型在软件需求规格说明中的应用：一项实证研究。",
    "tags": [
      "LLM应用",
      "软件开发",
      ""
    ]
  },
  {
    "title": "VANER: Leveraging Large Language Model for Versatile and Adaptive Biomedical Named Entity Recognition",
    "submit_datetime": "2024年04月27日",
    "abstract": "Prevalent solution for BioNER involves using representation learning techniques coupled with sequence labeling. However, such methods are inherently task-specific, demonstrate poor generalizability, and often require dedicated model for each dataset. To leverage the versatile capabilities of recently remarkable large language models (LLMs), several endeavors have explored generative approaches to entity extraction. Yet, these approaches often fall short of the effectiveness of previouly sequence labeling approaches. In this paper, we utilize the open-sourced LLM LLaMA2 as the backbone model, and design specific instructions to distinguish between different types of entities and datasets. By combining the LLM's understanding of instructions with sequence labeling techniques, we use mix of datasets to train a model capable of extracting various types of entities. Given that the backbone LLMs lacks specialized medical knowledge, we also integrate external entity knowledge bases and employ instruction tuning to compel the model to densely recognize carefully curated entities. Our model VANER, trained with a small partition of parameters, significantly outperforms previous LLMs-based models and, for the first time, as a model based on LLM, surpasses the majority of conventional state-of-the-art BioNER systems, achieving the highest F1 scores across three datasets.",
    "pdf_link": "https://arxiv.org/abs/2404.17835",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.17835v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17835/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17835v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17835/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17835v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17835/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17835v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17835/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17835v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17835/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17835v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17835/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17835v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17835/x7.png"
      }
    ],
    "abstract_cn": "在生物医学命名实体识别（BioNER）领域，常见的方法是结合表示学习和序列标注技术。但这些方法往往局限于特定任务，泛化能力不佳，且通常需要为每个数据集定制模型。为了发挥大型语言模型（LLMs）的潜力，已有研究尝试采用生成式方法进行实体提取，但这些方法的有效性通常不及传统的序列标注技术。本文中，我们采用开源的LLM LLaMA2作为基础模型，并设计了特定的指令来识别不同类型和数据集的实体。我们将LLM对指令的理解与序列标注技术相结合，利用多样化的数据集训练出一个能够抽取多种实体的模型。考虑到基础LLM缺乏专业的医学知识，我们还引入了外部实体知识库，并实施了指令调优，以提高模型对精心挑选实体的识别能力。我们的VANER模型，仅用少量参数训练，便显著超越了以往的LLM模型，并首次作为基于LLM的模型，超越了大多数传统BioNER系统，实现了三个数据集上的最高F1得分。",
    "title_cn": "VANER：借助大型语言模型，实现生物医学领域的多用途和自适应命名实体识别。",
    "tags": [
      "LLM应用",
      "生物医学",
      ""
    ]
  },
  {
    "title": "Testing and Understanding Erroneous Planning in LLM Agents through Synthesized User Inputs",
    "submit_datetime": "2024年04月27日",
    "abstract": "Agents based on large language models (LLMs) have demonstrated effectiveness in solving a wide range of tasks by integrating LLMs with key modules such as planning, memory, and tool usage. Increasingly, customers are adopting LLM agents across a variety of commercial applications critical to reliability, including support for mental well-being, chemical synthesis, and software development. Nevertheless, our observations and daily use of LLM agents indicate that they are prone to making erroneous plans, especially when the tasks are complex and require long-term planning.\n  In this paper, we propose PDoctor, a novel and automated approach to testing LLM agents and understanding their erroneous planning. As the first work in this direction, we formulate the detection of erroneous planning as a constraint satisfiability problem: an LLM agent's plan is considered erroneous if its execution violates the constraints derived from the user inputs. To this end, PDoctor first defines a domain-specific language (DSL) for user queries and synthesizes varying inputs with the assistance of the Z3 constraint solver. These synthesized inputs are natural language paragraphs that specify the requirements for completing a series of tasks. Then, PDoctor derives constraints from these requirements to form a testing oracle. We evaluate PDoctor with three mainstream agent frameworks and two powerful LLMs (GPT-3.5 and GPT-4). The results show that PDoctor can effectively detect diverse errors in agent planning and provide insights and error characteristics that are valuable to both agent developers and users. We conclude by discussing potential alternative designs and directions to extend PDoctor.",
    "pdf_link": "https://arxiv.org/abs/2404.17833",
    "graphs": [],
    "abstract_cn": "利用大型语言模型（LLM）构建的智能代理通过整合规划、记忆和工具使用等核心组件，在解决多样化任务上展现了显著成效。客户对于这些在心理健康、化学合成和软件开发等关键商业领域中发挥可靠性支持作用的LLM代理的采纳日益增多。尽管如此，我们对LLM代理的日常观察和使用经验揭示了它们在面对需要长期规划的复杂任务时，制定计划容易出错的倾向。本文介绍了PDoctor，这是一种创新的自动化测试方法，旨在检测LLM代理的错误规划行为并深入理解其原因。作为该领域的开创性研究，我们将错误规划的识别问题转化为一个约束满足问题：如果代理的计划执行与用户输入推导出的约束相违背，则视为错误规划。PDoctor首先为用户查询设计了一种特定领域的语言（DSL），并利用Z3约束求解器辅助生成多样化的输入。这些输入以自然语言段落的形式，明确了一系列任务完成的具体要求。随后，PDoctor从这些要求中提取约束，构建了一个测试预言机。我们对PDoctor进行了评估，涵盖了三种主流的代理框架和两款先进的LLM（GPT-3.5和GPT-4）。评估结果显示，PDoctor能够有效识别代理规划中的多种错误，并为代理开发者和用户提供了宝贵的见解和错误特征。文末，我们讨论了PDoctor可能的替代设计和未来发展方向。",
    "title_cn": "通过合成用户输入，我们对大型语言模型（LLM）代理中的错误规划进行了测试与理解。",
    "tags": [
      "Agent",
      "心理健康",
      "软件开发"
    ]
  },
  {
    "title": "Evaluation of Few-Shot Learning for Classification Tasks in the Polish Language",
    "submit_datetime": "2024年04月27日",
    "abstract": "We introduce a few-shot benchmark consisting of 7 different classification tasks native to the Polish language. We conducted an empirical comparison with 0 and 16 shots between fine-tuning, linear probing, SetFit, and in-context learning (ICL) using various pre-trained commercial and open-source models. Our findings reveal that ICL achieves the best performance, with commercial models like GPT-3.5 and GPT-4 attaining the best performance. However, there remains a significant 14 percentage points gap between our best few-shot learning score and the performance of HerBERT-large fine-tuned on the entire training dataset. Among the techniques, SetFit emerges as the second-best approach, closely followed by linear probing. We observed the worst and most unstable performance with non-linear head fine-tuning. Results for ICL indicate that continual pre-training of models like Mistral-7b or Llama-2-13b on Polish corpora is beneficial. This is confirmed by the improved performances of Bielik-7b and Trurl-13b, respectively. To further support experiments in few-shot learning for Polish, we are releasing handcrafted templates for the ICL.",
    "pdf_link": "https://arxiv.org/abs/2404.17832",
    "graphs": [],
    "abstract_cn": "本研究提出了一个包含7项特定于波兰语的分类任务的少样本基准测试。我们对微调、线性探测、SetFit和上下文学习（ICL）等不同方法进行了实证比较，涉及0到16个样本点，并采用了多种预训练的商业和开源模型。研究发现ICL在性能上独占鳌头，尤其是商业模型GPT-3.5和GPT-4表现最为出色。尽管如此，即便是我们最佳的少样本学习得分，与在完整训练集上进行微调的HerBERT-large模型相比，仍有14个百分点的差距。在所有技术中，SetFit紧随ICL之后，成为次佳选择，而线性探测也表现不俗。相比之下，非线性头部微调的表现最差，且波动较大。ICL的结果显示，对Mistral-7b或Llama-2-13b等模型在波兰语文本上的持续预训练能够带来益处，这一点从Bielik-7b和Trurl-13b的提升性能中得到了验证。为了进一步推动波兰语少样本学习的实验研究，我们发布了为ICL精心设计的模板。",
    "title_cn": "本文旨在评估少样本学习在波兰语分类任务中的应用效果。",
    "tags": [
      "分类：LLM应用",
      "",
      "机器学习"
    ]
  },
  {
    "title": "Recall, Retrieve and Reason: Towards Better In-Context Relation Extraction",
    "submit_datetime": "2024年04月27日",
    "abstract": "Relation extraction (RE) aims to identify relations between entities mentioned in texts. Although large language models (LLMs) have demonstrated impressive in-context learning (ICL) abilities in various tasks, they still suffer from poor performances compared to most supervised fine-tuned RE methods. Utilizing ICL for RE with LLMs encounters two challenges: (1) retrieving good demonstrations from training examples, and (2) enabling LLMs exhibit strong ICL abilities in RE. On the one hand, retrieving good demonstrations is a non-trivial process in RE, which easily results in low relevance regarding entities and relations. On the other hand, ICL with an LLM achieves poor performance in RE while RE is different from language modeling in nature or the LLM is not large enough. In this work, we propose a novel recall-retrieve-reason RE framework that synergizes LLMs with retrieval corpora (training examples) to enable relevant retrieving and reliable in-context reasoning. Specifically, we distill the consistently ontological knowledge from training datasets to let LLMs generate relevant entity pairs grounded by retrieval corpora as valid queries. These entity pairs are then used to retrieve relevant training examples from the retrieval corpora as demonstrations for LLMs to conduct better ICL via instruction tuning. Extensive experiments on different LLMs and RE datasets demonstrate that our method generates relevant and valid entity pairs and boosts ICL abilities of LLMs, achieving competitive or new state-of-the-art performance on sentence-level RE compared to previous supervised fine-tuning methods and ICL-based methods.",
    "pdf_link": "https://arxiv.org/abs/2404.17809",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.17809v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17809/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17809v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17809/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17809v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17809/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17809v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17809/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17809v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17809/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17809v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17809/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17809v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17809/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17809v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17809/x8.png"
      }
    ],
    "abstract_cn": "关系抽取（RE）的目的是识别文本中实体间的关系。大型语言模型（LLMs）虽然在多项任务中展现了卓越的上下文学习能力（ICL），但与经过监督的微调RE方法相比，其性能仍有所不及。利用LLMs进行RE时，面临两大挑战：首先，从训练样本中提取出高质量的示例并非易事，这可能导致与实体和关系的相关性降低；其次，当RE任务的本质与语言建模不同，或LLM的规模不够大时，LLMs在RE任务中的ICL表现不佳。为此，我们提出了一种创新的“回忆-检索-推理”RE框架，该框架将LLMs与检索语料库（即训练样本）相结合，以实现有效的信息检索和可靠的上下文推理。具体而言，我们从训练数据集中提取出稳定的本体知识，指导LLMs生成与检索语料库紧密相关的实体对，作为有效的查询条件。这些实体对随后被用于从检索语料库中检索出相关训练样本，为LLMs提供更好的ICL示例，通过指令调整来优化学习效果。在多种LLMs和RE数据集上的广泛测试显示，我们的方法能够有效地生成相关且有效的实体对，并显著提升LLMs的ICL能力，与以往的监督式微调方法和基于ICL的方法相比，在句子级别的RE任务上取得了可比或更高的成绩。",
    "title_cn": "回顾、检索、推理：迈向更高效的语境内关系抽取",
    "tags": [
      "LLM应用",
      "",
      "关系抽取"
    ]
  },
  {
    "title": "Meta In-Context Learning Makes Large Language Models Better Zero and Few-Shot Relation Extractors",
    "submit_datetime": "2024年04月27日",
    "abstract": "Relation extraction (RE) is an important task that aims to identify the relationships between entities in texts. While large language models (LLMs) have revealed remarkable in-context learning (ICL) capability for general zero and few-shot learning, recent studies indicate that current LLMs still struggle with zero and few-shot RE. Previous studies are mainly dedicated to design prompt formats and select good examples for improving ICL-based RE. Although both factors are vital for ICL, if one can fundamentally boost the ICL capability of LLMs in RE, the zero and few-shot RE performance via ICL would be significantly improved. To this end, we introduce \\textsc{Micre} (\\textbf{M}eta \\textbf{I}n-\\textbf{C}ontext learning of LLMs for \\textbf{R}elation \\textbf{E}xtraction), a new meta-training framework for zero and few-shot RE where an LLM is tuned to do ICL on a diverse collection of RE datasets (i.e., learning to learn in context for RE). Through meta-training, the model becomes more effectively to learn a new RE task in context by conditioning on a few training examples with no parameter updates or task-specific templates at inference time, enabling better zero and few-shot task generalization. We experiment \\textsc{Micre} on various LLMs with different model scales and 12 public RE datasets, and then evaluate it on unseen RE benchmarks under zero and few-shot settings. \\textsc{Micre} delivers comparable or superior performance compared to a range of baselines including supervised fine-tuning and typical in-context learning methods. We find that the gains are particular significant for larger model scales, and using a diverse set of the meta-training RE datasets is key to improvements. Empirically, we show that \\textsc{Micre} can transfer the relation semantic knowledge via relation label name during inference on target RE datasets.",
    "pdf_link": "https://arxiv.org/abs/2404.17807",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.17807v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17807/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17807v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17807/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17807v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17807/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17807v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17807/x4.png"
      }
    ],
    "abstract_cn": "关系抽取（RE）是一项核心任务，目的在于识别文本实体间的关系。尽管大型语言模型（LLMs）在常规的零样本和少样本学习中展现了卓越的上下文学习能力（ICL），但最新研究指出，现有LLMs在处理零样本和少样本的关系抽取上仍有挑战。过往研究多集中于设计提示格式和挑选恰当的例子以提升基于ICL的RE性能。虽然这两点对ICL至关重要，但如果能够从根本上增强LLMs在RE任务上的ICL能力，那么通过ICL实现的零样本和少样本RE性能有望显著提升。基于此，我们提出了\\textsc{Micre}（元上下文学习框架，用于LLMs的关系抽取），这是一个针对零样本和少样本RE的新型元训练框架，通过在多样化的RE数据集上进行ICL，调整LLM以适应RE任务（即在RE的上下文中学会学习）。通过元训练，模型能够在推理阶段，仅依赖少数训练样本，无需参数更新或特定任务模板，更高效地学习新的RE任务上下文，从而提升零样本和少样本任务的泛化能力。我们在不同规模的多种LLMs上对\\textsc{Micre}进行了实验，并在12个公共RE数据集上进行了评估，随后在未见过的RE基准上进行了零样本和少样本设置下的测试。\\textsc{Micre}与包括监督微调和典型上下文学习方法在内的多种基线相比，展现出了相当或更优的性能。我们发现，对于更大规模的模型，提升尤为明显，且使用多样化的元训练RE数据集是提升性能的关键。实际上，我们证明了\\textsc{Micre}能够在目标RE数据集的推理过程中，通过关系标签名称传递关系语义知识。",
    "title_cn": "引入元上下文学习技术，大型语言模型在零样本和少样本关系抽取任务上的表现得到了显著提升。",
    "tags": [
      "LLM应用",
      "",
      "关系抽取"
    ]
  },
  {
    "title": "Verco: Learning Coordinated Verbal Communication for Multi-agent Reinforcement Learning",
    "submit_datetime": "2024年04月27日",
    "abstract": "In recent years, multi-agent reinforcement learning algorithms have made significant advancements in diverse gaming environments, leading to increased interest in the broader application of such techniques. To address the prevalent challenge of partial observability, communication-based algorithms have improved cooperative performance through the sharing of numerical embedding between agents. However, the understanding of the formation of collaborative mechanisms is still very limited, making designing a human-understandable communication mechanism a valuable problem to address. In this paper, we propose a novel multi-agent reinforcement learning algorithm that embeds large language models into agents, endowing them with the ability to generate human-understandable verbal communication. The entire framework has a message module and an action module. The message module is responsible for generating and sending verbal messages to other agents, effectively enhancing information sharing among agents. To further enhance the message module, we employ a teacher model to generate message labels from the global view and update the student model through Supervised Fine-Tuning (SFT). The action module receives messages from other agents and selects actions based on current local observations and received messages. Experiments conducted on the Overcooked game demonstrate our method significantly enhances the learning efficiency and performance of existing methods, while also providing an interpretable tool for humans to understand the process of multi-agent cooperation.",
    "pdf_link": "https://arxiv.org/abs/2404.17780",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.17780v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17780/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17780v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17780/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17780v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17780/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17780v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17780/x4.png"
      }
    ],
    "abstract_cn": "近期，多智能体强化学习在各类游戏场景中实现了重大突破，激发了将其应用于更广泛领域的热情。面对部分可观测性的难题，通过智能体间数值嵌入的共享，通信驱动的算法显著提升了协作效果。尽管如此，我们对于如何形成协作机制的理解尚浅，设计出易于人类理解的通信机制成为了一个亟待解决的问题。本文提出了一种创新的多智能体强化学习算法，该算法将大型语言模型集成到智能体中，使其能够产生易于人类理解的语言交流。框架包含消息生成模块和动作选择模块。消息模块负责生成并向同伴发送口头信息，以促进信息的有效共享。为了提升消息模块的性能，我们引入了一个教师模型来从全局视角生成消息标签，并通过监督式微调（SFT）来训练学生模型。动作模块则根据接收到的信息和局部观察来决策行动。在Overcooked游戏中的实验结果证明，我们的方法不仅显著提升了学习效率和表现，还为人类理解多智能体协作过程提供了一种直观的工具。",
    "title_cn": "Verco：探索多智能体强化学习中的协同口头沟通技巧",
    "tags": [
      "Agent",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Medical Vision-Language Pre-Training for Brain Abnormalities",
    "submit_datetime": "2024年04月27日",
    "abstract": "Vision-language models have become increasingly powerful for tasks that require an understanding of both visual and linguistic elements, bridging the gap between these modalities. In the context of multimodal clinical AI, there is a growing need for models that possess domain-specific knowledge, as existing models often lack the expertise required for medical applications. In this paper, we take brain abnormalities as an example to demonstrate how to automatically collect medical image-text aligned data for pretraining from public resources such as PubMed. In particular, we present a pipeline that streamlines the pre-training process by initially collecting a large brain image-text dataset from case reports and published journals and subsequently constructing a high-performance vision-language model tailored to specific medical tasks. We also investigate the unique challenge of mapping subfigures to subcaptions in the medical domain. We evaluated the resulting model with quantitative and qualitative intrinsic evaluations. The resulting dataset and our code can be found here https://github.com/masoud-monajati/MedVL_pretraining_pipeline",
    "pdf_link": "https://arxiv.org/abs/2404.17779",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.17779v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17779/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17779v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17779/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17779v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17779/x3.png"
      }
    ],
    "abstract_cn": "视觉-语言模型在处理视觉与语言元素并重的任务上愈发展现出其强大能力，有效地连接了视觉与语言两大领域。在多模态临床人工智能领域，对于具备特定领域知识的模型的需求不断上升，因为现有的模型往往缺少医疗应用所需的专业技能。本文以脑部异常为例，介绍了如何自动从PubMed等公共资源中收集医学图像与文本对齐数据，用于模型的预训练。我们设计了一个高效的流程，首先从病例报告和学术期刊中搜集大量脑部图像与文本数据，进而构建一个专为特定医疗任务优化的高性能视觉-语言模型。此外，我们还探讨了在医学领域内将子图与子标题对应起来的独特挑战。通过定量和定性的内在评估方法，我们对所构建的模型进行了评估。相关数据集和代码已在以下链接公开：https://github.com/masoud-monajati/MedVL_pretraining_pipeline",
    "title_cn": "医学视觉与语言预训练：探索脑部异常识别",
    "tags": [
      "分类：LLM应用\n\n这篇论文摘要描述了视觉-语言模型在多模态临床人工智能领域的应用，特别是在处理脑部异常的医疗任务中。论文介绍了如何从公共资源中收集医学图像与文本对齐数据，用于模型的预训练，并构建了一个专为特定医疗任务优化的高性能视觉-语言模型。这篇论文主要关注于实际应用，因此可以归类为LLM应用。",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Swarm-based gradient descent meets simulated annealing",
    "submit_datetime": "2024年04月27日",
    "abstract": "We introduce a novel method for non-convex optimization which is at the interface between the swarm-based gradient-descent (SBGD) [J. Lu et. al., ArXiv:2211.17157; E.Tadmor and A. Zenginoglu, Acta Applicandae Math., 190, 2024] and Simulated Annealing (SA) [V. Cerny, J. optimization theory and appl., 45:41-51, 1985; S.Kirkpatrick et. al., Science, 220(4598):671-680, 1983; S. Geman and C.-R. Hwang, SIAM J. Control and Optimization, 24(5):1031-1043, 1986]. We follow the methodology of SBGD in which a swarm of agents, each identified with a position, ${\\mathbf x}$ and mass $m$, explores the ambient space. The agents proceed in gradient descent direction, and are subject to Brownian motion with annealing-rate dictated by a decreasing function of their mass. Thus, instead of the SA protocol for time-decreasing temperature, we let the swarm decide how to `cool down' agents, depending on their accumulated mass over time. The dynamics of masses is coupled with the dynamics of positions: agents at higher ground transfer (part of) their mass to those at lower ground. Consequently, the swarm is dynamically divided between heavier, cooler agents viewed as `leaders' and lighter, warmer agents viewed as `explorers'. Mean-field convergence analysis and benchmark optimizations demonstrate the effectiveness of the swarm-based method as a multi-dimensional global optimizer.",
    "pdf_link": "https://arxiv.org/abs/2404.18015",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.18015v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18015/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18015v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18015/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18015v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18015/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18015v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18015/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18015v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18015/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18015v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18015/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18015v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18015/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18015v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18015/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18015v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18015/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18015v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18015/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18015v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18015/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18015v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18015/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18015v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18015/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18015v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18015/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18015v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18015/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18015v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18015/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18015v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18015/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18015v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18015/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18015v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18015/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18015v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18015/x20.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18015v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18015/x21.png"
      }
    ],
    "abstract_cn": "本文提出了一种创新的非凸优化技术，它融合了群体梯度下降（SBGD）与模拟退火（SA）的精髓。在这种方法中，一群具有特定位置和质量的代理在空间中探索，它们顺着梯度下降的方向移动，并受到与其质量相关的退火率影响的布朗运动。不同于 SA 中随时间递减的温度规则，这里我们让群体根据代理随时间累积的质量来自主决定“降温”策略。代理的质量变化与位置变化相互关联：位于能量较高位置的代理会将其部分质量转移给能量较低位置的代理。这样的机制使得群体自动分化为“领导者”和“探索者”两种角色，前者质量较大、温度较低，后者则相反。通过平均场收敛分析和一系列基准优化测试，我们证实了这种基于群体的优化方法在多维全局优化问题上的强大性能。",
    "title_cn": "群体梯度下降与模拟退火的结合。",
    "tags": [
      "分类：Agent",
      "优化算法",
      "计算科学"
    ]
  },
  {
    "title": "VIEW: Visual Imitation Learning with Waypoints",
    "submit_datetime": "2024年04月27日",
    "abstract": "Robots can use Visual Imitation Learning (VIL) to learn everyday tasks from video demonstrations. However, translating visual observations into actionable robot policies is challenging due to the high-dimensional nature of video data. This challenge is further exacerbated by the morphological differences between humans and robots, especially when the video demonstrations feature humans performing tasks. To address these problems we introduce Visual Imitation lEarning with Waypoints (VIEW), an algorithm that significantly enhances the sample efficiency of human-to-robot VIL. VIEW achieves this efficiency using a multi-pronged approach: extracting a condensed prior trajectory that captures the demonstrator's intent, employing an agent-agnostic reward function for feedback on the robot's actions, and utilizing an exploration algorithm that efficiently samples around waypoints in the extracted trajectory. VIEW also segments the human trajectory into grasp and task phases to further accelerate learning efficiency. Through comprehensive simulations and real-world experiments, VIEW demonstrates improved performance compared to current state-of-the-art VIL methods. VIEW enables robots to learn a diverse range of manipulation tasks involving multiple objects from arbitrarily long video demonstrations. Additionally, it can learn standard manipulation tasks such as pushing or moving objects from a single video demonstration in under 30 minutes, with fewer than 20 real-world rollouts. Code and videos here: https://collab.me.vt.edu/view/",
    "pdf_link": "https://arxiv.org/abs/2404.17906",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.17906v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17906/front.jpg"
      },
      {
        "url": "https://arxiv.org/html/2404.17906v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17906/method.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17906v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17906/prior.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17906v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17906/exploration_bb.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17906v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17906/exploration_sampling.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17906v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17906/sim_tasks.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17906v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17906/sim_noise.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17906v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17906/sim_no_squishe.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17906v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17906/sim_exploration.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17906v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17906/sim_residual.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17906v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17906/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17906v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17906/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17906v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17906/exp_single_object.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17906v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17906/exp_multi_object.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17906v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17906/exp_residual.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17906v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17906/objects.jpg"
      },
      {
        "url": "https://arxiv.org/html/2404.17906v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17906/whirl_issues.png"
      }
    ],
    "abstract_cn": "机器人利用视觉模仿学习（VIL）能通过视频示范掌握日常任务。但将视觉信息转化为机器人可执行策略面临挑战，尤其是当涉及人类与机器人形态差异时。为应对这些难题，我们推出了一种名为“带有关键点的视觉模仿学习（VIEW）”的算法，它显著提升了从人类到机器人的VIL样本效率。VIEW通过精炼的先验轨迹捕捉示范意图、采用通用奖励函数对机器人行为进行反馈，以及利用探索算法在轨迹关键点周围高效采样，实现了这一效率。此外，VIEW将人类示范划分为抓取和执行阶段，以加快学习进程。经过广泛的模拟和现实世界测试，VIEW在性能上超越了现有的VIL技术。它使得机器人能够从任意长度的视频示范中学习多样化的操控任务。而且，VIEW还能在30分钟内，通过不到20次实际操作，学会如推或移动物体等标准操控任务。相关代码和视频在此链接：https://collab.me.vt.edu/view/",
    "title_cn": "VIEW：一种基于关键节点的视觉模仿学习方法",
    "tags": [
      "Agent",
      "机器人技术",
      "视觉模仿学习"
    ]
  },
  {
    "title": "Probabilistic Inference in Language Models via Twisted Sequential Monte Carlo",
    "submit_datetime": "2024年04月26日",
    "abstract": "Numerous capability and safety techniques of Large Language Models (LLMs), including RLHF, automated red-teaming, prompt engineering, and infilling, can be cast as sampling from an unnormalized target distribution defined by a given reward or potential function over the full sequence. In this work, we leverage the rich toolkit of Sequential Monte Carlo (SMC) for these probabilistic inference problems. In particular, we use learned twist functions to estimate the expected future value of the potential at each timestep, which enables us to focus inference-time computation on promising partial sequences. We propose a novel contrastive method for learning the twist functions, and establish connections with the rich literature of soft reinforcement learning. As a complementary application of our twisted SMC framework, we present methods for evaluating the accuracy of language model inference techniques using novel bidirectional SMC bounds on the log partition function. These bounds can be used to estimate the KL divergence between the inference and target distributions in both directions. We apply our inference evaluation techniques to show that twisted SMC is effective for sampling undesirable outputs from a pretrained model (a useful component of harmlessness training and automated red-teaming), generating reviews with varied sentiment, and performing infilling tasks.",
    "pdf_link": "https://arxiv.org/abs/2404.17546",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）的多项能力和安全技术，如RLHF、自动化红队对抗、提示设计和填充技术，本质上是从由奖励或潜能函数定义的未归一化目标分布中进行抽样。本研究中，我们采用了序列蒙特卡洛（SMC）方法来解决这些概率推断难题。我们特别利用学习到的扭曲函数来预测每个时间点潜能的期望未来值，从而将推断计算的重点放在有潜力的部分序列上。我们提出了一种创新的对比学习方法来训练这些扭曲函数，并与软强化学习领域的丰富文献建立了联系。此外，我们还展示了一种评估语言模型推断精度的新方法，即利用双向SMC界限来估计对数划分函数，进而计算推断分布与目标分布之间的KL散度。我们应用这些推断评估技术，证明了扭曲SMC在从预训练模型中抽取不良输出、生成情感多样的评论以及执行填充任务方面的有效性。",
    "title_cn": "本文介绍了一种新颖的方法，即通过扭曲的顺序蒙特卡洛（Twisted Sequential Monte Carlo）技术，来增强语言模型中的概率推断能力。",
    "tags": [
      "分类：LLM理论",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Exploring the Distinctiveness and Fidelity of the Descriptions Generated by Large Vision-Language Models",
    "submit_datetime": "2024年04月26日",
    "abstract": "Large Vision-Language Models (LVLMs) are gaining traction for their remarkable ability to process and integrate visual and textual data. Despite their popularity, the capacity of LVLMs to generate precise, fine-grained textual descriptions has not been fully explored. This study addresses this gap by focusing on \\textit{distinctiveness} and \\textit{fidelity}, assessing how models like Open-Flamingo, IDEFICS, and MiniGPT-4 can distinguish between similar objects and accurately describe visual features. We proposed the Textual Retrieval-Augmented Classification (TRAC) framework, which, by leveraging its generative capabilities, allows us to delve deeper into analyzing fine-grained visual description generation. This research provides valuable insights into the generation quality of LVLMs, enhancing the understanding of multimodal language models. Notably, MiniGPT-4 stands out for its better ability to generate fine-grained descriptions, outperforming the other two models in this aspect. The code is provided at \\url{https://anonymous.4open.science/r/Explore_FGVDs-E277}.",
    "pdf_link": "https://arxiv.org/abs/2404.17534",
    "graphs": [],
    "abstract_cn": "大型视觉-语言模型（LVLMs）因其卓越的视觉与文本数据处理能力而备受瞩目。然而，这些模型在生成精细、详尽的文本描述方面的潜力尚未被充分挖掘。本研究聚焦于“独特性”与“忠实度”，探讨了Open-Flamingo、IDEFICS和MiniGPT-4等模型区分相似物体和精确表述视觉特征的能力。我们引入了文本检索增强分类（TRAC）框架，借助其生成特性，深入探讨了细粒度视觉描述的生成机制。此项研究深化了我们对LVLMs生成质量的认识，尤其是在多模态语言模型的理解上。特别值得一提的是，MiniGPT-4在生成精细描述方面表现更为出色，超越了其他两种模型。相关代码已在\\url{https://anonymous.4open.science/r/Explore_FGVDs-E277}提供。",
    "title_cn": "本文旨在探究大型视觉-语言模型所生成描述的独特性和准确性。",
    "tags": [
      "分类：LLM应用",
      "计算机视觉",
      ""
    ]
  },
  {
    "title": "Large Language Model Agent as a Mechanical Designer",
    "submit_datetime": "2024年04月26日",
    "abstract": "Conventional mechanical design paradigms rely on experts systematically refining concepts through experience-guided modification and FEA to meet specific requirements. However, this approach can be time-consuming and heavily dependent on prior knowledge and experience. While numerous machine learning models have been developed to streamline this intensive and expert-driven iterative process, these methods typically demand extensive training data and considerable computational resources. Furthermore, methods based on deep learning are usually restricted to the specific domains and tasks for which they were trained, limiting their applicability across different tasks. This creates a trade-off between the efficiency of automation and the demand for resources. In this study, we present a novel approach that integrates pre-trained LLMs with a FEM module. The FEM module evaluates each design and provides essential feedback, guiding the LLMs to continuously learn, plan, generate, and optimize designs without the need for domain-specific training. We demonstrate the effectiveness of our proposed framework in managing the iterative optimization of truss structures, showcasing its capability to reason about and refine designs according to structured feedback and criteria. Our results reveal that these LLM-based agents can successfully generate truss designs that comply with natural language specifications with a success rate of up to 90%, which varies according to the applied constraints. By employing prompt-based optimization techniques we show that LLM based agents exhibit optimization behavior when provided with solution-score pairs to iteratively refine designs to meet specifications. This ability of LLM agents to produce viable designs and optimize them based on their inherent reasoning capabilities highlights their potential to develop and implement effective design strategies autonomously.",
    "pdf_link": "https://arxiv.org/abs/2404.17525",
    "graphs": [],
    "abstract_cn": "传统机械设计依赖资深专家通过经验驱动的修改和有限元分析（FEA）来逐步完善设计，以满足特定需求。但这一过程不仅耗时，而且高度依赖于既有知识和经验。尽管众多机器学习模型被开发用以简化这一复杂且专家主导的迭代设计流程，它们往往需要庞大的训练数据集和高额的计算资源。特别是，基于深度学习的模型通常只适用于它们所训练的特定领域和任务，这限制了它们的通用性，从而在自动化效率和资源消耗之间形成了一种权衡。在本研究中，我们提出了一种创新的方法，将预训练的大型语言模型（LLM）与有限元模块（FEM）相结合。FEM模块对每个设计方案进行评估，并提供关键反馈，引导LLM进行持续的学习、规划、设计生成和优化，无需特定领域的训练。我们在桁架结构的迭代优化管理中证明了所提出框架的有效性，展示了其根据结构化反馈和标准进行设计推理和改进的能力。研究结果显示，基于LLM的智能体能够以高达90%的成功率生成符合自然语言规格的桁架设计，这一成功率会根据所施加的约束条件而变化。通过采用基于提示的优化技术，我们证明了基于LLM的智能体在提供解决方案与得分对时，能够展现出优化行为，以迭代方式精细化设计以满足特定规格。LLM智能体的这种能力，即基于其内在推理能力来生成可行的设计并进行优化，突显了它们在自主开发和实施有效设计策略方面的潜力。",
    "title_cn": "大型语言模型作为机械设计代理",
    "tags": [
      "分类：Agent\n\n这篇论文提出了一种将大型语言模型（LLM）与有限元模块（FEM）相结合的创新方法，用于自动化机械设计过程。该方法利用LLM的推理能力来生成和优化设计，而FEM模块则提供关键反馈以指导LLM的学习过程。这种方法展示了LLM在自主开发和实施有效设计策略方面的潜力，因此可以归类为Agent领域。",
      "机械设计",
      "人工智能"
    ]
  },
  {
    "title": "On the Use of Large Language Models to Generate Capability Ontologies",
    "submit_datetime": "2024年04月26日",
    "abstract": "Capability ontologies are increasingly used to model functionalities of systems or machines. The creation of such ontological models with all properties and constraints of capabilities is very complex and can only be done by ontology experts. However, Large Language Models (LLMs) have shown that they can generate machine-interpretable models from natural language text input and thus support engineers / ontology experts. Therefore, this paper investigates how LLMs can be used to create capability ontologies. We present a study with a series of experiments in which capabilities with varying complexities are generated using different prompting techniques and with different LLMs. Errors in the generated ontologies are recorded and compared. To analyze the quality of the generated ontologies, a semi-automated approach based on RDF syntax checking, OWL reasoning, and SHACL constraints is used. The results of this study are very promising because even for complex capabilities, the generated ontologies are almost free of errors.",
    "pdf_link": "https://arxiv.org/abs/2404.17524",
    "graphs": [],
    "abstract_cn": "能力本体论正日益广泛应用于系统或机器功能建模。构建这些包含所有属性和约束的本体论模型极为复杂，通常需要本体论专家的专业知识。幸运的是，大型语言模型（LLMs）已证明能够从自然语言文本中生成机器可理解的模型，为工程师和本体论专家提供助力。本篇论文探讨了如何利用LLMs来构建能力本体论。我们通过一系列实验研究，这些实验采用了不同的提示技巧和多种LLMs来生成不同复杂度的能力。实验中记录了生成本体论的错误，并进行了比较。为了评估生成本体论的质量，我们采用了一种结合RDF语法检查、OWL推理和SHACL约束的半自动化分析方法。研究结果显示，即便是处理复杂能力，生成的本体论也几乎无误，这一成果令人鼓舞。",
    "title_cn": "探讨如何利用大型语言模型来构建能力本体的实践",
    "tags": [
      "LLM应用",
      "系统建模",
      "人工智能"
    ]
  },
  {
    "title": "Enhancing Legal Compliance and Regulation Analysis with Large Language Models",
    "submit_datetime": "2024年04月26日",
    "abstract": "This research explores the application of Large Language Models (LLMs) for automating the extraction of requirement-related legal content in the food safety domain and checking legal compliance of regulatory artifacts. With Industry 4.0 revolutionizing the food industry and with the General Data Protection Regulation (GDPR) reshaping privacy policies and data processing agreements, there is a growing gap between regulatory analysis and recent technological advancements. This study aims to bridge this gap by leveraging LLMs, namely BERT and GPT models, to accurately classify legal provisions and automate compliance checks. Our findings demonstrate promising results, indicating LLMs' significant potential to enhance legal compliance and regulatory analysis efficiency, notably by reducing manual workload and improving accuracy within reasonable time and financial constraints.",
    "pdf_link": "https://arxiv.org/abs/2404.17522",
    "graphs": [],
    "abstract_cn": "本研究着眼于利用大型语言模型（LLMs）自动化提取食品安全领域的法律相关内容，并确保监管文件的合法性。在工业4.0浪潮推动食品行业转型，以及GDPR新规重塑隐私政策与数据处理协议的背景下，法规分析与技术进步之间出现了脱节。通过运用BERT和GPT等LLMs，研究旨在精确分类法律条文并实现合规性检查的自动化，以期填补这一空白。研究结果显示，LLMs在提升法律合规性和监管分析的效率方面展现出巨大潜力，显著降低了人工操作的负担，并在可控的时间和成本范围内提高了准确性。",
    "title_cn": "借助大型语言模型，提升法律合规与法规分析的效能",
    "tags": [
      "LLM应用",
      "食品安全",
      "法律合规"
    ]
  },
  {
    "title": "A Comprehensive Evaluation on Event Reasoning of Large Language Models",
    "submit_datetime": "2024年04月26日",
    "abstract": "Event reasoning is a fundamental ability that underlies many applications. It requires event schema knowledge to perform global reasoning and needs to deal with the diversity of the inter-event relations and the reasoning paradigms. How well LLMs accomplish event reasoning on various relations and reasoning paradigms remains unknown. To mitigate this disparity, we comprehensively evaluate the abilities of event reasoning of LLMs. We introduce a novel benchmark EV2 for EValuation of EVent reasoning. EV2 consists of two levels of evaluation of schema and instance and is comprehensive in relations and reasoning paradigms. We conduct extensive experiments on EV2. We find that LLMs have abilities to accomplish event reasoning but their performances are far from satisfactory. We also notice the imbalance of event reasoning abilities in LLMs. Besides, LLMs have event schema knowledge, however, they're not aligned with humans on how to utilize the knowledge. Based on these findings, we introduce two methods to guide the LLMs to utilize the event schema knowledge. Both methods achieve improvements.",
    "pdf_link": "https://arxiv.org/abs/2404.17513",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.17513v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17513/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17513v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17513/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17513v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17513/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17513v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17513/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17513v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17513/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17513v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17513/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17513v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17513/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17513v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17513/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17513v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17513/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17513v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17513/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17513v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17513/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17513v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17513/x14.png"
      }
    ],
    "abstract_cn": "事件推理是支撑众多应用的基本技能，它依赖于事件模式知识以进行全局推理，并需应对事件间复杂关系及多样化的推理范式。目前，大型语言模型（LLMs）在不同关系和推理范式上的事件推理表现尚未明确。为了填补这一空白，我们对LLMs的事件推理能力进行了全面评估，并推出了EV2这一新的基准测试平台，旨在全面评估事件推理能力。EV2包含模式和实例两个层面的评估，覆盖了广泛的事件关系和推理范式。通过在EV2上的广泛实验，我们发现LLMs虽具备事件推理能力，但其表现尚有较大提升空间。我们还观察到LLMs在事件推理能力上存在不平衡现象。此外，尽管LLMs具备事件模式知识，但它们在如何应用这些知识上与人类存在差异。针对这些发现，我们提出了两种方法，引导LLMs更好地利用事件模式知识，两者均取得了显著提升。",
    "title_cn": "本文全面审视了大型语言模型在事件推理方面的表现。",
    "tags": [
      "分类：LLM应用",
      "人工智能",
      "事件推理"
    ]
  },
  {
    "title": "Ruffle&Riley: Insights from Designing and Evaluating a Large Language Model-Based Conversational Tutoring System",
    "submit_datetime": "2024年04月26日",
    "abstract": "Conversational tutoring systems (CTSs) offer learning experiences through interactions based on natural language. They are recognized for promoting cognitive engagement and improving learning outcomes, especially in reasoning tasks. Nonetheless, the cost associated with authoring CTS content is a major obstacle to widespread adoption and to research on effective instructional design. In this paper, we discuss and evaluate a novel type of CTS that leverages recent advances in large language models (LLMs) in two ways: First, the system enables AI-assisted content authoring by inducing an easily editable tutoring script automatically from a lesson text. Second, the system automates the script orchestration in a learning-by-teaching format via two LLM-based agents (Ruffle&Riley) acting as a student and a professor. The system allows for free-form conversations that follow the ITS-typical inner and outer loop structure. We evaluate Ruffle&Riley's ability to support biology lessons in two between-subject online user studies (N = 200) comparing the system to simpler QA chatbots and reading activity. Analyzing system usage patterns, pre/post-test scores and user experience surveys, we find that Ruffle&Riley users report high levels of engagement, understanding and perceive the offered support as helpful. Even though Ruffle&Riley users require more time to complete the activity, we did not find significant differences in short-term learning gains over the reading activity. Our system architecture and user study provide various insights for designers of future CTSs. We further open-source our system to support ongoing research on effective instructional design of LLM-based learning technologies.",
    "pdf_link": "https://arxiv.org/abs/2404.17460",
    "graphs": [],
    "abstract_cn": "会话式辅导系统（CTSs）利用自然语言互动提供学习体验，尤其在推理任务中，它们因其提升认知参与度和学习成效而备受推崇。然而，创作CTS内容的高昂成本成为了普及应用和深入教学设计研究的一大障碍。本文探讨并评估了一种新型CTS，它通过两种方式利用了大型语言模型（LLMs）的最新进展：首先，系统能够自动从课程文本生成易于编辑的辅导脚本，辅助AI内容创作；其次，通过两个基于LLM的代理（Ruffle&Riley）——分别模拟学生和教师的角色，系统自动化地在教学相长模式下编排对话脚本。该系统支持自由形式的对话，遵循智能辅导系统（ITS）的典型内外循环结构。通过两项在线用户研究（共200名参与者），我们评估了Ruffle&Riley在支持生物学课程方面的表现，并将其与简单的问答聊天机器人和阅读活动进行了对比。研究分析了系统使用模式、前后测试成绩以及用户体验调查，结果显示Ruffle&Riley的用户表现出高度的参与感、理解力，并认为所提供的帮助非常有用。尽管使用Ruffle&Riley的用户完成活动所需时间更长，但在短期学习成果上与阅读活动相比并无显著差异。我们的系统架构和用户研究为未来CTS设计者提供了宝贵的洞见，并且我们开源了系统，以支持对基于LLM的学习技术进行有效教学设计的持续研究。",
    "title_cn": "Ruffle&Riley：设计和评估一款基于大型语言模型的对话式教学系统的经验与洞见",
    "tags": [
      "Agent",
      "",
      "人工智能"
    ]
  },
  {
    "title": "\"ChatGPT Is Here to Help, Not to Replace Anybody\" -- An Evaluation of Students' Opinions On Integrating ChatGPT In CS Courses",
    "submit_datetime": "2024年04月26日",
    "abstract": "Large Language Models (LLMs) like GPT and Bard are capable of producing code based on textual descriptions, with remarkable efficacy. Such technology will have profound implications for computing education, raising concerns about cheating, excessive dependence, and a decline in computational thinking skills, among others. There has been extensive research on how teachers should handle this challenge but it is also important to understand how students feel about this paradigm shift. In this research, 52 first-year CS students were surveyed in order to assess their views on technologies with code-generation capabilities, both from academic and professional perspectives. Our findings indicate that while students generally favor the academic use of GPT, they don't over rely on it, only mildly asking for its help. Although most students benefit from GPT, some struggle to use it effectively, urging the need for specific GPT training. Opinions on GPT's impact on their professional lives vary, but there is a consensus on its importance in academic practice.",
    "pdf_link": "https://arxiv.org/abs/2404.17443",
    "graphs": [],
    "abstract_cn": "像 GPT 和 Bard 这样的大型语言模型能够根据文本描述高效生成代码，这在计算机教育领域可能引发一系列问题，包括对作弊行为、过度依赖以及计算思维能力下降的担忧。尽管已有大量研究探讨教师如何应对这一挑战，但了解学生对于这种技术变革的态度同样关键。本研究调查了52名大一计算机科学学生，旨在了解他们对具有代码生成功能技术的学术和职业看法。调查结果显示，学生们普遍认可 GPT 在学术上的用途，但并不会过度依赖它，而是适度地寻求其辅助。尽管 GPT 对大多数学生有所帮助，但也有学生在使用上存在困难，这凸显了对 GPT 特定培训的需求。关于 GPT 对他们未来职业生涯的影响，学生们的看法各异，但在学术实践中，他们普遍认为 GPT 的重要性不容忽视。",
    "title_cn": "\"ChatGPT 旨在助力，而非取代\"——探讨学生对于将 ChatGPT 整合进计算机科学课程的意见评估",
    "tags": [
      "分类：LLM应用",
      "计算机教育",
      ""
    ]
  },
  {
    "title": "InspectorRAGet: An Introspection Platform for RAG Evaluation",
    "submit_datetime": "2024年04月26日",
    "abstract": "Large Language Models (LLM) have become a popular approach for implementing Retrieval Augmented Generation (RAG) systems, and a significant amount of effort has been spent on building good models and metrics. In spite of increased recognition of the need for rigorous evaluation of RAG systems, few tools exist that go beyond the creation of model output and automatic calculation. We present InspectorRAGet, an introspection platform for RAG evaluation. InspectorRAGet allows the user to analyze aggregate and instance-level performance of RAG systems, using both human and algorithmic metrics as well as annotator quality. InspectorRAGet is suitable for multiple use cases and is available publicly to the community. The demo video is available at https://youtu.be/MJhe8QIXcEc",
    "pdf_link": "https://arxiv.org/abs/2404.17347",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLM）在构建检索增强生成（RAG）系统方面备受青睐，为此，人们投入了大量精力来开发优秀的模型和评价标准。尽管对RAG系统进行严谨评估的需求日益增长，但目前能够超越模型输出生成和自动计算的工具却相当稀缺。我们推出了InspectorRAGet，这是一个用于评估RAG系统的深度分析平台。该平台支持用户通过人工和算法评价指标，以及评估注释者的质量，来深入分析RAG系统的综合和个体表现。InspectorRAGet适用于多种应用场景，并且已经向公众开放。相关演示视频可以在 https://youtu.be/MJhe8QIXcEc 观看。",
    "title_cn": "InspectorRAGet：一个用于评估 RAG（Retrieval-Augmented Generation，检索增强生成）的内省式平台",
    "tags": [
      "RAG",
      "",
      "信息检索"
    ]
  },
  {
    "title": "When to Trust LLMs: Aligning Confidence with Response Quality",
    "submit_datetime": "2024年04月26日",
    "abstract": "Despite the success of large language models (LLMs) in natural language generation, much evidence shows that LLMs may produce incorrect or nonsensical text. This limitation highlights the importance of discerning when to trust LLMs, especially in safety-critical domains. Existing methods, which rely on verbalizing confidence to tell the reliability by inducing top-k responses and sampling-aggregating multiple responses, often fail, due to the lack of objective guidance of confidence. To address this, we propose CONfidence-Quality-ORDerpreserving alignment approach (CONQORD), leveraging reinforcement learning with a tailored dual-component reward function. This function encompasses quality reward and orderpreserving alignment reward functions. Specifically, the order-preserving reward incentivizes the model to verbalize greater confidence for responses of higher quality to align the order of confidence and quality. Experiments demonstrate that our CONQORD significantly improves the alignment performance between confidence levels and response accuracy, without causing the model to become over-cautious. Furthermore, the aligned confidence provided by CONQORD informs when to trust LLMs, and acts as a determinant for initiating the retrieval process of external knowledge. Aligning confidence with response quality ensures more transparent and reliable responses, providing better trustworthiness.",
    "pdf_link": "https://arxiv.org/abs/2404.17287",
    "graphs": [],
    "abstract_cn": "尽管大型语言模型（LLMs）在自然语言生成领域取得了显著成就，但它们有时仍会产生错误或不合逻辑的文本。这一问题凸显了在安全至关重要的领域中，如何正确信任LLMs的重要性。目前的方法，通常依赖于通过生成置信度来评估模型的可靠性，但由于缺乏客观的置信度指导，这些方法常常失效。为了改善这一状况，我们提出了一种名为CONQORD的新型方法，该方法结合了强化学习和特别设计的双重奖励机制。这种机制不仅包含质量奖励，还包括顺序保持奖励，以激励模型对更高质量的输出表达更高的置信度，从而实现置信度与质量的一致性。实验结果证明，CONQORD显著提升了置信度与响应准确性的一致性，同时避免了模型过于保守。此外，CONQORD所提供的置信度对齐机制，不仅指导我们何时可以信赖LLMs，还作为触发外部知识检索过程的关键因素。通过确保置信度与响应质量的一致性，CONQORD确保了模型提供更透明、更可靠的输出，增强了其可信度。",
    "title_cn": "信赖大型语言模型的时机：确保信心与回答品质相匹配",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Reinforcement Retrieval Leveraging Fine-grained Feedback for Fact Checking News Claims with Black-Box LLM",
    "submit_datetime": "2024年04月26日",
    "abstract": "Retrieval-augmented language models have exhibited promising performance across various areas of natural language processing (NLP), including fact-critical tasks. However, due to the black-box nature of advanced large language models (LLMs) and the non-retrieval-oriented supervision signal of specific tasks, the training of retrieval model faces significant challenges under the setting of black-box LLM. We propose an approach leveraging Fine-grained Feedback with Reinforcement Retrieval (FFRR) to enhance fact-checking on news claims by using black-box LLM. FFRR adopts a two-level strategy to gather fine-grained feedback from the LLM, which serves as a reward for optimizing the retrieval policy, by rating the retrieved documents based on the non-retrieval ground truth of the task. We evaluate our model on two public datasets for real-world news claim verification, and the results demonstrate that FFRR achieves significant improvements over strong LLM-enabled and non-LLM baselines.",
    "pdf_link": "https://arxiv.org/abs/2404.17283",
    "graphs": [],
    "abstract_cn": "检索增强型语言模型在自然语言处理（NLP）的多个领域，尤其是在关键事实任务中，表现出了显著的潜力。但是，由于高级大型语言模型（LLM）的不可预测性以及特定任务的监督信号缺乏检索导向，使得在黑箱LLM环境下训练检索模型遭遇了不小的挑战。为了提升新闻声明的事实核查能力，我们提出了一种新颖的方法——细粒度反馈与强化检索（FFRR），它利用黑箱LLM来优化事实核查过程。FFRR通过两级策略，从LLM获取细粒度的反馈信息，这些信息随后作为优化检索策略的奖励信号，通过评估检索文档与任务非检索基准真相的一致性来进行。我们在两个公共数据集上对模型进行了评估，这些数据集专门用于验证现实世界中的新闻声明，评估结果显示FFRR在与强大的LLM支持的基准模型以及非LLM的基准模型相比，实现了显著的性能提升。",
    "title_cn": "本文介绍了一种强化检索方法，该方法通过细粒度反馈来优化黑盒大型语言模型在事实核查新闻声明方面的性能。",
    "tags": [
      "LLM应用",
      "",
      ""
    ]
  },
  {
    "title": "MovieChat+: Question-aware Sparse Memory for Long Video Question Answering",
    "submit_datetime": "2024年04月26日",
    "abstract": "Recently, integrating video foundation models and large language models to build a video understanding system can overcome the limitations of specific pre-defined vision tasks. Yet, existing methods either employ complex spatial-temporal modules or rely heavily on additional perception models to extract temporal features for video understanding, and they only perform well on short videos. For long videos, the computational complexity and memory costs associated with long-term temporal connections are significantly increased, posing additional challenges.Taking advantage of the Atkinson-Shiffrin memory model, with tokens in Transformers being employed as the carriers of memory in combination with our specially designed memory mechanism, we propose MovieChat to overcome these challenges. We lift pre-trained multi-modal large language models for understanding long videos without incorporating additional trainable temporal modules, employing a zero-shot approach. MovieChat achieves state-of-the-art performance in long video understanding, along with the released MovieChat-1K benchmark with 1K long video, 2K temporal grounding labels, and 14K manual annotations for validation of the effectiveness of our method. The code along with the dataset can be accessed via the following https://github.com/rese1f/MovieChat.",
    "pdf_link": "https://arxiv.org/abs/2404.17176",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.17176v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17176/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17176v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17176/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17176v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17176/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17176v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17176/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17176v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17176/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17176v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17176/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17176v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17176/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17176v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17176/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17176v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17176/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17176v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17176/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17176v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17176/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17176v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17176/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17176v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17176/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17176v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17176/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17176v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17176/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17176v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17176/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17176v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17176/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17176v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17176/x18.png"
      }
    ],
    "abstract_cn": "近期，通过融合视频基础模型与大型语言模型，构建视频理解系统，有效突破了特定预设视觉任务的局限。不过，现有技术要么依赖复杂的时空处理模块，要么需要额外的感知模型来抽取时间特征，且主要适用于短视频。长视频的处理则面临计算复杂度和内存消耗随时间连接增长而显著上升的挑战。我们利用阿特金森-谢夫林记忆模型，并在变换器中使用令牌作为记忆载体，结合特别设计的记忆机制，提出了MovieChat解决方案。该模型通过零样本学习方式，提升了对长视频理解的预训练多模态大型语言模型性能，无需额外添加可训练的时间模块。MovieChat在长视频理解任务上达到了业界领先水平，并发布了包含1000段长视频、2000个时间定位标签和14000个手动注释的MovieChat-1K基准，用以验证方法的有效性。相关代码和数据集可在以下网址获取：https://github.com/rese1f/MovieChat。",
    "title_cn": "MovieChat+：为长篇视频问答量身定制的智能问答系统，具备问题感知的稀疏记忆功能。",
    "tags": [
      "LLM应用",
      "视频理解",
      "人工智能"
    ]
  },
  {
    "title": "A Unified Debugging Approach via LLM-Based Multi-Agent Synergy",
    "submit_datetime": "2024年04月26日",
    "abstract": "Tremendous efforts have been devoted to automating software debugging, a time-consuming process involving fault localization and repair generation. Recently, Large Language Models (LLMs) have shown great potential in automated debugging. However, we identified three challenges posed to traditional and LLM-based debugging tools: 1) the upstream imperfection of fault localization affects the downstream repair, 2) the deficiency in handling complex logic errors, and 3) the ignorance of program contexts. In this context, we propose the first automated, unified debugging framework, FixAgent, via LLM agent synergy. FixAgent can perform end-to-end localization, repair, and analysis of bugs. Our insight is that LLMs can benefit from general software engineering principles recognized by human developers in debugging, such as rubber duck debugging, enabling a better understanding of program functionality and logic bugs. Hence, we create three designs inspired by rubber ducking to address these challenges. They are agent specialization and synergy, key variable tracking, and program context comprehension, which request LLMs to provide explicit explanations and force them to focus on crucial program logic information. Experiments on the widely used dataset QuixBugs show that FixAgent correctly fixes 79 out of 80 bugs, 9 of which have never been fixed. It also plausibly patches 1.9X more defects than the best-performing repair tool on CodeFlaws, even with no bug location information and fewer than 0.6% sampling times. On average, FixAgent increases about 20% plausible and correct fixes compared to its base model using different LLMs, showing the effectiveness of our designs. Moreover, the correctness rate of FixAgent reaches remarkably 97.26%, indicating that FixAgent can potentially overcome the overfitting issue of the existing approaches.",
    "pdf_link": "https://arxiv.org/abs/2404.17153",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.17153v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17153/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17153v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17153/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17153v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17153/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17153v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17153/x4.png"
      }
    ],
    "abstract_cn": "为了简化软件调试这一繁琐过程，包括故障定位和修复生成，人们投入了巨大的努力。近期，大型语言模型（LLMs）在自动化调试领域展现出巨大潜力。尽管如此，我们发现传统及基于LLM的调试工具面临三大挑战：故障定位的不精确性会波及后续的修复工作；在处理复杂逻辑错误方面的不足；以及对程序上下文的忽略。针对这些问题，我们首次提出了一个自动化、集成的调试框架——FixAgent，它通过LLM代理的协同作用实现。FixAgent能够一站式完成漏洞的定位、修复和分析。我们洞察到，LLMs可以借鉴人类开发者在调试过程中采用的通用软件工程原则，例如橡皮鸭调试法，以促进对程序功能和逻辑错误的深入理解。因此，我们设计了三种受橡皮鸭调试法启发的机制来应对这些挑战：代理的专业化与协同、关键变量追踪以及程序上下文理解，这些机制要求LLMs提供清晰的解释，并引导它们关注程序逻辑的关键信息。在广泛使用的QuixBugs数据集上的测试显示，FixAgent成功修复了80个漏洞中的79个，其中9个是之前未被修复的。即便在没有漏洞位置信息和低于0.6%的采样次数的条件下，它在CodeFlaws上修复的缺陷数量也比最佳修复工具多1.9倍。平均来说，与使用不同LLMs的基础模型相比，FixAgent在合理和正确修复方面提升了大约20%，证明了我们设计的成效。此外，FixAgent的正确率高达97.26%，这表明它可能有能力解决现有方法中存在的过拟合问题。",
    "title_cn": "本文提出了一种基于大型语言模型（LLM）的多代理协同统一调试方法，旨在优化调试流程，提高问题解决效率。",
    "tags": [
      "Agent",
      "软件工程",
      "自动化调试"
    ]
  },
  {
    "title": "Quantifying Memorization of Domain-Specific Pre-trained Language Models using Japanese Newspaper and Paywalls",
    "submit_datetime": "2024年04月26日",
    "abstract": "Dominant pre-trained language models (PLMs) have been successful in high-quality natural language generation. However, the analysis of their generation is not mature: do they acquire generalizable linguistic abstractions, or do they simply memorize and recover substrings of the training data? Especially, few studies focus on domain-specific PLM. In this study, we pre-trained domain-specific GPT-2 models using a limited corpus of Japanese newspaper articles and quantified memorization of training data by comparing them with general Japanese GPT-2 models. Our experiments revealed that domain-specific PLMs sometimes \"copy and paste\" on a large scale. Furthermore, we replicated the empirical finding that memorization is related to duplication, model size, and prompt length, in Japanese the same as in previous English studies. Our evaluations are relieved from data contamination concerns by focusing on newspaper paywalls, which prevent their use as training data. We hope that our paper encourages a sound discussion such as the security and copyright of PLMs.",
    "pdf_link": "https://arxiv.org/abs/2404.17143",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.17143v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17143/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17143v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17143/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17143v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17143/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17143v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17143/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17143v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17143/experimental_result.png"
      }
    ],
    "abstract_cn": "主流的预训练语言模型（PLMs）在自然语言生成的高品质输出上取得了显著成就。但对于它们的生成机制，我们的理解尚不成熟：这些模型究竟是掌握了通用的语言抽象能力，还是仅仅记住并复现了训练数据中的片段？特别是，针对特定领域的PLMs的研究更是寥寥无几。本研究中，我们利用有限的日本报纸文章集合，预训练了特定领域的GPT-2模型，并通过与通用的日本GPT-2模型的比较，量化了对训练数据的记忆力。实验结果显示，特定领域的PLMs有时会大规模地进行“复制粘贴”操作。此外，我们还复现了之前在英语研究中发现的现象：记忆力与复制行为、模型大小和提示长度有关，这一现象在日本语中同样存在。我们的评估通过专注于报纸的付费内容，避免了数据污染的问题，因为这些内容不会被用作训练材料。我们期望本文能够促进关于PLMs安全性和版权等问题的深入讨论。",
    "title_cn": "本文旨在通过日本报纸和付费墙的方式，探究特定领域预训练语言模型的记忆量化问题。",
    "tags": [
      "LLM理论",
      "",
      ""
    ]
  },
  {
    "title": "Human-Imperceptible Retrieval Poisoning Attacks in LLM-Powered Applications",
    "submit_datetime": "2024年04月26日",
    "abstract": "Presently, with the assistance of advanced LLM application development frameworks, more and more LLM-powered applications can effortlessly augment the LLMs' knowledge with external content using the retrieval augmented generation (RAG) technique. However, these frameworks' designs do not have sufficient consideration of the risk of external content, thereby allowing attackers to undermine the applications developed with these frameworks. In this paper, we reveal a new threat to LLM-powered applications, termed retrieval poisoning, where attackers can guide the application to yield malicious responses during the RAG process. Specifically, through the analysis of LLM application frameworks, attackers can craft documents visually indistinguishable from benign ones. Despite the documents providing correct information, once they are used as reference sources for RAG, the application is misled into generating incorrect responses. Our preliminary experiments indicate that attackers can mislead LLMs with an 88.33\\% success rate, and achieve a 66.67\\% success rate in the real-world application, demonstrating the potential impact of retrieval poisoning.",
    "pdf_link": "https://arxiv.org/abs/2404.17196",
    "graphs": [],
    "abstract_cn": "当前，借助尖端的大型语言模型（LLM）应用开发框架，越来越多的LLM应用能够通过检索增强生成（RAG）技术轻松扩充其知识库。但这些框架在设计上对外部内容风险的考虑不足，容易让攻击者有机可乘。本文揭露了LLM应用面临的一个新风险——检索投毒，攻击者借此可以操纵应用在RAG过程中生成恶意回应。攻击者通过分析LLM应用框架，精心制作出外观上与正常文档无异的文档，这些文档虽提供正确信息，但一旦作为RAG的参考，却能误导应用产生错误结果。我们的初步实验显示，攻击者能够以88.33%的高成功率误导LLM，且在现实世界应用中的成功率也高达66.67%，这充分说明了检索投毒的严重性及其潜在的广泛影响。",
    "title_cn": "在大型语言模型（LLM）支持的应用程序中，悄然兴起了一种难以为人所察觉的检索投毒攻击。",
    "tags": [
      "分类：LLM应用",
      "网络安全",
      "人工智能"
    ]
  },
  {
    "title": "Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering",
    "submit_datetime": "2024年04月26日",
    "abstract": "In customer service technical support, swiftly and accurately retrieving relevant past issues is critical for efficiently resolving customer inquiries. The conventional retrieval methods in retrieval-augmented generation (RAG) for large language models (LLMs) treat a large corpus of past issue tracking tickets as plain text, ignoring the crucial intra-issue structure and inter-issue relations, which limits performance. We introduce a novel customer service question-answering method that amalgamates RAG with a knowledge graph (KG). Our method constructs a KG from historical issues for use in retrieval, retaining the intra-issue structure and inter-issue relations. During the question-answering phase, our method parses consumer queries and retrieves related sub-graphs from the KG to generate answers. This integration of a KG not only improves retrieval accuracy by preserving customer service structure information but also enhances answering quality by mitigating the effects of text segmentation. Empirical assessments on our benchmark datasets, utilizing key retrieval (MRR, Recall@K, NDCG@K) and text generation (BLEU, ROUGE, METEOR) metrics, reveal that our method outperforms the baseline by 77.6% in MRR and by 0.32 in BLEU. Our method has been deployed within LinkedIn's customer service team for approximately six months and has reduced the median per-issue resolution time by 28.6%.",
    "pdf_link": "https://arxiv.org/abs/2404.17723",
    "graphs": [],
    "abstract_cn": "在客户服务的技术支持环节，迅速准确地调取与过往问题相关的信息对于迅速解决客户咨询极为关键。传统上，大型语言模型（LLMs）中用于增强检索生成（RAG）的方法将历史问题跟踪票据视为普通文本，忽略了问题内部结构和问题间的联系，这大大限制了其效能。我们提出了一种创新的客户服务问答方法，该方法将RAG与知识图谱（KG）相结合。此方法利用历史数据构建KG，以保留问题内部结构和问题间的联系，用于信息检索。在问答环节，通过解析用户查询并从KG中调取相关子图来生成答案。这种KG的融合不仅通过保持客户服务的结构信息提升了检索的精确度，同时也通过减少文本分割的影响提升了回答的质量。基于我们的关键检索（MRR，Recall@K，NDCG@K）和文本生成（BLEU，ROUGE，METEOR）指标的基准数据集的实证评估显示，我们的方法在MRR上比基线提升了77.6%，在BLEU上提升了0.32。该方法已在LinkedIn客户服务团队中应用了大约六个月，成功将每个问题的平均解决时间缩短了28.6%。",
    "title_cn": "利用知识图谱提升检索生成技术，优化客户服务中的问答环节。",
    "tags": [
      "分类：RAG",
      "客户服务",
      "知识图谱"
    ]
  },
  {
    "title": "CoMM: Collaborative Multi-Agent, Multi-Reasoning-Path Prompting for Complex Problem Solving",
    "submit_datetime": "2024年04月26日",
    "abstract": "Large Language Models (LLMs) have shown great ability in solving traditional natural language tasks and elementary reasoning tasks with appropriate prompting techniques. However, their ability is still limited in solving complicated science problems. In this work, we aim to push the upper bound of the reasoning capability of LLMs by proposing a collaborative multi-agent, multi-reasoning-path (CoMM) prompting framework. Specifically, we prompt LLMs to play different roles in a problem-solving team, and encourage different role-play agents to collaboratively solve the target task. In particular, we discover that applying different reasoning paths for different roles is an effective strategy to implement few-shot prompting approaches in the multi-agent scenarios. Empirical results demonstrate the effectiveness of the proposed methods on two college-level science problems over competitive baselines. Our further analysis shows the necessity of prompting LLMs to play different roles or experts independently. We release the code at: https://github.com/amazon-science/comm-prompt",
    "pdf_link": "https://arxiv.org/abs/2404.17729",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.17729v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17729/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17729v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17729/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17729v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17729/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17729v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17729/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17729v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17729/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17729v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17729/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17729v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17729/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17729v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17729/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17729v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17729/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17729v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17729/x10.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）在解决传统自然语言处理任务和基础推理任务方面展现出卓越能力，但面对复杂科学问题时，它们的解决能力仍有局限。本研究致力于通过引入协作多代理、多推理路径（CoMM）的提示框架，提升LLMs的推理能力。我们引导LLMs在解决问题的团队中各司其职，并促进角色扮演的代理协同攻关。特别是，我们发现为不同角色设计不同的推理路径，是实现多代理场景下少次提示的有效策略。实验结果显示，该方法在两个大学级别的科学问题上优于现有基准。深入分析进一步证实了让LLMs独立扮演多样角色或专家的必要性。相关代码已在以下链接发布：https://github.com/amazon-science/comm-prompt",
    "title_cn": "CoMM：协同多智能体，多路径推理提示，助力解决复杂问题。",
    "tags": [
      "分类：Agent",
      "",
      ""
    ]
  },
  {
    "title": "PLAYER*: Enhancing LLM-based Multi-Agent Communication and Interaction in Murder Mystery Games",
    "submit_datetime": "2024年04月26日",
    "abstract": "Recent advancements in Large Language Models (LLMs) have enhanced the efficacy of agent communication and social interactions. Despite these advancements, building LLM-based agents for reasoning in dynamic environments involving competition and collaboration remains challenging due to the limitations of informed graph-based search methods. We propose PLAYER*, a novel framework based on an anytime sampling-based planner, which utilises sensors and pruners to enable a purely question-driven searching framework for complex reasoning tasks. We also introduce a quantifiable evaluation method using multiple-choice questions and construct the WellPlay dataset with 1,482 QA pairs. Experiments demonstrate PLAYER*'s efficiency and performance enhancements compared to existing methods in complex, dynamic environments with quantifiable results.",
    "pdf_link": "https://arxiv.org/abs/2404.17662",
    "graphs": [],
    "abstract_cn": "最新进展让大型语言模型（LLMs）在提升代理间的交流和社交互动方面取得了显著成效。尽管如此，由于现有信息图搜索方法的局限，开发能在竞争与合作并存的动态环境中进行推理的LLM代理仍然充满挑战。为此，我们提出了PLAYER*，这是一个创新的框架，它基于即时采样规划器，通过传感器和修剪器来构建一个完全由问题驱动的搜索框架，专门用于处理复杂的推理任务。此外，我们还开发了一种使用多项选择题进行量化评估的方法，并创建了包含1,482对问答的WellPlay数据集。实验结果证明，PLAYER*在处理复杂动态环境的任务时，其效率和性能均超越了现有方法，且提升效果是可以量化的。",
    "title_cn": "PLAYER*：提升基于大型语言模型的多智能体在谋杀谜题游戏中的沟通与互动",
    "tags": [
      "Agent",
      "社交互动",
      "代理推理"
    ]
  },
  {
    "title": "UMass-BioNLP at MEDIQA-M3G 2024: DermPrompt -- A Systematic Exploration of Prompt Engineering with GPT-4V for Dermatological Diagnosis",
    "submit_datetime": "2024年04月26日",
    "abstract": "This paper presents our team's participation in the MEDIQA-ClinicalNLP2024 shared task B. We present a novel approach to diagnosing clinical dermatology cases by integrating large multimodal models, specifically leveraging the capabilities of GPT-4V under a retriever and a re-ranker framework. Our investigation reveals that GPT-4V, when used as a retrieval agent, can accurately retrieve the correct skin condition 85% of the time using dermatological images and brief patient histories. Additionally, we empirically show that Naive Chain-of-Thought (CoT) works well for retrieval while Medical Guidelines Grounded CoT is required for accurate dermatological diagnosis. Further, we introduce a Multi-Agent Conversation (MAC) framework and show its superior performance and potential over the best CoT strategy. The experiments suggest that using naive CoT for retrieval and multi-agent conversation for critique-based diagnosis, GPT-4V can lead to an early and accurate diagnosis of dermatological conditions. The implications of this work extend to improving diagnostic workflows, supporting dermatological education, and enhancing patient care by providing a scalable, accessible, and accurate diagnostic tool.",
    "pdf_link": "https://arxiv.org/abs/2404.17749",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.17749v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17749/method.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17749v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17749/MAC_final.png"
      }
    ],
    "abstract_cn": "本论文展示了我们团队参与 MEDIQA-ClinicalNLP2024 共享任务 B 的成果。我们采用了一种创新的方法，通过融合大型多模态模型来诊断临床皮肤科病例，尤其是利用 GPT-4V 在检索和重排系统中的应用。研究发现，GPT-4V 作为检索工具时，能够凭借皮肤图像和患者简史，85% 的时间准确识别出正确的皮肤状况。我们还证实了，朴素链式思维（CoT）在检索中效果显著，而基于医学指南的 CoT 对于精确的皮肤科诊断至关重要。此外，我们引入了多代理对话（MAC）框架，并通过实验验证了其相较于最佳 CoT 策略的卓越性能和潜力。研究指出，结合朴素 CoT 检索和基于批评的多代理对话诊断，GPT-4V 有助于实现皮肤科疾病的早期和精确诊断。这项研究不仅推动了诊断流程的优化，还有助于皮肤科教育的发展，并为患者护理提供了一种高效、便捷、准确的诊断工具。",
    "title_cn": "UMass-BioNLP 团队在 2024 年 MEDIQA-M3G 竞赛中推出了 DermPrompt，这是一个针对皮肤科诊断的系统化提示工程探索项目，利用 GPT-4V 技术深入挖掘和优化诊断流程。",
    "tags": [
      "分类：LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Learning Manipulation Tasks in Dynamic and Shared 3D Spaces",
    "submit_datetime": "2024年04月26日",
    "abstract": "Automating the segregation process is a need for every sector experiencing a high volume of materials handling, repetitive and exhaustive operations, in addition to risky exposures. Learning automated pick-and-place operations can be efficiently done by introducing collaborative autonomous systems (e.g. manipulators) in the workplace and among human operators. In this paper, we propose a deep reinforcement learning strategy to learn the place task of multi-categorical items from a shared workspace between dual-manipulators and to multi-goal destinations, assuming the pick has been already completed. The learning strategy leverages first a stochastic actor-critic framework to train an agent's policy network, and second, a dynamic 3D Gym environment where both static and dynamic obstacles (e.g. human factors and robot mate) constitute the state space of a Markov decision process. Learning is conducted in a Gazebo simulator and experiments show an increase in cumulative reward function for the agent further away from human factors. Future investigations will be conducted to enhance the task performance for both agents simultaneously.",
    "pdf_link": "https://arxiv.org/abs/2404.17673",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.17673v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17673/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17673v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17673/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17673v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17673/sampled_pointcloud.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17673v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17673/predicted_pointcloud.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17673v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17673/pipeline_with_links.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17673v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17673/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17673v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17673/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17673v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17673/robot1_training.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17673v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17673/robot2_training.png"
      }
    ],
    "abstract_cn": "对于任何面临大量物料处理、重复性操作和潜在风险的行业而言，实现分离流程的自动化是迫切需求。通过引入协作式自主系统，如机械臂，可以高效地掌握自动化的拣选与放置操作。本文提出了一种深度强化学习策略，旨在教导代理如何在双机械手共享的工作空间中识别多类物品，并将它们放置到多个预定目标地点，前提是拣选动作已经完成。该策略首先采用随机演员-评论家框架来训练代理的策略网络，然后利用一个包含静态和动态障碍物（如人为因素和机器人伙伴）的动态3D Gym环境，构建马尔可夫决策过程的状态空间。在Gazebo模拟器中进行的学习实验显示，远离人为因素的代理累积奖励函数有所提升。未来的研究将进一步探索，以同步提升两个代理的任务执行效率。",
    "title_cn": "探索在动态且共享的三维空间里执行操控任务的学习过程。",
    "tags": [
      "Agent",
      "工业自动化",
      "机器人技术"
    ]
  },
  {
    "title": "Impact of Traffic-Following on Order of Autonomous Airspace Operations",
    "submit_datetime": "2024年04月26日",
    "abstract": "In this paper, we investigate the dynamic emergence of traffic order in a distributed multi-agent system, aiming to minimize inefficiencies that stem from unnecessary structural impositions. We introduce a methodology for developing a dynamically-updating traffic pattern map of the airspace by leveraging information about the consistency and frequency of flow directions used by current as well as preceding traffic. Informed by this map, an agent can discern the degree to which it is advantageous to follow traffic by trading off utilities such as time and order. We show that for the traffic levels studied, for low degrees of traffic-following behavior, there is minimal penalty in terms of aircraft travel times while improving the overall orderliness of the airspace. On the other hand, heightened traffic-following behavior may result in increased aircraft travel times, while marginally reducing the overall entropy of the airspace. Ultimately, the methods and metrics presented in this paper can be used to optimally and dynamically adjust an agent's traffic-following behavior based on these trade-offs.",
    "pdf_link": "https://arxiv.org/abs/2404.17627",
    "graphs": [],
    "abstract_cn": "本文深入探讨了在分布式多智能体系统中，如何通过最小化不必要的结构性限制来动态形成交通秩序。我们提出了一种创新的方法，通过分析当前和历史交通流向的一致性与频率，构建并实时更新空域的交通模式图。借助这一地图，智能体能够评估遵循交通流的效益，从而在时间和秩序之间做出权衡。研究表明，在低度遵循交通行为的情况下，飞机的旅行时间几乎不受影响，却能显著提升空域的有序性。然而，过度的交通跟随可能会增加飞行时间，尽管如此，它也能在一定程度上降低空域的总体混乱度。本研究提出的方法和评价指标，将有助于智能体基于这些权衡，进行最优和动态的交通行为调整。",
    "title_cn": "交通跟随行为对自动空中管制序列的影响",
    "tags": [
      "Agent",
      "交通管理",
      "智能体系统"
    ]
  },
  {
    "title": "Quantum Multi-Agent Reinforcement Learning for Aerial Ad-hoc Networks",
    "submit_datetime": "2024年04月26日",
    "abstract": "Quantum machine learning (QML) as combination of quantum computing with machine learning (ML) is a promising direction to explore, in particular due to the advances in realizing quantum computers and the hoped-for quantum advantage. A field within QML that is only little approached is quantum multi-agent reinforcement learning (QMARL), despite having shown to be potentially attractive for addressing industrial applications such as factory management, cellular access and mobility cooperation. This paper presents an aerial communication use case and introduces a hybrid quantum-classical (HQC) ML algorithm to solve it. This use case intends to increase the connectivity of flying ad-hoc networks and is solved by an HQC multi-agent proximal policy optimization algorithm in which the core of the centralized critic is replaced with a data reuploading variational quantum circuit. Results show a slight increase in performance for the quantum-enhanced solution with respect to a comparable classical algorithm, earlier reaching convergence, as well as the scalability of such a solution: an increase in the size of the ansatz, and thus also in the number of trainable parameters, leading to better outcomes. These promising results show the potential of QMARL to industrially-relevant complex use cases.",
    "pdf_link": "https://arxiv.org/abs/2404.17499",
    "graphs": [],
    "abstract_cn": "量子机器学习（QML），作为量子计算与机器学习（ML）结合的前沿领域，因其在量子计算机实现和量子优势预期方面的进展而备受瞩目。然而，QML中的一个较少被触及的子领域——量子多智能体强化学习（QMARL），尽管其在处理如工厂管理、蜂窝接入和移动性合作等工业应用方面显示出巨大潜力。本文通过一个空中通信的实例，引入了一种混合量子-经典（HQC）机器学习算法来应对挑战。该实例的目标是提升飞行自组织网络的连接性，通过HQC多智能体近端策略优化算法实现，该算法将集中式批评器核心替换为数据重新上传的变分量子电路。研究结果显示，量子增强解决方案在性能上略有提升，更快达到收敛，并且展现出良好的可扩展性：随着ansatz大小的增加，即训练参数数量的增加，可以获得更优的结果。这些充满希望的成果揭示了QMARL在解决工业界复杂应用场景中的潜力。",
    "title_cn": "本文探讨了量子多智能体强化学习在构建空中临时网络中的应用。",
    "tags": [
      "Agent",
      "量子计算",
      "工业自动化"
    ]
  },
  {
    "title": "A multi-agent model of hierarchical decision dynamics",
    "submit_datetime": "2024年04月26日",
    "abstract": "Decision making can be difficult when there are many actors (or agents) who may be coordinating or competing to achieve their various ideas of the optimum outcome. Here I present a simple decision making model with an explicitly hierarchical binary-tree structure, and evaluate how this might cooperate to take actions that match its various evaluations of the uncertain state of the world. Key features of agent behaviour are (a) the separation of its decision making process into three distinct steps: observation, judgement, and action; and (b) the evolution of coordination by the sharing of judgements.",
    "pdf_link": "https://arxiv.org/abs/2404.17477",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.17477v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17477/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17477v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17477/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17477v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17477/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17477v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17477/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17477v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17477/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17477v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17477/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17477v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17477/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17477v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17477/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17477v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17477/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17477v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17477/x10.png"
      }
    ],
    "abstract_cn": "在众多参与者可能追求各自最优结果而需协调或竞争的情境下，做出决策可能颇具挑战。本文介绍了一种结构清晰的分层二叉树决策模型，并探讨了该模型如何通过合作来采取与其对世界不确定性状态的不同评估相匹配的行动。该代理行为的显著特点包括：（a）决策过程被划分为观察、判断和行动三个独立阶段；（b）通过共享判断来促进协调机制的发展。",
    "title_cn": "一个分层决策过程的多智能体模型",
    "tags": [
      "Agent",
      "决策模型",
      "协调机制"
    ]
  },
  {
    "title": "Make-it-Real: Unleashing Large Multimodal Model's Ability for Painting 3D Objects with Realistic Materials",
    "submit_datetime": "2024年04月25日",
    "abstract": "Physically realistic materials are pivotal in augmenting the realism of 3D assets across various applications and lighting conditions. However, existing 3D assets and generative models often lack authentic material properties. Manual assignment of materials using graphic software is a tedious and time-consuming task. In this paper, we exploit advancements in Multimodal Large Language Models (MLLMs), particularly GPT-4V, to present a novel approach, Make-it-Real: 1) We demonstrate that GPT-4V can effectively recognize and describe materials, allowing the construction of a detailed material library. 2) Utilizing a combination of visual cues and hierarchical text prompts, GPT-4V precisely identifies and aligns materials with the corresponding components of 3D objects. 3) The correctly matched materials are then meticulously applied as reference for the new SVBRDF material generation according to the original diffuse map, significantly enhancing their visual authenticity. Make-it-Real offers a streamlined integration into the 3D content creation workflow, showcasing its utility as an essential tool for developers of 3D assets.",
    "pdf_link": "https://arxiv.org/abs/2404.16829",
    "graphs": [],
    "abstract_cn": "物理真实感材料对于提升3D资产在不同应用和光照条件下的真实度起着关键作用。但目前3D资产和生成模型往往缺少真实的材质属性。手动通过图形软件分配材质既繁琐又耗时。本文中，我们借助多模态大型语言模型（MLLMs），尤其是GPT-4V，提出了一种创新方法“Make-it-Real”：首先，我们展示了GPT-4V在识别和描述材质方面的高效能力，这有助于构建一个详尽的材质库；其次，通过结合视觉线索和层级化文本提示，GPT-4V能够精确地识别并匹配3D对象的相应部件的材质；最后，正确匹配的材质被精心应用于新的SVBRDF材质生成过程，以原始漫反射图为参考，显著提升了视觉真实感。“Make-it-Real”作为一个高效的工具，为3D内容创作流程提供了简化的集成方案，对3D资产开发者来说极具价值。",
    "title_cn": "实现真实：释放大型多模态模型的潜力，以绘制采用逼真材质的三维物体。",
    "tags": [
      "LLM应用",
      "3D建模",
      "人工智能"
    ]
  },
  {
    "title": "How Far Are We to GPT-4V? Closing the Gap to Commercial Multimodal Models with Open-Source Suites",
    "submit_datetime": "2024年04月25日",
    "abstract": "In this report, we introduce InternVL 1.5, an open-source multimodal large language model (MLLM) to bridge the capability gap between open-source and proprietary commercial models in multimodal understanding. We introduce three simple improvements: (1) Strong Vision Encoder: we explored a continuous learning strategy for the large-scale vision foundation model -- InternViT-6B, boosting its visual understanding capabilities, and making it can be transferred and reused in different LLMs. (2) Dynamic High-Resolution: we divide images into tiles ranging from 1 to 40 of 448$\\times$448 pixels according to the aspect ratio and resolution of the input images, which supports up to 4K resolution input. (3) High-Quality Bilingual Dataset: we carefully collected a high-quality bilingual dataset that covers common scenes, document images, and annotated them with English and Chinese question-answer pairs, significantly enhancing performance in OCR- and Chinese-related tasks. We evaluate InternVL 1.5 through a series of benchmarks and comparative studies. Compared to both open-source and proprietary models, InternVL 1.5 shows competitive performance, achieving state-of-the-art results in 8 of 18 benchmarks. Code has been released at https://github.com/OpenGVLab/InternVL.",
    "pdf_link": "https://arxiv.org/abs/2404.16821",
    "graphs": [],
    "abstract_cn": "本报告向您展示了InternVL 1.5，这是一款开源的多模态大型语言模型（MLLM），致力于缩小开源与商业专有模型在多模态理解领域的能力差距。我们带来了三项创新：（1）强化视觉编码器，通过持续学习策略优化了大规模视觉基础模型InternViT-6B，提升了视觉理解力，并便于在各类大型语言模型中迁移与复用。（2）动态高分辨率处理，根据输入图像的比例和分辨率，将图像分割成448×448像素的1至40块，支持最高4K分辨率的输入。（3）精心构建的高质量双语数据集，覆盖了日常生活场景和文档图像，并配有中英文问答对，显著提升了OCR及中文任务的处理能力。在一系列基准测试和对比研究中，InternVL 1.5与开源及商业模型相比，展现出了竞争力，在18个基准测试中的8个上达到了领先水平。相关代码已在GitHub上发布。",
    "title_cn": "我们距离 GPT-4V 还有多远？通过开源工具集，我们正逐步缩小与商业多模态模型之间的差距。",
    "tags": [
      "分类：LLM应用",
      "人工智能",
      "多模态理解"
    ]
  },
  {
    "title": "IndicGenBench: A Multilingual Benchmark to Evaluate Generation Capabilities of LLMs on Indic Languages",
    "submit_datetime": "2024年04月25日",
    "abstract": "As large language models (LLMs) see increasing adoption across the globe, it is imperative for LLMs to be representative of the linguistic diversity of the world. India is a linguistically diverse country of 1.4 Billion people. To facilitate research on multilingual LLM evaluation, we release IndicGenBench - the largest benchmark for evaluating LLMs on user-facing generation tasks across a diverse set 29 of Indic languages covering 13 scripts and 4 language families. IndicGenBench is composed of diverse generation tasks like cross-lingual summarization, machine translation, and cross-lingual question answering. IndicGenBench extends existing benchmarks to many Indic languages through human curation providing multi-way parallel evaluation data for many under-represented Indic languages for the first time. We evaluate a wide range of proprietary and open-source LLMs including GPT-3.5, GPT-4, PaLM-2, mT5, Gemma, BLOOM and LLaMA on IndicGenBench in a variety of settings. The largest PaLM-2 models performs the best on most tasks, however, there is a significant performance gap in all languages compared to English showing that further research is needed for the development of more inclusive multilingual language models. IndicGenBench is released at www.github.com/google-research-datasets/indic-gen-bench",
    "pdf_link": "https://arxiv.org/abs/2404.16816",
    "graphs": [],
    "abstract_cn": "随着大型语言模型（LLMs）在全球的广泛应用，确保它们能够体现全球语言多样性变得至关重要。印度，一个拥有14亿人口的多语言国家，为我们提供了丰富的研究素材。为了推动多语言LLM评估研究，我们推出了IndicGenBench——这是目前规模最大的基准测试平台，旨在评估LLM在29种印度语言上的用户生成任务表现，这些语言涵盖了13种不同的文字系统和4个语言系。IndicGenBench包含多种生成任务，包括跨语言摘要、机器翻译和跨语言问答等。该平台通过人工精选，首次为多种印度语言提供了多维度的并行评估数据，极大地扩展了现有基准测试的覆盖范围。我们在多种场景下对一系列商业和开源的LLMs进行了评估，包括GPT-3.5、GPT-4、PaLM-2、mT5、Gemma、BLOOM和LLaMA。其中，PaLM-2的最大模型在大多数任务上表现最为出色。然而，所有印度语言与英语相比仍有较大的性能差距，这表明我们仍需深化研究，以发展出更加全面和包容的多语言语言模型。IndicGenBench目前已在www.github.com/google-research-datasets/indic-gen-bench上线。",
    "title_cn": "IndicGenBench：一项多语言评估基准，旨在衡量大型语言模型在印度诸语言上的表现力。",
    "tags": [
      "LLM应用",
      "",
      "机器翻译"
    ]
  },
  {
    "title": "Make Your LLM Fully Utilize the Context",
    "submit_datetime": "2024年04月25日",
    "abstract": "While many contemporary large language models (LLMs) can process lengthy input, they still struggle to fully utilize information within the long context, known as the lost-in-the-middle challenge. We hypothesize that it stems from insufficient explicit supervision during the long-context training, which fails to emphasize that any position in a long context can hold crucial information. Based on this intuition, our study presents information-intensive (IN2) training, a purely data-driven solution to overcome lost-in-the-middle. Specifically, IN2 training leverages a synthesized long-context question-answer dataset, where the answer requires (1) fine-grained information awareness on a short segment (~128 tokens) within a synthesized long context (4K-32K tokens), and (2) the integration and reasoning of information from two or more short segments. Through applying this information-intensive training on Mistral-7B, we present FILM-7B (FILl-in-the-Middle). To thoroughly assess the ability of FILM-7B for utilizing long contexts, we design three probing tasks that encompass various context styles (document, code, and structured-data context) and information retrieval patterns (forward, backward, and bi-directional retrieval). The probing results demonstrate that FILM-7B can robustly retrieve information from different positions in its 32K context window. Beyond these probing tasks, FILM-7B significantly improves the performance on real-world long-context tasks (e.g., 23.5->26.9 F1 score on NarrativeQA), while maintaining a comparable performance on short-context tasks (e.g., 59.3->59.2 accuracy on MMLU). Github Link: https://github.com/microsoft/FILM.",
    "pdf_link": "https://arxiv.org/abs/2404.16811",
    "graphs": [],
    "abstract_cn": "当前众多先进的大型语言模型虽能处理长篇输入，却常在充分利用长文本信息时力不从心，这一现象被称为“迷失于中间”的难题。我们假设这一问题源于在长文本训练时缺乏充分的显式指导，未能突出长文本中任意位置都可能蕴含重要信息。基于此洞察，本研究引入了信息密集型（IN2）训练方法，这是一种纯粹基于数据驱动的解决方案，用以攻克“迷失于中间”的挑战。IN2训练特别采用了一个合成的长文本问答数据集，该数据集中的问题答案需要对长文本中的一个短小片段（约128个令牌）进行细致的信息感知，并整合推理来自两个或更多短片段的信息。我们将这种信息密集型训练应用于Mistral-7B模型，进而推出了FILM-7B（意为填补中间的空白）。为全面测试FILM-7B处理长文本的能力，我们设计了三种探索性任务，覆盖了多样的文本风格和信息检索方式。测试结果证明，FILM-7B能从其32K的上下文窗口中稳健地提取信息。此外，FILM-7B在现实世界的长文本任务中显著提升了性能，例如在NarrativeQA任务上的F1分数从23.5提升至26.9，同时在短文本任务上也保持了相当的性能，如在MMLU任务上的准确率从59.3微降至59.2。项目代码已在GitHub上公开：https://github.com/microsoft/FILM。",
    "title_cn": "充分发挥您的大型语言模型的上下文理解能力",
    "tags": [
      "LLM理论",
      "",
      "信息检索"
    ]
  },
  {
    "title": "Improving Diversity of Commonsense Generation by Large Language Models via In-Context Learning",
    "submit_datetime": "2024年04月25日",
    "abstract": "Generative Commonsense Reasoning (GCR) requires a model to reason about a situation using commonsense knowledge, while generating coherent sentences. Although the quality of the generated sentences is crucial, the diversity of the generation is equally important because it reflects the model's ability to use a range of commonsense knowledge facts. Large Language Models (LLMs) have shown proficiency in enhancing the generation quality across various tasks through in-context learning (ICL) using given examples without the need for any fine-tuning. However, the diversity aspect in LLM outputs has not been systematically studied before. To address this, we propose a simple method that diversifies the LLM generations, while preserving their quality. Experimental results on three benchmark GCR datasets show that our method achieves an ideal balance between the quality and diversity. Moreover, the sentences generated by our proposed method can be used as training data to improve diversity in existing commonsense generators.",
    "pdf_link": "https://arxiv.org/abs/2404.16807",
    "graphs": [],
    "abstract_cn": 