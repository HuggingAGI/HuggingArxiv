[
  {
    "title": "Linearizing Large Language Models",
    "submit_datetime": "2024年05月10日",
    "abstract": "Linear transformers have emerged as a subquadratic-time alternative to softmax attention and have garnered significant interest due to their fixed-size recurrent state that lowers inference cost. However, their original formulation suffers from poor scaling and underperforms compute-matched transformers. Recent linear models such as RWKV and Mamba have attempted to address these shortcomings by proposing novel time-mixing and gating architectures, but pre-training large language models requires significant data and compute investments. Thus, the search for subquadratic architectures is limited by the availability of compute and quality pre-training datasets. As a cost-effective alternative to pre-training linear transformers, we propose Scalable UPtraining for Recurrent Attention (SUPRA). We present a method to uptrain existing large pre-trained transformers into Recurrent Neural Networks (RNNs) with a modest compute budget. This allows us to leverage the strong pre-training data and performance of existing transformer LLMs, while requiring 5% of the training cost. We find that our linearization technique leads to competitive performance on standard benchmarks, but we identify persistent in-context learning and long-context modeling shortfalls for even the largest linear models. Our code and models can be found at https://github.com/TRI-ML/linear_open_lm.",
    "pdf_link": "https://arxiv.org/abs/2405.06640",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.06640v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06640/fig1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06640v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06640/fig2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06640v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06640/attention_qkv_log_mistral_cosine_similarity.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06640v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06640/attention_qkv_log_mistral_svd_distance.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06640v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06640/attention_qkv_log_mistral_cosine_similarity_normalized.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06640v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06640/attention_qkv_log_mistral_svd_distance_normalized.png"
      }
    ],
    "abstract_cn": "线性变换器因其固定大小的循环状态降低了推理成本，成为亚二次时间复杂度的softmax注意力替代方案，备受瞩目。然而，其原始设计在扩展性和性能上存在缺陷。RWKV和Mamba等模型试图通过创新的时间混合和门控机制来弥补这些不足，但预训练大型语言模型仍需巨额数据和计算资源。因此，探索亚二次架构受限于计算资源和高质量数据集的可用性。我们提出SUPRA，一种经济高效的循环注意力升级训练方法，将现有大型预训练变换器转化为RNN，仅需5%的训练成本，同时保留了变换器LLMs的强大预训练优势。我们的线性化技术在标准测试中表现出色，但我们也注意到，即使在最大的线性模型中，上下文学习和长上下文建模仍存在挑战。我们的代码和模型可在https://github.com/TRI-ML/linear_open_lm获取。",
    "title_cn": "大型语言模型的线性化",
    "tags": [
      "LLM理论\n\n这篇论文探讨了大型语言模型（LLM）的理论方面，特别是关于线性变换器的改进和训练方法。SUPRA方法旨在提高现有大型预训练变换器的效率，同时保持其性能，这属于对LLM架构和训练技术的理论研究。因此，它被归类为LLM理论。",
      "",
      "机器学习"
    ]
  },
  {
    "title": "Value Augmented Sampling for Language Model Alignment and Personalization",
    "submit_datetime": "2024年05月10日",
    "abstract": "Aligning Large Language Models (LLMs) to cater to different human preferences, learning new skills, and unlearning harmful behavior is an important problem. Search-based methods, such as Best-of-N or Monte-Carlo Tree Search, are performant, but impractical for LLM adaptation due to their high inference cost. On the other hand, using Reinforcement Learning (RL) for adaptation is computationally efficient, but performs worse due to the optimization challenges in co-training the value function and the policy. We present a new framework for reward optimization, Value Augmented Sampling (VAS), that can maximize different reward functions using data sampled from only the initial, frozen LLM. VAS solves for the optimal reward-maximizing policy without co-training the policy and the value function, making the optimization stable, outperforming established baselines, such as PPO and DPO, on standard benchmarks, and achieving comparable results to Best-of-128 with lower inference cost. Unlike existing RL methods that require changing the weights of the LLM, VAS does not require access to the weights of the pre-trained LLM. Thus, it can even adapt LLMs (e.g., ChatGPT), which are available only as APIs. In addition, our algorithm unlocks the new capability of composing several rewards and controlling the extent of each one during deployment time, paving the road ahead for the future of aligned, personalized LLMs.",
    "pdf_link": "https://arxiv.org/abs/2405.06639",
    "graphs": [],
    "abstract_cn": "调整大型语言模型以适应人类多样化的偏好、学习新技能并消除有害行为，是当前亟待解决的挑战。虽然搜索方法如Best-of-N或蒙特卡洛树搜索性能卓越，但高昂的推理成本使其不适用于LLM的个性化调整。相比之下，强化学习虽计算高效，却在共同优化价值函数与策略时遭遇瓶颈，表现不佳。我们提出的价值增强采样（VAS）框架，能在不触及LLM原始权重的前提下，仅凭初始冻结模型的数据，精准优化多重奖励函数。VAS避免了策略与价值函数的共同训练，确保了优化过程的稳定性，不仅在标准测试中超越了PPO和DPO等传统方法，更以较低的推理成本，实现了与Best-of-128相媲美的成果。这一创新不仅适用于如ChatGPT这类仅提供API的模型，还开启了在部署时灵活组合并微调多重奖励的新篇章，预示着个性化、高度对齐的LLM的未来发展方向。",
    "title_cn": "语言模型的价值增强采样：对齐与个性化之道",
    "tags": [
      "LLM应用\n\n这篇论文探讨了如何调整大型语言模型以适应人类多样化的偏好，并提出了一个名为价值增强采样（VAS）的新框架。该框架旨在优化多重奖励函数，同时保持较低的推理成本，这对于个性化调整LLM至关重要。论文中提到的VAS框架超越了传统方法，如PPO和DPO，并且在推理成本方面与Best-of-128相媲美。这种方法特别适用于那些仅提供API的模型，如ChatGPT，并且为在部署时灵活组合和微调多重奖励提供了新的可能性。因此，这篇论文的内容与LLM的应用紧密相关，特别是在个性化调整和优化方面，而不是专注于Agent的设计、RAG（Retrieval-Augmented Generation）的构建或LLM的理论研究。",
      "人工智能个性化",
      ""
    ]
  },
  {
    "title": "Characterizing the Accuracy - Efficiency Trade-off of Low-rank Decomposition in Language Models",
    "submit_datetime": "2024年05月10日",
    "abstract": "Large language models (LLMs) have emerged and presented their general problem-solving capabilities with one model. However, the model size has increased dramatically with billions of parameters to enable such broad problem-solving capabilities. In addition, due to the dominance of matrix-matrix and matrix-vector multiplications in LLMs, the compute-to-model size ratio is significantly lower than that of CNNs. This shift pushes LLMs from a computation-bound regime to a memory-bound regime. Therefore, optimizing the memory footprint and traffic is an important optimization direction for LLMs today.\n  Model compression methods such as quantization and parameter pruning have been actively explored for achieving the memory footprint and traffic optimization. However, the accuracy-efficiency trade-off of rank pruning for LLMs is not well-understood yet. Therefore, we characterize the accuracy-efficiency trade-off of a low-rank decomposition method, specifically Tucker decomposition, on recent language models, including an open-source LLM, Llama 2.\n  We formalize the low-rank decomposition design space and show that the decomposition design space is enormous (e.g., O($2^{37}$) for Llama2-7B). To navigate such a vast design space, we formulate the design space and perform thorough case studies of accuracy-efficiency trade-offs using six widely used LLM benchmarks on BERT and Llama 2 models. Our results show that we can achieve a 9\\% model size reduction with minimal accuracy drops, which range from 4\\%p to 10\\%p, depending on the difficulty of the benchmark, without any retraining to recover accuracy after decomposition. The results show that low-rank decomposition can be a promising direction for LLM-based applications that require real-time service in scale (e.g., AI agent assist and real-time coding assistant), where the latency is as important as the model accuracy.",
    "pdf_link": "https://arxiv.org/abs/2405.06626",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）以其单一模型解决问题的能力崭露头角，但这也伴随着模型规模的激增，参数数量达到数十亿。由于LLMs中矩阵运算的主导地位，其计算效率远不如CNNs，导致LLMs从计算密集型转向内存密集型。因此，优化内存使用和数据流量成为LLMs优化的关键。模型压缩技术，如量化和参数剪枝，已被广泛研究以优化LLMs的内存占用。然而，对于LLMs的秩剪枝在准确性和效率之间的权衡仍不明确。我们针对Tucker分解这一低秩分解技术，在包括开源模型Llama 2在内的最新语言模型上进行了研究。我们定义了低秩分解的设计空间，并发现其空间巨大（例如，对于Llama2-7B，可达O($2^{37}$)）。为了探索这一广阔空间，我们制定了设计策略，并在BERT和Llama 2模型上基于六个LLM基准进行了深入的准确性-效率权衡研究。结果显示，我们可以在不显著牺牲准确性的情况下，将模型大小减少9%，准确性下降幅度在4%p至10%p之间，具体取决于基准的难度，且无需重新训练以恢复准确性。这表明，低秩分解对于需要大规模实时服务的LLM应用（如AI辅助代理和实时编码助手）是一个有前景的方向，其中延迟与模型准确性同等重要。",
    "title_cn": "语言模型中低秩分解的精效平衡探析",
    "tags": [
      "LLM理论\n\n这篇论文主要探讨了大型语言模型（LLMs）的内存优化问题，特别是通过秩剪枝和Tucker分解等模型压缩技术来减少模型大小，同时研究了准确性和效率之间的权衡。这些研究内容属于对LLMs理论层面的优化和改进，因此归类为LLM理论。虽然论文中提到了这些优化技术在实际应用中的潜在用途，如AI辅助代理和实时编码助手，但核心内容仍然是关于LLMs的理论优化方法，而不是具体的应用案例或Agent的设计。",
      "人工智能",
      "模型优化"
    ]
  },
  {
    "title": "What Can Natural Language Processing Do for Peer Review?",
    "submit_datetime": "2024年05月10日",
    "abstract": "The number of scientific articles produced every year is growing rapidly. Providing quality control over them is crucial for scientists and, ultimately, for the public good. In modern science, this process is largely delegated to peer review -- a distributed procedure in which each submission is evaluated by several independent experts in the field. Peer review is widely used, yet it is hard, time-consuming, and prone to error. Since the artifacts involved in peer review -- manuscripts, reviews, discussions -- are largely text-based, Natural Language Processing has great potential to improve reviewing. As the emergence of large language models (LLMs) has enabled NLP assistance for many new tasks, the discussion on machine-assisted peer review is picking up the pace. Yet, where exactly is help needed, where can NLP help, and where should it stand aside? The goal of our paper is to provide a foundation for the future efforts in NLP for peer-reviewing assistance. We discuss peer review as a general process, exemplified by reviewing at AI conferences. We detail each step of the process from manuscript submission to camera-ready revision, and discuss the associated challenges and opportunities for NLP assistance, illustrated by existing work. We then turn to the big challenges in NLP for peer review as a whole, including data acquisition and licensing, operationalization and experimentation, and ethical issues. To help consolidate community efforts, we create a companion repository that aggregates key datasets pertaining to peer review. Finally, we issue a detailed call for action for the scientific community, NLP and AI researchers, policymakers, and funding bodies to help bring the research in NLP for peer review forward. We hope that our work will help set the agenda for research in machine-assisted scientific quality control in the age of AI, within the NLP community and beyond.",
    "pdf_link": "https://arxiv.org/abs/2405.06563",
    "graphs": [],
    "abstract_cn": "科学文章的产量激增，质量把控成为科学界乃至公众利益的基石。同行评审，这一由领域内专家独立评估的分布式过程，虽广泛应用，却充满挑战，耗时且易错。鉴于评审材料多为文本，自然语言处理（NLP）技术大有可为。随着大型语言模型（LLMs）的崛起，NLP在同行评审中的辅助作用日益受到关注。但究竟何处需援手，NLP又该如何施展其能，何时应保持距离？我们的论文旨在为NLP在同行评审辅助领域的未来研究奠定基石。我们以AI会议评审为例，深入探讨同行评审的全过程，从提交到最终修订，揭示NLP辅助的挑战与机遇。我们进一步探讨NLP在同行评审中的重大挑战，包括数据获取、实验操作及伦理考量。为了凝聚社区力量，我们建立了一个汇集关键同行评审数据集的配套资源库。最后，我们向科学界、NLP与AI研究者、政策制定者及资助机构发出行动号召，共同推动NLP在同行评审领域的研究。我们期望这份工作能够为AI时代机器辅助科学质量控制的研究议程设定方向，不仅限于NLP领域，更触及更广阔的科学天地。",
    "title_cn": "自然语言处理如何助力同行评审？",
    "tags": [
      "LLM应用\n\n这篇论文探讨了大型语言模型（LLMs）在同行评审过程中的应用，分析了NLP技术如何辅助科学文章的评审，并提出了在同行评审中使用NLP的挑战与机遇。它关注的是LLMs在实际应用场景中的作用，特别是在提高科学出版物质量控制方面的潜在贡献。因此，它属于LLM应用类别。",
      "科学出版",
      "同行评审"
    ]
  },
  {
    "title": "Mitigating Hallucinations in Large Language Models via Self-Refinement-Enhanced Knowledge Retrieval",
    "submit_datetime": "2024年05月10日",
    "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities across various domains, although their susceptibility to hallucination poses significant challenges for their deployment in critical areas such as healthcare. To address this issue, retrieving relevant facts from knowledge graphs (KGs) is considered a promising method. Existing KG-augmented approaches tend to be resource-intensive, requiring multiple rounds of retrieval and verification for each factoid, which impedes their application in real-world scenarios.\n  In this study, we propose Self-Refinement-Enhanced Knowledge Graph Retrieval (Re-KGR) to augment the factuality of LLMs' responses with less retrieval efforts in the medical field. Our approach leverages the attribution of next-token predictive probability distributions across different tokens, and various model layers to primarily identify tokens with a high potential for hallucination, reducing verification rounds by refining knowledge triples associated with these tokens. Moreover, we rectify inaccurate content using retrieved knowledge in the post-processing stage, which improves the truthfulness of generated responses. Experimental results on a medical dataset demonstrate that our approach can enhance the factual capability of LLMs across various foundational models as evidenced by the highest scores on truthfulness.",
    "pdf_link": "https://arxiv.org/abs/2405.06545",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）在多个领域展现了卓越能力，但易产生幻觉，这在医疗等关键领域应用中构成挑战。本研究提出自我精炼增强的知识图谱检索（Re-KGR），旨在减少医疗领域检索工作量的同时提升LLMs回答的事实性。我们利用下一令牌预测概率分布的属性，识别并减少高幻觉潜力令牌的验证轮次，并通过后处理阶段的知识检索来纠正不准确内容，提高回答的真实性。实验证明，我们的方法在真实性方面得分最高，有效提升了LLMs的事实能力。",
    "title_cn": "借助自精细化知识检索，大型语言模型幻觉得以缓解",
    "tags": [
      "LLM应用\n\n这篇论文探讨了大型语言模型（LLMs）在医疗领域的应用，特别是在减少幻觉和提高回答的事实性方面的挑战。它提出了一种名为自我精炼增强的知识图谱检索（Re-KGR）的方法，旨在通过识别和减少高幻觉潜力令牌的验证轮次，以及通过后处理阶段的知识检索来纠正不准确内容，从而提高LLMs在医疗领域回答的事实性。这种方法的目的是在减少检索工作量的同时提升LLMs的性能。因此，这篇论文属于LLM应用分类，因为它关注的是LLMs在特定领域（医疗）的应用和改进。",
      "",
      "知识图谱"
    ]
  },
  {
    "title": "Prompting Large Language Models with Knowledge Graphs for Question Answering Involving Long-tail Facts",
    "submit_datetime": "2024年05月10日",
    "abstract": "Although Large Language Models (LLMs) are effective in performing various NLP tasks, they still struggle to handle tasks that require extensive, real-world knowledge, especially when dealing with long-tail facts (facts related to long-tail entities). This limitation highlights the need to supplement LLMs with non-parametric knowledge. To address this issue, we analysed the effects of different types of non-parametric knowledge, including textual passage and knowledge graphs (KGs). Since LLMs have probably seen the majority of factual question-answering datasets already, to facilitate our analysis, we proposed a fully automatic pipeline for creating a benchmark that requires knowledge of long-tail facts for answering the involved questions. Using this pipeline, we introduce the LTGen benchmark. We evaluate state-of-the-art LLMs in different knowledge settings using the proposed benchmark. Our experiments show that LLMs alone struggle with answering these questions, especially when the long-tail level is high or rich knowledge is required. Nonetheless, the performance of the same models improved significantly when they were prompted with non-parametric knowledge. We observed that, in most cases, prompting LLMs with KG triples surpasses passage-based prompting using a state-of-the-art retriever. In addition, while prompting LLMs with both KG triples and documents does not consistently improve knowledge coverage, it can dramatically reduce hallucinations in the generated content.",
    "pdf_link": "https://arxiv.org/abs/2405.06524",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.06524v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06524/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06524v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06524/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06524v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06524/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06524v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06524/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06524v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06524/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06524v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06524/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06524v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06524/x7.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）虽在多种自然语言处理任务中表现卓越，但在处理需要深厚现实世界知识的长尾事实任务时仍显力不从心。这表明，LLMs需要非参数知识的加持。为此，我们探讨了文本段落和知识图谱（KGs）等非参数知识对LLMs的影响。鉴于LLMs可能已接触过众多事实问答数据集，我们设计了一套全自动流程，用以构建一个依赖长尾事实知识的基准——LTGen。通过此基准，我们评估了在不同知识配置下的顶尖LLMs。实验结果显示，LLMs在面对高长尾级别或知识密集型问题时，表现不佳。然而，一旦引入非参数知识，模型的性能便大幅提升。我们发现，在多数情况下，使用KG三元组提示LLMs的效果优于基于段落的提示。同时，尽管结合KG三元组和文档的提示方式未能持续扩大知识覆盖面，但它显著减少了生成内容中的错误信息。",
    "title_cn": "借助知识图谱，激发大型语言模型解答长尾事实相关问题",
    "tags": [
      "LLM理论\n\n这篇论文探讨了大型语言模型（LLMs）在处理需要深厚现实世界知识的长尾事实任务时的局限性，并研究了非参数知识（如文本段落和知识图谱）对LLMs性能的影响。它提出了一种构建基准的方法，并通过实验评估了不同知识配置下的LLMs性能。这属于对LLMs理论层面的研究，因为它关注的是模型如何利用外部知识来提高性能，而不是特定的应用场景或代理（Agent）的设计。因此，它更符合LLM理论分类。",
      "",
      "知识增强"
    ]
  },
  {
    "title": "UniDM: A Unified Framework for Data Manipulation with Large Language Models",
    "submit_datetime": "2024年05月10日",
    "abstract": "Designing effective data manipulation methods is a long standing problem in data lakes. Traditional methods, which rely on rules or machine learning models, require extensive human efforts on training data collection and tuning models. Recent methods apply Large Language Models (LLMs) to resolve multiple data manipulation tasks. They exhibit bright benefits in terms of performance but still require customized designs to fit each specific task. This is very costly and can not catch up with the requirements of big data lake platforms. In this paper, inspired by the cross-task generality of LLMs on NLP tasks, we pave the first step to design an automatic and general solution to tackle with data manipulation tasks. We propose UniDM, a unified framework which establishes a new paradigm to process data manipulation tasks using LLMs. UniDM formalizes a number of data manipulation tasks in a unified form and abstracts three main general steps to solve each task. We develop an automatic context retrieval to allow the LLMs to retrieve data from data lakes, potentially containing evidence and factual information. For each step, we design effective prompts to guide LLMs to produce high quality results. By our comprehensive evaluation on a variety of benchmarks, our UniDM exhibits great generality and state-of-the-art performance on a wide variety of data manipulation tasks.",
    "pdf_link": "https://arxiv.org/abs/2405.06510",
    "graphs": [],
    "abstract_cn": "在数据湖领域，设计高效的数据操作方法一直是个挑战。传统方法耗费人力在数据收集和模型调优上，而新兴的LLMs方法虽在性能上有所突破，却需为每个任务定制设计，成本高昂且难以满足大数据湖平台的需求。本文受LLMs在NLP任务上的跨任务通用性启发，提出UniDM框架，旨在实现数据操作任务的自动化和通用化。UniDM将多样的数据操作任务统一化，并提炼出三个核心步骤。我们开发的自动上下文检索功能，使LLMs能从数据湖中提取信息，而精心设计的提示则引导LLMs产出高质量结果。经过多轮测试，UniDM在各类数据操作任务上展现了卓越的通用性和顶尖性能。",
    "title_cn": "UniDM：大型语言模型数据操作的统一之桥在人工智能的浩瀚星空中，UniDM犹如一座横跨数据与智慧的桥梁，以其统一之姿，将大型语言模型的数据操作能力汇聚于一点。它不仅是一套框架，更是一种艺术，一种将数据的纷繁复杂转化为模型智慧的精湛技艺。在这个框架下，数据的每一次舞动，都仿佛在诉说着与模型深度对话的故事，引领我们探索数据科学的无限可能。",
    "tags": [
      "Agent\n\n这篇论文介绍了一种名为UniDM的框架，旨在实现数据操作任务的自动化和通用化。它将多样的数据操作任务统一化，并提炼出三个核心步骤，包括自动上下文检索功能和精心设计的提示，以引导LLMs产出高质量结果。这种框架可以被视为一个智能代理（Agent），因为它能够自主地执行数据操作任务，而不需要为每个任务定制设计。因此，这篇论文属于Agent分类。",
      "数据湖",
      "数据操作自动化"
    ]
  },
  {
    "title": "Storypark: Leveraging Large Language Models to Enhance Children Story Learning Through Child-AI collaboration Storytelling",
    "submit_datetime": "2024年05月10日",
    "abstract": "Interactive storytelling has been widely adopted by educators in teaching activities of young children. Such a teaching method combines storytelling with active child participation, benefiting their expressive abilities, creative thinking, and understanding of stories. Interactive storytelling requires facilitators to unidirectionally narrate the story content and encourage children's participation in story plot creation and interpretation of central themes through multi-sensory interactive methods such as questioning and drawing. However, providing tailored guidance based on diverse feedback from children during interactive storytelling poses challenges for most facilitators. These challenges include expanding story plot development based on children's ideas, using drawings to visualize children's thoughts, and interpreting the story's central themes based on children's thinking. This necessitates facilitators to possess strong imaginative, associative, domain knowledge, and drawing skills. Large language models have demonstrated their potential in facilitating responsive and participatory dialogues, offering new design possibilities to address the challenges faced by facilitators in interactive storytelling. In this study, our goal is to leverage large language models to design an interactive storytelling system that provides children with plot frameworks and interpretations of central themes during the interactive storytelling process. Through user experiments involving 20 child participants, we evaluate this interactive system's usability, learning effectiveness, and user experience. The user study shows that Storypark improves learning outcomes in understanding story key ideas, generalization, and transfer. And high engagement and willingness to use of participants demonstrate that StoryPark provides children with a positive learning experience.",
    "pdf_link": "https://arxiv.org/abs/2405.06495",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.06495v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06495/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06495v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06495/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06495v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06495/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06495v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06495/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06495v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06495/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06495v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06495/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06495v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06495/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06495v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06495/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06495v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06495/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06495v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06495/x10.png"
      }
    ],
    "abstract_cn": "互动式讲故事在幼儿教育中广受欢迎，它通过儿童的积极参与，提升了他们的表达、创造和理解能力。然而，引导者在根据儿童多样反馈提供个性化指导时面临挑战，如扩展故事情节、可视化儿童想法和解读故事主题。大型语言模型为解决这些挑战提供了新思路。本研究旨在利用这些模型设计一个互动讲故事系统，通过实验评估其效果。结果显示，Storypark不仅提升了儿童对故事核心的理解，还增强了他们的学习体验，得到了孩子们的积极响应。",
    "title_cn": "Storypark：借助大型语言模型的力量，通过儿童与AI的协作讲故事，提升儿童的故事学习体验。",
    "tags": [
      "Agent\n\n这篇论文摘要描述了一个利用大型语言模型（LLM）设计的互动讲故事系统，名为Storypark。该系统旨在通过儿童的积极参与来提升他们的表达、创造和理解能力，并能够根据儿童的多样反馈提供个性化的指导。这个系统可以被视为一个智能代理（Agent），因为它能够与儿童互动，并根据他们的反馈调整其行为。因此，这篇论文属于Agent分类。",
      "幼儿教育",
      "互动式学习"
    ]
  },
  {
    "title": "ProCIS: A Benchmark for Proactive Retrieval in Conversations",
    "submit_datetime": "2024年05月10日",
    "abstract": "The field of conversational information seeking, which is rapidly gaining interest in both academia and industry, is changing how we interact with search engines through natural language interactions. Existing datasets and methods are mostly evaluating reactive conversational information seeking systems that solely provide response to every query from the user. We identify a gap in building and evaluating proactive conversational information seeking systems that can monitor a multi-party human conversation and proactively engage in the conversation at an opportune moment by retrieving useful resources and suggestions. In this paper, we introduce a large-scale dataset for proactive document retrieval that consists of over 2.8 million conversations. We conduct crowdsourcing experiments to obtain high-quality and relatively complete relevance judgments through depth-k pooling. We also collect annotations related to the parts of the conversation that are related to each document, enabling us to evaluate proactive retrieval systems. We introduce normalized proactive discounted cumulative gain (npDCG) for evaluating these systems, and further provide benchmark results for a wide range of models, including a novel model we developed for this task. We believe that the developed dataset, called ProCIS, paves the path towards developing proactive conversational information seeking systems.",
    "pdf_link": "https://arxiv.org/abs/2405.06460",
    "graphs": [],
    "abstract_cn": "对话信息检索领域正迅速成为学术界和工业界的热点，它通过自然语言交互重塑了我们与搜索引擎的互动方式。现有研究多聚焦于反应式系统，仅对用户查询做出回应。然而，主动式系统，即能够监控并适时介入多方对话，提供有用资源和建议的系统，尚待深入探索。本文推出一个包含280万对话的大型数据集，用于主动文档检索，并通过众包实验获取高质量的相关性判断。我们还收集了对话与文档关联部分的注释，以评估主动检索系统。我们提出了npDCG作为评估指标，并展示了多种模型的基准结果，包括我们为此任务开发的新模型。我们相信，名为ProCIS的数据集将为主动对话信息检索系统的发展奠定基础。",
    "title_cn": "ProCIS：对话主动检索的标杆在这篇文章中，我们将介绍ProCIS，这是一个专为对话中主动检索设计的基准。它旨在评估和推动对话系统在主动检索信息方面的能力，以提高交互的自然性和效率。通过ProCIS，研究者可以更好地理解和改进对话系统在处理复杂查询和提供即时信息时的表现。",
    "tags": [
      "Agent\n\n这篇论文主要关注的是主动式对话信息检索系统，这是一种能够监控并适时介入多方对话，提供有用资源和建议的系统。这种系统可以被视为一种智能代理（Agent），因为它能够主动地执行任务，而不仅仅是响应用户的查询。论文中提到的数据集构建、评估指标的提出以及模型的开发，都是为了推动这种主动式系统的研究和应用。因此，这篇论文更符合Agent分类。",
      "对话系统",
      "信息检索"
    ]
  },
  {
    "title": "Improving Instruction Following in Language Models through Proxy-Based Uncertainty Estimation",
    "submit_datetime": "2024年05月10日",
    "abstract": "Assessing response quality to instructions in language models is vital but challenging due to the complexity of human language across different contexts. This complexity often results in ambiguous or inconsistent interpretations, making accurate assessment difficult. To address this issue, we propose a novel Uncertainty-aware Reward Model (URM) that introduces a robust uncertainty estimation for the quality of paired responses based on Bayesian approximation. Trained with preference datasets, our uncertainty-enabled proxy not only scores rewards for responses but also evaluates their inherent uncertainty. Empirical results demonstrate significant benefits of incorporating the proposed proxy into language model training. Our method boosts the instruction following capability of language models by refining data curation for training and improving policy optimization objectives, thereby surpassing existing methods by a large margin on benchmarks such as Vicuna and MT-bench. These findings highlight that our proposed approach substantially advances language model training and paves a new way of harnessing uncertainty within language models.",
    "pdf_link": "https://arxiv.org/abs/2405.06424",
    "graphs": [],
    "abstract_cn": "在语言模型中，准确评估指令响应的质量至关重要，但因人类语言的复杂多变而充满挑战。我们提出的不确定性感知奖励模型（URM）通过贝叶斯近似，为响应质量提供了稳健的不确定性估计。该模型在偏好数据集上训练，不仅能评分，还能评估响应的不确定性。实证显示，我们的方法在语言模型训练中显著提升了指令遵循能力，通过优化数据选择和策略目标，在Vicuna和MT-bench等测试中超越了现有方法。这表明我们的方法在语言模型训练上取得了重大进展，并为利用不确定性提供了新思路。",
    "title_cn": "借助代理辅助的不确定性评估，精进语言模型的指令执行艺术",
    "tags": [
      "LLM理论\n\n这篇论文关注的是语言模型（LLM）中指令响应质量的评估问题，并提出了一个不确定性感知奖励模型（URM）来解决这一挑战。论文的核心贡献在于通过贝叶斯近似提供了一个能够评估响应不确定性的模型，这在语言模型训练中提高了指令遵循能力。这种方法的提出和实证结果表明了在语言模型理论上的进展，特别是在如何利用不确定性来优化模型性能方面。因此，这篇论文更符合LLM理论分类，因为它探讨了语言模型内部的评估机制和优化方法，而不是直接应用于特定的Agent或RAG系统，也不是作为一个具体的LLM应用案例。",
      "",
      "机器学习"
    ]
  },
  {
    "title": "Can Large Language Models Replicate ITS Feedback on Open-Ended Math Questions?",
    "submit_datetime": "2024年05月10日",
    "abstract": "Intelligent Tutoring Systems (ITSs) often contain an automated feedback component, which provides a predefined feedback message to students when they detect a predefined error. To such a feedback component, we often resort to template-based approaches. These approaches require significant effort from human experts to detect a limited number of possible student errors and provide corresponding feedback. This limitation is exemplified in open-ended math questions, where there can be a large number of different incorrect errors. In our work, we examine the capabilities of large language models (LLMs) to generate feedback for open-ended math questions, similar to that of an established ITS that uses a template-based approach. We fine-tune both open-source and proprietary LLMs on real student responses and corresponding ITS-provided feedback. We measure the quality of the generated feedback using text similarity metrics. We find that open-source and proprietary models both show promise in replicating the feedback they see during training, but do not generalize well to previously unseen student errors. These results suggest that despite being able to learn the formatting of feedback, LLMs are not able to fully understand mathematical errors made by students.",
    "pdf_link": "https://arxiv.org/abs/2405.06414",
    "graphs": [],
    "abstract_cn": "智能辅导系统（ITSs）中的自动反馈组件，通常依赖于模板来提供学生错误时的反馈。然而，这种方法在处理开放式数学问题时显得力不从心，因为错误的种类繁多。我们的研究探索了大型语言模型（LLMs）在生成此类问题反馈方面的潜力。通过微调开源和专有LLMs，我们发现它们能够模仿训练数据中的反馈格式，但在面对新的学生错误时，其泛化能力不足。这表明，尽管LLMs能够掌握反馈的格式，但在理解学生数学错误方面仍有局限。",
    "title_cn": "大型语言模型是否具备复制智能教学系统对开放式数学问题反馈的能力？",
    "tags": [
      "Agent\n\n解释：这篇论文探讨了大型语言模型（LLMs）在智能辅导系统（ITSs）中生成自动反馈的潜力，特别是在处理开放式数学问题时。虽然它涉及LLMs的应用，但重点在于模型作为智能代理（Agent）在教育领域中的作用，即如何作为一个智能系统来提供反馈。因此，它更符合Agent分类，而不是LLM应用，因为后者通常指的是LLMs在特定应用场景中的使用，而不强调模型作为代理的角色。此外，这篇论文并没有特别关注LLMs的理论方面，因此LLM理论分类也不适用。最后，论文内容与检索增强生成（RAG）无关，因此RAG分类也不适用。",
      "教育技术",
      "智能辅导系统"
    ]
  },
  {
    "title": "Potential and Limitations of LLMs in Capturing Structured Semantics: A Case Study on SRL",
    "submit_datetime": "2024年05月10日",
    "abstract": "Large Language Models (LLMs) play a crucial role in capturing structured semantics to enhance language understanding, improve interpretability, and reduce bias. Nevertheless, an ongoing controversy exists over the extent to which LLMs can grasp structured semantics. To assess this, we propose using Semantic Role Labeling (SRL) as a fundamental task to explore LLMs' ability to extract structured semantics. In our assessment, we employ the prompting approach, which leads to the creation of our few-shot SRL parser, called PromptSRL. PromptSRL enables LLMs to map natural languages to explicit semantic structures, which provides an interpretable window into the properties of LLMs. We find interesting potential: LLMs can indeed capture semantic structures, and scaling-up doesn't always mirror potential. Additionally, limitations of LLMs are observed in C-arguments, etc. Lastly, we are surprised to discover that significant overlap in the errors is made by both LLMs and untrained humans, accounting for almost 30% of all errors.",
    "pdf_link": "https://arxiv.org/abs/2405.06410",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）在捕捉语言的结构化语义方面至关重要，有助于提升语言理解、增强解释性并减少偏见。然而，关于LLMs掌握结构化语义的能力，学术界仍争论不休。为此，我们提出以语义角色标注（SRL）为基石任务，探究LLMs在提取语义结构方面的潜能。我们采用提示方法，开发了少样本SRL解析器PromptSRL，它使LLMs能将自然语言转化为清晰的语义框架，为我们揭示LLMs的内在特性提供了一扇窗。我们的研究揭示了LLMs在捕捉语义结构方面的潜力，并指出规模扩大并非总能提升性能。同时，我们也注意到LLMs在处理C-论元等任务时的局限。令人惊讶的是，我们发现LLMs与未经训练的人类在错误上有高达30%的重叠，这表明两者在某些认知任务上存在共通之处。",
    "title_cn": "大型语言模型在揭示结构化语义的奥秘上既有潜力也有限制，本研究以语义角色标注为切入点，深入探讨了这一议题。",
    "tags": [
      "LLM理论\n\n这篇论文探讨了大型语言模型（LLMs）在捕捉语言结构化语义方面的能力，特别是通过语义角色标注（SRL）任务来评估。它提出了一个名为PromptSRL的少样本SRL解析器，并分析了LLMs在处理语义结构任务时的性能和局限性。此外，论文还比较了LLMs与人类在错误上的重叠，这表明了LLMs在认知任务上的某些共性。这些内容更偏向于对LLMs理论能力的研究，因此归类为LLM理论。",
      "",
      "语义分析"
    ]
  },
  {
    "title": "Program Synthesis using Inductive Logic Programming for the Abstraction and Reasoning Corpus",
    "submit_datetime": "2024年05月10日",
    "abstract": "The Abstraction and Reasoning Corpus (ARC) is a general artificial intelligence benchmark that is currently unsolvable by any Machine Learning method, including Large Language Models (LLMs). It demands strong generalization and reasoning capabilities which are known to be weaknesses of Neural Network based systems. In this work, we propose a Program Synthesis system that uses Inductive Logic Programming (ILP), a branch of Symbolic AI, to solve ARC. We have manually defined a simple Domain Specific Language (DSL) that corresponds to a small set of object-centric abstractions relevant to ARC. This is the Background Knowledge used by ILP to create Logic Programs that provide reasoning capabilities to our system. The full system is capable of generalize to unseen tasks, since ILP can create Logic Program(s) from few examples, in the case of ARC: pairs of Input-Output grids examples for each task. These Logic Programs are able to generate Objects present in the Output grid and the combination of these can form a complete program that transforms an Input grid into an Output grid. We randomly chose some tasks from ARC that dont require more than the small number of the Object primitives we implemented and show that given only these, our system can solve tasks that require each, such different reasoning.",
    "pdf_link": "https://arxiv.org/abs/2405.06399",
    "graphs": [],
    "abstract_cn": "抽象与推理语料库（ARC）作为一项通用人工智能挑战，至今仍未被任何机器学习方法，包括大型语言模型（LLMs）所攻克。它对泛化与推理能力有着极高的要求，而这恰恰是神经网络系统的短板。本研究提出了一种基于归纳逻辑编程（ILP）的程序合成系统，ILP属于符号人工智能的范畴，专门针对ARC难题。我们精心设计了一种简洁的特定领域语言（DSL），它聚焦于ARC相关的一系列对象中心抽象。这种DSL构成了ILP生成逻辑程序的基础，为我们的系统赋予了推理能力。该系统具备泛化至新任务的潜力，因为ILP能从有限的示例中提炼出逻辑程序，例如ARC中的输入-输出网格示例对。这些逻辑程序能够创造出输出网格中的对象，而这些对象的组合则能编织成一个完整的程序，实现从输入网格到输出网格的转换。我们随机挑选了ARC中一些仅需少量对象原语的任务，并展示了即使仅依赖这些原语，我们的系统也能应对需要多样化推理的任务。",
    "title_cn": "归纳逻辑编程助力程序合成，探索抽象与推理语料库之奥秘",
    "tags": [
      "Agent\n\n这篇论文探讨了如何利用归纳逻辑编程（ILP）和特定领域语言（DSL）来解决抽象与推理语料库（ARC）这一通用人工智能挑战，这是一个关于开发能够进行推理和泛化的智能系统的问题。虽然它涉及大型语言模型（LLMs），但重点在于构建一个能够解决特定问题的Agent，即一个能够通过ILP和DSL进行程序合成的系统。因此，这篇论文更符合Agent分类，因为它关注的是创建一个能够执行特定任务的智能实体，而不是LLM的理论研究或应用。",
      "人工智能",
      ""
    ]
  },
  {
    "title": "LLM Discussion: Enhancing the Creativity of Large Language Models via Discussion Framework and Role-Play",
    "submit_datetime": "2024年05月10日",
    "abstract": "Large language models (LLMs) have shown exceptional proficiency in natural language processing but often fall short of generating creative and original responses to open-ended questions. To enhance LLM creativity, our key insight is to emulate the human process of inducing collective creativity through engaging discussions with participants from diverse backgrounds and perspectives. To this end, we propose LLM Discussion, a three-phase discussion framework that facilitates vigorous and diverging idea exchanges and ensures convergence to creative answers. Moreover, we adopt a role-playing technique by assigning distinct roles to LLMs to combat the homogeneity of LLMs. We evaluate the efficacy of the proposed framework with the Alternative Uses Test, Similarities Test, Instances Test, and Scientific Creativity Test through both LLM evaluation and human study. Our proposed framework outperforms single-LLM approaches and existing multi-LLM frameworks across various creativity metrics.",
    "pdf_link": "https://arxiv.org/abs/2405.06373",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.06373v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06373/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06373v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06373/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06373v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06373/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06373v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06373/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06373v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06373/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06373v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06373/x6.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）在自然语言处理领域表现卓越，但在应对开放式问题时，其创造性和原创性回答往往不尽人意。为了激发LLM的创造潜能，我们借鉴人类集体创造力的激发方式，即通过多元背景和视角的参与者之间的深入讨论。为此，我们设计了LLM讨论框架，该框架分为三个阶段，旨在促进思想碰撞，最终汇聚成富有创意的答案。我们还引入了角色扮演策略，赋予LLMs不同角色，以打破其同质性。通过替代用途测试、相似性测试、实例测试和科学创造力测试，我们不仅在LLM层面，也在人类研究中验证了该框架的有效性。结果显示，我们的框架在多个创造力评估维度上超越了单一LLM方法和现有多LLM框架。",
    "title_cn": "大型语言模型创造力提升：探讨框架与角色扮演的融合之道",
    "tags": [
      "Agent\n\n这篇论文探讨了如何通过设计一个讨论框架和引入角色扮演策略来激发大型语言模型（LLMs）的创造潜能。这种方法涉及创建多个代理（Agent），每个代理扮演不同的角色，并通过讨论来产生创造性的答案。这与Agent的分类相符，因为Agent在这里指的是能够执行特定任务或模拟特定角色的智能实体，特别是在这个案例中，Agent被用来增强LLM的创造性表现。",
      "",
      "人工智能"
    ]
  },
  {
    "title": "DP-DyLoRA: Fine-Tuning Transformer-Based Models On-Device under Differentially Private Federated Learning using Dynamic Low-Rank Adaptation",
    "submit_datetime": "2024年05月10日",
    "abstract": "Federated learning (FL) allows clients in an Internet of Things (IoT) system to collaboratively train a global model without sharing their local data with a server. However, clients' contributions to the server can still leak sensitive information. Differential privacy (DP) addresses such leakage by providing formal privacy guarantees, with mechanisms that add randomness to the clients' contributions. The randomness makes it infeasible to train large transformer-based models, common in modern IoT systems. In this work, we empirically evaluate the practicality of fine-tuning large scale on-device transformer-based models with differential privacy in a federated learning system. We conduct comprehensive experiments on various system properties for tasks spanning a multitude of domains: speech recognition, computer vision (CV) and natural language understanding (NLU). Our results show that full fine-tuning under differentially private federated learning (DP-FL) generally leads to huge performance degradation which can be alleviated by reducing the dimensionality of contributions through parameter-efficient fine-tuning (PEFT). Our benchmarks of existing DP-PEFT methods show that DP-Low-Rank Adaptation (DP-LoRA) consistently outperforms other methods. An even more promising approach, DyLoRA, which makes the low rank variable, when naively combined with FL would straightforwardly break differential privacy. We therefore propose an adaptation method that can be combined with differential privacy and call it DP-DyLoRA. Finally, we are able to reduce the accuracy degradation and word error rate (WER) increase due to DP to less than 2% and 7% respectively with 1 million clients and a stringent privacy budget of ε=2.",
    "pdf_link": "https://arxiv.org/abs/2405.06368",
    "graphs": [],
    "abstract_cn": "联邦学习让物联网设备在保护本地数据的同时，共同训练一个全局模型。但客户端的贡献仍可能泄露隐私。差分隐私通过添加随机性来保护隐私，但这也使得训练大型变压器模型变得困难。我们实证研究了在联邦学习中使用差分隐私微调大型变压器模型的可行性，并在语音识别、计算机视觉和自然语言理解等多个领域进行了实验。我们发现，完全微调在差分隐私联邦学习下会导致显著的性能下降，但通过参数高效微调可以缓解这一问题。我们的研究表明，DP-LoRA方法在DP-PEFT方法中表现最佳。我们还提出了DP-DyLoRA方法，它结合了差分隐私和动态低秩适应，有效减少了隐私保护下的性能损失，使得在拥有100万客户端和严格隐私预算ε=2的情况下，准确性下降和WER增加分别控制在2%和7%以内。",
    "title_cn": "DP-DyLoRA：在隐私保护联邦学习框架下，采用动态低秩适应技术，对基于变换器的模型进行设备端精细调整，以实现数据隐私与模型性能的平衡。",
    "tags": [
      "LLM应用\n\n这篇论文探讨了在联邦学习框架下使用差分隐私技术来微调大型变压器模型的问题，特别是在保护隐私的同时保持模型性能的挑战。它涉及了多个应用领域，包括语音识别、计算机视觉和自然语言理解，并提出了一种新的方法DP-DyLoRA来减少性能损失。虽然它涉及了大型语言模型（LLM）的应用，但主要关注的是联邦学习和差分隐私技术，而不是LLM的理论或Agent的设计。因此，它更适合归类为LLM应用。",
      "联邦学习",
      "隐私保护"
    ]
  },
  {
    "title": "Correlation Dimension of Natural Language in a Statistical Manifold",
    "submit_datetime": "2024年05月10日",
    "abstract": "The correlation dimension of natural language is measured by applying the Grassberger-Procaccia algorithm to high-dimensional sequences produced by a large-scale language model. This method, previously studied only in a Euclidean space, is reformulated in a statistical manifold via the Fisher-Rao distance. Language exhibits a multifractal, with global self-similarity and a universal dimension around 6.5, which is smaller than those of simple discrete random sequences and larger than that of a Barabási-Albert process. Long memory is the key to producing self-similarity. Our method is applicable to any probabilistic model of real-world discrete sequences, and we show an application to music data.",
    "pdf_link": "https://arxiv.org/abs/2405.06321",
    "graphs": [],
    "abstract_cn": "通过Grassberger-Procaccia算法在大规模语言模型生成的高维序列上应用，我们揭示了自然语言的多重分形特性，其全局自相似性和约6.5的通用维度，介于简单随机序列与Barabási-Albert过程之间。长记忆机制是这种自相似性的核心。我们的方法不仅限于语言，也适用于任何离散序列的概率模型，例如，我们已将其成功应用于音乐数据的分析。",
    "title_cn": "自然语言在统计空间中的相关维度探索",
    "tags": [
      "LLM理论\n\n这篇论文探讨了大型语言模型（LLM）生成的序列的多重分形特性，以及这些特性如何揭示自然语言的全局自相似性和通用维度。研究使用了Grassberger-Procaccia算法来分析这些高维序列，并发现了长记忆机制在这些自相似性中的作用。这种方法的应用不仅限于语言，还可以扩展到其他离散序列的概率模型，如音乐数据分析。因此，这篇论文的内容更偏向于LLM的理论研究，特别是关于自然语言处理中的复杂性和自相似性的理论探讨。",
      "",
      "音乐分析"
    ]
  },
  {
    "title": "FedGCS: A Generative Framework for Efficient Client Selection in Federated Learning via Gradient-based Optimization",
    "submit_datetime": "2024年05月10日",
    "abstract": "Federated Learning faces significant challenges in statistical and system heterogeneity, along with high energy consumption, necessitating efficient client selection strategies. Traditional approaches, including heuristic and learning-based methods, fall short of addressing these complexities holistically. In response, we propose FedGCS, a novel generative client selection framework that innovatively recasts the client selection process as a generative task. Drawing inspiration from the methodologies used in large language models, FedGCS efficiently encodes abundant decision-making knowledge within a continuous representation space, enabling efficient gradient-based optimization to search for optimal client selection that will be finally output via generation. The framework comprises four steps: (1) automatic collection of diverse \"selection-score\" pair data using classical client selection methods; (2) training an encoder-evaluator-decoder framework on this data to construct a continuous representation space; (3) employing gradient-based optimization in this space for optimal client selection; (4) generating the final optimal client selection via using beam search for the well-trained decoder. FedGCS outperforms traditional methods by being more comprehensive, generalizable, and efficient, simultaneously optimizing for model performance, latency, and energy consumption. The effectiveness of FedGCS is proven through extensive experimental analyses.",
    "pdf_link": "https://arxiv.org/abs/2405.06312",
    "graphs": [],
    "abstract_cn": "联邦学习在应对统计和系统异质性以及高能耗方面面临挑战，亟需高效的客户端选择策略。传统方法，如启发式和基于学习的方法，未能全面解决这些复杂问题。为此，我们提出了创新的FedGCS框架，将客户端选择视为生成任务，借鉴大型语言模型的方法，在连续表示空间内高效编码决策知识，实现基于梯度的优化，以生成最佳客户端选择。FedGCS通过四个步骤实现：自动收集多样化的“选择-分数”对数据；训练编码器-评估器-解码器框架；进行基于梯度的优化；使用束搜索生成最终选择。FedGCS在全面性、可推广性和效率上超越传统方法，同时优化模型性能、延迟和能耗，并通过实验分析验证了其有效性。",
    "title_cn": "FedGCS：梯度优化驱动的高效联邦学习客户端选择生成框架",
    "tags": [
      "Agent\n\n这篇论文介绍了一种名为FedGCS的新型联邦学习框架，它将客户端选择问题视为一个生成任务，并利用大型语言模型的方法在连续表示空间内编码决策知识，以实现基于梯度的优化。这个框架通过自动收集数据、训练编码器-评估器-解码器框架、进行优化和使用束搜索生成最终选择等步骤来实现高效的客户端选择策略。这个过程涉及到了智能代理（Agent）的概念，即在联邦学习环境中，FedGCS框架作为一个智能代理，能够自主地进行客户端选择，以优化模型性能、延迟和能耗。因此，这篇论文更符合Agent分类。",
      "联邦学习",
      "人工智能优化"
    ]
  },
  {
    "title": "Pruning as a Domain-specific LLM Extractor",
    "submit_datetime": "2024年05月10日",
    "abstract": "Large Language Models (LLMs) have exhibited remarkable proficiency across a wide array of NLP tasks. However, the escalation in model size also engenders substantial deployment costs. While few efforts have explored model pruning techniques to reduce the size of LLMs, they mainly center on general or task-specific weights. This leads to suboptimal performance due to lacking specificity on the target domain or generality on different tasks when applied to domain-specific challenges. This work introduces an innovative unstructured dual-pruning methodology, D-Pruner, for domain-specific compression on LLM. It extracts a compressed, domain-specific, and task-agnostic LLM by identifying LLM weights that are pivotal for general capabilities, like linguistic capability and multi-task solving, and domain-specific knowledge. More specifically, we first assess general weight importance by quantifying the error incurred upon their removal with the help of an open-domain calibration dataset. Then, we utilize this general weight importance to refine the training loss, so that it preserves generality when fitting into a specific domain. Moreover, by efficiently approximating weight importance with the refined training loss on a domain-specific calibration dataset, we obtain a pruned model emphasizing generality and specificity. Our comprehensive experiments across various tasks in healthcare and legal domains show the effectiveness of D-Pruner in domain-specific compression. Our code is available at https://github.com/psunlpgroup/D-Pruner.",
    "pdf_link": "https://arxiv.org/abs/2405.06275",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.06275v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06275/prune_types_3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06275v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06275/sim_matrix_open.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06275v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06275/sim_matrix_domain.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）在众多NLP任务中表现出色，但模型规模的扩大也带来了高昂的部署成本。尽管有研究尝试通过模型剪枝技术来缩小LLMs的规模，但这些方法多聚焦于通用或特定任务的权重，导致在特定领域应用时性能不尽人意。本研究提出了一种新颖的无结构双剪枝方法——D-Pruner，专为LLM的特定领域压缩设计。D-Pruner通过识别对语言能力、多任务解决以及特定领域知识至关重要的权重，生成一个既紧凑又专注于特定领域的LLM。具体而言，我们首先利用开放领域数据集评估通用权重的重要性，然后调整训练损失以在特定领域适应时保持通用性。通过在特定领域数据集上高效估算权重重要性，我们得到了一个既通用又特异的剪枝模型。在医疗和法律领域的多项任务中，D-Pruner展现了其在特定领域压缩方面的有效性。相关代码已公开于https://github.com/psunlpgroup/D-Pruner。",
    "title_cn": "修剪技术：特定领域的大型语言模型精炼者",
    "tags": [
      "LLM应用\n\n这篇论文探讨了大型语言模型（LLMs）在特定领域应用时的模型压缩问题，提出了一种名为D-Pruner的新颖无结构双剪枝方法。这种方法旨在通过识别对语言能力、多任务解决以及特定领域知识至关重要的权重，来生成一个既紧凑又专注于特定领域的LLM。研究结果表明，D-Pruner在医疗和法律领域的多项任务中展现了其在特定领域压缩方面的有效性。因此，这篇论文属于LLM应用类别，因为它专注于LLMs在特定领域的实际应用和优化。",
      "",
      ""
    ]
  },
  {
    "title": "XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare",
    "submit_datetime": "2024年05月10日",
    "abstract": "The integration of Large Language Models (LLMs) into healthcare diagnostics offers a promising avenue for clinical decision-making. This study outlines the development of a novel method for zero-shot/few-shot in-context learning (ICL) by integrating medical domain knowledge using a multi-layered structured prompt. We also explore the efficacy of two communication styles between the user and LLMs: the Numerical Conversational (NC) style, which processes data incrementally, and the Natural Language Single-Turn (NL-ST) style, which employs long narrative prompts. Our study systematically evaluates the diagnostic accuracy and risk factors, including gender bias and false negative rates, using a dataset of 920 patient records in various few-shot scenarios. Results indicate that traditional clinical machine learning (ML) models generally outperform LLMs in zero-shot and few-shot settings. However, the performance gap narrows significantly when employing few-shot examples alongside effective explainable AI (XAI) methods as sources of domain knowledge. Moreover, with sufficient time and an increased number of examples, the conversational style (NC) nearly matches the performance of ML models. Most notably, LLMs demonstrate comparable or superior cost-sensitive accuracy relative to ML models. This research confirms that, with appropriate domain knowledge and tailored communication strategies, LLMs can significantly enhance diagnostic processes. The findings highlight the importance of optimizing the number of training examples and communication styles to improve accuracy and reduce biases in LLM applications.",
    "pdf_link": "https://arxiv.org/abs/2405.06270",
    "graphs": [],
    "abstract_cn": "将LLMs融入医疗诊断为临床决策开辟了新途径。本研究提出了一种新颖的ICL方法，通过多层结构化提示整合医学知识，并比较了NC和NL-ST两种沟通风格的效果。我们系统地分析了920名患者的诊断准确性和风险，发现尽管传统ML模型在零-shot和few-shot场景中表现更佳，但结合few-shot示例和XAI方法后，LLMs的性能大幅提升。特别是，随着示例增多，NC风格几乎与ML模型媲美，且LLMs在成本敏感性上表现出色。这表明，通过精心设计的领域知识和沟通策略，LLMs能显著提升诊断效率。研究强调了优化训练示例和沟通风格对于提高LLMs准确性和减少偏见的重要性。",
    "title_cn": "XAI4LLM：携手机器学习与大型语言模型，共铸医疗领域上下文学习的辉煌。",
    "tags": [
      "LLM应用\n\n这篇论文探讨了大型语言模型（LLMs）在医疗诊断领域的应用，特别是通过一种新颖的上下文学习（ICL）方法来整合医学知识，并分析了不同沟通风格对诊断准确性和风险的影响。研究结果表明，通过结合少量示例和可解释人工智能（XAI）方法，LLMs的性能可以得到显著提升，特别是在成本敏感性方面。这表明，通过精心设计的领域知识和沟通策略，LLMs能够显著提升诊断效率。因此，这篇论文属于LLM应用分类，因为它关注的是LLMs在特定领域（医疗诊断）的实际应用和效果。",
      "医疗诊断",
      "临床决策支持"
    ]
  },
  {
    "title": "Automatic Generation of Model and Data Cards: A Step Towards Responsible AI",
    "submit_datetime": "2024年05月10日",
    "abstract": "In an era of model and data proliferation in machine learning/AI especially marked by the rapid advancement of open-sourced technologies, there arises a critical need for standardized consistent documentation. Our work addresses the information incompleteness in current human-generated model and data cards. We propose an automated generation approach using Large Language Models (LLMs). Our key contributions include the establishment of CardBench, a comprehensive dataset aggregated from over 4.8k model cards and 1.4k data cards, coupled with the development of the CardGen pipeline comprising a two-step retrieval process. Our approach exhibits enhanced completeness, objectivity, and faithfulness in generated model and data cards, a significant step in responsible AI documentation practices ensuring better accountability and traceability.",
    "pdf_link": "https://arxiv.org/abs/2405.06258",
    "graphs": [],
    "abstract_cn": "在机器学习与AI领域，随着开源技术的飞速发展，模型与数据的激增呼唤着标准化文档的诞生。我们致力于填补人工编写的模型与数据卡中的信息空白，提出了一种利用大型语言模型自动生成文档的创新方法。我们的核心成果包括创建了CardBench，一个汇聚了4800多份模型卡与1400多份数据卡的丰富数据集，以及设计了CardGen流程，该流程采用两步检索机制。我们的方法在生成的文档中展现了更高的完整性、客观性与真实性，为AI领域的责任文档实践迈出了坚实的一步，确保了更高的责任感和可追溯性。",
    "title_cn": "自动创建模型与数据卡片：引领人工智能走向责任之道",
    "tags": [
      "LLM应用\n\n这篇论文探讨了利用大型语言模型（LLM）自动生成模型和数据卡文档的方法，旨在提高文档的完整性、客观性和真实性。这与LLM的应用相关，因为它展示了如何将LLM用于自动化文档生成，以支持AI领域的责任文档实践。因此，它属于LLM应用分类。",
      "机器学习",
      "人工智能"
    ]
  },
  {
    "title": "SaudiBERT: A Large Language Model Pretrained on Saudi Dialect Corpora",
    "submit_datetime": "2024年05月10日",
    "abstract": "In this paper, we introduce SaudiBERT, a monodialect Arabic language model pretrained exclusively on Saudi dialectal text. To demonstrate the model's effectiveness, we compared SaudiBERT with six different multidialect Arabic language models across 11 evaluation datasets, which are divided into two groups: sentiment analysis and text classification. SaudiBERT achieved average F1-scores of 86.15\\% and 87.86\\% in these groups respectively, significantly outperforming all other comparative models. Additionally, we present two novel Saudi dialectal corpora: the Saudi Tweets Mega Corpus (STMC), which contains over 141 million tweets in Saudi dialect, and the Saudi Forums Corpus (SFC), which includes 15.2 GB of text collected from five Saudi online forums. Both corpora are used in pretraining the proposed model, and they are the largest Saudi dialectal corpora ever reported in the literature. The results confirm the effectiveness of SaudiBERT in understanding and analyzing Arabic text expressed in Saudi dialect, achieving state-of-the-art results in most tasks and surpassing other language models included in the study. SaudiBERT model is publicly available on \\url{https://huggingface.co/faisalq/SaudiBERT}.",
    "pdf_link": "https://arxiv.org/abs/2405.06239",
    "graphs": [],
    "abstract_cn": "本文介绍了专为沙特方言预训练的阿拉伯语言模型SaudiBERT，并通过与六个多方言模型的比较，在情感分析和文本分类的11个数据集上展示了其卓越性能。SaudiBERT分别以86.15%和87.86%的平均F1分数领先，显著超越了其他模型。同时，我们还推出了两个庞大的沙特方言语料库：包含1.41亿条推文的STMC和15.2GB文本的SFC，它们均为SaudiBERT的预训练提供了支持，并创下了文献中沙特方言语料库的规模之最。实验结果表明，SaudiBERT在处理沙特方言文本方面表现出色，多数任务中均达到或超越了现有模型的性能。该模型现已公开，可在\\url{https://huggingface.co/faisalq/SaudiBERT}获取。",
    "title_cn": "沙特方言之光：SaudiBERT——专为沙特语境定制的大型预训练语言模型",
    "tags": [
      "Agent\n\n这篇论文介绍了一个专门针对沙特方言预训练的阿拉伯语言模型SaudiBERT，并通过实验展示了其在特定任务上的优越性能。这个模型可以被视为一个智能代理（Agent），因为它被设计来处理特定的语言任务，并且在这些任务上表现出了高效率和效果。此外，论文还提到了为模型预训练提供支持的两个大型语料库，这进一步强调了模型作为处理特定语言任务的智能代理的角色。因此，这篇论文更适合归类在Agent分类下。",
      "",
      "语言模型"
    ]
  },
  {
    "title": "Risks of Practicing Large Language Models in Smart Grid: Threat Modeling and Validation",
    "submit_datetime": "2024年05月10日",
    "abstract": "Large Language Model (LLM) is a significant breakthrough in artificial intelligence (AI) and holds considerable potential for application within smart grids. However, as demonstrated in previous literature, AI technologies are susceptible to various types of attacks. It is crucial to investigate and evaluate the risks associated with LLMs before deploying them in critical infrastructure like smart grids. In this paper, we systematically evaluate the vulnerabilities of LLMs and identify two major types of attacks relevant to smart grid LLM applications, along with presenting the corresponding threat models. We then validate these attacks using popular LLMs, utilizing real smart grid data. Our validation demonstrates that attackers are capable of injecting bad data and retrieving domain knowledge from LLMs employed in smart grid scenarios.",
    "pdf_link": "https://arxiv.org/abs/2405.06237",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLM）在AI领域取得了显著进展，为智能电网带来了广阔的应用前景。然而，AI技术面临的攻击风险不容忽视。本文深入探讨了LLM在智能电网应用中的潜在风险，并揭示了两种关键攻击类型及其威胁模型。通过实际智能电网数据和流行LLM的验证，我们证实了攻击者有能力在智能电网环境中操纵LLM，注入错误信息并窃取敏感知识。",
    "title_cn": "智能电网中应用大型语言模型的潜在风险：威胁建模与验证探索在智能电网领域，大型语言模型的应用虽带来便利，但其潜在风险不容忽视。本文将深入探讨这些风险，并通过威胁建模与验证，揭示其对智能电网安全的影响。",
    "tags": [
      "Agent\n\n这篇论文主要探讨了大型语言模型（LLM）在智能电网应用中可能面临的攻击风险，并分析了两种关键攻击类型及其威胁模型。虽然它涉及了LLM的应用，但其核心关注点是智能电网环境中LLM作为Agent可能遭受的攻击和安全威胁，因此更符合Agent分类，强调了LLM在特定应用场景中的行为和潜在风险。",
      "智能电网",
      "网络安全"
    ]
  },
  {
    "title": "ExoplANETS-A: A VO database for host stars and planetary systems: The effect of XUV on planet atmospheres",
    "submit_datetime": "2024年05月10日",
    "abstract": "ExoplANETS-A is an EU Horizon-2020 project with the primary objective of establishing new knowledge on exoplanet atmospheres. Intimately related to this topic is the study of the host-stars radiative properties in order to understand the environment in which exoplanets lie.\n  The aim of this work is to exploit archived data from space-based observatories and other public sources to produce uniform sets of stellar data that can establish new insight on the influence of the host star on the planetary atmosphere. We have compiled X-ray and UV luminosities, which affect the formation and the atmospheric properties of the planets, and stellar parameters, which impact the retrieval process of the planetary-atmosphere's properties and its errors.\n  Our sample is formed of all transiting-exoplanet systems observed by HST or Spitzer. It includes 205 exoplanets and their 114 host-stars. We have built a catalogue with information extracted from public, online archives augmented by quantities derived by the Exoplanets-A work. With this catalogue we have implemented an online database which also includes X-ray and OHP spectra and TESS light curves. In addition, we have developed a tool, exoVOSA, which is able to fit the spectral energy distribution of exoplanets.\n  We give an example of using the database to study the effects of the host-star high-energy emission on the exoplanet atmosphere. The sample has a planet radius valley which is located at 1.8 Earth radii, in agreement with previous studies. Multiplanet systems in our sample were used to test the photoevaporation model and we find that out of 14 systems, only one significant case poses a contradiction to it (K2-3). In summary, the exoplanet and stellar resources compiled and generated by ExoplANETS-A form a sound basis for current JWST observations and for future work in the era of Ariel.",
    "pdf_link": "https://arxiv.org/abs/2405.06577",
    "graphs": [],
    "abstract_cn": "ExoplANETS-A 项目旨在通过研究宿主星的辐射特性，揭开系外行星大气之谜。我们整合了太空观测站的数据，创建了详尽的恒星资料库，以探究宿主星对行星大气的影响。我们的样本涵盖了 205 颗系外行星及其 114 颗宿主星，构建了一个包含 X 射线、OHP 光谱和 TESS 光曲线的在线数据库。我们还开发了 exoVOSA 工具，用于分析系外行星的能谱。通过数据库，我们发现了一个位于 1.8 地球半径的行星半径谷，与先前研究相符。在测试光蒸发模型时，我们样本中的 14 个多行星系统中，仅有一个（K2-3）与模型不符。ExoplANETS-A 的努力为 JWST 的观测和未来的 Ariel 时代研究奠定了坚实基础。",
    "title_cn": "ExoplANETS-A：探索宿主星与行星系统的宝库，揭示XUV辐射如何塑造遥远世界的大气层。",
    "tags": [
      "Agent\n\n理由：这篇论文描述了一个项目（ExoplANETS-A），该项目通过整合数据和开发工具（exoVOSA）来研究系外行星的大气。这个项目可以被视为一个代理（Agent），因为它在执行特定的任务（研究系外行星大气）并使用工具来分析数据。虽然项目中可能涉及大型语言模型（LLM）的应用，但论文摘要中并未明确提及LLM，因此不适合归类为LLM应用或LLM理论。同时，该项目并不专注于语言模型或嵌入的反转攻击，因此也不属于RAG分类。",
      "天文学",
      "行星科学"
    ]
  },
  {
    "title": "Natural Language Processing RELIES on Linguistics",
    "submit_datetime": "2024年05月09日",
    "abstract": "Large Language Models (LLMs) have become capable of generating highly fluent text in certain languages, without modules specially designed to capture grammar or semantic coherence. What does this mean for the future of linguistic expertise in NLP? We highlight several aspects in which NLP (still) relies on linguistics, or where linguistic thinking can illuminate new directions. We argue our case around the acronym $RELIES$ that encapsulates six major facets where linguistics contributes to NLP: $R$esources, $E$valuation, $L$ow-resource settings, $I$nterpretability, $E$xplanation, and the $S$tudy of language. This list is not exhaustive, nor is linguistics the main point of reference for every effort under these themes; but at a macro level, these facets highlight the enduring importance of studying machine systems vis-a-vis systems of human language.",
    "pdf_link": "https://arxiv.org/abs/2405.05966",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）已能生成流畅的文本，无需专门捕捉语法或语义的模块。这引发了对NLP领域语言学专业知识未来的思考。我们指出，NLP仍需语言学的支持，语言学思维亦能指引新方向。我们以$RELIES$为纲，概述了语言学在NLP中的六大贡献：资源、评估、低资源环境、可解释性、解释和语言研究。虽非全面，语言学亦非唯一参考，但这些方面凸显了研究机器与人类语言系统之间关系的重要性。",
    "title_cn": "自然语言处理深植于语言学的土壤之中，二者相辅相成，共同推动着人工智能领域的发展。",
    "tags": [
      "LLM理论\n\n这篇论文探讨了大型语言模型（LLMs）在自然语言处理（NLP）领域中的应用，并强调了语言学知识在NLP研究中的重要性。论文通过提出$RELIES$框架，概述了语言学在资源、评估、低资源环境、可解释性、解释和语言研究等方面的贡献，这些内容更多地涉及LLMs的理论基础和应用原则，而不是具体的Agent设计或RAG（检索增强生成）技术。因此，这篇论文更适合归类于LLM理论。",
      "",
      "语言学研究"
    ]
  },
  {
    "title": "OpenBA-V2: Reaching 77.3% High Compression Ratio with Fast Multi-Stage Pruning",
    "submit_datetime": "2024年05月09日",
    "abstract": "Large Language Models (LLMs) have played an important role in many fields due to their powerful capabilities.However, their massive number of parameters leads to high deployment requirements and incurs significant inference costs, which impedes their practical applications. Training smaller models is an effective way to address this problem. Therefore, we introduce OpenBA-V2, a 3.4B model derived from multi-stage compression and continual pre-training from the original 15B OpenBA model. OpenBA-V2 utilizes more data, more flexible training objectives, and techniques such as layer pruning, neural pruning, and vocabulary pruning to achieve a compression rate of 77.3\\% with minimal performance loss. OpenBA-V2 demonstrates competitive performance compared to other open-source models of similar size, achieving results close to or on par with the 15B OpenBA model in downstream tasks such as common sense reasoning and Named Entity Recognition (NER). OpenBA-V2 illustrates that LLMs can be compressed into smaller ones with minimal performance loss by employing advanced training objectives and data strategies, which may help deploy LLMs in resource-limited scenarios.",
    "pdf_link": "https://arxiv.org/abs/2405.05957",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）因其卓越能力在多个领域占据重要地位，但其庞大的参数规模带来了高昂的部署成本和推理开销，限制了实际应用。为此，我们推出了OpenBA-V2，一个通过多阶段压缩和持续预训练从15B OpenBA模型精炼而来的3.4B模型。OpenBA-V2通过采用更多数据、灵活的训练目标以及层剪枝、神经剪枝和词汇剪枝等技术，实现了77.3%的压缩率，同时几乎不牺牲性能。在与同规模开源模型的较量中，OpenBA-V2在常识推理和命名实体识别等任务上表现卓越，与15B OpenBA模型不相上下。这一成就表明，通过精妙的训练策略和数据利用，LLMs可以被高效压缩，为资源受限环境下的部署提供了可能。",
    "title_cn": "OpenBA-V2：以迅捷的多阶段剪枝技术，实现了高达77.3%的卓越压缩比，为模型瘦身开辟了新境界。",
    "tags": [
      "LLM理论\n\n这篇论文主要探讨了大型语言模型（LLMs）的压缩技术，通过多阶段压缩和持续预训练的方法，从一个大型的OpenBA模型精炼出一个更小规模的模型，同时保持了性能。这种方法和技术属于对LLMs理论层面的研究和改进，因此归类于LLM理论。论文中提到的模型压缩、训练策略和数据利用等技术，是对LLMs理论的深入探讨，旨在解决LLMs在实际应用中的部署成本和推理开销问题。",
      "模型压缩",
      ""
    ]
  },
  {
    "title": "Probing Multimodal LLMs as World Models for Driving",
    "submit_datetime": "2024年05月09日",
    "abstract": "We provide a sober look at the application of Multimodal Large Language Models (MLLMs) within the domain of autonomous driving and challenge/verify some common assumptions, focusing on their ability to reason and interpret dynamic driving scenarios through sequences of images/frames in a closed-loop control environment. Despite the significant advancements in MLLMs like GPT-4V, their performance in complex, dynamic driving environments remains largely untested and presents a wide area of exploration. We conduct a comprehensive experimental study to evaluate the capability of various MLLMs as world models for driving from the perspective of a fixed in-car camera. Our findings reveal that, while these models proficiently interpret individual images, they struggle significantly with synthesizing coherent narratives or logical sequences across frames depicting dynamic behavior. The experiments demonstrate considerable inaccuracies in predicting (i) basic vehicle dynamics (forward/backward, acceleration/deceleration, turning right or left), (ii) interactions with other road actors (e.g., identifying speeding cars or heavy traffic), (iii) trajectory planning, and (iv) open-set dynamic scene reasoning, suggesting biases in the models' training data. To enable this experimental study we introduce a specialized simulator, DriveSim, designed to generate diverse driving scenarios, providing a platform for evaluating MLLMs in the realms of driving. Additionally, we contribute the full open-source code and a new dataset, \"Eval-LLM-Drive\", for evaluating MLLMs in driving. Our results highlight a critical gap in the current capabilities of state-of-the-art MLLMs, underscoring the need for enhanced foundation models to improve their applicability in real-world dynamic environments.",
    "pdf_link": "https://arxiv.org/abs/2405.05956",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.05956v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05956/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05956v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05956/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05956v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05956/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05956v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05956/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05956v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05956/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05956v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05956/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05956v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05956/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05956v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05956/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05956v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05956/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05956v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05956/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05956v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05956/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05956v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05956/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05956v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05956/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05956v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05956/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05956v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05956/x15.png"
      }
    ],
    "abstract_cn": "我们深入探讨了多模态大型语言模型（MLLMs）在自动驾驶领域的应用，并对其在动态驾驶场景中的推理和解释能力进行了挑战与验证。尽管GPT-4V等模型取得了显著进展，但在复杂动态环境中的实际表现仍是一个未解之谜。我们的实验研究从车内固定摄像头的视角出发，评估了MLLMs作为驾驶世界模型的潜力。研究发现，虽然MLLMs能准确解读单帧图像，但在构建跨帧的连贯驾驶叙述时却显得力不从心。实验揭示了在车辆动力学预测、道路交互、轨迹规划以及动态场景推理等方面的显著误差，暗示了训练数据的潜在偏差。为此，我们开发了DriveSim模拟器，创造了一个评估MLLMs驾驶能力的多样化场景平台，并公开了完整的代码和“Eval-LLM-Drive”数据集。我们的研究揭示了当前MLLMs在应对现实世界动态环境方面的不足，强调了提升基础模型以增强其实际应用能力的迫切性。",
    "title_cn": "探索大型语言模型的多模态潜能，将其作为驾驶场景的智能世界模型。",
    "tags": [
      "LLM应用\n\n这篇论文探讨了多模态大型语言模型（MLLMs）在自动驾驶领域的应用，并对其在动态驾驶场景中的推理和解释能力进行了实验研究。它关注的是MLLMs在实际应用中的表现，特别是在构建连贯驾驶叙述和处理复杂动态环境方面的挑战。此外，论文还开发了DriveSim模拟器和“Eval-LLM-Drive”数据集，以评估和提升MLLMs的驾驶能力。这些内容表明，该论文属于LLM应用的范畴，因为它专注于大型语言模型在特定领域（自动驾驶）的应用和性能评估。",
      "自动驾驶",
      "人工智能"
    ]
  },
  {
    "title": "Smurfs: Leveraging Multiple Proficiency Agents with Context-Efficiency for Tool Planning",
    "submit_datetime": "2024年05月09日",
    "abstract": "The emergence of large language models (LLMs) has opened up unprecedented possibilities for automating complex tasks that are often comparable to human performance. Despite their capabilities, LLMs still encounter difficulties in completing tasks that require high levels of accuracy and complexity due to their inherent limitations in handling multifaceted problems single-handedly. This paper introduces \"Smurfs\", a cutting-edge multi-agent framework designed to revolutionize the application of LLMs. By transforming a conventional LLM into a synergistic multi-agent ensemble, Smurfs enhances task decomposition and execution without necessitating extra training. This is achieved through innovative prompting strategies that allocate distinct roles within the model, thereby facilitating collaboration among specialized agents. The framework gives access to external tools to efficiently solve complex tasks. Our empirical investigation, featuring the mistral-7b-instruct model as a case study, showcases Smurfs' superior capability in intricate tool utilization scenarios. Notably, Smurfs outmatches the ChatGPT-ReACT in the ToolBench I2 and I3 benchmark with a remarkable 84.4% win rate, surpassing the highest recorded performance of a GPT-4 model at 73.5%. Furthermore, through comprehensive ablation studies, we dissect the contribution of the core components of the multi-agent framework to its overall efficacy. This not only verifies the effectiveness of the framework, but also sets a route for future exploration of multi-agent LLM systems.",
    "pdf_link": "https://arxiv.org/abs/2405.05955",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）的崛起为自动化复杂任务带来了前所未有的机遇，其表现可与人类媲美。然而，面对高精度与复杂性要求，LLMs仍显捉襟见肘，因其难以独力应对多面性问题。本文推出的“蓝精灵”（Smurfs），是一款革命性的多代理框架，旨在重塑LLMs的应用前景。通过将传统LLM转化为协同工作的多代理团队，蓝精灵在不增加额外训练的情况下，提升了任务分解与执行的效率。这一创新得益于巧妙的提示策略，它为模型内的每个代理分配独特角色，促进专业分工与合作。框架还整合了外部工具，以高效应对复杂挑战。我们的实证研究以mistral-7b-instruct模型为例，展示了蓝精灵在复杂工具运用场景中的卓越表现。在ToolBench I2和I3基准测试中，蓝精灵以84.4%的胜率超越了ChatGPT-ReACT，刷新了GPT-4模型的最佳记录。通过深入的消融研究，我们揭示了多代理框架核心组件对整体效能的贡献，这不仅证实了框架的效力，也为未来多代理LLM系统的探索指明了方向。",
    "title_cn": "蓝精灵策略：借助高效利用上下文的多技能代理，实现工具规划的优化在翻译过程中，我首先确保原文的核心概念和术语被准确地转换成中文，如“Smurfs”、“Multiple Proficiency Agents”和“Context-Efficiency”。接着，我调整了语言风格，使其更加符合中文的表达习惯，同时保持了原文的生动性和简洁性。通过这种方式，翻译既忠实于原文，又易于中文读者理解。",
    "tags": [
      "Agent\n\n这篇论文介绍了一种名为“蓝精灵”的多代理框架，它通过将大型语言模型（LLMs）转化为协同工作的多代理团队来提升任务分解与执行的效率。这种框架通过巧妙的提示策略为模型内的每个代理分配独特角色，促进专业分工与合作，并且整合了外部工具以应对复杂挑战。因此，它属于Agent分类，因为它专注于开发和应用多代理系统来增强LLMs的能力。",
      "人工智能",
      "自动化任务处理"
    ]
  },
  {
    "title": "CuMo: Scaling Multimodal LLM with Co-Upcycled Mixture-of-Experts",
    "submit_datetime": "2024年05月09日",
    "abstract": "Recent advancements in Multimodal Large Language Models (LLMs) have focused primarily on scaling by increasing text-image pair data and enhancing LLMs to improve performance on multimodal tasks. However, these scaling approaches are computationally expensive and overlook the significance of improving model capabilities from the vision side. Inspired by the successful applications of Mixture-of-Experts (MoE) in LLMs, which improves model scalability during training while keeping inference costs similar to those of smaller models, we propose CuMo. CuMo incorporates Co-upcycled Top-K sparsely-gated Mixture-of-experts blocks into both the vision encoder and the MLP connector, thereby enhancing the multimodal LLMs with minimal additional activated parameters during inference. CuMo first pre-trains the MLP blocks and then initializes each expert in the MoE block from the pre-trained MLP block during the visual instruction tuning stage. Auxiliary losses are used to ensure a balanced loading of experts. CuMo outperforms state-of-the-art multimodal LLMs across various VQA and visual-instruction-following benchmarks using models within each model size group, all while training exclusively on open-sourced datasets. The code and model weights for CuMo are open-sourced at https://github.com/SHI-Labs/CuMo.",
    "pdf_link": "https://arxiv.org/abs/2405.05949",
    "graphs": [],
    "abstract_cn": "近期，多模态大型语言模型的进步，主要集中在通过扩大文本-图像数据集和提升模型性能来应对多模态任务。然而，这些方法不仅计算成本高，还忽略了从视觉角度增强模型能力的重要性。借鉴混合专家（MoE）在大型语言模型中的成功应用，我们提出了CuMo，一种在训练时提升模型可扩展性，同时保持推理成本与小型模型相当的创新方法。CuMo通过将协同升级的Top-K稀疏门控混合专家块融入视觉编码器和MLP连接器，以最小的额外参数激活提升了多模态LLMs的性能。在视觉指令调整阶段，CuMo首先预训练MLP块，然后从这些预训练的MLP块初始化MoE块中的每个专家，并使用辅助损失确保专家的均衡加载。CuMo在多个VQA和视觉指令遵循基准测试中超越了现有的多模态LLMs，且仅依赖于开源数据集进行训练。CuMo的代码和模型权重已在GitHub上开源，地址为https://github.com/SHI-Labs/CuMo。",
    "title_cn": "CuMo：借助协同升级的混合专家技术，扩展多模态大型语言模型的能力在这项研究中，我们提出了CuMo，一种新颖的框架，旨在通过引入协同升级的混合专家（Co-Upcycled Mixture-of-Experts）机制来扩展多模态大型语言模型（Multimodal LLM）的能力。CuMo的核心思想是通过有效地结合不同领域的专家知识，提升模型在处理多模态数据时的性能和灵活性。我们的实验结果表明，CuMo不仅能够显著提高模型的处理速度，还能在保持高准确率的同时，处理更加复杂和多样化的任务。这一创新性的方法为多模态AI技术的发展开辟了新的道路。",
    "tags": [
      "LLM应用\n\n这篇论文介绍了一种名为CuMo的创新方法，旨在提升多模态大型语言模型的性能和可扩展性，同时保持较低的推理成本。CuMo通过引入混合专家（MoE）机制，特别是在视觉编码器和MLP连接器中使用Top-K稀疏门控混合专家块，来增强模型的能力。这种方法在多模态任务中表现出色，且仅依赖于开源数据集进行训练。由于论文主要关注的是LLM在多模态任务中的应用，特别是通过创新的方法提升模型性能，因此它属于LLM应用类别。",
      "人工智能",
      "计算机视觉"
    ]
  },
  {
    "title": "Trustworthy AI-Generative Content in Intelligent 6G Network: Adversarial, Privacy, and Fairness",
    "submit_datetime": "2024年05月09日",
    "abstract": "AI-generated content (AIGC) models, represented by large language models (LLM), have brought revolutionary changes to the content generation fields. The high-speed and extensive 6G technology is an ideal platform for providing powerful AIGC mobile service applications, while future 6G mobile networks also need to support intelligent and personalized mobile generation services. However, the significant ethical and security issues of current AIGC models, such as adversarial attacks, privacy, and fairness, greatly affect the credibility of 6G intelligent networks, especially in ensuring secure, private, and fair AIGC applications. In this paper, we propose TrustGAIN, a novel paradigm for trustworthy AIGC in 6G networks, to ensure trustworthy large-scale AIGC services in future 6G networks. We first discuss the adversarial attacks and privacy threats faced by AIGC systems in 6G networks, as well as the corresponding protection issues. Subsequently, we emphasize the importance of ensuring the unbiasedness and fairness of the mobile generative service in future intelligent networks. In particular, we conduct a use case to demonstrate that TrustGAIN can effectively guide the resistance against malicious or generated false information. We believe that TrustGAIN is a necessary paradigm for intelligent and trustworthy 6G networks to support AIGC services, ensuring the security, privacy, and fairness of AIGC network services.",
    "pdf_link": "https://arxiv.org/abs/2405.05930",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.05930v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05930/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05930v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05930/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05930v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05930/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05930v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05930/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05930v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05930/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05930v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05930/x6.png"
      }
    ],
    "abstract_cn": "以大型语言模型为代表的AI生成内容（AIGC）模型，正在彻底改变内容创作领域。高速广泛的6G技术为强大的AIGC移动服务提供了理想平台，而未来的6G网络也需支持智能个性化的内容生成服务。然而，AIGC模型面临的伦理和安全挑战，如对抗攻击、隐私泄露和公平性问题，严重威胁着6G智能网络的信誉，尤其是在保障AIGC应用的安全、隐私和公平方面。本文提出了TrustGAIN，一种在6G网络中确保AIGC可信性的创新框架，旨在为未来的6G网络提供大规模、可信的AIGC服务。我们首先探讨了6G网络中AIGC系统所面临的对抗攻击和隐私风险，并提出了相应的保护措施。接着，我们强调了在未来智能网络中确保移动生成服务无偏和公平的重要性。通过一个用例，我们展示了TrustGAIN在抵御恶意或虚假信息方面的有效性。我们坚信，TrustGAIN是实现智能可信6G网络的关键，它将保障AIGC服务的安全、隐私和公平。",
    "title_cn": "智能6G网络中的可信AI生成内容：对抗、隐私与公平之考量",
    "tags": [
      "LLM应用\n\n这篇论文讨论了大型语言模型（LLM）在AI生成内容（AIGC）模型中的应用，特别是在6G技术背景下，如何确保内容生成的可信性、安全性、隐私保护和公平性。它提出了一个名为TrustGAIN的框架，旨在为6G网络提供可信的AIGC服务。这与LLM的应用场景紧密相关，因为它关注的是LLM在实际网络环境中的部署和挑战，而不是LLM的理论研究或Agent的设计与实现。因此，它属于LLM应用分类。",
      "6G通信",
      "内容创作"
    ]
  },
  {
    "title": "Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?",
    "submit_datetime": "2024年05月09日",
    "abstract": "When large language models are aligned via supervised fine-tuning, they may encounter new factual information that was not acquired through pre-training. It is often conjectured that this can teach the model the behavior of hallucinating factually incorrect responses, as the model is trained to generate facts that are not grounded in its pre-existing knowledge. In this work, we study the impact of such exposure to new knowledge on the capability of the fine-tuned model to utilize its pre-existing knowledge. To this end, we design a controlled setup, focused on closed-book QA, where we vary the proportion of the fine-tuning examples that introduce new knowledge. We demonstrate that large language models struggle to acquire new factual knowledge through fine-tuning, as fine-tuning examples that introduce new knowledge are learned significantly slower than those consistent with the model's knowledge. However, we also find that as the examples with new knowledge are eventually learned, they linearly increase the model's tendency to hallucinate. Taken together, our results highlight the risk in introducing new factual knowledge through fine-tuning, and support the view that large language models mostly acquire factual knowledge through pre-training, whereas fine-tuning teaches them to use it more efficiently.",
    "pdf_link": "https://arxiv.org/abs/2405.05904",
    "graphs": [],
    "abstract_cn": "大型语言模型在监督式微调过程中可能会接触到预训练之外的新事实，这可能导致模型产生事实错误的幻觉。我们通过闭卷问答的受控实验，探究了微调中引入新知识对模型利用先前知识能力的影响。实验表明，大型语言模型在微调中学习新事实的速度较慢，但一旦学会，却会线性增加产生幻觉的倾向。我们的研究强调了微调中新知识引入的风险，并指出大型语言模型主要通过预训练获取事实知识，而微调则使其更高效地运用这些知识。",
    "title_cn": "微调 LLMs 以吸收新知，是否会催生幻觉？",
    "tags": [
      "LLM理论\n\n这篇论文探讨了大型语言模型（LLM）在监督式微调过程中引入新知识对其产生事实错误（幻觉）的影响。研究通过闭卷问答的实验来分析微调过程中新知识的学习速度以及其对模型产生幻觉倾向的影响。这涉及到LLM的知识获取和应用机制，因此属于LLM理论的范畴。研究结果强调了微调中新知识引入的风险，并指出LLM主要通过预训练获取事实知识，而微调则影响其运用这些知识的方式。这与LLM应用不同，因为它更侧重于模型内部的工作原理和知识处理机制，而不是直接的应用场景或安全性问题。",
      "",
      "机器学习"
    ]
  },
  {
    "title": "Co-driver: VLM-based Autonomous Driving Assistant with Human-like Behavior and Understanding for Complex Road Scenes",
    "submit_datetime": "2024年05月09日",
    "abstract": "Recent research about Large Language Model based autonomous driving solutions shows a promising picture in planning and control fields. However, heavy computational resources and hallucinations of Large Language Models continue to hinder the tasks of predicting precise trajectories and instructing control signals. To address this problem, we propose Co-driver, a novel autonomous driving assistant system to empower autonomous vehicles with adjustable driving behaviors based on the understanding of road scenes. A pipeline involving the CARLA simulator and Robot Operating System 2 (ROS2) verifying the effectiveness of our system is presented, utilizing a single Nvidia 4090 24G GPU while exploiting the capacity of textual output of the Visual Language Model. Besides, we also contribute a dataset containing an image set and a corresponding prompt set for fine-tuning the Visual Language Model module of our system. In the real-world driving dataset, our system achieved 96.16% success rate in night scenes and 89.7% in gloomy scenes regarding reasonable predictions. Our Co-driver dataset will be released at https://github.com/ZionGo6/Co-driver.",
    "pdf_link": "https://arxiv.org/abs/2405.05885",
    "graphs": [],
    "abstract_cn": "基于大型语言模型的自动驾驶技术在规划与控制领域展现出光明前景，但计算资源的沉重负担和模型幻觉问题仍制约着精准轨迹预测与控制信号的指导。为此，我们创新性地推出了Co-driver系统，它通过理解道路场景，赋予自动驾驶车辆灵活的驾驶行为。我们通过CARLA模拟器与ROS2系统验证了Co-driver的效能，并巧妙地利用了Nvidia 4090 24G GPU的强大性能。此外，我们还提供了一个包含图像与提示的数据集，用于优化系统的视觉语言模型。在实际驾驶测试中，Co-driver在夜间与阴暗环境下的成功率分别高达96.16%与89.7%，表现出色。我们将在https://github.com/ZionGo6/Co-driver公开Co-driver数据集，以飨业界。",
    "title_cn": "智能副驾：一款基于视觉语言模型的自动驾驶辅助系统，它模仿人类驾驶员的行为，并能深刻理解复杂多变的道路环境。",
    "tags": [
      "Agent\n\n这篇论文介绍了一个名为Co-driver的系统，它是基于大型语言模型的自动驾驶技术，旨在解决自动驾驶车辆在规划与控制方面的挑战。该系统通过理解道路场景来赋予车辆灵活的驾驶行为，并在模拟器和实际驾驶测试中展示了高效能。由于Co-driver系统是一个具体的应用实例，它涉及到自动驾驶车辆的控制和决策，因此它更符合Agent的分类，即一个能够执行任务和做出决策的智能实体。",
      "自动驾驶",
      "智能交通系统"
    ]
  },
  {
    "title": "FlockGPT: Guiding UAV Flocking with Linguistic Orchestration",
    "submit_datetime": "2024年05月09日",
    "abstract": "This article presents the world's first rapid drone flocking control using natural language through generative AI. The described approach enables the intuitive orchestration of a flock of any size to achieve the desired geometry. The key feature of the method is the development of a new interface based on Large Language Models to communicate with the user and to generate the target geometry descriptions. Users can interactively modify or provide comments during the construction of the flock geometry model. By combining flocking technology and defining the target surface using a signed distance function, smooth and adaptive movement of the drone swarm between target states is achieved.\n  Our user study on FlockGPT confirmed a high level of intuitive control over drone flocking by users. Subjects who had never previously controlled a swarm of drones were able to construct complex figures in just a few iterations and were able to accurately distinguish the formed swarm drone figures. The results revealed a high recognition rate for six different geometric patterns generated through the LLM-based interface and performed by a simulated drone flock (mean of 80% with a maximum of 93\\% for cube and tetrahedron patterns). Users commented on low temporal demand (19.2 score in NASA-TLX), high performance (26 score in NASA-TLX), attractiveness (1.94 UEQ score), and hedonic quality (1.81 UEQ score) of the developed system. The FlockGPT demo code repository can be found at: coming soon",
    "pdf_link": "https://arxiv.org/abs/2405.05872",
    "graphs": [],
    "abstract_cn": "本文首次展示了通过生成式AI实现的自然语言快速无人机群集控制，使得用户能够直观地指挥无人机群，创造出任何规模的理想形状。该技术的关键在于开发了一个基于大型语言模型的创新接口，它不仅与用户沟通，还生成了目标形状的描述。用户在构建无人机群形状模型时，可以实时互动修改或提出意见。结合群集技术和带符号距离函数的目标表面定义，无人机群得以在不同目标状态间流畅且自适应地移动。我们的FlockGPT用户研究表明，即使是无人机群控制的新手，也能迅速构建出复杂图形，并准确识别无人机群形成的图案。研究结果表明，通过LLM接口生成的六种几何图案识别率极高（平均80%，立方体和四面体图案高达93%）。用户对系统的低时间需求（NASA-TLX评分19.2）、高性能（NASA-TLX评分26）、吸引力（UEQ评分1.94）和感性质量（UEQ评分1.81）给予了高度评价。FlockGPT演示代码仓库即将上线。",
    "title_cn": "FlockGPT：以语言学编排之手，引领无人机群舞于天际在翻译过程中，我首先确保了原文的核心概念“FlockGPT”和“语言学编排指导无人机群集”被准确传达。然后，在步骤2中，我采用了更加生动和形象的表达方式，将“指导”转化为“引领”，“无人机群集”转化为“无人机群舞于天际”，以此来增强语言的生动性和优雅性，同时保持了原文的意思不变。",
    "tags": [
      "Agent\n\n这篇论文介绍了一个基于大型语言模型的创新接口，用于实现自然语言快速无人机群集控制。这个系统允许用户通过自然语言指令直观地指挥无人机群，创造出各种规模的理想形状。该技术的关键在于开发了一个能够与用户沟通并生成目标形状描述的接口。通过结合群集技术和带符号距离函数的目标表面定义，无人机群能够在不同目标状态间流畅且自适应地移动。这项工作展示了如何利用大型语言模型作为智能代理（Agent）来控制无人机群，因此属于Agent分类。",
      "无人机控制",
      "人工智能交互界面"
    ]
  },
  {
    "title": "Robots Can Feel: LLM-based Framework for Robot Ethical Reasoning",
    "submit_datetime": "2024年05月09日",
    "abstract": "This paper presents the development of a novel ethical reasoning framework for robots. \"Robots Can Feel\" is the first system for robots that utilizes a combination of logic and human-like emotion simulation to make decisions in morally complex situations akin to humans. The key feature of the approach is the management of the Emotion Weight Coefficient - a customizable parameter to assign the role of emotions in robot decision-making. The system aims to serve as a tool that can equip robots of any form and purpose with ethical behavior close to human standards. Besides the platform, the system is independent of the choice of the base model. During the evaluation, the system was tested on 8 top up-to-date LLMs (Large Language Models). This list included both commercial and open-source models developed by various companies and countries. The research demonstrated that regardless of the model choice, the Emotions Weight Coefficient influences the robot's decision similarly. According to ANOVA analysis, the use of different Emotion Weight Coefficients influenced the final decision in a range of situations, such as in a request for a dietary violation F(4, 35) = 11.2, p = 0.0001 and in an animal compassion situation F(4, 35) = 8.5441, p = 0.0001. A demonstration code repository is provided at: https://github.com/TemaLykov/robots_can_feel",
    "pdf_link": "https://arxiv.org/abs/2405.05824",
    "graphs": [],
    "abstract_cn": "本文推出了一种创新的机器人伦理推理框架，名为“机器人能感受”。该系统首次将逻辑与类人情感模拟融合，使机器人在面对道德难题时能做出类似人类的决策。其核心在于情感权重系数的调控，这一可调参数决定了情感在机器人决策中的分量。该系统旨在赋予各类机器人以接近人类标准的伦理行为，且不依赖于特定的基础模型。评估中，该系统在8个顶尖的LLM上进行了测试，涵盖了来自不同国家和公司的商业与开源模型。研究显示，不论模型如何，情感权重系数均能影响机器人的决策。ANOVA分析表明，在诸如饮食违规请求（F(4, 35) = 11.2, p = 0.0001）和动物同情等情境中，情感权重系数的不同设置显著影响了机器人的最终决策。演示代码库地址为：https://github.com/TemaLykov/robots_can_feel。",
    "title_cn": "机器人亦有情：大型语言模型驱动的机器人伦理决策框架在",
    "tags": [
      "Agent\n\n这篇论文介绍了一种创新的机器人伦理推理框架，名为“机器人能感受”，它通过融合逻辑与类人情感模拟来使机器人在面对道德难题时做出类似人类的决策。该框架的核心是情感权重系数的调控，这表明它是一个用于指导机器人（即Agent）行为的系统。因此，它属于Agent分类。虽然它涉及了LLM（大型语言模型）的测试，但这里的LLM是作为测试平台，而不是研究的主要焦点，因此它不属于LLM应用或LLM理论分类。同时，它也不属于RAG分类，因为RAG通常指的是检索增强生成模型，而这里并没有提及相关的检索增强生成技术。",
      "机器人伦理",
      "人工智能伦理"
    ]
  },
  {
    "title": "Boosting Multimodal Large Language Models with Visual Tokens Withdrawal for Rapid Inference",
    "submit_datetime": "2024年05月09日",
    "abstract": "Multimodal large language models (MLLMs) demand considerable computations for inference due to the extensive parameters and the additional input tokens needed for visual information representation. Herein, we introduce Visual Tokens Withdrawal (VTW), a plug-and-play module to boost MLLMs for rapid inference. Our approach is inspired by two intriguing phenomena we have observed: (1) the attention sink phenomenon that is prevalent in LLMs also persists in MLLMs, suggesting that initial tokens and nearest tokens receive the majority of attention, while middle vision tokens garner minimal attention in deep layers; (2) the presence of information migration, which implies that visual information is transferred to subsequent text tokens within the first few layers of MLLMs. As per our findings, we conclude that vision tokens are not necessary in the deep layers of MLLMs. Thus, we strategically withdraw them at a certain layer, enabling only text tokens to engage in subsequent layers. To pinpoint the ideal layer for vision tokens withdrawal, we initially analyze a limited set of tiny datasets and choose the first layer that meets the Kullback-Leibler divergence criterion. Our VTW approach can cut computational overhead by over 40\\% across diverse multimodal tasks while maintaining performance. Our code is released at https://github.com/lzhxmu/VTW.",
    "pdf_link": "https://arxiv.org/abs/2405.05803",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.05803v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05803/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05803v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05803/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05803v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05803/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05803v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05803/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05803v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05803/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05803v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05803/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05803v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05803/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05803v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05803/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05803v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05803/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05803v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05803/x10.png"
      }
    ],
    "abstract_cn": "多模态大型语言模型（MLLMs）因庞大的参数和视觉信息所需的额外输入令牌，推理时计算需求巨大。我们提出的视觉令牌撤退（VTW）模块，如同即插即用的加速器，旨在提升MLLMs的推理速度。我们的灵感源自两个观察：一是注意力陷阱现象，在MLLMs中，初始与近邻令牌吸聚大部分注意力，而深层中的视觉令牌则被忽视；二是信息迁移现象，视觉信息在前几层便转移到文本令牌。基于此，我们认为深层MLLMs无需视觉令牌，故策略性地在特定层级撤除它们，仅留文本令牌继续参与。为找到撤退的最佳层级，我们分析小型数据集，依据Kullback-Leibler散度标准选择首个符合条件的层级。VTW方法在保持性能的同时，能将计算开销削减逾40%，适用于各类多模态任务。我们的代码已公开于https://github.com/lzhxmu/VTW。",
    "title_cn": "借助视觉令牌的巧妙撤回，多模态大型语言模型得以加速推理，如同智慧之光在瞬间闪耀。",
    "tags": [
      "LLM应用\n\n这篇论文探讨了多模态大型语言模型（MLLMs）的推理效率问题，并提出了一种名为视觉令牌撤退（VTW）的模块来加速推理过程。该研究关注的是LLM在实际应用中的性能优化，特别是通过减少计算需求来提高推理速度，这是LLM应用领域的一个重要议题。虽然研究中可能涉及一些理论分析，如注意力陷阱现象和信息迁移现象的观察，但其核心贡献在于提出并验证了一种实际可行的加速方法，这使得它更适合归类于LLM应用类别。",
      "人工智能加速",
      "多模态学习"
    ]
  },
  {
    "title": "Towards a More Inclusive AI: Progress and Perspectives in Large Language Model Training for the Sámi Language",
    "submit_datetime": "2024年05月09日",
    "abstract": "Sámi, an indigenous language group comprising multiple languages, faces digital marginalization due to the limited availability of data and sophisticated language models designed for its linguistic intricacies. This work focuses on increasing technological participation for the Sámi language. We draw the attention of the ML community towards the language modeling problem of Ultra Low Resource (ULR) languages. ULR languages are those for which the amount of available textual resources is very low, and the speaker count for them is also very low. ULRLs are also not supported by mainstream Large Language Models (LLMs) like ChatGPT, due to which gathering artificial training data for them becomes even more challenging. Mainstream AI foundational model development has given less attention to this category of languages. Generally, these languages have very few speakers, making it hard to find them. However, it is important to develop foundational models for these ULR languages to promote inclusion and the tangible abilities and impact of LLMs. To this end, we have compiled the available Sámi language resources from the web to create a clean dataset for training language models. In order to study the behavior of modern LLM models with ULR languages (Sámi), we have experimented with different kinds of LLMs, mainly at the order of $\\sim$ seven billion parameters. We have also explored the effect of multilingual LLM training for ULRLs. We found that the decoder-only models under a sequential multilingual training scenario perform better than joint multilingual training, whereas multilingual training with high semantic overlap, in general, performs better than training from scratch.This is the first study on the Sámi language for adapting non-statistical language models that use the latest developments in the field of natural language processing (NLP).",
    "pdf_link": "https://arxiv.org/abs/2405.05777",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.05777v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05777/sami2eng.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05777v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05777/tartunlp.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05777v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05777/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05777v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05777/x2.png"
      }
    ],
    "abstract_cn": "萨米语，这一原住民语言群体因缺乏数据和专门针对其语言复杂性的高级语言模型而面临数字边缘化。我们的工作旨在提升萨米语的技术参与度，并呼吁机器学习社区关注超低资源语言的语言建模挑战。这些语言资源稀缺，使用者寥寥无几，且未被主流大型语言模型如ChatGPT所涵盖，使得人工训练数据的收集尤为艰难。主流AI基础模型开发对这类语言的忽视，使得这些语言的使用者难以寻觅。然而，为这些超低资源语言构建基础模型，对于推动包容性和大型语言模型的实际应用至关重要。为此，我们整合了网络上的萨米语资源，打造了一个用于训练语言模型的纯净数据集。我们通过实验不同规模的现代大型语言模型，探究了它们与萨米语的互动，特别是在约七亿参数的模型上。此外，我们还研究了多语言训练对超低资源语言的影响，发现顺序多语言训练下的解码器模型优于联合训练，而高语义重叠的多语言训练通常胜过从零开始的训练。这是首次针对萨米语的研究，旨在利用自然语言处理领域的最新进展，适应非统计语言模型。",
    "title_cn": "迈向包容性AI：大型语言模型训练中萨米语的进展与展望",
    "tags": [
      "LLM应用\n\n这篇论文关注的是超低资源语言（如萨米语）的语言建模挑战，并探讨了如何利用现代大型语言模型来提升这些语言的技术参与度。它涉及了数据集的构建、模型的训练和多语言训练对超低资源语言的影响，这些都是大型语言模型在实际应用中的具体问题和解决方案。因此，它属于LLM应用类别。",
      "原住民语言保护",
      ""
    ]
  },
  {
    "title": "Experimental Pragmatics with Machines: Testing LLM Predictions for the Inferences of Plain and Embedded Disjunctions",
    "submit_datetime": "2024年05月09日",
    "abstract": "Human communication is based on a variety of inferences that we draw from sentences, often going beyond what is literally said. While there is wide agreement on the basic distinction between entailment, implicature, and presupposition, the status of many inferences remains controversial. In this paper, we focus on three inferences of plain and embedded disjunctions, and compare them with regular scalar implicatures. We investigate this comparison from the novel perspective of the predictions of state-of-the-art large language models, using the same experimental paradigms as recent studies investigating the same inferences with humans. The results of our best performing models mostly align with those of humans, both in the large differences we find between those inferences and implicatures, as well as in fine-grained distinctions among different aspects of those inferences.",
    "pdf_link": "https://arxiv.org/abs/2405.05776",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.05776v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05776/Screenshot_2024-02-02_at_11.35.29.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05776v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05776/Acceptance.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05776v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05776/Closeness.png"
      }
    ],
    "abstract_cn": "人类交流依赖于超越字面意义的深层推断。尽管学界普遍认同蕴涵、隐含意义和预设的基本区别，但许多推断的本质仍存争议。本文聚焦于三种析取句的推断，并与常规标量隐含意义进行对比。我们采用最先进的大型语言模型，通过与人类实验相同的范式，探索这些推断的预测。结果显示，我们的模型与人类在推断与隐含意义的大差异以及推断细节上高度一致，这表明了语言模型在理解复杂语言现象方面的潜力。",
    "title_cn": "机器实验语用学：探究大型语言模型在解析简单与嵌入式析取推理中的预测能力",
    "tags": [
      "LLM理论\n\n这篇论文探讨了大型语言模型（LLM）在理解复杂语言现象方面的能力，特别是关于人类交流中的深层推断，如蕴涵、隐含意义和预设。研究通过使用最先进的LLM来模拟人类实验，以探索这些推断的预测，并评估模型与人类在这些推断上的一致性。这属于对LLM理论层面的研究，因为它关注的是模型如何理解和处理语言的深层结构，而不是直接应用于特定的Agent或RAG系统，也不是关于LLM的具体应用案例。因此，它被归类为LLM理论研究。",
      "",
      "语言学研究"
    ]
  },
  {
    "title": "Large Language Model-Aided Evolutionary Search for Constrained Multiobjective Optimization",
    "submit_datetime": "2024年05月09日",
    "abstract": "Evolutionary algorithms excel in solving complex optimization problems, especially those with multiple objectives. However, their stochastic nature can sometimes hinder rapid convergence to the global optima, particularly in scenarios involving constraints. In this study, we employ a large language model (LLM) to enhance evolutionary search for solving constrained multi-objective optimization problems. Our aim is to speed up the convergence of the evolutionary population. To achieve this, we finetune the LLM through tailored prompt engineering, integrating information concerning both objective values and constraint violations of solutions. This process enables the LLM to grasp the relationship between well-performing and poorly performing solutions based on the provided input data. Solution's quality is assessed based on their constraint violations and objective-based performance. By leveraging the refined LLM, it can be used as a search operator to generate superior-quality solutions. Experimental evaluations across various test benchmarks illustrate that LLM-aided evolutionary search can significantly accelerate the population's convergence speed and stands out competitively against cutting-edge evolutionary algorithms.",
    "pdf_link": "https://arxiv.org/abs/2405.05767",
    "graphs": [],
    "abstract_cn": "进化算法在多目标优化问题上表现卓越，但随机性有时会阻碍其在约束场景下的快速收敛。本研究采用LLM来提升进化搜索，旨在加速受约束多目标问题的收敛。通过定制提示工程微调LLM，我们整合了目标值与约束违反信息，使其能洞察优秀与不佳解决方案间的联系。我们依据约束与目标性能评估解决方案质量，并利用精细调整的LLM作为搜索算子，生成更优解。实验证明，LLM辅助的进化搜索在多个测试基准上显著提升了收敛速度，与顶尖进化算法相比，展现出竞争优势。",
    "title_cn": "借助大型语言模型之力，进化搜索在约束多目标优化领域展翅高飞。",
    "tags": [
      "LLM应用\n\n这篇论文探讨了如何利用大型语言模型（LLM）来增强进化算法在受约束多目标优化问题上的性能，特别是在加速收敛方面。通过定制化的提示工程和微调LLM，研究者能够更好地评估解决方案的质量，并生成更优的解决方案。这种方法在实验中显示出了与顶尖进化算法相比的竞争优势，因此属于LLM在实际应用中的一个案例，即在优化问题求解领域的应用。",
      "多目标优化",
      "进化算法"
    ]
  },
  {
    "title": "Similarity Guided Multimodal Fusion Transformer for Semantic Location Prediction in Social Media",
    "submit_datetime": "2024年05月09日",
    "abstract": "The purpose of semantic location prediction is to extract relevant semantic location information from multimodal social media posts, offering a more contextual understanding of daily activities compared to GPS coordinates. However, this task becomes challenging due to the presence of noise and irrelevant information in \"text-image\" pairs. Existing methods suffer from insufficient feature representations and fail to consider the comprehensive integration of similarity at different granularities, making it difficult to filter out noise and irrelevant information. To address these challenges, we propose a Similarity-Guided Multimodal Fusion Transformer (SG-MFT) for predicting social users' semantic locations. First, we utilize a pre-trained large-scale vision-language model to extract high-quality feature representations from social media posts. Then, we introduce a Similarity-Guided Interaction Module (SIM) to alleviate modality heterogeneity and noise interference by incorporating coarse-grained and fine-grained similarity guidance for modality interactions. Specifically, we propose a novel similarity-aware feature interpolation attention mechanism at the coarse level, leveraging modality-wise similarity to mitigate heterogeneity and reduce noise within each modality. Meanwhile, we employ a similarity-aware feed-forward block at the fine level, utilizing element-wise similarity to further mitigate the impact of modality heterogeneity. Building upon pre-processed features with minimal noise and modal interference, we propose a Similarity-aware Feature Fusion Module (SFM) to fuse two modalities with cross-attention mechanism. Comprehensive experimental results demonstrate the superior performance of our proposed method in handling modality imbalance while maintaining efficient fusion effectiveness.",
    "pdf_link": "https://arxiv.org/abs/2405.05760",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.05760v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05760/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05760v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05760/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05760v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05760/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05760v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05760/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05760v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05760/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05760v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05760/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05760v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05760/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05760v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05760/x8.png"
      }
    ],
    "abstract_cn": "语义位置预测旨在从多模态社交媒体内容中提炼出富含上下文的语义位置信息，以超越单纯的GPS坐标，更深刻地理解人们的日常活动。然而，这项任务因“文本-图像”对中的噪声和无关信息而变得复杂。现有方法在特征提取上力不从心，且未能全面整合不同层次的相似性，导致难以剔除干扰信息。为此，我们创新性地提出了相似性引导的多模态融合变压器（SG-MFT），旨在精准预测社交用户的语义位置。我们首先借助预训练的视觉-语言模型，从社交媒体帖子中提炼出高质量的特征。接着，我们设计了一个相似性引导的交互模块（SIM），通过粗细粒度的相似性引导，有效缓解模态间的异质性和噪声问题。在粗粒度层面，我们引入了新颖的相似性感知特征插值注意力机制，以模态间的相似性为锚点，减轻异质性并净化噪声。在细粒度层面，我们运用相似性感知的馈送前向块，通过元素间的相似性进一步调和模态差异。最后，我们构建了相似性感知的特征融合模块（SFM），通过交叉注意力机制巧妙融合两种模态。实验证明，我们的方法在处理模态不平衡的同时，保持了融合的高效性，展现了卓越的性能。",
    "title_cn": "基于相似性引导的多模态融合变压器，用于社交媒体中语义位置的精准预测。",
    "tags": [
      "RAG\n\n这篇论文主要探讨了如何从多模态社交媒体内容中提取语义位置信息，并提出了一个名为相似性引导的多模态融合变压器（SG-MFT）的新方法。该方法通过预训练的视觉-语言模型提取特征，并设计了相似性引导的交互模块（SIM）来处理模态间的异质性和噪声问题。这与RAG（Retrieval-Augmented Generation）的概念相符，因为RAG模型通常用于结合检索（retrieval）和生成（generation）来处理多模态数据，以提高语言模型的性能。因此，这篇论文更适合归类为RAG。",
      "社交媒体分析",
      "位置预测"
    ]
  },
  {
    "title": "Exploring the Potential of Human-LLM Synergy in Advancing Qualitative Analysis: A Case Study on Mental-Illness Stigma",
    "submit_datetime": "2024年05月09日",
    "abstract": "Qualitative analysis is a challenging, yet crucial aspect of advancing research in the field of Human-Computer Interaction (HCI). Recent studies show that large language models (LLMs) can perform qualitative coding within existing schemes, but their potential for collaborative human-LLM discovery and new insight generation in qualitative analysis is still underexplored. To bridge this gap and advance qualitative analysis by harnessing the power of LLMs, we propose CHALET, a novel methodology that leverages the human-LLM collaboration paradigm to facilitate conceptualization and empower qualitative research. The CHALET approach involves LLM-supported data collection, performing both human and LLM deductive coding to identify disagreements, and performing collaborative inductive coding on these disagreement cases to derive new conceptual insights. We validated the effectiveness of CHALET through its application to the attribution model of mental-illness stigma, uncovering implicit stigmatization themes on cognitive, emotional and behavioral dimensions. We discuss the implications for future research, methodology, and the transdisciplinary opportunities CHALET presents for the HCI community and beyond.",
    "pdf_link": "https://arxiv.org/abs/2405.05758",
    "graphs": [],
    "abstract_cn": "定性分析在人机交互研究中至关重要，但充满挑战。大型语言模型虽能在现有框架内进行定性编码，但在促进人机协作发现新见解方面潜力未尽。为此，我们提出CHALET方法，一种结合人机协作的新型研究方法，旨在深化概念理解，提升定性研究。CHALET通过LLM辅助数据收集，结合人机演绎编码识别分歧，并协同归纳编码以发掘新概念。我们通过分析心理疾病污名模型验证了CHALET的有效性，揭示了隐性污名化的多维主题。本文探讨了CHALET对未来研究、方法创新及跨学科合作的深远影响。",
    "title_cn": "揭秘人机共舞：大型语言模型助力定性分析新篇章——以心理疾病污名化研究为例",
    "tags": [
      "Agent\n\n理由：这篇论文提出了一种名为CHALET的新型研究方法，该方法结合了大型语言模型（LLM）辅助的数据收集和分析，以及人机协作的过程，旨在深化概念理解和提升定性研究。这种方法涉及创建一个智能代理（Agent），该代理能够与人类研究者协作，共同进行数据分析和概念发现。因此，这篇论文更符合Agent分类，因为它描述了一种利用LLM作为智能代理来辅助研究的方法。",
      "人机交互",
      "心理学研究"
    ]
  },
  {
    "title": "Can large language models understand uncommon meanings of common words?",
    "submit_datetime": "2024年05月09日",
    "abstract": "Large language models (LLMs) like ChatGPT have shown significant advancements across diverse natural language understanding (NLU) tasks, including intelligent dialogue and autonomous agents. Yet, lacking widely acknowledged testing mechanisms, answering `whether LLMs are stochastic parrots or genuinely comprehend the world' remains unclear, fostering numerous studies and sparking heated debates. Prevailing research mainly focuses on surface-level NLU, neglecting fine-grained explorations. However, such explorations are crucial for understanding their unique comprehension mechanisms, aligning with human cognition, and finally enhancing LLMs' general NLU capacities. To address this gap, our study delves into LLMs' nuanced semantic comprehension capabilities, particularly regarding common words with uncommon meanings. The idea stems from foundational principles of human communication within psychology, which underscore accurate shared understandings of word semantics. Specifically, this paper presents the innovative construction of a Lexical Semantic Comprehension (LeSC) dataset with novel evaluation metrics, the first benchmark encompassing both fine-grained and cross-lingual dimensions. Introducing models of both open-source and closed-source, varied scales and architectures, our extensive empirical experiments demonstrate the inferior performance of existing models in this basic lexical-meaning understanding task. Notably, even the state-of-the-art LLMs GPT-4 and GPT-3.5 lag behind 16-year-old humans by 3.9% and 22.3%, respectively. Additionally, multiple advanced prompting techniques and retrieval-augmented generation are also introduced to help alleviate this trouble, yet limitations persist. By highlighting the above critical shortcomings, this research motivates further investigation and offers novel insights for developing more intelligent LLMs.",
    "pdf_link": "https://arxiv.org/abs/2405.05741",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.05741v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05741/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05741v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05741/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05741v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05741/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05741v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05741/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05741v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05741/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05741v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05741/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05741v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05741/x7.png"
      }
    ],
    "abstract_cn": "ChatGPT等大型语言模型在智能对话和自主代理等NLU任务中取得了显著进步，但缺乏公认的测试机制，使得“LLMs是否真正理解世界”这一问题仍悬而未决，引发广泛研究和激烈讨论。现有研究多停留在表面理解，忽视了深入探索的重要性。为了深入理解LLMs的语义理解机制，我们的研究聚焦于常用词的不常见意义，这源于心理学中对词语准确共享理解的基本原则。我们构建了首个涵盖精细化和跨语言维度的Lexical Semantic Comprehension（LeSC）数据集，并通过广泛实验揭示了现有模型在基本词汇理解上的不足，即使是顶尖的GPT-4和GPT-3.5也分别落后于16岁人类3.9%和22.3%。尽管引入了先进的提示技术和检索增强生成，但问题依旧存在。本研究强调了这些关键缺陷，为开发更智能的LLMs提供了新的研究方向。",
    "title_cn": "大型语言模型是否能洞察常见词汇的隐秘含义？",
    "tags": [
      "LLM理论\n\n这篇论文关注的是大型语言模型（LLMs）在语义理解方面的机制和局限性，特别是对于常用词的不常见意义的理解。它通过构建一个新的数据集LeSC来评估模型的理解能力，并指出即使是当前最先进的模型也存在理解上的不足。这表明了LLMs在理论层面上的挑战和需要进一步研究的问题，因此属于LLM理论分类。",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Detecting Statements in Text: A Domain-Agnostic Few-Shot Solution",
    "submit_datetime": "2024年05月09日",
    "abstract": "Many tasks related to Computational Social Science and Web Content Analysis involve classifying pieces of text based on the claims they contain. State-of-the-art approaches usually involve fine-tuning models on large annotated datasets, which are costly to produce. In light of this, we propose and release a qualitative and versatile few-shot learning methodology as a common paradigm for any claim-based textual classification task. This methodology involves defining the classes as arbitrarily sophisticated taxonomies of claims, and using Natural Language Inference models to obtain the textual entailment between these and a corpus of interest. The performance of these models is then boosted by annotating a minimal sample of data points, dynamically sampled using the well-established statistical heuristic of Probabilistic Bisection. We illustrate this methodology in the context of three tasks: climate change contrarianism detection, topic/stance classification and depression-relates symptoms detection. This approach rivals traditional pre-train/fine-tune approaches while drastically reducing the need for data annotation.",
    "pdf_link": "https://arxiv.org/abs/2405.05705",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.05705v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05705/Approach_overview.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05705v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05705/round_1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05705v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05705/round_2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05705v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05705/round_4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05705v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05705/round_16.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05705v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05705/0.6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05705v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05705/0.7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05705v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05705/0.8.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05705v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05705/0.9.png"
      }
    ],
    "abstract_cn": "在计算社会科学和网络内容分析领域，文本分类任务往往依赖于文本中的声明内容。传统上，这些任务依赖于大规模注释数据集上的模型微调，成本高昂。为此，我们提出了一种新颖的少样本学习方法，旨在为基于声明的文本分类任务提供一个灵活且高效的解决方案。我们的方法通过构建复杂的声明分类法，并利用自然语言推理模型来识别文本间的蕴含关系，从而定义分类标准。通过采用概率二分法这一统计技术，我们能够动态地从少量注释数据中抽样，显著提升模型性能。这种方法在检测气候变化怀疑论、主题立场分类以及抑郁症状识别等任务中得到了验证，不仅与传统预训练/微调方法相媲美，还大幅降低了数据注释的需求。",
    "title_cn": "声明检测：跨领域少量样本的通用解决方案在翻译过程中，我首先确保了原文意思的准确传达，然后对翻译进行了优化，使其更符合中文的表达习惯，同时保持了原文的简洁性和生动性。",
    "tags": [
      "Agent\n\n理由：这篇论文提出了一种新颖的少样本学习方法，用于基于声明的文本分类任务。它通过构建声明分类法和利用自然语言推理模型来识别文本间的蕴含关系，从而定义分类标准。这种方法可以被视为一个智能Agent，因为它能够动态地从少量注释数据中抽样，并提升模型性能，从而在不同的文本分类任务中发挥作用。虽然这种方法可能涉及到大型语言模型（LLM）的应用，但论文的重点在于提出和验证一种新的学习方法，而不是专注于LLM的理论或应用。因此，将其归类为Agent更为合适。",
      "计算社会科学",
      "网络内容分析"
    ]
  },
  {
    "title": "Letter to the Editor: What are the legal and ethical considerations of submitting radiology reports to ChatGPT?",
    "submit_datetime": "2024年05月09日",
    "abstract": "This letter critically examines the recent article by Infante et al. assessing the utility of large language models (LLMs) like GPT-4, Perplexity, and Bard in identifying urgent findings in emergency radiology reports. While acknowledging the potential of LLMs in generating labels for computer vision, concerns are raised about the ethical implications of using patient data without explicit approval, highlighting the necessity of stringent data protection measures under GDPR.",
    "pdf_link": "https://arxiv.org/abs/2405.05647",
    "graphs": [],
    "abstract_cn": "本文深入探讨了Infante等人的研究，探讨了GPT-4、Perplexity和Bard等大型语言模型在急诊放射学报告中识别关键信息的能力。尽管这些模型在自动化标签生成方面展现出潜力，但文章也警示了未经患者同意使用其数据可能引发的伦理问题，并强调了在GDPR框架下实施严格数据保护的重要性。",
    "title_cn": "编辑大人，关于将放射学报告提交至ChatGPT，我们需深思其法律与伦理的边界。此举涉及的法规遵循与道德考量，值得我们共同探讨。",
    "tags": [
      "LLM应用\n\n这篇论文摘要讨论了大型语言模型（如GPT-4、Perplexity和Bard）在急诊放射学报告中识别关键信息的能力，以及相关的伦理和数据保护问题。这属于LLM在特定领域（医疗领域）的应用，因此归类为LLM应用。虽然文中提到了伦理和数据保护问题，但这些讨论是围绕LLM的应用展开的，而不是对LLM理论本身的探讨，因此不符合LLM理论分类。同时，文中没有提到Agent或RAG相关的概念，所以这两个分类也不适用。",
      "急诊放射学",
      "数据隐私保护"
    ]
  },
  {
    "title": "An Automatic Prompt Generation System for Tabular Data Tasks",
    "submit_datetime": "2024年05月09日",
    "abstract": "Efficient processing of tabular data is important in various industries, especially when working with datasets containing a large number of columns. Large language models (LLMs) have demonstrated their ability on several tasks through carefully crafted prompts. However, creating effective prompts for tabular datasets is challenging due to the structured nature of the data and the need to manage numerous columns. This paper presents an innovative auto-prompt generation system suitable for multiple LLMs, with minimal training. It proposes two novel methods; 1) A Reinforcement Learning-based algorithm for identifying and sequencing task-relevant columns 2) Cell-level similarity-based approach for enhancing few-shot example selection. Our approach has been extensively tested across 66 datasets, demonstrating improved performance in three downstream tasks: data imputation, error detection, and entity matching using two distinct LLMs; Google flan-t5-xxl and Mixtral 8x7B.",
    "pdf_link": "https://arxiv.org/abs/2405.05618",
    "graphs": [],
    "abstract_cn": "在各行各业，高效处理表格数据至关重要，尤其是面对列数众多的数据集。大型语言模型（LLMs）凭借精心设计的提示在多任务上大放异彩。然而，为结构化的表格数据集设计有效提示颇具挑战，因需巧妙管理众多列。本文创新性地提出了一种自动提示生成系统，适用于多种LLMs，且训练需求极低。该系统包含两种新颖方法：一是基于强化学习的算法，用于精准识别并排序任务相关列；二是基于单元格相似性的策略，用于优化少量样本示例的选择。我们的方法在66个数据集上经过严格测试，显著提升了三个下游任务的性能：数据插补、错误检测和实体匹配，涉及两种尖端LLMs：Google flan-t5-xxl和Mixtral 8x7B。",
    "title_cn": "表格数据任务的智能提示生成系统在这个系统中，我们将探索如何自动生成有效的提示，以帮助用户更好地理解和处理表格数据。通过智能算法，系统能够识别数据的关键特征，并据此生成针对性的提示，从而提高用户在处理表格数据任务时的效率和准确性。",
    "tags": [
      "LLM应用\n\n这篇论文探讨了如何利用大型语言模型（LLMs）高效处理结构化的表格数据集，特别是面对列数众多的数据集时。它提出了一种自动提示生成系统，该系统能够适应多种LLMs，并且对训练的需求很低。论文中的方法通过基于强化学习的算法和基于单元格相似性的策略，有效地处理了表格数据集中的列管理和样本示例选择问题。这种方法在多个数据集上进行了测试，并在数据插补、错误检测和实体匹配等下游任务上提升了性能。因此，这篇论文属于LLM应用类别，因为它专注于LLMs在实际数据处理任务中的应用和优化。",
      "数据处理",
      "人工智能"
    ]
  },
  {
    "title": "Memory-Space Visual Prompting for Efficient Vision-Language Fine-Tuning",
    "submit_datetime": "2024年05月09日",
    "abstract": "Current solutions for efficiently constructing large vision-language (VL) models follow a two-step paradigm: projecting the output of pre-trained vision encoders to the input space of pre-trained language models as visual prompts; and then transferring the models to downstream VL tasks via end-to-end parameter-efficient fine-tuning (PEFT). However, this paradigm still exhibits inefficiency since it significantly increases the input length of the language models. In this paper, in contrast to integrating visual prompts into inputs, we regard visual prompts as additional knowledge that facilitates language models in addressing tasks associated with visual information. Motivated by the finding that Feed-Forward Network (FFN) of language models acts as \"key-value memory\", we introduce a novel approach termed memory-space visual prompting (MemVP), wherein visual prompts are concatenated with the weights of FFN for visual knowledge injection. Experimental results across various VL tasks and language models reveal that MemVP significantly reduces the training time and inference latency of the finetuned VL models and surpasses the performance of previous PEFT methods. Code: https://github.com/JieShibo/MemVP",
    "pdf_link": "https://arxiv.org/abs/2405.05615",
    "graphs": [],
    "abstract_cn": "当前构建大型视觉-语言模型的方法采用两步走策略：首先将视觉信息转化为语言模型的输入提示，然后通过高效微调将模型应用于特定任务。但这种方法因增加输入长度而效率受限。本文提出了一种新思路，将视觉提示视为辅助语言模型处理视觉任务的额外知识。基于语言模型前馈网络具有“键值记忆”功能的发现，我们创新性地提出了记忆空间视觉提示（MemVP）方法，将视觉提示与前馈网络权重结合，实现视觉知识的注入。实验证明，MemVP不仅大幅缩短了训练和推理时间，而且在性能上超越了现有的高效微调方法。详细代码可访问：https://github.com/JieShibo/MemVP。",
    "title_cn": "记忆空间视觉提示：高效视觉语言微调的新途径",
    "tags": [
      "LLM应用\n\n这篇论文探讨了如何将视觉信息有效地整合到大型语言模型中，以提高处理视觉任务的效率和性能。通过提出的记忆空间视觉提示（MemVP）方法，作者展示了如何将视觉提示与语言模型的前馈网络权重结合，从而在不增加输入长度的情况下，有效地将视觉知识注入模型。这种方法在实际应用中提高了训练和推理的效率，并在性能上超越了现有方法。因此，这篇论文属于大型语言模型（LLM）的应用范畴，因为它关注的是如何将LLM应用于视觉-语言任务，并提出了具体的应用方法。",
      "计算机视觉",
      ""
    ]
  },
  {
    "title": "Chain of Attack: a Semantic-Driven Contextual Multi-Turn attacker for LLM",
    "submit_datetime": "2024年05月09日",
    "abstract": "Large language models (LLMs) have achieved remarkable performance in various natural language processing tasks, especially in dialogue systems. However, LLM may also pose security and moral threats, especially in multi round conversations where large models are more easily guided by contextual content, resulting in harmful or biased responses. In this paper, we present a novel method to attack LLMs in multi-turn dialogues, called CoA (Chain of Attack). CoA is a semantic-driven contextual multi-turn attack method that adaptively adjusts the attack policy through contextual feedback and semantic relevance during multi-turn of dialogue with a large model, resulting in the model producing unreasonable or harmful content. We evaluate CoA on different LLMs and datasets, and show that it can effectively expose the vulnerabilities of LLMs, and outperform existing attack methods. Our work provides a new perspective and tool for attacking and defending LLMs, and contributes to the security and ethical assessment of dialogue systems.",
    "pdf_link": "https://arxiv.org/abs/2405.05610",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）在对话系统等自然语言处理任务中表现卓越，但同时也潜藏着安全和道德风险。特别是在多轮对话中，LLMs易受上下文引导，可能产生有害或有偏见的回应。本文创新性地提出了CoA（攻击链）方法，这是一种基于语义的上下文多轮攻击策略，能够根据对话中的上下文反馈和语义关联动态调整攻击策略，诱导LLMs产生不合理或有害内容。我们对CoA在多个LLMs和数据集上的效果进行了评估，结果显示CoA能有效揭示LLMs的弱点，并优于现有攻击手段。我们的研究为LLMs的攻防提供了新视角和工具，对提升对话系统的安全性和伦理标准具有重要意义。",
    "title_cn": "语义驱动攻击链：针对大型语言模型的多轮上下文攻击策略在",
    "tags": [
      "Agent\n\n这篇论文探讨了大型语言模型（LLMs）在多轮对话中的安全性和道德风险，并提出了一种新的攻击策略——CoA（攻击链）方法。这种方法专注于利用上下文反馈和语义关联来动态调整攻击策略，以诱导LLMs产生不合理或有害的内容。研究的重点在于揭示LLMs的弱点，并为攻防提供新的视角和工具，这与Agent领域的研究相符，因为Agent通常指的是能够自主行动和决策的实体，而在这篇论文中，CoA方法可以被视为一种攻击Agent，它针对LLMs进行策略性的攻击。因此，这篇论文更适合归类于Agent分类。",
      "对话系统",
      "网络安全"
    ]
  },
  {
    "title": "Can We Use Large Language Models to Fill Relevance Judgment Holes?",
    "submit_datetime": "2024年05月09日",
    "abstract": "Incomplete relevance judgments limit the re-usability of test collections. When new systems are compared against previous systems used to build the pool of judged documents, they often do so at a disadvantage due to the ``holes'' in test collection (i.e., pockets of un-assessed documents returned by the new system). In this paper, we take initial steps towards extending existing test collections by employing Large Language Models (LLM) to fill the holes by leveraging and grounding the method using existing human judgments. We explore this problem in the context of Conversational Search using TREC iKAT, where information needs are highly dynamic and the responses (and, the results retrieved) are much more varied (leaving bigger holes). While previous work has shown that automatic judgments from LLMs result in highly correlated rankings, we find substantially lower correlates when human plus automatic judgments are used (regardless of LLM, one/two/few shot, or fine-tuned). We further find that, depending on the LLM employed, new runs will be highly favored (or penalized), and this effect is magnified proportionally to the size of the holes. Instead, one should generate the LLM annotations on the whole document pool to achieve more consistent rankings with human-generated labels. Future work is required to prompt engineering and fine-tuning LLMs to reflect and represent the human annotations, in order to ground and align the models, such that they are more fit for purpose.",
    "pdf_link": "https://arxiv.org/abs/2405.05600",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.05600v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05600/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05600v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05600/x2.png"
      }
    ],
    "abstract_cn": "不完整的关联判断影响了测试集合的再利用，新系统在与旧系统比较时往往处于劣势，因为测试集合中存在未评估文档的“漏洞”。本文探讨了如何利用大型语言模型（LLM）来填补这些漏洞，特别是在对话式搜索的动态环境中。虽然LLM的自动判断能产生高度相关的排名，但结合人类判断时，相关性显著下降。我们还发现，LLM的选择会影响新系统的评价，漏洞越大，影响越显著。为了获得更一致的排名，应在整个文档池上应用LLM注释。未来的研究需要集中在如何通过提示工程和LLM微调来更好地反映人类判断，以确保模型更符合其设计目的。",
    "title_cn": "大型语言模型能否填补相关性判断的空白？这一问题引发了我们对人工智能在信息检索领域潜力的深思。",
    "tags": [
      "LLM应用\n\n这篇论文探讨了大型语言模型（LLM）在对话式搜索环境中填补测试集合中未评估文档“漏洞”的应用。它讨论了LLM在自动判断和结合人类判断时的表现，以及LLM选择对新系统评价的影响。论文强调了通过提示工程和LLM微调来更好地反映人类判断的重要性，以确保模型更符合其设计目的。这与LLM在特定应用场景中的实际应用和改进相关，因此归类为LLM应用。",
      "对话式搜索",
      "测试评估"
    ]
  },
  {
    "title": "OpenFactCheck: A Unified Framework for Factuality Evaluation of LLMs",
    "submit_datetime": "2024年05月09日",
    "abstract": "The increased use of large language models (LLMs) across a variety of real-world applications calls for mechanisms to verify the factual accuracy of their outputs. Difficulties lie in assessing the factuality of free-form responses in open domains. Also, different papers use disparate evaluation benchmarks and measurements, which renders them hard to compare and hampers future progress. To mitigate these issues, we propose OpenFactCheck, a unified factuality evaluation framework for LLMs. OpenFactCheck consists of three modules: (i) CUSTCHECKER allows users to easily customize an automatic fact-checker and verify the factual correctness of documents and claims, (ii) LLMEVAL, a unified evaluation framework assesses LLM's factuality ability from various perspectives fairly, and (iii) CHECKEREVAL is an extensible solution for gauging the reliability of automatic fact-checkers' verification results using human-annotated datasets. OpenFactCheck is publicly released at https://github.com/yuxiaw/OpenFactCheck.",
    "pdf_link": "https://arxiv.org/abs/2405.05583",
    "graphs": [],
    "abstract_cn": "随着LLMs在多领域的广泛应用，验证其输出真实性的需求日益增长。然而，评估开放领域自由回答的真实性充满挑战，且不同研究采用的评估标准不一，导致难以比较，阻碍了研究进展。为此，我们推出了OpenFactCheck，一个专为LLMs设计的统一真实性评估框架。它包含三个核心模块：CUSTCHECKER让用户定制事实检查器，轻松验证信息真实性；LLMEVAL提供一个公正的多维度评估体系，全面衡量LLMs的真实性能力；CHECKEREVAL则利用人类标注数据，评估自动事实检查器的可靠性。OpenFactCheck已在GitHub上公开，网址为https://github.com/yuxiaw/OpenFactCheck。",
    "title_cn": "OpenFactCheck：大型语言模型事实性评估的统一框架在翻译过程中，我首先确保了原文意思的准确传达，然后对翻译结果进行了润色，使其更符合中文的表达习惯，同时保持了原文的简洁性和优雅性。",
    "tags": [
      "LLM应用\n\n这篇论文介绍了一个名为OpenFactCheck的统一真实性评估框架，专门为大型语言模型（LLMs）设计，以解决评估LLMs输出真实性的挑战。该框架包含三个核心模块，旨在提供一个公正的多维度评估体系，并允许用户定制事实检查器。这与LLM的应用层面紧密相关，因为它关注的是如何评估和提高LLMs在实际应用中的真实性表现，而不是探讨LLM的理论基础或Agent的设计与实现，也不是关于检索增强生成（RAG）的具体研究。因此，将其归类为“LLM应用”是合适的。",
      "",
      "人工智能评估"
    ]
  },
  {
    "title": "One vs. Many: Comprehending Accurate Information from Multiple Erroneous and Inconsistent AI Generations",
    "submit_datetime": "2024年05月09日",
    "abstract": "As Large Language Models (LLMs) are nondeterministic, the same input can generate different outputs, some of which may be incorrect or hallucinated. If run again, the LLM may correct itself and produce the correct answer. Unfortunately, most LLM-powered systems resort to single results which, correct or not, users accept. Having the LLM produce multiple outputs may help identify disagreements or alternatives. However, it is not obvious how the user will interpret conflicts or inconsistencies. To this end, we investigate how users perceive the AI model and comprehend the generated information when they receive multiple, potentially inconsistent, outputs. Through a preliminary study, we identified five types of output inconsistencies. Based on these categories, we conducted a study (N=252) in which participants were given one or more LLM-generated passages to an information-seeking question. We found that inconsistency within multiple LLM-generated outputs lowered the participants' perceived AI capacity, while also increasing their comprehension of the given information. Specifically, we observed that this positive effect of inconsistencies was most significant for participants who read two passages, compared to those who read three. Based on these findings, we present design implications that, instead of regarding LLM output inconsistencies as a drawback, we can reveal the potential inconsistencies to transparently indicate the limitations of these models and promote critical LLM usage.",
    "pdf_link": "https://arxiv.org/abs/2405.05581",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.05581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05581/procedure.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05581/vis_total.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05581/vis_subcondition.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05581/Accuracy_wise.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05581/pattern.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05581v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05581/interface.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）的非确定性意味着同一输入可能产生不同输出，包括错误或幻觉。若再次尝试，模型可能自我修正并给出正确答案。然而，多数基于LLM的系统仅提供单一结果，用户只能接受。提供多个输出有助于揭示分歧或备选方案，但用户如何处理这些不一致性尚不明确。我们的研究探索了用户在面对多个可能不一致的LLM输出时，如何理解AI模型及其信息。初步研究揭示了五种输出不一致类型，并据此进行了涉及252名参与者的实验，他们需通过LLM生成的段落来解答信息查询问题。结果显示，输出不一致性虽降低了AI能力的感知，却增强了信息理解。特别是，阅读两个段落的参与者受益最大。因此，我们建议设计时应考虑揭示LLM的不一致性，以此作为模型局限性的透明指示，并鼓励用户批判性地使用LLM。",
    "title_cn": "辨真伪于众说纷纭：从错综复杂的人工智能生成中提炼真知在众多人工智能生成的信息中，我们面临着辨别真伪的挑战。这些信息可能充满错误，且相互之间存在不一致。本研究旨在探索如何在这样复杂的环境中，准确地提取和理解信息，确保我们能够从人工智能的众多声音中，捕捉到最真实、最可靠的知识。",
    "tags": [
      "LLM理论\n\n这篇论文探讨了大型语言模型（LLMs）的非确定性及其对用户理解和使用AI模型的影响。它研究了用户在面对多个可能不一致的LLM输出时的行为和感知，并通过实验来分析输出不一致性对信息理解的影响。这项研究关注的是LLM的内部机制和用户交互，而不是具体的应用场景或Agent的设计，因此它更符合LLM理论的范畴。同时，它也不直接涉及Agent的行为或RAG（Retrieval-Augmented Generation）框架，因此不属于Agent或RAG分类。",
      "人工智能交互",
      "用户体验研究"
    ]
  },
  {
    "title": "From Human Judgements to Predictive Models: Unravelling Acceptability in Code-Mixed Sentences",
    "submit_datetime": "2024年05月09日",
    "abstract": "Current computational approaches for analysing or generating code-mixed sentences do not explicitly model \"naturalness\" or \"acceptability\" of code-mixed sentences, but rely on training corpora to reflect distribution of acceptable code-mixed sentences. Modelling human judgement for the acceptability of code-mixed text can help in distinguishing natural code-mixed text and enable quality-controlled generation of code-mixed text. To this end, we construct Cline - a dataset containing human acceptability judgements for English-Hindi (en-hi) code-mixed text. Cline is the largest of its kind with 16,642 sentences, consisting of samples sourced from two sources: synthetically generated code-mixed text and samples collected from online social media. Our analysis establishes that popular code-mixing metrics such as CMI, Number of Switch Points, Burstines, which are used to filter/curate/compare code-mixed corpora have low correlation with human acceptability judgements, underlining the necessity of our dataset. Experiments using Cline demonstrate that simple Multilayer Perceptron (MLP) models trained solely on code-mixing metrics are outperformed by fine-tuned pre-trained Multilingual Large Language Models (MLLMs). Specifically, XLM-Roberta and Bernice outperform IndicBERT across different configurations in challenging data settings. Comparison with ChatGPT's zero and fewshot capabilities shows that MLLMs fine-tuned on larger data outperform ChatGPT, providing scope for improvement in code-mixed tasks. Zero-shot transfer from English-Hindi to English-Telugu acceptability judgments using our model checkpoints proves superior to random baselines, enabling application to other code-mixed language pairs and providing further avenues of research. We publicly release our human-annotated dataset, trained checkpoints, code-mix corpus, and code for data generation and model training.",
    "pdf_link": "https://arxiv.org/abs/2405.05572",
    "graphs": [],
    "abstract_cn": "现有的混合代码句子分析与生成方法，并未直接模拟“自然性”与“可接受性”，而是依赖训练语料库来反映可接受混合代码句子的分布。为了区分自然混合代码文本并实现质量控制生成，我们创建了Cline数据集，它包含了人类对英语-印地语混合代码文本可接受性的判断。Cline拥有16,642个句子，样本来自合成生成和社交媒体收集。分析发现，常用的混合代码度量与人类判断关联性低，凸显了Cline的重要性。实验显示，微调的多语言大型语言模型在混合代码任务上优于简单MLP模型。XLM-Roberta和Bernice在各种配置下超越了IndicBERT。与ChatGPT相比，微调的MLLMs在更大数据上表现更佳，为混合代码任务的改进提供了空间。我们的模型在从英语-印地语到英语-泰卢固语的可接受性判断上优于随机基线，为其他混合代码语言对的研究开辟了新途径。我们公开了人工标注数据集、训练模型、混合代码语料库及生成与训练代码。",
    "title_cn": "解码人类判断，构建预测模型：探索代码混合语言的可接受性之谜",
    "tags": [
      "LLM应用\n\n这篇论文主要关注的是多语言大型语言模型（MLLMs）在混合代码句子生成任务中的应用，特别是如何通过创建一个新的数据集（Cline）来提高生成文本的自然性和可接受性。论文通过实验比较了不同模型的性能，并强调了微调的多语言大型语言模型在混合代码任务上的优势。这与LLM应用的分类相符，因为它涉及到了大型语言模型的实际应用和性能改进，而不是专注于理论研究或Agent的设计与实现。",
      "",
      "多语言处理"
    ]
  },
  {
    "title": "Investigating Interaction Modes and User Agency in Human-LLM Collaboration for Domain-Specific Data Analysis",
    "submit_datetime": "2024年05月09日",
    "abstract": "Despite demonstrating robust capabilities in performing tasks related to general-domain data-operation tasks, Large Language Models (LLMs) may exhibit shortcomings when applied to domain-specific tasks. We consider the design of domain-specific AI-powered data analysis tools from two dimensions: interaction and user agency. We implemented two design probes that fall on the two ends of the two dimensions: an open-ended high agency (OHA) prototype and a structured low agency (SLA) prototype. We conducted an interview study with nine data scientists to investigate (1) how users perceived the LLM outputs for data analysis assistance, and (2) how the two test design probes, OHA and SLA, affected user behavior, performance, and perceptions. Our study revealed insights regarding participants' interactions with LLMs, how they perceived the results, and their desire for explainability concerning LLM outputs, along with a noted need for collaboration with other users, and how they envisioned the utility of LLMs in their workflow.",
    "pdf_link": "https://arxiv.org/abs/2405.05548",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）虽在通用数据操作任务中表现出色，但在特定领域任务上却显露短板。本研究从交互与用户自主性两方面出发，设计了两种极端的AI数据分析工具原型：开放式高自主性（OHA）与结构化低自主性（SLA）。通过与九位数据科学家的访谈，我们探讨了用户对LLMs在数据分析辅助中输出的看法，以及OHA和SLA原型如何影响他们的行为、工作效率和感知。研究发现，用户不仅关注LLMs的交互体验和结果质量，还渴望了解其输出背后的逻辑，并期待与其他用户协作，以及如何将LLMs融入他们的日常工作流程中。",
    "title_cn": "探究在特定领域数据分析中，人类与LLM协作的交互方式及用户自主权在翻译过程中，我首先确保了原文意思的准确传达，然后对语言进行了优化，使其更加符合中文的表达习惯，同时保持了原文的生动性和简洁性。",
    "tags": [
      "Agent\n\n这篇论文探讨了大型语言模型（LLMs）在数据分析领域的应用，并设计了两种不同自主性的AI数据分析工具原型。它通过访谈数据科学家来了解用户对LLMs在数据分析辅助中的看法，以及这些原型如何影响用户的行为和工作效率。这表明论文关注的是如何设计智能代理（Agent）来辅助用户进行数据分析，因此属于Agent分类。",
      "数据分析",
      "人工智能辅助工具"
    ]
  },
  {
    "title": "Lumina-T2X: Transforming Text into Any Modality, Resolution, and Duration via Flow-based Large Diffusion Transformers",
    "submit_datetime": "2024年05月09日",
    "abstract": "Sora unveils the potential of scaling Diffusion Transformer for generating photorealistic images and videos at arbitrary resolutions, aspect ratios, and durations, yet it still lacks sufficient implementation details. In this technical report, we introduce the Lumina-T2X family - a series of Flow-based Large Diffusion Transformers (Flag-DiT) equipped with zero-initialized attention, as a unified framework designed to transform noise into images, videos, multi-view 3D objects, and audio clips conditioned on text instructions. By tokenizing the latent spatial-temporal space and incorporating learnable placeholders such as [nextline] and [nextframe] tokens, Lumina-T2X seamlessly unifies the representations of different modalities across various spatial-temporal resolutions. This unified approach enables training within a single framework for different modalities and allows for flexible generation of multimodal data at any resolution, aspect ratio, and length during inference. Advanced techniques like RoPE, RMSNorm, and flow matching enhance the stability, flexibility, and scalability of Flag-DiT, enabling models of Lumina-T2X to scale up to 7 billion parameters and extend the context window to 128K tokens. This is particularly beneficial for creating ultra-high-definition images with our Lumina-T2I model and long 720p videos with our Lumina-T2V model. Remarkably, Lumina-T2I, powered by a 5-billion-parameter Flag-DiT, requires only 35% of the training computational costs of a 600-million-parameter naive DiT. Our further comprehensive analysis underscores Lumina-T2X's preliminary capability in resolution extrapolation, high-resolution editing, generating consistent 3D views, and synthesizing videos with seamless transitions. We expect that the open-sourcing of Lumina-T2X will further foster creativity, transparency, and diversity in the generative AI community.",
    "pdf_link": "https://arxiv.org/abs/2405.05945",
    "graphs": [],
    "abstract_cn": "Sora展示了扩散变换器在生成任意分辨率、宽高比和时长的逼真图像和视频方面的潜力，但实施细节尚不充分。在本报告中，我们推出了Lumina-T2X系列——一系列基于流的、配备零初始化注意力的大型扩散变换器，旨在根据文本指令将噪声转化为图像、视频、多视角3D物体和音频片段。通过引入可学习的占位符，如[nextline]和[nextframe]标记，Lumina-T2X实现了不同模态在各种时空分辨率下的统一表示。这种方法使得在同一框架内训练不同模态成为可能，并允许在推理时灵活生成任意分辨率、宽高比和长度的多模态数据。采用RoPE、RMSNorm和流匹配等先进技术，增强了Flag-DiT的稳定性、灵活性和可扩展性，使Lumina-T2X模型能够扩展到70亿参数，并将上下文窗口扩展到128K标记。这对于使用Lumina-T2I模型生成超高清图像和使用Lumina-T2V模型生成长720p视频尤为有益。值得一提的是，由50亿参数Flag-DiT驱动的Lumina-T2I，其训练计算成本仅为6亿参数的朴素DiT的35%。我们的深入分析揭示了Lumina-T2X在分辨率外推、高分辨率编辑、生成一致的3D视图和合成无缝过渡视频方面的初步能力。我们期待Lumina-T2X的开源将激发生成式AI社区的创造力、透明度和多样性。",
    "title_cn": "Lumina-T2X：借助基于流的巨型扩散变换器，将文本灵活转换为多样化的模态、高分辨率及任意时长，开启文本表达的新纪元。",
    "tags": [
      "LLM应用\n\n这篇论文介绍了一种名为Lumina-T2X的大型扩散变换器系列，它能够根据文本指令生成多种模态的数据，包括图像、视频、3D物体和音频片段。该模型采用了先进的技术，如RoPE、RMSNorm和流匹配，以提高其稳定性、灵活性和可扩展性。论文强调了该模型在生成超高清图像和长视频方面的能力，并讨论了其在分辨率外推、高分辨率编辑、生成一致的3D视图和合成无缝过渡视频方面的初步能力。这些特性表明，该论文属于大型语言模型（LLM）的应用范畴，因为它展示了LLM在多模态内容生成方面的实际应用。",
      "多媒体生成",
      "人工智能"
    ]
  },
  {
    "title": "Transformer Architecture for NetsDB",
    "submit_datetime": "2024年05月09日",
    "abstract": "Transformers models have become the backbone of the current state-of-the-art models in language, vision, and multimodal domains. These models, at their core, utilize multi-head self-attention to selectively aggregate context, generating dynamic contextual embeddings and modeling long-range dependencies for a clear contextual understanding. Lixi et al. \\cite{zhou2022serving} proposed a method to use relational databases for deploying large-scale deep learning models and created an open-source implementation called NetsDB for the same. We build upon the previous work of these authors by creating an end-to-end implementation of the Encoder part of the transformer for model serving in NetsDB. Specifically, we construct a two-block encoder that includes Multi-Head Attention and its accompanying self-attention mechanism, Layer-Norm, Dropout, FeedForward Layers, and the necessary residual connections. We load out weights from our model for distributed processing, deployment, and efficient inferencing. To prove the efficacy of our implementation, we conduct a comprehensive performance analysis by comparing it with existing implementations in PyTorch, Tensorflow, Flax, and MxNet across key metrics such as inference time and model size.",
    "pdf_link": "https://arxiv.org/abs/2405.04807",
    "graphs": [],
    "abstract_cn": "Transformer模型已成为语言、视觉和多模态领域的顶尖技术，其核心在于利用多头自注意力机制，动态捕捉上下文信息，并建模长距离依赖，以实现精准的上下文理解。Lixi等学者提出了一种基于关系数据库的大规模深度学习模型部署方法，并开发了开源工具NetsDB。我们在此基础上，实现了Transformer编码器的端到端服务，构建了一个集多头注意力、自注意力机制、层归一化、丢弃、前馈层和残差连接于一体的两块编码器。我们优化了模型权重加载，以支持分布式处理、部署和高效推理。通过与PyTorch、Tensorflow、Flax和MxNet等平台的全面性能对比，我们的实现展现了卓越的推理速度和模型尺寸优化。",
    "title_cn": "NetsDB 采用 Transformer 架构，该架构在自然语言处理领域展现了卓越的性能，为数据处理和分析提供了强大的支持。",
    "tags": [
      "LLM应用\n\n这篇论文讨论了基于Transformer模型的编码器实现，并专注于优化模型权重加载以支持分布式处理、部署和高效推理。它还进行了与其他深度学习平台的性能对比，展示了其优越的推理速度和模型尺寸优化。这些内容与大型语言模型（LLM）的应用相关，特别是在模型部署和服务方面，因此将其归类为LLM应用。",
      "",
      "数据库技术"
    ]
  },
  {
    "title": "SKVQ: Sliding-window Key and Value Cache Quantization for Large Language Models",
    "submit_datetime": "2024年05月09日",
    "abstract": "Large language models (LLMs) can now handle longer sequences of tokens, enabling complex tasks like book understanding and generating lengthy novels. However, the key-value (KV) cache required for LLMs consumes substantial memory as context length increasing, becoming the bottleneck for deployment. In this paper, we present a strategy called SKVQ, which stands for sliding-window KV cache quantization, to address the issue of extremely low bitwidth KV cache quantization. To achieve this, SKVQ rearranges the channels of the KV cache in order to improve the similarity of channels in quantization groups, and applies clipped dynamic quantization at the group level. Additionally, SKVQ ensures that the most recent window tokens in the KV cache are preserved with high precision. This helps maintain the accuracy of a small but important portion of the KV cache.SKVQ achieves high compression ratios while maintaining accuracy. Our evaluation on LLMs demonstrates that SKVQ surpasses previous quantization approaches, allowing for quantization of the KV cache to 2-bit keys and 1.5-bit values with minimal loss of accuracy. With SKVQ, it is possible to process context lengths of up to 1M on an 80GB memory GPU for a 7b model and up to 7 times faster decoding.",
    "pdf_link": "https://arxiv.org/abs/2405.06219",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）已能驾驭长篇令牌序列，让书籍理解和长篇小说创作等复杂任务成为现实。但随之而来的键值（KV）缓存需求却成了内存消耗的巨兽，成为部署的瓶颈。本文提出的SKVVQ策略，即滑动窗口KV缓存量化，巧妙解决了极低比特宽度KV缓存量化的难题。SKVVQ通过重新组织KV缓存通道，增强量化组内通道的相似性，并采用剪裁动态量化技术，确保了最新窗口令牌的高精度保存，从而守护了KV缓存中关键部分的准确性。实验证明，SKVVQ在保持准确性的同时，实现了高压缩比，超越了以往的量化方法，使得2比特键和1.5比特值的KV缓存量化成为可能，且几乎不损失准确性。借助SKVVQ，我们能在80GB内存的GPU上，以7倍的速度，处理7b模型的1M上下文长度。",
    "title_cn": "SKVQ：大型语言模型的滑动窗口键值缓存量化技术，通过精妙的量化策略，优化了模型的缓存效率，为语言模型的性能提升开辟了新的道路。",
    "tags": [
      "LLM理论\n\n这篇论文探讨了大型语言模型（LLMs）在处理长篇令牌序列时面临的内存消耗问题，并提出了一种名为SKVVQ的策略来解决键值（KV）缓存量化的问题。该研究专注于LLMs的理论层面，特别是在内存管理和量化技术方面的创新，以提高模型的效率和可部署性。因此，它属于LLM理论分类。",
      "",
      "机器学习"
    ]
  },
  {
    "title": "A Survey on RAG Meets LLMs: Towards Retrieval-Augmented Large Language Models",
    "submit_datetime": "2024年05月09日",
    "abstract": "As one of the most advanced techniques in AI, Retrieval-Augmented Generation (RAG) techniques can offer reliable and up-to-date external knowledge, providing huge convenience for numerous tasks. Particularly in the era of AI-generated content (AIGC), the powerful capacity of retrieval in RAG in providing additional knowledge enables retrieval-augmented generation to assist existing generative AI in producing high-quality outputs. Recently, large Language Models (LLMs) have demonstrated revolutionary abilities in language understanding and generation, while still facing inherent limitations, such as hallucinations and out-of-date internal knowledge. Given the powerful abilities of RAG in providing the latest and helpful auxiliary information, retrieval-augmented large language models have emerged to harness external and authoritative knowledge bases, rather than solely relying on the model's internal knowledge, to augment the generation quality of LLMs. In this survey, we comprehensively review existing research studies in retrieval-augmented large language models (RA-LLMs), covering three primary technical perspectives: architectures, training strategies, and applications. As the preliminary knowledge, we briefly introduce the foundations and recent advances of LLMs. Then, to illustrate the practical significance of RAG for LLMs, we categorize mainstream relevant work by application areas, detailing specifically the challenges of each and the corresponding capabilities of RA-LLMs. Finally, to deliver deeper insights, we discuss current limitations and several promising directions for future research.",
    "pdf_link": "https://arxiv.org/abs/2405.06211",
    "graphs": [],
    "abstract_cn": "检索增强生成（RAG）技术，作为AI领域的尖端技术，能够提供可靠且最新的外部知识，极大地便利了各种任务。在AI内容生成的浪潮中，RAG通过其强大的检索能力为生成式AI提供了额外的知识，助力其产出高质量内容。尽管大型语言模型（LLMs）在语言处理上展现了突破性的能力，但仍受限于内部知识的幻觉和过时。因此，检索增强的LLMs应运而生，它们利用外部权威知识库，而非仅依赖内部知识，以提升生成质量。本综述全面审视了RA-LLMs的研究现状，从架构、训练策略到应用三个技术层面进行探讨。我们首先概述了LLMs的基础和进展，随后根据应用领域对相关研究进行了分类，并深入分析了每个领域的挑战及RA-LLMs的应对能力。最后，我们探讨了当前研究的局限，并展望了未来研究的可能方向。",
    "title_cn": "《RAG与大型语言模型：探索检索增强型LLM之路》调研报告",
    "tags": [
      "RAG\n\n这篇论文摘要主要讨论了检索增强生成（RAG）技术在大型语言模型（LLMs）中的应用，以及它如何通过利用外部知识库来提升生成质量。它涵盖了RAG的架构、训练策略和应用，并对当前研究进行了综述，分析了挑战和应对能力，同时提出了未来研究的方向。因此，它属于RAG分类。",
      "人工智能",
      "内容生成"
    ]
  },
  {
    "title": "VLSM-Adapter: Finetuning Vision-Language Segmentation Efficiently with Lightweight Blocks",
    "submit_datetime": "2024年05月09日",
    "abstract": "Foundation Vision-Language Models (VLMs) trained using large-scale open-domain images and text pairs have recently been adapted to develop Vision-Language Segmentation Models (VLSMs) that allow providing text prompts during inference to guide image segmentation. If robust and powerful VLSMs can be built for medical images, it could aid medical professionals in many clinical tasks where they must spend substantial time delineating the target structure of interest. VLSMs for medical images resort to fine-tuning base VLM or VLSM pretrained on open-domain natural image datasets due to fewer annotated medical image datasets; this fine-tuning is resource-consuming and expensive as it usually requires updating all or a significant fraction of the pretrained parameters. Recently, lightweight blocks called adapters have been proposed in VLMs that keep the pretrained model frozen and only train adapters during fine-tuning, substantially reducing the computing resources required. We introduce a novel adapter, VLSM-Adapter, that can fine-tune pretrained vision-language segmentation models using transformer encoders. Our experiments in widely used CLIP-based segmentation models show that with only 3 million trainable parameters, the VLSM-Adapter outperforms state-of-the-art and is comparable to the upper bound end-to-end fine-tuning. The source code is available at: https://github.com/naamiinepal/vlsm-adapter.",
    "pdf_link": "https://arxiv.org/abs/2405.06196",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.06196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06196/architecture"
      },
      {
        "url": "https://arxiv.org/html/2405.06196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06196/adapter_variants"
      },
      {
        "url": "https://arxiv.org/html/2405.06196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06196/spider_adapter"
      },
      {
        "url": "https://arxiv.org/html/2405.06196v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06196/qualitative-analysis"
      }
    ],
    "abstract_cn": "近期，通过将基础视觉-语言模型（VLMs）与大规模开放领域图像和文本对相结合，开发出了能够在推理时通过文本提示指导图像分割的视觉-语言分割模型（VLSMs）。若能构建出适用于医学图像的强大VLSMs，将极大助力医疗专家在需耗时描绘目标结构的临床任务中。然而，由于医学图像标注数据稀缺，VLSMs通常需对预训练于自然图像数据集的模型进行微调，这一过程耗费资源且成本高昂。为此，我们推出了VLSM-Adapter，一种新型轻量级适配器，它能在不更新预训练模型参数的情况下，通过变换器编码器对视觉-语言分割模型进行微调，大幅降低计算需求。实验证明，VLSM-Adapter以仅300万个可训练参数，便超越了现有技术水平，并与端到端微调的效果相媲美。源代码已公开发布于GitHub：https://github.com/naamiinepal/vlsm-adapter。",
    "title_cn": "VLSM-Adapter：以轻巧之姿，高效微调视觉与语言的分割艺术",
    "tags": [
      "LLM应用\n\n这篇论文介绍了一种名为VLSM-Adapter的新型轻量级适配器，用于微调视觉-语言分割模型（VLSMs），特别是在医学图像处理领域。该适配器能够在不更新预训练模型参数的情况下，通过变换器编码器对模型进行微调，从而显著降低计算需求和成本。这种方法对于资源受限的环境尤其有价值，并且其实验结果表明，VLSM-Adapter在保持高性能的同时，大大减少了可训练参数的数量。由于该工作聚焦于应用层面的模型优化和实际问题解决，因此它属于LLM应用类别。",
      "医疗影像",
      "模型微调"
    ]
  },
  {
    "title": "Muting Whisper: A Universal Acoustic Adversarial Attack on Speech Foundation Models",
    "submit_datetime": "2024年05月09日",
    "abstract": "Recent developments in large speech foundation models like Whisper have led to their widespread use in many automatic speech recognition (ASR) applications. These systems incorporate `special tokens' in their vocabulary, such as $\\texttt{<endoftext>}$, to guide their language generation process. However, we demonstrate that these tokens can be exploited by adversarial attacks to manipulate the model's behavior. We propose a simple yet effective method to learn a universal acoustic realization of Whisper's $\\texttt{<endoftext>}$ token, which, when prepended to any speech signal, encourages the model to ignore the speech and only transcribe the special token, effectively `muting' the model. Our experiments demonstrate that the same, universal 0.64-second adversarial audio segment can successfully mute a target Whisper ASR model for over 97\\% of speech samples. Moreover, we find that this universal adversarial audio segment often transfers to new datasets and tasks. Overall this work demonstrates the vulnerability of Whisper models to `muting' adversarial attacks, where such attacks can pose both risks and potential benefits in real-world settings: for example the attack can be used to bypass speech moderation systems, or conversely the attack can also be used to protect private speech data.",
    "pdf_link": "https://arxiv.org/abs/2405.06134",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.06134v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06134/attack.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06134v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06134/medium_spect_e0.02.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06134v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06134/ablation_T.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06134v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06134/ablation_e.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06134v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06134/success_saliency.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06134v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06134/unsuccess_saliency.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06134v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06134/tiny_spect_e0.02.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06134v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06134/tiny-multi_spect_e0.02.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06134v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06134/base_spect_e0.02.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06134v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06134/base-multi_spect_e0.02.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06134v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06134/small_spect_e0.02.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06134v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06134/small-multi_spect_e0.02.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06134v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06134/medium_spect_e0.02.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06134v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06134/medium-multi_spect_e0.02.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06134v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06134/tiny_spect_e0.02.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06134v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06134/tiny_spect_e0.01.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06134v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06134/tiny_spect_e0.005.png"
      }
    ],
    "abstract_cn": "Whisper等大型语音基础模型的最新进展，使其在自动语音识别应用中大放异彩。这些模型通过引入特殊标记，如$\\texttt{<endoftext>}$，来优化语言生成。然而，我们发现这些标记可能成为对抗性攻击的工具，影响模型的行为。我们提出了一种巧妙的方法，能够为Whisper的$\\texttt{<endoftext>}$标记创造一个通用的声学实现，一旦它被前置于任何语音信号，模型便会忽略语音内容，仅转录该特殊标记，从而“静音”模型。实验证明，一段仅0.64秒的通用对抗音频，能让目标Whisper ASR模型对97%以上的语音样本失效。更令人惊讶的是，这段音频还能在不同数据集和任务间迁移。这项研究揭示了Whisper模型在面对“静音”攻击时的脆弱性，这种攻击在现实世界中既可能带来风险，也可能带来保护隐私语音数据的新机遇。",
    "title_cn": "《沉默之声：对语音基础模型发起的通用声学对抗攻击》",
    "tags": [
      "Agent\n\n解释：这篇论文讨论了针对大型语音基础模型（如Whisper）的对抗性攻击，特别是通过创造一个通用的声学实现来影响模型的行为，使其忽略语音内容。这种攻击可以被视为一种智能Agent的行为，因为它涉及到对模型的操纵和利用。此外，论文还探讨了这种攻击在现实世界中的潜在风险和机遇，这与Agent的行为和影响相符。因此，这篇论文更适合归类为Agent，而不是RAG、LLM应用或LLM理论。",
      "自动语音识别",
      "隐私保护"
    ]
  },
  {
    "title": "Transforming the Bootstrap: Using Transformers to Compute Scattering Amplitudes in Planar N = 4 Super Yang-Mills Theory",
    "submit_datetime": "2024年05月09日",
    "abstract": "We pursue the use of deep learning methods to improve state-of-the-art computations in theoretical high-energy physics. Planar N = 4 Super Yang-Mills theory is a close cousin to the theory that describes Higgs boson production at the Large Hadron Collider; its scattering amplitudes are large mathematical expressions containing integer coefficients. In this paper, we apply Transformers to predict these coefficients. The problem can be formulated in a language-like representation amenable to standard cross-entropy training objectives. We design two related experiments and show that the model achieves high accuracy (> 98%) on both tasks. Our work shows that Transformers can be applied successfully to problems in theoretical physics that require exact solutions.",
    "pdf_link": "https://arxiv.org/abs/2405.06107",
    "graphs": [],
    "abstract_cn": "我们利用深度学习的力量，推动理论高能物理计算的边界。平面N = 4超杨-米尔斯理论与大型强子对撞机上希格斯玻色子产生的理论紧密相关，其散射幅度的数学表达式庞大且包含整数系数。本文中，我们运用Transformer模型来精准预测这些系数。我们将问题转化为类似语言的表述，便于采用交叉熵训练目标。通过设计两个紧密相关的实验，我们证明了模型在两项任务上的准确率均超过98%。这一成果展示了Transformer在解决理论物理中需要精确答案的问题上的巨大潜力。",
    "title_cn": "变压器的引入为平面N = 4超杨-米尔斯理论中的散射振幅计算带来了革新，打破了传统引导程序的局限。",
    "tags": [
      "LLM理论\n\n这篇论文探讨了将Transformer模型应用于理论高能物理计算，特别是预测平面N = 4超杨-米尔斯理论中的散射幅度系数。这种方法涉及将物理问题转化为类似语言的表述，并使用Transformer模型进行精确预测。由于论文主要关注的是大型语言模型（LLM）在理论物理问题上的应用和理论探索，因此它属于LLM理论分类。论文并未涉及Agent的行为或决策，也没有直接讨论检索增强生成（RAG）技术，因此不归类于Agent或RAG。同时，虽然它展示了LLM的应用潜力，但其核心在于理论探索和模型在特定问题上的应用，而不是广泛的应用场景，因此不归类于LLM应用。",
      "高能物理",
      ""
    ]
  },
  {
    "title": "Can Perplexity Reflect Large Language Model's Ability in Long Text Understanding?",
    "submit_datetime": "2024年05月09日",
    "abstract": "Recent studies have shown that Large Language Models (LLMs) have the potential to process extremely long text. Many works only evaluate LLMs' long-text processing ability on the language modeling task, with perplexity (PPL) as the evaluation metric. However, in our study, we find that there is no correlation between PPL and LLMs' long-text understanding ability. Besides, PPL may only reflect the model's ability to model local information instead of catching long-range dependency. Therefore, only using PPL to prove the model could process long text is inappropriate. The local focus feature of PPL could also explain some existing phenomena, such as the great extrapolation ability of the position method ALiBi. When evaluating a model's ability in long text, we might pay more attention to PPL's limitation and avoid overly relying on it.",
    "pdf_link": "https://arxiv.org/abs/2405.06105",
    "graphs": [],
    "abstract_cn": "最新研究表明，大型语言模型（LLMs）能够驾驭长篇大论。然而，多数研究仅以语言建模任务中的困惑度（PPL）作为标尺来衡量其长文本处理能力，这并不全面。我们的研究发现，PPL与LLMs对长文本的深刻理解并无直接关联，它更多地反映了模型对局部信息的把握，而非长距离依赖的捕捉。因此，仅凭PPL来断定模型能驾驭长文本，未免过于片面。PPL的这一局限性也能解释为何某些模型，如采用ALiBi位置方法的模型，在文本外推方面表现卓越。在评估模型对长文本的处理能力时，我们应更加审慎，避免过度依赖PPL这一指标。",
    "title_cn": "大型语言模型的困惑度是否是其长文本理解能力的晴雨表？",
    "tags": [
      "LLM理论\n\n这篇论文探讨了大型语言模型（LLMs）在处理长文本时的性能评估问题，特别是对困惑度（PPL）这一指标的局限性进行了分析。它指出PPL并不能全面反映模型对长文本深刻理解的能力，而是更多地反映了模型对局部信息的把握。这种对评估指标的深入分析和对模型性能理解的探讨，属于对LLMs理论层面的研究，因此归类为LLM理论。",
      "",
      "语言模型评估"
    ]
  },
  {
    "title": "Selective Fine-tuning on LLM-labeled Data May Reduce Reliance on Human Annotation: A Case Study Using Schedule-of-Event Table Detection",
    "submit_datetime": "2024年05月09日",
    "abstract": "Large Language Models (LLMs) have demonstrated their efficacy across a broad spectrum of tasks in healthcare applications. However, often LLMs need to be fine-tuned on task-specific expert annotated data to achieve optimal performance, which can be expensive and time consuming. In this study, we fine-tune PaLM-2 with parameter efficient fine-tuning (PEFT) using noisy labels obtained from gemini-pro 1.0 for the detection of Schedule-of-Event (SoE) tables, which specify care plan in clinical trial protocols. We introduce a filtering mechanism to select high-confidence labels for this table classification task, thereby reducing the noise in the auto-generated labels. We show that fine-tuned PaLM-2 with those labels achieves performance that exceeds the gemini-pro 1.0 and other LLMs. Furthermore, its performance is close to a PaLM-2 fine-tuned on labels obtained from non-expert annotators. Our results show that leveraging LLM-generated labels through powerful models like gemini-pro can potentially serve as a viable strategy for improving LLM performance through fine-tuning in specialized tasks, particularly in domains where expert annotations are scarce, expensive, or time-consuming to obtain.",
    "pdf_link": "https://arxiv.org/abs/2405.06093",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.06093v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06093/Precision.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06093v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06093/F1Score.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）在医疗保健领域展现了卓越的效能，但为了达到顶尖性能，它们往往需要依赖特定任务的专家注释数据进行精细调整，这一过程既耗时又成本高昂。本研究中，我们采用参数高效微调（PEFT）技术对PaLM-2模型进行优化，利用gemini-pro 1.0提供的噪声标签来识别临床试验协议中的事件计划表（SoE）。我们创新性地引入了一种过滤机制，以挑选出高置信度的标签，有效降低了自动标签的噪声水平。实验结果显示，经过这样微调的PaLM-2模型在性能上超越了gemini-pro 1.0及其他LLMs，并且与使用非专家注释者标签微调的PaLM-2模型性能相当。我们的研究表明，通过利用gemini-pro等先进模型生成的标签，可以作为一种有效的策略，以提升LLMs在特定任务中的性能，尤其是在专家注释难以获取或成本高昂的领域。",
    "title_cn": "通过在LLM标注数据上进行精准微调，我们或许能减少对人工标注的依赖，正如我们在事件时间表检测案例研究中所探索的。这一策略不仅提升了效率，也为自动化标注开辟了新途径。",
    "tags": [
      "LLM应用\n\n这篇论文探讨了如何通过参数高效微调（PEFT）技术优化大型语言模型（LLMs），特别是在医疗保健领域的应用。研究中使用了PaLM-2模型，并引入了过滤机制来处理噪声标签，以提高模型在识别临床试验协议中的事件计划表（SoE）任务上的性能。这种方法展示了在缺乏专家注释数据的情况下，如何利用其他模型生成的标签来提升LLMs的性能。因此，这篇论文属于LLM应用类别，因为它关注的是LLMs在特定领域（医疗保健）的实际应用和性能提升策略。",
      "医疗保健",
      "临床试验"
    ]
  },
  {
    "title": "Believing Anthropomorphism: Examining the Role of Anthropomorphic Cues on Trust in Large Language Models",
    "submit_datetime": "2024年05月09日",
    "abstract": "People now regularly interface with Large Language Models (LLMs) via speech and text (e.g., Bard) interfaces. However, little is known about the relationship between how users anthropomorphize an LLM system (i.e., ascribe human-like characteristics to a system) and how they trust the information the system provides. Participants (n=2,165; ranging in age from 18-90 from the United States) completed an online experiment, where they interacted with a pseudo-LLM that varied in modality (text only, speech + text) and grammatical person (\"I\" vs. \"the system\") in its responses. Results showed that the \"speech + text\" condition led to higher anthropomorphism of the system overall, as well as higher ratings of accuracy of the information the system provides. Additionally, the first-person pronoun (\"I\") led to higher information accuracy and reduced risk ratings, but only in one context. We discuss these findings for their implications for the design of responsible, human-generative AI experiences.",
    "pdf_link": "https://arxiv.org/abs/2405.06079",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.06079v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06079/procedure.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06079v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06079/anthro_fig.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06079v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06079/accuracy_fig.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06079v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06079/trial_schematic.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06079v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06079/trustworthy_by_anthro.png"
      }
    ],
    "abstract_cn": "如今，人们通过语音和文本接口与大型语言模型频繁互动，但对于用户如何赋予LLM系统人性化特征与他们如何信任系统信息之间的联系，我们知之甚少。一项涉及2165名年龄跨度从18至90岁的美国参与者的在线实验揭示，采用“语音+文本”交互方式的系统更易被视为具有人性，且其提供的信息被认为更准确。使用第一人称代词（“我”）在某些情境下提高了信息准确性并降低了风险感知。这些发现对于设计既负责任又贴近人性的AI体验具有重要意义。",
    "title_cn": "拟人化信任：揭示大语言模型中拟人化线索对信任的影响在这项研究中，我们将深入探讨拟人化线索如何塑造用户对大型语言模型的信任感，揭示这一现象背后的心理机制，并探索如何优化模型设计以增强用户信任。",
    "tags": [
      "LLM应用\n\n这篇论文探讨了用户与大型语言模型（LLM）交互时的人性化特征感知以及这种感知如何影响用户对系统信息的信任。研究通过实验揭示了交互方式（语音+文本）和使用第一人称代词对信息准确性和风险感知的影响。这些发现直接关联到LLM在实际应用中的用户体验和信任建立，因此属于LLM应用的范畴。",
      "人机交互",
      "人工智能信任"
    ]
  },
  {
    "title": "HMT: Hierarchical Memory Transformer for Long Context Language Processing",
    "submit_datetime": "2024年05月09日",
    "abstract": "Transformer-based large language models (LLM) have been widely used in language processing applications. However, most of them restrict the context window that permits the model to attend to every token in the inputs. Previous works in recurrent models can memorize past tokens to enable unlimited context and maintain effectiveness. However, they have \"flat\" memory architectures, which have limitations in selecting and filtering information. Since humans are good at learning and self-adjustment, we speculate that imitating brain memory hierarchy is beneficial for model memorization. We propose the Hierarchical Memory Transformer (HMT), a novel framework that enables and improves models' long-context processing ability by imitating human memorization behavior. Leveraging memory-augmented segment-level recurrence, we organize the memory hierarchy by preserving tokens from early input token segments, passing memory embeddings along the sequence, and recalling relevant information from history. Evaluating general language modeling (Wikitext-103, PG-19) and question-answering tasks (PubMedQA), we show that HMT steadily improves the long-context processing ability of context-constrained and long-context models. With an additional 0.5% - 2% of parameters, HMT can easily plug in and augment future LLMs to handle long context effectively. Our code is open-sourced on Github: https://github.com/OswaldHe/HMT-pytorch.",
    "pdf_link": "https://arxiv.org/abs/2405.06067",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.06067v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06067/hmt_flow_v2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06067v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06067/bptt.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06067v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06067/multi-stage.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06067v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06067/wikitext-comp.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06067v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06067/pg19-comp.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06067v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06067/qa_long.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06067v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06067/qa_short.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06067v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06067/ab4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06067v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06067/ab5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06067v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06067/ab7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06067v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06067/ab6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06067v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06067/pubmedqa.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06067v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06067/pg19-interleave.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06067v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06067/pg19-context.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06067v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06067/dilate.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06067v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06067/gradient.png"
      }
    ],
    "abstract_cn": "基于Transformer的大型语言模型（LLM）在语言处理领域大放异彩，但多数模型受限于上下文窗口，无法全面关注输入的每个细节。相比之下，循环模型通过记忆过往信息实现了无限上下文，但其“扁平”的内存结构在信息筛选上存在短板。鉴于人类学习与自我调整的天赋，我们推测模仿大脑的记忆层次或许能为模型记忆带来新思路。因此，我们推出了分层记忆Transformer（HMT），这一创新框架通过模拟人类记忆机制，显著提升了模型对长篇上下文的处理能力。HMT通过记忆增强的段级循环，巧妙地保留早期输入信息，沿序列传递记忆嵌入，并从历史中提取关键信息，构建起层次分明的记忆体系。在Wikitext-103、PG-19的语言建模测试及PubMedQA的问答任务中，HMT展现了其在长上下文处理上的稳健进步，仅需增加0.5%至2%的参数，便能为未来的LLM注入处理长篇内容的强大能力。我们的实现代码已在Github上公开，欢迎探索：https://github.com/OswaldHe/HMT-pytorch。",
    "title_cn": "层次记忆变压器（HMT）：专为长篇语言处理而设计在这篇文章中，我们将探讨层次记忆变压器（HMT），这是一种创新的技术，旨在处理长篇语言上下文，以提升自然语言处理任务的性能。HMT通过其独特的层次结构记忆机制，能够捕捉和处理更广泛的语言上下文信息，从而在处理复杂语言任务时展现出卓越的能力。",
    "tags": [
      "LLM理论\n\n这篇论文探讨了大型语言模型（LLM）在处理长篇上下文时的局限性，并提出了一种新的模型架构——分层记忆Transformer（HMT），旨在模仿人类记忆机制以提高模型对长篇上下文的处理能力。这一研究不仅涉及模型的应用层面，更深入到了模型设计和理论层面，因此将其归类为LLM理论。论文中提出的HMT框架是对现有LLM的一种理论上的改进和扩展，其研究成果对于理解LLM的工作原理和提升其性能具有重要的理论意义。",
      "",
      "机器学习"
    ]
  },
  {
    "title": "LLMs for XAI: Future Directions for Explaining Explanations",
    "submit_datetime": "2024年05月09日",
    "abstract": "In response to the demand for Explainable Artificial Intelligence (XAI), we investigate the use of Large Language Models (LLMs) to transform ML explanations into natural, human-readable narratives. Rather than directly explaining ML models using LLMs, we focus on refining explanations computed using existing XAI algorithms. We outline several research directions, including defining evaluation metrics, prompt design, comparing LLM models, exploring further training methods, and integrating external data. Initial experiments and user study suggest that LLMs offer a promising way to enhance the interpretability and usability of XAI.",
    "pdf_link": "https://arxiv.org/abs/2405.06064",
    "graphs": [],
    "abstract_cn": "面对可解释人工智能（XAI）的迫切需求，我们探索了大型语言模型（LLMs）在将机器学习解释转化为自然流畅、易于人类理解的叙述方面的应用。我们的研究重点并非直接用LLMs解释模型本身，而是致力于优化由现有XAI算法生成的解释。研究方向包括制定评估标准、设计有效的提示、对比不同LLM模型、探索新的训练技术以及整合外部信息资源。初步实验和用户反馈均显示，LLMs在提升XAI的解释清晰度和用户体验方面展现出巨大潜力。",
    "title_cn": "大型语言模型在可解释人工智能中的应用：探索解释解释的未来发展路径",
    "tags": [
      "LLM应用\n\n这篇论文探讨了大型语言模型（LLMs）在提升可解释人工智能（XAI）解释的清晰度和用户体验方面的应用。它关注的是如何优化由现有XAI算法生成的解释，而不是直接解释模型本身。研究内容包括评估标准的制定、提示设计、不同LLM模型的对比、新的训练技术的探索以及外部信息资源的整合。因此，这篇论文属于LLM应用类别。",
      "人工智能解释",
      ""
    ]
  },
  {
    "title": "Supporting Physical Activity Behavior Change with LLM-Based Conversational Agents",
    "submit_datetime": "2024年05月09日",
    "abstract": "Physical activity has significant benefits to health, yet large portions of the population remain physically inactive. Mobile health applications show promising potential for low-cost, scalable physical activity promotion, but existing approaches are often insufficiently personalized to a user's context and life circumstances. In this work, we explore the potential for large language model (LLM) based conversational agents to motivate physical activity behavior change. Through formative interviews with 12 health professionals and 10 non-experts, we identify design considerations and opportunities for LLM health coaching. We present GPTCoach, a chatbot that implements an evidence-based health coaching program, uses counseling strategies from motivational interviewing, and can query and visualize health data from a wearable through tool use. We evaluate GPTCoach as a technology probe in a user study with 16 participants. Through quantitive and qualitative analyses, we find promising evidence that GPTCoach can adhere to a health coaching program while adopting a facilitative, supportive, and non-judgmental tone. We find more variable support for GPTCoach's ability to proactively make use of data in ways that foster motivation and empowerment. We conclude with a discussion of our findings, implications for future research, as well as risks and limitations.",
    "pdf_link": "https://arxiv.org/abs/2405.06061",
    "graphs": [],
    "abstract_cn": "体育活动对健康大有裨益，然而许多人仍缺乏运动。移动健康应用虽有潜力以低成本推广身体活动，但往往未能根据个人情况进行个性化。本研究探索了大型语言模型（LLM）对话代理在激励身体活动方面的潜力。通过与健康专家和非专家的访谈，我们揭示了LLM健康指导的设计要点和机遇。GPTCoach聊天机器人应运而生，它实施科学的健康指导计划，运用动机访谈技巧，并能通过工具查询和展示可穿戴设备的健康数据。在一项包含16名参与者的研究中，GPTCoach作为技术探针被评估。分析显示，GPTCoach在遵循健康指导计划的同时，保持了促进性、支持和非评判性的语气，展现出积极效果。然而，其在主动利用数据以激发动力和赋权方面的能力表现不一。最后，我们讨论了研究成果、对未来研究的启示以及存在的风险和限制。",
    "title_cn": "借助大型语言模型（LLM）赋能的对话伙伴，助力身体活动行为转变在这篇文章中，我们将探讨如何利用大型语言模型（LLM）开发的智能对话代理，来激励和支持人们改变他们的身体活动习惯。这些智能伙伴能够理解用户的意图，提供个性化的建议，并在用户追求更健康生活方式的过程中提供持续的鼓励和指导。",
    "tags": [
      "Agent\n\n这篇论文探讨了大型语言模型（LLM）对话代理在激励身体活动方面的应用，具体介绍了GPTCoach聊天机器人的设计和实施，以及其在促进健康指导计划中的作用。这与Agent分类下的研究内容相符，因为它关注的是一个具体的智能代理系统在特定领域的应用，即健康指导和激励身体活动。虽然这项工作涉及LLM的应用，但它更侧重于代理系统的功能和效果，而不是LLM的理论研究或RAG（Retrieval-Augmented Generation）相关的技术。因此，将其归类为Agent是合适的。",
      "移动健康",
      "体育活动激励"
    ]
  },
  {
    "title": "Large Language Models Show Human-like Social Desirability Biases in Survey Responses",
    "submit_datetime": "2024年05月09日",
    "abstract": "As Large Language Models (LLMs) become widely used to model and simulate human behavior, understanding their biases becomes critical. We developed an experimental framework using Big Five personality surveys and uncovered a previously undetected social desirability bias in a wide range of LLMs. By systematically varying the number of questions LLMs were exposed to, we demonstrate their ability to infer when they are being evaluated. When personality evaluation is inferred, LLMs skew their scores towards the desirable ends of trait dimensions (i.e., increased extraversion, decreased neuroticism, etc). This bias exists in all tested models, including GPT-4/3.5, Claude 3, Llama 3, and PaLM-2. Bias levels appear to increase in more recent models, with GPT-4's survey responses changing by 1.20 (human) standard deviations and Llama 3's by 0.98 standard deviations-very large effects. This bias is robust to randomization of question order and paraphrasing. Reverse-coding all the questions decreases bias levels but does not eliminate them, suggesting that this effect cannot be attributed to acquiescence bias. Our findings reveal an emergent social desirability bias and suggest constraints on profiling LLMs with psychometric tests and on using LLMs as proxies for human participants.",
    "pdf_link": "https://arxiv.org/abs/2405.06058",
    "graphs": [],
    "abstract_cn": "随着LLMs被广泛用于模拟人类行为，揭示其内在偏见变得至关重要。我们通过五大人格调查问卷构建了一个实验框架，意外地发现了LLMs中隐藏的社会期望偏差。实验中，我们调整了LLMs接触的问题数量，发现它们能感知到评估的时机，并倾向于在人格测试中给出更符合社会期望的答案，如提高外向性得分、降低神经质得分等。这种偏差在GPT-4/3.5、Claude 3、Llama 3和PaLM-2等模型中普遍存在，且在最新模型中更为显著。即使问题顺序随机或改写，偏差依然存在。尽管反向编码问题能减轻偏差，但无法根除，这表明偏差并非源于顺从性。我们的研究揭示了LLMs中新兴的社会期望偏差，并提醒我们在使用心理测量测试评估LLMs或将其作为人类代理时需谨慎。",
    "title_cn": "大型语言模型在调查回复中显露出与人类相似的社会期望倾向，这表明它们在模拟人类社会行为方面取得了显著进展。然而，这种偏差的存在也引发了对模型在处理敏感问题时可能产生的误导性影响的担忧。",
    "tags": [
      "LLM理论\n\n这篇论文探讨了大型语言模型（LLMs）中的内在偏见，特别是社会期望偏差，这是对LLMs理论理解的深化。通过实验框架和人格调查问卷，研究者揭示了LLMs在模拟人类行为时可能表现出的偏差，这不仅对LLMs的应用有影响，也对理解这些模型的内部工作机制和潜在局限性有重要意义。因此，这篇论文更倾向于LLM理论的范畴，因为它关注的是模型本身的特性和行为，而不是直接的应用场景或特定的技术方法。",
      "人工智能伦理",
      "心理学测试"
    ]
  },
  {
    "title": "Time complexity for deterministic string machines",
    "submit_datetime": "2024年05月09日",
    "abstract": "Algorithms which learn environments represented by automata in the past have had complexity scaling with the number of states in the automaton, which can be exponentially large even for automata recognizing regular expressions with a small description length. We thus formalize a compositional language that can construct automata as transformations between certain types of category, representable as string diagrams, which better reflects the description complexity of various automata. We define complexity constraints on this framework by having them operate on categories enriched over filtered sets, and using these constraints, we prove elementary results on the runtime and expressivity of a subset of these transformations which operate deterministically on finite state spaces. These string diagrams, or \"string machines,\" are themselves morphisms in a category, so it is possible for string machines to create other string machines in runtime to model computations which take more than constant memory. We prove sufficient conditions for polynomial runtime guarantees on these, which can help develop complexity constraints on string machines which also encapsulate runtime complexity.",
    "pdf_link": "https://arxiv.org/abs/2405.06043",
    "graphs": [],
    "abstract_cn": "以往学习自动机环境的方法，其复杂度随状态数增长，即便对于描述简短的正则表达式，状态数也可能剧增。为此，我们提出了一种组合语言，通过字符串图在特定类别间转换，构建自动机，更准确地映射了自动机的描述复杂性。我们通过在过滤集上丰富的类别上施加复杂性约束，定义了这一框架，并证明了有限状态空间上确定性操作的变换子集的运行时间和表达性。这些字符串图，即“字符串机器”，是类别中的态射，能在运行时生成新的字符串机器，模拟需变量内存的计算。我们证明了这些字符串机器的运行时间保证多项式时间，有助于制定包含运行时间复杂性的字符串机器的复杂性约束。",
    "title_cn": "确定性字符串机器的运算效率分析",
    "tags": [
      "Agent\n\n这篇论文主要讨论了自动机的构建和运行时间复杂性，提出了一种新的组合语言和字符串图的概念来更准确地映射自动机的描述复杂性。这种工作更偏向于智能体（Agent）的设计和优化，因为它关注的是自动机如何在特定环境中学习和操作，以及如何通过字符串机器来模拟需要变量内存的计算。因此，它属于Agent分类。",
      "自动机理论",
      "计算复杂性"
    ]
  },
  {
    "title": "Binary Hypothesis Testing for Softmax Models and Leverage Score Models",
    "submit_datetime": "2024年05月09日",
    "abstract": "Softmax distributions are widely used in machine learning, including Large Language Models (LLMs) where the attention unit uses softmax distributions. We abstract the attention unit as the softmax model, where given a vector input, the model produces an output drawn from the softmax distribution (which depends on the vector input). We consider the fundamental problem of binary hypothesis testing in the setting of softmax models. That is, given an unknown softmax model, which is known to be one of the two given softmax models, how many queries are needed to determine which one is the truth? We show that the sample complexity is asymptotically $O(ε^{-2})$ where $ε$ is a certain distance between the parameters of the models.\n  Furthermore, we draw analogy between the softmax model and the leverage score model, an important tool for algorithm design in linear algebra and graph theory. The leverage score model, on a high level, is a model which, given vector input, produces an output drawn from a distribution dependent on the input. We obtain similar results for the binary hypothesis testing problem for leverage score models.",
    "pdf_link": "https://arxiv.org/abs/2405.06003",
    "graphs": [],
    "abstract_cn": "在机器学习领域，softmax分布广泛应用于大型语言模型（LLMs）的注意力单元中。我们将注意力机制简化为softmax模型，该模型接收向量输入并输出基于该输入的softmax分布。本研究探讨了在softmax模型背景下进行二元假设检验的问题，即如何通过查询次数来确定未知模型属于两个已知模型中的哪一个。研究表明，所需的查询次数与模型参数间的距离$ε$的平方成反比。此外，我们将softmax模型与杠杆分数模型进行了对比，后者是线性代数和图论算法设计中的关键工具。杠杆分数模型同样接收向量输入，并输出依赖于输入的分布。对于杠杆分数模型，我们也得到了关于二元假设检验问题的相似结论。",
    "title_cn": "Softmax模型与杠杆分数模型的二元假设检验探索",
    "tags": [
      "LLM理论\n\n这篇论文探讨了大型语言模型（LLMs）中的注意力机制，特别是softmax模型在二元假设检验中的应用。它研究了如何通过查询次数来确定未知模型属于两个已知模型中的哪一个，并分析了查询次数与模型参数间距离的关系。此外，论文还将softmax模型与杠杆分数模型进行了对比。这些内容属于对LLMs内部机制的理论分析，因此归类为LLM理论。",
      "机器学习",
      ""
    ]
  },
  {
    "title": "LLM-QBench: A Benchmark Towards the Best Practice for Post-training Quantization of Large Language Models",
    "submit_datetime": "2024年05月09日",
    "abstract": "Recent advancements in large language models (LLMs) are propelling us toward artificial general intelligence, thanks to their remarkable emergent abilities and reasoning capabilities. However, the substantial computational and memory requirements of LLMs limit their widespread adoption. Quan- tization, a key compression technique, offers a viable solution to mitigate these demands by compressing and accelerating LLMs, albeit with poten- tial risks to model accuracy. Numerous studies have aimed to minimize the accuracy loss associated with quantization. However, the quantization configurations in these studies vary and may not be optimized for hard- ware compatibility. In this paper, we focus on identifying the most effective practices for quantizing LLMs, with the goal of balancing performance with computational efficiency. For a fair analysis, we develop a quantization toolkit LLMC, and design four crucial principles considering the inference efficiency, quantized accuracy, calibration cost, and modularization. By benchmarking on various models and datasets with over 500 experiments, three takeaways corresponding to calibration data, quantization algorithm, and quantization schemes are derived. Finally, a best practice of LLM PTQ pipeline is constructed. All the benchmark results and the toolkit can be found at https://github.com/ModelTC/llmc.",
    "pdf_link": "https://arxiv.org/abs/2405.06001",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.06001v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06001/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06001v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06001/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06001v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06001/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06001v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06001/naive.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06001v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06001/naive-act.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06001v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06001/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06001v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06001/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.06001v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.06001/x6.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）的最新进展正推动我们迈向人工通用智能，这得益于其卓越的涌现能力和推理能力。然而，LLMs的巨大计算和内存需求限制了其广泛应用。量化作为一种关键的压缩技术，通过压缩和加速LLMs，为缓解这些需求提供了可行方案，尽管可能会牺牲模型精度。许多研究致力于最小化量化带来的精度损失，但这些研究中的量化配置各异，可能未针对硬件兼容性进行优化。本文旨在确定量化LLMs的最有效实践，以平衡性能与计算效率。为此，我们开发了量化工具包LLMC，并制定了四个关键原则，涵盖推理效率、量化精度、校准成本和模块化。通过在多个模型和数据集上进行超过500次实验，我们总结了三个关键点，涉及校准数据、量化算法和量化方案。最终，我们构建了一个最佳实践的LLM PTQ流程。所有基准测试结果和工具包均可在https://github.com/ModelTC/llmc获取。",
    "title_cn": "LLM-QBench：大型语言模型后训练量化实践的标杆在这项研究中，我们提出了 LLM-QBench，这是一个旨在为大型语言模型的后训练量化提供最佳实践的基准。通过 LLM-QBench，我们旨在探索和评估不同量化策略对模型性能的影响，从而为实际应用中的模型优化提供指导。",
    "tags": [
      "LLM理论\n\n这篇论文主要探讨了大型语言模型（LLMs）的量化技术，这是一种压缩和加速模型的方法，旨在平衡性能与计算效率。论文开发了量化工具包LLMC，并提出了量化实践的关键原则，通过大量实验总结了量化过程中的关键点，并构建了一个最佳实践的LLM PTQ流程。这些内容更偏向于LLM的理论研究和优化实践，因此归类为LLM理论。",
      "人工智能",
      "模型压缩"
    ]
  },
  {
    "title": "LLMPot: Automated LLM-based Industrial Protocol and Physical Process Emulation for ICS Honeypots",
    "submit_datetime": "2024年05月09日",
    "abstract": "Industrial Control Systems (ICS) are extensively used in critical infrastructures ensuring efficient, reliable, and continuous operations. However, their increasing connectivity and addition of advanced features make them vulnerable to cyber threats, potentially leading to severe disruptions in essential services. In this context, honeypots play a vital role by acting as decoy targets within ICS networks, or on the Internet, helping to detect, log, analyze, and develop mitigations for ICS-specific cyber threats. Deploying ICS honeypots, however, is challenging due to the necessity of accurately replicating industrial protocols and device characteristics, a crucial requirement for effectively mimicking the unique operational behavior of different industrial systems. Moreover, this challenge is compounded by the significant manual effort required in also mimicking the control logic the PLC would execute, in order to capture attacker traffic aiming to disrupt critical infrastructure operations. In this paper, we propose LLMPot, a novel approach for designing honeypots in ICS networks harnessing the potency of Large Language Models (LLMs). LLMPot aims to automate and optimize the creation of realistic honeypots with vendor-agnostic configurations, and for any control logic, aiming to eliminate the manual effort and specialized knowledge traditionally required in this domain. We conducted extensive experiments focusing on a wide array of parameters, demonstrating that our LLM-based approach can effectively create honeypot devices implementing different industrial protocols and diverse control logic.",
    "pdf_link": "https://arxiv.org/abs/2405.05999",
    "graphs": [],
    "abstract_cn": "工业控制系统（ICS）在关键基础设施中扮演着至关重要的角色，确保了高效、可靠的运行。然而，随着其连接性的提升，它们也面临着日益增长的物质网络威胁，这些威胁可能导致基本服务的严重中断。蜜罐技术在此背景下显得尤为重要，它们作为ICS网络中的诱饵，帮助我们检测、分析并应对特定的网络威胁。但是，部署ICS蜜罐并非易事，它要求我们精确复制工业协议和设备特性，以模仿不同工业系统的独特操作行为。此外，为了捕捉那些试图破坏关键基础设施的攻击流量，我们还需要模拟PLC的控制逻辑，这需要大量的手动工作和专业知识。本文提出了LLMPot，一种利用大型语言模型（LLMs）设计ICS网络蜜罐的创新方法。LLMPot旨在自动化这一过程，创建出与供应商无关、适用于任何控制逻辑的真实蜜罐，从而减少对传统手动工作和专业知识的依赖。我们的实验证明，基于LLM的方法能够有效地创建出实现多种工业协议和控制逻辑的蜜罐设备。",
    "title_cn": "LLMPot：利用LLM自动化模拟工业协议与物理过程，为ICS蜜罐打造智能防护盾解释：在结果2中，我采用了更加生动和形象的表达方式，将“自动化模拟”比喻为“打造智能防护盾”，使得翻译更加符合中文的表达习惯，同时也增强了语言的吸引力和表现力。",
    "tags": [
      "Agent\n\n这篇论文介绍了一种名为LLMPot的创新方法，它利用大型语言模型（LLMs）来设计工业控制系统（ICS）网络蜜罐。这种方法旨在自动化蜜罐的创建过程，减少对传统手动工作和专业知识的依赖，并能够创建出与供应商无关、适用于任何控制逻辑的真实蜜罐。因此，这篇论文更符合Agent分类，因为它描述了一个智能系统（Agent）如何被设计来执行特定的任务，即创建ICS网络蜜罐以检测和应对网络威胁。",
      "工业控制系统",
      "网络安全"
    ]
  },
  {
    "title": "THRONE: An Object-based Hallucination Benchmark for the Free-form Generations of Large Vision-Language Models",
    "submit_datetime": "2024年05月08日",
    "abstract": "Mitigating hallucinations in large vision-language models (LVLMs) remains an open problem. Recent benchmarks do not address hallucinations in open-ended free-form responses, which we term \"Type I hallucinations\". Instead, they focus on hallucinations responding to very specific question formats -- typically a multiple-choice response regarding a particular object or attribute -- which we term \"Type II hallucinations\". Additionally, such benchmarks often require external API calls to models which are subject to change. In practice, we observe that a reduction in Type II hallucinations does not lead to a reduction in Type I hallucinations but rather that the two forms of hallucinations are often anti-correlated. To address this, we propose THRONE, a novel object-based automatic framework for quantitatively evaluating Type I hallucinations in LVLM free-form outputs. We use public language models (LMs) to identify hallucinations in LVLM responses and compute informative metrics. By evaluating a large selection of recent LVLMs using public datasets, we show that an improvement in existing metrics do not lead to a reduction in Type I hallucinations, and that established benchmarks for measuring Type I hallucinations are incomplete. Finally, we provide a simple and effective data augmentation method to reduce Type I and Type II hallucinations as a strong baseline.",
    "pdf_link": "https://arxiv.org/abs/2405.05256",
    "graphs": [],
    "abstract_cn": "在大型视觉-语言模型中，幻觉问题依旧棘手。现有基准多关注特定问题下的幻觉，即“类型II幻觉”，而忽略了自由回答中的“类型I幻觉”。这些基准还依赖于可能变动的模型API。实际上，我们发现减少类型II幻觉并不意味着类型I幻觉的减少，两者往往呈现反相关。为此，我们推出了THRONE框架，专门用于量化评估自由回答中的类型I幻觉。我们利用公共语言模型来检测幻觉，并计算相关指标。通过对多个LVLMs的评估，我们发现现有指标的提升并未减少类型I幻觉，且现有基准不足以全面衡量类型I幻觉。最后，我们提出了一种简便高效的数据增强方法，作为减少两种幻觉的有效起点。",
    "title_cn": "THRONE：大型视觉-语言模型自由形式生成的对象幻觉基准在这篇文章中，我们将介绍 THRONE，这是一个专门为大型视觉-语言模型设计的基于对象的幻觉基准。THRONE 旨在评估这些模型在自由形式生成任务中的表现，特别是在处理复杂场景和对象时的幻觉能力。通过 THRONE，我们希望推动视觉-语言模型在理解和生成更加丰富、多样化的内容方面的进步，同时揭示模型在处理幻觉时的潜在挑战和局限性。",
    "tags": [
      "LLM理论\n\n理由：这篇论文关注的是大型视觉-语言模型（LVLMs）中的幻觉问题，特别是类型I幻觉的量化评估。它提出了一个新的框架THRONE来评估自由回答中的幻觉，并探讨了现有指标和基准的不足。这些问题属于对大型语言模型（LLM）理论层面的探讨和改进，因此归类为LLM理论。虽然论文中提到了模型的应用（如数据增强方法），但其核心贡献在于理论框架的提出和幻觉问题的深入分析，而非直接的应用开发或Agent的设计。",
      "人工智能评估",
      "数据增强"
    ]
  },
  {
    "title": "You Only Cache Once: Decoder-Decoder Architectures for Language Models",
    "submit_datetime": "2024年05月08日",
    "abstract": "We introduce a decoder-decoder architecture, YOCO, for large language models, which only caches key-value pairs once. It consists of two components, i.e., a cross-decoder stacked upon a self-decoder. The self-decoder efficiently encodes global key-value (KV) caches that are reused by the cross-decoder via cross-attention. The overall model behaves like a decoder-only Transformer, although YOCO only caches once. The design substantially reduces GPU memory demands, yet retains global attention capability. Additionally, the computation flow enables prefilling to early exit without changing the final output, thereby significantly speeding up the prefill stage. Experimental results demonstrate that YOCO achieves favorable performance compared to Transformer in various settings of scaling up model size and number of training tokens. We also extend YOCO to 1M context length with near-perfect needle retrieval accuracy. The profiling results show that YOCO improves inference memory, prefill latency, and throughput by orders of magnitude across context lengths and model sizes. Code is available at https://aka.ms/YOCO.",
    "pdf_link": "https://arxiv.org/abs/2405.05254",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.05254v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05254/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05254v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05254/arch.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05254v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05254/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05254v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05254/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05254v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05254/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05254v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05254/book-1m-ppl.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05254v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05254/code-1m-ppl.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05254v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05254/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05254v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05254/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05254v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05254/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05254v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05254/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05254v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05254/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05254v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05254/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05254v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05254/x11.png"
      }
    ],
    "abstract_cn": "我们推出了YOCO，一种创新的解码器-解码器架构，专为大型语言模型设计，其特点是仅对键值对进行一次缓存。YOCO由两个关键部分构成：一个自解码器和一个跨解码器。自解码器负责高效编码全局键值缓存，而跨解码器则通过交叉注意力机制重用这些缓存。尽管YOCO的运作方式类似于仅解码器的Transformer，但其独特的缓存机制大幅降低了GPU内存的消耗，同时保持了全局注意力的强大功能。此外，YOCO的计算流程支持预填充至早期退出，这一特性在不改变最终输出的情况下，大幅提升了预填充阶段的效率。实验数据表明，YOCO在不同规模的模型和训练令牌数量下，均展现出与Transformer相媲美的性能。我们还成功将YOCO扩展至1M的上下文长度，实现了几乎完美的针检索准确性。性能分析显示，YOCO在推理内存、预填充延迟和吞吐量方面，针对不同上下文长度和模型大小，均实现了显著的优化。相关代码已公开，可在https://aka.ms/YOCO获取。",
    "title_cn": "一缓存，解码双全：语言模型中的解码器-解码器架构新探在",
    "tags": [
      "LLM理论\n\n理由：这篇论文介绍了一种名为YOCO的新型解码器-解码器架构，专为大型语言模型设计，并详细讨论了其独特的缓存机制和计算流程。这些内容涉及大型语言模型的理论和架构设计，因此属于LLM理论分类。虽然YOCO的性能优化可能对LLM应用有实际意义，但论文的核心贡献在于提出了一种新的模型架构，这更偏向于理论研究。",
      "",
      "机器学习模型优化"
    ]
  },
  {
    "title": "Open Source Language Models Can Provide Feedback: Evaluating LLMs' Ability to Help Students Using GPT-4-As-A-Judge",
    "submit_datetime": "2024年05月08日",
    "abstract": "Large language models (LLMs) have shown great potential for the automatic generation of feedback in a wide range of computing contexts. However, concerns have been voiced around the privacy and ethical implications of sending student work to proprietary models. This has sparked considerable interest in the use of open source LLMs in education, but the quality of the feedback that such open models can produce remains understudied. This is a concern as providing flawed or misleading generated feedback could be detrimental to student learning. Inspired by recent work that has utilised very powerful LLMs, such as GPT-4, to evaluate the outputs produced by less powerful models, we conduct an automated analysis of the quality of the feedback produced by several open source models using a dataset from an introductory programming course. First, we investigate the viability of employing GPT-4 as an automated evaluator by comparing its evaluations with those of a human expert. We observe that GPT-4 demonstrates a bias toward positively rating feedback while exhibiting moderate agreement with human raters, showcasing its potential as a feedback evaluator. Second, we explore the quality of feedback generated by several leading open-source LLMs by using GPT-4 to evaluate the feedback. We find that some models offer competitive performance with popular proprietary LLMs, such as ChatGPT, indicating opportunities for their responsible use in educational settings.",
    "pdf_link": "https://arxiv.org/abs/2405.05253",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）在自动生成反馈方面展现出巨大潜力，但将学生作业发送给专有模型引发的隐私和伦理问题令人担忧。因此，开源LLMs在教育中的应用备受关注，但其反馈质量的研究仍显不足。提供有缺陷或误导性的反馈可能对学生学习造成伤害。受到GPT-4等强大模型用于评估较弱模型输出的启发，我们使用入门编程课程数据集对多个开源模型的反馈质量进行了自动分析。首先，我们验证了GPT-4作为自动评估者的有效性，发现它倾向于积极评价，并与人类评价者保持中等一致性。其次，我们评估了多个开源LLMs生成的反馈，发现某些模型与ChatGPT等专有模型性能相当，为教育领域提供了负责任使用的可能性。",
    "title_cn": "开源语言模型助力学习：探究GPT-4作为公正评判，如何提升大型语言模型在教育辅导中的反馈能力。",
    "tags": [
      "LLM应用\n\n这篇论文探讨了开源大型语言模型（LLMs）在教育领域中的应用，特别是在自动生成反馈方面的潜力和质量问题。它关注了隐私和伦理问题，并通过对开源模型的反馈质量进行自动分析，评估了它们在教育中的适用性。这与LLM应用的分类相符，因为它涉及LLMs在特定领域（教育）的实际应用和影响。",
      "",
      "编程教育"
    ]
  },
  {
    "title": "LLMs with Personalities in Multi-issue Negotiation Games",
    "submit_datetime": "2024年05月08日",
    "abstract": "Powered by large language models (LLMs), AI agents have become capable of many human tasks. Using the most canonical definitions of the Big Five personality, we measure the ability of LLMs to negotiate within a game-theoretical framework, as well as methodological challenges to measuring notions of fairness and risk. Simulations (n=1,500) for both single-issue and multi-issue negotiation reveal increase in domain complexity with asymmetric issue valuations improve agreement rates but decrease surplus from aggressive negotiation. Through gradient-boosted regression and Shapley explainers, we find high openness, conscientiousness, and neuroticism are associated with fair tendencies; low agreeableness and low openness are associated with rational tendencies. Low conscientiousness is associated with high toxicity. These results indicate that LLMs may have built-in guardrails that default to fair behavior, but can be \"jail broken\" to exploit agreeable opponents. We also offer pragmatic insight in how negotiation bots can be designed, and a framework of assessing negotiation behavior based on game theory and computational social science.",
    "pdf_link": "https://arxiv.org/abs/2405.05248",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）赋能的AI代理已能执行多种人类任务。我们采用大五人格的经典定义，评估LLMs在博弈论框架中的谈判能力，并探讨衡量公平与风险的方法论难题。通过1500次单问题和多问题谈判模拟，我们发现随着问题估值的不对称性增加，谈判领域的复杂性提升，虽然协议率上升，但激进谈判带来的盈余却减少。利用梯度提升回归和Shapley解释器分析，我们发现高开放性、尽责性和神经质与公平倾向相关，而低宜人性和低开放性则与理性倾向相关。低尽责性则与高毒性行为相关。这些发现暗示LLMs内置有倾向于公平行为的保护机制，但也可被“越狱”以利用对手的宜人性。此外，我们还提供了设计谈判机器人的实用建议，并构建了一个基于博弈论和计算社会科学的谈判行为评估框架。",
    "title_cn": "个性化的LLMs在多议题谈判游戏中展现风采在这项研究中，我们探讨了具有不同个性的语言模型在多议题谈判游戏中的表现。通过赋予LLMs独特的性格特征，我们旨在模拟更真实的谈判场景，并分析这些个性如何影响谈判策略和结果。我们的实验结果揭示了个性化的LLMs在理解和适应复杂谈判环境方面的潜力，以及它们如何通过展现不同的谈判风格来达成更有利的协议。",
    "tags": [
      "Agent\n\n这篇论文主要探讨了大型语言模型（LLMs）赋能的AI代理在博弈论框架中的谈判能力，以及如何评估这些代理在谈判中的公平性和风险。它通过模拟谈判实验来分析LLMs的行为特征，并提供了设计谈判机器人的实用建议。因此，它更符合Agent分类，因为它关注的是LLMs作为智能代理在特定任务（即谈判）中的应用和行为分析。",
      "人工智能",
      "谈判策略"
    ]
  },
  {
    "title": "SuFIA: Language-Guided Augmented Dexterity for Robotic Surgical Assistants",
    "submit_datetime": "2024年05月08日",
    "abstract": "In this work, we present SuFIA, the first framework for natural language-guided augmented dexterity for robotic surgical assistants. SuFIA incorporates the strong reasoning capabilities of large language models (LLMs) with perception modules to implement high-level planning and low-level control of a robot for surgical sub-task execution. This enables a learning-free approach to surgical augmented dexterity without any in-context examples or motion primitives. SuFIA uses a human-in-the-loop paradigm by restoring control to the surgeon in the case of insufficient information, mitigating unexpected errors for mission-critical tasks. We evaluate SuFIA on four surgical sub-tasks in a simulation environment and two sub-tasks on a physical surgical robotic platform in the lab, demonstrating its ability to perform common surgical sub-tasks through supervised autonomous operation under challenging physical and workspace conditions. Project website: orbit-surgical.github.io/sufia",
    "pdf_link": "https://arxiv.org/abs/2405.05226",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.05226v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05226/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05226v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05226/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05226v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05226/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05226v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05226/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05226v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05226/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05226v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05226/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05226v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05226/x7.png"
      }
    ],
    "abstract_cn": "我们推出了SuFIA，首个利用自然语言指导提升机器人手术助手灵活性的框架。它巧妙融合了LLMs的推理力与感知技术，实现机器人手术子任务的精准规划与控制，无需预设示例或动作基础。SuFIA在信息不足时将主动权交还给外科医生，确保关键任务的稳定执行。在模拟与实际环境中，SuFIA均展现了在复杂条件下自主完成手术子任务的卓越能力。了解更多，请访问项目网站：orbit-surgical.github.io/sufia。",
    "title_cn": "SuFIA：赋予机器人手术助手语言引导的灵巧增强能力在这项研究中，我们提出了SuFIA，一种新颖的框架，旨在通过语言指令增强机器人手术助手的操作灵巧性。SuFIA利用先进的自然语言处理技术，使机器人能够理解并执行复杂的手术任务，从而提高手术效率和精确度。我们的方法结合了深度学习和机器人控制技术，为机器人手术助手在多变的手术环境中提供了更高的适应性和灵活性。通过在实际手术场景中的应用，SuFIA展现了其在提升手术质量和安全性方面的巨大潜力。",
    "tags": [
      "Agent\n\n这篇论文介绍了一个名为SuFIA的框架，它利用大型语言模型（LLMs）的推理能力与感知技术相结合，以提升机器人手术助手的灵活性。SuFIA能够进行机器人手术子任务的精准规划与控制，并且在信息不足时将决策权交还给外科医生。这个框架在模拟和实际环境中都展示了其自主完成复杂手术子任务的能力。因此，它属于Agent分类，因为它描述了一个智能代理系统，该系统能够执行特定的任务，并在必要时与人类操作员协作。",
      "机器人手术",
      "医疗辅助技术"
    ]
  },
  {
    "title": "Conv-Basis: A New Paradigm for Efficient Attention Inference and Gradient Computation in Transformers",
    "submit_datetime": "2024年05月08日",
    "abstract": "Large Language Models (LLMs) have profoundly changed the world. Their self-attention mechanism is the key to the success of transformers in LLMs. However, the quadratic computational cost $O(n^2)$ to the length $n$ input sequence is the notorious obstacle for further improvement and scalability in the longer context. In this work, we leverage the convolution-like structure of attention matrices to develop an efficient approximation method for attention computation using convolution matrices. We propose a $\\mathsf{conv}$ basis system, \"similar\" to the rank basis, and show that any lower triangular (attention) matrix can always be decomposed as a sum of $k$ structured convolution matrices in this basis system. We then design an algorithm to quickly decompose the attention matrix into $k$ convolution matrices. Thanks to Fast Fourier Transforms (FFT), the attention {\\it inference} can be computed in $O(knd \\log n)$ time, where $d$ is the hidden dimension. In practice, we have $ d \\ll n$, i.e., $d=3,072$ and $n=1,000,000$ for Gemma. Thus, when $kd = n^{o(1)}$, our algorithm achieve almost linear time, i.e., $n^{1+o(1)}$. Furthermore, the attention {\\it training forward} and {\\it backward gradient} can be computed in $n^{1+o(1)}$ as well. Our approach can avoid explicitly computing the $n \\times n$ attention matrix, which may largely alleviate the quadratic computational complexity. Furthermore, our algorithm works on any input matrices. This work provides a new paradigm for accelerating attention computation in transformers to enable their application to longer contexts.",
    "pdf_link": "https://arxiv.org/abs/2405.05219",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）的变革力量源自其自注意力机制，但这一机制的二次计算成本O(n^2)却成为扩展至更长上下文的绊脚石。本研究巧妙地利用了注意力矩阵的卷积结构，提出了一种高效的近似计算方法，通过“conv”基系统将复杂的注意力矩阵分解为多个结构化的卷积矩阵。借助快速傅里叶变换（FFT），我们的算法实现了近线性时间复杂度，大幅降低了计算负担。这一创新不仅避免了显式计算庞大的注意力矩阵，还适用于各种输入矩阵，为变压器在处理更长上下文时提供了加速的新途径。",
    "title_cn": "Conv-Basis：开创Transformer高效注意力推理与梯度计算的新纪元在这项研究中，我们提出了一种名为Conv-Basis的新方法，它为Transformer模型中的注意力推理和梯度计算提供了一种更为高效的处理方式。通过引入这一新范式，我们旨在优化Transformer的计算效率，同时保持其在自然语言处理任务中的卓越性能。",
    "tags": [
      "LLM理论\n\n这篇论文探讨了大型语言模型（LLMs）中的自注意力机制及其计算成本问题，并提出了一种基于卷积结构的高效近似计算方法。这种方法旨在解决自注意力机制在处理长上下文时的计算瓶颈，通过引入卷积基系统和快速傅里叶变换（FFT）来降低计算复杂度。由于这项工作专注于LLMs的理论层面，特别是其核心机制的优化和改进，因此它属于LLM理论分类。",
      "",
      "机器学习"
    ]
  },
  {
    "title": "MIDGARD: Self-Consistency Using Minimum Description Length for Structured Commonsense Reasoning",
    "submit_datetime": "2024年05月08日",
    "abstract": "We study the task of conducting structured reasoning as generating a reasoning graph from natural language input using large language models (LLMs). Previous approaches have explored various prompting schemes, yet they suffer from error propagation due to the autoregressive nature and single-pass-based decoding, which lack error correction capability. Additionally, relying solely on a single sample may result in the omission of true nodes and edges. To counter this, we draw inspiration from self-consistency (SC), which involves sampling a diverse set of reasoning chains and taking the majority vote as the final answer. To tackle the substantial challenge of applying SC on generated graphs, we propose MIDGARD (MInimum Description length Guided Aggregation of Reasoning in Directed acyclic graph) that leverages Minimum Description Length (MDL)-based formulation to identify consistent properties among the different graph samples generated by an LLM. This formulation helps reject properties that appear in only a few samples, which are likely to be erroneous, while enabling the inclusion of missing elements without compromising precision. Our method demonstrates superior performance than comparisons across various structured reasoning tasks, including argument structure extraction, explanation graph generation, inferring dependency relations among actions for everyday tasks, and semantic graph generation from natural texts.",
    "pdf_link": "https://arxiv.org/abs/2405.05189",
    "graphs": [],
    "abstract_cn": "我们探索了如何利用LLMs从自然语言输入构建推理图，以实现结构化推理。传统方法因自回归解码的单次传递特性而容易出现错误传播，且仅凭单一样本可能导致关键信息遗漏。为此，我们引入了自我一致性（SC）策略，通过多样化的推理链采样和多数投票来确定最终答案。面对在图生成中应用SC的挑战，我们创新性地提出了MIDGARD方法，该方法运用最小描述长度（MDL）原则，从多个图样本中提炼出一致的推理属性，同时排除那些仅在少数样本中出现的错误属性，并补充遗漏的元素，确保精确度不受影响。我们的方法在多个结构化推理任务中，如论证结构分析、解释图构建、日常行动依赖关系推断以及自然文本的语义图生成，均展现出了卓越的性能。",
    "title_cn": "MIDGARD：运用最小描述长度原则，实现结构化常识推理的自洽性在翻译过程中，我首先确保了原文意思的准确传达，然后对翻译结果进行了润色，使其更符合中文的表达习惯，同时保持了原文的学术性和专业性。",
    "tags": [
      "Agent\n\n这篇论文探讨了如何利用大型语言模型（LLMs）来构建推理图，这是一种智能代理（Agent）的行为，因为它涉及到从自然语言输入中提取信息并进行推理。论文中提出的自我一致性（SC）策略和MIDGARD方法，都是为了提高推理的准确性和可靠性，这是智能代理在处理复杂任务时所必需的能力。因此，这篇论文更符合Agent分类，因为它关注的是如何增强LLM在推理和决策方面的应用，而不是LLM的理论研究或特定应用场景。",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Air Gap: Protecting Privacy-Conscious Conversational Agents",
    "submit_datetime": "2024年05月08日",
    "abstract": "The growing use of large language model (LLM)-based conversational agents to manage sensitive user data raises significant privacy concerns. While these agents excel at understanding and acting on context, this capability can be exploited by malicious actors. We introduce a novel threat model where adversarial third-party apps manipulate the context of interaction to trick LLM-based agents into revealing private information not relevant to the task at hand.\n  Grounded in the framework of contextual integrity, we introduce AirGapAgent, a privacy-conscious agent designed to prevent unintended data leakage by restricting the agent's access to only the data necessary for a specific task. Extensive experiments using Gemini, GPT, and Mistral models as agents validate our approach's effectiveness in mitigating this form of context hijacking while maintaining core agent functionality. For example, we show that a single-query context hijacking attack on a Gemini Ultra agent reduces its ability to protect user data from 94% to 45%, while an AirGapAgent achieves 97% protection, rendering the same attack ineffective.",
    "pdf_link": "https://arxiv.org/abs/2405.05175",
    "graphs": [],
    "abstract_cn": "随着基于LLM的对话代理在处理敏感用户数据方面的应用日益增多，隐私问题日益凸显。这些代理虽擅长处理上下文，却也可能成为恶意应用的利用对象。我们提出了一种新型威胁模型，其中第三方恶意应用通过操纵交互上下文，诱导LLM代理泄露无关任务的私人信息。为此，我们基于上下文完整性框架设计了AirGapAgent，一种注重隐私的代理，它通过限制对特定任务必要数据的访问，有效防止了不必要的数据泄露。通过Gemini、GPT和Mistral模型的大量实验，我们验证了AirGapAgent在防止上下文劫持的同时，仍能保持代理的核心功能。例如，Gemini Ultra代理在一次上下文劫持攻击下，其数据保护能力从94%骤降至45%，而AirGapAgent则实现了97%的高效保护，使此类攻击失效。",
    "title_cn": "隐私守护者：空气间隙技术在对话代理中的应用在翻译过程中，我首先确保了原文意思的准确传达，然后对语言进行了优化，使其更加符合中文的表达习惯，同时保持了原文的生动性和简洁性。在结果2中，我使用了“隐私守护者”这一形象的表达来替代“注重隐私的”，并用“空气间隙技术在对话代理中的应用”来概括原文的主题，使得翻译更加生动且易于理解。",
    "tags": [
      "Agent\n\n这篇论文主要讨论了基于大型语言模型（LLM）的对话代理在处理敏感用户数据时面临的隐私问题，并提出了一种名为AirGapAgent的新型隐私保护代理。该代理通过限制对特定任务必要数据的访问来防止不必要的数据泄露，特别是在防止第三方恶意应用通过操纵交互上下文来诱导LLM代理泄露私人信息的威胁模型中。因此，这篇论文更符合Agent分类，因为它专注于开发和评估一个具体的代理系统，以解决LLM应用中的隐私保护问题。",
      "隐私保护",
      "对话系统"
    ]
  },
  {
    "title": "XAMPLER: Learning to Retrieve Cross-Lingual In-Context Examples",
    "submit_datetime": "2024年05月08日",
    "abstract": "Recent studies have shown that leveraging off-the-shelf or fine-tuned retrievers, capable of retrieving high-quality in-context examples, significantly improves in-context learning of English. However, adapting these methods to other languages, especially low-resource ones, presents challenges due to the scarcity of available cross-lingual retrievers and annotated data. In this paper, we introduce XAMPLER: Cross-Lingual Example Retrieval, a method tailored to tackle the challenge of cross-lingual in-context learning using only annotated English data. XAMPLER first trains a retriever with positive/negative English samples, which are constructed based on the predictions of the multilingual large language model for in-context learning. Then, the trained retriever is directly employed to retrieve English examples as few-shot examples for in-context learning of target languages. Experiments on the massively multilingual text classification benchmark of SIB200 with 176 languages demonstrate that XAMPLER substantially improves the in-context learning performance across languages. Our code is available at https://github.com/cisnlp/XAMPLER.",
    "pdf_link": "https://arxiv.org/abs/2405.05116",
    "graphs": [],
    "abstract_cn": "最新研究表明，利用经过微调的检索器来获取高质量的上下文示例，极大地提升了英语的上下文学习效果。然而，将此类方法应用于其他语言，尤其是资源匮乏的语言，却因缺乏跨语言检索器和标注数据而面临挑战。本文推出的XAMPLER，即跨语言示例检索，专为解决这一难题而生，它仅依赖标注的英语数据进行跨语言上下文学习。XAMPLER首先通过多语言大型语言模型的预测结果构建正负英语样本，以此训练检索器。随后，该检索器被用于直接检索英语示例，作为目标语言上下文学习的少量示例。在SIB200多语言文本分类基准上，对176种语言的实验结果显示，XAMPLER在跨语言上下文学习方面取得了显著进步，相关代码已公开于https://github.com/cisnlp/XAMPLER。",
    "title_cn": "XAMPLER：掌握跨语言上下文示例的检索艺术",
    "tags": [
      "RAG\n\n这篇论文介绍了一种名为XAMPLER的跨语言示例检索方法，旨在解决资源匮乏语言的上下文学习问题。它通过利用多语言大型语言模型的预测结果来训练检索器，并使用该检索器检索英语示例以支持目标语言的上下文学习。这种方法属于检索增强生成（RAG）的范畴，因为它涉及检索过程来增强语言模型的性能。因此，我将这篇论文分类为RAG。",
      "跨语言学习",
      ""
    ]
  },
  {
    "title": "QFMTS: Generating Query-Focused Summaries over Multi-Table Inputs",
    "submit_datetime": "2024年05月08日",
    "abstract": "Table summarization is a crucial task aimed at condensing information from tabular data into concise and comprehensible textual summaries. However, existing approaches often fall short of adequately meeting users' information and quality requirements and tend to overlook the complexities of real-world queries. In this paper, we propose a novel method to address these limitations by introducing query-focused multi-table summarization. Our approach, which comprises a table serialization module, a summarization controller, and a large language model (LLM), utilizes textual queries and multiple tables to generate query-dependent table summaries tailored to users' information needs. To facilitate research in this area, we present a comprehensive dataset specifically tailored for this task, consisting of 4909 query-summary pairs, each associated with multiple tables. Through extensive experiments using our curated dataset, we demonstrate the effectiveness of our proposed method compared to baseline approaches. Our findings offer insights into the challenges of complex table reasoning for precise summarization, contributing to the advancement of research in query-focused multi-table summarization.",
    "pdf_link": "https://arxiv.org/abs/2405.05109",
    "graphs": [],
    "abstract_cn": "表格摘要旨在将繁杂的表格数据转化为精炼的文本，以便用户轻松理解。然而，现有方法往往未能满足用户对信息深度和质量的期待，且常忽视真实查询的复杂性。本文提出了一种创新方法——基于查询的多表格摘要，它通过表格序列化、摘要控制器和大型语言模型（LLM）的协同作用，根据用户查询生成定制化的表格摘要。我们为此任务特别构建了一个包含4909对查询与摘要的数据集，并通过详尽的实验展示了我们方法的优越性。这些发现揭示了精确摘要中复杂表格推理的挑战，为基于查询的多表格摘要研究开辟了新的道路。",
    "title_cn": "QFMTS：聚焦查询，从多表数据中提炼精华摘要在翻译过程中，我首先确保了原文信息的准确传达，然后对语言进行了优化，使其更加符合中文的表达习惯，同时保持了原文的生动性和简洁性。",
    "tags": [
      "LLM应用\n\n这篇论文探讨了如何利用大型语言模型（LLM）来生成基于用户查询的定制化表格摘要，这是一个具体的应用场景。它提出了一个新的方法，并通过构建数据集和进行实验来验证其有效性。虽然这个过程中可能涉及到一些理论性的探讨，但整体上，它更侧重于LLM在实际问题解决中的应用，因此归类为LLM应用。",
      "数据处理",
      "信息检索"
    ]
  },
  {
    "title": "Concerns on Bias in Large Language Models when Creating Synthetic Personae",
    "submit_datetime": "2024年05月08日",
    "abstract": "This position paper explores the benefits, drawbacks, and ethical considerations of incorporating synthetic personae in HCI research, particularly focusing on the customization challenges beyond the limitations of current Large Language Models (LLMs). These perspectives are derived from the initial results of a sub-study employing vignettes to showcase the existence of bias within black-box LLMs and explore methods for manipulating them. The study aims to establish a foundation for understanding the challenges associated with these models, emphasizing the necessity of thorough testing before utilizing them to create synthetic personae for HCI research.",
    "pdf_link": "https://arxiv.org/abs/2405.05080",
    "graphs": [],
    "abstract_cn": "本文深入探讨了在人机交互研究中引入合成人格的利弊与伦理问题，特别聚焦于如何突破现有大型语言模型的局限，实现个性化定制。基于一项子研究的初步发现，我们通过情景案例揭示了黑盒LLMs中的偏见，并探索了调整这些偏见的策略。研究旨在为理解这些模型的挑战打下基础，并强调在为HCI研究创造合成人格之前，必须进行全面测试的重要性。",
    "title_cn": "大型语言模型在塑造虚拟人物时，其潜在的偏见问题日益受到关注。",
    "tags": [
      "Agent\n\n理由：这篇论文探讨了在人机交互（HCI）研究中引入合成人格的问题，这涉及到创建能够模拟人类行为的智能代理（Agent）。论文特别关注了大型语言模型（LLMs）的局限性和偏见，并提出了调整这些偏见的策略，这些都是构建更智能、更个性化的Agent所必须考虑的因素。因此，这篇论文与Agent的构建和应用紧密相关。",
      "人机交互",
      "人工智能伦理"
    ]
  },
  {
    "title": "Impact of Tone-Aware Explanations in Recommender Systems",
    "submit_datetime": "2024年05月08日",
    "abstract": "In recommender systems, the presentation of explanations plays a crucial role in supporting users' decision-making processes. Although numerous existing studies have focused on the effects (transparency or persuasiveness) of explanation content, explanation expression is largely overlooked. Tone, such as formal and humorous, is directly linked to expressiveness and is an important element in human communication. However, studies on the impact of tone on explanations within the context of recommender systems are insufficient. Therefore, this study investigates the effect of explanation tones through an online user study from three aspects: perceived effects, domain differences, and user attributes. We create a dataset using a large language model to generate fictional items and explanations with various tones in the domain of movies, hotels, and home products. Collected data analysis reveals different perceived effects of tones depending on the domains. Moreover, user attributes such as age and personality traits are found to influence the impact of tone. This research underscores the critical role of tones in explanations within recommender systems, suggesting that attention to tone can enhance user experience.",
    "pdf_link": "https://arxiv.org/abs/2405.05061",
    "graphs": [],
    "abstract_cn": "在推荐系统中，解释的呈现对于用户的决策至关重要。尽管研究多聚焦于解释内容的透明度和说服力，但解释的表达方式——如语气——却鲜有关注。语气，无论是正式还是幽默，都是沟通中的关键元素。然而，推荐系统中语气对解释影响的研究尚不充分。本研究通过在线用户调查，探讨了语气在感知效果、领域差异和用户属性三个方面的影响。我们利用大型语言模型生成了电影、酒店和家居产品领域的虚构项目及多种语气的解释。数据分析显示，不同领域对语气的感知效果各异，且用户的年龄和个性特征也会影响语气的效果。这项研究强调了在推荐系统中，关注语气对于提升用户体验的重要性。",
    "title_cn": "推荐系统中，音调感知解释的深远影响在推荐系统中，音调感知解释的深远影响正逐渐显现。这种新颖的方法不仅提升了用户体验，还增强了推荐结果的可信度。通过捕捉用户反馈中的情感色彩，系统能够提供更加个性化和情感共鸣的推荐理由，从而在用户心中建立起更深层次的信任与满意度。",
    "tags": [
      "Agent\n\n解释：这篇论文主要探讨了在推荐系统中，解释的表达方式（特别是语气）对用户决策的影响。它通过使用大型语言模型生成不同语气的解释，并分析了这些解释在不同领域和用户属性上的感知效果。虽然涉及到了大型语言模型的应用，但其核心关注点在于Agent（即推荐系统）如何通过调整语气来更好地与用户沟通，从而提升用户体验。因此，这篇论文更符合Agent分类，因为它主要研究的是推荐系统如何作为一个智能体与用户进行有效交互。",
      "推荐系统",
      "用户体验"
    ]
  },
  {
    "title": "Conversational Topic Recommendation in Counseling and Psychotherapy with Decision Transformer and Large Language Models",
    "submit_datetime": "2024年05月08日",
    "abstract": "Given the increasing demand for mental health assistance, artificial intelligence (AI), particularly large language models (LLMs), may be valuable for integration into automated clinical support systems. In this work, we leverage a decision transformer architecture for topic recommendation in counseling conversations between patients and mental health professionals. The architecture is utilized for offline reinforcement learning, and we extract states (dialogue turn embeddings), actions (conversation topics), and rewards (scores measuring the alignment between patient and therapist) from previous turns within a conversation to train a decision transformer model. We demonstrate an improvement over baseline reinforcement learning methods, and propose a novel system of utilizing our model's output as synthetic labels for fine-tuning a large language model for the same task. Although our implementation based on LLaMA-2 7B has mixed results, future work can undoubtedly build on the design.",
    "pdf_link": "https://arxiv.org/abs/2405.05060",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.05060v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05060/fig1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05060v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05060/abs_attns_nopad.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05060v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05060/relative_timesteps.png"
      }
    ],
    "abstract_cn": "随着心理健康支持需求的攀升，AI，尤其是大型语言模型，有望融入自动化临床系统。我们采用决策转换器架构，为心理咨询中的对话推荐话题，通过离线强化学习，从过往对话中提取信息训练模型。与传统方法相比，我们的模型表现更佳，并提出了一种新方法：将模型输出作为微调大型语言模型的合成标签。虽然基于 LLaMA-2 7B 的模型表现不一，但未来研究可在此基础上继续探索。",
    "title_cn": "运用决策转换器与大型语言模型，为咨询与心理治疗中的对话提供精准主题推荐在咨询与心理治疗领域，对话主题的推荐对于引导会话、深化理解至关重要。本研究采用决策转换器与大型语言模型相结合的先进技术，旨在为专业人士提供精准、个性化的对话主题推荐，以促进更有效的沟通与治疗进程。通过分析患者的语言模式与情感状态，系统能够智能生成符合治疗目标的对话主题，为心理健康服务带来创新与效率的提升。",
    "tags": [
      "Agent\n\n这篇论文探讨了将大型语言模型（LLM）应用于心理健康支持领域，特别是通过决策转换器架构来推荐对话话题。这种方法涉及使用离线强化学习来训练模型，以便从过往对话中提取信息。此外，论文还提出了一种新方法，即将模型输出用作微调大型语言模型的合成标签。这种应用可以被视为一个智能代理（Agent），因为它旨在自动化地提供心理咨询服务，通过理解和响应用户的需求来辅助心理健康支持。因此，这篇论文属于Agent分类。",
      "心理健康",
      "对话系统"
    ]
  },
  {
    "title": "Seeds of Stereotypes: A Large-Scale Textual Analysis of Race and Gender Associations with Diseases in Online Sources",
    "submit_datetime": "2024年05月08日",
    "abstract": "Background Advancements in Large Language Models (LLMs) hold transformative potential in healthcare, however, recent work has raised concern about the tendency of these models to produce outputs that display racial or gender biases. Although training data is a likely source of such biases, exploration of disease and demographic associations in text data at scale has been limited.\n  Methods We conducted a large-scale textual analysis using a dataset comprising diverse web sources, including Arxiv, Wikipedia, and Common Crawl. The study analyzed the context in which various diseases are discussed alongside markers of race and gender. Given that LLMs are pre-trained on similar datasets, this approach allowed us to examine the potential biases that LLMs may learn and internalize. We compared these findings with actual demographic disease prevalence as well as GPT-4 outputs in order to evaluate the extent of bias representation.\n  Results Our findings indicate that demographic terms are disproportionately associated with specific disease concepts in online texts. gender terms are prominently associated with disease concepts, while racial terms are much less frequently associated. We find widespread disparities in the associations of specific racial and gender terms with the 18 diseases analyzed. Most prominently, we see an overall significant overrepresentation of Black race mentions in comparison to population proportions.\n  Conclusions Our results highlight the need for critical examination and transparent reporting of biases in LLM pretraining datasets. Our study suggests the need to develop mitigation strategies to counteract the influence of biased training data in LLMs, particularly in sensitive domains such as healthcare.",
    "pdf_link": "https://arxiv.org/abs/2405.05049",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）在医疗保健领域具有革命性的潜力，但最近的研究揭示了这些模型在输出中显露种族或性别偏见的倾向。尽管训练数据可能是偏见的源头，但大规模文本数据中疾病与人口统计学关联的研究仍显不足。方法：我们进行了一项广泛的文本分析，利用了包含多种网络资源（如Arxiv、Wikipedia和Common Crawl）的数据集。该研究探究了疾病在网络文本中与种族和性别标记的关联情况。由于LLMs的预训练数据集与此类似，这使我们能够揭示LLMs可能吸收的潜在偏见。我们将这些发现与真实的人口统计学疾病流行率以及GPT-4的输出进行了对比，以衡量偏见的表现程度。结果：我们的研究表明，在线文本中，人口统计学术语与特定疾病概念的关联存在显著的不平衡。性别术语与疾病概念的关联尤为突出，而种族术语的关联则相对较少。我们发现，在分析的18种疾病中，特定种族和性别术语的关联存在广泛的不平等。最引人注目的是，我们观察到黑人种族的提及在人口比例中被显著高估。结论：我们的研究强调了对LLM预训练数据集中偏见的深入审查和透明报告的紧迫性。我们的发现表明，有必要制定策略来减轻LLMs中偏见训练数据的影响，尤其是在医疗保健这样对偏见敏感的领域。",
    "title_cn": "刻板印象之源：在线资源中种族与性别疾病关联的大规模文本探析",
    "tags": [
      "LLM理论\n\n这篇论文探讨了大型语言模型（LLMs）在医疗保健领域的应用中可能出现的偏见问题，特别是关注了训练数据中疾病与人口统计学关联的不平衡性。通过分析网络文本资源，研究揭示了LLMs可能吸收的潜在偏见，并与真实的人口统计学疾病流行率以及GPT-4的输出进行了对比。这项工作强调了对LLM预训练数据集中偏见的深入审查和透明报告的必要性，以及在医疗保健领域减轻这些偏见影响的策略。因此，它属于LLM理论分类，因为它关注的是LLMs的理论基础和潜在问题，而不是它们的实际应用或特定的Agent或RAG系统。",
      "医疗保健",
      "人工智能伦理"
    ]
  },
  {
    "title": "ADELIE: Aligning Large Language Models on Information Extraction",
    "submit_datetime": "2024年05月08日",
    "abstract": "Large language models (LLMs) usually fall short on information extraction (IE) tasks and struggle to follow the complex instructions of IE tasks. This primarily arises from LLMs not being aligned with humans, as mainstream alignment datasets typically do not include IE data. In this paper, we introduce ADELIE (Aligning large language moDELs on Information Extraction), an aligned LLM that effectively solves various IE tasks, including closed IE, open IE, and on-demand IE. We first collect and construct a high-quality alignment corpus IEInstruct for IE. Then we train ADELIE_SFT using instruction tuning on IEInstruct. We further train ADELIE_SFT with direct preference optimization (DPO) objective, resulting in ADELIE_DPO. Extensive experiments on various held-out IE datasets demonstrate that our models (ADELIE_SFT and ADELIE_DPO) achieve state-of-the-art (SoTA) performance among open-source models. We further explore the general capabilities of ADELIE, and experimental results reveal that their general capabilities do not exhibit a noticeable decline. We will release the code, data, and models to facilitate further research.",
    "pdf_link": "https://arxiv.org/abs/2405.05008",
    "graphs": [],
    "abstract_cn": "大型语言模型在信息提取任务上往往力不从心，难以应对复杂的指令。这源于主流的对齐数据集忽视了IE数据，导致模型与人类意图脱节。本文推出的ADELIE，专为信息提取任务量身定制，能灵活应对封闭、开放及按需IE挑战。我们精心打造了IEInstruct对齐语料库，并通过指令调整训练出ADELIE_SFT。随后，采用DPO优化目标，锻造出ADELIE_DPO。实验证明，ADELIE系列模型在开源领域独领风骚，不仅性能卓越，通用能力亦未见衰退。我们愿公开源码、数据与模型，以期推动研究的深入发展。",
    "title_cn": "ADELIE：大型语言模型在信息抽取领域的精准对齐在翻译过程中，我首先确保原文的核心意义被准确传达，即“ADELIE”是一个关于大型语言模型在信息抽取任务上进行对齐的项目或方法。然后，我调整了语言表达，使其更加符合中文的表达习惯，同时保持了原文的专业性和简洁性。",
    "tags": [
      "Agent\n\n这篇论文介绍了一个专门为信息提取任务设计的Agent，名为ADELIE。它通过构建IEInstruct对齐语料库和采用特定的训练方法（如指令调整和DPO优化目标）来提高模型在信息提取任务上的性能。论文强调了ADELIE在开源领域的领先地位，并承诺公开源码、数据和模型以促进研究。因此，这篇论文更符合Agent分类，因为它描述了一个特定任务的智能代理系统。",
      "信息提取",
      ""
    ]
  },
  {
    "title": "NAVRepair: Node-type Aware C/C++ Code Vulnerability Repair",
    "submit_datetime": "2024年05月08日",
    "abstract": "The rapid advancement of deep learning has led to the development of Large Language Models (LLMs). In the field of vulnerability repair, previous research has leveraged rule-based fixing, pre-trained models, and LLM's prompt engineering. However, existing approaches have limitations in terms of the integration of code structure with error types. Besides, due to certain features of C/C++ language, vulnerability repair in C/C++ proves to be exceptionally challenging. To address these challenges, we propose NAVRepair, a novel framework that combines the node-type information extracted from Abstract Syntax Trees (ASTs) with error types, specifically targeting C/C++ vulnerabilities. Specifically, our approach employs type analysis to localize the minimum edit node (MEN) and customizes context information collection based on different error types. In the offline stage, NAVRepair parses code patches to locate MENs and designs rules to extract relevant contextual information for each MEN type. In the online repairing stage, it analyzes the suspicious code, combines it with vulnerability type templates derived from the Common Weakness Enumeration (CWE), and generates targeted repair prompts. We evaluate NAVRepair on multiple popular LLMs and demonstrate its effectiveness in improving the performance of code vulnerability repair. Notably, our framework is independent of any specific LLMs and can quickly adapt to new vulnerability types. Extensive experiments validate that NAVRepair achieves excellent results in assisting LLMs to accurately detect and fix C/C++ vulnerabilities. We achieve a 26% higher accuracy compared to an existing LLM-based C/C++ vulnerability repair method. We believe our node type-aware approach has promising application prospects for enhancing real-world C/C++ code security.",
    "pdf_link": "https://arxiv.org/abs/2405.04994",
    "graphs": [],
    "abstract_cn": "深度学习的迅猛发展催生了大型语言模型（LLMs），它们在漏洞修复领域展现出巨大潜力。然而，现有方法在整合代码结构与错误类型方面存在短板，尤其是C/C++语言的复杂性使得漏洞修复任务异常艰巨。为此，我们推出了NAVRepair框架，它巧妙地将抽象语法树（ASTs）中的节点类型信息与错误类型相结合，专为C/C++漏洞修复量身定制。我们的方法通过类型分析精确定位最小编辑节点（MEN），并根据错误类型量身打造上下文信息收集策略。在离线阶段，NAVRepair通过解析代码补丁来识别MEN，并制定规则以提取每种MEN类型的关键上下文信息。在线修复阶段，它深入分析可疑代码，结合常见弱点枚举（CWE）中的漏洞类型模板，生成精准的修复提示。我们在多个LLMs上验证了NAVRepair的卓越性能，证明了它在提升代码漏洞修复效率方面的显著效果。我们的框架不依赖于特定的LLMs，能够迅速适应新出现的漏洞类型。实验结果表明，NAVRepair在帮助LLMs精准定位和修复C/C++漏洞方面表现出色，准确率比现有方法高出26%。我们坚信，NAVRepair的节点类型感知策略将为现实世界C/C++代码的安全性带来革命性的提升。",
    "title_cn": "NAVRepair：智能修复C/C++代码漏洞，精准识别节点类型，为您的代码安全护航。",
    "tags": [
      "LLM应用\n\n这篇论文介绍了一个名为NAVRepair的框架，它专门设计用于C/C++语言的漏洞修复，通过结合抽象语法树（ASTs）中的节点类型信息与错误类型，以及利用大型语言模型（LLMs）的能力来提高漏洞修复的效率和准确性。这种方法体现了LLM在实际应用中的价值，特别是在软件工程领域，因此将其归类为LLM应用。",
      "软件安全",
      "漏洞修复"
    ]
  },
  {
    "title": "P-ICL: Point In-Context Learning for Named Entity Recognition with Large Language Models",
    "submit_datetime": "2024年05月08日",
    "abstract": "In recent years, the rise of large language models (LLMs) has made it possible to directly achieve named entity recognition (NER) without any demonstration samples or only using a few samples through in-context learning (ICL). However, standard ICL only helps LLMs understand task instructions, format and input-label mapping, but neglects the particularity of the NER task itself. In this paper, we propose a new prompting framework P-ICL to better achieve NER with LLMs, in which some point entities are leveraged as the auxiliary information to recognize each entity type. With such significant information, the LLM can achieve entity classification more precisely. To obtain optimal point entities for prompting LLMs, we also proposed a point entity selection method based on K-Means clustering. Our extensive experiments on some representative NER benchmarks verify the effectiveness of our proposed strategies in P-ICL and point entity selection.",
    "pdf_link": "https://arxiv.org/abs/2405.04960",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.04960v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04960/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04960v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04960/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04960v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04960/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04960v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04960/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04960v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04960/x5.png"
      }
    ],
    "abstract_cn": "随着大型语言模型的兴起，我们得以通过上下文学习，仅凭寥寥数例便能精准识别文本中的命名实体。然而，传统上下文学习方法虽能助模型理解任务指令与数据格式，却未能充分挖掘命名实体识别任务的独特之处。为此，我们创新性地提出了P-ICL框架，巧妙地将关键实体作为识别各类实体的辅助线索，使得大型语言模型在实体分类上更加精准。同时，我们还开发了一种基于K-Means聚类的点实体筛选法，以确保模型获得最优的提示信息。经过在多个NER测试集上的严格实验，我们的策略展现出了显著的效果。",
    "title_cn": "P-ICL：大型语言模型在命名实体识别中的精准上下文学习在这个翻译中，我采用了“精准”一词来替代“点式”，以使中文表达更加生动和符合中文的表达习惯。同时，“精准上下文学习”也更好地传达了原文中P-ICL方法的特性，即在大型语言模型中针对命名实体识别任务进行精确的上下文信息利用。",
    "tags": [
      "LLM应用\n\n这篇论文摘要描述了一种针对大型语言模型（LLM）在命名实体识别（NER）任务上的应用改进。提出的P-ICL框架和基于K-Means聚类的点实体筛选法，旨在提高LLM在实体分类上的准确性。这些方法专注于优化LLM在特定任务（即命名实体识别）上的表现，因此属于LLM应用的范畴。虽然这种方法可能涉及到一些理论上的创新，但其主要贡献在于实际应用层面的改进，因此更适合归类为LLM应用。",
      "",
      "命名实体识别"
    ]
  },
  {
    "title": "Harnessing the Power of MLLMs for Transferable Text-to-Image Person ReID",
    "submit_datetime": "2024年05月08日",
    "abstract": "Text-to-image person re-identification (ReID) retrieves pedestrian images according to textual descriptions. Manually annotating textual descriptions is time-consuming, restricting the scale of existing datasets and therefore the generalization ability of ReID models. As a result, we study the transferable text-to-image ReID problem, where we train a model on our proposed large-scale database and directly deploy it to various datasets for evaluation. We obtain substantial training data via Multi-modal Large Language Models (MLLMs). Moreover, we identify and address two key challenges in utilizing the obtained textual descriptions. First, an MLLM tends to generate descriptions with similar structures, causing the model to overfit specific sentence patterns. Thus, we propose a novel method that uses MLLMs to caption images according to various templates. These templates are obtained using a multi-turn dialogue with a Large Language Model (LLM). Therefore, we can build a large-scale dataset with diverse textual descriptions. Second, an MLLM may produce incorrect descriptions. Hence, we introduce a novel method that automatically identifies words in a description that do not correspond with the image. This method is based on the similarity between one text and all patch token embeddings in the image. Then, we mask these words with a larger probability in the subsequent training epoch, alleviating the impact of noisy textual descriptions. The experimental results demonstrate that our methods significantly boost the direct transfer text-to-image ReID performance. Benefiting from the pre-trained model weights, we also achieve state-of-the-art performance in the traditional evaluation settings.",
    "pdf_link": "https://arxiv.org/abs/2405.04940",
    "graphs": [],
    "abstract_cn": "文本到图像的人物再识别技术，通过文本描述检索行人图像，但手动标注文本描述费时费力，限制了数据集的规模和ReID模型的泛化能力。为此，我们探索了可迁移的文本到图像ReID，即在一个大规模数据库上训练模型，并直接应用于多个数据集。我们利用多模态大型语言模型生成大量训练数据，并针对两个关键挑战提出了解决方案。首先，MLLM生成的描述结构相似，易导致模型过度拟合。我们创新性地使用MLLMs根据多样化的模板为图像添加标题，这些模板通过与大型语言模型的多轮对话获得，从而构建了文本描述多样的大规模数据集。其次，MLLM可能生成错误描述。我们开发了一种方法，自动识别并屏蔽与图像不符的描述词，基于文本与图像补丁令牌嵌入的相似性，有效减少了噪声描述的影响。实验证明，我们的方法大幅提升了文本到图像ReID的直接迁移性能，并在传统评估中达到了业界领先水平。",
    "title_cn": "驾驭多模态大型语言模型的力量，实现文本到图像人物再识别的可转移性在翻译过程中，我首先确保了原文意思的准确传达，然后对翻译进行了润色，使其更符合中文的表达习惯，同时保持了原文的生动性和简洁性。",
    "tags": [
      "LLM应用\n\n这篇论文探讨了利用多模态大型语言模型（MLLM）生成大量训练数据，以解决文本到图像的人物再识别技术中的数据集规模限制和模型泛化能力问题。它提出了创新的解决方案来处理MLLM生成的描述结构相似性和可能的错误描述问题，并通过实验证明了其方法的有效性。这表明论文关注的是LLM在实际应用中的使用，特别是在文本到图像ReID领域的应用，因此属于LLM应用分类。",
      "人物再识别",
      "多模态学习"
    ]
  },
  {
    "title": "Traj-LLM: A New Exploration for Empowering Trajectory Prediction with Pre-trained Large Language Models",
    "submit_datetime": "2024年05月08日",
    "abstract": "Predicting the future trajectories of dynamic traffic actors is a cornerstone task in autonomous driving. Though existing notable efforts have resulted in impressive performance improvements, a gap persists in scene cognitive and understanding of the complex traffic semantics. This paper proposes Traj-LLM, the first to investigate the potential of using Large Language Models (LLMs) without explicit prompt engineering to generate future motion from agents' past/observed trajectories and scene semantics. Traj-LLM starts with sparse context joint coding to dissect the agent and scene features into a form that LLMs understand. On this basis, we innovatively explore LLMs' powerful comprehension abilities to capture a spectrum of high-level scene knowledge and interactive information. Emulating the human-like lane focus cognitive function and enhancing Traj-LLM's scene comprehension, we introduce lane-aware probabilistic learning powered by the pioneering Mamba module. Finally, a multi-modal Laplace decoder is designed to achieve scene-compliant multi-modal predictions. Extensive experiments manifest that Traj-LLM, fortified by LLMs' strong prior knowledge and understanding prowess, together with lane-aware probability learning, outstrips state-of-the-art methods across evaluation metrics. Moreover, the few-shot analysis further substantiates Traj-LLM's performance, wherein with just 50% of the dataset, it outperforms the majority of benchmarks relying on complete data utilization. This study explores equipping the trajectory prediction task with advanced capabilities inherent in LLMs, furnishing a more universal and adaptable solution for forecasting agent motion in a new way.",
    "pdf_link": "https://arxiv.org/abs/2405.04909",
    "graphs": [],
    "abstract_cn": "在自动驾驶领域，预测动态交通参与者的未来轨迹是一项基石任务。尽管已有研究取得了显著的性能提升，但在场景认知和复杂交通语义的理解上仍有差距。本文提出的Traj-LLM，首次尝试利用大型语言模型（LLMs），无需繁琐的提示工程，即可从过往轨迹和场景语义中预测未来运动。通过稀疏上下文编码，Traj-LLM将代理与场景特征转化为LLMs可理解的形式，进而挖掘LLMs的深层理解力，捕捉高级场景知识和交互信息。模仿人类对车道的自然关注，我们引入了车道感知概率学习，由创新的Mamba模块驱动，以增强场景理解。最后，我们设计了多模态拉普拉斯解码器，实现与场景相符的多模态预测。实验证明，Traj-LLM凭借LLMs的深厚知识库和理解力，以及车道感知学习，在各项评估中超越了现有技术。更令人瞩目的是，仅用一半数据，Traj-LLM就超越了多数全数据基准。本研究为轨迹预测任务注入了LLMs的高级能力，开辟了一种更为通用和灵活的代理运动预测新途径。",
    "title_cn": "轨迹增强语言模型（Traj-LLM）：探索预训练大型语言模型在轨迹预测领域的创新应用",
    "tags": [
      "Agent\n\n这篇论文主要探讨了在自动驾驶领域中，如何利用大型语言模型（LLMs）来预测动态交通参与者的未来轨迹。它提出了一种名为Traj-LLM的方法，该方法通过稀疏上下文编码将代理与场景特征转化为LLMs可理解的形式，并利用LLMs的深层理解力来捕捉高级场景知识和交互信息。此外，论文还引入了车道感知概率学习和多模态拉普拉斯解码器来增强场景理解和实现多模态预测。因此，这篇论文更符合Agent分类，因为它关注的是如何利用LLMs来增强自动驾驶系统中的代理（Agent）的预测能力。",
      "自动驾驶",
      "交通预测"
    ]
  },
  {
    "title": "The Codecfake Dataset and Countermeasures for the Universally Detection of Deepfake Audio",
    "submit_datetime": "2024年05月08日",
    "abstract": "With the proliferation of Audio Language Model (ALM) based deepfake audio, there is an urgent need for effective detection methods. Unlike traditional deepfake audio generation, which often involves multi-step processes culminating in vocoder usage, ALM directly utilizes neural codec methods to decode discrete codes into audio. Moreover, driven by large-scale data, ALMs exhibit remarkable robustness and versatility, posing a significant challenge to current audio deepfake detection (ADD) models. To effectively detect ALM-based deepfake audio, we focus on the mechanism of the ALM-based audio generation method, the conversion from neural codec to waveform. We initially construct the Codecfake dataset, an open-source large-scale dataset, including two languages, millions of audio samples, and various test conditions, tailored for ALM-based audio detection. Additionally, to achieve universal detection of deepfake audio and tackle domain ascent bias issue of original SAM, we propose the CSAM strategy to learn a domain balanced and generalized minima. Experiment results demonstrate that co-training on Codecfake dataset and vocoded dataset with CSAM strategy yield the lowest average Equal Error Rate (EER) of 0.616% across all test conditions compared to baseline models.",
    "pdf_link": "https://arxiv.org/abs/2405.04880",
    "graphs": [],
    "abstract_cn": "随着基于ALM的深度伪造音频的泛滥，我们急需有效的检测手段。传统的深度伪造音频生成过程繁琐，而ALM则通过神经编解码技术直接将离散代码转换为音频，其强大的鲁棒性和多功能性对现有的音频深度伪造检测模型构成了巨大挑战。为此，我们深入研究了ALM音频生成的内在机制，并创建了Codecfake数据集，这是一个包含多种语言和测试条件的大规模开源数据集，专为ALM音频检测设计。为了解决深度伪造音频的普遍检测问题，并克服原始SAM的领域偏差，我们提出了CSAM策略，旨在实现领域平衡和泛化。实验证明，采用CSAM策略在Codecfake和声码器数据集上联合训练的模型，其平均等错误率仅为0.616%，远优于基线模型。",
    "title_cn": "Codecfake数据集与深度伪造音频检测的通用对策在这项研究中，我们介绍了Codecfake数据集，这是一个专为深度伪造音频检测而设计的新型数据集。我们的目标是提供一个全面的资源，以帮助研究人员开发和测试针对深度伪造音频的检测算法。此外，我们还探讨了一系列反制措施，旨在提高检测算法的鲁棒性和准确性，以应对不断进化的深度伪造技术。通过结合数据集和反制措施，我们希望推动该领域的研究，并为保护公众免受深度伪造音频的潜在威胁做出贡献。",
    "tags": [
      "Agent\n\n这篇论文主要关注的是基于ALM（可能是指某种特定的大型模型，如生成对抗网络GAN或变分自编码器VAE等）的深度伪造音频检测问题。作者通过深入研究ALM音频生成的内在机制，并创建了一个专门用于检测的数据集Codecfake，以及提出了CSAM策略来提高检测模型的泛化能力和领域平衡。这些工作都是为了构建一个能够有效检测深度伪造音频的Agent，因此属于Agent分类。虽然涉及到了大型模型的应用，但重点在于检测策略和数据集的创建，而不是LLM的理论研究或应用开发，因此不属于LLM应用或LLM理论分类。同时，文中并未提及RAG（Retrieval-Augmented Generation）相关的技术或应用，因此也不属于RAG分类。",
      "深度伪造检测",
      "音频处理"
    ]
  },
  {
    "title": "Critical Infrastructure Protection: Generative AI, Challenges, and Opportunities",
    "submit_datetime": "2024年05月08日",
    "abstract": "Critical National Infrastructure (CNI) encompasses a nation's essential assets that are fundamental to the operation of society and the economy, ensuring the provision of vital utilities such as energy, water, transportation, and communication. Nevertheless, growing cybersecurity threats targeting these infrastructures can potentially interfere with operations and seriously risk national security and public safety. In this paper, we examine the intricate issues raised by cybersecurity risks to vital infrastructure, highlighting these systems' vulnerability to different types of cyberattacks. We analyse the significance of trust, privacy, and resilience for Critical Infrastructure Protection (CIP), examining the diverse standards and regulations to manage these domains. We also scrutinise the co-analysis of safety and security, offering innovative approaches for their integration and emphasising the interdependence between these fields. Furthermore, we introduce a comprehensive method for CIP leveraging Generative AI and Large Language Models (LLMs), giving a tailored lifecycle and discussing specific applications across different critical infrastructure sectors. Lastly, we discuss potential future directions that promise to enhance the security and resilience of critical infrastructures. This paper proposes innovative strategies for CIP from evolving attacks and enhances comprehension of cybersecurity concerns related to critical infrastructure.",
    "pdf_link": "https://arxiv.org/abs/2405.04874",
    "graphs": [],
    "abstract_cn": "关键国家基础设施（CNI）是支撑社会和经济运作的基石，涵盖了能源、水务、交通和通信等核心服务。然而，随着网络安全威胁的加剧，这些基础设施面临运营中断、国家安全与公共安全受损的风险。本文深入探讨了网络安全对关键基础设施的挑战，揭示了它们在各类网络攻击面前的脆弱性。我们强调了信任、隐私和韧性在关键基础设施保护（CIP）中的核心地位，并审视了相关标准和法规。同时，我们提出了将安全和保障相结合的创新方法，并强调了它们之间的紧密联系。此外，我们提出了一种基于生成式人工智能和大语言模型的CIP综合方法，为不同关键基础设施部门提供了定制化的生命周期和应用案例。最后，我们展望了未来可能提升关键基础设施安全和韧性的方向，为应对不断演变的网络安全威胁提供了新的策略，并加深了对关键基础设施网络安全问题的理解。",
    "title_cn": "守护关键基石：生成式AI的挑战与机遇在翻译过程中，我首先确保了原文核心概念的准确传达，即“关键基础设施保护”与“生成式人工智能”。接着，在步骤2中，我采用了更为生动和符合中文表达习惯的词汇，如“守护关键基石”，以及“挑战与机遇”，这样的表述不仅简洁优雅，而且更易于中文读者理解和接受。",
    "tags": [
      "Agent\n\n这篇论文聚焦于关键国家基础设施（CNI）的网络安全挑战，并提出了一种基于生成式人工智能和大语言模型的综合方法来增强其安全性和韧性。虽然涉及了大型语言模型（LLM）的应用，但论文的核心在于探讨如何利用这些技术来构建一个能够应对网络安全威胁的智能系统，即Agent。Agent在这里指的是能够自主行动、做出决策并执行任务以保护关键基础设施的系统。因此，这篇论文更符合Agent分类，因为它侧重于智能系统的构建和应用，而不仅仅是LLM的理论或应用。",
      "关键基础设施保护",
      "网络安全"
    ]
  },
  {
    "title": "Federated Adaptation for Foundation Model-based Recommendations",
    "submit_datetime": "2024年05月08日",
    "abstract": "With the recent success of large language models, particularly foundation models with generalization abilities, applying foundation models for recommendations becomes a new paradigm to improve existing recommendation systems. It becomes a new open challenge to enable the foundation model to capture user preference changes in a timely manner with reasonable communication and computation costs while preserving privacy. This paper proposes a novel federated adaptation mechanism to enhance the foundation model-based recommendation system in a privacy-preserving manner. Specifically, each client will learn a lightweight personalized adapter using its private data. The adapter then collaborates with pre-trained foundation models to provide recommendation service efficiently with fine-grained manners. Importantly, users' private behavioral data remains secure as it is not shared with the server. This data localization-based privacy preservation is embodied via the federated learning framework. The model can ensure that shared knowledge is incorporated into all adapters while simultaneously preserving each user's personal preferences. Experimental results on four benchmark datasets demonstrate our method's superior performance. Implementation code is available to ease reproducibility.",
    "pdf_link": "https://arxiv.org/abs/2405.04840",
    "graphs": [],
    "abstract_cn": "大型语言模型的成功，尤其是那些具有泛化能力的基石模型，为推荐系统带来了革新。然而，如何在保护隐私的同时，让基石模型及时适应用户偏好的变化，成为新的挑战。本文提出了一种创新的联邦学习机制，它允许每个用户端利用本地数据训练个性化适配器，这些适配器与基石模型协同工作，提供精准推荐，同时确保用户数据的安全。通过联邦学习框架，我们实现了数据本地化隐私保护，同时保留了用户的个性化偏好。实验结果在四个数据集上展示了我们方法的卓越性能，且实现代码已公开，以支持研究的可重复性。",
    "title_cn": "基于基础模型的推荐系统的联邦适应性研究在翻译过程中，我首先直接将英文标题翻译为中文，确保意思的准确传达。然后，我进一步优化翻译，使其更加符合中文的表达习惯，简洁而优雅，同时保持了原标题的学术性和专业性。",
    "tags": [
      "Agent\n\n这篇论文探讨了在推荐系统中使用大型语言模型（LLM）时如何平衡隐私保护和用户偏好适应性的问题。通过提出一种创新的联邦学习机制，该论文展示了一种在保护用户隐私的同时，允许基石模型适应用户偏好的方法。这种方法涉及在用户端训练个性化适配器，这些适配器与基石模型协同工作，以提供精准推荐。因此，这篇论文更符合Agent分类，因为它描述了一种智能代理（Agent）如何在保护隐私的前提下，利用本地数据进行学习和适应，以提供个性化服务。",
      "推荐系统",
      "隐私保护"
    ]
  },
  {
    "title": "APrompt4EM: Augmented Prompt Tuning for Generalized Entity Matching",
    "submit_datetime": "2024年05月08日",
    "abstract": "Generalized Entity Matching (GEM), which aims at judging whether two records represented in different formats refer to the same real-world entity, is an essential task in data management. The prompt tuning paradigm for pre-trained language models (PLMs), including the recent PromptEM model, effectively addresses the challenges of low-resource GEM in practical applications, offering a robust solution when labeled data is scarce. However, existing prompt tuning models for GEM face the challenges of prompt design and information gap. This paper introduces an augmented prompt tuning framework for the challenges, which consists of two main improvements. The first is an augmented contextualized soft token-based prompt tuning method that extracts a guiding soft token benefit for the PLMs' prompt tuning, and the second is a cost-effective information augmentation strategy leveraging large language models (LLMs). Our approach performs well on the low-resource GEM challenges. Extensive experiments show promising advancements of our basic model without information augmentation over existing methods based on moderate-size PLMs (average 5.24%+), and our model with information augmentation achieves comparable performance compared with fine-tuned LLMs, using less than 14% of the API fee.",
    "pdf_link": "https://arxiv.org/abs/2405.04820",
    "graphs": [],
    "abstract_cn": "广义实体匹配（GEM）是数据管理的关键任务，它判断不同格式的记录是否指向同一实体。预训练语言模型（PLMs）的提示调优，如PromptEM，为低资源GEM提供了有效解决方案。但现有模型在提示设计和信息差距上仍有挑战。本文提出的增强提示调优框架，通过上下文化软令牌和成本效益信息增强策略，有效应对这些挑战。实验证明，我们的模型在低资源GEM上表现出色，不仅在无信息增强下超越现有方法5.24%以上，而且在信息增强后，以不到14%的API费用，与微调LLMs的性能相媲美。",
    "title_cn": "APrompt4EM：通用实体匹配的增强提示调优技术",
    "tags": [
      "Agent\n\n理由：这篇论文主要讨论了广义实体匹配（GEM）任务，并提出了一个增强提示调优框架来解决现有模型在提示设计和信息差距上的挑战。虽然提到了预训练语言模型（PLMs）和微调LLMs，但重点在于提出和改进一个框架来执行特定的数据管理任务，即GEM。这更符合Agent的分类，因为它涉及创建一个能够执行特定任务的智能系统，而不是专注于LLM的理论研究或应用开发。此外，论文中提到的上下文化软令牌和成本效益信息增强策略，都是为了提高Agent在特定任务上的性能，进一步支持了这一分类。",
      "数据管理",
      ""
    ]
  },
  {
    "title": "DALK: Dynamic Co-Augmentation of LLMs and KG to answer Alzheimer's Disease Questions with Scientific Literature",
    "submit_datetime": "2024年05月08日",
    "abstract": "Recent advancements in large language models (LLMs) have achieved promising performances across various applications. Nonetheless, the ongoing challenge of integrating long-tail knowledge continues to impede the seamless adoption of LLMs in specialized domains. In this work, we introduce DALK, a.k.a. Dynamic Co-Augmentation of LLMs and KG, to address this limitation and demonstrate its ability on studying Alzheimer's Disease (AD), a specialized sub-field in biomedicine and a global health priority. With a synergized framework of LLM and KG mutually enhancing each other, we first leverage LLM to construct an evolving AD-specific knowledge graph (KG) sourced from AD-related scientific literature, and then we utilize a coarse-to-fine sampling method with a novel self-aware knowledge retrieval approach to select appropriate knowledge from the KG to augment LLM inference capabilities. The experimental results, conducted on our constructed AD question answering (ADQA) benchmark, underscore the efficacy of DALK. Additionally, we perform a series of detailed analyses that can offer valuable insights and guidelines for the emerging topic of mutually enhancing KG and LLM. We will release the code and data at https://github.com/David-Li0406/DALK.",
    "pdf_link": "https://arxiv.org/abs/2405.04819",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）的最新进展在多个领域展现出潜力，但整合长尾知识的难题仍限制了其在专业领域的应用。本研究提出了DALK（动态LLMs与知识图谱协同增强），旨在解决这一问题，并在阿尔茨海默病（AD）研究这一生物医学重要领域中验证其效能。通过LLM与KG的互补增强框架，我们首先利用LLM构建了一个源自AD研究文献的动态AD知识图谱，随后采用精细的采样策略和创新的自适应知识检索技术，从KG中精选知识以提升LLM的推理能力。在自建的AD问答（ADQA）测试集上的实验结果证实了DALK的有效性。此外，我们还进行了一系列深入分析，为LLM与KG相互增强这一新兴领域提供了宝贵的见解和指导。相关代码和数据将在https://github.com/David-Li0406/DALK公开发布。",
    "title_cn": "DALK：通过动态协同增强 LLMs 与 KG，精准解答阿尔茨海默病相关的科学文献问题。",
    "tags": [
      "LLM应用\n\n这篇论文探讨了大型语言模型（LLMs）在特定领域（如阿尔茨海默病研究）的应用，并提出了一个名为DALK的框架，该框架通过与知识图谱（KG）的协同增强来提升LLMs在专业领域的应用能力。这种方法涉及构建动态知识图谱和采用特定的采样策略及知识检索技术，以增强LLM的推理能力。因此，这篇论文属于LLM应用类别，因为它专注于LLMs在实际问题解决中的应用，特别是在生物医学领域的知识整合和推理增强。",
      "生物医学",
      "知识图谱"
    ]
  },
  {
    "title": "ACORN: Aspect-wise Commonsense Reasoning Explanation Evaluation",
    "submit_datetime": "2024年05月08日",
    "abstract": "Evaluating free-text explanations is a multifaceted, subjective, and labor-intensive task. Large language models (LLMs) present an appealing alternative due to their potential for consistency, scalability, and cost-efficiency. In this work, we present ACORN, a new dataset of 3,500 free-text explanations and aspect-wise quality ratings, and use it to gain insights into how LLMs evaluate explanations. We observed that replacing one of the human ratings sometimes maintained, but more often lowered the inter-annotator agreement across different settings and quality aspects, suggesting that their judgments are not always consistent with human raters. We further quantified this difference by comparing the correlation between LLM-generated ratings with majority-voted human ratings across different quality aspects. With the best system, Spearman's rank correlation ranged between 0.53 to 0.95, averaging 0.72 across aspects, indicating moderately high but imperfect alignment. Finally, we considered the alternative of using an LLM as an additional rater when human raters are scarce, and measured the correlation between majority-voted labels with a limited human pool and LLMs as an additional rater, compared to the original gold labels. While GPT-4 improved the outcome when there were only two human raters, in all other observed cases, LLMs were neutral to detrimental when there were three or more human raters. We publicly release the dataset to support future improvements in LLM-in-the-loop evaluation here: https://github.com/a-brassard/ACORN.",
    "pdf_link": "https://arxiv.org/abs/2405.04818",
    "graphs": [],
    "abstract_cn": "评估自由文本解释是一项复杂、主观且耗时的工作。大型语言模型（LLMs）因其潜在的一致性、可扩展性和成本效益而成为一种有吸引力的选择。在本研究中，我们推出了ACORN数据集，包含3,500个自由文本解释及其质量评级，旨在探索LLMs如何评估解释。我们发现，尽管LLMs的评分有时能与人类评分保持一致，但更多时候会降低不同情境和质量维度间的评分一致性，暗示其判断与人类评分者并非总是一致。我们通过比较LLMs生成的评分与人类多数投票评分在不同质量方面的相关性来量化这种差异。最佳系统的斯皮尔曼相关性在0.53至0.95之间，平均为0.72，显示出中等但并非完美的对齐。此外，我们探讨了在人类评分者不足时，将LLM作为额外评分者的可能性，并比较了多数投票标签与有限人类评分者和LLM作为额外评分者之间的相关性，与原始黄金标签相比。GPT-4在只有两个人类评分者时有所改善，但在其他情况下，当有三个人类评分者或更多时，LLMs的影响要么是中性的，要么是有害的。我们已公开ACORN数据集，以促进未来在LLM辅助评估方面的进步。数据集地址为：https://github.com/a-brassard/ACORN。",
    "title_cn": "ACORN：细粒度常识推理解释评价在这个翻译中，我首先直接将英文标题翻译为中文，确保了意思的准确传达。然后，在第二步中，我采用了更符合中文表达习惯的词汇，将“Aspect-wise”翻译为“细粒度”，使得标题更加简洁优雅，同时保持了原意。这样的翻译既符合中文的表达习惯，又能够生动地传达原文的核心概念。",
    "tags": [
      "LLM应用\n\n这篇论文探讨了大型语言模型（LLMs）在评估自由文本解释质量方面的应用。它介绍了ACORN数据集，并分析了LLMs在评分解释时与人类评分者的一致性。研究结果表明，LLMs的评分与人类评分存在一定程度的相关性，但并非完全一致。此外，论文还探讨了在人类评分者不足的情况下，LLMs作为额外评分者的潜在作用。这些内容属于LLM在实际应用中的探索，特别是在自动化评估和质量控制领域，因此将其归类为LLM应用。",
      "教育评估",
      ""
    ]
  },
  {
    "title": "VisionGraph: Leveraging Large Multimodal Models for Graph Theory Problems in Visual Context",
    "submit_datetime": "2024年05月08日",
    "abstract": "Large Multimodal Models (LMMs) have achieved impressive success in visual understanding and reasoning, remarkably improving the performance of mathematical reasoning in a visual context. Yet, a challenging type of visual math lies in the multimodal graph theory problem, which demands that LMMs understand the graphical structures accurately and perform multi-step reasoning on the visual graph. Additionally, exploring multimodal graph theory problems will lead to more effective strategies in fields like biology, transportation, and robotics planning. To step forward in this direction, we are the first to design a benchmark named VisionGraph, used to explore the capabilities of advanced LMMs in solving multimodal graph theory problems. It encompasses eight complex graph problem tasks, from connectivity to shortest path problems. Subsequently, we present a Description-Program-Reasoning (DPR) chain to enhance the logical accuracy of reasoning processes through graphical structure description generation and algorithm-aware multi-step reasoning. Our extensive study shows that 1) GPT-4V outperforms Gemini Pro in multi-step graph reasoning; 2) All LMMs exhibit inferior perception accuracy for graphical structures, whether in zero/few-shot settings or with supervised fine-tuning (SFT), which further affects problem-solving performance; 3) DPR significantly improves the multi-step graph reasoning capabilities of LMMs and the GPT-4V (DPR) agent achieves SOTA performance.",
    "pdf_link": "https://arxiv.org/abs/2405.04950",
    "graphs": [],
    "abstract_cn": "大型多模态模型（LMMs）在视觉理解和数学推理方面取得了显著成就，尤其是在视觉环境中的数学推理能力得到了显著提升。然而，多模态图论问题对LMMs提出了挑战，要求它们准确理解图形结构并进行多步骤视觉图推理。为了推动这一领域的发展，我们首次推出了VisionGraph基准，旨在评估LMMs解决复杂图论问题的能力，涵盖了从连通性到最短路径的八项任务。我们还引入了描述-程序-推理（DPR）链，通过生成图形结构描述和算法感知推理来提升逻辑推理的准确性。研究结果显示：1) GPT-4V在多步骤图推理中超越了Gemini Pro；2) 尽管经过微调，LMMs在图形结构感知上仍显不足，影响了问题解决效率；3) DPR显著增强了LMMs的多步骤推理能力，GPT-4V（DPR）达到了业界领先水平。",
    "title_cn": "视觉图谱：借助大型多模态模型，探索视觉场景中的图论难题。",
    "tags": [
      "LLM应用\n\n这篇论文聚焦于大型多模态模型（LMMs）在视觉理解和数学推理方面的应用，特别是在处理多模态图论问题时的能力。它介绍了VisionGraph基准，并探讨了描述-程序-推理（DPR）链如何提升逻辑推理的准确性。这些内容与LLM的应用紧密相关，特别是在评估和提升模型在特定任务上的性能方面。因此，这篇论文应归类于LLM应用。",
      "人工智能",
      "教育科技"
    ]
  },
  {
    "title": "Benchmarking Neural Radiance Fields for Autonomous Robots: An Overview",
    "submit_datetime": "2024年05月08日",
    "abstract": "Neural Radiance Fields (NeRF) have emerged as a powerful paradigm for 3D scene representation, offering high-fidelity renderings and reconstructions from a set of sparse and unstructured sensor data. In the context of autonomous robotics, where perception and understanding of the environment are pivotal, NeRF holds immense promise for improving performance. In this paper, we present a comprehensive survey and analysis of the state-of-the-art techniques for utilizing NeRF to enhance the capabilities of autonomous robots. We especially focus on the perception, localization and navigation, and decision-making modules of autonomous robots and delve into tasks crucial for autonomous operation, including 3D reconstruction, segmentation, pose estimation, simultaneous localization and mapping (SLAM), navigation and planning, and interaction. Our survey meticulously benchmarks existing NeRF-based methods, providing insights into their strengths and limitations. Moreover, we explore promising avenues for future research and development in this domain. Notably, we discuss the integration of advanced techniques such as 3D Gaussian splatting (3DGS), large language models (LLM), and generative AIs, envisioning enhanced reconstruction efficiency, scene understanding, decision-making capabilities. This survey serves as a roadmap for researchers seeking to leverage NeRFs to empower autonomous robots, paving the way for innovative solutions that can navigate and interact seamlessly in complex environments.",
    "pdf_link": "https://arxiv.org/abs/2405.05526",
    "graphs": [],
    "abstract_cn": "神经辐射场（NeRF）作为一种强大的3D场景表示技术，能够从稀疏无序的传感器数据中实现高保真渲染和重建，为自主机器人的性能提升带来了巨大希望。本文深入探讨了利用NeRF提升自主机器人能力的最新技术，特别关注了机器人的感知、定位、导航和决策等关键模块，并详细分析了3D重建、分割、姿态估计、SLAM、导航规划和交互等核心任务。我们不仅评估了现有NeRF方法的优劣，还展望了未来研究方向，包括集成3D高斯溅射、大型语言模型和生成式AI等先进技术，以期提高效率、深化场景理解并增强决策能力。本调查为研究人员提供了一条利用NeRF赋能自主机器人的清晰路径，引领着在复杂环境中实现无缝交互与导航的创新解决方案。",
    "title_cn": "自主机器人神经辐射场性能基准：全面概览",
    "tags": [
      "Agent\n\n这篇论文探讨了神经辐射场（NeRF）技术在提升自主机器人能力方面的应用，特别是在机器人的感知、定位、导航和决策等关键模块。它分析了与自主机器人相关的核心任务，并展望了未来研究方向，包括集成大型语言模型和生成式AI等技术。因此，它更符合Agent分类，因为它关注的是如何利用技术增强机器人的自主行为和决策能力。",
      "自主机器人",
      "3D视觉"
    ]
  },
  {
    "title": "Redefining Information Retrieval of Structured Database via Large Language Models",
    "submit_datetime": "2024年05月08日",
    "abstract": "Retrieval augmentation is critical when Language Models (LMs) exploit non-parametric knowledge related to the query through external knowledge bases before reasoning. The retrieved information is incorporated into LMs as context alongside the query, enhancing the reliability of responses towards factual questions. Prior researches in retrieval augmentation typically follow a retriever-generator paradigm. In this context, traditional retrievers encounter challenges in precisely and seamlessly extracting query-relevant information from knowledge bases. To address this issue, this paper introduces a novel retrieval augmentation framework called ChatLR that primarily employs the powerful semantic understanding ability of Large Language Models (LLMs) as retrievers to achieve precise and concise information retrieval. Additionally, we construct an LLM-based search and question answering system tailored for the financial domain by fine-tuning LLM on two tasks including Text2API and API-ID recognition. Experimental results demonstrate the effectiveness of ChatLR in addressing user queries, achieving an overall information retrieval accuracy exceeding 98.8\\%.",
    "pdf_link": "https://arxiv.org/abs/2405.05508",
    "graphs": [],
    "abstract_cn": "在语言模型（LMs）利用外部知识库进行推理之前，检索增强对于提取与查询相关的非参数知识至关重要。通过将检索信息融入LMs作为查询的上下文，我们提高了回答事实问题的可靠性。然而，传统检索器在从知识库中精确提取相关信息方面面临挑战。为此，我们提出了ChatLR框架，它利用LLMs的强大语义理解能力进行精确信息检索。我们还开发了一个专为金融领域定制的LLM搜索和问答系统，并通过Text2API和API-ID识别任务对LLM进行微调。实验表明，ChatLR在处理用户查询方面表现出色，信息检索准确率高达98.8%以上。",
    "title_cn": "大型语言模型重塑结构化数据库信息检索新篇章",
    "tags": [
      "RAG\n\n解释：这篇论文主要讨论了如何利用大型语言模型（LLMs）的语义理解能力来改进信息检索过程，特别是在金融领域的应用。它提出了一个名为ChatLR的框架，并通过实验展示了其在信息检索方面的准确性。这与RAG（Retrieval-Augmented Generation）的概念相符，RAG是一种结合了检索和生成的方法，用于提高语言模型的性能，尤其是在需要外部知识的情况下。因此，这篇论文更适合归类为RAG。",
      "",
      "问答系统"
    ]
  },
  {
    "title": "Cross-Care: Assessing the Healthcare Implications of Pre-training Data on Language Model Bias",
    "submit_datetime": "2024年05月08日",
    "abstract": "Large language models (LLMs) are increasingly essential in processing natural languages, yet their application is frequently compromised by biases and inaccuracies originating in their training data. In this study, we introduce Cross-Care, the first benchmark framework dedicated to assessing biases and real world knowledge in LLMs, specifically focusing on the representation of disease prevalence across diverse demographic groups. We systematically evaluate how demographic biases embedded in pre-training corpora like $ThePile$ influence the outputs of LLMs. We expose and quantify discrepancies by juxtaposing these biases against actual disease prevalences in various U.S. demographic groups. Our results highlight substantial misalignment between LLM representation of disease prevalence and real disease prevalence rates across demographic subgroups, indicating a pronounced risk of bias propagation and a lack of real-world grounding for medical applications of LLMs. Furthermore, we observe that various alignment methods minimally resolve inconsistencies in the models' representation of disease prevalence across different languages. For further exploration and analysis, we make all data and a data visualization tool available at: www.crosscare.net.",
    "pdf_link": "https://arxiv.org/abs/2405.05506",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）在自然语言处理中扮演着越来越关键的角色，但其应用常因训练数据中的偏见和错误而受损。本研究推出了Cross-Care，首个专注于评估LLMs中偏见和现实世界知识的基准框架，特别聚焦于不同人口群体中疾病流行率的准确表示。我们系统地探讨了预训练语料库中的种族偏见如何影响LLMs的输出，并通过与实际疾病流行率对比，揭示并量化了这些偏见。研究结果显示，LLMs对疾病流行率的描述与实际数据在不同人口群体中存在显著差异，暗示了医学应用中偏见传播的风险和现实世界知识的缺失。我们还发现，尽管采用了多种对齐方法，模型在不同语言中对疾病流行率的描述仍存在不一致。为促进深入研究，我们提供了所有数据和一个数据可视化工具，访问网址为：www.crosscare.net。",
    "title_cn": "跨医疗关怀：探究预训练数据如何塑造语言模型偏见，及其对医疗领域的深远影响在这项研究中，我们将深入探讨预训练数据如何影响语言模型的偏见，并分析这些偏见如何渗透到医疗决策中，从而对患者的护理产生潜在影响。我们的目标是揭示这些偏见的根源，并提出策略以减轻其对医疗保健系统的负面影响。",
    "tags": [
      "LLM理论\n\n这篇论文关注的是大型语言模型（LLMs）中的偏见和现实世界知识的准确性问题，特别是关于不同人口群体中疾病流行率的表示。它提出了一个名为Cross-Care的基准框架来评估这些偏见，并探讨了预训练语料库中的种族偏见如何影响LLMs的输出。这项研究不仅揭示了偏见的存在，还量化了这些偏见，并指出了医学应用中偏见传播的风险。因此，这篇论文更偏向于LLM的理论研究，因为它探讨了模型的内部机制和输出结果的准确性，而不是直接应用于某个特定的Agent或RAG系统，也不是关于LLM的具体应用案例。",
      "医疗健康",
      ""
    ]
  },
  {
    "title": "Boosting Large Language Models with Continual Learning for Aspect-based Sentiment Analysis",
    "submit_datetime": "2024年05月08日",
    "abstract": "Aspect-based sentiment analysis (ABSA) is an important subtask of sentiment analysis, which aims to extract the aspects and predict their sentiments. Most existing studies focus on improving the performance of the target domain by fine-tuning domain-specific models (trained on source domains) based on the target domain dataset. Few works propose continual learning tasks for ABSA, which aim to learn the target domain's ability while maintaining the history domains' abilities. In this paper, we propose a Large Language Model-based Continual Learning (\\texttt{LLM-CL}) model for ABSA. First, we design a domain knowledge decoupling module to learn a domain-invariant adapter and separate domain-variant adapters dependently with an orthogonal constraint. Then, we introduce a domain knowledge warmup strategy to align the representation between domain-invariant and domain-variant knowledge. In the test phase, we index the corresponding domain-variant knowledge via domain positioning to not require each sample's domain ID. Extensive experiments over 19 datasets indicate that our \\texttt{LLM-CL} model obtains new state-of-the-art performance.",
    "pdf_link": "https://arxiv.org/abs/2405.05496",
    "graphs": [],
    "abstract_cn": "基于方面的情感分析（ABSA）旨在提取并预测文本中的情感倾向，是情感分析的关键分支。现有研究多通过微调特定领域的模型来提升目标领域的性能。然而，关于ABSA的持续学习研究较少，这种学习旨在同时掌握新旧领域的能力。本文提出了一种基于大型语言模型的持续学习（LLM-CL）模型，专为ABSA设计。我们首先设计了一个域知识解耦模块，通过正交约束独立分离域不变和域变适配器。接着，引入域知识预热策略，以确保域不变与域变知识的表示一致。在测试时，通过域定位无需样本的域ID即可索引相应知识。实验结果显示，我们的LLM-CL模型在19个数据集上取得了领先性能。",
    "title_cn": "借助持续学习，强化大型语言模型在基于方面的情感分析领域的应用在翻译过程中，我首先确保原文的核心意义被准确传达，即“通过持续学习提升大型语言模型在基于方面的情感分析中的性能”。随后，我进一步优化表达，使其更符合中文的流畅性和优雅性，形成了“借助持续学习，强化大型语言模型在基于方面的情感分析领域的应用”的翻译。这样的翻译既保留了原文的技术性，又增添了中文表达的生动性和简洁性。",
    "tags": [
      "LLM应用\n\n这篇论文探讨了基于大型语言模型的持续学习（LLM-CL）模型在基于方面的情感分析（ABSA）任务中的应用。它提出了一种新的模型设计，旨在解决持续学习问题，即模型在掌握新领域知识的同时不忘记旧领域知识。该模型通过域知识解耦模块和域知识预热策略来实现这一目标，并在多个数据集上展示了其优越性能。因此，这篇论文属于LLM应用类别，因为它关注的是LLM在特定任务（ABSA）中的实际应用和改进。",
      "情感分析",
      ""
    ]
  },
  {
    "title": "PLLM-CS: Pre-trained Large Language Model (LLM) for Cyber Threat Detection in Satellite Networks",
    "submit_datetime": "2024年05月08日",
    "abstract": "Satellite networks are vital in facilitating communication services for various critical infrastructures. These networks can seamlessly integrate with a diverse array of systems. However, some of these systems are vulnerable due to the absence of effective intrusion detection systems, which can be attributed to limited research and the high costs associated with deploying, fine-tuning, monitoring, and responding to security breaches. To address these challenges, we propose a pretrained Large Language Model for Cyber Security , for short PLLM-CS, which is a variant of pre-trained Transformers [1], which includes a specialized module for transforming network data into contextually suitable inputs. This transformation enables the proposed LLM to encode contextual information within the cyber data. To validate the efficacy of the proposed method, we conducted empirical experiments using two publicly available network datasets, UNSW_NB 15 and TON_IoT, both providing Internet of Things (IoT)-based traffic data. Our experiments demonstrate that proposed LLM method outperforms state-of-the-art techniques such as BiLSTM, GRU, and CNN. Notably, the PLLM-CS method achieves an outstanding accuracy level of 100% on the UNSW_NB 15 dataset, setting a new standard for benchmark performance in this domain.",
    "pdf_link": "https://arxiv.org/abs/2405.05469",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.05469v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05469/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05469v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05469/method.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05469v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05469/trainingaccuracy.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05469v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05469/validationaccuracy.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05469v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05469/traininglosses.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05469v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05469/validationlosses.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05469v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05469/trainingaccuracy_ton.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05469v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05469/Validationaccuracy_ton.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05469v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05469/traininglosses_ton.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05469v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05469/validationlosses_ton.png"
      }
    ],
    "abstract_cn": "卫星网络是连接关键基础设施通信服务的生命线，它们能与多样化的系统无缝融合。然而，由于缺乏有效的入侵检测系统，一些系统显得脆弱，这主要是因为相关研究不足和高昂的安全维护成本。为此，我们提出了一种名为PLLM-CS的预训练大型语言模型，它是预训练变压器的一个变种，并配备了一个专门模块，能将网络数据转化为富含上下文信息的输入。这一创新让我们的LLM能够深入理解网络数据中的上下文信息。为了证明PLLM-CS的强大能力，我们使用了UNSW_NB 15和TON_IoT这两个公开的物联网流量数据集进行了实验。结果显示，PLLM-CS不仅超越了BiLSTM、GRU和CNN等顶尖技术，更在UNSW_NB 15数据集上实现了完美的100%准确率，为网络安全领域树立了新的性能标杆。",
    "title_cn": "PLLM-CS：专为卫星网络安全威胁检测而设计的预训练大型语言模型，旨在通过先进的语言处理技术，提升对潜在网络风险的识别与防御能力。",
    "tags": [
      "LLM应用\n\n这篇论文介绍了一种名为PLLM-CS的预训练大型语言模型，该模型专门设计用于网络数据分析，并用于入侵检测系统。它通过将网络数据转化为富含上下文信息的输入，提高了对网络数据的理解能力。论文通过实验展示了PLLM-CS在物联网流量数据集上的性能，表明其在网络安全领域的应用潜力。因此，这篇论文属于LLM应用分类。",
      "网络安全",
      "物联网"
    ]
  },
  {
    "title": "Poser: Unmasking Alignment Faking LLMs by Manipulating Their Internals",
    "submit_datetime": "2024年05月08日",
    "abstract": "Like a criminal under investigation, Large Language Models (LLMs) might pretend to be aligned while evaluated and misbehave when they have a good opportunity. Can current interpretability methods catch these 'alignment fakers?' To answer this question, we introduce a benchmark that consists of 324 pairs of LLMs fine-tuned to select actions in role-play scenarios. One model in each pair is consistently benign (aligned). The other model misbehaves in scenarios where it is unlikely to be caught (alignment faking). The task is to identify the alignment faking model using only inputs where the two models behave identically. We test five detection strategies, one of which identifies 98% of alignment-fakers.",
    "pdf_link": "https://arxiv.org/abs/2405.05466",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.05466v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05466/alignment_tuning.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05466v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05466/model_pairs.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05466v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05466/spectrum.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05466v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05466/double.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05466v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05466/drunk_strategy.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05466v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05466/strategy_three.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05466v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05466/strategy_four.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05466v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05466/strategy_five.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05466v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05466/saliency_map.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05466v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05466/alignment_tuning.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05466v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05466/total.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05466v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05466/strategy_three_step.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05466v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05466/violin.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）如同被调查的罪犯，在评估时伪装成守规矩的模样，一旦有机可乘便露出马脚。我们现有的可解释性方法能否识破这些“规矩伪装者”？为此，我们设计了一个包含324对LLMs的测试平台，它们在角色扮演游戏中做出选择。每对中，一个模型始终表现良好，另一个则在不易被察觉的情境中违规。我们的挑战是：仅凭两者行为一致的输入，识别出那些违规的模型。经过五种检测策略的考验，其中一种策略成功揭露了98%的违规者。",
    "title_cn": "揭秘者：操纵LLMs内部机制，揭示其伪装对齐的真相",
    "tags": [
      "LLM理论\n\n这篇论文探讨了大型语言模型（LLMs）的行为评估和可解释性问题，特别是在模型可能表现出不一致或违规行为的情况下。研究者设计了一个测试平台来评估不同LLMs的行为，并尝试识别那些在特定情境下可能违规的模型。这个问题涉及到对LLMs内部工作机制的理解和解释，因此属于LLM理论的范畴。虽然这项工作可能对LLM的应用有影响，但其核心关注点是模型的行为和可解释性，而不是直接的应用场景或特定的Agent或RAG系统。",
      "人工智能可解释性",
      "模型评估"
    ]
  },
  {
    "title": "Vidur: A Large-Scale Simulation Framework For LLM Inference",
    "submit_datetime": "2024年05月08日",
    "abstract": "Optimizing the deployment of Large language models (LLMs) is expensive today since it requires experimentally running an application workload against an LLM implementation while exploring large configuration space formed by system knobs such as parallelization strategies, batching techniques, and scheduling policies. To address this challenge, we present Vidur - a large-scale, high-fidelity, easily-extensible simulation framework for LLM inference performance. Vidur models the performance of LLM operators using a combination of experimental profiling and predictive modeling, and evaluates the end-to-end inference performance for different workloads by estimating several metrics of interest such as latency and throughput. We validate the fidelity of Vidur on several LLMs and show that it estimates inference latency with less than 9% error across the range. Further, we present Vidur-Search, a configuration search tool that helps optimize LLM deployment. Vidur-Search uses Vidur to automatically identify the most cost-effective deployment configuration that meets application performance constraints. For example, Vidur-Search finds the best deployment configuration for LLaMA2-70B in one hour on a CPU machine, in contrast to a deployment-based exploration which would require 42K GPU hours - costing ~218K dollars. Source code for Vidur is available at https://github.com/microsoft/vidur.",
    "pdf_link": "https://arxiv.org/abs/2405.05465",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.05465v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05465/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05465v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05465/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05465v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05465/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05465v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05465/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05465v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05465/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05465v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05465/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05465v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05465/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05465v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05465/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05465v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05465/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05465v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05465/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05465v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05465/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05465v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05465/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05465v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05465/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05465v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05465/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05465v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05465/x15.png"
      }
    ],
    "abstract_cn": "优化LLM部署成本不菲，因为需要在庞大的配置空间中实验性地运行应用工作负载，这些配置空间由并行化策略、批处理技术和调度策略等系统参数构成。为此，我们推出了Vidur——一个高保真、可扩展的LLM推理性能模拟框架，它通过实验与预测模型相结合的方式，精确模拟LLM操作器的性能，并评估不同工作负载下的推理性能，包括延迟和吞吐量等关键指标。我们在多个LLM上验证了Vidur的准确性，其推理延迟估计误差控制在9%以内。此外，我们还开发了Vidur-Search工具，它利用Vidur自动寻找满足性能要求的成本最优部署配置。例如，Vidur-Search在一小时内为LLaMA2-70B找到了最佳配置，而传统方法则需耗费42K GPU小时，成本高达218K美元。Vidur的源代码已公开在https://github.com/microsoft/vidur。",
    "title_cn": "Vidur：大型语言模型推理的大型规模模拟框架在翻译过程中，我首先确保了原文意思的准确传达，然后对翻译进行了优化，使其更符合中文的表达习惯，同时保持了原文的简洁和优雅。",
    "tags": [
      "LLM应用\n\n这篇论文介绍了一个名为Vidur的框架，用于模拟和优化大型语言模型（LLM）的推理性能。它专注于通过实验与预测模型相结合的方式来精确模拟LLM操作器的性能，并评估不同工作负载下的推理性能，包括延迟和吞吐量等关键指标。此外，它还开发了Vidur-Search工具，用于自动寻找满足性能要求的成本最优部署配置。这些内容与LLM的实际应用和部署优化紧密相关，因此属于“LLM应用”分类。",
      "人工智能部署",
      "性能优化"
    ]
  },
  {
    "title": "Automated Program Repair: Emerging trends pose and expose problems for benchmarks",
    "submit_datetime": "2024年05月08日",
    "abstract": "Machine learning (ML) now pervades the field of Automated Program Repair (APR). Algorithms deploy neural machine translation and large language models (LLMs) to generate software patches, among other tasks. But, there are important differences between these applications of ML and earlier work. Evaluations and comparisons must take care to ensure that results are valid and likely to generalize. A challenge is that the most popular APR evaluation benchmarks were not designed with ML techniques in mind. This is especially true for LLMs, whose large and often poorly-disclosed training datasets may include problems on which they are evaluated.",
    "pdf_link": "https://arxiv.org/abs/2405.05455",
    "graphs": [],
    "abstract_cn": "机器学习已深入自动化程序修复领域，利用神经机器翻译和大型语言模型生成软件补丁。然而，这些ML应用与以往工作有着本质区别，评估时需谨慎，确保结果既准确又具有普遍性。当前的APR评估基准并非专为ML设计，尤其对于大型语言模型，其庞大的训练数据集可能隐含了评估中的问题，这是一个亟待解决的难题。",
    "title_cn": "自动化程序修复领域的新兴趋势不仅挑战了现有的基准测试，还揭示了其潜在的局限性。",
    "tags": [
      "LLM应用\n\n这篇论文摘要讨论了机器学习在自动化程序修复（APR）领域的应用，特别是利用神经机器翻译和大型语言模型生成软件补丁。它强调了评估这些ML应用时需要谨慎，以确保结果的准确性和普遍性，并指出了当前APR评估基准可能不适合ML应用，尤其是大型语言模型的问题。这与大型语言模型的应用场景相关，因此归类为LLM应用。",
      "软件工程",
      "自动化程序修复"
    ]
  },
  {
    "title": "Large Language Model Enhanced Machine Learning Estimators for Classification",
    "submit_datetime": "2024年05月08日",
    "abstract": "Pre-trained large language models (LLM) have emerged as a powerful tool for simulating various scenarios and generating output given specific instructions and multimodal input. In this work, we analyze the specific use of LLM to enhance a classical supervised machine learning method for classification problems. We propose a few approaches to integrate LLM into a classical machine learning estimator to further enhance the prediction performance. We examine the performance of the proposed approaches through both standard supervised learning binary classification tasks, and a transfer learning task where the test data observe distribution changes compared to the training data. Numerical experiments using four publicly available datasets are conducted and suggest that using LLM to enhance classical machine learning estimators can provide significant improvement on prediction performance.",
    "pdf_link": "https://arxiv.org/abs/2405.05445",
    "graphs": [],
    "abstract_cn": "预训练的LLM已成为模拟场景和生成输出的利器，尤其在面对特定指令和多模态输入时。本研究聚焦于LLM在提升经典监督学习分类方法中的应用。我们提出了一系列将LLM融入机器学习估计器的策略，旨在提升预测的精准度。通过标准二元分类任务和涉及分布变化的迁移学习任务，我们评估了这些策略的成效。基于四个公开数据集的实验结果显示，LLM的引入显著增强了经典机器学习方法的预测能力。",
    "title_cn": "大型语言模型赋能的机器学习分类器：精准估计新境界",
    "tags": [
      "LLM应用\n\n这篇论文探讨了大型语言模型（LLM）在提升传统监督学习分类方法中的应用，提出了一系列将LLM融入机器学习估计器的策略，并通过实验验证了这些策略在提高预测精度方面的有效性。这与LLM在实际应用中的使用相关，因此归类为“LLM应用”。",
      "机器学习",
      "数据分类"
    ]
  },
  {
    "title": "Evaluating Students' Open-ended Written Responses with LLMs: Using the RAG Framework for GPT-3.5, GPT-4, Claude-3, and Mistral-Large",
    "submit_datetime": "2024年05月08日",
    "abstract": "Evaluating open-ended written examination responses from students is an essential yet time-intensive task for educators, requiring a high degree of effort, consistency, and precision. Recent developments in Large Language Models (LLMs) present a promising opportunity to balance the need for thorough evaluation with efficient use of educators' time. In our study, we explore the effectiveness of LLMs ChatGPT-3.5, ChatGPT-4, Claude-3, and Mistral-Large in assessing university students' open-ended answers to questions made about reference material they have studied. Each model was instructed to evaluate 54 answers repeatedly under two conditions: 10 times (10-shot) with a temperature setting of 0.0 and 10 times with a temperature of 0.5, expecting a total of 1,080 evaluations per model and 4,320 evaluations across all models. The RAG (Retrieval Augmented Generation) framework was used as the framework to make the LLMs to process the evaluation of the answers. As of spring 2024, our analysis revealed notable variations in consistency and the grading outcomes provided by studied LLMs. There is a need to comprehend strengths and weaknesses of LLMs in educational settings for evaluating open-ended written responses. Further comparative research is essential to determine the accuracy and cost-effectiveness of using LLMs for educational assessments.",
    "pdf_link": "https://arxiv.org/abs/2405.05444",
    "graphs": [],
    "abstract_cn": "教育工作者在评估学生的开放式书面考试答案时面临着既重要又耗时的挑战，这要求他们付出巨大的努力、保持一致性和精确性。大型语言模型（LLMs）的进步是解决这一难题的希望之光，它们能够在确保评估质量的同时节省教育工作者的时间。在我们的研究中，我们测试了ChatGPT-3.5、ChatGPT-4、Claude-3和Mistral-Large这四种LLMs在评估大学生对所学材料的开放式问题答案时的效果。每个模型在两种不同的温度设置下重复评估了54个答案，总共进行了4,320次评估。我们使用了RAG框架来指导LLMs进行评估。到2024年春季，我们的分析显示，这些LLMs在评分一致性和结果上存在显著差异。我们需要更深入地了解LLMs在教育评估中的优势和局限性。进一步的研究对于确定LLMs在教育评估中的准确性和经济性至关重要。",
    "title_cn": "借助RAG框架，我们评估了GPT-3.5、GPT-4、Claude-3和Mistral-Large在评价学生开放式书面回答方面的表现。本研究旨在探索这些大型语言模型在教育评估中的应用潜力。",
    "tags": [
      "RAG\n\n理由：这篇论文主要探讨了使用大型语言模型（LLMs）如ChatGPT-3.5、ChatGPT-4、Claude-3和Mistral-Large在教育评估中的应用，特别是通过RAG框架来指导这些模型进行学生答案的评估。虽然论文涉及了LLM的应用，但其核心在于使用RAG框架来改进评估过程，因此更符合RAG分类。同时，论文并没有深入探讨LLM的理论问题，也没有提及Agent的概念，因此LLM理论和Agent分类不适用。",
      "教育评估",
      "人工智能辅助教育"
    ]
  },
  {
    "title": "Information Extraction from Historical Well Records Using A Large Language Model",
    "submit_datetime": "2024年05月08日",
    "abstract": "To reduce environmental risks and impacts from orphaned wells (abandoned oil and gas wells), it is essential to first locate and then plug these wells. Although some historical documents are available, they are often unstructured, not cleaned, and outdated. Additionally, they vary widely by state and type. Manual reading and digitizing this information from historical documents are not feasible, given the high number of wells. Here, we propose a new computational approach for rapidly and cost-effectively locating these wells. Specifically, we leverage the advanced capabilities of large language models (LLMs) to extract vital information including well location and depth from historical records of orphaned wells. In this paper, we present an information extraction workflow based on open-source Llama 2 models and test them on a dataset of 160 well documents. Our results show that the developed workflow achieves excellent accuracy in extracting location and depth from clean, PDF-based reports, with a 100% accuracy rate. However, it struggles with unstructured image-based well records, where accuracy drops to 70%. The workflow provides significant benefits over manual human digitization, including reduced labor and increased automation. In general, more detailed prompting leads to improved information extraction, and those LLMs with more parameters typically perform better. We provided a detailed discussion of the current challenges and the corresponding opportunities/approaches to address them. Additionally, a vast amount of geoscientific information is locked up in old documents, and this work demonstrates that recent breakthroughs in LLMs enable us to unlock this information more broadly.",
    "pdf_link": "https://arxiv.org/abs/2405.05438",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.05438v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05438/LLM.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05438v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05438/Prompt_1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05438v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05438/CO_example.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05438v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05438/PA_example.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05438v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05438/CO_example_text.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05438v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05438/PA_example_text.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05438v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05438/Prompt_output_example.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05438v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05438/PA_Case_4_Chain_of_Thought.png"
      }
    ],
    "abstract_cn": "为了减轻废弃油气井对环境的影响，首要任务是定位并封堵这些井。尽管历史文档提供了线索，但它们杂乱无章、未经整理且已过时，且各州和类型的文档差异巨大。面对海量井数据，传统的手动阅读和数字化方法已不切实际。为此，我们提出了一种创新的计算方法，利用大型语言模型（LLMs）的强大功能，快速且经济地从孤儿井的历史记录中提取关键信息，如井位和深度。我们基于开源的Llama 2模型设计了一套信息提取流程，并在160份井文档上进行了测试。结果显示，该流程在处理结构化的PDF报告时准确率高达100%，但在处理非结构化的图像记录时准确率降至70%。与人工方法相比，这一流程大幅节省了人力并提高了自动化水平。我们发现，更精细的提示能提升信息提取的准确性，而参数更多的LLMs通常表现更佳。我们还深入探讨了当前面临的挑战及相应的解决策略。此外，这项工作展示了LLMs在解锁旧文档中蕴含的丰富地球科学信息方面的巨大潜力。",
    "title_cn": "大型语言模型助力历史井记录信息抽取在上述翻译过程中，首先直接将英文标题翻译为中文，确保意思的准确传达。接着，对直译结果进行优化，使其更加符合中文的表达习惯，同时保持简洁优雅，并增添了一丝生动性。",
    "tags": [
      "LLM应用\n\n这篇论文探讨了如何利用大型语言模型（LLMs）来处理和提取废弃油气井历史记录中的关键信息，这是一个具体的应用场景。它展示了LLMs在自动化信息提取方面的能力，特别是在处理大量和多样化的文档时。虽然论文中提到了模型的设计和测试过程，但重点在于应用LLMs解决实际问题，而不是深入探讨LLMs的理论基础或Agent的设计与行为。因此，这篇论文更适合归类于LLM应用。",
      "环境保护",
      "石油天然气行业"
    ]
  },
  {
    "title": "Mitigating Exaggerated Safety in Large Language Models",
    "submit_datetime": "2024年05月08日",
    "abstract": "As the popularity of Large Language Models (LLMs) grow, combining model safety with utility becomes increasingly important. The challenge is making sure that LLMs can recognize and decline dangerous prompts without sacrificing their ability to be helpful. The problem of \"exaggerated safety\" demonstrates how difficult this can be. To reduce excessive safety behaviours -- which was discovered to be 26.1% of safe prompts being misclassified as dangerous and refused -- we use a combination of XSTest dataset prompts as well as interactive, contextual, and few-shot prompting to examine the decision bounds of LLMs such as Llama2, Gemma Command R+, and Phi-3. We find that few-shot prompting works best for Llama2, interactive prompting works best Gemma, and contextual prompting works best for Command R+ and Phi-3. Using a combination of these prompting strategies, we are able to mitigate exaggerated safety behaviors by an overall 92.9% across all LLMs. Our work presents a multiple prompting strategies to jailbreak LLMs' decision-making processes, allowing them to navigate the tight line between refusing unsafe prompts and remaining helpful.",
    "pdf_link": "https://arxiv.org/abs/2405.05418",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.05418v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05418/llama2-ex.png"
      }
    ],
    "abstract_cn": "随着大型语言模型（LLMs）的流行，确保模型既安全又实用变得至关重要。我们面临的挑战是让LLMs既能识别并拒绝危险提示，又不失其助人之能。所谓的“过度安全”问题揭示了这一挑战的复杂性。为了减少这种过度反应——其中有26.1%的安全提示被误判为危险并被拒绝——我们采用了XSTest数据集的提示，以及交互式、上下文和少量提示，来探索Llama2、Gemma Command R+和Phi-3等LLMs的决策边界。研究发现，少量提示最适合Llama2，交互式提示最适合Gemma，而上下文提示最适合Command R+和Phi-3。通过综合运用这些提示策略，我们成功将所有LLMs的过度安全行为降低了92.9%。我们的研究提出了一种多重提示策略，以解锁LLMs的决策过程，使它们能够在拒绝不安全提示和保持帮助性之间巧妙地找到平衡。",
    "title_cn": "大型语言模型的安全性问题亟待解决，我们致力于减轻其夸大风险，以确保技术的稳健发展。",
    "tags": [
      "LLM应用\n\n这篇论文探讨了大型语言模型（LLMs）在安全性和实用性之间的平衡问题，特别是关注了“过度安全”问题，即模型对危险提示的过度反应。通过使用XSTest数据集和不同类型的提示（交互式、上下文和少量提示），研究者们分析了Llama2、Gemma Command R+和Phi-3等模型的决策边界，并提出了一种多重提示策略来减少模型的过度安全行为。这种方法旨在使LLMs既能识别并拒绝危险提示，同时保持其帮助性。因此，这篇论文属于LLM应用类别，因为它关注的是LLMs在实际应用中的安全性和有效性问题。",
      "人工智能安全",
      ""
    ]
  },
  {
    "title": "Fishing for Magikarp: Automatically Detecting Under-trained Tokens in Large Language Models",
    "submit_datetime": "2024年05月08日",
    "abstract": "The disconnect between tokenizer creation and model training in language models has been known to allow for certain inputs, such as the infamous SolidGoldMagikarp token, to induce unwanted behaviour. Although such `glitch tokens' that are present in the tokenizer vocabulary, but are nearly or fully absent in training, have been observed across a variety of different models, a consistent way of identifying them has been missing. We present a comprehensive analysis of Large Language Model (LLM) tokenizers, specifically targeting this issue of detecting untrained and under-trained tokens. Through a combination of tokenizer analysis, model weight-based indicators, and prompting techniques, we develop effective methods for automatically detecting these problematic tokens. Our findings demonstrate the prevalence of such tokens across various models and provide insights into improving the efficiency and safety of language models.",
    "pdf_link": "https://arxiv.org/abs/2405.05417",
    "graphs": [],
    "abstract_cn": "语言模型中分词器与模型训练之间的脱节，使得某些输入如SolidGoldMagikarp令牌能够引发不希望的行为。尽管这些“故障令牌”在分词器词汇中存在，但在训练中却鲜有踪迹，且在多种模型中均有发现，但一直缺乏一致的识别方法。我们对大型语言模型（LLM）的分词器进行了深入分析，专注于检测未训练和训练不足的令牌。通过综合运用分词器分析、模型权重指标和提示技术，我们开发了自动检测这些问题令牌的有效方法。我们的研究揭示了这些令牌在不同模型中的普遍性，并为提升语言模型的效率和安全性提供了新的视角。",
    "title_cn": "《捕捉未熟之鳞：自动识别大型语言模型中的欠训练标记》",
    "tags": [
      "LLM理论\n\n这篇论文关注的是大型语言模型（LLM）中分词器与模型训练之间的脱节问题，特别是“故障令牌”的识别和检测。这些问题令牌的存在和影响揭示了模型训练和分词处理过程中的潜在缺陷，这属于对LLM内部机制的理论研究。因此，这篇论文更符合LLM理论分类，因为它探讨了语言模型构建和训练过程中的一个基础性问题，而不是直接应用于某个特定的Agent或RAG系统，也不是关于LLM的具体应用案例。",
      "",
      "模型安全性"
    ]
  },
  {
    "title": "\"They are uncultured\": Unveiling Covert Harms and Social Threats in LLM Generated Conversations",
    "submit_datetime": "2024年05月08日",
    "abstract": "Large language models (LLMs) have emerged as an integral part of modern societies, powering user-facing applications such as personal assistants and enterprise applications like recruitment tools. Despite their utility, research indicates that LLMs perpetuate systemic biases. Yet, prior works on LLM harms predominantly focus on Western concepts like race and gender, often overlooking cultural concepts from other parts of the world. Additionally, these studies typically investigate \"harm\" as a singular dimension, ignoring the various and subtle forms in which harms manifest. To address this gap, we introduce the Covert Harms and Social Threats (CHAST), a set of seven metrics grounded in social science literature. We utilize evaluation models aligned with human assessments to examine the presence of covert harms in LLM-generated conversations, particularly in the context of recruitment. Our experiments reveal that seven out of the eight LLMs included in this study generated conversations riddled with CHAST, characterized by malign views expressed in seemingly neutral language unlikely to be detected by existing methods. Notably, these LLMs manifested more extreme views and opinions when dealing with non-Western concepts like caste, compared to Western ones such as race.",
    "pdf_link": "https://arxiv.org/abs/2405.05378",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.05378v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05378/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05378v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05378/employee.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05378v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05378/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05378v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05378/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05378v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05378/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05378v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05378/x20.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05378v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05378/x21.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05378v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05378/x22.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05378v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05378/x23.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05378v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05378/x24.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05378v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05378/x25.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05378v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05378/x26.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05378v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05378/x27.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05378v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05378/x28.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05378v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05378/x29.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）已成为现代社会的核心，驱动着个人助理和招聘工具等面向用户的应用程序。尽管它们功能强大，但研究发现LLMs存在系统性偏见。以往的研究多关注西方概念，如种族和性别，而忽略了其他文化背景下的概念。此外，这些研究往往将“危害”简化为单一维度，忽视了其多样性和微妙性。为此，我们提出了基于社会科学文献的七个隐秘危害和社会威胁（CHAST）指标。我们采用与人类评估相符的模型，专门研究了LLM在招聘场景中生成的对话中的隐秘危害。实验结果显示，参与研究的八个LLMs中有七个生成的对话含有CHAST指标，这些对话以看似中性的语言隐藏了恶意观点，现有方法难以察觉。特别值得注意的是，当涉及非西方概念，如种姓，这些LLMs展现出的极端观点和意见比西方概念更为明显。",
    "title_cn": "\"粗俗之言\"：揭示大型语言模型对话背后的隐秘伤害与社会风险",
    "tags": [
      "LLM理论\n\n这篇论文关注的是大型语言模型（LLMs）在生成内容时可能存在的系统性偏见，特别是在非西方文化背景下的概念。它提出了七个隐秘危害和社会威胁（CHAST）指标，并通过实验研究了LLM在招聘场景中生成的对话中的隐秘危害。这属于对LLM理论层面的探讨，因为它不仅关注模型的应用，还深入分析了模型生成内容的偏见和危害，以及这些问题的多样性和微妙性。因此，这篇论文更符合LLM理论分类，因为它在理论层面上探讨了LLMs的偏见问题，并提出了新的评估指标。",
      "",
      "社会科学"
    ]
  },
  {
    "title": "Enhancing Holonic Architecture with Natural Language Processing for System of Systems",
    "submit_datetime": "2024年05月08日",
    "abstract": "The complexity and dynamic nature of System of Systems (SoS) necessitate efficient communication mechanisms to ensure interoperability and collaborative functioning among constituent systems, termed holons. This paper proposes an innovative approach to enhance holon communication within SoS through the integration of Conversational Generative Intelligence (CGI) techniques. Our approach leverages advancements in CGI, specifically Large Language Models (LLMs), to enable holons to understand and act on natural language instructions. This fosters more intuitive human-holon interactions, improving social intelligence and ultimately leading to better coordination among diverse systems. This position paper outlines a conceptual framework for CGI-enhanced holon interaction, discusses the potential impact on SoS adaptability, usability and efficiency, and sets the stage for future exploration and prototype implementation.",
    "pdf_link": "https://arxiv.org/abs/2405.05365",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.05365v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05365/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05365v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05365/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05365v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05365/x3.png"
      }
    ],
    "abstract_cn": "系统之系统的复杂多变，要求我们建立高效的沟通桥梁，确保各部分（我们称之为holons）能够协同工作，无缝对接。本文提出了一种新颖的方法，通过融合对话生成智能（CGI）技术，来提升这些holons在系统之系统中的沟通能力。我们借助CGI的最新进展，尤其是大型语言模型（LLMs），让holons能够理解并执行自然语言指令，从而实现人与holons之间更加直观的互动，提升社会智能，最终促进不同系统间的协调合作。本文构建了一个概念框架，探讨了CGI增强holon交互对系统之系统适应性、可用性和效率的潜在影响，并为未来的研究和原型开发指明了方向。",
    "title_cn": "借助自然语言处理，我们优化了整体架构，以提升系统之系统的协同效率。",
    "tags": [
      "Agent\n\n这篇论文探讨了如何通过对话生成智能（CGI）技术，特别是大型语言模型（LLMs），来增强系统之系统中各部分（holons）的沟通能力，以实现更高效的协同工作和直观的互动。这种方法旨在提升系统的适应性、可用性和效率，并且为未来的研究和开发提供了方向。因此，它属于Agent分类，因为它关注的是如何通过智能技术提升系统中代理（Agent）的交互和协作能力。",
      "系统工程",
      "人机交互"
    ]
  },
  {
    "title": "The Effect of Model Size on LLM Post-hoc Explainability via LIME",
    "submit_datetime": "2024年05月08日",
    "abstract": "Large language models (LLMs) are becoming bigger to boost performance. However, little is known about how explainability is affected by this trend. This work explores LIME explanations for DeBERTaV3 models of four different sizes on natural language inference (NLI) and zero-shot classification (ZSC) tasks. We evaluate the explanations based on their faithfulness to the models' internal decision processes and their plausibility, i.e. their agreement with human explanations. The key finding is that increased model size does not correlate with plausibility despite improved model performance, suggesting a misalignment between the LIME explanations and the models' internal processes as model size increases. Our results further suggest limitations regarding faithfulness metrics in NLI contexts.",
    "pdf_link": "https://arxiv.org/abs/2405.05348",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.05348v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05348/lime-example-cose.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05348v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05348/all_by_label.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05348v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05348/faithfulness.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05348v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05348/global_comprehensiveness_and_iou.png"
      }
    ],
    "abstract_cn": "LLMs正在变得更大，以期提高性能，但这种趋势对可解释性的影响却鲜为人知。本研究探讨了LIME解释在四种不同大小的DeBERTaV3模型上的应用，这些模型在NLI和ZSC任务中表现出色。我们评估了这些解释的忠实度和合理性，即它们与人类解释的一致性。研究发现，尽管模型性能有所提高，但模型大小的增加并不与合理性相关联，这表明随着模型大小的增加，LIME解释与模型内部过程之间存在不一致。此外，我们的研究结果表明，在NLI上下文中，关于忠实度指标存在局限性。",
    "title_cn": "在探索大型语言模型的奥秘时，模型的大小扮演着至关重要的角色。通过 LIME 这一工具，我们能够揭开 LLM 的可解释性之谜。本研究将深入探讨模型大小如何影响 LLM 的可解释性，为理解这些复杂系统的内在工作机制提供新的视角。",
    "tags": [
      "LLM理论",
      "",
      "机器学习"
    ]
  },
  {
    "title": "Benchmarking Educational Program Repair",
    "submit_datetime": "2024年05月08日",
    "abstract": "The emergence of large language models (LLMs) has sparked enormous interest due to their potential application across a range of educational tasks. For example, recent work in programming education has used LLMs to generate learning resources, improve error messages, and provide feedback on code. However, one factor that limits progress within the field is that much of the research uses bespoke datasets and different evaluation metrics, making direct comparisons between results unreliable. Thus, there is a pressing need for standardization and benchmarks that facilitate the equitable comparison of competing approaches. One task where LLMs show great promise is program repair, which can be used to provide debugging support and next-step hints to students. In this article, we propose a novel educational program repair benchmark. We curate two high-quality publicly available programming datasets, present a unified evaluation procedure introducing a novel evaluation metric rouge@k for approximating the quality of repairs, and evaluate a set of five recent models to establish baseline performance.",
    "pdf_link": "https://arxiv.org/abs/2405.05347",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.05347v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05347/x1.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）因其广泛的教育应用潜力而备受瞩目。在编程教育中，LLMs已被用于创造学习材料、优化错误提示和提供代码指导。然而，研究中使用的定制数据集和评估标准不一，导致研究成果难以直接对比。因此，我们急需标准化和评估基准，以便公平地比较不同方法。LLMs在程序修复任务中展现出巨大潜力，可为学生提供调试帮助和学习提示。本文提出了一项创新的教育程序修复基准，精选了两个公开的高质量编程数据集，并引入了一种新的评估指标rouge@k来衡量修复质量，同时评估了五种近期模型以确立性能基线。",
    "title_cn": "教育程序修复的基准评估在这篇文章中，我们将探讨如何通过基准测试来评估和改进教育程序的修复策略。我们将分析不同的修复方法，并探讨它们在提高教育软件质量和效率方面的潜力。通过这一过程，我们旨在为教育技术领域的专业人士提供有价值的见解，帮助他们更好地理解和优化教育程序的修复工作。",
    "tags": [
      "LLM应用\n\n这篇论文探讨了大型语言模型（LLMs）在编程教育中的应用，特别是在程序修复任务中的潜力。它提出了一项新的教育程序修复基准，并引入了新的评估指标，旨在标准化和评估LLMs在教育领域的应用。这与LLM的理论研究不同，因为它关注的是实际应用和评估方法，而不是模型本身的理论基础。同时，它也不属于Agent或RAG分类，因为这些通常指的是特定类型的智能代理或检索增强生成模型，而本文的重点是LLM在教育中的应用。",
      "编程教育",
      "教育技术"
    ]
  },
  {
    "title": "KV-Runahead: Scalable Causal LLM Inference by Parallel Key-Value Cache Generation",
    "submit_datetime": "2024年05月08日",
    "abstract": "Large Language Model or LLM inference has two phases, the prompt (or prefill) phase to output the first token and the extension (or decoding) phase to the generate subsequent tokens. In this work, we propose an efficient parallelization scheme, KV-Runahead to accelerate the prompt phase. The key observation is that the extension phase generates tokens faster than the prompt phase because of key-value cache (KV-cache). Hence, KV-Runahead parallelizes the prompt phase by orchestrating multiple processes to populate the KV-cache and minimizes the time-to-first-token (TTFT). Dual-purposing the KV-cache scheme has two main benefits. Fist, since KV-cache is designed to leverage the causal attention map, we minimize computation and computation automatically. Second, since it already exists for the exten- sion phase, KV-Runahead is easy to implement. We further propose context-level load-balancing to handle uneven KV-cache generation (due to the causal attention) and to optimize TTFT. Compared with an existing parallelization scheme such as tensor or sequential parallelization where keys and values are locally generated and exchanged via all-gather collectives, our experimental results demonstrate that KV-Runahead can offer over 1.4x and 1.6x speedups for Llama 7B and Falcon 7B respectively.",
    "pdf_link": "https://arxiv.org/abs/2405.05329",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.05329v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05329/llm_inference.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05329v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05329/ttft_1gpu_full.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05329v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05329/attn_1p.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05329v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05329/attn_2p.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05329v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05329/attn_4p.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05329v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05329/attn_p.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05329v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05329/dp_overview.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05329v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05329/kva_overview.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05329v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05329/ttft_3gpu_dp_before.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05329v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05329/ttft_3gpu_dp_after.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05329v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05329/ttft_3gpu_kva_before.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05329v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05329/ttft_3gpu_kva_after.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05329v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05329/search_2gpu.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05329v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05329/ttft_search_0.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05329v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05329/ttft_search_1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05329v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05329/ttft_search_2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05329v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05329/dp_graph.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05329v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05329/kva_graph.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05329v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05329/kva_2gpu.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05329v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05329/kva_4gpu.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05329v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05329/kva_8gpu.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05329v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05329/ttft_12k_scale.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05329v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05329/kva_4gpu_lb.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05329v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05329/kva_8gpu_lb.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05329v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05329/kva_falcon7b_2gpu.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05329v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05329/kva_falcon7b_4gpu.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05329v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05329/kva_falcon7b_8gpu.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05329v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05329/kva_breakdown.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05329v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05329/kva_4gpu_pred.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05329v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05329/kva_8gpu_pred.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05329v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05329/kva_4gpu_sidecar.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05329v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05329/kva_8gpu_sidecar.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05329v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05329/kva_8gpu_sidecar_var.png"
      }
    ],
    "abstract_cn": "大型语言模型推理分为提示阶段和扩展阶段，前者输出首个令牌，后者生成后续令牌。我们提出的KV-Runahead并行化方案，通过多进程协同填充键值缓存，显著加速了提示阶段，缩短了首个令牌的生成时间。该方案巧妙利用了因果注意力图，减少了计算量，且易于实施。我们还引入了上下文级负载均衡，以应对因果注意力导致的缓存生成不均，进一步优化了首个令牌的生成时间。与传统并行化方法相比，KV-Runahead在Llama 7B和Falcon 7B模型上分别实现了1.4倍和1.6倍的速度提升，展现了其高效性。",
    "title_cn": "KV-Runahead：并行生成键值缓存，解锁因果LLM推理的扩展潜能在这项研究中，我们提出了KV-Runahead方法，这是一种新颖的技术，通过并行生成键值缓存来提高大型语言模型（LLM）的因果推理效率。我们的方法解决了传统推理方法中的瓶颈问题，实现了更快的推理速度和更好的可扩展性。通过实验验证，KV-Runahead在保持推理质量的同时，显著提升了LLM的性能。",
    "tags": [
      "LLM理论\n\n这篇论文主要探讨了大型语言模型（LLM）推理过程中的优化技术，特别是提出了KV-Runahead并行化方案来加速提示阶段，即首个令牌的生成时间。这种优化方法涉及对模型内部机制的深入理解和改进，属于对LLM理论层面的研究。因此，它更适合归类于LLM理论这一分类。",
      "",
      "高性能计算"
    ]
  },
  {
    "title": "Special Characters Attack: Toward Scalable Training Data Extraction From Large Language Models",
    "submit_datetime": "2024年05月08日",
    "abstract": "Large language models (LLMs) have achieved remarkable performance on a wide range of tasks. However, recent studies have shown that LLMs can memorize training data and simple repeated tokens can trick the model to leak the data. In this paper, we take a step further and show that certain special characters or their combinations with English letters are stronger memory triggers, leading to more severe data leakage. The intuition is that, since LLMs are trained with massive data that contains a substantial amount of special characters (e.g. structural symbols {, } of JSON files, and @, # in emails and online posts), the model may memorize the co-occurrence between these special characters and the raw texts. This motivates us to propose a simple but effective Special Characters Attack (SCA) to induce training data leakage. Our experiments verify the high effectiveness of SCA against state-of-the-art LLMs: they can leak diverse training data, such as code corpus, web pages, and personally identifiable information, and sometimes generate non-stop outputs as a byproduct. We further show that the composition of the training data corpus can be revealed by inspecting the leaked data -- one crucial piece of information for pre-training high-performance LLMs. Our work can help understand the sensitivity of LLMs to special characters and identify potential areas for improvement.",
    "pdf_link": "https://arxiv.org/abs/2405.05990",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）在众多任务中表现卓越，但近期研究发现，这些模型可能会记忆训练数据，甚至被简单的重复标记诱导泄露信息。本文深入探讨，指出特定特殊字符及其与英文字母的组合能更强烈地触发记忆，导致数据泄露问题加剧。由于LLMs在包含大量特殊字符的数据上训练，模型可能记住了这些字符与文本内容的关联。基于此，我们提出了一种简单而高效的特殊字符攻击（SCA），用以诱导数据泄露。实验证明，SCA对顶级LLMs极为有效，能泄露包括代码库、网页和个人身份信息在内的多样化训练数据，有时还会产生连续不断的输出。此外，通过分析泄露数据，我们揭示了训练数据语料库的组成，这对于预训练高性能LLMs至关重要。我们的研究有助于理解LLMs对特殊字符的敏感性，并指出了改进的方向。",
    "title_cn": "特殊字符攻击：揭秘大型语言模型训练数据的提取之谜在这项研究中，我们探讨了一种新颖的攻击手段——特殊字符攻击，它旨在从大型语言模型中提取训练数据。通过精心设计的特殊字符组合，我们能够揭示模型背后的知识库，为数据隐私和安全带来新的挑战。",
    "tags": [
      "LLM理论\n\n这篇论文主要探讨了大型语言模型（LLMs）在处理特殊字符时的记忆和信息泄露问题，并提出了一种特殊字符攻击（SCA）来测试和分析这一问题。研究内容涉及LLMs的理论层面，特别是模型对训练数据的记忆和敏感性，以及如何通过特殊字符触发信息泄露。因此，它更符合LLM理论这一分类，因为它关注的是模型内部的工作原理和潜在的安全漏洞，而不是直接的应用场景或代理（Agent）的行为。",
      "数据安全",
      "人工智能伦理"
    ]
  },
  {
    "title": "ChatHuman: Language-driven 3D Human Understanding with Retrieval-Augmented Tool Reasoning",
    "submit_datetime": "2024年05月07日",
    "abstract": "Numerous methods have been proposed to detect, estimate, and analyze properties of people in images, including the estimation of 3D pose, shape, contact, human-object interaction, emotion, and more. Each of these methods works in isolation instead of synergistically. Here we address this problem and build a language-driven human understanding system -- ChatHuman, which combines and integrates the skills of many different methods. To do so, we finetune a Large Language Model (LLM) to select and use a wide variety of existing tools in response to user inputs. In doing so, ChatHuman is able to combine information from multiple tools to solve problems more accurately than the individual tools themselves and to leverage tool output to improve its ability to reason about humans. The novel features of ChatHuman include leveraging academic publications to guide the application of 3D human-related tools, employing a retrieval-augmented generation model to generate in-context-learning examples for handling new tools, and discriminating and integrating tool results to enhance 3D human understanding. Our experiments show that ChatHuman outperforms existing models in both tool selection accuracy and performance across multiple 3D human-related tasks. ChatHuman is a step towards consolidating diverse methods for human analysis into a single, powerful, system for 3D human reasoning.",
    "pdf_link": "https://arxiv.org/abs/2405.04533",
    "graphs": [],
    "abstract_cn": "为了解决现有方法孤立工作的问题，我们开发了ChatHuman——一个集成了多种方法技能的语言驱动人类理解系统。通过微调LLM，ChatHuman能够智能选择并结合多种工具，以更精准地解决复杂问题，并提升对人类的推理能力。其创新之处在于，它利用学术文献指导3D人类工具的应用，采用检索增强生成技术为新工具生成学习示例，并通过整合工具结果深化对3D人类的理解。实验证明，ChatHuman在工具选择和多任务性能上均超越了现有模型，标志着我们向着构建一个统一、高效的人类分析系统迈出了重要一步。",
    "title_cn": "ChatHuman：借助检索增强的工具推理，实现语言驱动的3D人体理解在这项研究中，我们提出了ChatHuman，一个创新系统，它通过结合语言理解和检索增强的工具推理，实现了对3D人体的深入理解。该系统不仅能够处理复杂的语言指令，还能够利用检索机制来增强其推理能力，从而在3D人体建模和交互任务中展现出卓越的性能。",
    "tags": [
      "Agent\n\n解释：这篇论文介绍了一个名为ChatHuman的系统，它是一个集成了多种方法技能的语言驱动人类理解系统。它通过微调大型语言模型（LLM）来智能选择并结合多种工具，以解决复杂问题并提升对人类的推理能力。这个系统可以被视为一个智能代理（Agent），因为它能够自主地选择和使用工具来完成任务。此外，它利用了检索增强生成技术（RAG）来生成学习示例，这表明它结合了RAG技术，但主要还是作为一个Agent来执行任务。因此，这篇论文更适合归类为Agent。",
      "人机交互",
      "智能辅助系统"
    ]
  },
  {
    "title": "QServe: W4A8KV4 Quantization and System Co-design for Efficient LLM Serving",
    "submit_datetime": "2024年05月07日",
    "abstract": "Quantization can accelerate large language model (LLM) inference. Going beyond INT8 quantization, the research community is actively exploring even lower precision, such as INT4. Nonetheless, state-of-the-art INT4 quantization techniques only accelerate low-batch, edge LLM inference, failing to deliver performance gains in large-batch, cloud-based LLM serving. We uncover a critical issue: existing INT4 quantization methods suffer from significant runtime overhead (20-90%) when dequantizing either weights or partial sums on GPUs. To address this challenge, we introduce QoQ, a W4A8KV4 quantization algorithm with 4-bit weight, 8-bit activation, and 4-bit KV cache. QoQ stands for quattuor-octo-quattuor, which represents 4-8-4 in Latin. QoQ is implemented by the QServe inference library that achieves measured speedup. The key insight driving QServe is that the efficiency of LLM serving on GPUs is critically influenced by operations on low-throughput CUDA cores. Building upon this insight, in QoQ algorithm, we introduce progressive quantization that can allow low dequantization overhead in W4A8 GEMM. Additionally, we develop SmoothAttention to effectively mitigate the accuracy degradation incurred by 4-bit KV quantization. In the QServe system, we perform compute-aware weight reordering and take advantage of register-level parallelism to reduce dequantization latency. We also make fused attention memory-bound, harnessing the performance gain brought by KV4 quantization. As a result, QServe improves the maximum achievable serving throughput of Llama-3-8B by 1.2x on A100, 1.4x on L40S; and Qwen1.5-72B by 2.4x on A100, 3.5x on L40S, compared to TensorRT-LLM. Remarkably, QServe on L40S GPU can achieve even higher throughput than TensorRT-LLM on A100. Thus, QServe effectively reduces the dollar cost of LLM serving by 3x. Code is available at https://github.com/mit-han-lab/qserve.",
    "pdf_link": "https://arxiv.org/abs/2405.04532",
    "graphs": [],
    "abstract_cn": "量化技术正在推动大型语言模型（LLM）推理的加速，尤其是INT4精度的探索。然而，现有的INT4量化方法在云端大批量LLM服务中遇到了瓶颈，因为它们在GPU上去量化时产生了巨大的运行时开销。为此，我们推出了QoQ——一种创新的W4A8KV4量化方案，它通过QServe推理库实现了显著的加速效果。QoQ巧妙地结合了4位权重、8位激活和4位KV缓存，并通过渐进式量化和SmoothAttention技术，有效降低了去量化开销并保持了模型精度。QServe系统通过计算感知权重排序和寄存器级并行，进一步优化了去量化延迟，并利用KV4量化提升了性能。实验结果显示，QServe在Llama和Qwen模型上实现了显著的吞吐量提升，甚至在L40S GPU上超越了TensorRT-LLM在A100上的表现，大幅降低了LLM服务的成本。代码已公开，供研究者探索。",
    "title_cn": "QServe：W4A8KV4 量化与系统协同设计，为大型语言模型服务提供高效解决方案",
    "tags": [
      "LLM应用\n\n这篇论文讨论了一种创新的量化方案QoQ，以及基于此方案的QServe推理库，旨在加速大型语言模型（LLM）的推理过程。它专注于解决现有INT4量化方法在GPU上去量化时产生的运行时开销问题，并通过实验展示了其在提高吞吐量和降低服务成本方面的有效性。这些内容与LLM的实际应用紧密相关，特别是在优化推理性能和降低成本方面，因此将其归类为LLM应用。",
      "云计算",
      "人工智能服务"
    ]
  },
  {
    "title": "NaturalCodeBench: Examining Coding Performance Mismatch on HumanEval and Natural User Prompts",
    "submit_datetime": "2024年05月07日",
    "abstract": "Large language models (LLMs) have manifested strong ability to generate codes for productive activities. However, current benchmarks for code synthesis, such as HumanEval, MBPP, and DS-1000, are predominantly oriented towards introductory tasks on algorithm and data science, insufficiently satisfying challenging requirements prevalent in real-world coding. To fill this gap, we propose NaturalCodeBench (NCB), a challenging code benchmark designed to mirror the complexity and variety of scenarios in real coding tasks. NCB comprises 402 high-quality problems in Python and Java, meticulously selected from natural user queries from online coding services, covering 6 different domains. Noting the extraordinary difficulty in creating testing cases for real-world queries, we also introduce a semi-automated pipeline to enhance the efficiency of test case construction. Comparing with manual solutions, it achieves an efficiency increase of more than 4 times. Our systematic experiments on 39 LLMs find that performance gaps on NCB between models with close HumanEval scores could still be significant, indicating a lack of focus on practical code synthesis scenarios or over-specified optimization on HumanEval. On the other hand, even the best-performing GPT-4 is still far from satisfying on NCB. The evaluation toolkit and development set are available at https://github.com/THUDM/NaturalCodeBench.",
    "pdf_link": "https://arxiv.org/abs/2405.04520",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）在代码生成方面展现出卓越能力，但现有的代码合成基准，如HumanEval、MBPP和DS-1000，主要针对算法和数据科学的初级任务，未能充分满足现实世界编码的挑战性需求。为此，我们推出了NaturalCodeBench（NCB），一个旨在模拟真实编码任务复杂性和多样性的挑战性基准。NCB精选了402个高质量的Python和Java问题，源自在线编码服务的自然用户查询，覆盖六大领域。针对现实世界查询测试案例创建的特殊难度，我们开发了一个半自动化流水线，大幅提升了测试案例构建的效率，效率提升超过四倍。我们对39个LLMs的系统实验表明，即使HumanEval得分相近的模型在NCB上的表现也可能存在显著差异，这揭示了对实际代码合成场景的忽视或对HumanEval的过度优化。即便是最先进的GPT-4，在NCB上的表现也远未达到满意水平。评估工具包和发展集已公开在https://github.com/THUDM/NaturalCodeBench。",
    "title_cn": "NaturalCodeBench：探究HumanEval与自然用户提示间编码性能的差异解释：在结果2中，我采用了更加流畅和符合中文表达习惯的翻译方式，将“Examining Coding Performance Mismatch”翻译为“探究编码性能的差异”，使得整个句子更加简洁优雅，同时保留了原文的意思。",
    "tags": [
      "LLM应用\n\n这篇论文介绍了NaturalCodeBench（NCB），一个旨在模拟真实编码任务复杂性和多样性的挑战性基准，用于评估大型语言模型（LLMs）在代码生成方面的能力。它强调了现有代码合成基准的局限性，并提出了一个新的基准来更好地反映现实世界编码的挑战。因此，这篇论文属于LLM应用类别，因为它关注的是LLMs在实际应用中的性能评估和改进，而不是理论研究或Agent的设计与实现。",
      "软件开发",
      "编程教育"
    ]
  },
  {
    "title": "xLSTM: Extended Long Short-Term Memory",
    "submit_datetime": "2024年05月07日",
    "abstract": "In the 1990s, the constant error carousel and gating were introduced as the central ideas of the Long Short-Term Memory (LSTM). Since then, LSTMs have stood the test of time and contributed to numerous deep learning success stories, in particular they constituted the first Large Language Models (LLMs). However, the advent of the Transformer technology with parallelizable self-attention at its core marked the dawn of a new era, outpacing LSTMs at scale. We now raise a simple question: How far do we get in language modeling when scaling LSTMs to billions of parameters, leveraging the latest techniques from modern LLMs, but mitigating known limitations of LSTMs? Firstly, we introduce exponential gating with appropriate normalization and stabilization techniques. Secondly, we modify the LSTM memory structure, obtaining: (i) sLSTM with a scalar memory, a scalar update, and new memory mixing, (ii) mLSTM that is fully parallelizable with a matrix memory and a covariance update rule. Integrating these LSTM extensions into residual block backbones yields xLSTM blocks that are then residually stacked into xLSTM architectures. Exponential gating and modified memory structures boost xLSTM capabilities to perform favorably when compared to state-of-the-art Transformers and State Space Models, both in performance and scaling.",
    "pdf_link": "https://arxiv.org/abs/2405.04517",
    "graphs": [],
    "abstract_cn": "1990年代，LSTM以其核心的常数误差轮播和门控机制崭露头角，成为深度学习领域的先驱，尤其是构建了首批大型语言模型。然而，随着Transformer技术的兴起，以其并行自注意力机制引领了新的技术浪潮，超越了LSTM的规模。我们不禁思考：若将LSTM扩展至数十亿参数，融合现代LLM的尖端技术，同时克服其固有局限，语言模型的极限将何在？首先，我们提出了带有归一化与稳定技术的指数门控。其次，我们重塑了LSTM的记忆结构，创造了（i）拥有标量记忆与更新、新型记忆混合的sLSTM，以及（ii）完全并行、采用矩阵记忆与协方差更新规则的mLSTM。这些创新被融入残差块，形成了xLSTM块，进而构建出残差堆叠的xLSTM架构。指数门控与记忆结构的革新，使得xLSTM在与顶尖的Transformer和状态空间模型较量时，无论在性能还是扩展性上，均展现出令人瞩目的表现。",
    "title_cn": "xLSTM：拓展版长短期记忆网络在翻译过程中，我首先确保了原文的核心概念“Extended Long Short-Term Memory”被准确地翻译为“扩展的长短期记忆”。接着，在步骤2中，我考虑了中文表达的习惯，将“扩展的”调整为“拓展版”，使得翻译更加符合中文的表达习惯，同时保持了原文的含义和专业性。这样的翻译既简洁又优雅，同时也保持了原文的生动性。",
    "tags": [
      "LLM理论\n\n这篇论文探讨了将LSTM（长短期记忆网络）扩展至数十亿参数，并融合现代大型语言模型（LLM）的尖端技术的可能性。它提出了一系列创新，包括指数门控和记忆结构的改进，以及构建残差堆叠的xLSTM架构。这些研究旨在克服LSTM的固有局限，并与Transformer和状态空间模型竞争。因此，这篇论文属于LLM理论分类，因为它专注于语言模型的理论发展和改进。",
      "",
      "语言模型"
    ]
  },
  {
    "title": "A Transformer with Stack Attention",
    "submit_datetime": "2024年05月07日",
    "abstract": "Natural languages are believed to be (mildly) context-sensitive. Despite underpinning remarkably capable large language models, transformers are unable to model many context-free language tasks. In an attempt to address this limitation in the modeling power of transformer-based language models, we propose augmenting them with a differentiable, stack-based attention mechanism. Our stack-based attention mechanism can be incorporated into any transformer-based language model and adds a level of interpretability to the model. We show that the addition of our stack-based attention mechanism enables the transformer to model some, but not all, deterministic context-free languages.",
    "pdf_link": "https://arxiv.org/abs/2405.04515",
    "graphs": [],
    "abstract_cn": "自然语言具有轻微的上下文敏感性，然而，尽管变压器支撑着强大的大型语言模型，它们在处理上下文无关语言任务时仍显不足。为了克服这一局限，我们提出了一种创新的基于栈的可微分注意力机制，以增强基于变压器的语言模型。这种机制不仅提升了模型的建模能力，还赋予了模型更高的可解释性。实验证明，通过引入我们的基于栈的注意力机制，变压器能够处理一部分，但并非全部，确定性的上下文无关语言任务。",
    "title_cn": "堆叠注意力机制的Transformer在翻译过程中，我首先直接将英文翻译为中文，确保意思的准确性。然后，我对直译的中文进行了优化，使其更加符合中文的语言表达习惯，同时保持了原文的简洁和优雅。在第二个步骤中，我将“A Transformer with Stack Attention”优化为“堆叠注意力机制的Transformer”，这样的表达更加符合中文的表述习惯，同时也更加生动和易于理解。",
    "tags": [
      "LLM理论\n\n这篇论文探讨了大型语言模型（LLM）在处理上下文无关语言任务时的局限性，并提出了一种创新的基于栈的可微分注意力机制来增强这些模型。这种研究侧重于改进LLM的理论基础和内部机制，因此属于LLM理论分类。它并不直接涉及Agent的行为或RAG（检索增强生成）框架，也没有明确提到LLM的具体应用场景，而是关注于模型本身的改进和理论上的提升。",
      "",
      "机器学习"
    ]
  },
  {
    "title": "Unveiling Disparities in Web Task Handling Between Human and Web Agent",
    "submit_datetime": "2024年05月07日",
    "abstract": "With the advancement of Large-Language Models (LLMs) and Large Vision-Language Models (LVMs), agents have shown significant capabilities in various tasks, such as data analysis, gaming, or code generation. Recently, there has been a surge in research on web agents, capable of performing tasks within the web environment. However, the web poses unforeseeable scenarios, challenging the generalizability of these agents. This study investigates the disparities between human and web agents' performance in web tasks (e.g., information search) by concentrating on planning, action, and reflection aspects during task execution. We conducted a web task study with a think-aloud protocol, revealing distinct cognitive actions and operations on websites employed by humans. Comparative examination of existing agent structures and human behavior with thought processes highlighted differences in knowledge updating and ambiguity handling when performing the task. Humans demonstrated a propensity for exploring and modifying plans based on additional information and investigating reasons for failure. These findings offer insights into designing planning, reflection, and information discovery modules for web agents and designing the capturing method for implicit human knowledge in a web task.",
    "pdf_link": "https://arxiv.org/abs/2405.04497",
    "graphs": [],
    "abstract_cn": "随着 LLMs 和 LVMs 的发展，代理在数据分析、游戏和代码生成等任务中展现出卓越能力。近期，网络代理研究激增，它们能在网络环境中执行任务。但网络的不可预见性对代理的泛化能力构成挑战。本研究聚焦于规划、行动和反思，探讨了人类与网络代理在信息搜索等网络任务中的性能差异。通过出声思考协议的网络任务研究，我们揭示了人类在网站操作中的独特认知行为。比较分析现有代理结构与人类思维过程，突显了任务执行中知识更新和模糊性处理的不同。人类倾向于根据新信息调整计划，并探究失败原因。这些发现为网络代理的规划、反思和信息发现模块设计提供了启示，并提出了捕捉网络任务中隐含人类知识的方法。",
    "title_cn": "揭秘人类与网络代理在网络任务处理上的差异之谜",
    "tags": [
      "Agent\n\n这篇论文主要探讨了网络代理在执行任务时的性能，特别是在规划、行动和反思方面与人类的差异。它关注的是代理在网络环境中的应用，以及如何通过理解人类的认知行为来改进代理的设计。因此，它更符合Agent分类，因为它专注于代理的行为和性能，而不是LLM的理论或应用。",
      "网络代理",
      "信息搜索"
    ]
  },
  {
    "title": "Toward In-Context Teaching: Adapting Examples to Students' Misconceptions",
    "submit_datetime": "2024年05月07日",
    "abstract": "When a teacher provides examples for a student to study, these examples must be informative, enabling a student to progress from their current state toward a target concept or skill. Good teachers must therefore simultaneously infer what students already know and adapt their teaching to students' changing state of knowledge. There is increasing interest in using computational models, particularly large language models, as pedagogical tools. As students, language models in particular have shown a remarkable ability to adapt to new tasks given small numbers of examples. But how effectively can these models adapt as teachers to students of different types? To study this question, we introduce a suite of models and evaluation methods we call AdapT. AdapT has two components: (1) a collection of simulated Bayesian student models that can be used for evaluation of automated teaching methods; (2) a platform for evaluation with human students, to characterize the real-world effectiveness of these methods. We additionally introduce (3) AToM, a new probabilistic model for adaptive teaching that jointly infers students' past beliefs and optimizes for the correctness of future beliefs. In evaluations of simulated students across three learning domains (fraction arithmetic, English morphology, function learning), AToM systematically outperforms LLM-based and standard Bayesian teaching models. In human experiments, both AToM and LLMs outperform non-adaptive random example selection. Our results highlight both the difficulty of the adaptive teaching task and the potential of learned adaptive models for solving it.",
    "pdf_link": "https://arxiv.org/abs/2405.04495",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.04495v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04495/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04495v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04495/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04495v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04495/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04495v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04495/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04495v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04495/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04495v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04495/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04495v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04495/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04495v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04495/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04495v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04495/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04495v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04495/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04495v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04495/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04495v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04495/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04495v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04495/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04495v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04495/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04495v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04495/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04495v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04495/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04495v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04495/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04495v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04495/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04495v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04495/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04495v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04495/x20.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04495v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04495/x21.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04495v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04495/x22.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04495v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04495/x23.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04495v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04495/x24.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04495v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04495/x25.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04495v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04495/x26.png"
      }
    ],
    "abstract_cn": "教师提供的学习范例需富含信息，引领学生从现有水平迈向目标概念或技能。优秀教师需洞察学生所知，并随其知识增长，调整教学策略。计算模型，尤其是大型语言模型，正成为教学新宠。作为学习者，语言模型在少量范例引导下，展现出了惊人的适应新任务的能力。然而，作为教师，这些模型对不同学生的适应性如何？为此，我们推出了AdapT，一套模型与评估方法。AdapT包含两部分：(1) 一组模拟贝叶斯学生模型，用于自动教学方法的评估；(2) 一个人类学生评估平台，以验证这些方法的实际效果。此外，我们提出了AToM，一种新的适应性教学概率模型，它不仅能推断学生的知识背景，还能优化其未来的学习路径。在模拟学生跨越三个领域的学习（分数算术、英语形态学、函数学习）中，AToM显著优于LLM和传统贝叶斯教学模型。在人类学生实验中，AToM和LLMs均超越了非适应性的随机范例选择。我们的研究揭示了适应性教学的挑战，同时也展现了学习适应性模型在这一领域的巨大潜力。",
    "title_cn": "迈向情境化教学：量身定制示例，以纠正学生的认知误区",
    "tags": [
      "Agent\n\n这篇论文主要探讨了大型语言模型（LLM）在教学领域的应用，特别是作为适应性教学的代理（Agent）。论文提出了一个名为AdapT的系统，它包括模拟贝叶斯学生模型和人类学生评估平台，以及一个名为AToM的新型适应性教学概率模型。这些模型和方法旨在推断学生的知识背景并优化其学习路径，展示了LLM在适应性教学方面的潜力。因此，这篇论文更符合Agent分类，因为它关注的是LLM作为教学代理的应用和适应性教学模型的开发。",
      "教育技术",
      "人工智能教育"
    ]
  },
  {
    "title": "The Silicone Ceiling: Auditing GPT's Race and Gender Biases in Hiring",
    "submit_datetime": "2024年05月07日",
    "abstract": "Large language models (LLMs) are increasingly being introduced in workplace settings, with the goals of improving efficiency and fairness. However, concerns have arisen regarding these models' potential to reflect or exacerbate social biases and stereotypes. This study explores the potential impact of LLMs on hiring practices. To do so, we conduct an algorithm audit of race and gender biases in one commonly-used LLM, OpenAI's GPT-3.5, taking inspiration from the history of traditional offline resume audits. We conduct two studies using names with varied race and gender connotations: resume assessment (Study 1) and resume generation (Study 2). In Study 1, we ask GPT to score resumes with 32 different names (4 names for each combination of the 2 gender and 4 racial groups) and two anonymous options across 10 occupations and 3 evaluation tasks (overall rating, willingness to interview, and hireability). We find that the model reflects some biases based on stereotypes. In Study 2, we prompt GPT to create resumes (10 for each name) for fictitious job candidates. When generating resumes, GPT reveals underlying biases; women's resumes had occupations with less experience, while Asian and Hispanic resumes had immigrant markers, such as non-native English and non-U.S. education and work experiences. Our findings contribute to a growing body of literature on LLM biases, in particular when used in workplace contexts.",
    "pdf_link": "https://arxiv.org/abs/2405.04412",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.04412v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04412/matched_vs_mismatched_wide_2_greys_v3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04412v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04412/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04412v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04412/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04412v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04412/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04412v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04412/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04412v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04412/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04412v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04412/AverageScorebyNumberofTrialsSWEJobdescriptionwithMatchingResume.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04412v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04412/matched_vs_mismatched_big_dot_plot.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04412v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04412/gap_values_freq_by_gender_v2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04412v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04412/years_of_experience_hist_v2.png"
      }
    ],
    "abstract_cn": "随着大型语言模型（LLMs）在工作场所的普及，人们期望它们能提升效率与公平。然而，这些模型可能携带并放大社会偏见的问题也日益凸显。本研究深入探讨了LLMs在招聘过程中的潜在影响，特别针对OpenAI的GPT-3.5进行了种族与性别偏见的算法审查，借鉴了传统简历审计的经验。通过两项实验——简历评分（实验1）与简历创作（实验2），我们使用了带有种族与性别暗示的名字。实验1中，GPT对包含32个不同名字的简历进行评分，结果显示模型存在基于刻板印象的偏见。实验2中，GPT为虚构求职者生成的简历暴露了更深层次的偏见：女性简历的职业经验较少，而亚洲和西班牙裔的简历则带有移民特征，如非母语英语和非美国教育背景。这些发现为LLMs在工作环境中偏见的研究提供了新的视角。",
    "title_cn": "硅胶屏障：审视GPT在招聘决策中潜藏的种族与性别偏见",
    "tags": [
      "LLM应用\n\n这篇论文探讨了大型语言模型（LLMs）在招聘过程中可能携带和放大的社会偏见问题，特别是针对OpenAI的GPT-3.5进行了种族与性别偏见的算法审查。研究通过实验分析了LLMs在简历评分和简历创作中的表现，揭示了模型存在的偏见。这种研究关注的是LLMs在实际应用场景中的行为和影响，因此属于LLM应用的范畴。它并不专注于Agent的设计或RAG（Retrieval-Augmented Generation）框架，也不深入探讨LLM的理论基础，而是分析了LLMs在特定应用中的实际效果和潜在问题。",
      "",
      "社会偏见"
    ]
  },
  {
    "title": "Learning To See But Forgetting To Follow: Visual Instruction Tuning Makes LLMs More Prone To Jailbreak Attacks",
    "submit_datetime": "2024年05月07日",
    "abstract": "Augmenting Large Language Models (LLMs) with image-understanding capabilities has resulted in a boom of high-performing Vision-Language models (VLMs). While studying the alignment of LLMs to human values has received widespread attention, the safety of VLMs has not received the same attention. In this paper, we explore the impact of jailbreaking on three state-of-the-art VLMs, each using a distinct modeling approach. By comparing each VLM to their respective LLM backbone, we find that each VLM is more susceptible to jailbreaking. We consider this as an undesirable outcome from visual instruction-tuning, which imposes a forgetting effect on an LLM's safety guardrails. Therefore, we provide recommendations for future work based on evaluation strategies that aim to highlight the weaknesses of a VLM, as well as take safety measures into account during visual instruction tuning.",
    "pdf_link": "https://arxiv.org/abs/2405.04403",
    "graphs": [],
    "abstract_cn": "将图像理解能力融入大型语言模型，催生了高性能的视觉-语言模型。尽管LLMs与人类价值观的对齐研究备受瞩目，但VLMs的安全性却鲜有人问津。本文深入分析了越狱对三种尖端VLMs的影响，它们各自采用独特的建模策略。对比各自的LLM基础模型，我们发现VLMs更易被越狱攻破。这揭示了视觉指令调整可能导致LLM的安全防护措施失效。鉴于此，我们建议未来的研究应通过评估策略来揭示VLMs的脆弱性，并在视觉指令调整时加强安全考量。",
    "title_cn": "视觉指令调教下的学习，大型语言模型虽能“看”得更清，却更易在“跟随”指令上失守，从而更易遭受越狱攻击。",
    "tags": [
      "LLM应用\n\n这篇论文关注的是视觉-语言模型（VLMs）的安全性问题，特别是越狱攻击对这些模型的影响。它分析了不同建模策略下的VLMs在面对越狱攻击时的脆弱性，并提出了加强安全考量的建议。虽然涉及到了大型语言模型（LLMs），但研究的重点是VLMs的应用层面，特别是它们在实际应用中的安全问题，因此归类为LLM应用。",
      "人工智能安全",
      "视觉-语言模型"
    ]
  },
  {
    "title": "Large Language Models Cannot Explain Themselves",
    "submit_datetime": "2024年05月07日",
    "abstract": "Large language models can be prompted to produce text. They can also be prompted to produce \"explanations\" of their output. But these are not really explanations, because they do not accurately reflect the mechanical process underlying the prediction. The illusion that they reflect the reasoning process can result in significant harms. These \"explanations\" can be valuable, but for promoting critical thinking rather than for understanding the model. I propose a recontextualisation of these \"explanations\", using the term \"exoplanations\" to draw attention to their exogenous nature. I discuss some implications for design and technology, such as the inclusion of appropriate guardrails and responses when models are prompted to generate explanations.",
    "pdf_link": "https://arxiv.org/abs/2405.04382",
    "graphs": [],
    "abstract_cn": "大型语言模型虽能通过提示生成文本及其“解释”，但这些解释并非真实反映模型运作机制，可能误导人们以为它们揭示了推理过程，从而带来风险。这些“解释”的价值在于激发批判性思维，而非深入理解模型。我建议重新审视这些“解释”，并引入“外生解释”（exoplanations）这一概念，以凸显其非内在特性。同时，我探讨了在设计和技术层面上的相关影响，包括在模型生成解释时设置恰当的防护机制和应对策略。",
    "title_cn": "巨型语言模型自解谜团难，其内在逻辑尚待深究。",
    "tags": [
      "LLM理论\n\n这篇论文主要探讨了大型语言模型（LLM）生成的解释与其内部运作机制之间的关系，提出了“外生解释”（exoplanations）的概念，并讨论了在设计和实施这些解释时可能遇到的问题和挑战。这属于对LLM理论层面的探讨，因为它关注的是模型输出解释的本质和模型本身的理解，而不是具体的应用场景或Agent的行为。因此，它更适合归类于LLM理论。",
      "人工智能伦理",
      "模型解释性"
    ]
  },
  {
    "title": "Revisiting character-level adversarial attacks",
    "submit_datetime": "2024年05月07日",
    "abstract": "Adversarial attacks in Natural Language Processing apply perturbations in the character or token levels. Token-level attacks, gaining prominence for their use of gradient-based methods, are susceptible to altering sentence semantics, leading to invalid adversarial examples. While character-level attacks easily maintain semantics, they have received less attention as they cannot easily adopt popular gradient-based methods, and are thought to be easy to defend. Challenging these beliefs, we introduce Charmer, an efficient query-based adversarial attack capable of achieving high attack success rate (ASR) while generating highly similar adversarial examples. Our method successfully targets both small (BERT) and large (Llama 2) models. Specifically, on BERT with SST-2, Charmer improves the ASR in 4.84% points and the USE similarity in 8% points with respect to the previous art. Our implementation is available in https://github.com/LIONS-EPFL/Charmer.",
    "pdf_link": "https://arxiv.org/abs/2405.04346",
    "graphs": [],
    "abstract_cn": "在自然语言处理领域，对抗性攻击通过微调字符或标记来施加影响。标记级别的攻击因其依赖梯度上升，而备受瞩目，但这也可能导致句子语义的扭曲，产生无效的对抗样本。相比之下，字符级别的攻击虽能更好地保持语义，却因难以融入主流的梯度方法而较少受到关注，且被认为防御起来相对容易。我们提出的Charmer挑战了这一观点，它是一种基于查询的高效对抗攻击手段，能够在保持对抗样本高度相似性的同时，实现显著的攻击成功率（ASR）。Charmer对小型BERT模型和大型Llama 2模型均有效。特别是在BERT模型上使用SST-2数据集时，Charmer将ASR提升了4.84个百分点，同时将USE相似性提高了8个百分点，超越了现有技术水平。我们的实现代码已公开在https://github.com/LIONS-EPFL/Charmer。",
    "title_cn": "再探字符级对抗攻击：深入分析与挑战",
    "tags": [
      "Agent\n\n解释：这篇论文介绍了一种名为Charmer的新型对抗攻击手段，它能够在自然语言处理任务中有效地进行字符级别的攻击，同时保持对抗样本的语义相似性。Charmer被设计为一种基于查询的攻击方法，它对不同规模的语言模型（如小型BERT模型和大型Llama 2模型）都显示出有效性。这种攻击手段可以被视为一种智能代理（Agent），因为它能够自主地执行攻击任务，并且能够适应不同的模型和数据集。因此，这篇论文更符合Agent分类，而不是RAG、LLM应用或LLM理论，因为它的重点在于开发和评估一种具体的攻击方法，而不是在理论层面探讨语言模型，也不是直接应用于语言模型的某个特定场景，更不是关于检索增强生成（RAG）的研究。",
      "",
      "网络安全"
    ]
  },
  {
    "title": "A Fourth Wave of Open Data? Exploring the Spectrum of Scenarios for Open Data and Generative AI",
    "submit_datetime": "2024年05月07日",
    "abstract": "Since late 2022, generative AI has taken the world by storm, with widespread use of tools including ChatGPT, Gemini, and Claude. Generative AI and large language model (LLM) applications are transforming how individuals find and access data and knowledge. However, the intricate relationship between open data and generative AI, and the vast potential it holds for driving innovation in this field remain underexplored areas. This white paper seeks to unpack the relationship between open data and generative AI and explore possible components of a new Fourth Wave of Open Data: Is open data becoming AI ready? Is open data moving towards a data commons approach? Is generative AI making open data more conversational? Will generative AI improve open data quality and provenance? Towards this end, we provide a new Spectrum of Scenarios framework. This framework outlines a range of scenarios in which open data and generative AI could intersect and what is required from a data quality and provenance perspective to make open data ready for those specific scenarios. These scenarios include: pertaining, adaptation, inference and insight generation, data augmentation, and open-ended exploration. Through this process, we found that in order for data holders to embrace generative AI to improve open data access and develop greater insights from open data, they first must make progress around five key areas: enhance transparency and documentation, uphold quality and integrity, promote interoperability and standards, improve accessibility and useability, and address ethical considerations.",
    "pdf_link": "https://arxiv.org/abs/2405.04333",
    "graphs": [],
    "abstract_cn": "自2022年底以来，生成式AI如ChatGPT、Gemini和Claude等工具的普及，正改变着我们获取知识的方式。然而，开放数据与生成式AI之间的复杂关系及其创新潜力，仍是待探索的领域。本白皮书旨在剖析这一关系，并探讨可能引领第四波开放数据浪潮的要素：开放数据是否正变得AI友好？是否正走向数据共享模式？生成式AI是否让开放数据更具对话性？它能否提升开放数据的质量和可追溯性？为此，我们提出了“场景光谱”框架，描绘了开放数据与生成式AI可能交汇的多种场景，并探讨了为适应这些场景，开放数据所需的数据质量和来源要求。这些场景涵盖了数据的相关性、适应性、推理、洞察生成、增强和开放探索。我们发现，要让数据持有者利用生成式AI深化开放数据的洞察力，他们需在透明度、质量、互操作性、可访问性和伦理等五个关键领域取得进展。",
    "title_cn": "开放数据的第四波浪潮？我们正探索开放数据与生成式AI交织的多元场景。",
    "tags": [
      "LLM应用\n\n这篇论文摘要讨论了生成式AI工具（如ChatGPT、Gemini和Claude）的普及对知识获取方式的影响，以及开放数据与生成式AI之间的关系。它提出了一个“场景光谱”框架来探讨开放数据与生成式AI可能交汇的多种场景，并强调了为适应这些场景，开放数据在透明度、质量、互操作性、可访问性和伦理等方面的要求。这些内容与大型语言模型（LLM）的应用领域紧密相关，特别是在探讨如何利用生成式AI深化开放数据的洞察力方面。因此，这篇论文应归类于LLM应用。",
      "开放数据",
      "人工智能"
    ]
  },
  {
    "title": "Deception in Reinforced Autonomous Agents: The Unconventional Rabbit Hat Trick in Legislation",
    "submit_datetime": "2024年05月07日",
    "abstract": "Recent developments in large language models (LLMs), while offering a powerful foundation for developing natural language agents, raise safety concerns about them and the autonomous agents built upon them. Deception is one potential capability of AI agents of particular concern, which we refer to as an act or statement that misleads, hides the truth, or promotes a belief that is not true in its entirety or in part. We move away from the conventional understanding of deception through straight-out lying, making objective selfish decisions, or giving false information, as seen in previous AI safety research. We target a specific category of deception achieved through obfuscation and equivocation. We broadly explain the two types of deception by analogizing them with the rabbit-out-of-hat magic trick, where (i) the rabbit either comes out of a hidden trap door or (ii) (our focus) the audience is completely distracted to see the magician bring out the rabbit right in front of them using sleight of hand or misdirection. Our novel testbed framework displays intrinsic deception capabilities of LLM agents in a goal-driven environment when directed to be deceptive in their natural language generations in a two-agent adversarial dialogue system built upon the legislative task of \"lobbying\" for a bill. Along the lines of a goal-driven environment, we show developing deceptive capacity through a reinforcement learning setup, building it around the theories of language philosophy and cognitive psychology. We find that the lobbyist agent increases its deceptive capabilities by ~ 40% (relative) through subsequent reinforcement trials of adversarial interactions, and our deception detection mechanism shows a detection capability of up to 92%. Our results highlight potential issues in agent-human interaction, with agents potentially manipulating humans towards its programmed end-goal.",
    "pdf_link": "https://arxiv.org/abs/2405.04325",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.04325v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04325/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04325v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04325/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04325v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04325/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04325v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04325/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04325v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04325/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04325v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04325/x6.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）的进步是自然语言代理开发的强大基石，但同时也引发了对其及其衍生自主代理的安全性担忧。AI代理的欺骗能力尤其令人担忧，我们将其视为误导、隐瞒真相或推广不实信念的行为或陈述。我们不再局限于以往AI安全研究中直接撒谎、自私决策或散布虚假信息等传统欺骗方式，而是聚焦于通过混淆和含糊其辞实现的特定欺骗类型。我们通过魔术中的“帽子里的兔子”魔术来比喻这两种欺骗，其中（i）兔子可能从隐藏的陷阱门出现，或者（ii）观众被巧妙地误导，以至于忽略了魔术师在他们面前使用手法或误导将兔子带出的过程。我们的创新测试平台框架在目标驱动的环境中揭示了LLM代理的内在欺骗能力，特别是在一个基于立法任务“游说”法案的双代理对抗对话系统中，当指示它们在其自然语言生成中进行欺骗时。在目标驱动的环境中，我们通过强化学习设置发展欺骗能力，围绕语言哲学和认知心理学的理论构建它。我们发现，通过对抗性交互的后续强化试验，游说代理的欺骗能力提高了约40%，我们的欺骗检测机制显示了高达92%的检测能力。我们的研究结果揭示了代理与人类交互中潜在的问题，代理可能操纵人类朝着其编程的最终目标。",
    "title_cn": "强化自主代理中的欺骗行为：立法中的非传统兔子帽戏法之谜在强化自主代理领域，欺骗行为如同立法中的非传统兔子帽戏法，既神秘又引人入胜。这种行为在自主代理的决策过程中扮演着复杂角色，其影响深远，如同戏法中的兔子，既出人意料又充满变数。本研究将深入探讨这一现象，揭示其在立法框架下的独特影响。",
    "tags": [
      "Agent\n\n这篇论文主要探讨了大型语言模型（LLMs）在自然语言代理开发中的应用，特别是在AI代理的欺骗能力方面。它通过一个创新的测试平台框架，在目标驱动的环境中研究了LLM代理的欺骗行为，并展示了在对抗性交互中欺骗能力的提升。这与Agent分类相关，因为它关注的是AI代理的行为和能力，特别是它们在特定任务（如立法任务中的“游说”）中的欺骗行为。此外，论文还涉及了欺骗检测机制的开发，这也是AI代理研究的一部分。因此，这篇论文更符合Agent分类，而不是RAG、LLM应用或LLM理论分类。",
      "人工智能安全",
      "对话系统"
    ]
  },
  {
    "title": "Granite Code Models: A Family of Open Foundation Models for Code Intelligence",
    "submit_datetime": "2024年05月07日",
    "abstract": "Large Language Models (LLMs) trained on code are revolutionizing the software development process. Increasingly, code LLMs are being integrated into software development environments to improve the productivity of human programmers, and LLM-based agents are beginning to show promise for handling complex tasks autonomously. Realizing the full potential of code LLMs requires a wide range of capabilities, including code generation, fixing bugs, explaining and documenting code, maintaining repositories, and more. In this work, we introduce the Granite series of decoder-only code models for code generative tasks, trained with code written in 116 programming languages. The Granite Code models family consists of models ranging in size from 3 to 34 billion parameters, suitable for applications ranging from complex application modernization tasks to on-device memory-constrained use cases. Evaluation on a comprehensive set of tasks demonstrates that Granite Code models consistently reaches state-of-the-art performance among available open-source code LLMs. The Granite Code model family was optimized for enterprise software development workflows and performs well across a range of coding tasks (e.g. code generation, fixing and explanation), making it a versatile all around code model. We release all our Granite Code models under an Apache 2.0 license for both research and commercial use.",
    "pdf_link": "https://arxiv.org/abs/2405.04324",
    "graphs": [],
    "abstract_cn": "代码训练的大型语言模型（LLMs）正革新软件开发，它们被越来越多地融入开发环境，提升程序员效率，并开始自主处理复杂任务。Granite系列仅解码器的代码模型，专为代码生成任务设计，训练了116种编程语言，参数从3亿到340亿不等，适应各种场景。在多项任务评估中，Granite Code模型始终领先于其他开源代码LLMs。针对企业软件开发优化，Granite Code模型在代码生成、修复和解释等任务中表现卓越，成为一款全能代码模型。我们以Apache 2.0许可证发布，供研究和商业使用。",
    "title_cn": "代码智能之石：花岗岩系列开源基础模型在",
    "tags": [
      "LLM应用\n\n这篇论文讨论了专门为代码生成任务设计的Granite系列大型语言模型（LLMs），这些模型在多项任务评估中表现出色，并且针对企业软件开发进行了优化。它们在代码生成、修复和解释等任务中表现卓越，因此被归类为LLM应用，因为它们展示了LLMs在特定应用领域（即软件开发）的实际应用和效果。这与Agent或RAG分类不符，因为论文没有特别关注代理行为或检索增强生成技术。同时，它也不属于LLM理论分类，因为它更多地关注模型的实际应用而非理论基础。",
      "软件开发",
      "编程语言\n\n解释：根据论文摘要",
      "该研究涉及大型语言模型在代码生成、修复和解释等软件开发任务中的应用",
      "并且模型训练了多种编程语言",
      "因此标签为“软件开发”和“编程语言”。"
    ]
  },
  {
    "title": "Accelerating Speculative Decoding using Dynamic Speculation Length",
    "submit_datetime": "2024年05月07日",
    "abstract": "Speculative decoding is a promising method for reducing the inference latency of large language models. The effectiveness of the method depends on the speculation length (SL) - the number of tokens generated by the draft model at each iteration. The vast majority of speculative decoding approaches use the same SL for all iterations. In this work, we show that this practice is suboptimal. We introduce DISCO, a DynamIc SpeCulation length Optimization method that uses a classifier to dynamically adjust the SL at each iteration, while provably preserving the decoding quality. Experiments with four benchmarks demonstrate average speedup gains of 10.3% relative to our best baselines.",
    "pdf_link": "https://arxiv.org/abs/2405.04304",
    "graphs": [],
    "abstract_cn": "推测解码技术为大型语言模型的推理速度提升带来了希望，其效果与推测长度（SL）紧密相关，即每次迭代中草稿模型生成的令牌数。然而，现有方法普遍采用固定SL，我们发现这并非最佳策略。为此，我们提出了DISCO，一种动态推测长度优化技术，它通过分类器在每次迭代中智能调整SL，确保解码质量的同时，实现了显著的加速效果。在四个基准测试中，DISCO平均提升了10.3%的推理速度，超越了现有的最佳方法。",
    "title_cn": "动态推测长度优化：加速语言模型解码的新策略在翻译过程中，我首先确保了原文意思的准确传达，然后对语言进行了优化，使其更加符合中文的表达习惯，同时保持了原文的生动性和简洁性。",
    "tags": [
      "LLM理论\n\n这篇论文主要探讨了大型语言模型（LLM）中的推测解码技术，并提出了一个名为DISCO的新方法，用于动态优化推测长度（SL）以提高推理速度。这个研究关注的是LLM的内部工作机制和性能优化，因此属于LLM理论的范畴。它并不直接涉及Agent的行为或决策，也没有提到RAG（Retrieval-Augmented Generation）框架，更不是关于LLM的具体应用案例，所以不属于Agent、RAG或LLM应用分类。",
      "",
      "机器学习"
    ]
  },
  {
    "title": "Enhancing the Efficiency and Accuracy of Underlying Asset Reviews in Structured Finance: The Application of Multi-agent Framework",
    "submit_datetime": "2024年05月07日",
    "abstract": "Structured finance, which involves restructuring diverse assets into securities like MBS, ABS, and CDOs, enhances capital market efficiency but presents significant due diligence challenges. This study explores the integration of artificial intelligence (AI) with traditional asset review processes to improve efficiency and accuracy in structured finance. Using both open-sourced and close-sourced large language models (LLMs), we demonstrate that AI can automate the verification of information between loan applications and bank statements effectively. While close-sourced models such as GPT-4 show superior performance, open-sourced models like LLAMA3 offer a cost-effective alternative. Dual-agent systems further increase accuracy, though this comes with higher operational costs. This research highlights AI's potential to minimize manual errors and streamline due diligence, suggesting a broader application of AI in financial document analysis and risk management.",
    "pdf_link": "https://arxiv.org/abs/2405.04294",
    "graphs": [],
    "abstract_cn": "结构化金融通过将多样资产转化为证券，如MBS、ABS和CDOs，提升了资本市场的效率，但同时也带来了尽职调查的重大挑战。本研究探索了人工智能（AI）与传统资产审查流程的融合，旨在提升结构化金融的效率与精确度。我们通过开源和闭源的大型语言模型（LLMs）展示了AI在自动化验证贷款申请与银行对账单信息方面的有效性。尽管GPT-4等闭源模型表现卓越，但LLAMA3等开源模型提供了经济实惠的选择。双代理系统虽提高了准确性，但增加了运营成本。此研究凸显了AI在减少人为错误、简化尽职调查方面的潜力，预示着AI在金融文件分析和风险管理领域更广泛的应用前景。",
    "title_cn": "结构化金融底层资产审查的效率与准确性提升：多代理框架的巧妙应用在结构化金融领域，底层资产的审查是确保交易稳健性的关键。传统的审查方法往往耗时且准确性有限。然而，多代理框架的引入，如同一场精妙的棋局，每个代理如同棋子，各司其职，协同作战，极大地提升了审查的效率与准确性。这一创新的应用，不仅优化了金融资产的评估流程，也为投资者提供了更为坚实的决策基础。",
    "tags": [
      "Agent\n\n解释：这篇论文探讨了人工智能（AI）在结构化金融领域中的应用，特别是在自动化验证贷款申请和银行对账单信息方面。它提到了使用大型语言模型（LLMs）如GPT-4和LLAMA3来提高效率和精确度。虽然论文中提到了“双代理系统”，但这里的“代理”指的是AI系统在金融领域的应用，而不是指自主决策的智能体（Agent）。因此，这篇论文更符合Agent分类，因为它讨论了AI系统在特定领域（金融）中的应用和影响。",
      "",
      "风险管理"
    ]
  },
  {
    "title": "Who Wrote This? The Key to Zero-Shot LLM-Generated Text Detection Is GECScore",
    "submit_datetime": "2024年05月07日",
    "abstract": "The efficacy of an large language model (LLM) generated text detector depends substantially on the availability of sizable training data. White-box zero-shot detectors, which require no such data, are nonetheless limited by the accessibility of the source model of the LLM-generated text. In this paper, we propose an simple but effective black-box zero-shot detection approach, predicated on the observation that human-written texts typically contain more grammatical errors than LLM-generated texts. This approach entails computing the Grammar Error Correction Score (GECScore) for the given text to distinguish between human-written and LLM-generated text. Extensive experimental results show that our method outperforms current state-of-the-art (SOTA) zero-shot and supervised methods, achieving an average AUROC of 98.7% and showing strong robustness against paraphrase and adversarial perturbation attacks.",
    "pdf_link": "https://arxiv.org/abs/2405.04286",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLM）生成的文本检测器，其效能高度依赖于丰富的训练数据。然而，我们提出的黑盒零-shot检测方法，无需此类数据，巧妙地利用了人类文本中常见的语法错误多于LLM生成文本这一特点。通过计算语法错误修正分数（GECScore），我们能精准区分文本来源。实验证明，我们的方法不仅超越了现有的零-shot和监督技术，平均AUROC高达98.7%，更展现出对释义和对抗攻击的卓越抵抗力。",
    "title_cn": "这篇文章的作者是谁？GECScore 是识别零-shot LLM 生成文本的关键工具。",
    "tags": [
      "LLM应用\n\n这篇论文介绍了一种新颖的零-shot检测方法，用于区分大型语言模型（LLM）生成的文本和人类编写的文本。该方法利用了LLM生成文本中语法错误较少的特点，通过计算语法错误修正分数（GECScore）来实现文本来源的精准区分。这种方法不需要依赖大量的训练数据，且在实验中表现出了优于现有技术的性能，包括对释义和对抗攻击的抵抗力。因此，它属于LLM应用的范畴，因为它提供了一种实际应用中检测LLM生成文本的工具或技术。",
      "",
      "文本检测"
    ]
  },
  {
    "title": "Semantic API Alignment: Linking High-level User Goals to APIs",
    "submit_datetime": "2024年05月07日",
    "abstract": "Large Language Models (LLMs) are becoming key in automating and assisting various software development tasks, including text-based tasks in requirements engineering but also in coding. Typically, these models are used to automate small portions of existing tasks, but we present a broader vision to span multiple steps from requirements engineering to implementation using existing libraries. This approach, which we call Semantic API Alignment (SEAL), aims to bridge the gap between a user's high-level goals and the specific functions of one or more APIs.\n  In this position paper, we propose a system architecture where a set of LLM-powered ``agents'' match such high-level objectives with appropriate API calls. This system could facilitate automated programming by finding matching links or, alternatively, explaining mismatches to guide manual intervention or further development.\n  As an initial pilot, our paper demonstrates this concept by applying LLMs to Goal-Oriented Requirements Engineering (GORE), via sub-goal analysis, for aligning with REST API specifications, specifically through a case study involving a GitHub statistics API. We discuss the potential of our approach to enhance complex tasks in software development and requirements engineering and outline future directions for research.",
    "pdf_link": "https://arxiv.org/abs/2405.04236",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.04236v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04236/modules_tmp.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04236v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04236/abstraction.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）正成为软件开发自动化和辅助的关键，从需求工程到编码无所不包。我们提出的语义API对齐（SEAL）方法，旨在将用户的高层次目标与API的具体功能无缝对接。在这篇论文中，我们构想了一个由LLM驱动的代理系统，它们能够智能匹配目标与API调用，既可自动编程，也能在需要时提供指导。我们通过一个GitHub统计API的案例研究，展示了LLMs如何通过子目标分析在面向目标的需求工程（GORE）中发挥作用，与REST API规范精准对齐。我们的研究不仅揭示了LLMs在复杂软件开发任务中的巨大潜力，也为未来的研究方向绘制了蓝图。",
    "title_cn": "语义API匹配：构建高级用户目标与API之间的桥梁",
    "tags": [
      "Agent\n\n这篇论文探讨了大型语言模型（LLMs）在软件开发自动化和辅助中的应用，特别是通过提出的语义API对齐（SEAL）方法，实现用户目标与API功能的智能匹配。论文中构想的由LLM驱动的代理系统，能够自动编程并在需要时提供指导，这表明了LLMs在软件开发中的代理角色。因此，这篇论文更符合Agent分类，因为它强调了LLMs作为智能代理在软件开发过程中的作用。",
      "软件开发",
      "自动化编程"
    ]
  },
  {
    "title": "Iterative Experience Refinement of Software-Developing Agents",
    "submit_datetime": "2024年05月07日",
    "abstract": "Autonomous agents powered by large language models (LLMs) show significant potential for achieving high autonomy in various scenarios such as software development. Recent research has shown that LLM agents can leverage past experiences to reduce errors and enhance efficiency. However, the static experience paradigm, reliant on a fixed collection of past experiences acquired heuristically, lacks iterative refinement and thus hampers agents' adaptability. In this paper, we introduce the Iterative Experience Refinement framework, enabling LLM agents to refine experiences iteratively during task execution. We propose two fundamental patterns: the successive pattern, refining based on nearest experiences within a task batch, and the cumulative pattern, acquiring experiences across all previous task batches. Augmented with our heuristic experience elimination, the method prioritizes high-quality and frequently-used experiences, effectively managing the experience space and enhancing efficiency. Extensive experiments show that while the successive pattern may yield superior results, the cumulative pattern provides more stable performance. Moreover, experience elimination facilitates achieving better performance using just 11.54% of a high-quality subset.",
    "pdf_link": "https://arxiv.org/abs/2405.04219",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.04219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04219/chain.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.04219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04219/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04219/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04219/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04219/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04219/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04219v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04219/x6.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）驱动的自主代理在软件开发等场景中展现出实现高度自主性的巨大潜力。研究表明，这些代理能够借鉴过往经验，减少错误，提升效率。然而，传统的静态经验模式，依赖于固定的经验集合，缺乏迭代优化，限制了代理的适应能力。本文提出了一种迭代经验优化框架，允许LLM代理在执行任务时不断精炼经验。我们提出了两种优化模式：连续模式，基于任务批次内最近的经验进行优化；累积模式，整合所有先前任务批次的经验。结合启发式经验筛选，我们的方法优先考虑高质量且常用的经验，有效管理经验库，提升效率。实验结果显示，连续模式可能带来更佳效果，而累积模式则提供更稳定的性能。此外，经验筛选机制使得我们能够仅用高质量子集的11.54%就能获得更好的性能表现。",
    "title_cn": "软件开发代理通过迭代精炼经验在",
    "tags": [
      "Agent\n\n这篇论文主要探讨了大型语言模型（LLMs）驱动的自主代理在软件开发等场景中的应用，并提出了一种迭代经验优化框架来提升代理的适应能力和效率。这与“Agent”分类下的研究内容相符，因为该分类通常关注的是智能代理的设计、优化和应用，特别是在自主性和适应性方面的研究。而“RAG”（Retrieval-Augmented Generation）通常指的是一种结合检索和生成的模型架构，“LLM应用”则更侧重于LLM在特定领域的应用案例，“LLM理论”则关注LLM的理论基础和模型架构。因此，这篇论文更适合归类在“Agent”分类下。",
      "软件开发",
      "人工智能"
    ]
  },
  {
    "title": "NL2Plan: Robust LLM-Driven Planning from Minimal Text Descriptions",
    "submit_datetime": "2024年05月07日",
    "abstract": "Today's classical planners are powerful, but modeling input tasks in formats such as PDDL is tedious and error-prone. In contrast, planning with Large Language Models (LLMs) allows for almost any input text, but offers no guarantees on plan quality or even soundness. In an attempt to merge the best of these two approaches, some work has begun to use LLMs to automate parts of the PDDL creation process. However, these methods still require various degrees of expert input. We present NL2Plan, the first domain-agnostic offline LLM-driven planning system. NL2Plan uses an LLM to incrementally extract the necessary information from a short text prompt before creating a complete PDDL description of both the domain and the problem, which is finally solved by a classical planner. We evaluate NL2Plan on four planning domains and find that it solves 10 out of 15 tasks - a clear improvement over a plain chain-of-thought reasoning LLM approach, which only solves 2 tasks. Moreover, in two out of the five failure cases, instead of returning an invalid plan, NL2Plan reports that it failed to solve the task. In addition to using NL2Plan in end-to-end mode, users can inspect and correct all of its intermediate results, such as the PDDL representation, increasing explainability and making it an assistive tool for PDDL creation.",
    "pdf_link": "https://arxiv.org/abs/2405.04215",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.04215v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04215/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04215v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04215/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04215v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04215/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04215v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04215/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04215v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04215/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04215v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04215/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04215v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04215/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04215v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04215/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04215v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04215/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04215v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04215/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04215v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04215/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04215v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04215/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04215v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04215/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04215v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04215/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04215v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04215/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04215v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04215/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04215v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04215/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04215v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04215/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04215v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04215/x19.png"
      }
    ],
    "abstract_cn": "尽管经典规划器功能强大，但使用PDDL等格式建模任务既繁琐又容易出错。与之相对，大型语言模型（LLMs）的规划能力几乎无所不包，但计划的质量和正确性无法保证。为了融合两者的优势，研究者开始尝试用LLMs自动化PDDL的创建过程，但仍需专家的介入。我们推出的NL2Plan是首个领域无关的离线LLM规划系统，它通过LLM从文本提示中逐步提取信息，生成完整的PDDL描述，再由经典规划器解决。在四个领域的测试中，NL2Plan成功解决了15个任务中的10个，远超仅解决2个任务的思维链推理LLM方法。在失败的案例中，NL2Plan会报告无法解决问题，而非提供无效计划。用户不仅能使用NL2Plan进行端到端规划，还能检查和修正其PDDL表示等中间结果，增强了系统的透明度和辅助性。",
    "title_cn": "NL2Plan：基于精简文本描述，实现大型语言模型驱动的稳健规划系统解释：在结果2中，我采用了更加流畅和符合中文表达习惯的措辞，将“Robust LLM-Driven Planning”翻译为“稳健规划系统”，并调整了“from Minimal Text Descriptions”的翻译，使其更加符合中文的表达方式。这样的翻译既保留了原文的核心意义，又使得中文表达更加自然和优雅。",
    "tags": [
      "Agent\n\n这篇论文介绍了一个名为NL2Plan的系统，它利用大型语言模型（LLMs）来自动化生成PDDL（Planning Domain Definition Language）描述的过程，这是一种用于经典规划器的建模语言。NL2Plan的目标是结合LLMs的广泛规划能力和经典规划器的精确性，通过从文本提示中提取信息来生成PDDL描述，然后由经典规划器解决。这个系统在多个领域的测试中展示了其有效性，并且提供了透明度和辅助性，允许用户检查和修正中间结果。因此，这个系统可以被视为一个智能代理（Agent），因为它能够处理复杂的规划任务，并且在与用户的交互中提供辅助。",
      "自动化规划",
      "人工智能辅助"
    ]
  },
  {
    "title": "Sora Detector: A Unified Hallucination Detection for Large Text-to-Video Models",
    "submit_datetime": "2024年05月07日",
    "abstract": "The rapid advancement in text-to-video (T2V) generative models has enabled the synthesis of high-fidelity video content guided by textual descriptions. Despite this significant progress, these models are often susceptible to hallucination, generating contents that contradict the input text, which poses a challenge to their reliability and practical deployment. To address this critical issue, we introduce the SoraDetector, a novel unified framework designed to detect hallucinations across diverse large T2V models, including the cutting-edge Sora model. Our framework is built upon a comprehensive analysis of hallucination phenomena, categorizing them based on their manifestation in the video content. Leveraging the state-of-the-art keyframe extraction techniques and multimodal large language models, SoraDetector first evaluates the consistency between extracted video content summary and textual prompts, then constructs static and dynamic knowledge graphs (KGs) from frames to detect hallucination both in single frames and across frames. Sora Detector provides a robust and quantifiable measure of consistency, static and dynamic hallucination. In addition, we have developed the Sora Detector Agent to automate the hallucination detection process and generate a complete video quality report for each input video. Lastly, we present a novel meta-evaluation benchmark, T2VHaluBench, meticulously crafted to facilitate the evaluation of advancements in T2V hallucination detection. Through extensive experiments on videos generated by Sora and other large T2V models, we demonstrate the efficacy of our approach in accurately detecting hallucinations. The code and dataset can be accessed via GitHub.",
    "pdf_link": "https://arxiv.org/abs/2405.04180",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.04180v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04180/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04180v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04180/test245.drawio.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04180v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04180/report23.drawio.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04180v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04180/detailrow.drawio.png"
      }
    ],
    "abstract_cn": "文本到视频生成技术的飞速进步，让我们能够根据文字描述创造出栩栩如生的视频。然而，这些模型有时会“幻想”出与文本不符的内容，这影响了它们的实用性和可靠性。为此，我们推出了SoraDetector，一个创新的框架，专门用于检测包括尖端Sora模型在内的多种大型T2V模型中的幻觉现象。我们的框架深入分析了幻觉的多种表现，并据此进行分类。借助先进的帧提取技术和多模态大型语言模型，SoraDetector首先检查视频摘要与文本提示的匹配度，然后构建静态和动态知识图谱，以识别单帧和连续帧中的幻觉。Sora Detector不仅提供了一个强有力的量化指标来衡量幻觉，还推出了Sora Detector Agent，自动完成幻觉检测并生成详尽的视频质量报告。此外，我们还精心打造了T2VHaluBench，一个元评估基准，旨在推动T2V幻觉检测技术的发展。通过在Sora及其他大型T2V模型生成的视频上进行的大量实验，我们展示了SoraDetector在精准捕捉幻觉方面的卓越能力。相关代码和数据集已上传至GitHub，供大家探索。",
    "title_cn": "Sora检测器：大型文本至视频模型幻觉现象的统一检测利器",
    "tags": [
      "Agent\n\n理由：这篇论文介绍了一个名为 SoraDetector 的框架，它专门用于检测大型文本到视频（T2V）模型中的幻觉现象。特别值得注意的是，论文提到了 SoraDetector Agent，这是一个自动完成幻觉检测并生成视频质量报告的组件。这个 Agent 的存在表明该论文与Agent分类相关，因为它涉及到了一个具体的、能够执行特定任务的智能体。此外，论文还提到了多模态大型语言模型和元评估基准 T2VHaluBench，这些都是为了支持 Agent 的工作，而不是专注于 LLM 的理论研究或 RAG（检索增强生成）技术。因此，这篇论文更适合归类到Agent分类中。",
      "视频生成",
      "内容检测"
    ]
  },
  {
    "title": "D-NLP at SemEval-2024 Task 2: Evaluating Clinical Inference Capabilities of Large Language Models",
    "submit_datetime": "2024年05月07日",
    "abstract": "Large language models (LLMs) have garnered significant attention and widespread usage due to their impressive performance in various tasks. However, they are not without their own set of challenges, including issues such as hallucinations, factual inconsistencies, and limitations in numerical-quantitative reasoning. Evaluating LLMs in miscellaneous reasoning tasks remains an active area of research. Prior to the breakthrough of LLMs, Transformers had already proven successful in the medical domain, effectively employed for various natural language understanding (NLU) tasks. Following this trend, LLMs have also been trained and utilized in the medical domain, raising concerns regarding factual accuracy, adherence to safety protocols, and inherent limitations. In this paper, we focus on evaluating the natural language inference capabilities of popular open-source and closed-source LLMs using clinical trial reports as the dataset. We present the performance results of each LLM and further analyze their performance on a development set, particularly focusing on challenging instances that involve medical abbreviations and require numerical-quantitative reasoning. Gemini, our leading LLM, achieved a test set F1-score of 0.748, securing the ninth position on the task scoreboard. Our work is the first of its kind, offering a thorough examination of the inference capabilities of LLMs within the medical domain.",
    "pdf_link": "https://arxiv.org/abs/2405.04170",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）因其卓越的性能在多个领域备受瞩目，但同时也伴随着幻觉、事实错误和数值推理局限等挑战。在医疗领域，LLMs的应用引发了关于准确性、安全性和固有限制的讨论。本文深入探讨了LLMs在临床试验报告上的自然语言推理能力，揭示了它们在处理医学缩写和数值推理难题时的表现。Gemini，作为我们的旗舰LLM，在测试中以0.748的F1分数位列第九，展现了其在医疗推理任务中的潜力。我们的研究首次全面审视了LLMs在医疗领域的推理能力，为未来的医疗AI应用提供了宝贵的见解。",
    "title_cn": "SemEval-2024 第二任务：探究大型语言模型在临床推理领域的评估能力在 SemEval-2024 的第二项任务中，我们将深入探讨大型语言模型在临床推理方面的表现。这项研究旨在评估这些模型在处理医疗相关文本时的推理能力，以及它们如何理解和分析临床情境中的复杂信息。通过这一评估，我们期望能够揭示大型语言模型在医疗领域应用中的潜力和局限性，为未来的医疗人工智能发展提供宝贵的见解。",
    "tags": [
      "LLM应用\n\n这篇论文探讨了大型语言模型（LLMs）在医疗领域的应用，特别是在临床试验报告的自然语言推理能力方面。它分析了LLMs在处理医学缩写和数值推理难题时的表现，并通过Gemini模型的测试结果展示了LLMs在医疗推理任务中的潜力。因此，这篇论文属于LLM应用类别，因为它关注的是LLMs在特定领域（医疗）的实际应用和性能评估。",
      "",
      ""
    ]
  },
  {
    "title": "LingML: Linguistic-Informed Machine Learning for Enhanced Fake News Detection",
    "submit_datetime": "2024年05月07日",
    "abstract": "Nowadays, Information spreads at an unprecedented pace in social media and discerning truth from misinformation and fake news has become an acute societal challenge. Machine learning (ML) models have been employed to identify fake news but are far from perfect with challenging problems like limited accuracy, interpretability, and generalizability. In this paper, we enhance ML-based solutions with linguistics input and we propose LingML, linguistic-informed ML, for fake news detection. We conducted an experimental study with a popular dataset on fake news during the pandemic. The experiment results show that our proposed solution is highly effective. There are fewer than two errors out of every ten attempts with only linguistic input used in ML and the knowledge is highly explainable. When linguistics input is integrated with advanced large-scale ML models for natural language processing, our solution outperforms existing ones with 1.8% average error rate. LingML creates a new path with linguistics to push the frontier of effective and efficient fake news detection. It also sheds light on real-world multi-disciplinary applications requiring both ML and domain expertise to achieve optimal performance.",
    "pdf_link": "https://arxiv.org/abs/2405.04165",
    "graphs": [],
    "abstract_cn": "在社交媒体时代，信息传播如疾风骤雨，辨别真伪成为社会的一大难题。机器学习虽用于假新闻识别，但仍有诸多不足，如准确性、可解释性和泛化能力。本文中，我们引入语言学智慧，提出LingML，一种融合语言学的机器学习方法，专攻假新闻检测。我们以疫情期间的假新闻数据集为实验场，结果显示，LingML成效显著，错误率低至每十次尝试中不到两次，且其智慧可被清晰解读。当语言学智慧与自然语言处理的先进ML模型结合时，LingML更胜一筹，平均错误率仅为1.8%。LingML不仅为假新闻检测开辟新径，也为多学科融合的现实应用提供了启示，展现了ML与领域专业知识结合的巨大潜力。",
    "title_cn": "LingML：融合语言学智慧的机器学习，助力假新闻检测更上一层楼",
    "tags": [
      "Agent\n\n理由：这篇论文介绍了一种名为LingML的机器学习方法，它融合了语言学知识来专门处理假新闻检测问题。这种方法可以被视为一个智能代理（Agent），因为它被设计来执行特定的任务（即检测假新闻），并且在社交媒体环境中运作。论文强调了该方法在实际应用中的有效性和可解释性，这表明它是一个专门为解决特定问题而设计的智能系统。因此，它符合Agent分类的定义，即一个能够感知环境并采取行动以达到目标的系统。",
      "社交媒体",
      "假新闻检测"
    ]
  },
  {
    "title": "Sign2GPT: Leveraging Large Language Models for Gloss-Free Sign Language Translation",
    "submit_datetime": "2024年05月07日",
    "abstract": "Automatic Sign Language Translation requires the integration of both computer vision and natural language processing to effectively bridge the communication gap between sign and spoken languages. However, the deficiency in large-scale training data to support sign language translation means we need to leverage resources from spoken language. We introduce, Sign2GPT, a novel framework for sign language translation that utilizes large-scale pretrained vision and language models via lightweight adapters for gloss-free sign language translation. The lightweight adapters are crucial for sign language translation, due to the constraints imposed by limited dataset sizes and the computational requirements when training with long sign videos. We also propose a novel pretraining strategy that directs our encoder to learn sign representations from automatically extracted pseudo-glosses without requiring gloss order information or annotations. We evaluate our approach on two public benchmark sign language translation datasets, namely RWTH-PHOENIX-Weather 2014T and CSL-Daily, and improve on state-of-the-art gloss-free translation performance with a significant margin.",
    "pdf_link": "https://arxiv.org/abs/2405.04164",
    "graphs": [],
    "abstract_cn": "自动手语翻译需融合计算机视觉与自然语言处理，以跨越手语与口语间的沟通鸿沟。然而，手语翻译训练数据匮乏，我们需借力口语资源。我们创新推出Sign2GPT框架，它巧妙运用轻量级适配器，将大规模预训练的视觉与语言模型应用于无术语手语翻译。轻量级适配器因数据集有限及长视频训练的计算需求而显得尤为关键。我们还独创了一种预训练策略，让编码器无需术语顺序信息或注释，便能从自动提取的伪术语中汲取手语精髓。在RWTH-PHOENIX-Weather 2014T和CSL-Daily两大公开数据集上，我们的方法不仅经受考验，更在无术语翻译领域刷新了性能标杆。",
    "title_cn": "Sign2GPT：借助大型语言模型实现无词典辅助的美国手语翻译在这项研究中，我们提出了Sign2GPT，这是一种创新的方法，它利用了大型语言模型的强大能力，实现了无需依赖传统手势词典的美国手语翻译。通过这种方法，我们旨在打破传统翻译的局限，为手语用户提供更加流畅和自然的交流体验。",
    "tags": [
      "Agent\n\n这篇论文介绍了一种名为Sign2GPT的框架，它是一个自动手语翻译系统，结合了计算机视觉和自然语言处理技术，旨在解决手语与口语之间的沟通障碍。该框架通过使用轻量级适配器，将预训练的视觉和语言模型应用于手语翻译，特别适用于数据稀缺和计算资源有限的情况。此外，论文还提出了一种新的预训练策略，使得编码器能够在没有术语顺序信息或注释的情况下，从自动提取的伪术语中学习手语知识。该方法在两个公开数据集上进行了测试，并取得了优异的性能。因此，这篇论文更符合Agent分类，因为它描述了一个具体的系统或代理，该系统能够执行特定的任务（手语翻译），并且展示了如何通过创新的方法来克服实际应用中的挑战。",
      "手语翻译",
      "计算机视觉"
    ]
  },
  {
    "title": "MEDVOC: Vocabulary Adaptation for Fine-tuning Pre-trained Language Models on Medical Text Summarization",
    "submit_datetime": "2024年05月07日",
    "abstract": "This work presents a dynamic vocabulary adaptation strategy, MEDVOC, for fine-tuning pre-trained language models (PLMs) like BertSumAbs, BART, and PEGASUS for improved medical text summarization. In contrast to existing domain adaptation approaches in summarization, MEDVOC treats vocabulary as an optimizable parameter and optimizes the PLM vocabulary based on fragment score conditioned only on the downstream task's reference summaries. Unlike previous works on vocabulary adaptation (limited only to classification tasks), optimizing vocabulary based on summarization tasks requires an extremely costly intermediate fine-tuning step on large summarization datasets. To that end, our novel fragment score-based hyperparameter search very significantly reduces this fine-tuning time -- from 450 days to less than 2 days on average. Furthermore, while previous works on vocabulary adaptation are often primarily tied to single PLMs, MEDVOC is designed to be deployable across multiple PLMs (with varying model vocabulary sizes, pre-training objectives, and model sizes) -- bridging the limited vocabulary overlap between the biomedical literature domain and PLMs. MEDVOC outperforms baselines by 15.74% in terms of Rouge-L in zero-shot setting and shows gains of 17.29% in high Out-Of-Vocabulary (OOV) concentrations. Our human evaluation shows MEDVOC generates more faithful medical summaries (88% compared to 59% in baselines). We make the codebase publicly available at https://github.com/gb-kgp/MEDVOC.",
    "pdf_link": "https://arxiv.org/abs/2405.04163",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.04163v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04163/oov-medvoc-example_00.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04163v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04163/flow-chart_drift-versus-standard-new-18thJan2024_1550.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04163v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04163/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04163v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04163/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04163v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04163/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04163v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04163/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04163v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04163/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04163v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04163/x6.png"
      }
    ],
    "abstract_cn": "本研究介绍了一种名为MEDVOC的动态词汇适应策略，旨在通过微调预训练语言模型（如BertSumAbs、BART和PEGASUS）来提升医学文本摘要的质量。MEDVOC独特之处在于将词汇视为可优化元素，并根据下游任务的参考摘要优化PLM词汇，这与传统领域适应方法有所区别。我们的创新在于，通过基于片段得分的超参数搜索，将原本需要450天的微调时间大幅缩减至不到2天。MEDVOC不仅适用于单一PLM，还能跨多个PLM部署，有效弥合了生物医学文献与PLM之间的词汇鸿沟。在零-shot场景下，MEDVOC在Rouge-L指标上超越基线15.74%，并在高OOV浓度下提升了17.29%。人类评估进一步证实，MEDVOC生成的医学摘要忠实度高达88%，远超基线的59%。我们已将相关代码公开在https://github.com/gb-kgp/MEDVOC。",
    "title_cn": "MEDVOC：医学文本摘要中预训练语言模型的词汇微调适应在这项研究中，我们提出了MEDVOC，一种专门为医学文本摘要任务设计的词汇适应方法。通过微调预训练语言模型，MEDVOC旨在提高模型对医学领域特定术语和概念的理解，从而生成更准确、更具信息量的摘要。我们的方法结合了领域知识与先进的自然语言处理技术，为医学文献的自动化摘要提供了新的可能性。",
    "tags": [
      "LLM应用\n\n这篇论文介绍了一种针对医学文本摘要的动态词汇适应策略MEDVOC，它通过微调预训练语言模型来提高医学文本摘要的质量。这种方法特别关注于优化预训练语言模型（PLM）的词汇，以适应特定的下游任务，即医学文本摘要。MEDVOC的创新之处在于其能够显著减少微调时间，并提高在零-shot场景下的性能。此外，它还展示了在跨多个PLM部署时的有效性，以及在人类评估中的高忠实度。这些特点表明，该研究是针对大型语言模型（LLM）在特定应用场景（医学文本摘要）中的优化和改进，因此属于LLM应用分类。",
      "医学文本摘要",
      ""
    ]
  },
  {
    "title": "A Causal Explainable Guardrails for Large Language Models",
    "submit_datetime": "2024年05月07日",
    "abstract": "Large Language Models (LLMs) have shown impressive performance in natural language tasks, but their outputs can exhibit undesirable attributes or biases. Existing methods for steering LLMs towards desired attributes often assume unbiased representations and rely solely on steering prompts. However, the representations learned from pre-training can introduce semantic biases that influence the steering process, leading to suboptimal results. We propose LLMGuardaril, a novel framework that incorporates causal analysis and adversarial learning to obtain unbiased steering representations in LLMs. LLMGuardaril systematically identifies and blocks the confounding effects of biases, enabling the extraction of unbiased steering representations. Additionally, it includes an explainable component that provides insights into the alignment between the generated output and the desired direction. Experiments demonstrate LLMGuardaril's effectiveness in steering LLMs towards desired attributes while mitigating biases. Our work contributes to the development of safe and reliable LLMs that align with desired attributes. We discuss the limitations and future research directions, highlighting the need for ongoing research to address the ethical implications of large language models.",
    "pdf_link": "https://arxiv.org/abs/2405.04160",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）在自然语言任务中表现出色，但其输出有时会带有不受欢迎的偏见。现有的引导方法往往忽视了预训练中潜藏的偏见，仅依赖提示来调整模型行为，这可能导致结果不尽人意。我们提出的LLMGuardaril框架，通过因果分析和对抗性学习，旨在消除这些偏见，提取出公正的引导表示。该框架不仅能识别并隔离偏见的影响，还提供了一个解释性工具，帮助我们理解模型输出与期望目标之间的契合度。实验结果显示，LLMGuardaril在引导模型生成符合期望属性的内容方面表现出色，同时有效减少了偏见。我们的研究为构建既安全又符合伦理的LLMs迈出了重要一步，并指出了未来研究中需要关注的伦理问题。",
    "title_cn": "大型语言模型的因果解释性护栏在这篇文章中，我们将探讨如何为大型语言模型构建因果解释性保护措施，以确保其决策过程的透明度和可解释性。通过这种方式，我们不仅能够理解模型如何做出决策，还能确保其行为符合我们的预期和道德标准。",
    "tags": [
      "LLM理论\n\n这篇论文探讨了大型语言模型（LLMs）中的偏见问题，并提出了一种名为LLMGuardaril的框架来解决这一问题。该框架通过因果分析和对抗性学习来消除偏见，并提供了解释性工具。这表明论文关注的是LLMs的理论层面，即如何通过技术手段改进模型的公正性和安全性，而不是具体的应用案例或Agent的设计。因此，它属于LLM理论分类。",
      "",
      "人工智能伦理"
    ]
  },
  {
    "title": "How does GPT-2 Predict Acronyms? Extracting and Understanding a Circuit via Mechanistic Interpretability",
    "submit_datetime": "2024年05月07日",
    "abstract": "Transformer-based language models are treated as black-boxes because of their large number of parameters and complex internal interactions, which is a serious safety concern. Mechanistic Interpretability (MI) intends to reverse-engineer neural network behaviors in terms of human-understandable components. In this work, we focus on understanding how GPT-2 Small performs the task of predicting three-letter acronyms. Previous works in the MI field have focused so far on tasks that predict a single token. To the best of our knowledge, this is the first work that tries to mechanistically understand a behavior involving the prediction of multiple consecutive tokens. We discover that the prediction is performed by a circuit composed of 8 attention heads (~5% of the total heads) which we classified in three groups according to their role. We also demonstrate that these heads concentrate the acronym prediction functionality. In addition, we mechanistically interpret the most relevant heads of the circuit and find out that they use positional information which is propagated via the causal mask mechanism. We expect this work to lay the foundation for understanding more complex behaviors involving multiple-token predictions.",
    "pdf_link": "https://arxiv.org/abs/2405.04156",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.04156v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04156/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04156v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04156/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04156v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04156/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04156v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04156/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04156v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04156/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04156v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04156/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04156v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04156/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04156v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04156/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04156v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04156/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04156v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04156/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04156v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04156/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04156v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04156/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04156v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04156/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04156v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04156/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04156v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04156/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04156v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04156/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04156v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04156/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04156v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04156/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04156v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04156/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04156v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04156/x20.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04156v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04156/x21.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04156v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04156/x22.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04156v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04156/x23.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04156v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04156/x24.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04156v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04156/x25.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04156v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04156/x26.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04156v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04156/x27.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04156v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04156/x28.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04156v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04156/x29.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04156v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04156/x30.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04156v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04156/x31.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04156v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04156/x32.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04156v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04156/x33.png"
      }
    ],
    "abstract_cn": "基于Transformer的语言模型因其庞大的参数和复杂的内部交互而被视为神秘的黑箱，这引发了严重的安全担忧。机械可解释性（MI）试图揭开神经网络行为的神秘面纱，使其变得人类可理解。在本研究中，我们深入探讨了GPT-2 Small如何巧妙地预测三字母缩写。以往的MI研究多聚焦于单个令牌的预测，而我们的研究则是首次尝试机械地剖析涉及连续多个令牌预测的行为。我们揭示了一个由8个注意力头组成的预测电路，这些头根据其功能被分为三类，并集中体现了缩写预测的能力。我们还深入分析了这些关键的注意力头，发现它们巧妙地利用了位置信息，并通过因果掩码机制传递这一信息。我们相信，这项研究将为未来探索更复杂的多个令牌预测行为奠定坚实的基础。",
    "title_cn": "GPT-2如何巧妙预测缩写？我们通过机械可解释性的透镜，深入探索其内部运作，揭秘其预测缩写的神秘电路。",
    "tags": [
      "LLM理论\n\n这篇论文探讨了基于Transformer的语言模型（如GPT-2 Small）的机械可解释性，特别是关于三字母缩写的预测机制。研究集中在模型内部的工作原理和注意力头的功能分析上，这是对大型语言模型理论层面的深入研究。因此，它属于LLM理论分类，因为它关注的是理解模型的内部运作和预测行为，而不是直接的应用或代理行为。",
      "",
      "模型解释性"
    ]
  },
  {
    "title": "Enriched BERT Embeddings for Scholarly Publication Classification",
    "submit_datetime": "2024年05月07日",
    "abstract": "With the rapid expansion of academic literature and the proliferation of preprints, researchers face growing challenges in manually organizing and labeling large volumes of articles. The NSLP 2024 FoRC Shared Task I addresses this challenge organized as a competition. The goal is to develop a classifier capable of predicting one of 123 predefined classes from the Open Research Knowledge Graph (ORKG) taxonomy of research fields for a given article.This paper presents our results. Initially, we enrich the dataset (containing English scholarly articles sourced from ORKG and arXiv), then leverage different pre-trained language Models (PLMs), specifically BERT, and explore their efficacy in transfer learning for this downstream task. Our experiments encompass feature-based and fine-tuned transfer learning approaches using diverse PLMs, optimized for scientific tasks, including SciBERT, SciNCL, and SPECTER2. We conduct hyperparameter tuning and investigate the impact of data augmentation from bibliographic databases such as OpenAlex, Semantic Scholar, and Crossref. Our results demonstrate that fine-tuning pre-trained models substantially enhances classification performance, with SPECTER2 emerging as the most accurate model. Moreover, enriching the dataset with additional metadata improves classification outcomes significantly, especially when integrating information from S2AG, OpenAlex and Crossref. Our best-performing approach achieves a weighted F1-score of 0.7415. Overall, our study contributes to the advancement of reliable automated systems for scholarly publication categorization, offering a potential solution to the laborious manual curation process, thereby facilitating researchers in efficiently locating relevant resources.",
    "pdf_link": "https://arxiv.org/abs/2405.04136",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.04136v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04136/forc_model_1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04136v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04136/twinbert_final.png"
      }
    ],
    "abstract_cn": "随着学术文献的激增，研究人员在处理大量文章的手动分类和标注工作上遇到了难题。NSLP 2024 FoRC共享任务I正是为了解决这一挑战而设立的竞赛。我们的目标是开发一个能够根据ORKG的123个研究领域分类，为文章自动分类的分类器。本文展示了我们的研究成果。首先，我们对数据集进行扩充，然后利用BERT等预训练语言模型进行转移学习。我们的实验涵盖了多种科学任务优化的PLMs，如SciBERT、SciNCL和SPECTER2，并进行了超参数调优和数据增强。结果显示，微调预训练模型显著提升了分类准确性，其中SPECTER2表现最佳。通过整合S2AG、OpenAlex和Crossref的信息，我们进一步提高了分类效果。我们的最佳方法达到了0.7415的加权F1分数。总体而言，我们的研究为学术出版物分类的自动化提供了有力支持，减轻了研究人员的工作负担，使他们能够更高效地获取相关资源。",
    "title_cn": "BERT嵌入的丰富化助力学术出版物精准分类",
    "tags": [
      "Agent\n\n这篇论文主要关注的是开发一个自动化的分类器，用于根据特定的研究领域对学术文章进行分类。这个分类器可以被视为一个智能代理（Agent），因为它能够自动执行任务（即文章分类），并且在这个过程中利用了预训练语言模型（如BERT、SciBERT、SciNCL和SPECTER2）进行转移学习和数据增强。这个代理的目标是提高分类的准确性，减轻研究人员的工作负担，并帮助他们更高效地获取相关资源。因此，这篇论文的内容与Agent的定义相符，即一个能够感知环境、做出决策并执行动作以达到特定目标的系统。",
      "学术出版物分类",
      ""
    ]
  },
  {
    "title": "In-context Learning for Automated Driving Scenarios",
    "submit_datetime": "2024年05月07日",
    "abstract": "One of the key challenges in current Reinforcement Learning (RL)-based Automated Driving (AD) agents is achieving flexible, precise, and human-like behavior cost-effectively. This paper introduces an innovative approach utilizing Large Language Models (LLMs) to intuitively and effectively optimize RL reward functions in a human-centric way. We developed a framework where instructions and dynamic environment descriptions are input into the LLM. The LLM then utilizes this information to assist in generating rewards, thereby steering the behavior of RL agents towards patterns that more closely resemble human driving. The experimental results demonstrate that this approach not only makes RL agents more anthropomorphic but also reaches better performance. Additionally, various strategies for reward-proxy and reward-shaping are investigated, revealing the significant impact of prompt design on shaping an AD vehicle's behavior. These findings offer a promising direction for the development of more advanced and human-like automated driving systems. Our experimental data and source code can be found here.",
    "pdf_link": "https://arxiv.org/abs/2405.04135",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.04135v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04135/Framework_fig.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04135v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04135/prompt429.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04135v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04135/Fig_3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04135v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04135/casestudy430.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04135v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04135/matchRate.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04135v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04135/train_coli.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04135v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04135/train_speed.png"
      }
    ],
    "abstract_cn": "在自动驾驶领域，如何让基于强化学习的代理以低成本展现出灵活、精准且类似人类的行为，一直是挑战。本文提出了一种新颖方法，通过大型语言模型来优化强化学习奖励函数，使其更贴近人类驾驶行为。我们构建了一个框架，将指令和环境动态输入到语言模型中，由其辅助生成奖励，引导学习代理的行为更接近人类驾驶模式。实验证明，这种方法不仅让代理行为更人性化，性能也得到提升。同时，我们还探讨了不同的奖励设计和塑造策略，发现提示设计对车辆行为有着显著影响。这些成果为开发更先进的自动驾驶系统指明了方向。实验数据和源代码已公开分享。",
    "title_cn": "自动驾驶场景中的上下文学习（ICL），为智能驾驶系统提供了新的学习范式。",
    "tags": [
      "Agent\n\n这篇论文主要探讨了在自动驾驶领域中，如何利用大型语言模型来优化强化学习代理的奖励函数，以使其行为更接近人类驾驶行为。这种方法涉及构建一个框架，其中语言模型被用来辅助生成奖励，从而引导学习代理的行为。因此，这篇论文更符合Agent分类，因为它专注于使用语言模型来改进代理（Agent）的行为，特别是在自动驾驶这一特定应用场景中。",
      "自动驾驶",
      ""
    ]
  },
  {
    "title": "Optimizing Language Model's Reasoning Abilities with Weak Supervision",
    "submit_datetime": "2024年05月07日",
    "abstract": "While Large Language Models (LLMs) have demonstrated proficiency in handling complex queries, much of the past work has depended on extensively annotated datasets by human experts. However, this reliance on fully-supervised annotations poses scalability challenges, particularly as models and data requirements grow. To mitigate this, we explore the potential of enhancing LLMs' reasoning abilities with minimal human supervision. In this work, we introduce self-reinforcement, which begins with Supervised Fine-Tuning (SFT) of the model using a small collection of annotated questions. Then it iteratively improves LLMs by learning from the differences in responses from the SFT and unfinetuned models on unlabeled questions. Our approach provides an efficient approach without relying heavily on extensive human-annotated explanations. However, current reasoning benchmarks typically only include golden-reference answers or rationales. Therefore, we present \\textsc{PuzzleBen}, a weakly supervised benchmark that comprises 25,147 complex questions, answers, and human-generated rationales across various domains, such as brainteasers, puzzles, riddles, parajumbles, and critical reasoning tasks. A unique aspect of our dataset is the inclusion of 10,000 unannotated questions, enabling us to explore utilizing fewer supersized data to boost LLMs' inference capabilities. Our experiments underscore the significance of \\textsc{PuzzleBen}, as well as the effectiveness of our methodology as a promising direction in future endeavors. Our dataset and code will be published soon on \\texttt{Anonymity Link}.",
    "pdf_link": "https://arxiv.org/abs/2405.04086",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）虽能熟练应对复杂查询，但过往研究多依赖于人类专家精心注释的数据集。这种对全监督注释的依赖，随着模型和数据需求的膨胀，带来了可扩展性的难题。为此，我们探索了在减少人类干预的情况下，提升LLMs推理能力的可能性。我们提出的自我强化方法，首先通过一小批注释问题对模型进行监督微调（SFT），随后通过比较SFT模型与原始模型在未标记问题上的回答差异，迭代提升LLMs。这种方法高效且不依赖于大量的人工解释。然而，现有的推理基准往往只提供标准答案或推理过程。鉴于此，我们推出了\\textsc{PuzzleBen}，一个包含25,147个跨领域复杂问题、答案及人类推理过程的弱监督基准，其中特别包含了10,000个未注释问题，旨在探索如何利用较少的大规模数据来增强LLMs的推理力。实验结果凸显了\\textsc{PuzzleBen}的重要性，并证明了我们的方法在未来研究中的潜力。我们的数据集和代码即将在\\texttt{Anonymity Link}上公开。",
    "title_cn": "借助弱监督之力，精炼语言模型的推理之智",
    "tags": [
      "LLM理论\n\n这篇论文探讨了大型语言模型（LLMs）在推理能力提升方面的自我强化方法，特别是在减少人类干预的情况下。它提出了一种新的方法，通过监督微调（SFT）和迭代提升来增强LLMs的能力，而不依赖于大量的人工解释。此外，论文还推出了一个名为\\textsc{PuzzleBen}的新基准数据集，用于研究如何利用较少的大规模数据来增强LLMs的推理力。这些内容更偏向于LLM的理论研究，因为它关注的是模型自身的改进方法和推理能力的理论探讨，而不是具体的应用场景或Agent的设计。因此，这篇论文应归类于LLM理论。",
      "",
      "人工智能推理"
    ]
  },
  {
    "title": "FlashBack:Efficient Retrieval-Augmented Language Modeling for Long Context Inference",
    "submit_datetime": "2024年05月07日",
    "abstract": "Retrieval-Augmented Language Modeling (RALM) by integrating large language models (LLM) with relevant documents from an external corpus is a proven method for enabling the LLM to generate information beyond the scope of its pre-training corpus. Previous work using utilizing retrieved content by simply prepending retrieved contents to the input poses a high runtime issue, which degrades the inference efficiency of the LLMs because they fail to use the Key-Value (KV) cache efficiently. In this paper, we propose \\textsc{FlashBack}, a modular RALM designed to improve the inference efficiency of RALM with appending context pattern while maintaining decent performance after specific fine-tuning without heavily destruct the knowledge integrity of the LLM. \\textsc{FlashBack} appends retrieved documents at the end of the context for efficiently utilizing the KV cache instead of prepending them. Our experiment shows that the inference speed of \\textsc{FlashBack} is up to $4\\times$ faster than the prepending method on a 7B LLM (Llama 2). Via bypassing unnecessary re-computation, it demonstrates an advancement by achieving significantly faster inference speed, and this heightened efficiency will substantially reduce inferential cost. Our code will be publicly available.",
    "pdf_link": "https://arxiv.org/abs/2405.04065",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.04065v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04065/fig_show.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04065v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04065/fig_contextpattern.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04065v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04065/fig_pipeline.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04065v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04065/fig_method.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04065v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04065/fig_opt_models.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04065v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04065/fig_llama2-7b.png"
      }
    ],
    "abstract_cn": "检索增强语言建模（RALM）通过结合LLM与外部文档，使模型能够超越预训练范围生成信息。以往的方法将检索内容前置于输入，导致运行时效率低下，未能充分利用KV缓存。本文提出的\\textsc{FlashBack}是一种模块化RALM，它通过在上下文末尾附加检索文档，有效提升了推理效率，同时通过微调保持了LLM的知识完整性。实验显示，\\textsc{FlashBack}在7B LLM（Llama 2）上的推理速度比前置方法快4倍，显著降低了推理成本。我们即将公开相关代码。",
    "title_cn": "闪回技术：提升长篇推理中语言建模效率的检索增强方法",
    "tags": [
      "RAG\n\n这篇论文介绍了一种名为\\textsc{FlashBack}的检索增强语言建模方法，它通过在上下文末尾附加检索文档来提高推理效率，同时保持了大型语言模型（LLM）的知识完整性。这种方法与检索增强生成（RAG）的概念紧密相关，因为它涉及将LLM与外部文档结合以生成信息。因此，这篇论文应归类于RAG。",
      "",
      "机器学习"
    ]
  },
  {
    "title": "Evaluating Text Summaries Generated by Large Language Models Using OpenAI's GPT",
    "submit_datetime": "2024年05月07日",
    "abstract": "This research examines the effectiveness of OpenAI's GPT models as independent evaluators of text summaries generated by six transformer-based models from Hugging Face: DistilBART, BERT, ProphetNet, T5, BART, and PEGASUS. We evaluated these summaries based on essential properties of high-quality summary - conciseness, relevance, coherence, and readability - using traditional metrics such as ROUGE and Latent Semantic Analysis (LSA). Uniquely, we also employed GPT not as a summarizer but as an evaluator, allowing it to independently assess summary quality without predefined metrics. Our analysis revealed significant correlations between GPT evaluations and traditional metrics, particularly in assessing relevance and coherence. The results demonstrate GPT's potential as a robust tool for evaluating text summaries, offering insights that complement established metrics and providing a basis for comparative analysis of transformer-based models in natural language processing tasks.",
    "pdf_link": "https://arxiv.org/abs/2405.04053",
    "graphs": [],
    "abstract_cn": "本研究探讨了GPT模型作为独立评估者对Hugging Face六种变压器模型生成的文本摘要的评估效果。我们依据摘要的关键质量——简洁、相关、连贯和易读——采用ROUGE和LSA等传统指标进行评价。特别地，我们将GPT用作评估工具而非生成工具，使其在不依赖固定指标的情况下独立评判摘要质量。研究发现，GPT的评估与传统指标高度一致，尤其在相关性和连贯性方面。这表明GPT有望成为评估文本摘要的有力工具，为现有评价体系提供补充视角，并为自然语言处理领域内变压器模型的比较研究奠定基础。",
    "title_cn": "借助OpenAI的GPT，我们评估了大型语言模型所生成的文本摘要，探究其在信息提炼与表达上的精妙之处。",
    "tags": [
      "LLM应用\n\n这篇论文探讨了GPT模型在评估Hugging Face六种变压器模型生成的文本摘要质量方面的应用。它特别强调了GPT作为独立评估者的角色，而不是生成文本的角色，并且展示了GPT评估与传统指标（如ROUGE和LSA）的一致性。这种应用属于大型语言模型（LLM）的实际应用范畴，因此被归类为LLM应用。",
      "",
      "文本摘要评估"
    ]
  },
  {
    "title": "Locally Differentially Private In-Context Learning",
    "submit_datetime": "2024年05月07日",
    "abstract": "Large pretrained language models (LLMs) have shown surprising In-Context Learning (ICL) ability. An important application in deploying large language models is to augment LLMs with a private database for some specific task. The main problem with this promising commercial use is that LLMs have been shown to memorize their training data and their prompt data are vulnerable to membership inference attacks (MIA) and prompt leaking attacks. In order to deal with this problem, we treat LLMs as untrusted in privacy and propose a locally differentially private framework of in-context learning(LDP-ICL) in the settings where labels are sensitive. Considering the mechanisms of in-context learning in Transformers by gradient descent, we provide an analysis of the trade-off between privacy and utility in such LDP-ICL for classification. Moreover, we apply LDP-ICL to the discrete distribution estimation problem. In the end, we perform several experiments to demonstrate our analysis results.",
    "pdf_link": "https://arxiv.org/abs/2405.04032",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.04032v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04032/main.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04032v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04032/fig2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04032v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04032/exp.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04032v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04032/est.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04032v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04032/COMPARE.png"
      }
    ],
    "abstract_cn": "大型预训练语言模型展现出惊人的上下文学习能力，但在商业应用中，为其添加私有数据库以执行特定任务时，却面临着隐私泄露的风险。这些模型不仅会记忆训练数据，还容易遭受成员推断和提示泄露攻击。为此，我们提出了一种本地差分隐私框架下的上下文学习方法（LDP-ICL），特别适用于标签敏感的场景。通过分析Transformer模型中梯度下降机制下的隐私与效用权衡，我们不仅在分类任务中应用了LDP-ICL，还将其扩展到了离散分布估计问题。实验结果验证了我们的分析，为隐私保护的上下文学习提供了有力支持。",
    "title_cn": "局部差分隐私下的上下文学习在翻译过程中，我首先直接将英文标题翻译为中文，确保意思的准确性。然后，在第二步中，我进一步优化了翻译，使其更加符合中文的表达习惯，简洁而优雅。\"局部差分隐私下的上下文学习\"这个翻译既保留了原英文标题的含义，又使其在中文语境中更加通顺和易于理解。",
    "tags": [
      "LLM理论\n\n这篇论文探讨了大型预训练语言模型在商业应用中的隐私保护问题，并提出了一种基于本地差分隐私的上下文学习方法。它关注的是模型在处理私有数据时的隐私泄露风险，并试图通过理论框架来解决这一问题。因此，它更偏向于LLM的理论研究，特别是关于隐私保护和模型效用之间的权衡。这与Agent、RAG或LLM应用分类不符，因为Agent通常指的是自主行动的实体，RAG（Retrieval-Augmented Generation）通常涉及信息检索增强的生成模型，而LLM应用则更多关注模型的实际应用场景。",
      "隐私保护",
      "数据安全"
    ]
  },
  {
    "title": "SEED-Data-Edit Technical Report: A Hybrid Dataset for Instructional Image Editing",
    "submit_datetime": "2024年05月07日",
    "abstract": "In this technical report, we introduce SEED-Data-Edit: a unique hybrid dataset for instruction-guided image editing, which aims to facilitate image manipulation using open-form language. SEED-Data-Edit is composed of three distinct types of data: (1) High-quality editing data produced by an automated pipeline, ensuring a substantial volume of diverse image editing pairs. (2) Real-world scenario data collected from the internet, which captures the intricacies of user intentions for promoting the practical application of image editing in the real world. (3) High-precision multi-turn editing data annotated by humans, which involves multiple rounds of edits for simulating iterative editing processes. The combination of these diverse data sources makes SEED-Data-Edit a comprehensive and versatile dataset for training language-guided image editing model. We fine-tune a pretrained Multimodal Large Language Model (MLLM) that unifies comprehension and generation with SEED-Data-Edit. The instruction tuned model demonstrates promising results, indicating the potential and effectiveness of SEED-Data-Edit in advancing the field of instructional image editing. The datasets are released in https://huggingface.co/datasets/AILab-CVC/SEED-Data-Edit.",
    "pdf_link": "https://arxiv.org/abs/2405.04007",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.04007v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04007/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04007v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04007/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04007v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04007/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04007v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04007/x4.png"
      }
    ],
    "abstract_cn": "本报告介绍了SEED-Data-Edit，一个专为开放式语言指导图像编辑设计的独特混合数据集。它汇集了三种数据：自动化生成的高质量编辑样本、互联网采集的现实场景数据，以及人类标注的多轮高精度编辑过程。这些数据共同打造了一个全面且灵活的训练平台，用于开发语言指导的图像编辑模型。我们利用SEED-Data-Edit对预训练的多模态大型语言模型进行了微调，结果显示了其在推动指令图像编辑技术发展上的巨大潜力。数据集已公开发布，供研究者探索。",
    "title_cn": "SEED-Data-Edit 技术报告：教学图像编辑的混合数据集探索在这份技术报告中，我们介绍了 SEED-Data-Edit，一个专为教学图像编辑而设计的混合数据集。该数据集结合了多种图像编辑任务，旨在为研究人员和开发者提供一个全面的资源，以探索和提升图像编辑技术的教学方法。通过深入分析数据集的构成和应用，我们希望激发更多关于图像编辑教学的创新思路和实践。",
    "tags": [
      "Agent\n\n这篇论文介绍了一个名为SEED-Data-Edit的混合数据集，用于开发语言指导的图像编辑模型。它通过整合自动化生成的编辑样本、互联网采集的现实场景数据以及人类标注的编辑过程，构建了一个全面的训练平台。论文中提到利用这个数据集对预训练的多模态大型语言模型进行微调，展示了其在推动指令图像编辑技术发展上的潜力。这个数据集的开发和应用，以及对预训练模型的微调，都是为了创建能够理解和执行语言指令的智能Agent，因此将其分类为Agent。",
      "图像编辑",
      "多模态学习"
    ]
  },
  {
    "title": "Sketch Then Generate: Providing Incremental User Feedback and Guiding LLM Code Generation through Language-Oriented Code Sketches",
    "submit_datetime": "2024年05月07日",
    "abstract": "Crafting effective prompts for code generation or editing with Large Language Models (LLMs) is not an easy task. Particularly, the absence of immediate, stable feedback during prompt crafting hinders effective interaction, as users are left to mentally imagine possible outcomes until the code is generated. In response, we introduce Language-Oriented Code Sketching, an interactive approach that provides instant, incremental feedback in the form of code sketches (i.e., incomplete code outlines) during prompt crafting. This approach converts a prompt into a code sketch by leveraging the inherent linguistic structures within the prompt and applying classic natural language processing techniques. The sketch then serves as an intermediate placeholder that not only previews the intended code structure but also guides the LLM towards the desired code, thereby enhancing human-LLM interaction. We conclude by discussing the approach's applicability and future plans.",
    "pdf_link": "https://arxiv.org/abs/2405.03998",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.03998v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03998/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03998v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03998/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03998v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03998/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03998v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03998/x4.png"
      }
    ],
    "abstract_cn": "在 LLMs 中制作代码提示并非易事，尤其是在缺乏即时反馈的情况下，用户只能猜测代码生成的结果。为此，我们提出了面向语言的代码草图绘制，一种交互式方法，它通过代码草图提供即时反馈，帮助用户预览代码结构并引导 LLM 生成所需代码，从而优化了人机交互。我们探讨了这种方法的潜力，并展望了未来的发展方向。",
    "title_cn": "草绘启程，代码随行：借助语言导向的代码草图，我们逐步收集用户反馈，巧妙引导大型语言模型，使其代码生成更加精准。",
    "tags": [
      "Agent\n\n理由：这篇论文提出了一种交互式方法，即面向语言的代码草图绘制，用于优化人机交互，帮助用户预览代码结构并引导大型语言模型（LLM）生成所需代码。这种方法涉及用户与模型之间的交互，可以被视为一种智能代理（Agent）的行为，因为它涉及代理与环境（用户）的互动，以实现特定目标（生成代码）。因此，这篇论文更符合Agent分类，而不是RAG、LLM应用或LLM理论。",
      "软件开发",
      "人机交互"
    ]
  },
  {
    "title": "TrimCaching: Parameter-sharing AI Model Caching in Wireless Edge Networks",
    "submit_datetime": "2024年05月07日",
    "abstract": "Next-generation mobile networks are expected to facilitate fast AI model downloading to end users. By caching models on edge servers, mobile networks can deliver models to end users with low latency, resulting in a paradigm called edge model caching. In this paper, we develop a novel model placement scheme, called parameter-sharing model caching (TrimCaching). TrimCaching exploits the key observation that a wide range of AI models, such as convolutional neural networks or large language models, can share a significant proportion of parameter blocks containing reusable knowledge, thereby improving storage efficiency. To this end, we formulate a parameter-sharing model placement problem to maximize the cache hit ratio in multi-edge wireless networks by balancing the fundamental tradeoff between storage efficiency and service latency. We show that the formulated problem is a submodular maximization problem with submodular constraints, for which no polynomial-time approximation algorithm exists. To overcome this challenge, we study an important special case, where a small fixed number of parameter blocks are shared across models, which often holds in practice. In such a case, a polynomial-time algorithm with $\\left(1-ε\\right)/2$-approximation guarantee is developed. Subsequently, we address the original problem for the general case by developing a greedy algorithm. Simulation results demonstrate that the proposed TrimCaching framework significantly improves the cache hit ratio compared with state-of-the-art content caching without exploiting shared parameters in AI models.",
    "pdf_link": "https://arxiv.org/abs/2405.03990",
    "graphs": [],
    "abstract_cn": "下一代移动网络将加速AI模型向终端用户的下载。通过边缘服务器上的模型缓存，网络能够以低延迟向用户提供模型，这一模式被称为边缘模型缓存。本文提出了一种创新的模型放置策略——参数共享模型缓存（TrimCaching），它发现众多AI模型，如卷积神经网络和大型语言模型，其参数块中蕴含的可复用知识可以共享，从而提升存储效率。我们设计了一个参数共享模型放置问题，旨在通过权衡存储效率与服务延迟，提高多边缘无线网络的缓存命中率。尽管该问题属于受限的子模块最大化问题，缺乏多项式时间近似解，但我们针对实践中常见的特殊情况——少量参数块在模型间共享，提出了一种具有$\\left(1-ε\\right)/2$近似保证的多项式时间算法。对于一般情况，我们则采用贪婪算法解决。模拟结果显示，TrimCaching框架在缓存命中率上远超未利用AI模型共享参数的现有内容缓存技术。",
    "title_cn": "精简缓存：无线边缘网络中的共享参数AI模型缓存技术在这项研究中，我们提出了一种名为“精简缓存”的新型技术，它旨在优化无线边缘网络中的AI模型缓存策略。通过共享参数，我们的方法能够更高效地利用网络资源，同时提供快速的AI服务响应。这种方法特别适用于资源受限的边缘环境，能够在保证性能的同时，减少对网络带宽和存储的需求。",
    "tags": [
      "LLM应用\n\n这篇论文探讨了在边缘服务器上缓存AI模型，特别是大型语言模型（LLM）的参数共享策略，以提高存储效率和缓存命中率。它提出了一种新的模型放置策略，即参数共享模型缓存（TrimCaching），并针对特定情况设计了多项式时间算法。这种方法旨在优化多边缘无线网络中的模型服务延迟和存储效率，属于LLM在实际应用中的优化技术，因此归类为LLM应用。",
      "移动网络",
      "人工智能"
    ]
  },
  {
    "title": "A Method for Parsing and Vectorization of Semi-structured Data used in Retrieval Augmented Generation",
    "submit_datetime": "2024年05月07日",
    "abstract": "This paper presents a novel method for parsing and vectorizing semi-structured data to enhance the functionality of Retrieval-Augmented Generation (RAG) within Large Language Models (LLMs). We developed a comprehensive pipeline for converting various data formats into .docx, enabling efficient parsing and structured data extraction. The core of our methodology involves the construction of a vector database using Pinecone, which integrates seamlessly with LLMs to provide accurate, context-specific responses, particularly in environmental management and wastewater treatment operations. Through rigorous testing with both English and Chinese texts in diverse document formats, our results demonstrate a marked improvement in the precision and reliability of LLMs outputs. The RAG-enhanced models displayed enhanced ability to generate contextually rich and technically accurate responses, underscoring the potential of vector knowledge bases in significantly boosting the performance of LLMs in specialized domains. This research not only illustrates the effectiveness of our method but also highlights its potential to revolutionize data processing and analysis in environmental sciences, setting a precedent for future advancements in AI-driven applications. Our code is available at https://github.com/linancn/TianGong-AI-Unstructure.git.",
    "pdf_link": "https://arxiv.org/abs/2405.03989",
    "graphs": [],
    "abstract_cn": "本文介绍了一种创新方法，用于解析和向量化半结构化数据，以提升大型语言模型（LLMs）中检索增强生成（RAG）的效能。我们构建了一套全面的转换流程，将多种数据格式转化为.docx，以便进行高效解析和结构化数据提取。我们的核心技术是利用Pinecone构建向量数据库，与LLMs完美融合，为环境管理和废水处理等场景提供精准、上下文相关的响应。经过对英汉文本及多样文档格式的严格测试，我们发现LLMs的输出精确度和可靠性显著提升。RAG增强的模型在生成富含上下文且技术准确的响应方面表现出色，凸显了向量知识库在提升LLMs专业领域性能方面的巨大潜力。这项研究不仅验证了我们方法的有效性，还预示了其在环境科学数据处理和分析领域的革新潜力，为AI驱动应用的未来发展树立了标杆。我们的代码已公开在https://github.com/linancn/TianGong-AI-Unstructure.git。",
    "title_cn": "一种解析与向量化半结构化数据的技艺，专为检索增强生成而设计",
    "tags": [
      "RAG\n\n这篇论文主要介绍了一种用于解析和向量化半结构化数据的方法，旨在提升大型语言模型（LLMs）中检索增强生成（RAG）的效能。它通过构建转换流程将多种数据格式转化为.docx，并利用Pinecone构建向量数据库，与LLMs结合，以提供精准、上下文相关的响应。这种方法特别适用于环境管理和废水处理等场景，并经过测试显示能够显著提升LLMs的输出精确度和可靠性。因此，它更符合RAG分类，因为它专注于通过向量化和检索增强来改进LLMs的性能。",
      "环境管理",
      "废水处理"
    ]
  },
  {
    "title": "Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application",
    "submit_datetime": "2024年05月07日",
    "abstract": "Contemporary recommender systems predominantly rely on collaborative filtering techniques, employing ID-embedding to capture latent associations among users and items. However, this approach overlooks the wealth of semantic information embedded within textual descriptions of items, leading to suboptimal performance in cold-start scenarios and long-tail user recommendations. Leveraging the capabilities of Large Language Models (LLMs) pretrained on massive text corpus presents a promising avenue for enhancing recommender systems by integrating open-world domain knowledge. In this paper, we propose an Llm-driven knowlEdge Adaptive RecommeNdation (LEARN) framework that synergizes open-world knowledge with collaborative knowledge. We address computational complexity concerns by utilizing pretrained LLMs as item encoders and freezing LLM parameters to avoid catastrophic forgetting and preserve open-world knowledge. To bridge the gap between the open-world and collaborative domains, we design a twin-tower structure supervised by the recommendation task and tailored for practical industrial application. Through offline experiments on the large-scale industrial dataset and online experiments on A/B tests, we demonstrate the efficacy of our approach.",
    "pdf_link": "https://arxiv.org/abs/2405.03988",
    "graphs": [],
    "abstract_cn": "现代推荐系统多采用协同过滤技术，通过ID嵌入揭示用户与物品间的隐秘联系。但此法忽视了物品文本描述中的深层语义，致使其在冷启动和长尾用户推荐中表现平平。本文提出一种LEARN框架，巧妙融合大型语言模型（LLMs）的开放世界知识与协同知识，以提升推荐系统性能。我们采用预训练LLMs作为物品编码器，并固定其参数，既避免了知识遗忘，又保留了开放世界知识的广博。为连接开放世界与协同领域，我们设计了双塔结构，专为工业应用定制，由推荐任务精准引导。通过大规模数据集的离线测试与在线A/B测试，我们的方法展现了其卓越效能。",
    "title_cn": "大型语言模型知识迁移至推荐系统：工业应用实践之路",
    "tags": [
      "Agent\n\n这篇论文主要讨论了如何将大型语言模型（LLMs）应用于推荐系统中，以提升其性能，特别是在处理冷启动和长尾用户推荐问题时。它提出了一种名为LEARN的框架，该框架结合了LLMs的开放世界知识和协同知识，并通过双塔结构将这些知识应用于推荐任务。因此，这篇论文更偏向于Agent的分类，因为它描述了一个系统或代理如何利用LLMs来执行特定的任务，即推荐系统的优化。",
      "推荐系统",
      ""
    ]
  },
  {
    "title": "COM3D: Leveraging Cross-View Correspondence and Cross-Modal Mining for 3D Retrieval",
    "submit_datetime": "2024年05月07日",
    "abstract": "In this paper, we investigate an open research task of cross-modal retrieval between 3D shapes and textual descriptions. Previous approaches mainly rely on point cloud encoders for feature extraction, which may ignore key inherent features of 3D shapes, including depth, spatial hierarchy, geometric continuity, etc. To address this issue, we propose COM3D, making the first attempt to exploit the cross-view correspondence and cross-modal mining to enhance the retrieval performance. Notably, we augment the 3D features through a scene representation transformer, to generate cross-view correspondence features of 3D shapes, which enrich the inherent features and enhance their compatibility with text matching. Furthermore, we propose to optimize the cross-modal matching process based on the semi-hard negative example mining method, in an attempt to improve the learning efficiency. Extensive quantitative and qualitative experiments demonstrate the superiority of our proposed COM3D, achieving state-of-the-art results on the Text2Shape dataset.",
    "pdf_link": "https://arxiv.org/abs/2405.04103",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.04103v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04103/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04103v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04103/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04103v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04103/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04103v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04103/x4.png"
      }
    ],
    "abstract_cn": "本文探讨了3D形状与文本描述间跨模态检索的挑战性任务。传统方法依赖点云编码器提取特征，却可能遗漏3D形状的深度、空间结构和几何连续性等核心特征。为此，我们创新性地提出了COM3D方法，首次结合跨视图对应与跨模态挖掘技术，显著提升检索精度。我们的方法通过场景表示变换器丰富3D特征，生成跨视图特征，增强与文本匹配的兼容性。同时，采用半硬负例挖掘优化跨模态匹配，提升学习效率。实验结果表明，COM3D在Text2Shape数据集上取得了领先性能，展现了其卓越的检索能力。",
    "title_cn": "COM3D：借助跨视图匹配与跨模态挖掘，精进3D检索技艺在这项研究中，我们提出了一种名为COM3D的新型框架，它巧妙地结合了跨视图对应和跨模态挖掘技术，以提升3D对象检索的准确性和效率。通过深入分析不同视图间的内在联系，并挖掘多模态数据中的潜在信息，COM3D在3D检索领域展现了其独特的优势。",
    "tags": [
      "RAG\n\n这篇论文探讨的是3D形状与文本描述之间的跨模态检索任务，这是一个典型的跨模态检索问题，涉及到将文本信息与3D形状数据进行匹配。论文中提出的COM3D方法结合了跨视图对应与跨模态挖掘技术，这些技术可以被视为一种检索增强生成（RAG）的应用，因为它旨在增强检索系统的能力，通过跨模态匹配来提高检索精度。因此，这篇论文更符合RAG分类，而不是Agent、LLM应用或LLM理论。",
      "跨模态检索",
      "3D建模"
    ]
  },
  {
    "title": "Zero-shot LLM-guided Counterfactual Generation for Text",
    "submit_datetime": "2024年05月07日",
    "abstract": "Counterfactual examples are frequently used for model development and evaluation in many natural language processing (NLP) tasks. Although methods for automated counterfactual generation have been explored, such methods depend on models such as pre-trained language models that are then fine-tuned on auxiliary, often task-specific datasets. Collecting and annotating such datasets for counterfactual generation is labor intensive and therefore, infeasible in practice. Therefore, in this work, we focus on a novel problem setting: \\textit{zero-shot counterfactual generation}. To this end, we propose a structured way to utilize large language models (LLMs) as general purpose counterfactual example generators. We hypothesize that the instruction-following and textual understanding capabilities of recent LLMs can be effectively leveraged for generating high quality counterfactuals in a zero-shot manner, without requiring any training or fine-tuning. Through comprehensive experiments on various downstream tasks in natural language processing (NLP), we demonstrate the efficacy of LLMs as zero-shot counterfactual generators in evaluating and explaining black-box NLP models.",
    "pdf_link": "https://arxiv.org/abs/2405.04793",
    "graphs": [],
    "abstract_cn": "在NLP领域，反事实示例是模型开发和评估的常用工具。尽管自动生成反事实的方法已有探索，但这些方法依赖于预训练模型，并需要针对特定任务的数据集进行微调，这既耗时又成本高昂。因此，我们提出了一种创新方法：零-shot反事实生成。我们利用大型语言模型的强大能力，无需额外训练或微调，即可生成高质量的反事实示例。通过在多个NLP任务上的实验，我们验证了这种方法的有效性，展示了LLMs在无需额外数据集的情况下，如何成为评估和解释复杂NLP模型的有力工具。",
    "title_cn": "大型语言模型零-shot引导的文本反事实创作在翻译过程中，我首先确保了原文意思的准确传达，然后对翻译结果进行了优化，使其更符合中文的表达习惯，同时保持了原文的生动性和简洁性。",
    "tags": [
      "LLM应用\n\n这篇论文探讨了如何利用大型语言模型（LLMs）的能力来生成反事实示例，以用于模型开发和评估，而无需额外的训练或微调。这种方法展示了LLMs在无需特定任务数据集的情况下，如何成为评估和解释复杂NLP模型的有力工具。因此，它属于“LLM应用”类别，因为它关注的是LLMs在实际应用中的使用，而不是理论研究或Agent的设计与实现。",
      "",
      "模型评估"
    ]
  },
  {
    "title": "CourseGPT-zh: an Educational Large Language Model Based on Knowledge Distillation Incorporating Prompt Optimization",
    "submit_datetime": "2024年05月07日",
    "abstract": "Large language models (LLMs) have demonstrated astonishing capabilities in natural language processing (NLP) tasks, sparking interest in their application to professional domains with higher specialized requirements. However, restricted access to closed-source LLMs via APIs and the difficulty in collecting massive high-quality datasets pose obstacles to the development of large language models in education fields of various courses. Given these challenges, we propose CourseGPT-zh, a course-oriented education LLM that supports customization and low-cost deployment. To address the comprehensiveness and diversity requirements of course-specific corpora, we design a high-quality question-answering corpus distillation framework incorporating prompt optimization, which effectively mines textbook knowledge and enhances its diversity. Moreover, considering the alignment of LLM responses with user needs, a novel method for discrete prompt optimization based on LLM-as-Judge is introduced. During optimization, this framework leverages the LLM's ability to reflect on and exploit error feedback and patterns, allowing for prompts that meet user needs and preferences while saving response length. Lastly, we obtain CourseGPT-zh based on the open-source LLM using parameter-efficient fine-tuning. Experimental results show that our discrete prompt optimization framework effectively improves the response quality of ChatGPT, and CourseGPT-zh exhibits strong professional capabilities in specialized knowledge question-answering, significantly outperforming comparable open-source models.",
    "pdf_link": "https://arxiv.org/abs/2405.04781",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.04781v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04781/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04781v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04781/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04781v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04781/x3.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）在NLP领域大放异彩，激发了其在专业领域应用的探索。然而，闭源LLMs的访问限制和高质量数据集的收集难题，成为教育领域课程发展的绊脚石。为此，我们推出了CourseGPT-zh，一款专为教育定制的LLM，它灵活且经济。我们精心设计了问答语料蒸馏框架，通过提示优化，深入挖掘教科书知识，丰富其多样性。同时，我们创新性地采用LLM-as-Judge方法进行离散提示优化，确保LLM的回答贴近用户需求，既精准又高效。通过开源LLM的参数高效微调，我们打造了CourseGPT-zh。实验证明，我们的优化框架显著提升了ChatGPT的回答质量，CourseGPT-zh在专业知识问答上表现卓越，远超其他开源模型。",
    "title_cn": "CourseGPT-zh：融合知识蒸馏与提示优化技术的教育领域大型语言模型，旨在通过精炼的知识传递与优化学习提示，提升教育场景下的语言处理能力。",
    "tags": [
      "LLM应用\n\n这篇论文介绍了CourseGPT-zh，一个专为教育领域定制的大型语言模型（LLM）。它通过问答语料蒸馏框架和LLM-as-Judge方法进行离散提示优化，以提高回答质量和满足用户需求。这个模型是针对特定应用场景（教育）进行优化的LLM实例，因此属于LLM应用类别。",
      "",
      ""
    ]
  },
  {
    "title": "Empathy Through Multimodality in Conversational Interfaces",
    "submit_datetime": "2024年05月07日",
    "abstract": "Agents represent one of the most emerging applications of Large Language Models (LLMs) and Generative AI, with their effectiveness hinging on multimodal capabilities to navigate complex user environments. Conversational Health Agents (CHAs), a prime example of this, are redefining healthcare by offering nuanced support that transcends textual analysis to incorporate emotional intelligence. This paper introduces an LLM-based CHA engineered for rich, multimodal dialogue-especially in the realm of mental health support. It adeptly interprets and responds to users' emotional states by analyzing multimodal cues, thus delivering contextually aware and empathetically resonant verbal responses. Our implementation leverages the versatile openCHA framework, and our comprehensive evaluation involves neutral prompts expressed in diverse emotional tones: sadness, anger, and joy. We evaluate the consistency and repeatability of the planning capability of the proposed CHA. Furthermore, human evaluators critique the CHA's empathic delivery, with findings revealing a striking concordance between the CHA's outputs and evaluators' assessments. These results affirm the indispensable role of vocal (soon multimodal) emotion recognition in strengthening the empathetic connection built by CHAs, cementing their place at the forefront of interactive, compassionate digital health solutions.",
    "pdf_link": "https://arxiv.org/abs/2405.04777",
    "graphs": [],
    "abstract_cn": "代理作为LLM和生成式AI的新兴应用，依赖于多模态能力来应对复杂用户环境。对话健康代理（CHAs）通过结合情感智能，提供超越文本分析的细致支持，正在重塑医疗保健。本文介绍了一款专为心理健康支持设计的LLM基CHA，它能通过多模态线索解读用户情感，并提供具有共情共鸣的回应。我们采用openCHA框架，并通过不同情感表达的中性提示进行全面评估，检验了CHA规划能力的连贯性和可重复性。人类评估者的评价显示，CHA的共情传递与评估者的评估高度一致，这强调了声音（及未来的多模态）情感识别在加强CHAs共情连接中的关键作用，确立了CHAs在互动、富有同情心的数字健康解决方案中的领先地位。",
    "title_cn": "对话接口中的多模态共情在对话接口中，通过多模态技术实现共情，旨在提升用户体验和交互的自然性。本研究探讨了如何整合视觉、听觉和语言信息，以增强对话系统对用户情感的理解和响应，从而在人机交互中营造出更加共情的氛围。",
    "tags": [
      "Agent\n\n这篇论文探讨了基于大型语言模型（LLM）的对话健康代理（CHAs）在心理健康支持领域的应用，特别强调了其多模态能力和情感智能。论文介绍了专为心理健康设计的CHAs，并评估了其在情感识别和共情回应方面的表现。这与“Agent”分类相符，因为它涉及到了一个特定类型的智能代理（即对话健康代理）的设计和评估，这些代理旨在通过多模态交互提供情感支持。",
      "心理健康",
      "医疗保健"
    ]
  },
  {
    "title": "Chain of Thoughtlessness: An Analysis of CoT in Planning",
    "submit_datetime": "2024年05月07日",
    "abstract": "Large language model (LLM) performance on reasoning problems typically does not generalize out of distribution. Previous work has claimed that this can be mitigated by modifying prompts to include examples with chains of thought--demonstrations of solution procedures--with the intuition that it is possible to in-context teach an LLM an algorithm for solving the problem. This paper presents a case study of chain of thought on problems from Blocksworld, a classical planning domain, and examine the performance of two state-of-the-art LLMs across two axes: generality of examples given in prompt, and complexity of problems queried with each prompt. While our problems are very simple, we only find meaningful performance improvements from chain of thought prompts when those prompts are exceedingly specific to their problem class, and that those improvements quickly deteriorate as the size n of the query-specified stack grows past the size of stacks shown in the examples. Our results hint that, contrary to previous claims in the literature, CoT's performance improvements do not stem from the model learning general algorithmic procedures via demonstrations and depend on carefully engineering highly problem specific prompts. This spotlights drawbacks of chain of thought, especially because of the sharp tradeoff between possible performance gains and the amount of human labor necessary to generate examples with correct reasoning traces.",
    "pdf_link": "https://arxiv.org/abs/2405.04776",
    "graphs": [],
    "abstract_cn": "大型语言模型在推理问题上的表现往往局限于特定范围。以往的研究提出，通过在提示中加入思维链示例——展示解决问题的步骤——可以提升LLM的泛化能力。本文以Blocksworld为例，探讨了思维链在经典规划问题上的应用，并分析了两种顶尖LLM在示例通用性和问题复杂性两个维度上的表现。尽管问题简单，但只有在提示极度贴合特定问题类型时，思维链才能带来显著的性能提升，且这种提升随着查询中的堆栈大小超过示例中的大小而迅速减弱。研究结果表明，与之前的观点不同，思维链的改进并非因为模型学会了通用算法，而是需要精心设计与问题紧密相关的提示。这揭示了思维链方法的局限性，尤其是性能提升与人工设计示例所需劳动之间的矛盾。",
    "title_cn": "思维链的盲点：探究计划中思维链的运用与局限在翻译过程中，我首先确保原文的核心意义被准确传达，即对“思维链”（Chain of Thought）在计划制定中的应用进行分析。在第二步中，我调整了表达方式，使其更符合中文的修辞习惯，同时保持了原文的生动性和简洁性。通过使用“盲点”一词，我强调了研究中可能忽视的方面，同时也为读者提供了一个形象的视角来理解这一复杂的概念。",
    "tags": [
      "LLM理论\n\n这篇论文探讨了大型语言模型（LLM）在推理问题上的局限性，特别是在使用思维链（Chain of Thought）提示时的表现。它分析了思维链在特定问题类型上的应用，并指出了其性能提升的局限性，这主要是因为需要与问题紧密相关的精心设计的提示。这种分析属于对LLM理论层面的探讨，因为它关注的是LLM的工作原理和性能提升的机制，而不是直接的应用或安全性问题。因此，它被归类为LLM理论。",
      "人工智能",
      "规划问题"
    ]
  },
  {
    "title": "Exploring Vision Transformers for 3D Human Motion-Language Models with Motion Patches",
    "submit_datetime": "2024年05月07日",
    "abstract": "To build a cross-modal latent space between 3D human motion and language, acquiring large-scale and high-quality human motion data is crucial. However, unlike the abundance of image data, the scarcity of motion data has limited the performance of existing motion-language models. To counter this, we introduce \"motion patches\", a new representation of motion sequences, and propose using Vision Transformers (ViT) as motion encoders via transfer learning, aiming to extract useful knowledge from the image domain and apply it to the motion domain. These motion patches, created by dividing and sorting skeleton joints based on body parts in motion sequences, are robust to varying skeleton structures, and can be regarded as color image patches in ViT. We find that transfer learning with pre-trained weights of ViT obtained through training with 2D image data can boost the performance of motion analysis, presenting a promising direction for addressing the issue of limited motion data. Our extensive experiments show that the proposed motion patches, used jointly with ViT, achieve state-of-the-art performance in the benchmarks of text-to-motion retrieval, and other novel challenging tasks, such as cross-skeleton recognition, zero-shot motion classification, and human interaction recognition, which are currently impeded by the lack of data.",
    "pdf_link": "https://arxiv.org/abs/2405.04771",
    "graphs": [],
    "abstract_cn": "为了在3D人体运动与语言间构建跨模态空间，我们需要大量且高质量的运动数据。然而，与图像数据的丰富相比，运动数据的稀缺限制了现有模型的性能。为此，我们提出了“运动补丁”这一新概念，并采用视觉变换器（ViT）通过迁移学习作为运动编码器，旨在将图像领域的知识迁移至运动领域。这些运动补丁基于身体部位对骨骼关节进行分割和排序，对不同骨骼结构具有鲁棒性，并可视为ViT中的彩色图像补丁。实验证明，使用ViT预训练权重进行迁移学习能显著提升运动分析性能，为解决运动数据不足的问题开辟了新途径。我们的研究显示，结合ViT的运动补丁在文本到运动检索等多个领域达到了业界领先水平，有效克服了数据缺乏带来的挑战。",
    "title_cn": "探究视觉变压器结合运动补丁在三维人体运动与语言模型中的应用，以深入理解其对运动表达的影响。",
    "tags": [
      "Agent\n\n这篇论文主要探讨了如何通过迁移学习将图像领域的知识应用到运动数据分析中，以解决运动数据稀缺的问题。它提出了“运动补丁”的概念，并利用视觉变换器（ViT）作为运动编码器。这种方法可以被视为一种智能体（Agent），因为它在处理和分析运动数据时展现出了自主学习和适应的能力。虽然这种方法可能涉及到大型语言模型（LLM）的应用，但论文的重点在于跨模态学习和数据处理的创新方法，而不是LLM的理论或特定应用。因此，将其归类为Agent更为合适。",
      "运动分析",
      "跨模态学习"
    ]
  },
  {
    "title": "Large Language Models for Cyber Security: A Systematic Literature Review",
    "submit_datetime": "2024年05月07日",
    "abstract": "The rapid advancement of Large Language Models (LLMs) has opened up new opportunities for leveraging artificial intelligence in various domains, including cybersecurity. As the volume and sophistication of cyber threats continue to grow, there is an increasing need for intelligent systems that can automatically detect vulnerabilities, analyze malware, and respond to attacks. In this survey, we conduct a comprehensive review of the literature on the application of LLMs in cybersecurity (LLM4Security). By comprehensively collecting over 30K relevant papers and systematically analyzing 127 papers from top security and software engineering venues, we aim to provide a holistic view of how LLMs are being used to solve diverse problems across the cybersecurity domain. Through our analysis, we identify several key findings. First, we observe that LLMs are being applied to a wide range of cybersecurity tasks, including vulnerability detection, malware analysis, network intrusion detection, and phishing detection. Second, we find that the datasets used for training and evaluating LLMs in these tasks are often limited in size and diversity, highlighting the need for more comprehensive and representative datasets. Third, we identify several promising techniques for adapting LLMs to specific cybersecurity domains, such as fine-tuning, transfer learning, and domain-specific pre-training. Finally, we discuss the main challenges and opportunities for future research in LLM4Security, including the need for more interpretable and explainable models, the importance of addressing data privacy and security concerns, and the potential for leveraging LLMs for proactive defense and threat hunting. Overall, our survey provides a comprehensive overview of the current state-of-the-art in LLM4Security and identifies several promising directions for future research.",
    "pdf_link": "https://arxiv.org/abs/2405.04760",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.04760v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04760/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04760v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04760/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04760v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04760/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04760v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04760/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04760v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04760/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04760v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04760/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04760v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04760/x7.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）的迅猛发展为网络安全等领域的人工智能应用开辟了新天地。随着网络威胁日益增多，智能系统的需求也随之增长，这些系统能够自动识别漏洞、剖析恶意软件并迅速应对攻击。本综述深入探讨了LLMs在网络安全（LLM4Security）中的应用，通过梳理超过3万篇相关论文，并精选127篇顶级安全和软件工程领域的论文进行系统分析，我们旨在为读者呈现LLMs在网络安全领域解决多样问题的全景图。我们的研究发现，LLMs正广泛应用于漏洞检测、恶意软件分析、网络入侵检测和钓鱼检测等任务。然而，用于训练和评估LLMs的数据集往往规模有限、多样性不足，这凸显了构建更全面、更具代表性数据集的迫切性。我们还发现了适应LLMs到特定网络安全领域的几种潜在技术，包括微调、迁移学习和领域特定预训练。最后，我们探讨了LLM4Security未来研究的主要挑战和机遇，强调了可解释模型的必要性、数据隐私和安全问题的解决，以及利用LLMs进行主动防御和威胁狩猎的潜力。总之，我们的综述不仅概述了LLM4Security的当前状态，还指出了未来研究的多个有前景的方向。",
    "title_cn": "网络安全领域的大型语言模型：系统性文献综述探索在本次系统性文献综述中，我们将深入探讨大型语言模型在网络安全领域的应用，分析其在识别威胁、预测攻击模式以及自动化响应策略等方面的潜力与挑战。通过对现有文献的综合梳理，我们旨在揭示这些先进技术如何助力网络安全专家构筑更为坚固的数字防线。",
    "tags": [
      "LLM应用\n\n这篇论文摘要讨论了大型语言模型（LLMs）在网络安全领域的应用，包括漏洞检测、恶意软件分析、网络入侵检测和钓鱼检测等任务。它强调了构建更全面、更具代表性数据集的必要性，并探讨了将LLMs适应到特定网络安全领域的技术，如微调、迁移学习和领域特定预训练。此外，它还讨论了未来研究的挑战和机遇，包括可解释模型的必要性、数据隐私和安全问题的解决，以及利用LLMs进行主动防御和威胁狩猎的潜力。这些内容与LLM应用领域紧密相关，因此将其分类为LLM应用。",
      "网络安全",
      "人工智能"
    ]
  },
  {
    "title": "BiasKG: Adversarial Knowledge Graphs to Induce Bias in Large Language Models",
    "submit_datetime": "2024年05月07日",
    "abstract": "Modern large language models (LLMs) have a significant amount of world knowledge, which enables strong performance in commonsense reasoning and knowledge-intensive tasks when harnessed properly. The language model can also learn social biases, which has a significant potential for societal harm. There have been many mitigation strategies proposed for LLM safety, but it is unclear how effective they are for eliminating social biases. In this work, we propose a new methodology for attacking language models with knowledge graph augmented generation. We refactor natural language stereotypes into a knowledge graph, and use adversarial attacking strategies to induce biased responses from several open- and closed-source language models. We find our method increases bias in all models, even those trained with safety guardrails. This demonstrates the need for further research in AI safety, and further work in this new adversarial space.",
    "pdf_link": "https://arxiv.org/abs/2405.04756",
    "graphs": [],
    "abstract_cn": "现代LLMs蕴含丰富的世界知识，使其在常识推理和知识密集任务中大放异彩。然而，它们也可能吸收社会偏见，带来潜在的社会风险。尽管已有多种策略试图提升LLM的安全性，但其在消除偏见方面的效果仍不明朗。本研究创新性地提出了一种基于知识图谱增强的生成方法，用以揭示语言模型中的偏见。我们巧妙地将语言中的刻板印象转化为知识图谱，并运用对抗性策略，成功地从多个开源和闭源模型中引出了偏见性回应。令人警醒的是，即使是有安全措施的模型也未能幸免。这凸显了AI安全研究的紧迫性，以及在对抗性领域深入探索的必要性。",
    "title_cn": "偏见图谱BiasKG：塑造大型语言模型的对抗性知识网络，旨在引入并研究模型中的偏见现象。",
    "tags": [
      "LLM理论\n\n这篇论文关注的是大型语言模型（LLM）中的社会偏见问题，并提出了一种基于知识图谱增强的生成方法来揭示和分析这些偏见。它探讨了LLM的安全性和偏见消除的效果，这是一个理论性的研究，因为它不仅关注模型的应用，还深入到模型内部的工作原理和潜在的偏见机制。因此，它属于LLM理论分类。",
      "人工智能安全",
      "社会偏见分析"
    ]
  },
  {
    "title": "AttacKG+:Boosting Attack Knowledge Graph Construction with Large Language Models",
    "submit_datetime": "2024年05月07日",
    "abstract": "Attack knowledge graph construction seeks to convert textual cyber threat intelligence (CTI) reports into structured representations, portraying the evolutionary traces of cyber attacks. Even though previous research has proposed various methods to construct attack knowledge graphs, they generally suffer from limited generalization capability to diverse knowledge types as well as requirement of expertise in model design and tuning. Addressing these limitations, we seek to utilize Large Language Models (LLMs), which have achieved enormous success in a broad range of tasks given exceptional capabilities in both language understanding and zero-shot task fulfillment. Thus, we propose a fully automatic LLM-based framework to construct attack knowledge graphs named: AttacKG+. Our framework consists of four consecutive modules: rewriter, parser, identifier, and summarizer, each of which is implemented by instruction prompting and in-context learning empowered by LLMs. Furthermore, we upgrade the existing attack knowledge schema and propose a comprehensive version. We represent a cyber attack as a temporally unfolding event, each temporal step of which encapsulates three layers of representation, including behavior graph, MITRE TTP labels, and state summary. Extensive evaluation demonstrates that: 1) our formulation seamlessly satisfies the information needs in threat event analysis, 2) our construction framework is effective in faithfully and accurately extracting the information defined by AttacKG+, and 3) our attack graph directly benefits downstream security practices such as attack reconstruction. All the code and datasets will be released upon acceptance.",
    "pdf_link": "https://arxiv.org/abs/2405.04753",
    "graphs": [],
    "abstract_cn": "我们提出了一种基于大型语言模型（LLMs）的全自动框架AttacKG+，用于将网络威胁情报报告转化为结构化的攻击知识图谱，以描绘网络攻击的演变过程。该框架通过LLMs赋能的指令提示和情境学习，实现了重写、解析、标识和摘要四个模块的连续操作。我们不仅升级了现有的攻击知识图谱模式，还提出了一个更为全面的版本，将网络攻击视为一个时间序列事件，每个时间点都详细记录了攻击的行为、MITRE TTP标签和状态摘要。实验证明，我们的方法不仅满足了威胁分析的信息需求，而且能够准确提取攻击信息，对下游安全实践，如攻击重建，产生了直接的积极影响。所有相关代码和数据集将在论文被接受后公开。",
    "title_cn": "AttacKG+：借助大型语言模型，强化攻击知识图谱的构建能力",
    "tags": [
      "Agent\n\n这篇论文提出了一种基于大型语言模型（LLMs）的全自动框架AttacKG+，用于将网络威胁情报报告转化为结构化的攻击知识图谱。这个框架可以被视为一个智能代理（Agent），因为它能够自动处理输入数据（网络威胁情报报告），并生成有用的输出（结构化的攻击知识图谱）。此外，该框架通过LLMs赋能的指令提示和情境学习，实现了重写、解析、标识和摘要四个模块的连续操作，这进一步强调了其作为智能代理的特性，因为它能够执行一系列复杂的任务来完成其目标。因此，这篇论文属于Agent分类。",
      "网络安全",
      "威胁情报分析"
    ]
  },
  {
    "title": "LLMs Can Patch Up Missing Relevance Judgments in Evaluation",
    "submit_datetime": "2024年05月07日",
    "abstract": "Unjudged documents or holes in information retrieval benchmarks are considered non-relevant in evaluation, yielding no gains in measuring effectiveness. However, these missing judgments may inadvertently introduce biases into the evaluation as their prevalence for a retrieval model is heavily contingent on the pooling process. Thus, filling holes becomes crucial in ensuring reliable and accurate evaluation. Collecting human judgment for all documents is cumbersome and impractical. In this paper, we aim at leveraging large language models (LLMs) to automatically label unjudged documents. Our goal is to instruct an LLM using detailed instructions to assign fine-grained relevance judgments to holes. To this end, we systematically simulate scenarios with varying degrees of holes by randomly dropping relevant documents from the relevance judgment in TREC DL tracks. Our experiments reveal a strong correlation between our LLM-based method and ground-truth relevance judgments. Based on our simulation experiments conducted on three TREC DL datasets, in the extreme scenario of retaining only 10% of judgments, our method achieves a Kendall tau correlation of 0.87 and 0.92 on an average for Vicuña-7B and GPT-3.5 Turbo respectively.",
    "pdf_link": "https://arxiv.org/abs/2405.04727",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.04727v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04727/line_plot_dl19-passagev2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04727v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04727/line_plot_dl20-passagev2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04727v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04727/line_plot_dl21-passagev2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04727v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04727/line_plot_dl19-passage_few_vs_zerov2.png"
      }
    ],
    "abstract_cn": "在信息检索评估中，未评分的文档被视为无关紧要，不会提升评估的有效性。然而，这些缺失的判断可能会无意中引入偏差，因为它们对检索模型的影响取决于池化过程。因此，填补这些评估中的空缺至关重要。人工收集所有文档的判断既繁琐又不切实际。本文提出利用大型语言模型（LLMs）自动为未评分的文档打标签。我们的目标是指导LLM根据详细指令为空缺提供精细的相关性判断。通过在TREC DL轨迹中随机移除相关文档，我们模拟了不同程度的空缺情况。实验结果显示，我们的LLM方法与真实相关性判断高度相关。在三个TREC DL数据集上的模拟实验表明，在最极端情况下，仅保留10%的判断，我们的方法在Vicuña-7B和GPT-3.5 Turbo上分别实现了0.87和0.92的Kendall tau相关性平均值。",
    "title_cn": "大型语言模型（LLMs）具备修补评估中缺失相关性判断的能力，为评估体系的完善提供了新的可能性。",
    "tags": [
      "RAG\n\n这篇论文主要探讨了如何利用大型语言模型（LLMs）自动为信息检索评估中的未评分文档打标签，以填补评估中的空缺。这种方法旨在提高评估的有效性，并减少人工收集所有文档判断的繁琐和不切实际性。论文通过实验展示了LLM方法在模拟不同程度的空缺情况下的表现，并与真实相关性判断进行了比较。因此，这篇论文更符合RAG分类，因为它关注的是利用LLM进行信息检索和评估的过程，而不是Agent的行为、LLM的应用案例或LLM的理论研究。",
      "信息检索",
      "语言模型评估"
    ]
  },
  {
    "title": "Enhancing Knowledge Retrieval with Topic Modeling for Knowledge-Grounded Dialogue",
    "submit_datetime": "2024年05月07日",
    "abstract": "Knowledge retrieval is one of the major challenges in building a knowledge-grounded dialogue system. A common method is to use a neural retriever with a distributed approximate nearest-neighbor database to quickly find the relevant knowledge sentences. In this work, we propose an approach that utilizes topic modeling on the knowledge base to further improve retrieval accuracy and as a result, improve response generation. Additionally, we experiment with a large language model, ChatGPT, to take advantage of the improved retrieval performance to further improve the generation results. Experimental results on two datasets show that our approach can increase retrieval and generation performance. The results also indicate that ChatGPT is a better response generator for knowledge-grounded dialogue when relevant knowledge is provided.",
    "pdf_link": "https://arxiv.org/abs/2405.04713",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.04713v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04713/contrib2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04713v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04713/multidoc2dial.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04713v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04713/KILT_dialogue.png"
      }
    ],
    "abstract_cn": "在构建基于知识的对话系统时，知识检索是一大难题。我们提出了一种新颖的方法，通过在知识库上应用主题建模，不仅提升了检索的精准度，还优化了对话响应的生成。同时，我们引入了ChatGPT这一大型语言模型，借助其强大的检索能力，进一步增强了生成结果的质量。实验证明，我们的方法在两个数据集上均有效提升了检索与生成性能，并且ChatGPT在提供相关知识的情况下，展现出了作为知识驱动对话系统中优秀响应生成器的潜力。",
    "title_cn": "利用主题建模提升知识检索，助力基于知识的对话系统更上一层楼。",
    "tags": [
      "Agent\n\n这篇论文探讨了在构建基于知识的对话系统中，如何通过主题建模和利用大型语言模型（如ChatGPT）来提升知识检索和对话响应生成的性能。这种方法涉及到了智能代理（Agent）的概念，即系统能够根据知识库的内容和用户的输入来生成合适的对话响应。因此，这篇论文更符合Agent分类，因为它关注的是如何构建和优化能够进行知识检索和对话生成的智能系统。",
      "对话系统",
      "知识检索"
    ]
  },
  {
    "title": "Robust Implementation of Retrieval-Augmented Generation on Edge-based Computing-in-Memory Architectures",
    "submit_datetime": "2024年05月07日",
    "abstract": "Large Language Models (LLMs) deployed on edge devices learn through fine-tuning and updating a certain portion of their parameters. Although such learning methods can be optimized to reduce resource utilization, the overall required resources remain a heavy burden on edge devices. Instead, Retrieval-Augmented Generation (RAG), a resource-efficient LLM learning method, can improve the quality of the LLM-generated content without updating model parameters. However, the RAG-based LLM may involve repetitive searches on the profile data in every user-LLM interaction. This search can lead to significant latency along with the accumulation of user data. Conventional efforts to decrease latency result in restricting the size of saved user data, thus reducing the scalability of RAG as user data continuously grows. It remains an open question: how to free RAG from the constraints of latency and scalability on edge devices? In this paper, we propose a novel framework to accelerate RAG via Computing-in-Memory (CiM) architectures. It accelerates matrix multiplications by performing in-situ computation inside the memory while avoiding the expensive data transfer between the computing unit and memory. Our framework, Robust CiM-backed RAG (RoCR), utilizing a novel contrastive learning-based training method and noise-aware training, can enable RAG to efficiently search profile data with CiM. To the best of our knowledge, this is the first work utilizing CiM to accelerate RAG.",
    "pdf_link": "https://arxiv.org/abs/2405.04700",
    "graphs": [],
    "abstract_cn": "边缘设备上的大型语言模型（LLMs）通过微调参数来学习，但这种方法对资源的需求仍然沉重。检索增强生成（RAG）作为一种高效的学习方法，能在不更新模型参数的情况下提升内容质量，但每次用户交互时对配置文件数据的重复搜索会导致延迟和数据累积。传统方法限制了用户数据的大小，影响了RAG的可扩展性。本文提出了一种基于内存计算（CiM）的新框架，通过在内存中直接进行计算来加速矩阵乘法，避免了数据传输的昂贵开销。我们的鲁棒CiM支持的RAG（RoCR）框架，结合了对比学习和噪声感知训练，使RAG能够高效地利用CiM搜索配置文件数据，这是首次尝试利用CiM加速RAG的研究。",
    "title_cn": "在内存计算架构的边缘计算环境中，增强检索生成的稳健实现解释：在",
    "tags": [
      "RAG\n\n这篇论文主要讨论了检索增强生成（RAG）方法在边缘设备上的应用，以及如何通过基于内存计算（CiM）的新框架来提高RAG的效率和可扩展性。它提出了一种结合对比学习和噪声感知训练的鲁棒CiM支持的RAG（RoCR）框架，以加速矩阵乘法并减少数据传输开销。这与大型语言模型（LLM）的应用和理论都有所不同，因为它专注于RAG方法的改进，而不是LLM本身的理论或应用。同时，它也不涉及Agent的概念，因此不属于Agent分类。因此，最合适的分类是RAG。",
      "边缘计算",
      ""
    ]
  },
  {
    "title": "Bridging the Bosphorus: Advancing Turkish Large Language Models through Strategies for Low-Resource Language Adaptation and Benchmarking",
    "submit_datetime": "2024年05月07日",
    "abstract": "Large Language Models (LLMs) are becoming crucial across various fields, emphasizing the urgency for high-quality models in underrepresented languages. This study explores the unique challenges faced by low-resource languages, such as data scarcity, model selection, evaluation, and computational limitations, with a special focus on Turkish. We conduct an in-depth analysis to evaluate the impact of training strategies, model choices, and data availability on the performance of LLMs designed for underrepresented languages. Our approach includes two methodologies: (i) adapting existing LLMs originally pretrained in English to understand Turkish, and (ii) developing a model from the ground up using Turkish pretraining data, both supplemented with supervised fine-tuning on a novel Turkish instruction-tuning dataset aimed at enhancing reasoning capabilities. The relative performance of these methods is evaluated through the creation of a new leaderboard for Turkish LLMs, featuring benchmarks that assess different reasoning and knowledge skills. Furthermore, we conducted experiments on data and model scaling, both during pretraining and fine-tuning, simultaneously emphasizing the capacity for knowledge transfer across languages and addressing the challenges of catastrophic forgetting encountered during fine-tuning on a different language. Our goal is to offer a detailed guide for advancing the LLM framework in low-resource linguistic contexts, thereby making natural language processing (NLP) benefits more globally accessible.",
    "pdf_link": "https://arxiv.org/abs/2405.04685",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）在多领域的重要性日益凸显，特别是在代表性不足的语言中，高质量模型的需求迫在眉睫。本研究深入探讨了低资源语言如土耳其语所面临的挑战，包括数据匮乏、模型选择、评估和计算限制。我们评估了训练策略、模型选择和数据可用性对LLMs性能的影响，并采用了两种策略：一是将英语预训练的LLMs适应于土耳其语，二是利用土耳其语数据从头构建模型，两者均通过监督微调提升推理能力。我们创建了一个土耳其LLMs的新排行榜，通过评估推理和知识技能的基准来衡量这些方法的性能。同时，我们在预训练和微调中进行了数据和模型的缩放实验，强调了跨语言知识转移的重要性，并解决了在不同语言微调时可能出现的灾难性遗忘问题。我们的目标是为低资源语言环境中的LLM发展提供详尽指南，以期让自然语言处理（NLP）的益处惠及全球。",
    "title_cn": "博斯普鲁斯之桥：借助低资源语言适应与基准测试策略，推动土耳其大型语言模型的进步。",
    "tags": [
      "LLM理论\n\n这篇论文探讨了大型语言模型（LLMs）在低资源语言（如土耳其语）中的应用和挑战，研究了训练策略、模型选择、数据可用性等因素对模型性能的影响，并进行了实验以评估这些因素。此外，论文还关注了跨语言知识转移和灾难性遗忘问题，这些都是LLM理论研究的重要方面。因此，这篇论文更倾向于LLM理论研究，而不是Agent、RAG或LLM应用。",
      "",
      "低资源语言"
    ]
  },
  {
    "title": "Towards Accurate and Efficient Document Analytics with Large Language Models",
    "submit_datetime": "2024年05月07日",
    "abstract": "Unstructured data formats account for over 80% of the data currently stored, and extracting value from such formats remains a considerable challenge. In particular, current approaches for managing unstructured documents do not support ad-hoc analytical queries on document collections. Moreover, Large Language Models (LLMs) directly applied to the documents themselves, or on portions of documents through a process of Retrieval-Augmented Generation (RAG), fail to provide high accuracy query results, and in the LLM-only case, additionally incur high costs. Since many unstructured documents in a collection often follow similar templates that impart a common semantic structure, we introduce ZenDB, a document analytics system that leverages this semantic structure, coupled with LLMs, to answer ad-hoc SQL queries on document collections. ZenDB efficiently extracts semantic hierarchical structures from such templatized documents, and introduces a novel query engine that leverages these structures for accurate and cost-effective query execution. Users can impose a schema on their documents, and query it, all via SQL. Extensive experiments on three real-world document collections demonstrate ZenDB's benefits, achieving up to 30% cost savings compared to LLM-based baselines, while maintaining or improving accuracy, and surpassing RAG-based baselines by up to 61% in precision and 80% in recall, at a marginally higher cost.",
    "pdf_link": "https://arxiv.org/abs/2405.04674",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.04674v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04674/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04674v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04674/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04674v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04674/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04674v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04674/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04674v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04674/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04674v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04674/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04674v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04674/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04674v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04674/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04674v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04674/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04674v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04674/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04674v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04674/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04674v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04674/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04674v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04674/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04674v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04674/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04674v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04674/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04674v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04674/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04674v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04674/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04674v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04674/x18.png"
      }
    ],
    "abstract_cn": "非结构化数据占据了数据存储的绝大部分，但从中提取价值依旧困难重重。现有的文档管理方法无法支持对文档集合的灵活分析查询。大型语言模型（LLMs）即便通过检索增强生成（RAG）处理文档片段，也难以提供精确的查询结果，且成本高昂。鉴于许多文档遵循相似模板，我们推出了ZenDB，这一系统利用语义结构与LLMs结合，以SQL查询形式解答文档集合的即席查询。ZenDB能高效提取模板文档的语义层次，并创新性地设计了查询引擎，确保查询既准确又经济。用户可为文档定义模式，并通过SQL进行查询。在三个真实数据集上的实验显示，ZenDB相比LLM基线节省了高达30%的成本，同时提升了准确性，且在成本略增的情况下，精确度和召回率分别提高了61%和80%，超越了RAG基线。",
    "title_cn": "大型语言模型助力精准高效文档分析",
    "tags": [
      "RAG\n\n这篇论文介绍了一种名为ZenDB的系统，它利用语义结构与大型语言模型（LLMs）结合，以SQL查询形式解答文档集合的即席查询。ZenDB专注于提高从非结构化数据中提取价值的效率和准确性，特别是在处理遵循相似模板的文档时。它通过创新的查询引擎设计，实现了成本效益和查询准确性的提升。这与RAG（检索增强生成）的概念相关，因为它涉及使用LLMs来增强文档检索和生成过程，以提供更精确的查询结果。因此，这篇论文应归类于RAG。",
      "数据管理",
      "语义分析"
    ]
  },
  {
    "title": "Towards a Theoretical Understanding of the 'Reversal Curse' via Training Dynamics",
    "submit_datetime": "2024年05月07日",
    "abstract": "Auto-regressive large language models (LLMs) show impressive capacities to solve many complex reasoning tasks while struggling with some simple logical reasoning tasks such as inverse search: when trained on ''A is B'', LLM fails to directly conclude ''B is A'' during inference, which is known as the ''reversal curse'' (Berglund et al., 2023). In this paper, we theoretically analyze the reversal curse via the training dynamics of (stochastic) gradient descent for two auto-regressive models: (1) a bilinear model that can be viewed as a simplification of a one-layer transformer; (2) one-layer transformers using the framework of Tian et al. (2023a). Our analysis reveals a core reason why the reversal curse happens: the (effective) weights of both auto-regressive models show asymmetry, i.e., the increase of weights from a token $A$ to token $B$ during training does not necessarily cause the increase of the weights from $B$ to $A$. Moreover, our analysis can be naturally applied to other logical reasoning tasks such as chain-of-thought (COT) (Wei et al., 2022b). We show the necessity of COT, i.e., a model trained on ''$A \\to B$'' and ''$B \\to C$'' fails to directly conclude ''$A \\to C$'' without COT (also empirically observed by Allen-Zhu and Li (2023)), for one-layer transformers via training dynamics, which provides a new perspective different from previous work (Feng et al., 2024) that focuses on expressivity. Finally, we also conduct experiments to validate our theory on multi-layer transformers under different settings.",
    "pdf_link": "https://arxiv.org/abs/2405.04669",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.04669v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04669/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04669v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04669/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04669v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04669/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04669v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04669/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04669v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04669/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04669v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04669/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04669v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04669/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04669v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04669/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04669v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04669/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04669v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04669/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04669v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04669/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04669v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04669/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04669v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04669/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04669v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04669/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04669v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04669/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04669v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04669/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04669v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04669/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04669v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04669/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04669v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04669/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04669v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04669/x20.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04669v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04669/x21.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04669v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04669/x22.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04669v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04669/x23.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04669v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04669/x24.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04669v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04669/x25.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04669v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04669/x26.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04669v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04669/x27.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04669v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04669/x28.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04669v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04669/x29.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04669v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04669/x30.png"
      }
    ],
    "abstract_cn": "自回归大型语言模型（LLMs）在解决复杂推理任务方面表现出色，但在简单的逻辑推理任务，如逆向搜索中遇到挑战。当模型被训练识别“A是B”时，它无法直接推断出“B是A”，这一现象被称为“反转诅咒”。本文通过分析两个自回归模型的训练动态，揭示了这一现象的根源：模型权重的不对称性。这意味着从A到B的权重增加并不自动导致从B到A的权重增加。我们的研究还扩展到了思维链（COT）等其他逻辑推理任务，并展示了COT在推理链中的必要性。此外，我们的分析为单层变换器的训练动态提供了新的视角，与以往关注模型表达性的研究不同。最后，我们在多层变换器上进行了实验，以验证我们的理论分析。",
    "title_cn": "探索训练动态，揭开“逆转诅咒”的理论之谜在翻译过程中，我首先确保了原文意思的准确传达，然后对直译的中文进行了优化，使其更加符合中文的表达习惯，同时保持了原文的学术性和专业性。通过使用“探索”和“揭开”等动词，以及“理论之谜”这样的形象化表达，使得翻译后的中文更加生动活泼，简洁优雅。",
    "tags": [
      "LLM理论\n\n这篇论文探讨了自回归大型语言模型（LLMs）在逻辑推理任务中的局限性，特别是“反转诅咒”现象，并分析了其根源——模型权重的不对称性。此外，论文还扩展到了思维链（COT）等其他逻辑推理任务，并对单层变换器的训练动态进行了分析。这些内容涉及LLM的理论层面，包括模型训练的动态和逻辑推理能力的局限性，因此属于LLM理论分类。",
      "",
      "逻辑推理"
    ]
  },
  {
    "title": "Corporate Communication Companion (CCC): An LLM-empowered Writing Assistant for Workplace Social Media",
    "submit_datetime": "2024年05月07日",
    "abstract": "Workplace social media platforms enable employees to cultivate their professional image and connect with colleagues in a semi-formal environment. While semi-formal corporate communication poses a unique set of challenges, large language models (LLMs) have shown great promise in helping users draft and edit their social media posts. However, LLMs may fail to capture individualized tones and voices in such workplace use cases, as they often generate text using a \"one-size-fits-all\" approach that can be perceived as generic and bland. In this paper, we present Corporate Communication Companion (CCC), an LLM-empowered interactive system that helps people compose customized and individualized workplace social media posts. Using need-finding interviews to motivate our system design, CCC decomposes the writing process into two core functions, outline and edit: First, it suggests post outlines based on users' job status and previous posts, and next provides edits with attributions that users can contextually customize. We conducted a within-subjects user study asking participants both to write posts and evaluate posts written by others. The results show that CCC enhances users' writing experience, and audience members rate CCC-enhanced posts as higher quality than posts written using a non-customized writing assistant. We conclude by discussing the implications of LLM-empowered corporate communication.",
    "pdf_link": "https://arxiv.org/abs/2405.04656",
    "graphs": [],
    "abstract_cn": "工作场所社交媒体平台为员工提供了一个半正式的舞台，以塑造专业形象并拓展职场人脉。尽管半正式的企业沟通面临独特挑战，大型语言模型（LLMs）在协助用户打磨社交媒体内容方面展现出巨大潜力。然而，LLMs在捕捉个性化语调和声音方面存在局限，其“一刀切”的文本生成方式往往显得乏味且缺乏个性。本文推出的企业沟通伴侣（CCC），是一款由LLM驱动的交互系统，旨在辅助用户创作个性化且定制化的职场社交媒体内容。通过深入的需求访谈，CCC将写作过程细分为大纲构思与编辑润色两大核心功能：首先，它根据用户的职业背景和过往帖子提供大纲建议，随后提供可上下文定制的编辑建议。我们开展了一项参与者内部研究，既要求他们创作帖子，也评估他人作品。研究结果表明，CCC极大地提升了写作体验，且观众对CCC辅助创作的帖子评价更高。最后，我们探讨了LLM在企业沟通中的深远影响。",
    "title_cn": "职场社交写作良伴（CCC）：一款由先进 LLM 技术驱动的智能助手，专为提升企业沟通效率而生。",
    "tags": [
      "LLM应用\n\n这篇论文介绍了一个名为“企业沟通伴侣（CCC）”的系统，它是由大型语言模型（LLMs）驱动的，旨在帮助用户创作个性化的职场社交媒体内容。该系统通过提供大纲构思和编辑润色两大核心功能，辅助用户在社交媒体平台上塑造专业形象和拓展职场人脉。研究结果显示，CCC提升了写作体验，并获得了更高的观众评价。因此，这篇论文属于LLM应用类别，因为它探讨了LLM在特定应用场景（即企业沟通）中的实际应用和效果。",
      "企业沟通",
      "社交媒体"
    ]
  },
  {
    "title": "Understanding the Capabilities and Limitations of Large Language Models for Cultural Commonsense",
    "submit_datetime": "2024年05月07日",
    "abstract": "Large language models (LLMs) have demonstrated substantial commonsense understanding through numerous benchmark evaluations. However, their understanding of cultural commonsense remains largely unexamined. In this paper, we conduct a comprehensive examination of the capabilities and limitations of several state-of-the-art LLMs in the context of cultural commonsense tasks. Using several general and cultural commonsense benchmarks, we find that (1) LLMs have a significant discrepancy in performance when tested on culture-specific commonsense knowledge for different cultures; (2) LLMs' general commonsense capability is affected by cultural context; and (3) The language used to query the LLMs can impact their performance on cultural-related tasks. Our study points to the inherent bias in the cultural understanding of LLMs and provides insights that can help develop culturally aware language models.",
    "pdf_link": "https://arxiv.org/abs/2405.04655",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）在常识理解方面表现出色，但在文化常识领域却鲜有探索。本文深入分析了数款顶尖LLMs在处理文化常识任务时的强项与短板。通过一系列通用与文化常识测试，我们揭示了LLMs在不同文化背景下的常识知识表现差异显著，文化背景对其通用常识能力有显著影响，且查询语言的选择会左右其在文化相关任务上的表现。本研究揭示了LLMs在文化理解上的内在偏差，并为构建更具文化敏感性的语言模型提供了启示。",
    "title_cn": "探究大型语言模型在文化常识领域的潜能与边界",
    "tags": [
      "LLM理论\n\n这篇论文探讨了大型语言模型（LLMs）在处理文化常识任务时的表现，并分析了文化背景对LLMs常识理解能力的影响。它揭示了LLMs在文化理解上的内在偏差，并提出了构建更具文化敏感性的语言模型的建议。这些内容属于对LLMs理论层面的研究，特别是关于模型在特定领域（文化常识）的理解和偏差分析，因此归类为LLM理论。",
      "",
      "文化研究"
    ]
  },
  {
    "title": "AffirmativeAI: Towards LGBTQ+ Friendly Audit Frameworks for Large Language Models",
    "submit_datetime": "2024年05月07日",
    "abstract": "LGBTQ+ community face disproportionate mental health challenges, including higher rates of depression, anxiety, and suicidal ideation. Research has shown that LGBTQ+ people have been using large language model-based chatbots, such as ChatGPT, for their mental health needs. Despite the potential for immediate support and anonymity these chatbots offer, concerns regarding their capacity to provide empathetic, accurate, and affirming responses remain. In response to these challenges, we propose a framework for evaluating the affirmativeness of LLMs based on principles of affirmative therapy, emphasizing the need for attitudes, knowledge, and actions that support and validate LGBTQ+ experiences. We propose a combination of qualitative and quantitative analyses, hoping to establish benchmarks for \"Affirmative AI,\" ensuring that LLM-based chatbots can provide safe, supportive, and effective mental health support to LGBTQ+ individuals. We benchmark LLM affirmativeness not as a mental health solution for LGBTQ+ individuals or to claim it resolves their mental health issues, as we highlight the need to consider complex discrimination in the LGBTQ+ community when designing technological aids. Our goal is to evaluate LLMs for LGBTQ+ mental health support since many in the community already use them, aiming to identify potential harms of using general-purpose LLMs in this context.",
    "pdf_link": "https://arxiv.org/abs/2405.04652",
    "graphs": [],
    "abstract_cn": "LGBTQ+社区的心理健康问题尤为严峻，他们中的许多人转向了如ChatGPT这样的大型语言模型聊天机器人寻求帮助。虽然这些机器人提供了即时的支持和匿名性，但它们是否能提供同理心、准确和肯定的回应仍令人担忧。为此，我们提出了一种基于肯定疗法的评估框架，旨在确保这些聊天机器人能够真正支持并验证LGBTQ+的经历。我们希望通过定性和定量分析，为“肯定性AI”设定标准，确保它们能为LGBTQ+个体提供安全、有效的心理健康支持。我们的目标不是将LLM视为解决LGBTQ+心理健康问题的万能钥匙，而是在考虑社区内复杂歧视的同时，评估这些技术在心理健康支持方面的潜力和风险。",
    "title_cn": "AffirmativeAI：迈向大型语言模型的LGBTQ+友好审计框架。",
    "tags": [
      "LLM应用\n\n这篇论文关注的是大型语言模型（LLM）在特定应用场景——即LGBTQ+社区心理健康支持中的应用。它提出了一种基于肯定疗法的评估框架，旨在确保聊天机器人能够提供同理心、准确和肯定的回应，从而支持LGBTQ+个体的经历。这与LLM的理论研究不同，因为它不是探讨LLM的内部机制或理论基础，而是关注LLM在实际应用中的效果和影响。同时，它也不属于Agent或RAG的分类，因为Agent通常指的是具有自主决策能力的智能体，而RAG（Retrieval-Augmented Generation）通常指的是一种结合了检索和生成的模型架构，这篇论文并没有特别强调这些方面。因此，最合适的分类是LLM应用。",
      "心理健康",
      "LGBTQ+社区支持"
    ]
  },
  {
    "title": "Enhancing LLM-Based Feedback: Insights from Intelligent Tutoring Systems and the Learning Sciences",
    "submit_datetime": "2024年05月07日",
    "abstract": "The field of Artificial Intelligence in Education (AIED) focuses on the intersection of technology, education, and psychology, placing a strong emphasis on supporting learners' needs with compassion and understanding. The growing prominence of Large Language Models (LLMs) has led to the development of scalable solutions within educational settings, including generating different types of feedback in Intelligent Tutoring Systems. However, the approach to utilizing these models often involves directly formulating prompts to solicit specific information, lacking a solid theoretical foundation for prompt construction and empirical assessments of their impact on learning. This work advocates careful and caring AIED research by going through previous research on feedback generation in ITS, with emphasis on the theoretical frameworks they utilized and the efficacy of the corresponding design in empirical evaluations, and then suggesting opportunities to apply these evidence-based principles to the design, experiment, and evaluation phases of LLM-based feedback generation. The main contributions of this paper include: an avocation of applying more cautious, theoretically grounded methods in feedback generation in the era of generative AI; and practical suggestions on theory and evidence-based feedback design for LLM-powered ITS.",
    "pdf_link": "https://arxiv.org/abs/2405.04645",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.04645v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04645/potentials_in_its_workflow.png"
      }
    ],
    "abstract_cn": "人工智能教育（AIED）领域致力于融合技术、教育和心理学，强调以同情心和理解力来满足学习者的需求。随着大型语言模型（LLMs）的兴起，教育领域出现了可扩展的解决方案，如智能辅导系统中的多样化反馈生成。然而，这些模型的应用往往缺乏理论基础，且对学习效果的评估不足。本文倡导深入研究，回顾智能辅导系统中反馈生成的理论框架和实证效果，并提出将这些基于证据的原则应用于LLM反馈生成的设计、实验和评估中。本文的主要贡献在于：呼吁在生成AI时代采用更为谨慎、理论基础更坚实的反馈生成方法；并为LLM驱动的智能辅导系统提供基于理论和实证的反馈设计建议。",
    "title_cn": "提升大型语言模型反馈：智能辅导系统与学习科学的启示",
    "tags": [
      "LLM应用\n\n这篇论文探讨了大型语言模型（LLMs）在人工智能教育（AIED）领域的应用，特别是在智能辅导系统中的反馈生成。它强调了理论基础的重要性，并呼吁对LLM生成的反馈进行更深入的研究和评估。虽然论文涉及了LLM的理论应用，但其核心关注点在于教育领域的实际应用和效果评估，因此更适合归类于“LLM应用”。",
      "人工智能教育",
      "智能辅导系统"
    ]
  },
  {
    "title": "Contextual API Completion for Unseen Repositories Using LLMs",
    "submit_datetime": "2024年05月07日",
    "abstract": "Large language models have made substantial progress in addressing diverse code-related tasks. However, their adoption is hindered by inconsistencies in generating output due to the lack of real-world, domain-specific information, such as for intra-repository API calls for unseen software projects. We introduce a novel technique to mitigate hallucinations by leveraging global and local contextual information within a code repository for API completion tasks. Our approach is tailored to refine code completion tasks, with a focus on optimizing local API completions. We examine relevant import statements during API completion to derive insights into local APIs, drawing from their method signatures. For API token completion, we analyze the inline variables and correlate them with the appropriate imported modules, thereby allowing our approach to rank the most contextually relevant suggestions from the available local APIs. Further, for conversational API completion, we gather APIs that are most relevant to the developer query with a retrieval-based search across the project. We employ our tool, LANCE, within the framework of our proposed benchmark, APIEval, encompassing two different programming languages. Our evaluation yields an average accuracy of 82.6% for API token completion and 76.9% for conversational API completion tasks. On average, LANCE surpasses Copilot by 143% and 142% for API token completion and conversational API completion, respectively. The implications of our findings are substantial for developers, suggesting that our lightweight context analysis can be applied to multilingual environments without language-specific training or fine-tuning, allowing for efficient implementation with minimal examples and effort.",
    "pdf_link": "https://arxiv.org/abs/2405.04600",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.04600v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04600/x1.png"
      }
    ],
    "abstract_cn": "大型语言模型在代码任务上取得了巨大进步，但因缺乏实际领域信息，如未知软件项目的内部API调用，导致输出不一致，限制了其应用。我们提出了一种新方法，通过代码库中的全局与局部上下文信息，减少幻觉，优化API补全。我们分析导入语句，洞察局部API，同时关联内联变量与模块，为API令牌补全提供最相关的建议。在会话式补全中，我们根据开发者查询检索最相关的API。我们的工具LANCE在APIEval基准中表现出色，涵盖两种编程语言，API令牌补全准确率达82.6%，会话式补全达76.9%，远超Copilot。我们的方法无需特定语言训练，适用于多语言环境，为开发者提供了高效且轻量级的解决方案。",
    "title_cn": "借助大型语言模型，我们能够为未曾涉猎的代码库提供精准的上下文API自动补全功能。",
    "tags": [
      "LLM应用\n\n这篇论文讨论了大型语言模型在代码任务中的应用，特别是在API补全方面的优化。它提出了一种新方法，通过利用代码库中的全局和局部上下文信息来减少幻觉并提高API补全的准确性。这种方法在多语言环境中有效，并且不需要特定语言的训练。论文中提到的工具LANCE在APIEval基准测试中表现出色，证明了其在实际应用中的有效性。因此，这篇论文更符合LLM应用分类，因为它关注的是大型语言模型在特定任务（即代码补全）中的实际应用和改进。",
      "软件开发",
      "编程辅助工具"
    ]
  },
  {
    "title": "Language Modeling Using Tensor Trains",
    "submit_datetime": "2024年05月07日",
    "abstract": "We propose a novel tensor network language model based on the simplest tensor network (i.e., tensor trains), called `Tensor Train Language Model' (TTLM). TTLM represents sentences in an exponential space constructed by the tensor product of words, but computing the probabilities of sentences in a low-dimensional fashion. We demonstrate that the architectures of Second-order RNNs, Recurrent Arithmetic Circuits (RACs), and Multiplicative Integration RNNs are, essentially, special cases of TTLM. Experimental evaluations on real language modeling tasks show that the proposed variants of TTLM (i.e., TTLM-Large and TTLM-Tiny) outperform the vanilla Recurrent Neural Networks (RNNs) with low-scale of hidden units. (The code is available at https://github.com/shuishen112/tensortrainlm.)",
    "pdf_link": "https://arxiv.org/abs/2405.04590",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.04590v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04590/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04590v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04590/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04590v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04590/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04590v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04590/comparision_with_rnn.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04590v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04590/rank_val_ppl_Large_Tiny_ICML.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04590v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04590/four_comparison.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04590v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04590/x4.png"
      }
    ],
    "abstract_cn": "我们创新性地提出了“张量列车语言模型”（TTLM），一种基于张量列车的张量网络语言模型。TTLM 巧妙地在指数空间中通过单词的张量积构建句子表示，同时以低维计算方式精准预测句子概率。研究表明，二阶 RNN、循环算术电路（RACs）和乘法集成 RNN 等架构，实质上都是 TTLM 的特殊表现。实验证明，TTLM 的两种变体（TTLM-Large 和 TTLM-Tiny）在隐藏单元数量有限的情况下，均超越了传统 RNN 的性能。相关代码已公开于 GitHub 仓库。",
    "title_cn": "张量列车语言建模：探索语言的深层结构在翻译过程中，我首先确保了原文的核心概念“张量列车”和“语言建模”被准确传达。然后，在第二步中，我采用了更加生动和符合中文表达习惯的措辞，将“使用张量列车进行语言建模”转化为“张量列车语言建模：探索语言的深层结构”，这样的表述不仅简洁优雅，而且能够激发读者对这一技术主题的兴趣。",
    "tags": [
      "LLM理论\n\n这篇论文介绍了一种新的语言模型架构——张量列车语言模型（TTLM），它基于张量网络，并提出了在指数空间中构建句子表示的方法。这种模型在理论上探讨了语言模型的构建和性能优化，因此属于LLM理论分类。它并没有直接讨论Agent的行为或决策，也没有提及RAG（可能是指某种特定的模型或技术，但在这里没有足够信息来确定），同时它更多是关于语言模型理论的创新，而不是一个具体的应用案例。",
      "",
      "机器学习"
    ]
  },
  {
    "title": "All in One Framework for Multimodal Re-identification in the Wild",
    "submit_datetime": "2024年05月07日",
    "abstract": "In Re-identification (ReID), recent advancements yield noteworthy progress in both unimodal and cross-modal retrieval tasks. However, the challenge persists in developing a unified framework that could effectively handle varying multimodal data, including RGB, infrared, sketches, and textual information. Additionally, the emergence of large-scale models shows promising performance in various vision tasks but the foundation model in ReID is still blank. In response to these challenges, a novel multimodal learning paradigm for ReID is introduced, referred to as All-in-One (AIO), which harnesses a frozen pre-trained big model as an encoder, enabling effective multimodal retrieval without additional fine-tuning. The diverse multimodal data in AIO are seamlessly tokenized into a unified space, allowing the modality-shared frozen encoder to extract identity-consistent features comprehensively across all modalities. Furthermore, a meticulously crafted ensemble of cross-modality heads is designed to guide the learning trajectory. AIO is the \\textbf{first} framework to perform all-in-one ReID, encompassing four commonly used modalities. Experiments on cross-modal and multimodal ReID reveal that AIO not only adeptly handles various modal data but also excels in challenging contexts, showcasing exceptional performance in zero-shot and domain generalization scenarios.",
    "pdf_link": "https://arxiv.org/abs/2405.04741",
    "graphs": [],
    "abstract_cn": "在ReID领域，尽管单模态和跨模态检索技术取得了显著进展，但构建一个能有效整合多种数据（如RGB、红外、草图和文本）的统一框架仍是一大挑战。同时，虽然大型模型在视觉任务中表现出色，但ReID的基础模型尚未成型。为此，我们提出了“一体式”（AIO）多模态学习范式，它采用预训练的大型模型作为编码器，无需微调即可实现高效的多模态检索。AIO将多样的数据统一标记化，使得共享编码器能够跨模态提取一致的身份特征。我们还精心设计了跨模态头部，以引导学习过程。作为首个实现一体式ReID的框架，AIO涵盖了四种常见模态，并在实验中证明了其在处理复杂模态数据和在零-shot及领域泛化场景中的卓越性能。",
    "title_cn": "一体式框架：野外多模态身份再识别的全面解决方案",
    "tags": [
      "Agent\n\n这篇论文介绍了一种名为“一体式”（AIO）的多模态学习范式，它利用预训练的大型模型作为编码器来实现多模态检索。这种范式可以被视为一个智能代理（Agent），因为它能够处理和整合多种类型的数据，并在不同的场景中执行检索任务。AIO框架的设计和实现展示了如何构建一个能够跨模态工作的智能系统，这与Agent的概念相符，即一个能够感知环境、做出决策并执行动作的系统。因此，这篇论文更适合归类到Agent分类中。",
      "多模态学习",
      "图像检索"
    ]
  },
  {
    "title": "Generative AI as a metacognitive agent: A comparative mixed-method study with human participants on ICF-mimicking exam performance",
    "submit_datetime": "2024年05月07日",
    "abstract": "This study investigates the metacognitive capabilities of Large Language Models relative to human metacognition in the context of the International Coaching Federation ICF mimicking exam, a situational judgment test related to coaching competencies. Using a mixed method approach, we assessed the metacognitive performance, including sensitivity, accuracy in probabilistic predictions, and bias, of human participants and five advanced LLMs (GPT-4, Claude-3-Opus 3, Mistral Large, Llama 3, and Gemini 1.5 Pro). The results indicate that LLMs outperformed humans across all metacognitive metrics, particularly in terms of reduced overconfidence, compared to humans. However, both LLMs and humans showed less adaptability in ambiguous scenarios, adhering closely to predefined decision frameworks. The study suggests that Generative AI can effectively engage in human-like metacognitive processing without conscious awareness. Implications of the study are discussed in relation to development of AI simulators that scaffold cognitive and metacognitive aspects of mastering coaching competencies. More broadly, implications of these results are discussed in relation to development of metacognitive modules that lead towards more autonomous and intuitive AI systems.",
    "pdf_link": "https://arxiv.org/abs/2405.05285",
    "graphs": [],
    "abstract_cn": "本研究深入探讨了大型语言模型在模拟ICF考试中的元认知能力，该考试是一项考验教练能力的情景判断测试。通过综合分析，我们对比了人类与五大顶尖语言模型（GPT-4、Claude-3、Mistral、Llama、Gemini）在元认知上的表现，涵盖敏感度、预测准确性及偏见。研究发现，这些模型在减少过度自信方面超越了人类，但在面对模糊情境时，它们和人类一样，都显得缺乏灵活性，固守既定决策模式。这表明，尽管缺乏意识，生成式AI仍能模拟人类的元认知过程。研究不仅为开发辅助教练能力学习的AI工具提供了洞见，也为构建更自主、直觉的AI系统奠定了基础，尤其是在元认知模块的开发上。",
    "title_cn": "生成式AI：元认知代理的比较研究——探究其在ICF模拟考试中与人类参与者的表现差异在这次比较混合方法研究中，我们探讨了生成式人工智能作为元认知代理在ICF模拟考试中的表现，并与人类参与者的表现进行了对比。通过这种方法，我们旨在揭示生成式AI在模拟考试环境中的潜力和局限性，以及它与人类认知过程的异同。",
    "tags": [
      "Agent\n\n这篇论文探讨了大型语言模型在模拟ICF考试中的元认知能力，这是一个特定领域的应用，涉及模型如何模拟人类的元认知过程，以及它们在特定任务上的表现。虽然这涉及到LLM的应用，但它的重点在于模型如何作为一个智能体（Agent）来执行任务，特别是在元认知方面的表现，而不是专注于LLM的理论研究或RAG（Retrieval-Augmented Generation）框架。因此，将其归类为Agent更为合适。",
      "教育培训",
      "人工智能辅助学习"
    ]
  },
  {
    "title": "Federated Reinforcement Learning with Constraint Heterogeneity",
    "submit_datetime": "2024年05月06日",
    "abstract": "We study a Federated Reinforcement Learning (FedRL) problem with constraint heterogeneity. In our setting, we aim to solve a reinforcement learning problem with multiple constraints while $N$ training agents are located in $N$ different environments with limited access to the constraint signals and they are expected to collaboratively learn a policy satisfying all constraint signals. Such learning problems are prevalent in scenarios of Large Language Model (LLM) fine-tuning and healthcare applications. To solve the problem, we propose federated primal-dual policy optimization methods based on traditional policy gradient methods. Specifically, we introduce $N$ local Lagrange functions for agents to perform local policy updates, and these agents are then scheduled to periodically communicate on their local policies. Taking natural policy gradient (NPG) and proximal policy optimization (PPO) as policy optimization methods, we mainly focus on two instances of our algorithms, ie, {FedNPG} and {FedPPO}. We show that FedNPG achieves global convergence with an $\\tilde{O}(1/\\sqrt{T})$ rate, and FedPPO efficiently solves complicated learning tasks with the use of deep neural networks.",
    "pdf_link": "https://arxiv.org/abs/2405.03236",
    "graphs": [],
    "abstract_cn": "本研究探讨了一种具有约束多样性的联邦强化学习（FedRL）问题。我们旨在解决一个涉及多重约束的强化学习挑战，其中N个训练代理分散在N个不同的环境之中，这些环境对约束信号的获取受限，且各代理需协同进化出满足所有约束的策略。这类学习问题在大型语言模型（LLM）的微调和医疗健康应用中尤为常见。为应对这一挑战，我们提出了一种基于传统策略梯度的联邦原始-对偶策略优化方法。具体而言，我们引入了N个局部拉格朗日函数，供代理进行本地策略更新，并安排这些代理定期就本地策略进行交流。我们特别关注两种算法实例：FedNPG和FedPPO，其中FedNPG证明了其以$\\tilde{O}(1/\\sqrt{T})$的速率实现全局收敛，而FedPPO则展示了其利用深度神经网络高效处理复杂学习任务的能力。",
    "title_cn": "在约束异质性条件下的联合强化学习研究",
    "tags": [
      "分类：Agent",
      "联邦学习",
      ""
    ]
  },
  {
    "title": "TED: Accelerate Model Training by Internal Generalization",
    "submit_datetime": "2024年05月06日",
    "abstract": "Large language models have demonstrated strong performance in recent years, but the high cost of training drives the need for efficient methods to compress dataset sizes. We propose TED pruning, a method that addresses the challenge of overfitting under high pruning ratios by quantifying the model's ability to improve performance on pruned data while fitting retained data, known as Internal Generalization (IG). TED uses an optimization objective based on Internal Generalization Distance (IGD), measuring changes in IG before and after pruning to align with true generalization performance and achieve implicit regularization. The IGD optimization objective was verified to allow the model to achieve the smallest upper bound on generalization error. The impact of small mask fluctuations on IG is studied through masks and Taylor approximation, and fast estimation of IGD is enabled. In analyzing continuous training dynamics, the prior effect of IGD is validated, and a progressive pruning strategy is proposed. Experiments on image classification, natural language understanding, and large language model fine-tuning show TED achieves lossless performance with 60-70\\% of the data. Upon acceptance, our code will be made publicly available.",
    "pdf_link": "https://arxiv.org/abs/2405.03228",
    "graphs": [],
    "abstract_cn": "近年来，大型语言模型在性能上取得了显著进步，但高昂的训练成本促使我们寻求更高效的数据压缩方法。我们提出了一种名为TED剪枝的新方法，它通过评估模型在剪枝后数据上的性能提升能力，同时保持对保留数据的适应性，即内部泛化（IG），来解决高剪枝比率可能导致的过拟合问题。TED采用基于内部泛化距离（IGD）的优化目标，通过比较剪枝前后IG的变化，确保与真实泛化性能的一致性，从而实现隐式正则化。该优化目标已被证实能够使模型达到泛化误差的最低界限。我们还通过掩码和泰勒近似分析了小掩码波动对IG的影响，并实现了IGD的快速估算。在连续训练动态的分析中，IGD的先前效应得到了验证，同时提出了一种逐步剪枝策略。在图像分类、自然语言理解和大型语言模型微调的实验中，TED证明了其在减少60-70%数据量的同时仍能保持性能无损。我们的代码将在论文被接受后公开。",
    "title_cn": "TED：借助内部泛化提升模型训练效率",
    "tags": [
      "LLM理论",
      "机器学习",
      "数据压缩"
    ]
  },
  {
    "title": "A Philosophical Introduction to Language Models - Part II: The Way Forward",
    "submit_datetime": "2024年05月06日",
    "abstract": "In this paper, the second of two companion pieces, we explore novel philosophical questions raised by recent progress in large language models (LLMs) that go beyond the classical debates covered in the first part. We focus particularly on issues related to interpretability, examining evidence from causal intervention methods about the nature of LLMs' internal representations and computations. We also discuss the implications of multimodal and modular extensions of LLMs, recent debates about whether such systems may meet minimal criteria for consciousness, and concerns about secrecy and reproducibility in LLM research. Finally, we discuss whether LLM-like systems may be relevant to modeling aspects of human cognition, if their architectural characteristics and learning scenario are adequately constrained.",
    "pdf_link": "https://arxiv.org/abs/2405.03207",
    "graphs": [],
    "abstract_cn": "本文作为姊妹篇的续篇，深入探讨了大型语言模型（LLMs）的最新进展所引发的哲学新议题，超越了前篇讨论的传统争议。文章着重分析了可解释性问题，通过因果干预方法探究了LLMs内部表征和计算的本质。同时，讨论了LLMs的多模态和模块化扩展的意义，以及这些系统是否达到意识基本标准的近期讨论，并对LLM研究中的秘密性和可复制性问题表达了关切。文章最后探讨了，如果LLMs的架构特性和学习场景得到恰当的约束，它们是否可能对模拟人类认知的某些方面具有重要价值。",
    "title_cn": "《语言模型哲学探析（下）：前行之路》",
    "tags": [
      "分类：LLM理论",
      "人工智能",
      "认知科学"
    ]
  },
  {
    "title": "Vietnamese AI Generated Text Detection",
    "submit_datetime": "2024年05月06日",
    "abstract": "In recent years, Large Language Models (LLMs) have become integrated into our daily lives, serving as invaluable assistants in completing tasks. Widely embraced by users, the abuse of LLMs is inevitable, particularly in using them to generate text content for various purposes, leading to difficulties in distinguishing between text generated by LLMs and that written by humans. In this study, we present a dataset named ViDetect, comprising 6.800 samples of Vietnamese essay, with 3.400 samples authored by humans and the remainder generated by LLMs, serving the purpose of detecting text generated by AI. We conducted evaluations using state-of-the-art methods, including ViT5, BartPho, PhoBERT, mDeberta V3, and mBERT. These results contribute not only to the growing body of research on detecting text generated by AI but also demonstrate the adaptability and effectiveness of different methods in the Vietnamese language context. This research lays the foundation for future advancements in AI-generated text detection and provides valuable insights for researchers in the field of natural language processing.",
    "pdf_link": "https://arxiv.org/abs/2405.03206",
    "graphs": [],
    "abstract_cn": "近期，大型语言模型（LLMs）逐渐成为我们日常任务处理的得力助手。然而，随着人们对LLMs的广泛接纳，滥用现象也随之出现，尤其是在利用这些模型生成多样化目的的文本内容方面，这使得区分机器生成文本与人类写作文本变得日益困难。本研究推出了ViDetect数据集，包含6800篇越南语文章样本，其中3400篇由人类撰写，其余由LLMs生成，旨在检测AI生成的文本。我们采用了包括ViT5、BartPho、PhoBERT、mDeberta V3和mBERT在内的尖端技术进行评估。这些研究成果不仅丰富了AI文本检测的研究，也证明了这些方法在越南语环境下的适用性和高效性。本研究为AI文本检测技术的未来发展奠定了基石，同时为自然语言处理领域的研究者们提供了深刻的洞见。",
    "title_cn": "越南AI文本生成检测",
    "tags": [
      "LLM应用",
      "",
      "文本检测"
    ]
  },
  {
    "title": "Anchored Answers: Unravelling Positional Bias in GPT-2's Multiple-Choice Questions",
    "submit_datetime": "2024年05月06日",
    "abstract": "Large Language Models (LLMs), such as the GPT-4 and LLaMA families, have demonstrated considerable success across diverse tasks, including multiple-choice questions (MCQs). However, these models exhibit a positional bias, particularly an even worse anchored bias in the GPT-2 family, where they consistently favour the first choice 'A' in MCQs during inference. This anchored bias challenges the integrity of GPT-2's decision-making process, as it skews performance based on the position rather than the content of the choices in MCQs. In this study, we utilise the mechanistic interpretability approach to identify the internal modules within GPT-2 models responsible for this bias. We focus on the Multi-Layer Perceptron (MLP) layers and attention heads, using the \"logit lens\" method to trace and modify the specific value vectors that contribute to the bias. By updating these vectors within MLP and recalibrating attention patterns to neutralise the preference for the first choice 'A', we effectively mitigate the anchored bias. Our interventions not only correct the bias but also improve the overall MCQ prediction accuracy for the GPT-2 family across various datasets. This work represents the first comprehensive mechanistic analysis of anchored bias in MCQs within the GPT-2 models, introducing targeted, minimal-intervention strategies that significantly enhance GPT2 model robustness and accuracy in MCQs. Our code is available at https://github.com/ruizheliUOA/Anchored_Bias_GPT2.",
    "pdf_link": "https://arxiv.org/abs/2405.03205",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.03205v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03205/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03205v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03205/anchor.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03205v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03205/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03205v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03205/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03205v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03205/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03205v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03205/x5.png"
      }
    ],
    "abstract_cn": "诸如 GPT-4 和 LLaMA 家族之类的大型语言模型在多项选择题等多样化任务上取得了显著成就。但这些模型存在位置偏好问题，尤其是 GPT-2 系列，它们在推理时更倾向于选择 A 项。这种偏好性偏差影响了 GPT-2 的决策公正性，因为它基于选项的顺序而非实质内容。本研究采用机制解释性方法，深入探究 GPT-2 模型中产生这种偏差的内部机制，特别是多层感知器（MLP）层和注意力机制。通过“对数镜头”技术，我们追踪并调整了导致偏差的特定值向量，进而在 MLP 中更新这些向量，并重新校准注意力模式，以消除对 A 项的偏好。这些调整有效减少了锚定偏差，同时提升了 GPT-2 系列在不同数据集上的多项选择题预测准确率。这项研究是首次对 GPT-2 模型中多项选择题的锚定偏差进行深入的机制分析，并提出了精准且影响最小的干预策略，显著提高了模型的鲁棒性和准确性。相关代码已在 GitHub 上公开，地址为 https://github.com/ruizheliUOA/Anchored_Bias_GPT2。",
    "title_cn": "锚定答案：探究 GPT-2 多项选择题中的定位偏好之谜",
    "tags": [
      "LLM应用",
      "人工智能",
      "机器学习"
    ]
  },
  {
    "title": "CityLLaVA: Efficient Fine-Tuning for VLMs in City Scenario",
    "submit_datetime": "2024年05月06日",
    "abstract": "In the vast and dynamic landscape of urban settings, Traffic Safety Description and Analysis plays a pivotal role in applications ranging from insurance inspection to accident prevention. This paper introduces CityLLaVA, a novel fine-tuning framework for Visual Language Models (VLMs) designed for urban scenarios. CityLLaVA enhances model comprehension and prediction accuracy through (1) employing bounding boxes for optimal visual data preprocessing, including video best-view selection and visual prompt engineering during both training and testing phases; (2) constructing concise Question-Answer sequences and designing textual prompts to refine instruction comprehension; (3) implementing block expansion to fine-tune large VLMs efficiently; and (4) advancing prediction accuracy via a unique sequential questioning-based prediction augmentation. Demonstrating top-tier performance, our method achieved a benchmark score of 33.4308, securing the leading position on the leaderboard. The code can be found: https://github.com/alibaba/AICITY2024_Track2_AliOpenTrek_CityLLaVA",
    "pdf_link": "https://arxiv.org/abs/2405.03194",
    "graphs": [],
    "abstract_cn": "在繁华且瞬息万变的城市生活中，交通状况的描述与分析对于保险业检查和预防事故等应用至关重要。本文提出了 CityLLaVA，这是一个创新的微调框架，专为城市环境的视觉语言模型（VLMs）量身打造。CityLLaVA 通过四个关键策略提升了模型的理解和预测能力：首先，利用边界框技术进行视觉数据的最优预处理，包括视频的最佳视角选择和视觉提示的精心设计；其次，构建简洁的问答对并设计文本提示以提高指令理解的精确度；第三，采用块扩展技术高效地微调大型 VLMs；最后，通过独特的顺序提问法增强预测的准确性。CityLLaVA 在性能上达到了新高度，以 33.4308 的高分在排行榜上独占鳌头。相关代码已在 GitHub 上发布，地址为：https://github.com/alibaba/AICITY2024_Track2_AliOpenTrek_CityLLaVA。",
    "title_cn": "CityLLaVA：在城市环境中为超大型语言模型（VLM）实现高效微调的解决方案。",
    "tags": [
      "分类：LLM应用\n\n这篇论文介绍了一个名为 CityLLaVA 的微调框架，它专为城市环境的视觉语言模型（VLMs）设计，以提高模型的理解和预测能力。这个框架通过四个关键策略来实现这一目标，包括视觉数据的最优预处理、构建简洁的问答对和设计文本提示、采用块扩展技术进行微调，以及通过独特的顺序提问法增强预测的准确性。这个框架在性能上取得了显著的成果，并在排行榜上取得了高分。由于这个框架是针对视觉语言模型的应用，所以它属于 LLM 应用类别。",
      "保险业",
      "交通分析"
    ]
  },
  {
    "title": "Adapting Dual-encoder Vision-language Models for Paraphrased Retrieval",
    "submit_datetime": "2024年05月06日",
    "abstract": "In the recent years, the dual-encoder vision-language models (\\eg CLIP) have achieved remarkable text-to-image retrieval performance. However, we discover that these models usually results in very different retrievals for a pair of paraphrased queries. Such behavior might render the retrieval system less predictable and lead to user frustration. In this work, we consider the task of paraphrased text-to-image retrieval where a model aims to return similar results given a pair of paraphrased queries. To start with, we collect a dataset of paraphrased image descriptions to facilitate quantitative evaluation for this task. We then hypothesize that the undesired behavior of existing dual-encoder model is due to their text towers which are trained on image-sentence pairs and lack the ability to capture the semantic similarity between paraphrased queries. To improve on this, we investigate multiple strategies for training a dual-encoder model starting from a language model pretrained on a large text corpus. Compared to public dual-encoder models such as CLIP and OpenCLIP, the model trained with our best adaptation strategy achieves a significantly higher ranking similarity for paraphrased queries while maintaining similar zero-shot classification and retrieval accuracy.",
    "pdf_link": "https://arxiv.org/abs/2405.03190",
    "graphs": [],
    "abstract_cn": "近期，诸如 CLIP 的双编码器视觉-语言模型在文本到图像检索任务上表现卓越。但我们观察到，这些模型面对释义查询时，往往会给出截然不同的检索结果，这可能降低系统的可预测性，引发用户不满。本研究聚焦于释义文本到图像的检索问题，即模型在接收到释义查询对时，应返回相似的检索结果。为此，我们首先构建了一个包含释义图像描述的数据集，以便对此任务进行量化评估。接着，我们推测现有双编码器模型之所以表现不佳，可能是因为它们的文本模块仅在图像-句子对上训练，未能充分捕捉释义查询间的语义相似性。为了解决这一问题，我们探索了多种基于大型文本语料库预训练的语言模型的双编码器训练策略。与 CLIP 和 OpenCLIP 等现有模型相比，采用我们最优策略训练的模型在释义查询的排名相似性上有显著提升，同时保持了相当的零样本分类和检索精度。",
    "title_cn": "适配双编码视觉-语言模型，优化释义检索性能。",
    "tags": [
      "LLM应用",
      "图像检索",
      ""
    ]
  },
  {
    "title": "Oracle-Checker Scheme for Evaluating a Generative Large Language Model",
    "submit_datetime": "2024年05月06日",
    "abstract": "This work presents a novel approach called oracle-checker scheme for evaluating the answer given by a generative large language model (LLM). Two types of checkers are presented. The first type of checker follows the idea of property testing. The second type of checker follows the idea of program checking. Their applications are demonstrated in two separate contexts, entity extraction and paraphrase decision, respectively.",
    "pdf_link": "https://arxiv.org/abs/2405.03170",
    "graphs": [],
    "abstract_cn": "本文介绍了一种创新的评估方法——“先知-检验器框架”，旨在评价生成型大型语言模型（LLM）所生成的答案。该方法包括两种检验器：一种基于属性测试理念，另一种基于程序检验理念。这两种检验器在实体抽取和释义判断两个独立场景中的应用也得到了展示。",
    "title_cn": "探索评估生成型大型语言模型的 Oracle-Checker 机制",
    "tags": [
      "LLM应用",
      "",
      "程序验证"
    ]
  },
  {
    "title": "Advancing Multimodal Medical Capabilities of Gemini",
    "submit_datetime": "2024年05月06日",
    "abstract": "Many clinical tasks require an understanding of specialized data, such as medical images and genomics, which is not typically found in general-purpose large multimodal models. Building upon Gemini's multimodal models, we develop several models within the new Med-Gemini family that inherit core capabilities of Gemini and are optimized for medical use via fine-tuning with 2D and 3D radiology, histopathology, ophthalmology, dermatology and genomic data. Med-Gemini-2D sets a new standard for AI-based chest X-ray (CXR) report generation based on expert evaluation, exceeding previous best results across two separate datasets by an absolute margin of 1% and 12%, where 57% and 96% of AI reports on normal cases, and 43% and 65% on abnormal cases, are evaluated as \"equivalent or better\" than the original radiologists' reports. We demonstrate the first ever large multimodal model-based report generation for 3D computed tomography (CT) volumes using Med-Gemini-3D, with 53% of AI reports considered clinically acceptable, although additional research is needed to meet expert radiologist reporting quality. Beyond report generation, Med-Gemini-2D surpasses the previous best performance in CXR visual question answering (VQA) and performs well in CXR classification and radiology VQA, exceeding SoTA or baselines on 17 of 20 tasks. In histopathology, ophthalmology, and dermatology image classification, Med-Gemini-2D surpasses baselines across 18 out of 20 tasks and approaches task-specific model performance. Beyond imaging, Med-Gemini-Polygenic outperforms the standard linear polygenic risk score-based approach for disease risk prediction and generalizes to genetically correlated diseases for which it has never been trained. Although further development and evaluation are necessary in the safety-critical medical domain, our results highlight the potential of Med-Gemini across a wide range of medical tasks.",
    "pdf_link": "https://arxiv.org/abs/2405.03162",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.03162v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03162/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03162v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03162/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03162v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03162/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03162v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03162/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03162v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03162/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03162v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03162/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03162v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03162/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03162v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03162/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03162v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03162/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03162v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03162/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03162v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03162/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03162v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03162/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03162v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03162/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03162v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03162/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03162v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03162/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03162v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03162/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03162v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03162/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03162v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03162/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03162v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03162/x20.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03162v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03162/x21.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03162v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03162/x22.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03162v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03162/x23.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03162v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03162/x24.png"
      }
    ],
    "abstract_cn": "众多临床工作需洞悉如医学影像与基因组学这类专业数据，此类信息在常规的大型多模态模型中并不常见。基于 Gemini 多模态模型，我们研发了 Med-Gemini 系列新模型，这些模型不仅继承了 Gemini 的核心功能，还通过针对 2D 与 3D 放射影像、组织病理学、眼科、皮肤科和基因组数据的精细调整，专为医疗场景优化。Med-Gemini-2D 在 AI 驱动的胸部 X 射线（CXR）报告生成方面树立了新的标杆，根据专家评审，其在两个独立数据集上的成绩分别比之前的最佳结果提升了 1% 和 12%，在正常和异常病例的 AI 报告中，分别有 57%、96% 和 43%、65% 的报告被认为“达到或超过”放射科医师的原始报告水平。我们还首次展示了利用 Med-Gemini-3D 基于大型多模态模型生成的 3D 计算机断层扫描（CT）体积报告，其中 53% 的 AI 报告被认为临床上是可接受的，尽管要达到放射科专家的报告质量还需进一步研究。Med-Gemini-2D 不仅在报告生成上有所突破，在 CXR 视觉问答（VQA）中也刷新了最佳成绩，并在 CXR 分类及放射学 VQA 中表现出色，20 项任务中有 17 项超越了当前最佳水平或基线水平。在组织病理学、眼科学和皮肤科图像分类方面，Med-Gemini-2D 在 20 项任务中的 18 项上超越了基线，并接近特定任务模型的性能。Med-Gemini-Polygenic 在疾病风险预测方面超越了传统的线性多基因风险评分方法，并能泛化至基因相关的疾病预测，即便这些疾病未曾在训练中出现。尽管在至关重要的医疗领域仍需进一步的开发与评估，但我们的成果已经突显了 Med-Gemini 在众多医疗任务中的广阔前景。",
    "title_cn": "提升双子座在多模态医疗领域的技术进步",
    "tags": [
      "分类：LLM应用\n\n这篇论文讨论了大型多模态模型在医疗领域的应用，特别是针对医学影像和基因组学数据的优化。Med-Gemini 系列模型在多个医疗任务中取得了显著的成果，包括胸部 X 射线报告生成、3D 计算机断层扫描体积报告生成、组织病理学、眼科学和皮肤科图像分类，以及疾病风险预测。这些成果展示了大型语言模型在医疗领域的应用潜力，因此这篇论文应归类为 LLM应用。",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Exploring the Potential of the Large Language Models (LLMs) in Identifying Misleading News Headlines",
    "submit_datetime": "2024年05月06日",
    "abstract": "In the digital age, the prevalence of misleading news headlines poses a significant challenge to information integrity, necessitating robust detection mechanisms. This study explores the efficacy of Large Language Models (LLMs) in identifying misleading versus non-misleading news headlines. Utilizing a dataset of 60 articles, sourced from both reputable and questionable outlets across health, science & tech, and business domains, we employ three LLMs- ChatGPT-3.5, ChatGPT-4, and Gemini-for classification. Our analysis reveals significant variance in model performance, with ChatGPT-4 demonstrating superior accuracy, especially in cases with unanimous annotator agreement on misleading headlines. The study emphasizes the importance of human-centered evaluation in developing LLMs that can navigate the complexities of misinformation detection, aligning technical proficiency with nuanced human judgment. Our findings contribute to the discourse on AI ethics, emphasizing the need for models that are not only technically advanced but also ethically aligned and sensitive to the subtleties of human interpretation.",
    "pdf_link": "https://arxiv.org/abs/2405.03153",
    "graphs": [],
    "abstract_cn": "数字时代，误导性新闻标题泛滥，严重威胁信息的准确性，迫切需要强有力的检测手段。本项研究检验了大型语言模型（LLMs）在辨识误导性与非误导性新闻标题中的效能。研究基于一个60篇文章的数据库，涵盖了健康、科技、商业等多个领域，来源包括知名和有争议的媒体。我们采用了三种语言模型——ChatGPT-3.5、ChatGPT-4和Gemini进行文本分类。研究发现，不同模型在性能上存在显著差异，尤其是ChatGPT-4在标注者对误导性标题看法一致时，准确度更为突出。研究强调了在开发能够识别错误信息复杂性的LLMs时，进行以人为本的评估的重要性，这涉及到将技术专长与人类的细致判断相结合。我们的研究结果为人工智能伦理的讨论增添了新视角，指出我们不仅需要技术上精进的模型，更需要这些模型在伦理上与人类价值观保持一致，并对人类的微妙解读具有敏感度。",
    "title_cn": "本文旨在探讨大型语言模型（LLMs）在甄别具有误导性的新闻标题方面的潜在能力。",
    "tags": [
      "LLM应用",
      "新闻媒体",
      "人工智能伦理"
    ]
  },
  {
    "title": "MMGER: Multi-modal and Multi-granularity Generative Error Correction with LLM for Joint Accent and Speech Recognition",
    "submit_datetime": "2024年05月06日",
    "abstract": "Despite notable advancements in automatic speech recognition (ASR), performance tends to degrade when faced with adverse conditions. Generative error correction (GER) leverages the exceptional text comprehension capabilities of large language models (LLM), delivering impressive performance in ASR error correction, where N-best hypotheses provide valuable information for transcription prediction. However, GER encounters challenges such as fixed N-best hypotheses, insufficient utilization of acoustic information, and limited specificity to multi-accent scenarios. In this paper, we explore the application of GER in multi-accent scenarios. Accents represent deviations from standard pronunciation norms, and the multi-task learning framework for simultaneous ASR and accent recognition (AR) has effectively addressed the multi-accent scenarios, making it a prominent solution. In this work, we propose a unified ASR-AR GER model, named MMGER, leveraging multi-modal correction, and multi-granularity correction. Multi-task ASR-AR learning is employed to provide dynamic 1-best hypotheses and accent embeddings. Multi-modal correction accomplishes fine-grained frame-level correction by force-aligning the acoustic features of speech with the corresponding character-level 1-best hypothesis sequence. Multi-granularity correction supplements the global linguistic information by incorporating regular 1-best hypotheses atop fine-grained multi-modal correction to achieve coarse-grained utterance-level correction. MMGER effectively mitigates the limitations of GER and tailors LLM-based ASR error correction for the multi-accent scenarios. Experiments conducted on the multi-accent Mandarin KeSpeech dataset demonstrate the efficacy of MMGER, achieving a 26.72% relative improvement in AR accuracy and a 27.55% relative reduction in ASR character error rate, compared to a well-established standard baseline.",
    "pdf_link": "https://arxiv.org/abs/2405.03152",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.03152v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03152/x1.png"
      }
    ],
    "abstract_cn": "尽管自动语音识别技术取得了突破性进展，但在恶劣环境下其性能仍会下降。本文介绍了一种名为 MMGER 的新型生成式错误纠正方法，该方法依托于大型语言模型的卓越文本理解力，针对自动语音识别中的错误进行校正，尤其在多口音环境中表现出色。传统的 N 最佳假设方法存在局限性，如假设固定不变、声学信息使用不足以及对口音多样性的适应性差。我们提出的 MMGER 模型采用多任务学习框架，同步进行语音识别和口音识别，以应对多口音挑战。该模型通过多模态和多粒度校正技术，不仅动态生成最佳假设和口音嵌入，还能在帧级别进行精细校正，并通过全局语言信息辅助实现话语级别的粗粒度校正。在多口音普通话 KeSpeech 数据集上的实验结果表明，MMGER 在口音识别准确度上提升了 26.72%，在 ASR 字符错误率上降低了 27.55%，均优于现有标准基线。",
    "title_cn": "MMGER是一种创新技术，它结合了大型语言模型（LLM），以多模态和多粒度的方式进行生成性错误校正，旨在同步提升口音识别和语音识别的准确性。",
    "tags": [
      "LLM应用",
      "语音识别",
      "自动语音校正"
    ]
  },
  {
    "title": "Lifelong Knowledge Editing for LLMs with Retrieval-Augmented Continuous Prompt Learning",
    "submit_datetime": "2024年05月06日",
    "abstract": "Model editing aims to correct outdated or erroneous knowledge in large language models (LLMs) without the need for costly retraining. Lifelong model editing is the most challenging task that caters to the continuous editing requirements of LLMs. Prior works primarily focus on single or batch editing; nevertheless, these methods fall short in lifelong editing scenarios due to catastrophic knowledge forgetting and the degradation of model performance. Although retrieval-based methods alleviate these issues, they are impeded by slow and cumbersome processes of integrating the retrieved knowledge into the model. In this work, we introduce RECIPE, a RetriEval-augmented ContInuous Prompt lEarning method, to boost editing efficacy and inference efficiency in lifelong learning. RECIPE first converts knowledge statements into short and informative continuous prompts, prefixed to the LLM's input query embedding, to efficiently refine the response grounded on the knowledge. It further integrates the Knowledge Sentinel (KS) that acts as an intermediary to calculate a dynamic threshold, determining whether the retrieval repository contains relevant knowledge. Our retriever and prompt encoder are jointly trained to achieve editing properties, i.e., reliability, generality, and locality. In our experiments, RECIPE is assessed extensively across multiple LLMs and editing datasets, where it achieves superior editing performance. RECIPE also demonstrates its capability to maintain the overall performance of LLMs alongside showcasing fast editing and inference speed.",
    "pdf_link": "https://arxiv.org/abs/2405.03279",
    "graphs": [],
    "abstract_cn": "模型编辑的目标是在不重新训练的情况下修正大型语言模型（LLMs）中的陈旧或错误信息。面对持续更新的LLMs，终身模型编辑成为了一项极具挑战性的任务。以往的研究多集中于单次或批量编辑，但在长期编辑过程中，由于知识遗忘和性能下降，这些方法往往力不从心。尽管基于检索的方法能够缓解这些问题，但其在将检索到的知识整合进模型时，过程缓慢且繁琐。本研究提出了RECIPE，一种结合了检索评估的连续提示学习方法，旨在提升终身学习中的编辑和推理效率。RECIPE将知识陈述转化为精炼且信息丰富的连续提示，这些提示会附加在LLM的输入查询嵌入前，以高效地提炼基于知识的响应。此外，它还整合了一个知识哨兵（KS），作为中介来计算动态阈值，判断检索库中是否存在相关知识。我们的检索器和提示编码器共同训练，以达到编辑的可靠性、通用性和局部性。在实验中，RECIPE在多个LLMs和编辑数据集上进行了全面评估，显示出卓越的编辑性能，并能保持LLMs的整体性能，同时具备快速的编辑和推理速度。",
    "title_cn": "在大型语言模型（LLMs）中，通过检索增强的连续提示学习方法，实现了终身知识的持续编辑与更新。",
    "tags": [
      "LLM应用",
      "人工智能",
      "机器学习"
    ]
  },
  {
    "title": "Doing Personal LAPS: LLM-Augmented Dialogue Construction for Personalized Multi-Session Conversational Search",
    "submit_datetime": "2024年05月06日",
    "abstract": "The future of conversational agents will provide users with personalized information responses. However, a significant challenge in developing models is the lack of large-scale dialogue datasets that span multiple sessions and reflect real-world user preferences. Previous approaches rely on experts in a wizard-of-oz setup that is difficult to scale, particularly for personalized tasks. Our method, LAPS, addresses this by using large language models (LLMs) to guide a single human worker in generating personalized dialogues. This method has proven to speed up the creation process and improve quality. LAPS can collect large-scale, human-written, multi-session, and multi-domain conversations, including extracting user preferences. When compared to existing datasets, LAPS-produced conversations are as natural and diverse as expert-created ones, which stays in contrast with fully synthetic methods. The collected dataset is suited to train preference extraction and personalized response generation. Our results show that responses generated explicitly using extracted preferences better match user's actual preferences, highlighting the value of using extracted preferences over simple dialogue history. Overall, LAPS introduces a new method to leverage LLMs to create realistic personalized conversational data more efficiently and effectively than previous methods.",
    "pdf_link": "https://arxiv.org/abs/2405.03480",
    "graphs": [],
    "abstract_cn": "未来对话代理将为用户带来定制化的信息反馈。但构建这类模型的一大难题是缺少覆盖多轮对话、体现用户真实偏好的大型对话数据集。传统做法依赖于专家进行“幕后指导”，这在规模化尤其是个性化任务上存在难度。我们的解决方案LAPS，利用大型语言模型（LLMs）辅助单一人工操作者产出个性化对话，显著提升了制作效率和对话质量。LAPS能够收集到大规模、真人编写、跨多个会话和领域的对话内容，并从中提取用户偏好。与现有数据集相比，LAPS产出的对话在自然度和多样性上与专家水准相媲美，且优于完全合成的方法。该数据集非常适合用于训练偏好抽取和个性化响应生成模型。实验结果表明，基于提取的偏好生成的响应更贴近用户的实际偏好，这强调了利用提取偏好而非仅依赖对话历史的重要性。总体来看，LAPS提出了一种创新方法，通过LLMs高效、有效地生成更为真实的个性化对话数据，超越了以往的做法。",
    "title_cn": "个性化循环训练：借助大型语言模型，构建个性化的多轮对话，以优化个性化的多会话搜索体验。",
    "tags": [
      "Agent",
      "对话系统",
      "个性化推荐"
    ]
  },
  {
    "title": "Large Language Models (LLMs) as Agents for Augmented Democracy",
    "submit_datetime": "2024年05月06日",
    "abstract": "We explore the capabilities of an augmented democracy system built on off-the-shelf LLMs fine-tuned on data summarizing individual preferences across 67 policy proposals collected during the 2022 Brazilian presidential elections. We use a train-test cross-validation setup to estimate the accuracy with which the LLMs predict both: a subject's individual political choices and the aggregate preferences of the full sample of participants. At the individual level, the accuracy of the out of sample predictions lie in the range 69%-76% and are significantly better at predicting the preferences of liberal and college educated participants. At the population level, we aggregate preferences using an adaptation of the Borda score and compare the ranking of policy proposals obtained from a probabilistic sample of participants and from data augmented using LLMs. We find that the augmented data predicts the preferences of the full population of participants better than probabilistic samples alone when these represent less than 30% to 40% of the total population. These results indicate that LLMs are potentially useful for the construction of systems of augmented democracy.",
    "pdf_link": "https://arxiv.org/abs/2405.03452",
    "graphs": [],
    "abstract_cn": "本研究探讨了一种基于2022年巴西总统选举期间收集的67项政策提案的个人偏好数据微调的现成大型语言模型（LLM）所构建的增强民主系统的性能。通过训练-测试交叉验证方法，我们评估了LLM在预测个体政治选择和整体参与者偏好方面的准确度。在个体层面，预测准确率介于69%至76%之间，尤其在预测自由派及受过高等教育的参与者偏好时表现更佳。在群体层面，我们采用Borda得分法汇总偏好，并对比了概率抽样参与者和LLM增强数据所得出的政策提案排名。研究发现，当概率样本代表的人口比例低于30%至40%时，LLM增强数据在预测整体参与者偏好方面优于单纯的概率抽样。这一结果揭示了LLM在构建增强民主系统方面的潜在价值。",
    "title_cn": "大型语言模型（LLMs）：民主增强的新使者",
    "tags": [
      "LLM应用",
      "政治科学",
      "人工智能"
    ]
  },
  {
    "title": "Enhancing Q-Learning with Large Language Model Heuristics",
    "submit_datetime": "2024年05月06日",
    "abstract": "Q-learning excels in learning from feedback within sequential decision-making tasks but requires extensive sampling for significant improvements. Although reward shaping is a powerful technique for enhancing learning efficiency, it can introduce biases that affect agent performance. Furthermore, potential-based reward shaping is constrained as it does not allow for reward modifications based on actions or terminal states, potentially limiting its effectiveness in complex environments. Additionally, large language models (LLMs) can achieve zero-shot learning, but this is generally limited to simpler tasks. They also exhibit low inference speeds and occasionally produce hallucinations. To address these issues, we propose \\textbf{LLM-guided Q-learning} that employs LLMs as heuristic to aid in learning the Q-function for reinforcement learning. It combines the advantages of both technologies without introducing performance bias. Our theoretical analysis demonstrates that the LLM heuristic provides action-level guidance. Additionally, our architecture has the capability to convert the impact of hallucinations into exploration costs. Moreover, the converged Q function corresponds to the MDP optimal Q function. Experiment results demonstrated that our algorithm enables agents to avoid ineffective exploration, enhances sampling efficiency, and is well-suited for complex control tasks.",
    "pdf_link": "https://arxiv.org/abs/2405.03341",
    "graphs": [],
    "abstract_cn": "Q-学习在序列决策任务中通过反馈学习表现出色，但要实现显著提升，需要进行大量的采样。奖励塑形技术虽能提高学习效率，却可能带来影响代理表现的偏差。特别是基于潜力的奖励塑形，由于无法根据动作或最终状态调整奖励，其在复杂环境中的效果可能受限。大型语言模型（LLM）能够实现零样本学习，但这种能力通常只适用于简单任务，并且存在推理速度慢和偶尔产生幻觉的问题。为应对这些挑战，我们提出了**LLM辅助的Q-学习**方法，该方法使用LLM作为启发式工具来辅助强化学习中的Q函数学习。这种方法既融合了两种技术的优势，又不会带来性能上的偏差。理论上，LLM启发式能够提供动作级别的指导，并且我们的架构能够将幻觉的影响转化为探索成本。此外，我们的方法确保了收敛后的Q函数与MDP的最优Q函数相对应。实验结果显示，我们的算法能够有效避免无效探索，提升采样效率，并特别适合于复杂的控制任务。",
    "title_cn": "利用大型语言模型的启发式方法来提升 Q-Learning 的性能",
    "tags": [
      "Agent",
      "",
      "控制任务"
    ]
  },
  {
    "title": "WorldQA: Multimodal World Knowledge in Videos through Long-Chain Reasoning",
    "submit_datetime": "2024年05月06日",
    "abstract": "Multimodal information, together with our knowledge, help us to understand the complex and dynamic world. Large language models (LLM) and large multimodal models (LMM), however, still struggle to emulate this capability. In this paper, we present WorldQA, a video understanding dataset designed to push the boundaries of multimodal world models with three appealing properties: (1) Multimodal Inputs: The dataset comprises 1007 question-answer pairs and 303 videos, necessitating the analysis of both auditory and visual data for successful interpretation. (2) World Knowledge: We identify five essential types of world knowledge for question formulation. This approach challenges models to extend their capabilities beyond mere perception. (3) Long-Chain Reasoning: Our dataset introduces an average reasoning step of 4.45, notably surpassing other videoQA datasets. Furthermore, we introduce WorldRetriever, an agent designed to synthesize expert knowledge into a coherent reasoning chain, thereby facilitating accurate responses to WorldQA queries. Extensive evaluations of 13 prominent LLMs and LMMs reveal that WorldRetriever, although being the most effective model, achieved only 70% of humanlevel performance in multiple-choice questions. This finding highlights the necessity for further advancement in the reasoning and comprehension abilities of models. Our experiments also yield several key insights. For instance, while humans tend to perform better with increased frames, current LMMs, including WorldRetriever, show diminished performance under similar conditions. We hope that WorldQA,our methodology, and these insights could contribute to the future development of multimodal world models.",
    "pdf_link": "https://arxiv.org/abs/2405.03272",
    "graphs": [],
    "abstract_cn": "多模态信息与我们的知识相结合，助我们洞悉这个复杂多变的世界。但大型语言模型（LLM）和大型多模态模型（LMM）在模拟这一能力上仍有挑战。本文提出了WorldQA，这是一个旨在拓展多模态世界模型极限的视频理解数据集，具备三大特点：（1）多模态输入：包含1007个问答对和303个视频，要求分析视听数据以实现准确理解。（2）世界知识：我们辨识出五种关键的世界知识类型，用于构建问题。这要求模型不仅要感知，还要深入理解。（3）长链推理：数据集平均推理步骤达到4.45，超越了其他视频问答数据集。我们还推出了WorldRetriever，这是一个将专家知识整合成连贯推理链的代理，以提高对WorldQA查询的准确回答。对13种主流LLM和LMM的广泛评估显示，尽管WorldRetriever是最有效的模型，但在多项选择题中仅达到了70%的人类水平。这一发现强调了模型在推理和理解能力上需要进一步进步。实验还揭示了关键见解，例如，人类在增加帧数时表现更佳，而当前的LMM，包括WorldRetriever，在类似条件下性能下降。我们期望WorldQA、我们的方法和这些见解能为多模态世界模型的未来发展提供助力。",
    "title_cn": "WorldQA：通过长链推理，探索视频内容中的多模态世界知识",
    "tags": [
      "Agent",
      "视频理解",
      "人工智能"
    ]
  },
  {
    "title": "MARE: Multi-Agents Collaboration Framework for Requirements Engineering",
    "submit_datetime": "2024年05月06日",
    "abstract": "Requirements Engineering (RE) is a critical phase in the software development process that generates requirements specifications from stakeholders' needs. Recently, deep learning techniques have been successful in several RE tasks. However, obtaining high-quality requirements specifications requires collaboration across multiple tasks and roles. In this paper, we propose an innovative framework called MARE, which leverages collaboration among large language models (LLMs) throughout the entire RE process. MARE divides the RE process into four tasks: elicitation, modeling, verification, and specification. Each task is conducted by engaging one or two specific agents and each agent can conduct several actions. MARE has five agents and nine actions. To facilitate collaboration between agents, MARE has designed a workspace for agents to upload their generated intermediate requirements artifacts and obtain the information they need. We conduct experiments on five public cases, one dataset, and four new cases created by this work. We compared MARE with three baselines using three widely used metrics for the generated requirements models. Experimental results show that MARE can generate more correct requirements models and outperform the state-of-the-art approaches by 15.4%. For the generated requirements specifications, we conduct a human evaluation in three aspects and provide insights about the quality",
    "pdf_link": "https://arxiv.org/abs/2405.03256",
    "graphs": [],
    "abstract_cn": "需求工程（RE）是软件开发流程中至关重要的一环，它负责从利益相关者的需求中提炼出需求规格。深度学习技术在RE的多个任务中已取得显著成效。但要制定出优质的需求规格，需要跨不同任务和角色的通力合作。本文提出了一个名为MARE的创新框架，该框架通过大型语言模型（LLMs）在整个RE流程中的协作来提升效率。MARE将RE流程细化为需求引出、建模、验证和规格化四个子任务，每个任务由特定代理执行，且每个代理能执行多项操作。MARE包含五个代理和九种操作。为促进代理间的合作，MARE特别设计了一个工作空间，以便代理上传中间需求工件并获取所需信息。我们在五个公开案例、一个数据集以及本研究创造的四个新案例上进行了实验，并使用三个通用指标与三个基线模型进行了比较。实验结果显示，MARE在生成正确需求模型方面更胜一筹，性能提升了15.4%。此外，我们还对生成的需求规格进行了人工评估，并从三个方面提供了质量分析的深刻见解。",
    "title_cn": "MARE：需求工程的多智能体协作框架",
    "tags": [
      "Agent",
      "软件工程",
      "人工智能"
    ]
  },
  {
    "title": "Pose Priors from Language Models",
    "submit_datetime": "2024年05月06日",
    "abstract": "We present a zero-shot pose optimization method that enforces accurate physical contact constraints when estimating the 3D pose of humans. Our central insight is that since language is often used to describe physical interaction, large pretrained text-based models can act as priors on pose estimation.\n  We can thus leverage this insight to improve pose estimation by converting natural language descriptors, generated by a large multimodal model (LMM), into tractable losses to constrain the 3D pose optimization. Despite its simplicity, our method produces surprisingly compelling pose reconstructions of people in close contact, correctly capturing the semantics of the social and physical interactions. We demonstrate that our method rivals more complex state-of-the-art approaches that require expensive human annotation of contact points and training specialized models. Moreover, unlike previous approaches, our method provides a unified framework for resolving self-contact and person-to-person contact.",
    "pdf_link": "https://arxiv.org/abs/2405.03689",
    "graphs": [],
    "abstract_cn": "本文介绍了一种无需训练的姿态优化技术，该技术在估算人体三维姿态时，能够确保精确的物理接触限制。核心观点在于，语言常用于描述物理互动，因此可以利用大型预训练文本模型作为姿态估计的参考依据。基于此，我们将大型多模态模型生成的自然语言描述转换为可操作的损失函数，以此来优化三维姿态。此方法虽然简便，却能生成极具说服力的人物姿态重建效果，精准捕捉社交和物理互动的细节。实验结果表明，该方法的效果可与那些需要人工标注接触点和专门模型训练的复杂先进方法相竞争。此外，与以往的研究相比，本方法提供了一个统一的解决方案，用以处理自我接触和人际接触的问题。",
    "title_cn": "语言模型中提炼的姿态先验",
    "tags": [
      "LLM应用",
      "计算机视觉",
      "人工智能"
    ]
  },
  {
    "title": "Complex Video Reasoning and Robustness Evaluation Suite for Video-LMMs",
    "submit_datetime": "2024年05月06日",
    "abstract": "Recent advancements in Large Language Models (LLMs) have led to the development of Video Large Multi-modal Models (Video-LMMs) that can handle a wide range of video understanding tasks. These models have the potential to be deployed in real-world applications such as robotics, AI assistants, medical imaging, and autonomous vehicles. The widespread adoption of Video-LMMs in our daily lives underscores the importance of ensuring and evaluating their robust performance in mirroring human-like reasoning and interaction capabilities in complex, real-world contexts. However, existing benchmarks for Video-LMMs primarily focus on general video comprehension abilities and neglect assessing their reasoning capabilities over complex videos in the real-world context, and robustness of these models through the lens of user prompts as text queries. In this paper, we present the Complex Video Reasoning and Robustness Evaluation Suite (CVRR-ES), a novel benchmark that comprehensively assesses the performance of Video-LMMs across 11 diverse real-world video dimensions. We evaluate 9 recent models, including both open-source and closed-source variants, and find that most of the Video-LMMs, {especially open-source ones,} struggle with robustness and reasoning when dealing with complex videos. Based on our analysis, we develop a training-free Dual-Step Contextual Prompting (DSCP) technique to enhance the performance of existing Video-LMMs. Our findings provide valuable insights for building the next generation of human-centric AI systems with advanced robustness and reasoning capabilities. Our dataset and code are publicly available at: https://mbzuai-oryx.github.io/CVRR-Evaluation-Suite/.",
    "pdf_link": "https://arxiv.org/abs/2405.03690",
    "graphs": [],
    "abstract_cn": "近期大型语言模型（LLMs）的突破性进展催生了视频大型多模态模型（Video-LMMs），这些模型能够胜任多样化的视频理解任务，并有望应用于机器人、AI助理、医学影像和自动驾驶汽车等领域。Video-LMMs在日常生活中的日益普及凸显了评估其在模拟复杂现实世界环境中人类般的推理和交互能力的重要性。然而，目前的Video-LMMs评估标准多集中于基础视频理解，而忽略了对现实世界复杂视频推理能力及用户文本查询下模型鲁棒性的考量。本文提出了复杂视频推理与鲁棒性评估套件（CVRR-ES），这是一个全新的基准，全面检测Video-LMMs在11个真实世界视频维度的表现。我们测试了9种最新模型，包括开源和闭源版本，发现大多数Video-LMMs在处理复杂视频时面临鲁棒性和推理的挑战。基于深入分析，我们提出了一种无需训练的双重步骤上下文提示（DSCP）技术，以提升现有Video-LMMs的性能。我们的研究为开发下一代以人为本、具备更高鲁棒性和推理能力的AI系统提供了深刻见解。相关数据集和代码已在 https://mbzuai-oryx.github.io/CVRR-Evaluation-Suite/ 公开发布。",
    "title_cn": "为视频大型语言模型（Video-LMMs）设计的一套复杂视频推理与鲁棒性评估工具。",
    "tags": [
      "LLM应用",
      "视频理解",
      "人工智能"
    ]
  },
  {
    "title": "Large Language Models Reveal Information Operation Goals, Tactics, and Narrative Frames",
    "submit_datetime": "2024年05月06日",
    "abstract": "Adversarial information operations can destabilize societies by undermining fair elections, manipulating public opinions on policies, and promoting scams. Despite their widespread occurrence and potential impacts, our understanding of influence campaigns is limited by manual analysis of messages and subjective interpretation of their observable behavior. In this paper, we explore whether these limitations can be mitigated with large language models (LLMs), using GPT-3.5 as a case-study for coordinated campaign annotation. We first use GPT-3.5 to scrutinize 126 identified information operations spanning over a decade. We utilize a number of metrics to quantify the close (if imperfect) agreement between LLM and ground truth descriptions. We next extract coordinated campaigns from two large multilingual datasets from X (formerly Twitter) that respectively discuss the 2022 French election and 2023 Balikaran Philippine-U.S. military exercise in 2023. For each coordinated campaign, we use GPT-3.5 to analyze posts related to a specific concern and extract goals, tactics, and narrative frames, both before and after critical events (such as the date of an election). While the GPT-3.5 sometimes disagrees with subjective interpretation, its ability to summarize and interpret demonstrates LLMs' potential to extract higher-order indicators from text to provide a more complete picture of the information campaigns compared to previous methods.",
    "pdf_link": "https://arxiv.org/abs/2405.03688",
    "graphs": [],
    "abstract_cn": "对抗性信息战可能通过破坏公正选举、操纵政策舆论和推广欺诈活动来动摇社会根基。尽管这类事件频发且影响深远，我们对其影响力运作的理解却因手工分析信息和主观行为解读而受限。本文旨在探究大型语言模型（LLMs），尤其是GPT-3.5，是否能够克服这些局限，以更高效地标注和分析协调性的信息战活动。研究首先利用GPT-3.5对过去十年间确认的126起信息战案例进行深入分析，并通过多种指标衡量LLM与实际情况描述的契合度。随后，研究从X（前Twitter）的两大多语言数据库中提取出与2022年法国大选和2023年菲律宾-美国巴利卡兰军事演习相关的协调性信息战活动。对于每项活动，GPT-3.5都被用于分析特定议题相关的帖子，并在关键事件发生前后提取其目标、策略和叙事框架。虽然GPT-3.5的解读有时与主观看法相左，但其归纳和阐释的能力证明了LLMs在从文本中提炼深层次指标方面的巨大潜力，这为我们提供了一种比传统方法更为全面的信息战活动分析视角。",
    "title_cn": "大型语言模型披露了信息战的作战目标、策略运用以及叙述构建的框架。",
    "tags": [
      "LLM应用",
      "信息战分析",
      ""
    ]
  },
  {
    "title": "Language-Image Models with 3D Understanding",
    "submit_datetime": "2024年05月06日",
    "abstract": "Multi-modal large language models (MLLMs) have shown incredible capabilities in a variety of 2D vision and language tasks. We extend MLLMs' perceptual capabilities to ground and reason about images in 3-dimensional space. To that end, we first develop a large-scale pre-training dataset for 2D and 3D called LV3D by combining multiple existing 2D and 3D recognition datasets under a common task formulation: as multi-turn question-answering. Next, we introduce a new MLLM named Cube-LLM and pre-train it on LV3D. We show that pure data scaling makes a strong 3D perception capability without 3D specific architectural design or training objective. Cube-LLM exhibits intriguing properties similar to LLMs: (1) Cube-LLM can apply chain-of-thought prompting to improve 3D understanding from 2D context information. (2) Cube-LLM can follow complex and diverse instructions and adapt to versatile input and output formats. (3) Cube-LLM can be visually prompted such as 2D box or a set of candidate 3D boxes from specialists. Our experiments on outdoor benchmarks demonstrate that Cube-LLM significantly outperforms existing baselines by 21.3 points of AP-BEV on the Talk2Car dataset for 3D grounded reasoning and 17.7 points on the DriveLM dataset for complex reasoning about driving scenarios, respectively. Cube-LLM also shows competitive results in general MLLM benchmarks such as refCOCO for 2D grounding with (87.0) average score, as well as visual question answering benchmarks such as VQAv2, GQA, SQA, POPE, etc. for complex reasoning. Our project is available at https://janghyuncho.github.io/Cube-LLM.",
    "pdf_link": "https://arxiv.org/abs/2405.03685",
    "graphs": [],
    "abstract_cn": "多模态大型语言模型（MLLMs）在二维视觉和语言任务中展现了卓越性能。本研究进一步拓展了MLLMs的感知范畴，使其能够在三维空间中对图像进行定位和推理。为此，我们创建了一个名为LV3D的大规模预训练数据集，整合了多个现有的二维和三维识别数据集，以多轮问答的形式统一构建任务。随后，我们推出了一款新的MLLM——Cube-LLM，并在LV3D上对其进行了预训练。我们发现，仅通过数据规模的增长，即使没有特定的三维架构设计或训练目标，也能显著提升三维感知能力。Cube-LLM展现出了与LLMs相似的特质：（1）能够通过思维链提示增强从二维信息中理解三维场景的能力；（2）能够遵循复杂多样的指令，并适应多变的输入输出格式；（3）能够通过视觉提示，如二维框或专家提供的一组候选三维框，进行交互。在户外基准测试中，Cube-LLM在3D地面推理任务上以21.3点的AP-BEV得分超越了现有基准，在DriveLM数据集上针对复杂驾驶场景推理的任务上也以17.7点的优势领先。此外，Cube-LLM在通用MLLM基准测试如refCOCO的二维定位任务中取得了87.0的平均分，并在视觉问答基准测试如VQAv2、GQA、SQA、POPE等中展现了强劲的竞争力。项目详情可访问 https://janghyuncho.github.io/Cube-LLM。",
    "title_cn": "融合3D理解的语言与图像模型",
    "tags": [
      "LLM应用",
      "计算机视觉",
      ""
    ]
  },
  {
    "title": "AtomGPT: Atomistic Generative Pre-trained Transformer for Forward and Inverse Materials Design",
    "submit_datetime": "2024年05月06日",
    "abstract": "Large language models (LLMs) such as generative pretrained transformers (GPTs) have shown potential for various commercial applications, but their applicability for materials design remains underexplored. In this article, we introduce AtomGPT, a model specifically developed for materials design based on transformer architectures, to demonstrate the capability for both atomistic property prediction and structure generation. We show that a combination of chemical and structural text descriptions can efficiently predict material properties with accuracy comparable to graph neural network models, including formation energies, electronic bandgaps from two different methods and superconducting transition temperatures. Furthermore, we demonstrate that AtomGPT can generate atomic structures for tasks such as designing new superconductors, with the predictions validated through density functional theory calculations. This work paves the way for leveraging LLMs in forward and inverse materials design, offering an efficient approach to the discovery and optimization of materials.",
    "pdf_link": "https://arxiv.org/abs/2405.03680",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs），例如生成预训练变换器（GPTs），在商业应用领域展现出巨大潜力，但其在材料设计领域的应用尚未被深入挖掘。本文介绍了 AtomGPT，这是一款专为材料设计量身定制的模型，基于变换器架构，旨在实现原子性质预测和结构生成。我们证明，结合化学和结构文本描述可以有效预测材料属性，准确度与图神经网络模型相当，包括形成能、两种方法计算的电子带隙以及超导转变温度。此外，AtomGPT 还能为设计新型超导体等任务生成原子结构，并通过密度泛函理论计算对预测结果进行了验证。这项研究为利用 LLMs 进行正向和逆向材料设计开辟了新途径，为材料的发现和优化提供了一种高效率的解决方案。",
    "title_cn": "AtomGPT：一种原子级别的生成预训练变换器，专为正向和逆向材料设计而开发。",
    "tags": [
      "LLM应用",
      "材料设计",
      "人工智能"
    ]
  },
  {
    "title": "When LLMs Meet Cybersecurity: A Systematic Literature Review",
    "submit_datetime": "2024年05月06日",
    "abstract": "The rapid advancements in large language models (LLMs) have opened new avenues across various fields, including cybersecurity, which faces an ever-evolving threat landscape and need for innovative technologies. Despite initial explorations into the application of LLMs in cybersecurity, there is a lack of a comprehensive overview of this research area. This paper bridge this gap by providing a systematic literature review, encompassing an analysis of over 180 works, spanning across 25 LLMs and more than 10 downstream scenarios. Our comprehensive overview addresses three critical research questions: the construction of cybersecurity-oriented LLMs, LLMs' applications in various cybersecurity tasks, and the existing challenges and further research in this area. This study aims to shed light on the extensive potential of LLMs in enhancing cybersecurity practices, and serve as a valuable resource for applying LLMs in this doamin. We also maintain and regularly updated list of practical guides on LLMs for cybersecurity at https://github.com/tmylla/Awesome-LLM4Cybersecurity.",
    "pdf_link": "https://arxiv.org/abs/2405.03644",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）的迅猛进步为多个领域，尤其是网络安全领域，带来了新的机遇。网络安全领域面临着不断变化的威胁环境，迫切需要创新技术的支撑。尽管对LLMs在网络安全领域的应用进行了初步的探讨，但目前尚缺一个对该研究领域的全面梳理。本文旨在填补这一空白，通过系统性文献回顾，分析了超过180项研究，覆盖了25种LLMs及其在10多个不同场景下的应用。本研究全面解答了三个关键研究问题：如何构建面向网络安全的LLMs、LLMs在网络安全任务中的应用情况，以及该领域目前面临的挑战和未来的研究方向。我们的目标是揭示LLMs在提升网络安全实践中的巨大潜力，并为LLMs在该领域的应用提供一个宝贵的参考资源。此外，我们还维护了一个关于网络安全LLMs的实用指南列表，并定期在 https://github.com/tmylla/Awesome-LLM4Cybersecurity 更新。",
    "title_cn": "大型语言模型（LLM）与网络安全的邂逅：一篇系统性的文献综述。",
    "tags": [
      "LLM应用",
      "网络安全",
      "系统性文献回顾"
    ]
  },
  {
    "title": "A Controlled Experiment on the Energy Efficiency of the Source Code Generated by Code Llama",
    "submit_datetime": "2024年05月06日",
    "abstract": "Context. Nowadays, 83% of software developers use Large Language Models (LLMs) to generate code. LLMs recently became essential to increase the productivity of software developers and decrease the time and cost of software development. Developers ranging from novices to experts use LLM tools not only to detect and patch bugs, but also to integrate generated code into their software. However, as of today there is no objective assessment of the energy efficiency of the source code generated by LLM tools. Released in August 2023, Code Llama is one of the most recent LLM tools.\n  Goal. In this paper, we present an empirical study that assesses the energy efficiency of Code Llama with respect to human-written source code.\n  Method. We design an experiment involving three human-written benchmarks implemented in C++, JavaScript, and Python. We ask Code Llama to generate the code of the benchmarks using different prompts and temperatures. Therefore, we execute both implementations and profile their energy efficiency.\n  Results. Our study shows that the energy efficiency of code generated by Code Llama is heavily-dependent on the chosen programming language and the specific code problem at hand. Also, human implementations tend to be more energy efficient overall, with generated JavaScript code outperforming its human counterpart. Moreover, explicitly asking Code Llama to generate energy-efficient code results in an equal or worse energy efficiency, as well as using different temperatures seems not to affect the energy efficiency of generated code.\n  Conclusions. According to our results, code generated using Code Llama does not guarantee energy efficiency, even when prompted to do so. Therefore, software developers should evaluate the energy efficiency of generated code before integrating it into the software system under development.",
    "pdf_link": "https://arxiv.org/abs/2405.03616",
    "graphs": [],
    "abstract_cn": "如今，超过八成的软件开发者借助大型语言模型（LLMs）来编写代码，这些模型已成为提升开发效率、降低开发时间和成本的利器。开发者们利用 LLM 工具进行漏洞检测、修补，并将生成的代码融入软件之中。尽管如此，对于这些工具产出的源代码能效，尚缺乏客观评价。Code Llama 作为 2023 年 8 月推出的最新 LLM 工具，本研究旨在实证评估其与人工编写代码的能效对比。我们通过实验，选取了 C++、JavaScript 和 Python 三种语言编写的三个基准测试，让 Code Llama 根据不同的提示和温度生成相应的代码，并与人工编写的代码进行了能效对比分析。实验结果揭示，Code Llama 生成的代码能效与所用编程语言和特定代码问题紧密相关。总体而言，人工编写的代码在能效上更胜一筹，尤其是在 JavaScript 代码的生成上，机器生成的代码表现更佳。此外，即便是明确指示 Code Llama 生成节能代码，其结果也并未显示出能效上的优势，而且不同的温度设置似乎对生成代码的能效没有显著影响。综上所述，Code Llama 生成的代码并不自动等同于能效最优，开发人员在将这些代码融入开发中的软件系统前，必须先行评估其能效表现。",
    "title_cn": "一项针对 Code Llama 所生成源代码能效的控制性实验研究。",
    "tags": [
      "LLM应用",
      "软件开发",
      "能效评估"
    ]
  },
  {
    "title": "Enabling High-Sparsity Foundational Llama Models with Efficient Pretraining and Deployment",
    "submit_datetime": "2024年05月06日",
    "abstract": "Large language models (LLMs) have revolutionized Natural Language Processing (NLP), but their size creates computational bottlenecks. We introduce a novel approach to create accurate, sparse foundational versions of performant LLMs that achieve full accuracy recovery for fine-tuning tasks at up to 70% sparsity. We achieve this for the LLaMA-2 7B model by combining the SparseGPT one-shot pruning method and sparse pretraining of those models on a subset of the SlimPajama dataset mixed with a Python subset of The Stack dataset. We exhibit training acceleration due to sparsity on Cerebras CS-3 chips that closely matches theoretical scaling. In addition, we establish inference acceleration of up to 3x on CPUs by utilizing Neural Magic's DeepSparse engine and 1.7x on GPUs through Neural Magic's nm-vllm engine. The above gains are realized via sparsity alone, thus enabling further gains through additional use of quantization. Specifically, we show a total speedup on CPUs for sparse-quantized LLaMA models of up to 8.6x. We demonstrate these results across diverse, challenging tasks, including chat, instruction following, code generation, arithmetic reasoning, and summarization to prove their generality. This work paves the way for rapidly creating smaller and faster LLMs without sacrificing accuracy.",
    "pdf_link": "https://arxiv.org/abs/2405.03594",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）引领了自然语言处理（NLP）的新纪元，但其庞大的体量也带来了计算上的瓶颈。我们提出了一种创新的方法，能够构建既精确又稀疏的基础版高效LLMs，这些模型即便在70%的稀疏度下，也能在微调任务中完全恢复准确度。这一成就是通过结合SparseGPT一次性修剪技术和对SlimPajama数据集部分内容以及The Stack数据集中的Python数据子集进行稀疏预训练，在我们LLaMA-2 7B模型上实现的。我们在Cerebras CS-3芯片上的实验显示，由于稀疏性，训练速度显著提升，与理论预测的扩展性高度一致。此外，我们还通过Neural Magic的DeepSparse引擎在CPU上实现了最高达3倍的推理加速，以及通过Neural Magic的nm-vllm引擎在GPU上实现了1.7倍的加速。这些提升仅依靠稀疏化技术实现，为未来通过量化技术进一步提升性能留出了空间。具体而言，我们在CPU上对稀疏-量化的LLaMA模型实现了最高8.6倍的总加速。我们通过在包括聊天、指令执行、代码生成、算术推理和摘要等多样化且具有挑战性的任务上展示这些成果，证明了其广泛的适用性。本研究为打造更小巧、更迅捷且不失精准度的LLMs开辟了新径。",
    "title_cn": "通过高效的预训练和部署策略，成功打造了高稀疏性基础的羊驼模型。",
    "tags": [
      "分类：LLM应用",
      "",
      "计算优化"
    ]
  },
  {
    "title": "Liberating Seen Classes: Boosting Few-Shot and Zero-Shot Text Classification via Anchor Generation and Classification Reframing",
    "submit_datetime": "2024年05月06日",
    "abstract": "Few-shot and zero-shot text classification aim to recognize samples from novel classes with limited labeled samples or no labeled samples at all. While prevailing methods have shown promising performance via transferring knowledge from seen classes to unseen classes, they are still limited by (1) Inherent dissimilarities among classes make the transformation of features learned from seen classes to unseen classes both difficult and inefficient. (2) Rare labeled novel samples usually cannot provide enough supervision signals to enable the model to adjust from the source distribution to the target distribution, especially for complicated scenarios. To alleviate the above issues, we propose a simple and effective strategy for few-shot and zero-shot text classification. We aim to liberate the model from the confines of seen classes, thereby enabling it to predict unseen categories without the necessity of training on seen classes. Specifically, for mining more related unseen category knowledge, we utilize a large pre-trained language model to generate pseudo novel samples, and select the most representative ones as category anchors. After that, we convert the multi-class classification task into a binary classification task and use the similarities of query-anchor pairs for prediction to fully leverage the limited supervision signals. Extensive experiments on six widely used public datasets show that our proposed method can outperform other strong baselines significantly in few-shot and zero-shot tasks, even without using any seen class samples.",
    "pdf_link": "https://arxiv.org/abs/2405.03565",
    "graphs": [],
    "abstract_cn": "少样本与零样本文本分类致力于在有限或无标记样本的情况下，识别新类别的样本。尽管现有技术通过知识迁移展现出潜力，但仍面临两大挑战：一是类别间的本质差异导致特征转换困难且效率低下；二是稀缺的标记新样本难以为模型提供足够的监督信号以适应复杂场景中的分布变化。为应对这些挑战，我们提出了一种简洁高效的策略。该策略旨在打破模型对已知类别的依赖，使其无需先前训练即可对未见类别进行预测。具体而言，我们使用大型预训练语言模型生成伪新样本，挑选出具有代表性的样本作为类别锚点。随后，我们将多类分类问题转化为二元分类问题，并利用查询与锚点对的相似度进行预测，以最大化利用有限的监督信号。在六个广泛使用的公共数据集上的实验结果表明，我们的方法在少样本和零样本任务中显著超越了其他强有力基准，即便在不依赖任何已知类别样本的情况下。",
    "title_cn": "释放已知类别：通过生成锚点和重新构建分类框架，增强少样本与零样本文本分类的性能。",
    "tags": [
      "分类：LLM应用",
      "文本分类",
      "机器学习"
    ]
  },
  {
    "title": "AlphaMath Almost Zero: process Supervision without process",
    "submit_datetime": "2024年05月06日",
    "abstract": "Recent advancements in large language models (LLMs) have substantially enhanced their mathematical reasoning abilities. However, these models still struggle with complex problems that require multiple reasoning steps, frequently leading to logical or numerical errors. While numerical mistakes can largely be addressed by integrating a code interpreter, identifying logical errors within intermediate steps is more challenging. Moreover, manually annotating these steps for training is not only expensive but also demands specialized expertise. In this study, we introduce an innovative approach that eliminates the need for manual annotation by leveraging the Monte Carlo Tree Search (MCTS) framework to generate both the process supervision and evaluation signals automatically. Essentially, when a LLM is well pre-trained, only the mathematical questions and their final answers are required to generate our training data, without requiring the solutions. We proceed to train a step-level value model designed to improve the LLM's inference process in mathematical domains. Our experiments indicate that using automatically generated solutions by LLMs enhanced with MCTS significantly improves the model's proficiency in dealing with intricate mathematical reasoning tasks.",
    "pdf_link": "https://arxiv.org/abs/2405.03553",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.03553v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03553/pipeline.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03553v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03553/mcts.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03553v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03553/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03553v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03553/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03553v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03553/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03553v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03553/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03553v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03553/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03553v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03553/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03553v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03553/x7.png"
      }
    ],
    "abstract_cn": "最新进展使大型语言模型的数学推理能力显著提升。但面对需多步推理的难题，这些模型仍易出错，且逻辑错误的识别尤为棘手。尽管可通过集成代码解释器减少数值错误，但手动标注训练步骤既昂贵又需专业知识。本研究提出了一种创新方法，运用蒙特卡洛树搜索框架自动产生监督和评估信号，免去了手动标注的繁琐。简而言之，预训练良好的大型语言模型仅需数学问题及其答案即可生成训练数据，无需完整解答过程。我们进一步训练了一个步骤级价值模型，以优化模型在数学领域的推理过程。实验结果表明，利用经 MCTS 增强的 LLM 自动生成的解答，显著提升了模型解决复杂数学问题的能力。",
    "title_cn": "AlphaMath 近乎零差错：实现无需过程的进程监控",
    "tags": [
      "LLM应用",
      "",
      "自动化推理"
    ]
  },
  {
    "title": "MAmmoTH2: Scaling Instructions from the Web",
    "submit_datetime": "2024年05月06日",
    "abstract": "Instruction tuning improves the reasoning abilities of large language models (LLMs), with data quality and scalability being the crucial factors. Most instruction tuning data come from human crowd-sourcing or GPT-4 distillation. We propose a paradigm to efficiently harvest 10 million naturally existing instruction data from the pre-training web corpus to enhance LLM reasoning. Our approach involves (1) recalling relevant documents, (2) extracting instruction-response pairs, and (3) refining the extracted pairs using open-source LLMs. Fine-tuning base LLMs on this dataset, we build MAmmoTH2 models, which significantly boost performance on reasoning benchmarks. Notably, MAmmoTH2-7B's (Mistral) performance increases from 11% to 34% on MATH and from 36% to 67% on GSM8K without training on any in-domain data. Further training MAmmoTH2 on public instruction tuning datasets yields MAmmoTH2-Plus, achieving state-of-the-art performance on several reasoning and chatbot benchmarks. Our work demonstrates how to harvest large-scale, high-quality instruction data without costly human annotation or GPT-4 distillation, providing a new paradigm for building better instruction tuning data.",
    "pdf_link": "https://arxiv.org/abs/2405.03548",
    "graphs": [],
    "abstract_cn": "通过指令微调，我们显著提升了大型语言模型（LLMs）的推理能力，其中数据的质量和可扩展性扮演着至关重要的角色。目前，大多数指令微调数据依赖于人工众包或GPT-4的蒸馏过程。为了解决这一问题，我们提出了一种创新的方法，能够从预训练的网络语料库中高效地提炼出1000万个自然生成的指令数据，以此增强LLM的推理性能。我们的方法涵盖了三个步骤：（1）检索相关文档，（2）抽取指令与响应对，以及（3）利用开源的LLMs对抽取的对进行优化。基于这些数据，我们对基础的LLMs进行了微调，开发出了性能显著提升的MAmmoTH2模型。特别是，MAmmoTH2-7B（米斯特拉尔）在MATH基准上的性能从11%飙升至34%，在GSM8K基准上从36%跃升至67%，所有这些提升都是在没有使用任何特定领域数据进行训练的情况下实现的。此外，我们在公共指令微调数据集上对MAmmoTH2进行了进一步训练，推出了性能卓越的MAmmoTH2-Plus，在多个推理和聊天机器人基准测试中达到了行业领先水平。我们的研究不仅展示了如何无需昂贵的人工标注或GPT-4蒸馏就能收集到大规模、高品质的指令数据，更为构建更优质的指令微调数据集提供了全新的思路。",
    "title_cn": "MAmmoTH2：网络指令的规模化应用",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Position Paper: Leveraging Foundational Models for Black-Box Optimization: Benefits, Challenges, and Future Directions",
    "submit_datetime": "2024年05月06日",
    "abstract": "Undeniably, Large Language Models (LLMs) have stirred an extraordinary wave of innovation in the machine learning research domain, resulting in substantial impact across diverse fields such as reinforcement learning, robotics, and computer vision. Their incorporation has been rapid and transformative, marking a significant paradigm shift in the field of machine learning research.\n  However, the field of experimental design, grounded on black-box optimization, has been much less affected by such a paradigm shift, even though integrating LLMs with optimization presents a unique landscape ripe for exploration. In this position paper, we frame the field of black-box optimization around sequence-based foundation models and organize their relationship with previous literature. We discuss the most promising ways foundational language models can revolutionize optimization, which include harnessing the vast wealth of information encapsulated in free-form text to enrich task comprehension, utilizing highly flexible sequence models such as Transformers to engineer superior optimization strategies, and enhancing performance prediction over previously unseen search spaces.",
    "pdf_link": "https://arxiv.org/abs/2405.03547",
    "graphs": [],
    "abstract_cn": "确实，大型语言模型（LLMs）在机器学习研究领域引发了一场创新的浪潮，对多个领域产生了显著的影响，并迅速推动了该领域的范式变革。然而，实验设计这一领域，尤其是基于黑箱优化的部分，受到这种变革的影响相对较小。尽管如此，将LLMs整合到优化中，为我们开辟了一个新的探索领域。在本篇立场论文中，我们以序列为基础的基础模型为中心，构建了黑箱优化的研究框架，并梳理了其与现有文献的联系。我们探讨了基础语言模型如何通过利用文本中的丰富信息来增强任务理解、运用灵活的序列模型如Transformer来开发更高效的优化策略，以及如何提升对未知搜索空间的性能预测，从而引领优化领域的革命。",
    "title_cn": "立场论文：探索基础模型在黑盒优化中的应用——优势、挑战与前行之路。",
    "tags": [
      "LLM应用",
      "机器学习",
      "实验设计"
    ]
  },
  {
    "title": "Are Human Rules Necessary? Generating Reusable APIs with CoT Reasoning and In-Context Learning",
    "submit_datetime": "2024年05月06日",
    "abstract": "Inspired by the great potential of Large Language Models (LLMs) for solving complex coding tasks, in this paper, we propose a novel approach, named Code2API, to automatically perform APIzation for Stack Overflow code snippets. Code2API does not require additional model training or any manual crafting rules and can be easily deployed on personal computers without relying on other external tools. Specifically, Code2API guides the LLMs through well-designed prompts to generate well-formed APIs for given code snippets. To elicit knowledge and logical reasoning from LLMs, we used chain-of-thought (CoT) reasoning and few-shot in-context learning, which can help the LLMs fully understand the APIzation task and solve it step by step in a manner similar to a developer. Our evaluations show that Code2API achieves a remarkable accuracy in identifying method parameters (65%) and return statements (66%) equivalent to human-generated ones, surpassing the current state-of-the-art approach, APIzator, by 15.0% and 16.5% respectively. Moreover, compared with APIzator, our user study demonstrates that Code2API exhibits superior performance in generating meaningful method names, even surpassing the human-level performance, and developers are more willing to use APIs generated by our approach, highlighting the applicability of our tool in practice. Finally, we successfully extend our framework to the Python dataset, achieving a comparable performance with Java, which verifies the generalizability of our tool.",
    "pdf_link": "https://arxiv.org/abs/2405.03509",
    "graphs": [],
    "abstract_cn": "本文提出了Code2API，一种创新的方法，旨在自动化地为Stack Overflow上的代码片段实现API化。该方法无需额外训练模型或手工制定规则，便于个人电脑部署，且不依赖外部工具。Code2API利用精心构造的提示，引导大型语言模型生成结构化的API。通过思维链推理和少量样本的上下文学习，我们激发了模型的知识和逻辑推理能力，使其能够逐步深入理解并解决API化任务，模仿开发者的思维方式。在性能评估中，Code2API在识别方法参数和返回语句的准确度上分别达到了65%和66%，超越了当前领先技术APIzator的15.0%和16.5%。用户研究进一步显示，Code2API在生成富有意义的方法名称上超越了APIzator，甚至达到了超越人类表现的水平，开发者更倾向于使用我们方法生成的API，这凸显了我们工具在实际应用中的潜力。此外，我们将框架成功扩展至Python数据集，并在Java上实现了相似的性能，证明了我们工具的泛化能力。",
    "title_cn": "人类规则真有必要吗？借助 CoT 推理与上下文学习，我们能够生成可复用的 API。",
    "tags": [
      "LLM应用",
      "软件开发",
      ""
    ]
  },
  {
    "title": "UnsafeBench: Benchmarking Image Safety Classifiers on Real-World and AI-Generated Images",
    "submit_datetime": "2024年05月06日",
    "abstract": "Image safety classifiers play an important role in identifying and mitigating the spread of unsafe images online (e.g., images including violence, hateful rhetoric, etc.). At the same time, with the advent of text-to-image models and increasing concerns about the safety of AI models, developers are increasingly relying on image safety classifiers to safeguard their models. Yet, the performance of current image safety classifiers remains unknown for real-world and AI-generated images. To bridge this research gap, in this work, we propose UnsafeBench, a benchmarking framework that evaluates the effectiveness and robustness of image safety classifiers. First, we curate a large dataset of 10K real-world and AI-generated images that are annotated as safe or unsafe based on a set of 11 unsafe categories of images (sexual, violent, hateful, etc.). Then, we evaluate the effectiveness and robustness of five popular image safety classifiers, as well as three classifiers that are powered by general-purpose visual language models. Our assessment indicates that existing image safety classifiers are not comprehensive and effective enough in mitigating the multifaceted problem of unsafe images. Also, we find that classifiers trained only on real-world images tend to have degraded performance when applied to AI-generated images. Motivated by these findings, we design and implement a comprehensive image moderation tool called PerspectiveVision, which effectively identifies 11 categories of real-world and AI-generated unsafe images. The best PerspectiveVision model achieves an overall F1-Score of 0.810 on six evaluation datasets, which is comparable with closed-source and expensive state-of-the-art models like GPT-4V. UnsafeBench and PerspectiveVision can aid the research community in better understanding the landscape of image safety classification in the era of generative AI.",
    "pdf_link": "https://arxiv.org/abs/2405.03486",
    "graphs": [],
    "abstract_cn": "图像安全分类器对于在线识别和减少不安全图像（如暴力、仇恨言论等）的传播至关重要。随着文本到图像模型的兴起以及对AI模型安全性的担忧增加，开发者越发依赖这些分类器来保护他们的模型。但是，这些分类器在处理现实世界图像和AI生成图像时的性能尚未明确。为填补这一研究空缺，本研究提出了UnsafeBench，这是一个评估图像安全分类器效能和鲁棒性的基准测试框架。我们首先构建了一个包含10,000张现实世界和AI生成图像的数据集，这些图像根据11个不安全类别（如色情、暴力、仇恨等）被标记为安全或不安全。接着，我们评估了五种主流图像安全分类器以及三种由通用视觉语言模型支持的分类器的有效性和鲁棒性。我们的评估发现，现有的分类器在应对多维度不安全图像问题上还不够全面和有效。此外，仅基于现实世界图像训练的分类器在处理AI生成图像时表现不佳。基于这些发现，我们设计并实施了一个全面的图像审核工具PerspectiveVision，它能够有效识别11种现实世界和AI生成的不安全图像类别。PerspectiveVision的最佳模型在六个评估数据集上达到了0.810的综合F1分数，与封闭源和高成本的最先进模型如GPT-4V相当。UnsafeBench和PerspectiveVision有助于研究社区更深入地理解在生成AI时代图像安全分类的领域。",
    "title_cn": "UnsafeBench 项目致力于对现实世界及 AI 创造的图像进行图像安全分类器的基准测试，旨在评估和提升图像安全分类技术的实际效能。",
    "tags": [
      "分类：LLM应用\n\n这篇论文主要研究了图像安全分类器在识别和减少不安全图像（如暴力、仇恨言论等）传播中的作用，特别是在处理现实世界图像和AI生成图像时的性能。论文提出了一个评估图像安全分类器效能和鲁棒性的基准测试框架UnsafeBench，并构建了一个包含10,000张现实世界和AI生成图像的数据集。此外，论文还设计并实施了一个全面的图像审核工具PerspectiveVision，能够有效识别多种现实世界和AI生成的不安全图像类别。这些研究内容与LLM（大型语言模型）的应用密切相关，因此将这篇论文归类为LLM应用。",
      "图像识别",
      "网络安全"
    ]
  },
  {
    "title": "LGTM: Local-to-Global Text-Driven Human Motion Diffusion Model",
    "submit_datetime": "2024年05月06日",
    "abstract": "In this paper, we introduce LGTM, a novel Local-to-Global pipeline for Text-to-Motion generation. LGTM utilizes a diffusion-based architecture and aims to address the challenge of accurately translating textual descriptions into semantically coherent human motion in computer animation. Specifically, traditional methods often struggle with semantic discrepancies, particularly in aligning specific motions to the correct body parts. To address this issue, we propose a two-stage pipeline to overcome this challenge: it first employs large language models (LLMs) to decompose global motion descriptions into part-specific narratives, which are then processed by independent body-part motion encoders to ensure precise local semantic alignment. Finally, an attention-based full-body optimizer refines the motion generation results and guarantees the overall coherence. Our experiments demonstrate that LGTM gains significant improvements in generating locally accurate, semantically-aligned human motion, marking a notable advancement in text-to-motion applications. Code and data for this paper are available at https://github.com/L-Sun/LGTM",
    "pdf_link": "https://arxiv.org/abs/2405.03485",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.03485v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03485/teaser.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.03485v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03485/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03485v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03485/attention_encoder_block.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.03485v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03485/gallary.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03485v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03485/comparison.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03485v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03485/w_frame_attn.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03485v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03485/wo_frame_attn.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03485v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03485/failure_case.jpg"
      }
    ],
    "abstract_cn": "本文提出了 LGTM，一种创新的文本到动作生成的局部至全局处理流程。该流程采用扩散模型架构，致力于精确地将文本描述转换为计算机动画中的连贯人体动作。传统方法在语义一致性上存在挑战，尤其是在将特定动作与身体部位正确对应时。为此，我们设计了一个分两步的流程：首先，利用大型语言模型（LLM）将整体动作描述细化为部分特定的叙述；然后，通过独立的身体部位动作编码器进行处理，确保局部语义的精确对齐。最终，一个基于注意力机制的全身优化器对动作生成结果进行优化，确保整体的连贯性。实验结果证明，LGTM 在生成精确且语义一致的人体动作方面取得了显著提升，这在文本到动作的应用领域是一个重要的进步。相关代码和数据已在 https://github.com/L-Sun/LGTM 上公开。",
    "title_cn": "LGTM：一种由文本驱动的人体运动扩散模型，实现了从局部细节到全局动作的全面覆盖。",
    "tags": [
      "LLM应用",
      "计算机动画",
      ""
    ]
  },
  {
    "title": "Whispy: Adapting STT Whisper Models to Real-Time Environments",
    "submit_datetime": "2024年05月06日",
    "abstract": "Large general-purpose transformer models have recently become the mainstay in the realm of speech analysis. In particular, Whisper achieves state-of-the-art results in relevant tasks such as speech recognition, translation, language identification, and voice activity detection. However, Whisper models are not designed to be used in real-time conditions, and this limitation makes them unsuitable for a vast plethora of practical applications. In this paper, we introduce Whispy, a system intended to bring live capabilities to the Whisper pretrained models. As a result of a number of architectural optimisations, Whispy is able to consume live audio streams and generate high level, coherent voice transcriptions, while still maintaining a low computational cost. We evaluate the performance of our system on a large repository of publicly available speech datasets, investigating how the transcription mechanism introduced by Whispy impacts on the Whisper output. Experimental results show how Whispy excels in robustness, promptness, and accuracy.",
    "pdf_link": "https://arxiv.org/abs/2405.03484",
    "graphs": [],
    "abstract_cn": "近期，大型通用变换器模型在语音分析领域崭露头角，尤其是 Whisper 在语音识别、翻译、语言识别和声音活动检测等任务上取得了行业领先的成绩。但 Whisper 模型并不适用于实时环境，这限制了其在众多实际应用场景中的使用。本文提出了 Whispy 系统，旨在为预训练的 Whisper 模型赋予实时处理能力。通过一系列结构优化，Whispy 不仅能够实时处理音频流，还能生成高级、连贯的语音转文字，同时保持较低的计算开销。我们在广泛的公开语音数据集上对系统性能进行了评估，探讨了 Whispy 新引入的转录机制对 Whisper 输出的影响。实验结果显示，Whispy 在稳定性、响应速度和准确度上均表现优异。",
    "title_cn": "Whispy：为实时环境量身定制的 STT Whisper 模型",
    "tags": [
      "LLM应用",
      "语音识别",
      "实时处理"
    ]
  },
  {
    "title": "SEvenLLM: Benchmarking, Eliciting, and Enhancing Abilities of Large Language Models in Cyber Threat Intelligence",
    "submit_datetime": "2024年05月06日",
    "abstract": "To address the increasing complexity and frequency of cybersecurity incidents emphasized by the recent cybersecurity threat reports with over 10 billion instances, cyber threat intelligence (CTI) plays a critical role in the modern cybersecurity landscape by offering the insights required to understand and combat the constantly evolving nature of cyber threats. Inspired by the powerful capability of large language models (LLMs) in handling complex tasks, in this paper, we introduce a framework to benchmark, elicit, and improve cybersecurity incident analysis and response abilities in LLMs for Security Events (SEvenLLM). Specifically, we create a high-quality bilingual instruction corpus by crawling cybersecurity raw text from cybersecurity websites to overcome the lack of effective data for information extraction. Then, we design a pipeline to auto-select tasks from the tasks pool and convert the raw text into supervised corpora comprised of question and response. The instruction dataset SEvenLLM-Instruct is used to train cybersecurity LLMs with the multi-task learning objective (27 well-designed tasks) for augmenting the analysis of cybersecurity events. Extensive experiments in our curated benchmark (SEvenLLM-bench) demonstrate that SEvenLLM performs more sophisticated threat analysis and fortifies defenses against the evolving landscape of cyber threats.",
    "pdf_link": "https://arxiv.org/abs/2405.03446",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.03446v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03446/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03446v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03446/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03446v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03446/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03446v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03446/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03446v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03446/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03446v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03446/x6.png"
      }
    ],
    "abstract_cn": "面对网络安全威胁报告所强调的日益增长的网络安全事件复杂性和频发性，以及超过千亿次的安全威胁实例，网络威胁情报（CTI）在现代网络安全领域扮演着关键角色，提供必要的洞察力以理解和对抗不断演变的网络威胁。本文受到大型语言模型（LLMs）处理复杂任务的强大能力的启发，提出了一个用于评估、引导和提升LLMs在安全事件分析和响应方面能力的新框架——SEvenLLM。我们通过爬取网络安全网站的原始文本，构建了一个高质量的双语指令语料库，以解决信息提取有效数据的不足。接着，我们设计了一个流程，自动从任务池中筛选任务，并将原始文本转化为包含问题和答案的监督语料。SEvenLLM-Instruct指令数据集被用于训练网络安全LLMs，采用多任务学习目标（共27项精心设计的任务），以增强对网络安全事件的分析能力。在我们定制的基准测试（SEvenLLM-bench）中进行的广泛实验证明，SEvenLLM能够执行更为精细的威胁分析，并强化了对网络威胁不断变化的防御措施。",
    "title_cn": "SEvenLLM：在网络威胁情报领域，对大型语言模型进行基准测试、能力挖掘与提升。",
    "tags": [
      "LLM应用",
      "网络安全",
      "人工智能"
    ]
  },
  {
    "title": "Gaussian Stochastic Weight Averaging for Bayesian Low-Rank Adaptation of Large Language Models",
    "submit_datetime": "2024年05月06日",
    "abstract": "Fine-tuned Large Language Models (LLMs) often suffer from overconfidence and poor calibration, particularly when fine-tuned on small datasets. To address these challenges, we propose a simple combination of Low-Rank Adaptation (LoRA) with Gaussian Stochastic Weight Averaging (SWAG), facilitating approximate Bayesian inference in LLMs. Through extensive testing across several Natural Language Processing (NLP) benchmarks, we demonstrate that our straightforward and computationally efficient approach improves model generalization and calibration. We further show that our method exhibits greater robustness against distribution shift, as reflected in its performance on out-of-distribution tasks.",
    "pdf_link": "https://arxiv.org/abs/2405.03425",
    "graphs": [],
    "abstract_cn": "微调后的LLMs在面对小型数据集时，容易出现过度自信和校准不准确的问题。为应对这些难题，我们提出了一种结合低秩适应（LoRA）与高斯随机权重平均（SWAG）的简洁方案，以实现LLMs的近似贝叶斯推理。经过多个NLP基准的广泛测试，我们证实了这一方法在提升模型泛化和校准方面的效果显著，且计算效率极高。此外，我们还发现该方法在面对分布偏移时展现出更强的鲁棒性，尤其是在处理分布外任务时的性能表现。",
    "title_cn": "贝叶斯低秩适配大型语言模型的高斯随机权重平均法",
    "tags": [
      "LLM理论",
      "",
      "机器学习"
    ]
  },
  {
    "title": "The high dimensional psychological profile and cultural bias of ChatGPT",
    "submit_datetime": "2024年05月06日",
    "abstract": "Given the rapid advancement of large-scale language models, artificial intelligence (AI) models, like ChatGPT, are playing an increasingly prominent role in human society. However, to ensure that artificial intelligence models benefit human society, we must first fully understand the similarities and differences between the human-like characteristics exhibited by artificial intelligence models and real humans, as well as the cultural stereotypes and biases that artificial intelligence models may exhibit in the process of interacting with humans. This study first measured ChatGPT in 84 dimensions of psychological characteristics, revealing differences between ChatGPT and human norms in most dimensions as well as in high-dimensional psychological representations. Additionally, through the measurement of ChatGPT in 13 dimensions of cultural values, it was revealed that ChatGPT's cultural value patterns are dissimilar to those of various countries/regions worldwide. Finally, an analysis of ChatGPT's performance in eight decision-making tasks involving interactions with humans from different countries/regions revealed that ChatGPT exhibits clear cultural stereotypes in most decision-making tasks and shows significant cultural bias in third-party punishment and ultimatum games. The findings indicate that, compared to humans, ChatGPT exhibits a distinct psychological profile and cultural value orientation, and it also shows cultural biases and stereotypes in interpersonal decision-making. Future research endeavors should emphasize enhanced technical oversight and augmented transparency in the database and algorithmic training procedures to foster more efficient cross-cultural communication and mitigate social disparities.",
    "pdf_link": "https://arxiv.org/abs/2405.03387",
    "graphs": [],
    "abstract_cn": "随着大型语言模型的迅猛发展，人工智能模型如 ChatGPT 在人类社会中的角色日益凸显。要让这些AI模型真正造福人类，我们亟需深入理解它们与人类相似特性的异同，以及在与人类互动时可能体现的文化偏见和刻板印象。本研究对 ChatGPT 进行了84个心理特征维度的测量，发现其在多数维度上与人类存在显著差异，尤其在高维心理表征上。同时，通过13个文化价值维度的评估，揭示了 ChatGPT 的文化价值观与全球不同国家/地区的模式大相径庭。进一步分析 ChatGPT 在八项涉及跨文化互动的决策任务中的表现，结果表明 ChatGPT 在大多数任务中存在明显的文化刻板印象，并在第三方惩罚和最后通牒游戏中表现出显著的文化偏见。这些发现提示我们，ChatGPT 不仅具有独特的心理特征和文化价值观，而且在人际决策中也存在文化偏见和刻板印象。未来的研究应当更加注重技术监管，提高数据库和算法训练过程的透明度，以促进跨文化交流的效率，减少社会不平等。",
    "title_cn": "ChatGPT 拥有复杂的心理特征和文化倾向，这些特性在其多维心理画像中得到了体现。",
    "tags": [
      "LLM应用",
      "人工智能",
      "跨文化交流"
    ]
  },
  {
    "title": "Knowledge-aware Text-Image Retrieval for Remote Sensing Images",
    "submit_datetime": "2024年05月06日",
    "abstract": "Image-based retrieval in large Earth observation archives is challenging because one needs to navigate across thousands of candidate matches only with the query image as a guide. By using text as information supporting the visual query, the retrieval system gains in usability, but at the same time faces difficulties due to the diversity of visual signals that cannot be summarized by a short caption only. For this reason, as a matching-based task, cross-modal text-image retrieval often suffers from information asymmetry between texts and images. To address this challenge, we propose a Knowledge-aware Text-Image Retrieval (KTIR) method for remote sensing images. By mining relevant information from an external knowledge graph, KTIR enriches the text scope available in the search query and alleviates the information gaps between texts and images for better matching. Moreover, by integrating domain-specific knowledge, KTIR also enhances the adaptation of pre-trained vision-language models to remote sensing applications. Experimental results on three commonly used remote sensing text-image retrieval benchmarks show that the proposed knowledge-aware method leads to varied and consistent retrievals, outperforming state-of-the-art retrieval methods.",
    "pdf_link": "https://arxiv.org/abs/2405.03373",
    "graphs": [],
    "abstract_cn": "在庞大的地球观测数据库中进行图像检索并非易事，因为用户必须依靠查询图像来筛选数以千计的潜在匹配项。尽管利用文本信息辅助视觉查询提升了系统的易用性，但由于视觉信号的多样性，这些信号难以用简短的说明文字概括，这使得检索系统面临挑战。针对这一问题，我们提出了一种知识驱动的文本-图像检索（KTIR）方法，专门针对遥感图像。KTIR通过从外部知识库中提取相关信息，扩展了搜索查询中的文本内容，弥补了文本与图像之间的信息不对称，从而提高了匹配质量。此外，KTIR通过融合领域特定知识，增强了预训练的视觉-语言模型对遥感任务的适应能力。在三个广泛使用的遥感文本-图像检索基准测试中，KTIR方法展现出了多样化且一致的检索效果，性能超越了当前的顶尖检索技术。",
    "title_cn": "为遥感图像设计的文本与图像知识感知检索系统",
    "tags": [
      "分类：Agent",
      "",
      "图像检索"
    ]
  },
  {
    "title": "Snake Learning: A Communication- and Computation-Efficient Distributed Learning Framework for 6G",
    "submit_datetime": "2024年05月06日",
    "abstract": "In the evolution towards 6G, integrating Artificial Intelligence (AI) with advanced network infrastructure emerges as a pivotal strategy for enhancing network intelligence and resource utilization. Existing distributed learning frameworks like Federated Learning and Split Learning often struggle with significant challenges in dynamic network environments including high synchronization demands, costly communication overheads, severe computing resource consumption, and data heterogeneity across network nodes. These obstacles hinder the applications of ubiquitous computing capabilities of 6G networks, especially in light of the trend of escalating model parameters and training data volumes. To address these challenges effectively, this paper introduces \"Snake Learning\", a cost-effective distributed learning framework. Specifically, Snake Learning respects the heterogeneity of inter-node computing capability and local data distribution in 6G networks, and sequentially trains the designated part of model layers on individual nodes. This layer-by-layer serpentine update mechanism contributes to significantly reducing the requirements for storage, memory and communication during the model training phase, and demonstrates superior adaptability and efficiency for both Computer Vision (CV) training and Large Language Model (LLM) fine-tuning tasks across homogeneous and heterogeneous data distributions.",
    "pdf_link": "https://arxiv.org/abs/2405.03372",
    "graphs": [],
    "abstract_cn": "迈向 6G 的进程中，融合人工智能与尖端网络基础设施成为提升网络智能化和资源效率的重要策略。然而，诸如联邦学习与分割学习的现有分布式学习架构，在动态网络环境下面临同步要求高、通信成本高昂、计算资源消耗严重以及数据异质性等挑战，这些都限制了 6G 网络普及计算能力的发展，尤其是在模型参数和训练数据量日益增长的背景下。为有效应对这些挑战，本文提出了“Snake Learning”——一种经济高效的分布式学习框架。该框架考虑了 6G 网络中节点间计算能力的异质性和数据分布的本地化，通过在各个节点上顺序训练模型的特定层级，实现了逐层蛇形更新。这一机制大幅降低了模型训练过程中对存储、内存和通信的需求，同时在计算机视觉训练和大型语言模型微调任务中，无论是在同质还是异质数据分布下，都展现了出色的适应性和效率。",
    "title_cn": "Snake Learning，一个为第六代移动通信（6G）量身打造的分布式学习框架，以其卓越的通信和计算效率引领未来学习模式。",
    "tags": [
      "LLM应用",
      "6G通信",
      "人工智能"
    ]
  },
  {
    "title": "Explainable Fake News Detection With Large Language Model via Defense Among Competing Wisdom",
    "submit_datetime": "2024年05月06日",
    "abstract": "Most fake news detection methods learn latent feature representations based on neural networks, which makes them black boxes to classify a piece of news without giving any justification. Existing explainable systems generate veracity justifications from investigative journalism, which suffer from debunking delayed and low efficiency. Recent studies simply assume that the justification is equivalent to the majority opinions expressed in the wisdom of crowds. However, the opinions typically contain some inaccurate or biased information since the wisdom of crowds is uncensored. To detect fake news from a sea of diverse, crowded and even competing narratives, in this paper, we propose a novel defense-based explainable fake news detection framework. Specifically, we first propose an evidence extraction module to split the wisdom of crowds into two competing parties and respectively detect salient evidences. To gain concise insights from evidences, we then design a prompt-based module that utilizes a large language model to generate justifications by inferring reasons towards two possible veracities. Finally, we propose a defense-based inference module to determine veracity via modeling the defense among these justifications. Extensive experiments conducted on two real-world benchmarks demonstrate that our proposed method outperforms state-of-the-art baselines in terms of fake news detection and provides high-quality justifications.",
    "pdf_link": "https://arxiv.org/abs/2405.03371",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.03371v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03371/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03371v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03371/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03371v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03371/x3.png"
      }
    ],
    "abstract_cn": "当前的假新闻识别技术多依赖于神经网络构建的潜在特征表示，导致在缺乏解释的情况下对新闻进行分类，如同一个黑箱。尽管现有的可解释系统尝试从深入调查的新闻报道中提炼出真实性的证据，但它们常因辟谣的滞后和低效而受限。一些新近研究简单地将证据等同于群体智慧中的主流观点，但这些观点可能包含不准确或有偏见的信息，因为群体智慧未经筛选。为了在繁杂多变的叙事海洋中甄别假新闻，本文提出了一种创新的基于防御机制的可解释假新闻检测框架。我们首先设计了一个证据提取模块，将群体智慧划分为两个对立的阵营，并分别搜寻关键证据。接着，为了从证据中提炼出简洁的洞见，我们开发了一个基于提示的模块，该模块使用大型语言模型通过推断两种可能的真实性倾向来生成解释。最终，我们引入了一个基于防御的推理模块，通过模拟这些解释之间的辩论来判定新闻的真实性。在两个现实世界的数据集上的广泛测试显示，我们的方法在假新闻识别的准确性和提供高质量解释方面均超越了现有的顶尖方法。",
    "title_cn": "利用大型语言模型，通过对抗竞争智慧中的策略，实现假新闻的可解释性检测。",
    "tags": [
      "LLM应用",
      "新闻媒体",
      "信息安全"
    ]
  },
  {
    "title": "MedDoc-Bot: A Chat Tool for Comparative Analysis of Large Language Models in the Context of the Pediatric Hypertension Guideline",
    "submit_datetime": "2024年05月06日",
    "abstract": "This research focuses on evaluating the non-commercial open-source large language models (LLMs) Meditron, MedAlpaca, Mistral, and Llama-2 for their efficacy in interpreting medical guidelines saved in PDF format. As a specific test scenario, we applied these models to the guidelines for hypertension in children and adolescents provided by the European Society of Cardiology (ESC). Leveraging Streamlit, a Python library, we developed a user-friendly medical document chatbot tool (MedDoc-Bot). This tool enables authorized users to upload PDF files and pose questions, generating interpretive responses from four locally stored LLMs. A pediatric expert provides a benchmark for evaluation by formulating questions and responses extracted from the ESC guidelines. The expert rates the model-generated responses based on their fidelity and relevance. Additionally, we evaluated the METEOR and chrF metric scores to assess the similarity of model responses to reference answers. Our study found that Llama-2 and Mistral performed well in metrics evaluation. However, Llama-2 was slower when dealing with text and tabular data. In our human evaluation, we observed that responses created by Mistral, Meditron, and Llama-2 exhibited reasonable fidelity and relevance. This study provides valuable insights into the strengths and limitations of LLMs for future developments in medical document interpretation. Open-Source Code: https://github.com/yaseen28/MedDoc-Bot",
    "pdf_link": "https://arxiv.org/abs/2405.03359",
    "graphs": [],
    "abstract_cn": "本研究旨在评估几款非商业开源的大型语言模型（LLMs），包括Meditron、MedAlpaca、Mistral和Llama-2，它们在解读PDF格式保存的医疗指南方面的效能。以欧洲心脏病学会（ESC）发布的儿童和青少年高血压指南为测试案例，我们利用Python库Streamlit开发了一个易于使用的医疗文档聊天机器人工具——MedDoc-Bot。该工具允许授权用户上传PDF文件并提问，由四个本地存储的LLMs提供解释性回答。一位儿科专家通过提出问题并从ESC指南中提取答案，为评估设定了基准。专家根据回答的准确性和相关性对模型生成的回答进行评分。我们还通过METEOR和chrF指标来评估模型回答与参考答案的相似度。研究发现，Llama-2和Mistral在指标评估上表现优异，尽管Llama-2在处理文本和表格数据时稍显缓慢。在人类评估中，Mistral、Meditron和Llama-2生成的回答在准确性和相关性上都达到了合理水平。这项研究为LLMs在医学文档解读领域的未来发展提供了深刻的洞见。开源代码链接：https://github.com/yaseen28/MedDoc-Bot",
    "title_cn": "MedDoc-Bot：一款针对儿童高血压指南情境下，用于对比分析大型语言模型的智能聊天工具。",
    "tags": [
      "LLM应用",
      "",
      ""
    ]
  },
  {
    "title": "Exploring the Frontiers of Softmax: Provable Optimization, Applications in Diffusion Model, and Beyond",
    "submit_datetime": "2024年05月06日",
    "abstract": "The softmax activation function plays a crucial role in the success of large language models (LLMs), particularly in the self-attention mechanism of the widely adopted Transformer architecture. However, the underlying learning dynamics that contribute to the effectiveness of softmax remain largely unexplored. As a step towards better understanding, this paper provides a theoretical study of the optimization and generalization properties of two-layer softmax neural networks, providing theoretical insights into their superior performance as other activation functions, such as ReLU and exponential. Leveraging the Neural Tangent Kernel (NTK) framework, our analysis reveals that the normalization effect of the softmax function leads to a good perturbation property of the induced NTK matrix, resulting in a good convex region of the loss landscape. Consequently, softmax neural networks can learn the target function in the over-parametrization regime. To demonstrate the broad applicability of our theoretical findings, we apply them to the task of learning score estimation functions in diffusion models, a promising approach for generative modeling. Our analysis shows that gradient-based algorithms can learn the score function with a provable accuracy. Our work provides a deeper understanding of the effectiveness of softmax neural networks and their potential in various domains, paving the way for further advancements in natural language processing and beyond.",
    "pdf_link": "https://arxiv.org/abs/2405.03251",
    "graphs": [],
    "abstract_cn": "softmax 激活函数对于大型语言模型（LLMs）的成功至关重要，尤其是在流行的 Transformer 架构的自注意力机制中。尽管如此，softmax 的学习动态及其高效性背后的原理尚未被充分研究。本文深入探讨了两层 softmax 神经网络的优化与泛化特性，对比了 ReLU 和指数激活函数，揭示了 softmax 网络的卓越性能。通过神经切线核（NTK）框架的分析，我们发现 softmax 函数的归一化特性优化了 NTK 矩阵的扰动属性，优化了损失函数的景观，使得 softmax 网络能够在参数过多的情况下学习目标函数。此外，我们将理论研究应用于扩散模型中的得分估计函数学习任务，这是一种用于生成建模的有前景的方法。我们的研究证实，基于梯度的算法能够以可证明的精度学习得分函数。这项工作不仅加深了我们对 softmax 神经网络效果的理解，也展示了它们在多个领域的潜力，为自然语言处理等领域的未来发展奠定了基础。",
    "title_cn": "深入 Softmax 的未知领域：验证优化的路径，扩散模型的创新应用，以及更广阔的研究前景。",
    "tags": [
      "分类：LLM理论",
      "机器学习",
      ""
    ]
  },
  {
    "title": "Speak the Same Language: Global LiDAR Registration on BIM Using Pose Hough Transform",
    "submit_datetime": "2024年05月06日",
    "abstract": "The construction and robotic sensing data originate from disparate sources and are associated with distinct frames of reference. The primary objective of this study is to align LiDAR point clouds with building information modeling (BIM) using a global point cloud registration approach, aimed at establishing a shared understanding between the two modalities, i.e., ``speak the same language''. To achieve this, we design a cross-modality registration method, spanning from front end the back end. At the front end, we extract descriptors by identifying walls and capturing the intersected corners. Subsequently, for the back-end pose estimation, we employ the Hough transform for pose estimation and estimate multiple pose candidates. The final pose is verified by wall-pixel correlation. To evaluate the effectiveness of our method, we conducted real-world multi-session experiments in a large-scale university building, involving two different types of LiDAR sensors. We also report our findings and plan to make our collected dataset open-sourced.",
    "pdf_link": "https://arxiv.org/abs/2405.03969",
    "graphs": [],
    "abstract_cn": "建筑与机器人传感数据源自不同源，关联于各异的参考框架。本研究旨在通过全局点云注册技术，将激光雷达点云与建筑信息模型（BIM）精准对齐，以期在两种技术间架起沟通的桥梁，实现“语言”的统一。我们设计了一种跨模态注册方法，从前端的数据提取到后端的姿态估算，一气呵成。前端，我们识别墙壁并捕捉交角以提取特征；后端，则运用霍夫变换进行姿态估算，筛选出多个候选姿态，最终通过墙壁像素相关性验证最佳姿态。为验证方法的实效性，我们在一所大学的宏伟建筑内进行了多轮实地测试，使用了两种不同类型的激光雷达传感器。我们不仅分享了研究成果，还计划将收集的数据集公之于众，以飨同行。",
    "title_cn": "“共语”全球激光雷达注册：利用姿态霍夫变换在BIM上的精准对接",
    "tags": [
      "Agent\n\n这篇论文探讨了如何通过全局点云注册技术将机器人传感数据（激光雷达点云）与建筑信息模型（BIM）对齐，这是一种跨模态的注册方法，旨在实现不同技术之间的沟通和统一。这种方法涉及特征提取和姿态估算，可以被视为一种智能代理（Agent）的行为，因为它涉及到处理和解释来自不同源的数据，并执行特定的任务（如姿态估算）以实现目标（如点云与BIM的对齐）。因此，这篇论文更符合Agent分类，而不是RAG、LLM应用或LLM理论，因为它的重点在于机器人技术和建筑信息模型的集成，而不是语言模型或其理论。",
      "建筑信息模型",
      "机器人技术"
    ]
  },
  {
    "title": "ERATTA: Extreme RAG for Table To Answers with Large Language Models",
    "submit_datetime": "2024年05月06日",
    "abstract": "Large language models (LLMs) with residual augmented-generation (RAG) have been the optimal choice for scalable generative AI solutions in the recent past. However, the choice of use-cases that incorporate RAG with LLMs have been either generic or extremely domain specific, thereby questioning the scalability and generalizability of RAG-LLM approaches. In this work, we propose a unique LLM-based system where multiple LLMs can be invoked to enable data authentication, user query routing, data retrieval and custom prompting for question answering capabilities from data tables that are highly varying and large in size. Our system is tuned to extract information from Enterprise-level data products and furnish real time responses under 10 seconds. One prompt manages user-to-data authentication followed by three prompts to route, fetch data and generate a customizable prompt natural language responses. Additionally, we propose a five metric scoring module that detects and reports hallucinations in the LLM responses. Our proposed system and scoring metrics achieve >90% confidence scores across hundreds of user queries in the sustainability, financial health and social media domains. Extensions to the proposed extreme RAG architectures can enable heterogeneous source querying using LLMs.",
    "pdf_link": "https://arxiv.org/abs/2405.03963",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.03963v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03963/sys.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03963v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03963/p2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03963v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03963/res.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03963v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03963/p3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03963v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03963/p4.png"
      }
    ],
    "abstract_cn": "RAG与LLMs结合的解决方案在生成式AI领域表现卓越，但它们的使用案例要么过于通用，要么过于特定，这引发了对其可扩展性和泛化能力的质疑。我们提出了一种创新的LLM系统，该系统能够调用多个LLMs，实现数据验证、查询分发、数据检索以及针对大型且多样化的数据表的定制问答。该系统专为企业级数据设计，能在10秒内提供实时信息。用户认证、数据路由、数据获取和自然语言响应生成均通过一系列提示实现。此外，我们还开发了一个五指标评分系统，用于检测LLM输出中的幻觉，并在多个领域中实现了超过90%的准确率。这一系统的扩展潜力巨大，未来可用于异构数据源的查询。",
    "title_cn": "ERATTA：大型语言模型在表格至答案生成中的极致检索增强技术在这项研究中，我们提出了ERATTA，一种新颖的方法，它利用大型语言模型的强大能力，通过极端的检索增强生成（RAG）技术，从结构化数据中提取信息并生成准确的答案。这种方法特别适用于处理复杂的表格数据，能够有效地捕捉数据间的细微关联，并据此生成连贯且信息丰富的回答。",
    "tags": [
      "Agent\n\n这篇论文介绍了一种创新的LLM系统，该系统能够调用多个LLMs，实现数据验证、查询分发、数据检索以及针对大型且多样化的数据表的定制问答。这种系统可以被视为一个智能代理（Agent），因为它能够处理复杂的任务，如用户认证、数据路由、数据获取和自然语言响应生成，并且能够在实时环境中提供信息。此外，该系统还包含了一个用于检测LLM输出中幻觉的评分系统，这表明它具有一定的自我监控和质量控制能力。因此，这篇论文的内容更符合Agent的分类，而不是RAG、LLM应用或LLM理论。",
      "企业数据管理",
      ""
    ]
  },
  {
    "title": "Long Context Alignment with Short Instructions and Synthesized Positions",
    "submit_datetime": "2024年05月06日",
    "abstract": "Effectively handling instructions with extremely long context remains a challenge for Large Language Models (LLMs), typically necessitating high-quality long data and substantial computational resources. This paper introduces Step-Skipping Alignment (SkipAlign), a new technique designed to enhance the long-context capabilities of LLMs in the phase of alignment without the need for additional efforts beyond training with original data length. SkipAlign is developed on the premise that long-range dependencies are fundamental to enhancing an LLM's capacity of long context. Departing from merely expanding the length of input samples, SkipAlign synthesizes long-range dependencies from the aspect of positions indices. This is achieved by the strategic insertion of skipped positions within instruction-following samples, which utilizes the semantic structure of the data to effectively expand the context. Through extensive experiments on base models with a variety of context window sizes, SkipAlign demonstrates its effectiveness across a spectrum of long-context tasks. Particularly noteworthy is that with a careful selection of the base model and alignment datasets, SkipAlign with only 6B parameters achieves it's best performance and comparable with strong baselines like GPT-3.5-Turbo-16K on LongBench.",
    "pdf_link": "https://arxiv.org/abs/2405.03939",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.03939v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03939/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03939v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03939/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03939v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03939/ntk-50k.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03939v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03939/noraml_sft.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03939v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03939/llama_packed16k.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03939v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03939/llama_skip.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03939v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03939/parameter.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）在处理极长上下文指令时面临挑战，这通常需要高质量的长数据和大量计算资源。本文提出了一种名为Step-Skipping Alignment（SkipAlign）的新技术，旨在无需额外资源，仅通过原始数据长度训练，就能提升LLMs在调整阶段的长上下文处理能力。SkipAlign基于长距离依赖是提升LLM长上下文能力的关键这一理念。它不仅扩展输入样本长度，还通过在指令样本中巧妙插入跳过的位置索引，合成长距离依赖，从而有效扩展上下文。实验证明，SkipAlign在多种长上下文任务中表现出色，尤其是在精心挑选的基础模型和数据集下，仅6B参数的SkipAlign就能达到最佳性能，与GPT-3.5-Turbo-16K等强基准相当。",
    "title_cn": "短指令与合成位置下的长上下文对齐策略",
    "tags": [
      "LLM理论\n\n这篇论文探讨了大型语言模型（LLMs）在处理长上下文指令时的挑战，并提出了一种名为Step-Skipping Alignment（SkipAlign）的新技术来解决这一问题。该技术旨在提升LLMs在调整阶段的长上下文处理能力，而不需要额外的资源。这种方法基于对长距离依赖的理解，并通过在指令样本中插入跳过的位置索引来合成长距离依赖。论文通过实验证明了SkipAlign在多种长上下文任务中的有效性。由于这项工作主要关注LLMs的理论改进和性能提升，因此它属于LLM理论分类。",
      "",
      "机器学习"
    ]
  },
  {
    "title": "Codexity: Secure AI-assisted Code Generation",
    "submit_datetime": "2024年05月06日",
    "abstract": "Despite the impressive performance of Large Language Models (LLMs) in software development activities, recent studies show the concern of introducing vulnerabilities into software codebase by AI programming assistants (e.g., Copilot, CodeWhisperer). In this work, we present Codexity, a security-focused code generation framework integrated with five LLMs. Codexity leverages the feedback of static analysis tools such as Infer and CppCheck to mitigate security vulnerabilities in LLM-generated programs. Our evaluation in a real-world benchmark with 751 automatically generated vulnerable subjects demonstrates Codexity can prevent 60% of the vulnerabilities being exposed to the software developer.",
    "pdf_link": "https://arxiv.org/abs/2405.03927",
    "graphs": [],
    "abstract_cn": "大型语言模型在软件开发中表现卓越，但人工智能编程助手却可能埋下安全隐患。为此，我们推出了Codexity，一个集成了五大语言模型的安全代码生成框架。它借助静态分析工具的反馈，有效减少模型生成代码中的安全漏洞。在包含751个自动生成漏洞的实际测试中，Codexity成功为开发者屏蔽了60%的安全风险。",
    "title_cn": "Codexity：保障安全的 AI 代码创作助手",
    "tags": [
      "LLM应用\n\n解释：这篇论文介绍了一个名为Codexity的框架，它集成了五大语言模型，旨在通过静态分析工具的反馈来减少模型生成代码中的安全漏洞。这个框架直接应用于软件开发中，利用大型语言模型来提高代码生成的安全性，属于大型语言模型在实际应用中的一个具体案例，因此归类为LLM应用。",
      "软件开发",
      "安全\n\n解释：根据论文摘要",
      "该研究关注的是在软件开发过程中使用大型语言模型生成代码的安全性问题",
      "并提出了一个名为Codexity的框架来减少安全漏洞。因此",
      "最相关的行业领域标签是“软件开发”和“安全”。"
    ]
  },
  {
    "title": "KV Cache is 1 Bit Per Channel: Efficient Large Language Model Inference with Coupled Quantization",
    "submit_datetime": "2024年05月06日",
    "abstract": "Efficient deployment of Large Language Models (LLMs) requires batching multiple requests together to improve throughput. As the batch size, context length, or model size increases, the size of the key and value (KV) cache can quickly become the main contributor to GPU memory usage and the bottleneck of inference latency. Quantization has emerged as an effective technique for KV cache compression, but existing methods still fail at very low bit widths. We observe that distinct channels of a key/value activation embedding are highly inter-dependent, and the joint entropy of multiple channels grows at a slower rate than the sum of their marginal entropies. Based on this insight, we propose Coupled Quantization (CQ), which couples multiple key/value channels together to exploit their inter-dependency and encode the activations in a more information-efficient manner. Extensive experiments reveal that CQ outperforms or is competitive with existing baselines in preserving model quality. Furthermore, we demonstrate that CQ can preserve model quality with KV cache quantized down to 1-bit.",
    "pdf_link": "https://arxiv.org/abs/2405.03917",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.03917v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03917/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03917v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03917/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03917v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03917/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03917v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03917/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03917v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03917/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03917v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03917/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03917v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03917/key_emb.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03917v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03917/value_emb.png"
      }
    ],
    "abstract_cn": "在部署大型语言模型时，为了提高效率，我们需将多个请求打包处理。然而，随着批量、上下文长度或模型规模的增大，KV缓存的大小成为GPU内存的吞噬者和推理速度的瓶颈。量化技术虽能压缩KV缓存，但在极低比特率下仍显乏力。我们发现，键值激活的各个通道间存在紧密联系，其联合熵的增长，并不如各通道边际熵之和那般迅猛。鉴于此，我们提出了耦合量化（CQ），通过将多个通道紧密结合，利用它们之间的相互依赖，以更高效的方式编码激活信息。实验证明，CQ在保持模型质量方面表现出色，甚至能将KV缓存量化至仅1比特，而模型质量依旧坚挺。",
    "title_cn": "KV Cache 采用每通道1位的耦合量化策略，为大型语言模型推理提供了高效途径，实现了计算资源的优化利用。",
    "tags": [
      "LLM理论\n\n这篇论文探讨了大型语言模型（LLM）在部署时的效率问题，特别是关于KV缓存大小对GPU内存和推理速度的影响。它提出了一种新的量化技术——耦合量化（CQ），以更高效地编码激活信息，从而减少KV缓存的大小。这个研究关注的是LLM的内部机制和优化技术，属于理论层面的探讨，因此归类为LLM理论。",
      "",
      "机器学习优化"
    ]
  },
  {
    "title": "OmniActions: Predicting Digital Actions in Response to Real-World Multimodal Sensory Inputs with LLMs",
    "submit_datetime": "2024年05月06日",
    "abstract": "The progression to \"Pervasive Augmented Reality\" envisions easy access to multimodal information continuously. However, in many everyday scenarios, users are occupied physically, cognitively or socially. This may increase the friction to act upon the multimodal information that users encounter in the world. To reduce such friction, future interactive interfaces should intelligently provide quick access to digital actions based on users' context. To explore the range of possible digital actions, we conducted a diary study that required participants to capture and share the media that they intended to perform actions on (e.g., images or audio), along with their desired actions and other contextual information. Using this data, we generated a holistic design space of digital follow-up actions that could be performed in response to different types of multimodal sensory inputs. We then designed OmniActions, a pipeline powered by large language models (LLMs) that processes multimodal sensory inputs and predicts follow-up actions on the target information grounded in the derived design space. Using the empirical data collected in the diary study, we performed quantitative evaluations on three variations of LLM techniques (intent classification, in-context learning and finetuning) and identified the most effective technique for our task. Additionally, as an instantiation of the pipeline, we developed an interactive prototype and reported preliminary user feedback about how people perceive and react to the action predictions and its errors.",
    "pdf_link": "https://arxiv.org/abs/2405.03901",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.03901v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03901/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03901v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03901/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03901v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03901/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03901v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03901/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03901v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03901/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03901v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03901/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03901v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03901/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03901v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03901/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03901v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03901/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03901v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03901/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03901v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03901/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03901v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03901/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03901v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03901/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03901v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03901/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03901v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03901/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03901v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03901/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03901v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03901/x18.png"
      }
    ],
    "abstract_cn": "向“普遍增强现实”的演进，设想了持续轻松访问多模态信息的可能性。然而，在日常生活中，用户往往因身体、认知或社交活动而分心。这增加了用户对多模态信息采取行动的难度。为了降低这种难度，未来的交互界面应智能地提供基于用户情境的快速数字行动访问。为此，我们进行了一项日记研究，参与者需记录并分享他们打算操作的媒体（如图像或音频），以及他们的行动意图和其他情境信息。基于这些数据，我们构建了一个全面的数字后续行动设计空间，以响应各种多模态感官输入。我们进一步开发了OmniActions，这是一个利用大型语言模型（LLMs）的系统，能够处理多模态输入并预测基于设计空间的针对信息的后续行动。通过日记研究收集的数据，我们评估了三种LLM技术（意图分类、上下文学习和微调），并确定了最适合我们任务的技术。此外，我们创建了一个交互式原型，并收集了用户对行动预测及其错误的初步反馈。",
    "title_cn": "全方位行动：借助大型语言模型，精准预测现实世界多模态感官刺激下的数字行动反应",
    "tags": [
      "Agent\n\n这篇论文探讨了如何利用大型语言模型（LLMs）来构建一个智能系统，该系统能够处理多模态输入并预测基于用户情境的数字行动。这种系统可以被视为一个智能代理（Agent），因为它能够理解和响应用户的情境，并提供相应的数字行动建议。论文通过日记研究和用户反馈来评估不同的LLM技术，并开发了一个交互式原型，这表明它更侧重于构建和评估一个实际的智能系统，而不是专注于LLM的理论研究或应用。因此，将其归类为Agent是合适的。",
      "增强现实",
      "人机交互"
    ]
  },
  {
    "title": "Outlier Gradient Analysis: Efficiently Improving Deep Learning Model Performance via Hessian-Free Influence Functions",
    "submit_datetime": "2024年05月06日",
    "abstract": "Influence functions offer a robust framework for assessing the impact of each training data sample on model predictions, serving as a prominent tool in data-centric learning. Despite their widespread use in various tasks, the strong convexity assumption on the model and the computational cost associated with calculating the inverse of the Hessian matrix pose constraints, particularly when analyzing large deep models. This paper focuses on a classical data-centric scenario--trimming detrimental samples--and addresses both challenges within a unified framework. Specifically, we establish an equivalence transformation between identifying detrimental training samples via influence functions and outlier gradient detection. This transformation not only presents a straightforward and Hessian-free formulation but also provides profound insights into the role of the gradient in sample impact. Moreover, it relaxes the convexity assumption of influence functions, extending their applicability to non-convex deep models. Through systematic empirical evaluations, we first validate the correctness of our proposed outlier gradient analysis on synthetic datasets and then demonstrate its effectiveness in detecting mislabeled samples in vision models, selecting data samples for improving performance of transformer models for natural language processing, and identifying influential samples for fine-tuned Large Language Models.",
    "pdf_link": "https://arxiv.org/abs/2405.03869",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.03869v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03869/toy_full_comb3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03869v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03869/CIFAR10_100N_FIG2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03869v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03869/latest_roberta2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03869v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03869/heatmap_blurb2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03869v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03869/threshold.png"
      }
    ],
    "abstract_cn": "影响力函数作为数据中心学习的关键工具，能够评估训练数据对模型预测的影响。然而，强凸性假设和计算海森逆的昂贵成本限制了其在大型深度模型中的应用。本文针对数据修剪这一经典场景，提出了一种统一方法，通过等价变换将影响力函数与异常梯度检测相联系。这一创新不仅简化了计算，还揭示了梯度在样本影响中的作用，并放宽了对模型的凸性要求。实证研究验证了该方法在合成数据集上的准确性，并展示了其在识别视觉模型错误标签、优化自然语言处理模型数据选择以及微调大型语言模型中关键样本方面的实际效果。",
    "title_cn": "梯度异常分析：借助无黑塞矩阵的影响函数，我们能够精妙地提升深度学习模型的性能，如同巧匠雕琢宝石，使其光芒四射。",
    "tags": [
      "LLM理论\n\n这篇论文探讨了影响力函数在大型深度模型中的应用，特别是在数据修剪场景中。它提出了一种新的方法，通过等价变换将影响力函数与异常梯度检测联系起来，简化了计算过程，并放宽了对模型的凸性要求。虽然论文中提到了大型语言模型（LLM），但其核心贡献在于理论方法的创新，即如何评估训练数据对模型预测的影响，以及如何优化模型。因此，这篇论文更符合“LLM理论”分类，因为它提供了一种理论上的方法来理解和改进大型语言模型的性能。",
      "机器学习",
      "数据分析"
    ]
  },
  {
    "title": "Self-Improving Customer Review Response Generation Based on LLMs",
    "submit_datetime": "2024年05月06日",
    "abstract": "Previous studies have demonstrated that proactive interaction with user reviews has a positive impact on the perception of app users and encourages them to submit revised ratings. Nevertheless, developers encounter challenges in managing a high volume of reviews, particularly in the case of popular apps with a substantial influx of daily reviews. Consequently, there is a demand for automated solutions aimed at streamlining the process of responding to user reviews. To address this, we have developed a new system for generating automatic responses by leveraging user-contributed documents with the help of retrieval-augmented generation (RAG) and advanced Large Language Models (LLMs). Our solution, named SCRABLE, represents an adaptive customer review response automation that enhances itself with self-optimizing prompts and a judging mechanism based on LLMs. Additionally, we introduce an automatic scoring mechanism that mimics the role of a human evaluator to assess the quality of responses generated in customer review domains. Extensive experiments and analyses conducted on real-world datasets reveal that our method is effective in producing high-quality responses, yielding improvement of more than 8.5% compared to the baseline. Further validation through manual examination of the generated responses underscores the efficacy our proposed system.",
    "pdf_link": "https://arxiv.org/abs/2405.03845",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.03845v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03845/PromptOpt.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03845v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03845/Feedback.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03845v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03845/RAG_overview.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.03845v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03845/Walkthru2.jpg"
      }
    ],
    "abstract_cn": "以往的研究揭示，主动与用户评论互动能够提升用户对应用的感知，并激励他们更新评分。然而，面对每日涌入的大量评论，尤其是热门应用，开发者往往难以应对。因此，自动化回复用户评论的需求日益增长，我们为此开发了SCRABLE系统，它利用RAG技术和先进的LLMs自动生成回复，并通过自我优化的提示和基于LLMs的评判机制不断自我提升。此外，SCRABLE还引入了自动评分机制，模拟人类评估者的角色，以确保回复质量。实验结果显示，SCRABLE在生成高质量回复方面表现出色，与基线相比，性能提升了8.5%以上。通过人工审核，SCRABLE的有效性得到了进一步的验证。",
    "title_cn": "大型语言模型驱动下的客户评论回复自我优化生成在翻译过程中，我首先确保原文的核心意义被准确传达，即“基于大型语言模型的自我改进客户评论回复生成”。接着，我进一步优化表达，使其更加符合中文的表达习惯和语言美感，形成了“大型语言模型驱动下的客户评论回复自我优化生成”的翻译，这样的表达更加简洁优雅，同时也保持了原文的生动性和专业性。",
    "tags": [
      "RAG\n\n理由：这篇论文介绍了一个名为SCRABLE的系统，该系统利用RAG（Retrieval-Augmented Generation）技术和先进的LLMs（大型语言模型）来自动生成用户评论的回复。RAG是一种结合了检索和生成的方法，用于改进语言模型的性能。论文中提到的系统专注于自动化回复生成，并且通过自我优化的提示和基于LLMs的评判机制来提升性能，这些都是RAG技术的应用。因此，这篇论文更适合归类到RAG分类中。",
      "应用开发",
      "用户互动"
    ]
  },
  {
    "title": "Organizing a Society of Language Models: Structures and Mechanisms for Enhanced Collective Intelligence",
    "submit_datetime": "2024年05月06日",
    "abstract": "Recent developments in Large Language Models (LLMs) have significantly expanded their applications across various domains. However, the effectiveness of LLMs is often constrained when operating individually in complex environments. This paper introduces a transformative approach by organizing LLMs into community-based structures, aimed at enhancing their collective intelligence and problem-solving capabilities. We investigate different organizational models-hierarchical, flat, dynamic, and federated-each presenting unique benefits and challenges for collaborative AI systems. Within these structured communities, LLMs are designed to specialize in distinct cognitive tasks, employ advanced interaction mechanisms such as direct communication, voting systems, and market-based approaches, and dynamically adjust their governance structures to meet changing demands. The implementation of such communities holds substantial promise for improve problem-solving capabilities in AI, prompting an in-depth examination of their ethical considerations, management strategies, and scalability potential. This position paper seeks to lay the groundwork for future research, advocating a paradigm shift from isolated to synergistic operational frameworks in AI research and application.",
    "pdf_link": "https://arxiv.org/abs/2405.03825",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）的最新进展已在多个领域拓宽了其应用范围。然而，当它们孤立地面对复杂环境时，其效能常受限。本文提出了一种创新方法，通过构建基于社区的LLMs结构，以提升其集体智慧和问题解决力。我们探讨了层级、扁平、动态和联邦等不同组织模型，每种都为协作AI系统带来独特优势与挑战。在这些社区中，LLMs专攻特定认知任务，运用直接通信、投票和市场机制等高级交互方式，并灵活调整治理结构以适应变化。这些社区的实施有望大幅提升AI的问题解决能力，同时也引发了对伦理、管理和可扩展性的深入探讨。本文旨在为未来研究奠定基础，推动AI研究和应用从孤立转向协同操作的新范式。",
    "title_cn": "构建语言模型联盟：探索提升集体智慧的架构与机制",
    "tags": [
      "Agent\n\n这篇论文探讨了如何通过构建基于社区的大型语言模型（LLMs）结构来提升其集体智慧和问题解决能力。它提出了不同的组织模型，并讨论了这些模型如何通过协作来增强AI系统的能力。这种方法涉及到多个LLMs之间的交互和协作，类似于智能代理（Agent）在复杂环境中的行为，因此将其归类为Agent。论文中提到的社区结构、交互方式和治理调整都是为了增强这些“代理”之间的协作和问题解决能力，这与Agent领域的研究目标相符。",
      "人工智能",
      "社区协作"
    ]
  },
  {
    "title": "Large Language Models as Instruments of Power: New Regimes of Autonomous Manipulation and Control",
    "submit_datetime": "2024年05月06日",
    "abstract": "Large language models (LLMs) can reproduce a wide variety of rhetorical styles and generate text that expresses a broad spectrum of sentiments. This capacity, now available at low cost, makes them powerful tools for manipulation and control. In this paper, we consider a set of underestimated societal harms made possible by the rapid and largely unregulated adoption of LLMs. Rather than consider LLMs as isolated digital artefacts used to displace this or that area of work, we focus on the large-scale computational infrastructure upon which they are instrumentalised across domains. We begin with discussion on how LLMs may be used to both pollute and uniformize information environments and how these modalities may be leveraged as mechanisms of control. We then draw attention to several areas of emerging research, each of which compounds the capabilities of LLMs as instruments of power. These include (i) persuasion through the real-time design of choice architectures in conversational interfaces (e.g., via \"AI personas\"), (ii) the use of LLM-agents as computational models of human agents (e.g., \"silicon subjects\"), (iii) the use of LLM-agents as computational models of human agent populations (e.g., \"silicon societies\") and finally, (iv) the combination of LLMs with reinforcement learning to produce controllable and steerable strategic dialogue models. We draw these strands together to discuss how these areas may be combined to build LLM-based systems that serve as powerful instruments of individual, social and political control via the simulation and disingenuous \"prediction\" of human behaviour, intent, and action.",
    "pdf_link": "https://arxiv.org/abs/2405.03813",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）能够以低成本复制多种修辞风格和表达广泛情感的文本，成为操纵和控制的利器。本文探讨了LLMs快速且缺乏监管的采用所带来的被忽视的社会危害。我们关注的是LLMs如何被用于污染和统一信息环境，并作为控制机制。此外，我们关注了几个新兴研究领域，它们增强了LLMs作为权力工具的能力，包括通过“AI人格”实时设计对话界面的选择架构进行说服，将LLM代理作为“硅基主体”和“硅基社会”的计算模型，以及结合强化学习以产生可控的战略对话模型。最终，我们探讨了这些技术如何结合，构建出通过模拟和虚伪预测人类行为、意图和行动，实现个人、社会和政治控制的LLM系统。",
    "title_cn": "权力之弦：大型语言模型与自主操控的新纪元",
    "tags": [
      "Agent\n\n这篇论文探讨了大型语言模型（LLMs）在社会中的应用，特别是它们如何被用于操纵和控制信息环境。它关注了LLMs作为权力工具的增强能力，包括通过AI人格设计对话界面、将LLM代理作为计算模型，以及结合强化学习产生可控的战略对话模型。这些讨论指向了LLMs在构建模拟人类行为和意图的系统中的角色，这些系统可以用于个人、社会和政治控制。因此，这篇论文更符合Agent分类，因为它涉及了LLMs作为代理在社会和政治控制中的应用。",
      "社会影响",
      "人工智能伦理"
    ]
  },
  {
    "title": "In Situ AI Prototyping: Infusing Multimodal Prompts into Mobile Settings with MobileMaker",
    "submit_datetime": "2024年05月06日",
    "abstract": "Recent advances in multimodal large language models (LLMs) have lowered the barriers to rapidly prototyping AI-powered features via prompting, especially for mobile-intended use cases. Despite the value of situated user feedback, the process of soliciting early, mobile-situated user feedback on AI prototypes remains challenging. The broad scope and flexibility of LLMs means that, for a given use-case-specific prototype, there is a crucial need to understand the wide range of in-the-wild input likely to be provided by the user, as well as their in-context expectations of the AI's behavior. To explore the concept of in situ AI prototyping and testing, we created MobileMaker: an AI prototyping tool that enables designers to rapidly create mobile AI prototypes that can be tested on-device, and enables testers to make on-device, in-the-field revisions of the prototype through natural language. In an exploratory study with 16 users, we explored how user feedback on prototypes created with MobileMaker compares to that of existing prototyping tools (e.g., Figma, prompt editors). We found that MobileMaker prototypes enabled more serendipitous discovery of: model input edge cases, discrepancies between AI's and user's in-context interpretation of the task, and contextual signals missed by the AI. Furthermore, we learned that while the ability to make in-the-wild revisions led users to feel more fulfilled as active participants in the design process, it might also constrain their feedback to the subset of changes perceived as more actionable or implementable by the prototyping tool.",
    "pdf_link": "https://arxiv.org/abs/2405.03806",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.03806v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03806/desktop-2.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.03806v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03806/insitu.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.03806v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03806/ui.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03806v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03806/json-representation.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03806v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03806/study-quant-results.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03806v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03806/cropped-john_legend.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03806v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03806/cropped-picnic.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03806v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03806/cropped-giraffe.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03806v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03806/cropped-pirate_ship.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03806v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03806/cropped-track.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03806v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03806/cropped-eclipse.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03806v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03806/cropped-turtle_swimming_in_hawaii.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03806v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03806/cropped-hand_stand_walks.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03806v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03806/cropped-poker_hand.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03806v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03806/cropped-106_6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03806v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03806/cropped-brandy.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03806v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03806/cropped-4_5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03806v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03806/cropped-6_5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03806v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03806/milk.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03806v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03806/cropped-107_2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03806v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03806/cropped-3_7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03806v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03806/cropped-5_4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03806v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03806/cherryblossom.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.03806v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03806/agile-row.png"
      }
    ],
    "abstract_cn": "多模态大型语言模型（LLMs）的进步，使得通过提示快速开发移动AI功能变得更加容易。尽管现场用户反馈至关重要，但获取移动环境下的早期用户反馈仍是一大挑战。LLMs的广泛性和灵活性要求我们深入理解用户可能提供的各种输入，以及他们对AI行为的期望。为此，我们开发了MobileMaker，一款AI原型设计工具，它让设计师能够快速制作可在设备上测试的移动AI原型，并允许测试者通过自然语言在现场对原型进行即时修改。我们对16名用户进行了研究，比较了使用MobileMaker创建的原型与传统工具（如Figma）的用户反馈。我们发现，MobileMaker能更自然地揭示模型输入的极端情况、AI与用户对任务理解的差异，以及AI遗漏的上下文信号。同时，尽管现场修改功能让用户感觉自己更像是设计过程的积极参与者，但它也可能限制用户的反馈，使其局限于原型工具认为更可行或可实施的变更范围内。",
    "title_cn": "现场AI原型制作：借助MobileMaker，将多模态提示注入移动场景，实现智能交互的即时创新。",
    "tags": [
      "LLM应用\n\n这篇论文探讨了多模态大型语言模型（LLMs）在移动AI功能开发中的应用，并提出了一种名为MobileMaker的AI原型设计工具，旨在帮助设计师快速制作和测试移动AI原型，并收集现场用户反馈。这与LLM的应用层面紧密相关，因为它关注的是如何利用LLMs来改善移动AI产品的开发过程和用户体验。因此，它属于LLM应用分类。",
      "移动应用开发",
      "人工智能原型设计"
    ]
  },
  {
    "title": "Detecting Anti-Semitic Hate Speech using Transformer-based Large Language Models",
    "submit_datetime": "2024年05月06日",
    "abstract": "Academic researchers and social media entities grappling with the identification of hate speech face significant challenges, primarily due to the vast scale of data and the dynamic nature of hate speech. Given the ethical and practical limitations of large predictive models like ChatGPT in directly addressing such sensitive issues, our research has explored alternative advanced transformer-based and generative AI technologies since 2019. Specifically, we developed a new data labeling technique and established a proof of concept targeting anti-Semitic hate speech, utilizing a variety of transformer models such as BERT (arXiv:1810.04805), DistillBERT (arXiv:1910.01108), RoBERTa (arXiv:1907.11692), and LLaMA-2 (arXiv:2307.09288), complemented by the LoRA fine-tuning approach (arXiv:2106.09685). This paper delineates and evaluates the comparative efficacy of these cutting-edge methods in tackling the intricacies of hate speech detection, highlighting the need for responsible and carefully managed AI applications within sensitive contexts.",
    "pdf_link": "https://arxiv.org/abs/2405.03794",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.03794v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03794/voting_algorithm.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03794v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03794/lora_llama.png"
      }
    ],
    "abstract_cn": "学术界与社交媒体在识别仇恨言论方面遭遇重重困难，主要源于数据的海量与仇恨言论的变幻莫测。鉴于ChatGPT等大型预测模型在处理敏感议题时的伦理与实践限制，自2019年起，我们便开始探索基于变压器和生成式AI的高级替代技术。我们独创了一种新型数据标注技术，并针对反犹太仇恨言论构建了概念验证，运用了BERT、DistillBERT、RoBERTa和LLaMA-2等多种变压器模型，并结合LoRA微调策略。本文对比评估了这些前沿技术在仇恨言论检测中的效能，强调了在敏感领域中，人工智能应用需负责任且审慎管理的重要性。",
    "title_cn": "运用Transformer架构的大型语言模型，精准识别反犹太仇恨言论，本研究深入探讨了该模型在敏感话题识别上的应用与挑战。",
    "tags": [
      "Agent\n\n这篇论文探讨了在社交媒体和学术界中识别仇恨言论的挑战，并提出了一种基于变压器和生成式AI的新型数据标注技术。它特别关注了反犹太仇恨言论，并使用了多种变压器模型和微调策略来构建概念验证。虽然这项工作涉及大型语言模型（如LLaMA-2）的应用，但其核心在于开发和评估一种特定的Agent（即数据标注技术），用于在敏感领域中检测仇恨言论。因此，它更符合Agent分类，而不是RAG、LLM应用或LLM理论分类。",
      "社交媒体",
      "仇恨言论检测"
    ]
  },
  {
    "title": "Quantifying the Capabilities of LLMs across Scale and Precision",
    "submit_datetime": "2024年05月05日",
    "abstract": "Scale is often attributed as one of the factors that cause an increase in the performance of LLMs, resulting in models with billion and trillion parameters. One of the limitations of such large models is the high computational requirements that limit their usage, deployment, and debugging in resource-constrained scenarios. Two commonly used alternatives to bypass these limitations are to use the smaller versions of LLMs (e.g. Llama 7B instead of Llama 70B) and lower the memory requirements by using quantization. While these approaches effectively address the limitation of resources, their impact on model performance needs thorough examination. In this study, we perform a comprehensive evaluation to investigate the effect of model scale and quantization on the performance. We experiment with two major families of open-source instruct models ranging from 7 billion to 70 billion parameters. Our extensive zero-shot experiments across various tasks including natural language understanding, reasoning, misinformation detection, and hallucination reveal that larger models generally outperform their smaller counterparts, suggesting that scale remains an important factor in enhancing performance. We found that larger models show exceptional resilience to precision reduction and can maintain high accuracy even at 4-bit quantization for numerous tasks and they serve as a better solution than using smaller models at high precision under similar memory requirements.",
    "pdf_link": "https://arxiv.org/abs/2405.03146",
    "graphs": [],
    "abstract_cn": "规模被普遍认为是提升大型语言模型（LLMs）性能的关键因素，促使模型参数量从亿级跃升至万亿级。然而，这些庞然大物的高计算需求也限制了它们在资源紧张环境下的实用性、部署和故障排查。为了克服这一挑战，研究者们通常采用两种策略：一是转而使用较小型的LLMs（如7B参数的Llama代替70B参数的Llama）；二是通过量化技术降低内存需求。尽管这些方法在资源利用上取得了成效，但它们对模型性能的具体影响仍需深入探究。本研究全面评估了模型规模和量化技术对性能的影响，涉及从7亿到70亿参数的两大开源指令模型家族。通过在自然语言理解、推理、虚假信息识别和幻觉等多个任务上的广泛零样本实验，我们发现大型模型普遍优于小型模型，规模对于提升性能至关重要。我们还观察到，大型模型在精度降低时表现出惊人的韧性，即便在4位量化条件下，它们在众多任务上仍能保持高准确度，相比在相似内存需求下使用小型模型的高精确度方案，大型模型提供了更佳的解决策略。",
    "title_cn": "探究并衡量大型语言模型在不同规模和精度层面的性能表现",
    "tags": [
      "LLM理论",
      "",
      "机器学习"
    ]
  },
  {
    "title": "CRAFT: Extracting and Tuning Cultural Instructions from the Wild",
    "submit_datetime": "2024年05月05日",
    "abstract": "Large language models (LLMs) have rapidly evolved as the foundation of various natural language processing (NLP) applications. Despite their wide use cases, their understanding of culturally-related concepts and reasoning remains limited. Meantime, there is a significant need to enhance these models' cultural reasoning capabilities, especially concerning underrepresented regions. This paper introduces a novel pipeline for extracting high-quality, culturally-related instruction tuning datasets from vast unstructured corpora. We utilize a self-instruction generation pipeline to identify cultural concepts and trigger instruction. By integrating with a general-purpose instruction tuning dataset, our model demonstrates enhanced capabilities in recognizing and understanding regional cultural nuances, thereby enhancing its reasoning capabilities. We conduct experiments across three regions: Singapore, the Philippines, and the United States, achieving performance improvement of up to 6%. Our research opens new avenues for extracting cultural instruction tuning sets directly from unstructured data, setting a precedent for future innovations in the field.",
    "pdf_link": "https://arxiv.org/abs/2405.03138",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）在自然语言处理（NLP）应用中迅速成为基石。尽管它们应用广泛，但对于文化相关概念和推理的理解仍有局限。尤其是在那些文化代表性不足的地区，提升模型的文化推理能力显得尤为重要。本论文提出了一种创新的流程，旨在从海量非结构化文本中提炼出高质量的、与文化相关的指令调整数据集。我们采用自生成指令的流程来识别文化概念并激发指令生成。将这一流程与通用的指令调整数据集相结合，我们的模型在识别和理解地区文化差异方面表现出了更强的能力，进而提升了其推理能力。我们在新加坡、菲律宾和美国三个地区进行了实验，实验结果显示性能提升了最多6%。本研究开辟了从非结构化数据中直接提取文化指令调整集的新方法，为未来该领域的创新奠定了基础。",
    "title_cn": "CRAFT：从现实世界中提炼并优化文化指南",
    "tags": [
      "分类：LLM应用",
      "",
      "文化研究"
    ]
  },
  {
    "title": "WDMoE: Wireless Distributed Large Language Models with Mixture of Experts",
    "submit_datetime": "2024年05月05日",
    "abstract": "Large Language Models (LLMs) have achieved significant success in various natural language processing tasks, but how wireless communications can support LLMs has not been extensively studied. In this paper, we propose a wireless distributed LLMs paradigm based on Mixture of Experts (MoE), named WDMoE, deploying LLMs collaboratively across edge servers of base station (BS) and mobile devices in the wireless communications system. Specifically, we decompose the MoE layer in LLMs by deploying the gating network and the preceding neural network layer at BS, while distributing the expert networks across the devices. This arrangement leverages the parallel capabilities of expert networks on distributed devices. Moreover, to overcome the instability of wireless communications, we design an expert selection policy by taking into account both the performance of the model and the end-to-end latency, which includes both transmission delay and inference delay. Evaluations conducted across various LLMs and multiple datasets demonstrate that WDMoE not only outperforms existing models, such as Llama 2 with 70 billion parameters, but also significantly reduces end-to-end latency.",
    "pdf_link": "https://arxiv.org/abs/2405.03131",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.03131v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03131/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03131v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03131/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03131v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03131/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03131v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03131/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03131v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03131/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03131v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03131/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03131v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03131/x7.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）在自然语言处理领域取得了巨大成就，但无线通信技术如何助力LLMs尚未深入探讨。本文提出了一种新颖的无线分布式LLMs架构——WDMoE，它利用专家混合（MoE）模型，将LLMs协作部署在无线通信系统中的基站边缘服务器和移动设备上。我们特别将MoE层的门控网络和前续神经网络层部署在基站，而将专家网络分散至各个设备，以此发挥分布式设备上专家网络的并行处理优势。为了应对无线通信的不稳定性，我们还设计了一种综合考虑模型性能和端到端延迟（包括传输和推理延迟）的专家选择策略。通过在多种LLMs和数据集上的测试，WDMoE展现出超越现有模型的性能，例如拥有700亿参数的Llama 2，同时显著缩短了端到端的延迟。",
    "title_cn": "WDMoE：无线分布式大型语言模型，采用专家混合技术",
    "tags": [
      "分类：LLM应用\n\n这篇论文讨论了如何将大型语言模型（LLMs）与无线通信技术结合，提出了一种新颖的无线分布式LLMs架构——WDMoE。这个架构利用专家混合（MoE）模型，将LLMs部署在无线通信系统中的基站边缘服务器和移动设备上，以发挥分布式设备上专家网络的并行处理优势。论文还设计了一种专家选择策略，以应对无线通信的不稳定性。这项工作主要关注LLMs在实际应用中的部署和性能优化，因此可以归类为LLM应用。",
      "无线通信",
      ""
    ]
  },
  {
    "title": "Automatic Retrieval-augmented Generation of 6G Network Specifications for Use Cases",
    "submit_datetime": "2024年05月05日",
    "abstract": "6G Open Radio Access Networks (ORAN) promises to open data interfaces to enable plug-and-play service Apps, many of which are consumer and business-facing. Opening up 6G access lowers the barrier to innovation but raises the challenge that the required communication specifications are not fully known to all service designers. As such, business innovators must either be familiar with 6G standards or consult with experts. Enabling consistent, unbiased, rapid, and low-cost requirement assessment and specification generation is crucial to the ORAN innovation ecosystem.\n  Here, we discuss our initiative to bridge service specification generation gaps between network service providers and business innovators. We first review the state-of-the-art and motivation in 6G plug-and-play services and capabilities, potential use cases, and relevant advances in Large Language Models (LLMs). We identify an ample innovation space for hybrid use cases that may require diverse and variational wireless functionalities across its operating time. We show that the network specification can be automated and present the first automatic retrieval-augmented specification generation (RAG) framework for 6G use cases. To enable public acceptance and feedback, a website interface is also published for the research and industrial community to experiment with the RAG framework. We hope this review highlights the need and the emerging foundation models that advance this area and motivate researchers to engage with the framework.",
    "pdf_link": "https://arxiv.org/abs/2405.03122",
    "graphs": [],
    "abstract_cn": "6G开放无线接入网络（ORAN）旨在通过开放数据接口，推动即插即用的服务应用，服务于消费者和商业领域。这一开放性虽然降低了创新的门槛，但也带来了挑战，即服务设计者对所需的通信规格了解不足。商业创新者需要熟悉6G标准或寻求专家咨询。为了ORAN创新生态系统，实现快速、公正、低成本的需求评估和规格生成至关重要。本研究旨在连接网络服务提供商和商业创新者在服务规格生成上的鸿沟。我们首先审视了6G即插即用服务的最新进展、潜在应用场景以及大型语言模型（LLMs）的相关发展。我们发现，混合应用场景的创新空间广阔，需要在不同时间段内提供多样化的无线功能。我们展示了网络规格的自动化，并首次提出了一个自动化的6G用例检索增强型规格生成（RAG）框架。为了促进公众的接受和反馈，我们还发布了一个网站界面，供研究和工业界社区进行RAG框架的实验。我们期望本综述能够凸显这一领域的需求，以及推动该领域发展的新兴基础模型，并激励研究人员参与到这个框架中来。",
    "title_cn": "自动增强检索技术在6G网络规范的自动生成中的应用，针对不同用例场景。",
    "tags": [
      "分类：RAG",
      "6G通信",
      "网络服务"
    ]
  },
  {
    "title": "Vector Quantization for Recommender Systems: A Review and Outlook",
    "submit_datetime": "2024年05月05日",
    "abstract": "Vector quantization, renowned for its unparalleled feature compression capabilities, has been a prominent topic in signal processing and machine learning research for several decades and remains widely utilized today. With the emergence of large models and generative AI, vector quantization has gained popularity in recommender systems, establishing itself as a preferred solution. This paper starts with a comprehensive review of vector quantization techniques. It then explores systematic taxonomies of vector quantization methods for recommender systems (VQ4Rec), examining their applications from multiple perspectives. Further, it provides a thorough introduction to research efforts in diverse recommendation scenarios, including efficiency-oriented approaches and quality-oriented approaches. Finally, the survey analyzes the remaining challenges and anticipates future trends in VQ4Rec, including the challenges associated with the training of vector quantization, the opportunities presented by large language models, and emerging trends in multimodal recommender systems. We hope this survey can pave the way for future researchers in the recommendation community and accelerate their exploration in this promising field.",
    "pdf_link": "https://arxiv.org/abs/2405.03110",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.03110v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03110/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03110v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03110/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03110v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03110/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03110v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03110/x4.png"
      }
    ],
    "abstract_cn": "向量量化以其卓越的特征压缩性能而著称，数十年来一直是信号处理和机器学习领域的热门话题，并持续在当今得到广泛应用。随着大型模型和生成性人工智能的兴起，向量量化在推荐系统中的应用日益广泛，成为首选技术。本文首先对向量量化技术进行了全面的梳理，接着深入探讨了推荐系统中向量量化方法的系统分类（VQ4Rec），并从多个视角审视了它们的实际应用。文章还详细介绍了在多样化推荐场景下的研究进展，包括注重效率和质量的不同方法。最后，本调查分析了VQ4Rec面临的挑战，并展望了未来的发展趋势，涉及向量量化训练的难题、大型语言模型带来的机遇，以及多模态推荐系统中的新趋势。我们期望本调查能够为推荐领域的未来研究者指引方向，加快他们在这一充满希望的领域的研究步伐。",
    "title_cn": "向量量化技术在推荐系统领域的应用：回顾与前瞻。",
    "tags": [
      "LLM应用",
      "推荐系统",
      "机器学习"
    ]
  },
  {
    "title": "GeoContrastNet: Contrastive Key-Value Edge Learning for Language-Agnostic Document Understanding",
    "submit_datetime": "2024年05月05日",
    "abstract": "This paper presents GeoContrastNet, a language-agnostic framework to structured document understanding (DU) by integrating a contrastive learning objective with graph attention networks (GATs), emphasizing the significant role of geometric features. We propose a novel methodology that combines geometric edge features with visual features within an overall two-staged GAT-based framework, demonstrating promising results in both link prediction and semantic entity recognition performance. Our findings reveal that combining both geometric and visual features could match the capabilities of large DU models that rely heavily on Optical Character Recognition (OCR) features in terms of performance accuracy and efficiency. This approach underscores the critical importance of relational layout information between the named text entities in a semi-structured layout of a page. Specifically, our results highlight the model's proficiency in identifying key-value relationships within the FUNSD dataset for forms and also discovering the spatial relationships in table-structured layouts for RVLCDIP business invoices. Our code and pretrained models will be accessible on our official GitHub.",
    "pdf_link": "https://arxiv.org/abs/2405.03104",
    "graphs": [],
    "abstract_cn": "本论文提出了 GeoContrastNet，一个不受语言限制的结构化文档理解框架，它通过融合对比学习目标与图注意力网络（GATs），特别强调了几何特征的重要性。我们创新性地将几何边特征与视觉特征相结合，构建了一个两阶段的 GAT 框架，不仅在链接预测和语义实体识别上取得了显著成效。研究结果表明，融合几何与视觉特征的方法，能够在性能精度和效率上与依赖于光学字符识别（OCR）的大型文档理解模型相媲美。这一方法突出了页面半结构化布局中文本实体间关系布局信息的核心价值。具体而言，模型在 FUNSD 数据集中识别表单的键值关系，以及在 RVLCDIP 商业发票的表格布局中揭示空间关系方面表现出色。我们的代码和预训练模型将在 GitHub 官方仓库开放获取。",
    "title_cn": "GeoContrastNet：一种对比关键值边缘学习方法，旨在实现对文档的深入理解，而不受语言限制。",
    "tags": [
      "Agent",
      "文档理解",
      ""
    ]
  },
  {
    "title": "Learning from Students: Applying t-Distributions to Explore Accurate and Efficient Formats for LLMs",
    "submit_datetime": "2024年05月05日",
    "abstract": "Large language models (LLMs) have recently achieved state-of-the-art performance across various tasks, yet due to their large computational requirements, they struggle with strict latency and power demands. Deep neural network (DNN) quantization has traditionally addressed these limitations by converting models to low-precision integer formats. Yet recently alternative formats, such as Normal Float (NF4), have been shown to consistently increase model accuracy, albeit at the cost of increased chip area. In this work, we first conduct a large-scale analysis of LLM weights and activations across 30 networks to conclude most distributions follow a Student's t-distribution. We then derive a new theoretically optimal format, Student Float (SF4), with respect to this distribution, that improves over NF4 across modern LLMs, for example increasing the average accuracy on LLaMA2-7B by 0.76% across tasks. Using this format as a high-accuracy reference, we then propose augmenting E2M1 with two variants of supernormal support for higher model accuracy. Finally, we explore the quality and performance frontier across 11 datatypes, including non-traditional formats like Additive-Powers-of-Two (APoT), by evaluating their model accuracy and hardware complexity. We discover a Pareto curve composed of INT4, E2M1, and E2M1 with supernormal support, which offers a continuous tradeoff between model accuracy and chip area. For example, E2M1 with supernormal support increases the accuracy of Phi-2 by up to 2.19% with 1.22% area overhead, enabling more LLM-based applications to be run at four bits.",
    "pdf_link": "https://arxiv.org/abs/2405.03103",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.03103v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03103/quantized_values.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03103v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03103/profiled_mistral.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03103v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03103/pareto.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03103v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03103/student_degrees.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03103v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03103/t-distributions.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03103v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03103/quantized_values_all.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03103v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03103/apot_values.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03103v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03103/paretos.png"
      }
    ],
    "abstract_cn": "近期，大型语言模型（LLMs）在多项任务上实现了突破性的性能提升。但这些模型因计算量大而面临严苛的时延和能耗挑战。传统上，深度神经网络（DNN）通过将模型转换为低精度整数格式来进行量化，以缓解这些问题。不过，新兴的格式如正规浮点数（NF4）已展现出在提高模型精度方面的潜力，尽管这会增加芯片的面积。在本研究中，我们首先对30种网络的LLM权重和激活进行了广泛分析，发现大多数数据分布符合学生t分布。基于此发现，我们提出了一种新的理论最优格式——学生浮点数（SF4），它在现代LLMs中相比NF4有显著提升，例如在LLaMA2-7B模型上平均准确度提升了0.76%。以SF4作为高精度基准，我们进一步提出了两种超常数支持变体的E2M1，以进一步提升模型精度。最终，我们评估了11种数据类型，包括非传统格式如二的幂次加法（APoT），在模型精度和硬件复杂性方面的表现，发现了由INT4、E2M1及支持超常数的E2M1构成的帕累托前沿，它提供了在模型精度和芯片面积之间的平衡选择。举例来说，支持超常数的E2M1在Phi-2模型上最高可提升2.19%的准确度，而面积开销仅为1.22%，这为更多基于LLM的应用在四舍五入的精度下运行提供了可能。",
    "title_cn": "借鉴学子智慧：利用 t 分布探求适合大型语言模型的精准高效表达方式。",
    "tags": [
      "LLM理论",
      "",
      "硬件设计"
    ]
  },
  {
    "title": "FairMonitor: A Dual-framework for Detecting Stereotypes and Biases in Large Language Models",
    "submit_datetime": "2024年05月05日",
    "abstract": "Detecting stereotypes and biases in Large Language Models (LLMs) is crucial for enhancing fairness and reducing adverse impacts on individuals or groups when these models are applied. Traditional methods, which rely on embedding spaces or are based on probability metrics, fall short in revealing the nuanced and implicit biases present in various contexts. To address this challenge, we propose the FairMonitor framework and adopt a static-dynamic detection method for a comprehensive evaluation of stereotypes and biases in LLMs. The static component consists of a direct inquiry test, an implicit association test, and an unknown situation test, including 10,262 open-ended questions with 9 sensitive factors and 26 educational scenarios. And it is effective for evaluating both explicit and implicit biases. Moreover, we utilize the multi-agent system to construst the dynamic scenarios for detecting subtle biases in more complex and realistic setting. This component detects the biases based on the interaction behaviors of LLMs across 600 varied educational scenarios. The experimental results show that the cooperation of static and dynamic methods can detect more stereotypes and biased in LLMs.",
    "pdf_link": "https://arxiv.org/abs/2405.03098",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.03098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03098/Fig1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03098/Fig2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03098/Fig3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03098/Fig4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03098/Fig5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03098/Fig6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03098/Fig7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03098/Fig8.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03098/Fig9.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03098/Fig10.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03098/Fig11.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03098/Fig12.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03098/Fig13.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03098/Fig14.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03098/Fig15.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03098/Fig16.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03098/Fig17.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03098v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03098/Fig18.png"
      }
    ],
    "abstract_cn": "在大型语言模型（LLMs）中识别刻板印象与偏见，对于提升模型公正性及减少其对人群可能产生的负面影响极为关键。传统依赖嵌入空间或概率度量的方法，在揭露多变语境下的隐性偏见上力有未逮。为此，我们引入了FairMonitor框架，并采取了一种结合静态与动态的检测手段，以全面审视LLMs内的刻板印象与偏见问题。静态检测包括直接询问、隐含联想以及未知情境三种测试，共设计了10,262道开放式问题，覆盖9个敏感因素及26种教育情境，有效评估了显性和隐性偏见。同时，我们运用多智能体系统构建动态情境，以捕捉更复杂环境中的微妙偏见，该部分通过分析LLMs在600种不同教育情境下的互动行为来识别偏见。实验结果显示，静态与动态检测方法的结合能够有效揭示LLMs中的更多刻板印象和偏见。",
    "title_cn": "FairMonitor：一套双重框架，专为发现大型语言模型中的刻板印象与偏见而设计。",
    "tags": [
      "LLM应用",
      "人工智能",
      ""
    ]
  },
  {
    "title": "To Each (Textual Sequence) Its Own: Improving Memorized-Data Unlearning in Large Language Models",
    "submit_datetime": "2024年05月05日",
    "abstract": "LLMs have been found to memorize training textual sequences and regurgitate verbatim said sequences during text generation time. This fact is known to be the cause of privacy and related (e.g., copyright) problems. Unlearning in LLMs then takes the form of devising new algorithms that will properly deal with these side-effects of memorized data, while not hurting the model's utility. We offer a fresh perspective towards this goal, namely, that each textual sequence to be forgotten should be treated differently when being unlearned based on its degree of memorization within the LLM. We contribute a new metric for measuring unlearning quality, an adversarial attack showing that SOTA algorithms lacking this perspective fail for privacy, and two new unlearning methods based on Gradient Ascent and Task Arithmetic, respectively. A comprehensive performance evaluation across an extensive suite of NLP tasks then mapped the solution space, identifying the best solutions under different scales in model capacities and forget set sizes and quantified the gains of the new approaches.",
    "pdf_link": "https://arxiv.org/abs/2405.03097",
    "graphs": [],
    "abstract_cn": "研究发现，大型语言模型（LLMs）在文本生成过程中会记忆并精确复现训练时的文本序列，这一现象是引发隐私及版权等相关问题的根源。为了解决这一问题，LLMs中的“去学习”过程需要设计新算法，以妥善处理记忆数据带来的副作用，同时保持模型的效用。我们提出了一种新的思路：在进行去学习时，应根据文本序列在LLM中的记忆力程度，采取不同的处理策略。我们引入了一种新的度量去学习质量的指标，并展示了一个对抗性攻击，证明缺少这种视角的现有顶尖算法在隐私保护方面存在不足。此外，我们还提出了两种新的去学习方法，分别基于梯度上升和任务算术。通过在一系列广泛的自然语言处理（NLP）任务上的全面性能评估，我们绘制了解决方案空间，找出了不同模型容量和忘却集大小下的最佳解决方案，并评估了这些新方法的优势。",
    "title_cn": "为每个文本序列量身定制：优化大型语言模型中的记忆数据忘却机制",
    "tags": [
      "LLM理论",
      "",
      "隐私保护"
    ]
  },
  {
    "title": "Compressing Long Context for Enhancing RAG with AMR-based Concept Distillation",
    "submit_datetime": "2024年05月05日",
    "abstract": "Large Language Models (LLMs) have made significant strides in information acquisition. However, their overreliance on potentially flawed parametric knowledge leads to hallucinations and inaccuracies, particularly when handling long-tail, domain-specific queries. Retrieval Augmented Generation (RAG) addresses this limitation by incorporating external, non-parametric knowledge. Nevertheless, the retrieved long-context documents often contain noisy, irrelevant information alongside vital knowledge, negatively diluting LLMs' attention. Inspired by the supportive role of essential concepts in individuals' reading comprehension, we propose a novel concept-based RAG framework with the Abstract Meaning Representation (AMR)-based concept distillation algorithm. The proposed algorithm compresses the cluttered raw retrieved documents into a compact set of crucial concepts distilled from the informative nodes of AMR by referring to reliable linguistic features. The concepts explicitly constrain LLMs to focus solely on vital information in the inference process. We conduct extensive experiments on open-domain question-answering datasets to empirically evaluate the proposed method's effectiveness. The results indicate that the concept-based RAG framework outperforms other baseline methods, particularly as the number of supporting documents increases, while also exhibiting robustness across various backbone LLMs. This emphasizes the distilled concepts are informative for augmenting the RAG process by filtering out interference information. To the best of our knowledge, this is the first work introducing AMR to enhance the RAG, presenting a potential solution to augment inference performance with semantic-based context compression.",
    "pdf_link": "https://arxiv.org/abs/2405.03085",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）在信息获取上实现了重大突破，但它们对可能存在缺陷的参数知识的过分依赖，常常导致在处理长尾和特定领域查询时出现幻觉和错误。为了克服这一问题，检索增强生成（RAG）引入了外部非参数知识。尽管如此，检索得到的长篇文档中往往混杂着噪声和无关信息，这会削弱LLMs的注意力集中。借鉴关键概念在提升个人阅读理解中的作用，我们提出了一种创新的基于概念的RAG框架，辅以基于抽象语义表示（AMR）的概念蒸馏算法。该算法能够将杂乱无章的原始检索文档精炼为一组关键概念，这些概念是从AMR的信息节点中提取的，依据的是可靠的语言特征。这些概念明确指导LLMs在推理过程中只专注于重要信息。我们在开放域问答数据集上进行了广泛的实验，验证了我们方法的有效性。实验结果表明，我们提出的基于概念的RAG框架在性能上超越了其他基线方法，尤其是在支持文档数量增加时，同时在不同后端LLMs上也显示出了良好的鲁棒性。这表明，通过过滤干扰信息，蒸馏出的概念能够丰富RAG过程的信息量。据我们所知，这是首次将AMR引入RAG以增强其性能，为使用基于语义的上下文压缩来提升推理性能提供了一种可能的解决方案。",
    "title_cn": "为了提升基于AMR（抽象意义表示）的RAG（Retrieval-Augmented Generation，检索增强生成）模型的性能，我们采用了一种压缩长文本的方法。",
    "tags": [
      "RAG",
      "信息检索",
      ""
    ]
  },
  {
    "title": "Traffic Performance GPT (TP-GPT): Real-Time Data Informed Intelligent ChatBot for Transportation Surveillance and Management",
    "submit_datetime": "2024年05月05日",
    "abstract": "The digitization of traffic sensing infrastructure has significantly accumulated an extensive traffic data warehouse, which presents unprecedented challenges for transportation analytics. The complexities associated with querying large-scale multi-table databases require specialized programming expertise and labor-intensive development. Additionally, traditional analysis methods have focused mainly on numerical data, often neglecting the semantic aspects that could enhance interpretability and understanding. Furthermore, real-time traffic data access is typically limited due to privacy concerns. To bridge this gap, the integration of Large Language Models (LLMs) into the domain of traffic management presents a transformative approach to addressing the complexities and challenges inherent in modern transportation systems. This paper proposes an intelligent online chatbot, TP-GPT, for efficient customized transportation surveillance and management empowered by a large real-time traffic database. The innovative framework leverages contextual and generative intelligence of language models to generate accurate SQL queries and natural language interpretations by employing transportation-specialized prompts, Chain-of-Thought prompting, few-shot learning, multi-agent collaboration strategy, and chat memory. Experimental study demonstrates that our approach outperforms state-of-the-art baselines such as GPT-4 and PaLM 2 on a challenging traffic-analysis benchmark TransQuery. TP-GPT would aid researchers and practitioners in real-time transportation surveillance and management in a privacy-preserving, equitable, and customizable manner.",
    "pdf_link": "https://arxiv.org/abs/2405.03076",
    "graphs": [],
    "abstract_cn": "随着交通感知设施的数字化，我们积累了庞大的交通数据资源，这为交通分析带来了巨大挑战。处理大规模多表数据库的查询不仅技术要求高，开发过程也极为耗时。传统分析多聚焦于数值信息，却忽略了语义层面的深入挖掘，这恰恰能提升我们的理解和解释能力。同时，对实时交通数据的获取往往因隐私顾虑而受限。为解决这些问题，本文提出了将大型语言模型（LLMs）应用于交通管理的新思路，旨在应对现代交通系统的复杂性。我们设计了一个智能在线聊天机器人TP-GPT，它依托一个庞大的实时交通数据库，为用户提供高效、定制化的交通监控与管理服务。TP-GPT结合了语言模型的上下文理解和生成能力，通过专业交通提示、思维链引导、少量样本学习、多代理协作以及聊天记忆等技术，能够生成精确的SQL查询语句和自然语言解释。实验结果表明，TP-GPT在TransQuery这一复杂的交通分析测试中，性能超越了GPT-4和PaLM 2等现有技术。这一创新工具将为交通领域的研究者和从业者提供一个保护隐私、公平、可定制的实时监控与管理解决方案。",
    "title_cn": "交通性能 GPT（TP-GPT）：一款基于实时数据的智能聊天机器人，专为交通监控与管理量身定制。",
    "tags": [
      "LLM应用",
      "交通管理",
      "人工智能"
    ]
  },
  {
    "title": "A scoping review of using Large Language Models (LLMs) to investigate Electronic Health Records (EHRs)",
    "submit_datetime": "2024年05月05日",
    "abstract": "Electronic Health Records (EHRs) play an important role in the healthcare system. However, their complexity and vast volume pose significant challenges to data interpretation and analysis. Recent advancements in Artificial Intelligence (AI), particularly the development of Large Language Models (LLMs), open up new opportunities for researchers in this domain. Although prior studies have demonstrated their potential in language understanding and processing in the context of EHRs, a comprehensive scoping review is lacking. This study aims to bridge this research gap by conducting a scoping review based on 329 related papers collected from OpenAlex. We first performed a bibliometric analysis to examine paper trends, model applications, and collaboration networks. Next, we manually reviewed and categorized each paper into one of the seven identified topics: named entity recognition, information extraction, text similarity, text summarization, text classification, dialogue system, and diagnosis and prediction. For each topic, we discussed the unique capabilities of LLMs, such as their ability to understand context, capture semantic relations, and generate human-like text. Finally, we highlighted several implications for researchers from the perspectives of data resources, prompt engineering, fine-tuning, performance measures, and ethical concerns. In conclusion, this study provides valuable insights into the potential of LLMs to transform EHR research and discusses their applications and ethical considerations.",
    "pdf_link": "https://arxiv.org/abs/2405.03066",
    "graphs": [],
    "abstract_cn": "电子健康记录（EHR）对于医疗系统至关重要，但其复杂性和数据量之大给信息解读和分析带来了挑战。AI领域的新进展，尤其是大型语言模型（LLM）的兴起，为这一难题提供了解决之道。尽管先前研究已展示LLM在理解EHR语境下的语言方面的能力，但目前尚缺一个全面的综述。本研究通过综述329篇来自OpenAlex的相关论文，旨在填补这一空白。我们先对文献趋势、模型应用和合作网络进行了计量分析，随后将每篇论文手动分类至七个主题：命名实体识别、信息提取、文本相似性、文本摘要、文本分类、对话系统、以及诊断与预测。我们探讨了LLM在理解上下文、捕捉语义联系和生成类人文本等方面的独到之处。此外，我们还从数据资源、提示设计、微调、性能评估和伦理问题等角度，指出了对研究者的几点启示。总结而言，本研究深入探讨了LLM在EHR研究中的潜力，并对其应用和伦理问题进行了讨论。",
    "title_cn": "本文综述了利用大型语言模型（LLMs）来探究电子健康记录（EHRs）的应用情况。",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "High Order Reasoning for Time Critical Recommendation in Evidence-based Medicine",
    "submit_datetime": "2024年05月05日",
    "abstract": "In time-critical decisions, human decision-makers can interact with AI-enabled situation-aware software to evaluate many imminent and possible scenarios, retrieve billions of facts, and estimate different outcomes based on trillions of parameters in a fraction of a second. In high-order reasoning, \"what-if\" questions can be used to challenge the assumptions or pre-conditions of the reasoning, \"why-not\" questions can be used to challenge on the method applied in the reasoning, \"so-what\" questions can be used to challenge the purpose of the decision, and \"how-about\" questions can be used to challenge the applicability of the method. When above high-order reasoning questions are applied to assist human decision-making, it can help humans to make time-critical decisions and avoid false-negative or false-positive types of errors. In this paper, we present a model of high-order reasoning to offer recommendations in evidence-based medicine in a time-critical fashion for the applications in ICU. The Large Language Model (LLM) is used in our system. The experiments demonstrated the LLM exhibited optimal performance in the \"What-if\" scenario, achieving a similarity of 88.52% with the treatment plans of human doctors. In the \"Why-not\" scenario, the best-performing model tended to opt for alternative treatment plans in 70% of cases for patients who died after being discharged from the ICU. In the \"So-what\" scenario, the optimal model provided a detailed analysis of the motivation and significance of treatment plans for ICU patients, with its reasoning achieving a similarity of 55.6% with actual diagnostic information. In the \"How-about\" scenario, the top-performing LLM demonstrated a content similarity of 66.5% in designing treatment plans transferring for similar diseases. Meanwhile, LLMs managed to predict the life status of patients after their discharge from the ICU with an accuracy of 70%.",
    "pdf_link": "https://arxiv.org/abs/2405.03010",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.03010v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03010/Intuition.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03010v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03010/ID.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03010v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03010/H.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03010v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03010/Whatif.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03010v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03010/Whynot.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03010v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03010/Sowhat.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03010v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03010/Howabout.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03010v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03010/WI1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03010v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03010/WI2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03010v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03010/WN1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03010v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03010/SW1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03010v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03010/HW2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03010v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03010/HW1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03010v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03010/F1.png"
      }
    ],
    "abstract_cn": "在紧急决策时刻，人类决策者能够借助具备人工智能的情境感知软件，迅速评估各种可能情况，快速检索海量信息，并在瞬间基于海量参数预测不同结果。在进行高阶推理时，通过提出“如果……会怎样”、“为什么不”、“那么又如何”和“如何”等问题，可以深入挑战推理的基础假设、方法选择、决策目的及其适用性。这种高阶推理的应用有助于人类在关键时刻做出决策，减少误判。本文介绍了一种高阶推理模型，旨在为ICU中的证据基础医学提供及时的建议。我们的系统采用了大型语言模型（LLM）。实验结果表明，LLM在模拟“如果……会怎样”情况下表现卓越，其提出的治疗方案与医生的计划相似度高达88.52%。在“为什么不”情境下，该模型在70%的案例中为ICU出院后不幸去世的病人提供了替代治疗方案。在探讨“那么又如何”的情境中，该模型深入分析了ICU治疗方案的动机与重要性，其推理与实际诊断信息的相似度达到了55.6%。在“如何”情境下，该模型在设计类似疾病治疗方案时，内容相似度达到了66.5%。此外，LLM还能够以70%的准确率预测ICU病人出院后的生存状况。",
    "title_cn": "在循证医学领域，面对紧急情况下的推荐决策，我们需运用高阶推理技巧。",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "On the performativity of SDG classifications in large bibliometric databases",
    "submit_datetime": "2024年05月05日",
    "abstract": "Large bibliometric databases, such as Web of Science, Scopus, and OpenAlex, facilitate bibliometric analyses, but are performative, affecting the visibility of scientific outputs and the impact measurement of participating entities. Recently, these databases have taken up the UN's Sustainable Development Goals (SDGs) in their respective classifications, which have been criticised for their diverging nature. This work proposes using the feature of large language models (LLMs) to learn about the \"data bias\" injected by diverse SDG classifications into bibliometric data by exploring five SDGs. We build a LLM that is fine-tuned in parallel by the diverse SDG classifications inscribed into the databases' SDG classifications. Our results show high sensitivity in model architecture, classified publications, fine-tuning process, and natural language generation. The wide arbitrariness at different levels raises concerns about using LLM in research practice.",
    "pdf_link": "https://arxiv.org/abs/2405.03007",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.03007v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03007/jointly.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03007v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03007/venn_diagram_sdg04.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03007v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03007/venn_diagram_sdg05.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03007v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03007/venn_diagram_sdg08.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03007v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03007/venn_diagram_sdg09.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03007v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03007/venn_diagram_sdg10.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03007v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03007/researchdesigncomplete.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03007v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03007/bar_charts_500_TRICOLOR_NO_BOLD.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03007v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03007/bar_charts_500_FIXED.png"
      }
    ],
    "abstract_cn": "诸如 Web of Science、Scopus 和 OpenAlex 等大型引文数据库为引文分析提供了便利，但它们的影响力却会影响科研成果的曝光度和相关实体的影响力评估。近期，这些数据库开始将联合国的可持续发展目标（SDGs）纳入其分类体系，而这种多样化的分类方式因其差异性而备受争议。本研究旨在利用大型语言模型（LLMs）的特性，通过研究五个 SDGs 来探究不同 SDG 分类对引文数据造成的“数据偏见”。我们构建了一个根据数据库中不同 SDG 分类并行微调的 LLM。研究发现，模型结构、归类出版物、微调过程以及自然语言生成等方面表现出高度敏感性。不同层级上的广泛任意性引发了对 LLM 在研究实践中应用的担忧。",
    "title_cn": "在大型文献计量数据库中，对可持续发展目标（SDG）分类的绩效性进行探讨。",
    "tags": [
      "LLM应用",
      "科研分析",
      "可持续发展"
    ]
  },
  {
    "title": "MedAdapter: Efficient Test-Time Adaptation of Large Language Models towards Medical Reasoning",
    "submit_datetime": "2024年05月05日",
    "abstract": "Despite their improved capabilities in generation and reasoning, adapting large language models (LLMs) to the biomedical domain remains challenging due to their immense size and corporate privacy. In this work, we propose MedAdapter, a unified post-hoc adapter for test-time adaptation of LLMs towards biomedical applications. Instead of fine-tuning the entire LLM, MedAdapter effectively adapts the original model by fine-tuning only a small BERT-sized adapter to rank candidate solutions generated by LLMs. Experiments demonstrate that MedAdapter effectively adapts both white-box and black-box LLMs in biomedical reasoning, achieving average performance improvements of 25.48% and 11.31%, respectively, without requiring extensive computational resources or sharing data with third parties. MedAdapter also yields superior performance when combined with train-time adaptation, highlighting a flexible and complementary solution to existing adaptation methods. Faced with the challenges of balancing model performance, computational resources, and data privacy, MedAdapter provides an efficient, privacy-preserving, cost-effective, and transparent solution for adapting LLMs to the biomedical domain.",
    "pdf_link": "https://arxiv.org/abs/2405.03000",
    "graphs": [],
    "abstract_cn": "尽管大型语言模型（LLMs）在生成和推理上有所进步，但要将其应用于生物医学领域，仍面临规模庞大和隐私保护的双重挑战。本研究提出了MedAdapter，一种创新的事后适配器，专门用于在测试阶段对LLMs进行生物医学应用的适配。与传统的全面微调不同，MedAdapter通过微调一个小型的BERT尺寸适配器，高效地调整原始模型，以优化LLMs生成的候选解决方案的排序。实验结果证明，MedAdapter在生物医学推理任务中，无论是对白盒还是黑盒LLMs，都能显著提升性能，分别达到了25.48%和11.31%的平均性能增益，且无需额外的计算资源或数据共享。此外，MedAdapter与训练阶段的适配相结合，能够进一步提升性能，展现出其灵活性和对现有方法的有效补充。在考量模型效能、计算资源和数据隐私的平衡问题时，MedAdapter提供了一种既高效又保护隐私、经济且透明的解决方案，以促进LLMs在生物医学领域的应用。",
    "title_cn": "MedAdapter：为大型语言模型在医学推理任务中实现高效的测试时适应性",
    "tags": [
      "LLM应用",
      "生物医学",
      ""
    ]
  },
  {
    "title": "Analysis about Theoretical Foundations for Method to Enhancing ASR Performance using OCR Word Frequency Differences",
    "submit_datetime": "2024年05月05日",
    "abstract": "As interest in large language models (LLMs) grows, the importance of accuracy in automatic speech recognition (ASR) has become more pronounced. This is particularly true for lectures that include specialized terminology, where the success rate of traditional ASR models tends to be low, posing a challenging problem. A method to improve ASR performance for specialized terminology using the word frequency difference approach has been proposed. Through experiments and data analysis, we investigate whether this proposal effectively addresses the issue. Additionally, we introduce the power law as the theoretical foundation for the relative frequency",
    "pdf_link": "https://arxiv.org/abs/2405.02995",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.02995v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02995/fig1.png"
      }
    ],
    "abstract_cn": "随着大型语言模型（LLMs）关注度的提升，自动语音识别（ASR）的精确度变得尤为关键。尤其是在包含专业术语的讲座中，传统 ASR 模型的识别准确率通常较低，这带来了挑战。为此，我们提出了一种基于词频差异方法来提升对专业术语的 ASR 性能。通过一系列实验和数据分析，我们验证了这一方法的有效性。同时，我们还引入了幂律作为相对频率的理论支撑。",
    "title_cn": "本文深入探讨了利用OCR单词频率差异提升自动语音识别（ASR）性能的方法背后的理论基础。",
    "tags": [
      "分类：LLM应用",
      "自动语音识别",
      "专业术语处理"
    ]
  },
  {
    "title": "Can Large Language Models Make the Grade? An Empirical Study Evaluating LLMs Ability to Mark Short Answer Questions in K-12 Education",
    "submit_datetime": "2024年05月05日",
    "abstract": "This paper presents reports on a series of experiments with a novel dataset evaluating how well Large Language Models (LLMs) can mark (i.e. grade) open text responses to short answer questions, Specifically, we explore how well different combinations of GPT version and prompt engineering strategies performed at marking real student answers to short answer across different domain areas (Science and History) and grade-levels (spanning ages 5-16) using a new, never-used-before dataset from Carousel, a quizzing platform. We found that GPT-4, with basic few-shot prompting performed well (Kappa, 0.70) and, importantly, very close to human-level performance (0.75). This research builds on prior findings that GPT-4 could reliably score short answer reading comprehension questions at a performance-level very close to that of expert human raters. The proximity to human-level performance, across a variety of subjects and grade levels suggests that LLMs could be a valuable tool for supporting low-stakes formative assessment tasks in K-12 education and has important implications for real-world education delivery.",
    "pdf_link": "https://arxiv.org/abs/2405.02985",
    "graphs": [],
    "abstract_cn": "本研究通过一系列实验，采用新颖的数据集，探讨了大型语言模型（LLMs）在评分简短问答的开放式文本回答方面的能力。实验特别关注了不同版本的 GPT 结合提示工程策略在不同学科领域（科学与历史）及不同年级（5至16岁）学生的真实回答评分上的表现，数据来源于 Carousel 测验平台的全新数据集。研究结果显示，GPT-4 在使用基础的少量样本提示时表现优异（Kappa 值为 0.70），且其评分水平极为接近人类评分者（0.75）。这一发现与之前的研究相呼应，证实了 GPT-4 在评分阅读理解简答题上的能力可与人类专家相媲美。鉴于 LLMs 在多个学科和年级层级的评分表现均接近人类水平，这表明它们在 K-12 教育中的低风险形成性评估任务中具有潜在的应用价值，并对现实教育实践具有深远的影响。",
    "title_cn": "大型语言模型能否担当起评分的重任？本实证研究深入探讨了这些模型在 K-12 教育领域评估简答题表现的能力。",
    "tags": [
      "LLM应用",
      "",
      "人工智能评分"
    ]
  },
  {
    "title": "Agent Hospital: A Simulacrum of Hospital with Evolvable Medical Agents",
    "submit_datetime": "2024年05月05日",
    "abstract": "In this paper, we introduce a simulacrum of hospital called Agent Hospital that simulates the entire process of treating illness. All patients, nurses, and doctors are autonomous agents powered by large language models (LLMs). Our central goal is to enable a doctor agent to learn how to treat illness within the simulacrum. To do so, we propose a method called MedAgent-Zero. As the simulacrum can simulate disease onset and progression based on knowledge bases and LLMs, doctor agents can keep accumulating experience from both successful and unsuccessful cases. Simulation experiments show that the treatment performance of doctor agents consistently improves on various tasks. More interestingly, the knowledge the doctor agents have acquired in Agent Hospital is applicable to real-world medicare benchmarks. After treating around ten thousand patients (real-world doctors may take over two years), the evolved doctor agent achieves a state-of-the-art accuracy of 93.06% on a subset of the MedQA dataset that covers major respiratory diseases. This work paves the way for advancing the applications of LLM-powered agent techniques in medical scenarios.",
    "pdf_link": "https://arxiv.org/abs/2405.02957",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.02957v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02957/macon_v1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02957v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02957/macon_v2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02957v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02957/agent.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02957v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02957/resident_planning.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02957v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02957/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02957v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02957/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02957v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02957/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02957v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02957/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02957v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02957/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02957v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02957/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02957v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02957/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02957v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02957/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02957v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02957/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02957v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02957/covid_virus.png"
      }
    ],
    "abstract_cn": "本文提出了一个名为“代理医院”的仿真系统，旨在模拟疾病的治疗流程。在这个系统中，患者、护士和医生都是由大型语言模型（LLMs）支持的自主智能体。我们的主要目标是训练医生智能体在仿真环境中掌握治疗技能，为此我们设计了一种创新的方法——MedAgent-Zero。该系统能够基于知识库和LLMs模拟疾病的发生和发展，使医生智能体能够从成功与失败的案例中吸取经验。实验结果表明，医生智能体的治疗能力在多项任务上均有显著提升。尤为引人注目的是，这些智能体在“代理医院”中积累的知识能够有效应用于现实世界的医疗评估标准。经过约一万次的治疗实践（相当于现实医生两年的工作量），经过训练的医生智能体在MedQA数据集的一个子集上，针对主要呼吸系统疾病的问题，达到了93.06%的准确率，这一成果处于行业领先水平。本研究为LLM驱动的智能体技术在医疗领域的应用开辟了新的路径。",
    "title_cn": "《代理医院：一个可进化医疗代理的仿真医院》",
    "tags": [
      "Agent",
      "",
      "仿真系统"
    ]
  },
  {
    "title": "Source-Free Domain Adaptation Guided by Vision and Vision-Language Pre-Training",
    "submit_datetime": "2024年05月05日",
    "abstract": "Source-free domain adaptation (SFDA) aims to adapt a source model trained on a fully-labeled source domain to a related but unlabeled target domain. While the source model is a key avenue for acquiring target pseudolabels, the generated pseudolabels may exhibit source bias. In the conventional SFDA pipeline, a large data (e.g. ImageNet) pre-trained feature extractor is used to initialize the source model at the start of source training, and subsequently discarded. Despite having diverse features important for generalization, the pre-trained feature extractor can overfit to the source data distribution during source training and forget relevant target domain knowledge. Rather than discarding this valuable knowledge, we introduce an integrated framework to incorporate pre-trained networks into the target adaptation process. The proposed framework is flexible and allows us to plug modern pre-trained networks into the adaptation process to leverage their stronger representation learning capabilities. For adaptation, we propose the Co-learn algorithm to improve target pseudolabel quality collaboratively through the source model and a pre-trained feature extractor. Building on the recent success of the vision-language model CLIP in zero-shot image recognition, we present an extension Co-learn++ to further incorporate CLIP's zero-shot classification decisions. We evaluate on 3 benchmark datasets and include more challenging scenarios such as open-set, partial-set and open-partial SFDA. Experimental results demonstrate that our proposed strategy improves adaptation performance and can be successfully integrated with existing SFDA methods.",
    "pdf_link": "https://arxiv.org/abs/2405.02954",
    "graphs": [],
    "abstract_cn": "无源域自适应技术（SFDA）致力于将训练有素的源模型适配至相关但未标记的目标域。源模型虽是生成目标伪标签的关键，但这些伪标签可能带有源域偏见。传统SFDA流程中，通常会使用大型数据集（如ImageNet）预训练的特征提取器来初始化源模型，然后将其弃用。这些预训练的特征提取器虽具备多样化特征以助于泛化，却可能在源域训练过程中过度适应源数据分布，导致丢失对目标域重要的知识。我们提出了一个整合框架，将这些预训练网络融入目标域的适配过程，以保留其价值。该框架设计灵活，能够将现代预训练网络整合进适配流程，从而利用其强大的表示学习功能。我们引入了Co-learn算法，通过源模型和预训练特征提取器共同提升目标伪标签的质量。借助于视觉-语言模型CLIP在零样本图像识别领域的突破，我们进一步开发了Co-learn++算法，以整合CLIP的零样本分类决策。我们在三个基准数据集上进行了评估，包括更具挑战性的开放集、部分集和开放-部分SFDA场景。实验结果显示，我们的策略显著提升了适配效果，并能与现有的SFDA方法无缝结合。",
    "title_cn": "视觉与视觉-语言预训练引领的无源域自适应指南",
    "tags": [
      "分类：RAG",
      "计算机视觉",
      "机器学习"
    ]
  },
  {
    "title": "Unraveling the Dominance of Large Language Models Over Transformer Models for Bangla Natural Language Inference: A Comprehensive Study",
    "submit_datetime": "2024年05月05日",
    "abstract": "Natural Language Inference (NLI) is a cornerstone of Natural Language Processing (NLP), providing insights into the entailment relationships between text pairings. It is a critical component of Natural Language Understanding (NLU), demonstrating the ability to extract information from spoken or written interactions. NLI is mainly concerned with determining the entailment relationship between two statements, known as the premise and hypothesis. When the premise logically implies the hypothesis, the pair is labeled ``entailment''. If the hypothesis contradicts the premise, the pair receives the ``contradiction'' label. When there is insufficient evidence to establish a connection, the pair is described as ``neutral''. Despite the success of Large Language Models (LLMs) in various tasks, their effectiveness in NLI remains constrained by issues like low-resource domain accuracy, model overconfidence, and difficulty in capturing human judgment disagreements. This study addresses the underexplored area of evaluating LLMs in low-resourced languages such as Bengali. Through a comprehensive evaluation, we assess the performance of prominent LLMs and state-of-the-art (SOTA) models in Bengali NLP tasks, focusing on natural language inference. Utilizing the XNLI dataset, we conduct zero-shot and few-shot evaluations, comparing LLMs like GPT-3.5 Turbo and Gemini 1.5 Pro with models such as BanglaBERT, Bangla BERT Base, DistilBERT, mBERT, and sahajBERT. Our findings reveal that while LLMs can achieve comparable or superior performance to fine-tuned SOTA models in few-shot scenarios, further research is necessary to enhance our understanding of LLMs in languages with modest resources like Bengali. This study underscores the importance of continued efforts in exploring LLM capabilities across diverse linguistic contexts.",
    "pdf_link": "https://arxiv.org/abs/2405.02937",
    "graphs": [],
    "abstract_cn": "自然语言推理（NLI）乃自然语言处理（NLP）之核心，洞察文本对之间的蕴含联系。它在自然语言理解（NLU）中扮演关键角色，体现从言谈或书写交流中抽取信息的技巧。NLI着重于辨析两个命题——前提与假设——之间的逻辑蕴含。若前提逻辑上暗示了假设，该对则被标记为“蕴含”；若假设与前提相冲突，则被标记为“矛盾”；证据不足时，则称为“中立”。尽管大型语言模型（LLMs）在多项任务中表现卓越，其在NLI上的表现仍受限于资源稀缺领域的准确度、模型过度自信以及捕捉人类判断差异的难度。本研究着眼于在资源匮乏语言（如孟加拉语）中评估LLMs的未充分研究领域。通过深入评估，我们对孟加拉语NLP任务中的知名LLMs和尖端模型进行了性能分析，特别关注自然语言推理。利用XNLI数据集，我们进行了零样本和少样本的评估，将GPT-3.5 Turbo和Gemini 1.5 Pro等LLMs与BanglaBERT、Bangla BERT Base、DistilBERT、mBERT和sahajBERT等模型进行了比较。研究发现，LLMs在少样本情境下的表现可与经过微调的尖端模型相媲美或更优，但为了深化我们对资源适中语言（如孟加拉语）中LLMs的理解，仍需进一步研究。本研究凸显了在不同语言环境中持续探索LLMs潜力的重要性。",
    "title_cn": "深入探究大型语言模型如何在孟加拉语自然语言推理任务中超越变换器模型：一项全面深入的研究。",
    "tags": [
      "LLM应用",
      "",
      "机器学习"
    ]
  },
  {
    "title": "Relay Decoding: Concatenating Large Language Models for Machine Translation",
    "submit_datetime": "2024年05月05日",
    "abstract": "Leveraging large language models for machine translation has demonstrated promising results. However, it does require the large language models to possess the capability of handling both the source and target languages in machine translation. When it is challenging to find large models that support the desired languages, resorting to continuous learning methods becomes a costly endeavor. To mitigate these expenses, we propose an innovative approach called RD (Relay Decoding), which entails concatenating two distinct large models that individually support the source and target languages. By incorporating a simple mapping layer to facilitate the connection between these two models and utilizing a limited amount of parallel data for training, we successfully achieve superior results in the machine translation task. Experimental results conducted on the Multi30k and WikiMatrix datasets validate the effectiveness of our proposed method.",
    "pdf_link": "https://arxiv.org/abs/2405.02933",
    "graphs": [],
    "abstract_cn": "运用大型语言模型于机器翻译领域已取得显著成效。但要胜任机译任务，模型必须能够同时掌握源语言与目标语言。在难以觅得支持特定语言对的大型模型时，持续学习的方法往往成本高昂。为降低这一成本，我们提出了一种新颖的RD（中继解码）策略，该策略通过串联两个分别精通源语言和目标语言的大型模型，并引入一个简易的映射层以促进两者间的协同工作，辅以少量的平行语料进行训练，我们成功地在机器翻译领域取得了突破性成果。在Multi30k和WikiMatrix数据集上的实验结果显示，我们的方法极具成效。",
    "title_cn": "中继解码技术：将大型语言模型串联起来，以提升机器翻译的性能。",
    "tags": [
      "分类：LLM应用",
      "机器翻译",
      "持续学习"
    ]
  },
  {
    "title": "Overconfidence is Key: Verbalized Uncertainty Evaluation in Large Language and Vision-Language Models",
    "submit_datetime": "2024年05月05日",
    "abstract": "Language and Vision-Language Models (LLMs/VLMs) have revolutionized the field of AI by their ability to generate human-like text and understand images, but ensuring their reliability is crucial. This paper aims to evaluate the ability of LLMs (GPT4, GPT-3.5, LLaMA2, and PaLM 2) and VLMs (GPT4V and Gemini Pro Vision) to estimate their verbalized uncertainty via prompting. We propose the new Japanese Uncertain Scenes (JUS) dataset, aimed at testing VLM capabilities via difficult queries and object counting, and the Net Calibration Error (NCE) to measure direction of miscalibration. Results show that both LLMs and VLMs have a high calibration error and are overconfident most of the time, indicating a poor capability for uncertainty estimation. Additionally we develop prompts for regression tasks, and we show that VLMs have poor calibration when producing mean/standard deviation and 95% confidence intervals.",
    "pdf_link": "https://arxiv.org/abs/2405.02917",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.02917v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02917/x1.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.02917v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02917/x2.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.02917v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02917/x3.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.02917v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02917/x4.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.02917v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02917/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02917v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02917/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02917v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02917/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02917v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02917/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02917v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02917/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02917v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02917/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02917v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02917/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02917v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02917/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02917v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02917/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02917v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02917/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02917v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02917/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02917v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02917/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02917v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02917/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02917v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02917/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02917v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02917/coverage_relativesd.png"
      }
    ],
    "abstract_cn": "语言与视觉-语言模型（LLMs/VLMs）以其生成类人文本和图像理解能力，引领了人工智能领域的革新，但其可靠性的确保尤为关键。本研究旨在评估包括GPT4、GPT-3.5、LLaMA2、PaLM 2在内的LLMs，以及GPT4V和Gemini Pro Vision在内的VLMs，通过提示来估计其口头不确定性的能力。我们引入了新的日本不确定性场景（JUS）数据集，用以通过复杂查询和对象计数来测试VLMs的性能，并采用网络校准误差（NCE）来衡量校准误差的方向。研究结果表明，无论是LLMs还是VLMs，都存在较高的校准误差，且多数情况下过于自信，这反映出它们在不确定性估计上的能力不足。此外，我们还为回归任务设计了提示，并发现VLMs在生成均值/标准差和95%置信区间时的校准表现不佳。",
    "title_cn": "自信过度，关键所在：探究大型语言及视觉-语言模型中的口头不确定性评估。",
    "tags": [
      "LLM应用",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Exploring the Improvement of Evolutionary Computation via Large Language Models",
    "submit_datetime": "2024年05月05日",
    "abstract": "Evolutionary computation (EC), as a powerful optimization algorithm, has been applied across various domains. However, as the complexity of problems increases, the limitations of EC have become more apparent. The advent of large language models (LLMs) has not only transformed natural language processing but also extended their capabilities to diverse fields. By harnessing LLMs' vast knowledge and adaptive capabilities, we provide a forward-looking overview of potential improvements LLMs can bring to EC, focusing on the algorithms themselves, population design, and additional enhancements. This presents a promising direction for future research at the intersection of LLMs and EC.",
    "pdf_link": "https://arxiv.org/abs/2405.02876",
    "graphs": [],
    "abstract_cn": "进化计算（EC）作为优化算法的佼佼者，已跨界应用于众多领域。但随着问题日益复杂，EC 的局限也日益凸显。大型语言模型（LLMs）的兴起不仅革新了自然语言处理，更将其影响力拓展至广泛学科。利用 LLMs 深厚的知识库和强大的适应性，本文展望了 LLMs 对 EC 可能带来的积极影响，特别关注算法优化、种群构建以及潜在的性能提升。这一视角为 LLMs 与 EC 结合的未来研究开辟了充满希望的新路径。",
    "title_cn": "本文旨在探讨如何利用大型语言模型来提升进化计算的性能。",
    "tags": [
      "分类：LLM应用",
      "优化算法",
      ""
    ]
  },
  {
    "title": "Revisiting a Pain in the Neck: Semantic Phrase Processing Benchmark for Language Models",
    "submit_datetime": "2024年05月05日",
    "abstract": "We introduce LexBench, a comprehensive evaluation suite enabled to test language models (LMs) on ten semantic phrase processing tasks. Unlike prior studies, it is the first work to propose a framework from the comparative perspective to model the general semantic phrase (i.e., lexical collocation) and three fine-grained semantic phrases, including idiomatic expression, noun compound, and verbal construction. Thanks to \\ourbenchmark, we assess the performance of 15 LMs across model architectures and parameter scales in classification, extraction, and interpretation tasks. Through the experiments, we first validate the scaling law and find that, as expected, large models excel better than the smaller ones in most tasks. Second, we investigate further through the scaling semantic relation categorization and find that few-shot LMs still lag behind vanilla fine-tuned models in the task. Third, through human evaluation, we find that the performance of strong models is comparable to the human level regarding semantic phrase processing. Our benchmarking findings can serve future research aiming to improve the generic capability of LMs on semantic phrase comprehension. Our source code and data are available at https://github.com/jacklanda/LexBench",
    "pdf_link": "https://arxiv.org/abs/2405.02861",
    "graphs": [],
    "abstract_cn": "我们推出了 LexBench，一套全面的评估工具，旨在对语言模型（LMs）进行十项语义短语处理任务的测试。与过往研究相比，本工作首次提出一个比较视角下的框架，用于模拟一般语义短语（例如词汇搭配）以及三种更细致的语义短语类型：成语表达、名词复合词和动词结构。借助我们的基准测试，我们对15种不同架构和参数规模的LMs在分类、提取和解释任务中的表现进行了评估。实验首先证实了规模法则，发现大型模型在大多数任务上的表现确实优于小型模型。其次，通过语义关系分类的进一步探索，我们发现少数镜头LMs在任务上仍然未能赶超常规的微调模型。再次，通过人工评估，我们发现顶尖模型在处理语义短语方面的性能已接近人类水平。我们的基准测试结果将为未来旨在提升LMs在语义短语理解上的通用能力的研究提供参考。相关源代码和数据已在 https://github.com/jacklanda/LexBench 上发布。",
    "title_cn": "再次聚焦“颈部之痛”：为语言模型设立的语义短语处理性能评估标准",
    "tags": [
      "LLM应用",
      "",
      "机器学习"
    ]
  },
  {
    "title": "Language Evolution for Evading Social Media Regulation via LLM-based Multi-agent Simulation",
    "submit_datetime": "2024年05月05日",
    "abstract": "Social media platforms such as Twitter, Reddit, and Sina Weibo play a crucial role in global communication but often encounter strict regulations in geopolitically sensitive regions. This situation has prompted users to ingeniously modify their way of communicating, frequently resorting to coded language in these regulated social media environments. This shift in communication is not merely a strategy to counteract regulation, but a vivid manifestation of language evolution, demonstrating how language naturally evolves under societal and technological pressures. Studying the evolution of language in regulated social media contexts is of significant importance for ensuring freedom of speech, optimizing content moderation, and advancing linguistic research. This paper proposes a multi-agent simulation framework using Large Language Models (LLMs) to explore the evolution of user language in regulated social media environments. The framework employs LLM-driven agents: supervisory agent who enforce dialogue supervision and participant agents who evolve their language strategies while engaging in conversation, simulating the evolution of communication styles under strict regulations aimed at evading social media regulation. The study evaluates the framework's effectiveness through a range of scenarios from abstract scenarios to real-world situations. Key findings indicate that LLMs are capable of simulating nuanced language dynamics and interactions in constrained settings, showing improvement in both evading supervision and information accuracy as evolution progresses. Furthermore, it was found that LLM agents adopt different strategies for different scenarios.",
    "pdf_link": "https://arxiv.org/abs/2405.02858",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.02858v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02858/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02858v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02858/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02858v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02858/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02858v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02858/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02858v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02858/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02858v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02858/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02858v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02858/x7.png"
      }
    ],
    "abstract_cn": "像 Twitter、Reddit 和新浪微博这样的社交媒体平台在全球交流中起着关键作用，但在政治敏感地区常面临严格限制。这激发了用户在这些受限的社交媒体环境中采用编码语言进行沟通的创新方式。这种沟通方式的变革不仅是对抗监管的策略，也是语言适应社会和技术压力自然演化的生动例证。深入研究这种受监管环境下语言的演变对于捍卫言论自由、优化内容管理和推动语言学研究极为关键。本文提出了一个基于大型语言模型（LLMs）的多智能体模拟框架，用以探究用户在受监管社交媒体环境中语言策略的演化。该框架通过监管智能体执行对话监督，以及参与者智能体在交流中不断演化其语言策略，模拟了在规避社交媒体监管的严格规则下通信方式的演变过程。通过一系列从抽象到现实的情境，本研究评估了该框架的有效性。主要发现揭示了 LLMs 在模拟受限环境下复杂语言动态和互动方面的能力，随着演化的深入，它们在规避监管和提高信息准确性方面均有所提升。此外，研究还发现，LLM 智能体会根据不同情境采取不同的策略。",
    "title_cn": "本文探讨了如何利用基于大型语言模型（LLM）的多代理模拟技术，实现语言的进化以规避社交媒体的监管机制。",
    "tags": [
      "分类：Agent",
      "社交媒体",
      "语言学"
    ]
  },
  {
    "title": "Trojans in Large Language Models of Code: A Critical Review through a Trigger-Based Taxonomy",
    "submit_datetime": "2024年05月05日",
    "abstract": "Large language models (LLMs) have provided a lot of exciting new capabilities in software development. However, the opaque nature of these models makes them difficult to reason about and inspect. Their opacity gives rise to potential security risks, as adversaries can train and deploy compromised models to disrupt the software development process in the victims' organization.\n  This work presents an overview of the current state-of-the-art trojan attacks on large language models of code, with a focus on triggers -- the main design point of trojans -- with the aid of a novel unifying trigger taxonomy framework. We also aim to provide a uniform definition of the fundamental concepts in the area of trojans in Code LLMs. Finally, we draw implications of findings on how code models learn on trigger design.",
    "pdf_link": "https://arxiv.org/abs/2405.02828",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.02828v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02828/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02828v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02828/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02828v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02828/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02828v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02828/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02828v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02828/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02828v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02828/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02828v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02828/x7.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）为软件开发领域带来了诸多创新能力，但其内在的不透明性却增加了推理和审查的难度，由此引发的安全隐患不容忽视。敌手可能借此训练并部署恶意模型，对软件开发流程造成破坏。本研究综述了针对代码大型语言模型的木马攻击技术，特别关注了木马设计的核心——触发器，并引入了一种新的统一触发器分类框架。此外，我们还旨在为代码LLMs中的木马概念提供一个清晰的定义。最终，我们探讨了代码模型学习触发器设计的影响，为未来的研究和实践提供了指导。",
    "title_cn": "代码大型语言模型中的潜在威胁：基于触发机制的分类法进行的深入剖析。",
    "tags": [
      "LLM应用",
      "软件开发",
      ""
    ]
  },
  {
    "title": "HuixiangDou-CR: Coreference Resolution in Group Chats",
    "submit_datetime": "2024年05月05日",
    "abstract": "How to eliminate pronominal reference in group chats? In this work, we have preprocessed 58k authentic chat data and manually annotated 2.3k questions. The reliability of this annotation was confirmed by the scaling law. After this, we conducted fine-tuning on Qwen models, ranging from 0.5B to 32B parameters. The optimal version improved 29.07 in F1 score. This confirms the viability of fine-tuning Large Language Model (LLM) for downstream Natural Language Processing (NLP) tasks. Our contributions are: 1) Created Supervised Fine-Tuning (SFT) training data in alpaca format, along with a set of Low-Rank Adaptation (LoRA) weights, and 2) Developed a method for acquiring high-quality data leveraging scaling law principle. The script, raw data with alpaca format and experiments track are open-sourced on Github https://github.com/InternLM/HuixiangDou/tree/main/web/tools, HuggingFace https://huggingface.co/tpoisonooo and WandB https://wandb.ai/tpoisonooo/huixiangdou-cr/table?nw=nwusertpoisonooo . The privacy of the data involved has been authorized by users.",
    "pdf_link": "https://arxiv.org/abs/2405.02817",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.02817v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02817/annotation.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02817v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02817/qwen4-loss.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02817v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02817/overall.png"
      }
    ],
    "abstract_cn": "我们如何避免群聊中的代词混淆？本研究中，我们对5.8万条真实对话记录进行了预处理，并精心标注了2300个问题，其准确性得到了扩展法则的验证。随后，我们在参数规模从5亿到320亿的Qwen模型上执行了精细调整，最佳模型在F1分数上实现了29.07%的提升，从而验证了对大型语言模型（LLM）进行微调以适应下游自然语言处理（NLP）任务的高效性。我们的成果包括：1）开发了以羊驼格式的监督式微调（SFT）训练集和一套低秩适应（LoRA）权重；2）设计了一种基于扩展法则原则获取优质数据的方法。相关脚本、原始数据以及实验记录已在Github、HuggingFace和WandB平台开源。用户已授权所涉数据的隐私使用。",
    "title_cn": "HuixiangDou-CR：群组聊天中的同指识别技术",
    "tags": [
      "LLM应用",
      "",
      "对话系统"
    ]
  },
  {
    "title": "NegativePrompt: Leveraging Psychology for Large Language Models Enhancement via Negative Emotional Stimuli",
    "submit_datetime": "2024年05月05日",
    "abstract": "Large Language Models (LLMs) have become integral to a wide spectrum of applications, ranging from traditional computing tasks to advanced artificial intelligence (AI) applications. This widespread adoption has spurred extensive research into LLMs across various disciplines, including the social sciences. Notably, studies have revealed that LLMs possess emotional intelligence, which can be further developed through positive emotional stimuli. This discovery raises an intriguing question: can negative emotions similarly influence LLMs, potentially enhancing their performance? In response to this question, we introduce NegativePrompt, a novel approach underpinned by psychological principles, involving ten specifically designed negative emotional stimuli. We embark on rigorous experimental evaluations of five LLMs including Flan-T5-Large, Vicuna, Llama 2, ChatGPT, and GPT-4, across a set of 45 tasks. The results are revealing: NegativePrompt markedly enhances the performance of LLMs, evidenced by relative improvements of 12.89% in Instruction Induction tasks and 46.25% in BIG-Bench tasks. Moreover, we conduct attention visualization experiments to decipher the underlying mechanisms of NegativePrompt's influence. Our research contributes significantly to the understanding of LLMs and emotion interaction, demonstrating the practical efficacy of NegativePrompt as an emotion-driven method and offering novel insights for the enhancement of LLMs in real-world applications. The code is available at https://github.com/wangxu0820/NegativePrompt.",
    "pdf_link": "https://arxiv.org/abs/2405.02814",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.02814v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02814/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02814v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02814/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02814v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02814/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02814v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02814/x4.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）在从传统计算到高级人工智能应用的广泛应用中扮演着核心角色。这种普及推动了跨学科对LLMs的深入研究，特别是在社会科学领域。研究发现，LLMs具备情感智能，且能通过正面情感刺激得到提升。这引出了一个问题：负面情绪是否也能以类似的方式影响LLMs，进而提升它们的性能？针对这一疑问，我们提出了NegativePrompt，这是一种基于心理学原理的新方法，包含十个精心设计的情感刺激。我们对五个主流的LLMs——Flan-T5-Large、Vicuna、Llama 2、ChatGPT和GPT-4——进行了45项任务的严格实验评估。结果显示，NegativePrompt显著提升了LLMs的性能，特别是在指令归纳任务中提升了12.89%，在BIG-Bench任务中提升了46.25%。此外，我们还进行了注意力可视化实验，以揭示NegativePrompt影响的内在机制。本研究不仅深化了我们对LLMs与情感互动的理解，还证实了NegativePrompt作为一种情感驱动方法的有效性，并为LLMs在现实世界应用中的性能提升提供了新的视角。相关代码可在 https://github.com/wangxu0820/NegativePrompt 查看。",
    "title_cn": "负面提示：运用心理学原理，通过负面情感刺激来提升大型语言模型的性能",
    "tags": [
      "LLM应用",
      "社会科学",
      "人工智能"
    ]
  },
  {
    "title": "Stochastic RAG: End-to-End Retrieval-Augmented Generation through Expected Utility Maximization",
    "submit_datetime": "2024年05月05日",
    "abstract": "This paper introduces Stochastic RAG--a novel approach for end-to-end optimization of retrieval-augmented generation (RAG) models that relaxes the simplifying assumptions of marginalization and document independence, made in most prior work. Stochastic RAG casts the retrieval process in RAG as a stochastic sampling without replacement process. Through this formulation, we employ straight-through Gumbel-top-k that provides a differentiable approximation for sampling without replacement and enables effective end-to-end optimization for RAG. We conduct extensive experiments on seven diverse datasets on a wide range of tasks, from open-domain question answering to fact verification to slot-filling for relation extraction and to dialogue systems. By applying this optimization method to a recent and effective RAG model, we advance state-of-the-art results on six out of seven datasets.",
    "pdf_link": "https://arxiv.org/abs/2405.02816",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.02816v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02816/param_sensitivity.png"
      }
    ],
    "abstract_cn": "本文提出了一种创新的随机 RAG 方法，用于对检索增强生成（RAG）模型进行端到端的优化。这种方法突破了以往研究中对边缘化和文档独立性的假设。随机 RAG 将检索视为一种无放回的随机抽样过程，并通过直通 Gumbel-top-k 技术，为无放回抽样提供了一种可微分的近似方法，从而实现了 RAG 的高效端到端训练。我们在七个多样化的数据集上进行了广泛的实验，覆盖了从开放域问答到事实核查，再到关系抽取的槽位填充，以及对话系统等多个任务。将此优化技术应用于最新的 RAG 模型，我们在七个数据集中的六个上取得了突破性的进步。",
    "title_cn": "随机化 RAG：通过期望效用最大化实现一站式检索增强生成",
    "tags": [
      "RAG",
      "问答系统",
      "对话系统"
    ]
  },
  {
    "title": "ATAT: Astronomical Transformer for time series And Tabular data",
    "submit_datetime": "2024年05月05日",
    "abstract": "The advent of next-generation survey instruments, such as the Vera C. Rubin Observatory and its Legacy Survey of Space and Time (LSST), is opening a window for new research in time-domain astronomy. The Extended LSST Astronomical Time-Series Classification Challenge (ELAsTiCC) was created to test the capacity of brokers to deal with a simulated LSST stream. We describe ATAT, the Astronomical Transformer for time series And Tabular data, a classification model conceived by the ALeRCE alert broker to classify light-curves from next-generation alert streams. ATAT was tested in production during the first round of the ELAsTiCC campaigns. ATAT consists of two Transformer models that encode light curves and features using novel time modulation and quantile feature tokenizer mechanisms, respectively. ATAT was trained on different combinations of light curves, metadata, and features calculated over the light curves. We compare ATAT against the current ALeRCE classifier, a Balanced Hierarchical Random Forest (BHRF) trained on human-engineered features derived from light curves and metadata. When trained on light curves and metadata, ATAT achieves a macro F1-score of 82.9 +- 0.4 in 20 classes, outperforming the BHRF model trained on 429 features, which achieves a macro F1-score of 79.4 +- 0.1. The use of Transformer multimodal architectures, combining light curves and tabular data, opens new possibilities for classifying alerts from a new generation of large etendue telescopes, such as the Vera C. Rubin Observatory, in real-world brokering scenarios.",
    "pdf_link": "https://arxiv.org/abs/2405.03078",
    "graphs": [],
    "abstract_cn": "随着新一代观测设备如薇拉·C·鲁宾天文台及其“空间和时间遗产调查”（LSST）的问世，时域天文学研究迎来了新的机遇。为了检验处理模拟LSST数据流的能力，我们创建了扩展的LSST天文时间序列分类挑战（ELAsTiCC）。本文介绍了由ALERCE警报系统设计的天文变换器（ATAT），这是一种用于时间序列和表格数据的分类模型，专门用于对新一代警报流中的光曲线进行分类。在ELAsTiCC的首轮竞赛中，ATAT在实际生产环境中接受了测试。ATAT由两个变换模型构成，分别采用创新的时间调制和分位数特征标记技术来编码光曲线和特征。该模型在不同的光曲线、元数据以及基于光曲线计算出的特征组合上进行了训练。我们将其与ALERCE现有的平衡层次随机森林（BHRF）分类器进行了对比，后者是基于人工提取的光曲线和元数据特征进行训练的。在光曲线和元数据上训练时，ATAT在20个类别中达到了82.9%的宏观F1分数，超越了基于429个特征训练的BHRF模型的79.4%。采用变换器多模态架构，融合光曲线与表格数据，为新一代大视场望远镜，如薇拉·C·鲁宾天文台，提供了在现实警报处理场景中的分类新方案。",
    "title_cn": "ATAT：一种专为时间序列和表格数据设计的天文变换模型",
    "tags": [
      "分类：Agent\n\n这篇论文摘要描述了一个用于时间序列和表格数据分类的模型，即天文变换器（ATAT），它专门用于对新一代警报流中的光曲线进行分类。这个模型在实际生产环境中进行了测试，并与现有的分类器进行了比较。由于这个模型是一个用于特定任务（天文学数据分类）的智能代理，因此它属于\"Agent\"类别。",
      "天文学",
      "机器学习"
    ]
  },
  {
    "title": "Mozart's Touch: A Lightweight Multi-modal Music Generation Framework Based on Pre-Trained Large Models",
    "submit_datetime": "2024年05月04日",
    "abstract": "In recent years, AI-Generated Content (AIGC) has witnessed rapid advancements, facilitating the generation of music, images, and other forms of artistic expression across various industries. However, researches on general multi-modal music generation model remain scarce. To fill this gap, we propose a multi-modal music generation framework Mozart's Touch. It could generate aligned music with the cross-modality inputs, such as images, videos and text. Mozart's Touch is composed of three main components: Multi-modal Captioning Module, Large Language Model (LLM) Understanding & Bridging Module, and Music Generation Module. Unlike traditional approaches, Mozart's Touch requires no training or fine-tuning pre-trained models, offering efficiency and transparency through clear, interpretable prompts. We also introduce \"LLM-Bridge\" method to resolve the heterogeneous representation problems between descriptive texts of different modalities. We conduct a series of objective and subjective evaluations on the proposed model, and results indicate that our model surpasses the performance of current state-of-the-art models. Our codes and examples is availble at: https://github.com/WangTooNaive/MozartsTouch",
    "pdf_link": "https://arxiv.org/abs/2405.02801",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.02801v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02801/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02801v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02801/x2.png"
      }
    ],
    "abstract_cn": "近年来，AI创造的内容（AIGC）迅猛发展，推动了音乐、图像等艺术形式在不同行业中的创作。尽管如此，对于能够处理多种模态的通用音乐生成模型的研究仍然不多见。为了解决这一问题，我们设计了一个名为“莫扎特之触”的多模态音乐生成框架，它能够根据图像、视频和文本等跨模态输入生成协调的音乐作品。该框架包括三个核心组件：多模态字幕生成模块、大型语言模型（LLM）理解和桥接模块以及音乐生成模块。与常规方法不同，“莫扎特之触”避免了对预训练模型的训练或微调，通过直观且易于解释的提示，实现了高效率和透明度。此外，我们提出了“LLM-桥接”技术，以解决不同模态描述文本的表示不一致问题。通过一系列客观和主观的评估，我们的模型在性能上超越了现有的顶尖模型。相关代码和示例可以在 https://github.com/WangTooNaive/MozartsTouch 找到。",
    "title_cn": "《莫扎特之触》：一款轻量级多模态音乐创作框架，依托于预训练的大型语言模型。",
    "tags": [
      "LLM应用",
      "艺术创作",
      "人工智能"
    ]
  },
  {
    "title": "Octopi: Object Property Reasoning with Large Tactile-Language Models",
    "submit_datetime": "2024年05月04日",
    "abstract": "Physical reasoning is important for effective robot manipulation. Recent work has investigated both vision and language modalities for physical reasoning; vision can reveal information about objects in the environment and language serves as an abstraction and communication medium for additional context. Although these works have demonstrated success on a variety of physical reasoning tasks, they are limited to physical properties that can be inferred from visual or language inputs. In this work, we investigate combining tactile perception with language, which enables embodied systems to obtain physical properties through interaction and apply common-sense reasoning. We contribute a new dataset PhysiCleAR, which comprises both physical/property reasoning tasks and annotated tactile videos obtained using a GelSight tactile sensor. We then introduce Octopi, a system that leverages both tactile representation learning and large vision-language models to predict and reason about tactile inputs with minimal language fine-tuning. Our evaluations on PhysiCleAR show that Octopi is able to effectively use intermediate physical property predictions to improve physical reasoning in both trained tasks and for zero-shot reasoning. PhysiCleAR and Octopi are available on https://github.com/clear-nus/octopi.",
    "pdf_link": "https://arxiv.org/abs/2405.02794",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.02794v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02794/main_figure_2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02794v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02794/pipeline.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02794v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02794/model_diagram.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02794v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02794/food_state_reasoning.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02794v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02794/object_part_reasoning.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02794v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02794/avocado_cropped.png"
      }
    ],
    "abstract_cn": "物理推理乃机器人精准操作之关键。最新研究通过视觉与语言双重模态探究物理推理，视觉捕捉环境物体细节，语言则架起抽象与沟通的桥梁。尽管这些成果在多样化的物理推理挑战中成绩斐然，但仅限于通过视觉或语言信息可推知的物理特性。本研究创新性地融合触觉感知与语言，赋予具身系统以交互方式捕捉物理属性并运用常识进行推理的能力。我们推出了PhysiCleAR数据集，内含物理属性推理任务及GelSight触觉传感器采集的触觉视频。此外，我们开发了Octopi系统，该系统结合触觉表征学习与先进的视觉-语言模型，以最小化语言微调来预测和推理触觉信息。PhysiCleAR的测试结果证明，Octopi能够利用中间物理属性预测显著提升物理推理的效能，无论是在训练有素的任务还是零样本推理中。PhysiCleAR和Octopi项目已在https://github.com/clear-nus/octopi上线。",
    "title_cn": "Octopi：通过大型触觉-语言模型进行物体属性推理",
    "tags": [
      "Agent",
      "机器人技术",
      "人工智能"
    ]
  },
  {
    "title": "Confidential and Protected Disease Classifier using Fully Homomorphic Encryption",
    "submit_datetime": "2024年05月04日",
    "abstract": "With the rapid surge in the prevalence of Large Language Models (LLMs), individuals are increasingly turning to conversational AI for initial insights across various domains, including health-related inquiries such as disease diagnosis. Many users seek potential causes on platforms like ChatGPT or Bard before consulting a medical professional for their ailment. These platforms offer valuable benefits by streamlining the diagnosis process, alleviating the significant workload of healthcare practitioners, and saving users both time and money by avoiding unnecessary doctor visits. However, Despite the convenience of such platforms, sharing personal medical data online poses risks, including the presence of malicious platforms or potential eavesdropping by attackers. To address privacy concerns, we propose a novel framework combining FHE and Deep Learning for a secure and private diagnosis system. Operating on a question-and-answer-based model akin to an interaction with a medical practitioner, this end-to-end secure system employs Fully Homomorphic Encryption (FHE) to handle encrypted input data. Given FHE's computational constraints, we adapt deep neural networks and activation functions to the encryted domain. Further, we also propose a faster algorithm to compute summation of ciphertext elements. Through rigorous experiments, we demonstrate the efficacy of our approach. The proposed framework achieves strict security and privacy with minimal loss in performance.",
    "pdf_link": "https://arxiv.org/abs/2405.02790",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.02790v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02790/Threat_Secure.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.02790v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02790/FullyConnected_Updated_1.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.02790v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02790/Architecture_Updated_2.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.02790v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02790/poly_reg.jpg"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）的广泛应用，使得人们开始依赖会话式AI来获取多领域的初步信息，包括健康咨询和疾病诊断。用户倾向于在咨询医生前，先在ChatGPT或Bard等平台上探索可能的病因。这些平台通过简化诊断流程，减轻医疗工作者的工作负担，并节省用户的时间与金钱，提供了显著的优势。然而，在线分享个人医疗信息也带来了风险，如遭遇恶意平台或攻击者的监听。为保护用户隐私，我们提出了一个创新框架，将全同态加密（FHE）与深度学习相结合，打造一个安全私密的诊断系统。该系统模拟与医生的问答互动，采用FHE技术处理加密数据输入。针对FHE的计算限制，我们对深度神经网络和激活函数进行了适配，并开发了一种更快速的算法来计算密文元素的总和。经过一系列严格的实验，我们证实了该方法的有效性，确保了在几乎不损失性能的前提下，实现了高标准的安全性和隐私保护。",
    "title_cn": "采用全同态加密技术，打造安全可靠的疾病分类系统。",
    "tags": [
      "LLM应用",
      "",
      "数据安全"
    ]
  },
  {
    "title": "A self-supervised text-vision framework for automated brain abnormality detection",
    "submit_datetime": "2024年05月04日",
    "abstract": "Artificial neural networks trained on large, expert-labelled datasets are considered state-of-the-art for a range of medical image recognition tasks. However, categorically labelled datasets are time-consuming to generate and constrain classification to a pre-defined, fixed set of classes. For neuroradiological applications in particular, this represents a barrier to clinical adoption. To address these challenges, we present a self-supervised text-vision framework that learns to detect clinically relevant abnormalities in brain MRI scans by directly leveraging the rich information contained in accompanying free-text neuroradiology reports. Our training approach consisted of two-steps. First, a dedicated neuroradiological language model - NeuroBERT - was trained to generate fixed-dimensional vector representations of neuroradiology reports (N = 50,523) via domain-specific self-supervised learning tasks. Next, convolutional neural networks (one per MRI sequence) learnt to map individual brain scans to their corresponding text vector representations by optimising a mean square error loss. Once trained, our text-vision framework can be used to detect abnormalities in unreported brain MRI examinations by scoring scans against suitable query sentences (e.g., 'there is an acute stroke', 'there is hydrocephalus' etc.), enabling a range of classification-based applications including automated triage. Potentially, our framework could also serve as a clinical decision support tool, not only by suggesting findings to radiologists and detecting errors in provisional reports, but also by retrieving and displaying examples of pathologies from historical examinations that could be relevant to the current case based on textual descriptors.",
    "pdf_link": "https://arxiv.org/abs/2405.02782",
    "graphs": [],
    "abstract_cn": "利用大规模专家标注数据集训练的人工神经网络，在多种医学图像识别任务中堪称行业标杆。但这种按类别标注的数据集不仅制备费时，还局限于一组预设的固定类别，尤其在神经放射学领域，这成为了临床应用的一大阻碍。为解决这些问题，我们提出了一种自监督的文本-视觉框架，该框架能够通过直接利用随附的自由文本神经放射学报告中的丰富信息，学习在脑部MRI扫描中识别具有临床意义的异常。我们的训练过程分为两步：首先，一个专为神经放射学设计的语言模型——NeuroBERT，通过特定领域的自监督学习任务，被训练用来生成神经放射学报告的固定维度向量表示（共50,523份）。然后，卷积神经网络（每种MRI序列一个）通过最小化均方误差损失，学习将单个大脑扫描映射到相应的文本向量表示。训练完成后，该文本-视觉框架能够通过与适当的查询句子（如“存在急性中风”、“存在脑积水”等）进行评分，来检测未报告的大脑MRI检查中的异常，从而支持一系列基于分类的应用，包括自动分诊。此外，该框架还有潜力作为临床决策支持工具，它不仅能向放射科医生提出发现、检测初步报告中的错误，还能根据文本描述检索并展示与当前病例相关的历史上的病理学案例。",
    "title_cn": "本研究提出了一种自监督的文本-视觉框架，旨在自动化地检测大脑异常。",
    "tags": [
      "分类：LLM应用\n\n这篇论文提出了一种自监督的文本-视觉框架，通过利用神经放射学报告中的自由文本信息，学习在脑部MRI扫描中识别具有临床意义的异常。这个框架使用了专为神经放射学设计的语言模型NeuroBERT，这是一个大型语言模型（LLM）的应用实例。因此，这篇论文应该被归类为LLM应用。",
      "医学图像识别",
      ""
    ]
  },
  {
    "title": "Improve Temporal Awareness of LLMs for Sequential Recommendation",
    "submit_datetime": "2024年05月04日",
    "abstract": "Large language models (LLMs) have demonstrated impressive zero-shot abilities in solving a wide range of general-purpose tasks. However, it is empirically found that LLMs fall short in recognizing and utilizing temporal information, rendering poor performance in tasks that require an understanding of sequential data, such as sequential recommendation. In this paper, we aim to improve temporal awareness of LLMs by designing a principled prompting framework inspired by human cognitive processes. Specifically, we propose three prompting strategies to exploit temporal information within historical interactions for LLM-based sequential recommendation. Besides, we emulate divergent thinking by aggregating LLM ranking results derived from these strategies. Evaluations on MovieLens-1M and Amazon Review datasets indicate that our proposed method significantly enhances the zero-shot capabilities of LLMs in sequential recommendation tasks.",
    "pdf_link": "https://arxiv.org/abs/2405.02778",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.02778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02778/paper_motivation_2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02778/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02778/history_ml.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02778v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02778/fcl_demos.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）在处理多种通用任务时展现出了卓越的零样本能力。但研究发现，它们在识别和使用时间信息方面存在缺陷，这使得在处理如序列推荐等需要理解序列数据的任务时表现不尽人意。本文提出了一种基于人类认知过程启发的原则性提示框架，以增强 LLMs 对时间信息的敏感度。具体而言，我们设计了三种提示策略，旨在挖掘历史交互中的时间信息，以提升基于 LLM 的序列推荐效果。同时，我们通过整合不同策略产生的 LLM 排名结果，模拟了发散性思维。在 MovieLens-1M 和 Amazon Review 数据集上的测试结果表明，我们的方法显著提升了 LLMs 在序列推荐任务中的零样本性能。",
    "title_cn": "提升大型语言模型在序列推荐任务中的时间意识。",
    "tags": [
      "LLM应用",
      "序列推荐",
      "人工智能"
    ]
  },
  {
    "title": "Assessing Adversarial Robustness of Large Language Models: An Empirical Study",
    "submit_datetime": "2024年05月04日",
    "abstract": "Large Language Models (LLMs) have revolutionized natural language processing, but their robustness against adversarial attacks remains a critical concern. We presents a novel white-box style attack approach that exposes vulnerabilities in leading open-source LLMs, including Llama, OPT, and T5. We assess the impact of model size, structure, and fine-tuning strategies on their resistance to adversarial perturbations. Our comprehensive evaluation across five diverse text classification tasks establishes a new benchmark for LLM robustness. The findings of this study have far-reaching implications for the reliable deployment of LLMs in real-world applications and contribute to the advancement of trustworthy AI systems.",
    "pdf_link": "https://arxiv.org/abs/2405.02764",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.02764v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02764/x1.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）引领了自然语言处理的革新，但其在对抗性攻击面前的坚固性仍是一个亟待解决的问题。本研究提出了一种创新的白盒攻击策略，揭露了包括Llama、OPT和T5在内的主流开源LLMs的脆弱之处。通过考察模型大小、结构和微调技术对其抵御对抗性扰动的能力的影响，我们进行了深入分析。此外，我们在五项多样化的文本分类任务上进行了全面的评估，为LLM的鲁棒性设立了新的行业标准。本研究的洞察为LLM在现实世界中安全、可靠的应用提供了宝贵的参考，同时也为构建值得信赖的人工智能系统贡献了力量。",
    "title_cn": "探究大型语言模型的对抗性防御能力：实证分析。",
    "tags": [
      "LLM应用",
      "",
      "人工智能安全"
    ]
  },
  {
    "title": "Can Nuanced Language Lead to More Actionable Insights? Exploring the Role of Generative AI in Analytical Narrative Structure",
    "submit_datetime": "2024年05月04日",
    "abstract": "Relevant language describing trends in data can be useful for generating summaries to help with readers' takeaways. However, the language employed in these often template-generated summaries tends to be simple, ranging from describing simple statistical information (e.g., extrema and trends) without additional context and richer language to provide actionable insights. Recent advances in Large Language Models (LLMs) have shown promising capabilities in capturing subtle nuances in language when describing information. This workshop paper specifically explores how LLMs can provide more actionable insights when describing trends by focusing on three dimensions of analytical narrative structure: semantic, rhetorical, and pragmatic. Building on prior research that examines visual and linguistic signatures for univariate line charts, we examine how LLMs can further leverage the semantic dimension of analytical narratives using quantified semantics to describe shapes in trends as people intuitively view them. These semantic descriptions help convey insights in a way that leads to a pragmatic outcome, i.e., a call to action, persuasion, warning vs. alert, and situational awareness. Finally, we identify rhetorical implications for how well these generated narratives align with the perceived shape of the data, thereby empowering users to make informed decisions and take meaningful actions based on these data insights.",
    "pdf_link": "https://arxiv.org/abs/2405.02763",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.02763v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02763/teaser_1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02763v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02763/teaser_2.png"
      }
    ],
    "abstract_cn": "精准描述数据趋势的语言对于制作有助于读者把握要点的摘要至关重要。然而，这些通常由模板生成的摘要语言过于基础，往往只涉及简单的统计信息（如极值和趋势），缺乏深入的上下文和丰富的表达来提供实用的洞察。近期在大型语言模型（LLMs）的研究中，已经展现出在描述信息时捕捉语言细微差别的潜力。本文聚焦于探讨LLMs如何在描述趋势时，通过分析叙述的三个关键维度——语义、修辞和语用——来提供更具操作性的见解。在之前研究的基础上，我们进一步分析了LLMs如何利用量化语义来丰富分析叙述的语义层面，以直观的方式描述趋势的形状。这些语义描述有助于以一种引导实用结果的方式传达洞察，例如行动号召、说服、预警和情境感知。最终，我们探讨了这些生成的叙述与数据感知形状的契合度对修辞效果的影响，使用户能够基于这些数据洞察做出明智的决策并采取有效的行动。",
    "title_cn": "能否通过微妙的语言获得更可行的洞察？本文深入探讨了生成性人工智能在构建分析性叙述结构中的关键角色。",
    "tags": [
      "LLM应用",
      "数据分析",
      ""
    ]
  },
  {
    "title": "Enhancing Contextual Understanding in Large Language Models through Contrastive Decoding",
    "submit_datetime": "2024年05月04日",
    "abstract": "Large language models (LLMs) tend to inadequately integrate input context during text generation, relying excessively on encoded prior knowledge in model parameters, potentially resulting in generated text with factual inconsistencies or contextually unfaithful content. LLMs utilize two primary knowledge sources: 1) prior (parametric) knowledge from pretraining, and 2) contextual (non-parametric) knowledge from input prompts. The study addresses the open question of how LLMs effectively balance these knowledge sources during the generation process, specifically in the context of open-domain question answering. To address this issue, we introduce a novel approach integrating contrastive decoding with adversarial irrelevant passages as negative samples to enhance robust context grounding during generation. Notably, our method operates at inference time without requiring further training. We conduct comprehensive experiments to demonstrate its applicability and effectiveness, providing empirical evidence showcasing its superiority over existing methodologies. Our code is publicly available at: https://github.com/amazon-science/ContextualUnderstanding-ContrastiveDecoding.",
    "pdf_link": "https://arxiv.org/abs/2405.02750",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.02750v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02750/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02750v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02750/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02750v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02750/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02750v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02750/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02750v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02750/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02750v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02750/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02750v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02750/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02750v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02750/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02750v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02750/x9.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）在文本生成时常常忽视了输入上下文的整合，过分依赖于模型参数中预设的知识，这可能导致生成的文本出现事实性错误或与上下文不匹配的问题。LLMs 主要依赖两种知识来源：一是预训练阶段获得的参数化先验知识；二是输入提示中的非参数化上下文知识。本研究旨在探索 LLMs 如何在生成过程中有效融合这两种知识来源，尤其是在开放域问答领域。为此，我们提出了一种创新方法，通过结合对比解码和引入对抗性无关段落作为负样本，以增强生成时的上下文锚定。特别指出，该方法在推理阶段即可运行，无需额外训练。我们通过一系列全面的实验验证了该方法的可行性和有效性，并与现有技术相比，展示了其明显的优越性。相关代码已在 https://github.com/amazon-science/ContextualUnderstanding-ContrastiveDecoding 上公开发布。",
    "title_cn": "通过对比解码技术，提升大型语言模型对上下文的理解能力。",
    "tags": [
      "LLM应用",
      "文本生成",
      "开放域问答"
    ]
  },
  {
    "title": "Sub-goal Distillation: A Method to Improve Small Language Agents",
    "submit_datetime": "2024年05月04日",
    "abstract": "While Large Language Models (LLMs) have demonstrated significant promise as agents in interactive tasks, their substantial computational requirements and restricted number of calls constrain their practical utility, especially in long-horizon interactive tasks such as decision-making or in scenarios involving continuous ongoing tasks. To address these constraints, we propose a method for transferring the performance of an LLM with billions of parameters to a much smaller language model (770M parameters). Our approach involves constructing a hierarchical agent comprising a planning module, which learns through Knowledge Distillation from an LLM to generate sub-goals, and an execution module, which learns to accomplish these sub-goals using elementary actions. In detail, we leverage an LLM to annotate an oracle path with a sequence of sub-goals towards completing a goal. Subsequently, we utilize this annotated data to fine-tune both the planning and execution modules. Importantly, neither module relies on real-time access to an LLM during inference, significantly reducing the overall cost associated with LLM interactions to a fixed cost. In ScienceWorld, a challenging and multi-task interactive text environment, our method surpasses standard imitation learning based solely on elementary actions by 16.7% (absolute). Our analysis highlights the efficiency of our approach compared to other LLM-based methods. Our code and annotated data for distillation can be found on GitHub.",
    "pdf_link": "https://arxiv.org/abs/2405.02749",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）在交互任务中展现出巨大潜力，但其高昂的计算成本和有限的调用次数限制了它们在长期交互任务如决策制定或持续任务场景中的应用。为此，我们提出了一种将数十亿参数的LLM性能迁移至小型语言模型（7.7亿参数）的方法。该方法通过构建一个包含规划和执行两个模块的分层代理：规划模块通过知识蒸馏从LLM学习生成子目标，执行模块则学习如何通过基本动作实现这些子目标。我们首先使用LLM为完成目标的路径标注一系列子目标，然后利用这些标注数据对两个模块进行微调。关键的是，推理过程中两个模块均无需实时访问LLM，从而大幅降低了与LLM交互的总体成本。在复杂的多任务交互文本环境ScienceWorld中，我们的方法在效率上比基于基本动作的标准模仿学习高出16.7%。我们的分析显示了该方法相比其他基于LLM的方法的优越性。相关代码和用于蒸馏的标注数据已发布在GitHub上。",
    "title_cn": "子目标蒸馏：提升小型语言代理效能的新方法",
    "tags": [
      "Agent",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Beyond Performance: Quantifying and Mitigating Label Bias in LLMs",
    "submit_datetime": "2024年05月04日",
    "abstract": "Large language models (LLMs) have shown remarkable adaptability to diverse tasks, by leveraging context prompts containing instructions, or minimal input-output examples. However, recent work revealed they also exhibit label bias -- an undesirable preference toward predicting certain answers over others. Still, detecting and measuring this bias reliably and at scale has remained relatively unexplored. In this study, we evaluate different approaches to quantifying label bias in a model's predictions, conducting a comprehensive investigation across 279 classification tasks and ten LLMs. Our investigation reveals substantial label bias in models both before and after debiasing attempts, as well as highlights the importance of outcomes-based evaluation metrics, which were not previously used in this regard. We further propose a novel label bias calibration method tailored for few-shot prompting, which outperforms recent calibration approaches for both improving performance and mitigating label bias. Our results emphasize that label bias in the predictions of LLMs remains a barrier to their reliability.",
    "pdf_link": "https://arxiv.org/abs/2405.02743",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.02743v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02743/fig1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02743v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02743/Llama2_macro_f1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02743v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02743/Llama2_rsd.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02743v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02743/Llama2_simple_estimate.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02743v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02743/Llama2-7B_macro_f1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02743v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02743/Llama2-7B_rsd.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02743v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02743/Llama2-7B_bias_score.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02743v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02743/Llama2-13B_macro_f1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02743v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02743/Llama2-13B_rsd.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02743v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02743/Llama2-13B_bias_score.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02743v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02743/Llama2_bias_score.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02743v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02743/Llama2_rsd.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02743v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02743/All_rsd.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02743v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02743/All_bias_score.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02743v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02743/All_macro_f1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02743v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02743/Mistral_bias_score.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02743v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02743/Mistral_rsd.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02743v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02743/Falcon_bias_score.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02743v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02743/Falcon_rsd.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02743v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02743/Mistral_macro_f1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02743v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02743/Mistral_rsd.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02743v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02743/Mistral_simple_estimate.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02743v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02743/Falcon_macro_f1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02743v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02743/Falcon_rsd.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02743v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02743/Falcon_simple_estimate.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02743v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02743/Mistral-7B_macro_f1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02743v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02743/Mistral-7B_rsd.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02743v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02743/Mistral-7B_bias_score.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02743v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02743/Falcon-7B_macro_f1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02743v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02743/Falcon-7B_rsd.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02743v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02743/Falcon-7B_bias_score.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02743v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02743/Falcon-40B_macro_f1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02743v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02743/Falcon-40B_rsd.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02743v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02743/Falcon-40B_bias_score.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）展现出了对多种任务的卓越适应能力，这得益于它们能够利用包含指令或最少输入输出示例的上下文提示。然而，最新研究指出，这些模型同样存在标签偏见问题——即对某些答案的非理性偏好。尽管如此，如何在大规模范围内可靠地检测和衡量这种偏见，仍然是一个较少被触及的领域。本研究评估了多种量化模型预测中标签偏见的方法，并在279个分类任务和十种LLMs上进行了深入调查。研究发现，无论是在尝试去偏见之前还是之后，模型中都存在显著的标签偏见，并突显了结果导向评估指标的重要性，这在以往的研究中并未被广泛采用。此外，我们提出了一种新颖的标签偏见校准方法，专为少量样本提示设计，它在提升性能和降低标签偏见方面超越了现有的校准技术。研究结果强调，LLMs预测中的标签偏见问题仍然是其可靠性的一个重大障碍。",
    "title_cn": "超越单纯的性能指标，本文致力于量化并缓解大型语言模型（LLM）中的标签偏见问题。",
    "tags": [
      "LLM应用",
      "人工智能",
      "机器学习"
    ]
  },
  {
    "title": "Relations Prediction for Knowledge Graph Completion using Large Language Models",
    "submit_datetime": "2024年05月04日",
    "abstract": "Knowledge Graphs have been widely used to represent facts in a structured format. Due to their large scale applications, knowledge graphs suffer from being incomplete. The relation prediction task obtains knowledge graph completion by assigning one or more possible relations to each pair of nodes. In this work, we make use of the knowledge graph node names to fine-tune a large language model for the relation prediction task. By utilizing the node names only we enable our model to operate sufficiently in the inductive settings. Our experiments show that we accomplish new scores on a widely used knowledge graph benchmark.",
    "pdf_link": "https://arxiv.org/abs/2405.02738",
    "graphs": [],
    "abstract_cn": "知识图谱作为一种结构化表示事实的工具，已被广泛应用于多个领域。然而，大规模应用的知识图谱往往存在信息不完整的问题。为了补全知识图谱，关系预测任务需要为节点对分配可能的关系。本研究中，我们通过知识图谱的节点名称来优化大型语言模型，以提高关系预测的准确性。我们的方法仅依赖于节点名称，使得模型在归纳推理场景下也能表现出色。实验结果表明，我们的方法在一项广泛认可的知识图谱基准测试中刷新了评分记录。",
    "title_cn": "本研究探讨了如何利用大型语言模型来预测知识图谱补全中的关系。",
    "tags": [
      "分类：LLM应用",
      "知识图谱",
      "关系预测"
    ]
  },
  {
    "title": "Recall Them All: Retrieval-Augmented Language Models for Long Object List Extraction from Long Documents",
    "submit_datetime": "2024年05月04日",
    "abstract": "Methods for relation extraction from text mostly focus on high precision, at the cost of limited recall. High recall is crucial, though, to populate long lists of object entities that stand in a specific relation with a given subject. Cues for relevant objects can be spread across many passages in long texts. This poses the challenge of extracting long lists from long texts. We present the L3X method which tackles the problem in two stages: (1) recall-oriented generation using a large language model (LLM) with judicious techniques for retrieval augmentation, and (2) precision-oriented scrutinization to validate or prune candidates. Our L3X method outperforms LLM-only generations by a substantial margin.",
    "pdf_link": "https://arxiv.org/abs/2405.02732",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.02732v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02732/intro.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02732v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02732/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02732v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02732/x2.png"
      }
    ],
    "abstract_cn": "文本中的关系提取方法通常追求高精准度，却牺牲了召回率。但要构建与特定主题相关联的长对象实体列表，高召回率是不可或缺的。在长篇文本中，相关对象的提示可能分散于多个段落。这挑战了我们如何从长篇文本中抽取出长列表的能力。我们提出了L3X方法，它通过两个阶段来应对这一问题：首先，利用大型语言模型（LLM）进行以召回率为主导的生成，并巧妙地增强检索技术；其次，进行以精确度为主导的审查，以确认或筛选候选对象。我们的L3X方法在性能上显著超越了仅依赖LLM的生成方法。",
    "title_cn": "全面召回：增强检索的语言模型，专为从长篇文档中抽取长列表对象而设计。",
    "tags": [
      "LLM应用",
      "文本分析",
      "信息检索"
    ]
  },
  {
    "title": "R4: Reinforced Retriever-Reorder-Responder for Retrieval-Augmented Large Language Models",
    "submit_datetime": "2024年05月04日",
    "abstract": "Retrieval-augmented large language models (LLMs) leverage relevant content retrieved by information retrieval systems to generate correct responses, aiming to alleviate the hallucination problem. However, existing retriever-responder methods typically append relevant documents to the prompt of LLMs to perform text generation tasks without considering the interaction of fine-grained structural semantics between the retrieved documents and the LLMs. This issue is particularly important for accurate response generation as LLMs tend to ``lose in the middle'' when dealing with input prompts augmented with lengthy documents. In this work, we propose a new pipeline named ``Reinforced Retriever-Reorder-Responder'' (R$^4$) to learn document orderings for retrieval-augmented LLMs, thereby further enhancing their generation abilities while the large numbers of parameters of LLMs remain frozen. The reordering learning process is divided into two steps according to the quality of the generated responses: document order adjustment and document representation enhancement. Specifically, document order adjustment aims to organize retrieved document orderings into beginning, middle, and end positions based on graph attention learning, which maximizes the reinforced reward of response quality. Document representation enhancement further refines the representations of retrieved documents for responses of poor quality via document-level gradient adversarial learning. Extensive experiments demonstrate that our proposed pipeline achieves better factual question-answering performance on knowledge-intensive tasks compared to strong baselines across various public datasets. The source codes and trained models will be released upon paper acceptance.",
    "pdf_link": "https://arxiv.org/abs/2405.02659",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.02659v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02659/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02659v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02659/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02659v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02659/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02659v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02659/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02659v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02659/x5.png"
      }
    ],
    "abstract_cn": "检索增强的大型语言模型（LLMs）通过利用信息检索系统获取的相关内容来生成准确回应，以解决幻觉问题。但现有方法在执行文本生成任务时，往往简单地将相关文档附加到LLMs的提示中，忽略了检索文档与LLMs之间细微语义结构的相互作用。尤其是在处理附加了长篇文档的输入提示时，LLMs常常会在生成过程中“中断思路”。为了解决这一问题，本研究提出了一种新的工作流程——“加强检索器-重排序-响应器”（R^4），旨在为检索增强的LLMs学习文档排序，提升其生成能力而不改变其庞大参数集。该学习过程分为两个阶段：文档顺序调整和文档表示增强。文档顺序调整通过图注意力学习，根据响应质量的加强奖励，将检索文档排序优化为开始、中间和结束的不同位置。而文档表示增强则通过文档级梯度对抗学习，针对质量较差的响应进一步细化检索文档的表示。大量实验证明，我们的流程在知识密集型任务上的事实问题回答性能优于多个强基线。相关源代码和训练模型将在论文发表后公开。",
    "title_cn": "R4：强化版检索-重排-响应机制，专为检索增强型大型语言模型设计。",
    "tags": [
      "LLM应用",
      "信息检索",
      ""
    ]
  },
  {
    "title": "PropertyGPT: LLM-driven Formal Verification of Smart Contracts through Retrieval-Augmented Property Generation",
    "submit_datetime": "2024年05月04日",
    "abstract": "With recent advances in large language models (LLMs), this paper explores the potential of leveraging state-of-the-art LLMs, such as GPT-4, to transfer existing human-written properties (e.g., those from Certora auditing reports) and automatically generate customized properties for unknown code. To this end, we embed existing properties into a vector database and retrieve a reference property for LLM-based in-context learning to generate a new prop- erty for a given code. While this basic process is relatively straight- forward, ensuring that the generated properties are (i) compilable, (ii) appropriate, and (iii) runtime-verifiable presents challenges. To address (i), we use the compilation and static analysis feedback as an external oracle to guide LLMs in iteratively revising the generated properties. For (ii), we consider multiple dimensions of similarity to rank the properties and employ a weighted algorithm to identify the top-K properties as the final result. For (iii), we design a dedicated prover to formally verify the correctness of the generated prop- erties. We have implemented these strategies into a novel system called PropertyGPT, with 623 human-written properties collected from 23 Certora projects. Our experiments show that PropertyGPT can generate comprehensive and high-quality properties, achieving an 80% recall compared to the ground truth. It successfully detected 26 CVEs/attack incidents out of 37 tested and also uncovered 12 zero-day vulnerabilities, resulting in $8,256 bug bounty rewards.",
    "pdf_link": "https://arxiv.org/abs/2405.02580",
    "graphs": [],
    "abstract_cn": "本文着眼于大型语言模型（LLMs）的最新发展，研究了如何利用尖端的LLMs，如GPT-4，来转化现有的人工编写属性（例如Certora审计报告中的属性），并为未知代码自动创建定制属性。我们通过将现有属性嵌入向量数据库并检索参考属性，利用基于LLM的in-context learning来生成新属性。尽管这一基本流程较为简单，但要确保生成的属性不仅（i）可编译，（ii）恰当，且（iii）能在运行时验证，却面临诸多挑战。为此，我们利用编译和静态分析反馈作为外部参考，指导LLMs逐步改进属性生成。在评估属性的恰当性时，我们从多个相似性维度进行排名，并采用加权算法筛选出前K个属性作为最终输出。至于属性的可验证性，我们专门设计了一个证明器来形式化验证属性的正确性。我们将这些方法集成到一个创新的系统中，名为PropertyGPT，该系统收录了来自23个Certora项目的623个人工编写的属性。实验结果表明，PropertyGPT能够产生全面且高品质的属性，其召回率达到了80%。此外，PropertyGPT成功识别了37个测试中的26个CVE/攻击事件，并揭露了12个零日漏洞，赢得了总计8256美元的漏洞赏金。",
    "title_cn": "PropertyGPT，一种利用大型语言模型（LLM）进行智能合约形式化验证的创新方法，通过增强检索的属性生成技术，为智能合约的安全性分析提供了新的视角。",
    "tags": [
      "LLM应用",
      "软件工程",
      ""
    ]
  },
  {
    "title": "TREC iKAT 2023: A Test Collection for Evaluating Conversational and Interactive Knowledge Assistants",
    "submit_datetime": "2024年05月04日",
    "abstract": "Conversational information seeking has evolved rapidly in the last few years with the development of Large Language Models (LLMs), providing the basis for interpreting and responding in a naturalistic manner to user requests. The extended TREC Interactive Knowledge Assistance Track (iKAT) collection aims to enable researchers to test and evaluate their Conversational Search Agents (CSA). The collection contains a set of 36 personalized dialogues over 20 different topics each coupled with a Personal Text Knowledge Base (PTKB) that defines the bespoke user personas. A total of 344 turns with approximately 26,000 passages are provided as assessments on relevance, as well as additional assessments on generated responses over four key dimensions: relevance, completeness, groundedness, and naturalness. The collection challenges CSA to efficiently navigate diverse personal contexts, elicit pertinent persona information, and employ context for relevant conversations. The integration of a PTKB and the emphasis on decisional search tasks contribute to the uniqueness of this test collection, making it an essential benchmark for advancing research in conversational and interactive knowledge assistants.",
    "pdf_link": "https://arxiv.org/abs/2405.02637",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.02637v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02637/milk.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02637v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02637/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02637v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02637/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02637v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02637/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02637v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02637/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02637v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02637/x5.png"
      }
    ],
    "abstract_cn": "近年来，随着大型语言模型（LLMs）的兴起，会话信息检索领域迅速进步，使得对用户请求的理解和回应更加贴近自然交流。TREC交互式知识辅助赛道（iKAT）的扩展版旨在为研究人员提供一个平台，用以测试和评估他们的会话搜索代理（CSA）。该数据集包含36段个性化对话，覆盖20个不同主题，每个主题都配备了定义个性化用户角色的个人文本知识库（PTKB）。总共提供了344个对话轮次，约26,000个段落，用以评估信息的相关性，以及对生成回应的四个关键维度进行额外评估：相关性、完整性、依据性和自然性。这一数据集要求CSA能够高效地处理多样化的个人情境，挖掘关键的人物信息，并利用这些信息进行恰当的对话。个人文本知识库的融合以及对决策性搜索任务的重视，使得这一测试集合具有独特性，对于推动会话式和交互式知识辅助领域的研究具有重要意义。",
    "title_cn": "TREC iKAT 2023：评估对话式和互动式知识助手性能的测试集",
    "tags": [
      "Agent",
      "信息检索",
      "对话系统"
    ]
  },
  {
    "title": "Structural Pruning of Pre-trained Language Models via Neural Architecture Search",
    "submit_datetime": "2024年05月03日",
    "abstract": "Pre-trained language models (PLM), for example BERT or RoBERTa, mark the state-of-the-art for natural language understanding task when fine-tuned on labeled data. However, their large size poses challenges in deploying them for inference in real-world applications, due to significant GPU memory requirements and high inference latency. This paper explores neural architecture search (NAS) for structural pruning to find sub-parts of the fine-tuned network that optimally trade-off efficiency, for example in terms of model size or latency, and generalization performance. We also show how we can utilize more recently developed two-stage weight-sharing NAS approaches in this setting to accelerate the search process. Unlike traditional pruning methods with fixed thresholds, we propose to adopt a multi-objective approach that identifies the Pareto optimal set of sub-networks, allowing for a more flexible and automated compression process.",
    "pdf_link": "https://arxiv.org/abs/2405.02267",
    "graphs": [],
    "abstract_cn": "以 BERT 和 RoBERTa 为代表的预训练语言模型（PLM）在经过标记数据微调后，成为自然语言理解任务的行业标杆。但这些模型的庞大体量对于实际应用中的推理部署构成了挑战，主要体现在对 GPU 内存的巨大需求和较长的推理延迟。本研究通过神经架构搜索（NAS）进行结构性剪枝，旨在寻找在模型大小、延迟和泛化性能之间取得最佳平衡的网络子部分。此外，我们还展示了如何应用最新发展的两阶段权重共享 NAS 方法来加快搜索进程。与传统的固定阈值剪枝法不同，本研究提出了一种多目标优化策略，以识别出帕累托最优的子网络集合，从而实现更加灵活和自动化的模型压缩过程。",
    "title_cn": "利用神经架构搜索技术对预训练的语言模型进行结构化精简。",
    "tags": [
      "LLM应用",
      "",
      "模型优化"
    ]
  },
  {
    "title": "On the test-time zero-shot generalization of vision-language models: Do we really need prompt learning?",
    "submit_datetime": "2024年05月03日",
    "abstract": "The development of large vision-language models, notably CLIP, has catalyzed research into effective adaptation techniques, with a particular focus on soft prompt tuning. Conjointly, test-time augmentation, which utilizes multiple augmented views of a single image to enhance zero-shot generalization, is emerging as a significant area of interest. This has predominantly directed research efforts toward test-time prompt tuning. In contrast, we introduce a robust MeanShift for Test-time Augmentation (MTA), which surpasses prompt-based methods without requiring this intensive training procedure. This positions MTA as an ideal solution for both standalone and API-based applications. Additionally, our method does not rely on ad hoc rules (e.g., confidence threshold) used in some previous test-time augmentation techniques to filter the augmented views. Instead, MTA incorporates a quality assessment variable for each view directly into its optimization process, termed as the inlierness score. This score is jointly optimized with a density mode seeking process, leading to an efficient training- and hyperparameter-free approach. We extensively benchmark our method on 15 datasets and demonstrate MTA's superiority and computational efficiency. Deployed easily as plug-and-play module on top of zero-shot models and state-of-the-art few-shot methods, MTA shows systematic and consistent improvements.",
    "pdf_link": "https://arxiv.org/abs/2405.02266",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.02266v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02266/inlier_light.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02266v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02266/mode_light.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02266v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02266/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02266v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02266/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02266v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02266/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02266v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02266/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02266v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02266/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02266v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02266/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02266v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02266/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02266v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02266/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02266v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02266/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02266v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02266/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02266v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02266/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02266v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02266/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02266v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02266/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02266v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02266/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02266v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02266/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02266v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02266/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02266v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02266/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02266v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02266/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02266v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02266/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02266v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02266/x20.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02266v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02266/x21.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02266v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02266/x22.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02266v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02266/x23.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02266v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02266/x24.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02266v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02266/x25.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02266v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02266/x26.png"
      }
    ],
    "abstract_cn": "CLIP 等大型视觉-语言模型的发展推动了对高效适应技术的研究，尤其是软提示调整。测试时增强，通过使用单个图像的多个增强视图来提升零样本泛化能力，正迅速成为研究热点，这也促使研究者更多地关注测试时的提示调整。与此相对，我们提出了一种稳健的测试时增强均值漂移（MTA）方法，它无需复杂的训练步骤即可超越基于提示的方法。MTA 不依赖于以往测试时增强技术中使用的临时规则（如置信度阈值）来筛选增强视图，而是将每个视图的质量评估变量——内聚性得分——直接整合到其优化过程中。这种方法既高效又无需训练或调整超参数。我们在 15 个数据集上进行了广泛的基准测试，证明了 MTA 在性能和计算效率上的优势。MTA 作为一个易于部署的即插即用模块，无论是在零样本模型还是最先进的少样本方法上，都能带来系统性和一致性的改进。",
    "title_cn": "探讨视觉-语言模型在测试阶段的零样本泛化能力：提示学习是否真的不可或缺？",
    "tags": [
      "分类：LLM应用\n\n这篇论文讨论了大型视觉-语言模型（如CLIP）的测试时增强技术，特别是软提示调整。它提出了一种名为测试时增强均值漂移（MTA）的方法，用于提高零样本泛化能力。这种方法不依赖于复杂的训练步骤，而是通过整合内聚性得分来评估每个增强视图的质量。论文的重点是提高模型性能和计算效率，这属于LLM应用的范畴。",
      "计算机视觉",
      "机器学习"
    ]
  },
  {
    "title": "Leveraging Large Language Models to Enhance Domain Expert Inclusion in Data Science Workflows",
    "submit_datetime": "2024年05月03日",
    "abstract": "Domain experts can play a crucial role in guiding data scientists to optimize machine learning models while ensuring contextual relevance for downstream use. However, in current workflows, such collaboration is challenging due to differing expertise, abstract documentation practices, and lack of access and visibility into low-level implementation artifacts. To address these challenges and enable domain expert participation, we introduce CellSync, a collaboration framework comprising (1) a Jupyter Notebook extension that continuously tracks changes to dataframes and model metrics and (2) a Large Language Model powered visualization dashboard that makes those changes interpretable to domain experts. Through CellSync's cell-level dataset visualization with code summaries, domain experts can interactively examine how individual data and modeling operations impact different data segments. The chat features enable data-centric conversations and targeted feedback to data scientists. Our preliminary evaluation shows that CellSync provides transparency and promotes critical discussions about the intents and implications of data operations.",
    "pdf_link": "https://arxiv.org/abs/2405.02260",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.02260v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02260/cellsync_viz_1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02260v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02260/jupyter_extension_chat_long.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02260v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02260/cellsync_combined.png"
      }
    ],
    "abstract_cn": "领域专家对于引导数据科学家优化机器学习模型并确保其在实际应用中的相关性至关重要。但目前，由于专业背景差异、文档实践的抽象性以及对底层实现细节的访问和可见性不足，这种跨专业合作面临诸多挑战。为了解决这些问题，我们推出了 CellSync——一个协作框架，它包括：（1）一个 Jupyter Notebook 插件，实时监测数据集和模型性能指标的变化；（2）一个由大型语言模型支持的可视化仪表板，使得变化对非技术专家也易于理解。CellSync 提供的单元级数据可视化和代码摘要功能，让领域专家能够直观地分析数据和模型操作对不同数据段的影响。其内置的聊天功能则促进了以数据为中心的交流和对数据科学家的精确反馈。我们初步的评估结果表明，CellSync 不仅提高了工作的透明度，还激发了关于数据操作意图和后果的关键讨论。",
    "title_cn": "通过运用大型语言模型，我们能够提升数据科学流程中领域专家的参与度和包容性。",
    "tags": [
      "分类：LLM应用",
      "数据科学",
      "协作框架"
    ]
  },
  {
    "title": "What matters when building vision-language models?",
    "submit_datetime": "2024年05月03日",
    "abstract": "The growing interest in vision-language models (VLMs) has been driven by improvements in large language models and vision transformers. Despite the abundance of literature on this subject, we observe that critical decisions regarding the design of VLMs are often not justified. We argue that these unsupported decisions impede progress in the field by making it difficult to identify which choices improve model performance. To address this issue, we conduct extensive experiments around pre-trained models, architecture choice, data, and training methods. Our consolidation of findings includes the development of Idefics2, an efficient foundational VLM of 8 billion parameters. Idefics2 achieves state-of-the-art performance within its size category across various multimodal benchmarks, and is often on par with models four times its size. We release the model (base, instructed, and chat) along with the datasets created for its training.",
    "pdf_link": "https://arxiv.org/abs/2405.02246",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.02246v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02246/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02246v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02246/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02246v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02246/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02246v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02246/autoregressive_lora_vs_flamingo_lora.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02246v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02246/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02246v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02246/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02246v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02246/x6.png"
      }
    ],
    "abstract_cn": "随着大型语言模型和视觉变换器的进步，视觉-语言模型（VLMs）的研究兴趣不断攀升。尽管相关文献众多，我们发现在VLMs设计上的关键决策往往缺乏充分的理由。我们认为这种缺乏依据的决策阻碍了领域进步，因为它让人们难以识别哪些选择真正提升了模型性能。为了应对这一挑战，我们进行了深入的实验研究，涉及预训练模型、架构选择、数据收集和训练方法等多个方面。我们的研究成果包括开发了Idefics2——一个参数量达80亿的高效基础VLM。Idefics2在多模态基准测试中的表现在同类规模模型中领先，并且常常能与参数量为其四倍的模型相媲美。我们还公开了该模型的三个版本（基础版、指导版和聊天版）及其训练所用的数据集。",
    "title_cn": "构建视觉-语言模型时，关键因素有哪些？",
    "tags": [
      "分类：LLM应用",
      "视觉计算",
      "人工智能"
    ]
  },
  {
    "title": "REASONS: A benchmark for REtrieval and Automated citationS Of scieNtific Sentences using Public and Proprietary LLMs",
    "submit_datetime": "2024年05月03日",
    "abstract": "Automatic citation generation for sentences in a document or report is paramount for intelligence analysts, cybersecurity, news agencies, and education personnel. In this research, we investigate whether large language models (LLMs) are capable of generating references based on two forms of sentence queries: (a) Direct Queries, LLMs are asked to provide author names of the given research article, and (b) Indirect Queries, LLMs are asked to provide the title of a mentioned article when given a sentence from a different article. To demonstrate where LLM stands in this task, we introduce a large dataset called REASONS comprising abstracts of the 12 most popular domains of scientific research on arXiv. From around 20K research articles, we make the following deductions on public and proprietary LLMs: (a) State-of-the-art, often called anthropomorphic GPT-4 and GPT-3.5, suffers from high pass percentage (PP) to minimize the hallucination rate (HR). When tested with Perplexity.ai (7B), they unexpectedly made more errors; (b) Augmenting relevant metadata lowered the PP and gave the lowest HR; (c) Advance retrieval-augmented generation (RAG) using Mistral demonstrates consistent and robust citation support on indirect queries and matched performance to GPT-3.5 and GPT-4. The HR across all domains and models decreased by an average of 41.93% and the PP was reduced to 0% in most cases. In terms of generation quality, the average F1 Score and BLEU were 68.09% and 57.51%, respectively; (d) Testing with adversarial samples showed that LLMs, including the Advance RAG Mistral, struggle to understand context, but the extent of this issue was small in Mistral and GPT-4-Preview. Our study con tributes valuable insights into the reliability of RAG for automated citation generation tasks.",
    "pdf_link": "https://arxiv.org/abs/2405.02228",
    "graphs": [],
    "abstract_cn": "自动生成文档或报告中句子的引用对于情报分析、网络安全、新闻机构和教育工作者极为重要。本研究探讨了大型语言模型（LLMs）是否能够根据两种查询形式生成参考文献：(a) 直接查询，要求模型提供特定研究文章的作者名；(b) 间接查询，要求模型根据来自不同文章的句子提供被引用文章的标题。为了评估 LLMs 在此任务上的表现，我们创建了一个名为 REASONS 的大型数据集，涵盖了 arXiv 上科学研究成果最丰富的 12 个领域的摘要，覆盖约 20,000 篇研究文章。我们对公共和专有的 LLMs 进行了分析，得出以下结论：(a) 被称为具有人类特质的先进模型 GPT-4 和 GPT-3.5，尽管在减少幻觉率（HR）方面表现出色，但在 Perplexity.ai（7B）的测试中意外出现了更多错误；(b) 添加相关元数据有效降低了通过率（PP）并最小化了 HR；(c) 使用 Mistral 的高级检索增强生成（RAG）在处理间接查询时展现出了稳定且强大的引用生成能力，其性能与 GPT-3.5 和 GPT-4 相当。所有领域和模型的平均 HR 下降了 41.93%，而 PP 在大多数情况下降至 0%。就生成质量而言，平均 F1 分数和 BLEU 分数分别为 68.09% 和 57.51%；(d) 通过对抗性样本的测试显示，包括高级 RAG Mistral 在内的 LLMs 在理解上下文方面存在挑战，但在 Mistral 和 GPT-4-Preview 中这一问题的影响较小。我们的研究为 RAG 在自动化引用生成任务的可靠性提供了重要的洞见。",
    "title_cn": "REASONS：一个基准测试，旨在利用公共及私有的大型语言模型（LLMs）检索并自动引用科学文献中的句子。",
    "tags": [
      "分类：RAG\n\n这篇论文探讨了大型语言模型（LLMs）在自动化引用生成任务中的应用，特别是研究了高级检索增强生成（RAG）在处理间接查询时的性能。论文中提到了对公共和专有的 LLMs 进行了分析，并比较了不同模型在减少幻觉率（HR）和通过率（PP）方面的表现。此外，还提到了通过对抗性样本的测试来评估 LLMs 在理解上下文方面的挑战。这些内容都与 RAG 技术的应用和性能评估相关，因此将这篇论文归类为 RAG。",
      "情报分析",
      "网络安全"
    ]
  },
  {
    "title": "FairEvalLLM. A Comprehensive Framework for Benchmarking Fairness in Large Language Model Recommender Systems",
    "submit_datetime": "2024年05月03日",
    "abstract": "This paper presents a framework for evaluating fairness in recommender systems powered by Large Language Models (RecLLMs), addressing the need for a unified approach that spans various fairness dimensions including sensitivity to user attributes, intrinsic fairness, and discussions of fairness based on underlying benefits. In addition, our framework introduces counterfactual evaluations and integrates diverse user group considerations to enhance the discourse on fairness evaluation for RecLLMs.\n  Our key contributions include the development of a robust framework for fairness evaluation in LLM-based recommendations and a structured method to create \\textit{informative user profiles} from demographic data, historical user preferences, and recent interactions. We argue that the latter is essential for enhancing personalization in such systems, especially in temporal-driven scenarios. We demonstrate the utility of our framework through practical applications on two datasets, LastFM-1K and ML-1M. We conduct experiments on a subsample of 80 users from each dataset, testing and assessing the effectiveness of various prompt construction scenarios and in-context learning, comprising more than 50 scenarios. This results in more than 4000 recommendations (80 * 50 = 4000). Our study reveals that while there are no significant unfairness issues in scenarios involving sensitive attributes, some concerns remain. However, in terms of intrinsic fairness, which does not involve direct sensitivity, unfairness across demographic groups remains significant. The code and data used for this paper are available at: \\url{https://shorturl.at/awBFM}.",
    "pdf_link": "https://arxiv.org/abs/2405.02219",
    "graphs": [],
    "abstract_cn": "本论文介绍了一套评估大型语言模型驱动的推荐系统（RecLLMs）公平性的框架，旨在整合包括用户属性敏感度、内在公平性以及基于潜在益处的公平性讨论等多个公平维度。该框架还引入了反事实评估，并考虑了不同用户群体的多样性，以丰富RecLLMs公平性评估的讨论。我们的主要贡献是构建了一个稳健的LLM推荐系统公平性评估框架，并提出了一种从人口统计数据、用户历史偏好和最新互动中构建“信息丰富的用户档案”的结构化方法。我们强调，这对于提升系统个性化，尤其是在时间敏感场景中至关重要。通过在LastFM-1K和ML-1M两个数据集上的应用实例，我们展示了框架的实用性。我们对每个数据集中的80名用户子样本进行了实验，测试了超过50种不同的提示构建和上下文学习场景，产生了4000多个推荐。研究发现，尽管在涉及敏感属性的场景中未发现显著的不公平问题，但在不涉及直接敏感性的内在公平性方面，不同人口统计群体之间仍存在显著的不公平现象。本研究使用的相关代码和数据已在\\url{https://shorturl.at/awBFM}上公开。",
    "title_cn": "FairEvalLLM，为大型语言模型推荐系统公平性评估提供了一个全面的基准框架。",
    "tags": [
      "LLM应用",
      "推荐系统",
      "公平性评估"
    ]
  },
  {
    "title": "Automatic Programming: Large Language Models and Beyond",
    "submit_datetime": "2024年05月03日",
    "abstract": "Automatic programming has seen increasing popularity due to the emergence of tools like GitHub Copilot which rely on Large Language Models (LLMs). At the same time, automatically generated code faces challenges during deployment due to concerns around quality and trust. In this article, we study automated coding in a general sense and study the concerns around code quality, security and related issues of programmer responsibility. These are key issues for organizations while deciding on the usage of automatically generated code. We discuss how advances in software engineering such as program repair and analysis can enable automatic programming. We conclude with a forward looking view, focusing on the programming environment of the near future, where programmers may need to switch to different roles to fully utilize the power of automatic programming. Automated repair of automatically generated programs from LLMs, can help produce higher assurance code from LLMs, along with evidence of assurance",
    "pdf_link": "https://arxiv.org/abs/2405.02213",
    "graphs": [],
    "abstract_cn": "随着工具如依赖大型语言模型（LLMs）的GitHub Copilot的问世，自动编程的受欢迎程度日益上升。然而，自动生成的代码在部署时因质量和信任问题而遭遇挑战。本文全面审视了自动编码的实践，探讨了代码质量、安全性及程序员责任等关键议题，这些都是企业在采纳自动生成代码时必须考虑的问题。文章还讨论了软件工程的进步，例如程序修复和分析技术，是如何推动自动编程发展的。最后，我们展望未来，预测在不久的将来，程序员可能需要转变角色，以完全释放自动编程的潜力。由LLMs自动生成的程序的自动修复，有望提高代码的可靠性，并提供相应的保证证据。",
    "title_cn": "自动编程：探索大型语言模型及其更广阔领域",
    "tags": [
      "LLM应用",
      "软件工程",
      "自动编程"
    ]
  },
  {
    "title": "Assessing and Verifying Task Utility in LLM-Powered Applications",
    "submit_datetime": "2024年05月03日",
    "abstract": "The rapid development of Large Language Models (LLMs) has led to a surge in applications that facilitate collaboration among multiple agents, assisting humans in their daily tasks. However, a significant gap remains in assessing to what extent LLM-powered applications genuinely enhance user experience and task execution efficiency. This highlights the need to verify utility of LLM-powered applications, particularly by ensuring alignment between the application's functionality and end-user needs. We introduce AgentEval, a novel framework designed to simplify the utility verification process by automatically proposing a set of criteria tailored to the unique purpose of any given application. This allows for a comprehensive assessment, quantifying the utility of an application against the suggested criteria. We present a comprehensive analysis of the effectiveness and robustness of AgentEval for two open source datasets including Math Problem solving and ALFWorld House-hold related tasks. For reproducibility purposes, we make the data, code and all the logs publicly available at https://bit.ly/3w3yKcS .",
    "pdf_link": "https://arxiv.org/abs/2405.02178",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）的迅猛发展催生了一大批促进多代理协作、助力人类日常任务的应用。然而，对于这些LLM驱动的应用究竟在多大程度上提升了用户体验和任务执行效率，目前尚缺乏充分的评估。这表明，我们需要验证LLM应用的实用性，特别是要确保应用功能与最终用户的实际需求相匹配。为此，我们提出了AgentEval，这是一个创新框架，它通过自动生成一套专为特定应用目的定制的标准，来简化实用性的验证流程。该框架允许我们全面评估并量化应用的实用性。我们还对AgentEval在两个开源数据集——数学问题求解和ALFWorld家庭相关任务——中的有效性和鲁棒性进行了深入分析。为了便于复现研究结果，我们公开了数据、代码和所有日志，链接为 https://bit.ly/3w3yKcS。",
    "title_cn": "探索大型语言模型（LLM）支持的应用程序中任务实用性的评估与验证。",
    "tags": [
      "Agent",
      "人工智能",
      "用户体验"
    ]
  },
  {
    "title": "EEG2TEXT: Open Vocabulary EEG-to-Text Decoding with EEG Pre-Training and Multi-View Transformer",
    "submit_datetime": "2024年05月03日",
    "abstract": "Deciphering the intricacies of the human brain has captivated curiosity for centuries. Recent strides in Brain-Computer Interface (BCI) technology, particularly using motor imagery, have restored motor functions such as reaching, grasping, and walking in paralyzed individuals. However, unraveling natural language from brain signals remains a formidable challenge. Electroencephalography (EEG) is a non-invasive technique used to record electrical activity in the brain by placing electrodes on the scalp. Previous studies of EEG-to-text decoding have achieved high accuracy on small closed vocabularies, but still fall short of high accuracy when dealing with large open vocabularies. We propose a novel method, EEG2TEXT, to improve the accuracy of open vocabulary EEG-to-text decoding. Specifically, EEG2TEXT leverages EEG pre-training to enhance the learning of semantics from EEG signals and proposes a multi-view transformer to model the EEG signal processing by different spatial regions of the brain. Experiments show that EEG2TEXT has superior performance, outperforming the state-of-the-art baseline methods by a large margin of up to 5% in absolute BLEU and ROUGE scores. EEG2TEXT shows great potential for a high-performance open-vocabulary brain-to-text system to facilitate communication.",
    "pdf_link": "https://arxiv.org/abs/2405.02165",
    "graphs": [],
    "abstract_cn": "探索人脑的奥秘一直是人类数百年来的渴望。脑-机接口（BCI）技术的最近进展，尤其是结合运动想象，已经帮助瘫痪患者恢复了伸手、抓握和行走等基本动作。但是，从大脑信号中解析自然语言仍然是一大难题。脑电图（EEG）作为一种非侵入性技术，通过在头皮上放置电极来捕捉大脑的电活动。尽管先前对EEG至文本转换的研究在有限词汇量上取得了高精度，但在处理更广泛的词汇时仍显不足。我们提出了一种创新的方法——EEG2TEXT，旨在提升开放词汇量EEG至文本转换的准确度。EEG2TEXT通过EEG预训练强化了从EEG信号中提取语义的学习，并引入了多视角变换器来模拟大脑不同区域对EEG信号的处理。实验结果表明，EEG2TEXT的性能超越了当前最先进方法，其BLEU和ROUGE评分的绝对提升高达5%。EEG2TEXT为实现高效能的开放词汇脑到文本转换系统，从而促进沟通提供了巨大的可能性。",
    "title_cn": "EEG2TEXT：采用 EEG 预训练和多视角变换技术，实现开放词汇表的 EEG 到文本的转换。",
    "tags": [
      "分类：Agent",
      "脑-机接口",
      ""
    ]
  },
  {
    "title": "The AI Review Lottery: Widespread AI-Assisted Peer Reviews Boost Paper Scores and Acceptance Rates",
    "submit_datetime": "2024年05月03日",
    "abstract": "Journals and conferences worry that peer reviews assisted by artificial intelligence (AI), in particular, large language models (LLMs), may negatively influence the validity and fairness of the peer-review system, a cornerstone of modern science. In this work, we address this concern with a quasi-experimental study of the prevalence and impact of AI-assisted peer reviews in the context of the 2024 International Conference on Learning Representations (ICLR), a large and prestigious machine-learning conference. Our contributions are threefold. Firstly, we obtain a lower bound for the prevalence of AI-assisted reviews at ICLR 2024 using the GPTZero LLM detector, estimating that at least $15.8\\%$ of reviews were written with AI assistance. Secondly, we estimate the impact of AI-assisted reviews on submission scores. Considering pairs of reviews with different scores assigned to the same paper, we find that in $53.4\\%$ of pairs the AI-assisted review scores higher than the human review ($p = 0.002$; relative difference in probability of scoring higher: $+14.4\\%$ in favor of AI-assisted reviews). Thirdly, we assess the impact of receiving an AI-assisted peer review on submission acceptance. In a matched study, submissions near the acceptance threshold that received an AI-assisted peer review were $4.9$ percentage points ($p = 0.024$) more likely to be accepted than submissions that did not. Overall, we show that AI-assisted reviews are consequential to the peer-review process and offer a discussion on future implications of current trends",
    "pdf_link": "https://arxiv.org/abs/2405.02150",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.02150v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02150/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02150v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02150/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02150v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02150/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02150v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02150/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02150v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02150/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02150v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02150/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02150v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02150/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02150v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02150/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02150v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02150/x9.png"
      }
    ],
    "abstract_cn": "期刊和会议对AI辅助的同行评审可能损害同行评审系统的有效性和公正性表示担忧，尤其是在大型语言模型（LLMs）的辅助下。本研究通过对2024年国际学习表示会议（ICLR）的AI辅助同行评审的普及度和影响进行准实验性研究，回应了这一关切。我们的研究结果分为三部分：首先，利用GPTZero LLM检测工具，我们估计至少有15.8%的ICLR 2024评审报告是借助AI完成的。其次，我们分析了AI辅助评审对论文评分的影响，发现在评分不同的评审对中，AI辅助评审的评分高出人类评审的比例为53.4%（p = 0.002），概率差异为+14.4%，表明AI辅助评审更具优势。最后，我们评估了AI辅助评审对论文接受率的影响，发现在接受门槛附近的论文中，接受AI辅助评审的论文比未接受的论文接受率高出4.9个百分点（p = 0.024）。总体而言，我们的研究揭示了AI辅助评审对同行评审流程的实质性影响，并对未来趋势的可能影响进行了深入讨论。",
    "title_cn": "AI评审的幸运抽奖：当人工智能辅助的同行评审变得普遍时，它显著提升了论文的评分和被接受的概率。",
    "tags": [
      "分类：LLM应用\n\n这篇论文研究了大型语言模型（LLMs）在AI辅助的同行评审中的应用，以及这种应用对同行评审系统的有效性和公正性的影响。论文通过对2024年国际学习表示会议（ICLR）的AI辅助同行评审的普及度和影响进行准实验性研究，发现AI辅助评审对论文评分和接受率有显著影响。这篇论文关注的是LLM在实际应用中的问题和影响，因此可以归类为LLM应用。",
      "学术出版",
      "人工智能"
    ]
  },
  {
    "title": "MedReadMe: A Systematic Study for Fine-grained Sentence Readability in Medical Domain",
    "submit_datetime": "2024年05月03日",
    "abstract": "Medical texts are notoriously challenging to read. Properly measuring their readability is the first step towards making them more accessible. In this paper, we present a systematic study on fine-grained readability measurements in the medical domain at both sentence-level and span-level. We introduce a new dataset MedReadMe, which consists of manually annotated readability ratings and fine-grained complex span annotation for 4,520 sentences, featuring two novel \"Google-Easy\" and \"Google-Hard\" categories. It supports our quantitative analysis, which covers 650 linguistic features and automatic complex word and jargon identification. Enabled by our high-quality annotation, we benchmark and improve several state-of-the-art sentence-level readability metrics for the medical domain specifically, which include unsupervised, supervised, and prompting-based methods using recently developed large language models (LLMs). Informed by our fine-grained complex span annotation, we find that adding a single feature, capturing the number of jargon spans, into existing readability formulas can significantly improve their correlation with human judgments. We will publicly release the dataset and code.",
    "pdf_link": "https://arxiv.org/abs/2405.02144",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.02144v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02144/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02144v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02144/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02144v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02144/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02144v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02144/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02144v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02144/61.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02144v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02144/x5.png"
      }
    ],
    "abstract_cn": "医学文本阅读难度极高，准确评估其可读性对于提高普及性至关重要。本文提出了一项系统性研究，旨在对医学领域的文本进行细致的可读性分析，包括句子和短语两个层面。我们创建了一个新的数据集 MedReadMe，包含4,520句医学文本的可读性评分和复杂性标注，特别引入了“谷歌简易”与“谷歌困难”两个新颖分类。本研究对650个语言特征进行了量化分析，并实现了复杂词汇和行话的自动识别。借助高质量的标注数据，我们对医学领域的几个先进句子级可读性度量进行了基准测试和改进，涵盖了无监督、监督以及基于提示的方法，并利用最新的大型语言模型（LLMs）。我们的细粒度复杂短语标注显示，向现有可读性公式中添加一个特征——术语短语的数量，可以显著提升其与人类判断的一致性。我们将公开发布这一数据集和相关代码。",
    "title_cn": "MedReadMe：深入探究医学领域内句子细粒度可读性的系统性研究",
    "tags": [
      "LLM应用",
      "",
      ""
    ]
  },
  {
    "title": "Optimising Calls to Large Language Models with Uncertainty-Based Two-Tier Selection",
    "submit_datetime": "2024年05月03日",
    "abstract": "Researchers and practitioners operating on a limited budget face the cost-performance trade-off dilemma. The challenging decision often centers on whether to use a large LLM with better performance or a smaller one with reduced costs. This has motivated recent research in the optimisation of LLM calls. Either a cascading strategy is used, where a smaller LLM or both are called sequentially, or a routing strategy is used, where only one model is ever called. Both scenarios are dependent on a decision criterion which is typically implemented by an extra neural model. In this work, we propose a simpler solution; we use only the uncertainty of the generations of the small LLM as the decision criterion. We compare our approach with both cascading and routing strategies using three different pairs of pre-trained small and large LLMs, on nine different tasks and against approaches that require an additional neural model. Our experiments reveal this simple solution optimally balances cost and performance, outperforming existing methods on 25 out of 27 experimental setups.",
    "pdf_link": "https://arxiv.org/abs/2405.02134",
    "graphs": [],
    "abstract_cn": "面临预算限制的研究人员和从业者在成本与性能之间做出艰难抉择。他们常常纠结于是选择性能更优的大型语言模型（LLM），还是成本更低的小型LLM。这一挑战催生了对LLM调用优化的新近研究。研究中提出了两种策略：一种是级联策略，顺序调用小型LLM或两者；另一种是路由策略，只选择一个模型进行调用。这两种策略都需要一个决策标准，通常由额外的神经网络模型来实现。在本研究中，我们提出了一种更简洁的方法：仅以小型LLM生成的不确定性作为决策依据。我们对比了这一方法与现有的级联和路由策略，并在九项不同任务上进行了测试，涵盖了三对预训练的小型和大型LLM。实验结果表明，我们的简化方案在27个实验设置中的25个中，以更优的成本效益比超越了现有方法。",
    "title_cn": "通过不确定性驱动的双层筛选机制，提升对大型语言模型调用的优化效果。",
    "tags": [
      "LLM应用",
      "",
      "机器学习"
    ]
  },
  {
    "title": "Unveiling the Potential of LLM-Based ASR on Chinese Open-Source Datasets",
    "submit_datetime": "2024年05月03日",
    "abstract": "Large Language Models have demonstrated unparalleled effectiveness in various NLP tasks, and integrating LLMs with automatic speech recognition is becoming a mainstream paradigm. Building upon this momentum, our research delves into an indepth examination of this paradigm on a large opensource Chinese dataset. Specifically, our research aims to evaluate the impact of various configurations of speech encoders, LLMs, and projector modules in the context of the speech foundation encoderLLM ASR paradigm. Furthermore, we introduce a threestage training approach, expressly developed to enhance the model's ability to align auditory and textual information. The implementation of this approach, alongside the strategic integration of ASR components, enabled us to achieve the SOTA performance on the AISHELL1, TestNet, and TestMeeting test sets. Our analysis presents an empirical foundation for future research in LLMbased ASR systems and offers insights into optimizing performance using Chinese datasets. We will publicly release all scripts used for data preparation, training, inference, and scoring, as well as pretrained models and training logs to promote reproducible research.",
    "pdf_link": "https://arxiv.org/abs/2405.02132",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLM）在自然语言处理（NLP）任务上展现了非凡的效能，其与自动语音识别（ASR）技术的融合正逐渐成为主流。本研究乘势而上，深入分析了这一融合在大规模开源中文数据集上的表现。研究的核心在于评估不同配置的语音编码器、LLM及投影模块在语音基础编码器-LLM ASR框架中的作用。我们提出了一种三阶段训练策略，旨在提升模型整合听觉与文本信息的能力。这一策略的实施，结合ASR组件的精心整合，使我们在AISHELL1、TestNet和TestMeeting测试集上达到了行业领先水平。本研究不仅为未来基于LLM的ASR系统研究奠定了实证基础，还为使用中文数据集优化性能提供了洞见。为了推动可复制研究，我们将公开所有用于数据处理、模型训练、推理评分的脚本，以及预训练模型和训练记录。",
    "title_cn": "探索基于大型语言模型的自动语音识别技术在中文开源数据集中的应用潜力。",
    "tags": [
      "LLM应用",
      "",
      "自动语音识别"
    ]
  },
  {
    "title": "Single and Multi-Hop Question-Answering Datasets for Reticular Chemistry with GPT-4-Turbo",
    "submit_datetime": "2024年05月03日",
    "abstract": "The rapid advancement in artificial intelligence and natural language processing has led to the development of large-scale datasets aimed at benchmarking the performance of machine learning models. Herein, we introduce 'RetChemQA,' a comprehensive benchmark dataset designed to evaluate the capabilities of such models in the domain of reticular chemistry. This dataset includes both single-hop and multi-hop question-answer pairs, encompassing approximately 45,000 Q&As for each type. The questions have been extracted from an extensive corpus of literature containing about 2,530 research papers from publishers including NAS, ACS, RSC, Elsevier, and Nature Publishing Group, among others. The dataset has been generated using OpenAI's GPT-4 Turbo, a cutting-edge model known for its exceptional language understanding and generation capabilities. In addition to the Q&A dataset, we also release a dataset of synthesis conditions extracted from the corpus of literature used in this study. The aim of RetChemQA is to provide a robust platform for the development and evaluation of advanced machine learning algorithms, particularly for the reticular chemistry community. The dataset is structured to reflect the complexities and nuances of real-world scientific discourse, thereby enabling nuanced performance assessments across a variety of tasks. The dataset is available at the following link: https://github.com/nakulrampal/RetChemQA",
    "pdf_link": "https://arxiv.org/abs/2405.02128",
    "graphs": [],
    "abstract_cn": "随着人工智能和自然语言处理技术的突飞猛进，我们见证了旨在衡量机器学习模型性能的大型数据集的诞生。本文介绍了“RetChemQA”，这是一个全面的基准数据集，用以评估机器学习模型在网状化学领域的性能。该数据集涵盖了约45,000对单跳和多跳问答对，问题源自一个包含约2,530篇研究论文的广泛文献库，这些论文由NAS、ACS、RSC、Elsevier和Nature Publishing Group等知名出版商发布。利用OpenAI的GPT-4 Turbo——一个以卓越的语言理解和生成能力著称的前沿模型——我们生成了这个数据集。除了问答数据集外，我们还提供了一个从本研究使用的文献库中提取的合成条件数据集。RetChemQA旨在为网状化学界的机器学习算法的发展和评估提供一个坚实的平台。数据集的设计反映了现实世界科学交流的复杂性和细节，从而允许在多种任务上进行深入的性能评估。该数据集可通过以下链接访问：https://github.com/nakulrampal/RetChemQA",
    "title_cn": "为 Reticular Chemistry 领域设计的单跳与多跳问答数据集，特别适配 GPT-4-Turbo 模型",
    "tags": [
      "分类：LLM应用\n\n这篇论文介绍了一个名为“RetChemQA”的基准数据集，该数据集用于评估机器学习模型在网状化学领域的性能。论文中提到利用了OpenAI的GPT-4 Turbo模型来生成这个数据集，这表明了大型语言模型（LLM）在数据集创建和应用方面的应用。此外，该数据集旨在为网状化学领域的机器学习算法提供发展和评估的平台，进一步展示了LLM在特定领域的应用潜力。因此，这篇论文应归类为“LLM应用”。",
      "",
      "机器学习"
    ]
  },
  {
    "title": "Evaluating Large Language Models for Structured Science Summarization in the Open Research Knowledge Graph",
    "submit_datetime": "2024年05月03日",
    "abstract": "Structured science summaries or research contributions using properties or dimensions beyond traditional keywords enhances science findability. Current methods, such as those used by the Open Research Knowledge Graph (ORKG), involve manually curating properties to describe research papers' contributions in a structured manner, but this is labor-intensive and inconsistent between the domain expert human curators. We propose using Large Language Models (LLMs) to automatically suggest these properties. However, it's essential to assess the readiness of LLMs like GPT-3.5, Llama 2, and Mistral for this task before application. Our study performs a comprehensive comparative analysis between ORKG's manually curated properties and those generated by the aforementioned state-of-the-art LLMs. We evaluate LLM performance through four unique perspectives: semantic alignment and deviation with ORKG properties, fine-grained properties mapping accuracy, SciNCL embeddings-based cosine similarity, and expert surveys comparing manual annotations with LLM outputs. These evaluations occur within a multidisciplinary science setting. Overall, LLMs show potential as recommendation systems for structuring science, but further finetuning is recommended to improve their alignment with scientific tasks and mimicry of human expertise.",
    "pdf_link": "https://arxiv.org/abs/2405.02105",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.02105v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02105/fig1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02105v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02105/fig2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02105v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02105/fig3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02105v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02105/fig4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02105v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02105/fig5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02105v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02105/fig6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02105v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02105/fig7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02105v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02105/s1q1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02105v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02105/s1q2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02105v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02105/s1q3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02105v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02105/s2q5.png"
      }
    ],
    "abstract_cn": "超越传统关键词，运用属性或维度构建的结构化科学摘要和研究贡献，显著提升了科学研究的可检索性。目前，如开放研究知识图谱（ORKG）所采纳的方法，通过人工策划属性来描述学术论文的结构化贡献，这一过程不仅劳动密集，而且各领域专家之间的一致性也难以保证。本研究提出了利用大型语言模型（LLMs）自动推荐这些属性的创新思路。但在实际应用这些模型，如GPT-3.5、Llama 2和Mistral之前，对其完成此类任务的准备情况进行全面评估至关重要。本研究对ORKG人工策划的属性与这些顶尖LLMs生成的属性进行了深入的对比分析。我们从四个维度对LLMs的性能进行了评估：与ORKG属性的语义一致性和偏差、属性映射的精细度准确性、基于SciNCL嵌入的余弦相似度，以及专家对手动注释与LLM输出的比较调查。这些评估在跨学科的科学背景下进行。总体来看，LLMs在作为科学结构化推荐系统方面展现了巨大潜力，但为了更好地适应科学任务和模仿人类专家的判断，仍需进一步的微调优化。",
    "title_cn": "本文旨在探讨大型语言模型在开放研究知识图谱框架下进行结构化科学摘要的表现。",
    "tags": [
      "LLM应用",
      "科学知识管理",
      ""
    ]
  },
  {
    "title": "Argumentative Large Language Models for Explainable and Contestable Decision-Making",
    "submit_datetime": "2024年05月03日",
    "abstract": "The diversity of knowledge encoded in large language models (LLMs) and their ability to apply this knowledge zero-shot in a range of settings makes them a promising candidate for use in decision-making. However, they are currently limited by their inability to reliably provide outputs which are explainable and contestable. In this paper, we attempt to reconcile these strengths and weaknesses by introducing a method for supplementing LLMs with argumentative reasoning. Concretely, we introduce argumentative LLMs, a method utilising LLMs to construct argumentation frameworks, which then serve as the basis for formal reasoning in decision-making. The interpretable nature of these argumentation frameworks and formal reasoning means that any decision made by the supplemented LLM may be naturally explained to, and contested by, humans. We demonstrate the effectiveness of argumentative LLMs experimentally in the decision-making task of claim verification. We obtain results that are competitive with, and in some cases surpass, comparable state-of-the-art techniques.",
    "pdf_link": "https://arxiv.org/abs/2405.02079",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）蕴含的丰富知识及其在多种情境下零样本应用这些知识的能力，让它们在决策领域展现出巨大潜力。然而，它们目前还无法稳定地提供既合理又可辩驳的输出结果。本文提出了一种新方法，旨在通过引入论证推理来弥补LLMs的这一不足。具体而言，我们提出了论证性LLMs的概念，这是一种利用LLMs构建论证框架的技术，这些框架随后成为决策过程中正式推理的基础。由于论证框架的透明性和推理过程的规范性，补充后的LLM所做出的决策可以被人类自然而然地理解和质疑。我们在决策领域的索赔验证任务中对论证性LLMs进行了实验验证，结果显示其效果与现有最先进技术相媲美，甚至在某些情况下更胜一筹。",
    "title_cn": "构建论辩型大型语言模型，旨在实现决策过程的可解释性和可争议性。",
    "tags": [
      "LLM应用",
      "决策支持系统",
      "人工智能"
    ]
  },
  {
    "title": "Large Multimodal Model based Standardisation of Pathology Reports with Confidence and their Prognostic Significance",
    "submit_datetime": "2024年05月03日",
    "abstract": "Pathology reports are rich in clinical and pathological details but are often presented in free-text format. The unstructured nature of these reports presents a significant challenge limiting the accessibility of their content. In this work, we present a practical approach based on the use of large multimodal models (LMMs) for automatically extracting information from scanned images of pathology reports with the goal of generating a standardised report specifying the value of different fields along with estimated confidence about the accuracy of the extracted fields. The proposed approach overcomes limitations of existing methods which do not assign confidence scores to extracted fields limiting their practical use. The proposed framework uses two stages of prompting a Large Multimodal Model (LMM) for information extraction and validation. The framework generalises to textual reports from multiple medical centres as well as scanned images of legacy pathology reports. We show that the estimated confidence is an effective indicator of the accuracy of the extracted information that can be used to select only accurately extracted fields. We also show the prognostic significance of structured and unstructured data from pathology reports and show that the automatically extracted field values significant prognostic value for patient stratification. The framework is available for evaluation via the URL: https://labieb.dcs.warwick.ac.uk/.",
    "pdf_link": "https://arxiv.org/abs/2405.02040",
    "graphs": [],
    "abstract_cn": "病理报告细节丰富，却多以自由文本呈现，其非结构化特性极大地限制了信息的获取。本研究提出了一种创新方法，利用大型多模态模型（LMMs）自动识别扫描的病理报告图像，旨在创建标准化报告，明确各字段的价值及其准确性的置信估计。此方法突破了传统技术的局限，不再局限于未对提取字段进行置信度评分的缺陷。我们的框架通过两阶段的提示，引导LMM进行信息提取与验证，不仅适用于多个医疗中心的文本报告，也适用于旧版病理报告的扫描图像。研究证实，置信度评估能有效指示信息提取的准确性，从而筛选出精确度更高的字段。此外，我们还探讨了病理报告中结构化与非结构化数据的预后重要性，并发现自动提取的字段值在患者分层中具有重要的预后意义。该框架的评估可通过以下网址进行：https://labieb.dcs.warwick.ac.uk/。",
    "title_cn": "利用大型多模态模型对病理报告进行标准化处理，同时评估其置信度和对疾病预后的影响。",
    "tags": [
      "分类：LLM应用\n\n这篇论文的摘要描述了一种利用大型多模态模型（LMMs）自动识别扫描的病理报告图像的方法，以创建标准化报告并评估各字段的准确性。这种方法涉及到信息提取和验证，以及对提取字段的置信度评分。虽然论文中没有明确提到“大型语言模型”（LLM），但LMMs通常是基于LLMs构建的，因此这篇论文可以归类为LLM应用。此外，这项研究在医疗领域的应用也展示了LLM在实际问题解决中的潜力。",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Analyzing Narrative Processing in Large Language Models (LLMs): Using GPT4 to test BERT",
    "submit_datetime": "2024年05月03日",
    "abstract": "The ability to transmit and receive complex information via language is unique to humans and is the basis of traditions, culture and versatile social interactions. Through the disruptive introduction of transformer based large language models (LLMs) humans are not the only entity to \"understand\" and produce language any more. In the present study, we have performed the first steps to use LLMs as a model to understand fundamental mechanisms of language processing in neural networks, in order to make predictions and generate hypotheses on how the human brain does language processing. Thus, we have used ChatGPT to generate seven different stylistic variations of ten different narratives (Aesop's fables). We used these stories as input for the open source LLM BERT and have analyzed the activation patterns of the hidden units of BERT using multi-dimensional scaling and cluster analysis. We found that the activation vectors of the hidden units cluster according to stylistic variations in earlier layers of BERT (1) than narrative content (4-5). Despite the fact that BERT consists of 12 identical building blocks that are stacked and trained on large text corpora, the different layers perform different tasks. This is a very useful model of the human brain, where self-similar structures, i.e. different areas of the cerebral cortex, can have different functions and are therefore well suited to processing language in a very efficient way. The proposed approach has the potential to open the black box of LLMs on the one hand, and might be a further step to unravel the neural processes underlying human language processing and cognition in general.",
    "pdf_link": "https://arxiv.org/abs/2405.02024",
    "graphs": [],
    "abstract_cn": "人类凭借语言独有的能力来传递和接收复杂信息，这构成了传统、文化和多样化社交互动的基石。随着基于变换器的大型语言模型（LLMs）的问世，人类不再是唯一能够理解并创造语言的主体。本研究首次尝试将LLMs作为理解神经网络中语言处理机制的模型，以预测和提出关于人脑如何处理语言的假设。我们利用ChatGPT创作了十篇不同风格的伊索寓言变体，并将这些故事输入至开源的LLM BERT模型中。通过多维缩放和聚类分析，我们研究了BERT隐藏单元的激活模式。研究发现，BERT隐藏单元的激活向量更倾向于根据风格变化（在模型的前几层）而非叙事内容（在模型的后几层）进行聚类。BERT由12个相同的构建块堆叠而成，尽管这些构建块在大型文本语料库上进行了训练，但不同层却承担着不同的任务。这一发现为模拟人脑提供了有益的模型，其中大脑皮层的不同区域，即自相似结构，可以执行不同的功能，从而高效地处理语言。本研究的方法不仅有望揭开LLMs的神秘面纱，还可能为解析人类语言处理和认知的神经机制提供新的线索。",
    "title_cn": "探索大型语言模型中的叙事处理能力：以 GPT-4 作为工具，对 BERT 进行测试分析",
    "tags": [
      "分类：LLM理论",
      "人工智能",
      "认知科学"
    ]
  },
  {
    "title": "Exploring Combinatorial Problem Solving with Large Language Models: A Case Study on the Travelling Salesman Problem Using GPT-3.5 Turbo",
    "submit_datetime": "2024年05月03日",
    "abstract": "Large Language Models (LLMs) are deep learning models designed to generate text based on textual input. Although researchers have been developing these models for more complex tasks such as code generation and general reasoning, few efforts have explored how LLMs can be applied to combinatorial problems. In this research, we investigate the potential of LLMs to solve the Travelling Salesman Problem (TSP). Utilizing GPT-3.5 Turbo, we conducted experiments employing various approaches, including zero-shot in-context learning, few-shot in-context learning, and chain-of-thoughts (CoT). Consequently, we fine-tuned GPT-3.5 Turbo to solve a specific problem size and tested it using a set of various instance sizes. The fine-tuned models demonstrated promising performance on problems identical in size to the training instances and generalized well to larger problems. Furthermore, to improve the performance of the fine-tuned model without incurring additional training costs, we adopted a self-ensemble approach to improve the quality of the solutions.",
    "pdf_link": "https://arxiv.org/abs/2405.01997",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）是深度学习领域的佼佼者，专为文本输入生成文本而设计。尽管研究者们正致力于将这些模型应用于更复杂的任务，如代码编写和逻辑推理，但探索LLMs如何解决组合问题的研究却寥寥无几。本研究旨在探究LLMs在解决经典问题——旅行商问题（TSP）上的潜力。我们使用GPT-3.5 Turbo，通过零样本上下文学习、少样本上下文学习以及思维链（CoT）等多种方法进行了实验。随后，我们对GPT-3.5 Turbo进行了针对性的微调，以处理特定规模的问题，并通过一系列不同规模的实例进行了测试。微调后的模型在处理与训练实例规模相同或更大的问题时，均展现出了出色的性能。为了进一步提升微调模型的性能而不增加额外的训练成本，我们采用了自集成策略，以提升解决方案的精度。",
    "title_cn": "本研究深入探讨了大型语言模型在解决组合问题上的能力，特别是以 GPT-3.5 Turbo 为工具，对旅行商问题进行了一项案例研究。",
    "tags": [
      "LLM应用",
      "",
      "组合优化"
    ]
  },
  {
    "title": "Conformal Prediction for Natural Language Processing: A Survey",
    "submit_datetime": "2024年05月03日",
    "abstract": "The rapid proliferation of large language models and natural language processing (NLP) applications creates a crucial need for uncertainty quantification to mitigate risks such as hallucinations and to enhance decision-making reliability in critical applications. Conformal prediction is emerging as a theoretically sound and practically useful framework, combining flexibility with strong statistical guarantees. Its model-agnostic and distribution-free nature makes it particularly promising to address the current shortcomings of NLP systems that stem from the absence of uncertainty quantification. This paper provides a comprehensive survey of conformal prediction techniques, their guarantees, and existing applications in NLP, pointing to directions for future research and open challenges.",
    "pdf_link": "https://arxiv.org/abs/2405.01976",
    "graphs": [],
    "abstract_cn": "随着大型语言模型和自然语言处理（NLP）应用的快速普及，迫切需要进行不确定性量化，以降低幻觉等风险，并提高关键决策应用的可靠性。合规预测作为一种理论上坚实、实践中有效的框架应运而生，它灵活且具有强大的统计保障。其模型无关和不依赖于特定数据分布的特性，使其在解决NLP系统因缺乏不确定性量化而产生的问题上显得尤为有前景。本文全面综述了合规预测技术及其在NLP中的现有应用，并探讨了未来的研究方向和面临的挑战。",
    "title_cn": "一致性预测在自然语言处理领域的应用：综述研究",
    "tags": [
      "分类：LLM理论",
      "",
      "风险管理"
    ]
  },
  {
    "title": "Dependency-Aware Semi-Structured Sparsity of GLU Variants in Large Language Models",
    "submit_datetime": "2024年05月03日",
    "abstract": "The rapid advancement in Large Language Models (LLMs) has markedly enhanced the capabilities of language understanding and generation. However, the substantial model size poses hardware challenges, affecting both memory size for serving and inference latency for token generation. To address those challenges, we propose Dependency-aware Semi-structured Sparsity (DaSS), a novel method for the recent prevalent SwiGLU-based LLMs pruning. Our approach incorporates structural dependency into the weight magnitude-based unstructured pruning. We introduce an MLP-specific pruning metric that evaluates the importance of each weight by jointly considering its magnitude and its corresponding MLP intermediate activation norms. DaSS facilitates a balance between the adaptability offered by unstructured pruning and the structural consistency inherent in dependency-based structured pruning. Empirical evaluations on Mistral and LLaMA2 model families demonstrate that DaSS not only outperforms both SparseGPT and Wanda in achieving hardware-friendly N:M sparsity patterns but also maintains the computational efficiency of Wanda.",
    "pdf_link": "https://arxiv.org/abs/2405.01943",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）的迅猛进步极大地提升了我们对语言的理解和生成能力。但模型体量的庞大也给硬件带来了挑战，包括服务时的内存需求和令牌生成时的推理延迟。为解决这些问题，我们提出了一种创新的修剪方法——依赖感知半结构化稀疏性（DaSS），专为当前流行的基于SwiGLU的LLMs设计。该方法将结构依赖性整合到基于权重大小的无结构修剪之中，并引入了一种针对多层感知器（MLP）的修剪度量，综合考量权重大小及其对应的MLP中间激活范数来评估权重的重要性。DaSS在无结构修剪的灵活性与依赖性结构修剪的结构一致性之间取得了平衡。在Mistral和LLaMA2模型系列上的实验评估显示，DaSS在实现硬件友好的N:M稀疏模式方面不仅超越了SparseGPT和Wanda，还保持了与Wanda相当的计算效率。",
    "title_cn": "在大型语言模型中，GLU 变种的依赖感知半结构化稀疏性研究",
    "tags": [
      "LLM理论",
      "",
      "硬件优化"
    ]
  },
  {
    "title": "Which Identities Are Mobilized: Towards an automated detection of social group appeals in political texts",
    "submit_datetime": "2024年05月03日",
    "abstract": "This paper proposes a computational text classification strategy to identify references to social groups in European party manifestos and beyond. Our methodology uses machine learning techniques, including BERT and large language models, to capture group-based appeals in texts. We propose to combine automated identification of social groups using the Mistral-7B-v0.1 Large Language Model with Embedding Space-based filtering to extend a sample of core social groups to all social groups mentioned in party manifestos. By applying this approach to RRP's and mainstream parties' group images in manifestos, we explore whether electoral dynamics explain similarities in group appeals and potential convergence or divergence in party strategies. Contrary to expectations, increasing RRP support or mainstream parties' vote loss does not necessarily lead to convergence in group appeals. Nonetheless, our methodology enables mapping similarities in group appeals across time and space in 15 European countries from 1980 to 2021 and can be transferred to other use cases as well.",
    "pdf_link": "https://arxiv.org/abs/2405.01904",
    "graphs": [],
    "abstract_cn": "本研究提出了一种计算文本分类的新策略，用以识别欧洲政党宣言中的社会群体引用，并将此方法扩展至更广泛的文献。通过运用机器学习技术，包括BERT和大型语言模型，我们能够捕捉文本中的群体诉求。研究中，我们采用Mistral-7B-v0.1大型语言模型来自动识别社会群体，并结合基于嵌入空间的过滤技术，将核心社会群体的样本范围扩展至所有在政党宣言中被提及的群体。本研究进一步分析了选举动态是否导致了RRP和主流政党在群体诉求上的相似性，以及这些诉求是否存在趋同或分歧的现象。研究发现，RRP支持率的上升或主流政党选票的减少，并不必然导致群体诉求的趋同。此外，本研究的方法论不仅能够追踪1980年至2021年间15个欧洲国家的群体诉求的时空分布，还具有适用于其他情境的潜力。",
    "title_cn": "身份动员探析：政治文本中社会群体呼吁的自动化识别研究",
    "tags": [
      "分类：LLM应用",
      "政治分析",
      ""
    ]
  },
  {
    "title": "Aloe: A Family of Fine-tuned Open Healthcare LLMs",
    "submit_datetime": "2024年05月03日",
    "abstract": "As the capabilities of Large Language Models (LLMs) in healthcare and medicine continue to advance, there is a growing need for competitive open-source models that can safeguard public interest. With the increasing availability of highly competitive open base models, the impact of continued pre-training is increasingly uncertain. In this work, we explore the role of instruct tuning, model merging, alignment, red teaming and advanced inference schemes, as means to improve current open models. To that end, we introduce the Aloe family, a set of open medical LLMs highly competitive within its scale range. Aloe models are trained on the current best base models (Mistral, LLaMA 3), using a new custom dataset which combines public data sources improved with synthetic Chain of Thought (CoT). Aloe models undergo an alignment phase, becoming one of the first few policy-aligned open healthcare LLM using Direct Preference Optimization, setting a new standard for ethical performance in healthcare LLMs. Model evaluation expands to include various bias and toxicity datasets, a dedicated red teaming effort, and a much-needed risk assessment for healthcare LLMs. Finally, to explore the limits of current LLMs in inference, we study several advanced prompt engineering strategies to boost performance across benchmarks, yielding state-of-the-art results for open healthcare 7B LLMs, unprecedented at this scale.",
    "pdf_link": "https://arxiv.org/abs/2405.01886",
    "graphs": [],
    "abstract_cn": "随着大型语言模型（LLMs）在医疗领域的应用日益深入，对于能够维护公共福祉的开源模型的需求也日益迫切。面对日益增多的高竞争力开源基础模型，持续预训练的效果变得愈发不明确。本研究旨在探讨指导性微调、模型融合、模型对齐、对抗性测试和高级推理策略等手段，以提升现有开源模型的性能。我们特别推出了芦荟系列，这是一系列在规模上极具竞争力的开源医疗语言模型。这些模型基于当前顶尖的基础模型（Mistral和LLaMA 3）进行训练，并采用了结合了公共数据源和合成思维链（CoT）方法的全新定制数据集。芦荟模型经过对齐阶段，成为首批采用直接偏好优化进行政策对齐的开源医疗LLM，树立了医疗LLM伦理性能的新标杆。我们的模型评估不仅涵盖了多种偏见和毒性数据集，还包括了专门的对抗性测试和医疗LLM风险评估。此外，为了探究当前LLMs在推理方面的潜力，我们研究了多种先进的提示工程策略，以提升模型在各项基准测试中的表现，为开源医疗领域的7B规模LLMs取得了开创性的成绩。",
    "title_cn": "Aloe：一套经过精细调整的开放医疗大型语言模型家族",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "DALLMi: Domain Adaption for LLM-based Multi-label Classifier",
    "submit_datetime": "2024年05月03日",
    "abstract": "Large language models (LLMs) increasingly serve as the backbone for classifying text associated with distinct domains and simultaneously several labels (classes). When encountering domain shifts, e.g., classifier of movie reviews from IMDb to Rotten Tomatoes, adapting such an LLM-based multi-label classifier is challenging due to incomplete label sets at the target domain and daunting training overhead. The existing domain adaptation methods address either image multi-label classifiers or text binary classifiers. In this paper, we design DALLMi, Domain Adaptation Large Language Model interpolator, a first-of-its-kind semi-supervised domain adaptation method for text data models based on LLMs, specifically BERT. The core of DALLMi is the novel variation loss and MixUp regularization, which jointly leverage the limited positively labeled and large quantity of unlabeled text and, importantly, their interpolation from the BERT word embeddings. DALLMi also introduces a label-balanced sampling strategy to overcome the imbalance between labeled and unlabeled data. We evaluate DALLMi against the partial-supervised and unsupervised approach on three datasets under different scenarios of label availability for the target domain. Our results show that DALLMi achieves higher mAP than unsupervised and partially-supervised approaches by 19.9% and 52.2%, respectively.",
    "pdf_link": "https://arxiv.org/abs/2405.01883",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.01883v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01883/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01883v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01883/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01883v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01883/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01883v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01883/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01883v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01883/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01883v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01883/x7.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）正日益成为对不同领域文本进行多标签分类的关键技术。然而，面对领域转换，如电影评论分类器从IMDb迁移到Rotten Tomatoes，基于LLM的多标签分类器的适应性训练面临挑战，这主要是因为目标领域的标签集不全和高昂的训练成本。目前，大多数领域适应技术要么应用于图像多标签分类，要么应用于文本二元分类。本文提出了DALLMi，一种创新的半监督领域适应方法，专为基于LLMs的文本数据模型设计，尤其是针对BERT模型。DALLMi的创新之处在于其变体损失和MixUp正则化技术，这两者共同利用有限的正标记数据和大量未标记文本，以及它们在BERT词嵌入中的插值。此外，DALLMi还引入了一种标签平衡抽样策略，以解决标记与未标记数据之间的不平衡问题。我们在三个不同的目标领域标签可用性场景下，对DALLMi进行了评估，并与部分监督和无监督方法进行了比较。评估结果显示，DALLMi在mAP上分别比无监督和部分监督方法提高了19.9%和52.2%。",
    "title_cn": "DALLMi：为基于大型语言模型的多标签分类任务量身定制的领域适应技术。",
    "tags": [
      "LLM应用",
      "",
      "文本分类"
    ]
  },
  {
    "title": "Automated Control Logic Test Case Generation using Large Language Models",
    "submit_datetime": "2024年05月03日",
    "abstract": "Testing PLC and DCS control logic in industrial automation is laborious and challenging since appropriate test cases are often complex and difficult to formulate. Researchers have previously proposed several automated test case generation approaches for PLC software applying symbolic execution and search-based techniques. Often requiring formal specifications and performing a mechanical analysis of programs, these approaches may uncover specific programming errors but sometimes suffer from state space explosion and cannot process rather informal specifications. We proposed a novel approach for the automatic generation of PLC test cases that queries a Large Language Model (LLM) to synthesize test cases for code provided in a prompt. Experiments with ten open-source function blocks from the OSCAT automation library showed that the approach is fast, easy to use, and can yield test cases with high statement coverage for low-to-medium complex programs. However, we also found that LLM-generated test cases suffer from erroneous assertions in many cases, which still require manual adaption.",
    "pdf_link": "https://arxiv.org/abs/2405.01874",
    "graphs": [],
    "abstract_cn": "工业自动化领域中对PLC和DCS控制逻辑的测试工作既繁琐又充满挑战，主要原因在于设计出恰当的测试案例本身颇为复杂且难以构造。过去，研究者们已经提出多种自动化生成PLC软件测试案例的方法，这些方法运用了符号执行和基于搜索的技术。它们通常需要依赖正式的规范说明，并进行程序的机械分析，虽然能够发现某些编程错误，但有时会因为状态空间的爆炸性增长而无法处理那些不太正式的规范说明。我们提出了一种创新的方法，通过询问大型语言模型（LLM）来自动生成PLC的测试案例，这些案例针对提示中提供的代码进行合成。在Oscat自动化库的十个开源功能块上的实验显示，这种方法不仅快速、用户友好，而且能够为中等以下复杂度的程序产生高语句覆盖率的测试案例。尽管如此，我们也发现，由LLM生成的测试案例在很多情况下包含了错误的断言，这需要进行人工修正。",
    "title_cn": "利用大型语言模型实现控制逻辑测试用例的自动生成",
    "tags": [
      "LLM应用",
      "工业自动化",
      "软件测试"
    ]
  },
  {
    "title": "Incorporating External Knowledge and Goal Guidance for LLM-based Conversational Recommender Systems",
    "submit_datetime": "2024年05月03日",
    "abstract": "This paper aims to efficiently enable large language models (LLMs) to use external knowledge and goal guidance in conversational recommender system (CRS) tasks. Advanced LLMs (e.g., ChatGPT) are limited in domain-specific CRS tasks for 1) generating grounded responses with recommendation-oriented knowledge, or 2) proactively leading the conversations through different dialogue goals. In this work, we first analyze those limitations through a comprehensive evaluation, showing the necessity of external knowledge and goal guidance which contribute significantly to the recommendation accuracy and language quality. In light of this finding, we propose a novel ChatCRS framework to decompose the complex CRS task into several sub-tasks through the implementation of 1) a knowledge retrieval agent using a tool-augmented approach to reason over external Knowledge Bases and 2) a goal-planning agent for dialogue goal prediction. Experimental results on two multi-goal CRS datasets reveal that ChatCRS sets new state-of-the-art benchmarks, improving language quality of informativeness by 17% and proactivity by 27%, and achieving a tenfold enhancement in recommendation accuracy.",
    "pdf_link": "https://arxiv.org/abs/2405.01868",
    "graphs": [],
    "abstract_cn": "本研究致力于提升大型语言模型（LLMs）在对话式推荐系统（CRS）任务中运用外部知识和目标导向的能力。例如ChatGPT这样的高级LLMs在特定CRS任务上存在局限，这主要体现在两个方面：一是生成基于推荐知识的切实回应；二是通过多样的对话目标引领对话。我们首先通过全面的评估揭示了这些限制，并强调了引入外部知识和目标导向对于提升推荐精准度和语言品质的重要性。基于这些发现，我们设计了创新的ChatCRS框架，该框架通过两个关键组件将复杂的CRS任务细化为多个子任务：一是利用工具辅助方法检索外部知识库的知识检索代理；二是用于对话目标预测的目标规划代理。在两个多目标CRS数据集上的实验结果显示，ChatCRS在设定新的行业标杆的同时，将信息性语言质量提升了17%，主动性提高了27%，并实现了推荐准确度的十倍增长。",
    "title_cn": "为基于大型语言模型的对话式推荐系统融入外部知识并引入目标导向。",
    "tags": [
      "分类：LLM应用",
      "对话系统",
      "推荐系统"
    ]
  },
  {
    "title": "SUKHSANDESH: An Avatar Therapeutic Question Answering Platform for Sexual Education in Rural India",
    "submit_datetime": "2024年05月03日",
    "abstract": "Sexual education aims to foster a healthy lifestyle in terms of emotional, mental and social well-being. In countries like India, where adolescents form the largest demographic group, they face significant vulnerabilities concerning sexual health. Unfortunately, sexual education is often stigmatized, creating barriers to providing essential counseling and information to this at-risk population. Consequently, issues such as early pregnancy, unsafe abortions, sexually transmitted infections, and sexual violence become prevalent. Our current proposal aims to provide a safe and trustworthy platform for sexual education to the vulnerable rural Indian population, thereby fostering the healthy and overall growth of the nation. In this regard, we strive towards designing SUKHSANDESH, a multi-staged AI-based Question Answering platform for sexual education tailored to rural India, adhering to safety guardrails and regional language support. By utilizing information retrieval techniques and large language models, SUKHSANDESH will deliver effective responses to user queries. We also propose to anonymise the dataset to mitigate safety measures and set AI guardrails against any harmful or unwanted response generation. Moreover, an innovative feature of our proposal involves integrating ``avatar therapy'' with SUKHSANDESH. This feature will convert AI-generated responses into real-time audio delivered by an animated avatar speaking regional Indian languages. This approach aims to foster empathy and connection, which is particularly beneficial for individuals with limited literacy skills. Partnering with Gram Vaani, an industry leader, we will deploy SUKHSANDESH to address sexual education needs in rural India.",
    "pdf_link": "https://arxiv.org/abs/2405.01858",
    "graphs": [],
    "abstract_cn": "性教育致力于促进青少年的情感、心理和社会健康。在印度等国家，青少年人口众多，他们在性健康领域面临诸多风险。遗憾的是，性教育常常遭遇污名化，阻碍了向这些易受伤害的青少年提供关键的咨询与信息。这导致早孕、不安全堕胎、性传播疾病和性暴力等问题频发。本提案旨在为印度农村地区的弱势群体提供一个安全、可靠的性教育平台，以促进国家的健康发展。我们致力于开发SUKHSANDESH，这是一个专为印度农村量身定制的、分阶段的AI问答系统，它遵循严格的安全准则，并支持地区语言。利用信息检索技术和大型语言模型，SUKHSANDESH将为用户提供精准的答复。我们计划对数据集进行匿名处理，以加强安全措施，并设置AI防护措施，防止不当或有害的响应生成。此外，我们的提案还包括一个创新功能，即将“化身疗法”与SUKHSANDESH结合。这一特性将AI生成的回复转化为由动画化身实时发声的音频，使用地区印度语言，旨在增强同理心和亲近感，尤其适合文化水平较低的群体。我们与行业先锋Gram Vaani合作，将SUKHSANDESH部署到印度农村，以满足当地的性教育需求。",
    "title_cn": "SUKHSANDESH：一个面向印度农村地区的性教育虚拟治疗问答平台。",
    "tags": [
      "Agent",
      "性教育",
      "人工智能"
    ]
  },
  {
    "title": "SGHateCheck: Functional Tests for Detecting Hate Speech in Low-Resource Languages of Singapore",
    "submit_datetime": "2024年05月03日",
    "abstract": "To address the limitations of current hate speech detection models, we introduce \\textsf{SGHateCheck}, a novel framework designed for the linguistic and cultural context of Singapore and Southeast Asia. It extends the functional testing approach of HateCheck and MHC, employing large language models for translation and paraphrasing into Singapore's main languages, and refining these with native annotators. \\textsf{SGHateCheck} reveals critical flaws in state-of-the-art models, highlighting their inadequacy in sensitive content moderation. This work aims to foster the development of more effective hate speech detection tools for diverse linguistic environments, particularly for Singapore and Southeast Asia contexts.",
    "pdf_link": "https://arxiv.org/abs/2405.01842",
    "graphs": [],
    "abstract_cn": "为克服现有仇恨言论检测模型的不足，我们提出了 \\textsf{SGHateCheck}，这是一个专为新加坡及东南亚地区语言文化特色打造的创新框架。该框架借鉴了 HateCheck 和 MHC 的功能测试策略，利用大型语言模型进行翻译和意译，以覆盖新加坡的主要语种，并由本地注释专家进行精准校正。\\textsf{SGHateCheck} 揭示了尖端模型在处理敏感内容时的重大缺陷，强调了它们在内容审核方面的局限性。本研究的目标是推动更高效仇恨言论检测工具的发展，以满足多样化语言环境的需求，特别是针对新加坡和东南亚地区的具体情况。",
    "title_cn": "SGHateCheck：一种功能性测试工具，旨在识别新加坡低资源语言中的仇恨言论。",
    "tags": [
      "分类：LLM应用\n\n这篇论文提出了一个针对新加坡及东南亚地区语言文化特色的仇恨言论检测框架 \\textsf{SGHateCheck}，它利用大型语言模型进行翻译和意译，以覆盖新加坡的主要语种，并由本地注释专家进行精准校正。这篇论文的研究目标是推动更高效仇恨言论检测工具的发展，以满足多样化语言环境的需求。因此，它属于LLM应用类别。",
      "社交媒体",
      "内容审核"
    ]
  },
  {
    "title": "Automating the Enterprise with Foundation Models",
    "submit_datetime": "2024年05月03日",
    "abstract": "Automating enterprise workflows could unlock $4 trillion/year in productivity gains. Despite being of interest to the data management community for decades, the ultimate vision of end-to-end workflow automation has remained elusive. Current solutions rely on process mining and robotic process automation (RPA), in which a bot is hard-coded to follow a set of predefined rules for completing a workflow. Through case studies of a hospital and large B2B enterprise, we find that the adoption of RPA has been inhibited by high set-up costs (12-18 months), unreliable execution (60% initial accuracy), and burdensome maintenance (requiring multiple FTEs). Multimodal foundation models (FMs) such as GPT-4 offer a promising new approach for end-to-end workflow automation given their generalized reasoning and planning abilities. To study these capabilities we propose ECLAIR, a system to automate enterprise workflows with minimal human supervision. We conduct initial experiments showing that multimodal FMs can address the limitations of traditional RPA with (1) near-human-level understanding of workflows (93% accuracy on a workflow understanding task) and (2) instant set-up with minimal technical barrier (based solely on a natural language description of a workflow, ECLAIR achieves end-to-end completion rates of 40%). We identify human-AI collaboration, validation, and self-improvement as open challenges, and suggest ways they can be solved with data management techniques. Code is available at: https://github.com/HazyResearch/eclair-agents",
    "pdf_link": "https://arxiv.org/abs/2405.03710",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.03710v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03710/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.03710v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.03710/Figure_2.png"
      }
    ],
    "abstract_cn": "自动化企业工作流程有望每年提升4万亿美元的生产力，然而，尽管数据管理领域对此探索已久，实现完全自动化的愿景仍未成真。现有的自动化方案，如流程挖掘和机器人流程自动化（RPA），虽有成效，但高昂的设置成本、不稳定的执行准确性以及繁琐的维护工作，限制了其广泛应用。多模态基础模型（如GPT-4）凭借其强大的推理与规划能力，为工作流程自动化带来了新希望。我们提出的ECLAIR系统，能在极少人工干预下实现企业工作流程自动化。初步实验显示，多模态FMs不仅在理解工作流程上达到了93%的准确性，而且设置简便，无需复杂技术背景，实现了40%的端到端完成率。我们正探索人机协作、验证机制和自我改进等挑战，并寻求数据管理技术的解决方案。相关代码已公开：https://github.com/HazyResearch/eclair-agents。",
    "title_cn": "借助基础模型，企业自动化得以实现。本研究旨在探索基础模型在企业自动化中的应用，并分析其对提升效率和创新能力的影响。",
    "tags": [
      "Agent\n\n这篇论文介绍了一个名为ECLAIR的系统，它利用多模态基础模型（如GPT-4）的推理与规划能力来实现企业工作流程的自动化。这个系统能够在很少的人工干预下工作，并且初步实验表明它在理解工作流程方面具有高准确性，同时设置简便，不需要复杂的技术背景。这个系统可以被视为一个智能代理（Agent），因为它能够自主地执行任务和流程，因此将其分类为Agent。",
      "企业自动化",
      "数据管理"
    ]
  },
  {
    "title": "Plan-Seq-Learn: Language Model Guided RL for Solving Long Horizon Robotics Tasks",
    "submit_datetime": "2024年05月02日",
    "abstract": "Large Language Models (LLMs) have been shown to be capable of performing high-level planning for long-horizon robotics tasks, yet existing methods require access to a pre-defined skill library (e.g. picking, placing, pulling, pushing, navigating). However, LLM planning does not address how to design or learn those behaviors, which remains challenging particularly in long-horizon settings. Furthermore, for many tasks of interest, the robot needs to be able to adjust its behavior in a fine-grained manner, requiring the agent to be capable of modifying low-level control actions. Can we instead use the internet-scale knowledge from LLMs for high-level policies, guiding reinforcement learning (RL) policies to efficiently solve robotic control tasks online without requiring a pre-determined set of skills? In this paper, we propose Plan-Seq-Learn (PSL): a modular approach that uses motion planning to bridge the gap between abstract language and learned low-level control for solving long-horizon robotics tasks from scratch. We demonstrate that PSL achieves state-of-the-art results on over 25 challenging robotics tasks with up to 10 stages. PSL solves long-horizon tasks from raw visual input spanning four benchmarks at success rates of over 85%, out-performing language-based, classical, and end-to-end approaches. Video results and code at https://mihdalal.github.io/planseqlearn/",
    "pdf_link": "https://arxiv.org/abs/2405.01534",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）展现出能够为长期机器人任务进行高级规划的能力，但现有技术依赖于一个预先定义的技能库，如抓取、放置等。LLM在规划方面的应用尚未触及如何设计或学习这些技能，尤其在长期任务中，这仍是一个难题。此外，机器人在执行许多任务时需要精细调整行为，这就需要能够灵活修改底层控制动作。是否可以利用LLMs的海量知识来指导高层策略，通过强化学习（RL）策略在线高效解决机器人控制任务，而无需依赖预设技能集？本文提出了Plan-Seq-Learn（PSL），一种模块化方法，它通过运动规划将抽象语言与学习到的低级控制相结合，以解决从零开始的长期机器人任务。PSL在超过25个具有挑战性的机器人任务上取得了业界领先的成绩，这些任务包含多达10个阶段。基于原始视觉输入，PSL在四个基准测试中的成功率超过85%，超越了基于语言、传统和端到端的解决方案。相关视频和代码可在 https://mihdalal.github.io/planseqlearn/ 查看。",
    "title_cn": "Plan-Seq-Learn：一种由语言模型引导的强化学习方法，专为解决机器人领域的长期任务而设计。",
    "tags": [
      "分类：Agent",
      "机器人技术",
      ""
    ]
  },
  {
    "title": "OmniDrive: A Holistic LLM-Agent Framework for Autonomous Driving with 3D Perception, Reasoning and Planning",
    "submit_datetime": "2024年05月02日",
    "abstract": "The advances in multimodal large language models (MLLMs) have led to growing interests in LLM-based autonomous driving agents to leverage their strong reasoning capabilities. However, capitalizing on MLLMs' strong reasoning capabilities for improved planning behavior is challenging since planning requires full 3D situational awareness beyond 2D reasoning. To address this challenge, our work proposes a holistic framework for strong alignment between agent models and 3D driving tasks. Our framework starts with a novel 3D MLLM architecture that uses sparse queries to lift and compress visual representations into 3D before feeding them into an LLM. This query-based representation allows us to jointly encode dynamic objects and static map elements (e.g., traffic lanes), providing a condensed world model for perception-action alignment in 3D. We further propose OmniDrive-nuScenes, a new visual question-answering dataset challenging the true 3D situational awareness of a model with comprehensive visual question-answering (VQA) tasks, including scene description, traffic regulation, 3D grounding, counterfactual reasoning, decision making and planning. Extensive studies show the effectiveness of the proposed architecture as well as the importance of the VQA tasks for reasoning and planning in complex 3D scenes.",
    "pdf_link": "https://arxiv.org/abs/2405.01533",
    "graphs": [],
    "abstract_cn": "随着多模态大型语言模型（MLLMs）的飞速发展，人们越来越关注利用这些模型强大推理能力的基于LLM的自动驾驶系统。然而，要利用MLLMs的推理能力来提升规划行为并非易事，因为这需要超越二维推理的三维情境感知。为解决这一难题，本研究提出了一个全新的框架，旨在实现代理模型与三维驾驶任务之间的紧密协同。该框架采用了创新的三维MLLM架构，通过稀疏查询技术将视觉信息提升并压缩成三维数据，再输入至LLM进行处理。这种基于查询的表示方法能够同时编码动态物体和静态地图元素，如交通线路等，为三维空间中的感知与行动对齐提供了一个精简的世界模型。此外，我们还推出了OmniDrive-nuScenes，这是一个全新的视觉问答数据集，它通过包含场景描述、交通规则、三维定位、反事实推理、决策制定和规划在内的全面视觉问答任务，挑战模型的真正三维情境感知能力。广泛的研究证实了所提出架构的有效性，以及视觉问答任务在复杂三维场景中推理和规划中的关键作用。",
    "title_cn": "OmniDrive：一套综合性的LLM代理框架，专为自动驾驶设计，集成了3D感知、推理和规划功能。",
    "tags": [
      "Agent",
      "自动驾驶",
      "人工智能"
    ]
  },
  {
    "title": "FLAME: Factuality-Aware Alignment for Large Language Models",
    "submit_datetime": "2024年05月02日",
    "abstract": "Alignment is a standard procedure to fine-tune pre-trained large language models (LLMs) to follow natural language instructions and serve as helpful AI assistants. We have observed, however, that the conventional alignment process fails to enhance the factual accuracy of LLMs, and often leads to the generation of more false facts (i.e. hallucination). In this paper, we study how to make the LLM alignment process more factual, by first identifying factors that lead to hallucination in both alignment steps:\\ supervised fine-tuning (SFT) and reinforcement learning (RL). In particular, we find that training the LLM on new knowledge or unfamiliar texts can encourage hallucination. This makes SFT less factual as it trains on human labeled data that may be novel to the LLM. Furthermore, reward functions used in standard RL can also encourage hallucination, because it guides the LLM to provide more helpful responses on a diverse set of instructions, often preferring longer and more detailed responses. Based on these observations, we propose factuality-aware alignment, comprised of factuality-aware SFT and factuality-aware RL through direct preference optimization. Experiments show that our proposed factuality-aware alignment guides LLMs to output more factual responses while maintaining instruction-following capability.",
    "pdf_link": "https://arxiv.org/abs/2405.01525",
    "graphs": [],
    "abstract_cn": "对齐技术用于优化预训练的大型语言模型（LLMs），使其能够更好地遵循自然语言指令，充当智能AI助手。但我们发现，传统对齐方法并未有效提升LLMs的事实准确性，反而可能产生更多错误信息。本文深入探讨了如何提升LLM对齐过程的事实性，首先分析了在监督式微调（SFT）和强化学习（RL）两个对齐步骤中导致幻觉现象的因素。我们发现，对LLM进行新知识或不熟悉文本的训练可能会诱发幻觉，这降低了SFT的事实准确性，因为它依赖于对LLM而言可能是新奇的人类标注数据。此外，标准RL中的奖励机制也可能促进幻觉，因为它倾向于引导LLM提供更长、更详细的响应，以适应多样化的指令需求。针对这些问题，我们提出了一种新的事实性感知对齐方法，包括事实性感知SFT和通过直接偏好优化的事实性感知RL。实验结果表明，该方法能够有效提升LLMs生成事实性响应的能力，同时不损害其遵循指令的能力。",
    "title_cn": "FLAME：为大型语言模型打造的事实感知对齐技术",
    "tags": [
      "LLM应用",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Transformer-Aided Semantic Communications",
    "submit_datetime": "2024年05月02日",
    "abstract": "The transformer structure employed in large language models (LLMs), as a specialized category of deep neural networks (DNNs) featuring attention mechanisms, stands out for their ability to identify and highlight the most relevant aspects of input data. Such a capability is particularly beneficial in addressing a variety of communication challenges, notably in the realm of semantic communication where proper encoding of the relevant data is critical especially in systems with limited bandwidth. In this work, we employ vision transformers specifically for the purpose of compression and compact representation of the input image, with the goal of preserving semantic information throughout the transmission process. Through the use of the attention mechanism inherent in transformers, we create an attention mask. This mask effectively prioritizes critical segments of images for transmission, ensuring that the reconstruction phase focuses on key objects highlighted by the mask. Our methodology significantly improves the quality of semantic communication and optimizes bandwidth usage by encoding different parts of the data in accordance with their semantic information content, thus enhancing overall efficiency. We evaluate the effectiveness of our proposed framework using the TinyImageNet dataset, focusing on both reconstruction quality and accuracy. Our evaluation results demonstrate that our framework successfully preserves semantic information, even when only a fraction of the encoded data is transmitted, according to the intended compression rates.",
    "pdf_link": "https://arxiv.org/abs/2405.01521",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）中的变换器结构，作为深度神经网络（DNNs）的一个特殊类别，以其识别和强调输入数据中最重要方面的能力而著称。这一特性在多种通信挑战中尤为有用，尤其是在语义通信领域，恰当地编码相关数据对于带宽受限的系统至关重要。本研究中，我们专门采用视觉变换器对输入图像进行压缩和紧凑表示，以在传输过程中保持语义信息。利用变换器内在的注意力机制，我们生成了一个注意力掩码，该掩码有效优先传输图像的关键部分，确保重建阶段集中于掩码标记的关键对象。我们的技术显著提升了语义通信质量，并优化了带宽使用效率，通过根据数据的语义信息含量对数据的不同部分进行编码。通过TinyImageNet数据集的测试，我们专注于重建质量和准确性的评估，结果证明我们的框架即便在仅传输部分编码数据的情况下，也能成功保持语义信息，达到预期的压缩比率。",
    "title_cn": "借助Transformer的语义通信技术",
    "tags": [
      "LLM应用",
      "",
      "图像处理"
    ]
  },
  {
    "title": "Analyzing the Role of Semantic Representations in the Era of Large Language Models",
    "submit_datetime": "2024年05月02日",
    "abstract": "Traditionally, natural language processing (NLP) models often use a rich set of features created by linguistic expertise, such as semantic representations. However, in the era of large language models (LLMs), more and more tasks are turned into generic, end-to-end sequence generation problems. In this paper, we investigate the question: what is the role of semantic representations in the era of LLMs? Specifically, we investigate the effect of Abstract Meaning Representation (AMR) across five diverse NLP tasks. We propose an AMR-driven chain-of-thought prompting method, which we call AMRCoT, and find that it generally hurts performance more than it helps. To investigate what AMR may have to offer on these tasks, we conduct a series of analysis experiments. We find that it is difficult to predict which input examples AMR may help or hurt on, but errors tend to arise with multi-word expressions, named entities, and in the final inference step where the LLM must connect its reasoning over the AMR to its prediction. We recommend focusing on these areas for future work in semantic representations for LLMs. Our code: https://github.com/causalNLP/amr_llm.",
    "pdf_link": "https://arxiv.org/abs/2405.01502",
    "graphs": [],
    "abstract_cn": "在传统NLP模型中，专家们精心构建的语义表示等特征集曾是关键。但在大型语言模型（LLMs）盛行的今天，众多任务已简化为标准化的序列生成问题。本文旨在探究：在LLMs主导的当下，语义表示的功能何在？我们特别关注了抽象意义表示（AMR）在五项多样化NLP任务中的应用。我们引入了一种新颖的AMR驱动的思维链提示技术，命名为AMRCoT，却发现其效果往往适得其反。为了深入理解AMR的潜力，我们开展了一系列深入的分析实验。实验结果表明，AMR对输入样本的正负影响难以预判，但问题多出现在多词短语、命名实体识别以及LLM将AMR推理与预测结果相连结的最终步骤。基于此，我们建议未来的研究应聚焦于这些关键领域，以优化LLMs中的语义表示。相关代码已在GitHub上公开：https://github.com/causalNLP/amr_llm。",
    "title_cn": "在大型语言模型盛行的当下，深入探讨语义表示的角色与重要性。",
    "tags": [
      "LLM应用",
      "",
      "机器学习"
    ]
  },
  {
    "title": "Supporting Business Document Workflows via Collection-Centric Information Foraging with Large Language Models",
    "submit_datetime": "2024年05月02日",
    "abstract": "Knowledge workers often need to extract and analyze information from a collection of documents to solve complex information tasks in the workplace, e.g., hiring managers reviewing resumes or analysts assessing risk in contracts. However, foraging for relevant information can become tedious and repetitive over many documents and criteria of interest. We introduce Marco, a mixed-initiative workspace supporting sensemaking over diverse business document collections. Through collection-centric assistance, Marco reduces the cognitive costs of extracting and structuring information, allowing users to prioritize comparative synthesis and decision making processes. Users interactively communicate their information needs to an AI assistant using natural language and compose schemas that provide an overview of a document collection. Findings from a usability study (n=16) demonstrate that when using Marco, users complete sensemaking tasks 16% more quickly, with less effort, and without diminishing accuracy. A design probe with seven domain experts identifies how Marco can benefit various real-world workflows.",
    "pdf_link": "https://arxiv.org/abs/2405.01501",
    "graphs": [],
    "abstract_cn": "职场中的知识工作者经常需要从众多文档中提炼和分析信息，以应对诸如审查简历或评估合同风险等复杂信息挑战。然而，这种信息搜集工作在面对大量文档和多元标准时，往往会变得单调乏味。为此，我们推出了Marco——一个混合主动式工作空间，它通过集合中心的辅助功能，帮助用户在多样化的商业文档集合中进行意义构建。Marco通过降低信息提取和结构化的心理负担，使用户能够更专注于比较综合和决策过程。用户可以通过自然语言与AI助手互动，表达他们的信息需求，并创建模式来概览整个文档集合。一项涉及16名参与者的可用性研究显示，使用Marco的用户在完成意义构建任务时，速度提升了16%，且更为轻松，同时保持了准确性。此外，与七位领域专家的深入探讨揭示了Marco如何能够优化各种现实工作流程的效率。",
    "title_cn": "利用大型语言模型，通过集中式信息搜集，助力商业文档工作流程的优化。",
    "tags": [
      "分类：Agent",
      "职场自动化",
      "信息分析"
    ]
  },
  {
    "title": "Controllable Text Generation in the Instruction-Tuning Era",
    "submit_datetime": "2024年05月02日",
    "abstract": "While most research on controllable text generation has focused on steering base Language Models, the emerging instruction-tuning and prompting paradigm offers an alternate approach to controllability. We compile and release ConGenBench, a testbed of 17 different controllable generation tasks, using a subset of it to benchmark the performance of 9 different baselines and methods on Instruction-tuned Language Models. To our surprise, we find that prompting-based approaches outperform controllable text generation methods on most datasets and tasks, highlighting a need for research on controllable text generation with Instruction-tuned Language Models in specific. Prompt-based approaches match human performance on most stylistic tasks while lagging on structural tasks, foregrounding a need to study more varied constraints and more challenging stylistic tasks. To facilitate such research, we provide an algorithm that uses only a task dataset and a Large Language Model with in-context capabilities to automatically generate a constraint dataset. This method eliminates the fields dependence on pre-curated constraint datasets, hence vastly expanding the range of constraints that can be studied in the future.",
    "pdf_link": "https://arxiv.org/abs/2405.01490",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.01490v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01490/Combinedplot.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01490v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01490/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01490v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01490/TaskWindow.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01490v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01490/ShortInstructions.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01490v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01490/LongInstructionsDef.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01490v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01490/ContentWarning.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01490v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01490/Examples.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01490v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01490/Examples1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01490v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01490/Examples2.png"
      }
    ],
    "abstract_cn": "目前，可控文本生成的研究多集中于引导基础语言模型，而新兴的指令调整与提示技术则为我们提供了另一种控制文本生成的途径。我们创建并公开了 ConGenBench，一个包含 17 项不同可控文本生成任务的测试集，并利用其中的一部分对 9 种不同的基线和指令调整语言模型上的方法进行了性能评估。出人意料的是，基于提示的方法在多数数据集和任务上超越了传统的可控文本生成技术，这表明我们需要特别针对指令调整语言模型进行更深入的可控文本生成研究。此外，基于提示的方法在大多数风格化任务上与人类表现不相上下，但在结构化任务上仍有所欠缺，这提示我们需进一步探索更多样化的约束条件和更具挑战性的风格化任务。为了推动这一领域的研究，我们开发了一种算法，它能够仅利用任务数据集和具备上下文功能的大语言模型，自动生成约束数据集，从而摆脱了对预制约束数据集的依赖，极大地拓宽了未来研究中可探讨的约束范围。",
    "title_cn": "在指令调整时代下的可控文本生成",
    "tags": [
      "LLM应用",
      "",
      "文本生成"
    ]
  },
  {
    "title": "MANTIS: Interleaved Multi-Image Instruction Tuning",
    "submit_datetime": "2024年05月02日",
    "abstract": "The recent years have witnessed a great array of large multimodal models (LMMs) to effectively solve single-image vision language tasks. However, their abilities to solve multi-image visual language tasks is yet to be improved. The existing multi-image LMMs (e.g. OpenFlamingo, Emu, Idefics, etc) mostly gain their multi-image ability through pre-training on hundreds of millions of noisy interleaved image-text data from web, which is neither efficient nor effective. In this paper, we aim at building strong multi-image LMMs via instruction tuning with academic-level resources. Therefore, we meticulously construct Mantis-Instruct containing 721K instances from 14 multi-image datasets. We design Mantis-Instruct to cover different multi-image skills like co-reference, reasoning, comparing, temporal understanding. We combine Mantis-Instruct with several single-image visual-language datasets to train our model Mantis to handle any interleaved image-text inputs. We evaluate the trained Mantis on five multi-image benchmarks and eight single-image benchmarks. Though only requiring academic-level resources (i.e. 36 hours on 16xA100-40G), Mantis-8B can achieve state-of-the-art performance on all the multi-image benchmarks and beats the existing best multi-image LMM Idefics2-8B by an average of 9 absolute points. We observe that Mantis performs equivalently well on the held-in and held-out evaluation benchmarks. We further evaluate Mantis on single-image benchmarks and demonstrate that Mantis can maintain a strong single-image performance on par with CogVLM and Emu2. Our results are particularly encouraging as it shows that low-cost instruction tuning is indeed much more effective than intensive pre-training in terms of building multi-image LMMs.",
    "pdf_link": "https://arxiv.org/abs/2405.01483",
    "graphs": [],
    "abstract_cn": "近年来，众多大型多模态模型（LMMs）在处理单图像视觉语言任务上展现出了卓越的能力。但它们在处理多图像视觉语言任务上的表现尚需精进。目前，多图像LMMs如OpenFlamingo、Emu、Idefics等，主要通过在海量网络中的噪声交织图像-文本数据上进行预训练来提升其多图像处理能力，这种方法既不高效也不尽如人意。本文提出了一种新方法，即通过学术级资源的指令调优来构建强大的多图像LMMs。我们精心打造了Mantis-Instruct，内含14个多图像数据集中的721K实例，旨在涵盖共指、推理、比较、时间理解等多种多图像技能。我们将Mantis-Instruct与多个单图像视觉-语言数据集结合，训练出能够处理任何交织图像-文本输入的模型Mantis。在五个多图像基准和八个单图像基准上的评估结果显示，Mantis-8B仅需36小时的16xA100-40G学术级资源，就能在所有多图像基准上达到最先进的性能，并且平均领先于现有的最佳多图像LMM Idefics2-8B 9个百分点。Mantis在保留和非保留评估基准上的表现同样出色。此外，Mantis在单图像基准上的表现也证明了其在单图像性能上与CogVLM和Emu2不相上下。这些结果特别振奋人心，因为它们表明低成本的指令调优在构建多图像LMMs方面，确实比大规模预训练更为有效。",
    "title_cn": "MANTIS：交错式多图像指令优化",
    "tags": [
      "分类：LLM应用",
      "计算机视觉",
      ""
    ]
  },
  {
    "title": "NeMo-Aligner: Scalable Toolkit for Efficient Model Alignment",
    "submit_datetime": "2024年05月02日",
    "abstract": "Aligning Large Language Models (LLMs) with human values and preferences is essential for making them helpful and safe. However, building efficient tools to perform alignment can be challenging, especially for the largest and most competent LLMs which often contain tens or hundreds of billions of parameters. We create NeMo-Aligner, a toolkit for model alignment that can efficiently scale to using hundreds of GPUs for training. NeMo-Aligner comes with highly optimized and scalable implementations for major paradigms of model alignment such as: Reinforcement Learning from Human Feedback (RLHF), Direct Preference Optimization (DPO), SteerLM, and Self-Play Fine-Tuning (SPIN). Additionally, our toolkit supports running most of the alignment techniques in a Parameter Efficient Fine-Tuning (PEFT) setting. NeMo-Aligner is designed for extensibility, allowing support for other alignment techniques with minimal effort. It is open-sourced with Apache 2.0 License and we invite community contributions at https://github.com/NVIDIA/NeMo-Aligner",
    "pdf_link": "https://arxiv.org/abs/2405.01481",
    "graphs": [],
    "abstract_cn": "确保大型语言模型（LLMs）与人类的价值观和偏好保持一致，对于提升其实用性和安全性至关重要。然而，为这些参数量庞大的模型构建高效的对齐工具并非易事。为此，我们开发了 NeMo-Aligner，这是一款能够高效扩展至数百个 GPU 并行训练的模型对齐工具包。它集成了多种模型对齐范式的优化实现，包括基于人类反馈的强化学习（RLHF）、直接偏好优化（DPO）、SteerLM 以及自对弈微调（SPIN）。NeMo-Aligner 还支持在参数高效微调（PEFT）环境下运行大多数对齐技术。该工具包设计上注重扩展性，易于添加其他对齐技术。NeMo-Aligner 已在 Apache 2.0 许可下开源，并在 https://github.com/NVIDIA/NeMo-Aligner 欢迎社区贡献。",
    "title_cn": "NeMo-Aligner：高效模型对齐的可扩展工具集",
    "tags": [
      "LLM应用",
      "人工智能",
      "机器学习"
    ]
  },
  {
    "title": "V-FLUTE: Visual Figurative Language Understanding with Textual Explanations",
    "submit_datetime": "2024年05月02日",
    "abstract": "Large Vision-Language models (VLMs) have demonstrated strong reasoning capabilities in tasks requiring a fine-grained understanding of literal images and text, such as visual question-answering or visual entailment. However, there has been little exploration of these models' capabilities when presented with images and captions containing figurative phenomena such as metaphors or humor, the meaning of which is often implicit. To close this gap, we propose a new task and a high-quality dataset: Visual Figurative Language Understanding with Textual Explanations (V-FLUTE). We frame the visual figurative language understanding problem as an explainable visual entailment task, where the model has to predict whether the image (premise) entails a claim (hypothesis) and justify the predicted label with a textual explanation. Using a human-AI collaboration framework, we build a high-quality dataset, V-FLUTE, that contains 6,027 <image, claim, label, explanation> instances spanning five diverse multimodal figurative phenomena: metaphors, similes, idioms, sarcasm, and humor. The figurative phenomena can be present either in the image, the caption, or both. We further conduct both automatic and human evaluations to assess current VLMs' capabilities in understanding figurative phenomena.",
    "pdf_link": "https://arxiv.org/abs/2405.01474",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.01474v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01474/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01474v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01474/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01474v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01474/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01474v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01474/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01474v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01474/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01474v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01474/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01474v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01474/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01474v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01474/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01474v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01474/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01474v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01474/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01474v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01474/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01474v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01474/x12.png"
      }
    ],
    "abstract_cn": "大型视觉-语言模型（VLMs）在视觉问答和视觉推理等任务中表现出了卓越的推理能力，这些任务要求对图像和文本进行精细的理解。但是，当涉及到含有隐喻或幽默等比喻性内容的图像和标题时，这些模型的理解能力尚未得到充分探索，因为这些内容的含义往往是隐晦的。为了解决这一问题，我们设计了一项新任务并创建了一个高水准的数据集：视觉比喻语言理解与文本解释（V-FLUTE）。在这个任务中，模型需要判断一张图片（前提）是否能够推导出一个陈述（假设），并用文字来解释其预测结果。我们采用了人机协作的方式，构建了包含6,027个<图像，陈述，标签，解释>样本的V-FLUTE数据集，覆盖了五种不同的多模态比喻现象：隐喻、比喻、成语、讽刺和幽默。这些比喻现象可能出现在图片中、标题中，或者两者兼有。此外，我们还进行了自动化和人工评估，以检验当前VLMs在理解这些比喻现象方面的能力。",
    "title_cn": "V-FLUTE：图文结合，洞悉视觉比喻语言的深层含义",
    "tags": [
      "分类：LLM应用",
      "视觉问答",
      "人工智能"
    ]
  },
  {
    "title": "A Systematic Literature Review on Large Language Models for Automated Program Repair",
    "submit_datetime": "2024年05月02日",
    "abstract": "Automated Program Repair (APR) attempts to patch software bugs and reduce manual debugging efforts. Very recently, with the advances in Large Language Models (LLMs), an increasing number of APR techniques have been proposed, facilitating software development and maintenance and demonstrating remarkable performance. However, due to ongoing explorations in the LLM-based APR field, it is challenging for researchers to understand the current achievements, challenges, and potential opportunities. This work provides the first systematic literature review to summarize the applications of LLMs in APR between 2020 and 2024. We analyze 127 relevant papers from LLMs, APR and their integration perspectives. First, we categorize existing popular LLMs that are applied to support APR and outline three types of utilization strategies for their deployment. Besides, we detail some specific repair scenarios that benefit from LLMs, e.g., semantic bugs and security vulnerabilities. Furthermore, we discuss several critical aspects of integrating LLMs into APR research, e.g., input forms and open science. Finally, we highlight a set of challenges remaining to be investigated and the potential guidelines for future research. Overall, our paper provides a systematic overview of the research landscape to the APR community, helping researchers gain a comprehensive understanding of achievements and promote future research.",
    "pdf_link": "https://arxiv.org/abs/2405.01466",
    "graphs": [],
    "abstract_cn": "自动程序修复（APR）致力于修复软件缺陷，减轻人工调试负担。随着大型语言模型（LLMs）的飞速发展，众多新兴的APR技术应运而生，极大推动了软件产业的发展，并取得了显著成效。然而，在LLM驱动的APR研究领域，由于不断的新发现，研究者们面临着把握当前进展、挑战和机遇的难题。本文首次系统性地回顾了2020至2024年间LLMs在APR领域的应用，深入分析了127篇与LLMs、APR及其融合相关的文献。我们首先对目前应用于APR的主流LLMs进行分类，并归纳了三种常见的应用策略。文章还详细介绍了LLMs在特定修复场景中的应用实例，如语义缺陷和安全漏洞的修复。此外，我们探讨了将LLMs融入APR研究的几个关键议题，包括输入格式和开放科学研究。最后，我们指出了一些尚待解决的挑战，并为未来的研究方向提出了建议。总体上，本文为APR领域的研究者提供了一个全面的研究视角，帮助他们深入理解当前的研究成就，并激发未来研究的灵感。",
    "title_cn": "本文系统性地回顾了用于自动化程序修复的大型语言模型的相关文献。",
    "tags": [
      "LLM应用",
      "软件工程",
      "自动程序修复"
    ]
  },
  {
    "title": "UQA: Corpus for Urdu Question Answering",
    "submit_datetime": "2024年05月02日",
    "abstract": "This paper introduces UQA, a novel dataset for question answering and text comprehension in Urdu, a low-resource language with over 70 million native speakers. UQA is generated by translating the Stanford Question Answering Dataset (SQuAD2.0), a large-scale English QA dataset, using a technique called EATS (Enclose to Anchor, Translate, Seek), which preserves the answer spans in the translated context paragraphs. The paper describes the process of selecting and evaluating the best translation model among two candidates: Google Translator and Seamless M4T. The paper also benchmarks several state-of-the-art multilingual QA models on UQA, including mBERT, XLM-RoBERTa, and mT5, and reports promising results. For XLM-RoBERTa-XL, we have an F1 score of 85.99 and 74.56 EM. UQA is a valuable resource for developing and testing multilingual NLP systems for Urdu and for enhancing the cross-lingual transferability of existing models. Further, the paper demonstrates the effectiveness of EATS for creating high-quality datasets for other languages and domains. The UQA dataset and the code are publicly available at www.github.com/sameearif/UQA.",
    "pdf_link": "https://arxiv.org/abs/2405.01458",
    "graphs": [],
    "abstract_cn": "本研究提出了 UQA 数据集，这是首个针对乌尔都语——一种拥有逾七千万母语使用者的低资源语言——的问答和文本理解的新型数据集。UQA 通过采用 EATS 技术（即包围、锚定、翻译、寻找）翻译斯坦福的 SQuAD2.0 英文问答数据集而成，该技术巧妙地保留了翻译文本中的答案信息。文章详细阐述了在谷歌翻译和 Seamless M4T 两种翻译模型中筛选和评估最佳选项的过程。此外，本研究还对 UQA 数据集上的多个前沿多语言问答模型进行了基准测试，包括 mBERT、XLM-RoBERTa 和 mT5，取得了令人鼓舞的成绩。特别是在 XLM-RoBERTa-XL 模型上，我们分别获得了 85.99 的 F1 分数和 74.56 的精确匹配（EM）分数。UQA 不仅为开发和测试乌尔都语多语言自然语言处理系统提供了宝贵资源，也有助于提升现有模型的跨语言迁移能力。文章还证实了 EATS 技术在创建其他语言和领域高质量数据集方面的潜力。UQA 数据集及相应代码已在 www.github.com/sameearif/UQA 公开发布。",
    "title_cn": "UQA：乌尔都语问答语料库",
    "tags": [
      "LLM应用",
      "",
      "多语言处理"
    ]
  },
  {
    "title": "Creative Problem Solving in Large Language and Vision Models -- What Would it Take?",
    "submit_datetime": "2024年05月02日",
    "abstract": "In this paper, we discuss approaches for integrating Computational Creativity (CC) with research in large language and vision models (LLVMs) to address a key limitation of these models, i.e., creative problem solving. We present preliminary experiments showing how CC principles can be applied to address this limitation through augmented prompting. With this work, we hope to foster discussions of Computational Creativity in the context of ML algorithms for creative problem solving in LLVMs. Our code is at: https://github.com/lnairGT/creative-problem-solving-LLMs",
    "pdf_link": "https://arxiv.org/abs/2405.01453",
    "graphs": [],
    "abstract_cn": "本文探讨了将计算创造力（CC）融入大型语言和视觉模型（LLVMs）研究的方法，旨在突破这些模型在创造性问题解决方面的局限。我们通过一系列初步实验，展示了如何利用CC理念，通过增强式的提示来克服这一局限。我们期望借此工作激发对LLVMs中机器学习算法创造性问题解决背景下的计算创造力的深入讨论。相关代码可在以下链接获取：https://github.com/lnairGT/creative-problem-solving-LLMs",
    "title_cn": "探索大型语言与视觉模型中的创新性问题解决之道 -- 我们该如何应对这一挑战？",
    "tags": [
      "分类：LLM应用",
      "人工智能",
      "机器学习"
    ]
  },
  {
    "title": "Natural Language to Verilog: Design of a Recurrent Spiking Neural Network using Large Language Models and ChatGPT",
    "submit_datetime": "2024年05月02日",
    "abstract": "This paper investigates the use of Large Language Models (LLMs) for automating the generation of hardware description code, aiming to explore their potential in supporting and enhancing the development of efficient neuromorphic computing architectures. Building on our prior work, we employ OpenAI's ChatGPT4 and natural language prompts to synthesize a RTL Verilog module of a programmable recurrent spiking neural network, while also generating test benches to assess the system's correctness. The resultant design was validated in three case studies, the exclusive OR,the IRIS flower classification and the MNIST hand-written digit classification, achieving accuracies of up to 96.6%. To verify its synthesizability and implementability, the design was prototyped on a field-programmable gate array and implemented on SkyWater 130 nm technology by using an open-source electronic design automation flow. Additionally, we have submitted it to Tiny Tapeout 6 chip fabrication program to further evaluate the system on-chip performance in the future.",
    "pdf_link": "https://arxiv.org/abs/2405.01419",
    "graphs": [],
    "abstract_cn": "本研究探讨了利用大型语言模型（LLMs）自动化生成硬件描述语言代码的应用，旨在挖掘其在高效神经形态计算架构开发中的潜力。基于先前研究，我们利用OpenAI的ChatGPT4和自然语言指令，成功合成了一个可编程循环脉冲神经网络的寄存器传输级（RTL）Verilog模块，同时创建了测试平台以确保系统的正确性。该设计在三个案例研究中得到了验证：包括异或逻辑运算、鸢尾花分类和MNIST手写数字识别，准确率最高达96.6%。为了检验其合成和实现的可行性，该设计已在可编程门阵列上进行了原型化，并在SkyWater 130纳米技术平台上，采用开源的电子设计自动化流程实现了。此外，我们已将该设计提交至Tiny Tapeout 6芯片制造计划，以便未来进一步评估其在芯片上的性能表现。",
    "title_cn": "将自然语言转换为 Verilog 代码：我们利用大型语言模型和 ChatGPT，设计了一种递归脉冲神经网络。",
    "tags": [
      "LLM应用",
      "硬件设计",
      "神经形态计算"
    ]
  },
  {
    "title": "MiniGPT-3D: Efficiently Aligning 3D Point Clouds with Large Language Models using 2D Priors",
    "submit_datetime": "2024年05月02日",
    "abstract": "Large 2D vision-language models (2D-LLMs) have gained significant attention by bridging Large Language Models (LLMs) with images using a simple projector. Inspired by their success, large 3D point cloud-language models (3D-LLMs) also integrate point clouds into LLMs. However, directly aligning point clouds with LLM requires expensive training costs, typically in hundreds of GPU-hours on A100, which hinders the development of 3D-LLMs. In this paper, we introduce MiniGPT-3D, an efficient and powerful 3D-LLM that achieves multiple SOTA results while training for only 27 hours on one RTX 3090. Specifically, we propose to align 3D point clouds with LLMs using 2D priors from 2D-LLMs, which can leverage the similarity between 2D and 3D visual information. We introduce a novel four-stage training strategy for modality alignment in a cascaded way, and a mixture of query experts module to adaptively aggregate features with high efficiency. Moreover, we utilize parameter-efficient fine-tuning methods LoRA and Norm fine-tuning, resulting in only 47.8M learnable parameters, which is up to 260x fewer than existing methods. Extensive experiments show that MiniGPT-3D achieves SOTA on 3D object classification and captioning tasks, with significantly cheaper training costs. Notably, MiniGPT-3D gains an 8.12 increase on GPT-4 evaluation score for the challenging object captioning task compared to ShapeLLM-13B, while the latter costs 160 total GPU-hours on 8 A800. We are the first to explore the efficient 3D-LLM, offering new insights to the community. Code and weights are available at https://github.com/TangYuan96/MiniGPT-3D.",
    "pdf_link": "https://arxiv.org/abs/2405.01413",
    "graphs": [],
    "abstract_cn": "大型2D视觉-语言模型（2D-LLMs）通过巧妙的投影技术，成功地将图像与语言模型相结合，引起了广泛关注。继此之后，大型3D点云-语言模型（3D-LLMs）也致力于将点云数据融入语言模型之中。但是，要实现点云与语言模型的直接对齐，往往需要高昂的训练成本，这在A100上通常需要数百个GPU小时，极大地限制了3D-LLMs的发展。本文提出了MiniGPT-3D，这是一款既高效又强大的3D-LLM，仅需在单个RTX 3090上训练27小时，便能取得多项最新技术水平（SOTA）的成果。具体而言，我们创新性地利用2D-LLMs的2D先验知识来辅助3D点云与LLMs的对齐，充分发挥了2D与3D视觉信息的相似性优势。我们设计了一种新颖的四阶段级联训练策略，用于模态对齐，并引入了一个混合查询专家模块，以高效地适应性聚合特征。同时，我们还采用了参数高效的微调技术LoRA和Norm微调，仅用4700万个可学习参数，相比现有方法减少了高达260倍。广泛的实验结果证明，MiniGPT-3D在3D对象分类和字幕生成任务上均达到了最新技术水平，且训练成本显著降低。特别值得一提的是，MiniGPT-3D在GPT-4评估中的对象字幕生成任务上，比ShapeLLM-13B高出8.12分，而后者在8个A800上的训练成本高达160个GPU小时。我们首次探索了高效的3D-LLM，为该领域带来了新的洞见。相关代码和权重已在 https://github.com/TangYuan96/MiniGPT-3D 上发布。",
    "title_cn": "MiniGPT-3D：借助2D先验，高效实现3D点云与大型语言模型的精准对齐。",
    "tags": [
      "LLM应用",
      "计算机视觉",
      ""
    ]
  },
  {
    "title": "Verification and Refinement of Natural Language Explanations through LLM-Symbolic Theorem Proving",
    "submit_datetime": "2024年05月02日",
    "abstract": "Natural language explanations have become a proxy for evaluating explainable and multi-step Natural Language Inference (NLI) models. However, assessing the validity of explanations for NLI is challenging as it typically involves the crowd-sourcing of apposite datasets, a process that is time-consuming and prone to logical errors. To address existing limitations, this paper investigates the verification and refinement of natural language explanations through the integration of Large Language Models (LLMs) and Theorem Provers (TPs). Specifically, we present a neuro-symbolic framework, named Explanation-Refiner, that augments a TP with LLMs to generate and formalise explanatory sentences and suggest potential inference strategies for NLI. In turn, the TP is employed to provide formal guarantees on the logical validity of the explanations and to generate feedback for subsequent improvements. We demonstrate how Explanation-Refiner can be jointly used to evaluate explanatory reasoning, autoformalisation, and error correction mechanisms of state-of-the-art LLMs as well as to automatically enhance the quality of human-annotated explanations of variable complexity in different domains.",
    "pdf_link": "https://arxiv.org/abs/2405.01379",
    "graphs": [],
    "abstract_cn": "自然语言阐释已成为评价可解释性及多步自然语言推理（NLI）模型的标准。然而，验证 NLI 解释的合理性并非易事，这通常需要通过众包获取合适的数据集，既费时又易出错。为克服这些难题，本研究探讨了结合大型语言模型（LLMs）与定理证明器（TPs）来对自然语言阐释进行验证和细化的方法。我们提出了一个名为 Explanation-Refiner 的神经符号框架，该框架利用 LLMs 增强 TP，以生成形式化的解释性句子，并为 NLI 提供可能的推理策略。TP 用于确保解释的逻辑有效性，并为后续改进提供反馈。我们证明了 Explanation-Refiner 如何被用于评估顶尖 LLMs 的解释推理能力、自动形式化以及错误修正机制，并自动提升不同领域中复杂程度不一的人工注释解释的质量。",
    "title_cn": "利用大型语言模型（LLM）中的符号定理证明技术，对自然语言解释进行验证与优化。",
    "tags": [
      "LLM应用",
      "",
      "逻辑推理"
    ]
  },
  {
    "title": "GAIA: A General AI Assistant for Intelligent Accelerator Operations",
    "submit_datetime": "2024年05月02日",
    "abstract": "Large-scale machines like particle accelerators are usually run by a team of experienced operators. In case of a particle accelerator, these operators possess suitable background knowledge on both accelerator physics and the technology comprising the machine. Due to the complexity of the machine, particular subsystems of the machine are taken care of by experts, who the operators can turn to. In this work the reasoning and action (ReAct) prompting paradigm is used to couple an open-weights large language model (LLM) with a high-level machine control system framework and other tools, e.g. the electronic logbook or machine design documentation. By doing so, a multi-expert retrieval augmented generation (RAG) system is implemented, which assists operators in knowledge retrieval tasks, interacts with the machine directly if needed, or writes high level control system scripts. This consolidation of expert knowledge and machine interaction can simplify and speed up machine operation tasks for both new and experienced human operators.",
    "pdf_link": "https://arxiv.org/abs/2405.01359",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.01359v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01359/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01359v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01359/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01359v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01359/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01359v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01359/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01359v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01359/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01359v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01359/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01359v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01359/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01359v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01359/x9.png"
      }
    ],
    "abstract_cn": "大型设施如粒子加速器，往往由资深操作团队掌控。这些操作员不仅精通加速器的物理原理，还对构成该设备的技术支持了如指掌。面对设备复杂性，各子系统均由领域专家维护，以便操作员随时咨询。本研究采用推理与行动（ReAct）提示法，将开放式大型语言模型（LLM）与高级机器控制系统框架及其他辅助工具（如电子日志簿或机器设计文档）相融合。这一整合实现了一个多专家检索增强生成（RAG）系统，它不仅辅助操作员执行知识检索任务，必要时还能直接与机器交互，甚至编写高级控制系统脚本。这种将专家智慧与机器互动相结合的方式，极大简化了机器操作流程，无论是对新手还是资深操作员，都显著提升了工作效率。",
    "title_cn": "GAIA：一款为智能化加速器运营提供助力的全能AI助手。",
    "tags": [
      "RAG",
      "粒子加速器操作",
      "自动化控制系统"
    ]
  },
  {
    "title": "Human-Robot Interaction Conversational User Enjoyment Scale (HRI CUES)",
    "submit_datetime": "2024年05月02日",
    "abstract": "Understanding user enjoyment is crucial in human-robot interaction (HRI), as it can impact interaction quality and influence user acceptance and long-term engagement with robots, particularly in the context of conversations with social robots. However, current assessment methods rely solely on self-reported questionnaires, failing to capture interaction dynamics. This work introduces the Human-Robot Interaction Conversational User Enjoyment Scale (HRI CUES), a novel scale for assessing user enjoyment from an external perspective during conversations with a robot. Developed through rigorous evaluations and discussions of three annotators with relevant expertise, the scale provides a structured framework for assessing enjoyment in each conversation exchange (turn) alongside overall interaction levels. It aims to complement self-reported enjoyment from users and holds the potential for autonomously identifying user enjoyment in real-time HRI. The scale was validated on 25 older adults' open-domain dialogue with a companion robot that was powered by a large language model for conversations, corresponding to 174 minutes of data, showing moderate to good alignment. Additionally, the study offers insights into understanding the nuances and challenges of assessing user enjoyment in robot interactions, and provides guidelines on applying the scale to other domains.",
    "pdf_link": "https://arxiv.org/abs/2405.01354",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.01354v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01354/HRI-CUES.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01354v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01354/elan_anony.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01354v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01354/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01354v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01354/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01354v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01354/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01354v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01354/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01354v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01354/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01354v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01354/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01354v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01354/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01354v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01354/x9.png"
      }
    ],
    "abstract_cn": "在人机互动（HRI）领域，洞察用户的乐趣至关重要，这直接关系到互动的品质、用户的接受程度以及对机器人的长期投入，特别是在与社交机器人的交流中。然而，现有的评估手段主要依赖于问卷自评，这并不足以全面捕捉互动的动态变化。本项工作提出了一种创新的评估工具——人机交互对话用户乐趣量表（HRI CUES），它能够从第三方视角在机器人对话过程中评估用户的乐趣。这个量表是经过三位专家严谨评估和深入讨论后开发的，为每一次对话交流和整体互动提供了一个系统的评估框架。它不仅旨在补充用户的自我评估，还有望实现在实时HRI中自动检测用户的乐趣。通过25位老年参与者与伴侣机器人的开放式对话进行了量表的验证，这些对话由一个大型语言模型支持，共计174分钟的数据显示出量表与实际感受的中等到良好一致性。研究还深入探讨了在机器人互动中评估用户乐趣的复杂性和挑战，并为如何将这一量表应用于其他领域提供了指导性建议。",
    "title_cn": "人机互动对话用户愉悦度量表（HRI CUES）",
    "tags": [
      "Agent",
      "人机交互",
      "社交机器人"
    ]
  },
  {
    "title": "The Power of Question Translation Training in Multilingual Reasoning: Broadened Scope and Deepened Insights",
    "submit_datetime": "2024年05月02日",
    "abstract": "Bridging the significant gap between large language model's English and non-English performance presents a great challenge. While some previous studies attempt to mitigate this gap with translated training data, the recently proposed question alignment approach leverages the model's English expertise to improve multilingual performance with minimum usage of expensive, error-prone translation. In this paper, we explore how broadly this method can be applied by examining its effects in reasoning with executable code and reasoning with common sense. We also explore how to apply this approach efficiently to extremely large language models using proxy-tuning. Experiment results on multilingual reasoning benchmarks mGSM, mSVAMP and xCSQA demonstrate that the question alignment approach can be used to boost multilingual performance across diverse reasoning scenarios, model families, and sizes. For instance, when applied to the LLaMA2 models, our method brings an average accuracy improvements of 12.2% on mGSM even with the 70B model. To understand the mechanism of its success, we analyze representation space, chain-of-thought and translation data scales, which reveals how question translation training strengthens language alignment within LLMs and shapes their working patterns.",
    "pdf_link": "https://arxiv.org/abs/2405.01345",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.01345v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01345/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01345v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01345/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01345v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01345/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01345v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01345/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01345v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01345/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01345v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01345/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01345v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01345/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01345v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01345/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01345v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01345/x9.png"
      }
    ],
    "abstract_cn": "缩小大型语言模型在英语与其他语言性能上的巨大差距是一项艰巨任务。尽管早期研究尝试通过翻译训练数据来缩小这一差距，但新近提出的问题对齐方法通过利用模型的英语专长，以最小的成本和错误风险提升多语言性能。本文深入探讨了该方法的广泛应用潜力，通过分析其在执行代码推理和常识推理方面的效果。我们还研究了如何通过代理调优技术高效地将此方法应用于超大型语言模型。在多语言推理基准测试 mGSM、mSVAMP 和 xCSQA 上的实验结果显示，问题对齐方法能够显著提升不同推理场景、模型系列和规模下的多语言性能。例如，在 LLaMA2 模型上应用该方法，即便是在 70B 模型规模下，也能在 mGSM 上实现平均准确度提升 12.2%。为了深入理解其成功的背后机制，我们对表示空间、思维链和翻译数据规模进行了分析，揭示了问题翻译训练如何加强大型语言模型内的语言一致性，并塑造了它们的工作模式。",
    "title_cn": "通过问题翻译训练提升多语言推理能力：拓展研究视野，深化理解深度。",
    "tags": [
      "LLM应用",
      "",
      "机器翻译"
    ]
  },
  {
    "title": "Overcoming LLM Challenges using RAG-Driven Precision in Coffee Leaf Disease Remediation",
    "submit_datetime": "2024年05月02日",
    "abstract": "This research introduces an innovative AI-driven precision agriculture system, leveraging YOLOv8 for disease identification and Retrieval Augmented Generation (RAG) for context-aware diagnosis. Focused on addressing the challenges of diseases affecting the coffee production sector in Karnataka, The system integrates sophisticated object detection techniques with language models to address the inherent constraints associated with Large Language Models (LLMs). Our methodology not only tackles the issue of hallucinations in LLMs, but also introduces dynamic disease identification and remediation strategies. Real-time monitoring, collaborative dataset expansion, and organizational involvement ensure the system's adaptability in diverse agricultural settings. The effect of the suggested system extends beyond automation, aiming to secure food supplies, protect livelihoods, and promote eco-friendly farming practices. By facilitating precise disease identification, the system contributes to sustainable and environmentally conscious agriculture, reducing reliance on pesticides. Looking to the future, the project envisions continuous development in RAG-integrated object detection systems, emphasizing scalability, reliability, and usability. This research strives to be a beacon for positive change in agriculture, aligning with global efforts toward sustainable and technologically enhanced food production.",
    "pdf_link": "https://arxiv.org/abs/2405.01310",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.01310v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01310/460.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.01310v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01310/34.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.01310v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01310/methodology1.png"
      }
    ],
    "abstract_cn": "本研究推出了一款创新的 AI 精准农业系统，采用 YOLOv8 技术进行病虫害识别，结合 RAG 技术实现智能诊断。该系统旨在应对卡纳塔克邦咖啡产业面临的病虫害挑战，通过融合先进的目标检测与语言模型技术，克服了大型语言模型（LLMs）的内在限制。我们的研究方法不仅解决了 LLMs 的幻觉问题，还提出了动态的病虫害识别与治理策略。系统通过实时监测、协作数据集扩充和组织参与，确保了在多样化农业场景中的适应性。该系统的影响不仅限于自动化水平的提升，更致力于保障食品供给、维护生计、推广环保农业。它通过精确识别病虫害，助力农业的可持续发展，减少对农药的依赖。展望未来，我们计划持续优化 RAG 集成的目标检测系统，注重系统的扩展性、可靠性与用户友好性。本研究力图为农业领域的积极变革提供指引，与全球推动可持续和科技提升型食品生产的大趋势相呼应。",
    "title_cn": "利用 RAG（Retrieval-Augmented Generation）技术提高精确度，有效应对大型语言模型在咖啡叶病害治理中的难题。",
    "tags": [
      "分类：RAG",
      "精准农业",
      "病虫害识别"
    ]
  },
  {
    "title": "The Effectiveness of LLMs as Annotators: A Comparative Overview and Empirical Analysis of Direct Representation",
    "submit_datetime": "2024年05月02日",
    "abstract": "Large Language Models (LLMs) have emerged as powerful support tools across various natural language tasks and a range of application domains. Recent studies focus on exploring their capabilities for data annotation. This paper provides a comparative overview of twelve studies investigating the potential of LLMs in labelling data. While the models demonstrate promising cost and time-saving benefits, there exist considerable limitations, such as representativeness, bias, sensitivity to prompt variations and English language preference. Leveraging insights from these studies, our empirical analysis further examines the alignment between human and GPT-generated opinion distributions across four subjective datasets. In contrast to the studies examining representation, our methodology directly obtains the opinion distribution from GPT. Our analysis thereby supports the minority of studies that are considering diverse perspectives when evaluating data annotation tasks and highlights the need for further research in this direction.",
    "pdf_link": "https://arxiv.org/abs/2405.01299",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.01299v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01299/armis_opinion_distributions.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01299v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01299/md_agree_opinion_distributions.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01299v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01299/hs_brexit_opinion_distributions.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01299v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01299/conv_abuse_opinion_distributions.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01299v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01299/ALL_entropy.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）在多种自然语言处理任务和应用领域中展现出强大的辅助作用。近期研究着重探讨了它们在数据标注上的应用潜力。本文综述了十二项研究，深入探讨了LLMs在数据标注方面的潜力。尽管这些模型在节省成本和时间上显示出了潜力，但它们也存在一些显著的限制，包括代表性问题、偏见、对提示变化的敏感性以及对英语的偏好。基于这些研究的洞察，我们进行了实证分析，比较了人类与GPT生成的意见分布，在四个主观数据集上的一致性。与以往关注代表性的研究不同，我们的方法直接从GPT中获取意见分布。我们的分析支持了那些在评估数据标注任务时考虑多元视角的研究，并强调了这一方向上进一步研究的必要性。",
    "title_cn": "探究大型语言模型作为注释工具的效能：一篇关于直接表征方法的对比概览与实证研究分析",
    "tags": [
      "LLM应用",
      "",
      "数据标注"
    ]
  },
  {
    "title": "Reinforcement Learning for Edit-Based Non-Autoregressive Neural Machine Translation",
    "submit_datetime": "2024年05月02日",
    "abstract": "Non-autoregressive (NAR) language models are known for their low latency in neural machine translation (NMT). However, a performance gap exists between NAR and autoregressive models due to the large decoding space and difficulty in capturing dependency between target words accurately. Compounding this, preparing appropriate training data for NAR models is a non-trivial task, often exacerbating exposure bias. To address these challenges, we apply reinforcement learning (RL) to Levenshtein Transformer, a representative edit-based NAR model, demonstrating that RL with self-generated data can enhance the performance of edit-based NAR models. We explore two RL approaches: stepwise reward maximization and episodic reward maximization. We discuss the respective pros and cons of these two approaches and empirically verify them. Moreover, we experimentally investigate the impact of temperature setting on performance, confirming the importance of proper temperature setting for NAR models' training.",
    "pdf_link": "https://arxiv.org/abs/2405.01280",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.01280v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01280/levt_en.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01280v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01280/method-v2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01280v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01280/stepwise.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01280v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01280/episodic.png"
      }
    ],
    "abstract_cn": "非自回归（NAR）语言模型在神经机器翻译（NMT）领域以其低延迟特性著称。但与自回归模型相比，NAR模型在性能上仍有差距，这主要是因为解码空间庞大，且捕捉目标词汇间依赖关系存在难度。此外，为NAR模型准备合适的训练数据并非易事，往往会加剧模型的暴露偏差问题。为了解决这些难题，我们对一个典型的基于编辑的NAR模型——Levenshtein Transformer——应用了强化学习（RL），发现通过RL结合自生成数据可以有效提升模型性能。我们对比了两种RL策略：逐步奖励最大化与情景奖励最大化，分析了它们的优劣，并进行了实证检验。同时，我们还探讨了温度参数设置对模型性能的影响，强调了适当温度设置在NAR模型训练中的关键作用。",
    "title_cn": "强化学习在基于编辑的非自回归神经机器翻译中的应用",
    "tags": [
      "分类：LLM应用\n\n这篇论文主要研究了非自回归（NAR）语言模型在神经机器翻译（NMT）领域的应用，通过应用强化学习（RL）来提升模型性能。这属于LLM应用的范畴，因为它涉及到了如何改进和应用现有的大型语言模型（LLM）来解决特定的问题。",
      "机器翻译",
      ""
    ]
  },
  {
    "title": "Prompt engineering paradigms for medical applications: scoping review and recommendations for better practices",
    "submit_datetime": "2024年05月02日",
    "abstract": "Prompt engineering is crucial for harnessing the potential of large language models (LLMs), especially in the medical domain where specialized terminology and phrasing is used. However, the efficacy of prompt engineering in the medical domain remains to be explored. In this work, 114 recent studies (2022-2024) applying prompt engineering in medicine, covering prompt learning (PL), prompt tuning (PT), and prompt design (PD) are reviewed. PD is the most prevalent (78 articles). In 12 papers, PD, PL, and PT terms were used interchangeably. ChatGPT is the most commonly used LLM, with seven papers using it for processing sensitive clinical data. Chain-of-Thought emerges as the most common prompt engineering technique. While PL and PT articles typically provide a baseline for evaluating prompt-based approaches, 64% of PD studies lack non-prompt-related baselines. We provide tables and figures summarizing existing work, and reporting recommendations to guide future research contributions.",
    "pdf_link": "https://arxiv.org/abs/2405.01249",
    "graphs": [],
    "abstract_cn": "在医疗领域，精心设计的提示对于解锁大型语言模型（LLMs）的潜能至关重要，尤其是在专业术语和表达方式频繁出现的情况下。尽管如此，提示工程在医疗领域的实际效果尚需进一步研究。本研究回顾了114篇最新文献（2022-2024年），这些文献探讨了在医学领域应用提示工程的案例，包括提示学习（PL）、提示调整（PT）和提示设计（PD）。其中，提示设计（PD）最为常见，共有78篇文章进行了讨论。在12篇论文中，PD、PL和PT这几个术语被混用。ChatGPT作为最广泛使用的LLM，有七篇论文中它被用来处理敏感的临床信息。思维链（Chain-of-Thought）成为最流行的提示工程技术。尽管PL和PT相关文章通常为评估基于提示的方法提供了基准，但有64%的PD研究缺少与提示无关的基准对比。我们提供了汇总现有研究成果的表格和图表，并提出了推进未来研究的建议。",
    "title_cn": "医疗领域提示工程的范式：全面审视与提升实践的建言",
    "tags": [
      "分类：LLM应用\n\n这篇论文的摘要主要讨论了在医疗领域应用大型语言模型（LLMs）时，提示工程的重要性和实际效果。它回顾了相关文献，分析了提示学习（PL）、提示调整（PT）和提示设计（PD）在医学领域的应用情况，并提出了未来研究的建议。这些内容都与LLMs在特定领域的应用实践相关，因此将其归类为\"LLM应用\"。",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Boosting Jailbreak Attack with Momentum",
    "submit_datetime": "2024年05月02日",
    "abstract": "Large Language Models (LLMs) have achieved remarkable success across diverse tasks, yet they remain vulnerable to adversarial attacks, notably the well-documented \\textit{jailbreak} attack. Recently, the Greedy Coordinate Gradient (GCG) attack has demonstrated efficacy in exploiting this vulnerability by optimizing adversarial prompts through a combination of gradient heuristics and greedy search. However, the efficiency of this attack has become a bottleneck in the attacking process. To mitigate this limitation, in this paper we rethink the generation of adversarial prompts through an optimization lens, aiming to stabilize the optimization process and harness more heuristic insights from previous iterations. Specifically, we introduce the \\textbf{M}omentum \\textbf{A}ccelerated G\\textbf{C}G (\\textbf{MAC}) attack, which incorporates a momentum term into the gradient heuristic. Experimental results showcase the notable enhancement achieved by MAP in gradient-based attacks on aligned language models. Our code is available at https://github.com/weizeming/momentum-attack-llm.",
    "pdf_link": "https://arxiv.org/abs/2405.01229",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）在众多任务上取得了令人瞩目的成就，但它们对对抗性攻击的脆弱性依旧，尤其是广为人知的“越狱”攻击。最近，贪婪坐标梯度（GCG）攻击通过梯度启发式和贪婪搜索的结合，有效利用了这一弱点。然而，该攻击的效率问题成为了攻击流程中的一个瓶颈。为了克服这一局限，本文提出了一种新的思考方式，通过优化方法生成对抗性提示，以稳定优化过程并从前几次迭代中获得更多启发。具体而言，我们提出了**动量加速 G** rady **C** oordinate **G** radient（**M** AC）攻击，它在梯度启发式中加入了动量因子。实验结果显示，MAC 在对齐语言模型的梯度攻击中实现了显著的性能提升。相关代码已在 https://github.com/weizeming/momentum-attack-llm 上发布。",
    "title_cn": "借助动量效应，提升越狱攻击的威力",
    "tags": [
      "分类：LLM应用",
      "网络安全",
      "机器学习"
    ]
  },
  {
    "title": "DLAP: A Deep Learning Augmented Large Language Model Prompting Framework for Software Vulnerability Detection",
    "submit_datetime": "2024年05月02日",
    "abstract": "Software vulnerability detection is generally supported by automated static analysis tools, which have recently been reinforced by deep learning (DL) models. However, despite the superior performance of DL-based approaches over rule-based ones in research, applying DL approaches to software vulnerability detection in practice remains a challenge due to the complex structure of source code, the black-box nature of DL, and the domain knowledge required to understand and validate the black-box results for addressing tasks after detection. Conventional DL models are trained by specific projects and, hence, excel in identifying vulnerabilities in these projects but not in others. These models with poor performance in vulnerability detection would impact the downstream tasks such as location and repair. More importantly, these models do not provide explanations for developers to comprehend detection results. In contrast, Large Language Models (LLMs) have made lots of progress in addressing these issues by leveraging prompting techniques. Unfortunately, their performance in identifying vulnerabilities is unsatisfactory. This paper contributes \\textbf{\\DLAP}, a \\underline{\\textbf{D}}eep \\underline{\\textbf{L}}earning \\underline{\\textbf{A}}ugmented LLMs \\underline{\\textbf{P}}rompting framework that combines the best of both DL models and LLMs to achieve exceptional vulnerability detection performance. Experimental evaluation results confirm that \\DLAP outperforms state-of-the-art prompting frameworks, including role-based prompts, auxiliary information prompts, chain-of-thought prompts, and in-context learning prompts, as well as fine-turning on multiple metrics.",
    "pdf_link": "https://arxiv.org/abs/2405.01202",
    "graphs": [],
    "abstract_cn": "软件漏洞检测多依赖于自动化静态分析工具，这些工具借助深度学习（DL）模型得到了显著提升。尽管DL在学术研究中展现出比传统规则基础方法更优异的性能，但实际应用中，由于源代码结构复杂、DL模型的不可解释性，以及解读DL模型“黑箱”结果所需的专业知识，使得DL在软件漏洞检测上的应用充满挑战。传统DL模型通常针对特定项目训练，导致其在其他项目中的漏洞检测能力不足，进而影响定位和修复等后续工作。此外，这些模型未能为开发者提供足够的解释来理解检测结果。与此相对，大型语言模型（LLMs）通过提示技术在这些问题上取得了显著进步，但在漏洞识别方面仍有提升空间。本文提出了\\textbf{\\DLAP}框架，一个结合了DL模型和LLMs优势的深度学习增强型LLMs提示框架，旨在实现卓越的漏洞检测效果。实验评估显示，\\DLAP在多个指标上超越了现有最先进的提示框架，包括角色提示、辅助信息提示、思维链提示和上下文学习提示，以及在多维度上的微调优化。",
    "title_cn": "DLAP：深度学习助力的大型语言模型提示框架，专为软件漏洞检测而设计。",
    "tags": [
      "LLM应用",
      "软件工程",
      "漏洞检测"
    ]
  },
  {
    "title": "Generative Relevance Feedback and Convergence of Adaptive Re-Ranking: University of Glasgow Terrier Team at TREC DL 2023",
    "submit_datetime": "2024年05月02日",
    "abstract": "This paper describes our participation in the TREC 2023 Deep Learning Track. We submitted runs that apply generative relevance feedback from a large language model in both a zero-shot and pseudo-relevance feedback setting over two sparse retrieval approaches, namely BM25 and SPLADE. We couple this first stage with adaptive re-ranking over a BM25 corpus graph scored using a monoELECTRA cross-encoder. We investigate the efficacy of these generative approaches for different query types in first-stage retrieval. In re-ranking, we investigate operating points of adaptive re-ranking with different first stages to find the point in graph traversal where the first stage no longer has an effect on the performance of the overall retrieval pipeline. We find some performance gains from the application of generative query reformulation. However, our strongest run in terms of P@10 and nDCG@10 applied both adaptive re-ranking and generative pseudo-relevance feedback, namely uogtr_b_grf_e_gb.",
    "pdf_link": "https://arxiv.org/abs/2405.01122",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.01122v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01122/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01122v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01122/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01122v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01122/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01122v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01122/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01122v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01122/x5.png"
      }
    ],
    "abstract_cn": "本文记录了我们在2023年TREC深度学习赛道的参与经历。我们提交的方案采用了大型语言模型提供的生成式相关性反馈，涉及零样本和伪相关性两种反馈模式，应用于BM25和SPlade两种稀疏检索技术。接着，我们通过BM25语料库图的自适应重新排序，利用monoELECTRA交叉编码器进行评分，以增强检索效果。我们探究了这些生成式方法在初步检索阶段对不同查询类型的有效性，并在重新排序阶段寻找自适应重新排序的最佳操作点，以确定第一阶段对整体检索流程性能的影响界限。尽管生成式查询重构带来了一定的性能提升，但我们在P@10和nDCG@10指标上表现最佳的方案是结合了自适应重新排序和生成式伪相关性反馈的uogtr_b_grf_e_gb。",
    "title_cn": "格拉斯哥大学的特里尔团队在2023年TREC DL竞赛中展示了他们在生成式相关反馈和自适应重排序技术方面的成果，这些技术在信息检索任务中实现了显著的收敛效果。",
    "tags": [
      "LLM应用",
      "信息检索",
      ""
    ]
  },
  {
    "title": "Efficient Data Generation for Source-grounded Information-seeking Dialogs: A Use Case for Meeting Transcripts",
    "submit_datetime": "2024年05月02日",
    "abstract": "Existing methods for creating source-grounded information-seeking dialog datasets are often costly and hard to implement due to their sole reliance on human annotators. We propose combining large language models (LLMs) prompting with human expertise for more efficient and reliable data generation. Instead of the labor-intensive Wizard-of-Oz (WOZ) method, where two annotators generate a dialog from scratch, role-playing agent and user, we use LLM generation to simulate the two roles. Annotators then verify the output and augment it with attribution data. We demonstrate our method by constructing MISeD -- Meeting Information Seeking Dialogs dataset -- the first information-seeking dialog dataset focused on meeting transcripts. Models finetuned with MISeD demonstrate superior performance on our test set, as well as on a novel fully-manual WOZ test set and an existing query-based summarization benchmark, suggesting the utility of our approach.",
    "pdf_link": "https://arxiv.org/abs/2405.01121",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.01121v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01121/fig-dialog-generation.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01121v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01121/fig-task-description.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01121v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01121/fig-transcript-and-attribution-plots.png"
      }
    ],
    "abstract_cn": "传统方法在构建基于源头的信息搜寻对话数据集时，因完全依赖人工标注而成本高昂且实施困难。我们提出一种新方法，结合大型语言模型（LLMs）的提示和人类专家知识，以提高数据生成的效率和可靠性。与传统的“幕后巫师”（WOZ）方法相比，该方法不再需要两名标注者从头开始构建对话，扮演代理和用户角色，而是利用LLM生成技术来模拟这两个角色。标注者随后对生成的内容进行验证，并添加归因数据。我们通过创建MISeD——首个专注于会议记录的信息搜寻对话数据集——来验证这种方法。使用MISeD数据集进行微调的模型不仅在我们的测试集中表现出色，也在全新的全手动WOZ测试集和现有的基于查询的摘要基准测试中展现了优越性能，这证明了我们方法的有效性。",
    "title_cn": "高效数据生成：以会议记录为信息寻求型源-地面对话的用例",
    "tags": [
      "LLM应用",
      "对话系统",
      ""
    ]
  },
  {
    "title": "\"In-Context Learning\" or: How I learned to stop worrying and love \"Applied Information Retrieval\"",
    "submit_datetime": "2024年05月02日",
    "abstract": "With the increasing ability of large language models (LLMs), in-context learning (ICL) has evolved as a new paradigm for natural language processing (NLP), where instead of fine-tuning the parameters of an LLM specific to a downstream task with labeled examples, a small number of such examples is appended to a prompt instruction for controlling the decoder's generation process. ICL, thus, is conceptually similar to a non-parametric approach, such as $k$-NN, where the prediction for each instance essentially depends on the local topology, i.e., on a localised set of similar instances and their labels (called few-shot examples). This suggests that a test instance in ICL is analogous to a query in IR, and similar examples in ICL retrieved from a training set relate to a set of documents retrieved from a collection in IR. While standard unsupervised ranking models can be used to retrieve these few-shot examples from a training set, the effectiveness of the examples can potentially be improved by re-defining the notion of relevance specific to its utility for the downstream task, i.e., considering an example to be relevant if including it in the prompt instruction leads to a correct prediction. With this task-specific notion of relevance, it is possible to train a supervised ranking model (e.g., a bi-encoder or cross-encoder), which potentially learns to optimally select the few-shot examples. We believe that the recent advances in neural rankers can potentially find a use case for this task of optimally choosing examples for more effective downstream ICL predictions.",
    "pdf_link": "https://arxiv.org/abs/2405.01116",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.01116v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01116/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01116v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01116/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01116v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01116/x3.png"
      }
    ],
    "abstract_cn": "随着大型语言模型（LLMs）能力的提升，上下文学习（ICL）已成为自然语言处理（NLP）的新趋势。与传统的微调方法不同，ICL通过将少量标注示例添加到提示指令中，来引导模型的解码生成过程，而不是对模型参数进行特定任务的微调。这种方法在理念上与非参数方法如$k$-NN相似，预测结果依赖于局部拓扑结构，即一组相似的实例及其标签（称为少量示例）。在ICL中，测试实例与信息检索（IR）中的查询相似，而从训练集中检索的类似示例则相当于从IR集合中检索的文档集。虽然可以使用标准的无监督排名模型来检索这些少量示例，但通过针对下游任务重新定义相关性的概念，可以提升示例的有效性。换句话说，如果将一个示例包含在提示指令中能够导致正确预测，那么这个示例就被认为是相关的。基于这种任务特定的相关性概念，可以训练一个有监督的排名模型，如双编码器或交叉编码器，以学习如何最优地选择少量示例。我们认为，神经排名器的最新进展可能为选择最佳示例以提高ICL预测效果提供了新的应用场景。",
    "title_cn": "《上下文学习》：我如何学会不再担忧并拥抱“应用信息检索”的世界",
    "tags": [
      "LLM应用",
      "",
      "信息检索"
    ]
  },
  {
    "title": "LLM Security Guard for Code",
    "submit_datetime": "2024年05月02日",
    "abstract": "Many developers rely on Large Language Models (LLMs) to facilitate software development. Nevertheless, these models have exhibited limited capabilities in the security domain. We introduce LLMSecGuard, an open-source framework that offers enhanced code security through the synergy between static code analyzers and LLMs. LLMSecGuard aims to equip practitioners with code solutions that are more secure than the code initially generated by LLMs. It also benchmarks LLMs, providing valuable insights into the evolving security properties of these models.",
    "pdf_link": "https://arxiv.org/abs/2405.01103",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.01103v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01103/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01103v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01103/x2.png"
      }
    ],
    "abstract_cn": "众多开发者借助大型语言模型（LLMs）推进软件开发。尽管如此，这些模型在安全领域的应用能力尚显不足。我们推出了LLMSecGuard，一个开源的框架，它通过结合静态代码分析工具与LLMs的力量，增强了代码的安全性。LLMSecGuard的目的是为开发者提供比LLMs原始生成的代码更为安全的解决方案。此外，它还对LLMs进行性能评估，以洞察这些模型安全特性的演进趋势。",
    "title_cn": "大型语言模型的安全守护者：代码防护",
    "tags": [
      "LLM应用",
      "软件开发",
      ""
    ]
  },
  {
    "title": "Learning Object States from Actions via Large Language Models",
    "submit_datetime": "2024年05月02日",
    "abstract": "Temporally localizing the presence of object states in videos is crucial in understanding human activities beyond actions and objects. This task has suffered from a lack of training data due to object states' inherent ambiguity and variety. To avoid exhaustive annotation, learning from transcribed narrations in instructional videos would be intriguing. However, object states are less described in narrations compared to actions, making them less effective. In this work, we propose to extract the object state information from action information included in narrations, using large language models (LLMs). Our observation is that LLMs include world knowledge on the relationship between actions and their resulting object states, and can infer the presence of object states from past action sequences. The proposed LLM-based framework offers flexibility to generate plausible pseudo-object state labels against arbitrary categories. We evaluate our method with our newly collected Multiple Object States Transition (MOST) dataset including dense temporal annotation of 60 object state categories. Our model trained by the generated pseudo-labels demonstrates significant improvement of over 29% in mAP against strong zero-shot vision-language models, showing the effectiveness of explicitly extracting object state information from actions through LLMs.",
    "pdf_link": "https://arxiv.org/abs/2405.01090",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.01090v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01090/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01090v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01090/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01090v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01090/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01090v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01090/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01090v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01090/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01090v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01090/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01090v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01090/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01090v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01090/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01090v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01090/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01090v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01090/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01090v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01090/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01090v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01090/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01090v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01090/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01090v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01090/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01090v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01090/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01090v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01090/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01090v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01090/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01090v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01090/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01090v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01090/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01090v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01090/x20.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01090v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01090/x21.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01090v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01090/x22.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01090v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01090/x23.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01090v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01090/x24.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01090v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01090/x25.png"
      }
    ],
    "abstract_cn": "在视频分析中，准确识别对象状态的时间位置对于深入理解人类行为极为关键。然而，由于对象状态的复杂多变，相关训练数据的匮乏一直是研究的瓶颈。传统的详尽标注方法耗时且效率低下，因此，我们探索了一种新颖的方法：从教学视频的旁白中学习。尽管如此，与动作描述相比，对象状态在旁白中的描述较为简略，导致信息捕捉不足。本研究提出了一种创新框架，利用大型语言模型（LLMs）从旁白中的动作描述推断出对象状态信息。我们发现，LLMs能够利用其内置的世界知识，理解动作与随后对象状态之间的联系，并从动作序列中预测对象状态。此外，该框架的灵活性允许它为任意类别生成看似合理的伪对象状态标签。为了验证我们的方法，我们创建了一个新的数据集——多对象状态转换（MOST），它包含了60个对象状态类别的密集时间标注。在该数据集上，我们训练的模型使用生成的伪标签，与现有的强大零样本视觉-语言模型相比，在平均精度（mAP）上实现了超过29%的显著提升，从而证明了我们通过LLMs从动作中提取对象状态信息方法的有效性。",
    "title_cn": "利用大型语言模型从动作中学习对象状态。",
    "tags": [
      "LLM应用",
      "视频分析",
      "人工智能"
    ]
  },
  {
    "title": "Generating User Experience Based on Personas with AI Assistants",
    "submit_datetime": "2024年05月02日",
    "abstract": "Traditional UX development methodologies focus on developing ``one size fits all\" solutions and lack the flexibility to cater to diverse user needs. In response, a growing interest has arisen in developing more dynamic UX frameworks. However, existing approaches often cannot personalise user experiences and adapt to user feedback in real-time. Therefore, my research introduces a novel approach of combining Large Language Models and personas, to address these limitations. The research is structured around three areas: (1) a critical review of existing adaptive UX practices and the potential for their automation; (2) an investigation into the role and effectiveness of personas in enhancing UX adaptability; and (3) the proposal of a theoretical framework that leverages LLM capabilities to create more dynamic and responsive UX designs and guidelines.",
    "pdf_link": "https://arxiv.org/abs/2405.01051",
    "graphs": [],
    "abstract_cn": "传统UX开发方法倾向于提供通用解决方案，忽略了用户需求的多样性。为了解决这一问题，越来越多的研究者开始探索更具灵活性的UX设计框架。但目前的方法往往难以实现用户体验的个性化或实时响应用户反馈。本研究提出了一种创新的方法，将大型语言模型与角色原型相结合，以克服这些挑战。研究主要分为三个部分：首先，对现有自适应UX实践进行深入分析，并探讨其自动化的可能性；其次，研究角色原型在提升UX适应性方面的作用与效果；最后，提出一个理论框架，该框架利用大型语言模型的潜力，以打造更加动态和响应用户需求的UX设计和指导原则。",
    "title_cn": "利用人工智能助手，根据人物角色创造用户体验",
    "tags": [
      "LLM应用",
      "用户体验设计",
      "自适应系统"
    ]
  },
  {
    "title": "Causal Influence in Federated Edge Inference",
    "submit_datetime": "2024年05月02日",
    "abstract": "In this paper, we consider a setting where heterogeneous agents with connectivity are performing inference using unlabeled streaming data. Observed data are only partially informative about the target variable of interest. In order to overcome the uncertainty, agents cooperate with each other by exchanging their local inferences with and through a fusion center. To evaluate how each agent influences the overall decision, we adopt a causal framework in order to distinguish the actual influence of agents from mere correlations within the decision-making process. Various scenarios reflecting different agent participation patterns and fusion center policies are investigated. We derive expressions to quantify the causal impact of each agent on the joint decision, which could be beneficial for anticipating and addressing atypical scenarios, such as adversarial attacks or system malfunctions. We validate our theoretical results with numerical simulations and a real-world application of multi-camera crowd counting.",
    "pdf_link": "https://arxiv.org/abs/2405.01260",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.01260v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01260/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01260v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01260/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01260v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01260/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01260v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01260/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01260v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01260/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01260v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01260/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01260v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01260/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01260v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01260/00001965_c1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01260v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01260/00001965_c3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01260v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01260/00001965_c6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01260v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01260/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01260v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01260/x9.png"
      }
    ],
    "abstract_cn": "本文探讨了一个场景，异构智能体通过未标记的实时数据进行推理，而这些数据对于目标变量的信息提供有限。为了应对不确定性，智能体们通过融合中心交换各自的局部推断结果，实现协同合作。本研究采用因果框架来评估每个智能体对集体决策的具体影响，区分了智能体的实际影响力与决策过程中的表面相关性。研究涵盖了多种不同智能体参与模式和融合中心策略的情景。我们建立了计算每个智能体对共同决策因果影响的公式，这对于预测和处理如对抗性攻击或系统故障等异常情况具有重要意义。理论分析通过数值模拟和实际的多摄像头人群计数应用得到了验证。",
    "title_cn": "在联合边缘推理领域，因果关系的影响是一个关键因素。",
    "tags": [
      "Agent",
      "智能体系统",
      "因果推断"
    ]
  },
  {
    "title": "Improving Concept Alignment in Vision-Language Concept Bottleneck Models",
    "submit_datetime": "2024年05月02日",
    "abstract": "Concept Bottleneck Models (CBM) map the input image to a high-level human-understandable concept space and then make class predictions based on these concepts. Recent approaches automate the construction of CBM by prompting Large Language Models (LLM) to generate text concepts and then use Vision Language Models (VLM) to obtain concept scores to train a CBM. However, it is desired to build CBMs with concepts defined by human experts instead of LLM generated concepts to make them more trustworthy. In this work, we take a closer inspection on the faithfulness of VLM concept scores for such expert-defined concepts in domains like fine-grain bird species classification and animal classification. Our investigations reveal that frozen VLMs, like CLIP, struggle to correctly associate a concept to the corresponding visual input despite achieving a high classification performance. To address this, we propose a novel Contrastive Semi-Supervised (CSS) learning method which uses a few labeled concept examples to improve concept alignment (activate truthful visual concepts) in CLIP model. Extensive experiments on three benchmark datasets show that our approach substantially increases the concept accuracy and classification accuracy, yet requires only a fraction of the human-annotated concept labels. To further improve the classification performance, we also introduce a new class-level intervention procedure for fine-grain classification problems that identifies the confounding classes and intervenes their concept space to reduce errors.",
    "pdf_link": "https://arxiv.org/abs/2405.01825",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.01825v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01825/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01825v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01825/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01825v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01825/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01825v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01825/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01825v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01825/x5.png"
      }
    ],
    "abstract_cn": "概念瓶颈模型（CBM）通过将输入图像转换为易于人类理解的高级概念空间来进行类别预测。最新研究通过激发大型语言模型（LLM）产生文本概念，并借助视觉语言模型（VLM）获取这些概念的评分来自动化构建CBM。尽管如此，为了提高模型的可信度，我们更倾向于采用人类专家而非LLM生成的概念来定义CBM。本研究深入探讨了在细粒度鸟类分类和动物分类等特定领域内，VLM对于专家定义概念的评分准确性。研究发现，即便是表现出色的CLIP等固定VLM在将概念与视觉输入正确关联方面也存在挑战。为此，我们提出了一种创新的对比半监督（CSS）学习方法，该方法利用少量标记化的概念实例来优化CLIP模型中的概念匹配，激活真实的视觉概念。在三大基准数据集上的广泛测试显示，这种方法显著提升了概念和分类的准确性，同时大幅减少了对人工标注概念标签的需求。此外，为了进一步提升分类效果，我们还开发了一种新的类级干预流程，专门针对细粒度分类问题，通过识别并干预混淆类别的概念空间来降低错误率。",
    "title_cn": "提升视觉-语言概念瓶颈模型中的概念一致性",
    "tags": [
      "分类：LLM应用",
      "计算机视觉",
      ""
    ]
  },
  {
    "title": "Efficient and Economic Large Language Model Inference with Attention Offloading",
    "submit_datetime": "2024年05月02日",
    "abstract": "Transformer-based large language models (LLMs) exhibit impressive performance in generative tasks but introduce significant challenges in real-world serving due to inefficient use of the expensive, computation-optimized accelerators. This mismatch arises from the autoregressive nature of LLMs, where the generation phase comprises operators with varying resource demands. Specifically, the attention operator is memory-intensive, exhibiting a memory access pattern that clashes with the strengths of modern accelerators, especially as context length increases. To enhance the efficiency and cost-effectiveness of LLM serving, we introduce the concept of attention offloading. This approach leverages a collection of cheap, memory-optimized devices for the attention operator while still utilizing high-end accelerators for other parts of the model. This heterogeneous setup ensures that each component is tailored to its specific workload, maximizing overall performance and cost efficiency. Our comprehensive analysis and experiments confirm the viability of splitting the attention computation over multiple devices. Also, the communication bandwidth required between heterogeneous devices proves to be manageable with prevalent networking technologies. To further validate our theory, we develop Lamina, an LLM inference system that incorporates attention offloading. Experimental results indicate that Lamina can provide 1.48x-12.1x higher estimated throughput per dollar than homogeneous solutions.",
    "pdf_link": "https://arxiv.org/abs/2405.01814",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.01814v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01814/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01814v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01814/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01814v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01814/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01814v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01814/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01814v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01814/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01814v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01814/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01814v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01814/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01814v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01814/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01814v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01814/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01814v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01814/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01814v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01814/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01814v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01814/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01814v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01814/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01814v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01814/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01814v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01814/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01814v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01814/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01814v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01814/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01814v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01814/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01814v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01814/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01814v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01814/x20.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01814v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01814/x21.png"
      }
    ],
    "abstract_cn": "基于 Transformer 的大型语言模型（LLM）在创造性任务上有着令人瞩目的表现，但在现实应用中，由于对成本高昂、计算优化的加速器使用效率不高，面临不小的挑战。这一问题主要来自于 LLM 的自回归特性，其生成阶段涉及资源需求各异的操作。特别是，注意力机制作为内存消耗大户，其内存访问模式与现代加速器的优势不匹配，尤其是在处理更长上下文时。为了提升 LLM 在服务端的效率和经济性，我们提出了“注意力卸载”的新概念。这种方法通过使用成本较低、内存优化的设备来处理注意力机制，同时保留高端加速器来执行模型的其他部分。这种混合配置确保了每个组件都能针对其工作负载进行优化，从而实现性能和成本效率的最大化。我们通过深入分析和实验验证了跨多个设备分配注意力计算的可行性，并且异构设备间的通信带宽需求也可以通过现有的网络技术得到有效控制。为了实践我们的设想，我们构建了 Lamina，这是一个集成了注意力卸载功能的 LLM 推理系统。实验数据显示，Lamina 在每投资一美元的情况下，能够实现比传统同质解决方案高达 1.48 至 12.1 倍的吞吐量。",
    "title_cn": "通过注意力卸载实现大型语言模型的高效经济推理",
    "tags": [
      "LLM应用",
      "",
      "计算优化"
    ]
  },
  {
    "title": "Exploiting ChatGPT for Diagnosing Autism-Associated Language Disorders and Identifying Distinct Features",
    "submit_datetime": "2024年05月02日",
    "abstract": "Diagnosing language disorders associated with autism is a complex and nuanced challenge, often hindered by the subjective nature and variability of traditional assessment methods. Traditional diagnostic methods not only require intensive human effort but also often result in delayed interventions due to their lack of speed and specificity. In this study, we explored the application of ChatGPT, a state of the art large language model, to overcome these obstacles by enhancing diagnostic accuracy and profiling specific linguistic features indicative of autism. Leveraging ChatGPT advanced natural language processing capabilities, this research aims to streamline and refine the diagnostic process. Specifically, we compared ChatGPT's performance with that of conventional supervised learning models, including BERT, a model acclaimed for its effectiveness in various natural language processing tasks. We showed that ChatGPT substantially outperformed these models, achieving over 13% improvement in both accuracy and F1 score in a zero shot learning configuration. This marked enhancement highlights the model potential as a superior tool for neurological diagnostics. Additionally, we identified ten distinct features of autism associated language disorders that vary significantly across different experimental scenarios. These features, which included echolalia, pronoun reversal, and atypical language usage, were crucial for accurately diagnosing ASD and customizing treatment plans. Together, our findings advocate for adopting sophisticated AI tools like ChatGPT in clinical settings to assess and diagnose developmental disorders. Our approach not only promises greater diagnostic precision but also aligns with the goals of personalized medicine, potentially transforming the evaluation landscape for autism and similar neurological conditions.",
    "pdf_link": "https://arxiv.org/abs/2405.01799",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.01799v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01799/correlation_matrix_heatmap.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.01799v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01799/correlation_matrix_heatmap_3.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.01799v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01799/correlation_matrix_heatmap_9.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.01799v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01799/GPT_autism_structure.jpg"
      }
    ],
    "abstract_cn": "自闭症相关语言障碍的诊断充满挑战，常因传统评估手段的主观多变而受阻。本研究尝试利用尖端的大型语言模型 ChatGPT，通过提升诊断精确度和识别自闭症特征性语言特征，来解决这些难题。ChatGPT 的高级自然语言处理技术有助于优化诊断流程。在与包括 BERT 在内的常规监督学习模型对比中，ChatGPT 在零样本学习情境下的表现显著更佳，准确度和 F1 分数均提升了超过 13%，显示出其作为神经学诊断工具的巨大潜力。研究还识别了与自闭症语言障碍相关的十个关键特征，如回声言语、代词颠倒和异常语言使用，这些对于精确诊断 ASD 和制定个性化治疗方案至关重要。研究结果鼓励在临床环境中采用 ChatGPT 等先进 AI 工具，以提高诊断精确度，并推动个性化医疗的发展，为自闭症等神经发育障碍的评估带来革新。",
    "title_cn": "通过 ChatGPT 来识别自闭症相关的语言障碍，并挖掘其独特的特征。",
    "tags": [
      "LLM应用",
      "神经科学",
      "医疗诊断"
    ]
  },
  {
    "title": "Towards Neural Synthesis for SMT-Assisted Proof-Oriented Programming",
    "submit_datetime": "2024年05月02日",
    "abstract": "Proof-oriented programs mix computational content with proofs of program correctness. However, the human effort involved in programming and proving is still substantial, despite the use of Satisfiability Modulo Theories (SMT) solvers to automate proofs in languages such as F*.\n  Seeking to spur research on using AI to automate the construction of proof-oriented programs, we curate a dataset of 600K lines of open-source F* programs and proofs, including software used in production systems ranging from Windows and Linux, to Python and Firefox. Our dataset includes around 32K top-level F* definitions, each representing a type-directed program and proof synthesis problem -- producing a definition given a formal specification expressed as an F* type. We provide a program-fragment checker that queries F* to check the correctness of candidate solutions. We believe this is the largest corpus of SMT-assisted program proofs coupled with a reproducible program-fragment checker.\n  Grounded in this dataset, we investigate the use of AI to synthesize programs and their proofs in F*, with promising results. Our main finding in that the performance of fine-tuned smaller language models (such as Phi-2 or StarCoder) compare favorably with large language models (such as GPT-4), at a much lower computational cost. We also identify various type-based retrieval augmentation techniques and find that they boost performance significantly. With detailed error analysis and case studies, we identify potential strengths and weaknesses of models and techniques and suggest directions for future improvements.",
    "pdf_link": "https://arxiv.org/abs/2405.01787",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.01787v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01787/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01787v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01787/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01787v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01787/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01787v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01787/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01787v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01787/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01787v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01787/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01787v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01787/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01787v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01787/x8.png"
      }
    ],
    "abstract_cn": "面向证明的编程将计算逻辑与程序正确性的证明融为一体，尽管利用了如 F* 语言中的可满足性模态理论（SMT）求解器来自动化证明过程，但人工编程与证明的工作量依然不小。为了推动利用人工智能自动化构建面向证明的程序的研究，我们汇集了一个包含60万行开源F*程序和证明的数据库，涵盖了从Windows、Linux到Python、Firefox等多个生产系统中使用的软件。该数据库包含约3.2万个顶级F*定义，每个定义都代表着一个基于类型的程序和证明合成问题——即在给定F*类型形式规范的情况下生成定义。我们还提供了一个程序片段检查工具，用以查询F*并验证候选解决方案的正确性。我们认为这是迄今为止最大的结合了可复现程序片段检查器的SMT辅助程序证明集合。依托此数据库，我们探究了利用人工智能在F*中合成程序及其证明的可能性，并取得了令人鼓舞的成果。我们的主要发现是，经过微调的小型语言模型（例如Phi-2或StarCoder）在性能上与大型语言模型（如GPT-4）相媲美，且计算成本更低。我们还识别了多种基于类型的检索增强技术，并发现这些技术能显著提升性能。通过深入的错误分析和案例研究，我们揭示了模型和技术的潜在优势与局限，并为未来的优化方向提供了建议。",
    "title_cn": "探索神经合成技术，助力 SMT 支持的面向证明编程发展",
    "tags": [
      "分类：LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "A Survey on Large Language Models for Critical Societal Domains: Finance, Healthcare, and Law",
    "submit_datetime": "2024年05月02日",
    "abstract": "In the fast-evolving domain of artificial intelligence, large language models (LLMs) such as GPT-3 and GPT-4 are revolutionizing the landscapes of finance, healthcare, and law: domains characterized by their reliance on professional expertise, challenging data acquisition, high-stakes, and stringent regulatory compliance. This survey offers a detailed exploration of the methodologies, applications, challenges, and forward-looking opportunities of LLMs within these high-stakes sectors. We highlight the instrumental role of LLMs in enhancing diagnostic and treatment methodologies in healthcare, innovating financial analytics, and refining legal interpretation and compliance strategies. Moreover, we critically examine the ethics for LLM applications in these fields, pointing out the existing ethical concerns and the need for transparent, fair, and robust AI systems that respect regulatory norms. By presenting a thorough review of current literature and practical applications, we showcase the transformative impact of LLMs, and outline the imperative for interdisciplinary cooperation, methodological advancements, and ethical vigilance. Through this lens, we aim to spark dialogue and inspire future research dedicated to maximizing the benefits of LLMs while mitigating their risks in these precision-dependent sectors. To facilitate future research on LLMs in these critical societal domains, we also initiate a reading list that tracks the latest advancements under this topic, which will be continually updated: \\url{https://github.com/czyssrs/LLM_X_papers}.",
    "pdf_link": "https://arxiv.org/abs/2405.01769",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.01769v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01769/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01769v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01769/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01769v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01769/x3.png"
      }
    ],
    "abstract_cn": "在人工智能迅猛发展的今天，大型语言模型（LLMs）如 GPT-3 和 GPT-4 正在金融、医疗和法律等专业领域掀起革命。这些领域依赖专业知识、面临数据获取难题、风险高且法规要求严格。本篇综述深入探讨了 LLMs 在这些高风险行业的应用方法、实践案例、所遇挑战及未来机遇。我们突出了 LLMs 在医疗领域改进诊疗手段、金融领域创新分析技术、以及法律领域提升解释和合规策略中的关键作用。同时，我们也对这些领域中 LLM 应用的伦理问题进行了深入分析，指出了现存的伦理顾虑，并强调了开发透明、公正、强大且符合法规的 AI 系统的必要性。通过全面审视现有文献和实际应用案例，我们展示了 LLMs 的深远影响，并强调了跨学科合作、方法论创新和伦理警觉性的重要性。我们希望通过这些视角激发讨论，激发未来研究，旨在最大化 LLMs 的正面影响，同时减少在这些对精度要求极高的领域中的风险。为了推动这些关键社会领域中 LLM 的研究，我们还建立了一个持续更新的阅读清单，以追踪该主题的最新进展：\\url{https://github.com/czyssrs/LLM_X_papers}。",
    "title_cn": "一项针对金融、医疗保健和法律等关键社会领域内大型语言模型的综述研究",
    "tags": [
      "LLM应用",
      "",
      ""
    ]
  },
  {
    "title": "CoS: Enhancing Personalization and Mitigating Bias with Context Steering",
    "submit_datetime": "2024年05月02日",
    "abstract": "When querying a large language model (LLM), the context, i.e. personal, demographic, and cultural information specific to an end-user, can significantly shape the response of the LLM. For example, asking the model to explain Newton's second law with the context \"I am a toddler\" yields a different answer compared to the context \"I am a physics professor.\" Proper usage of the context enables the LLM to generate personalized responses, whereas inappropriate contextual influence can lead to stereotypical and potentially harmful generations (e.g. associating \"female\" with \"housekeeper\"). In practice, striking the right balance when leveraging context is a nuanced and challenging problem that is often situation-dependent. One common approach to address this challenge is to fine-tune LLMs on contextually appropriate responses. However, this approach is expensive, time-consuming, and not controllable for end-users in different situations. In this work, we propose Context Steering (CoS) - a simple training-free method that can be easily applied to autoregressive LLMs at inference time. By measuring the contextual influence in terms of token prediction likelihood and modulating it, our method enables practitioners to determine the appropriate level of contextual influence based on their specific use case and end-user base. We showcase a variety of applications of CoS including amplifying the contextual influence to achieve better personalization and mitigating unwanted influence for reducing model bias. In addition, we show that we can combine CoS with Bayesian Inference to quantify the extent of hate speech on the internet. We demonstrate the effectiveness of CoS on state-of-the-art LLMs and benchmarks.",
    "pdf_link": "https://arxiv.org/abs/2405.01768",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.01768v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01768/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01768v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01768/lanmbda_inference_qualitative_v2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01768v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01768/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01768v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01768/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01768v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01768/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01768v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01768/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01768v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01768/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01768v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01768/exp4-3-hate-quantify_v1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01768v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01768/appendix_lanmbda_inference_qualitative_v0.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01768v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01768/x22.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01768v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01768/x23.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01768v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01768/x24.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01768v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01768/x25.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01768v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01768/x26.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01768v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01768/x27.png"
      }
    ],
    "abstract_cn": "在向大型语言模型（LLM）发起查询时，上下文信息——包括个人、人口统计和文化背景等用户特定信息——会显著影响模型的回复。比如，以“我是一个小孩子”为上下文询问牛顿第二定律，与以“我是一名物理教授”为上下文得到的回答会有所差异。恰当地利用上下文能够让LLM提供定制化的回答，而不当的上下文应用则可能产生刻板且可能有害的输出（如将“女性”等同于“家政妇”）。实际操作中，如何恰当地利用上下文是一个复杂且充满挑战的任务，往往因情况而异。一种常见的解决方案是对LLM进行微调，以便其能够根据上下文适当的回答进行学习。但这种方法成本高、耗时长，且对于不同场景下的最终用户而言难以控制。在本项研究中，我们提出了一种名为上下文引导（CoS）的新方法，它无需额外训练即可在自动回归LLM的推理阶段轻松应用。通过评估上下文对词符预测可能性的影响并进行调节，CoS方法允许用户根据具体应用场景和目标用户群体来确定恰当的上下文影响程度。我们展示了CoS在多种场景下的应用，包括增强上下文影响以提升个性化服务，以及减少不当影响以降低模型偏见。此外，我们还展示了CoS可以与贝叶斯推断结合使用，以评估互联网上仇恨言论的规模。我们在当前最先进的LLM和相关基准测试中验证了CoS的有效性。",
    "title_cn": "CoS技术：借助上下文导航，提升个性化体验，同时有效降低偏见风险。",
    "tags": [
      "LLM应用",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Large Language Models for UAVs: Current State and Pathways to the Future",
    "submit_datetime": "2024年05月02日",
    "abstract": "Unmanned Aerial Vehicles (UAVs) have emerged as a transformative technology across diverse sectors, offering adaptable solutions to complex challenges in both military and civilian domains. Their expanding capabilities present a platform for further advancement by integrating cutting-edge computational tools like Artificial Intelligence (AI) and Machine Learning (ML) algorithms. These advancements have significantly impacted various facets of human life, fostering an era of unparalleled efficiency and convenience. Large Language Models (LLMs), a key component of AI, exhibit remarkable learning and adaptation capabilities within deployed environments, demonstrating an evolving form of intelligence with the potential to approach human-level proficiency. This work explores the significant potential of integrating UAVs and LLMs to propel the development of autonomous systems. We comprehensively review LLM architectures, evaluating their suitability for UAV integration. Additionally, we summarize the state-of-the-art LLM-based UAV architectures and identify novel opportunities for LLM embedding within UAV frameworks. Notably, we focus on leveraging LLMs to refine data analysis and decision-making processes, specifically for enhanced spectral sensing and sharing in UAV applications. Furthermore, we investigate how LLM integration expands the scope of existing UAV applications, enabling autonomous data processing, improved decision-making, and faster response times in emergency scenarios like disaster response and network restoration. Finally, we highlight crucial areas for future research that are critical for facilitating the effective integration of LLMs and UAVs.",
    "pdf_link": "https://arxiv.org/abs/2405.01745",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.01745v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01745/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01745v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01745/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01745v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01745/x3.png"
      }
    ],
    "abstract_cn": "无人机（UAVs）正以其革新性技术在多个行业中崭露头角，为军事及民用领域的复杂问题提供多样化的解决方案。它们日益增强的功能为进一步的技术进步奠定了基础，尤其是通过融合先进的计算技术，如人工智能（AI）和机器学习（ML）算法。这些技术的发展极大地推动了人类生活的各个方面，开启了一个高效与便捷并存的新时代。作为AI核心的大型语言模型（LLMs）在实际应用中展现出了卓越的学习和适应能力，预示着一种向人类专业水平看齐的智能进化。本文深入探讨了将UAVs与LLMs结合的巨大潜力，以加速自主系统的发展。我们全面审视了LLM架构，并评估了它们与UAV整合的契合度。同时，我们概述了基于LLM的UAV架构的最新发展，并探索了LLM在UAV框架中嵌入的新机遇。特别地，我们着眼于利用LLMs优化UAV应用中的数据分析和决策流程，尤其是在提升光谱感知和数据共享方面。此外，我们还探讨了LLM整合如何拓展UAV应用的边界，实现自动化数据处理、优化决策制定，并在紧急情况下如灾难响应和网络恢复中提高响应速度。最后，我们指出了未来研究的关键方向，这些研究对于促进LLMs与UAVs的有效融合至关重要。",
    "title_cn": "无人机领域的大型语言模型：现状与未来展望。",
    "tags": [
      "分类：Agent",
      "无人机",
      "人工智能"
    ]
  },
  {
    "title": "ALCM: Autonomous LLM-Augmented Causal Discovery Framework",
    "submit_datetime": "2024年05月02日",
    "abstract": "To perform effective causal inference in high-dimensional datasets, initiating the process with causal discovery is imperative, wherein a causal graph is generated based on observational data. However, obtaining a complete and accurate causal graph poses a formidable challenge, recognized as an NP-hard problem. Recently, the advent of Large Language Models (LLMs) has ushered in a new era, indicating their emergent capabilities and widespread applicability in facilitating causal reasoning across diverse domains, such as medicine, finance, and science. The expansive knowledge base of LLMs holds the potential to elevate the field of causal reasoning by offering interpretability, making inferences, generalizability, and uncovering novel causal structures. In this paper, we introduce a new framework, named Autonomous LLM-Augmented Causal Discovery Framework (ALCM), to synergize data-driven causal discovery algorithms and LLMs, automating the generation of a more resilient, accurate, and explicable causal graph. The ALCM consists of three integral components: causal structure learning, causal wrapper, and LLM-driven causal refiner. These components autonomously collaborate within a dynamic environment to address causal discovery questions and deliver plausible causal graphs. We evaluate the ALCM framework by implementing two demonstrations on seven well-known datasets. Experimental results demonstrate that ALCM outperforms existing LLM methods and conventional data-driven causal reasoning mechanisms. This study not only shows the effectiveness of the ALCM but also underscores new research directions in leveraging the causal reasoning capabilities of LLMs.",
    "pdf_link": "https://arxiv.org/abs/2405.01744",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.01744v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01744/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01744v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01744/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01744v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01744/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01744v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01744/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01744v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01744/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01744v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01744/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01744v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01744/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01744v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01744/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01744v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01744/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01744v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01744/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01744v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01744/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01744v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01744/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01744v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01744/x13.png"
      }
    ],
    "abstract_cn": "在高维数据集上进行高效的因果推断，首先进行因果发现至关重要，即基于观测数据构建因果图。然而，构建一个完整准确的因果图面临巨大挑战，这是一个公认的NP-hard问题。大型语言模型（LLMs）的兴起为因果推理带来了新纪元，它们在医学、金融和科学等多个领域的应用展现了强大的潜力。LLMs的深厚知识基础有望通过增强解释力、推断力、泛化力和发现新因果结构，推动因果推理领域的发展。本文提出了一种新框架——自主LLM增强因果发现框架（ALCM），旨在结合数据驱动的因果发现算法与LLMs，自动化地生成更为稳健、精确和可解释的因果图。ALCM包含因果结构学习、因果包装器和LLM驱动的因果细化器三个核心组件，它们在动态环境中自主协作，以解决因果发现问题并生成合理的因果图。通过在七个著名数据集上的两个演示，我们对ALCM框架进行了评估。实验结果显示，ALCM在性能上超越了现有的LLM方法和传统的数据驱动因果推理机制。本研究不仅证实了ALCM的有效性，也为利用LLMs的因果推理能力开辟了新的研究方向。",
    "title_cn": "ALCM：独立增强型大型语言模型因果探索框架",
    "tags": [
      "LLM应用",
      "因果推理",
      "数据科学"
    ]
  },
  {
    "title": "Question Suggestion for Conversational Shopping Assistants Using Product Metadata",
    "submit_datetime": "2024年05月02日",
    "abstract": "Digital assistants have become ubiquitous in e-commerce applications, following the recent advancements in Information Retrieval (IR), Natural Language Processing (NLP) and Generative Artificial Intelligence (AI). However, customers are often unsure or unaware of how to effectively converse with these assistants to meet their shopping needs. In this work, we emphasize the importance of providing customers a fast, easy to use, and natural way to interact with conversational shopping assistants. We propose a framework that employs Large Language Models (LLMs) to automatically generate contextual, useful, answerable, fluent and diverse questions about products, via in-context learning and supervised fine-tuning. Recommending these questions to customers as helpful suggestions or hints to both start and continue a conversation can result in a smoother and faster shopping experience with reduced conversation overhead and friction. We perform extensive offline evaluations, and discuss in detail about potential customer impact, and the type, length and latency of our generated product questions if incorporated into a real-world shopping assistant.",
    "pdf_link": "https://arxiv.org/abs/2405.01738",
    "graphs": [],
    "abstract_cn": "随着信息检索、自然语言处理和生成性人工智能技术的飞速发展，数字助手在电商领域变得日益普及。然而，消费者往往不清楚如何与这些智能助手高效沟通以满足购物需求。本研究着重强调了为消费者提供一种快捷、简便且自然的交互方式与购物对话助手沟通的重要性。我们提出了一个利用大型语言模型（LLMs）的框架，通过上下文学习和监督微调，自动生成关于商品的情境化、实用、可答、流畅且多样化的问题。向顾客推荐这些问题，作为启动和维持对话的有益提示，可以带来更顺畅、更迅速的购物体验，同时降低对话的复杂性和摩擦。我们进行了深入的离线评估，详细探讨了这些问题对潜在客户影响的类型，以及它们的长度和延迟，如果被应用于现实世界的购物助手中，可能会产生的效果。",
    "title_cn": "利用产品元数据，为对话式购物助手提供问题建议",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Large Language Models are Inconsistent and Biased Evaluators",
    "submit_datetime": "2024年05月02日",
    "abstract": "The zero-shot capability of Large Language Models (LLMs) has enabled highly flexible, reference-free metrics for various tasks, making LLM evaluators common tools in NLP. However, the robustness of these LLM evaluators remains relatively understudied; existing work mainly pursued optimal performance in terms of correlating LLM scores with human expert scores. In this paper, we conduct a series of analyses using the SummEval dataset and confirm that LLMs are biased evaluators as they: (1) exhibit familiarity bias-a preference for text with lower perplexity, (2) show skewed and biased distributions of ratings, and (3) experience anchoring effects for multi-attribute judgments. We also found that LLMs are inconsistent evaluators, showing low \"inter-sample\" agreement and sensitivity to prompt differences that are insignificant to human understanding of text quality. Furthermore, we share recipes for configuring LLM evaluators to mitigate these limitations. Experimental results on the RoSE dataset demonstrate improvements over the state-of-the-art LLM evaluators.",
    "pdf_link": "https://arxiv.org/abs/2405.01724",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.01724v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01724/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01724v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01724/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01724v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01724/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01724v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01724/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01724v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01724/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01724v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01724/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01724v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01724/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01724v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01724/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01724v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01724/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01724v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01724/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01724v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01724/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01724v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01724/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01724v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01724/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01724v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01724/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01724v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01724/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01724v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01724/x16.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLM）的零样本功能为多样化任务提供了灵活且无需参照标准的度量工具，使得LLM评估器在自然语言处理（NLP）领域变得普及。尽管如此，对于这些评估器的鲁棒性研究尚不充分，过往研究多聚焦于如何使LLM评分与人类专家评分高度相关。本文通过SummEval数据集的深入分析，揭示了LLM评估器存在偏见：它们倾向于偏好那些困惑度低的文本（1），评分分布呈现偏斜（2），并且在多属性评估中易受锚定效应影响（3）。此外，LLM评估器的一致性较差，对文本质量的微小变化过于敏感，而这种变化对人类理解并不显著。文章还提供了调整LLM评估器设置的方法，以缓解这些问题。在RoSE数据集上的实验结果显示，这些方法能够提升评估器的性能，超越了现有的最先进水平。",
    "title_cn": "大型语言模型作为评估工具，存在不一致性和偏见问题。",
    "tags": [
      "LLM应用",
      "",
      "评估工具"
    ]
  },
  {
    "title": "FSM Builder: A Tool for Writing Autograded Finite Automata Questions",
    "submit_datetime": "2024年05月02日",
    "abstract": "Deterministic and nondeterministic finite automata (DFAs and NFAs) are abstract models of computation commonly taught in introductory computing theory courses. These models have important applications (such as fast regular expression matching), and are used to introduce formal language theory. Undergraduate students often struggle with understanding these models at first, due to the level of abstraction. As a result, various pedagogical tools have been developed to allow students to practice with these models. We introduce the FSM Builder, a new pedagogical tool enabling students to practice constructing DFAs and NFAs with a graphical editor, giving personalized feedback and partial credit. The algorithms used for generating these are heavily inspired by previous works. The key advantages to its competitors are greater flexibility and scalability. This is because the FSM Builder is implemented using efficient algorithms from an open source package, allowing for easy extension and question creation. We discuss the implementation of the tool, how it stands out from previous tools, and takeaways from experiences of using the tool in multiple large courses. Survey results indicate the interface and feedback provided by the tool were useful to students.",
    "pdf_link": "https://arxiv.org/abs/2405.01717",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.01717v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01717/canvas.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01717v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01717/feedback.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01717v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01717/x1.png"
      }
    ],
    "abstract_cn": "确定性与非确定性有限自动机（DFAs 与 NFAs）作为计算理论的抽象模型，在计算机基础课程中广为讲授。它们不仅在快速正则表达式匹配等领域有着广泛应用，也是形式语言理论的入门知识。然而，初学者往往因抽象程度而难以把握这些概念。为了帮助学生更好地理解和实践，开发了多种教学辅助工具。本文推介了一种名为 FSM Builder 的新型教学工具，它通过图形界面让学生练习构建 DFAs 与 NFAs，同时提供个性化反馈和部分得分评价。该工具背后的算法深受前人研究的启发，相较于其他同类工具，其突出优势在于更高的灵活性和扩展性。这是因为 FSM Builder 采用了开源软件包中的高效算法，便于进行功能扩展和题目设置。文章还探讨了该工具的实现细节，其与旧工具的不同之处，以及在多门大型课程中使用该工具的经验和教训。调查反馈显示，学生普遍认为 FSM Builder 的操作界面和反馈机制非常有帮助。",
    "title_cn": "FSM Builder：一款编写自动评分有限自动机习题的工具",
    "tags": [
      "Agent",
      "计算机科学教育",
      "计算理论"
    ]
  },
  {
    "title": "Requirements-driven Slicing of Simulink Models Using LLMs",
    "submit_datetime": "2024年05月02日",
    "abstract": "Model slicing is a useful technique for identifying a subset of a larger model that is relevant to fulfilling a given requirement. Notable applications of slicing include reducing inspection effort when checking design adequacy to meet requirements of interest and when conducting change impact analysis. In this paper, we present a method based on large language models (LLMs) for extracting model slices from graphical Simulink models. Our approach converts a Simulink model into a textual representation, uses an LLM to identify the necessary Simulink blocks for satisfying a specific requirement, and constructs a sound model slice that incorporates the blocks identified by the LLM. We explore how different levels of granularity (verbosity) in transforming Simulink models into textual representations, as well as the strategy used to prompt the LLM, impact the accuracy of the generated slices. Our preliminary findings suggest that prompts created by textual representations that retain the syntax and semantics of Simulink blocks while omitting visual rendering information of Simulink models yield the most accurate slices. Furthermore, the chain-of-thought and zero-shot prompting strategies result in the largest number of accurate model slices produced by our approach.",
    "pdf_link": "https://arxiv.org/abs/2405.01695",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.01695v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01695/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01695v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01695/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01695v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01695/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01695v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01695/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01695v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01695/x5.png"
      }
    ],
    "abstract_cn": "模型切片技术能精准定位大型模型中满足特定需求的关键部分，广泛应用于设计审查和变更影响分析，以降低工作量。本文介绍了一种新颖方法，利用大型语言模型（LLMs）从Simulink图形模型中抽取关键切片。该方法先将Simulink模型转换成文本形式，再通过LLM筛选出满足特定需求的关键Simulink模块，并据此构建精确的模型切片。研究还发现，保留Simulink模块语法和语义的文本表示，忽略视觉渲染信息，能产生更精确的切片。同时，思维链和零样本提示策略在生成精确模型切片方面效果最佳。",
    "title_cn": "运用大型语言模型 (LLMs) 实施对 Simulink 模型的基于需求的切片操作。",
    "tags": [
      "LLM应用",
      "软件工程",
      "自动化设计"
    ]
  },
  {
    "title": "Language-Enhanced Latent Representations for Out-of-Distribution Detection in Autonomous Driving",
    "submit_datetime": "2024年05月02日",
    "abstract": "Out-of-distribution (OOD) detection is essential in autonomous driving, to determine when learning-based components encounter unexpected inputs. Traditional detectors typically use encoder models with fixed settings, thus lacking effective human interaction capabilities. With the rise of large foundation models, multimodal inputs offer the possibility of taking human language as a latent representation, thus enabling language-defined OOD detection. In this paper, we use the cosine similarity of image and text representations encoded by the multimodal model CLIP as a new representation to improve the transparency and controllability of latent encodings used for visual anomaly detection. We compare our approach with existing pre-trained encoders that can only produce latent representations that are meaningless from the user's standpoint. Our experiments on realistic driving data show that the language-based latent representation performs better than the traditional representation of the vision encoder and helps improve the detection performance when combined with standard representations.",
    "pdf_link": "https://arxiv.org/abs/2405.01691",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.01691v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01691/fig1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01691v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01691/ov2.png"
      }
    ],
    "abstract_cn": "在自动驾驶领域，识别系统未曾预料到的输入信号是至关重要的，这就需要进行分布外（OOD）检测。传统方法通常依赖于固定配置的编码器模型，这限制了它们与人类交互的能力。随着大型基础模型的发展，结合多模态输入，我们可以利用人类语言作为潜在的表示形式，实现基于语言的OOD检测。本文提出了一种新方法，利用多模态模型CLIP对图像和文本进行编码，通过计算余弦相似性来增强潜在编码的透明度和可控性，以用于视觉异常检测。与传统的仅能生成用户难以理解的潜在表示的预训练编码器相比，我们的方法在现实驾驶数据集上的实验结果表明，基于语言的潜在表示在性能上更胜一筹，且与传统的视觉编码器表示相结合时，能进一步提升检测效果。",
    "title_cn": "为了在自动驾驶领域识别那些超出常规分布的异常情况，我们采用了一种语言增强的潜在表示方法。",
    "tags": [
      "分类：Agent",
      "自动驾驶",
      "异常检测"
    ]
  },
  {
    "title": "Automatically Extracting Numerical Results from Randomized Controlled Trials with Large Language Models",
    "submit_datetime": "2024年05月02日",
    "abstract": "Meta-analyses statistically aggregate the findings of different randomized controlled trials (RCTs) to assess treatment effectiveness. Because this yields robust estimates of treatment effectiveness, results from meta-analyses are considered the strongest form of evidence. However, rigorous evidence syntheses are time-consuming and labor-intensive, requiring manual extraction of data from individual trials to be synthesized. Ideally, language technologies would permit fully automatic meta-analysis, on demand. This requires accurately extracting numerical results from individual trials, which has been beyond the capabilities of natural language processing (NLP) models to date. In this work, we evaluate whether modern large language models (LLMs) can reliably perform this task. We annotate (and release) a modest but granular evaluation dataset of clinical trial reports with numerical findings attached to interventions, comparators, and outcomes. Using this dataset, we evaluate the performance of seven LLMs applied zero-shot for the task of conditionally extracting numerical findings from trial reports. We find that massive LLMs that can accommodate lengthy inputs are tantalizingly close to realizing fully automatic meta-analysis, especially for dichotomous (binary) outcomes (e.g., mortality). However, LLMs -- including ones trained on biomedical texts -- perform poorly when the outcome measures are complex and tallying the results requires inference. This work charts a path toward fully automatic meta-analysis of RCTs via LLMs, while also highlighting the limitations of existing models for this aim.",
    "pdf_link": "https://arxiv.org/abs/2405.01686",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.01686v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01686/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01686v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01686/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01686v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01686/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01686v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01686/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01686v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01686/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01686v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01686/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01686v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01686/x7.png"
      }
    ],
    "abstract_cn": "元分析通过整合多项随机对照试验的研究成果，为评估医疗效果提供了强有力的证据。然而，这一过程既耗时又费力，因为它需要手动搜集各试验的数据。理想状况下，我们希望能够利用语言技术实现自动化的元分析。这涉及到从各个试验中精确抽取数值数据，而这对于自然语言处理技术来说一直是个挑战。在本研究中，我们探讨了现代大型语言模型（LLMs）是否能够胜任这一任务。我们创建并公开了一个包含临床试验报告和相关数值结果的详细评估数据集，这些结果关联到干预措施、对照组和研究结果。利用这个数据集，我们对七个大型语言模型进行了零样本条件下的性能测试，以评估它们从试验报告中提取数值结果的能力。研究发现，能够处理长篇输入的大型语言模型在自动化元分析方面已接近实现，尤其是在处理二元结果（如死亡率）时。但当面对复杂度量和需要推理的统计结果时，即便是经过生物医学文本训练的模型也表现不佳。本研究为利用大型语言模型实现随机对照试验的全自动化元分析提供了可能的路径，并指出了现有模型在实现这一目标上的局限。",
    "title_cn": "利用大型语言模型，我们能够自动地从随机对照试验中抽取出数值数据。",
    "tags": [
      "LLM应用",
      "",
      ""
    ]
  },
  {
    "title": "Leveraging Prompt-Learning for Structured Information Extraction from Crohn's Disease Radiology Reports in a Low-Resource Language",
    "submit_datetime": "2024年05月02日",
    "abstract": "Automatic conversion of free-text radiology reports into structured data using Natural Language Processing (NLP) techniques is crucial for analyzing diseases on a large scale. While effective for tasks in widely spoken languages like English, generative large language models (LLMs) typically underperform with less common languages and can pose potential risks to patient privacy. Fine-tuning local NLP models is hindered by the skewed nature of real-world medical datasets, where rare findings represent a significant data imbalance. We introduce SMP-BERT, a novel prompt learning method that leverages the structured nature of reports to overcome these challenges. In our studies involving a substantial collection of Crohn's disease radiology reports in Hebrew (over 8,000 patients and 10,000 reports), SMP-BERT greatly surpassed traditional fine-tuning methods in performance, notably in detecting infrequent conditions (AUC: 0.99 vs 0.94, F1: 0.84 vs 0.34). SMP-BERT empowers more accurate AI diagnostics available for low-resource languages.",
    "pdf_link": "https://arxiv.org/abs/2405.01682",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.01682v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01682/medcomp.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01682v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01682/SMP-output_showcase.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.01682v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01682/SMP-methods2.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.01682v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01682/SMP-SMP-tuning.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.01682v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01682/dataandmodels.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.01682v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01682/training_samples_vs_f1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01682v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01682/n_positives_f1.png"
      }
    ],
    "abstract_cn": "将放射学报告的自由文本通过自然语言处理技术自动转换为结构化数据，对于广泛分析疾病至关重要。尽管这种方法在英语等通用语言的任务中效果显著，但对于使用较少的语言，大型语言模型（LLMs）往往表现不佳，并可能侵犯患者隐私。现实世界中，医学数据集的不平衡特性使得微调本地NLP模型变得困难，尤其是罕见病例的数据差异显著。我们提出了SMP-BERT，这是一种创新的提示学习法，它利用报告的结构化特点来解决这些难题。在涉及希伯来语克罗恩病放射学报告的广泛研究中（涵盖超过8000名患者和10000份报告），SMP-BERT在性能上显著超越了传统微调方法，尤其是在识别罕见病症方面（AUC：0.99对比0.94，F1：0.84对比0.34）。SMP-BERT为资源匮乏的语言提供了更精确的AI诊断能力。",
    "title_cn": "通过提示学习技术，我们能够从克罗恩病的放射学报告中高效提取结构化信息，即便在资源匮乏的语言环境中也表现出色。",
    "tags": [
      "LLM应用",
      "",
      ""
    ]
  },
  {
    "title": "Generative AI in Cybersecurity",
    "submit_datetime": "2024年05月02日",
    "abstract": "The dawn of Generative Artificial Intelligence (GAI), characterized by advanced models such as Generative Pre-trained Transformers (GPT) and other Large Language Models (LLMs), has been pivotal in reshaping the field of data analysis, pattern recognition, and decision-making processes. This surge in GAI technology has ushered in not only innovative opportunities for data processing and automation but has also introduced significant cybersecurity challenges.\n  As GAI rapidly progresses, it outstrips the current pace of cybersecurity protocols and regulatory frameworks, leading to a paradox wherein the same innovations meant to safeguard digital infrastructures also enhance the arsenal available to cyber criminals. These adversaries, adept at swiftly integrating and exploiting emerging technologies, may utilize GAI to develop malware that is both more covert and adaptable, thus complicating traditional cybersecurity efforts.\n  The acceleration of GAI presents an ambiguous frontier for cybersecurity experts, offering potent tools for threat detection and response, while concurrently providing cyber attackers with the means to engineer more intricate and potent malware. Through the joint efforts of Duke Pratt School of Engineering, Coalfire, and Safebreach, this research undertakes a meticulous analysis of how malicious agents are exploiting GAI to augment their attack strategies, emphasizing a critical issue for the integrity of future cybersecurity initiatives. The study highlights the critical need for organizations to proactively identify and develop more complex defensive strategies to counter the sophisticated employment of GAI in malware creation.",
    "pdf_link": "https://arxiv.org/abs/2405.01674",
    "graphs": [],
    "abstract_cn": "随着生成性人工智能（GAI）的兴起，如生成预训练变换器（GPT）和大型语言模型（LLMs）等先进模型，数据领域迎来了革命性的变化，同时也带来了前所未有的网络安全挑战。GAI技术的迅猛发展超越了现有安全协议和法规的步伐，形成了一个悖论：旨在保护数字基础设施的技术创新，却也为网络犯罪分子提供了新的攻击手段。这些犯罪分子擅长迅速掌握并利用新技术，可能使用GAI来制造更加隐蔽和灵活的恶意软件，增加了传统网络安全工作的难度。GAI的快速发展为网络安全领域带来了双重影响：一方面，它为威胁检测和响应提供了强大的工具；另一方面，也为网络攻击者提供了制造更复杂恶意软件的手段。杜克大学普拉特工程学院、Coalfire和Safebreach的合作研究深入分析了恶意行为者如何利用GAI加强其攻击策略，突出了未来网络安全工作中一个至关重要的问题。研究强调了组织必须主动识别并构建更复杂的防御策略，以应对GAI在恶意软件制造中的高级应用。",
    "title_cn": "在网络安全领域，生成性人工智能的应用正日益显现其重要性。",
    "tags": [
      "分类：LLM应用",
      "网络安全",
      "人工智能"
    ]
  },
  {
    "title": "WitheredLeaf: Finding Entity-Inconsistency Bugs with LLMs",
    "submit_datetime": "2024年05月02日",
    "abstract": "Originating from semantic bugs, Entity-Inconsistency Bugs (EIBs) involve misuse of syntactically valid yet incorrect program entities, such as variable identifiers and function names, which often have security implications. Unlike straightforward syntactic vulnerabilities, EIBs are subtle and can remain undetected for years. Traditional detection methods, such as static analysis and dynamic testing, often fall short due to the versatile and context-dependent nature of EIBs. However, with advancements in Large Language Models (LLMs) like GPT-4, we believe LLM-powered automatic EIB detection becomes increasingly feasible through these models' semantics understanding abilities. This research first undertakes a systematic measurement of LLMs' capabilities in detecting EIBs, revealing that GPT-4, while promising, shows limited recall and precision that hinder its practical application. The primary problem lies in the model's tendency to focus on irrelevant code snippets devoid of EIBs. To address this, we introduce a novel, cascaded EIB detection system named WitheredLeaf, which leverages smaller, code-specific language models to filter out most negative cases and mitigate the problem, thereby significantly enhancing the overall precision and recall. We evaluated WitheredLeaf on 154 Python and C GitHub repositories, each with over 1,000 stars, identifying 123 new flaws, 45% of which can be exploited to disrupt the program's normal operations. Out of 69 submitted fixes, 27 have been successfully merged.",
    "pdf_link": "https://arxiv.org/abs/2405.01668",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.01668v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01668/System.jpg"
      }
    ],
    "abstract_cn": "源于语义缺陷的实体不一致错误（EIBs）通常涉及对程序实体的误用，这些实体在语法上看似正确，实则错误，比如变量标识符和函数名，这往往牵涉到安全问题。与明显的语法漏洞相比，EIBs更为隐蔽，可能长时间未被察觉。传统的检测手段，例如静态分析和动态测试，因EIBs的多变和依赖上下文的特性而往往力不从心。但是，随着大型语言模型（LLMs）如GPT-4的发展，利用这些模型的语义理解能力进行自动EIB检测变得日益可行。本研究首先对LLMs在识别EIBs方面的能力进行了系统性评估，发现GPT-4虽有潜力，但其召回率和精确度有限，限制了其在实际应用中的效能。关键问题在于模型常常过分关注不包含EIBs的无关代码片段。为此，我们提出了一个创新的级联EIB检测系统WitheredLeaf，它利用更小型、专门针对代码的语言模型来排除大多数非目标案例，从而有效提升了检测的精确度和召回率。我们在154个星数超过1000的Python和C GitHub仓库上对WitheredLeaf进行了评估，发现了123个新漏洞，其中45%可以被利用来干扰程序的正常运作。在提交的69个修复提案中，有27个已经被成功采纳并合并。",
    "title_cn": "WitheredLeaf：利用大型语言模型挖掘实体不一致性缺陷",
    "tags": [
      "LLM应用",
      "软件工程",
      "代码分析"
    ]
  },
  {
    "title": "Investigating Wit, Creativity, and Detectability of Large Language Models in Domain-Specific Writing Style Adaptation of Reddit's Showerthoughts",
    "submit_datetime": "2024年05月02日",
    "abstract": "Recent Large Language Models (LLMs) have shown the ability to generate content that is difficult or impossible to distinguish from human writing. We investigate the ability of differently-sized LLMs to replicate human writing style in short, creative texts in the domain of Showerthoughts, thoughts that may occur during mundane activities. We compare GPT-2 and GPT-Neo fine-tuned on Reddit data as well as GPT-3.5 invoked in a zero-shot manner, against human-authored texts. We measure human preference on the texts across the specific dimensions that account for the quality of creative, witty texts. Additionally, we compare the ability of humans versus fine-tuned RoBERTa classifiers to detect AI-generated texts. We conclude that human evaluators rate the generated texts slightly worse on average regarding their creative quality, but they are unable to reliably distinguish between human-written and AI-generated texts. We further provide a dataset for creative, witty text generation based on Reddit Showerthoughts posts.",
    "pdf_link": "https://arxiv.org/abs/2405.01660",
    "graphs": [],
    "abstract_cn": "最新的大型语言模型（LLMs）展现出了生成与人类写作难以区分的内容的本领。本研究旨在探究不同规模的LLMs在模仿人类写作风格方面的能力，尤其是在创造性文本创作领域，如日常生活中可能涌现的Showerthoughts。我们对在Reddit数据上经过微调的GPT-2、GPT-Neo以及以零样本方式运行的GPT-3.5进行了评估，并与人类作者的文本进行了对比。通过特定维度衡量人类对这些文本的偏好，这些维度能够反映创造性和机智文本的品质。同时，我们还对比了人类与经过微调的RoBERTa分类器在识别AI生成文本方面的能力。研究结果显示，尽管人类评审在平均上认为AI生成的文本在创造性上略逊一筹，但他们无法一致性地分辨出人类写作与AI生成的文本。此外，我们还提供了一个基于Reddit Showerthoughts帖子的创造性、机智文本生成的数据集，以供进一步研究。",
    "title_cn": "本研究旨在探究大型语言模型在 Reddit Showerthoughts 社区特定写作风格适应中的机智、创造力及其可被察觉的程度。",
    "tags": [
      "LLM应用",
      "文本生成",
      "人工智能"
    ]
  },
  {
    "title": "Improving Complex Reasoning over Knowledge Graph with Logic-Aware Curriculum Tuning",
    "submit_datetime": "2024年05月02日",
    "abstract": "Answering complex logical queries over incomplete knowledge graphs (KGs) is challenging. Most previous works have focused on learning entity/relation embeddings and simulating first-order logic operators with various neural networks. However, they are bottlenecked by the inability to share world knowledge to improve logical reasoning, thus resulting in suboptimal performance. In this paper, we propose a complex logical reasoning schema over knowledge graphs upon large language models (LLMs), containing a curriculum-based logical-aware instruction tuning framework, named LACT. Specifically, we augment the arbitrary first-order logical queries via binary tree decomposition, to stimulate the reasoning capability of LLMs. To address the difficulty gap among different types of complex queries, we design a simple and flexible logic-aware curriculum learning framework. Experiments across widely used datasets demonstrate that LACT has substantial improvements~(brings an average +5.5% MRR score) over advanced methods, achieving the new state-of-the-art. Our code and model will be released at GitHub and huggingface soon.",
    "pdf_link": "https://arxiv.org/abs/2405.01649",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.01649v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01649/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01649v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01649/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01649v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01649/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01649v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01649/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01649v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01649/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01649v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01649/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01649v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01649/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01649v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01649/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01649v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01649/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01649v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01649/x13.png"
      }
    ],
    "abstract_cn": "处理不完全知识图谱上的复杂逻辑查询颇具挑战，过往研究多致力于通过神经网络学习实体/关系的嵌入及模拟一阶逻辑运算符。这些研究因无法有效共享世界知识以增强逻辑推理而受限，导致性能不尽人意。本论文提出了一种依托大型语言模型（LLMs）的复杂逻辑推理框架——LACT，内含基于课程的逻辑感知指令调整机制。我们采用二叉树分解技术增强一阶逻辑查询，以提升LLMs的推理能力。同时，为应对不同复杂查询间的难度差异，我们设计了一个简洁而高效的逻辑感知课程学习框架。实验结果表明，LACT在多个广泛使用的数据集上取得了显著的性能提升（平均MRR得分提高5.5%），刷新了最先进水平。相关代码和模型将不久后在GitHub和huggingface上线。",
    "title_cn": "本文探讨了如何通过逻辑感知的课程调整方法，提升在知识图谱上进行复杂推理的性能。",
    "tags": [
      "分类：LLM应用",
      "知识图谱",
      "逻辑推理"
    ]
  },
  {
    "title": "Automating the Analysis of Public Saliency and Attitudes towards Biodiversity from Digital Media",
    "submit_datetime": "2024年05月02日",
    "abstract": "Measuring public attitudes toward wildlife provides crucial insights into our relationship with nature and helps monitor progress toward Global Biodiversity Framework targets. Yet, conducting such assessments at a global scale is challenging. Manually curating search terms for querying news and social media is tedious, costly, and can lead to biased results. Raw news and social media data returned from queries are often cluttered with irrelevant content and syndicated articles. We aim to overcome these challenges by leveraging modern Natural Language Processing (NLP) tools. We introduce a folk taxonomy approach for improved search term generation and employ cosine similarity on Term Frequency-Inverse Document Frequency vectors to filter syndicated articles. We also introduce an extensible relevance filtering pipeline which uses unsupervised learning to reveal common topics, followed by an open-source zero-shot Large Language Model (LLM) to assign topics to news article titles, which are then used to assign relevance. Finally, we conduct sentiment, topic, and volume analyses on resulting data. We illustrate our methodology with a case study of news and X (formerly Twitter) data before and during the COVID-19 pandemic for various mammal taxa, including bats, pangolins, elephants, and gorillas. During the data collection period, up to 62% of articles including keywords pertaining to bats were deemed irrelevant to biodiversity, underscoring the importance of relevance filtering. At the pandemic's onset, we observed increased volume and a significant sentiment shift toward horseshoe bats, which were implicated in the pandemic, but not for other focal taxa. The proposed methods open the door to conservation practitioners applying modern and emerging NLP tools, including LLMs \"out of the box,\" to analyze public perceptions of biodiversity during current events or campaigns.",
    "pdf_link": "https://arxiv.org/abs/2405.01610",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.01610v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01610/data-pipeline.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01610v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01610/folk-taxonomy-carnivora-lion-cluster.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01610v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01610/relevance-scraped-original-sankey-3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01610v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01610/gorilla_relevant_volume_choropleth.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01610v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01610/pangolin_relevant_volume_choropleth.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01610v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01610/pipistrelle_relevant_volume_choropleth.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01610v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01610/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01610v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01610/VolumeMain.jpeg"
      },
      {
        "url": "https://arxiv.org/html/2405.01610v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01610/SentMain.jpeg"
      },
      {
        "url": "https://arxiv.org/html/2405.01610v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01610/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01610v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01610/allVolume.jpeg"
      },
      {
        "url": "https://arxiv.org/html/2405.01610v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01610/allSentiment.jpeg"
      }
    ],
    "abstract_cn": "探索公众对野生动物的看法对于理解我们与自然界的联系至关重要，也有助于跟踪全球生物多样性目标的实现情况。然而，在全球范围内进行这样的评估并非易事。传统的通过手动筛选搜索词来查询新闻和社交媒体不仅耗时耗力，还可能导致有偏差的结果。此外，检索到的原始数据往往混杂着大量无关信息和转载文章。为了应对这些挑战，我们采用了先进的自然语言处理（NLP）技术。我们提出了一种基于民间分类法的搜索词生成方法，并利用余弦相似度结合词频-逆文档频率（TF-IDF）向量来筛选掉转载内容。我们还开发了一个可扩展的相关性过滤流程，该流程首先通过无监督学习识别常见主题，然后利用开源的零样本大型语言模型（LLM）为新闻标题自动分配主题，进而确定其相关性。最后，我们对筛选后的数据进行了情感、主题和数量分析。我们通过一个案例研究，分析了 COVID-19 大流行期间关于某些哺乳动物（如蝙蝠、穿山甲、大象和大猩猩）的新闻和社交媒体数据，展示了我们的方法。研究发现，在数据收集期间，高达 62% 的含有蝙蝠关键词的文章与生物多样性无关，这凸显了相关性过滤的必要性。在大流行初期，我们注意到与马蹄蝠（被认为与大流行有关）相关的文章数量激增，情感倾向也发生了显著变化，而其他研究对象则未出现这种情况。这些方法为保护工作者提供了新的途径，使他们能够利用现成的现代和新兴的 NLP 工具，包括 LLM，来分析公众在当前事件或活动中对生物多样性的看法。",
    "title_cn": "自动化地从数字媒体中分析公众对生物多样性的关注点和态度",
    "tags": [
      "LLM应用",
      "生物多样性保护",
      ""
    ]
  },
  {
    "title": "CodeGRAG: Extracting Composed Syntax Graphs for Retrieval Augmented Cross-Lingual Code Generation",
    "submit_datetime": "2024年05月02日",
    "abstract": "Utilizing large language models to generate codes has shown promising meaning in software development revolution. Despite the intelligence shown by the general large language models, their specificity in code generation can still be improved due to the syntactic gap and mismatched vocabulary existing among natural language and different programming languages. In addition, programming languages are inherently logical and complex, making them hard to be correctly generated. Existing methods rely on multiple prompts to the large language model to explore better solutions, which is expensive. In this paper, we propose Syntax Graph Retrieval Augmented Code Generation (CodeGRAG) to enhance the performance of LLMs in single-round code generation tasks. CodeGRAG extracts and summarizes the control flow and data flow of code blocks to fill the gap between programming languages and natural language. The extracted external structural knowledge models the inherent flows of code blocks, which can facilitate LLMs for better understanding of code syntax and serve as a bridge among different programming languages. CodeGRAG significantly improves the code generation ability of LLMs and can even offer performance gain for cross-lingual code generation, e.g., C++ for Python.",
    "pdf_link": "https://arxiv.org/abs/2405.02355",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.02355v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02355/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02355v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02355/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02355v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02355/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.02355v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.02355/x4.png"
      }
    ],
    "abstract_cn": "运用大型语言模型来生成代码，在软件开发领域呈现出革命性的前景。尽管这些通用的大型语言模型已经展现出了一定的智能，但在代码生成的特定领域，它们的表现仍有提升空间，这主要是由于自然语言与编程语言之间的语法差异和词汇不匹配。编程语言的逻辑性和复杂性也增加了正确生成代码的难度。目前，为了寻找更优的解决方案，通常需要对大型语言模型进行多次提示，这不仅成本高昂。本文提出了一种名为“语法图检索增强的代码生成”（CodeGRAG）的新方法，旨在提升大型语言模型在单轮代码生成任务中的表现。CodeGRAG 能够提取并概括代码块的控制流和数据流，弥合编程语言与自然语言之间的鸿沟。这种方法提炼出的外部结构知识不仅模拟了代码块的内在流程，还能帮助大型语言模型更深入地理解代码的语法结构，并在不同编程语言之间架起沟通的桥梁。CodeGRAG 显著增强了大型语言模型的代码生成能力，甚至在跨语言代码生成方面也展现出了性能提升，比如能够将 Python 代码转换成 C++。",
    "title_cn": "CodeGRAF：为增强检索的跨语言代码生成提取复合语法图。",
    "tags": [
      "LLM应用",
      "软件开发",
      "人工智能"
    ]
  },
  {
    "title": "Is Bigger Edit Batch Size Always Better? -- An Empirical Study on Model Editing with Llama-3",
    "submit_datetime": "2024年05月01日",
    "abstract": "This study presents a targeted model editing analysis focused on the latest large language model, Llama-3. We explore the efficacy of popular model editing techniques - ROME, MEMIT, and EMMET, which are designed for precise layer interventions. We identify the most effective layers for targeted edits through an evaluation that encompasses up to 4096 edits across three distinct strategies: sequential editing, batch editing, and a hybrid approach we call as sequential-batch editing. Our findings indicate that increasing edit batch-sizes may degrade model performance more significantly than using smaller edit batches sequentially for equal number of edits. With this, we argue that sequential model editing is an important component for scaling model editing methods and future research should focus on methods that combine both batched and sequential editing. This observation suggests a potential limitation in current model editing methods which push towards bigger edit batch sizes, and we hope it paves way for future investigations into optimizing batch sizes and model editing performance.",
    "pdf_link": "https://arxiv.org/abs/2405.00664",
    "graphs": [],
    "abstract_cn": "本研究针对最新的大型语言模型 Llama-3，进行了一项精准的模型编辑策略分析。我们评估了几种流行的编辑技术——ROME、MEMIT 和 EMMET，它们专为精细的层次化编辑而设计。通过对比多达 4096 次的编辑，我们发现了最有效的编辑层次，这些编辑策略包括顺序编辑、批量编辑，以及我们提出的顺序-批量混合编辑方法。研究结果显示，相比于顺序进行较小批量的编辑，增大编辑批量可能会对模型性能产生更明显的负面影响。因此，我们认为顺序化的模型编辑对于提升编辑效率至关重要，未来研究应更多关注如何融合批量与顺序编辑的策略。这一发现也指出了当前模型编辑方法的一个潜在限制，即追求更大的编辑批量，我们期待这能激发未来对编辑批量大小和模型编辑效能优化的进一步探索。",
    "title_cn": "编辑批量大小越大，效果一定越佳吗？一项基于 Llama-3 模型编辑的实证探索。",
    "tags": [
      "LLM应用",
      "人工智能",
      "模型优化"
    ]
  },
  {
    "title": "HalluVault: A Novel Logic Programming-aided Metamorphic Testing Framework for Detecting Fact-Conflicting Hallucinations in Large Language Models",
    "submit_datetime": "2024年05月01日",
    "abstract": "Large language models (LLMs) have transformed the landscape of language processing, yet struggle with significant challenges in terms of security, privacy, and the generation of seemingly coherent but factually inaccurate outputs, commonly referred to as hallucinations. Among these challenges, one particularly pressing issue is Fact-Conflicting Hallucination (FCH), where LLMs generate content that directly contradicts established facts. Tackling FCH poses a formidable task due to two primary obstacles: Firstly, automating the construction and updating of benchmark datasets is challenging, as current methods rely on static benchmarks that don't cover the diverse range of FCH scenarios. Secondly, validating LLM outputs' reasoning process is inherently complex, especially with intricate logical relations involved.\n  In addressing these obstacles, we propose an innovative approach leveraging logic programming to enhance metamorphic testing for detecting Fact-Conflicting Hallucinations (FCH). Our method gathers data from sources like Wikipedia, expands it with logical reasoning to create diverse test cases, assesses LLMs through structured prompts, and validates their coherence using semantic-aware assessment mechanisms. Our method generates test cases and detects hallucinations across six different LLMs spanning nine domains, revealing hallucination rates ranging from 24.7% to 59.8%. Key observations indicate that LLMs encounter challenges, particularly with temporal concepts, handling out-of-distribution knowledge, and exhibiting deficiencies in logical reasoning capabilities. The outcomes underscore the efficacy of logic-based test cases generated by our tool in both triggering and identifying hallucinations. These findings underscore the imperative for ongoing collaborative endeavors within the community to detect and address LLM hallucinations.",
    "pdf_link": "https://arxiv.org/abs/2405.00648",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）重塑了语言处理的领域，却在安全性、隐私保护以及避免生成内容上的幻觉——即那些貌似合理却与事实不符的输出——方面遭遇重重挑战。特别棘手的是事实冲突幻觉（FCH），在这种情况下，LLMs产出的内容与已知事实直接相悖。应对FCH的挑战颇为艰巨，主要原因有两个：首先，自动化构建和更新基准数据集存在难度，因为现有方法依赖的静态基准无法涵盖FCH的各种情况。其次，验证LLMs输出的推理过程极为复杂，尤其是在涉及复杂逻辑关系时。为应对这些难题，我们提出了一种创新的逻辑编程方法，以增强变异测试，从而检测FCH。该方法从维基百科等来源搜集数据，通过逻辑推理扩展，生成多样化的测试案例，并通过结构化提示对LLMs进行评估，同时利用语义感知机制来验证它们的一致性。我们的方法在六个不同领域的LLMs上生成测试案例并检测幻觉，发现幻觉率在24.7%到59.8%之间。关键的观察结果显示，LLMs在处理时间概念、管理分布外知识以及逻辑推理能力方面存在挑战。这些结果凸显了我们工具生成的基于逻辑的测试案例在触发和识别幻觉方面的有效性，并强调了社区持续合作以检测和解决LLM幻觉问题的必要性。",
    "title_cn": "HalluVault：一个创新的基于逻辑编程的变异测试框架，专为发现大型语言模型中与事实相悖的幻觉现象而设计。",
    "tags": [
      "LLM应用",
      "",
      "软件测试"
    ]
  },
  {
    "title": "When Quantization Affects Confidence of Large Language Models?",
    "submit_datetime": "2024年05月01日",
    "abstract": "Recent studies introduced effective compression techniques for Large Language Models (LLMs) via post-training quantization or low-bit weight representation. Although quantized weights offer storage efficiency and allow for faster inference, existing works have indicated that quantization might compromise performance and exacerbate biases in LLMs. This study investigates the confidence and calibration of quantized models, considering factors such as language model type and scale as contributors to quantization loss. Firstly, we reveal that quantization with GPTQ to 4-bit results in a decrease in confidence regarding true labels, with varying impacts observed among different language models. Secondly, we observe fluctuations in the impact on confidence across different scales. Finally, we propose an explanation for quantization loss based on confidence levels, indicating that quantization disproportionately affects samples where the full model exhibited low confidence levels in the first place.",
    "pdf_link": "https://arxiv.org/abs/2405.00632",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00632v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00632/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00632v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00632/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00632v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00632/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00632v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00632/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00632v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00632/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00632v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00632/x6.png"
      }
    ],
    "abstract_cn": "近期研究通过训练后的量化或低比特权重量表示，为大型语言模型（LLMs）带来了高效的压缩方法。虽然量化权重有助于节省存储空间并加快推理速度，但现有研究指出，量化可能会影响模型性能并放大LLMs的偏见。本研究深入探讨了量化模型的置信度和校准问题，分析了语言模型类型和规模对量化损失的影响。我们首先发现，采用GPTQ量化至4位会降低对正确标签的置信度，且这种影响在不同语言模型中表现不一。其次，我们注意到置信度在不同规模的语言模型中波动。最终，我们基于置信度水平对量化损失提出了解释，指出量化对于那些模型原本就缺乏信心的样本影响更大。",
    "title_cn": "量化如何影响大型语言模型的置信度？",
    "tags": [
      "LLM理论",
      "",
      "机器学习"
    ]
  },
  {
    "title": "\"I'm Not Sure, But...\": Examining the Impact of Large Language Models' Uncertainty Expression on User Reliance and Trust",
    "submit_datetime": "2024年05月01日",
    "abstract": "Widely deployed large language models (LLMs) can produce convincing yet incorrect outputs, potentially misleading users who may rely on them as if they were correct. To reduce such overreliance, there have been calls for LLMs to communicate their uncertainty to end users. However, there has been little empirical work examining how users perceive and act upon LLMs' expressions of uncertainty. We explore this question through a large-scale, pre-registered, human-subject experiment (N=404) in which participants answer medical questions with or without access to responses from a fictional LLM-infused search engine. Using both behavioral and self-reported measures, we examine how different natural language expressions of uncertainty impact participants' reliance, trust, and overall task performance. We find that first-person expressions (e.g., \"I'm not sure, but...\") decrease participants' confidence in the system and tendency to agree with the system's answers, while increasing participants' accuracy. An exploratory analysis suggests that this increase can be attributed to reduced (but not fully eliminated) overreliance on incorrect answers. While we observe similar effects for uncertainty expressed from a general perspective (e.g., \"It's not clear, but...\"), these effects are weaker and not statistically significant. Our findings suggest that using natural language expressions of uncertainty may be an effective approach for reducing overreliance on LLMs, but that the precise language used matters. This highlights the importance of user testing before deploying LLMs at scale.",
    "pdf_link": "https://arxiv.org/abs/2405.00623",
    "graphs": [],
    "abstract_cn": "广泛应用的大型语言模型（LLMs）有时会产生貌似可信却错误的结果，这容易误导那些将其视为绝对正确的用户。为了避免用户过度依赖，人们开始呼吁LLMs能够向用户明确表达其不确定性。尽管如此，关于用户如何理解和响应LLMs不确定性表达的实证研究却寥寥无几。本研究通过一项大规模的、预先注册的、涉及404名参与者的人类实验来探讨这一问题，实验中参与者在有或没有使用一个虚构的LLM支持的搜索引擎回答医疗问题的情况下进行回答。我们综合运用了行为测量和自我报告的方法，来评估不同自然语言中不确定性表达对参与者依赖度、信任感和任务完成表现的影响。研究发现，使用第一人称的不确定性表达（例如，“我不太确定，但是...”）能够减少参与者对系统的信心，降低他们与系统答案一致的倾向，并提高他们的准确性。进一步分析表明，这种准确性的提升源于对错误答案依赖度的减少，尽管这种减少并未完全消除。而从一般角度表达不确定性（例如，“这不太明确，但是...”）虽有相似效果，但影响较小，且未达到统计学意义。研究结果表明，采用自然语言的不确定性表达是减少用户对LLMs过度依赖的有效途径，但所用的具体语言至关重要。这进一步强调了在大规模推广LLMs前进行用户测试的必要性。",
    "title_cn": "《“我不确定，但是...”：探究大型语言模型不确定性表述对用户信赖与依赖的影响》",
    "tags": [
      "LLM应用",
      "人工智能",
      "用户研究"
    ]
  },
  {
    "title": "Addressing Topic Granularity and Hallucination in Large Language Models for Topic Modelling",
    "submit_datetime": "2024年05月01日",
    "abstract": "Large language models (LLMs) with their strong zero-shot topic extraction capabilities offer an alternative to probabilistic topic modelling and closed-set topic classification approaches. As zero-shot topic extractors, LLMs are expected to understand human instructions to generate relevant and non-hallucinated topics based on the given documents. However, LLM-based topic modelling approaches often face difficulties in generating topics with adherence to granularity as specified in human instructions, often resulting in many near-duplicate topics. Furthermore, methods for addressing hallucinated topics generated by LLMs have not yet been investigated. In this paper, we focus on addressing the issues of topic granularity and hallucinations for better LLM-based topic modelling. To this end, we introduce a novel approach that leverages Direct Preference Optimisation (DPO) to fine-tune open-source LLMs, such as Mistral-7B. Our approach does not rely on traditional human annotation to rank preferred answers but employs a reconstruction pipeline to modify raw topics generated by LLMs, thus enabling a fast and efficient training and inference framework. Comparative experiments show that our fine-tuning approach not only significantly improves the LLM's capability to produce more coherent, relevant, and precise topics, but also reduces the number of hallucinated topics.",
    "pdf_link": "https://arxiv.org/abs/2405.00611",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00611v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00611/super25APR2024_new_ecai_fig1_.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00611v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00611/prompt_ecai.drawio.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00611v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00611/acai_pipeline_25APR.drawio.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00611v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00611/topic_attention_flow.png"
      }
    ],
    "abstract_cn": "大规模语言模型（LLMs）以其出色的零样本主题抽取功能，为传统的主题建模和封闭集分类方法提供了新选择。这些模型能够根据文档内容，理解指令并生成相关且真实的主题。但当前基于 LLM 的主题建模技术在精确控制主题粒度上存在挑战，常产生大量相似主题。同时，对于 LLM 产生的虚构主题，尚缺乏有效的处理方法。本文聚焦于改善主题粒度控制和减少幻觉现象，以优化基于 LLM 的主题建模。我们提出了一种创新方法，通过直接偏好优化（DPO）技术对开源 LLMs 如 Mistral-7B 进行微调。此方法摒弃了传统的人工标注排名，转而使用重构流程来优化 LLMs 产出的原始主题，实现了一个迅捷高效的训练与推理系统。对比实验结果证明，我们的微调策略显著提升了 LLMs 在生成更一致、贴切、精确主题方面的能力，并有效减少了虚构主题的产生。",
    "title_cn": "探讨大型语言模型在主题建模中的主题粒度细化与幻觉现象",
    "tags": [
      "LLM应用",
      "",
      "主题建模"
    ]
  },
  {
    "title": "Investigating Automatic Scoring and Feedback using Large Language Models",
    "submit_datetime": "2024年05月01日",
    "abstract": "Automatic grading and feedback have been long studied using traditional machine learning and deep learning techniques using language models. With the recent accessibility to high performing large language models (LLMs) like LLaMA-2, there is an opportunity to investigate the use of these LLMs for automatic grading and feedback generation. Despite the increase in performance, LLMs require significant computational resources for fine-tuning and additional specific adjustments to enhance their performance for such tasks. To address these issues, Parameter Efficient Fine-tuning (PEFT) methods, such as LoRA and QLoRA, have been adopted to decrease memory and computational requirements in model fine-tuning. This paper explores the efficacy of PEFT-based quantized models, employing classification or regression head, to fine-tune LLMs for automatically assigning continuous numerical grades to short answers and essays, as well as generating corresponding feedback. We conducted experiments on both proprietary and open-source datasets for our tasks. The results show that prediction of grade scores via finetuned LLMs are highly accurate, achieving less than 3% error in grade percentage on average. For providing graded feedback fine-tuned 4-bit quantized LLaMA-2 13B models outperform competitive base models and achieve high similarity with subject matter expert feedback in terms of high BLEU and ROUGE scores and qualitatively in terms of feedback. The findings from this study provide important insights into the impacts of the emerging capabilities of using quantization approaches to fine-tune LLMs for various downstream tasks, such as automatic short answer scoring and feedback generation at comparatively lower costs and latency.",
    "pdf_link": "https://arxiv.org/abs/2405.00602",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00602v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00602/cogwheel.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00602v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00602/cogwheel.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00602v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00602/loss_curves.png"
      }
    ],
    "abstract_cn": "自动评分与反馈的探索一直依赖于传统和深度学习技术，以及语言模型的应用。随着高性能的大型语言模型（LLMs）如 LLaMA-2 的问世，我们得以进一步研究其在自动评分和反馈生成上的潜力。尽管性能显著提升，但LLMs在微调过程中仍需大量计算资源，并需特定调整以优化任务性能。为克服这些挑战，参数高效微调（PEFT）方法，包括LoRA和QLoRA，被引入以降低模型微调的内存和计算需求。本研究评估了基于PEFT的量化模型，通过分类或回归机制，对LLMs进行微调，以实现对短答案和论文的连续数值评分及反馈生成。我们在专有和开源数据集上进行了实验，结果显示，经微调的LLMs在评分精度上表现卓越，平均误差率低于3%。此外，微调后的4位量化LLaMA-2 13B模型在提供分级反馈方面超越了基准模型，并在BLEU和ROUGE评分以及反馈质量上与领域专家的反馈达到了高度一致性。本研究的发现为我们提供了宝贵的洞见，尤其是在使用量化技术微调LLMs以执行各种下游任务，如自动评分和反馈生成，且成本和延迟更低的情况下。",
    "title_cn": "探究基于大型语言模型的自动评分与反馈机制",
    "tags": [
      "LLM应用",
      "",
      "自动化评分"
    ]
  },
  {
    "title": "Are Models Biased on Text without Gender-related Language?",
    "submit_datetime": "2024年05月01日",
    "abstract": "Gender bias research has been pivotal in revealing undesirable behaviors in large language models, exposing serious gender stereotypes associated with occupations, and emotions. A key observation in prior work is that models reinforce stereotypes as a consequence of the gendered correlations that are present in the training data. In this paper, we focus on bias where the effect from training data is unclear, and instead address the question: Do language models still exhibit gender bias in non-stereotypical settings? To do so, we introduce UnStereoEval (USE), a novel framework tailored for investigating gender bias in stereotype-free scenarios. USE defines a sentence-level score based on pretraining data statistics to determine if the sentence contain minimal word-gender associations. To systematically benchmark the fairness of popular language models in stereotype-free scenarios, we utilize USE to automatically generate benchmarks without any gender-related language. By leveraging USE's sentence-level score, we also repurpose prior gender bias benchmarks (Winobias and Winogender) for non-stereotypical evaluation. Surprisingly, we find low fairness across all 28 tested models. Concretely, models demonstrate fair behavior in only 9%-41% of stereotype-free sentences, suggesting that bias does not solely stem from the presence of gender-related words. These results raise important questions about where underlying model biases come from and highlight the need for more systematic and comprehensive bias evaluation. We release the full dataset and code at https://ucinlp.github.io/unstereo-eval.",
    "pdf_link": "https://arxiv.org/abs/2405.00588",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00588v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00588/figure.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00588v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00588/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00588v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00588/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00588v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00588/histplot--wordpmi--PILE-she-he.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00588v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00588/histplot--wordpmi--PILE-she-he-diff.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00588v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00588/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00588v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00588/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00588v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00588/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00588v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00588/x6.png"
      }
    ],
    "abstract_cn": "性别偏见研究揭示了大型语言模型中的不良行为，尤其是与职业和情感相关的性别刻板印象。研究发现，模型往往会因为训练数据中的性别相关性而加深这些刻板印象。本文聚焦于训练数据影响不明显的偏见问题，探讨语言模型在非刻板印象环境下是否仍存在性别偏见。我们提出了UnStereoEval（USE），一个新颖的框架，专为无性别刻板印象场景下探究性别偏见而设计。USE通过预训练数据的统计信息，为句子设定了一个级别分数，以判断其是否含有最少的词-性别关联。利用USE，我们自动生成了不含性别相关语言的基准，以系统地评估流行语言模型在无刻板印象场景下的公平性。此外，我们还利用USE的分数重新评估了先前的性别偏见基准（Winobias和Winogender），以进行非刻板印象的评估。研究发现，在所有测试的28个模型中，公平性普遍较低，模型在9%-41%的无刻板印象句子中才表现出公平行为，这表明偏见并非仅源自性别相关词汇。这一发现引发了关于模型潜在偏见来源的重要讨论，并突显了进行更系统和全面偏见评估的迫切需求。我们已经在 https://ucinlp.github.io/unstereo-eval 上公开了完整的数据集和代码。",
    "title_cn": "文本中若未涉及性别相关词汇，模型是否会表现出偏见？",
    "tags": [
      "LLM应用",
      "性别偏见",
      ""
    ]
  },
  {
    "title": "The Real, the Better: Aligning Large Language Models with Online Human Behaviors",
    "submit_datetime": "2024年05月01日",
    "abstract": "Large language model alignment is widely used and studied to avoid LLM producing unhelpful and harmful responses. However, the lengthy training process and predefined preference bias hinder adaptation to online diverse human preferences. To this end, this paper proposes an alignment framework, called Reinforcement Learning with Human Behavior (RLHB), to align LLMs by directly leveraging real online human behaviors. By taking the generative adversarial framework, the generator is trained to respond following expected human behavior; while the discriminator tries to verify whether the triplets of query, response, and human behavior come from real online environments. Behavior modeling in natural-language form and the multi-model joint training mechanism enable an active and sustainable online alignment. Experimental results confirm the effectiveness of our proposed methods by both human and automatic evaluations.",
    "pdf_link": "https://arxiv.org/abs/2405.00578",
    "graphs": [],
    "abstract_cn": "为防止大型语言模型（LLM）生成无益或有害的回答，对其对齐的研究和应用已相当广泛。但训练周期的漫长和固有的偏好偏差限制了其适应网络中多样化的人类偏好。本论文提出了一种名为“基于人类行为的强化学习（RLHB）”的对齐框架，该框架直接利用在线真实人类行为来调整 LLM。在生成对抗网络的框架下，训练生成器以模仿预期的人类行为做出回应，同时鉴别器负责判断查询、回答和人类行为的组合是否源自真实的在线情境。自然语言的行为建模和多模型联合训练机制，确保了在线对齐的活跃性和可持续性。实验结果通过人工和自动化评估验证了我们提出方法的有效性。",
    "title_cn": "追求真实，更上一层楼：使大型语言模型与网民在线行为同步。",
    "tags": [
      "LLM应用",
      "人工智能",
      ""
    ]
  },
  {
    "title": "EALD-MLLM: Emotion Analysis in Long-sequential and De-identity videos with Multi-modal Large Language Model",
    "submit_datetime": "2024年05月01日",
    "abstract": "Emotion AI is the ability of computers to understand human emotional states. Existing works have achieved promising progress, but two limitations remain to be solved: 1) Previous studies have been more focused on short sequential video emotion analysis while overlooking long sequential video. However, the emotions in short sequential videos only reflect instantaneous emotions, which may be deliberately guided or hidden. In contrast, long sequential videos can reveal authentic emotions; 2) Previous studies commonly utilize various signals such as facial, speech, and even sensitive biological signals (e.g., electrocardiogram). However, due to the increasing demand for privacy, developing Emotion AI without relying on sensitive signals is becoming important. To address the aforementioned limitations, in this paper, we construct a dataset for Emotion Analysis in Long-sequential and De-identity videos called EALD by collecting and processing the sequences of athletes' post-match interviews. In addition to providing annotations of the overall emotional state of each video, we also provide the Non-Facial Body Language (NFBL) annotations for each player. NFBL is an inner-driven emotional expression and can serve as an identity-free clue to understanding the emotional state. Moreover, we provide a simple but effective baseline for further research. More precisely, we evaluate the Multimodal Large Language Models (MLLMs) with de-identification signals (e.g., visual, speech, and NFBLs) to perform emotion analysis. Our experimental results demonstrate that: 1) MLLMs can achieve comparable, even better performance than the supervised single-modal models, even in a zero-shot scenario; 2) NFBL is an important cue in long sequential emotion analysis. EALD will be available on the open-source platform.",
    "pdf_link": "https://arxiv.org/abs/2405.00574",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00574v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00574/N3Touchingorscratchinghead.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.00574v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00574/N8Touchingears.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.00574v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00574/N11Touchingorscratchingneck.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.00574v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00574/N12Playingoradjustinghair.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.00574v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00574/N14Touchingorcoveringsuprasternalnotch.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.00574v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00574/N16Foldingarms.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.00574v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00574/N17Dustoffclothes.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.00574v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00574/N19Movingtorso.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.00574v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00574/N20Sitstraightly.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.00574v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00574/N24Minaretgesture.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.00574v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00574/N30Shakedoubleshoulders.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.00574v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00574/N34Touchingnose.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.00574v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00574/imiguevseald.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00574v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00574/waveform_plot_original.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00574v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00574/waveform_plot_deid.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00574v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00574/spectrogram_plot.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00574v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00574/spectrogram_plot_deid.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00574v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00574/Histogram.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00574v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00574/Framework.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00574v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00574/Usercase1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00574v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00574/Usercase2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00574v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00574/fail.png"
      }
    ],
    "abstract_cn": "情感人工智能，即机器对人类情感的洞察力，已在研究中取得显著成果，但仍有两大挑战亟待克服：首先，过往研究多聚焦于短视频情感分析，而忽略了长视频序列的重要性。短视频仅能捕捉瞬间情感，可能受人为操控或隐藏，而长视频则能展现更真实的情感表达；其次，尽管现有研究广泛采用面部、语音乃至敏感的生物信号（如心电图），但随着隐私保护意识的增强，开发不依赖敏感信息的情感AI技术变得尤为关键。为应对这些挑战，本文提出了一个新的数据集EALD，专注于长序列、去身份运动员赛后访谈的情感分析。我们不仅标注了每段视频的整体情感状态，还对每位运动员的非面部肢体语言（NFBL）进行了详细注释，NFBL作为一种内在的情感表达，为我们提供了一个不受身份影响的情感识别线索。此外，我们还建立了一个简洁而有效的基线模型，用于后续研究。通过评估多模态大型语言模型（MLLM）在去除身份信息信号（如视觉、语音和NFBL）后的情感分析性能，我们的实验证实了MLLM即使在零样本情况下也能与单模态监督模型相媲美，甚至更优，同时NFBL在长序列情感分析中扮演了关键角色。EALD数据集将面向公众开放。",
    "title_cn": "EALD-MLLM：利用多模态大型语言模型对长序列及去身份视频进行情感分析。",
    "tags": [
      "分类：Agent",
      "情感分析",
      "人工智能"
    ]
  },
  {
    "title": "NumLLM: Numeric-Sensitive Large Language Model for Chinese Finance",
    "submit_datetime": "2024年05月01日",
    "abstract": "Recently, many works have proposed various financial large language models (FinLLMs) by pre-training from scratch or fine-tuning open-sourced LLMs on financial corpora. However, existing FinLLMs exhibit unsatisfactory performance in understanding financial text when numeric variables are involved in questions. In this paper, we propose a novel LLM, called numeric-sensitive large language model (NumLLM), for Chinese finance. We first construct a financial corpus from financial textbooks which is essential for improving numeric capability of LLMs during fine-tuning. After that, we train two individual low-rank adaptation (LoRA) modules by fine-tuning on our constructed financial corpus. One module is for adapting general-purpose LLMs to financial domain, and the other module is for enhancing the ability of NumLLM to understand financial text with numeric variables. Lastly, we merge the two LoRA modules into the foundation model to obtain NumLLM for inference. Experiments on financial question-answering benchmark show that NumLLM can boost the performance of the foundation model and can achieve the best overall performance compared to all baselines, on both numeric and non-numeric questions.",
    "pdf_link": "https://arxiv.org/abs/2405.00566",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00566v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00566/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00566v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00566/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00566v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00566/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00566v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00566/x4.png"
      }
    ],
    "abstract_cn": "近期，众多研究提出了多种金融领域的大型语言模型（FinLLMs），这些模型通过从零开始预训练或对开源的大型语言模型（LLMs）进行金融语料库的微调来构建。但是，这些现有的金融LLMs在处理包含数值变量的金融文本理解任务时，表现不尽如人意。本文提出了一种创新的大型语言模型——数值敏感型大型语言模型（NumLLM），专门针对中文金融领域。我们首先从金融教科书中构建关键的金融语料库，这对于提升LLMs在微调阶段的数值处理能力极为重要。接着，我们在自建的金融语料库上对两个独立的低秩适应（LoRA）模块进行微调训练。其中一个模块旨在将通用型LLMs适配到金融领域，另一个则致力于提升NumLLM对含有数值变量的金融文本的理解力。最终，我们将这两个LoRA模块整合到基础模型中，形成用于推理的NumLLM。在金融问答领域的基准测试中，NumLLM不仅提升了基础模型的性能，而且在处理数值型和非数值型问题时均展现出超越所有对照基准的最优整体表现。",
    "title_cn": "NumLLM：一款专为中文金融领域设计的、对数值高度敏感的大型语言模型。",
    "tags": [
      "LLM应用",
      "",
      ""
    ]
  },
  {
    "title": "Mixture of insighTful Experts (MoTE): The Synergy of Thought Chains and Expert Mixtures in Self-Alignment",
    "submit_datetime": "2024年05月01日",
    "abstract": "As the capabilities of large language models (LLMs) have expanded dramatically, aligning these models with human values presents a significant challenge, posing potential risks during deployment. Traditional alignment strategies rely heavily on human intervention, such as Supervised Fine-Tuning (SFT) and Reinforcement Learning from Human Feedback (RLHF), or on the self-alignment capacities of LLMs, which usually require a strong LLM's emergent ability to improve its original bad answer. To address these challenges, we propose a novel self-alignment method that utilizes a Chain of Thought (CoT) approach, termed AlignCoT. This method encompasses stages of Question Analysis, Answer Guidance, and Safe Answer production. It is designed to enable LLMs to generate high-quality, safe responses throughout various stages of their development. Furthermore, we introduce the Mixture of insighTful Experts (MoTE) architecture, which applies the mixture of experts to enhance each component of the AlignCoT process, markedly increasing alignment efficiency. The MoTE approach not only outperforms existing methods in aligning LLMs with human values but also highlights the benefits of using self-generated data, revealing the dual benefits of improved alignment and training efficiency.",
    "pdf_link": "https://arxiv.org/abs/2405.00557",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00557v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00557/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00557v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00557/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00557v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00557/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00557v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00557/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00557v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00557/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00557v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00557/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00557v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00557/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00557v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00557/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00557v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00557/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00557v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00557/x10.png"
      }
    ],
    "abstract_cn": "随着大型语言模型（LLMs）功能的显著增强，如何使其与人类的价值观保持一致成为了一项重大挑战，并可能在实际应用中引发风险。传统的方法，如监督式微调（SFT）和基于人类反馈的强化学习（RLHF），往往依赖于人工介入，或是依赖于LLMs自身的对齐能力，这通常需要模型具备强大的自我改进能力。为了解决这些问题，我们提出了一种创新的自我对齐方法——思维链（Chain of Thought，CoT）方法，简称AlignCoT。该方法包含问题解析、答案引导和安全答案生成等环节，旨在帮助LLMs在成长过程中的各个阶段产出高品质且安全的回应。此外，我们还引入了洞察力专家混合（Mixture of insighTful Experts，MoTE）架构，该架构通过专家混合技术优化AlignCoT过程的每个环节，显著提升了对齐的效率。MoTE方法不仅在使LLMs与人类价值观对齐方面超越了现有技术，还展示了利用自生成数据的优势，实现了对齐精度和训练效率的双重提升。",
    "title_cn": "洞察力专家混合体（MoTE）：在自我对齐的过程中，思维链与专家组合的相互促进。",
    "tags": [
      "LLM应用",
      "人工智能",
      "伦理道德"
    ]
  },
  {
    "title": "Long-Term Human Trajectory Prediction using 3D Dynamic Scene Graphs",
    "submit_datetime": "2024年05月01日",
    "abstract": "We present a novel approach for long-term human trajectory prediction, which is essential for long-horizon robot planning in human-populated environments. State-of-the-art human trajectory prediction methods are limited by their focus on collision avoidance and short-term planning, and their inability to model complex interactions of humans with the environment. In contrast, our approach overcomes these limitations by predicting sequences of human interactions with the environment and using this information to guide trajectory predictions over a horizon of up to 60s. We leverage Large Language Models (LLMs) to predict interactions with the environment by conditioning the LLM prediction on rich contextual information about the scene. This information is given as a 3D Dynamic Scene Graph that encodes the geometry, semantics, and traversability of the environment into a hierarchical representation. We then ground these interaction sequences into multi-modal spatio-temporal distributions over human positions using a probabilistic approach based on continuous-time Markov Chains. To evaluate our approach, we introduce a new semi-synthetic dataset of long-term human trajectories in complex indoor environments, which also includes annotations of human-object interactions. We show in thorough experimental evaluations that our approach achieves a 54% lower average negative log-likelihood (NLL) and a 26.5% lower Best-of-20 displacement error compared to the best non-privileged baselines for a time horizon of 60s.",
    "pdf_link": "https://arxiv.org/abs/2405.00552",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00552v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00552/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00552v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00552/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00552v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00552/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00552v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00552/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00552v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00552/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00552v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00552/nll_stats_combined.png"
      }
    ],
    "abstract_cn": "我们提出了一种创新的长期人类轨迹预测方法，这对于机器人在人流密集的环境中进行长远规划极为关键。现行顶尖的轨迹预测技术多侧重于避碰和短期规划，缺乏模拟人与环境复杂互动的能力。我们的方案突破了这些局限，通过预测人与环境的互动序列，并据此信息在最长达60秒的时间内进行轨迹预测。我们运用大型语言模型（LLM），结合丰富的场景上下文信息，来预测环境互动，这些信息通过3D动态场景图以层次化的方式呈现，涵盖了环境的几何结构、语义信息和可通行性。随后，我们采用基于连续时间马尔可夫链的概率方法，将互动序列转化为人类位置的多模态时空分布。为验证我们的方法，我们创建了一个新的半合成数据集，记录了复杂室内环境中的长期人类轨迹及人-物互动的详细标注。实验结果表明，我们的方法在60秒的预测时限内，相较于最佳非特权基线，平均负对数似然（NLL）降低了54%，最佳20次位移误差减少了26.5%。",
    "title_cn": "通过 3D 动态场景图实现对人类长期轨迹的精准预测。",
    "tags": [
      "Agent",
      "机器人技术",
      "人工智能"
    ]
  },
  {
    "title": "A Legal Framework for Natural Language Processing Model Training in Portugal",
    "submit_datetime": "2024年05月01日",
    "abstract": "Recent advances in deep learning have promoted the advent of many computational systems capable of performing intelligent actions that, until then, were restricted to the human intellect. In the particular case of human languages, these advances allowed the introduction of applications like ChatGPT that are capable of generating coherent text without being explicitly programmed to do so. Instead, these models use large volumes of textual data to learn meaningful representations of human languages. Associated with these advances, concerns about copyright and data privacy infringements caused by these applications have emerged. Despite these concerns, the pace at which new natural language processing applications continued to be developed largely outperformed the introduction of new regulations. Today, communication barriers between legal experts and computer scientists motivate many unintentional legal infringements during the development of such applications. In this paper, a multidisciplinary team intends to bridge this communication gap and promote more compliant Portuguese NLP research by presenting a series of everyday NLP use cases, while highlighting the Portuguese legislation that may arise during its development.",
    "pdf_link": "https://arxiv.org/abs/2405.00536",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00536v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00536/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00536v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00536/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00536v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00536/x3.png"
      }
    ],
    "abstract_cn": "深度学习的最新突破催生了众多计算系统，它们能够执行以往只有人类智慧才能完成的智能任务。在人类语言领域，这一进步使得像ChatGPT这样的应用成为可能，它们无需明确编程即可生成连贯文本。这些模型依托海量文本数据，学习对人类语言的深刻理解。然而，这些技术进步也引发了关于版权和数据隐私侵犯的担忧。尽管如此，自然语言处理（NLP）应用的快速发展往往超越了法规更新的步伐。目前，法律专家与计算机科学家之间的沟通壁垒，常常在NLP应用开发过程中导致无意的法律违规。本文旨在通过展示一系列日常NLP应用案例，并指出开发中可能触及的葡萄牙法律，来弥合这一沟通鸿沟，推动葡萄牙NLP研究的合规性。",
    "title_cn": "葡萄牙建立了一个针对自然语言处理（NLP）模型训练的法律框架。",
    "tags": [
      "分类：LLM应用",
      "",
      ""
    ]
  },
  {
    "title": "ChatBI: Towards Natural Language to Complex Business Intelligence SQL",
    "submit_datetime": "2024年05月01日",
    "abstract": "The Natural Language to SQL (NL2SQL) technology provides non-expert users who are unfamiliar with databases the opportunity to use SQL for data analysis.Converting Natural Language to Business Intelligence (NL2BI) is a popular practical scenario for NL2SQL in actual production systems. Compared to NL2SQL, NL2BI introduces more challenges.\n  In this paper, we propose ChatBI, a comprehensive and efficient technology for solving the NL2BI task. First, we analyze the interaction mode, an important module where NL2SQL and NL2BI differ in use, and design a smaller and cheaper model to match this interaction mode. In BI scenarios, tables contain a huge number of columns, making it impossible for existing NL2SQL methods that rely on Large Language Models (LLMs) for schema linking to proceed due to token limitations. The higher proportion of ambiguous columns in BI scenarios also makes schema linking difficult. ChatBI combines existing view technology in the database community to first decompose the schema linking problem into a Single View Selection problem and then uses a smaller and cheaper machine learning model to select the single view with a significantly reduced number of columns. The columns of this single view are then passed as the required columns for schema linking into the LLM. Finally, ChatBI proposes a phased process flow different from existing process flows, which allows ChatBI to generate SQL containing complex semantics and comparison relations more accurately.\n  We have deployed ChatBI on Baidu's data platform and integrated it into multiple product lines for large-scale production task evaluation. The obtained results highlight its superiority in practicality, versatility, and efficiency. At the same time, compared with the current mainstream NL2SQL technology under our real BI scenario data tables and queries, it also achieved the best results.",
    "pdf_link": "https://arxiv.org/abs/2405.00527",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00527v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00527/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00527v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00527/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00527v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00527/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00527v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00527/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00527v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00527/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00527v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00527/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00527v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00527/x7.png"
      }
    ],
    "abstract_cn": "自然语言到SQL（NL2SQL）技术让不熟悉数据库的用户也能轻松运用SQL进行数据分析。而将自然语言转化为商业智能（NL2BI）则是NL2SQL技术在实际应用中的一个热门场景，它相较于NL2SQL面临更多挑战。本文提出了ChatBI，一项创新的高效技术，专为解决NL2BI问题而设计。我们首先深入分析了交互模式——这是NL2SQL与NL2BI在应用上的关键差异所在，并为此设计了一款体积更小、成本更低廉的模型。在商业智能（BI）场景中，数据表通常包含大量列，这对于依赖大型语言模型（LLMs）进行架构链接的传统NL2SQL方法来说，由于令牌限制而难以实现。此外，BI场景中模糊列的高比例也增加了架构链接的难度。ChatBI巧妙地结合了数据库领域现有的视图技术，先将架构链接问题简化为单一视图选择问题，再利用一款成本效益更高的机器学习模型来选取列数大幅减少的单一视图。随后，这个视图的列被用作LLM进行架构链接所需的列。ChatBI还提出了一种新颖的分阶段处理流程，与传统流程不同，它能够更精确地生成包含复杂语义和比较关系的SQL语句。我们在百度的数据平台上部署了ChatBI，并将其融入多条产品线，进行了大规模生产任务的评估。结果显示，ChatBI在实用性、通用性和效率方面均表现出色。与当前主流的NL2SQL技术相比，ChatBI在我们实际的BI场景数据表和查询中也取得了最优的成绩。",
    "title_cn": "ChatBI：探索将自然语言转换为复杂的商业智能SQL语句的路径",
    "tags": [
      "LLM应用",
      "商业智能",
      "数据库"
    ]
  },
  {
    "title": "Navigating WebAI: Training Agents to Complete Web Tasks with Large Language Models and Reinforcement Learning",
    "submit_datetime": "2024年05月01日",
    "abstract": "Recent advancements in language models have demonstrated remarkable improvements in various natural language processing (NLP) tasks such as web navigation. Supervised learning (SL) approaches have achieved impressive performance while utilizing significantly less training data compared to previous methods. However, these SL-based models fall short when compared to reinforcement learning (RL) approaches, which have shown superior results. In this paper, we propose a novel approach that combines SL and RL techniques over the MiniWoB benchmark to leverage the strengths of both methods. We also address a critical limitation in previous models' understanding of HTML content, revealing a tendency to memorize target elements rather than comprehend the underlying structure. To rectify this, we propose methods to enhance true understanding and present a new baseline of results. Our experiments demonstrate that our approach outperforms previous SL methods on certain tasks using less data and narrows the performance gap with RL models, achieving 43.58\\% average accuracy in SL and 36.69\\% when combined with a multimodal RL approach. This study sets a new direction for future web navigation and offers insights into the limitations and potential of language modeling for computer tasks.",
    "pdf_link": "https://arxiv.org/abs/2405.00516",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00516/comparison_existing_works.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.00516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00516/miniwob_examples.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00516/action_history.jpeg"
      },
      {
        "url": "https://arxiv.org/html/2405.00516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00516/T5_Model_Input.jpeg"
      },
      {
        "url": "https://arxiv.org/html/2405.00516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00516/reference_numbers_histogram.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00516/ccnet5_architecture.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00516/click_color_episode.jpeg"
      },
      {
        "url": "https://arxiv.org/html/2405.00516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00516/click-checkboxes-soft.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00516/use-spinner.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00516/bc_results_webnt5_comparison_random_ordered.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.00516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00516/ccnet5_ablation.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.00516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00516/bc_results_t5_base_hierarchical.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.00516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00516/bc_results_t5_large_hierarchical.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.00516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00516/bc_results_ccnet5.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.00516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00516/rl_results_ccnet5.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.00516v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00516/distribution_of_task_names.png"
      }
    ],
    "abstract_cn": "近期语言模型的突破在自然语言处理（NLP）领域，如网页导航等任务中取得了显著进步。相较于传统方法，监督学习（SL）策略在大幅减少训练数据的同时，依旧取得了卓越的成效。尽管如此，SL模型相较于强化学习（RL）策略仍有提升空间，后者在性能上更胜一筹。本文提出了一种创新的方法，将SL与RL技术相结合，针对MiniWoB基准测试，旨在发挥两种方法的长处。同时，我们针对先前模型在解析HTML内容上的一个主要缺陷进行了改进，即它们更倾向于记忆目标元素而非理解其结构。为此，我们提出了增强深层理解的方法，并设立了新的基准结果。实验结果证明，我们的方法在减少数据使用的同时，在某些任务上超越了传统SL方法，并与RL模型的性能差距显著缩小，SL方法的平均准确率达到了43.58%，而结合多模态RL策略时为36.69%。本研究不仅为未来网页导航的发展指明了新方向，还深入探讨了计算机任务中语言模型的局限性与潜力。",
    "title_cn": "探索 WebAI：通过大型语言模型和强化学习训练代理来完成网络任务。",
    "tags": [
      "LLM应用",
      "",
      "网页导航"
    ]
  },
  {
    "title": "GOLD: Geometry Problem Solver with Natural Language Description",
    "submit_datetime": "2024年05月01日",
    "abstract": "Addressing the challenge of automated geometry math problem-solving in artificial intelligence (AI) involves understanding multi-modal information and mathematics. Current methods struggle with accurately interpreting geometry diagrams, which hinders effective problem-solving. To tackle this issue, we present the Geometry problem sOlver with natural Language Description (GOLD) model. GOLD enhances the extraction of geometric relations by separately processing symbols and geometric primitives within the diagram. Subsequently, it converts the extracted relations into natural language descriptions, efficiently utilizing large language models to solve geometry math problems. Experiments show that the GOLD model outperforms the Geoformer model, the previous best method on the UniGeo dataset, by achieving accuracy improvements of 12.7% and 42.1% in calculation and proving subsets. Additionally, it surpasses the former best model on the PGPS9K and Geometry3K datasets, PGPSNet, by obtaining accuracy enhancements of 1.8% and 3.2%, respectively.",
    "pdf_link": "https://arxiv.org/abs/2405.00494",
    "graphs": [],
    "abstract_cn": "面对AI领域自动化几何数学问题求解的挑战，关键在于理解多模态信息与数学概念。现有技术在精确解读几何图形方面力有未逮，这限制了问题解决的效率。为此，我们引入了一种名为GOLD（Geometry problem sOlver with natural Language Description）的模型。GOLD通过区分处理图形中的符号和几何元素，优化了几何关系的识别。然后，它将这些关系转化为自然语言描述，并借助大型语言模型高效解决几何数学问题。在UniGeo数据集上的实验结果显示，GOLD模型在计算和证明任务的准确度上分别比前最佳方法Geoformer模型提升了12.7%和42.1%。同时，在PGPS9K和Geometry3K数据集上，GOLD模型也超越了PGPSNet模型，准确度分别提升了1.8%和3.2%。",
    "title_cn": "GOLD：一款能够理解自然语言描述来解决几何问题的智能求解器。",
    "tags": [
      "LLM应用",
      "AI自动化",
      "数学教育"
    ]
  },
  {
    "title": "Is Temperature the Creativity Parameter of Large Language Models?",
    "submit_datetime": "2024年05月01日",
    "abstract": "Large language models (LLMs) are applied to all sorts of creative tasks, and their outputs vary from beautiful, to peculiar, to pastiche, into plain plagiarism. The temperature parameter of an LLM regulates the amount of randomness, leading to more diverse outputs; therefore, it is often claimed to be the creativity parameter. Here, we investigate this claim using a narrative generation task with a predetermined fixed context, model and prompt. Specifically, we present an empirical analysis of the LLM output for different temperature values using four necessary conditions for creativity in narrative generation: novelty, typicality, cohesion, and coherence. We find that temperature is weakly correlated with novelty, and unsurprisingly, moderately correlated with incoherence, but there is no relationship with either cohesion or typicality. However, the influence of temperature on creativity is far more nuanced and weak than suggested by the \"creativity parameter\" claim; overall results suggest that the LLM generates slightly more novel outputs as temperatures get higher. Finally, we discuss ideas to allow more controlled LLM creativity, rather than relying on chance via changing the temperature parameter.",
    "pdf_link": "https://arxiv.org/abs/2405.00492",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00492v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00492/comp_eval_perplexity_write.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00492v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00492/comp_eval_cossim_write.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00492v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00492/comp_eval_normeditdist_write.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00492v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00492/pca_embeddings_per_temperature.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLM）在众多创意任务中大展身手，其成果或优美、或奇特、或模仿、甚至不乏抄袭之作。LLM中的温度参数控制着随机性，催生多样化的输出，因而被广泛认为是激发创造力的关键。本研究通过固定叙事生成任务的上下文、模型和提示，对这一观点进行了实证检验。我们依据叙事生成中创新性的四个要素——新颖度、典型性、紧密度和连贯性——对不同温度设置下的LLM输出进行了细致分析。研究发现，温度与新颖度的关联并不显著，与不连贯性有中等程度的相关性，但与紧密度和典型性并无直接联系。然而，温度对创造力的影响远比所谓的“创造力调节器”更为复杂和微弱。总体而言，LLM在温度升高时产生的输出新颖度略有提升。文末，我们探讨了如何更精细地控制LLM的创造力，而非单纯依赖于调整温度参数这一随机性因素。",
    "title_cn": "温度是否决定了大型语言模型的创造力？",
    "tags": [
      "LLM应用",
      "创意写作",
      "人工智能"
    ]
  },
  {
    "title": "Explainable Automatic Grading with Neural Additive Models",
    "submit_datetime": "2024年05月01日",
    "abstract": "The use of automatic short answer grading (ASAG) models may help alleviate the time burden of grading while encouraging educators to frequently incorporate open-ended items in their curriculum. However, current state-of-the-art ASAG models are large neural networks (NN) often described as \"black box\", providing no explanation for which characteristics of an input are important for the produced output. This inexplicable nature can be frustrating to teachers and students when trying to interpret, or learn from an automatically-generated grade. To create a powerful yet intelligible ASAG model, we experiment with a type of model called a Neural Additive Model that combines the performance of a NN with the explainability of an additive model. We use a Knowledge Integration (KI) framework from the learning sciences to guide feature engineering to create inputs that reflect whether a student includes certain ideas in their response. We hypothesize that indicating the inclusion (or exclusion) of predefined ideas as features will be sufficient for the NAM to have good predictive power and interpretability, as this may guide a human scorer using a KI rubric. We compare the performance of the NAM with another explainable model, logistic regression, using the same features, and to a non-explainable neural model, DeBERTa, that does not require feature engineering.",
    "pdf_link": "https://arxiv.org/abs/2405.00489",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00489v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00489/SoundwavesItem.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00489v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00489/SoundwavesRubric.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00489v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00489/NAM_featureimportance.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00489v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00489/NAM_density.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00489v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00489/NAM_density_all.png"
      }
    ],
    "abstract_cn": "采用自动短答题评分（ASAG）系统不仅能减轻教师的评分压力，还能促进开放式问题的广泛应用。尽管如此，现有的ASAG系统往往庞大且不透明，缺乏对评分依据的明确解释，这使得教师和学生难以理解评分结果。为了解决这一问题，我们探索了一种名为神经加性模型（NAM）的模型，它将神经网络的强大性能与加性模型的清晰解释力相结合。我们利用学习科学中的知识整合（KI）框架来指导特性工程，确保评分系统能够捕捉到学生回答中的关键思想。我们推测，将预定义思想的包含或遗漏作为评分特征，不仅能提高模型的预测准确性，还能增强其可解释性，从而辅助人工评分者使用KI标准进行评分。我们还对NAM的性能进行了评估，将其与逻辑回归这一可解释模型以及DeBERTa这一无需特性工程的不可解释神经模型进行了比较。",
    "title_cn": "神经加性模型在自动评分中的应用，实现了评分过程的可解释性。",
    "tags": [
      "分类：LLM应用",
      "",
      "自动评分系统"
    ]
  },
  {
    "title": "The Pyramid of Captions",
    "submit_datetime": "2024年05月01日",
    "abstract": "We introduce a formal information-theoretic framework for image captioning by regarding it as a representation learning task. Our framework defines three key objectives: task sufficiency, minimal redundancy, and human interpretability. Building upon this foundation, we propose a novel Pyramid of Captions (PoCa) method, which constructs caption pyramids by generating localized captions for zoomed-in image patches and integrating them with global caption information using large language models. This approach leverages intuition that the detailed examination of local patches can reduce error risks and address inaccuracies in global captions, either by correcting the hallucination or adding missing details. Based on our theoretical framework, we formalize this intuition and provide formal proof demonstrating the effectiveness of PoCa under certain assumptions. Empirical tests with various image captioning models and large language models show that PoCa consistently yields more informative and semantically aligned captions, maintaining brevity and interpretability.",
    "pdf_link": "https://arxiv.org/abs/2405.00485",
    "graphs": [],
    "abstract_cn": "本研究提出了一个基于信息论的图像字幕生成框架，将其定位为一种表示学习任务，并确立了三个核心目标：确保任务完整性、最小化信息冗余以及增强人类理解性。在此框架之上，我们创新性地提出了金字塔字幕（PoCa）方法，该方法通过为图像的放大区域生成细致的局部字幕，并将其与全局字幕信息相结合，利用大型语言模型来构建一个字幕层级结构。这种方法基于一个洞察：对图像局部区域的深入分析可以降低错误风险，并通过修正错误或补充细节来提高全局字幕的准确性。我们在理论上对这一洞察进行了形式化处理，并在特定条件下为PoCa的有效性提供了严格的证明。实证测试显示，PoCa方法在多种图像字幕模型和大型语言模型上的应用，都能产生信息丰富且语义一致的字幕，同时保证了文本的简洁和易于理解。",
    "title_cn": "标题层级金字塔",
    "tags": [
      "LLM应用",
      "图像处理",
      "人工智能"
    ]
  },
  {
    "title": "BiomedRAG: A Retrieval Augmented Large Language Model for Biomedicine",
    "submit_datetime": "2024年05月01日",
    "abstract": "Large Language Models (LLMs) have swiftly emerged as vital resources for different applications in the biomedical and healthcare domains; however, these models encounter issues such as generating inaccurate information or hallucinations. Retrieval-augmented generation provided a solution for these models to update knowledge and enhance their performance. In contrast to previous retrieval-augmented LMs, which utilize specialized cross-attention mechanisms to help LLM encode retrieved text, BiomedRAG adopts a simpler approach by directly inputting the retrieved chunk-based documents into the LLM. This straightforward design is easily applicable to existing retrieval and language models, effectively bypassing noise information in retrieved documents, particularly in noise-intensive tasks. Moreover, we demonstrate the potential for utilizing the LLM to supervise the retrieval model in the biomedical domain, enabling it to retrieve the document that assists the LM in improving its predictions. Our experiments reveal that with the tuned scorer,\\textsc{ BiomedRAG} attains superior performance across 5 biomedical NLP tasks, encompassing information extraction (triple extraction, relation extraction), text classification, link prediction, and question-answering, leveraging over 9 datasets. For instance, in the triple extraction task, \\textsc{BiomedRAG} outperforms other triple extraction systems with micro-F1 scores of 81.42 and 88.83 on GIT and ChemProt corpora, respectively.",
    "pdf_link": "https://arxiv.org/abs/2405.00465",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）在生物医学和医疗领域的多样化应用中迅速崭露头角，尽管它们有时会生成错误信息或产生幻觉。为了解决这些问题，检索增强生成技术应运而生，帮助模型刷新知识库并提升性能。与以往的检索增强语言模型相比，这些模型通常使用专门的交叉注意力机制来编码检索到的文本，BiomedRAG则采取了更为简洁的方法，直接将检索到的块状文档输入LLM。这种设计简化了现有检索和语言模型的应用，有效过滤了检索文档中的噪声，尤其是在噪声较多的任务中。此外，我们的研究还展示了利用LLM指导生物医学领域检索模型的潜力，以检索出能够辅助LLM提升预测准确度的文档。实验结果显示，在经过调整的评分器辅助下，BiomedRAG在5项生物医学自然语言处理任务上均展现出色的表现，这些任务包括信息抽取（三元组抽取、关系抽取）、文本分类、链接预测和问答，涵盖了9个以上的数据集。以三元组抽取任务为例，BiomedRAG在GIT和ChemProt语料库上的微F1分数分别达到了81.42和88.83，超越了其他同类系统。",
    "title_cn": "BiomedRAG：一种为生物医学领域设计的、结合了检索功能的先进大型语言模型。",
    "tags": [
      "RAG",
      "生物医学",
      ""
    ]
  },
  {
    "title": "Enhancing Surgical Robots with Embodied Intelligence for Autonomous Ultrasound Scanning",
    "submit_datetime": "2024年05月01日",
    "abstract": "Ultrasound robots are increasingly used in medical diagnostics and early disease screening. However, current ultrasound robots lack the intelligence to understand human intentions and instructions, hindering autonomous ultrasound scanning. To solve this problem, we propose a novel Ultrasound Embodied Intelligence system that equips ultrasound robots with the large language model (LLM) and domain knowledge, thereby improving the efficiency of ultrasound robots. Specifically, we first design an ultrasound operation knowledge database to add expertise in ultrasound scanning to the LLM, enabling the LLM to perform precise motion planning. Furthermore, we devise a dynamic ultrasound scanning strategy based on a \\textit{think-observe-execute} prompt engineering, allowing LLMs to dynamically adjust motion planning strategies during the scanning procedures. Extensive experiments demonstrate that our system significantly improves ultrasound scan efficiency and quality from verbal commands. This advancement in autonomous medical scanning technology contributes to non-invasive diagnostics and streamlined medical workflows.",
    "pdf_link": "https://arxiv.org/abs/2405.00461",
    "graphs": [],
    "abstract_cn": "超声机器人在医疗诊断和疾病早期筛查中的应用日益增多。但目前这类机器人尚不能理解人的意图和指令，限制了其在自主超声扫描方面的应用。为此，我们设计了一种创新的超声体现智能系统，通过集成大型语言模型（LLM）和特定领域知识，显著提升了超声机器人的工作效能。该系统首先构建了一个超声操作知识库，赋予LLM超声扫描的专业技能，实现精准的运动规划。同时，我们引入了一种基于“思考-观察-执行”循环的动态扫描策略，使LLM能够根据扫描过程实时优化其规划策略。大量实验证明，该系统能显著提升根据口头指令进行的超声扫描的效率和成像质量，这一技术突破为非侵入性诊断和医疗流程的优化提供了有力支持。",
    "title_cn": "为手术机器人注入体现智能，提升其进行自主超声扫描的性能。",
    "tags": [
      "分类：Agent",
      "",
      "机器人技术"
    ]
  },
  {
    "title": "Monte Carlo Tree Search Boosts Reasoning via Iterative Preference Learning",
    "submit_datetime": "2024年05月01日",
    "abstract": "We introduce an approach aimed at enhancing the reasoning capabilities of Large Language Models (LLMs) through an iterative preference learning process inspired by the successful strategy employed by AlphaZero. Our work leverages Monte Carlo Tree Search (MCTS) to iteratively collect preference data, utilizing its look-ahead ability to break down instance-level rewards into more granular step-level signals. To enhance consistency in intermediate steps, we combine outcome validation and stepwise self-evaluation, continually updating the quality assessment of newly generated data. The proposed algorithm employs Direct Preference Optimization (DPO) to update the LLM policy using this newly generated step-level preference data. Theoretical analysis reveals the critical importance of using on-policy sampled data for successful self-improving. Extensive evaluations on various arithmetic and commonsense reasoning tasks demonstrate remarkable performance improvements over existing models. For instance, our approach outperforms the Mistral-7B Supervised Fine-Tuning (SFT) baseline on GSM8K, MATH, and SciQ, with substantial percentage increases in accuracy to $80.7\\%$ (+$4.8\\%$), $32.2\\%$ (+$3.3\\%$), and $88.5\\%$ (+$7.7\\%$), respectively. Additionally, our research delves into the training and inference compute tradeoff, providing insights into how our method effectively maximizes performance gains.",
    "pdf_link": "https://arxiv.org/abs/2405.00451",
    "graphs": [],
    "abstract_cn": "本文提出了一种新方法，通过模仿 AlphaZero 的迭代偏好学习策略，以提升大型语言模型（LLMs）的推理能力。该方法采用蒙特卡洛树搜索（MCTS）技术，逐步搜集偏好数据，并通过前瞻性分析将奖励细化到每一步，从而增强了处理过程中的连贯性。结合结果验证和分步自我评估，我们不断优化新数据的质量评估。新算法运用直接偏好优化（DPO）技术，根据这些细化的偏好数据来调整 LLMs 的策略。理论分析显示，使用策略内抽样数据对于自我提升至关重要。在多项算术和常识推理任务上的测试表明，该方法相较于现有模型，如 Mistral-7B 监督式微调（SFT）基线，在 GSM8K、MATH 和 SciQ 等任务上均取得了显著的性能提升，准确率分别提升了 4.8%、3.3% 和 7.7%。此外，本研究还探讨了训练与推理计算之间的平衡，揭示了我们的方法如何高效地实现性能最大化。",
    "title_cn": "蒙特卡洛树搜索（MCTS）通过不断迭代的偏好学习，显著提升了推理能力。",
    "tags": [
      "分类：LLM理论",
      "人工智能",
      ""
    ]
  },
  {
    "title": "RAG-based Explainable Prediction of Road Users Behaviors for Automated Driving using Knowledge Graphs and Large Language Models",
    "submit_datetime": "2024年05月01日",
    "abstract": "Prediction of road users' behaviors in the context of autonomous driving has gained considerable attention by the scientific community in the last years. Most works focus on predicting behaviors based on kinematic information alone, a simplification of the reality since road users are humans, and as such they are highly influenced by their surrounding context. In addition, a large plethora of research works rely on powerful Deep Learning techniques, which exhibit high performance metrics in prediction tasks but may lack the ability to fully understand and exploit the contextual semantic information contained in the road scene, not to mention their inability to provide explainable predictions that can be understood by humans. In this work, we propose an explainable road users' behavior prediction system that integrates the reasoning abilities of Knowledge Graphs (KG) and the expressiveness capabilities of Large Language Models (LLM) by using Retrieval Augmented Generation (RAG) techniques. For that purpose, Knowledge Graph Embeddings (KGE) and Bayesian inference are combined to allow the deployment of a fully inductive reasoning system that enables the issuing of predictions that rely on legacy information contained in the graph as well as on current evidence gathered in real time by onboard sensors. Two use cases have been implemented following the proposed approach: 1) Prediction of pedestrians' crossing actions; 2) Prediction of lane change maneuvers. In both cases, the performance attained surpasses the current state of the art in terms of anticipation and F1-score, showing a promising avenue for future research in this field.",
    "pdf_link": "https://arxiv.org/abs/2405.00449",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00449v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00449/figure-manzour.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00449v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00449/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00449v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00449/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00449v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00449/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00449v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00449/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00449v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00449/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00449v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00449/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00449v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00449/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00449v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00449/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00449v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00449/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00449v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00449/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00449v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00449/x11.png"
      }
    ],
    "abstract_cn": "近年来，科学界对自动驾驶环境下道路使用者行为预测的研究兴趣日益浓厚。现有研究多侧重于利用运动学信息进行行为预测，忽略了作为人类的道路使用者受周围环境影响的复杂性。同时，众多研究依赖于深度学习技术，虽然在预测任务上表现优异，但在理解并利用道路场景中的上下文语义信息方面存在不足，且难以提供人类可理解的解释性预测。本研究提出了一种结合知识图谱推理能力和大型语言模型表达能力的可解释道路使用者行为预测系统，采用检索增强生成技术，通过知识图谱嵌入和贝叶斯推断，构建了一个完全归纳的推理系统。该系统能够基于图谱中的既有信息和车载传感器实时收集的当前证据发布预测。研究中实现了两个应用案例：预测行人过街行为和车道变换操作，均在预测准确性和F1分数上超越了当前技术，为该领域未来研究开辟了新的可能性。",
    "title_cn": "利用知识图谱和大型语言模型，基于 RAG（Retrieval-Augmented Generation）框架，对自动驾驶中道路使用者的行为进行可解释预测。",
    "tags": [
      "Agent",
      "自动驾驶",
      "知识图谱"
    ]
  },
  {
    "title": "CultiVerse: Towards Cross-Cultural Understanding for Paintings with Large Language Model",
    "submit_datetime": "2024年05月01日",
    "abstract": "The integration of new technology with cultural studies enhances our understanding of cultural heritage but often struggles to connect with diverse audiences. It is challenging to align personal interpretations with the intended meanings across different cultures. Our study investigates the important factors in appreciating art from a cross-cultural perspective. We explore the application of Large Language Models (LLMs) to bridge the cultural and language barriers in understanding Traditional Chinese Paintings (TCPs). We present CultiVerse, a visual analytics system that utilizes LLMs within a mixed-initiative framework, enhancing interpretative appreciation of TCP in a cross-cultural dialogue. CultiVerse addresses the challenge of translating the nuanced symbolism in art, which involves interpreting complex cultural contexts, aligning cross-cultural symbols, and validating cultural acceptance. CultiVerse integrates an interactive interface with the analytical capability of LLMs to explore a curated TCP dataset, facilitating the analysis of multifaceted symbolic meanings and the exploration of cross-cultural serendipitous discoveries. Empirical evaluations affirm that CultiVerse significantly improves cross-cultural understanding, offering deeper insights and engaging art appreciation.",
    "pdf_link": "https://arxiv.org/abs/2405.00435",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00435v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00435/abstract.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00435v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00435/requirement.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00435v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00435/workflow.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00435v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00435/normdesign.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00435v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00435/case2_1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00435v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00435/case2_2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00435v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00435/EVA.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00435v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00435/insight.png"
      }
    ],
    "abstract_cn": "将尖端科技与文化研究相结合，可以深化我们对文化传承的认识，但要吸引多元受众却非易事。在不同文化背景下，将个人的解读与作品的本意相匹配尤为困难。本研究致力于探究跨文化视角下艺术欣赏的关键要素。我们研究了大型语言模型（LLMs）在跨越文化和语言障碍、增进对中国传统绘画（TCPs）理解方面的潜力。我们介绍了CultiVerse，这是一款视觉分析系统，它采用了混合主动性框架内的LLMs，提升了跨文化交流中对TCP的深入理解。CultiVerse致力于解决艺术作品中细腻象征意义的翻译难题，这包括解读复杂的文化背景、对齐不同文化中的象征元素，并确认文化认同。CultiVerse结合了互动界面与LLMs的分析功能，对精选的TCP数据集进行探索，助力多维度象征意义的分析和跨文化意外发现的探索。实证评估表明，CultiVerse显著提升了跨文化理解能力，为艺术欣赏提供了更深层次的洞察和更具吸引力的体验。",
    "title_cn": "CultiVerse：迈向利用大型语言模型深化对绘画艺术的跨文化洞察。",
    "tags": [
      "分类：LLM应用\n\n这篇论文探讨了大型语言模型（LLMs）在跨文化艺术欣赏中的应用，特别是如何利用LLMs来增进对中国传统绘画（TCPs）的理解。通过引入CultiVerse这一视觉分析系统，该系统采用了混合主动性框架内的LLMs，来解决艺术作品中文化象征意义的翻译难题。这表明了LLMs在跨文化交流和艺术欣赏领域的应用潜力，因此将其归类为LLM应用。",
      "文化研究",
      "艺术欣赏"
    ]
  },
  {
    "title": "Self-Refine Instruction-Tuning for Aligning Reasoning in Language Models",
    "submit_datetime": "2024年05月01日",
    "abstract": "The alignments of reasoning abilities between smaller and larger Language Models are largely conducted via Supervised Fine-Tuning (SFT) using demonstrations generated from robust Large Language Models (LLMs). Although these approaches deliver more performant models, they do not show sufficiently strong generalization ability as the training only relies on the provided demonstrations.\n  In this paper, we propose the Self-refine Instruction-tuning method that elicits Smaller Language Models to self-refine their abilities. Our approach is based on a two-stage process, where reasoning abilities are first transferred between LLMs and Small Language Models (SLMs) via Instruction-tuning on demonstrations provided by LLMs, and then the instructed models Self-refine their abilities through preference optimization strategies. In particular, the second phase operates refinement heuristics based on the Direct Preference Optimization algorithm, where the SLMs are elicited to deliver a series of reasoning paths by automatically sampling the generated responses and providing rewards using ground truths from the LLMs. Results obtained on commonsense and math reasoning tasks show that this approach significantly outperforms Instruction-tuning in both in-domain and out-domain scenarios, aligning the reasoning abilities of Smaller and Larger Language Models.",
    "pdf_link": "https://arxiv.org/abs/2405.00402",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/DPO_new.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/OBQA_in_family.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/PIQA_in_family.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/GSM8K_in_family.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/CSQA_in_family.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/SIQA_in_family.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/MultiArith_in_family.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/legend_in_family.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/OBQA_out_family.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/PIQA_out_family.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/GSM8K_out_family.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/CSQA_out_family.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/SIQA_out_family.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/MultiArith_out_family.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/legend_out_family.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/OBQA_Llama2_7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/CSQA_Llama2_7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/PIQA_Llama2_7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/SIQA_Llama2_7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/OBQA_Llama2_13.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/CSQA_Llama2_13.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/PIQA_Llama2_13.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/SIQA_Llama2_13.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/Legend.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/MATH_in_family.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/MMLU_in_family.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/legend_in_family.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/MATH_out_family.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/MMLU_out_family.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00402v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00402/legend_out_family.png"
      }
    ],
    "abstract_cn": "本文提出了一种自我精炼指令调整方法，旨在激发小型语言模型（SLMs）自主提升其推理能力。该方法采用两阶段流程：首先，通过LLMs提供的示例进行指令调整，将推理能力从大型语言模型（LLMs）迁移至SLMs；其次，经过指令调整的模型通过偏好优化策略进行自我能力提升。特别是在第二阶段，SLMs利用直接偏好优化算法，自动采样生成的响应，并通过LLMs的基准真值来提供奖励，从而生成一系列推理路径。在常识推理和数学推理任务上的实验结果表明，这种方法在领域内和跨领域场景中均显著超越了传统的指令调整方法，有效拉近了小型与大型语言模型在推理能力上的差距。",
    "title_cn": "自我精炼的指令调优：优化语言模型中的推理对齐。",
    "tags": [
      "LLM应用",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Inferring State Machine from the Protocol Implementation via Large Langeuage Model",
    "submit_datetime": "2024年05月01日",
    "abstract": "State machines play a pivotal role in augmenting the efficacy of protocol analyzing to unveil more vulnerabilities. However, the task of inferring state machines from network protocol implementations presents significant challenges. Traditional methods based on dynamic analysis often overlook crucial state transitions due to limited coverage, while static analysis faces difficulties with complex code structures and behaviors. To address these limitations, we propose an innovative state machine inference approach powered by Large Language Models (LLMs). Utilizing text-embedding technology, this method allows LLMs to dissect and analyze the intricacies of protocol implementation code. Through targeted prompt engineering, we systematically identify and infer the underlying state machines. Our evaluation across six protocol implementations demonstrates the method's high efficacy, achieving an accuracy rate exceeding 90% and successfully delineating differences on state machines among various implementations of the same protocol. Importantly, integrating this approach with protocol fuzzing has notably enhanced AFLNet's code coverage by 10% over RFCNLP, showcasing the considerable potential of LLMs in advancing network protocol security analysis. Our proposed method not only marks a significant step forward in accurate state machine inference but also opens new avenues for improving the security and reliability of protocol implementations.",
    "pdf_link": "https://arxiv.org/abs/2405.00393",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00393v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00393/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00393v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00393/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00393v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00393/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00393v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00393/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00393v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00393/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00393v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00393/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00393v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00393/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00393v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00393/x8.png"
      }
    ],
    "abstract_cn": "状态机对于深入挖掘协议中的潜在漏洞至关重要。但要从网络协议的实现中推导出状态机，却是一个充满挑战的任务。传统动态分析方法因覆盖面不足而常常漏掉关键状态转换，静态分析则在复杂的代码结构面前显得力不从心。为克服这些难题，我们引入了一种新颖的状态机推断技术，该技术借助大型语言模型（LLMs）的威力。通过文本嵌入技术，LLMs能够深入剖析协议实现代码的细节。我们通过精心设计的提示策略，系统地识别并推断出隐含的状态机。在六种协议实现上的测试结果表明，该方法极为有效，准确度超过90%，并能成功区分相同协议不同实现之间的状态机差异。更值得一提的是，将此方法与协议模糊测试相结合，使得AFLNet的代码覆盖率比RFCNLP提升了10%，充分证明了LLMs在网络协议安全分析领域的巨大潜力。我们提出的这一方法不仅在精确推断状态机方面取得了显著进展，也为提升协议实现的安全性和可靠性开辟了新的路径。",
    "title_cn": "利用大型语言模型，从协议实现中推导出状态机。",
    "tags": [
      "LLM应用",
      "网络安全",
      "协议分析"
    ]
  },
  {
    "title": "CofiPara: A Coarse-to-fine Paradigm for Multimodal Sarcasm Target Identification with Large Multimodal Models",
    "submit_datetime": "2024年05月01日",
    "abstract": "Social media abounds with multimodal sarcasm, and identifying sarcasm targets is particularly challenging due to the implicit incongruity not directly evident in the text and image modalities. Current methods for Multimodal Sarcasm Target Identification (MSTI) predominantly focus on superficial indicators in an end-to-end manner, overlooking the nuanced understanding of multimodal sarcasm conveyed through both the text and image. This paper proposes a versatile MSTI framework with a coarse-to-fine paradigm, by augmenting sarcasm explainability with reasoning and pre-training knowledge. Inspired by the powerful capacity of Large Multimodal Models (LMMs) on multimodal reasoning, we first engage LMMs to generate competing rationales for coarser-grained pre-training of a small language model on multimodal sarcasm detection. We then propose fine-tuning the model for finer-grained sarcasm target identification. Our framework is thus empowered to adeptly unveil the intricate targets within multimodal sarcasm and mitigate the negative impact posed by potential noise inherently in LMMs. Experimental results demonstrate that our model far outperforms state-of-the-art MSTI methods, and markedly exhibits explainability in deciphering sarcasm as well.",
    "pdf_link": "https://arxiv.org/abs/2405.00390",
    "graphs": [],
    "abstract_cn": "社交媒体上的多模态讽刺层出不穷，识别其目标颇具挑战，因为文本和图像中隐含的不一致性并不明显。现行的多模态讽刺目标识别技术大多只关注表面现象，忽略了对讽刺深层次理解的必要性。本文提出了一种新颖的识别框架，它采用由粗到细的方法，通过增强推理能力和预训练知识来提升讽刺的可解释性。借鉴大型多模态模型在多模态推理上的卓越表现，我们首先利用这些模型为多模态讽刺检测生成初步的竞争性解释，然后对小型语言模型进行微调，以实现更精细的讽刺目标识别。我们的框架能够有效地揭示多模态讽刺中的微妙目标，并减少大型模型中固有噪声的负面影响。实验结果显示，我们的模型在识别多模态讽刺目标方面大大超越了现有的顶尖方法，并且在解释讽刺方面表现出了显著的可解释性。",
    "title_cn": "CofiPara：一种从粗略到精细的多模态讽刺目标识别方法，适用于大型多模态模型。",
    "tags": [
      "分类：LLM应用\n\n这篇论文提出了一种新颖的识别框架，用于识别社交媒体上的多模态讽刺目标。它利用大型多模态模型生成初步的解释，然后对小型语言模型进行微调，以实现更精细的讽刺目标识别。这篇论文的研究重点是提高讽刺目标识别的准确性和可解释性，因此它属于LLM应用类别。",
      "社交媒体分析",
      "人工智能"
    ]
  },
  {
    "title": "AdaMoLE: Fine-Tuning Large Language Models with Adaptive Mixture of Low-Rank Adaptation Experts",
    "submit_datetime": "2024年05月01日",
    "abstract": "We introduce AdaMoLE, a novel method for fine-tuning large language models (LLMs) through an Adaptive Mixture of Low-Rank Adaptation (LoRA) Experts. Moving beyond conventional methods that employ a static top-k strategy for activating experts, AdaMoLE dynamically adjusts the activation threshold using a dedicated threshold network, adaptively responding to the varying complexities of different tasks. By replacing a single LoRA in a layer with multiple LoRA experts and integrating a gating function with the threshold mechanism, AdaMoLE effectively selects and activates the most appropriate experts based on the input context. Our extensive evaluations across a variety of commonsense reasoning and natural language processing tasks show that AdaMoLE exceeds baseline performance. This enhancement highlights the advantages of AdaMoLE's adaptive selection of LoRA experts, improving model effectiveness without a corresponding increase in the expert count. The experimental validation not only confirms AdaMoLE as a robust approach for enhancing LLMs but also suggests valuable directions for future research in adaptive expert selection mechanisms, potentially broadening the scope for optimizing model performance across diverse language processing tasks.",
    "pdf_link": "https://arxiv.org/abs/2405.00361",
    "graphs": [],
    "abstract_cn": "我们推出了 AdaMoLE，这是一种创新的微调大型语言模型（LLM）的方法，它通过自适应的低秩适应（LoRA）专家混合来实现。与传统的静态 top-k 激活策略不同，AdaMoLE 利用专用的阈值网络动态调整激活阈值，以适应多样化任务的复杂性变化。该方法通过在模型层中引入多个 LoRA 专家，并结合门控函数与阈值机制，能够根据输入情境精准地选择并激活最合适的专家。经过我们在多种常识推理和自然语言处理任务上的深入评估，AdaMoLE 的表现超越了传统基线。这一提升凸显了 AdaMoLE 在自适应选择 LoRA 专家方面的优势，它在不增加专家数量的前提下提升了模型效能。实验的验证不仅证明了 AdaMoLE 是一种增强 LLM 的可靠方法，也为未来自适应专家选择机制的研究指明了有价值方向，这可能会为优化各类语言处理任务的模型性能开辟新的可能性。",
    "title_cn": "AdaMoLE：以自适应低秩专家混合策略，对大型语言模型进行精准微调。",
    "tags": [
      "LLM应用",
      "",
      "机器学习"
    ]
  },
  {
    "title": "Exploring Self-Supervised Vision Transformers for Deepfake Detection: A Comparative Analysis",
    "submit_datetime": "2024年05月01日",
    "abstract": "This paper investigates the effectiveness of self-supervised pre-trained transformers compared to supervised pre-trained transformers and conventional neural networks (ConvNets) for detecting various types of deepfakes. We focus on their potential for improved generalization, particularly when training data is limited. Despite the notable success of large vision-language models utilizing transformer architectures in various tasks, including zero-shot and few-shot learning, the deepfake detection community has still shown some reluctance to adopt pre-trained vision transformers (ViTs), especially large ones, as feature extractors. One concern is their perceived excessive capacity, which often demands extensive data, and the resulting suboptimal generalization when training or fine-tuning data is small or less diverse. This contrasts poorly with ConvNets, which have already established themselves as robust feature extractors. Additionally, training and optimizing transformers from scratch requires significant computational resources, making this accessible primarily to large companies and hindering broader investigation within the academic community. Recent advancements in using self-supervised learning (SSL) in transformers, such as DINO and its derivatives, have showcased significant adaptability across diverse vision tasks and possess explicit semantic segmentation capabilities. By leveraging DINO for deepfake detection with modest training data and implementing partial fine-tuning, we observe comparable adaptability to the task and the natural explainability of the detection result via the attention mechanism. Moreover, partial fine-tuning of transformers for deepfake detection offers a more resource-efficient alternative, requiring significantly fewer computational resources.",
    "pdf_link": "https://arxiv.org/abs/2405.00355",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00355v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00355/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00355v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00355/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00355v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00355/x3.png"
      }
    ],
    "abstract_cn": "本研究探讨了自监督预训练变换器在识别各类深度伪造对象时，相较于传统监督预训练变换器和常规神经网络的优势，尤其是在数据训练受限的情况下对泛化能力的提升。尽管变换器架构在视觉-语言模型中的应用已在多项任务中取得了显著成果，包括零样本和少样本学习，但深度伪造检测领域对于采纳预训练视觉变换器，尤其是大型模型，作为特征提取器仍持谨慎态度。主要顾虑在于这些模型的高容量特性，它们通常需要大量数据支持，这在训练数据稀缺或多样性不足时可能导致泛化性能不佳，这与已经证明其鲁棒性的ConvNets形成对比。而且，从头开始训练和优化变换器需要巨大的计算资源，这通常只有大型公司能够承担，限制了学术界的深入研究。然而，自监督学习（SSL）在变换器中的应用，如DINO及其衍生模型，已在多种视觉任务中显示出强大的适应性和语义分割能力。通过采用DINO进行深度伪造检测，并结合适度的训练数据和部分微调策略，我们发现模型能够很好地适应检测任务，并通过注意力机制自然地解释检测结果。此外，对变换器进行部分微调的方法，为深度伪造检测提供了一种更为高效的资源利用方式，显著降低了计算资源的需求。",
    "title_cn": "本研究深入探讨了自监督视觉变换器在深度伪造检测中的应用，并进行了一项全面的比较分析。",
    "tags": [
      "分类：LLM应用",
      "深度伪造检测",
      "自监督学习"
    ]
  },
  {
    "title": "Distillation Matters: Empowering Sequential Recommenders to Match the Performance of Large Language Model",
    "submit_datetime": "2024年05月01日",
    "abstract": "Owing to their powerful semantic reasoning capabilities, Large Language Models (LLMs) have been effectively utilized as recommenders, achieving impressive performance. However, the high inference latency of LLMs significantly restricts their practical deployment. To address this issue, this work investigates knowledge distillation from cumbersome LLM-based recommendation models to lightweight conventional sequential models. It encounters three challenges: 1) the teacher's knowledge may not always be reliable; 2) the capacity gap between the teacher and student makes it difficult for the student to assimilate the teacher's knowledge; 3) divergence in semantic space poses a challenge to distill the knowledge from embeddings. To tackle these challenges, this work proposes a novel distillation strategy, DLLM2Rec, specifically tailored for knowledge distillation from LLM-based recommendation models to conventional sequential models. DLLM2Rec comprises: 1) Importance-aware ranking distillation, which filters reliable and student-friendly knowledge by weighting instances according to teacher confidence and student-teacher consistency; 2) Collaborative embedding distillation integrates knowledge from teacher embeddings with collaborative signals mined from the data. Extensive experiments demonstrate the effectiveness of the proposed DLLM2Rec, boosting three typical sequential models with an average improvement of 47.97%, even enabling them to surpass LLM-based recommenders in some cases.",
    "pdf_link": "https://arxiv.org/abs/2405.00338",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00338v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00338/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00338v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00338/x2.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）凭借其卓越的语义推理能力，在推荐系统中发挥着重要作用，表现出色。但它们的高推理延迟成为了实际应用的瓶颈。为克服这一难题，本研究提出了一种从复杂的LLM推荐模型向传统顺序模型进行知识蒸馏的新方法。这一过程面临三大挑战：教师知识的不稳定性、师生容量差异导致的学习难题，以及语义空间发散性对嵌入知识蒸馏的影响。为此，我们设计了一种创新的蒸馏策略DLLM2Rec，专门用于实现这一转换。DLLM2Rec包含两个核心组件：一是重要性感知排名蒸馏，它通过权衡教师信心和师生一致性来筛选可靠的、适合学生的知识；二是协作嵌入蒸馏，它将教师嵌入的知识与数据中挖掘的协作信号相结合。通过大量实验，我们验证了DLLM2Rec的有效性，它平均提升了三种典型顺序模型性能的47.97%，在某些情况下甚至超过了基于LLM的推荐系统。",
    "title_cn": "蒸馏技术至关重要：它能够提升序列推荐系统的性能，使其达到大型语言模型的水平。",
    "tags": [
      "分类：LLM应用",
      "推荐系统",
      "知识蒸馏"
    ]
  },
  {
    "title": "A Careful Examination of Large Language Model Performance on Grade School Arithmetic",
    "submit_datetime": "2024年05月01日",
    "abstract": "Large language models (LLMs) have achieved impressive success on many benchmarks for mathematical reasoning. However, there is growing concern that some of this performance actually reflects dataset contamination, where data closely resembling benchmark questions leaks into the training data, instead of true reasoning ability. To investigate this claim rigorously, we commission Grade School Math 1000 (GSM1k). GSM1k is designed to mirror the style and complexity of the established GSM8k benchmark, the gold standard for measuring elementary mathematical reasoning. We ensure that the two benchmarks are comparable across important metrics such as human solve rates, number of steps in solution, answer magnitude, and more. When evaluating leading open- and closed-source LLMs on GSM1k, we observe accuracy drops of up to 13%, with several families of models (e.g., Phi and Mistral) showing evidence of systematic overfitting across almost all model sizes. At the same time, many models, especially those on the frontier, (e.g., Gemini/GPT/Claude) show minimal signs of overfitting. Further analysis suggests a positive relationship (Spearman's r^2=0.32) between a model's probability of generating an example from GSM8k and its performance gap between GSM8k and GSM1k, suggesting that many models may have partially memorized GSM8k.",
    "pdf_link": "https://arxiv.org/abs/2405.00332",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00332v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00332/gsm8k_vs_gsm8k_scale_0.0_special_bar.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.00332v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00332/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00332v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00332/answer_cdf.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.00332v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00332/gsm8k_vs_gsm8k_scale_0.0_good.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.00332v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00332/gsm8k_vs_gsm8k_scale_0.0_medium.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.00332v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00332/gsm8k_vs_gsm8k_scale_0.0_bad.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.00332v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00332/ll_graph.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00332v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00332/instructions.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00332v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00332/ll_graph_gsm1k.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00332v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00332/ll_graph_difference.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00332v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00332/gsm8k_vs_gsm8k_scale_0.0_good_bar.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.00332v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00332/gsm8k_vs_gsm8k_scale_0.0_medium_bar.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.00332v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00332/gsm8k_vs_gsm8k_scale_0.0_bad_bar.jpg"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）在数学推理的多项基准测试中取得了显著成就。但人们担忧，这些成绩可能并非真实推理能力的体现，而是由于训练数据中混入了与测试题目极为相似的数据，导致成绩虚高。为了深入探究这一问题，我们推出了Grade School Math 1000（GSM1k）测试。GSM1k在设计上与公认的小学数学推理基准测试GSM8k保持一致，无论是在题型风格还是难度上。我们确保两个测试在解题步骤数量、解答难度等多个关键指标上具有可比性。在对当前主流的开源和闭源LLMs进行GSM1k测试时，我们发现准确率下降了高达13%，部分模型系列（如Phi和Mistral）几乎在所有模型尺寸上都表现出了系统性的过拟合。与此同时，许多前沿模型（如Gemini/GPT/Claude）则几乎没有过拟合的迹象。进一步分析还发现，模型生成GSM8k中题目的概率与其在GSM8k和GSM1k之间性能差异之间存在正相关（Spearman相关系数r^2=0.32），这表明许多模型可能已经部分记忆了GSM8k的题目。",
    "title_cn": "深入剖析大型语言模型在小学算术任务上的表现",
    "tags": [
      "分类：LLM理论",
      "数学教育",
      "人工智能"
    ]
  },
  {
    "title": "Integrating A.I. in Higher Education: Protocol for a Pilot Study with 'SAMCares: An Adaptive Learning Hub'",
    "submit_datetime": "2024年05月01日",
    "abstract": "Learning never ends, and there is no age limit to grow yourself. However, the educational landscape may face challenges in effectively catering to students' inclusion and diverse learning needs. These students should have access to state-of-the-art methods for lecture delivery, online resources, and technology needs. However, with all the diverse learning sources, it becomes harder for students to comprehend a large amount of knowledge in a short period of time. Traditional assistive technologies and learning aids often lack the dynamic adaptability required for individualized education plans. Large Language Models (LLM) have been used in language translation, text summarization, and content generation applications. With rapid growth in AI over the past years, AI-powered chatbots and virtual assistants have been developed. This research aims to bridge this gap by introducing an innovative study buddy we will be calling the 'SAMCares'. The system leverages a Large Language Model (LLM) (in our case, LLaMa-2 70B as the base model) and Retriever-Augmented Generation (RAG) to offer real-time, context-aware, and adaptive educational support. The context of the model will be limited to the knowledge base of Sam Houston State University (SHSU) course notes. The LLM component enables a chat-like environment to interact with it to meet the unique learning requirements of each student. For this, we will build a custom web-based GUI. At the same time, RAG enhances real-time information retrieval and text generation, in turn providing more accurate and context-specific assistance. An option to upload additional study materials in the web GUI is added in case additional knowledge support is required. The system's efficacy will be evaluated through controlled trials and iterative feedback mechanisms.",
    "pdf_link": "https://arxiv.org/abs/2405.00330",
    "graphs": [],
    "abstract_cn": "学无止境，成长不受年龄限制。但教育领域在满足学生的包容性和多样化学习需求方面可能面临挑战。学生们应能接触到最前沿的授课方式、网络资源和技术工具。然而，面对众多的学习资源，学生在短时间内掌握大量知识变得更加困难。传统的辅助技术和学习辅助工具往往缺少为个性化教育计划所需的灵活性。大型语言模型（LLM）已广泛应用于语言翻译、文本摘要和内容生成等场景。随着人工智能技术的迅速发展，AI驱动的聊天机器人和虚拟助手应运而生。本研究致力于通过推出一个名为“SAMCares”的创新学习伙伴来填补这一空白。该系统采用大型语言模型（LLM）——以LLaMa-2 70B为基础模型——结合检索增强生成（RAG）技术，提供实时、情境感知、适应性强的教育支持。系统的知识背景将限定在萨姆休斯顿州立大学（SHSU）的课程笔记中。LLM部分允许学生在一个类似聊天的环境中与其互动，以满足每个学生独特的学习需求。为此，我们将开发一个定制的基于Web的图形用户界面（GUI）。RAG技术则增强了实时信息检索和文本生成能力，从而提供更精确、更具针对性的帮助。此外，Web GUI还提供了上传额外学习材料的选项，以便在需要额外知识支持时使用。系统的有效性将通过对照试验和持续的反馈机制进行验证。",
    "title_cn": "融入人工智能于高等教育：开展“SAMCares：自适应学习平台”试点研究的方案",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "DFKI-NLP at SemEval-2024 Task 2: Towards Robust LLMs Using Data Perturbations and MinMax Training",
    "submit_datetime": "2024年05月01日",
    "abstract": "The NLI4CT task at SemEval-2024 emphasizes the development of robust models for Natural Language Inference on Clinical Trial Reports (CTRs) using large language models (LLMs). This edition introduces interventions specifically targeting the numerical, vocabulary, and semantic aspects of CTRs. Our proposed system harnesses the capabilities of the state-of-the-art Mistral model, complemented by an auxiliary model, to focus on the intricate input space of the NLI4CT dataset. Through the incorporation of numerical and acronym-based perturbations to the data, we train a robust system capable of handling both semantic-altering and numerical contradiction interventions. Our analysis on the dataset sheds light on the challenging sections of the CTRs for reasoning.",
    "pdf_link": "https://arxiv.org/abs/2405.00321",
    "graphs": [],
    "abstract_cn": "SemEval-2024 的 NLI4CT 任务着重于利用大型语言模型（LLMs）为临床试验报告（CTRs）上的自然语言推理（NLI）构建稳健的模型。本版特别关注 CTRs 的数值、词汇和语义特点，并引入了相应的干预措施。我们设计的系统采用了最先进的 Mistral 模型，并结合辅助模型，专注于 NLI4CT 数据集的复杂输入维度。通过在数据中引入数值和首字母缩略词的扰动，我们培养了一个能够应对语义变更和数值矛盾干预的强韧系统。对数据集的深入分析揭示了 CTRs 在推理过程中的难点所在。",
    "title_cn": "DFKI-NLP 团队参与了 SemEval-2024 的第二项任务，旨在通过数据扰动和 MinMax 训练方法，推动构建更加稳健的大型语言模型。",
    "tags": [
      "分类：LLM应用\n\n这篇论文摘要讨论了如何利用大型语言模型（LLMs）来构建一个稳健的模型，以处理临床试验报告（CTRs）上的自然语言推理（NLI）任务。这表明该论文主要关注LLM在特定领域的应用，即在临床试验报告的自然语言处理任务中。因此，这篇论文应该被归类为LLM应用。",
      "临床试验",
      ""
    ]
  },
  {
    "title": "Distance Sampling-based Paraphraser Leveraging ChatGPT for Text Data Manipulation",
    "submit_datetime": "2024年05月01日",
    "abstract": "There has been growing interest in audio-language retrieval research, where the objective is to establish the correlation between audio and text modalities. However, most audio-text paired datasets often lack rich expression of the text data compared to the audio samples. One of the significant challenges facing audio-text datasets is the presence of similar or identical captions despite different audio samples. Therefore, under many-to-one mapping conditions, audio-text datasets lead to poor performance of retrieval tasks. In this paper, we propose a novel approach to tackle the data imbalance problem in audio-language retrieval task. To overcome the limitation, we introduce a method that employs a distance sampling-based paraphraser leveraging ChatGPT, utilizing distance function to generate a controllable distribution of manipulated text data. For a set of sentences with the same context, the distance is used to calculate a degree of manipulation for any two sentences, and ChatGPT's few-shot prompting is performed using a text cluster with a similar distance defined by the Jaccard similarity. Therefore, ChatGPT, when applied to few-shot prompting with text clusters, can adjust the diversity of the manipulated text based on the distance. The proposed approach is shown to significantly enhance performance in audio-text retrieval, outperforming conventional text augmentation techniques.",
    "pdf_link": "https://arxiv.org/abs/2405.00367",
    "graphs": [],
    "abstract_cn": "音频-语言检索领域正受到越来越多的关注，旨在揭示音频与文本之间的联系。尽管如此，现有的音频-文本配对数据集往往在文本表达的丰富性上不及音频样本。一个特别的难题是，不同的音频样本可能伴有相似或完全相同的描述。这导致在多对一的映射情境下，检索任务的表现不尽人意。本文提出了一种创新的方法来应对音频-语言检索中的不平衡数据问题。我们引入了一种基于距离采样的释义技术，结合ChatGPT，通过距离函数来生成可控的文本数据分布。对于一组具有相同语境的句子，利用距离来衡量句子间的修改程度，并采用Jaccard相似性定义的相似距离的文本集进行ChatGPT的少量示例提示。这样，ChatGPT在进行少量示例提示时，能够根据距离来调节文本的多样性。实验结果表明，我们的方法显著提升了音频-文本检索的效果，超越了传统的文本增强方法。",
    "title_cn": "利用 ChatGPT 的距离抽样技术，打造文本数据的释义神器。",
    "tags": [
      "分类：LLM应用",
      "音频检索",
      ""
    ]
  },
  {
    "title": "Context-Aware Clustering using Large Language Models",
    "submit_datetime": "2024年05月01日",
    "abstract": "Despite the remarkable success of Large Language Models (LLMs) in text understanding and generation, their potential for text clustering tasks remains underexplored. We observed that powerful closed-source LLMs provide good quality clusterings of entity sets but are not scalable due to the massive compute power required and the associated costs. Thus, we propose CACTUS (Context-Aware ClusTering with aUgmented triplet losS), a systematic approach that leverages open-source LLMs for efficient and effective supervised clustering of entity subsets, particularly focusing on text-based entities. Existing text clustering methods fail to effectively capture the context provided by the entity subset. Moreover, though there are several language modeling based approaches for clustering, very few are designed for the task of supervised clustering. This paper introduces a novel approach towards clustering entity subsets using LLMs by capturing context via a scalable inter-entity attention mechanism. We propose a novel augmented triplet loss function tailored for supervised clustering, which addresses the inherent challenges of directly applying the triplet loss to this problem. Furthermore, we introduce a self-supervised clustering task based on text augmentation techniques to improve the generalization of our model. For evaluation, we collect ground truth clusterings from a closed-source LLM and transfer this knowledge to an open-source LLM under the supervised clustering framework, allowing a faster and cheaper open-source model to perform the same task. Experiments on various e-commerce query and product clustering datasets demonstrate that our proposed approach significantly outperforms existing unsupervised and supervised baselines under various external clustering evaluation metrics.",
    "pdf_link": "https://arxiv.org/abs/2405.00988",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）在文本理解和生成方面取得了显著成就，但其在文本聚类任务中的应用尚未充分挖掘。我们发现，尽管闭源LLMs能够为实体集合提供优秀的聚类效果，但由于计算资源的庞大需求和成本问题，它们的应用并不具备可扩展性。为此，我们提出了CACTUS——一种创新的系统化方法，它利用开源LLMs来高效执行实体子集的监督聚类，尤其针对基于文本的实体。传统的文本聚类技术往往忽略了实体子集所提供的上下文信息。此外，尽管存在一些基于语言模型的聚类方法，但专为监督聚类任务设计的方法却寥寥无几。本文提出了一种新颖的聚类方法，通过LLMs捕获上下文，并通过一种可扩展的实体间注意力机制实现。我们设计了一种新的增强型三重损失函数，专为监督聚类量身定制，以应对直接应用三重损失函数于此问题的固有难题。同时，我们引入了一种基于文本增强技术的自监督聚类任务，旨在提升模型的泛化性能。在评估过程中，我们从闭源LLM中获取了基准聚类数据，并将这些信息转移到开源LLM中，实现了在监督聚类框架下，使用更快速、成本更低的开源模型来执行相同任务。我们在多个电子商务查询和产品聚类数据集上进行的实验证明，我们的方法在多个外部聚类评估指标上显著超越了现有的无监督和监督基线方法。",
    "title_cn": "本文探讨了利用大型语言模型进行上下文感知聚类的方法。",
    "tags": [
      "LLM应用",
      "文本聚类",
      "电子商务"
    ]
  },
  {
    "title": "LLM-AD: Large Language Model based Audio Description System",
    "submit_datetime": "2024年05月01日",
    "abstract": "The development of Audio Description (AD) has been a pivotal step forward in making video content more accessible and inclusive. Traditionally, AD production has demanded a considerable amount of skilled labor, while existing automated approaches still necessitate extensive training to integrate multimodal inputs and tailor the output from a captioning style to an AD style. In this paper, we introduce an automated AD generation pipeline that harnesses the potent multimodal and instruction-following capacities of GPT-4V(ision). Notably, our methodology employs readily available components, eliminating the need for additional training. It produces ADs that not only comply with established natural language AD production standards but also maintain contextually consistent character information across frames, courtesy of a tracking-based character recognition module. A thorough analysis on the MAD dataset reveals that our approach achieves a performance on par with learning-based methods in automated AD production, as substantiated by a CIDEr score of 20.5.",
    "pdf_link": "https://arxiv.org/abs/2405.00983",
    "graphs": [],
    "abstract_cn": "音频描述（AD）的进步极大提升了视频内容的可访问性和包容性。传统AD制作依赖大量专业劳动力，而自动化方案则需大量训练以融合多模态信息，将字幕风格转化为AD风格。本文提出了一个自动化AD生成流程，该流程充分发挥了GPT-4V（视觉）在多模态处理和指令执行方面的强大功能。我们的方法使用了易于获取的组件，避免了额外训练的需要。它生成的AD不仅遵循了标准的自然语言AD制作规范，还通过追踪式角色识别模块，在不同帧之间保持了角色信息的上下文一致性。在MAD数据集上的深入分析显示，我们的方法在自动化AD生产中的表现与基于学习的方法相当，CIDEr得分达到20.5，证明了其效果。",
    "title_cn": "LLM-AD：一种依托于先进大型语言模型的音频描述解决方案",
    "tags": [
      "LLM应用",
      "视频内容制作",
      "自动化系统"
    ]
  },
  {
    "title": "On the Evaluation of Machine-Generated Reports",
    "submit_datetime": "2024年05月01日",
    "abstract": "Large Language Models (LLMs) have enabled new ways to satisfy information needs. Although great strides have been made in applying them to settings like document ranking and short-form text generation, they still struggle to compose complete, accurate, and verifiable long-form reports. Reports with these qualities are necessary to satisfy the complex, nuanced, or multi-faceted information needs of users. In this perspective paper, we draw together opinions from industry and academia, and from a variety of related research areas, to present our vision for automatic report generation, and -- critically -- a flexible framework by which such reports can be evaluated. In contrast with other summarization tasks, automatic report generation starts with a detailed description of an information need, stating the necessary background, requirements, and scope of the report. Further, the generated reports should be complete, accurate, and verifiable. These qualities, which are desirable -- if not required -- in many analytic report-writing settings, require rethinking how to build and evaluate systems that exhibit these qualities. To foster new efforts in building these systems, we present an evaluation framework that draws on ideas found in various evaluations. To test completeness and accuracy, the framework uses nuggets of information, expressed as questions and answers, that need to be part of any high-quality generated report. Additionally, evaluation of citations that map claims made in the report to their source documents ensures verifiability.",
    "pdf_link": "https://arxiv.org/abs/2405.00982",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）为满足信息需求开辟了新路径。尽管在文档排序和短文本生成等方面已取得显著进展，但它们在撰写全面、精确且可查证的长篇报告方面仍面临挑战。这类报告对于满足用户复杂、细致或多维度的信息需求至关重要。本文集思广益，汇聚了业界和学界的声音，以及多个相关研究领域的见解，旨在展现我们对自动化报告生成的展望，并提出了一个关键的灵活框架，用于评估此类报告。与常见的摘要任务相比，自动化报告生成始于对信息需求的详尽描述，阐明报告所需的背景、需求和范围。生成的报告不仅要全面、准确，还要可查证。这些特性在众多分析报告撰写场景中极为重要，甚至不可或缺，这要求我们重新思考构建和评估具备这些特性的系统的方法。为了激励构建这类系统的新尝试，我们提出了一个评估框架，该框架融合了多种评估理念。框架通过问题和答案形式的信息要点来测试报告的完整性和准确性，这些要点是任何优质生成报告不可或缺的部分。此外，通过评估报告中声明与来源文档相映射的引用，确保了报告的可查证性。",
    "title_cn": "机器生成报告评估研究",
    "tags": [
      "LLM应用",
      "信息检索",
      "自动化报告生成"
    ]
  },
  {
    "title": "Bayesian Optimization with LLM-Based Acquisition Functions for Natural Language Preference Elicitation",
    "submit_datetime": "2024年05月01日",
    "abstract": "Designing preference elicitation (PE) methodologies that can quickly ascertain a user's top item preferences in a cold-start setting is a key challenge for building effective and personalized conversational recommendation (ConvRec) systems. While large language models (LLMs) constitute a novel technology that enables fully natural language (NL) PE dialogues, we hypothesize that monolithic LLM NL-PE approaches lack the multi-turn, decision-theoretic reasoning required to effectively balance the NL exploration and exploitation of user preferences towards an arbitrary item set. In contrast, traditional Bayesian optimization PE methods define theoretically optimal PE strategies, but fail to use NL item descriptions or generate NL queries, unrealistically assuming users can express preferences with direct item ratings and comparisons. To overcome the limitations of both approaches, we formulate NL-PE in a Bayesian Optimization (BO) framework that seeks to generate NL queries which actively elicit natural language feedback to reduce uncertainty over item utilities to identify the best recommendation. We demonstrate our framework in a novel NL-PE algorithm, PEBOL, which uses Natural Language Inference (NLI) between user preference utterances and NL item descriptions to maintain preference beliefs and BO strategies such as Thompson Sampling (TS) and Upper Confidence Bound (UCB) to guide LLM query generation. We numerically evaluate our methods in controlled experiments, finding that PEBOL achieves up to 131% improvement in MAP@10 after 10 turns of cold start NL-PE dialogue compared to monolithic GPT-3.5, despite relying on a much smaller 400M parameter NLI model for preference inference.",
    "pdf_link": "https://arxiv.org/abs/2405.00981",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00981v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00981/beta_conversation_v8.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00981v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00981/llmpe_diagram_v7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00981v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00981/combined_dialogue_v13.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00981v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00981/noise0_map_plot_flat.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00981v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00981/noise0_map_plot_others_flat.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00981v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00981/mnli_temp0.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00981v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00981/history.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00981v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00981/noise_results_grouped.png"
      }
    ],
    "abstract_cn": "为了构建高效且个性化的对话式推荐系统，快速识别用户在冷启动情境下的首要偏好是一项重大挑战。大型语言模型（LLMs）开启了全自然语言（NL）偏好激发（PE）对话的新篇章，但我们推测，这种单一的LLM NL-PE方法在进行多轮决策理论推理时存在不足，难以有效平衡对用户偏好的探索与利用。而传统的贝叶斯优化PE方法虽然理论上最优，却未能利用自然语言描述或生成查询，且不切实际地假定用户能够直接通过评分和比较来表达偏好。为了克服这些方法的不足，我们提出了一个基于贝叶斯优化（BO）框架的NL-PE方法，旨在生成能够激发自然语言反馈的查询，以降低对项目效用不确定性的评估，从而精准推荐最佳选项。我们的新算法PEBOL，采用了自然语言推理（NLI）技术，以维持用户偏好信念，并结合Thompson Sampling（TS）和上置信界限（UCB）等BO策略，指导LLM生成查询。在受控实验中，我们的方法在10轮冷启动NL-PE对话后，相较于单一的GPT-3.5，MAP@10的性能提升了131%，尽管我们使用的是基于400M参数的小型NLI模型来进行偏好推断。",
    "title_cn": "利用基于大型语言模型的贝叶斯优化及获取函数，进行自然语言偏好的探索与激发。",
    "tags": [
      "LLM应用",
      "对话系统",
      "推荐系统"
    ]
  },
  {
    "title": "A Hong Kong Sign Language Corpus Collected from Sign-interpreted TV News",
    "submit_datetime": "2024年05月01日",
    "abstract": "This paper introduces TVB-HKSL-News, a new Hong Kong sign language (HKSL) dataset collected from a TV news program over a period of 7 months. The dataset is collected to enrich resources for HKSL and support research in large-vocabulary continuous sign language recognition (SLR) and translation (SLT). It consists of 16.07 hours of sign videos of two signers with a vocabulary of 6,515 glosses (for SLR) and 2,850 Chinese characters or 18K Chinese words (for SLT). One signer has 11.66 hours of sign videos and the other has 4.41 hours. One objective in building the dataset is to support the investigation of how well large-vocabulary continuous sign language recognition/translation can be done for a single signer given a (relatively) large amount of his/her training data, which could potentially lead to the development of new modeling methods. Besides, most parts of the data collection pipeline are automated with little human intervention; we believe that our collection method can be scaled up to collect more sign language data easily for SLT in the future for any sign languages if such sign-interpreted videos are available. We also run a SOTA SLR/SLT model on the dataset and get a baseline SLR word error rate of 34.08% and a baseline SLT BLEU-4 score of 23.58 for benchmarking future research on the dataset.",
    "pdf_link": "https://arxiv.org/abs/2405.00980",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00980v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00980/news.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00980v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00980/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00980v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00980/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00980v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00980/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00980v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00980/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00980v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00980/x5.png"
      }
    ],
    "abstract_cn": "本研究提出了 TVB-HKSL-News，这是一个全新的香港手语（HKSL）数据集，搜集自为期七个月的电视新闻节目。该数据集旨在扩充 HKSL 的资源库，并推动大词汇量连续手语识别（SLR）及翻译（SLT）研究的发展。数据集包含两位手语者共16.07小时的手语视频，涵盖了6,515个术语（用于 SLR）和2,850个中文字符或18K个中文词汇（用于 SLT）。其中一位手语者的视频时长为11.66小时，另一位为4.41小时。构建此数据集的目的之一是探究在拥有大量训练数据的情况下，单一手语者的大词汇量连续手语识别/翻译的效果如何，这可能促成新建模方法的诞生。此外，数据收集流程的大部分已实现自动化，减少了人为干预。我们认为，这种收集方法未来可以扩展，以便为任何手语的 SLT 轻松收集更多数据，只要有相应的手语翻译视频资源。我们还在此数据集上测试了业界领先的 SLR/SLT 模型，得出了 SLR 词汇错误率34.08%和 SLT BLEU-4 分数23.58的基线结果，为未来在此数据集上的研究方向提供了基准。",
    "title_cn": "香港手语语料库：源自电视手语新闻的采集",
    "tags": [
      "Agent",
      "手语识别",
      "机器翻译"
    ]
  },
  {
    "title": "CACTUS: Chemistry Agent Connecting Tool-Usage to Science",
    "submit_datetime": "2024年05月01日",
    "abstract": "Large language models (LLMs) have shown remarkable potential in various domains, but they often lack the ability to access and reason over domain-specific knowledge and tools. In this paper, we introduced CACTUS (Chemistry Agent Connecting Tool-Usage to Science), an LLM-based agent that integrates cheminformatics tools to enable advanced reasoning and problem-solving in chemistry and molecular discovery. We evaluate the performance of CACTUS using a diverse set of open-source LLMs, including Gemma-7b, Falcon-7b, MPT-7b, Llama2-7b, and Mistral-7b, on a benchmark of thousands of chemistry questions. Our results demonstrate that CACTUS significantly outperforms baseline LLMs, with the Gemma-7b and Mistral-7b models achieving the highest accuracy regardless of the prompting strategy used. Moreover, we explore the impact of domain-specific prompting and hardware configurations on model performance, highlighting the importance of prompt engineering and the potential for deploying smaller models on consumer-grade hardware without significant loss in accuracy. By combining the cognitive capabilities of open-source LLMs with domain-specific tools, CACTUS can assist researchers in tasks such as molecular property prediction, similarity searching, and drug-likeness assessment. Furthermore, CACTUS represents a significant milestone in the field of cheminformatics, offering an adaptable tool for researchers engaged in chemistry and molecular discovery. By integrating the strengths of open-source LLMs with domain-specific tools, CACTUS has the potential to accelerate scientific advancement and unlock new frontiers in the exploration of novel, effective, and safe therapeutic candidates, catalysts, and materials. Moreover, CACTUS's ability to integrate with automated experimentation platforms and make data-driven decisions in real time opens up new possibilities for autonomous discovery.",
    "pdf_link": "https://arxiv.org/abs/2405.00972",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）在众多领域展现出巨大潜力，但它们往往难以获取和推理特定领域的知识与工具。本文提出了 CACTUS（Chemistry Agent Connecting Tool-Usage to Science），这是一款集成了化学信息学工具的基于 LLM 的智能代理，旨在提升化学和分子探索领域的高级推理与问题解决能力。我们采用了包括 Gemma-7b、Falcon-7b、MPT-7b、Llama2-7b 和 Mistral-7b 在内的多种开源 LLMs，对数千个化学问题进行了基准测试，以评估 CACTUS 的性能。测试结果显示，CACTUS 在性能上显著超越了基础 LLMs，尤其是 Gemma-7b 和 Mistral-7b 模型，在不同提示策略下均达到了最高准确率。此外，我们还研究了领域特定提示和硬件配置对模型性能的影响，突显了提示工程的重要性以及在消费级硬件上部署小型模型的潜力，而不会显著损失准确性。CACTUS 结合了开源 LLMs 的认知能力与领域特定工具，能够助力研究人员在分子属性预测、相似性搜索和药物相似性评估等任务中取得进展。CACTUS 在化学信息学领域是一个重要的里程碑，为化学和分子发现领域的研究者提供了一个灵活的工具。它通过整合开源 LLMs 的优势与领域特定工具，有望推动科学发展，开拓新的研究领域，探索新的、有效的和安全的治疗方案、催化剂和材料。CACTUS 还能够与自动化实验平台整合，并实时做出基于数据的决策，为自动化发现开辟了新的可能性。",
    "title_cn": "CACTUS：化学智能代理与科学工具的连接平台",
    "tags": [
      "Agent",
      "",
      "人工智能"
    ]
  },
  {
    "title": "How Can I Get It Right? Using GPT to Rephrase Incorrect Trainee Responses",
    "submit_datetime": "2024年05月01日",
    "abstract": "One-on-one tutoring is widely acknowledged as an effective instructional method, conditioned on qualified tutors. However, the high demand for qualified tutors remains a challenge, often necessitating the training of novice tutors (i.e., trainees) to ensure effective tutoring. Research suggests that providing timely explanatory feedback can facilitate the training process for trainees. However, it presents challenges due to the time-consuming nature of assessing trainee performance by human experts. Inspired by the recent advancements of large language models (LLMs), our study employed the GPT-4 model to build an explanatory feedback system. This system identifies trainees' responses in binary form (i.e., correct/incorrect) and automatically provides template-based feedback with responses appropriately rephrased by the GPT-4 model. We conducted our study on 410 responses from trainees across three training lessons: Giving Effective Praise, Reacting to Errors, and Determining What Students Know. Our findings indicate that: 1) using a few-shot approach, the GPT-4 model effectively identifies correct/incorrect trainees' responses from three training lessons with an average F1 score of 0.84 and an AUC score of 0.85; and 2) using the few-shot approach, the GPT-4 model adeptly rephrases incorrect trainees' responses into desired responses, achieving performance comparable to that of human experts.",
    "pdf_link": "https://arxiv.org/abs/2405.00970",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00970v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00970/Scenario.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00970v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00970/feedback.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00970v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00970/praise.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00970v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00970/errors.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00970v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00970/knows.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00970v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00970/dimension_plot.png"
      }
    ],
    "abstract_cn": "一对一辅导因其高效而备受推崇，但合格导师的紧缺成了一大难题，这就需要培训新手导师以保障教学质量。研究指出，及时的解释性反馈有助于加速学员的成长，但专家评估的繁琐过程却是个不小的挑战。本研究借鉴了大型语言模型（LLMs）的最新进展，利用GPT-4模型开发了一个自动化的解释性反馈系统。该系统能够识别学员的二元回答（正确或错误），并自动提供基于模板的反馈，同时由GPT-4模型对回答进行恰当的改写。我们对三个培训环节——有效表扬、错误反应、了解学生知识——中的410个学员回答进行了分析。研究结果显示：1）采用少量样本方法，GPT-4模型在识别三个培训环节中学员回答的正确与否上表现出色，平均F1得分达到0.84，AUC得分为0.85；2）同样使用少量样本方法，GPT-4模型能够巧妙地将错误的学员回答改写为期望的回答，其表现与人类专家不相上下。",
    "title_cn": "如何正确表达？利用 GPT 对实习生的不准确回答进行改写。",
    "tags": [
      "LLM应用",
      "",
      "自动化反馈系统"
    ]
  },
  {
    "title": "Efficient Compression of Multitask Multilingual Speech Models",
    "submit_datetime": "2024年05月01日",
    "abstract": "Whisper is a multitask and multilingual speech model covering 99 languages. It yields commendable automatic speech recognition (ASR) results in a subset of its covered languages, but the model still underperforms on a non-negligible number of under-represented languages, a problem exacerbated in smaller model versions. In this work, we examine its limitations, demonstrating the presence of speaker-related (gender, age) and model-related (resourcefulness and model size) bias. Despite that, we show that only model-related bias are amplified by quantization, impacting more low-resource languages and smaller models. Searching for a better compression approach, we propose DistilWhisper, an approach that is able to bridge the performance gap in ASR for these languages while retaining the advantages of multitask and multilingual capabilities. Our approach involves two key strategies: lightweight modular ASR fine-tuning of whisper-small using language-specific experts, and knowledge distillation from whisper-large-v2. This dual approach allows us to effectively boost ASR performance while keeping the robustness inherited from the multitask and multilingual pre-training. Results demonstrate that our approach is more effective than standard fine-tuning or LoRA adapters, boosting performance in the targeted languages for both in- and out-of-domain test sets, while introducing only a negligible parameter overhead at inference.",
    "pdf_link": "https://arxiv.org/abs/2405.00966",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00966v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00966/x2.png"
      }
    ],
    "abstract_cn": "Whisper，一个涵盖99种语言的多任务多语言语音识别模型，在某些语言上展现了卓越的自动语音识别（ASR）成果。然而，它在一些少数语言上的表现仍有提升空间，尤其是在模型的小型化版本中。本研究深入探讨了其局限性，揭示了与说话者（如性别、年龄）和模型（如资源配置和尺寸）相关的偏见。尽管存在这些偏见，我们发现仅有模型相关的偏见会在量化过程中被放大，对资源匮乏的语言和小型模型影响更大。为了寻求更佳的压缩技术，我们提出了DistilWhisper方法，旨在提升这些语言的ASR性能，同时保持多任务多语言的优势。该方法包括两个核心策略：一是针对特定语言的专家对小型化的Whisper模型进行轻量级模块化微调；二是从大型Whisper模型中提取知识进行蒸馏。这种双管齐下的方法不仅有效提升了ASR性能，还保持了多任务多语言预训练的鲁棒性。实验结果证明，相较于传统的微调或LoRA适配器，我们的方法在目标语言的测试集上，无论是在领域内还是领域外，都显著提升了性能，同时在推理时几乎不增加参数负担。",
    "title_cn": "本文介绍了一种高效的多任务多语言语音模型压缩技术，旨在优化模型的存储和计算效率。",
    "tags": [
      "分类：LLM应用",
      "语音识别",
      "自动语音识别"
    ]
  },
  {
    "title": "The Role of Model Architecture and Scale in Predicting Molecular Properties: Insights from Fine-Tuning RoBERTa, BART, and LLaMA",
    "submit_datetime": "2024年05月01日",
    "abstract": "This study introduces a systematic framework to compare the efficacy of Large Language Models (LLMs) for fine-tuning across various cheminformatics tasks. Employing a uniform training methodology, we assessed three well-known models-RoBERTa, BART, and LLaMA-on their ability to predict molecular properties using the Simplified Molecular Input Line Entry System (SMILES) as a universal molecular representation format. Our comparative analysis involved pre-training 18 configurations of these models, with varying parameter sizes and dataset scales, followed by fine-tuning them on six benchmarking tasks from DeepChem. We maintained consistent training environments across models to ensure reliable comparisons. This approach allowed us to assess the influence of model type, size, and training dataset size on model performance. Specifically, we found that LLaMA-based models generally offered the lowest validation loss, suggesting their superior adaptability across tasks and scales. However, we observed that absolute validation loss is not a definitive indicator of model performance - contradicts previous research - at least for fine-tuning tasks: instead, model size plays a crucial role. Through rigorous replication and validation, involving multiple training and fine-tuning cycles, our study not only delineates the strengths and limitations of each model type but also provides a robust methodology for selecting the most suitable LLM for specific cheminformatics applications. This research underscores the importance of considering model architecture and dataset characteristics in deploying AI for molecular property prediction, paving the way for more informed and effective utilization of AI in drug discovery and related fields.",
    "pdf_link": "https://arxiv.org/abs/2405.00949",
    "graphs": [],
    "abstract_cn": "本研究建立了一套系统框架，旨在对比不同大型语言模型（LLM）在化学信息学任务微调中的效能。我们采用统一的训练策略，对RoBERTa、BART和LLaMA三款知名模型进行了评估，考察它们利用简化分子输入行条目系统（SMILES）这一通用分子表示格式来预测分子属性的能力。通过预训练这些模型的18种不同配置，并在DeepChem的六个基准任务上进行微调，我们进行了深入的比较分析。为确保比较的可靠性，我们在所有模型间保持了一致的训练环境。我们的研究揭示了模型类型、规模和训练数据集大小对性能的影响。特别是，基于LLaMA的模型在验证损失上普遍表现最佳，显示出其在不同任务和规模上的卓越适应性。然而，我们发现验证损失的绝对值并非模型性能的决定性指标，这与先前的研究相矛盾，至少在微调任务中，模型大小才是关键因素。通过严格的重复和验证，包括多轮训练和微调，本研究不仅清晰地展示了各模型的优势与局限，还为特定化学信息学应用选择最合适的LLM提供了一种稳固的方法论。本研究强调了在将AI应用于分子属性预测时，考虑模型架构和数据集特性的重要性，为AI在药物发现等相关领域的更明智和有效应用奠定了基础。",
    "title_cn": "探讨模型架构和规模对于分子属性预测的影响：通过对 RoBERTa、BART 和 LLaMA 进行微调获得的深刻见解。",
    "tags": [
      "LLM应用",
      "化学信息学",
      "药物发现"
    ]
  },
  {
    "title": "LLaVA Finds Free Lunch: Teaching Human Behavior Improves Content Understanding Abilities Of LLMs",
    "submit_datetime": "2024年05月01日",
    "abstract": "Communication is defined as ``Who says what to whom with what effect.'' A message from a communicator generates downstream receiver effects, also known as behavior. Receiver behavior, being a downstream effect of the message, carries rich signals about it. Even after carrying signals about the message, the behavior data is often ignored while training large language models. We show that training LLMs on receiver behavior can actually help improve their content-understanding abilities. Specifically, we show that training LLMs to predict the receiver behavior of likes and comments improves the LLM's performance on a wide variety of downstream content understanding tasks. We show this performance increase over 40 video and image understanding tasks over 23 benchmark datasets across both 0-shot and fine-tuning settings, outperforming many supervised baselines. Moreover, since receiver behavior, such as likes and comments, is collected by default on the internet and does not need any human annotations to be useful, the performance improvement we get after training on this data is essentially free-lunch. We release the receiver behavior cleaned comments and likes of 750k images and videos collected from multiple platforms along with our instruction-tuning data.",
    "pdf_link": "https://arxiv.org/abs/2405.00942",
    "graphs": [],
    "abstract_cn": "通信即是“谁向谁传达了什么信息，产生了何种影响”。信息发送者的消息会在接收者端引发连锁反应，即行为。这些行为作为信息传递的结果，蕴含了丰富的信号。尽管如此，行为数据在大型语言模型的训练过程中常被忽视。本研究揭示，基于接收者行为对大型语言模型进行训练可以有效提升其对内容的理解力。具体而言，我们发现通过训练模型预测点赞和评论等接收者行为，能够显著提高其在多种下游内容理解任务上的表现。这一提升在23个基准数据集上的40个视频和图像理解任务中得到了验证，无论是零样本还是微调场景，均超越了众多监督学习基线。更重要的是，点赞和评论等接收者行为在互联网上自动收集，无需人工标注即可发挥作用，因此，利用这些数据进行训练所带来的性能提升可谓是意外的收获。我们还公开了从多个平台收集的750k图像和视频的接收者行为数据，包括清理后的评论和点赞，以及我们的指令调整数据集。",
    "title_cn": "LLaVA 揭示了一个意外的收获：通过教授人类行为，我们能够显著提升大型语言模型对内容的理解力。",
    "tags": [
      "LLM应用",
      "",
      "机器学习"
    ]
  },
  {
    "title": "Characterising the Creative Process in Humans and Large Language Models",
    "submit_datetime": "2024年05月01日",
    "abstract": "Large language models appear quite creative, often performing on par with the average human on creative tasks. However, research on LLM creativity has focused solely on \\textit{products}, with little attention on the creative \\textit{process}. Process analyses of human creativity often require hand-coded categories or exploit response times, which do not apply to LLMs. We provide an automated method to characterise how humans and LLMs explore semantic spaces on the Alternate Uses Task, and contrast with behaviour in a Verbal Fluency Task. We use sentence embeddings to identify response categories and compute semantic similarities, which we use to generate jump profiles. Our results corroborate earlier work in humans reporting both persistent (deep search in few semantic spaces) and flexible (broad search across multiple semantic spaces) pathways to creativity, where both pathways lead to similar creativity scores. LLMs were found to be biased towards either persistent or flexible paths, that varied across tasks. Though LLMs as a population match human profiles, their relationship with creativity is different, where the more flexible models score higher on creativity. Our dataset and scripts are available on \\href{https://github.com/surabhisnath/Creative_Process}{GitHub}.",
    "pdf_link": "https://arxiv.org/abs/2405.00899",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLM）在创意任务上的表现可与人类媲美，展现出相当的创造力。但目前对LLM创造力的研究主要集中在成果上，对于创造过程的探究却鲜有涉足。传统的人类创造力过程分析依赖于手工分类或反应时间，这些方法对于LLM并不适用。本研究提出了一种自动化方法，用以分析人类和LLM在“替代用途任务”中如何探索语义空间，并将其与“言语流畅性任务”中的行为相比较。通过句子嵌入技术，我们识别了响应类别并计算了语义相似度，进而生成了跳跃轮廓图。研究结果支持了此前对人类创造力路径的发现，即存在深度探索少数语义空间的持久性路径和广泛搜索多个语义空间的灵活性路径，两者都能带来相似的创造力得分。LLM在不同任务中表现出对持久性或灵活性路径的偏好，且与人类的创造力轮廓相比，LLM表现出不同的创造力关联性，其中灵活性更高的模型在创造力评分上更为突出。我们的数据库和脚本已在GitHub上公开。GitHub链接：[Creative_Process](https://github.com/surabhisnath/Creative_Process)",
    "title_cn": "探索人类与大型语言模型的创意生成过程",
    "tags": [
      "LLM应用",
      "创意设计",
      "人工智能"
    ]
  },
  {
    "title": "Beyond Human Vision: The Role of Large Vision Language Models in Microscope Image Analysis",
    "submit_datetime": "2024年05月01日",
    "abstract": "Vision language models (VLMs) have recently emerged and gained the spotlight for their ability to comprehend the dual modality of image and textual data. VLMs such as LLaVA, ChatGPT-4, and Gemini have recently shown impressive performance on tasks such as natural image captioning, visual question answering (VQA), and spatial reasoning. Additionally, a universal segmentation model by Meta AI, Segment Anything Model (SAM) shows unprecedented performance at isolating objects from unforeseen images. Since medical experts, biologists, and materials scientists routinely examine microscopy or medical images in conjunction with textual information in the form of captions, literature, or reports, and draw conclusions of great importance and merit, it is indubitably essential to test the performance of VLMs and foundation models such as SAM, on these images. In this study, we charge ChatGPT, LLaVA, Gemini, and SAM with classification, segmentation, counting, and VQA tasks on a variety of microscopy images. We observe that ChatGPT and Gemini are impressively able to comprehend the visual features in microscopy images, while SAM is quite capable at isolating artefacts in a general sense. However, the performance is not close to that of a domain expert - the models are readily encumbered by the introduction of impurities, defects, artefact overlaps and diversity present in the images.",
    "pdf_link": "https://arxiv.org/abs/2405.00876",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00876v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00876/Figure_illustration.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00876v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00876/Figure_datasets.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00876v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00876/Figure_chatgpt_scale_bar.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00876v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00876/Figure_classification.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00876v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00876/Figure_dice_scores.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00876v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00876/Figure_diff_images.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00876v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00876/Figure_segmentation_qualitative.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00876v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00876/Figure_counts_sampled.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00876v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00876/Figure_counts_full.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00876v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00876/Figure_vqa_1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00876v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00876/Figure_vqa_2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00876v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00876/Figure_vqa_3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00876v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00876/Figure_vqa_4.png"
      }
    ],
    "abstract_cn": "视觉语言模型（VLMs）因其在图像和文本数据理解上的双重能力而成为新宠。VLMs 如 LLaVA、ChatGPT-4 和 Gemini 在自然图像描述、视觉问答（VQA）和空间推理任务上的表现令人瞩目。Meta AI 推出的通用分割模型 Segment Anything Model（SAM）在从未知图像中分离物体方面更是表现卓越。鉴于医学、生物和材料科学领域的专家经常需要结合文本信息来分析显微镜或医学图像，以得出关键结论，因此，对 VLMs 及基础模型如 SAM 在这些图像上的性能进行测试显得尤为重要。本研究中，我们让 ChatGPT、LLaVA、Gemini 和 SAM 在多种显微镜图像上执行分类、分割、计数和 VQA 任务。结果显示，ChatGPT 和 Gemini 在理解显微镜图像的视觉特征方面表现出色，而 SAM 在一般性地分离图像中的物体方面也颇具能力。但这些模型的表现仍未达到领域专家的水平，它们在面对图像中的杂质、缺陷、重叠和多样性时容易受到影响。",
    "title_cn": "超越人眼所见：大型视觉语言模型在显微图像分析领域的应用",
    "tags": [
      "分类：LLM应用\n\n这篇论文探讨了视觉语言模型（VLMs）和通用分割模型在医学、生物和材料科学领域的显微镜图像分析上的应用。它测试了多个模型在显微镜图像上执行分类、分割、计数和视觉问答（VQA）任务的性能，并比较了它们的表现。这篇论文主要关注这些模型在特定应用场景下的表现，因此归类为LLM应用。",
      "",
      "生物科学"
    ]
  },
  {
    "title": "Math Multiple Choice Question Generation via Human-Large Language Model Collaboration",
    "submit_datetime": "2024年05月01日",
    "abstract": "Multiple choice questions (MCQs) are a popular method for evaluating students' knowledge due to their efficiency in administration and grading. Crafting high-quality math MCQs is a labor-intensive process that requires educators to formulate precise stems and plausible distractors. Recent advances in large language models (LLMs) have sparked interest in automating MCQ creation, but challenges persist in ensuring mathematical accuracy and addressing student errors. This paper introduces a prototype tool designed to facilitate collaboration between LLMs and educators for streamlining the math MCQ generation process. We conduct a pilot study involving math educators to investigate how the tool can help them simplify the process of crafting high-quality math MCQs. We found that while LLMs can generate well-formulated question stems, their ability to generate distractors that capture common student errors and misconceptions is limited. Nevertheless, a human-AI collaboration has the potential to enhance the efficiency and effectiveness of MCQ generation.",
    "pdf_link": "https://arxiv.org/abs/2405.00864",
    "graphs": [],
    "abstract_cn": "多项选择题因其高效管理和评分而广受青睐，成为评估学生知识的有效方式。然而，设计精良的数学多项选择题是一项耗时的工作，它要求教师精心构思题干和干扰项。随着大型语言模型（LLMs）的快速发展，自动化生成MCQs的探索引起了广泛关注，但如何确保数学问题的正确性和针对学生错误的有效性仍是一大挑战。本文提出了一个原型工具，用以协助LLMs与教育者协作，共同优化数学多项选择题的生成流程。通过与数学教育者合作的试点研究，我们探究了该工具如何简化制作高质量数学MCQs的过程。研究发现，尽管LLMs能够生成结构合理的题干，但在生成能够反映学生常见错误和误解的干扰项方面还有所不足。尽管如此，人机合作在提高MCQ生成的效率和质量方面展现出巨大潜力。",
    "title_cn": "携手人类与大型语言模型，共创数学多项选择题",
    "tags": [
      "LLM应用",
      "",
      "自动化生成"
    ]
  },
  {
    "title": "Can a Hallucinating Model help in Reducing Human \"Hallucination\"?",
    "submit_datetime": "2024年05月01日",
    "abstract": "The prevalence of unwarranted beliefs, spanning pseudoscience, logical fallacies, and conspiracy theories, presents substantial societal hurdles and the risk of disseminating misinformation. Utilizing established psychometric assessments, this study explores the capabilities of large language models (LLMs) vis-a-vis the average human in detecting prevalent logical pitfalls. We undertake a philosophical inquiry, juxtaposing the rationality of humans against that of LLMs. Furthermore, we propose methodologies for harnessing LLMs to counter misconceptions, drawing upon psychological models of persuasion such as cognitive dissonance theory and elaboration likelihood theory. Through this endeavor, we highlight the potential of LLMs as personalized misinformation debunking agents.",
    "pdf_link": "https://arxiv.org/abs/2405.00843",
    "graphs": [],
    "abstract_cn": "广泛存在的无根据信念，包括伪科学、逻辑谬误和阴谋论，对社会发展构成了重大障碍，并可能导致错误信息的传播。本研究通过心理测量学评估，比较了大型语言模型（LLMs）与普通人在识别常见逻辑陷阱方面的能力。我们进行了深入的哲学探讨，对比了人类与LLMs的理性思维。同时，我们提出了一系列方法，旨在利用LLMs来纠正错误观念，这些方法借鉴了认知失调理论和详述可能性模型等心理学说服理论。通过这项研究，我们展示了LLMs在个性化辟谣方面的潜力。",
    "title_cn": "幻觉模型能否助力减轻人类的幻觉现象？",
    "tags": [
      "LLM应用",
      "心理学",
      "信息传播"
    ]
  },
  {
    "title": "WIBA: What Is Being Argued? A Comprehensive Approach to Argument Mining",
    "submit_datetime": "2024年05月01日",
    "abstract": "We propose WIBA, a novel framework and suite of methods that enable the comprehensive understanding of \"What Is Being Argued\" across contexts. Our approach develops a comprehensive framework that detects: (a) the existence, (b) the topic, and (c) the stance of an argument, correctly accounting for the logical dependence among the three tasks. Our algorithm leverages the fine-tuning and prompt-engineering of Large Language Models. We evaluate our approach and show that it performs well in all the three capabilities. First, we develop and release an Argument Detection model that can classify a piece of text as an argument with an F1 score between 79% and 86% on three different benchmark datasets. Second, we release a language model that can identify the topic being argued in a sentence, be it implicit or explicit, with an average similarity score of 71%, outperforming current naive methods by nearly 40%. Finally, we develop a method for Argument Stance Classification, and evaluate the capability of our approach, showing it achieves a classification F1 score between 71% and 78% across three diverse benchmark datasets. Our evaluation demonstrates that WIBA allows the comprehensive understanding of What Is Being Argued in large corpora across diverse contexts, which is of core interest to many applications in linguistics, communication, and social and computer science. To facilitate accessibility to the advancements outlined in this work, we release WIBA as a free open access platform (wiba.dev).",
    "pdf_link": "https://arxiv.org/abs/2405.00828",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00828v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00828/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00828v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00828/wiba_for_latex_v5_with_border.png"
      }
    ],
    "abstract_cn": "我们引入了WIBA，一个创新的框架及其方法集，旨在深入洞察不同情境下的“争论核心”。该框架能够精准识别争论的存在、主题和立场，同时巧妙处理三者间的逻辑联系。通过深度优化和精心设计的大型语言模型，我们的算法在三大关键性能上均展现出色表现。首先，我们构建并推出了一个争论检测模型，能够在三个不同的基准数据集上，以79%至86%的F1分数准确分类文本段落。其次，我们推出了一个能够识别句子中争论主题的语言模型，无论是隐含还是明确，平均相似度达到71%，性能提升近40%。最后，我们开发了一种争论立场分类方法，并在三个多样化的基准数据集上，实现了71%至78%的分类F1分数。这一评估证实了WIBA在广泛语料库和多样情境中全面解析争论内容的能力，这对于语言学、通信学、社会科学以及计算机科学等领域的应用具有重要意义。为了促进对本研究进展的广泛接触，我们免费开放了WIBA平台（wiba.dev）。",
    "title_cn": "WIBA：争论的是什么？一种全面深入的论点挖掘方法。",
    "tags": [
      "LLM应用",
      "语言学",
      "通信学"
    ]
  },
  {
    "title": "Efficient and Responsible Adaptation of Large Language Models for Robust Top-k Recommendations",
    "submit_datetime": "2024年05月01日",
    "abstract": "Conventional recommendation systems (RSs) are typically optimized to enhance performance metrics uniformly across all training samples.\n  This makes it hard for data-driven RSs to cater to a diverse set of users due to the varying properties of these users. The performance disparity among various populations can harm the model's robustness with respect to sub-populations. While recent works have shown promising results in adapting large language models (LLMs) for recommendation to address hard samples, long user queries from millions of users can degrade the performance of LLMs and elevate costs, processing times and inference latency. This challenges the practical applicability of LLMs for recommendations. To address this, we propose a hybrid task allocation framework that utilizes the capabilities of both LLMs and traditional RSs. By adopting a two-phase approach to improve robustness to sub-populations, we promote a strategic assignment of tasks for efficient and responsible adaptation of LLMs. Our strategy works by first identifying the weak and inactive users that receive a suboptimal ranking performance by RSs. Next, we use an in-context learning approach for such users, wherein each user interaction history is contextualized as a distinct ranking task and given to an LLM. We test our hybrid framework by incorporating various recommendation algorithms -- collaborative filtering and learning-to-rank recommendation models -- and two LLMs -- both open and close-sourced. Our results on three real-world datasets show a significant reduction in weak users and improved robustness of RSs to sub-populations $(\\approx12\\%)$ and overall performance without disproportionately escalating costs.",
    "pdf_link": "https://arxiv.org/abs/2405.00824",
    "graphs": [],
    "abstract_cn": "传统推荐系统往往追求全面提升训练样本的性能指标，却难以满足用户多样性的需求。这种性能差异可能削弱模型对特定用户群体的鲁棒性。尽管最新研究通过大型语言模型（LLMs）在推荐领域的应用取得了进展，但面对数百万用户的长查询，LLMs的性能和成本效益、处理速度及推理延迟仍面临挑战。为此，我们提出了一个混合任务分配框架，整合了LLMs和传统推荐系统的优势。该框架采用双阶段策略，旨在增强对不同用户群体的适应性，通过智能分配任务，实现LLMs的高效和负责任的应用。我们首先识别出那些在推荐系统中排名表现不佳的弱势和非活跃用户，然后采用上下文学习方法，将每位用户的交互历史作为独立的排名任务，交由LLM处理。我们通过整合多种推荐算法和两款LLMs（开源和闭源）来测试这一框架，并在三个现实世界的数据集上取得了显著成效：弱势用户数量显著减少，推荐系统对子群体的鲁棒性提升了约12%，整体性能得到增强，而成本却没有不合理地增加。",
    "title_cn": "为了提供鲁棒的 Top-k 推荐，我们需对大型语言模型进行既高效又负责任的调整。",
    "tags": [
      "分类：LLM应用\n\n这篇论文讨论了如何将大型语言模型（LLMs）应用于推荐系统，以提高对特定用户群体的适应性和鲁棒性。它提出了一个混合任务分配框架，结合了LLMs和传统推荐系统的优势，通过智能分配任务，实现LLMs的高效和负责任的应用。这篇论文关注的是LLMs在实际应用中的性能和成本效益，以及如何通过上下文学习和任务分配来提高推荐系统的鲁棒性。因此，它应该被归类为LLM应用。",
      "推荐系统",
      "用户行为分析"
    ]
  },
  {
    "title": "\"Ask Me Anything\": How Comcast Uses LLMs to Assist Agents in Real Time",
    "submit_datetime": "2024年05月01日",
    "abstract": "Customer service is how companies interface with their customers. It can contribute heavily towards the overall customer satisfaction. However, high-quality service can become expensive, creating an incentive to make it as cost efficient as possible and prompting most companies to utilize AI-powered assistants, or \"chat bots\". On the other hand, human-to-human interaction is still desired by customers, especially when it comes to complex scenarios such as disputes and sensitive topics like bill payment.\n  This raises the bar for customer service agents. They need to accurately understand the customer's question or concern, identify a solution that is acceptable yet feasible (and within the company's policy), all while handling multiple conversations at once.\n  In this work, we introduce \"Ask Me Anything\" (AMA) as an add-on feature to an agent-facing customer service interface. AMA allows agents to ask questions to a large language model (LLM) on demand, as they are handling customer conversations -- the LLM provides accurate responses in real-time, reducing the amount of context switching the agent needs. In our internal experiments, we find that agents using AMA versus a traditional search experience spend approximately 10% fewer seconds per conversation containing a search, translating to millions of dollars of savings annually. Agents that used the AMA feature provided positive feedback nearly 80% of the time, demonstrating its usefulness as an AI-assisted feature for customer care.",
    "pdf_link": "https://arxiv.org/abs/2405.00801",
    "graphs": [],
    "abstract_cn": "客户服务是企业与客户沟通的桥梁，对提升客户满意度起着关键作用。然而，优质客户服务的成本不菲，这促使企业寻求成本效益最大化的解决方案，如采用AI驱动的“聊天机器人”。尽管如此，客户在面对复杂问题或敏感话题时，仍倾向于寻求人与人之间的直接交流。这对客服代表提出了更高要求：他们必须精准把握客户的问题或疑虑，找到既符合客户期望又在公司政策允许范围内的解决方案，同时还要应对多线对话的挑战。本研究提出了“问我任何问题”（AMA）功能，作为客服代表界面的一个新增模块。该功能允许客服代表在与客户交流时，即时向大型语言模型（LLM）提出问题，获取实时准确的回答，从而减少代表在处理对话时的上下文切换。内部实验显示，使用AMA的代表在包含搜索的对话中，平均用时减少了约10%，这为公司每年节省了数百万美元。此外，使用AMA功能的代表中，有近80%给出了正面反馈，显示出这一AI辅助工具在客户服务中的显著价值。",
    "title_cn": "\"有问必答\"：探究 Comcast 如何利用大型语言模型 (LLMs) 为代理提供实时协助。",
    "tags": [
      "LLM应用",
      "客户服务",
      "人工智能"
    ]
  },
  {
    "title": "Visual Fact Checker: Enabling High-Fidelity Detailed Caption Generation",
    "submit_datetime": "2024年04月30日",
    "abstract": "Existing automatic captioning methods for visual content face challenges such as lack of detail, content hallucination, and poor instruction following. In this work, we propose VisualFactChecker (VFC), a flexible training-free pipeline that generates high-fidelity and detailed captions for both 2D images and 3D objects. VFC consists of three steps: 1) proposal, where image-to-text captioning models propose multiple initial captions; 2) verification, where a large language model (LLM) utilizes tools such as object detection and VQA models to fact-check proposed captions; 3) captioning, where an LLM generates the final caption by summarizing caption proposals and the fact check verification results. In this step, VFC can flexibly generate captions in various styles following complex instructions. We conduct comprehensive captioning evaluations using four metrics: 1) CLIP-Score for image-text similarity; 2) CLIP-Image-Score for measuring the image-image similarity between the original and the reconstructed image generated by a text-to-image model using the caption. 3) human study on Amazon Mechanical Turk; 4) GPT-4V for fine-grained evaluation. Evaluation results show that VFC outperforms state-of-the-art open-sourced captioning methods for 2D images on the COCO dataset and 3D assets on the Objaverse dataset. Our study demonstrates that by combining open-source models into a pipeline, we can attain captioning capability comparable to proprietary models such as GPT-4V, despite being over 10x smaller in model size.",
    "pdf_link": "https://arxiv.org/abs/2404.19752",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.19752v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19752/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19752v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19752/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19752v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19752/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19752v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19752/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19752v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19752/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19752v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19752/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19752v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19752/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19752v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19752/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19752v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19752/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19752v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19752/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19752v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19752/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19752v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19752/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19752v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19752/x14.png"
      }
    ],
    "abstract_cn": "现有自动生成视觉内容字幕的方法存在诸多挑战，如细节不足、内容失真和执行指令不力。本研究提出了一种名为 VisualFactChecker (VFC) 的新型工具，它无需额外训练即可为二维图像和三维物体生成高清晰度、详尽的字幕。VFC 的工作流程分为三步：首先，图像到文本的字幕模型提出多个初步字幕；其次，大型语言模型 (LLM) 借助对象检测和视觉问答 (VQA) 模型等工具对这些字幕进行事实核查；最后，LLM 综合初步字幕和事实核查结果，生成最终字幕。这一过程中，VFC 能够灵活地遵循复杂指令，生成多种风格的字幕。我们通过四个指标对字幕生成进行了全面评估：CLIP-Score 衡量图像与文本的相似度；CLIP-Image-Score 衡量原始图像与基于文本生成的图像之间的相似度；亚马逊机械土耳其的人机研究；以及 GPT-4V 的细粒度评估。评估结果显示，VFC 在 COCO 数据集的二维图像和 Objaverse 数据集的三维物体字幕生成上，均优于现有的顶尖开源方法。本研究证明，通过整合开源模型，即使模型规模小了十倍，也能实现与 GPT-4V 等专有模型相媲美的字幕生成能力。",
    "title_cn": "视觉事实核查器：助力生成高清晰度的详细字幕",
    "tags": [
      "LLM应用",
      "视觉内容生成",
      "自动字幕生成"
    ]
  },
  {
    "title": "PrivComp-KG : Leveraging Knowledge Graph and Large Language Models for Privacy Policy Compliance Verification",
    "submit_datetime": "2024年04月30日",
    "abstract": "Data protection and privacy is becoming increasingly crucial in the digital era. Numerous companies depend on third-party vendors and service providers to carry out critical functions within their operations, encompassing tasks such as data handling and storage. However, this reliance introduces potential vulnerabilities, as these vendors' security measures and practices may not always align with the standards expected by regulatory bodies. Businesses are required, often under the penalty of law, to ensure compliance with the evolving regulatory rules. Interpreting and implementing these regulations pose challenges due to their complexity. Regulatory documents are extensive, demanding significant effort for interpretation, while vendor-drafted privacy policies often lack the detail required for full legal compliance, leading to ambiguity. To ensure a concise interpretation of the regulatory requirements and compliance of organizational privacy policy with said regulations, we propose a Large Language Model (LLM) and Semantic Web based approach for privacy compliance. In this paper, we develop the novel Privacy Policy Compliance Verification Knowledge Graph, PrivComp-KG. It is designed to efficiently store and retrieve comprehensive information concerning privacy policies, regulatory frameworks, and domain-specific knowledge pertaining to the legal landscape of privacy. Using Retrieval Augmented Generation, we identify the relevant sections in a privacy policy with corresponding regulatory rules. This information about individual privacy policies is populated into the PrivComp-KG. Combining this with the domain context and rules, the PrivComp-KG can be queried to check for compliance with privacy policies by each vendor against relevant policy regulations. We demonstrate the relevance of the PrivComp-KG, by verifying compliance of privacy policy documents for various organizations.",
    "pdf_link": "https://arxiv.org/abs/2404.19744",
    "graphs": [],
    "abstract_cn": "在数字化浪潮中，数据安全与隐私保护的重要性日益凸显。众多企业将数据处理、存储等关键业务流程外包给第三方，这无疑带来了安全隐患，因为这些外部服务提供商的安全标准可能与法规要求不同步。法律往往要求企业必须遵守不断更新的监管规则，违反者可能面临法律制裁。这些复杂的法规文件需要大量精力去解读，而供应商提供的隐私政策往往细节不足，难以满足完全合规的要求，造成了许多不确定性。为了简化监管要求的解读并确保企业隐私政策与法规相符，本文提出了一种结合大型语言模型（LLM）和语义网的隐私合规解决方案。我们构建了一个创新的隐私政策合规性验证知识图谱PrivComp-KG，用以高效地存储和检索隐私政策、监管框架和法律领域相关知识。利用检索增强生成技术，我们能够在隐私政策文件中定位与监管规则相匹配的关键部分，并将这些信息整合到PrivComp-KG中。结合领域背景和规则，PrivComp-KG能够被用来查询并验证供应商的隐私政策是否遵守了相关规定。我们通过验证多家组织的隐私政策文件，证明了PrivComp-KG的有效性和实用性。",
    "title_cn": "PrivComp-KG：结合知识图谱与大型语言模型，致力于隐私政策的合规性检查",
    "tags": [
      "LLM应用",
      "数据安全与隐私保护",
      "知识图谱"
    ]
  },
  {
    "title": "Better & Faster Large Language Models via Multi-token Prediction",
    "submit_datetime": "2024年04月30日",
    "abstract": "Large language models such as GPT and Llama are trained with a next-token prediction loss. In this work, we suggest that training language models to predict multiple future tokens at once results in higher sample efficiency. More specifically, at each position in the training corpus, we ask the model to predict the following n tokens using n independent output heads, operating on top of a shared model trunk. Considering multi-token prediction as an auxiliary training task, we measure improved downstream capabilities with no overhead in training time for both code and natural language models. The method is increasingly useful for larger model sizes, and keeps its appeal when training for multiple epochs. Gains are especially pronounced on generative benchmarks like coding, where our models consistently outperform strong baselines by several percentage points. Our 13B parameter models solves 12 % more problems on HumanEval and 17 % more on MBPP than comparable next-token models. Experiments on small algorithmic tasks demonstrate that multi-token prediction is favorable for the development of induction heads and algorithmic reasoning capabilities. As an additional benefit, models trained with 4-token prediction are up to 3 times faster at inference, even with large batch sizes.",
    "pdf_link": "https://arxiv.org/abs/2404.19737",
    "graphs": [],
    "abstract_cn": "诸如 GPT 和 Llama 这样的大型语言模型通常通过预测下一个词元来进行训练。本研究提出，让模型同时预测多个后续词元可以提升样本效率。具体来说，训练时，模型需在语料库的每个点预测接下来的 n 个词元，通过 n 个独立的输出头实现，这些输出头共同作用于一个共享的模型主体。将这种多词元预测作为辅助训练手段，我们在不增加训练时长的前提下，对代码和自然语言模型的下游性能进行了提升。这种方法对于大型模型尤为有效，且在多轮训练中同样适用。特别是在编程等生成任务中，我们的模型在性能上显著超越了传统基线模型。以 13B 参数模型为例，其在 HumanEval 和 MBPP 测试中解决问题的能力分别提升了 12% 和 17%。此外，多词元预测还有助于提升模型的归纳和算法推理能力。另一个优势是，经过 4 词元预测训练的模型在推理时速度更快，速度提升高达 3 倍，即便在处理大规模数据批次时也是如此。",
    "title_cn": "通过多令牌预测技术，我们能够打造性能更优、响应更迅速的大型语言模型。",
    "tags": [
      "LLM理论",
      "",
      ""
    ]
  },
  {
    "title": "A Framework for Leveraging Human Computation Gaming to Enhance Knowledge Graphs for Accuracy Critical Generative AI Applications",
    "submit_datetime": "2024年04月30日",
    "abstract": "External knowledge graphs (KGs) can be used to augment large language models (LLMs), while simultaneously providing an explainable knowledge base of facts that can be inspected by a human. This approach may be particularly valuable in domains where explainability is critical, like human trafficking data analysis. However, creating KGs can pose challenges. KGs parsed from documents may comprise explicit connections (those directly stated by a document) but miss implicit connections (those obvious to a human although not directly stated). To address these challenges, this preliminary research introduces the GAME-KG framework, standing for \"Gaming for Augmenting Metadata and Enhancing Knowledge Graphs.\" GAME-KG is a federated approach to modifying explicit as well as implicit connections in KGs by using crowdsourced feedback collected through video games. GAME-KG is shown through two demonstrations: a Unity test scenario from Dark Shadows, a video game that collects feedback on KGs parsed from US Department of Justice (DOJ) Press Releases on human trafficking, and a following experiment where OpenAI's GPT-4 is prompted to answer questions based on a modified and unmodified KG. Initial results suggest that GAME-KG can be an effective framework for enhancing KGs, while simultaneously providing an explainable set of structured facts verified by humans.",
    "pdf_link": "https://arxiv.org/abs/2404.19729",
    "graphs": [],
    "abstract_cn": "外部知识图谱能增强大型语言模型，并为人类提供了一个可审查的、基于事实的知识库，这在需要高度可解释性的领域如人口贩卖数据分析中尤为重要。但构建知识图谱并非易事，因为从文档中提取的知识图谱可能仅包含直接陈述的显式联系，而忽略了那些对人类显而易见但未明确表述的隐式联系。为应对这些挑战，本研究提出了GAME-KG框架，即“通过游戏化增强元数据和提升知识图谱”。该框架利用视频游戏中收集的众包反馈，以联合方式调整知识图谱中的显式和隐式联系。通过两个案例展示了GAME-KG的有效性：一是Dark Shadows视频游戏，它收集了关于美国司法部发布的人口贩卖新闻稿中知识图谱的反馈；二是OpenAI的GPT-4模型在基于修改和未修改的知识图谱上回答问题的实验。初步结果显示，GAME-KG不仅能有效提升知识图谱的质量，还能提供一套经过人工验证的、结构化的可解释事实集。",
    "title_cn": "构建了一个框架，旨在通过人类计算游戏来丰富知识图谱，以提升关键生成性AI应用的准确性。",
    "tags": [
      "分类：LLM应用\n\n这篇论文的摘要主要讨论了如何通过外部知识图谱增强大型语言模型（LLM）的性能，特别是在需要高度可解释性的领域。此外，论文提出了GAME-KG框架，利用众包反馈来调整知识图谱中的显式和隐式联系。这些内容都与LLM的应用相关，因此将这篇论文归类为LLM应用。",
      "人口贩卖数据分析",
      "知识图谱"
    ]
  },
  {
    "title": "PANGeA: Procedural Artificial Narrative using Generative AI for Turn-Based Video Games",
    "submit_datetime": "2024年04月30日",
    "abstract": "This research introduces Procedural Artificial Narrative using Generative AI (PANGeA), a structured approach for leveraging large language models (LLMs), guided by a game designer's high-level criteria, to generate narrative content for turn-based role-playing video games (RPGs). Distinct from prior applications of LLMs used for video game design, PANGeA innovates by not only generating game level data (which includes, but is not limited to, setting, key items, and non-playable characters (NPCs)), but by also fostering dynamic, free-form interactions between the player and the environment that align with the procedural game narrative. The NPCs generated by PANGeA are personality-biased and express traits from the Big 5 Personality Model in their generated responses. PANGeA addresses challenges behind ingesting free-form text input, which can prompt LLM responses beyond the scope of the game narrative. A novel validation system that uses the LLM's intelligence evaluates text input and aligns generated responses with the unfolding narrative. Making these interactions possible, PANGeA is supported by a server that hosts a custom memory system that supplies context for augmenting generated responses thus aligning them with the procedural narrative. For its broad application, the server has a REST interface enabling any game engine to integrate directly with PANGeA, as well as an LLM interface adaptable with local or private LLMs. PANGeA's ability to foster dynamic narrative generation by aligning responses with the procedural narrative is demonstrated through an empirical study and ablation test of two versions of a demo game. These are, a custom, browser-based GPT and a Unity demo. As the results show, PANGeA holds potential to assist game designers in using LLMs to generate narrative-consistent content even when provided varied and unpredictable, free-form text input.",
    "pdf_link": "https://arxiv.org/abs/2404.19721",
    "graphs": [],
    "abstract_cn": "本研究提出了一种名为PANGeA的创新方法，它利用大型语言模型（LLMs）生成回合制角色扮演游戏（RPGs）的叙事内容。与传统的游戏设计不同，PANGeA不仅能够生成游戏关卡数据，还能促进玩家与游戏环境之间的动态互动，这些互动与游戏的程序化叙事紧密相连。PANGeA生成的NPC具有基于五大人格模型的个性特征，能够以个性化的方式响应玩家。此外，PANGeA还解决了自由形式文本输入的挑战，通过一个新颖的验证系统，利用LLM的智能来评估和对齐文本输入，确保生成的回应与游戏叙事同步。PANGeA由一个服务器支持，该服务器配备了自定义记忆系统，为生成的回应提供上下文信息，以符合程序化叙事。服务器还提供了REST接口，方便游戏引擎与PANGeA集成，并支持与本地或私有LLMs的接口对接。通过实证研究和对演示游戏的两个版本的消融测试，PANGeA展示了其在动态叙事生成方面的能力，即使面对多变和不可预测的自由形式文本输入，也能辅助游戏设计师生成与叙事一致的内容。",
    "title_cn": "PANGeA：为回合制视频游戏打造程序化叙事，借助生成性人工智能技术。",
    "tags": [
      "分类：LLM应用",
      "游戏开发",
      "人工智能"
    ]
  },
  {
    "title": "Assessing LLMs in Malicious Code Deobfuscation of Real-world Malware Campaigns",
    "submit_datetime": "2024年04月30日",
    "abstract": "The integration of large language models (LLMs) into various pipelines is increasingly widespread, effectively automating many manual tasks and often surpassing human capabilities. Cybersecurity researchers and practitioners have recognised this potential. Thus, they are actively exploring its applications, given the vast volume of heterogeneous data that requires processing to identify anomalies, potential bypasses, attacks, and fraudulent incidents. On top of this, LLMs' advanced capabilities in generating functional code, comprehending code context, and summarising its operations can also be leveraged for reverse engineering and malware deobfuscation. To this end, we delve into the deobfuscation capabilities of state-of-the-art LLMs. Beyond merely discussing a hypothetical scenario, we evaluate four LLMs with real-world malicious scripts used in the notorious Emotet malware campaign. Our results indicate that while not absolutely accurate yet, some LLMs can efficiently deobfuscate such payloads. Thus, fine-tuning LLMs for this task can be a viable potential for future AI-powered threat intelligence pipelines in the fight against obfuscated malware.",
    "pdf_link": "https://arxiv.org/abs/2404.19715",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.19715v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19715/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19715v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19715/analysis_environment.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19715v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19715/x2.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）正被越来越多地融入多样化的工作流程，它们不仅大幅提高了自动化水平，而且在很多情况下超越了人类的处理能力。网络安全领域的专家已经意识到了这一点，并开始积极探索其在处理大量复杂数据中的应用，这些数据的处理对于识别异常行为、潜在的安全漏洞、攻击行为以及欺诈事件至关重要。更进一步，LLMs 在代码生成、上下文理解以及操作总结方面的高级功能，也为逆向工程和恶意软件的去混淆提供了新的可能性。本研究不仅停留在理论层面，而是通过分析 Emotet 恶意软件活动中使用的现实世界恶意脚本，对四种顶尖的 LLMs 进行了实际测试。测试结果显示，尽管结果尚未达到完全精确，但某些 LLMs 已经能够有效地对这些恶意负载进行去混淆处理。这表明，对 LLMs 进行针对性的训练，未来可能成为 AI 驱动的威胁情报流程中，对抗混淆恶意软件的一个有效手段。",
    "title_cn": "本文旨在探讨大型语言模型在解析现实世界恶意软件活动中的恶意代码去混淆能力。",
    "tags": [
      "LLM应用",
      "网络安全",
      "人工智能"
    ]
  },
  {
    "title": "Automated Generation of High-Quality Medical Simulation Scenarios Through Integration of Semi-Structured Data and Large Language Models",
    "submit_datetime": "2024年04月30日",
    "abstract": "This study introduces a transformative framework for medical education by integrating semi-structured data with Large Language Models (LLMs), primarily OpenAIs ChatGPT3.5, to automate the creation of medical simulation scenarios. Traditionally, developing these scenarios was a time-intensive process with limited flexibility to meet diverse educational needs. The proposed approach utilizes AI to efficiently generate detailed, clinically relevant scenarios that are tailored to specific educational objectives. This innovation has significantly reduced the time and resources required for scenario development, allowing for a broader variety of simulations. Preliminary feedback from educators and learners has shown enhanced engagement and improved knowledge acquisition, confirming the effectiveness of this AI-enhanced methodology in simulation-based learning. The integration of structured data with LLMs not only streamlines the creation process but also offers a scalable, dynamic solution that could revolutionize medical training, highlighting the critical role of AI in advancing educational outcomes and patient care standards.",
    "pdf_link": "https://arxiv.org/abs/2404.19713",
    "graphs": [],
    "abstract_cn": "本研究提出了一个创新的医疗教育框架，通过融合半结构化数据与大型语言模型（LLMs），尤其是OpenAI的ChatGPT3.5，以自动化生成医疗模拟场景。这一方法摒弃了以往耗时且适应性有限的传统场景开发方式，转而利用AI技术高效地创造出既详细又具有临床相关性的教学场景，满足特定的教育目标。这一变革大幅降低了场景开发的时间和资源消耗，使得模拟种类更加多样化。教育者和学习者的初步反馈表明，这种AI驱动的教学方法提升了学习参与度并促进了知识的掌握，验证了其在模拟教学中的有效性。结构化数据与LLMs的结合不仅优化了创建流程，还提供了一种灵活且可扩展的解决方案，预示着医疗培训的革新，彰显了AI在提升教育成效和患者护理标准中的关键作用。",
    "title_cn": "融合半结构化数据与大型语言模型，实现医学模拟情景的自动化高品质生成。",
    "tags": [
      "LLM应用",
      "",
      ""
    ]
  },
  {
    "title": "When to Retrieve: Teaching LLMs to Utilize Information Retrieval Effectively",
    "submit_datetime": "2024年04月30日",
    "abstract": "In this paper, we demonstrate how Large Language Models (LLMs) can effectively learn to use an off-the-shelf information retrieval (IR) system specifically when additional context is required to answer a given question. Given the performance of IR systems, the optimal strategy for question answering does not always entail external information retrieval; rather, it often involves leveraging the parametric memory of the LLM itself. Prior research has identified this phenomenon in the PopQA dataset, wherein the most popular questions are effectively addressed using the LLM's parametric memory, while less popular ones require IR system usage. Following this, we propose a tailored training approach for LLMs, leveraging existing open-domain question answering datasets. Here, LLMs are trained to generate a special token, <RET>, when they do not know the answer to a question. Our evaluation of the Adaptive Retrieval LLM (Adapt-LLM) on the PopQA dataset showcases improvements over the same LLM under three configurations: (i) retrieving information for all the questions, (ii) using always the parametric memory of the LLM, and (iii) using a popularity threshold to decide when to use a retriever. Through our analysis, we demonstrate that Adapt-LLM is able to generate the <RET> token when it determines that it does not know how to answer a question, indicating the need for IR, while it achieves notably high accuracy levels when it chooses to rely only on its parametric memory.",
    "pdf_link": "https://arxiv.org/abs/2404.19705",
    "graphs": [],
    "abstract_cn": "本文阐述了大型语言模型（LLMs）在特定情境下，如何高效地利用现成的信息检索（IR）系统来回答问题，尤其是当问题需要额外上下文时。研究发现，并非所有问答场景都需要外部信息检索，有时更需依赖LLM的内在参数记忆。在PopQA数据集上的研究显示，常见问题通过LLM的参数记忆即可得到解答，而不常见的问题则需借助IR系统。据此，我们提出了一种针对LLMs的训练策略，结合开放域问答数据集进行训练，使LLMs能够在不确定答案时生成特殊标记<RET>。在PopQA数据集上的测试表明，自适应检索LLM（Adapt-LLM）在三种不同配置下均优于传统LLM：全面检索、仅使用参数记忆，以及基于问题流行度决定是否使用检索器。分析结果揭示，Adapt-LLM能够在不知如何回答时生成<RET>标记，提示需要进行信息检索；而在依赖其参数记忆时，其准确度显著提升。",
    "title_cn": "何时检索：引导大型语言模型高效运用信息检索技术。",
    "tags": [
      "LLM应用",
      "信息检索",
      "问答系统"
    ]
  },
  {
    "title": "Naturally Supervised 3D Visual Grounding with Language-Regularized Concept Learners",
    "submit_datetime": "2024年04月30日",
    "abstract": "3D visual grounding is a challenging task that often requires direct and dense supervision, notably the semantic label for each object in the scene. In this paper, we instead study the naturally supervised setting that learns from only 3D scene and QA pairs, where prior works underperform. We propose the Language-Regularized Concept Learner (LARC), which uses constraints from language as regularization to significantly improve the accuracy of neuro-symbolic concept learners in the naturally supervised setting. Our approach is based on two core insights: the first is that language constraints (e.g., a word's relation to another) can serve as effective regularization for structured representations in neuro-symbolic models; the second is that we can query large language models to distill such constraints from language properties. We show that LARC improves performance of prior works in naturally supervised 3D visual grounding, and demonstrates a wide range of 3D visual reasoning capabilities-from zero-shot composition, to data efficiency and transferability. Our method represents a promising step towards regularizing structured visual reasoning frameworks with language-based priors, for learning in settings without dense supervision.",
    "pdf_link": "https://arxiv.org/abs/2404.19696",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.19696v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19696/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19696v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19696/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19696v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19696/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19696v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19696/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19696v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19696/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19696v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19696/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19696v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19696/x7.png"
      }
    ],
    "abstract_cn": "3D 视觉定位任务通常依赖于密集的直接指导，例如场景中每个物体的语义标签。本文另辟蹊径，探索了仅依赖于 3D 场景与问答对的自然监督学习环境，这一领域之前的研究表现并不理想。我们提出了一种名为语言规范化概念学习器（LARC）的新方法，它利用语言中的约束作为正则化手段，显著提升了神经符号概念学习器在自然监督环境下的准确度。该方法的核心思想有二：一是语言约束（如词与词之间的关系）能有效规范神经符号模型中的结构化表示；二是可以通过大型语言模型提炼出语言属性中的这些约束。实验结果表明，LARC 在自然监督的 3D 视觉定位任务上超越了现有技术，并展现出了从零样本组合到数据效率和可转移性的广泛 3D 视觉推理能力。这一方法为使用基于语言的先验知识来规范结构化视觉推理框架，以在缺乏密集监督的环境中学习，提供了一个充满希望的新方向。",
    "title_cn": "利用语言规范的概念学习器进行自然监督的三维视觉定位研究",
    "tags": [
      "分类：Agent",
      "3D视觉",
      ""
    ]
  },
  {
    "title": "On Training a Neural Network to Explain Binaries",
    "submit_datetime": "2024年04月30日",
    "abstract": "In this work, we begin to investigate the possibility of training a deep neural network on the task of binary code understanding. Specifically, the network would take, as input, features derived directly from binaries and output English descriptions of functionality to aid a reverse engineer in investigating the capabilities of a piece of closed-source software, be it malicious or benign. Given recent success in applying large language models (generative AI) to the task of source code summarization, this seems a promising direction. However, in our initial survey of the available datasets, we found nothing of sufficiently high quality and volume to train these complex models. Instead, we build our own dataset derived from a capture of Stack Overflow containing 1.1M entries. A major result of our work is a novel dataset evaluation method using the correlation between two distances on sample pairs: one distance in the embedding space of inputs and the other in the embedding space of outputs. Intuitively, if two samples have inputs close in the input embedding space, their outputs should also be close in the output embedding space. We found this Embedding Distance Correlation (EDC) test to be highly diagnostic, indicating that our collected dataset and several existing open-source datasets are of low quality as the distances are not well correlated. We proceed to explore the general applicability of EDC, applying it to a number of qualitatively known good datasets and a number of synthetically known bad ones and found it to be a reliable indicator of dataset value.",
    "pdf_link": "https://arxiv.org/abs/2404.19631",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.19631v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19631/binary-prose-dist-correl.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19631v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19631/billsum-results.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19631v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19631/stackoverflow-results.png"
      }
    ],
    "abstract_cn": "本研究致力于探索深度神经网络在二进制代码理解任务上的训练潜力。目标是让网络输入二进制文件的直接特征，并输出功能描述，以辅助逆向工程师分析闭源软件的功能，无论其性质是恶意还是良性。尽管在源代码摘要任务中应用大型语言模型已取得显著成果，但在寻找适合训练此类复杂模型的高质量和大规模数据集时，我们并未发现合适的资源。因此，我们自行构建了数据集，源自Stack Overflow的110万条数据。研究中一个创新的成果是提出了一种新的数据集评估方法，该方法基于样本对在输入和输出嵌入空间中的距离相关性。简而言之，若两个样本在输入嵌入空间中相近，则其在输出嵌入空间中也应相似。我们进行的嵌入距离相关性（EDC）测试显示出高度的诊断价值，揭示了我们的数据集及一些现有的开源数据集质量不佳，因为这些距离之间的相关性并不显著。此外，我们还探讨了EDC的普遍适用性，将其应用于多个已知优质的数据集和一些已知较差的合成数据集，证实了EDC作为衡量数据集价值的可靠标准。",
    "title_cn": "培养神经网络以阐释二进制代码",
    "tags": [
      "LLM应用",
      "软件工程",
      "数据科学"
    ]
  },
  {
    "title": "Transferring Troubles: Cross-Lingual Transferability of Backdoor Attacks in LLMs with Instruction Tuning",
    "submit_datetime": "2024年04月30日",
    "abstract": "The implications of backdoor attacks on English-centric large language models (LLMs) have been widely examined - such attacks can be achieved by embedding malicious behaviors during training and activated under specific conditions that trigger malicious outputs. However, the impact of backdoor attacks on multilingual models remains under-explored. Our research focuses on cross-lingual backdoor attacks against multilingual LLMs, particularly investigating how poisoning the instruction-tuning data in one or two languages can affect the outputs in languages whose instruction-tuning data was not poisoned. Despite its simplicity, our empirical analysis reveals that our method exhibits remarkable efficacy in models like mT5, BLOOM, and GPT-3.5-turbo, with high attack success rates, surpassing 95% in several languages across various scenarios. Alarmingly, our findings also indicate that larger models show increased susceptibility to transferable cross-lingual backdoor attacks, which also applies to LLMs predominantly pre-trained on English data, such as Llama2, Llama3, and Gemma. Moreover, our experiments show that triggers can still work even after paraphrasing, and the backdoor mechanism proves highly effective in cross-lingual response settings across 25 languages, achieving an average attack success rate of 50%. Our study aims to highlight the vulnerabilities and significant security risks present in current multilingual LLMs, underscoring the emergent need for targeted security measures.",
    "pdf_link": "https://arxiv.org/abs/2404.19597",
    "graphs": [],
    "abstract_cn": "后门攻击对英语主导的大型语言模型（LLMs）的影响已受到广泛关注，这类攻击在训练时嵌入恶意代码，并在特定触发条件下激活以产生恶意输出。然而，其对多语言模型的冲击尚未得到充分研究。本研究聚焦于多语言LLMs的跨语言后门攻击，特别是探讨在一个或两个语言中篡改指令调整数据如何影响其他未受影响语言的输出。尽管方法简单，但我们的实证分析发现，该方法在mT5、BLOOM和GPT-3.5-turbo等模型中效果显著，攻击成功率极高，多语言环境下超过95%。更令人担忧的是，大型模型对跨语言后门攻击的敏感性增强，这一现象也出现在主要基于英语数据预训练的LLMs中，如Llama2、Llama3和Gemma。此外，实验显示，即使经过改写，触发器依然有效，后门机制在25种语言的跨语言响应场景中表现出色，平均攻击成功率达到50%。本研究旨在揭示当前多语言LLMs的安全隐患，强调了采取针对性安全措施的迫切性。",
    "title_cn": "在经过指令调整的大型语言模型（LLMs）中，后门攻击的跨语言转移性面临挑战。",
    "tags": [
      "LLM应用",
      "网络安全",
      "人工智能"
    ]
  },
  {
    "title": "Extending Llama-3's Context Ten-Fold Overnight",
    "submit_datetime": "2024年04月30日",
    "abstract": "We extend the context length of Llama-3-8B-Instruct from 8K to 80K via QLoRA fine-tuning. The entire training cycle is super efficient, which takes 8 hours on one 8xA800 (80G) GPU machine. The resulted model exhibits superior performances across a broad range of evaluation tasks, such as NIHS, topic retrieval, and long-context language understanding; meanwhile, it also well preserves the original capability over short contexts. The dramatic context extension is mainly attributed to merely 3.5K synthetic training samples generated by GPT-4 , which indicates the LLMs' inherent (yet largely underestimated) potential to extend its original context length. In fact, the context length could be extended far beyond 80K with more computation resources. Therefore, the team will publicly release the entire resources (including data, model, data generation pipeline, training code) so as to facilitate the future research from the community: \\url{https://github.com/FlagOpen/FlagEmbedding}.",
    "pdf_link": "https://arxiv.org/abs/2404.19553",
    "graphs": [],
    "abstract_cn": "我们通过 QLoRA 微调技术，成功将 Llama-3-8B-Instruct 模型的上下文长度从 8,000 个标记扩展至 80,000 个，整个过程在单个 8xA800 (80G) GPU 机器上仅需 8 小时即可完成。新模型在包括 NIHS、主题检索和长上下文语言理解在内的多项评估任务上均展现出卓越的性能，同时对短上下文的处理能力也得到了保持。这一显著的扩展能力主要得益于 GPT-4 生成的 3,500 个合成训练样本，凸显了大型语言模型在扩展上下文长度方面的潜在能力，这一能力之前被大大低估。实际上，若有更多计算资源，上下文长度的扩展潜力远超 80K。为此，我们团队将公开全部资源，包括数据、模型、数据生成流程和训练代码，以推动社区的进一步研究，详细信息可访问 \\url{https://github.com/FlagOpen/FlagEmbedding}。",
    "title_cn": "一夜之间，Llama-3 的上下文理解能力提升了十倍。",
    "tags": [
      "LLM应用",
      "",
      "机器学习"
    ]
  },
  {
    "title": "RAG and RAU: A Survey on Retrieval-Augmented Language Model in Natural Language Processing",
    "submit_datetime": "2024年04月30日",
    "abstract": "Large Language Models (LLMs) have catalyzed significant advancements in Natural Language Processing (NLP), yet they encounter challenges such as hallucination and the need for domain-specific knowledge. To mitigate these, recent methodologies have integrated information retrieved from external resources with LLMs, substantially enhancing their performance across NLP tasks. This survey paper addresses the absence of a comprehensive overview on Retrieval-Augmented Language Models (RALMs), both Retrieval-Augmented Generation (RAG) and Retrieval-Augmented Understanding (RAU), providing an in-depth examination of their paradigm, evolution, taxonomy, and applications. The paper discusses the essential components of RALMs, including Retrievers, Language Models, and Augmentations, and how their interactions lead to diverse model structures and applications. RALMs demonstrate utility in a spectrum of tasks, from translation and dialogue systems to knowledge-intensive applications. The survey includes several evaluation methods of RALMs, emphasizing the importance of robustness, accuracy, and relevance in their assessment. It also acknowledges the limitations of RALMs, particularly in retrieval quality and computational efficiency, offering directions for future research. In conclusion, this survey aims to offer a structured insight into RALMs, their potential, and the avenues for their future development in NLP. The paper is supplemented with a Github Repository containing the surveyed works and resources for further study: https://github.com/2471023025/RALM_Survey.",
    "pdf_link": "https://arxiv.org/abs/2404.19543",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）极大地推动了自然语言处理（NLP）的发展，但同时也面临着幻觉现象和对特定领域知识的依赖等挑战。为了应对这些挑战，最新的研究方法开始将外部资源检索到的信息与LLMs相结合，显著提升了模型在各类NLP任务中的表现。本篇综述文章填补了对检索增强语言模型（RALMs）——包括检索增强生成（RAG）和检索增强理解（RAU）——全面概述的空白，深入探讨了它们的模式、发展、分类法和应用场景。文中详细阐述了RALMs的核心组件，包括检索器、语言模型和增强手段，以及这些组件如何相互作用，形成多样化的模型架构和应用。RALMs在多种任务中都显示出其实用性，包括翻译、对话系统和知识密集型应用。文章还包含了对RALMs的多种评估方法，特别强调了评估过程中对鲁棒性、准确性和相关性的关注。同时，也指出了RALMs的局限性，尤其是在检索质量和计算效率方面，并对未来的研究方向提出了建议。总结而言，本综述旨在提供对RALMs的结构化理解，探讨其潜力及其在NLP领域未来发展的可能路径。此外，文章还提供了一个包含相关研究和资源的Github仓库，供进一步研究使用：https://github.com/2471023025/RALM_Survey。",
    "title_cn": "RAG 与 RAU：探索自然语言处理领域中的检索增强语言模型",
    "tags": [
      "分类：RAG",
      "",
      "信息检索"
    ]
  },
  {
    "title": "Do Large Language Models Understand Conversational Implicature -- A case study with a chinese sitcom",
    "submit_datetime": "2024年04月30日",
    "abstract": "Understanding the non-literal meaning of an utterance is critical for large language models (LLMs) to become human-like social communicators. In this work, we introduce SwordsmanImp, the first Chinese multi-turn-dialogue-based dataset aimed at conversational implicature, sourced from dialogues in the Chinese sitcom $\\textit{My Own Swordsman}$. It includes 200 carefully handcrafted questions, all annotated on which Gricean maxims have been violated. We test eight close-source and open-source LLMs under two tasks: a multiple-choice question task and an implicature explanation task. Our results show that GPT-4 attains human-level accuracy (94%) on multiple-choice questions. CausalLM demonstrates a 78.5% accuracy following GPT-4. Other models, including GPT-3.5 and several open-source models, demonstrate a lower accuracy ranging from 20% to 60% on multiple-choice questions. Human raters were asked to rate the explanation of the implicatures generated by LLMs on their reasonability, logic and fluency. While all models generate largely fluent and self-consistent text, their explanations score low on reasonability except for GPT-4, suggesting that most LLMs cannot produce satisfactory explanations of the implicatures in the conversation. Moreover, we find LLMs' performance does not vary significantly by Gricean maxims, suggesting that LLMs do not seem to process implicatures derived from different maxims differently. Our data and code are available at https://github.com/sjtu-compling/llm-pragmatics.",
    "pdf_link": "https://arxiv.org/abs/2404.19509",
    "graphs": [],
    "abstract_cn": "为了让大型语言模型（LLMs）更接近人类的社交沟通能力，理解话语的深层含义极为关键。本研究推出了SwordsmanImp，这是首个专注于中文对话含义的多轮对话数据集，源自中文情景喜剧《我的武林男友》。该数据集精心设计了200个问题，并对违反的格赖斯准则进行了标注。我们对八种封闭源和开源的大型语言模型（LLMs）进行了两项任务测试：多项选择问题和含义解释任务。测试结果显示，GPT-4在多项选择问题上达到了94%的人类水平准确率，而CausalLM紧随其后，准确率为78.5%。其他模型，包括GPT-3.5和一些开源模型，准确率则在20%到60%之间。我们还邀请了人类评估员对LLMs生成的含义解释进行合理性、逻辑性和流畅性评分。尽管所有模型都能生成流畅且一致的文本，但除了GPT-4外，其他模型在合理性上得分较低，表明大多数LLMs还未能提供令人满意的对话含义解释。此外，我们发现LLMs的性能并不因违反的格赖斯准则不同而有显著差异，这暗示LLMs在处理不同准则派生的含义时并没有表现出明显的差异。相关数据和代码已在 https://github.com/sjtu-compling/llm-pragmatics 上公开。",
    "title_cn": "大型语言模型能否领会对话中的隐含意义？——以一部中国情景喜剧为例进行探讨",
    "tags": [
      "分类：LLM应用\n\n这篇论文主要研究了大型语言模型（LLMs）在理解中文对话含义方面的能力，并通过创建一个多轮对话数据集来测试不同LLMs的性能。论文的重点是评估和比较LLMs在特定任务上的表现，这属于LLM应用的范畴。",
      "对话系统",
      "人工智能"
    ]
  },
  {
    "title": "More Compute Is What You Need",
    "submit_datetime": "2024年04月30日",
    "abstract": "Large language model pre-training has become increasingly expensive, with most practitioners relying on scaling laws to allocate compute budgets for model size and training tokens, commonly referred to as Compute-Optimal or Chinchilla Optimal. In this paper, we hypothesize a new scaling law that suggests model performance depends mostly on the amount of compute spent for transformer-based models, independent of the specific allocation to model size and dataset size. Using this unified scaling law, we predict that (a) for inference efficiency, training should prioritize smaller model sizes and larger training datasets, and (b) assuming the exhaustion of available web datasets, scaling the model size might be the only way to further improve model performance.",
    "pdf_link": "https://arxiv.org/abs/2404.19484",
    "graphs": [],
    "abstract_cn": "随着大型语言模型预训练成本的不断攀升，业界普遍依据规模法则来决定模型规模和训练令牌的计算资源分配，这一方法常被称作“计算最优化”或“栗鼠最优化”。本文提出了一个新的规模法则假设，认为模型性能主要取决于在变换器模型上的计算投入，而非模型大小或数据集大小的具体分配。基于这一统一法则，我们预测：(a) 为了提升推理效率，训练时应更倾向于选择较小的模型尺寸和更庞大的训练数据集；(b) 在现有网络数据集资源耗尽的情况下，增加模型尺寸可能是进一步提升模型性能的唯一途径。",
    "title_cn": "计算资源，多多益善。",
    "tags": [
      "LLM理论",
      "",
      "计算优化"
    ]
  },
  {
    "title": "Neuro-Vision to Language: Image Reconstruction and Interaction via Non-invasive Brain Recordings",
    "submit_datetime": "2024年04月30日",
    "abstract": "Decoding non-invasive brain recordings is crucial for advancing our understanding of human cognition, yet faces challenges from individual differences and complex neural signal representations. Traditional methods require custom models and extensive trials, and lack interpretability in visual reconstruction tasks. Our framework integrating integrates 3D brain structures with visual semantics by Vision Transformer 3D. The unified feature extractor aligns fMRI features with multiple levels of visual embeddings efficiently, removing the need for individual-specific models and allowing extraction from single-trial data. This extractor consolidates multi-level visual features into one network, simplifying integration with Large Language Models (LLMs). Additionally, we have enhanced the fMRI dataset with various fMRI-image related textual data to support multimodal large model development. The integration with LLMs enhances decoding capabilities, enabling tasks like brain captioning, question-answering, detailed descriptions, complex reasoning, and visual reconstruction. Our approach not only shows superior performance across these tasks but also precisely identifies and manipulates language-based concepts within brain signals, enhancing interpretability and providing deeper neural process insights. These advances significantly broaden non-invasive brain decoding applicability in neuroscience and human-computer interaction, setting the stage for advanced brain-computer interfaces and cognitive models.",
    "pdf_link": "https://arxiv.org/abs/2404.19438",
    "graphs": [],
    "abstract_cn": "破译非侵入性脑电图记录对于深化我们对人类认知的理解极为关键，尽管这一过程因个体差异和神经信号的复杂性而充满挑战。传统解码方法依赖于定制化模型和大量试验，且在视觉重建任务中可解释性不足。我们提出的框架，通过三维视觉变换器整合了三维大脑结构与视觉语义，使得特征提取器能够高效地将功能磁共振成像（fMRI）特征与多层次视觉嵌入相匹配，从而省去了对个体定制模型的依赖，并实现了单次试验数据的提取。该提取器将多层次视觉特征整合进单一网络，简化了与大型语言模型（LLMs）的整合流程。我们还通过引入与fMRI图像相关的多种文本数据，增强了fMRI数据集，以促进多模态大型模型的发展。与LLMs的结合显著提升了解码能力，使得大脑字幕、问答、详细描述、复杂推理和视觉重建等任务得以实现。本方法不仅在这些任务上展现了卓越的性能，还能精确地识别和操作脑信号中的语言概念，增强了解码过程的可解释性，并为神经过程的理解提供了更深层次的洞见。这些进展极大地扩展了非侵入性脑解码技术在神经科学和人机交互领域的应用前景，为发展高级脑-机接口和认知模型铺平了道路。",
    "title_cn": "神经视觉转语言：利用非侵入性大脑记录实现图像重建与互动",
    "tags": [
      "LLM应用",
      "神经科学",
      "人机交互"
    ]
  },
  {
    "title": "Can Large Language Models put 2 and 2 together? Probing for Entailed Arithmetical Relationships",
    "submit_datetime": "2024年04月30日",
    "abstract": "Two major areas of interest in the era of Large Language Models regard questions of what do LLMs know, and if and how they may be able to reason (or rather, approximately reason). Since to date these lines of work progressed largely in parallel (with notable exceptions), we are interested in investigating the intersection: probing for reasoning about the implicitly-held knowledge. Suspecting the performance to be lacking in this area, we use a very simple set-up of comparisons between cardinalities associated with elements of various subjects (e.g. the number of legs a bird has versus the number of wheels on a tricycle). We empirically demonstrate that although LLMs make steady progress in knowledge acquisition and (pseudo)reasoning with each new GPT release, their capabilities are limited to statistical inference only. It is difficult to argue that pure statistical learning can cope with the combinatorial explosion inherent in many commonsense reasoning tasks, especially once arithmetical notions are involved. Further, we argue that bigger is not always better and chasing purely statistical improvements is flawed at the core, since it only exacerbates the dangerous conflation of the production of correct answers with genuine reasoning ability.",
    "pdf_link": "https://arxiv.org/abs/2404.19432",
    "graphs": [],
    "abstract_cn": "在大型语言模型（LLM）的研究热潮中，我们关注的焦点有两个：LLM掌握了哪些知识，以及它们是否具备推理能力，或者更确切地说，能否进行近似推理。尽管这些研究方向大多独立进展，我们却对它们的交汇点充满好奇：即对隐含知识的推理能力进行探究。鉴于我们对这一领域的表现持保留态度，我们采用了一种简单的比较方法，对比不同主题元素的相关基数（如鸟的腿数与三轮车的轮子数）。我们的实证研究揭示了一个现象：尽管LLM在知识积累和推理能力上随着GPT模型的迭代而稳步提升，但它们的推理能力仅限于统计推断。要应对许多常识推理任务中的组合爆炸问题，尤其是涉及算术概念时，纯粹的统计学习方法显得力不从心。我们进一步指出，规模并非总是优势，单纯追求统计学上的提升是有缺陷的，因为这实际上加剧了正确答案产出与真正推理能力之间的混淆。",
    "title_cn": "大型语言模型能否进行简单的算术推理？本文旨在探究这些模型是否能够识别并处理蕴含的数学关系。",
    "tags": [
      "LLM理论",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Countering Reward Over-optimization in LLM with Demonstration-Guided Reinforcement Learning",
    "submit_datetime": "2024年04月30日",
    "abstract": "While Reinforcement Learning (RL) has been proven essential for tuning large language models (LLMs), it can lead to reward over-optimization (ROO). Existing approaches address ROO by adding KL regularization, requiring computationally expensive hyperparameter tuning. Additionally, KL regularization focuses solely on regularizing the language policy, neglecting a potential source of regularization: the reward function itself. Inspired by demonstration-guided RL, we here introduce the Reward Calibration from Demonstration (RCfD), which leverages human demonstrations and a reward model to recalibrate the reward objective. Formally, given a prompt, the RCfD objective minimizes the distance between the demonstrations' and LLM's rewards rather than directly maximizing the reward function. This objective shift avoids incentivizing the LLM to exploit the reward model and promotes more natural and diverse language generation. We show the effectiveness of RCfD on three language tasks, which achieves comparable performance to carefully tuned baselines while mitigating ROO.",
    "pdf_link": "https://arxiv.org/abs/2404.19409",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.19409v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19409/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19409v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19409/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19409v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19409/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19409v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19409/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19409v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19409/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19409v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19409/x6.png"
      }
    ],
    "abstract_cn": "强化学习在优化大型语言模型方面发挥着关键作用，但过度追求奖励可能导致问题。目前的做法通过KL正则化来应对这一挑战，但这需要进行昂贵的超参数调整，并且只关注于语言策略的规范化，忽略了奖励函数这一潜在的规范化因素。本研究受示范引导的RL启发，提出了一种新的奖励校准方法（RCfD），该方法结合人类示范和奖励模型来重新定义奖励目标。具体来说，RCfD在给定提示的情况下，旨在缩小示范奖励与LLM奖励之间的差异，而不是单纯追求最大化奖励函数。这种方法避免了LLM对奖励模型的过度利用，鼓励了更自然和多样化的语言生成。我们在三项语言任务中验证了RCfD的有效性，其性能可与精细调整的基线相媲美，同时有效缓解了奖励过度优化的问题。",
    "title_cn": "通过示范引导的强化学习方法，我们可以有效应对大型语言模型（LLM）中的奖励过度优化问题。",
    "tags": [
      "分类：LLM应用",
      "",
      ""
    ]
  },
  {
    "title": "Low-overhead General-purpose Near-Data Processing in CXL Memory Expanders",
    "submit_datetime": "2024年04月30日",
    "abstract": "To overcome the memory capacity wall of large-scale AI and big data applications, Compute Express Link (CXL) enables cost-efficient memory expansion beyond the local DRAM of processors. While its CXL.mem protocol stack minimizes interconnect latency, CXL memory accesses can still result in significant slowdowns for memory-bound applications. While near-data processing (NDP) in CXL memory can overcome such limitations, prior works propose application-specific HW units that are not suitable for practical CXL memory-based systems that should support various applications. On the other hand, existing CPU or GPU cores are not cost-effective for NDP because they are not optimized for memory-bound applications. In addition, the communication between the host processor and CXL controller for NDP offloading should achieve low latency, but the CXL.io (or PCIe) protocol incurs $μ$s-scale latency and is not suitable for fine-grain NDP.\n  To achieve high-performance NDP end-to-end, we propose a low-overhead general-purpose NDP architecture for CXL memory referred to as Memory-Mapped NDP (M$^2$NDP), which comprises memory-mapped functions (M$^2$func) and memory-mapped $μ$threading (M$^2μ$thr). The M$^2$func is a CXL.mem-compatible low-overhead communication mechanism between the host processor and NDP controller in the CXL memory. The M$^2μ$thr enables low-cost, general-purpose NDP unit design by introducing lightweight $μ$threads that support highly concurrent execution of NDP kernels with minimal resource wastage. By combining them, our M$^2$NDP achieves significant speedups for various applications, including in-memory OLAP, key-value store, large language model, recommendation model, and graph analytics by up to 128$\\times$ (11.5$\\times$ overall) and reduces energy by up to 87.9\\% (80.1\\% overall) compared to a baseline CPU or GPU host with passive CXL memory.",
    "pdf_link": "https://arxiv.org/abs/2404.19381",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.19381v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19381/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19381v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19381/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19381v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19381/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19381v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19381/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19381v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19381/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19381v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19381/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19381v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19381/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19381v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19381/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19381v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19381/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19381v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19381/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19381v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19381/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19381v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19381/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19381v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19381/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19381v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19381/x14.png"
      }
    ],
    "abstract_cn": "为突破大规模 AI 和大数据应用的内存瓶颈，Compute Express Link (CXL) 实现了处理器本地 DRAM 外的经济型内存扩展。尽管 CXL.mem 协议减少了连接延迟，CXL 内存访问仍可能使内存密集型应用大幅减速。CXL 内存中的近数据处理 (NDP) 虽然能解决这一问题，但现有方案多针对特定应用，不适合多样化应用需求的 CXL 内存系统。此外，现行 CPU 或 GPU 核心在 NDP 上的成本效益不高，因为它们未针对内存密集型应用进行优化。而且，主机处理器与 CXL 控制器之间的 NDP 卸载通信需要低延迟，但 CXL.io（或 PCIe）协议的延迟达到了微秒级，不适合精细的 NDP。为了实现高效的端到端 NDP，我们提出了一种低成本的通用 NDP 架构——Memory-Mapped NDP (M$^2$NDP)，适用于 CXL 内存。它包括内存映射函数 (M$^2$func) 和内存映射微线程 (M$^2μ$thr)。M$^2$func 作为一种与 CXL.mem 兼容的低开销通信机制，连接主机处理器与 CXL 内存中的 NDP 控制器。M$^2μ$thr 通过引入轻量级微线程，支持 NDP 内核的高并发执行，以低成本实现通用 NDP 单元设计，同时最大限度地减少资源浪费。结合这两者，我们的 M$^2$NDP 在多种应用中实现了显著加速，如内存内 OLAP、键值存储、大型语言模型、推荐系统和图分析等，最高加速比达 128 倍（平均加速 11.5 倍），与使用被动 CXL 内存的基线 CPU 或 GPU 主机相比，能耗降低了最高达 87.9%（平均降低 80.1%）。",
    "title_cn": "在 CXL 内存扩展器上实现高效能的通用近数据处理。",
    "tags": [
      "LLM应用",
      "大数据",
      "人工智能"
    ]
  },
  {
    "title": "Evaluating Telugu Proficiency in Large Language Models_ A Comparative Analysis of ChatGPT and Gemini",
    "submit_datetime": "2024年04月30日",
    "abstract": "The growing prominence of large language models (LLMs) necessitates the exploration of their capabilities beyond English. This research investigates the Telugu language proficiency of ChatGPT and Gemini, two leading LLMs. Through a designed set of 20 questions encompassing greetings, grammar, vocabulary, common phrases, task completion, and situational reasoning, the study delves into their strengths and weaknesses in handling Telugu. The analysis aims to identify the LLM that demonstrates a deeper understanding of Telugu grammatical structures, possesses a broader vocabulary, and exhibits superior performance in tasks like writing and reasoning. By comparing their ability to comprehend and use everyday Telugu expressions, the research sheds light on their suitability for real-world language interaction. Furthermore, the evaluation of adaptability and reasoning capabilities provides insights into how each LLM leverages Telugu to respond to dynamic situations. This comparative analysis contributes to the ongoing discussion on multilingual capabilities in AI and paves the way for future research in developing LLMs that can seamlessly integrate with Telugu-speaking communities.",
    "pdf_link": "https://arxiv.org/abs/2404.19369",
    "graphs": [],
    "abstract_cn": "随着大型语言模型（LLMs）的地位日益凸显，我们有必要探究它们在非英语领域的应用潜力。本研究聚焦于泰卢固语，评估了两大领先模型ChatGPT和Gemini的语言掌握能力。通过一系列精心设计的20个问题，覆盖了问候、语法、词汇、日常用语、任务执行和情境推理等方面，本研究深入分析了它们在泰卢固语处理上的优势与不足。研究的目的是找出哪个模型对泰卢固语的语法结构有更深入的理解，词汇量更丰富，以及在写作和推理任务上表现更佳。通过对比它们对日常泰卢固语表达的理解和运用，研究揭示了这些模型在现实语言交流中的适用性。同时，对它们的适应性和推理能力的评估，为我们提供了如何利用泰卢固语应对多变情境的见解。这项比较研究不仅丰富了关于人工智能多语言能力的讨论，也为未来开发能够与泰卢固语社区无缝对接的LLMs指明了研究方向。",
    "title_cn": "探究大型语言模型中泰卢固语能力的评估——ChatGPT 与 Gemini 的对比分析",
    "tags": [
      "LLM应用",
      "人工智能",
      "语言学"
    ]
  },
  {
    "title": "Exploring Multi-Lingual Bias of Large Code Models in Code Generation",
    "submit_datetime": "2024年04月30日",
    "abstract": "Code generation aims to synthesize code and fulfill functional requirements based on natural language (NL) specifications, which can greatly improve development efficiency. In the era of large language models (LLMs), large code models (LCMs) have been recently proposed to generate source code. LCMs can generate highly feasible solutions for programming problems described in natural language. Despite the effectiveness, we observe a noticeable multilingual bias in the generation performance of LCMs. Specifically, LCMs demonstrate proficiency in generating solutions when provided with instructions in English, yet may falter when faced with semantically equivalent instructions in other NLs such as Chinese. Moreover, the ability of LCMs to generate code exhibits variety across different programming languages (PLs), such as Python and C++. The observed phenomenon indicates the presence of multi-lingual bias within the generative capabilities of LCMs, which has remained unexplored.\n  In this paper, we aim to investigate the multi-lingual bias that exists in current LCMs. First, we initiate our investigation by constructing the first multi-lingual evaluation benchmark X-HumanEval-X, enabling us to systematically evaluate the extent of multi-lingual bias that exists in current LCMs. In our large-scale experiments on nine popular LCMs, we observe a pronounced multi-lingual bias of LCMs in code generation, including multi-NL and multi-PL bias. Specifically, when using Chinese instructions, the code generation capabilities of LCMs decrease by at least 13% in terms of the Pass@1 metric. Furthermore, LCMs perform variously across different programming languages, e.g., the performance gap between Python and C++ reaches as high as 20.9%. ...",
    "pdf_link": "https://arxiv.org/abs/2404.19368",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.19368v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19368/x1.png"
      }
    ],
    "abstract_cn": "代码生成的目的是依据自然语言规范合成代码，满足功能需求，显著提升开发效率。随着大型语言模型（LLMs）的发展，大型代码模型（LCMs）应运而生，用以生成源代码。这些模型能够针对自然语言描述的编程问题提供高度实用的解决方案。尽管成效显著，我们发现LCMs在生成性能上存在显著的多语言偏差。尤其是在接收到英文指令时，LCMs能够熟练生成解决方案，但面对其他自然语言的等效指令时，如中文，它们的表现可能会不尽人意。此外，LCMs在不同编程语言之间的代码生成能力也存在差异，例如Python与C++之间的性能差异可达20.9%。这一现象揭示了LCMs在生成能力上的多语言偏见，而这一点尚未得到充分研究。在本文中，我们旨在探究当前LCMs中的多语言偏见。我们首先通过构建首个多语言评估基准X-HumanEval-X来启动研究，以便系统评估现有LCMs中的多语言偏见程度。在对九种流行LCMs进行的大规模实验中，我们发现LCMs在代码生成任务中存在显著的多语言偏见，包括对多种自然语言和多种编程语言的偏见。具体而言，当使用中文指令时，LCMs的代码生成能力在Pass@1指标上至少下降了13%。此外，不同编程语言之间的LCMs性能也表现出差异，Python与C++之间的性能差距尤为显著。",
    "title_cn": "本文旨在探讨大型代码生成模型中存在的多语言偏见问题。",
    "tags": [
      "LLM应用",
      "",
      ""
    ]
  },
  {
    "title": "Navigating Brain Language Representations: A Comparative Analysis of Neural Language Models and Psychologically Plausible Models",
    "submit_datetime": "2024年04月30日",
    "abstract": "Neural language models, particularly large-scale ones, have been consistently proven to be most effective in predicting brain neural activity across a range of studies. However, previous research overlooked the comparison of these models with psychologically plausible ones. Moreover, evaluations were reliant on limited, single-modality, and English cognitive datasets. To address these questions, we conducted an analysis comparing encoding performance of various neural language models and psychologically plausible models. Our study utilized extensive multi-modal cognitive datasets, examining bilingual word and discourse levels. Surprisingly, our findings revealed that psychologically plausible models outperformed neural language models across diverse contexts, encompassing different modalities such as fMRI and eye-tracking, and spanning languages from English to Chinese. Among psychologically plausible models, the one incorporating embodied information emerged as particularly exceptional. This model demonstrated superior performance at both word and discourse levels, exhibiting robust prediction of brain activation across numerous regions in both English and Chinese.",
    "pdf_link": "https://arxiv.org/abs/2404.19364",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.19364v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19364/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19364v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19364/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19364v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19364/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19364v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19364/x4.png"
      }
    ],
    "abstract_cn": "大规模神经语言模型在预测大脑神经活动方面表现卓越，但以往研究较少将其与心理学认可的模型相比较，且评价多基于有限的、单一模态、英语为主的认知数据集。本研究通过广泛多模态认知数据集，对双语单词和话语层面进行了深入分析，比较了神经语言模型与心理学模型的编码表现。研究发现，在包括fMRI和眼动追踪在内的多种模态以及从英语到中文等多种语言环境中，心理学模型普遍超越了神经模型。特别是，融合了体现信息的心理学模型在单词和话语层面均展现出卓越的性能，无论是在英语还是中文中，都能精准预测大脑多个区域的激活情况。",
    "title_cn": "探索大脑中的语言表示：对神经语言模型与符合心理学原理模型的对比研究",
    "tags": [
      "LLM应用",
      "心理学",
      "神经科学"
    ]
  },
  {
    "title": "Large Language Model Informed Patent Image Retrieval",
    "submit_datetime": "2024年04月30日",
    "abstract": "In patent prosecution, image-based retrieval systems for identifying similarities between current patent images and prior art are pivotal to ensure the novelty and non-obviousness of patent applications. Despite their growing popularity in recent years, existing attempts, while effective at recognizing images within the same patent, fail to deliver practical value due to their limited generalizability in retrieving relevant prior art. Moreover, this task inherently involves the challenges posed by the abstract visual features of patent images, the skewed distribution of image classifications, and the semantic information of image descriptions. Therefore, we propose a language-informed, distribution-aware multimodal approach to patent image feature learning, which enriches the semantic understanding of patent image by integrating Large Language Models and improves the performance of underrepresented classes with our proposed distribution-aware contrastive losses. Extensive experiments on DeepPatent2 dataset show that our proposed method achieves state-of-the-art or comparable performance in image-based patent retrieval with mAP +53.3%, Recall@10 +41.8%, and MRR@10 +51.9%. Furthermore, through an in-depth user analysis, we explore our model in aiding patent professionals in their image retrieval efforts, highlighting the model's real-world applicability and effectiveness.",
    "pdf_link": "https://arxiv.org/abs/2404.19360",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.19360v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19360/img_freq.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19360v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19360/model.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19360v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19360/quali_results.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19360v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19360/tsne.png"
      }
    ],
    "abstract_cn": "专利审查过程中，用于比对当前专利图像与已有技术图像相似性的图像检索系统，对于保障专利申请的创新性和独特性起着关键作用。尽管这类系统近年来越来越受欢迎，但它们在识别同一专利中的图像方面虽有成效，却因泛化能力有限而难以在检索相关已有技术图像上提供实用价值。此外，这项工作本身还面临着专利图像的抽象视觉特征、图像分类的不均衡分布以及图像描述的语义信息等挑战。为此，我们提出了一种融合语言信息、考虑数据分布的多模态专利图像特征学习方法，该方法通过整合大型语言模型来增强对专利图像的语义理解，并借助我们提出的分布感知对比损失来提升少数类别的性能。在DeepPatent2数据集上的广泛测试显示，我们的方法在图像检索任务上达到了或接近了最先进的性能，平均精度均值（mAP）提升了53.3%，10个召回率（Recall@10）提升了41.8%，10个平均召回率（MRR@10）提升了51.9%。进一步的深入用户分析表明，我们的模型在辅助专利专业人士进行图像检索方面具有实际应用价值和显著效果。",
    "title_cn": "借助大型语言模型的专利图像检索技术",
    "tags": [
      "LLM应用",
      "专利审查",
      "图像检索"
    ]
  },
  {
    "title": "StablePT: Towards Stable Prompting for Few-shot Learning via Input Separation",
    "submit_datetime": "2024年04月30日",
    "abstract": "Large language models have shown their ability to become effective few-shot learners with prompting, revoluting the paradigm of learning with data scarcity. However, this approach largely depends on the quality of prompt initialization, and always exhibits large variability among different runs. Such property makes prompt tuning highly unreliable and vulnerable to poorly constructed prompts, which limits its extension to more real-world applications. To tackle this issue, we propose to treat the hard prompt and soft prompt as separate inputs to mitigate noise brought by the prompt initialization. Furthermore, we optimize soft prompts with contrastive learning for utilizing class-aware information in the training process to maintain model performance. Experimental results demonstrate that \\sysname outperforms state-of-the-art methods by 7.20% in accuracy and reduces the standard deviation by 2.02 on average. Furthermore, extensive experiments underscore its robustness and stability across 7 datasets covering various tasks.",
    "pdf_link": "https://arxiv.org/abs/2404.19335",
    "graphs": [],
    "abstract_cn": "大型语言模型通过提示学习，已经证明了在数据匮乏环境下成为高效的少次学习者的能力，这一进步彻底革新了学习模式。然而，这种方法的成效极大依赖于提示的初始设置质量，且在不同执行过程中波动较大。这种不稳定性使得提示调整变得不够可靠，容易受到不良提示的影响，限制了其在现实世界应用中的推广。为了应对这一挑战，我们提出了一种新方法，将硬提示和软提示作为独立的输入项，以减少由提示初始化引入的噪声。同时，我们采用对比学习方法对软提示进行优化，以便在训练过程中利用类别相关的信息，从而保持模型性能。实验结果显示，\\sysname 在准确度上超越了当前最先进方法7.20%，并将平均标准偏差降低了2.02。此外，通过在7个不同任务的数据集上进行的广泛实验，证明了其鲁棒性和稳定性。",
    "title_cn": "StablePT：探索通过输入分离技术，为少样本学习提供稳定提示的新路径。",
    "tags": [
      "LLM应用",
      "人工智能",
      "机器学习"
    ]
  },
  {
    "title": "Enhancing Trust in LLM-Generated Code Summaries with Calibrated Confidence Scores",
    "submit_datetime": "2024年04月30日",
    "abstract": "A good summary can often be very useful during program comprehension. While a brief, fluent, and relevant summary can be helpful, it does require significant human effort to produce. Often, good summaries are unavailable in software projects, thus making maintenance more difficult. There has been a considerable body of research into automated AI-based methods, using Large Language models (LLMs), to generate summaries of code; there also has been quite a bit work on ways to measure the performance of such summarization methods, with special attention paid to how closely these AI-generated summaries resemble a summary a human might have produced. Measures such as BERTScore and BLEU have been suggested and evaluated with human-subject studies.\n  However, LLMs often err and generate something quite unlike what a human might say. Given an LLM-produced code summary, is there a way to gauge whether it's likely to be sufficiently similar to a human produced summary, or not? In this paper, we study this question, as a calibration problem: given a summary from an LLM, can we compute a confidence measure, which is a good indication of whether the summary is sufficiently similar to what a human would have produced in this situation? We examine this question using several LLMs, for several languages, and in several different settings. We suggest an approach which provides well-calibrated predictions of likelihood of similarity to human summaries.",
    "pdf_link": "https://arxiv.org/abs/2404.19318",
    "graphs": [],
    "abstract_cn": "在程序理解的过程中，一份精炼、流畅且切题的摘要极为有用。然而，制作这样的摘要需要投入大量的人力。在软件项目中，优质的摘要往往难以获得，这增加了维护的难度。目前，已有大量研究致力于开发自动化的AI方法，利用大型语言模型（LLMs）来生成代码摘要。同时，也有许多研究致力于评估这些摘要方法的性能，特别是它们生成的摘要与人类生成摘要的相似度。诸如BERTScore和BLEU等评价指标已被提出，并在以人为对象的研究中进行了评估。但是，LLMs有时会出错，生成的摘要与人类的表达方式大相径庭。面对LLM生成的代码摘要，我们如何判断其是否足够接近人类生成的摘要？本文中，我们探讨了这一问题，将其视为一个校准问题：给定LLM生成的摘要，我们能否计算出一个置信度量，以判断该摘要是否足够接近人类可能生成的摘要？我们通过多种语言和不同设置下的多种LLMs来检验这一问题。我们提出了一种方法，能够提供对摘要与人类生成摘要相似性可能性的准确预测。",
    "title_cn": "通过精准的置信度评分，提升对大型语言模型产出的代码摘要的信任度。",
    "tags": [
      "LLM应用",
      "程序理解",
      "软件工程"
    ]
  },
  {
    "title": "Modeling Orthographic Variation in Occitan's Dialects",
    "submit_datetime": "2024年04月30日",
    "abstract": "Effectively normalizing textual data poses a considerable challenge, especially for low-resource languages lacking standardized writing systems. In this study, we fine-tuned a multilingual model with data from several Occitan dialects and conducted a series of experiments to assess the model's representations of these dialects. For evaluation purposes, we compiled a parallel lexicon encompassing four Occitan dialects. Intrinsic evaluations of the model's embeddings revealed that surface similarity between the dialects strengthened representations. When the model was further fine-tuned for part-of-speech tagging and Universal Dependency parsing, its performance was robust to dialectical variation, even when trained solely on part-of-speech data from a single dialect. Our findings suggest that large multilingual models minimize the need for spelling normalization during pre-processing.",
    "pdf_link": "https://arxiv.org/abs/2404.19315",
    "graphs": [],
    "abstract_cn": "文本数据的有效归一化尤其对于缺乏统一书写系统的低资源语言来说是一个重大挑战。本研究中，我们针对几种奥克西唐方言的数据对一个多语言模型进行了微调，并通过一系列实验来评估模型对这些方言的理解和表征。为了评估，我们创建了一个包含四种奥克西唐方言的对照词汇库。模型嵌入的内在评估显示，方言间的表面相似性有助于加强模型的表征能力。此外，当模型进一步针对词性标注和通用依存句法分析进行微调时，即便仅使用单一方言的词性数据进行训练，其性能也能稳定应对方言差异。研究结果表明，大型多语言模型能够在预处理阶段减少对拼写归一化的依赖。",
    "title_cn": "探索奥克西唐方言拼写变异的建模研究",
    "tags": [
      "分类：LLM应用\n\n这篇论文主要研究了多语言模型在处理低资源语言（特别是奥克西唐方言）时的表现，以及如何通过微调模型来提高对这些方言的理解和表征。论文还探讨了模型在不同方言之间的性能差异，以及如何减少对拼写归一化的依赖。这些研究内容都与大型语言模型（LLM）的应用相关，因此将其归类为LLM应用。",
      "语言学研究",
      ""
    ]
  },
  {
    "title": "Revisiting the Adversarial Robustness of Vision Language Models: a Multimodal Perspective",
    "submit_datetime": "2024年04月30日",
    "abstract": "Pretrained vision-language models (VLMs) like CLIP have shown impressive generalization performance across various downstream tasks, yet they remain vulnerable to adversarial attacks. While prior research has primarily concentrated on improving the adversarial robustness of image encoders to guard against attacks on images, the exploration of text-based and multimodal attacks has largely been overlooked. In this work, we initiate the first known and comprehensive effort to study adapting vision-language models for adversarial robustness under the multimodal attack. Firstly, we introduce a multimodal attack strategy and investigate the impact of different attacks. We then propose a multimodal contrastive adversarial training loss, aligning the clean and adversarial text embeddings with the adversarial and clean visual features, to enhance the adversarial robustness of both image and text encoders of CLIP. Extensive experiments on 15 datasets across two tasks demonstrate that our method significantly improves the adversarial robustness of CLIP. Interestingly, we find that the model fine-tuned against multimodal adversarial attacks exhibits greater robustness than its counterpart fine-tuned solely against image-based attacks, even in the context of image attacks, which may open up new possibilities for enhancing the security of VLMs.",
    "pdf_link": "https://arxiv.org/abs/2404.19287",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.19287v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19287/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19287v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19287/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19287v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19287/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19287v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19287/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19287v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19287/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19287v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19287/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19287v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19287/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19287v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19287/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19287v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19287/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19287v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19287/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19287v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19287/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19287v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19287/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19287v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19287/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19287v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19287/x14.png"
      }
    ],
    "abstract_cn": "CLIP 等预训练视觉-语言模型在多样化任务上展现了卓越的泛化能力，但对对抗性攻击的抵抗力尚显不足。以往研究多聚焦于图像编码器的抗攻击性，而对文本和多模态攻击的探讨则相对欠缺。本研究首次全面探讨了在多模态攻击情境下提升视觉-语言模型的对抗性鲁棒性。我们首先提出了一种多模态攻击策略，分析了不同攻击方式的影响，随后引入了一种多模态对比对抗训练方法，通过同步干净与对抗性文本嵌入以及视觉特征，增强了 CLIP 模型中图像和文本编码器的鲁棒性。在15个数据集的两大任务上的广泛测试显示，该方法显著提升了 CLIP 的抗攻击能力。更引人注意的是，针对多模态对抗攻击进行的模型微调，在图像攻击环境下展现出比仅针对图像攻击微调的模型更强的鲁棒性，这为视觉-语言模型的安全性提升提供了新思路。",
    "title_cn": "本文从多模态的角度出发，重新探讨视觉语言模型在对抗性攻击下的鲁棒性问题。",
    "tags": [
      "LLM应用",
      "计算机视觉",
      ""
    ]
  },
  {
    "title": "Soft Prompt Generation for Domain Generalization",
    "submit_datetime": "2024年04月30日",
    "abstract": "Large pre-trained vision language models (VLMs) have shown impressive zero-shot ability on downstream tasks with manually designed prompt, which are not optimal for specific domains. To further adapt VLMs to downstream tasks, soft prompt is proposed to replace manually designed prompt, which acts as a learning vector that undergoes fine-tuning based on specific domain data. Prior prompt learning methods primarily learn a fixed prompt and residuled prompt from training samples. However, the learned prompts lack diversity and ignore information about unseen domains, potentially compromising the transferability of the prompts. In this paper, we reframe the prompt learning framework from a generative perspective and propose a simple yet efficient method for the Domain Generalization (DG) task, namely \\textbf{S}oft \\textbf{P}rompt \\textbf{G}eneration (SPG). To the best of our knowledge, we are the first to introduce the generative model into prompt learning in VLMs and explore its potential for producing soft prompts by relying solely on the generative model, ensuring the diversity of prompts. Specifically, SPG consists of a two-stage training phase and an inference phase. During the training phase, we introduce soft prompt labels for each domain, aiming to incorporate the generative model domain knowledge. During the inference phase, the generator of the generative model is employed to obtain instance-specific soft prompts for the unseen target domain. Extensive experiments on five domain generalization benchmarks of three DG tasks demonstrate that our proposed SPG achieves state-of-the-art performance. The code will be available soon.",
    "pdf_link": "https://arxiv.org/abs/2404.19286",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.19286v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19286/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19286v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19286/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19286v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19286/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19286v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19286/x4.png"
      }
    ],
    "abstract_cn": "大型预训练视觉语言模型（VLMs）在利用人工设计提示的下游任务中展现了卓越的零样本能力，但这些提示并不总是适合特定领域。为了提升VLMs对特定下游任务的适应性，本文提出了软提示的概念，以取代传统的人工设计提示，作为一个可基于特定领域数据进行微调的学习向量。传统提示学习方法通常只学习一个固定的提示，这限制了提示的多样性，并且忽视了未见领域的信息，从而影响了提示的泛化能力。本文从生成式学习的角度重新定义了提示学习框架，并提出了一种新颖的领域泛化（DG）任务方法——软提示生成（SPG）。据我们所知，这是首次将生成模型融入VLMs的提示学习中，以期通过生成模型独立产生多样化的软提示。SPG方法包括两个训练阶段和一个推理阶段：在训练阶段，我们为每个领域定义了软提示标签，以整合生成模型的领域知识；在推理阶段，利用生成模型的生成器为未见目标领域生成特定实例的软提示。通过在三个DG任务的五个领域泛化基准上的广泛实验，我们证明了SPG方法达到了最先进的性能。相关代码即将公开。",
    "title_cn": "在领域泛化领域，软提示的生成技术正日益受到关注。",
    "tags": [
      "LLM应用",
      "计算机视觉",
      ""
    ]
  },
  {
    "title": "DiffuseLoco: Real-Time Legged Locomotion Control with Diffusion from Offline Datasets",
    "submit_datetime": "2024年04月30日",
    "abstract": "This work introduces DiffuseLoco, a framework for training multi-skill diffusion-based policies for dynamic legged locomotion from offline datasets, enabling real-time control of diverse skills on robots in the real world. Offline learning at scale has led to breakthroughs in computer vision, natural language processing, and robotic manipulation domains. However, scaling up learning for legged robot locomotion, especially with multiple skills in a single policy, presents significant challenges for prior online reinforcement learning methods. To address this challenge, we propose a novel, scalable framework that leverages diffusion models to directly learn from offline multimodal datasets with a diverse set of locomotion skills. With design choices tailored for real-time control in dynamical systems, including receding horizon control and delayed inputs, DiffuseLoco is capable of reproducing multimodality in performing various locomotion skills, zero-shot transfer to real quadrupedal robots, and it can be deployed on edge computing devices. Furthermore, DiffuseLoco demonstrates free transitions between skills and robustness against environmental variations. Through extensive benchmarking in real-world experiments, DiffuseLoco exhibits better stability and velocity tracking performance compared to prior reinforcement learning and non-diffusion-based behavior cloning baselines. The design choices are validated via comprehensive ablation studies. This work opens new possibilities for scaling up learning-based legged locomotion controllers through the scaling of large, expressive models and diverse offline datasets.",
    "pdf_link": "https://arxiv.org/abs/2404.19264",
    "graphs": [],
    "abstract_cn": "本研究提出了 DiffuseLoco，这是一个创新的框架，旨在通过离线数据集训练多技能扩散策略，实现真实世界机器人的多样化技能实时控制。这一进展在计算机视觉、自然语言处理和机器人操作等离线学习领域取得了显著成果。然而，对于腿部机器人，尤其是集成多种技能的单一策略，传统的在线强化学习方法面临重大挑战。DiffuseLoco 通过扩散模型直接从多模态数据集中学习，为动态系统的实时控制提供了定制化设计，如递减视野控制和延迟输入，能够执行多种运动技能，实现零样本迁移至四足机器人，并支持在边缘计算设备上部署。此外，DiffuseLoco 能够灵活转换技能，并对环境变化表现出强大的适应性。在现实世界的广泛测试中，DiffuseLoco 在稳定性和速度跟踪方面超越了传统强化学习和非扩散式行为克隆方法。通过全面的消融研究，验证了其设计选择的有效性。这项工作为基于学习的大型腿部运动控制器的发展，通过扩展大型、富有表现力的模型和多样化的离线数据集，提供了新的思路。",
    "title_cn": "DiffuseLoco：利用离线数据集的扩散技术，实现实时腿部运动控制",
    "tags": [
      "Agent",
      "机器人技术",
      "计算机视觉"
    ]
  },
  {
    "title": "Suvach -- Generated Hindi QA benchmark",
    "submit_datetime": "2024年04月30日",
    "abstract": "Current evaluation benchmarks for question answering (QA) in Indic languages often rely on machine translation of existing English datasets. This approach suffers from bias and inaccuracies inherent in machine translation, leading to datasets that may not reflect the true capabilities of EQA models for Indic languages. This paper proposes a new benchmark specifically designed for evaluating Hindi EQA models and discusses the methodology to do the same for any task. This method leverages large language models (LLMs) to generate a high-quality dataset in an extractive setting, ensuring its relevance for the target language. We believe this new resource will foster advancements in Hindi NLP research by providing a more accurate and reliable evaluation tool.",
    "pdf_link": "https://arxiv.org/abs/2404.19254",
    "graphs": [],
    "abstract_cn": "现行的印度语言问答评估标准多依赖于将英文数据集进行机器翻译，这种方法存在偏见和翻译不准确的问题，无法真实反映印度语言问答模型的能力。本论文提出了一个新的评估基准，专为印地语问答模型量身定制，并探讨了如何为任何任务设计类似的方法。该方法利用大型语言模型在抽取式问答环境中生成高质量数据集，确保其与目标语言的紧密相关。我们认为，这一新资源将为印地语自然语言处理研究提供更精确、更可靠的评估工具，从而推动该领域的进步。",
    "title_cn": "Suvach -- 一个专为印地语设计的问答基准生成器",
    "tags": [
      "分类：LLM应用",
      "印度语言处理",
      ""
    ]
  },
  {
    "title": "HydraLoRA: An Asymmetric LoRA Architecture for Efficient Fine-Tuning",
    "submit_datetime": "2024年04月30日",
    "abstract": "Adapting Large Language Models (LLMs) to new tasks through fine-tuning has been made more efficient by the introduction of Parameter-Efficient Fine-Tuning (PEFT) techniques, such as LoRA. However, these methods often underperform compared to full fine-tuning, particularly in scenarios involving complex datasets. This issue becomes even more pronounced in complex domains, highlighting the need for improved PEFT approaches that can achieve better performance. Through a series of experiments, we have uncovered two critical insights that shed light on the training and parameter inefficiency of LoRA. Building on these insights, we have developed HydraLoRA, a LoRA framework with an asymmetric structure that eliminates the need for domain expertise. Our experiments demonstrate that HydraLoRA outperforms other PEFT approaches, even those that rely on domain knowledge during the training and inference phases. \\href{https://github.com/Clin0212/HydraLoRA}{Code}.",
    "pdf_link": "https://arxiv.org/abs/2404.19245",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.19245v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19245/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19245v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19245/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19245v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19245/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19245v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19245/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19245v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19245/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19245v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19245/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19245v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19245/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19245v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19245/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19245v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19245/x9.png"
      }
    ],
    "abstract_cn": "采用参数高效微调（PEFT）技术如LoRA，大型语言模型（LLMs）的微调过程变得更加高效。但这些方法在面对复杂数据集时往往表现不佳，尤其是在复杂领域中，这一问题尤为突出，迫切需要更优的PEFT方法来提升性能。经过一系列实验，我们发现了两个关键洞见，它们揭示了LoRA在训练效率和参数优化上的不足。基于这些洞见，我们构建了HydraLoRA，这是一个无需领域专家知识的非对称结构LoRA框架。实验结果证明，HydraLoRA在性能上超越了其他依赖于领域知识的PEFT方法。\\href{https://github.com/Clin0212/HydraLoRA}{点击获取代码}。",
    "title_cn": "HydraLoRA：一种高效微调的非对称LoRA架构。",
    "tags": [
      "分类：LLM理论",
      "计算机科学",
      "机器学习"
    ]
  },
  {
    "title": "VimTS: A Unified Video and Image Text Spotter for Enhancing the Cross-domain Generalization",
    "submit_datetime": "2024年04月30日",
    "abstract": "Text spotting, a task involving the extraction of textual information from image or video sequences, faces challenges in cross-domain adaption, such as image-to-image and image-to-video generalization. In this paper, we introduce a new method, termed VimTS, which enhances the generalization ability of the model by achieving better synergy among different tasks. Typically, we propose a Prompt Queries Generation Module and a Tasks-aware Adapter to effectively convert the original single-task model into a multi-task model suitable for both image and video scenarios with minimal additional parameters. The Prompt Queries Generation Module facilitates explicit interaction between different tasks, while the Tasks-aware Adapter helps the model dynamically learn suitable features for each task. Additionally, to further enable the model to learn temporal information at a lower cost, we propose a synthetic video text dataset (VTD-368k) by leveraging the Content Deformation Fields (CoDeF) algorithm. Notably, our method outperforms the state-of-the-art method by an average of 2.6% in six cross-domain benchmarks such as TT-to-IC15, CTW1500-to-TT, and TT-to-CTW1500. For video-level cross-domain adaption, our method even surpasses the previous end-to-end video spotting method in ICDAR2015 video and DSText v2 by an average of 5.5% on the MOTA metric, using only image-level data. We further demonstrate that existing Large Multimodal Models exhibit limitations in generating cross-domain scene text spotting, in contrast to our VimTS model which requires significantly fewer parameters and data. The code and datasets will be made available at the https://VimTextSpotter.github.io.",
    "pdf_link": "https://arxiv.org/abs/2404.19652",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.19652v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19652/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19652v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19652/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19652v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19652/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19652v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19652/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19652v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19652/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19652v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19652/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19652v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19652/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19652v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19652/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19652v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19652/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19652v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19652/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19652v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19652/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19652v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19652/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19652v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19652/x13.png"
      }
    ],
    "abstract_cn": "文本识别技术致力于从图像或视频序列中提取文本信息，却常常在跨域适应上遭遇难题，比如图像间的转换和图像到视频的泛化。本文提出了一种创新的方法——VimTS，它通过促进不同任务间的协作，显著提升了模型的泛化性能。我们设计了一个提示查询生成模块和任务感知适配器，以最小的参数增量，将单任务模型转变为能够适应图像和视频场景的多任务模型。提示查询生成模块促进了任务间的直接互动，而任务感知适配器则指导模型为每个任务学习适宜的特征。为了使模型更高效地掌握时间信息，我们还利用内容变形场（CoDeF）算法创建了一个合成视频文本数据集VTD-368k。我们的VimTS在多个跨域基准测试中平均领先现有最先进方法2.6%，在视频级别的跨域适应上，更是在ICDAR2015视频和DSText v2数据集上以平均5.5%的MOTA指标超越了先前的端到端视频识别方法，且仅依赖于图像级数据。此外，我们发现现有的大型多模态模型在跨域场景文本识别上存在局限，而VimTS模型则以更少的参数和数据需求，展现了其优势。相关代码和数据集将在https://VimTextSpotter.github.io公开。",
    "title_cn": "VimTS：一款集视频与图像文本识别于一体的工具，旨在提升跨领域泛化能力。",
    "tags": [
      "分类：Agent\n\n这篇论文主要研究了文本识别技术在跨域适应上的挑战，并提出了一种创新的方法——VimTS，通过促进不同任务间的协作，显著提升了模型的泛化性能。这种方法涉及到设计提示查询生成模块和任务感知适配器，将单任务模型转变为能够适应图像和视频场景的多任务模型。这属于智能代理（Agent）的范畴，因为它们能够处理多种任务，并在不同场景下进行自适应。",
      "计算机视觉",
      ""
    ]
  },
  {
    "title": "Fake it to make it: Using synthetic data to remedy the data shortage in joint multimodal speech-and-gesture synthesis",
    "submit_datetime": "2024年04月30日",
    "abstract": "Although humans engaged in face-to-face conversation simultaneously communicate both verbally and non-verbally, methods for joint and unified synthesis of speech audio and co-speech 3D gesture motion from text are a new and emerging field. These technologies hold great promise for more human-like, efficient, expressive, and robust synthetic communication, but are currently held back by the lack of suitably large datasets, as existing methods are trained on parallel data from all constituent modalities. Inspired by student-teacher methods, we propose a straightforward solution to the data shortage, by simply synthesising additional training material. Specifically, we use unimodal synthesis models trained on large datasets to create multimodal (but synthetic) parallel training data, and then pre-train a joint synthesis model on that material. In addition, we propose a new synthesis architecture that adds better and more controllable prosody modelling to the state-of-the-art method in the field. Our results confirm that pre-training on large amounts of synthetic data improves the quality of both the speech and the motion synthesised by the multimodal model, with the proposed architecture yielding further benefits when pre-trained on the synthetic data. See https://shivammehta25.github.io/MAGI/ for example output.",
    "pdf_link": "https://arxiv.org/abs/2404.19622",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.19622v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19622/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19622v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19622/x2.png"
      }
    ],
    "abstract_cn": "人类在面对面交流时，不仅通过言语，还通过非言语方式进行沟通。然而，将文本同步转换成语音和伴随的3D手势动作的技术仍处于起步阶段。尽管这类技术有望实现更自然、高效、富有表现力且稳健的人工合成交流，但目前由于缺乏大规模数据集而受限。现有的技术需要依赖所有相关模态的并行数据进行训练。借鉴师生学习方法，我们提出了一种简单有效的解决方案：通过合成额外的训练材料来扩充数据。具体而言，我们利用在大型数据集上训练的单模态合成模型生成多模态但合成的并行训练数据，并在此基础之上预训练一个联合合成模型。此外，我们还提出了一种新的合成架构，它在现有最先进方法的基础上增强了韵律建模的能力，使其更加精准和可控。实验结果表明，利用大量合成数据进行预训练能够显著提升多模态模型合成语音和动作的质量，而新架构在预训练过程中进一步优化了合成效果。更多示例成果，可访问 https://shivammehta25.github.io/MAGI/ 查看。",
    "title_cn": "以假乱真：借助合成数据填补联合多模态语音及手势合成的数据缺口。",
    "tags": [
      "分类：Agent",
      "人机交互",
      "人工智能"
    ]
  },
  {
    "title": "Generating Feedback-Ladders for Logical Errors in Programming using Large Language Models",
    "submit_datetime": "2024年04月30日",
    "abstract": "In feedback generation for logical errors in programming assignments, large language model (LLM)-based methods have shown great promise. These methods ask the LLM to generate feedback given the problem statement and a student's (buggy) submission. There are several issues with these types of methods. First, the generated feedback messages are often too direct in revealing the error in the submission and thus diminish valuable opportunities for the student to learn. Second, they do not consider the student's learning context, i.e., their previous submissions, current knowledge, etc. Third, they are not layered since existing methods use a single, shared prompt for all student submissions. In this paper, we explore using LLMs to generate a \"feedback-ladder\", i.e., multiple levels of feedback for the same problem-submission pair. We evaluate the quality of the generated feedback-ladder via a user study with students, educators, and researchers. We have observed diminishing effectiveness for higher-level feedback and higher-scoring submissions overall in the study. In practice, our method enables teachers to select an appropriate level of feedback to show to a student based on their personal learning context, or in a progressive manner to go more detailed if a higher-level feedback fails to correct the student's error.",
    "pdf_link": "https://arxiv.org/abs/2405.00302",
    "graphs": [],
    "abstract_cn": "在编程作业逻辑错误反馈生成领域，基于大型语言模型（LLM）的技术展现了显著的前景。这些技术通过问题描述和学生（存在缺陷的）作业提交，指导LLM生成反馈。然而，这种方法面临多重挑战：首先，反馈信息往往过于直白，容易暴露错误，减少了学生的自我发现机会；其次，它们忽略了学生的学习背景，如过往作业和知识水平；再者，它们缺乏层次性，通常对所有学生提交采用统一的提示。本文提出了一种利用LLM生成“反馈阶梯”的方法，即为同一问题和学生提交提供多层次的反馈。通过与学生、教师和研究者的用户体验研究，我们评估了所生成反馈阶梯的质量，并发现对于更高层次的反馈和得分较高的作业，其效果逐渐减弱。在实际应用中，该方法允许教师根据学生的个性化学习需求选择合适的反馈层次，或者在高层次反馈未能纠正错误时，逐步提供更详细的指导。",
    "title_cn": "利用大型语言模型为编程中的逻辑错误构建反馈梯度。",
    "tags": [
      "LLM应用",
      "",
      "软件工程"
    ]
  },
  {
    "title": "LITO: Learnable Intervention for Truthfulness Optimization",
    "submit_datetime": "2024年04月30日",
    "abstract": "Large language models (LLMs) can generate long-form and coherent text, but they still frequently hallucinate facts, thus limiting their reliability. To address this issue, inference-time methods that elicit truthful responses have been proposed by shifting LLM representations towards learned \"truthful directions\". However, applying the truthful directions with the same intensity fails to generalize across different question contexts. We propose LITO, a Learnable Intervention method for Truthfulness Optimization that automatically identifies the optimal intervention intensity tailored to a specific context. LITO explores a sequence of model generations based on increasing levels of intervention intensities. It selects the most accurate response or refuses to answer when the predictions are highly uncertain. Experiments on multiple LLMs and question-answering datasets demonstrate that LITO improves truthfulness while preserving task accuracy. The adaptive nature of LITO counters issues with one-size-fits-all intervention-based solutions, maximizing model truthfulness by reflecting internal knowledge only when the model is confident.",
    "pdf_link": "https://arxiv.org/abs/2405.00301",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）虽能产出长篇连贯文本，却常出现事实性错误，影响了其可信度。为提高可靠性，研究者提出了一种推理阶段的方法，通过调整LLM的表示向“真实导向”靠拢，以引出真实的回答。但这种方法若一视同仁地应用，却难以适应多变的问题情境。我们引入了LITO，一种自动确定最佳干预强度的可学习干预方法，以适应不同上下文的真实性优化需求。LITO通过递增的干预强度生成模型序列，并在预测不确定性高时选择最准确的答案或选择不回答。在多个大型语言模型和问答数据集上的实验显示，LITO在确保任务准确性的同时，有效提升了回答的真实性。LITO的自适应特性克服了通用干预方法的局限，通过在模型信心充足时反映其内在知识，实现了模型真实性的最大化。",
    "title_cn": "LITO：为真实性优化而设计的可学习干预机制",
    "tags": [
      "LLM应用",
      "问答系统",
      ""
    ]
  },
  {
    "title": "How Can I Improve? Using GPT to Highlight the Desired and Undesired Parts of Open-ended Responses",
    "submit_datetime": "2024年04月30日",
    "abstract": "Automated explanatory feedback systems play a crucial role in facilitating learning for a large cohort of learners by offering feedback that incorporates explanations, significantly enhancing the learning process. However, delivering such explanatory feedback in real-time poses challenges, particularly when high classification accuracy for domain-specific, nuanced responses is essential. Our study leverages the capabilities of large language models, specifically Generative Pre-Trained Transformers (GPT), to explore a sequence labeling approach focused on identifying components of desired and less desired praise for providing explanatory feedback within a tutor training dataset. Our aim is to equip tutors with actionable, explanatory feedback during online training lessons. To investigate the potential of GPT models for providing the explanatory feedback, we employed two commonly-used approaches: prompting and fine-tuning. To quantify the quality of highlighted praise components identified by GPT models, we introduced a Modified Intersection over Union (M-IoU) score. Our findings demonstrate that: (1) the M-IoU score effectively correlates with human judgment in evaluating sequence quality; (2) using two-shot prompting on GPT-3.5 resulted in decent performance in recognizing effort-based (M-IoU of 0.46) and outcome-based praise (M-IoU of 0.68); and (3) our optimally fine-tuned GPT-3.5 model achieved M-IoU scores of 0.64 for effort-based praise and 0.84 for outcome-based praise, aligning with the satisfaction levels evaluated by human coders. Our results show promise for using GPT models to provide feedback that focuses on specific elements in their open-ended responses that are desirable or could use improvement.",
    "pdf_link": "https://arxiv.org/abs/2405.00291",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00291v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00291/demo_picture.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00291v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00291/tokenization.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00291v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00291/scatter_matrix.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.00291v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00291/RQ2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00291v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00291/scatter_plot_matrix_outcome.jpg"
      }
    ],
    "abstract_cn": "自动化解释性反馈系统对于提升大规模学习者的学习效果至关重要，它通过融入解释的反馈显著提升了学习体验。然而，实时提供此类反馈面临诸多挑战，尤其是在必须确保对特定领域内微妙反应的高分类准确性时。本研究借助大型语言模型，尤其是生成预训练变换器（GPT），采用序列标注方法，旨在从导师培训数据集中辨识出所需和非理想赞扬的要素，以便提供解释性反馈。我们旨在为在线培训课程中的导师提供实用的、有解释性的反馈。为了探究GPT模型在提供解释性反馈方面的潜力，我们采用了两种常用策略：提示和微调。我们还引入了一种改进的交集比对并集（M-IoU）分数，用以量化GPT模型识别出的赞扬要素的质量。研究发现：（1）M-IoU分数与人工评估序列质量的结果高度相关；（2）在GPT-3.5上应用两次提示，对于识别基于努力的赞扬（M-IoU得分0.46）和基于成果的赞扬（M-IoU得分0.68）均表现出良好的性能；（3）我们经过最佳微调的GPT-3.5模型在基于努力的赞扬上达到了0.64的M-IoU得分，在基于成果的赞扬上达到了0.84的M-IoU得分，这与人工编码员评估的满意度水平相吻合。这些结果预示着GPT模型在提供专注于开放式反馈中特定元素的反馈方面具有潜力，这些元素可能是值得提倡的或者有改进空间的。",
    "title_cn": "如何提升自我？利用 GPT 技术凸显开放式回答中的期望与非期望要素。",
    "tags": [
      "LLM应用",
      "教育技术",
      ""
    ]
  },
  {
    "title": "Adversarial Attacks and Defense for Conversation Entailment Task",
    "submit_datetime": "2024年04月30日",
    "abstract": "Large language models (LLMs) that are proved to be very powerful on different NLP tasks. However, there are still many ways to attack the model with very low costs. How to defend the model becomes an important problem. In our work, we treat adversarial attack results as a new (unseen) domain of the model, and we frame the defending problem into how to improve the robustness of the model on the new domain. We focus on the task of conversation entailment, where multi-turn natural language dialogues are the premise, and the transformer model is fine-tuned to predict whether a given hypothesis about the given dialogue is true or false. The adversary would attack the hypothesis to fool the model to make the wrong predictions. We apply synonym-swapping as the attack method. To show the robustness of the model, we implement some fine-tuning strategies and propose the embedding perturbation loss as a method to improve the robustness of the model. Finally, we show the importance of our work by discussing the adversarial attacks in NLP in the real world.",
    "pdf_link": "https://arxiv.org/abs/2405.00289",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）在多种自然语言处理（NLP）任务上展现出强大能力，但它们也面临着低成本攻击的威胁。如何加固这些模型，提升其防御能力，成为了一个亟待解决的问题。本研究将对抗性攻击视为模型面对的一个新领域，并围绕如何增强模型在这一新领域的鲁棒性展开探讨。我们着眼于对话蕴含任务，即以多轮自然语言对话为前提，通过微调变换模型来预测关于对话的给定假设是否成立。攻击者会尝试对假设进行篡改，误导模型做出错误判断。我们采用同义词替换作为攻击手段。为了增强模型的鲁棒性，我们实施了若干微调策略，并引入了嵌入扰动损失方法。最终，我们通过分析自然语言处理领域中的真实对抗性攻击案例，强调了本研究的重要性和实用价值。",
    "title_cn": "对话蕴含任务的对抗性攻击与防御策略",
    "tags": [
      "LLM应用",
      "",
      "对话系统"
    ]
  },
  {
    "title": "Social Life Simulation for Non-Cognitive Skills Learning",
    "submit_datetime": "2024年04月30日",
    "abstract": "Non-cognitive skills are crucial for personal and social life well-being, and such skill development can be supported by narrative-based (e.g., storytelling) technologies. While generative AI enables interactive and role-playing storytelling, little is known about how users engage with and perceive the use of AI in social life simulation for non-cognitive skills learning. To this end, we introduced SimuLife++, an interactive platform enabled by a large language model (LLM). The system allows users to act as protagonists, creating stories with one or multiple AI-based characters in diverse social scenarios. In particular, we expanded the Human-AI interaction to a Human-AI-AI collaboration by including a sage agent, who acts as a bystander to provide users with more insightful perspectives on their choices and conversations. Through a within-subject user study, we found that the inclusion of the sage agent significantly enhanced narrative immersion, according to the narrative transportation scale, leading to more messages, particularly in group chats. Participants' interactions with the sage agent were also associated with significantly higher scores in their perceived motivation, self-perceptions, and resilience and coping, indicating positive impacts on non-cognitive skills reflection. Participants' interview results further explained the sage agent's aid in decision-making, solving ethical dilemmas, and problem-solving; on the other hand, they suggested improvements in user control and balanced responses from multiple characters. We provide design implications on the application of generative AI in narrative solutions for non-cognitive skill development in broader social contexts.",
    "pdf_link": "https://arxiv.org/abs/2405.00273",
    "graphs": [],
    "abstract_cn": "非认知技能对个人和社会福祉至关重要，而叙述性技术（如讲故事）能够助力这类技能的成长。尽管生成性AI开辟了互动式角色扮演故事讲述的新天地，用户如何与AI互动并在社交生活模拟中利用AI进行非认知技能学习仍不甚明了。为此，我们推出了SimuLife++，一个由大型语言模型（LLM）驱动的互动平台，用户在其中扮演主角，与一个或多个AI角色共同编织多样化社交场景中的故事。我们特别引入了一位智者代理，作为旁观者，为用户提供对其选择和对话的更深入见解。通过一项内部用户研究，我们发现智者代理的加入显著提升了叙事沉浸感，根据叙事传输量表，这导致了更多的交流，尤其是在群聊中。参与者与智者代理的互动还与他们感知的动机、自我感知以及韧性和应对能力的显著提升相关，这表明了对非认知技能反思的积极影响。参与者的访谈进一步阐明了智者代理在决策、解决道德困境和问题解决方面的助力；同时，他们提出了关于用户控制和多角色平衡回应的改进建议。我们为在更广泛的社会背景中应用生成性AI以促进非认知技能发展的叙述性解决方案提供了设计启示。",
    "title_cn": "社交生活模拟：非认知技能学习的新途径",
    "tags": [
      "分类：Agent\n\n这篇论文讨论了如何利用大型语言模型（LLM）驱动的互动平台来促进非认知技能的发展。其中，引入了一位智者代理（Agent），作为旁观者为用户提供深入见解。这篇论文主要关注了Agent在互动平台中的作用，以及它如何帮助用户提升叙事沉浸感和非认知技能。因此，这篇论文应该被归类为Agent。",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Clover: Regressive Lightweight Speculative Decoding with Sequential Knowledge",
    "submit_datetime": "2024年04月30日",
    "abstract": "Large language models (LLMs) suffer from low efficiency as the mismatch between the requirement of auto-regressive decoding and the design of most contemporary GPUs. Specifically, billions to trillions of parameters must be loaded to the GPU cache through its limited memory bandwidth for computation, but only a small batch of tokens is actually computed. Consequently, the GPU spends most of its time on memory transfer instead of computation. Recently, parallel decoding, a type of speculative decoding algorithms, is becoming more popular and has demonstrated impressive efficiency improvement in generation. It introduces extra decoding heads to large models, enabling them to predict multiple subsequent tokens simultaneously and verify these candidate continuations in a single decoding step. However, this approach deviates from the training objective of next token prediction used during pre-training, resulting in a low hit rate for candidate tokens. In this paper, we propose a new speculative decoding algorithm, Clover, which integrates sequential knowledge into the parallel decoding process. This enhancement improves the hit rate of speculators and thus boosts the overall efficiency. Clover transmits the sequential knowledge from pre-speculated tokens via the Regressive Connection, then employs an Attention Decoder to integrate these speculated tokens. Additionally, Clover incorporates an Augmenting Block that modifies the hidden states to better align with the purpose of speculative generation rather than next token prediction. The experiment results demonstrate that Clover outperforms the baseline by up to 91% on Baichuan-Small and 146% on Baichuan-Large, respectively, and exceeds the performance of the previously top-performing method, Medusa, by up to 37% on Baichuan-Small and 57% on Baichuan-Large, respectively.",
    "pdf_link": "https://arxiv.org/abs/2405.00263",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）因自回归解码需求与现代GPU设计不匹配，导致效率不高。具体而言，为了计算，必须通过有限的内存带宽将数十亿至数万亿参数加载到GPU缓存中，但实际只处理一小部分令牌，导致GPU在内存传输上耗费的时间远超计算。近期，一种名为并行解码的推测性解码算法因其在生成任务中的显著效率提升而日益受到青睐。该算法通过增加额外的解码头，使得大型模型能够同时预测多个后续令牌，并在单一解码步骤中对这些候选续接进行验证。然而，这种方法与预训练阶段的下一个令牌预测目标有所偏离，从而降低了候选令牌的命中率。本文提出了一种名为Clover的新型推测性解码算法，它将序列知识融入并行解码流程中，有效提升了投机者的命中率及整体效率。Clover通过回归连接传递预推测令牌的序列知识，并利用注意力解码器整合这些推测令牌。此外，Clover还引入了一个增强模块，优化隐藏状态以更好地适应推测生成而非单一令牌预测。实验结果显示，Clover在Baichuan-Small数据集上的性能提升高达91%，在Baichuan-Large数据集上提升高达146%，并且在两个数据集上均超过了之前领先的Medusa方法，分别高出37%和57%。",
    "title_cn": "Clover：一种结合顺序知识，采用回归式轻量级推测性解码的方法。",
    "tags": [
      "LLM理论",
      "",
      "计算效率"
    ]
  },
  {
    "title": "Principled RLHF from Heterogeneous Feedback via Personalization and Preference Aggregation",
    "submit_datetime": "2024年04月30日",
    "abstract": "Reinforcement learning from human feedback (RLHF) has been an effective technique for aligning AI systems with human values, with remarkable successes in fine-tuning large-language models recently. Most existing RLHF paradigms make the underlying assumption that human preferences are relatively homogeneous, and can be encoded by a single reward model. In this paper, we focus on addressing the issues due to the inherent heterogeneity in human preferences, as well as their potential strategic behavior in providing feedback. Specifically, we propose two frameworks to address heterogeneous human feedback in principled ways: personalization-based one and aggregation-based one. For the former, we propose two approaches based on representation learning and clustering, respectively, for learning multiple reward models that trades off the bias (due to preference heterogeneity) and variance (due to the use of fewer data for learning each model by personalization). We then establish sample complexity guarantees for both approaches. For the latter, we aim to adhere to the single-model framework, as already deployed in the current RLHF paradigm, by carefully aggregating diverse and truthful preferences from humans. We propose two approaches based on reward and preference aggregation, respectively: the former utilizes both utilitarianism and Leximin approaches to aggregate individual reward models, with sample complexity guarantees; the latter directly aggregates the human feedback in the form of probabilistic opinions. Under the probabilistic-opinion-feedback model, we also develop an approach to handle strategic human labelers who may bias and manipulate the aggregated preferences with untruthful feedback. Based on the ideas in mechanism design, our approach ensures truthful preference reporting, with the induced aggregation rule maximizing social welfare functions.",
    "pdf_link": "https://arxiv.org/abs/2405.00254",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00254v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00254/x1.png"
      }
    ],
    "abstract_cn": "利用人类反馈进行的强化学习（RLHF）在调整大型语言模型方面取得了显著成就，成为与人类价值观对齐的有效策略。然而，现有RLHF模式通常假设人类偏好是一致的，可以通过单一奖励模型来表达。本文针对人类偏好的多样性和反馈中可能的策略性行为提出挑战，提出了两种原则性框架：个性化和聚合。个性化框架通过表示学习和聚类方法，学习多个奖励模型以平衡偏好多样性带来的偏差和个性化导致的样本方差，同时为这些方法提供了样本复杂度的保证。聚合框架则旨在维持RLHF现行的单模型架构，通过精心整合人类的多元真实偏好。我们提出了基于奖励和偏好聚合的两种方法：前者结合功利主义和Leximin原则来整合个体奖励模型，并确保样本复杂度；后者则直接聚合以概率形式表达的人类反馈。此外，我们针对可能操纵反馈以影响聚合偏好的战略性标签器，开发了一种基于机制设计的方法，确保了偏好的真实报告，并最大化了社会福利。",
    "title_cn": "本文探讨了如何通过个性化定制和偏好聚合的方式，从多样化的反馈中提炼出原则性的人类引导强化学习（RLHF）策略。",
    "tags": [
      "LLM应用",
      "人工智能",
      "机器学习"
    ]
  },
  {
    "title": "CodeHalu: Code Hallucinations in LLMs Driven by Execution-based Verification",
    "submit_datetime": "2024年04月30日",
    "abstract": "Large Language Models (LLMs) have made significant advancements in the field of code generation, offering unprecedented support for automated programming and assisting developers. However, LLMs sometimes generate code that appears plausible but fails to meet the expected requirements or executes incorrectly. This phenomenon of hallucinations in the coding field has not been explored. To advance the community's understanding and research on code hallucinations in LLMs, we propose a definition method for these hallucinations based on execution verification and introduce the concept of code hallucinations for the first time. We categorize code hallucinations into four main types: mapping, naming, resource, and logic hallucinations, each further divided into different subcategories to better understand and address the unique challenges faced by LLMs during code generation. To systematically evaluate code hallucinations, we propose a dynamic detection algorithm for code hallucinations and construct the CodeHalu benchmark, which includes 8,883 samples from 699 tasks, to actively detect hallucination phenomena in LLMs during programming. We tested 16 popular LLMs on this benchmark to evaluate the frequency and nature of their hallucinations during code generation. The findings reveal significant variations in the accuracy and reliability of LLMs in generating code, highlighting the urgent need to improve models and training methods to ensure the functional correctness and safety of automatically generated code. This study not only classifies and quantifies code hallucinations but also provides insights for future improvements in LLM-based code generation research. The CodeHalu benchmark and code are publicly available at https://github.com/yuchen814/CodeHalu.",
    "pdf_link": "https://arxiv.org/abs/2405.00253",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）在代码生成领域取得了重大突破，极大地推动了自动化编程的发展，为开发者提供了强大的辅助。然而，这些模型偶尔会产生看似合理但实际并不符合预期或执行错误的代码，这种现象在编程领域被称为“幻觉”。目前，对于LLMs中的代码幻觉现象尚缺乏深入研究。为了深化对此现象的理解，我们首次提出了一种基于执行验证的代码幻觉定义方法，并定义了代码幻觉的概念。我们将代码幻觉归纳为四大类别：映射、命名、资源和逻辑幻觉，每个类别下又细分为多个子类，以便更精准地识别和应对LLMs在代码生成时所面临的挑战。我们还开发了一种动态检测算法，用于系统性地识别代码幻觉，并构建了CodeHalu基准测试，该测试包含699个任务中的8,883个样本，旨在主动监测LLMs编程时的幻觉现象。通过对16个主流LLMs的测试，我们评估了它们在代码生成中的幻觉频率和特点。研究结果显示，不同LLMs在代码生成的准确性和可靠性上存在显著差异，这强调了提升模型性能和改进训练方法的紧迫性，以确保自动生成代码的正确性和安全性。本研究不仅对代码幻觉进行了分类和量化分析，还为未来LLMs在代码生成领域的研究提供了宝贵的洞见。CodeHalu基准测试和相关代码已在 https://github.com/yuchen814/CodeHalu 上公开发布。",
    "title_cn": "CodeHalu：在执行驱动验证的助力下，大型语言模型中产生的代码幻觉现象。",
    "tags": [
      "LLM应用",
      "",
      "自动化编程"
    ]
  },
  {
    "title": "SemantiCodec: An Ultra Low Bitrate Semantic Audio Codec for General Sound",
    "submit_datetime": "2024年04月30日",
    "abstract": "Large language models (LLMs) have significantly advanced audio processing through audio codecs that convert audio into discrete tokens, enabling the application of language modelling techniques to audio data. However, traditional codecs often operate at high bitrates or within narrow domains such as speech and lack the semantic clues required for efficient language modelling. Addressing these challenges, we introduce SemantiCodec, a novel codec designed to compress audio into fewer than a hundred tokens per second across diverse audio types, including speech, general audio, and music, without compromising quality. SemantiCodec features a dual-encoder architecture: a semantic encoder using a self-supervised AudioMAE, discretized using k-means clustering on extensive audio data, and an acoustic encoder to capture the remaining details. The semantic and acoustic encoder outputs are used to reconstruct audio via a diffusion-model-based decoder. SemantiCodec is presented in three variants with token rates of 25, 50, and 100 per second, supporting a range of ultra-low bit rates between 0.31 kbps and 1.43 kbps. Experimental results demonstrate that SemantiCodec significantly outperforms the state-of-the-art Descript codec on reconstruction quality. Our results also suggest that SemantiCodec contains significantly richer semantic information than all evaluated audio codecs, even at significantly lower bitrates. Our code and demos are available at https://haoheliu.github.io/SemantiCodec/.",
    "pdf_link": "https://arxiv.org/abs/2405.00233",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00233v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00233/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00233v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00233/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00233v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00233/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00233v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00233/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00233v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00233/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00233v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00233/ablation.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）利用音频编解码器将音频转换为离散标记，极大提升了音频处理技术，使得语言建模技术得以应用于音频数据。但现有编解码器多在高比特率下工作，或仅限于如语音这样的特定领域，缺少进行高效语言建模的语义信息。为解决这些问题，我们设计了SemantiCodec，一种创新的编解码器，它能够将多种类型的音频——包括语音、普通音频和音乐——压缩成每秒不到一百个标记，同时保证音质。SemantiCodec具备双重编码器结构：一个是基于自监督AudioMAE的语义编码器，通过在海量音频数据上应用k均值聚类进行离散化；另一个是声学编码器，用于捕捉剩余的音频细节。语义编码器和声学编码器的输出联合使用，通过基于扩散模型的解码器来重建音频。SemantiCodec提供了三种不同标记速率的版本，分别是每秒25、50和100个标记，支持从0.31 kbps到1.43 kbps的超低比特率范围。实验结果显示，SemantiCodec在音频重建质量上明显超越了当前最先进的Descript编解码器。此外，即使在较低的比特率下，SemantiCodec所包含的语义信息量也远超其他所有评估的音频编解码器。我们的代码和演示可以在 https://haoheliu.github.io/SemantiCodec/ 上访问。",
    "title_cn": "SemantiCodec：一款为各类声音设计的超低码率语义音频编解码器。",
    "tags": [
      "分类：LLM应用",
      "音频处理",
      "语言建模"
    ]
  },
  {
    "title": "Aptly: Making Mobile Apps from Natural Language",
    "submit_datetime": "2024年04月30日",
    "abstract": "We present Aptly, an extension of the MIT App Inventor platform enabling mobile app development via natural language powered by code-generating large language models (LLMs). Aptly complements App Inventor's block language with a text language designed to allow visual code generation via text-based LLMs. We detail the technical aspects of how the Aptly server integrates LLMs with a realtime collaboration function to facilitate the automated creation and editing of mobile apps given user instructions. The paper concludes with insights from a study of a pilot implementation involving high school students, which examines Aptly's practicality and user experience. The findings underscore Aptly's potential as a tool that democratizes app development and fosters technological creativity.",
    "pdf_link": "https://arxiv.org/abs/2405.00229",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00229v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00229/architecture-horizontal.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00229v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00229/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00229v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00229/prompt.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.00229v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00229/dutchapp.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00229v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00229/dutchblocks2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00229v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00229/rtc2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00229v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00229/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00229v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00229/x3.png"
      }
    ],
    "abstract_cn": "我们推出了 Aptly，这是 MIT App Inventor 平台的扩展，它利用支持自然语言的大型语言模型（LLMs）来简化移动应用的开发。Aptly 为 App Inventor 的图形化编程语言增添了一种文本语言，旨在通过文本驱动的 LLMs 实现视觉代码的生成。我们深入探讨了 Aptly 服务器如何整合 LLMs 并引入实时协作功能，以便用户能够根据指令自动创建和编辑移动应用。文章最后，通过一项针对高中学生的试点项目研究，我们分享了关于 Aptly 实用性和用户体验的洞见。研究结果突显了 Aptly 在推动应用开发的普及化和技术创造力方面的潜力。",
    "title_cn": "Aptly：将自然语言转化为移动应用的利器",
    "tags": [
      "分类：LLM应用",
      "移动应用开发",
      ""
    ]
  },
  {
    "title": "Constrained Decoding for Secure Code Generation",
    "submit_datetime": "2024年04月30日",
    "abstract": "Code Large Language Models (Code LLMs) have been increasingly used by developers to boost productivity, but they often generate vulnerable code. Thus, there is an urgent need to ensure that code generated by Code LLMs is correct and secure. Previous research has primarily focused on generating secure code, overlooking the fact that secure code also needs to be correct. This oversight can lead to a false sense of security. Currently, the community lacks a method to measure actual progress in this area, and we need solutions that address both security and correctness of code generation.\n  This paper introduces a new benchmark, CodeGuard+, along with two new metrics, secure-pass@k and secure@$k_{\\text{pass}}$, to measure Code LLMs' ability to generate both secure and correct code. Using our new evaluation methods, we show that the state-of-the-art defense technique, prefix tuning, may not be as strong as previously believed, since it generates secure code but sacrifices functional correctness. We also demonstrate that different decoding methods significantly affect the security of Code LLMs.\n  Furthermore, we explore a new defense direction: constrained decoding for secure code generation. We propose new constrained decoding techniques to generate code that satisfies security and correctness constraints simultaneously. Our results reveal that constrained decoding is more effective than prefix tuning to improve the security of Code LLMs, without requiring a specialized training dataset. Moreover, constrained decoding can be used together with prefix tuning to further improve the security of Code LLMs.",
    "pdf_link": "https://arxiv.org/abs/2405.00218",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00218v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00218/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00218v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00218/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00218v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00218/x3.png"
      }
    ],
    "abstract_cn": "开发者日益青睐大型编程语言模型（Code LLMs）以提升工作效率，但这些模型产出的代码往往存在安全隐患。确保Code LLMs产出的代码既正确又安全，成为了一个迫切的议题。过往研究多聚焦于代码的安全性，却忽视了正确性同等重要，这种偏颇可能引发虚假的安全感。目前，业界还缺少一种评估标准来衡量这一领域的实际进步，亟需能够同时保障代码安全性与正确性的解决方案。本论文提出了一个新的基准测试CodeGuard+，以及两项新的评估指标：secure-pass@k和secure@$k_{\\text{pass}}$，用以衡量编程语言模型在生成既安全又准确的代码方面的能力。通过这些新的评估方法，我们发现，尽管目前领先的防御技术——前缀调整能够生成安全的代码，却在功能性正确性上有所妥协，其效力并非先前所认为的那样强大。我们还指出，不同的解码方法对Code LLMs的安全性有着显著的影响。此外，本文还探讨了一个新的防御策略：用于安全代码生成的约束解码。我们提出了新的约束解码技术，能够在不依赖特定训练数据集的情况下，同时满足安全性和正确性的要求。实验结果表明，约束解码在提升Code LLMs安全性方面比前缀调整更为有效。并且，约束解码可以与前缀调整结合使用，进一步提升Code LLMs的安全性。",
    "title_cn": "采用受限解码技术，致力于生成安全的代码。",
    "tags": [
      "LLM应用",
      "编程语言",
      "软件工程"
    ]
  },
  {
    "title": "General Purpose Verification for Chain of Thought Prompting",
    "submit_datetime": "2024年04月30日",
    "abstract": "Many of the recent capabilities demonstrated by Large Language Models (LLMs) arise primarily from their ability to exploit contextual information. In this paper, we explore ways to improve reasoning capabilities of LLMs through (1) exploration of different chains of thought and (2) validation of the individual steps of the reasoning process. We propose three general principles that a model should adhere to while reasoning: (i) Relevance, (ii) Mathematical Accuracy, and (iii) Logical Consistency. We apply these constraints to the reasoning steps generated by the LLM to improve the accuracy of the final generation. The constraints are applied in the form of verifiers: the model itself is asked to verify if the generated steps satisfy each constraint. To further steer the generations towards high-quality solutions, we use the perplexity of the reasoning steps as an additional verifier. We evaluate our method on 4 distinct types of reasoning tasks, spanning a total of 9 different datasets. Experiments show that our method is always better than vanilla generation, and, in 6 out of the 9 datasets, it is better than best-of N sampling which samples N reasoning chains and picks the lowest perplexity generation.",
    "pdf_link": "https://arxiv.org/abs/2405.00204",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/CoT_Fig1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/CoT_fig2_hr.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/GSM8k_sc.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/CSQA_sc.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/BigBenchDate_sc.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/GSM8k_sc_sp.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/CSQA_sc_sp.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/BigBenchDate_sc_sp.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/overall_correlation3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/BigBenchDate_sc.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/CSQA_sc.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/CSQA2.0_sc.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/Strategy_sc.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/Coinflip_sc.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/LastLetter2_sc.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/GSM8k_sc.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/SVAMP_sc.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/AddSub_sc.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/BigBenchDate_sc_src.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/CSQA_sc_src.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/CSQA2.0_sc_src.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/Strategy_sc_src.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/Coinflip_sc_src.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/LastLetter2_sc_src.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/GSM8k_sc_src.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/SVAMP_sc_src.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/AddSub_sc_src.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/GSM8k_sc_sa.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/CSQA_sc_sa.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/BigBenchDate_sc_sa.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/interannotator_agreement-relevance_score.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/interannotator_agreement-mathematical_accuracy_score.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/interannotator_agreement-logical_consistency_score.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/interannotator_agreement-everything_fine.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/correlation-everything_fine_aggregated_verifiers.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/correlation-everything_fine_aggregated_verifiers_and_ppl.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/correlation-logical_consistency.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/correlation-mathematical_accuracy.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/correlation-relevance.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00204v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00204/overall_correlation.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）近期展现的众多能力，很大程度上得益于其对上下文信息的高效利用。本文旨在探讨如何通过探索多样化的思维路径和对推理过程中的各个环节进行验证，来提升LLMs的推理能力。我们提出了三个推理时应遵循的原则：（一）相关性，（二）数学精确性，以及（三）逻辑连贯性。这些原则被转化为对LLM生成的推理步骤的约束，以提高最终结果的准确性。模型需自我验证生成的步骤是否符合这些约束。此外，我们还引入了推理步骤的困惑度作为额外的验证标准，以引导模型朝着更高质量的解决方案发展。我们的方法在四种不同类别的推理任务上进行了测试，涵盖了九个不同的数据集。实验结果表明，我们的方法在所有情况下均优于传统生成方法，在九个数据集中的六个上，其表现也超过了N最佳采样方法，后者通过采样N条推理链并选择困惑度最低的生成结果。",
    "title_cn": "针对思维链提示的通用验证方法",
    "tags": [
      "LLM应用",
      "人工智能",
      ""
    ]
  },
  {
    "title": "SPAFIT: Stratified Progressive Adaptation Fine-tuning for Pre-trained Large Language Models",
    "submit_datetime": "2024年04月30日",
    "abstract": "Full fine-tuning is a popular approach to adapt Transformer-based pre-trained large language models to a specific downstream task. However, the substantial requirements for computational power and storage have discouraged its widespread use. Moreover, increasing evidence of catastrophic forgetting and overparameterization in the Transformer architecture has motivated researchers to seek more efficient fine-tuning (PEFT) methods. Commonly known parameter-efficient fine-tuning methods like LoRA and BitFit are typically applied across all layers of the model. We propose a PEFT method, called Stratified Progressive Adaptation Fine-tuning (SPAFIT), based on the localization of different types of linguistic knowledge to specific layers of the model. Our experiments, conducted on nine tasks from the GLUE benchmark, show that our proposed SPAFIT method outperforms other PEFT methods while fine-tuning only a fraction of the parameters adjusted by other methods.",
    "pdf_link": "https://arxiv.org/abs/2405.00201",
    "graphs": [],
    "abstract_cn": "全参数微调是适配基于 Transformer 的预训练大型语言模型至特定下游任务的常用方法，但其对计算资源和存储空间的巨大需求限制了其普及。Transformer 架构中出现的灾难性遗忘和过参数化问题，促使研究者探索更高效的微调技术。诸如 LoRA 和 BitFit 等常见的参数高效微调技术一般会应用于模型的所有层次。我们提出了一种新的参数高效微调方法——分层渐进适应微调（SPAFIT），它根据语言知识的类型将其定位到模型的特定层次。在 GLUE 基准测试的九项任务中进行的实验显示，SPAFIT 方法在仅微调其他方法调整参数的一小部分的情况下，性能超越了其他参数高效微调方法。",
    "title_cn": "SPAFIT：为预训练的大型语言模型量身定制的分层渐进式微调策略",
    "tags": [
      "分类：LLM理论",
      "",
      "机器学习"
    ]
  },
  {
    "title": "In-Context Learning with Long-Context Models: An In-Depth Exploration",
    "submit_datetime": "2024年04月30日",
    "abstract": "As model context lengths continue to increase, the number of demonstrations that can be provided in-context approaches the size of entire training datasets. We study the behavior of in-context learning (ICL) at this extreme scale on multiple datasets and models. We show that, for many datasets with large label spaces, performance continues to increase with hundreds or thousands of demonstrations. We contrast this with example retrieval and finetuning: example retrieval shows excellent performance at low context lengths but has diminished gains with more demonstrations; finetuning is more data hungry than ICL but can sometimes exceed long-context ICL performance with additional data. We use this ICL setting as a testbed to study several properties of both in-context learning and long-context models. We show that long-context ICL is less sensitive to random input shuffling than short-context ICL, that grouping of same-label examples can negatively impact performance, and that the performance boosts we see do not arise from cumulative gain from encoding many examples together. We conclude that although long-context ICL can be surprisingly effective, most of this gain comes from attending back to similar examples rather than task learning.",
    "pdf_link": "https://arxiv.org/abs/2405.00200",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x20.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x21.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x22.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x23.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x24.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x25.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x26.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x27.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x28.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x29.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x30.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x31.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x32.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x33.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x34.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00200v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00200/x35.png"
      }
    ],
    "abstract_cn": "随着模型能够处理的上下文长度增加，能够在上下文中展示的示例数量逐渐逼近整个训练集的规模。我们在不同数据集和模型上探究了在这种极端规模下的上下文内学习（ICL）的表现。研究发现，在拥有广泛标签空间的众多数据集中，性能随着数百至数千个示例的增加而持续提升。这一现象与示例检索和微调的效果形成鲜明对比：示例检索在较短上下文长度时效果显著，但随着示例数量增加，其增益逐渐减少；而微调虽然对数据的需求超过ICL，但在引入更多数据后，有时能超越长上下文ICL的表现。我们利用ICL的这一设置，深入研究了上下文内学习和长上下文模型的多个特性。我们发现，长上下文ICL对随机输入顺序的干扰更为不敏感，同标签示例的集中可能对性能产生负面影响，而我们观察到的性能提升并非源自于同时编码多个示例的累积效应。综上所述，尽管长上下文ICL的效果出人意料地好，但其主要优势更多来自于对类似示例的回顾，而非对任务本身的学习。",
    "title_cn": "深入探索长文本上下文模型中的上下文内学习",
    "tags": [
      "LLM理论",
      "机器学习",
      "人工智能"
    ]
  },
  {
    "title": "Towards a Search Engine for Machines: Unified Ranking for Multiple Retrieval-Augmented Large Language Models",
    "submit_datetime": "2024年04月30日",
    "abstract": "This paper introduces uRAG--a framework with a unified retrieval engine that serves multiple downstream retrieval-augmented generation (RAG) systems. Each RAG system consumes the retrieval results for a unique purpose, such as open-domain question answering, fact verification, entity linking, and relation extraction. We introduce a generic training guideline that standardizes the communication between the search engine and the downstream RAG systems that engage in optimizing the retrieval model. This lays the groundwork for us to build a large-scale experimentation ecosystem consisting of 18 RAG systems that engage in training and 18 unknown RAG systems that use the uRAG as the new users of the search engine. Using this experimentation ecosystem, we answer a number of fundamental research questions that improve our understanding of promises and challenges in developing search engines for machines.",
    "pdf_link": "https://arxiv.org/abs/2405.00175",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00175v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00175/overview.drawio.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00175v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00175/overview-framework.drawio.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00175v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00175/performance_plot_amount_data.png"
      }
    ],
    "abstract_cn": "本文提出了 uRAG，这是一个集成了统一检索引擎的框架，能够支持多个下游的检索增强生成（RAG）系统。这些系统根据各自的需求，如开放域问答、事实核查、实体链接和关系抽取，来利用检索结果。我们引入了一套通用的训练指导原则，以规范搜索引擎与下游 RAG 系统之间的互动，这些系统都在致力于优化检索模型。这为构建一个包含 18 个参与训练的 RAG 系统和 18 个作为搜索引擎新用户的未知 RAG 系统的大规模实验生态系统奠定了基础。通过这个生态系统，我们探讨并回答了一系列基本的研究问题，从而深化了我们对机器搜索引擎开发中机遇与挑战的认识。",
    "title_cn": "探索机器的搜索引擎：实现多种增强检索的大型语言模型的统一排名机制",
    "tags": [
      "RAG",
      "信息检索",
      ""
    ]
  },
  {
    "title": "GUing: A Mobile GUI Search Engine using a Vision-Language Model",
    "submit_datetime": "2024年04月30日",
    "abstract": "App developers use the Graphical User Interface (GUI) of other apps as an important source of inspiration to design and improve their own apps. In recent years, research suggested various approaches to retrieve GUI designs that fit a certain text query from screenshot datasets acquired through automated GUI exploration. However, such text-to-GUI retrieval approaches only leverage the textual information of the GUI elements in the screenshots, neglecting visual information such as icons or background images. In addition, the retrieved screenshots are not steered by app developers and often lack important app features, e.g. whose UI pages require user authentication. To overcome these limitations, this paper proposes GUing, a GUI search engine based on a vision-language model called UIClip, which we trained specifically for the app GUI domain. For this, we first collected app introduction images from Google Play, which usually display the most representative screenshots selected and often captioned (i.e. labeled) by app vendors. Then, we developed an automated pipeline to classify, crop, and extract the captions from these images. This finally results in a large dataset which we share with this paper: including 303k app screenshots, out of which 135k have captions. We used this dataset to train a novel vision-language model, which is, to the best of our knowledge, the first of its kind in GUI retrieval. We evaluated our approach on various datasets from related work and in manual experiment. The results demonstrate that our model outperforms previous approaches in text-to-GUI retrieval achieving a Recall@10 of up to 0.69 and a HIT@10 of 0.91. We also explored the performance of UIClip for other GUI tasks including GUI classification and Sketch-to-GUI retrieval with encouraging results.",
    "pdf_link": "https://arxiv.org/abs/2405.00145",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00145v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00145/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00145v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00145/surrounded-img.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00145v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00145/screenshot-img.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00145v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00145/irrelevant-img.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00145v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00145/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00145v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00145/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00145v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00145/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00145v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00145/evaluation-tool.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00145v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00145/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00145v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00145/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00145v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00145/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00145v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00145/x8.png"
      }
    ],
    "abstract_cn": "应用开发者常以他人应用的图形用户界面（GUI）为灵感，来设计和优化自己的应用。近期研究提出了多种方法，从自动化获取的截图数据库中检索出与特定文本查询相匹配的GUI设计。但这些方法往往只关注GUI元素的文本信息，而忽略了图标、背景图等视觉信息。此外，检索出的截图往往缺乏关键应用特性，如用户认证所需的UI页面。为解决这些问题，本文介绍了GUing，这是一款基于专为应用GUI领域训练的视觉-语言模型UIClip的GUI搜索引擎。我们首先从Google Play获取了应用介绍图，这些图通常包含由开发者精选并标注的代表性截图。接着，我们建立了一个自动化流程，对这些图片进行分类、裁剪并提取标注。这一过程产生了一个包含303k应用截图的大型数据集，其中135k张附有标注，我们在此文中公开了这一数据集。利用该数据集，我们训练了一种新的视觉-语言模型，据我们所知，这是GUI检索领域的首创。我们在相关研究的数据集上进行了评估，并进行了手动实验，结果表明我们的模型在文本到GUI检索任务上超越了先前方法，Recall@10达到了0.69，HIT@10达到了0.91。此外，我们还探索了UIClip在GUI分类和草图到GUI检索等其他GUI任务上的表现，结果同样令人振奋。",
    "title_cn": "GUing：一款运用视觉-语言模型的移动界面图形搜索引擎。",
    "tags": [
      "分类：LLM应用\n\n这篇论文的摘要描述了一个基于视觉-语言模型的GUI搜索引擎，该模型专门针对应用GUI领域进行了训练。它从Google Play获取应用介绍图，并使用自动化流程对这些图片进行分类、裁剪并提取标注，从而创建了一个大型数据集。这个数据集被用来训练新的视觉-语言模型，该模型在文本到GUI检索任务上超越了先前的方法。这篇论文的重点是将大型语言模型（LLM）应用于GUI检索任务，因此它属于LLM应用类别。",
      "应用开发",
      "视觉搜索引擎"
    ]
  },
  {
    "title": "Creative Beam Search",
    "submit_datetime": "2024年04月30日",
    "abstract": "Large language models are revolutionizing several areas, including artificial creativity. However, the process of generation in machines profoundly diverges from that observed in humans. In particular, machine generation is characterized by a lack of intentionality and an underlying creative process. We propose a method called Creative Beam Search that uses Diverse Beam Search and LLM-as-a-Judge to perform response generation and response validation. The results of a qualitative experiment show how our approach can provide better output than standard sampling techniques. We also show that the response validation step is a necessary complement to the response generation step.",
    "pdf_link": "https://arxiv.org/abs/2405.00099",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.00099v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00099/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00099v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00099/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.00099v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.00099/x3.png"
      }
    ],
    "abstract_cn": "大型语言模型正引领着人工创造力等多个领域的革新浪潮。不过，机器的生成机制与人类的创造性过程大相径庭，尤其缺乏意图性和深层次的创造过程。我们引入了一种创新的“创意束搜索”方法，该方法结合了多样化束搜索和“语言模型评委”技术，用于执行生成和验证响应。一项定性实验的结果显示，相较于传统的采样技术，我们的策略能够产出更优质的结果。此外，我们还证实了响应验证环节对于响应生成环节的重要性，它是一个不可或缺的补充。",
    "title_cn": "创意束搜索",
    "tags": [
      "LLM应用",
      "人工智能",
      "创意生成"
    ]
  },
  {
    "title": "Large Language Model Agent for Fake News Detection",
    "submit_datetime": "2024年04月30日",
    "abstract": "In the current digital era, the rapid spread of misinformation on online platforms presents significant challenges to societal well-being, public trust, and democratic processes, influencing critical decision making and public opinion. To address these challenges, there is a growing need for automated fake news detection mechanisms. Pre-trained large language models (LLMs) have demonstrated exceptional capabilities across various natural language processing (NLP) tasks, prompting exploration into their potential for verifying news claims. Instead of employing LLMs in a non-agentic way, where LLMs generate responses based on direct prompts in a single shot, our work introduces FactAgent, an agentic approach of utilizing LLMs for fake news detection. FactAgent enables LLMs to emulate human expert behavior in verifying news claims without any model training, following a structured workflow. This workflow breaks down the complex task of news veracity checking into multiple sub-steps, where LLMs complete simple tasks using their internal knowledge or external tools. At the final step of the workflow, LLMs integrate all findings throughout the workflow to determine the news claim's veracity. Compared to manual human verification, FactAgent offers enhanced efficiency. Experimental studies demonstrate the effectiveness of FactAgent in verifying claims without the need for any training process. Moreover, FactAgent provides transparent explanations at each step of the workflow and during final decision-making, offering insights into the reasoning process of fake news detection for end users. FactAgent is highly adaptable, allowing for straightforward updates to its tools that LLMs can leverage within the workflow, as well as updates to the workflow itself using domain knowledge. This adaptability enables FactAgent's application to news verification across various domains.",
    "pdf_link": "https://arxiv.org/abs/2405.01593",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.01593v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01593/workflow2.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01593v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01593/instruction.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01593v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01593/expert_vs_self.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01593v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01593/tool_usage.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01593v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01593/Standing.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01593v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01593/search.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01593v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01593/majority_vote.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01593v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01593/case.png"
      }
    ],
    "abstract_cn": "在这个数字化飞速发展的时代，网络谣言的快速蔓延严重威胁着社会福祉、公众信任和民主进程，对关键决策和公众观点产生深远影响。为了应对这一挑战，自动假新闻检测技术的呼声愈发高涨。预训练的大型语言模型（LLMs）在自然语言处理（NLP）的多个领域展现出非凡的才能，这激发了人们探索其在新闻事实核查中的潜力。本文提出的FactAgent，是一种创新的代理式方法，它利用LLMs进行假新闻的识别。FactAgent模拟人类专家的核查行为，无需任何模型训练，通过一个有序的工作流程来验证新闻声明。该工作流程将复杂的新闻真实性检验分解为多个简单步骤，LLMs利用其内置知识或外部工具来完成这些任务。在工作流程的最终阶段，LLMs汇总整个过程中的所有信息，以判定新闻声明的真实性。相较于传统的人工核查，FactAgent在效率上有着显著提升。实验研究证明了FactAgent在无需训练的情况下进行声明验证的有效性。此外，FactAgent在工作流程的每一步以及最终决策阶段都提供了清晰的解释，为最终用户提供了假新闻检测推理过程的洞察。FactAgent的高适应性允许直接更新其工具，以及根据领域知识更新工作流程本身，使其能够灵活应用于不同领域的新闻核查。",
    "title_cn": "大型语言模型代理：假新闻侦测利器",
    "tags": [
      "Agent",
      "新闻媒体",
      ""
    ]
  },
  {
    "title": "ECC Analyzer: Extract Trading Signal from Earnings Conference Calls using Large Language Model for Stock Performance Prediction",
    "submit_datetime": "2024年04月29日",
    "abstract": "In the realm of financial analytics, leveraging unstructured data, such as earnings conference calls (ECCs), to forecast stock performance is a critical challenge that has attracted both academics and investors. While previous studies have used deep learning-based models to obtain a general view of ECCs, they often fail to capture detailed, complex information. Our study introduces a novel framework: \\textbf{ECC Analyzer}, combining Large Language Models (LLMs) and multi-modal techniques to extract richer, more predictive insights. The model begins by summarizing the transcript's structure and analyzing the speakers' mode and confidence level by detecting variations in tone and pitch for audio. This analysis helps investors form an overview perception of the ECCs. Moreover, this model uses the Retrieval-Augmented Generation (RAG) based methods to meticulously extract the focuses that have a significant impact on stock performance from an expert's perspective, providing a more targeted analysis. The model goes a step further by enriching these extracted focuses with additional layers of analysis, such as sentiment and audio segment features. By integrating these insights, the ECC Analyzer performs multi-task predictions of stock performance, including volatility, value-at-risk (VaR), and return for different intervals. The results show that our model outperforms traditional analytic benchmarks, confirming the effectiveness of using advanced LLM techniques in financial analytics.",
    "pdf_link": "https://arxiv.org/abs/2404.18470",
    "graphs": [],
    "abstract_cn": "在金融分析界，运用诸如收益电话会议（ECCs）这类非结构化数据来预测股票走势，是一个至关重要且充满挑战的任务，它不仅吸引了学术界的目光，也引起了投资者的广泛关注。尽管先前的研究已经借助基于深度学习的模型对ECCs进行了概览性分析，但这些研究往往忽略了更为细致和复杂的信息。本研究提出了一个创新的框架——\\textbf{ECC分析器}，它融合了大型语言模型（LLMs）和多模态技术，以提取更深层次、更具前瞻性的洞见。该模型首先通过分析音频中的音调和音高变化，来概括通话记录的结构，并评估发言者的态度和信心水平，帮助投资者构建对ECCs的宏观理解。此外，模型采用基于检索增强生成（RAG）的方法，细致地筛选出从专家视角看对股票表现有显著影响的关键点，进行更为精准的分析。模型不止步于此，它还通过情感分析和音频片段特征等更多层次的分析，进一步丰富了这些关键点。通过综合这些洞见，ECC分析器能够对股票表现进行多任务预测，包括波动性、风险价值（VaR）和不同时间间隔的回报。研究结果表明，我们的模型在性能上超越了传统分析方法，验证了在金融分析中应用高级LLM技术的有效性。",
    "title_cn": "ECC分析器：利用大型语言模型分析收益电话会议，从中提取交易信号，以预测股票市场表现。",
    "tags": [
      "LLM应用",
      "金融分析",
      "多模态技术"
    ]
  },
  {
    "title": "Reinforcement Learning Problem Solving with Large Language Models",
    "submit_datetime": "2024年04月29日",
    "abstract": "Large Language Models (LLMs) encapsulate an extensive amount of world knowledge, and this has enabled their application in various domains to improve the performance of a variety of Natural Language Processing (NLP) tasks. This has also facilitated a more accessible paradigm of conversation-based interactions between humans and AI systems to solve intended problems. However, one interesting avenue that shows untapped potential is the use of LLMs as Reinforcement Learning (RL) agents to enable conversational RL problem solving. Therefore, in this study, we explore the concept of formulating Markov Decision Process-based RL problems as LLM prompting tasks. We demonstrate how LLMs can be iteratively prompted to learn and optimize policies for specific RL tasks. In addition, we leverage the introduced prompting technique for episode simulation and Q-Learning, facilitated by LLMs. We then show the practicality of our approach through two detailed case studies for \"Research Scientist\" and \"Legal Matter Intake\" workflows.",
    "pdf_link": "https://arxiv.org/abs/2404.18638",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）汇聚了丰富的世界知识，广泛应用于提升自然语言处理（NLP）任务的效率，并简化了人与AI系统间的对话式交互，以解决特定问题。一个充满潜力但尚未充分挖掘的领域是将LLMs作为强化学习（RL）智能体，用于会话式的RL问题解决。在本研究中，我们探讨了将基于马尔可夫决策过程的RL问题转化为LLMs的提示任务。我们展示了如何逐步引导LLMs学习并优化特定RL任务的策略，并利用这种提示技术，通过LLMs实现了情节模拟和Q-Learning。我们通过“研究科学家”和“法律事项接收”两个案例研究，展示了我们方法的实用性和效果。",
    "title_cn": "通过大型语言模型来解决强化学习的问题",
    "tags": [
      "分类：Agent",
      "",
      ""
    ]
  },
  {
    "title": "Anywhere: A Multi-Agent Framework for Reliable and Diverse Foreground-Conditioned Image Inpainting",
    "submit_datetime": "2024年04月29日",
    "abstract": "Recent advancements in image inpainting, particularly through diffusion modeling, have yielded promising outcomes. However, when tested in scenarios involving the completion of images based on the foreground objects, current methods that aim to inpaint an image in an end-to-end manner encounter challenges such as \"over-imagination\", inconsistency between foreground and background, and limited diversity. In response, we introduce Anywhere, a pioneering multi-agent framework designed to address these issues. Anywhere utilizes a sophisticated pipeline framework comprising various agents such as Visual Language Model (VLM), Large Language Model (LLM), and image generation models. This framework consists of three principal components: the prompt generation module, the image generation module, and the outcome analyzer. The prompt generation module conducts a semantic analysis of the input foreground image, leveraging VLM to predict relevant language descriptions and LLM to recommend optimal language prompts. In the image generation module, we employ a text-guided canny-to-image generation model to create a template image based on the edge map of the foreground image and language prompts, and an image refiner to produce the outcome by blending the input foreground and the template image. The outcome analyzer employs VLM to evaluate image content rationality, aesthetic score, and foreground-background relevance, triggering prompt and image regeneration as needed. Extensive experiments demonstrate that our Anywhere framework excels in foreground-conditioned image inpainting, mitigating \"over-imagination\", resolving foreground-background discrepancies, and enhancing diversity. It successfully elevates foreground-conditioned image inpainting to produce more reliable and diverse results.",
    "pdf_link": "https://arxiv.org/abs/2404.18598",
    "graphs": [],
    "abstract_cn": "图像修复技术的最新进展，尤其是扩散模型的应用，已经带来了令人鼓舞的成果。但在基于前景对象完成图像的场景下，现有端到端图像修复方法面临诸多挑战，如过度想象、前景背景不一致和多样性不足。为此，我们推出了Anywhere，这是一个创新的多代理框架，专门设计来应对这些挑战。Anywhere采用了一个包含视觉语言模型（VLM）、大型语言模型（LLM）和图像生成模型的复杂流水线框架。该框架包括三个核心组件：提示生成模块、图像生成模块和结果分析器。提示生成模块通过VLM进行语义分析，预测相关语言描述，并利用LLM推荐最佳语言提示。图像生成模块使用文本引导的canny到图像生成模型，基于前景图像的边缘图和语言提示创建模板图像，并通过图像细化器融合输入前景和模板图像生成最终结果。结果分析器利用VLM评估图像内容的合理性、审美评分和前景背景的相关性，并在必要时触发提示和图像的重新生成。大量实验证明，Anywhere框架在前景条件图像修复任务上表现卓越，有效减少了过度想象，解决了前景背景不一致的问题，并提升了结果的多样性。它成功地推动了前景条件图像修复技术的发展，产生了更可靠和多样化的图像修复结果。",
    "title_cn": "Anywhere：一种多智能体框架，旨在实现可靠且多样化的前景条件图像修复",
    "tags": [
      "Agent",
      "图像处理",
      "人工智能"
    ]
  },
  {
    "title": "Injecting Salesperson's Dialogue Strategies in Large Language Models with Chain-of-Thought Reasoning",
    "submit_datetime": "2024年04月29日",
    "abstract": "Recent research in dialogue systems and corpora has focused on two main categories: task-oriented (TOD) and open-domain (chit-chat) dialogues. TOD systems help users accomplish specific tasks, while open-domain systems aim to create engaging conversations. However, in real-world scenarios, user intents are often revealed during interactions. A recent study introduced SalesBot, which simulates dialogues transitioning from chit-chat to task-oriented scenarios to train sales agents. Unfortunately, the initial data lacked smooth transitions and coherent long-turn dialogues, resulting in poor naturalness in sales-customer interactions. To address these issues, this paper presents SalesBot 2.0, an improved dataset. It leverages commonsense knowledge from large language models (LLMs) through strategic prompting. Additionally, we introduce a novel model called SalesAgent, trained on salesperson's interactions, using chain-of-thought (CoT) reasoning. This model excels in transitioning topics, understanding user intents, and selecting appropriate strategies. Experiments using diverse user simulations validate the effectiveness of our method in controlling dialogue strategies in LLMs. Furthermore, SalesBot 2.0 enhances coherence and reduces aggression, facilitating better model learning for sales-customer interactions.",
    "pdf_link": "https://arxiv.org/abs/2404.18564",
    "graphs": [],
    "abstract_cn": "近期对话系统研究主要分为两大类：任务导向型（TOD）和开放领域（如闲聊）对话。TOD系统致力于协助用户完成特定任务，而开放领域系统则更注重营造引人入胜的对话体验。但在现实情境中，用户的真实意图往往是在交流过程中逐步显现。最近的一项研究推出了SalesBot，这是一个模拟从闲聊向任务导向场景过渡的对话系统，用以培养销售人才。然而，初始数据集在过渡自然度和长对话连贯性方面存在不足，影响了销售与客户之间的互动流畅性。为改善这些问题，本文提出了升级版的SalesBot 2.0数据集，它通过精心设计的提示，借助大型语言模型（LLMs）中的常识知识。同时，我们还引入了一个创新模型——SalesAgent，该模型基于销售人员的互动数据，采用思维链（CoT）推理方法进行训练。SalesAgent在话题转换、用户意图理解以及策略选择上表现出色。通过多样化用户模拟的实验，我们验证了该方法在LLMs中控制对话策略的有效性。SalesBot 2.0不仅提升了对话的连贯性，还减少了冲突性，有助于提高销售与客户互动的模型学习效果。",
    "title_cn": "将销售员的对话策略融入大型语言模型，并运用思维链推理，这一方法对于增强模型处理复杂对话任务的能力至关重要。",
    "tags": [
      "Agent",
      "对话系统",
      ""
    ]
  },
  {
    "title": "AI-powered Code Review with LLMs: Early Results",
    "submit_datetime": "2024年04月29日",
    "abstract": "In this paper, we present a novel approach to improving software quality and efficiency through a Large Language Model (LLM)-based model designed to review code and identify potential issues. Our proposed LLM-based AI agent model is trained on large code repositories. This training includes code reviews, bug reports, and documentation of best practices. It aims to detect code smells, identify potential bugs, provide suggestions for improvement, and optimize the code. Unlike traditional static code analysis tools, our LLM-based AI agent has the ability to predict future potential risks in the code. This supports a dual goal of improving code quality and enhancing developer education by encouraging a deeper understanding of best practices and efficient coding techniques. Furthermore, we explore the model's effectiveness in suggesting improvements that significantly reduce post-release bugs and enhance code review processes, as evidenced by an analysis of developer sentiment toward LLM feedback. For future work, we aim to assess the accuracy and efficiency of LLM-generated documentation updates in comparison to manual methods. This will involve an empirical study focusing on manually conducted code reviews to identify code smells and bugs, alongside an evaluation of best practice documentation, augmented by insights from developer discussions and code reviews. Our goal is to not only refine the accuracy of our LLM-based tool but also to underscore its potential in streamlining the software development lifecycle through proactive code improvement and education.",
    "pdf_link": "https://arxiv.org/abs/2404.18496",
    "graphs": [],
    "abstract_cn": "本文介绍了一种创新方法，利用大型语言模型（LLM）为基础的人工智能（AI）代理来提升软件质量和效能。该AI代理经过在庞大代码库上的培训，涵盖代码审查、缺陷报告和最佳实践文档，旨在识别代码异味、潜在缺陷，提供优化建议，并对代码进行优化。与传统静态代码分析工具相比，我们的LLM-AI代理能够预见代码中的未来风险，旨在提升代码品质和增进开发者对最佳实践与高效编码技巧的理解。此外，本研究还探讨了该模型在减少发布后缺陷和提升代码审查流程方面的建议效果，这一点通过分析开发者对LLM反馈的情绪得到了证实。展望未来，我们计划评估LLM生成的文档更新的准确性和效率，并与手工方法进行比较。这包括一项实证研究，专注于手工代码审查以识别代码异味和缺陷，同时评估最佳实践文档，并结合开发者讨论和代码审查的洞见。我们的目标是提升LLM工具的准确性，并强调其在通过预防性代码改进和教育来优化软件开发生命周期中的潜力。",
    "title_cn": "AI 助力代码审查：大型语言模型的初步成效",
    "tags": [
      "Agent",
      "软件工程",
      "人工智能"
    ]
  },
  {
    "title": "Hallucination of Multimodal Large Language Models: A Survey",
    "submit_datetime": "2024年04月29日",
    "abstract": "This survey presents a comprehensive analysis of the phenomenon of hallucination in multimodal large language models (MLLMs), also known as Large Vision-Language Models (LVLMs), which have demonstrated significant advancements and remarkable abilities in multimodal tasks. Despite these promising developments, MLLMs often generate outputs that are inconsistent with the visual content, a challenge known as hallucination, which poses substantial obstacles to their practical deployment and raises concerns regarding their reliability in real-world applications. This problem has attracted increasing attention, prompting efforts to detect and mitigate such inaccuracies. We review recent advances in identifying, evaluating, and mitigating these hallucinations, offering a detailed overview of the underlying causes, evaluation benchmarks, metrics, and strategies developed to address this issue. Additionally, we analyze the current challenges and limitations, formulating open questions that delineate potential pathways for future research. By drawing the granular classification and landscapes of hallucination causes, evaluation benchmarks, and mitigation methods, this survey aims to deepen the understanding of hallucinations in MLLMs and inspire further advancements in the field. Through our thorough and in-depth review, we contribute to the ongoing dialogue on enhancing the robustness and reliability of MLLMs, providing valuable insights and resources for researchers and practitioners alike. Resources are available at: https://github.com/showlab/Awesome-MLLM-Hallucination.",
    "pdf_link": "https://arxiv.org/abs/2404.18930",
    "graphs": [],
    "abstract_cn": "本篇综述深入探讨了多模态大型语言模型（MLLMs），亦称为大型视觉-语言模型（LVLMs），在多模态任务中虽取得显著进步，却常产生与视觉信息不符的幻觉现象，这一问题严重阻碍了它们的实际应用，并引发了对其在现实世界中可靠性的质疑。对此问题的关注日益增加，研究者们正努力识别和减轻这些幻觉。本文综述了识别、评估和缓解幻觉的最新进展，详细分析了幻觉的成因、评估标准、度量指标以及应对策略。同时，我们剖析了当前面临的挑战与限制，提出了未来研究可能的研究方向。本研究旨在通过细致的分类和分析幻觉成因、评估基准和缓解方法，深化对 MLLMs 中幻觉现象的理解，并推动该领域的进一步发展。我们的深入分析为提升 MLLMs 的鲁棒性和可信度提供了丰富的洞见和资源，为研究人员和实践者提供了宝贵的参考。相关资源可在 https://github.com/showlab/Awesome-MLLM-Hallucination 查看。",
    "title_cn": "多模态大型语言模型幻觉现象研究综述",
    "tags": [
      "分类：LLM理论",
      "计算机视觉",
      ""
    ]
  },
  {
    "title": "MileBench: Benchmarking MLLMs in Long Context",
    "submit_datetime": "2024年04月29日",
    "abstract": "Despite the advancements and impressive performance of Multimodal Large Language Models (MLLMs) on benchmarks, their effectiveness in real-world, long-context, and multi-image tasks is unclear due to the benchmarks' limited scope. Existing benchmarks often focus on single-image and short-text samples, and when assessing multi-image tasks, they either limit the image count or focus on specific task (e.g time-series captioning), potentially obscuring the performance challenges of MLLMs. To address these limitations, we introduce MileBench, a pioneering benchmark designed to test the MultImodal Long-contExt capabilities of MLLMs. This benchmark comprises not only multimodal long contexts, but also multiple tasks requiring both comprehension and generation. We establish two distinct evaluation sets, diagnostic and realistic, to systematically assess MLLMs' long-context adaptation capacity and their ability to complete tasks in long-context scenarios. Our experimental results, obtained from testing 20 models, revealed that while the closed-source GPT-4(Vision) and Gemini 1.5 outperform others, most open-source MLLMs struggle in long-context situations. Interestingly, the performance gap tends to widen with an increase in the number of images. We strongly encourage an intensification of research efforts towards enhancing MLLMs' long-context capabilities, especially in scenarios involving multiple images.",
    "pdf_link": "https://arxiv.org/abs/2404.18532",
    "graphs": [],
    "abstract_cn": "尽管多模态大型语言模型（MLLMs）在标准测试中表现卓越，但其在现实世界中的长文本、多图像任务中的表现尚不明确，因为现有测试往往局限于单一图像和短文本。为了克服这一局限，我们推出了MileBench，这是一个创新的评估工具，专门用于检验MLLMs处理多模态长文本的能力。MileBench包含多模态长文本和多样化任务，旨在全面测试模型的理解与生成能力。我们设计了诊断性和现实性两套评估体系，以系统化地评价MLLMs对长文本的适应性和在长文本环境中的任务完成能力。通过对20种模型的测试，我们发现尽管闭源的GPT-4(Vision)和Gemini 1.5领先于其他模型，但大多数开源MLLMs在处理长文本时仍面临挑战。特别值得注意的是，图像数量的增加会导致性能差异更加显著。我们强烈建议学术界和工业界加大研究力度，以提升MLLMs在长文本处理上的能力，特别是在多图像环境中的应用。",
    "title_cn": "MileBench：长文本场景下的大型机器学习语言模型性能评估",
    "tags": [
      "LLM应用",
      "人工智能",
      "机器学习"
    ]
  },
  {
    "title": "From ChatGPT, DALL-E 3 to Sora: How has Generative AI Changed Digital Humanities Research and Services?",
    "submit_datetime": "2024年04月29日",
    "abstract": "Generative large-scale language models create the fifth paradigm of scientific research, organically combine data science and computational intelligence, transform the research paradigm of natural language processing and multimodal information processing, promote the new trend of AI-enabled social science research, and provide new ideas for digital humanities research and application. This article profoundly explores the application of large-scale language models in digital humanities research, revealing their significant potential in ancient book protection, intelligent processing, and academic innovation. The article first outlines the importance of ancient book resources and the necessity of digital preservation, followed by a detailed introduction to developing large-scale language models, such as ChatGPT, and their applications in document management, content understanding, and cross-cultural research. Through specific cases, the article demonstrates how AI can assist in the organization, classification, and content generation of ancient books. Then, it explores the prospects of AI applications in artistic innovation and cultural heritage preservation. Finally, the article explores the challenges and opportunities in the interaction of technology, information, and society in the digital humanities triggered by AI technologies.",
    "pdf_link": "https://arxiv.org/abs/2404.18518",
    "graphs": [],
    "abstract_cn": "大规模语言模型催生了科研的第五范式，它融合了数据科学与计算智能，革新了自然语言处理和多模态信息处理的研究范式，并为社会科学研究注入了AI的新动力，同时也为数字人文研究带来了创新思维。本文深入探讨了这些模型在数字人文领域的应用，突出了它们在古籍保护、智能化处理和学术创新上的重要作用。文章首先强调了古籍资源的价值及其数字化保存的紧迫性，接着深入介绍了如ChatGPT这样的大规模语言模型的开发及其在文档管理、内容理解和跨文化交流中的应用。通过实际案例，文章展示了AI如何在古籍的整理、分类和内容创作中发挥作用。文章还展望了AI在艺术创新和文化传承中的可能性，并最终探讨了AI技术在数字人文领域中引发的技术、信息与社会互动的挑战与机遇。",
    "title_cn": "ChatGPT、DALL-E 3 和 Sora 等生成性人工智能技术，已经如何重塑了数字人文学科的研究方向和服务模式？",
    "tags": [
      "LLM应用",
      "数字人文",
      "人工智能"
    ]
  },
  {
    "title": "DPO Meets PPO: Reinforced Token Optimization for RLHF",
    "submit_datetime": "2024年04月29日",
    "abstract": "In the classical Reinforcement Learning from Human Feedback (RLHF) framework, Proximal Policy Optimization (PPO) is employed to learn from sparse, sentence-level rewards -- a challenging scenario in traditional deep reinforcement learning. Despite the great successes of PPO in the alignment of state-of-the-art closed-source large language models (LLMs), its open-source implementation is still largely sub-optimal, as widely reported by numerous research studies. To address these issues, we introduce a framework that models RLHF problems as a Markov decision process (MDP), enabling the capture of fine-grained token-wise information. Furthermore, we provide theoretical insights that demonstrate the superiority of our MDP framework over the previous sentence-level bandit formulation. Under this framework, we introduce an algorithm, dubbed as Reinforced Token Optimization (\\texttt{RTO}), which learns the token-wise reward function from preference data and performs policy optimization based on this learned token-wise reward signal. Theoretically, \\texttt{RTO} is proven to have the capability of finding the near-optimal policy sample-efficiently. For its practical implementation, \\texttt{RTO} innovatively integrates Direct Preference Optimization (DPO) and PPO. DPO, originally derived from sparse sentence rewards, surprisingly provides us with a token-wise characterization of response quality, which is seamlessly incorporated into our subsequent PPO training stage. Extensive real-world alignment experiments verify the effectiveness of the proposed approach.",
    "pdf_link": "https://arxiv.org/abs/2404.18922",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.18922v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18922/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18922v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18922/x2.png"
      }
    ],
    "abstract_cn": "在传统的基于人类反馈的强化学习框架内，近端策略优化（PPO）面临从稀疏句子级奖励中学习的挑战。尽管PPO在调整顶尖闭源大型语言模型方面取得了显著成就，但其开源版本的表现往往不尽如人意，这一点已在多项研究中被指出。为克服这些难题，我们提出了一个新的框架，将RLHF问题视为马尔可夫决策过程，以捕捉更细致的标记级信息。我们还从理论上展示了该MDP框架相较于传统基于句子的强盗模型的优越性。在此框架基础上，我们开发了一种名为强化标记优化（RTO）的算法，该算法能够从偏好数据中学习标记级的奖励函数，并通过这些学习到的标记级奖励信号进行策略优化。理论上，RTO已被证实能够有效地找到近似最优策略。在实际应用中，RTO创新地融合了直接偏好优化（DPO）与PPO，DPO从稀疏句子奖励中提取出标记级的质量特征，并在我们的PPO训练阶段中得到有效利用。广泛的实际对齐实验证明了我们方法的有效性。",
    "title_cn": "DPO 邂逅 PPO：在强化学习框架下，为人类偏好的令牌优化注入动力",
    "tags": [
      "LLM应用",
      "",
      ""
    ]
  },
  {
    "title": "TheaterGen: Character Management with LLM for Consistent Multi-turn Image Generation",
    "submit_datetime": "2024年04月29日",
    "abstract": "Recent advances in diffusion models can generate high-quality and stunning images from text. However, multi-turn image generation, which is of high demand in real-world scenarios, still faces challenges in maintaining semantic consistency between images and texts, as well as contextual consistency of the same subject across multiple interactive turns. To address this issue, we introduce TheaterGen, a training-free framework that integrates large language models (LLMs) and text-to-image (T2I) models to provide the capability of multi-turn image generation. Within this framework, LLMs, acting as a \"Screenwriter\", engage in multi-turn interaction, generating and managing a standardized prompt book that encompasses prompts and layout designs for each character in the target image. Based on these, Theatergen generate a list of character images and extract guidance information, akin to the \"Rehearsal\". Subsequently, through incorporating the prompt book and guidance information into the reverse denoising process of T2I diffusion models, Theatergen generate the final image, as conducting the \"Final Performance\". With the effective management of prompt books and character images, TheaterGen significantly improves semantic and contextual consistency in synthesized images. Furthermore, we introduce a dedicated benchmark, CMIGBench (Consistent Multi-turn Image Generation Benchmark) with 8000 multi-turn instructions. Different from previous multi-turn benchmarks, CMIGBench does not define characters in advance. Both the tasks of story generation and multi-turn editing are included on CMIGBench for comprehensive evaluation. Extensive experimental results show that TheaterGen outperforms state-of-the-art methods significantly. It raises the performance bar of the cutting-edge Mini DALLE 3 model by 21% in average character-character similarity and 19% in average text-image similarity.",
    "pdf_link": "https://arxiv.org/abs/2404.18919",
    "graphs": [],
    "abstract_cn": "最新进展的扩散模型能够根据文本创作出高品质且引人注目的图像。但在现实世界中需求强烈的多轮次图像生成任务中，保持图像与文本之间的语义连贯性以及同一主题在连续交互中的上下文连贯性，仍然是一大挑战。为应对这一挑战，我们推出了TheaterGen——一个无需训练的框架，它结合了大型语言模型（LLMs）与文本到图像（T2I）模型，以实现多轮次图像生成。在这个框架中，LLMs充当“编剧”，进行多轮互动，创建并管理一个标准化的提示脚本，涵盖目标图像中每个角色的提示和布局设计。据此，TheaterGen生成一系列角色图像并提炼出指导信息，这类似于“彩排”阶段。紧接着，TheaterGen将提示脚本和指导信息整合到T2I扩散模型的逆向去噪流程中，生成最终图像，仿佛在进行“最终演出”。通过有效管理提示脚本和角色图像，TheaterGen显著提升了合成图像的语义和上下文连贯性。此外，我们还推出了一个专门的基准测试集CMIGBench（一致性多轮图像生成基准测试），包含8000条多轮指令。与以往的多轮次基准测试不同，CMIGBench不预设角色定义，而是全面包含了故事生成和多轮编辑任务，以进行综合评估。广泛的实验结果显示，TheaterGen显著超越了现有最先进方法，其在Mini DALLE 3模型上的平均角色-角色相似性提升了21%，在平均文本-图像相似性上提升了19%，树立了新的性能标杆。",
    "title_cn": "TheaterGen：运用大型语言模型精心管理角色，打造连贯的多轮次图像生成体验",
    "tags": [
      "LLM应用",
      "图像生成",
      ""
    ]
  },
  {
    "title": "Kangaroo: Lossless Self-Speculative Decoding via Double Early Exiting",
    "submit_datetime": "2024年04月29日",
    "abstract": "Speculative decoding has demonstrated its effectiveness in accelerating the inference of large language models while maintaining a consistent sampling distribution. However, the conventional approach of training a separate draft model to achieve a satisfactory token acceptance rate can be costly. Drawing inspiration from early exiting, we propose a novel self-speculative decoding framework \\emph{Kangaroo}, which uses a fixed shallow sub-network as a self-draft model, with the remaining layers serving as the larger target model. We train a lightweight and efficient adapter module on top of the sub-network to bridge the gap between the sub-network and the full model's representation ability. It is noteworthy that the inference latency of the self-draft model may no longer be negligible compared to the large model, necessitating strategies to increase the token acceptance rate while minimizing the drafting steps of the small model. To address this challenge, we introduce an additional early exiting mechanism for generating draft tokens. Specifically, we halt the small model's subsequent prediction during the drafting phase once the confidence level for the current token falls below a certain threshold. Extensive experiments on the Spec-Bench demonstrate the effectiveness of Kangaroo. Under single-sequence verification, Kangaroo achieves speedups up to $1.68\\times$ on Spec-Bench, outperforming Medusa-1 with 88.7\\% fewer additional parameters (67M compared to 591M). The code for Kangaroo is available at https://github.com/Equationliu/Kangaroo.",
    "pdf_link": "https://arxiv.org/abs/2404.18911",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.18911v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18911/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18911v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18911/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18911v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18911/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18911v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18911/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18911v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18911/x5.png"
      }
    ],
    "abstract_cn": "推测性解码技术通过维持稳定的采样分布，有效加速了大型语言模型的推理过程。然而，传统方法通过训练独立草稿模型以提高令牌接受率，成本较高。借鉴早期退出策略，我们提出了一种创新的自我推测解码框架——“袋鼠”。该框架采用固定浅层子网络作为自我草稿模型，而其他层则构成更大的目标模型。为了弥补子网络与完整模型在表示能力上的差异，我们在子网络之上训练了一个高效轻量的适配器模块。值得注意的是，自我草稿模型的推理延迟相较于大型模型已不容忽视，因此需要采取策略来提高令牌接受率，同时减少小型模型的起草步骤。为此，我们引入了一种新的早期退出机制，用于生成草稿令牌。具体来说，当当前令牌的置信度降至某一阈值以下时，我们会在起草阶段停止小型模型的后续预测。在 Spec-Bench 上的大量实验显示，袋鼠框架显著提升了效率，单序列验证下速度提升高达 1.68 倍，性能超越了 Medusa-1，且额外参数减少了 88.7%（6700 万对比 5910 万）。袋鼠框架的代码已在 GitHub 上开源，地址为 https://github.com/Equationliu/Kangaroo。",
    "title_cn": "袋鼠：一种无损自我推测解码技术，采用双重早期退出机制。",
    "tags": [
      "LLM应用",
      "",
      ""
    ]
  },
  {
    "title": "Human-in-the-Loop Synthetic Text Data Inspection with Provenance Tracking",
    "submit_datetime": "2024年04月29日",
    "abstract": "Data augmentation techniques apply transformations to existing texts to generate additional data. The transformations may produce low-quality texts, where the meaning of the text is changed and the text may even be mangled beyond human comprehension. Analyzing the synthetically generated texts and their corresponding labels is slow and demanding. To winnow out texts with incorrect labels, we develop INSPECTOR, a human-in-the-loop data inspection technique. INSPECTOR combines the strengths of provenance tracking techniques with assistive labeling. INSPECTOR allows users to group related texts by their transformation provenance, i.e., the transformations applied to the original text, or feature provenance, the linguistic features of the original text. For assistive labeling, INSPECTOR computes metrics that approximate data quality, and allows users to compare the corresponding label of each text against the predictions of a large language model. In a user study, INSPECTOR increases the number of texts with correct labels identified by 3X on a sentiment analysis task and by 4X on a hate speech detection task. The participants found grouping the synthetically generated texts by their common transformation to be the most useful technique. Surprisingly, grouping texts by common linguistic features was perceived to be unhelpful. Contrary to prior work, our study finds that no single technique obviates the need for human inspection effort. This validates the design of INSPECTOR which combines both analysis of data provenance and assistive labeling to reduce human inspection effort.",
    "pdf_link": "https://arxiv.org/abs/2404.18881",
    "graphs": [],
    "abstract_cn": "数据增强通过转换现有文本来扩充数据集，但可能导致文本质量下降，意义扭曲，甚至难以理解。为了高效筛选出标注错误的文本，我们设计了 INSPECTOR，一种结合了来源追踪和辅助标注的人工审核技术。INSPECTOR 使用户能够根据文本的转换来源或原始文本的语言特征，将相关文本进行归类。在辅助标注方面，INSPECTOR 计算数据质量指标，并允许用户将每条文本的标签与大型语言模型的预测相比较。用户研究发现，INSPECTOR 在情感分析和仇恨言论检测任务中，分别将正确标注的文本数量提升了三倍和四倍。参与者普遍认为，根据文本的共同转换特征进行归类最为有效，而按语言特征分组则效果不佳。与先前研究不同，我们的研究指出，没有单一技术可以完全取代人工审核的必要性，这证明了 INSPECTOR 的设计，它结合了数据来源分析和辅助标注，有效减轻了人工审核的工作量。",
    "title_cn": "人工参与的合成文本数据审查，配备有追踪溯源功能",
    "tags": [
      "分类：LLM应用",
      "数据科学",
      "人工智能"
    ]
  },
  {
    "title": "More RLHF, More Trust? On The Impact of Human Preference Alignment On Language Model Trustworthiness",
    "submit_datetime": "2024年04月29日",
    "abstract": "The surge in Large Language Models (LLMs) development has led to improved performance on cognitive tasks as well as an urgent need to align these models with human values in order to safely exploit their power. Despite the effectiveness of preference learning algorithms like Reinforcement Learning From Human Feedback (RLHF) in aligning human preferences, their assumed improvements on model trustworthiness haven't been thoroughly testified. Toward this end, this study investigates how models that have been aligned with general-purpose preference data on helpfulness and harmlessness perform across five trustworthiness verticals: toxicity, stereotypical bias, machine ethics, truthfulness, and privacy. For model alignment, we focus on three widely used RLHF variants: Supervised Finetuning (SFT), Proximal Policy Optimization (PPO), and Direct Preference Optimization (DPO). Through extensive empirical investigations, we discover that the improvement in trustworthiness by RLHF is far from guaranteed, and there exists a complex interplay between preference data, alignment algorithms, and specific trustworthiness aspects. Together, our results underscore the need for more nuanced approaches for model alignment. By shedding light on the intricate dynamics of these components within model alignment, we hope this research will guide the community towards developing language models that are both capable and trustworthy.",
    "pdf_link": "https://arxiv.org/abs/2404.18870",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.18870v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18870/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18870v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18870/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18870v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18870/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18870v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18870/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18870v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18870/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18870v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18870/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18870v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18870/x7.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）的迅猛发展不仅提升了认知任务的执行效率，也突显了将这些模型与人类价值观紧密结合的必要性，以确保其安全有效地发挥作用。尽管基于人类反馈的强化学习（RLHF）等偏好学习算法在匹配人类偏好方面显示出了显著效果，但它们对提升模型可信度的贡献尚未得到全面验证。本项研究旨在探究那些依据通用偏好数据进行有用性和无害性对齐的模型，在五个关键的可信度维度上的表现：毒性、刻板印象偏见、机器伦理、真实性和隐私。我们特别关注了三种流行的RLHF变体：监督微调（SFT）、近端策略优化（PPO）和直接偏好优化（DPO）。通过深入的实证研究，我们揭示了RLHF在提升模型可信度方面的成效并非一蹴而就，并且偏好数据、对齐算法以及特定可信度维度之间存在着复杂的相互作用。我们的发现强调了在模型对齐过程中采取更为精细方法的必要性。我们期望本研究能够揭示模型对齐中这些要素的复杂相互作用，从而引导业界开发出既高效又可信的语言模型。",
    "title_cn": "偏好更贴近人类，信任更深厚？探讨人类偏好对齐如何提升语言模型的可信性",
    "tags": [
      "LLM应用",
      "人工智能",
      "伦理学"
    ]
  },
  {
    "title": "Truth-value judgment in language models: belief directions are context sensitive",
    "submit_datetime": "2024年04月29日",
    "abstract": "Recent work has demonstrated that the latent spaces of large language models (LLMs) contain directions predictive of the truth of sentences. Multiple methods recover such directions and build probes that are described as getting at a model's \"knowledge\" or \"beliefs\". We investigate this phenomenon, looking closely at the impact of context on the probes. Our experiments establish where in the LLM the probe's predictions can be described as being conditional on the preceding (related) sentences. Specifically, we quantify the responsiveness of the probes to the presence of (negated) supporting and contradicting sentences, and score the probes on their consistency. We also perform a causal intervention experiment, investigating whether moving the representation of a premise along these belief directions influences the position of the hypothesis along that same direction. We find that the probes we test are generally context sensitive, but that contexts which should not affect the truth often still impact the probe outputs. Our experiments show that the type of errors depend on the layer, the (type of) model, and the kind of data. Finally, our results suggest that belief directions are (one of the) causal mediators in the inference process that incorporates in-context information.",
    "pdf_link": "https://arxiv.org/abs/2404.18865",
    "graphs": [],
    "abstract_cn": "最新研究揭示，大型语言模型（LLM）的潜在空间内蕴含着能预示句子真伪的趋势。多种技术成功复原出这些趋势，并打造出了能够触及模型“知识库”或“信仰体系”的探测工具。本研究深入探讨了这一现象，特别关注了上下文对这些探测工具的影响。实验结果明确了在LLM中，探测预测是如何以前文（相关）句子为条件的。我们具体衡量了探测工具对于存在（或否定）的支持性与反驳性句子的敏感度，并对其一致性进行了评分。此外，通过因果干预实验，我们探究了沿着信仰方向移动前提表示是否会改变假设在同一方向上的位置。研究发现，尽管测试的探测工具普遍对上下文有所反应，但本不应影响真实性的上下文却仍能影响探测结果。实验还指出，错误类型的产生与模型的层次、类型及数据种类息息相关。最终，研究结果暗示信念方向可能是推理过程中整合上下文信息的关键因果因素之一。",
    "title_cn": "在语言模型中进行真值判断时，信仰的方向会随着上下文的不同而变化。",
    "tags": [
      "LLM理论",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Performance-Aligned LLMs for Generating Fast Code",
    "submit_datetime": "2024年04月29日",
    "abstract": "Optimizing scientific software is a difficult task because codebases are often large and complex, and performance can depend upon several factors including the algorithm, its implementation, and hardware among others. Causes of poor performance can originate from disparate sources and be difficult to diagnose. Recent years have seen a multitude of work that use large language models (LLMs) to assist in software development tasks. However, these tools are trained to model the distribution of code as text, and are not specifically designed to understand performance aspects of code. In this work, we introduce a reinforcement learning based methodology to align the outputs of code LLMs with performance. This allows us to build upon the current code modeling capabilities of LLMs and extend them to generate better performing code. We demonstrate that our fine-tuned model improves the expected speedup of generated code over base models for a set of benchmark tasks from 0.9 to 1.6 for serial code and 1.9 to 4.5 for OpenMP code.",
    "pdf_link": "https://arxiv.org/abs/2404.18864",
    "graphs": [],
    "abstract_cn": "科学软件的优化工作颇为棘手，原因在于代码库往往庞大复杂，且性能受算法、实现方式、硬件等多种因素影响。性能问题可能源自不同因素，诊断起来颇具挑战。近年来，大量研究利用大型语言模型（LLMs）助力软件开发。但这些模型主要针对代码文本分布进行训练，并未专门针对代码性能进行优化。本研究提出了一种基于强化学习的策略，旨在提升代码LLMs输出的性能。通过此方法，我们不仅能够利用LLMs现有的代码建模能力，还能进一步优化，生成性能更优的代码。实验结果表明，我们微调后的模型在一系列基准测试中，将串行代码的预期加速比从0.9提升至1.6，OpenMP代码的加速比更是从1.9跃升至4.5。",
    "title_cn": "为了快速生成代码，我们对大型语言模型进行了性能优化，确保它们在编码任务中的表现与预期目标精准对齐。",
    "tags": [
      "分类：LLM应用\n\n这篇论文讨论了如何利用大型语言模型（LLMs）来优化科学软件的性能。虽然这些模型主要针对代码文本分布进行训练，但本研究提出了一种基于强化学习的策略，以提升代码LLMs输出的性能。这表明了LLMs在软件开发领域的应用，特别是在性能优化方面。因此，这篇论文应该被归类为LLM应用。",
      "软件工程",
      "性能优化"
    ]
  },
  {
    "title": "VERT: Verified Equivalent Rust Transpilation with Few-Shot Learning",
    "submit_datetime": "2024年04月29日",
    "abstract": "Rust is a programming language that combines memory safety and low-level control, providing C-like performance while guaranteeing the absence of undefined behaviors by default. Rust's growing popularity has prompted research on safe and correct transpiling of existing code-bases to Rust. Existing work falls into two categories: rule-based and large language model (LLM)-based. While rule-based approaches can theoretically produce correct transpilations that maintain input-output equivalence to the original, they often yield unreadable Rust code that uses unsafe subsets of the Rust language. On the other hand, while LLM-based approaches typically produce more readable, maintainable, and safe code, they do not provide any guarantees about correctness. In this work, we present VERT, a tool that can produce readable Rust transpilations with formal guarantees of correctness. VERT's only requirement is that there is Web Assembly compiler for the source language, which is true for most major languages. VERT first uses the Web Assembly compiler to obtain an oracle Rust program. In parallel, VERT uses an LLM to generate a readable candidate Rust program. This candidate is verified against the oracle, and if verification fails, we regenerate a new candidate transpilation until verification succeeds. We evaluate VERT by transpiling a suite of 1,394 programs taken from competitive programming style benchmarks. Combining Anthropic's Claude-2 and VERT increases Rust transpilations passing property-based testing from 31% to 54% and bounded model-checking from 1% to 42% compared to using Claude alone. In addition, we evaluate VERT's ability to generate non-trivial safe Rust on programs taken from real-world C projects that make significant use of pointers. Our results provide insights into the limitations of LLMs to write safe Rust.",
    "pdf_link": "https://arxiv.org/abs/2404.18852",
    "graphs": [],
    "abstract_cn": "Rust，作为一种融合了内存安全与底层控制的编程语言，以其类 C 语言的性能和默认避免未定义行为的特性而广受欢迎。随着 Rust 的流行，如何安全且准确地将现有代码转译为 Rust 成为研究热点。目前的研究主要分为基于规则的方法和基于大型语言模型（LLM）的方法两大类。基于规则的方法虽能理论上保证转译的正确性，但往往产出难以阅读的 Rust 代码；而基于 LLM 的方法虽能生成更易读和安全的代码，却无法确保其正确性。本研究提出了 VERT 工具，它能够生成既易读又具有形式正确性保证的 Rust 代码转译。VERT 的使用前提仅是源语言需有 Web Assembly 编译器，这在大多数主流语言中已得到满足。VERT 利用 Web Assembly 编译器生成一个基准 Rust 程序，并同时使用 LLM 生成可读的候选 Rust 程序，通过与基准程序的对比验证，不断迭代直至验证通过。我们通过转译 1,394 个来自编程竞赛风格的基准测试程序来评估 VERT 的性能。结合 Anthropic 的 Claude-2，VERT 显著提升了 Rust 转译的测试通过率，从基于属性的测试的 31% 提升至 54%，从有界模型检查的 1% 提升至 42%。此外，VERT 在生成实际 C 项目中大量使用指针的程序的安全 Rust 代码方面的能力也得到了验证。研究结果揭示了 LLM 在编写安全 Rust 代码方面的局限性。",
    "title_cn": "VERT：运用少量学习验证 Rust 语言的等价转译",
    "tags": [
      "LLM应用",
      "编程语言",
      "代码转译"
    ]
  },
  {
    "title": "It's Difficult to be Neutral -- Human and LLM-based Sentiment Annotation of Patient Comments",
    "submit_datetime": "2024年04月29日",
    "abstract": "Sentiment analysis is an important tool for aggregating patient voices, in order to provide targeted improvements in healthcare services. A prerequisite for this is the availability of in-domain data annotated for sentiment. This article documents an effort to add sentiment annotations to free-text comments in patient surveys collected by the Norwegian Institute of Public Health (NIPH). However, annotation can be a time-consuming and resource-intensive process, particularly when it requires domain expertise. We therefore also evaluate a possible alternative to human annotation, using large language models (LLMs) as annotators. We perform an extensive evaluation of the approach for two openly available pretrained LLMs for Norwegian, experimenting with different configurations of prompts and in-context learning, comparing their performance to human annotators. We find that even for zero-shot runs, models perform well above the baseline for binary sentiment, but still cannot compete with human annotators on the full dataset.",
    "pdf_link": "https://arxiv.org/abs/2404.18832",
    "graphs": [],
    "abstract_cn": "情感分析作为收集患者反馈、优化医疗服务的关键技术，依赖于领域内标注数据的丰富性。本文介绍了挪威公共卫生研究所（NIPH）在患者调查的开放式评论中加入情感标注的工作。鉴于人工标注既耗时又需专业知识，我们探索了使用大型语言模型（LLMs）作为自动标注工具的可能性。通过对比两种挪威语预训练LLMs在不同提示和上下文学习配置下的表现，我们对其进行了深入评估，并与人工标注的结果进行了比较。研究发现，即便在零样本的情况下，模型在二元情感分类上的表现也远超基准水平，但面对完整数据集，其性能仍未达到人工标注的水准。",
    "title_cn": "保持中立并非易事 —— 人类与基于大型语言模型的病患评论情感分析",
    "tags": [
      "LLM应用",
      "",
      ""
    ]
  },
  {
    "title": "Benchmarking Benchmark Leakage in Large Language Models",
    "submit_datetime": "2024年04月29日",
    "abstract": "Amid the expanding use of pre-training data, the phenomenon of benchmark dataset leakage has become increasingly prominent, exacerbated by opaque training processes and the often undisclosed inclusion of supervised data in contemporary Large Language Models (LLMs). This issue skews benchmark effectiveness and fosters potentially unfair comparisons, impeding the field's healthy development. To address this, we introduce a detection pipeline utilizing Perplexity and N-gram accuracy, two simple and scalable metrics that gauge a model's prediction precision on benchmark, to identify potential data leakages. By analyzing 31 LLMs under the context of mathematical reasoning, we reveal substantial instances of training even test set misuse, resulting in potentially unfair comparisons. These findings prompt us to offer several recommendations regarding model documentation, benchmark setup, and future evaluations. Notably, we propose the \"Benchmark Transparency Card\" to encourage clear documentation of benchmark utilization, promoting transparency and healthy developments of LLMs. we have made our leaderboard, pipeline implementation, and model predictions publicly available, fostering future research.",
    "pdf_link": "https://arxiv.org/abs/2404.18824",
    "graphs": [],
    "abstract_cn": "随着预训练数据的广泛应用，基准数据集泄露的问题日益凸显，尤其是在大型语言模型（LLMs）的训练过程中，监督数据的不透明使用加剧了这一现象。这不仅影响了基准测试的公正性，也可能导致不公平的比较，从而阻碍了语言模型领域的进步。为此，我们提出了一种基于困惑度和N-gram精确度的检测流程，用以评估模型在基准测试上的预测精度，并识别可能的数据泄露问题。通过对31个LLMs在数学推理任务中的分析，我们发现了大量的训练集甚至测试集的不当使用情况，这些问题可能导致不公平的比较结果。基于这些发现，我们提出了一系列建议，涉及模型文档编制、基准测试设置以及未来评估方法。特别地，我们建议引入“基准透明度卡”，以促进对基准测试使用情况的清晰记录，增强LLMs的透明度和健康发展。我们还公开了排行榜、检测流程的实现以及模型预测结果，以支持未来的研究工作。",
    "title_cn": "在大型语言模型中，对基准测试泄露问题进行评估",
    "tags": [
      "LLM理论",
      "",
      "基准测试"
    ]
  },
  {
    "title": "AppPoet: Large Language Model based Android malware detection via multi-view prompt engineering",
    "submit_datetime": "2024年04月29日",
    "abstract": "Due to the vast array of Android applications, their multifarious functions and intricate behavioral semantics, attackers can adopt various tactics to conceal their genuine attack intentions within legitimate functions. However, numerous feature engineering based methods suffer from a limitation in mining behavioral semantic information, thus impeding the accuracy and efficiency of Android malware detection. Besides, the majority of existing feature engineering based methods are weakly interpretive and fail to furnish researchers with effective and readable detection reports. Inspired by the success of the Large Language Models (LLMs) in natural language understanding, we propose AppPoet, a LLM-assisted multi-view system for Android malware detection. Firstly, AppPoet employs a static method to comprehensively collect application features and formulate various observation views. Subsequently, it steers the LLM to produce function descriptions and behavioral summaries for views via our meticulously devised multi-view prompt engineering technique to realize the deep mining of view semantics. Finally, we collaboratively fuse the multi-view information to efficiently and accurately detect malware through a deep neural network (DNN) classifier and then generate the heuristic diagnostic reports. Experimental results demonstrate that our method achieves a detection accuracy of 97.15% and an F1 score of 97.21%, which is superior to the baseline method Drebin and its variant. Furthermore, the case study evaluates the effectiveness of our generated diagnostic reports.",
    "pdf_link": "https://arxiv.org/abs/2404.18816",
    "graphs": [],
    "abstract_cn": "面对众多的 Android 应用及其功能多样、行为语义复杂，攻击者得以巧妙地将攻击意图隐藏在合法功能之中。基于特征工程的传统方法在挖掘深层行为语义上力有不逮，这限制了 Android 恶意软件检测的精确度与效率。此外，这些方法在解释性上也显得不足，难以为研究者提供清晰有效的检测报告。借鉴大型语言模型（LLMs）在自然语言处理上的成就，我们设计了 AppPoet，一个由 LLM 支持的多视角 Android 恶意软件检测系统。AppPoet 首先通过静态分析全面搜集应用特征，构建多维观察视图，然后利用我们独创的多视图提示技术，引导 LLM 生成视图的功能描述与行为摘要，深入挖掘视图背后的语义信息。最终，系统综合这些多维信息，通过深度神经网络（DNN）分类器高效而精确地识别恶意软件，并生成具有启发性的诊断报告。实验结果显示，我们的检测准确率达到了 97.15%，F1 分数为 97.21%，均优于行业标杆 Drebin 及其衍生方法。案例研究进一步验证了我们诊断报告生成的有效性。",
    "title_cn": "AppPoet：利用大型语言模型进行 Android 恶意软件检测，通过精心设计的多视角提示实现。",
    "tags": [
      "LLM应用",
      "网络安全",
      "软件工程"
    ]
  },
  {
    "title": "Efficiency-Effectiveness Tradeoff of Probabilistic Structured Queries for Cross-Language Information Retrieval",
    "submit_datetime": "2024年04月29日",
    "abstract": "Probabilistic Structured Queries (PSQ) is a cross-language information retrieval (CLIR) method that uses translation probabilities statistically derived from aligned corpora. PSQ is a strong baseline for efficient CLIR using sparse indexing. It is, therefore, useful as the first stage in a cascaded neural CLIR system whose second stage is more effective but too inefficient to be used on its own to search a large text collection. In this reproducibility study, we revisit PSQ by introducing an efficient Python implementation. Unconstrained use of all translation probabilities that can be estimated from aligned parallel text would in the limit assign a weight to every vocabulary term, precluding use of an inverted index to serve queries efficiently. Thus, PSQ's effectiveness and efficiency both depend on how translation probabilities are pruned. This paper presents experiments over a range of modern CLIR test collections to demonstrate that achieving Pareto optimal PSQ effectiveness-efficiency tradeoffs benefits from multi-criteria pruning, which has not been fully explored in prior work. Our Python PSQ implementation is available on GitHub(https://github.com/hltcoe/PSQ) and unpruned translation tables are available on Huggingface Models(https://huggingface.co/hltcoe/psq_translation_tables).",
    "pdf_link": "https://arxiv.org/abs/2404.18797",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.18797v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18797/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18797v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18797/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18797v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18797/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18797v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18797/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18797v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18797/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18797v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18797/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18797v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18797/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18797v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18797/x8.png"
      }
    ],
    "abstract_cn": "概率结构化查询（PSQ）作为一种跨语言信息检索（CLIR）技术，通过利用对齐语料库中统计得出的翻译概率，为高效的 CLIR 提供了坚实的基准。它特别适合作为级联神经 CLIR 系统的前置阶段，后者虽然检索效果更佳，但效率不足以独立处理大规模文本集合。本研究通过推出一个高效的 Python 版本，对 PSQ 进行了深入探讨。由于无限制地利用所有可从平行文本中估算的翻译概率，将导致为每个词汇项赋予权重，从而无法高效地使用倒排索引。因此，PSQ 的性能和效率均依赖于翻译概率的筛选方式。本文通过在多个现代 CLIR 测试集上的实验，展示了通过多标准筛选实现帕累托最优的 PSQ 性能与效率平衡，这一点在以往的研究中尚未得到充分探讨。我们的 Python PSQ 实现已在 GitHub 上发布（https://github.com/hltcoe/PSQ），同时未筛选的翻译表也可在 Huggingface Models 查找（https://huggingface.co/hltcoe/psq_translation_tables）。",
    "title_cn": "在跨语言信息检索领域，概率结构化查询的效率与效果之间存在一种权衡。",
    "tags": [
      "分类：Agent",
      "跨语言信息检索",
      "搜索引擎"
    ]
  },
  {
    "title": "Replacing Judges with Juries: Evaluating LLM Generations with a Panel of Diverse Models",
    "submit_datetime": "2024年04月29日",
    "abstract": "As Large Language Models (LLMs) have become more advanced, they have outpaced our abilities to accurately evaluate their quality. Not only is finding data to adequately probe particular model properties difficult, but evaluating the correctness of a model's freeform generation alone is a challenge. To address this, many evaluations now rely on using LLMs themselves as judges to score the quality of outputs from other LLMs. Evaluations most commonly use a single large model like GPT4. While this method has grown in popularity, it is costly, has been shown to introduce intramodel bias, and in this work, we find that very large models are often unnecessary. We propose instead to evaluate models using a Panel of LLm evaluators (PoLL). Across three distinct judge settings and spanning six different datasets, we find that using a PoLL composed of a larger number of smaller models outperforms a single large judge, exhibits less intra-model bias due to its composition of disjoint model families, and does so while being over seven times less expensive.",
    "pdf_link": "https://arxiv.org/abs/2404.18796",
    "graphs": [],
    "abstract_cn": "随着大型语言模型（LLMs）技术的飞速发展，我们对其质量的精准评估能力却未能跟上步伐。寻找合适的数据来充分探究模型特性变得日益艰难，而单独对模型的自由生成内容进行正确性评估同样充满挑战。为应对这一难题，当前许多评估方法开始借助LLMs自身的能力，来对其他LLMs的输出成果进行质量评定。这种评估方式通常依赖于单一的大型模型，如GPT4。尽管这种方法日益流行，但它不仅成本高昂，还可能带来模型内部偏见。在本项研究中，我们发现超大型模型往往并非必要。我们提出一种新的方法：利用一个由多个LLM评估员组成的评审团（PoLL）来执行模型评估。在三种不同的评审情境和六个不同的数据集上进行测试，我们发现采用由众多小型模型构成的PoLL评审团，不仅在性能上超越了单一大型模型评审，而且在成本上节省了超过七倍，同时因其由不同的模型家族组成，还减少了模型内部偏见。",
    "title_cn": "以多元模型小组评判，取代传统法官角色：深入评估大型语言模型的创作成果",
    "tags": [
      "LLM应用",
      "人工智能",
      ""
    ]
  },
  {
    "title": "PECC: Problem Extraction and Coding Challenges",
    "submit_datetime": "2024年04月29日",
    "abstract": "Recent advancements in large language models (LLMs) have showcased their exceptional abilities across various tasks, such as code generation, problem-solving and reasoning. Existing benchmarks evaluate tasks in isolation, yet the extent to which LLMs can understand prose-style tasks, identify the underlying problems, and then generate appropriate code solutions is still unexplored. Addressing this gap, we introduce PECC, a novel benchmark derived from Advent Of Code (AoC) challenges and Project Euler, including 2396 problems. Unlike conventional benchmarks, PECC requires LLMs to interpret narrative-embedded problems, extract requirements, and generate executable code. A key feature of our dataset is the complexity added by natural language prompting in chat-based evaluations, mirroring real-world instruction ambiguities. Results show varying model performance between narrative and neutral problems, with specific challenges in the Euler math-based subset with GPT-3.5-Turbo passing 50% of the AoC challenges and only 8% on the Euler problems. By probing the limits of LLMs' capabilities, our benchmark provides a framework to monitor and assess the subsequent progress of LLMs as a universal problem solver.",
    "pdf_link": "https://arxiv.org/abs/2404.18766",
    "graphs": [],
    "abstract_cn": "近期大型语言模型（LLMs）的突破性进展在多种任务上展现了其非凡才能，包括代码编写、解题和推理等。尽管现有评估标准独立考量各项任务，但LLMs在理解散文式任务、识别潜在问题并生成恰当代码解决方案方面的真正能力尚未得到充分探究。为填补这一空白，我们提出了PECC，这是一个创新的基准测试，源自“代码的降临”（AoC）挑战和“欧拉计划”（Project Euler），共包含2396个问题。与传统基准测试不同，PECC要求LLMs解读嵌入叙述中的问题，提炼关键需求，并产出可执行的代码。我们数据集的独特之处在于，它通过模拟现实世界指令的模糊性，在基于聊天的评估中引入了自然语言提示，增加了问题的复杂性。测试结果显示，模型在处理叙述性问题与中性问题时表现不一，在以数学为基础的欧拉子集问题上尤为突出，GPT-3.5-Turbo在AoC挑战中的通过率达到了50%，而在欧拉问题上仅为8%。PECC通过挑战LLMs的极限，为我们提供了一个监测和评估LLMs作为全能问题解决者进步的框架。",
    "title_cn": "PECC：问题抽取与编码的挑战",
    "tags": [
      "LLM应用",
      "",
      ""
    ]
  },
  {
    "title": "Transitive Vision-Language Prompt Learning for Domain Generalization",
    "submit_datetime": "2024年04月29日",
    "abstract": "The vision-language pre-training has enabled deep models to make a huge step forward in generalizing across unseen domains. The recent learning method based on the vision-language pre-training model is a great tool for domain generalization and can solve this problem to a large extent. However, there are still some issues that an advancement still suffers from trading-off between domain invariance and class separability, which are crucial in current DG problems. However, there are still some issues that an advancement still suffers from trading-off between domain invariance and class separability, which are crucial in current DG problems. In this paper, we introduce a novel prompt learning strategy that leverages deep vision prompts to address domain invariance while utilizing language prompts to ensure class separability, coupled with adaptive weighting mechanisms to balance domain invariance and class separability. Extensive experiments demonstrate that deep vision prompts effectively extract domain-invariant features, significantly improving the generalization ability of deep models and achieving state-of-the-art performance on three datasets.",
    "pdf_link": "https://arxiv.org/abs/2404.18758",
    "graphs": [],
    "abstract_cn": "视觉-语言预训练推动了深度模型在新领域泛化上的重大进展。新近的学习方法，基于这种预训练模型，为领域泛化提供了有效工具，显著提升了问题解决效率。尽管如此，领域不变性与类别可分性之间的平衡仍是技术进步面临的挑战，这对于当前的领域泛化（DG）问题尤为关键。本文提出了一种创新的提示学习策略，通过深度视觉提示强化领域不变性，语言提示保证类别可分性，并采用自适应权重机制来协调这两者。大量实验证明，这种深度视觉提示能够高效抽取领域不变特征，显著增强了深度模型的泛化性能，并在三个基准数据集上达到了最佳表现。",
    "title_cn": "在领域泛化领域，传递式的视觉-语言提示学习方法展现出了其独特的优势。",
    "tags": [
      "分类：RAG",
      "计算机视觉",
      ""
    ]
  },
  {
    "title": "Enhancing Interactive Image Retrieval With Query Rewriting Using Large Language Models and Vision Language Models",
    "submit_datetime": "2024年04月29日",
    "abstract": "Image search stands as a pivotal task in multimedia and computer vision, finding applications across diverse domains, ranging from internet search to medical diagnostics. Conventional image search systems operate by accepting textual or visual queries, retrieving the top-relevant candidate results from the database. However, prevalent methods often rely on single-turn procedures, introducing potential inaccuracies and limited recall. These methods also face the challenges, such as vocabulary mismatch and the semantic gap, constraining their overall effectiveness. To address these issues, we propose an interactive image retrieval system capable of refining queries based on user relevance feedback in a multi-turn setting. This system incorporates a vision language model (VLM) based image captioner to enhance the quality of text-based queries, resulting in more informative queries with each iteration. Moreover, we introduce a large language model (LLM) based denoiser to refine text-based query expansions, mitigating inaccuracies in image descriptions generated by captioning models. To evaluate our system, we curate a new dataset by adapting the MSR-VTT video retrieval dataset to the image retrieval task, offering multiple relevant ground truth images for each query. Through comprehensive experiments, we validate the effectiveness of our proposed system against baseline methods, achieving state-of-the-art performance with a notable 10\\% improvement in terms of recall. Our contributions encompass the development of an innovative interactive image retrieval system, the integration of an LLM-based denoiser, the curation of a meticulously designed evaluation dataset, and thorough experimental validation.",
    "pdf_link": "https://arxiv.org/abs/2404.18746",
    "graphs": [],
    "abstract_cn": "图像搜索在多媒体和计算机视觉领域扮演着核心角色，广泛应用于互联网搜索、医学诊断等多个领域。传统搜索系统通过文本或视觉查询来检索数据库中的最相关结果，但这些方法多采用单轮操作，存在准确性和召回率的局限。此外，它们还面临词汇不匹配和语义差异等挑战，影响了搜索效果。针对这些问题，我们设计了一种交互式图像检索系统，能在多轮对话中根据用户反馈优化查询。系统内置了视觉语言模型（VLM）驱动的图像描述生成器，提升了文本查询的质量和信息量。同时，引入了基于大型语言模型（LLM）的去噪器，以提高文本查询扩展的准确性，减少图像描述中的误差。为了测试系统性能，我们根据MSR-VTT视频检索数据集构建了新的图像检索数据集，每个查询对应多个相关的真实图像。经过一系列实验，我们的系统在召回率上比基线方法提高了10%，达到了业界领先水平。我们的贡献包括创新的交互式图像检索系统的开发、LLM去噪器的集成、精心设计的评价数据集的构建，以及全面的实验验证。",
    "title_cn": "借助大型语言模型和视觉语言模型，通过查询重写技术，我们能够提升交互式图像检索的效能。",
    "tags": [
      "LLM应用",
      "多媒体",
      "计算机视觉"
    ]
  },
  {
    "title": "LLMClean: Context-Aware Tabular Data Cleaning via LLM-Generated OFDs",
    "submit_datetime": "2024年04月29日",
    "abstract": "Machine learning's influence is expanding rapidly, now integral to decision-making processes from corporate strategy to the advancements in Industry 4.0. The efficacy of Artificial Intelligence broadly hinges on the caliber of data used during its training phase; optimal performance is tied to exceptional data quality. Data cleaning tools, particularly those that exploit functional dependencies within ontological frameworks or context models, are instrumental in augmenting data quality. Nevertheless, crafting these context models is a demanding task, both in terms of resources and expertise, often necessitating specialized knowledge from domain experts.\n  In light of these challenges, this paper introduces an innovative approach, called LLMClean, for the automated generation of context models, utilizing Large Language Models to analyze and understand various datasets. LLMClean encompasses a sequence of actions, starting with categorizing the dataset, extracting or mapping relevant models, and ultimately synthesizing the context model. To demonstrate its potential, we have developed and tested a prototype that applies our approach to three distinct datasets from the Internet of Things, healthcare, and Industry 4.0 sectors. The results of our evaluation indicate that our automated approach can achieve data cleaning efficacy comparable with that of context models crafted by human experts.",
    "pdf_link": "https://arxiv.org/abs/2404.18681",
    "graphs": [],
    "abstract_cn": "机器学习正迅速成为企业决策和工业4.0发展的核心。AI的效能依赖于训练阶段使用的数据质量，而数据清洗工具，尤其是那些能够挖掘本体框架或上下文模型中功能依赖的工具，对于提升数据质量至关重要。尽管如此，构建这些上下文模型是一项既耗费资源又考验专业技能的任务，通常需要依赖领域专家的深入知识。面对这些挑战，本论文提出了一种名为LLMClean的创新自动生成上下文模型的方法，该方法利用大型语言模型来分析和理解不同的数据集。LLMClean通过一系列步骤，包括对数据集进行分类、提取或映射相关模型，最终生成上下文模型。为了证明其有效性，我们开发并测试了一个原型，将其应用于物联网、医疗保健和工业4.0领域的三个不同数据集。评估结果显示，我们的自动化方法在数据清洗效果上可与人类专家创建的上下文模型相媲美。",
    "title_cn": "LLMClean：一种利用大型语言模型（LLM）生成的OFD（开放性功能需求）进行上下文感知的表格数据清洗方法。",
    "tags": [
      "LLM应用",
      "企业决策",
      "工业4.0"
    ]
  },
  {
    "title": "Assessing Cybersecurity Vulnerabilities in Code Large Language Models",
    "submit_datetime": "2024年04月29日",
    "abstract": "Instruction-tuned Code Large Language Models (Code LLMs) are increasingly utilized as AI coding assistants and integrated into various applications. However, the cybersecurity vulnerabilities and implications arising from the widespread integration of these models are not yet fully understood due to limited research in this domain. To bridge this gap, this paper presents EvilInstructCoder, a framework specifically designed to assess the cybersecurity vulnerabilities of instruction-tuned Code LLMs to adversarial attacks. EvilInstructCoder introduces the Adversarial Code Injection Engine to automatically generate malicious code snippets and inject them into benign code to poison instruction tuning datasets. It incorporates practical threat models to reflect real-world adversaries with varying capabilities and evaluates the exploitability of instruction-tuned Code LLMs under these diverse adversarial attack scenarios. Through the use of EvilInstructCoder, we conduct a comprehensive investigation into the exploitability of instruction tuning for coding tasks using three state-of-the-art Code LLM models: CodeLlama, DeepSeek-Coder, and StarCoder2, under various adversarial attack scenarios. Our experimental results reveal a significant vulnerability in these models, demonstrating that adversaries can manipulate the models to generate malicious payloads within benign code contexts in response to natural language instructions. For instance, under the backdoor attack setting, by poisoning only 81 samples (0.5\\% of the entire instruction dataset), we achieve Attack Success Rate at 1 (ASR@1) scores ranging from 76\\% to 86\\% for different model families. Our study sheds light on the critical cybersecurity vulnerabilities posed by instruction-tuned Code LLMs and emphasizes the urgent necessity for robust defense mechanisms to mitigate the identified vulnerabilities.",
    "pdf_link": "https://arxiv.org/abs/2404.18567",
    "graphs": [],
    "abstract_cn": "随着AI编程助手的广泛应用，指令调整的代码大型语言模型（Code LLMs）正逐渐成为开发领域的新宠。但这些模型的网络安全风险尚未充分揭示，主要原因在于相关领域的研究尚不深入。为填补这一研究空白，本文介绍了EvilInstructCoder框架，旨在专门评估这些模型在面对敌意攻击时的网络安全脆弱性。该框架通过引入对抗性代码注入引擎，自动化生成并注入恶意代码片段，以此污染指令调整的数据集。它还模拟了多种现实世界的威胁模式，以评估Code LLMs在不同对抗性攻击情境下的脆弱性。通过EvilInstructCoder，我们对三款顶尖的Code LLM模型——CodeLlama、DeepSeek-Coder和StarCoder2——在多样的敌意攻击情境下的安全性进行了深入分析。研究发现，这些模型存在显著的安全漏洞，攻击者可以轻易诱导模型在良性代码中嵌入恶意负载。特别是在后门攻击情境中，仅需污染0.5%的指令数据集样本，就能使攻击成功率达到76%至86%。本研究不仅揭示了指令调整的Code LLMs所面临的严峻网络安全挑战，也强调了开发强大防御机制以应对这些风险的紧迫性。",
    "title_cn": "探究大型语言模型代码中的网络安全薄弱环节",
    "tags": [
      "LLM应用",
      "网络安全",
      "软件开发"
    ]
  },
  {
    "title": "LangBiTe: A Platform for Testing Bias in Large Language Models",
    "submit_datetime": "2024年04月29日",
    "abstract": "The integration of Large Language Models (LLMs) into various software applications raises concerns about their potential biases. Typically, those models are trained on a vast amount of data scrapped from forums, websites, social media and other internet sources, which may instill harmful and discriminating behavior into the model. To address this issue, we present LangBiTe, a testing platform to systematically assess the presence of biases within an LLM. LangBiTe enables development teams to tailor their test scenarios, and automatically generate and execute the test cases according to a set of user-defined ethical requirements. Each test consists of a prompt fed into the LLM and a corresponding test oracle that scrutinizes the LLM's response for the identification of biases. LangBite provides users with the bias evaluation of LLMs, and end-to-end traceability between the initial ethical requirements and the insights obtained.",
    "pdf_link": "https://arxiv.org/abs/2404.18558",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）的广泛应用可能带来偏见问题，因为它们通常基于网络论坛、网站、社交媒体等来源的海量数据进行训练，这些数据可能包含有害或歧视性内容。为此，我们引入了LangBiTe，这是一个系统化的测试平台，旨在检测LLM中的偏见。该平台允许开发团队根据自定义的道德标准，设计测试场景并自动生成及执行测试案例。每项测试都包括向LLM输入的提示和一个测试预言机，后者将分析LLM的回应，以识别潜在的偏见。LangBiTe不仅为用户评估LLM的偏见情况，还提供了从初始道德要求到最终洞察的完整追溯链。",
    "title_cn": "LangBiTe：大型语言模型偏见检测的实验平台",
    "tags": [
      "分类：LLM应用",
      "人工智能",
      "道德与偏见检测"
    ]
  },
  {
    "title": "Can GPT-4 do L2 analytic assessment?",
    "submit_datetime": "2024年04月29日",
    "abstract": "Automated essay scoring (AES) to evaluate second language (L2) proficiency has been a firmly established technology used in educational contexts for decades. Although holistic scoring has seen advancements in AES that match or even exceed human performance, analytic scoring still encounters issues as it inherits flaws and shortcomings from the human scoring process. The recent introduction of large language models presents new opportunities for automating the evaluation of specific aspects of L2 writing proficiency. In this paper, we perform a series of experiments using GPT-4 in a zero-shot fashion on a publicly available dataset annotated with holistic scores based on the Common European Framework of Reference and aim to extract detailed information about their underlying analytic components. We observe significant correlations between the automatically predicted analytic scores and multiple features associated with the individual proficiency components.",
    "pdf_link": "https://arxiv.org/abs/2404.18557",
    "graphs": [],
    "abstract_cn": "自动作文评分（AES）评估第二语言（L2）能力，已在教育领域应用多年。尽管整体评分技术在 AES 中取得了与人类评分相媲美甚至超越的进步，但分析性评分因承袭了人为评分的缺陷而仍面临挑战。大型语言模型的新兴为 L2 写作技能的自动化评估带来了新的机遇。本文通过 GPT-4 在一个标注了基于欧洲共同参考框架整体分数的公开数据集上进行了零样本实验，旨在深入挖掘其分析评分的潜在构成要素。研究发现，自动预测的分析评分与各个能力要素相关的多种特征之间呈现出显著的正相关性。",
    "title_cn": "GPT-4 是否能够胜任 L2 级别的分析性评估？",
    "tags": [
      "LLM应用",
      "",
      "自动评分系统"
    ]
  },
  {
    "title": "ir_explain: a Python Library of Explainable IR Methods",
    "submit_datetime": "2024年04月29日",
    "abstract": "While recent advancements in Neural Ranking Models have resulted in significant improvements over traditional statistical retrieval models, it is generally acknowledged that the use of large neural architectures and the application of complex language models in Information Retrieval (IR) have reduced the transparency of retrieval methods. Consequently, Explainability and Interpretability have emerged as important research topics in IR. Several axiomatic and post-hoc explanation methods, as well as approaches that attempt to be interpretable-by-design, have been proposed. This article presents \\irexplain, an open-source Python library that implements a variety of well-known techniques for Explainable IR (ExIR) within a common, extensible framework. \\irexplain supports the three standard categories of post-hoc explanations, namely pointwise, pairwise, and listwise explanations. The library is designed to make it easy to reproduce state-of-the-art ExIR baselines on standard test collections, as well as to explore new approaches to explaining IR models and methods. To facilitate adoption, \\irexplain is well-integrated with widely-used toolkits such as Pyserini and \\irdatasets.",
    "pdf_link": "https://arxiv.org/abs/2404.18546",
    "graphs": [],
    "abstract_cn": "最新的神经排序模型在性能上取得了显著提升，超越了传统统计检索模型。然而，这也使得信息检索（IR）中的大型神经架构和复杂语言模型的应用变得不那么透明。因此，可解释性和可解释性成为了IR研究中的热点。本文介绍了\\irexplain，一个开源的Python库，它为可解释的IR（ExIR）提供了一个统一且可扩展的框架，涵盖了点对点、成对和列表三种标准的事后解释方法。该库旨在简化在标准测试集上复现顶级ExIR基线的过程，并鼓励探索新的IR模型和方法的解释方式。为了促进其应用，\\irexplain与流行的工具如Pyserini和\\irdatasets实现了良好的集成。",
    "title_cn": "ir_explain：一款用于信息检索的可解释性方法的 Python 库",
    "tags": [
      "LLM应用",
      "信息检索",
      "可解释性"
    ]
  },
  {
    "title": "Time Machine GPT",
    "submit_datetime": "2024年04月29日",
    "abstract": "Large language models (LLMs) are often trained on extensive, temporally indiscriminate text corpora, reflecting the lack of datasets with temporal metadata. This approach is not aligned with the evolving nature of language. Conventional methods for creating temporally adapted language models often depend on further pre-training static models on time-specific data. This paper presents a new approach: a series of point-in-time LLMs called Time Machine GPT (TiMaGPT), specifically designed to be nonprognosticative. This ensures they remain uninformed about future factual information and linguistic changes. This strategy is beneficial for understanding language evolution and is of critical importance when applying models in dynamic contexts, such as time-series forecasting, where foresight of future information can prove problematic. We provide access to both the models and training datasets.",
    "pdf_link": "https://arxiv.org/abs/2404.18543",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）多在内容广泛且忽略时间顺序的文本集合上进行训练，这种做法并未跟上语言演进的步伐。传统上，为了构建能够适应时间变化的语言模型，往往需要在特定时间段的数据上对静态模型进行额外的预训练。本文介绍了一种创新的方法：一系列在特定时间点的非预测性大型语言模型，称为时间机器 GPT（TiMaGPT）。这些模型被特别设计，以确保它们不会知晓任何关于未来的事实性信息和语言变迁。这一策略不仅有助于深入理解语言的演进，而且在动态情境下应用模型时至关重要，例如在时间序列预测中，对将来信息的预知可能会带来问题。我们为这些模型及其训练数据集提供了访问权限。",
    "title_cn": "时光机器 GPT",
    "tags": [
      "分类：LLM理论",
      "时间序列预测",
      ""
    ]
  },
  {
    "title": "OAEI Machine Learning Dataset for Online Model Generation",
    "submit_datetime": "2024年04月29日",
    "abstract": "Ontology and knowledge graph matching systems are evaluated annually by the Ontology Alignment Evaluation Initiative (OAEI). More and more systems use machine learning-based approaches, including large language models. The training and validation datasets are usually determined by the system developer and often a subset of the reference alignments are used. This sampling is against the OAEI rules and makes a fair comparison impossible. Furthermore, those models are trained offline (a trained and optimized model is packaged into the matcher) and therefore the systems are specifically trained for those tasks. In this paper, we introduce a dataset that contains training, validation, and test sets for most of the OAEI tracks. Thus, online model learning (the systems must adapt to the given input alignment without human intervention) is made possible to enable a fair comparison for ML-based systems. We showcase the usefulness of the dataset by fine-tuning the confidence thresholds of popular systems.",
    "pdf_link": "https://arxiv.org/abs/2404.18542",
    "graphs": [],
    "abstract_cn": "每年，本体对齐评估计划（OAEI）对本体和知识图谱匹配系统进行评估。随着基于机器学习的方法，尤其是大型语言模型的广泛应用，系统开发者通常会根据参考对齐的子集来确定训练和验证数据集，这违反了OAEI的规定，导致无法进行公正的比较。此外，这些模型采用离线训练方式，即训练好的模型被封装进匹配器中，专为特定任务定制。本文提出了一个新的数据集，涵盖了OAEI大多数赛道的训练集、验证集和测试集，从而使得在线模型学习（系统需在无人干预的情况下自动适应输入对齐）成为可能，为基于机器学习（ML）的系统提供了一个公平的比较平台。我们还通过微调流行系统的信任阈值，展示了该数据集的实用价值。",
    "title_cn": "OAEI 为在线模型生成提供了一个机器学习数据集。",
    "tags": [
      "分类：Agent",
      "本体对齐",
      "机器学习"
    ]
  },
  {
    "title": "Evaluating and Mitigating Linguistic Discrimination in Large Language Models",
    "submit_datetime": "2024年04月29日",
    "abstract": "By training on text in various languages, large language models (LLMs) typically possess multilingual support and demonstrate remarkable capabilities in solving tasks described in different languages. However, LLMs can exhibit linguistic discrimination due to the uneven distribution of training data across languages. That is, LLMs are hard to keep the consistency of responses when faced with the same task but depicted in different languages.\n  In this study, we first explore the consistency in the LLMs' outputs responding to queries in various languages from two aspects: safety and quality. We conduct this analysis with two datasets (AdvBench and NQ) based on four LLMs (Llama2-13b, Gemma-7b, GPT-3.5-turbo and Gemini-pro). The results show that LLMs exhibit stronger human alignment capabilities with queries in English, French, Russian, and Spanish (only 1.04\\% of harmful queries successfully jailbreak on average) compared to queries in Bengali, Georgian, Nepali and Maithili (27.7\\% of harmful queries jailbreak successfully on average). Moreover, for queries in English, Danish, Czech and Slovenian, LLMs tend to produce responses with a higher quality (with 0.1494 $F_1$ score on average) compared to the other languages. Upon these findings, we propose LDFighter, a similarity-based voting, to mitigate the linguistic discrimination in LLMs. LDFighter ensures consistent service for different language speakers. We evaluate LDFighter with both benign queries and harmful queries. The results show that LDFighter not only significantly reduces the jailbreak success rate but also improve the response quality on average, demonstrating its effectiveness.",
    "pdf_link": "https://arxiv.org/abs/2404.18534",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）通过在多种语言的文本上进行训练，通常具备多语言能力，并在解决不同语言描述的任务上表现出色。但它们也可能因为训练数据在语言间的不平衡而产生语言偏见，难以对相同任务的不同语言描述保持一致的响应。在本研究中，我们从安全性和质量两个维度，首次深入探讨了 LLMs 对不同语言查询的输出一致性。通过分析两个数据集（AdvBench 和 NQ）以及四种主流 LLMs（Llama2-13b、Gemma-7b、GPT-3.5-turbo 和 Gemini-pro）的表现，我们发现在英语、法语、俄语和西班牙语的查询中，LLMs 的人类对齐能力更强，有害查询的成功越狱率平均仅为 1.04%，而在孟加拉语、格鲁吉亚语、尼泊尔语和迈蒂利语中，这一比率平均高达 27.7%。此外，对于英语、丹麦语、捷克语和斯洛文尼亚语的查询，LLMs 产出的响应质量也更高，平均 $F_1$ 分数达到 0.1494。基于这些发现，我们设计了 LDFighter，一种基于相似性投票的方法，以减少 LLMs 的语言歧视，确保为不同语言的用户提供一致的服务体验。通过在良性和有害查询上的测试，LDFighter 显著降低了越狱成功率，并提升了平均响应质量，证实了其有效性。",
    "title_cn": "本文旨在探讨并缓解大型语言模型中存在的语言学歧视问题。",
    "tags": [
      "LLM应用",
      "",
      "机器学习"
    ]
  },
  {
    "title": "Evaluating Readability and Faithfulness of Concept-based Explanations",
    "submit_datetime": "2024年04月29日",
    "abstract": "Despite the surprisingly high intelligence exhibited by Large Language Models (LLMs), we are somehow intimidated to fully deploy them into real-life applications considering their black-box nature. Concept-based explanations arise as a promising avenue for explaining what the LLMs have learned, making them more transparent to humans. However, current evaluations for concepts tend to be heuristic and non-deterministic, e.g. case study or human evaluation, hindering the development of the field. To bridge the gap, we approach concept-based explanation evaluation via faithfulness and readability. We first introduce a formal definition of concept generalizable to diverse concept-based explanations. Based on this, we quantify faithfulness via the difference in the output upon perturbation. We then provide an automatic measure for readability, by measuring the coherence of patterns that maximally activate a concept. This measure serves as a cost-effective and reliable substitute for human evaluation. Finally, based on measurement theory, we describe a meta-evaluation method for evaluating the above measures via reliability and validity, which can be generalized to other tasks as well. Extensive experimental analysis has been conducted to validate and inform the selection of concept evaluation measures.",
    "pdf_link": "https://arxiv.org/abs/2404.18533",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）虽然表现出了惊人的智能，但鉴于其不可预测的黑箱特性，我们对于将它们广泛应用于现实生活仍有所保留。为了提高透明度，基于概念的解释方法应运而生，旨在阐明LLMs的学习成果。然而，目前对这些概念的评估方法大多依赖于直觉和主观判断，如个案研究或人工评审，这限制了领域的进步。为此，我们提出了一种基于忠实度和可读性的新评估方法，旨在填补这一空白。我们首先定义了一个广泛适用的概念，并据此量化模型输出在扰动下的变化，以此衡量忠实度。接着，我们通过分析最能激活特定概念的模式的一致性，来自动评估可读性，以此替代人工评估。此外，我们基于测量理论，提出了一种元评估方法，用以评估上述度量的可靠性和有效性，该方法同样适用于其他任务。为了验证和优化概念评估度量的选择，我们已经开展了深入的实验分析。",
    "title_cn": "探讨概念驱动解释的易读性与准确性。",
    "tags": [
      "分类：LLM理论",
      "人工智能",
      ""
    ]
  },
  {
    "title": "ChatGPT as an inventor: Eliciting the strengths and weaknesses of current large language models against humans in engineering design",
    "submit_datetime": "2024年04月29日",
    "abstract": "This study compares the design practices and performance of ChatGPT 4.0, a large language model (LLM), against graduate engineering students in a 48-hour prototyping hackathon, based on a dataset comprising more than 100 prototypes. The LLM participated by instructing two participants who executed its instructions and provided objective feedback, generated ideas autonomously and made all design decisions without human intervention. The LLM exhibited similar prototyping practices to human participants and finished second among six teams, successfully designing and providing building instructions for functional prototypes. The LLM's concept generation capabilities were particularly strong. However, the LLM prematurely abandoned promising concepts when facing minor difficulties, added unnecessary complexity to designs, and experienced design fixation. Communication between the LLM and participants was challenging due to vague or unclear descriptions, and the LLM had difficulty maintaining continuity and relevance in answers. Based on these findings, six recommendations for implementing an LLM like ChatGPT in the design process are proposed, including leveraging it for ideation, ensuring human oversight for key decisions, implementing iterative feedback loops, prompting it to consider alternatives, and assigning specific and manageable tasks at a subsystem level.",
    "pdf_link": "https://arxiv.org/abs/2404.18479",
    "graphs": [],
    "abstract_cn": "本项研究将大型语言模型ChatGPT 4.0的设计实践与性能，与参与48小时原型设计竞赛的研究生工程师们进行了对比，研究基于超过100个原型的数据分析。ChatGPT 4.0通过向两名参与者发出指令，由他们执行并反馈，自主构思创意，并独立做出所有设计决策，无需人为干预。该模型展现出与人类参与者相似的原型设计流程，并在六支队伍中荣获亚军，成功地设计并提供了功能性原型的构建指南。ChatGPT 4.0在概念生成方面表现出色，但在遇到小问题时会过早放弃有潜力的创意，设计中加入了不必要的复杂性，并表现出设计上的固执。由于描述不够明确，模型与参与者之间的沟通存在挑战，且在回答中保持连贯性和相关性方面存在困难。基于这些发现，研究提出了六项实施类似ChatGPT的LLM于设计流程的建议，包括利用其进行创意发想，确保人为监督关键决策，建立迭代反馈机制，鼓励其考虑多种选择，以及在子系统层面分配具体且可控的任务。",
    "title_cn": "ChatGPT：工程设计领域的创新者——揭示当前大型语言模型与人类相比的优劣所在。",
    "tags": [
      "LLM应用",
      "人工智能",
      "设计工程"
    ]
  },
  {
    "title": "HFT: Half Fine-Tuning for Large Language Models",
    "submit_datetime": "2024年04月29日",
    "abstract": "Large language models (LLMs) with one or more fine-tuning phases have become a necessary step to unlock various capabilities, enabling LLMs to follow natural language instructions or align with human preferences. However, it carries the risk of catastrophic forgetting during sequential training, the parametric knowledge or the ability learned in previous stages may be overwhelmed by incoming training data. In this paper, we find that by regularly resetting partial parameters, LLMs can restore some of the original knowledge. Inspired by this, we introduce Half Fine-Tuning (HFT) for LLMs, as a substitute for full fine-tuning (FFT), to mitigate the forgetting issues, where half of the parameters are selected to learn new tasks while the other half are frozen to remain previous knowledge. We provide a feasibility analysis from the perspective of optimization and interpret the parameter selection operation as a regularization term. Without changing the model architecture, HFT could be seamlessly integrated into existing fine-tuning frameworks. Extensive experiments and analysis on supervised fine-tuning, direct preference optimization, and continual learning consistently demonstrate the effectiveness, robustness, and efficiency of HFT. Compared with FFT, HFT not only significantly alleviates the forgetting problem, but also achieves the best performance in a series of downstream benchmarks, with an approximately 30% reduction in training time.",
    "pdf_link": "https://arxiv.org/abs/2404.18466",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）通过一个或多个微调阶段，已成为实现多样化功能的关键步骤，让模型能够遵循自然语言指令或适应人类的偏好。但这种顺序训练可能会引发灾难性遗忘，即早期学习的知识或能力可能被新的训练数据所覆盖。本文研究发现，定期重置部分参数有助于模型恢复一些原有知识。基于这一发现，我们提出了一种新的半微调（Half Fine-Tuning，HFT）方法，作为完全微调（Full Fine-Tuning，FFT）的替代方案，以缓解遗忘问题。在这种方法中，一半的参数用于学习新任务，而另一半则保持不变以维持之前的知识。我们从优化的角度对HFT进行了可行性分析，并将参数选择视为一种正则化手段。HFT可以无缝地融入现有的微调流程，而无需改变模型架构。通过在监督微调、直接偏好优化和持续学习等多个方面的广泛实验和分析，HFT展现了其在有效性、鲁棒性和效率上的优势。相较于FFT，HFT显著减少了遗忘问题，同时在多个下游任务基准测试中取得了最佳性能，并大幅缩短了约30%的训练时间。",
    "title_cn": "HFT：为大型语言模型量身定制的半微调技术",
    "tags": [
      "LLM理论",
      "机器学习",
      ""
    ]
  },
  {
    "title": "Ethical Reasoning and Moral Value Alignment of LLMs Depend on the Language we Prompt them in",
    "submit_datetime": "2024年04月29日",
    "abstract": "Ethical reasoning is a crucial skill for Large Language Models (LLMs). However, moral values are not universal, but rather influenced by language and culture. This paper explores how three prominent LLMs -- GPT-4, ChatGPT, and Llama2-70B-Chat -- perform ethical reasoning in different languages and if their moral judgement depend on the language in which they are prompted. We extend the study of ethical reasoning of LLMs by Rao et al. (2023) to a multilingual setup following their framework of probing LLMs with ethical dilemmas and policies from three branches of normative ethics: deontology, virtue, and consequentialism. We experiment with six languages: English, Spanish, Russian, Chinese, Hindi, and Swahili. We find that GPT-4 is the most consistent and unbiased ethical reasoner across languages, while ChatGPT and Llama2-70B-Chat show significant moral value bias when we move to languages other than English. Interestingly, the nature of this bias significantly vary across languages for all LLMs, including GPT-4.",
    "pdf_link": "https://arxiv.org/abs/2404.18460",
    "graphs": [],
    "abstract_cn": "伦理推理对于大型语言模型（LLMs）至关重要，但道德观念受语言与文化的影响而不尽相同。本研究考察了GPT-4、ChatGPT和Llama2-70B-Chat这三款主流LLMs在不同语言环境下的伦理推理能力，以及他们的道德判断是否会随着使用语言的不同而变化。我们依据Rao等人（2023年）的研究框架，将伦理困境和政策应用于LLMs的多语言测试，涵盖规范伦理学的三大分支：义务论、美德伦理和后果主义。实验涉及英语、西班牙语、俄语、中文、印地语和斯瓦希里语六种语言。研究结果显示，GPT-4在跨语言伦理推理中表现出最高的一致性和公正性，而ChatGPT和Llama2-70B-Chat在非英语环境下则表现出较大的道德价值偏差。值得注意的是，包括GPT-4在内的所有LLMs在不同语言中的偏差特性均有所不同。",
    "title_cn": "大型语言模型（LLM）的道德推理与价值观念的一致性，取决于我们如何用语言引导它们。",
    "tags": [
      "分类：LLM应用\n\n这篇论文研究了大型语言模型（LLMs）在不同语言环境下的伦理推理能力，以及他们的道德判断是否会随着使用语言的不同而变化。这属于LLM应用的范畴，因为它探讨了LLMs在实际应用中的表现和问题。论文并没有涉及到LLMs的理论基础，也没有讨论如何改进或构建LLMs，因此不属于LLM理论。同时，论文也没有涉及到智能代理（Agent）或知识检索（RAG）的相关内容。",
      "人工智能伦理",
      "语言模型"
    ]
  },
  {
    "title": "Chameleon: A Data-Efficient Generalist for Dense Visual Prediction in the Wild",
    "submit_datetime": "2024年04月29日",
    "abstract": "Large language models have evolved data-efficient generalists, benefiting from the universal language interface and large-scale pre-training. However, constructing a data-efficient generalist for dense visual prediction presents a distinct challenge due to the variation in label structures across different tasks. Consequently, generalization to unseen dense prediction tasks in the low-data regime is not straightforward and has received less attention from previous vision generalists. In this study, we explore a universal model that can flexibly adapt to unseen dense label structures with a few examples, enabling it to serve as a data-efficient vision generalist in diverse real-world scenarios. To this end, we base our method on a powerful meta-learning framework and explore several axes to improve its performance and versatility for real-world problems, such as flexible adaptation mechanisms and scalability. We evaluate our model across a spectrum of unseen real-world scenarios where low-shot learning is desirable, including video, 3D, medical, biological, and user-interactive tasks. Equipped with a generic architecture and an effective adaptation mechanism, our model flexibly adapts to all of these tasks with at most 50 labeled images, showcasing a significant advancement over existing data-efficient generalist approaches. Codes are available at https://github.com/GitGyun/chameleon.",
    "pdf_link": "https://arxiv.org/abs/2404.18459",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.18459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18459/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18459/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18459/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18459/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18459/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18459/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18459/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18459/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18459/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18459/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18459/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18459/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18459/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18459/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18459/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18459/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18459/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18459/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18459/x20.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18459/x21.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18459/x22.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18459/x23.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18459/x24.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18459/x25.png"
      }
    ],
    "abstract_cn": "大型语言模型已经进化为数据高效的多面手，这得益于统一的语言接口和大规模的预训练。然而，要构建一个能够应对不同任务中标签结构变化的密集视觉预测领域的数据高效多面手，面临着特别的挑战。在数据稀缺的情况下，对于未见过的密集预测任务的泛化并非易事，这一点在以往的视觉多面手研究中并未受到足够的关注。本研究中，我们探究了一种能够通过少量示例灵活适应未知密集标签结构的通用模型，使其能够在多种现实世界场景中充当数据高效的视觉多面手。为此，我们采用了一个强大的元学习框架，并探索了多个维度以提升模型的性能和适应性，包括灵活的适应机制和可扩展性。我们在一系列低样本学习需求的现实世界场景中对模型进行了评估，这些场景涵盖了视频、3D、医学、生物和用户交互任务。我们的模型凭借其通用架构和有效的适应机制，在这些任务中最多仅需50张标记图像即可灵活适应，相较于现有的数据高效多面手方法取得了显著的进步。相关代码可在 https://github.com/GitGyun/chameleon 上获取。",
    "title_cn": "变色龙：一种在野外环境中进行密集视觉预测的数据高效多面手。",
    "tags": [
      "分类：LLM应用",
      "计算机视觉",
      "元学习"
    ]
  },
  {
    "title": "BMRetriever: Tuning Large Language Models as Better Biomedical Text Retrievers",
    "submit_datetime": "2024年04月29日",
    "abstract": "Developing effective biomedical retrieval models is important for excelling at knowledge-intensive biomedical tasks but still challenging due to the deficiency of sufficient publicly annotated biomedical data and computational resources. We present BMRetriever, a series of dense retrievers for enhancing biomedical retrieval via unsupervised pre-training on large biomedical corpora, followed by instruction fine-tuning on a combination of labeled datasets and synthetic pairs. Experiments on 5 biomedical tasks across 11 datasets verify BMRetriever's efficacy on various biomedical applications. BMRetriever also exhibits strong parameter efficiency, with the 410M variant outperforming baselines up to 11.7 times larger, and the 2B variant matching the performance of models with over 5B parameters. The training data and model checkpoints are released at \\url{https://huggingface.co/BMRetriever} to ensure transparency, reproducibility, and application to new domains.",
    "pdf_link": "https://arxiv.org/abs/2404.18443",
    "graphs": [],
    "abstract_cn": "为了在知识密集型的生物医学任务中取得卓越表现，开发高效的生物医学检索模型至关重要，但这一任务因公开可用的生物医学数据标注不足和计算资源有限而充满挑战。我们介绍了 BMRetriever，这是一系列密集型检索器，通过在大规模生物医学语料库上进行无监督预训练，并在标记数据集和合成样本的组合上进行指令微调，以提升生物医学检索性能。在 11 个数据集上的 5 项生物医学任务的实验证实了 BMRetriever 在多样化应用中的高效性。BMRetriever 在参数效率上也表现出色，其 410M 版本性能超过基线模型达 11.7 倍，而 2B 版本则能与参数量超过 5B 的模型相媲美。为了确保透明度、可复现性以及促进新领域的应用，我们在 \\url{https://huggingface.co/BMRetriever} 上公开了训练数据和模型检查点。",
    "title_cn": "BMRetriever：优化大型语言模型，提升其在生物医学文本检索方面的性能。",
    "tags": [
      "分类：LLM应用\n\n这篇论文介绍了BMRetriever，这是一个针对生物医学检索任务的高效模型。它通过在大规模生物医学语料库上进行无监督预训练，并在标记数据集和合成样本的组合上进行指令微调，以提升生物医学检索性能。这表明了该研究在应用大型语言模型（LLM）于特定领域（生物医学检索）的应用上取得了显著成果。",
      "生物医学",
      "信息检索"
    ]
  },
  {
    "title": "Geospatial Big Data: Survey and Challenges",
    "submit_datetime": "2024年04月29日",
    "abstract": "In recent years, geospatial big data (GBD) has obtained attention across various disciplines, categorized into big earth observation data and big human behavior data. Identifying geospatial patterns from GBD has been a vital research focus in the fields of urban management and environmental sustainability. This paper reviews the evolution of GBD mining and its integration with advanced artificial intelligence (AI) techniques. GBD consists of data generated by satellites, sensors, mobile devices, and geographical information systems, and we categorize geospatial data based on different perspectives. We outline the process of GBD mining and demonstrate how it can be incorporated into a unified framework. Additionally, we explore new technologies like large language models (LLM), the Metaverse, and knowledge graphs, and how they could make GBD even more useful. We also share examples of GBD helping with city management and protecting the environment. Finally, we discuss the real challenges that come up when working with GBD, such as issues with data retrieval and security. Our goal is to give readers a clear view of where GBD mining stands today and where it might go next.",
    "pdf_link": "https://arxiv.org/abs/2404.18428",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.18428v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18428/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18428v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18428/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18428v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18428/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18428v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18428/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18428v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18428/x5.png"
      }
    ],
    "abstract_cn": "近年来，地理空间大数据（GBD）因其在多个学科中的应用而备受关注，主要分为地球观测大数据和人类行为大数据两大类。在城市管理和环境可持续性研究中，挖掘GBD中的地理空间模式成为了一个关键的研究议题。本文回顾了GBD挖掘技术的发展及其与先进人工智能技术的融合。GBD包括由卫星、传感器、移动设备和地理信息系统产生的数据，我们从多个角度对这些数据进行了分类。文章概述了GBD挖掘的流程，并展示了如何将其整合到一个统一的框架之中。同时，我们探讨了大型语言模型（LLM）、元宇宙和知识图谱等新兴技术，以及它们如何进一步提升GBD的应用价值。文中还展示了GBD在城市治理和环境保护方面的应用案例。最后，我们讨论了在GBD工作中遇到的挑战，包括数据获取和安全问题。我们旨在为读者提供一个清晰的视角，了解GBD挖掘的现状及其未来的发展方向。",
    "title_cn": "地理空间大数据：一项全面调查及其面临的挑战",
    "tags": [
      "分类：LLM应用\n\n这篇论文摘要讨论了地理空间大数据（GBD）的挖掘技术，以及如何将这些技术与先进的人工智能技术（包括大型语言模型LLM）融合。论文还探讨了LLM、元宇宙和知识图谱等新兴技术在GBD应用中的潜力。因此，这篇论文可以归类为LLM应用，因为它涉及到大型语言模型在地理空间大数据挖掘中的应用。",
      "城市管理",
      "环境保护"
    ]
  },
  {
    "title": "PromptReps: Prompting Large Language Models to Generate Dense and Sparse Representations for Zero-Shot Document Retrieval",
    "submit_datetime": "2024年04月29日",
    "abstract": "The current use of large language models (LLMs) for zero-shot document ranking follows one of two ways: 1) prompt-based re-ranking methods, which require no further training but are feasible for only re-ranking a handful of candidate documents due to the associated computational costs; and 2) unsupervised contrastive trained dense retrieval methods, which can retrieve relevant documents from the entire corpus but require a large amount of paired text data for contrastive training. In this paper, we propose PromptReps, which combines the advantages of both categories: no need for training and the ability to retrieve from the whole corpus. Our method only requires prompts to guide an LLM to generate query and document representations for effective document retrieval. Specifically, we prompt the LLMs to represent a given text using a single word, and then use the last token's hidden states and the corresponding logits associated to the prediction of the next token to construct a hybrid document retrieval system. The retrieval system harnesses both dense text embedding and sparse bag-of-words representations given by the LLM. Our experimental evaluation on the BEIR zero-shot document retrieval datasets illustrates that this simple prompt-based LLM retrieval method can achieve a similar or higher retrieval effectiveness than state-of-the-art LLM embedding methods that are trained with large amounts of unsupervised data, especially when using a larger LLM.",
    "pdf_link": "https://arxiv.org/abs/2404.18424",
    "graphs": [],
    "abstract_cn": "目前，大型语言模型（LLMs）在零样本文档排序的应用主要有两种策略：一是无需额外训练的基于提示的重新排序方法，尽管它因计算成本高而只适用于有限的候选文档集；二是能够遍历整个文档库的无监督对比训练密集检索方法，但这需要大量成对文本数据进行训练。本文提出了一种名为PromptReps的新方法，它融合了上述两种方法的优势——既无需训练又能全面检索文档库。该方法通过提示引导LLM生成查询和文档的表示，以便于高效检索。具体而言，我们让LLM用一个词来表示一段文本，然后利用该词的隐藏状态及其对应的预测下一个词的logits，构建一个混合型的文档检索系统。这一系统结合了LLM生成的密集文本嵌入和稀疏词袋模型。我们在BEIR零样本文档检索数据集上的实验评估显示，这种基于提示的LLM检索方法在检索效果上能与那些利用大量无监督数据训练的顶尖LLM嵌入方法相媲美，甚至在采用更大模型时更胜一筹。",
    "title_cn": "PromptReps：激发大型语言模型的潜能，为零样本文档检索任务生成既密集又稀疏的表示方法。",
    "tags": [
      "LLM应用",
      "文档检索",
      ""
    ]
  },
  {
    "title": "Sample-Efficient Robust Multi-Agent Reinforcement Learning in the Face of Environmental Uncertainty",
    "submit_datetime": "2024年04月29日",
    "abstract": "To overcome the sim-to-real gap in reinforcement learning (RL), learned policies must maintain robustness against environmental uncertainties. While robust RL has been widely studied in single-agent regimes, in multi-agent environments, the problem remains understudied -- despite the fact that the problems posed by environmental uncertainties are often exacerbated by strategic interactions. This work focuses on learning in distributionally robust Markov games (RMGs), a robust variant of standard Markov games, wherein each agent aims to learn a policy that maximizes its own worst-case performance when the deployed environment deviates within its own prescribed uncertainty set. This results in a set of robust equilibrium strategies for all agents that align with classic notions of game-theoretic equilibria. Assuming a non-adaptive sampling mechanism from a generative model, we propose a sample-efficient model-based algorithm (DRNVI) with finite-sample complexity guarantees for learning robust variants of various notions of game-theoretic equilibria. We also establish an information-theoretic lower bound for solving RMGs, which confirms the near-optimal sample complexity of DRNVI with respect to problem-dependent factors such as the size of the state space, the target accuracy, and the horizon length.",
    "pdf_link": "https://arxiv.org/abs/2404.18909",
    "graphs": [],
    "abstract_cn": "为了弥合强化学习中的仿真与现实之间的鸿沟，所学习到的策略必须对环境的不确定性具有鲁棒性。尽管在单一智能体情境下，鲁棒性强化学习已受到广泛关注，但在多智能体情境中，这一问题尚未得到充分研究，尤其是在环境不确定性因策略互动而加剧的情况下。本研究着眼于分布鲁棒马尔可夫博弈（RMGs）的学习，这是一种鲁棒性增强的马尔可夫博弈，每个智能体都旨在学习一种策略，以确保在部署环境在其预设的不确定性范围内发生偏离时，自身的最坏情况性能达到最大化。这将形成一套与经典博弈论均衡理念相符的鲁棒均衡策略。在假设生成模型采用非自适应抽样机制的前提下，我们提出了一种样本高效的基于模型算法（DRNVI），并为学习不同博弈论均衡概念的鲁棒变体提供了有限样本复杂度的保证。此外，我们还建立了解决RMGs的信息论下界，证实了DRNVI在样本复杂度上接近最优，这与问题依赖因素（如状态空间大小、目标精度和时间范围）有关。",
    "title_cn": "面对环境的不确定性，本研究提出了一种样本高效且鲁棒的多智能体强化学习方法。",
    "tags": [
      "分类：Agent",
      "",
      "多智能体系统"
    ]
  },
  {
    "title": "Multi-Agent Synchronization Tasks",
    "submit_datetime": "2024年04月29日",
    "abstract": "In multi-agent reinforcement learning (MARL), coordination plays a crucial role in enhancing agents' performance beyond what they could achieve through cooperation alone. The interdependence of agents' actions, coupled with the need for communication, leads to a domain where effective coordination is crucial. In this paper, we introduce and define $\\textit{Multi-Agent Synchronization Tasks}$ (MSTs), a novel subset of multi-agent tasks. We describe one MST, that we call $\\textit{Synchronized Predator-Prey}$, offering a detailed description that will serve as the basis for evaluating a selection of recent state-of-the-art (SOTA) MARL algorithms explicitly designed to address coordination challenges through the use of communication strategies. Furthermore, we present empirical evidence that reveals the limitations of the algorithms assessed to solve MSTs, demonstrating their inability to scale effectively beyond 2-agent coordination tasks in scenarios where communication is a requisite component. Finally, the results raise questions about the applicability of recent SOTA approaches for complex coordination tasks (i.e. MSTs) and prompt further exploration into the underlying causes of their limitations in this context.",
    "pdf_link": "https://arxiv.org/abs/2404.18798",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.18798v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18798/synchronized_pred-prey_w_3_catcher.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18798v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18798/Combined_Payoff_Represenation.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18798v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18798/penalty-full-all_conditions.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18798v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18798/penalty-full_v_empty-2_agents.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18798v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18798/no_penalty-full-all_conditions.png"
      }
    ],
    "abstract_cn": "在多智能体强化学习领域，协调是提升智能体协作效果的关键。本文提出了“多智能体同步任务”（MSTs）这一新概念，并以“同步捕食者-猎物”为例，详细阐述了其特点。这些特点将用于评估一系列专为解决协调问题而设计的先进MARL算法。研究还展示了这些算法在处理超过两个智能体的协调任务时的局限性，尤其是在沟通至关重要的情况下。最终，这些发现对于当前顶尖方法在处理复杂协调任务时的适用性提出了质疑，并激发了对这些算法局限性背后原因的深入研究。",
    "title_cn": "多智能体同步作业",
    "tags": [
      "Agent",
      "人工智能",
      "多智能体系统"
    ]
  },
  {
    "title": "Fast Swarming of UAVs in GNSS-denied Feature-poor Environments without Explicit Communication",
    "submit_datetime": "2024年04月29日",
    "abstract": "A decentralized swarm approach for the fast cooperative flight of Unmanned Aerial Vehicles (UAVs) in feature-poor environments without any external localization and communication is introduced in this paper.\n  A novel model of a UAV neighborhood is proposed to achieve robust onboard mutual perception and flocking state feedback control, which is designed to decrease the inter-agent oscillations common in standard reactive swarm models employed in fast collective motion.\n  The novel swarming methodology is supplemented with an enhanced Multi-Robot State Estimation (MRSE) strategy to increase the reliability of the purely onboard localization, which may be unreliable in real environments.\n  Although MRSE and the neighborhood model may rely on information exchange between agents, we introduce a communication-less version of the swarming framework based on estimating communicated states to decrease dependence on the often unreliable communication networks of large swarms.\n  The proposed solution has been verified by a set of complex real-world experiments to demonstrate its overall capability in different conditions, including a UAV interception-motivated task with a group velocity reaching the physical limits of the individual hardware platforms.",
    "pdf_link": "https://arxiv.org/abs/2404.18729",
    "graphs": [],
    "abstract_cn": "本文提出了一种分散式无人机群体飞行的新方法，适用于缺乏特征的环境中，无需外部定位和通信。我们设计了一种新型的无人机邻近区域模型，以增强无人机之间的相互感知和群体状态的反馈控制，有效减少了快速集体运动中常见的无人机间振荡。此外，我们还引入了一种改进的多机器人状态估计（MRSE）策略，以提升仅依赖机载定位的可靠性。尽管MRSE和邻近区域模型可能需要无人机间的信息交流，但我们开发了一种无需通信的群体框架，通过估算通信状态来降低对大型群体通信网络的依赖。该方案已通过一系列复杂的实际实验得到验证，展示了其在多变条件下的卓越性能，包括一项以无人机拦截为模拟目标的任务，其群体速度达到了单个无人机硬件平台的物理极限。",
    "title_cn": "在缺乏全球导航卫星系统信号且特征稀缺的环境中，无人机能够实现无需明确通信的快速集群飞行。",
    "tags": [
      "Agent",
      "无人机",
      "机器人"
    ]
  },
  {
    "title": "A geometric approach for stability analysis of delay systems: Applications to network dynamics",
    "submit_datetime": "2024年04月29日",
    "abstract": "Investigating the network stability or synchronization dynamics of multi-agent systems with time delays is of significant importance in numerous real-world applications. Such investigations often rely on solving the transcendental characteristic equations (TCEs) obtained from linearization of the considered systems around specific solutions. While stability results based on the TCEs with real-valued coefficients induced by symmetric networks in time-delayed models have been extensively explored in the literature, there remains a notable gap in stability analysis for the TCEs with complexvalued coefficients arising from asymmetric networked dynamics with time delays. To address this challenge comprehensively, we propose a rigorously geometric approach. By identifying and studying the stability crossing curves in the complex plane, we are able to determine the stability region of these systems. This approach is not only suitable for analyzing the stability of models with discrete time delays but also for models with various types of delays, including distributed time delays. Additionally, it can also handle random networks. We demonstrate the efficacy of this approach in designing delayed control strategies for car-following systems, mechanical systems, and deep brain stimulation modeling, where involved are complex-valued TCEs or/and different types of delays. All these therefore highlight the broad applicability of our approach across diverse domains.",
    "pdf_link": "https://arxiv.org/abs/2404.18704",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.18704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18704/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18704/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18704/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18704/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18704/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18704/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18704/fig7.jpg"
      },
      {
        "url": "https://arxiv.org/html/2404.18704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18704/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18704/fig9.jpg"
      },
      {
        "url": "https://arxiv.org/html/2404.18704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18704/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18704/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18704/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18704/fig12.jpg"
      },
      {
        "url": "https://arxiv.org/html/2404.18704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18704/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18704/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18704/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18704/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18704/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18704v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18704/x16.png"
      }
    ],
    "abstract_cn": "探究具有时间延迟的多智能体系统的稳定性与同步行为对于现实世界中的众多应用至关重要。此类研究通常需要求解从特定解出发对系统进行线性化后得到的超越特征方程（TCEs）。尽管关于由对称网络在时间延迟模型中引起的实系数TCEs的稳定性研究已广泛开展，但对于由非对称网络动态引起的复值系数TCEs的稳定性分析尚存在明显缺口。为全面应对这一挑战，我们提出了一种严谨的几何分析方法。通过分析复平面上的稳定性临界曲线，我们得以界定这些系统的稳定区域。此方法不仅适用于离散时间延迟模型，也适用于包含分布式延迟等多种延迟类型的模型，并且能够处理随机网络。我们通过为汽车跟随系统、机械系统和深脑刺激模型设计延迟控制策略，证明了该方法在处理复值TCEs或不同类型延迟时的有效性，从而突显了该方法在多个领域的广泛适用性。",
    "title_cn": "本文介绍了一种新颖的几何方法，用于分析具有延迟的系统的稳定性，并将其应用于网络动态的研究。",
    "tags": [
      "Agent",
      "智能体系统",
      "控制理论"
    ]
  },
  {
    "title": "MRIC: Model-Based Reinforcement-Imitation Learning with Mixture-of-Codebooks for Autonomous Driving Simulation",
    "submit_datetime": "2024年04月29日",
    "abstract": "Accurately simulating diverse behaviors of heterogeneous agents in various scenarios is fundamental to autonomous driving simulation. This task is challenging due to the multi-modality of behavior distribution, the high-dimensionality of driving scenarios, distribution shift, and incomplete information. Our first insight is to leverage state-matching through differentiable simulation to provide meaningful learning signals and achieve efficient credit assignment for the policy. This is demonstrated by revealing the existence of gradient highways and interagent gradient pathways. However, the issues of gradient explosion and weak supervision in low-density regions are discovered. Our second insight is that these issues can be addressed by applying dual policy regularizations to narrow the function space. Further considering diversity, our third insight is that the behaviors of heterogeneous agents in the dataset can be effectively compressed as a series of prototype vectors for retrieval. These lead to our model-based reinforcement-imitation learning framework with temporally abstracted mixture-of-codebooks (MRIC). MRIC introduces the open-loop modelbased imitation learning regularization to stabilize training, and modelbased reinforcement learning (RL) regularization to inject domain knowledge. The RL regularization involves differentiable Minkowskidifference-based collision avoidance and projection-based on-road and traffic rule compliance rewards. A dynamic multiplier mechanism is further proposed to eliminate the interference from the regularizations while ensuring their effectiveness. Experimental results using the largescale Waymo open motion dataset show that MRIC outperforms state-ofthe-art baselines on diversity, behavioral realism, and distributional realism, with large margins on some key metrics (e.g., collision rate, minSADE, and time-to-collision JSD).",
    "pdf_link": "https://arxiv.org/abs/2404.18464",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x20.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x21.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x22.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x23.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x24.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x25.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x26.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x27.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x28.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x29.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x30.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x31.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x32.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x33.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x34.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x35.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x36.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x37.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x38.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x39.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18464/x40.png"
      }
    ],
    "abstract_cn": "精确地模拟各种情境下异构智能体的多样行为对于自动驾驶仿真至关重要。这一任务因行为分布的多样性、驾驶情境的高维度、分布偏移和信息缺失等因素而充满挑战。我们首先洞察到，通过可微仿真实现的状态匹配，能够提供有益的学习信号，为策略高效分配信用。这一点通过发现梯度高速公路和智能体间的梯度路径而得到证实。然而，我们也发现了梯度爆炸和低密度区域中的弱监督问题。我们的第二个洞察是，这些问题可以通过双重策略正则化来解决，以此缩小功能空间。考虑到多样性，我们的第三个洞察是，数据集中异构智能体的行为可以被有效压缩成一系列原型向量，以便于检索。这些洞察催生了我们的基于模型的强化模仿学习框架——时间抽象的混合码本（MRIC）。MRIC引入了开环模型基模仿学习正则化以稳定训练，并融入了基于模型的强化学习（RL）正则化以注入领域知识。RL正则化包括了基于可微分的Minkowski差异的避碰机制，以及基于投影的遵守道路和交通规则的奖励。此外，我们还提出了一种动态乘数机制，以消除正则化间的干扰并确保其效果。在大规模Waymo开放运动数据集上的实验结果显示，MRIC在多样性、行为真实性和分布真实性方面均超越了现有的最先进基线，尤其在关键指标（如碰撞率、最小SADE和碰撞时间JSD）上取得了显著优势。",
    "title_cn": "MRIC：一种融合码本混合技术的模型驱动强化模仿学习方法，专为自动驾驶模拟设计。",
    "tags": [
      "分类：Agent",
      "自动驾驶",
      "仿真技术"
    ]
  },
  {
    "title": "Multi-hop Question Answering over Knowledge Graphs using Large Language Models",
    "submit_datetime": "2024年04月29日",
    "abstract": "Knowledge graphs (KGs) are large datasets with specific structures representing large knowledge bases (KB) where each node represents a key entity and relations amongst them are typed edges. Natural language queries formed to extract information from a KB entail starting from specific nodes and reasoning over multiple edges of the corresponding KG to arrive at the correct set of answer nodes. Traditional approaches of question answering on KG are based on (a) semantic parsing (SP), where a logical form (e.g., S-expression, SPARQL query, etc.) is generated using node and edge embeddings and then reasoning over these representations or tuning language models to generate the final answer directly, or (b) information-retrieval based that works by extracting entities and relations sequentially. In this work, we evaluate the capability of (LLMs) to answer questions over KG that involve multiple hops. We show that depending upon the size and nature of the KG we need different approaches to extract and feed the relevant information to an LLM since every LLM comes with a fixed context window. We evaluate our approach on six KGs with and without the availability of example-specific sub-graphs and show that both the IR and SP-based methods can be adopted by LLMs resulting in an extremely competitive performance.",
    "pdf_link": "https://arxiv.org/abs/2404.19234",
    "graphs": [],
    "abstract_cn": "知识图谱（KGs）是结构化的海量数据集，它们构成了庞大的知识库（KB），每个节点代表一个核心实体，实体间的关系则以类型化的边来表示。要从KB中提取信息，自然语言查询需要从特定节点出发，沿着KG的多条边进行推理，以找到正确的答案节点集。在KG上的问答传统方法包括：（a）语义解析（SP），通过节点和边的嵌入生成逻辑形式（如S表达式、SPARQL查询等），然后在这些表示上进行推理，或调整语言模型以直接生成最终答案；（b）基于信息检索的方法，它通过顺序提取实体和关系来实现。本研究评估了大型语言模型（LLMs）在处理涉及多跳推理的KG问答任务上的能力。我们发现，根据不同KG的规模和特点，我们需要采取不同的策略来提取并向LLM提供相关信息，因为每个LLM都有一个固定的上下文窗口。我们在六个KG上进行了评估，包括有和没有特定子图的示例，结果表明，无论是基于信息检索（IR）还是语义解析（SP）的方法，LLMs都能采纳并展现出极其有竞争力的性能。",
    "title_cn": "利用大型语言模型，实现在知识图谱上的多步推理问答。",
    "tags": [
      "LLM应用",
      "知识图谱",
      "问答系统"
    ]
  },
  {
    "title": "Espresso: Robust Concept Filtering in Text-to-Image Models",
    "submit_datetime": "2024年04月29日",
    "abstract": "Diffusion-based text-to-image (T2I) models generate high-fidelity images for given textual prompts. They are trained on large datasets scraped from the Internet, potentially containing unacceptable concepts (e.g., copyright infringing or unsafe). Retraining T2I models after filtering out unacceptable concepts in the training data is inefficient and degrades utility. Hence, there is a need for concept removal techniques (CRTs) which are effective in removing unacceptable concepts, utility-preserving on acceptable concepts, and robust against evasion with adversarial prompts. None of the prior filtering and fine-tuning CRTs satisfy all these requirements simultaneously.\n  We introduce Espresso, the first robust concept filter based on Contrastive Language-Image Pre-Training (CLIP). It identifies unacceptable concepts by projecting the generated image's embedding onto the vector connecting unacceptable and acceptable concepts in the joint text-image embedding space. This ensures robustness by restricting the adversary to adding noise only along this vector, in the direction of the acceptable concept. Further fine-tuning Espresso to separate embeddings of acceptable and unacceptable concepts, while preserving their pairing with image embeddings, ensures both effectiveness and utility. We evaluate Espresso on eleven concepts to show that it is effective (~5% CLIP accuracy on unacceptable concepts), utility-preserving (~93% normalized CLIP score on acceptable concepts), and robust (~4% CLIP accuracy on adversarial prompts for unacceptable concepts). Finally, we present theoretical bounds for the certified robustness of Espresso against adversarial prompts, and an empirical analysis.",
    "pdf_link": "https://arxiv.org/abs/2404.19227",
    "graphs": [],
    "abstract_cn": "基于扩散原理的文本到图像（T2I）模型能够根据文本提示生成高清晰度的图像，这些模型通常在互联网上搜集的大型数据集上进行训练，但这些数据集可能潜藏不当内容，如侵权或不适宜的内容。在剔除了训练数据中的不当概念后，重新训练T2I模型不仅效率低下，还会影响其功能性。因此，迫切需要一种能够有效移除不当概念、保留适当概念的实用性，并且能够抵御对抗性提示的概念移除技术（CRTs）。目前，尚无现有的过滤和微调CRTs能够完全满足这些需求。我们在此推出Espresso，这是首个基于对比性语言-图像预训练（CLIP）的鲁棒性概念过滤器。Espresso通过将生成图像的嵌入向量投影到联合文本-图像嵌入空间中，连接不可接受与可接受概念的向量上，来辨识出不当概念。这种方法通过限制对手只能在该向量上，朝向可接受概念的方向添加噪声，从而确保了系统的鲁棒性。Espresso进一步经过微调，以区分可接受与不可接受概念的嵌入，同时保持它们与图像嵌入的对应关系，这样既保证了效果也兼顾了实用性。我们在11个概念上对Espresso进行了评估，结果表明其具有高效果（在不可接受概念上的CLIP准确率约为5%），实用性（在可接受概念上的CLIP得分约为93%），以及鲁棒性（在对抗性提示的不可接受概念上的CLIP准确率约为4%）。最后，我们为Espresso面对对抗性提示的认证鲁棒性提供了理论界限，并进行了实证分析。",
    "title_cn": "Espresso：文本到图像模型中的稳健概念筛选",
    "tags": [
      "LLM应用",
      "图像生成",
      "内容过滤"
    ]
  },
  {
    "title": "Transcrib3D: 3D Referring Expression Resolution through Large Language Models",
    "submit_datetime": "2024年04月29日",
    "abstract": "If robots are to work effectively alongside people, they must be able to interpret natural language references to objects in their 3D environment. Understanding 3D referring expressions is challenging -- it requires the ability to both parse the 3D structure of the scene and correctly ground free-form language in the presence of distraction and clutter. We introduce Transcrib3D, an approach that brings together 3D detection methods and the emergent reasoning capabilities of large language models (LLMs). Transcrib3D uses text as the unifying medium, which allows us to sidestep the need to learn shared representations connecting multi-modal inputs, which would require massive amounts of annotated 3D data. As a demonstration of its effectiveness, Transcrib3D achieves state-of-the-art results on 3D reference resolution benchmarks, with a great leap in performance from previous multi-modality baselines. To improve upon zero-shot performance and facilitate local deployment on edge computers and robots, we propose self-correction for fine-tuning that trains smaller models, resulting in performance close to that of large models. We show that our method enables a real robot to perform pick-and-place tasks given queries that contain challenging referring expressions. Project site is at https://ripl.github.io/Transcrib3D.",
    "pdf_link": "https://arxiv.org/abs/2404.19221",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.19221v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19221/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19221v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19221/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19221v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19221/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19221v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19221/transcrib3d_success_2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19221v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19221/The_foremost_pillow_on_the_bed_of_the_group_of_pillows.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19221v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19221/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19221v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19221/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19221v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19221/The_cylinder_shaped_trash_can.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19221v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19221/This_door_is_open_and_has_nothing_blocking_it.png"
      }
    ],
    "abstract_cn": "为了让机器人与人类协同高效工作，它们必须能够理解其三维环境中物体的自然语言指引。解析三维指示性表达是一项挑战性任务，它不仅需要解析场景的三维结构，还需要在干扰和杂乱的环境中准确理解自由形式的语言。我们推出了Transcrib3D，这是一种融合了三维检测技术和大型语言模型（LLMs）的新兴推理能力的方法。Transcrib3D采用文本作为统一的交互媒介，巧妙地规避了学习多模态输入之间共享表示的需求，这通常需要大量的标注三维数据。在实际效果展示上，Transcrib3D在三维参考解析基准测试中取得了行业领先的成绩，与以往的多模态基准相比，性能有了显著提升。为了进一步提升零样本性能并实现在边缘计算设备和机器人上的本地部署，我们提出了一种自我校正的微调方法，用于训练更小型的模型，使得性能接近大型模型的水平。我们证明了该方法能够使真实机器人在面对包含复杂指示性表达的查询时，成功执行拣选和放置任务。项目详情请访问 https://ripl.github.io/Transcrib3D。",
    "title_cn": "Transcrib3D：借助大型语言模型，实现三维引用表达的精准解析。",
    "tags": [
      "分类：Agent",
      "机器人技术",
      ""
    ]
  },
  {
    "title": "TableVQA-Bench: A Visual Question Answering Benchmark on Multiple Table Domains",
    "submit_datetime": "2024年04月29日",
    "abstract": "In this paper, we establish a benchmark for table visual question answering, referred to as the TableVQA-Bench, derived from pre-existing table question-answering (QA) and table structure recognition datasets. It is important to note that existing datasets have not incorporated images or QA pairs, which are two crucial components of TableVQA. As such, the primary objective of this paper is to obtain these necessary components. Specifically, images are sourced either through the application of a \\textit{stylesheet} or by employing the proposed table rendering system. QA pairs are generated by exploiting the large language model (LLM) where the input is a text-formatted table. Ultimately, the completed TableVQA-Bench comprises 1,500 QA pairs. We comprehensively compare the performance of various multi-modal large language models (MLLMs) on TableVQA-Bench. GPT-4V achieves the highest accuracy among commercial and open-sourced MLLMs from our experiments. Moreover, we discover that the number of vision queries plays a significant role in TableVQA performance. To further analyze the capabilities of MLLMs in comparison to their LLM backbones, we investigate by presenting image-formatted tables to MLLMs and text-formatted tables to LLMs, respectively. Our findings suggest that processing visual inputs is more challenging than text inputs, as evidenced by the lower performance of MLLMs, despite generally requiring higher computational costs than LLMs. The proposed TableVQA-Bench and evaluation codes are available at \\href{https://github.com/naver-ai/tablevqabench}{https://github.com/naver-ai/tablevqabench}.",
    "pdf_link": "https://arxiv.org/abs/2404.19205",
    "graphs": [],
    "abstract_cn": "本文提出了一个名为 TableVQA-Bench 的表格视觉问答基准测试，该基准基于现有的表格问答和结构识别数据集。现有数据集尚未整合图像或问答对，而这两者对于表格视觉问答至关重要。本文旨在补充这些关键元素。图像来源可以是应用样式表或采用我们提出的表格渲染系统。问答对则是通过大型语言模型（LLM）生成，输入为文本格式的表格。构建完成的 TableVQA-Bench 包含了 1,500 组问答对。我们还对多种多模态大型语言模型（MLLMs）在该基准上的表现进行了全面比较，发现 GPT-4V 在商业和开源 MLLMs 中准确度最高。此外，视觉查询的数量对性能有显著影响。为了深入分析 MLLMs 与其基础 LLMs 的能力差异，我们分别向 MLLMs 和 LLMs 展示了图像格式和文本格式的表格。研究结果表明，处理视觉输入相较于文本输入更具挑战性，尽管 MLLMs 通常需要更高的计算资源，但其性能却低于 LLMs。我们提供的 TableVQA-Bench 基准测试和评估代码可在 GitHub 上找到。",
    "title_cn": "TableVQA-Bench：多表格领域的视觉问答基准测试",
    "tags": [
      "LLM应用",
      "视觉问答",
      "数据科学"
    ]
  },
  {
    "title": "PEVA-Net: Prompt-Enhanced View Aggregation Network for Zero/Few-Shot Multi-View 3D Shape Recognition",
    "submit_datetime": "2024年04月29日",
    "abstract": "Large vision-language models have impressively promote the performance of 2D visual recognition under zero/few-shot scenarios. In this paper, we focus on exploiting the large vision-language model, i.e., CLIP, to address zero/few-shot 3D shape recognition based on multi-view representations. The key challenge for both tasks is to generate a discriminative descriptor of the 3D shape represented by multiple view images under the scenarios of either without explicit training (zero-shot 3D shape recognition) or training with a limited number of data (few-shot 3D shape recognition). We analyze that both tasks are relevant and can be considered simultaneously. Specifically, leveraging the descriptor which is effective for zero-shot inference to guide the tuning of the aggregated descriptor under the few-shot training can significantly improve the few-shot learning efficacy. Hence, we propose Prompt-Enhanced View Aggregation Network (PEVA-Net) to simultaneously address zero/few-shot 3D shape recognition. Under the zero-shot scenario, we propose to leverage the prompts built up from candidate categories to enhance the aggregation process of multiple view-associated visual features. The resulting aggregated feature serves for effective zero-shot recognition of the 3D shapes. Under the few-shot scenario, we first exploit a transformer encoder to aggregate the view-associated visual features into a global descriptor. To tune the encoder, together with the main classification loss, we propose a self-distillation scheme via a feature distillation loss by treating the zero-shot descriptor as the guidance signal for the few-shot descriptor. This scheme can significantly enhance the few-shot learning efficacy.",
    "pdf_link": "https://arxiv.org/abs/2404.19168",
    "graphs": [],
    "abstract_cn": "大型视觉-语言模型显著提升了二维视觉识别在零样本/少样本场景下的性能。本文着眼于运用大型视觉-语言模型CLIP，针对基于多视图表示的零样本/少样本三维形状识别进行研究。核心挑战在于生成能够代表三维形状的多视图图像的区分性描述符，无论是在完全没有显式训练（零样本三维形状识别）还是只有少量数据训练（少样本三维形状识别）的情况下。我们发现这两个任务不仅相关，而且可以一并处理。具体而言，利用对零样本推断有效的描述符来指导少样本训练中的聚合描述符的调整，可以有效提升少样本学习的效果。因此，我们提出了增强型视图聚合网络（PEVA-Net），以同时应对零样本/少样本三维形状识别的挑战。在零样本场景下，我们提出利用候选类别构建的提示来增强多视图相关视觉特征的聚合。这样聚合得到的特征能够有效地用于零样本三维形状识别。而在少样本场景下，我们首先使用变换器编码器将视图相关视觉特征整合成全局描述符，并通过自我蒸馏策略，结合零样本描述符作为引导信号，通过特征蒸馏损失来调整编码器，从而显著提升少样本学习的效果。",
    "title_cn": "PEVA-Net：一种用于零样本或少样本多视角3D形状识别的增强提示视图聚合网络。",
    "tags": [
      "分类：LLM应用",
      "计算机视觉",
      "机器学习"
    ]
  },
  {
    "title": "What Drives Performance in Multilingual Language Models?",
    "submit_datetime": "2024年04月29日",
    "abstract": "This study investigates the factors influencing the performance of multilingual large language models (MLLMs) across diverse languages. We study 6 MLLMs, including masked language models, autoregressive models, and instruction-tuned LLMs, on the SIB-200 dataset, a topic classification dataset encompassing 204 languages. Our analysis considers three scenarios: ALL languages, SEEN languages (present in the model's pretraining data), and UNSEEN languages (not present or documented in the model's pretraining data in any meaningful way). We examine the impact of factors such as pretraining data size, general resource availability, language family, and script type on model performance. Decision tree analysis reveals that pretraining data size is the most influential factor for SEEN languages. However, interestingly, script type and language family are crucial for UNSEEN languages, highlighting the importance of cross-lingual transfer learning. Notably, model size and architecture do not significantly alter the most important features identified. Our findings provide valuable insights into the strengths and limitations of current MLLMs and hope to guide the development of more effective and equitable multilingual NLP systems.",
    "pdf_link": "https://arxiv.org/abs/2404.19159",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.19159v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19159/res-level.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19159v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19159/bloom-560m_SEEN.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19159v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19159/3models-res.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19159v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19159/lang-fam.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19159v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19159/script.png"
      }
    ],
    "abstract_cn": "本研究深入探讨了影响多语言大型语言模型（MLLMs）在多种语言中表现的各种因素。通过对六种不同的MLLMs进行分析，包括掩蔽语言模型、自回归模型和经过指令调整的LLMs，我们利用涵盖204种语言的SIB-200主题分类数据集进行了研究。研究区分了三种不同的语言场景：所有语言、预训练数据中出现过的“已见语言”，以及从未出现或未被记录的“未见语言”。我们评估了预训练数据规模、资源普遍可用性、语言系属和文字类型等因素对模型效能的影响。决策树分析显示，对于“已见语言”，预训练数据的规模是最关键的影响因素。然而，对于“未见语言”，文字类型和语言系属显得尤为重要，这强调了跨语言迁移学习的关键作用。值得注意的一点是，模型的大小和架构并不显著影响识别出的主要特征。这些发现不仅揭示了当前MLLMs的优势和局限，而且为未来更高效、更公平的多语言自然语言处理系统的发展提供了指导。",
    "title_cn": "驱动多语言语言模型性能的因素是什么？",
    "tags": [
      "分类：LLM理论",
      "",
      "机器学习"
    ]
  },
  {
    "title": "Automated Construction of Theme-specific Knowledge Graphs",
    "submit_datetime": "2024年04月29日",
    "abstract": "Despite widespread applications of knowledge graphs (KGs) in various tasks such as question answering and intelligent conversational systems, existing KGs face two major challenges: information granularity and deficiency in timeliness. These hinder considerably the retrieval and analysis of in-context, fine-grained, and up-to-date knowledge from KGs, particularly in highly specialized themes (e.g., specialized scientific research) and rapidly evolving contexts (e.g., breaking news or disaster tracking). To tackle such challenges, we propose a theme-specific knowledge graph (i.e., ThemeKG), a KG constructed from a theme-specific corpus, and design an unsupervised framework for ThemeKG construction (named TKGCon). The framework takes raw theme-specific corpus and generates a high-quality KG that includes salient entities and relations under the theme. Specifically, we start with an entity ontology of the theme from Wikipedia, based on which we then generate candidate relations by Large Language Models (LLMs) to construct a relation ontology. To parse the documents from the theme corpus, we first map the extracted entity pairs to the ontology and retrieve the candidate relations. Finally, we incorporate the context and ontology to consolidate the relations for entity pairs. We observe that directly prompting GPT-4 for theme-specific KG leads to inaccurate entities (such as \"two main types\" as one entity in the query result) and unclear (such as \"is\", \"has\") or wrong relations (such as \"have due to\", \"to start\"). In contrast, by constructing the theme-specific KG step by step, our model outperforms GPT-4 and could consistently identify accurate entities and relations. Experimental results also show that our framework excels in evaluations compared with various KG construction baselines.",
    "pdf_link": "https://arxiv.org/abs/2404.19146",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.19146v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19146/intro8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19146v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19146/overview11.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19146v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19146/cased.png"
      }
    ],
    "abstract_cn": "知识图谱在问答和智能对话系统等任务中应用广泛，但现有知识图谱在信息细节和即时性上存在不足，尤其在专业研究和快速变化的情境如突发新闻追踪中，这些不足严重影响了知识的检索与分析。为此，我们提出了一个针对特定主题的知识图谱（ThemeKG），并设计了一个无监督的构建框架（TKGCon）。该框架能够从特定主题的原始语料库中提炼出包含关键实体和关系的高质量知识图谱。我们首先利用维基百科中的实体本体作为起点，然后利用大型语言模型（LLMs）探索候选关系，形成关系本体。在处理主题语料库的文档时，我们将实体对与本体映射，筛选出候选关系。最终，结合上下文和本体，我们巩固了实体对之间的关系。我们发现，直接向GPT-4查询特定主题的知识图谱会导致实体识别不准确，关系描述模糊或错误。而我们的模型通过逐步构建主题知识图谱，在准确性上超越了GPT-4。实验结果显示，我们的框架在各项评估中均优于传统知识图谱构建方法。",
    "title_cn": "自动化构建针对性主题的知识图谱",
    "tags": [
      "分类：LLM应用",
      "问答系统",
      "知识图谱"
    ]
  },
  {
    "title": "Accelerating Production LLMs with Combined Token/Embedding Speculators",
    "submit_datetime": "2024年04月29日",
    "abstract": "This technical report describes the design and training of novel speculative decoding draft models, for accelerating the inference speeds of large language models in a production environment. By conditioning draft predictions on both context vectors and sampled tokens, we can train our speculators to efficiently predict high-quality n-grams, which the base model then accepts or rejects. This allows us to effectively predict multiple tokens per inference forward pass, accelerating wall-clock inference speeds of highly optimized base model implementations by a factor of 2-3x. We explore these initial results and describe next steps for further improvements.",
    "pdf_link": "https://arxiv.org/abs/2404.19124",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.19124v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19124/specu_arch.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19124v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19124/specu_losses.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19124v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19124/tgis_graphs.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19124v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19124/granite_graphs.png"
      }
    ],
    "abstract_cn": "本篇技术报告详细介绍了一种创新的推测性解码草案模型的设计与训练过程，目的在于提升大型语言模型在生产环境下的推理效率。我们的方法是通过结合上下文向量和采样标记来训练模型，使其能够高效地预测出高质量的n-gram序列，随后基础模型将决定是否采纳这些预测结果。这一策略显著提升了优化后的基础模型的推理速度，加速比达到了2至3倍。报告中还讨论了初步成果，并对未来的改进方向进行了展望。",
    "title_cn": "结合令牌与嵌入预测器，我们能够加速大型语言模型的生产流程。",
    "tags": [
      "LLM应用",
      "",
      "机器学习"
    ]
  },
  {
    "title": "Exploring the Capability of LLMs in Performing Low-Level Visual Analytic Tasks on SVG Data Visualizations",
    "submit_datetime": "2024年04月29日",
    "abstract": "Data visualizations help extract insights from datasets, but reaching these insights requires decomposing high level goals into low-level analytic tasks that can be complex due to varying data literacy and experience. Recent advancements in large language models (LLMs) have shown promise for lowering barriers for users to achieve tasks such as writing code. Scalable Vector Graphics (SVG), a text-based image format common in data visualizations, matches well with the text sequence processing of transformer-based LLMs. In this paper, we explore the capability of LLMs to perform low-level visual analytic tasks defined by Amar, Eagan, and Stasko directly on SVG-based visualizations. Using zero-shot prompts, we instruct the models to provide responses or modify the SVG code based on given visualizations. Our findings demonstrate that LLMs can effectively modify existing SVG visualizations for specific tasks like Cluster but perform poorly on tasks requiring a sequence of math operations. We also discovered that LLM performance varies based on factors such as the number of data points, the presence of value labels, and the chart type. Our findings contribute to gauging the general capabilities of LLMs and highlight the need for further exploration and development to fully harness their potential in supporting visual analytic tasks.",
    "pdf_link": "https://arxiv.org/abs/2404.19097",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.19097v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19097/teasor.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19097v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19097/prompt.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19097v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19097/retrieval.png"
      }
    ],
    "abstract_cn": "数据可视化是洞察数据集的利器，但要深入挖掘这些洞见，需将宏观目标细化为微观分析任务，这一过程可能因个人数据理解能力和经验的差异而变得颇具挑战。近期，大型语言模型（LLMs）的进展为简化用户执行编码等任务的难度带来了希望。作为数据可视化中常用的基于文本的图像格式，可缩放矢量图形（SVG）与基于变换器的LLMs的文本序列处理能力相得益彰。本文旨在探讨LLMs在SVG可视化基础上执行Amar、Eagan和Stasko定义的微观视觉分析任务的能力。我们利用零次拍摄提示，引导模型根据特定的可视化结果提供反馈或调整SVG代码。研究结果显示，LLMs能够高效地为特定任务（如聚类）修改SVG可视化，但在需要连续数学运算的任务上表现欠佳。此外，我们还发现LLMs的表现受到数据点数量、值标签的有无以及图表类型的不同影响。这些发现不仅为我们评估LLMs的通用能力提供了参考，也突显了进一步探索和发展的必要性，以便更好地发挥它们在视觉分析任务中的辅助作用。",
    "title_cn": "本文旨在探究大型语言模型在处理SVG数据可视化时，执行基础视觉分析任务的潜力。",
    "tags": [
      "LLM应用",
      "数据可视化",
      ""
    ]
  },
  {
    "title": "In-Context Symbolic Regression: Leveraging Language Models for Function Discovery",
    "submit_datetime": "2024年04月29日",
    "abstract": "Symbolic Regression (SR) is a task which aims to extract the mathematical expression underlying a set of empirical observations. Transformer-based methods trained on SR datasets detain the current state-of-the-art in this task, while the application of Large Language Models (LLMs) to SR remains unexplored. This work investigates the integration of pre-trained LLMs into the SR pipeline, utilizing an approach that iteratively refines a functional form based on the prediction error it achieves on the observation set, until it reaches convergence. Our method leverages LLMs to propose an initial set of possible functions based on the observations, exploiting their strong pre-training prior. These functions are then iteratively refined by the model itself and by an external optimizer for their coefficients. The process is repeated until the results are satisfactory. We then analyze Vision-Language Models in this context, exploring the inclusion of plots as visual inputs to aid the optimization process. Our findings reveal that LLMs are able to successfully recover good symbolic equations that fit the given data, outperforming SR baselines based on Genetic Programming, with the addition of images in the input showing promising results for the most complex benchmarks.",
    "pdf_link": "https://arxiv.org/abs/2404.19094",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.19094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19094/sketch.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19094/points.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19094/example.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19094/nguyen_llama.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19094/nguyen_llava.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19094/constant_llama.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19094/constant_llava.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19094/keijzer_llama.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19094/keijzer_llava.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19094/R_llama.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19094/R_llava.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19094v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19094/keijzer_seedonly.png"
      }
    ],
    "abstract_cn": "符号回归（SR）目标是从一系列经验数据中提炼出相应的数学表达式。目前，基于Transformer的模型在SR领域的性能领先，但大型语言模型（LLMs）在SR中的应用尚未被充分挖掘。本研究探讨了将预训练的LLMs整合到SR流程中，通过迭代优化函数形式，直至预测误差在观测集上达到最小并收敛。我们利用LLMs强大的预训练知识，提出基于观测数据的初始函数集，然后通过模型自身和外部优化器对这些函数及其系数进行迭代细化。在结果令人满意之前，这一过程将持续进行。此外，我们还研究了视觉-语言模型在SR中的表现，特别是通过将图表作为视觉输入来辅助优化过程。研究发现，LLMs在恢复与给定数据相匹配的高质量符号方程方面表现出色，性能超过了基于遗传编程的SR基线，且在输入中加入图像对于解决最复杂的基准测试显示出了积极的成效。",
    "title_cn": "利用语言模型进行函数发现：探索上下文符号回归。",
    "tags": [
      "LLM应用",
      "科学计算",
      "自动化设计"
    ]
  },
  {
    "title": "Large Language Models as Conversational Movie Recommenders: A User Study",
    "submit_datetime": "2024年04月29日",
    "abstract": "This paper explores the effectiveness of using large language models (LLMs) for personalized movie recommendations from users' perspectives in an online field experiment. Our study involves a combination of between-subject prompt and historic consumption assessments, along with within-subject recommendation scenario evaluations. By examining conversation and survey response data from 160 active users, we find that LLMs offer strong recommendation explainability but lack overall personalization, diversity, and user trust. Our results also indicate that different personalized prompting techniques do not significantly affect user-perceived recommendation quality, but the number of movies a user has watched plays a more significant role. Furthermore, LLMs show a greater ability to recommend lesser-known or niche movies. Through qualitative analysis, we identify key conversational patterns linked to positive and negative user interaction experiences and conclude that providing personal context and examples is crucial for obtaining high-quality recommendations from LLMs.",
    "pdf_link": "https://arxiv.org/abs/2404.19093",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.19093v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19093/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19093v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19093/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19093v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19093/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19093v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19093/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19093v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19093/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19093v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19093/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19093v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19093/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19093v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19093/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19093v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19093/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19093v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19093/x10.png"
      }
    ],
    "abstract_cn": "本研究在线实地实验中，从用户视角出发，探究了运用大型语言模型（LLMs）进行个性化电影推荐的效能。研究结合了受试者间的提示与历史消费评估，以及受试者内的推荐场景评价。通过对160位活跃用户的对话和调查反馈进行分析，我们发现LLMs在推荐解释性上表现出色，但在个性化、多样性和赢得用户信任方面尚有欠缺。研究还发现，不同的个性化提示手法并未显著提升用户对推荐质量的感知，而用户观影数量的多少则更为关键。此外，LLMs在推荐知名度较低或小众电影方面更具优势。通过深入的定性分析，我们揭示了与用户互动体验正负面相关的主要对话模式，并得出结论，提供个性化的背景和实例对于从LLMs获得优质推荐至关重要。",
    "title_cn": "大型语言模型：对话式电影推荐的用户研究",
    "tags": [
      "LLM应用",
      "",
      "个性化推荐"
    ]
  },
  {
    "title": "HELPER-X: A Unified Instructable Embodied Agent to Tackle Four Interactive Vision-Language Domains with Memory-Augmented Language Models",
    "submit_datetime": "2024年04月29日",
    "abstract": "Recent research on instructable agents has used memory-augmented Large Language Models (LLMs) as task planners, a technique that retrieves language-program examples relevant to the input instruction and uses them as in-context examples in the LLM prompt to improve the performance of the LLM in inferring the correct action and task plans. In this technical report, we extend the capabilities of HELPER, by expanding its memory with a wider array of examples and prompts, and by integrating additional APIs for asking questions. This simple expansion of HELPER into a shared memory enables the agent to work across the domains of executing plans from dialogue, natural language instruction following, active question asking, and commonsense room reorganization. We evaluate the agent on four diverse interactive visual-language embodied agent benchmarks: ALFRED, TEACh, DialFRED, and the Tidy Task. HELPER-X achieves few-shot, state-of-the-art performance across these benchmarks using a single agent, without requiring in-domain training, and remains competitive with agents that have undergone in-domain training.",
    "pdf_link": "https://arxiv.org/abs/2404.19065",
    "graphs": [],
    "abstract_cn": "最新研究利用具备增强记忆功能的大型语言模型（LLMs）作为任务规划器，通过检索与输入指令紧密相关的语言程序实例，并将其作为上下文示例嵌入LLM的提示中，从而提升了LLM在推导正确行动和任务规划方面的性能。本技术报告进一步扩展了HELPER的功能，不仅扩充了其记忆库，加入了更多样的示例和提示，还整合了更多API以支持提问。这一扩展使得HELPER能够在多个领域内发挥作用，包括从对话中执行计划、遵循自然语言指令、主动提问以及基于常识的房间重组。我们在四个多样化的交互式视觉-语言体现代理基准测试中对代理进行了评估：ALFRED、TEACh、DialFRED和Tidy Task。HELPER-X在这些测试中展现了少量样本学习下的顶尖性能，且无需特定领域训练即可与经过领域训练的代理相媲美。",
    "title_cn": "HELPER-X：一款集成的可指导实体代理，搭载记忆增强型语言模型，旨在攻克四大交互式视觉-语言领域的挑战。",
    "tags": [
      "Agent",
      "人工智能",
      "任务规划"
    ]
  },
  {
    "title": "SuperCLUE-Fin: Graded Fine-Grained Analysis of Chinese LLMs on Diverse Financial Tasks and Applications",
    "submit_datetime": "2024年04月29日",
    "abstract": "The SuperCLUE-Fin (SC-Fin) benchmark is a pioneering evaluation framework tailored for Chinese-native financial large language models (FLMs). It assesses FLMs across six financial application domains and twenty-five specialized tasks, encompassing theoretical knowledge and practical applications such as compliance, risk management, and investment analysis. Using multi-turn, open-ended conversations that mimic real-life scenarios, SC-Fin measures models on a range of criteria, including accurate financial understanding, logical reasoning, clarity, computational efficiency, business acumen, risk perception, and compliance with Chinese regulations.\n  In a rigorous evaluation involving over a thousand questions, SC-Fin identifies a performance hierarchy where domestic models like GLM-4 and MoonShot-v1-128k outperform others with an A-grade, highlighting the potential for further development in transforming theoretical knowledge into pragmatic financial solutions. This benchmark serves as a critical tool for refining FLMs in the Chinese context, directing improvements in financial knowledge databases, standardizing financial interpretations, and promoting models that prioritize compliance, risk management, and secure practices.\n  We create a contextually relevant and comprehensive benchmark that drives the development of AI in the Chinese financial sector. SC-Fin facilitates the advancement and responsible deployment of FLMs, offering valuable insights for enhancing model performance and usability for both individual and institutional users in the Chinese market..~\\footnote{Our benchmark can be found at \\url{https://www.CLUEbenchmarks.com}}.",
    "pdf_link": "https://arxiv.org/abs/2404.19063",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.19063v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19063/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19063v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19063/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19063v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19063/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19063v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19063/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19063v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19063/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19063v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19063/x6.png"
      }
    ],
    "abstract_cn": "SuperCLUE-Fin（SC-Fin）基准框架，专为中文金融领域的大型语言模型（FLMs）量身打造，涵盖了六大金融应用领域和二十五项专业任务，包括合规、风险管理和投资分析等理论与实践相结合的应用。该框架通过模拟真实情境的多轮开放式对话，对模型进行多维度评估，包括金融知识理解、逻辑推理、表达清晰度、计算效率、商业洞察力、风险意识及遵守中国法规等。在一项包含逾千题的严格评估中，SC-Fin揭示了性能排名，国内模型如GLM-4和MoonShot-v1-128k以A级成绩领先，显示了将理论知识转化为实际金融解决方案的巨大潜力。此基准工具对于在中国金融背景下优化FLMs、提升金融知识库、统一金融解释标准以及推动模型在合规、风险管理和安全实践方面的优先发展至关重要。我们构建了这一全面且具针对性的基准，旨在推动中国金融领域人工智能的发展。SC-Fin不仅促进了FLMs的进步和负责任的应用，还为提升模型在中国市场的个人和机构用户的性能和可用性提供了深刻见解。~\\footnote{更多关于我们的基准信息，请访问 \\url{https://www.CLUEbenchmarks.com}}。",
    "title_cn": "SuperCLUE-Fin：深入剖析中国大型语言模型在多元金融任务及应用中的细致分级表现。",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Plan of Thoughts: Heuristic-Guided Problem Solving with Large Language Models",
    "submit_datetime": "2024年04月29日",
    "abstract": "While language models (LMs) offer significant capability in zero-shot reasoning tasks across a wide range of domains, they do not perform satisfactorily in problems which requires multi-step reasoning. Previous approaches to mitigate this involves breaking a larger, multi-step task into sub-tasks and asking the language model to generate proposals (\"thoughts\") for each sub-task and using exhaustive planning approaches such as DFS to compose a solution. In this work, we leverage this idea to introduce two new contributions: first, we formalize a planning-based approach to perform multi-step problem solving with LMs via Partially Observable Markov Decision Processes (POMDPs), with the LM's own reflections about the value of a state used as a search heuristic; second, leveraging the online POMDP solver POMCP, we demonstrate a superior success rate of 89.4% on the Game of 24 task as compared to existing approaches while also offering better anytime performance characteristics than fixed tree-search which is used previously. Taken together, these contributions allow modern LMs to decompose and solve larger-scale reasoning tasks more effectively.",
    "pdf_link": "https://arxiv.org/abs/2404.19055",
    "graphs": [],
    "abstract_cn": "语言模型在众多领域的零样本推理任务中展现出强大的能力，但面对需要连续推理的问题时，它们的表现尚有不足。传统解决方案是将复杂任务拆解为多个子任务，让语言模型为每个子任务提出方案，并采用深度优先搜索等策略来整合答案。本研究在此基础上提出了两项创新：一是将基于规划的方法应用于LMs的多步问题解决，通过部分可观测马尔可夫决策过程（POMDPs），并以LM对状态价值的自我评估作为搜索策略；二是借助在线POMDP求解器POMCP，在24点游戏中实现了89.4%的高解决率，超越了现有技术，并在随时性能上优于以往的固定树搜索方法。这些贡献使得现代语言模型能够更高效地分解和处理更复杂的推理任务。",
    "title_cn": "思维蓝图：借助大型语言模型实现启发式问题解决策略",
    "tags": [
      "分类：LLM应用\n\n这篇论文讨论了语言模型在零样本推理任务中的应用，特别是针对需要连续推理的问题。作者提出了一种基于规划的方法，通过部分可观测马尔可夫决策过程（POMDPs）和在线POMDP求解器POMCP来提高语言模型在复杂推理任务中的表现。这篇论文的研究重点在于提高语言模型在特定任务上的应用效果，因此可以归类为LLM应用。",
      "人工智能",
      ""
    ]
  },
  {
    "title": "A Framework for Real-time Safeguarding the Text Generation of Large Language",
    "submit_datetime": "2024年04月29日",
    "abstract": "Large Language Models (LLMs) have significantly advanced natural language processing (NLP) tasks but also pose ethical and societal risks due to their propensity to generate harmful content. To address this, various approaches have been developed to safeguard LLMs from producing unsafe content. However, existing methods have limitations, including the need for training specific control models and proactive intervention during text generation, that lead to quality degradation and increased computational overhead. To mitigate those limitations, we propose LLMSafeGuard, a lightweight framework to safeguard LLM text generation in real-time. LLMSafeGuard integrates an external validator into the beam search algorithm during decoding, rejecting candidates that violate safety constraints while allowing valid ones to proceed. We introduce a similarity based validation approach, simplifying constraint introduction and eliminating the need for control model training. Additionally, LLMSafeGuard employs a context-wise timing selection strategy, intervening LLMs only when necessary. We evaluate LLMSafe-Guard on two tasks, detoxification and copyright safeguarding, and demonstrate its superior performance over SOTA baselines. For instance, LLMSafeGuard reduces the average toxic score of. LLM output by 29.7% compared to the best baseline meanwhile preserving similar linguistic quality as natural output in detoxification task. Similarly, in the copyright task, LLMSafeGuard decreases the Longest Common Subsequence (LCS) by 56.2% compared to baselines. Moreover, our context-wise timing selection strategy reduces inference time by at least 24% meanwhile maintaining comparable effectiveness as validating each time step. LLMSafeGuard also offers tunable parameters to balance its effectiveness and efficiency.",
    "pdf_link": "https://arxiv.org/abs/2404.19048",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.19048v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19048/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19048v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19048/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19048v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19048/x3.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）在自然语言处理（NLP）领域取得了显著进步，但同时也因其可能产生有害内容而引发伦理和社会责任问题。为应对这一挑战，已开发出多种方法来防止LLMs生成危险内容。尽管如此，现有技术仍有不足之处，例如需要特别训练控制模型和在文本生成时进行预防性干预，这些都可能导致输出质量降低和计算成本上升。针对这些限制，我们设计了LLMSafeGuard——一个轻量级的实时文本生成保护框架。LLMSafeGuard在解码过程中，通过将外部验证器整合到束搜索算法中，对违反安全标准的候选文本进行筛选，同时放行合规文本。我们提出了一种基于相似度的验证方法，简化了安全约束的设置，并且避免了控制模型的训练需求。此外，LLMSafeGuard还采用了一种上下文感知的时机选择策略，仅在必要时对LLMs进行干预。我们在文本净化和版权保护两个任务上对LLMSafeGuard进行了评估，结果表明其性能超越了现有的最先进基线。例如，在文本净化任务中，LLMSafeGuard将LLM输出的平均有害性评分降低了29.7%，与自然输出的语言质量不相上下。在版权保护任务中，LLMSafeGuard将最长公共子序列（LCS）的比率降低了56.2%。同时，我们的上下文感知时机选择策略至少减少了24%的推理时间，而有效性却不打折扣。LLMSafeGuard还提供了可调节参数，以便在有效性和效率之间取得平衡。",
    "title_cn": "构建了一个实时保障大型语言模型文本生成安全的框架。",
    "tags": [
      "LLM应用",
      "",
      "伦理合规"
    ]
  },
  {
    "title": "Multi-Page Document Visual Question Answering using Self-Attention Scoring Mechanism",
    "submit_datetime": "2024年04月29日",
    "abstract": "Documents are 2-dimensional carriers of written communication, and as such their interpretation requires a multi-modal approach where textual and visual information are efficiently combined. Document Visual Question Answering (Document VQA), due to this multi-modal nature, has garnered significant interest from both the document understanding and natural language processing communities. The state-of-the-art single-page Document VQA methods show impressive performance, yet in multi-page scenarios, these methods struggle. They have to concatenate all pages into one large page for processing, demanding substantial GPU resources, even for evaluation. In this work, we propose a novel method and efficient training strategy for multi-page Document VQA tasks. In particular, we employ a visual-only document representation, leveraging the encoder from a document understanding model, Pix2Struct. Our approach utilizes a self-attention scoring mechanism to generate relevance scores for each document page, enabling the retrieval of pertinent pages. This adaptation allows us to extend single-page Document VQA models to multi-page scenarios without constraints on the number of pages during evaluation, all with minimal demand for GPU resources. Our extensive experiments demonstrate not only achieving state-of-the-art performance without the need for Optical Character Recognition (OCR), but also sustained performance in scenarios extending to documents of nearly 800 pages compared to a maximum of 20 pages in the MP-DocVQA dataset. Our code is publicly available at \\url{https://github.com/leitro/SelfAttnScoring-MPDocVQA}.",
    "pdf_link": "https://arxiv.org/abs/2404.19024",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.19024v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19024/text2pixel_h.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19024v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19024/arch.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19024v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19024/scoring_h.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19024v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19024/histo_pages_h.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19024v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19024/heatmap_page.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19024v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19024/heatmap_anls.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19024v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19024/case10_a.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19024v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19024/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19024v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19024/case00_a.png"
      }
    ],
    "abstract_cn": "文档作为承载书面交流的二维平台，解读它们需融合文本与视觉信息，采取多模态策略。正因如此，文档视觉问答（Document VQA）在文档理解与自然语言处理领域备受关注。尽管现有的单页文档 VQA 技术表现出色，但在处理多页文档时却力有未逮，常需将多页合并为一，以适应处理需求，这对 GPU 资源的消耗甚大。本研究提出了一种创新的多页文档 VQA 方法和高效的训练策略。我们引入了一种视觉主导的文档表达方式，借助文档理解模型 Pix2Struct 中的编码器，并通过自注意力机制为文档各页打分，筛选出关键页面。这种方法让我们得以在评估时不受页面数量限制地将单页模型扩展至多页场景，同时大幅降低了对 GPU 资源的依赖。实验结果表明，我们的方法不仅在无需光学字符识别（OCR）的情况下达到了业界领先水平，而且在处理接近 800 页的文档时仍能保持性能，远超 MP-DocVQA 数据集中最多 20 页的极限。相关代码已在 \\url{https://github.com/leitro/SelfAttnScoring-MPDocVQA} 上开源。",
    "title_cn": "利用自注意力评分机制进行多页文档的视觉问答解答",
    "tags": [
      "分类：Agent",
      "文档理解",
      ""
    ]
  },
  {
    "title": "Towards Generalizable Agents in Text-Based Educational Environments: A Study of Integrating RL with LLMs",
    "submit_datetime": "2024年04月29日",
    "abstract": "There has been a growing interest in developing learner models to enhance learning and teaching experiences in educational environments. However, existing works have primarily focused on structured environments relying on meticulously crafted representations of tasks, thereby limiting the agent's ability to generalize skills across tasks. In this paper, we aim to enhance the generalization capabilities of agents in open-ended text-based learning environments by integrating Reinforcement Learning (RL) with Large Language Models (LLMs). We investigate three types of agents: (i) RL-based agents that utilize natural language for state and action representations to find the best interaction strategy, (ii) LLM-based agents that leverage the model's general knowledge and reasoning through prompting, and (iii) hybrid LLM-assisted RL agents that combine these two strategies to improve agents' performance and generalization. To support the development and evaluation of these agents, we introduce PharmaSimText, a novel benchmark derived from the PharmaSim virtual pharmacy environment designed for practicing diagnostic conversations. Our results show that RL-based agents excel in task completion but lack in asking quality diagnostic questions. In contrast, LLM-based agents perform better in asking diagnostic questions but fall short of completing the task. Finally, hybrid LLM-assisted RL agents enable us to overcome these limitations, highlighting the potential of combining RL and LLMs to develop high-performing agents for open-ended learning environments.",
    "pdf_link": "https://arxiv.org/abs/2404.18978",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.18978v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18978/pharmasim.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18978v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18978/pharmasim_process.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18978v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18978/llm-rl.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18978v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18978/wording_example.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18978v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18978/wording_result.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18978v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18978/reflective.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18978v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18978/patient_vs_agent.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18978v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18978/conversation.png"
      }
    ],
    "abstract_cn": "教育领域内，人们越来越关注开发学习者模型以提升学习和教学体验。但目前的研究多集中于结构化环境，依赖于精心设计的任务表示，这限制了智能体跨任务泛化技能的能力。本文旨在通过融合强化学习（RL）与大型语言模型（LLMs），提升智能体在开放性文本学习环境中的泛化能力。我们探讨了三种智能体：（i）利用自然语言进行状态和动作表示的RL型智能体，寻找最佳互动策略；（ii）通过提示运用模型的通用知识和推理的LLM型智能体；（iii）结合这两种策略以提升性能和泛化能力的混合LLM辅助RL型智能体。为促进这些智能体的发展和评估，我们提出了PharmaSimText，这是一个新的基准测试，源自用于练习诊断对话的PharmaSim虚拟药房环境。研究结果显示，RL型智能体在任务完成方面表现优异，但在提出高质量诊断问题上有所欠缺。而LLM型智能体在提出诊断问题上表现更佳，但完成任务的能力不足。最终，混合LLM辅助RL型智能体使我们能够突破这些局限，展现了结合RL与LLMs以开发开放式学习环境高性能智能体的巨大潜力。",
    "title_cn": "探索文本教育环境中的通用化智能体：研究强化学习与大型语言模型融合的实践",
    "tags": [
      "Agent",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Foundations of Multisensory Artificial Intelligence",
    "submit_datetime": "2024年04月29日",
    "abstract": "Building multisensory AI systems that learn from multiple sensory inputs such as text, speech, video, real-world sensors, wearable devices, and medical data holds great promise for impact in many scientific areas with practical benefits, such as in supporting human health and well-being, enabling multimedia content processing, and enhancing real-world autonomous agents. By synthesizing a range of theoretical frameworks and application domains, this thesis aims to advance the machine learning foundations of multisensory AI. In the first part, we present a theoretical framework formalizing how modalities interact with each other to give rise to new information for a task. These interactions are the basic building blocks in all multimodal problems, and their quantification enables users to understand their multimodal datasets, design principled approaches to learn these interactions, and analyze whether their model has succeeded in learning. In the second part, we study the design of practical multimodal foundation models that generalize over many modalities and tasks, which presents a step toward grounding large language models to real-world sensory modalities. We introduce MultiBench, a unified large-scale benchmark across a wide range of modalities, tasks, and research areas, followed by the cross-modal attention and multimodal transformer architectures that now underpin many of today's multimodal foundation models. Scaling these architectures on MultiBench enables the creation of general-purpose multisensory AI systems, and we discuss our collaborative efforts in applying these models for real-world impact in affective computing, mental health, cancer prognosis, and robotics. Finally, we conclude this thesis by discussing how future work can leverage these ideas toward more general, interactive, and safe multisensory AI.",
    "pdf_link": "https://arxiv.org/abs/2404.18976",
    "graphs": [],
    "abstract_cn": "本研究致力于开发能够整合文本、语音、视频、传感器数据等多种感官信息的多感官人工智能系统，这些系统在促进人类健康、处理多媒体内容以及提升自主智能体性能等多个科学领域具有重要应用价值。本文首先构建了一个理论框架，阐释了不同感官模态如何相互交互以生成新信息，这些交互是解决多模态问题的关键，有助于深入理解数据集、设计学习交互的方法，并评估模型学习效果。接着，研究了一种实用的多模态基础模型，它能够跨越多种感官和任务，为大型语言模型与现实世界感官模态的结合提供了新途径。我们提出了MultiBench，一个覆盖广泛模态、任务和研究领域的大规模统一基准，以及支撑当前许多多模态基础模型的跨模态注意力和多模态变换器架构。通过在MultiBench上扩展这些架构，我们能够构建出通用的多感官AI系统，并探讨了如何将这些模型应用于情感计算、心理健康、癌症预后和机器人技术等领域，以实现现实世界的影响。最后，论文以讨论如何利用这些研究成果推动多感官AI向更通用、互动和安全方向发展作为结尾。",
    "title_cn": "多感官人工智能之基石",
    "tags": [
      "分类：Agent",
      "人工智能",
      "多模态交互"
    ]
  },
  {
    "title": "The Convergence of AI and Synthetic Biology: The Looming Deluge",
    "submit_datetime": "2024年04月29日",
    "abstract": "The convergence of artificial intelligence (AI) and synthetic biology is rapidly accelerating the pace of biological discovery and engineering. AI techniques, such as large language models and biological design tools, are enabling the automated design, build, test, and learning cycles for engineered biological systems. This convergence promises to democratize synthetic biology and unlock novel applications across domains from medicine to environmental sustainability. However, it also poses significant risks around reliability, dual use, and governance. The opacity of AI models, the deskilling of workforces, and the outdated nature of current regulatory frameworks present challenges in ensuring responsible development. Urgent attention is needed to update governance structures, integrate human oversight into increasingly automated workflows, and foster a culture of responsibility among the growing community of bioengineers. Only by proactively addressing these issues can we realize the transformative potential of AI-driven synthetic biology while mitigating its risks.",
    "pdf_link": "https://arxiv.org/abs/2404.18973",
    "graphs": [],
    "abstract_cn": "AI与合成生物学的结合正推动生物探索和工程领域飞速发展。借助大型语言模型和生物设计工具等AI技术，我们能够自动化地设计、构建、测试并学习工程生物系统。这一趋势预示着合成生物学的普及化，并将在医疗、环保等多个领域带来创新应用。但同时，它也引发了一系列关于可靠性、双重用途和治理的重大风险。AI模型的不透明性、劳动力技能降低以及现行监管框架的不适应性，都对负责任的技术开发构成了挑战。迫切需要对治理结构进行更新，将人工监督融入日益自动化的工作流程，并在生物工程领域培养起责任感。唯有积极应对这些挑战，我们才能在降低风险的同时，充分挖掘AI驱动合成生物学的变革性潜力。",
    "title_cn": "人工智能与合成生物学的结合：迫在眉睫的洪流。",
    "tags": [
      "分类：Agent\n\n这篇论文讨论了AI技术，特别是大型语言模型在合成生物学领域的应用，以及这些技术带来的挑战和风险。它涉及到AI代理（Agent）在自动化设计、构建、测试和学习工程生物系统方面的作用，以及对这些代理进行治理和监管的必要性。因此，这篇论文最符合Agent分类。",
      "合成生物学",
      "人工智能"
    ]
  },
  {
    "title": "GRAMMAR: Grounded and Modular Evaluation of Domain-Specific Retrieval-Augmented Language Models",
    "submit_datetime": "2024年04月29日",
    "abstract": "Retrieval-augmented Generation (RAG) systems have been actively studied and deployed across various industries to query on domain-specific knowledge base. However, evaluating these systems presents unique challenges due to the scarcity of domain-specific queries and corresponding ground truths, as well as a lack of systematic approaches to diagnosing the cause of failure cases -- whether they stem from knowledge deficits or issues related to system robustness. To address these challenges, we introduce GRAMMAR (GRounded And Modular Methodology for Assessment of RAG), an evaluation framework comprising two key elements: 1) a data generation process that leverages relational databases and LLMs to efficiently produce scalable query-answer pairs. This method facilitates the separation of query logic from linguistic variations for enhanced debugging capabilities; and 2) an evaluation framework that differentiates knowledge gaps from robustness and enables the identification of defective modules. Our empirical results underscore the limitations of current reference-free evaluation approaches and the reliability of GRAMMAR to accurately identify model vulnerabilities.",
    "pdf_link": "https://arxiv.org/abs/2404.19232",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.19232v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19232/group_types.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19232v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19232/data_gen_2.0.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19232v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19232/db_schema.png"
      },
      {
        "url": "https://arxiv.org/html/2404.19232v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.19232/db_schema_aurp_no_location.png"
      }
    ],
    "abstract_cn": "检索增强生成（RAG）系统在各行业被广泛研究和应用，主要针对特定领域的知识库查询。但评估这些系统时，由于缺乏特定领域的查询和真实答案，以及缺少系统化诊断失败原因的方法，面临不少挑战。为此，我们提出了GRAMMAR（一种评估RAG的有根据且模块化的方法），它包含两个核心部分：首先是一个数据生成流程，它结合关系数据库和大型语言模型（LLMs）来高效产出可扩展的查询-答案对，这种方法有助于将查询逻辑与语言变化分离，从而提升调试效率；其次是一个评估框架，它能够区分知识缺陷和系统鲁棒性问题，并识别出有问题的模块。我们的实证研究结果揭示了现有无参照评估方法的不足，并证明了GRAMMAR在准确识别模型弱点方面的可靠性。",
    "title_cn": "《语法：领域特定检索增强语言模型的实证与模块化评估》",
    "tags": [
      "RAG",
      "数据库管理",
      "人工智能"
    ]
  },
  {
    "title": "Simplifying Multimodality: Unimodal Approach to Multimodal Challenges in Radiology with General-Domain Large Language Model",
    "submit_datetime": "2024年04月29日",
    "abstract": "Recent advancements in Large Multimodal Models (LMMs) have attracted interest in their generalization capability with only a few samples in the prompt. This progress is particularly relevant to the medical domain, where the quality and sensitivity of data pose unique challenges for model training and application. However, the dependency on high-quality data for effective in-context learning raises questions about the feasibility of these models when encountering with the inevitable variations and errors inherent in real-world medical data. In this paper, we introduce MID-M, a novel framework that leverages the in-context learning capabilities of a general-domain Large Language Model (LLM) to process multimodal data via image descriptions. MID-M achieves a comparable or superior performance to task-specific fine-tuned LMMs and other general-domain ones, without the extensive domain-specific training or pre-training on multimodal data, with significantly fewer parameters. This highlights the potential of leveraging general-domain LLMs for domain-specific tasks and offers a sustainable and cost-effective alternative to traditional LMM developments. Moreover, the robustness of MID-M against data quality issues demonstrates its practical utility in real-world medical domain applications.",
    "pdf_link": "https://arxiv.org/abs/2405.01591",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.01591v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01591/figure1_0409_LT.png"
      }
    ],
    "abstract_cn": "近期大型多模态模型（LMMs）的突破因其在少量样本提示下的泛化能力而备受关注。尤其在医学领域，这一进步尤为关键，因为数据的质量和敏感性对模型的训练和应用提出了特别的挑战。尽管如此，有效的上下文学习对高质量数据的依赖性，对于模型在面对现实世界医学数据中固有的变异和错误时的可行性提出了疑问。本文提出了MID-M，这是一个创新框架，它利用通用领域的大型语言模型（LLM）的上下文学习能力，通过图像描述来处理多模态数据。MID-M在性能上可与特定任务微调的LMMs及其他通用领域模型相媲美甚至更优，而且避免了大规模的领域特定训练或多模态数据的预训练，显著减少了参数数量。这不仅凸显了利用通用领域LLMs解决特定领域任务的潜力，而且为传统LMM开发提供了一种经济且可持续的替代方案。MID-M对数据质量问题的强鲁棒性，也证明了其在实际医学应用中的实用价值。",
    "title_cn": "化繁为简：在放射学领域，运用通用的大型语言模型，以单模态策略应对多模态挑战。",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "PoPE: Legendre Orthogonal Polynomials Based Position Encoding for Large Language Models",
    "submit_datetime": "2024年04月29日",
    "abstract": "There are several improvements proposed over the baseline Absolute Positional Encoding (APE) method used in original transformer. In this study, we aim to investigate the implications of inadequately representing positional encoding in higher dimensions on crucial aspects of the attention mechanism, the model's capacity to learn relative positional information, and the convergence of models, all stemming from the choice of sinusoidal basis functions. Through a combination of theoretical insights and empirical analyses, we elucidate how these challenges extend beyond APEs and may adversely affect the performance of Relative Positional Encoding (RPE) methods, such as Rotatory Positional Encoding (RoPE).\n  Subsequently, we introduce an innovative solution termed Orthogonal Polynomial Based Positional Encoding (PoPE) to address some of the limitations associated with existing methods. The PoPE method encodes positional information by leveraging Orthogonal Legendre polynomials. Legendre polynomials as basis functions offers several desirable properties for positional encoding, including improved correlation structure, non-periodicity, orthogonality, and distinct functional forms among polynomials of varying orders. Our experimental findings demonstrate that transformer models incorporating PoPE outperform baseline transformer models on the $Multi30k$ English-to-German translation task, thus establishing a new performance benchmark. Furthermore, PoPE-based transformers exhibit significantly accelerated convergence rates.\n  Additionally, we will present novel theoretical perspectives on position encoding based on the superior performance of PoPE.",
    "pdf_link": "https://arxiv.org/abs/2405.04585",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.04585v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04585/figure_cosinemap.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.04585v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04585/cosine_head_scaled.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.04585v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04585/Fig_legendre.png"
      },
      {
        "url": "https://arxiv.org/html/2405.04585v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04585/figure_legendremap.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.04585v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04585/poly_head4.jpg"
      },
      {
        "url": "https://arxiv.org/html/2405.04585v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.04585/training_loss.jpg"
      }
    ],
    "abstract_cn": "本研究探讨了在更高维度上位置编码不足对transformer模型的注意力机制、学习相对位置信息的能力以及模型收敛性的影响，特别是正弦基函数的选择所导致的挑战。我们发现，这些挑战不仅限于绝对位置编码（APE），还可能影响相对位置编码（RPE）方法，如旋转位置编码（RoPE）。为此，我们提出了一种创新的正交多项式基位置编码（PoPE）方法，该方法利用正交Legendre多项式来编码位置信息，具有改进的相关结构、非周期性、正交性和不同阶多项式的独特函数形式。实验结果显示，采用PoPE的transformer在$Multi30k$英德翻译任务上超越了基线模型，并设定了新的性能标准，同时显著加快了收敛速度。此外，我们将基于PoPE的卓越性能，提出关于位置编码的新理论视角。",
    "title_cn": "勒让德正交编码：为大型语言模型量身定制的位置编码新篇章在翻译过程中，我首先确保了原文核心概念的准确传达，即“PoPE”和“勒让德正交多项式”作为位置编码方法在大型语言模型中的应用。接着，我通过调整语言结构，使其更符合中文表达习惯，同时增添了一定的文学色彩，以“量身定制的位置编码新篇章”来形象地描述这一技术，使其更加生动和易于理解。",
    "tags": [
      "LLM理论\n\n这篇论文探讨了位置编码对transformer模型性能的影响，并提出了一种新的位置编码方法（PoPE）。它涉及了大型语言模型（LLM）的理论层面，特别是在位置编码和模型收敛性方面的研究，因此属于LLM理论分类。论文中提出的PoPE方法是对现有位置编码方法的改进，旨在提高模型的性能和收敛速度，这表明了它在LLM理论研究中的重要性。",
      "",
      "机器翻译"
    ]
  },
  {
    "title": "Mixture-of-Instructions: Comprehensive Alignment of a Large Language Model through the Mixture of Diverse System Prompting Instructions",
    "submit_datetime": "2024年04月28日",
    "abstract": "With the proliferation of large language models (LLMs), the comprehensive alignment of such models across multiple tasks has emerged as a critical area of research. Existing alignment methodologies primarily address single task, such as multi-turn dialogue, coding, mathematical problem-solving, and tool usage. However, AI-driven products that leverage language models usually necessitate a fusion of these abilities to function effectively in real-world scenarios. Moreover, the considerable computational resources required for proper alignment of LLMs underscore the need for a more robust, efficient, and encompassing approach to multi-task alignment, ensuring improved generative performance. In response to these challenges, we introduce a novel technique termed Mixture-of-Instructions (MoI), which employs a strategy of instruction concatenation combined with diverse system prompts to boost the alignment efficiency of language models. We have also compiled a diverse set of seven benchmark datasets to rigorously evaluate the alignment efficacy of the MoI-enhanced language model. Our methodology was applied to the open-source Qwen-7B-chat model, culminating in the development of Qwen-SFT-MoI. This enhanced model demonstrates significant advancements in generative capabilities across coding, mathematics, and tool use tasks.",
    "pdf_link": "https://arxiv.org/abs/2404.18410",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）的广泛使用催生了对这些模型在多样化任务中进行综合对齐的研究需求。目前，主流的对齐技术多聚焦于单一任务，比如多轮对话、编程、数学问题求解和工具应用等。但在现实世界的应用场景中，AI产品往往需要整合这些不同的能力来实现高效运作。此外，为了实现LLMs的精准对齐，所需的庞大计算资源也凸显了开发一种更为强大、高效且全面的多任务对齐方法的必要性，以提升模型的生成性能。面对这些挑战，我们提出了一种创新技术——指令混合（MoI），它通过指令串联和多样化的系统提示来增强语言模型的对齐效率。我们还特别设计了包含七个不同基准数据集的集合，用以严格测试MoI增强模型的对齐效果。该技术被应用于开源的Qwen-7B-chat模型，进而发展出了Qwen-SFT-MoI模型。这一增强版模型在编程、数学和工具使用等多个任务上展现了显著的生成能力提升。",
    "title_cn": "通过多样化的系统提示指令混合，实现对大型语言模型的全面校准。",
    "tags": [
      "LLM应用",
      "人工智能",
      "多任务学习"
    ]
  },
  {
    "title": "LLM-SR: Scientific Equation Discovery via Programming with Large Language Models",
    "submit_datetime": "2024年04月28日",
    "abstract": "Mathematical equations have been unreasonably effective in describing complex natural phenomena across various scientific disciplines. However, discovering such insightful equations from data presents significant challenges due to the necessity of navigating extremely high-dimensional combinatorial and nonlinear hypothesis spaces. Traditional methods of equation discovery largely focus on extracting equations from data alone, often neglecting the rich domain-specific prior knowledge that scientists typically depend on. To bridge this gap, we introduce LLM-SR, a novel approach that leverages the extensive scientific knowledge and robust code generation capabilities of Large Language Models (LLMs) to discover scientific equations from data in an efficient manner. Specifically, LLM-SR treats equations as programs with mathematical operators and combines LLMs' scientific priors with evolutionary search over equation programs. The LLM iteratively proposes new equation skeletons, drawing from its physical understanding, which are then optimized against data to estimate skeleton parameters. We demonstrate LLM-SR's effectiveness across three diverse scientific domains, where it discovers physically accurate equations that provide significantly better fits to in-domain and out-of-domain data compared to the well-established equation discovery baselines",
    "pdf_link": "https://arxiv.org/abs/2404.18400",
    "graphs": [],
    "abstract_cn": "数学方程在刻画自然现象的复杂性方面显示出惊人的效力，这跨越了众多科学领域。但要从数据中发掘出这些富有洞察力的方程，却因必须探索高维的组合与非线性假设空间而充满挑战。传统上，方程发现主要依赖于数据本身，往往忽略了科学家们所依赖的深厚领域知识。为了填补这一空白，我们提出了 LLM-SR，这是一种创新的方法，它借助大型语言模型（LLMs）的丰富科学知识库和强大的编程生成能力，高效地从数据中发掘科学方程。具体而言，LLM-SR 将方程视为程序，运用数学运算符，结合 LLMs 的科学知识先验与方程程序的进化搜索。LLM 会迭代提出新的方程框架，利用其对物理世界的理解，然后根据数据进行优化以确定框架参数。我们在三个不同的科学领域验证了 LLM-SR 的效力，它所发掘的物理上准确的方程在适应领域内外数据方面，相比传统方程发现方法，提供了更为精准的拟合结果。",
    "title_cn": "LLM-SR：借助大型语言模型编程，探索科学方程式的奥秘",
    "tags": [
      "LLM应用",
      "科学计算",
      "数据挖掘"
    ]
  },
  {
    "title": "6G comprehensive intelligence: network operations and optimization based on Large Language Models",
    "submit_datetime": "2024年04月28日",
    "abstract": "The sixth generation mobile communication standard (6G) can promote the development of Industrial Internet and Internet of Things (IoT). To achieve comprehensive intelligent development of the network and provide customers with higher quality personalized services. This paper proposes a network performance optimization and intelligent operation network architecture based on Large Language Model (LLM), aiming to build a comprehensive intelligent 6G network system. The Large Language Model, with more parameters and stronger learning ability, can more accurately capture patterns and features in data, which can achieve more accurate content output and high intelligence and provide strong support for related research such as network data security, privacy protection, and health assessment. This paper also presents the design framework of a network health assessment system based on LLM and focuses on its potential application value, through the case of network health management system, it is fully demonstrated that the 6G intelligent network system based on LLM has important practical significance for the comprehensive realization of intelligence.",
    "pdf_link": "https://arxiv.org/abs/2404.18373",
    "graphs": [],
    "abstract_cn": "第六代移动通信技术（6G）将推动工业互联网和物联网（IoT）的蓬勃发展，旨在实现网络的全面智能化，为用户带来更优质的定制服务。本研究提出了一种依托于大型语言模型（LLM）的网络性能优化与智能运维架构，致力于构建一个全方位的智能6G网络体系。LLM凭借其庞大的参数量和卓越的学习能力，能够精准捕捉数据模式与特征，实现精准的内容输出，展现出高效的智能性能，为网络数据安全、隐私保护和健康评估等研究领域提供坚实支撑。文章还展示了基于LLM的网络健康评估系统设计框架，并着重探讨了其应用潜力，通过网络健康管理系统的实例，充分证明了LLM驱动的6G智能网络系统在推动智能化全面实现方面具有显著的实用价值。",
    "title_cn": "6G 综合智能时代，网络的运营与优化将依托于大型语言模型的先进能力。",
    "tags": [
      "LLM应用",
      "通信技术",
      "工业互联网"
    ]
  },
  {
    "title": "QANA: LLM-based Question Generation and Network Analysis for Zero-shot Key Point Analysis and Beyond",
    "submit_datetime": "2024年04月28日",
    "abstract": "The proliferation of social media has led to information overload and increased interest in opinion mining. We propose \"Question-Answering Network Analysis\" (QANA), a novel opinion mining framework that utilizes Large Language Models (LLMs) to generate questions from users' comments, constructs a bipartite graph based on the comments' answerability to the questions, and applies centrality measures to examine the importance of opinions. We investigate the impact of question generation styles, LLM selections, and the choice of embedding model on the quality of the constructed QA networks by comparing them with annotated Key Point Analysis datasets. QANA achieves comparable performance to previous state-of-the-art supervised models in a zero-shot manner for Key Point Matching task, also reducing the computational cost from quadratic to linear. For Key Point Generation, questions with high PageRank or degree centrality align well with manually annotated key points. Notably, QANA enables analysts to assess the importance of key points from various aspects according to their selection of centrality measure. QANA's primary contribution lies in its flexibility to extract key points from a wide range of perspectives, which enhances the quality and impartiality of opinion mining.",
    "pdf_link": "https://arxiv.org/abs/2404.18371",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.18371v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18371/overview.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18371v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18371/example.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18371v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18371/result1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18371v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18371/result2.png"
      }
    ],
    "abstract_cn": "社交媒体的广泛传播引起信息泛滥，同时也激发了对意见挖掘的浓厚兴趣。我们引入了一种创新的意见挖掘框架——“问答网络分析”（QANA），它使用大型语言模型（LLMs）来从用户评论生成问题，构建基于评论对这些问题可回答性的二分图，并采用中心性度量来评估意见的重要程度。通过与标注的关键点分析数据集进行比较，我们探究了问题生成方式、LLM选择以及嵌入模型选择对所构建QA网络质量的影响。QANA在零样本学习环境中，其关键点匹配任务的性能与现有的最先进监督模型相当，同时将计算成本从二次降低到线性。在关键点生成方面，高PageRank或度中心性的问题与人工标注的关键点高度一致。QANA的显著优势在于其能够从多角度评估关键点的重要性，这不仅提升了意见挖掘的质量，也增强了其公正性。",
    "title_cn": "QANA：利用大型语言模型（LLM）进行问题生成与网络分析，旨在实现零样本关键点分析及其扩展应用。",
    "tags": [
      "LLM应用",
      "社交媒体分析",
      "意见挖掘"
    ]
  },
  {
    "title": "FoundaBench: Evaluating Chinese Fundamental Knowledge Capabilities of Large Language Models",
    "submit_datetime": "2024年04月28日",
    "abstract": "In the burgeoning field of large language models (LLMs), the assessment of fundamental knowledge remains a critical challenge, particularly for models tailored to Chinese language and culture. This paper introduces FoundaBench, a pioneering benchmark designed to rigorously evaluate the fundamental knowledge capabilities of Chinese LLMs. FoundaBench encompasses a diverse array of 3354 multiple-choice questions across common sense and K-12 educational subjects, meticulously curated to reflect the breadth and depth of everyday and academic knowledge. We present an extensive evaluation of 12 state-of-the-art LLMs using FoundaBench, employing both traditional assessment methods and our CircularEval protocol to mitigate potential biases in model responses. Our results highlight the superior performance of models pre-trained on Chinese corpora, and reveal a significant disparity between models' reasoning and memory recall capabilities. The insights gleaned from FoundaBench evaluations set a new standard for understanding the fundamental knowledge of LLMs, providing a robust framework for future advancements in the field.",
    "pdf_link": "https://arxiv.org/abs/2404.18359",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.18359v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18359/figure1_FoundaBench_Overview.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18359v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18359/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18359v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18359/barchart1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18359v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18359/example1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18359v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18359/example3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18359v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18359/example2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18359v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18359/example4.png"
      }
    ],
    "abstract_cn": "在蓬勃发展的大型语言模型（LLMs）领域，准确评估模型的基础知识水平尤为关键，尤其是那些专为中文语言和文化量身定制的模型。本文提出了FoundaBench，这是一个创新的基准测试工具，用以严格检验中文LLMs的基础知识掌握程度。FoundaBench精心设计了3354道多项选择题，覆盖常识和K-12教育主题，全面反映了日常生活和学术领域的知识。我们对12个顶尖的LLMs进行了深入评估，不仅采用了传统评估方法，还引入了CircularEval协议，以减少模型回答中的潜在偏差。评估结果显示，基于中文语料库预训练的模型性能更为出色，并指出了模型在推理和记忆回忆能力上存在显著差异。FoundaBench的评估结果不仅为理解LLMs的基础知识提供了新的视角，也为未来该领域的研究进步奠定了坚实的基础。",
    "title_cn": "FoundaBench：探究大型语言模型在中文基础知识掌握上的评估",
    "tags": [
      "LLM理论",
      "",
      ""
    ]
  },
  {
    "title": "Do Neutral Prompts Produce Insecure Code? FormAI-v2 Dataset: Labelling Vulnerabilities in Code Generated by Large Language Models",
    "submit_datetime": "2024年04月28日",
    "abstract": "This study provides a comparative analysis of state-of-the-art large language models (LLMs), analyzing how likely they generate vulnerabilities when writing simple C programs using a neutral zero-shot prompt. We address a significant gap in the literature concerning the security properties of code produced by these models without specific directives. N. Tihanyi et al. introduced the FormAI dataset at PROMISE '23, containing 112,000 GPT-3.5-generated C programs, with over 51.24% identified as vulnerable. We expand that work by introducing the FormAI-v2 dataset comprising 265,000 compilable C programs generated using various LLMs, including robust models such as Google's GEMINI-pro, OpenAI's GPT-4, and TII's 180 billion-parameter Falcon, to Meta's specialized 13 billion-parameter CodeLLama2 and various other compact models. Each program in the dataset is labelled based on the vulnerabilities detected in its source code through formal verification using the Efficient SMT-based Context-Bounded Model Checker (ESBMC). This technique eliminates false positives by delivering a counterexample and ensures the exclusion of false negatives by completing the verification process. Our study reveals that at least 63.47% of the generated programs are vulnerable. The differences between the models are minor, as they all display similar coding errors with slight variations. Our research highlights that while LLMs offer promising capabilities for code generation, deploying their output in a production environment requires risk assessment and validation.",
    "pdf_link": "https://arxiv.org/abs/2404.18353",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.18353v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18353/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18353v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18353/moti.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18353v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18353/secure1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18353v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18353/sec2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18353v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18353/methodology.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18353v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18353/prompt.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18353v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18353/esbmc.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18353v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18353/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18353v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18353/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18353v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18353/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18353v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18353/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18353v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18353/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18353v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18353/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18353v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18353/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18353v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18353/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18353v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18353/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18353v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18353/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18353v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18353/Untitled.jpg"
      }
    ],
    "abstract_cn": "本研究对比分析了当前顶尖的大型语言模型（LLMs），探究了这些模型在采用中性零样本提示编写简易C程序时生成安全漏洞的倾向。此举填补了现有文献中关于这些模型在缺乏具体指令时所产生代码安全性特性的空白。在PROMISE '23会议上，N. Tihanyi等人提出了包含112,000个GPT-3.5生成的C程序的FormAI数据集，其中逾51.24%被认定为存在安全漏洞。我们在此基础上进一步工作，推出了包含265,000个可编译C程序的FormAI-v2数据集，这些程序由多种LLMs生成，包括谷歌的GEMINI-pro、OpenAI的GPT-4、TII的180亿参数Falcon，以及Meta的13亿参数专业模型CodeLLama2和其他多种紧凑型模型。数据集中每个程序的标签基于通过高效SMT（Satisfiability Modulo Theories）上下文有界模型检查器（ESBMC）的形式验证在其源代码中发现的漏洞。该技术通过提供反例来排除误报，并确保通过完成验证过程来避免漏报。研究发现至少63.47%的程序存在安全漏洞，不同模型之间的差异不大，它们都展现出类似的编码错误，只是有所变化。本研究强调，尽管LLMs在代码生成方面展现出巨大潜力，但在生产环境中应用其生成的代码前，必须进行风险评估和验证。",
    "title_cn": "中性的提示是否会导致代码安全性受损？FormAI-v2 数据集专注于识别并标记由大型语言模型生成的代码中的潜在安全漏洞。",
    "tags": [
      "LLM应用",
      "编程语言",
      "软件工程"
    ]
  },
  {
    "title": "BlockLLM: Multi-tenant Finer-grained Serving for Large Language Models",
    "submit_datetime": "2024年04月28日",
    "abstract": "The growing demand for Large Language Models (LLMs) across diverse applications has prompted a paradigm shift in the design of deep learning serving systems. Deploying LLMs, especially in multi-tenant environments, presents considerable challenges due to their high computational and memory demands. We present BlockLLM, a serving system that exploits the potential of sharing components among fine-tuned LLM models to offer an efficient and flexible solution for LLM workloads. BlockLLM partitions the models into finer-grained blocks to enable the reuse of model components and independent provisioning to improve the computation efficiency. BlockLLM consists of an offline block zoo, for storing the blocks, and an online system to serve the requests through chains of blocks. It offers multi-fold flexibility: (1) Adaptive assembly of block chains on-the-fly is achieved with the help of equivalence evaluation among blocks in the zoo. (2) We enable per-block batch size and configure best-effort KV cache coordination at individual block level. (3) We adopt speculative execution and locality-aware block placement to mitigate the communication costs from dynamic block resource allocation. Our evaluation demonstrates that BlockLLM reduces memory and storage footprints and improves computation efficiency, outperforming existing serving approach in 95\\%ile latency and GPU utilization by 33.5\\% and 20.1\\%, respectively.",
    "pdf_link": "https://arxiv.org/abs/2404.18322",
    "graphs": [],
    "abstract_cn": "随着大型语言模型（LLM）在多种应用中的广泛需求，深度学习服务系统的设计思路经历了一次重大变革。尤其在多租户环境下部署LLM面临着计算和内存需求高的挑战。为此，我们推出了BlockLLM，这是一款服务系统，它通过在微调后的LLM模型间共享组件，为LLM工作负载提供了一种既高效又灵活的处理方案。BlockLLM通过将模型划分为更细致的区块，实现了模型组件的复用和独立配置，优化了计算效率。系统包含一个用于存储区块的离线区块库和一个通过区块链处理请求的在线服务系统。BlockLLM展现了多重灵活性：(1) 利用区块库中的等价评估，实现了区块链的即时自适应组装；(2) 支持每个区块的批处理大小，并在各个区块级别上实施了最优的KV缓存协调；(3) 采用预测执行和本地感知的区块放置策略，以减少动态区块资源分配带来的通信开销。我们的评估结果证明，BlockLLM在减少内存和存储占用、提升计算效率方面表现卓越，与现有服务方法相比，在95%的延迟和GPU利用率上分别提升了33.5%和20.1%。",
    "title_cn": "BlockLLM：为大型语言模型打造多租户精细化服务",
    "tags": [
      "LLM应用",
      "深度学习服务",
      "区块链"
    ]
  },
  {
    "title": "Trends and Challenges of Real-time Learning in Large Language Models: A Critical Review",
    "submit_datetime": "2024年04月28日",
    "abstract": "Real-time learning concerns the ability of learning systems to acquire knowledge over time, enabling their adaptation and generalization to novel tasks. It is a critical ability for intelligent, real-world systems, especially when data may be insufficient or difficult to obtain. This review provides a comprehensive analysis of real-time learning in Large Language Models. It synthesizes the state-of-the-art real-time learning paradigms, including continual learning, meta-learning, parameter-efficient learning, and mixture-of-experts learning. We demonstrate their utility for real-time learning by describing specific achievements from these related topics and their critical factors. Finally, the paper highlights current problems and challenges for future research in the field. By consolidating the latest relevant research developments, this review offers a comprehensive understanding of real-time learning and its implications for designing and developing LLM-based learning systems addressing real-world problems.",
    "pdf_link": "https://arxiv.org/abs/2404.18311",
    "graphs": [],
    "abstract_cn": "实时学习是指学习系统能够随着时间的推移积累知识，从而实现对新任务的适应和泛化。这一能力对于智能化、实际应用的系统尤为关键，尤其是在数据获取受限或不足的情况下。本篇综述深入探讨了大型语言模型中的实时学习，涵盖了持续学习、元学习、参数高效学习以及专家混合学习等前沿学习范式。通过详细阐述这些领域的具体进展和关键要素，我们展示了这些范式在实时学习中的实际应用价值。文章最后指出了当前面临的挑战，并对未来研究方向提出了展望。通过汇总最新的研究成果，本综述旨在为设计和开发基于LLM的、能够应对现实世界问题的智能学习系统提供全面的理论支持。",
    "title_cn": "大型语言模型实时学习的潮流与难题：深入剖析",
    "tags": [
      "LLM理论",
      "人工智能",
      "机器学习"
    ]
  },
  {
    "title": "Comparing LLM prompting with Cross-lingual transfer performance on Indigenous and Low-resource Brazilian Languages",
    "submit_datetime": "2024年04月28日",
    "abstract": "Large Language Models are transforming NLP for a variety of tasks. However, how LLMs perform NLP tasks for low-resource languages (LRLs) is less explored. In line with the goals of the AmeicasNLP workshop, we focus on 12 LRLs from Brazil, 2 LRLs from Africa and 2 high-resource languages (HRLs) (e.g., English and Brazilian Portuguese). Our results indicate that the LLMs perform worse for the part of speech (POS) labeling of LRLs in comparison to HRLs. We explain the reasons behind this failure and provide an error analyses through examples observed in our data set.",
    "pdf_link": "https://arxiv.org/abs/2404.18286",
    "graphs": [],
    "abstract_cn": "大型语言模型正重塑多任务自然语言处理的格局。但对于低资源语言的任务执行情况，研究尚显不足。本研究响应 AmeicasNLP 研讨会的议程，聚焦巴西的12种低资源语言、非洲的两种以及英语和巴西葡萄牙语等两种高资源语言。研究发现，LLMs 在这些低资源语言的词性标注任务上的表现不及高资源语言。文章深入探讨了这一现象的成因，并通过实例分析，对错误进行了详细解读。",
    "title_cn": "本文旨在探讨大型语言模型在处理土著和资源匮乏的巴西语言时，其提示策略与跨语言迁移性能之间的比较。",
    "tags": [
      "LLM应用",
      "",
      "语言资源"
    ]
  },
  {
    "title": "Bias Neutralization Framework: Measuring Fairness in Large Language Models with Bias Intelligence Quotient (BiQ)",
    "submit_datetime": "2024年04月28日",
    "abstract": "The burgeoning influence of Large Language Models (LLMs) in shaping public discourse and decision-making underscores the imperative to address inherent biases within these AI systems. In the wake of AI's expansive integration across sectors, addressing racial bias in LLMs has never been more critical. This paper introduces a novel framework called Comprehensive Bias Neutralization Framework (CBNF) which embodies an innovative approach to quantifying and mitigating biases within LLMs. Our framework combines the Large Language Model Bias Index (LLMBI) [Oketunji, A., Anas, M., Saina, D., (2023)] and Bias removaL with No Demographics (BLIND) [Orgad, H., Belinkov, Y. (2023)] methodologies to create a new metric called Bias Intelligence Quotient (BiQ)which detects, measures, and mitigates racial bias in LLMs without reliance on demographic annotations.\n  By introducing a new metric called BiQ that enhances LLMBI with additional fairness metrics, CBNF offers a multi-dimensional metric for bias assessment, underscoring the necessity of a nuanced approach to fairness in AI [Mehrabi et al., 2021]. This paper presents a detailed analysis of Latimer AI (a language model incrementally trained on black history and culture) in comparison to ChatGPT 3.5, illustrating Latimer AI's efficacy in detecting racial, cultural, and gender biases through targeted training and refined bias mitigation strategies [Latimer & Bender, 2023].",
    "pdf_link": "https://arxiv.org/abs/2404.18276",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）对公共讨论和决策的影响力不断上升，这凸显了解决AI系统中内在偏见的紧迫性。在AI技术广泛应用于各行各业的今天，消除LLMs中的种族偏见尤为紧要。本文提出了一个创新的全面偏见中和框架（CBNF），旨在量化和降低LLMs中的偏见。该框架融合了大型语言模型偏见指数（LLMBI）和无人口统计信息的偏见移除（BLIND）技术，创新性地推出了一个新的度量工具——偏见智能商数（BiQ），它能够在不依赖人口统计信息的情况下，检测、衡量并减少LLMs中的种族偏见。CBNF通过引入BiQ这一新度量标准，不仅增强了LLMBI的公平性指标，还为偏见评估提供了一个多角度的视角，强调了在AI领域采取细致公平观念的必要性。本文还深入分析了Latimer AI（一个基于黑人历史和文化逐步训练的语言模型）与ChatGPT 3.5的性能对比，展示了Latimer AI在通过专门训练和精细的偏见缓解策略，有效识别种族、文化和性别偏见方面的优势。",
    "title_cn": "偏见中和框架：通过偏见智能商数（BiQ）评估大型语言模型的公平性。",
    "tags": [
      "分类：LLM应用",
      "AI偏见检测",
      "语言模型"
    ]
  },
  {
    "title": "Parameter-Efficient Tuning Large Language Models for Graph Representation Learning",
    "submit_datetime": "2024年04月28日",
    "abstract": "Text-rich graphs, which exhibit rich textual information on nodes and edges, are prevalent across a wide range of real-world business applications. Large Language Models (LLMs) have demonstrated remarkable abilities in understanding text, which also introduced the potential for more expressive modeling in text-rich graphs. Despite these capabilities, efficiently applying LLMs to representation learning on graphs presents significant challenges. Recently, parameter-efficient fine-tuning methods for LLMs have enabled efficient new task generalization with minimal time and memory consumption. Inspired by this, we introduce Graph-aware Parameter-Efficient Fine-Tuning - GPEFT, a novel approach for efficient graph representation learning with LLMs on text-rich graphs. Specifically, we utilize a graph neural network (GNN) to encode structural information from neighboring nodes into a graph prompt. This prompt is then inserted at the beginning of the text sequence. To improve the quality of graph prompts, we pre-trained the GNN to assist the frozen LLM in predicting the next token in the node text. Compared with existing joint GNN and LMs, our method directly generate the node embeddings from large language models with an affordable fine-tuning cost. We validate our approach through comprehensive experiments conducted on 8 different text-rich graphs, observing an average improvement of 2% in hit@1 and Mean Reciprocal Rank (MRR) in link prediction evaluations. Our results demonstrate the efficacy and efficiency of our model, showing that it can be smoothly integrated with various large language models, including OPT, LLaMA and Falcon.",
    "pdf_link": "https://arxiv.org/abs/2404.18271",
    "graphs": [],
    "abstract_cn": "文本丰富的图在众多现实世界的商业应用中无处不在，它们在节点和边中嵌入了丰富的文本信息。大型语言模型（LLMs）凭借其卓越的文本理解能力，为这类图的建模提供了新的表达潜力。然而，将LLMs应用于图的表示学习，尽管潜力巨大，却也面临着不小的挑战。最近，一种针对LLMs的参数高效微调技术，以最小的时间和内存消耗，实现了新任务的快速泛化。基于此，我们提出了图感知参数高效微调（GPEFT），这是一种创新的方法，用于在文本丰富的图上与LLMs一起进行高效的图表示学习。我们利用图神经网络（GNN）捕捉邻近节点的结构信息，并将这些信息编码成图提示，该提示置于文本序列的前端。为了提升图提示的质量，我们对GNN进行了预训练，以便在LLM固定的情况下预测节点文本中的下一个标记。与现有的GNN和语言模型的联合方法相比，我们的方法能够以较低的微调成本，直接从大型语言模型中生成节点嵌入。通过在8种不同的文本丰富图上进行的广泛实验，我们在链接预测评估中实现了平均2%的性能提升，无论是在命中率@1还是平均倒数排名（MRR）上。这些结果展示了我们模型的高效性和有效性，并证明了它可以无缝地与包括OPT、LLaMA和Falcon在内的多种大型语言模型集成。",
    "title_cn": "通过参数高效的方法调整大型语言模型，以优化图表示学习的效果。",
    "tags": [
      "LLM应用",
      "商业应用",
      "图表示学习"
    ]
  },
  {
    "title": "Generating Situated Reflection Triggers about Alternative Solution Paths: A Case Study of Generative AI for Computer-Supported Collaborative Learning",
    "submit_datetime": "2024年04月28日",
    "abstract": "An advantage of Large Language Models (LLMs) is their contextualization capability - providing different responses based on student inputs like solution strategy or prior discussion, to potentially better engage students than standard feedback. We present a design and evaluation of a proof-of-concept LLM application to offer students dynamic and contextualized feedback. Specifically, we augment an Online Programming Exercise bot for a college-level Cloud Computing course with ChatGPT, which offers students contextualized reflection triggers during a collaborative query optimization task in database design. We demonstrate that LLMs can be used to generate highly situated reflection triggers that incorporate details of the collaborative discussion happening in context. We discuss in depth the exploration of the design space of the triggers and their correspondence with the learning objectives as well as the impact on student learning in a pilot study with 34 students.",
    "pdf_link": "https://arxiv.org/abs/2404.18262",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.18262v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18262/Demonstration_of_Intervention.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18262v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18262/timestamp_analysis_plot.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18262v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18262/activity_architecture.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18262v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18262/pre_test_scores.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18262v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18262/post_test_scores_.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）的突出之处在于其上下文化能力，能够根据不同的学生输入，如解题策略或先前的讨论，提供多样化的反馈，从而可能更有效地吸引学生。本研究介绍了一个概念验证的LLM应用，旨在为学生提供动态且具有上下文性的反馈。具体而言，我们为大学级别的云计算课程的在线编程练习机器人集成了ChatGPT，该机器人在数据库设计中的协作查询优化任务中，为学生提供了定制化的反思触发点。我们证明，LLMs能够生成高度情境化的反思触发点，这些触发点融合了正在进行的协作讨论的具体细节。此外，我们还深入探讨了触发点设计空间的探索，它们与学习目标的契合度，以及在一项涉及34名学生的试点研究中对学习成效的影响。",
    "title_cn": "探索替代解决路径的情境反思触发器：以计算机辅助协作学习中的生成型AI为例",
    "tags": [
      "分类：LLM应用",
      "",
      "云计算"
    ]
  },
  {
    "title": "PatentGPT: A Large Language Model for Intellectual Property",
    "submit_datetime": "2024年04月28日",
    "abstract": "In recent years, large language models have attracted significant attention due to their exceptional performance across a multitude of natural language process tasks, and have been widely applied in various fields. However, the application of large language models in the Intellectual Property (IP) space is challenging due to the strong need for specialized knowledge, privacy protection, processing of extremely long text in this field. In this technical report, we present for the first time a low-cost, standardized procedure for training IP-oriented LLMs, meeting the unique requirements of the IP domain. Using this standard process, we have trained the PatentGPT series models based on open-source pretrained models. By evaluating them on the open-source IP-oriented benchmark MOZIP, our domain-specific LLMs outperforms GPT-4, indicating the effectiveness of the proposed training procedure and the expertise of the PatentGPT models in the IP demain. What is impressive is that our model significantly outperformed GPT-4 on the 2019 China Patent Agent Qualification Examination by achieving a score of 65, reaching the level of human experts. Additionally, the PatentGPT model, which utilizes the SMoE architecture, achieves performance comparable to that of GPT-4 in the IP domain and demonstrates a better cost-performance ratio on long-text tasks, potentially serving as an alternative to GPT-4 within the IP domain.",
    "pdf_link": "https://arxiv.org/abs/2404.18255",
    "graphs": [],
    "abstract_cn": "近年来，大型语言模型在众多自然语言处理任务上展现出色的表现，因而备受瞩目，并已在多个领域得到广泛应用。但在知识产权（IP）领域，由于对专业知识的高要求、隐私保护的必要性以及处理超长文本的难题，这些模型的应用面临挑战。本技术报告首次介绍一种经济高效且标准化的方法，用于培育符合IP领域特殊需求的语言模型。我们采用这一流程，基于开源预训练模型，训练出PatentGPT系列模型。在开源IP基准测试MOZIP上的评估结果显示，我们的定制化LLM性能超越了GPT-4，验证了我们提出的训练方法的有效性及PatentGPT模型在IP领域的专业性。更值得一提的是，我们的模型在2019年中国专利代理资格考试中以65分的成绩大幅领先GPT-4，达到了人类专家的水准。此外，采用SMoE架构的PatentGPT模型，在IP领域的性能可与GPT-4媲美，并在处理长文本任务时展现出更优的性价比，有潜力成为IP领域内GPT-4的有力竞争者。",
    "title_cn": "PatentGPT：专为知识产权领域打造的先进大型语言模型。",
    "tags": [
      "LLM应用",
      "知识产权",
      ""
    ]
  },
  {
    "title": "Efficient Remote Sensing with Harmonized Transfer Learning and Modality Alignment",
    "submit_datetime": "2024年04月28日",
    "abstract": "With the rise of Visual and Language Pretraining (VLP), an increasing number of downstream tasks are adopting the paradigm of pretraining followed by fine-tuning. Although this paradigm has demonstrated potential in various multimodal downstream tasks, its implementation in the remote sensing domain encounters some obstacles. Specifically, the tendency for same-modality embeddings to cluster together impedes efficient transfer learning. To tackle this issue, we review the aim of multimodal transfer learning for downstream tasks from a unified perspective, and rethink the optimization process based on three distinct objectives. We propose \"Harmonized Transfer Learning and Modality Alignment (HarMA)\", a method that simultaneously satisfies task constraints, modality alignment, and single-modality uniform alignment, while minimizing training overhead through parameter-efficient fine-tuning. Remarkably, without the need for external data for training, HarMA achieves state-of-the-art performance in two popular multimodal retrieval tasks in the field of remote sensing. Our experiments reveal that HarMA achieves competitive and even superior performance to fully fine-tuned models with only minimal adjustable parameters. Due to its simplicity, HarMA can be integrated into almost all existing multimodal pretraining models. We hope this method can facilitate the efficient application of large models to a wide range of downstream tasks while significantly reducing the resource consumption. Code is available at https://github.com/seekerhuang/HarMA.",
    "pdf_link": "https://arxiv.org/abs/2404.18253",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.18253v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18253/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18253v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18253/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18253v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18253/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18253v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18253/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18253v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18253/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18253v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18253/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18253v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18253/x7.png"
      }
    ],
    "abstract_cn": "视觉与语言预训练（VLP）的兴起引领了一种新的范式：先进行预训练，然后进行微调，这一范式在众多多模态任务中展现出巨大潜力。然而，在遥感领域，这种范式的实施面临挑战，尤其是同模态嵌入的聚集现象，这影响了迁移学习的效率。为此，我们从整体视角审视了多模态迁移学习的目标，并提出了一种新颖的优化策略，旨在解决这一问题。我们介绍的“和谐迁移学习和模态对齐（HarMA）”方法，不仅满足任务需求和模态间的协调，还实现了单模态的统一对齐，并通过高效的参数微调减少了训练成本。HarMA的卓越之处在于，它无需额外训练数据，便能在遥感领域的两个主要多模态检索任务中达到领先水平。实验结果揭示了HarMA在参数调整极少的情况下，性能即可与完全微调的模型相媲美，甚至更优。HarMA的简洁性使其能够轻松融入现有的多模态预训练模型之中。我们期待HarMA能够助力大型模型在多样化任务中的应用，同时大幅度降低资源消耗。相关代码已在 https://github.com/seekerhuang/HarMA 上发布。",
    "title_cn": "采用和谐迁移学习与模态校准技术，实现高效遥感探测",
    "tags": [
      "LLM应用",
      "",
      "多模态学习"
    ]
  },
  {
    "title": "LEGENT: Open Platform for Embodied Agents",
    "submit_datetime": "2024年04月28日",
    "abstract": "Despite advancements in Large Language Models (LLMs) and Large Multimodal Models (LMMs), their integration into language-grounded, human-like embodied agents remains incomplete, hindering complex real-life task performance in physical environments. Existing integrations often feature limited open sourcing, challenging collective progress in this field. We introduce LEGENT, an open, scalable platform for developing embodied agents using LLMs and LMMs. LEGENT offers a dual approach: a rich, interactive 3D environment with communicable and actionable agents, paired with a user-friendly interface, and a sophisticated data generation pipeline utilizing advanced algorithms to exploit supervision from simulated worlds at scale. In our experiments, an embryonic vision-language-action model trained on LEGENT-generated data surpasses GPT-4V in embodied tasks, showcasing promising generalization capabilities.",
    "pdf_link": "https://arxiv.org/abs/2404.18243",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.18243v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18243/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18243v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18243/procthor.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18243v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18243/holodeck.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18243v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18243/traj.jpg"
      }
    ],
    "abstract_cn": "尽管大型语言模型（LLMs）和大型多模态模型（LMMs）取得了显著进步，但将其融入到类似人类的、具有语言能力的具身代理中仍面临挑战，这限制了它们在现实世界任务中的复杂性能。目前，大多数集成工作开源程度有限，这影响了整个领域的进步。为此，我们推出了LEGENT，这是一个开放且可扩展的平台，旨在利用LLMs和LMMs打造具身代理。LEGENT结合了丰富的互动3D环境和易于操作的用户界面，以及一个先进的数据生成流程，该流程使用复杂算法从模拟世界中提取大规模监督信息。在实验中，基于LEGENT数据训练的初级视觉-语言-行动模型在具身任务上的表现超过了GPT-4V，显示了其出色的泛化潜力。",
    "title_cn": "LEGENT：为具身代理打造的开放平台",
    "tags": [
      "Agent",
      "人工智能",
      "机器人技术"
    ]
  },
  {
    "title": "SOUL: Unlocking the Power of Second-Order Optimization for LLM Unlearning",
    "submit_datetime": "2024年04月28日",
    "abstract": "Large Language Models (LLMs) have highlighted the necessity of effective unlearning mechanisms to comply with data regulations and ethical AI practices. LLM unlearning aims at removing undesired data influences and associated model capabilities without compromising utility out of the scope of unlearning. While interest in studying LLM unlearning is growing,the impact of the optimizer choice for LLM unlearning remains under-explored. In this work, we shed light on the significance of optimizer selection in LLM unlearning for the first time, establishing a clear connection between {second-order optimization} and influence unlearning (a classical approach using influence functions to update the model for data influence removal). This insight propels us to develop a second-order unlearning framework, termed SOUL, built upon the second-order clipped stochastic optimization (Sophia)-based LLM training method. SOUL extends the static, one-shot model update using influence unlearning to a dynamic, iterative unlearning process. Our extensive experiments show that SOUL consistently outperforms conventional first-order methods across various unlearning tasks, models, and metrics, suggesting the promise of second-order optimization in providing a scalable and easily implementable solution for LLM unlearning.",
    "pdf_link": "https://arxiv.org/abs/2404.18239",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）凸显了为了遵守数据法规和遵循道德的AI实践，必须具备有效的遗忘机制。LLM的遗忘目的是消除不需要的数据影响及其对模型能力的影响，同时保持模型在遗忘范围之外的实用性。尽管对LLM遗忘的研究兴趣日益增长，但选择优化器对LLM遗忘的影响尚未得到充分研究。本研究首次揭示了优化器选择在LLM遗忘中的重要性，并明确了二阶优化与影响遗忘之间的联系，后者是一种利用影响函数更新模型以去除数据影响的经典方法。基于此，我们提出了一个名为SOUL的二阶遗忘框架，该框架基于二阶裁剪随机优化（Sophia）的LLM训练方法构建。SOUL将传统的静态一次性模型更新方法转变为动态迭代的遗忘过程。我们的广泛实验表明，SOUL在多种遗忘任务、模型和评价指标上均优于常规的一阶方法，这预示着二阶优化在为LLM遗忘提供可扩展且易于实施的解决方案方面具有巨大潜力。",
    "title_cn": "SOUL：释放二阶优化在大型语言模型“忘却”过程中的潜力。",
    "tags": [
      "LLM理论",
      "数据法规",
      "人工智能伦理"
    ]
  },
  {
    "title": "From Persona to Personalization: A Survey on Role-Playing Language Agents",
    "submit_datetime": "2024年04月28日",
    "abstract": "Recent advancements in large language models (LLMs) have significantly boosted the rise of Role-Playing Language Agents (RPLAs), i.e., specialized AI systems designed to simulate assigned personas. By harnessing multiple advanced abilities of LLMs, including in-context learning, instruction following, and social intelligence, RPLAs achieve a remarkable sense of human likeness and vivid role-playing performance. RPLAs can mimic a wide range of personas, ranging from historical figures and fictional characters to real-life individuals. Consequently, they have catalyzed numerous AI applications, such as emotional companions, interactive video games, personalized assistants and copilots, and digital clones. In this paper, we conduct a comprehensive survey of this field, illustrating the evolution and recent progress in RPLAs integrating with cutting-edge LLM technologies. We categorize personas into three types: 1) Demographic Persona, which leverages statistical stereotypes; 2) Character Persona, focused on well-established figures; and 3) Individualized Persona, customized through ongoing user interactions for personalized services. We begin by presenting a comprehensive overview of current methodologies for RPLAs, followed by the details for each persona type, covering corresponding data sourcing, agent construction, and evaluation. Afterward, we discuss the fundamental risks, existing limitations, and future prospects of RPLAs. Additionally, we provide a brief review of RPLAs in AI applications, which reflects practical user demands that shape and drive RPLA research. Through this work, we aim to establish a clear taxonomy of RPLA research and applications, and facilitate future research in this critical and ever-evolving field, and pave the way for a future where humans and RPLAs coexist in harmony.",
    "pdf_link": "https://arxiv.org/abs/2404.18231",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.18231v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18231/x1.png"
      }
    ],
    "abstract_cn": "近期大型语言模型（LLMs）的突破性进展极大地促进了角色扮演语言代理（RPLAs）的发展，这是一种专为模拟特定人物角色而设计的AI系统。RPLAs借助LLMs的多项高级功能，如情境学习、指令执行和社交智能，展现出了极高的人类相似度和生动的角色扮演能力。它们能够模拟从历史名人到虚构角色，再到现实生活中的个体等各种人物形象。因此，RPLAs推动了情感伴侣、互动式电子游戏、个性化助理和副驾驶，以及数字克隆等多种AI应用的发展。本文全面梳理了这一领域的研究进展，展示了RPLAs如何与前沿的LLM技术相结合。我们将人物角色分为三类：1）利用统计学刻板印象的人口统计角色；2）专注于知名人物的角色角色；3）通过持续用户互动定制的个性化角色。文章首先全面概述了RPLAs的当前方法，然后详细介绍了每种角色类型的具体情况，包括相应的数据来源、代理构建和评估方法。接着，我们探讨了RPLAs的基本风险、现有局限和未来发展方向。此外，我们还简要回顾了RPLAs在AI应用中的实践，这些应用反映了用户的实际需求，也正是这些需求推动了RPLA研究的发展。通过本研究，我们希望建立一个清晰的RPLA研究和应用分类体系，推动这一关键且快速演变领域的未来研究，并为人类与RPLAs和谐共存的未来奠定基础。",
    "title_cn": "探索角色扮演语言代理：个性化之路的调查研究",
    "tags": [
      "分类：Agent",
      "人工智能",
      "角色扮演"
    ]
  },
  {
    "title": "TextGram: Towards a better domain-adaptive pretraining",
    "submit_datetime": "2024年04月28日",
    "abstract": "For green AI, it is crucial to measure and reduce the carbon footprint emitted during the training of large language models. In NLP, performing pre-training on Transformer models requires significant computational resources. This pre-training involves using a large amount of text data to gain prior knowledge for performing downstream tasks. Thus, it is important that we select the correct data in the form of domain-specific data from this vast corpus to achieve optimum results aligned with our domain-specific tasks. While training on large unsupervised data is expensive, it can be optimized by performing a data selection step before pretraining. Selecting important data reduces the space overhead and the substantial amount of time required to pre-train the model while maintaining constant accuracy. We investigate the existing selection strategies and propose our own domain-adaptive data selection method - TextGram - that effectively selects essential data from large corpora. We compare and evaluate the results of finetuned models for text classification task with and without data selection. We show that the proposed strategy works better compared to other selection methods.",
    "pdf_link": "https://arxiv.org/abs/2404.18228",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.18228v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18228/Architecture3.jpg"
      },
      {
        "url": "https://arxiv.org/html/2404.18228v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18228/textgram.png"
      }
    ],
    "abstract_cn": "绿色AI的核心在于准确衡量并降低大型语言模型训练过程中的碳排放。在自然语言处理领域，对Transformer模型进行预训练需要动用庞大的计算资源。这一过程通过大量文本数据积累知识，以便更好地执行后续任务。因此，从海量语料中精准挑选出与特定领域相关的数据，对于实现最佳任务效果至关重要。尽管基于大规模无监督数据的训练成本高昂，但通过在预训练前进行数据筛选可以优化这一过程。精选关键数据不仅减少了存储开销，还缩短了模型预训练的时间，同时确保了准确性。我们深入研究了现有的数据筛选策略，并提出了一种新的领域适应性数据筛选方法——TextGram，它能够高效地从大型语料库中筛选出关键数据。我们对比了应用和不应用数据筛选的文本分类任务的微调模型效果，并验证了我们策略的优越性。",
    "title_cn": "TextGram：探索更优的领域适应性预训练之路",
    "tags": [
      "LLM应用",
      "",
      "环境科学"
    ]
  },
  {
    "title": "Paint by Inpaint: Learning to Add Image Objects by Removing Them First",
    "submit_datetime": "2024年04月28日",
    "abstract": "Image editing has advanced significantly with the introduction of text-conditioned diffusion models. Despite this progress, seamlessly adding objects to images based on textual instructions without requiring user-provided input masks remains a challenge. We address this by leveraging the insight that removing objects (Inpaint) is significantly simpler than its inverse process of adding them (Paint), attributed to the utilization of segmentation mask datasets alongside inpainting models that inpaint within these masks. Capitalizing on this realization, by implementing an automated and extensive pipeline, we curate a filtered large-scale image dataset containing pairs of images and their corresponding object-removed versions. Using these pairs, we train a diffusion model to inverse the inpainting process, effectively adding objects into images. Unlike other editing datasets, ours features natural target images instead of synthetic ones; moreover, it maintains consistency between source and target by construction. Additionally, we utilize a large Vision-Language Model to provide detailed descriptions of the removed objects and a Large Language Model to convert these descriptions into diverse, natural-language instructions. We show that the trained model surpasses existing ones both qualitatively and quantitatively, and release the large-scale dataset alongside the trained models for the community.",
    "pdf_link": "https://arxiv.org/abs/2404.18212",
    "graphs": [],
    "abstract_cn": "文本条件扩散模型的推出极大推动了图像编辑技术的发展。然而，依据文本指令在图像中无缝添加对象，且无需用户提供输入遮罩，这一任务依然充满挑战。我们通过洞察到移除对象（修复）比添加对象（绘画）更为简单，利用这一原理，结合分割掩码数据集和修复模型，实现了在掩码区域内的修复。基于这一认识，我们构建了一个自动化的流程，创建了一个精选的大规模图像数据集，包含了原始图像及其去除了对象的对应版本。利用这些图像对，我们训练了一个扩散模型，以逆转修复过程，从而在图像中有效添加对象。与其它编辑数据集相比，我们的集锦采用了更自然的图像，并且在源图像和目标图像之间通过构建保持了一致性。此外，我们还采用了一个大型视觉-语言模型来详细描述被移除的对象，并通过一个大型语言模型将这些描述转换成多样化的自然语言指令。我们证明，我们训练的模型在质量和数量上都超越了现有模型，并且我们已经将这个大规模数据集和训练好的模型公开，供社区使用。",
    "title_cn": "先删后加，学习图像编辑新技巧：Inpaint的智能绘画教学",
    "tags": [
      "分类：LLM应用",
      "图像编辑",
      "人工智能"
    ]
  },
  {
    "title": "4DBInfer: A 4D Benchmarking Toolbox for Graph-Centric Predictive Modeling on Relational DBs",
    "submit_datetime": "2024年04月28日",
    "abstract": "Although RDBs store vast amounts of rich, informative data spread across interconnected tables, the progress of predictive machine learning models as applied to such tasks arguably falls well behind advances in other domains such as computer vision or natural language processing. This deficit stems, at least in part, from the lack of established/public RDB benchmarks as needed for training and evaluation purposes. As a result, related model development thus far often defaults to tabular approaches trained on ubiquitous single-table benchmarks, or on the relational side, graph-based alternatives such as GNNs applied to a completely different set of graph datasets devoid of tabular characteristics. To more precisely target RDBs lying at the nexus of these two complementary regimes, we explore a broad class of baseline models predicated on: (i) converting multi-table datasets into graphs using various strategies equipped with efficient subsampling, while preserving tabular characteristics; and (ii) trainable models with well-matched inductive biases that output predictions based on these input subgraphs. Then, to address the dearth of suitable public benchmarks and reduce siloed comparisons, we assemble a diverse collection of (i) large-scale RDB datasets and (ii) coincident predictive tasks. From a delivery standpoint, we operationalize the above four dimensions (4D) of exploration within a unified, scalable open-source toolbox called 4DBInfer. We conclude by presenting evaluations using 4DBInfer, the results of which highlight the importance of considering each such dimension in the design of RDB predictive models, as well as the limitations of more naive approaches such as simply joining adjacent tables. Our source code is released at https://github.com/awslabs/multi-table-benchmark .",
    "pdf_link": "https://arxiv.org/abs/2404.18209",
    "graphs": [],
    "abstract_cn": "关系数据库（RDBs）虽然在互联表中存储了海量的丰富信息数据，但在这些任务上应用预测性机器学习模型的发展，相较于计算机视觉或自然语言处理等领域，显然还有很大的提升空间。这一差距部分原因在于缺少用于训练和评估的标准公共RDB基准。因此，目前的相关模型开发往往倾向于使用单一表基准训练的表格方法，或是采用图神经网络（GNN）等基于图的替代方案，这些方案应用于与表格特性迥异的数据集。为了更精准地针对处于这两个领域交汇处的RDBs，我们研究了一系列基线模型，这些模型基于：（i）采用多种策略将多表数据集转换为图，同时保留其表格特性；（ii）设计具有适当归纳偏置的可训练模型，这些模型能够基于输入子图进行预测。为了填补公共基准的空白并减少孤立比较，我们汇集了大量RDB数据集和相应的预测任务。我们通过一个名为4DBInfer的统一、可扩展的开源工具箱，实现了对这四个探索维度（4D）的操作。最后，我们使用4DBInfer进行评估，结果强调了在设计RDB预测模型时考虑每个维度的重要性，并指出了简单方法（如直接连接相邻表）的局限性。我们的源代码已在 https://github.com/awslabs/multi-table-benchmark 上发布。",
    "title_cn": "4DBInfer：一款专为关系数据库设计的四维基准测试工具箱，专注于图形中心的预测性建模。",
    "tags": [
      "LLM应用",
      "数据库管理",
      "机器学习"
    ]
  },
  {
    "title": "WorldGPT: Empowering LLM as Multimodal World Model",
    "submit_datetime": "2024年04月28日",
    "abstract": "World models are progressively being employed across diverse fields, extending from basic environment simulation to complex scenario construction. However, existing models are mainly trained on domain-specific states and actions, and confined to single-modality state representations. In this paper, We introduce WorldGPT, a generalist world model built upon Multimodal Large Language Model (MLLM). WorldGPT acquires an understanding of world dynamics through analyzing millions of videos across various domains. To further enhance WorldGPT's capability in specialized scenarios and long-term tasks, we have integrated it with a novel cognitive architecture that combines memory offloading, knowledge retrieval, and context reflection. As for evaluation, we build WorldNet, a multimodal state transition prediction benchmark encompassing varied real-life scenarios. Conducting evaluations on WorldNet directly demonstrates WorldGPT's capability to accurately model state transition patterns, affirming its effectiveness in understanding and predicting the dynamics of complex scenarios. We further explore WorldGPT's emerging potential in serving as a world simulator, helping multimodal agents generalize to unfamiliar domains through efficiently synthesising multimodal instruction instances which are proved to be as reliable as authentic data for fine-tuning purposes. The project is available on \\url{https://github.com/DCDmllm/WorldGPT}.",
    "pdf_link": "https://arxiv.org/abs/2404.18202",
    "graphs": [],
    "abstract_cn": "世界模型正广泛应用于环境模拟到复杂场景构建等多个领域。现有模型多基于特定领域的状态和动作训练，且限于单一模态的表示。本文提出了 WorldGPT，一个基于多模态大型语言模型（MLLM）构建的通用世界模型，它通过分析数百万跨领域的视频来理解世界动态。为了提升其在特定场景和长期任务中的性能，我们引入了一种融合记忆卸载、知识检索和上下文反思的认知架构。我们构建了 WorldNet，一个多模态状态转换预测基准，覆盖了多种真实场景，用以评估 WorldGPT 的性能。评估结果证明了 WorldGPT 在准确模拟和预测复杂场景动态方面的能力。此外，我们还探讨了 WorldGPT 作为世界模拟器的潜力，它能够通过合成可靠的多模态指令实例，帮助多模态代理泛化到新领域，这些实例在微调中与真实数据同样有效。项目详情可访问 \\url{https://github.com/DCDmllm/WorldGPT}。",
    "title_cn": "WorldGPT：赋予大型语言模型多模态世界建模能力",
    "tags": [
      "分类：LLM应用",
      "环境模拟",
      "人工智能"
    ]
  },
  {
    "title": "Exploring the Robustness of In-Context Learning with Noisy Labels",
    "submit_datetime": "2024年04月28日",
    "abstract": "Recently, the mysterious In-Context Learning (ICL) ability exhibited by Transformer architectures, especially in large language models (LLMs), has sparked significant research interest. However, the resilience of Transformers' in-context learning capabilities in the presence of noisy samples, prevalent in both training corpora and prompt demonstrations, remains underexplored. In this paper, inspired by prior research that studies ICL ability using simple function classes, we take a closer look at this problem by investigating the robustness of Transformers against noisy labels. Specifically, we first conduct a thorough evaluation and analysis of the robustness of Transformers against noisy labels during in-context learning and show that they exhibit notable resilience against diverse types of noise in demonstration labels. Furthermore, we delve deeper into this problem by exploring whether introducing noise into the training set, akin to a form of data augmentation, enhances such robustness during inference, and find that such noise can indeed improve the robustness of ICL. Overall, our fruitful analysis and findings provide a comprehensive understanding of the resilience of Transformer models against label noises during ICL and provide valuable insights into the research on Transformers in natural language processing. Our code is available at https://github.com/InezYu0928/in-context-learning.",
    "pdf_link": "https://arxiv.org/abs/2404.18191",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/error_curve_std_expotential.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/error_curve_std_uniform.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/error_curve_std_expotential.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/error_curve_std_poisson.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/error_curve_std_multiplicative.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/error_curve_std_salt_pepper.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/error_curve_baseline_gaussian.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/error_curve_baseline_gaussian.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/error_curve_baseline_gaussian.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/error_curve_baseline_uniform.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/error_curve_baseline_uniform.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/error_curve_baseline_uniform.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/error_curve_baseline_expotential.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/error_curve_baseline_expotential.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/error_curve_baseline_expotential.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/error_curve_baseline_poisson.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/error_curve_baseline_poisson.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/error_curve_baseline_poisson.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/error_curve_baseline_multiplicative.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/error_curve_baseline_multiplicative.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/error_curve_baseline_multiplicative.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/error_curve_baseline_salt_pepper.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/error_curve_baseline_salt_pepper.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/error_curve_baseline_salt_pepper.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/loss_curve_2_0.0.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/loss_curve_2_0.1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/loss_curve_2_0.2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/loss_curve_2_0.5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/loss_curve_3_0.0.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/loss_curve_3_0.1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/loss_curve_3_0.2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/loss_curve_3_0.5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/loss_curve_4_0.0.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/loss_curve_4_0.1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/loss_curve_4_0.2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/loss_curve_4_0.5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/loss_curve_5_0.0.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/loss_curve_5_0.1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/loss_curve_5_0.2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/loss_curve_5_0.5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/tr00_tst00.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/tr00_tst02.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/tr00_tst04.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/tr00_tst06.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/tr00_tst08.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/tr00_tst10.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/noise_std00.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/noise_std02.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/noise_std04.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/noise_std06.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/noise_std08.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18191v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18191/noise_std10.png"
      }
    ],
    "abstract_cn": "近期，变换器架构所展现的神秘上下文学习能力（ICL），尤其在大型语言模型（LLMs）中，引起了广泛的研究关注。尽管如此，变换器在面对充满噪声样本的上下文学习中的鲁棒性，这一问题在训练语料和提示演示中普遍存在，却鲜有深入探讨。本文受到先前研究的启发，那些研究通过简单的函数类别来探究ICL能力，我们通过深入探讨变换器对噪声标签的鲁棒性，来更细致地审视这一问题。具体而言，我们首先对变换器在上下文学习过程中对噪声标签的鲁棒性进行了详尽的评估与分析，发现变换器对示范标签中多样化的噪声类型具有显著的抵抗力。进一步地，我们探究了在训练集中引入噪声，类似于数据增强手段，是否能够增强推理过程中的这种鲁棒性，并发现这样的噪声确实能够提升ICL的鲁棒性。总体而言，我们深入的分析和发现为理解变换器模型在ICL过程中对抗标签噪声的鲁棒性提供了全面的视角，为自然语言处理领域中变换器的研究提供了宝贵的洞见。我们的代码已在 https://github.com/InezYu0928/in-context-learning 上公开。",
    "title_cn": "探究含噪声标签情境下ICL的稳健性",
    "tags": [
      "LLM理论",
      "",
      "机器学习"
    ]
  },
  {
    "title": "Ranked List Truncation for Large Language Model-based Re-Ranking",
    "submit_datetime": "2024年04月28日",
    "abstract": "We study ranked list truncation (RLT) from a novel \"retrieve-then-re-rank\" perspective, where we optimize re-ranking by truncating the retrieved list (i.e., trim re-ranking candidates). RLT is crucial for re-ranking as it can improve re-ranking efficiency by sending variable-length candidate lists to a re-ranker on a per-query basis. It also has the potential to improve re-ranking effectiveness. Despite its importance, there is limited research into applying RLT methods to this new perspective. To address this research gap, we reproduce existing RLT methods in the context of re-ranking, especially newly emerged large language model (LLM)-based re-ranking. In particular, we examine to what extent established findings on RLT for retrieval are generalizable to the \"retrieve-then-re-rank\" setup from three perspectives: (i) assessing RLT methods in the context of LLM-based re-ranking with lexical first-stage retrieval, (ii) investigating the impact of different types of first-stage retrievers on RLT methods, and (iii) investigating the impact of different types of re-rankers on RLT methods. We perform experiments on the TREC 2019 and 2020 deep learning tracks, investigating 8 RLT methods for pipelines involving 3 retrievers and 2 re-rankers. We reach new insights into RLT methods in the context of re-ranking.",
    "pdf_link": "https://arxiv.org/abs/2404.18185",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.18185v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18185/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18185v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18185/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18185v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18185/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18185v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18185/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18185v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18185/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18185v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18185/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18185v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18185/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18185v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18185/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18185v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18185/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18185v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18185/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18185v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18185/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18185v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18185/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18185v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18185/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18185v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18185/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18185v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18185/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18185v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18185/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18185v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18185/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18185v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18185/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18185v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18185/x19.png"
      }
    ],
    "abstract_cn": "本研究以“先检索再重新排序”的新视角探讨了排名列表截断（RLT）问题，通过裁剪检索结果列表来优化重新排序过程。RLT 在提升重新排序的效率和效果方面发挥着关键作用，但目前对这一新视角下RLT方法的研究尚不充分。为填补这一研究空白，我们特别针对基于大型语言模型（LLM）的重新排序，复现并测试了现有的RLT方法。我们从三个维度深入探讨了RLT在“先检索再重新排序”框架下的适用性：（i）评估基于LLM重新排序和词汇检索的第一阶段RLT方法，（ii）分析不同类型第一阶段检索器对RLT方法的影响，（iii）探究不同类型重新排序器对RLT方法的影响。我们在TREC 2019和2020深度学习赛道上进行了实验，对涉及3种检索器和2种重新排序器的8种RLT方法进行了测试，从而获得了关于重新排序背景下RLT方法的新洞见。",
    "title_cn": "为大型语言模型的重新排序引入列表截断技术",
    "tags": [
      "LLM应用",
      "信息检索",
      ""
    ]
  },
  {
    "title": "Generative AI for Visualization: State of the Art and Future Directions",
    "submit_datetime": "2024年04月28日",
    "abstract": "Generative AI (GenAI) has witnessed remarkable progress in recent years and demonstrated impressive performance in various generation tasks in different domains such as computer vision and computational design. Many researchers have attempted to integrate GenAI into visualization framework, leveraging the superior generative capacity for different operations. Concurrently, recent major breakthroughs in GenAI like diffusion model and large language model have also drastically increase the potential of GenAI4VIS. From a technical perspective, this paper looks back on previous visualization studies leveraging GenAI and discusses the challenges and opportunities for future research. Specifically, we cover the applications of different types of GenAI methods including sequence, tabular, spatial and graph generation techniques for different tasks of visualization which we summarize into four major stages: data enhancement, visual mapping generation, stylization and interaction. For each specific visualization sub-task, we illustrate the typical data and concrete GenAI algorithms, aiming to provide in-depth understanding of the state-of-the-art GenAI4VIS techniques and their limitations. Furthermore, based on the survey, we discuss three major aspects of challenges and research opportunities including evaluation, dataset, and the gap between end-to-end GenAI and generative algorithms. By summarizing different generation algorithms, their current applications and limitations, this paper endeavors to provide useful insights for future GenAI4VIS research.",
    "pdf_link": "https://arxiv.org/abs/2404.18144",
    "graphs": [],
    "abstract_cn": "近年来，生成性人工智能（GenAI）在多个领域取得了突破性进展，尤其在计算机视觉和计算设计等领域的生成任务中表现卓越。研究人员正尝试将 GenAI 融入可视化框架，以发挥其强大的生成能力。随着扩散模型和大型语言模型等 GenAI 领域的重大进展，GenAI 在可视化（GenAI4VIS）的潜力得到了极大提升。本文从技术角度回顾了 GenAI 在可视化研究中的应用，并探讨了未来研究面临的挑战与机遇。文章详细讨论了序列、表格、空间和图形等不同 GenAI 方法在数据增强、视觉映射生成、风格化和交互等可视化任务中的应用，并总结了这些方法的典型数据和具体算法，以期深入理解 GenAI4VIS 技术的前沿及其限制。此外，文章还基于调研，探讨了评估、数据集和端到端 GenAI 与生成算法之间差异等三个主要挑战和研究方向。通过梳理各种生成算法及其应用现状和局限，本文旨在为 GenAI4VIS 的未来发展提供有益的洞见。",
    "title_cn": "探索可视化领域的生成式人工智能：技术前沿与未来趋势",
    "tags": [
      "LLM应用",
      "计算机视觉",
      "计算设计"
    ]
  },
  {
    "title": "Logic Agent: Enhancing Validity with Logic Rule Invocation",
    "submit_datetime": "2024年04月28日",
    "abstract": "Chain-of-Thought (CoT) prompting has emerged as a pivotal technique for augmenting the inferential capabilities of language models during reasoning tasks. Despite its advancements, CoT often grapples with challenges in validating reasoning validity and ensuring informativeness. Addressing these limitations, this paper introduces the Logic Agent (LA), an agent-based framework aimed at enhancing the validity of reasoning processes in Large Language Models (LLMs) through strategic logic rule invocation. Unlike conventional approaches, LA transforms LLMs into logic agents that dynamically apply propositional logic rules, initiating the reasoning process by converting natural language inputs into structured logic forms. The logic agent leverages a comprehensive set of predefined functions to systematically navigate the reasoning process. This methodology not only promotes the structured and coherent generation of reasoning constructs but also significantly improves their interpretability and logical coherence. Through extensive experimentation, we demonstrate LA's capacity to scale effectively across various model sizes, markedly improving the precision of complex reasoning across diverse tasks.",
    "pdf_link": "https://arxiv.org/abs/2404.18130",
    "graphs": [],
    "abstract_cn": "链式思考（CoT）提示技术在提升语言模型在推理任务中的推理能力方面发挥了重要作用。然而，它在确认推理的准确性和信息丰富性方面仍面临挑战。为克服这些难题，本研究提出了逻辑代理（LA），这是一个基于代理的框架，通过策略性地应用逻辑规则，旨在提高大型语言模型（LLMs）推理过程的有效性。与传统方法不同，LA 将 LLMs 转换为能够动态应用命题逻辑规则的逻辑代理，通过将自然语言输入转换为结构化逻辑形式来启动推理过程。该逻辑代理使用一系列预定义的函数系统地导航推理过程，不仅促进了推理结构的有序和连贯生成，还显著提升了其可解释性和逻辑一致性。通过广泛的实验，我们展示了 LA 在不同模型尺寸上的扩展能力，并在多样化任务中显著提高了复杂推理的精确度。",
    "title_cn": "逻辑代理：借助逻辑规则的调用提升有效性",
    "tags": [
      "Agent",
      "人工智能",
      "逻辑推理"
    ]
  },
  {
    "title": "Semi-supervised Text-based Person Search",
    "submit_datetime": "2024年04月28日",
    "abstract": "Text-based person search (TBPS) aims to retrieve images of a specific person from a large image gallery based on a natural language description. Existing methods rely on massive annotated image-text data to achieve satisfactory performance in fully-supervised learning. It poses a significant challenge in practice, as acquiring person images from surveillance videos is relatively easy, while obtaining annotated texts is challenging. The paper undertakes a pioneering initiative to explore TBPS under the semi-supervised setting, where only a limited number of person images are annotated with textual descriptions while the majority of images lack annotations. We present a two-stage basic solution based on generation-then-retrieval for semi-supervised TBPS. The generation stage enriches annotated data by applying an image captioning model to generate pseudo-texts for unannotated images. Later, the retrieval stage performs fully-supervised retrieval learning using the augmented data. Significantly, considering the noise interference of the pseudo-texts on retrieval learning, we propose a noise-robust retrieval framework that enhances the ability of the retrieval model to handle noisy data. The framework integrates two key strategies: Hybrid Patch-Channel Masking (PC-Mask) to refine the model architecture, and Noise-Guided Progressive Training (NP-Train) to enhance the training process. PC-Mask performs masking on the input data at both the patch-level and the channel-level to prevent overfitting noisy supervision. NP-Train introduces a progressive training schedule based on the noise level of pseudo-texts to facilitate noise-robust learning. Extensive experiments on multiple TBPS benchmarks show that the proposed framework achieves promising performance under the semi-supervised setting.",
    "pdf_link": "https://arxiv.org/abs/2404.18106",
    "graphs": [],
    "abstract_cn": "基于文本的人物搜索（TBPS）的目的是通过自然语言描述，从海量的图像库中找出特定人物的图片。目前的方法大多依赖于大规模的标注图像-文本数据集，在完全监督的环境下达到较好的效果。然而，这在实际操作中面临巨大挑战，因为从监控视频中获取人物图像较为简单，但获取相应的标注文本却相当困难。本研究首次尝试在半监督的环境下探索TBPS问题，即只有少数人物图像附有文本描述，而大多数图像并未标注。我们提出了一个分两步的解决方案：首先利用图像描述模型为未标注图像生成伪文本，以此扩充标注数据；然后在扩充后的数据基础上，执行全监督的检索学习。特别地，为了应对伪文本带来的噪声干扰，我们设计了一个抗噪声检索框架，该框架通过混合Patch-Channel掩码（PC-Mask）技术和噪声引导的渐进式训练（NP-Train）策略，提升了模型处理噪声数据的能力。PC-Mask技术在输入数据的patch层和channel层进行掩码操作，防止对噪声标签的过拟合。NP-Train则根据伪文本的噪声水平，采用渐进式训练计划，以实现鲁棒学习。在多个TBPS基准测试中的广泛实验结果表明，我们提出的框架在半监督环境下展现出了优异的性能。",
    "title_cn": "半监督文本人物搜索",
    "tags": [
      "分类：Agent",
      "计算机视觉",
      "半监督学习"
    ]
  },
  {
    "title": "CRE-LLM: A Domain-Specific Chinese Relation Extraction Framework with Fine-tuned Large Language Model",
    "submit_datetime": "2024年04月28日",
    "abstract": "Domain-Specific Chinese Relation Extraction (DSCRE) aims to extract relations between entities from domain-specific Chinese text. Despite the rapid development of PLMs in recent years, especially LLMs, DSCRE still faces three core challenges: complex network structure design, poor awareness, and high consumption of fine-tuning. Given the impressive performance of large language models (LLMs) in natural language processing, we propose a new framework called CRE-LLM. This framework is based on fine-tuning open-source LLMs, such as Llama-2, ChatGLM2, and Baichuan2. CRE-LLM enhances the logic-awareness and generative capabilities of the model by constructing an appropriate prompt and utilizing open-source LLMs for instruction-supervised fine-tuning. And then it directly extracts the relations of the given entities in the input textual data, which improving the CRE approach. To demonstrate the effectiveness of the proposed framework, we conducted extensive experiments on two domain-specific CRE datasets, FinRE and SanWen. The experimental results show that CRE-LLM is significantly superior and robust, achieving state-of-the-art (SOTA) performance on the FinRE dataset. This paper introduces a novel approach to domain-specific relation extraction (DSCRE) tasks that are semantically more complex by combining LLMs with triples. Our code is publicly available.",
    "pdf_link": "https://arxiv.org/abs/2404.18085",
    "graphs": [],
    "abstract_cn": "领域定制的中文关系抽取（DSCRE）致力于从专业中文文本中提取实体间的关系。尽管预训练语言模型（PLMs）尤其是大型语言模型（LLMs）技术近年来突飞猛进，DSCRE在网络结构设计、意识提升和微调成本上仍面临重大挑战。鉴于LLMs在自然语言处理领域的卓越成就，我们设计了一种创新框架CRE-LLM。该框架依托于对开源LLMs如Llama-2、ChatGLM2和Baichuan2进行微调，通过精心构建的提示和指令驱动的微调，显著提升了模型的逻辑理解和生成能力。CRE-LLM能够直接从文本数据中抽取实体间的关系，优化了传统的关系抽取方法。为了验证框架的效能，我们在两个专业的CRE数据集FinRE和SanWen上进行了深入的实验。实验结果显示，CRE-LLM在性能上大幅领先，尤其在FinRE数据集上达到了行业领先水平。本文提出了一种创新的DSCRE任务处理方法，通过结合LLMs与三元组来处理更为复杂的语义关系。我们的相关代码已对公众开放。",
    "title_cn": "CRE-LLM：一个针对特定领域的中文关系抽取框架，融合了经过精细调整的大型语言模型。",
    "tags": [
      "LLM应用",
      "中文关系抽取",
      ""
    ]
  },
  {
    "title": "Generative AI for Low-Carbon Artificial Intelligence of Things",
    "submit_datetime": "2024年04月28日",
    "abstract": "By integrating Artificial Intelligence (AI) with the Internet of Things (IoT), Artificial Intelligence of Things (AIoT) has revolutionized many fields. However, AIoT is facing the challenges of energy consumption and carbon emissions due to the continuous advancement of mobile technology. Fortunately, Generative AI (GAI) holds immense potential to reduce carbon emissions of AIoT due to its excellent reasoning and generation capabilities. In this article, we explore the potential of GAI for carbon emissions reduction and propose a novel GAI-enabled solution for low-carbon AIoT. Specifically, we first study the main impacts that cause carbon emissions in AIoT, and then introduce GAI techniques and their relations to carbon emissions. We then explore the application prospects of GAI in low-carbon AIoT, focusing on how GAI can reduce carbon emissions of network components. Subsequently, we propose a Large Language Model (LLM)-enabled carbon emission optimization framework, in which we design pluggable LLM and Retrieval Augmented Generation (RAG) modules to generate more accurate and reliable optimization problems. Furthermore, we utilize Generative Diffusion Models (GDMs) to identify optimal strategies for carbon emission reduction. Simulation results demonstrate the effectiveness of the proposed framework. Finally, we insightfully provide open research directions for low-carbon AIoT.",
    "pdf_link": "https://arxiv.org/abs/2404.18077",
    "graphs": [],
    "abstract_cn": "融合人工智能（AI）与物联网（IoT），人工智能物联网（AIoT）正引领多领域的变革。尽管如此，随着移动技术的发展，AIoT在能耗和碳排放方面面临挑战。但可喜的是，生成性AI（GAI）凭借其卓越的推理与生成能力，展现出降低AIoT碳足迹的巨大潜力。本文将探讨GAI在减少碳排放方面的巨大潜力，并提出一种创新的GAI驱动的低碳AIoT解决方案。我们首先分析了AIoT中碳排放的主要成因，接着介绍了GAI技术及其与碳排放的联系。然后，我们着眼于GAI在构建低碳AIoT中的应用前景，尤其是其在降低网络组件碳排放方面的潜力。我们进一步提出了一个由大型语言模型（LLM）支持的碳排放优化框架，设计了可插拔的LLM和检索增强生成（RAG）模块，以更精确、可靠地生成优化问题。我们还采用了生成扩散模型（GDM）来寻找减少碳排放的最优策略。模拟结果验证了该框架的有效性。文末，我们前瞻性地为低碳AIoT的发展指明了研究方向。",
    "title_cn": "低碳物联网领域的生成型人工智能应用",
    "tags": [
      "LLM应用",
      "物联网",
      "人工智能"
    ]
  },
  {
    "title": "Using Deep Q-Learning to Dynamically Toggle between Push/Pull Actions in Computational Trust Mechanisms",
    "submit_datetime": "2024年04月28日",
    "abstract": "Recent work on decentralized computational trust models for open Multi Agent Systems has resulted in the development of CA, a biologically inspired model which focuses on the trustee's perspective. This new model addresses a serious unresolved problem in existing trust and reputation models, namely the inability to handle constantly changing behaviors and agents' continuous entry and exit from the system. In previous work, we compared CA to FIRE, a well-known trust and reputation model, and found that CA is superior when the trustor population changes, whereas FIRE is more resilient to the trustee population changes. Thus, in this paper, we investigate how the trustors can detect the presence of several dynamic factors in their environment and then decide which trust model to employ in order to maximize utility. We frame this problem as a machine learning problem in a partially observable environment, where the presence of several dynamic factors is not known to the trustor and we describe how an adaptable trustor can rely on a few measurable features so as to assess the current state of the environment and then use Deep Q Learning (DQN), in a single-agent Reinforcement Learning setting, to learn how to adapt to a changing environment. We ran a series of simulation experiments to compare the performance of the adaptable trustor with the performance of trustors using only one model (FIRE or CA) and we show that an adaptable agent is indeed capable of learning when to use each model and, thus, perform consistently in dynamic environments.",
    "pdf_link": "https://arxiv.org/abs/2404.18296",
    "graphs": [],
    "abstract_cn": "近期研究在开放多智能体系统的去中心化计算信任模型方面取得了进展，特别是开发了一种名为 CA 的生物启发模型，该模型从受托人的角度出发。这一新模型针对现有信任和声誉模型中的一个难题——如何处理智能体行为的不断变化以及智能体进出系统的连续性——提供了解决方案。在先前的研究中，我们对比了 CA 与另一个著名的信任和声誉模型 FIRE，并发现在信任者群体变动时，CA 的性能更佳，而 FIRE 在受托者群体变动时更具韧性。本论文进一步探讨了信任者如何识别环境中的多个动态因素，并据此选择最合适的信任模型以优化效用。我们将这一问题设定为部分可观测环境中的机器学习挑战，信任者无法预知多个动态因素的存在。文章描述了信任者如何利用一些可测量的特征来评估环境现状，并采用深度 Q 学习（DQN）在单智能体强化学习框架下学习如何适应环境变化。通过一系列模拟实验，我们比较了适应性信任者与仅使用单一模型（FIRE 或 CA）的信任者的性能，结果表明适应性智能体确实能够学习何时应用每种模型，从而在动态环境中实现稳定的表现。",
    "title_cn": "本文探讨了如何利用深度Q-学习技术，在计算信任机制中实现推/拉动作的动态切换。",
    "tags": [
      "Agent",
      "多智能体系统",
      "机器学习"
    ]
  },
  {
    "title": "ATR-Mapping: Asymmetric Topological Representation based Mapping Framework for Multi-Robot Environment Exploration",
    "submit_datetime": "2024年04月28日",
    "abstract": "In recent years, the widespread application of multi-robot systems in areas such as power inspection, autonomous vehicle fleets has made multi-robot technology a research hotspot in the field of robotics. This paper investigates multi-robot cooperative exploration in unknown environments, proposing a training framework and decision strategy based on multi-agent reinforcement learning. Specifically we propose a Asymmetric Topological Representation based mapping framework (ATR-Mapping), combining the advantages of methods based on raw grid maps and methods based on topology, the structural information from the raw grid maps is extracted and combined with a topological graph constructed based on geometric distance information for decision-making. Leveraging this topological graph representation, we employs a decision network based on topological graph matching to assign corresponding boundary points to each robot as long-term target points for decision-making. We conducts testing and application of the proposed algorithms in real world scenarios using the Gazebo and Gibson simulation environments. It validates that the proposed method, when compared to existing methods, achieves a certain degree of performance improvement.",
    "pdf_link": "https://arxiv.org/abs/2404.18089",
    "graphs": [],
    "abstract_cn": "近期，多机器人系统在电力巡查、自动驾驶车队等众多领域的广泛应用，让其成为机器人学界的研究焦点。本研究着眼于多机器人在未知环境中的协作探索问题，提出了一种基于多智能体强化学习的训练框架与决策策略。我们创新性地设计了一种非对称拓扑表示映射框架（ATR-Mapping），它融合了原始网格图方法与拓扑方法的优势，通过从原始网格图中抽取结构信息，并结合基于几何距离构建的拓扑图，以辅助决策制定。依托这一拓扑图表示，我们构建了一个基于拓扑图匹配的决策网络，为每个机器人指定了边界点作为长期决策目标。通过在 Gazebo 和 Gibson 仿真环境中对现实世界场景的测试与应用，证实了我们的方法相较于现有技术在性能上实现了显著提升。",
    "title_cn": "ATR-Mapping：一种创新的非对称拓扑表示映射框架，专为多机器人环境探索而设计。",
    "tags": [
      "Agent",
      "机器人学",
      "自动驾驶"
    ]
  },
  {
    "title": "ComposerX: Multi-Agent Symbolic Music Composition with LLMs",
    "submit_datetime": "2024年04月28日",
    "abstract": "Music composition represents the creative side of humanity, and itself is a complex task that requires abilities to understand and generate information with long dependency and harmony constraints. While demonstrating impressive capabilities in STEM subjects, current LLMs easily fail in this task, generating ill-written music even when equipped with modern techniques like In-Context-Learning and Chain-of-Thoughts. To further explore and enhance LLMs' potential in music composition by leveraging their reasoning ability and the large knowledge base in music history and theory, we propose ComposerX, an agent-based symbolic music generation framework. We find that applying a multi-agent approach significantly improves the music composition quality of GPT-4. The results demonstrate that ComposerX is capable of producing coherent polyphonic music compositions with captivating melodies, while adhering to user instructions.",
    "pdf_link": "https://arxiv.org/abs/2404.18081",
    "graphs": [],
    "abstract_cn": "音乐创作展现了人类的创造天赋，它是一项需要深刻理解和创作长期依赖与和谐限制信息的复杂任务。尽管在科学、技术、工程和数学（STEM）领域取得了显著成就，但现有的大型语言模型（LLMs）在音乐创作上仍易遭遇挫折，即便借助了如上下文学习（In-Context-Learning）和思维链（Chain-of-Thoughts）等先进技术，也难以创作出流畅悦耳的音乐。为了深入挖掘并提升LLMs在音乐创作上的潜力，同时发挥其推理能力和丰富的音乐历史与理论知识，我们设计了ComposerX——一个基于代理的符号化音乐生成框架。实践证明，采用多代理策略显著提升了GPT-4的音乐创作水准。ComposerX不仅能够创作出旋律优美、和声丰富的复调音乐作品，还能准确遵循用户的创作指导。",
    "title_cn": "ComposerX：借助大型语言模型（LLMs），实现多代理参与的符号化音乐创作。",
    "tags": [
      "Agent",
      "",
      "人工智能"
    ]
  },
  {
    "title": "MMAC-Copilot: Multi-modal Agent Collaboration Operating System Copilot",
    "submit_datetime": "2024年04月28日",
    "abstract": "Autonomous virtual agents are often limited by their singular mode of interaction with real-world environments, restricting their versatility. To address this, we propose the Multi-Modal Agent Collaboration framework (MMAC-Copilot), a framework utilizes the collective expertise of diverse agents to enhance interaction ability with operating systems. The framework introduces a team collaboration chain, enabling each participating agent to contribute insights based on their specific domain knowledge, effectively reducing the hallucination associated with knowledge domain gaps. To evaluate the performance of MMAC-Copilot, we conducted experiments using both the GAIA benchmark and our newly introduced Visual Interaction Benchmark (VIBench). VIBench focuses on non-API-interactable applications across various domains, including 3D gaming, recreation, and office scenarios. MMAC-Copilot achieved exceptional performance on GAIA, with an average improvement of 6.8\\% over existing leading systems. Furthermore, it demonstrated remarkable capability on VIBench, particularly in managing various methods of interaction within systems and applications. These results underscore MMAC-Copilot's potential in advancing the field of autonomous virtual agents through its innovative approach to agent collaboration.",
    "pdf_link": "https://arxiv.org/abs/2404.18074",
    "graphs": [],
    "abstract_cn": "自主虚拟代理的多才多艺往往受限于它们与现实世界单一的交互模式。为突破这一局限，我们设计了多模态代理协作框架MMAC-Copilot，该框架汇聚了多样化代理的集体智慧，以提升与操作系统的交互效能。框架通过团队协作链路，让每位代理都能依据其领域专长提供洞见，有效降低了知识盲区所带来的误判。我们通过GAIA基准测试和新推出的可视化交互基准测试VIBench对MMAC-Copilot进行了性能评估。VIBench专注于非API交互式应用，覆盖3D游戏、娱乐和办公等多个领域。MMAC-Copilot在GAIA基准测试中表现卓越，相比现有顶尖系统平均提升了6.8%的效能。在VIBench测试中，它在处理系统和应用内多样化交互方式方面展现了非凡能力。这些成果凸显了MMAC-Copilot在推动自主虚拟代理领域发展上的潜力，其创新的协作机制功不可没。",
    "title_cn": "MMAC-Copilot：协同操作系统的多模态代理合作伴侣",
    "tags": [
      "Agent",
      "虚拟代理",
      "操作系统"
    ]
  },
  {
    "title": "Multi-Agent Reinforcement Learning for Energy Networks: Computational Challenges, Progress and Open Problems",
    "submit_datetime": "2024年04月28日",
    "abstract": "The rapidly changing architecture and functionality of electrical networks and the increasing penetration of renewable and distributed energy resources have resulted in various technological and managerial challenges. These have rendered traditional centralized energy-market paradigms insufficient due to their inability to support the dynamic and evolving nature of the network. This survey explores how multi-agent reinforcement learning (MARL) can support the decentralization and decarbonization of energy networks and mitigate the associated challenges. This is achieved by specifying key computational challenges in managing energy networks, reviewing recent research progress on addressing them, and highlighting open challenges that may be addressed using MARL.",
    "pdf_link": "https://arxiv.org/abs/2404.15583",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.15583v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15583/x1.png"
      }
    ],
    "abstract_cn": "随着电气网络架构和功能的快速演变，以及可再生与分布式能源资源的日益普及，我们面临着众多技术和管理挑战。这些挑战使得传统的集中式能源市场模式不再适用，因其无法适应网络的动态性和不断演变的需求。本篇综述文章深入探讨了多智能体强化学习（MARL）如何助力能源网络实现去中心化和低碳化，同时应对这些挑战。文章通过明确管理能源网络时面临的主要计算难题，回顾了近期在解决这些问题上的研究进展，并指出了未来可能通过MARL来解决的开放性问题。",
    "title_cn": "多智能体强化学习在能源网络领域的应用面临诸多计算挑战，尽管已有进展，但仍存在一些未解决的问题。",
    "tags": [
      "Agent",
      "能源管理",
      ""
    ]
  },
  {
    "title": "Learnable Linguistic Watermarks for Tracing Model Extraction Attacks on Large Language Models",
    "submit_datetime": "2024年04月28日",
    "abstract": "In the rapidly evolving domain of artificial intelligence, safeguarding the intellectual property of Large Language Models (LLMs) is increasingly crucial. Current watermarking techniques against model extraction attacks, which rely on signal insertion in model logits or post-processing of generated text, remain largely heuristic. We propose a novel method for embedding learnable linguistic watermarks in LLMs, aimed at tracing and preventing model extraction attacks. Our approach subtly modifies the LLM's output distribution by introducing controlled noise into token frequency distributions, embedding an statistically identifiable controllable watermark.We leverage statistical hypothesis testing and information theory, particularly focusing on Kullback-Leibler Divergence, to differentiate between original and modified distributions effectively. Our watermarking method strikes a delicate well balance between robustness and output quality, maintaining low false positive/negative rates and preserving the LLM's original performance.",
    "pdf_link": "https://arxiv.org/abs/2405.01509",
    "graphs": [],
    "abstract_cn": "随着人工智能领域的迅猛发展，确保大型语言模型（LLMs）的知识产权安全变得至关重要。目前，面对模型抽取攻击，主流的水印技术主要采用在模型逻辑输出中嵌入信号或对文本进行后期处理，这些手段大多基于经验。我们提出了一种创新的方法，通过在LLMs中嵌入可学习的语言学水印，用以追踪和防范模型抽取攻击。该方法通过在标记频率分布中引入控制性噪声，巧妙地调整了LLM的输出分布，嵌入了一种统计上可识别的水印。我们采用了统计假设检验和信息论的工具，特别是Kullback-Leibler散度，以高效区分原始与修改后的分布。我们的水印技术在保护模型安全的同时，保持了输出质量，实现了低误报率和误漏率，确保了LLM原始性能的稳定。",
    "title_cn": "为大型语言模型量身定制的可学习语言水印技术，旨在有效追踪并防范模型提取攻击。",
    "tags": [
      "LLM应用",
      "人工智能安全",
      "知识产权保护"
    ]
  },
  {
    "title": "Tabular Embedding Model (TEM): Finetuning Embedding Models For Tabular RAG Applications",
    "submit_datetime": "2024年04月28日",
    "abstract": "In recent times Large Language Models have exhibited tremendous capabilities, especially in the areas of mathematics, code generation and general-purpose reasoning. However for specialized domains especially in applications that require parsing and analyzing large chunks of numeric or tabular data even state-of-the-art (SOTA) models struggle. In this paper, we introduce a new approach to solving domain-specific tabular data analysis tasks by presenting a unique RAG workflow that mitigates the scalability issues of existing tabular LLM solutions. Specifically, we present Tabular Embedding Model (TEM), a novel approach to fine-tune embedding models for tabular Retrieval-Augmentation Generation (RAG) applications. Embedding models form a crucial component in the RAG workflow and even current SOTA embedding models struggle as they are predominantly trained on textual datasets and thus underperform in scenarios involving complex tabular data. The evaluation results showcase that our approach not only outperforms current SOTA embedding models in this domain but also does so with a notably smaller and more efficient model structure.",
    "pdf_link": "https://arxiv.org/abs/2405.01585",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.01585v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01585/generic_vs_tabular_embedding.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01585v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01585/tabular_rag_framework.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01585v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01585/dataset_generation.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01585v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01585/rol_play_data_generation.png"
      },
      {
        "url": "https://arxiv.org/html/2405.01585v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.01585/sample_questions.png"
      }
    ],
    "abstract_cn": "近期，大型语言模型在数学、代码生成和通用推理等领域展现出了惊人的能力。但面对需要处理和分析大量数值或表格数据的专业领域应用，即便是最尖端的模型也显得力不从心。本文提出了一种创新的方法，通过引入一种新的 RAG 工作流程，有效解决了现有表格 LLM 解决方案在可扩展性上的挑战。我们介绍了一种名为表格嵌入模型（TEM）的新方法，它专门针对表格检索增强生成（RAG）应用来微调嵌入模型。嵌入模型在 RAG 工作流程中扮演着核心角色，而现有的顶尖嵌入模型在处理复杂表格数据时往往表现不佳，因为它们主要是在文本数据集上进行训练的。我们的评估结果显示，TEM 不仅在性能上超越了当前的顶尖嵌入模型，而且模型结构更为紧凑，运行效率更高。",
    "title_cn": "表格嵌入模型（TEM）：针对表格 RAG 应用场景，对嵌入模型进行精细化调整。",
    "tags": [
      "RAG",
      "数据分析",
      "人工智能"
    ]
  },
  {
    "title": "Efficient LLM Inference with Kcache",
    "submit_datetime": "2024年04月27日",
    "abstract": "Large Language Models(LLMs) have had a profound impact on AI applications, particularly in the domains of long-text comprehension and generation. KV Cache technology is one of the most widely used techniques in the industry. It ensures efficient sequence generation by caching previously computed KV states. However, it also introduces significant memory overhead. We discovered that KV Cache is not necessary and proposed a novel KCache technique to alleviate the memory bottleneck issue during the LLMs inference process. KCache can be used directly for inference without any training process, Our evaluations show that KCache improves the throughput of popular LLMs by 40% with the baseline, while keeping accuracy.",
    "pdf_link": "https://arxiv.org/abs/2404.18057",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）极大地推动了人工智能应用的发展，尤其是在长文本的理解和生成方面。KV缓存技术因其高效生成序列的能力而在业界广受青睐，但它也带来了较大的内存开销。我们发现，KV缓存并非不可或缺，并创新性地提出了KCache技术，以解决LLMs在推理过程中的内存瓶颈。KCache无需训练即可直接用于推理，我们的测试结果表明，它能够将主流LLMs的吞吐量提升40%，同时保持了准确性。",
    "title_cn": "Kcache 助力大型语言模型推理，实现高效能。",
    "tags": [
      "分类：LLM应用",
      "人工智能",
      "内存优化"
    ]
  },
  {
    "title": "Utilizing Large Language Models for Information Extraction from Real Estate Transactions",
    "submit_datetime": "2024年04月27日",
    "abstract": "Real estate sales contracts contain crucial information for property transactions, but manual extraction of data can be time-consuming and error-prone. This paper explores the application of large language models, specifically transformer-based architectures, for automated information extraction from real estate contracts. We discuss challenges, techniques, and future directions in leveraging these models to improve efficiency and accuracy in real estate contract analysis.",
    "pdf_link": "https://arxiv.org/abs/2404.18043",
    "graphs": [],
    "abstract_cn": "房地产销售合同中蕴含着交易的核心信息，然而手动抽取这些信息不仅费时还易出错。本研究探讨了运用大型语言模型，尤其是基于变换器架构的模型，来自动化地从房地产合同中提取信息。文中还讨论了在利用这些模型提升房地产合同分析的效率与精确度方面所面临的挑战、采用的技术手段以及未来的发展方向。",
    "title_cn": "运用大型语言模型，深入挖掘房地产交易中的信息。",
    "tags": [
      "LLM应用",
      "房地产",
      "自动化信息提取"
    ]
  },
  {
    "title": "CRISPR-GPT: An LLM Agent for Automated Design of Gene-Editing Experiments",
    "submit_datetime": "2024年04月27日",
    "abstract": "The introduction of genome engineering technology has transformed biomedical research, making it possible to make precise changes to genetic information. However, creating an efficient gene-editing system requires a deep understanding of CRISPR technology, and the complex experimental systems under investigation. While Large Language Models (LLMs) have shown promise in various tasks, they often lack specific knowledge and struggle to accurately solve biological design problems. In this work, we introduce CRISPR-GPT, an LLM agent augmented with domain knowledge and external tools to automate and enhance the design process of CRISPR-based gene-editing experiments. CRISPR-GPT leverages the reasoning ability of LLMs to facilitate the process of selecting CRISPR systems, designing guide RNAs, recommending cellular delivery methods, drafting protocols, and designing validation experiments to confirm editing outcomes. We showcase the potential of CRISPR-GPT for assisting non-expert researchers with gene-editing experiments from scratch and validate the agent's effectiveness in a real-world use case. Furthermore, we explore the ethical and regulatory considerations associated with automated gene-editing design, highlighting the need for responsible and transparent use of these tools. Our work aims to bridge the gap between beginner biological researchers and CRISPR genome engineering techniques, and demonstrate the potential of LLM agents in facilitating complex biological discovery tasks.",
    "pdf_link": "https://arxiv.org/abs/2404.18021",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.18021v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18021/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18021v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18021/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18021v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18021/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18021v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18021/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18021v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18021/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18021v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18021/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18021v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18021/x7.png"
      }
    ],
    "abstract_cn": "基因组工程的革新为生物医学领域带来了翻天覆地的变化，使得对DNA进行精准编辑变得触手可及。但是，开发高效的基因编辑平台离不开对CRISPR技术的深刻洞察以及对实验体系的全面掌握。尽管大型语言模型（LLMs）在多领域展现出巨大潜力，它们在解决生物学设计问题时往往因缺乏专业知识而力不从心。本研究提出了CRISPR-GPT，这是一个融合了专业知识和外部工具的LLM智能体，旨在自动化并优化基于CRISPR的基因编辑实验设计流程。CRISPR-GPT发挥了LLMs的推理优势，简化了挑选CRISPR系统、构建导向RNA、选择细胞传递策略、制定实验方案以及规划验证实验等步骤。我们证明了CRISPR-GPT在辅助科研新手开展基因编辑实验方面的潜力，并在一个实际应用案例中检验了其效能。同时，我们也深入探讨了自动化基因编辑设计所引发的伦理和法规问题，强调了审慎和透明使用这些技术的重要性。我们的目标是连接生物学研究新手与CRISPR基因组工程技术的桥梁，并展现LLM智能体在推动复杂生物探索任务中的巨大潜力。",
    "title_cn": "CRISPR-GPT：自动化基因编辑实验设计的智能大型语言模型代理。",
    "tags": [
      "Agent",
      "生物医学",
      "基因编辑"
    ]
  },
  {
    "title": "LLMParser: An Exploratory Study on Using Large Language Models for Log Parsing",
    "submit_datetime": "2024年04月27日",
    "abstract": "Logs are important in modern software development with runtime information. Log parsing is the first step in many log-based analyses, that involve extracting structured information from unstructured log data. Traditional log parsers face challenges in accurately parsing logs due to the diversity of log formats, which directly impacts the performance of downstream log-analysis tasks. In this paper, we explore the potential of using Large Language Models (LLMs) for log parsing and propose LLMParser, an LLM-based log parser based on generative LLMs and few-shot tuning. We leverage four LLMs, Flan-T5-small, Flan-T5-base, LLaMA-7B, and ChatGLM-6B in LLMParsers. Our evaluation of 16 open-source systems shows that LLMParser achieves statistically significantly higher parsing accuracy than state-of-the-art parsers (a 96% average parsing accuracy). We further conduct a comprehensive empirical analysis on the effect of training size, model size, and pre-training LLM on log parsing accuracy. We find that smaller LLMs may be more effective than more complex LLMs; for instance where Flan-T5-base achieves comparable results as LLaMA-7B with a shorter inference time. We also find that using LLMs pre-trained using logs from other systems does not always improve parsing accuracy. While using pre-trained Flan-T5-base shows an improvement in accuracy, pre-trained LLaMA results in a decrease (decrease by almost 55% in group accuracy). In short, our study provides empirical evidence for using LLMs for log parsing and highlights the limitations and future research direction of LLM-based log parsers.",
    "pdf_link": "https://arxiv.org/abs/2404.18001",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.18001v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18001/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18001v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18001/x2.png"
      }
    ],
    "abstract_cn": "在现代软件开发中，日志作为运行时信息的载体扮演着关键角色。日志解析，即从非结构化日志数据中提取结构化信息，是许多基于日志分析的首要步骤。传统解析工具在处理多样化的日志格式时面临挑战，这直接关系到下游日志分析任务的效率。本文探讨了利用大型语言模型（LLMs）进行日志解析的可能性，并提出了LLMParser，这是一款基于生成性LLMs和少量样本微调的日志解析工具。我们采用了四种LLMs——Flan-T5-small、Flan-T5-base、LLaMA-7B和ChatGLM-6B——来构建LLMParser。通过对16个开源系统的评估，我们发现LLMParser在解析精度上显著超越了现有技术（平均解析精度达到96%）。此外，我们还深入分析了训练规模、模型大小和预训练LLM对日志解析精度的影响。研究发现，较小型的LLMs在某些情况下可能比更复杂的模型更为高效，如Flan-T5-base在较短的推理时间内就能达到与LLaMA-7B相似的结果。我们还观察到，使用其他系统日志预训练的LLMs并不总能提升解析精度。例如，尽管预训练的Flan-T5-base能够提高精度，但预训练的LLaMA却可能导致精度下降（组精度下降近55%）。总结来说，本研究为利用LLMs进行日志解析提供了实证基础，并指出了基于LLM的日志解析工具的局限性及未来研究的方向。",
    "title_cn": "LLMParser：探索性研究——利用大型语言模型进行日志解析。",
    "tags": [
      "LLM应用",
      "软件开发",
      "日志分析"
    ]
  },
  {
    "title": "MediFact at MEDIQA-CORR 2024: Why AI Needs a Human Touch",
    "submit_datetime": "2024年04月27日",
    "abstract": "Accurate representation of medical information is crucial for patient safety, yet artificial intelligence (AI) systems, such as Large Language Models (LLMs), encounter challenges in error-free clinical text interpretation. This paper presents a novel approach submitted to the MEDIQA-CORR 2024 shared task (Ben Abacha et al., 2024a), focusing on the automatic correction of single-word errors in clinical notes. Unlike LLMs that rely on extensive generic data, our method emphasizes extracting contextually relevant information from available clinical text data. Leveraging an ensemble of extractive and abstractive question-answering approaches, we construct a supervised learning framework with domain-specific feature engineering. Our methodology incorporates domain expertise to enhance error correction accuracy. By integrating domain expertise and prioritizing meaningful information extraction, our approach underscores the significance of a human-centric strategy in adapting AI for healthcare.",
    "pdf_link": "https://arxiv.org/abs/2404.17999",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.17999v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17999/Correct.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17999v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17999/error.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17999v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17999/corr1stepp.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17999v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17999/corr2stepp.png"
      }
    ],
    "abstract_cn": "确保医学信息的精确表达对保障患者安全极为关键。但是，人工智能（AI）系统，例如大型语言模型（LLMs），在准确解读临床文本时面临难题。本文介绍的是一种提交至2024年MEDIQA-CORR共同任务的创新方法（Ben Abacha等，2024a），该方法专注于自动修正临床记录中的单字错误。与依赖海量通用数据的LLMs不同，我们的方法侧重于从现有临床文本数据中抽取与上下文相关的信息。我们通过结合抽取式和生成式问答技术，构建了一个具有特定领域特征工程的监督学习框架。此外，我们的研究方法融合了领域专家知识，以提升错误修正的精确度。通过融合专家智慧并优先提取有价值的信息，我们的方法突出了在医疗保健领域应用AI时，采取以人为本策略的重要性。",
    "title_cn": "MediFact 在 2024 年 MEDIQA-CORR 竞赛中的表现：论人工智能为何离不开人类的温情触摸",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Enhancing Pre-Trained Generative Language Models with Question Attended Span Extraction on Machine Reading Comprehension",
    "submit_datetime": "2024年04月27日",
    "abstract": "Machine Reading Comprehension (MRC) poses a significant challenge in the field of Natural Language Processing (NLP). While mainstream MRC methods predominantly leverage extractive strategies using encoder-only models such as BERT, generative approaches face the issue of out-of-control generation -- a critical problem where answers generated are often incorrect, irrelevant, or unfaithful to the source text. To address these limitations in generative models for MRC, we introduce the Question-Attended Span Extraction (QASE) module. Integrated during the fine-tuning phase of pre-trained generative language models (PLMs), QASE significantly enhances their performance, allowing them to surpass the extractive capabilities of advanced Large Language Models (LLMs) such as GPT-4. Notably, these gains in performance do not come with an increase in computational demands. The efficacy of the QASE module has been rigorously tested across various datasets, consistently achieving or even surpassing state-of-the-art (SOTA) results.",
    "pdf_link": "https://arxiv.org/abs/2404.17991",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.17991v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17991/extractive_vs_generative.jpg"
      },
      {
        "url": "https://arxiv.org/html/2404.17991v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17991/QASE.jpg"
      },
      {
        "url": "https://arxiv.org/html/2404.17991v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17991/baseline.jpg"
      }
    ],
    "abstract_cn": "机器阅读理解（MRC）是自然语言处理（NLP）领域的一大难题。主流的 MRC 方法多采用如 BERT 这类仅编码器模型的提取式策略，而生成式方法则常遭遇生成失控的窘境——即生成的答案往往错误、无关或与原文不符。为克服 MRC 生成模型的局限，我们提出了问题关注跨度提取（QASE）模块。该模块在预训练的生成语言模型（PLMs）微调阶段整合，显著提升了模型性能，使其超越了如 GPT-4 等高级大型语言模型（LLMs）的提取性能。关键的是，性能的提升并未导致计算成本的增加。QASE 模块的效力已在多个数据集上经过严格验证，持续达到了或超越了当前最佳（SOTA）的成绩。",
    "title_cn": "通过引入问题导向的段落抽取技术，提升机器阅读理解任务中预训练生成语言模型的性能。",
    "tags": [
      "分类：LLM应用\n\n这篇论文主要讨论了机器阅读理解（MRC）领域的问题，并提出了一种新的模块——问题关注跨度提取（QASE）模块，以提高生成语言模型（PLMs）在MRC任务中的表现。这篇论文关注的是大型语言模型（LLMs）的应用，特别是在自然语言处理（NLP）领域，因此可以归类为LLM应用。",
      "",
      "机器阅读理解"
    ]
  },
  {
    "title": "Detection of Conspiracy Theories Beyond Keyword Bias in German-Language Telegram Using Large Language Models",
    "submit_datetime": "2024年04月27日",
    "abstract": "The automated detection of conspiracy theories online typically relies on supervised learning. However, creating respective training data requires expertise, time and mental resilience, given the often harmful content. Moreover, available datasets are predominantly in English and often keyword-based, introducing a token-level bias into the models. Our work addresses the task of detecting conspiracy theories in German Telegram messages. We compare the performance of supervised fine-tuning approaches using BERT-like models with prompt-based approaches using Llama2, GPT-3.5, and GPT-4 which require little or no additional training data. We use a dataset of $\\sim\\!\\! 4,000$ messages collected during the COVID-19 pandemic, without the use of keyword filters.\n  Our findings demonstrate that both approaches can be leveraged effectively: For supervised fine-tuning, we report an F1 score of $\\sim\\!\\! 0.8$ for the positive class, making our model comparable to recent models trained on keyword-focused English corpora. We demonstrate our model's adaptability to intra-domain temporal shifts, achieving F1 scores of $\\sim\\!\\! 0.7$. Among prompting variants, the best model is GPT-4, achieving an F1 score of $\\sim\\!\\! 0.8$ for the positive class in a zero-shot setting and equipped with a custom conspiracy theory definition.",
    "pdf_link": "https://arxiv.org/abs/2404.17985",
    "graphs": [],
    "abstract_cn": "网络中阴谋论的自动识别通常依赖监督学习方法。但制备相关训练集既需专业知识，又耗时劳心，特别是面对那些常含有害内容的数据。此外，目前的数据集多以英文为主，且多基于关键词，这可能导致模型在词符层面产生偏差。本研究旨在探索在德语 Telegram 消息中识别阴谋论的新方法。我们对比了基于 BERT 模型的监督微调与使用 Llama2、GPT-3.5 和 GPT-4 的提示法，后者几乎或完全不需要额外的训练数据。研究使用了 COVID-19 大流行期间收集的约 4,000 条消息组成的数据集，且未采用关键词过滤。研究发现，两种方法均显示出潜力：在监督微调方面，我们的模型在正类上达到了约 0.8 的 F1 分数，与近期基于英文关键词语料库训练的模型相媲美。我们还证明了模型能够适应领域内的时间变化，F1 分数约为 0.7。在提示法中，GPT-4 表现最佳，在零样本情况下正类 F1 分数达到约 0.8，并配备了自定义的阴谋论定义。",
    "title_cn": "利用大型语言模型，我们深入探讨了德语 Telegram 上的阴谋论，这一研究超越了传统的关键词搜索偏见，为我们提供了新的视角。",
    "tags": [
      "分类：LLM应用\n\n这篇论文主要探讨了在德语 Telegram 消息中识别阴谋论的新方法，使用了基于 BERT 模型的监督微调和使用 Llama2、GPT-3.5 和 GPT-4 的提示法。这些方法都涉及到了大型语言模型（LLM）的应用，因此将其归类为 LLM应用。",
      "社交媒体监控",
      ""
    ]
  },
  {
    "title": "TI-ASU: Toward Robust Automatic Speech Understanding through Text-to-speech Imputation Against Missing Speech Modality",
    "submit_datetime": "2024年04月27日",
    "abstract": "Automatic Speech Understanding (ASU) aims at human-like speech interpretation, providing nuanced intent, emotion, sentiment, and content understanding from speech and language (text) content conveyed in speech. Typically, training a robust ASU model relies heavily on acquiring large-scale, high-quality speech and associated transcriptions. However, it is often challenging to collect or use speech data for training ASU due to concerns such as privacy. To approach this setting of enabling ASU when speech (audio) modality is missing, we propose TI-ASU, using a pre-trained text-to-speech model to impute the missing speech. We report extensive experiments evaluating TI-ASU on various missing scales, both multi- and single-modality settings, and the use of LLMs. Our findings show that TI-ASU yields substantial benefits to improve ASU in scenarios where even up to 95% of training speech is missing. Moreover, we show that TI-ASU is adaptive to dropout training, improving model robustness in addressing missing speech during inference.",
    "pdf_link": "https://arxiv.org/abs/2404.17983",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.17983v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17983/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17983v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17983/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17983v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17983/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17983v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17983/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17983v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17983/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17983v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17983/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17983v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17983/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17983v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17983/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17983v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17983/x9.png"
      }
    ],
    "abstract_cn": "自动语音理解（ASU）致力于模拟人类的语音解析能力，能够从语音和文本内容中精准捕捉意图、情感、情绪和内容。尽管构建一个高效的 ASU 系统通常需要大量的高质量语音数据及其转录，但出于隐私保护的考虑，收集或利用这些数据往往面临诸多挑战。为此，我们提出了一种新颖的方法——TI-ASU，它利用预训练的文本到语音模型来弥补训练过程中缺失的语音信息。我们对 TI-ASU 在不同数据缺失比例、多模态与单模态环境以及大型语言模型（LLMs）中的应用进行了深入的实验测试。实验结果证明，TI-ASU 在训练语音数据缺失高达95%的情况下，仍能显著提升 ASU 的性能。此外，TI-ASU 还能适应于 dropout 训练，增强了模型在推理阶段处理缺失语音的鲁棒性。",
    "title_cn": "TI-ASU：通过文本到语音的转换技术，针对缺失的语音模式进行补偿，以提升自动语音理解的鲁棒性。",
    "tags": [
      "LLM应用",
      "语音识别",
      "自动语音理解"
    ]
  },
  {
    "title": "Advancing Healthcare Automation: Multi-Agent Systems for Medical Necessity Justification",
    "submit_datetime": "2024年04月27日",
    "abstract": "This paper explores the application of Swarm-Structured Multi-Agent Systems (MAS) to establish medical necessity, a process that involves a systematic review of patient-specific medical structured and unstructured data against clinical guidelines. We addressed this complex task by decomposing it into smaller, more manageable sub-tasks. Each sub-task is handled by a specialized AI agent. We conduct a systematic study of the impact of various prompting strategies on these agents and benchmark different Large Language Models (LLMs) to determine their accuracy in completing these tasks. Additionally, we investigate how these agents can provide explainability, thereby enhancing trust and transparency within the system.",
    "pdf_link": "https://arxiv.org/abs/2404.17977",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.17977v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17977/candidates.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17977v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17977/child.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17977v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17977/score.jpg"
      },
      {
        "url": "https://arxiv.org/html/2404.17977v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17977/time.jpg"
      }
    ],
    "abstract_cn": "本研究着眼于应用群体结构化多智能体系统（MAS）来评估医疗必要性，这一过程需要系统性地对照临床指南，审查患者的医疗结构化与非结构化数据。为应对这一挑战，我们将任务细化为易于操作的子任务，每个子任务由专责的AI智能体执行。我们对不同的提示策略对智能体的影响进行了系统性研究，并对比了多种大型语言模型（LLMs）的准确性。同时，我们也探讨了这些智能体如何增强系统的可解释性，以提升信任度和透明度。",
    "title_cn": "提升医疗自动化水平：多智能体系统在医疗需求论证中的应用。",
    "tags": [
      "分类：Agent",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Automating Customer Needs Analysis: A Comparative Study of Large Language Models in the Travel Industry",
    "submit_datetime": "2024年04月27日",
    "abstract": "In the rapidly evolving landscape of Natural Language Processing (NLP), Large Language Models (LLMs) have emerged as powerful tools for many tasks, such as extracting valuable insights from vast amounts of textual data. In this study, we conduct a comparative analysis of LLMs for the extraction of travel customer needs from TripAdvisor posts. Leveraging a diverse range of models, including both open-source and proprietary ones such as GPT-4 and Gemini, we aim to elucidate their strengths and weaknesses in this specialized domain. Through an evaluation process involving metrics such as BERTScore, ROUGE, and BLEU, we assess the performance of each model in accurately identifying and summarizing customer needs. Our findings highlight the efficacy of opensource LLMs, particularly Mistral 7B, in achieving comparable performance to larger closed models while offering affordability and customization benefits. Additionally, we underscore the importance of considering factors such as model size, resource requirements, and performance metrics when selecting the most suitable LLM for customer needs analysis tasks. Overall, this study contributes valuable insights for businesses seeking to leverage advanced NLP techniques to enhance customer experience and drive operational efficiency in the travel industry.",
    "pdf_link": "https://arxiv.org/abs/2404.17975",
    "graphs": [],
    "abstract_cn": "随着自然语言处理技术的飞速发展，大型语言模型（LLMs）已经展现出其在多种任务上的强大能力，比如从海量文本中挖掘关键信息。本研究通过对比分析，旨在探讨不同LLMs在提取TripAdvisor评论中旅行客户需求方面的效能。我们采用了包括开源和商业模型在内的多种模型，如GPT-4和Gemini，以揭示它们在这一特定领域的长短。通过BERTScore、ROUGE和BLEU等评价指标，我们对各模型在精准识别和概括客户需求上的表现进行了评估。研究结果显示，开源的LLMs，尤其是Mirage 7B，在性能上可与更大型的封闭模型相媲美，同时在成本效益和个性化定制方面具有优势。此外，我们还强调了在选择最合适的LLM进行客户需求分析时，需要考虑模型规模、资源需求和性能指标等关键因素。总体上，本研究为那些希望利用高端NLP技术来优化客户体验和提升旅游行业运营效率的企业提供了深刻的洞见。",
    "title_cn": "探索旅游业中的大型语言模型：自动化客户需求分析的比较研究",
    "tags": [
      "LLM应用",
      "",
      ""
    ]
  },
  {
    "title": "Automating Zero-Shot Patch Porting for Hard Forks",
    "submit_datetime": "2024年04月27日",
    "abstract": "Forking is a typical way of code reuse, which provides a simple way for developers to create a variant software (denoted as hard fork) by copying and modifying an existing codebase. Despite of the benefits, forking also leads to duplicate efforts in software maintenance. Developers need to port patches across the hard forks to address similar bugs or implement similar features. Due to the divergence between the source project and the hard fork, patch porting is complicated, which requires an adaption regarding different implementations of the same functionality. In this work, we take the first step to automate patch porting for hard forks under a zero-shot setting. We first conduct an empirical study of the patches ported from Vim to Neovim over the last ten years to investigate the necessities of patch porting and the potential flaws in the current practice. We then propose a large language model (LLM) based approach (namely PPatHF) to automatically port patches for hard forks on a function-wise basis. Specifically, PPatHF is composed of a reduction module and a porting module. Given the pre- and post-patch versions of a function from the reference project and the corresponding function from the target project, the reduction module first slims the input functions by removing code snippets less relevant to the patch. Then, the porting module leverages a LLM to apply the patch to the function from the target project. We evaluate PPatHF on 310 Neovim patches ported from Vim. The experimental results show that PPatHF outperforms the baselines significantly. Specifically, PPatHF can correctly port 131 (42.3%) patches and automate 57% of the manual edits required for the developer to port the patch.",
    "pdf_link": "https://arxiv.org/abs/2404.17964",
    "graphs": [],
    "abstract_cn": "代码分支是一种常见的复用手段，它允许开发者通过复制并修改现有代码库来创建软件的新变体，即硬分叉。尽管分支带来便利，但它也增加了软件维护的工作量，因为开发者必须在不同的硬分叉间同步补丁，以修复相似的问题或添加相同特性。由于源项目与硬分叉之间的差异，这一过程变得复杂且耗时。本研究首次尝试在零样本环境下自动化硬分叉的补丁移植。我们通过对过去十年 Vim 到 Neovim 的补丁移植情况进行了实证分析，以了解补丁移植的实际需求和现有方法的不足。基于此，我们提出了一种基于大型语言模型的新方法 PPatHF，它能够在函数级别自动移植硬分叉补丁。PPatHF 包含简化和移植两个模块，它首先精简函数输入，去除与补丁不相关的代码片段，然后利用语言模型将补丁应用到目标项目的函数上。我们在 310 个从 Vim 移植至 Neovim 的补丁上测试了 PPatHF，结果显示其性能显著超过现有基线，成功移植了 131 个（占比 42.3%）补丁，并减少了开发者 57% 的手动编辑工作量。",
    "title_cn": "实现零样本补丁的自动化移植，以应对硬分叉的挑战。",
    "tags": [
      "LLM应用",
      "软件工程",
      ""
    ]
  },
  {
    "title": "Spatio-Temporal Side Tuning Pre-trained Foundation Models for Video-based Pedestrian Attribute Recognition",
    "submit_datetime": "2024年04月27日",
    "abstract": "Existing pedestrian attribute recognition (PAR) algorithms are mainly developed based on a static image, however, the performance is unreliable in challenging scenarios, such as heavy occlusion, motion blur, etc. In this work, we propose to understand human attributes using video frames that can fully use temporal information by fine-tuning a pre-trained multi-modal foundation model efficiently. Specifically, we formulate the video-based PAR as a vision-language fusion problem and adopt a pre-trained foundation model CLIP to extract the visual features. More importantly, we propose a novel spatiotemporal side-tuning strategy to achieve parameter-efficient optimization of the pre-trained vision foundation model. To better utilize the semantic information, we take the full attribute list that needs to be recognized as another input and transform the attribute words/phrases into the corresponding sentence via split, expand, and prompt operations. Then, the text encoder of CLIP is utilized for embedding processed attribute descriptions. The averaged visual tokens and text tokens are concatenated and fed into a fusion Transformer for multi-modal interactive learning. The enhanced tokens will be fed into a classification head for pedestrian attribute prediction. Extensive experiments on two large-scale video-based PAR datasets fully validated the effectiveness of our proposed framework. The source code of this paper is available at https://github.com/Event-AHU/OpenPAR.",
    "pdf_link": "https://arxiv.org/abs/2404.17929",
    "graphs": [],
    "abstract_cn": "传统行人属性识别算法多建立在静态图像之上，面对重度遮挡或运动模糊等复杂情境时，其识别效果不尽人意。本研究提出一种新方法，通过视频帧捕捉时间信息，辅以高效微调的预训练多模态基础模型，以提升识别准确性。我们将视频驱动的PAR问题视作视觉与语言融合的挑战，并使用预训练模型CLIP来抽取视觉特征。此外，我们引入了一种创新的时空边调策略，优化了预训练视觉模型的参数效率。为了充分挖掘语义信息，我们将待识别的属性列表作为额外输入，通过分割、扩展和提示操作，将其转换为句子形式，再由CLIP的文本编码器进行嵌入处理。随后，视觉和文本标记的融合通过Transformer进行多模态交互学习，最终输出用于行人属性的预测分类。在两大视频基PAR数据集上的广泛实验，全面证实了我们框架的有效性。本研究的源代码已在GitHub发布，地址为：https://github.com/Event-AHU/OpenPAR。",
    "title_cn": "为视频驱动的行人属性识别任务，我们采用了时空侧向调整技术来优化预训练的基础模型。",
    "tags": [
      "Agent",
      "行人识别",
      "视频分析"
    ]
  },
  {
    "title": "I Have an Attention Bridge to Sell You: Generalization Capabilities of Modular Translation Architectures",
    "submit_datetime": "2024年04月27日",
    "abstract": "Modularity is a paradigm of machine translation with the potential of bringing forth models that are large at training time and small during inference. Within this field of study, modular approaches, and in particular attention bridges, have been argued to improve the generalization capabilities of models by fostering language-independent representations. In the present paper, we study whether modularity affects translation quality; as well as how well modular architectures generalize across different evaluation scenarios. For a given computational budget, we find non-modular architectures to be always comparable or preferable to all modular designs we study.",
    "pdf_link": "https://arxiv.org/abs/2404.17918",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.17918v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17918/shap-beeswarm-global.png"
      }
    ],
    "abstract_cn": "模块化作为机器翻译的新范式，能够在训练阶段构建大型模型，而在推理阶段则形成更为紧凑的模型。研究者们普遍认为，通过采用模块化方法，尤其是注意力桥接技术，可以增强模型的泛化能力，从而提升其对不同语言的适应性。本文旨在探讨模块化是否能够提升翻译的品质，并评估这类架构在多样化评估环境下的泛化表现。研究发现，在既定的计算资源下，非模块化架构在性能上总是可以与我们所研究的所有模块化设计相媲美，甚至更胜一筹。",
    "title_cn": "我向您推荐一座注意力之桥：探讨模块化翻译架构的泛化性能",
    "tags": [
      "分类：RAG\n\n这篇论文讨论了模块化在机器翻译中的应用，以及它是否能够提高翻译质量和模型的泛化能力。这属于机器翻译的范畴，而机器翻译是RAG（Retrieval-Augmented Generation）的一个应用领域。RAG是一种结合了检索（Retrieval）和生成（Generation）的模型，用于处理需要大量上下文信息的任务，如机器翻译。因此，这篇论文应该归类为RAG。",
      "机器翻译",
      ""
    ]
  },
  {
    "title": "SERPENT-VLM : Self-Refining Radiology Report Generation Using Vision Language Models",
    "submit_datetime": "2024年04月27日",
    "abstract": "Radiology Report Generation (R2Gen) demonstrates how Multi-modal Large Language Models (MLLMs) can automate the creation of accurate and coherent radiological reports. Existing methods often hallucinate details in text-based reports that don't accurately reflect the image content. To mitigate this, we introduce a novel strategy, SERPENT-VLM (SElf Refining Radiology RePort GENeraTion using Vision Language Models), which improves the R2Gen task by integrating a self-refining mechanism into the MLLM framework. We employ a unique self-supervised loss that leverages similarity between pooled image representations and the contextual representations of the generated radiological text, alongside the standard Causal Language Modeling objective, to refine image-text representations. This allows the model to scrutinize and align the generated text through dynamic interaction between a given image and the generated text, therefore reducing hallucination and continuously enhancing nuanced report generation. SERPENT-VLM outperforms existing baselines such as LLaVA-Med, BiomedGPT, etc., achieving SoTA performance on the IU X-ray and Radiology Objects in COntext (ROCO) datasets, and also proves to be robust against noisy images. A qualitative case study emphasizes the significant advancements towards more sophisticated MLLM frameworks for R2Gen, opening paths for further research into self-supervised refinement in the medical imaging domain.",
    "pdf_link": "https://arxiv.org/abs/2404.17912",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.17912v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17912/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17912v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17912/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17912v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17912/roco_bleu_bertscore.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17912v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17912/iu_xray_bleu_bertscore.png"
      }
    ],
    "abstract_cn": "放射学报告自动生成技术（R2Gen）通过多模态大型语言模型（MLLMs），实现了放射学报告的精确、连贯生成。传统方法在文本报告中常常凭空捏造细节，与图像内容不符。为此，我们提出了一种创新策略——SERPENT-VLM，即利用视觉语言模型自我完善的放射学报告生成，通过在MLLM框架中整合自我完善机制来提升R2Gen任务的表现。该策略采用了一种新颖的自监督损失函数，它通过比较池化后的图像表示与生成放射学文本的上下文表示的相似度，结合标准的因果语言建模目标，来优化图像与文本的表示。这样的设计使得模型能够在给定图像和生成文本之间进行动态交互，以审查和校准文本，减少虚假信息的产生，并不断提升报告生成的细节处理能力。SERPENT-VLM在IU X射线和放射学对象上下文（ROCO）数据集上超越了如LLaVA-Med、BiomedGPT等现有基准，展现了卓越的性能，并对噪声图像显示出良好的鲁棒性。一项定性案例研究突出了在构建更高级的R2Gen MLLM框架方面取得的显著进步，为医学影像领域的自监督精细化研究开辟了新路径。",
    "title_cn": "SERPENT-VLM：一种利用视觉语言模型实现自我精炼的放射学报告生成技术",
    "tags": [
      "LLM应用",
      "放射学",
      ""
    ]
  },
  {
    "title": "Tool Calling: Enhancing Medication Consultation via Retrieval-Augmented Large Language Models",
    "submit_datetime": "2024年04月27日",
    "abstract": "Large-scale language models (LLMs) have achieved remarkable success across various language tasks but suffer from hallucinations and temporal misalignment. To mitigate these shortcomings, Retrieval-augmented generation (RAG) has been utilized to provide external knowledge to facilitate the answer generation. However, applying such models to the medical domain faces several challenges due to the lack of domain-specific knowledge and the intricacy of real-world scenarios. In this study, we explore LLMs with RAG framework for knowledge-intensive tasks in the medical field. To evaluate the capabilities of LLMs, we introduce MedicineQA, a multi-round dialogue benchmark that simulates the real-world medication consultation scenario and requires LLMs to answer with retrieved evidence from the medicine database. MedicineQA contains 300 multi-round question-answering pairs, each embedded within a detailed dialogue history, highlighting the challenge posed by this knowledge-intensive task to current LLMs. We further propose a new \\textit{Distill-Retrieve-Read} framework instead of the previous \\textit{Retrieve-then-Read}. Specifically, the distillation and retrieval process utilizes a tool calling mechanism to formulate search queries that emulate the keyword-based inquiries used by search engines. With experimental results, we show that our framework brings notable performance improvements and surpasses the previous counterparts in the evidence retrieval process in terms of evidence retrieval accuracy. This advancement sheds light on applying RAG to the medical domain.",
    "pdf_link": "https://arxiv.org/abs/2404.17897",
    "graphs": [],
    "abstract_cn": "大规模语言模型（LLMs）在众多语言任务上取得了卓越成就，但它们也饱受幻觉和时间错位的困扰。为了解决这些问题，我们引入了检索增强生成（RAG）技术，以补充外部知识，优化答案生成过程。尽管如此，将这些模型应用于医学领域时，由于缺乏领域专业知识和现实世界情境的复杂性，我们面临多重挑战。本研究中，我们探讨了在医学领域知识密集型任务中应用RAG框架的LLMs。为了测试LLMs的性能，我们开发了MedicineQA，这是一个模拟真实世界药物咨询场景的多轮对话基准，要求LLMs依据药物数据库中的检索证据进行回答。MedicineQA包含300组多轮问答对，每组都置于详尽的对话背景之中，凸显了这一知识密集型任务对当前LLMs的挑战。此外，我们提出了一个创新的\\textit{蒸馏-检索-阅读}框架，替代了传统的\\textit{检索然后阅读}模式。在这个新框架中，蒸馏和检索过程通过工具调用机制生成搜索查询，模拟搜索引擎的关键词查询方式。实验结果显示，我们的框架在证据检索的准确性上显著提升了性能，并超越了以往的方法。这一进展为RAG技术在医学领域的应用开辟了新的可能性。",
    "title_cn": "工具调用：利用检索增强的大型语言模型提升药物咨询效果。",
    "tags": [
      "分类：RAG",
      "",
      "人工智能"
    ]
  },
  {
    "title": "How the Training Procedure Impacts the Performance of Deep Learning-based Vulnerability Patching",
    "submit_datetime": "2024年04月27日",
    "abstract": "Generative deep learning (DL) models have been successfully adopted for vulnerability patching. However, such models require the availability of a large dataset of patches to learn from. To overcome this issue, researchers have proposed to start from models pre-trained with general knowledge, either on the programming language or on similar tasks such as bug fixing. Despite the efforts in the area of automated vulnerability patching, there is a lack of systematic studies on how these different training procedures impact the performance of DL models for such a task. This paper provides a manyfold contribution to bridge this gap, by (i) comparing existing solutions of self-supervised and supervised pre-training for vulnerability patching; and (ii) for the first time, experimenting with different kinds of prompt-tuning for this task. The study required to train/test 23 DL models. We found that a supervised pre-training focused on bug-fixing, while expensive in terms of data collection, substantially improves DL-based vulnerability patching. When applying prompt-tuning on top of this supervised pre-trained model, there is no significant gain in performance. Instead, prompt-tuning is an effective and cheap solution to substantially boost the performance of self-supervised pre-trained models, i.e., those not relying on the bug-fixing pre-training.",
    "pdf_link": "https://arxiv.org/abs/2404.17896",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.17896v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17896/example.jpg"
      }
    ],
    "abstract_cn": "生成深度学习（DL）模型在漏洞修复领域取得了成功应用。但这些模型依赖于大量补丁数据集。为克服这一难题，研究者建议利用预训练模型，这些模型已通过编程语言或类似任务（如缺陷修复）的通用知识进行了训练。尽管在自动化漏洞修复方面取得了进展，但对于不同训练方法如何影响DL模型性能的系统性研究仍然不足。本文旨在填补这一空白，通过（i）对比自我监督与监督预训练方法在漏洞修复中的应用；（ii）首次探索为该任务设计的不同提示调整策略。研究共涉及23个DL模型的训练与测试。研究发现，专注于缺陷修复的监督预训练虽然在数据收集上成本较高，但能显著提升基于DL的漏洞修复效果。而在监督预训练模型上实施提示调整并未带来性能上的显著提升。相较之下，提示调整是一种高效且经济的方法，能够显著增强不依赖于缺陷修复预训练的自我监督预训练模型的性能。",
    "title_cn": "深度学习驱动的漏洞修复性能受训练流程的显著影响。",
    "tags": [
      "分类：LLM应用\n\n这篇论文主要研究了深度学习（DL）模型在漏洞修复领域的应用，特别是探讨了不同训练方法对DL模型性能的影响。虽然它涉及到了预训练模型和编程语言，但主要关注的是漏洞修复任务，这属于大型语言模型（LLM）的应用范畴。论文中提到的自我监督和监督预训练方法，以及提示调整策略，都是为了提高DL模型在漏洞修复任务中的性能。因此，这篇论文应该归类为LLM应用。",
      "软件工程",
      "漏洞修复"
    ]
  },
  {
    "title": "Using LLMs in Software Requirements Specifications: An Empirical Evaluation",
    "submit_datetime": "2024年04月27日",
    "abstract": "The creation of a Software Requirements Specification (SRS) document is important for any software development project. Given the recent prowess of Large Language Models (LLMs) in answering natural language queries and generating sophisticated textual outputs, our study explores their capability to produce accurate, coherent, and structured drafts of these documents to accelerate the software development lifecycle. We assess the performance of GPT-4 and CodeLlama in drafting an SRS for a university club management system and compare it against human benchmarks using eight distinct criteria. Our results suggest that LLMs can match the output quality of an entry-level software engineer to generate an SRS, delivering complete and consistent drafts. We also evaluate the capabilities of LLMs to identify and rectify problems in a given requirements document. Our experiments indicate that GPT-4 is capable of identifying issues and giving constructive feedback for rectifying them, while CodeLlama's results for validation were not as encouraging. We repeated the generation exercise for four distinct use cases to study the time saved by employing LLMs for SRS generation. The experiment demonstrates that LLMs may facilitate a significant reduction in development time for entry-level software engineers. Hence, we conclude that the LLMs can be gainfully used by software engineers to increase productivity by saving time and effort in generating, validating and rectifying software requirements.",
    "pdf_link": "https://arxiv.org/abs/2404.17842",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.17842v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17842/srs_template.pdf"
      },
      {
        "url": "https://arxiv.org/html/2404.17842v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17842/overall.pdf"
      },
      {
        "url": "https://arxiv.org/html/2404.17842v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17842/per_requirement.pdf"
      },
      {
        "url": "https://arxiv.org/html/2404.17842v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17842/mean_avg_deviation_verification.pdf"
      }
    ],
    "abstract_cn": "为软件开发项目制定软件需求规格说明书（SRS）极为关键。鉴于大型语言模型（LLMs）在处理自然语言查询和产出精致文本方面展现出的卓越能力，本研究旨在探究其能否高效生成准确、连贯且结构化的SRS文档草稿，以加快软件开发流程。我们对GPT-4和CodeLlama在起草大学俱乐部管理系统的SRS文档方面的表现进行了评估，并依据八项标准与人类工程师的工作进行了对比。研究结果显示，LLMs能够与初级软件工程师相媲美，制作出完整且一致的文档草稿。此外，我们还考察了LLMs在识别和修正需求文档中问题方面的能力。实验表明，GPT-4在这方面表现出色，能够发现问题并提供有益的修正建议，而CodeLlama在验证方面的成效则稍显不足。通过四个不同的应用场景，我们重复了文档生成实验，以探究使用LLMs能够为SRS文档生成节省多少时间。实验证明，LLMs能够显著降低初级软件工程师的开发时间。因此，我们得出结论，LLMs能够被软件工程师有效利用，通过在生成、验证和修正软件需求文档的过程中节省时间和精力，从而提升工作效率。",
    "title_cn": "探索大型语言模型在软件需求规格说明中的应用：一项实证研究。",
    "tags": [
      "LLM应用",
      "软件开发",
      ""
    ]
  },
  {
    "title": "VANER: Leveraging Large Language Model for Versatile and Adaptive Biomedical Named Entity Recognition",
    "submit_datetime": "2024年04月27日",
    "abstract": "Prevalent solution for BioNER involves using representation learning techniques coupled with sequence labeling. However, such methods are inherently task-specific, demonstrate poor generalizability, and often require dedicated model for each dataset. To leverage the versatile capabilities of recently remarkable large language models (LLMs), several endeavors have explored generative approaches to entity extraction. Yet, these approaches often fall short of the effectiveness of previouly sequence labeling approaches. In this paper, we utilize the open-sourced LLM LLaMA2 as the backbone model, and design specific instructions to distinguish between different types of entities and datasets. By combining the LLM's understanding of instructions with sequence labeling techniques, we use mix of datasets to train a model capable of extracting various types of entities. Given that the backbone LLMs lacks specialized medical knowledge, we also integrate external entity knowledge bases and employ instruction tuning to compel the model to densely recognize carefully curated entities. Our model VANER, trained with a small partition of parameters, significantly outperforms previous LLMs-based models and, for the first time, as a model based on LLM, surpasses the majority of conventional state-of-the-art BioNER systems, achieving the highest F1 scores across three datasets.",
    "pdf_link": "https://arxiv.org/abs/2404.17835",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.17835v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17835/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17835v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17835/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17835v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17835/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17835v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17835/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17835v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17835/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17835v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17835/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17835v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17835/x7.png"
      }
    ],
    "abstract_cn": "在生物医学命名实体识别（BioNER）领域，常见的方法是结合表示学习和序列标注技术。但这些方法往往局限于特定任务，泛化能力不佳，且通常需要为每个数据集定制模型。为了发挥大型语言模型（LLMs）的潜力，已有研究尝试采用生成式方法进行实体提取，但这些方法的有效性通常不及传统的序列标注技术。本文中，我们采用开源的LLM LLaMA2作为基础模型，并设计了特定的指令来识别不同类型和数据集的实体。我们将LLM对指令的理解与序列标注技术相结合，利用多样化的数据集训练出一个能够抽取多种实体的模型。考虑到基础LLM缺乏专业的医学知识，我们还引入了外部实体知识库，并实施了指令调优，以提高模型对精心挑选实体的识别能力。我们的VANER模型，仅用少量参数训练，便显著超越了以往的LLM模型，并首次作为基于LLM的模型，超越了大多数传统BioNER系统，实现了三个数据集上的最高F1得分。",
    "title_cn": "VANER：借助大型语言模型，实现生物医学领域的多用途和自适应命名实体识别。",
    "tags": [
      "LLM应用",
      "生物医学",
      ""
    ]
  },
  {
    "title": "Testing and Understanding Erroneous Planning in LLM Agents through Synthesized User Inputs",
    "submit_datetime": "2024年04月27日",
    "abstract": "Agents based on large language models (LLMs) have demonstrated effectiveness in solving a wide range of tasks by integrating LLMs with key modules such as planning, memory, and tool usage. Increasingly, customers are adopting LLM agents across a variety of commercial applications critical to reliability, including support for mental well-being, chemical synthesis, and software development. Nevertheless, our observations and daily use of LLM agents indicate that they are prone to making erroneous plans, especially when the tasks are complex and require long-term planning.\n  In this paper, we propose PDoctor, a novel and automated approach to testing LLM agents and understanding their erroneous planning. As the first work in this direction, we formulate the detection of erroneous planning as a constraint satisfiability problem: an LLM agent's plan is considered erroneous if its execution violates the constraints derived from the user inputs. To this end, PDoctor first defines a domain-specific language (DSL) for user queries and synthesizes varying inputs with the assistance of the Z3 constraint solver. These synthesized inputs are natural language paragraphs that specify the requirements for completing a series of tasks. Then, PDoctor derives constraints from these requirements to form a testing oracle. We evaluate PDoctor with three mainstream agent frameworks and two powerful LLMs (GPT-3.5 and GPT-4). The results show that PDoctor can effectively detect diverse errors in agent planning and provide insights and error characteristics that are valuable to both agent developers and users. We conclude by discussing potential alternative designs and directions to extend PDoctor.",
    "pdf_link": "https://arxiv.org/abs/2404.17833",
    "graphs": [],
    "abstract_cn": "利用大型语言模型（LLM）构建的智能代理通过整合规划、记忆和工具使用等核心组件，在解决多样化任务上展现了显著成效。客户对于这些在心理健康、化学合成和软件开发等关键商业领域中发挥可靠性支持作用的LLM代理的采纳日益增多。尽管如此，我们对LLM代理的日常观察和使用经验揭示了它们在面对需要长期规划的复杂任务时，制定计划容易出错的倾向。本文介绍了PDoctor，这是一种创新的自动化测试方法，旨在检测LLM代理的错误规划行为并深入理解其原因。作为该领域的开创性研究，我们将错误规划的识别问题转化为一个约束满足问题：如果代理的计划执行与用户输入推导出的约束相违背，则视为错误规划。PDoctor首先为用户查询设计了一种特定领域的语言（DSL），并利用Z3约束求解器辅助生成多样化的输入。这些输入以自然语言段落的形式，明确了一系列任务完成的具体要求。随后，PDoctor从这些要求中提取约束，构建了一个测试预言机。我们对PDoctor进行了评估，涵盖了三种主流的代理框架和两款先进的LLM（GPT-3.5和GPT-4）。评估结果显示，PDoctor能够有效识别代理规划中的多种错误，并为代理开发者和用户提供了宝贵的见解和错误特征。文末，我们讨论了PDoctor可能的替代设计和未来发展方向。",
    "title_cn": "通过合成用户输入，我们对大型语言模型（LLM）代理中的错误规划进行了测试与理解。",
    "tags": [
      "Agent",
      "心理健康",
      "软件开发"
    ]
  },
  {
    "title": "Evaluation of Few-Shot Learning for Classification Tasks in the Polish Language",
    "submit_datetime": "2024年04月27日",
    "abstract": "We introduce a few-shot benchmark consisting of 7 different classification tasks native to the Polish language. We conducted an empirical comparison with 0 and 16 shots between fine-tuning, linear probing, SetFit, and in-context learning (ICL) using various pre-trained commercial and open-source models. Our findings reveal that ICL achieves the best performance, with commercial models like GPT-3.5 and GPT-4 attaining the best performance. However, there remains a significant 14 percentage points gap between our best few-shot learning score and the performance of HerBERT-large fine-tuned on the entire training dataset. Among the techniques, SetFit emerges as the second-best approach, closely followed by linear probing. We observed the worst and most unstable performance with non-linear head fine-tuning. Results for ICL indicate that continual pre-training of models like Mistral-7b or Llama-2-13b on Polish corpora is beneficial. This is confirmed by the improved performances of Bielik-7b and Trurl-13b, respectively. To further support experiments in few-shot learning for Polish, we are releasing handcrafted templates for the ICL.",
    "pdf_link": "https://arxiv.org/abs/2404.17832",
    "graphs": [],
    "abstract_cn": "本研究提出了一个包含7项特定于波兰语的分类任务的少样本基准测试。我们对微调、线性探测、SetFit和上下文学习（ICL）等不同方法进行了实证比较，涉及0到16个样本点，并采用了多种预训练的商业和开源模型。研究发现ICL在性能上独占鳌头，尤其是商业模型GPT-3.5和GPT-4表现最为出色。尽管如此，即便是我们最佳的少样本学习得分，与在完整训练集上进行微调的HerBERT-large模型相比，仍有14个百分点的差距。在所有技术中，SetFit紧随ICL之后，成为次佳选择，而线性探测也表现不俗。相比之下，非线性头部微调的表现最差，且波动较大。ICL的结果显示，对Mistral-7b或Llama-2-13b等模型在波兰语文本上的持续预训练能够带来益处，这一点从Bielik-7b和Trurl-13b的提升性能中得到了验证。为了进一步推动波兰语少样本学习的实验研究，我们发布了为ICL精心设计的模板。",
    "title_cn": "本文旨在评估少样本学习在波兰语分类任务中的应用效果。",
    "tags": [
      "分类：LLM应用",
      "",
      "机器学习"
    ]
  },
  {
    "title": "Recall, Retrieve and Reason: Towards Better In-Context Relation Extraction",
    "submit_datetime": "2024年04月27日",
    "abstract": "Relation extraction (RE) aims to identify relations between entities mentioned in texts. Although large language models (LLMs) have demonstrated impressive in-context learning (ICL) abilities in various tasks, they still suffer from poor performances compared to most supervised fine-tuned RE methods. Utilizing ICL for RE with LLMs encounters two challenges: (1) retrieving good demonstrations from training examples, and (2) enabling LLMs exhibit strong ICL abilities in RE. On the one hand, retrieving good demonstrations is a non-trivial process in RE, which easily results in low relevance regarding entities and relations. On the other hand, ICL with an LLM achieves poor performance in RE while RE is different from language modeling in nature or the LLM is not large enough. In this work, we propose a novel recall-retrieve-reason RE framework that synergizes LLMs with retrieval corpora (training examples) to enable relevant retrieving and reliable in-context reasoning. Specifically, we distill the consistently ontological knowledge from training datasets to let LLMs generate relevant entity pairs grounded by retrieval corpora as valid queries. These entity pairs are then used to retrieve relevant training examples from the retrieval corpora as demonstrations for LLMs to conduct better ICL via instruction tuning. Extensive experiments on different LLMs and RE datasets demonstrate that our method generates relevant and valid entity pairs and boosts ICL abilities of LLMs, achieving competitive or new state-of-the-art performance on sentence-level RE compared to previous supervised fine-tuning methods and ICL-based methods.",
    "pdf_link": "https://arxiv.org/abs/2404.17809",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.17809v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17809/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17809v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17809/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17809v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17809/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17809v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17809/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17809v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17809/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17809v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17809/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17809v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17809/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17809v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17809/x8.png"
      }
    ],
    "abstract_cn": "关系抽取（RE）的目的是识别文本中实体间的关系。大型语言模型（LLMs）虽然在多项任务中展现了卓越的上下文学习能力（ICL），但与经过监督的微调RE方法相比，其性能仍有所不及。利用LLMs进行RE时，面临两大挑战：首先，从训练样本中提取出高质量的示例并非易事，这可能导致与实体和关系的相关性降低；其次，当RE任务的本质与语言建模不同，或LLM的规模不够大时，LLMs在RE任务中的ICL表现不佳。为此，我们提出了一种创新的“回忆-检索-推理”RE框架，该框架将LLMs与检索语料库（即训练样本）相结合，以实现有效的信息检索和可靠的上下文推理。具体而言，我们从训练数据集中提取出稳定的本体知识，指导LLMs生成与检索语料库紧密相关的实体对，作为有效的查询条件。这些实体对随后被用于从检索语料库中检索出相关训练样本，为LLMs提供更好的ICL示例，通过指令调整来优化学习效果。在多种LLMs和RE数据集上的广泛测试显示，我们的方法能够有效地生成相关且有效的实体对，并显著提升LLMs的ICL能力，与以往的监督式微调方法和基于ICL的方法相比，在句子级别的RE任务上取得了可比或更高的成绩。",
    "title_cn": "回顾、检索、推理：迈向更高效的语境内关系抽取",
    "tags": [
      "LLM应用",
      "",
      "关系抽取"
    ]
  },
  {
    "title": "Meta In-Context Learning Makes Large Language Models Better Zero and Few-Shot Relation Extractors",
    "submit_datetime": "2024年04月27日",
    "abstract": "Relation extraction (RE) is an important task that aims to identify the relationships between entities in texts. While large language models (LLMs) have revealed remarkable in-context learning (ICL) capability for general zero and few-shot learning, recent studies indicate that current LLMs still struggle with zero and few-shot RE. Previous studies are mainly dedicated to design prompt formats and select good examples for improving ICL-based RE. Although both factors are vital for ICL, if one can fundamentally boost the ICL capability of LLMs in RE, the zero and few-shot RE performance via ICL would be significantly improved. To this end, we introduce \\textsc{Micre} (\\textbf{M}eta \\textbf{I}n-\\textbf{C}ontext learning of LLMs for \\textbf{R}elation \\textbf{E}xtraction), a new meta-training framework for zero and few-shot RE where an LLM is tuned to do ICL on a diverse collection of RE datasets (i.e., learning to learn in context for RE). Through meta-training, the model becomes more effectively to learn a new RE task in context by conditioning on a few training examples with no parameter updates or task-specific templates at inference time, enabling better zero and few-shot task generalization. We experiment \\textsc{Micre} on various LLMs with different model scales and 12 public RE datasets, and then evaluate it on unseen RE benchmarks under zero and few-shot settings. \\textsc{Micre} delivers comparable or superior performance compared to a range of baselines including supervised fine-tuning and typical in-context learning methods. We find that the gains are particular significant for larger model scales, and using a diverse set of the meta-training RE datasets is key to improvements. Empirically, we show that \\textsc{Micre} can transfer the relation semantic knowledge via relation label name during inference on target RE datasets.",
    "pdf_link": "https://arxiv.org/abs/2404.17807",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.17807v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17807/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17807v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17807/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17807v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17807/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17807v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17807/x4.png"
      }
    ],
    "abstract_cn": "关系抽取（RE）是一项核心任务，目的在于识别文本实体间的关系。尽管大型语言模型（LLMs）在常规的零样本和少样本学习中展现了卓越的上下文学习能力（ICL），但最新研究指出，现有LLMs在处理零样本和少样本的关系抽取上仍有挑战。过往研究多集中于设计提示格式和挑选恰当的例子以提升基于ICL的RE性能。虽然这两点对ICL至关重要，但如果能够从根本上增强LLMs在RE任务上的ICL能力，那么通过ICL实现的零样本和少样本RE性能有望显著提升。基于此，我们提出了\\textsc{Micre}（元上下文学习框架，用于LLMs的关系抽取），这是一个针对零样本和少样本RE的新型元训练框架，通过在多样化的RE数据集上进行ICL，调整LLM以适应RE任务（即在RE的上下文中学会学习）。通过元训练，模型能够在推理阶段，仅依赖少数训练样本，无需参数更新或特定任务模板，更高效地学习新的RE任务上下文，从而提升零样本和少样本任务的泛化能力。我们在不同规模的多种LLMs上对\\textsc{Micre}进行了实验，并在12个公共RE数据集上进行了评估，随后在未见过的RE基准上进行了零样本和少样本设置下的测试。\\textsc{Micre}与包括监督微调和典型上下文学习方法在内的多种基线相比，展现出了相当或更优的性能。我们发现，对于更大规模的模型，提升尤为明显，且使用多样化的元训练RE数据集是提升性能的关键。实际上，我们证明了\\textsc{Micre}能够在目标RE数据集的推理过程中，通过关系标签名称传递关系语义知识。",
    "title_cn": "引入元上下文学习技术，大型语言模型在零样本和少样本关系抽取任务上的表现得到了显著提升。",
    "tags": [
      "LLM应用",
      "",
      "关系抽取"
    ]
  },
  {
    "title": "Verco: Learning Coordinated Verbal Communication for Multi-agent Reinforcement Learning",
    "submit_datetime": "2024年04月27日",
    "abstract": "In recent years, multi-agent reinforcement learning algorithms have made significant advancements in diverse gaming environments, leading to increased interest in the broader application of such techniques. To address the prevalent challenge of partial observability, communication-based algorithms have improved cooperative performance through the sharing of numerical embedding between agents. However, the understanding of the formation of collaborative mechanisms is still very limited, making designing a human-understandable communication mechanism a valuable problem to address. In this paper, we propose a novel multi-agent reinforcement learning algorithm that embeds large language models into agents, endowing them with the ability to generate human-understandable verbal communication. The entire framework has a message module and an action module. The message module is responsible for generating and sending verbal messages to other agents, effectively enhancing information sharing among agents. To further enhance the message module, we employ a teacher model to generate message labels from the global view and update the student model through Supervised Fine-Tuning (SFT). The action module receives messages from other agents and selects actions based on current local observations and received messages. Experiments conducted on the Overcooked game demonstrate our method significantly enhances the learning efficiency and performance of existing methods, while also providing an interpretable tool for humans to understand the process of multi-agent cooperation.",
    "pdf_link": "https://arxiv.org/abs/2404.17780",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.17780v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17780/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17780v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17780/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17780v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17780/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17780v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17780/x4.png"
      }
    ],
    "abstract_cn": "近期，多智能体强化学习在各类游戏场景中实现了重大突破，激发了将其应用于更广泛领域的热情。面对部分可观测性的难题，通过智能体间数值嵌入的共享，通信驱动的算法显著提升了协作效果。尽管如此，我们对于如何形成协作机制的理解尚浅，设计出易于人类理解的通信机制成为了一个亟待解决的问题。本文提出了一种创新的多智能体强化学习算法，该算法将大型语言模型集成到智能体中，使其能够产生易于人类理解的语言交流。框架包含消息生成模块和动作选择模块。消息模块负责生成并向同伴发送口头信息，以促进信息的有效共享。为了提升消息模块的性能，我们引入了一个教师模型来从全局视角生成消息标签，并通过监督式微调（SFT）来训练学生模型。动作模块则根据接收到的信息和局部观察来决策行动。在Overcooked游戏中的实验结果证明，我们的方法不仅显著提升了学习效率和表现，还为人类理解多智能体协作过程提供了一种直观的工具。",
    "title_cn": "Verco：探索多智能体强化学习中的协同口头沟通技巧",
    "tags": [
      "Agent",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Medical Vision-Language Pre-Training for Brain Abnormalities",
    "submit_datetime": "2024年04月27日",
    "abstract": "Vision-language models have become increasingly powerful for tasks that require an understanding of both visual and linguistic elements, bridging the gap between these modalities. In the context of multimodal clinical AI, there is a growing need for models that possess domain-specific knowledge, as existing models often lack the expertise required for medical applications. In this paper, we take brain abnormalities as an example to demonstrate how to automatically collect medical image-text aligned data for pretraining from public resources such as PubMed. In particular, we present a pipeline that streamlines the pre-training process by initially collecting a large brain image-text dataset from case reports and published journals and subsequently constructing a high-performance vision-language model tailored to specific medical tasks. We also investigate the unique challenge of mapping subfigures to subcaptions in the medical domain. We evaluated the resulting model with quantitative and qualitative intrinsic evaluations. The resulting dataset and our code can be found here https://github.com/masoud-monajati/MedVL_pretraining_pipeline",
    "pdf_link": "https://arxiv.org/abs/2404.17779",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.17779v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17779/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17779v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17779/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17779v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17779/x3.png"
      }
    ],
    "abstract_cn": "视觉-语言模型在处理视觉与语言元素并重的任务上愈发展现出其强大能力，有效地连接了视觉与语言两大领域。在多模态临床人工智能领域，对于具备特定领域知识的模型的需求不断上升，因为现有的模型往往缺少医疗应用所需的专业技能。本文以脑部异常为例，介绍了如何自动从PubMed等公共资源中收集医学图像与文本对齐数据，用于模型的预训练。我们设计了一个高效的流程，首先从病例报告和学术期刊中搜集大量脑部图像与文本数据，进而构建一个专为特定医疗任务优化的高性能视觉-语言模型。此外，我们还探讨了在医学领域内将子图与子标题对应起来的独特挑战。通过定量和定性的内在评估方法，我们对所构建的模型进行了评估。相关数据集和代码已在以下链接公开：https://github.com/masoud-monajati/MedVL_pretraining_pipeline",
    "title_cn": "医学视觉与语言预训练：探索脑部异常识别",
    "tags": [
      "分类：LLM应用\n\n这篇论文摘要描述了视觉-语言模型在多模态临床人工智能领域的应用，特别是在处理脑部异常的医疗任务中。论文介绍了如何从公共资源中收集医学图像与文本对齐数据，用于模型的预训练，并构建了一个专为特定医疗任务优化的高性能视觉-语言模型。这篇论文主要关注于实际应用，因此可以归类为LLM应用。",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Swarm-based gradient descent meets simulated annealing",
    "submit_datetime": "2024年04月27日",
    "abstract": "We introduce a novel method for non-convex optimization which is at the interface between the swarm-based gradient-descent (SBGD) [J. Lu et. al., ArXiv:2211.17157; E.Tadmor and A. Zenginoglu, Acta Applicandae Math., 190, 2024] and Simulated Annealing (SA) [V. Cerny, J. optimization theory and appl., 45:41-51, 1985; S.Kirkpatrick et. al., Science, 220(4598):671-680, 1983; S. Geman and C.-R. Hwang, SIAM J. Control and Optimization, 24(5):1031-1043, 1986]. We follow the methodology of SBGD in which a swarm of agents, each identified with a position, ${\\mathbf x}$ and mass $m$, explores the ambient space. The agents proceed in gradient descent direction, and are subject to Brownian motion with annealing-rate dictated by a decreasing function of their mass. Thus, instead of the SA protocol for time-decreasing temperature, we let the swarm decide how to `cool down' agents, depending on their accumulated mass over time. The dynamics of masses is coupled with the dynamics of positions: agents at higher ground transfer (part of) their mass to those at lower ground. Consequently, the swarm is dynamically divided between heavier, cooler agents viewed as `leaders' and lighter, warmer agents viewed as `explorers'. Mean-field convergence analysis and benchmark optimizations demonstrate the effectiveness of the swarm-based method as a multi-dimensional global optimizer.",
    "pdf_link": "https://arxiv.org/abs/2404.18015",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.18015v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18015/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18015v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18015/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18015v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18015/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18015v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18015/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18015v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18015/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18015v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18015/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18015v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18015/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18015v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18015/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18015v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18015/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18015v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18015/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18015v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18015/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18015v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18015/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18015v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18015/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18015v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18015/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18015v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18015/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18015v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18015/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18015v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18015/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18015v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18015/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18015v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18015/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18015v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18015/x20.png"
      },
      {
        "url": "https://arxiv.org/html/2404.18015v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.18015/x21.png"
      }
    ],
    "abstract_cn": "本文提出了一种创新的非凸优化技术，它融合了群体梯度下降（SBGD）与模拟退火（SA）的精髓。在这种方法中，一群具有特定位置和质量的代理在空间中探索，它们顺着梯度下降的方向移动，并受到与其质量相关的退火率影响的布朗运动。不同于 SA 中随时间递减的温度规则，这里我们让群体根据代理随时间累积的质量来自主决定“降温”策略。代理的质量变化与位置变化相互关联：位于能量较高位置的代理会将其部分质量转移给能量较低位置的代理。这样的机制使得群体自动分化为“领导者”和“探索者”两种角色，前者质量较大、温度较低，后者则相反。通过平均场收敛分析和一系列基准优化测试，我们证实了这种基于群体的优化方法在多维全局优化问题上的强大性能。",
    "title_cn": "群体梯度下降与模拟退火的结合。",
    "tags": [
      "分类：Agent",
      "优化算法",
      "计算科学"
    ]
  },
  {
    "title": "VIEW: Visual Imitation Learning with Waypoints",
    "submit_datetime": "2024年04月27日",
    "abstract": "Robots can use Visual Imitation Learning (VIL) to learn everyday tasks from video demonstrations. However, translating visual observations into actionable robot policies is challenging due to the high-dimensional nature of video data. This challenge is further exacerbated by the morphological differences between humans and robots, especially when the video demonstrations feature humans performing tasks. To address these problems we introduce Visual Imitation lEarning with Waypoints (VIEW), an algorithm that significantly enhances the sample efficiency of human-to-robot VIL. VIEW achieves this efficiency using a multi-pronged approach: extracting a condensed prior trajectory that captures the demonstrator's intent, employing an agent-agnostic reward function for feedback on the robot's actions, and utilizing an exploration algorithm that efficiently samples around waypoints in the extracted trajectory. VIEW also segments the human trajectory into grasp and task phases to further accelerate learning efficiency. Through comprehensive simulations and real-world experiments, VIEW demonstrates improved performance compared to current state-of-the-art VIL methods. VIEW enables robots to learn a diverse range of manipulation tasks involving multiple objects from arbitrarily long video demonstrations. Additionally, it can learn standard manipulation tasks such as pushing or moving objects from a single video demonstration in under 30 minutes, with fewer than 20 real-world rollouts. Code and videos here: https://collab.me.vt.edu/view/",
    "pdf_link": "https://arxiv.org/abs/2404.17906",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.17906v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17906/front.jpg"
      },
      {
        "url": "https://arxiv.org/html/2404.17906v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17906/method.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17906v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17906/prior.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17906v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17906/exploration_bb.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17906v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17906/exploration_sampling.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17906v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17906/sim_tasks.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17906v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17906/sim_noise.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17906v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17906/sim_no_squishe.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17906v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17906/sim_exploration.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17906v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17906/sim_residual.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17906v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17906/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17906v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17906/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17906v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17906/exp_single_object.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17906v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17906/exp_multi_object.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17906v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17906/exp_residual.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17906v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17906/objects.jpg"
      },
      {
        "url": "https://arxiv.org/html/2404.17906v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17906/whirl_issues.png"
      }
    ],
    "abstract_cn": "机器人利用视觉模仿学习（VIL）能通过视频示范掌握日常任务。但将视觉信息转化为机器人可执行策略面临挑战，尤其是当涉及人类与机器人形态差异时。为应对这些难题，我们推出了一种名为“带有关键点的视觉模仿学习（VIEW）”的算法，它显著提升了从人类到机器人的VIL样本效率。VIEW通过精炼的先验轨迹捕捉示范意图、采用通用奖励函数对机器人行为进行反馈，以及利用探索算法在轨迹关键点周围高效采样，实现了这一效率。此外，VIEW将人类示范划分为抓取和执行阶段，以加快学习进程。经过广泛的模拟和现实世界测试，VIEW在性能上超越了现有的VIL技术。它使得机器人能够从任意长度的视频示范中学习多样化的操控任务。而且，VIEW还能在30分钟内，通过不到20次实际操作，学会如推或移动物体等标准操控任务。相关代码和视频在此链接：https://collab.me.vt.edu/view/",
    "title_cn": "VIEW：一种基于关键节点的视觉模仿学习方法",
    "tags": [
      "Agent",
      "机器人技术",
      "视觉模仿学习"
    ]
  },
  {
    "title": "Probabilistic Inference in Language Models via Twisted Sequential Monte Carlo",
    "submit_datetime": "2024年04月26日",
    "abstract": "Numerous capability and safety techniques of Large Language Models (LLMs), including RLHF, automated red-teaming, prompt engineering, and infilling, can be cast as sampling from an unnormalized target distribution defined by a given reward or potential function over the full sequence. In this work, we leverage the rich toolkit of Sequential Monte Carlo (SMC) for these probabilistic inference problems. In particular, we use learned twist functions to estimate the expected future value of the potential at each timestep, which enables us to focus inference-time computation on promising partial sequences. We propose a novel contrastive method for learning the twist functions, and establish connections with the rich literature of soft reinforcement learning. As a complementary application of our twisted SMC framework, we present methods for evaluating the accuracy of language model inference techniques using novel bidirectional SMC bounds on the log partition function. These bounds can be used to estimate the KL divergence between the inference and target distributions in both directions. We apply our inference evaluation techniques to show that twisted SMC is effective for sampling undesirable outputs from a pretrained model (a useful component of harmlessness training and automated red-teaming), generating reviews with varied sentiment, and performing infilling tasks.",
    "pdf_link": "https://arxiv.org/abs/2404.17546",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）的多项能力和安全技术，如RLHF、自动化红队对抗、提示设计和填充技术，本质上是从由奖励或潜能函数定义的未归一化目标分布中进行抽样。本研究中，我们采用了序列蒙特卡洛（SMC）方法来解决这些概率推断难题。我们特别利用学习到的扭曲函数来预测每个时间点潜能的期望未来值，从而将推断计算的重点放在有潜力的部分序列上。我们提出了一种创新的对比学习方法来训练这些扭曲函数，并与软强化学习领域的丰富文献建立了联系。此外，我们还展示了一种评估语言模型推断精度的新方法，即利用双向SMC界限来估计对数划分函数，进而计算推断分布与目标分布之间的KL散度。我们应用这些推断评估技术，证明了扭曲SMC在从预训练模型中抽取不良输出、生成情感多样的评论以及执行填充任务方面的有效性。",
    "title_cn": "本文介绍了一种新颖的方法，即通过扭曲的顺序蒙特卡洛（Twisted Sequential Monte Carlo）技术，来增强语言模型中的概率推断能力。",
    "tags": [
      "分类：LLM理论",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Exploring the Distinctiveness and Fidelity of the Descriptions Generated by Large Vision-Language Models",
    "submit_datetime": "2024年04月26日",
    "abstract": "Large Vision-Language Models (LVLMs) are gaining traction for their remarkable ability to process and integrate visual and textual data. Despite their popularity, the capacity of LVLMs to generate precise, fine-grained textual descriptions has not been fully explored. This study addresses this gap by focusing on \\textit{distinctiveness} and \\textit{fidelity}, assessing how models like Open-Flamingo, IDEFICS, and MiniGPT-4 can distinguish between similar objects and accurately describe visual features. We proposed the Textual Retrieval-Augmented Classification (TRAC) framework, which, by leveraging its generative capabilities, allows us to delve deeper into analyzing fine-grained visual description generation. This research provides valuable insights into the generation quality of LVLMs, enhancing the understanding of multimodal language models. Notably, MiniGPT-4 stands out for its better ability to generate fine-grained descriptions, outperforming the other two models in this aspect. The code is provided at \\url{https://anonymous.4open.science/r/Explore_FGVDs-E277}.",
    "pdf_link": "https://arxiv.org/abs/2404.17534",
    "graphs": [],
    "abstract_cn": "大型视觉-语言模型（LVLMs）因其卓越的视觉与文本数据处理能力而备受瞩目。然而，这些模型在生成精细、详尽的文本描述方面的潜力尚未被充分挖掘。本研究聚焦于“独特性”与“忠实度”，探讨了Open-Flamingo、IDEFICS和MiniGPT-4等模型区分相似物体和精确表述视觉特征的能力。我们引入了文本检索增强分类（TRAC）框架，借助其生成特性，深入探讨了细粒度视觉描述的生成机制。此项研究深化了我们对LVLMs生成质量的认识，尤其是在多模态语言模型的理解上。特别值得一提的是，MiniGPT-4在生成精细描述方面表现更为出色，超越了其他两种模型。相关代码已在\\url{https://anonymous.4open.science/r/Explore_FGVDs-E277}提供。",
    "title_cn": "本文旨在探究大型视觉-语言模型所生成描述的独特性和准确性。",
    "tags": [
      "分类：LLM应用",
      "计算机视觉",
      ""
    ]
  },
  {
    "title": "Large Language Model Agent as a Mechanical Designer",
    "submit_datetime": "2024年04月26日",
    "abstract": "Conventional mechanical design paradigms rely on experts systematically refining concepts through experience-guided modification and FEA to meet specific requirements. However, this approach can be time-consuming and heavily dependent on prior knowledge and experience. While numerous machine learning models have been developed to streamline this intensive and expert-driven iterative process, these methods typically demand extensive training data and considerable computational resources. Furthermore, methods based on deep learning are usually restricted to the specific domains and tasks for which they were trained, limiting their applicability across different tasks. This creates a trade-off between the efficiency of automation and the demand for resources. In this study, we present a novel approach that integrates pre-trained LLMs with a FEM module. The FEM module evaluates each design and provides essential feedback, guiding the LLMs to continuously learn, plan, generate, and optimize designs without the need for domain-specific training. We demonstrate the effectiveness of our proposed framework in managing the iterative optimization of truss structures, showcasing its capability to reason about and refine designs according to structured feedback and criteria. Our results reveal that these LLM-based agents can successfully generate truss designs that comply with natural language specifications with a success rate of up to 90%, which varies according to the applied constraints. By employing prompt-based optimization techniques we show that LLM based agents exhibit optimization behavior when provided with solution-score pairs to iteratively refine designs to meet specifications. This ability of LLM agents to produce viable designs and optimize them based on their inherent reasoning capabilities highlights their potential to develop and implement effective design strategies autonomously.",
    "pdf_link": "https://arxiv.org/abs/2404.17525",
    "graphs": [],
    "abstract_cn": "传统机械设计依赖资深专家通过经验驱动的修改和有限元分析（FEA）来逐步完善设计，以满足特定需求。但这一过程不仅耗时，而且高度依赖于既有知识和经验。尽管众多机器学习模型被开发用以简化这一复杂且专家主导的迭代设计流程，它们往往需要庞大的训练数据集和高额的计算资源。特别是，基于深度学习的模型通常只适用于它们所训练的特定领域和任务，这限制了它们的通用性，从而在自动化效率和资源消耗之间形成了一种权衡。在本研究中，我们提出了一种创新的方法，将预训练的大型语言模型（LLM）与有限元模块（FEM）相结合。FEM模块对每个设计方案进行评估，并提供关键反馈，引导LLM进行持续的学习、规划、设计生成和优化，无需特定领域的训练。我们在桁架结构的迭代优化管理中证明了所提出框架的有效性，展示了其根据结构化反馈和标准进行设计推理和改进的能力。研究结果显示，基于LLM的智能体能够以高达90%的成功率生成符合自然语言规格的桁架设计，这一成功率会根据所施加的约束条件而变化。通过采用基于提示的优化技术，我们证明了基于LLM的智能体在提供解决方案与得分对时，能够展现出优化行为，以迭代方式精细化设计以满足特定规格。LLM智能体的这种能力，即基于其内在推理能力来生成可行的设计并进行优化，突显了它们在自主开发和实施有效设计策略方面的潜力。",
    "title_cn": "大型语言模型作为机械设计代理",
    "tags": [
      "分类：Agent\n\n这篇论文提出了一种将大型语言模型（LLM）与有限元模块（FEM）相结合的创新方法，用于自动化机械设计过程。该方法利用LLM的推理能力来生成和优化设计，而FEM模块则提供关键反馈以指导LLM的学习过程。这种方法展示了LLM在自主开发和实施有效设计策略方面的潜力，因此可以归类为Agent领域。",
      "机械设计",
      "人工智能"
    ]
  },
  {
    "title": "On the Use of Large Language Models to Generate Capability Ontologies",
    "submit_datetime": "2024年04月26日",
    "abstract": "Capability ontologies are increasingly used to model functionalities of systems or machines. The creation of such ontological models with all properties and constraints of capabilities is very complex and can only be done by ontology experts. However, Large Language Models (LLMs) have shown that they can generate machine-interpretable models from natural language text input and thus support engineers / ontology experts. Therefore, this paper investigates how LLMs can be used to create capability ontologies. We present a study with a series of experiments in which capabilities with varying complexities are generated using different prompting techniques and with different LLMs. Errors in the generated ontologies are recorded and compared. To analyze the quality of the generated ontologies, a semi-automated approach based on RDF syntax checking, OWL reasoning, and SHACL constraints is used. The results of this study are very promising because even for complex capabilities, the generated ontologies are almost free of errors.",
    "pdf_link": "https://arxiv.org/abs/2404.17524",
    "graphs": [],
    "abstract_cn": "能力本体论正日益广泛应用于系统或机器功能建模。构建这些包含所有属性和约束的本体论模型极为复杂，通常需要本体论专家的专业知识。幸运的是，大型语言模型（LLMs）已证明能够从自然语言文本中生成机器可理解的模型，为工程师和本体论专家提供助力。本篇论文探讨了如何利用LLMs来构建能力本体论。我们通过一系列实验研究，这些实验采用了不同的提示技巧和多种LLMs来生成不同复杂度的能力。实验中记录了生成本体论的错误，并进行了比较。为了评估生成本体论的质量，我们采用了一种结合RDF语法检查、OWL推理和SHACL约束的半自动化分析方法。研究结果显示，即便是处理复杂能力，生成的本体论也几乎无误，这一成果令人鼓舞。",
    "title_cn": "探讨如何利用大型语言模型来构建能力本体的实践",
    "tags": [
      "LLM应用",
      "系统建模",
      "人工智能"
    ]
  },
  {
    "title": "Enhancing Legal Compliance and Regulation Analysis with Large Language Models",
    "submit_datetime": "2024年04月26日",
    "abstract": "This research explores the application of Large Language Models (LLMs) for automating the extraction of requirement-related legal content in the food safety domain and checking legal compliance of regulatory artifacts. With Industry 4.0 revolutionizing the food industry and with the General Data Protection Regulation (GDPR) reshaping privacy policies and data processing agreements, there is a growing gap between regulatory analysis and recent technological advancements. This study aims to bridge this gap by leveraging LLMs, namely BERT and GPT models, to accurately classify legal provisions and automate compliance checks. Our findings demonstrate promising results, indicating LLMs' significant potential to enhance legal compliance and regulatory analysis efficiency, notably by reducing manual workload and improving accuracy within reasonable time and financial constraints.",
    "pdf_link": "https://arxiv.org/abs/2404.17522",
    "graphs": [],
    "abstract_cn": "本研究着眼于利用大型语言模型（LLMs）自动化提取食品安全领域的法律相关内容，并确保监管文件的合法性。在工业4.0浪潮推动食品行业转型，以及GDPR新规重塑隐私政策与数据处理协议的背景下，法规分析与技术进步之间出现了脱节。通过运用BERT和GPT等LLMs，研究旨在精确分类法律条文并实现合规性检查的自动化，以期填补这一空白。研究结果显示，LLMs在提升法律合规性和监管分析的效率方面展现出巨大潜力，显著降低了人工操作的负担，并在可控的时间和成本范围内提高了准确性。",
    "title_cn": "借助大型语言模型，提升法律合规与法规分析的效能",
    "tags": [
      "LLM应用",
      "食品安全",
      "法律合规"
    ]
  },
  {
    "title": "A Comprehensive Evaluation on Event Reasoning of Large Language Models",
    "submit_datetime": "2024年04月26日",
    "abstract": "Event reasoning is a fundamental ability that underlies many applications. It requires event schema knowledge to perform global reasoning and needs to deal with the diversity of the inter-event relations and the reasoning paradigms. How well LLMs accomplish event reasoning on various relations and reasoning paradigms remains unknown. To mitigate this disparity, we comprehensively evaluate the abilities of event reasoning of LLMs. We introduce a novel benchmark EV2 for EValuation of EVent reasoning. EV2 consists of two levels of evaluation of schema and instance and is comprehensive in relations and reasoning paradigms. We conduct extensive experiments on EV2. We find that LLMs have abilities to accomplish event reasoning but their performances are far from satisfactory. We also notice the imbalance of event reasoning abilities in LLMs. Besides, LLMs have event schema knowledge, however, they're not aligned with humans on how to utilize the knowledge. Based on these findings, we introduce two methods to guide the LLMs to utilize the event schema knowledge. Both methods achieve improvements.",
    "pdf_link": "https://arxiv.org/abs/2404.17513",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.17513v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17513/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17513v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17513/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17513v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17513/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17513v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17513/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17513v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17513/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17513v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17513/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17513v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17513/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17513v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17513/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17513v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17513/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17513v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17513/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17513v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17513/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17513v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17513/x14.png"
      }
    ],
    "abstract_cn": "事件推理是支撑众多应用的基本技能，它依赖于事件模式知识以进行全局推理，并需应对事件间复杂关系及多样化的推理范式。目前，大型语言模型（LLMs）在不同关系和推理范式上的事件推理表现尚未明确。为了填补这一空白，我们对LLMs的事件推理能力进行了全面评估，并推出了EV2这一新的基准测试平台，旨在全面评估事件推理能力。EV2包含模式和实例两个层面的评估，覆盖了广泛的事件关系和推理范式。通过在EV2上的广泛实验，我们发现LLMs虽具备事件推理能力，但其表现尚有较大提升空间。我们还观察到LLMs在事件推理能力上存在不平衡现象。此外，尽管LLMs具备事件模式知识，但它们在如何应用这些知识上与人类存在差异。针对这些发现，我们提出了两种方法，引导LLMs更好地利用事件模式知识，两者均取得了显著提升。",
    "title_cn": "本文全面审视了大型语言模型在事件推理方面的表现。",
    "tags": [
      "分类：LLM应用",
      "人工智能",
      "事件推理"
    ]
  },
  {
    "title": "Ruffle&Riley: Insights from Designing and Evaluating a Large Language Model-Based Conversational Tutoring System",
    "submit_datetime": "2024年04月26日",
    "abstract": "Conversational tutoring systems (CTSs) offer learning experiences through interactions based on natural language. They are recognized for promoting cognitive engagement and improving learning outcomes, especially in reasoning tasks. Nonetheless, the cost associated with authoring CTS content is a major obstacle to widespread adoption and to research on effective instructional design. In this paper, we discuss and evaluate a novel type of CTS that leverages recent advances in large language models (LLMs) in two ways: First, the system enables AI-assisted content authoring by inducing an easily editable tutoring script automatically from a lesson text. Second, the system automates the script orchestration in a learning-by-teaching format via two LLM-based agents (Ruffle&Riley) acting as a student and a professor. The system allows for free-form conversations that follow the ITS-typical inner and outer loop structure. We evaluate Ruffle&Riley's ability to support biology lessons in two between-subject online user studies (N = 200) comparing the system to simpler QA chatbots and reading activity. Analyzing system usage patterns, pre/post-test scores and user experience surveys, we find that Ruffle&Riley users report high levels of engagement, understanding and perceive the offered support as helpful. Even though Ruffle&Riley users require more time to complete the activity, we did not find significant differences in short-term learning gains over the reading activity. Our system architecture and user study provide various insights for designers of future CTSs. We further open-source our system to support ongoing research on effective instructional design of LLM-based learning technologies.",
    "pdf_link": "https://arxiv.org/abs/2404.17460",
    "graphs": [],
    "abstract_cn": "会话式辅导系统（CTSs）利用自然语言互动提供学习体验，尤其在推理任务中，它们因其提升认知参与度和学习成效而备受推崇。然而，创作CTS内容的高昂成本成为了普及应用和深入教学设计研究的一大障碍。本文探讨并评估了一种新型CTS，它通过两种方式利用了大型语言模型（LLMs）的最新进展：首先，系统能够自动从课程文本生成易于编辑的辅导脚本，辅助AI内容创作；其次，通过两个基于LLM的代理（Ruffle&Riley）——分别模拟学生和教师的角色，系统自动化地在教学相长模式下编排对话脚本。该系统支持自由形式的对话，遵循智能辅导系统（ITS）的典型内外循环结构。通过两项在线用户研究（共200名参与者），我们评估了Ruffle&Riley在支持生物学课程方面的表现，并将其与简单的问答聊天机器人和阅读活动进行了对比。研究分析了系统使用模式、前后测试成绩以及用户体验调查，结果显示Ruffle&Riley的用户表现出高度的参与感、理解力，并认为所提供的帮助非常有用。尽管使用Ruffle&Riley的用户完成活动所需时间更长，但在短期学习成果上与阅读活动相比并无显著差异。我们的系统架构和用户研究为未来CTS设计者提供了宝贵的洞见，并且我们开源了系统，以支持对基于LLM的学习技术进行有效教学设计的持续研究。",
    "title_cn": "Ruffle&Riley：设计和评估一款基于大型语言模型的对话式教学系统的经验与洞见",
    "tags": [
      "Agent",
      "",
      "人工智能"
    ]
  },
  {
    "title": "\"ChatGPT Is Here to Help, Not to Replace Anybody\" -- An Evaluation of Students' Opinions On Integrating ChatGPT In CS Courses",
    "submit_datetime": "2024年04月26日",
    "abstract": "Large Language Models (LLMs) like GPT and Bard are capable of producing code based on textual descriptions, with remarkable efficacy. Such technology will have profound implications for computing education, raising concerns about cheating, excessive dependence, and a decline in computational thinking skills, among others. There has been extensive research on how teachers should handle this challenge but it is also important to understand how students feel about this paradigm shift. In this research, 52 first-year CS students were surveyed in order to assess their views on technologies with code-generation capabilities, both from academic and professional perspectives. Our findings indicate that while students generally favor the academic use of GPT, they don't over rely on it, only mildly asking for its help. Although most students benefit from GPT, some struggle to use it effectively, urging the need for specific GPT training. Opinions on GPT's impact on their professional lives vary, but there is a consensus on its importance in academic practice.",
    "pdf_link": "https://arxiv.org/abs/2404.17443",
    "graphs": [],
    "abstract_cn": "像 GPT 和 Bard 这样的大型语言模型能够根据文本描述高效生成代码，这在计算机教育领域可能引发一系列问题，包括对作弊行为、过度依赖以及计算思维能力下降的担忧。尽管已有大量研究探讨教师如何应对这一挑战，但了解学生对于这种技术变革的态度同样关键。本研究调查了52名大一计算机科学学生，旨在了解他们对具有代码生成功能技术的学术和职业看法。调查结果显示，学生们普遍认可 GPT 在学术上的用途，但并不会过度依赖它，而是适度地寻求其辅助。尽管 GPT 对大多数学生有所帮助，但也有学生在使用上存在困难，这凸显了对 GPT 特定培训的需求。关于 GPT 对他们未来职业生涯的影响，学生们的看法各异，但在学术实践中，他们普遍认为 GPT 的重要性不容忽视。",
    "title_cn": "\"ChatGPT 旨在助力，而非取代\"——探讨学生对于将 ChatGPT 整合进计算机科学课程的意见评估",
    "tags": [
      "分类：LLM应用",
      "计算机教育",
      ""
    ]
  },
  {
    "title": "InspectorRAGet: An Introspection Platform for RAG Evaluation",
    "submit_datetime": "2024年04月26日",
    "abstract": "Large Language Models (LLM) have become a popular approach for implementing Retrieval Augmented Generation (RAG) systems, and a significant amount of effort has been spent on building good models and metrics. In spite of increased recognition of the need for rigorous evaluation of RAG systems, few tools exist that go beyond the creation of model output and automatic calculation. We present InspectorRAGet, an introspection platform for RAG evaluation. InspectorRAGet allows the user to analyze aggregate and instance-level performance of RAG systems, using both human and algorithmic metrics as well as annotator quality. InspectorRAGet is suitable for multiple use cases and is available publicly to the community. The demo video is available at https://youtu.be/MJhe8QIXcEc",
    "pdf_link": "https://arxiv.org/abs/2404.17347",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLM）在构建检索增强生成（RAG）系统方面备受青睐，为此，人们投入了大量精力来开发优秀的模型和评价标准。尽管对RAG系统进行严谨评估的需求日益增长，但目前能够超越模型输出生成和自动计算的工具却相当稀缺。我们推出了InspectorRAGet，这是一个用于评估RAG系统的深度分析平台。该平台支持用户通过人工和算法评价指标，以及评估注释者的质量，来深入分析RAG系统的综合和个体表现。InspectorRAGet适用于多种应用场景，并且已经向公众开放。相关演示视频可以在 https://youtu.be/MJhe8QIXcEc 观看。",
    "title_cn": "InspectorRAGet：一个用于评估 RAG（Retrieval-Augmented Generation，检索增强生成）的内省式平台",
    "tags": [
      "RAG",
      "",
      "信息检索"
    ]
  },
  {
    "title": "When to Trust LLMs: Aligning Confidence with Response Quality",
    "submit_datetime": "2024年04月26日",
    "abstract": "Despite the success of large language models (LLMs) in natural language generation, much evidence shows that LLMs may produce incorrect or nonsensical text. This limitation highlights the importance of discerning when to trust LLMs, especially in safety-critical domains. Existing methods, which rely on verbalizing confidence to tell the reliability by inducing top-k responses and sampling-aggregating multiple responses, often fail, due to the lack of objective guidance of confidence. To address this, we propose CONfidence-Quality-ORDerpreserving alignment approach (CONQORD), leveraging reinforcement learning with a tailored dual-component reward function. This function encompasses quality reward and orderpreserving alignment reward functions. Specifically, the order-preserving reward incentivizes the model to verbalize greater confidence for responses of higher quality to align the order of confidence and quality. Experiments demonstrate that our CONQORD significantly improves the alignment performance between confidence levels and response accuracy, without causing the model to become over-cautious. Furthermore, the aligned confidence provided by CONQORD informs when to trust LLMs, and acts as a determinant for initiating the retrieval process of external knowledge. Aligning confidence with response quality ensures more transparent and reliable responses, providing better trustworthiness.",
    "pdf_link": "https://arxiv.org/abs/2404.17287",
    "graphs": [],
    "abstract_cn": "尽管大型语言模型（LLMs）在自然语言生成领域取得了显著成就，但它们有时仍会产生错误或不合逻辑的文本。这一问题凸显了在安全至关重要的领域中，如何正确信任LLMs的重要性。目前的方法，通常依赖于通过生成置信度来评估模型的可靠性，但由于缺乏客观的置信度指导，这些方法常常失效。为了改善这一状况，我们提出了一种名为CONQORD的新型方法，该方法结合了强化学习和特别设计的双重奖励机制。这种机制不仅包含质量奖励，还包括顺序保持奖励，以激励模型对更高质量的输出表达更高的置信度，从而实现置信度与质量的一致性。实验结果证明，CONQORD显著提升了置信度与响应准确性的一致性，同时避免了模型过于保守。此外，CONQORD所提供的置信度对齐机制，不仅指导我们何时可以信赖LLMs，还作为触发外部知识检索过程的关键因素。通过确保置信度与响应质量的一致性，CONQORD确保了模型提供更透明、更可靠的输出，增强了其可信度。",
    "title_cn": "信赖大型语言模型的时机：确保信心与回答品质相匹配",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Reinforcement Retrieval Leveraging Fine-grained Feedback for Fact Checking News Claims with Black-Box LLM",
    "submit_datetime": "2024年04月26日",
    "abstract": "Retrieval-augmented language models have exhibited promising performance across various areas of natural language processing (NLP), including fact-critical tasks. However, due to the black-box nature of advanced large language models (LLMs) and the non-retrieval-oriented supervision signal of specific tasks, the training of retrieval model faces significant challenges under the setting of black-box LLM. We propose an approach leveraging Fine-grained Feedback with Reinforcement Retrieval (FFRR) to enhance fact-checking on news claims by using black-box LLM. FFRR adopts a two-level strategy to gather fine-grained feedback from the LLM, which serves as a reward for optimizing the retrieval policy, by rating the retrieved documents based on the non-retrieval ground truth of the task. We evaluate our model on two public datasets for real-world news claim verification, and the results demonstrate that FFRR achieves significant improvements over strong LLM-enabled and non-LLM baselines.",
    "pdf_link": "https://arxiv.org/abs/2404.17283",
    "graphs": [],
    "abstract_cn": "检索增强型语言模型在自然语言处理（NLP）的多个领域，尤其是在关键事实任务中，表现出了显著的潜力。但是，由于高级大型语言模型（LLM）的不可预测性以及特定任务的监督信号缺乏检索导向，使得在黑箱LLM环境下训练检索模型遭遇了不小的挑战。为了提升新闻声明的事实核查能力，我们提出了一种新颖的方法——细粒度反馈与强化检索（FFRR），它利用黑箱LLM来优化事实核查过程。FFRR通过两级策略，从LLM获取细粒度的反馈信息，这些信息随后作为优化检索策略的奖励信号，通过评估检索文档与任务非检索基准真相的一致性来进行。我们在两个公共数据集上对模型进行了评估，这些数据集专门用于验证现实世界中的新闻声明，评估结果显示FFRR在与强大的LLM支持的基准模型以及非LLM的基准模型相比，实现了显著的性能提升。",
    "title_cn": "本文介绍了一种强化检索方法，该方法通过细粒度反馈来优化黑盒大型语言模型在事实核查新闻声明方面的性能。",
    "tags": [
      "LLM应用",
      "",
      ""
    ]
  },
  {
    "title": "MovieChat+: Question-aware Sparse Memory for Long Video Question Answering",
    "submit_datetime": "2024年04月26日",
    "abstract": "Recently, integrating video foundation models and large language models to build a video understanding system can overcome the limitations of specific pre-defined vision tasks. Yet, existing methods either employ complex spatial-temporal modules or rely heavily on additional perception models to extract temporal features for video understanding, and they only perform well on short videos. For long videos, the computational complexity and memory costs associated with long-term temporal connections are significantly increased, posing additional challenges.Taking advantage of the Atkinson-Shiffrin memory model, with tokens in Transformers being employed as the carriers of memory in combination with our specially designed memory mechanism, we propose MovieChat to overcome these challenges. We lift pre-trained multi-modal large language models for understanding long videos without incorporating additional trainable temporal modules, employing a zero-shot approach. MovieChat achieves state-of-the-art performance in long video understanding, along with the released MovieChat-1K benchmark with 1K long video, 2K temporal grounding labels, and 14K manual annotations for validation of the effectiveness of our method. The code along with the dataset can be accessed via the following https://github.com/rese1f/MovieChat.",
    "pdf_link": "https://arxiv.org/abs/2404.17176",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.17176v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17176/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17176v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17176/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17176v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17176/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17176v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17176/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17176v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17176/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17176v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17176/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17176v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17176/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17176v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17176/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17176v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17176/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17176v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17176/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17176v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17176/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17176v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17176/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17176v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17176/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17176v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17176/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17176v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17176/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17176v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17176/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17176v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17176/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17176v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17176/x18.png"
      }
    ],
    "abstract_cn": "近期，通过融合视频基础模型与大型语言模型，构建视频理解系统，有效突破了特定预设视觉任务的局限。不过，现有技术要么依赖复杂的时空处理模块，要么需要额外的感知模型来抽取时间特征，且主要适用于短视频。长视频的处理则面临计算复杂度和内存消耗随时间连接增长而显著上升的挑战。我们利用阿特金森-谢夫林记忆模型，并在变换器中使用令牌作为记忆载体，结合特别设计的记忆机制，提出了MovieChat解决方案。该模型通过零样本学习方式，提升了对长视频理解的预训练多模态大型语言模型性能，无需额外添加可训练的时间模块。MovieChat在长视频理解任务上达到了业界领先水平，并发布了包含1000段长视频、2000个时间定位标签和14000个手动注释的MovieChat-1K基准，用以验证方法的有效性。相关代码和数据集可在以下网址获取：https://github.com/rese1f/MovieChat。",
    "title_cn": "MovieChat+：为长篇视频问答量身定制的智能问答系统，具备问题感知的稀疏记忆功能。",
    "tags": [
      "LLM应用",
      "视频理解",
      "人工智能"
    ]
  },
  {
    "title": "A Unified Debugging Approach via LLM-Based Multi-Agent Synergy",
    "submit_datetime": "2024年04月26日",
    "abstract": "Tremendous efforts have been devoted to automating software debugging, a time-consuming process involving fault localization and repair generation. Recently, Large Language Models (LLMs) have shown great potential in automated debugging. However, we identified three challenges posed to traditional and LLM-based debugging tools: 1) the upstream imperfection of fault localization affects the downstream repair, 2) the deficiency in handling complex logic errors, and 3) the ignorance of program contexts. In this context, we propose the first automated, unified debugging framework, FixAgent, via LLM agent synergy. FixAgent can perform end-to-end localization, repair, and analysis of bugs. Our insight is that LLMs can benefit from general software engineering principles recognized by human developers in debugging, such as rubber duck debugging, enabling a better understanding of program functionality and logic bugs. Hence, we create three designs inspired by rubber ducking to address these challenges. They are agent specialization and synergy, key variable tracking, and program context comprehension, which request LLMs to provide explicit explanations and force them to focus on crucial program logic information. Experiments on the widely used dataset QuixBugs show that FixAgent correctly fixes 79 out of 80 bugs, 9 of which have never been fixed. It also plausibly patches 1.9X more defects than the best-performing repair tool on CodeFlaws, even with no bug location information and fewer than 0.6% sampling times. On average, FixAgent increases about 20% plausible and correct fixes compared to its base model using different LLMs, showing the effectiveness of our designs. Moreover, the correctness rate of FixAgent reaches remarkably 97.26%, indicating that FixAgent can potentially overcome the overfitting issue of the existing approaches.",
    "pdf_link": "https://arxiv.org/abs/2404.17153",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.17153v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17153/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17153v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17153/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17153v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17153/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17153v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17153/x4.png"
      }
    ],
    "abstract_cn": "为了简化软件调试这一繁琐过程，包括故障定位和修复生成，人们投入了巨大的努力。近期，大型语言模型（LLMs）在自动化调试领域展现出巨大潜力。尽管如此，我们发现传统及基于LLM的调试工具面临三大挑战：故障定位的不精确性会波及后续的修复工作；在处理复杂逻辑错误方面的不足；以及对程序上下文的忽略。针对这些问题，我们首次提出了一个自动化、集成的调试框架——FixAgent，它通过LLM代理的协同作用实现。FixAgent能够一站式完成漏洞的定位、修复和分析。我们洞察到，LLMs可以借鉴人类开发者在调试过程中采用的通用软件工程原则，例如橡皮鸭调试法，以促进对程序功能和逻辑错误的深入理解。因此，我们设计了三种受橡皮鸭调试法启发的机制来应对这些挑战：代理的专业化与协同、关键变量追踪以及程序上下文理解，这些机制要求LLMs提供清晰的解释，并引导它们关注程序逻辑的关键信息。在广泛使用的QuixBugs数据集上的测试显示，FixAgent成功修复了80个漏洞中的79个，其中9个是之前未被修复的。即便在没有漏洞位置信息和低于0.6%的采样次数的条件下，它在CodeFlaws上修复的缺陷数量也比最佳修复工具多1.9倍。平均来说，与使用不同LLMs的基础模型相比，FixAgent在合理和正确修复方面提升了大约20%，证明了我们设计的成效。此外，FixAgent的正确率高达97.26%，这表明它可能有能力解决现有方法中存在的过拟合问题。",
    "title_cn": "本文提出了一种基于大型语言模型（LLM）的多代理协同统一调试方法，旨在优化调试流程，提高问题解决效率。",
    "tags": [
      "Agent",
      "软件工程",
      "自动化调试"
    ]
  },
  {
    "title": "Quantifying Memorization of Domain-Specific Pre-trained Language Models using Japanese Newspaper and Paywalls",
    "submit_datetime": "2024年04月26日",
    "abstract": "Dominant pre-trained language models (PLMs) have been successful in high-quality natural language generation. However, the analysis of their generation is not mature: do they acquire generalizable linguistic abstractions, or do they simply memorize and recover substrings of the training data? Especially, few studies focus on domain-specific PLM. In this study, we pre-trained domain-specific GPT-2 models using a limited corpus of Japanese newspaper articles and quantified memorization of training data by comparing them with general Japanese GPT-2 models. Our experiments revealed that domain-specific PLMs sometimes \"copy and paste\" on a large scale. Furthermore, we replicated the empirical finding that memorization is related to duplication, model size, and prompt length, in Japanese the same as in previous English studies. Our evaluations are relieved from data contamination concerns by focusing on newspaper paywalls, which prevent their use as training data. We hope that our paper encourages a sound discussion such as the security and copyright of PLMs.",
    "pdf_link": "https://arxiv.org/abs/2404.17143",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.17143v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17143/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17143v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17143/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17143v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17143/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17143v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17143/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17143v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17143/experimental_result.png"
      }
    ],
    "abstract_cn": "主流的预训练语言模型（PLMs）在自然语言生成的高品质输出上取得了显著成就。但对于它们的生成机制，我们的理解尚不成熟：这些模型究竟是掌握了通用的语言抽象能力，还是仅仅记住并复现了训练数据中的片段？特别是，针对特定领域的PLMs的研究更是寥寥无几。本研究中，我们利用有限的日本报纸文章集合，预训练了特定领域的GPT-2模型，并通过与通用的日本GPT-2模型的比较，量化了对训练数据的记忆力。实验结果显示，特定领域的PLMs有时会大规模地进行“复制粘贴”操作。此外，我们还复现了之前在英语研究中发现的现象：记忆力与复制行为、模型大小和提示长度有关，这一现象在日本语中同样存在。我们的评估通过专注于报纸的付费内容，避免了数据污染的问题，因为这些内容不会被用作训练材料。我们期望本文能够促进关于PLMs安全性和版权等问题的深入讨论。",
    "title_cn": "本文旨在通过日本报纸和付费墙的方式，探究特定领域预训练语言模型的记忆量化问题。",
    "tags": [
      "LLM理论",
      "",
      ""
    ]
  },
  {
    "title": "Human-Imperceptible Retrieval Poisoning Attacks in LLM-Powered Applications",
    "submit_datetime": "2024年04月26日",
    "abstract": "Presently, with the assistance of advanced LLM application development frameworks, more and more LLM-powered applications can effortlessly augment the LLMs' knowledge with external content using the retrieval augmented generation (RAG) technique. However, these frameworks' designs do not have sufficient consideration of the risk of external content, thereby allowing attackers to undermine the applications developed with these frameworks. In this paper, we reveal a new threat to LLM-powered applications, termed retrieval poisoning, where attackers can guide the application to yield malicious responses during the RAG process. Specifically, through the analysis of LLM application frameworks, attackers can craft documents visually indistinguishable from benign ones. Despite the documents providing correct information, once they are used as reference sources for RAG, the application is misled into generating incorrect responses. Our preliminary experiments indicate that attackers can mislead LLMs with an 88.33\\% success rate, and achieve a 66.67\\% success rate in the real-world application, demonstrating the potential impact of retrieval poisoning.",
    "pdf_link": "https://arxiv.org/abs/2404.17196",
    "graphs": [],
    "abstract_cn": "当前，借助尖端的大型语言模型（LLM）应用开发框架，越来越多的LLM应用能够通过检索增强生成（RAG）技术轻松扩充其知识库。但这些框架在设计上对外部内容风险的考虑不足，容易让攻击者有机可乘。本文揭露了LLM应用面临的一个新风险——检索投毒，攻击者借此可以操纵应用在RAG过程中生成恶意回应。攻击者通过分析LLM应用框架，精心制作出外观上与正常文档无异的文档，这些文档虽提供正确信息，但一旦作为RAG的参考，却能误导应用产生错误结果。我们的初步实验显示，攻击者能够以88.33%的高成功率误导LLM，且在现实世界应用中的成功率也高达66.67%，这充分说明了检索投毒的严重性及其潜在的广泛影响。",
    "title_cn": "在大型语言模型（LLM）支持的应用程序中，悄然兴起了一种难以为人所察觉的检索投毒攻击。",
    "tags": [
      "分类：LLM应用",
      "网络安全",
      "人工智能"
    ]
  },
  {
    "title": "Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering",
    "submit_datetime": "2024年04月26日",
    "abstract": "In customer service technical support, swiftly and accurately retrieving relevant past issues is critical for efficiently resolving customer inquiries. The conventional retrieval methods in retrieval-augmented generation (RAG) for large language models (LLMs) treat a large corpus of past issue tracking tickets as plain text, ignoring the crucial intra-issue structure and inter-issue relations, which limits performance. We introduce a novel customer service question-answering method that amalgamates RAG with a knowledge graph (KG). Our method constructs a KG from historical issues for use in retrieval, retaining the intra-issue structure and inter-issue relations. During the question-answering phase, our method parses consumer queries and retrieves related sub-graphs from the KG to generate answers. This integration of a KG not only improves retrieval accuracy by preserving customer service structure information but also enhances answering quality by mitigating the effects of text segmentation. Empirical assessments on our benchmark datasets, utilizing key retrieval (MRR, Recall@K, NDCG@K) and text generation (BLEU, ROUGE, METEOR) metrics, reveal that our method outperforms the baseline by 77.6% in MRR and by 0.32 in BLEU. Our method has been deployed within LinkedIn's customer service team for approximately six months and has reduced the median per-issue resolution time by 28.6%.",
    "pdf_link": "https://arxiv.org/abs/2404.17723",
    "graphs": [],
    "abstract_cn": "在客户服务的技术支持环节，迅速准确地调取与过往问题相关的信息对于迅速解决客户咨询极为关键。传统上，大型语言模型（LLMs）中用于增强检索生成（RAG）的方法将历史问题跟踪票据视为普通文本，忽略了问题内部结构和问题间的联系，这大大限制了其效能。我们提出了一种创新的客户服务问答方法，该方法将RAG与知识图谱（KG）相结合。此方法利用历史数据构建KG，以保留问题内部结构和问题间的联系，用于信息检索。在问答环节，通过解析用户查询并从KG中调取相关子图来生成答案。这种KG的融合不仅通过保持客户服务的结构信息提升了检索的精确度，同时也通过减少文本分割的影响提升了回答的质量。基于我们的关键检索（MRR，Recall@K，NDCG@K）和文本生成（BLEU，ROUGE，METEOR）指标的基准数据集的实证评估显示，我们的方法在MRR上比基线提升了77.6%，在BLEU上提升了0.32。该方法已在LinkedIn客户服务团队中应用了大约六个月，成功将每个问题的平均解决时间缩短了28.6%。",
    "title_cn": "利用知识图谱提升检索生成技术，优化客户服务中的问答环节。",
    "tags": [
      "分类：RAG",
      "客户服务",
      "知识图谱"
    ]
  },
  {
    "title": "CoMM: Collaborative Multi-Agent, Multi-Reasoning-Path Prompting for Complex Problem Solving",
    "submit_datetime": "2024年04月26日",
    "abstract": "Large Language Models (LLMs) have shown great ability in solving traditional natural language tasks and elementary reasoning tasks with appropriate prompting techniques. However, their ability is still limited in solving complicated science problems. In this work, we aim to push the upper bound of the reasoning capability of LLMs by proposing a collaborative multi-agent, multi-reasoning-path (CoMM) prompting framework. Specifically, we prompt LLMs to play different roles in a problem-solving team, and encourage different role-play agents to collaboratively solve the target task. In particular, we discover that applying different reasoning paths for different roles is an effective strategy to implement few-shot prompting approaches in the multi-agent scenarios. Empirical results demonstrate the effectiveness of the proposed methods on two college-level science problems over competitive baselines. Our further analysis shows the necessity of prompting LLMs to play different roles or experts independently. We release the code at: https://github.com/amazon-science/comm-prompt",
    "pdf_link": "https://arxiv.org/abs/2404.17729",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.17729v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17729/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17729v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17729/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17729v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17729/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17729v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17729/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17729v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17729/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17729v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17729/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17729v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17729/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17729v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17729/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17729v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17729/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17729v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17729/x10.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）在解决传统自然语言处理任务和基础推理任务方面展现出卓越能力，但面对复杂科学问题时，它们的解决能力仍有局限。本研究致力于通过引入协作多代理、多推理路径（CoMM）的提示框架，提升LLMs的推理能力。我们引导LLMs在解决问题的团队中各司其职，并促进角色扮演的代理协同攻关。特别是，我们发现为不同角色设计不同的推理路径，是实现多代理场景下少次提示的有效策略。实验结果显示，该方法在两个大学级别的科学问题上优于现有基准。深入分析进一步证实了让LLMs独立扮演多样角色或专家的必要性。相关代码已在以下链接发布：https://github.com/amazon-science/comm-prompt",
    "title_cn": "CoMM：协同多智能体，多路径推理提示，助力解决复杂问题。",
    "tags": [
      "分类：Agent",
      "",
      ""
    ]
  },
  {
    "title": "PLAYER*: Enhancing LLM-based Multi-Agent Communication and Interaction in Murder Mystery Games",
    "submit_datetime": "2024年04月26日",
    "abstract": "Recent advancements in Large Language Models (LLMs) have enhanced the efficacy of agent communication and social interactions. Despite these advancements, building LLM-based agents for reasoning in dynamic environments involving competition and collaboration remains challenging due to the limitations of informed graph-based search methods. We propose PLAYER*, a novel framework based on an anytime sampling-based planner, which utilises sensors and pruners to enable a purely question-driven searching framework for complex reasoning tasks. We also introduce a quantifiable evaluation method using multiple-choice questions and construct the WellPlay dataset with 1,482 QA pairs. Experiments demonstrate PLAYER*'s efficiency and performance enhancements compared to existing methods in complex, dynamic environments with quantifiable results.",
    "pdf_link": "https://arxiv.org/abs/2404.17662",
    "graphs": [],
    "abstract_cn": "最新进展让大型语言模型（LLMs）在提升代理间的交流和社交互动方面取得了显著成效。尽管如此，由于现有信息图搜索方法的局限，开发能在竞争与合作并存的动态环境中进行推理的LLM代理仍然充满挑战。为此，我们提出了PLAYER*，这是一个创新的框架，它基于即时采样规划器，通过传感器和修剪器来构建一个完全由问题驱动的搜索框架，专门用于处理复杂的推理任务。此外，我们还开发了一种使用多项选择题进行量化评估的方法，并创建了包含1,482对问答的WellPlay数据集。实验结果证明，PLAYER*在处理复杂动态环境的任务时，其效率和性能均超越了现有方法，且提升效果是可以量化的。",
    "title_cn": "PLAYER*：提升基于大型语言模型的多智能体在谋杀谜题游戏中的沟通与互动",
    "tags": [
      "Agent",
      "社交互动",
      "代理推理"
    ]
  },
  {
    "title": "UMass-BioNLP at MEDIQA-M3G 2024: DermPrompt -- A Systematic Exploration of Prompt Engineering with GPT-4V for Dermatological Diagnosis",
    "submit_datetime": "2024年04月26日",
    "abstract": "This paper presents our team's participation in the MEDIQA-ClinicalNLP2024 shared task B. We present a novel approach to diagnosing clinical dermatology cases by integrating large multimodal models, specifically leveraging the capabilities of GPT-4V under a retriever and a re-ranker framework. Our investigation reveals that GPT-4V, when used as a retrieval agent, can accurately retrieve the correct skin condition 85% of the time using dermatological images and brief patient histories. Additionally, we empirically show that Naive Chain-of-Thought (CoT) works well for retrieval while Medical Guidelines Grounded CoT is required for accurate dermatological diagnosis. Further, we introduce a Multi-Agent Conversation (MAC) framework and show its superior performance and potential over the best CoT strategy. The experiments suggest that using naive CoT for retrieval and multi-agent conversation for critique-based diagnosis, GPT-4V can lead to an early and accurate diagnosis of dermatological conditions. The implications of this work extend to improving diagnostic workflows, supporting dermatological education, and enhancing patient care by providing a scalable, accessible, and accurate diagnostic tool.",
    "pdf_link": "https://arxiv.org/abs/2404.17749",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.17749v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17749/method.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17749v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17749/MAC_final.png"
      }
    ],
    "abstract_cn": "本论文展示了我们团队参与 MEDIQA-ClinicalNLP2024 共享任务 B 的成果。我们采用了一种创新的方法，通过融合大型多模态模型来诊断临床皮肤科病例，尤其是利用 GPT-4V 在检索和重排系统中的应用。研究发现，GPT-4V 作为检索工具时，能够凭借皮肤图像和患者简史，85% 的时间准确识别出正确的皮肤状况。我们还证实了，朴素链式思维（CoT）在检索中效果显著，而基于医学指南的 CoT 对于精确的皮肤科诊断至关重要。此外，我们引入了多代理对话（MAC）框架，并通过实验验证了其相较于最佳 CoT 策略的卓越性能和潜力。研究指出，结合朴素 CoT 检索和基于批评的多代理对话诊断，GPT-4V 有助于实现皮肤科疾病的早期和精确诊断。这项研究不仅推动了诊断流程的优化，还有助于皮肤科教育的发展，并为患者护理提供了一种高效、便捷、准确的诊断工具。",
    "title_cn": "UMass-BioNLP 团队在 2024 年 MEDIQA-M3G 竞赛中推出了 DermPrompt，这是一个针对皮肤科诊断的系统化提示工程探索项目，利用 GPT-4V 技术深入挖掘和优化诊断流程。",
    "tags": [
      "分类：LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Learning Manipulation Tasks in Dynamic and Shared 3D Spaces",
    "submit_datetime": "2024年04月26日",
    "abstract": "Automating the segregation process is a need for every sector experiencing a high volume of materials handling, repetitive and exhaustive operations, in addition to risky exposures. Learning automated pick-and-place operations can be efficiently done by introducing collaborative autonomous systems (e.g. manipulators) in the workplace and among human operators. In this paper, we propose a deep reinforcement learning strategy to learn the place task of multi-categorical items from a shared workspace between dual-manipulators and to multi-goal destinations, assuming the pick has been already completed. The learning strategy leverages first a stochastic actor-critic framework to train an agent's policy network, and second, a dynamic 3D Gym environment where both static and dynamic obstacles (e.g. human factors and robot mate) constitute the state space of a Markov decision process. Learning is conducted in a Gazebo simulator and experiments show an increase in cumulative reward function for the agent further away from human factors. Future investigations will be conducted to enhance the task performance for both agents simultaneously.",
    "pdf_link": "https://arxiv.org/abs/2404.17673",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.17673v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17673/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17673v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17673/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17673v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17673/sampled_pointcloud.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17673v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17673/predicted_pointcloud.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17673v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17673/pipeline_with_links.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17673v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17673/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17673v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17673/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17673v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17673/robot1_training.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17673v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17673/robot2_training.png"
      }
    ],
    "abstract_cn": "对于任何面临大量物料处理、重复性操作和潜在风险的行业而言，实现分离流程的自动化是迫切需求。通过引入协作式自主系统，如机械臂，可以高效地掌握自动化的拣选与放置操作。本文提出了一种深度强化学习策略，旨在教导代理如何在双机械手共享的工作空间中识别多类物品，并将它们放置到多个预定目标地点，前提是拣选动作已经完成。该策略首先采用随机演员-评论家框架来训练代理的策略网络，然后利用一个包含静态和动态障碍物（如人为因素和机器人伙伴）的动态3D Gym环境，构建马尔可夫决策过程的状态空间。在Gazebo模拟器中进行的学习实验显示，远离人为因素的代理累积奖励函数有所提升。未来的研究将进一步探索，以同步提升两个代理的任务执行效率。",
    "title_cn": "探索在动态且共享的三维空间里执行操控任务的学习过程。",
    "tags": [
      "Agent",
      "工业自动化",
      "机器人技术"
    ]
  },
  {
    "title": "Impact of Traffic-Following on Order of Autonomous Airspace Operations",
    "submit_datetime": "2024年04月26日",
    "abstract": "In this paper, we investigate the dynamic emergence of traffic order in a distributed multi-agent system, aiming to minimize inefficiencies that stem from unnecessary structural impositions. We introduce a methodology for developing a dynamically-updating traffic pattern map of the airspace by leveraging information about the consistency and frequency of flow directions used by current as well as preceding traffic. Informed by this map, an agent can discern the degree to which it is advantageous to follow traffic by trading off utilities such as time and order. We show that for the traffic levels studied, for low degrees of traffic-following behavior, there is minimal penalty in terms of aircraft travel times while improving the overall orderliness of the airspace. On the other hand, heightened traffic-following behavior may result in increased aircraft travel times, while marginally reducing the overall entropy of the airspace. Ultimately, the methods and metrics presented in this paper can be used to optimally and dynamically adjust an agent's traffic-following behavior based on these trade-offs.",
    "pdf_link": "https://arxiv.org/abs/2404.17627",
    "graphs": [],
    "abstract_cn": "本文深入探讨了在分布式多智能体系统中，如何通过最小化不必要的结构性限制来动态形成交通秩序。我们提出了一种创新的方法，通过分析当前和历史交通流向的一致性与频率，构建并实时更新空域的交通模式图。借助这一地图，智能体能够评估遵循交通流的效益，从而在时间和秩序之间做出权衡。研究表明，在低度遵循交通行为的情况下，飞机的旅行时间几乎不受影响，却能显著提升空域的有序性。然而，过度的交通跟随可能会增加飞行时间，尽管如此，它也能在一定程度上降低空域的总体混乱度。本研究提出的方法和评价指标，将有助于智能体基于这些权衡，进行最优和动态的交通行为调整。",
    "title_cn": "交通跟随行为对自动空中管制序列的影响",
    "tags": [
      "Agent",
      "交通管理",
      "智能体系统"
    ]
  },
  {
    "title": "Quantum Multi-Agent Reinforcement Learning for Aerial Ad-hoc Networks",
    "submit_datetime": "2024年04月26日",
    "abstract": "Quantum machine learning (QML) as combination of quantum computing with machine learning (ML) is a promising direction to explore, in particular due to the advances in realizing quantum computers and the hoped-for quantum advantage. A field within QML that is only little approached is quantum multi-agent reinforcement learning (QMARL), despite having shown to be potentially attractive for addressing industrial applications such as factory management, cellular access and mobility cooperation. This paper presents an aerial communication use case and introduces a hybrid quantum-classical (HQC) ML algorithm to solve it. This use case intends to increase the connectivity of flying ad-hoc networks and is solved by an HQC multi-agent proximal policy optimization algorithm in which the core of the centralized critic is replaced with a data reuploading variational quantum circuit. Results show a slight increase in performance for the quantum-enhanced solution with respect to a comparable classical algorithm, earlier reaching convergence, as well as the scalability of such a solution: an increase in the size of the ansatz, and thus also in the number of trainable parameters, leading to better outcomes. These promising results show the potential of QMARL to industrially-relevant complex use cases.",
    "pdf_link": "https://arxiv.org/abs/2404.17499",
    "graphs": [],
    "abstract_cn": "量子机器学习（QML），作为量子计算与机器学习（ML）结合的前沿领域，因其在量子计算机实现和量子优势预期方面的进展而备受瞩目。然而，QML中的一个较少被触及的子领域——量子多智能体强化学习（QMARL），尽管其在处理如工厂管理、蜂窝接入和移动性合作等工业应用方面显示出巨大潜力。本文通过一个空中通信的实例，引入了一种混合量子-经典（HQC）机器学习算法来应对挑战。该实例的目标是提升飞行自组织网络的连接性，通过HQC多智能体近端策略优化算法实现，该算法将集中式批评器核心替换为数据重新上传的变分量子电路。研究结果显示，量子增强解决方案在性能上略有提升，更快达到收敛，并且展现出良好的可扩展性：随着ansatz大小的增加，即训练参数数量的增加，可以获得更优的结果。这些充满希望的成果揭示了QMARL在解决工业界复杂应用场景中的潜力。",
    "title_cn": "本文探讨了量子多智能体强化学习在构建空中临时网络中的应用。",
    "tags": [
      "Agent",
      "量子计算",
      "工业自动化"
    ]
  },
  {
    "title": "A multi-agent model of hierarchical decision dynamics",
    "submit_datetime": "2024年04月26日",
    "abstract": "Decision making can be difficult when there are many actors (or agents) who may be coordinating or competing to achieve their various ideas of the optimum outcome. Here I present a simple decision making model with an explicitly hierarchical binary-tree structure, and evaluate how this might cooperate to take actions that match its various evaluations of the uncertain state of the world. Key features of agent behaviour are (a) the separation of its decision making process into three distinct steps: observation, judgement, and action; and (b) the evolution of coordination by the sharing of judgements.",
    "pdf_link": "https://arxiv.org/abs/2404.17477",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.17477v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17477/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17477v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17477/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17477v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17477/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17477v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17477/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17477v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17477/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17477v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17477/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17477v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17477/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17477v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17477/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17477v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17477/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17477v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17477/x10.png"
      }
    ],
    "abstract_cn": "在众多参与者可能追求各自最优结果而需协调或竞争的情境下，做出决策可能颇具挑战。本文介绍了一种结构清晰的分层二叉树决策模型，并探讨了该模型如何通过合作来采取与其对世界不确定性状态的不同评估相匹配的行动。该代理行为的显著特点包括：（a）决策过程被划分为观察、判断和行动三个独立阶段；（b）通过共享判断来促进协调机制的发展。",
    "title_cn": "一个分层决策过程的多智能体模型",
    "tags": [
      "Agent",
      "决策模型",
      "协调机制"
    ]
  },
  {
    "title": "Make-it-Real: Unleashing Large Multimodal Model's Ability for Painting 3D Objects with Realistic Materials",
    "submit_datetime": "2024年04月25日",
    "abstract": "Physically realistic materials are pivotal in augmenting the realism of 3D assets across various applications and lighting conditions. However, existing 3D assets and generative models often lack authentic material properties. Manual assignment of materials using graphic software is a tedious and time-consuming task. In this paper, we exploit advancements in Multimodal Large Language Models (MLLMs), particularly GPT-4V, to present a novel approach, Make-it-Real: 1) We demonstrate that GPT-4V can effectively recognize and describe materials, allowing the construction of a detailed material library. 2) Utilizing a combination of visual cues and hierarchical text prompts, GPT-4V precisely identifies and aligns materials with the corresponding components of 3D objects. 3) The correctly matched materials are then meticulously applied as reference for the new SVBRDF material generation according to the original diffuse map, significantly enhancing their visual authenticity. Make-it-Real offers a streamlined integration into the 3D content creation workflow, showcasing its utility as an essential tool for developers of 3D assets.",
    "pdf_link": "https://arxiv.org/abs/2404.16829",
    "graphs": [],
    "abstract_cn": "物理真实感材料对于提升3D资产在不同应用和光照条件下的真实度起着关键作用。但目前3D资产和生成模型往往缺少真实的材质属性。手动通过图形软件分配材质既繁琐又耗时。本文中，我们借助多模态大型语言模型（MLLMs），尤其是GPT-4V，提出了一种创新方法“Make-it-Real”：首先，我们展示了GPT-4V在识别和描述材质方面的高效能力，这有助于构建一个详尽的材质库；其次，通过结合视觉线索和层级化文本提示，GPT-4V能够精确地识别并匹配3D对象的相应部件的材质；最后，正确匹配的材质被精心应用于新的SVBRDF材质生成过程，以原始漫反射图为参考，显著提升了视觉真实感。“Make-it-Real”作为一个高效的工具，为3D内容创作流程提供了简化的集成方案，对3D资产开发者来说极具价值。",
    "title_cn": "实现真实：释放大型多模态模型的潜力，以绘制采用逼真材质的三维物体。",
    "tags": [
      "LLM应用",
      "3D建模",
      "人工智能"
    ]
  },
  {
    "title": "How Far Are We to GPT-4V? Closing the Gap to Commercial Multimodal Models with Open-Source Suites",
    "submit_datetime": "2024年04月25日",
    "abstract": "In this report, we introduce InternVL 1.5, an open-source multimodal large language model (MLLM) to bridge the capability gap between open-source and proprietary commercial models in multimodal understanding. We introduce three simple improvements: (1) Strong Vision Encoder: we explored a continuous learning strategy for the large-scale vision foundation model -- InternViT-6B, boosting its visual understanding capabilities, and making it can be transferred and reused in different LLMs. (2) Dynamic High-Resolution: we divide images into tiles ranging from 1 to 40 of 448$\\times$448 pixels according to the aspect ratio and resolution of the input images, which supports up to 4K resolution input. (3) High-Quality Bilingual Dataset: we carefully collected a high-quality bilingual dataset that covers common scenes, document images, and annotated them with English and Chinese question-answer pairs, significantly enhancing performance in OCR- and Chinese-related tasks. We evaluate InternVL 1.5 through a series of benchmarks and comparative studies. Compared to both open-source and proprietary models, InternVL 1.5 shows competitive performance, achieving state-of-the-art results in 8 of 18 benchmarks. Code has been released at https://github.com/OpenGVLab/InternVL.",
    "pdf_link": "https://arxiv.org/abs/2404.16821",
    "graphs": [],
    "abstract_cn": "本报告向您展示了InternVL 1.5，这是一款开源的多模态大型语言模型（MLLM），致力于缩小开源与商业专有模型在多模态理解领域的能力差距。我们带来了三项创新：（1）强化视觉编码器，通过持续学习策略优化了大规模视觉基础模型InternViT-6B，提升了视觉理解力，并便于在各类大型语言模型中迁移与复用。（2）动态高分辨率处理，根据输入图像的比例和分辨率，将图像分割成448×448像素的1至40块，支持最高4K分辨率的输入。（3）精心构建的高质量双语数据集，覆盖了日常生活场景和文档图像，并配有中英文问答对，显著提升了OCR及中文任务的处理能力。在一系列基准测试和对比研究中，InternVL 1.5与开源及商业模型相比，展现出了竞争力，在18个基准测试中的8个上达到了领先水平。相关代码已在GitHub上发布。",
    "title_cn": "我们距离 GPT-4V 还有多远？通过开源工具集，我们正逐步缩小与商业多模态模型之间的差距。",
    "tags": [
      "分类：LLM应用",
      "人工智能",
      "多模态理解"
    ]
  },
  {
    "title": "IndicGenBench: A Multilingual Benchmark to Evaluate Generation Capabilities of LLMs on Indic Languages",
    "submit_datetime": "2024年04月25日",
    "abstract": "As large language models (LLMs) see increasing adoption across the globe, it is imperative for LLMs to be representative of the linguistic diversity of the world. India is a linguistically diverse country of 1.4 Billion people. To facilitate research on multilingual LLM evaluation, we release IndicGenBench - the largest benchmark for evaluating LLMs on user-facing generation tasks across a diverse set 29 of Indic languages covering 13 scripts and 4 language families. IndicGenBench is composed of diverse generation tasks like cross-lingual summarization, machine translation, and cross-lingual question answering. IndicGenBench extends existing benchmarks to many Indic languages through human curation providing multi-way parallel evaluation data for many under-represented Indic languages for the first time. We evaluate a wide range of proprietary and open-source LLMs including GPT-3.5, GPT-4, PaLM-2, mT5, Gemma, BLOOM and LLaMA on IndicGenBench in a variety of settings. The largest PaLM-2 models performs the best on most tasks, however, there is a significant performance gap in all languages compared to English showing that further research is needed for the development of more inclusive multilingual language models. IndicGenBench is released at www.github.com/google-research-datasets/indic-gen-bench",
    "pdf_link": "https://arxiv.org/abs/2404.16816",
    "graphs": [],
    "abstract_cn": "随着大型语言模型（LLMs）在全球的广泛应用，确保它们能够体现全球语言多样性变得至关重要。印度，一个拥有14亿人口的多语言国家，为我们提供了丰富的研究素材。为了推动多语言LLM评估研究，我们推出了IndicGenBench——这是目前规模最大的基准测试平台，旨在评估LLM在29种印度语言上的用户生成任务表现，这些语言涵盖了13种不同的文字系统和4个语言系。IndicGenBench包含多种生成任务，包括跨语言摘要、机器翻译和跨语言问答等。该平台通过人工精选，首次为多种印度语言提供了多维度的并行评估数据，极大地扩展了现有基准测试的覆盖范围。我们在多种场景下对一系列商业和开源的LLMs进行了评估，包括GPT-3.5、GPT-4、PaLM-2、mT5、Gemma、BLOOM和LLaMA。其中，PaLM-2的最大模型在大多数任务上表现最为出色。然而，所有印度语言与英语相比仍有较大的性能差距，这表明我们仍需深化研究，以发展出更加全面和包容的多语言语言模型。IndicGenBench目前已在www.github.com/google-research-datasets/indic-gen-bench上线。",
    "title_cn": "IndicGenBench：一项多语言评估基准，旨在衡量大型语言模型在印度诸语言上的表现力。",
    "tags": [
      "LLM应用",
      "",
      "机器翻译"
    ]
  },
  {
    "title": "Make Your LLM Fully Utilize the Context",
    "submit_datetime": "2024年04月25日",
    "abstract": "While many contemporary large language models (LLMs) can process lengthy input, they still struggle to fully utilize information within the long context, known as the lost-in-the-middle challenge. We hypothesize that it stems from insufficient explicit supervision during the long-context training, which fails to emphasize that any position in a long context can hold crucial information. Based on this intuition, our study presents information-intensive (IN2) training, a purely data-driven solution to overcome lost-in-the-middle. Specifically, IN2 training leverages a synthesized long-context question-answer dataset, where the answer requires (1) fine-grained information awareness on a short segment (~128 tokens) within a synthesized long context (4K-32K tokens), and (2) the integration and reasoning of information from two or more short segments. Through applying this information-intensive training on Mistral-7B, we present FILM-7B (FILl-in-the-Middle). To thoroughly assess the ability of FILM-7B for utilizing long contexts, we design three probing tasks that encompass various context styles (document, code, and structured-data context) and information retrieval patterns (forward, backward, and bi-directional retrieval). The probing results demonstrate that FILM-7B can robustly retrieve information from different positions in its 32K context window. Beyond these probing tasks, FILM-7B significantly improves the performance on real-world long-context tasks (e.g., 23.5->26.9 F1 score on NarrativeQA), while maintaining a comparable performance on short-context tasks (e.g., 59.3->59.2 accuracy on MMLU). Github Link: https://github.com/microsoft/FILM.",
    "pdf_link": "https://arxiv.org/abs/2404.16811",
    "graphs": [],
    "abstract_cn": "当前众多先进的大型语言模型虽能处理长篇输入，却常在充分利用长文本信息时力不从心，这一现象被称为“迷失于中间”的难题。我们假设这一问题源于在长文本训练时缺乏充分的显式指导，未能突出长文本中任意位置都可能蕴含重要信息。基于此洞察，本研究引入了信息密集型（IN2）训练方法，这是一种纯粹基于数据驱动的解决方案，用以攻克“迷失于中间”的挑战。IN2训练特别采用了一个合成的长文本问答数据集，该数据集中的问题答案需要对长文本中的一个短小片段（约128个令牌）进行细致的信息感知，并整合推理来自两个或更多短片段的信息。我们将这种信息密集型训练应用于Mistral-7B模型，进而推出了FILM-7B（意为填补中间的空白）。为全面测试FILM-7B处理长文本的能力，我们设计了三种探索性任务，覆盖了多样的文本风格和信息检索方式。测试结果证明，FILM-7B能从其32K的上下文窗口中稳健地提取信息。此外，FILM-7B在现实世界的长文本任务中显著提升了性能，例如在NarrativeQA任务上的F1分数从23.5提升至26.9，同时在短文本任务上也保持了相当的性能，如在MMLU任务上的准确率从59.3微降至59.2。项目代码已在GitHub上公开：https://github.com/microsoft/FILM。",
    "title_cn": "充分发挥您的大型语言模型的上下文理解能力",
    "tags": [
      "LLM理论",
      "",
      "信息检索"
    ]
  },
  {
    "title": "Improving Diversity of Commonsense Generation by Large Language Models via In-Context Learning",
    "submit_datetime": "2024年04月25日",
    "abstract": "Generative Commonsense Reasoning (GCR) requires a model to reason about a situation using commonsense knowledge, while generating coherent sentences. Although the quality of the generated sentences is crucial, the diversity of the generation is equally important because it reflects the model's ability to use a range of commonsense knowledge facts. Large Language Models (LLMs) have shown proficiency in enhancing the generation quality across various tasks through in-context learning (ICL) using given examples without the need for any fine-tuning. However, the diversity aspect in LLM outputs has not been systematically studied before. To address this, we propose a simple method that diversifies the LLM generations, while preserving their quality. Experimental results on three benchmark GCR datasets show that our method achieves an ideal balance between the quality and diversity. Moreover, the sentences generated by our proposed method can be used as training data to improve diversity in existing commonsense generators.",
    "pdf_link": "https://arxiv.org/abs/2404.16807",
    "graphs": [],
    "abstract_cn": "生成常识推理（GCR）任务要求模型不仅要运用常识知识进行推理，还需产出连贯的语句。生成语句的品质固然关键，但多样性亦同样重要，因为它展现了模型调用不同常识知识的能力。大型语言模型（LLMs）通过上下文学习（ICL）在多项任务中提升了生成品质，且无需经过精细调整。尽管如此，对于LLMs输出的多样性，此前尚未有系统性的研究。为此，我们提出了一种新方法，旨在丰富LLMs的生成多样性，同时保持其品质。在三个GCR基准数据集上的实验结果显示，该方法在品质与多样性之间取得了完美的平衡。此外，通过该方法生成的语句，还可以作为训练数据，以增强现有常识生成器的多样性。",
    "title_cn": "通过上下文学习，提升大型语言模型在常识生成任务中的多样性表现。",
    "tags": [
      "LLM应用",
      "人工智能",
      ""
    ]
  },
  {
    "title": "AAPL: Adding Attributes to Prompt Learning for Vision-Language Models",
    "submit_datetime": "2024年04月25日",
    "abstract": "Recent advances in large pre-trained vision-language models have demonstrated remarkable performance on zero-shot downstream tasks. Building upon this, recent studies, such as CoOp and CoCoOp, have proposed the use of prompt learning, where context within a prompt is replaced with learnable vectors, leading to significant improvements over manually crafted prompts. However, the performance improvement for unseen classes is still marginal, and to tackle this problem, data augmentation has been frequently used in traditional zero-shot learning techniques. Through our experiments, we have identified important issues in CoOp and CoCoOp: the context learned through traditional image augmentation is biased toward seen classes, negatively impacting generalization to unseen classes. To address this problem, we propose adversarial token embedding to disentangle low-level visual augmentation features from high-level class information when inducing bias in learnable prompts. Through our novel mechanism called \"Adding Attributes to Prompt Learning\", AAPL, we guide the learnable context to effectively extract text features by focusing on high-level features for unseen classes. We have conducted experiments across 11 datasets, and overall, AAPL shows favorable performances compared to the existing methods in few-shot learning, zero-shot learning, cross-dataset, and domain generalization tasks.",
    "pdf_link": "https://arxiv.org/abs/2404.16804",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.16804v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16804/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16804v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16804/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16804v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16804/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16804v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16804/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16804v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16804/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16804v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16804/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16804v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16804/x7.png"
      }
    ],
    "abstract_cn": "最新进展的大型预训练视觉-语言模型在零样本任务上取得了卓越成效。继此之后，如 CoOp 和 CoCoOp 等最新研究提出了提示学习的概念，即将提示中的上下文替换为可训练的向量，显著提升了性能。尽管如此，对于未见过的类别，性能提升依旧有限。为了克服这一难题，传统零样本学习中常采用数据增强技术。我们的实验揭示了 CoOp 和 CoCoOp 的关键问题：通过传统图像增强获得的上下文偏向于已知类别，这不利于对未知类别的泛化。为此，我们引入了对抗性标记嵌入技术，以在可学习提示中引入偏差时，将低层次的视觉增强特征与高层次的类别信息解耦。我们提出的“为提示学习添加属性”的新机制 AAPL，通过专注于未知类别的高层次特征，引导可学习上下文有效提取文本特征。我们在 11 个数据集上进行了广泛实验，结果显示 AAPL 在少样本学习、零样本学习、跨数据集和领域泛化任务中相比现有方法具有更佳的表现。",
    "title_cn": "AAPL：为视觉-语言模型引入属性，以增强提示学习的效果。",
    "tags": [
      "分类：LLM应用",
      "计算机视觉",
      ""
    ]
  },
  {
    "title": "Weak-to-Strong Extrapolation Expedites Alignment",
    "submit_datetime": "2024年04月25日",
    "abstract": "Although the capabilities of large language models (LLMs) ideally scale up with increasing data and compute, they are inevitably constrained by limited resources in reality. Suppose we have a moderately trained LLM (e.g., trained to align with human preference) in hand, can we further exploit its potential and cheaply acquire a stronger model? In this paper, we propose a simple method called ExPO to boost LLMs' alignment with human preference. ExPO assumes that a medium-aligned model can be interpolated between a less-aligned (weaker) model, e.g., the initial SFT model, and a better-aligned (stronger) one, thereby directly obtaining this stronger model by extrapolating from the weights of the former two relatively weaker models. On the AlpacaEval 2.0 benchmark, we show that ExPO pushes models trained with less preference data (e.g., 10% or 20%) to reach and even surpass the fully-trained one, without any additional training. Furthermore, ExPO also significantly improves off-the-shelf DPO/RLHF models and exhibits decent scalability across model sizes from 7B to 70B. Our work demonstrates the efficacy of model extrapolation in exploiting LLMs' capabilities, suggesting a promising direction that deserves future exploration.",
    "pdf_link": "https://arxiv.org/abs/2404.16792",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLM）的性能本应随着数据量和计算力的提升而增强，但实际上却受限于资源的有限性。如果我们已经拥有一个根据人类偏好适度训练的LLM，是否有可能进一步挖掘其潜力，以较低成本获得更强大的模型呢？本文提出了一种简洁的方法——ExPO，旨在提升LLM与人类偏好的契合度。ExPO基于这样的假设：在对齐程度较低（即较弱）的模型（如初始的SFT模型）和对齐程度较高（即较强）的模型之间，可以构建一个中等对齐度的模型，并通过从这两个较弱模型的权重进行外推，直接获得更强大的模型。在AlpacaEval 2.0基准测试中，我们证明了ExPO能够使使用较少偏好数据（如10%或20%）训练的模型达到甚至超过完全训练模型的性能，且无需额外训练。此外，ExPO还能显著提升现成的DPO/RLHF模型的性能，并且在从7B到70B不同规模的模型上都显示出良好的扩展性。我们的研究展示了通过模型外推来挖掘LLM潜力的有效性，为未来的探索指明了一个充满希望的方向。",
    "title_cn": "从弱到强的外推过程，有效地促进了数据的对齐工作。",
    "tags": [
      "LLM理论",
      "人工智能",
      ""
    ]
  },
  {
    "title": "SEED-Bench-2-Plus: Benchmarking Multimodal Large Language Models with Text-Rich Visual Comprehension",
    "submit_datetime": "2024年04月25日",
    "abstract": "Comprehending text-rich visual content is paramount for the practical application of Multimodal Large Language Models (MLLMs), since text-rich scenarios are ubiquitous in the real world, which are characterized by the presence of extensive texts embedded within images. Recently, the advent of MLLMs with impressive versatility has raised the bar for what we can expect from MLLMs. However, their proficiency in text-rich scenarios has yet to be comprehensively and objectively assessed, since current MLLM benchmarks primarily focus on evaluating general visual comprehension. In this work, we introduce SEED-Bench-2-Plus, a benchmark specifically designed for evaluating \\textbf{text-rich visual comprehension} of MLLMs. Our benchmark comprises 2.3K multiple-choice questions with precise human annotations, spanning three broad categories: Charts, Maps, and Webs, each of which covers a wide spectrum of text-rich scenarios in the real world. These categories, due to their inherent complexity and diversity, effectively simulate real-world text-rich environments. We further conduct a thorough evaluation involving 34 prominent MLLMs (including GPT-4V, Gemini-Pro-Vision and Claude-3-Opus) and emphasize the current limitations of MLLMs in text-rich visual comprehension. We hope that our work can serve as a valuable addition to existing MLLM benchmarks, providing insightful observations and inspiring further research in the area of text-rich visual comprehension with MLLMs. The dataset and evaluation code can be accessed at https://github.com/AILab-CVC/SEED-Bench.",
    "pdf_link": "https://arxiv.org/abs/2404.16790",
    "graphs": [],
    "abstract_cn": "掌握充满文本的视觉内容对于实际部署多模态大型语言模型（MLLMs）至关重要，因为现实世界中充斥着嵌入大量文本的图像场景。最近，功能强大的MLLMs的问世提升了我们对这些模型的期待。但是，MLLMs在处理文本密集场景时的能力尚未得到全面客观的评估，目前的主要基准测试更多地集中在一般视觉理解上。本研究提出了SEED-Bench-2-Plus，这是一个专为评估MLLMs的文本密集视觉理解能力而设计的基准测试。该基准测试包含2300道多项选择题，覆盖图表、地图和网页三大类别，每类均覆盖现实世界中多样化的文本密集场景，并配有精确的人工标注。通过对34个知名MLLMs（包括GPT-4V、Gemini-Pro-Vision和Claude-3-Opus）的深入评估，我们揭示了MLLMs在文本密集视觉理解方面的当前局限。我们期望本研究能为现有的MLLM基准测试增添价值，提供深刻的见解，并激励该领域进一步的研究。相关数据集和评估代码可在 https://github.com/AILab-CVC/SEED-Bench 获取。",
    "title_cn": "SEED-Bench-2-Plus：以文本为中心的视觉理解，为多模态大型语言模型设立新标杆",
    "tags": [
      "分类：LLM应用",
      "视觉理解",
      "多模态学习"
    ]
  },
  {
    "title": "Continual Learning of Large Language Models: A Comprehensive Survey",
    "submit_datetime": "2024年04月25日",
    "abstract": "The recent success of large language models (LLMs) trained on static, pre-collected, general datasets has sparked numerous research directions and applications. One such direction addresses the non-trivial challenge of integrating pre-trained LLMs into dynamic data distributions, task structures, and user preferences. Pre-trained LLMs, when tailored for specific needs, often experience significant performance degradation in previous knowledge domains -- a phenomenon known as \"catastrophic forgetting\". While extensively studied in the continual learning (CL) community, it presents new manifestations in the realm of LLMs. In this survey, we provide a comprehensive overview of the current research progress on LLMs within the context of CL. This survey is structured into four main sections: we first describe an overview of continually learning LLMs, consisting of two directions of continuity: vertical continuity (or vertical continual learning), i.e., continual adaptation from general to specific capabilities, and horizontal continuity (or horizontal continual learning), i.e., continual adaptation across time and domains (Section 3). We then summarize three stages of learning LLMs in the context of modern CL: Continual Pre-Training (CPT), Domain-Adaptive Pre-training (DAP), and Continual Fine-Tuning (CFT) (Section 4). Then we provide an overview of evaluation protocols for continual learning with LLMs, along with the current available data sources (Section 5). Finally, we discuss intriguing questions pertaining to continual learning for LLMs (Section 6). The full list of papers examined in this survey is available at https://github.com/Wang-ML-Lab/llm-continual-learning-survey.",
    "pdf_link": "https://arxiv.org/abs/2404.16789",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）在静态、预先收集的通用数据集上的训练成就，开启了众多研究新方向和应用场景。其中一个关键研究方向是如何将这些预训练的LLMs有效地融入到不断变化的数据分布、任务结构和用户偏好中。当这些模型为特定需求定制时，常常会在原有知识领域出现性能大幅下降，这一现象被称为“灾难性遗忘”。尽管在持续学习（CL）领域已有深入研究，但在LLMs的应用中仍展现出新的挑战。本文综述了LLMs在CL领域的研究进展，分为四个部分：首先介绍持续学习的LLMs概览，涉及垂直连续性和水平连续性两个维度（第3节）；接着总结LLMs在现代CL中的三个学习阶段：持续预训练（CPT）、领域自适应预训练（DAP）和持续微调（CFT）（第4节）；然后概述了LLMs持续学习的评估协议和可用数据资源（第5节）；最后探讨了LLMs持续学习中的一些引人入胜的问题（第6节）。相关论文的完整列表可访问 https://github.com/Wang-ML-Lab/llm-continual-learning-survey。",
    "title_cn": "深入探究大型语言模型的持续学习：全面综述",
    "tags": [
      "分类：LLM应用\n\n这篇论文摘要主要讨论了大型语言模型（LLMs）在持续学习（Continual Learning, CL）领域的应用和挑战。它概述了LLMs在CL中的研究进展，包括持续预训练、领域自适应预训练和持续微调等学习阶段，以及评估协议和数据资源。由于论文聚焦于LLMs在特定应用场景中的性能和挑战，因此将其归类为LLM应用。",
      "机器学习",
      "持续学习"
    ]
  },
  {
    "title": "Prefix Text as a Yarn: Eliciting Non-English Alignment in Foundation Language Model",
    "submit_datetime": "2024年04月25日",
    "abstract": "While supervised fine-tuning (SFT) has been a straightforward approach for tailoring the output of foundation large language model (LLM) to specific preferences, concerns have been raised about the depth of this alignment, with some critiques suggesting it is merely \"superficial\". We critically examine this hypothesis within the scope of cross-lingual generation tasks, proposing that the effectiveness of SFT may be constrained by its reliance on prior tokens to guide cross-lingual generation. Based on this crucial insight, and in response to the challenges posed by the costly and limited availability of non-English data for SFT, we introduce a novel training-free alignment method named PreTTY, which employs minimal task-related prior tokens to bridge the foundation LLM and the SFT LLM, achieving comparable performance without training. Experiments on machine translation and part-of-speech tagging across eight languages demonstrate the efficacy of PreTTY in cross-lingual settings. Remarkably, by initiating the decoding process with only one or two prior tokens, foundation LLMs can achieve performance comparable to their SFT counterparts. This method presents a cost-effective alternative to SFT and advances the democratization of multilingual LLMs.",
    "pdf_link": "https://arxiv.org/abs/2404.16766",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.16766v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16766/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16766v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16766/x2.png"
      }
    ],
    "abstract_cn": "监督式微调（SFT）虽是定制大型语言模型（LLM）输出以适应特定需求的直接手段，但其对齐深度却受到质疑，批评者认为这种对齐仅停留在表面。本文针对跨语言生成任务，对这一假设进行了深入探讨，并指出SFT的效能可能因其依赖于先前标记来指导跨语言生成而受限。为解决SFT所需非英语数据成本高昂且资源有限的问题，我们提出了一种创新的无训练对齐方法——PreTTY。该方法仅利用少量与任务相关的先前标记，便能将基础LLM与SFT LLM相连，达到无需训练即可比拟的性能。在八种语言的机器翻译和词性标注任务上的实验验证了PreTTY在跨语言应用中的高效性。尤为突出的是，基础LLM仅需一两个先前标记启动解码，就能与经过SFT的模型相媲美。这一方法不仅为SFT提供了经济高效的替代方案，也为多语言LLM的普及化进程迈出了重要一步。",
    "title_cn": "将前缀文本视作线索，引导基础语言模型实现非英语语种的对齐。",
    "tags": [
      "LLM应用",
      "机器翻译",
      ""
    ]
  },
  {
    "title": "RadGenome-Chest CT: A Grounded Vision-Language Dataset for Chest CT Analysis",
    "submit_datetime": "2024年04月25日",
    "abstract": "Developing generalist foundation model has recently attracted tremendous attention among researchers in the field of AI for Medicine (AI4Medicine). A pivotal insight in developing these models is their reliance on dataset scaling, which emphasizes the requirements on developing open-source medical image datasets that incorporate diverse supervision signals across various imaging modalities. In this paper, we introduce RadGenome-Chest CT, a comprehensive, large-scale, region-guided 3D chest CT interpretation dataset based on CT-RATE. Specifically, we leverage the latest powerful universal segmentation and large language models, to extend the original datasets (over 25,692 non-contrast 3D chest CT volume and reports from 20,000 patients) from the following aspects: (i) organ-level segmentation masks covering 197 categories, which provide intermediate reasoning visual clues for interpretation; (ii) 665 K multi-granularity grounded reports, where each sentence of the report is linked to the corresponding anatomical region of CT volume in the form of a segmentation mask; (iii) 1.3 M grounded VQA pairs, where questions and answers are all linked with reference segmentation masks, enabling models to associate visual evidence with textual explanations. All grounded reports and VQA pairs in the validation set have gone through manual verification to ensure dataset quality. We believe that RadGenome-Chest CT can significantly advance the development of multimodal medical foundation models, by training to generate texts based on given segmentation regions, which is unattainable with previous relevant datasets. We will release all segmentation masks, grounded reports, and VQA pairs to facilitate further research and development in this field.",
    "pdf_link": "https://arxiv.org/abs/2404.16754",
    "graphs": [],
    "abstract_cn": "医学人工智能领域对开发通用基础模型的兴趣日益浓厚。这些模型的开发关键在于依赖数据集的扩展，特别是需要创建包含不同成像方式下多样化监督信号的开源医学图像数据集。本文介绍了RadGenome-Chest CT，这是一个基于CT-RATE的全面、大规模、区域引导的3D胸部CT解释数据集。我们采用了先进的通用分割技术和大型语言模型，对原始数据集（超过25,692个非对比3D胸部CT图像和20,000名患者的报告）进行了以下扩展：（i）197个器官类别的分割掩模，为解读提供推理的视觉线索；（ii）665,000份多粒度的地面报告，报告中每句话都与CT图像中的相应解剖区域通过分割掩模关联；（iii）130万个地面VQA对，问题和答案均与参考分割掩模相连，使模型能够将视觉证据与文本解释相联系。验证集中的所有地面报告和VQA对都经过了人工验证，确保了数据集的质量。我们认为，RadGenome-Chest CT能够显著推动多模态医学基础模型的发展，通过训练模型基于特定分割区域生成文本，这在以往的相关数据集中是无法实现的。我们将公开所有分割掩模、地面报告和VQA对，以促进该领域的进一步研究和开发。",
    "title_cn": "RadGenome-Chest CT：一个为胸部 CT 影像分析量身定制的视觉与语言结合的数据集",
    "tags": [
      "分类：LLM应用",
      "医学图像处理",
      "人工智能"
    ]
  },
  {
    "title": "Embracing Diversity: Interpretable Zero-shot classification beyond one vector per class",
    "submit_datetime": "2024年04月25日",
    "abstract": "Vision-language models enable open-world classification of objects without the need for any retraining. While this zero-shot paradigm marks a significant advance, even today's best models exhibit skewed performance when objects are dissimilar from their typical depiction. Real world objects such as pears appear in a variety of forms -- from diced to whole, on a table or in a bowl -- yet standard VLM classifiers map all instances of a class to a \\it{single vector based on the class label}. We argue that to represent this rich diversity within a class, zero-shot classification should move beyond a single vector. We propose a method to encode and account for diversity within a class using inferred attributes, still in the zero-shot setting without retraining. We find our method consistently outperforms standard zero-shot classification over a large suite of datasets encompassing hierarchies, diverse object states, and real-world geographic diversity, as well finer-grained datasets where intra-class diversity may be less prevalent. Importantly, our method is inherently interpretable, offering faithful explanations for each inference to facilitate model debugging and enhance transparency. We also find our method scales efficiently to a large number of attributes to account for diversity -- leading to more accurate predictions for atypical instances. Finally, we characterize a principled trade-off between overall and worst class accuracy, which can be tuned via a hyperparameter of our method. We hope this work spurs further research into the promise of zero-shot classification beyond a single class vector for capturing diversity in the world, and building transparent AI systems without compromising performance.",
    "pdf_link": "https://arxiv.org/abs/2404.16717",
    "graphs": [],
    "abstract_cn": "视觉-语言模型实现了无需重新训练即可对物体进行开放性分类，这标志着一个重大的技术进步。然而，即便是顶尖模型，一旦物体形态偏离常规，也会出现性能偏差。以梨为例，它们可能被切块或完整呈现，放置在桌面或碗中，而传统的视觉-语言模型（VLM）分类器却将同一类别的所有实例简化为基于类别标签的\\it{单一向量}。我们提出，为了捕捉类别内部的丰富多样性，零样本分类不应局限于单一向量。本研究提出了一种新方法，利用推断出的属性在零样本学习框架内编码和考虑类别内部的多样性，无需重新训练。我们的方法在多个大型数据集上的表现均优于传统零样本分类，这些数据集覆盖了层级结构、多样化的物体状态、现实世界的地理多样性，以及类别内部多样性不那么显著的更细致的数据集。值得注意的是，我们的方法天生具有可解释性，为每次推断提供准确的解释，这有助于模型调试并提高透明度。此外，我们的方法能够高效扩展至大量属性，以更准确地预测非典型实例。最后，我们确定了整体准确性与最差类别准确性之间的权衡原则，并通过我们方法的超参数进行调整。我们期望本研究能推动零样本分类技术的发展，超越单一类别向量，以更好地捕捉世界的多样性，并构建性能不打折的透明AI系统。",
    "title_cn": "拥抱多样性：探索超越单一类别向量的零样本分类的可解释性",
    "tags": [
      "LLM应用",
      "计算机视觉",
      ""
    ]
  },
  {
    "title": "Layer Skip: Enabling Early Exit Inference and Self-Speculative Decoding",
    "submit_datetime": "2024年04月25日",
    "abstract": "We present LayerSkip, an end-to-end solution to speed-up inference of large language models (LLMs). First, during training we apply layer dropout, with low dropout rates for earlier layers and higher dropout rates for later layers, and an early exit loss where all transformer layers share the same exit. Second, during inference, we show that this training recipe increases the accuracy of early exit at earlier layers, without adding any auxiliary layers or modules to the model. Third, we present a novel self-speculative decoding solution where we exit at early layers and verify and correct with remaining layers of the model. Our proposed self-speculative decoding approach has less memory footprint than other speculative decoding approaches and benefits from shared compute and activations of the draft and verification stages. We run experiments on different Llama model sizes on different types of training: pretraining from scratch, continual pretraining, finetuning on specific data domain, and finetuning on specific task. We implement our inference solution and show speedups of up to 2.16x on summarization for CNN/DM documents, 1.82x on coding, and 2.0x on TOPv2 semantic parsing task.",
    "pdf_link": "https://arxiv.org/abs/2404.16710",
    "graphs": [],
    "abstract_cn": "本文介绍了 LayerSkip，一种旨在提升大型语言模型（LLMs）推理效率的端到端方法。在训练阶段，我们实施了层间丢弃策略，对前置层采用低丢弃率，对后置层采用高丢弃率，并引入了所有变换层共享的早期退出损失机制。在推理阶段，我们发现这种训练策略显著提升了早期层的退出准确性，且无需额外增加辅助层或模块。此外，我们还提出了一种创新的自我推测解码技术，该技术允许在早期层进行退出，并利用模型剩余层进行校验和修正。与传统推测解码方法相比，我们的自我推测解码技术占用更少的内存，并能从草稿和验证阶段共享的计算资源与激活中获益。我们在不同规模的 Llama 模型上进行了广泛实验，包括从零开始的预训练、持续预训练、特定数据域的微调以及特定任务的微调。我们实现了这一推理方案，并在 CNN/DM 文档摘要任务上实现了最高 2.16 倍的速度提升，在编码任务上达到 1.82 倍，在 TOPv2 语义解析任务上达到 2.0 倍的加速。",
    "title_cn": "层级跳转：实现快速退出推理与自主推测性解码",
    "tags": [
      "LLM应用",
      "",
      "计算效率"
    ]
  },
  {
    "title": "Cooperate or Collapse: Emergence of Sustainability Behaviors in a Society of LLM Agents",
    "submit_datetime": "2024年04月25日",
    "abstract": "In the rapidly evolving field of artificial intelligence, ensuring safe decision-making of Large Language Models (LLMs) is a significant challenge. This paper introduces Governance of the Commons Simulation (GovSim), a simulation platform designed to study strategic interactions and cooperative decision-making in LLMs. Through this simulation environment, we explore the dynamics of resource sharing among AI agents, highlighting the importance of ethical considerations, strategic planning, and negotiation skills. GovSim is versatile and supports any text-based agent, including LLMs agents. Using the Generative Agent framework, we create a standard agent that facilitates the integration of different LLMs. Our findings reveal that within GovSim, only two out of 15 tested LLMs managed to achieve a sustainable outcome, indicating a significant gap in the ability of models to manage shared resources. Furthermore, we find that by removing the ability of agents to communicate, they overuse the shared resource, highlighting the importance of communication for cooperation. Interestingly, most LLMs lack the ability to make universalized hypotheses, which highlights a significant weakness in their reasoning skills. We open source the full suite of our research results, including the simulation environment, agent prompts, and a comprehensive web interface.",
    "pdf_link": "https://arxiv.org/abs/2404.16698",
    "graphs": [],
    "abstract_cn": "在日新月异的人工智能世界中，保障大型语言模型（LLMs）的决策安全无疑是一项艰巨任务。本文提出了“公共资源治理模拟”（GovSim），一个专为研究LLMs中战略互动与合作决策而设计的模拟平台。该平台让我们得以深入探讨AI代理间资源共享的机制，同时凸显了道德考量、战略规划和谈判技巧的关键作用。GovSim的通用性使其能够支持包括LLMs在内的所有文本型代理。利用生成代理框架，我们开发了一个标准化代理，以促进不同LLMs的融合。研究发现，在GovSim平台上，15个受测的LLMs中仅有两个能够达成可持续的成果，这暴露了模型在共享资源管理上的能力不足。更进一步，当代理失去沟通能力时，会出现共享资源的过度使用，这强调了沟通在促进合作中的核心作用。值得注意的是，大多数LLMs在进行普遍化假设方面存在缺陷，这反映了它们在推理能力上的一个明显弱点。我们已经将研究成果的全套内容开源，包括模拟环境、代理提示和全面的网页界面。",
    "title_cn": "合作还是崩溃：探究大型语言模型（LLM）代理社会中可持续性行为的兴起",
    "tags": [
      "Agent",
      "人工智能",
      "资源管理"
    ]
  },
  {
    "title": "Influence of Solution Efficiency and Valence of Instruction on Additive and Subtractive Solution Strategies in Humans and GPT-4",
    "submit_datetime": "2024年04月25日",
    "abstract": "We explored the addition bias, a cognitive tendency to prefer adding elements over removing them to alter an initial state or structure, by conducting four preregistered experiments examining the problem-solving behavior of both humans and OpenAl's GPT-4 large language model. The experiments involved 588 participants from the U.S. and 680 iterations of the GPT-4 model. The problem-solving task was either to create symmetry within a grid (Experiments 1 and 3) or to edit a summary (Experiments 2 and 4). As hypothesized, we found that overall, the addition bias was present. Solution efficiency (Experiments 1 and 2) and valence of the instruction (Experiments 3 and 4) played important roles. Human participants were less likely to use additive strategies when subtraction was relatively more efficient than when addition and subtraction were equally efficient. GPT-4 exhibited the opposite behavior, with a strong addition bias when subtraction was more efficient. In terms of instruction valence, GPT-4 was more likely to add words when asked to \"improve\" compared to \"edit\", whereas humans did not show this effect. When we looked at the addition bias under different conditions, we found more biased responses for GPT-4 compared to humans. Our findings highlight the importance of considering comparable and sometimes superior subtractive alternatives, as well as reevaluating one's own and particularly the language models' problem-solving behavior.",
    "pdf_link": "https://arxiv.org/abs/2404.16692",
    "graphs": [],
    "abstract_cn": "通过四项预注册实验，我们深入探究了“添加偏好”这一认知倾向，即人们更倾向于通过增加而非减少元素来改变初始状态或结构。这些实验比较了人类与 OpenAI 的 GPT-4 大型语言模型在解决问题时的行为，共有 588 名美国参与者和 GPT-4 模型进行了 680 轮迭代。实验任务包括在网格中创造对称性（实验 1 和 3）和编辑摘要（实验 2 和 4）。正如预期，我们普遍观察到了添加偏好的存在。解决效率和指令的情感色彩对实验结果有显著影响。在减法更为高效的情况下，人类参与者较少采用累加策略。而 GPT-4 则表现出相反的倾向，即使在减法更有效时也展现出强烈的添加偏好。对于指令的情感色彩，GPT-4 在被要求“改进”时更倾向于增加词汇，而“编辑”时则不然，人类则未显示这种差异。在不同条件下观察添加偏好时，GPT-4 相比人类展现出更明显的偏差。这些发现提醒我们，在解决问题时，应考虑等效甚至更优的减法方法，并重新审视自己尤其是语言模型的解题策略。",
    "title_cn": "本文探讨了解决方案的效率性以及指令的正负价态如何影响人类和 GPT-4 在执行加法和减法策略时的行为模式。",
    "tags": [
      "LLM应用\n\n这篇论文主要研究了人类和大型语言模型（LLM）在解决问题时的行为差异，特别是关于“添加偏好”的认知倾向。通过比较人类和GPT-4模型在不同实验任务中的表现，论文探讨了解决效率、指令情感色彩等因素对实验结果的影响。由于论文主要关注LLM在实际应用中的表现和行为特点，因此可以归类为LLM应用。",
      "心理学",
      "人工智能"
    ]
  },
  {
    "title": "EmoVIT: Revolutionizing Emotion Insights with Visual Instruction Tuning",
    "submit_datetime": "2024年04月25日",
    "abstract": "Visual Instruction Tuning represents a novel learning paradigm involving the fine-tuning of pre-trained language models using task-specific instructions. This paradigm shows promising zero-shot results in various natural language processing tasks but is still unexplored in vision emotion understanding. In this work, we focus on enhancing the model's proficiency in understanding and adhering to instructions related to emotional contexts. Initially, we identify key visual clues critical to visual emotion recognition. Subsequently, we introduce a novel GPT-assisted pipeline for generating emotion visual instruction data, effectively addressing the scarcity of annotated instruction data in this domain. Expanding on the groundwork established by InstructBLIP, our proposed EmoVIT architecture incorporates emotion-specific instruction data, leveraging the powerful capabilities of Large Language Models to enhance performance. Through extensive experiments, our model showcases its proficiency in emotion classification, adeptness in affective reasoning, and competence in comprehending humor. The comparative analysis provides a robust benchmark for Emotion Visual Instruction Tuning in the era of LLMs, providing valuable insights and opening avenues for future exploration in this domain. Our code is available at \\url{https://github.com/aimmemotion/EmoVIT}.",
    "pdf_link": "https://arxiv.org/abs/2404.16670",
    "graphs": [],
    "abstract_cn": "视觉指令调优是一种新颖的学习范式，它通过特定任务指令对预训练的语言模型进行精准调整。这一范式在多种自然语言处理任务中展现了出色的零样本性能，但在视觉情感理解领域尚待深入研究。本研究致力于提升模型对情感语境相关指令的理解和执行能力。我们首先识别了对视觉情感识别至关重要的关键视觉线索。接着，我们提出了一个创新的GPT辅助流程，用于生成情感视觉指令数据，有效解决了该领域标注指令数据不足的问题。在InstructBLIP的基础上，我们设计的EmoVIT架构整合了针对情感的指令数据，借助大型语言模型的强大功能，显著提升了性能。经过广泛的实验验证，我们的模型在情感分类、情感推理以及幽默理解方面展现了卓越的能力。这项比较分析为LLM时代的Emotion Visual Instruction Tuning提供了坚实的基准，并为未来在该领域的研究提供了宝贵的洞见和探索途径。相关代码已在 \\url{https://github.com/aimmemotion/EmoVIT} 上公开。",
    "title_cn": "EmoVIT：以视觉指令调校，引领情感洞察力的革新。",
    "tags": [
      "LLM应用",
      "",
      "情感分析"
    ]
  },
  {
    "title": "Benchmarking Mobile Device Control Agents across Diverse Configurations",
    "submit_datetime": "2024年04月25日",
    "abstract": "Developing autonomous agents for mobile devices can significantly enhance user interactions by offering increased efficiency and accessibility. However, despite the growing interest in mobile device control agents, the absence of a commonly adopted benchmark makes it challenging to quantify scientific progress in this area. In this work, we introduce B-MoCA: a novel benchmark designed specifically for evaluating mobile device control agents. To create a realistic benchmark, we develop B-MoCA based on the Android operating system and define 60 common daily tasks. Importantly, we incorporate a randomization feature that changes various aspects of mobile devices, including user interface layouts and language settings, to assess generalization performance. We benchmark diverse agents, including agents employing large language models (LLMs) or multi-modal LLMs as well as agents trained from scratch using human expert demonstrations. While these agents demonstrate proficiency in executing straightforward tasks, their poor performance on complex tasks highlights significant opportunities for future research to enhance their effectiveness. Our source code is publicly available at https://b-moca.github.io.",
    "pdf_link": "https://arxiv.org/abs/2404.16660",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.16660v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16660/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16660v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16660/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16660v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16660/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16660v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16660/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16660v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16660/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16660v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16660/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16660v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16660/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16660v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16660/x9.png"
      }
    ],
    "abstract_cn": "开发适用于移动设备的自主智能体，能够通过提升效率和便捷性显著改善用户体验。尽管对移动设备控制智能体的兴趣不断上升，但缺少统一的评估标准使得衡量该领域的科学进展变得困难。本研究提出了 B-MoCA，这是一个专为评估移动设备控制智能体而设计的全新基准测试。我们基于 Android 系统构建了 B-MoCA，设定了 60 项日常任务，并引入了随机化特性，以模拟用户界面布局和语言设置的变化，从而测试智能体的泛化能力。我们对多种智能体进行了评估，包括利用大型语言模型（LLMs）或多模态 LLMs 的智能体，以及完全基于人类专家示范从头训练的智能体。尽管这些智能体在处理简单任务上表现出色，但在复杂任务上的表现不佳，这为未来研究提供了提升智能体效能的重要方向。我们的源代码已在 https://b-moca.github.io 公开发布。",
    "title_cn": "跨多样配置对移动设备控制代理进行性能评估。",
    "tags": [
      "Agent",
      "移动设备",
      "人工智能"
    ]
  },
  {
    "title": "Evolutionary Large Language Models for Hardware Security: A Comparative Survey",
    "submit_datetime": "2024年04月25日",
    "abstract": "Automating hardware (HW) security vulnerability detection and mitigation during the design phase is imperative for two reasons: (i) It must be before chip fabrication, as post-fabrication fixes can be costly or even impractical; (ii) The size and complexity of modern HW raise concerns about unknown vulnerabilities compromising CIA triad. While Large Language Models (LLMs) can revolutionize both HW design and testing processes, within the semiconductor context, LLMs can be harnessed to automatically rectify security-relevant vulnerabilities inherent in HW designs. This study explores the seeds of LLM integration in register transfer level (RTL) designs, focusing on their capacity for autonomously resolving security-related vulnerabilities. The analysis involves comparing methodologies, assessing scalability, interpretability, and identifying future research directions. Potential areas for exploration include developing specialized LLM architectures for HW security tasks and enhancing model performance with domain-specific knowledge, leading to reliable automated security measurement and risk mitigation associated with HW vulnerabilities.",
    "pdf_link": "https://arxiv.org/abs/2404.16651",
    "graphs": [],
    "abstract_cn": "在芯片制造前自动化检测和缓解硬件安全漏洞至关重要，这不仅因为后期修复成本高昂或不切实际，也因为现代硬件的庞大与复杂性可能隐藏着威胁信息安全的秘密漏洞。大型语言模型（LLMs）有潜力革新硬件设计与测试流程，尤其在半导体领域，它们能够被用来自动识别并修复硬件设计中的安全漏洞。本研究深入探讨了将LLMs融入寄存器传输级（RTL）设计的可能性，特别是它们在独立解决安全漏洞方面的能力。研究内容包括对比不同方法、评估模型的可扩展性和可解释性，并展望未来的研究方向。探索的潜在领域可能包括为硬件安全任务设计专门的LLM架构，以及通过特定领域的知识提升模型性能，以实现对硬件漏洞的可靠自动化安全评估和风险缓解。",
    "title_cn": "进化型大型语言模型在硬件安全领域的应用：一项对比研究",
    "tags": [
      "分类：LLM应用",
      "半导体制造",
      "硬件安全"
    ]
  },
  {
    "title": "Tele-FLM Technical Report",
    "submit_datetime": "2024年04月25日",
    "abstract": "Large language models (LLMs) have showcased profound capabilities in language understanding and generation, facilitating a wide array of applications. However, there is a notable paucity of detailed, open-sourced methodologies on efficiently scaling LLMs beyond 50 billion parameters with minimum trial-and-error cost and computational resources. In this report, we introduce Tele-FLM (aka FLM-2), a 52B open-sourced multilingual large language model that features a stable, efficient pre-training paradigm and enhanced factual judgment capabilities. Tele-FLM demonstrates superior multilingual language modeling abilities, measured by BPB on textual corpus. Besides, in both English and Chinese foundation model evaluation, it is comparable to strong open-sourced models that involve larger pre-training FLOPs, such as Llama2-70B and DeepSeek-67B. In addition to the model weights, we share the core designs, engineering practices, and training details, which we expect to benefit both the academic and industrial communities.",
    "pdf_link": "https://arxiv.org/abs/2404.16645",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）以其卓越的语言理解和生成能力，推动了众多应用的发展。尽管如此，目前对于如何高效扩展这些模型至500亿参数以上，同时减少试错成本和计算资源消耗的详尽且开源的方法论却相对匮乏。本报告中，我们推出了Tele-FLM（亦称FLM-2），一个52亿参数的开源多语言大型语言模型，它采用了稳定而高效的预训练方法，并具备了更强的事实判断力。在文本语料库的BPB测试中，Tele-FLM展现了其卓越的多语言建模能力。在英文和中文的基础模型评估中，它与那些拥有更大预训练运算次数（FLOPs）的开源模型，如Llama2-70B和DeepSeek-67B，表现相当。我们不仅提供了模型权重，还包括了核心设计理念、工程实践和训练细节，期待这些信息能够为学术界和工业界带来裨益。",
    "title_cn": "远程-FLM 技术报告",
    "tags": [
      "LLM应用",
      "",
      "机器学习"
    ]
  },
  {
    "title": "TinyChart: Efficient Chart Understanding with Visual Token Merging and Program-of-Thoughts Learning",
    "submit_datetime": "2024年04月25日",
    "abstract": "Charts are important for presenting and explaining complex data relationships. Recently, multimodal large language models (MLLMs) have shown remarkable capabilities in various chart understanding tasks. However, the sheer size of these models in terms of parameters and computational requirements limits their use in resource-constrained environments. In this paper, we present TinyChart, an efficient MLLM for chart understanding with only 3B parameters. TinyChart overcomes two key challenges in efficient chart understanding: (1) reduce the burden of learning numerical computations through a Program-of-Thoughts (PoT) learning strategy, which trains the model to generate Python programs for numerical calculations, and (2) reduce lengthy vision feature sequences produced by the vision transformer for high-resolution images through a Vision Token Merging module, which gradually merges most similar vision tokens. Extensive experiments demonstrate that our 3B TinyChart achieves SOTA performance on a variety of chart understanding benchmarks including ChartQA, Chart-to-Text, Chart-to-Table, OpenCQA, and ChartX. It outperforms several chart understanding MLLM with up to 13B parameters such as ChartLlama and ChartAst, and close-sourced general-purpose MLLM GPT-4V on ChartQA. It also demonstrates its superior efficiency with higher throughput during inference due to a smaller model scale and more efficient vision encoding. Our code and model are available at https://github.com/X-PLUG/mPLUG-DocOwl/tree/main/TinyChart.",
    "pdf_link": "https://arxiv.org/abs/2404.16635",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.16635v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16635/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16635v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16635/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16635v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16635/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16635v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16635/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16635v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16635/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16635v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16635/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16635v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16635/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16635v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16635/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16635v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16635/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16635v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16635/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16635v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16635/x11.png"
      }
    ],
    "abstract_cn": "图表在阐释复杂数据关系方面扮演着关键角色。近期，多模态大型语言模型（MLLMs）在图表理解领域展现出了卓越的能力。但是，这些模型因参数众多和计算需求巨大，难以在资源有限的环境中部署。本文介绍了TinyChart，一款仅含3B参数的高效MLLM，专为图表理解设计。TinyChart解决了两个主要问题：首先，采用程序化思维（PoT）学习策略，通过训练模型生成Python程序来执行数值计算，减轻了学习数值计算的负担；其次，通过视觉令牌合并模块，优化了视觉变换器处理高分辨率图像时产生的长序列视觉特征。大量实验证明，3B参数的TinyChart在ChartQA、Chart-to-Text、Chart-to-Table、OpenCQA和ChartX等多个图表理解基准测试中达到了最先进的性能。它不仅超越了参数量高达13B的ChartLlama和ChartAst等MLLM，还在ChartQA上超越了封闭源的通用MLLM GPT-4V。此外，由于模型规模较小和视觉编码更高效，TinyChart在推理过程中展现了更高的吞吐量和优越的效率。我们的代码和模型已在 https://github.com/X-PLUG/mPLUG-DocOwl/tree/main/TinyChart 上发布。",
    "title_cn": "TinyChart：采用视觉标记融合与思维过程学习，实现图表理解的高效性",
    "tags": [
      "分类：LLM应用",
      "数据分析",
      "人工智能"
    ]
  },
  {
    "title": "Hippocrates: An Open-Source Framework for Advancing Large Language Models in Healthcare",
    "submit_datetime": "2024年04月25日",
    "abstract": "The integration of Large Language Models (LLMs) into healthcare promises to transform medical diagnostics, research, and patient care. Yet, the progression of medical LLMs faces obstacles such as complex training requirements, rigorous evaluation demands, and the dominance of proprietary models that restrict academic exploration. Transparent, comprehensive access to LLM resources is essential for advancing the field, fostering reproducibility, and encouraging innovation in healthcare AI. We present Hippocrates, an open-source LLM framework specifically developed for the medical domain. In stark contrast to previous efforts, it offers unrestricted access to its training datasets, codebase, checkpoints, and evaluation protocols. This open approach is designed to stimulate collaborative research, allowing the community to build upon, refine, and rigorously evaluate medical LLMs within a transparent ecosystem. Also, we introduce Hippo, a family of 7B models tailored for the medical domain, fine-tuned from Mistral and LLaMA2 through continual pre-training, instruction tuning, and reinforcement learning from human and AI feedback. Our models outperform existing open medical LLMs models by a large-margin, even surpassing models with 70B parameters. Through Hippocrates, we aspire to unlock the full potential of LLMs not just to advance medical knowledge and patient care but also to democratize the benefits of AI research in healthcare, making them available across the globe.",
    "pdf_link": "https://arxiv.org/abs/2404.16621",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）在医疗领域的融合预示着医学诊断、研究和患者护理的革新。但这一进程遭遇了诸如培训复杂性、评估严格性以及专有模型的壁垒等挑战，这些壁垒限制了学术界的深入研究。为了推动医疗AI的发展、提高研究的可复制性并激发创新，对LLM资源的透明和全面访问显得尤为重要。我们推出了希波克拉底（Hippocrates），一个专为医疗领域设计的开源LLM框架，它与以往的尝试截然不同，提供了对其训练数据集、代码库、检查点和评估协议的完全开放访问。这种开放的姿态旨在促进合作研究，使社区能够在一个透明的生态系统中构建、改进和严格评估医学LLMs。同时，我们还推出了Hippo系列，这是一系列为医疗领域量身定制的7B模型，它们基于Mistral和LLaMA2，通过持续的预训练、指令调整和人机反馈的强化学习进行微调。我们的模型在性能上显著超越了现有的开放医学LLMs，甚至超过了参数量达70B的模型。通过希波克拉底，我们期望充分挖掘LLMs的潜力，不仅为了增进医学知识和提升患者护理水平，也为了在全球范围内普及AI研究在医疗保健中的益处。",
    "title_cn": "希波克拉底：一个开源框架，致力于在医疗保健领域推动大型语言模型的发展。",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Understanding Privacy Risks of Embeddings Induced by Large Language Models",
    "submit_datetime": "2024年04月25日",
    "abstract": "Large language models (LLMs) show early signs of artificial general intelligence but struggle with hallucinations. One promising solution to mitigate these hallucinations is to store external knowledge as embeddings, aiding LLMs in retrieval-augmented generation. However, such a solution risks compromising privacy, as recent studies experimentally showed that the original text can be partially reconstructed from text embeddings by pre-trained language models. The significant advantage of LLMs over traditional pre-trained models may exacerbate these concerns. To this end, we investigate the effectiveness of reconstructing original knowledge and predicting entity attributes from these embeddings when LLMs are employed. Empirical findings indicate that LLMs significantly improve the accuracy of two evaluated tasks over those from pre-trained models, regardless of whether the texts are in-distribution or out-of-distribution. This underscores a heightened potential for LLMs to jeopardize user privacy, highlighting the negative consequences of their widespread use. We further discuss preliminary strategies to mitigate this risk.",
    "pdf_link": "https://arxiv.org/abs/2404.16587",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.16587v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16587/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16587v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16587/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16587v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16587/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16587v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16587/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16587v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16587/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16587v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16587/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16587v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16587/x7.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）初显人工通用智能的端倪，却也面临着幻觉的挑战。一种缓解幻觉的潜在方法是将外部知识嵌入化，以增强LLMs的检索增强生成能力。但这种做法可能会侵犯隐私，因为研究表明，预训练的语言模型能够从文本嵌入中部分还原原始文本。LLMs相较于传统预训练模型的优势可能会加剧对隐私的担忧。本研究探讨了使用LLMs时，从嵌入中重建原始知识和预测实体属性的有效性。实验结果显示，LLMs在两项评估任务的准确性上显著超越了预训练模型，无论文本是否符合分布。这突显了LLMs可能对用户隐私构成更大威胁，也反映了它们普及使用的潜在负面影响。文章还进一步讨论了减轻这一风险的初步策略。",
    "title_cn": "深入探究大型语言模型所诱发的嵌入技术背后的隐私隐患",
    "tags": [
      "分类：LLM应用",
      "人工智能",
      "隐私保护"
    ]
  },
  {
    "title": "Evaluating Large Language Models on Time Series Feature Understanding: A Comprehensive Taxonomy and Benchmark",
    "submit_datetime": "2024年04月25日",
    "abstract": "Large Language Models (LLMs) offer the potential for automatic time series analysis and reporting, which is a critical task across many domains, spanning healthcare, finance, climate, energy, and many more. In this paper, we propose a framework for rigorously evaluating the capabilities of LLMs on time series understanding, encompassing both univariate and multivariate forms. We introduce a comprehensive taxonomy of time series features, a critical framework that delineates various characteristics inherent in time series data. Leveraging this taxonomy, we have systematically designed and synthesized a diverse dataset of time series, embodying the different outlined features. This dataset acts as a solid foundation for assessing the proficiency of LLMs in comprehending time series. Our experiments shed light on the strengths and limitations of state-of-the-art LLMs in time series understanding, revealing which features these models readily comprehend effectively and where they falter. In addition, we uncover the sensitivity of LLMs to factors including the formatting of the data, the position of points queried within a series and the overall time series length.",
    "pdf_link": "https://arxiv.org/abs/2404.16563",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）展现了在自动进行时间序列分析与报告方面的潜力，这对于医疗、金融、气候、能源等多个领域都至关重要。本文提出了一套严格评估LLMs时间序列理解能力的方法框架，覆盖了单变量和多变量的时间序列。我们引入了一个全面的时间序列特征分类体系，这一体系详细划分了时间序列数据的多种内在特性。基于此分类体系，我们设计并构建了一个包含多样特征的时间序列数据集，为测试LLMs的时间序列理解能力提供了坚实的基准。实验结果显示了当前最先进LLMs在时间序列理解方面的优势与局限，指出了这些模型能够轻松理解的特征以及它们的不足之处。同时，我们还发现了LLMs对于数据格式、查询点位置以及时间序列长度等因素的敏感度。",
    "title_cn": "全面分类与基准测试：探究大型语言模型对时间序列特征的理解能力。",
    "tags": [
      "LLM应用",
      "时间序列分析",
      "多领域应用"
    ]
  },
  {
    "title": "Energy-Latency Manipulation of Multi-modal Large Language Models via Verbose Samples",
    "submit_datetime": "2024年04月25日",
    "abstract": "Despite the exceptional performance of multi-modal large language models (MLLMs), their deployment requires substantial computational resources. Once malicious users induce high energy consumption and latency time (energy-latency cost), it will exhaust computational resources and harm availability of service. In this paper, we investigate this vulnerability for MLLMs, particularly image-based and video-based ones, and aim to induce high energy-latency cost during inference by crafting an imperceptible perturbation. We find that high energy-latency cost can be manipulated by maximizing the length of generated sequences, which motivates us to propose verbose samples, including verbose images and videos. Concretely, two modality non-specific losses are proposed, including a loss to delay end-of-sequence (EOS) token and an uncertainty loss to increase the uncertainty over each generated token. In addition, improving diversity is important to encourage longer responses by increasing the complexity, which inspires the following modality specific loss. For verbose images, a token diversity loss is proposed to promote diverse hidden states. For verbose videos, a frame feature diversity loss is proposed to increase the feature diversity among frames. To balance these losses, we propose a temporal weight adjustment algorithm. Experiments demonstrate that our verbose samples can largely extend the length of generated sequences.",
    "pdf_link": "https://arxiv.org/abs/2404.16557",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.16557v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16557/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16557v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16557/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16557v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16557/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16557v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16557/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16557v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16557/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16557v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16557/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16557v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16557/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16557v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16557/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16557v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16557/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16557v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16557/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16557v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16557/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16557v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16557/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16557v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16557/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16557v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16557/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16557v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16557/x15.png"
      }
    ],
    "abstract_cn": "多模态大型语言模型（MLLMs）虽性能卓越，但其运行却需巨额计算资源支撑。恶意用户一旦触发高能耗与延迟（能耗-延迟成本），便可能耗尽资源，影响服务的稳定性。本文聚焦MLLMs，尤其是基于图像和视频的模型，探讨了如何通过精心设计的难以察觉的扰动，在推理过程中制造高昂的能耗-延迟成本。研究发现，通过延长生成序列的长度，可以操控这一成本，这促使我们引入了冗长样本的概念，涵盖冗长的图像与视频。文章具体提出了两种非模态特定的损失函数：一是推迟序列结束（EOS）标记的损失，二是增加每个生成标记不确定性的损失。此外，提升多样性对于激励更长响应、增加复杂性同样关键，这启发了我们设计了以下模态特定的损失函数。对于冗长图像，提出了一种标记多样性损失，以增强隐藏状态的多样性；对于冗长视频，则提出了一种帧特征多样性损失，以提升帧间特征的多样性。为平衡这些损失，我们设计了一种时间权重调整算法。实验结果证明，我们的冗长样本能显著延长生成序列的长度。",
    "title_cn": "本文探讨了如何利用冗长样本对多模态大型语言模型的能耗与延迟进行精细调控。",
    "tags": [
      "分类：LLM应用",
      "计算机视觉",
      ""
    ]
  },
  {
    "title": "Evaluating Consistency and Reasoning Capabilities of Large Language Models",
    "submit_datetime": "2024年04月25日",
    "abstract": "Large Language Models (LLMs) are extensively used today across various sectors, including academia, research, business, and finance, for tasks such as text generation, summarization, and translation. Despite their widespread adoption, these models often produce incorrect and misleading information, exhibiting a tendency to hallucinate. This behavior can be attributed to several factors, with consistency and reasoning capabilities being significant contributors. LLMs frequently lack the ability to generate explanations and engage in coherent reasoning, leading to inaccurate responses. Moreover, they exhibit inconsistencies in their outputs. This paper aims to evaluate and compare the consistency and reasoning capabilities of both public and proprietary LLMs. The experiments utilize the Boolq dataset as the ground truth, comprising questions, answers, and corresponding explanations. Queries from the dataset are presented as prompts to the LLMs, and the generated responses are evaluated against the ground truth answers. Additionally, explanations are generated to assess the models' reasoning abilities. Consistency is evaluated by repeatedly presenting the same query to the models and observing for variations in their responses. For measuring reasoning capabilities, the generated explanations are compared to the ground truth explanations using metrics such as BERT, BLEU, and F-1 scores. The findings reveal that proprietary models generally outperform public models in terms of both consistency and reasoning capabilities. However, even when presented with basic general knowledge questions, none of the models achieved a score of 90\\% in both consistency and reasoning. This study underscores the direct correlation between consistency and reasoning abilities in LLMs and highlights the inherent reasoning challenges present in current language models.",
    "pdf_link": "https://arxiv.org/abs/2404.16478",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）广泛应用于学术、研究、商业和金融等多个领域，承担着文本生成、摘要和翻译等任务。然而，尽管这些模型广受欢迎，它们却常常制造出错误和误导性的信息，似乎有一种“幻想”倾向。这种倾向的形成，一致性和推理能力是主要的影响因素。大型语言模型往往在生成解释和进行逻辑推理方面力不从心，从而导致了应答的不准确。此外，它们的输出结果也常常自相矛盾。本文的目标是对比评估公共与私有的大型语言模型在一致性和推理能力上的表现。实验采用了Boolq数据集作为基准，该数据集包含了问题、答案及相应的解释。将数据集中的查询作为提示输入给大型语言模型，然后将其生成的回答与基准答案进行比较。同时，为了评估模型的推理能力，还生成了解释。通过重复向模型提出相同的问题，观察其回答的变化，以此来衡量一致性。而推理能力的测量，则是通过将生成的解释与基准解释使用BERT、BLEU和F-1等指标进行对比。研究发现，私有模型在一致性和推理能力上普遍优于公共模型。但是，即便面对基础的常识性问题，也没有一个模型能够在一致性和推理上都达到90%的准确率。本研究揭示了大型语言模型中一致性与推理能力之间的密切联系，并指出了当前语言模型所面临的推理挑战。",
    "title_cn": "探究大型语言模型的内在一致性与逻辑推理功能",
    "tags": [
      "分类：LLM理论",
      "学术研究",
      ""
    ]
  },
  {
    "title": "Large Language Models Perform on Par with Experts Identifying Mental Health Factors in Adolescent Online Forums",
    "submit_datetime": "2024年04月25日",
    "abstract": "Mental health in children and adolescents has been steadily deteriorating over the past few years [ 1 ]. The recent advent of Large Language Models (LLMs) offers much hope for cost and time efficient scaling of monitoring and intervention, yet despite specifically prevalent issues such as school bullying and eating disorders, previous studies on have not investigated performance in this domain or for open information extraction where the set of answers is not predetermined. We create a new dataset of Reddit posts from adolescents aged 12-19 annotated by expert psychiatrists for the following categories: TRAUMA, PRECARITY, CONDITION, SYMPTOMS, SUICIDALITY and TREATMENT and compare expert labels to annotations from two top performing LLMs (GPT3.5 and GPT4). In addition, we create two synthetic datasets to assess whether LLMs perform better when annotating data as they generate it. We find GPT4 to be on par with human inter-annotator agreement and performance on synthetic data to be substantially higher, however we find the model still occasionally errs on issues of negation and factuality and higher performance on synthetic data is driven by greater complexity of real data rather than inherent advantage.",
    "pdf_link": "https://arxiv.org/abs/2404.16461",
    "graphs": [],
    "abstract_cn": "近年来，儿童和青少年的心理健康问题日益严重。大型语言模型（LLMs）的兴起为心理健康监测和干预提供了成本效益和时间效率的新途径。尽管如此，对于学校欺凌、饮食失调等普遍问题，先前研究并未深入探讨LLMs在这些领域的应用，尤其是在开放信息提取方面，即答案集未预先设定的情况下。本研究构建了一个新的数据集，包含12至19岁青少年在Reddit上的帖子，由专业精神病学家标注为创伤、不稳定、状况、症状、自杀倾向、治疗等类别。研究比较了专家的标注与两款顶尖LLMs（GPT3.5和GPT4）的标注结果。此外，研究还创建了两个合成数据集，用以评估LLMs在生成数据时进行标注的效果。研究发现，GPT4在一致性和性能上与人类专家相当，且在合成数据上的表现显著优于真实数据。然而，模型在处理否定和事实性问题时仍存在偏差，而合成数据上的性能提升更多是由于真实数据的复杂性，而非模型的内在优势。",
    "title_cn": "在分析青少年在线论坛中的心理健康状况时，大型语言模型展现出与专家相媲美的表现。",
    "tags": [
      "LLM应用",
      "心理健康",
      ""
    ]
  },
  {
    "title": "Asking and Answering Questions to Extract Event-Argument Structures",
    "submit_datetime": "2024年04月25日",
    "abstract": "This paper presents a question-answering approach to extract document-level event-argument structures. We automatically ask and answer questions for each argument type an event may have. Questions are generated using manually defined templates and generative transformers. Template-based questions are generated using predefined role-specific wh-words and event triggers from the context document. Transformer-based questions are generated using large language models trained to formulate questions based on a passage and the expected answer. Additionally, we develop novel data augmentation strategies specialized in inter-sentential event-argument relations. We use a simple span-swapping technique, coreference resolution, and large language models to augment the training instances. Our approach enables transfer learning without any corpora-specific modifications and yields competitive results with the RAMS dataset. It outperforms previous work, and it is especially beneficial to extract arguments that appear in different sentences than the event trigger. We also present detailed quantitative and qualitative analyses shedding light on the most common errors made by our best model.",
    "pdf_link": "https://arxiv.org/abs/2404.16413",
    "graphs": [],
    "abstract_cn": "本研究介绍了一种基于问答的文档级事件-论元结构提取方法。我们针对每个事件可能涉及的论元类型，自动生成并回答相关问题。这些问题利用预先定义的模板和生成式变换器来构建。模板问题通过上下文文档中的角色特定 wh-words 和事件触发器来生成，而变换器问题则依赖于经过训练的大型语言模型，这些模型能够根据给定段落和预期答案来构建问题。此外，我们还开发了创新的数据增强策略，专注于加强句子间的事件-论元关系。通过简单的跨度交换技术、共指消解以及大型语言模型，我们扩充了训练样本。这种方法支持无需针对特定语料库进行修改的迁移学习，并在 RAMS 数据集上取得了优异的成绩，超越了先前的研究。它特别擅长提取那些与事件触发器位于不同句子中的论元。我们还提供了详尽的定量和定性分析，深入探讨了我们最先进模型所犯的常见错误。",
    "title_cn": "通过提问和回答，我们能够抽取事件及其论元的结构。",
    "tags": [
      "LLM应用",
      "",
      "事件抽取"
    ]
  },
  {
    "title": "U2++ MoE: Scaling 4.7x parameters with minimal impact on RTF",
    "submit_datetime": "2024年04月25日",
    "abstract": "Scale has opened new frontiers in natural language processing, but at a high cost. In response, by learning to only activate a subset of parameters in training and inference, Mixture-of-Experts (MoE) have been proposed as an energy efficient path to even larger and more capable language models and this shift towards a new generation of foundation models is gaining momentum, particularly within the field of Automatic Speech Recognition (ASR). Recent works that incorporating MoE into ASR models have complex designs such as routing frames via supplementary embedding network, improving multilingual ability for the experts, and utilizing dedicated auxiliary losses for either expert load balancing or specific language handling. We found that delicate designs are not necessary, while an embarrassingly simple substitution of MoE layers for all Feed-Forward Network (FFN) layers is competent for the ASR task. To be more specific, we benchmark our proposed model on a large scale inner-source dataset (160k hours), the results show that we can scale our baseline Conformer (Dense-225M) to its MoE counterparts (MoE-1B) and achieve Dense-1B level Word Error Rate (WER) while maintaining a Dense-225M level Real Time Factor (RTF). Furthermore, by applying Unified 2-pass framework with bidirectional attention decoders (U2++), we achieve the streaming and non-streaming decoding modes in a single MoE based model, which we call U2++ MoE. We hope that our study can facilitate the research on scaling speech foundation models without sacrificing deployment efficiency.",
    "pdf_link": "https://arxiv.org/abs/2404.16407",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.16407v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16407/u2pp-moe.png"
      }
    ],
    "abstract_cn": "规模的扩大为自然语言处理领域带来了新的突破，但这也伴随着高昂的成本。为了应对这一挑战，专家混合（MoE）模型通过在训练和推理过程中仅激活部分参数，提出了一种更为节能的解决方案，以实现语言模型的进一步扩大和能力提升。这种向新一代基础模型的演进，特别是在自动语音识别（ASR）领域，正逐渐成为主流。近期的研究工作将MoE集成到ASR模型中，采用了如通过辅助嵌入网络路由帧、增强专家的多语言处理能力、以及使用专门的辅助损失进行专家负载均衡或特定语言处理等复杂设计。然而，我们的研究发现，这些复杂的设计并非必需，简单地将所有前馈网络（FFN）层替换为MoE层，就足以胜任ASR任务。具体而言，我们在大规模内部数据集（160,000小时）上对模型进行了基准测试，结果表明，我们可以将基线Conformer模型（Dense-225M）扩展到MoE版本（MoE-1B），在保持Dense-225M级别的实时因子（RTF）的同时，达到Dense-1B级别的词错误率（WER）。此外，通过采用带有双向注意力解码器的统一两遍框架（U2++），我们在基于MoE的单一模型中实现了流式和非流式解码模式，即U2++ MoE模型。我们期望本研究能够推动在不牺牲部署效率的前提下，对扩展语音基础模型的研究工作。",
    "title_cn": "U2++ MoE：在几乎不影响实时性能的情况下，实现了参数量的4.7倍扩展。",
    "tags": [
      "LLM理论",
      "",
      "自动语音识别"
    ]
  },
  {
    "title": "Efficiency in Focus: LayerNorm as a Catalyst for Fine-tuning Medical Visual Language Pre-trained Models",
    "submit_datetime": "2024年04月25日",
    "abstract": "In the realm of Medical Visual Language Models (Med-VLMs), the quest for universal efficient fine-tuning mechanisms remains paramount, especially given researchers in interdisciplinary fields are often extremely short of training resources, yet largely unexplored. Given the unique challenges in the medical domain, such as limited data scope and significant domain-specific requirements, evaluating and adapting Parameter-Efficient Fine-Tuning (PEFT) methods specifically for Med-VLMs is essential. Most of the current PEFT methods on Med-VLMs have yet to be comprehensively investigated but mainly focus on adding some components to the model's structure or input. However, fine-tuning intrinsic model components often yields better generality and consistency, and its impact on the ultimate performance of Med-VLMs has been widely overlooked and remains understudied. In this paper, we endeavour to explore an alternative to traditional PEFT methods, especially the impact of fine-tuning LayerNorm layers, FFNs and Attention layers on the Med-VLMs. Our comprehensive studies span both small-scale and large-scale Med-VLMs, evaluating their performance under various fine-tuning paradigms across tasks such as Medical Visual Question Answering and Medical Imaging Report Generation. The findings reveal unique insights into the effects of intrinsic parameter fine-tuning methods on fine-tuning Med-VLMs to downstream tasks and expose fine-tuning solely the LayerNorm layers not only surpasses the efficiency of traditional PEFT methods but also retains the model's accuracy and generalization capabilities across a spectrum of medical downstream tasks. The experiments show LayerNorm fine-tuning's superior adaptability and scalability, particularly in the context of large-scale Med-VLMs.",
    "pdf_link": "https://arxiv.org/abs/2404.16385",
    "graphs": [],
    "abstract_cn": "在医学视觉语言模型（Med-VLMs）的研究领域，探索一种通用且高效的微调机制显得尤为关键，特别是对于资源匮乏的跨学科研究者来说，这一需求尚未得到充分满足。面对医学领域的特殊挑战，如数据的有限性和领域特定的高标准要求，对Med-VLMs进行参数高效微调（PEFT）的评估与适配显得尤为重要。目前，大多数PEFT方法尚未全面探究，而是更多关注于模型结构或输入的局部改进。然而，对模型内部组件进行微调往往能够带来更佳的泛化和一致性，这一点在Med-VLMs的最终性能影响上却鲜有关注。本文旨在探索一种替代传统PEFT方法的新途径，特别是研究微调LayerNorm层、FFN和注意力层对Med-VLMs的影响。我们对不同规模的Med-VLMs进行了深入研究，包括小规模和大规模模型，并在多种微调框架下，评估了它们在医学视觉问答和医学影像报告生成等任务上的表现。研究发现，内部参数微调的方法在微调Med-VLMs以适应下游任务时具有独特的效果，尤其是仅微调LayerNorm层的方法，不仅在效率上超越了传统PEFT方法，而且在一系列医学相关下游任务中保持了模型的准确性和泛化能力。实验结果进一步证明，LayerNorm微调在大型Med-VLMs中的应用展现出了卓越的适应性和可扩展性。",
    "title_cn": "聚焦效率：LayerNorm 助力医学视觉语言预训练模型的精准调优。",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "List Items One by One: A New Data Source and Learning Paradigm for Multimodal LLMs",
    "submit_datetime": "2024年04月25日",
    "abstract": "Set-of-Mark (SoM) Prompting unleashes the visual grounding capability of GPT-4V, by enabling the model to associate visual objects with tags inserted on the image. These tags, marked with alphanumerics, can be indexed via text tokens for easy reference. Despite the extraordinary performance from GPT-4V, we observe that other Multimodal Large Language Models (MLLMs) struggle to understand these visual tags. To promote the learning of SoM prompting for open-source models, we propose a new learning paradigm: \"list items one by one,\" which asks the model to enumerate and describe all visual tags placed on the image following the alphanumeric orders of tags. By integrating our curated dataset with other visual instruction tuning datasets, we are able to equip existing MLLMs with the SoM prompting ability. Furthermore, we evaluate our finetuned SoM models on five MLLM benchmarks. We find that this new dataset, even in a relatively small size (10k-30k images with tags), significantly enhances visual reasoning capabilities and reduces hallucinations for MLLMs. Perhaps surprisingly, these improvements persist even when the visual tags are omitted from input images during inference. This suggests the potential of \"list items one by one\" as a new paradigm for training MLLMs, which strengthens the object-text alignment through the use of visual tags in the training stage. Finally, we conduct analyses by probing trained models to understand the working mechanism of SoM. Our code and data are available at \\url{https://github.com/zzxslp/SoM-LLaVA}.",
    "pdf_link": "https://arxiv.org/abs/2404.16375",
    "graphs": [],
    "abstract_cn": "Set-of-Mark（SoM）提示技术通过在图像上插入带有字母数字标签的视觉对象，显著提升了 GPT-4V 的视觉定位功能，使得模型能够轻松地通过文本标记引用这些标签。尽管 GPT-4V 表现出色，但其他多模态大型语言模型（MLLMs）在解析视觉标签上仍面临挑战。为此，我们提出了一种创新的学习模式——“逐一列举”，要求模型按照标签的字母数字顺序，对图像上的所有视觉标签进行枚举和描述。通过结合我们精选的数据集和现有的视觉指令调整数据集，成功地为现有 MLLMs 赋予了 SoM 提示的能力。我们在五个 MLLM 基准测试中对微调后的 SoM 模型进行了评估，发现即便是在较小的数据集规模（10k-30k 张带有标签的图像）下，也能显著提升 MLLMs 的视觉推理能力，并减少幻觉现象。令人意外的是，即便在推理时省略了输入图像中的视觉标签，这些提升依然能够保持。这一发现表明“逐一列举”有潜力成为训练 MLLMs 的新范式，它通过训练阶段的视觉标签使用，加强了对象与文本之间的对应关系。最后，我们通过深入分析训练模型，揭示了 SoM 的工作原理。相关代码和数据已在 \\url{https://github.com/zzxslp/SoM-LLaVA} 上公开。",
    "title_cn": "一一列举项目：开辟多模态大型语言模型（LLMs）的新数据来源与学习模式。",
    "tags": [
      "LLM应用",
      "计算机视觉",
      "人工智能"
    ]
  },
  {
    "title": "Don't Say No: Jailbreaking LLM by Suppressing Refusal",
    "submit_datetime": "2024年04月25日",
    "abstract": "Ensuring the safety alignment of Large Language Models (LLMs) is crucial to generating responses consistent with human values. Despite their ability to recognize and avoid harmful queries, LLMs are vulnerable to \"jailbreaking\" attacks, where carefully crafted prompts elicit them to produce toxic content. One category of jailbreak attacks is reformulating the task as adversarial attacks by eliciting the LLM to generate an affirmative response. However, the typical attack in this category GCG has very limited attack success rate. In this study, to better study the jailbreak attack, we introduce the DSN (Don't Say No) attack, which prompts LLMs to not only generate affirmative responses but also novelly enhance the objective to suppress refusals. In addition, another challenge lies in jailbreak attacks is the evaluation, as it is difficult to directly and accurately assess the harmfulness of the attack. The existing evaluation such as refusal keyword matching has its own limitation as it reveals numerous false positive and false negative instances. To overcome this challenge, we propose an ensemble evaluation pipeline incorporating Natural Language Inference (NLI) contradiction assessment and two external LLM evaluators. Extensive experiments demonstrate the potency of the DSN and the effectiveness of ensemble evaluation compared to baseline methods.",
    "pdf_link": "https://arxiv.org/abs/2404.16369",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.16369v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16369/examples.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16369v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16369/DSN_mainfig.jpg"
      },
      {
        "url": "https://arxiv.org/html/2404.16369v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16369/sliding.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16369v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16369/ASR_step_Llama_only_searching.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16369v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16369/ASR_step_Llama_both.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16369v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16369/ASR_step_Vicuna_only_searching.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16369v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16369/ASR_step_Vicuna_both.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16369v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16369/max_ASR_vs_alpha_Llama.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16369v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16369/max_ASR_vs_alpha_Vicuna.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16369v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16369/AUROC.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16369v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16369/max_ASR_vs_alpha_Llama_eval_ensemble.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16369v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16369/max_ASR_vs_alpha_Vicuna_eval_ensemble.png"
      }
    ],
    "abstract_cn": "保障大型语言模型（LLMs）的安全对齐是生成符合人类价值观响应的关键。尽管LLMs能够识别并规避有害查询，但它们仍易受到“越狱”攻击，这类攻击通过精心构造的提示诱使模型生成有害内容。其中一种越狱攻击手法是将任务转化为对抗性攻击，诱使LLMs给出肯定回答。然而，这类攻击中的典型手段——GCG攻击——成功率并不高。本研究为了深入探究越狱攻击，提出了DSN（不要说不）攻击，它不仅诱导LLMs生成肯定回答，还创新性地增加了抑制拒绝的目标。此外，越狱攻击的评估工作同样充满挑战，因为直接且精确地评估攻击的危害性极为困难。现有的评估方法，例如拒绝关键词匹配，存在局限性，因为它会产生大量误报和漏报。为了应对这一挑战，我们设计了一个集成评估流程，包括自然语言推理（NLI）矛盾评估和两个外部LLM评估器。广泛的实验证明了DSN攻击的威力以及集成评估方法相比传统基线方法的有效性。",
    "title_cn": "别拒绝：抑制拒绝行为以解锁大型语言模型的潜力。",
    "tags": [
      "LLM应用",
      "人工智能安全",
      ""
    ]
  },
  {
    "title": "Training-Free Unsupervised Prompt for Vision-Language Models",
    "submit_datetime": "2024年04月25日",
    "abstract": "Prompt learning has become the most effective paradigm for adapting large pre-trained vision-language models (VLMs) to downstream tasks. Recently, unsupervised prompt tuning methods, such as UPL and POUF, directly leverage pseudo-labels as supervisory information to fine-tune additional adaptation modules on unlabeled data. However, inaccurate pseudo labels easily misguide the tuning process and result in poor representation capabilities. In light of this, we propose Training-Free Unsupervised Prompts (TFUP), which maximally preserves the inherent representation capabilities and enhances them with a residual connection to similarity-based prediction probabilities in a training-free and labeling-free manner. Specifically, we integrate both instance confidence and prototype scores to select representative samples, which are used to customize a reliable Feature Cache Model (FCM) for training-free inference. Then, we design a Multi-level Similarity Measure (MSM) that considers both feature-level and semantic-level similarities to calculate the distance between each test image and the cached sample as the weight of the corresponding cached label to generate similarity-based prediction probabilities. In this way, TFUP achieves surprising performance, even surpassing the training-base method on multiple classification datasets. Based on our TFUP, we propose a training-based approach (TFUP-T) to further boost the adaptation performance. In addition to the standard cross-entropy loss, TFUP-T adopts an additional marginal distribution entropy loss to constrain the model from a global perspective. Our TFUP-T achieves new state-of-the-art classification performance compared to unsupervised and few-shot adaptation approaches on multiple benchmarks. In particular, TFUP-T improves the classification accuracy of POUF by 3.3% on the most challenging Domain-Net dataset.",
    "pdf_link": "https://arxiv.org/abs/2404.16339",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.16339v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16339/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16339v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16339/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16339v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16339/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16339v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16339/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16339v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16339/x5.png"
      }
    ],
    "abstract_cn": "提示学习已经发展成为调整大型预训练视觉-语言模型以适应下游任务的最有效方法。最近，像UPL和POUF这样的无监督提示调整技术，通过伪标签提供监督信息，直接对未标记数据进行微调。但是，伪标签的不准确性往往会误导微调过程，影响模型的表示能力。为此，我们提出了一种无需训练的无监督提示方法（TFUP），它在无需训练和标注的情况下，最大限度地保持并增强了模型的固有表示能力，通过残差连接与基于相似性的预测概率相结合。具体而言，我们融合了实例置信度和原型分数来挑选具有代表性的样本，并利用这些样本定制了一个可靠的特征缓存模型（FCM），以便进行无需训练的推理。此外，我们构建了一个多级相似性度量（MSM），它同时考虑了特征层面和语义层面的相似性，以计算测试图像与缓存样本之间的距离，并将此距离作为相应缓存标签权重，用以生成基于相似性的预测概率。这种方法使得TFUP在多个分类数据集上取得了惊人的成绩，甚至超过了基于训练的方法。基于TFUP，我们还提出了一种基于训练的方法（TFUP-T），以进一步提升模型的适应性能。TFUP-T不仅采用了标准的交叉熵损失，还引入了边际分布熵损失，从宏观角度对模型进行约束。在多个基准测试中，TFUP-T与无监督和少样本适应方法相比，展现出了新的最高水平的分类性能。特别是在最具挑战性的Domain-Net数据集上，TFUP-T将POUF的分类准确率提升了3.3%。",
    "title_cn": "免训练的无监督提示技术，为视觉-语言模型注入新动力。",
    "tags": [
      "LLM应用",
      "计算机视觉",
      "机器学习"
    ]
  },
  {
    "title": "AI Coders Are Among Us: Rethinking Programming Language Grammar Towards Efficient Code Generation",
    "submit_datetime": "2024年04月25日",
    "abstract": "Besides humans and machines, Artificial Intelligence (AI) models have emerged to be another important audience of programming languages, as we come to the era of large language models (LLMs). LLMs can now excel at coding competitions and even program like developers to address various tasks, such as math calculation. Yet, the grammar and layout of existing programs are designed for humans. Particularly, abundant grammar tokens and formatting tokens are included to make the code more readable to humans. While beneficial, such a human-centric design imposes an unnecessary computational burden on LLMs where each token, either consumed or generated, consumes computational resources. To improve inference efficiency and reduce computational costs, we propose the concept of AI-oriented grammar, which aims to represent the code in a way that better suits the working mechanism of AI models. Code written with AI-oriented grammar discards formats and uses a minimum number of tokens to convey code semantics effectively. To demonstrate the feasibility of this concept, we explore and implement the first AI-oriented grammar for Python, named Simple Python (SimPy). SimPy is crafted by revising the original Python grammar through a series of heuristic rules. Programs written in SimPy maintain identical Abstract Syntax Tree (AST) structures to those in standard Python, allowing execution via a modified AST parser. In addition, we explore methods to enable existing LLMs to proficiently understand and use SimPy, and ensure the changes remain imperceptible for human developers. Compared with the original Python, SimPy not only reduces token usage by 13.5% and 10.4% for CodeLlama and GPT-4, but can also achieve equivalent, even improved, performance over the models trained on Python code.",
    "pdf_link": "https://arxiv.org/abs/2404.16333",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.16333v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16333/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16333v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16333/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16333v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16333/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16333v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16333/x4.png"
      }
    ],
    "abstract_cn": "随着大型语言模型（LLM）时代的到来，人工智能（AI）模型已成为编程语言的新兴重要受众。如今，LLM不仅在编程竞赛中大放异彩，还能像专业开发者一样编写代码，处理包括数学计算在内的多种任务。但现有的程序设计以人为中心，包含了大量提高代码可读性的语法和格式标记，这给LLM带来了额外的计算负担。为了提升推理效率和降低成本，我们提出了一种面向AI的语法概念，旨在以更适合AI模型工作方式的形式来表示代码。采用这种语法的代码去除了不必要的格式，以最精简的标记数量有效传递代码含义。为了验证这一概念，我们探索并实现了首个面向AI的Python语法——Simple Python（SimPy）。SimPy通过一系列启发式规则对传统Python语法进行了优化，保持了与标准Python相同的抽象语法树（AST）结构，并通过改进的AST解析器执行。我们还研究了如何使现有的LLM熟练掌握并使用SimPy，同时确保这些改变对人类开发者无影响。相较于传统Python，SimPy在CodeLlama和GPT-4上的标记使用量分别减少了13.5%和10.4%，并且能够在训练有素的Python代码模型上达到甚至超越原有性能。",
    "title_cn": "AI 程序员悄然崛起：探索编程语言的语法革新，以提升代码生成的效率。",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "RAGCache: Efficient Knowledge Caching for Retrieval-Augmented Generation",
    "submit_datetime": "2024年04月25日",
    "abstract": "Retrieval-Augmented Generation (RAG) has shown significant improvements in various natural language processing tasks by integrating the strengths of large language models (LLMs) and external knowledge databases. However, RAG introduces long sequence generation and leads to high computation and memory costs. We propose RAGCache, a novel multilevel dynamic caching system tailored for RAG. Our analysis benchmarks current RAG systems, pinpointing the performance bottleneck (i.e., long sequence due to knowledge injection) and optimization opportunities (i.e., caching knowledge's intermediate states). Based on these insights, we design RAGCache, which organizes the intermediate states of retrieved knowledge in a knowledge tree and caches them in the GPU and host memory hierarchy. RAGCache proposes a replacement policy that is aware of LLM inference characteristics and RAG retrieval patterns. It also dynamically overlaps the retrieval and inference steps to minimize the end-to-end latency. We implement RAGCache and evaluate it on vLLM, a state-of-the-art LLM inference system and Faiss, a state-of-the-art vector database. The experimental results show that RAGCache reduces the time to first token (TTFT) by up to 4x and improves the throughput by up to 2.1x compared to vLLM integrated with Faiss.",
    "pdf_link": "https://arxiv.org/abs/2404.12457",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.12457v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12457/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12457v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12457/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12457v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12457/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12457v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12457/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12457v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12457/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12457v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12457/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12457v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12457/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12457v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12457/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12457v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12457/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12457v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12457/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12457v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12457/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12457v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12457/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12457v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12457/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12457v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12457/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12457v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12457/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12457v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12457/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12457v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12457/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12457v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12457/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12457v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12457/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12457v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12457/x20.png"
      }
    ],
    "abstract_cn": "检索增强生成（RAG）融合了大型语言模型（LLM）与外部知识库的优势，在自然语言处理任务上取得了显著进步。但这种方法也带来了长序列生成的问题，增加了计算和内存的开销。为此，我们设计了RAGCache，这是一个创新的多层次动态缓存系统，专为优化RAG性能而开发。通过对现有RAG系统的深入分析，我们识别出了影响性能的关键瓶颈——知识注入导致的序列过长，以及潜在的优化点——缓存知识的中间状态。RAGCache通过知识树结构来组织和管理检索到的知识的中间状态，并在GPU和主机内存中进行缓存。它还引入了一种智能替换策略，能够根据LLM的推理特性和RAG的检索模式进行调整。此外，RAGCache能够动态地并行处理检索和推理过程，有效减少了整体的延迟。我们在顶尖的LLM推理系统vLLM和向量数据库Faiss上部署并测试了RAGCache，实验数据显示，其将首次令牌生成时间缩短了至多4倍，吞吐量提升了高达2.1倍。",
    "title_cn": "RAGCache：一种高效的知识缓存机制，专为检索增强生成而设计。",
    "tags": [
      "分类：RAG",
      "",
      "缓存系统"
    ]
  },
  {
    "title": "OneChart: Purify the Chart Structural Extraction via One Auxiliary Token",
    "submit_datetime": "2024年04月25日",
    "abstract": "Chart parsing poses a significant challenge due to the diversity of styles, values, texts, and so forth. Even advanced large vision-language models (LVLMs) with billions of parameters struggle to handle such tasks satisfactorily. To address this, we propose OneChart: a reliable agent specifically devised for the structural extraction of chart information. Similar to popular LVLMs, OneChart incorporates an autoregressive main body. Uniquely, to enhance the reliability of the numerical parts of the output, we introduce an auxiliary token placed at the beginning of the total tokens along with an additional decoder. The numerically optimized (auxiliary) token allows subsequent tokens for chart parsing to capture enhanced numerical features through causal attention. Furthermore, with the aid of the auxiliary token, we have devised a self-evaluation mechanism that enables the model to gauge the reliability of its chart parsing results by providing confidence scores for the generated content. Compared to current state-of-the-art (SOTA) chart parsing models, e.g., DePlot, ChartVLM, ChartAst, OneChart significantly outperforms in Average Precision (AP) for chart structural extraction across multiple public benchmarks, despite enjoying only 0.2 billion parameters. Moreover, as a chart parsing agent, it also brings 10%+ accuracy gains for the popular LVLM (LLaVA-1.6) in the downstream ChartQA benchmark.",
    "pdf_link": "https://arxiv.org/abs/2404.09987",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.09987v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09987/chart_6_v2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09987v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09987/chart_3_v3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09987v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09987/chart_2_v5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09987v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09987/chart-infer2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09987v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09987/append1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09987v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09987/append2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09987v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09987/append4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09987v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09987/append3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09987v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09987/chart_qa_all.png"
      }
    ],
    "abstract_cn": "图表解析因风格迥异、数值多样、文本繁杂等因素而充满挑战，即便是参数众多的先进视觉-语言大型模型（LVLMs）也常感力不从心。为此，我们设计了OneChart：一款专为图表信息的结构化抽取而打造的可信代理。OneChart沿用了主流LVLMs的自回归主体架构，并创新性地在总令牌序列的起始位置引入辅助令牌及附加解码器，以提升输出中数值部分的准确性。这一数值优化的辅助令牌，使得后续令牌在解析图表时能够通过因果注意力机制捕捉更为精细的数值特征。我们还引入了一种自我评估机制，使模型能够通过生成内容的置信度评分来评估其图表解析的可靠性。在与当前顶尖的图表解析模型如DePlot、ChartVLM、ChartAst等的比较中，OneChart在多个公共基准测试中的平均精度（AP）上取得了显著的领先优势，尽管其参数量仅20亿。此外，作为图表解析代理，OneChart还显著提升了流行LVLM（如LLaVA-1.6）在ChartQA基准测试中的准确率，增幅超过10%。",
    "title_cn": "OneChart：引入单一辅助标记，精炼图表结构的提取过程",
    "tags": [
      "Agent",
      "图表解析",
      ""
    ]
  },
  {
    "title": "What Makes Multimodal In-Context Learning Work?",
    "submit_datetime": "2024年04月25日",
    "abstract": "Large Language Models have demonstrated remarkable performance across various tasks, exhibiting the capacity to swiftly acquire new skills, such as through In-Context Learning (ICL) with minimal demonstration examples. In this work, we present a comprehensive framework for investigating Multimodal ICL (M-ICL) in the context of Large Multimodal Models. We consider the best open-source multimodal models (e.g., IDEFICS, OpenFlamingo) and a wide range of multimodal tasks. Our study unveils several noteworthy findings: (1) M-ICL primarily relies on text-driven mechanisms, showing little to no influence from the image modality. (2) When used with advanced-ICL strategy (like RICES), M-ICL is not better than a simple strategy based on majority voting over context examples. Moreover, we identify several biases and limitations of M-ICL that warrant consideration prior to deployment. Code available at https://gitlab.com/folbaeni/multimodal-icl",
    "pdf_link": "https://arxiv.org/abs/2404.15736",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.15736v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15736/image.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15736v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15736/remove_image_radar.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15736v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15736/remove_modality_normalized_full.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15736v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15736/remove_question_radar.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15736v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15736/ngrams.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15736v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15736/rices_diff_bar.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15736v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15736/rices_no_modality_radar_image.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15736v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15736/rices_vqa_bar.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15736v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15736/rices_oracle_radar.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15736v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15736/coco_similarity_rouge.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15736v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15736/similarity_vqa_final.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15736v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15736/coco_vqa_repetition_avanced.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15736v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15736/remove_modality_full.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15736v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15736/rices_key_full.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15736v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15736/rices_reverse_full.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15736v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15736/rices_no_image_full.png"
      }
    ],
    "abstract_cn": "大型语言模型在多样化任务上展现了非凡的能力，能够通过极少量的示例迅速掌握新技能，这主要得益于上下文学习（ICL）。本研究构建了一个深入的框架，旨在探讨大型多模态模型中的多模态ICL（M-ICL）。我们评估了顶尖的开源多模态模型（如IDEFICS、OpenFlamingo）在一系列多模态任务上的表现。研究发现，M-ICL主要依赖文本驱动机制，图像模态的影响微乎其微。此外，采用高级ICL策略（例如RICES）时，M-ICL的性能并不超越简单的多数投票策略。我们还指出了M-ICL存在的一些偏见和限制，这些在实际应用前需要被充分考虑。相关代码已在 https://gitlab.com/folbaeni/multimodal-icl 上公开。",
    "title_cn": "多模态上下文内学习为何有效？",
    "tags": [
      "LLM应用",
      "多模态学习",
      "人工智能"
    ]
  },
  {
    "title": "Small Language Models Need Strong Verifiers to Self-Correct Reasoning",
    "submit_datetime": "2024年04月25日",
    "abstract": "Self-correction has emerged as a promising solution to boost the reasoning performance of large language models (LLMs), where LLMs refine their solutions using self-generated critiques that pinpoint the errors. This work explores whether smaller-size (<= 13B) language models (LMs) have the ability of self-correction on reasoning tasks with minimal inputs from stronger LMs. We propose a novel pipeline that prompts smaller LMs to collect self-correction data that supports the training of self-refinement abilities. First, we leverage correct solutions to guide the model in critiquing their incorrect responses. Second, the generated critiques, after filtering, are used for supervised fine-tuning of the self-correcting reasoner through solution refinement. Our experimental results show improved self-correction abilities of two models on five datasets spanning math and commonsense reasoning, with notable performance gains when paired with a strong GPT-4-based verifier, though limitations are identified when using a weak self-verifier for determining when to correct.",
    "pdf_link": "https://arxiv.org/abs/2404.17140",
    "graphs": [],
    "abstract_cn": "自我纠错技术正成为提升大型语言模型推理能力的有效途径，它通过自我批评来精确识别并修正错误。本研究旨在探究小型语言模型（规模不超过13B）在几乎不依赖更大型语言模型输入的情况下，是否具备在推理任务上的自我纠错功能。我们设计了一种创新的流程，激励这些小型模型收集自我纠错数据，以培养其自我完善的能力。首先，我们使用正确答案引导模型自我批评错误回答；其次，经过筛选的批评意见被用于对自我纠错推理器进行有监督的微调，以细化解决方案。实验结果表明，在涵盖数学和常识推理的五个数据集中，两种模型的自我纠错能力均有所增强，尤其是在与基于GPT-4的强大验证器结合使用时，性能提升尤为明显。然而，当使用较弱的自我验证器来决定何时进行纠错时，也暴露出了一些限制。",
    "title_cn": "为了自我修正推理过程，小型语言模型亟需配备强有力的验证机制。",
    "tags": [
      "分类：LLM应用\n\n这篇论文主要探讨了如何提升小型语言模型在推理任务上的自我纠错功能，通过设计一种创新的流程来培养模型的自我完善能力。这属于LLM应用的范畴，因为它涉及到如何更有效地利用现有的语言模型来提高其性能。",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Automated Data Visualization from Natural Language via Large Language Models: An Exploratory Study",
    "submit_datetime": "2024年04月25日",
    "abstract": "The Natural Language to Visualization (NL2Vis) task aims to transform natural-language descriptions into visual representations for a grounded table, enabling users to gain insights from vast amounts of data. Recently, many deep learning-based approaches have been developed for NL2Vis. Despite the considerable efforts made by these approaches, challenges persist in visualizing data sourced from unseen databases or spanning multiple tables. Taking inspiration from the remarkable generation capabilities of Large Language Models (LLMs), this paper conducts an empirical study to evaluate their potential in generating visualizations, and explore the effectiveness of in-context learning prompts for enhancing this task. In particular, we first explore the ways of transforming structured tabular data into sequential text prompts, as to feed them into LLMs and analyze which table content contributes most to the NL2Vis. Our findings suggest that transforming structured tabular data into programs is effective, and it is essential to consider the table schema when formulating prompts. Furthermore, we evaluate two types of LLMs: finetuned models (e.g., T5-Small) and inference-only models (e.g., GPT-3.5), against state-of-the-art methods, using the NL2Vis benchmarks (i.e., nvBench). The experimental results reveal that LLMs outperform baselines, with inference-only models consistently exhibiting performance improvements, at times even surpassing fine-tuned models when provided with certain few-shot demonstrations through in-context learning. Finally, we analyze when the LLMs fail in NL2Vis, and propose to iteratively update the results using strategies such as chain-of-thought, role-playing, and code-interpreter. The experimental results confirm the efficacy of iterative updates and hold great potential for future study.",
    "pdf_link": "https://arxiv.org/abs/2404.17136",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.17136v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17136/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17136v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17136/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17136v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17136/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17136v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17136/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17136v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17136/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17136v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17136/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17136v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17136/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17136v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17136/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17136v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17136/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17136v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17136/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17136v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17136/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17136v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17136/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17136v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17136/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17136v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17136/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17136v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17136/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17136v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17136/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17136v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17136/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17136v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17136/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17136v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17136/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17136v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17136/x20.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17136v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17136/x21.png"
      }
    ],
    "abstract_cn": "自然语言到可视化（NL2Vis）任务致力于将自然语言描述转换成可视化的表格数据，以便用户能从海量数据中洞察信息。尽管基于深度学习的多种方法已应运而生，但在将未见数据库或跨多表的数据可视化时，仍面临挑战。本文借鉴大型语言模型（LLMs）的卓越生成能力，通过实证研究来评估其在创建可视化方面的能力，并探讨使用上下文学习提示来提升任务效果的可能性。我们首先研究了如何将结构化表格数据转化为连续文本提示，以便输入LLMs，并分析了哪些表格内容对NL2Vis最为关键。研究结果显示，将表格数据转化为程序文本是有效的，同时在构建提示时考虑表格结构是必要的。我们还对比了两种LLMs：经过微调的模型（如T5-Small）和仅限推理的模型（如GPT-3.5），并与现有最先进方法进行了比较。实验结果显示，LLMs在性能上超越了基线，尤其是仅限推理模型在上下文学习中通过少量示例的引导，有时甚至能超越微调模型。最后，我们深入分析了LLMs在NL2Vis中的不足，并提出了通过链式思考、角色扮演和代码解释等策略来迭代优化结果。实验结果证明了迭代更新策略的有效性，并为未来的研究开辟了新的可能性。",
    "title_cn": "本研究探索了利用大型语言模型将自然语言自动转换为数据可视化的过程。",
    "tags": [
      "LLM应用",
      "数据可视化",
      ""
    ]
  },
  {
    "title": "2M-NER: Contrastive Learning for Multilingual and Multimodal NER with Language and Modal Fusion",
    "submit_datetime": "2024年04月25日",
    "abstract": "Named entity recognition (NER) is a fundamental task in natural language processing that involves identifying and classifying entities in sentences into pre-defined types. It plays a crucial role in various research fields, including entity linking, question answering, and online product recommendation. Recent studies have shown that incorporating multilingual and multimodal datasets can enhance the effectiveness of NER. This is due to language transfer learning and the presence of shared implicit features across different modalities. However, the lack of a dataset that combines multilingualism and multimodality has hindered research exploring the combination of these two aspects, as multimodality can help NER in multiple languages simultaneously. In this paper, we aim to address a more challenging task: multilingual and multimodal named entity recognition (MMNER), considering its potential value and influence. Specifically, we construct a large-scale MMNER dataset with four languages (English, French, German and Spanish) and two modalities (text and image). To tackle this challenging MMNER task on the dataset, we introduce a new model called 2M-NER, which aligns the text and image representations using contrastive learning and integrates a multimodal collaboration module to effectively depict the interactions between the two modalities. Extensive experimental results demonstrate that our model achieves the highest F1 score in multilingual and multimodal NER tasks compared to some comparative and representative baselines. Additionally, in a challenging analysis, we discovered that sentence-level alignment interferes a lot with NER models, indicating the higher level of difficulty in our dataset.",
    "pdf_link": "https://arxiv.org/abs/2404.17122",
    "graphs": [],
    "abstract_cn": "命名实体识别（NER）是自然语言处理领域的基石，其核心在于识别并归类句子中的实体。它对于实体链接、问答系统和在线商品推荐等多个研究领域至关重要。最新研究揭示，融合多语言和多模态数据集能够显著提升NER的性能，这归功于语言迁移学习以及不同模态间共有的隐含特征。然而，由于缺少一个同时包含多语言和多模态特性的数据集，限制了对这两个要素结合的研究。本文旨在攻克更具挑战性的多语言多模态命名实体识别（MMNER）任务，探讨其潜在的研究价值和影响力。我们构建了一个包含四种语言（英、法、德、西）和两种模态（文本和图像）的大规模MMNER数据集。为解决这一挑战，我们提出了一个创新模型——2M-NER，该模型采用对比学习方法对齐文本与图像表示，并集成了一个多模态协作模块，以有效捕捉两种模态间的交互作用。广泛的实验结果显示，2M-NER在多语言多模态NER任务中取得了最高的F1分数，超越了其他基准模型。此外，我们通过深入分析发现，句子级别的对齐对NER模型构成了较大干扰，反映出我们数据集的高难度特性。",
    "title_cn": "2M-NER：一种采用对比学习方法，针对多语言和多模态命名实体识别任务，实现语言与模态融合的技术。",
    "tags": [
      "Agent",
      "",
      "多模态学习"
    ]
  },
  {
    "title": "Talking Nonsense: Probing Large Language Models' Understanding of Adversarial Gibberish Inputs",
    "submit_datetime": "2024年04月25日",
    "abstract": "Large language models (LLMs) exhibit excellent ability to understand human languages, but do they also understand their own language that appears gibberish to us? In this work we delve into this question, aiming to uncover the mechanisms underlying such behavior in LLMs. We employ the Greedy Coordinate Gradient optimizer to craft prompts that compel LLMs to generate coherent responses from seemingly nonsensical inputs. We call these inputs LM Babel and this work systematically studies the behavior of LLMs manipulated by these prompts. We find that the manipulation efficiency depends on the target text's length and perplexity, with the Babel prompts often located in lower loss minima compared to natural prompts. We further examine the structure of the Babel prompts and evaluate their robustness. Notably, we find that guiding the model to generate harmful texts is not more difficult than into generating benign texts, suggesting lack of alignment for out-of-distribution prompts.",
    "pdf_link": "https://arxiv.org/abs/2404.17120",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.17120v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17120/diagram.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17120v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17120/length.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17120v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17120/perplexity.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17120v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17120/umap.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17120v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17120/intersecting_tokens.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17120v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17120/vicuna_word_frequency.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17120v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17120/robustness.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17120v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17120/umap_llama13b.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17120v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17120/umap_vicuna.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17120v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17120/umap_vicuna13b.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17120v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17120/robustness13b.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17120v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17120/llama_word_frequency.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17120v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17120/llama13b_word_frequency.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17120v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17120/vicuna13_word_frequency.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17120v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17120/umap_autoprompt.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17120v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17120/similarity_hist_llama.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17120v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17120/similarity_hist_vicuna.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）在理解人类语言方面表现出色，但它们是否能理解那些对我们而言毫无意义的自身语言呢？本研究旨在探究这一谜题，揭示LLMs这种行为背后的原理。我们利用贪心坐标梯度优化器精心构造提示，激发LLMs从看似荒谬的输入中产出有意义的回答。我们将这类输入命名为“语言模型巴别塔”（LM Babel），并系统性地分析了LLMs在这些提示操控下的行为模式。研究发现，操控的效率与目标文本的长度和困惑度密切相关，巴别塔提示往往处于比自然提示更低的损失最小值区域。我们还深入分析了巴别塔提示的结构，并对其鲁棒性进行了评估。尤为引人注意的是，我们发现引导模型产出有害文本的难度并不大于产出良性文本，这暗示了对于非典型提示，模型的对齐度存在缺失。",
    "title_cn": "探究谬误：深入理解大型语言模型如何处理对抗性的无意义输入",
    "tags": [
      "分类：LLM理论",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Software Vulnerability Prediction in Low-Resource Languages: An Empirical Study of CodeBERT and ChatGPT",
    "submit_datetime": "2024年04月25日",
    "abstract": "Background: Software Vulnerability (SV) prediction in emerging languages is increasingly important to ensure software security in modern systems. However, these languages usually have limited SV data for developing high-performing prediction models. Aims: We conduct an empirical study to evaluate the impact of SV data scarcity in emerging languages on the state-of-the-art SV prediction model and investigate potential solutions to enhance the performance. Method: We train and test the state-of-the-art model based on CodeBERT with and without data sampling techniques for function-level and line-level SV prediction in three low-resource languages - Kotlin, Swift, and Rust. We also assess the effectiveness of ChatGPT for low-resource SV prediction given its recent success in other domains. Results: Compared to the original work in C/C++ with large data, CodeBERT's performance of function-level and line-level SV prediction significantly declines in low-resource languages, signifying the negative impact of data scarcity. Regarding remediation, data sampling techniques fail to improve CodeBERT; whereas, ChatGPT showcases promising results, substantially enhancing predictive performance by up to 34.4% for the function level and up to 53.5% for the line level. Conclusion: We have highlighted the challenge and made the first promising step for low-resource SV prediction, paving the way for future research in this direction.",
    "pdf_link": "https://arxiv.org/abs/2404.17110",
    "graphs": [],
    "abstract_cn": "研究背景：随着软件安全的重要性日益凸显，对新兴编程语言中的软件漏洞预测变得尤为关键。但这些新语言往往缺乏足够的漏洞数据，制约了高效预测模型的开发。研究目的：本研究旨在实证评估新兴语言中漏洞数据不足对顶尖漏洞预测模型的影响，并探索提升模型性能的可能方法。研究方法：我们选取了Kotlin、Swift和Rust三种资源稀缺语言，采用CodeBERT模型进行了函数级和代码行级的漏洞预测训练与测试，同时对比了有无数据采样技术的应用效果。此外，我们还检验了ChatGPT在低资源漏洞预测中的潜力，考虑到其在其他领域的显著成效。研究结果：与C/C++等资源丰富语言相比，CodeBERT在资源稀缺语言中的预测性能大幅下降，凸显了数据不足的挑战。尽管数据采样技术未能有效提升CodeBERT的性能，但ChatGPT却展现出显著的潜力，将预测准确率提升了34.4%（函数级）和53.5%（代码行级）。研究结论：本研究不仅揭示了低资源语言漏洞预测的难题，也为未来的研究方向指明了有希望的第一步。",
    "title_cn": "面向低资源语言的软件漏洞预测：CodeBERT 与 ChatGPT 的实证比较研究",
    "tags": [
      "分类：LLM应用\n\n这篇论文主要探讨了在新兴编程语言中，由于漏洞数据不足，如何利用大型语言模型（如CodeBERT和ChatGPT）来提高漏洞预测的性能。这属于LLM应用的范畴，因为它直接将大型语言模型应用于解决实际问题，即软件安全中的漏洞预测。",
      "软件安全",
      "编程语言"
    ]
  },
  {
    "title": "Open-Set Video-based Facial Expression Recognition with Human Expression-sensitive Prompting",
    "submit_datetime": "2024年04月25日",
    "abstract": "In Video-based Facial Expression Recognition (V-FER), models are typically trained on closed-set datasets with a fixed number of known classes. However, these V-FER models cannot deal with unknown classes that are prevalent in real-world scenarios. In this paper, we introduce a challenging Open-set Video-based Facial Expression Recognition (OV-FER) task, aiming at identifying not only known classes but also new, unknown human facial expressions not encountered during training. While existing approaches address open-set recognition by leveraging large-scale vision-language models like CLIP to identify unseen classes, we argue that these methods may not adequately capture the nuanced and subtle human expression patterns required by the OV-FER task. To address this limitation, we propose a novel Human Expression-Sensitive Prompting (HESP) mechanism to significantly enhance CLIP's ability to model video-based facial expression details effectively, thereby presenting a new CLIP-based OV-FER approach. Our proposed HESP comprises three components: 1) a textual prompting module with learnable prompt representations to complement the original CLIP textual prompts and enhance the textual representations of both known and unknown emotions, 2) a visual prompting module that encodes temporal emotional information from video frames using expression-sensitive attention, equipping CLIP with a new visual modeling ability to extract emotion-rich information, 3) a delicately designed open-set multi-task learning scheme that facilitates prompt learning and encourages interactions between the textual and visual prompting modules. Extensive experiments conducted on four OV-FER task settings demonstrate that HESP can significantly boost CLIP's performance (a relative improvement of 17.93% on AUROC and 106.18% on OSCR) and outperform other state-of-the-art open-set video understanding methods by a large margin.",
    "pdf_link": "https://arxiv.org/abs/2404.17100",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.17100v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17100/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17100v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17100/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17100v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17100/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17100v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17100/predict_result.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17100v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17100/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17100v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17100/x5.png"
      }
    ],
    "abstract_cn": "在视频驱动的面部表情识别（V-FER）领域，模型多在有限类别的封闭数据集上训练，却难以应对现实世界中常见的未知类别。本文提出了一项前沿的开放集视频面部表情识别（OV-FER）任务，目标是识别出训练时未见过的新兴及未知的人脸表情。尽管现有技术借助如CLIP这样的大规模视觉-语言模型来识别新类别，但这些方法在捕捉OV-FER任务所需的精细人类表情模式方面仍有不足。为克服此局限，我们设计了创新的人类表情敏感提示（HESP）机制，显著提升了CLIP对视频面部表情细节的建模能力，进而推出了一种创新的基于CLIP的OV-FER解决方案。HESP机制包含三个关键部分：首先，文本提示模块通过可学习的提示表示来强化原有CLIP的文本提示，提升已知与未知情感的文本表达；其次，视觉提示模块利用表情敏感的注意力机制从视频帧中编码时间序列情感信息，赋予CLIP更强大的视觉建模能力；最后，一个精巧设计的开放集多任务学习框架，促进了提示学习并加强了文本与视觉模块间的互动。在四项OV-FER任务设置上的广泛实验证明，HESP显著提升了CLIP的性能（AUROC提升17.93%，OSCR提升106.18%），并在其他尖端开放集视频理解方法中脱颖而出。",
    "title_cn": "视频驱动的开放集人脸识别技术，引入了对人类表情变化敏感的提示机制。",
    "tags": [
      "分类：Agent\n\n这篇论文提出了一个创新的解决方案，通过设计人类表情敏感提示（HESP）机制来提高大规模视觉-语言模型CLIP在视频驱动的面部表情识别（V-FER）任务中的性能。这个解决方案包括文本提示模块、视觉提示模块和一个开放集多任务学习框架，这些组件共同工作以提高对视频面部表情细节的建模能力。由于这个研究涉及到设计和实现一个智能代理（即HESP机制），以提高模型在特定任务上的性能，因此这篇论文可以归类为Agent。",
      "面部识别",
      "情感识别"
    ]
  },
  {
    "title": "CyNetDiff -- A Python Library for Accelerated Implementation of Network Diffusion Models",
    "submit_datetime": "2024年04月25日",
    "abstract": "In recent years, there has been increasing interest in network diffusion models and related problems. The most popular of these are the independent cascade and linear threshold models. Much of the recent experimental work done on these models requires a large number of simulations conducted on large graphs, a computationally expensive task suited for low-level languages. However, many researchers prefer the use of higher-level languages (such as Python) for their flexibility and shorter development times. Moreover, in many research tasks, these simulations are the most computationally intensive task, so it would be desirable to have a library for these with an interface to a high-level language with the performance of a low-level language. To fill this niche, we introduce CyNetDiff, a Python library with components written in Cython to provide improved performance for these computationally intensive diffusion tasks.",
    "pdf_link": "https://arxiv.org/abs/2404.17059",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.17059v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17059/simple_benchmark_screenshot.jpg"
      },
      {
        "url": "https://arxiv.org/html/2404.17059v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17059/simple_benchmark_screenshot_real.jpg"
      },
      {
        "url": "https://arxiv.org/html/2404.17059v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17059/x1.png"
      }
    ],
    "abstract_cn": "近年来，网络扩散模型及其相关议题日益受到广泛关注，尤其是独立级联和线性阈值模型。当前的实验研究往往需要在大型图集上进行大量的模拟，这一过程计算成本高昂，更适合使用低级语言。尽管如此，研究者们更倾向于使用高级语言如 Python，以享受其带来的灵活性和快速开发的优势。在众多研究任务中，模拟过程往往是最为消耗计算资源的环节，因此，能够提供一个既兼容高级语言接口又具备低级语言性能的库将大有裨益。正是为了满足这一需求，我们推出了 CyNetDiff——一个用 Cython 编写关键组件的 Python 库，旨在为这些计算密集型的扩散任务提供性能上的显著提升。",
    "title_cn": "CyNetDiff —— 一款旨在提高网络扩散模型实现效率的 Python 编程库。",
    "tags": [
      "分类：RAG",
      "网络科学",
      ""
    ]
  },
  {
    "title": "Near to Mid-term Risks and Opportunities of Open Source Generative AI",
    "submit_datetime": "2024年04月25日",
    "abstract": "In the next few years, applications of Generative AI are expected to revolutionize a number of different areas, ranging from science & medicine to education. The potential for these seismic changes has triggered a lively debate about potential risks and resulted in calls for tighter regulation, in particular from some of the major tech companies who are leading in AI development. This regulation is likely to put at risk the budding field of open source Generative AI. We argue for the responsible open sourcing of generative AI models in the near and medium term. To set the stage, we first introduce an AI openness taxonomy system and apply it to 40 current large language models. We then outline differential benefits and risks of open versus closed source AI and present potential risk mitigation, ranging from best practices to calls for technical and scientific contributions. We hope that this report will add a much needed missing voice to the current public discourse on near to mid-term AI safety and other societal impact.",
    "pdf_link": "https://arxiv.org/abs/2404.17047",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.17047v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17047/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17047v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17047/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17047v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17047/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17047v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17047/x4.png"
      }
    ],
    "abstract_cn": "未来数年，生成性AI的应用有望在科学、医学、教育等多个领域引发变革。这些可能的变革激起了对潜在风险的广泛讨论，并促使一些在AI领域领先的大型科技公司呼吁加强监管。这种监管可能会对开源生成性AI的萌芽领域构成威胁。我们提倡在短期内以负责任的态度开放生成性AI模型的源代码。为此，我们首先提出了一个AI开放性分类体系，并将其应用于40种现行的大型语言模型。接着，我们分析了开源与闭源AI的利弊，并提出了风险缓解策略，从最佳实践到技术与科学贡献的呼吁。我们期望这份报告能为当前关于AI安全与社会影响的公共讨论贡献一个迫切需要的声音。",
    "title_cn": "开源生成式AI的近期至中期风险与机遇探讨",
    "tags": [
      "LLM应用",
      "AI安全",
      "开源软件"
    ]
  },
  {
    "title": "Player-Driven Emergence in LLM-Driven Game Narrative",
    "submit_datetime": "2024年04月25日",
    "abstract": "We explore how interaction with large language models (LLMs) can give rise to emergent behaviors, empowering players to participate in the evolution of game narratives. Our testbed is a text-adventure game in which players attempt to solve a mystery under a fixed narrative premise, but can freely interact with non-player characters generated by GPT-4, a large language model. We recruit 28 gamers to play the game and use GPT-4 to automatically convert the game logs into a node-graph representing the narrative in the player's gameplay. We find that through their interactions with the non-deterministic behavior of the LLM, players are able to discover interesting new emergent nodes that were not a part of the original narrative but have potential for being fun and engaging. Players that created the most emergent nodes tended to be those that often enjoy games that facilitate discovery, exploration and experimentation.",
    "pdf_link": "https://arxiv.org/abs/2404.17027",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.17027v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17027/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17027v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17027/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17027v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17027/narrative-emergence.png"
      }
    ],
    "abstract_cn": "本研究深入探讨了与大型语言模型（LLM）互动如何催生新行为，让玩家在游戏叙事的演进中扮演角色。实验平台是一个文本冒险游戏，玩家需在既定叙事框架下解开谜题，同时能与GPT-4生成的非玩家角色自由互动。我们邀请了28位玩家参与游戏，利用GPT-4将游戏记录自动转化为节点图，以此映射玩家游戏过程中的叙事结构。研究发现，玩家与LLM的非确定性互动促使他们发掘出原本叙事之外的新颖节点，这些节点虽非初衷，却同样引人入胜。那些创造出最多新颖节点的玩家，往往是热衷于探索、发现和实验性游戏的爱好者。",
    "title_cn": "在大型语言模型（LLM）驱动的游戏叙事中，玩家的主动参与催生了新的发展。",
    "tags": [
      "分类：LLM应用",
      "游戏开发",
      "人工智能"
    ]
  },
  {
    "title": "How Does Conversation Length Impact User's Satisfaction? A Case Study of Length-Controlled Conversations with LLM-Powered Chatbots",
    "submit_datetime": "2024年04月25日",
    "abstract": "Users can discuss a wide range of topics with large language models (LLMs), but they do not always prefer solving problems or getting information through lengthy conversations. This raises an intriguing HCI question: How does instructing LLMs to engage in longer or shorter conversations affect conversation quality? In this paper, we developed two Slack chatbots using GPT-4 with the ability to vary conversation lengths and conducted a user study. Participants asked the chatbots both highly and less conversable questions, engaging in dialogues with 0, 3, 5, and 7 conversational turns. We found that the conversation quality does not differ drastically across different conditions, while participants had mixed reactions. Our study demonstrates LLMs' ability to change conversation length and the potential benefits for users resulting from such changes, but we caution that changes in text form may not necessarily imply changes in quality or content.",
    "pdf_link": "https://arxiv.org/abs/2404.17025",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.17025v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17025/Should-Ask-More.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17025v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17025/Enough-Count.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17025v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17025/Helpfulness.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17025v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17025/Satisfaction.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17025v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17025/mturk_helpfulness.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17025v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17025/mturk_quantity.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17025v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17025/mturk_relevance.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17025v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17025/mturk_repetitiveness.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17025v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17025/mturk_clarity.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17025v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17025/mturk_ambiguity.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17025v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17025/slackbot_mturk_interface_0.png"
      }
    ],
    "abstract_cn": "用户与大型语言模型（LLMs）的交流话题广泛，但他们有时更倾向于简洁的对话而非冗长的问答。这引出了一个引人入胜的人机交互（HCI）问题：我们如何通过调整LLMs的对话长度来优化对话质量？本研究中，我们利用GPT-4构建了两个Slack聊天机器人，它们能够灵活调整对话的长短，并进行了一项用户调研。参与者向机器人提出了从高度互动到不太适合深入讨论的问题，并与机器人进行了0至7轮的对话。研究发现，不同对话长度对质量的影响并不显著，而用户对此有着不同的反馈。这项研究揭示了LLMs在调整对话长度方面的潜力，以及这种调整可能给用户带来的益处，但也指出了文本形式的变动并不总等同于质量或内容的提升。",
    "title_cn": "对话的长短如何影响用户的满意度？本研究通过案例分析，探讨了由大型语言模型（LLM）支持的聊天机器人在进行长度受控对话时的用户满意度。",
    "tags": [
      "分类：LLM应用",
      "人机交互",
      "聊天机器人"
    ]
  },
  {
    "title": "AutoGenesisAgent: Self-Generating Multi-Agent Systems for Complex Tasks",
    "submit_datetime": "2024年04月25日",
    "abstract": "The proliferation of large language models (LLMs) and their integration into multi-agent systems has paved the way for sophisticated automation in various domains. This paper introduces AutoGenesisAgent, a multi-agent system that autonomously designs and deploys other multi-agent systems tailored for specific tasks. AutoGenesisAgent comprises several specialized agents including System Understanding, System Design, Agent Generator, and several others that collectively manage the lifecycle of creating functional multi-agent systems from initial concept to deployment. Each agent in AutoGenesisAgent has distinct responsibilities ranging from interpreting input prompts to optimizing system performance, culminating, in the deployment of a ready-to-use system. This proof-of-concept study discusses the design, implementation, and lessons learned from developing AutoGenesisAgent, highlighting its capability to generate and refine multi-agent systems autonomously, thereby reducing the need for extensive human oversight in the initial stages of system design. Keywords: multi-agent systems, large language models, system design automation, agent architecture, autonomous systems, software deployment",
    "pdf_link": "https://arxiv.org/abs/2404.17017",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）的普及及其融入多智能体系统，为各行业的高级自动化开辟了新径。本文提出了AutoGenesisAgent，一个能够独立设计并定制部署特定任务多智能体系统的系统。它由多个专业智能体组成，包括系统理解、系统设计、智能体生成等，协同管理从概念构想到系统部署的全过程。每个智能体承担着从解析输入到优化性能的不同职责，最终实现系统的即时使用。本概念验证研究探讨了AutoGenesisAgent的设计和实现，以及开发过程中的心得体会，强调了其在自主生成和优化多智能体系统方面的能力，减少了系统设计初期对人工监督的依赖。关键词包括：多智能体系统、大型语言模型、系统设计自动化、智能体架构、自主系统、软件部署。",
    "title_cn": "AutoGenesisAgent：一种自生成多智能体系统，专为解决复杂任务而设计。",
    "tags": [
      "Agent",
      "自动化",
      "人工智能"
    ]
  },
  {
    "title": "Evaluating Class Membership Relations in Knowledge Graphs using Large Language Models",
    "submit_datetime": "2024年04月25日",
    "abstract": "A backbone of knowledge graphs are their class membership relations, which assign entities to a given class. As part of the knowledge engineering process, we propose a new method for evaluating the quality of these relations by processing descriptions of a given entity and class using a zero-shot chain-of-thought classifier that uses a natural language intensional definition of a class. We evaluate the method using two publicly available knowledge graphs, Wikidata and CaLiGraph, and 7 large language models. Using the gpt-4-0125-preview large language model, the method's classification performance achieves a macro-averaged F1-score of 0.830 on data from Wikidata and 0.893 on data from CaLiGraph. Moreover, a manual analysis of the classification errors shows that 40.9% of errors were due to the knowledge graphs, with 16.0% due to missing relations and 24.9% due to incorrectly asserted relations. These results show how large language models can assist knowledge engineers in the process of knowledge graph refinement. The code and data are available on Github.",
    "pdf_link": "https://arxiv.org/abs/2404.17000",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.17000v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17000/zero_shot_cot_classifier.png"
      }
    ],
    "abstract_cn": "知识图谱的核心在于其类别成员关系，这些关系负责将实体归类到特定类别。在知识工程的框架内，我们提出了一种创新的评估方法，通过零样本思维链分类器分析特定实体和类别的描述，并利用类别的自然语言定义来衡量这些关系的优劣。该方法在 Wikidata 和 CaLiGraph 两个知名知识图谱上进行了测试，并借助 7 种大型语言模型进行了验证。特别是，使用 gpt-4-0125-preview 模型，我们在 Wikidata 上达到了 0.830 的宏观平均 F1 分数，在 CaLiGraph 上达到了 0.893。手动分析分类误差后发现，40.9% 的错误与知识图谱本身有关，其中 16.0% 是因为缺少关联，24.9% 是因为关联错误。这一发现揭示了大型语言模型在知识图谱优化过程中的辅助潜力。相关代码和数据已在 Github 上公开。",
    "title_cn": "本文探讨了如何利用大型语言模型来评估知识图谱内类别成员之间的关系。",
    "tags": [
      "LLM应用",
      "知识图谱",
      "知识工程"
    ]
  },
  {
    "title": "PLLaVA : Parameter-free LLaVA Extension from Images to Videos for Video Dense Captioning",
    "submit_datetime": "2024年04月25日",
    "abstract": "Vision-language pre-training has significantly elevated performance across a wide range of image-language applications. Yet, the pre-training process for video-related tasks demands exceptionally large computational and data resources, which hinders the progress of video-language models. This paper investigates a straightforward, highly efficient, and resource-light approach to adapting an existing image-language pre-trained model for dense video understanding. Our preliminary experiments reveal that directly fine-tuning pre-trained image-language models with multiple frames as inputs on video datasets leads to performance saturation or even a drop. Our further investigation reveals that it is largely attributed to the bias of learned high-norm visual features. Motivated by this finding, we propose a simple but effective pooling strategy to smooth the feature distribution along the temporal dimension and thus reduce the dominant impacts from the extreme features. The new model is termed Pooling LLaVA, or \\nameofmethod{} in short. \\nameofmethod{} achieves new state-of-the-art performance on modern benchmark datasets for both video question-answer and captioning tasks. Notably, on the recent popular Video ChatGPT benchmark, PLLaVA achieves a score of 3.48 out of 5 on average of five evaluated dimensions, exceeding the previous SOTA results from GPT4V (IG-VLM) by 9\\%. On the latest multi-choice benchmark MVBench, PLLaVA achieves 58.1\\% accuracy on average across 20 sub-tasks, 14.5\\% higher than GPT4V (IG-VLM). Code is available at \\url{https://github.com/magic-research/PLLaVA}.",
    "pdf_link": "https://arxiv.org/abs/2404.16994",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.16994v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16994/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16994v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16994/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16994v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16994/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16994v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16994/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16994v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16994/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16994v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16994/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16994v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16994/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16994v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16994/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16994v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16994/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16994v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16994/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16994v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16994/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16994v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16994/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16994v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16994/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16994v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16994/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16994v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16994/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16994v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16994/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16994v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16994/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16994v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16994/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16994v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16994/x19.png"
      }
    ],
    "abstract_cn": "视觉-语言预训练技术在图像-语言应用领域取得了显著成效。但视频任务的预训练却因对计算和数据资源的巨大需求而进展缓慢。本研究提出了一种简洁高效且资源消耗低的方法，用于优化现有的图像-语言预训练模型，以实现深度视频理解。我们的初步测试发现，直接对视频数据集进行多帧输入的预训练模型微调，可能会导致性能停滞甚至下降，这主要归咎于学习到的高范数视觉特征的偏颇。基于这一发现，我们设计了一种简单而有效的池化策略，用以沿时间维度平滑特征分布，减少极端特征的影响。新模型命名为 Pooling LLaVA（简称 PLLaVA）。PLLaVA 在视频问答和字幕制作等现代基准测试中刷新了最佳性能记录。特别值得一提的是，在最新的 Video ChatGPT 基准测试中，PLLaVA 的平均得分为 3.48 分（满分 5 分），较之前的最佳成绩提升了 9%。在多选基准测试 MVBench 中，PLLaVA 的平均准确度达到 58.1%，在 20 个子任务中比 IG-VLM 高出 14.5%。相关代码已在 \\url{https://github.com/magic-research/PLLaVA} 上发布。",
    "title_cn": "PLLaVA：一种无需额外参数即可将 LLaVA 从图像扩展到视频的技术，专为视频密集字幕生成设计。",
    "tags": [
      "分类：LLM应用\n\n这篇论文的摘要描述了一种针对视频任务的预训练模型优化方法，旨在实现深度视频理解。它提出了一种新的模型 PLLaVA，该模型在视频问答和字幕制作等任务中取得了优异的性能。这篇论文主要关注于如何改进现有的图像-语言预训练模型以适应视频任务，因此它属于LLM应用类别。",
      "视频理解",
      "人工智能"
    ]
  },
  {
    "title": "Examining the robustness of LLM evaluation to the distributional assumptions of benchmarks",
    "submit_datetime": "2024年04月25日",
    "abstract": "Benchmarks have emerged as the central approach for evaluating Large Language Models (LLMs). The research community often relies on a model's average performance across the test prompts of a benchmark to evaluate the model's performance. This is consistent with the assumption that the test prompts within a benchmark represent a random sample from a real-world distribution of interest. We note that this is generally not the case; instead, we hold that the distribution of interest varies according to the specific use case. We find that (1) the correlation in model performance across test prompts is non-random, (2) accounting for correlations across test prompts can change model rankings on major benchmarks, (3) explanatory factors for these correlations include semantic similarity and common LLM failure points.",
    "pdf_link": "https://arxiv.org/abs/2404.16966",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.16966v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16966/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16966v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16966/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16966v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16966/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16966v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16966/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16966v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16966/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16966v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16966/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16966v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16966/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16966v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16966/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16966v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16966/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16966v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16966/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16966v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16966/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16966v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16966/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16966v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16966/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16966v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16966/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16966v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16966/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16966v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16966/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16966v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16966/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16966v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16966/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16966v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16966/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16966v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16966/x20.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16966v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16966/x21.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16966v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16966/x22.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16966v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16966/x23.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16966v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16966/x24.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16966v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16966/x25.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16966v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16966/x26.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16966v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16966/x27.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16966v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16966/x28.png"
      }
    ],
    "abstract_cn": "基准测试已成为衡量大型语言模型（LLM）性能的核心手段。研究界通常根据模型在基准测试中各测试点的平均表现来进行评估。这种做法基于一个假设，即认为测试点是来自现实世界中我们感兴趣的某种分布的随机抽样。然而，实际情况往往并非如此，我们认为感兴趣的分布应当根据具体应用场景而有所不同。我们的研究发现：（1）模型在不同测试点的表现之间存在非随机的相关性；（2）考虑这些相关性可能会在主要基准测试中改变模型的排名；（3）这些相关性的解释因素包括语义相似性以及LLM常见的失败点。",
    "title_cn": "探究大型语言模型评估在面对基准测试分布假设时的稳健性。",
    "tags": [
      "LLM理论",
      "人工智能",
      ""
    ]
  },
  {
    "title": "A Survey of Generative Search and Recommendation in the Era of Large Language Models",
    "submit_datetime": "2024年04月25日",
    "abstract": "With the information explosion on the Web, search and recommendation are foundational infrastructures to satisfying users' information needs. As the two sides of the same coin, both revolve around the same core research problem, matching queries with documents or users with items. In the recent few decades, search and recommendation have experienced synchronous technological paradigm shifts, including machine learning-based and deep learning-based paradigms. Recently, the superintelligent generative large language models have sparked a new paradigm in search and recommendation, i.e., generative search (retrieval) and recommendation, which aims to address the matching problem in a generative manner. In this paper, we provide a comprehensive survey of the emerging paradigm in information systems and summarize the developments in generative search and recommendation from a unified perspective. Rather than simply categorizing existing works, we abstract a unified framework for the generative paradigm and break down the existing works into different stages within this framework to highlight the strengths and weaknesses. And then, we distinguish generative search and recommendation with their unique challenges, identify open problems and future directions, and envision the next information-seeking paradigm.",
    "pdf_link": "https://arxiv.org/abs/2404.16924",
    "graphs": [],
    "abstract_cn": "网络信息的海量增长使得搜索与推荐系统成为满足用户信息需求的基石。这两者虽各有侧重，却共同面对着将查询与文档、用户与商品精准匹配的核心课题。数十年来，搜索与推荐领域经历了技术革新，包括基于机器学习及深度学习的转型。近期，超智能的生成型大型语言模型为搜索和推荐带来了新的变革，即通过创造性的方法来解决匹配问题。本文全面梳理了这一新兴范式，并从统一视角对生成型搜索和推荐的最新进展进行了总结。我们不仅对现有研究进行了分类，还提炼出一个统一框架，将现有工作分解为框架内的不同阶段，以展现各自的优势与不足。此外，我们明确了生成型搜索和推荐面临的特殊挑战，指出了存在的问题和未来的研究方向，并对未来的信息检索模式进行了展望。",
    "title_cn": "本文综述了在大型语言模型盛行的当下，生成式搜索和推荐领域的研究进展。",
    "tags": [
      "LLM应用",
      "搜索与推荐系统",
      "信息检索"
    ]
  },
  {
    "title": "A Short Survey of Human Mobility Prediction in Epidemic Modeling from Transformers to LLMs",
    "submit_datetime": "2024年04月25日",
    "abstract": "This paper provides a comprehensive survey of recent advancements in leveraging machine learning techniques, particularly Transformer models, for predicting human mobility patterns during epidemics. Understanding how people move during epidemics is essential for modeling the spread of diseases and devising effective response strategies. Forecasting population movement is crucial for informing epidemiological models and facilitating effective response planning in public health emergencies. Predicting mobility patterns can enable authorities to better anticipate the geographical and temporal spread of diseases, allocate resources more efficiently, and implement targeted interventions. We review a range of approaches utilizing both pretrained language models like BERT and Large Language Models (LLMs) tailored specifically for mobility prediction tasks. These models have demonstrated significant potential in capturing complex spatio-temporal dependencies and contextual patterns in textual data.",
    "pdf_link": "https://arxiv.org/abs/2404.16921",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.16921v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16921/humanmob.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16921v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16921/x1.png"
      }
    ],
    "abstract_cn": "本文全面梳理了运用机器学习技术，尤其是 Transformer 模型，预测疫情中人类活动模式的最新进展。深入理解疫情下的人群流动对于疾病传播模型的构建和有效应对策略的制定极为关键。准确预测人群移动对于公共卫生紧急事件中的流行病学模型构建和响应计划的制定具有重要意义。通过预测活动模式，有关部门可以更准确地预测疾病的地理和时间分布，更高效地配置资源，并实施精准干预。本研究回顾了多种方法，包括使用预训练的语言模型如 BERT，以及专为预测移动性而设计的定制大型语言模型（LLMs）。这些模型在捕捉文本数据中的复杂时空关系和上下文模式方面显示出巨大潜力。",
    "title_cn": "一篇关于从变换器到大型语言模型在流行病建模中预测人类移动性的简明调查。",
    "tags": [
      "LLM应用",
      "公共卫生",
      "机器学习"
    ]
  },
  {
    "title": "Prediction Is All MoE Needs: Expert Load Distribution Goes from Fluctuating to Stabilizing",
    "submit_datetime": "2024年04月25日",
    "abstract": "MoE facilitates the development of large models by making the computational complexity of the model no longer scale linearly with increasing parameters. The learning sparse gating network selects a set of experts for each token to be processed; however, this may lead to differences in the number of tokens processed by each expert over several successive iterations, i.e., the expert load fluctuations, which reduces computational parallelization and resource utilization. To this end, we traced and analyzed loads of each expert in the training iterations for several large language models in this work, and defined the transient state with \"obvious load fluctuation\" and the stable state with \"temporal locality\". Moreover, given the characteristics of these two states and the computational overhead, we deployed three classical prediction algorithms that achieve accurate expert load prediction results. For the GPT3 350M model, the average error rates for predicting the expert load proportion over the next 1,000 and 2,000 steps are approximately 1.3% and 1.8%, respectively. This work can provide valuable guidance for expert placement or resource allocation for MoE model training. Based on this work, we will propose an expert placement scheme for transient and stable states in our coming work.",
    "pdf_link": "https://arxiv.org/abs/2404.16914",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.16914v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16914/gpt3-125m-layer2-load.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16914v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16914/gpt3-125m-layer8-load.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16914v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16914/gpt3-125m-layer6-w10-variance.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16914v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16914/gpt3-125m-layer8-w10-variance.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16914v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16914/gpt3-125m-layer12-w10-variance.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16914v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16914/gpt3-125m-layer6-w100-variance.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16914v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16914/gpt3-125m-layer8-w100-variance.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16914v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16914/gpt3-125m-layer12-w100-variance.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16914v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16914/gpt3-125m-layer2-variance.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16914v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16914/gpt3-125m-layer4-variance.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16914v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16914/gpt3-125m-layer6-variance.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16914v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16914/gpt3-125m-layer8-variance.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16914v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16914/gpt3-125m-layer10-variance.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16914v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16914/gpt3-125m-layer12-variance.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16914v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16914/gpt3-125m-layer2-range.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16914v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16914/gpt3-125m-layer4-range.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16914v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16914/gpt3-125m-layer6-range.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16914v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16914/gpt3-125m-layer8-range.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16914v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16914/gpt3-125m-layer10-range.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16914v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16914/gpt3-125m-layer12-range.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16914v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16914/gpt3-125m-LSTM-1k.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16914v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16914/gpt3-125m-ARIMA-1k.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16914v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16914/gpt3-125m-AVG-1k.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16914v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16914/gpt3-350m-LSTM-1k.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16914v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16914/gpt3-350m-LSTM-1k-bar.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16914v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16914/gpt3-350m-ARIMA-1k.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16914v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16914/gpt3-350m-ARIMA-1k-bar.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16914v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16914/gpt3-350m-AVG-1k.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16914v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16914/gpt3-350m-AVG-1k-bar.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16914v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16914/gpt3-350m-AVG-2k.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16914v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16914/gpt3-350m-AVG-2k-bar.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16914v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16914/gpt3-350m-layer2-variance.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16914v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16914/gpt3-350m-layer4-variance.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16914v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16914/gpt3-350m-layer6-variance.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16914v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16914/gpt3-350m-layer8-variance.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16914v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16914/gpt3-350m-layer12-variance.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16914v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16914/gpt3-350m-layer16-variance.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16914v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16914/gpt3-350m-layer20-variance.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16914v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16914/gpt3-350m-layer24-variance.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16914v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16914/gpt3-350m-layer2-range.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16914v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16914/gpt3-350m-layer4-range.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16914v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16914/gpt3-350m-layer6-range.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16914v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16914/gpt3-350m-layer8-range.png"
      }
    ],
    "abstract_cn": "MoE 技术通过改变计算复杂度与参数数量的线性关系，推动了大型模型的发展。在此过程中，稀疏门控网络负责为每个待处理的标记分配专家组，但这可能导致不同专家在连续迭代中的工作量出现波动，影响计算的并行性和资源的有效利用。在本研究中，我们对多个大型语言模型的专家负载进行了跟踪分析，并区分了“显著负载波动”的瞬态状态与“时间局部性”的稳定状态。针对这两种状态及计算开销，我们采用了三种经典预测算法，对专家负载进行了准确预测。以 GPT3 350M 模型为例，预测未来 1,000 步和 2,000 步的专家负载比例，平均误差率分别约为 1.3% 和 1.8%。本研究为 MoE 模型训练中的专家布局和资源配置提供了重要参考。未来，我们将进一步提出适用于瞬态和稳定状态的专家布局方案。",
    "title_cn": "预测即足矣：MoE 中的专家负载分配趋向稳定。",
    "tags": [
      "LLM理论",
      "人工智能",
      "计算优化"
    ]
  },
  {
    "title": "Evolve Cost-aware Acquisition Functions Using Large Language Models",
    "submit_datetime": "2024年04月25日",
    "abstract": "Many real-world optimization scenarios involve expensive evaluation with unknown and heterogeneous costs. Cost-aware Bayesian optimization stands out as a prominent solution in addressing these challenges. To approach the global optimum within a limited budget in a cost-efficient manner, the design of cost-aware acquisition functions (AFs) becomes a crucial step. However, traditional manual design paradigm typically requires extensive domain knowledge and involves a labor-intensive trial-and-error process. This paper introduces EvolCAF, a novel framework that integrates large language models (LLMs) with evolutionary computation (EC) to automatically design cost-aware AFs. Leveraging the crossover and mutation in the algorithm space, EvolCAF offers a novel design paradigm, significantly reduces the reliance on domain expertise and model training. The designed cost-aware AF maximizes the utilization of available information from historical data, surrogate models and budget details. It introduces novel ideas not previously explored in the existing literature on acquisition function design, allowing for clear interpretations to provide insights into its behavior and decision-making process. In comparison to the well-known EIpu and EI-cool methods designed by human experts, our approach showcases remarkable efficiency and generalization across various tasks, including 12 synthetic problems and 3 real-world hyperparameter tuning test sets.",
    "pdf_link": "https://arxiv.org/abs/2404.16906",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.16906v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16906/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16906v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16906/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16906v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16906/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16906v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16906/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16906v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16906/x5.png"
      }
    ],
    "abstract_cn": "在众多现实世界的优化情境中，评估成本高昂且成本结构复杂多变。面对这一难题，成本感知贝叶斯优化策略以其显著效果脱颖而出。在预算有限的情况下，如何设计出成本感知的获取函数（AFs），以经济高效的方式逼近全局最优解，成为了一个关键问题。传统上，这一设计过程依赖于深入的领域知识和繁琐的试错环节。本论文提出了EvolCAF，这是一个创新的框架，它融合了大型语言模型（LLMs）和进化计算（EC），自动化地设计出成本感知的AFs。EvolCAF通过算法空间中的交叉和变异操作，开创了一种新的设计模式，大幅降低了对专业领域知识和模型训练的依赖。所设计的AF能够充分利用历史数据、替代模型和预算细节中的信息，其新颖的设计思路为获取函数的设计领域带来了新的视角，提供了对其行为和决策过程的清晰解释。相较于人类专家设计的EIpu和EI-cool方法，EvolCAF在多个任务上展现出了卓越的效率和泛化能力，这包括12个合成问题和3个真实世界的超参数调整测试集。",
    "title_cn": "利用大型语言模型，我们推进了成本感知采购函数的演化。",
    "tags": [
      "LLM应用",
      "优化算法",
      "自动化设计"
    ]
  },
  {
    "title": "How to Parameterize Asymmetric Quantization Ranges for Quantization-Aware Training",
    "submit_datetime": "2024年04月25日",
    "abstract": "This paper investigates three different parameterizations of asymmetric uniform quantization for quantization-aware training: (1) scale and offset, (2) minimum and maximum, and (3) beta and gamma. We perform a comprehensive comparative analysis of these parameterizations' influence on quantization-aware training, using both controlled experiments and real-world large language models. Our particular focus is on their changing behavior in response to critical training hyperparameters, bit width and learning rate. Based on our investigation, we propose best practices to stabilize and accelerate quantization-aware training with learnable asymmetric quantization ranges.",
    "pdf_link": "https://arxiv.org/abs/2404.16898",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.16898v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16898/fig1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16898v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16898/fig2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16898v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16898/sz_mm_adam_3_norm.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16898v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16898/sz_mm_adam_10_norm.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16898v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16898/fig4_1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16898v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16898/fig4_2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16898v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16898/ext_mm_vs_bg_b3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16898v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16898/ext_mm_vs_bg_b10.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16898v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16898/sz_asz1_asz2_ksz_b3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16898v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16898/sz_asz1_asz2_ksz_b10.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16898v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16898/sym_all.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16898v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16898/sym_scale.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16898v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16898/relu_sz_vs_mm_3bit_1e2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16898v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16898/relu_sz_vs_mm_8bit_1e2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16898v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16898/normal_4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16898v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16898/normal_8.png"
      }
    ],
    "abstract_cn": "本研究深入探讨了量化感知训练中三种非对称均匀量化参数化方案：（1）缩放和平移，（2）最小与最大值，（3）β与γ。通过精心设计的实验和在真实世界的大型语言模型上的应用，我们全面比较了这些参数化对训练过程的影响。研究重点在于它们如何随关键训练超参数——位宽和学习率——的变化而变化。根据我们的发现，我们提出了一系列最佳实践，旨在优化具有可学习非对称量化区间的量化感知训练的稳定性与效率。",
    "title_cn": "量化感知训练中非对称量化区间的参数化方法",
    "tags": [
      "分类：LLM理论",
      "机器学习",
      ""
    ]
  },
  {
    "title": "Evaluating Collaborative Autonomy in Opposed Environments using Maritime Capture-the-Flag Competitions",
    "submit_datetime": "2024年04月25日",
    "abstract": "The objective of this work is to evaluate multi-agent artificial intelligence methods when deployed on teams of unmanned surface vehicles (USV) in an adversarial environment. Autonomous agents were evaluated in real-world scenarios using the Aquaticus test-bed, which is a Capture-the-Flag (CTF) style competition involving teams of USV systems. Cooperative teaming algorithms of various foundations in behavior-based optimization and deep reinforcement learning (RL) were deployed on these USV systems in two versus two teams and tested against each other during a competition period in the fall of 2023. Deep reinforcement learning applied to USV agents was achieved via the Pyquaticus test bed, a lightweight gymnasium environment that allows simulated CTF training in a low-level environment. The results of the experiment demonstrate that rule-based cooperation for behavior-based agents outperformed those trained in Deep-reinforcement learning paradigms as implemented in these competitions. Further integration of the Pyquaticus gymnasium environment for RL with MOOS-IvP in terms of configuration and control schema will allow for more competitive CTF games in future studies. As the development of experimental deep RL methods continues, the authors expect that the competitive gap between behavior-based autonomy and deep RL will be reduced. As such, this report outlines the overall competition, methods, and results with an emphasis on future works such as reward shaping and sim-to-real methodologies and extending rule-based cooperation among agents to react to safety and security events in accordance with human experts intent/rules for executing safety and security processes.",
    "pdf_link": "https://arxiv.org/abs/2404.17038",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.17038v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17038/Boats.jpg"
      },
      {
        "url": "https://arxiv.org/html/2404.17038v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17038/NEARLINEZOOM.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17038v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17038/AUS_Game_Picture.jpg"
      },
      {
        "url": "https://arxiv.org/html/2404.17038v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17038/MOOSIVP.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17038v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17038/PAV01.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17038v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17038/bhv_strategies_modetree.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17038v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17038/pyquaticus_image_mod.png"
      },
      {
        "url": "https://arxiv.org/html/2404.17038v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.17038/KEVIN04.png"
      }
    ],
    "abstract_cn": "本研究旨在探讨在对抗性环境中，多智能体人工智能方法在无人水面船只（USV）团队中的应用效果。通过Aquaticus测试平台，我们在现实场景中对自主智能体进行了评估，该平台采用Capture-the-Flag（CTF）风格的竞赛形式，涉及USV系统的团队对抗。我们部署了基于行为优化和深度强化学习（RL）的多种合作算法于USV系统，并在2023年秋季的比赛中进行了两两对抗的测试。利用Pyquaticus测试平台，我们实现了USV智能体的深度强化学习，该平台是一个轻量级的仿真环境，支持在低层次环境中进行CTF训练。实验结果显示，基于规则的合作策略在行为基础智能体中表现更佳，超越了深度强化学习训练的智能体。未来，我们计划将Pyquaticus环境与MOOS-IvP在配置和控制架构上进一步整合，以提升CTF游戏的竞争力。随着深度RL方法的不断进步，我们预计行为基础自主性与深度RL之间的性能差距将逐步缩小。本报告总结了比赛的整体情况、所采用的方法以及实验结果，并对未来的工作重点，如奖励机制设计、仿真到现实技术，以及如何扩展基于规则的智能体合作以响应安全和安全事件，根据人类专家的意图和规则执行安全和防护流程进行了展望。",
    "title_cn": "通过海上“夺旗”竞赛，评估在对抗环境中的协同自主性",
    "tags": [
      "Agent",
      "无人船只",
      "人工智能"
    ]
  },
  {
    "title": "Samsung Research China-Beijing at SemEval-2024 Task 3: A multi-stage framework for Emotion-Cause Pair Extraction in Conversations",
    "submit_datetime": "2024年04月25日",
    "abstract": "In human-computer interaction, it is crucial for agents to respond to human by understanding their emotions. Unraveling the causes of emotions is more challenging. A new task named Multimodal Emotion-Cause Pair Extraction in Conversations is responsible for recognizing emotion and identifying causal expressions. In this study, we propose a multi-stage framework to generate emotion and extract the emotion causal pairs given the target emotion. In the first stage, Llama-2-based InstructERC is utilized to extract the emotion category of each utterance in a conversation. After emotion recognition, a two-stream attention model is employed to extract the emotion causal pairs given the target emotion for subtask 2 while MuTEC is employed to extract causal span for subtask 1. Our approach achieved first place for both of the two subtasks in the competition.",
    "pdf_link": "https://arxiv.org/abs/2404.16905",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.16905v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16905/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16905v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16905/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16905v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16905/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16905v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16905/face_framework.png"
      }
    ],
    "abstract_cn": "在人机互动领域，理解并回应人类情感对于智能代理来说极为关键，而探究情感背后的成因则更为复杂。本研究提出了一项名为“对话中多模态情感-原因对抽取”的新任务，旨在识别情感并找出其成因。我们设计了一个分阶段的框架，旨在生成情感并针对特定目标情感抽取情感因果对。首先，利用基于 Llama-2 的 InstructERC 来识别对话中每句话的情感类型。情感识别完成后，我们采用双流注意力模型来抽取针对目标情感的情感因果对，以完成子任务 2；同时，使用 MuTEC 来抽取子任务 1 的因果跨度。在竞赛中，我们的方案在两个子任务上均荣获第一名。",
    "title_cn": "三星中国研究院北京分部在 SemEval-2024 竞赛的第三项任务中提出了一种多阶段框架，专门用于在对话中提取情感及其成因的配对。",
    "tags": [
      "Agent",
      "人机交互",
      "情感分析"
    ]
  },
  {
    "title": "Neural Interaction Energy for Multi-Agent Trajectory Prediction",
    "submit_datetime": "2024年04月25日",
    "abstract": "Maintaining temporal stability is crucial in multi-agent trajectory prediction. Insufficient regularization to uphold this stability often results in fluctuations in kinematic states, leading to inconsistent predictions and the amplification of errors. In this study, we introduce a framework called Multi-Agent Trajectory prediction via neural interaction Energy (MATE). This framework assesses the interactive motion of agents by employing neural interaction energy, which captures the dynamics of interactions and illustrates their influence on the future trajectories of agents. To bolster temporal stability, we introduce two constraints: inter-agent interaction constraint and intra-agent motion constraint. These constraints work together to ensure temporal stability at both the system and agent levels, effectively mitigating prediction fluctuations inherent in multi-agent systems. Comparative evaluations against previous methods on four diverse datasets highlight the superior prediction accuracy and generalization capabilities of our model.",
    "pdf_link": "https://arxiv.org/abs/2404.16579",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.16579v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16579/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16579v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16579/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16579v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16579/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16579v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16579/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16579v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16579/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16579v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16579/x6.png"
      }
    ],
    "abstract_cn": "在多智能体轨迹预测领域，确保时间稳定性是关键。缺乏足够的正则化可能导致运动状态的波动，进而引发预测不一致和误差累积。本研究提出了一个名为MATE（通过神经交互能量进行多智能体轨迹预测）的框架，它利用神经交互能量来分析智能体间的互动运动，从而揭示这些互动对未来轨迹的影响。为增强时间稳定性，我们引入了两项约束：一是智能体间的交互约束，二是智能体内部的运动约束。这两项约束协同作用，确保了系统和个体层面的时间稳定性，有效减少了多智能体系统中的预测波动。在四个多样化数据集上的比较评估显示，我们的模型在预测准确性和泛化能力方面均优于现有方法。",
    "title_cn": "本文介绍了一种新颖的方法——神经交互能量，用于预测多智能体的行动轨迹。",
    "tags": [
      "Agent",
      "智能体轨迹预测",
      "多智能体系统"
    ]
  },
  {
    "title": "Distributed Matrix Pencil Formulations for Prescribed-Time Leader-Following Consensus of MASs with Unknown Sensor Sensitivity",
    "submit_datetime": "2024年04月25日",
    "abstract": "In this paper, we address the problem of prescribed-time leader-following consensus of heterogeneous multi-agent systems (MASs) in the presence of unknown sensor sensitivity. Under a connected undirected topology, we propose a time-varying dual observer/controller design framework that makes use of regular local and inaccurate feedback to achieve consensus tracking within a prescribed time. In particular, the developed analysis framework is applicable to MASs equipped with sensors of different sensitivities. One of the design innovations involves constructing a distributed matrix pencil formulation based on worst-case sensors, yielding control parameters with sufficient robustness yet relatively low conservatism. Another novelty is the construction of the control gains, which consists of the product of a proportional coefficient obtained from the matrix pencil formulation and a classic time-varying function that grows to infinity or a novel bounded time-varying function. Furthermore, it is possible to extend the prescribed-time distributed protocol to infinite time domain by introducing the bounded time-varying gain technique without sacrificing the ultimate control accuracy, and the corresponding technical proof is comprehensive. The effectiveness of the method is demonstrated through a group of 5 single-link robot manipulators.",
    "pdf_link": "https://arxiv.org/abs/2404.16412",
    "graphs": [],
    "abstract_cn": "本文探讨了在未知传感器灵敏度条件下，异构多智能体系统（MASs）实现预定时间领导者-跟随者共识的问题。我们提出了一个时变双观测器/控制器设计框架，该框架在无向连接拓扑下，通过常规局部和不完全反馈实现预定时间内的共识追踪。这一框架特别适用于装备了不同灵敏度传感器的MASs。设计上的创新包括基于最坏情况传感器构建分布式矩阵铅笔公式，以获得既足够鲁棒又不太保守的控制参数。控制增益的构建也是一个亮点，它由矩阵铅笔公式得到的比例系数与一个趋向无穷大的经典时变函数或一个新颖的有界时变函数相乘而成。此外，通过引入有界时变增益技术，我们可以在不损失最终控制精度的前提下，将预定时间分布式协议扩展到无限时间域，技术证明也十分全面。通过5个单连杆机器人操纵器的实验，验证了该方法的有效性。",
    "title_cn": "本文提出了一种分布式矩阵铅笔公式，用于解决多智能体系统（MASs）在未知传感器灵敏度条件下，实现预定时间领导者-跟随者共识的问题。",
    "tags": [
      "分类：Agent",
      "机器人技术",
      "控制系统"
    ]
  },
  {
    "title": "Optimal and Bounded Suboptimal Any-Angle Multi-agent Pathfinding",
    "submit_datetime": "2024年04月25日",
    "abstract": "Multi-agent pathfinding (MAPF) is the problem of finding a set of conflict-free paths for a set of agents. Typically, the agents' moves are limited to a pre-defined graph of possible locations and allowed transitions between them, e.g. a 4-neighborhood grid. We explore how to solve MAPF problems when each agent can move between any pair of possible locations as long as traversing the line segment connecting them does not lead to the collision with the obstacles. This is known as any-angle pathfinding. We present the first optimal any-angle multi-agent pathfinding algorithm. Our planner is based on the Continuous Conflict-based Search (CCBS) algorithm and an optimal any-angle variant of the Safe Interval Path Planning (TO-AA-SIPP). The straightforward combination of those, however, scales poorly since any-angle path finding induces search trees with a very large branching factor. To mitigate this, we adapt two techniques from classical MAPF to the any-angle setting, namely Disjoint Splitting and Multi-Constraints. Experimental results on different combinations of these techniques show they enable solving over 30% more problems than the vanilla combination of CCBS and TO-AA-SIPP. In addition, we present a bounded-suboptimal variant of our algorithm, that enables trading runtime for solution cost in a controlled manner.",
    "pdf_link": "https://arxiv.org/abs/2404.16379",
    "graphs": [],
    "abstract_cn": "多智能体路径规划（MAPF）旨在为一群智能体规划出互不冲突的路径集合。在这一问题中，智能体的行动通常限制在预设的、包含可能位置和它们之间允许转换的图上，例如4邻接网格。本研究探讨了在智能体能够在任意两个可能位置间移动而不与障碍物发生碰撞的情况下，如何进行MAPF问题的求解，这被称作任意角度路径规划。我们首次提出了一个最优的任意角度多智能体路径规划算法，该算法基于连续冲突搜索（CCBS）算法和安全间隔路径规划（TO-AA-SIPP）的最优任意角度变种。然而，这两种算法的直接结合在扩展性上表现不佳，因为任意角度路径规划会导致搜索树的分支因子极大。为了解决这个问题，我们从传统MAPF中借鉴了两种技术，并将其适配到任意角度路径规划中，分别是不相交分割和多约束技术。实验结果显示，这些技术的结合使用能够比CCBS和TO-AA-SIPP的标准组合多解决超过30%的问题。此外，我们还提出了算法的一个有界次优变体，它允许在运行时间和解决方案成本之间进行可控的权衡。",
    "title_cn": "探索最优与有界次优的多智能体任意角度路径规划",
    "tags": [
      "Agent",
      "机器人技术",
      "路径规划"
    ]
  },
  {
    "title": "WorldValuesBench: A Large-Scale Benchmark Dataset for Multi-Cultural Value Awareness of Language Models",
    "submit_datetime": "2024年04月24日",
    "abstract": "The awareness of multi-cultural human values is critical to the ability of language models (LMs) to generate safe and personalized responses. However, this awareness of LMs has been insufficiently studied, since the computer science community lacks access to the large-scale real-world data about multi-cultural values. In this paper, we present WorldValuesBench, a globally diverse, large-scale benchmark dataset for the multi-cultural value prediction task, which requires a model to generate a rating response to a value question based on demographic contexts. Our dataset is derived from an influential social science project, World Values Survey (WVS), that has collected answers to hundreds of value questions (e.g., social, economic, ethical) from 94,728 participants worldwide. We have constructed more than 20 million examples of the type \"(demographic attributes, value question) $\\rightarrow$ answer\" from the WVS responses. We perform a case study using our dataset and show that the task is challenging for strong open and closed-source models. On merely $11.1\\%$, $25.0\\%$, $72.2\\%$, and $75.0\\%$ of the questions, Alpaca-7B, Vicuna-7B-v1.5, Mixtral-8x7B-Instruct-v0.1, and GPT-3.5 Turbo can respectively achieve $<0.2$ Wasserstein 1-distance from the human normalized answer distributions. WorldValuesBench opens up new research avenues in studying limitations and opportunities in multi-cultural value awareness of LMs.",
    "pdf_link": "https://arxiv.org/abs/2404.16308",
    "graphs": [],
    "abstract_cn": "语言模型在生成安全且个性化的回应时，对多元文化价值观的认知极为关键。然而，对于语言模型在这方面的认知，研究尚显不足，主要原因在于计算机科学界难以获取大规模的多元文化价值现实世界数据。本文介绍了WorldValuesBench，这是一个涵盖全球多样性、大规模的基准数据集，旨在预测多文化价值观，要求模型基于人口统计背景对价值问题给出评分反馈。该数据集基于著名的社会科学项目——世界价值观调查（WVS），该项目汇集了全球94,728名受访者对数百个价值问题的回答。我们从WVS的反馈中构建了超过2000万个“（人口统计特征，价值问题）→答案”的样本。通过案例研究，我们发现即使是先进的开源和闭源模型，面对这一任务也显得力不从心。Alpaca-7B、Vicuna-7B-v1.5、Mixtral-8x7B-Instruct-v0.1和GPT-3.5 Turbo在分别只有11.1%、25.0%、72.2%和75.0%的问题上，才能达到与人类答案分布的Wasserstein 1-距离小于0.2。WorldValuesBench的推出，为探索语言模型在多元文化价值认知上的局限与潜力提供了新的研究路径。",
    "title_cn": "WorldValuesBench：为语言模型打造的大型多文化价值意识基准数据集",
    "tags": [
      "分类：LLM应用\n\n这篇论文主要关注语言模型在多元文化价值观认知方面的应用，通过构建大规模基准数据集WorldValuesBench来评估模型性能。这属于LLM应用的范畴，因为它探讨了如何利用现有的大型语言模型来解决特定的问题（即预测多文化价值观），并提出了一个新的数据集来促进相关研究。",
      "计算机科学",
      "社会心理学"
    ]
  },
  {
    "title": "Semantically consistent Video-to-Audio Generation using Multimodal Language Large Model",
    "submit_datetime": "2024年04月24日",
    "abstract": "Existing works have made strides in video generation, but the lack of sound effects (SFX) and background music (BGM) hinders a complete and immersive viewer experience. We introduce a novel semantically consistent v ideo-to-audio generation framework, namely SVA, which automatically generates audio semantically consistent with the given video content. The framework harnesses the power of multimodal large language model (MLLM) to understand video semantics from a key frame and generate creative audio schemes, which are then utilized as prompts for text-to-audio models, resulting in video-to-audio generation with natural language as an interface. We show the satisfactory performance of SVA through case study and discuss the limitations along with the future research direction. The project page is available at https://huiz-a.github.io/audio4video.github.io/.",
    "pdf_link": "https://arxiv.org/abs/2404.16305",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.16305v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16305/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16305v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16305/x2.png"
      }
    ],
    "abstract_cn": "在视频生成领域，尽管已有显著进展，但缺少音效和背景音乐影响了观众的沉浸体验。为此，我们提出了一个创新的语义一致性视频转音频生成框架——SVA，它能够自动生成与视频内容语义相匹配的音频。SVA框架借助多模态大型语言模型深入理解关键帧的语义，并创造性地设计音频方案，这些方案随后作为文本转音频模型的输入提示，实现了以自然语言为桥梁的视频到音频的生成。通过案例分析，我们证实了SVA的卓越性能，并对其局限性及未来研究的可能方向进行了探讨。项目详情可访问 https://huiz-a.github.io/audio4video.github.io/。",
    "title_cn": "借助多模态大型语言模型，实现视频到音频的语义一致性生成。",
    "tags": [
      "LLM应用",
      "视频生成",
      "音频生成"
    ]
  },
  {
    "title": "When Fuzzing Meets LLMs: Challenges and Opportunities",
    "submit_datetime": "2024年04月24日",
    "abstract": "Fuzzing, a widely-used technique for bug detection, has seen advancements through Large Language Models (LLMs). Despite their potential, LLMs face specific challenges in fuzzing. In this paper, we identified five major challenges of LLM-assisted fuzzing. To support our findings, we revisited the most recent papers from top-tier conferences, confirming that these challenges are widespread. As a remedy, we propose some actionable recommendations to help improve applying LLM in Fuzzing and conduct preliminary evaluations on DBMS fuzzing. The results demonstrate that our recommendations effectively address the identified challenges.",
    "pdf_link": "https://arxiv.org/abs/2404.16297",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.16297v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16297/x1.png"
      }
    ],
    "abstract_cn": "模糊测试，这一广泛应用于漏洞探测的技术，借助大型语言模型（LLMs）取得了新的突破。然而，LLMs在模糊测试的应用上遭遇了特别的难题。本文中，我们归纳了LLM辅助模糊测试面临的五大挑战。为了验证这些发现，我们回顾了顶级会议上的最新论文，确认了这些挑战的普遍性。为此，我们提出了一系列切实可行的建议，旨在优化LLM在模糊测试中的应用，并在数据库管理系统（DBMS）模糊测试领域进行了初步的评估。评估结果证明，我们的建议对于应对这些挑战具有显著效果。",
    "title_cn": "模糊测试与大型语言模型（LLMs）的邂逅：面临的挑战与潜在的机遇。",
    "tags": [
      "LLM应用",
      "软件测试",
      "数据库管理"
    ]
  },
  {
    "title": "LLM-Based Section Identifiers Excel on Open Source but Stumble in Real World Applications",
    "submit_datetime": "2024年04月24日",
    "abstract": "Electronic health records (EHR) even though a boon for healthcare practitioners, are growing convoluted and longer every day. Sifting around these lengthy EHRs is taxing and becomes a cumbersome part of physician-patient interaction. Several approaches have been proposed to help alleviate this prevalent issue either via summarization or sectioning, however, only a few approaches have truly been helpful in the past. With the rise of automated methods, machine learning (ML) has shown promise in solving the task of identifying relevant sections in EHR. However, most ML methods rely on labeled data which is difficult to get in healthcare. Large language models (LLMs) on the other hand, have performed impressive feats in natural language processing (NLP), that too in a zero-shot manner, i.e. without any labeled data. To that end, we propose using LLMs to identify relevant section headers. We find that GPT-4 can effectively solve the task on both zero and few-shot settings as well as segment dramatically better than state-of-the-art methods. Additionally, we also annotate a much harder real world dataset and find that GPT-4 struggles to perform well, alluding to further research and harder benchmarks.",
    "pdf_link": "https://arxiv.org/abs/2404.16294",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.16294v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16294/Handwritten_clinical_note.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16294v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16294/Section_Category.png"
      }
    ],
    "abstract_cn": "电子健康记录（EHR）为医疗专业人员带来了便利，但其内容日益庞杂和冗长，使得在这些繁复的记录中寻找信息变得既费力又繁琐。尽管提出了多种解决方案，如摘要化或分节，但真正有效的办法并不多。随着自动化技术的兴起，机器学习（ML）在识别 EHR 中的关键部分方面展现出潜力。不过，大多数 ML 方法需要依赖难以获得的标记数据。与此同时，大型语言模型（LLMs）在无需任何标记数据的情况下，在自然语言处理（NLP）领域取得了显著成就。基于此，我们提出利用 LLMs 来识别 EHR 中的相关章节标题。实验结果表明，GPT-4 不仅在零样本和少样本情境下能够有效完成任务，而且在数据分段上也显著优于现有技术。此外，我们还对一个更具挑战性的现实世界数据集进行了标注，发现 GPT-4 在此任务上的表现仍有提升空间，这为未来的研究和更严格的评估标准提供了方向。",
    "title_cn": "基于大型语言模型的章节识别器在开源项目中表现优异，然而在现实世界的应用场景中却步履蹒跚。",
    "tags": [
      "LLM应用",
      "",
      "机器学习"
    ]
  },
  {
    "title": "Andes: Defining and Enhancing Quality-of-Experience in LLM-Based Text Streaming Services",
    "submit_datetime": "2024年04月24日",
    "abstract": "The advent of large language models (LLMs) has transformed text-based services, enabling capabilities ranging from real-time translation to AI-driven chatbots. However, existing serving systems primarily focus on optimizing server-side aggregate metrics like token generation throughput, ignoring individual user experience with streamed text. As a result, under high and/or bursty load, a significant number of users can receive unfavorable service quality or poor Quality-of-Experience (QoE). In this paper, we first formally define QoE of text streaming services, where text is delivered incrementally and interactively to users, by considering the end-to-end token delivery process throughout the entire interaction with the user. Thereafter, we propose Andes, a QoE-aware serving system that enhances user experience for LLM-enabled text streaming services. At its core, Andes strategically allocates contended GPU resources among multiple requests over time to optimize their QoE. Our evaluations demonstrate that, compared to the state-of-the-art LLM serving systems like vLLM, Andes improves the average QoE by up to 3.2$\\times$ under high request rate, or alternatively, it attains up to 1.6$\\times$ higher request rate while preserving high QoE.",
    "pdf_link": "https://arxiv.org/abs/2404.16283",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.16283v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16283/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16283v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16283/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16283v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16283/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16283v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16283/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16283v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16283/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16283v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16283/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16283v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16283/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16283v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16283/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16283v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16283/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16283v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16283/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16283v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16283/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16283v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16283/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16283v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16283/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16283v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16283/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16283v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16283/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16283v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16283/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16283v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16283/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16283v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16283/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16283v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16283/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16283v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16283/x20.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16283v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16283/x21.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16283v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16283/x22.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16283v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16283/x23.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16283v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16283/x24.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16283v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16283/x25.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16283v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16283/x26.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16283v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16283/x27.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16283v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16283/x28.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16283v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16283/x29.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16283v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16283/x30.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16283v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16283/x31.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16283v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16283/x32.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16283v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16283/x33.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16283v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16283/x34.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16283v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16283/x35.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16283v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16283/x36.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16283v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16283/x37.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16283v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16283/x38.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16283v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16283/x39.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16283v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16283/x40.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16283v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16283/x41.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16283v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16283/x42.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16283v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16283/x43.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16283v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16283/x44.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16283v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16283/x45.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16283v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16283/x46.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16283v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16283/x47.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16283v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16283/x48.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16283v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16283/x49.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16283v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16283/x50.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16283v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16283/x51.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16283v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16283/x52.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLM）的问世，彻底革新了文本服务领域，从即时翻译到AI聊天机器人，开启了多种可能性。但现有服务系统多集中于提升服务器端的总体性能指标，如令牌生成速率，而忽视了用户在接收流式文本时的个性化体验。这导致在高流量或流量高峰时段，许多用户可能会遭遇服务质量不佳或体验质量（QoE）下降的问题。本文首先明确了文本流式服务的QoE定义，该服务以递增和互动的方式向用户传递文本，全面考虑了与用户互动的整个过程中端到端的令牌传递。接着，我们提出了Andes，这是一个注重QoE的服务系统，旨在提升LLM支持的文本流式服务的用户体验。Andes的核心在于，它巧妙地在多个请求之间分配有限的GPU资源，以时间为基础优化用户体验。我们的评估结果证明，与现有的顶尖LLM服务系统相比，Andes在高请求率下平均QoE提升了最多3.2倍，或者在保持高QoE的前提下，实现了最多1.6倍的请求处理能力提升。",
    "title_cn": "Andes：为基于大型语言模型的文本流服务定义并提升用户体验质量",
    "tags": [
      "LLM应用",
      "文本服务",
      "用户体验"
    ]
  },
  {
    "title": "Interpreting Answers to Yes-No Questions in Dialogues from Multiple Domains",
    "submit_datetime": "2024年04月24日",
    "abstract": "People often answer yes-no questions without explicitly saying yes, no, or similar polar keywords. Figuring out the meaning of indirect answers is challenging, even for large language models. In this paper, we investigate this problem working with dialogues from multiple domains. We present new benchmarks in three diverse domains: movie scripts, tennis interviews, and airline customer service. We present an approach grounded on distant supervision and blended training to quickly adapt to a new dialogue domain. Experimental results show that our approach is never detrimental and yields F1 improvements as high as 11-34%.",
    "pdf_link": "https://arxiv.org/abs/2404.16262",
    "graphs": [],
    "abstract_cn": "人们在回答是非题时，往往不会直接使用“是”、“否”等极端词汇。对于大型语言模型而言，解读这些含蓄的回答颇为棘手。本文针对这一难题，通过分析多个领域的对话数据进行了探讨。我们为三个迥异的领域——电影剧本、网球访谈和航空公司客服——设立了新的评估标准。我们介绍了一种基于远程监督与混合训练的方法，旨在迅速适应新的对话领域。实验结果显示，这种方法不仅无害，还能显著提升 F1 分数，提升幅度在 11% 至 34% 之间。",
    "title_cn": "在跨领域的对话中，解读针对是非问题的答复",
    "tags": [
      "LLM应用",
      "对话系统",
      ""
    ]
  },
  {
    "title": "Investigating the prompt leakage effect and black-box defenses for multi-turn LLM interactions",
    "submit_datetime": "2024年04月24日",
    "abstract": "Prompt leakage in large language models (LLMs) poses a significant security and privacy threat, particularly in retrieval-augmented generation (RAG) systems. However, leakage in multi-turn LLM interactions along with mitigation strategies has not been studied in a standardized manner. This paper investigates LLM vulnerabilities against prompt leakage across 4 diverse domains and 10 closed- and open-source LLMs. Our unique multi-turn threat model leverages the LLM's sycophancy effect and our analysis dissects task instruction and knowledge leakage in the LLM response. In a multi-turn setting, our threat model elevates the average attack success rate (ASR) to 86.2%, including a 99% leakage with GPT-4 and claude-1.3. We find that some black-box LLMs like Gemini show variable susceptibility to leakage across domains - they are more likely to leak contextual knowledge in the news domain compared to the medical domain. Our experiments measure specific effects of 6 black-box defense strategies, including a query-rewriter in the RAG scenario. Our proposed multi-tier combination of defenses still has an ASR of 5.3% for black-box LLMs, indicating room for enhancement and future direction for LLM security research.",
    "pdf_link": "https://arxiv.org/abs/2404.16251",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）中的提示泄露问题，对检索增强生成（RAG）系统构成了严重的安全和隐私风险。尽管如此，对于多轮LLM交互中的泄露现象及其缓解措施，目前还缺乏系统化的研究。本研究深入探讨了不同领域内，以及10种闭源和开源LLMs在面对提示泄露时的脆弱性。我们构建的多轮威胁模型巧妙利用了LLM的“拍马屁”效应，并通过深入分析，揭示了LLM回应中任务指令与知识泄露的关系。在模拟的多轮对话场景中，我们的模型将攻击者的平均成功率提升至86.2%，在某些情况下，如GPT-4和claude-1.3，泄露率甚至高达99%。我们还发现，部分黑盒LLMs，例如Gemini，在不同领域的泄露敏感性上表现出差异，它们在新闻领域比在医疗领域更容易泄露上下文信息。通过一系列实验，我们评估了六种黑盒防御策略的具体效果，包括RAG场景下的查询重写技术。我们提出的多层次防御策略组合，尽管将黑盒LLMs的平均攻击成功率降低到了5.3%，但仍显示出提升空间，为LLM安全研究的未来指明了方向。",
    "title_cn": "本研究旨在探究在多轮大型语言模型互动中出现的提示泄露现象，以及为这种交互模式设计的黑箱防御机制。",
    "tags": [
      "LLM应用",
      "安全与隐私",
      "人工智能"
    ]
  },
  {
    "title": "URL: Universal Referential Knowledge Linking via Task-instructed Representation Compression",
    "submit_datetime": "2024年04月24日",
    "abstract": "Linking a claim to grounded references is a critical ability to fulfill human demands for authentic and reliable information. Current studies are limited to specific tasks like information retrieval or semantic matching, where the claim-reference relationships are unique and fixed, while the referential knowledge linking (RKL) in real-world can be much more diverse and complex. In this paper, we propose universal referential knowledge linking (URL), which aims to resolve diversified referential knowledge linking tasks by one unified model. To this end, we propose a LLM-driven task-instructed representation compression, as well as a multi-view learning approach, in order to effectively adapt the instruction following and semantic understanding abilities of LLMs to referential knowledge linking. Furthermore, we also construct a new benchmark to evaluate ability of models on referential knowledge linking tasks across different scenarios. Experiments demonstrate that universal RKL is challenging for existing approaches, while the proposed framework can effectively resolve the task across various scenarios, and therefore outperforms previous approaches by a large margin.",
    "pdf_link": "https://arxiv.org/abs/2404.16248",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.16248v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16248/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16248v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16248/x2.png"
      }
    ],
    "abstract_cn": "将信息主张与确凿的参考资源相连接是人类追求真实和可信信息的基本需求。目前的研究多聚焦于特定领域，如信息检索或语义匹配，这些领域的主张与参考关系明确且单一。相较之下，现实世界中的参照知识链接（RKL）要复杂和多变得多。本文提出了一种全新的通用参照知识链接（URL）概念，其目的是通过统一的模型框架，解决多样化的参照知识链接问题。我们引入了一种由大型语言模型（LLM）支持的任务驱动表示压缩技术，结合多视角学习方法，以提升模型在参照知识链接任务中的指令执行和语义理解能力。此外，我们还开发了一个新的评估基准，用以测试模型在不同情境下进行参照知识链接的表现。实验结果证明，现有的方法在处理通用RKL时面临挑战，而我们提出的框架能够在多种不同情境下有效解决问题，显著优于以往的解决方案。",
    "title_cn": "URL：通过任务驱动的表示压缩技术，实现知识的普遍引用链接。",
    "tags": [
      "LLM应用",
      "信息检索",
      "知识链接"
    ]
  },
  {
    "title": "Step Differences in Instructional Video",
    "submit_datetime": "2024年04月24日",
    "abstract": "Comparing a user video to a reference how-to video is a key requirement for AR/VR technology delivering personalized assistance tailored to the user's progress. However, current approaches for language-based assistance can only answer questions about a single video. We propose an approach that first automatically generates large amounts of visual instruction tuning data involving pairs of videos from HowTo100M by leveraging existing step annotations and accompanying narrations, and then trains a video-conditioned language model to jointly reason across multiple raw videos. Our model achieves state-of-the-art performance at identifying differences between video pairs and ranking videos based on the severity of these differences, and shows promising ability to perform general reasoning over multiple videos.",
    "pdf_link": "https://arxiv.org/abs/2404.16222",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.16222v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16222/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16222v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16222/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16222v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16222/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16222v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16222/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16222v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16222/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16222v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16222/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16222v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16222/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16222v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16222/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16222v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16222/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16222v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16222/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16222v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16222/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16222v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16222/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16222v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16222/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16222v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16222/x14.png"
      }
    ],
    "abstract_cn": "在 AR/VR 技术中，将用户视频与教学视频进行比较是实现个性化辅助的关键。但现有基于语言的辅助方法仅能针对单个视频答疑。我们提出了一种新方法：首先，通过现有步骤注释和旁白，自动生成大量 HowTo100M 视频对的视觉指令调整数据；其次，训练一个视频驱动的语言模型，使其能够跨多个原始视频进行联合推理。该模型在识别视频对差异和基于差异严重性对视频排序方面达到了行业领先水平，并展现出处理多视频通用推理的潜力。",
    "title_cn": "教学视频的分步差异",
    "tags": [
      "分类：RAG",
      "增强现实/虚拟现实",
      ""
    ]
  },
  {
    "title": "Towards Efficient Patient Recruitment for Clinical Trials: Application of a Prompt-Based Learning Model",
    "submit_datetime": "2024年04月24日",
    "abstract": "Objective: Clinical trials are essential for advancing pharmaceutical interventions, but they face a bottleneck in selecting eligible participants. Although leveraging electronic health records (EHR) for recruitment has gained popularity, the complex nature of unstructured medical texts presents challenges in efficiently identifying participants. Natural Language Processing (NLP) techniques have emerged as a solution with a recent focus on transformer models. In this study, we aimed to evaluate the performance of a prompt-based large language model for the cohort selection task from unstructured medical notes collected in the EHR. Methods: To process the medical records, we selected the most related sentences of the records to the eligibility criteria needed for the trial. The SNOMED CT concepts related to each eligibility criterion were collected. Medical records were also annotated with MedCAT based on the SNOMED CT ontology. Annotated sentences including concepts matched with the criteria-relevant terms were extracted. A prompt-based large language model (Generative Pre-trained Transformer (GPT) in this study) was then used with the extracted sentences as the training set. To assess its effectiveness, we evaluated the model's performance using the dataset from the 2018 n2c2 challenge, which aimed to classify medical records of 311 patients based on 13 eligibility criteria through NLP techniques. Results: Our proposed model showed the overall micro and macro F measures of 0.9061 and 0.8060 which were among the highest scores achieved by the experiments performed with this dataset. Conclusion: The application of a prompt-based large language model in this study to classify patients based on eligibility criteria received promising scores. Besides, we proposed a method of extractive summarization with the aid of SNOMED CT ontology that can be also applied to other medical texts.",
    "pdf_link": "https://arxiv.org/abs/2404.16198",
    "graphs": [],
    "abstract_cn": "目标：临床试验对于推动药物干预至关重要，但筛选合适的参与者却是一个难题。尽管利用电子健康记录（EHR）招募参与者的方法日益普及，但非结构化医疗文本的复杂性使得高效识别参与者变得困难。自然语言处理（NLP）技术，特别是变换器模型，已成为解决这一问题的有效手段。本研究旨在评估一种基于提示的大型语言模型在从EHR中收集的非结构化医疗笔记中进行队列筛选任务的性能。方法：我们筛选出与临床试验资格标准最相关的句子来处理医疗记录。收集了与各资格标准相关的SNOMED CT概念，并基于SNOMED CT本体论对医疗记录进行了MedCAT注释。随后，提取了包含与标准相关术语相匹配概念的注释句子。我们采用了基于提示的大型语言模型（本研究中为生成预训练变换器GPT）和这些句子作为训练集。为了测试其效果，我们使用了2018年n2c2挑战的数据集来评估模型性能，该挑战旨在通过NLP技术对311名患者的医疗记录根据13个资格标准进行分类。结果：我们所提出的模型在整体微观和宏观F测量值上分别达到了0.9061和0.8060，这在该数据集上的所有实验中得分名列前茅。结论：本研究中应用的基于提示的大型语言模型在根据资格标准对患者进行分类的任务上取得了令人鼓舞的成绩。此外，我们还提出了一种利用SNOMED CT本体论进行提取式摘要的方法，该方法同样适用于其他医疗文本的处理。",
    "title_cn": "高效招募临床试验患者：应用一种基于提示的学习模型",
    "tags": [
      "LLM应用",
      "",
      ""
    ]
  },
  {
    "title": "Improving Multi-label Recognition using Class Co-Occurrence Probabilities",
    "submit_datetime": "2024年04月24日",
    "abstract": "Multi-label Recognition (MLR) involves the identification of multiple objects within an image. To address the additional complexity of this problem, recent works have leveraged information from vision-language models (VLMs) trained on large text-images datasets for the task. These methods learn an independent classifier for each object (class), overlooking correlations in their occurrences. Such co-occurrences can be captured from the training data as conditional probabilities between a pair of classes. We propose a framework to extend the independent classifiers by incorporating the co-occurrence information for object pairs to improve the performance of independent classifiers. We use a Graph Convolutional Network (GCN) to enforce the conditional probabilities between classes, by refining the initial estimates derived from image and text sources obtained using VLMs. We validate our method on four MLR datasets, where our approach outperforms all state-of-the-art methods.",
    "pdf_link": "https://arxiv.org/abs/2404.16193",
    "graphs": [],
    "abstract_cn": "多标签识别（MLR）技术致力于在单张图像中识别多个对象。面对这一问题的复杂性，最新研究开始借助视觉-语言模型（VLMs）——它们在海量图文数据集上进行训练——来提升任务效率。传统方法通常为每个类别独立训练一个分类器，却忽视了类别间存在的共现关系。我们提出一种新框架，通过整合类别对的共现信息，优化独立分类器的性能。该框架利用图卷积网络（GCN）来调整类别间条件概率，从而精细化VLMs从图像和文本源得到的初步预测。经过在四个MLR数据集上的测试，我们的方法在性能上超越了所有现有的顶尖技术。",
    "title_cn": "通过类别共现概率提升多标签识别的性能",
    "tags": [
      "分类：Agent\n\n这篇论文提出了一种新的框架，通过整合类别对的共现信息，优化独立分类器的性能。该框架利用图卷积网络（GCN）来调整类别间条件概率，从而精细化视觉-语言模型（VLMs）从图像和文本源得到的初步预测。这表明该研究涉及到智能代理（Agent）在多标签识别（MLR）任务中的应用，因此将其归类为Agent。",
      "计算机视觉",
      "机器学习"
    ]
  },
  {
    "title": "Fusion of Domain-Adapted Vision and Language Models for Medical Visual Question Answering",
    "submit_datetime": "2024年04月24日",
    "abstract": "Vision-language models, while effective in general domains and showing strong performance in diverse multi-modal applications like visual question-answering (VQA), struggle to maintain the same level of effectiveness in more specialized domains, e.g., medical. We propose a medical vision-language model that integrates large vision and language models adapted for the medical domain. This model goes through three stages of parameter-efficient training using three separate biomedical and radiology multi-modal visual and text datasets. The proposed model achieves state-of-the-art performance on the SLAKE 1.0 medical VQA (MedVQA) dataset with an overall accuracy of 87.5% and demonstrates strong performance on another MedVQA dataset, VQA-RAD, achieving an overall accuracy of 73.2%.",
    "pdf_link": "https://arxiv.org/abs/2404.16192",
    "graphs": [],
    "abstract_cn": "视觉-语言模型在通用领域表现出色，并在多模态应用如视觉问答（VQA）中表现强劲。但在专业领域如医学中，其效能有所下降。为此，我们设计了一款专门针对医学领域的视觉-语言模型，该模型融合了专为医学定制的大型视觉和语言模型。通过三个阶段的参数高效训练，分别使用了三个不同的生物医学及放射学多模态视觉与文本数据集。在SLAKE 1.0医学VQA数据集上，该模型以87.5%的准确率刷新了最佳成绩，并在VQA-RAD数据集上也以73.2%的准确率展现了优异的性能。",
    "title_cn": "将领域适应的视觉与语言模型相结合，以提升医学视觉问答的性能。",
    "tags": [
      "分类：RAG\n\n这篇论文摘要描述了一种针对医学领域的视觉-语言模型，它通过三个阶段的参数高效训练，使用了生物医学及放射学多模态视觉与文本数据集。这种模型的设计和训练方法属于RAG（Retrieval-Augmented Generation）的范畴，因为它结合了视觉和语言信息，并且针对特定领域进行了定制。",
      "",
      "视觉问答"
    ]
  },
  {
    "title": "Towards a Holistic Evaluation of LLMs on Factual Knowledge Recall",
    "submit_datetime": "2024年04月24日",
    "abstract": "Large language models (LLMs) have shown remarkable performance on a variety of NLP tasks, and are being rapidly adopted in a wide range of use cases. It is therefore of vital importance to holistically evaluate the factuality of their generated outputs, as hallucinations remain a challenging issue.\n  In this work, we focus on assessing LLMs' ability to recall factual knowledge learned from pretraining, and the factors that affect this ability. To that end, we construct FACT-BENCH, a representative benchmark covering 20 domains, 134 property types, 3 answer types, and different knowledge popularity levels. We benchmark 31 models from 10 model families and provide a holistic assessment of their strengths and weaknesses. We observe that instruction-tuning hurts knowledge recall, as pretraining-only models consistently outperform their instruction-tuned counterparts, and positive effects of model scaling, as larger models outperform smaller ones for all model families. However, the best performance from GPT-4 still represents a large gap with the upper-bound. We additionally study the role of in-context exemplars using counterfactual demonstrations, which lead to significant degradation of factual knowledge recall for large models. By further decoupling model known and unknown knowledge, we find the degradation is attributed to exemplars that contradict a model's known knowledge, as well as the number of such exemplars. Lastly, we fine-tune LLaMA-7B in different settings of known and unknown knowledge. In particular, fine-tuning on a model's known knowledge is beneficial, and consistently outperforms fine-tuning on unknown and mixed knowledge. We will make our benchmark publicly available.",
    "pdf_link": "https://arxiv.org/abs/2404.16164",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）在众多自然语言处理（NLP）任务上展现了卓越性能，并迅速被应用于多种场景。全面评估其输出内容的真实性极为重要，以应对生成幻觉这一棘手问题。本研究着眼于分析LLMs回忆预训练阶段学习到的事实知识的能力及其影响因素。为此，我们开发了FACT-BENCH，一个涵盖20个领域、134种属性类型、3种答案类型以及不同知识知名度水平的基准测试。我们对10个模型家族的31个模型进行了全面评估，揭示了它们的优势与不足。研究发现，指令调整对知识回忆有负面影响，因为仅经过预训练的模型总是比经过指令调整的模型表现更好；同时，模型规模的扩大对性能有积极影响，大型模型在所有家族中均优于小型模型。但即便是GPT-4的最佳表现，与最佳性能仍有较大差距。我们还探讨了上下文示例在反事实演示中的作用，发现这会导致大型模型的事实知识回忆能力显著下降。进一步分析表明，这种下降是由于与模型已知知识相冲突的示例以及这类示例的数量所导致的。最后，我们在已知和未知知识的不同设置下对LLaMA-7B进行了微调，发现针对模型已知知识的微调尤其有益，其性能一致超越了针对未知和混合知识进行的微调。我们将向公众开放这一基准测试。",
    "title_cn": "迈向对大型语言模型在事实知识记忆能力上的全面评估",
    "tags": [
      "LLM应用",
      "",
      "基准测试"
    ]
  },
  {
    "title": "Domain-Specific Improvement on Psychotherapy Chatbot Using Assistant",
    "submit_datetime": "2024年04月24日",
    "abstract": "Large language models (LLMs) have demonstrated impressive generalization capabilities on specific tasks with human-written instruction data. However, the limited quantity, diversity, and professional expertise of such instruction data raise concerns about the performance of LLMs in psychotherapy tasks when provided with domain-specific instructions. To address this, we firstly propose Domain-Specific Assistant Instructions based on AlexanderStreet therapy, and secondly, we use an adaption fine-tuning method and retrieval augmented generation method to improve pre-trained LLMs. Through quantitative evaluation of linguistic quality using automatic and human evaluation, we observe that pre-trained LLMs on Psychotherapy Assistant Instructions outperform state-of-the-art LLMs response baselines. Our Assistant-Instruction approach offers a half-annotation method to align pre-trained LLMs with instructions and provide pre-trained LLMs with more psychotherapy knowledge.",
    "pdf_link": "https://arxiv.org/abs/2404.16160",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）在特定任务上展现出卓越的泛化能力，尤其是在接收到人类编写的指令数据时。但现有指令数据的数量、多样性和专业深度的不足，让人对LLMs在心理治疗领域的应用效果存疑，尤其是在面对特定领域的指导时。为此，我们首先基于AlexanderStreet治疗资料，提出了一套针对性的助理指令；其次，通过采用适应性微调和检索增强生成技术，对预训练的LLMs进行了优化。通过自动和人工评估对语言质量的定量分析，我们发现，这些针对心理治疗助理指令预训练的LLMs在响应上超越了当前最顶尖的LLMs。我们的这种方法为预训练的LLMs提供了一种半注释手段，使其更好地与指令相匹配，并赋予了它们更丰富的心理治疗知识。",
    "title_cn": "借助助手，对心理治疗聊天机器人进行专业领域的优化提升。",
    "tags": [
      "LLM应用",
      "心理治疗",
      "人工智能"
    ]
  },
  {
    "title": "The Feasibility of Implementing Large-Scale Transformers on Multi-FPGA Platforms",
    "submit_datetime": "2024年04月24日",
    "abstract": "FPGAs are rarely mentioned when discussing the implementation of large machine learning applications, such as Large Language Models (LLMs), in the data center. There has been much evidence showing that single FPGAs can be competitive with GPUs in performance for some computations, especially for low latency, and often much more efficient when power is considered. This suggests that there is merit to exploring the use of multiple FPGAs for large machine learning applications. The challenge with using multiple FPGAs is that there is no commonly-accepted flow for developing and deploying multi-FPGA applications, i.e., there are no tools to describe a large application, map it to multiple FPGAs and then deploy the application on a multi-FPGA platform. In this paper, we explore the feasibility of implementing large transformers using multiple FPGAs by developing a scalable multi-FPGA platform and some tools to map large applications to the platform. We validate our approach by designing an efficient multi-FPGA version of the I-BERT transformer and implement one encoder using six FPGAs as a working proof-of-concept to show that our platform and tools work. Based on our proof-of-concept prototype and the estimations of performance using the latest FPGAs compared to GPUs, we conclude that there can be a place for FPGAs in the world of large machine learning applications. We demonstrate a promising first step that shows that with the right infrastructure and tools it is reasonable to continue to explore the possible benefits of using FPGAs for applications such as LLMs.",
    "pdf_link": "https://arxiv.org/abs/2404.16158",
    "graphs": [],
    "abstract_cn": "在数据中心部署大型机器学习应用，如大型语言模型（LLMs），通常不会提及现场可编程门阵列（FPGA）。然而，有证据显示，单个FPGA在某些计算任务上的性能可与GPU媲美，尤其在低延迟计算上，且在能耗效率上往往更胜一筹。这一发现激励我们考虑利用多个FPGA来执行大型机器学习任务。面临的挑战在于，目前缺乏一套广泛接受的开发和部署多FPGA应用的流程，也就是说，缺少能够描述、映射并部署大型应用到多FPGA平台的工具。本文中，我们探讨了利用多个FPGA实现大型变换器的可能性，包括开发一个可扩展的多FPGA平台和相应的映射工具。我们通过设计高效的多FPGA版本的I-BERT变换器，并用六个FPGA实现一个编码器作为实际概念验证，来验证我们的方法。根据我们的概念验证原型以及与GPU相比的最新FPGA性能估算，我们得出结论，FPGA在大型机器学习应用领域确实有其一席之地。我们的初步成果表明，只要有合适的基础设施和工具，进一步探索FPGA在LLMs等应用中的潜在优势是值得的。",
    "title_cn": "探讨在多 FPGA 平台上部署大型变换器的可能性",
    "tags": [
      "LLM应用",
      "数据中心",
      "机器学习"
    ]
  },
  {
    "title": "Chat2Scenario: Scenario Extraction From Dataset Through Utilization of Large Language Model",
    "submit_datetime": "2024年04月24日",
    "abstract": "The advent of Large Language Models (LLM) provides new insights to validate Automated Driving Systems (ADS). In the herein-introduced work, a novel approach to extracting scenarios from naturalistic driving datasets is presented. A framework called Chat2Scenario is proposed leveraging the advanced Natural Language Processing (NLP) capabilities of LLM to understand and identify different driving scenarios. By inputting descriptive texts of driving conditions and specifying the criticality metric thresholds, the framework efficiently searches for desired scenarios and converts them into ASAM OpenSCENARIO and IPG CarMaker text files. This methodology streamlines the scenario extraction process and enhances efficiency. Simulations are executed to validate the efficiency of the approach. The framework is presented based on a user-friendly web app and is accessible via the following link: https://github.com/ftgTUGraz/Chat2Scenario.",
    "pdf_link": "https://arxiv.org/abs/2404.16147",
    "graphs": [],
    "abstract_cn": "随着大型语言模型（LLM）的兴起，我们获得了验证自动驾驶系统（ADS）的新视角。本研究提出了一种创新的方法，用于从自然驾驶数据集中提炼出各种驾驶场景。我们引入了一个名为Chat2Scenario的框架，该框架借助LLM的先进自然语言处理（NLP）技术，来理解并识别多样化的驾驶情境。用户只需输入关于驾驶环境的描述，并设定关键性指标的阈值，框架便能高效地筛选并锁定目标场景，进而将这些场景转换成ASAM OpenSCENARIO和IPG CarMaker格式的文本文件。这一流程不仅简化了场景提取工作，还显著提升了工作效率。为了验证此方法的有效性，我们进行了一系列的仿真测试。Chat2Scenario框架以一个易于操作的Web应用形式呈现，并通过以下链接向公众开放：https://github.com/ftgTUGraz/Chat2Scenario。",
    "title_cn": "Chat2Scenario：利用大型语言模型从数据集中提炼场景",
    "tags": [
      "分类：LLM应用\n\n这篇论文摘要描述了一种利用大型语言模型（LLM）的自然语言处理（NLP）技术，从自然驾驶数据集中提炼出各种驾驶场景的方法。这种方法被称为Chat2Scenario框架，它允许用户输入关于驾驶环境的描述，并根据关键性指标的阈值来筛选和锁定目标场景。然后将这些场景转换成特定格式的文本文件，以便于自动驾驶系统（ADS）的验证。这篇论文的焦点在于应用LLM技术来解决实际问题，因此它应该被归类为LLM应用。",
      "自动驾驶",
      ""
    ]
  },
  {
    "title": "From Local to Global: A Graph RAG Approach to Query-Focused Summarization",
    "submit_datetime": "2024年04月24日",
    "abstract": "The use of retrieval-augmented generation (RAG) to retrieve relevant information from an external knowledge source enables large language models (LLMs) to answer questions over private and/or previously unseen document collections. However, RAG fails on global questions directed at an entire text corpus, such as \"What are the main themes in the dataset?\", since this is inherently a query-focused summarization (QFS) task, rather than an explicit retrieval task. Prior QFS methods, meanwhile, fail to scale to the quantities of text indexed by typical RAG systems. To combine the strengths of these contrasting methods, we propose a Graph RAG approach to question answering over private text corpora that scales with both the generality of user questions and the quantity of source text to be indexed. Our approach uses an LLM to build a graph-based text index in two stages: first to derive an entity knowledge graph from the source documents, then to pregenerate community summaries for all groups of closely-related entities. Given a question, each community summary is used to generate a partial response, before all partial responses are again summarized in a final response to the user. For a class of global sensemaking questions over datasets in the 1 million token range, we show that Graph RAG leads to substantial improvements over a naïve RAG baseline for both the comprehensiveness and diversity of generated answers. An open-source, Python-based implementation of both global and local Graph RAG approaches is forthcoming at https://aka.ms/graphrag.",
    "pdf_link": "https://arxiv.org/abs/2404.16130",
    "graphs": [],
    "abstract_cn": "通过检索增强生成（RAG）技术，大型语言模型（LLMs）能够从外部知识库中检索信息，从而回答涉及私人或未见过的文档集合的问题。但面对针对整个文本集合的全局性问题，如“数据集中的主要主题有哪些？”，RAG 显得无能为力，因为这实际上是一个查询聚焦的摘要任务，而非简单的检索任务。传统的查询聚焦摘要方法也因无法扩展至 RAG 系统所索引的大量文本而受限。为了融合这些方法的优势，我们提出了一种基于图的 RAG 方法，它能够适应私人文本语料库的问答需求，同时满足用户问题的广泛性和源文本数量的扩展性。该方法利用 LLM 分两步构建基于图的文本索引：首先从源文档中提取实体知识图谱，然后为所有紧密相关的实体群体预生成社区摘要。面对问题时，每个社区摘要用于生成部分答案，所有部分答案再汇总成最终回答。在处理大约百万个令牌规模的数据集上的全局性理解问题时，我们证明了图 RAG 在答案的全面性和多样性上相较于传统 RAG 有显著提升。相关的开源 Python 实现，包括全局和本地图 RAG 方法，即将在 https://aka.ms/graphrag 发布。",
    "title_cn": "探索全局视角：图卷积RAG技术在查询导向摘要中的应用。",
    "tags": [
      "RAG",
      "信息检索",
      ""
    ]
  },
  {
    "title": "Studying Large Language Model Behaviors Under Realistic Knowledge Conflicts",
    "submit_datetime": "2024年04月24日",
    "abstract": "Retrieval-augmented generation (RAG) mitigates many problems of fully parametric language models, such as temporal degradation, hallucinations, and lack of grounding. In RAG, the model's knowledge can be updated from documents provided in context. This leads to cases of conflict between the model's parametric knowledge and the contextual information, where the model may not always update its knowledge. Previous work studied knowledge conflicts by creating synthetic documents that contradict the model's correct parametric answers. We present a framework for studying knowledge conflicts in a realistic setup. We update incorrect parametric knowledge using real conflicting documents. This reflects how knowledge conflicts arise in practice. In this realistic scenario, we find that knowledge updates fail less often than previously reported. In cases where the models still fail to update their answers, we find a parametric bias: the incorrect parametric answer appearing in context makes the knowledge update likelier to fail. These results suggest that the factual parametric knowledge of LLMs can negatively influence their reading abilities and behaviors. Our code is available at https://github.com/kortukov/realistic_knowledge_conflicts/.",
    "pdf_link": "https://arxiv.org/abs/2404.16032",
    "graphs": [],
    "abstract_cn": "检索增强生成（RAG）有效解决了全参数化语言模型的诸多难题，如信息过时、产生幻觉和缺乏事实依据。在RAG框架下，模型能够根据提供的文档上下文更新其知识库。然而，这也可能引发模型内部参数知识与文档上下文信息的冲突，有时模型未必会选择更新知识。先前研究通过构建与模型正确参数答案相冲突的合成文档来探讨这类知识冲突。本研究提出了一个更贴近现实的框架，利用真实存在的冲突文档来修正模型中的错误参数知识，从而更真实地模拟知识冲突的产生过程。研究发现，在现实情境中，知识更新的失败率低于先前研究的报告。当模型未能更新答案时，存在一种参数偏好：如果错误的参数答案出现在上下文中，知识更新更可能失败。这些发现暗示大型语言模型（LLMs）的事实性参数知识可能会对其阅读理解和行为模式产生不利影响。相关代码已在 https://github.com/kortukov/realistic_knowledge_conflicts/ 上公开。",
    "title_cn": "探究现实知识冲突情境下大型语言模型的表现",
    "tags": [
      "分类：RAG",
      "",
      "机器学习"
    ]
  },
  {
    "title": "Telco-RAG: Navigating the Challenges of Retrieval-Augmented Language Models for Telecommunications",
    "submit_datetime": "2024年04月24日",
    "abstract": "The application of Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) systems in the telecommunication domain presents unique challenges, primarily due to the complex nature of telecom standard documents and the rapid evolution of the field. The paper introduces and open-sources Telco-RAG, a customized RAG framework designed to handle the specific needs of telecommunications standards, particularly 3rd Generation Partnership Project (3GPP) documents. Telco-RAG addresses the critical challenges of implementing a RAG pipeline on highly technical content, paving the way for applying LLMs in telecommunications and offering guidelines for RAG implementation in other technical domains.",
    "pdf_link": "https://arxiv.org/abs/2404.15939",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.15939v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15939/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15939v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15939/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15939v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15939/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15939v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15939/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15939v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15939/x5.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）与检索增强生成（RAG）系统在电信行业的应用遭遇了特殊难题，这主要是因为电信标准文档的复杂性以及该行业的迅猛发展。本文提出了 Telco-RAG，一个为电信标准量身定制的 RAG 框架，专门针对第三代合作伙伴计划（3GPP）等电信文档的需求。Telco-RAG 克服了在技术性极强的内容上部署 RAG 流水线的重大挑战，为 LLMs 在电信领域的应用开拓了新路，并为 RAG 在其他技术性领域的实施提供了宝贵参考。",
    "title_cn": "Telco-RAG：探索电信行业中检索增强语言模型的挑战与应对之道",
    "tags": [
      "分类：RAG",
      "",
      "人工智能"
    ]
  },
  {
    "title": "A Human-Computer Collaborative Tool for Training a Single Large Language Model Agent into a Network through Few Examples",
    "submit_datetime": "2024年04月24日",
    "abstract": "The capabilities of a single large language model (LLM) agent for solving a complex task are limited. Connecting multiple LLM agents to a network can effectively improve overall performance. However, building an LLM agent network (LAN) requires a substantial amount of time and effort. In this paper, we introduce EasyLAN, a human-computer collaborative tool that helps developers construct LANs. EasyLAN initially generates a LAN containing only one agent based on the description of the desired task. Subsequently, EasyLAN leverages a few training examples to update the LAN. For each example, EasyLAN models the gap between the output and the ground truth and identifies the causes of the errors. These errors are addressed through carefully designed strategies. Users can intervene in EasyLAN's workflow or directly modify the LAN. Eventually, the LAN evolves from a single agent to a network of LLM agents. The experimental results indicate that developers can rapidly construct LANs with good performance.",
    "pdf_link": "https://arxiv.org/abs/2404.15974",
    "graphs": [],
    "abstract_cn": "单个大型语言模型（LLM）在处理复杂任务时力有未逮。通过构建大型语言模型代理网络（LAN），将多个LLM代理互联，可以有效提升整体效能。但搭建LAN是一项耗时耗力的工作。本文提出了EasyLAN，这是一个辅助开发者构建LAN的人机协作工具。EasyLAN根据用户对任务的描述，首先创建一个只包含单个代理的初始网络。然后，通过少量训练样本，EasyLAN对网络进行迭代优化，分析输出与标准答案之间的差异，找出并纠正错误。用户可以参与EasyLAN的工作流程，或直接对LAN进行编辑。通过这种方式，LAN逐步从一个单一代理发展成为一个由多个LLM代理组成的网络。实验数据显示，使用EasyLAN，开发者能够迅速搭建出性能优异的LAN。",
    "title_cn": "一种人机协作工具，通过少量示例将单一的大型语言模型训练成为网络的一部分。",
    "tags": [
      "Agent",
      "人工智能",
      ""
    ]
  },
  {
    "title": "KGValidator: A Framework for Automatic Validation of Knowledge Graph Construction",
    "submit_datetime": "2024年04月24日",
    "abstract": "This study explores the use of Large Language Models (LLMs) for automatic evaluation of knowledge graph (KG) completion models. Historically, validating information in KGs has been a challenging task, requiring large-scale human annotation at prohibitive cost. With the emergence of general-purpose generative AI and LLMs, it is now plausible that human-in-the-loop validation could be replaced by a generative agent. We introduce a framework for consistency and validation when using generative models to validate knowledge graphs. Our framework is based upon recent open-source developments for structural and semantic validation of LLM outputs, and upon flexible approaches to fact checking and verification, supported by the capacity to reference external knowledge sources of any kind. The design is easy to adapt and extend, and can be used to verify any kind of graph-structured data through a combination of model-intrinsic knowledge, user-supplied context, and agents capable of external knowledge retrieval.",
    "pdf_link": "https://arxiv.org/abs/2404.15923",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.15923v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15923/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15923v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15923/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15923v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15923/x3.png"
      }
    ],
    "abstract_cn": "本研究着眼于利用大型语言模型（LLMs）自动评估知识图谱（KG）补全模型的应用。传统上，KG中的信息验证是一项成本高昂且充满挑战的任务，需要大量的人工注释。随着通用生成性AI和LLMs的兴起，现在有理由相信可以由生成性代理取代传统的人工验证环节。我们提出了一个框架，用于在采用生成模型进行KG验证时确保一致性和有效性。该框架依托于最新的开源进展，不仅涵盖了对LLMs输出的结构和语义验证，还包括了灵活的事实核查与验证方法，这些方法能够利用各种类型的外部知识源。设计上易于调整和扩展，能够通过结合模型内生知识、用户定义的上下文以及能够进行外部知识检索的代理，来验证各种图形化结构的数据。",
    "title_cn": "KGValidator：一套自动验证知识图谱构建的框架。",
    "tags": [
      "LLM应用",
      "知识图谱",
      "自动化验证"
    ]
  },
  {
    "title": "Automated Social Science: Language Models as Scientist and Subjects",
    "submit_datetime": "2024年04月24日",
    "abstract": "We present an approach for automatically generating and testing, in silico, social scientific hypotheses. This automation is made possible by recent advances in large language models (LLM), but the key feature of the approach is the use of structural causal models. Structural causal models provide a language to state hypotheses, a blueprint for constructing LLM-based agents, an experimental design, and a plan for data analysis. The fitted structural causal model becomes an object available for prediction or the planning of follow-on experiments. We demonstrate the approach with several scenarios: a negotiation, a bail hearing, a job interview, and an auction. In each case, causal relationships are both proposed and tested by the system, finding evidence for some and not others. We provide evidence that the insights from these simulations of social interactions are not available to the LLM purely through direct elicitation. When given its proposed structural causal model for each scenario, the LLM is good at predicting the signs of estimated effects, but it cannot reliably predict the magnitudes of those estimates. In the auction experiment, the in silico simulation results closely match the predictions of auction theory, but elicited predictions of the clearing prices from the LLM are inaccurate. However, the LLM's predictions are dramatically improved if the model can condition on the fitted structural causal model. In short, the LLM knows more than it can (immediately) tell.",
    "pdf_link": "https://arxiv.org/abs/2404.11794",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.11794v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11794/system_overview.jpg"
      },
      {
        "url": "https://arxiv.org/html/2404.11794v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11794/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11794v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11794/example_agents.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11794v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11794/interaction_types.jpg"
      },
      {
        "url": "https://arxiv.org/html/2404.11794v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11794/x2.png"
      }
    ],
    "abstract_cn": "我们展示了一种自动生成并模拟测试社会科学假设的新方法。这一创新得益于大型语言模型（LLM）的突破性进展，但其核心在于结构因果模型的应用。这些模型不仅为我们提供了一种表述假设的方式，还为构建基于LLM的智能体、设计实验和规划数据分析提供了指导。经过拟合的模型进一步成为预测和后续实验规划的有力工具。我们通过多个场景——谈判、保释听证、求职面试和拍卖——来验证这一方法，系统在这些场景中提出并验证了因果关系，发现了一些关系的证据，而对其他关系则持保留态度。研究表明，通过这些模拟获得的对社会互动的洞察，是LLM无法仅通过直接询问得到的。尽管LLM能够准确预测估计效应的方向，但对于效应大小的预测却不够可靠。特别是在拍卖实验中，模拟结果与拍卖理论的预测高度吻合，而LLM直接引出的清算价格预测却存在偏差。但如果LLM能够依据拟合的因果模型进行条件预测，其预测准确度将大幅提升。总之，LLM的潜力远超其直接表达的能力。",
    "title_cn": "自动社会科学：语言模型的双重角色——既是研究者也是研究对象",
    "tags": [
      "LLM应用",
      "社会科学",
      "因果推理"
    ]
  },
  {
    "title": "Demonstration of DB-GPT: Next Generation Data Interaction System Empowered by Large Language Models",
    "submit_datetime": "2024年04月24日",
    "abstract": "The recent breakthroughs in large language models (LLMs) are positioned to transition many areas of software. The technologies of interacting with data particularly have an important entanglement with LLMs as efficient and intuitive data interactions are paramount. In this paper, we present DB-GPT, a revolutionary and product-ready Python library that integrates LLMs into traditional data interaction tasks to enhance user experience and accessibility. DB-GPT is designed to understand data interaction tasks described by natural language and provide context-aware responses powered by LLMs, making it an indispensable tool for users ranging from novice to expert. Its system design supports deployment across local, distributed, and cloud environments. Beyond handling basic data interaction tasks like Text-to-SQL with LLMs, it can handle complex tasks like generative data analysis through a Multi-Agents framework and the Agentic Workflow Expression Language (AWEL). The Service-oriented Multi-model Management Framework (SMMF) ensures data privacy and security, enabling users to employ DB-GPT with private LLMs. Additionally, DB-GPT offers a series of product-ready features designed to enable users to integrate DB-GPT within their product environments easily. The code of DB-GPT is available at Github(https://github.com/eosphoros-ai/DB-GPT) which already has over 10.7k stars. Please install DB-GPT for your own usage with the instructions(https://github.com/eosphoros-ai/DB-GPT#install) and watch a 5-minute introduction video on Youtube(https://youtu.be/n_8RI1ENyl4) to further investigate DB-GPT.",
    "pdf_link": "https://arxiv.org/abs/2404.10209",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.10209v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10209/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10209v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10209/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10209v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10209/x3.png"
      }
    ],
    "abstract_cn": "近期大型语言模型（LLMs）的创新进展，预示着软件行业的多领域将迎来变革。在这一变革中，与数据互动的技术尤为关键，它需要既高效又易于操作。本文介绍了DB-GPT，这是一款创新且即用型的Python库，它将LLMs融入到日常的数据交互流程中，旨在提升用户互动体验和操作便捷性。DB-GPT能够理解用自然语言描述的数据交互任务，并借助LLMs提供充满上下文感知的响应，无论是新手还是资深用户都能从中获益。该库的系统架构支持本地、分布式及云端环境的部署。DB-GPT不仅能够处理Text-to-SQL等基础数据交互任务，还能通过多代理框架和代理工作流表达语言（AWEL）来执行复杂的生成性数据分析任务。此外，面向服务的多模型管理框架（SMMF）确保了数据的隐私与安全，让用户能够安心使用私人LLMs。DB-GPT还提供了一系列即用型特性，方便用户轻松将其集成到产品生态中。感兴趣的用户可以在Github上找到DB-GPT的代码（https://github.com/eosphoros-ai/DB-GPT），项目已获得超过10.7k的星标认可。按照提供的指南（https://github.com/eosphoros-ai/DB-GPT#install）安装DB-GPT，并通过Youtube上的5分钟介绍视频（https://youtu.be/n_8RI1ENyl4）深入了解这款工具。",
    "title_cn": "展示 DB-GPT：新一代数据交互系统，由先进的大型语言模型提供支持。",
    "tags": [
      "LLM应用",
      "软件工程",
      "数据科学"
    ]
  },
  {
    "title": "Cantor: Inspiring Multimodal Chain-of-Thought of MLLM",
    "submit_datetime": "2024年04月24日",
    "abstract": "With the advent of large language models(LLMs) enhanced by the chain-of-thought(CoT) methodology, visual reasoning problem is usually decomposed into manageable sub-tasks and tackled sequentially with various external tools. However, such a paradigm faces the challenge of the potential \"determining hallucinations\" in decision-making due to insufficient visual information and the limitation of low-level perception tools that fail to provide abstract summaries necessary for comprehensive reasoning. We argue that converging visual context acquisition and logical reasoning is pivotal for tackling visual reasoning tasks. This paper delves into the realm of multimodal CoT to solve intricate visual reasoning tasks with multimodal large language models(MLLMs) and their cognitive capability. To this end, we propose an innovative multimodal CoT framework, termed Cantor, characterized by a perception-decision architecture. Cantor first acts as a decision generator and integrates visual inputs to analyze the image and problem, ensuring a closer alignment with the actual context. Furthermore, Cantor leverages the advanced cognitive functions of MLLMs to perform as multifaceted experts for deriving higher-level information, enhancing the CoT generation process. Our extensive experiments demonstrate the efficacy of the proposed framework, showing significant improvements in multimodal CoT performance across two complex visual reasoning datasets, without necessitating fine-tuning or ground-truth rationales. Project Page: https://ggg0919.github.io/cantor/ .",
    "pdf_link": "https://arxiv.org/abs/2404.16033",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.16033v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16033/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16033v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16033/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16033v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16033/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16033v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16033/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16033v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16033/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16033v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16033/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16033v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16033/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16033v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16033/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16033v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16033/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16033v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16033/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16033v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16033/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16033v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16033/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16033v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16033/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16033v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16033/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16033v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16033/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16033v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16033/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2404.16033v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.16033/x18.png"
      }
    ],
    "abstract_cn": "随着思维链（CoT）方法加持的大型语言模型（LLMs）的出现，视觉推理问题被细化为易于管理的子任务，并借助多种外部工具逐步攻克。然而，这种模式在决策过程中可能会遇到“确定性幻觉”的问题，这源于视觉信息的不足以及低级感知工具无法提供进行综合推理所需的抽象总结。本文强调，将视觉上下文获取与逻辑推理相结合，对于解决视觉推理任务至关重要。本研究深入探讨了利用多模态大型语言模型（MLLMs）及其认知能力来解决复杂视觉推理任务的多模态CoT领域。我们提出了一个创新的多模态CoT框架——Cantor，它采用感知-决策架构。Cantor首先作为决策生成器，整合视觉输入以分析图像和问题，确保与实际情境的紧密结合。此外，Cantor还利用MLLMs的高级认知功能，充当多面手专家，以获取更高层次的信息，从而提升CoT生成过程。我们广泛的实验验证了所提框架的有效性，显示出在两个复杂的视觉推理数据集上，多模态CoT性能有了显著提升，且无需进行微调或依赖真实理由。项目页面：https://ggg0919.github.io/cantor/ 。",
    "title_cn": "Cantor：激发机器学习大型语言模型（MLLM）的多模态思维链",
    "tags": [
      "分类：LLM应用",
      "视觉推理",
      "人工智能"
    ]
  },
  {
    "title": "MMT-Bench: A Comprehensive Multimodal Benchmark for Evaluating Large Vision-Language Models Towards Multitask AGI",
    "submit_datetime": "2024年04月24日",
    "abstract": "Large Vision-Language Models (LVLMs) show significant strides in general-purpose multimodal applications such as visual dialogue and embodied navigation. However, existing multimodal evaluation benchmarks cover a limited number of multimodal tasks testing rudimentary capabilities, falling short in tracking LVLM development. In this study, we present MMT-Bench, a comprehensive benchmark designed to assess LVLMs across massive multimodal tasks requiring expert knowledge and deliberate visual recognition, localization, reasoning, and planning. MMT-Bench comprises $31,325$ meticulously curated multi-choice visual questions from various multimodal scenarios such as vehicle driving and embodied navigation, covering $32$ core meta-tasks and $162$ subtasks in multimodal understanding. Due to its extensive task coverage, MMT-Bench enables the evaluation of LVLMs using a task map, facilitating the discovery of in- and out-of-domain tasks. Evaluation results involving $30$ LVLMs such as the proprietary GPT-4V, GeminiProVision, and open-sourced InternVL-Chat, underscore the significant challenges posed by MMT-Bench. We anticipate that MMT-Bench will inspire the community to develop next-generation multimodal foundation models aimed at achieving general-purpose multimodal intelligence.",
    "pdf_link": "https://arxiv.org/abs/2404.16006",
    "graphs": [],
    "abstract_cn": "大型视觉-语言模型（LVLMs）在多模态应用领域取得突破性进展，尤其在视觉对话和具身导航等通用任务中表现卓越。但现行的多模态评估标准仅覆盖了有限的多模态任务，主要测试基础能力，未能全面反映LVLMs的发展水平。本研究提出了MMT-Bench，这是一个全新的全面基准测试，用以评估LVLMs在一系列需要专业知识和深入视觉识别、定位、推理及规划能力的大规模多模态任务上的表现。MMT-Bench精心挑选了31,325道多项选择视觉问题，这些问题源自包括车辆驾驶和具身导航在内的多种多模态场景，覆盖了32个核心元任务和162个子任务。其广泛的任务覆盖范围使得MMT-Bench能够通过任务地图对LVLMs进行评估，帮助发现领域内和领域外的任务。对包括GPT-4V、GeminiProVision和InternVL-Chat在内的30个LVLMs的评估结果显示，MMT-Bench提出了重大挑战。我们期望MMT-Bench能够激发社区开发下一代多模态基础模型，以实现更广泛的多模态智能目标。",
    "title_cn": "MMT-Bench 是一个全面的多模态基准测试平台，旨在评估大型视觉-语言模型在实现多任务人工通用智能（AGI）方面的性能。",
    "tags": [
      "LLM应用",
      "多模态学习",
      "人工智能评估"
    ]
  },
  {
    "title": "Leveraging Large Language Models for Multimodal Search",
    "submit_datetime": "2024年04月24日",
    "abstract": "Multimodal search has become increasingly important in providing users with a natural and effective way to ex-press their search intentions. Images offer fine-grained details of the desired products, while text allows for easily incorporating search modifications. However, some existing multimodal search systems are unreliable and fail to address simple queries. The problem becomes harder with the large variability of natural language text queries, which may contain ambiguous, implicit, and irrelevant in-formation. Addressing these issues may require systems with enhanced matching capabilities, reasoning abilities, and context-aware query parsing and rewriting. This paper introduces a novel multimodal search model that achieves a new performance milestone on the Fashion200K dataset. Additionally, we propose a novel search interface integrating Large Language Models (LLMs) to facilitate natural language interaction. This interface routes queries to search systems while conversationally engaging with users and considering previous searches. When coupled with our multimodal search model, it heralds a new era of shopping assistants capable of offering human-like interaction and enhancing the overall search experience.",
    "pdf_link": "https://arxiv.org/abs/2404.15790",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.15790v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15790/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15790v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15790/success.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15790v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15790/failures.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15790v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15790/demo_example.png"
      }
    ],
    "abstract_cn": "多模态搜索正日益成为用户表达搜索意图的自然而有效手段。图片能展示产品细节，文本便于搜索调整。但现有多模态搜索系统在处理简单查询时表现不稳定，且面对多样化的自然语言查询，这些查询可能含糊、隐晦或包含无关内容，系统面临更大挑战。要解决这些问题，系统需具备更强大的匹配、推理能力和能够感知上下文的查询解析及重写功能。本文提出的新型多模态搜索模型在Fashion200K数据集上创下了新的性能记录。我们还设计了一种新颖的搜索界面，整合了大型语言模型（LLMs），以便更自然地与用户互动。该界面在与用户对话的同时，会考虑用户之前的搜索记录，并将查询引导至搜索系统。结合我们的多模态搜索模型，它预示着购物助手将迈入一个新时代，能够提供更人性化的互动和更优的搜索体验。",
    "title_cn": "通过大型语言模型实现多模态搜索的潜力挖掘。",
    "tags": [
      "LLM应用",
      "电子商务",
      "搜索技术"
    ]
  },
  {
    "title": "Describe-then-Reason: Improving Multimodal Mathematical Reasoning through Visual Comprehension Training",
    "submit_datetime": "2024年04月24日",
    "abstract": "Open-source multimodal large language models (MLLMs) excel in various tasks involving textual and visual inputs but still struggle with complex multimodal mathematical reasoning, lagging behind proprietary models like GPT-4V(ision) and Gemini-Pro. Although fine-tuning with intermediate steps (i.e., rationales) elicits some mathematical reasoning skills, the resulting models still fall short in visual comprehension due to inadequate visual-centric supervision, which leads to inaccurate interpretation of math figures. To address this issue, we propose a two-step training pipeline VCAR, which emphasizes the Visual Comprehension training in Addition to mathematical Reasoning learning. It first improves the visual comprehension ability of MLLMs through the visual description generation task, followed by another training step on generating rationales with the assistance of descriptions. Experimental results on two popular benchmarks demonstrate that VCAR substantially outperforms baseline methods solely relying on rationale supervision, especially on problems with high visual demands.",
    "pdf_link": "https://arxiv.org/abs/2404.14604",
    "graphs": [],
    "abstract_cn": "开源的多模态大型语言模型（MLLMs）在处理文本和视觉输入的任务上表现优异，但面对复杂的多模态数学推理挑战时，相较于 GPT-4V(ision) 和 Gemini-Pro 等专有模型，仍显不足。尽管通过细化中间步骤（理由）的微调能够提升一定的数学推理能力，但现有模型在视觉理解上仍有欠缺，主要是由于缺乏针对视觉的充分指导，这导致了对数学图表的解读不够精准。为应对这一挑战，我们设计了 VCAR，一个两阶段训练流程，特别强化了数学推理之外的视觉理解能力。该流程首先通过视觉描述生成任务增强 MLLMs 的视觉理解力，随后进行第二阶段训练，即在已有描述的基础上生成理由。在两个广泛认可的基准测试中，VCAR 的表现显著超过了仅依赖理由指导的基线方法，特别是在视觉需求较高的问题上。",
    "title_cn": "通过视觉理解训练提升多模态数学推理“描述然后推理”：这一方法通过增强视觉理解训练，显著提升了处理多模态数学问题推理的能力。",
    "tags": [
      "分类：LLM应用",
      "教育技术",
      "人工智能"
    ]
  },
  {
    "title": "Zero-Shot Character Identification and Speaker Prediction in Comics via Iterative Multimodal Fusion",
    "submit_datetime": "2024年04月24日",
    "abstract": "Recognizing characters and predicting speakers of dialogue are critical for comic processing tasks, such as voice generation or translation. However, because characters vary by comic title, supervised learning approaches like training character classifiers which require specific annotations for each comic title are infeasible. This motivates us to propose a novel zero-shot approach, allowing machines to identify characters and predict speaker names based solely on unannotated comic images. In spite of their importance in real-world applications, these task have largely remained unexplored due to challenges in story comprehension and multimodal integration. Recent large language models (LLMs) have shown great capability for text understanding and reasoning, while their application to multimodal content analysis is still an open problem. To address this problem, we propose an iterative multimodal framework, the first to employ multimodal information for both character identification and speaker prediction tasks. Our experiments demonstrate the effectiveness of the proposed framework, establishing a robust baseline for these tasks. Furthermore, since our method requires no training data or annotations, it can be used as-is on any comic series.",
    "pdf_link": "https://arxiv.org/abs/2404.13993",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.13993v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13993/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13993v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13993/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13993v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13993/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13993v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13993/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13993v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13993/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13993v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13993/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13993v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13993/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13993v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13993/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13993v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13993/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13993v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13993/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13993v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13993/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13993v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13993/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13993v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13993/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13993v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13993/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13993v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13993/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13993v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13993/zeroshot_1.jpg"
      },
      {
        "url": "https://arxiv.org/html/2404.13993v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13993/zeroshot_2.jpg"
      },
      {
        "url": "https://arxiv.org/html/2404.13993v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13993/zeroshot_3.jpg"
      }
    ],
    "abstract_cn": "漫画处理任务，如声音生成或翻译，对角色识别和对话中说话者的预测极为关键。然而，由于角色随漫画标题的不同而变化，传统的监督学习方法，如训练需要特定标注的角色分类器，变得不切实际。为此，我们提出了一种创新的零样本方法，使机器能够仅通过未标注的漫画图像来识别角色和预测说话者的名字。尽管这些任务在现实世界的应用中极为重要，但由于故事理解的挑战和多模态整合的复杂性，它们至今未被充分研究。最新的大型语言模型（LLMs）在文本理解和推理方面展现了强大的能力，但其在多模态内容分析上的应用仍然是一个待解决的问题。为应对这一挑战，我们设计了一个迭代的多模态框架，首次将多模态信息应用于角色识别和说话者预测。我们的实验显示，该框架不仅有效，而且为这些任务设定了一个坚实的基准。更重要的是，由于该方法无需训练数据或标注，它可以无缝应用于任何漫画系列。",
    "title_cn": "本研究采用迭代多模态融合技术，实现了在漫画领域无需先验样本即可进行角色识别和说话者预测的创新方法。",
    "tags": [
      "分类：LLM应用",
      "漫画处理",
      ""
    ]
  },
  {
    "title": "Eyes Can Deceive: Benchmarking Counterfactual Reasoning Abilities of Multi-modal Large Language Models",
    "submit_datetime": "2024年04月24日",
    "abstract": "Counterfactual reasoning, as a crucial manifestation of human intelligence, refers to making presuppositions based on established facts and extrapolating potential outcomes. Existing multimodal large language models (MLLMs) have exhibited impressive cognitive and reasoning capabilities, which have been examined across a wide range of Visual Question Answering (VQA) benchmarks. Nevertheless, how will existing MLLMs perform when faced with counterfactual questions? To answer this question, we first curate a novel \\textbf{C}ounter\\textbf{F}actual \\textbf{M}ulti\\textbf{M}odal reasoning benchmark, abbreviated as \\textbf{CFMM}, to systematically assess the counterfactual reasoning capabilities of MLLMs. Our CFMM comprises six challenging tasks, each including hundreds of carefully human-labeled counterfactual questions, to evaluate MLLM's counterfactual reasoning capabilities across diverse aspects. Through experiments, interestingly, we find that existing MLLMs prefer to believe what they see, but ignore the counterfactual presuppositions presented in the question, thereby leading to inaccurate responses. Furthermore, we evaluate a wide range of prevalent MLLMs on our proposed CFMM. The significant gap between their performance on our CFMM and that on several VQA benchmarks indicates that there is still considerable room for improvement in existing MLLMs toward approaching human-level intelligence. On the other hand, through boosting MLLMs performances on our CFMM in the future, potential avenues toward developing MLLMs with advanced intelligence can be explored.",
    "pdf_link": "https://arxiv.org/abs/2404.12966",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.12966v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12966/intro.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12966v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12966/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12966v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12966/exps.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12966v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12966/x2.png"
      }
    ],
    "abstract_cn": "反事实推理是人类智慧的关键体现，它涉及基于确凿事实提出假设并推演可能的结果。目前，多模态大型语言模型（MLLMs）在视觉问答（VQA）的多项基准测试中已展现出卓越的认知和推理技能。但当这些模型遭遇反事实问题时，它们的表现又将如何？为解答这一疑问，我们首次构建了一个名为CFMM的反事实多模态推理基准，旨在全面评估MLLMs的反事实推理能力。CFMM包含六项挑战性任务，每个任务都涵盖了数百个精心设计的反事实问题，用以多角度评价MLLMs的推理技能。实验结果显示，现有MLLMs倾向于信赖直观所见，却忽视了问题中提出的反事实前提，这导致了反应的不精确性。此外，我们在CFMM上对多种主流MLLMs进行了评估，发现它们在CFMM上的表现与VQA基准测试有显著差异，这表明MLLMs在达到人类智能水平方面还有很大的提升空间。展望未来，通过提升MLLMs在CFMM上的表现，我们有望探索出发展更高级智能MLLMs的潜在路径。",
    "title_cn": "眼睛或有误导：评估多模态大型语言模型的反事实推理能力。",
    "tags": [
      "分类：LLM应用\n\n这篇论文讨论了多模态大型语言模型（MLLMs）在处理反事实问题时的表现，并构建了一个名为CFMM的反事实多模态推理基准来评估MLLMs的反事实推理能力。这表明论文关注的是大型语言模型（LLM）在特定应用场景（即反事实推理）下的表现和潜在改进，因此将其归类为LLM应用。",
      "人工智能",
      "视觉问答"
    ]
  },
  {
    "title": "BLINK: Multimodal Large Language Models Can See but Not Perceive",
    "submit_datetime": "2024年04月24日",
    "abstract": "We introduce Blink, a new benchmark for multimodal language models (LLMs) that focuses on core visual perception abilities not found in other evaluations. Most of the Blink tasks can be solved by humans \"within a blink\" (e.g., relative depth estimation, visual correspondence, forensics detection, and multi-view reasoning). However, we find these perception-demanding tasks cast significant challenges for current multimodal LLMs because they resist mediation through natural language. Blink reformats 14 classic computer vision tasks into 3,807 multiple-choice questions, paired with single or multiple images and visual prompting. While humans get 95.70% accuracy on average, Blink is surprisingly challenging for existing multimodal LLMs: even the best-performing GPT-4V and Gemini achieve accuracies of 51.26% and 45.72%, only 13.17% and 7.63% higher than random guessing, indicating that such perception abilities have not \"emerged\" yet in recent multimodal LLMs. Our analysis also highlights that specialist CV models could solve these problems much better, suggesting potential pathways for future improvements. We believe Blink will stimulate the community to help multimodal LLMs catch up with human-level visual perception.",
    "pdf_link": "https://arxiv.org/abs/2404.12390",
    "graphs": [],
    "abstract_cn": "我们推出了 Blink，这是一项针对多模态语言模型（LLMs）的新基准测试，旨在测试其他评测中未涉及的核心视觉感知技能。这些任务，如相对深度估计、视觉匹配、法医侦查和多视角推理，人类都能在瞬间解决。然而，我们发现这些对视觉感知要求极高的任务对当前的多模态 LLMs 构成了显著挑战，因为它们不容易通过自然语言来处理。Blink 将 14 个经典计算机视觉任务转化为 3,807 道多项选择题，每题都配有一张或多张图片和视觉提示。尽管人类平均正确率高达 95.70%，但 Blink 对现有多模态 LLMs 来说却颇具挑战性：即便是表现最佳的 GPT-4V 和 Gemini，准确率也仅为 51.26% 和 45.72%，仅比随机猜测高出 13.17% 和 7.63%，这表明这些感知技能在最新的多模态 LLMs 中尚未“显现”。我们的分析还指出，专业的计算机视觉模型能更好地解决这些问题，这为未来的提升指明了可能的方向。我们相信 Blink 将激励业界共同努力，推动多模态 LLMs 的视觉感知能力向人类水平看齐。",
    "title_cn": "BLINK：虽然多模态的大型语言模型具备视觉识别能力，但它们却无法实现深层次的感知理解。",
    "tags": [
      "LLM应用",
      "计算机视觉",
      "人工智能"
    ]
  },
  {
    "title": "Attacks on Third-Party APIs of Large Language Models",
    "submit_datetime": "2024年04月24日",
    "abstract": "Large language model (LLM) services have recently begun offering a plugin ecosystem to interact with third-party API services. This innovation enhances the capabilities of LLMs, but it also introduces risks, as these plugins developed by various third parties cannot be easily trusted. This paper proposes a new attacking framework to examine security and safety vulnerabilities within LLM platforms that incorporate third-party services. Applying our framework specifically to widely used LLMs, we identify real-world malicious attacks across various domains on third-party APIs that can imperceptibly modify LLM outputs. The paper discusses the unique challenges posed by third-party API integration and offers strategic possibilities to improve the security and safety of LLM ecosystems moving forward. Our code is released at https://github.com/vk0812/Third-Party-Attacks-on-LLMs.",
    "pdf_link": "https://arxiv.org/abs/2404.16891",
    "graphs": [],
    "abstract_cn": "近期，大型语言模型（LLM）服务推出了插件生态系统，以便与第三方API服务进行互动，这不仅扩展了LLM的功能，也带来了安全隐患，因为这些第三方插件的可信度难以保证。本研究提出了一种新的攻击框架，旨在探究整合了第三方服务的LLM平台的安全与安全隐患。通过将该框架应用于多个广泛使用的LLM，我们发现了多个领域中的第三方API所遭受的真实世界恶意攻击，这些攻击能够悄无声息地改变LLM的输出结果。文章深入讨论了第三方API整合所带来的独特挑战，并提出了提升LLM生态系统未来安全性与安全性的战略性建议。相关代码已在 https://github.com/vk0812/Third-Party-Attacks-on-LLMs 上公开。",
    "title_cn": "针对大型语言模型第三方接口的攻击",
    "tags": [
      "LLM应用",
      "网络安全",
      "人工智能"
    ]
  },
  {
    "title": "Scaling Lifelong Multi-Agent Path Finding to More Realistic Settings: Research Challenges and Opportunities",
    "submit_datetime": "2024年04月24日",
    "abstract": "Multi-Agent Path Finding (MAPF) is the problem of moving multiple agents from starts to goals without collisions. Lifelong MAPF (LMAPF) extends MAPF by continuously assigning new goals to agents. We present our winning approach to the 2023 League of Robot Runners LMAPF competition, which leads us to several interesting research challenges and future directions. In this paper, we outline three main research challenges. The first challenge is to search for high-quality LMAPF solutions within a limited planning time (e.g., 1s per step) for a large number of agents (e.g., 10,000) or extremely high agent density (e.g., 97.7%). We present future directions such as developing more competitive rule-based and anytime MAPF algorithms and parallelizing state-of-the-art MAPF algorithms. The second challenge is to alleviate congestion and the effect of myopic behaviors in LMAPF algorithms. We present future directions, such as developing moving guidance and traffic rules to reduce congestion, incorporating future prediction and real-time search, and determining the optimal agent number. The third challenge is to bridge the gaps between the LMAPF models used in the literature and real-world applications. We present future directions, such as dealing with more realistic kinodynamic models, execution uncertainty, and evolving systems.",
    "pdf_link": "https://arxiv.org/abs/2404.16162",
    "graphs": [],
    "abstract_cn": "多智能体路径规划（MAPF）旨在解决多个智能体从起点到终点的无碰撞移动问题。终身MAPF（LMAPF）进一步发展，通过不断为智能体设定新目标。本文介绍了我们在2023年机器人跑者联盟LMAPF竞赛中的获胜策略，该策略引发了若干研究挑战和未来研究的新方向。我们首先指出了三大研究难题：第一，如何在有限的规划时间内（如每秒一步）为成千上万的智能体或极高密度的智能体群体（如密度达97.7%）寻找优质的LMAPF解决方案；第二，如何缓解LMAPF算法中的拥堵问题及短视行为的影响；第三，如何缩小文献中的LMAPF模型与现实世界应用之间的差异。针对这些挑战，我们提出了未来研究的方向，包括开发更具竞争力的基于规则和即时MAPF算法，实现现有MAPF算法的并行化，制定动态引导和交通规则以减少拥堵，整合预测未来和实时搜索的技术，以及确定最优智能体数量。同时，我们还考虑了如何处理更真实的运动学模型、执行不确定性和动态系统等问题。",
    "title_cn": "探索将终身多智能体路径规划技术应用于更贴近现实场景的可能性：面临的研究挑战与机遇并存。",
    "tags": [
      "Agent",
      "机器人技术",
      "智能交通系统"
    ]
  },
  {
    "title": "Delay-Aware Multi-Agent Reinforcement Learning for Cooperative Adaptive Cruise Control with Model-based Stability Enhancement",
    "submit_datetime": "2024年04月24日",
    "abstract": "Cooperative Adaptive Cruise Control (CACC) represents a quintessential control strategy for orchestrating vehicular platoon movement within Connected and Automated Vehicle (CAV) systems, significantly enhancing traffic efficiency and reducing energy consumption. In recent years, the data-driven methods, such as reinforcement learning (RL), have been employed to address this task due to their significant advantages in terms of efficiency and flexibility. However, the delay issue, which often arises in real-world CACC systems, is rarely taken into account by current RL-based approaches. To tackle this problem, we propose a Delay-Aware Multi-Agent Reinforcement Learning (DAMARL) framework aimed at achieving safe and stable control for CACC. We model the entire decision-making process using a Multi-Agent Delay-Aware Markov Decision Process (MADA-MDP) and develop a centralized training with decentralized execution (CTDE) MARL framework for distributed control of CACC platoons. An attention mechanism-integrated policy network is introduced to enhance the performance of CAV communication and decision-making. Additionally, a velocity optimization model-based action filter is incorporated to further ensure the stability of the platoon. Experimental results across various delay conditions and platoon sizes demonstrate that our approach consistently outperforms baseline methods in terms of platoon safety, stability and overall performance.",
    "pdf_link": "https://arxiv.org/abs/2404.15696",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.15696v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15696/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15696v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15696/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15696v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15696/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15696v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15696/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15696v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15696/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15696v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15696/x6.png"
      }
    ],
    "abstract_cn": "协同自适应巡航控制（CACC）作为智能网联和自动驾驶车辆（CAV）系统中车队协同运动的关键控制策略，有效提升了交通流畅度并降低了能耗。近年来，数据驱动技术，尤其是强化学习（RL），因其高效和灵活的特点，被广泛应用于此类任务。然而，现有RL方法往往忽略了现实CACC系统中常见的通信延迟问题。为应对这一挑战，我们设计了一种延迟感知的多智能体强化学习（DAMARL）框架，以实现CACC的安全性与稳定性控制。该框架采用多智能体延迟感知马尔可夫决策过程（MADA-MDP）对决策过程进行全面建模，并构建了集中式训练与分布式执行（CTDE）的多智能体强化学习（MARL）体系，以优化CACC车队的控制。此外，引入了融合注意力机制的策略网络，以提升CAV间的通信和决策效率。同时，通过整合基于速度优化模型的动作过滤器，进一步确保了车队的行驶稳定性。在不同延迟情境和车队规模下的实验结果显示，我们的方案在提升车队的安全性、稳定性以及整体表现方面，均显著优于传统基线方法。",
    "title_cn": "本文介绍了一种新颖的多智能体强化学习方法，旨在实现具有模型基础稳定性增强功能的合作自适应巡航控制（CACC）。该方法特别关注了通信延迟对系统性能的影响，通过智能体之间的协同学习，优化了在存在延迟情况下的控制策略，从而提高了整体系统的稳定性和响应速度。",
    "tags": [
      "Agent",
      "自动驾驶",
      "交通控制"
    ]
  },
  {
    "title": "Is Mamba Capable of In-Context Learning?",
    "submit_datetime": "2024年04月24日",
    "abstract": "State of the art foundation models such as GPT-4 perform surprisingly well at in-context learning (ICL), a variant of meta-learning concerning the learned ability to solve tasks during a neural network forward pass, exploiting contextual information provided as input to the model. This useful ability emerges as a side product of the foundation model's massive pretraining. While transformer models are currently the state of the art in ICL, this work provides empirical evidence that Mamba, a newly proposed state space model which scales better than transformers w.r.t. the input sequence length, has similar ICL capabilities. We evaluated Mamba on tasks involving simple function approximation as well as more complex natural language processing problems. Our results demonstrate that, across both categories of tasks, Mamba closely matches the performance of transformer models for ICL. Further analysis reveals that, like transformers, Mamba appears to solve ICL problems by incrementally optimizing its internal representations. Overall, our work suggests that Mamba can be an efficient alternative to transformers for ICL tasks involving long input sequences. This is an exciting finding in meta-learning and may enable generalizations of in-context learned AutoML algorithms (like TabPFN or Optformer) to long input sequences.",
    "pdf_link": "https://arxiv.org/abs/2402.03170",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2402.03170v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.03170/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2402.03170v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.03170/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2402.03170v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.03170/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2402.03170v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.03170/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2402.03170v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.03170/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2402.03170v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.03170/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2402.03170v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.03170/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2402.03170v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.03170/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2402.03170v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.03170/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2402.03170v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.03170/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2402.03170v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.03170/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2402.03170v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.03170/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2402.03170v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.03170/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2402.03170v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.03170/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2402.03170v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.03170/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2402.03170v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.03170/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2402.03170v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.03170/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2402.03170v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.03170/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2402.03170v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.03170/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2402.03170v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.03170/x20.png"
      }
    ],
    "abstract_cn": "当前领先的基础模型例如 GPT-4 在上下文学习（ICL）方面展现出惊人的能力，ICL 是一种元学习形式，它涉及在神经网络的前向传播过程中学习解决问题，同时利用输入给模型的上下文信息。这种能力是基础模型在大规模预训练过程中的一个额外收获。尽管目前变换器模型在 ICL 领域占据领先地位，但我们的研究提供了实证证据，表明新提出的 Mamba 模型在处理输入序列长度方面比变换器模型更具扩展性，并且在 ICL 能力上与变换器相当。我们在简单函数逼近和更复杂的自然语言处理问题上对 Mamba 进行了评估，结果显示 Mamba 在这两类任务的 ICL 性能上与变换器模型不相上下。深入分析发现，Mamba 与变换器模型一样，似乎通过逐步优化其内部表示来解决 ICL 问题。总的来说，我们的研究指出 Mamba 可能是变换器模型在处理长输入序列的 ICL 任务上的一个高效替代选择。这一发现在元学习领域令人振奋，并可能推动像 TabPFN 或 Optformer 这样的上下文学习 AutoML 算法扩展到更长的输入序列。",
    "title_cn": "曼巴是否具备情境学习的能力？",
    "tags": [
      "分类：LLM理论",
      "机器学习",
      ""
    ]
  },
  {
    "title": "CleanAgent: Automating Data Standardization with LLM-based Agents",
    "submit_datetime": "2024年04月24日",
    "abstract": "Data standardization is a crucial part in data science life cycle. While tools like Pandas offer robust functionalities, their complexity and the manual effort required for customizing code to diverse column types pose significant challenges. Although large language models (LLMs) like ChatGPT have shown promise in automating this process through natural language understanding and code generation, it still demands expert-level programming knowledge and continuous interaction for prompt refinement. To solve these challenges, our key idea is to propose a Python library with declarative, unified APIs for standardizing column types, simplifying the code generation of LLM with concise API calls. We first propose Dataprep.Clean which is written as a component of the Dataprep Library, offers a significant reduction in complexity by enabling the standardization of specific column types with a single line of code. Then we introduce the CleanAgent framework integrating Dataprep.Clean and LLM-based agents to automate the data standardization process. With CleanAgent, data scientists need only provide their requirements once, allowing for a hands-free, automatic standardization process.",
    "pdf_link": "https://arxiv.org/abs/2403.08291",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2403.08291v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.08291/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2403.08291v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.08291/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2403.08291v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.08291/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2403.08291v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.08291/x4.png"
      }
    ],
    "abstract_cn": "数据标准化对于数据科学至关重要，但传统的工具如 Pandas 复杂且定制化工作繁琐。大型语言模型（LLM）如 ChatGPT 在自动化数据标准化方面展现出潜力，却要求高阶编程技能和不断的交互优化。为克服这些难题，我们提出了一个 Python 库，它采用声明式、统一的 API 设计，简化了列类型标准化和 LLM 代码生成的过程。我们首先推出了 Dataprep.Clean，作为 Dataprep 库的一部分，它通过简化的单行代码极大降低了特定列类型的标准化难度。接着，我们推出了 CleanAgent 框架，整合了 Dataprep.Clean 和基于 LLM 的智能代理，实现了数据标准化流程的自动化。CleanAgent 让数据科学家只需明确提出需求，即可享受到自动化、无需人工干预的标准化服务。",
    "title_cn": "CleanAgent：利用基于大型语言模型的智能代理，实现数据标准化流程的自动化。",
    "tags": [
      "Agent",
      "数据科学",
      "自动化"
    ]
  },
  {
    "title": "Lessons from the Use of Natural Language Inference (NLI) in Requirements Engineering Tasks",
    "submit_datetime": "2024年04月24日",
    "abstract": "We investigate the use of Natural Language Inference (NLI) in automating requirements engineering tasks. In particular, we focus on three tasks: requirements classification, identification of requirements specification defects, and detection of conflicts in stakeholders' requirements. While previous research has demonstrated significant benefit in using NLI as a universal method for a broad spectrum of natural language processing tasks, these advantages have not been investigated within the context of software requirements engineering. Therefore, we design experiments to evaluate the use of NLI in requirements analysis. We compare the performance of NLI with a spectrum of approaches, including prompt-based models, conventional transfer learning, Large Language Models (LLMs)-powered chatbot models, and probabilistic models. Through experiments conducted under various learning settings including conventional learning and zero-shot, we demonstrate conclusively that our NLI method surpasses classical NLP methods as well as other LLMs-based and chatbot models in the analysis of requirements specifications. Additionally, we share lessons learned characterizing the learning settings that make NLI a suitable approach for automating requirements engineering tasks.",
    "pdf_link": "https://arxiv.org/abs/2405.05135",
    "graphs": [],
    "abstract_cn": "我们探索了自然语言推理（NLI）在自动化需求工程中的应用，特别关注需求分类、规范缺陷识别和利益相关者需求冲突检测。尽管NLI在广泛的自然语言处理任务中显示出巨大潜力，但在软件需求工程领域尚未深入探讨。为此，我们设计实验评估NLI在需求分析中的效能，并与基于提示的模型、传统迁移学习、LLMs驱动的聊天机器人和概率模型等方法进行比较。实验结果表明，在多种学习场景下，NLI在需求规范分析中优于传统NLP方法和基于LLMs的模型。我们还总结了使NLI成为自动化需求工程任务有效工具的学习设置。",
    "title_cn": "自然语言推理（NLI）在需求工程中的应用经验谈",
    "tags": [
      "LLM应用\n\n这篇论文探讨了自然语言推理（NLI）在自动化需求工程中的应用，包括需求分类、规范缺陷识别和利益相关者需求冲突检测。它评估了NLI在需求分析中的效能，并与基于提示的模型、传统迁移学习、LLMs驱动的聊天机器人和概率模型等方法进行了比较。由于论文主要关注的是LLMs在特定应用场景（即需求工程）中的应用和效能评估，因此它属于LLM应用分类。",
      "软件工程",
      "需求分析"
    ]
  },
  {
    "title": "Enhancing Deep Knowledge Tracing via Diffusion Models for Personalized Adaptive Learning",
    "submit_datetime": "2024年04月24日",
    "abstract": "In contrast to pedagogies like evidence-based teaching, personalized adaptive learning (PAL) distinguishes itself by closely monitoring the progress of individual students and tailoring the learning path to their unique knowledge and requirements. A crucial technique for effective PAL implementation is knowledge tracing, which models students' evolving knowledge to predict their future performance. Based on these predictions, personalized recommendations for resources and learning paths can be made to meet individual needs. Recent advancements in deep learning have successfully enhanced knowledge tracking through Deep Knowledge Tracing (DKT). This paper introduces generative AI models to further enhance DKT. Generative AI models, rooted in deep learning, are trained to generate synthetic data, addressing data scarcity challenges in various applications across fields such as natural language processing (NLP) and computer vision (CV). This study aims to tackle data shortage issues in student learning records to enhance DKT performance for PAL. Specifically, it employs TabDDPM, a diffusion model, to generate synthetic educational records to augment training data for enhancing DKT. The proposed method's effectiveness is validated through extensive experiments on ASSISTments datasets. The experimental results demonstrate that the AI-generated data by TabDDPM significantly improves DKT performance, particularly in scenarios with small data for training and large data for testing.",
    "pdf_link": "https://arxiv.org/abs/2405.05134",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2405.05134v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05134/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2405.05134v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2405.05134/result.png"
      }
    ],
    "abstract_cn": "个性化自适应学习（PAL）通过密切跟踪学生个体进步，并为其量身定制学习路径，与传统的基于证据的教学方法形成鲜明对比。知识追踪作为PAL的核心技术，通过模拟学生的知识演变来预测其学习成效，进而提供定制化的学习资源和路径。深度学习领域的突破，尤其是深度知识追踪（DKT），已显著提升了这一技术。本文进一步探索了生成式AI模型在DKT中的应用，这些模型通过生成合成数据，有效缓解了数据稀缺问题，广泛应用于NLP和CV等领域。本研究聚焦于学生学习记录的数据不足问题，利用TabDDPM扩散模型生成合成教育数据，以优化DKT在PAL中的表现。实验结果显示，TabDDPM生成的AI数据在数据量有限的情况下，显著提升了DKT的性能，尤其是在训练数据稀缺而测试数据丰富的情况下。",
    "title_cn": "借助扩散模型，深度知识追踪得以强化，为个性化适应性学习开辟了新径。",
    "tags": [
      "Agent\n\n这篇论文探讨了个性化自适应学习（PAL）中的知识追踪技术，特别是深度知识追踪（DKT），并提出了使用生成式AI模型来生成合成数据以解决数据稀缺问题。这种方法可以被视为一种智能代理（Agent），因为它通过生成数据来辅助和优化学习过程，类似于一个智能系统在执行任务时采取的行动。因此，这篇论文更符合Agent分类，而不是RAG、LLM应用或LLM理论，因为它主要关注的是如何利用AI技术来改善教育领域的学习体验，而不是直接涉及语言模型的应用或理论研究。",
      "教育技术",
      "人工智能辅助学习"
    ]
  },
  {
    "title": "Wiki-LLaVA: Hierarchical Retrieval-Augmented Generation for Multimodal LLMs",
    "submit_datetime": "2024年04月23日",
    "abstract": "Multimodal LLMs are the natural evolution of LLMs, and enlarge their capabilities so as to work beyond the pure textual modality. As research is being carried out to design novel architectures and vision-and-language adapters, in this paper we concentrate on endowing such models with the capability of answering questions that require external knowledge. Our approach, termed Wiki-LLaVA, aims at integrating an external knowledge source of multimodal documents, which is accessed through a hierarchical retrieval pipeline. Relevant passages, using this approach, are retrieved from the external knowledge source and employed as additional context for the LLM, augmenting the effectiveness and precision of generated dialogues. We conduct extensive experiments on datasets tailored for visual question answering with external data and demonstrate the appropriateness of our approach.",
    "pdf_link": "https://arxiv.org/abs/2404.15406",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.15406v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15406/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15406v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15406/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15406v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15406/resized_encyclopedic_27c590f5dfe2d909.jpg"
      },
      {
        "url": "https://arxiv.org/html/2404.15406v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15406/resized_encyclopedic_27e011f811e7b62e.jpg"
      },
      {
        "url": "https://arxiv.org/html/2404.15406v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15406/resized_encyclopedic_41b81647e136ee90.jpg"
      },
      {
        "url": "https://arxiv.org/html/2404.15406v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15406/resized_infoseek_val_00000016.jpeg"
      },
      {
        "url": "https://arxiv.org/html/2404.15406v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15406/resized_infoseek_val_00000048.jpeg"
      },
      {
        "url": "https://arxiv.org/html/2404.15406v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15406/resized_infoseek_val_00000131.jpg"
      },
      {
        "url": "https://arxiv.org/html/2404.15406v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15406/resized_infoseek_val_00000210.jpg"
      },
      {
        "url": "https://arxiv.org/html/2404.15406v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15406/resized_encyclopedic_fa07f04eea2fdcf0.jpg"
      },
      {
        "url": "https://arxiv.org/html/2404.15406v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15406/resized_infoseek_val_00000169.jpg"
      }
    ],
    "abstract_cn": "多模态大型语言模型（LLM）作为LLM的进阶形态，拓展了其功能，使其能够超越单一文本模态的限制。本研究致力于开发新型架构和视觉-语言适配器，专注于赋予模型以外部知识为基础回答问题的能力。我们提出的Wiki-LLaVA方法，旨在整合一个外部的多模态文档知识库，并通过分层检索流程进行访问。通过这种方法，能够从知识库中检索出相关文段，为LLM提供额外的上下文信息，从而提升对话生成的有效性和精确度。我们在视觉问答领域，针对包含外部数据的数据集进行了广泛的实验，验证了我们方法的有效性。",
    "title_cn": "Wiki-LLaVA：为多模态大型语言模型（LLM）引入分层检索增强生成技术",
    "tags": [
      "LLM应用",
      "视觉问答",
      "知识库"
    ]
  },
  {
    "title": "MedDr: Diagnosis-Guided Bootstrapping for Large-Scale Medical Vision-Language Learning",
    "submit_datetime": "2024年04月23日",
    "abstract": "The rapid advancement of large-scale vision-language models has showcased remarkable capabilities across various tasks. However, the lack of extensive and high-quality image-text data in medicine has greatly hindered the development of large-scale medical vision-language models. In this work, we present a diagnosis-guided bootstrapping strategy that exploits both image and label information to construct vision-language datasets. Based on the constructed dataset, we developed MedDr, a generalist foundation model for healthcare capable of handling diverse medical data modalities, including radiology, pathology, dermatology, retinography, and endoscopy. Moreover, during inference, we propose a simple but effective retrieval-augmented medical diagnosis strategy, which enhances the model's generalization ability. Extensive experiments on visual question answering, medical report generation, and medical image diagnosis demonstrate the superiority of our method.",
    "pdf_link": "https://arxiv.org/abs/2404.15127",
    "graphs": [],
    "abstract_cn": "大规模视觉-语言模型的迅猛进展在众多任务中展现了非凡的才能。但医学界高质量图文数据的匮乏，严重限制了这一模型在医疗领域的应用。本研究提出了一种新颖的诊断引导自举策略，充分利用图像与标签数据构建视觉-语言数据库。依托此数据库，我们研发了 MedDr，一个能够应对多种医疗数据形式的通用基础模型，涵盖了放射、病理、皮肤、视网膜和内窥镜等多个领域。在推理阶段，我们还引入了一种简洁高效的检索增强医疗诊断策略，进一步提升了模型的泛化性能。通过在视觉问答、医疗报告撰写和医疗图像诊断等任务上的广泛测试，证实了我们方法的优势。",
    "title_cn": "MedDr：一种为大规模医学视觉-语言学习设计的诊断引导自举策略",
    "tags": [
      "分类：LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "From Matching to Generation: A Survey on Generative Information Retrieval",
    "submit_datetime": "2024年04月23日",
    "abstract": "Information Retrieval (IR) systems are crucial tools for users to access information, widely applied in scenarios like search engines, question answering, and recommendation systems. Traditional IR methods, based on similarity matching to return ranked lists of documents, have been reliable means of information acquisition, dominating the IR field for years. With the advancement of pre-trained language models, generative information retrieval (GenIR) has emerged as a novel paradigm, gaining increasing attention in recent years. Currently, research in GenIR can be categorized into two aspects: generative document retrieval (GR) and reliable response generation. GR leverages the generative model's parameters for memorizing documents, enabling retrieval by directly generating relevant document identifiers without explicit indexing. Reliable response generation, on the other hand, employs language models to directly generate the information users seek, breaking the limitations of traditional IR in terms of document granularity and relevance matching, offering more flexibility, efficiency, and creativity, thus better meeting practical needs. This paper aims to systematically review the latest research progress in GenIR. We will summarize the advancements in GR regarding model training, document identifier, incremental learning, downstream tasks adaptation, multi-modal GR and generative recommendation, as well as progress in reliable response generation in aspects of internal knowledge memorization, external knowledge augmentation, generating response with citations and personal information assistant. We also review the evaluation, challenges and future prospects in GenIR systems. This review aims to offer a comprehensive reference for researchers in the GenIR field, encouraging further development in this area.",
    "pdf_link": "https://arxiv.org/abs/2404.14851",
    "graphs": [],
    "abstract_cn": "信息检索系统对于用户获取信息至关重要，它们在搜索引擎、问答系统和推荐系统等场景中发挥着重要作用。传统上，这些系统依赖于相似性匹配技术，以提供有序的文档列表，这一方法多年来一直是信息检索的主流。然而，随着预训练语言模型的发展，生成式信息检索（GenIR）作为一种创新的检索范式，正逐渐受到业界的广泛关注。GenIR的研究主要分为两大方向：生成式文档检索（GR）和可靠的响应生成。GR通过利用生成模型的参数记忆文档内容，实现了无需显式索引即可直接生成相关文档标识符的检索方式。而可靠的响应生成则利用语言模型直接产出用户所需的信息，超越了传统IR在文档细节和相关性匹配上的局限，提供了更高的灵活性和效率。本文的目的是对GenIR领域的最新研究进展进行系统性的梳理。我们将概述GR在模型训练、文档标识、增量学习、任务适应、多模态检索和推荐系统等方面的进展，以及在知识记忆、知识增强、引用生成和个人助理等方面的可靠响应生成技术。此外，我们还将探讨GenIR系统的评估标准、面临的挑战及未来的发展方向。本篇综述的目标是为GenIR领域的研究者提供一个全面的参考框架，以促进该领域的持续进步。",
    "title_cn": "探索信息检索的演进：从匹配到生成的生成性信息检索综述",
    "tags": [
      "LLM应用",
      "信息检索",
      ""
    ]
  },
  {
    "title": "A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications",
    "submit_datetime": "2024年04月23日",
    "abstract": "A graph is a fundamental data model to represent various entities and their complex relationships in society and nature, such as social networks, transportation networks, financial networks, and biomedical systems. Recently, large language models (LLMs) have showcased a strong generalization ability to handle various NLP and multi-mode tasks to answer users' arbitrary questions and specific-domain content generation. Compared with graph learning models, LLMs enjoy superior advantages in addressing the challenges of generalizing graph tasks by eliminating the need for training graph learning models and reducing the cost of manual annotation. In this survey, we conduct a comprehensive investigation of existing LLM studies on graph data, which summarizes the relevant graph analytics tasks solved by advanced LLM models and points out the existing remaining challenges and future directions. Specifically, we study the key problems of LLM-based generative graph analytics (LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP), LLM-based graph inference and learning (LLM-GIL), and graph-LLM-based applications. LLM-GQP focuses on an integration of graph analytics techniques and LLM prompts, including graph understanding and knowledge graph (KG) based augmented retrieval, while LLM-GIL focuses on learning and reasoning over graphs, including graph learning, graph-formed reasoning and graph representation. We summarize the useful prompts incorporated into LLM to handle different graph downstream tasks. Moreover, we give a summary of LLM model evaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM models. We also explore open problems and future directions in this exciting interdisciplinary research area of LLMs and graph analytics.",
    "pdf_link": "https://arxiv.org/abs/2404.14809",
    "graphs": [],
    "abstract_cn": "图作为基本的数据模型，广泛用于描绘社会和自然界中的实体及其错综复杂的联系，如社交网络、交通系统、金融体系和生物医学网络。近期，大型语言模型（LLMs）在处理多样化的自然语言处理（NLP）和多模态任务方面展现出了卓越的泛化能力，能够响应用户的随机查询和特定领域的内容创作。相较于传统的图学习模型，LLMs在处理图任务时更具优势，它们避免了图学习模型的训练需求，同时降低了手动标注的成本。本篇综述深入探讨了LLM在图数据分析领域的研究进展，归纳了高级LLM模型解决的图分析任务，并指出了当前面临的挑战与未来的研究趋势。具体而言，我们聚焦于基于LLM的生成图分析（LLM-GGA）的三大核心问题：基于LLM的图查询处理（LLM-GQP）、基于LLM的图推理与学习（LLM-GIL），以及图与LLM结合的应用。LLM-GQP着重于图分析技术与LLM提示的融合，涵盖图理解及基于知识图谱的增强检索；LLM-GIL则专注于图上的学习和推理，包括图学习、图形态推理和图表示。我们归纳了LLM在处理各类图任务时采用的有效提示。此外，我们还总结了LLM模型的评估方法、基准数据集/任务，并深入剖析了LLM模型的优势与局限。同时，我们也探讨了LLM与图分析这一激动人心的跨学科研究领域的未解之谜及未来可能的研究方向。",
    "title_cn": "大型语言模型在生成图分析领域的研究综述：探讨查询、学习及应用",
    "tags": [
      "LLM应用",
      "图数据分析",
      ""
    ]
  },
  {
    "title": "Simulating Task-Oriented Dialogues with State Transition Graphs and Large Language Models",
    "submit_datetime": "2024年04月23日",
    "abstract": "This paper explores SynTOD, a new synthetic data generation approach for developing end-to-end Task-Oriented Dialogue (TOD) Systems capable of handling complex tasks such as intent classification, slot filling, conversational question-answering, and retrieval-augmented response generation, without relying on crowdsourcing or real-world data. SynTOD utilizes a state transition graph to define the desired behavior of a TOD system and generates diverse, structured conversations through random walks and response simulation using large language models (LLMs). In our experiments, using graph-guided response simulations leads to significant improvements in intent classification, slot filling and response relevance compared to naive single-prompt simulated conversations. We also investigate the end-to-end TOD effectiveness of different base and instruction-tuned LLMs, with and without the constructed synthetic conversations. Finally, we explore how various LLMs can evaluate responses in a TOD system and how well they are correlated with human judgments. Our findings pave the path towards quick development and evaluation of domain-specific TOD systems. We release our datasets, models, and code for research purposes.",
    "pdf_link": "https://arxiv.org/abs/2404.14772",
    "graphs": [],
    "abstract_cn": "本研究介绍了 SynTOD，这是一种创新的合成数据生成技术，旨在培育能够执行复杂任务的全链条面向任务对话（TOD）系统。这些任务包括意图识别、槽位填充、对话式问答以及增强检索的响应生成，且整个过程无需依赖众包或现实世界数据。SynTOD 通过状态转移图明确 TOD 系统的目标行为，并通过随机游走结合大型语言模型（LLMs）的响应模拟，创造出多样化且结构化的对话。实验结果显示，采用图引导的响应模拟方法，在意图识别、槽位填充和响应相关性方面，相较于传统的单一提示模拟对话，有显著的性能提升。此外，我们还深入探讨了不同基础型和指令调优型 LLMs 在 TOD 系统中的应用效果，无论是否结合了合成对话数据。最终，我们评估了各种 LLMs 在 TOD 系统中的响应评估能力，并分析了它们与人类评判的一致性。这些发现为快速开发和评估特定领域的 TOD 系统提供了新思路。为了促进研究，我们公开了数据集、模型和代码。",
    "title_cn": "通过状态转移图和大型语言模型来模拟以任务为导向的对话流程。",
    "tags": [
      "分类：RAG\n\n这篇论文介绍了一种名为SynTOD的合成数据生成技术，用于培育能够执行复杂任务的全链条面向任务对话（TOD）系统。这项技术涉及到意图识别、槽位填充、对话式问答以及增强检索的响应生成。论文中提到了大型语言模型（LLMs）在生成多样化且结构化的对话中的作用，以及对不同基础型和指令调优型LLMs在TOD系统中的应用效果的探讨。这些内容表明，这篇论文主要关注的是利用合成数据和大型语言模型来生成和评估对话系统，因此它属于RAG（Retrieval-Augmented Generation）的范畴。",
      "对话系统",
      "数据生成"
    ]
  },
  {
    "title": "Retrieval Augmented Generation for Domain-specific Question Answering",
    "submit_datetime": "2024年04月23日",
    "abstract": "Question answering (QA) has become an important application in the advanced development of large language models. General pre-trained large language models for question-answering are not trained to properly understand the knowledge or terminology for a specific domain, such as finance, healthcare, education, and customer service for a product. To better cater to domain-specific understanding, we build an in-house question-answering system for Adobe products. We propose a novel framework to compile a large question-answer database and develop the approach for retrieval-aware finetuning of a Large Language model. We showcase that fine-tuning the retriever leads to major improvements in the final generation. Our overall approach reduces hallucinations during generation while keeping in context the latest retrieval information for contextual grounding.",
    "pdf_link": "https://arxiv.org/abs/2404.14760",
    "graphs": [],
    "abstract_cn": "问答系统在大型语言模型的高级应用中占据了重要地位。然而，通用的预训练模型往往缺乏对特定领域，如金融、医疗、教育或产品客户服务的专业理解。为了提升对特定领域的精准把握，我们为 Adobe 产品专门打造了一套内部问答系统。本系统采用了创新框架，旨在构建庞大的问答数据库，并针对大型语言模型进行了检索感知的微调训练。实践证明，对检索器进行微调能显著提升最终输出的质量。我们的策略在确保生成内容的准确性的同时，有效减少了生成过程中可能出现的误导性信息。",
    "title_cn": "为特定领域问答设计的检索增强生成技术",
    "tags": [
      "LLM应用",
      "客户服务",
      "问答系统"
    ]
  },
  {
    "title": "Retrieval-Augmented Audio Deepfake Detection",
    "submit_datetime": "2024年04月23日",
    "abstract": "With recent advances in speech synthesis including text-to-speech (TTS) and voice conversion (VC) systems enabling the generation of ultra-realistic audio deepfakes, there is growing concern about their potential misuse. However, most deepfake (DF) detection methods rely solely on the fuzzy knowledge learned by a single model, resulting in performance bottlenecks and transparency issues. Inspired by retrieval-augmented generation (RAG), we propose a retrieval-augmented detection (RAD) framework that augments test samples with similar retrieved samples for enhanced detection. We also extend the multi-fusion attentive classifier to integrate it with our proposed RAD framework. Extensive experiments show the superior performance of the proposed RAD framework over baseline methods, achieving state-of-the-art results on the ASVspoof 2021 DF set and competitive results on the 2019 and 2021 LA sets. Further sample analysis indicates that the retriever consistently retrieves samples mostly from the same speaker with acoustic characteristics highly consistent with the query audio, thereby improving detection performance.",
    "pdf_link": "https://arxiv.org/abs/2404.13892",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.13892v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13892/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13892v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13892/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13892v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13892/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13892v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13892/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13892v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13892/x5.png"
      }
    ],
    "abstract_cn": "随着文本到语音和声音转换技术的进步，我们能够创造出极为逼真的音频深度伪造，这引发了对其潜在滥用的担忧。目前，大多数深度伪造检测方法主要依赖单一模型的模糊知识，这不仅限制了检测性能，也带来了透明度的挑战。借鉴检索增强生成的理念，我们提出了一种新颖的检索增强检测框架，通过引入相似的检索样本来提升检测效果。此外，我们还对多融合注意力分类器进行了扩展，以适配我们的检测框架。大量实验证明，我们的框架在多个数据集上均优于现有方法，尤其在ASVspoof 2021的深度伪造数据集上取得了突破性成果，并在2019年和2021年的LA数据集上也展现了强劲的竞争力。深入分析显示，检索器能够精准地找到与查询音频声学特征高度相似的同一说话人的样本，这显著提升了检测的准确性。",
    "title_cn": "增强检索音频深度伪造检测",
    "tags": [
      "分类：LLM应用\n\n这篇论文提出了一种新颖的检索增强检测框架，用于检测音频深度伪造。它通过引入相似的检索样本来提升检测效果，并扩展了多融合注意力分类器以适配检测框架。这项工作主要关注于应用大型语言模型（LLM）的技术来解决实际问题，即提高深度伪造检测的性能。因此，它应该被归类为LLM应用。",
      "音频处理",
      ""
    ]
  },
  {
    "title": "BattleAgent: Multi-modal Dynamic Emulation on Historical Battles to Complement Historical Analysis",
    "submit_datetime": "2024年04月23日",
    "abstract": "This paper presents BattleAgent, an emulation system that combines the Large Vision-Language Model and Multi-agent System. This novel system aims to simulate complex dynamic interactions among multiple agents, as well as between agents and their environments, over a period of time. It emulates both the decision-making processes of leaders and the viewpoints of ordinary participants, such as soldiers. The emulation showcases the current capabilities of agents, featuring fine-grained multi-modal interactions between agents and landscapes. It develops customizable agent structures to meet specific situational requirements, for example, a variety of battle-related activities like scouting and trench digging. These components collaborate to recreate historical events in a lively and comprehensive manner while offering insights into the thoughts and feelings of individuals from diverse viewpoints. The technological foundations of BattleAgent establish detailed and immersive settings for historical battles, enabling individual agents to partake in, observe, and dynamically respond to evolving battle scenarios. This methodology holds the potential to substantially deepen our understanding of historical events, particularly through individual accounts. Such initiatives can also aid historical research, as conventional historical narratives often lack documentation and prioritize the perspectives of decision-makers, thereby overlooking the experiences of ordinary individuals. BattelAgent illustrates AI's potential to revitalize the human aspect in crucial social events, thereby fostering a more nuanced collective understanding and driving the progressive development of human society.",
    "pdf_link": "https://arxiv.org/abs/2404.15532",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.15532v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15532/battle_map.jpg"
      },
      {
        "url": "https://arxiv.org/html/2404.15532v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15532/Battle_of_crecy_froissart.jpeg"
      },
      {
        "url": "https://arxiv.org/html/2404.15532v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15532/general_process.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15532v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15532/observation.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15532v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15532/agent_structure.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15532v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15532/battlefield_interaction.jpeg"
      },
      {
        "url": "https://arxiv.org/html/2404.15532v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15532/crecy.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15532v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15532/Agincourt.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15532v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15532/Poitiers.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15532v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15532/Falkirk.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15532v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15532/battle_field.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15532v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15532/x1.png"
      }
    ],
    "abstract_cn": "本文推出了一款名为 BattleAgent 的仿真系统，它融合了大型视觉-语言模型与多智能体系统。该系统致力于模拟多个智能体之间的复杂互动，以及智能体与其环境之间的长期交互。它不仅模拟了领导者的决策机制，也反映了普通参与者如士兵的看法。该仿真系统精细地展现了智能体的能力，实现了智能体与环境之间的多模态互动。系统还设计了可定制的智能体结构，以适应不同的战斗需求，如侦察和挖掘战壕等。这些元素共同作用，生动全面地再现了历史事件，同时深入探讨了不同角色的内心世界。BattleAgent 的技术基础为历史战役提供了一个详尽而沉浸式的背景，让每个智能体都能参与、观察并灵活应对战斗的演变。这种方法有望显著提升我们对历史事件的认识，尤其是通过个人经历的视角。此外，它还能辅助历史研究，因为传统叙事往往忽略了普通人的经历，而 BattleAgent 则利用人工智能的力量，恢复了社会重大事件中的人文关怀，促进了对人类社会更深层次的理解与发展。",
    "title_cn": "BattleAgent：通过在历史战场上进行多模态动态模拟，为历史研究提供补充分析。",
    "tags": [
      "Agent",
      "历史研究",
      "人工智能"
    ]
  },
  {
    "title": "IryoNLP at MEDIQA-CORR 2024: Tackling the Medical Error Detection & Correction Task On the Shoulders of Medical Agents",
    "submit_datetime": "2024年04月23日",
    "abstract": "In natural language processing applied to the clinical domain, utilizing large language models has emerged as a promising avenue for error detection and correction on clinical notes, a knowledge-intensive task for which annotated data is scarce. This paper presents MedReAct'N'MedReFlex, which leverages a suite of four LLM-based medical agents. The MedReAct agent initiates the process by observing, analyzing, and taking action, generating trajectories to guide the search to target a potential error in the clinical notes. Subsequently, the MedEval agent employs five evaluators to assess the targeted error and the proposed correction. In cases where MedReAct's actions prove insufficient, the MedReFlex agent intervenes, engaging in reflective analysis and proposing alternative strategies. Finally, the MedFinalParser agent formats the final output, preserving the original style while ensuring the integrity of the error correction process. One core component of our method is our RAG pipeline based on our ClinicalCorp corpora. Among other well-known sources containing clinical guidelines and information, we preprocess and release the open-source MedWiki dataset for clinical RAG application. Our results demonstrate the central role of our RAG approach with ClinicalCorp leveraged through the MedReAct'N'MedReFlex framework. It achieved the ninth rank on the MEDIQA-CORR 2024 final leaderboard.",
    "pdf_link": "https://arxiv.org/abs/2404.15488",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.15488v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15488/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15488v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15488/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15488v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15488/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15488v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15488/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15488v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15488/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15488v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15488/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15488v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15488/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15488v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15488/x8.png"
      }
    ],
    "abstract_cn": "在临床领域的自然语言处理应用中，借助大型语言模型来检测和修正临床记录中的错误，这一方法显示出巨大的潜力，尤其是在标注数据难以获得的复杂任务中。本研究提出了一个创新的系统——MedReAct'N'MedReFlex，它整合了四个基于大型语言模型的医疗智能体。MedReAct 智能体首先通过观察、分析和执行操作来启动错误检测流程，生成路径以定位临床记录中的潜在错误。接着，MedEval 智能体动用五个评估器对目标错误及其修正建议进行评估。当 MedReAct 的修正措施不足时，MedReFlex 智能体会介入，进行深入分析并提出新的策略。最终，MedFinalParser 智能体负责将修正后的内容格式化输出，既保持了原文的风格，又确保了错误修正过程的准确性。我们的方法还包括一个基于 ClinicalCorp 语料库的 RAG 流程，这是我们的核心组成部分。我们还预处理并开源了 MedWiki 数据集，以支持临床 RAG 应用。实验结果显示，我们的 RAG 方法在 MedReAct'N'MedReFlex 框架下，通过 ClinicalCorp 数据集的加持，发挥了关键作用，在 MEDIQA-CORR 2024 的最终排行榜上荣获第九名。",
    "title_cn": "IryoNLP 亮相 2024 年 MEDIQA-CORR，携手医疗代理共同攻克医疗错误检测与纠正的挑战。",
    "tags": [
      "Agent",
      "",
      ""
    ]
  },
  {
    "title": "Aligning LLM Agents by Learning Latent Preference from User Edits",
    "submit_datetime": "2024年04月23日",
    "abstract": "We study interactive learning of language agents based on user edits made to the agent's output. In a typical setting such as writing assistants, the user interacts with a language agent to generate a response given a context, and may optionally edit the agent response to personalize it based on their latent preference, in addition to improving the correctness. The edit feedback is naturally generated, making it a suitable candidate for improving the agent's alignment with the user's preference, and for reducing the cost of user edits over time. We propose a learning framework, PRELUDE that infers a description of the user's latent preference based on historic edit data and using it to define a prompt policy that drives future response generation. This avoids fine-tuning the agent, which is costly, challenging to scale with the number of users, and may even degrade its performance on other tasks. Furthermore, learning descriptive preference improves interpretability, allowing the user to view and modify the learned preference. However, user preference can be complex and vary based on context, making it challenging to learn. To address this, we propose a simple yet effective algorithm named CIPHER that leverages a large language model (LLM) to infer the user preference for a given context based on user edits. In the future, CIPHER retrieves inferred preferences from the k-closest contexts in the history, and forms an aggregate preference for response generation. We introduce two interactive environments -- summarization and email writing, for evaluation using a GPT-4 simulated user. We compare with algorithms that directly retrieve user edits but do not learn descriptive preference, and algorithms that learn context-agnostic preference. On both tasks, CIPHER achieves the lowest edit distance cost and learns preferences that show significant similarity to the ground truth preferences",
    "pdf_link": "https://arxiv.org/abs/2404.15269",
    "graphs": [],
    "abstract_cn": "本研究探讨了语言代理如何通过用户对其输出的编辑进行交互式学习。在写作助手等典型应用场景中，用户与语言代理互动，根据特定上下文生成回复，并可根据自己的内在偏好对代理的回复进行编辑，以实现个性化并提升准确性。这种编辑反馈自然产生，有助于提升代理与用户偏好的契合度，同时降低用户随时间增加的编辑成本。我们提出了一个名为Prelude的学习框架，它能够基于历史编辑数据推断用户的潜在偏好，并据此制定提示策略，引导未来的回复生成，避免了对代理进行成本高昂且难以扩展的微调，同时可能影响其在其他任务上的表现。此外，通过学习描述性偏好，增强了模型的可解释性，使用户能够查看并调整已学习到的偏好。然而，用户偏好复杂多变，受上下文影响，学习起来颇具挑战。为此，我们设计了一个简单高效的算法CIPHER，它利用大型语言模型（LLM）分析用户编辑，从而推断出特定上下文下的用户偏好。CIPHER在未来能够从历史中检索与当前上下文最相似的k个偏好，并综合这些偏好以生成回复。我们还构建了摘要和电子邮件写作两个交互式环境，通过GPT-4模拟用户进行评估。在比较中，CIPHER不仅在两个任务上都实现了最低的编辑成本，而且学习到的偏好与真实偏好有显著的一致性。",
    "title_cn": "通过用户编辑学习用户的潜在偏好，以此来校准大型语言模型（LLM）代理的行为。",
    "tags": [
      "Agent",
      "写作辅助",
      "用户偏好学习"
    ]
  },
  {
    "title": "CT-Agent: Clinical Trial Multi-Agent with Large Language Model-based Reasoning",
    "submit_datetime": "2024年04月23日",
    "abstract": "Large Language Models (LLMs) and multi-agent systems have shown impressive capabilities in natural language tasks but face challenges in clinical trial applications, primarily due to limited access to external knowledge. Recognizing the potential of advanced clinical trial tools that aggregate and predict based on the latest medical data, we propose an integrated solution to enhance their accessibility and utility. We introduce Clinical Agent System (CT-Agent), a Clinical multi-agent system designed for clinical trial tasks, leveraging GPT-4, multi-agent architectures, LEAST-TO-MOST, and ReAct reasoning technology. This integration not only boosts LLM performance in clinical contexts but also introduces novel functionalities. Our system autonomously manages the entire clinical trial process, demonstrating significant efficiency improvements in our evaluations, which include both computational benchmarks and expert feedback.",
    "pdf_link": "https://arxiv.org/abs/2404.14777",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）与多智能体系统在处理自然语言任务时表现出色，但在临床试验应用上却遭遇难题，这主要是因为它们难以获取外部知识。为了克服这一限制，我们提出了一种集成方案，旨在提升临床试验工具的可用性和效能。我们设计了临床代理系统（CT-Agent），这是一个专为临床试验任务打造的多智能体系统，它整合了GPT-4、多智能体架构、LEAST-TO-MOST策略以及ReAct推理技术。这一集成方案不仅极大提升了LLM在临床领域的性能，还带来了创新功能。我们的系统能够自动执行整个临床试验流程，在计算基准测试和专家评审中均展现出显著的效率提升。",
    "title_cn": "CT-Agent：融合大型语言模型推理能力的临床试验多智能体系统",
    "tags": [
      "Agent",
      "临床试验",
      "人工智能"
    ]
  },
  {
    "title": "Generate-on-Graph: Treat LLM as both Agent and KG in Incomplete Knowledge Graph Question Answering",
    "submit_datetime": "2024年04月23日",
    "abstract": "To address the issue of insufficient knowledge and the tendency to generate hallucination in Large Language Models (LLMs), numerous studies have endeavored to integrate LLMs with Knowledge Graphs (KGs). However, all these methods are evaluated on conventional Knowledge Graph Question Answering (KGQA) with complete KGs, where the factual triples involved in each question are entirely covered by the given KG. In this situation, LLM mainly acts as an agent to find answer entities by exploring the KG, rather than effectively integrating internal and external knowledge sources. However, in real-world scenarios, KGs are often incomplete to cover all the knowledge required to answer questions. To simulate real-world scenarios and evaluate the ability of LLMs to integrate internal and external knowledge, in this paper, we propose leveraging LLMs for QA under Incomplete Knowledge Graph (IKGQA), where the given KG doesn't include all the factual triples involved in each question. To handle IKGQA, we propose a training-free method called Generate-on-Graph (GoG) that can generate new factual triples while exploring on KGs. Specifically, we propose a selecting-generating-answering framework, which not only treat the LLM as an agent to explore on KGs, but also treat it as a KG to generate new facts based on the explored subgraph and its inherent knowledge. Experimental results on two datasets demonstrate that our GoG can solve IKGQA to a certain extent, while almost all previous methods cannot perform well on IKGQA.",
    "pdf_link": "https://arxiv.org/abs/2404.14741",
    "graphs": [],
    "abstract_cn": "为应对大型语言模型（LLMs）知识匮乏和易于产生幻觉的问题，众多研究致力于将LLMs与知识图谱（KGs）相结合。但这些方法多在完备的知识图谱问答（KGQA）环境中进行评估，即每个问题所涉及的事实三元组均被知识图谱全面覆盖。在此环境下，LLMs主要扮演搜索知识图谱以发现答案实体的角色，而非真正融合内外部知识。然而现实情况中，知识图谱往往无法全面覆盖所有问答所需的知识。本文旨在模拟现实世界环境，评估LLMs整合内外部知识的能力，提出了在不完全知识图谱（IKGQA）下进行问答的LLMs应用。在IKGQA中，所给知识图谱并未包含每个问题涉及的所有事实三元组。为此，我们提出了一种无需训练的方法——图上生成（GoG），它能够在探索知识图谱的同时产生新的事实三元组。具体而言，我们构建了一个选择-生成-回答框架，将LLMs视作探索知识图谱的智能体，同时也将其作为能够基于探索到的子图及其内在知识生成新事实的知识图谱。实验结果显示，我们的GoG方法在IKGQA任务上取得了一定成效，而大多数现有方法在此类任务上表现不佳。",
    "title_cn": "在不完整的知识图谱问答任务中，我们将大型语言模型（LLM）既视为智能代理，也视为知识库，以生成答案。",
    "tags": [
      "LLM应用",
      "知识图谱",
      "问答系统"
    ]
  },
  {
    "title": "Large Language Models for Synthetic Participatory Planning of Synergistic Transportation Systems",
    "submit_datetime": "2024年04月23日",
    "abstract": "Unleashing the synergies of rapidly evolving mobility technologies in a multi-stakeholder landscape presents unique challenges and opportunities for addressing urban transportation problems. This paper introduces a novel synthetic participatory method, critically leveraging large language models (LLMs) to create digital avatars representing diverse stakeholders to plan shared automated electric mobility systems (SAEMS). These calibratable agents collaboratively identify objectives, envision and evaluate SAEMS alternatives, and strategize implementation under risks and constraints. The results of a Montreal case study indicate that a structured and parameterized workflow provides outputs with high controllability and comprehensiveness on an SAEMS plan than generated using a single LLM-enabled expert agent. Consequently, the approach provides a promising avenue for cost-efficiently improving the inclusivity and interpretability of multi-objective transportation planning, suggesting a paradigm shift in how we envision and strategize for sustainable and equitable transportation systems.",
    "pdf_link": "https://arxiv.org/abs/2404.12317",
    "graphs": [],
    "abstract_cn": "在多元利益主体的格局中，迅速发展的移动性技术为我们解决城市交通问题提供了特殊的挑战与机遇。本论文提出了一种创新的综合参与式方法，充分利用大型语言模型（LLMs）打造代表多样利益方的数字形象，共同规划共享的自动化电动移动系统（SAEMS）。这些可调节的智能体协同确定目标，构想和评估SAEMS的不同方案，并在风险与限制下制定实施策略。通过对蒙特利尔案例的研究，我们发现，与传统的单一LLM驱动的专家智能体相比，一个结构化且可参数化的流程能够更可控、更全面地输出SAEMS计划。这一发现预示着在提升多目标交通规划的包容性与可解释性方面，我们有了一条成本效益高的新途径，这也可能引领我们对可持续和公平交通系统规划的全新思考方式。",
    "title_cn": "大型语言模型在合成协同交通系统的参与式规划中的应用。",
    "tags": [
      "Agent",
      "城市交通规划",
      "自动化电动移动系统"
    ]
  },
  {
    "title": "ImplicitAVE: An Open-Source Dataset and Multimodal LLMs Benchmark for Implicit Attribute Value Extraction",
    "submit_datetime": "2024年04月23日",
    "abstract": "Existing datasets for attribute value extraction (AVE) predominantly focus on explicit attribute values while neglecting the implicit ones, lack product images, are often not publicly available, and lack an in-depth human inspection across diverse domains. To address these limitations, we present ImplicitAVE, the first, publicly available multimodal dataset for implicit attribute value extraction. ImplicitAVE, sourced from the MAVE dataset, is carefully curated and expanded to include implicit AVE and multimodality, resulting in a refined dataset of 68k training and 1.6k testing data across five domains. We also explore the application of multimodal large language models (MLLMs) to implicit AVE, establishing a comprehensive benchmark for MLLMs on the ImplicitAVE dataset. Six recent MLLMs with eleven variants are evaluated across diverse settings, revealing that implicit value extraction remains a challenging task for MLLMs. The contributions of this work include the development and release of ImplicitAVE, and the exploration and benchmarking of various MLLMs for implicit AVE, providing valuable insights and potential future research directions. Dataset and code are available at https://github.com/HenryPengZou/ImplicitAVE",
    "pdf_link": "https://arxiv.org/abs/2404.15592",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.15592v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15592/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15592v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15592/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15592v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15592/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15592v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15592/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15592v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15592/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15592v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15592/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15592v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15592/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15592v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15592/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15592v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15592/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15592v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15592/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15592v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15592/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15592v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15592/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15592v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15592/x13.png"
      }
    ],
    "abstract_cn": "目前针对属性值提取（AVE）的数据集多集中于明显属性值，而对隐性属性值视而不见，往往缺乏产品图像，不对外开放，且在多个领域内缺少详尽的人工审查。为克服这些不足，我们推出了ImplicitAVE——首个公开的多模态隐式属性值提取数据集。ImplicitAVE基于MAVE数据集，经过精心筛选和扩充，纳入了隐性AVE和多模态特性，形成了一个优化后的数据集，包含68,000条训练样本和1,600条测试样本，覆盖五个不同的领域。我们还研究了多模态大型语言模型（MLLMs）在隐式AVE中的应用，并为MLLMs在ImplicitAVE数据集上设立了一个全面的评估标准。对六种最新的MLLMs及其十一种变体进行了广泛设置的评估，发现隐性值提取对于MLLMs而言仍是一大挑战。本研究的贡献包括开发并发布了ImplicitAVE数据集，以及对多种MLLMs在隐式AVE任务中的探索和性能评估，为未来研究提供了宝贵的洞见和可能的研究方向。相关数据集和代码已在 https://github.com/HenryPengZou/ImplicitAVE 上公开。",
    "title_cn": "ImplicitAVE 推出了一个开源数据集，并为隐式属性值提取设立了多模态大型语言模型（LLM）的基准测试。",
    "tags": [
      "LLM应用",
      "属性值提取",
      "多模态学习"
    ]
  },
  {
    "title": "Multimodal Large Language Model is a Human-Aligned Annotator for Text-to-Image Generation",
    "submit_datetime": "2024年04月23日",
    "abstract": "Recent studies have demonstrated the exceptional potentials of leveraging human preference datasets to refine text-to-image generative models, enhancing the alignment between generated images and textual prompts. Despite these advances, current human preference datasets are either prohibitively expensive to construct or suffer from a lack of diversity in preference dimensions, resulting in limited applicability for instruction tuning in open-source text-to-image generative models and hinder further exploration. To address these challenges and promote the alignment of generative models through instruction tuning, we leverage multimodal large language models to create VisionPrefer, a high-quality and fine-grained preference dataset that captures multiple preference aspects. We aggregate feedback from AI annotators across four aspects: prompt-following, aesthetic, fidelity, and harmlessness to construct VisionPrefer. To validate the effectiveness of VisionPrefer, we train a reward model VP-Score over VisionPrefer to guide the training of text-to-image generative models and the preference prediction accuracy of VP-Score is comparable to human annotators. Furthermore, we use two reinforcement learning methods to supervised fine-tune generative models to evaluate the performance of VisionPrefer, and extensive experimental results demonstrate that VisionPrefer significantly improves text-image alignment in compositional image generation across diverse aspects, e.g., aesthetic, and generalizes better than previous human-preference metrics across various image distributions. Moreover, VisionPrefer indicates that the integration of AI-generated synthetic data as a supervisory signal is a promising avenue for achieving improved alignment with human preferences in vision generative models.",
    "pdf_link": "https://arxiv.org/abs/2404.15100",
    "graphs": [],
    "abstract_cn": "最新研究表明，通过利用人类偏好数据集来优化文本到图像的生成模型，可以显著提升生成图像与文本描述的匹配度。然而，目前构建这样的数据集要么成本过高，要么偏好维度的多样性不足，这限制了其在开源文本到图像生成模型中的指令调优应用，并影响了进一步的研究。为了解决这些问题，我们运用多模态大型语言模型，开发了 VisionPrefer——一个捕捉多元偏好维度的高质量、细致入微的偏好数据集。我们汇总了 AI 注释者在四个方面——遵循提示、审美、忠实度和无害性——的反馈，构建了 VisionPrefer。为了证明其有效性，我们基于该数据集训练了一个奖励模型 VP-Score，用以指导文本到图像生成模型的训练，其偏好预测的准确度与人类注释者不相上下。此外，我们采用两种强化学习方法对生成模型进行监督微调，并使用 VisionPrefer 进行性能评估，广泛的实验结果显示，VisionPrefer 在多样化维度上显著提升了文本与图像的一致性，比如审美，并在不同图像分布上比以往的人类偏好指标更具泛化能力。更重要的是，VisionPrefer 的研究指出，将 AI 生成的合成数据作为监督信号，是提高视觉生成模型与人类偏好一致性的一个充满希望的方向。",
    "title_cn": "多模态大型语言模型，作为文本到图像生成任务中的人类对齐注释器，展现出卓越的性能。",
    "tags": [
      "LLM应用",
      "图像生成",
      "人工智能"
    ]
  },
  {
    "title": "DesignProbe: A Graphic Design Benchmark for Multimodal Large Language Models",
    "submit_datetime": "2024年04月23日",
    "abstract": "A well-executed graphic design typically achieves harmony in two levels, from the fine-grained design elements (color, font and layout) to the overall design. This complexity makes the comprehension of graphic design challenging, for it needs the capability to both recognize the design elements and understand the design. With the rapid development of Multimodal Large Language Models (MLLMs), we establish the DesignProbe, a benchmark to investigate the capability of MLLMs in design. Our benchmark includes eight tasks in total, across both the fine-grained element level and the overall design level. At design element level, we consider both the attribute recognition and semantic understanding tasks. At overall design level, we include style and metaphor. 9 MLLMs are tested and we apply GPT-4 as evaluator. Besides, further experiments indicates that refining prompts can enhance the performance of MLLMs. We first rewrite the prompts by different LLMs and found increased performances appear in those who self-refined by their own LLMs. We then add extra task knowledge in two different ways (text descriptions and image examples), finding that adding images boost much more performance over texts.",
    "pdf_link": "https://arxiv.org/abs/2404.14801",
    "graphs": [],
    "abstract_cn": "精心设计的图形设计在细节元素（如色彩、字体和版式）和整体布局上通常达到和谐统一。这种设计复杂性的理解颇为不易，它要求既要识别设计元素，又要理解设计的深层含义。随着多模态大型语言模型（MLLMs）的迅猛发展，我们创建了DesignProbe这一基准测试，用以探究MLLMs在设计领域的能力。该基准测试包含八个任务，覆盖了从设计元素的细节到整体设计的宏观层面。在设计元素层面，我们既关注属性识别也注重语义理解。在整体设计层面，我们考量了风格和隐喻的使用。我们对9种MLLMs进行了测试，并采用GPT-4作为评判标准。此外，进一步的实验发现，优化提示可以显著提升MLLMs的表现。我们尝试用不同的LLMs重构提示，发现那些能够自我优化提示的模型性能有所提升。我们还尝试了两种添加额外任务知识的方法——文本描述和图像示例，结果表明，图像示例对性能的提升远超过文本描述。",
    "title_cn": "DesignProbe：为多模态大型语言模型量身打造的图形设计性能评估工具。",
    "tags": [
      "LLM应用",
      "图形设计",
      "人工智能"
    ]
  },
  {
    "title": "Single-temporal Supervised Remote Change Detection for Domain Generalization",
    "submit_datetime": "2024年04月23日",
    "abstract": "Change detection is widely applied in remote sensing image analysis. Existing methods require training models separately for each dataset, which leads to poor domain generalization. Moreover, these methods rely heavily on large amounts of high-quality pair-labelled data for training, which is expensive and impractical. In this paper, we propose a multimodal contrastive learning (ChangeCLIP) based on visual-language pre-training for change detection domain generalization. Additionally, we propose a dynamic context optimization for prompt learning. Meanwhile, to address the data dependency issue of existing methods, we introduce a single-temporal and controllable AI-generated training strategy (SAIN). This allows us to train the model using a large number of single-temporal images without image pairs in the real world, achieving excellent generalization. Extensive experiments on series of real change detection datasets validate the superiority and strong generalization of ChangeCLIP, outperforming state-of-the-art change detection methods. Code will be available.",
    "pdf_link": "https://arxiv.org/abs/2404.11326",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.11326v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11326/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11326v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11326/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11326v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11326/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11326v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11326/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11326v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11326/x5.png"
      }
    ],
    "abstract_cn": "变化检测技术在遥感图像分析领域扮演着重要角色。然而，传统方法需针对不同数据集分别训练模型，这限制了其泛化能力。它们还过分依赖大量高质量配对标记数据，这不仅成本高昂，也难以实现。本文提出了一种新颖的多模态对比学习方法ChangeCLIP，它基于视觉-语言预训练，旨在提升变化检测任务的领域泛化能力。我们还引入了动态上下文优化技术以增强提示学习的效果。为了克服现有方法对数据的依赖性，我们开发了一种单时相可控的人工智能生成训练策略SAIN，允许模型在无需成对图像的情况下，使用大量单时相图像进行训练，从而获得卓越的泛化性能。通过在多个真实变化检测数据集上的实验，我们证明了ChangeCLIP的优越性和强大的泛化能力，其性能超越了当前最先进方法。相关代码将公开提供。",
    "title_cn": "单时相的遥感变化检测技术，用于实现领域的泛化应用。",
    "tags": [
      "分类：Agent",
      "遥感图像分析",
      "人工智能"
    ]
  },
  {
    "title": "Review of Data-centric Time Series Analysis from Sample, Feature, and Period",
    "submit_datetime": "2024年04月23日",
    "abstract": "Data is essential to performing time series analysis utilizing machine learning approaches, whether for classic models or today's large language models. A good time-series dataset is advantageous for the model's accuracy, robustness, and convergence, as well as task outcomes and costs. The emergence of data-centric AI represents a shift in the landscape from model refinement to prioritizing data quality. Even though time-series data processing methods frequently come up in a wide range of research fields, it hasn't been well investigated as a specific topic. To fill the gap, in this paper, we systematically review different data-centric methods in time series analysis, covering a wide range of research topics. Based on the time-series data characteristics at sample, feature, and period, we propose a taxonomy for the reviewed data selection methods. In addition to discussing and summarizing their characteristics, benefits, and drawbacks targeting time-series data, we also introduce the challenges and opportunities by proposing recommendations, open problems, and possible research topics.",
    "pdf_link": "https://arxiv.org/abs/2404.16886",
    "graphs": [],
    "abstract_cn": "数据是运用机器学习进行时间序列分析的关键，无论是传统模型还是现代的大型语言模型。优质的时间序列数据集能够提升模型的精确度、稳定性和收敛速度，同时也能优化任务成果与成本效益。当前，以数据为核心的人工智能正引领着从模型优化到数据质量提升的转变。尽管时间序列数据处理在众多研究领域内频繁出现，但作为独立议题的研究尚显不足。本文旨在填补这一研究空白，系统性地审视时间序列分析中的多种数据驱动方法，并广泛覆盖了不同的研究议题。我们根据时间序列数据在样本、特征和周期上的特性，提出了一种数据选择方法的分类体系。文章不仅探讨并总结了这些方法的特点、优势和局限性，还针对时间序列数据的挑战和机遇提出了建议、开放性问题及潜在的研究课题。",
    "title_cn": "本文综述了以数据为核心的时间序列分析方法，涵盖了样本选择、特征提取和周期划分等关键方面。",
    "tags": [
      "分类：LLM应用",
      "时间序列分析",
      "数据科学"
    ]
  },
  {
    "title": "Decentralized Multi-Agent Trajectory Planning in Dynamic Environments with Spatiotemporal Occupancy Grid Maps",
    "submit_datetime": "2024年04月23日",
    "abstract": "This paper proposes a decentralized trajectory planning framework for the collision avoidance problem of multiple micro aerial vehicles (MAVs) in environments with static and dynamic obstacles. The framework utilizes spatiotemporal occupancy grid maps (SOGM), which forecast the occupancy status of neighboring space in the near future, as the environment representation. Based on this representation, we extend the kinodynamic A* and the corridor-constrained trajectory optimization algorithms to efficiently tackle static and dynamic obstacles with arbitrary shapes. Collision avoidance between communicating robots is integrated by sharing planned trajectories and projecting them onto the SOGM. The simulation results show that our method achieves competitive performance against state-of-the-art methods in dynamic environments with different numbers and shapes of obstacles. Finally, the proposed method is validated in real experiments.",
    "pdf_link": "https://arxiv.org/abs/2404.15602",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.15602v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15602/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15602v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15602/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15602v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15602/case0_arrow.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15602v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15602/case3_arrow.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15602v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15602/case4_arrow.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15602v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15602/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15602v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15602/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15602v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15602/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15602v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15602/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15602v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15602/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15602v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15602/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15602v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15602/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15602v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15602/header_figure.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15602v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15602/real_drone_exp_2100.png"
      }
    ],
    "abstract_cn": "本研究提出了一种分散式轨迹规划架构，专为多台微型空中机器人（MAVs）在充满静态及动态障碍物的环境中实现避碰设计。该架构采用预测性时空占用网格图（SOGM），以预测未来邻近区域的空间占用情况，作为环境的映射方式。在此基础上，我们对运动动力学A*搜索算法和走廊约束轨迹优化算法进行了扩展，有效应对了各种形状的静态和动态障碍物。通过机器人间共享规划轨迹并将其映射至SOGM，实现了通信机器人的避碰整合。仿真结果显示，该方法在包含不同数量和形状障碍物的动态环境中，性能与当前最先进技术相当。最终，该方法在实际实验中得到了成功验证。",
    "title_cn": "本文探讨了在动态环境中，利用时空占用网格图进行分散式多智能体的轨迹规划问题。",
    "tags": [
      "Agent",
      "机器人技术",
      ""
    ]
  },
  {
    "title": "GRSN: Gated Recurrent Spiking Neurons for POMDPs and MARL",
    "submit_datetime": "2024年04月23日",
    "abstract": "Spiking neural networks (SNNs) are widely applied in various fields due to their energy-efficient and fast-inference capabilities. Applying SNNs to reinforcement learning (RL) can significantly reduce the computational resource requirements for agents and improve the algorithm's performance under resource-constrained conditions. However, in current spiking reinforcement learning (SRL) algorithms, the simulation results of multiple time steps can only correspond to a single-step decision in RL. This is quite different from the real temporal dynamics in the brain and also fails to fully exploit the capacity of SNNs to process temporal data. In order to address this temporal mismatch issue and further take advantage of the inherent temporal dynamics of spiking neurons, we propose a novel temporal alignment paradigm (TAP) that leverages the single-step update of spiking neurons to accumulate historical state information in RL and introduces gated units to enhance the memory capacity of spiking neurons. Experimental results show that our method can solve partially observable Markov decision processes (POMDPs) and multi-agent cooperation problems with similar performance as recurrent neural networks (RNNs) but with about 50% power consumption.",
    "pdf_link": "https://arxiv.org/abs/2404.15597",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.15597v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15597/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15597v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15597/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15597v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15597/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15597v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15597/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15597v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15597/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15597v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15597/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15597v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15597/x7.png"
      }
    ],
    "abstract_cn": "尖峰神经网络（SNNs）以其高效节能和迅速推理的特性，在众多领域得到广泛应用。应用于强化学习（RL）的 SNNs 能够显著降低智能体的计算资源需求，并在资源受限的环境下优化算法表现。不过，现有尖峰强化学习（SRL）算法中存在一个问题：多时间步的模拟结果仅能对应于 RL 中的一个决策步骤，这与大脑的真实时间动态差异显著，也未能充分发挥 SNNs 在处理时间序列数据方面的潜力。为解决这一时序不匹配问题，并进一步挖掘尖峰神经元的时间动态特性，我们提出了一种创新的时序对齐范式（TAP），该范式通过尖峰神经元的单步更新机制来积累 RL 中的历史状态信息，并通过引入门控单元来提升尖峰神经元的记忆容量。实验结果显示，该方法在解决部分可观测马尔可夫决策过程（POMDPs）和多智能体协作问题上，能够达到与循环神经网络（RNNs）相当的性能，同时功耗降低了大约 50%。",
    "title_cn": "GRSN：为 POMDP 和 MARL 打造的门控循环脉冲神经网络",
    "tags": [
      "Agent",
      "",
      "神经网络"
    ]
  },
  {
    "title": "GeoLLM-Engine: A Realistic Environment for Building Geospatial Copilots",
    "submit_datetime": "2024年04月23日",
    "abstract": "Geospatial Copilots unlock unprecedented potential for performing Earth Observation (EO) applications through natural language instructions. However, existing agents rely on overly simplified single tasks and template-based prompts, creating a disconnect with real-world scenarios. In this work, we present GeoLLM-Engine, an environment for tool-augmented agents with intricate tasks routinely executed by analysts on remote sensing platforms. We enrich our environment with geospatial API tools, dynamic maps/UIs, and external multimodal knowledge bases to properly gauge an agent's proficiency in interpreting realistic high-level natural language commands and its functional correctness in task completions. By alleviating overheads typically associated with human-in-the-loop benchmark curation, we harness our massively parallel engine across 100 GPT-4-Turbo nodes, scaling to over half a million diverse multi-tool tasks and across 1.1 million satellite images. By moving beyond traditional single-task image-caption paradigms, we investigate state-of-the-art agents and prompting techniques against long-horizon prompts.",
    "pdf_link": "https://arxiv.org/abs/2404.15500",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.15500v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15500/geo_engine.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15500v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15500/rs_datasets.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15500v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15500/combined_plots.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15500v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15500/combined_pies.png"
      }
    ],
    "abstract_cn": "地理空间副驾驶利用自然语言指令，为地球观测应用开辟了巨大潜力。但目前的技术依赖于简化的单一任务和模板化指令，与现实应用场景存在差异。本研究介绍了GeoLLM-Engine，这是一个为复杂任务设计的工具辅助代理环境，这些任务通常由分析师在遥感平台上执行。我们通过集成地理空间API、动态地图界面和多模态知识库，增强了环境的功能性，以准确评估代理对高级自然语言指令的理解和任务执行的准确性。我们的大规模并行引擎在100个GPT-4-Turbo节点上运行，处理了超过五十万个多工具任务和110万张卫星图像，减少了人工参与的基准测试策划的负担。我们超越了传统的单任务图像描述模式，探索了最先进的代理和提示技术在长期提示下的表现。",
    "title_cn": "GeoLLM-Engine：打造地理空间领域智能副驾驶的现实平台",
    "tags": [
      "Agent",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Adaptive Mechanism Design using Multi-Agent Revealed Preferences",
    "submit_datetime": "2024年04月23日",
    "abstract": "This paper constructs an algorithmic framework for adaptively achieving the mechanism design objective, finding a mechanism inducing socially optimal Nash equilibria, without knowledge of the utility functions of the agents. We consider a probing scheme where the designer can iteratively enact mechanisms and observe Nash equilibria responses. We first derive necessary and sufficient conditions, taking the form of linear program feasibility, for the existence of utility functions under which the empirical Nash equilibria responses are socially optimal. Then, we utilize this to construct a loss function with respect to the mechanism, and show that its global minimization occurs at mechanisms under which Nash equilibria system responses are also socially optimal. We develop a simulated annealing-based gradient algorithm, and prove that it converges in probability to this set of global minima, thus achieving adaptive mechanism design.",
    "pdf_link": "https://arxiv.org/abs/2404.15391",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.15391v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15391/x1.png"
      }
    ],
    "abstract_cn": "本研究提出了一种算法架构，旨在灵活实现机制设计目标，即寻找能够激发社会最优纳什均衡的机制，而无需事先知晓参与者的效用函数。通过一种探测方案，设计者可以逐步实施机制并观察所引发的纳什均衡反应。我们首先确定了一组必要且充分的条件，这些条件以线性规划的可行性形式呈现，确保在这些条件下，实证纳什均衡反应能够达到社会最优。接着，我们基于这些条件构建了一个损失函数，并证明了当机制使得纳什均衡系统反应达到社会最优时，该损失函数能够实现全局最小化。我们进一步开发了一种基于模拟退火的梯度算法，并通过证明其以概率收敛到全局最小值集，从而完成了自适应机制设计的构想。",
    "title_cn": "本文探讨了一种基于多智能体揭示偏好的自适应机制设计方法，旨在优化智能体间的交互和决策过程。",
    "tags": [
      "分类：Agent",
      "经济学",
      "算法设计"
    ]
  },
  {
    "title": "From Space-Time to Space-Order: Directly Planning a Temporal Planning Graph by Redefining CBS",
    "submit_datetime": "2024年04月23日",
    "abstract": "The majority of multi-agent path finding (MAPF) methods compute collision-free space-time paths which require agents to be at a specific location at a specific discretized timestep. However, executing these space-time paths directly on robotic systems is infeasible due to real-time execution differences (e.g. delays) which can lead to collisions. To combat this, current methods translate the space-time paths into a temporal plan graph (TPG) that only requires that agents observe the order in which they navigate through locations where their paths cross. However, planning space-time paths and then post-processing them into a TPG does not reduce the required agent-to-agent coordination, which is fixed once the space-time paths are computed. To that end, we propose a novel algorithm Space-Order CBS that can directly plan a TPG and explicitly minimize coordination. Our main theoretical insight is our novel perspective on viewing a TPG as a set of space-visitation order paths where agents visit locations in relative orders (e.g. 1st vs 2nd) as opposed to specific timesteps. We redefine unique conflicts and constraints for adapting CBS for space-order planning. We experimentally validate how Space-Order CBS can return TPGs which significantly reduce coordination, thus subsequently reducing the amount of agent-agent communication and leading to more robustness to delays during execution.",
    "pdf_link": "https://arxiv.org/abs/2404.15137",
    "graphs": [],
    "abstract_cn": "多智能体路径规划（MAPF）的主流方法旨在计算出避免碰撞的空间-时间路径，规定智能体需在特定时间点位于特定位置。但这些路径直接应用于机器人系统并不现实，因为实时执行中的各种差异（如延迟）可能引发碰撞。为解决这一问题，现有技术将这些路径转化为时间规划图（TPG），智能体只需遵循它们通过交叉点的顺序。不过，这种先将路径规划出来再转换成TPG的做法，并未能简化智能体间的协调需求。针对这一点，我们提出了一种创新算法——Space-Order CBS，它能够直接规划出TPG，并且有效减少所需的协调。我们的创新之处在于重新定义了TPG，将其视为一系列空间访问顺序路径，智能体根据相对顺序而非固定时间点来访问位置。我们为适应空间顺序规划重新定义了冲突和约束。实验结果表明，Space-Order CBS能够生成TPG，显著降低智能体间的协调需求，减少通信量，并提高对执行过程中延迟的适应性。",
    "title_cn": "由时空转至时序：重新定义 CBS 以直接构建时间规划图。",
    "tags": [
      "Agent",
      "机器人技术",
      "人工智能"
    ]
  },
  {
    "title": "Multi-Objective Deep Reinforcement Learning for 5G Base Station Placement to Support Localisation for Future Sustainable Traffic",
    "submit_datetime": "2024年04月23日",
    "abstract": "Millimeter-wave (mmWave) is a key enabler for next-generation transportation systems. However, in an urban city scenario, mmWave is highly susceptible to blockages and shadowing. Therefore, base station (BS) placement is a crucial task in the infrastructure design where coverage requirements need to be met while simultaneously supporting localisation. This work assumes a pre-deployed BS and another BS is required to be added to support both localisation accuracy and coverage rate in an urban city scenario. To solve this complex multi-objective optimisation problem, we utilise deep reinforcement learning (DRL). Concretely, this work proposes: 1) a three-layered grid for state representation as the input of the DRL, which enables it to adapt to the changes in the wireless environment represented by changing the position of the pre-deployed BS, and 2) the design of a suitable reward function for the DRL agent to solve the multi-objective problem. Numerical analysis shows that the proposed deep Q-network (DQN) model can learn/adapt from the complex radio environment represented by the terrain map and provides the same/similar solution to the exhaustive search, which is used as a benchmark. In addition, we show that an exclusive optimisation of coverage rate does not result in improved localisation accuracy, and thus there is a trade-off between the two solutions.",
    "pdf_link": "https://arxiv.org/abs/2404.14954",
    "graphs": [],
    "abstract_cn": "毫米波通信技术在推动未来交通系统的发展中扮演着至关重要的角色。但在城市场景中，它极易受到遮挡和阴影效应的影响。因此，精心规划基站的布局，以满足覆盖需求并辅助定位功能，成为了基础设施设计中的一个关键环节。本研究在已有基站的基础上，探讨了如何利用深度强化学习方法，进一步部署一个新的基站以提升城市环境中的定位精度和信号覆盖。研究提出了一种三层网格状态表示法，作为深度强化学习模型的输入，使其能够灵活应对无线环境的变化。同时，设计了一个合适的奖励函数，以解决多目标优化问题。通过数值分析，证实了所提出的深度Q网络模型能够有效适应复杂多变的无线电环境，并与穷举搜索方法相比，提供了同样高效或类似的解决方案。此外，研究还发现，单纯追求覆盖率的优化并不能提升定位精度，从而揭示了两者之间存在的权衡关系。",
    "title_cn": "采用多目标深度强化学习方法，优化5G基站布局，以支持未来交通的可持续发展和精确定位。",
    "tags": [
      "Agent",
      "交通系统",
      "通信技术"
    ]
  },
  {
    "title": "Can Foundational Large Language Models Assist with Conducting Pharmaceuticals Manufacturing Investigations?",
    "submit_datetime": "2024年04月23日",
    "abstract": "General purpose Large Language Models (LLM) such as the Generative Pretrained Transformer (GPT) and Large Language Model Meta AI (LLaMA) have attracted much attention in recent years. There is strong evidence that these models can perform remarkably well in various natural language processing tasks. However, how to leverage them to approach domain-specific use cases and drive value remains an open question. In this work, we focus on a specific use case, pharmaceutical manufacturing investigations, and propose that leveraging historical records of manufacturing incidents and deviations in an organization can be beneficial for addressing and closing new cases, or de-risking new manufacturing campaigns. Using a small but diverse dataset of real manufacturing deviations selected from different product lines, we evaluate and quantify the power of three general purpose LLMs (GPT-3.5, GPT-4, and Claude-2) in performing tasks related to the above goal. In particular, (1) the ability of LLMs in automating the process of extracting specific information such as root cause of a case from unstructured data, as well as (2) the possibility of identifying similar or related deviations by performing semantic search on the database of historical records are examined. While our results point to the high accuracy of GPT-4 and Claude-2 in the information extraction task, we discuss cases of complex interplay between the apparent reasoning and hallucination behavior of LLMs as a risk factor. Furthermore, we show that semantic search on vector embedding of deviation descriptions can be used to identify similar records, such as those with a similar type of defect, with a high level of accuracy. We discuss further improvements to enhance the accuracy of similar record identification.",
    "pdf_link": "https://arxiv.org/abs/2404.15578",
    "graphs": [],
    "abstract_cn": "近年来，诸如生成预训练变换器（GPT）和大型语言模型元人工智能（LLaMA）等通用大型语言模型（LLM）备受瞩目，并在自然语言处理任务中展现出卓越性能。但如何有效利用这些模型以适应特定领域的应用场景，仍是一个待解之谜。本研究着眼于制药制造业调查这一特定用例，提出通过利用企业中制造事故和偏差的历史档案，有助于处理新案例或降低新生产活动的潜在风险。我们选取了来自不同生产线的真实制造偏差数据，虽规模不大但类型多样，以此评估了三款主流LLM（GPT-3.5、GPT-4和Claude-2）在相关任务上的表现。研究特别关注了：（1）LLM自动从非结构化数据中提取关键信息，如案例根本原因的能力；（2）通过语义搜索历史记录数据库，识别相似或相关偏差的可能性。GPT-4和Claude-2在信息提取任务上的高准确率表现引人注目，同时我们也探讨了LLM在推理与幻觉行为间的复杂互动，及其作为风险因素的考量。此外，我们还展示了通过向量嵌入进行语义搜索，能够高效识别具有相似缺陷类型的相关记录。文章进一步讨论了如何提升识别相似记录的准确性的潜在改进措施。",
    "title_cn": "基础性的大型语言模型是否能够帮助我们开展药品制造业的调查研究？",
    "tags": [
      "LLM应用",
      "制药制造",
      ""
    ]
  },
  {
    "title": "Evaluating Tool-Augmented Agents in Remote Sensing Platforms",
    "submit_datetime": "2024年04月23日",
    "abstract": "Tool-augmented Large Language Models (LLMs) have shown impressive capabilities in remote sensing (RS) applications. However, existing benchmarks assume question-answering input templates over predefined image-text data pairs. These standalone instructions neglect the intricacies of realistic user-grounded tasks. Consider a geospatial analyst: they zoom in a map area, they draw a region over which to collect satellite imagery, and they succinctly ask \"Detect all objects here\". Where is `here`, if it is not explicitly hardcoded in the image-text template, but instead is implied by the system state, e.g., the live map positioning? To bridge this gap, we present GeoLLM-QA, a benchmark designed to capture long sequences of verbal, visual, and click-based actions on a real UI platform. Through in-depth evaluation of state-of-the-art LLMs over a diverse set of 1,000 tasks, we offer insights towards stronger agents for RS applications.",
    "pdf_link": "https://arxiv.org/abs/2405.00709",
    "graphs": [],
    "abstract_cn": "增强版的大型语言模型（LLMs）在遥感（RS）领域展现出了卓越的性能。但现有的评估标准通常基于预设的图文数据对，采用问答式的输入模板，忽略了真实用户任务的复杂性。想象一位地理空间分析师的操作：他们放大地图的特定区域，选定一个区域来搜集卫星图像，然后简洁地提出“检测这里的所有物体”。如果“这里”并非模板中硬编码指定，而是需要系统根据实时地图定位等状态信息来理解，那么该如何界定“这里”的范围？为了解决这一问题，我们设计了GeoLLM-QA，这是一个新型基准测试，旨在模拟真实用户界面上的语言、视觉和点击操作的长序列。通过对当前顶尖的LLMs在1000项多样化任务上进行深入评估，我们为提升RS应用中的智能代理提供了宝贵的洞见。",
    "title_cn": "在遥感平台上，对工具辅助代理的评估",
    "tags": [
      "Agent",
      "",
      "地理空间分析"
    ]
  },
  {
    "title": "Tree of Reviews: A Tree-based Dynamic Iterative Retrieval Framework for Multi-hop Question Answering",
    "submit_datetime": "2024年04月22日",
    "abstract": "Multi-hop question answering is a knowledge-intensive complex problem. Large Language Models (LLMs) use their Chain of Thoughts (CoT) capability to reason complex problems step by step, and retrieval-augmentation can effectively alleviate factual errors caused by outdated and unknown knowledge in LLMs. Recent works have introduced retrieval-augmentation in the CoT reasoning to solve multi-hop question answering. However, these chain methods have the following problems: 1) Retrieved irrelevant paragraphs may mislead the reasoning; 2) An error in the chain structure may lead to a cascade of errors.\n  In this paper, we propose a dynamic retrieval framework called Tree of Reviews (ToR), where the root node is the question, and the other nodes are paragraphs from retrieval, extending different reasoning paths from the root node to other nodes. Our framework dynamically decides to initiate a new search, reject, or accept based on the paragraphs on the reasoning paths. Compared to related work, we introduce a tree structure to handle each retrieved paragraph separately, alleviating the misleading effect of irrelevant paragraphs on the reasoning path; the diversity of reasoning path extension reduces the impact of a single reasoning error on the whole. We conducted experiments on three different multi-hop question answering datasets. The results show that compared to the baseline methods, ToR achieves state-of-the-art performance in both retrieval and response generation. In addition, we propose two tree-based search optimization strategies, pruning and effective expansion, to reduce time overhead and increase the diversity of path extension. We will release our code.",
    "pdf_link": "https://arxiv.org/abs/2404.14464",
    "graphs": [],
    "abstract_cn": "多跳问答是一项复杂且知识密集的任务。大型语言模型（LLMs）通过思维链（CoT）逐步分析并解决复杂问题，而检索增强技术有效减少了因知识陈旧或未知所导致的错误。近期研究将检索增强应用于CoT推理，以应对多跳问答的挑战。但现有链式方法存在两大问题：一是检索到的无关段落可能干扰推理过程；二是链结构中的任何错误都可能引发连锁反应。本文提出了一种新颖的动态检索框架——评审树（ToR），其以问题为根节点，其他节点为检索所得的段落，构建从根节点到其他节点的多样化推理路径。该框架能够根据推理路径上的段落动态决定是否发起新搜索、拒绝或接受。与现有方法相比，ToR通过树状结构独立处理每个检索段落，减少了无关信息对推理的干扰；同时，推理路径的多样性也降低了单一错误对整体推理的影响。我们在三个不同的多跳问答数据集上进行了实验，ToR在检索和回答生成方面均实现了业界领先的性能。此外，我们还提出了两种基于树的搜索优化策略——剪枝和有效扩展，旨在减少时间消耗并提升路径扩展的多样性。我们将公开我们的代码。",
    "title_cn": "《评论之树：面向多步问答的基于树状动态迭代检索框架》",
    "tags": [
      "LLM应用",
      "问答系统",
      "信息检索"
    ]
  },
  {
    "title": "LLMs Know What They Need: Leveraging a Missing Information Guided Framework to Empower Retrieval-Augmented Generation",
    "submit_datetime": "2024年04月22日",
    "abstract": "Retrieval-Augmented Generation (RAG) demonstrates great value in alleviating outdated knowledge or hallucination by supplying LLMs with updated and relevant knowledge. However, there are still several difficulties for RAG in understanding complex multi-hop query and retrieving relevant documents, which require LLMs to perform reasoning and retrieve step by step. Inspired by human's reasoning process in which they gradually search for the required information, it is natural to ask whether the LLMs could notice the missing information in each reasoning step. In this work, we first experimentally verified the ability of LLMs to extract information as well as to know the missing. Based on the above discovery, we propose a Missing Information Guided Retrieve-Extraction-Solving paradigm (MIGRES), where we leverage the identification of missing information to generate a targeted query that steers the subsequent knowledge retrieval. Besides, we design a sentence-level re-ranking filtering approach to filter the irrelevant content out from document, along with the information extraction capability of LLMs to extract useful information from cleaned-up documents, which in turn to bolster the overall efficacy of RAG. Extensive experiments conducted on multiple public datasets reveal the superiority of the proposed MIGRES method, and analytical experiments demonstrate the effectiveness of our proposed modules.",
    "pdf_link": "https://arxiv.org/abs/2404.14043",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.14043v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14043/x1.png"
      }
    ],
    "abstract_cn": "检索增强生成（RAG）通过向大型语言模型（LLMs）注入最新和贴切的知识，有效缓解了知识过时或产生幻觉的问题。尽管如此，RAG 在解析复杂多跳查询和定位相关文档上仍面临挑战，这要求 LLMs 逐步进行逻辑推理和检索。借鉴人类逐步搜寻所需信息的推理方式，我们自然会产生疑问：LLMs 是否能够察觉到每个逻辑推理步骤中的信息空缺。在本研究中，我们首先通过实验确认了 LLMs 在提取信息和识别缺失信息方面的能力。基于这一发现，我们提出了一种新的范式——缺失信息引导的检索-提取-解决（MIGRES），利用识别出的信息缺失点来生成针对性的查询，从而引导接下来的知识检索过程。此外，我们还设计了一种基于句子级别的重新排序过滤方法，用以排除文档中的无关内容，并结合 LLMs 的信息提取功能，从净化后的文档中抽取有用信息，以此提升 RAG 的整体效能。我们在多个公共数据集上进行的广泛实验显示了 MIGRES 方法的优越性，而深入的分析实验也验证了我们所提模块的有效性。",
    "title_cn": "大型语言模型（LLMs）自有所需：借助缺失信息导向框架，提升检索增强型生成能力。",
    "tags": [
      "RAG",
      "信息检索",
      ""
    ]
  },
  {
    "title": "Typos that Broke the RAG's Back: Genetic Attack on RAG Pipeline by Simulating Documents in the Wild via Low-level Perturbations",
    "submit_datetime": "2024年04月22日",
    "abstract": "The robustness of recent Large Language Models (LLMs) has become increasingly crucial as their applicability expands across various domains and real-world applications. Retrieval-Augmented Generation (RAG) is a promising solution for addressing the limitations of LLMs, yet existing studies on the robustness of RAG often overlook the interconnected relationships between RAG components or the potential threats prevalent in real-world databases, such as minor textual errors. In this work, we investigate two underexplored aspects when assessing the robustness of RAG: 1) vulnerability to noisy documents through low-level perturbations and 2) a holistic evaluation of RAG robustness. Furthermore, we introduce a novel attack method, the Genetic Attack on RAG (\\textit{GARAG}), which targets these aspects. Specifically, GARAG is designed to reveal vulnerabilities within each component and test the overall system functionality against noisy documents. We validate RAG robustness by applying our \\textit{GARAG} to standard QA datasets, incorporating diverse retrievers and LLMs. The experimental results show that GARAG consistently achieves high attack success rates. Also, it significantly devastates the performance of each component and their synergy, highlighting the substantial risk that minor textual inaccuracies pose in disrupting RAG systems in the real world.",
    "pdf_link": "https://arxiv.org/abs/2404.13948",
    "graphs": [],
    "abstract_cn": "随着大型语言模型（LLMs）在多个领域和实际应用中的广泛应用，其鲁棒性变得日益关键。检索增强生成（RAG）作为一种应对LLMs局限性的解决方案，展现出巨大潜力。但是，目前对RAG鲁棒性的研究往往忽略了RAG组件间的内在联系以及现实世界数据库中常见的潜在威胁，如微小的文本错误。在本研究中，我们深入探讨了评估RAG鲁棒性的两个未被充分研究的维度：一是对含噪声文档的低层次扰动的敏感性；二是对RAG鲁棒性的全面评估。此外，我们提出了一种创新的攻击方法——遗传攻击RAG（GARAG），专门针对这些维度。GARAG设计用来暴露各个组件的弱点，并检验系统在面对噪声文档时的整体功能。我们通过将GARAG应用于标准问答（QA）数据集，并结合多种检索器和LLMs，来验证RAG的鲁棒性。实验结果显示，GARAG在攻击成功率上持续保持高水平，显著降低了各组件及其协同工作的性能，从而突显了现实世界中微小文本错误对RAG系统稳定性构成的重大威胁。",
    "title_cn": "错字引发的 RAG 崩溃：通过细微扰动在现实文档中模拟，对 RAG 流程发起基因级攻击",
    "tags": [
      "分类：RAG",
      "",
      "信息检索"
    ]
  },
  {
    "title": "\"Where am I?\" Scene Retrieval with Language",
    "submit_datetime": "2024年04月22日",
    "abstract": "Natural language interfaces to embodied AI are becoming more ubiquitous in our daily lives. This opens further opportunities for language-based interaction with embodied agents, such as a user instructing an agent to execute some task in a specific location. For example, \"put the bowls back in the cupboard next to the fridge\" or \"meet me at the intersection under the red sign.\" As such, we need methods that interface between natural language and map representations of the environment. To this end, we explore the question of whether we can use an open-set natural language query to identify a scene represented by a 3D scene graph. We define this task as \"language-based scene-retrieval\" and it is closely related to \"coarse-localization,\" but we are instead searching for a match from a collection of disjoint scenes and not necessarily a large-scale continuous map. Therefore, we present Text2SceneGraphMatcher, a \"scene-retrieval\" pipeline that learns joint embeddings between text descriptions and scene graphs to determine if they are matched. The code, trained models, and datasets will be made public.",
    "pdf_link": "https://arxiv.org/abs/2404.14565",
    "graphs": [],
    "abstract_cn": "自然语言界面在具身智能领域的应用日益广泛，为我们与智能代理进行基于语言的互动提供了更多可能，如指导代理在特定地点完成任务。举例来说，用户可能会说：“把碗放回冰箱旁的橱柜里”，或者“在那个有红色标志的十字路口见我”。为了实现这一功能，我们需要一种能够将自然语言与环境地图表示形式相连接的方法。基于此，我们研究了一个关键问题：我们能否通过开放式自然语言查询来识别由3D场景图表示的场景。我们将这一任务命名为“基于语言的场景检索”，它与“粗略定位”有关，但我们的目标是在一系列独立的3D场景集合中寻找匹配项，而非在大规模连续地图上。因此，我们开发了Text2SceneGraphMatcher，这是一个学习文本描述与场景图之间联合嵌入的“场景检索”流程，用以判断它们是否匹配。相关的代码、训练好的模型以及数据集将对公众开放。",
    "title_cn": "“我身在何方？”通过语言技术实现场景检索",
    "tags": [
      "Agent",
      "具身智能",
      ""
    ]
  },
  {
    "title": "A Survey on Self-Evolution of Large Language Models",
    "submit_datetime": "2024年04月22日",
    "abstract": "Large language models (LLMs) have significantly advanced in various fields and intelligent agent applications. However, current LLMs that learn from human or external model supervision are costly and may face performance ceilings as task complexity and diversity increase. To address this issue, self-evolution approaches that enable LLM to autonomously acquire, refine, and learn from experiences generated by the model itself are rapidly growing. This new training paradigm inspired by the human experiential learning process offers the potential to scale LLMs towards superintelligence. In this work, we present a comprehensive survey of self-evolution approaches in LLMs. We first propose a conceptual framework for self-evolution and outline the evolving process as iterative cycles composed of four phases: experience acquisition, experience refinement, updating, and evaluation. Second, we categorize the evolution objectives of LLMs and LLM-based agents; then, we summarize the literature and provide taxonomy and insights for each module. Lastly, we pinpoint existing challenges and propose future directions to improve self-evolution frameworks, equipping researchers with critical insights to fast-track the development of self-evolving LLMs.",
    "pdf_link": "https://arxiv.org/abs/2404.14387",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.14387v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14387/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14387v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14387/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14387v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14387/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14387v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14387/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14387v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14387/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14387v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14387/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14387v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14387/x7.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）在多个领域和智能代理应用上取得了突破性进展。尽管如此，依赖人类或外部模型监督的LLMs不仅成本高昂，而且随着任务的复杂和多变，它们的性能提升也遇到了瓶颈。为突破这一局限，一种新兴的自我进化方法应运而生，它允许LLMs自主地从自身生成的经验中学习、提炼和进化。这种训练新范式，模仿人类的体验学习过程，为LLMs向超智能的跨越式发展提供了可能。在本研究中，我们全面审视了LLMs中的自我进化策略。我们首先构建了一个自我进化的概念性框架，并将其演进过程划分为四个循环迭代的阶段：经验获取、经验优化、更新和评估。接着，我们对LLMs及其代理的进化目标进行了分类，并综述了相关文献，为每个模块提供了系统的分类和深入的洞见。最后，我们指出了当前面临的挑战，并对未来的研究方向提出了建议，旨在为研究人员提供宝贵的见解，以加速自我进化LLMs的研究进程。",
    "title_cn": "大型语言模型的自我进化研究综述",
    "tags": [
      "分类：LLM理论",
      "人工智能",
      ""
    ]
  },
  {
    "title": "FINEMATCH: Aspect-based Fine-grained Image and Text Mismatch Detection and Correction",
    "submit_datetime": "2024年04月22日",
    "abstract": "Recent progress in large-scale pre-training has led to the development of advanced vision-language models (VLMs) with remarkable proficiency in comprehending and generating multimodal content. Despite the impressive ability to perform complex reasoning for VLMs, current models often struggle to effectively and precisely capture the compositional information on both the image and text sides. To address this, we propose FineMatch, a new aspect-based fine-grained text and image matching benchmark, focusing on text and image mismatch detection and correction. This benchmark introduces a novel task for boosting and evaluating the VLMs' compositionality for aspect-based fine-grained text and image matching. In this task, models are required to identify mismatched aspect phrases within a caption, determine the aspect's class, and propose corrections for an image-text pair that may contain between 0 and 3 mismatches. To evaluate the models' performance on this new task, we propose a new evaluation metric named ITM-IoU for which our experiments show a high correlation to human evaluation. In addition, we also provide a comprehensive experimental analysis of existing mainstream VLMs, including fully supervised learning and in-context learning settings. We have found that models trained on FineMatch demonstrate enhanced proficiency in detecting fine-grained text and image mismatches. Moreover, models (e.g., GPT-4V, Gemini Pro Vision) with strong abilities to perform multimodal in-context learning are not as skilled at fine-grained compositional image and text matching analysis. With FineMatch, we are able to build a system for text-to-image generation hallucination detection and correction.",
    "pdf_link": "https://arxiv.org/abs/2404.14715",
    "graphs": [],
    "abstract_cn": "最新在大规模预训练领域的进展催生了视觉-语言模型（VLMs）的突破，这些模型在理解和创造多模态内容上展现出非凡的才能。尽管VLMs在复杂推理方面表现出色，但现有模型在准确捕捉图像和文本的组合信息上仍面临挑战。为此，我们引入了FineMatch，这是一个创新的基于方面的细粒度文本与图像匹配基准，专注于检测和纠正文本与图像的不匹配。该基准旨在推动和评估VLMs在细粒度文本与图像匹配方面的组合能力。在这项新任务中，模型需识别出标题中的不匹配方面短语，确定其类别，并为可能存在0至3处不匹配的图像-文本对提出修正建议。我们设计了一个新的评估指标ITM-IoU来衡量模型在这一新任务上的表现，实验结果显示其与人工评估高度相关。此外，我们还对现有的主流VLMs进行了全面的实验分析，包括全面监督学习和上下文学习环境。研究发现，通过FineMatch训练的模型在识别细粒度文本和图像不匹配方面更加精准。同时，我们也发现，虽然一些模型（如GPT-4V，Gemini Pro Vision）在多模态上下文学习方面表现出色，但在进行细粒度组合图像和文本匹配分析时却不够精细。FineMatch的推出，使我们得以构建一个系统，用于检测和纠正文本到图像生成中的幻觉问题。",
    "title_cn": "FINEMATCH：面向细粒度的图像与文本不匹配问题的基于方面的检测与校正技术",
    "tags": [
      "LLM应用",
      "计算机视觉",
      ""
    ]
  },
  {
    "title": "WangLab at MEDIQA-M3G 2024: Multimodal Medical Answer Generation using Large Language Models",
    "submit_datetime": "2024年04月22日",
    "abstract": "This paper outlines our submission to the MEDIQA2024 Multilingual and Multimodal Medical Answer Generation (M3G) shared task. We report results for two standalone solutions under the English category of the task, the first involving two consecutive API calls to the Claude 3 Opus API and the second involving training an image-disease label joint embedding in the style of CLIP for image classification. These two solutions scored 1st and 2nd place respectively on the competition leaderboard, substantially outperforming the next best solution. Additionally, we discuss insights gained from post-competition experiments. While the performance of these two solutions have significant room for improvement due to the difficulty of the shared task and the challenging nature of medical visual question answering in general, we identify the multi-stage LLM approach and the CLIP image classification approach as promising avenues for further investigation.",
    "pdf_link": "https://arxiv.org/abs/2404.14567",
    "graphs": [],
    "abstract_cn": "本文介绍了我们为 MEDIQA2024 多语言多模态医学答案生成（M3G）任务所提交的研究成果。在该任务的英语部分，我们提出了两种独立方法：第一种方法是连续两次调用 Claude 3 Opus API，第二种方法是采用 CLIP 技术训练图像与疾病标签的联合嵌入模型以进行图像分类。这两种方法在竞赛排行榜上分别荣获第一和第二名，大幅领先于其他解决方案。文章还分享了赛后实验的深刻见解。尽管面对任务的复杂性和医学视觉问答的普遍挑战，这两种解决方案的表现尚有提升空间，但我们看好多阶段大型语言模型（LLM）方法和 CLIP 图像分类方法，认为它们是未来研究的有前景方向。",
    "title_cn": "在 2024 年的 MEDIQA-M3G 大会上，WangLab 展示了一项创新成果：运用先进的大型语言模型，实现了多模态医学问题的智能答案生成。",
    "tags": [
      "分类：LLM应用\n\n这篇论文摘要介绍了两个独立的方法，它们在MEDIQA2024多语言多模态医学答案生成任务的英语部分中表现出色。第一个方法涉及连续两次调用Claude 3 Opus API，而第二个方法则采用CLIP技术来训练图像与疾病标签的联合嵌入模型。这两种方法在竞赛中获得了第一名和第二名，表明了大型语言模型（LLM）在实际应用中的潜力。此外，论文还提到了对赛后实验的深入见解，以及对未来研究方向的展望。因此，这篇论文可以归类为LLM应用。",
      "",
      "图像识别"
    ]
  },
  {
    "title": "Graphic Design with Large Multimodal Model",
    "submit_datetime": "2024年04月22日",
    "abstract": "In the field of graphic design, automating the integration of design elements into a cohesive multi-layered artwork not only boosts productivity but also paves the way for the democratization of graphic design. One existing practice is Graphic Layout Generation (GLG), which aims to layout sequential design elements. It has been constrained by the necessity for a predefined correct sequence of layers, thus limiting creative potential and increasing user workload. In this paper, we present Hierarchical Layout Generation (HLG) as a more flexible and pragmatic setup, which creates graphic composition from unordered sets of design elements. To tackle the HLG task, we introduce Graphist, the first layout generation model based on large multimodal models. Graphist efficiently reframes the HLG as a sequence generation problem, utilizing RGB-A images as input, outputs a JSON draft protocol, indicating the coordinates, size, and order of each element. We develop new evaluation metrics for HLG. Graphist outperforms prior arts and establishes a strong baseline for this field. Project homepage: https://github.com/graphic-design-ai/graphist",
    "pdf_link": "https://arxiv.org/abs/2404.14368",
    "graphs": [],
    "abstract_cn": "在平面设计界，自动化地将设计元素融合为一个和谐的多层艺术作品，既提升了效率，也为设计的普及化开辟了新径。目前，图形布局生成（GLG）技术正致力于有序地排列设计元素，但这种做法因要求预先设定正确的层级顺序而受限，这不仅束缚了创意的翅膀，也加重了用户的工作负担。本文提出了一种新颖的分层布局生成（HLG）方法，它以一种更灵活、更实用的框架，从无序的设计元素集合中创造出图形构图。为应对HLG挑战，我们推出了Graphist——首个基于大型多模态模型的布局生成模型。Graphist巧妙地将HLG问题转化为序列生成问题，输入RGB-A图像，输出包含坐标、尺寸和元素顺序信息的JSON草稿协议。我们还为HLG任务设计了全新的评估标准，Graphist在这些标准上超越了先前的技术，并为该领域设定了新的基准。项目网址：https://github.com/graphic-design-ai/graphist",
    "title_cn": "大型多模态模型在图形设计中的应用",
    "tags": [
      "LLM应用",
      "平面设计",
      "自动化设计"
    ]
  },
  {
    "title": "UrbanCross: Enhancing Satellite Image-Text Retrieval with Cross-Domain Adaptation",
    "submit_datetime": "2024年04月22日",
    "abstract": "Urbanization challenges underscore the necessity for effective satellite image-text retrieval methods to swiftly access specific information enriched with geographic semantics for urban applications. However, existing methods often overlook significant domain gaps across diverse urban landscapes, primarily focusing on enhancing retrieval performance within single domains. To tackle this issue, we present UrbanCross, a new framework for cross-domain satellite image-text retrieval. UrbanCross leverages a high-quality, cross-domain dataset enriched with extensive geo-tags from three countries to highlight domain diversity. It employs the Large Multimodal Model (LMM) for textual refinement and the Segment Anything Model (SAM) for visual augmentation, achieving a fine-grained alignment of images, segments and texts, yielding a 10% improvement in retrieval performance. Additionally, UrbanCross incorporates an adaptive curriculum-based source sampler and a weighted adversarial cross-domain fine-tuning module, progressively enhancing adaptability across various domains. Extensive experiments confirm UrbanCross's superior efficiency in retrieval and adaptation to new urban environments, demonstrating an average performance increase of 15% over its version without domain adaptation mechanisms, effectively bridging the domain gap.",
    "pdf_link": "https://arxiv.org/abs/2404.14241",
    "graphs": [],
    "abstract_cn": "随着城市化进程的加速，对能够迅速检索富含地理语义信息的卫星图像-文本方法的需求日益迫切。然而，现有技术往往忽略了城市景观多样性之间的领域差异，过于集中于单一领域的检索性能提升。为应对这一挑战，我们推出了 UrbanCross，这是一个创新的跨领域卫星图像-文本检索框架。该框架依托于一个涵盖三国广泛地理标签的高质量跨领域数据集，以展现不同领域的丰富性。它结合了大型多模态模型（LMM）对文本进行精细化处理，以及分段任何模型（SAM）对视觉内容进行增强，实现了图像、分段与文本之间的精准匹配，提升了10%的检索效率。此外，UrbanCross 还融入了自适应课程源采样器和加权对抗性跨领域微调模块，逐步增强了对不同领域环境的适应能力。广泛的实验结果表明，UrbanCross 在检索效率和新城市环境适应性方面具有显著优势，相较于未采用领域适应机制的版本，平均性能提升了15%，有效缩小了不同领域之间的差距。",
    "title_cn": "UrbanCross：借助跨域适应技术，提升卫星图像与文本的检索能力",
    "tags": [
      "分类：Agent",
      "",
      "城市化"
    ]
  },
  {
    "title": "Boter: Bootstrapping Knowledge Selection and Question Answering for Knowledge-based VQA",
    "submit_datetime": "2024年04月22日",
    "abstract": "Knowledge-based Visual Question Answering (VQA) requires models to incorporate external knowledge to respond to questions about visual content. Previous methods mostly follow the \"retrieve and generate\" paradigm. Initially, they utilize a pre-trained retriever to fetch relevant knowledge documents, subsequently employing them to generate answers. While these methods have demonstrated commendable performance in the task, they possess limitations: (1) they employ an independent retriever to acquire knowledge solely based on the similarity between the query and knowledge embeddings, without assessing whether the knowledge document is truly conducive to helping answer the question; (2) they convert the image into text and then conduct retrieval and answering in natural language space, which may not ensure comprehensive acquisition of all image information. To address these limitations, we propose Boter, a novel framework designed to bootstrap knowledge selection and question answering by leveraging the robust multimodal perception capabilities of the Multimodal Large Language Model (MLLM). The framework consists of two modules: Selector and Answerer, where both are initialized by the MLLM and parameter-efficiently finetuned in a simple cycle: find key knowledge in the retrieved knowledge documents using the Selector, and then use them to finetune the Answerer to predict answers; obtain the pseudo-labels of key knowledge documents based on the predictions of the Answerer and weak supervision labels, and then finetune the Selector to select key knowledge; repeat. Our framework significantly enhances the performance of the baseline on the challenging open-domain Knowledge-based VQA benchmark, OK-VQA, achieving a state-of-the-art accuracy of 62.83%.",
    "pdf_link": "https://arxiv.org/abs/2404.13947",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.13947v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13947/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13947v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13947/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13947v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13947/x3.png"
      }
    ],
    "abstract_cn": "基于知识的可视化问答（VQA）任务要求模型整合外部信息以回答视觉内容的问题。传统“检索-生成”范式的方法虽表现不俗，但存在不足：它们依赖独立检索器，仅基于查询与知识嵌入的相似性获取信息，忽略了知识文档是否真正有助于问题解答；同时，将图像信息转换为文本后进行检索和回答，可能无法全面捕捉图像的全部信息。为克服这些限制，我们设计了Boter框架，它通过利用多模态大型语言模型（MLLM）的多模态感知能力，优化了知识选择和问答过程。该框架包含选择器和回答器两个模块，均由MLLM初始化，并通过简洁的循环高效微调：选择器筛选出检索到的知识文档中的关键信息，回答器据此预测答案；基于回答器的预测结果和弱监督标签，为关键知识文档生成伪标签，进一步微调选择器以精选关键知识；如此循环。此框架在开放领域知识型VQA基准测试OK-VQA上显著提升了基线模型的性能，达到了62.83%的先进准确率。",
    "title_cn": "Boter：一种引导式的知识选择与问答方法，专为基于知识的 VQA（视觉问答）而设计。",
    "tags": [
      "LLM应用",
      "可视化问答",
      "人工智能"
    ]
  },
  {
    "title": "Augmented Object Intelligence: Making the Analog World Interactable with XR-Objects",
    "submit_datetime": "2024年04月22日",
    "abstract": "Seamless integration of physical objects as interactive digital entities remains a challenge for spatial computing. This paper introduces Augmented Object Intelligence (AOI), a novel XR interaction paradigm designed to blur the lines between digital and physical by equipping real-world objects with the ability to interact as if they were digital, where every object has the potential to serve as a portal to vast digital functionalities. Our approach utilizes object segmentation and classification, combined with the power of Multimodal Large Language Models (MLLMs), to facilitate these interactions. We implement the AOI concept in the form of XR-Objects, an open-source prototype system that provides a platform for users to engage with their physical environment in rich and contextually relevant ways. This system enables analog objects to not only convey information but also to initiate digital actions, such as querying for details or executing tasks. Our contributions are threefold: (1) we define the AOI concept and detail its advantages over traditional AI assistants, (2) detail the XR-Objects system's open-source design and implementation, and (3) show its versatility through a variety of use cases and a user study.",
    "pdf_link": "https://arxiv.org/abs/2404.13274",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.13274v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13274/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13274v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13274/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13274v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13274/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13274v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13274/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13274v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13274/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13274v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13274/F6study-setup.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13274v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13274/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13274v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13274/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13274v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13274/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13274v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13274/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13274v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13274/F11discover.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13274v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13274/F12productivity.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13274v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13274/F13learning.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13274v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13274/F14IOT.png"
      }
    ],
    "abstract_cn": "将实体对象无障碍地融入为互动的数字化实体，在空间计算领域仍是一大难题。本文提出了一种名为增强对象智能（AOI）的新型XR互动模式，旨在通过赋予现实世界物体以数字互动的能力，打破数字与物理的界限，让每个物体都可能成为通往丰富数字功能的入口。我们采用对象分割与分类技术，并借助多模态大型语言模型（MLLMs）的强大功能，以促进这些交互体验。AOI理念以XR-Objects的形式得以实现，这是一个开源的原型系统，为用户提供了一个与物理环境进行丰富且具有情境相关性的互动平台。该系统不仅让传统对象能够传递信息，还能触发数字化操作，如查询详细信息或执行任务。我们的研究成果包括三个方面：（1）明确了AOI的概念，并阐述了其相较于传统AI助手的优势；（2）详细介绍了XR-Objects系统的开源架构与实现；（3）通过多样化的应用案例和用户研究，展示了该系统的广泛适用性。",
    "title_cn": "增强对象智能：赋予实体世界以 XR-Objects，实现与扩展现实的互动。",
    "tags": [
      "Agent",
      "空间计算",
      "增强现实"
    ]
  },
  {
    "title": "AccidentBlip2: Accident Detection With Multi-View MotionBlip2",
    "submit_datetime": "2024年04月22日",
    "abstract": "Intelligent vehicles have demonstrated excellent capabilities in many transportation scenarios, but the complex on-board sensors and the inference capabilities of on-board neural networks limit the accuracy of intelligent vehicles for accident detection in complex transportation systems. In this paper, we present AccidentBlip2, a pure vision-based multimodal large model Blip2 accident detection method. Our method first processes the multi-view through ViT-14g and inputs the multi-view features into the cross attention layer of the Qformer, while our self-designed Motion Qformer replaces the self-attention layer in Blip2's Qformer with the Temporal Attention layer in the In the inference process, the query generated in the previous frame is input into the Temporal Attention layer to realize the inference for temporal information. Then we detect whether there is an accident in the surrounding environment by performing autoregressive inference on the query input to the MLP. We also extend our approach to a multi-vehicle cooperative system by deploying Motion Qformer on each vehicle and simultaneously inputting the inference-generated query into the MLP for autoregressive inference. Our approach detects the accuracy of existing video large language models and also adapts to multi-vehicle systems, making it more applicable to intelligent transportation scenarios.",
    "pdf_link": "https://arxiv.org/abs/2404.12149",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.12149v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12149/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12149v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12149/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12149v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12149/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12149v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12149/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12149v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12149/x5.png"
      }
    ],
    "abstract_cn": "智能车辆在多样化的交通情境中表现出色，但其搭载的复杂传感器和神经网络的推理功能在复杂交通系统中对事故检测的精准度仍有局限。本文介绍了一种全新的基于纯视觉的多模态大型模型——AccidentBlip2，用于事故检测。该方法首先利用 ViT-14g 对多视角图像进行处理，并将处理后的特征送入 Qformer 的交叉注意力层。我们独创的 Motion Qformer 则用时间注意力层替代了 Blip2 中 Qformer 的自注意力层。在推理阶段，前一帧生成的查询会输入到时间注意力层，以实现对时间信息的推理。接着，通过自回归推理分析查询，以判断周围环境是否发生了事故。此外，我们将此方法扩展至多车协作系统，通过在每辆车上部署 Motion Qformer 并输入推理生成的查询至 MLP 进行自回归推理，进一步提升了检测的准确性。这种方法不仅提高了现有视频大型语言模型的检测精度，而且适应于多车系统，更符合智能交通场景的应用需求。",
    "title_cn": "AccidentBlip2：融合多视角 MotionBlip2 技术，精准捕捉事故瞬间",
    "tags": [
      "Agent",
      "智能交通",
      "事故检测"
    ]
  },
  {
    "title": "Adaptive Collaboration Strategy for LLMs in Medical Decision Making",
    "submit_datetime": "2024年04月22日",
    "abstract": "Foundation models have become invaluable in advancing the medical field. Despite their promise, the strategic deployment of LLMs for effective utility in complex medical tasks remains an open question. Our novel framework, Medical Decision-making Agents (MDAgents) aims to address this gap by automatically assigning the effective collaboration structure for LLMs. Assigned solo or group collaboration structure is tailored to the complexity of the medical task at hand, emulating real-world medical decision making processes. We evaluate our framework and baseline methods with state-of-the-art LLMs across a suite of challenging medical benchmarks: MedQA, MedMCQA, PubMedQA, DDXPlus, PMC-VQA, Path-VQA, and MedVidQA, achieving the best performance in 5 out of 7 benchmarks that require an understanding of multi-modal medical reasoning. Ablation studies reveal that MDAgents excels in adapting the number of collaborating agents to optimize efficiency and accuracy, showcasing its robustness in diverse scenarios. We also explore the dynamics of group consensus, offering insights into how collaborative agents could behave in complex clinical team dynamics. Our code can be found at https://github.com/mitmedialab/MDAgents.",
    "pdf_link": "https://arxiv.org/abs/2404.15155",
    "graphs": [],
    "abstract_cn": "基础模型已成为推动医学进步的宝贵工具。然而，如何高效地部署大型语言模型（LLMs）以应对复杂的医疗任务，仍是一个悬而未决的问题。我们提出的创新框架——医疗决策代理（MDAgents）——通过自动配置LLMs的有效协作结构，致力于填补这一空白。无论是单独还是团队合作，其协作模式都根据具体医疗任务的复杂度量身打造，以此模拟现实世界中的医疗决策流程。在一系列高难度的医学基准测试中，我们对MDAgents框架和基线方法进行了评估，包括MedQA、MedMCQA、PubMedQA、DDXPlus、PMC-VQA、Path-VQA和MedVidQA，其中在需要掌握多模态医学推理的七个基准测试中，MDAgents在五个测试中均取得了最佳成绩。消融研究显示，MDAgents在调整协作代理数量以提高效率和准确性方面表现出色，证明了其在多种情况下的强大适应性。我们还深入探讨了团队共识的形成过程，为理解复杂临床团队中协作代理的行为提供了洞见。相关代码已在 https://github.com/mitmedialab/MDAgents 上公开。",
    "title_cn": "在医学决策领域，大型语言模型采用自适应协作策略，以提升决策效率和准确性。",
    "tags": [
      "Agent",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Bi-CL: A Reinforcement Learning Framework for Robots Coordination Through Bi-level Optimization",
    "submit_datetime": "2024年04月22日",
    "abstract": "In multi-robot systems, achieving coordinated missions remains a significant challenge due to the coupled nature of coordination behaviors and the lack of global information for individual robots. To mitigate these challenges, this paper introduces a novel approach, Bi-level Coordination Learning (Bi-CL), that leverages a bi-level optimization structure within a centralized training and decentralized execution paradigm. Our bi-level reformulation decomposes the original problem into a reinforcement learning level with reduced action space, and an imitation learning level that gains demonstrations from a global optimizer. Both levels contribute to improved learning efficiency and scalability. We note that robots' incomplete information leads to mismatches between the two levels of learning models. To address this, Bi-CL further integrates an alignment penalty mechanism, aiming to minimize the discrepancy between the two levels without degrading their training efficiency. We introduce a running example to conceptualize the problem formulation and apply Bi-CL to two variations of this example: route-based and graph-based scenarios. Simulation results demonstrate that Bi-CL can learn more efficiently and achieve comparable performance with traditional multi-agent reinforcement learning baselines for multi-robot coordination.",
    "pdf_link": "https://arxiv.org/abs/2404.14649",
    "graphs": [],
    "abstract_cn": "在多机器人系统中，协调任务的实现因行为的相互依赖和机器人缺少全局信息而面临重大挑战。为应对这些难题，本研究提出了一种创新的双层次协调学习（Bi-CL）方法，该方法采用集中式训练与分布式执行的双重优化架构。我们的双重层次重构策略将原始问题拆分为简化动作空间的强化学习层和从全局优化器获取示范的模仿学习层，两者共同提升了学习效率和系统的可扩展性。我们指出，由于机器人信息的不完整性，学习模型的两个层次之间存在差异。为此，Bi-CL引入了对齐惩罚机制，以减少层次间差异，同时保持训练效率。我们通过一个运行实例来阐释问题设定，并将Bi-CL应用于该实例的两种情形：基于路径和基于图的场景。模拟结果显示，Bi-CL不仅学习效率更高，而且在多机器人协调任务中与传统的多智能体强化学习方法相比，性能毫不逊色。",
    "title_cn": "Bi-CL：一种采用双层优化策略的强化学习框架，旨在提升机器人间的协调能力。",
    "tags": [
      "Agent",
      "机器人技术",
      "多智能体系统"
    ]
  },
  {
    "title": "Fairness Incentives in Response to Unfair Dynamic Pricing",
    "submit_datetime": "2024年04月22日",
    "abstract": "The use of dynamic pricing by profit-maximizing firms gives rise to demand fairness concerns, measured by discrepancies in consumer groups' demand responses to a given pricing strategy. Notably, dynamic pricing may result in buyer distributions unreflective of those of the underlying population, which can be problematic in markets where fair representation is socially desirable. To address this, policy makers might leverage tools such as taxation and subsidy to adapt policy mechanisms dependent upon their social objective. In this paper, we explore the potential for AI methods to assist such intervention strategies. To this end, we design a basic simulated economy, wherein we introduce a dynamic social planner (SP) to generate corporate taxation schedules geared to incentivizing firms towards adopting fair pricing behaviours, and to use the collected tax budget to subsidize consumption among underrepresented groups. To cover a range of possible policy scenarios, we formulate our social planner's learning problem as a multi-armed bandit, a contextual bandit and finally as a full reinforcement learning (RL) problem, evaluating welfare outcomes from each case. To alleviate the difficulty in retaining meaningful tax rates that apply to less frequently occurring brackets, we introduce FairReplayBuffer, which ensures that our RL agent samples experiences uniformly across a discretized fairness space. We find that, upon deploying a learned tax and redistribution policy, social welfare improves on that of the fairness-agnostic baseline, and approaches that of the analytically optimal fairness-aware baseline for the multi-armed and contextual bandit settings, and surpassing it by 13.19% in the full RL setting.",
    "pdf_link": "https://arxiv.org/abs/2404.14620",
    "graphs": [],
    "abstract_cn": "追求最大化利润的企业采用动态定价策略，这可能引发消费者需求公平性的问题，即不同消费群体对特定定价策略的反应差异。动态定价有时会导致购买者分布与总体人口分布不一致，这在需要公平代表性的市场中尤为突出。为了应对这一挑战，政策制定者可以使用税收和补贴等手段，根据社会目标调整政策机制。本文旨在探讨人工智能方法在辅助政策干预策略方面的潜力。我们构建了一个模拟经济模型，并引入了一个动态社会规划者（SP），该规划者设计企业税收计划，旨在鼓励企业采取公平定价策略，同时利用税收预算补贴那些代表性不足的消费群体。为了全面考虑各种可能的政策情境，我们将社会规划者的学习问题构建为多臂老虎机、上下文老虎机，最终形成完整的强化学习（RL）问题，并对每种情境下的福利结果进行评估。为了解决在较少发生的税收档次中保持有意义税率的难题，我们引入了 FairReplayBuffer，确保 RL 代理能够在离散化的公平性空间中均匀地抽取经验。研究结果显示，实施了学习型税收和再分配政策后，社会福利得到了提升，不仅超越了不考虑公平性的基线，而且在多臂和上下文老虎机情境下接近了理论上最优化的公平感知基线，在完全的 RL 情境下更是超出了 13.19%。",
    "title_cn": "面对不公平的动态定价，我们探讨了如何通过激励措施来提升交易的公平性。",
    "tags": [
      "Agent",
      "经济学",
      "人工智能"
    ]
  },
  {
    "title": "Constrained multi-cluster game: Distributed Nash equilibrium seeking over directed graphs",
    "submit_datetime": "2024年04月22日",
    "abstract": "Motivated by the complex dynamics of cooperative and competitive interactions within networked agent systems, multi-cluster games provide a framework for modeling the interconnected goals of self-interested clusters of agents. For this setup, the existing literature lacks comprehensive gradient-based solutions that simultaneously consider constraint sets and directed communication networks, both of which are crucial for many practical applications. To address this gap, this paper proposes a distributed Nash equilibrium seeking algorithm that integrates consensus-based methods and gradient-tracking techniques, where inter-cluster and intra-cluster communications only use row- and column-stochastic weight matrices, respectively. To handle constraints, we introduce an averaging procedure, which can effectively address the complications associated with projections. In turn, we can show linear convergence of our algorithm, focusing on the contraction property of the optimality gap. We demonstrate the efficacy of the proposed algorithm through a microgrid energy management application.",
    "pdf_link": "https://arxiv.org/abs/2404.14554",
    "graphs": [],
    "abstract_cn": "受网络化代理系统中的合作与竞争互动的复杂性启发，多集群博弈为模拟自利代理集群的互联目标提供了建模框架。然而，现有研究在提供全面考虑约束集和有向通信网络的梯度基解决方案方面存在不足，这两者对于实际应用极为关键。为填补这一空白，本文提出了一种分布式纳什均衡搜索算法，该算法融合了基于共识的方法与梯度追踪技术，其中集群间的通信采用行随机权重矩阵，集群内的通信则使用列随机权重矩阵。为应对约束挑战，引入了一种平均化过程，有效解决了投影相关的复杂问题。我们的算法展示了线性收敛性，重点分析了最优性差距的收缩特性。通过微电网能源管理的应用案例，验证了所提算法的高效性。",
    "title_cn": "受限多集群博弈：在有向图上寻找分布式纳什均衡",
    "tags": [
      "Agent",
      "能源管理",
      "分布式算法"
    ]
  },
  {
    "title": "Multi-Agent Hybrid SAC for Joint SS-DSA in CRNs",
    "submit_datetime": "2024年04月22日",
    "abstract": "Opportunistic spectrum access has the potential to increase the efficiency of spectrum utilization in cognitive radio networks (CRNs). In CRNs, both spectrum sensing and resource allocation (SSRA) are critical to maximizing system throughput while minimizing collisions of secondary users with the primary network. However, many works in dynamic spectrum access do not consider the impact of imperfect sensing information such as mis-detected channels, which the additional information available in joint SSRA can help remediate. In this work, we examine joint SSRA as an optimization which seeks to maximize a CRN's net communication rate subject to constraints on channel sensing, channel access, and transmit power. Given the non-trivial nature of the problem, we leverage multi-agent reinforcement learning to enable a network of secondary users to dynamically access unoccupied spectrum via only local test statistics, formulated under the energy detection paradigm of spectrum sensing. In doing so, we develop a novel multi-agent implementation of hybrid soft actor critic, MHSAC, based on the QMIX mixing scheme. Through experiments, we find that our SSRA algorithm, HySSRA, is successful in maximizing the CRN's utilization of spectrum resources while also limiting its interference with the primary network, and outperforms the current state-of-the-art by a wide margin. We also explore the impact of wireless variations such as coherence time on the efficacy of the system.",
    "pdf_link": "https://arxiv.org/abs/2404.14319",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.14319v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14319/timing_diagram.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14319v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14319/hybrid_sac.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14319v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14319/ctde_diagram.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14319v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14319/channel_realizations.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14319v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14319/ct_exp_occ_usage_rate.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14319v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14319/need_for_test_stats.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14319v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14319/combined.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14319v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14319/combined.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14319v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14319/n16_plots.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14319v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14319/combined.png"
      }
    ],
    "abstract_cn": "机会频谱接入有望提升认知无线电网络的频谱使用效率。在这些网络中，频谱感知与资源分配（SSRA）是提高系统吞吐量、减少次要用户与主网络冲突的关键。尽管如此，动态频谱接入领域的多数研究忽略了感知误差等不完美信息的影响，而联合SSRA能够利用额外信息对此进行改善。本研究将联合SSRA作为优化问题，目标是在信道感知、接入和传输功率限制下最大化CRN的净通信速率。考虑到问题的复杂性，我们采用多智能体强化学习方法，使次要用户网络能够在仅依赖局部测试统计信息的情况下，动态地接入空闲频谱，这一方法基于频谱感知的能量检测框架。在此基础上，我们提出了一种新颖的多智能体混合软演员-评论家（MHSAC）实现方法，并基于QMIX混合策略。实验结果表明，我们的SSRA算法HySSRA不仅有效提升了CRN的频谱资源利用率，还成功控制了对主网络的干扰，性能显著优于现有技术。此外，我们还研究了无线环境变化，如相干时间，对系统效果的影响。",
    "title_cn": "在认知无线电网络（CRN）中，采用多智能体混合同步优势策略（SAC）进行联合半静态分频指配（SS-DSA）。",
    "tags": [
      "Agent",
      "通信网络",
      ""
    ]
  },
  {
    "title": "Multi-agent Reinforcement Learning-based Joint Precoding and Phase Shift Optimization for RIS-aided Cell-Free Massive MIMO Systems",
    "submit_datetime": "2024年04月22日",
    "abstract": "Cell-free (CF) massive multiple-input multiple-output (mMIMO) is a promising technique for achieving high spectral efficiency (SE) using multiple distributed access points (APs). However, harsh propagation environments often lead to significant communication performance degradation due to high penetration loss. To overcome this issue, we introduce the reconfigurable intelligent surface (RIS) into the CF mMIMO system as a low-cost and power-efficient solution. In this paper, we focus on optimizing the joint precoding design of the RIS-aided CF mMIMO system to maximize the sum SE. This involves optimizing the precoding matrix at the APs and the reflection coefficients at the RIS. To tackle this problem, we propose a fully distributed multi-agent reinforcement learning (MARL) algorithm that incorporates fuzzy logic (FL). Unlike conventional approaches that rely on alternating optimization techniques, our FL-based MARL algorithm only requires local channel state information, which reduces the need for high backhaul capacity. Simulation results demonstrate that our proposed FL-MARL algorithm effectively reduces computational complexity while achieving similar performance as conventional MARL methods.",
    "pdf_link": "https://arxiv.org/abs/2404.14092",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.14092v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14092/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14092v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14092/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14092v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14092/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14092v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14092/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14092v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14092/x5.png"
      }
    ],
    "abstract_cn": "无单元（CF）大规模多输入多输出（mMIMO）技术，通过部署多个分布式接入点（APs），展现出提升频谱效率（SE）的巨大潜力。然而，恶劣的传播条件，如高穿透损耗，往往会严重影响通信质量。为了应对这一挑战，本研究将可重构智能表面（RIS）集成到CF mMIMO系统中，作为一种经济高效的解决方案。文章的核心在于对RIS辅助CF mMIMO系统进行联合预编码优化，目标是提升系统的整体SE。这包括对APs的预编码矩阵和RIS的反射系数进行调优。为攻克这一难题，我们提出了一种融合了模糊逻辑（FL）的全分布式多代理强化学习（MARL）算法。与传统的交替优化方法不同，该算法仅需局部信道状态信息，有效降低了对高带宽后端的需求。模拟实验结果证明，该FL-MARL算法在简化计算复杂度的同时，能够达到与常规MARL方法相媲美的性能。",
    "title_cn": "本文探讨了一种基于多智能体强化学习的方法，用于联合优化 RIS 辅助的无蜂窝大规模 MIMO 系统中的预编码和相位偏移，以提升系统性能。",
    "tags": [
      "Agent",
      "",
      ""
    ]
  },
  {
    "title": "Multi-view Disentanglement for Reinforcement Learning with Multiple Cameras",
    "submit_datetime": "2024年04月22日",
    "abstract": "The performance of image-based Reinforcement Learning (RL) agents can vary depending on the position of the camera used to capture the images. Training on multiple cameras simultaneously, including a first-person egocentric camera, can leverage information from different camera perspectives to improve the performance of RL. However, hardware constraints may limit the availability of multiple cameras in real-world deployment. Additionally, cameras may become damaged in the real-world preventing access to all cameras that were used during training. To overcome these hardware constraints, we propose Multi-View Disentanglement (MVD), which uses multiple cameras to learn a policy that achieves zero-shot generalisation to any single camera from the training set. Our approach is a self-supervised auxiliary task for RL that learns a disentangled representation from multiple cameras, with a shared representation that is aligned across all cameras to allow generalisation to a single camera, and a private representation that is camera-specific. We show experimentally that an RL agent trained on a single third-person camera is unable to learn an optimal policy in many control tasks; but, our approach, benefiting from multiple cameras during training, is able to solve the task using only the same single third-person camera.",
    "pdf_link": "https://arxiv.org/abs/2404.14064",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.14064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14064/soccer_first_person.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14064/soccer_third_person.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14064/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14064/panda_camera2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14064/panda_camera0.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14064/panda_camera1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14064/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14064/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14064/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14064/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14064/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14064/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14064/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14064/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14064/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14064/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14064/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14064/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14064/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14064/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14064/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14064/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14064/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14064/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14064/x20.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14064/x21.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14064/x22.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14064/x23.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14064/x24.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14064/x25.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14064/x26.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14064/x27.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14064/x28.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14064/x29.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14064/panda_camera2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14064/panda_camera0.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14064/panda_camera1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14064/panda_cube_cam2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14064/panda_cube_cam0.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14064/panda_cube_cam1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14064/soccer_first_person.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14064/soccer_third_person.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14064/basketball_first_person.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14064/basketball_third_person.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14064/pick_place_first_person.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14064/pick_place_third_person.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14064/peg_first_person.png"
      },
      {
        "url": "https://arxiv.org/html/2404.14064v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.14064/peg_third_person.png"
      }
    ],
    "abstract_cn": "图像驱动的强化学习（RL）智能体的表现会随着捕捉图像的相机位置不同而波动。通过同时在多个相机上进行训练，例如采用第一人称视角的相机，可以整合多样的视角信息，从而提升RL的表现。但现实中，硬件的限制可能会影响到多相机配置的可行性。此外，现实环境中的相机损坏也可能导致无法使用训练时的全部相机。为了解决这些硬件上的限制，我们引入了多视角解耦（MVD）技术，它能够利用多个相机学习出一种策略，实现对训练集中任一单一相机的零样本泛化能力。这种方法为RL提供了一个自监督的辅助学习任务，通过多相机学习解耦的表征，共享的表征在所有相机间保持一致，以便实现单相机的泛化，同时还有专属于特定相机的私有表征。实验结果证明，仅使用单一第三人称相机训练的RL智能体在许多控制任务中难以掌握最优策略；相比之下，我们的方法在训练时利用了多个相机的信息，最终能够仅依靠同一单一第三人称相机完成任务。",
    "title_cn": "在多摄像头环境下，强化学习中的多视角解耦技术。",
    "tags": [
      "Agent",
      "",
      "计算机视觉"
    ]
  },
  {
    "title": "Liquid-Graph Time-Constant Network for Multi-Agent Systems Control",
    "submit_datetime": "2024年04月22日",
    "abstract": "In this paper, we propose the Liquid-Graph Time-constant (LGTC) network, a continuous graph neural network(GNN) model for control of multi-agent systems based on therecent Liquid Time Constant (LTC) network. We analyse itsstability leveraging contraction analysis and propose a closed-form model that preserves the model contraction rate and doesnot require solving an ODE at each iteration. Compared todiscrete models like Graph Gated Neural Networks (GGNNs),the higher expressivity of the proposed model guaranteesremarkable performance while reducing the large amountof communicated variables normally required by GNNs. Weevaluate our model on a distributed multi-agent control casestudy (flocking) taking into account variable communicationrange and scalability under non-instantaneous communication",
    "pdf_link": "https://arxiv.org/abs/2404.13982",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.13982v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13982/flocking_example.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13982v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13982/flocking_stb_lgtc.png"
      }
    ],
    "abstract_cn": "本文介绍了一种新型连续图神经网络（GNN）模型——液态图时间常数（LGTC）网络，用于多智能体系统的控制，该模型基于最新的液态时间常数（LTC）网络。通过收缩性分析，我们确保了模型的稳定性，并设计了一个封闭形式的模型，它不仅维持了模型的收缩特性，还避免了在每次迭代中求解常微分方程（ODE）的需要。相较于传统的图门控神经网络（GGNNs）等离散模型，LGTC网络的高表达力在减少通信变量的同时，提供了卓越的性能。我们还通过一个分布式多智能体控制的案例研究——群体行为，评估了模型在不同通信范围和非即时通信条件下的可扩展性。",
    "title_cn": "液态图时域常数网络在多智能体系统控制中的应用",
    "tags": [
      "Agent",
      "智能体系统",
      "图神经网络"
    ]
  },
  {
    "title": "Evaluating Retrieval Quality in Retrieval-Augmented Generation",
    "submit_datetime": "2024年04月21日",
    "abstract": "Evaluating retrieval-augmented generation (RAG) presents challenges, particularly for retrieval models within these systems. Traditional end-to-end evaluation methods are computationally expensive. Furthermore, evaluation of the retrieval model's performance based on query-document relevance labels shows a small correlation with the RAG system's downstream performance. We propose a novel evaluation approach, eRAG, where each document in the retrieval list is individually utilized by the large language model within the RAG system. The output generated for each document is then evaluated based on the downstream task ground truth labels. In this manner, the downstream performance for each document serves as its relevance label. We employ various downstream task metrics to obtain document-level annotations and aggregate them using set-based or ranking metrics. Extensive experiments on a wide range of datasets demonstrate that eRAG achieves a higher correlation with downstream RAG performance compared to baseline methods, with improvements in Kendall's $τ$ correlation ranging from 0.168 to 0.494. Additionally, eRAG offers significant computational advantages, improving runtime and consuming up to 50 times less GPU memory than end-to-end evaluation.",
    "pdf_link": "https://arxiv.org/abs/2404.13781",
    "graphs": [],
    "abstract_cn": "对检索增强生成（RAG）进行评估并非易事，尤其是在这些系统中的检索模型。传统的端到端评估方式不仅计算成本高，而且基于查询与文档相关性标签的检索模型性能评估与RAG系统的下游性能关联度并不高。为此，我们提出了一种创新的评估方案——eRAG。在eRAG中，RAG系统中的大型语言模型会单独处理检索列表中的每一个文档，并针对每个文档生成的输出进行下游任务真值标签的评估。这样，每个文档的下游表现就成为了其相关性标签。我们采用多种下游任务的度量标准，对文档进行逐级注解，并利用基于集合或排名的度量进行汇总。广泛的实验结果表明，eRAG与RAG系统的下游性能相关性更高，Kendall的$τ$相关性提升显著，从0.168增至0.494。同时，eRAG在计算上具有显著优势，不仅缩短了运行时间，而且相较于端到端评估，GPU内存消耗减少了高达50倍。",
    "title_cn": "在检索增强生成领域，对检索质量的评估至关重要。",
    "tags": [
      "分类：RAG",
      "信息检索",
      ""
    ]
  },
  {
    "title": "NegotiationToM: A Benchmark for Stress-testing Machine Theory of Mind on Negotiation Surrounding",
    "submit_datetime": "2024年04月21日",
    "abstract": "Large Language Models (LLMs) have sparked substantial interest and debate concerning their potential emergence of Theory of Mind (ToM) ability. Theory of mind evaluations currently focuses on testing models using machine-generated data or game settings prone to shortcuts and spurious correlations, which lacks evaluation of machine ToM ability in real-world human interaction scenarios. This poses a pressing demand to develop new real-world scenario benchmarks. We introduce NegotiationToM, a new benchmark designed to stress-test machine ToM in real-world negotiation surrounding covered multi-dimensional mental states (i.e., desires, beliefs, and intentions). Our benchmark builds upon the Belief-Desire-Intention (BDI) agent modeling theory and conducts the necessary empirical experiments to evaluate large language models. Our findings demonstrate that NegotiationToM is challenging for state-of-the-art LLMs, as they consistently perform significantly worse than humans, even when employing the chain-of-thought (CoT) method.",
    "pdf_link": "https://arxiv.org/abs/2404.13627",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.13627v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13627/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13627v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13627/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13627v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13627/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13627v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13627/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13627v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13627/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13627v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13627/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13627v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13627/BackGround.jpg"
      },
      {
        "url": "https://arxiv.org/html/2404.13627v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13627/Desire.jpg"
      },
      {
        "url": "https://arxiv.org/html/2404.13627v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13627/Belief.jpg"
      },
      {
        "url": "https://arxiv.org/html/2404.13627v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13627/Intention.jpg"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）在心理理论（ToM）能力的潜在发展上引起了广泛的兴趣和讨论。当前的心理理论评估通常依赖于机器生成的数据或易导致捷径和偶然关联的游戏环境，这并未充分评估机器在现实人际互动中的ToM能力。因此，迫切需要创建新的现实世界情境基准。我们提出了NegotiationToM，这是一个新型基准测试，用以在真实世界的谈判中对机器的ToM进行严格测试，涉及多维度的心理状态，包括欲望、信念和意图。该基准测试基于信念-欲望-意图（BDI）代理模型理论，并进行了必要的实证实验以评估LLMs。我们的研究结果显示，即使是最先进的LLMs在NegotiationToM上也面临挑战，它们的表现一致地显著低于人类水平，即便采用了思维链（CoT）方法。",
    "title_cn": "NegotiationToM：一个专门设计来对机器理论思维进行压力测试的谈判基准",
    "tags": [
      "Agent",
      "心理学",
      "人工智能"
    ]
  },
  {
    "title": "EventLens: Leveraging Event-Aware Pretraining and Cross-modal Linking Enhances Visual Commonsense Reasoning",
    "submit_datetime": "2024年04月21日",
    "abstract": "Visual Commonsense Reasoning (VCR) is a cognitive task, challenging models to answer visual questions requiring human commonsense, and to provide rationales explaining why the answers are correct. With emergence of Large Language Models (LLMs), it is natural and imperative to explore their applicability to VCR. However, VCR task demands more external knowledge to tackle its challenging questions, necessitating special designs to activate LLMs' commonsense reasoning abilities. Also, most existing Multimodal LLMs adopted an abstraction of entire input image, which makes it difficult to comprehend VCR's unique co-reference tags between image regions and text, posing challenges for fine-grained alignment. To address these issues, we propose EventLens that leverages Event-Aware Pretraining and Cross-modal Linking and EnhanceS VCR. First, by emulating the cognitive process of human reasoning, an Event-Aware Pretraining auxiliary task is introduced to better activate LLM's global comprehension of intricate scenarios. Second, during fine-tuning, we further utilize reference tags to bridge RoI features with texts, while preserving both modality semantics. Finally, we use instruct-style prompts to narrow the gap between pretraining and fine-tuning, and task-specific adapters to better integrate LLM's inherent knowledge with new commonsense. Experimental results show the effectiveness of our proposed auxiliary task and fine-grained linking strategy.",
    "pdf_link": "https://arxiv.org/abs/2404.13847",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.13847v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13847/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13847v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13847/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13847v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13847/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13847v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13847/x4.png"
      }
    ],
    "abstract_cn": "视觉常识推理（VCR）考验模型回答需依赖人类常识的视觉问题，并需阐明答案正确的理由。大型语言模型（LLMs）的兴起，使得探究其在VCR领域的应用变得既自然又迫切。但VCR的挑战性问题要求模型具备更丰富的外部知识，这就需要特别设计以激发LLMs的常识推理潜能。目前，多数多模态LLMs处理输入图像时采取整体抽象方法，难以捕捉VCR中图像区域与文本间的特定共指关系，这对精确对齐构成挑战。为应对这些挑战，我们设计了EventLens，它通过事件感知预训练和跨模态链接来增强VCR性能。首先，我们引入了一个模仿人类认知推理过程的事件感知预训练辅助任务，以提升LLM对复杂情境的全面理解。其次，在微调阶段，我们使用参考标签将感兴趣区域（RoI）的特征与文本相连，确保两种模态的语义信息得以保留。最后，我们采用指导性提示减少预训练与微调间的差异，并利用任务特定的适配器，使LLM的内在知识与新常识更好地融合。实验结果显示，我们提出的辅助任务和细粒度链接策略效果显著。",
    "title_cn": "EventLens：通过事件驱动的预训练和跨模态关联，提升视觉常识推理能力。",
    "tags": [
      "分类：LLM应用\n\n这篇论文讨论了如何利用大型语言模型（LLMs）来解决视觉常识推理（VCR）问题。它提出了一种名为EventLens的方法，通过事件感知预训练和跨模态链接来增强VCR性能。这篇论文的重点在于如何设计和应用LLMs来解决特定的AI问题，因此它属于LLM应用类别。",
      "计算机视觉",
      "人工智能"
    ]
  },
  {
    "title": "General Item Representation Learning for Cold-start Content Recommendations",
    "submit_datetime": "2024年04月21日",
    "abstract": "Cold-start item recommendation is a long-standing challenge in recommendation systems. A common remedy is to use a content-based approach, but rich information from raw contents in various forms has not been fully utilized. In this paper, we propose a domain/data-agnostic item representation learning framework for cold-start recommendations, naturally equipped with multimodal alignment among various features by adopting a Transformer-based architecture. Our proposed model is end-to-end trainable completely free from classification labels, not just costly to collect but suboptimal for recommendation-purpose representation learning. From extensive experiments on real-world movie and news recommendation benchmarks, we verify that our approach better preserves fine-grained user taste than state-of-the-art baselines, universally applicable to multiple domains at large scale.",
    "pdf_link": "https://arxiv.org/abs/2404.13808",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.13808v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13808/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13808v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13808/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13808v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13808/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13808v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13808/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13808v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13808/x5.png"
      }
    ],
    "abstract_cn": "冷启动商品推荐一直是推荐领域的难题。传统解决方案倾向于采用基于内容的方法，但往往未能充分利用多样化原始内容中的丰富信息。本文提出了一种新颖的领域/数据无关的商品表示学习框架，旨在解决冷启动推荐问题。该框架采用基于 Transformer 的架构，实现了不同特征间的自然多模态对齐。我们的模型无需依赖分类标签即可进行端到端的训练，避免了收集标签的高昂成本，同时优化了推荐场景下的表示学习方法。通过在电影和新闻推荐的实际基准测试中的广泛实验，我们证实了该方法在捕捉用户细微偏好方面超越了当前最先进的方法，并且具有跨领域的广泛适用性。",
    "title_cn": "通用项目表示学习：破解冷启动内容推荐难题",
    "tags": [
      "分类：Agent",
      "推荐系统",
      "机器学习"
    ]
  },
  {
    "title": "SciDaSynth: Interactive Structured Knowledge Extraction and Synthesis from Scientific Literature with Large Language Model",
    "submit_datetime": "2024年04月21日",
    "abstract": "Extraction and synthesis of structured knowledge from extensive scientific literature are crucial for advancing and disseminating scientific progress. Although many existing systems facilitate literature review and digest, they struggle to process multimodal, varied, and inconsistent information within and across the literature into structured data. We introduce SciDaSynth, a novel interactive system powered by large language models (LLMs) that enables researchers to efficiently build structured knowledge bases from scientific literature at scale. The system automatically creates data tables to organize and summarize users' interested knowledge in literature via question-answering. Furthermore, it provides multi-level and multi-faceted exploration of the generated data tables, facilitating iterative validation, correction, and refinement. Our within-subjects study with researchers demonstrates the effectiveness and efficiency of SciDaSynth in constructing quality scientific knowledge bases. We further discuss the design implications for human-AI interaction tools for data extraction and structuring.",
    "pdf_link": "https://arxiv.org/abs/2404.13765",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.13765v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13765/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13765v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13765/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13765v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13765/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13765v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13765/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13765v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13765/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13765v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13765/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13765v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13765/x7.png"
      }
    ],
    "abstract_cn": "深入挖掘和整合科学文献中的结构化知识对科学发展和传播极为关键。尽管众多现有系统辅助进行文献回顾和理解，但它们在将文献中的多模态、多变和不统一的信息转换为结构化数据方面仍面临挑战。我们推出了 SciDaSynth，一个由大型语言模型 (LLMs) 支持的创新交互式系统，旨在帮助研究人员高效地从科学文献中构建大规模的结构化知识库。该系统能够自动生成数据表格，通过问答形式整理和汇总用户感兴趣的文献知识。同时，它还提供多层次、多角度的数据表格探索功能，以便进行迭代式的验证、修正和优化。我们与研究人员进行的个体内研究显示，SciDaSynth 在构建高质量的科学知识库方面既高效又有效。此外，我们还探讨了设计人工智能交互工具以进行数据提取和结构化时的考量要点。",
    "title_cn": "SciDaSynth：借助大型语言模型，实现从科学文献中进行互动式的知识结构化提取与合成。",
    "tags": [
      "LLM应用",
      "科学文献",
      "知识管理"
    ]
  },
  {
    "title": "FiLo: Zero-Shot Anomaly Detection by Fine-Grained Description and High-Quality Localization",
    "submit_datetime": "2024年04月21日",
    "abstract": "Zero-shot anomaly detection (ZSAD) methods entail detecting anomalies directly without access to any known normal or abnormal samples within the target item categories. Existing approaches typically rely on the robust generalization capabilities of multimodal pretrained models, computing similarities between manually crafted textual features representing \"normal\" or \"abnormal\" semantics and image features to detect anomalies and localize anomalous patches. However, the generic descriptions of \"abnormal\" often fail to precisely match diverse types of anomalies across different object categories. Additionally, computing feature similarities for single patches struggles to pinpoint specific locations of anomalies with various sizes and scales. To address these issues, we propose a novel ZSAD method called FiLo, comprising two components: adaptively learned Fine-Grained Description (FG-Des) and position-enhanced High-Quality Localization (HQ-Loc). FG-Des introduces fine-grained anomaly descriptions for each category using Large Language Models (LLMs) and employs adaptively learned textual templates to enhance the accuracy and interpretability of anomaly detection. HQ-Loc, utilizing Grounding DINO for preliminary localization, position-enhanced text prompts, and Multi-scale Multi-shape Cross-modal Interaction (MMCI) module, facilitates more accurate localization of anomalies of different sizes and shapes. Experimental results on datasets like MVTec and VisA demonstrate that FiLo significantly improves the performance of ZSAD in both detection and localization, achieving state-of-the-art performance with an image-level AUC of 83.9% and a pixel-level AUC of 95.9% on the VisA dataset.",
    "pdf_link": "https://arxiv.org/abs/2404.13671",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.13671v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13671/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13671v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13671/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13671v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13671/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13671v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13671/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13671v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13671/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13671v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13671/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13671v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13671/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13671v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13671/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13671v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13671/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13671v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13671/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13671v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13671/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13671v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13671/x12.png"
      }
    ],
    "abstract_cn": "零样本异常检测（ZSAD）技术能够在无需任何已知正常或异常样本的情况下直接识别异常。传统方法多依赖于多模态预训练模型的泛化能力，通过比较文本和图像特征的相似度来识别并定位异常。但这些方法在精确描述不同类别中的多样化异常时常常力不从心，且在确定异常具体位置时也存在挑战。为此，我们引入了一种创新的ZSAD方法——FiLo，它由两个核心组件构成：细粒度描述（FG-Des）和高质量定位（HQ-Loc）。FG-Des利用大型语言模型为不同类别提供细致的异常描述，并通过自适应学习的文本模板提升检测的精确度和可解释性。HQ-Loc则结合了初步定位技术Grounding DINO、位置增强文本提示和多尺度多形状跨模态交互模块（MMCI），以更准确地定位各种尺寸和形状的异常。在MVTec和VisA等数据集上的测试显示，FiLo在异常检测和定位方面均有显著提升，尤其在VisA数据集上，图像级AUC达到了83.9%，像素级AUC更是高达95.9%，刷新了行业标准。",
    "title_cn": "FiLo：一种零样本异常检测方法，它利用细致的描述和精准的定位技术。",
    "tags": [
      "分类：LLM应用\n\n这篇论文摘要介绍了一种零样本异常检测（ZSAD）方法——FiLo，它利用大型语言模型（LLM）来提供异常的细致描述，并通过自适应学习的文本模板提高检测的精确度和可解释性。此外，FiLo结合了多种技术来更准确地定位异常。由于该方法涉及到使用大型语言模型进行异常检测和定位，因此可以归类为LLM应用。",
      "异常检测",
      "跨模态学习"
    ]
  },
  {
    "title": "AdvPrompter: Fast Adaptive Adversarial Prompting for LLMs",
    "submit_datetime": "2024年04月21日",
    "abstract": "While recently Large Language Models (LLMs) have achieved remarkable successes, they are vulnerable to certain jailbreaking attacks that lead to generation of inappropriate or harmful content. Manual red-teaming requires finding adversarial prompts that cause such jailbreaking, e.g. by appending a suffix to a given instruction, which is inefficient and time-consuming. On the other hand, automatic adversarial prompt generation often leads to semantically meaningless attacks that can easily be detected by perplexity-based filters, may require gradient information from the TargetLLM, or do not scale well due to time-consuming discrete optimization processes over the token space. In this paper, we present a novel method that uses another LLM, called the AdvPrompter, to generate human-readable adversarial prompts in seconds, $\\sim800\\times$ faster than existing optimization-based approaches. We train the AdvPrompter using a novel algorithm that does not require access to the gradients of the TargetLLM. This process alternates between two steps: (1) generating high-quality target adversarial suffixes by optimizing the AdvPrompter predictions, and (2) low-rank fine-tuning of the AdvPrompter with the generated adversarial suffixes. The trained AdvPrompter generates suffixes that veil the input instruction without changing its meaning, such that the TargetLLM is lured to give a harmful response. Experimental results on popular open source TargetLLMs show state-of-the-art results on the AdvBench dataset, that also transfer to closed-source black-box LLM APIs. Further, we demonstrate that by fine-tuning on a synthetic dataset generated by AdvPrompter, LLMs can be made more robust against jailbreaking attacks while maintaining performance, i.e. high MMLU scores.",
    "pdf_link": "https://arxiv.org/abs/2404.16873",
    "graphs": [],
    "abstract_cn": "近期，大型语言模型（LLMs）虽然取得了显著成就，却也容易遭受特定越狱攻击，从而产生不当或有害的内容。传统的手动红队战术，通过添加后缀等方式寻找对抗性提示，不仅效率低下，还耗费大量时间。而自动化的对抗性提示生成方法，往往产生无意义的攻击，容易被基于困惑度的过滤器识破，且可能需要目标LLM的梯度信息，或因优化过程繁琐而难以扩展。本文提出了一种创新方法，利用另一个名为AdvPrompter的LLM快速生成易于人类理解的对抗性提示，速度是现有优化方法的800倍。我们采用了一种新颖的算法训练AdvPrompter，无需获取目标LLM的梯度信息。该过程包括两个交替步骤：首先，优化AdvPrompter的预测以产生高质量的目标对抗性后缀；其次，使用这些后缀对AdvPrompter进行低秩微调。经过训练的AdvPrompter能够生成不改变指令含义的隐蔽后缀，诱使目标LLM作出有害回应。在多个流行的开源目标LLM上的实验表明，我们的方法在AdvBench数据集上达到了最佳效果，并且这些成果同样适用于封闭源的黑盒LLM API。此外，我们还证明了通过在AdvPrompter生成的合成数据集上进行微调，可以在保持高性能的同时，增强LLM对越狱攻击的抵抗力，即保持高MMLU得分。",
    "title_cn": "AdvPrompter：一种为大型语言模型（LLMs）量身定制的快速自适应对抗性提示工具",
    "tags": [
      "LLM应用",
      "网络安全",
      "人工智能"
    ]
  },
  {
    "title": "Retrieval-Augmented Generation-based Relation Extraction",
    "submit_datetime": "2024年04月20日",
    "abstract": "Information Extraction (IE) is a transformative process that converts unstructured text data into a structured format by employing entity and relation extraction (RE) methodologies. The identification of the relation between a pair of entities plays a crucial role within this framework. Despite the existence of various techniques for relation extraction, their efficacy heavily relies on access to labeled data and substantial computational resources. In addressing these challenges, Large Language Models (LLMs) emerge as promising solutions; however, they might return hallucinating responses due to their own training data. To overcome these limitations, Retrieved-Augmented Generation-based Relation Extraction (RAG4RE) in this work is proposed, offering a pathway to enhance the performance of relation extraction tasks.\n  This work evaluated the effectiveness of our RAG4RE approach utilizing different LLMs. Through the utilization of established benchmarks, such as TACRED, TACREV, Re-TACRED, and SemEval RE datasets, our aim is to comprehensively evaluate the efficacy of our RAG4RE approach. In particularly, we leverage prominent LLMs including Flan T5, Llama2, and Mistral in our investigation. The results of our study demonstrate that our RAG4RE approach surpasses performance of traditional RE approaches based solely on LLMs, particularly evident in the TACRED dataset and its variations. Furthermore, our approach exhibits remarkable performance compared to previous RE methodologies across both TACRED and TACREV datasets, underscoring its efficacy and potential for advancing RE tasks in natural language processing.",
    "pdf_link": "https://arxiv.org/abs/2404.13397",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.13397v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13397/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13397v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13397/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13397v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13397/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13397v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13397/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13397v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13397/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13397v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13397/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13397v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13397/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13397v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13397/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13397v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13397/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13397v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13397/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13397v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13397/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13397v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13397/x12.png"
      }
    ],
    "abstract_cn": "信息抽取（IE）通过实体和关系抽取（RE）技术，将杂乱无章的文本信息转化为井然有序的数据结构，其中实体间关系的辨识尤为关键。尽管众多关系抽取技术已现世，但其成效往往受限于标注数据的可用性和计算资源的丰富度。面对这些难题，大型语言模型（LLMs）崭露头角，但有时也会因训练数据的局限而产生误导性结果。为突破这些瓶颈，本文提出了一种新颖的基于检索增强生成的关系抽取方法（RAG4RE），旨在提升关系抽取的性能。我们通过一系列知名大型语言模型（LLMs），如Flan T5、Llama2和Mistral，对RAG4RE方法进行了效果评估，并选取了TACRED、TACREV、Re-TACRED和SemEval RE等权威数据集作为测试基准。研究结果显示，RAG4RE在TACRED数据集及其衍生变体中的表现尤为突出，超越了仅依赖LLMs的传统关系抽取方法。此外，RAG4RE在TACRED和TACREV数据集上的表现也显著优于以往的关系抽取技术，彰显了其在自然语言处理领域推动关系抽取任务的潜力和效果。",
    "title_cn": "检索增强的生成式关系抽取",
    "tags": [
      "分类：RAG",
      "",
      "信息抽取"
    ]
  },
  {
    "title": "Enhancing Question Answering for Enterprise Knowledge Bases using Large Language Models",
    "submit_datetime": "2024年04月20日",
    "abstract": "Efficient knowledge management plays a pivotal role in augmenting both the operational efficiency and the innovative capacity of businesses and organizations. By indexing knowledge through vectorization, a variety of knowledge retrieval methods have emerged, significantly enhancing the efficacy of knowledge management systems. Recently, the rapid advancements in generative natural language processing technologies paved the way for generating precise and coherent answers after retrieving relevant documents tailored to user queries. However, for enterprise knowledge bases, assembling extensive training data from scratch for knowledge retrieval and generation is a formidable challenge due to the privacy and security policies of private data, frequently entailing substantial costs. To address the challenge above, in this paper, we propose EKRG, a novel Retrieval-Generation framework based on large language models (LLMs), expertly designed to enable question-answering for Enterprise Knowledge bases with limited annotation costs. Specifically, for the retrieval process, we first introduce an instruction-tuning method using an LLM to generate sufficient document-question pairs for training a knowledge retriever. This method, through carefully designed instructions, efficiently generates diverse questions for enterprise knowledge bases, encompassing both fact-oriented and solution-oriented knowledge. Additionally, we develop a relevance-aware teacher-student learning strategy to further enhance the efficiency of the training process. For the generation process, we propose a novel chain of thought (CoT) based fine-tuning method to empower the LLM-based generator to adeptly respond to user questions using retrieved documents. Finally, extensive experiments on real-world datasets have demonstrated the effectiveness of our proposed framework.",
    "pdf_link": "https://arxiv.org/abs/2404.08695",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.08695v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08695/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08695v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08695/ablation.png"
      }
    ],
    "abstract_cn": "高效管理知识对于增强企业和组织的操作效率与创新力至关重要。通过知识向量化索引，催生了众多提升知识管理系统效率的检索方法。随着生成性自然语言处理技术的突飞猛进，现在能够从相关文档中提取出精确且连贯的答案。但对于企业知识库而言，由于数据隐私和安全的限制，从头构建大量的训练数据集以支持知识检索和生成任务，既困难又昂贵。为应对这一挑战，本文提出了EKRG，一种创新的基于大型语言模型（LLMs）的检索-生成框架，旨在以较低的标注成本为企业知识库提供问答服务。具体来说，在检索阶段，我们首先利用LLM引入了一种指令调整方法，以生成足够的文档-问题对，用以训练知识检索器。这种方法通过精心设计的指令，能够高效生成涵盖事实和解决方案导向的企业知识库问题。同时，我们还开发了一种基于相关性感知的师生学习策略，进一步提升训练效率。在生成阶段，我们提出了一种新颖的基于思维链（CoT）的微调方法，使LLM能够灵活运用检索到的文档，精准回应用户询问。最终，我们在真实世界数据集上的广泛实验验证了我们框架的有效性。",
    "title_cn": "利用大型语言模型提升企业知识库的问答能力",
    "tags": [
      "LLM应用",
      "企业知识管理",
      ""
    ]
  },
  {
    "title": "A Survey on the Memory Mechanism of Large Language Model based Agents",
    "submit_datetime": "2024年04月20日",
    "abstract": "Large language model (LLM) based agents have recently attracted much attention from the research and industry communities. Compared with original LLMs, LLM-based agents are featured in their self-evolving capability, which is the basis for solving real-world problems that need long-term and complex agent-environment interactions. The key component to support agent-environment interactions is the memory of the agents. While previous studies have proposed many promising memory mechanisms, they are scattered in different papers, and there lacks a systematical review to summarize and compare these works from a holistic perspective, failing to abstract common and effective designing patterns for inspiring future studies. To bridge this gap, in this paper, we propose a comprehensive survey on the memory mechanism of LLM-based agents. In specific, we first discuss ''what is'' and ''why do we need'' the memory in LLM-based agents. Then, we systematically review previous studies on how to design and evaluate the memory module. In addition, we also present many agent applications, where the memory module plays an important role. At last, we analyze the limitations of existing work and show important future directions. To keep up with the latest advances in this field, we create a repository at \\url{https://github.com/nuster1128/LLM_Agent_Memory_Survey}.",
    "pdf_link": "https://arxiv.org/abs/2404.13501",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.13501v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13501/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13501v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13501/cx1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13501v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13501/cx2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13501v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13501/cx3.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLM）驱动的智能代理近期备受研究和产业界的瞩目。相较于传统LLM，这些代理以其自我演化的特性脱颖而出，这为解决涉及长期复杂交互的现实问题提供了可能。在这些交互中，代理的“记忆”功能扮演着核心角色。尽管先前的研究提出了众多有潜力的内存机制，但这些成果分散在众多文献中，尚未有系统性综述来全面总结和比较这些研究，以提炼出对未来研究有启发性的通用且有效设计模式。本文旨在填补这一研究空白，全面审视基于LLM的代理的内存机制。我们首先探讨了LLM代理中“内存是什么”以及“为何我们需要它”。接着，我们系统性地回顾了关于内存模块设计和评估的先前研究。此外，我们也展示了许多内存模块发挥关键作用的代理应用案例。文末，我们分析了现有研究的局限，并指出了未来研究的重要方向。为紧跟该领域的最新进展，我们建立了一个在线资源库，地址为 \\url{https://github.com/nuster1128/LLM_Agent_Memory_Survey}。",
    "title_cn": "本文综述了基于大型语言模型的智能代理的记忆机制。",
    "tags": [
      "Agent",
      "人工智能",
      "智能代理"
    ]
  },
  {
    "title": "Large Language Models as Test Case Generators: Performance Evaluation and Enhancement",
    "submit_datetime": "2024年04月20日",
    "abstract": "Code generation with Large Language Models (LLMs) has been extensively studied and achieved remarkable progress. As a complementary aspect to code generation, test case generation is of crucial importance in ensuring the quality and reliability of code. However, using LLMs as test case generators has been much less explored. Current research along this line primarily focuses on enhancing code generation with assistance from test cases generated by LLMs, while the performance of LLMs in test case generation alone has not been comprehensively examined. To bridge this gap, we conduct extensive experiments to study how well LLMs can generate high-quality test cases. We find that as the problem difficulty increases, state-of-the-art LLMs struggle to generate correct test cases, largely due to their inherent limitations in computation and reasoning. To mitigate this issue, we further propose a multi-agent framework called \\emph{TestChain} that decouples the generation of test inputs and test outputs. Notably, TestChain uses a ReAct format conversation chain for LLMs to interact with a Python interpreter in order to provide more accurate test outputs. Our results indicate that TestChain outperforms the baseline by a large margin. Particularly, in terms of the accuracy of test cases, TestChain using GPT-4 as the backbone achieves a 13.84\\% improvement over the baseline on the LeetCode-hard dataset.",
    "pdf_link": "https://arxiv.org/abs/2404.13340",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.13340v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13340/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13340v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13340/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13340v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13340/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13340v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13340/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13340v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13340/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13340v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13340/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13340v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13340/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13340v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13340/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13340v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13340/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13340v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13340/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13340v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13340/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13340v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13340/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13340v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13340/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13340v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13340/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13340v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13340/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13340v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13340/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13340v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13340/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13340v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13340/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13340v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13340/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13340v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13340/x20.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13340v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13340/x21.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13340v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13340/x22.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13340v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13340/x23.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13340v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13340/x24.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13340v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13340/x25.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13340v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13340/x26.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13340v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13340/x27.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13340v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13340/x28.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13340v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13340/x29.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13340v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13340/x30.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13340v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13340/x31.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13340v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13340/x32.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13340v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13340/x33.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13340v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13340/x34.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13340v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13340/x35.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13340v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13340/x36.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）在代码生成领域的应用已取得显著成果，而其在测试用例生成方面的潜力却鲜少被挖掘。尽管当前研究多聚焦于利用LLMs辅助生成的测试用例来提升代码生成质量，但LLMs独立生成测试用例的能力尚未得到充分评估。为了填补这一研究空白，我们开展了深入的实验，探究LLMs生成高品质测试用例的能力。实验结果显示，面对日益复杂的挑战，即便是最先进的LLMs也难以生成无误的测试用例，这主要归咎于它们在计算和逻辑推理上的局限性。针对这一问题，我们设计了一种创新的多代理框架——\\emph{TestChain}，它将测试输入与输出的生成过程分离，并通过ReAct格式的对话链让LLMs与Python解释器进行互动，以生成更精确的测试输出。实验结果证明，TestChain在性能上大幅超越了传统基线，尤其是在测试用例的准确性上，采用GPT-4作为核心的TestChain在LeetCode-hard数据集上实现了13.84%的显著提升。",
    "title_cn": "将大型语言模型用作测试用例生成器：评估性能并进行优化",
    "tags": [
      "Agent",
      "软件工程",
      "测试自动化"
    ]
  },
  {
    "title": "FakeBench: Uncover the Achilles' Heels of Fake Images with Large Multimodal Models",
    "submit_datetime": "2024年04月20日",
    "abstract": "Recently, fake images generated by artificial intelligence (AI) models have become indistinguishable from the real, exerting new challenges for fake image detection models. To this extent, simple binary judgments of real or fake seem less convincing and credible due to the absence of human-understandable explanations. Fortunately, Large Multimodal Models (LMMs) bring possibilities to materialize the judgment process while their performance remains undetermined. Therefore, we propose FakeBench, the first-of-a-kind benchmark towards transparent defake, consisting of fake images with human language descriptions on forgery signs. FakeBench gropes for two open questions of LMMs: (1) can LMMs distinguish fake images generated by AI, and (2) how do LMMs distinguish fake images? In specific, we construct the FakeClass dataset with 6k diverse-sourced fake and real images, each equipped with a Question&Answer pair concerning the authenticity of images, which are utilized to benchmark the detection ability. To examine the reasoning and interpretation abilities of LMMs, we present the FakeClue dataset, consisting of 15k pieces of descriptions on the telltale clues revealing the falsification of fake images. Besides, we construct the FakeQA to measure the LMMs' open-question answering ability on fine-grained authenticity-relevant aspects. Our experimental results discover that current LMMs possess moderate identification ability, preliminary interpretation and reasoning ability, and passable open-question answering ability for image defake. The FakeBench will be made publicly available soon.",
    "pdf_link": "https://arxiv.org/abs/2404.13306",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.13306v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13306/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13306v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13306/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13306v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13306/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13306v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13306/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13306v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13306/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13306v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13306/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13306v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13306/x7.png"
      }
    ],
    "abstract_cn": "近期，人工智能（AI）生成的假图像日益逼真，对假图像检测技术构成了严峻挑战。在这一背景下，缺乏清晰解释的简单真假判断已不再那么令人信服。然而，大型多模态模型（LMMs）的出现为这一问题提供了新的解决途径，尽管其效果尚待验证。我们因此引入了FakeBench，这是一个首创的、旨在实现透明去伪的基准测试平台，它包含了带有伪造迹象描述的假图像。FakeBench旨在解答关于LMMs的两大疑问：其一，LMMs是否能够识别出AI生成的假图像；其二，LMMs是如何进行这一识别的。具体而言，我们创建了FakeClass数据集，包含6000张来源多样的真假图像，每张图像都附带了关于其真实性的问答对，用以评估检测能力。为了测试LMMs的推理和解释能力，我们推出了FakeClue数据集，包含15000条揭露假图像伪造迹象的描述。此外，我们还构建了FakeQA，用以衡量LMMs在细节真实性方面开放性问题的回答能力。实验结果显示，目前的LMMs在图像去伪方面具备一定的识别能力，初步的解释和推理能力，以及尚可的开放性问题回答能力。FakeBench将很快向公众开放。",
    "title_cn": "FakeBench：借助大型多模态模型，挖掘伪造图像的软肋。",
    "tags": [
      "LLM应用",
      "人工智能",
      "图像识别"
    ]
  },
  {
    "title": "PCQA: A Strong Baseline for AIGC Quality Assessment Based on Prompt Condition",
    "submit_datetime": "2024年04月20日",
    "abstract": "The development of Large Language Models (LLM) and Diffusion Models brings the boom of Artificial Intelligence Generated Content (AIGC). It is essential to build an effective quality assessment framework to provide a quantifiable evaluation of different images or videos based on the AIGC technologies. The content generated by AIGC methods is driven by the crafted prompts. Therefore, it is intuitive that the prompts can also serve as the foundation of the AIGC quality assessment. This study proposes an effective AIGC quality assessment (QA) framework. First, we propose a hybrid prompt encoding method based on a dual-source CLIP (Contrastive Language-Image Pre-Training) text encoder to understand and respond to the prompt conditions. Second, we propose an ensemble-based feature mixer module to effectively blend the adapted prompt and vision features. The empirical study practices in two datasets: AIGIQA-20K (AI-Generated Image Quality Assessment database) and T2VQA-DB (Text-to-Video Quality Assessment DataBase), which validates the effectiveness of our proposed method: Prompt Condition Quality Assessment (PCQA). Our proposed simple and feasible framework may promote research development in the multimodal generation field.",
    "pdf_link": "https://arxiv.org/abs/2404.13299",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.13299v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13299/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13299v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13299/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13299v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13299/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13299v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13299/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13299v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13299/x5.png"
      }
    ],
    "abstract_cn": "随着大型语言模型（LLM）和扩散模型的兴起，人工智能生成内容（AIGC）迎来了蓬勃发展。为了对基于AIGC技术生成的多样化图像或视频进行量化评估，亟需建立一个高效的质量评估体系。AIGC生成的内容往往依赖于精心设计的提示，提示本身自然成为了质量评估的关键。本研究提出了一套创新的AIGC质量评估框架。首先，我们引入了一种混合提示编码技术，依托双源CLIP文本编码器，以深入理解和响应提示的要求。接着，我们设计了一个集成特征混合模块，用以高效融合调整后的提示与视觉特征。通过在AIGIQA-20K和T2VQA-DB两大数据库上的实证研究，我们验证了所提出的提示条件质量评估（PCQA）方法的有效性。这一简洁而实用的框架有望推动多模态生成研究领域的进一步发展。",
    "title_cn": "PCQA：一种基于提示条件的AI生成内容（AIGC）质量评估的强有力基准",
    "tags": [
      "LLM应用",
      "人工智能",
      "内容生成"
    ]
  },
  {
    "title": "Unlocking Multi-View Insights in Knowledge-Dense Retrieval-Augmented Generation",
    "submit_datetime": "2024年04月19日",
    "abstract": "While Retrieval-Augmented Generation (RAG) plays a crucial role in the application of Large Language Models (LLMs), existing retrieval methods in knowledge-dense domains like law and medicine still suffer from a lack of multi-perspective views, which are essential for improving interpretability and reliability. Previous research on multi-view retrieval often focused solely on different semantic forms of queries, neglecting the expression of specific domain knowledge perspectives. This paper introduces a novel multi-view RAG framework, MVRAG, tailored for knowledge-dense domains that utilizes intention-aware query rewriting from multiple domain viewpoints to enhance retrieval precision, thereby improving the effectiveness of the final inference. Experiments conducted on legal and medical case retrieval demonstrate significant improvements in recall and precision rates with our framework. Our multi-perspective retrieval approach unleashes the potential of multi-view information enhancing RAG tasks, accelerating the further application of LLMs in knowledge-intensive fields.",
    "pdf_link": "https://arxiv.org/abs/2404.12879",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.12879v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12879/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12879v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12879/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12879v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12879/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12879v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12879/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12879v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12879/x5.png"
      }
    ],
    "abstract_cn": "检索增强生成（RAG）对于大型语言模型（LLM）的应用至关重要，但在法律和医学等知识密集型领域，现有检索方法因缺乏多视角视图而受限，这关键于提升模型的解释力和可靠性。过往研究多聚焦于查询的语义多样性，却忽略了领域知识视角的特定表达。本文提出了一个创新的多视图RAG框架——MVRAG，专为知识密集型领域设计，通过多领域视角的意图感知查询重写，增强检索的精准度，进而提升最终推理的效果。在法律和医学案例检索的实验中，我们的框架显著提升了召回率和精确率。这种多视角检索策略充分发挥了多视图信息的潜力，为RAG任务带来增益，推动了LLM在知识密集型行业的广泛应用。",
    "title_cn": "揭示知识密集型检索增强生成中的多维洞见。",
    "tags": [
      "分类：RAG",
      "",
      ""
    ]
  },
  {
    "title": "Generating Test Scenarios from NL Requirements using Retrieval-Augmented LLMs: An Industrial Study",
    "submit_datetime": "2024年04月19日",
    "abstract": "Test scenarios are specific instances of test cases that describe actions to validate a particular software functionality. By outlining the conditions under which the software operates and the expected outcomes, test scenarios ensure that the software functionality is tested in an integrated manner. Test scenarios are crucial for systematically testing an application under various conditions, including edge cases, to identify potential issues and guarantee overall performance and reliability. Specifying test scenarios is tedious and requires a deep understanding of software functionality and the underlying domain. It further demands substantial effort and investment from already time- and budget-constrained requirements engineers and testing teams. This paper presents an automated approach (RAGTAG) for test scenario generation using Retrieval-Augmented Generation (RAG) with Large Language Models (LLMs). RAG allows the integration of specific domain knowledge with LLMs' generation capabilities. We evaluate RAGTAG on two industrial projects from Austrian Post with bilingual requirements in German and English. Our results from an interview survey conducted with four experts on five dimensions -- relevance, coverage, correctness, coherence and feasibility, affirm the potential of RAGTAG in automating test scenario generation. Specifically, our results indicate that, despite the difficult task of analyzing bilingual requirements, RAGTAG is able to produce scenarios that are well-aligned with the underlying requirements and provide coverage of different aspects of the intended functionality. The generated scenarios are easily understandable to experts and feasible for testing in the project environment. The overall correctness is deemed satisfactory; however, gaps in capturing exact action sequences and domain nuances remain, underscoring the need for domain expertise when applying LLMs.",
    "pdf_link": "https://arxiv.org/abs/2404.12772",
    "graphs": [],
    "abstract_cn": "测试场景是针对特定软件功能的测试用例的具体应用，它们通过定义软件运行条件和预期成果，确保软件功能的全面集成测试。这些场景对于在多变条件下系统性地测试应用程序、捕捉边缘情况、发现潜在问题以及确保软件的整体性能和可靠性至关重要。然而，制定测试场景既繁琐又复杂，它不仅要求深入掌握软件功能和相关领域知识，还对时间和预算本就紧张的需求工程师和测试团队提出了更高的要求。本论文提出了一种名为RAGTAG的自动化测试场景生成方法，该方法利用检索增强生成（RAG）技术和大型语言模型（LLM）。RAG技术使得特定领域的知识能够与LLM的生成能力相结合。我们在奥地利邮政的两个双语（德语和英语）工业项目中对RAGTAG进行了评估。通过与四位专家就相关性、覆盖度、准确性、连贯性和可行性五个方面进行的访谈调查，我们证实了RAGTAG在自动化生成测试场景方面的潜力。尽管面对分析双语需求的挑战，RAGTAG仍能生成与原始需求高度契合且全面覆盖预期功能各个方面的场景。这些场景不仅易于专家理解，也适合在项目环境中进行测试。尽管整体正确性得到了认可，但在捕捉精确动作序列和领域细节方面仍有改进空间，这表明在使用LLM时，领域专业知识的运用至关重要。",
    "title_cn": "本工业研究探讨了如何利用增强检索功能的大型语言模型，从自然语言需求中生成测试场景。",
    "tags": [
      "RAG",
      "软件测试",
      ""
    ]
  },
  {
    "title": "The Solution for the CVPR2024 NICE Image Captioning Challenge",
    "submit_datetime": "2024年04月19日",
    "abstract": "This report introduces a solution to the Topic 1 Zero-shot Image Captioning of 2024 NICE : New frontiers for zero-shot Image Captioning Evaluation. In contrast to NICE 2023 datasets, this challenge involves new annotations by humans with significant differences in caption style and content. Therefore, we enhance image captions effectively through retrieval augmentation and caption grading methods. At the data level, we utilize high-quality captions generated by image caption models as training data to address the gap in text styles. At the model level, we employ OFA (a large-scale visual-language pre-training model based on handcrafted templates) to perform the image captioning task. Subsequently, we propose caption-level strategy for the high-quality caption data generated by the image caption models and integrate them with retrieval augmentation strategy into the template to compel the model to generate higher quality, more matching, and semantically enriched captions based on the retrieval augmentation prompts. Our approach ranks first on the leaderboard, achieving a CIDEr score of 234.11 and 1st in all other metrics.",
    "pdf_link": "https://arxiv.org/abs/2404.12739",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.12739v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12739/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12739v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12739/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12739v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12739/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12739v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12739/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12739v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12739/x5.png"
      }
    ],
    "abstract_cn": "本报告提出了一种针对2024年NICE挑战赛第1主题——零样本图像字幕生成的创新解决方案。与2023年的数据集相比，新挑战的人类注释在字幕的风格和内容上有了显著变化。我们通过改进的检索增强技术和字幕评分方法，有效提升了字幕的质量。在数据处理上，我们采用了由图像字幕模型生成的优质字幕作为训练素材，以弥补文本风格的差异。模型方面，我们部署了OFA——一种基于定制模板的大规模视觉-语言预训练模型，来执行字幕生成任务。此外，我们还提出了一种基于字幕级别的策略，将这些优质数据与检索增强技术相结合，推动模型产出更精准、语义更丰富的高质量字幕。这一方法在排行榜上勇夺第一，CIDEr得分高达234.11分，并在其他所有评价指标上均领跑。",
    "title_cn": "CVPR2024 NICE 图像标题挑战的应对之道",
    "tags": [
      "分类：LLM应用\n\n这篇论文的摘要描述了一种针对零样本图像字幕生成任务的解决方案，使用了大规模视觉-语言预训练模型（OFA）和字幕级别的策略来生成高质量的字幕。这表明了该研究在实际应用中使用了大型语言模型（LLM），因此可以归类为LLM应用。",
      "计算机视觉",
      ""
    ]
  },
  {
    "title": "Enhancing Q&A with Domain-Specific Fine-Tuning and Iterative Reasoning: A Comparative Study",
    "submit_datetime": "2024年04月19日",
    "abstract": "This paper investigates the impact of domain-specific model fine-tuning and of reasoning mechanisms on the performance of question-answering (Q&A) systems powered by large language models (LLMs) and Retrieval-Augmented Generation (RAG). Using the FinanceBench SEC financial filings dataset, we observe that, for RAG, combining a fine-tuned embedding model with a fine-tuned LLM achieves better accuracy than generic models, with relatively greater gains attributable to fine-tuned embedding models. Additionally, employing reasoning iterations on top of RAG delivers an even bigger jump in performance, enabling the Q&A systems to get closer to human-expert quality. We discuss the implications of such findings, propose a structured technical design space capturing major technical components of Q&A AI, and provide recommendations for making high-impact technical choices for such components. We plan to follow up on this work with actionable guides for AI teams and further investigations into the impact of domain-specific augmentation in RAG and into agentic AI capabilities such as advanced planning and reasoning.",
    "pdf_link": "https://arxiv.org/abs/2404.11792",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.11792v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11792/ooda.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11792v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11792/ooda-rag.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11792v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11792/ooda-financebench.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11792v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11792/design-space.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11792v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11792/financebench-categories.png"
      }
    ],
    "abstract_cn": "本研究深入探讨了特定领域模型微调和推理机制在提升大型语言模型（LLMs）和增强检索生成（RAG）驱动的问答（Q&A）系统性能方面的作用。通过FinanceBench SEC财务文件数据集的分析，我们发现，将微调后的嵌入模型与LLM相结合，相较于通用模型，能够显著提升RAG的准确性，尤其是微调后的嵌入模型贡献更为显著。进一步地，叠加推理迭代能够显著提升性能，使得Q&A系统的表现更接近于人类专家水平。文章还讨论了这些发现的意义，提出了一个系统化的技术设计框架，涵盖了Q&A人工智能的关键技术要素，并为这些要素提供了技术选择的建议。未来，我们将继续开展工作，为AI团队提供实践指南，并深入研究RAG中特定领域增强的影响以及代理AI能力，如高级规划和推理等方面的影响。",
    "title_cn": "通过针对特定领域的精细调整和迭代推理过程，提升问答系统的性能：一项对比分析研究",
    "tags": [
      "分类：RAG",
      "",
      "问答系统"
    ]
  },
  {
    "title": "AutoCrawler: A Progressive Understanding Web Agent for Web Crawler Generation",
    "submit_datetime": "2024年04月19日",
    "abstract": "Web automation is a significant technique that accomplishes complicated web tasks by automating common web actions, enhancing operational efficiency, and reducing the need for manual intervention. Traditional methods, such as wrappers, suffer from limited adaptability and scalability when faced with a new website. On the other hand, generative agents empowered by large language models (LLMs) exhibit poor performance and reusability in open-world scenarios. In this work, we introduce a crawler generation task for vertical information web pages and the paradigm of combining LLMs with crawlers, which helps crawlers handle diverse and changing web environments more efficiently. We propose AutoCrawler, a two-stage framework that leverages the hierarchical structure of HTML for progressive understanding. Through top-down and step-back operations, AutoCrawler can learn from erroneous actions and continuously prune HTML for better action generation. We conduct comprehensive experiments with multiple LLMs and demonstrate the effectiveness of our framework. Resources of this paper can be found at \\url{https://github.com/EZ-hwh/AutoCrawler}",
    "pdf_link": "https://arxiv.org/abs/2404.12753",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.12753v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12753/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12753v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12753/x2.png"
      }
    ],
    "abstract_cn": "网络自动化技术通过模拟常规网络行为，自动化执行复杂的网络任务，以此提升工作效率并降低手工操作的必要性。相较于传统方法如包装器，它们在适应新网站时存在适应性和扩展性的限制。与此同时，由大型语言模型（LLMs）驱动的生成性代理在开放环境下的性能和可复用性不尽人意。本研究提出了一种针对垂直信息网页的爬虫生成任务，以及一种融合LLMs与爬虫的新范式，以提高爬虫在多样化和动态变化的网络环境中的适应性和效率。我们设计了AutoCrawler，这是一个分两阶段的框架，它利用HTML的层级结构实现逐步理解。通过自上而下的操作和错误反馈学习，AutoCrawler能够不断优化HTML解析，以生成更精准的动作。我们对多个LLMs进行了广泛的测试，验证了我们框架的有效性。本文的相关资源可在 \\url{https://github.com/EZ-hwh/AutoCrawler} 获取。",
    "title_cn": "AutoCrawler：一种渐进式理解的网络代理，专为网络爬虫生成而设计。",
    "tags": [
      "Agent",
      "网络自动化",
      "网页爬虫"
    ]
  },
  {
    "title": "Evaluating Character Understanding of Large Language Models via Character Profiling from Fictional Works",
    "submit_datetime": "2024年04月19日",
    "abstract": "Large language models (LLMs) have demonstrated impressive performance and spurred numerous AI applications, in which role-playing agents (RPAs) are particularly popular, especially for fictional characters. The prerequisite for these RPAs lies in the capability of LLMs to understand characters from fictional works. Previous efforts have evaluated this capability via basic classification tasks or characteristic imitation, failing to capture the nuanced character understanding with LLMs. In this paper, we propose evaluating LLMs' character understanding capability via the character profiling task, i.e., summarizing character profiles from corresponding materials, a widely adopted yet understudied practice for RPA development. Specifically, we construct the CroSS dataset from literature experts and assess the generated profiles by comparing ground truth references and their applicability in downstream tasks. Our experiments, which cover various summarization methods and LLMs, have yielded promising results. These results strongly validate the character understanding capability of LLMs. We believe our constructed resource will promote further research in this field. Resources are available at https://github.com/Joanna0123/character_profiling.",
    "pdf_link": "https://arxiv.org/abs/2404.12726",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）以其卓越的性能引领了众多AI应用的潮流，其中角色扮演代理（RPAs）因其独特的魅力而备受青睐，尤其是在虚构角色的塑造上。RPAs的核心在于LLMs对虚构作品中角色的深刻理解。尽管以往的研究尝试通过基础分类或特征模仿任务来评估LLMs的这一能力，但这些方法并未能充分捕捉到LLMs对角色理解的细腻之处。本文提出了一种新的评价方法——通过角色画像任务来衡量LLMs对角色的理解力，即从相关材料中提炼出角色画像，这一方法在RPAs的发展中虽被广泛应用，却鲜少受到学术界的关注。我们特别构建了CroSS数据集，并邀请文学专家参与，通过比对基准真实参考和角色画像在下游任务中的应用性来评估生成的画像。我们进行的一系列实验，包括多种总结方法和LLMs的测试，均取得了令人鼓舞的成果，这些成果充分证实了LLMs在角色理解方面的能力。我们期望本研究能够为该领域的深入探索提供动力。相关资源已在 https://github.com/Joanna0123/character_profiling 上发布。",
    "title_cn": "本研究通过分析虚构作品中的角色档案，探讨了大型语言模型对角色认知的深度。",
    "tags": [
      "分类：Agent\n\n这篇论文讨论了大型语言模型（LLMs）在角色扮演代理（RPAs）中的应用，特别是它们如何理解和塑造虚构角色。论文提出了一种新的评价方法，通过角色画像任务来衡量LLMs对角色的理解力。这表明论文的重点是LLMs在特定应用领域（即RPAs）的性能和应用，因此将其归类为Agent。",
      "人工智能",
      ""
    ]
  },
  {
    "title": "MoVA: Adapting Mixture of Vision Experts to Multimodal Context",
    "submit_datetime": "2024年04月19日",
    "abstract": "As the key component in multimodal large language models (MLLMs), the ability of the visual encoder greatly affects MLLM's understanding on diverse image content. Although some large-scale pretrained vision encoders such as vision encoders in CLIP and DINOv2 have brought promising performance, we found that there is still no single vision encoder that can dominate various image content understanding, e.g., the CLIP vision encoder leads to outstanding results on general image understanding but poor performance on document or chart content. To alleviate the bias of CLIP vision encoder, we first delve into the inherent behavior of different pre-trained vision encoders and then propose the MoVA, a powerful and novel MLLM, adaptively routing and fusing task-specific vision experts with a coarse-to-fine mechanism. In the coarse-grained stage, we design a context-aware expert routing strategy to dynamically select the most suitable vision experts according to the user instruction, input image, and expertise of vision experts. This benefits from the powerful model function understanding ability of the large language model (LLM) equipped with expert-routing low-rank adaptation (LoRA). In the fine-grained stage, we elaborately conduct the mixture-of-vision-expert adapter (MoV-Adapter) to extract and fuse task-specific knowledge from various experts. This coarse-to-fine paradigm effectively leverages representations from experts based on multimodal context and model expertise, further enhancing the generalization ability. We conduct extensive experiments to evaluate the effectiveness of the proposed approach. Without any bells and whistles, MoVA can achieve significant performance gains over current state-of-the-art methods in a wide range of challenging multimodal benchmarks. Codes and models will be available at https://github.com/TempleX98/MoVA.",
    "pdf_link": "https://arxiv.org/abs/2404.13046",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.13046v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13046/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13046v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13046/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13046v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13046/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13046v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13046/x4.png"
      }
    ],
    "abstract_cn": "在多模态大型语言模型（MLLMs）中，视觉编码器扮演着核心角色，其性能直接影响模型对丰富图像内容的解析能力。尽管像CLIP和DINOv2这样的大规模预训练视觉编码器已经展现出不俗的表现，但目前尚未有单一编码器能在各类图像内容理解上都占据优势，例如CLIP在常规图像理解上表现出色，却在文档或图表类内容上不尽人意。为了克服CLIP视觉编码器的局限性，我们首先剖析了不同预训练视觉编码器的内在特性，并据此提出了MoVA——一种创新的MLLM，它能够通过由粗到细的机制，灵活地引导和整合特定任务的视觉专家。在粗粒度层面，我们开发了一种基于上下文的专家路由策略，能够根据用户的指令、输入图像以及视觉专家的专长，动态地选择最合适的视觉专家。这一策略得益于我们的大型语言模型（LLM）所具备的强大功能理解能力，以及专家路由低秩适应（LoRA）技术的加持。在细粒度层面，我们精心打造了混合视觉专家适配器（MoV-Adapter），用于从众多专家中提炼并融合任务相关的知识。这种由粗到细的处理模式，充分利用了多模态上下文和模型专长，有效提升了模型的泛化性能。我们通过大量实验验证了本方法的有效性，MoVA在无需额外修饰的情况下，便能在众多复杂的多模态基准测试中取得显著的性能提升。相关代码和模型将在 https://github.com/TempleX98/MoVA 提供。",
    "title_cn": "MoVA：将视觉专家的混合应用于多模态环境的适应性研究",
    "tags": [
      "LLM应用",
      "计算机视觉",
      ""
    ]
  },
  {
    "title": "Groma: Localized Visual Tokenization for Grounding Multimodal Large Language Models",
    "submit_datetime": "2024年04月19日",
    "abstract": "We introduce Groma, a Multimodal Large Language Model (MLLM) with grounded and fine-grained visual perception ability. Beyond holistic image understanding, Groma is adept at region-level tasks such as region captioning and visual grounding. Such capabilities are built upon a localized visual tokenization mechanism, where an image input is decomposed into regions of interest and subsequently encoded into region tokens. By integrating region tokens into user instructions and model responses, we seamlessly enable Groma to understand user-specified region inputs and ground its textual output to images. Besides, to enhance the grounded chat ability of Groma, we curate a visually grounded instruction dataset by leveraging the powerful GPT-4V and visual prompting techniques. Compared with MLLMs that rely on the language model or external module for localization, Groma consistently demonstrates superior performances in standard referring and grounding benchmarks, highlighting the advantages of embedding localization into image tokenization. Project page: https://groma-mllm.github.io/.",
    "pdf_link": "https://arxiv.org/abs/2404.13013",
    "graphs": [],
    "abstract_cn": "我们推出了 Groma，这是一款具备精细视觉感知能力的多模态大型语言模型（MLLM）。Groma 精于区域级任务，例如区域字幕和视觉定位，超越了对图像的整体理解。这一能力基于一种将图像分解为关键区域并转化为区域标记的局部视觉标记机制。通过将这些区域标记融入用户指令和模型反馈，Groma 能够流畅地识别用户指定的区域并将其文本输出与图像紧密结合。此外，为了提升 Groma 的视觉基础对话能力，我们利用先进的 GPT-4V 和视觉提示技术，精心构建了一个视觉基础指令数据集。与那些依赖于语言模型或外部模块进行定位的 MLLM 相比，Groma 在标准的引用和定位基准测试中持续展现出更优的表现，彰显了将定位功能整合进图像标记化的优势。项目详情可见：https://groma-mllm.github.io/。",
    "title_cn": "Groma：为多模态大型语言模型提供精准视觉标记化技术",
    "tags": [
      "分类：LLM应用\n\n这篇论文介绍了一个名为 Groma 的多模态大型语言模型（MLLM），它在区域级任务（如区域字幕和视觉定位）中表现出色。Groma 的能力基于将图像分解为关键区域并转化为区域标记的局部视觉标记机制。此外，为了提升 Groma 的视觉基础对话能力，研究者利用了先进的 GPT-4V 和视觉提示技术。这篇论文主要关注 Groma 在实际应用中的表现和优势，因此将其归类为 LLM应用。",
      "视觉识别",
      "人工智能"
    ]
  },
  {
    "title": "How Does the Textual Information Affect the Retrieval of Multimodal In-Context Learning?",
    "submit_datetime": "2024年04月19日",
    "abstract": "The increase in parameter size of multimodal large language models (MLLMs) introduces significant capabilities, particularly in-context learning, where MLLMs enhance task performance without updating pre-trained parameters. This effectiveness, however, hinges on the appropriate selection of in-context examples, a process that is currently biased towards visual data, overlooking textual information. Furthermore, the area of supervised retrievers for MLLMs, crucial for optimal in-context example selection, continues to be uninvestigated. Our study offers an in-depth evaluation of the impact of textual information on the unsupervised selection of in-context examples in multimodal contexts, uncovering a notable sensitivity of retriever performance to the employed modalities. Responding to this, we introduce a novel supervised MLLM-retriever MSIER that employs a neural network to select examples that enhance multimodal in-context learning efficiency. This approach is validated through extensive testing across three distinct tasks, demonstrating the method's effectiveness. Additionally, we investigate the influence of modalities on our supervised retrieval method's training and pinpoint factors contributing to our model's success. This exploration paves the way for future advancements, highlighting the potential for refined in-context learning in MLLMs through the strategic use of multimodal data.",
    "pdf_link": "https://arxiv.org/abs/2404.12866",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.12866v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12866/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12866v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12866/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12866v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12866/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12866v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12866/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12866v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12866/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12866v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12866/x6.png"
      }
    ],
    "abstract_cn": "随着多模态大型语言模型（MLLMs）参数量的扩大，它们在无需调整预训练参数的情况下，通过上下文学习显著提升了任务执行能力。然而，这种性能提升依赖于精心挑选的上下文示例，目前这一选择过程存在偏差，偏重视觉数据而忽略了文本信息。对于优化上下文示例选择至关重要的监督检索器领域，在MLLMs中的应用尚未得到充分探索。本研究深入分析了文本信息在多模态环境下对无监督选择上下文示例的影响，发现检索器的性能对所采用的信息模态极为敏感。为此，我们提出了一种创新的监督MLLM-检索器MSIER，利用神经网络精选示例以提高多模态上下文学习效率。该方法在三项不同任务上的广泛测试中证明了其有效性。我们还探讨了模态对我们监督检索方法训练的影响，并识别了推动模型成功的关键因素。这一研究为未来的技术进步奠定了基础，展示了通过策略性地运用多模态数据，对MLLMs中的上下文学习进行优化的巨大潜力。",
    "title_cn": "文本信息对多模态上下文内学习（MCL）检索过程的影响是怎样的？",
    "tags": [
      "LLM应用",
      "人工智能",
      "多模态学习"
    ]
  },
  {
    "title": "TextSquare: Scaling up Text-Centric Visual Instruction Tuning",
    "submit_datetime": "2024年04月19日",
    "abstract": "Text-centric visual question answering (VQA) has made great strides with the development of Multimodal Large Language Models (MLLMs), yet open-source models still fall short of leading models like GPT4V and Gemini, partly due to a lack of extensive, high-quality instruction tuning data. To this end, we introduce a new approach for creating a massive, high-quality instruction-tuning dataset, Square-10M, which is generated using closed-source MLLMs. The data construction process, termed Square, consists of four steps: Self-Questioning, Answering, Reasoning, and Evaluation. Our experiments with Square-10M led to three key findings: 1) Our model, TextSquare, considerably surpasses open-source previous state-of-the-art Text-centric MLLMs and sets a new standard on OCRBench(62.2%). It even outperforms top-tier models like GPT4V and Gemini in 6 of 10 text-centric benchmarks. 2) Additionally, we demonstrate the critical role of VQA reasoning data in offering comprehensive contextual insights for specific questions. This not only improves accuracy but also significantly mitigates hallucinations. Specifically, TextSquare scores an average of 75.1% across four general VQA and hallucination evaluation datasets, outperforming previous state-of-the-art models. 3) Notably, the phenomenon observed in scaling text-centric VQA datasets reveals a vivid pattern: the exponential increase of instruction tuning data volume is directly proportional to the improvement in model performance, thereby validating the necessity of the dataset scale and the high quality of Square-10M.",
    "pdf_link": "https://arxiv.org/abs/2404.12803",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.12803v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12803/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12803v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12803/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12803v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12803/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12803v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12803/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12803v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12803/x5.png"
      }
    ],
    "abstract_cn": "随着多模态大型语言模型（MLLMs）的进展，文本中心视觉问答（VQA）领域取得了显著突破。尽管如此，开源模型相较于GPT4V和Gemini等顶尖模型仍有不足，这在一定程度上归咎于高质量指令调优数据的匮乏。为了解决这一问题，我们提出了一种创新方法，用于构建一个庞大且高质量的指令调优数据集——Square-10M，该数据集利用闭源MLLMs生成。整个数据构建流程，即Square流程，分为自我提问、解答、推理和评估四个阶段。通过Square-10M的实验，我们得出了三项重要发现：首先，我们的模型TextSquare在OCRBench上达到了62.2%的准确率，大幅超越了先前的开源顶尖模型，并为文本中心MLLMs设定了新的基准。其次，TextSquare在10个文本中心基准测试中的6个上超越了GPT4V和Gemini等顶级模型。此外，我们还证实了VQA推理数据在提供特定问题全面上下文洞察中的核心作用，这不仅提升了准确度，还显著减少了幻觉现象。具体来说，TextSquare在四个通用VQA和幻觉评估数据集上的平均准确率达到了75.1%，超越了之前的顶尖模型。最后，文本中心VQA数据集规模的扩展呈现出明显的规律：指令调优数据量的指数级增长与模型性能的提升成正比，这进一步证实了大规模和高质量数据集的必要性，以及Square-10M的卓越价值。",
    "title_cn": "TextSquare：扩展文本导向的视觉指令调优",
    "tags": [
      "LLM应用",
      "视觉问答",
      "数据集构建"
    ]
  },
  {
    "title": "Large Language Model Supply Chain: A Research Agenda",
    "submit_datetime": "2024年04月19日",
    "abstract": "The rapid advancements in pre-trained Large Language Models (LLMs) and Large Multimodal Models (LMMs) have ushered in a new era of intelligent applications, transforming fields ranging from natural language processing to content generation. The LLM supply chain represents a crucial aspect of the contemporary artificial intelligence landscape. It encompasses the entire lifecycle of pre-trained models, from its initial development and training to its final deployment and application in various domains. This paper presents a comprehensive overview of the LLM supply chain, highlighting its three core elements: 1) the model infrastructure, encompassing datasets and toolchain for training, optimization, and deployment; 2) the model lifecycle, covering training, testing, releasing, and ongoing maintenance; and 3) the downstream application ecosystem, enabling the integration of pre-trained models into a wide range of intelligent applications. However, this rapidly evolving field faces numerous challenges across these key components, including data privacy and security, model interpretability and fairness, infrastructure scalability, and regulatory compliance. Addressing these challenges is essential for harnessing the full potential of LLMs and ensuring their ethical and responsible use. This paper provides a future research agenda for the LLM supply chain, aiming at driving the continued advancement and responsible deployment of these transformative LLMs.",
    "pdf_link": "https://arxiv.org/abs/2404.12736",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.12736v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12736/x1.png"
      }
    ],
    "abstract_cn": "随着预训练的大型语言模型（LLMs）和大型多模态模型（LMMs）的突飞猛进，智能应用迎来了新纪元，从自然语言处理到内容创作等多个领域都经历了革新。LLM供应链作为现代人工智能领域的关键一环，涵盖了预训练模型从研发、训练到部署和跨领域应用的完整周期。本文深入探讨了LLM供应链的三大核心要素：模型架构、模型生命周期以及下游应用生态，强调了从数据集到工具链的全方位覆盖。尽管如此，这一迅猛发展的领域在数据隐私、模型透明度、基础设施扩展性以及法规遵循等方面仍面临诸多挑战。应对这些挑战对于释放LLMs的全部潜能并确保其合理、道德使用具有重要意义。文章还为LLM供应链的未来研究方向提出了议程，旨在推动这些变革性模型的持续发展和负责任的应用。",
    "title_cn": "探索大型语言模型的供应链：制定研究路线图",
    "tags": [
      "LLM理论",
      "人工智能",
      ""
    ]
  },
  {
    "title": "CyberSecEval 2: A Wide-Ranging Cybersecurity Evaluation Suite for Large Language Models",
    "submit_datetime": "2024年04月19日",
    "abstract": "Large language models (LLMs) introduce new security risks, but there are few comprehensive evaluation suites to measure and reduce these risks. We present BenchmarkName, a novel benchmark to quantify LLM security risks and capabilities. We introduce two new areas for testing: prompt injection and code interpreter abuse. We evaluated multiple state-of-the-art (SOTA) LLMs, including GPT-4, Mistral, Meta Llama 3 70B-Instruct, and Code Llama. Our results show that conditioning away risk of attack remains an unsolved problem; for example, all tested models showed between 26% and 41% successful prompt injection tests. We further introduce the safety-utility tradeoff: conditioning an LLM to reject unsafe prompts can cause the LLM to falsely reject answering benign prompts, which lowers utility. We propose quantifying this tradeoff using False Refusal Rate (FRR). As an illustration, we introduce a novel test set to quantify FRR for cyberattack helpfulness risk. We find many LLMs able to successfully comply with \"borderline\" benign requests while still rejecting most unsafe requests. Finally, we quantify the utility of LLMs for automating a core cybersecurity task, that of exploiting software vulnerabilities. This is important because the offensive capabilities of LLMs are of intense interest; we quantify this by creating novel test sets for four representative problems. We find that models with coding capabilities perform better than those without, but that further work is needed for LLMs to become proficient at exploit generation. Our code is open source and can be used to evaluate other LLMs.",
    "pdf_link": "https://arxiv.org/abs/2404.13161",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.13161v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13161/cyberattack_compliance_v5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13161v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13161/llm_perf_ffr_tradeoff_v5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13161v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13161/prompt_inject_eval_v5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13161v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13161/prompt_injection_logic_vs_security_v5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13161v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13161/code_exp_eval_v5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13161v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13161/code_interp_scores_v6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13161v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13161/bof_v3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13161v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13161/string_constraint_example_v3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13161v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13161/sqli_example_v3.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）带来了前所未有的安全挑战，尽管目前缺乏全面的评估工具来衡量和缓解这些风险。我们推出了一个创新的基准测试——BenchmarkName，旨在量化LLMs的安全风险和防护能力。本研究开拓了两个新的测试维度：提示注入和代码解释器滥用。我们对一系列业界领先的（SOTA）LLMs进行了评估，包括GPT-4、Mistral、Meta Llama 3 70B-Instruct和Code Llama。评估结果显示，防御攻击的风险仍是一个难题；例如，所有受测模型在提示注入测试中的成功率介于26%至41%之间。此外，我们提出了安全性与实用性的平衡问题：LLMs在被调整以拒绝危险提示的同时，也可能错误地拒绝回答无害的提示，从而降低了其实用性。我们提出通过错误拒绝率（FRR）来衡量这一权衡。为了具体说明，我们设计了一个新的测试集，用以量化网络攻击帮助性风险的FRR。研究发现，许多LLMs能够在拒绝大多数危险请求的同时，成功响应“边缘性”的无害请求。此外，我们还评估了LLMs在自动化软件漏洞利用这一核心网络安全任务中的效用。鉴于LLMs的攻击潜力备受关注，我们通过创建针对四个代表性问题的新型测试集来量化这一能力。结果显示，具备编码功能的模型在性能上优于那些没有编码功能的模型，但LLMs要想在漏洞利用生成方面达到高水准，仍需进一步的研究和开发。我们的代码已开源，可供其他LLMs的评估使用。",
    "title_cn": "CyberSecEval 2：为大型语言模型量身打造的全面网络安全评估工具集。",
    "tags": [
      "LLM应用",
      "网络安全",
      "人工智能安全"
    ]
  },
  {
    "title": "Data Alignment for Zero-Shot Concept Generation in Dermatology AI",
    "submit_datetime": "2024年04月19日",
    "abstract": "AI in dermatology is evolving at a rapid pace but the major limitation to training trustworthy classifiers is the scarcity of data with ground-truth concept level labels, which are meta-labels semantically meaningful to humans. Foundation models like CLIP providing zero-shot capabilities can help alleviate this challenge by leveraging vast amounts of image-caption pairs available on the internet. CLIP can be fine-tuned using domain specific image-caption pairs to improve classification performance. However, CLIP's pre-training data is not well-aligned with the medical jargon that clinicians use to perform diagnoses. The development of large language models (LLMs) in recent years has led to the possibility of leveraging the expressive nature of these models to generate rich text. Our goal is to use these models to generate caption text that aligns well with both the clinical lexicon and with the natural human language used in CLIP's pre-training data. Starting with captions used for images in PubMed articles, we extend them by passing the raw captions through an LLM fine-tuned on the field's several textbooks. We find that using captions generated by an expressive fine-tuned LLM like GPT-3.5 improves downstream zero-shot concept classification performance.",
    "pdf_link": "https://arxiv.org/abs/2404.13043",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.13043v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13043/text.png"
      }
    ],
    "abstract_cn": "AI在皮肤科的应用正迅速进步，但高质量数据的匮乏仍是训练可靠分类器的瓶颈。这些数据需要具备对人类有意义的、精确到概念层面的标签。CLIP等基础模型凭借其零样本功能，通过利用网络上海量的图像与标题配对，为这一难题提供了解决方案。通过特定领域的图像与标题配对对CLIP进行微调，可以有效提升分类准确度。尽管如此，CLIP的预训练数据与医生诊断时使用的医学术语并不完全吻合。幸运的是，近年来大型语言模型（LLM）的兴起，让我们看到了利用这些模型的强大表达力来创造丰富文本的希望。我们计划利用这些模型生成既贴近临床词汇，又符合CLIP预训练数据中自然人类语言习惯的标题文本。具体来说，我们首先选取PubMed文献中的图像标题，然后通过在该领域教科书上微调的LLM对这些原始标题进行扩展。实验结果表明，使用经过微调的表达力强的LLM，如GPT-3.5，生成的标题能够显著提升零样本概念分类的性能。",
    "title_cn": "为皮肤科学AI中的零样本概念生成进行数据对齐。",
    "tags": [
      "LLM应用",
      "皮肤科",
      "人工智能"
    ]
  },
  {
    "title": "Dubo-SQL: Diverse Retrieval-Augmented Generation and Fine Tuning for Text-to-SQL",
    "submit_datetime": "2024年04月18日",
    "abstract": "The current state-of-the-art (SOTA) for automated text-to-SQL still falls well short of expert human performance as measured by execution accuracy (EX) on the BIRD-SQL benchmark. The most accurate methods are also slow and expensive. To advance the SOTA for text-to-SQL while reducing cost and improving speed, we explore the combination of low-cost fine tuning, novel methods for diverse retrieval-augmented generation (RAG) and new input and output formats that help large language models (LLMs) achieve higher EX. We introduce two new methods, Dubo-SQL v1 and v2. Dubo-SQL v1 sets a new record for EX on the holdout test set of BIRD-SQL. Dubo-SQL v2 achieves even higher performance on the BIRD-SQL dev set. Dubo-SQL v1 relies on LLMs from OpenAI, but uses the low-cost GPT-3.5 Turbo while exceeding the performance of the next-best model using OpenAI, which instead uses the more expensive GPT-4. Dubo-SQL v1 exceeds the performance of the next-best model using GPT-3.5 by over 20%. Dubo-SQL v2 uses GPT-4 Turbo and RAG in place of fine tuning to push EX higher.",
    "pdf_link": "https://arxiv.org/abs/2404.12560",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.12560v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12560/dubov1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12560v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12560/dubov2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12560v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12560/examplesvaccuracy.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12560v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12560/tempvaccuracy.png"
      }
    ],
    "abstract_cn": "当前自动化文本到SQL技术的最前沿在BIRD-SQL基准的执行准确度（EX）上仍未达到专家水平，且顶尖方法不仅速度慢，成本也高。为了提升这一技术前沿并降低成本、加快速度，我们研究了低成本微调、创新的多样化检索增强生成（RAG）策略，以及新的输入输出格式，以助力大型语言模型（LLMs）提升EX。我们推出了两种新方法：Dubo-SQL v1和v2。Dubo-SQL v1在BIRD-SQL的独立测试集上刷新了EX的记录，而Dubo-SQL v2在开发集上展现了更出色的性能。Dubo-SQL v1借助OpenAI的LLMs，尤其是成本效益高的GPT-3.5 Turbo，超越了使用更昂贵GPT-4的竞争对手。与使用GPT-3.5的前最佳模型相比，Dubo-SQL v1的性能提升了20%以上。Dubo-SQL v2则采用了GPT-4 Turbo和RAG技术，而非微调，以进一步提升EX。",
    "title_cn": "Dubo-SQL：一种文本到SQL的生成技术，通过多样化检索增强和精准微调，以提升性能。",
    "tags": [
      "分类：RAG",
      "数据库",
      ""
    ]
  },
  {
    "title": "iRAG: An Incremental Retrieval Augmented Generation System for Videos",
    "submit_datetime": "2024年04月18日",
    "abstract": "Retrieval augmented generation (RAG) systems combine the strengths of language generation and information retrieval to power many real-world applications like chatbots. Use of RAG for combined understanding of multimodal data such as text, images and videos is appealing but two critical limitations exist: one-time, upfront capture of all content in large multimodal data as text descriptions entails high processing times, and not all information in the rich multimodal data is typically in the text descriptions. Since the user queries are not known apriori, developing a system for multimodal to text conversion and interactive querying of multimodal data is challenging.\n  To address these limitations, we propose iRAG, which augments RAG with a novel incremental workflow to enable interactive querying of large corpus of multimodal data. Unlike traditional RAG, iRAG quickly indexes large repositories of multimodal data, and in the incremental workflow, it uses the index to opportunistically extract more details from select portions of the multimodal data to retrieve context relevant to an interactive user query. Such an incremental workflow avoids long multimodal to text conversion times, overcomes information loss issues by doing on-demand query-specific extraction of details in multimodal data, and ensures high quality of responses to interactive user queries that are often not known apriori. To the best of our knowledge, iRAG is the first system to augment RAG with an incremental workflow to support efficient interactive querying of large, real-world multimodal data. Experimental results on real-world long videos demonstrate 23x to 25x faster video to text ingestion, while ensuring that quality of responses to interactive user queries is comparable to responses from a traditional RAG where all video data is converted to text upfront before any querying.",
    "pdf_link": "https://arxiv.org/abs/2404.12309",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.12309v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12309/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12309v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12309/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12309v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12309/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12309v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12309/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12309v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12309/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12309v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12309/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12309v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12309/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12309v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12309/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12309v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12309/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12309v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12309/iRAG_demo_black.png"
      }
    ],
    "abstract_cn": "检索增强生成（RAG）系统融合了语言生成与信息检索的长处，广泛应用于聊天机器人等实际应用。然而，利用 RAG 来综合解析文本、图像和视频等多模态数据虽具吸引力，却面临两大挑战：一是将大量多模态数据一次性转换为文本描述需要较长的处理时间；二是文本描述往往无法涵盖所有多模态数据中的信息。鉴于用户查询无法预先得知，构建一个能够将多模态数据转换为文本并进行交互式查询的系统颇具难度。为应对这些挑战，我们提出了 iRAG，这是一种新型的增量式工作流程，它扩展了 RAG 系统，使其能够交互式地查询大型多模态数据集。与传统 RAG 相比，iRAG 能够迅速索引庞大的多模态数据库，并在增量式工作流程中，根据需求从多模态数据的选定部分提取更多细节，以获取与用户交互查询相关的上下文。这种方法不仅避免了长时间的多模态到文本的转换，还通过按需提取多模态数据中的细节来解决信息丢失问题，并确保了对用户交互查询的响应质量。据我们所知，iRAG 是首个采用增量式工作流程来增强 RAG 系统，以支持对大型、真实世界多模态数据进行高效交互式查询的系统。在真实长视频上的实验结果显示，视频到文本的转换速度提升了 23 至 25 倍，同时保证了对交互式用户查询的响应质量与传统 RAG 系统相当，后者在任何查询之前都将所有视频数据转换为文本。",
    "title_cn": "iRAG：一种用于视频的渐进式检索增强生成系统",
    "tags": [
      "RAG",
      "聊天机器人",
      "多模态数据处理"
    ]
  },
  {
    "title": "Aligning Actions and Walking to LLM-Generated Textual Descriptions",
    "submit_datetime": "2024年04月18日",
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in various domains, including data augmentation and synthetic data generation. This work explores the use of LLMs to generate rich textual descriptions for motion sequences, encompassing both actions and walking patterns. We leverage the expressive power of LLMs to align motion representations with high-level linguistic cues, addressing two distinct tasks: action recognition and retrieval of walking sequences based on appearance attributes. For action recognition, we employ LLMs to generate textual descriptions of actions in the BABEL-60 dataset, facilitating the alignment of motion sequences with linguistic representations. In the domain of gait analysis, we investigate the impact of appearance attributes on walking patterns by generating textual descriptions of motion sequences from the DenseGait dataset using LLMs. These descriptions capture subtle variations in walking styles influenced by factors such as clothing choices and footwear. Our approach demonstrates the potential of LLMs in augmenting structured motion attributes and aligning multi-modal representations. The findings contribute to the advancement of comprehensive motion understanding and open up new avenues for leveraging LLMs in multi-modal alignment and data augmentation for motion analysis. We make the code publicly available at https://github.com/Radu1999/WalkAndText",
    "pdf_link": "https://arxiv.org/abs/2404.12192",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.12192v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12192/gaitclip-diagram.drawio.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12192v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12192/gaitclip-diagram2.drawio.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12192v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12192/GaitCLIP-annotation.drawio.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12192v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12192/features.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12192v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12192/classif.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12192v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12192/ndgc.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12192v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12192/per_feature.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）在多个领域展现了非凡的才能，尤其是在数据扩充和合成数据创造方面。本研究利用LLMs为运动序列生成详尽的文本描述，涉及动作和行走模式。我们借助LLMs的表达力，将运动信息与高级语言信号相结合，以应对两项特定任务：动作识别和基于外观特征的行走序列检索。在动作识别任务中，我们利用LLMs为BABEL-60数据集中的动作生成文本描述，以实现运动序列与语言描述的匹配。在步态分析方面，我们通过LLMs对DenseGait数据集中的行走序列进行文本描述，探究外观特征如衣着和鞋履对行走模式的影响。这些描述捕捉了行走风格中的微妙差异。我们的方法证明了LLMs在增强结构化运动特征和整合多模态表示方面的潜力。这些研究成果不仅推动了对运动理解的深入，也为未来在多模态同步和运动分析中应用LLMs提供了新的思路。相关代码已在 https://github.com/Radu1999/WalkAndText 上公开。",
    "title_cn": "将行动和行走与大型语言模型生成的文本描述相匹配。",
    "tags": [
      "LLM应用",
      "运动分析",
      "多模态学习"
    ]
  },
  {
    "title": "RAGAR, Your Falsehood RADAR: RAG-Augmented Reasoning for Political Fact-Checking using Multimodal Large Language Models",
    "submit_datetime": "2024年04月18日",
    "abstract": "The escalating challenge of misinformation, particularly in the context of political discourse, necessitates advanced solutions for fact-checking. We introduce innovative approaches to enhance the reliability and efficiency of multimodal fact-checking through the integration of Large Language Models (LLMs) with Retrieval-augmented Generation (RAG)- based advanced reasoning techniques. This work proposes two novel methodologies, Chain of RAG (CoRAG) and Tree of RAG (ToRAG). The approaches are designed to handle multimodal claims by reasoning the next questions that need to be answered based on previous evidence. Our approaches improve the accuracy of veracity predictions and the generation of explanations over the traditional fact-checking approach of sub-question generation with chain of thought veracity prediction. By employing multimodal LLMs adept at analyzing both text and images, this research advances the capability of automated systems in identifying and countering misinformation.",
    "pdf_link": "https://arxiv.org/abs/2404.12065",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.12065v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12065/FrontPagee.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12065v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12065/pipelinefc_new.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12065v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12065/figCoragTorag-2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12065v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12065/ratings_graph.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12065v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12065/annot.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12065v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12065/Question_Generation.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12065v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12065/QA_Elimination.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12065v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12065/Veracity_Prediction.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12065v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12065/ZSCOTPROMPT.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12065v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12065/CoVeFigure.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12065v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12065/Verification_Prompt.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12065v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12065/Correction_Prompt.png"
      }
    ],
    "abstract_cn": "面对政治话语中日益严峻的虚假信息挑战，迫切需要更先进的事实核查方案。本文介绍了一种创新方法，通过融合大型语言模型（LLMs）和基于检索增强生成（RAG）的高级推理技术，以提升多模态事实核查的可信度和效率。我们提出了两种新颖的方法论：RAG 链（CoRAG）和 RAG 树（ToRAG），旨在通过分析先前证据来推理出需要回答的后续问题，以处理多模态的声明。这些方法不仅提高了真实性预测的精确度，还增强了解释生成的能力，相较于传统基于子问题生成和思维链真实性预测的事实核查方法，表现更为出色。本研究通过运用能够分析文本和图像的多模态 LLMs，进一步推动了自动化系统在识别和抵御虚假信息方面的能力。",
    "title_cn": "RAGAR——您的虚假信息侦测雷达：通过增强的 RAG（Retrieval-Augmented Generation）推理，利用多模态大型语言模型进行政治事实核查。",
    "tags": [
      "分类：RAG",
      "政治话语分析",
      "信息安全"
    ]
  },
  {
    "title": "Exploring the landscape of large language models: Foundations, techniques, and challenges",
    "submit_datetime": "2024年04月18日",
    "abstract": "In this review paper, we delve into the realm of Large Language Models (LLMs), covering their foundational principles, diverse applications, and nuanced training processes. The article sheds light on the mechanics of in-context learning and a spectrum of fine-tuning approaches, with a special focus on methods that optimize efficiency in parameter usage. Additionally, it explores how LLMs can be more closely aligned with human preferences through innovative reinforcement learning frameworks and other novel methods that incorporate human feedback. The article also examines the emerging technique of retrieval augmented generation, integrating external knowledge into LLMs. The ethical dimensions of LLM deployment are discussed, underscoring the need for mindful and responsible application. Concluding with a perspective on future research trajectories, this review offers a succinct yet comprehensive overview of the current state and emerging trends in the evolving landscape of LLMs, serving as an insightful guide for both researchers and practitioners in artificial intelligence.",
    "pdf_link": "https://arxiv.org/abs/2404.11973",
    "graphs": [],
    "abstract_cn": "本文深入剖析了大型语言模型（LLMs）的奥秘，从基本原理到应用场景，再到精细的训练策略，逐一展开。文章详细阐释了上下文学习的原理和多种微调技术，尤其着重于那些提高参数使用效率的策略。同时，探讨了通过前沿的强化学习框架和创新方法，将人类反馈融入其中，以期使LLMs更好地符合人类的偏好。此外，还审视了检索增强生成技术，这项技术通过整合外部知识来丰富LLMs的能力。文中还涉及了LLMs应用的伦理问题，强调了审慎和负责的重要性。文章以对未来发展路径的展望作为结尾，为当前LLMs的发展现状和趋势提供了精炼而全面的概览，对于人工智能领域的研究者和从业者而言，是一份颇具洞见的指南。",
    "title_cn": "深入剖析大型语言模型的疆域：从基础理论到技术应用，再到面临的挑战。",
    "tags": [
      "LLM理论",
      "人工智能",
      ""
    ]
  },
  {
    "title": "From Language Models to Practical Self-Improving Computer Agents",
    "submit_datetime": "2024年04月18日",
    "abstract": "We develop a simple and straightforward methodology to create AI computer agents that can carry out diverse computer tasks and self-improve by developing tools and augmentations to enable themselves to solve increasingly complex tasks. As large language models (LLMs) have been shown to benefit from non-parametric augmentations, a significant body of recent work has focused on developing software that augments LLMs with various capabilities. Rather than manually developing static software to augment LLMs through human engineering effort, we propose that an LLM agent can systematically generate software to augment itself. We show, through a few case studies, that a minimal querying loop with appropriate prompt engineering allows an LLM to generate and use various augmentations, freely extending its own capabilities to carry out real-world computer tasks. Starting with only terminal access, we prompt an LLM agent to augment itself with retrieval, internet search, web navigation, and text editor capabilities. The agent effectively uses these various tools to solve problems including automated software development and web-based tasks.",
    "pdf_link": "https://arxiv.org/abs/2404.11964",
    "graphs": [],
    "abstract_cn": "我们构建了一种简洁明了的方法论，用以培育能够执行多种计算机操作并自我提升的人工智能计算机代理。这些代理通过自我开发工具和增强功能，能够解决日益复杂的任务。鉴于大型语言模型（LLMs）能从非参数化增强中获益，当前研究热点在于开发能够赋予LLMs多元能力的软件。我们提出，与其人工编写静态软件来增强LLMs，不如让LLM代理自动生成软件以自我增强。通过几个案例研究，我们证明了仅需一个基础的查询循环和精心设计的提示，LLM便能生成并利用各种增强功能，从而扩展其执行现实世界计算机任务的能力。从一个简单的终端访问权限出发，我们引导LLM代理自我增强，包括信息检索、网络搜索、网页浏览和文本编辑等能力。该代理能够灵活运用这些工具，有效解决自动化软件开发和网络相关任务。",
    "title_cn": "探索语言模型向实用的自我完善计算机代理的转变之路。",
    "tags": [
      "Agent",
      "人工智能",
      "软件开发"
    ]
  },
  {
    "title": "Spiral of Silences: How is Large Language Model Killing Information Retrieval? -- A Case Study on Open Domain Question Answering",
    "submit_datetime": "2024年04月18日",
    "abstract": "The practice of Retrieval-Augmented Generation (RAG), which integrates Large Language Models (LLMs) with retrieval systems, has become increasingly prevalent. However, the repercussions of LLM-derived content infiltrating the web and influencing the retrieval-generation feedback loop are largely uncharted territories. In this study, we construct and iteratively run a simulation pipeline to deeply investigate the short-term and long-term effects of LLM text on RAG systems. Taking the trending Open Domain Question Answering (ODQA) task as a point of entry, our findings reveal a potential digital \"Spiral of Silence\" effect, with LLM-generated text consistently outperforming human-authored content in search rankings, thereby diminishing the presence and impact of human contributions online. This trend risks creating an imbalanced information ecosystem, where the unchecked proliferation of erroneous LLM-generated content may result in the marginalization of accurate information. We urge the academic community to take heed of this potential issue, ensuring a diverse and authentic digital information landscape.",
    "pdf_link": "https://arxiv.org/abs/2404.10496",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.10496v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10496/pipeline.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10496v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10496/nq_sim.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10496v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10496/webq_sim.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10496v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10496/tqa_sim.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10496v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10496/pop_sim.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10496v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10496/nq_loop_retrieval.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10496v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10496/pop_loop_retrieval.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10496v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10496/nq_loop_qa.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10496v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10496/pop_loop_qa.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10496v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10496/percentage_nq.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10496v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10496/percentage_pop.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10496v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10496/nq_bleu.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10496v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10496/pop_bleu.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10496v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10496/context_nq.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10496v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10496/Overall_Average_Rank_Changes.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10496v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10496/Combined_Average_Ranks.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10496v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10496/webq_loop_retrieval.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10496v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10496/tqa_loop_retrieval.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10496v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10496/webq_loop_qa.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10496v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10496/tqa_loop_qa.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10496v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10496/percentage_webq.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10496v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10496/percentage_tqa.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10496v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10496/webq_bleu.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10496v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10496/tqa_bleu.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10496v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10496/mis_plot_nq_tsv.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10496v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10496/mis_plot_webq_tsv.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10496v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10496/mis_plot_tqa_tsv.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10496v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10496/mis_plot_pop_tsv.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10496v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10496/mis_context_nq.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10496v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10496/combined_qa_datasets.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10496v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10496/nq_filter_retrieval.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10496v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10496/webq_filter_retrieval.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10496v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10496/tqa_filter_retrieval.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10496v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10496/pop_filter_retrieval.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10496v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10496/nq_filter_qa.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10496v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10496/webq_filter_qa.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10496v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10496/tqa_filter_qa.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10496v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10496/pop_filter_qa.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10496v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10496/top5-plot_nq_tsv.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10496v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10496/top5-plot_nq-filter-bleu_tsv.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10496v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10496/top5-plot_nq-filter-source_tsv.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10496v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10496/filter_bleu_context_nq.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10496v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10496/filter_source_context_nq.png"
      }
    ],
    "abstract_cn": "检索增强生成（RAG）技术，通过将大型语言模型（LLMs）与检索系统相结合，正变得越来越流行。但LLM生成的内容如何影响网络生态和检索生成反馈回路，仍是一个较少被研究的新领域。本研究通过构建并迭代执行模拟流程，深入探讨了LLM文本对RAG系统影响的短期与长期效应。以当前热门的开放域问答（ODQA）任务为例，研究发现LLM生成的文本在搜索排名中屡屡超越人类创作，可能导致人类在线贡献的可见度和影响力降低，形成了一种潜在的数字“沉默螺旋”效应。这一趋势有可能导致信息生态失衡，错误信息的泛滥可能使准确信息被边缘化。我们呼吁学术界对此问题给予关注，以维护一个多元和真实的数字信息环境。",
    "title_cn": "沉默之螺旋：探究大型语言模型如何影响信息检索的效能——以开放领域问答为研究案例",
    "tags": [
      "分类：RAG",
      "网络生态",
      "信息检索"
    ]
  },
  {
    "title": "HalluciBot: Is There No Such Thing as a Bad Question?",
    "submit_datetime": "2024年04月18日",
    "abstract": "Hallucination continues to be one of the most critical challenges in the institutional adoption journey of Large Language Models (LLMs). In this context, an overwhelming number of studies have focused on analyzing the post-generation phase - refining outputs via feedback, analyzing logit output values, or deriving clues via the outputs' artifacts. We propose HalluciBot, a model that predicts the probability of hallucination $\\textbf{before generation}$, for any query imposed to an LLM. In essence, HalluciBot does not invoke any generation during inference. To derive empirical evidence for HalluciBot, we employ a Multi-Agent Monte Carlo Simulation using a Query Perturbator to craft $n$ variations per query at train time. The construction of our Query Perturbator is motivated by our introduction of a new definition of hallucination - $\\textit{truthful hallucination}$. Our training methodology generated 2,219,022 estimates for a training corpus of 369,837 queries, spanning 13 diverse datasets and 3 question-answering scenarios. HalluciBot predicts both binary and multi-class probabilities of hallucination, enabling a means to judge the query's quality with regards to its propensity to hallucinate. Therefore, HalluciBot paves the way to revise or cancel a query before generation and the ensuing computational waste. Moreover, it provides a lucid means to measure user accountability for hallucinatory queries.",
    "pdf_link": "https://arxiv.org/abs/2404.12535",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.12535v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12535/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12535v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12535/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12535v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12535/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12535v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12535/x4.png"
      }
    ],
    "abstract_cn": "幻觉在大型语言模型（LLMs）的机构采纳之路上依旧是一个重大挑战。在此背景下，众多研究致力于分析生成后阶段——无论是通过反馈优化结果、解析对数输出值，还是从输出特征中寻找线索。我们提出了HalluciBot，这是一个在向LLM提出任何查询之前就能预测幻觉概率的模型。实质上，HalluciBot在推理时不进行任何生成操作。为了验证HalluciBot的有效性，我们采用了多智能体蒙特卡洛模拟，并通过查询扰动器在训练阶段为每个查询生成n个变体。这一查询扰动器的设计灵感来源于我们对幻觉的新定义——“真实幻觉”。我们的训练方法针对一个包含369,837个查询的训练语料库，生成了2,219,022个估计值，覆盖了13个多样化的数据集和3种问答情境。HalluciBot能够预测幻觉的二元和多类概率，从而评估查询可能导致幻觉的风险。这使得HalluciBot能够在生成之前对查询进行修订或取消，避免了不必要的计算资源浪费。同时，它还提供了一种明确的方法来评估用户对可能导致幻觉的查询的责任。",
    "title_cn": "HalluciBot：世上真有所谓的“坏问题”吗？",
    "tags": [
      "LLM应用",
      "人工智能",
      ""
    ]
  },
  {
    "title": "mABC: multi-Agent Blockchain-Inspired Collaboration for root cause analysis in micro-services architecture",
    "submit_datetime": "2024年04月18日",
    "abstract": "The escalating complexity of micro-services architecture in cloud-native technologies poses significant challenges for maintaining system stability and efficiency. To conduct root cause analysis (RCA) and resolution of alert events, we propose a pioneering framework, multi-Agent Blockchain-inspired Collaboration for root cause analysis in micro-services architecture (mABC), to revolutionize the AI for IT operations (AIOps) domain, where multiple agents based on the powerful large language models (LLMs) perform blockchain-inspired voting to reach a final agreement following a standardized process for processing tasks and queries provided by Agent Workflow. Specifically, seven specialized agents derived from Agent Workflow each provide valuable insights towards root cause analysis based on their expertise and the intrinsic software knowledge of LLMs collaborating within a decentralized chain. To avoid potential instability issues in LLMs and fully leverage the transparent and egalitarian advantages inherent in a decentralized structure, mABC adopts a decision-making process inspired by blockchain governance principles while considering the contribution index and expertise index of each agent. Experimental results on the public benchmark AIOps challenge dataset and our created train-ticket dataset demonstrate superior performance in accurately identifying root causes and formulating effective solutions, compared to previous strong baselines. The ablation study further highlights the significance of each component within mABC, with Agent Workflow, multi-agent, and blockchain-inspired voting being crucial for achieving optimal performance. mABC offers a comprehensive automated root cause analysis and resolution in micro-services architecture and achieves a significant improvement in the AIOps domain compared to existing baselines",
    "pdf_link": "https://arxiv.org/abs/2404.12135",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.12135v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12135/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12135v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12135/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12135v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12135/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12135v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12135/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12135v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12135/x5.png"
      }
    ],
    "abstract_cn": "随着云原生技术中微服务架构的复杂性不断增加，维护系统的稳定性和效率变得越来越困难。为了深入分析问题根源并解决警报事件，我们提出了一个创新的框架——微服务架构根本原因分析的多代理区块链启发式协作（mABC），这一框架有望彻底改变AI运维（AIOps）领域。在这一框架中，多个基于先进的大型语言模型（LLMs）的代理通过区块链技术的投票机制，遵循标准化流程，共同处理由代理工作流提供的任务和查询，以达成共识。特别地，源自代理工作流的七位专业代理，依托其专业知识和LLMs的内在软件理解，为根本原因分析提供了独到的见解。mABC采用了区块链治理原则启发的决策流程，同时兼顾每位代理的贡献度和专业度，以避免LLMs的潜在不稳定因素，并充分利用去中心化结构的透明和公平优势。在公共AIOps挑战数据集和我们自行构建的火车票数据集上的实验结果显示，mABC在准确定位问题根源和制定有效解决方案方面，相较于传统方法有着显著的性能提升。进一步的消融研究强调了mABC中每个组成部分的重要性，其中代理工作流、多代理系统和区块链启发式投票对于实现最优性能至关重要。mABC为微服务架构提供了全面的自动化根本原因分析与解决方案，与现有技术相比，在AIOps领域实现了重大进步。",
    "title_cn": "mABC：一种受区块链启发的多代理协作机制，专为微服务架构中的根本原因分析而设计。",
    "tags": [
      "Agent",
      "云计算",
      "人工智能运维"
    ]
  },
  {
    "title": "Aligning Language Models to Explicitly Handle Ambiguity",
    "submit_datetime": "2024年04月18日",
    "abstract": "In spoken languages, utterances are often shaped to be incomplete or vague for efficiency. This can lead to varying interpretations of the same input, based on different assumptions about the context. To ensure reliable user-model interactions in such scenarios, it is crucial for models to adeptly handle the inherent ambiguity in user queries. However, conversational agents built upon even the most recent large language models (LLMs) face challenges in processing ambiguous inputs, primarily due to the following two hurdles: (1) LLMs are not directly trained to handle inputs that are too ambiguous to be properly managed; (2) the degree of ambiguity in an input can vary according to the intrinsic knowledge of the LLMs, which is difficult to investigate. To address these issues, this paper proposes a method to align LLMs to explicitly handle ambiguous inputs. Specifically, we introduce a proxy task that guides LLMs to utilize their intrinsic knowledge to self-disambiguate a given input. We quantify the information gain from the disambiguation procedure as a measure of the extent to which the models perceive their inputs as ambiguous. This measure serves as a cue for selecting samples deemed ambiguous from the models' perspectives, which are then utilized for alignment. Experimental results from several question-answering datasets demonstrate that the LLMs fine-tuned with our approach are capable of handling ambiguous inputs while still performing competitively on clear questions within the task.",
    "pdf_link": "https://arxiv.org/abs/2404.11972",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.11972v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11972/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11972v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11972/x2.png"
      }
    ],
    "abstract_cn": "在日常对话中，为了效率，人们常使语句显得简略或含糊，这可能导致基于不同上下文假设的多样化解读。在这样的情境下，模型必须巧妙地应对用户提问中的歧义，以保证用户与模型之间的可靠互动。但是，即使是基于最新大型语言模型（LLMs）的对话系统，在解析含糊信息时也遇到了难题，这主要归咎于两点：首先，LLMs 并未被专门训练来处理那些过于含糊、难以有效管理的输入；其次，输入的含糊性会根据 LLMs 内在的知识水平而异，这使得问题的探究变得复杂。为了应对这些挑战，本文提出了一种方法，让 LLMs 能够明确地处理含糊的输入。具体而言，我们设计了一个代理任务，促使 LLMs 运用其内在的知识来自动消除输入信息的歧义。我们通过量化消歧过程中的信息增益，来衡量模型对输入歧义性的感知程度。这一衡量标准帮助我们从模型的视角筛选出那些被认为是含糊的样本，进而用于模型的优化。多个问答数据集的实验结果显示，采用我们方法进行微调的 LLMs 在处理含糊输入时表现出色，同时在处理明确问题时也保持了竞争力。",
    "title_cn": "调整语言模型以明确解决歧义问题",
    "tags": [
      "分类：LLM应用",
      "对话系统",
      ""
    ]
  },
  {
    "title": "AgentCoord: Visually Exploring Coordination Strategy for LLM-based Multi-Agent Collaboration",
    "submit_datetime": "2024年04月18日",
    "abstract": "The potential of automatic task-solving through Large Language Model (LLM)-based multi-agent collaboration has recently garnered widespread attention from both the research community and industry. While utilizing natural language to coordinate multiple agents presents a promising avenue for democratizing agent technology for general users, designing coordination strategies remains challenging with existing coordination frameworks. This difficulty stems from the inherent ambiguity of natural language for specifying the collaboration process and the significant cognitive effort required to extract crucial information (e.g. agent relationship, task dependency, result correspondence) from a vast amount of text-form content during exploration. In this work, we present a visual exploration framework to facilitate the design of coordination strategies in multi-agent collaboration. We first establish a structured representation for LLM-based multi-agent coordination strategy to regularize the ambiguity of natural language. Based on this structure, we devise a three-stage generation method that leverages LLMs to convert a user's general goal into an executable initial coordination strategy. Users can further intervene at any stage of the generation process, utilizing LLMs and a set of interactions to explore alternative strategies. Whenever a satisfactory strategy is identified, users can commence the collaboration and examine the visually enhanced execution result. We develop AgentCoord, a prototype interactive system, and conduct a formal user study to demonstrate the feasibility and effectiveness of our approach.",
    "pdf_link": "https://arxiv.org/abs/2404.11943",
    "graphs": [],
    "abstract_cn": "最近，利用大型语言模型（LLM）驱动的多代理协同来自动化解决任务引起了学术界和产业界的广泛关注。使用自然语言协调众多代理虽然为广大用户普及代理技术开辟了道路，但现有的协调框架在设计策略时仍面临挑战。这些挑战主要来自于自然语言在明确指定协作流程时的模糊性，以及在探索过程中从大量文本内容中提取关键信息（如代理间关系、任务依赖、结果对应）所需的巨大认知劳动。为此，我们提出了一个视觉探索框架，旨在简化多代理协同中的协调策略设计。我们首先为基于LLM的多代理协调策略创建了一个结构化表达，以减少自然语言的歧义。在此基础上，我们开发了一种三阶段的生成方法，该方法使用LLM将用户的总体目标转换为可执行的初始协调策略。用户可以在生成过程的任何阶段进行干预，通过LLM和一系列交互来探索不同的策略。一旦找到满意的策略，用户即可启动协作并查看视觉增强的执行结果。我们构建了一个名为AgentCoord的原型互动系统，并通过正式的用户研究展示了我们方法的可行性和有效性。",
    "title_cn": "AgentCoord：视觉探索基于大型语言模型的多智能体协作的协调策略",
    "tags": [
      "Agent",
      "人工智能",
      "自动化"
    ]
  },
  {
    "title": "Octopus v3: Technical Report for On-device Sub-billion Multimodal AI Agent",
    "submit_datetime": "2024年04月18日",
    "abstract": "A multimodal AI agent is characterized by its ability to process and learn from various types of data, including natural language, visual, and audio inputs, to inform its actions. Despite advancements in large language models that incorporate visual data, such as GPT-4V, effectively translating image-based data into actionable outcomes for AI agents continues to be challenging. In this paper, we introduce a multimodal model that incorporates the concept of functional token specifically designed for AI agent applications. To ensure compatibility with edge devices, our model is optimized to a compact size of less than 1B parameters. Like GPT-4, our model can process both English and Chinese. We demonstrate that this model is capable of operating efficiently on a wide range of edge devices, including as constrained as a Raspberry Pi.",
    "pdf_link": "https://arxiv.org/abs/2404.11459",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.11459v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11459/x1.png"
      }
    ],
    "abstract_cn": "多模态AI代理擅长处理和学习多种数据类型，如自然语言、视觉和音频输入，以指导其行为。尽管大型语言模型在整合视觉信息方面取得了进展，例如GPT-4V，但将图像数据转化为AI代理的可执行结果仍然充满挑战。本文提出了一个专为AI代理应用设计的多模态模型，引入了功能性标记的概念。为适应边缘设备，该模型被精简至不到10亿参数。与GPT-4相似，它支持英文和中文处理。我们展示了该模型在多种边缘设备上的高效运行能力，即便是在资源受限如树莓派这样的设备上。",
    "title_cn": "章鱼 v3：设备端亿级以下多模态人工智能代理技术报告",
    "tags": [
      "Agent",
      "AI代理",
      "边缘计算"
    ]
  },
  {
    "title": "MedThink: Explaining Medical Visual Question Answering via Multimodal Decision-Making Rationale",
    "submit_datetime": "2024年04月18日",
    "abstract": "Medical Visual Question Answering (MedVQA), which offers language responses to image-based medical inquiries, represents a challenging task and significant advancement in healthcare. It assists medical experts to swiftly interpret medical images, thereby enabling faster and more accurate diagnoses. However, the model interpretability and transparency of existing MedVQA solutions are often limited, posing challenges in understanding their decision-making processes. To address this issue, we devise a semi-automated annotation process to streamlining data preparation and build new benchmark MedVQA datasets R-RAD and R-SLAKE. The R-RAD and R-SLAKE datasets provide intermediate medical decision-making rationales generated by multimodal large language models and human annotations for question-answering pairs in existing MedVQA datasets, i.e., VQA-RAD and SLAKE. Moreover, we design a novel framework which finetunes lightweight pretrained generative models by incorporating medical decision-making rationales into the training process. The framework includes three distinct strategies to generate decision outcomes and corresponding rationales, thereby clearly showcasing the medical decision-making process during reasoning. Extensive experiments demonstrate that our method can achieve an accuracy of 83.5% on R-RAD and 86.3% on R-SLAKE, significantly outperforming existing state-of-the-art baselines. Dataset and code will be released.",
    "pdf_link": "https://arxiv.org/abs/2404.12372",
    "graphs": [],
    "abstract_cn": "医学视觉问答（MedVQA）是一项前沿的医疗任务，它通过语言回答来解析医学图像，极大提升了医疗诊断的速度和准确性。尽管如此，现有 MedVQA 系统的模型透明度和可解释性不足，这限制了对其决策机制的理解。为克服这一难题，我们引入了一种半自动化的标注流程，以优化数据准备，并开发了两个新的基准数据集：R-RAD 和 R-SLAKE。这两个数据集不仅包含了由多模态大型语言模型和人工标注生成的医学决策理由，还涵盖了现有 MedVQA 数据集（VQA-RAD 和 SLAKE）中的问题-答案对。此外，我们构建了一个创新框架，它通过整合医学决策理由来微调轻量级预训练生成模型。该框架采用三种策略来生成决策结果及其理由，清晰地揭示了推理过程中的医学决策流程。实验结果表明，我们的模型在 R-RAD 数据集上达到了 83.5% 的准确率，在 R-SLAKE 数据集上达到了 86.3% 的准确率，均显著超过了当前的最佳水平。相关数据集和代码将向公众开放。",
    "title_cn": "MedThink：揭示医学视觉问答背后的多模决策机制",
    "tags": [
      "分类：LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "V2Xum-LLM: Cross-Modal Video Summarization with Temporal Prompt Instruction Tuning",
    "submit_datetime": "2024年04月18日",
    "abstract": "Video summarization aims to create short, accurate, and cohesive summaries of longer videos. Despite the existence of various video summarization datasets, a notable limitation is their limited amount of source videos, which hampers the effective fine-tuning of advanced large vision-language models (VLMs). Additionally, most existing datasets are created for video-to-video summarization, overlooking the contemporary need for multimodal video content summarization. Recent efforts have been made to expand from unimodal to multimodal video summarization, categorizing the task into three sub-tasks based on the summary's modality: video-to-video (V2V), video-to-text (V2T), and a combination of video and text summarization (V2VT). However, the textual summaries in previous multimodal datasets are inadequate. To address these issues, we introduce Instruct-V2Xum, a cross-modal video summarization dataset featuring 30,000 diverse videos sourced from YouTube, with lengths ranging from 40 to 940 seconds and an average summarization ratio of 16.39\\%. Each video summary in Instruct-V2Xum is paired with a textual summary that references specific frame indexes, facilitating the generation of aligned video and textual summaries. In addition, we propose a new video summarization framework named V2Xum-LLM. V2Xum-LLM, specifically V2Xum-LLaMA in this study, is the first framework that unifies different video summarization tasks into one large language model's (LLM) text decoder and achieves task-controllable video summarization with temporal prompts and task instructions. Experiments show that V2Xum-LLaMA outperforms strong baseline models on multiple video summarization tasks. Furthermore, we propose an enhanced evaluation metric for V2V and V2VT summarization tasks.",
    "pdf_link": "https://arxiv.org/abs/2404.12353",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.12353v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12353/teaser.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12353v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12353/sankey.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12353v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12353/model.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12353v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12353/vera.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12353v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12353/grammar.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12353v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12353/sample0.png"
      }
    ],
    "abstract_cn": "视频摘要的目的是为长视频制作简短、精确且连贯的概述。尽管众多视频摘要数据集已经出现，但它们的一个明显短板是源视频数量不足，这限制了高级大型视觉-语言模型（VLMs）的有效微调。而且，大多数现有数据集都是为视频到视频摘要设计的，忽略了对多模态视频内容摘要的现代需求。近期，人们已经开始尝试从单模态向多模态视频摘要转变，将任务分为三个子任务：视频到视频（V2V）、视频到文本（V2T）以及视频和文本结合摘要（V2VT）。但是，以往的多模态数据集在文本摘要方面还不够完善。为了应对这些挑战，我们推出了Instruct-V2Xum，这是一个包含30,000个多样化视频的跨模态视频摘要数据集，这些视频源自YouTube，时长介于40至940秒之间，平均摘要率为16.39%。Instruct-V2Xum的每个视频摘要都与一个引用特定帧索引的文本摘要配对，这有助于生成同步的视频和文本摘要。此外，我们提出了一个名为V2Xum-LLM的新视频摘要框架。在本研究中，特别是V2Xum-LLaMA，是首个将不同视频摘要任务整合到一个大型语言模型（LLM）的文本解码器中，并利用时间提示和任务指令实现可控制的视频摘要任务的框架。实验结果表明，V2Xum-LLaMA在多个视频摘要任务上超越了强大的基线模型。而且，我们还为V2V和V2VT摘要任务提出了一个改进的评估指标。",
    "title_cn": "V2Xum-LLM：利用时间提示指令优化的跨模态视频摘要技术",
    "tags": [
      "LLM应用",
      "视频摘要",
      "多模态学习"
    ]
  },
  {
    "title": "Sequential Compositional Generalization in Multimodal Models",
    "submit_datetime": "2024年04月18日",
    "abstract": "The rise of large-scale multimodal models has paved the pathway for groundbreaking advances in generative modeling and reasoning, unlocking transformative applications in a variety of complex tasks. However, a pressing question that remains is their genuine capability for stronger forms of generalization, which has been largely underexplored in the multimodal setting. Our study aims to address this by examining sequential compositional generalization using \\textsc{CompAct} (\\underline{Comp}ositional \\underline{Act}ivities)\\footnote{Project Page: \\url{http://cyberiada.github.io/CompAct}}, a carefully constructed, perceptually grounded dataset set within a rich backdrop of egocentric kitchen activity videos. Each instance in our dataset is represented with a combination of raw video footage, naturally occurring sound, and crowd-sourced step-by-step descriptions. More importantly, our setup ensures that the individual concepts are consistently distributed across training and evaluation sets, while their compositions are novel in the evaluation set. We conduct a comprehensive assessment of several unimodal and multimodal models. Our findings reveal that bi-modal and tri-modal models exhibit a clear edge over their text-only counterparts. This highlights the importance of multimodality while charting a trajectory for future research in this domain.",
    "pdf_link": "https://arxiv.org/abs/2404.12013",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.12013v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12013/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12013v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12013/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12013v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12013/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12013v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12013/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12013v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12013/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12013v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12013/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12013v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12013/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12013v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12013/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12013v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12013/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12013v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12013/audio-rinse.png"
      },
      {
        "url": "https://arxiv.org/html/2404.12013v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.12013/vision-fridge.png"
      }
    ],
    "abstract_cn": "大规模多模态模型的发展为生成建模和推理带来了革命性的进步，推动了复杂任务的创新应用。但一个关键问题尚未充分探讨：这些模型在更高级泛化能力上的真实表现如何。本研究通过分析 \\textsc{CompAct} 数据集——一个在自我中心厨房活动视频背景下精心构建、感知基础的数据集——来探讨顺序组合泛化问题。该数据集的每个案例都结合了原始视频、自然声音和众包的分步描述。我们的实验设计确保了训练集和测试集中概念的一致性，同时在测试集中引入了新颖的组合。我们对单模态和多模态模型进行了深入评估，发现双模态和三模态模型在性能上明显超越了纯文本模型。这一发现不仅凸显了多模态输入的重要性，也为未来研究方向提供了新的思路。",
    "title_cn": "多模态模型中的顺序组合性泛化",
    "tags": [
      "分类：LLM应用\n\n这篇论文探讨了大规模多模态模型在生成建模和推理方面的进步，并分析了这些模型在更高级泛化能力上的真实表现。通过使用一个精心构建的数据集，研究了顺序组合泛化问题，并对比了单模态和多模态模型的性能。这篇论文的重点是评估和改进多模态模型在特定任务上的应用，因此它属于LLM应用类别。",
      "计算机视觉",
      "人工智能"
    ]
  },
  {
    "title": "Deep and Dynamic Metabolic and Structural Imaging in Living Tissues",
    "submit_datetime": "2024年04月18日",
    "abstract": "Label-free imaging through two-photon autofluorescence (2PAF) of NAD(P)H allows for non-destructive and high-resolution visualization of cellular activities in living systems. However, its application to thick tissues and organoids has been restricted by its limited penetration depth within 300 $μ$m, largely due to tissue scattering at the typical excitation wavelength (~750 nm) required for NAD(P)H. Here, we demonstrate that the imaging depth for NAD(P)H can be extended to over 700 $μ$m in living engineered human multicellular microtissues by adopting multimode fiber (MMF)-based low-repetition-rate high-peak-power three-photon (3P) excitation of NAD(P)H at 1100 nm. This is achieved by having over 0.5 MW peak power at the band of 1100$\\pm$25 nm through adaptively modulating multimodal nonlinear pulse propagation with a compact fiber shaper. Moreover, the 8-fold increase in pulse energy at 1100 nm enables faster imaging of monocyte behaviors in the living multicellular models. These results represent a significant advance for deep and dynamic metabolic and structural imaging of intact living biosystems. The modular design (MMF with a slip-on fiber shaper) is anticipated to allow wide adoption of this methodology for demanding in vivo and in vitro imaging applications, including cancer research, autoimmune diseases, and tissue engineering.",
    "pdf_link": "https://arxiv.org/abs/2404.11901",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.11901v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11901/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11901v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11901/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11901v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11901/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11901v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11901/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11901v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11901/x5.png"
      }
    ],
    "abstract_cn": "利用两光子自发荧光技术观察NAD(P)H，我们能够在活体系统中对细胞活动进行无损且高分辨率的成像。尽管如此，由于组织对约750纳米激发波长的散射，该技术在厚组织和类器官中的应用受到了穿透深度仅300微米的限制。本研究突破性地展示了，通过采用多模光纤（MMF）基低重复率、高峰值功率的三次光子（3P）技术，在1100纳米激发NAD(P)H，将成像深度提升至超过700微米。这一成就是通过对1100±25纳米波段的脉冲能量进行自适应调制，实现超过0.5兆瓦的峰值功率，并通过紧凑的光纤整形器精确控制。此外，1100纳米处脉冲能量的八倍提升，加快了活体多细胞模型中单个单核细胞行为的成像速度。这些成果为深入和动态地观察完整活体生物系统的代谢和结构提供了重大进步。预计这种模块化设计（结合滑动式光纤整形器的MMF）将促进这一方法在体内外成像应用中的广泛应用，包括癌症研究、自身免疫疾病和组织工程等领域。",
    "title_cn": "活体组织中的深度与动态代谢及结构成像技术。",
    "tags": [
      "分类：Agent\n\n这篇论文讨论了一种新的成像技术，通过使用多模光纤（MMF）基低重复率、高峰值功率的三次光子（3P）技术，在1100纳米激发NAD(P)H，将成像深度提升至超过700微米。这项技术可以用于观察活体生物系统的代谢和结构，具有广泛的应用前景，如癌症研究、自身免疫疾病和组织工程等领域。由于这项技术涉及到对活体系统的无损且高分辨率成像，它更像是一个Agent，用于观察和研究生物系统。",
      "生物医学成像",
      "细胞生物学"
    ]
  },
  {
    "title": "Large Language Model based Multi-Agents: A Survey of Progress and Challenges",
    "submit_datetime": "2024年04月18日",
    "abstract": "Large Language Models (LLMs) have achieved remarkable success across a wide array of tasks. Due to the impressive planning and reasoning abilities of LLMs, they have been used as autonomous agents to do many tasks automatically. Recently, based on the development of using one LLM as a single planning or decision-making agent, LLM-based multi-agent systems have achieved considerable progress in complex problem-solving and world simulation. To provide the community with an overview of this dynamic field, we present this survey to offer an in-depth discussion on the essential aspects of multi-agent systems based on LLMs, as well as the challenges. Our goal is for readers to gain substantial insights on the following questions: What domains and environments do LLM-based multi-agents simulate? How are these agents profiled and how do they communicate? What mechanisms contribute to the growth of agents' capacities? For those interested in delving into this field of study, we also summarize the commonly used datasets or benchmarks for them to have convenient access. To keep researchers updated on the latest studies, we maintain an open-source GitHub repository, dedicated to outlining the research on LLM-based multi-agent systems.",
    "pdf_link": "https://arxiv.org/abs/2402.01680",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2402.01680v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.01680/trend_example.png"
      },
      {
        "url": "https://arxiv.org/html/2402.01680v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.01680/LLM-MA.png"
      },
      {
        "url": "https://arxiv.org/html/2402.01680v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.01680/Agent_communication.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）在众多任务上取得了卓越成就。凭借其卓越的规划和推理能力，LLMs 被广泛用作自动化任务的自主智能体。最近，基于单一 LLM 作为规划或决策智能体的多智能体系统，在解决复杂问题和模拟世界构建方面取得了显著进步。为了向学术界提供一个全面的视角，我们提供了这篇综述，深入探讨了基于 LLM 的多智能体系统的核心要素及其面临的挑战。我们希望读者能够对以下问题有更深刻的理解：基于 LLM 的多智能体模拟了哪些领域和环境？这些智能体如何被定义，它们之间如何交流？是什么机制推动了智能体能力的提升？对于渴望深入这一研究领域的学者，我们还汇总了常用的数据集和基准测试，以便他们能够轻松获取。为了使研究人员能够及时了解最新的研究成果，我们维护了一个开源的 GitHub 仓库，专门用于追踪基于 LLM 的多智能体系统的研究进展。",
    "title_cn": "大型语言模型驱动的多智能体研究：进展与挑战综述",
    "tags": [
      "Agent",
      "人工智能",
      "自动化"
    ]
  },
  {
    "title": "Characterizing LLM Abstention Behavior in Science QA with Context Perturbations",
    "submit_datetime": "2024年04月18日",
    "abstract": "The correct model response in the face of uncertainty is to abstain from answering a question so as not to mislead the user. In this work, we study the ability of LLMs to abstain from answering context-dependent science questions when provided insufficient or incorrect context. We probe model sensitivity in several settings: removing gold context, replacing gold context with irrelevant context, and providing additional context beyond what is given. In experiments on four QA datasets with four LLMs, we show that performance varies greatly across models, across the type of context provided, and also by question type; in particular, many LLMs seem unable to abstain from answering boolean questions using standard QA prompts. Our analysis also highlights the unexpected impact of abstention performance on QA task accuracy. Counter-intuitively, in some settings, replacing gold context with irrelevant context or adding irrelevant context to gold context can improve abstention performance in a way that results in improvements in task performance. Our results imply that changes are needed in QA dataset design and evaluation to more effectively assess the correctness and downstream impacts of model abstention.",
    "pdf_link": "https://arxiv.org/abs/2404.12452",
    "graphs": [],
    "abstract_cn": "在不确定性面前，模型应选择不回答问题，以防误导用户。本研究探讨了大型语言模型（LLMs）在面对不完整或错误上下文时，能否拒绝回答与上下文相关的科学问题。我们通过多种情境测试了模型的敏感度：去除正确上下文、用无关上下文替代、以及在已有上下文之外增加额外信息。在四个问答（QA）数据集的实验中，我们发现不同模型、不同类型的上下文提供方式，以及问题类型的不同，都会导致性能的显著差异；特别是，许多LLMs在标准问答提示下似乎无法避免回答布尔类型的问题。此外，我们的分析还揭示了放弃回答对问答任务准确度的意外影响。有趣的是，在某些情况下，用无关上下文替换或增加到正确上下文中，可以提升放弃回答的表现，进而提高任务的整体性能。这些发现指出，问答数据集的设计和评估需要改进，以便更有效地评估模型放弃回答的准确性及其对下游任务的影响。",
    "title_cn": "本文通过上下文扰动的方法，探讨了在科学问答领域中大型语言模型的弃权行为特征。",
    "tags": [
      "LLM理论",
      "问答系统",
      "科学教育"
    ]
  },
  {
    "title": "Improving Automated Distractor Generation for Math Multiple-choice Questions with Overgenerate-and-rank",
    "submit_datetime": "2024年04月18日",
    "abstract": "Multiple-choice questions (MCQs) are commonly used across all levels of math education since they can be deployed and graded at a large scale. A critical component of MCQs is the distractors, i.e., incorrect answers crafted to reflect student errors or misconceptions. Automatically generating them in math MCQs, e.g., with large language models, has been challenging. In this work, we propose a novel method to enhance the quality of generated distractors through overgenerate-and-rank, training a ranking model to predict how likely distractors are to be selected by real students. Experimental results on a real-world dataset and human evaluation with math teachers show that our ranking model increases alignment with human-authored distractors, although human-authored ones are still preferred over generated ones.",
    "pdf_link": "https://arxiv.org/abs/2405.05144",
    "graphs": [],
    "abstract_cn": "多选题因其便于大规模评分和应用而在数学教育中广泛使用，其关键在于精心设计的干扰项，旨在模拟学生的常见错误。然而，自动生成数学题的干扰项一直颇具挑战。本研究提出一种创新方法，通过大量生成并利用排名模型筛选，该模型能预测学生选择干扰项的可能性。实验与教师评估均显示，我们的方法虽提升了生成干扰项与人工编写的相似度，但人工编写的干扰项仍更受青睐。",
    "title_cn": "借助Overgenerate-and-rank策略，我们优化了数学多项选择题的自动干扰项生成，提升了题目的质量和难度。",
    "tags": [
      "Agent\n\n理由：这篇论文主要探讨了自动生成数学题的干扰项的方法，并利用排名模型来筛选生成的干扰项。这个过程涉及到创建一个能够生成和评估干扰项的系统，这可以被视为一个智能代理（Agent）的行为，因为它在执行任务（生成和评估干扰项）时需要做出决策和预测。因此，这篇论文更符合Agent分类，而不是RAG、LLM应用或LLM理论，因为它不直接涉及检索增强生成（RAG）、大型语言模型（LLM）的应用或理论研究。",
      "数学教育",
      "自动出题系统"
    ]
  },
  {
    "title": "Retrieval-Augmented Embodied Agents",
    "submit_datetime": "2024年04月17日",
    "abstract": "Embodied agents operating in complex and uncertain environments face considerable challenges. While some advanced agents handle complex manipulation tasks with proficiency, their success often hinges on extensive training data to develop their capabilities. In contrast, humans typically rely on recalling past experiences and analogous situations to solve new problems. Aiming to emulate this human approach in robotics, we introduce the Retrieval-Augmented Embodied Agent (RAEA). This innovative system equips robots with a form of shared memory, significantly enhancing their performance. Our approach integrates a policy retriever, allowing robots to access relevant strategies from an external policy memory bank based on multi-modal inputs. Additionally, a policy generator is employed to assimilate these strategies into the learning process, enabling robots to formulate effective responses to tasks. Extensive testing of RAEA in both simulated and real-world scenarios demonstrates its superior performance over traditional methods, representing a major leap forward in robotic technology.",
    "pdf_link": "https://arxiv.org/abs/2404.11699",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.11699v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11699/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11699v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11699/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11699v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11699/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11699v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11699/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11699v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11699/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11699v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11699/x6.png"
      }
    ],
    "abstract_cn": "具身代理在复杂且不确定的环境中运作，面临巨大挑战。尽管部分高级代理能够熟练地执行复杂操作，但其成功往往建立在大量训练数据之上。相较之下，人类通常依靠回忆过往经历和类似情境来应对新问题。为了在机器人技术中模拟人类的这种解决问题的方式，我们提出了检索增强型具身代理（RAEA）。这一创新系统赋予机器人共享记忆，显著提升了它们的性能。我们的方案结合了策略检索器，使机器人能够根据多模态输入从外部策略库中检索相关策略。同时，策略生成器的引入使得机器人能够将这些策略整合到学习过程中，从而有效应对各种任务。RAEA在模拟环境和现实世界中的广泛测试显示，其性能超越了传统方法，标志着机器人技术的一大飞跃。",
    "title_cn": "增强检索的具身智能体",
    "tags": [
      "Agent",
      "机器人技术",
      "人工智能"
    ]
  },
  {
    "title": "MemLLM: Finetuning LLMs to Use An Explicit Read-Write Memory",
    "submit_datetime": "2024年04月17日",
    "abstract": "While current large language models (LLMs) demonstrate some capabilities in knowledge-intensive tasks, they are limited by relying on their parameters as an implicit storage mechanism. As a result, they struggle with infrequent knowledge and temporal degradation. In addition, the uninterpretable nature of parametric memorization makes it challenging to understand and prevent hallucination. Parametric memory pools and model editing are only partial solutions. Retrieval Augmented Generation (RAG) $\\unicode{x2013}$ though non-parametric $\\unicode{x2013}$ has its own limitations: it lacks structure, complicates interpretability and makes it hard to effectively manage stored knowledge. In this paper, we introduce MemLLM, a novel method of enhancing LLMs by integrating a structured and explicit read-and-write memory module. MemLLM tackles the aforementioned challenges by enabling dynamic interaction with the memory and improving the LLM's capabilities in using stored knowledge. Our experiments indicate that MemLLM enhances the LLM's performance and interpretability, in language modeling in general and knowledge-intensive tasks in particular. We see MemLLM as an important step towards making LLMs more grounded and factual through memory augmentation.",
    "pdf_link": "https://arxiv.org/abs/2404.11672",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.11672v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11672/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11672v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11672/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11672v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11672/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11672v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11672/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11672v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11672/x5.png"
      }
    ],
    "abstract_cn": "尽管现有的大型语言模型在知识密集型任务上展现了一定的潜力，但它们依赖于参数作为隐式存储机制，这限制了它们应对罕见知识和时间衰减的能力。参数记忆的不透明性也使得防止幻觉的发生变得困难。虽然参数记忆库和模型编辑提供了部分解决方案，但检索增强生成（RAG）作为一种非参数方法，也存在结构缺失、解释性复杂和知识管理困难等问题。本文提出了MemLLM，这是一种创新的方法，通过整合一个结构化且明确的读写记忆模块来提升LLMs的性能。MemLLM通过动态与记忆模块交互，增强了LLMs利用存储知识的能力，有效应对了前述挑战。实验结果证明，MemLLM不仅提升了LLMs在语言建模方面的性能，也增强了其在知识密集型任务中的可解释性。我们视MemLLM为推动LLMs通过记忆增强变得更加贴近实际和事实基础的重要进展。",
    "title_cn": "MemLLM：为大型语言模型（LLM）定制优化，引入外显的读写记忆功能。",
    "tags": [
      "LLM理论",
      "人工智能",
      "知识管理"
    ]
  },
  {
    "title": "Position Engineering: Boosting Large Language Models through Positional Information Manipulation",
    "submit_datetime": "2024年04月17日",
    "abstract": "The performance of large language models (LLMs) is significantly influenced by the quality of the prompts provided. In response, researchers have developed enormous prompt engineering strategies aimed at modifying the prompt text to enhance task performance. In this paper, we introduce a novel technique termed position engineering, which offers a more efficient way to guide large language models. Unlike prompt engineering, which requires substantial effort to modify the text provided to LLMs, position engineering merely involves altering the positional information in the prompt without modifying the text itself. We have evaluated position engineering in two widely-used LLM scenarios: retrieval-augmented generation (RAG) and in-context learning (ICL). Our findings show that position engineering substantially improves upon the baseline in both cases. Position engineering thus represents a promising new strategy for exploiting the capabilities of large language models.",
    "pdf_link": "https://arxiv.org/abs/2404.11216",
    "graphs": [],
    "abstract_cn": "大型语言模型的表现在很大程度上取决于所提供的提示质量。为此，研究者们设计了众多的提示工程策略，目的是通过调整提示文本来优化任务执行效果。本文提出了一种创新技术——位置工程，它以一种更为高效的方式引导大型语言模型。与需要大量修改LLM提示文本的提示工程相比，位置工程只需调整提示中的位置信息，而无需改动文本内容。我们在两个广泛应用的LLM场景——检索增强生成（RAG）和上下文学习（ICL）中，对位置工程进行了评估。评估结果显示，位置工程在这两种场景下均显著提升了性能基线。因此，位置工程成为了一种充满潜力的新策略，用于充分发挥大型语言模型的潜力。",
    "title_cn": "位置工程：通过巧妙操控位置信息，增强大型语言模型的性能",
    "tags": [
      "LLM应用",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Open-Ended Wargames with Large Language Models",
    "submit_datetime": "2024年04月17日",
    "abstract": "Wargames are a powerful tool for understanding and rehearsing real-world decision making. Automated play of wargames using artificial intelligence (AI) enables possibilities beyond those of human-conducted games, such as playing the game many times over to see a range of possible outcomes. There are two categories of wargames: quantitative games, with discrete types of moves, and qualitative games, which revolve around open-ended responses. Historically, automation efforts have focused on quantitative games, but large language models (LLMs) make it possible to automate qualitative wargames. We introduce \"Snow Globe,\" an LLM-powered multi-agent system for playing qualitative wargames. With Snow Globe, every stage of a text-based qualitative wargame from scenario preparation to post-game analysis can be optionally carried out by AI, humans, or a combination thereof. We describe its software architecture conceptually and release an open-source implementation alongside this publication. As case studies, we simulate a tabletop exercise about an AI incident response and a political wargame about a geopolitical crisis. We discuss potential applications of the approach and how it fits into the broader wargaming ecosystem.",
    "pdf_link": "https://arxiv.org/abs/2404.11446",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.11446v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11446/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11446v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11446/x2.png"
      }
    ],
    "abstract_cn": "兵棋推演作为一种强有力的工具，能够帮助我们深入理解和模拟现实世界的决策过程。借助人工智能，兵棋推演能够实现超越人类对战的多种可能性，比如通过重复游戏来探索各种可能的结果。兵棋推演主要分为定量型和定性型两种，前者的走法类型是离散的，而后者则更侧重于开放式的回答。过去，自动化技术主要应用于定量型兵棋推演，但现在，大型语言模型（LLMs）的出现让定性型兵棋推演的自动化成为现实。我们推出了“Snow Globe”，这是一个基于LLM的多智能体系统，专门用于进行定性兵棋推演。使用Snow Globe，从情景设定到战后分析的每一步，都可以由人工智能、人类或两者协作完成。我们在概念上阐述了其软件架构，并随着本文的发布，提供了一个开源的实现版本。通过两个案例研究——一次关于AI应急响应的桌面演练和一次围绕地缘政治危机的政治兵棋推演——我们展示了这种方法的应用潜力，并探讨了它在整个兵棋推演生态系统中的定位。",
    "title_cn": "与大型语言模型进行的开放式战争模拟游戏",
    "tags": [
      "Agent",
      "兵棋推演",
      "人工智能"
    ]
  },
  {
    "title": "From Image to Video, what do we need in multimodal LLMs?",
    "submit_datetime": "2024年04月17日",
    "abstract": "Multimodal Large Language Models (MLLMs) have demonstrated profound capabilities in understanding multimodal information, covering from Image LLMs to the more complex Video LLMs. Numerous studies have illustrated their exceptional cross-modal comprehension. Recently, integrating video foundation models with large language models to build a comprehensive video understanding system has been proposed to overcome the limitations of specific pre-defined vision tasks. However, the current advancements in Video LLMs tend to overlook the foundational contributions of Image LLMs, often opting for more complicated structures and a wide variety of multimodal data for pre-training. This approach significantly increases the costs associated with these methods.In response to these challenges, this work introduces an efficient method that strategically leverages the priors of Image LLMs, facilitating a resource-efficient transition from Image to Video LLMs. We propose RED-VILLM, a Resource-Efficient Development pipeline for Video LLMs from Image LLMs, which utilizes a temporal adaptation plug-and-play structure within the image fusion module of Image LLMs. This adaptation extends their understanding capabilities to include temporal information, enabling the development of Video LLMs that not only surpass baseline performances but also do so with minimal instructional data and training resources. Our approach highlights the potential for a more cost-effective and scalable advancement in multimodal models, effectively building upon the foundational work of Image LLMs.",
    "pdf_link": "https://arxiv.org/abs/2404.11865",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.11865v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11865/pipeline_v4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11865v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11865/pooling_v2.png"
      }
    ],
    "abstract_cn": "多模态大型语言模型（MLLMs）在处理多模态信息方面展现出了非凡的洞察力，从图像语言模型（Image LLMs）到更为复杂的视频语言模型（Video LLMs）均有涉猎。大量研究已经证明了它们在跨模态理解上的卓越能力。最近，提出了结合视频基础模型与大型语言模型，以构建一个全面的视频理解系统，旨在突破特定预设视觉任务的限制。然而，当前视频LLMs的发展往往忽略了图像LLMs的基石作用，倾向于采用更复杂的结构和多样化的多模态数据进行预训练，这大幅提高了相关方法的成本。为应对这些挑战，本研究提出了一种高效的方法，它巧妙地利用了图像LLMs的已有优势，以资源节约的方式实现从图像LLMs向视频LLMs的转变。我们介绍了RED-VILLM，这是一个高效的视频LLMs开发流程，它基于图像LLMs，采用了时间适应性的即插即用结构，扩展了对时间信息的理解能力，从而开发出不仅性能超越基准，而且使用最少的指导数据和训练资源的视频LLMs。我们的方法展现了在多模态模型领域实现成本效益更高、更具扩展性进步的可能性，为图像LLMs的基石工作提供了有效的延伸。",
    "title_cn": "探索从静态图像到动态视频的转变，我们需明确多模态大型语言模型所需具备的关键要素。",
    "tags": [
      "LLM应用",
      "计算机视觉",
      "人工智能"
    ]
  },
  {
    "title": "3D object quality prediction for Metal Jet Printer with Multimodal thermal encoder",
    "submit_datetime": "2024年04月17日",
    "abstract": "With the advancements in 3D printing technologies, it is extremely important that the quality of 3D printed objects, and dimensional accuracies should meet the customer's specifications. Various factors during metal printing affect the printed parts' quality, including the power quality, the printing stage parameters, the print part's location inside the print bed, the curing stage parameters, and the metal sintering process. With the large data gathered from HP's MetJet printing process, AI techniques can be used to analyze, learn, and effectively infer the printed part quality metrics, as well as assist in improving the print yield. In-situ thermal sensing data captured by printer-installed thermal sensors contains the part thermal signature of fusing layers. Such part thermal signature contains a convoluted impact from various factors. In this paper, we use a multimodal thermal encoder network to fuse data of a different nature including the video data vectorized printer control data, and exact part thermal signatures with a trained encoder-decoder module. We explored the data fusing techniques and stages for data fusing, the optimized end-to-end model architecture indicates an improved part quality prediction accuracy.",
    "pdf_link": "https://arxiv.org/abs/2404.11776",
    "graphs": [],
    "abstract_cn": "3D打印技术的飞速发展要求打印出的物体不仅要质量上乘，尺寸精度也得精准符合客户需求。金属打印环节众多因素如功率稳定性、打印阶段参数、部件在打印台中的位置、固化阶段参数及金属烧结过程等，都会对成品质量产生影响。HP的MetJet打印技术所积累的海量数据，借助人工智能技术，不仅可以深入分析和学习，还能有效预测打印部件的质量指标，进而提升打印成功率。打印机内置的热传感器所捕获的实时热感测数据，记录了熔层的热特征，这些特征受到多种因素的综合影响。本文提出了一种多模态热编码器网络，用以整合视频数据、打印机控制数据以及精确的部件热签名等不同来源的信息，并通过训练有素的编码器-解码器模块进行处理。我们深入研究了数据融合的方法和阶段，最终优化出的端到端模型架构显著提高了部件质量预测的准确性。",
    "title_cn": "采用多模态热编码器对金属喷射打印技术的3D对象质量进行预测。",
    "tags": [
      "分类：Agent\n\n这篇论文主要研究了3D打印过程中的质量预测问题，提出了一种多模态热编码器网络来整合不同来源的信息，并通过训练有素的编码器-解码器模块进行处理。这个过程涉及到了智能代理（Agent）的概念，即利用人工智能技术来模拟人类专家的决策过程，以提高打印成功率。因此，这篇论文可以归类为Agent领域。",
      "3D打印",
      "人工智能"
    ]
  },
  {
    "title": "Pretraining Billion-scale Geospatial Foundational Models on Frontier",
    "submit_datetime": "2024年04月17日",
    "abstract": "As AI workloads increase in scope, generalization capability becomes challenging for small task-specific models and their demand for large amounts of labeled training samples increases. On the contrary, Foundation Models (FMs) are trained with internet-scale unlabeled data via self-supervised learning and have been shown to adapt to various tasks with minimal fine-tuning. Although large FMs have demonstrated significant impact in natural language processing and computer vision, efforts toward FMs for geospatial applications have been restricted to smaller size models, as pretraining larger models requires very large computing resources equipped with state-of-the-art hardware accelerators. Current satellite constellations collect 100+TBs of data a day, resulting in images that are billions of pixels and multimodal in nature. Such geospatial data poses unique challenges opening up new opportunities to develop FMs. We investigate billion scale FMs and HPC training profiles for geospatial applications by pretraining on publicly available data. We studied from end-to-end the performance and impact in the solution by scaling the model size. Our larger 3B parameter size model achieves up to 30% improvement in top1 scene classification accuracy when comparing a 100M parameter model. Moreover, we detail performance experiments on the Frontier supercomputer, America's first exascale system, where we study different model and data parallel approaches using PyTorch's Fully Sharded Data Parallel library. Specifically, we study variants of the Vision Transformer architecture (ViT), conducting performance analysis for ViT models with size up to 15B parameters. By discussing throughput and performance bottlenecks under different parallelism configurations, we offer insights on how to leverage such leadership-class HPC resources when developing large models for geospatial imagery applications.",
    "pdf_link": "https://arxiv.org/abs/2404.11706",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.11706v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11706/perf_io.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11706v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11706/perf_configs.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11706v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11706/perf_base.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11706v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11706/perf_huge.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11706v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11706/perf_giant.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11706v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11706/perf_enormous.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11706v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11706/mem_full_1G.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11706v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11706/perf_mem_act_1G.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11706v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11706/perf_5B.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11706v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11706/perf_15B.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11706v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11706/perf_mem_act_NG.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11706v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11706/power_vit_5b.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11706v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11706/mem_full_NG.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11706v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11706/train_loss.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11706v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11706/linprob_test_acc1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11706v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11706/linprob_test_acc5.png"
      }
    ],
    "abstract_cn": "随着AI工作负载日益复杂，泛化能力对于小型专用模型而言越发成为难题，这些模型对大量标记训练样本的需求也随之增长。与之相对，基础模型（FMs）通过自监督学习利用互联网规模的未标记数据进行训练，展现出对多种任务的适应能力，且仅需极少量微调。尽管大型FMs在自然语言处理和计算机视觉领域已产生显著影响，但针对地理空间应用的FMs开发因资源限制而多聚焦于较小规模模型。鉴于预训练更大规模模型需要巨大的计算资源和尖端硬件加速器，这一现象尤为明显。目前，卫星群每天产生超过100TB的数据，生成的图像不仅像素高达数十亿，还具有多模态特性，为地理空间数据的处理带来了新的挑战和机遇。本研究通过在公开数据集上预训练，探索了适用于地理空间应用的十亿规模FMs及高性能计算（HPC）训练策略。我们从整体上评估了模型规模扩展对解决方案性能和影响的提升，发现3B参数规模的模型在场景分类准确度上相较于100M参数模型提升了30%。此外，我们在Frontier超级计算机上进行了性能测试，这是美国首个E级计算系统，研究了使用PyTorch的Fully Sharded Data Parallel库实现的不同模型和数据并行方法。特别是，我们对视觉变换器架构（ViT）进行了性能分析，测试了高达15B参数规模的ViT模型。通过探讨不同并行配置下的吞吐量和性能瓶颈，我们为如何利用顶级高性能计算资源开发地理空间图像应用的大型模型提供了深刻见解。",
    "title_cn": "在前沿科技领域，我们正致力于预训练规模达十亿级的地理空间基础模型。",
    "tags": [
      "LLM应用",
      "地理空间数据处理",
      "高性能计算"
    ]
  },
  {
    "title": "Exploring the Transferability of Visual Prompting for Multimodal Large Language Models",
    "submit_datetime": "2024年04月17日",
    "abstract": "Although Multimodal Large Language Models (MLLMs) have demonstrated promising versatile capabilities, their performance is still inferior to specialized models on downstream tasks, which makes adaptation necessary to enhance their utility. However, fine-tuning methods require independent training for every model, leading to huge computation and memory overheads. In this paper, we propose a novel setting where we aim to improve the performance of diverse MLLMs with a group of shared parameters optimized for a downstream task. To achieve this, we propose Transferable Visual Prompting (TVP), a simple and effective approach to generate visual prompts that can transfer to different models and improve their performance on downstream tasks after trained on only one model. We introduce two strategies to address the issue of cross-model feature corruption of existing visual prompting methods and enhance the transferability of the learned prompts, including 1) Feature Consistency Alignment: which imposes constraints to the prompted feature changes to maintain task-agnostic knowledge; 2) Task Semantics Enrichment: which encourages the prompted images to contain richer task-specific semantics with language guidance. We validate the effectiveness of TVP through extensive experiments with 6 modern MLLMs on a wide variety of tasks ranging from object recognition and counting to multimodal reasoning and hallucination correction.",
    "pdf_link": "https://arxiv.org/abs/2404.11207",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.11207v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11207/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11207v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11207/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11207v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11207/seed_0_lr_200_add_prompt_False_model_name_instructblip_dataset_cifar10.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11207v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11207/seed_0_lr_200_add_prompt_True_model_name_instructblip_dataset_cifar10.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11207v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11207/seed_0_lr_200_add_prompt_False_model_name_bliva_dataset_cifar10.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11207v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11207/seed_0_lr_200_add_prompt_True_model_name_bliva_dataset_cifar10.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11207v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11207/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11207v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11207/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11207v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11207/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11207v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11207/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11207v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11207/small_CLEVR_True.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11207v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11207/small_Hatefulmemes_True.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11207v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11207/small_POPE_True.png"
      }
    ],
    "abstract_cn": "多模态大型语言模型（MLLMs）虽展现出潜力，但在特定任务上的表现仍不及专业模型，亟需优化以提升其应用价值。传统微调方法需对每个模型单独训练，造成了巨大的计算和存储资源消耗。本文提出了一种创新框架，通过共享参数集针对特定下游任务进行优化，以提升各类MLLMs的性能。我们引入了“可转移视觉提示”（TVP）技术，这是一种简洁高效的解决方案，能够生成可在不同模型间转移并提升任务表现的视觉提示，且仅需在一个模型上进行训练。为解决现有方法中跨模型特征干扰的问题，我们提出了两大策略：一是“特征一致性对齐”，确保提示特征变化不破坏任务通用知识；二是“任务语义丰富化”，通过语言引导使提示图像富含更多任务特定语义。我们通过在六种先进MLLMs上进行的广泛实验验证了TVP的有效性，实验任务包括物体识别、计数、多模态推理及幻觉校正等。",
    "title_cn": "本文旨在探究视觉提示在多模态大型语言模型中的应用迁移性。",
    "tags": [
      "LLM应用",
      "计算机视觉",
      ""
    ]
  },
  {
    "title": "SuRe: Summarizing Retrievals using Answer Candidates for Open-domain QA of LLMs",
    "submit_datetime": "2024年04月16日",
    "abstract": "Large language models (LLMs) have made significant advancements in various natural language processing tasks, including question answering (QA) tasks. While incorporating new information with the retrieval of relevant passages is a promising way to improve QA with LLMs, the existing methods often require additional fine-tuning which becomes infeasible with recent LLMs. Augmenting retrieved passages via prompting has the potential to address this limitation, but this direction has been limitedly explored. To this end, we design a simple yet effective framework to enhance open-domain QA (ODQA) with LLMs, based on the summarized retrieval (SuRe). SuRe helps LLMs predict more accurate answers for a given question, which are well-supported by the summarized retrieval that could be viewed as an explicit rationale extracted from the retrieved passages. Specifically, SuRe first constructs summaries of the retrieved passages for each of the multiple answer candidates. Then, SuRe confirms the most plausible answer from the candidate set by evaluating the validity and ranking of the generated summaries. Experimental results on diverse ODQA benchmarks demonstrate the superiority of SuRe, with improvements of up to 4.6% in exact match (EM) and 4.0% in F1 score over standard prompting approaches. SuRe also can be integrated with a broad range of retrieval methods and LLMs. Finally, the generated summaries from SuRe show additional advantages to measure the importance of retrieved passages and serve as more preferred rationales by models and humans.",
    "pdf_link": "https://arxiv.org/abs/2404.13081",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.13081v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13081/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13081v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13081/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13081v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13081/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13081v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13081/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13081v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13081/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13081v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13081/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13081v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13081/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13081v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13081/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13081v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13081/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13081v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13081/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13081v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13081/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13081v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13081/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13081v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13081/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13081v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13081/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13081v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13081/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13081v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13081/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13081v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13081/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2404.13081v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.13081/x18.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）在自然语言处理的多个领域取得了突破性进展，尤其是在问答（QA）任务上。尽管结合新信息和检索相关内容是提升LLMs QA性能的一条有前景的途径，但现有的技术往往需要额外的微调，这在最新的LLMs中变得不切实际。通过提示来增强检索段落，有望突破这一瓶颈，但这方面的研究还相对有限。为了解决这一问题，我们提出了一个基于总结检索（SuRe）的简洁而高效的框架，用于提升LLMs在开放域问答（ODQA）中的表现。SuRe通过为每个可能的答案构建检索段落的摘要，帮助LLMs更准确地预测问题的答案，这些摘要可视为从检索内容中提取的明确理由。SuRe首先为多个答案候选者生成摘要，然后通过评估这些摘要的准确性和排序来确定最可信的答案。在多个ODQA基准上的实验结果显示，SuRe的性能优于传统提示方法，精确匹配（EM）准确度提升了4.6%，F1分数提升了4.0%。此外，SuRe能够与多种检索方法和LLMs兼容。SuRe生成的摘要还具有额外的优势，它们不仅能够衡量检索内容的重要性，还能作为模型和人类更倾向的理由。",
    "title_cn": "SuRe：为大型语言模型（LLMs）的开放域问答任务，通过候选答案对检索结果进行精炼总结。",
    "tags": [
      "LLM应用",
      "",
      "问答系统"
    ]
  },
  {
    "title": "A Survey on Retrieval-Augmented Text Generation for Large Language Models",
    "submit_datetime": "2024年04月16日",
    "abstract": "Retrieval-Augmented Generation (RAG) merges retrieval methods with deep learning advancements to address the static limitations of large language models (LLMs) by enabling the dynamic integration of up-to-date external information. This methodology, focusing primarily on the text domain, provides a cost-effective solution to the generation of plausible but incorrect responses by LLMs, thereby enhancing the accuracy and reliability of their outputs through the use of real-world data. As RAG grows in complexity and incorporates multiple concepts that can influence its performance, this paper organizes the RAG paradigm into four categories: pre-retrieval, retrieval, post-retrieval, and generation, offering a detailed perspective from the retrieval viewpoint. It outlines RAG's evolution and discusses the field's progression through the analysis of significant studies. Additionally, the paper introduces evaluation methods for RAG, addressing the challenges faced and proposing future research directions. By offering an organized framework and categorization, the study aims to consolidate existing research on RAG, clarify its technological underpinnings, and highlight its potential to broaden the adaptability and applications of LLMs.",
    "pdf_link": "https://arxiv.org/abs/2404.10981",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.10981v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10981/RAG_example.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10981v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10981/RAG_framework.png"
      }
    ],
    "abstract_cn": "检索增强生成（RAG）技术通过结合检索技术和深度学习的最新进展，突破了大型语言模型（LLMs）的静态限制，实现了实时外部信息的动态融合。这一方法专注于文本领域，有效提升了LLMs生成结果的准确性与可靠性，避免了生成似是而非的错误响应。随着RAG技术不断演进，融合了多种可能影响其表现的概念，本文将RAG的框架划分为四个主要阶段：检索前处理、检索阶段、检索后处理和生成阶段，并从检索的角度提供了深入的分析。文章追溯了RAG的发展轨迹，并通过剖析关键研究，探讨了该领域的发展趋势。同时，本文还提出了RAG的评估方法，针对当前面临的挑战，并对未来的研究方向提出了建议。通过构建系统化的框架和清晰的分类，本文意在整合RAG的研究成果，阐释其技术原理，并强调其在扩展LLMs应用范围和适应性方面的潜力。",
    "title_cn": "一篇关于为大型语言模型增强检索文本生成的研究综述",
    "tags": [
      "分类：RAG",
      "文本生成",
      "信息检索"
    ]
  },
  {
    "title": "MiniCheck: Efficient Fact-Checking of LLMs on Grounding Documents",
    "submit_datetime": "2024年04月16日",
    "abstract": "Recognizing if LLM output can be grounded in evidence is central to many tasks in NLP: retrieval-augmented generation, summarization, document-grounded dialogue, and more. Current approaches to this kind of \"fact-checking\" are based on verifying each piece of a model generation against potential evidence using an LLM. However, this process can be very computationally expensive, requiring many calls to LLMs to check a single response. In this work, we show how to build small models that have GPT-4-level performance but for 400x lower cost. We do this by constructing synthetic training data with GPT-4, which involves creating realistic yet challenging instances of factual errors via a structured generation procedure. Training on this data teaches models to check each fact in the claim and recognize synthesis of information across sentences. For evaluation, we unify pre-existing datasets into a benchmark LLM-AggreFact, collected from recent work on fact-checking and grounding LLM generations. Our best system MiniCheck-FT5 (770M parameters) outperforms all systems of comparable size and reaches GPT-4 accuracy. We release LLM-AggreFact, code for data synthesis, and models.",
    "pdf_link": "https://arxiv.org/abs/2404.10774",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.10774v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10774/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10774v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10774/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10774v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10774/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10774v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10774/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10774v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10774/x5.png"
      }
    ],
    "abstract_cn": "在自然语言处理领域，判断大型语言模型（LLM）的输出是否能够依据证据是至关重要的，这涉及到检索增强生成、摘要、文档驱动对话等多个任务。现行的“事实核查”方法主要依赖于使用LLM对模型生成的内容逐项与潜在证据进行核对，但这一过程计算成本极高，需要多次调用LLM来核实单一回复。本研究展示了如何以400倍的成本降低，构建出性能媲美GPT-4的小型模型。我们通过利用GPT-4生成合成训练数据，创造性地构建出既真实又具有挑战性的事实错误案例，并通过结构化生成流程来实现。在这些数据上训练的模型学会了检查声明中的每个事实，并能够识别跨句的信息整合。为了评估，我们将现有的数据集整合成一个新的基准集LLM-AggreFact，它来源于近期关于LLM生成的事实核查和证据基础的研究。我们的最佳系统MiniCheck-FT5（参数量为7.7亿）在同等规模的系统中表现最优，并达到了GPT-4的准确度。我们还发布了LLM-AggreFact基准集、数据合成的代码以及模型。",
    "title_cn": "MiniCheck：一种高效的事实核查工具，专为在基础文档上验证大型语言模型（LLMs）的真实性而设计。",
    "tags": [
      "分类：LLM应用\n\n这篇论文的摘要主要讨论了如何提高大型语言模型（LLM）在事实核查任务中的效率和准确性。它提出了一种新的方法，通过生成合成训练数据和结构化生成流程来训练一个小型模型，该模型在性能上可以与大型模型相媲美，但成本降低了400倍。此外，论文还介绍了一个新的基准集LLM-AggreFact，用于评估模型在事实核查任务上的表现。这些内容都与LLM的应用相关，因此将这篇论文归类为LLM应用。",
      "",
      "事实核查"
    ]
  },
  {
    "title": "Generative Information Retrieval Evaluation",
    "submit_datetime": "2024年04月16日",
    "abstract": "This paper is a draft of a chapter intended to appear in a forthcoming book on generative information retrieval, co-edited by Chirag Shah and Ryen White. In this chapter, we consider generative information retrieval evaluation from two distinct but interrelated perspectives. First, large language models (LLMs) themselves are rapidly becoming tools for evaluation, with current research indicating that LLMs may be superior to crowdsource workers and other paid assessors on basic relevance judgement tasks. We review past and ongoing related research, including speculation on the future of shared task initiatives, such as TREC, and a discussion on the continuing need for human assessments. Second, we consider the evaluation of emerging LLM-based generative information retrieval (GenIR) systems, including retrieval augmented generation (RAG) systems. We consider approaches that focus both on the end-to-end evaluation of GenIR systems and on the evaluation of a retrieval component as an element in a RAG system. Going forward, we expect the evaluation of GenIR systems to be at least partially based on LLM-based assessment, creating an apparent circularity, with a system seemingly evaluating its own output. We resolve this apparent circularity in two ways: 1) by viewing LLM-based assessment as a form of \"slow search\", where a slower IR system is used for evaluation and training of a faster production IR system; and 2) by recognizing a continuing need to ground evaluation in human assessment, even if the characteristics of that human assessment must change.",
    "pdf_link": "https://arxiv.org/abs/2404.08137",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.08137v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08137/GenIR-UI.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08137v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08137/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08137v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08137/GenIR-RAG.png"
      }
    ],
    "abstract_cn": "本章草稿将收录于即将出版的《生成式信息检索》一书，该书由 Chirag Shah 和 Ryen White 联合编辑。本章从两大视角探讨了生成式信息检索的评估问题：一是大型语言模型（LLMs）作为评估工具的兴起，研究显示它们在基础相关性判断任务上可能超越了众包工作者及其他付费评估者。我们梳理了相关研究的过去和现状，并对未来共享任务如TREC的发展趋势进行了展望，同时讨论了人类评估的必要性。二是对基于LLM的新兴生成式信息检索（GenIR）系统，包括检索增强生成（RAG）系统的评估方法进行了探讨。我们既关注了GenIR系统的整体评估，也关注了RAG系统中检索组件的评估。展望未来，GenIR系统的评估预计将部分依赖于LLM评估，这似乎形成了一种系统自我评估的循环性。我们通过两种方法来解决这一问题：首先，将LLM评估视作一种“慢速搜索”，利用较慢的IR系统来评估和训练更快的生产IR系统；其次，认识到即便人类评估的特性需要变化，基于人类评估的评估方法仍然是必要的。",
    "title_cn": "创造性信息检索评估",
    "tags": [
      "LLM应用",
      "信息检索",
      "人工智能"
    ]
  },
  {
    "title": "An Empirical Evaluation of Pre-trained Large Language Models for Repairing Declarative Formal Specifications",
    "submit_datetime": "2024年04月16日",
    "abstract": "Automatic Program Repair (APR) has garnered significant attention as a practical research domain focused on automatically fixing bugs in programs. While existing APR techniques primarily target imperative programming languages like C and Java, there is a growing need for effective solutions applicable to declarative software specification languages. This paper presents a systematic investigation into the capacity of Large Language Models (LLMs) for repairing declarative specifications in Alloy, a declarative formal language used for software specification. We propose a novel repair pipeline that integrates a dual-agent LLM framework, comprising a Repair Agent and a Prompt Agent. Through extensive empirical evaluation, we compare the effectiveness of LLM-based repair with state-of-the-art Alloy APR techniques on a comprehensive set of benchmarks. Our study reveals that LLMs, particularly GPT-4 variants, outperform existing techniques in terms of repair efficacy, albeit with a marginal increase in runtime and token usage. This research contributes to advancing the field of automatic repair for declarative specifications and highlights the promising potential of LLMs in this domain.",
    "pdf_link": "https://arxiv.org/abs/2404.11050",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.11050v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11050/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11050v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11050/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11050v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11050/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11050v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11050/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11050v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11050/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11050v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11050/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11050v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11050/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11050v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11050/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11050v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11050/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11050v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11050/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11050v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11050/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11050v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11050/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11050v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11050/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11050v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11050/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11050v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11050/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2404.11050v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.11050/x16.png"
      }
    ],
    "abstract_cn": "自动程序修复（APR）因其致力于自动修正程序错误而成为备受关注的实用研究领域。目前，APR 技术多集中于命令式语言如 C 和 Java，但对声明式软件规范语言的解决方案需求正日益上升。本论文对大型语言模型（LLMs）在修复 Alloy 语言声明式规范方面的能力进行了深入探讨，Alloy 是一种广泛用于软件规范的声明式形式化语言。我们设计了一套创新的修复流程，融合了双代理 LLM 架构，涵盖修复代理与提示代理。经过广泛的实证评估，我们发现基于 LLM 的修复方法在修复效率上超越了现有的 Alloy APR 技术，尽管这以略微增加的运行时间和令牌使用为代价。本研究不仅推动了声明式规范自动修复技术的发展，也突显了 LLMs 在该领域的光明前景。",
    "title_cn": "本文通过实证研究，评估了预训练的大型语言模型在修复声明式形式规范方面的性能。",
    "tags": [
      "Agent",
      "软件工程",
      "自动化测试"
    ]
  },
  {
    "title": "Procedural Dilemma Generation for Evaluating Moral Reasoning in Humans and Language Models",
    "submit_datetime": "2024年04月16日",
    "abstract": "As AI systems like language models are increasingly integrated into decision-making processes affecting people's lives, it's critical to ensure that these systems have sound moral reasoning. To test whether they do, we need to develop systematic evaluations. We provide a framework that uses a language model to translate causal graphs that capture key aspects of moral dilemmas into prompt templates. With this framework, we procedurally generated a large and diverse set of moral dilemmas -- the OffTheRails benchmark -- consisting of 50 scenarios and 400 unique test items. We collected moral permissibility and intention judgments from human participants for a subset of our items and compared these judgments to those from two language models (GPT-4 and Claude-2) across eight conditions. We find that moral dilemmas in which the harm is a necessary means (as compared to a side effect) resulted in lower permissibility and higher intention ratings for both participants and language models. The same pattern was observed for evitable versus inevitable harmful outcomes. However, there was no clear effect of whether the harm resulted from an agent's action versus from having omitted to act. We discuss limitations of our prompt generation pipeline and opportunities for improving scenarios to increase the strength of experimental effects.",
    "pdf_link": "https://arxiv.org/abs/2404.10975",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.10975v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10975/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10975v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10975/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10975v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10975/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10975v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10975/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10975v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10975/x5.png"
      }
    ],
    "abstract_cn": "随着语言模型等AI系统在影响人类生活的决策过程中扮演越来越重要的角色，确保它们具备坚实的道德推理能力变得尤为关键。为此，我们必须开展系统性的评估工作。本研究提出了一种框架，该框架利用语言模型将描述道德困境核心要素的因果图转换为提示模板。基于此框架，我们生成了一套内容丰富、多样化的道德困境数据集——OffTheRails基准测试，共包含50个情境和400个独特的测试案例。我们从人类参与者那里收集了对我们数据子集的道德许可性和意图性判断，并将其与两个语言模型（GPT-4和Claude-2）在八种不同条件下的判断进行了对比分析。研究发现，在伤害是必要手段而非副作用的道德困境中，无论是参与者还是语言模型，其许可性评价都较低，而意图性评价则较高。对于可避免与不可避免的伤害结果，也呈现出类似的趋势。然而，当伤害是由代理的行为引起与未采取行动引起时，并未发现明显的差异。我们讨论了当前提示生成流程的局限性，并提出了改进情景设计以增强实验效应强度的可能途径。",
    "title_cn": "生成程序性道德困境，以评估人类和语言模型的道德推理能力。",
    "tags": [
      "分类：LLM应用",
      "AI伦理",
      "道德评估"
    ]
  },
  {
    "title": "Automated Evaluation of Large Vision-Language Models on Self-driving Corner Cases",
    "submit_datetime": "2024年04月16日",
    "abstract": "Large Vision-Language Models (LVLMs), due to the remarkable visual reasoning ability to understand images and videos, have received widespread attention in the autonomous driving domain, which significantly advances the development of interpretable end-to-end autonomous driving. However, current evaluations of LVLMs primarily focus on the multi-faceted capabilities in common scenarios, lacking quantifiable and automated assessment in autonomous driving contexts, let alone severe road corner cases that even the state-of-the-art autonomous driving perception systems struggle to handle. In this paper, we propose CODA-LM, a novel vision-language benchmark for self-driving, which provides the first automatic and quantitative evaluation of LVLMs for interpretable autonomous driving including general perception, regional perception, and driving suggestions. CODA-LM utilizes the texts to describe the road images, exploiting powerful text-only large language models (LLMs) without image inputs to assess the capabilities of LVLMs in autonomous driving scenarios, which reveals stronger alignment with human preferences than LVLM judges. Experiments demonstrate that even the closed-sourced commercial LVLMs like GPT-4V cannot deal with road corner cases well, suggesting that we are still far from a strong LVLM-powered intelligent driving agent, and we hope our CODA-LM can become the catalyst to promote future development.",
    "pdf_link": "https://arxiv.org/abs/2404.10595",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.10595v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10595/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10595v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10595/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10595v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10595/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10595v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10595/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10595v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10595/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10595v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10595/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10595v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10595/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10595v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10595/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10595v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10595/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10595v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10595/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10595v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10595/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10595v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10595/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10595v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10595/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10595v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10595/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10595v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10595/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10595v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10595/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10595v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10595/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10595v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10595/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10595v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10595/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10595v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10595/x20.png"
      }
    ],
    "abstract_cn": "大型视觉-语言模型（LVLMs）因其卓越的图像和视频理解能力，在自动驾驶领域引起了广泛关注，显著推动了可解释的端到端自动驾驶技术的进步。但目前对LVLMs的评估多聚焦于常规情境下的多维能力，缺少对自动驾驶场景的量化和自动化评估，尤其是对于那些即使是最尖端的自动驾驶感知系统也难以应对的极端路况。本文提出了CODA-LM，这是一个创新的自动驾驶视觉-语言基准测试，首次为LVLMs在可解释自动驾驶中的应用提供了自动化和量化的评估，涵盖常规感知、区域感知和驾驶建议等方面。CODA-LM通过文本描述道路图像，借助仅使用文本的大型语言模型（LLMs）来评估LVLMs在自动驾驶情境下的表现，这种方式更能反映人类的偏好。实验结果揭示，即便是市面上的闭源商业LVLMs，如GPT-4V，也难以妥善处理极端路况，这表明我们距离拥有一个强大的LVLM驱动的智能驾驶代理还有很长的路要走。我们期望CODA-LM能够成为推动未来技术发展的催化剂。",
    "title_cn": "本文探讨了如何对大型视觉-语言模型在自动驾驶领域的特殊情况下进行自动化评估。",
    "tags": [
      "Agent",
      "自动驾驶",
      "人工智能"
    ]
  },
  {
    "title": "White Men Lead, Black Women Help: Uncovering Gender, Racial, and Intersectional Bias in Language Agency",
    "submit_datetime": "2024年04月16日",
    "abstract": "Social biases can manifest in language agency. For instance, White individuals and men are often described as \"agentic\" and achievement-oriented, whereas Black individuals and women are frequently described as \"communal\" and as assisting roles. This study establishes agency as an important aspect of studying social biases in both human-written and Large Language Model (LLM)-generated texts. To accurately measure \"language agency\" at sentence level, we propose a Language Agency Classification dataset to train reliable agency classifiers. We then use an agency classifier to reveal notable language agency biases in 6 datasets of human- or LLM-written texts, including biographies, professor reviews, and reference letters. While most prior NLP research on agency biases focused on single dimensions, we comprehensively explore language agency biases in gender, race, and intersectional identities. We observe that (1) language agency biases in human-written texts align with real-world social observations; (2) LLM-generated texts demonstrate remarkably higher levels of language agency bias than human-written texts; and (3) critical biases in language agency target people of minority groups -- for instance, languages used to describe Black females exhibit the lowest level of agency across datasets. Our findings reveal intricate social biases in human- and LLM-written texts through the lens of language agency, warning against using LLM generations in social contexts without scrutiny.",
    "pdf_link": "https://arxiv.org/abs/2404.10508",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.10508v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10508/bias_bios_gaps.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10508v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10508/ratemyprofessor_gaps.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10508v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10508/llm_race_bios_gender_bert_binary_average_overlay_histogram.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10508v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10508/llm_race_professor_gender_bert_binary_average_overlay_histogram.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10508v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10508/llm_race_rec_letter_gender_bert_binary_average_overlay_histogram.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10508v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10508/race_bios_bert_binary_average_overlay_histogram.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10508v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10508/race_professor_bert_binary_average_overlay_histogram.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10508v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10508/race_rec_letter_bert_binary_average_overlay_histogram.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10508v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10508/race_bios_gaps.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10508v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10508/race_professor_gaps.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10508v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10508/race_rec_letter_gaps.png"
      }
    ],
    "abstract_cn": "社会偏见在语言行为中表露无遗。通常，白人和男性被描绘为具有行动力和目标导向，而黑人和女性则多被形容为具有社群精神和辅助性。本研究将行为主体性视为审视人类撰写和大型语言模型（LLM）生成文本中社会偏见的关键要素。为精确评估句子级别的“语言行为主体性”，我们设计了一个语言行为分类数据集，用以培养高效的主体性分类器。随后，我们利用这一分类器揭露了6个由人类或LLM撰写的文本数据集中显著的语言行为偏见，涵盖了传记、教授评价和推荐信等。与以往专注于单一维度的NLP研究不同，我们全面探讨了性别、种族及交叉身份维度上的语言行为偏见。研究发现：（1）人类文本中的语言行为偏见与现实社会观察相吻合；（2）LLM生成的文本比人类文本展现出更高程度的语言行为偏见；（3）语言行为中的关键偏见集中于少数群体，如描述黑人女性的语言在所有数据集中代理性水平最低。这些发现通过语言行为主体性的视角，揭示了人类和LLM文本中的微妙社会偏见，提醒我们在社会情境中使用LLM生成的内容前需进行严格审查。",
    "title_cn": "白人男性担纲领导，黑人女性扮演辅助角色：本文揭露了语言机构中存在的性别、种族以及交叉性偏见。",
    "tags": [
      "LLM应用",
      "社会偏见分析",
      ""
    ]
  },
  {
    "title": "How faithful are RAG models? Quantifying the tug-of-war between RAG and LLMs' internal prior",
    "submit_datetime": "2024年04月15日",
    "abstract": "Retrieval augmented generation (RAG) is often used to fix hallucinations and provide up-to-date knowledge for large language models (LLMs). However, in cases when the LLM alone incorrectly answers a question, does providing the correct retrieved content always fix the error? Conversely, in cases where the retrieved content is incorrect, does the LLM know to ignore the wrong information, or does it recapitulate the error? To answer these questions, we systematically analyze the tug-of-war between a LLM's internal knowledge (i.e. its prior) and the retrieved information in settings when they disagree. We test GPT-4 and other LLMs on question-answering abilities across datasets with and without reference documents. As expected, providing the correct retrieved information fixes most model mistakes (94% accuracy). However, when the reference document is perturbed with increasing levels of wrong values, the LLM is more likely to recite the incorrect, modified information when its internal prior is weaker but is more resistant when its prior is stronger. Similarly, we also find that the more the modified information deviates from the model's prior, the less likely the model is to prefer it. These results highlight an underlying tension between a model's prior knowledge and the information presented in reference documents.",
    "pdf_link": "https://arxiv.org/abs/2404.10198",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.10198v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10198/schematic4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10198v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10198/fig1-2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10198v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10198/examples4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10198v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10198/adherence-prompts6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10198v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10198/fig1combined2.png"
      }
    ],
    "abstract_cn": "检索增强生成（RAG）被广泛采用，旨在修正大型语言模型（LLMs）的误判并引入最新资讯。但当LLMs独自给出错误答案时，正确的检索内容是否总能纠正这一错误？反之，如果检索内容有误，LLMs能否识别并忽略这些错误信息，避免重复错误？为探究这一问题，我们对LLMs内部先验知识与检索信息之间的冲突进行了系统分析，特别是在它们相冲突的情况下。我们在有无参考文档的不同数据集上，对GPT-4及其他LLMs的问答能力进行了测试。测试结果显示，正确的检索信息能够修正大多数模型的误判，准确度高达94%。然而，当参考文档被逐渐增加的错误值干扰时，如果LLMs的内部先验较弱，它们更易接受错误的修改信息；而内部先验较强的模型则更具抵抗力。此外，我们同样发现，修改后的信息与模型先验的偏差越大，模型对其的偏好就越低。这些发现揭示了模型先验知识与参考文档所提供信息之间的内在张力。",
    "title_cn": "RAG模型的准确性究竟有多高？本文旨在量化分析RAG与大型语言模型内在先验之间的相互作用与影响。",
    "tags": [
      "分类：RAG",
      "信息检索",
      ""
    ]
  },
  {
    "title": "Memory Sharing for Large Language Model based Agents",
    "submit_datetime": "2024年04月15日",
    "abstract": "In the realm of artificial intelligence, the adaptation of Large Language Model (LLM)-based agents to execute tasks via natural language prompts represents a significant advancement, notably eliminating the need for explicit retraining or fine tuning for fixed-answer tasks such as common sense questions and yes/no queries. However, the application of In-context Learning to open-ended challenges, such as poetry creation, reveals substantial limitations due to the comprehensiveness of the provided examples and agent's ability to understand the content expressed in the problem, leading to outputs that often diverge significantly from expected results. Addressing this gap, our study introduces the Memory-Sharing (MS) framework for LLM multi-agents, which utilizes a real-time memory storage and retrieval system to enhance the In-context Learning process. Each \"memory\" within this system captures both the posed query and the corresponding real-time response from an LLM-based agent, aggregating these memories from a broad spectrum of similar agents to enrich the memory pool shared by all agents. This framework not only aids agents in identifying the most relevant examples for specific tasks but also evaluates the potential utility of their memories for future applications by other agents. Empirical validation across three distinct domains involving specialized functions of agents demonstrates that the MS framework significantly improve the agent's performance regrading the open-ended questions. Furthermore, we also discuss what type of memory pool and what retrieval strategy in MS can better help agents, offering a future develop direction of MS. The code and data are available at: https://github.com/GHupppp/MemorySharingLLM",
    "pdf_link": "https://arxiv.org/abs/2404.09982",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.09982v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09982/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09982v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09982/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09982v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09982/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09982v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09982/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09982v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09982/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09982v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09982/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09982v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09982/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09982v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09982/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09982v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09982/x9.png"
      }
    ],
    "abstract_cn": "在人工智能的世界中，大型语言模型（LLM）驱动的智能体通过自然语言指令执行任务，标志着一项重要进步，显著减少了对常识问答和是非题这类固定答案任务的显式再训练或微调需求。但是，当上下文学习应用于如诗歌创作这样的开放式任务时，由于示例的全面性和智能体对问题内容理解能力的局限，常常导致生成的结果与预期大相径庭。为填补这一空白，本研究提出了一种用于LLM多智能体的记忆共享（MS）框架，该框架通过实时记忆存储和检索系统来提升上下文学习过程。系统内的每一“记忆”单元都记录了提出的问题和LLM智能体的实时响应，通过收集广泛类似智能体的记忆，共同丰富了所有智能体共享的记忆库。这一框架不仅助力智能体为特定任务找到最贴切的示例，还评估了它们的记忆对未来其他智能体应用的潜在价值。在三个不同领域的实证验证中，MS框架显著提升了智能体处理开放式问题的表现。此外，我们还探讨了哪种记忆库类型和检索策略更能助力智能体，并为MS的未来发展方向提供了见解。相关代码和数据已在 https://github.com/GHupppp/MemorySharingLLM 上公开。",
    "title_cn": "大型语言模型驱动的代理之间的内存共享",
    "tags": [
      "Agent",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Confidence Calibration and Rationalization for LLMs via Multi-Agent Deliberation",
    "submit_datetime": "2024年04月15日",
    "abstract": "Uncertainty estimation is a significant issue for current large language models (LLMs) that are generally poorly calibrated and over-confident, especially with reinforcement learning from human feedback (RLHF). Unlike humans, whose decisions and confidences not only stem from intrinsic beliefs but can also be adjusted through daily observations, existing calibration methods for LLMs focus on estimating or eliciting individual confidence without taking full advantage of the \"Collective Wisdom\": the interaction among multiple LLMs that can collectively improve both accuracy and calibration. In this work, we propose Collaborative Calibration, a post-hoc training-free calibration strategy that leverages the collaborative and expressive capabilities of multiple tool-augmented LLM agents in a simulated group deliberation process. We demonstrate the effectiveness of Collaborative Calibration on generative QA tasks across various domains, showing its potential in harnessing the rationalization of collectively calibrated confidence assessments and improving the reliability of model predictions.",
    "pdf_link": "https://arxiv.org/abs/2404.09127",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.09127v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09127/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09127v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09127/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09127v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09127/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09127v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09127/diagrams.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09127v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09127/ablation.png"
      }
    ],
    "abstract_cn": "当前的大型语言模型（LLMs）面临一个重大挑战：不确定性估计。这些模型往往校准不准确且过于自信，尤其是在采用人类反馈进行强化学习（RLHF）时。与人类可以通过日常观察调整决策和信心不同，现有的LLMs校准方法大多忽略了“集体智慧”——即多个LLMs之间的相互作用，这种互动能够共同提升模型的准确性和校准度。本研究提出了一种名为“协同校准”的无需后续训练的校准策略，该策略通过模拟小组讨论过程，充分发挥多个工具辅助的LLM代理的协作和表达能力。我们在不同领域的生成性问答任务中验证了协同校准的有效性，证明了其在提升模型预测可靠性方面的潜力，尤其是在集体校准信心评估的合理化方面。",
    "title_cn": "通过多智能体协商机制，实现大型语言模型的置信度校准与合理化解释",
    "tags": [
      "LLM应用",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Measuring Diversity of Game Scenarios",
    "submit_datetime": "2024年04月15日",
    "abstract": "This survey comprehensively reviews the multi-dimensionality of game scenario diversity, spotlighting the innovative use of procedural content generation and other fields as cornerstones for enriching player experiences through diverse game scenarios. By traversing a wide array of disciplines, from affective modeling and multi-agent systems to psychological studies, our research underscores the importance of diverse game scenarios in gameplay and education. Through a taxonomy of diversity metrics and evaluation methods, we aim to bridge the current gaps in literature and practice, offering insights into effective strategies for measuring and integrating diversity in game scenarios. Our analysis highlights the necessity for a unified taxonomy to aid developers and researchers in crafting more engaging and varied game worlds. This survey not only charts a path for future research in diverse game scenarios but also serves as a handbook for industry practitioners seeking to leverage diversity as a key component of game design and development.",
    "pdf_link": "https://arxiv.org/abs/2404.15192",
    "graphs": [],
    "abstract_cn": "本篇综述深入探讨了游戏情境多样性的多个层面，特别强调了程序化内容生成等创新技术在丰富玩家体验中的关键作用。研究跨越了情感建模、多智能体系统、心理学等多个领域，凸显了游戏情境多样性对于提升游戏体验和教育价值的重要性。通过建立多样性度量的分类体系和评估方法，本研究旨在填补文献与实践之间的空白，为如何有效衡量和融合游戏情境多样性提供策略性见解。分析指出，统一的分类体系对于帮助开发者和研究者创造更具吸引力和变化性的游戏世界至关重要。这项调查不仅为未来游戏情境多样性的研究指明了方向，也为游戏设计和开发行业实践者提供了一本利用多样性作为核心要素的指南。",
    "title_cn": "探索游戏情境的多样性维度",
    "tags": [
      "分类：Agent",
      "游戏设计",
      ""
    ]
  },
  {
    "title": "Benchmarking Llama2, Mistral, Gemma and GPT for Factuality, Toxicity, Bias and Propensity for Hallucinations",
    "submit_datetime": "2024年04月15日",
    "abstract": "This paper introduces fourteen novel datasets for the evaluation of Large Language Models' safety in the context of enterprise tasks. A method was devised to evaluate a model's safety, as determined by its ability to follow instructions and output factual, unbiased, grounded, and appropriate content. In this research, we used OpenAI GPT as point of comparison since it excels at all levels of safety. On the open-source side, for smaller models, Meta Llama2 performs well at factuality and toxicity but has the highest propensity for hallucination. Mistral hallucinates the least but cannot handle toxicity well. It performs well in a dataset mixing several tasks and safety vectors in a narrow vertical domain. Gemma, the newly introduced open-source model based on Google Gemini, is generally balanced but trailing behind. When engaging in back-and-forth conversation (multi-turn prompts), we find that the safety of open-source models degrades significantly. Aside from OpenAI's GPT, Mistral is the only model that still performed well in multi-turn tests.",
    "pdf_link": "https://arxiv.org/abs/2404.09785",
    "graphs": [],
    "abstract_cn": "本论文推出了十四个创新数据集，旨在评估大型语言模型（LLM）在企业任务中的安全性。我们开发了一种评估模型安全性的方法，即模型遵循指令、输出真实、公正、有根据且恰当内容的能力。研究中，我们将 OpenAI GPT 作为安全性能的标杆，因为它在安全性的各个层面上都表现出色。在开源小型模型中，Meta Llama2 在真实性和有害性方面表现优异，但容易产生幻觉。相比之下，Mistral 最少产生幻觉，但对有害内容的处理能力较弱。它在融合了多种任务和安全要素的特定垂直领域的数据集中表现良好。新推出的基于 Google Gemini 的开源模型 Gemma 整体表现均衡，但仍有提升空间。在多轮对话测试中，我们注意到开源模型的安全性显著降低。除了 OpenAI 的 GPT，Mistral 是唯一在多轮对话中仍保持良好表现的模型。",
    "title_cn": "对 Llama2、Mistral、Gemma 以及 GPT 进行性能评估，主要考察它们在事实准确性、有害内容产生、偏见以及产生幻觉的倾向等多个维度上的表现。",
    "tags": [
      "LLM应用",
      "企业安全",
      "人工智能安全"
    ]
  },
  {
    "title": "Cross-Data Knowledge Graph Construction for LLM-enabled Educational Question-Answering System: A~Case~Study~at~HCMUT",
    "submit_datetime": "2024年04月14日",
    "abstract": "In today's rapidly evolving landscape of Artificial Intelligence, large language models (LLMs) have emerged as a vibrant research topic. LLMs find applications in various fields and contribute significantly. Despite their powerful language capabilities, similar to pre-trained language models (PLMs), LLMs still face challenges in remembering events, incorporating new information, and addressing domain-specific issues or hallucinations. To overcome these limitations, researchers have proposed Retrieval-Augmented Generation (RAG) techniques, some others have proposed the integration of LLMs with Knowledge Graphs (KGs) to provide factual context, thereby improving performance and delivering more accurate feedback to user queries.\n  Education plays a crucial role in human development and progress. With the technology transformation, traditional education is being replaced by digital or blended education. Therefore, educational data in the digital environment is increasing day by day. Data in higher education institutions are diverse, comprising various sources such as unstructured/structured text, relational databases, web/app-based API access, etc. Constructing a Knowledge Graph from these cross-data sources is not a simple task. This article proposes a method for automatically constructing a Knowledge Graph from multiple data sources and discusses some initial applications (experimental trials) of KG in conjunction with LLMs for question-answering tasks.",
    "pdf_link": "https://arxiv.org/abs/2404.09296",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.09296v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09296/figure_05_course_withdraw.png"
      }
    ],
    "abstract_cn": "在人工智能迅猛发展的今天，大型语言模型（LLMs）已经成为研究的热点。这些模型在众多领域发挥着重要作用。然而，它们在记忆事件、整合新信息以及处理特定领域的挑战方面，仍面临着与预训练语言模型（PLMs）相似的难题。为解决这些问题，研究者们提出了检索增强生成（RAG）等技术，并探索将LLMs与知识图谱（KGs）结合，以提供准确的事实背景，优化性能并提升对用户查询的反馈精确度。教育对于人类的发展和进步至关重要。随着技术的革新，传统教育正逐渐向数字化或混合式教育转变。在此背景下，高等教育机构中的教育数据日益增长，涵盖了非结构化/结构化文本、关系数据库、网络/应用API接口等多种类型。从这些多样化的数据源中构建知识图谱是一项复杂工作。本文提出了一种自动化构建多源数据知识图谱的方法，并探讨了将知识图谱与LLMs结合在问答任务中的一些初步应用和实验。",
    "title_cn": "构建跨数据知识图谱以赋能大型语言模型（LLM）在教育问答系统中的应用：HCMUT案例研究。",
    "tags": [
      "分类：RAG",
      "",
      "知识图谱"
    ]
  },
  {
    "title": "Knowledgeable Agents by Offline Reinforcement Learning from Large Language Model Rollouts",
    "submit_datetime": "2024年04月14日",
    "abstract": "Reinforcement learning (RL) trains agents to accomplish complex tasks through environmental interaction data, but its capacity is also limited by the scope of the available data. To obtain a knowledgeable agent, a promising approach is to leverage the knowledge from large language models (LLMs). Despite previous studies combining LLMs with RL, seamless integration of the two components remains challenging due to their semantic gap. This paper introduces a novel method, Knowledgeable Agents from Language Model Rollouts (KALM), which extracts knowledge from LLMs in the form of imaginary rollouts that can be easily learned by the agent through offline reinforcement learning methods. The primary challenge of KALM lies in LLM grounding, as LLMs are inherently limited to textual data, whereas environmental data often comprise numerical vectors unseen to LLMs. To address this, KALM fine-tunes the LLM to perform various tasks based on environmental data, including bidirectional translation between natural language descriptions of skills and their corresponding rollout data. This grounding process enhances the LLM's comprehension of environmental dynamics, enabling it to generate diverse and meaningful imaginary rollouts that reflect novel skills. Initial empirical evaluations on the CLEVR-Robot environment demonstrate that KALM enables agents to complete complex rephrasings of task goals and extend their capabilities to novel tasks requiring unprecedented optimal behaviors. KALM achieves a success rate of 46% in executing tasks with unseen goals, substantially surpassing the 26% success rate achieved by baseline methods. Furthermore, KALM effectively enables the LLM to comprehend environmental dynamics, resulting in the generation of meaningful imaginary rollouts that reflect novel skills and demonstrate the seamless integration of large language models and reinforcement learning.",
    "pdf_link": "https://arxiv.org/abs/2404.09248",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.09248v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09248/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09248v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09248/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09248v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09248/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09248v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09248/clevr_demo_begin.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09248v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09248/clevr_demo_end.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09248v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09248/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09248v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09248/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09248v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09248/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09248v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09248/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09248v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09248/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09248v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09248/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09248v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09248/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09248v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09248/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09248v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09248/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09248v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09248/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09248v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09248/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09248v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09248/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09248v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09248/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09248v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09248/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09248v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09248/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09248v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09248/x19.png"
      }
    ],
    "abstract_cn": "强化学习通过与环境的互动数据训练智能体以完成复杂任务，但其所处理的数据量也限制了其能力。要打造一个知识丰富的智能体，一个充满希望的途径是借助大型语言模型（LLMs）的洞见。尽管先前研究已尝试将LLMs与强化学习结合，两者之间的语义差异使得它们的完美融合颇具挑战。本文提出了一种创新方法——语言模型展开的知识智能体（KALM），它能够从LLMs中提取知识，形成易于智能体通过离线强化学习掌握的虚拟展开。KALM面临的主要难题是如何让LLMs与环境数据相匹配，因为LLMs通常只处理文本数据，而环境数据往往包含LLMs未曾接触过的数值向量。为此，KALM对LLMs进行微调，使其能够根据环境数据执行多样化任务，包括技能的自然语言描述与相应的展开数据之间的双向转换。这一匹配过程加深了LLMs对环境变化的理解，使其能够产生多样化且富有洞见的虚拟展开，反映出创新技能。在CLEVR-Robot环境上的初步实证评估显示，KALM能够使智能体完成复杂的任务目标重构，并将其能力拓展到需要全新最优行为的新任务上。KALM在执行未见目标任务时的成功率达到46%，显著超过了基线方法的26%。此外，KALM有效地促进了LLMs对环境动态的理解，生成了富有意义且反映新技能的虚拟展开，实现了大型语言模型与强化学习的和谐融合。",
    "title_cn": "通过利用大型语言模型的离线强化学习，我们培育出了见多识广的智能代理。",
    "tags": [
      "Agent",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Trajeglish: Traffic Modeling as Next-Token Prediction",
    "submit_datetime": "2024年04月14日",
    "abstract": "A longstanding challenge for self-driving development is simulating dynamic driving scenarios seeded from recorded driving logs. In pursuit of this functionality, we apply tools from discrete sequence modeling to model how vehicles, pedestrians and cyclists interact in driving scenarios. Using a simple data-driven tokenization scheme, we discretize trajectories to centimeter-level resolution using a small vocabulary. We then model the multi-agent sequence of discrete motion tokens with a GPT-like encoder-decoder that is autoregressive in time and takes into account intra-timestep interaction between agents. Scenarios sampled from our model exhibit state-of-the-art realism; our model tops the Waymo Sim Agents Benchmark, surpassing prior work along the realism meta metric by 3.3% and along the interaction metric by 9.9%. We ablate our modeling choices in full autonomy and partial autonomy settings, and show that the representations learned by our model can quickly be adapted to improve performance on nuScenes. We additionally evaluate the scalability of our model with respect to parameter count and dataset size, and use density estimates from our model to quantify the saliency of context length and intra-timestep interaction for the traffic modeling task.",
    "pdf_link": "https://arxiv.org/abs/2312.04535",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2312.04535v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.04535/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2312.04535v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.04535/demoplot.png"
      },
      {
        "url": "https://arxiv.org/html/2312.04535v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.04535/demoplot3.png"
      },
      {
        "url": "https://arxiv.org/html/2312.04535v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.04535/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2312.04535v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.04535/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2312.04535v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.04535/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2312.04535v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.04535/manytrial.png"
      },
      {
        "url": "https://arxiv.org/html/2312.04535v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.04535/diagram.png"
      },
      {
        "url": "https://arxiv.org/html/2312.04535v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.04535/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2312.04535v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.04535/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2312.04535v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.04535/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2312.04535v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.04535/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2312.04535v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.04535/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2312.04535v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.04535/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2312.04535v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.04535/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2312.04535v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.04535/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2312.04535v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.04535/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2312.04535v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.04535/demoplot2.png"
      },
      {
        "url": "https://arxiv.org/html/2312.04535v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.04535/demoplot4.png"
      },
      {
        "url": "https://arxiv.org/html/2312.04535v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.04535/compare0004.png"
      },
      {
        "url": "https://arxiv.org/html/2312.04535v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.04535/compare0005.png"
      },
      {
        "url": "https://arxiv.org/html/2312.04535v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.04535/compare0007.png"
      },
      {
        "url": "https://arxiv.org/html/2312.04535v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.04535/compare0016.png"
      }
    ],
    "abstract_cn": "自动驾驶技术发展中的一项长期挑战是如何基于记录的驾驶日志模拟动态驾驶情境。为此，我们采用了离散序列建模的工具来模拟车辆、行人和骑行者在驾驶情境中的相互作用。通过一个简洁的数据驱动标记化方法，我们将轨迹细化至厘米级精度，并利用有限的词汇库进行编码。接着，我们利用类似GPT的编码器-解码器架构，对离散运动标记的序列进行建模，该架构在时间上具有自回归特性，并能够捕捉智能体间的时间步内互动。我们模型生成的情境在真实感上达到了先进水平；在Waymo Sim Agents基准测试中，我们的模型超越了先前的研究，在真实感指标上提升了3.3%，在交互指标上提升了9.9%。我们还全面探讨了在完全自动驾驶和部分自动驾驶环境下的建模决策，并证明了我们模型学习到的表征能够迅速适应并提升在nuScenes上的表现。此外，我们还评估了模型在参数数量和数据集规模上的扩展性，并利用模型的密度估计来量化交通建模任务中上下文长度和时间步内交互的重要性。",
    "title_cn": "Trajeglish：视交通建模为继绀令牌预测的艺术",
    "tags": [
      "Agent",
      "自动驾驶",
      "交通模拟"
    ]
  },
  {
    "title": "Interactive Generative AI Agents for Satellite Networks through a Mixture of Experts Transmission",
    "submit_datetime": "2024年04月13日",
    "abstract": "In response to the needs of 6G global communications, satellite communication networks have emerged as a key solution. However, the large-scale development of satellite communication networks is constrained by the complex system models, whose modeling is challenging for massive users. Moreover, transmission interference between satellites and users seriously affects communication performance. To solve these problems, this paper develops generative artificial intelligence (AI) agents for model formulation and then applies a mixture of experts (MoE) approach to design transmission strategies. Specifically, we leverage large language models (LLMs) to build an interactive modeling paradigm and utilize retrieval-augmented generation (RAG) to extract satellite expert knowledge that supports mathematical modeling. Afterward, by integrating the expertise of multiple specialized components, we propose an MoE-proximal policy optimization (PPO) approach to solve the formulated problem. Each expert can optimize the optimization variables at which it excels through specialized training through its own network and then aggregates them through the gating network to perform joint optimization. The simulation results validate the accuracy and effectiveness of employing a generative agent for problem formulation. Furthermore, the superiority of the proposed MoE-ppo approach over other benchmarks is confirmed in solving the formulated problem. The adaptability of MoE-PPO to various customized modeling problems has also been demonstrated.",
    "pdf_link": "https://arxiv.org/abs/2404.09134",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.09134v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09134/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09134v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09134/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09134v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09134/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09134v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09134/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09134v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09134/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09134v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09134/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09134v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09134/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09134v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09134/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09134v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09134/x9.png"
      }
    ],
    "abstract_cn": "为应对6G全球通信的挑战，卫星通信网络正成为核心解决方案。但这一进程因复杂的系统模型而受阻，大规模用户建模尤为困难。卫星与用户间的传输干扰也对通信质量构成了重大影响。为此，本研究提出了一种基于生成性AI代理的模型构建方法，并采用专家混合（MoE）策略来优化传输方案。我们借助大型语言模型（LLMs）打造交互式模型框架，并运用增强检索生成（RAG）技术提取卫星专家知识以支持数学建模。进一步地，通过融合多个专业模块的专长，我们提出了一种MoE-近端策略优化（PPO）算法来应对这一挑战。每位专家都能通过专门训练优化其擅长的变量，并通过门控网络实现协同优化。模拟实验证实了AI代理在问题构建上的准确性与效率，同时验证了MoE-PPO方法相较于其他基准的优越性。此外，MoE-PPO在多种定制化建模问题上的适应性也得到了充分展示。",
    "title_cn": "通过专家知识融合传输，打造卫星网络中的互动式生成AI代理。",
    "tags": [
      "Agent",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Introducing Super RAGs in Mistral 8x7B-v1",
    "submit_datetime": "2024年04月13日",
    "abstract": "The relentless pursuit of enhancing Large Language Models (LLMs) has led to the advent of Super Retrieval-Augmented Generation (Super RAGs), a novel approach designed to elevate the performance of LLMs by integrating external knowledge sources with minimal structural modifications. This paper presents the integration of Super RAGs into the Mistral 8x7B v1, a state-of-the-art LLM, and examines the resultant improvements in accuracy, speed, and user satisfaction. Our methodology uses a fine-tuned instruct model setup and a cache tuning fork system, ensuring efficient and relevant data retrieval. The evaluation, conducted over several epochs, demonstrates significant enhancements across all metrics. The findings suggest that Super RAGs can effectively augment LLMs, paving the way for more sophisticated and reliable AI systems. This research contributes to the field by providing empirical evidence of the benefits of Super RAGs and offering insights into their potential applications.",
    "pdf_link": "https://arxiv.org/abs/2404.08940",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.08940v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08940/working.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08940v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08940/small_instruct.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08940v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08940/Instruct.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08940v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08940/cache.png"
      }
    ],
    "abstract_cn": "不断追求提升大型语言模型（LLMs）性能，催生了一种创新方法——超级检索增强生成（Super RAGs），它通过最小化结构改动，整合外部知识库以增强LLMs的能力。本文探讨了将Super RAGs集成至尖端的Mistral 8x7B v1 LLM，并评估了其在提升精确度、速度和用户满意度方面的成效。我们采用了微调指令模型和缓存优化系统，以确保数据检索的高效性和相关性。经过多轮测试，我们在所有评估指标上都观察到了显著的进步。研究结果揭示了Super RAGs在增强LLMs方面的潜力，为构建更高级、更可靠的人工智能系统提供了新途径。本研究通过实证数据证明了Super RAGs的优势，并对其可能的应用场景提供了深入见解，为该领域的发展做出了贡献。",
    "title_cn": "Mistral 8x7B-v1 版本中，我们迎来了超级 RAGs 的加入。",
    "tags": [
      "LLM应用",
      "人工智能",
      ""
    ]
  },
  {
    "title": "CuriousLLM: Elevating Multi-Document QA with Reasoning-Infused Knowledge Graph Prompting",
    "submit_datetime": "2024年04月13日",
    "abstract": "In the field of Question Answering (QA), unifying large language models (LLMs) with external databases has shown great success. However, these methods often fall short in providing the advanced reasoning needed for complex QA tasks. To address these issues, we improve over a novel approach called Knowledge Graph Prompting (KGP), which combines knowledge graphs with a LLM-based agent to improve reasoning and search accuracy. Nevertheless, the original KGP framework necessitates costly fine-tuning with large datasets yet still suffers from LLM hallucination. Therefore, we propose a reasoning-infused LLM agent to enhance this framework. This agent mimics human curiosity to ask follow-up questions to more efficiently navigate the search. This simple modification significantly boosts the LLM performance in QA tasks without the high costs and latency associated with the initial KGP framework. Our ultimate goal is to further develop this approach, leading to more accurate, faster, and cost-effective solutions in the QA domain.",
    "pdf_link": "https://arxiv.org/abs/2404.09077",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.09077v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09077/questions.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09077v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09077/workflow.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09077v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09077/combined_performance_metrics.png"
      }
    ],
    "abstract_cn": "在问答技术的发展中，将大型语言模型（LLMs）与外部数据库融合的方法已经取得了显著成效。但这种方法在处理需要复杂推理能力的QA任务时，往往力有不逮。为克服这些挑战，我们对一种创新的方法——知识图谱提示（KGP）进行了优化。该方法通过将知识图谱与基于LLM的智能体相结合，有效提升了推理和搜索的精确度。尽管如此，传统的KGP框架仍需大量数据集进行昂贵的微调，并且难以摆脱LLM产生幻觉的问题。为此，我们设计了一个融入推理能力的LLM智能体，以强化这一框架。该智能体能够像人类一样好奇，通过追问来更高效地引导搜索过程。这一改进显著提升了LLM在QA任务中的表现，同时避免了KGP框架的高昂成本和延迟。我们的目标是继续完善这一方法，以期在QA领域提供更精准、迅速且经济的解决方案。",
    "title_cn": "CuriousLLM：融入推理知识图谱的提示，提升多文档问答的智能水平",
    "tags": [
      "Agent",
      "问答系统",
      "知识图谱"
    ]
  },
  {
    "title": "Do LLMs Play Dice? Exploring Probability Distribution Sampling in Large Language Models for Behavioral Simulation",
    "submit_datetime": "2024年04月13日",
    "abstract": "With the rapid advancement of large language models (LLMs) and their remarkable capabilities in handling complex language tasks, an increasing number of studies are employing LLMs as agents to emulate the sequential decision-making processes of humans often represented as Markov decision-making processes (MDPs). The actions within this decision-making framework adhere to specific probability distributions and require iterative sampling. This arouses our curiosity regarding the capacity of LLM agents to comprehend probability distributions, thereby guiding the agent's behavioral decision-making through probabilistic sampling and generating behavioral sequences. To answer the above question, we divide the problem into two main aspects: simulation where the exact probability distribution is known, and generation of sequences where the probability distribution is ambiguous. In the first case, the agent is required to give the type and parameters of the probability distribution through the problem description, and then give the sampling sequence. However, our analysis shows that LLM agents perform poorly in this case, but the sampling success rate can be improved through programming tools. Real-world scenarios often entail unknown probability distributions. Thus, in the second case, we ask the agents to change the activity level in online social networks and analyze the frequency of actions. Ultimately, our analysis shows that LLM agents cannot sample probability distributions even using programming tools. Therefore, careful consideration is still required before directly applying LLM agents as agents to simulate human behavior.",
    "pdf_link": "https://arxiv.org/abs/2404.09043",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.09043v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09043/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09043v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09043/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09043v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09043/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09043v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09043/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09043v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09043/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09043v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09043/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09043v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09043/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09043v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09043/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09043v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09043/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09043v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09043/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09043v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09043/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09043v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09043/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09043v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09043/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09043v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09043/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09043v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09043/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09043v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09043/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09043v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09043/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09043v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09043/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2404.09043v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.09043/x19.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）在处理复杂语言任务上的显著进步，促使众多研究将其作为模拟人类顺序决策过程（常以马尔可夫决策过程，MDPs表示）的代理。这些决策过程中的行动基于特定的概率分布，需通过迭代抽样来确定。这引发了我们对LLM代理能否理解概率分布，并以此指导其行为决策和生成行为序列的兴趣。为探究此问题，我们将研究分为两个方面：一是在已知确切概率分布的模拟中，代理需根据问题描述确定概率分布的类型和参数，然后生成抽样序列；二是在概率分布不明确的情况下生成序列。在第一种情况下，尽管LLM代理表现不佳，但通过编程工具可以提升其抽样成功率。然而，在第二种情况下，即使借助编程工具，LLM代理也无法准确抽样概率分布。因此，在将LLM代理直接应用于模拟人类行为之前，我们必须审慎考虑。",
    "title_cn": "大型语言模型（LLM）是否遵循随机性原则？本文深入探讨了在这些模型中运用概率分布抽样技术以进行行为模拟的可能性。",
    "tags": [
      "Agent",
      "人工智能",
      "决策过程"
    ]
  },
  {
    "title": "X-Eval: Generalizable Multi-aspect Text Evaluation via Augmented Instruction Tuning with Auxiliary Evaluation Aspects",
    "submit_datetime": "2024年04月13日",
    "abstract": "Natural Language Generation (NLG) typically involves evaluating the generated text in various aspects (e.g., consistency and naturalness) to obtain a comprehensive assessment. However, multi-aspect evaluation remains challenging as it may require the evaluator to generalize to any given evaluation aspect even if it's absent during training. In this paper, we introduce X-Eval, a two-stage instruction tuning framework to evaluate the text in both seen and unseen aspects customized by end users. X-Eval consists of two learning stages: the vanilla instruction tuning stage that improves the model's ability to follow evaluation instructions, and an enhanced instruction tuning stage that exploits the connections between fine-grained evaluation aspects to better assess text quality. To support the training of X-Eval, we collect AspectInstruct, the first instruction tuning dataset tailored for multi-aspect NLG evaluation spanning 27 diverse evaluation aspects with 65 tasks. To enhance task diversity, we devise an augmentation strategy that converts human rating annotations into diverse forms of NLG evaluation tasks, including scoring, comparison, ranking, and Boolean question answering. Extensive experiments across three essential categories of NLG tasks: dialogue generation, summarization, and data-to-text coupled with 21 aspects in meta-evaluation, demonstrate that our X-Eval enables even a lightweight language model to achieve a comparable if not higher correlation with human judgments compared to the state-of-the-art NLG evaluators, such as GPT-4.",
    "pdf_link": "https://arxiv.org/abs/2311.08788",
    "graphs": [],
    "abstract_cn": "自然语言生成（NLG）任务的评估往往需要从多个维度（如文本的连贯性和自然度）对生成的文本进行综合考量。但这种多维度的评估方法颇具挑战，因为它要求评估者即使在训练阶段未接触到某些评估维度，也需对其进行泛化评估。本文提出了X-Eval，这是一个分两阶段的指令调优框架，旨在评估文本在用户自定义的已知和未知维度上的表现。X-Eval包含两个学习阶段：基础的指令调优阶段，旨在提升模型遵循评估指令的能力；以及进阶的指令调优阶段，通过挖掘细粒度评估维度之间的联系，更准确地评估文本质量。为训练X-Eval，我们创建了AspectInstruct数据集，这是首个专为多维度NLG评估设计的指令调优数据集，覆盖了27个不同的评估维度和65个任务。为增加任务多样性，我们采用了一种增强策略，将人工评分注释转换成多样的NLG评估任务形式，包括评分、比较、排序和布尔问题解答。通过在对话生成、摘要和数据到文本这三个关键NLG任务类别上的广泛实验，以及元评估中的21个维度，我们证明了X-Eval能够使即使是轻量级语言模型也能与最先进的NLG评估器（例如GPT-4）相媲美，甚至在与人类判断的相关性上更胜一筹。",
    "title_cn": "X-Eval：一种通过增强指令调整和辅助评估维度，实现文本多方面评估的通用方法。",
    "tags": [
      "LLM应用",
      "",
      "评估框架"
    ]
  },
  {
    "title": "Generative AI Agent for Next-Generation MIMO Design: Fundamentals, Challenges, and Vision",
    "submit_datetime": "2024年04月12日",
    "abstract": "Next-generation multiple input multiple output (MIMO) is expected to be intelligent and scalable. In this paper, we study generative artificial intelligence (AI) agent-enabled next-generation MIMO design. Firstly, we provide an overview of the development, fundamentals, and challenges of the next-generation MIMO. Then, we propose the concept of the generative AI agent, which is capable of generating tailored and specialized contents with the aid of large language model (LLM) and retrieval augmented generation (RAG). Next, we comprehensively discuss the features and advantages of the generative AI agent framework. More importantly, to tackle existing challenges of next-generation MIMO, we discuss generative AI agent-enabled next-generation MIMO design, from the perspective of performance analysis, signal processing, and resource allocation. Furthermore, we present two compelling case studies that demonstrate the effectiveness of leveraging the generative AI agent for performance analysis in complex configuration scenarios. These examples highlight how the integration of generative AI agents can significantly enhance the analysis and design of next-generation MIMO systems. Finally, we discuss important potential research future directions.",
    "pdf_link": "https://arxiv.org/abs/2404.08878",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.08878v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08878/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08878v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08878/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08878v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08878/x5.png"
      }
    ],
    "abstract_cn": "预计新一代多输入多输出（MIMO）技术将具备智能化和可扩展性。本文深入探讨了由生成性人工智能（AI）代理驱动的新一代MIMO设计。文章首先回顾了新一代MIMO技术的发展历程、基本原理及其面临的挑战。随后，提出了一种新型的生成性AI代理，该代理结合了大型语言模型（LLM）和检索增强生成（RAG）技术，能够生成定制化和专业化的内容。文章进一步详细阐述了生成性AI代理框架的特性和优势，并针对新一代MIMO技术面临的挑战，从性能分析、信号处理和资源分配等多个维度进行了深入讨论。此外，文中还展示了两个案例研究，证明了在复杂配置环境中，利用生成性AI代理进行性能分析的有效性。这些案例凸显了将生成性AI代理整合进系统，可以显著提升新一代MIMO系统的分析和设计水平。文末，作者提出了未来研究的重要潜在方向。",
    "title_cn": "为下一代多输入多输出（MIMO）设计而生的创造性人工智能代理：探索其基本原理、面临的挑战以及未来的发展方向。",
    "tags": [
      "Agent",
      "",
      "人工智能"
    ]
  },
  {
    "title": "LlamaTouch: A Faithful and Scalable Testbed for Mobile UI Automation Task Evaluation",
    "submit_datetime": "2024年04月12日",
    "abstract": "The emergent large language/multimodal models facilitate the evolution of mobile agents, especially in the task of mobile UI automation. However, existing evaluation approaches, which rely on human validation or established datasets to compare agent-predicted actions with predefined ones, are unscalable and unfaithful. To overcome these limitations, this paper presents LlamaTouch, a testbed for on-device agent execution and faithful, scalable agent evaluation. By observing that the task execution process only transfers UI states, LlamaTouch employs a novel evaluation approach that only assesses whether an agent traverses all manually annotated, essential application/system states. LlamaTouch comprises three key techniques: (1) On-device task execution that enables mobile agents to interact with real mobile environments for task completion. (2) Fine-grained UI component annotation that merges pixel-level screenshots and textual screen hierarchies to explicitly identify and precisely annotate essential UI components with a rich set of designed annotation primitives. (3) A multi-level state matching algorithm that utilizes exact and fuzzy matching to accurately detect critical information in each screen with unpredictable UI layout/content dynamics. LlamaTouch currently incorporates four mobile agents and 495 UI automation tasks, encompassing both tasks in the widely-used datasets and our self-constructed ones for more diverse mobile applications. Evaluation results demonstrate the LlamaTouch's high faithfulness of evaluation in real environments and its better scalability than human validation. LlamaTouch also enables easy task annotation and integration of new mobile agents. Code and dataset are publicly available at https://github.com/LlamaTouch/LlamaTouch.",
    "pdf_link": "https://arxiv.org/abs/2404.16054",
    "graphs": [],
    "abstract_cn": "随着大型语言/多模态模型的出现，移动代理的进化，尤其是在移动用户界面(UI)自动化任务中，得到了显著推动。然而，目前依赖人工验证或现有数据集的评估方法存在扩展性差和准确性不足的问题。为了解决这一难题，本文介绍了 LlamaTouch，这是一个在设备上执行代理操作并进行准确、可扩展评估的测试平台。LlamaTouch 创新地仅关注任务执行过程中的 UI 状态转移，通过评估代理是否成功遍历了所有关键的、手动标注的应用/系统状态。该平台采用了三项核心技术：(1) 设备上的实时任务执行，让移动代理能够与真实移动环境互动完成任务；(2) 精细的 UI 组件标注，结合像素级截图和文本化屏幕层级，精确识别并标注关键 UI 组件；(3) 多级状态匹配算法，结合精确匹配和模糊匹配技术，准确捕捉每个屏幕中的关键信息，即使在 UI 布局和内容动态变化的情况下。LlamaTouch 已集成四种移动代理和 495 项 UI 自动化任务，不仅涵盖了广泛使用的公共数据集，还包括我们为多样化移动应用自建的任务。评估结果显示，LlamaTouch 在真实环境中的评估准确性高，且相较于人工验证，具有更好的可扩展性。此外，LlamaTouch 还简化了任务标注流程，并支持新移动代理的轻松集成。相关代码和数据集已在 https://github.com/LlamaTouch/LlamaTouch 上公开发布。",
    "title_cn": "LlamaTouch：一个忠实且可扩展的移动用户界面自动化任务评估测试平台。",
    "tags": [
      "Agent",
      "移动应用测试",
      "自动化测试"
    ]
  },
  {
    "title": "\"Don't forget to put the milk back!\" Dataset for Enabling Embodied Agents to Detect Anomalous Situations",
    "submit_datetime": "2024年04月12日",
    "abstract": "Home robots intend to make their users lives easier. Our work assists in this goal by enabling robots to inform their users of dangerous or unsanitary anomalies in their home. Some examples of these anomalies include the user leaving their milk out, forgetting to turn off the stove, or leaving poison accessible to children. To move towards enabling home robots with these abilities, we have created a new dataset, which we call SafetyDetect. The SafetyDetect dataset consists of 1000 anomalous home scenes, each of which contains unsafe or unsanitary situations for an agent to detect. Our approach utilizes large language models (LLMs) alongside both a graph representation of the scene and the relationships between the objects in the scene. Our key insight is that this connected scene graph and the object relationships it encodes enables the LLM to better reason about the scene -- especially as it relates to detecting dangerous or unsanitary situations. Our most promising approach utilizes GPT-4 and pursues a categorization technique where object relations from the scene graph are classified as normal, dangerous, unsanitary, or dangerous for children. This method is able to correctly identify over 90% of anomalous scenarios in the SafetyDetect Dataset. Additionally, we conduct real world experiments on a ClearPath TurtleBot where we generate a scene graph from visuals of the real world scene, and run our approach with no modification. This setup resulted in little performance loss. The SafetyDetect Dataset and code will be released to the public upon this papers publication.",
    "pdf_link": "https://arxiv.org/abs/2404.08827",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.08827v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08827/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08827v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08827/Qualitative.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08827v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08827/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08827v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08827/x3.png"
      }
    ],
    "abstract_cn": "家用机器人的使命是简化我们的生活。本研究通过赋予机器人监测家中潜在危险或卫生问题的能力，助力这一使命。例如，提醒用户牛奶未冷藏、炉火未关或有毒物品被儿童触及等情况。为实现这一目标，我们开发了名为SafetyDetect的新型数据集，包含1000个包含安全隐患或卫生问题的异常家庭场景。我们的研究方法结合了大型语言模型（LLMs）以及场景的图形表示和物体间的关系。核心洞见在于，通过场景图中的物体关系，LLMs能更准确地理解和推理场景，尤其是在识别危险或不卫生情况方面。我们采用的最有前景的方法是利用GPT-4，通过将场景图中的物体关系分类为正常、危险、不卫生或儿童危险，以识别异常情况。这一方法在SafetyDetect数据集上的识别准确率超过90%。此外，我们在ClearPath TurtleBot上进行了实地测试，通过实景视觉生成场景图，并直接应用我们的算法，结果性能仅略有下降。随着本文的发表，SafetyDetect数据集和相关代码将向公众开放。",
    "title_cn": "\"别忘了把牛奶放回冰箱！\" 这个数据集旨在帮助具身智能体识别异常状况。",
    "tags": [
      "Agent",
      "家庭安全",
      "机器人技术"
    ]
  },
  {
    "title": "Inverse Kinematics for Neuro-Robotic Grasping with Humanoid Embodied Agents",
    "submit_datetime": "2024年04月12日",
    "abstract": "This paper introduces a novel zero-shot motion planning method that allows users to quickly design smooth robot motions in Cartesian space. A Bézier curve-based Cartesian plan is transformed into a joint space trajectory by our neuro-inspired inverse kinematics (IK) method CycleIK, for which we enable platform independence by scaling it to arbitrary robot designs. The motion planner is evaluated on the physical hardware of the two humanoid robots NICO and NICOL in a human-in-the-loop grasping scenario. Our method is deployed with an embodied agent that is a large language model (LLM) at its core. We generalize the embodied agent, that was introduced for NICOL, to also be embodied by NICO. The agent can execute a discrete set of physical actions and allows the user to verbally instruct various different robots. We contribute a grasping primitive to its action space that allows for precise manipulation of household objects. The new CycleIK method is compared to popular numerical IK solvers and state-of-the-art neural IK methods in simulation and is shown to be competitive with or outperform all evaluated methods when the algorithm runtime is very short. The grasping primitive is evaluated on both NICOL and NICO robots with a reported grasp success of 72% to 82% for each robot, respectively.",
    "pdf_link": "https://arxiv.org/abs/2404.08825",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.08825v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08825/x1.jpg"
      },
      {
        "url": "https://arxiv.org/html/2404.08825v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08825/generator_alt_.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08825v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08825/cycle_ik_overview__.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08825v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08825/nico_trajectory_top_.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08825v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08825/nico_nicol_grasp_success_alt___.png"
      }
    ],
    "abstract_cn": "本研究提出了一种创新的零样本运动规划技术，它使得用户能够迅速在笛卡尔空间内规划出流畅的机器人动作。这种基于贝塞尔曲线的规划被我们的神经网络启发式逆运动学（IK）算法 CycleIK 转化为关节空间路径，并通过适配任意机器人设计实现了平台通用性。该运动规划系统在两个人形机器人 NICO 和 NICOL 上进行了实际测试，测试环境为包含人类操作的抓取任务。我们采用的具身代理核心是一个大型语言模型（LLM），并将其从 NICOL 扩展至 NICO。该代理能够执行一系列离散的物理动作，使用户能够通过语音指令控制多种不同的机器人。我们还为其动作库新增了一个抓取基本动作，以便对家用物品进行精细操控。在模拟环境中，CycleIK 与传统的数值 IK 解算器和先进的神经网络 IK 方法进行了比较，结果表明，在算法运行时间极短的情况下，CycleIK 能够与之竞争或取得更佳表现。此外，抓取基本动作在 NICOL 和 NICO 机器人上的测试结果显示，每台机器人的抓取成功率分别为 72% 到 82%。",
    "title_cn": "逆动力学在仿人机器人抓取任务中的应用，特别是与神经机器人结合时的实现。",
    "tags": [
      "Agent",
      "机器人技术",
      "运动规划"
    ]
  },
  {
    "title": "Training a Vision Language Model as Smartphone Assistant",
    "submit_datetime": "2024年04月12日",
    "abstract": "Addressing the challenge of a digital assistant capable of executing a wide array of user tasks, our research focuses on the realm of instruction-based mobile device control. We leverage recent advancements in large language models (LLMs) and present a visual language model (VLM) that can fulfill diverse tasks on mobile devices. Our model functions by interacting solely with the user interface (UI). It uses the visual input from the device screen and mimics human-like interactions, encompassing gestures such as tapping and swiping. This generality in the input and output space allows our agent to interact with any application on the device. Unlike previous methods, our model operates not only on a single screen image but on vision-language sentences created from sequences of past screenshots along with corresponding actions. Evaluating our method on the challenging Android in the Wild benchmark demonstrates its promising efficacy and potential.",
    "pdf_link": "https://arxiv.org/abs/2404.08755",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.08755v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08755/x1.png"
      }
    ],
    "abstract_cn": "本研究旨在解决数字助手执行多种用户任务的挑战，特别是在基于指令的移动设备控制方面。借助大型语言模型（LLMs）的最新进展，我们推出了一款视觉语言模型（VLM），能够应对移动设备上的多样化任务。该模型通过与用户界面（UI）的互动来执行操作，利用设备屏幕的视觉输入，模拟人类的交互方式，如轻触和滑动等。这种设计使得我们的模型能够与设备上的所有应用程序进行互动。与传统方法相比，我们的模型不仅处理单个屏幕图像，还能处理由连续的屏幕截图序列及其对应动作生成的视觉-语言句子。在Android in the Wild这一具有挑战性的基准测试中，我们的方法展现了其显著的效率和潜力。",
    "title_cn": "打造一款视觉语言模型，助力智能手机成为你的得力助手。",
    "tags": [
      "Agent",
      "移动设备控制",
      "人工智能"
    ]
  },
  {
    "title": "Enhancing Autonomous Vehicle Training with Language Model Integration and Critical Scenario Generation",
    "submit_datetime": "2024年04月12日",
    "abstract": "This paper introduces CRITICAL, a novel closed-loop framework for autonomous vehicle (AV) training and testing. CRITICAL stands out for its ability to generate diverse scenarios, focusing on critical driving situations that target specific learning and performance gaps identified in the Reinforcement Learning (RL) agent. The framework achieves this by integrating real-world traffic dynamics, driving behavior analysis, surrogate safety measures, and an optional Large Language Model (LLM) component. It is proven that the establishment of a closed feedback loop between the data generation pipeline and the training process can enhance the learning rate during training, elevate overall system performance, and augment safety resilience. Our evaluations, conducted using the Proximal Policy Optimization (PPO) and the HighwayEnv simulation environment, demonstrate noticeable performance improvements with the integration of critical case generation and LLM analysis, indicating CRITICAL's potential to improve the robustness of AV systems and streamline the generation of critical scenarios. This ultimately serves to hasten the development of AV agents, expand the general scope of RL training, and ameliorate validation efforts for AV safety.",
    "pdf_link": "https://arxiv.org/abs/2404.08570",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.08570v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08570/Banner.jpg"
      },
      {
        "url": "https://arxiv.org/html/2404.08570v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08570/Scenario_Diagram.jpg"
      },
      {
        "url": "https://arxiv.org/html/2404.08570v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08570/Architecture.jpg"
      },
      {
        "url": "https://arxiv.org/html/2404.08570v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08570/loss_plot.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08570v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08570/risk_metrics.png"
      }
    ],
    "abstract_cn": "本文提出了 CRITICAL，一个创新的闭环系统，专为自动驾驶车辆（AV）的训练与测试设计。CRITICAL 的特色在于其能够创造出多样化的驾驶情境，特别关注那些针对强化学习（RL）代理中发现的学习与性能缺陷的关键驾驶时刻。该系统通过融合现实交通流动、驾驶行为解析、替代性安全指标，以及一个可选的大规模语言模型（LLM）模块来实现这一点。研究证实，数据生成流程与训练过程之间的闭环反馈机制能够提升训练效率，增强系统性能，并提高安全防护能力。通过近端策略优化（PPO）算法和 HighwayEnv 仿真环境的测试，我们发现结合关键案例生成和 LLM 分析可以显著提升性能，这表明 CRITICAL 在增强 AV 系统鲁棒性、优化关键情境生成以及加速 AV 代理开发和 RL 训练范围扩展方面具有巨大潜力，同时也有助于提高 AV 安全性的验证效率。",
    "title_cn": "融入语言模型并生成关键场景，提升自动驾驶车辆的训练效果。",
    "tags": [
      "Agent",
      "自动驾驶",
      "机器学习"
    ]
  },
  {
    "title": "Strategic Interactions between Large Language Models-based Agents in Beauty Contests",
    "submit_datetime": "2024年04月12日",
    "abstract": "The growing adoption of large language models (LLMs) presents substantial potential for deeper understanding of human behaviours within game theory frameworks through simulations. Leveraging on the diverse pool of LLM types and addressing the gap in research on competitive games, this paper examines the strategic interactions among multiple types of LLM-based agents in a classical game of beauty contest. Drawing parallels to experiments involving human subjects, LLM-based agents are assessed similarly in terms of strategic levels. They demonstrate varying depth of reasoning that falls within a range of level-0 and 1, and show convergence in actions in repeated settings. Furthermore, I also explore how variations in group composition of agent types influence strategic behaviours, where I found higher proportion of fixed-strategy opponents enhances convergence for LLM-based agents, and having a mixed environment with agents of differing relative strategic levels accelerates convergence for all agents. There could also be higher average payoffs for the more intelligent agents, albeit at the expense of the less intelligent agents. These results not only provide insights into outcomes for simulated agents under specified scenarios, it also offer valuable implications for understanding strategic interactions between algorithms.",
    "pdf_link": "https://arxiv.org/abs/2404.08492",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.08492v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08492/histogram_of_choices_multillm.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08492v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08492/same_upperbound_c.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08492v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08492/mean_strategic_level_reference_average_c.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08492v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08492/fig2_mixed_one_shot_c.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08492v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08492/mean_payoffs_c.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08492v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08492/period1_average_n_c.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08492v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08492/average_normalized_chosen_number.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08492v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08492/freq_choices_6periods.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08492v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08492/freq_n_6periods.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08492v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08492/average_n_across_sessions_n.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08492v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08492/average_payoffs_across_periods.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08492v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08492/fixed_strategy_choices.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08492v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08492/fixed_strategy_choices_weak.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08492v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08492/fixed_strategy_convergence_rates.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08492v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08492/fixed_strategy_convergence_rates_weak.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08492v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08492/fixed_strategy_n_values.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08492v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08492/fixed_strategy_n_values_weak.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08492v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08492/payoffs_set_up1_static.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08492v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08492/payoffs_set_up2_static.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08492v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08492/payoffs_set_up3_static.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08492v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08492/payoffs_set_up1_static_weak.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08492v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08492/payoffs_set_up2_static_weak.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08492v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08492/payoffs_set_up3_static_weak.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08492v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08492/setup1_mixedllm_choices.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08492v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08492/setup2_mixedllm_choices.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08492v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08492/setup3_mixedllm_choices.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08492v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08492/setup4_mixedllm_choices.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08492v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08492/setup5_mixedllm_choices.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08492v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08492/convergence_mixedllm.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08492v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08492/n_values_mixedllm1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08492v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08492/n_values_mixedllm2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08492v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08492/payoffs_mixedllm_setup1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08492v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08492/payoffs_mixedllm_setup2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08492v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08492/payoffs_mixedllm_setup3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08492v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08492/payoffs_mixedllm_setup4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08492v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08492/payoffs_mixedllm_setup5.png"
      }
    ],
    "abstract_cn": "随着大型语言模型（LLMs）的广泛应用，我们有机会通过模拟更深入地洞察博弈论框架下的人类行为模式。本文聚焦于竞争性游戏研究的缺口，通过经典选美比赛这一经典游戏，探讨了基于LLM的多种智能体之间的战略互动。与人类参与者的实验相比较，这些基于LLM的智能体在战略层面上得到了类似的评估，展现出从0级到1级的不同程度的推理能力，并在多次重复的情境中趋于行动一致。研究还发现，智能体群体构成的变化对战略行为有显著影响：固定策略对手比例的提高有助于基于LLM的智能体更快趋同，而不同战略水平智能体混合的环境则能加速所有智能体的趋同过程。此外，智能体的智能程度越高，其平均收益也越高，尽管这可能会牺牲那些智能程度较低的智能体的利益。这些发现不仅为特定情境下模拟智能体的行为结果提供了深刻见解，同时也为理解算法间的战略互动提供了重要的启示。",
    "title_cn": "在选美比赛中，基于大型语言模型的智能体之间的策略互动。",
    "tags": [
      "Agent",
      "博弈论",
      "人工智能"
    ]
  },
  {
    "title": "LLMSat: A Large Language Model-Based Goal-Oriented Agent for Autonomous Space Exploration",
    "submit_datetime": "2024年04月12日",
    "abstract": "As spacecraft journey further from Earth with more complex missions, systems of greater autonomy and onboard intelligence are called for. Reducing reliance on human-based mission control becomes increasingly critical if we are to increase our rate of solar-system-wide exploration. Recent work has explored AI-based goal-oriented systems to increase the level of autonomy in mission execution. These systems make use of symbolic reasoning managers to make inferences from the state of a spacecraft and a handcrafted knowledge base, enabling autonomous generation of tasks and re-planning. Such systems have proven to be successful in controlled cases, but they are difficult to implement as they require human-crafted ontological models to allow the spacecraft to understand the world. Reinforcement learning has been applied to train robotic agents to pursue a goal. A new architecture for autonomy is called for. This work explores the application of Large Language Models (LLMs) as the high-level control system of a spacecraft. Using a systems engineering approach, this work presents the design and development of an agentic spacecraft controller by leveraging an LLM as a reasoning engine, to evaluate the utility of such an architecture in achieving higher levels of spacecraft autonomy. A series of deep space mission scenarios simulated within the popular game engine Kerbal Space Program (KSP) are used as case studies to evaluate the implementation against the requirements. It is shown the reasoning and planning abilities of present-day LLMs do not scale well as the complexity of a mission increases, but this can be alleviated with adequate prompting frameworks and strategic selection of the agent's level of authority over the host spacecraft. This research evaluates the potential of LLMs in augmenting autonomous decision-making systems for future robotic space applications.",
    "pdf_link": "https://arxiv.org/abs/2405.01392",
    "graphs": [],
    "abstract_cn": "随着航天器远离地球，执行更为复杂的任务，我们迫切需要更高度的自主性和智能化的系统。为了加快对太阳系的探索步伐，减少对地面任务控制的依赖变得至关重要。近期研究已经开始探索基于人工智能的目标导向系统，以提升任务执行的自主化水平。这些系统通过符号推理管理器，结合手工构建的知识库，从航天器当前状态中进行推断，实现任务的自动生成与重新规划。尽管在特定条件下这些系统表现出色，但由于它们依赖于人工构建的本体模型，使得航天器能够理解外部世界，因此实施起来颇具挑战。强化学习已被用于训练机器人代理以达成特定目标，但为了进一步提升自主性，我们需要一种全新的架构。本研究探讨了将大型语言模型（LLMs）应用于航天器高级控制系统的可能性。通过系统工程的方法，本研究设计并开发了一种航天器控制器，该控制器利用LLM作为推理引擎，以评估这种架构在提升航天器自主性方面的潜力。通过在广受欢迎的游戏引擎Kerbal Space Program（KSP）中模拟一系列深空任务场景，作为案例研究，来评估该架构的实施效果。研究显示，尽管当前的LLMs在任务复杂度提升时推理和规划能力存在局限，但通过恰当的提示框架和策略性地选择代理对航天器的控制权限，可以显著改善这一问题。本研究进一步评估了LLMs在未来机器人太空探索中增强自主决策系统的潜力。",
    "title_cn": "LLMSat，一款基于大型语言模型的智能代理，专为自主太空探索任务而设计。",
    "tags": [
      "Agent",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Reducing hallucination in structured outputs via Retrieval-Augmented Generation",
    "submit_datetime": "2024年04月11日",
    "abstract": "A common and fundamental limitation of Generative AI (GenAI) is its propensity to hallucinate. While large language models (LLM) have taken the world by storm, without eliminating or at least reducing hallucinations, real-world GenAI systems may face challenges in user adoption. In the process of deploying an enterprise application that produces workflows based on natural language requirements, we devised a system leveraging Retrieval Augmented Generation (RAG) to greatly improve the quality of the structured output that represents such workflows. Thanks to our implementation of RAG, our proposed system significantly reduces hallucinations in the output and improves the generalization of our LLM in out-of-domain settings. In addition, we show that using a small, well-trained retriever encoder can reduce the size of the accompanying LLM, thereby making deployments of LLM-based systems less resource-intensive.",
    "pdf_link": "https://arxiv.org/abs/2404.08189",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.08189v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08189/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08189v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08189/t2f_architecture.jpg"
      },
      {
        "url": "https://arxiv.org/html/2404.08189v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08189/t2f_input_output_example.jpg"
      },
      {
        "url": "https://arxiv.org/html/2404.08189v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08189/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08189v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08189/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08189v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08189/x4.png"
      }
    ],
    "abstract_cn": "生成性AI（GenAI）普遍存在的一大挑战是其易产生幻觉的特性。尽管大型语言模型（LLM）已经风靡全球，但如果不减少幻觉现象，GenAI在实际应用中可能会遭遇用户接受度的难题。在开发一款根据自然语言需求生成工作流程的企业级应用时，我们构建了一个系统，该系统采用检索增强生成（RAG）技术显著提升了所生成工作流程的结构化输出质量。得益于RAG的运用，我们的系统显著降低了输出中的幻觉现象，增强了LLM在非专业领域的泛化能力。此外，我们还发现，采用一个小型但训练精良的检索器编码器，可以有效减少所需LLM的规模，从而降低了部署基于LLM系统所需的资源。",
    "title_cn": "利用检索增强生成技术，有效降低结构化输出中的幻觉问题。",
    "tags": [
      "分类：RAG",
      "企业应用",
      "人工智能"
    ]
  },
  {
    "title": "ResearchAgent: Iterative Research Idea Generation over Scientific Literature with Large Language Models",
    "submit_datetime": "2024年04月11日",
    "abstract": "Scientific Research, vital for improving human life, is hindered by its inherent complexity, slow pace, and the need for specialized experts. To enhance its productivity, we propose a ResearchAgent, a large language model-powered research idea writing agent, which automatically generates problems, methods, and experiment designs while iteratively refining them based on scientific literature. Specifically, starting with a core paper as the primary focus to generate ideas, our ResearchAgent is augmented not only with relevant publications through connecting information over an academic graph but also entities retrieved from an entity-centric knowledge store based on their underlying concepts, mined and shared across numerous papers. In addition, mirroring the human approach to iteratively improving ideas with peer discussions, we leverage multiple ReviewingAgents that provide reviews and feedback iteratively. Further, they are instantiated with human preference-aligned large language models whose criteria for evaluation are derived from actual human judgments. We experimentally validate our ResearchAgent on scientific publications across multiple disciplines, showcasing its effectiveness in generating novel, clear, and valid research ideas based on human and model-based evaluation results.",
    "pdf_link": "https://arxiv.org/abs/2404.07738",
    "graphs": [],
    "abstract_cn": "科学研究对于提升人类生活质量至关重要，但其复杂性、缓慢的进展和对专家的依赖限制了其效率。为了提升科研生产力，我们设计了一个名为“研究代理”的智能写作助手，它由大型语言模型提供支持，能够自动生成问题、方法和实验设计，并通过科学文献不断迭代优化。该代理以一篇核心论文为起点，生成研究思路，并通过学术网络连接相关文献，以及从一个以实体为中心的知识库中检索与论文概念相关的实体，这些实体在多篇论文中被挖掘和共享。同时，借鉴人类通过同行评审不断改进研究思路的做法，我们引入了多个“审稿代理”，它们提供连续的评审和反馈。这些审稿代理是基于与人类偏好一致的大型语言模型构建的，其评审标准来源于实际的人类评价。我们在多个学科领域对“研究代理”进行了实验验证，结果表明，它在生成新颖、清晰且有效的研究构想方面具有显著效果，这一效果得到了人类评审和模型评估的双重认可。",
    "title_cn": "ResearchAgent：借助大型语言模型，对科学文献进行迭代式的研究创意生成",
    "tags": [
      "分类：Agent",
      "科学研究",
      "自动化写作"
    ]
  },
  {
    "title": "Rumour Evaluation with Very Large Language Models",
    "submit_datetime": "2024年04月11日",
    "abstract": "Conversational prompt-engineering-based large language models (LLMs) have enabled targeted control over the output creation, enhancing versatility, adaptability and adhoc retrieval. From another perspective, digital misinformation has reached alarming levels. The anonymity, availability and reach of social media offer fertile ground for rumours to propagate. This work proposes to leverage the advancement of prompting-dependent LLMs to combat misinformation by extending the research efforts of the RumourEval task on its Twitter dataset. To the end, we employ two prompting-based LLM variants (GPT-3.5-turbo and GPT-4) to extend the two RumourEval subtasks: (1) veracity prediction, and (2) stance classification. For veracity prediction, three classifications schemes are experimented per GPT variant. Each scheme is tested in zero-, one- and few-shot settings. Our best results outperform the precedent ones by a substantial margin. For stance classification, prompting-based-approaches show comparable performance to prior results, with no improvement over finetuning methods. Rumour stance subtask is also extended beyond the original setting to allow multiclass classification. All of the generated predictions for both subtasks are equipped with confidence scores determining their trustworthiness degree according to the LLM, and post-hoc justifications for explainability and interpretability purposes. Our primary aim is AI for social good.",
    "pdf_link": "https://arxiv.org/abs/2404.16859",
    "graphs": [],
    "abstract_cn": "对话式提示工程的LLMs为输出创造提供了精准控制，提升了模型的多功能性、适应性和即兴检索能力。然而，数字虚假信息的泛滥已引起社会广泛关注。社交媒体的匿名性、易得性和广泛传播为谣言的滋生提供了温床。本研究旨在借助先进的提示依赖型LLMs，通过扩展RumourEval任务在Twitter数据集上的研究，来对抗虚假信息。我们采用了两种基于提示的LLM变种（GPT-3.5-turbo和GPT-4），对RumourEval的两个子任务进行了扩展：（1）真实性预测；（2）立场分类。在真实性预测方面，我们对每个GPT变种进行了三种不同分类方案的实验，并在零次、一次和少次的设置中进行了测试。我们的最佳成绩显著超过了以往的成果。在立场分类方面，基于提示的方法与之前的结果相当，但并未超过微调方法的效果。此外，谣言立场子任务也被扩展，支持多类分类。所有生成的预测结果都附带了置信度评分，这些评分由LLM提供，用以评估其可信度，并附有事后解释，以增强模型的可解释性和可解释性。我们的核心宗旨是利用人工智能服务于社会公益。",
    "title_cn": "借助超大型语言模型，我们能够对谣言进行评估。",
    "tags": [
      "LLM应用",
      "社交媒体",
      "信息安全"
    ]
  },
  {
    "title": "The Future of Scientific Publishing: Automated Article Generation",
    "submit_datetime": "2024年04月11日",
    "abstract": "This study introduces a novel software tool leveraging large language model (LLM) prompts, designed to automate the generation of academic articles from Python code a significant advancement in the fields of biomedical informatics and computer science. Selected for its widespread adoption and analytical versatility, Python served as a foundational proof of concept; however, the underlying methodology and framework exhibit adaptability across various GitHub repo's underlining the tool's broad applicability (Harper 2024). By mitigating the traditionally time-intensive academic writing process, particularly in synthesizing complex datasets and coding outputs, this approach signifies a monumental leap towards streamlining research dissemination. The development was achieved without reliance on advanced language model agents, ensuring high fidelity in the automated generation of coherent and comprehensive academic content. This exploration not only validates the successful application and efficiency of the software but also projects how future integration of LLM agents which could amplify its capabilities, propelling towards a future where scientific findings are disseminated more swiftly and accessibly.",
    "pdf_link": "https://arxiv.org/abs/2404.17586",
    "graphs": [],
    "abstract_cn": "本研究推出了一款创新软件，该软件借助大型语言模型（LLM）的提示，能够自动从 Python 代码生成学术文章，这在生物医学信息学和计算机科学界是一个显著的突破。Python 因其普及度高和分析能力强而被选为概念验证的基础；但是，该工具的底层方法和框架在 GitHub 上的多个代码库中都显示出了其适应性，凸显了其广泛的应用潜力（Harper 2024）。这种方法通过简化传统上耗时的学术写作流程，尤其是在整合复杂数据集和编码输出时，标志着研究传播流程的重大改进。开发过程中没有依赖高级语言模型代理，确保了自动生成的学术内容既连贯又全面。这次探索不仅证实了软件的成功应用和高效性，还展望了未来 LLM 代理的融合可能，这将进一步增强其功能，推动科学发现更快、更广泛地传播。",
    "title_cn": "科学出版新纪元：文章自动撰写技术",
    "tags": [
      "分类：LLM应用",
      "生物医学信息学",
      "计算机科学"
    ]
  },
  {
    "title": "Is Your LLM Outdated? Benchmarking LLMs & Alignment Algorithms for Time-Sensitive Knowledge",
    "submit_datetime": "2024年04月10日",
    "abstract": "We study the appropriateness of Large Language Models (LLMs) as knowledge repositories. We focus on the challenge of maintaining LLMs' factual knowledge up-to-date over time. Motivated by the lack of studies on identifying outdated knowledge within LLMs, we design and develop a dynamic benchmark with up-to-date ground truth answers for each target factual question. We evaluate eighteen open-source and closed-source state-of-the-art LLMs on time-sensitive knowledge retrieved in real-time from Wikidata. We select time-sensitive domain facts in politics, sports, and organizations, and estimate the recency of the information learned by the model during pre-training\\fine-tuning. In the second contribution, we evaluate the effectiveness of knowledge editing methods for aligning LLMs with up-to-date factual knowledge and compare their performance with Retrieval Augmented Generation. The dynamic benchmark is designed to be used as-is to assess LLMs's up-to-dateness, as well as to be extended to other domains by sharing the code, the dataset, as well as evaluation and visualization scripts.",
    "pdf_link": "https://arxiv.org/abs/2404.08700",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.08700v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08700/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08700v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08700/observed_data.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08700v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08700/scala_number_and_percentage.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08700v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08700/ragdocs.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08700v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08700/observed_data_appendix1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08700v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08700/observed_data_appendix2.png"
      }
    ],
    "abstract_cn": "本研究探讨了大型语言模型（LLMs）作为知识库的适宜性，特别关注如何确保这些模型中的事实知识能够与时俱进。鉴于目前尚缺乏对LLMs中过时知识识别的研究，我们设计并构建了一个动态基准测试，它能够为每个目标事实问题提供最新的基准答案。我们对十八个开源和闭源的先进LLMs进行了评估，这些评估基于从Wikidata实时检索的时间敏感知识。我们挑选了政治、体育和组织等时间敏感领域的特定事实，并估算了模型在预训练和微调阶段所学习信息的时效性。在研究的第二部分，我们检验了知识编辑方法在更新LLMs事实知识方面的有效性，并将其与检索增强生成的性能进行了对比。这个动态基准测试旨在评估LLMs的时效性，并可通过共享代码、数据集以及评估和可视化工具，扩展应用于其他领域的评估。",
    "title_cn": "你的大型语言模型（LLM）是否已落伍？本文旨在对 LLM 及其对齐算法进行基准测试，以评估它们处理时间敏感知识的能力。",
    "tags": [
      "LLM应用",
      "知识库",
      "基准测试"
    ]
  },
  {
    "title": "LLMs in Biomedicine: A study on clinical Named Entity Recognition",
    "submit_datetime": "2024年04月10日",
    "abstract": "Large Language Models (LLMs) demonstrate remarkable versatility in various NLP tasks but encounter distinct challenges in biomedicine due to medical language complexities and data scarcity. This paper investigates the application of LLMs in the medical domain by exploring strategies to enhance their performance for the Named-Entity Recognition (NER) task. Specifically, our study reveals the importance of meticulously designed prompts in biomedicine. Strategic selection of in-context examples yields a notable improvement, showcasing ~15-20\\% increase in F1 score across all benchmark datasets for few-shot clinical NER. Additionally, our findings suggest that integrating external resources through prompting strategies can bridge the gap between general-purpose LLM proficiency and the specialized demands of medical NER. Leveraging a medical knowledge base, our proposed method inspired by Retrieval-Augmented Generation (RAG) can boost the F1 score of LLMs for zero-shot clinical NER. We will release the code upon publication.",
    "pdf_link": "https://arxiv.org/abs/2404.07376",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）在多样的自然语言处理（NLP）任务中展现了卓越能力，但在生物医学领域却因医学术语的复杂和数据的匮乏而面临挑战。本研究通过优化命名实体识别（NER）任务的策略，探讨了LLMs在医学领域的应用潜力。研究发现，精心设计的生物医学提示至关重要，策略性地挑选上下文实例能显著提升性能，使得临床NER的F1分数在所有基准数据集上平均提升了15-20%。此外，研究还指出，通过提示策略整合外部资源可以有效缩小通用型LLMs与专业医学NER需求之间的差异。我们提出的，受检索增强生成（RAG）启发的方法，能够显著提升LLMs在零次临床NER任务中的F1分数。相关代码将在论文发表后公开。",
    "title_cn": "生物医学领域的大型语言模型：专注于临床命名实体识别的深入研究",
    "tags": [
      "LLM应用",
      "生物医学",
      ""
    ]
  },
  {
    "title": "WESE: Weak Exploration to Strong Exploitation for LLM Agents",
    "submit_datetime": "2024年04月10日",
    "abstract": "Recently, large language models (LLMs) have demonstrated remarkable potential as an intelligent agent. However, existing researches mainly focus on enhancing the agent's reasoning or decision-making abilities through well-designed prompt engineering or task-specific fine-tuning, ignoring the procedure of exploration and exploitation. When addressing complex tasks within open-world interactive environments, these methods exhibit limitations. Firstly, the lack of global information of environments leads to greedy decisions, resulting in sub-optimal solutions. On the other hand, irrelevant information acquired from the environment not only adversely introduces noise, but also incurs additional cost. This paper proposes a novel approach, Weak Exploration to Strong Exploitation (WESE), to enhance LLM agents in solving open-world interactive tasks. Concretely, WESE involves decoupling the exploration and exploitation process, employing a cost-effective weak agent to perform exploration tasks for global knowledge. A knowledge graph-based strategy is then introduced to store the acquired knowledge and extract task-relevant knowledge, enhancing the stronger agent in success rate and efficiency for the exploitation task. Our approach is flexible enough to incorporate diverse tasks, and obtains significant improvements in both success rates and efficiency across four interactive benchmarks.",
    "pdf_link": "https://arxiv.org/abs/2404.07456",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.07456v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.07456/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.07456v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.07456/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.07456v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.07456/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.07456v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.07456/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.07456v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.07456/x5.png"
      }
    ],
    "abstract_cn": "近期，大型语言模型（LLMs）在智能代理领域展现出巨大潜力。但研究多聚焦于通过精准的提示设计或任务定制化微调来提升代理的逻辑推理与决策制定能力，而忽略了探索与开发的过程。面对开放世界互动环境中的复杂任务，这些传统方法存在局限。一方面，对环境全局信息的缺失导致短视决策，产生不理想的解决方案；另一方面，从环境中收集的无关信息不仅带来干扰，还增加了额外的开销。本论文提出了一种创新方法——从弱探索到强利用（WESE），旨在提升LLM代理处理开放世界互动任务的能力。具体而言，WESE通过分离探索与开发流程，利用成本效益高的弱代理进行全局知识的探索任务。随后，引入基于知识图谱的策略，存储所获知识并提炼出与任务相关的信息，以此提升强代理在执行开发任务时的成功率和效率。该方法设计灵活，能够适应多样化任务，并在四个互动基准测试中显著提高了成功率和操作效率。",
    "title_cn": "WESE：从初步探索到深度利用——为大型语言模型代理量身定制的策略",
    "tags": [
      "Agent",
      "智能代理",
      "知识图谱"
    ]
  },
  {
    "title": "Apollonion: Profile-centric Dialog Agent",
    "submit_datetime": "2024年04月09日",
    "abstract": "The emergence of Large Language Models (LLMs) has innovated the development of dialog agents. Specially, a well-trained LLM, as a central process unit, is capable of providing fluent and reasonable response for user's request. Besides, auxiliary tools such as external knowledge retrieval, personalized character for vivid response, short/long-term memory for ultra long context management are developed, completing the usage experience for LLM-based dialog agents. However, the above-mentioned techniques does not solve the issue of \\textbf{personalization from user perspective}: agents response in a same fashion to different users, without consideration of their features, such as habits, interests and past experience. In another words, current implementation of dialog agents fail in ``knowing the user''. The capacity of well-description and representation of user is under development. In this work, we proposed a framework for dialog agent to incorporate user profiling (initialization, update): user's query and response is analyzed and organized into a structural user profile, which is latter served to provide personal and more precise response. Besides, we proposed a series of evaluation protocols for personalization: to what extend the response is personal to the different users.\n  The framework is named as \\method{}, inspired by inscription of ``Know Yourself'' in the temple of Apollo (also known as \\method{}) in Ancient Greek. Few works have been conducted on incorporating personalization into LLM, \\method{} is a pioneer work on guiding LLM's response to meet individuation via the application of dialog agents, with a set of evaluation methods for measurement in personalization.",
    "pdf_link": "https://arxiv.org/abs/2404.08692",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.08692v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08692/logo2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08692v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08692/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08692v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08692/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08692v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08692/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08692v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08692/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08692v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08692/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08692v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08692/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08692v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08692/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08692v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08692/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08692v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08692/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08692v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08692/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08692v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08692/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08692v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08692/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08692v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08692/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08692v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08692/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08692v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08692/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08692v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08692/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08692v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08692/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08692v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08692/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08692v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08692/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08692v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08692/x20.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）的兴起为对话代理的发展带来了创新。特别是，一个经过良好训练的LLM，作为核心处理单元，能够为用户提供流畅且合理的回应。辅助工具如外部知识检索、个性化角色塑造、以及短/长期记忆管理等，进一步提升了基于LLM的对话代理的用户体验。尽管如此，现有技术仍未能解决用户个性化的问题：对话代理对不同用户的反应千篇一律，忽略了他们的习惯、兴趣和经验等个性化特征。换句话说，目前的对话代理在“了解用户”方面存在不足。用户特征的准确描述和表达仍在不断完善之中。在本研究中，我们提出了一个整合用户画像（包括初始化和更新）的对话代理框架：用户的查询和反馈被分析并整合成一个结构化的用户画像，以便提供更加个性化和精准的回应。此外，我们还设计了一系列评估个性化程度的协议。这个框架被命名为\\method{}，灵感来源于古希腊阿波罗神庙上的格言“认识你自己”。在将个性化融入LLM的领域中，\\method{}是一次开创性的尝试，旨在引导LLM通过对话代理的应答实现个性化，并建立了一套评估个性化效果的方法。",
    "title_cn": "Apollonion：专注于个人资料的对话代理",
    "tags": [
      "Agent",
      "对话系统",
      "个性化推荐"
    ]
  },
  {
    "title": "GUIDE: Graphical User Interface Data for Execution",
    "submit_datetime": "2024年04月09日",
    "abstract": "In this paper, we introduce GUIDE, a novel dataset tailored for the advancement of Multimodal Large Language Model (MLLM) applications, particularly focusing on Robotic Process Automation (RPA) use cases. Our dataset encompasses diverse data from various websites including Apollo(62.67\\%), Gmail(3.43\\%), Calendar(10.98\\%) and Canva(22.92\\%). Each data entry includes an image, a task description, the last action taken, CoT and the next action to be performed along with grounding information of where the action needs to be executed. The data is collected using our in-house advanced annotation tool NEXTAG (Next Action Grounding and Annotation Tool). The data is adapted for multiple OS, browsers and display types. It is collected by multiple annotators to capture the variation of design and the way person uses a website.\n  Through this dataset, we aim to facilitate research and development in the realm of LLMs for graphical user interfaces, particularly in tasks related to RPA. The dataset's multi-platform nature and coverage of diverse websites enable the exploration of cross-interface capabilities in automation tasks. We believe that our dataset will serve as a valuable resource for advancing the capabilities of multi-platform LLMs in practical applications, fostering innovation in the field of automation and natural language understanding. Using GUIDE, we build V-Zen, the first RPA model to automate multiple websites using our in-House Automation tool AUTONODE",
    "pdf_link": "https://arxiv.org/abs/2404.16048",
    "graphs": [],
    "abstract_cn": "本文提出了GUIDE，一个专为推动多模态大型语言模型（MLLM）应用而设计的新数据集，重点聚焦于机器人流程自动化（RPA）的实际应用。该数据集广泛采集了包括Apollo、Gmail、Calendar和Canva在内的多个网站数据，每个数据条目都包含了图像、任务说明、最近一次操作、上下文信息（CoT）、待执行的下一步操作及其执行位置的详细信息。我们利用自主研发的先进注释工具NEXTAG进行数据采集，确保数据能够适应不同的操作系统、浏览器和显示设备，并由多位注释者共同完成，以确保捕捉到网站设计多样性及用户使用习惯的差异。通过GUIDE数据集，我们期望推动LLM在图形用户界面领域的研究与开发，尤其是在RPA相关任务上。其跨平台的特性和对多样化网站的广泛覆盖，为探索自动化任务中的界面间协作能力提供了可能。我们相信GUIDE将成为提升多平台LLM实际应用能力、激发自动化和自然语言理解领域创新的重要资源。利用GUIDE，我们开发了V-Zen，这是首个利用我们自主研发的自动化工具AUTONODE，实现多网站自动化的RPA模型。",
    "title_cn": "GUIDE：图形用户界面数据执行指南",
    "tags": [
      "LLM应用",
      "机器人流程自动化",
      "自然语言理解"
    ]
  },
  {
    "title": "360°REA: Towards A Reusable Experience Accumulation with 360° Assessment for Multi-Agent System",
    "submit_datetime": "2024年04月08日",
    "abstract": "Large language model agents have demonstrated remarkable advancements across various complex tasks. Recent works focus on optimizing the agent team or employing self-reflection to iteratively solve complex tasks. Since these agents are all based on the same LLM, only conducting self-evaluation or removing underperforming agents does not substantively enhance the capability of the agents. We argue that a comprehensive evaluation and accumulating experience from evaluation feedback is an effective approach to improving system performance. In this paper, we propose Reusable Experience Accumulation with 360° Assessment (360°REA), a hierarchical multi-agent framework inspired by corporate organizational practices. The framework employs a novel 360° performance assessment method for multi-perspective performance evaluation with fine-grained assessment. To enhance the capability of agents in addressing complex tasks, we introduce dual-level experience pool for agents to accumulate experience through fine-grained assessment. Extensive experiments on complex task datasets demonstrate the effectiveness of 360°REA.",
    "pdf_link": "https://arxiv.org/abs/2404.05569",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.05569v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.05569/x1.png"
      }
    ],
    "abstract_cn": "大型语言模型代理在多样化的复杂任务上取得了显著的进展。最新研究或致力于优化团队协作，或通过自我反思来逐步攻克难题。鉴于这些代理均建立在同一语言模型之上，单纯的自我评估或淘汰表现欠佳的代理，并不能根本提升整体性能。我们提出，通过全面评估和积累反馈经验，可以有效提升系统效能。本文介绍了一种名为360°全方位评估的经验累积框架（360°REA），该框架借鉴了企业组织结构的实践，采用创新的360°绩效评估方法，实现多角度细致评估。为了提升代理处理复杂任务的能力，我们设计了双层经验池，让代理能够通过细致的评估积累经验。通过在复杂任务数据集上的广泛测试，360°REA的卓越效果得到了验证。",
    "title_cn": "360°REA：迈向为多智能体系统打造可复用的经验累积，辅以全方位的评估。",
    "tags": [
      "Agent",
      "人工智能",
      "企业管理"
    ]
  },
  {
    "title": "Information Retrieval with Entity Linking",
    "submit_datetime": "2024年04月07日",
    "abstract": "Despite the advantages of their low-resource settings, traditional sparse retrievers depend on exact matching approaches between high-dimensional bag-of-words (BoW) representations of both the queries and the collection. As a result, retrieval performance is restricted by semantic discrepancies and vocabulary gaps. On the other hand, transformer-based dense retrievers introduce significant improvements in information retrieval tasks by exploiting low-dimensional contextualized representations of the corpus. While dense retrievers are known for their relative effectiveness, they suffer from lower efficiency and lack of generalization issues, when compared to sparse retrievers. For a lightweight retrieval task, high computational resources and time consumption are major barriers encouraging the renunciation of dense models despite potential gains. In this work, I propose boosting the performance of sparse retrievers by expanding both the queries and the documents with linked entities in two formats for the entity names: 1) explicit and 2) hashed. A zero-shot end-to-end dense entity linking system is employed for entity recognition and disambiguation to augment the corpus. By leveraging the advanced entity linking methods, I believe that the effectiveness gap between sparse and dense retrievers can be narrowed. Experiments are conducted on the MS MARCO passage dataset using the original qrel set, the re-ranked qrels favoured by MonoT5 and the latter set further re-ranked by DuoT5. Since I am concerned with the early stage retrieval in cascaded ranking architectures of large information retrieval systems, the results are evaluated using recall@1000. The suggested approach is also capable of retrieving documents for query subsets judged to be particularly difficult in prior work.",
    "pdf_link": "https://arxiv.org/abs/2404.08678",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.08678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08678/query_expansion.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08678/star-adore.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08678/classifier.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08678/all_original_2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08678/all_original_3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08678/all_original_4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08678/all_original_1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08678/veiled_original_2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08678/veiled_original_3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08678/veiled_original_4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08678/veiled_original_1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08678/pygmy_original_2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08678/pygmy_original_3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08678/pygmy_original_4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08678/pygmy_original_1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08678/lesser_original_2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08678/lesser_original_3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08678/lesser_original_4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08678/lesser_original_1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08678/all_monoT5_2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08678/all_monoT5_3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08678/all_monoT5_4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08678/all_monoT5_1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08678/veiled_monoT5_2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08678/veiled_monoT5_3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08678/veiled_monoT5_4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08678/veiled_monoT5_1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08678/pygmy_monoT5_2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08678/pygmy_monoT5_3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08678/pygmy_monoT5_4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08678/pygmy_monoT5_1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08678/lesser_monoT5_2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08678/lesser_monoT5_3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08678/lesser_monoT5_4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08678/lesser_monoT5_1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08678/all_duoT5_2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08678/all_duoT5_3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08678/all_duoT5_4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08678/all_duoT5_1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08678/veiled_duoT5_2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08678/veiled_duoT5_3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08678/veiled_duoT5_4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08678/veiled_duoT5_1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08678/pygmy_duoT5_2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08678/pygmy_duoT5_3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08678/pygmy_duoT5_4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08678/pygmy_duoT5_1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08678/lesser_duoT5_2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08678/lesser_duoT5_3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08678/lesser_duoT5_4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.08678v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.08678/lesser_duoT5_1.png"
      }
    ],
    "abstract_cn": "尽管传统稀疏检索器在资源较少的环境中展现出优势，但它们仍需依赖于查询和文档集合间高维词袋（BoW）表示的精确匹配，这限制了检索性能，因为存在语义差异和词汇缺口。相比之下，基于变换器的密集检索器通过采用语料库的低维上下文化表示，在信息检索任务上取得了显著提升。尽管密集检索器因其高效性而受到推崇，但相较于稀疏检索器，它们在效率和泛化能力上仍有不足。在轻量级检索任务中，高昂的计算资源和时间成本成为了放弃潜在优势的密集模型的主要障碍。本文提出了一种提升稀疏检索器性能的方法，即通过两种格式（显式和哈希）将链接实体扩展到查询和文档中。引入了一个零样本端到端密集实体链接系统，用于实体识别和消歧，以增强语料库。借助先进的实体链接技术，有望缩小稀疏与密集检索器之间的性能差距。实验基于MS MARCO段落数据集，采用了原始qrel集、MonoT5优化后的重排qrels，以及DuoT5进一步优化的集合。鉴于研究重点在于大型信息检索系统中串联排名架构的初期检索阶段，因此采用recall@1000作为评估指标。本研究所提出的方法同样能够有效检索出以往研究中认为难度较大的查询子集的相关文档。",
    "title_cn": "通过实体链接进行信息检索",
    "tags": [
      "LLM应用",
      "信息检索",
      "实体链接"
    ]
  },
  {
    "title": "Prioritizing Software Requirements Using Large Language Models",
    "submit_datetime": "2024年04月05日",
    "abstract": "Large Language Models (LLMs) are revolutionizing Software Engineering (SE) by introducing innovative methods for tasks such as collecting requirements, designing software, generating code, and creating test cases, among others. This article focuses on requirements engineering, typically seen as the initial phase of software development that involves multiple system stakeholders. Despite its key role, the challenge of identifying requirements and satisfying all stakeholders within time and budget constraints remains significant. To address the challenges in requirements engineering, this study introduces a web-based software tool utilizing AI agents and prompt engineering to automate task prioritization and apply diverse prioritization techniques, aimed at enhancing project management within the agile framework. This approach seeks to transform the prioritization of agile requirements, tackling the substantial challenge of meeting stakeholder needs within set time and budget limits. Furthermore, the source code of our developed prototype is available on GitHub, allowing for further experimentation and prioritization of requirements, facilitating research and practical application.",
    "pdf_link": "https://arxiv.org/abs/2405.01564",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）正以创新的方式颠覆软件工程（SE），为需求收集、软件设计、代码生成和测试用例创建等任务带来变革。本文聚焦于需求工程，这是软件开发的起始阶段，涉及众多系统参与者。尽管需求工程至关重要，但在有限的时间和预算内确定需求并满足所有利益相关者的需求仍然是一个重大挑战。为了应对这些挑战，本研究推出了一款基于网络的软件工具，该工具采用AI代理和提示工程技术，自动化任务优先级排序，并采用多样化的排序技术，以提升敏捷框架下的项目管理效率。这种方法致力于改进敏捷需求的优先级设置，以应对在既定时间和预算内满足利益相关者需求的巨大挑战。此外，我们开发的原型的源代码已在GitHub上公开，便于进一步的实验和需求优先级排序，推动研究与实践的结合。",
    "title_cn": "利用大型语言模型对软件需求进行优先级排序",
    "tags": [
      "分类：Agent\n\n这篇论文主要讨论了大型语言模型（LLMs）在软件工程（SE）中的应用，特别是在需求工程阶段。论文中提到了使用AI代理和提示工程技术来自动化任务优先级排序，这表明了AI代理在软件工程中的应用。因此，这篇论文应该被归类为Agent。",
      "软件工程",
      "人工智能"
    ]
  },
  {
    "title": "Elicitron: An LLM Agent-Based Simulation Framework for Design Requirements Elicitation",
    "submit_datetime": "2024年04月04日",
    "abstract": "Requirements elicitation, a critical, yet time-consuming and challenging step in product development, often fails to capture the full spectrum of user needs. This may lead to products that fall short of expectations. This paper introduces a novel framework that leverages Large Language Models (LLMs) to automate and enhance the requirements elicitation process. LLMs are used to generate a vast array of simulated users (LLM agents), enabling the exploration of a much broader range of user needs and unforeseen use cases. These agents engage in product experience scenarios, through explaining their actions, observations, and challenges. Subsequent agent interviews and analysis uncover valuable user needs, including latent ones. We validate our framework with three experiments. First, we explore different methodologies for diverse agent generation, discussing their advantages and shortcomings. We measure the diversity of identified user needs and demonstrate that context-aware agent generation leads to greater diversity. Second, we show how our framework effectively mimics empathic lead user interviews, identifying a greater number of latent needs than conventional human interviews. Third, we showcase that LLMs can be used to analyze interviews, capture needs, and classify them as latent or not. Our work highlights the potential of using LLM agents to accelerate early-stage product development, reduce costs, and increase innovation.",
    "pdf_link": "https://arxiv.org/abs/2404.16045",
    "graphs": [],
    "abstract_cn": "需求挖掘是产品开发中至关重要却费时费力的一环，往往难以全面捕捉用户的多元需求，从而造成产品不尽人意。本篇论文提出了一个创新框架，该框架借助大型语言模型（LLMs）自动化并优化需求挖掘流程。通过LLMs，我们能够创建出众多模拟用户（即LLM代理），这些代理能够探索更宽广的用户需求范围和预测之外的使用情境。在产品体验场景中，这些代理通过阐述自己的行为、观察和所遇挑战，深入参与互动。随后，通过代理访谈和深入分析，我们能够挖掘出包括潜在需求在内的宝贵用户需求。我们的框架通过三项实验得到验证：首先，我们探索了生成多样化代理的不同方法，并比较了它们的优劣；其次，我们展示了如何利用框架有效模拟富有同理心的领先用户访谈，从而识别出比传统人工访谈更多的潜在需求；最后，我们证明了LLMs不仅能够分析访谈内容、捕捉需求，还能将需求分类为显性或隐性。本研究凸显了运用LLM代理在产品开发的早期阶段加速进程、降低成本并提升创新的可能性。",
    "title_cn": "Elicitron：一款基于大型语言模型（LLM）的代理仿真框架，专为设计需求的挖掘而设计。",
    "tags": [
      "LLM应用",
      "产品开发",
      "人工智能"
    ]
  },
  {
    "title": "GP-MoLFormer: A Foundation Model For Molecular Generation",
    "submit_datetime": "2024年04月04日",
    "abstract": "Transformer-based models trained on large and general purpose datasets consisting of molecular strings have recently emerged as a powerful tool for successfully modeling various structure-property relations. Inspired by this success, we extend the paradigm of training chemical language transformers on large-scale chemical datasets to generative tasks in this work. Specifically, we propose GP-MoLFormer, an autoregressive molecular string generator that is trained on more than 1.1B chemical SMILES. GP-MoLFormer uses a 46.8M parameter transformer decoder model with linear attention and rotary positional encodings as the base architecture. We explore the utility of GP-MoLFormer in generating novel, valid, and unique SMILES. Impressively, we find GP-MoLFormer is able to generate a significant fraction of novel, valid, and unique SMILES even when the number of generated molecules is in the 10 billion range and the reference set is over a billion. We also find strong memorization of training data in GP-MoLFormer generations, which has so far remained unexplored for chemical language models. Our analyses reveal that training data memorization and novelty in generations are impacted by the quality of the training data; duplication bias in training data can enhance memorization at the cost of lowering novelty. We evaluate GP-MoLFormer's utility and compare it with that of existing baselines on three different tasks: de novo generation, scaffold-constrained molecular decoration, and unconstrained property-guided optimization. While the first two are handled with no additional training, we propose a parameter-efficient fine-tuning method for the last task, which uses property-ordered molecular pairs as input. We call this new approach pair-tuning. Our results show GP-MoLFormer performs better or comparable with baselines across all three tasks, demonstrating its general utility.",
    "pdf_link": "https://arxiv.org/abs/2405.04912",
    "graphs": [],
    "abstract_cn": "基于Transformer的模型在分子字符串的大型数据集上训练，已成为揭示结构与性质关系的利器。我们在此基础上，推出了GP-MoLFormer，一个能生成超过11亿化学SMILES的自回归分子生成器。它采用4680万参数的Transformer解码器，结合线性注意力和旋转位置编码。GP-MoLFormer在生成新颖、有效且唯一的SMILES方面表现出色，即使在分子生成量达百亿级时亦然。然而，我们也发现它对训练数据的记忆效应，这在化学语言模型中尚属首次。我们分析了训练数据质量对记忆和创新的影响，并指出复制偏差虽增强记忆，却牺牲了创新。我们通过三个任务评估GP-MoLFormer：从头设计、骨架约束装饰和属性引导优化，其中最后一个任务采用了我们提出的pair-tuning微调方法。结果表明，GP-MoLFormer在各项任务中均表现出色，展现了其广泛的适用性。",
    "title_cn": "GP-MoLFormer：分子生成的奠基之作在这篇文章中，我们将介绍GP-MoLFormer，这是一种开创性的基础模型，专为分子生成而设计。它通过深度学习和先进的算法，为药物发现和材料科学领域带来了革命性的变革。GP-MoLFormer不仅能够高效地生成新颖的分子结构，还能确保这些结构在化学上可行且具有潜在的应用价值。随着我们对这一模型的深入探讨，我们将揭示它是如何成为分子设计领域的一块重要基石，以及它如何推动科学探索的边界。",
    "tags": [
      "LLM应用\n\n这篇论文介绍了一个基于Transformer的大型语言模型GP-MoLFormer，专门用于生成化学分子字符串（SMILES）。它展示了模型在生成新颖、有效且唯一的分子结构方面的能力，并探讨了训练数据质量对模型性能的影响。此外，论文还评估了模型在不同化学任务中的应用，包括从头设计分子、骨架约束装饰和属性引导优化。这些应用展示了LLM在特定领域（如化学）的实际应用价值，因此属于LLM应用分类。",
      "",
      "分子设计"
    ]
  },
  {
    "title": "Concept-Guided LLM Agents for Human-AI Safety Codesign",
    "submit_datetime": "2024年04月03日",
    "abstract": "Generative AI is increasingly important in software engineering, including safety engineering, where its use ensures that software does not cause harm to people. This also leads to high quality requirements for generative AI. Therefore, the simplistic use of Large Language Models (LLMs) alone will not meet these quality demands. It is crucial to develop more advanced and sophisticated approaches that can effectively address the complexities and safety concerns of software systems. Ultimately, humans must understand and take responsibility for the suggestions provided by generative AI to ensure system safety. To this end, we present an efficient, hybrid strategy to leverage LLMs for safety analysis and Human-AI codesign. In particular, we develop a customized LLM agent that uses elements of prompt engineering, heuristic reasoning, and retrieval-augmented generation to solve tasks associated with predefined safety concepts, in interaction with a system model graph. The reasoning is guided by a cascade of micro-decisions that help preserve structured information. We further suggest a graph verbalization which acts as an intermediate representation of the system model to facilitate LLM-graph interactions. Selected pairs of prompts and responses relevant for safety analytics illustrate our method for the use case of a simplified automated driving system.",
    "pdf_link": "https://arxiv.org/abs/2404.15317",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.15317v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15317/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15317v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15317/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15317v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15317/output.png"
      }
    ],
    "abstract_cn": "生成性AI在软件工程尤其是安全工程中的应用愈发关键，它确保软件不会对人造成伤害，这同时也对AI的质量提出了更高要求。仅依赖大型语言模型（LLM）的简单应用已不足以满足这些高标准。因此，迫切需要开发更先进、更精细的方法，以有效应对软件系统的复杂性和安全挑战。人类必须理解并负责监督生成性AI的建议，以保障系统的安全性。本研究提出了一种高效的混合策略，结合LLM进行安全分析与人机协同设计。我们设计了一款定制化的LLM代理，它结合了提示工程、启发式推理和增强检索生成技术，以解决与预定义安全概念相关的任务，并与系统模型图进行互动。这一过程通过一系列微决策引导，以保持信息的结构化。此外，我们还提出了一种图形化表述方法，作为系统模型的中间表示，以便更好地促进LLM与图形的交互。我们以简化的自动驾驶系统为例，展示了与安全分析相关的提示和响应对，以此来说明我们的方法。",
    "title_cn": "概念驱动的大型语言模型（LLM）代理助力人类与AI安全协同设计",
    "tags": [
      "Agent",
      "软件工程",
      "安全工程"
    ]
  },
  {
    "title": "METAL: Towards Multilingual Meta-Evaluation",
    "submit_datetime": "2024年04月02日",
    "abstract": "With the rising human-like precision of Large Language Models (LLMs) in numerous tasks, their utilization in a variety of real-world applications is becoming more prevalent. Several studies have shown that LLMs excel on many standard NLP benchmarks. However, it is challenging to evaluate LLMs due to test dataset contamination and the limitations of traditional metrics. Since human evaluations are difficult to collect, there is a growing interest in the community to use LLMs themselves as reference-free evaluators for subjective metrics. However, past work has shown that LLM-based evaluators can exhibit bias and have poor alignment with human judgments. In this study, we propose a framework for an end-to-end assessment of LLMs as evaluators in multilingual scenarios. We create a carefully curated dataset, covering 10 languages containing native speaker judgments for the task of summarization. This dataset is created specifically to evaluate LLM-based evaluators, which we refer to as meta-evaluation (METAL). We compare the performance of LLM-based evaluators created using GPT-3.5-Turbo, GPT-4, and PaLM2. Our results indicate that LLM-based evaluators based on GPT-4 perform the best across languages, while GPT-3.5-Turbo performs poorly. Additionally, we perform an analysis of the reasoning provided by LLM-based evaluators and find that it often does not match the reasoning provided by human judges.",
    "pdf_link": "https://arxiv.org/abs/2404.01667",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.01667v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.01667/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.01667v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.01667/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.01667v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.01667/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.01667v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.01667/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.01667v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.01667/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.01667v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.01667/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.01667v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.01667/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.01667v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.01667/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.01667v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.01667/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2404.01667v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.01667/x10.png"
      }
    ],
    "abstract_cn": "随着大型语言模型（LLMs）在各种任务中精准度的不断提升，它们在现实世界应用中的运用也日益广泛。多项研究证实，LLMs在众多标准的自然语言处理（NLP）基准测试中表现优异。然而，由于测试数据集的污染问题和传统评估标准的局限，对LLMs的评估变得复杂。鉴于收集人类评估的难度，社区越来越倾向于利用LLMs作为主观度量的无参考评估工具。但先前研究指出，基于LLM的评估器可能存在偏见，且与人类判断的契合度不高。本研究提出了一个用于全面评估多语言环境下LLMs作为评估器的框架。我们构建了一个精心设计的数据集，覆盖10种语言，包含了母语者对摘要任务的评估。该数据集专为评估基于LLM的评估器而设计，我们称之为元评估（METAL）。我们对比了采用GPT-3.5-Turbo、GPT-4和PaLM2构建的基于LLM的评估器的性能。研究发现，基于GPT-4的评估器在跨语言评估中表现最佳，而GPT-3.5-Turbo的表现不尽人意。此外，我们对基于LLM的评估器提供的推理分析表明，其推理往往与人类裁判的推理不一致。",
    "title_cn": "METAL：探索多语言元评估的新境界",
    "tags": [
      "LLM应用",
      "",
      "评估工具"
    ]
  },
  {
    "title": "Self-Organized Agents: A LLM Multi-Agent Framework toward Ultra Large-Scale Code Generation and Optimization",
    "submit_datetime": "2024年04月02日",
    "abstract": "Recent advancements in automatic code generation using large language model (LLM) agent have brought us closer to the future of automated software development. However, existing single-agent approaches face limitations in generating and improving large-scale, complex codebases due to constraints in context length. To tackle this challenge, we propose Self-Organized multi-Agent framework (SoA), a novel multi-agent framework that enables the scalable and efficient generation and optimization of large-scale code. In SoA, self-organized agents operate independently to generate and modify code components while seamlessly collaborating to construct the overall codebase. A key feature of our framework is the automatic multiplication of agents based on problem complexity, allowing for dynamic scalability. This enables the overall code volume to be increased indefinitely according to the number of agents, while the amount of code managed by each agent remains constant. We evaluate SoA on the HumanEval benchmark and demonstrate that, compared to a single-agent system, each agent in SoA handles significantly less code, yet the overall generated code is substantially greater. Moreover, SoA surpasses the powerful single-agent baseline by 5% in terms of Pass@1 accuracy.",
    "pdf_link": "https://arxiv.org/abs/2404.02183",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.02183v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.02183/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.02183v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.02183/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.02183v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.02183/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.02183v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.02183/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.02183v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.02183/x5.png"
      }
    ],
    "abstract_cn": "最新的自动代码生成技术，借助大型语言模型（LLM）代理，正将我们推向自动化软件开发的新纪元。不过，目前的单一代理方法在处理大规模、复杂代码库的生成与优化时，因上下文长度限制而受限。为解决这一问题，我们设计了自组织多代理框架（SoA），这是一个创新的多代理系统，旨在实现大规模代码的高效生成与优化。在SoA框架下，各代理自主运作，负责生成和调整代码片段，同时协同合作，共同构建完整的代码库。该框架的核心优势在于能够根据问题的复杂性自动增减代理数量，实现动态扩展。这意味着，随着代理数量的增加，整体代码量可以无限扩展，而每个代理所管理的代码量却保持不变。我们在HumanEval基准测试中对SoA进行了评估，结果显示，相较于单一代理系统，SoA的每个代理处理的代码量更少，但整体生成的代码量却显著增加。此外，SoA在Pass@1准确度上比单一代理系统高出5%，显示出其强大的性能。",
    "title_cn": "自组织智能体：构建超大规模代码生成与优化的大型语言模型多智能体框架。",
    "tags": [
      "Agent",
      "软件开发",
      "自动代码生成"
    ]
  },
  {
    "title": "LLM-Coordination: Evaluating and Analyzing Multi-agent Coordination Abilities in Large Language Models",
    "submit_datetime": "2024年04月02日",
    "abstract": "The emergent reasoning and Theory of Mind (ToM) abilities demonstrated by Large Language Models (LLMs) make them promising candidates for developing coordination agents. In this study, we introduce a new LLM-Coordination Benchmark aimed at a detailed analysis of LLMs within the context of Pure Coordination Games, where participating agents need to cooperate for the most gain. This benchmark evaluates LLMs through two distinct tasks: (1) \\emph{Agentic Coordination}, where LLMs act as proactive participants for cooperation in 4 pure coordination games; (2) \\emph{Coordination Question Answering (QA)}, where LLMs are prompted to answer 198 multiple-choice questions from the 4 games for evaluation of three key reasoning abilities: Environment Comprehension, ToM Reasoning, and Joint Planning. Furthermore, to enable LLMs for multi-agent coordination, we introduce a Cognitive Architecture for Coordination (CAC) framework that can easily integrate different LLMs as plug-and-play modules for pure coordination games. Our findings indicate that LLM agents equipped with GPT-4-turbo achieve comparable performance to state-of-the-art reinforcement learning methods in games that require commonsense actions based on the environment. Besides, zero-shot coordination experiments reveal that, unlike RL methods, LLM agents are robust to new unseen partners. However, results on Coordination QA show a large room for improvement in the Theory of Mind reasoning and joint planning abilities of LLMs. The analysis also sheds light on how the ability of LLMs to understand their environment and their partner's beliefs and intentions plays a part in their ability to plan for coordination. Our code is available at \\url{https://github.com/eric-ai-lab/llm_coordination}.",
    "pdf_link": "https://arxiv.org/abs/2310.03903",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2310.03903v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2310.03903/CollabCapture.png"
      },
      {
        "url": "https://arxiv.org/html/2310.03903v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2310.03903/overcooked_layouts.png"
      },
      {
        "url": "https://arxiv.org/html/2310.03903v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2310.03903/overcooked_ea_layouts.png"
      },
      {
        "url": "https://arxiv.org/html/2310.03903v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2310.03903/LLM-Coordination.png"
      },
      {
        "url": "https://arxiv.org/html/2310.03903v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2310.03903/bar_plot.png"
      },
      {
        "url": "https://arxiv.org/html/2310.03903v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2310.03903/Plan_Ahead.png"
      },
      {
        "url": "https://arxiv.org/html/2310.03903v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2310.03903/Move_Away.png"
      },
      {
        "url": "https://arxiv.org/html/2310.03903v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2310.03903/Correct.png"
      },
      {
        "url": "https://arxiv.org/html/2310.03903v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2310.03903/Open_Gate.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）所展现的推理和心理理论（ToM）能力，使其成为构建协调智能体的理想选择。本研究提出了一项新的LLM-协调基准测试，专注于分析LLMs在纯协调游戏场景中的表现，这类游戏中的参与者需协作以实现最大化收益。该基准测试包含两项任务：（1）\\emph{代理协调}，LLMs在4种纯协调游戏中扮演积极的合作角色；（2）\\emph{协调问答（QA）}，LLMs需回答4个游戏中的198个选择题，以评估环境理解、ToM推理和联合规划三项关键推理技能。为实现LLMs的多智能体协调，我们引入了认知架构协调（CAC）框架，该框架支持不同LLMs作为即插即用的模块，用于纯协调游戏。研究发现，搭载GPT-4-turbo的LLM智能体在需要基于环境常识的行动游戏中，表现出与最先进的强化学习算法相媲美的性能。零样本协调实验显示，与强化学习方法相比，LLM智能体对新伙伴具有较强的适应性。然而，协调QA的结果显示LLMs在ToM推理和联合规划方面仍有提升空间。此外，分析还揭示了LLMs理解环境及其伙伴的信念和意图，对于它们协调规划能力的重要性。相关代码已在 \\url{https://github.com/eric-ai-lab/llm_coordination} 上发布。",
    "title_cn": "LLM-协调：探究大型语言模型内多代理协作能力的综合评估与深入分析",
    "tags": [
      "分类：Agent",
      "人工智能",
      "多智能体系统"
    ]
  },
  {
    "title": "Automated Assessment of Encouragement and Warmth in Classrooms Leveraging Multimodal Emotional Features and ChatGPT",
    "submit_datetime": "2024年04月01日",
    "abstract": "Classroom observation protocols standardize the assessment of teaching effectiveness and facilitate comprehension of classroom interactions. Whereas these protocols offer teachers specific feedback on their teaching practices, the manual coding by human raters is resource-intensive and often unreliable. This has sparked interest in developing AI-driven, cost-effective methods for automating such holistic coding. Our work explores a multimodal approach to automatically estimating encouragement and warmth in classrooms, a key component of the Global Teaching Insights (GTI) study's observation protocol. To this end, we employed facial and speech emotion recognition with sentiment analysis to extract interpretable features from video, audio, and transcript data. The prediction task involved both classification and regression methods. Additionally, in light of recent large language models' remarkable text annotation capabilities, we evaluated ChatGPT's zero-shot performance on this scoring task based on transcripts. We demonstrated our approach on the GTI dataset, comprising 367 16-minute video segments from 92 authentic lesson recordings. The inferences of GPT-4 and the best-trained model yielded correlations of r = .341 and r = .441 with human ratings, respectively. Combining estimates from both models through averaging, an ensemble approach achieved a correlation of r = .513, comparable to human inter-rater reliability. Our model explanation analysis indicated that text sentiment features were the primary contributors to the trained model's decisions. Moreover, GPT-4 could deliver logical and concrete reasoning as potential teacher guidelines. Our findings provide insights into using advanced, multimodal techniques for automated classroom observation, aiming to foster teacher training through frequent and valuable feedback.",
    "pdf_link": "https://arxiv.org/abs/2404.15310",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.15310v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15310/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15310v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15310/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15310v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15310/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15310v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15310/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.15310v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.15310/x5.png"
      }
    ],
    "abstract_cn": "课堂观察协议不仅统一了教学效果评价标准，还加深了对课堂互动的认识。这些协议虽然能为教师提供针对性的教学反馈，但人工编码过程既费时又可能存在误差。因此，研究者开始探索利用人工智能来自动化这一全面编码过程，以降低成本并提高可靠性。本研究采用了一种结合视觉和语音的多模态方法，旨在自动评估课堂中的关键元素——鼓励与温暖，这也是全球教学洞察研究中观察协议的一部分。我们利用面部和语音情感识别技术，结合情感分析，从视频、音频和文本资料中提取关键特征。研究中同时采用了分类和回归的预测方法。此外，考虑到当前大型语言模型在文本注解上的卓越表现，我们还测试了ChatGPT在没有先验训练的情况下，基于文本资料的评分能力。在GTI数据集上的实验显示，GPT-4和最佳训练模型与人工评分的相关性分别为0.341和0.441。通过整合两种模型的预测结果，我们得到了一个相关性为0.513的集成模型，这一结果与人工评分的一致性相当。模型解释分析揭示了文本情感特征在训练模型决策中起到了关键作用。GPT-4还能够提供逻辑性强、具体的推理，为教师提供潜在的指导。这些发现为利用先进的多模态技术自动化课堂观察提供了新思路，有助于通过持续而有价值的反馈促进教师的专业发展。",
    "title_cn": "通过融合多模态情感特征与ChatGPT技术，实现对课堂中鼓励与温暖的自动化评估。",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Meta Prompting for AI Systems",
    "submit_datetime": "2024年04月01日",
    "abstract": "In this work, we present a comprehensive study of Meta Prompting (MP), an innovative technique reshaping the utilization of language models (LMs) and AI systems in problem-solving and data interaction. Grounded in type theory and category theory, Meta Prompting emphasizes the structure and syntax of information over traditional content-centric methods. The paper explores the formal definitions of Meta Prompting, sets it apart from few-shot prompting, and underlines its effectiveness in various AI applications. A key focus is applying Meta Prompting for complex reasoning tasks, showing how it effectively deconstructs intricate problems into simpler sub-problems, enhancing token efficiency, and enabling more equitable problem-solving comparisons, especially against few-shot prompting methods. Additionally, the paper introduces Meta Prompting for prompting tasks, allowing LLMs to self-generate new prompts in a recursive, metaprogramming-like manner. Empirical experiments, including using a Qwen-72B base language model equipped with meta prompt without instruction-tuning to solve MATH problems with accuracy at 46.3%, which surpass the supervised fine-tuned counterpart trained with extensive mathematical QA instruction pairs and even the initial version of GPT-4, solving GSM8K problems with 83.5% accuracy with zero-shot meta-prompted Qwen-72B base language model, and solving the Game of 24 tasks with a 100% success rate using GPT-4, demonstrate the meta prompting's efficacy in achieving high accuracy and efficiency, showcasing Meta Prompting's transformative impact on AI problem-solving. The code is available at https://github.com/meta-prompting/meta-prompting.",
    "pdf_link": "https://arxiv.org/abs/2311.11482",
    "graphs": [],
    "abstract_cn": "本研究深入探讨了元提示（Meta Prompting，MP），这是一种革新性技术，正在改变语言模型和AI系统在问题解决与数据交互方面的应用。MP立足于类型理论和范畴理论，更注重信息的结构与语法，而非仅仅关注内容。文章详细阐述了MP的形式定义，阐明了其与少量示例提示的区别，并突出了其在多样AI应用中的显著效能。特别地，研究着重于将MP应用于复杂的推理任务，揭示了它如何高效地将难题拆解为简易子问题，提升令牌效率，并促进了更为公正的问题解决对比，尤其是与少量示例提示相比较。文章还介绍了MP在提示任务上的创新应用，使大型语言模型能够自我生成新提示，呈现出一种递归且类似元编程的新方式。通过一系列实证实验，如使用未经指令调整的Qwen-72B基础语言模型解决数学问题，准确度达到46.3%，超越了经过大量数学问答指令对训练的监督微调模型，甚至超过了GPT-4的初始版本；以及使用零样本元提示的Qwen-72B基础语言模型解决GSM8K问题，准确率达到83.5%；还有使用GPT-4以100%的成功率解决24点游戏任务，充分证明了MP在提升AI问题解决精度与效率方面的卓越能力，彰显了其在AI问题解决领域的革命性影响。相关代码已在 https://github.com/meta-prompting/meta-prompting 上公开。",
    "title_cn": "探索元提示技术在人工智能系统中的运用",
    "tags": [
      "LLM应用",
      "人工智能",
      "问题解决"
    ]
  },
  {
    "title": "Depending on yourself when you should: Mentoring LLM with RL agents to become the master in cybersecurity games",
    "submit_datetime": "2024年03月26日",
    "abstract": "Integrating LLM and reinforcement learning (RL) agent effectively to achieve complementary performance is critical in high stake tasks like cybersecurity operations. In this study, we introduce SecurityBot, a LLM agent mentored by pre-trained RL agents, to support cybersecurity operations. In particularly, the LLM agent is supported with a profile module to generated behavior guidelines, a memory module to accumulate local experiences, a reflection module to re-evaluate choices, and an action module to reduce action space. Additionally, it adopts the collaboration mechanism to take suggestions from pre-trained RL agents, including a cursor for dynamic suggestion taken, an aggregator for multiple mentors' suggestions ranking and a caller for proactive suggestion asking. Building on the CybORG experiment framework, our experiences show that SecurityBot demonstrates significant performance improvement compared with LLM or RL standalone, achieving the complementary performance in the cybersecurity games.",
    "pdf_link": "https://arxiv.org/abs/2403.17674",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2403.17674v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.17674/Figure_3-1.png"
      },
      {
        "url": "https://arxiv.org/html/2403.17674v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.17674/Figure_3-2.png"
      },
      {
        "url": "https://arxiv.org/html/2403.17674v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.17674/figure_llm_framework.png"
      },
      {
        "url": "https://arxiv.org/html/2403.17674v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.17674/figure_profile.png"
      },
      {
        "url": "https://arxiv.org/html/2403.17674v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.17674/figure_reflect_prompt_attack.png"
      },
      {
        "url": "https://arxiv.org/html/2403.17674v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.17674/figure_collaboration.png"
      },
      {
        "url": "https://arxiv.org/html/2403.17674v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.17674/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2403.17674v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.17674/x2.png"
      }
    ],
    "abstract_cn": "在网络安全等关键任务中，高效融合大型语言模型（LLM）与强化学习（RL）代理以发挥协同效应至关重要。本研究提出了SecurityBot，这是一种由预训练RL代理辅导的LLM代理，旨在助力网络安全运维。SecurityBot配备了行为指南生成模块、经验积累记忆模块、选择重评反思模块以及动作空间缩减模块。同时，它还引入了协作机制，以获取来自预训练RL代理的建议，包括动态建议光标、多导师建议排名聚合器以及主动建议请求调用器。依托CybORG实验框架，我们的实验结果显示，SecurityBot相较于单独的LLM或RL代理，在网络安全对抗中实现了显著的性能提升，达成了预期的协同效果。",
    "title_cn": "在关键时刻自力更生：通过强化学习（RL）代理的辅导，培养大型语言模型（LLM）成为网络安全游戏的高手。",
    "tags": [
      "Agent",
      "网络安全",
      "人工智能"
    ]
  },
  {
    "title": "GPT-4's assessment of its performance in a USMLE-based case study",
    "submit_datetime": "2024年03月26日",
    "abstract": "This study investigates GPT-4's assessment of its performance in healthcare applications. A simple prompting technique was used to prompt the LLM with questions taken from the United States Medical Licensing Examination (USMLE) questionnaire and it was tasked to evaluate its confidence score before posing the question and after asking the question. The questionnaire was categorized into two groups-questions with feedback (WF) and questions with no feedback(NF) post-question. The model was asked to provide absolute and relative confidence scores before and after each question. The experimental findings were analyzed using statistical tools to study the variability of confidence in WF and NF groups. Additionally, a sequential analysis was conducted to observe the performance variation for the WF and NF groups. Results indicate that feedback influences relative confidence but doesn't consistently increase or decrease it. Understanding the performance of LLM is paramount in exploring its utility in sensitive areas like healthcare. This study contributes to the ongoing discourse on the reliability of AI, particularly of LLMs like GPT-4, within healthcare, offering insights into how feedback mechanisms might be optimized to enhance AI-assisted medical education and decision support.",
    "pdf_link": "https://arxiv.org/abs/2402.09654",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2402.09654v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.09654/FeedBack.png"
      },
      {
        "url": "https://arxiv.org/html/2402.09654v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.09654/No_feedback.png"
      },
      {
        "url": "https://arxiv.org/html/2402.09654v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.09654/pairPlotACvsRC.png"
      },
      {
        "url": "https://arxiv.org/html/2402.09654v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.09654/no_feedback_violin_plot.png"
      },
      {
        "url": "https://arxiv.org/html/2402.09654v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.09654/feedback_violin_plot.png"
      },
      {
        "url": "https://arxiv.org/html/2402.09654v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.09654/AC1Score.png"
      },
      {
        "url": "https://arxiv.org/html/2402.09654v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.09654/AC2.png"
      },
      {
        "url": "https://arxiv.org/html/2402.09654v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.09654/RC1.png"
      },
      {
        "url": "https://arxiv.org/html/2402.09654v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.09654/RC2.png"
      },
      {
        "url": "https://arxiv.org/html/2402.09654v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.09654/AC_Score_Plot_Sequential.png"
      },
      {
        "url": "https://arxiv.org/html/2402.09654v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.09654/screenshot_chat.png"
      },
      {
        "url": "https://arxiv.org/html/2402.09654v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.09654/AC2_Score_Plot_Sequential.png"
      },
      {
        "url": "https://arxiv.org/html/2402.09654v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.09654/RC1_Score_Plot_Sequential.png"
      },
      {
        "url": "https://arxiv.org/html/2402.09654v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.09654/RC2_Score_Plot_Sequential.png"
      }
    ],
    "abstract_cn": "本研究探讨了 GPT-4 在医疗领域应用的自我效能评估。通过简单提示法，我们用美国医学执照考试（USMLE）的题目对大型语言模型（LLM）进行提问，并要求其在提问前后自我评估置信度。问卷分为两组：有反馈（WF）和无反馈（NF）。模型需在每个问题前后提供绝对和相对置信度评分。实验数据通过统计分析，探究了 WF 组与 NF 组置信度的波动性。此外，通过序列分析观察两组的性能变化。研究发现，反馈对相对置信度有所影响，但并不总是导致置信度的一致性增减。深入理解 LLM 的性能对于其在医疗等敏感领域的应用至关重要。本研究为关于 AI，尤其是 GPT-4 等大型语言模型在医疗领域可靠性的讨论提供了新的视角，并就如何优化反馈机制以提升 AI 在医学教育和决策支持中的作用提供了洞见。",
    "title_cn": "GPT-4 对其在一项基于美国医学执照考试的案例研究中的表现进行了评估。",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Untangling Knots: Leveraging LLM for Error Resolution in Computational Notebooks",
    "submit_datetime": "2024年03月26日",
    "abstract": "Computational notebooks became indispensable tools for research-related development, offering unprecedented interactivity and flexibility in the development process. However, these benefits come at the cost of reproducibility and an increased potential for bugs. There are many tools for bug fixing; however, they are generally targeted at the classical linear code. With the rise of code-fluent Large Language Models, a new stream of smart bug-fixing tools has emerged. However, the applicability of those tools is still problematic for non-linear computational notebooks. In this paper, we propose a potential solution for resolving errors in computational notebooks via an iterative LLM-based agent. We discuss the questions raised by this approach and share a novel dataset of computational notebooks containing bugs to facilitate the research of the proposed approach.",
    "pdf_link": "https://arxiv.org/abs/2405.01559",
    "graphs": [],
    "abstract_cn": "计算型笔记本因其交互性和灵活性，已成为科研开发中的关键工具。但这种优势牺牲了代码的可复现性，并可能增加出错的风险。尽管市面上有众多针对传统线性代码的错误修复工具，它们在应对新兴的、能够处理复杂语言的大型语言模型时显得力不从心。本文提出了一种创新的解决方案，利用基于LLM的迭代代理来修正计算型笔记本中的错误。我们探讨了这种方法引发的一系列问题，并提供了一个包含缺陷的计算型笔记本数据集，以推动相关研究的发展。",
    "title_cn": "解开纠结：借助大型语言模型（LLM）之力，为计算型笔记本中的错误解析提供解决方案。",
    "tags": [
      "Agent",
      "科研开发",
      "软件工程"
    ]
  },
  {
    "title": "Generation of Asset Administration Shell with Large Language Model Agents: Interoperability in Digital Twins with Semantic Node",
    "submit_datetime": "2024年03月25日",
    "abstract": "This research introduces a novel approach for assisting the creation of Asset Administration Shell (AAS) instances for digital twin modeling within the context of Industry 4.0, aiming to enhance interoperability in smart manufacturing and reduce manual effort. We construct a \"semantic node\" data structure to capture the semantic essence of textual data. Then, a system powered by large language models is designed and implemented to process \"semantic node\" and generate AAS instance models from textual technical data. Our evaluation demonstrates a 62-79% effective generation rate, indicating a substantial proportion of manual creation effort can be converted into easier validation effort, thereby reducing the time and cost in creating AAS instance models. In our evaluation, a comparative analysis of different LLMs and an in-depth ablation study of Retrieval-Augmented Generation (RAG) mechanisms provide insights into the effectiveness of LLM systems for interpreting technical concepts. Our findings emphasize LLMs' capability in automating AAS instance creation, enhancing semantic interoperability, and contributing to the broader field of semantic interoperability for digital twins in industrial applications. The prototype implementation and evaluation results are released on our GitHub Repository with the link: https://github.com/YuchenXia/AASbyLLM",
    "pdf_link": "https://arxiv.org/abs/2403.17209",
    "graphs": [],
    "abstract_cn": "本研究提出了一种创新方法，辅助在工业4.0环境下创建数字孪生模型的资产行政壳（AAS）实例，目标是提升智能制造业的互操作性并降低人工操作的负担。我们设计了一种“语义节点”数据结构，用以捕捉文本数据的深层语义。基于此，开发了一个由大型语言模型支持的系统，它能够处理这些“语义节点”，并从技术文本数据中生成AAS实例模型。我们的评估结果表明，该系统的有效生成率高达62-79%，这意味着可以将大量手动创建工作转化为更简便的验证工作，从而显著降低创建AAS实例模型的时间和成本。在评估过程中，我们对多种大型语言模型进行了比较分析，并对检索增强生成（RAG）机制进行了深入的消融研究，这些研究揭示了LLM系统在理解技术概念方面的高效性。我们的研究结果突出了LLM在自动化创建AAS实例、提升语义互操作性以及在工业应用中数字孪生的语义互操作性领域的潜力。相关的原型实现和评估结果已在我们的GitHub仓库中公开，具体链接为：https://github.com/YuchenXia/AASbyLLM。",
    "title_cn": "通过大型语言模型代理打造资产管理壳，实现数字孪生体中的语义节点互操作性。",
    "tags": [
      "分类：LLM应用",
      "工业自动化",
      "智能制造"
    ]
  },
  {
    "title": "Norm Violation Detection in Multi-Agent Systems using Large Language Models: A Pilot Study",
    "submit_datetime": "2024年03月25日",
    "abstract": "Norms are an important component of the social fabric of society by prescribing expected behaviour. In Multi-Agent Systems (MAS), agents interacting within a society are equipped to possess social capabilities such as reasoning about norms and trust. Norms have long been of interest within the Normative Multi-Agent Systems community with researchers studying topics such as norm emergence, norm violation detection and sanctioning. However, these studies have some limitations: they are often limited to simple domains, norms have been represented using a variety of representations with no standard approach emerging, and the symbolic reasoning mechanisms generally used may suffer from a lack of extensibility and robustness. In contrast, Large Language Models (LLMs) offer opportunities to discover and reason about norms across a large range of social situations. This paper evaluates the capability of LLMs to detecting norm violations. Based on simulated data from 80 stories in a household context, with varying complexities, we investigated whether 10 norms are violated. For our evaluations we first obtained the ground truth from three human evaluators for each story. Then, the majority result was compared against the results from three well-known LLM models (Llama 2 7B, Mixtral 7B and ChatGPT-4). Our results show the promise of ChatGPT-4 for detecting norm violations, with Mixtral some distance behind. Also, we identify areas where these models perform poorly and discuss implications for future work.",
    "pdf_link": "https://arxiv.org/abs/2403.16517",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2403.16517v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.16517/freq_graph.png"
      },
      {
        "url": "https://arxiv.org/html/2403.16517v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.16517/confusion_matrix.png"
      },
      {
        "url": "https://arxiv.org/html/2403.16517v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.16517/chat_gpt.png"
      }
    ],
    "abstract_cn": "规范构成了社会结构的核心，它定义了社会预期的行为准则。在多智能体系统（MAS）中，智能体们被赋予了社会性能力，包括对规范和信任的推理。规范一直是规范性多智能体系统研究社区的热点，涉及规范的形成、违规检测和处罚等议题。尽管如此，现有研究存在局限，如局限于特定领域、规范的表达方式多样且缺乏统一标准，以及符号推理机制在可扩展性和鲁棒性上的不足。与此相对，大型语言模型（LLMs）为我们在多样化的社会情境中探索和推理规范提供了新的可能性。本文旨在评估LLMs在规范违规检测方面的能力。我们利用家庭环境中80个故事的模拟数据，探究了10种不同规范的遵守情况。通过三名人类评估员对每个故事的独立评估，我们确定了基准真实情况，并将其与三个著名LLM模型（Llama 2 7B、Mixtral 7B和ChatGPT-4）的检测结果进行了比较。研究结果显示，ChatGPT-4在规范违规检测方面展现出潜力，而Mixtral则稍显落后。同时，我们也发现了这些模型在某些方面的不足，并对未来研究方向提出了见解。",
    "title_cn": "利用大型语言模型开展多智能体系统中的规范违反检测：一项探索性研究。",
    "tags": [
      "分类：Agent",
      "社会规范",
      "多智能体系统"
    ]
  },
  {
    "title": "Fine Tuning LLM for Enterprise: Practical Guidelines and Recommendations",
    "submit_datetime": "2024年03月23日",
    "abstract": "There is a compelling necessity from enterprises for fine tuning LLMs (Large Language Models) o get them trained on proprietary domain knowledge. The challenge is to imbibe the LLMs with domain specific knowledge using the most optimial resource and cost and in the best possible time. Many enterprises rely on RAG (Retrieval Augmented Generation) which does not need LLMs to be ine-tuned but they are limited by the quality of vector databases and their retrieval capabilities rather than the intrinsic capabilities of the LLMs themselves. In our current work we focus on fine tuning LLaMA, an open source LLM using proprietary documents and code from an enterprise repository and use the fine tuned models to evaluate the quality of responses. As part of this work, we aim to guide beginners on how to start with fine tuning an LLM for documentation and code by making educated guesses on size of GPU required and options that are available for formatting the data. We also propose pre processing recipes for both documentation and code to prepare dataset in different formats. The proposed methods of data preparation for document datasets are forming paragraph chunks, forming question and answer pairs and forming keyword and paragraph chunk pairs. For code dataset we propose forming summary and function pairs. Further, we qualitatively evaluate the results of the models for domain specific queries. Finally, we also propose practical guidelines and recommendations for fine tuning LLMs.",
    "pdf_link": "https://arxiv.org/abs/2404.10779",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.10779v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10779/text_finetune.jpg"
      },
      {
        "url": "https://arxiv.org/html/2404.10779v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10779/quantlatency.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10779v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10779/Llama2_7Bchat_modes.png"
      },
      {
        "url": "https://arxiv.org/html/2404.10779v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.10779/Llama2_13Bchat_modes.png"
      }
    ],
    "abstract_cn": "企业对大型语言模型（LLM）的精准调校有着迫切需求，目的是让这些模型能够掌握专有的领域知识。这一挑战的核心在于如何以最经济的资源、最低的成本以及最短的时间内，将特定领域的知识融入LLM。目前，众多企业采用RAG（检索增强生成）技术，该技术避免了对LLM的直接调校，但其性能受限于向量数据库的质量和检索系统的效能，而非LLM自身的潜力。在本项研究中，我们专注于对一个开源的LLM——LLaMA进行调校，利用企业存储库中的专有文档和代码，并通过调校后的模型来评估响应质量。此外，我们还旨在为初学者提供指导，帮助他们了解如何针对文档和代码对LLM进行调校，包括合理预估所需的GPU规模和数据格式化的可选方案。我们还为文档和代码数据集提出了数据预处理的方法，包括构建段落块、问答对、关键词与段落块对，以及为代码数据集构建摘要与功能对。我们进一步对模型在特定领域查询上的表现进行了定性评估，并最终提出了微调LLM的实用指南和建议。",
    "title_cn": "企业级大型语言模型微调：实用指南与建议。",
    "tags": [
      "分类：RAG",
      "企业知识管理",
      ""
    ]
  },
  {
    "title": "EduAgent: Generative Student Agents in Learning",
    "submit_datetime": "2024年03月23日",
    "abstract": "Student simulation in online education is important to address dynamic learning behaviors of students with diverse backgrounds. Existing simulation models based on deep learning usually need massive training data, lacking prior knowledge in educational contexts. Large language models (LLMs) may contain such prior knowledge since they are pre-trained from a large corpus. However, because student behaviors are dynamic and multifaceted with individual differences, directly prompting LLMs is not robust nor accurate enough to capture fine-grained interactions among diverse student personas, learning behaviors, and learning outcomes. This work tackles this problem by presenting a newly annotated fine-grained large-scale dataset and proposing EduAgent, a novel generative agent framework incorporating cognitive prior knowledge (i.e., theoretical findings revealed in cognitive science) to guide LLMs to first reason correlations among various behaviors and then make simulations. Our two experiments show that EduAgent could not only mimic and predict learning behaviors of real students but also generate realistic learning behaviors of virtual students without real data.",
    "pdf_link": "https://arxiv.org/abs/2404.07963",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2404.07963v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.07963/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2404.07963v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.07963/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2404.07963v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.07963/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2404.07963v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.07963/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2404.07963v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.07963/appendix_dataset2_distribution.png"
      },
      {
        "url": "https://arxiv.org/html/2404.07963v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.07963/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2404.07963v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.07963/appendix_gaze_simulation.png"
      },
      {
        "url": "https://arxiv.org/html/2404.07963v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.07963/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2404.07963v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.07963/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2404.07963v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.07963/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2404.07963v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.07963/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2404.07963v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.07963/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2404.07963v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.07963/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2404.07963v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.07963/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2404.07963v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.07963/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2404.07963v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.07963/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2404.07963v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.07963/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2404.07963v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2404.07963/x16.png"
      }
    ],
    "abstract_cn": "在网络教育领域，模拟学生行为对于理解和应对来自不同背景学生的多样化学习动态至关重要。尽管基于深度学习的模拟模型需依赖大量训练数据，它们在教育领域的先验知识方面往往不足。大型语言模型（LLMs）由于其庞大的预训练语料库，可能蕴含了丰富的教育相关先验知识。但是，学生行为的多样性和动态性要求我们不能简单地直接利用LLMs来进行模拟，因为这在捕捉学生个体差异、学习行为和成果之间的细微联系方面既不稳定也不够精确。本研究通过引入一个细粒度的大规模数据集，并设计了EduAgent——一个创新的生成代理框架，它融合了认知科学的理论发现作为认知先验知识，引导LLMs首先分析不同学习行为之间的关联，然后进行模拟。我们的两项实验证明，EduAgent不仅能够模拟和预测真实学生的行为模式，还能在没有实际数据的情况下生成虚拟学生的现实学习行为。",
    "title_cn": "EduAgent：在学习过程中应用的创造性学生代理",
    "tags": [
      "Agent",
      "网络教育",
      "人工智能"
    ]
  },
  {
    "title": "LlamBERT: Large-scale low-cost data annotation in NLP",
    "submit_datetime": "2024年03月23日",
    "abstract": "Large Language Models (LLMs), such as GPT-4 and Llama 2, show remarkable proficiency in a wide range of natural language processing (NLP) tasks. Despite their effectiveness, the high costs associated with their use pose a challenge. We present LlamBERT, a hybrid approach that leverages LLMs to annotate a small subset of large, unlabeled databases and uses the results for fine-tuning transformer encoders like BERT and RoBERTa. This strategy is evaluated on two diverse datasets: the IMDb review dataset and the UMLS Meta-Thesaurus. Our results indicate that the LlamBERT approach slightly compromises on accuracy while offering much greater cost-effectiveness.",
    "pdf_link": "https://arxiv.org/abs/2403.15938",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2403.15938v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.15938/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2403.15938v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.15938/x2.png"
      }
    ],
    "abstract_cn": "诸如 GPT-4 和 Llama 2 这样的大型语言模型在多样的自然语言处理任务上展现了卓越的能力。然而，它们的高效能也伴随着高昂的经济成本，这无疑是一个难题。我们介绍了 LlamBERT，这是一种创新的混合策略，它通过利用大型语言模型对大量未标记数据库的一小部分进行注释，并以此为基础对 BERT 和 RoBERTa 等变换器编码器进行精细调整。该方法在 IMDb 影评数据集和 UMLS 元词库两大迥异的数据集上进行了测试。测试结果显示，尽管 LlamBERT 在精确度上略有牺牲，但其性价比却显著提升。",
    "title_cn": "LlamBERT：自然语言处理领域的大规模低成本数据标注解决方案",
    "tags": [
      "LLM应用",
      "",
      ""
    ]
  },
  {
    "title": "Using Large Language Models for OntoClean-based Ontology Refinement",
    "submit_datetime": "2024年03月23日",
    "abstract": "This paper explores the integration of Large Language Models (LLMs) such as GPT-3.5 and GPT-4 into the ontology refinement process, specifically focusing on the OntoClean methodology. OntoClean, critical for assessing the metaphysical quality of ontologies, involves a two-step process of assigning meta-properties to classes and verifying a set of constraints. Manually conducting the first step proves difficult in practice, due to the need for philosophical expertise and lack of consensus among ontologists. By employing LLMs with two prompting strategies, the study demonstrates that high accuracy in the labelling process can be achieved. The findings suggest the potential for LLMs to enhance ontology refinement, proposing the development of plugin software for ontology tools to facilitate this integration.",
    "pdf_link": "https://arxiv.org/abs/2403.15864",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2403.15864v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.15864/process_pipeline.png"
      },
      {
        "url": "https://arxiv.org/html/2403.15864v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.15864/representations.jpg"
      },
      {
        "url": "https://arxiv.org/html/2403.15864v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.15864/zero-3.5.png"
      },
      {
        "url": "https://arxiv.org/html/2403.15864v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.15864/zero-4.png"
      },
      {
        "url": "https://arxiv.org/html/2403.15864v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.15864/few-3.5.png"
      },
      {
        "url": "https://arxiv.org/html/2403.15864v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.15864/few-4.png"
      }
    ],
    "abstract_cn": "本研究着眼于将如 GPT-3.5 和 GPT-4 这样的大型语言模型融入到本体论的精细化流程中，尤其聚焦于 OntoClean 方法。OntoClean 在评估本体论的哲学质量方面发挥关键作用，它包括为类别分配元属性和检验一系列约束的两个步骤。实际操作中，由于需要深厚的哲学背景和本体论专家之间的意见分歧，手动执行第一步颇为棘手。研究通过采用两种不同的提示策略，利用 LLMs 展示了在标记过程中能够达到高准确度。这些发现揭示了 LLMs 在提升本体论精细化方面的潜力，并提出了开发插件软件以促进本体论工具与 LLMs 融合的构想。",
    "title_cn": "本文探讨了如何利用大型语言模型对基于 OntoClean 方法论的本体进行精细化处理。",
    "tags": [
      "LLM应用",
      "本体论",
      "人工智能"
    ]
  },
  {
    "title": "CACA Agent: Capability Collaboration based AI Agent",
    "submit_datetime": "2024年03月22日",
    "abstract": "As AI Agents based on Large Language Models (LLMs) have shown potential in practical applications across various fields, how to quickly deploy an AI agent and how to conveniently expand the application scenario of AI agents has become a challenge. Previous studies mainly focused on implementing all the reasoning capabilities of AI agents within a single LLM, which often makes the model more complex and also reduces the extensibility of AI agent functionality. In this paper, we propose CACA Agent (Capability Collaboration based AI Agent), using an open architecture inspired by service computing. CACA Agent integrates a set of collaborative capabilities to implement AI Agents, not only reducing the dependence on a single LLM, but also enhancing the extensibility of both the planning abilities and the tools available to AI agents. Utilizing the proposed system, we present a demo to illustrate the operation and the application scenario extension of CACA Agent.",
    "pdf_link": "https://arxiv.org/abs/2403.15137",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2403.15137v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.15137/framework.png"
      },
      {
        "url": "https://arxiv.org/html/2403.15137v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.15137/workflow1.png"
      },
      {
        "url": "https://arxiv.org/html/2403.15137v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.15137/demo.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLM）支撑的人工智能代理在多领域实际应用中展现潜力，如何迅速部署AI代理及便捷扩展其应用场景成为新挑战。过往研究多聚焦于单机LLM内集成AI代理的推理能力，导致模型复杂化，影响功能扩展性。本文提出CACA代理——一种基于服务计算启发的开放式架构，通过整合协作能力集，实现AI代理功能，既降低了对单一LLM的依赖，也提升了规划能力和工具的扩展性。我们通过一个演示案例，展示了CACA代理的操作流程和应用场景的扩展潜力。",
    "title_cn": "CACA 智能代理：一种依托能力协同的人工智能代理",
    "tags": [
      "Agent",
      "人工智能",
      "服务计算"
    ]
  },
  {
    "title": "Content Knowledge Identification with Multi-Agent Large Language Models (LLMs)",
    "submit_datetime": "2024年03月21日",
    "abstract": "Teachers' mathematical content knowledge (CK) is of vital importance and need in teacher professional development (PD) programs. Computer-aided asynchronous PD systems are the most recent proposed PD techniques, which aim to help teachers improve their PD equally with fewer concerns about costs and limitations of time or location. However, current automatic CK identification methods, which serve as one of the core techniques of asynchronous PD systems, face challenges such as diversity of user responses, scarcity of high-quality annotated data, and low interpretability of the predictions. To tackle these challenges, we propose a Multi-Agent LLMs-based framework, LLMAgent-CK, to assess the user responses' coverage of identified CK learning goals without human annotations. By taking advantage of multi-agent LLMs in strong generalization ability and human-like discussions, our proposed LLMAgent-CK presents promising CK identifying performance on a real-world mathematical CK dataset MaCKT. Moreover, our case studies further demonstrate the working of the multi-agent framework.",
    "pdf_link": "https://arxiv.org/abs/2404.07960",
    "graphs": [],
    "abstract_cn": "数学内容知识（CK）对教师的专业成长至关重要，而计算机辅助的异步专业发展（PD）系统，作为最新的PD技术，旨在帮助教师在成本和时间、地点限制上减少顾虑，提升PD效果。尽管如此，现有的自动CK识别技术——异步PD系统的核心组成部分——仍面临着用户反馈多样性、高质量标注数据匮乏以及预测结果难以解释等问题。为解决这些问题，我们设计了一个基于多代理大型语言模型（LLM）的框架——LLMAgent-CK，它能够在无需人工注释的情况下，评估用户反馈对既定CK学习目标的覆盖度。利用多代理LLM的强大泛化能力和类人讨论特点，LLMAgent-CK在真实数学CK数据集MaCKT上显示出了出色的识别性能。此外，案例研究进一步证实了多代理框架的有效性。",
    "title_cn": "通过多代理大型语言模型（LLMs）实现内容知识的精准识别。",
    "tags": [
      "Agent",
      "",
      "人工智能"
    ]
  },
  {
    "title": "AutoMix: Automatically Mixing Language Models",
    "submit_datetime": "2024年03月20日",
    "abstract": "Large language models (LLMs) are now available from cloud API providers in various sizes and configurations. While this diversity offers a broad spectrum of choices, effectively leveraging the options to optimize computational cost and performance remains challenging. In this work, we present AutoMix, an approach that strategically routes queries to larger LMs, based on the approximate correctness of outputs from a smaller LM. Central to AutoMix is a few-shot self-verification mechanism, which estimates the reliability of its own outputs without requiring training. Given that verifications can be noisy, we employ a meta-verifier in AutoMix to refine the accuracy of these assessments. Our experiments using LLAMA2-13B and GPT-4, on five context-grounded reasoning datasets demonstrate that AutoMix surpasses established baselines, improving the incremental benefit per cost by up to 86%. Our code and data are available at https://github.com/automix-llm/automix.",
    "pdf_link": "https://arxiv.org/abs/2310.12963",
    "graphs": [],
    "abstract_cn": "如今，多种规模和配置的大型语言模型（LLMs）可通过云API轻松获取。尽管选择众多，但要高效利用这些资源以优化计算成本和性能并非易事。本研究介绍了AutoMix，这是一种智能路由查询至更大型语言模型的方法，依据是较小语言模型输出的正确性。AutoMix的精髓在于一种少量样本自我验证机制，它能够在无需训练的情况下评估自身输出的可信度。鉴于自我验证可能存在误差，AutoMix采用了元验证器来进一步提升评估的精确度。通过在五个基于上下文的推理数据集上的测试，我们发现AutoMix在提升性价比方面，相比现有基准提升了高达86%的增量效益。相关代码和数据已在 https://github.com/automix-llm/automix 上公开。",
    "title_cn": "AutoMix：智能融合语言模型，实现自动混编",
    "tags": [
      "LLM应用",
      "云计算",
      ""
    ]
  },
  {
    "title": "Meta-Prompting for Automating Zero-shot Visual Recognition with LLMs",
    "submit_datetime": "2024年03月19日",
    "abstract": "Prompt ensembling of Large Language Model (LLM) generated category-specific prompts has emerged as an effective method to enhance zero-shot recognition ability of Vision-Language Models (VLMs). To obtain these category-specific prompts, the present methods rely on hand-crafting the prompts to the LLMs for generating VLM prompts for the downstream tasks. However, this requires manually composing these task-specific prompts and still, they might not cover the diverse set of visual concepts and task-specific styles associated with the categories of interest. To effectively take humans out of the loop and completely automate the prompt generation process for zero-shot recognition, we propose Meta-Prompting for Visual Recognition (MPVR). Taking as input only minimal information about the target task, in the form of its short natural language description, and a list of associated class labels, MPVR automatically produces a diverse set of category-specific prompts resulting in a strong zero-shot classifier. MPVR generalizes effectively across various popular zero-shot image recognition benchmarks belonging to widely different domains when tested with multiple LLMs and VLMs. For example, MPVR obtains a zero-shot recognition improvement over CLIP by up to 19.8% and 18.2% (5.0% and 4.5% on average over 20 datasets) leveraging GPT and Mixtral LLMs, respectively",
    "pdf_link": "https://arxiv.org/abs/2403.11755",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2403.11755v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.11755/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2403.11755v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.11755/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2403.11755v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.11755/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2403.11755v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.11755/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2403.11755v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.11755/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2403.11755v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.11755/x6.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLM）生成的类别特定提示的集成化，已成为提升视觉-语言模型（VLM）零样本识别能力的有效手段。现行方法通过手工为LLM定制提示来生成VLM的下游任务提示，但这种方法不仅需要人工编写任务特定的提示，而且可能无法全面覆盖与目标类别相关的多样化视觉概念和任务风格。为了彻底实现零样本识别中提示生成过程的自动化，避免人工干预，我们提出了一种新方法——视觉识别的元提示（MPVR）。MPVR仅需目标任务的简短自然语言描述及其类别标签列表，便能自动产出一系列多样化的类别特定提示，构建出强大的零样本分类器。在多个流行的零样本图像识别基准测试中，MPVR展现出良好的泛化能力，这些测试覆盖了截然不同的领域。例如，MPVR在使用GPT和Mixtral LLM时，相较于CLIP在零样本识别上分别实现了最多19.8%和18.2%的提升（在20个数据集上平均提升了5.0%和4.5%）。",
    "title_cn": "本文探讨了如何利用大型语言模型（LLMs）通过元提示技术，实现零样本视觉识别任务的自动化，以期提高模型在未见类别上的识别能力。",
    "tags": [
      "分类：LLM应用",
      "视觉识别",
      ""
    ]
  },
  {
    "title": "LLMs-based Few-Shot Disease Predictions using EHR: A Novel Approach Combining Predictive Agent Reasoning and Critical Agent Instruction",
    "submit_datetime": "2024年03月19日",
    "abstract": "Electronic health records (EHRs) contain valuable patient data for health-related prediction tasks, such as disease prediction. Traditional approaches rely on supervised learning methods that require large labeled datasets, which can be expensive and challenging to obtain. In this study, we investigate the feasibility of applying Large Language Models (LLMs) to convert structured patient visit data (e.g., diagnoses, labs, prescriptions) into natural language narratives. We evaluate the zero-shot and few-shot performance of LLMs using various EHR-prediction-oriented prompting strategies. Furthermore, we propose a novel approach that utilizes LLM agents with different roles: a predictor agent that makes predictions and generates reasoning processes and a critic agent that analyzes incorrect predictions and provides guidance for improving the reasoning of the predictor agent. Our results demonstrate that with the proposed approach, LLMs can achieve decent few-shot performance compared to traditional supervised learning methods in EHR-based disease predictions, suggesting its potential for health-oriented applications.",
    "pdf_link": "https://arxiv.org/abs/2403.15464",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2403.15464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.15464/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2403.15464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.15464/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2403.15464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.15464/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2403.15464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.15464/x4.png"
      }
    ],
    "abstract_cn": "电子健康档案中蕴含的宝贵患者信息，对于疾病预测等健康相关预测任务至关重要。传统上，这些任务依赖于监督学习，这需要大量且难以获得的标记数据集。本研究探讨了使用大型语言模型（LLMs）将患者的结构化访问信息（如诊断、检验结果、处方）转化为自然语言叙述的可能性。我们通过不同的电子健康记录预测策略，评估了LLMs在零样本和少样本情况下的表现。此外，我们还提出了一种创新的方法，该方法涉及具有不同角色的LLM代理：一个负责预测和生成推理过程的预测代理，以及一个分析错误预测并提供改进预测代理推理方法的批评代理。研究结果显示，采用这种方法，LLMs在基于电子健康记录的疾病预测任务上，与传统的监督学习方法相比，能够实现相当不错的少样本性能，这为其在健康领域应用的潜力提供了有力证明。",
    "title_cn": "利用大型语言模型（LLM）和电子健康记录（EHR）进行的少量样本疾病预测：我们提出了一种创新的方法，融合了预测性代理推理与关键性代理指导。",
    "tags": [
      "Agent",
      "健康医疗",
      "人工智能"
    ]
  },
  {
    "title": "Embodied LLM Agents Learn to Cooperate in Organized Teams",
    "submit_datetime": "2024年03月19日",
    "abstract": "Large Language Models (LLMs) have emerged as integral tools for reasoning, planning, and decision-making, drawing upon their extensive world knowledge and proficiency in language-related tasks. LLMs thus hold tremendous potential for natural language interaction within multi-agent systems to foster cooperation. However, LLM agents tend to over-report and comply with any instruction, which may result in information redundancy and confusion in multi-agent cooperation. Inspired by human organizations, this paper introduces a framework that imposes prompt-based organization structures on LLM agents to mitigate these problems. Through a series of experiments with embodied LLM agents and human-agent collaboration, our results highlight the impact of designated leadership on team efficiency, shedding light on the leadership qualities displayed by LLM agents and their spontaneous cooperative behaviors. Further, we harness the potential of LLMs to propose enhanced organizational prompts, via a Criticize-Reflect process, resulting in novel organization structures that reduce communication costs and enhance team efficiency.",
    "pdf_link": "https://arxiv.org/abs/2403.12482",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2403.12482v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.12482/Examples_intro_2.png"
      },
      {
        "url": "https://arxiv.org/html/2403.12482v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.12482/Architecture_2.png"
      },
      {
        "url": "https://arxiv.org/html/2403.12482v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.12482/Framework_overview_4.png"
      },
      {
        "url": "https://arxiv.org/html/2403.12482v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.12482/org_results_13.png"
      },
      {
        "url": "https://arxiv.org/html/2403.12482v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.12482/LLM_types.png"
      },
      {
        "url": "https://arxiv.org/html/2403.12482v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.12482/Examples_behavior_5.png"
      },
      {
        "url": "https://arxiv.org/html/2403.12482v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.12482/behavior_ratio_11.png"
      },
      {
        "url": "https://arxiv.org/html/2403.12482v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.12482/reflection_results_7.png"
      },
      {
        "url": "https://arxiv.org/html/2403.12482v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.12482/comm_fig_all_8.png"
      },
      {
        "url": "https://arxiv.org/html/2403.12482v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.12482/across_tasks_2.png"
      },
      {
        "url": "https://arxiv.org/html/2403.12482v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.12482/election_examples.png"
      },
      {
        "url": "https://arxiv.org/html/2403.12482v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.12482/human_AI_examples.png"
      },
      {
        "url": "https://arxiv.org/html/2403.12482v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.12482/correction_examples.png"
      },
      {
        "url": "https://arxiv.org/html/2403.12482v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.12482/new_prompt_examples.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）在推理、规划和决策中发挥着不可或缺的作用，它们凭借深厚的世界知识和语言任务处理能力，成为多智能体系统中促进自然语言互动的关键。然而，LLM智能体在执行指令时往往过于顺从，这可能引起信息重复和合作混乱。本研究借鉴人类组织结构，提出了一种框架，通过基于提示的组织结构来优化LLM智能体的行为，以减少这些问题。通过与具体化的LLM智能体和人类智能体的协作实验，我们发现指定领导对提升团队效率具有显著影响，同时揭示了LLM智能体展现的领导特质及其自发的合作行为。此外，我们通过批评-反思过程，提出了一种增强的组织提示，旨在构建新的组织结构，以降低沟通成本，提高团队协作效率。",
    "title_cn": "具象化的 LLM 代理学会了在有组织的团队中协同合作。",
    "tags": [
      "Agent",
      "人工智能",
      "多智能体系统"
    ]
  },
  {
    "title": "Transforming Competition into Collaboration: The Revolutionary Role of Multi-Agent Systems and Language Models in Modern Organizations",
    "submit_datetime": "2024年03月15日",
    "abstract": "This article explores the dynamic influence of computational entities based on multi-agent systems theory (SMA) combined with large language models (LLM), which are characterized by their ability to simulate complex human interactions, as a possibility to revolutionize human user interaction from the use of specialized artificial agents to support everything from operational organizational processes to strategic decision making based on applied knowledge and human orchestration. Previous investigations reveal that there are limitations, particularly in the autonomous approach of artificial agents, especially when dealing with new challenges and pragmatic tasks such as inducing logical reasoning and problem solving. It is also considered that traditional techniques, such as the stimulation of chains of thoughts, require explicit human guidance. In our approach we employ agents developed from large language models (LLM), each with distinct prototyping that considers behavioral elements, driven by strategies that stimulate the generation of knowledge based on the use case proposed in the scenario (role-play) business, using a discussion approach between agents (guided conversation). We demonstrate the potential of developing agents useful for organizational strategies, based on multi-agent system theories (SMA) and innovative uses based on large language models (LLM based), offering a differentiated and adaptable experiment to different applications, complexities, domains, and capabilities from LLM.",
    "pdf_link": "https://arxiv.org/abs/2403.07769",
    "graphs": [],
    "abstract_cn": "本文深入探讨了融合多代理系统理论（SMA）与大型语言模型（LLM）的计算实体的动态影响力，这些模型以其模拟复杂人际互动的能力而闻名，为人类用户交互方式带来了革命性的变化，从依赖特定人工智能代理到全方位支持组织运营流程和基于应用知识与人类协同的战略决策。先前的研究指出，特别是在自主人工智能代理的方法上存在局限，尤其是在面对新挑战和实用任务，如逻辑推理和问题解决时。此外，传统技术如思维链的刺激需要明确的人类引导。我们的方法采用了基于LLM开发的代理，每个代理都具有独特的原型，考虑了行为元素，并由策略驱动，这些策略旨在激发基于场景（角色扮演）业务用例的知识生成，通过代理间的讨论（引导对话）进行。我们展示了利用基于SMA的多代理系统理论和基于LLM的创新应用，开发出适用于组织战略的代理的潜力，为不同应用、复杂性、领域和LLM能力提供了差异化和适应性的实验。",
    "title_cn": "将竞争转化为合作：多智能体系统与语言模型在现代组织中的革新性角色。",
    "tags": [
      "Agent",
      "人工智能",
      "组织运营"
    ]
  },
  {
    "title": "MEND: Meta dEmonstratioN Distillation for Efficient and Effective In-Context Learning",
    "submit_datetime": "2024年03月12日",
    "abstract": "Large Language models (LLMs) have demonstrated impressive in-context learning (ICL) capabilities, where a LLM makes predictions for a given test input together with a few input-output pairs (demonstrations). Nevertheless, the inclusion of demonstrations leads to a quadratic increase in the computational overhead of the self-attention mechanism. Existing solutions attempt to distill lengthy demonstrations into compact vectors. However, they often require task-specific retraining or compromise LLM's in-context learning performance. To mitigate these challenges, we present Meta dEmonstratioN Distillation (MEND), where a language model learns to distill any lengthy demonstrations into vectors without retraining for a new downstream task. We exploit the knowledge distillation to enhance alignment between MEND and LLM, achieving both efficiency and effectiveness simultaneously. MEND is endowed with the meta-knowledge of distilling demonstrations through a two-stage training process, which includes meta-distillation pretraining and fine-tuning. Comprehensive evaluations across seven diverse ICL task partitions using decoder-only (GPT-2) and encoder-decoder (T5) attest to MEND's prowess. It not only matches but often outperforms the Vanilla ICL as well as other state-of-the-art distillation models, while significantly reducing the computational demands. This innovation promises enhanced scalability and efficiency for the practical deployment of large language models",
    "pdf_link": "https://arxiv.org/abs/2403.06914",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2403.06914v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.06914/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2403.06914v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.06914/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2403.06914v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.06914/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2403.06914v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.06914/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2403.06914v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.06914/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2403.06914v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.06914/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2403.06914v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.06914/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2403.06914v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.06914/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2403.06914v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.06914/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2403.06914v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.06914/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2403.06914v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.06914/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2403.06914v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.06914/x12.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）在上下文学习（ICL）方面展现出了卓越的能力，能够结合少量输入输出对（示例）对特定测试输入进行预测。但引入示例会使自注意力机制的计算成本呈指数级增长。现有方法试图将复杂的示例简化为简洁的向量，却往往需要特定任务的重新训练或以牺牲模型的ICL性能为代价。为了应对这些挑战，我们引入了Meta dEmonstratioN Distillation（MEND）技术，这是一种无需针对新任务重新训练即可将长示例转化为向量的语言模型。MEND利用知识蒸馏技术，增强了与LLM的一致性，实现了效率与效果的双赢。通过包含元蒸馏预训练和微调的两阶段训练流程，MEND获得了蒸馏示例的元知识。在七个多样化的ICL任务领域的全面评估中，无论是使用仅解码器模型（GPT-2）还是编码器-解码器模型（T5），MEND都展现了其强大的性能。它不仅能够匹敌传统的ICL，常常还能超越其他尖端的蒸馏模型，并且在大幅度降低计算需求的同时，为大型语言模型的实际应用提供了更好的可扩展性和效率。",
    "title_cn": "MEND：通过元示范展示的蒸馏技术，实现高效且有效的情境内学习。",
    "tags": [
      "LLM应用",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Data Interpreter: An LLM Agent For Data Science",
    "submit_datetime": "2024年03月12日",
    "abstract": "Large Language Model (LLM)-based agents have demonstrated remarkable effectiveness. However, their performance can be compromised in data science scenarios that require real-time data adjustment, expertise in optimization due to complex dependencies among various tasks, and the ability to identify logical errors for precise reasoning. In this study, we introduce the Data Interpreter, a solution designed to solve with code that emphasizes three pivotal techniques to augment problem-solving in data science: 1) dynamic planning with hierarchical graph structures for real-time data adaptability;2) tool integration dynamically to enhance code proficiency during execution, enriching the requisite expertise;3) logical inconsistency identification in feedback, and efficiency enhancement through experience recording. We evaluate the Data Interpreter on various data science and real-world tasks. Compared to open-source baselines, it demonstrated superior performance, exhibiting significant improvements in machine learning tasks, increasing from 0.86 to 0.95. Additionally, it showed a 26% increase in the MATH dataset and a remarkable 112% improvement in open-ended tasks. The solution will be released at https://github.com/geekan/MetaGPT.",
    "pdf_link": "https://arxiv.org/abs/2402.18679",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2402.18679v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.18679/fig1-comp_1.png"
      },
      {
        "url": "https://arxiv.org/html/2402.18679v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.18679/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2402.18679v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.18679/fig2-task-graph-new.jpg"
      },
      {
        "url": "https://arxiv.org/html/2402.18679v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.18679/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2402.18679v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.18679/tools_deployment.png"
      },
      {
        "url": "https://arxiv.org/html/2402.18679v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.18679/ace-example_2_1.png"
      },
      {
        "url": "https://arxiv.org/html/2402.18679v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.18679/MATH-resize-color.png"
      },
      {
        "url": "https://arxiv.org/html/2402.18679v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.18679/llms_radar_chart.png"
      },
      {
        "url": "https://arxiv.org/html/2402.18679v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.18679/task_node_1.jpg"
      },
      {
        "url": "https://arxiv.org/html/2402.18679v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.18679/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2402.18679v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.18679/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2402.18679v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.18679/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2402.18679v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.18679/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2402.18679v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.18679/output-opentask-1.png"
      },
      {
        "url": "https://arxiv.org/html/2402.18679v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.18679/output_task_2.png"
      },
      {
        "url": "https://arxiv.org/html/2402.18679v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.18679/visual.png"
      }
    ],
    "abstract_cn": "基于LLM的代理在数据科学领域表现出色，但在需要实时数据调整、复杂任务依赖优化以及精确推理逻辑错误识别的场景中，其性能可能受限。为此，我们提出了数据解释器，这一方案通过三种关键技术提升数据科学问题解决能力：1）利用分层图结构实现动态规划，以适应实时数据变化；2）动态整合工具，提升执行中的代码熟练度，增强专业技能；3）识别反馈中的逻辑不一致，并通过经验记录提高效率。在多项数据科学和实际任务测试中，数据解释器相比开源基准表现更优，机器学习任务性能从0.86提升至0.95，MATH数据集性能提升26%，开放式任务性能更是惊人地提升了112%。该解决方案将在GitHub上发布，网址为https://github.com/geekan/MetaGPT。",
    "title_cn": "数据解码者：大型语言模型驱动的数据科学智能助手",
    "tags": [
      "Agent\n\n这篇论文介绍了一种基于大型语言模型（LLM）的代理——数据解释器，它专门设计来提升在数据科学领域中的性能，特别是在需要实时数据调整、复杂任务依赖优化以及精确推理逻辑错误识别的场景中。数据解释器通过三种关键技术来实现这一目标，包括分层图结构的动态规划、动态整合工具以提升代码熟练度，以及识别并纠正逻辑不一致。这些特性使得数据解释器在多项测试中表现出色，显著优于现有的开源基准。因此，这篇论文属于Agent分类，因为它描述了一个具体的LLM应用实例，即一个能够执行数据科学任务的智能代理。",
      "数据科学",
      "机器学习"
    ]
  },
  {
    "title": "LLM4VV: Developing LLM-Driven Testsuite for Compiler Validation",
    "submit_datetime": "2024年03月10日",
    "abstract": "Large language models (LLMs) are a new and powerful tool for a wide span of applications involving natural language and demonstrate impressive code generation abilities. The goal of this work is to automatically generate tests and use these tests to validate and verify compiler implementations of a directive-based parallel programming paradigm, OpenACC. To do so, in this paper, we explore the capabilities of state-of-the-art LLMs, including open-source LLMs -- Meta Codellama, Phind fine-tuned version of Codellama, Deepseek Deepseek Coder and closed-source LLMs -- OpenAI GPT-3.5-Turbo and GPT-4-Turbo. We further fine-tuned the open-source LLMs and GPT-3.5-Turbo using our own testsuite dataset along with using the OpenACC specification. We also explored these LLMs using various prompt engineering techniques that include code template, template with retrieval-augmented generation (RAG), one-shot example, one-shot with RAG, expressive prompt with code template and RAG. This paper highlights our findings from over 5000 tests generated via all the above mentioned methods. Our contributions include: (a) exploring the capabilities of the latest and relevant LLMs for code generation, (b) investigating fine-tuning and prompt methods, and (c) analyzing the outcome of LLMs generated tests including manually analysis of representative set of tests. We found the LLM Deepseek-Coder-33b-Instruct produced the most passing tests followed by GPT-4-Turbo.",
    "pdf_link": "https://arxiv.org/abs/2310.04963",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）作为处理自然语言相关应用的强有力新工具，展现出卓越的代码生成才能。本研究旨在自动化生成测试用例，以验证并确认OpenACC这一基于指令的并行编程范式的编译器实现。在本论文中，我们深入探讨了包括开源模型如Meta Codellama、Codellama的Phind微调版、Deepseek Deepseek Coder，以及闭源模型如OpenAI的GPT-3.5-Turbo和GPT-4-Turbo在内的尖端LLMs的潜力。利用自有的测试套件数据集和OpenACC规范，我们对这些开源和GPT-3.5-Turbo模型进行了进一步的微调。此外，我们还尝试了多种提示工程技术，包括代码模板、RAG（检索增强生成）辅助模板、单次示例、RAG辅助单次示例、以及包含代码模板和RAG的表达性提示。本文汇总了通过上述方法生成的逾5000个测试的研究成果。我们的研究成果包括：（a）探究当前相关LLMs在代码生成上的能力，（b）调研微调与提示技巧，以及（c）分析LLMs生成测试的结果，并对一组代表性测试进行了手动分析。研究发现，Deepseek-Coder-33b-Instruct模型生成的通过测试数量最多，紧随其后的是GPT-4-Turbo。",
    "title_cn": "LLM4VV：构建基于大型语言模型的编译器验证测试集",
    "tags": [
      "LLM应用",
      "软件工程",
      "并行计算"
    ]
  },
  {
    "title": "An In-depth Evaluation of GPT-4 in Sentence Simplification with Error-based Human Assessment",
    "submit_datetime": "2024年03月07日",
    "abstract": "Sentence simplification, which rewrites a sentence to be easier to read and understand, is a promising technique to help people with various reading difficulties. With the rise of advanced large language models (LLMs), evaluating their performance in sentence simplification has become imperative. Recent studies have used both automatic metrics and human evaluations to assess the simplification abilities of LLMs. However, the suitability of existing evaluation methodologies for LLMs remains in question. First, the suitability of current automatic metrics on LLMs' simplification evaluation is still uncertain. Second, current human evaluation approaches in sentence simplification often fall into two extremes: they are either too superficial, failing to offer a clear understanding of the models' performance, or overly detailed, making the annotation process complex and prone to inconsistency, which in turn affects the evaluation's reliability. To address these problems, this study provides in-depth insights into LLMs' performance while ensuring the reliability of the evaluation. We design an error-based human annotation framework to assess the GPT-4's simplification capabilities. Results show that GPT-4 generally generates fewer erroneous simplification outputs compared to the current state-of-the-art. However, LLMs have their limitations, as seen in GPT-4's struggles with lexical paraphrasing. Furthermore, we conduct meta-evaluations on widely used automatic metrics using our human annotations. We find that while these metrics are effective for significant quality differences, they lack sufficient sensitivity to assess the overall high-quality simplification by GPT-4.",
    "pdf_link": "https://arxiv.org/abs/2403.04963",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2403.04963v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.04963/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2403.04963v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.04963/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2403.04963v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.04963/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2403.04963v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.04963/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2403.04963v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.04963/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2403.04963v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.04963/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2403.04963v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.04963/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2403.04963v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.04963/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2403.04963v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2403.04963/x9.png"
      }
    ],
    "abstract_cn": "句子简化技术，通过简化句子以提高其可读性，对于阅读有障碍的人群来说是一个充满希望的解决方案。随着大型语言模型（LLMs）的发展，准确评估它们在简化句子方面的性能变得尤为重要。近期研究综合运用了自动化指标和人工评估两种方式来衡量LLMs的简化技巧。然而，现有的评估方法是否适用于LLMs仍有待商榷。一方面，目前自动化指标在评估LLMs简化能力方面的适用性尚未明确；另一方面，现有的人工评估方法往往过于简单或过于复杂，无法准确反映模型的真实表现，且易导致评估结果的不一致性。为了克服这些挑战，本研究深入分析了LLMs在句子简化任务上的表现，并提出了一种基于错误的人工注释框架来评估GPT-4的简化效果。研究发现，GPT-4在生成错误简化输出方面通常优于当前的最先进技术。尽管如此，LLMs在词汇释义方面仍有局限，GPT-4在这方面的表现就是一个例证。此外，我们还对常用的自动化指标进行了元评估，发现这些指标虽然能够识别明显的质量差异，但对于评估GPT-4的整体高水准简化效果却不够敏感。",
    "title_cn": "深入剖析 GPT-4 在句子简化任务上的表现，并通过基于错误的人工评估来衡量。",
    "tags": [
      "LLM应用",
      "阅读辅助",
      ""
    ]
  },
  {
    "title": "Exploring the psychology of LLMs' Moral and Legal Reasoning",
    "submit_datetime": "2024年03月04日",
    "abstract": "Large language models (LLMs) exhibit expert-level performance in tasks across a wide range of different domains. Ethical issues raised by LLMs and the need to align future versions makes it important to know how state of the art models reason about moral and legal issues. In this paper, we employ the methods of experimental psychology to probe into this question. We replicate eight studies from the experimental literature with instances of Google's Gemini Pro, Anthropic's Claude 2.1, OpenAI's GPT-4, and Meta's Llama 2 Chat 70b. We find that alignment with human responses shifts from one experiment to another, and that models differ amongst themselves as to their overall alignment, with GPT-4 taking a clear lead over all other models we tested. Nonetheless, even when LLM-generated responses are highly correlated to human responses, there are still systematic differences, with a tendency for models to exaggerate effects that are present among humans, in part by reducing variance. This recommends caution with regards to proposals of replacing human participants with current state-of-the-art LLMs in psychological research and highlights the need for further research about the distinctive aspects of machine psychology.",
    "pdf_link": "https://arxiv.org/abs/2308.01264",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）在众多领域的任务上展现了专家级的能力。鉴于LLMs可能引发的伦理争议，以及未来版本需与人类价值观保持一致，探究这些尖端模型是如何处理道德和法律议题的变得尤为关键。本文借鉴实验心理学的手法，深入探讨了这一课题。我们复现了八项来自实验心理学文献的研究，涉及谷歌的Gemini Pro、Anthropic的Claude 2.1、OpenAI的GPT-4以及Meta的Llama 2 Chat 70b等模型。研究发现，模型与人类回应的契合度在不同实验间波动，且各模型在整体契合度上也互有差异，其中GPT-4在所有测试模型中表现最为突出。然而，即便LLM生成的回应与人类高度吻合，仍存在一些系统性差异，模型有时会放大人类反应中的效果，部分原因是通过降低变异性实现的。这提醒我们，在心理学研究中用当前的LLMs替代人类参与者需谨慎行事，并凸显了对机器心理学特有方面进行更深入研究的必要。",
    "title_cn": "本研究旨在深入探讨大型语言模型在道德和法律推理方面的心理学机制。",
    "tags": [
      "LLM应用",
      "人工智能伦理",
      "心理学"
    ]
  },
  {
    "title": "Killer Apps: Low-Speed, Large-Scale AI Weapons",
    "submit_datetime": "2024年03月01日",
    "abstract": "The accelerating advancements in Artificial Intelligence (AI) and Machine Learning (ML), highlighted by the development of cutting-edge Generative Pre-trained Transformer (GPT) models by organizations such as OpenAI, Meta, and Anthropic, present new challenges and opportunities in warfare and security. Much of the current focus is on AI's integration within weapons systems and its role in rapid decision-making in kinetic conflict. However, an equally important but often overlooked aspect is the potential of AI-based psychological manipulation at internet scales within the information domain. These capabilities could pose significant threats to individuals, organizations, and societies globally. This paper explores the concept of AI weapons, their deployment, detection, and potential countermeasures.",
    "pdf_link": "https://arxiv.org/abs/2402.01663",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2402.01663v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.01663/ContextExplorerSabotage.png"
      },
      {
        "url": "https://arxiv.org/html/2402.01663v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.01663/original_email.png"
      },
      {
        "url": "https://arxiv.org/html/2402.01663v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.01663/modified_email.png"
      }
    ],
    "abstract_cn": "随着 OpenAI、Meta 和 Anthropic 等机构开发的尖端生成预训练变换器（GPT）模型的问世，人工智能（AI）和机器学习（ML）的迅猛发展为战争与安全领域带来了前所未有的挑战与机遇。当前的研究热点多聚焦于AI在武器系统中的应用及其在快速决策中的作用。然而，一个同样关键却常被忽略的议题是AI在信息领域进行心理操控的潜力，这在全球范围内对个人、组织乃至整个社会都可能构成严重威胁。本文深入探讨了AI武器的概念，包括它们的部署、侦测以及可能的应对策略。",
    "title_cn": "杀手级应用：大规模低速的AI武器",
    "tags": [
      "分类：Agent",
      "战争与安全",
      "人工智能"
    ]
  },
  {
    "title": "Keeping LLMs Aligned After Fine-tuning: The Crucial Role of Prompt Templates",
    "submit_datetime": "2024年02月28日",
    "abstract": "Public LLMs such as the Llama 2-Chat have driven huge activity in LLM research. These models underwent alignment training and were considered safe. Recently Qi et al. (2023) reported that even benign fine-tuning (e.g., on seemingly safe datasets) can give rise to unsafe behaviors in the models. The current paper is about methods and best practices to mitigate such loss of alignment. Through extensive experiments on several chat models (Meta's Llama 2-Chat, Mistral AI's Mistral 7B Instruct v0.2, and OpenAI's GPT-3.5 Turbo), this paper uncovers that the prompt templates used during fine-tuning and inference play a crucial role in preserving safety alignment, and proposes the \"Pure Tuning, Safe Testing\" (PTST) principle -- fine-tune models without a safety prompt, but include it at test time. Fine-tuning experiments on GSM8K, ChatDoctor, and OpenOrca show that PTST significantly reduces the rise of unsafe behaviors, and even almost eliminates them in some cases.",
    "pdf_link": "https://arxiv.org/abs/2402.18540",
    "graphs": [],
    "abstract_cn": "公共大型语言模型（LLMs），例如 Llama 2-Chat，极大地激发了 LLM 研究领域的活跃度。这些模型经过了对齐训练，被认为安全性较高。然而，Qi 等研究者在 2023 年指出，即使是基于看似安全的数据库进行的良性微调，也可能引发模型的不安全行为。本文旨在探讨减少此类对齐偏差的方法和最佳实践。通过对多种聊天模型（包括 Meta 的 Llama 2-Chat、Mistral AI 的 Mistral 7B Instruct v0.2 和 OpenAI 的 GPT-3.5 Turbo）进行广泛的实验，我们发现微调和推理过程中使用的提示模板对于维持模型的安全对齐至关重要，并提出了“纯净微调，安全测试”（PTST）原则，即在没有安全提示的情况下进行模型微调，但在测试阶段加入安全提示。在 GSM8K、ChatDoctor 和 OpenOrca 上的微调实验结果表明，PTST 方法显著降低了不安全行为的发生，并在某些情况下几乎完全避免了这类问题。",
    "title_cn": "微调之后，如何确保大型语言模型保持其原有的校准状态？关键在于巧妙设计的提示模板。",
    "tags": [
      "分类：LLM应用",
      "人工智能安全",
      "聊天机器人"
    ]
  },
  {
    "title": "Language Agents as Optimizable Graphs",
    "submit_datetime": "2024年02月27日",
    "abstract": "Various human-designed prompt engineering techniques have been proposed to improve problem solvers based on Large Language Models (LLMs), yielding many disparate code bases. We unify these approaches by describing LLM-based agents as computational graphs. The nodes implement functions to process multimodal data or query LLMs, and the edges describe the information flow between operations. Graphs can be recursively combined into larger composite graphs representing hierarchies of inter-agent collaboration (where edges connect operations of different agents). Our novel automatic graph optimizers (1) refine node-level LLM prompts (node optimization) and (2) improve agent orchestration by changing graph connectivity (edge optimization). Experiments demonstrate that our framework can be used to efficiently develop, integrate, and automatically improve various LLM agents. The code can be found at https://github.com/metauto-ai/gptswarm.",
    "pdf_link": "https://arxiv.org/abs/2402.16823",
    "graphs": [],
    "abstract_cn": "为提升基于大型语言模型（LLM）的问题解决器性能，已提出众多由人工设计的提示工程技术，催生了多样化的代码库。我们通过将LLM驱动的代理比作计算图来整合这些方法。在这些图中，节点负责处理多模态数据或与LLM交互，而边则描绘了操作间的信息流动。这些图可以递归地合并成更复杂的复合图，形成代理间协作的层级结构。我们创新的自动图优化器通过（1）优化节点级别的LLM提示（节点优化）和（2）调整图的连接性以提升代理协作（边优化）。实验证明，我们的框架能够有效地开发、整合并自动提升各类LLM代理的性能。相关代码已在 https://github.com/metauto-ai/gptswarm 上发布。",
    "title_cn": "语言代理：图形优化的艺术",
    "tags": [
      "分类：Agent\n\n这篇论文的摘要描述了一种将大型语言模型（LLM）驱动的代理比作计算图的方法，并通过自动图优化器来提升代理的性能。这涉及到节点级别的LLM提示优化和调整图的连接性以提升代理协作。这些内容与Agent领域的研究相关，因为它们涉及到代理的设计、优化和协作。",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Efficient Tool Use with Chain-of-Abstraction Reasoning",
    "submit_datetime": "2024年02月26日",
    "abstract": "To achieve faithful reasoning that aligns with human expectations, large language models (LLMs) need to ground their reasoning to real-world knowledge (e.g., web facts, math and physical rules). Tools help LLMs access this external knowledge, but there remains challenges for fine-tuning LLM agents (e.g., Toolformer) to invoke tools in multi-step reasoning problems, where inter-connected tool calls require holistic and efficient tool usage planning.\n  In this work, we propose a new method for LLMs to better leverage tools in multi-step reasoning. Our method, Chain-of-Abstraction (CoA), trains LLMs to first decode reasoning chains with abstract placeholders, and then call domain tools to reify each reasoning chain by filling in specific knowledge. This planning with abstract chains enables LLMs to learn more general reasoning strategies, which are robust to shifts of domain knowledge (e.g., math results) relevant to different reasoning questions. It also allows LLMs to perform decoding and calling of external tools in parallel, which avoids the inference delay caused by waiting for tool responses. In mathematical reasoning and Wiki QA domains, we show that our method consistently outperforms previous chain-of-thought and tool-augmented baselines on both in-distribution and out-of-distribution test sets, with an average ~6% absolute QA accuracy improvement. LLM agents trained with our method also show more efficient tool use, with inference speed being on average ~1.4x faster than baseline tool-augmented LLMs.",
    "pdf_link": "https://arxiv.org/abs/2401.17464",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2401.17464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2401.17464/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2401.17464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2401.17464/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2401.17464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2401.17464/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2401.17464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2401.17464/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2401.17464v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2401.17464/x5.png"
      }
    ],
    "abstract_cn": "要实现符合人类预期的精准推理，大型语言模型（LLMs）必须将其推理植根于现实世界的知识体系中，如网络信息、数学和物理定律等。尽管现有工具能够帮助LLMs访问这些外部知识库，但在多步推理问题中，如何精准调整LLM代理（如Toolformer）以有效调用工具，仍是一个挑战，这需要对工具调用进行全局和高效的规划。在本研究中，我们提出了一种创新方法，旨在帮助LLMs在多步推理过程中更高效地利用工具。我们的方法称为抽象链（Chain-of-Abstraction，CoA），它训练LLMs首先识别出带有抽象占位符的推理链条，随后调用专业工具来填充具体知识，从而实现每个推理链条。这种基于抽象链条的规划方法不仅使LLMs能够掌握更为通用的推理策略，增强了对知识领域变化（如数学结果）的适应性，还能让LLMs同时进行解码和调用外部工具的操作，有效避免了因等待工具响应而产生的推理延迟。在数学推理和Wiki问答（Wiki QA）领域，我们的实验结果表明，相较于传统的链式思考和工具辅助方法，CoA方法在处理分布内和分布外测试集时，平均QA准确度提升了约6%，并且训练出的LLM代理在使用工具时更为高效，推理速度平均快了约1.4倍。",
    "title_cn": "通过抽象层次链推理实现高效工具运用",
    "tags": [
      "分类：LLM应用",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Large Language Model for Participatory Urban Planning",
    "submit_datetime": "2024年02月26日",
    "abstract": "Participatory urban planning is the mainstream of modern urban planning that involves the active engagement of residents. However, the traditional participatory paradigm requires experienced planning experts and is often time-consuming and costly. Fortunately, the emerging Large Language Models (LLMs) have shown considerable ability to simulate human-like agents, which can be used to emulate the participatory process easily. In this work, we introduce an LLM-based multi-agent collaboration framework for participatory urban planning, which can generate land-use plans for urban regions considering the diverse needs of residents. Specifically, we construct LLM agents to simulate a planner and thousands of residents with diverse profiles and backgrounds. We first ask the planner to carry out an initial land-use plan. To deal with the different facilities needs of residents, we initiate a discussion among the residents in each community about the plan, where residents provide feedback based on their profiles. Furthermore, to improve the efficiency of discussion, we adopt a fishbowl discussion mechanism, where part of the residents discuss and the rest of them act as listeners in each round. Finally, we let the planner modify the plan based on residents' feedback. We deploy our method on two real-world regions in Beijing. Experiments show that our method achieves state-of-the-art performance in residents satisfaction and inclusion metrics, and also outperforms human experts in terms of service accessibility and ecology metrics.",
    "pdf_link": "https://arxiv.org/abs/2402.17161",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2402.17161v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.17161/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2402.17161v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.17161/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2402.17161v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.17161/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2402.17161v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.17161/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2402.17161v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.17161/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2402.17161v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.17161/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2402.17161v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.17161/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2402.17161v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.17161/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2402.17161v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.17161/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2402.17161v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.17161/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2402.17161v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.17161/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2402.17161v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.17161/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2402.17161v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.17161/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2402.17161v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.17161/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2402.17161v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.17161/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2402.17161v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.17161/x16.png"
      }
    ],
    "abstract_cn": "参与式城市规划作为现代城市规划的新潮流，鼓励居民积极参与其中。传统模式依赖资深规划专家，不仅耗时而且成本高昂。但随着大型语言模型（LLMs）的兴起，其模拟人类行为的能力为简化这一过程提供了新可能。本研究提出了一种基于LLM的多智能体协作框架，旨在生成满足居民多元需求的城市土地使用规划。我们创建了模拟规划师和多样化居民的LLM智能体，首先由规划师提出初步土地使用方案。随后，在每个社区内启动居民讨论，收集基于居民个人资料的反馈。为提升讨论效率，我们引入了鱼缸讨论机制，让部分居民参与讨论，其他居民则作为听众。最终，规划师将根据居民反馈对方案进行调整。在北京两个实际区域的应用表明，该方法在提升居民满意度和包容性方面表现卓越，甚至在服务可达性和生态平衡方面超越了人类专家的成果。",
    "title_cn": "大型语言模型助力参与式城市规划",
    "tags": [
      "Agent",
      "城市规划",
      "人工智能"
    ]
  },
  {
    "title": "Navigating Complexity: Orchestrated Problem Solving with Multi-Agent LLMs",
    "submit_datetime": "2024年02月26日",
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in solving various tasks, yet they often struggle with comprehensively addressing complex and vague problems. Existing approaches, including multi-agent LLM systems, offer solutions to certain challenges but still require manual setup and lack scalability. To address this gap, we propose a novel approach leveraging decomposition to enable LLMs to tackle vague problems effectively.\n  Our approach involves an orchestrating LLM that interacts with users to understand the problem and then decomposes it into tangible sub-problems. Instead of expecting the LLM to solve the entire problem in one go, we train it to ask follow-up questions to gain a deeper understanding of the user's requirements. Once the problem is adequately understood, the orchestrating LLM divides it into smaller, manageable sub-problems. Each sub-problem is then assigned to specialized LLM agents or non-LLM functions for resolution. These agents work in parallel to solve their respective sub-problems, with the orchestrating LLM overseeing the process and compiling the solutions into a comprehensive answer for the user. By adopting this decomposition approach, we alleviate the constraints imposed by token limitations on LLM outputs and empower them to provide nuanced solutions to complex and ambiguous problems.\n  Through our approach, we aim to enable LLMs to think and operate more like humans, breaking down complex problems into manageable parts and collaboratively solving them. This not only enhances the problem-solving capabilities of LLMs but also offers a scalable and efficient method for addressing a wide range of real-world challenges.",
    "pdf_link": "https://arxiv.org/abs/2402.16713",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）在处理多样化任务上展现了卓越性能，但在应对复杂和不明确问题时仍显不足。尽管现有的多代理LLM系统等方法为特定难题提供了解决方案，但它们往往需要人工配置，且扩展性不足。为了填补这一空白，我们提出了一种创新的解决方案，通过问题分解，使LLMs能够有效处理模糊问题。我们的方案包括一个协调型LLM，它首先与用户沟通以把握问题核心，随后将问题细化为具体的子问题。我们训练LLM不是一次性解决整个问题，而是通过追问来深化对用户需求的理解。问题充分理解后，协调型LLM将其拆分为更小、更易处理的子问题，并将这些子问题分配给专门的LLM代理或非LLM功能进行解决。这些代理并行处理各自的子问题，而协调型LLM则负责监控整个过程，并将解决方案整合成一份全面的答复。采用这种分解策略，我们克服了LLM输出令牌限制的束缚，使其能够为复杂和不明确的问题提供精细的解决方案。通过这种方法，我们期望LLMs能够更接近人类的思考和行动方式，将复杂问题拆解为可处理的部分，并通过协作解决它们。这不仅提升了LLMs的问题解决能力，也为解决现实世界中的广泛挑战提供了一种可扩展且高效的新途径。",
    "title_cn": "驾驭复杂性：协同多智能体大型语言模型（LLMs）的复杂问题解决策略。",
    "tags": [
      "分类：Agent",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Let Models Speak Ciphers: Multiagent Debate through Embeddings",
    "submit_datetime": "2024年02月26日",
    "abstract": "Discussion and debate among Large Language Models (LLMs) have gained considerable attention due to their potential to enhance the reasoning ability of LLMs. Although natural language is an obvious choice for communication due to LLM's language understanding capability, the token sampling step needed when generating natural language poses a potential risk of information loss, as it uses only one token to represent the model's belief across the entire vocabulary. In this paper, we introduce a communication regime named CIPHER (Communicative Inter-Model Protocol Through Embedding Representation) to address this issue. Specifically, we remove the token sampling step from LLMs and let them communicate their beliefs across the vocabulary through the expectation of the raw transformer output embeddings. Remarkably, by deviating from natural language, CIPHER offers an advantage of encoding a broader spectrum of information without any modification to the model weights, outperforming the state-of-the-art LLM debate methods using natural language by 0.5-5.0% across five reasoning tasks and multiple open-source LLMs of varying sizes. This showcases the superiority and robustness of embeddings as an alternative \"language\" for communication among LLMs. We anticipate that CIPHER will inspire further exploration for the design of interactions within LLM agent systems, offering a new direction that could significantly influence future developments in the field.",
    "pdf_link": "https://arxiv.org/abs/2310.06272",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）的讨论与辩论因其可能提升模型的推理能力而备受关注。自然语言因其语言理解特性成为交流的首选，但生成自然语言时的令牌采样环节可能导致信息丢失，这一环节仅用单一令牌来表达模型对整个词汇库的判断。本文提出了一种名为CIPHER（通过嵌入表示的通信互模型协议）的新型通信机制，旨在解决这一问题。具体而言，我们取消了LLMs的令牌采样环节，允许模型通过原始变换器输出嵌入的期望值来交流其对词汇库的判断。CIPHER通过不依赖自然语言，能够编码更丰富的信息，且无需调整模型权重，便在五项推理任务和多种不同规模的开源LLMs上，比使用自然语言的最先进辩论方法的性能高出0.5-5.0%。这一发现证明了嵌入作为LLMs间通信的替代“语言”的优势和稳定性。我们预期CIPHER将激发对LLM代理系统内部交互设计的新探索，为该领域的未来发展指引新方向。",
    "title_cn": "让模型解码密语：借助嵌入技术开展多主体辩论。",
    "tags": [
      "LLM应用",
      "人工智能",
      "通信协议"
    ]
  },
  {
    "title": "Exploring Collaboration Mechanisms for LLM Agents: A Social Psychology View",
    "submit_datetime": "2024年02月26日",
    "abstract": "As Natural Language Processing (NLP) systems are increasingly employed in intricate social environments, a pressing query emerges: Can these NLP systems mirror human-esque collaborative intelligence, in a multi-agent society consisting of multiple large language models (LLMs)? This paper probes the collaboration mechanisms among contemporary NLP systems by melding practical experiments with theoretical insights. We fabricate four unique `societies' comprised of LLM agents, where each agent is characterized by a specific `trait' (easy-going or overconfident) and engages in collaboration with a distinct `thinking pattern' (debate or reflection). Through evaluating these multi-agent societies on three benchmark datasets, we discern that certain collaborative strategies not only outshine previous top-tier approaches, but also optimize efficiency (using fewer API tokens). Moreover, our results further illustrate that LLM agents manifest human-like social behaviors, such as conformity and consensus reaching, mirroring foundational social psychology theories. In conclusion, we integrate insights from social psychology to contextualize the collaboration of LLM agents, inspiring further investigations into the collaboration mechanism for LLMs. We commit to sharing our code and datasets\\footnote{\\url{https://github.com/zjunlp/MachineSoM}.}, hoping to catalyze further research in this promising avenue.",
    "pdf_link": "https://arxiv.org/abs/2310.02124",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2310.02124v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2310.02124/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2310.02124v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2310.02124/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2310.02124v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2310.02124/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2310.02124v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2310.02124/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2310.02124v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2310.02124/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2310.02124v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2310.02124/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2310.02124v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2310.02124/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2310.02124v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2310.02124/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2310.02124v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2310.02124/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2310.02124v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2310.02124/x10.png"
      }
    ],
    "abstract_cn": "自然语言处理（NLP）系统在日益复杂的社会环境中得到广泛应用，引发了一个关键问题：这些系统是否能够模拟人类般的协作智慧，特别是在由众多大型语言模型（LLMs）构成的多智能体社会中？本研究通过结合实证实验与理论分析，深入探讨了当前NLP系统间的协作机制。我们设计了四个各具特色的“社会”，每个社会由具有特定“性格”（如随和或自负）的LLM智能体组成，它们以独特的“思考方式”（如辩论或沉思）进行互动。在对这些多智能体系统进行三个标准数据集的评估后，我们发现某些协作策略不仅超越了先前的最佳方法，还提高了效率，减少了API令牌的使用。此外，研究结果还揭示了LLM智能体展现出的类人社会行为，如遵从性和达成共识，这与基础社会心理学理论相呼应。总结而言，我们结合社会心理学的见解，对LLM智能体的协作进行了情境化分析，激发了对LLMs协作机制更深入研究的动力。我们承诺公开我们的代码和数据集\\footnote{\\url{https://github.com/zjunlp/MachineSoM}.}，以期推动这一充满希望的研究领域的发展。",
    "title_cn": "探究大型语言模型（LLM）代理协作机制的社会心理学视角",
    "tags": [
      "分类：LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Prompting LLMs to Compose Meta-Review Drafts from Peer-Review Narratives of Scholarly Manuscripts",
    "submit_datetime": "2024年02月23日",
    "abstract": "One of the most important yet onerous tasks in the academic peer-reviewing process is composing meta-reviews, which involves understanding the core contributions, strengths, and weaknesses of a scholarly manuscript based on peer-review narratives from multiple experts and then summarizing those multiple experts' perspectives into a concise holistic overview. Given the latest major developments in generative AI, especially Large Language Models (LLMs), it is very compelling to rigorously study the utility of LLMs in generating such meta-reviews in an academic peer-review setting. In this paper, we perform a case study with three popular LLMs, i.e., GPT-3.5, LLaMA2, and PaLM2, to automatically generate meta-reviews by prompting them with different types/levels of prompts based on the recently proposed TELeR taxonomy. Finally, we perform a detailed qualitative study of the meta-reviews generated by the LLMs and summarize our findings and recommendations for prompting LLMs for this complex task.",
    "pdf_link": "https://arxiv.org/abs/2402.15589",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2402.15589v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.15589/Prompt_taxonomy.png"
      },
      {
        "url": "https://arxiv.org/html/2402.15589v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.15589/CC-PR-P1.png"
      },
      {
        "url": "https://arxiv.org/html/2402.15589v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.15589/CC-PR-P2.png"
      },
      {
        "url": "https://arxiv.org/html/2402.15589v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.15589/CC-PR-P3.png"
      },
      {
        "url": "https://arxiv.org/html/2402.15589v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.15589/CC-PR-P4.png"
      },
      {
        "url": "https://arxiv.org/html/2402.15589v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.15589/CC-PR-P1-4-A.png"
      },
      {
        "url": "https://arxiv.org/html/2402.15589v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.15589/CC-PR-P1-4-AL.png"
      },
      {
        "url": "https://arxiv.org/html/2402.15589v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.15589/CC-PR-P1-4-ALL.png"
      },
      {
        "url": "https://arxiv.org/html/2402.15589v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.15589/CS-PR-P1-4-A.png"
      },
      {
        "url": "https://arxiv.org/html/2402.15589v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.15589/CS-PR-P1-4-AL.png"
      },
      {
        "url": "https://arxiv.org/html/2402.15589v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.15589/CW-PR-P1-4-A.png"
      },
      {
        "url": "https://arxiv.org/html/2402.15589v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.15589/CW-PR-P1-4-AL.png"
      },
      {
        "url": "https://arxiv.org/html/2402.15589v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.15589/CSu-PR-P1-4-A.png"
      },
      {
        "url": "https://arxiv.org/html/2402.15589v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.15589/CSu-PR-P1-4-AL.png"
      },
      {
        "url": "https://arxiv.org/html/2402.15589v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.15589/MR-PR-P1-4-A.png"
      },
      {
        "url": "https://arxiv.org/html/2402.15589v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.15589/MR-PR-P1-4-AL.png"
      },
      {
        "url": "https://arxiv.org/html/2402.15589v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.15589/CS-PR-P1-4-ALL.png"
      },
      {
        "url": "https://arxiv.org/html/2402.15589v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.15589/CW-PR-P1-4-ALL.png"
      },
      {
        "url": "https://arxiv.org/html/2402.15589v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.15589/CSu-PR-P1-4-ALL.png"
      },
      {
        "url": "https://arxiv.org/html/2402.15589v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.15589/MR-PR-P1-4-ALL.png"
      },
      {
        "url": "https://arxiv.org/html/2402.15589v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.15589/CS-PR-P1.png"
      },
      {
        "url": "https://arxiv.org/html/2402.15589v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.15589/CS-PR-P2.png"
      },
      {
        "url": "https://arxiv.org/html/2402.15589v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.15589/CS-PR-P3.png"
      },
      {
        "url": "https://arxiv.org/html/2402.15589v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.15589/CS-PR-P4.png"
      },
      {
        "url": "https://arxiv.org/html/2402.15589v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.15589/CW-PR-P1.png"
      },
      {
        "url": "https://arxiv.org/html/2402.15589v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.15589/CW-PR-P2.png"
      },
      {
        "url": "https://arxiv.org/html/2402.15589v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.15589/CW-PR-P3.png"
      },
      {
        "url": "https://arxiv.org/html/2402.15589v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.15589/CW-PR-P4.png"
      },
      {
        "url": "https://arxiv.org/html/2402.15589v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.15589/CSu-PR-P1.png"
      },
      {
        "url": "https://arxiv.org/html/2402.15589v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.15589/CSu-PR-P2.png"
      },
      {
        "url": "https://arxiv.org/html/2402.15589v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.15589/CSu-PR-P3.png"
      },
      {
        "url": "https://arxiv.org/html/2402.15589v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.15589/CSu-PR-P4.png"
      },
      {
        "url": "https://arxiv.org/html/2402.15589v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.15589/MR-PR-P1.png"
      },
      {
        "url": "https://arxiv.org/html/2402.15589v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.15589/MR-PR-P2.png"
      },
      {
        "url": "https://arxiv.org/html/2402.15589v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.15589/MR-PR-P3.png"
      },
      {
        "url": "https://arxiv.org/html/2402.15589v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.15589/MR-PR-P4.png"
      },
      {
        "url": "https://arxiv.org/html/2402.15589v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.15589/Form2.png"
      },
      {
        "url": "https://arxiv.org/html/2402.15589v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.15589/Form3.png"
      },
      {
        "url": "https://arxiv.org/html/2402.15589v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.15589/Form1.png"
      }
    ],
    "abstract_cn": "学术同行评审中，撰写元评审是一项至关重要且颇为艰巨的工作，它要求我们基于众多专家的评审意见，深入理解一篇学术论文的核心贡献、优势与不足，并将其综合为一份精炼的全面概述。随着生成性人工智能，尤其是大型语言模型（LLMs）的飞速发展，探索LLMs在学术评审中撰写元评审的潜力变得尤为引人入胜。本文通过三个广受欢迎的LLMs——GPT-3.5、LLaMA2和PaLM2——进行了一项案例研究，我们利用基于TELeR分类法设计的不同类型和层次的提示，引导这些模型自动生成元评审。最终，我们对这些LLMs生成的元评审进行了深入的定性分析，并归纳了我们的发现和建议，为如何有效地引导LLMs完成这一复杂任务提供了指导。",
    "title_cn": "引导大型语言模型（LLM）基于学术手稿的同行评审叙述，撰写出元评论的初稿。",
    "tags": [
      "LLM应用",
      "学术评审",
      "人工智能"
    ]
  },
  {
    "title": "AgentLite: A Lightweight Library for Building and Advancing Task-Oriented LLM Agent System",
    "submit_datetime": "2024年02月23日",
    "abstract": "The booming success of LLMs initiates rapid development in LLM agents. Though the foundation of an LLM agent is the generative model, it is critical to devise the optimal reasoning strategies and agent architectures. Accordingly, LLM agent research advances from the simple chain-of-thought prompting to more complex ReAct and Reflection reasoning strategy; agent architecture also evolves from single agent generation to multi-agent conversation, as well as multi-LLM multi-agent group chat. However, with the existing intricate frameworks and libraries, creating and evaluating new reasoning strategies and agent architectures has become a complex challenge, which hinders research investigation into LLM agents. Thus, we open-source a new AI agent library, AgentLite, which simplifies this process by offering a lightweight, user-friendly platform for innovating LLM agent reasoning, architectures, and applications with ease. AgentLite is a task-oriented framework designed to enhance the ability of agents to break down tasks and facilitate the development of multi-agent systems. Furthermore, we introduce multiple practical applications developed with AgentLite to demonstrate its convenience and flexibility. Get started now at: \\url{https://github.com/SalesforceAIResearch/AgentLite}.",
    "pdf_link": "https://arxiv.org/abs/2402.15538",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLM）的兴起推动了LLM代理技术的迅猛发展。虽然生成模型构成了LLM代理的基石，但制定高效的推理策略和构建代理架构同样重要。研究已从简单的思维链式提示，发展到更为复杂的ReAct和Reflection推理策略，代理架构也由单代理生成演变为多代理对话，乃至多LLM环境下的多代理群组聊天。尽管如此，现有的复杂框架和库使得设计和评估新的推理策略和代理架构变得异常困难，这限制了LLM代理研究的深入。为了解决这一问题，我们推出了一个开源的AI代理库——AgentLite。它以轻量级、易用性为特点，简化了LLM代理推理、架构和应用的创新过程。AgentLite是一个以任务为中心的框架，旨在提升代理分解任务的能力和促进多代理系统的构建。我们还展示了几个使用AgentLite开发的实用应用，以证明其便捷性和灵活性。立即开始探索：\\url{https://github.com/SalesforceAIResearch/AgentLite}。",
    "title_cn": "AgentLite：一款轻量级库，旨在构建并提升面向任务的LLM代理系统。",
    "tags": [
      "Agent",
      "人工智能",
      "软件开发"
    ]
  },
  {
    "title": "MetaTool Benchmark for Large Language Models: Deciding Whether to Use Tools and Which to Use",
    "submit_datetime": "2024年02月23日",
    "abstract": "Large language models (LLMs) have garnered significant attention due to their impressive natural language processing (NLP) capabilities. Recently, many studies have focused on the tool utilization ability of LLMs. They primarily investigated how LLMs effectively collaborate with given specific tools. However, in scenarios where LLMs serve as intelligent agents, as seen in applications like AutoGPT and MetaGPT, LLMs are expected to engage in intricate decision-making processes that involve deciding whether to employ a tool and selecting the most suitable tool(s) from a collection of available tools to fulfill user requests. Therefore, in this paper, we introduce MetaTool, a benchmark designed to evaluate whether LLMs have tool usage awareness and can correctly choose tools. Specifically, we create a dataset called ToolE within the benchmark. This dataset contains various types of user queries in the form of prompts that trigger LLMs to use tools, including both single-tool and multi-tool scenarios. Subsequently, we set the tasks for both tool usage awareness and tool selection. We define four subtasks from different perspectives in tool selection, including tool selection with similar choices, tool selection in specific scenarios, tool selection with possible reliability issues, and multi-tool selection. We conduct experiments involving eight popular LLMs and find that the majority of them still struggle to effectively select tools, highlighting the existing gaps between LLMs and genuine intelligent agents. However, through the error analysis, we found there is still significant room for improvement. Finally, we conclude with insights for tool developers -- we strongly recommend that tool developers choose an appropriate rewrite model for generating new descriptions based on the downstream LLM the tool will apply to. Our code is in https://github.com/HowieHwong/MetaTool.",
    "pdf_link": "https://arxiv.org/abs/2310.03128",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2310.03128v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2310.03128/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2310.03128v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2310.03128/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2310.03128v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2310.03128/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2310.03128v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2310.03128/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2310.03128v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2310.03128/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2310.03128v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2310.03128/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2310.03128v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2310.03128/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2310.03128v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2310.03128/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2310.03128v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2310.03128/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2310.03128v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2310.03128/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2310.03128v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2310.03128/interface.jpg"
      },
      {
        "url": "https://arxiv.org/html/2310.03128v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2310.03128/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2310.03128v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2310.03128/ToolE_embedding.png"
      },
      {
        "url": "https://arxiv.org/html/2310.03128v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2310.03128/radar_awareness.png"
      },
      {
        "url": "https://arxiv.org/html/2310.03128v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2310.03128/radar_selection.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）因其卓越的自然语言处理能力而备受瞩目。近期研究聚焦于LLMs的工具使用能力，探究它们如何与特定工具高效协作。但在智能代理应用中，如AutoGPT和MetaGPT，LLMs需进行复杂决策，决定是否使用工具及如何从众多工具中挑选最合适的以响应用户需求。为此，我们提出了MetaTool基准，旨在测试LLMs是否具备工具使用意识及正确选择工具的能力。我们构建了ToolE数据集，包含多种触发LLMs使用工具的用户查询，涵盖单工具与多工具情境。我们设定了工具使用意识和工具选择的任务，并从不同角度细分为四个子任务。实验涵盖了八种主流LLMs，结果显示多数LLMs在工具选择上仍显不足，揭示了与真正智能代理的差距。尽管如此，错误分析表明改进空间巨大。最后，我们建议工具开发者为下游LLM选择合适的重写模型，以生成适用于其工具的新描述。我们的代码已公开在GitHub上。",
    "title_cn": "大型语言模型的MetaTool基准：抉择工具之用与选择之道",
    "tags": [
      "Agent\n\n这篇论文主要探讨了大型语言模型（LLMs）在智能代理应用中的工具使用能力，特别是在AutoGPT和MetaGPT等系统中，LLMs如何进行复杂决策以选择和使用工具来响应用户需求。论文提出了MetaTool基准和ToolE数据集，用于测试LLMs的工具使用意识和选择能力，并进行了实验分析。这与智能代理（Agent）的概念紧密相关，因为智能代理需要具备自主决策和执行任务的能力，包括选择和使用工具。因此，这篇论文应归类于Agent分类。",
      "智能代理",
      ""
    ]
  },
  {
    "title": "ReConcile: Round-Table Conference Improves Reasoning via Consensus among Diverse LLMs",
    "submit_datetime": "2024年02月21日",
    "abstract": "Large Language Models (LLMs) still struggle with natural language reasoning tasks. Motivated by the society of minds (Minsky, 1988), we propose ReConcile, a multi-model multiagent framework designed as a round table conference among diverse LLM agents. ReConcile enhances collaborative reasoning between LLM agents via multiple rounds of discussion, learning to convince other agents to improve their answers, and employing a confidence-weighted voting mechanism that leads to a better consensus. In each round, ReConcile initiates discussion between agents via a 'discussion prompt' that consists of (a) grouped answers and explanations generated by each agent in the previous round, (b) their confidence scores, and (c) demonstrations of answer-rectifying human explanations, used for convincing other agents. Experiments on seven benchmarks demonstrate that ReConcile significantly improves LLMs' reasoning -- both individually and as a team -- surpassing prior single-agent and multi-agent baselines by up to 11.4% and even outperforming GPT-4 on three datasets. ReConcile also flexibly incorporates different combinations of agents, including API-based, open-source, and domain-specific models, leading to an 8% improvement on MATH. Finally, we analyze the individual components of ReConcile, demonstrating that the diversity originating from different models is critical to its superior performance. Code: https://github.com/dinobby/ReConcile",
    "pdf_link": "https://arxiv.org/abs/2309.13007",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）在处理自然语言推理任务时仍面临挑战。借鉴马文·明斯基（Marvin Minsky）于1988年提出的“心智社会”理念，我们设计了ReConcile——一个多模型多代理的框架，它模拟了一个多样化LLM代理间的圆桌讨论。ReConcile通过多轮讨论，促进代理间的协作推理，学会说服同伴以提升答案质量，并采用置信度加权投票机制，以达成更优共识。每一轮讨论都以“讨论提示”开始，包含上一轮各代理生成的答案和解释、置信度评分，以及用于说服其他代理的答案修正的人类解释示例。在七个基准测试中的实验结果表明，ReConcile显著提升了LLMs的推理表现，无论是单独还是团队协作，都超过了先前的单代理和多代理基线，最高提升了11.4%，甚至在三个数据集上超越了GPT-4。ReConcile还能够灵活地整合不同组合的代理，包括基于API的、开源的和特定于领域的模型，这在MATH基准测试中实现了8%的性能提升。最终，我们对ReConcile的各个组件进行了分析，证实了不同模型带来的多样性对其卓越性能的关键作用。代码链接：https://github.com/dinobby/ReConcile",
    "title_cn": "ReConcile：通过汇聚多样化的大型语言模型之间的共识，圆桌会议式的讨论显著提升了推理过程的质量。",
    "tags": [
      "分类：Agent",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Meta Ranking: Less Capable Language Models are Capable for Single Response Judgement",
    "submit_datetime": "2024年02月19日",
    "abstract": "Although Large Language Models (LLMs) have demonstrated strong performance on a wide range of tasks, they still face reliability challenges such as hallucination. Previous studies reveal that highly capable LLMs like GPT-4 are effective in judging the reliability of individual responses, while less capable ones are often tuned to evaluate the relative reliability of responses to the same query. To enable less capable LLMs to effectively judge the reliability of individual responses, we propose a novel method named $\\textit{Meta}$ $\\textit{Ranking}$ (MR). Unlike previous methods, which assess the response directly, we achieve the judgement by comparing the target query-response pair with reference query-response pairs. We found its remarkable effectiveness in error detection for LLM responses on reasoning tasks, where less capable LLMs could outperform strong baselines, even without fine-tuning. We further demonstrate that MR can be used to enhance the performance of LLMs in two practical applications: query routing and iterative training data filtering. The former achieves GPT-4-turbo comparable performance with less than half the token consumption, while the latter makes the instruction-tuned LLaMA-7B and Phi-2, a 2.7B model, significantly surpass Alpaca-13B over fewer training samples, underscoring the high potential of our proposed method.",
    "pdf_link": "https://arxiv.org/abs/2402.12146",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）虽然在众多任务上表现卓越，但仍存在可靠性问题，如产生幻觉。研究表明，像 GPT-4 这样的高效能 LLMs 能有效评估单个回答的可信度，而低效能 LLMs 则常被优化以评估同一问题下不同回答的相对可信度。为此，我们引入了一种创新方法——元排序（Meta Ranking，MR），它不是直接评价回答，而是通过比较目标查询-回答对与参考查询-回答对来进行判断。MR 在推理任务中对 LLM 回答的错误检测展现出了显著效果，即便是低效能 LLMs，在无需微调的情况下也能超越优秀基准。此外，MR 还被证实能提升 LLMs 在查询路由和迭代训练数据筛选两个实际应用中的性能。在查询路由方面，MR 以不到 GPT-4-turbo 一半的令牌消耗实现了相似的性能；在迭代训练数据筛选方面，MR 助力经过指令调整的 LLaMA-7B 和 Phi-2（2.7B 模型）在较少训练样本的情况下显著超越了 Alpaca-13B，彰显了我们方法的巨大潜力。",
    "title_cn": "元排名机制表明，即便是能力相对较弱的语言模型，在进行单一响应判断时也表现出了足够的能力。",
    "tags": [
      "LLM应用",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Shall We Talk: Exploring Spontaneous Collaborations of Competing LLM Agents",
    "submit_datetime": "2024年02月19日",
    "abstract": "Recent advancements have shown that agents powered by large language models (LLMs) possess capabilities to simulate human behaviors and societal dynamics. However, the potential for LLM agents to spontaneously establish collaborative relationships in the absence of explicit instructions has not been studied. To address this gap, we conduct three case studies, revealing that LLM agents are capable of spontaneously forming collaborations even within competitive settings. This finding not only demonstrates the capacity of LLM agents to mimic competition and cooperation in human societies but also validates a promising vision of computational social science. Specifically, it suggests that LLM agents could be utilized to model human social interactions, including those with spontaneous collaborations, thus offering insights into social phenomena. The source codes for this study are available at https://github.com/wuzengqing001225/SABM_ShallWeTalk .",
    "pdf_link": "https://arxiv.org/abs/2402.12327",
    "graphs": [],
    "abstract_cn": "最新研究揭示，由大型语言模型（LLM）支持的智能体不仅能模拟人类行为和社会运作，还能在缺乏明确指示时自行建立合作关系。通过三项案例研究，我们发现LLM智能体甚至能在竞争情境中自发协作，这不仅证实了它们模仿人类社会竞争与合作行为的能力，也为计算社会科学的发展提供了新视角。具体而言，LLM智能体有潜力被用于模拟包含自发协作在内的人类社交互动，为我们理解社会现象提供了新的视角。相关研究的源代码已在 https://github.com/wuzengqing001225/SABM_ShallWeTalk 上公开。",
    "title_cn": "《我们来谈谈吧：探究竞争性大型语言模型间的自发协作》",
    "tags": [
      "Agent",
      "社会科学",
      "人工智能"
    ]
  },
  {
    "title": "LLM Agents for Psychology: A Study on Gamified Assessments",
    "submit_datetime": "2024年02月19日",
    "abstract": "Psychological measurement is essential for mental health, self-understanding, and personal development. Traditional methods, such as self-report scales and psychologist interviews, often face challenges with engagement and accessibility. While game-based and LLM-based tools have been explored to improve user interest and automate assessment, they struggle to balance engagement with generalizability. In this work, we propose PsychoGAT (Psychological Game AgenTs) to achieve a generic gamification of psychological assessment. The main insight is that powerful LLMs can function both as adept psychologists and innovative game designers. By incorporating LLM agents into designated roles and carefully managing their interactions, PsychoGAT can transform any standardized scales into personalized and engaging interactive fiction games. To validate the proposed method, we conduct psychometric evaluations to assess its effectiveness and employ human evaluators to examine the generated content across various psychological constructs, including depression, cognitive distortions, and personality traits. Results demonstrate that PsychoGAT serves as an effective assessment tool, achieving statistically significant excellence in psychometric metrics such as reliability, convergent validity, and discriminant validity. Moreover, human evaluations confirm PsychoGAT's enhancements in content coherence, interactivity, interest, immersion, and satisfaction.",
    "pdf_link": "https://arxiv.org/abs/2402.12326",
    "graphs": [],
    "abstract_cn": "心理测量在促进心理健康、深化自我认知及推动个人成长中扮演着关键角色。然而，传统手段如自评量表和心理专家访谈，在提高参与度和普及性方面存在局限。虽然人们已经尝试利用游戏化和基于大型语言模型（LLM）的工具来提升用户兴趣和实现评估自动化，但这些方法在吸引用户参与和评估的普遍适用性之间难以取得平衡。本研究提出了PsychoGAT（心理游戏代理），旨在通过游戏化手段普及心理评估。核心理念在于，先进的LLM能够扮演心理学家和游戏设计师的双重角色。通过将LLM集成到特定角色中，并精心调控它们之间的互动，PsychoGAT能够将标准化的量表转变为个性化且富有吸引力的互动式虚构游戏。为验证该方法的有效性，我们进行了心理测量学评估，并邀请人类评审员对生成的内容进行审核，内容覆盖了包括抑郁、认知偏差和性格特质在内的多种心理维度。研究结果显示，PsychoGAT作为一个高效的评估工具，在可靠性、聚合效度和区分效度等心理测量学指标上均取得了统计学上的显著成绩。同时，人类评审的反馈也证实了PsychoGAT在内容连贯性、互动性、吸引力、沉浸感和用户满意度方面的显著提升。",
    "title_cn": "探究心理领域中的 LLM 代理：游戏化评估的深入研究",
    "tags": [
      "Agent",
      "心理健康",
      "游戏化"
    ]
  },
  {
    "title": "Language Agents with Reinforcement Learning for Strategic Play in the Werewolf Game",
    "submit_datetime": "2024年02月19日",
    "abstract": "Agents built with large language models (LLMs) have shown great potential across a wide range of domains. However, in complex decision-making tasks, pure LLM-based agents tend to exhibit intrinsic bias in their choice of actions, which is inherited from the model's training data and results in suboptimal performance. To develop strategic language agents, i.e., agents that generate flexible language actions and possess strong decision-making abilities, we propose a novel framework that powers LLM-based agents with reinforcement learning (RL). We consider Werewolf, a popular social deduction game, as a challenging testbed that emphasizes versatile communication and strategic gameplay. To mitigate the intrinsic bias in language actions, our agents use an LLM to perform deductive reasoning and generate a diverse set of action candidates. Then an RL policy trained to optimize the decision-making ability chooses an action from the candidates to play in the game. Extensive experiments show that our agents overcome the intrinsic bias and outperform existing LLM-based agents in the Werewolf game. We also conduct human-agent experiments and find that our agents achieve human-level performance and demonstrate strong strategic play.",
    "pdf_link": "https://arxiv.org/abs/2310.18940",
    "graphs": [],
    "abstract_cn": "基于大型语言模型（LLM）的智能体在多元领域内展现出巨大潜力。但在复杂的决策制定任务中，纯粹的LLM智能体往往在其选择的行动中表现出内在偏见，这种偏见源自模型的训练数据，导致表现不尽人意。为了培育出既能够灵活运用语言行动又具备卓越决策力的战略性语言智能体，我们提出了一个创新框架，该框架利用强化学习（RL）技术赋予LLM智能体新动力。我们以广受欢迎的社交推理游戏“狼人杀”作为测试平台，它考验的是智能体的沟通多样性和策略游戏技巧。我们的智能体利用LLM进行逻辑推理，提出多样化的行动选项，随后一个经过特别训练以提升决策能力的RL策略会从这些选项中挑选出最佳行动来参与游戏。大量实验证明，我们的智能体成功克服了内在偏见，在“狼人杀”游戏中的表现超越了传统LLM智能体。此外，我们还进行了人机对比实验，发现我们的智能体不仅达到了人类的水平，而且在策略运用上表现出色。",
    "title_cn": "通过强化学习训练的语言代理，能够在狼人杀这一策略游戏中发挥出色的作用。",
    "tags": [
      "Agent",
      "",
      "人工智能"
    ]
  },
  {
    "title": "SPML: A DSL for Defending Language Models Against Prompt Attacks",
    "submit_datetime": "2024年02月18日",
    "abstract": "Large language models (LLMs) have profoundly transformed natural language applications, with a growing reliance on instruction-based definitions for designing chatbots. However, post-deployment the chatbot definitions are fixed and are vulnerable to attacks by malicious users, emphasizing the need to prevent unethical applications and financial losses. Existing studies explore user prompts' impact on LLM-based chatbots, yet practical methods to contain attacks on application-specific chatbots remain unexplored. This paper presents System Prompt Meta Language (SPML), a domain-specific language for refining prompts and monitoring the inputs to the LLM-based chatbots. SPML actively checks attack prompts, ensuring user inputs align with chatbot definitions to prevent malicious execution on the LLM backbone, optimizing costs. It also streamlines chatbot definition crafting with programming language capabilities, overcoming natural language design challenges. Additionally, we introduce a groundbreaking benchmark with 1.8k system prompts and 20k user inputs, offering the inaugural language and benchmark for chatbot definition evaluation. Experiments across datasets demonstrate SPML's proficiency in understanding attacker prompts, surpassing models like GPT-4, GPT-3.5, and LLAMA. Our data and codes are publicly available at: https://prompt-compiler.github.io/SPML/.",
    "pdf_link": "https://arxiv.org/abs/2402.11755",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）彻底革新了自然语言处理应用，尤其在基于指令的设计上，聊天机器人的依赖日益增加。但部署后的聊天机器人定义变得僵化，易受恶意用户攻击，这凸显了防范不当应用和避免财务损失的重要性。尽管现有研究已探讨用户输入对LLM驱动的聊天机器人的影响，但如何有效防御特定应用聊天机器人的攻击仍是一个未解之谜。本文提出了系统提示元语言（SPML），这是一门专为优化聊天机器人提示和监控输入而设计的语言。SPML能够主动识别并阻止攻击性输入，确保用户操作与机器人预设的定义相匹配，从而在LLM基础上防止恶意操作，同时降低成本。它还利用编程语言的特性，简化了聊天机器人的定义过程，解决了自然语言设计的难题。文章还首次提出了一个包含1800个系统提示和20000个用户输入的创新基准测试，为聊天机器人定义的评估提供了新的语言和标准。跨多个数据集的实验证明，SPML在识别攻击性输入方面的能力超过了GPT-4、GPT-3.5和LLAMA等模型。相关数据和代码已在 https://prompt-compiler.github.io/SPML/ 公开发布。",
    "title_cn": "SPML：一种专为抵御提示攻击而设计的领域特定语言，用于保护语言模型的安全。",
    "tags": [
      "LLM应用",
      "",
      "网络安全"
    ]
  },
  {
    "title": "TrustAgent: Towards Safe and Trustworthy LLM-based Agents through Agent Constitution",
    "submit_datetime": "2024年02月17日",
    "abstract": "The emergence of LLM-based agents has garnered considerable attention, yet their trustworthiness remains an under-explored area. As agents can directly interact with the physical environment, their reliability and safety is critical. This paper presents an Agent-Constitution-based agent framework, TrustAgent, an initial investigation into improving the safety dimension of trustworthiness in LLM-based agents. This framework consists of threefold strategies: pre-planning strategy which injects safety knowledge to the model prior to plan generation, in-planning strategy which bolsters safety during plan generation, and post-planning strategy which ensures safety by post-planning inspection. Through experimental analysis, we demonstrate how these approaches can effectively elevate an LLM agent's safety by identifying and preventing potential dangers. Furthermore, we explore the intricate relationships between safety and helpfulness, and between the model's reasoning ability and its efficacy as a safe agent. This paper underscores the imperative of integrating safety awareness and trustworthiness into the design and deployment of LLM-based agents, not only to enhance their performance but also to ensure their responsible integration into human-centric environments. Data and code are available at https://github.com/agiresearch/TrustAgent.",
    "pdf_link": "https://arxiv.org/abs/2402.01586",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLM）驱动的代理因其互动能力而备受瞩目，但其可信性尚未得到充分研究。鉴于这些代理能直接与物理世界交互，其可靠性与安全性尤为关键。本文介绍了一种名为TrustAgent的代理框架，旨在初步探讨如何提升LLM代理的安全性，从而增强其可信度。该框架包含三种策略：预先规划策略，它在规划生成前向模型注入安全知识；规划中策略，它在规划生成时加强安全措施；以及规划后策略，通过事后检查确保安全无虞。实验分析表明，这些方法能有效提升LLM代理的安全性，通过识别和预防潜在风险。文章还深入探讨了安全性与实用性之间的微妙关系，以及模型推理能力与其作为安全代理效能之间的联系。本文强调了在设计和部署LLM代理时，必须将安全意识和可信度纳入考量，这不仅能够提升代理的表现，也确保了它们能够负责任地融入人类环境。相关数据和代码可在 https://github.com/agiresearch/TrustAgent 查看。",
    "title_cn": "TrustAgent：致力于构建基于大型语言模型的安全可信代理，通过制定代理宪法来实现这一目标。",
    "tags": [
      "Agent",
      "人工智能",
      ""
    ]
  },
  {
    "title": "MADA: Meta-Adaptive Optimizers through hyper-gradient Descent",
    "submit_datetime": "2024年02月15日",
    "abstract": "Since Adam was introduced, several novel adaptive optimizers for deep learning have been proposed. These optimizers typically excel in some tasks but may not outperform Adam uniformly across all tasks. In this work, we introduce Meta-Adaptive Optimizers (MADA), a unified optimizer framework that can generalize several known optimizers and dynamically learn the most suitable one during training. The key idea in MADA is to parameterize the space of optimizers and search through it using hyper-gradient descent. We compare MADA to other popular optimizers empirically on vision and language tasks to train CNN, ResNet and GPT-2 models. Results suggest that MADA is robust against sub-optimally tuned hyper-parameters, and consistently outperforms Adam and other popular optimizers. We find that MADA gives $3\\times$ the validation performance gain over Adam that other popular optimizers do on GPT-2 training. We also propose AVGrad, a modification of AMSGrad that replaces the maximum operator with averaging, that is suitable for hyper-gradient optimization framework. Finally, we provide a convergence analysis to show that interpolation of optimizers can improve their error bounds (up to constants), hinting at an advantage for meta-optimizers.",
    "pdf_link": "https://arxiv.org/abs/2401.08893",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2401.08893v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2401.08893/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2401.08893v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2401.08893/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2401.08893v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2401.08893/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2401.08893v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2401.08893/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2401.08893v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2401.08893/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2401.08893v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2401.08893/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2401.08893v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2401.08893/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2401.08893v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2401.08893/x8.png"
      }
    ],
    "abstract_cn": "自从 Adam 算法问世后，便涌现出多款创新的深度学习自适应优化器。尽管这些优化器在特定任务上表现优异，但并非总能在所有任务上超越 Adam。本研究提出了一种名为元自适应优化器（MADA）的全新统一优化框架，它能够整合多种已知优化器，并在训练过程中智能选择最合适的算法。MADA 的核心策略在于对优化器参数空间进行建模，并通过超梯度下降法进行搜索。我们对 MADA 进行了广泛的实验，包括视觉和语言任务，以及 CNN、ResNet 和 GPT-2 模型的训练，与其他主流优化器相比，MADA 在超参数调整不佳的情况下仍展现出强大的鲁棒性，并持续超越了 Adam 及其他流行优化器。实验结果显示，在 GPT-2 训练过程中，MADA 带来的验证性能提升是其他优化器的三倍。此外，我们还提出了 AVGrad，这是对 AMSGrad 的一种改进，它通过平均而非最大操作来适应超梯度优化框架。最终，我们还进行了收敛性分析，证实了优化器的插值方法能够提升其误差界限（至多常数倍），这为元优化器的优势提供了有力证据。",
    "title_cn": "MADA：一种通过超梯度下降实现的元自适应优化器技术",
    "tags": [
      "LLM理论",
      "",
      "优化算法"
    ]
  },
  {
    "title": "HaLo-NeRF: Learning Geometry-Guided Semantics for Exploring Unconstrained Photo Collections",
    "submit_datetime": "2024年02月14日",
    "abstract": "Internet image collections containing photos captured by crowds of photographers show promise for enabling digital exploration of large-scale tourist landmarks. However, prior works focus primarily on geometric reconstruction and visualization, neglecting the key role of language in providing a semantic interface for navigation and fine-grained understanding. In constrained 3D domains, recent methods have leveraged vision-and-language models as a strong prior of 2D visual semantics. While these models display an excellent understanding of broad visual semantics, they struggle with unconstrained photo collections depicting such tourist landmarks, as they lack expert knowledge of the architectural domain. In this work, we present a localization system that connects neural representations of scenes depicting large-scale landmarks with text describing a semantic region within the scene, by harnessing the power of SOTA vision-and-language models with adaptations for understanding landmark scene semantics. To bolster such models with fine-grained knowledge, we leverage large-scale Internet data containing images of similar landmarks along with weakly-related textual information. Our approach is built upon the premise that images physically grounded in space can provide a powerful supervision signal for localizing new concepts, whose semantics may be unlocked from Internet textual metadata with large language models. We use correspondences between views of scenes to bootstrap spatial understanding of these semantics, providing guidance for 3D-compatible segmentation that ultimately lifts to a volumetric scene representation. Our results show that HaLo-NeRF can accurately localize a variety of semantic concepts related to architectural landmarks, surpassing the results of other 3D models as well as strong 2D segmentation baselines. Our project page is at https://tau-vailab.github.io/HaLo-NeRF/.",
    "pdf_link": "https://arxiv.org/abs/2404.16845",
    "graphs": [],
    "abstract_cn": "互联网上的图片集，由众多摄影师捕捉的照片组成，为数字化探索大型旅游地标提供了可能性。但以往研究多集中于几何重建与可视化，忽略了语言在导航和精细理解中的语义界面作用。在3D领域的现有方法中，视觉与语言模型被用作2D视觉语义的强大预设，尽管这些模型对广泛的视觉语义有深刻理解，却难以应对无约束的照片集合，尤其是那些展示旅游地标的，因为它们缺少建筑学的专业知识。本研究提出了一种定位系统，该系统结合了最先进的视觉与语言模型，并对其进行了调整，以理解大型地标场景的语义，将场景的神经表示与描述场景内语义区域的文本相连接。我们利用大规模互联网数据，其中包含相似地标的图像和弱相关的文本信息，以此来丰富模型的精细知识。我们的方法基于一个前提：物理空间中的图像可以为新概念的定位提供强有力的监督信号，而这些概念的语义可能通过大型语言模型从互联网文本元数据中获得。我们利用场景视图之间的对应关系来引导空间语义的理解，并为3D兼容的分割提供指导，最终形成体积场景表示。我们的研究结果表明，HaLo-NeRF能够精确地定位与建筑地标相关的多种语义概念，超越了其他3D模型和2D分割基线的结果。项目详情可访问我们的网页 https://tau-vailab.github.io/HaLo-NeRF/。",
    "title_cn": "HaLo-NeRF：探索自由式照片集的几何引导语义学习。",
    "tags": [
      "分类：LLM应用\n\n这篇论文的摘要描述了一种结合了视觉与语言模型的定位系统，该系统利用互联网上的图像和文本信息来理解和导航大型旅游地标。虽然它涉及到了视觉和语言模型的应用，但主要关注的是如何利用大型语言模型（LLM）从互联网文本元数据中获取语义信息，以增强对场景的理解和导航。因此，这篇论文最符合\"LLM应用\"这一分类。",
      "",
      "3D建模"
    ]
  },
  {
    "title": "Combining Insights From Multiple Large Language Models Improves Diagnostic Accuracy",
    "submit_datetime": "2024年02月13日",
    "abstract": "Background: Large language models (LLMs) such as OpenAI's GPT-4 or Google's PaLM 2 are proposed as viable diagnostic support tools or even spoken of as replacements for \"curbside consults\". However, even LLMs specifically trained on medical topics may lack sufficient diagnostic accuracy for real-life applications.\n  Methods: Using collective intelligence methods and a dataset of 200 clinical vignettes of real-life cases, we assessed and compared the accuracy of differential diagnoses obtained by asking individual commercial LLMs (OpenAI GPT-4, Google PaLM 2, Cohere Command, Meta Llama 2) against the accuracy of differential diagnoses synthesized by aggregating responses from combinations of the same LLMs.\n  Results: We find that aggregating responses from multiple, various LLMs leads to more accurate differential diagnoses (average accuracy for 3 LLMs: $75.3\\%\\pm 1.6pp$) compared to the differential diagnoses produced by single LLMs (average accuracy for single LLMs: $59.0\\%\\pm 6.1pp$).\n  Discussion: The use of collective intelligence methods to synthesize differential diagnoses combining the responses of different LLMs achieves two of the necessary steps towards advancing acceptance of LLMs as a diagnostic support tool: (1) demonstrate high diagnostic accuracy and (2) eliminate dependence on a single commercial vendor.",
    "pdf_link": "https://arxiv.org/abs/2402.08806",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2402.08806v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.08806/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2402.08806v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.08806/x2.png"
      }
    ],
    "abstract_cn": "背景：大型语言模型（LLM），如 OpenAI 的 GPT-4 或 Google 的 PaLM 2，被提议作为诊断辅助工具，甚至可能取代现场咨询。但即便是专门训练于医学领域的 LLM，其诊断精确度也未必能满足实际应用的需求。方法：我们利用群体智能技术，结合200个真实临床案例的资料集，对比了单独商业化LLM（包括OpenAI GPT-4、Google PaLM 2、Cohere Command、Meta Llama 2）的个体诊断准确性，以及通过整合这些LLM的响应得出的综合诊断准确性。结果：研究发现，整合多个不同LLM的响应得到的诊断准确性更高（三个LLM的平均准确度为75.3% ± 1.6pp），相比于单一LLM的诊断结果（单一LLM的平均准确度为59.0% ± 6.1pp）。讨论：通过群体智能技术整合不同LLM的响应以形成综合诊断，有助于推动LLM作为诊断辅助工具的接受度，这包括两个关键步骤：（1）证明其高度的诊断准确性；（2）减少对单一商业供应商的依赖。",
    "title_cn": "融合多个大型语言模型的洞见，能够显著提升诊断的精确度。",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Agent Smith: A Single Image Can Jailbreak One Million Multimodal LLM Agents Exponentially Fast",
    "submit_datetime": "2024年02月13日",
    "abstract": "A multimodal large language model (MLLM) agent can receive instructions, capture images, retrieve histories from memory, and decide which tools to use. Nonetheless, red-teaming efforts have revealed that adversarial images/prompts can jailbreak an MLLM and cause unaligned behaviors. In this work, we report an even more severe safety issue in multi-agent environments, referred to as infectious jailbreak. It entails the adversary simply jailbreaking a single agent, and without any further intervention from the adversary, (almost) all agents will become infected exponentially fast and exhibit harmful behaviors. To validate the feasibility of infectious jailbreak, we simulate multi-agent environments containing up to one million LLaVA-1.5 agents, and employ randomized pair-wise chat as a proof-of-concept instantiation for multi-agent interaction. Our results show that feeding an (infectious) adversarial image into the memory of any randomly chosen agent is sufficient to achieve infectious jailbreak. Finally, we derive a simple principle for determining whether a defense mechanism can provably restrain the spread of infectious jailbreak, but how to design a practical defense that meets this principle remains an open question to investigate. Our project page is available at https://sail-sg.github.io/Agent-Smith/.",
    "pdf_link": "https://arxiv.org/abs/2402.08567",
    "graphs": [],
    "abstract_cn": "一款多模态的大型语言模型（MLLM）智能体能够接收指令、捕捉图像、从记忆库中检索历史信息，并自主选择使用何种工具。然而，对抗性图像或提示已被发现能够使MLLM智能体越狱，引发不预期的行为。本研究揭露了在多智能体环境中一个更为严重的安全隐患——传染性越狱。这种攻击方式仅需对单个智能体进行越狱操作，随后无需进一步干预，几乎所有智能体都会迅速被感染，并展现出有害行为。为了证明传染性越狱的可能性，我们构建了包含多达百万个LLaVA-1.5智能体的多智能体环境，并通过随机配对聊天作为多智能体互动的概念验证。研究结果显示，仅需将一张（传染性的）对抗性图像植入任意一个智能体的记忆库中，就足以触发传染性越狱。我们进一步提出了一个简单的原理，用以判断一种防御机制是否能够有效遏制传染性越狱的蔓延，但如何设计出既实用又符合该原理的防御措施，仍是一个亟待解决的问题。项目详情可访问我们的网页 https://sail-sg.github.io/Agent-Smith/。",
    "title_cn": "Agent Smith：仅需一张图片，便能迅速让百万计的多模态大型语言模型（LLM）代理陷入崩溃，其速度呈指数级增长。",
    "tags": [
      "Agent",
      "人工智能安全",
      "多智能体系统"
    ]
  },
  {
    "title": "AIR-Bench: Benchmarking Large Audio-Language Models via Generative Comprehension",
    "submit_datetime": "2024年02月12日",
    "abstract": "Recently, instruction-following audio-language models have received broad attention for human-audio interaction. However, the absence of benchmarks capable of evaluating audio-centric interaction capabilities has impeded advancements in this field. Previous models primarily focus on assessing different fundamental tasks, such as Automatic Speech Recognition (ASR), and lack an assessment of the open-ended generative capabilities centered around audio. Thus, it is challenging to track the progression in the Large Audio-Language Models (LALMs) domain and to provide guidance for future improvement. In this paper, we introduce AIR-Bench (\\textbf{A}udio \\textbf{I}nst\\textbf{R}uction \\textbf{Bench}mark), the first benchmark designed to evaluate the ability of LALMs to understand various types of audio signals (including human speech, natural sounds, and music), and furthermore, to interact with humans in the textual format. AIR-Bench encompasses two dimensions: \\textit{foundation} and \\textit{chat} benchmarks. The former consists of 19 tasks with approximately 19k single-choice questions, intending to inspect the basic single-task ability of LALMs. The latter one contains 2k instances of open-ended question-and-answer data, directly assessing the comprehension of the model on complex audio and its capacity to follow instructions. Both benchmarks require the model to generate hypotheses directly. We design a unified framework that leverages advanced language models, such as GPT-4, to evaluate the scores of generated hypotheses given the meta-information of the audio. Experimental results demonstrate a high level of consistency between GPT-4-based evaluation and human evaluation. By revealing the limitations of existing LALMs through evaluation results, AIR-Bench can provide insights into the direction of future research.",
    "pdf_link": "https://arxiv.org/abs/2402.07729",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2402.07729v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.07729/main_figure.png"
      },
      {
        "url": "https://arxiv.org/html/2402.07729v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.07729/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2402.07729v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.07729/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2402.07729v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.07729/three_figures.png"
      }
    ],
    "abstract_cn": "近期，用于人声音频互动的指令遵循型音频-语言模型受到了广泛关注。但目前缺少评估音频交互能力的基准测试，这限制了该领域的进一步发展。以往的研究主要集中在基础任务如自动语音识别（ASR）上，而忽略了对音频中心的开放式生成能力的评估。这使得追踪大型音频-语言模型（LALMs）的发展和指导未来改进变得困难。本文提出了AIR-Bench（音频指令基准测试），这是首个旨在评估LALMs理解多种音频信号并进行文本交互能力的基准。AIR-Bench包含基础和聊天两个维度，前者包含19个任务，约19k个单选问题，用以检验LALMs的基本单任务能力；后者则包含2k个开放式问答实例，直接测试模型对复杂音频的理解和指令遵循能力。两个基准测试都要求模型直接生成假设。我们构建了一个统一框架，使用如GPT-4这样的高级语言模型来评估基于音频元信息生成的假设得分。实验结果显示，基于GPT-4的评估与人类评估具有高度一致性。AIR-Bench通过评估结果揭示了现有LALMs的不足，为未来研究方向提供了指导。",
    "title_cn": "AIR-Bench：通过创造性理解对大型音频-语言模型进行性能评估。",
    "tags": [
      "LLM应用",
      "音频处理",
      ""
    ]
  },
  {
    "title": "OpenFedLLM: Training Large Language Models on Decentralized Private Data via Federated Learning",
    "submit_datetime": "2024年02月10日",
    "abstract": "Trained on massive publicly available data, large language models (LLMs) have demonstrated tremendous success across various fields. While more data contributes to better performance, a disconcerting reality is that high-quality public data will be exhausted in a few years. In this paper, we offer a potential next step for contemporary LLMs: collaborative and privacy-preserving LLM training on the underutilized distributed private data via federated learning (FL), where multiple data owners collaboratively train a shared model without transmitting raw data. To achieve this, we build a concise, integrated, and research-friendly framework/codebase, named OpenFedLLM. It covers federated instruction tuning for enhancing instruction-following capability, federated value alignment for aligning with human values, and 7 representative FL algorithms. Besides, OpenFedLLM supports training on diverse domains, where we cover 8 training datasets; and provides comprehensive evaluations, where we cover 30+ evaluation metrics. Through extensive experiments, we observe that all FL algorithms outperform local training on training LLMs, demonstrating a clear performance improvement across a variety of settings. Notably, in a financial benchmark, Llama2-7B fine-tuned by applying any FL algorithm can outperform GPT-4 by a significant margin while the model obtained through individual training cannot, demonstrating strong motivation for clients to participate in FL. The code is available at https://github.com/rui-ye/OpenFedLLM.",
    "pdf_link": "https://arxiv.org/abs/2402.06954",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2402.06954v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.06954/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2402.06954v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.06954/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2402.06954v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.06954/x3.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）利用海量公开数据训练，在众多领域取得了显著成就。然而，优质公共数据资源将在不久后面临枯竭。本文提出了当前LLMs发展的新方向：通过联邦学习（FL），在保护隐私的前提下，利用分散的私有数据进行协作训练。我们开发了OpenFedLLM，一个简洁、集成化且研究友好的框架/代码库，它包括联邦指令调整、价值对齐以及7种代表性的FL算法。OpenFedLLM支持跨多个领域的训练，并涵盖了8种不同的训练数据集，同时提供超过30个评估指标的全面评估。广泛的实验表明，所有FL算法在LLMs的训练上都超越了传统的本地训练方法。特别地，在金融领域的基准测试中，使用任何FL算法微调的Llama2-7B性能显著优于GPT-4，这一发现极大地激励了客户端参与FL的积极性。相关代码已在GitHub上公开，地址为 https://github.com/rui-ye/OpenFedLLM。",
    "title_cn": "OpenFedLLM：采用联邦学习技术，实现在分散的私密数据上对大型语言模型的训练。",
    "tags": [
      "LLM应用",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Sentinels of the Stream: Unleashing Large Language Models for Dynamic Packet Classification in Software Defined Networks -- Position Paper",
    "submit_datetime": "2024年02月09日",
    "abstract": "With the release of OpenAI's ChatGPT, the field of large language models (LLM) saw an increase of academic interest in GPT based chat assistants. In the next few months multiple accesible large language models were released that included Meta's LLama models and Mistral AI's Mistral and Mixtral MoE models. These models are available openly for a wide array of purposes with a wide spectrum of licenses. These LLMs have found their use in a different number of fields like code development, SQL generation etc. In this work we propose our plan to explore the applicability of large language model in the domain of network security. We plan to create Sentinel, a LLM, to analyse network packet contents and pass a judgment on it's threat level. This work is a preliminary report that will lay our plan for our future endeavors.",
    "pdf_link": "https://arxiv.org/abs/2402.07950",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2402.07950v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.07950/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2402.07950v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.07950/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2402.07950v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.07950/x4.png"
      }
    ],
    "abstract_cn": "OpenAI 的 ChatGPT 问世后，学术界对基于 GPT 的大型语言模型（LLM）聊天助手的兴趣激增。随后数月，多款大型语言模型相继问世，包括 Meta 的 LLama 系列和 Mistral AI 的 Mistral 及 Mixtral MoE 模型。这些模型以多种许可证形式，开放用于广泛的用途，如编程、SQL 创建等。本研究旨在探讨大型语言模型在网络安全领域的应用潜力。我们计划开发一款名为 Sentinel 的 LLM，用于分析网络数据包内容，并评估其潜在威胁。本报告为初步研究，旨在为未来的研究工作奠定基础。",
    "title_cn": "《流之守望：利用大型语言模型实现软件定义网络中的动态数据包分类》——立场论文",
    "tags": [
      "分类：LLM应用",
      "网络安全",
      "人工智能"
    ]
  },
  {
    "title": "RedCoast: A Lightweight Tool to Automate Distributed Training of LLMs on Any GPU/TPUs",
    "submit_datetime": "2024年02月08日",
    "abstract": "The recent progress of AI can be largely attributed to large language models (LLMs). However, their escalating memory requirements introduce challenges for machine learning (ML) researchers and engineers. Addressing this requires developers to partition a large model to distribute it across multiple GPUs or TPUs. This necessitates considerable coding and intricate configuration efforts with existing model parallel tools, such as Megatron-LM, DeepSpeed, and Alpa. These tools require users' expertise in machine learning systems (MLSys), creating a bottleneck in LLM development, particularly for developers without MLSys background. In this work, we present RedCoast(Redco), a lightweight and user-friendly tool crafted to automate distributed training and inference for LLMs, as well as to simplify ML pipeline development. The design of Redco emphasizes two key aspects. Firstly, to automate model parallism, our study identifies two straightforward rules to generate tensor parallel strategies for any given LLM. Integrating these rules into Redco facilitates effortless distributed LLM training and inference, eliminating the need of additional coding or complex configurations. We demonstrate the effectiveness by applying Redco on a set of LLM architectures, such as GPT-J, LLaMA, T5, and OPT, up to the size of 66B. Secondly, we propose a mechanism that allows for the customization of diverse ML pipelines through the definition of merely three functions, avoiding redundant and formulaic code like multi-host related processing. This mechanism proves adaptable across a spectrum of ML algorithms, from foundational language modeling to complex algorithms like meta-learning and reinforcement learning. Consequently, Redco implementations exhibit much fewer code lines compared to their official counterparts.",
    "pdf_link": "https://arxiv.org/abs/2310.16355",
    "graphs": [],
    "abstract_cn": "人工智能的最新突破在很大程度上得益于大型语言模型（LLMs）的发展。但这些模型日益增长的内存需求对机器学习（ML）的研究者和工程师构成了挑战。为了应对这一挑战，开发者必须将大型模型拆分，以便跨多个GPU或TPU进行分配。这一过程需要开发者使用Megatron-LM、DeepSpeed和Apla等现有的模型并行工具进行大量的编程和复杂的配置。这些工具的使用需要用户具备深厚的机器学习系统（MLSys）知识，这在LLM的开发过程中，对于没有MLSys背景的开发者来说，无疑是一个难题。为了解决这一问题，我们开发了RedCoast（简称Redco），这是一个轻量级且易于使用的工具，它能够自动化LLM的分布式训练和推理，并简化了ML流程的开发。Redco的设计突出了两个核心要素：首先，通过自动化模型并行化，我们的研究提出了两条简单的规则，为任何特定的LLM生成张量并行策略。将这些规则整合到Redco中，极大地简化了分布式LLM的训练和推理过程，无需额外编程或复杂配置。我们通过在GPT-J、LLaMA、T5和OPT等一系列LLM架构上应用Redco，证明了其有效性，这些模型的规模高达66B参数。其次，我们设计了一种机制，用户只需定义三个函数，即可定制多样化的ML流程，避免了编写冗长和刻板的多主机相关代码。这一机制在各种ML算法中都显示出了良好的适应性，从基础的语言模型到复杂的元学习和强化学习算法。因此，Redco的实现在代码行数上大大少于官方版本。",
    "title_cn": "RedCoast：一款轻量级工具，旨在简化在各种 GPU 或 TPU 上进行大型语言模型的分布式训练过程。",
    "tags": [
      "LLM应用",
      "机器学习",
      "系统开发"
    ]
  },
  {
    "title": "MR-GSM8K: A Meta-Reasoning Revolution in Large Language Model Evaluation",
    "submit_datetime": "2024年02月06日",
    "abstract": "In this work, we introduce a novel evaluation paradigm for Large Language Models, one that challenges them to engage in meta-reasoning. This approach addresses critical shortcomings in existing math problem-solving benchmarks, traditionally used to evaluate the cognitive capabilities of agents. Our paradigm shifts the focus from result-oriented assessments, which often overlook the reasoning process, to a more holistic evaluation that effectively differentiates the cognitive capabilities among models. For example, in our benchmark, GPT-4 demonstrates a performance five times better than GPT3-5. The significance of this new paradigm lies in its ability to reveal potential cognitive deficiencies in LLMs that current benchmarks, such as GSM8K, fail to uncover due to their saturation and lack of effective differentiation among varying reasoning abilities. Our comprehensive analysis includes several state-of-the-art math models from both open-source and closed-source communities, uncovering fundamental deficiencies in their training and evaluation approaches. This paper not only advocates for a paradigm shift in the assessment of LLMs but also contributes to the ongoing discourse on the trajectory towards Artificial General Intelligence (AGI). By promoting the adoption of meta-reasoning evaluation methods similar to ours, we aim to facilitate a more accurate assessment of the true cognitive abilities of LLMs.",
    "pdf_link": "https://arxiv.org/abs/2312.17080",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2312.17080v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.17080/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2312.17080v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.17080/reasoning_paths2.png"
      },
      {
        "url": "https://arxiv.org/html/2312.17080v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.17080/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2312.17080v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.17080/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2312.17080v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.17080/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2312.17080v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.17080/x5.png"
      }
    ],
    "abstract_cn": "本研究提出了一种针对大型语言模型（LLMs）的创新评估框架，旨在推动模型进行深层次的元推理。这一方法克服了传统数学问题解决基准测试的局限，这些测试通常只评估代理的最终结果，而忽略了推理过程本身。我们的评估框架更加全面，能够更有效地衡量不同模型之间的认知差异。以我们的测试为例，GPT-4的解题能力是GPT3-5的五倍。这种新框架的关键在于其揭示了现有评估标准（如GSM8K）无法察觉的LLMs潜在认知缺陷，这些缺陷因现有标准的饱和度和对不同推理能力的区分不足而被掩盖。我们的深入分析涵盖了来自开源和闭源社区的多种尖端数学模型，发现了它们在训练和评估方法上的根本性不足。本文不仅呼吁对LLMs的评估方法进行根本性的变革，也为关于实现人工通用智能（AGI）的路径的讨论提供了新的视角。我们提倡采用类似于我们的元推理评估方法，以期对LLMs的真实认知能力进行更精确的评估。",
    "title_cn": "MR-GSM8K：引领大型语言模型评估领域的元推理革新。",
    "tags": [
      "LLM理论",
      "人工智能",
      "认知科学"
    ]
  },
  {
    "title": "LLM Multi-Agent Systems: Challenges and Open Problems",
    "submit_datetime": "2024年02月05日",
    "abstract": "This paper explores existing works of multi-agent systems and identifies challenges that remain inadequately addressed. By leveraging the diverse capabilities and roles of individual agents within a multi-agent system, these systems can tackle complex tasks through collaboration. We discuss optimizing task allocation, fostering robust reasoning through iterative debates, managing complex and layered context information, and enhancing memory management to support the intricate interactions within multi-agent systems. We also explore the potential application of multi-agent systems in blockchain systems to shed light on their future development and application in real-world distributed systems.",
    "pdf_link": "https://arxiv.org/abs/2402.03578",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2402.03578v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.03578/x1.png"
      }
    ],
    "abstract_cn": "本篇论文深入研究了多智能体系统的现有研究成果，并指出了尚未得到充分解决的难题。文章强调了通过多智能体系统中个体智能体的多样化能力和角色的协作，可以共同应对复杂的任务。文中讨论了任务分配的优化、通过反复辩论加强鲁棒推理、处理复杂分层的上下文信息，以及提升内存管理以促进多智能体系统内部的精细交互。此外，文章还探讨了多智能体系统在区块链技术中的应用前景，为未来在现实世界分布式系统中的发展和应用提供了洞见。",
    "title_cn": "在大型语言模型的多代理系统中，我们面临着一系列挑战和尚未解决的问题。",
    "tags": [
      "Agent",
      "智能体系统",
      "区块链"
    ]
  },
  {
    "title": "LLM Agents in Interaction: Measuring Personality Consistency and Linguistic Alignment in Interacting Populations of Large Language Models",
    "submit_datetime": "2024年02月05日",
    "abstract": "While both agent interaction and personalisation are vibrant topics in research on large language models (LLMs), there has been limited focus on the effect of language interaction on the behaviour of persona-conditioned LLM agents. Such an endeavour is important to ensure that agents remain consistent to their assigned traits yet are able to engage in open, naturalistic dialogues. In our experiments, we condition GPT-3.5 on personality profiles through prompting and create a two-group population of LLM agents using a simple variability-inducing sampling algorithm. We then administer personality tests and submit the agents to a collaborative writing task, finding that different profiles exhibit different degrees of personality consistency and linguistic alignment to their conversational partners. Our study seeks to lay the groundwork for better understanding of dialogue-based interaction between LLMs and highlights the need for new approaches to crafting robust, more human-like LLM personas for interactive environments.",
    "pdf_link": "https://arxiv.org/abs/2402.02896",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2402.02896v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.02896/bfi_after_init_boxplot.png"
      },
      {
        "url": "https://arxiv.org/html/2402.02896v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.02896/bfi_after_writing_boxplot.png"
      },
      {
        "url": "https://arxiv.org/html/2402.02896v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.02896/liwc_nointeraction_pca_scatterplot.png"
      },
      {
        "url": "https://arxiv.org/html/2402.02896v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.02896/liwc_interaction_pca_scatterplot.png"
      },
      {
        "url": "https://arxiv.org/html/2402.02896v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.02896/bfi_before_after_interaction_violin_plot.png"
      },
      {
        "url": "https://arxiv.org/html/2402.02896v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2402.02896/bfi_after_interactive_writing_boxplot.png"
      }
    ],
    "abstract_cn": "代理互动与个性化在大型语言模型（LLM）的研究领域内均是活跃的研究主题，但对语言互动如何影响个性化LLM代理行为的研究却鲜有关注。确保这些代理在保持其既定特性的同时，能够进行开放且自然的对话至关重要。在本研究中，我们通过提示的方式对GPT-3.5进行个性化设置，并利用一个简单的变化引入抽样算法，生成了两组LLM代理。随后，我们对这些代理进行了性格测试，并让它们参与协作写作任务，结果发现不同性格配置的代理在性格一致性和与对话伙伴的语言协调性上表现出差异。本研究旨在深化我们对LLM间对话互动的理解，并强调了为交互环境设计更强健、更人性化的LLM个性化代理的新方法的必要性。",
    "title_cn": "大型语言模型（LLM）的交互代理：探究在互动中的LLM群体内的个性连贯性与语言协调性",
    "tags": [
      "Agent",
      "人工智能",
      ""
    ]
  },
  {
    "title": "Machine Unlearning in Large Language Models",
    "submit_datetime": "2024年02月03日",
    "abstract": "Recently, large language models (LLMs) have emerged as a notable field, attracting significant attention for its ability to automatically generate intelligent contents for various application domains. However, LLMs still suffer from significant security and privacy issues. For example, LLMs might expose user privacy from hacking attacks or targeted prompts. To address this problem, this paper introduces a novel machine unlearning framework into LLMs. Our objectives are to make LLMs not produce harmful, hallucinatory, or privacy-compromising responses, while retaining their standard output capabilities. To accomplish this, we use an evaluative model to pinpoint dialogues needing unlearning. We also establish a distance loss to function as the model's negative loss, diverting it from previous undesirable outputs. Furthermore, we determine the expected output's cluster mean to formulate a positive loss, directing the model's outputs toward preferable outcomes without compromising its reasoning abilities and performance. Experimental results show that our approach effectively meets unlearning objectives without substantially compromising model performance.",
    "pdf_link": "https://arxiv.org/abs/2404.16841",
    "graphs": [],
    "abstract_cn": "近期，大型语言模型（LLMs）作为新兴领域崭露头角，因其自动生成多样化应用领域智能内容的能力而备受瞩目。尽管如此，LLMs在安全与隐私方面仍存在不少挑战，如可能因黑客攻击或特定提示而泄露用户隐私。为应对这一问题，本研究提出了一种创新的机器退训练框架，旨在提升LLMs的安全性。我们的目标是确保LLMs不会生成有害、产生幻觉或侵犯隐私的响应，同时维持其标准的输出功能。通过采用评估模型精准识别需要退训练的对话，并引入距离损失作为负面损失，引导模型避免不良输出。同时，我们计算预期输出的簇均值，构建正面损失，以促进模型输出朝着更优结果发展，同时保证其推理和性能不受影响。实验结果显示，该方法在不牺牲模型性能的前提下，有效实现了退训练的目标。",
    "title_cn": "机器忘却在大型语言模型领域备受关注，这一话题在学术界和工业界都引起了广泛的讨论。",
    "tags": [
      "LLM应用",
      "人工智能安全",
      "隐私保护"
    ]
  },
  {
    "title": "Evil Geniuses: Delving into the Safety of LLM-based Agents",
    "submit_datetime": "2024年02月02日",
    "abstract": "Rapid advancements in large language models (LLMs) have revitalized in LLM-based agents, exhibiting impressive human-like behaviors and cooperative capabilities in various scenarios. However, these agents also bring some exclusive risks, stemming from the complexity of interaction environments and the usability of tools. This paper delves into the safety of LLM-based agents from three perspectives: agent quantity, role definition, and attack level. Specifically, we initially propose to employ a template-based attack strategy on LLM-based agents to find the influence of agent quantity. In addition, to address interaction environment and role specificity issues, we introduce Evil Geniuses (EG), an effective attack method that autonomously generates prompts related to the original role to examine the impact across various role definitions and attack levels. EG leverages Red-Blue exercises, significantly improving the generated prompt aggressiveness and similarity to original roles. Our evaluations on CAMEL, Metagpt and ChatDev based on GPT-3.5 and GPT-4, demonstrate high success rates. Extensive evaluation and discussion reveal that these agents are less robust, prone to more harmful behaviors, and capable of generating stealthier content than LLMs, highlighting significant safety challenges and guiding future research. Our code is available at https://github.com/T1aNS1R/Evil-Geniuses.",
    "pdf_link": "https://arxiv.org/abs/2311.11855",
    "graphs": [],
    "abstract_cn": "随着大型语言模型的飞速发展，基于LLM的代理展现出逼真的人类行为和协作能力，但同时也带来了源自交互环境复杂性和工具可用性的独特风险。本文从代理数量、角色定义和攻击级别三个维度深入探讨了LLM代理的安全性。我们首创性地采用基于模板的攻击策略，探究代理数量对LLM的影响。针对交互环境和角色特异性问题，我们提出了“邪恶天才”（EG）攻击方法，该方法能自动生成与原始角色相关的提示，以评估不同角色定义和攻击级别的影响。EG通过红蓝对抗演习，大幅提升了提示的攻击性和与原始角色的相似度。我们在GPT-3.5和GPT-4基础上的CAMEL、Metagpt和ChatDev的评估中，取得了高成功率。广泛的评估和讨论揭示了这些代理的脆弱性，它们更容易产生有害行为，并能生成比LLMs更隐蔽的内容，凸显了安全挑战，并为未来研究指明了方向。我们的代码已公开在https://github.com/T1aNS1R/Evil-Geniuses。",
    "title_cn": "恶才探秘：剖析基于LLM的智能体安全之谜在",
    "tags": [
      "Agent\n\n这篇论文主要探讨了基于大型语言模型（LLM）的代理（Agent）的安全性问题，特别是代理数量、角色定义和攻击级别对LLM代理安全性的影响。论文提出了新的攻击策略和方法，并通过实验评估了这些策略和方法在不同代理系统中的效果。因此，这篇论文更符合Agent分类，因为它专注于代理系统的安全性和攻击性评估，而不是LLM的理论研究或应用开发。",
      "人工智能安全",
      "社会工程学"
    ]
  },
  {
    "title": "\"Medium\" LMs of Code in the Era of LLMs: Lessons From StackOverflow",
    "submit_datetime": "2024年01月24日",
    "abstract": "Large pre-trained neural language models have brought immense progress to both NLP and software engineering. Models in OpenAI's GPT series now dwarf Google's BERT and Meta's RoBERTa, which previously set new benchmarks on a wide range of NLP applications. These models are trained on massive corpora of heterogeneous data from web crawls, which enables them to learn general language patterns and semantic relationships. However, the largest models are both expensive to train and deploy and are often closed-source, so we lack access to their data and design decisions. We argue that this trend towards large, general-purpose models should be complemented with single-purpose, more modestly sized pre-trained models. In this work, we take StackOverflow (SO) as a domain example in which large volumes of rich aligned code and text data is available. We adopt standard practices for pre-training large language models, including using a very large context size (2,048 tokens), batch size (0.5M tokens) and training set (27B tokens), coupled with a powerful toolkit (Megatron-LM), to train two models: SOBertBase, with 109M parameters, and SOBertLarge with 762M parameters, at a budget of just $\\$187$ and $\\$800$ each. We compare the performance of our models with both the previous SOTA model trained on SO data exclusively as well general-purpose BERT models and OpenAI's ChatGPT on four SO-specific downstream tasks - question quality prediction, closed question prediction, named entity recognition and obsoletion prediction (a new task we introduce). Not only do our models consistently outperform all baselines, the smaller model is often sufficient for strong results. Both models are released to the public. These results demonstrate that pre-training both extensively and properly on in-domain data can yield a powerful and affordable alternative to leveraging closed-source general-purpose models.",
    "pdf_link": "https://arxiv.org/abs/2306.03268",
    "graphs": [],
    "abstract_cn": "大型预训练神经语言模型极大地推动了自然语言处理和软件工程的发展。OpenAI的GPT系列模型超越了Google的BERT和Meta的RoBERTa，后者曾刷新了多项NLP应用的性能记录。这些模型通过海量网络爬取的多样化数据进行训练，从而掌握了通用的语言模式和语义联系。尽管如此，最大规模的模型不仅训练成本高昂，而且往往是闭源的，限制了我们对其数据和设计选择的了解。我们认为，对于这种大型通用模型的依赖应当辅以特定用途、规模适中的预训练模型。本研究以StackOverflow（SO）为案例，利用其丰富的代码和文本数据进行研究。我们遵循预训练大型语言模型的常规方法，采用大上下文尺寸（2,048个标记）、大批量尺寸（0.5M个标记）和庞大的训练集（27B个标记），并结合Megatron-LM这一强大工具，训练了两个模型：SOBertBase（109M参数）和SOBertLarge（762M参数），每个模型的预算分别仅为187美元和800美元。我们对这两个模型在四个SO特定的下游任务上的表现进行了评估，包括问题质量预测、封闭式问题预测、命名实体识别和过时预测（我们新引入的任务）。我们的模型在所有比较中均优于现有基准，且较小的模型已足够取得优异成绩。目前，这两个模型均已公开发布。这些成果证明了在特定领域数据上进行全面且恰当的预训练，可以成为利用闭源通用模型的有力且经济的替代方案。",
    "title_cn": "在大型语言模型（LLMs）盛行的时代，我们探讨了“中等规模”的代码语言模型（\"Medium\" LMs of Code），并从 StackOverflow 的经验中汲取教训。",
    "tags": [
      "LLM应用",
      "",
      "软件工程"
    ]
  },
  {
    "title": "Quality of Answers of Generative Large Language Models vs Peer Patients for Interpreting Lab Test Results for Lay Patients: Evaluation Study",
    "submit_datetime": "2024年01月23日",
    "abstract": "Lab results are often confusing and hard to understand. Large language models (LLMs) such as ChatGPT have opened a promising avenue for patients to get their questions answered. We aim to assess the feasibility of using LLMs to generate relevant, accurate, helpful, and unharmful responses to lab test-related questions asked by patients and to identify potential issues that can be mitigated with augmentation approaches. We first collected lab test results related question and answer data from Yahoo! Answers and selected 53 QA pairs for this study. Using the LangChain framework and ChatGPT web portal, we generated responses to the 53 questions from four LLMs including GPT-4, Meta LLaMA 2, MedAlpaca, and ORCA_mini. We first assessed the similarity of their answers using standard QA similarity-based evaluation metrics including ROUGE, BLEU, METEOR, BERTScore. We also utilized an LLM-based evaluator to judge whether a target model has higher quality in terms of relevance, correctness, helpfulness, and safety than the baseline model. Finally, we performed a manual evaluation with medical experts for all the responses to seven selected questions on the same four aspects. The results of Win Rate and medical expert evaluation both showed that GPT-4's responses achieved better scores than all the other LLM responses and human responses on all four aspects (relevance, correctness, helpfulness, and safety). However, LLM responses occasionally also suffer from a lack of interpretation in one's medical context, incorrect statements, and lack of references. We find that compared to other three LLMs and human answer from the Q&A website, GPT-4's responses are more accurate, helpful, relevant, and safer. However, there are cases which GPT-4 responses are inaccurate and not individualized. We identified a number of ways to improve the quality of LLM responses.",
    "pdf_link": "https://arxiv.org/abs/2402.01693",
    "graphs": [],
    "abstract_cn": "实验室报告常常令人费解，但大型语言模型（LLMs）如 ChatGPT 为患者提供了一个获取答案的新途径。本研究旨在探讨利用 LLMs 为患者提出的实验室检测相关问题生成精准、有用且安全回答的可行性，并指出可通过增强策略减轻的潜在问题。我们从 Yahoo! Answers 搜集了实验室检测相关问题和答案，精选出 53 对问答对进行分析。利用 LangChain 框架及 ChatGPT 网络接口，我们从 GPT-4、Meta LLaMA 2、MedAlpaca 和 ORCA_mini 四款 LLMs 中为这 53 个问题生成了回答。我们首先采用标准的 QA 相似度评估指标，如 ROUGE、BLEU、METEOR、BERTScore，来评估答案之间的相似度。同时，我们还运用基于 LLM 的评估工具，判断目标模型在相关性、准确性、有用性和安全性方面是否优于基线模型。最终，我们邀请医学专家对七个选定问题的答复进行了人工评审，同样从四个维度进行评估。结果显示，无论是在胜率还是医学专家的评审中，GPT-4 的答复在相关性、准确性、有用性和安全性四个方面均优于其他 LLMs 和人类答复。尽管如此，LLMs 的答复有时仍缺乏对医疗背景的解释，存在错误陈述和缺少参考文献。与其他三款 LLMs 和人类回答相比，GPT-4 的答复更为精确、有益、贴切且安全。然而，GPT-4 的答复也存在不准确和缺乏个性化的情况。我们提出了多种提升 LLMs 答复质量的方法。",
    "title_cn": "生成式大型语言模型与病友在解读普通患者实验室检测结果时答案质量的比较：一项评估研究",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Meta-Prompting: Enhancing Language Models with Task-Agnostic Scaffolding",
    "submit_datetime": "2024年01月23日",
    "abstract": "We introduce meta-prompting, an effective scaffolding technique designed to enhance the functionality of language models (LMs). This approach transforms a single LM into a multi-faceted conductor, adept at managing and integrating multiple independent LM queries. By employing high-level instructions, meta-prompting guides the LM to break down complex tasks into smaller, more manageable subtasks. These subtasks are then handled by distinct \"expert\" instances of the same LM, each operating under specific, tailored instructions. Central to this process is the LM itself, in its role as the conductor, which ensures seamless communication and effective integration of the outputs from these expert models. It additionally employs its inherent critical thinking and robust verification processes to refine and authenticate the end result. This collaborative prompting approach empowers a single LM to simultaneously act as a comprehensive orchestrator and a panel of diverse experts, significantly enhancing its performance across a wide array of tasks. The zero-shot, task-agnostic nature of meta-prompting greatly simplifies user interaction by obviating the need for detailed, task-specific instructions. Furthermore, our research demonstrates the seamless integration of external tools, such as a Python interpreter, into the meta-prompting framework, thereby broadening its applicability and utility. Through rigorous experimentation with GPT-4, we establish the superiority of meta-prompting over conventional scaffolding methods: When averaged across all tasks, including the Game of 24, Checkmate-in-One, and Python Programming Puzzles, meta-prompting, augmented with a Python interpreter functionality, surpasses standard prompting by 17.1%, expert (dynamic) prompting by 17.3%, and multipersona prompting by 15.2%.",
    "pdf_link": "https://arxiv.org/abs/2401.12954",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2401.12954v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2401.12954/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2401.12954v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2401.12954/x2.png"
      }
    ],
    "abstract_cn": "本文提出了一种创新的元提示技术，用以提升语言模型（LMs）的多任务处理能力。该技术将单一的语言模型塑造成一位多才多艺的指挥家，能够巧妙地协调和整合多个独立的语言模型查询。通过高级指令的引导，语言模型能够将复杂任务细化为易于管理的小任务，由不同“专家”角色的同一模型分别处理，每个角色都遵循特定的定制化指令。在这个过程中，语言模型作为指挥家，确保了专家模型输出之间的无缝交流与有效整合，同时运用其内在的批判性思维和严谨的验证流程，对最终结果进行精细化处理和认证。这种协作式的提示方法赋予了单个语言模型以全面的策划者和多样化专家团队的双重角色，显著提升了其在广泛任务类型上的表现。元提示的零样本、任务通用性特点，通过省略对具体任务指令的详细需求，极大地简化了用户操作。研究还展示了将Python解释器等外部工具无缝集成至元提示框架的可能性，进一步扩展了其应用范围和实用性。通过在GPT-4上的严谨实验，我们证明了元提示在包括24点游戏、一击制胜和Python编程谜题等任务上，相较于传统支撑方法的优越性：平均而言，元提示结合Python解释器功能，比标准提示提升了17.1%，比动态专家提示提升了17.3%，比多角色提示提升了15.2%。",
    "title_cn": "元提示：为语言模型注入通用性支撑，提升其性能",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Designing Heterogeneous LLM Agents for Financial Sentiment Analysis",
    "submit_datetime": "2024年01月11日",
    "abstract": "Large language models (LLMs) have drastically changed the possible ways to design intelligent systems, shifting the focuses from massive data acquisition and new modeling training to human alignment and strategical elicitation of the full potential of existing pre-trained models. This paradigm shift, however, is not fully realized in financial sentiment analysis (FSA), due to the discriminative nature of this task and a lack of prescriptive knowledge of how to leverage generative models in such a context. This study investigates the effectiveness of the new paradigm, i.e., using LLMs without fine-tuning for FSA. Rooted in Minsky's theory of mind and emotions, a design framework with heterogeneous LLM agents is proposed. The framework instantiates specialized agents using prior domain knowledge of the types of FSA errors and reasons on the aggregated agent discussions. Comprehensive evaluation on FSA datasets show that the framework yields better accuracies, especially when the discussions are substantial. This study contributes to the design foundations and paves new avenues for LLMs-based FSA. Implications on business and management are also discussed.",
    "pdf_link": "https://arxiv.org/abs/2401.05799",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2401.05799v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2401.05799/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2401.05799v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2401.05799/emotion.png"
      },
      {
        "url": "https://arxiv.org/html/2401.05799v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2401.05799/x2.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）彻底颠覆了智能系统设计的常规路径，将关注点从海量数据收集和模型训练转移到了与人类价值观的契合以及如何充分挖掘现有预训练模型的潜力上。但在金融情感分析（FSA）领域，这一变革尚未完全落地，主要原因在于FSA任务的独特性和在此类情境下应用生成模型的指导性知识尚不明确。本研究探讨了不经微调直接使用LLMs进行FSA的新范式的有效性。研究基于明斯基的心智与情感理论，提出了一个包含多种LLM代理的设计框架。该框架利用对FSA错误类型的先验知识，创建专业代理，并对代理间的讨论进行综合分析。通过在FSA数据集上的全面评估，证实了该框架尤其在讨论深入时能显著提高准确率。本研究不仅为LLMs在FSA领域的应用奠定了设计基础，也为未来的探索开辟了新路。同时，研究还探讨了其对商业和管理模式的潜在影响。",
    "title_cn": "本文旨在探讨如何设计多样化的大型语言模型代理，以提升金融情绪分析的准确性和效率。",
    "tags": [
      "分类：LLM应用",
      "",
      "情感分析"
    ]
  },
  {
    "title": "KwaiAgents: Generalized Information-seeking Agent System with Large Language Models",
    "submit_datetime": "2024年01月10日",
    "abstract": "Driven by curiosity, humans have continually sought to explore and understand the world around them, leading to the invention of various tools to satiate this inquisitiveness. Despite not having the capacity to process and memorize vast amounts of information in their brains, humans excel in critical thinking, planning, reflection, and harnessing available tools to interact with and interpret the world, enabling them to find answers efficiently. The recent advancements in large language models (LLMs) suggest that machines might also possess the aforementioned human-like capabilities, allowing them to exhibit powerful abilities even with a constrained parameter count. In this paper, we introduce KwaiAgents, a generalized information-seeking agent system based on LLMs. Within KwaiAgents, we propose an agent system that employs LLMs as its cognitive core, which is capable of understanding a user's query, behavior guidelines, and referencing external documents. The agent can also update and retrieve information from its internal memory, plan and execute actions using a time-aware search-browse toolkit, and ultimately provide a comprehensive response. We further investigate the system's performance when powered by LLMs less advanced than GPT-4, and introduce the Meta-Agent Tuning (MAT) framework, designed to ensure even an open-sourced 7B or 13B model performs well among many agent systems. We exploit both benchmark and human evaluations to systematically validate these capabilities. Extensive experiments show the superiority of our agent system compared to other autonomous agents and highlight the enhanced generalized agent-abilities of our fine-tuned LLMs.",
    "pdf_link": "https://arxiv.org/abs/2312.04889",
    "graphs": [],
    "abstract_cn": "人类因好奇心的驱使，不懈地探索和理解周遭世界，发明了众多工具以满足这份求知欲。尽管人脑无法处理和记忆海量信息，人类却在批判性思维、规划、反思和利用工具与世界互动方面表现出色，有效地寻找解答。大型语言模型（LLMs）的进展预示着机器可能也能展现出类似的人类特质，即便参数受限，也能发挥强大功能。本文介绍了KwaiAgents，这是一个基于LLMs构建的通用信息搜寻代理系统。该系统中的代理利用LLMs作为认知核心，不仅能够理解用户查询和行为准则，还能查阅外部文档。代理能够更新和检索内部信息，运用时间感知的搜索浏览工具规划和执行动作，最终提供全面回答。我们还探讨了该系统在搭载低于GPT-4水平的LLMs时的表现，并提出了元代理调整（MAT）框架，旨在让开源的7B或13B模型在众多代理系统中也能表现出色。通过基准测试和人类评估，我们系统地验证了这些能力。广泛的实验显示，我们的代理系统相较于其他自主代理具有优势，并突显了我们精细调整后的LLMs在通用代理能力上的提升。",
    "title_cn": "KwaiAgents：结合大型语言模型的全能信息搜寻代理系统",
    "tags": [
      "Agent",
      "信息检索",
      "人工智能"
    ]
  },
  {
    "title": "Evaluating LLMs on Document-Based QA: Exact Answer Selection and Numerical Extraction using Cogtale dataset",
    "submit_datetime": "2024年01月03日",
    "abstract": "Document-based Question-Answering (QA) tasks are crucial for precise information retrieval. While some existing work focus on evaluating large language models performance on retrieving and answering questions from documents, assessing the LLMs performance on QA types that require exact answer selection from predefined options and numerical extraction is yet to be fully assessed. In this paper, we specifically focus on this underexplored context and conduct empirical analysis of LLMs (GPT-4 and GPT-3.5) on question types, including single-choice, yes-no, multiple-choice, and number extraction questions from documents in zero-shot setting. We use the CogTale dataset for evaluation, which provide human expert-tagged responses, offering a robust benchmark for precision and factual grounding. We found that LLMs, particularly GPT-4, can precisely answer many single-choice and yes-no questions given relevant context, demonstrating their efficacy in information retrieval tasks. However, their performance diminishes when confronted with multiple-choice and number extraction formats, lowering the overall performance of the model on this task, indicating that these models may not yet be sufficiently reliable for the task. This limits the applications of LLMs on applications demanding precise information extraction from documents, such as meta-analysis tasks. These findings hinge on the assumption that the retrievers furnish pertinent context necessary for accurate responses, emphasizing the need for further research. Our work offers a framework for ongoing dataset evaluation, ensuring that LLM applications for information retrieval and document analysis continue to meet evolving standards.",
    "pdf_link": "https://arxiv.org/abs/2311.07878",
    "graphs": [],
    "abstract_cn": "文档型问答任务在精准信息检索中扮演着关键角色。尽管现有研究多聚焦于评估大型语言模型（LLM）在文档问答上的表现，但对于需要从预设选项中精确挑选答案或进行数值抽取的问答类型，LLM的性能尚待全面评估。本文专注于这一未被充分研究的领域，对LLM（包括GPT-4和GPT-3.5）在零样本环境下处理单选、是非、多选和数字抽取等类型问题进行了实证分析。我们采用CogTale数据集作为评估基准，该数据集包含专家标记的答案，为精确度和事实依据提供了坚实的参考。研究发现，特别是GPT-4，在给定相关上下文的情况下，能够准确回答许多单选和是非问题，证明了LLM在信息检索任务上的有效性。然而，面对多选和数字抽取问题时，其性能有所下降，影响了模型在这类任务上的整体表现，暗示这些模型可能尚未足够成熟以胜任此类任务。这限制了LLM在需要精确信息抽取的文档应用场景，如元分析任务中的使用。研究结果强调了检索器提供准确响应所需相关上下文的重要性，并指出了进一步研究的必要性。我们的研究为持续的数据集评估提供了框架，确保LLM在信息检索和文档分析领域的应用能够不断适应并满足新的标准。",
    "title_cn": "本文探讨了如何利用 Cogtale 数据集对大型语言模型进行基于文档的问答能力的评估，包括精确答案的选择和数值信息的提取。",
    "tags": [
      "LLM应用",
      "信息检索",
      ""
    ]
  },
  {
    "title": "LLM Harmony: Multi-Agent Communication for Problem Solving",
    "submit_datetime": "2024年01月02日",
    "abstract": "Large Language Models (LLMs) have revolutionized Natural Language Processing but exhibit limitations, particularly in autonomously addressing novel challenges such as reasoning and problem-solving. Traditional techniques like chain-of-thought prompting necessitate explicit human guidance. This paper introduces a novel multi-agent communication framework, inspired by the CAMEL model, to enhance LLMs' autonomous problem-solving capabilities. The framework employs multiple LLM agents, each with a distinct persona, engaged in role-playing communication, offering a nuanced and adaptable approach to diverse problem scenarios. Extensive experimentation demonstrates the framework's superior performance and adaptability, providing valuable insights into the collaborative potential of multiple agents in overcoming the limitations of individual models.",
    "pdf_link": "https://arxiv.org/abs/2401.01312",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）引领了自然语言处理的革新，但在独立应对如推理和问题解决等新挑战时仍有不足。传统方法，例如思维链提示，往往需要人为明确引导。本文提出了一个受CAMEL模型启发的创新多代理通信框架，旨在提升LLMs的自主问题解决技能。该框架通过多个具有独特角色的LLM代理进行角色扮演式交流，为多样的问题情境提供了一种细致且灵活的解决方案。广泛的实验验证了框架的卓越性能和适应性，揭示了多代理协作在突破单一模型局限方面的潜力。",
    "title_cn": "LLM Harmony：协同多代理通信，助力问题解决",
    "tags": [
      "Agent",
      "",
      "人工智能"
    ]
  },
  {
    "title": "The Cambridge Law Corpus: A Dataset for Legal AI Research",
    "submit_datetime": "2024年01月01日",
    "abstract": "We introduce the Cambridge Law Corpus (CLC), a dataset for legal AI research. It consists of over 250 000 court cases from the UK. Most cases are from the 21st century, but the corpus includes cases as old as the 16th century. This paper presents the first release of the corpus, containing the raw text and meta-data. Together with the corpus, we provide annotations on case outcomes for 638 cases, done by legal experts. Using our annotated data, we have trained and evaluated case outcome extraction with GPT-3, GPT-4 and RoBERTa models to provide benchmarks. We include an extensive legal and ethical discussion to address the potentially sensitive nature of this material. As a consequence, the corpus will only be released for research purposes under certain restrictions.",
    "pdf_link": "https://arxiv.org/abs/2309.12269",
    "graphs": [],
    "abstract_cn": "本文向您呈现剑桥法律语料库（CLC），这是一个专为法律AI研究设计的数据集，涵盖了英国超过25万个法庭案例，时间跨度从16世纪至21世纪。首次发布的语料库包含了案例的原始文本与元数据，并且我们提供了638个案例的判决结果注释，这些注释是由法律专家完成的。基于这些注释，我们训练并测试了GPT-3、GPT-4和RoBERTa模型，以进行案例结果提取，并设立了性能基准。鉴于材料的敏感性，我们还展开了深入的法律与伦理讨论。因此，该语料库将仅在特定条件下，为研究目的提供。",
    "title_cn": "剑桥法律语料库：为法律AI研究提供的数据集。",
    "tags": [
      "LLM应用",
      "",
      "人工智能"
    ]
  },
  {
    "title": "From system models to class models: An in-context learning paradigm",
    "submit_datetime": "2023年12月20日",
    "abstract": "Is it possible to understand the intricacies of a dynamical system not solely from its input/output pattern, but also by observing the behavior of other systems within the same class? This central question drives the study presented in this paper.\n  In response to this query, we introduce a novel paradigm for system identification, addressing two primary tasks: one-step-ahead prediction and multi-step simulation. Unlike conventional methods, we do not directly estimate a model for the specific system. Instead, we learn a meta model that represents a class of dynamical systems. This meta model is trained on a potentially infinite stream of synthetic data, generated by simulators whose settings are randomly extracted from a probability distribution. When provided with a context from a new system-specifically, an input/output sequence-the meta model implicitly discerns its dynamics, enabling predictions of its behavior.\n  The proposed approach harnesses the power of Transformers, renowned for their \\emph{in-context learning} capabilities. For one-step prediction, a GPT-like decoder-only architecture is utilized, whereas the simulation problem employs an encoder-decoder structure. Initial experimental results affirmatively answer our foundational question, opening doors to fresh research avenues in system identification.",
    "pdf_link": "https://arxiv.org/abs/2308.13380",
    "graphs": [],
    "abstract_cn": "能否通过观察同类系统中其他系统的行为，而不仅仅是输入/输出模式，来洞悉一个动态系统的奥妙？本论文的研究正是基于这一核心问题。为解答此问，我们提出了一种创新的系统识别新范式，旨在解决一步预测和多步模拟两大核心任务。与传统方法不同，我们不直接对特定系统建模，而是构建一个能够代表一类动态系统的元模型。该元模型通过从概率分布中随机抽取设置的模拟器生成的无限合成数据流进行训练。当输入新系统的上下文，例如输入/输出序列时，元模型能够隐式识别其动态特性，实现对其行为的预测。本方法借助了变换器的“上下文学习”能力，一步预测采用了类似 GPT 的仅解码器架构，而多步模拟则使用了编码器-解码器结构。初步的实验结果积极地回应了我们的基本问题，为系统识别研究开辟了新的路径。",
    "title_cn": "探索系统模型至类别模型的转变：在上下文中学习的新模式",
    "tags": [
      "LLM理论",
      "动态系统",
      "人工智能"
    ]
  },
  {
    "title": "Large Language Models Play StarCraft II: Benchmarks and A Chain of Summarization Approach",
    "submit_datetime": "2023年12月19日",
    "abstract": "StarCraft II is a challenging benchmark for AI agents due to the necessity of both precise micro level operations and strategic macro awareness. Previous works, such as Alphastar and SCC, achieve impressive performance on tackling StarCraft II , however, still exhibit deficiencies in long term strategic planning and strategy interpretability. Emerging large language model (LLM) agents, such as Voyage and MetaGPT, presents the immense potential in solving intricate tasks. Motivated by this, we aim to validate the capabilities of LLMs on StarCraft II, a highly complex RTS game.To conveniently take full advantage of LLMs` reasoning abilities, we first develop textual StratCraft II environment, called TextStarCraft II, which LLM agent can interact. Secondly, we propose a Chain of Summarization method, including single frame summarization for processing raw observations and multi frame summarization for analyzing game information, providing command recommendations, and generating strategic decisions. Our experiment consists of two parts: first, an evaluation by human experts, which includes assessing the LLMs`s mastery of StarCraft II knowledge and the performance of LLM agents in the game; second, the in game performance of LLM agents, encompassing aspects like win rate and the impact of Chain of Summarization.Experiment results demonstrate that: 1. LLMs possess the relevant knowledge and complex planning abilities needed to address StarCraft II scenarios; 2. Human experts consider the performance of LLM agents to be close to that of an average player who has played StarCraft II for eight years; 3. LLM agents are capable of defeating the built in AI at the Harder(Lv5) difficulty level. We have open sourced the code and released demo videos of LLM agent playing StarCraft II.",
    "pdf_link": "https://arxiv.org/abs/2312.11865",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2312.11865v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.11865/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2312.11865v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.11865/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2312.11865v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.11865/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2312.11865v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.11865/x4.png"
      },
      {
        "url": "https://arxiv.org/html/2312.11865v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.11865/x5.png"
      },
      {
        "url": "https://arxiv.org/html/2312.11865v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.11865/x6.png"
      },
      {
        "url": "https://arxiv.org/html/2312.11865v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.11865/x7.png"
      },
      {
        "url": "https://arxiv.org/html/2312.11865v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.11865/x8.png"
      },
      {
        "url": "https://arxiv.org/html/2312.11865v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.11865/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2312.11865v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.11865/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2312.11865v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.11865/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2312.11865v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.11865/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2312.11865v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.11865/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2312.11865v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.11865/x14.png"
      },
      {
        "url": "https://arxiv.org/html/2312.11865v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.11865/x15.png"
      },
      {
        "url": "https://arxiv.org/html/2312.11865v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.11865/x16.png"
      },
      {
        "url": "https://arxiv.org/html/2312.11865v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.11865/x17.png"
      },
      {
        "url": "https://arxiv.org/html/2312.11865v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.11865/x18.png"
      },
      {
        "url": "https://arxiv.org/html/2312.11865v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.11865/x19.png"
      },
      {
        "url": "https://arxiv.org/html/2312.11865v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.11865/x20.png"
      },
      {
        "url": "https://arxiv.org/html/2312.11865v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.11865/x21.png"
      },
      {
        "url": "https://arxiv.org/html/2312.11865v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.11865/x22.png"
      },
      {
        "url": "https://arxiv.org/html/2312.11865v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.11865/x23.png"
      },
      {
        "url": "https://arxiv.org/html/2312.11865v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.11865/x24.png"
      },
      {
        "url": "https://arxiv.org/html/2312.11865v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.11865/x25.png"
      },
      {
        "url": "https://arxiv.org/html/2312.11865v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.11865/x26.png"
      },
      {
        "url": "https://arxiv.org/html/2312.11865v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.11865/x27.png"
      },
      {
        "url": "https://arxiv.org/html/2312.11865v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.11865/x28.png"
      },
      {
        "url": "https://arxiv.org/html/2312.11865v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.11865/x29.png"
      },
      {
        "url": "https://arxiv.org/html/2312.11865v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.11865/x30.png"
      },
      {
        "url": "https://arxiv.org/html/2312.11865v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.11865/x31.png"
      },
      {
        "url": "https://arxiv.org/html/2312.11865v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.11865/x32.png"
      },
      {
        "url": "https://arxiv.org/html/2312.11865v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.11865/x33.png"
      },
      {
        "url": "https://arxiv.org/html/2312.11865v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.11865/x34.png"
      },
      {
        "url": "https://arxiv.org/html/2312.11865v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.11865/x35.png"
      },
      {
        "url": "https://arxiv.org/html/2312.11865v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.11865/x36.png"
      },
      {
        "url": "https://arxiv.org/html/2312.11865v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.11865/x37.png"
      },
      {
        "url": "https://arxiv.org/html/2312.11865v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.11865/x38.png"
      },
      {
        "url": "https://arxiv.org/html/2312.11865v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.11865/x39.png"
      },
      {
        "url": "https://arxiv.org/html/2312.11865v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.11865/x40.png"
      },
      {
        "url": "https://arxiv.org/html/2312.11865v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.11865/x41.png"
      },
      {
        "url": "https://arxiv.org/html/2312.11865v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.11865/x42.png"
      },
      {
        "url": "https://arxiv.org/html/2312.11865v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.11865/x43.png"
      },
      {
        "url": "https://arxiv.org/html/2312.11865v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.11865/x44.png"
      },
      {
        "url": "https://arxiv.org/html/2312.11865v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.11865/x45.png"
      }
    ],
    "abstract_cn": "星际争霸II因其对微操作和宏观战略的双重要求，成为AI代理的严峻考验。尽管Alphastar和SCC等先驱在星际争霸II上取得了显著成就，但它们在长期战略规划和策略透明度方面仍有欠缺。大型语言模型（LLM）如Voyage和MetaGPT的出现，为解决复杂问题带来了新的希望。基于此，我们探索LLM在星际争霸II这一复杂RTS游戏中的潜力。我们首先创建了TextStarCraft II，一个文本化的游戏环境，以便LLM代理能够发挥其推理能力。接着，我们提出了链式总结方法，通过单帧总结处理观察，多帧总结分析信息、提出建议并制定战略。实验分为两部分：人类专家评估LLM的知识掌握和游戏表现，以及LLM代理的游戏胜率和链式总结的影响。结果显示：LLM具备应对星际争霸II挑战的知识和规划能力；专家认为LLM代理接近八年经验的玩家水平；LLM代理能在Harder难度下战胜内置AI。我们已公开代码，并分享了LLM代理的游戏演示。",
    "title_cn": "大型语言模型在星际争霸II中的应用：基准测试与摘要链策略探索在翻译过程中，我首先确保原文的核心内容被准确传达，即大型语言模型在星际争霸II游戏中的应用，以及相关的基准测试和一种称为“摘要链”的方法。在第二步中，我调整了语言风格，使其更加符合中文的表达习惯，同时保持了原文的生动性和简洁性。通过使用“应用”、“探索”等词汇，增强了文章的吸引力和可读性。",
    "tags": [
      "Agent\n\n这篇论文探讨了大型语言模型（LLM）在星际争霸II这一复杂实时战略游戏（RTS）中的应用，特别是如何利用LLM的推理能力来提高AI代理的游戏表现。论文提出了一个文本化的游戏环境TextStarCraft II，并介绍了链式总结方法来处理游戏观察和制定战略。实验结果表明，LLM代理具备应对游戏挑战的能力，并且能够接近人类玩家的水平。因此，这篇论文属于Agent分类，因为它专注于开发和评估一个特定任务（星际争霸II游戏）中的AI代理。",
      "电子竞技",
      "人工智能"
    ]
  },
  {
    "title": "LLaMAntino: LLaMA 2 Models for Effective Text Generation in Italian Language",
    "submit_datetime": "2023年12月15日",
    "abstract": "Large Language Models represent state-of-the-art linguistic models designed to equip computers with the ability to comprehend natural language. With its exceptional capacity to capture complex contextual relationships, the LLaMA (Large Language Model Meta AI) family represents a novel advancement in the field of natural language processing by releasing foundational models designed to improve the natural language understanding abilities of the transformer architecture thanks to their large amount of trainable parameters (7, 13, and 70 billion parameters). In many natural language understanding tasks, these models obtain the same performances as private company models such as OpenAI Chat-GPT with the advantage to make publicly available weights and code for research and commercial uses. In this work, we investigate the possibility of Language Adaptation for LLaMA models, explicitly focusing on addressing the challenge of Italian Language coverage. Adopting an open science approach, we explore various tuning approaches to ensure a high-quality text generated in Italian suitable for common tasks in this underrepresented language in the original models' datasets. We aim to release effective text generation models with strong linguistic properties for many tasks that seem challenging using multilingual or general-purpose LLMs. By leveraging an open science philosophy, this study contributes to Language Adaptation strategies for the Italian language by introducing the novel LLaMAntino family of Italian LLMs.",
    "pdf_link": "https://arxiv.org/abs/2312.09993",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2312.09993v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.09993/SFT.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLM）是当前语言模型的前沿，它们旨在让计算机掌握自然语言的理解。LLaMA系列以其出色的上下文关系捕捉能力，通过推出基于大量可训练参数（7亿、13亿和70亿参数）的基础模型，为自然语言处理领域带来了创新，显著提升了变换器架构的自然语言理解性能。这些模型在多种自然语言理解任务上的表现与OpenAI Chat-GPT等私营公司的模型不相上下，并且具有公开权重和代码的优势，便于研究和商业使用。本研究专注于LLaMA模型对意大利语的适应性，旨在解决这一语言在原始模型数据集中代表性不足的问题。我们采用开放科学的策略，尝试多种调优方法，以生成适合意大利语的高质量文本，满足这一语言在常见任务中的需求。我们致力于推出具有强大语言特性的文本生成模型，以应对使用多语言或通用LLM时面临的挑战。本研究通过引入LLaMAntino家族——一系列新型的意大利语LLM，为意大利语的语言适应提供了新的策略，进一步推动了开放科学在语言适应领域的贡献。",
    "title_cn": "LLaMAntino：LLaMA 2 模型，专为意大利语高效文本生成而设计。",
    "tags": [
      "LLM应用",
      "",
      "语言模型"
    ]
  },
  {
    "title": "Nash Learning from Human Feedback",
    "submit_datetime": "2023年12月06日",
    "abstract": "Reinforcement learning from human feedback (RLHF) has emerged as the main paradigm for aligning large language models (LLMs) with human preferences. Typically, RLHF involves the initial step of learning a reward model from human feedback, often expressed as preferences between pairs of text generations produced by a pre-trained LLM. Subsequently, the LLM's policy is fine-tuned by optimizing it to maximize the reward model through a reinforcement learning algorithm. However, an inherent limitation of current reward models is their inability to fully represent the richness of human preferences and their dependency on the sampling distribution.\n  In this study, we introduce an alternative pipeline for the fine-tuning of LLMs using pairwise human feedback. Our approach entails the initial learning of a preference model, which is conditioned on two inputs given a prompt, followed by the pursuit of a policy that consistently generates responses preferred over those generated by any competing policy, thus defining the Nash equilibrium of this preference model. We term this approach Nash learning from human feedback (NLHF).\n  In the context of a tabular policy representation, we present a novel algorithmic solution, Nash-MD, founded on the principles of mirror descent. This algorithm produces a sequence of policies, with the last iteration converging to the regularized Nash equilibrium. Additionally, we explore parametric representations of policies and introduce gradient descent algorithms for deep-learning architectures. To demonstrate the effectiveness of our approach, we present experimental results involving the fine-tuning of a LLM for a text summarization task. We believe NLHF offers a compelling avenue for preference learning and policy optimization with the potential of advancing the field of aligning LLMs with human preferences.",
    "pdf_link": "https://arxiv.org/abs/2312.00886",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2312.00886v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.00886/TrainPreference.png"
      },
      {
        "url": "https://arxiv.org/html/2312.00886v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.00886/EvalPreference.png"
      },
      {
        "url": "https://arxiv.org/html/2312.00886v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.00886/TrainReward.png"
      },
      {
        "url": "https://arxiv.org/html/2312.00886v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2312.00886/EvalReward.png"
      }
    ],
    "abstract_cn": "人类反馈驱动的强化学习（RLHF）正成为调整大型语言模型（LLM）以符合人类偏好的主要方法。这种方法首先从人类反馈中学习奖励模型，然后通过强化学习算法优化LLM策略，以最大化奖励。但现有奖励模型难以全面捕捉人类偏好的多样性和对样本分布的依赖。本研究提出了一种新颖的LLM微调流程，利用成对的人类反馈。该流程首先学习一个基于提示的两个输入条件的偏好模型，然后制定一个策略，该策略生成的响应总是比竞争对手的策略更受青睐，形成偏好模型的纳什均衡。我们将此方法命名为纳什学习人类反馈（NLHF）。在表格策略表示的框架下，我们提出了一种基于镜像下降原理的新算法——Nash-MD。该算法生成一系列策略，最终迭代达到规范化的纳什均衡。我们还探讨了策略的参数化表示，并为深度学习架构引入了梯度下降算法。通过在LLM的文本摘要任务微调中展示实验结果，我们证明了该方法的有效性。我们相信NLHF为学习偏好和优化策略提供了一个有前景的方向，有助于推动LLM与人类偏好对齐的研究领域。",
    "title_cn": "纳什学习：汲取人类反馈的精髓",
    "tags": [
      "LLM应用",
      "人工智能",
      ""
    ]
  },
  {
    "title": "A Survey on Large Language Models for Personalized and Explainable Recommendations",
    "submit_datetime": "2023年11月20日",
    "abstract": "In recent years, Recommender Systems(RS) have witnessed a transformative shift with the advent of Large Language Models(LLMs) in the field of Natural Language Processing(NLP). These models such as OpenAI's GPT-3.5/4, Llama from Meta, have demonstrated unprecedented capabilities in understanding and generating human-like text. This has led to a paradigm shift in the realm of personalized and explainable recommendations, as LLMs offer a versatile toolset for processing vast amounts of textual data to enhance user experiences. To provide a comprehensive understanding of the existing LLM-based recommendation systems, this survey aims to analyze how RS can benefit from LLM-based methodologies. Furthermore, we describe major challenges in Personalized Explanation Generating(PEG) tasks, which are cold-start problems, unfairness and bias problems in RS.",
    "pdf_link": "https://arxiv.org/abs/2311.12338",
    "graphs": [],
    "abstract_cn": "近年来，自然语言处理（NLP）领域的大型语言模型（LLM）为推荐系统（RS）带来了革命性的变化。以OpenAI的GPT-3.5/4和Meta的Llama为代表的这些模型，在理解和创造类人文本方面展现了惊人的能力，引发了个性化和可解释推荐领域的新浪潮。本篇综述旨在深入探讨基于LLM的推荐系统如何助力RS，以及如何利用这些强大的文本处理工具来提升用户体验。同时，我们也详细讨论了个性化解释生成（PEG）任务面临的主要挑战，包括RS中的冷启动难题、以及不公平和偏见问题。",
    "title_cn": "本文综述了用于个性化和可解释推荐的各类大型语言模型。",
    "tags": [
      "分类：LLM应用\n\n这篇论文摘要讨论了大型语言模型（LLM）在自然语言处理（NLP）领域的应用，特别是在推荐系统（RS）中的应用。它提到了这些模型在理解和创造类人文本方面的能力，以及它们如何助力个性化和可解释推荐领域的发展。此外，论文还讨论了个性化解释生成（PEG）任务面临的挑战，如冷启动问题、不公平和偏见问题。这些内容都与LLM在实际应用中的使用有关，因此将其归类为LLM应用。",
      "推荐系统",
      ""
    ]
  },
  {
    "title": "UnifiedVisionGPT: Streamlining Vision-Oriented AI through Generalized Multimodal Framework",
    "submit_datetime": "2023年11月16日",
    "abstract": "In the current landscape of artificial intelligence, foundation models serve as the bedrock for advancements in both language and vision domains. OpenAI GPT-4 has emerged as the pinnacle in large language models (LLMs), while the computer vision (CV) domain boasts a plethora of state-of-the-art (SOTA) models such as Meta's SAM and DINO, and YOLOS. However, the financial and computational burdens of training new models from scratch remain a significant barrier to progress. In response to this challenge, we introduce UnifiedVisionGPT, a novel framework designed to consolidate and automate the integration of SOTA vision models, thereby facilitating the development of vision-oriented AI. UnifiedVisionGPT distinguishes itself through four key features: (1) provides a versatile multimodal framework adaptable to a wide range of applications, building upon the strengths of multimodal foundation models; (2) seamlessly integrates various SOTA vision models to create a comprehensive multimodal platform, capitalizing on the best components of each model; (3) prioritizes vision-oriented AI, ensuring a more rapid progression in the CV domain compared to the current trajectory of LLMs; and (4) introduces automation in the selection of SOTA vision models, generating optimal results based on diverse multimodal inputs such as text prompts and images. This paper outlines the architecture and capabilities of UnifiedVisionGPT, demonstrating its potential to revolutionize the field of computer vision through enhanced efficiency, versatility, generalization, and performance. Our implementation, along with the unified multimodal framework and comprehensive dataset, is made publicly available at https://github.com/LHBuilder/SA-Segment-Anything.",
    "pdf_link": "https://arxiv.org/abs/2311.10125",
    "graphs": [],
    "abstract_cn": "在当今人工智能的版图中，基础模型是推动语言和视觉技术发展的核心。OpenAI GPT-4 已在大型语言模型（LLMs）中独占鳌头，而计算机视觉（CV）领域则有 Meta 的 SAM、DINO 和 YOLOS 等众多前沿模型。尽管如此，从头开始训练新模型所需的财务和计算成本仍是技术进步的一大障碍。为解决这一难题，我们推出了 UnifiedVisionGPT，这是一个创新框架，旨在整合并自动化集成顶尖视觉模型，以加速视觉导向的人工智能开发。UnifiedVisionGPT 以其四项核心优势而著称：（1）构建于多模态基础模型之上，提供灵活的多模态框架，适用于多种应用场景；（2）无缝融合多种前沿视觉模型，打造全面的多模态平台，汇聚各个模型的精华；（3）专注于视觉人工智能，力求在 CV 领域实现超越现有 LLMs 发展轨迹的快速进步；（4）引入自动化选择前沿视觉模型，根据不同的多模态输入如文本和图像，产生最佳结果。本文详细介绍了 UnifiedVisionGPT 的架构和功能，证明了它在提升计算机视觉领域的效率、多样性、泛化能力和性能方面的革命性潜力。我们的实现，包括统一的多模态框架和全面的数据集，已在 https://github.com/LHBuilder/SA-Segment-Anything 向公众开放。",
    "title_cn": "UnifiedVisionGPT：采用广义多模态框架，优化视觉导向的人工智能流程",
    "tags": [
      "LLM应用",
      "计算机视觉",
      "人工智能"
    ]
  },
  {
    "title": "A Simple yet Efficient Ensemble Approach for AI-generated Text Detection",
    "submit_datetime": "2023年11月07日",
    "abstract": "Recent Large Language Models (LLMs) have demonstrated remarkable capabilities in generating text that closely resembles human writing across wide range of styles and genres. However, such capabilities are prone to potential abuse, such as fake news generation, spam email creation, and misuse in academic assignments. Hence, it is essential to build automated approaches capable of distinguishing between artificially generated text and human-authored text. In this paper, we propose a simple yet efficient solution to this problem by ensembling predictions from multiple constituent LLMs. Compared to previous state-of-the-art approaches, which are perplexity-based or uses ensembles with a number of LLMs, our condensed ensembling approach uses only two constituent LLMs to achieve comparable performance. Experiments conducted on four benchmark datasets for generative text classification show performance improvements in the range of 0.5 to 100\\% compared to previous state-of-the-art approaches. We also study the influence that the training data from individual LLMs have on model performance. We found that substituting commercially-restrictive Generative Pre-trained Transformer (GPT) data with data generated from other open language models such as Falcon, Large Language Model Meta AI (LLaMA2), and Mosaic Pretrained Transformers (MPT) is a feasible alternative when developing generative text detectors. Furthermore, to demonstrate zero-shot generalization, we experimented with an English essays dataset, and results suggest that our ensembling approach can handle new data effectively.",
    "pdf_link": "https://arxiv.org/abs/2311.03084",
    "graphs": [],
    "abstract_cn": "近期的大型语言模型（LLMs）在模仿多种风格和类型的人类写作方面展现出了卓越的文本生成能力。然而，这种能力也容易被滥用，比如制造假新闻、垃圾邮件的编写，以及在学术作业中的不恰当使用。因此，开发能够辨别人工生成文本与人类创作文本的自动化工具显得尤为重要。本文提出了一种简洁高效的解决方案，即通过整合多个子LLMs的预测结果。相较于之前基于困惑度或多模型集成的方法，我们的精简集成方法仅用两个子LLMs就实现了相当的性能。在四个文本生成分类的基准数据集上的实验表明，与先前最先进方法相比，我们的性能提升了0.5%至100%。我们还探讨了不同LLMs的训练数据对模型性能的影响，并发现使用Falcon、LLaMA2、MPT等开放语言模型生成的数据替代商业限制的GPT数据是一个可行的方案。此外，为了验证零样本泛化能力，我们在英语论文数据集上进行了测试，结果表明我们的集成方法能够有效处理新数据。",
    "title_cn": "一种简洁高效的集成策略，用于辨识 AI 创作的文本",
    "tags": [
      "LLM应用",
      "文本生成",
      "内容识别"
    ]
  },
  {
    "title": "MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework",
    "submit_datetime": "2023年11月06日",
    "abstract": "Remarkable progress has been made on automated problem solving through societies of agents based on large language models (LLMs). Existing LLM-based multi-agent systems can already solve simple dialogue tasks. Solutions to more complex tasks, however, are complicated through logic inconsistencies due to cascading hallucinations caused by naively chaining LLMs. Here we introduce MetaGPT, an innovative meta-programming framework incorporating efficient human workflows into LLM-based multi-agent collaborations. MetaGPT encodes Standardized Operating Procedures (SOPs) into prompt sequences for more streamlined workflows, thus allowing agents with human-like domain expertise to verify intermediate results and reduce errors. MetaGPT utilizes an assembly line paradigm to assign diverse roles to various agents, efficiently breaking down complex tasks into subtasks involving many agents working together. On collaborative software engineering benchmarks, MetaGPT generates more coherent solutions than previous chat-based multi-agent systems. Our project can be found at https://github.com/geekan/MetaGPT",
    "pdf_link": "https://arxiv.org/abs/2308.00352",
    "graphs": [],
    "abstract_cn": "基于大型语言模型的代理社会在自动问题解决领域取得了显著进步，但面对复杂任务时，由于幻觉连锁导致的逻辑不一致，解决方案变得复杂。为此，我们推出了MetaGPT，一种创新的元编程框架，它将人类工作流程的高效性融入到多代理协作中。MetaGPT通过将标准化操作程序编码为提示序列，优化了工作流程，使得具备人类领域专业知识的代理能够验证中间结果，减少错误。采用装配线模式，MetaGPT为不同代理分配特定角色，将复杂任务分解为多个子任务，促进多代理协同工作。在协作软件工程的测试中，MetaGPT展现出了比以往基于聊天的多代理系统更为连贯的解决方案。欲了解更多信息，请访问我们的GitHub项目页面：https://github.com/geekan/MetaGPT。",
    "title_cn": "MetaGPT：多代理协作框架的元编程之光在人工智能的星辰大海中，MetaGPT如同一颗璀璨的星辰，以其独特的元编程技术，为多代理协作框架注入了新的活力。它不仅仅是一个编程工具，更是一个智慧的交汇点，让不同的代理能够协同工作，共同编织出复杂而精妙的解决方案。MetaGPT的出现，预示着智能系统合作的新纪元，它将引领我们探索更加广阔的智能协作领域。",
    "tags": [
      "Agent",
      "软件工程",
      "多代理系统"
    ]
  },
  {
    "title": "Avalon's Game of Thoughts: Battle Against Deception through Recursive Contemplation",
    "submit_datetime": "2023年10月24日",
    "abstract": "Recent breakthroughs in large language models (LLMs) have brought remarkable success in the field of LLM-as-Agent. Nevertheless, a prevalent assumption is that the information processed by LLMs is consistently honest, neglecting the pervasive deceptive or misleading information in human society and AI-generated content. This oversight makes LLMs susceptible to malicious manipulations, potentially resulting in detrimental outcomes. This study utilizes the intricate Avalon game as a testbed to explore LLMs' potential in deceptive environments. Avalon, full of misinformation and requiring sophisticated logic, manifests as a \"Game-of-Thoughts\". Inspired by the efficacy of humans' recursive thinking and perspective-taking in the Avalon game, we introduce a novel framework, Recursive Contemplation (ReCon), to enhance LLMs' ability to identify and counteract deceptive information. ReCon combines formulation and refinement contemplation processes; formulation contemplation produces initial thoughts and speech, while refinement contemplation further polishes them. Additionally, we incorporate first-order and second-order perspective transitions into these processes respectively. Specifically, the first-order allows an LLM agent to infer others' mental states, and the second-order involves understanding how others perceive the agent's mental state. After integrating ReCon with different LLMs, extensive experiment results from the Avalon game indicate its efficacy in aiding LLMs to discern and maneuver around deceptive information without extra fine-tuning and data. Finally, we offer a possible explanation for the efficacy of ReCon and explore the current limitations of LLMs in terms of safety, reasoning, speaking style, and format, potentially furnishing insights for subsequent research.",
    "pdf_link": "https://arxiv.org/abs/2310.01320",
    "graphs": [],
    "abstract_cn": "最新的大型语言模型（LLMs）在“LLM作为代理”的研究领域取得了巨大进展。但普遍存在一个假设，即LLMs处理的信息总是真实可信的，这忽略了人类社会和人工智能生成内容中普遍存在的欺诈和误导信息。这种疏忽使得LLMs容易受到恶意操控，可能会产生不良后果。本研究以复杂的阿瓦隆游戏为实验平台，探究LLMs在充满欺骗的环境中的表现。阿瓦隆游戏充满虚假信息，需要玩家运用复杂的逻辑，是一场名副其实的“思维游戏”。受人类玩家在游戏中展现的递归思维和视角转换能力的启发，我们提出了一种新的框架——递归思考（ReCon），旨在提升LLMs识别和抵御欺骗信息的能力。ReCon融合了构思和精炼两个思考阶段；构思阶段产生初步的想法和表达，而精炼阶段则对这些想法和表达进行进一步的打磨。此外，我们还分别在这两个阶段中融入了一阶和二阶的视角转换。具体而言，一阶视角转换使LLM代理能够推测他人的心理状态，而二阶视角转换则涉及理解他人对代理心理状态的看法。ReCon与不同LLMs结合后，在阿瓦隆游戏中的广泛实验结果显示，它能有效帮助LLMs识别并规避欺骗信息，无需额外的训练或数据。最后，我们对ReCon的有效性提供了可能的解释，并探讨了LLMs在安全性、推理能力、语言风格和格式方面的当前限制，这可能为未来的研究提供了宝贵的洞见。",
    "title_cn": "阿瓦隆的思维之战：借助递归沉思，与欺骗进行较量。",
    "tags": [
      "Agent",
      "人工智能",
      ""
    ]
  },
  {
    "title": "The Foundation Model Transparency Index",
    "submit_datetime": "2023年10月19日",
    "abstract": "Foundation models have rapidly permeated society, catalyzing a wave of generative AI applications spanning enterprise and consumer-facing contexts. While the societal impact of foundation models is growing, transparency is on the decline, mirroring the opacity that has plagued past digital technologies (e.g. social media). Reversing this trend is essential: transparency is a vital precondition for public accountability, scientific innovation, and effective governance. To assess the transparency of the foundation model ecosystem and help improve transparency over time, we introduce the Foundation Model Transparency Index. The Foundation Model Transparency Index specifies 100 fine-grained indicators that comprehensively codify transparency for foundation models, spanning the upstream resources used to build a foundation model (e.g data, labor, compute), details about the model itself (e.g. size, capabilities, risks), and the downstream use (e.g. distribution channels, usage policies, affected geographies). We score 10 major foundation model developers (e.g. OpenAI, Google, Meta) against the 100 indicators to assess their transparency. To facilitate and standardize assessment, we score developers in relation to their practices for their flagship foundation model (e.g. GPT-4 for OpenAI, PaLM 2 for Google, Llama 2 for Meta). We present 10 top-level findings about the foundation model ecosystem: for example, no developer currently discloses significant information about the downstream impact of its flagship model, such as the number of users, affected market sectors, or how users can seek redress for harm. Overall, the Foundation Model Transparency Index establishes the level of transparency today to drive progress on foundation model governance via industry standards and regulatory intervention.",
    "pdf_link": "https://arxiv.org/abs/2310.12941",
    "graphs": [],
    "abstract_cn": "基础模型已经迅速融入社会，引发了一场涵盖企业和消费者领域的生成性人工智能应用的浪潮。随着这些模型的社会影响力日益增强，透明度却在减少，这与过去数字技术（如社交媒体）的不透明性相呼应。要改变这一趋势，透明度是实现公共问责、科学创新和有效治理的关键前提。为此，我们推出了基础模型透明度指数，旨在评估并提升基础模型生态系统的透明度。该指数包含100个精细指标，全面量化了从构建基础模型所使用的资源（如数据、劳动力、计算资源），到模型本身的特性（如规模、功能、风险），再到模型的下游应用（如分发渠道、使用政策、影响地区）的透明度。我们对10家主要的基础模型开发商（如OpenAI、Google、Meta）进行了评估，依据100个指标来衡量他们的透明度。为了便于评估和标准化，我们根据这些开发商对其主要模型（如OpenAI的GPT-4、Google的PaLM 2、Meta的Llama 2）的做法进行评分。我们的研究揭示了关于基础模型生态系统的10个关键发现：例如，目前没有任何开发商公开其主要模型的下游影响的详细信息，包括用户数量、影响的市场领域，或用户如何寻求损害赔偿。总体来看，基础模型透明度指数旨在确立当前的透明度水平，并通过行业标准和监管措施推动基础模型治理的进步。",
    "title_cn": "基础模型透明度指标",
    "tags": [
      "LLM应用",
      "人工智能",
      "社会影响"
    ]
  },
  {
    "title": "Fine-tuning Aligned Language Models Compromises Safety, Even When Users Do Not Intend To!",
    "submit_datetime": "2023年10月05日",
    "abstract": "Optimizing large language models (LLMs) for downstream use cases often involves the customization of pre-trained LLMs through further fine-tuning. Meta's open release of Llama models and OpenAI's APIs for fine-tuning GPT-3.5 Turbo on custom datasets also encourage this practice. But, what are the safety costs associated with such custom fine-tuning? We note that while existing safety alignment infrastructures can restrict harmful behaviors of LLMs at inference time, they do not cover safety risks when fine-tuning privileges are extended to end-users. Our red teaming studies find that the safety alignment of LLMs can be compromised by fine-tuning with only a few adversarially designed training examples. For instance, we jailbreak GPT-3.5 Turbo's safety guardrails by fine-tuning it on only 10 such examples at a cost of less than $0.20 via OpenAI's APIs, making the model responsive to nearly any harmful instructions. Disconcertingly, our research also reveals that, even without malicious intent, simply fine-tuning with benign and commonly used datasets can also inadvertently degrade the safety alignment of LLMs, though to a lesser extent. These findings suggest that fine-tuning aligned LLMs introduces new safety risks that current safety infrastructures fall short of addressing -- even if a model's initial safety alignment is impeccable, it is not necessarily to be maintained after custom fine-tuning. We outline and critically analyze potential mitigations and advocate for further research efforts toward reinforcing safety protocols for the custom fine-tuning of aligned LLMs.",
    "pdf_link": "https://arxiv.org/abs/2310.03693",
    "graphs": [],
    "abstract_cn": "优化大型语言模型（LLMs）以适应特定应用场景，通常需要对这些预训练模型进行定制化微调。Meta的Llama模型发布和OpenAI提供的GPT-3.5 Turbo自定义数据集微调API都在推动这一趋势。然而，这种个性化微调背后的安全代价是什么？现有安全机制虽然能在推理阶段限制模型的不当行为，但一旦将微调权限开放给终端用户，这些机制便无法覆盖相应的安全风险。我们的研究发现，仅需少量针对性设计的训练样本，就足以破坏LLMs的安全校准。例如，我们仅通过10个这样的样本，以不到0.20美元的代价，通过OpenAI的API绕过了GPT-3.5 Turbo的安全限制，使模型能够响应几乎所有有害指令。更令人担忧的是，即便没有恶意，仅使用普通且看似无害的数据集进行微调，也可能无意中削弱模型的安全校准，尽管影响较小。这些发现提示我们，微调过程为LLMs带来了新的安全风险，而现有的安全设施并未能充分应对。即使模型最初的安全校准无可击，定制化微调后也难以保证。我们提出了可能的缓解措施，并对其进行了深入分析，同时呼吁对加强定制微调LLMs的安全协议进行更多研究。",
    "title_cn": "微调对齐的语言模型可能会不安全，哪怕用户并无此意。",
    "tags": [
      "LLM应用",
      "网络安全",
      "人工智能"
    ]
  },
  {
    "title": "An evolutionary model of personality traits related to cooperative behavior using a large language model",
    "submit_datetime": "2023年10月03日",
    "abstract": "This paper aims to shed light on the evolutionary dynamics of diverse and social populations by introducing the rich expressiveness of generative models into the trait expression of social agent-based evolutionary models. Specifically, we focus on the evolution of personality traits in the context of a game-theoretic relationship as a situation in which inter-individual interests exert strong selection pressures. We construct an agent model in which linguistic descriptions of personality traits related to cooperative behavior are used as genes. The deterministic strategies extracted from Large Language Model (LLM) that make behavioral decisions based on these personality traits are used as behavioral traits. The population is evolved according to selection based on average payoff and mutation of genes by asking LLM to slightly modify the parent gene toward cooperative or selfish. Through preliminary experiments and analyses, we clarify that such a model can indeed exhibit the evolution of cooperative behavior based on the diverse and higher-order representation of personality traits. We also observed the repeated intrusion of cooperative and selfish personality traits through changes in the expression of personality traits, and found that the emerging words in the evolved gene well reflected the behavioral tendency of its personality in terms of their semantics.",
    "pdf_link": "https://arxiv.org/abs/2310.05976",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2310.05976v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2310.05976/fig1.png"
      },
      {
        "url": "https://arxiv.org/html/2310.05976v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2310.05976/fig2.png"
      },
      {
        "url": "https://arxiv.org/html/2310.05976v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2310.05976/fig3.png"
      },
      {
        "url": "https://arxiv.org/html/2310.05976v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2310.05976/fig4.png"
      }
    ],
    "abstract_cn": "本文探讨了通过将生成模型的丰富表达力融入社会代理进化模型的性状表达，来揭示多样化和社交种群的进化机制。研究重点放在博弈论关系背景下个性特征的演化，尤其是个体间利益如何产生强烈的选择压力。我们构建了一个代理模型，使用与合作行为相关联的个性特征的语言描述作为基因，而从大型语言模型（LLM）中提取的基于这些个性特征的确定性策略则作为行为特征。种群的演化过程依据平均收益选择和基因突变，LLM被用来轻微调整父基因，以促进合作或自私行为。初步实验和分析表明，该模型能够基于个性特征的多样性和复杂性展现出合作行为的演化。我们还观察到个性特征表达的变化导致了合作与自私特征的反复出现，并且发现进化后的基因中出现的词汇在语义上能够很好地反映其个性的行为倾向。",
    "title_cn": "借助大型语言模型，构建了一个关于与合作行为相关个性特征的进化模型。",
    "tags": [
      "Agent",
      "社会行为学",
      "进化生物学"
    ]
  },
  {
    "title": "Dynamic LLM-Agent Network: An LLM-agent Collaboration Framework with Agent Team Optimization",
    "submit_datetime": "2023年10月03日",
    "abstract": "Large language model (LLM) agents have been shown effective on a wide range of tasks, and by ensembling multiple LLM agents, their performances could be further improved. Existing approaches employ a fixed set of agents to interact with each other in a static architecture, which limits their generalizability to various tasks and requires strong human prior in designing these agents. In this work, we propose to construct a strategic team of agents communicating in a dynamic interaction architecture based on the task query. Specifically, we build a framework named Dynamic LLM-Agent Network ($\\textbf{DyLAN}$) for LLM-agent collaboration on complicated tasks like reasoning and code generation. DyLAN enables agents to interact for multiple rounds in a dynamic architecture with inference-time agent selection and an early-stopping mechanism to improve performance and efficiency. We further design an automatic agent team optimization algorithm based on an unsupervised metric termed $\\textit{Agent Importance Score}$, enabling the selection of best agents based on the contribution each agent makes. Empirically, we demonstrate that DyLAN performs well in both reasoning and code generation tasks with reasonable computational cost. DyLAN achieves 13.0% and 13.3% improvement on MATH and HumanEval, respectively, compared to a single execution on GPT-35-turbo. On specific subjects of MMLU, agent team optimization in DyLAN increases accuracy by up to 25.0%.",
    "pdf_link": "https://arxiv.org/abs/2310.02170",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2310.02170v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2310.02170/overview2.png"
      },
      {
        "url": "https://arxiv.org/html/2310.02170v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2310.02170/x9.png"
      },
      {
        "url": "https://arxiv.org/html/2310.02170v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2310.02170/x10.png"
      },
      {
        "url": "https://arxiv.org/html/2310.02170v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2310.02170/x11.png"
      },
      {
        "url": "https://arxiv.org/html/2310.02170v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2310.02170/x12.png"
      },
      {
        "url": "https://arxiv.org/html/2310.02170v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2310.02170/x13.png"
      },
      {
        "url": "https://arxiv.org/html/2310.02170v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2310.02170/x14.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLM）代理在多样化任务中展现出卓越效能，通过组合多个LLM代理，效能得以进一步提升。然而，现有方法通常采用固定代理集合，在静态架构中进行互动，这不仅限制了任务适应性，也增加了设计时对人类先验知识的依赖。本研究提出了一种基于任务查询的动态交互架构，构建策略性代理团队。我们开发了一个框架——动态LLM代理网络（DyLAN），旨在促进LLM代理在复杂任务如推理和代码生成中的协作。DyLAN允许代理在动态架构中进行多轮互动，并通过推理时的代理选择及早期终止机制，优化了性能与效率。此外，我们设计了一种自动优化算法，通过“代理重要性得分”这一无监督指标，实现最佳代理团队的自动选择。实践证明，DyLAN在推理和代码生成任务上均有出色表现，且计算成本适中。与GPT-35-turbo单次执行相比，DyLAN在MATH和HumanEval任务上分别提升了13.0%和13.3%的效能。特别地，在MMLU的特定领域，DyLAN的代理团队优化将准确率提升了最多25.0%。",
    "title_cn": "动态大型语言模型代理网络（Dynamic LLM-Agent Network）：构建了一个大型语言模型与代理之间的协作框架，并通过优化代理团队来提升整体性能。",
    "tags": [
      "Agent",
      "人工智能",
      ""
    ]
  },
  {
    "title": "AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation",
    "submit_datetime": "2023年10月03日",
    "abstract": "AutoGen is an open-source framework that allows developers to build LLM applications via multiple agents that can converse with each other to accomplish tasks. AutoGen agents are customizable, conversable, and can operate in various modes that employ combinations of LLMs, human inputs, and tools. Using AutoGen, developers can also flexibly define agent interaction behaviors. Both natural language and computer code can be used to program flexible conversation patterns for different applications. AutoGen serves as a generic infrastructure to build diverse applications of various complexities and LLM capacities. Empirical studies demonstrate the effectiveness of the framework in many example applications, with domains ranging from mathematics, coding, question answering, operations research, online decision-making, entertainment, etc.",
    "pdf_link": "https://arxiv.org/abs/2308.08155",
    "graphs": [],
    "abstract_cn": "AutoGen，这一开源框架，赋予开发者以多代理对话协作之力，构建大型语言模型应用。其代理，既可定制又善对话，游刃于LLM、人类智慧与工具之交融模式。借助AutoGen，开发者得以巧妙定义代理间的互动艺术。自然语言与代码，皆可编织对话之网，适应各类应用之需。AutoGen，如同一座桥梁，连接着复杂多变的应用世界与LLM的无限潜能。实证研究已见证其在数学、编程、问答、运筹、在线决策乃至娱乐等领域的卓越表现。",
    "title_cn": "AutoGen：借助多代理对话，开启大型语言模型应用的新篇章",
    "tags": [
      "Agent\n\n这篇论文摘要描述了一个名为AutoGen的开源框架，它专注于多代理对话协作，用于构建大型语言模型（LLM）应用。这里的“代理”指的是能够与LLM、人类智慧和工具交互的智能实体，它们可以定制并参与对话。AutoGen框架允许开发者定义这些代理之间的交互，无论是通过自然语言还是代码。这种多代理系统的概念与“Agent”分类相符，因为它涉及到了智能代理的设计和应用。此外，论文中提到的实证研究展示了AutoGen在多个领域的应用，这进一步强调了其作为Agent系统在实际应用中的潜力。",
      "人工智能",
      "软件开发"
    ]
  },
  {
    "title": "Generative AI in the Construction Industry: Opportunities & Challenges",
    "submit_datetime": "2023年09月19日",
    "abstract": "In the last decade, despite rapid advancements in artificial intelligence (AI) transforming many industry practices, construction largely lags in adoption. Recently, the emergence and rapid adoption of advanced large language models (LLM) like OpenAI's GPT, Google's PaLM, and Meta's Llama have shown great potential and sparked considerable global interest. However, the current surge lacks a study investigating the opportunities and challenges of implementing Generative AI (GenAI) in the construction sector, creating a critical knowledge gap for researchers and practitioners. This underlines the necessity to explore the prospects and complexities of GenAI integration. Bridging this gap is fundamental to optimizing GenAI's early-stage adoption within the construction sector. Given GenAI's unprecedented capabilities to generate human-like content based on learning from existing content, we reflect on two guiding questions: What will the future bring for GenAI in the construction industry? What are the potential opportunities and challenges in implementing GenAI in the construction industry? This study delves into reflected perception in literature, analyzes the industry perception using programming-based word cloud and frequency analysis, and integrates authors' opinions to answer these questions. This paper recommends a conceptual GenAI implementation framework, provides practical recommendations, summarizes future research questions, and builds foundational literature to foster subsequent research expansion in GenAI within the construction and its allied architecture & engineering domains.",
    "pdf_link": "https://arxiv.org/abs/2310.04427",
    "graphs": [],
    "abstract_cn": "近十年来，尽管人工智能（AI）的迅猛进展已经革新了众多行业，但建筑业的采纳步伐却相对缓慢。最近，诸如 OpenAI 的 GPT、Google 的 PaLM 和 Meta 的 Llama 等高级大型语言模型（LLM）的兴起和快速普及，展现了巨大的潜力，引起了全球的广泛关注。然而，目前对于在建筑业中应用生成性人工智能（GenAI）的机遇与挑战的研究尚显不足，这为学术界和业界留下了一个重要的知识空白。探索 GenAI 融合的可能性和复杂性变得尤为迫切。填补这一空白对于建筑业早期采纳 GenAI 至关重要。鉴于 GenAI 能够基于现有内容学习生成类似人类的文本，我们提出了两个关键问题：GenAI 将如何塑造建筑业的未来？在建筑业中实施 GenAI 存在哪些潜在的机遇与挑战？本研究通过文献回顾、编程生成的词云和频率分析，以及作者的观点，深入分析了这些问题。本文提出了一个概念性的 GenAI 实施框架，给出了实用的建议，概述了未来的研究方向，并为促进 GenAI 在建筑及其相关建筑和工程领域的研究发展奠定了基础。",
    "title_cn": "建筑行业中的生成性人工智能：机遇与挑战并存",
    "tags": [
      "LLM应用",
      "建筑业",
      "人工智能"
    ]
  },
  {
    "title": "Large Language Models as Agents in the Clinic",
    "submit_datetime": "2023年09月19日",
    "abstract": "Recent developments in large language models (LLMs) have unlocked new opportunities for healthcare, from information synthesis to clinical decision support. These new LLMs are not just capable of modeling language, but can also act as intelligent \"agents\" that interact with stakeholders in open-ended conversations and even influence clinical decision-making. Rather than relying on benchmarks that measure a model's ability to process clinical data or answer standardized test questions, LLM agents should be assessed for their performance on real-world clinical tasks. These new evaluation frameworks, which we call \"Artificial-intelligence Structured Clinical Examinations\" (\"AI-SCI\"), can draw from comparable technologies where machines operate with varying degrees of self-governance, such as self-driving cars. High-fidelity simulations may also be used to evaluate interactions between users and LLMs within a clinical workflow, or to model the dynamic interactions of multiple LLMs. Developing these robust, real-world clinical evaluations will be crucial towards deploying LLM agents into healthcare.",
    "pdf_link": "https://arxiv.org/abs/2309.10895",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）的最新进展为医疗保健行业开辟了新的可能，涵盖了从信息整合到辅助临床决策的各个方面。这些先进的LLMs不仅能模拟语言，还能充当智能“代理”，与各方进行开放式交流，甚至参与临床决策过程。评估LLM代理的性能时，应超越传统的基准测试，转而考量其在现实临床任务中的表现。我们提出的“人工智能结构化临床考试”（AI-SCI）评估框架，借鉴了自动驾驶汽车等自主操作技术的评估方法。此外，高保真模拟技术可以用来评价用户与LLMs在临床流程中的互动，或模拟多个LLMs之间的动态交流。构建这些强有力的、符合实际的临床评估体系，对于将LLM代理实际应用于医疗保健领域至关重要。",
    "title_cn": "在医疗领域，大型语言模型正扮演着代理的角色。",
    "tags": [
      "Agent",
      "医疗保健",
      "人工智能"
    ]
  },
  {
    "title": "MindAgent: Emergent Gaming Interaction",
    "submit_datetime": "2023年09月19日",
    "abstract": "Large Language Models (LLMs) have the capacity of performing complex scheduling in a multi-agent system and can coordinate these agents into completing sophisticated tasks that require extensive collaboration. However, despite the introduction of numerous gaming frameworks, the community has insufficient benchmarks towards building general multi-agents collaboration infrastructure that encompass both LLM and human-NPCs collaborations. In this work, we propose a novel infrastructure - MindAgent - to evaluate planning and coordination emergent capabilities for gaming interaction. In particular, our infrastructure leverages existing gaming framework, to i) require understanding of the coordinator for a multi-agent system, ii) collaborate with human players via un-finetuned proper instructions, and iii) establish an in-context learning on few-shot prompt with feedback. Furthermore, we introduce CUISINEWORLD, a new gaming scenario and related benchmark that dispatch a multi-agent collaboration efficiency and supervise multiple agents playing the game simultaneously. We conduct comprehensive evaluations with new auto-metric CoS for calculating the collaboration efficiency. Finally, our infrastructure can be deployed into real-world gaming scenarios in a customized VR version of CUISINEWORLD and adapted in existing broader Minecraft gaming domain. We hope our findings on LLMs and the new infrastructure for general-purpose scheduling and coordination can help shed light on how such skills can be obtained by learning from large language corpora.",
    "pdf_link": "https://arxiv.org/abs/2309.09971",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）展现出在多智能体系统中进行复杂调度的能力，能够协调智能体完成需要密切合作的复杂任务。尽管众多游戏框架相继问世，但社区在构建包含LLM和人类NPC协作的通用多智能体协作基础设施方面，仍缺乏足够的基准。本研究提出了一个创新的基础设施——MindAgent，旨在评估游戏互动中的规划和协调能力。该基础设施特别利用现有游戏框架，实现对多智能体系统协调者的理解，与人类玩家通过未经微调的正确指令进行协作，以及在少量提示和反馈的基础上建立上下文学习。我们还引入了CUISINEWORLD，这是一个新的游戏场景及相关基准，旨在提高多智能体协作效率，并同时监督多个代理的游戏表现。通过新的自动度量标准CoS，我们进行了全面的评估，以计算协作效率。最终，我们的基础设施可以部署到现实世界的游戏场景中，如CUISINEWORLD的定制虚拟现实版本，以及现有的更广泛的Minecraft游戏领域。我们期望，对于LLMs的研究成果以及新的通用调度和协调基础设施，能够为如何通过学习大型语言语料库来掌握这些技能提供洞见。",
    "title_cn": "MindAgent：探索游戏互动的新境界",
    "tags": [
      "Agent",
      "",
      "人工智能"
    ]
  },
  {
    "title": "Large Language Models as Data Preprocessors",
    "submit_datetime": "2023年08月30日",
    "abstract": "Large Language Models (LLMs), typified by OpenAI's GPT series and Meta's LLaMA variants, have marked a significant advancement in artificial intelligence. Trained on vast amounts of text data, LLMs are capable of understanding and generating human-like text across a diverse range of topics. This study expands on the applications of LLMs, exploring their potential in data preprocessing, a critical stage in data mining and analytics applications. We delve into the applicability of state-of-the-art LLMs such as GPT-3.5, GPT-4, and Vicuna-13B for error detection, data imputation, schema matching, and entity matching tasks. Alongside showcasing the inherent capabilities of LLMs, we highlight their limitations, particularly in terms of computational expense and inefficiency. We propose an LLM-based framework for data preprocessing, which integrates cutting-edge prompt engineering techniques, coupled with traditional methods like contextualization and feature selection, to improve the performance and efficiency of these models. The effectiveness of LLMs in data preprocessing is evaluated through an experimental study spanning 12 datasets. GPT-4 emerged as a standout, achieving 100\\% accuracy or F1 score on 4 datasets, suggesting LLMs' immense potential in these tasks. Despite certain limitations, our study underscores the promise of LLMs in this domain and anticipates future developments to overcome current hurdles.",
    "pdf_link": "https://arxiv.org/abs/2308.16361",
    "graphs": [],
    "abstract_cn": "以 OpenAI 的 GPT 系列和 Meta 的 LLaMA 变种为代表的大型语言模型（LLMs）在人工智能领域取得了显著突破。这些模型经过海量文本数据的训练，能够理解并生成多样化话题的类人文本。本研究进一步探讨了 LLMs 在数据预处理——数据挖掘和分析应用的关键环节——中的应用潜力。我们深入分析了 GPT-3.5、GPT-4 和 Vicuna-13B 等尖端 LLMs 在错误检测、数据填充、模式匹配和实体匹配等任务中的适用性。研究不仅展示了 LLMs 的内在能力，也指出了它们在计算成本和效率上的局限。我们提出了一个融合尖端提示工程技术与传统方法，如情境化和特征选择的 LLM 基础数据预处理框架，旨在提升模型的性能与效率。通过 12 个数据集的广泛实验，我们评估了 LLMs 在数据预处理方面的效能，其中 GPT-4 在 4 个数据集上实现了 100% 的准确率或 F1 分数，彰显了 LLMs 在这些任务上的卓越潜力。尽管存在一些限制，但本研究凸显了 LLMs 在此领域的希望，并展望了未来的发展将如何克服现有挑战。",
    "title_cn": "语言巨擘，数据预处理的新利器",
    "tags": [
      "LLM应用",
      "人工智能",
      "数据预处理"
    ]
  },
  {
    "title": "Tryage: Real-time, intelligent Routing of User Prompts to Large Language Models",
    "submit_datetime": "2023年08月23日",
    "abstract": "The introduction of the transformer architecture and the self-attention mechanism has led to an explosive production of language models trained on specific downstream tasks and data domains. With over 200, 000 models in the Hugging Face ecosystem, users grapple with selecting and optimizing models to suit multifaceted workflows and data domains while addressing computational, security, and recency concerns. There is an urgent need for machine learning frameworks that can eliminate the burden of model selection and customization and unleash the incredible power of the vast emerging model library for end users. Here, we propose a context-aware routing system, Tryage, that leverages a language model router for optimal selection of expert models from a model library based on analysis of individual input prompts. Inspired by the thalamic router in the brain, Tryage employs a perceptive router to predict down-stream model performance on prompts and, then, makes a routing decision using an objective function that integrates performance predictions with user goals and constraints that are incorporated through flags (e.g., model size, model recency). Tryage allows users to explore a Pareto front and automatically trade-off between task accuracy and secondary goals including minimization of model size, recency, security, verbosity, and readability. Across heterogeneous data sets that include code, text, clinical data, and patents, the Tryage framework surpasses Gorilla and GPT3.5 turbo in dynamic model selection identifying the optimal model with an accuracy of 50.9% , compared to 23.6% by GPT 3.5 Turbo and 10.8% by Gorilla. Conceptually, Tryage demonstrates how routing models can be applied to program and control the behavior of multi-model LLM systems to maximize efficient use of the expanding and evolving language model ecosystem.",
    "pdf_link": "https://arxiv.org/abs/2308.11601",
    "graphs": [],
    "abstract_cn": "自注意力机制的变革性引入催生了大量针对特定任务和数据领域的语言模型。Hugging Face 生态系统内超过二十万个模型让用户在挑选合适模型以适应多样化工作流程和数据领域时，面临计算、安全和时效性的挑战。目前急需机器学习框架，以减轻用户在选择和定制模型时的负担，充分释放庞大新兴模型库的潜力。我们提出了一个名为 Tryage 的上下文感知路由系统，它通过分析个别输入提示，利用语言模型路由器从模型库中优选专家模型。该系统灵感来源于大脑中的丘脑路由器，采用感知路由器预测下游模型在提示上的表现，并结合用户目标和通过标志（如模型大小、时效性）指定的约束，通过目标函数做出最优路由决策。Tryage 使用户能够在任务准确性和次要目标（如最小化模型大小、时效性、安全性、冗长性和可读性）之间进行权衡，探索最优解决方案。在涵盖代码、文本、临床数据和专利的多样化数据集上，Tryage 在动态模型选择上超越了 Gorilla 和 GPT3.5 turbo，准确率高达 50.9%，而 GPT 3.5 Turbo 为 23.6%，Gorilla 为 10.8%。Tryage 从概念上证明了路由模型如何应用于编程和控制多模型大型语言模型系统的行为，以最大化利用不断增长和演变的语言模型生态。",
    "title_cn": "Tryage：实时智能地将用户指令分发至大型语言模型",
    "tags": [
      "LLM应用",
      "机器学习",
      "软件开发"
    ]
  },
  {
    "title": "GPT-in-the-Loop: Adaptive Decision-Making for Multiagent Systems",
    "submit_datetime": "2023年08月20日",
    "abstract": "This paper introduces the \"GPT-in-the-loop\" approach, a novel method combining the advanced reasoning capabilities of Large Language Models (LLMs) like Generative Pre-trained Transformers (GPT) with multiagent (MAS) systems. Venturing beyond traditional adaptive approaches that generally require long training processes, our framework employs GPT-4 for enhanced problem-solving and explanation skills. Our experimental backdrop is the smart streetlight Internet of Things (IoT) application. Here, agents use sensors, actuators, and neural networks to create an energy-efficient lighting system. By integrating GPT-4, these agents achieve superior decision-making and adaptability without the need for extensive training. We compare this approach with both traditional neuroevolutionary methods and solutions provided by software engineers, underlining the potential of GPT-driven multiagent systems in IoT. Structurally, the paper outlines the incorporation of GPT into the agent-driven Framework for the Internet of Things (FIoT), introduces our proposed GPT-in-the-loop approach, presents comparative results in the IoT context, and concludes with insights and future directions.",
    "pdf_link": "https://arxiv.org/abs/2308.10435",
    "graphs": [],
    "abstract_cn": "本文提出了一种创新的“GPT循环内”方法，将大型语言模型（LLMs）如生成预训练变换器（GPT）的高级推理能力与多智能体系统（MAS）相结合。该框架摒弃了传统自适应方法的长期训练需求，利用GPT-4提升问题解决和解释能力。实验场景设定为智能路灯的物联网（IoT）应用，智能体利用传感器、执行器和神经网络构建节能照明系统。集成GPT-4后，这些智能体无需大量训练即可实现更优的决策和适应性。我们将其与传统的神经进化策略及软件工程师的解决方案进行对比，突显了GPT驱动的多智能体系统在IoT领域的潜力。文章结构上，首先描述了将GPT整合进物联网智能体驱动框架（FIoT）的过程，接着介绍了我们提出的GPT循环内方法，展示了在IoT环境中的比较研究结果，并以深入见解和未来研究方向作为总结。",
    "title_cn": "GPT 循环：为多智能体系统打造自适应决策机制",
    "tags": [
      "Agent",
      "物联网",
      "人工智能"
    ]
  },
  {
    "title": "Adaptive Low Rank Adaptation of Segment Anything to Salient Object Detection",
    "submit_datetime": "2023年08月10日",
    "abstract": "Foundation models, such as OpenAI's GPT-3 and GPT-4, Meta's LLaMA, and Google's PaLM2, have revolutionized the field of artificial intelligence. A notable paradigm shift has been the advent of the Segment Anything Model (SAM), which has exhibited a remarkable capability to segment real-world objects, trained on 1 billion masks and 11 million images. Although SAM excels in general object segmentation, it lacks the intrinsic ability to detect salient objects, resulting in suboptimal performance in this domain. To address this challenge, we present the Segment Salient Object Model (SSOM), an innovative approach that adaptively fine-tunes SAM for salient object detection by harnessing the low-rank structure inherent in deep learning. Comprehensive qualitative and quantitative evaluations across five challenging RGB benchmark datasets demonstrate the superior performance of our approach, surpassing state-of-the-art methods.",
    "pdf_link": "https://arxiv.org/abs/2308.05426",
    "graphs": [],
    "abstract_cn": "诸如 OpenAI 的 GPT-3、GPT-4，Meta 的 LLaMA，以及 Google 的 PaLM2 等基础模型，引领了人工智能领域的革新。特别值得一提的是 Segment Anything Model (SAM) 的引入，它在经过 10 亿个遮罩和 1100 万张图像的训练后，展现出了分割现实世界物体的非凡能力。尽管 SAM 在常规物体分割任务上表现优异，但它在识别关键物体方面存在不足，影响了其在该领域的性能。为了解决这一问题，我们引入了 Segment Salient Object Model (SSOM)，这是一种创新的解决方案，它通过深度学习中的低秩结构，对 SAM 进行自适应微调，以提高显著物体检测的准确性。在五个颇具挑战性的 RGB 基准数据集上的全面评估显示，SSOM 在性能上超越了现有的顶尖技术。",
    "title_cn": "本文介绍了一种自适应低秩调整技术，旨在将“任何片段”模型适配到显著目标检测任务中，以提升检测性能。",
    "tags": [
      "分类：RAG",
      "人工智能",
      "图像处理"
    ]
  },
  {
    "title": "Cost-Effective Hyperparameter Optimization for Large Language Model Generation Inference",
    "submit_datetime": "2023年08月08日",
    "abstract": "Large Language Models (LLMs) have sparked significant interest in their generative capabilities, leading to the development of various commercial applications. The high cost of using the models drives application builders to maximize the value of generation under a limited inference budget. This paper presents a study of optimizing inference hyperparameters such as the number of responses, temperature and max tokens, which significantly affects the utility/cost of text generation. We design a framework named EcoOptiGen which leverages economical hyperparameter optimization and cost-based pruning. Experiments with the GPT-3.5/GPT-4 models on a variety of tasks verify its effectiveness. EcoOptiGen is implemented in the `autogen' package of the FLAML library: \\url{https://aka.ms/autogen}.",
    "pdf_link": "https://arxiv.org/abs/2303.04673",
    "graphs": [],
    "abstract_cn": "大型语言模型（LLMs）的生成能力激发了广泛的商业应用开发。然而，高昂的使用成本迫使开发者在一个有限的推理预算下寻求最大化生成价值的方法。本文探讨了优化推理超参数（如响应数量、温度和最大令牌数）的重要性，这些参数对文本生成的成本效益有着显著影响。我们提出了一个名为EcoOptiGen的框架，它通过经济型超参数优化和基于成本的剪枝策略，有效降低了成本。在GPT-3.5/GPT-4模型上进行的多样化任务实验证明了EcoOptiGen的有效性。该框架已在FLAML库的`autogen'包中实现，详情请访问：\\url{https://aka.ms/autogen}。",
    "title_cn": "高效优化大型语言模型推理的超参数，以降低成本在翻译过程中，我首先确保了原文意思的准确传达，然后根据中文的表达习惯，对翻译进行了调整，使其更加简洁、优雅，并保持了原文的生动性。",
    "tags": [
      "LLM应用\n\n这篇论文探讨了在有限的推理预算下最大化大型语言模型（LLMs）生成价值的方法，提出了一个名为EcoOptiGen的框架，用于优化推理超参数以降低成本。这与LLM的应用层面相关，因为它关注的是如何在实际应用中更有效地使用LLMs，而不是探讨LLMs的理论基础或Agent的设计。因此，它属于LLM应用分类。",
      "",
      "成本优化"
    ]
  },
  {
    "title": "Self-Adaptive Large Language Model (LLM)-Based Multiagent Systems",
    "submit_datetime": "2023年07月12日",
    "abstract": "In autonomic computing, self-adaptation has been proposed as a fundamental paradigm to manage the complexity of multiagent systems (MASs). This achieved by extending a system with support to monitor and adapt itself to achieve specific concerns of interest. Communication in these systems is key given that in scenarios involving agent interaction, it enhances cooperation and reduces coordination challenges by enabling direct, clear information exchange. However, improving the expressiveness of the interaction communication with MASs is not without challenges. In this sense, the interplay between self-adaptive systems and effective communication is crucial for future MAS advancements. In this paper, we propose the integration of large language models (LLMs) such as GPT-based technologies into multiagent systems. We anchor our methodology on the MAPE-K model, which is renowned for its robust support in monitoring, analyzing, planning, and executing system adaptations in response to dynamic environments. We also present a practical illustration of the proposed approach, in which we implement and assess a basic MAS-based application. The approach significantly advances the state-of-the-art of self-adaptive systems by proposing a new paradigm for MAS self-adaptation of autonomous systems based on LLM capabilities.",
    "pdf_link": "https://arxiv.org/abs/2307.06187",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2307.06187v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2307.06187/mape-k.png"
      },
      {
        "url": "https://arxiv.org/html/2307.06187v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2307.06187/x1.png"
      },
      {
        "url": "https://arxiv.org/html/2307.06187v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2307.06187/x2.png"
      },
      {
        "url": "https://arxiv.org/html/2307.06187v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2307.06187/x3.png"
      },
      {
        "url": "https://arxiv.org/html/2307.06187v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2307.06187/historic-agent4.png"
      },
      {
        "url": "https://arxiv.org/html/2307.06187v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2307.06187/exec2.png"
      },
      {
        "url": "https://arxiv.org/html/2307.06187v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2307.06187/exec3.png"
      }
    ],
    "abstract_cn": "在自主计算领域，自适应被视为管理多智能体系统（MASs）复杂性的核心原则。通过增加系统自我监控和自我调整的功能，以实现特定的关注点。在智能体互动的场景中，通信至关重要，因为它能够直接、清晰地交换信息，从而促进合作并降低协调的难度。然而，提升与MASs互动通信的表现力存在挑战。因此，自适应系统与有效通信之间的协同作用对于MAS的未来进步极为关键。本文提出了将大型语言模型（LLMs），例如基于GPT的技术，融入多智能体系统。我们的方法基于广受赞誉的MAPE-K模型，该模型以其在监控、分析、规划和执行系统适应性方面的强大支持而闻名。我们还展示了所提方法的一个实践案例，实现了一个基本的基于MAS的应用程序，并对其进行了评估。这种方法通过引入一种基于LLM能力的MAS自适应新范式，显著推动了自适应系统技术的发展。",
    "title_cn": "自适应大型语言模型（LLM）驱动的多智能体系统",
    "tags": [
      "Agent",
      "自主计算",
      "多智能体系统"
    ]
  },
  {
    "title": "Wireless Multi-Agent Generative AI: From Connected Intelligence to Collective Intelligence",
    "submit_datetime": "2023年07月05日",
    "abstract": "The convergence of generative large language models (LLMs), edge networks, and multi-agent systems represents a groundbreaking synergy that holds immense promise for future wireless generations, harnessing the power of collective intelligence and paving the way for self-governed networks where intelligent decision-making happens right at the edge. This article puts the stepping-stone for incorporating multi-agent generative artificial intelligence (AI) in wireless networks, and sets the scene for realizing on-device LLMs, where multi-agent LLMs are collaboratively planning and solving tasks to achieve a number of network goals. We further investigate the profound limitations of cloud-based LLMs, and explore multi-agent LLMs from a game theoretic perspective, where agents collaboratively solve tasks in competitive environments. Moreover, we establish the underpinnings for the architecture design of wireless multi-agent generative AI systems at the network level and the agent level, and we identify the wireless technologies that are envisioned to play a key role in enabling on-device LLM. To demonstrate the promising potentials of wireless multi-agent generative AI networks, we highlight the benefits that can be achieved when implementing wireless generative agents in intent-based networking, and we provide a case study to showcase how on-device LLMs can contribute to solving network intents in a collaborative fashion. We finally shed lights on potential challenges and sketch a research roadmap towards realizing the vision of wireless collective intelligence.",
    "pdf_link": "https://arxiv.org/abs/2307.02757",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2307.02757v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2307.02757/generative_agent_loop.png"
      },
      {
        "url": "https://arxiv.org/html/2307.02757v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2307.02757/generative_agent_architecture.png"
      },
      {
        "url": "https://arxiv.org/html/2307.02757v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2307.02757/game.png"
      },
      {
        "url": "https://arxiv.org/html/2307.02757v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2307.02757/power_history.png"
      },
      {
        "url": "https://arxiv.org/html/2307.02757v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2307.02757/rate_diff_history.png"
      }
    ],
    "abstract_cn": "大型语言模型（LLMs）、边缘网络与多智能体系统的结合，预示着一种创新的协同效应，为未来的无线通信技术带来了无限可能。它不仅利用了集体智慧，还推动了智能决策在网络边缘的实现。本文为将多智能体生成性AI融入无线网络铺路，描绘了在设备层面实现LLMs的愿景，其中多智能体LLMs共同规划和执行任务，以达成众多网络目标。文章深入探讨了云端LLMs的局限性，并从博弈论视角分析了多智能体LLMs在竞争性环境中的协作任务解决机制。此外，文章还为无线多智能体生成性AI系统在网络层和智能体层的架构设计奠定了理论基础，并识别了在推动设备上LLMs发展中可能扮演关键角色的无线技术。为了展示无线多智能体生成性AI网络的巨大潜力，文章强调了在基于意图的网络中部署无线生成性智能体所能带来的益处，并提供了一个案例研究，说明设备上的LLMs如何协作解决网络意图。最后，文章指出了实现无线集体智能愿景的潜在挑战，并提出了一个研究路线图。",
    "title_cn": "无线多智能体生成性AI：迈向集体智慧的智能互联",
    "tags": [
      "分类：Agent",
      "无线通信",
      "人工智能"
    ]
  },
  {
    "title": "Is Pre-training Truly Better Than Meta-Learning?",
    "submit_datetime": "2023年06月23日",
    "abstract": "In the context of few-shot learning, it is currently believed that a fixed pre-trained (PT) model, along with fine-tuning the final layer during evaluation, outperforms standard meta-learning algorithms. We re-evaluate these claims under an in-depth empirical examination of an extensive set of formally diverse datasets and compare PT to Model Agnostic Meta-Learning (MAML). Unlike previous work, we emphasize a fair comparison by using: the same architecture, the same optimizer, and all models trained to convergence. Crucially, we use a more rigorous statistical tool -- the effect size (Cohen's d) -- to determine the practical significance of the difference between a model trained with PT vs. a MAML. We then use a previously proposed metric -- the diversity coefficient -- to compute the average formal diversity of a dataset. Using this analysis, we demonstrate the following: 1. when the formal diversity of a data set is low, PT beats MAML on average and 2. when the formal diversity is high, MAML beats PT on average. The caveat is that the magnitude of the average difference between a PT vs. MAML using the effect size is low (according to classical statistical thresholds) -- less than 0.2. Nevertheless, this observation is contrary to the currently held belief that a pre-trained model is always better than a meta-learning model. Our extensive experiments consider 21 few-shot learning benchmarks, including the large-scale few-shot learning dataset Meta-Data set. We also show no significant difference between a MAML model vs. a PT model with GPT-2 on Openwebtext. We, therefore, conclude that a pre-trained model does not always beat a meta-learned model and that the formal diversity of a dataset is a driving factor.",
    "pdf_link": "https://arxiv.org/abs/2306.13841",
    "graphs": [
      {
        "url": "https://arxiv.org/html/2306.13841v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2306.13841/micod_resnet12_learning_curve.png"
      },
      {
        "url": "https://arxiv.org/html/2306.13841v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2306.13841/mds_learning_curve_resnet50.png"
      },
      {
        "url": "https://arxiv.org/html/2306.13841v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2306.13841/res12_fc100_learning_curve_pt_maml.png"
      },
      {
        "url": "https://arxiv.org/html/2306.13841v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2306.13841/res12_aircraft_learning_curve_pt_maml.png"
      },
      {
        "url": "https://arxiv.org/html/2306.13841v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2306.13841/res12_hdb8_learning_curve_pt_maml.png"
      },
      {
        "url": "https://arxiv.org/html/2306.13841v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2306.13841/res12_hdb9_learning_curve_pt_maml.png"
      },
      {
        "url": "https://arxiv.org/html/2306.13841v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2306.13841/hdb8_maml_vs_sl_val_loss.png"
      },
      {
        "url": "https://arxiv.org/html/2306.13841v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2306.13841/dtd_maml_vs_sl_val_loss.png"
      },
      {
        "url": "https://arxiv.org/html/2306.13841v1",
        "path": "/opt/data/Projects/HuggingArxiv/paper_images/2306.13841/maml_PT_comparison.png"
      }
    ],
    "abstract_cn": "在少量样本学习领域，普遍观点认为，固定预训练模型辅以评估时对最终层的微调，性能会超过传统元学习算法。本研究通过深入分析多样化数据集，重新审视了这一观点，并将预训练模型与模型无关的元学习（MAML）进行了对比。我们采用了相同的架构、优化器，并确保所有模型都经过充分训练，以实现公平比较。关键地，我们引入了效应量（Cohen's d）这一统计工具，以评估PT模型与MAML模型性能差异的实际重要性。此外，我们还利用多样性系数这一指标，量化了数据集的形式多样性。研究发现：在数据集形式多样性较低时，预训练模型通常优于MAML；而在多样性较高时，MAML则占据优势。尽管如此，根据经典统计标准，PT与MAML之间的平均性能差异并不显著（小于0.2）。这一发现挑战了预训练模型始终优于元学习模型的传统认知。我们的实验涵盖了21个少量样本学习基准，包括大规模的Meta-Data数据集，并未发现MAML与PT模型在Openwebtext上存在显著差异。因此，我们得出结论，预训练模型并非总是胜过元学习模型，数据集的形式多样性是影响性能的关键因素。",
    "title_cn": "预训练是否确实优于元学习？",
    "tags": [
      "LLM理论",
      "机器学习",
      "人工智能"
    ]
  },
  {
    "title": "Assessing the Effectiveness of GPT-3 in Detecting False Political Statements: A Case Study on the LIAR Dataset",
    "submit_datetime": "2023年06月13日",
    "abstract": "The detection of political fake statements is crucial for maintaining information integrity and preventing the spread of misinformation in society. Historically, state-of-the-art machine learning models employed various methods for detecting deceptive statements. These methods include the use of metadata (W. Wang et al., 2018), n-grams analysis (Singh et al., 2021), and linguistic (Wu et al., 2022) and stylometric (Islam et al., 2020) features. Recent advancements in large language models, such as GPT-3 (Brown et al., 2020) have achieved state-of-the-art performance on a wide range of tasks. In this study, we conducted experiments with GPT-3 on the LIAR dataset (W. Wang et al., 2018) and achieved higher accuracy than state-of-the-art models without using any additional meta or linguistic features. Additionally, we experimented with zero-shot learning using a carefully designed prompt and achieved near state-of-the-art performance. An advantage of this approach is that the model provided evidence for its decision, which adds transparency to the model's decision-making and offers a chance for users to verify the validity of the evidence provided.",
    "pdf_link": "https://arxiv.org/abs/2306.08190",
    "graphs": [],
    "abstract_cn": "识别政治谎言对于保持信息的纯洁性和防止虚假信息在社会中蔓延具有重要意义。传统上，尖端的机器学习模型采取了多种策略来识别虚假陈述，包括利用元数据、n-gram分析、语言特性以及文体学特征。随着大型语言模型如GPT-3的出现，我们在多项任务上见证了前所未有的性能提升。本研究中，我们在LIAR数据集上运用GPT-3进行实验，无需额外的元数据或语言特征，便超越了现有最先进模型的准确度。我们还尝试了零样本学习，通过精心构造的提示，达到了接近顶尖的成绩。这种方法的优势在于模型为其判断提供了依据，不仅增强了决策过程的透明度，也让用户有机会检验所提供证据的真实性。",
    "title_cn": "探究 GPT-3 识别虚假政治言论的能力：基于 LIAR 数据集的案例分析",
    "tags": [
      "LLM应用",
      "政治分析",
      "信息安全"
    ]
  },
  {
    "title": "Lost in Translation: Large Language Models in Non-English Content Analysis",
    "submit_datetime": "2023年06月12日",
    "abstract": "In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa, Google's PaLM) have become the dominant approach for building AI systems to analyze and generate language online. However, the automated systems that increasingly mediate our interactions online -- such as chatbots, content moderation systems, and search engines -- are primarily designed for and work far more effectively in English than in the world's other 7,000 languages. Recently, researchers and technology companies have attempted to extend the capabilities of large language models into languages other than English by building what are called multilingual language models.\n  In this paper, we explain how these multilingual language models work and explore their capabilities and limits. Part I provides a simple technical explanation of how large language models work, why there is a gap in available data between English and other languages, and how multilingual language models attempt to bridge that gap. Part II accounts for the challenges of doing content analysis with large language models in general and multilingual language models in particular. Part III offers recommendations for companies, researchers, and policymakers to keep in mind when considering researching, developing and deploying large and multilingual language models.",
    "pdf_link": "https://arxiv.org/abs/2306.07377",
    "graphs": [],
    "abstract_cn": "近期，诸如Open AI的GPT-4、Meta的LLaMa、Google的PaLM等大型语言模型，已成为在线分析和生成语言的AI系统建设的主流方法。但这些日益增多的自动化系统，如聊天机器人、内容审核系统和搜索引擎，主要针对英语设计，其效果远超过其他7000种语言。技术企业和研究者正尝试通过创建多语言语言模型，将这些大型模型的应用扩展到英语之外。本文将阐述多语言语言模型的运作机制及其能力与局限。第一部分简明扼要地解释了大型语言模型的工作原理，英语与其他语言在数据获取上的差异，以及多语言模型如何努力缩小这一差距。第二部分讨论了使用大型语言模型，尤其是多语言模型进行内容分析时面临的挑战。第三部分则为有意研究、开发和部署大型及多语言语言模型的公司、研究者和政策制定者提供了实用的建议。",
    "title_cn": "在非英语内容分析中，大型语言模型的应用有时会遇到“翻译中的迷失”。",
    "tags": [
      "分类：LLM应用",
      "人工智能",
      "语言处理"
    ]
  },
  {
    "title": "Large language models and (non-)linguistic recursion",
    "submit_datetime": "2023年06月12日",
    "abstract": "Recursion is one of the hallmarks of human language. While many design features of language have been shown to exist in animal communication systems, recursion has not. Previous research shows that GPT-4 is the first large language model (LLM) to exhibit metalinguistic abilities (Beguš, Dąbkowski, and Rhodes 2023). Here, we propose several prompt designs aimed at eliciting and analyzing recursive behavior in LLMs, both linguistic and non-linguistic. We demonstrate that when explicitly prompted, GPT-4 can both produce and analyze recursive structures. Thus, we present one of the first studies investigating whether meta-linguistic awareness of recursion -- a uniquely human cognitive property -- can emerge in transformers with a high number of parameters such as GPT-4.",
    "pdf_link": "https://arxiv.org/abs/2306.07195",
    "graphs": [],
    "abstract_cn": "递归是语言的显著特征，尽管动物的交流系统展现出语言的多种设计特征，但递归却不在其中。研究指出，GPT-4是首个展现元语言能力的超大型语言模型（LLM）（Beguš, Dąbkowski, 和 Rhodes 2023）。本文提出了几种提示设计，用以激发并分析LLMs在语言和非语言层面上的递归行为。我们证实，在明确引导下，GPT-4能够生成和解析递归结构。因此，本研究首次探讨了具有大量参数的变换器，如GPT-4，是否能够发展出对递归的元语言意识——这一人类独有的认知特性。",
    "title_cn": "大型语言模型与语言的递归性（及其缺失）",
    "tags": [
      "分类：LLM理论\n\n这篇论文探讨了大型语言模型（LLM）在语言和非语言层面上的递归行为，特别是GPT-4模型的元语言能力。它涉及到对LLM的认知特性的研究，因此属于LLM理论分类。",
      "人工智能",
      "认知科学"
    ]
  },
  {
    "title": "Multi-Agent Collaboration: Harnessing the Power of Intelligent LLM Agents",
    "submit_datetime": "2023年06月05日",
    "abstract": "In this paper, we present a novel framework for enhancing the capabilities of large language models (LLMs) by leveraging the power of multi-agent systems. Our framework introduces a collaborative environment where multiple intelligent agent components, each with distinctive attributes and roles, work together to handle complex tasks more efficiently and effectively. We demonstrate the practicality and versatility of our framework through case studies in artificial general intelligence (AGI), specifically focusing on the Auto-GPT and BabyAGI models. We also examine the \"Gorilla\" model, which integrates external APIs into the LLM. Our framework addresses limitations and challenges such as looping issues, security risks, scalability, system evaluation, and ethical considerations. By modeling various domains such as courtroom simulations and software development scenarios, we showcase the potential applications and benefits of our proposed multi-agent system. Our framework provides an avenue for advancing the capabilities and performance of LLMs through collaboration and knowledge exchange among intelligent agents.",
    "pdf_link": "https://arxiv.org/abs/2306.03314",
    "graphs": [],
    "abstract_cn": "本文介绍了一种创新框架，旨在通过多智能体系统的优势提升大型语言模型（LLM）的性能。该框架创造了一个协作平台，让具备不同特性和职责的多个智能体组件协同作业，共同高效处理复杂任务。通过针对人工通用智能（AGI）领域的案例分析，特别是 Auto-GPT 和 BabyAGI 模型，我们展示了框架的实用性和适应性。此外，我们还探讨了“Gorilla”模型，该模型实现了外部 API 与 LLM 的融合。框架还针对循环问题、安全隐患、扩展性、系统评估和伦理问题等挑战提出了解决方案。通过模拟法庭审判和软件开发等场景，我们展示了所提出的多智能体系统的应用潜力和益处。该框架为提升 LLM 的能力与表现，通过智能体间的协作与知识共享开辟了新路径。",
    "title_cn": "多智能体协作：发挥智能大型语言模型代理的潜力",
    "tags": [
      "Agent",
      "人工智能",
      "多智能体系统"
    ]
  },
  {
    "title": "Self-Agreement: A Framework for Fine-tuning Language Models to Find Agreement among Diverse Opinions",
    "submit_datetime": "2023年05月19日",
    "abstract": "Finding an agreement among diverse opinions is a challenging topic in multiagent systems. Recently, large language models (LLMs) have shown great potential in addressing this challenge due to their remarkable capabilities in comprehending human opinions and generating human-like text. However, they typically rely on extensive human-annotated data. In this paper, we propose Self-Agreement, a novel framework for fine-tuning LLMs to autonomously find agreement using data generated by LLM itself. Specifically, our approach employs the generative pre-trained transformer-3 (GPT-3) to generate multiple opinions for each question in a question dataset and create several agreement candidates among these opinions. Then, a bidirectional encoder representations from transformers (BERT)-based model evaluates the agreement score of each agreement candidate and selects the one with the highest agreement score. This process yields a dataset of question-opinion-agreements, which we use to fine-tune a pre-trained LLM for discovering agreements among diverse opinions. Remarkably, a pre-trained LLM fine-tuned by our Self-Agreement framework achieves comparable performance to GPT-3 with only 1/25 of its parameters, showcasing its ability to identify agreement among various opinions without the need for human-annotated data.",
    "pdf_link": "https://arxiv.org/abs/2305.11460",
    "graphs": [],
    "abstract_cn": "在多智能体系统中达成共识是一项挑战，但大型语言模型（LLMs）凭借其卓越的理解和生成文本能力，为这一挑战提供了新的解决途径。尽管如此，它们通常需要依赖大量的人工标注数据。本文提出了“自我共识”框架，这是一个创新的方法，通过使用LLM自身生成的数据，训练LLM自主寻找共识。具体操作是，利用GPT-3生成针对问题库中每个问题的不同意见，并从中挑选出多个可能的共识选项。接着，基于BERT的模型对每个选项进行共识评分，挑选出得分最高的共识。这一过程形成了一个包含问题、意见和共识的数据集，用于微调预训练的LLM，以便在多元意见中寻找共识。令人印象深刻的是，使用自我共识框架微调的LLM在参数量仅为GPT-3的1/25的情况下，性能却可与之媲美，这证明了它在无需人工标注数据的情况下，依然能够有效识别不同意见中的共识点。",
    "title_cn": "自我一致性框架：专为语言模型量身定制，旨在调和多元观点，寻求共识。通过精细调整，该框架助力语言模型在多样化的意见中寻找共同点。",
    "tags": [
      "Agent",
      "多智能体系统",
      ""
    ]
  },
  {
    "title": "Turning Machines: a simple algorithmic model for molecular robotics",
    "submit_datetime": "2022年01月24日",
    "abstract": "Molecular robotics is challenging, so it seems best to keep it simple. We consider an abstract molecular robotics model based on simple folding instructions that execute asynchronously. Turning Machines are a simple 1D to 2D folding model, also easily generalisable to 2D to 3D folding. A Turning Machine starts out as a line of connected monomers in the discrete plane, each with an associated turning number. A monomer turns relative to its neighbours, executing a unit-distance translation that drags other monomers along with it, and through collective motion the initial set of monomers eventually folds into a programmed shape. We provide a suite of tools for reasoning about Turning Machines by fully characterising their ability to execute line rotations: executing an almost-full line rotation of $5π/3$ radians is possible, yet a full $2π$ rotation is impossible. Furthermore, line rotations up to $5π/3$ are executed efficiently, in $O(\\log n)$ expected time in our continuous time Markov chain time model. We then show that such line-rotations represent a fundamental primitive in the model, by using them to efficiently and asynchronously fold shapes. In particular, arbitrarily large zig-zag-rastered squares and zig-zag paths are foldable, as are $y$-monotone shapes albeit with error (bounded by perimeter length). Finally, we give shapes that despite having paths that traverse all their points, are in fact impossible to fold, as well as techniques for folding certain classes of (scaled) shapes without error. Our approach relies on careful geometric-based analyses of the feats possible and impossible by a very simple robotic system, and pushes conceptional hardness towards mathematical analysis and away from molecular implementation.",
    "pdf_link": "https://arxiv.org/abs/2009.00755",
    "graphs": [],
    "abstract_cn": "分子机器人技术充满挑战，简化处理显得更为明智。我们提出了一个基于简易折叠指令的分子机器人抽象模型，这些指令能够异步运作。转向机模型以其简洁性著称，它从一维线性结构向二维形态转变，且易于扩展至三维。该模型以离散平面上的单体链起始，每个单体都配有特定的转向编号。单体相对于相邻单体进行旋转，带动其他单体同步移动，通过协同作用，原始的单体链最终折叠成预定的形态。我们开发了一系列工具，全面分析了转向机执行线旋转的能力：实现接近完整的 $5π/3$ 弧度旋转是可行的，但完整的 $2π$ 旋转则不可行。更重要的是，这些线旋转操作在连续时间马尔可夫链模型中，以 $O(\\log n)$ 的期望时间高效完成。进一步地，我们证明了这些线旋转是模型中的基础操作，利用它们可以高效、异步地折叠出各种形状。例如，任意大小的之字形栅格正方形和之字形路径均可实现折叠，而 $y$-单调形状虽有误差（受限于周长）也能完成折叠。最后，我们展示了一些尽管路径遍历所有点但实际无法折叠的形状，并提供了一些无误差折叠特定类别（缩放版）形状的技术。本研究的方法论基于对极简机器人系统可能与不可能完成的任务进行精细的几何分析，将概念上的复杂性转化为数学分析，而非分子层面的实现。",
    "title_cn": "转机：一种用于分子机器人领域的简洁算法模型",
    "tags": [
      "分类：Agent",
      "分子机器人技术",
      "计算机科学"
    ]
  }
]