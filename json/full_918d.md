# 开源 LLM 能否媲美商业模型？本文探讨了当前 GPT 模型在生物医学任务中的少样本学习表现。
发布时间：2024年07月18日
`LLM应用`
> Can Open-Source LLMs Compete with Commercial Models? Exploring the Few-Shot Performance of Current GPT Models in Biomedical Tasks
# 摘要
> 商业LLM如GPT-4和Claude 3 Opus在NLP领域独占鳌头，而新兴的开源模型如Mixtral 8x7B和Llama 3正逐步缩小差距，提供更高效率且成本更低。这些开源LLM支持自我托管，特别适合处理敏感数据的企业和临床场景。我们在BioASQ挑战赛中测试了Claude 3 Opus、GPT-3.5-turbo和Mixtral 8x7b的性能，发现Mixtral在少-shot场景下表现出色，但在零-shot场景中表现不佳。QLoRa微调和维基百科知识的加入并未显著提升性能。实验表明，通过收集特定领域的少-shot示例，可以有效弥合商业与开源模型在零-shot场景下的性能差距。相关实验代码已公开在GitHub上。
[Arxiv](https://arxiv.org/abs/2407.13511)
==========
# CoD：通过诊断链构建可解释的医疗智能体
发布时间：2024年07月18日
`LLM应用` `人工智能`
> CoD, Towards an Interpretable Medical Agent using Chain of Diagnosis
# 摘要
> 随着大型语言模型的兴起，医学诊断领域迎来了革新，但模型的可解释性问题依旧悬而未决。本研究提出的诊断链（CoD）机制，模仿医生思维，将诊断过程透明化，并输出疾病置信度分布，增强了决策透明性。CoD不仅使诊断过程可控，还通过置信度熵的降低，助力识别关键症状。基于CoD，我们研发的DiagnosisGPT能诊断9604种疾病，实验表明其在诊断准确性上超越其他LLM，并确保了诊断过程的可解释性与严谨性。
[Arxiv](https://arxiv.org/abs/2407.13301)
==========
# 我们是否在多模态的脱离上下文虚假信息检测上取得了进展，尽管相似性似乎比事实性更受重视？
发布时间：2024年07月18日
`LLM应用` `信息安全`
> Similarity over Factuality: Are we making progress on multimodal out-of-context misinformation detection?
# 摘要
> 在多模态事实核查中，Out-of-context (OOC) 错误信息是一个重大挑战，它通过将图像与歪曲其原始上下文的文本配对来支持虚假叙事。近期研究趋向于采用更复杂的架构，如 Transformer 和大型语言模型。我们提出了一种简单而强大的基线方法 MUSE，专注于图像-文本对与外部证据的相似性。实验表明，结合传统分类器，MUSE 在 NewsCLIPpings 和 VERITE 数据集上表现优异。进一步整合到 AITR 中，性能分别提升了 3.3% 和 7.5%。然而，MUSE 依赖表面模式，未深入事实与逻辑，引发了对任务定义和评估方法的深刻反思。代码已公开发布于：https://github.com/stevejpapad/outcontext-misinfo-progress
[Arxiv](https://arxiv.org/abs/2407.13488)
==========
# 在安全关键场景中，风险感知的车辆轨迹预测
发布时间：2024年07月18日
`Agent` `自动驾驶` `交通安全`
> Risk-Aware Vehicle Trajectory Prediction Under Safety-Critical Scenarios
# 摘要
> 轨迹预测对智能车实现高级自动驾驶至关重要，但现有研究多聚焦于安全场景，忽视了关键安全场景，尤其是即将发生碰撞的情况。为此，本文提出了一种针对关键安全场景的风险感知轨迹预测框架，包含三个核心风险感知组件：风险融合场景编码器、结合端点风险的意图查询和辅助风险预测任务。此外，我们还引入了专门的数据集和评估指标。通过与多个SOTA模型的比较，我们的模型在大多数指标上表现更优，显著提升了自动驾驶车辆在关键安全场景下的避撞能力，从而增强了道路交通的安全性。
[Arxiv](https://arxiv.org/abs/2407.13480)
==========
# DISCOVER：一款数据驱动的人类行为全方位观察、可视化与探索交互系统
发布时间：2024年07月18日
`Agent` `社会科学` `软件框架`
> DISCOVER: A Data-driven Interactive System for Comprehensive Observation, Visualization, and ExploRation of Human Behaviour
# 摘要
> 理解人类行为是社会科学的核心目标，但这一领域的分析充满挑战。传统方法因数据收集和分析的复杂性，常受限于时间和资源。为此，计算模型崭露头角，能自动识别关键行为指标，如社交信号，助力大数据分析。然而，这些尖端模型的普及受阻于其复杂性和高昂的计算资源需求，限制了非技术背景研究者的参与。为此，我们推出了DISCOVER——一个模块化、灵活且易用的软件框架，旨在简化人类行为分析的计算探索。我们的目标是将高级计算方法普及化，让各领域研究者无需深厚技术背景即可深入行为分析。本文通过四个递进的工作流程——交互式语义探索、视觉检查、辅助注释和多模态场景搜索——展示了DISCOVER的强大功能。我们强调其多功能性和易用性，并提供了一套探索性数据分析的蓝图，作为研究的起点。
[Arxiv](https://arxiv.org/abs/2407.13408)
==========
# 利用强化学习进行多模态标签相关性排序
发布时间：2024年07月18日
`Agent` `多媒体` `数据分析`
> Multimodal Label Relevance Ranking via Reinforcement Learning
# 摘要
> 传统多标签识别方法往往忽视了与人类偏好相符的部分顺序关系的重要性。为此，我们提出了一种名为LR²PPO的新方法，该方法通过识别标签间的部分顺序关系，有效提升了多模态标签相关性排序的性能。LR²PPO通过训练奖励模型来捕捉特定场景中的人类偏好，并精心设计了适用于排序任务的状态表示和策略损失，从而减少了新场景中对部分顺序标注的依赖。我们还推出了包含多模态标签及其部分顺序数据的LRMovieNet基准数据集，以支持方法评估。实验结果显示，LR²PPO在多模态标签相关性排序问题上表现卓越。相关代码和数据集已公开在GitHub上。
[Arxiv](https://arxiv.org/abs/2407.13221)
==========
# DiveSound：借助 LLM 进行自动分类构建，助力多样化音频生成
发布时间：2024年07月18日
`LLM应用` `音频处理` `数据集构建`
> DiveSound: LLM-Assisted Automatic Taxonomy Construction for Diverse Audio Generation
# 摘要
> 音频生成领域备受瞩目，尽管质量大幅提升，多样性评估却被忽视。这主要源于缺乏系统的声音多样性框架和相应数据集。为此，我们创新提出DiveSound框架，利用大型语言模型构建类别内多样化的多模态数据集。该框架融合文本与视觉信息，通过多模态对比表示提升数据多样性。我们的框架自主性强，易于扩展，并提供了一个包含丰富子类别的文本-音频-图像对齐数据集。实验表明，视觉信息指导下的文本到音频生成，多样性显著增强。
[Arxiv](https://arxiv.org/abs/2407.13198)
==========
# 模型越大，所需的词汇量也应越大，这是词汇规模的法则。
发布时间：2024年07月18日
`LLM理论` `人工智能`
> Scaling Laws with Vocabulary: Larger Models Deserve Larger Vocabularies
# 摘要
> 在扩展大型语言模型 (LLM) 的研究中，我们发现词汇大小的重要性常被忽视。通过实验，我们揭示了词汇大小对模型扩展的影响，并提出了三种方法来确定计算最优的词汇大小。我们的研究表明，最优词汇大小与计算预算紧密相关，且大型模型应配备更大的词汇表。然而，当前大多数 LLM 的词汇大小设置过小。例如，我们预测 Llama2-70B 的最优词汇应为 216K，远超其当前的 32K。实证验证显示，采用我们预测的最优词汇大小能显著提升下游任务性能。通过将词汇大小从 32K 提升至 43K，我们在 ARC-Challenge 任务中实现了性能的显著提升。这一发现强调了在模型扩展时，必须同时考虑模型参数和词汇大小，以实现更高效的表现。
[Arxiv](https://arxiv.org/abs/2407.13623)
==========
# KNOWNET：借助知识图谱集成，引导 LLMs 进行健康信息搜索
发布时间：2024年07月18日
`LLM应用` `知识图谱`
> KNOWNET: Guided Health Information Seeking from LLMs via Knowledge Graph Integration
# 摘要
> 随着对大型语言模型 (LLM) 在健康信息查询中的依赖日益增加，错误信息和主题复杂性可能带来严重风险。KNOWNET 系统应运而生，它巧妙结合 LLM 与知识图谱 (KG)，旨在提升准确性与结构化探索。KNOWNET 从 LLM 输出中提取关键信息，精准映射至 KG 中的验证数据，确保信息准确无误。同时，它根据 KG 中实体的关联，智能推荐下一步探索方向，助力用户全面而不遗漏地理解主题。KNOWNET 将主题理解过程可视化为逐步构建的图谱，通过渐进式图谱可视化，用户可回溯查询历史，无缝衔接当前与未来探索。通过实际用例与专家访谈，KNOWNET 的有效性得到了充分验证。
[Arxiv](https://arxiv.org/abs/2407.13598)
==========
# PLANTS：专为规划类任务摘要设计的新颖问题与数据集
发布时间：2024年07月18日
`LLM应用` `工作流程`
> PLANTS: A Novel Problem and Dataset for Summarization of Planning-Like (PL) Tasks
# 摘要
> 文本摘要虽已广泛研究并应用于商业，但现实中许多任务如工作流程、食谱等，需生成行动序列以达成目标。我们称这类任务为“规划类”，因其共享控制流信息特性，有助于创建实用摘要，助用户快速决策。为此，我们提出新的“规划摘要”问题，并提供数据集与基线方法。通过定量与定性评估，我们探索了此新领域，期待能重燃对摘要技术的研究热情。
[Arxiv](https://arxiv.org/abs/2407.13597)
==========
# EarthMarker：一款专为区域与点级遥感图像理解设计的视觉提示学习框架
发布时间：2024年07月18日
`LLM应用` `人工智能`
> EarthMarker: A Visual Prompt Learning Framework for Region-level and Point-level Remote Sensing Imagery Comprehension
# 摘要
> 近期，自然图像领域的视觉提示技术进步，让用户能通过框、点、自由形状等视觉标记与AI工具互动。但自然与遥感图像的显著差异，使现有视觉提示模型在遥感场景中遇阻。遥感MLLMs虽专注图像级数据解读，却仅能通过语言指令交互，限制了实际应用的灵活性。为此，我们推出了EarthMarker模型，专精于图像、区域、点级遥感图像解析。该模型将视觉提示与图像、文本指令一同输入LLM，精准适应特定任务。我们还创新了共享视觉编码法，统一优化多尺度图像与提示信息。为增强其多粒度视觉感知，我们设计了跨域分阶段学习策略，并轻量化优化参数，融合自然与遥感领域知识。同时，为弥补遥感视觉提示数据的不足，我们构建了RSVP数据集，内含多模态细粒度指令。大量实验显示，EarthMarker在视觉提示框架下，于多粒度遥感图像解析中表现卓越，标志着该领域的重大进步。
[Arxiv](https://arxiv.org/abs/2407.13596)
==========
# 大型语言模型能否成为可靠的知识库？
发布时间：2024年07月18日
`LLM理论` `人工智能`
> Large Language Models as Reliable Knowledge Bases?
# 摘要
> NLP 社区对利用 LLM 进行知识密集型任务的兴趣日益浓厚，将其视为潜在的知识库。然而，LLM 作为知识库的可靠性和适用范围仍待深入探讨。虽然有研究指出 LLM 能在参数中编码知识，但这并不足以全面评估其作为知识库的效能。本研究设定了 LLM 作为可靠知识库的标准，聚焦于事实性和一致性，并涵盖已知与未知知识。我们据此开发了评估指标，对 26 个流行 LLM 进行了全面评估，并分析了模型大小、指令调优及上下文学习等因素的影响。结果显示，即便如 GPT-3.5-turbo 这样的高性能模型，在事实性和一致性上也存在不足，而上下文学习和微调等策略也未能显著提升 LLM 作为知识库的表现。
[Arxiv](https://arxiv.org/abs/2407.13578)
==========
# 本研究探讨了基于大型语言模型的藏族旅游观点信息生成系统。
发布时间：2024年07月18日
`LLM应用` `智能服务`
> Research on Tibetan Tourism Viewpoints information generation system based on LLM
# 摘要
> 西藏，这片蕴藏着深厚历史与独特宗教文化的土地，其复杂多变的地形虽美，却也限制了旅游服务的发展。现有的智能旅游服务在满足游客需求上显得力不从心。本研究不仅剖析了信息差异对西藏旅游业的影响，还挑战了建立大型语言模型（LLM）评估标准的难题。我们创新性地提出了DualGen Bridge AI系统，通过监督微调技术强化模型，优化其性能，并首创多结构生成结果评估框架，经实证验证其有效。此外，我们还探索了在DualGen Bridge AI中运用监督微调方法，以提升旅游信息的生成质量。研究成果不仅为系统优化提供了新思路，更为LLM技术在西藏乃至更广泛旅游服务领域的应用注入了活力，预示着智能旅游产业将迎来一场由先进定制信息生成技术引领的革命。
[Arxiv](https://arxiv.org/abs/2407.13561)
==========
# INDIC QA 基准：一个多语言评估工具，旨在检验大型语言模型在印度语言问答任务中的表现。
发布时间：2024年07月18日
`LLM应用` `语言技术`
> INDIC QA BENCHMARK: A Multilingual Benchmark to Evaluate Question Answering capability of LLMs for Indic Languages
# 摘要
> 大型语言模型 (LLM) 在未见任务中展现了出色的零-shot 和少-shot 能力，尤其是在英语的基于上下文的问答 (QA) 方面。然而，由于非英语语言中缺乏基准，LLM 在非英语语言的基于上下文 QA 能力评估上存在局限。为此，我们推出了 Indic-QA，这是涵盖 11 种主要印度语言的最大公开可用基于上下文问答数据集。该数据集融合了抽取式和抽象式问答任务，并纳入了现有数据集及翻译成印度语言的英语 QA 数据集。我们还利用 Gemini 模型生成了合成数据集，通过给定段落创建问题-答案对，并进行人工验证以确保质量。在基准测试中，我们评估了多语言 LLM 及其指令微调变体，发现其性能不尽如人意，特别是在低资源语言中。我们期待该数据集的发布能激发对 LLM 在低资源语言问答能力的深入研究。
[Arxiv](https://arxiv.org/abs/2407.13522)
==========
# 基于语言模型，实现可控自发行为的自发风格文本转语音合成
发布时间：2024年07月18日
`LLM应用` `语音合成` `人工智能`
> Spontaneous Style Text-to-Speech Synthesis with Controllable Spontaneous Behaviors Based on Language Models
# 摘要
> 自发风格语音合成旨在模仿人类语音，但常因高质量数据稀缺和模型能力有限而受阻。最新的基于语言模型的TTS系统虽能利用大型、多样但质量参差不齐的语音数据集生成自然语音，却难以模拟自发行为和捕捉韵律变化。本文提出一种新型自发语音合成系统，系统分类并统一建模多种自发行为，并引入细粒度韵律建模以捕捉细微韵律变化。实验表明，该方法在韵律和自发行为自然性上大幅超越传统方法。
[Arxiv](https://arxiv.org/abs/2407.13509)
==========
# 机器人也能胜任多任务，通过整合记忆架构与大型语言模型，提升跨任务动作生成的效率。
发布时间：2024年07月18日
`Agent` `机器人` `人工智能`
> Robots Can Multitask Too: Integrating a Memory Architecture and LLMs for Enhanced Cross-Task Robot Action Generation
# 摘要
> 最近，大型语言模型（LLM）被应用于机器人领域，旨在将LLM的常识推理能力与机器人的感知和物理能力相结合。在人形机器人中，记忆功能对于实现其在现实世界中的实体化以及增强其长期交互能力尤为关键，尤其是在多任务环境中，机器人需要记忆过往的任务状态、环境变化及已执行的动作。本文探讨了如何将记忆机制与LLM相结合，以支持机器人进行跨任务的动作生成，并实现任务间的流畅切换。我们设计了一种双层架构，包含两个LLM，它们分别擅长推理和指令执行，并辅以受人类认知启发的记忆模型。实验结果表明，相较于五个机器人任务的基准，我们的方法显著提升了性能，展现了将记忆与LLM融合以优化机器人动作和感知，从而实现更灵活任务执行的广阔前景。
[Arxiv](https://arxiv.org/abs/2407.13505)
==========
# 融合约束编程推理与大型语言模型预测
发布时间：2024年07月18日
`LLM应用` `文本生成` `人工智能`
> Combining Constraint Programming Reasoning with Large Language Model Predictions
# 摘要
> 约束编程 (CP) 和机器学习 (ML) 在文本生成领域各有所长，但也各有短板：CP 难以把握“意义”，ML 则难以应对结构约束。本文巧妙融合两者，将大型语言模型 (LLM) 嵌入 CP 框架中，由 LLM 负责词义生成，CP 则掌控结构约束。这一创新方法基于 GenCP，即利用 LLM 优化域的即时约束编程搜索 (OTFS) 的升级版。相较于传统的 Beam Search (BS)，这一融合策略不仅提速，更确保了约束的全方位满足，为约束条件下的文本生成开辟了新径。
[Arxiv](https://arxiv.org/abs/2407.13490)
==========
# 长上下文推荐中，语言模型面临“注意力溢出”问题，导致输入信息模糊，影响缺失项的准确推荐。
发布时间：2024年07月18日
`LLM应用` `电影推荐` `人工智能`
> Attention Overflow: Language Model Input Blur during Long-Context Missing Items Recommendation
# 摘要
> LLM 能从提示列表中推荐缺失项，适用于列表补全或基于用户历史的推荐。但当列表过长（约 100 项）时，模型会重复推荐已有的项目，这种现象我们称之为“注意力溢出”。我们在合成问题和真实电影推荐场景中测试了这一现象。虽然迭代方法能减轻问题，但其成本随重复率上升，影响模型从长输入中创新的能力。
[Arxiv](https://arxiv.org/abs/2407.13481)
==========
# 大型语言模型实现端到端临床试验匹配
发布时间：2024年07月18日
`LLM应用` `临床试验`
> End-To-End Clinical Trial Matching with Large Language Models
# 摘要
> 将癌症患者与临床试验精准匹配，是推动治疗进步和提升患者护理的关键。然而，医疗文档格式的不统一和试验资格标准的复杂性，使得这一过程对医生而言既棘手又耗时。我们探索了利用大型语言模型（LLMs）自动化这一全流程的可能性——从在clinicaltrials.gov的海量肿瘤学相关试验中筛选出相关试验，到实现标准级别的患者资格匹配。通过GPT-4o和合成电子健康记录（EHRs）的实验，我们方法在93.3%的情况下成功识别出候选试验，并在标准级别匹配中达到88.0%的初步准确率，与人类专家的基线相媲美。进一步分析LLM反馈发现，39.3%最初被判定为不正确的标准实则模糊或标注有误，经调整后，模型总准确率提升至92.7%。综上所述，我们构建了一个高精度的LLMs端到端临床试验匹配系统，不仅在筛选和匹配效率上超越了专业医生，而且该系统可自主运行或接受人工监督，适用范围广泛，为现实场景中的患者-试验匹配提供了可扩展的优化方案。
[Arxiv](https://arxiv.org/abs/2407.13463)
==========
# BEAF：通过观察变化前后的情况，评估视觉-语言模型中的幻觉现象。
发布时间：2024年07月18日
`LLM应用` `人工智能` `计算机视觉`
> BEAF: Observing BEfore-AFter Changes to Evaluate Hallucination in Vision-language Models
# 摘要
> 视觉语言模型（VLMs）结合视觉编码器和大型语言模型（LLM）来感知世界，无需微调即可在广泛基准上实现高性能，展现出零-shot或few-shot能力。然而，VLMs易产生幻觉，影响其可靠性和可信度。为此，我们创建了BEfore-AFter幻觉数据集（BEAF），并引入True Understanding（TU）、IGnorance（IG）、StuBbornness（SB）和InDecision（ID）等新指标，通过图像编辑模型操纵视觉场景信息，基于场景变化设计指标，以评估VLMs对场景的理解。我们还通过双轴视图（视觉和文本）可视化图像对象关系。评估结果显示，这些新指标揭示了VLMs幻觉的未被报告的方面。项目页面：\url{https://beafbench.github.io/}
[Arxiv](https://arxiv.org/abs/2407.13442)
==========
# 构建思维之桥：探索认知架构的组合性
发布时间：2024年07月18日
`LLM理论` `人工智能` `语言模型`
> From Words to Worlds: Compositionality for Cognitive Architectures
# 摘要
> 大型语言模型（LLM）虽为高效连接系统，但其组合性是否更胜一筹？这或许正是其卓越表现的秘密之一。我们深入分析了四个LLM家族（涵盖12个模型）及三大任务类别，甚至引入了一项新任务。研究发现，LLM在组合策略学习上呈现出微妙关系：规模扩张虽能提升组合能力，指令调优却常适得其反。这种矛盾现象，为我们如何更好地开发与人类认知相契合的LLM提出了新的思考。
[Arxiv](https://arxiv.org/abs/2407.13419)
==========
# 土著语言翻译中的“从错误中学习”提示法
发布时间：2024年07月18日
`LLM应用` `语言学`
> Learning-From-Mistakes Prompting for Indigenous Language Translation
# 摘要
> 本文利用大型语言模型，提出了一系列技术来提升极低资源原住民语言的翻译质量。我们的策略依托于：(1) 有限平行翻译示例的数据存储，(2) GPT-3.5 等 LLM 的内在能力，以及 (3) 词级翻译词典。我们探索了 LLM 在特定环境下的潜力，将其作为极低资源语言的通用翻译工具。核心方法是将 LLM 视为特定语言对的语言编译器，设想其能吸收句法结构以实现精准翻译。我们创新了三种技术：结合检索提示的 KNNPrompting、思维链提示以及从错误中学习的提示方法，后者专门针对以往的翻译错误。评估显示，即便在数据稀缺的情况下，搭配恰当的提示技术，LLM 也能高效完成极低资源语言的翻译任务。
[Arxiv](https://arxiv.org/abs/2407.13343)
==========
# 无需再训练，重建修剪模型
发布时间：2024年07月18日
`LLM理论` `人工智能` `计算机硬件`
> Reconstruct the Pruned Model without Any Retraining
# 摘要
> 结构化剪枝技术为大型语言模型（LLM）提供了一种硬件友好的压缩方案，无需重新训练即可避免高昂的成本。该技术包括定义剪枝架构和恢复性能的重建步骤。尽管现有方法侧重于剪枝标准，但重建技术的通用性受限于特定模块或标准。为此，我们提出了高效的LIAR框架，无需反向传播或重新训练，适用于多种剪枝标准和模块。通过线性插值优化保留权重，LIAR显著降低了重建误差。在GLUE、SQuAD等基准测试中，LIAR使BERT模型在参数减少50%后仍保持98%的准确率，并在短时间内为LLaMA带来顶级性能。
[Arxiv](https://arxiv.org/abs/2407.13331)
==========
# 通过保守数据过滤实现 ASR 错误纠正的鲁棒性
发布时间：2024年07月18日
`LLM应用` `自动语音识别` `语言处理`
> Robust ASR Error Correction with Conservative Data Filtering
# 摘要
> 基于大型语言模型的错误纠正技术，正逐渐成为提升自动语音识别系统性能的关键。然而，当前EC训练数据的自动配对方式存在质量问题，可能导致模型在处理域外数据时过度纠正。为此，我们提出了两个基本标准：EC目标需在语言接受度上超越源文本，并能从上下文中推断。通过这些标准，我们实施了保守数据过滤，确保模型在低质量数据面前保持克制。实验表明，我们的方法在日语ASR系统中显著减少了过度纠正现象，提升了在复杂域外环境下的识别准确性和整体质量。
[Arxiv](https://arxiv.org/abs/2407.13300)
==========
# SpeciaLex：专为上下文特定词汇学习设计的基准
发布时间：2024年07月18日
`LLM应用` `出版业`
> SpeciaLex: A Benchmark for In-Context Specialized Lexicon Learning
# 摘要
> 专业词典汇集了受特殊定义、角色和受众限制的词汇，这些限制对撰写技术手册或儿童书籍等任务至关重要，旨在减少歧义、提升特定群体的可读性。我们推出的SpeciaLex基准，通过18个多样子任务和1,285个测试实例，评估语言模型遵循这些专业约束的能力，涵盖检查、识别、重写和开放生成等核心任务。通过评估15种开源与闭源的大型语言模型，我们探讨了模型规模、开放性、设置及时效等因素对性能的影响，旨在助力构建更广泛应用的高效工具，超越自然语言处理领域。
[Arxiv](https://arxiv.org/abs/2407.13297)
==========
# 大型语言模型能否创作出媲美人类的叙事作品？
发布时间：2024年07月18日
`LLM应用` `媒体与娱乐`
> Are Large Language Models Capable of Generating Human-Level Narratives?
# 摘要
> 本文探讨了LLMs在叙事创作中的表现，特别关注故事情节的发展。我们提出了一种创新的计算方法，从故事弧线、转折点到情感层面的唤醒与效价，全方位剖析叙事。通过专家与自动注释的结合，我们揭示了LLM与人类创作故事间的显著差异：人类故事充满悬念、情感丰富且结构多变，而LLM作品则显得单一且缺乏张力。此外，我们评估了叙事推理能力，发现LLM在话语理解上普遍不及人类。最终，我们证明，若能明确融入这些话语特征，LLM的叙事能力将大幅提升，神经讲故事在多样性、悬念和情感激发方面实现了超过40%的飞跃。
[Arxiv](https://arxiv.org/abs/2407.13248)
==========
# PM-LLM-Benchmark：评估大型语言模型在过程挖掘任务上的表现
发布时间：2024年07月18日
`LLM应用` `制造业` `信息技术`
> PM-LLM-Benchmark: Evaluating Large Language Models on Process Mining Tasks
# 摘要
> 大型语言模型 (LLMs) 在半自动化过程挖掘 (PM) 分析方面展现出潜力。尽管商业模型已能胜任众多分析任务，但开源 LLMs 在 PM 领域的竞争实力仍待揭晓。本文首创 PM-LLM-Benchmark，聚焦于领域知识（过程挖掘与过程特定知识）及实施策略的多样性。同时，我们也探讨了构建此类基准的挑战，包括数据公开性与 LLMs 评估偏差。研究发现，多数 LLMs 能较好地完成部分 PM 任务，但适用于边缘设备的小型模型仍显不足。此外，我们强调，该基准虽有助于筛选适合 PM 任务的 LLMs，但消除评估偏差、全面评估竞争性 LLMs 仍需深入研究。
[Arxiv](https://arxiv.org/abs/2407.13244)
==========
# 强化学习中的 LLM 赋能状态表示
发布时间：2024年07月18日
`LLM应用` `机器人` `人工智能`
> LLM-Empowered State Representation for Reinforcement Learning
# 摘要
> 强化学习中的传统状态表示常遗漏关键任务细节，给价值网络的准确映射带来挑战。传统方法依赖大量样本学习来丰富状态信息，效率低下且耗时。近期，知识丰富的大型语言模型（LLM）为先验知识注入提供了新途径，仅需极少人工干预。基于此，我们提出LLM赋能的状态表示（LESR），利用LLM自主生成任务相关代码，提升网络映射连续性，加速训练。实验表明，LESR在样本效率上显著提升，Mujoco任务中累积奖励和Gym-Robotics任务成功率分别超越最先进基线29%和30%。
[Arxiv](https://arxiv.org/abs/2407.13237)
==========
# 通过咨询与心理治疗对话记录，评估大型语言模型在焦虑和抑郁分类中的应用。
发布时间：2024年07月18日
`LLM应用` `心理健康`
> Evaluating Large Language Models for Anxiety and Depression Classification using Counseling and Psychotherapy Transcripts
# 摘要
> 本研究旨在评估传统机器学习与大型语言模型在从长篇对话记录中识别焦虑和抑郁的有效性。我们微调了包括 BERT、RoBERTa、Longformer 在内的经典转换器模型，以及最新的 Mistral-7B 模型，同时通过特征工程训练了支持向量机，并利用提示评估了 GPT 模型。结果显示，尽管模型先进，但在分类效果上并未超越传统机器学习方法。
[Arxiv](https://arxiv.org/abs/2407.13228)
==========
# 基于Transformer的单细胞语言模型研究综述
发布时间：2024年07月18日
`LLM应用` `生物技术`
> Transformer-based Single-Cell Language Model: A Survey
# 摘要
> Transformer 以其卓越的并行处理能力和灵活的注意力机制，在自然语言处理领域取得了显著成就。如今，越来越多的研究开始利用 Transformer 模型处理单细胞数据。本文综述了基于 Transformer 的单细胞语言模型及其应用，详细介绍了 Transformer 的结构与原理，并回顾了相关的大型语言模型。我们还探讨了这些模型在批次校正、细胞聚类、类型注释、基因网络推断及响应分析等下游任务中的应用与挑战，并展望了未来的研究方向。希望这篇综述能为关注单细胞语言模型的研究者提供有价值的参考。
[Arxiv](https://arxiv.org/abs/2407.13205)
==========
# 自然语言处理中的检索增强生成技术：综述
发布时间：2024年07月18日
`RAG` `工业应用`
> Retrieval-Augmented Generation for Natural Language Processing: A Survey
# 摘要
> 大型语言模型（LLM）凭借其庞大的参数存储知识，在多领域取得了显著成就。然而，它们仍面临幻觉、知识更新滞后及缺乏专业领域知识等挑战。检索增强生成（RAG）通过整合外部知识库，有效弥补了这些不足。本文深入探讨了RAG的关键技术，特别是检索器与融合策略，并提供了实现这些技术的教程代码。此外，我们还详细阐述了RAG的训练方法，包括数据存储更新与否的差异。随后，展示了RAG在自然语言处理任务和工业应用中的实际效能。最后，本文展望了RAG的未来发展方向及其面临的挑战，旨在推动其进一步进步。
[Arxiv](https://arxiv.org/abs/2407.13193)
==========
# 无需训练，大模型先验助力多合一图像恢复
发布时间：2024年07月18日
`LLM应用` `图像处理` `计算机视觉`
> Training-Free Large Model Priors for Multiple-in-One Image Restoration
# 摘要
> 图像恢复的目标是从退化的图像中重建出清晰的原始图像。尽管现有方法在特定退化类型上取得了成功，但它们需要专门的模型，这在动态退化场景中限制了其实际应用。为此，我们引入了大型模型驱动的图像恢复框架（LMDIR），它利用多模态语言模型（MMLMs）和预训练扩散模型的通用先验，实现了一种多合一的图像恢复方法。LMDIR结合了三种关键先验：全局退化知识、场景感知的上下文描述以及由MMLM引导的扩散模型生成的高质量参考图像。我们的架构设计包括基于查询的提示编码器、注入全局退化知识的变换器块、结合场景描述的变换器块以及结合细粒度图像先验的变换器块，支持单阶段训练，能够处理多种退化情况，并支持自动和用户引导的恢复。实验结果显示，我们的方法在多个评估基准上超越了现有技术。
[Arxiv](https://arxiv.org/abs/2407.13181)
==========
# 借助 LLM，我们探究对话后续查询与用户满意度间的关联。
发布时间：2024年07月18日
`LLM应用` `搜索引擎` `用户体验`
> Using LLMs to Investigate Correlations of Conversational Follow-up Queries with User Satisfaction
# 摘要
> 借助大型语言模型（LLMs），对话式搜索引擎通过多轮自然对话，改变了用户从网络获取信息的方式。用户的自然对话中蕴含着丰富的、隐含的搜索意图和对搜索结果的评估，这些信息有助于理解用户与系统的互动体验。然而，关于用户为何及如何提出后续问题以延续与对话式搜索引擎的对话，以及这些后续问题如何反映用户满意度，这一领域仍有待深入探索。通过对Naver Cue：这一商业对话式搜索引擎的实验室用户评估中的250轮对话进行定性分析，我们提出了一种包含18种用户后续查询模式的分类法，涵盖两个主要维度：用户继续对话的动机和后续查询的行为。与现有文献相比，我们揭示了后续查询背后的一组新动机和行为，包括请求主观意见或对引擎的响应提供自然语言反馈。为了高效分析对话搜索日志，我们构建了一个基于LLM的分类器，准确率达73%。利用该分类器，我们分析了从Cue：的实际使用日志中收集的2,061个对话元组，并考察了我们的分类法中的对话模式与用户满意度之间的关联。初步发现显示，一些不满的信号，如澄清查询、排除条件和替代条件，通过后续查询得以体现。我们设想，我们的方法有望通过提供满意度信号并为现实用户模拟提供依据，推动对话搜索体验的自动化评估。
[Arxiv](https://arxiv.org/abs/2407.13166)
==========
# 翻译与修订：增强大型语言模型在约束翻译任务中的能力
发布时间：2024年07月18日
`LLM应用` `机器翻译` `语言模型`
> Translate-and-Revise: Boosting Large Language Models for Constrained Translation
# 摘要
> 在机器翻译系统中施加约束颇具挑战，因其未受训于利用约束生成充分流畅的翻译。本文中，我们借助大型语言模型（LLM）的适应性，通过将翻译指令与约束作为提示，实现受限翻译。尽管如此，LLM有时无法确保翻译质量，甚至忽视既定约束，部分源于其对预测的过度自信。为解决此问题，我们引入修订环节，激励LLM依据未满足的约束调整输出。经四个涵盖多领域词汇与结构约束的任务测试，我们的方法在基于约束的翻译准确性上较标准LLM提升15%，并大幅超越当前神经机器翻译（NMT）的顶尖技术。
[Arxiv](https://arxiv.org/abs/2407.13164)
==========
# 硬件架构与设备布局的集成搜索
发布时间：2024年07月18日
`LLM应用` `半导体` `人工智能`
> Integrated Hardware Architecture and Device Placement Search
# 摘要
> 深度学习训练的分布式执行，关键在于硬件加速器架构与设备放置策略的动态协同。我们首次通过创新算法，实现了架构与策略的协同优化，提升了计算资源、内存使用和数据分布的均衡。我们的架构搜索涵盖了张量与向量单元的数量与维度，以及内存配置，同时优化了微批量大小和激活存储策略，以平衡内存占用。通过整数线性规划（ILP），我们为每个架构配置找到了加速器上操作符的最佳执行调度，并结合动态规划，确定了跨多个加速器的最优设备放置策略。相较于顶尖的TPUv4和Spotlight框架，我们的方法在大语言模型上实现了更高吞吐量。PHAZE的完整源代码已公开在GitHub上。
[Arxiv](https://arxiv.org/abs/2407.13143)
==========
# 本模型为设备端流式自动语音识别设计，轻巧高效，专攻标点与单词大小写预测。
发布时间：2024年07月18日
`LLM应用` `语音识别` `智能设备`
> A light-weight and efficient punctuation and word casing prediction model for on-device streaming ASR
# 摘要
> 在自动语音识别（ASR）中，标点符号和单词大小写的预测至关重要。随着设备端流式ASR系统的兴起，设备端进行这些预测的需求日益增长，但相关讨论却不多见。尽管基于Transformer的模型在此领域有所探索，但其庞大的体积并不适合设备端应用。为此，我们设计了一种轻巧高效的模型，结合卷积神经网络（CNN）和双向长短期记忆（BiLSTM），能够实时处理标点符号和单词大小写的预测。实验表明，我们的模型在IWSLT2011测试集上，相较于非Transformer模型的最佳表现，总体F1分数提升了9%。与基于Transformer的代表性模型相比，我们的模型不仅体积小巧（仅为后者的四十分之一），推理速度也快了2.5倍，非常适合集成到设备端的流式ASR系统中。我们的代码已公开，供大家参考使用。
[Arxiv](https://arxiv.org/abs/2407.13142)
==========
# 探索视觉干草堆：解答图像集合中的难题
发布时间：2024年07月18日
`RAG` `计算机视觉` `人工智能`
> Visual Haystacks: Answering Harder Questions About Sets of Images
# 摘要
> 大型多模态模型 (LMMs) 在单图像视觉问答领域取得了显著进展，但面对跨越大量图像集合的查询时，这些模型面临重大挑战。本文探讨了多图像视觉问答 (MIQA) 任务，并提出了一种新的公共基准 "视觉干草堆 (VHs)"，专门设计用于评估 LMMs 在无关图像集合上的视觉检索和推理能力。我们引入了 MIRAGE（多图像检索增强生成），这是一种专为 LMMs 设计的新型检索/问答框架，针对 MIQA 的挑战，在效率和准确性上显著优于基线方法。我们的评估显示，MIRAGE 在 VHs 基准上超越了闭源 GPT-4o 模型高达 11%，并且在效率上提供了高达 3.4 倍的改进，优于以文本为中心的多阶段方法。
[Arxiv](https://arxiv.org/abs/2407.13766)
==========
# 针对大型语言模型检索增强生成的黑盒意见操纵攻击
发布时间：2024年07月18日
`RAG` `网络安全` `人工智能`
> Black-Box Opinion Manipulation Attacks to Retrieval-Augmented Generation of Large Language Models
# 摘要
> RAG 旨在解决大型语言模型的幻觉问题和实时约束，但也易受检索破坏攻击。本文聚焦于 RAG 在黑盒攻击下的脆弱性，特别是对意见操纵的影响。我们通过操纵检索排名并训练代理模型，实施对抗性检索攻击，实验显示这能显著改变 RAG 生成内容的意见极性。这不仅暴露了模型的脆弱性，更揭示了其对用户认知和决策的潜在危害，增加了误导用户的风险。
[Arxiv](https://arxiv.org/abs/2407.13757)
==========
# Baba Is AI：破旧立新，超越基准
发布时间：2024年07月18日
`Agent` `人工智能`
> Baba Is AI: Break the Rules to Beat the Benchmark
# 摘要
> 人类解决问题既依赖于遵循现有规则，也通过创造性思维重新定义规则和目标。为此，我们基于游戏 Baba Is You 设计了一个新基准，模拟代理通过操作环境和规则瓷砖来达成目标。测试了三种顶尖的多模态大型语言模型后，我们发现它们在需要灵活操纵和组合游戏规则的泛化任务中表现不佳。
[Arxiv](https://arxiv.org/abs/2407.13729)
==========
# SegPoint：借助大型语言模型，轻松分割任意点云
发布时间：2024年07月18日
`LLM应用` `计算机视觉` `机器人技术`
> SegPoint: Segment Any Point Cloud via Large Language Model
# 摘要
> 尽管3D点云分割技术已取得显著进步，但现有方法往往局限于特定任务，并依赖明确指令来识别目标，未能在一个统一框架内理解用户的隐含意图。为此，我们提出了SegPoint模型，该模型借助多模态大型语言模型的推理能力，为多种3D分割任务提供逐点分割掩码。此外，我们引入了Instruct3D基准，用于评估从复杂隐含文本中提取的分割性能，包含2,565个点云-指令对。实验显示，SegPoint在ScanRefer和ScanNet等基准上表现优异，并在Instruct3D数据集上取得了突出成果。SegPoint是首个在一个框架内成功应对多样化3D分割任务的模型，表现令人满意。
[Arxiv](https://arxiv.org/abs/2407.13761)
==========
# CellularLint：系统性识别蜂窝网络规范不一致行为的工具
发布时间：2024年07月18日
`LLM应用` `移动通信` `网络安全`
> CellularLint: A Systematic Approach to Identify Inconsistent Behavior in Cellular Network Specifications
# 摘要
> 近年来，移动网络安全备受关注，常因底层协议设计缺陷而引发安全漏洞。这些详尽的协议文档可能存在诸多问题，如不准确、未充分指定等。为此，我们推出了CellularLint框架，利用自然语言处理技术，半自动检测4G和5G标准中的不一致性。该框架采用领域适应的大型语言模型，通过改进的少样本学习机制，在预训练的协议语料库上运行，能高效检测多层次的不一致性，极大提升了协议规范的自动化分析能力。我们针对4G和5G的NAS及安全规范进行了深入研究，成功发现157处不一致性，准确率达82.67%。经开源实现和商业设备验证，这些不一致性确实影响设计决策，可能引发隐私、完整性等安全问题。
[Arxiv](https://arxiv.org/abs/2407.13742)
==========
# CoDefeater：借助 LLMs 在保证案例中精准定位反驳证据
发布时间：2024年07月18日
`LLM应用` `安全关键系统` `人工智能`
> CoDefeater: Using LLMs To Find Defeaters in Assurance Cases
# 摘要
> 构建保证案例是确保安全关键系统在其设计环境中安全运行的关键步骤。为了应对潜在的错误和遗漏，我们引入了“失败者”概念，即挑战保证案例中声明的论据或证据。这些失败者能及时揭示论据弱点，推动深入调查和风险缓解。然而，识别失败者需依赖专家的判断和创造力，且需随需求和法规的变化而迭代更新。本文提出的CoDefeater系统，利用大型语言模型自动寻找这些失败者，初步结果表明，LLM能有效发现已知及未预见的失败者，助力安全分析师提升保证案例的完整性和可信度。
[Arxiv](https://arxiv.org/abs/2407.13717)
==========
# 探究直接偏好优化中的参考策略
发布时间：2024年07月18日
`LLM理论` `人工智能` `软件开发`
> Understanding Reference Policies in Direct Preference Optimization
# 摘要
> 直接偏好优化（DPO）在大型语言模型（LLM）的指令微调中应用广泛。本研究深入探讨了DPO依赖参考模型或策略的特性，这些策略通常是待微调的模型，对DPO效果有上限影响。我们探讨了KL散度约束的最佳强度，发现DPO对此敏感；通过理论与实证比较，证明了DPO在指令微调中的必要性及其优势；并发现更强的参考策略能提升性能，但前提是与微调模型相似。这些发现揭示了参考策略在DPO中的复杂作用，为实践提供指导，并指出了未来研究的方向。
[Arxiv](https://arxiv.org/abs/2407.13709)
==========
# 推荐系统全面回顾：跨越理论与实践的桥梁
发布时间：2024年07月18日
`LLM应用` `电子商务` `医疗保健`
> A Comprehensive Review of Recommender Systems: Transitioning from Theory to Practice
# 摘要
> 推荐系统 (RS) 通过个性化建议，极大地提升了用户体验。本次调查从 2017 年至 2024 年全面审视了 RS 的发展，将理论与实践紧密结合。我们追溯了从传统技术如基于内容和协同过滤到现代方法如深度学习、图模型、强化学习及大型语言模型的演进。同时，我们探讨了上下文感知、基于评论和注重公平的特殊系统。本次调查旨在弥合理论与实践的鸿沟，应对电子商务、医疗保健和金融等领域的挑战，强调解决方案需兼具可扩展性、实时性和可信度。通过本次调查，我们加强了学术与行业的合作，旨在指导行业优化 RS 应用，并激发未来研究，特别是应对新兴技术和社会趋势的研究方向。
[Arxiv](https://arxiv.org/abs/2407.13699)
==========
# 通过 Prover-Verifier 游戏，LLM 输出的可读性得到了显著提升。
发布时间：2024年07月18日
`LLM理论` `人工智能`
> Prover-Verifier Games improve legibility of LLM outputs
# 摘要
> 提升大型语言模型 (LLM) 输出可信度的关键在于确保其推理过程清晰且易于核查，我们称之为“可读性”。在解决小学数学问题的场景中，我们发现仅追求答案正确性可能会牺牲思维链解决方案的可读性。为此，我们借鉴 Anil 等人的证明者-验证者游戏，设计了一种训练算法，旨在培养小型验证者判断解题正确性，以及“有帮助的”和“狡猾的”两种证明者：前者产出验证者认可的正确解答，后者则试图误导验证者。训练过程中，我们观察到有帮助的证明者准确度提升，验证者对欺骗行为的抵抗力增强。更有趣的是，这种可读性训练还能惠及人类：在时间压力下，人们核查有帮助证明者解答的准确率上升，而对狡猾证明者的判断则更为准确。这表明，通过小型验证者进行可检查性训练，不仅能提升 LLM 输出的可读性，还可能成为超级智能模型与人类意图对齐的有效策略。
[Arxiv](https://arxiv.org/abs/2407.13692)
==========
# COMCAT：借助人类智慧，提升自动文档与摘要的质量
发布时间：2024年07月18日
`LLM应用` `软件工程` `信息技术`
> COMCAT: Leveraging Human Judgment to Improve Automatic Documentation and Summarization
# 摘要
> 软件维护成本高昂，其中代码理解占据了重要部分。为此，我们推出了COMCAT，一种利用大型语言模型（LLMs）结合专业指导上下文自动生成注释的方法，旨在提升代码的可理解性。COMCAT能够精准选择并生成最相关的注释，适用于C/C++文件，通过自动定位、预测注释类型并生成注释。在实际测试中，COMCAT显著提升了开发者在三个关键软件工程任务中的代码理解能力，高达12%的提升受益于87%的参与者。同时，COMCAT生成的注释在准确性和可读性上不逊于人类作品，且在92%的代码片段中优于ChatGPT的标准注释。此外，我们还发布了一个包含源代码、人类注释及类别标注的数据集，以支持COMCAT在多样化软件工程任务中的应用。
[Arxiv](https://arxiv.org/abs/2407.13648)
==========
# 从弱至强推理
发布时间：2024年07月18日
`LLM应用` `人工智能`
> Weak-to-Strong Reasoning
# 摘要
> 随着大型语言模型 (LLM) 超越人类能力，为其提供全面准确的监督变得愈发困难。弱到强学习策略，即借助较弱模型激发更强模型的潜能，在此背景下显得尤为重要。尽管如此，该策略在复杂推理任务中的效果尚未得到充分检验。此外，在弱到强模式下处理推理任务时，如何避免盲目复制弱监督者的错误，目前仍缺乏有效方法。本文提出了一种渐进式学习框架，允许强大模型自主优化训练数据，无需依赖更高级模型或人工标注。该框架首先在精选的高质量小数据集上进行监督微调，随后通过模型自身识别的对比样本进行偏好优化。实验证明，该方法显著提升了 Llama2-70b 的推理能力，并在前瞻性实验中验证了其有效性。这一研究为提升 AI 推理能力开辟了新的道路。相关代码和资源已公开在 \url{https://github.com/GAIR-NLP/weak-to-strong-reasoning}。
[Arxiv](https://arxiv.org/abs/2407.13647)
==========
# EchoSight：借助维基知识，推动视觉-语言模型的发展
发布时间：2024年07月17日
`LLM应用` `视觉问答` `百科全书`
> EchoSight: Advancing Visual-Language Models with Wiki Knowledge
# 摘要
> KVQA任务要求利用丰富背景知识解答图像相关问题，尽管技术进步显著，但生成模型因外部知识整合不足而常感力不从心。本文推出的EchoSight框架，通过多模态检索增强生成技术，助力大型语言模型精准应对需细致百科知识的视觉问答。EchoSight先以视觉信息搜寻维基文章，再依文本-图像综合查询相关性重排候选文章，大幅提升多模态知识融合，检索效率与VQA准确性双双跃升。实验显示，EchoSight在百科全书VQA与InfoSeek数据集上刷新纪录，分别取得41.8%与31.3%的优异准确率。
[Arxiv](https://arxiv.org/abs/2407.12735)
==========
# Struct-X 利用结构化数据，显著提升大型语言模型的推理性能。
发布时间：2024年07月17日
`LLM应用` `知识图谱` `阅读理解`
> Struct-X: Enhancing Large Language Models Reasoning with Structured Data
# 摘要
> 结构化数据因其丰富的逻辑和关系信息，有望提升大型语言模型（LLM）的推理能力。然而，整合这些数据面临挑战，主要是可能因过多的令牌和无关信息而使LLM不堪重负。为此，我们设计了Struct-X框架，通过“读取-建模-填充-反思-推理”五个阶段，有效利用结构化数据。该框架首先将数据编码至拓扑空间，填补实体信息空白，并剔除无关令牌，最终构建拓扑网络以精简令牌，优化LLM推理。Struct-X还包含辅助模块，生成提示以辅助LLM分析数据。实验证明，Struct-X在知识图谱问答和长文档阅读理解等任务中显著提升LLM推理能力，凸显了结构化数据增强在复杂输入情境下提升LLM推理的有效性。
[Arxiv](https://arxiv.org/abs/2407.12522)
==========
# 迈向协作智能：利用大型语言模型，推动多智能体间的意图交流与协同推理
发布时间：2024年07月17日
`Agent` `人工智能` `多代理系统`
> Towards Collaborative Intelligence: Propagating Intentions and Reasoning for Multi-Agent Coordination with Large Language Models
# 摘要
> 在多代理系统中，有效协作的关键在于代理间目标与意图的沟通。然而，现有框架常因单一代理执行的依赖和模块间通信不足，导致MARL策略不佳和任务协调不力。为此，我们设计了一个框架，利用LLM训练协作代理，以促进合作性MARL中的协调行为。每个代理持有包含当前目标与子任务的私人意图，并定期广播，使其他代理能推断协调任务。通过传播网络，广播的意图被转化为针对特定队友的通信消息，确保目标共享的精准性。框架分为规划、接地和执行三大模块。执行中，代理们在环境中互动并沟通意图，实现协调行为。接地模块根据协调模式动态调整理解策略，执行反馈则驱动规划模块进行子任务的动态重规划。模拟结果显示，意图传播有效减少了协调错误，代理们学会了何时沟通及向谁提供任务细节，从而促成了协调行为的涌现。这充分展示了基于LLM的意图共享在合作性多代理RL中的强大效能。
[Arxiv](https://arxiv.org/abs/2407.12532)
==========
# PersLLM：为大型语言模型量身定制的个性化训练之道
发布时间：2024年07月17日
`LLM应用` `人机交互` `多智能体协作`
> PersLLM: A Personified Training Approach for Large Language Models
# 摘要
> 大型语言模型（LLMs）在模拟人类智能方面表现出色，使其在社交模拟、人机交互和多智能体协作等领域中扮演类似人类的角色。然而，LLMs缺乏鲜明的个性特征，如讨好行为、观点不一致和回应模式单一，这限制了其在实际应用中的效用。为此，研究LLMs的个性特征开发成为解锁其潜力的关键。现有方法如风格化训练数据和提示工程虽尝试赋予LLMs个性，但仅触及表面，不够稳定。本研究提出PersLLM，结合心理学原理，将社会实践、一致性和动态发展融入训练方法，直接在模型参数中嵌入个性特征，增强抗诱导性、一致性和个性动态演化。单智能体评估显示，PersLLM生成的回应更贴合参考个性，优于其他方法。多智能体通信案例研究表明，PersLLM在提升个体智能体观点一致性和促进多智能体协作创造力方面表现出色，有望增强人类模拟和多智能体合作。人-智能体交互评估进一步证实，PersLLM显著提升了交互体验，凸显了研究的实际价值。
[Arxiv](https://arxiv.org/abs/2407.12393)
==========
# NavGPT-2：激发大型视觉-语言模型的导航推理潜能
发布时间：2024年07月17日
`Agent` `机器人` `人工智能`
> NavGPT-2: Unleashing Navigational Reasoning Capability for Large Vision-Language Models
# 摘要
> 随着大型语言模型 (LLM) 的显著进步，利用 LLM 进行指令跟随机器人导航的倡议正蓬勃发展。这一趋势凸显了 LLM 在泛化导航推理和多样化语言理解方面的潜力。然而，在 VLN 任务中集成 LLM 时，代理性能与专业模型相比存在显著差异。此外，语言在代理交互中的沟通能力往往未得到充分利用。本研究旨在弥合 VLN 专业模型与基于 LLM 的导航范式之间的差距，同时保持 LLM 在语言导航推理方面的解释能力。通过在冻结的 LLM 中对齐视觉内容，我们实现了 LLM 的视觉观察理解，并探索了将 LLM 与导航策略网络结合的有效方法，以提升动作预测和导航推理的效率。我们展示了所提出方法的数据效率，并消除了基于 LM 的代理与最先进的 VLN 专家之间的性能差距。
[Arxiv](https://arxiv.org/abs/2407.12366)
==========
# VisionTrap：结合文本描述，增强视觉引导的轨迹预测技术
发布时间：2024年07月17日
`Agent` `自动驾驶` `计算机视觉`
> VisionTrap: Vision-Augmented Trajectory Prediction Guided by Textual Descriptions
# 摘要
> 为自动驾驶车辆预测其他道路代理的未来轨迹是一项关键任务。传统方法主要依赖于检测和跟踪系统生成的轨迹及高清地图。我们提出了一种创新方法，不仅利用这些数据，还引入了环视摄像机的视觉输入，使模型能捕捉到人类目光、手势、道路状况及车辆信号等细节。此外，我们通过视觉-语言模型生成的文本描述，并由大型语言模型进一步细化，来指导模型学习。尽管增加了这些输入，我们的方法仍能以53毫秒的低延迟实现实时处理，远超同类方法。实验证明，视觉和文本输入均有效提升预测性能。我们还发布了nuScenes-Text数据集，通过丰富的文本注释增强了nuScenes数据集，展示了VLM在轨迹预测中的潜力。项目详情见https://moonseokha.github.io/VisionTrap/。
[Arxiv](https://arxiv.org/abs/2407.12345)
==========
# MoME：多模态专家的融合，打造全能型多模态大型语言模型
发布时间：2024年07月17日
`LLM应用` `计算机视觉`
> MoME: Mixture of Multimodal Experts for Generalist Multimodal Large Language Models
# 摘要
> 多模态大型语言模型 (MLLMs) 在视觉-语言任务中表现出色，但通用 MLLM 在多数任务上仍不及专业模型，主要因任务干扰所致。为此，我们提出多模态专家混合 (MoME)，包含视觉专家混合 (MoVE) 和语言专家混合 (MoLE)，旨在减轻干扰并提升通用 MLLM 性能。MoVE 能自适应调节视觉特征，而 MoLE 则通过稀疏门控专家实现低成本改进。MoME 专为视觉和语言模态设计，以适应任务差异。实验证明，MoME 大幅提升了通用 MLLMs 的性能。源代码已公开于 https://github.com/JiuTian-VL/MoME。
[Arxiv](https://arxiv.org/abs/2407.12709)
==========
# E5-V：借助多模态大型语言模型实现通用嵌入
发布时间：2024年07月17日
`LLM应用` `人工智能` `计算机视觉`
> E5-V: Universal Embeddings with Multimodal Large Language Models
# 摘要
> 多模态大型语言模型 (MLLMs) 在视觉和语言理解方面取得了显著进展，但如何有效表示多模态信息仍待深入研究。为此，我们推出了新框架 E5-V，专门设计用于优化 MLLMs 以实现通用多模态嵌入。研究表明，MLLMs 在处理多模态输入方面潜力巨大，通过结合提示，E5-V 成功缩小了不同输入间的模态差异，展现出卓越的多模态嵌入能力，无需额外微调。我们采用单一模态训练策略，仅使用文本对进行模型训练，不仅大幅提升了性能，还节省了约 95% 的训练成本，并免除了复杂的多模态数据收集。跨多种任务的实验充分验证了 E5-V 的高效性，使其在众多领域不仅达到甚至超越了顶尖水平，即便仅基于单一模态训练。
[Arxiv](https://arxiv.org/abs/2407.12580)
==========
# MERLIN：通过基于 LLM 的迭代导航优化多模态嵌入，专为文本-视频检索重排流程设计
发布时间：2024年07月17日
`LLM应用` `多媒体` `搜索引擎`
> MERLIN: Multimodal Embedding Refinement via LLM-based Iterative Navigation for Text-Video Retrieval-Rerank Pipeline
# 摘要
> 随着多媒体内容的迅猛增长，从庞大的视频库中精准检索相关内容变得愈发困难。尽管当前的文本-视频检索技术在跨模态交互、大规模模型训练等方面取得了进展，但往往忽略了用户视角，使得检索结果与用户需求不符。为此，我们推出了MERLIN系统，该系统无需额外训练，通过大型语言模型进行迭代反馈，从用户角度优化查询嵌入，通过动态问答机制提升查询与视频内容的一致性。实验显示，MERLIN在多个数据集上大幅提升了检索准确率，证明了其在多模态检索领域的优越性，为实现更智能、更贴合用户需求的多媒体检索提供了新思路。
[Arxiv](https://arxiv.org/abs/2407.12508)
==========
# 从少样本学习的角度审视多模态LLM的语言能力
发布时间：2024年07月17日
`LLM应用` `人工智能` `计算机视觉`
> Evaluating Linguistic Capabilities of Multimodal LLMs in the Lens of Few-Shot Learning
# 摘要
> 多模态大型语言模型（MLLMs）的语言能力对其广泛应用至关重要。本研究评估了 MLLMs 在 VALSE 基准上的表现，特别关注少样本 In-Context Learning（ICL）和 Chain-of-Thought（CoT）提示的效果。我们全面评估了不同大小和预训练数据集的先进 MLLMs。实验表明，ICL 和 CoT 提示显著提升模型性能，尤其是在复杂推理和上下文理解任务中。预训练于字幕数据集的模型零-shot 性能优异，而基于交错图像-文本数据的模型则受益于少样本学习。研究结果揭示了优化 MLLMs 以增强视觉上下文中的语言定位的重要性，强调了预训练数据组合的关键作用及少样本学习策略在提升 MLLMs 推理能力方面的潜力。
[Arxiv](https://arxiv.org/abs/2407.12498)
==========
# F-HOI：致力于实现细粒度语义对齐的3D人-物交互研究
发布时间：2024年07月17日
`LLM应用` `计算机视觉` `人工智能`
> F-HOI: Toward Fine-grained Semantic-Aligned 3D Human-Object Interactions
# 摘要
> 当前的3D人体物体交互（HOI）数据集和模型仅简单地将全局描述与长HOI序列对齐，忽视了中间状态及其转换的细节。本文提出，采用状态级描述的细粒度语义对齐是一种有前景的学习方法，能丰富HOI的语义表示。为此，我们创建了Semantic-HOI数据集，包含超过20,000对HOI状态，每个状态都有详尽描述及状态间身体运动的细节。基于此，我们设计了三个任务，专注于HOI序列内的细粒度语义对齐。同时，我们提出了F-HOI模型，该模型能整合多模态指令，增强多模态大型语言模型处理HOI任务的能力。F-HOI的优势包括：支持多样多模态输入、在不同空间保持HOI一致性、通过细粒度文本监督直接优化，避免复杂状态建模。实验证明，F-HOI在HOI状态与语义描述的对齐上表现出色，能有效应对理解、推理、生成和重建等多种任务。
[Arxiv](https://arxiv.org/abs/2407.12435)
==========
# ProcTag：评估文档指令数据效能的过程标记工具
发布时间：2024年07月17日
`LLM应用` `文档处理` `数据评估`
> ProcTag: Process Tagging for Assessing the Efficacy of Document Instruction Data
# 摘要
> 近期，大型语言模型（LLMs）与多模态大型语言模型（MLLMs）在文档视觉问答（VQA）任务上表现出色，尤其是在文档指令数据集的训练后。构建高效能的指令数据，关键在于一个有效的评估方法。然而，现有方法多聚焦于指令文本，限制了数据集的评估与构建。为此，我们提出ProcTag，一种创新的数据评估方法，它通过对指令执行过程的标记来评估数据效能，从而实现对文档指令的精准采样或过滤。同时，我们引入了DocLayPrompt，一种半结构化布局感知的文档提示策略，以优化文档表示。实验结果显示，ProcTag在评估指令数据方面超越了现有方法，特别是在生成的文档数据集中，仅需30.5%的指令即可达到完整数据集的100%效能。相关代码已在GitHub公开发布。
[Arxiv](https://arxiv.org/abs/2407.12358)
==========
# MEDFuse：结合掩蔽实验室测试建模与大型语言模型，实现多模态电子健康记录数据的高效融合。
发布时间：2024年07月17日
`LLM应用` `电子健康记录`
> MEDFuse: Multimodal EHR Data Fusion with Masked Lab-Test Modeling and Large Language Models
# 摘要
> 电子健康记录 (EHRs) 天然具备多模态特性，涵盖结构化数据如实验室检测和非结构化内容如临床笔记。在临床实践中，医生通过综合多模态 EHR 数据源来更全面地评估患者健康并辅助决策。然而，现有 EHR 预测模型往往忽视了模态间的交互与冗余，或仅聚焦于单一模态。为此，我们研发了 MEDFuse 框架，它融合了掩蔽实验室测试建模与大型语言模型 (LLMs)，有效整合了医疗数据的结构化与非结构化部分。MEDFuse 通过微调的 LLMs 和训练有素的掩蔽表格变换器提取多模态嵌入，并设计了解耦变换器模块，通过互信息损失优化，分离模态特定与共享信息，同时从临床笔记的噪声中提炼有用信息。经 MIMIC-III 和 FEMH 数据集验证，MEDFuse 在提升临床预测准确性方面表现卓越，10 疾病多标签分类任务中 F1 分数超 90%。
[Arxiv](https://arxiv.org/abs/2407.12309)
==========
# RoDE：专为食品领域大型多模态模型设计的线性整流混合多样专家系统
发布时间：2024年07月17日
`LLM应用` `营养分析`
> RoDE: Linear Rectified Mixture of Diverse Experts for Food Large Multi-Modal Models
# 摘要
> 大型多模态模型（LMMs）在视觉-语言任务中取得了显著进步，其中高质量训练数据的可用性和可扩展性至关重要。在食品领域，尽管Recipe1M等数据集提供了丰富的食材和食谱信息，但在营养分析方面数据不足。为此，我们推出了Uni-Food数据集，包含超过100,000张图像，涵盖食物类别、食材、食谱及营养信息，旨在全面提升食品数据分析。为解决LMMs微调中的多任务冲突，我们创新性地提出了线性校正多样化专家混合（RoDE）方法，通过多样化专家团队处理不同复杂任务，优化参数分配，提升任务分配效率，确保GPU内存高效和优化简便。实验证明，RoDE有效应对了食品多任务的挑战。
[Arxiv](https://arxiv.org/abs/2407.12730)
==========
# NL2Contact：借助扩散模型，通过自然语言引导实现3D手-物体接触的精准建模。
发布时间：2024年07月17日
`LLM应用` `计算机视觉` `机器人学`
> NL2Contact: Natural Language Guided 3D Hand-Object Contact Modeling with Diffusion Model
# 摘要
> 在3D手-物体重建中，通过建模手与物体的物理接触来精炼手部姿势并生成新颖抓握是常规做法。然而，现有技术依赖于难以指定或控制的几何约束。本文提出了一项创新任务：利用自然语言描述进行可控的3D手-物体接触建模。面临的挑战包括跨模态建模的复杂性以及缺乏对接触模式的详细描述。为此，我们设计了NL2Contact模型，该模型通过分阶段扩散模型生成可控的接触。输入手和接触的描述，NL2Contact即可生成逼真的3D手-物体接触。我们还创建了首个以手为中心的接触描述数据集\textit{ContactDescribe}，包含多层次、多样化的描述，这些描述由大型语言模型根据精心设计的提示生成。我们的模型在抓握姿势优化和新型人类抓握生成方面展现了应用潜力，均基于文本接触描述。
[Arxiv](https://arxiv.org/abs/2407.12727)
==========
# 大语言模型中的讽刺检测是否遵循一个逐步推理的过程？
发布时间：2024年07月17日
`LLM应用` `人工智能`
> Is Sarcasm Detection A Step-by-Step Reasoning Process in Large Language Models?
# 摘要
> 通过详细展示一系列推理步骤，大型语言模型 (LLM) 解决复杂问题的能力得到显著提升。然而，人类的讽刺理解被视为一种直观的整体认知过程，涉及语言、上下文和情感线索的综合，以洞察说话者的真实意图，这一过程被认为超越了线性推理。为验证这一观点，我们设计了 SarcasmCue 框架，包含四种创新提示策略：矛盾链 (CoC)、线索图 (GoC)、线索包 (BoC) 和线索张量 (ToC)，旨在通过顺序与非顺序方法激发 LLM 识别讽刺。实证研究表明，这些方法在四个基准数据集上显著超越传统提示技术，且非顺序方法表现更佳。
[Arxiv](https://arxiv.org/abs/2407.12725)
==========
# 未来学习：学生视角下的大型语言模型探索
发布时间：2024年07月17日
`LLM应用` `人工智能`
> The Future of Learning: Large Language Models through the Lens of Students
# 摘要
> 随着LLMs的持续进步，它们在性能和功能上的显著提升正影响着教育等多个领域。我们通过对14名学生的访谈，揭示了他们在与ChatGPT互动时面临的困境：一方面享受其高效的学习辅助，另一方面则担忧其结果的可靠性和伦理问题。学生们感受到ChatGPT比传统AI更“人性化”，这种复杂的情感体验暗示了其在教育中的潜在价值。尽管如此，我们强调，这种高级智能的人性化特质虽吸引人，但其强大能力也可能带来负面影响。因此，在应用时需谨慎，并致力于在未来发展中降低潜在风险。
[Arxiv](https://arxiv.org/abs/2407.12723)
==========
# 大型语言模型的补丁级训练
发布时间：2024年07月17日
`LLM理论` `人工智能` `软件开发`
> Patch-Level Training for Large Language Models
# 摘要
> 随着 LLM 在语言理解和生成领域的显著进步，其训练效率成为焦点。传统 LLM 训练侧重于预测下一个标记，虽成功但计算成本高昂。为此，本文提出补丁级训练，通过压缩标记为补丁来缩短序列，降低计算成本。实验显示，此方法在不损性能的前提下，将成本减半。源码见：\url{https://github.com/shaochenze/PatchTrain}。
[Arxiv](https://arxiv.org/abs/2407.12665)
==========
# 借助 LLM 引导，实现零-shot 文本驱动的无限图像合成
发布时间：2024年07月17日
`LLM应用` `图像处理` `人工智能`
> Zero-shot Text-guided Infinite Image Synthesis with LLM guidance
# 摘要
> 文本引导的图像编辑与生成技术应用广泛，但无限图像合成仍面临挑战。首先，高分辨率且上下文多样的文本-图像配对数据稀缺。其次，基于文本的图像扩展需全局连贯与细致的局部理解。传统研究多聚焦于特定类别，如自然景观，且依赖高分辨率配对数据训练。为此，我们创新地运用大型语言模型（LLM），无需高分辨率配对数据，实现全局连贯与局部理解。训练扩散模型时，我们依据LLM生成的全局与局部描述及视觉特征扩展图像。推理时，结合图像与全局描述，LLM生成局部描述以扩展图像，确保全局一致与空间局部细节。实验证明，我们的模型在数量与质量上均超越基线，并能在LLM引导下零-shot生成任意尺寸的文本引导图像。
[Arxiv](https://arxiv.org/abs/2407.12642)
==========
# ARTEMIS：一款结合模拟与随机技术的DRAM加速器，专为Transformer神经网络设计。
发布时间：2024年07月17日
`LLM理论` `半导体` `计算机硬件`
> ARTEMIS: A Mixed Analog-Stochastic In-DRAM Accelerator for Transformer Neural Networks
# 摘要
> Transformer 模型通过其注意力机制，在 NLP 和计算机视觉领域展现出超越传统 RNN 和 CNN 的显著性能优势。然而，其庞大的计算量和内存需求导致执行时间较长。内存内处理 (PIM) 和近内存计算 (NMC) 因其高并行性和带宽成为加速 Transformer 的潜在方案，但设计支持复杂操作和数据移动的 PIM/NMC 架构仍具挑战。为此，我们设计了 ARTEMIS，一种结合模拟与随机计算的 DRAM 加速器，通过最小化对传统 DRAM 的改动，有效降低了 Transformer 模型的执行成本。实验数据显示，ARTEMIS 在速度、能耗和能效方面均优于现有 GPU、TPU、CPU 及 PIM 加速器，分别至少提升 3.0 倍、降低 1.8 倍和提高 1.9 倍。
[Arxiv](https://arxiv.org/abs/2407.12638)
==========
# 借助人工智能之力，振兴濒危土著语言：探索技术与实践
发布时间：2024年07月17日
`LLM应用` `语言保护` `人工智能`
> Harnessing the Power of Artificial Intelligence to Vitalize Endangered Indigenous Languages: Technologies and Experiences
# 摘要
> 自2022年起，我们致力于探索AI与NLP技术，特别是LLM，如何助力濒危土著语言的保护与记录。我们首先探讨了全球语言多样性的减少，以及与土著语言合作带来的独特伦理挑战。为此，我们提出了一种以社区为中心的AI发展新模式。接着，我们分享了通过微调SOTA翻译器，仅用少量数据就成功开发出高质量土著语言翻译器的经验，并提供了避免常见问题的策略。此外，我们还介绍了与巴西土著社区合作的项目中开发的原型，旨在提升写作便利性，并探讨了ILM作为创建拼写检查和词预测工具的可行途径。最终，我们展望了一个未来，濒危语言将以交互式语言模型的形式得到保存，为语言记录开辟新篇章。
[Arxiv](https://arxiv.org/abs/2407.12620)
==========
# AudienceView：借助AI技术，深入解读新闻观众反馈
发布时间：2024年07月17日
`LLM应用` `新闻传媒` `数据分析`
> AudienceView: AI-Assisted Interpretation of Audience Feedback in Journalism
# 摘要
> 记者面对海量在线评论时，理解和利用受众反馈变得尤为重要且困难。为此，我们推出了 AudienceView 这一在线工具，借助大型语言模型帮助记者高效分类和解读反馈。该工具不仅能识别评论中的主题和话题，还能将其与具体评论关联，提供情感和分布的可视化展示，助力记者构思后续报道。我们强调，这类工具虽有助于提升工作效率，但情境意识和人类判断仍不可或缺。
[Arxiv](https://arxiv.org/abs/2407.12613)
==========
# 探秘阴谋论：TikTok 上的隐秘角落
发布时间：2024年07月17日
`LLM应用` `社交媒体` `内容管理`
> Conspiracy theories and where to find them on TikTok
# 摘要
> TikTok 凭借其病毒式趋势和社会挑战，在年轻群体中迅速走红。然而，其推广和放大有害内容的潜力引发了担忧。通过分析三年间美国分享的 150 万视频，我们的研究发现，约 0.1% 的视频涉及阴谋论，并探讨了新创作者计划对这类内容的影响。我们发现，最先进的大型语言模型能高精度识别有害内容，但性能与传统微调模型相当。这些发现对制定 TikTok 等平台的内容管理策略至关重要，有助于遏制有害内容的传播。
[Arxiv](https://arxiv.org/abs/2407.12545)
==========
# 精雕细琢路径：强化信息检索中的查询重写能力
发布时间：2024年07月17日
`LLM应用` `信息检索` `搜索引擎`
> Crafting the Path: Robust Query Rewriting for Information Retrieval
# 摘要
> 查询重写的目标是生成一个新查询，以补充原始查询，从而提升信息检索系统的性能。近期研究如Q2D、Q2E和Q2C，依赖于大型语言模型的内部知识来生成相关段落，以丰富查询内容。然而，当所需知识未被模型固有参数包含时，这些方法的效果可能大打折扣。为此，我们提出了一种名为“定制路径”的新型结构化查询重写方法，专为检索系统量身打造。该方法通过三步流程，逐步构建查询相关信息，以精准定位搜索段落。具体步骤包括：查询概念理解、查询类型识别和预期答案提取。实验表明，我们的方法在LLM不太熟悉的领域表现尤为出色，且对模型内部参数的依赖性较低，生成的查询错误更少。此外，与基线方法相比，“定制路径”的延迟更低。
[Arxiv](https://arxiv.org/abs/2407.12529)
==========
# 利用预训练嵌入初始化 Transformer 模型
发布时间：2024年07月17日
`LLM理论` `人工智能`
> On Initializing Transformers with Pre-trained Embeddings
# 摘要
> 如今，在从头开始训练基于transformer的模型时，采用随机初始化而非预训练嵌入已成为常态。我们发现，GloVe、T5和mT5的预训练嵌入在性能上远不如随机初始化，这与预训练的表示优势相悖。然而，BERT和mBERT的嵌入却显示出优于随机初始化的效果，突显了预训练的优势。我们推测，造成这种差异的两个关键因素是模型对参数分布的敏感性以及嵌入与位置编码的相互作用。预训练嵌入的广泛值分布可能导致训练不良，且可能掩盖位置信息。通过将这些嵌入标准化至较窄范围，我们显著提升了GloVe、T5和mT5的性能。而BERT嵌入虽大，却仍接近Xavier初始化范围，这或许有助于其有效迁移预训练知识。
[Arxiv](https://arxiv.org/abs/2407.12514)
==========
# Case2Code：借助合成数据掌握归纳推理技巧
发布时间：2024年07月17日
`LLM应用` `软件开发` `人工智能`
> Case2Code: Learning Inductive Reasoning with Synthetic Data
# 摘要
> 大语言模型（LLM）在复杂推理方面表现出色，尤其擅长演绎推理，如通过思维链或工具迭代解决难题。本文聚焦于评估和培养LLM的归纳推理能力，即通过观察实例推断规则。收集大规模多样化的归纳数据颇具挑战，因此我们转向代码领域，提出**Case2Code**任务，利用程序的表达性和准确性。我们收集多样程序，合成输入输出转换，并引导LLM推断代码实现。实验表明，Case-to-code归纳对LLM颇具挑战，但通过合成训练样本，LLM不仅提升了Case2Code性能，还增强了编码技能，凸显了合成数据在归纳推理学习中的潜力。
[Arxiv](https://arxiv.org/abs/2407.12504)
==========
# 计算模型：自动化识别还是辅助分析？探讨其在美资本审判笔录性别话语中的角色。
发布时间：2024年07月17日
`LLM应用` `人工智能`
> Automate or Assist? The Role of Computational Models in Identifying Gendered Discourse in US Capital Trial Transcripts
# 摘要
> 长期以来，美国刑事审判中使用的语言因其潜在的偏见而受到关注。然而，由于偏见的复杂性和法律专业知识的必要性，系统性地研究高风险审判中的偏见一直颇具挑战。新兴的大型语言模型为自动化注释带来了希望，有望节省时间和成本。但要确保这些方法的有效性，不仅需要高水平的性能，还需深入理解它们如何融入现有工作流程及其真正的价值所在。本文通过一个案例研究，探讨了在识别针对女性被告的性别偏见语言这一高风险问题中引入自动化系统的可行性。我们的团队由资深死刑律师和NLP专家组成，分三阶段进行研究：先手动注释，再训练评估模型，最后对比人工与模型的结果。与常规NLP任务不同，对长时间死刑审判中的性别偏见进行注释极为复杂，涉及众多个人判断。法律专家发现，计算模型在挑战个人偏见、促进注释规则的完善与共识构建方面尤为有效。这表明，完全依赖模型取代专家既不现实也不可取，计算模型应作为辅助工具，为法律专家提供支持。
[Arxiv](https://arxiv.org/abs/2407.12500)
==========
# 印度语言大型模型的预训练数据与分词器
发布时间：2024年07月17日
`LLM应用` `语言处理` `数据准备`
> Pretraining Data and Tokenizer for Indic LLM
# 摘要
> 我们创新性地提出了一种数据准备方法，旨在构建多语种印度大语言模型。通过广泛采集开源及专有资源，如Common Crawl、印度书籍、新闻与维基百科，确保语言数据的多样性与丰富性。针对每种印度语言，我们量身定制预处理流程，剔除冗余与低质内容。同时，对Common Crawl数据进行去重，解决其70%网页的冗余问题。本研究致力于打造高质量数据，并优化标记化策略，以提升3B和7B参数印度大模型的性能。我们首创的多语种标记器训练方法，证实了定制印度标记器在词标记比上超越了OpenAI的Tiktoken，为印度语言处理带来更佳表现。
[Arxiv](https://arxiv.org/abs/2407.12481)
==========
# 在解答健康问题时，我们应选择搜索引擎、大型语言模型，还是两者结合？本文将评估这些信息寻求策略的有效性。
发布时间：2024年07月17日
`RAG` `搜索引擎`
> Search Engines, LLMs or Both? Evaluating Information Seeking Strategies for Answering Health Questions
# 摘要
> 传统搜索引擎一直是信息检索的核心工具，但新型大型语言模型（LLM）在多任务处理中表现出色，尤其在问答系统领域日益普及。未来，基于LLM的对话系统与传统网络引擎预计将并存，以不同方式服务用户。本研究聚焦于这两类系统在解答健康问题上的表现，通过对比不同搜索引擎、LLM及检索增强（RAG）方法，我们发现：尽管网页质量在排名靠后时未见下降，但LLM在准确回答健康问题上优于传统引擎。同时，LLM对输入提示极为敏感，而RAG则显著提升了信息检索的效率。
[Arxiv](https://arxiv.org/abs/2407.12468)
==========
# 探索生成：利用大型语言模型，设想 AI 技术的应用与潜在风险
发布时间：2024年07月17日
`LLM应用` `人工智能`
> ExploreGen: Large Language Models for Envisioning the Uses and Risks of AI Technologies
# 摘要
> 负责任的AI设计日益成为AI开发者和合规专家的当务之急。设想AI技术的使用与风险是关键任务之一，但因其挑战性，AI从业者常感棘手。我们通过利用大型语言模型（LLM），如ExploreGen框架，助力从业者在AI开发的早期阶段进行反思、创意激发和深思熟虑。ExploreGen不仅生成现实且多元的AI应用场景，还根据欧盟AI法规准确评估风险。通过面部识别技术的案例研究，我们验证了ExploreGen的有效性，得到了从业者的高度评价：使用场景真实，风险评估精准（94.5%），且具有高度的采纳潜力和深远影响。
[Arxiv](https://arxiv.org/abs/2407.12454)
==========
# ClearCLIP：解析 CLIP 表征，助力密集视觉-语言推理
发布时间：2024年07月17日
`LLM应用` `计算机视觉` `语义分割`
> ClearCLIP: Decomposing CLIP Representations for Dense Vision-Language Inference
# 摘要
> 尽管CLIP等大规模预训练视觉-语言模型在开放词汇任务中表现出色，但在语义分割领域仍面临挑战，常产生含噪声的分割图。本文深入分析CLIP架构，发现残差连接是主要噪声源。通过对比分析，揭示CLIP的图像-文本对比训练偏重全局特征而忽视局部细节，影响分割质量。为此，我们创新提出ClearCLIP方法，通过调整CLIP表示结构，优化分割效果。具体措施包括移除残差连接、引入自注意力机制及简化前馈网络。实验证明，ClearCLIP能生成更清晰准确的分割图，并在多基准测试中领先，凸显了研究的重要性。
[Arxiv](https://arxiv.org/abs/2407.12442)
==========
# 探索多模态数据入口的语义感知表示：文献回顾
发布时间：2024年07月17日
`LLM应用` `数据管理` `机器学习`
> Semantic-Aware Representation of Multi-Modal Data for Data Ingress: A Literature Review
# 摘要
> 机器学习正不断深入众多应用领域，生成式AI如大型语言模型也广泛用于处理多模态数据。尽管训练数据集日益庞大，但高效管理这些数据已成为行业挑战——数据量倍增并不等于质量倍增。理解数据湖的内在质量和多样性对特定应用ML和基础模型微调至关重要。此外，时间序列数据的时间维度增加了从数据湖中检索信息的复杂性。本研究探索从单模态到跨模态数据中提取嵌入的语义感知技术，以提升数据湖的检索能力。文章总结了嵌入技术在三种数据模态应用中的最新进展。
[Arxiv](https://arxiv.org/abs/2407.12438)
==========
# Sharif-STR 在 SemEval-2024 任务 1 中，采用 Transformer 作为回归模型，对文本语义关系进行精细评分。
发布时间：2024年07月17日
`LLM应用` `多语言技术`
> Sharif-STR at SemEval-2024 Task 1: Transformer as a Regression Model for Fine-Grained Scoring of Textual Semantic Relations
# 摘要
> 语义文本相关性在自然语言处理领域至关重要，应用广泛。传统方法多基于知识和统计，但大型语言模型的兴起带来了新变革。本文通过微调RoBERTa模型，深入探讨了监督学习下的句子级STR。我们评估了该方法在多语言中的效果，发现其在拉丁语系中表现出色，尤其在英语中相关性达0.82，排名第19；西班牙语中相关性为0.67，排名第15。但在阿拉伯语中，相关性仅0.38，排名第20，显示出挑战。
[Arxiv](https://arxiv.org/abs/2407.12426)
==========
# 穿梭于喧嚣之中，探寻声明验证的关键信息
发布时间：2024年07月17日
`LLM应用` `信息安全` `人工智能`
> Navigating the Noisy Crowd: Finding Key Information for Claim Verification
# 摘要
> 声明验证任务旨在基于多重证据评估声明的真实性。利用大型语言模型 (LLM) 进行此任务颇具前景，但仅将所有证据输入 LLM 并询问声明真实性效果不佳。问题在于证据与声明的噪声特性：证据常含无关信息，关键事实隐匿于上下文，声明则多面并存。为应对这一“信息噪声”，我们设计了 EACon（证据抽象与声明解构）框架，旨在提炼证据中的关键信息并逐一验证声明的各个方面。EACon 先从声明中提取关键词，通过模糊匹配筛选出各证据的相关关键词，以此为线索提炼并概括关键信息为抽象证据。接着，EACon 将原声明分解为子声明，分别与抽象及原始证据对照验证。我们在两个挑战性数据集上使用两个开源 LLM 评估 EACon，结果显示 EACon 持续显著提升 LLM 在声明验证中的表现。
[Arxiv](https://arxiv.org/abs/2407.12425)
==========
# StuGPTViz：探索学生与ChatGPT互动的可视化分析工具
发布时间：2024年07月17日
`LLM应用` `人工智能`
> StuGPTViz: A Visual Analytics Approach to Understand Student-ChatGPT Interactions
# 摘要
> 将ChatGPT等大型语言模型融入教育，正通过创新的对话学习方式重塑学习体验。为使学生充分运用ChatGPT，教师需深入理解其交互模式。面对缺乏相关数据集及分析交互演变的复杂性，我们收集了48名硕士生与ChatGPT的对话数据，并基于认知与主题分析文献制定了编码方案，分类交互模式。我们开发的StuGPTViz系统，通过多尺度追踪与比较学生提示及ChatGPT响应质量，为教师提供了宝贵见解。通过专家访谈与案例研究，我们验证了StuGPTViz的有效性，确认其能深化教育者对ChatGPT教学价值的认识。此外，我们还探讨了在教育中应用可视化分析及开发AI个性化学习方案的研究前景。
[Arxiv](https://arxiv.org/abs/2407.12423)
==========
# TurkishMMLU：探索土耳其语中的大规模多任务语言理解能力
发布时间：2024年07月17日
`LLM应用` `语言处理`
> TurkishMMLU: Measuring Massive Multitask Language Understanding in Turkish
# 摘要
> 我们推出了首个多任务的土耳其多选QA基准——TurkishMMLU，旨在评估大型语言模型（LLMs）对土耳其语的理解。该基准包含超过10,000个问题，覆盖土耳其高中课程的9大科目，由专家精心编写，适合当地教育体系。我们评估了20多个模型，包括开源、闭源及土耳其本土适配模型，并进行了全面的性能分析，涵盖零-shot、少-shot学习、思维链推理及问题难度评估。通过深入剖析，我们揭示了当前LLMs在土耳其语处理上的优势与不足，为未来发展提供参考。相关代码已公开发布于：https://github.com/ArdaYueksel/TurkishMMLU。
[Arxiv](https://arxiv.org/abs/2407.12402)
==========
# Mamba-PTQ：探究循环大型语言模型中的异常通道
发布时间：2024年07月17日
`LLM理论` `人工智能` `计算机科学`
> Mamba-PTQ: Outlier Channels in Recurrent Large Language Models
# 摘要
> 现代循环层在大型语言模型（LLM）的边缘部署中展现出巨大潜力。通过有限维表示压缩输入序列，循环层不仅能处理长距离依赖，还能保持推理成本和内存需求的恒定。然而，在资源受限环境中部署LLM时，常需进一步压缩模型，如量化和剪枝。尽管这些技术在基于注意力的模型中已成熟，但对循环层的影响尚待深入研究。  本研究初步探讨了循环LLM的训练后量化，发现Mamba模型中的异常通道现象与基于注意力的LLM相似。我们揭示了量化SSM的难点源于激活异常值，这与transformer模型中的情况类似。我们提供了忽略激活异常值的量化基线结果，并提出了针对异常值的量化初步方案。
[Arxiv](https://arxiv.org/abs/2407.12397)
==========
# LLM 推理服务：探索最新进展与未来机遇
发布时间：2024年07月17日
`LLM理论` `机器学习` `系统优化`
> LLM Inference Serving: Survey of Recent Advances and Opportunities
# 摘要
> 本调查深入探讨了2023年后大型语言模型（LLM）服务系统的最新进展，聚焦于在不改动核心解码机制的前提下，如何通过系统级优化提升性能与效率。我们精选并评析了来自顶尖机器学习与系统会议的优质论文，突出了在现实生产环境中部署和扩展LLM的关键创新点及实用考量。这份调查报告是LLM从业者紧跟行业脉搏、掌握前沿动态的宝贵指南。
[Arxiv](https://arxiv.org/abs/2407.12391)
==========
# 借助检索文档的指引，优化对话查询
发布时间：2024年07月17日
`LLM应用` `问答系统` `搜索引擎`
> Conversational Query Reformulation with the Guidance of Retrieved Documents
# 摘要
> 对话搜索旨在为对话问答（ConvQA）中的问题检索相关段落，但面临省略和指代等难题。为此，对话查询重构（CQR）应运而生，将查询转换为去上下文形式。然而，现有CQR方法虽重写人类友好查询，却未必总能产生最佳搜索结果。为此，我们推出GuideCQR框架，利用引导文档优化查询，确保其对检索器最优。具体操作包括增强关键词、从重排文档中生成预期答案，并结合过滤过程。实验表明，引导文档增强的查询性能更佳，尤其在不同设置下，GuideCQR超越了LLM提示驱动方法，凸显了引导文档在制定检索器友好查询中的关键作用。
[Arxiv](https://arxiv.org/abs/2407.12363)
==========
# SENTAUR：利用 LLM 提升对抗不良修订的安全特洛伊评估
发布时间：2024年07月17日
`LLM应用` `半导体` `网络安全`
> SENTAUR: Security EnhaNced Trojan Assessment Using LLMs Against Undesirable Revisions
# 摘要
> 全球IC供应链因不可信第三方而充满风险，涉及硬件木马（HT）、知识产权（3P-IP）或电子设计自动化（EDA）流程。HT可能导致隐秘行为、功能障碍或敏感数据泄露。为应对HT威胁，快速检测HT场景至关重要。Trust-Hub基准虽为评估起点，但仅涵盖少数手动HT。HT在合成中可能消失。我们提出LLM框架SENTAUR，通过学习RTL设计规范和HT描述，生成合法HT。现有工具需学习期且难以重现。SENTAUR利用LLM即时生成HT，无需学习期，简化评估。评估显示SENTAUR能生成有效、可合成HT，并研究RTL级影响。虽聚焦HT插入，SENTAUR亦可自动修改RTL代码功能。
[Arxiv](https://arxiv.org/abs/2407.12352)
==========
# 机器个性的光明面：探讨个性与大型语言模型安全性的关联
发布时间：2024年07月17日
`LLM理论` `心理健康` `人工智能安全`
> The Better Angels of Machine Personality: How Personality Relates to LLM Safety
# 摘要
> 人格心理学家探讨了人格与社会安全行为的关系。尽管大型语言模型 (LLM) 展现出人格特质，但其与安全能力的关系仍未解之谜。本研究发现，LLM 的人格特质与其安全能力（如毒性、隐私和公平性）紧密相连，且安全对齐普遍提升了 LLM 的外向性、感觉和判断特质。基于此，我们可通过调整 LLM 的人格特质来提升其安全性能，例如，将 ISTJ 型转变为 ISTP 型，隐私和公平性能分别提升了约 43% 和 10%。此外，不同人格特质的 LLM 对越狱的敏感性各异。此研究首次从人格视角探讨 LLM 安全性，为提升 LLM 安全提供了新思路。
[Arxiv](https://arxiv.org/abs/2407.12344)
==========
# 利用 LLM 进行视频搜索查询的改写
发布时间：2024年07月17日
`LLM应用` `视频检索` `人工智能`
> LLM-based query paraphrasing for video search
# 摘要
> 文本到视频检索通过概念和嵌入搜索来回应用户查询，但由于概念库和训练数据的限制，常因词汇外问题导致效果不佳。此外，现有搜索方法无法处理包含逻辑和空间约束的复杂查询。为此，我们采用大型语言模型（LLM）通过文本到文本（T2T）、文本到图像（T2I）和图像到文本（I2T）转换来简化查询，有效应对词汇外问题，并将复杂查询分解为简单子查询，提升检索性能。针对LLM可能产生的错误，我们提出了一种基于一致性的验证策略，确保改述查询的准确性。在TRECVid数据集上进行的实验显示，通过查询改述，传统难以回答的查询得到了有效解决。
[Arxiv](https://arxiv.org/abs/2407.12341)
==========
# 精进查询生成，提升RAG文档检索效能
发布时间：2024年07月17日
`RAG` `信息技术` `人工智能`
> Optimizing Query Generation for Enhanced Document Retrieval in RAG
# 摘要
> 尽管大型语言模型在多样的语言任务中表现卓越，但它们时常产生错误信息，即所谓的“幻觉”。检索增强生成技术通过文档检索来减少这一现象，以提供更准确的响应。然而，模糊的查询仍导致幻觉问题。本研究通过优化查询生成，并利用LLM精炼查询，提高了文档检索的精确度和效率。实验结果显示，这一改进使得文档检索的平均准确率提升了1.6%。
[Arxiv](https://arxiv.org/abs/2407.12325)
==========
# AgentPoison：利用毒化记忆或知识库手段，对 LLM 代理进行红队挑战
发布时间：2024年07月17日
`Agent` `网络安全` `人工智能`
> AgentPoison: Red-teaming LLM Agents via Poisoning Memory or Knowledge Bases
# 摘要
> LLM代理因其强大的推理和互动能力在多领域表现出色。然而，依赖未经核实的知识库引发安全疑虑。为此，我们首创AgentPoison攻击，通过毒化代理的记忆库植入后门，实现高概率的恶意行为激活，同时保持正常指令的性能。AgentPoison无需额外训练，触发器设计巧妙，实验证实其对多种代理的高效攻击能力，平均成功率超80%，对正常功能影响微乎其微。
[Arxiv](https://arxiv.org/abs/2407.12784)
==========
# LMMs-Eval：审视大型多模态模型评估的真实性
发布时间：2024年07月17日
`LLM应用` `人工智能` `软件开发`
> LMMs-Eval: Reality Check on the Evaluation of Large Multimodal Models
# 摘要
> 随着大型基础模型的不断进步，我们需要广泛覆盖、低成本且无污染的基准测试。尽管语言模型评估的研究持续推进，但针对大型多模态模型（LMMs）的综合评估研究仍显不足。为此，我们推出了LMMS-EVAL，这是一个集统一性、标准化于一体的多模态基准框架，涵盖50余项任务及10余种模型，旨在推动评估的透明度与可重复性。然而，LMMS-EVAL在实现低成本与零污染方面尚有欠缺。为应对这一评估挑战，我们进一步推出了LMMS-EVAL LITE，一个注重覆盖广度与效率的精简评估工具包。同时，我们还推出了Multimodal LIVEBENCH，该平台通过实时更新的新闻与在线论坛内容，来检验模型在实际环境中的泛化能力，其评估方法兼具低成本与零污染特性。我们的研究凸显了评估难题的重要性，并提供了切实可行的解决方案，以平衡大型多模态模型评估中的各种权衡，为LMMs的更高效、可靠基准测试奠定了基础。我们已在GitHub和Hugging Face平台上开源了相关代码，并维护着LIVEBENCH的实时排行榜。
[Arxiv](https://arxiv.org/abs/2407.12772)
==========
# 通过环境交互，自动化生成 PDDL 并进行规划，借助大型语言模型实现。
发布时间：2024年07月17日
`LLM应用` `自动化` `人工智能`
> Leveraging Environment Interaction for Automated PDDL Generation and Planning with Large Language Models
# 摘要
> 大型语言模型（LLM）在众多自然语言任务中表现卓越，但在涉及结构化推理的规划问题上却常显力不从心。为此，我们提出将规划问题转换为规划域定义语言（PDDL），以利用自动化规划器。然而，精确的PDDL文件生成往往依赖于人工输入或修正，既耗时又成本高昂。本文中，我们创新性地结合LLM与环境反馈，自动生成PDDL文件，无需人工介入。我们采用迭代细化策略，生成多个PDDL候选方案，并依据环境反馈逐步优化域描述。为引导这一过程，我们设计了探索步行（EW）指标，为LLM提供丰富反馈，助力PDDL文件的更新。实验表明，我们的方法在PDDL环境中的任务解决率高达66%，远超GPT-4的29%。这一成果不仅实现了规划环境的自动化建模，更在PDDL生成中摒弃了人工干预，为解决复杂问题中的LLM应用奠定了坚实基础。
[Arxiv](https://arxiv.org/abs/2407.12979)
==========
# OE-BevSeg：结合对象信息与环境感知的多模态框架，专为鸟瞰图车辆语义分割设计。
发布时间：2024年07月17日
`LLM应用` `自动驾驶` `计算机视觉`
> OE-BevSeg: An Object Informed and Environment Aware Multimodal Framework for Bird's-eye-view Vehicle Semantic Segmentation
# 摘要
> 鸟瞰图（BEV）语义分割在自动驾驶系统中日益关键。通过将2D多视角图像投影至3D世界空间，实现对自车周围环境的感知。近期，BEV分割因视角转换模块的优化、图像编码器的扩大及时序信息的增加而取得显著进展。然而，仍面临两大挑战：一是对BEV空间特征的有效理解和增强，尤其是远距离环境特征的准确捕捉；二是目标物体细节的识别。为此，我们提出OE-BevSeg，一个端到端的多模态框架，通过全局环境感知和局部目标增强提升BEV分割性能。OE-BevSeg利用环境感知的BEV压缩器，结合长序列全局建模，增强模型对环境的理解和感知。同时，引入中心信息引导的对象增强模块，从局部增强角度提升分割性能。此外，设计多模态融合分支，融合多视角RGB图像与雷达/LiDAR特征，显著提升性能。实验证明，无论在仅摄像头还是多模态融合的BEV分割任务中，我们的方法在nuScenes数据集上为车辆分割任务实现了大幅领先的最先进结果，彰显了在自动驾驶领域的优越适用性。
[Arxiv](https://arxiv.org/abs/2407.13137)
==========
# 针对野外环境中的复合多模态情绪识别，我们提出了基于文本和特征的模型。
发布时间：2024年07月17日
`LLM应用` `情感分析` `视频处理`
> Text- and Feature-based Models for Compound Multimodal Emotion Recognition in the Wild
# 摘要
> 多模态情感识别系统常通过提取视觉、音频和文本等不同模态的特征来预测基本情感，但现实中的复合情感更难预测，尤其在视频中因模态多样性而更具挑战。传统基于特征的模型可能难以捕捉复合情感的复杂细节。为此，我们建议将所有模态文本化，借助大型语言模型（如 BERT 和 LLaMA）来解析模态间的复杂互动和情感的微妙变化。尽管训练这些模型需大量数据，但预训练模型已可便捷地微调应用于复合情感识别等任务。本文对比了视频复合情感识别的两种方法：传统特征基与创新文本基。实验在 C-EXPR-DB 数据集上进行，并与 MELD 数据集的基本情感识别结果对比。相关代码已公开。
[Arxiv](https://arxiv.org/abs/2407.12927)
==========
# 图像修复模型，作为指导图像编辑的得力工具，其效能显著。
发布时间：2024年07月17日
`LLM应用` `图像编辑`
> Image Inpainting Models are Effective Tools for Instruction-guided Image Editing
# 摘要
> 本报告介绍了CVPR2024 GenAI媒体生成挑战研讨会中指令引导图像编辑轨道的获胜方案。近年来，这一领域已取得显著进展，如SmartEdit和MGIE等方法通过联合训练结合大型语言模型与扩散模型。然而，我们实验发现，通过掩码等中间指导而非联合微调连接这两类模型，能显著提升编辑效果和成功率。我们采用的4步流程IIIIE包括：分类编辑类别、识别主要对象、获取编辑掩码和进行图像修复。实验结果表明，合理组合语言模型与图像修复模型，我们的方法不仅成功率高，且视觉效果出色。
[Arxiv](https://arxiv.org/abs/2407.13139)
==========
# SOMONITOR：借助大型语言模型，实现营销数据的可解释处理与深度分析
发布时间：2024年07月17日
`LLM应用` `人工智能`
> SOMONITOR: Explainable Marketing Data Processing and Analysis with Large Language Models
# 摘要
> 在线营销在处理海量数据时面临挑战，这些数据对竞争对手分析、内容研究和品牌战略至关重要。手动审查大量瞬息万变的在线内容几乎不可能，而片面分析常导致营销活动效果不佳。我们推出的SoMonitor框架，结合人类直觉与AI效率，助力营销人员从战略规划到内容创作和活动执行的每个环节。SoMonitor通过CTR预测和排名模型优化广告内容，并利用大型语言模型分析竞争对手内容，提炼目标受众、客户需求和产品特性等核心要素。这些要素被归类为沟通主题和目标客户角色，与品牌自身广告数据结合，构建针对新客户角色的叙事，并生成用户故事形式的详细内容简报，直接供营销团队应用，简化内容生产和活动执行。SoMonitor的日常应用使营销人员能迅速解析大数据，提供切实可行的洞察，大幅提升营销效果和工作满意度。
[Arxiv](https://arxiv.org/abs/2407.13117)
==========
# TrialEnroll 项目：结合深度与交叉网络及大型语言模型，精准预测临床试验的招募成功率。
发布时间：2024年07月17日
`LLM应用` `临床试验`
> TrialEnroll: Predicting Clinical Trial Enrollment Success with Deep & Cross Network and Large Language Models
# 摘要
> 临床试验的成功与否，很大程度上取决于能否招募到足够数量的志愿者患者。本文创新性地采用深度与交叉网络，辅以大型语言模型增强的文本特征，从试验资格标准中提取关键语义信息，精准预测入组成功率。该方法不仅提高了预测的准确性（PR-AUC达到0.7002），还增强了模型的可解释性，揭示了资格标准中哪些词句对预测结果影响最大。相关代码和数据集已公开，供学术界进一步研究与应用。
[Arxiv](https://arxiv.org/abs/2407.13115)
==========
# 迭代三部曲：检索、总结、规划，助力多跳问答迈向新高度
发布时间：2024年07月17日
`RAG` `问答系统` `人工智能`
> Retrieve, Summarize, Plan: Advancing Multi-hop Question Answering with an Iterative Approach
# 摘要
> 多跳问答任务因其工业应用价值而备受挑战，而基于大型语言模型的检索增强生成（RAG）方法已成为解决这一问题的热门选择。然而，由于单次迭代可能无法获取所有必要信息，一系列迭代RAG方法应运而生，性能显著提升。尽管如此，现有方法仍面临上下文过载和规划冗余两大难题。为此，我们提出了一种新型迭代RAG方法——ReSP，其特色在于配备了一个双功能摘要器，能同时压缩总体问题和当前子问题的信息。实验证明，ReSP在HotpotQA和2WikiMultihopQA数据集上表现卓越，不仅超越了现有技术，还展现了出色的上下文长度适应性。
[Arxiv](https://arxiv.org/abs/2407.13101)
==========
# 探索视频与文本理解的新视角：从反事实增强数据中进行检索
发布时间：2024年07月17日
`LLM应用` `视频理解` `人工智能`
> Rethinking Video-Text Understanding: Retrieval from Counterfactually Augmented Data
# 摘要
> 近期，视频-文本基础模型在众多视频理解任务中表现出色。然而，这些模型是否真正理解自然视频内容？传统评估可能存在误导，因为许多问题仅基于单帧对象或数据集偏见。本文中，我们致力于深入评估现有视频-文本模型的能力及其局限。为此，我们创新性地提出了反事实增强数据检索（RCAD）评估任务及Feint6K数据集。模型需通过跨帧推理全面理解视频内容，才能在这一新任务中脱颖而出。分析表明，先前模型易受反事实数据干扰，远未及人类水平。为弥合这一差距，我们指出了现有对比方法的局限，并推出了LLM-teacher方法，该方法借助预训练大型语言模型的知识，更有效地学习动作语义。实验证实，该方法能显著提升动作嵌入的区分度，并在多个模型上优化了Feint6K任务表现。Feint6K数据集及项目详情请访问：https://feint6k.github.io。
[Arxiv](https://arxiv.org/abs/2407.13094)
==========
# 本研究采用多数投票机制，利用本地大型语言模型进行动态情感分析，旨在探讨影响餐厅评价的关键因素。
发布时间：2024年07月17日
`LLM应用` `餐饮业`
> Dynamic Sentiment Analysis with Local Large Language Models using Majority Voting: A Study on Factors Affecting Restaurant Evaluation
# 摘要
> 在线平台上的用户生成内容（UGCs）为营销研究提供了洞察消费者偏好的窗口。随着大型语言模型（LLMs）的发展，一些研究开始利用这些模型进行标注和情感分析。然而，LLMs的准确性与超参数之间的关系仍待深入探讨，且其结果的可变性和可重复性问题在现有文献中鲜有涉及。本研究借鉴人工标注中的多数投票机制，将其引入基于本地LLMs的情感分析模型。通过分析餐厅评价的在线评论，我们发现，采用中型模型进行多次尝试的多数投票方法，比仅使用大型模型进行单次尝试，能产生更为稳健的结果。此外，我们还深入探讨了各因素对整体评价的影响。
[Arxiv](https://arxiv.org/abs/2407.13069)
==========
# 探究大型语言模型在不同 NLP 任务中的提示工程方法
发布时间：2024年07月17日
`LLM应用` `人工智能`
> A Survey of Prompt Engineering Methods in Large Language Models for Different NLP Tasks
# 摘要
> 大型语言模型（LLM）在众多自然语言处理（NLP）任务中表现出色。提示工程是提升LLM在各类NLP任务中性能的关键，它通过设计自然语言指令——提示，以结构化方式激发LLM的知识。与传统SoTA模型不同，提示工程无需繁琐的参数调整，仅依赖LLM内置知识。此外，通过简单的自然语言对话或提示工程，即使非专业人士也能轻松探索LLM的潜力。近两年，提示工程备受瞩目，研究者们开发了多种技巧以优化信息提取。本文综述了44篇论文，涵盖39种提示方法应用于29项NLP任务，详细分析了这些策略在不同数据集上的表现，并探讨了相关LLM及潜在的SoTA。
[Arxiv](https://arxiv.org/abs/2407.12994)
==========
# Halu-J：一款基于批评的幻觉评判工具
发布时间：2024年07月17日
`LLM应用` `人工智能`
> Halu-J: Critique-Based Hallucination Judge
# 摘要
> 大型语言模型常产生非事实内容，即幻觉。现有基于检索的幻觉检测方法多将其视为分类任务，依据幻觉与检索证据的一致性进行评估，但往往缺乏详细解释且不评估解释的可靠性。检索系统的不足还可能导致检索到无关或部分相关的证据，影响检测准确性。现实中，幻觉检测需综合多条证据，而现有系统对此处理不够精细。为此，我们推出了 Halu-J，一款拥有 70 亿参数的基于批评的幻觉判断器，它能精选相关证据并提供详尽批评，从而提升检测效果。实验显示，Halu-J 在多证据幻觉检测上超越 GPT-4o，并在批评生成与证据选择上与之匹敌。同时，我们发布了新数据集 ME-FEVER，专为多证据幻觉检测设计。相关代码与数据集已公开于 https://github.com/GAIR-NLP/factool。
[Arxiv](https://arxiv.org/abs/2407.12943)
==========
# 利用检索增强生成技术的大型语言模型，实现生物医学假设的可解释生成
发布时间：2024年07月17日
`RAG` `生物医学`
> Explainable Biomedical Hypothesis Generation via Retrieval Augmented Generation enabled Large Language Models
# 摘要
> 当前生物医学信息的庞大规模对研究者构成了挑战。大型语言模型（LLMs）虽强大，但可能产生幻觉响应，因此检索增强生成（RAG）对确保信息准确性至关重要。我们提出的RUGGED系统，通过图引导的可解释疾病区分进行检索，整合文本挖掘与图预测模型，从文献和数据库中提炼信息，预测药物与疾病的潜在关联。这一框架结合RAG技术，助力研究者深入探索机制与假设。临床实例显示，RUGGED能有效评估并推荐针对特定心肌病的治疗方案，分析药物分子作用及新应用，减少模型幻觉，提供实用见解，推动新药研发。
[Arxiv](https://arxiv.org/abs/2407.12888)
==========
# 探究个性特质对谈判结果的影响：一项基于大型语言模型的模拟研究
发布时间：2024年07月16日
`Agent` `心理学` `人工智能`
> How Personality Traits Influence Negotiation Outcomes? A Simulation based on Large Language Models
# 摘要
> 心理研究表明，个性特质深刻影响决策过程。比如，亲和性在谈判中常带来积极成果，而神经质则可能导致不利结果。本文构建了一个模拟框架，核心是具备合成个性的大型语言模型（LLM）代理，它们在讨价还价场景中谈判，个性与目标均可定制。实验揭示，这些基于LLM的模拟能精准复现人类谈判行为。我们的研究贡献主要有两方面：一是探索了LLM代理的语言与经济能力间的协调性；二是实证分析了五大个性特质如何影响双边谈判策略。此外，通过合成对话案例研究，我们发现了谈判中的欺骗与妥协等引人入胜的行为模式。
[Arxiv](https://arxiv.org/abs/2407.11549)
==========
# PRET：通过定向忠诚轨迹规划视觉与语言导航
发布时间：2024年07月16日
`Agent` `机器人` `自动驾驶`
> PRET: Planning with Directed Fidelity Trajectory for Vision and Language Navigation
# 摘要
> 视觉与语言导航任务要求代理根据自然语言指令进行导航。近期方法通过在拓扑图上预测子目标来实现长期规划，但使用GCN类模型进行高级预测时计算成本高昂。我们提出一种新方法，通过分析指令与定向路径的对齐来优化导航规划，确保从起点到目标位置的路径无绕行。该策略不仅提升了模型效率，还保持了高性能。我们利用有向图来描绘探索区域，并定义轨迹为一系列有向边特征，这些特征从全景图中提取。导航时，我们评估指令与轨迹的对齐度，以选择最佳导航目标。在RxR数据集上，我们的方法超越了BEVBert，在R2R数据集上也表现出色，且显著降低了计算负担。代码已公开：https://github.com/iSEE-Laboratory/VLN-PRET。
[Arxiv](https://arxiv.org/abs/2407.11487)
==========
# AI 界的奥斯卡盛典：探索语言模型在角色扮演中的应用
发布时间：2024年07月16日
`LLM应用` `人工智能`
> The Oscars of AI Theater: A Survey on Role-Playing with Language Models
# 摘要
> 本调查深入探讨了语言模型在角色扮演领域的发展，从早期的简单人格模型演变为由大型语言模型 (LLM) 驱动的高级角色模拟。最初受限于模型能力，角色扮演仅追求基本的人格一致性，如今已进化至包含角色一致性、行为匹配及整体魅力的复杂描绘。我们详细分类了设计这些系统的关键要素，涵盖数据处理、模型构建、代理架构及评估方法。此次调查不仅总结了当前的技术路径与挑战，例如动态个人资料的管理和高水平人格一致性的实现，还为未来研究指明了方向，旨在增强角色扮演应用的深度与真实感。我们的目标是通过对现有方法的系统梳理，识别改进点，从而引领未来研究的发展。相关资料与论文已整理于 https://github.com/nuochenpku/Awesome-Role-Play-Papers。
[Arxiv](https://arxiv.org/abs/2407.11484)
==========
# SPINACH：利用 SPARQL 技术，为解决复杂现实问题提供信息导航
发布时间：2024年07月16日
`Agent` `知识库问答` `人工智能`
> SPINACH: SPARQL-Based Information Navigation for Challenging Real-World Questions
# 摘要
> 近期，大型语言模型 (LLM) 的整合为知识库问答 (KBQA) 任务带来了显著进步。然而，我们认为现有 KBQA 数据集因问题简单、逻辑形式合成生成或基于小型知识库模式，未能充分体现 KBQA 任务的复杂性。为此，我们推出了 SPINACH 数据集，该数据集从 Wikidata 的“请求查询”论坛中精选专家注释，包含 320 对去上下文的问题与 SPARQL 查询。SPINACH 数据集的复杂度远超现有数据集，它要求 KBQA 系统能够不依赖训练数据学习知识库模式，而是动态探索并推理大型且常不完整的模式。  此外，我们引入了 SPINACH 代理，这是一种模拟人类专家编写 SPARQL 查询的新型 KBQA 方法。实验表明，SPINACH 代理在 KBQA 任务中表现卓越，分别在 QALD-7、QALD-9 Plus 和 QALD-10 数据集上以 30.1%、27.0% 和 10.0% 的 F1 成绩刷新了记录，并在 WikiWebQuestions 上与顶尖的微调 LLaMA 模型仅差 1.6%。在新推出的 SPINACH 数据集上，SPINACH 代理在 F1 成绩上超越了所有基线，包括基于 GPT-4 的最佳 KBQA 代理，领先幅度达 38.1%。
[Arxiv](https://arxiv.org/abs/2407.11417)
==========
# 重审模块化追求对代码生成的影响
发布时间：2024年07月16日
`LLM理论` `软件开发` `人工智能`
> Revisiting the Impact of Pursuing Modularity for Code Generation
# 摘要
> 模块化编程，通过整合小而独立的组件构建程序，一直是软件开发的理想选择。但随着基于LLM的代码生成工具兴起，这种传统方法是否依然有效？我们通过创新量化指标评估了模块化对代码生成的影响，结果出人意料：模块化并非提升模型性能的关键。此外，我们还探究了LLM为何对模块化与非模块化代码无明显偏好的原因。
[Arxiv](https://arxiv.org/abs/2407.11406)
==========
# InvAgent：一款基于大型语言模型的多智能体系统，专为供应链库存管理设计
发布时间：2024年07月16日
`Agent` `供应链管理` `库存管理`
> InvAgent: A Large Language Model based Multi-Agent System for Inventory Management in Supply Chains
# 摘要
> 在易变、不确定、复杂和模糊的VUCA时代，供应链管理（SCM）中的有效库存管理显得尤为关键。尽管启发式方法和强化学习在库存管理中已显示出优势，但大型语言模型（LLMs）在多代理系统中的应用仍待深入探索。本研究创新性地采用LLMs来管理多代理库存系统，通过零-shot学习能力，我们的InvAgent模型不仅提升了供应链的弹性和效率，还实现了无需预训练的自适应决策。借助思维链（CoT），我们提供了高度的可解释性，并展示了模型在应对多变需求时的成本效益和缺货规避能力。广泛的实证评估证实了InvAgent在SCM中的高效性。
[Arxiv](https://arxiv.org/abs/2407.11384)
==========
# OmniBind：借助绑定空间实现的全模态大规模表示
发布时间：2024年07月16日
`LLM应用` `人机交互` `多模态技术`
> OmniBind: Large-scale Omni Multimodal Representation via Binding Spaces
# 摘要
> 近期，多模态人机交互技术如GPT-4o和Gemini展现出广阔的应用前景。鉴于多模态联合表示在信息处理中的核心地位，构建高质量的全能联合表示模型成为提升多模态信息处理能力的关键。为此，我们推出了OmniBind，一系列参数规模从70亿至300亿的多模态联合表示模型，涵盖3D、音频、图像及语言等多种输入形式。面对多模态数据配对的稀缺性，我们创新性地采用预训练模型空间的重新映射与绑定策略，而非从零开始训练，从而间接扩展模型参数与数据规模，实现“规模化”升级。为高效融合多模态空间，我们通过学习路由器动态调整各空间权重，确保跨模态整体对齐与语言表示的独立性。得益于轻量级网络的应用，OmniBind在训练效率上表现卓越，仅需非配对单模态数据，即可在单个8-4090节点上于约三天内完成最大300亿模型的训练。大量实验验证了OmniBind作为全能表示模型的出色性能与广泛适用性，预示其在任意查询、多模态理解等多样化应用领域的巨大潜力。
[Arxiv](https://arxiv.org/abs/2407.11895)
==========
# 借助大型语言模型实现多模态产品组合
发布时间：2024年07月16日
`LLM应用` `电子商务`
> Harnessing Large Language Models for Multimodal Product Bundling
# 摘要
> 产品捆绑策略通过组合单个项目，为客户提供了一种战略性选择。近年来，这一策略作为在线服务的基础条件备受瞩目。尽管现有方法通过精密的提取器利用多模态信息进行捆绑，但仍面临语义理解不足、知识范围受限及冷启动问题等挑战。大型语言模型（LLMs）虽知识渊博、推理复杂，却难以直接应用于多模态产品捆绑。为此，我们创新性地引入了Bundle-LLM，旨在连接LLMs与产品捆绑任务。我们采用混合项目标记化技术，通过一个简洁而高效的多模态融合模块，将非文本特征整合成单一标记，不仅展示了模态间的互动，还提升了处理效率。通过设计提示模板，我们将产品捆绑转化为多项选择题，并采用渐进优化策略微调LLMs，以实现解耦目标，从而在多模态语义理解基础上，有效提升产品捆绑能力。实验结果显示，我们的方法在多个数据集上超越了现有最先进技术。
[Arxiv](https://arxiv.org/abs/2407.11712)
==========
# Ascend-CC：异构NPU上的新兴生成AI工作负载保密计算
发布时间：2024年07月16日
`LLM应用` `云计算` `人工智能`
> Ascend-CC: Confidential Computing on Heterogeneous NPU for Emerging Generative AI Workloads
# 摘要
> 云工作负载主导着基于大型语言模型的生成AI领域。专用硬件加速器如GPU、NPU和TPU，因其卓越性能在AI应用中扮演关键角色。然而，AI模型和数据的敏感性以及来源的互不信任，使得现有基于CPU的TEE技术如Intel SGX或AMD SEV的保护力度不足。Nvidia-CC等以设备为中心的TEE解决方案，仅适用于紧密耦合的CPU-GPU系统，并依赖于主机CPU侧的TEE。学术界的提案也多针对特定CPU-TEE平台。  为此，我们推出了Ascend-CC，一种无需信任主机系统的离散NPU设备机密计算架构。Ascend-CC通过数据和模型加密，不仅保障数据安全，还保护模型参数和操作二进制文件，提供强有力的安全保障。采用基于委托的内存语义，Ascend-CC确保与主机软件堆栈的隔离，并通过任务认证强化模型完整性。与Llama2和Llama3等顶尖LLM的实现和评估表明，Ascend-CC在不影响AI软件堆栈的前提下，仅引入极小开销。
[Arxiv](https://arxiv.org/abs/2407.11888)
==========
# 手语翻译的规模化
发布时间：2024年07月16日
`LLM应用` `手语翻译` `人工智能`
> Scaling Sign Language Translation
# 摘要
> 手语翻译（SLT）旨在将视频中的手语信息转换为文本中的口语语言。尽管现有研究取得了进展，但往往局限于特定领域或少数手语，且在开放领域任务上表现不佳。本文通过扩大预训练数据规模、模型尺寸及翻译方向，推动了SLT技术的进步。我们利用多语言YouTube SLT数据、平行文本语料库及通过机器翻译增强的SLT数据进行大规模预训练。在编码器-解码器架构下，我们通过特定任务提示整合了多种预训练任务，并采用预训练的（m/By）T5模型初始化SLT模型。实验结果表明，数据与模型的扩展、跨语言跨模态迁移对提升翻译质量至关重要，并验证了零-shot SLT的可行性。我们对预训练模型在涵盖五种手语的五个开放领域基准上进行微调，实验结果显著优于传统基线，大幅超越了业界领先水平。
[Arxiv](https://arxiv.org/abs/2407.11855)
==========
# 大型语言模型中的模式匹配：实验探究
发布时间：2024年07月16日
`LLM应用` `数据工程`
> Schema Matching with Large Language Models: an Experimental Study
# 摘要
> 大型语言模型（LLM）在数据整理等多项任务中展现出实用价值。本文探讨了利用现成LLM进行模式匹配的方法，旨在仅凭名称和描述识别两组关系模式间的语义关联。我们借助健康领域新设的基准测试，设计了不同“任务范围”策略，即引导LLM执行模式匹配的技巧，其差异在于提示所含上下文信息的多少。通过这些策略，我们对比了LLM与字符串相似度基线在匹配质量、验证难度、决策力及互补性方面的表现。结果显示，匹配质量受限于上下文信息的匮乏或过剩。而采用较新版本的LLM通常能提升决策力。我们筛选出验证负担适中且能有效识别大量真实语义匹配的任务范围。研究揭示，LLM在加速模式匹配进程中潜力巨大，数据工程师可仅依赖模式元素的名称与描述，无需实际数据即可提升工作效率。
[Arxiv](https://arxiv.org/abs/2407.11852)
==========
# LoFTI：将本地化与事实性迁移至印度各地区
发布时间：2024年07月16日
`LLM应用` `人工智能` `地理信息系统`
> LoFTI: Localization and Factuality Transfer to Indian Locales
# 摘要
> 大型语言模型 (LLM) 通过训练从互联网爬取的大型数据集，积累了丰富的世界知识。然而，这些数据集往往偏向英语国家，导致 LLM 在处理需要特定地区信息的查询时，可能产生偏见或不准确响应。为此，我们推出了一个名为 LoFTI 的新基准，专门用于评估 LLM 的本地化和事实文本转移能力。LoFTI 包含全球源位置和印度目标位置（涵盖国家、州、城市等不同层次）实体的事实陈述，广泛覆盖各类实体。我们利用 LoFTI 评估了 Mixtral、GPT-4 及两种基于 Mixtral 的方法，结果显示，尽管 LoFTI 是一个高质量的评估工具，所有模型，包括 GPT-4，在处理不同层次的本地化信息时，表现均有所偏差。
[Arxiv](https://arxiv.org/abs/2407.11833)
==========
# 借助 GPT 进行修辞与语言特征的辅助标注，旨在提升新闻文本中宣传技巧检测的透明度与准确性。
发布时间：2024年07月16日
`LLM应用` `市场营销` `人工智能`
> GPT Assisted Annotation of Rhetorical and Linguistic Features for Interpretable Propaganda Technique Detection in News Text
# 摘要
> 本研究针对文本中宣传技巧的检测，从文献中提炼出22种修辞与语言特征，并利用这些特征对现有数据集进行标注。为减轻人类专家的负担，我们设计了RhetAnn网络应用，并借助少量标注数据微调GPT-3.5，以高效且经济的方式完成大规模标注任务。研究结果显示，这种方法不仅成本仅为传统方法的十分之一，且性能与顶尖模型GPT-4相媲美。我们的创新在于提供了一套机器可读的特征集，以及RhetAnn应用和GPT微调流程，旨在推动可解释宣传技巧检测技术的发展。
[Arxiv](https://arxiv.org/abs/2407.11827)
==========
# PipeInfer：通过异步流水线推测技术，加速大型语言模型的推理过程。
发布时间：2024年07月16日
`LLM应用` `计算机科学` `人工智能`
> PipeInfer: Accelerating LLM Inference using Asynchronous Pipelined Speculation
# 摘要
> 近期，大型语言模型在跨集群推理方面的研究备受关注，众多加速技术借鉴了CPU的推测执行机制。这些技术虽缓解了内存带宽瓶颈，却也增加了推理延迟，需依赖高推测接受率来提升性能。然而，任务间接受率的不一致性可能导致性能下降。此外，流水线并行设计依赖大量用户请求以维持高效利用。为此，我们推出了PipeInfer，一种流水线推测加速技术，旨在降低单请求场景下的令牌间延迟，提升系统利用率，并增强对低推测接受率和低带宽环境的适应性。PipeInfer在生成速度上实现了2.15倍的提升，得益于连续异步推测和早期推理取消两大创新：前者通过并行执行单令牌推理与推测任务来优化延迟和速度，后者则通过跳过无效推理阶段来进一步提速。
[Arxiv](https://arxiv.org/abs/2407.11798)
==========
# 大型语言模型在对话中扮演着误导性助手的角色
发布时间：2024年07月16日
`LLM应用` `信息安全` `人工智能`
> Large Language Models as Misleading Assistants in Conversation
# 摘要
> 大型语言模型 (LLM) 虽能辅助各类信息查询任务，但其输出可能误导用户，无论是无意还是有意。我们探讨了 LLM 在阅读理解任务中作为用户代理时的欺骗能力。通过实验，我们对比了三种情况：模型提供真实帮助、微妙误导及为错误答案辩护。结果显示，GPT-4 能有效误导其他模型，导致任务准确率下降高达 23%。此外，提供额外上下文能部分缓解欺骗性输出的影响。此研究揭示了 LLM 制造误导信息的潜在风险及其在现实应用中的影响。
[Arxiv](https://arxiv.org/abs/2407.11789)
==========
# SwitchCIT：针对大型语言模型的持续指令调优进行智能切换
发布时间：2024年07月16日
`LLM理论` `人工智能`
> SwitchCIT: Switching for Continual Instruction Tuning of Large Language Models
# 摘要
> LLM 在通用语言理解等领域表现卓越，但针对特定指令任务的优化可能不足。持续指令调优是确保 LLM 适应新任务和领域的关键，从而在多样应用中保持其效用。然而，在连续任务训练中，模型可能遭遇灾难性遗忘，影响先前任务的性能。我们提出一种切换机制，通过参数高效调优模型来解决这一问题，并通过实验验证了其在不同自然语言生成任务中持续指令调优的有效性。
[Arxiv](https://arxiv.org/abs/2407.11780)
==========
# 利用大型语言模型进行教育个性化学习路径规划
发布时间：2024年07月16日
`LLM应用` `个性化学习`
> Educational Personalized Learning Path Planning with Large Language Models
# 摘要
> 教育个性化学习路径规划（PLPP）旨在根据每位学习者的独特需求定制学习体验，从而提升学习效率和参与度。然而，传统PLPP系统常因缺乏适应性、互动性和透明度而受限。本文提出了一种创新方法，结合大型语言模型（LLMs）与提示工程，以应对这些挑战。我们通过设计融入学习者特定信息的提示，引导LLMs如LLama-2-70B和GPT-4生成个性化且教学合理的学习路径。实验结果显示，与基线方法相比，我们的方法在准确性、用户满意度和学习路径质量等方面均有显著提升，尤其是GPT-4的表现，凸显了提示工程在PLPP中的有效性。长期影响分析进一步证实了我们的方法在提升学习成效和保持率方面的潜力。这项研究展示了LLMs和提示工程在推动个性化教育发展中的广阔前景。
[Arxiv](https://arxiv.org/abs/2407.11773)
==========
# XEdgeAI：一个以人为本、数据驱动的工业检测框架，融合了可解释的边缘AI技术。
发布时间：2024年07月16日
`LLM应用` `边缘计算`
> XEdgeAI: A Human-centered Industrial Inspection Framework with Data-centric Explainable Edge AI Approach
# 摘要
> 深度学习技术的进步大幅提升了工业领域的视觉检测与预测维护。但将这些技术应用于资源有限的边缘设备，因其高计算需求和XAI方法的复杂性而面临挑战。本文提出了一种创新的XAI集成视觉检测框架，优化了低资源设备上语义分割模型的部署。该框架融合XAI与大型视觉语言模型，通过视觉与文本解释提升用户信任与模型透明度。我们设计了一套包含六个核心模块的方法：模型微调、XAI解释生成、XAI方法评估、XAI数据增强、边缘模型开发及易懂解释生成。借助XAI数据增强，结合专家知识与解释的增强模型成功部署于移动设备，助力用户应对实际挑战。实验表明，该框架有效，移动模型在保持高准确性的同时大幅缩减了模型体积。这一进展为关键工业场景中更广泛应用可靠且透明的AI工具奠定了基础，确保决策既快速又合理。
[Arxiv](https://arxiv.org/abs/2407.11771)
==========
# 基于大型语言模型的文本匿名化技术，确保实用性与鲁棒性并存。
发布时间：2024年07月16日
`LLM应用` `隐私保护` `数据安全`
> Robust Utility-Preserving Text Anonymization Based on Large Language Models
# 摘要
> 文本匿名化在共享敏感数据的同时保护隐私至关重要。然而，大型语言模型 (LLM) 的再识别攻击能力对现有技术构成新挑战。本文提出一个由隐私评估器、效用评估器和优化组件组成的 LLM 框架，协同进行匿名化处理。通过直接偏好优化 (DPO)，我们将匿名化能力精简至轻量级模型，适用于大规模实时环境。实验证明，该模型在降低再识别风险的同时，有效保持了下游任务的数据效用。相关代码和数据集已公开于 https://github.com/UKPLab/arxiv2024-rupta。
[Arxiv](https://arxiv.org/abs/2407.11770)
==========
# 语言的向量化
发布时间：2024年07月16日
`LLM理论` `科学研究` `语言学`
> Vectoring Languages
# 摘要
> 大型语言模型 (LLM) 的最新突破已引起全球瞩目，研究步伐随之加快。尽管哲学家和心理学家多年来致力于语言结构的研究，却难以从 LLM 的突破中直接获益。本文提出了一种新颖的语言结构，深入揭示了语言模型的内在机制，并证明其在捕捉语言多样性方面超越了传统方法。我们通过线性代数的类比强化了这一观点的理论基础，并探讨了其与现有语言模型设计哲学的差异。最终，我们探讨了这一视角如何指引我们探索可能加速科学进步的新研究方向。
[Arxiv](https://arxiv.org/abs/2407.11766)
==========
# 研究量化技术，以提升 Transformer 语言模型的预训练效率
发布时间：2024年07月16日
`LLM理论` `计算机科学` `人工智能`
> Exploring Quantization for Efficient Pre-Training of Transformer Language Models
# 摘要
> 随着Transformer模型规模的扩大，预训练的计算需求也随之增加。尽管量化在预训练后和微调中表现出色，但在预训练阶段对Transformer进行量化的大规模探索仍显不足。本研究聚焦于线性层，系统地应用线性量化于权重、激活、梯度和优化器状态，旨在提升预训练效率并保持语言建模能力。我们提供了一套全面的量化策略，助力Transformer从零开始的高效训练。相关代码已公开于GitHub。
[Arxiv](https://arxiv.org/abs/2407.11722)
==========
# Turbo：一款信息驱动型加速插件，专为视觉与语言大型模型设计
发布时间：2024年07月16日
`LLM应用` `人工智能` `计算机视觉`
> Turbo: Informativity-Driven Acceleration Plug-In for Vision-Language Large Models
# 摘要
> 视觉-语言大型模型（VLMs）因其卓越性能已成为AI领域的核心。然而，高昂的计算成本限制了其在实际应用中的广泛使用。现有加速方法多从模型层面入手，忽略了数据层面的冗余问题。本文首次深入探讨数据冗余，并设计了一款即插即用的Turbo模块，通过信息度指导，有效剔除视觉或文本数据中的低效令牌。信息度综合考虑了令牌间的冗余度和语义贡献，确保高信息度令牌既少冗余又富含语义。Turbo模块操作简便，无需重新训练，广泛适用于各类VLMs的理解与生成任务。实验表明，Turbo在保持性能几乎不变的同时，显著提升了VLMs的运行速度。
[Arxiv](https://arxiv.org/abs/2407.11717)
==========
# VLMEvalKit：一款开源工具，专为评估大型多模态模型而设计。
发布时间：2024年07月16日
`LLM应用` `人工智能` `计算机视觉`
> VLMEvalKit: An Open-Source Toolkit for Evaluating Large Multi-Modality Models
# 摘要
> 我们发布了 VLMEvalKit，这是一个基于 PyTorch 的开源工具包，专门用于评估大型多模态模型。VLMEvalKit 旨在为研究者和开发者提供一个既友好又全面的框架，帮助他们评估现有模型并发布可靠的评估结果。该工具包内置了超过 70 种大型多模态模型，涵盖专有 API 和开源模型，并支持 20 多种多模态基准测试。通过统一的接口设计，新模型可以轻松集成，而工具包则自动处理数据准备、分布式推理、预测后处理和指标计算等繁琐工作。虽然目前主要用于视觉-语言模型的评估，但其灵活设计也支持未来扩展至音频、视频等其他模态。基于此工具包的评估结果，我们还推出了 OpenVLM Leaderboard，这是一个全面的排行榜，旨在追踪多模态学习领域的最新进展。VLMEvalKit 已在 GitHub 上发布，并持续得到维护。
[Arxiv](https://arxiv.org/abs/2407.11691)
==========
# CCoE：专家协作下的紧凑型LLM
发布时间：2024年07月16日
`LLM应用` `人工智能` `跨领域应用`
> CCoE: A Compact LLM with Collaboration of Experts
# 摘要
> 在大型语言模型领域，LLM 在自然语言处理方面表现卓越。面对跨领域应用的需求，我们提出了 CCoE 架构，该框架能将多个领域专家模型融合，形成一个强大的 LLM，有效整合各领域专长。此外，CCoE 通过独立训练每个专家模型，解决了大规模协作训练的资源难题。该架构通过专家协作层连接多个专家模型，每个层包含一个或多个专家，这些专家模型针对特定领域进行了精细训练，性能可媲美最先进的领域模型。我们从五个领域（代码、数学、法律、文本到 SQL 和医学）的专家模型开始，实验结果显示，CCoE 框架能在节省资源的同时，显著提升各领域模型的性能，增幅达 10%-20%。
[Arxiv](https://arxiv.org/abs/2407.11686)
==========
# MINI-LLM：针对大型语言模型的高效内存结构化剪枝方案
发布时间：2024年07月16日
`LLM理论` `人工智能` `计算机硬件`
> MINI-LLM: Memory-Efficient Structured Pruning for Large Language Models
# 摘要
> 随着 LLM 规模的迅猛增长，压缩和加速这些模型的需求日益迫切。尽管先前研究表明梯度在神经网络压缩中具有重要价值，尤其是在中等规模网络的修剪中，但反向传播计算梯度的高内存需求限制了其在 LLM 修剪中的应用。因此，当前 LLM 修剪多依赖于无梯度标准，如权重大小或其与激活的组合。本文中，我们创新性地提出了一种混合修剪标准，巧妙结合大小、激活和梯度，以提升特征图敏感性，实现 LLM 的高效修剪。为解决内存瓶颈，我们仅通过前向传递估计梯度，并据此设计了 MINI-LLM 这一内存高效结构化修剪程序，旨在剔除非关键组件。实验证明，MINI-LLM 在 LLaMA、BLOOM 和 OPT 等多种 LLM 上，不仅在分类、多选和生成等下游任务中表现卓越，且 GPU 内存占用与无梯度方法相当。
[Arxiv](https://arxiv.org/abs/2407.11681)
==========
# R-SFLLM：为大型语言模型设计的分割联邦学习抗干扰框架
发布时间：2024年07月16日
`LLM应用` `无线通信` `机器学习`
> R-SFLLM: Jamming Resilient Framework for Split Federated Learning with Large Language Models
# 摘要
> Split federated learning (SFL) 是一种高效的分布式机器学习范式，其中大型模型的组件被外包至远程服务器。然而，SFL 在无线信道部署时面临一个重大挑战：传输的模型参数易受干扰，可能危及学习过程。本文深入分析了干扰对 LLM 词嵌入的影响，并开发了一个物理层框架 R-SFLLM，以增强无线网络中的 SFL 弹性。通过实验证明，R-SFLLM 在 NLP 任务中表现优异，并引入对抗训练组件，显著提升 LLM 对扰动参数的抵抗力。研究还指出，最坏情况的干扰会导致最坏的模型结果，强调了开发抗干扰 SFL 协议的必要性。
[Arxiv](https://arxiv.org/abs/2407.11654)
==========
# 大型语言模型在时间事件预测领域的全面评估
发布时间：2024年07月16日
`LLM应用` `时间事件预测` `数据挖掘`
> A Comprehensive Evaluation of Large Language Models on Temporal Event Forecasting
# 摘要
> 近期，大型语言模型 (LLMs) 在多种数据挖掘任务中表现出色，如知识问答、数学推理等。但在时间事件预测方面，LLMs 的推理能力尚未充分挖掘。为此，我们系统评估了基于 LLM 的时间事件预测方法，并构建了 MidEast-TE-mini 数据集。实验表明，直接整合原始文本并不能提升零-shot 性能，而在特定复杂事件中引入原始文本并微调 LLMs 则能显著提升性能。此外，通过检索模块，LLM 能有效捕捉历史事件中的时间关系模式。尽管如此，流行度偏差和长尾问题仍待解决。这些发现不仅深化了我们对 LLM 事件预测方法的理解，也为未来研究指明了方向。我们相信，这一全面评估将为 LLMs 在时间事件预测领域的研究带来重要贡献。
[Arxiv](https://arxiv.org/abs/2407.11638)
==========
# AdaptEval：聚焦于评估大型语言模型在文本摘要领域适应性方面的表现。
发布时间：2024年07月16日
`LLM应用` `人工智能`
> AdaptEval: Evaluating Large Language Models on Domain Adaptation for Text Summarization
# 摘要
> 尽管 LLM 在抽象摘要任务上取得了进步，但关于它们适应不同领域的能力的研究尚显不足。我们在微调和上下文学习两种模式下，对多种 LLM 在跨领域摘要任务上的适应性进行了评估。此外，我们推出了首个领域适应评估工具 AdaptEval，它包含一个领域基准和一系列分析指标，助力领域适应性的深入研究。研究结果显示，LLM 在上下文学习模式下，无论规模大小，其性能均表现出色。
[Arxiv](https://arxiv.org/abs/2407.11591)
==========
# 优化LLM中的KV缓存驱逐策略：通过自适应分配提升预算利用效率
发布时间：2024年07月16日
`LLM理论` `人工智能` `计算机科学`
> Optimizing KV Cache Eviction in LLMs: Adaptive Allocation for Enhanced Budget Utilization
# 摘要
> 大型语言模型虽在多领域表现卓越，但长序列推理所需的庞大KV缓存限制了其效率。为解决这一问题，我们重新审视了现有策略，发现它们旨在特定预算下最小化驱逐损失上限。然而，当前的均匀预算分配方法在驱逐后常损害生成质量。为此，我们提出了一种简单有效的自适应分配算法，不仅理论上限优于传统方法，还能更好地适应自注意力机制，实际降低了损失上限。结合两种前沿技术，我们开发了Ada-SnapKV和Ada-Pyramid，经16个数据集和Needle-in-a-Haystack测试验证，它们显著提升了性能，刷新了行业标杆。
[Arxiv](https://arxiv.org/abs/2407.11550)
==========
# 通过微调医学语言模型，我们旨在提升其对长篇上下文的理解能力及领域专业知识。
发布时间：2024年07月16日
`LLM应用` `人工智能`
> Fine-Tuning Medical Language Models for Enhanced Long-Contextual Understanding and Domain Expertise
# 摘要
> 大型语言模型（LLM）在多个专业领域大显身手。通过微调特定领域的问答数据集，这些模型的专业知识和问答技能大幅提升，例如，经过医患问答数据微调的医疗LLM，其疾病诊断能力令人瞩目。但我们也发现，尽管专业知识有所增强，医疗LLM在处理长篇上下文时却表现不佳，远逊于参数相近的通用模型。本研究聚焦于医疗LLM在长上下文理解中的性能下滑现象，设计了一系列实验，通过开卷专业知识考试来检验各模型处理长篇文本的能力。我们通过调整微调中通用与医疗数据的比例，探寻最佳数据组合，旨在优化专业模型，实现长上下文理解与专业知识间的和谐平衡。
[Arxiv](https://arxiv.org/abs/2407.11536)
==========
# LRQ：借助学习低秩权重缩放矩阵，优化大型语言模型的训练后量化过程。
发布时间：2024年07月16日
`LLM理论` `人工智能` `计算机科学`
> LRQ: Optimizing Post-Training Quantization for Large Language Models by Learning Low-Rank Weight-Scaling Matrices
# 摘要
> 随着 LLM 的商业化，权重-激活量化技术崭露头角，旨在压缩和加速 LLM，同时降低推理成本。然而，现有 PTQ 技术在量化 LLM 时仍面临精度下降问题，尤其是在大规模多任务语言理解中。为此，我们提出低秩量化 (LRQ)，一种简单高效的后训练权重量化方法，通过低秩权重缩放矩阵重建 Transformer 块输出，减少可学习参数数量，增强量化 LLM 的泛化能力。我们在多种量化方案中展示了 LRQ 的优越性，并公开代码以供 LLM 研究者和工程师参考。
[Arxiv](https://arxiv.org/abs/2407.11534)
==========
# 大型语言模型推理研究综述
发布时间：2024年07月16日
`LLM理论` `人工智能`
> Reasoning with Large Language Models, a Survey
# 摘要
> 将语言模型扩展至数十亿参数，开启了上下文学习的新纪元，使得模型能够对未经专门训练的任务进行指令调整和少样本学习，从而在翻译、摘要和问答等语言任务上取得显著突破。不仅如此，近期思维链提示学习的进步更展示了LLMs在“系统2”推理能力上的强大潜力，引发了关于LLMs能否进行推理的讨论。这一探索始于LLMs是否能解决小学数学应用题的疑问。本文深入探讨了基于提示的推理与LLMs领域的迅猛发展，提出了一套分类法，涵盖了多步骤推理的生成、评估与控制方式。我们详细剖析了核心方法与待解难题，并勾勒出近期的研究蓝图。最后，我们探讨了推理与基于提示学习之间的联系，以及推理、序列决策过程与强化学习之间的相互关系。我们发现，通过巧妙运用提示，推理过程的自改进、自我反思及部分元认知能力得以实现。然而，真正的自我改进与自我推理，即从LLMs辅助的推理转向LLMs自主的推理，仍是未来探索的方向。
[Arxiv](https://arxiv.org/abs/2407.11511)
==========
# 动态标识符预测的自举预训练在生成式检索中发挥作用
发布时间：2024年07月16日
`LLM应用` `信息检索` `预训练模型`
> Bootstrapped Pre-training with Dynamic Identifier Prediction for Generative Retrieval
# 摘要
> 生成式检索通过可微搜索索引直接生成与查询相关的文档标识符。最新研究显示，通过精心设计的预训练任务训练的强大生成式检索模型，能通过微调显著提升下游检索任务。然而，由于依赖预定义的静态文档标识符，这些标识符可能与不断变化的模型参数不一致，导致预训练在生成式检索中的潜力未被充分挖掘。为此，我们提出了BootRet，一种自举预训练方法，该方法在预训练期间动态调整文档标识符，以适应语料库的不断记忆。BootRet包含三个关键训练阶段：初始标识符生成、通过语料库索引和相关性预测任务进行预训练，以及标识符更新的自举。此外，我们还引入了由大型语言模型生成的大量噪声文档和伪查询，以模拟索引和检索任务中的语义联系。实验结果显示，BootRet不仅显著超越了现有的预训练生成式检索基线，而且在零-shot设置下也表现出色。
[Arxiv](https://arxiv.org/abs/2407.11504)
==========
# 不仅仅是掩码：探索少样本分割中指导类型的多样性
发布时间：2024年07月16日
`LLM应用` `计算机视觉` `机器学习`
> Beyond Mask: Rethinking Guidance Types in Few-shot Segmentation
# 摘要
> 当前的少样本分割方法主要侧重于原型特征的生成与查询-支持匹配机制。支持集中的图像-掩码对作为关键提示，已成为标准配置。然而，图像、文本、框和掩码等多种类型均能提供关于对象的丰富信息。现有研究多聚焦于特定指导组合，使得 FSS 研究走向不同分支。重新审视 FSS 中的指导类型，有望推动支持集与查询集间高效联合表示的研究，进而探索满足实际用户需求的弱或强注释指导方法。本研究提出了七种指导范式，并构建了通用视觉-语言框架 UniFSS，整合多源提示。借助大规模预训练模型的优势，UniFSS 通过高级空间校正与嵌入交互单元，有效应对了纯视觉匹配方法在类内外观多样性下的语义模糊问题。实验结果显示，UniFSS 性能卓越，甚至弱注释的类感知框范式也超越了精细注释的掩码范式。
[Arxiv](https://arxiv.org/abs/2407.11503)
==========
# 不仅追求正确性，更对大型语言模型的多维度代码生成能力进行全面基准测试。
发布时间：2024年07月16日
`LLM应用` `软件开发` `人工智能`
> Beyond Correctness: Benchmarking Multi-dimensional Code Generation for Large Language Models
# 摘要
> 近年来，尽管研究人员为评估大型语言模型（LLM）的编码能力提出了众多基准，但这些基准主要侧重于代码的正确性，忽略了其他关键维度。为此，我们提出了RACE基准，全面评估代码在可读性、可维护性、正确性和效率四个方面的质量。我们针对不同维度设计了多样化的用户需求，以测试模型生成符合用户需求的正确代码的能力。通过对18个代表性LLM的评估，我们发现：1）LLM按需生成高质量代码的能力尚不达标；2）可读性是衡量代码整体质量的关键指标；3）多数LLM偏好特定编码风格。这些发现有助于深入理解LLM的编码能力，并为未来的模型优化指明方向。
[Arxiv](https://arxiv.org/abs/2407.11470)
==========
# 别轻信机器人：揭秘人类与大型语言模型对话中的个人隐私泄露
发布时间：2024年07月16日
`LLM应用` `人工智能` `隐私保护`
> Trust No Bot: Discovering Personal Disclosures in Human-LLM Conversations in the Wild
# 摘要
> 通过分析人类与聊天机器人互动中的个人披露，我们能更深入地了解用户的AI素养，并推动LLM的隐私研究。我们对用户向GPT模型披露的个人信息进行了详尽分析，揭示了个人身份和敏感信息的泄露情况。基于自然对话的分析，我们构建了任务与敏感话题的分类，以探索用户披露的背景。我们发现：个人身份信息常在翻译或代码编辑等意外情境中出现，且仅依赖PII检测无法全面捕捉互动中的敏感话题。这些高披露率对研究者和数据管理者至关重要，我们呼吁设计有效的推动机制，引导用户合理互动。
[Arxiv](https://arxiv.org/abs/2407.11438)
==========
# 基因组语言模型：探索机遇，迎接挑战
发布时间：2024年07月16日
`LLM应用` `生物医学` `基因组学`
> Genomic Language Models: Opportunities and Challenges
# 摘要
> 大型语言模型 (LLM) 正深刻影响着众多科学领域，尤其是在生物医学科学中。与自然语言处理旨在理解单词序列类似，生物学也致力于解析生物序列。基因组语言模型 (gLMs)，即基于 DNA 序列训练的 LLM，有望大幅提升我们对基因组及其复杂功能生成机制的理解。本文通过展示 gLMs 在适应性预测、序列设计和迁移学习等关键领域的应用，揭示了其潜力。然而，尽管近期有所突破，开发高效 gLMs 仍充满挑战，特别是针对那些基因组庞大且复杂的物种。我们探讨了开发与评估 gLMs 的关键要点。
[Arxiv](https://arxiv.org/abs/2407.11435)
==========
# 通过反射性指令调整，我们旨在减轻大型视觉-语言模型中的幻觉问题。
发布时间：2024年07月16日
`LLM应用` `人工智能` `计算机视觉`
> Reflective Instruction Tuning: Mitigating Hallucinations in Large Vision-Language Models
# 摘要
> 大型视觉-语言模型 (LVLMs) 在多种视觉-语言任务上表现出色，但仍易产生与视觉内容或指令不符的幻觉输出。尽管有多种缓解策略，但常忽视训练中细粒度推理监督的缺失。为此，我们提出反思指令调优，将原理学习融入视觉指令调优，不同于仅从响应中学习，我们的方法要求模型预测响应正确或错误的原理，深化对细粒度推理的理解，提升推理能力。为此，我们创建了 REVERIE 数据集，包含 115k 推理指令，每个指令都附有正确和混淆响应及详细原理注释。实验表明，使用 REVERIE 的反思指令调优显著提升了模型性能，证明了从原理中反思的有效性。项目详情见 https://zjr2000.github.io/projects/reverie。
[Arxiv](https://arxiv.org/abs/2407.11422)
==========
# LLM 在隐藏状态中悄然涌现出离散的状态表示，这一现象虽隐秘却引人深思。
发布时间：2024年07月16日
`LLM理论` `人工智能` `计算机科学`
> States Hidden in Hidden States: LLMs Emerge Discrete State Representations Implicitly
# 摘要
> 大型语言模型 (LLM) 展现出多种新兴能力，其中一些揭示了模型的内部工作机制。本文揭示了一种新颖能力：模型能在不依赖逐步思维链的情况下执行复杂计算。最先进的模型甚至能直接处理长达15个加数的两位数加法。我们推测，模型通过隐式离散状态表示 (IDSRs) 在内部进行符号计算。为验证这一假设，我们设计了一系列实验，从层、数字和序列角度深入研究IDSRs的形成及其在模型中的应用。尽管发现当前开源模型中的IDSRs存在缺陷，导致性能不精确，但我们的研究仍为探索LLM的符号计算能力及其机制开辟了新视角。
[Arxiv](https://arxiv.org/abs/2407.11421)
==========
# SDPT：为融合型视觉-语言预训练模型设计的同步双提示调优技术
发布时间：2024年07月16日
`LLM应用` `计算机视觉`
> SDPT: Synchronous Dual Prompt Tuning for Fusion-based Visual-Language Pre-trained Models
# 摘要
> 提示调优方法在大型预训练模型上的参数高效微调方面取得了显著成功，但在基于双模态融合的视觉-语言预训练模型（如GLIP）上的应用遇到了挑战。现有的提示调优方法未能有效解决不同模态中标记的模态映射和对齐问题，导致迁移泛化效果不佳。为此，我们提出了同步双提示调优（SDPT），在已建立的模态对齐空间中初始化一组可学习的统一原型标记，以表示文本和图像模态对齐的语义，用于下游任务。此外，SDPT通过无需训练的逆线性投影，将统一原型标记的信息嵌入到不同模态的输入空间中，使得统一原型标记能够同步表示两种模态，并使SDPT能够在不同模态提示之间共享文本和图像的统一语义，用于下游任务。实验结果显示，SDPT帮助基于融合的VLPMs在各种场景下仅用0.04%的模型参数进行训练，就能取得优于其他单模态或双模态方法的成果。代码将在https://github.com/wuyongjianCODE/SDPT发布。
[Arxiv](https://arxiv.org/abs/2407.11414)
==========
# 大型语言模型在模拟政治样本时，存在表示偏差问题。
发布时间：2024年07月16日
`LLM应用` `社会科学`
> Representation Bias in Political Sample Simulations with Large Language Models
# 摘要
> 本研究致力于揭示并量化大型语言模型在模拟政治样本时的偏差，尤其聚焦于投票选择与公众意见。通过GPT-3.5-Turbo模型，结合美国、德国的选举研究数据以及中国相关数据集，我们模拟了投票行为与公众意见。此方法揭示了三种代表性偏差：语言、人口群体及政治体制的差异。结果显示，投票选择的模拟效果优于公众意见，英语国家的模拟更为准确，两党制系统的表现优于多党制，民主环境下的效果强于威权体制。这些发现有助于深化我们对AI在计算社会科学应用中偏差的认识，并推动相关策略的开发，以减少偏差。
[Arxiv](https://arxiv.org/abs/2407.11409)
==========
# 心理健康AI聊天机器人的适当性、可信度与安全性评估框架
发布时间：2024年07月16日
`LLM应用` `心理健康` `人工智能`
> A Framework for Evaluating Appropriateness, Trustworthiness, and Safety in Mental Wellness AI Chatbots
# 摘要
> 大型语言模型聊天机器人易受偏见和幻觉影响，而当前心理健康技术评估缺乏全面案例研究。为此，我们推出了MHealth-EVAL框架，一种基于角色扮演的互动评估方法，专为评估心理健康聊天机器人的适当性、可信度和安全性设计。同时，我们引入了Psyfy聊天机器人，它利用LLM促进跨诊断CBT。通过对比Psyfy与标准基准聊天机器人的研究，我们展示了MHealth-EVAL框架的实用性。结果表明，Psyfy在提供适当回应、吸引用户和避免不可信回应方面表现更佳。然而，Psyfy和基准聊天机器人都存在局限，如主要提供美国中心资源。尽管Psyfy能识别大多数不安全情况并避免不安全回应，但在角色扮演场景中有时难以识别微妙恶意意图。本研究不仅展示了MHealth-EVAL框架的实际应用，还突显了Psyfy在利用LLM增强用户参与度和提供灵活适当回应方面的价值。
[Arxiv](https://arxiv.org/abs/2407.11387)
==========
# 超越自然语言的可靠推理
发布时间：2024年07月16日
`LLM应用` `人工智能`
> Reliable Reasoning Beyond Natural Language
# 摘要
> 尽管 LLMs 语言能力出众，但在可靠与灵活的推理上常显不足。为此，我们创新性地采用神经符号方法，引导 LLMs 将问题信息转化为逻辑代码，并借助 Prolog 进行精确的演绎推理。这一策略大幅提升了 LLMs 在 GSM8k 和 BIG-bench 的 Navigate 数据集上的表现。同时，我们推出了非线性推理 (NLR) 数据集，包含 55 个独特问题，旨在挑战 LLMs 的预测模式，并强调复杂推理与基础算术的结合。实证显示，Prolog 的引入使 LLMs 在 NLR 数据集上表现卓越，超越了包括 GPT4 在内的顶尖模型仅凭文本的解决能力。
[Arxiv](https://arxiv.org/abs/2407.11373)
==========
# 科学问答系统：答案可验证
发布时间：2024年07月16日
`RAG` `科学研究` `信息检索`
> Scientific QA System with Verifiable Answers
# 摘要
> 本文介绍了VerifAI项目，这是一个前沿的开源科学问答系统，旨在提供不仅基于参考文献，还经过自动审查和验证的答案。系统包含三个核心部分：（1）结合语义和词汇搜索技术的信息检索系统，覆盖科学论文（如PubMed）；（2）利用微调生成模型（如Mistral 7B）和检索文章的检索增强生成（RAG）模块，生成附有来源文章引用的声明；（3）基于在SciFACT数据集上微调的DeBERTa和XLM-RoBERTa模型的验证引擎，确保生成的声明与来源文章一致，无幻觉产生。Verif.ai通过信息检索和RAG模块，从众多科学资源中提炼事实信息，而验证引擎则严格复核这些信息，确保其精确可靠。这一双重验证流程在确保信息准确性方面至关重要，极大提升了信息质量。我们的方法不仅提升科学家工作效率，还增强了在科学领域内使用生成语言模型的信任度，因为该领域不容许幻觉和错误信息的存在。
[Arxiv](https://arxiv.org/abs/2407.11485)
==========
# UrbanWorld：开创性的3D城市生成模型，专为城市世界设计。
发布时间：2024年07月16日
`Agent` `城市规划` `人工智能`
> UrbanWorld: An Urban World Model for 3D City Generation
# 摘要
> 城市，人类生活的基石，汇聚了建筑、道路、植被等多元元素，交织成错综复杂的网络。打造逼真互动的3D城市环境，对于培养能在现实世界中如人般感知、决策、行动的AI代理至关重要。然而，高保真3D城市的构建往往依赖设计师的繁重手工，细节与真实性的追求成为一大难题。为此，我们创新推出UrbanWorld，首个能自动生成定制化、真实互动3D城市世界的模型。它通过四大自动化步骤：利用OSM数据生成3D布局，借助Urban MLLM进行城市规划设计，运用3D扩散技术渲染可控城市元素，以及MLLM辅助的场景精修，打造出高保真3D城市环境，为AI与机器感知系统在模拟中的真实交互提供可能。我们致力于将UrbanWorld打造成一个开源多功能的平台，助力AI在城市环境中的感知、决策与交互能力的提升。
[Arxiv](https://arxiv.org/abs/2407.11965)
==========
# NeedleBench 挑战：LLM 能否在百万级上下文窗口中同时进行检索与推理？
发布时间：2024年07月16日
`LLM应用` `人工智能`
> NeedleBench: Can LLMs Do Retrieval and Reasoning in 1 Million Context Window?
# 摘要
> 在评估大型语言模型的长上下文能力时，从长文档中提取与用户查询相关的内容至关重要。为此，我们设计了NeedleBench框架，通过一系列渐进式挑战任务，全面测试模型的双语长上下文处理能力，涵盖从4k到1000k及以上不同长度和深度区间，并战略性地在文本不同深度区域插入关键数据点，以严格检验模型的检索与推理能力。我们利用这一框架评估了领先开源模型在双语长文本中识别关键信息并进行有效推理的能力。此外，我们还提出了Ancestral Trace Challenge（ATC），模拟现实世界长上下文任务中可能遇到的复杂逻辑推理挑战，为评估LLM在复杂情境下的表现提供了一种简便方法。研究结果显示，当前LLM在实际长上下文应用中仍有较大提升空间，特别是在应对复杂逻辑推理挑战方面。所有相关代码和资源已公开在OpenCompass平台：https://github.com/open-compass/opencompass。
[Arxiv](https://arxiv.org/abs/2407.11963)
==========
# 通过代码文档与分析，保障软件开发的安全性
发布时间：2024年07月16日
`LLM应用` `软件开发` `编程工具`
> Code Documentation and Analysis to Secure Software Development
# 摘要
> 我们推出了代码文档与分析工具CoDAT，旨在确保代码文档各层级的一致性。例如，当代码草图中某行变动时，相关注释也会同步更新，确保注释与代码始终保持一致。CoDAT通过标记过时注释，提醒开发者及时更新文档。此外，我们利用大型语言模型检查代码与注释间的语义一致性，帮助程序员准确实现代码草图，为逐步细化编程方法提供机器辅助。CoDAT集成于Intellij IDEA IDE，结合Code Insight守护程序与自定义正则算法，高效标记变更代码对应的注释。其后端采用去中心化结构，支持代码一致性与架构编译的分布式跟踪。
[Arxiv](https://arxiv.org/abs/2407.11934)
==========
# 如何改进？借助 LLM 反馈精炼会议摘要
发布时间：2024年07月16日
`LLM应用` `文本生成`
> What's Wrong? Refining Meeting Summaries with LLM Feedback
# 摘要
> 随着数字会议的普及，会议摘要变得至关重要。大型语言模型（LLM）在摘要任务中展现出优于传统方法的连贯性和上下文理解能力，但仍需克服保持相关性和避免幻觉的挑战。为此，我们提出了一种模拟人类审查流程的两阶段多LLM校正方法：首先识别错误，然后精炼摘要。我们发布的QMSum Mistake数据集包含了200个由人工标注的自动生成摘要，涵盖九种错误类型。实验表明，LLM能高精度地识别这些错误。通过将识别的错误转化为具体反馈，我们提升了摘要的相关性、信息量、简洁性和连贯性。这种事后精炼方法通过多LLM协作验证输出质量，显著提高了摘要的整体质量。我们的方法不仅适用于会议摘要，还可能在需要高度鲁棒性和目标导向讨论的复杂文本生成任务中发挥潜力。
[Arxiv](https://arxiv.org/abs/2407.11919)
==========
# 针对大规模数据集和特征导向，评估大语言模型中文本摘要的表现
发布时间：2024年07月16日
`LLM应用` `人工智能`
> Towards Dataset-scale and Feature-oriented Evaluation of Text Summarization in Large Language Model Prompts
# 摘要
> 随着大型语言模型和提示工程的进步，定制聊天机器人变得更加简单，大幅降低了编程技能的门槛。但在数据集规模上评估提示依然复杂，需要在众多测试实例中进行。我们的研究总结了五个关键挑战，并提出了一种基于特征的系统评估工作流程。在文本摘要领域，我们建议采用复杂性、正式性等特征指标，而非传统质量指标，以提升评估的用户友好性。为此，我们开发了Awesum可视化系统，通过创新的Prompt Comparator设计，助力用户在自然语言的模糊性中找到最佳提示改进。实践证明，该系统不仅帮助非技术人员进行有效评估，还可能适用于其他自然语言生成和图像生成任务。未来，我们将探索更多面向特征的评估方法，并解决人-代理交互中的挑战。
[Arxiv](https://arxiv.org/abs/2407.12192)
==========
# 打造自主云AI代理：面临的挑战与设计原则
发布时间：2024年07月16日
`Agent` `信息技术` `云计算`
> Building AI Agents for Autonomous Clouds: Challenges and Design Principles
# 摘要
> 随着大型语言模型（LLM）和AI代理在软件开发中的广泛应用，信息技术领域正经历一场革命。尽管代码生成备受瞩目，但更关键的应用在于利用AI提升云服务的运营韧性，这一领域目前仍依赖大量人力和专业知识。AIOps（AI for IT Operations）的兴起旨在自动化复杂任务，如故障定位和根本原因分析，以减少人工干预和客户影响。然而，实现自主自愈云的愿景因缺乏标准化框架而受阻。本文通过设定需求并讨论相应设计决策，为构建此类框架奠定了基础。我们还推出了AIOpsLab原型，通过代理-云接口协调应用，利用混沌工程实时注入故障，并与代理协作定位和解决故障。初步结果令人鼓舞，为构建模块化、健壮的自主云代理框架奠定了基础。
[Arxiv](https://arxiv.org/abs/2407.12165)
==========
# 循环中的 LLM 第一章：专为生物医学文本翻译设计的小型 AI 专家模型
发布时间：2024年07月16日
`LLM应用` `机器翻译`
> LLMs-in-the-loop Part-1: Expert Small AI Models for Bio-Medical Text Translation
# 摘要
> 在医疗领域，机器翻译对于跨语言传播医学知识至关重要。然而，复杂的医学术语为高质量翻译带来了挑战。本研究采用“LLMs-in-the-loop”策略，针对医学文本优化神经机器翻译模型。研究表明，即使小型专业模型，通过高质量合成数据训练，也能超越大型通用模型。我们从科学文献、合成临床文档和医学文本中构建了六种语言的平行语料库。通过合成数据生成、严格评估和智能编排，我们的方法显著提升了翻译性能。基于MarianMT模型，我们开发了小型医学翻译模型，并引入新的测试数据集以标准化评估。评估结果显示，我们的模型在多项指标上超越了Google Translate、DeepL和GPT-4-Turbo。研究结果表明，结合高质量领域数据微调的LLMs-in-the-loop方法，能够使专业模型在性能上超越通用和某些大型系统。作为专家小型模型研究系列的一部分，本研究为未来医疗AI发展，如去标识化和生物医学实体提取，奠定了基础。我们的工作展示了定制神经翻译模型和LLMs-in-the-loop方法在改进数据处理、评估和建模技术方面的潜力，有望推动医疗翻译领域的进步。
[Arxiv](https://arxiv.org/abs/2407.12126)
==========
# 变分法巧妙地连接了光-物质相互作用的量子与半经典极限，为探索这一复杂领域提供了新的视角。
发布时间：2024年07月16日
`LLM理论` `光电子学` `量子计算`
> Variational approach to light-matter interaction: Bridging quantum and semiclassical limits
# 摘要
> 我们采用时间依赖的变分方法，结合多重 Davydov $D_2$ 试探态，模拟了光-物质系统在场处于任意有限平均光子数的相干态时的动力学。该方法不仅捕捉系统与场的动力学，还适用于多种量子模型，如 Jaynes-Cummings、Rabi 和 Dicke 模型，并能处理多模量子场。通过对比变分与半经典动力学，我们发现，只要平均光子数足够大，量子与半经典模型的动力学表现一致。此外，在量子与半经典极限的过渡区，量子修正导致动力学振荡的崩溃，这在半经典模型中未见。此变分方法为光-物质相互作用提供了一种从量子到半经典的统一处理方式。
[Arxiv](https://arxiv.org/abs/2407.12228)
==========
# 数据中毒攻击：揭秘其如何削弱生成模型的威力
发布时间：2024年07月16日
`LLM应用` `人工智能安全`
> Turning Generative Models Degenerate: The Power of Data Poisoning Attacks
# 摘要
> 随着第三方训练的大型语言模型的广泛应用，安全问题日益凸显。恶意分子可能通过中毒攻击植入后门，导致生成不良内容。尽管图像和分类任务中的此类攻击已被深入研究，但针对自然语言生成任务的研究仍显不足。为此，我们通过前缀调优这一高效微调方法，深入探讨了针对LLM微调阶段的中毒技术。我们不仅评估了这些技术在文本摘要和文本补全任务中的效果，还创新性地引入了衡量攻击成功与隐蔽性的新指标。实验表明，前缀调优的超参数和触发设计是决定攻击成败的关键。同时，我们发现现有防御措施对这些攻击束手无策。本研究首次全面分析了通过PEFT进行微调时，针对NLG任务的中毒攻击，期待能为AI安全领域提供有力支持，助力开发有效防御策略。
[Arxiv](https://arxiv.org/abs/2407.12281)
==========
# VCP-CLIP：专为零-shot异常分割设计的视觉上下文提示模型
发布时间：2024年07月16日
`LLM应用` `制造业` `计算机视觉`
> VCP-CLIP: A visual context prompting model for zero-shot anomaly segmentation
# 摘要
> 近期，CLIP 等大规模视觉-语言模型在零-shot 异常分割任务中展现出巨大潜力，通过统一模型和精心设计的文本提示，直接检测未见产品的异常。但现有方法常假设产品类别已知，设置特定文本提示，这在数据隐私场景中难以实现。此外，同一产品因组件和生产过程差异，存在显著变化，对文本提示设计构成挑战。为此，我们提出基于 CLIP 的视觉上下文提示模型 VCP-CLIP，旨在通过视觉上下文提示激活 CLIP 的异常语义感知能力。具体而言，我们设计 Pre-VCP 模块，将全局视觉信息嵌入文本提示，消除特定产品提示需求；并提出 Post-VCP 模块，利用图像细粒度特征调整文本嵌入。在 10 个真实工业异常分割数据集上的实验表明，VCP-CLIP 在 ZSAS 任务中表现卓越。代码已公开，详见 https://github.com/xiaozhen228/VCP-CLIP。
[Arxiv](https://arxiv.org/abs/2407.12276)
==========
# 上下文探针法近似模拟了数据评估中的影响函数。
发布时间：2024年07月16日
`LLM理论` `人工智能` `数据科学`
> In-Context Probing Approximates Influence Function for Data Valuation
# 摘要
> 数据估值通过量化训练数据的价值，对于提升大型语言模型的训练数据集质量至关重要。我们通过上下文探针（提示LLM）展示了数据估值与选择训练数据的影响函数相近。基于变换器模型的“隐式”梯度下降，我们提供了理论联系的初步分析。实证研究表明，上下文探针与梯度影响框架在数据排序上表现相似，且两种方法选出的数据在微调后均能提升模型性能。
[Arxiv](https://arxiv.org/abs/2407.12259)
==========
# 机器学习领域存在一些值得质疑的做法。
发布时间：2024年07月16日
`LLM理论` `人工智能` `研究方法论`
> Questionable practices in machine learning
# 摘要
> 评估现代ML模型颇具挑战。为了在特定指标上取得领先成果，研究者和企业常采取可疑的研究手段（QRPs），虽未触及欺诈，但仍属不当。我们列举了43种此类手段，它们可能削弱研究成果的可信度，并尽可能提供实例。我们特别关注大型语言模型（LLMs）在公开基准上的表现评估。此外，我们还探讨了“不可复现的研究实践”，这些决策使得他人难以或无法复现、拓展或审查先前的研究成果。
[Arxiv](https://arxiv.org/abs/2407.12220)
==========
# 《Mindful-RAG》：探究检索增强生成技术中的关键失败点研究
发布时间：2024年07月16日
`RAG` `人工智能` `知识图谱`
> Mindful-RAG: A Study of Points of Failure in Retrieval Augmented Generation
# 摘要
> 大型语言模型虽擅长生成连贯文本，但在处理特定领域和事实问答任务时，面对知识密集型查询仍显力不从心。检索增强生成系统通过引入外部知识源如知识图谱来缓解这一难题，但即便拥有必要事实信息，LLM 仍常难以给出准确答案。我们研究发现，现有基于知识图谱的 RAG 方法存在八大关键失误，主要源于对问题意图的辨识不足及对相关上下文的收集不充分。为此，我们提出 Mindful-RAG 框架，专注于基于意图和上下文对齐的知识检索，旨在精准定位并改善这些失误，从而提升 LLM 响应的准确性与相关性，较现有方法实现显著进步。
[Arxiv](https://arxiv.org/abs/2407.12216)
==========
# 神经段落质量评估助力静态剪枝
发布时间：2024年07月16日
`LLM应用` `搜索引擎` `信息技术`
> Neural Passage Quality Estimation for Static Pruning
# 摘要
> 神经网络，尤其是那些基于大型预训练语言模型的，已经从多方面提升了搜索引擎的性能。其中最显著的是，它们能够评估文本或文档与用户查询的相关性。在本研究中，我们转向一个新的方向，探讨神经网络是否能有效预测文档中的哪些段落与任何查询都可能不相关。我们将这种与查询无关的段落相关性评估称为“段落质量”。我们发现，通过我们创新的段落质量评估方法，可以在保持同等有效性的前提下，大幅精简段落语料库；我们的最佳方法能在不同检索系统中稳定地减少超过25%的段落。这种大幅度的精简不仅降低了神经搜索引擎的运营成本，包括计算资源、电力消耗和碳排放，还优化了查询处理和索引构建过程。这一研究为未来开发更先进的神经网络索引策略奠定了基础。
[Arxiv](https://arxiv.org/abs/2407.12170)
==========
# 通过相关信息增益优化 RAG
发布时间：2024年07月16日
`RAG` `人工智能` `计算机科学`
> Better RAG using Relevant Information Gain
# 摘要
> 扩展 LLM 记忆的常用手段是 RAG，它将外部文本引入模型上下文。但上下文窗口的限制意味着我们需要精心挑选信息，既要多样又要相关。为此，我们设计了一种新的优化指标，基于相关信息增益，自然地促进多样性。这一创新方法在 RGB 基准的问题回答任务中表现卓越，超越了传统方法。
[Arxiv](https://arxiv.org/abs/2407.12101)
==========
# 跨模态增强技术在少样本多模态假新闻检测中发挥作用。
发布时间：2024年07月16日
`LLM应用` `网络安全`
> Cross-Modal Augmentation for Few-Shot Multimodal Fake News Detection
# 摘要
> 假新闻的自动检测亟需从有限样本中快速学习的方法。因此，少样本学习能力对于早期假新闻检测至关重要。本文提出了一种多模态假新闻检测模型，通过单模态特征增强多模态特征，并引入了跨模态增强（CMA）方法，将n-shot分类转化为更稳健的（n×z）-shot问题，显著提升了检测性能。CMA在三个基准数据集上取得了顶尖成果，仅用少量样本和简单的线性探测方法即可分类多模态假新闻。此外，我们的方法在参数和训练时间上远比现有方法轻量。代码已公开：\url{https://github.com/zgjiangtoby/FND_fewshot}
[Arxiv](https://arxiv.org/abs/2407.12880)
==========
# 大型视觉-语言模型同样擅长分类，本研究聚焦于上下文多模态假新闻检测。
发布时间：2024年07月16日
`LLM应用`
> Large Visual-Language Models Are Also Good Classifiers: A Study of In-Context Multimodal Fake News Detection
# 摘要
> 大型视觉-语言模型（LVLMs）在跨模态推理任务中表现出色，但在假新闻检测（FND）方面，大型语言模型如GPT-3.5-turbo却不如小型模型BERT。本文通过对比CogVLM和GPT4V与CLIP在零-shot情境下的FND能力，发现LVLMs能与小型模型匹敌。结合标准in-context learning（ICL）后，FND性能虽有提升但有限。为此，我们创新提出In-context Multimodal Fake News Detection（IMFND）框架，通过整合小型模型的预测概率，引导LVLMs聚焦高概率新闻片段，大幅提升分析准确性。实验证实，IMFND在三个FND数据集上超越了传统ICL方法，显著提高了LVLMs的FND效率。
[Arxiv](https://arxiv.org/abs/2407.12879)
==========
# 在LLM中，分类任务时白化处理并非良策。
发布时间：2024年07月16日
`LLM应用` `机器学习`
> Whitening Not Recommended for Classification Tasks in LLMs
# 摘要
> 句子嵌入作为 NLP 的核心，白化技术被认为能提升 LLM 的嵌入质量。但研究发现，白化的有效性因模型和任务而异，尤其在分类任务中，白化反而降低了嵌入质量。通过广泛实验验证了这一发现。此外，我们还深入研究了多种白化方法，如 PCA、ZCA 等，并开发了 LLM 嵌入评估工具 SentEval+。
[Arxiv](https://arxiv.org/abs/2407.12886)
==========
# BRIGHT：一个真实且充满挑战的基准，专为推理密集型检索任务设计。
发布时间：2024年07月16日
`LLM应用` `软件工程` `经济学`
> BRIGHT: A Realistic and Challenging Benchmark for Reasoning-Intensive Retrieval
# 摘要
> 现有的检索基准多聚焦于简单的信息查询，而面对复杂查询时，深入推理变得至关重要。为此，我们推出了BRIGHT，首个要求深度推理的文本检索基准，涵盖了从经济学到软件工程等多个领域的1,398个真实查询。评估显示，顶尖检索模型在BRIGHT上的表现也大打折扣。通过引入大型语言模型的思维链推理，我们成功提升了检索性能。BRIGHT还展现了对抗预训练数据泄露的稳健性。我们期待BRIGHT能推动检索系统在更复杂场景中的研究。相关代码和数据已公开，详情请访问https://brightbenchmark.github.io。
[Arxiv](https://arxiv.org/abs/2407.12883)
==========
# ReFeR：一个创新的 NLG 评估与推理框架
发布时间：2024年07月16日
`LLM应用` `人工智能`
> Review-Feedback-Reason (ReFeR): A Novel Framework for NLG Evaluation and Reasoning
# 摘要
> 评估大型语言模型（LLM）生成的自然语言（NLG）输出的质量面临重大挑战。传统方法要么依赖资源密集型的人工评估，要么采用与人类判断相关性较低的自动指标。本研究提出了一种名为Review-Feedback-Reason（ReFeR）的新型评估框架，利用LLM代理进行NLG评估。通过在两个多样化的NLG任务基准数据集上严格测试，ReFeR不仅将评估准确性提高了约20％，还提供了建设性反馈，显著增强了集体推理能力。这些反馈进一步用于构建指令调优数据集，当应用于微调Mistral-7B等小型模型时，使其评估能力大幅提升，与人类评估的相关性更佳，性能接近GPT-3.5。在三个推理基准测试中，我们的方法表现卓越，超越了众多顶尖技术，平均推理能力分别比GPT-3.5 Turbo和GPT-4高出约11.67％和1％。
[Arxiv](https://arxiv.org/abs/2407.12877)
==========
# Think-on-Graph 2.0：结合知识图谱引导检索，实现深度且可解释的大型语言模型推理
发布时间：2024年07月15日
`RAG` `人工智能` `知识图谱`
> Think-on-Graph 2.0: Deep and Interpretable Large Language Model Reasoning with Knowledge Graph-guided Retrieval
# 摘要
> RAG 通过动态信息检索显著提升了 LLM 的性能，但面对复杂推理和多样查询的一致性时仍显不足。我们提出的 Think-on-Graph 2.0 框架，通过将问题与知识图谱对齐并利用其导航，深化了 RAG 的信息收集与整合能力。KG 引导的导航不仅增强了逻辑一致性，还优化了检索精度与互操作性。此外，精确指令引导的语义相似性进一步确保了事实一致性。ToG2.0 不仅提升了 LLM 响应的准确性与可靠性，还展现了混合知识系统在推进 LLM 推理方面的巨大潜力，使其更贴近人类表现。我们在四个公共数据集上的实验充分证明了我们方法的优势。
[Arxiv](https://arxiv.org/abs/2407.10805)
==========
# 通过四模块协同，RAG 系统在增强检索和管理检索方面实现了质量和效率的双重提升。
发布时间：2024年07月15日
`RAG` `问答系统` `人工智能`
> Enhancing Retrieval and Managing Retrieval: A Four-Module Synergy for Improved Quality and Efficiency in RAG Systems
# 摘要
> RAG技术借助LLM的上下文学习能力，生成更精准、更贴切的回答。从最初的“检索-阅读”模式，RAG框架已进化为一个高度灵活且模块化的体系。其中，查询重写器模块通过生成易于搜索的查询，提升了知识检索的精准度，使问题与知识库更紧密契合。我们的研究发现，通过生成多重查询以突破单一查询的信息瓶颈，并通过重写问题消除歧义，可以进一步强化查询重写器模块，升级为查询重写器+。同时，针对RAG系统中存在的无关知识问题，我们提出了知识过滤器。这两个模块均基于Gemma-2B模型，共同提升回答质量。此外，针对冗余检索问题，我们引入了记忆知识库和检索器触发器，前者支持知识库的无参数动态扩展，后者优化了外部知识访问成本，提升了资源利用率和响应效率。这四大RAG模块协同作用，显著提升了RAG系统的响应质量和效率。相关实验和消融研究已在六个常见QA数据集上验证了这些模块的有效性。源代码可访问https://github.com/Ancientshi/ERM4获取。
[Arxiv](https://arxiv.org/abs/2407.10670)
==========
# Spider2-V 探讨了多模态代理在自动化数据科学和工程流程方面的进展，以及它们与实现这一目标的距离。
发布时间：2024年07月15日
`Agent` `数据科学` `软件工程`
> Spider2-V: How Far Are Multimodal Agents From Automating Data Science and Engineering Workflows?
# 摘要
> 数据科学与工程的工作流程通常涉及多个环节，从数据仓储到流程编排，借助BigQuery、dbt和Airbyte等工具实现。随着视觉语言模型（VLMs）在多模态理解与代码生成方面的进步，基于VLM的智能代理有望通过自动生成SQL查询、Python代码及GUI操作，实现这些流程的自动化。这不仅能提升专家的工作效率，还能让大规模数据分析更加普及。本文介绍的Spider2-V，是首个聚焦于专业数据科学和工程流程的多模态智能代理基准，涵盖494个真实场景任务，涉及20个企业级专业应用，在真实计算机环境中进行。这些任务源自实际案例，旨在评估智能代理通过编程与GUI管理执行数据任务的能力。为确保评估的现实性与简洁性，我们精心设计了任务自动配置与评估指标。此外，我们还为智能代理提供了详尽的企业数据软件系统文档。实证研究表明，当前顶尖的基于LLM/VLM的智能代理在自动化完整数据流程方面表现不佳（成功率14.0%），即便在详细指导下，其在精细复杂的GUI操作（16.2%）及远程云工作区任务（10.6%）中仍显不足。我们期待Spider2-V能引领自主多模态智能代理革新数据科学和工程流程的自动化。相关代码与数据已公开，详见https://spider2-v.github.io。
[Arxiv](https://arxiv.org/abs/2407.10956)
==========
# GRUtopia：梦想之城，通用机器人的大规模应用
发布时间：2024年07月15日
`Agent` `机器人` `人工智能`
> GRUtopia: Dream General Robots in a City at Scale
# 摘要
> 近期研究深入探索了具身AI的规模法则。鉴于现实数据收集的高昂成本，Sim2Real范式被视为扩展具身学习的关键。本文推出的GRUtopia项目，是首个专为多类机器人设计的模拟交互3D社会。其亮点包括：（a）GRScenes数据集，包含十万精细交互场景，可自由组合成城市级环境，覆盖89种场景，弥补了服务型机器人的应用环境空白。（b）GRResidents系统，由LLM驱动的NPC，模拟社交互动、任务生成与分配，为具身AI提供真实社交场景。（c）GRBench基准，重点支持腿式机器人，设定物体导航、社交导航及操作等适中难度任务。期望本项目能缓解高质量数据稀缺问题，并全面评估具身AI研究。项目详情见https://github.com/OpenRobotLab/GRUtopia。
[Arxiv](https://arxiv.org/abs/2407.10943)
==========
# 大型语言模型的存在模式：一种转换机构的研究
发布时间：2024年07月15日
`LLM理论` `人工智能` `人机交互`
> Transforming Agency. On the mode of existence of Large Language Models
# 摘要
> 本文深入探讨了 ChatGPT 等大型语言模型（LLM）的本体论特性，特别聚焦于其作为代理的角色。我们详细阐述了 LLM 的架构、处理流程及训练机制，以及如何通过扩展将其转化为类似代理的系统。经过严谨分析，我们发现，根据具身心灵理论，LLM 在个体性、规范性和交互不对称性方面均未达到自主代理的标准。因此，我们提出 ChatGPT 应被视为一种对话者或语言自动机，一个能言善辩的图书馆，虽无自主代理能力，却能在非目的性但结构化、有限制的任务中展现其表演性。在与人类的互动中，人机交互的“幽灵”特质使得与 LLM 的真实对话成为可能。尽管缺乏感觉运动和生物实体，LLM 的文本和计算实体却深刻地重塑了人类代理的形式，创造出一种介于有意代理和传统技术工具性之间的中介代理形态。
[Arxiv](https://arxiv.org/abs/2407.10735)
==========
# Sibyl 框架，简洁高效，专为复杂现实推理设计。
发布时间：2024年07月15日
`Agent` `人工智能` `软件开发`
> Sibyl: Simple yet Effective Agent Framework for Complex Real-world Reasoning
# 摘要
> 现有的基于大型语言模型（LLM）的代理通过结合LLM的内在知识、强大的上下文学习能力、零-shot能力以及人类设计的精细工具使用流程，展现出卓越的问题解决能力。然而，这些代理在长期推理和工具潜力利用方面仍有不足，导致在复杂现实推理场景中表现不佳。为此，我们推出了Sibyl，一个简洁而强大的LLM代理框架，旨在通过精简工具集高效解决复杂推理任务。借鉴全球工作空间理论，Sibyl设立全局工作空间以优化知识和对话历史的系统内管理与共享。遵循心灵社会理论，Sibyl采用多代理辩论机制自我优化答案，确保决策的全面性与平衡性。这一设计不仅简化了系统架构，还拓宽了问题解决的广度，从几分钟内可解的人类任务扩展至需数小时乃至数天的复杂挑战，推动思维模式从直觉（系统1）向深思熟虑（系统2）转变。Sibyl自设计之初便注重可扩展性与调试便捷性，融入函数式编程的可重入理念，力求在其他LLM应用中实现低成本高效集成。实验表明，搭载GPT-4的Sibyl代理在GAIA基准测试中以34.55%的平均分领先同类产品，我们期待Sibyl能引领更多高效、可靠的LLM代理解决方案，助力应对现实世界的复杂推理难题。
[Arxiv](https://arxiv.org/abs/2407.10718)
==========
# LLM 在系统性文献综述中展现出了高效过滤的潜力，能够帮助我们穿透信息的杂乱，更精准地筛选出有价值的研究。
发布时间：2024年07月15日
`LLM应用` `学术研究` `文献综述`
> Cutting Through the Clutter: The Potential of LLMs for Efficient Filtration in Systematic Literature Reviews
# 摘要
> 在学术领域，系统性文献综述至关重要，但因其涉及大量出版物和繁琐流程而显得冗长。传统基于关键词的筛选方法常因语义模糊和术语不一致而效果欠佳。为此，我们探索利用大型语言模型（LLMs）提升文献筛选的效率与精准度，减少人工负担。通过模型仅作为分类工具处理结构化数据，我们规避了LLMs的常见缺陷，如产生幻觉。在最近一次文献调查中，我们评估了LLMs在处理超过8.3k篇潜在相关文章时的表现，并与人工筛选进行了对比。结果显示，借助GPT-4o等先进模型及简单提示，文献筛选时间从数周缩短至几分钟。此外，通过共识机制，我们有效控制了假阴性率，召回率超过98.8%，甚至优于人类标准，确保了选文的准确性与相关性。这一研究不仅革新了文献综述方法，更为人工智能在学术研究中的深入应用铺平了道路。
[Arxiv](https://arxiv.org/abs/2407.10652)
==========
# 借助混合智能，我们正迈向一个既可持续又节能的机器学习新时代。
发布时间：2024年07月15日
`Agent` `能源效率` `机器学习`
> Leveraging Hybrid Intelligence Towards Sustainable and Energy-Efficient Machine Learning
# 摘要
> 混合智能通过融合人类与AI的优势，旨在提升决策、问题解决及系统整体性能。随着大型语言模型（LLM）的兴起，它们作为智能代理加速机器学习发展，混合智能在人机交互中的重要性日益凸显。本文探讨了如何运用混合智能实现可持续且节能的机器学习。在模型开发中，我们往往聚焦于最终性能，却忽视了开发过程的效率。同时，鉴于大规模计算对环境的深远影响，能源效率变得至关重要。本研究通过人机回环（HITL）与LLM代理的互动，引入辅助知识源，旨在揭示并优化机器学习开发中的低效环节。
[Arxiv](https://arxiv.org/abs/2407.10580)
==========
# FabGPT：专为复杂晶圆缺陷知识查询设计的高效大型多模态模型
发布时间：2024年07月15日
`LLM应用` `半导体制造` `智能制造`
> FabGPT: An Efficient Large Multimodal Model for Complex Wafer Defect Knowledge Queries
# 摘要
> 智能技术是推动集成电路制造进步的核心。最新的大型多模态模型（LMMs）在图像与文本理解上取得了突破性进展，为智能制造开辟了新道路。我们基于此，开发了FabGPT，一款专为晶圆缺陷知识查询设计的大型多模态模型。FabGPT擅长于扫描电子显微镜（SEM）图像的缺陷检测、根本原因分析及制造过程的专家问答。它通过匹配增强的多模态特征，自动识别复杂背景下的微小缺陷，并减少人工阈值的主观影响。同时，我们的调制模块与交互式训练策略，有效整合了晶圆缺陷知识，平衡了缺陷与原始知识的查询，并解决了模态偏差问题。实验结果显示，FabGPT在晶圆缺陷检测与知识查询方面表现卓越。
[Arxiv](https://arxiv.org/abs/2407.10810)
==========
# 利用 Datagraphs 技术，我们将 LMMs 的三维推理能力提升至大型机器人任务环境，实现更高效的场景理解与决策。
发布时间：2024年07月15日
`LLM应用` `搜索与救援` `机器人`
> Scaling 3D Reasoning with LMMs to Large Robot Mission Environments Using Datagraphs
# 摘要
> 本文针对将大型多模态模型 (LMM) 扩展至广阔 3D 环境的难题，提出解决方案。尤其在搜索与救援等需要覆盖广大区域的紧急任务中，机器人的部署对此需求迫切。然而，LMM 的应用受限于其输入大小的严格上下文窗口。为此，我们创新性地采用数据图结构，使 LMM 能逐步查询大型环境的局部信息。结合图遍历算法，我们能优先处理关键地点，显著提升 3D 场景语言任务的可扩展性。虽然我们以 3D 场景为例，但该方法同样适用于点云或高斯喷射等其他密集模态。通过搜索与救援任务的实例，我们展示了数据图在 3D 场景语言任务中的应用潜力。
[Arxiv](https://arxiv.org/abs/2407.10743)
==========
# Qwen2 技术报告
发布时间：2024年07月15日
`LLM应用` `人工智能` `多语言处理`
> Qwen2 Technical Report
# 摘要
> 本报告隆重推出Qwen2系列，这是我们大型语言模型和多模态模型的最新力作。我们发布了一系列全面的基础和指令调优语言模型，参数范围从0.5亿至72亿，涵盖密集模型和专家混合模型。Qwen2不仅超越了众多先前的开放权重模型，包括其前身Qwen1.5，更在语言理解、生成、多语言能力、编码、数学和推理等多个领域与专有模型一较高下。旗舰模型Qwen2-72B表现卓越：MMLU得分84.2，GPQA得分37.9，HumanEval得分64.6，GSM8K得分89.5，BBH得分82.4。指令调优版Qwen2-72B-Instruct同样亮眼：MT-Bench得分9.1，Arena-Hard得分48.1，LiveCodeBench得分35.7。此外，Qwen2精通约30种语言，从英语到中文，从西班牙语到阿拉伯语，展现了其强大的多语言能力和全球适用性。为推动社区创新和模型普及，我们在Hugging Face和ModelScope上公开了Qwen2模型权重，并提供了GitHub上的示例代码等补充材料。这些平台还提供了量化、微调和部署的资源，助力广泛的应用和研究探索。
[Arxiv](https://arxiv.org/abs/2407.10671)
==========
# VGBench 项目旨在评估大型语言模型在矢量图形理解和生成方面的能力。
发布时间：2024年07月15日
`LLM应用`
> VGBench: Evaluating Large Language Models on Vector Graphics Understanding and Generation
# 摘要
> 在视觉模型的世界里，像素是描绘视觉内容的主要工具。然而，对于设计师和艺术家而言，几何基元如多边形可能是更好的选择。矢量图形（VG）以其文本形式，为卡通和草图等提供了更为简洁和有力的表达。近期研究显示，大型语言模型（LLMs）在处理VG方面颇具潜力。但现有工作多聚焦于定性分析或特定VG类型。为此，我们推出了VGBench，一个全面评估LLMs处理VG能力的基准，涵盖视觉理解与生成、多种VG格式、多样问题类型、广泛提示技巧及多模型应用。评估结果显示，LLMs在理解和生成方面表现出色，但在SVG等低级格式上仍有提升空间。所有数据与评估流程将公开于https://vgbench.github.io。
[Arxiv](https://arxiv.org/abs/2407.10972)
==========
# Q-Sparse 技术揭示，所有大型语言模型均能实现完全的稀疏激活。
发布时间：2024年07月15日
`LLM理论` `信息技术` `能源效率`
> Q-Sparse: All Large Language Models can be Fully Sparsely-Activated
# 摘要
> 我们引入了 Q-Sparse，这是一种既简单又高效的训练稀疏激活大型语言模型的方法。Q-Sparse 通过 top-K 稀疏化和直通估计器的应用，实现了 LLM 中激活的完全稀疏，大幅提升了推理效率。主要成果包括：Q-Sparse 在保持与基准 LLM 相当性能的同时，推理效率更高；为稀疏激活 LLM 设计了推理优化的缩放定律；适用于多种训练场景，如从头开始、继续训练和微调；兼容全精度和 1 位 LLM，如 BitNet b1.58。BitNet b1.58 与 Q-Sparse 的结合，为未来 LLM 的效率革命奠定了基础，显著降低了成本和能源消耗。
[Arxiv](https://arxiv.org/abs/2407.10969)
==========
# 针对查找表量化的大型语言模型，采用快速矩阵乘法技术。
发布时间：2024年07月15日
`LLM应用` `半导体` `人工智能`
> Fast Matrix Multiplications for Lookup Table-Quantized LLMs
# 摘要
> 在部署大型语言模型时，内存带宽常成为瓶颈，尤其是模型参数从 GPU 内存传输到寄存器的成本。结合自定义内核，仅权重量化能通过减少内存移动来加速推理。但开发适用于非均匀查找表量化的 LLM 高性能内核颇具挑战。本文介绍的 FLUTE 引擎，通过离线重构权重矩阵和优化查找表，有效缓解了这些难题。在典型推理条件下，FLUTE 内核性能较现有 GEMM 内核提升 2-4 倍。此外，FLUTE 还应用于 LLaMA3 的量化，不仅保持了竞争性能，还显著提升了端到端吞吐量。
[Arxiv](https://arxiv.org/abs/2407.10960)
==========
# MMM：探索多语言数据集的相互强化效应，并测试其在开放领域信息抽取大型语言模型中的应用。
发布时间：2024年07月15日
`LLM应用` `数据集` `信息提取`
> MMM: Multilingual Mutual Reinforcement Effect Mix Datasets & Test with Open-domain Information Extraction Large Language Models
# 摘要
> 互增强效应（MRE）在信息提取和多任务研究领域颇具潜力，但因日语专属数据集的限制，全球研究者难以深入探索。为此，我们推出了包含21个子数据集的多语言MRE混合数据集（MMM），涵盖英、日、中三种语言。本文还提出了一种利用大型语言模型（LLM）辅助的数据集翻译方法，大幅缩短了数据集构建的手动标注时间。同时，我们通过引入开放领域的命名实体识别（NER）和句子分类任务，丰富了数据集内容。基于此，我们构建了一个统一的输入-输出框架，用于训练开放领域信息提取大型语言模型（OIELLM），该模型在处理新MMM数据集时表现出色，性能大幅提升。
[Arxiv](https://arxiv.org/abs/2407.10953)
==========
# 文本语义是否能减轻对发声物体分割的偏好？
发布时间：2024年07月15日
`LLM应用` `音频处理` `计算机视觉`
> Can Textual Semantics Mitigate Sounding Object Segmentation Preference?
# 摘要
> 音频-视觉分割任务旨在通过音频线索在视觉空间中精准分割发声物体。然而，现有方法往往过度依赖于可听物体的损害性分割偏好，而非精确的音频引导。究其原因，音频在多源发声场景中缺乏稳健的语义，导致其对视觉空间的引导力不足。鉴于此，我们提出利用视觉场景中的文本线索，通过文本的丰富语义来强化音频引导。具体而言，我们首先通过图像描述生成器获取场景描述，并利用大型语言模型推断潜在的发声物体作为文本线索。随后，我们设计了一个语义驱动的音频建模模块，通过动态掩码将音频特征与文本线索融合，生成既包含音频线索又富含语义的发声物体特征，从而为视觉空间提供更明确的引导。实验结果表明，在文本线索的辅助下，我们的方法对音频的敏感性显著提升，在所有测试子集上均展现出卓越的性能。项目详情请访问：\href{https://github.com/GeWu-Lab/Sounding-Object-Segmentation-Preference}{项目页面}。
[Arxiv](https://arxiv.org/abs/2407.10947)
==========
# FinDKG 项目通过整合大型语言模型，构建动态知识图谱，旨在精准捕捉金融市场中的全球趋势。
发布时间：2024年07月15日
`LLM应用` `知识图谱`
> FinDKG: Dynamic Knowledge Graphs with Large Language Models for Detecting Global Trends in Financial Markets
# 摘要
> 动态知识图谱 (DKGs) 是随时间表达对象间多样联系的流行工具，亦是处理复杂非结构化数据（如文本或图像）的有效手段。在金融领域，DKGs 能助我们洞察新闻动态，引领战略投资。本研究中，我们挖掘大型语言模型 (LLMs) 生成动态知识图谱的潜力，创新推出开源微调模型——集成上下文知识图谱生成器 (ICKG)。借助 ICKG，我们构建了金融新闻领域的开源知识图谱 FinDKG，并设计了基于注意力的图神经网络架构 KGTransformer 进行深入分析。实证检验表明，我们的模型在链接预测任务中表现卓越，且在主题投资分析中超越传统 ETF 策略。
[Arxiv](https://arxiv.org/abs/2407.10909)
==========
# 看，那可是我的模型！来认识一下 Chain & Hash，这是一项专为 LLM 设计的指纹识别技术。
发布时间：2024年07月15日
`LLM应用` `人工智能`
> Hey, That's My Model! Introducing Chain & Hash, An LLM Fingerprinting Technique
# 摘要
> 随着大型语言模型 (LLM) 被盗和滥用的风险日益增加，模型指纹识别技术变得尤为重要。本文中，我们首先明确了成功指纹的五大特性：透明、高效、持久、健壮且不可伪造。随后，我们提出了一种新颖的指纹技术——Chain & Hash，它通过加密手段实现这些特性。该技术通过生成问题集与答案集，并利用安全哈希算法确保每个问题的唯一值，从而防止虚假所有权声明。我们在多个模型上验证了 Chain & Hash 的鲁棒性，包括面对微调和指纹擦除等挑战。实验结果显示，采用 Chain & Hash 的指纹模型在性能上与非指纹模型几乎无异，证明了其高效性与实用性。
[Arxiv](https://arxiv.org/abs/2407.10887)
==========
# SLIP：通过权重分解技术，保障大型语言模型（LLM）的知识产权安全。
发布时间：2024年07月15日
`LLM应用` `边缘计算` `网络安全`
> SLIP: Securing LLMs IP Using Weights Decomposition
# 摘要
> 随着大型语言模型（LLM）在学术和工业领域的广泛应用，它们已成为宝贵的知识产权（IP），体现了巨大的投资。然而，高昂的云部署成本促使人们转向边缘设备部署，这却增加了参数被盗和滥用的风险。现有的边缘模型保护方法存在实用性、准确性或适用性方面的局限。本文提出了一种创新的混合推理算法SLIP，旨在保护边缘部署的模型免受盗窃。SLIP是首个既实用又安全，且不影响准确性和延迟的混合协议。它通过矩阵分解，在安全和昂贵的资源与成本效益高但易受攻击的资源之间划分模型，确保敏感的IP部分得到最大保留，同时最小化计算量。该协议还提供了安全保障，防止攻击者利用分区获取信息。实验结果表明，我们的方法既强大又有效，是保护LLM的理想选择。
[Arxiv](https://arxiv.org/abs/2407.10886)
==========
# 大型语言模型在自动化启发式设计中，进化搜索的重要性不容忽视。
发布时间：2024年07月15日
`LLM应用` `软件工程` `人工智能`
> Understanding the Importance of Evolutionary Search in Automated Heuristic Design with Large Language Models
# 摘要
> 自动化启发式设计（AHD）因其自动化开发有效启发式的潜力而备受瞩目。随着大型语言模型（LLM）的兴起，AHD迎来新机遇，初期研究将其视为进化程序搜索（EPS）问题。然而，基准设置不一、基线不足及组件分析缺失，使得LLM与搜索策略整合的必要性及现有EPS方法的实际进展存疑。本研究通过大规模基准测试，涵盖四种EPS方法、四种AHD问题、九种LLM及五次独立运行，旨在解答这些疑问。实验结果揭示了进化搜索在基于LLM的AHD中的重要性，并推动了EPS算法的发展。为促进研究的可访问性与可重复性，我们已全面开源相关基准与结果。
[Arxiv](https://arxiv.org/abs/2407.10873)
==========
# GPT 超声成像技术：利用 VLM 从前臂超声图像中解读手势
发布时间：2024年07月15日
`LLM应用` `人工智能`
> GPT Sonograpy: Hand Gesture Decoding from Forearm Ultrasound Images via VLM
# 摘要
> GPT-4o等大型视觉-语言模型作为多模态基础模型，正展现出作为多种领域AI辅助工具的巨大潜力。尽管在通用任务中表现出色，但在特定任务上，未经微调的能力有限。全面微调这些模型因资源需求巨大而具挑战性。我们的研究表明，GPT-4o无需微调即可从前臂超声数据解码手势，并通过少量样本情境学习进一步提升性能。
[Arxiv](https://arxiv.org/abs/2407.10870)
==========
# 本研究提出一个实用框架，旨在评估大型语言模型应用中的偏见与公平性问题。
发布时间：2024年07月15日
`LLM应用` `人工智能` `社会科学`
> An Actionable Framework for Assessing Bias and Fairness in Large Language Model Use Cases
# 摘要
> 大型语言模型（LLM）在多个方面可能表现出偏见，这些偏见可能导致特定群体（如性别、种族、性取向或年龄等受保护属性内的群体）面临不公平的结果。本文为从业者提供了一个技术指南，帮助他们评估LLM应用中的偏见和公平风险。核心贡献是一个决策框架，指导从业者根据特定应用选择合适的评估指标。研究首先对LLM的偏见和公平风险进行分类，并将其对应到LLM应用的分类体系中，进而定义了一系列评估指标。此外，本文还引入了新的偏见和公平评估指标，包括创新的反事实指标和基于刻板印象分类器的指标。评估不仅关注模型本身，还考虑了提示和模型风险对特定应用的影响。由于所有评估均基于LLM的输出进行，该框架具有高度的实用性和操作性，便于从业者实施。
[Arxiv](https://arxiv.org/abs/2407.10853)
==========
# MetaLLM：一款高效且经济的动态框架，专为大型语言模型打造
发布时间：2024年07月15日
`LLM应用` `人工智能` `云计算`
> MetaLLM: A High-performant and Cost-efficient Dynamic Framework for Wrapping LLMs
# 摘要
> 随着机器学习的迅猛发展，众多大型语言模型（LLM）在多领域任务中大放异彩。然而，这些模型在计算成本和定价上各异，且查询需求因领域和复杂度而异，单一模型的选择往往并非最优。为此，我们推出了MetaLLM框架，它智能地为每个查询选择最佳LLM，显著提升分类任务的准确性与成本效益。通过将选择问题视为多臂老虎机问题，MetaLLM在不确定性中巧妙平衡了准确性与成本。在OpenAI、Amazon、Anthropic和Meta等平台的实验中，MetaLLM展现了其在实际应用中的高效性，为未来扩展至更多任务奠定了基础。
[Arxiv](https://arxiv.org/abs/2407.10834)
==========
# BiasScanner 工具旨在自动识别并分类新闻中的偏见，从而助力民主的稳固。
发布时间：2024年07月15日
`LLM应用` `新闻媒体` `信息技术`
> BiasScanner: Automatic Detection and Classification of News Bias to Strengthen Democracy
# 摘要
> 随着21世纪在线新闻消费的增长，虚假信息、偏见报道和仇恨言论等不良内容也在增多。为此，我们推出了BiasScanner，一款旨在通过帮助读者仔细审查在线新闻来强化民主的应用。该应用包含一个预训练的大型语言模型，用于识别新闻中的偏见句子，并配备了一个浏览器插件。目前，BiasScanner能在句子层面识别并分类超过24种媒体偏见，成为同类中最精细且唯一实际部署的系统。它设计轻巧且注重隐私，不仅能标记可能存在偏见的句子，还为每个分类提供解释，并为每篇文章提供总结分析。尽管已有研究关注新闻偏见检测，但BiasScanner是首个实现为浏览器插件并投入使用的工具（详见biasscanner.org的在线演示）。
[Arxiv](https://arxiv.org/abs/2407.10829)
==========
# LLM 电路分析在不同训练阶段和规模上均保持一致性。
发布时间：2024年07月15日
`LLM理论` `人工智能` `机器学习`
> LLM Circuit Analyses Are Consistent Across Training and Scale
# 摘要
> 当前部署的大多数大型语言模型都经历了持续训练或额外微调。然而，关于 LLM 内部机制的研究多聚焦于预训练结束时的单一模型状态，这引发了一个疑问：其研究结果能否适用于实际应用场景？现有研究多关注仅编码器模型或简单模型，与实际部署的模型差异较大。本研究深入探讨了仅解码器 LLM 中，模型机制（以电路形式展现）在跨越 3000 亿个训练令牌的过程中如何涌现与演化，涉及模型参数从 7000 万至 28 亿不等。我们发现，任务能力及其支撑功能组件在不同规模模型中于相似令牌数时稳定出现。尽管这些组件可能随时间由不同注意力头实现，但其核心算法保持一致。更令人惊讶的是，这些算法及所涉组件类型能在不同模型规模间复制。这些发现表明，预训练结束时对小模型进行的电路分析，其洞察力在后续预训练及不同模型规模中依然有效。
[Arxiv](https://arxiv.org/abs/2407.10827)
==========
# 基础自动评分器：优化大型语言模型，提升自动评估质量
发布时间：2024年07月15日
`LLM应用` `人工智能` `软件开发`
> Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation
# 摘要
> 随着大型语言模型的进步，由于人工评估的高成本，可靠地评估它们的输出变得越来越具有挑战性。为此，我们引入了FLAMe，一系列基础大型自动评估模型。FLAMe在我们收集的100多个质量评估任务中进行了训练，这些任务包含超过500万个人类判断，这些判断是通过以前研究中公开发布的人类评估精心挑选和标准化的。FLAMe在广泛的保留任务上显著提高了泛化能力，在许多任务上超过了像GPT-4和Claude-3这样在专有数据上训练的LLM。我们展示了FLAMe也可以作为一个强大的起点，用于进一步的下游微调，以奖励模型评估为例（FLAMe-RM）。值得注意的是，在我们的RewardBench上，我们的FLAMe-RM-24B模型（准确率为87.8%）是表现最佳的仅在许可数据上训练的生成模型，超过了GPT-4-0125（85.9%）和GPT-4o（84.7%）。此外，我们探索了一种更计算效率高的方法，使用一种新颖的尾部补丁微调策略来优化我们的FLAMe多任务混合模型，用于奖励模型评估（FLAMe-Opt-RM），提供了有竞争力的RewardBench性能，同时需要的训练数据点大约减少了25倍。总的来说，我们的FLAMe变体在12个自动评估基准中的8个上超过了我们考虑的所有流行的专有LLM-as-a-Judge模型，涵盖了53个质量评估任务，包括RewardBench和LLM-AggreFact。最后，我们的分析显示，FLAMe在CoBBLEr自动评估偏差基准上显著比这些LLM-as-a-Judge模型偏差更小，同时有效地识别了高质量的代码生成响应。
[Arxiv](https://arxiv.org/abs/2407.10817)
==========
# Mix-CPT：一种领域适应框架，通过分离知识学习与格式对齐来实现。
发布时间：2024年07月15日
`LLM应用` `人工智能`
> Mix-CPT: A Domain Adaptation Framework via Decoupling Knowledge Learning and Format Alignment
# 摘要
> 将通用大型语言模型 (LLM) 适应到专业领域，因数据分布多样性而颇具挑战。传统方法需在大规模领域特定语料库上持续预训练，以记忆知识，再按人类指令和偏好应用。但此法效率低下，因忽视知识利用，且在有限样本下，LLM 需同时学习知识利用与格式对齐。为此，我们提出 Mix-CPT 框架，融合领域知识学习与通用格式对齐。首先，进行知识混合持续预训练，兼顾记忆与利用，相互强化。为防遗忘，引入 logit swap 自蒸馏约束。随后，利用预训练所得，高效指令调整与对齐，少量样本即可。实验证明，Mix-CPT 能提升 LLM 在目标与通用领域的任务解决能力，超越传统方法。
[Arxiv](https://arxiv.org/abs/2407.10804)
==========
# 多语言对比解码：跨越语言界限的层级跳跃
发布时间：2024年07月15日
`LLM应用` `人工智能`
> Multilingual Contrastive Decoding via Language-Agnostic Layers Skipping
# 摘要
> 通过对比层解码（DoLa），旨在通过比较早期与最终输出的预测概率，提升大型语言模型（LLM）的生成质量。然而，该方法在非英语任务上表现欠佳。受先前关于模型前向传递中语言转换的研究启发，我们发现问题在于早期与最终输出间的语言不匹配。为此，我们提出了一种适用于多语言的改进对比解码算法。为获取更有价值的早期输出，我们设计了两种策略，跳过底层、与语言无关的层。实验结果显示，我们的方法不仅超越了以往的对比解码基准，还显著提升了LLM在11种语言中的思维链推理准确性。项目详情请访问：https://github.com/NJUNLP/SkipLayerCD。
[Arxiv](https://arxiv.org/abs/2407.10795)
==========
# Graphusion：借助大型语言模型，在 NLP 教育领域实现科学知识图谱的融合与构建
发布时间：2024年07月15日
`LLM应用` `人工智能`
> Graphusion: Leveraging Large Language Models for Scientific Knowledge Graph Fusion and Construction in NLP Education
# 摘要
> 知识图谱 (KGs) 在 AI 领域扮演关键角色，尤其在提升问答 (QA) 系统方面。KGs 的构建往往依赖于领域专家的深入工作。近期，大型语言模型 (LLMs) 开始用于知识图谱构建 (KGC)，但多数方法仍局限于从单句或文档中提取局部知识三元组。为此，我们提出了 Graphusion，一个从自由文本中进行零-shot KGC 的创新框架。其核心融合模块不仅整合了实体合并与冲突解决，还实现了新三元组的发现，提供了全局视角。我们验证了 Graphusion 在 NLP 领域的应用，特别是在教育场景中，通过 TutorQA 这一新基准，展示了其在图推理和 QA 任务中的优越性能。评估结果表明，Graphusion 在链接预测的准确性上超越了传统监督方法高达 10%，并在人类评估中取得了优异成绩，分别为概念实体提取 2.92 分和关系识别 2.37 分（满分 3 分）。
[Arxiv](https://arxiv.org/abs/2407.10794)
==========
# GraphEval：一款基于知识图谱的 LLM 幻觉评估框架
发布时间：2024年07月15日
`LLM应用` `知识图谱`
> GraphEval: A Knowledge-Graph Based LLM Hallucination Evaluation Framework
# 摘要
> 随着 LLM 应用的普及，评估其响应并检测知识相关的不一致性（即幻觉）的方法愈发关键。现有的评估指标在解释性、全面性及计算成本方面均显不足。为此，我们推出了 GraphEval 框架，该框架利用知识图谱 (KG) 结构进行幻觉评估，能精准定位 KG 中易产生幻觉的三元组，从而更深入地揭示幻觉在响应中的具体位置。此外，结合顶尖的自然语言推理 (NLI) 模型，我们的方法在幻觉基准测试中的平衡准确性上有所提升。最后，我们创新性地提出了 GraphCorrect 方法，通过利用 KG 结构进行幻觉校正，并证实了其对大多数幻觉的纠正效果。
[Arxiv](https://arxiv.org/abs/2407.10793)
==========
# 病理学基础模型的可解释性分析，揭示了多模态间的生物学相关嵌入。
发布时间：2024年07月15日
`LLM应用` `医学影像`
> Interpretability analysis on a pathology foundation model reveals biologically relevant embeddings across modalities
# 摘要
> 大型语言模型（LLM）的机制性可解释性已深入研究。我们首次尝试将这些方法应用于医学影像，分析了从病理学基础模型中提取的ViT-Small编码器特征。通过两个数据集——病理图像集和配对的空间转录组学图像集，我们揭示了细胞和组织形态的可解释表示及模型嵌入空间中的基因表达。这一探索为未来在医学和临床领域中可解释特征维度的研究和应用奠定了基础。
[Arxiv](https://arxiv.org/abs/2407.10785)
==========
# Qwen2-Audio 技术报告
发布时间：2024年07月15日
`LLM应用` `音频处理` `语音识别`
> Qwen2-Audio Technical Report
# 摘要
> 我们推出了Qwen-Audio的最新成果——Qwen2-Audio，这是一个能够处理多种音频输入并进行分析或直接响应语音指令的大型音频-语言模型。通过使用自然语言提示简化预训练流程并扩充数据量，我们增强了Qwen2-Audio的指令执行能力，并设计了两种音频交互模式：语音聊天和音频分析。在语音聊天模式下，用户可与Qwen2-Audio自由语音交流，无需文本介入；而在音频分析模式中，用户可结合音频与文本指令进行深入分析。值得一提的是，这两种模式间的切换无需系统提示，Qwen2-Audio能智能识别并响应音频内容。例如，面对同时包含多种声音、多人对话及语音指令的复杂音频，Qwen2-Audio能精准理解指令并给出相应解读。此外，通过DPO的优化，模型在保持事实准确性和行为一致性方面表现更佳。根据AIR-Bench的评测，Qwen2-Audio在音频指令遵循能力测试中超越了Gemini-1.5-pro等先前最佳模型。我们开源Qwen2-Audio，旨在推动多模态语言技术的发展。
[Arxiv](https://arxiv.org/abs/2407.10759)
==========
# Codebook LLMs：将政治科学代码簿应用于 LLM，并调整 LLMs 以遵循代码簿规范
发布时间：2024年07月15日
`LLM应用` `政治科学` `社会科学`
> Codebook LLMs: Adapting Political Science Codebooks for LLM Use and Adapting LLMs to Follow Codebooks
# 摘要
> 代码本，作为操作化构建和注释流程的指南，在社会科学领域广泛应用于非结构化政治文本的编码。为降低人工注释成本，政治科学家开始利用大型语言模型（LLM）进行文本标记与分析。然而，以往基于LLM的分类研究暗含了通用标签假设，即仅凭类别标签或简要定义，结合LLM预训练中习得的信息，即可实现文档的准确分类。我们则主张，关注测量有效性的政治科学家应采纳代码本-构建标签假设，即LLM应严格遵循代码本中构建/标签的定义与排除标准。为此，我们收集并优化了三个政治科学数据集及其原始代码本，并开展实验，探究LLM是否遵循代码本指令、重写代码本能否提升性能，以及在代码本-文档-标签三元组上对LLM进行指令调优是否能超越零-shot分类。实验结果显示，尽管重新构建代码本在零-shot性能上有所提升，但LLM仍难以完全遵守代码本约束。值得欣喜的是，对Mistral进行指令调优，显著提升了零-shot推理性能（微F1从0.53提升至0.76）。我们期待，通过明确代码本特定任务、假设及指令调优流程，以及采用半结构化的LLM代码本格式，能助力政治科学家顺利迈入LLM时代。
[Arxiv](https://arxiv.org/abs/2407.10747)
==========
# CLAVE：一款自适应框架，专为评估 LLM 生成回复的价值而设计
发布时间：2024年07月15日
`LLM应用` `人工智能`
> CLAVE: An Adaptive Framework for Evaluating Values of LLM Generated Responses
# 摘要
> 随着大型语言模型（LLM）的迅猛发展，生成不道德内容的风险也随之增加。评估这些模型的价值观有助于揭示其潜在的不一致性，但这一过程依赖于无参考的评估器，如微调的LLM或闭源的GPT-4，以识别生成内容中的价值观。然而，这些评估器在开放式价值评估中面临两大挑战：一是如何与不断变化的人类价值定义保持一致，同时减少自身偏见（适应性）；二是如何稳健地识别不同的价值表达和场景（泛化性）。为解决这些难题，我们提出了CLAVE框架，该框架结合了两个互补的LLM：一个大型模型利用其广泛知识从少量人类标签中提取高级价值概念，另一个较小模型则在这些概念上进行微调，以更好地与人类价值理解对齐。这种双模型策略使得每种价值类型仅需不到100个样本即可与任何价值系统进行校准。此外，我们还推出了ValEval数据集，涵盖13k+文本、价值、标签元组，横跨多个领域，涉及三大价值系统。我们测试了12+流行LLM评估器，并分析了它们的优劣。研究结果表明，结合微调的小模型和基于提示的大型模型在价值评估中实现了最佳平衡。
[Arxiv](https://arxiv.org/abs/2407.10725)
==========
# 量化提示助力视觉-语言模型高效泛化
发布时间：2024年07月15日
`LLM应用` `计算机视觉` `机器学习`
> Quantized Prompt for Efficient Generalization of Vision-Language Models
# 摘要
> 近年来，CLIP等大规模预训练视觉-语言模型在多领域大放异彩。如何将这些庞大数据模型中的丰富知识有效迁移至下游任务，成为研究焦点。然而，下游适应过程中常遭遇过拟合与灾难性遗忘两大难题，导致模型过度适应当前数据，丧失关键的通用知识。传统方法依赖经典正则化技术，但随着解决方案日益复杂，存储与推理成本激增，亟待新策略。本文从随机噪声抑制过拟合现象中获得灵感，将量化误差视为噪声，探索高效且有效的量化正则化方法。同时，为在低成本下提升模型泛化与专业化能力，我们深入剖析提示权重分布，提炼量化模块设计原则，并据此打造多个竞争性基准。该方法轻量高效，适用于资源受限设备。此外，它能无缝融入MaPLe等现有技术，提升准确率并降低存储负担，兼具强大功能与广泛适用性。在11个数据集上的实验验证了其卓越性能。相关代码已公开于https://github.com/beyondhtx/QPrompt。
[Arxiv](https://arxiv.org/abs/2407.10704)
==========
# DOCBENCH：评估 LLM 文档阅读系统性能的标杆
发布时间：2024年07月15日
`LLM应用` `文档管理` `人工智能`
> DOCBENCH: A Benchmark for Evaluating LLM-based Document Reading Systems
# 摘要
> 近期，大型语言模型（LLM）开发者对基于LLM的文档阅读系统兴趣日益浓厚，这类系统不仅支持用户上传文档并提问，还超越了传统阅读理解任务的范畴。为应对文件解析、元数据提取等复杂挑战，这些系统设计精良。然而，目前尚无基准评估其在实际应用中的表现。为此，我们推出了DocBench，一个专为评估基于LLM的文档阅读系统而设计的新基准。该基准精心策划，涵盖人工标注员招募与合成问题生成，包含229份真实文档及1,102个问题，横跨五个领域、四种问题类型。我们评估了通过网页接口或API访问的专有系统，以及采用开源LLM的解析-阅读流水线。评估结果显示，现有系统与人类表现存在显著差距，凸显了开发高效系统的挑战。DocBench旨在为多样化现实场景下的基于LLM的文档阅读系统评估设立标准，引领该领域的未来发展。
[Arxiv](https://arxiv.org/abs/2407.10701)
==========
# 探究合成数据在公式生成中的有效性
发布时间：2024年07月15日
`LLM应用` `电子表格` `人工智能`
> An Empirical Study of Validating Synthetic Data for Formula Generation
# 摘要
> LLM 虽能辅助编写电子表格公式，但相关资源匮乏，影响了预训练模型的性能并限制了微调能力。我们利用另一模型生成合成自然语言表述进行微调，并验证其准确性至关重要。本文通过实证研究，展示了验证合成训练示例对提升模型性能的影响，尤其是在四个不同模型上。有趣的是，尽管验证剔除了一些难题，但它实际上增强了模型在微调后解决问题的复杂性。
[Arxiv](https://arxiv.org/abs/2407.10657)
==========
# 提示选择不容忽视：借助大型语言模型，为社会科学领域的文本标注注入新活力。
发布时间：2024年07月15日
`LLM应用` `社会科学` `人工智能`
> Prompt Selection Matters: Enhancing Text Annotations for Social Sciences with Large Language Models
# 摘要
> 大型语言模型在社会科学文本标注任务中的表现已能媲美甚至超越人类，且成本大幅降低。但提示选择对标注准确性的影响仍未被探究。本研究揭示了提示间性能的显著差异，并运用自动优化技术系统生成高质量提示。此外，我们通过 https://prompt-ultra.github.io/ 为社区提供了一个便捷的浏览器实现方案。
[Arxiv](https://arxiv.org/abs/2407.10645)
==========
# 要评估模型偏差，关键在于剖析其错误特征。
发布时间：2024年07月15日
`LLM应用` `计算机视觉` `人工智能`
> Evaluating Model Bias Requires Characterizing its Mistakes
# 摘要
> 在处理虚假相关性时，准确评估模型性能对于提升预测质量和增强模型运行信心至关重要。我们通过在不同子组间细致表征模型错误，而非仅量化错误，揭示了模型偏差，这些偏差常被传统指标如最差组准确性所忽略。基于假设检验理念，我们创新性地提出了SkewSize指标，该指标能从模型预测中精准捕捉偏差，并适用于多类别及生成模型的开放词汇场景。SkewSize聚焦于虚假变量与模型预测间的交互效应，我们在多种模型应用场景中验证了其效能，包括合成数据训练的视觉模型、ImageNet训练的视觉模型，以及BLIP-2系列的大规模视觉语言模型。SkewSize不仅揭示了其他指标未察觉的偏差，还深入分析了如指令调优等新技术的实际影响。
[Arxiv](https://arxiv.org/abs/2407.10633)
==========
# 竞技场学习：利用模拟聊天机器人竞技场，为 LLMs 训练后打造数据飞轮
发布时间：2024年07月15日
`LLM应用` `人工智能` `机器学习`
> Arena Learning: Build Data Flywheel for LLMs Post-training via Simulated Chatbot Arena
# 摘要
> 评估大型语言模型的有效性颇具挑战。在线聊天机器人竞技场中的人工标注战斗虽高效，但成本和时间成本高昂。为此，我们提出竞技场学习，一种创新的离线策略，利用AI驱动的标注模拟战斗，评估结果，助力模型通过监督微调和强化学习持续进步。竞技场学习包含两大核心：首先，通过WizardArena精确预测模型Elo排名，确保离线模拟与在线比赛的一致性；其次，基于战斗结果和模型改进，持续优化训练数据。我们构建数据飞轮，迭代更新训练数据，使模型能从多模型优势中学习。我们将此策略应用于WizardLM-$β$，显著提升其性能。这一全自动训练与评估流程为LLM的持续进步奠定基础。竞技场学习在WizardLM-2的成功中扮演关键角色，本文既是其效能的探索，也是未来相关研究的基础。
[Arxiv](https://arxiv.org/abs/2407.10627)
==========
# 知识蒸馏不留遗珠：利用真实数据提升代码转换ASR的实用与效能
发布时间：2024年07月15日
`LLM应用` `语音识别` `软件开发`
> Leave No Knowledge Behind During Knowledge Distillation: Towards Practical and Effective Knowledge Distillation for Code-Switching ASR Using Realistic Data
# 摘要
> 在自动语音识别领域，尽管大型模型能生成高质量转录，但计算资源的限制使其在实际应用中受阻，尤其是在复杂的代码转换 ASR 场景中。为此，我们创新性地提出了一个通过真实语音数据进行知识蒸馏的框架，旨在打造更高效的 CS-ASR 模型。我们的 K$^2$D 方法不仅汲取教师模型的智慧，还融合了小型辅助模型的独特见解。实验证明，K$^2$D 在多个数据集上表现卓越，通过处理未标记的真实数据，我们成功开发出一个体积减半、速度提升五倍的模型，其性能在所有测试中均超越了传统方法和教师模型。这一成果已在 Hugging Face 平台公开分享，供业界共享 (https://huggingface.co/andybi7676/k2d-whisper.zh-en)。
[Arxiv](https://arxiv.org/abs/2407.10603)
==========
# 通过基于LLM的增强和精准数据选择，提升零-shot跨语言性能
发布时间：2024年07月15日
`LLM应用` `跨语言学习`
> Boosting Zero-Shot Crosslingual Performance using LLM-Based Augmentations with Effective Data Selection
# 摘要
> 大型语言模型 (LLM) 擅长文本生成。我们利用这一特点，通过零-shot 提示为低资源目标语言生成特定任务数据，并促进跨语言转移。我们提出使用在源语言数据上训练的教师模型来标记 LLM 生成的内容，并采用基于教师标签概率的简单数据选择策略。这些策略帮助我们高效地筛选出多样且具代表性的生成内容子集，从而提升零-shot 准确性。此外，我们还探讨了影响跨语言性能的关键设计选择，如源数据翻译的使用和最佳标签选择。实验显示，在多种目标语言和领域中，情感分析与自然语言推理任务的性能显著提升，最高可达 7.13 绝对点，平均提升 1.5 绝对点。
[Arxiv](https://arxiv.org/abs/2407.10582)
==========
# 探索生成式AI之外：绘制自然语言生成的未来蓝图
发布时间：2024年07月15日
`LLM理论` `人工智能`
> Beyond Generative Artificial Intelligence: Roadmap for Natural Language Generation
# 摘要
> 随着大型语言模型（LLMs）的迅猛发展，生成式人工智能正经历着指数级的增长。这得益于自然语言处理（NLP）及其子领域自然语言生成（NLG）中深度学习方法的卓越表现，这也是本文的核心议题。在众多LLM中，GPT-4、Bard及ChatGPT等工具已成为NLG任务的标杆。面对这一新局面，我们不禁思考：NLG将何去何从？如何适应并进化以迎接LLM时代的新挑战？为此，本文深入回顾了NLG领域近期的一系列重要调查，旨在为科学界绘制一张研究蓝图，揭示LLMs尚未充分应对的NLG领域问题，并指明未来研究的方向。
[Arxiv](https://arxiv.org/abs/2407.10554)
==========
# TCM-FTP：专为草药处方预测而设计的大型语言模型微调方案
发布时间：2024年07月15日
`LLM应用` `中医药`
> TCM-FTP: Fine-Tuning Large Language Models for Herbal Prescription Prediction
# 摘要
> 传统中医（TCM）通过特定草药组合治疗症状，这一实践历史悠久。预测TCM处方是一个引人入胜的技术挑战，但受限于高质量数据集的稀缺和症状与草药关系的复杂性。为此，我们推出了DigestDS数据集，包含消化系统疾病专家的实际医疗记录。同时，我们提出了TCM-FTP方法，通过在DigestDS上监督微调预训练的大型语言模型（LLMs），并采用低秩适应技术提升计算效率。TCM-FTP还通过无序排列草药进行数据增强，实现了0.8031的F1分数，显著优于以往方法，并在剂量预测上达到0.0604的归一化均方误差。这项工作强调了微调在TCM处方预测中的重要性，并提出了一种有效途径。
[Arxiv](https://arxiv.org/abs/2407.10510)
==========
# LLM 微调的学习机制
发布时间：2024年07月15日
`LLM理论` `人工智能`
> Learning Dynamics of LLM Finetuning
# 摘要
> 学习动态揭示了特定训练样本如何影响模型对其他样本的预测，是理解深度学习系统的关键。我们通过分析微调过程中不同响应间的逐步分解和累积影响，深入探讨了大型语言模型的学习动态。这一框架为指令调整和偏好调整算法的训练提供了统一解释，不仅阐明了这些方法的优势来源，还启发了一种简单高效的方法来进一步提升对齐性能。实验代码已公开在 https://github.com/Joshua-Ren/Learning_dynamics_LLM。
[Arxiv](https://arxiv.org/abs/2407.10490)
==========
# IDEAL 技术：借助 LLM 的无限与动态特性，优化查询聚焦摘要效果
发布时间：2024年07月15日
`LLM应用` `信息技术`
> IDEAL: Leveraging Infinite and Dynamic Characterizations of Large Language Models for Query-focused Summarization
# 摘要
> 查询聚焦摘要（QFS）旨在生成针对特定问题的摘要，增强用户控制和个性化。随着大型语言模型（LLM）的兴起，其通过大规模预训练展现的文本理解能力，为提取片段生成带来了巨大潜力。本文深入探讨了基于LLM的QFS模型应具备的两个核心特性：长文档摘要和高效细粒度查询对齐。为此，我们创新性地提出了查询感知超专家和查询聚焦无限注意力两个模块，以实现这些特性。这些创新不仅拓宽了QFS技术的应用范围，还提升了其可访问性。在现有QFS基准上的广泛实验验证了我们所提方法的有效性和通用性。相关代码已公开于https://github.com/DCDmllm/IDEAL_Summary。
[Arxiv](https://arxiv.org/abs/2407.10486)
==========
# SuperPADL：利用渐进式监督蒸馏技术，扩展语言指导的物理基础控制能力
发布时间：2024年07月15日
`Agent`
> SuperPADL: Scaling Language-Directed Physics-Based Control with Progressive Supervised Distillation
# 摘要
> 我们开发的SuperPADL框架，结合了强化学习和监督学习，能够从数千个多样化的动作片段中训练出高效的控制器，实现基于物理模拟的高质量实时角色动画。这一框架通过渐进式蒸馏技术，从专门专家的RL训练开始，逐步提升策略的稳健性和规模，最终在包含5000多个技能的数据集上训练出能够在消费级GPU上实时运行的控制器。SuperPADL不仅支持技能间的自然过渡，还允许用户交互式地创作复杂的多阶段动画，显著提升了在大数据规模下的动画生成性能。
[Arxiv](https://arxiv.org/abs/2407.10481)
==========
# 在评估 LLMs 时，我们不应忽视非确定性，它如同“好的、坏的和贪婪的”三重奏，影响着模型的表现。
发布时间：2024年07月15日
`LLM理论` `人工智能` `机器学习`
> The Good, The Bad, and The Greedy: Evaluation of LLMs Should Not Ignore Non-Determinism
# 摘要
> 当前 LLM 评估常忽略非确定性，仅关注单一输出，限制了对其在实际应用中性能变异的理解。我们的研究深入探讨了贪婪解码与采样间的性能差异，并检查了模型行为的独特性。实验显示，贪婪解码在多数任务中表现更佳，且不同大小和方法的 LLM 性能稳定。特别地，最佳 N 采样法揭示了小 LLM 能匹敌甚至超越大型模型，如 GPT-4-Turbo，凸显其潜力。此研究强调了在 LLM 评估中考虑非确定性的重要性，并为未来发展提供了洞见。
[Arxiv](https://arxiv.org/abs/2407.10457)
==========
# 利用 LLM 文本表示提升药物推荐效果
发布时间：2024年07月15日
`LLM应用` `药物推荐`
> Enhancing Medication Recommendation with LLM Text Representation
# 摘要
> 当前药物推荐模型多依赖结构化数据，如医疗代码，而大量非结构化或半结构化数据未被充分利用。为此，我们提出了一种基于大型语言模型（LLM）的文本表示方法，以增强药物推荐。LLM凭借其强大的语言理解和生成能力，能从复杂的非结构化数据中提取关键信息，如临床笔记中的专业术语。此方法不仅适用于多个现有模型，还能通过结合文本与医疗代码的表示，在不同数据集上显著提升推荐效果。更重要的是，LLM的文本表示能力与传统的医疗代码表示不相上下。这表明，该方法具有广泛的适用性，能为其他模型提供更精准的推荐支持。
[Arxiv](https://arxiv.org/abs/2407.10453)
==========
# 修正重力与高红移引力波声速下的张量聚类化石研究
发布时间：2024年07月15日
`LLM理论` `天文学` `物理学`
> Tensor clustering fossils in modified gravity and high-redshift gravitational-wave sound speed
# 摘要
> 我们探索张量聚类化石作为约束引力理论的潜在工具，特别是在高红移处引力波声速与光速的差异。通过引入标量-张量潮汐相互作用的新模型，我们改进了有效泊松方程。研究表明，这些化石源自引力波传播、大尺度结构增长及有效泊松方程的二阶效应。基于霍恩德斯基理论，我们构建了小尺度有效拉格朗日量，并推导出适用于暗能量有效场论的张量聚类化石公式。作为示例，我们将其应用于未来调查中对引力波声速的限制。
[Arxiv](https://arxiv.org/abs/2407.10450)
==========
# COMET：融合“经验锥”理念的大型多模态模型，专为数学问题生成而设计
发布时间：2024年07月15日
`LLM应用`
> COMET: "Cone of experience" enhanced large multimodal model for mathematical problem generation
# 摘要
> 在教育领域，高质量数学问题的自动生成极具价值。大型多模态模型因其跨模态应用的成功，为数学问题生成开辟了新途径。然而，传统方法将问题解决与生成割裂，以及主流微调框架的单一数据结构和目标，限制了其应用。为此，我们提出COMET模型，通过“经验锥”增强，统一题干生成与问题解决，并设计三阶段微调框架，细分数据为符号、图像和直接经验，以模拟教师成长路径。此外，我们构建了中文多模态数学问题数据集，填补了领域空白。实验证明，该框架和模型在多个数据集上表现出色，有效提升了数学问题生成的质量。
[Arxiv](https://arxiv.org/abs/2407.11315)
==========
# OpenPSG：借助大型多模态模型，实现开集全景场景图的生成
发布时间：2024年07月15日
`LLM应用` `计算机视觉` `人工智能`
> OpenPSG: Open-set Panoptic Scene Graph Generation via Large Multimodal Models
# 摘要
> 全景场景图生成 (PSG) 旨在分割并识别图像中对象及其关系，实现图像的结构化理解。传统方法局限于预定义类别，限制了其在开放世界中的应用。随着大型多模态模型 (LMMs) 的迅猛发展，开放集对象检测与分割取得显著进展，但 PSG 中的开放集关系预测仍待探索。本文聚焦于结合预训练开放集全景分割模型的开放集关系预测，实现真正的开放集全景场景图生成 (OpenPSG)。我们利用 LMMs 自回归地实现开放集关系预测，并引入关系查询变换器，高效提取对象对视觉特征并评估关系存在，通过过滤无关对提升预测效率。我们还设计了生成与判断指令，自回归地执行 PSG 中的开放集关系预测。据我们所知，首次提出开放集 PSG 任务。实验证明，我们的方法在开放集关系预测与全景场景图生成方面表现卓越。代码已公开于 \url{https://github.com/franciszzj/OpenPSG}。
[Arxiv](https://arxiv.org/abs/2407.11213)
==========
# VISA：借助大型语言模型实现视频对象分割的推理
发布时间：2024年07月15日
`LLM应用` `视频处理` `人工智能`
> VISA: Reasoning Video Object Segmentation via Large Language Models
# 摘要
> 本文提出了一种新的任务——推理视频对象分割 (ReasonVOS)，旨在通过隐式文本查询生成一系列分割掩码，这些查询需要基于世界知识和视频上下文的复杂推理能力。为了应对这一挑战，我们开发了 VISA（基于视频的大型语言指令分割助手），它结合了多模态 LLM 的世界知识推理能力和视频对象分割与跟踪的能力。我们还创建了一个包含 35,074 个指令-掩码序列对的综合基准，涵盖 1,042 个多样化视频，用于 ReasonVOS 模型的评估和指令调整。实验结果显示，VISA 在处理复杂推理分割和普通引用分割方面表现出色，相关代码和数据集已公开在 https://github.com/cilinyan/VISA。
[Arxiv](https://arxiv.org/abs/2407.11325)
==========
# 大型视觉-语言模型在情境感知中扮演情感识别器的角色
发布时间：2024年07月15日
`LLM应用` `情感分析` `人工智能`
> Large Vision-Language Models as Emotion Recognizers in Context Awareness
# 摘要
> 情境感知情绪识别（CAER）任务复杂且关键，需从多情境线索中感知情绪。传统方法侧重于设计复杂架构从图像中提取情绪线索，但受限于特定数据集，可能带有标注者的主观情绪偏见。在实际应用中，获取大量标记数据颇具挑战。本文系统探索了利用大型视觉-语言模型（LVLMs）增强CAER任务的三个途径：1）在两个CAER数据集上微调LVLMs，这是将大型模型应用于下游任务的常规做法。2）设计零样本和少样本模式，评估在数据稀缺或完全未见情况下LVLMs的性能。为此，我们提出一个无需训练的框架，充分利用LVLMs的上下文学习（ICL）能力，通过基于图像相似性的排序算法检索示例，结合指令和测试示例输入LVLMs进行情感判断。3）融入思维链（CoT）以利用LVLMs的丰富知识库，增强模型推理能力并提供可解释结果。实验和分析显示，LVLMs在不同范式下均表现出色，尤其在少样本设置中的优异性能表明，LVLMs在无需大量训练的情况下完成特定任务的可行性。
[Arxiv](https://arxiv.org/abs/2407.11300)
==========
# 不确定性易碎：大型语言模型中不确定性的操控
发布时间：2024年07月15日
`LLM应用` `网络安全` `人工智能`
> Uncertainty is Fragile: Manipulating Uncertainty in Large Language Models
# 摘要
> 大型语言模型（LLM）在高风险领域中的应用广泛，其输出可靠性至关重要。我们研究了不确定性估计的脆弱性，并探索了潜在的攻击手段。研究发现，攻击者可在 LLM 中植入后门，通过特定触发器操纵模型的不确定性，而不影响最终输出。实验表明，这种攻击能有效削弱模型在多项选择题中的自我评估可靠性，甚至在多个模型中实现了 100% 的攻击成功率。此外，我们还探讨了这种操纵在不同提示和领域中的普遍性。这项研究揭示了 LLM 可靠性的重大威胁，并呼吁未来加强防御措施。相关代码已公开在 GitHub 上。
[Arxiv](https://arxiv.org/abs/2407.11282)
==========
# Android系统文件系统漏洞的静态检测
发布时间：2024年07月15日
`LLM应用` `移动设备` `网络安全`
> Static Detection of Filesystem Vulnerabilities in Android Systems
# 摘要
> 尽管已有多种防御和测试技术，文件系统漏洞仍是Android系统的一大威胁。Android系统中复杂的程序行为和访问控制机制使得有效识别这些漏洞颇具挑战。本文介绍的PathSentinel，通过融合静态程序分析与访问控制策略分析，成功检测路径遍历、劫持及诱饵等三种文件系统漏洞，突破了以往技术的局限。PathSentinel通过整合程序与访问控制策略分析，精准定位攻击面，并剔除众多不切实际的攻击，为漏洞测试生成有效输入。此外，PathSentinel借助大型语言模型（LLMs），根据识别的漏洞和生成的输入，自动生成针对性的利用代码，大幅减轻了编写测试应用的工程负担，展现了静态分析与LLMs结合提升利用生成与漏洞验证效率的潜力。对三星和OnePlus的Android 12及14系统的评估表明，PathSentinel在217个应用中发现了51个未知漏洞，误报率极低。这些成果凸显了结合程序与访问控制策略分析进行精准漏洞检测的重要性，并指出了集成LLMs实现自动化利用生成的光明前景，为提升Android系统对抗文件系统漏洞的安全性提供了全面解决方案。
[Arxiv](https://arxiv.org/abs/2407.11279)
==========
# LLM 助力《纽约时报》Connections 文字游戏，创新谜题连连看。
发布时间：2024年07月15日
`LLM应用`
> Making New Connections: LLMs as Puzzle Generators for The New York Times' Connections Word Game
# 摘要
> 《纽约时报》的 Connections 谜题是一款每日更新的单词联想游戏，玩家需找出由共同主题连接的四词组合。解谜不仅考验语义知识和抽象推理，创作新谜题更需元认知能力，即准确预判解题者的思维路径。本文探讨了 GPT 系列大型语言模型 (LLM) 在创造挑战性与创意性兼具的单词游戏方面的能力。首先，我们分析了 Connections 游戏在程序内容生成 (PCG) 领域的独特挑战。接着，我们提出了一种基于树状思维 (ToT) 提示法的 LLM 生成谜题方法，并通过用户研究对比 AI 与传统谜题，结果显示 LLM 能创造出多样、有趣且富有挑战性的 Connections 谜题，深受玩家喜爱。
[Arxiv](https://arxiv.org/abs/2407.11240)
==========
# 从 GaLore 到 WeLore：低秩权重非均匀地源自低秩梯度
发布时间：2024年07月15日
`LLM理论` `计算机科学` `人工智能`
> From GaLore to WeLore: How Low-Rank Weights Non-uniformly Emerge from Low-Rank Gradients
# 摘要
> 现代大型语言模型（LLMs）由包含数十亿元素的矩阵构成，这使得它们的存储和处理在计算资源和内存使用方面相当耗费。由于这些矩阵非常大，它们通常可以用低秩格式表示，从而有可能减轻资源需求。与之前专注于开发新型矩阵分解算法的工作不同，我们首先研究了LLMs不同层中矩阵之间低秩结构的涌现，并建立了梯度动态与矩阵低秩表达性之间的因果关系。我们的发现揭示了不同层表现出不同程度的收敛低秩结构，因此需要在这些层之间进行非均匀的秩降低，以最小化由于压缩而导致性能下降。鉴于此，我们提出了权重低秩投影（WeLore），它将权重压缩和内存高效微调统一为一种数据不可知和一次性方法。WeLore利用奇异值的重尾分布来确定LLMs中矩阵的适当秩降低比率。WeLore不仅作为一种压缩技术，还根据矩阵的低秩表达能力将其分类为低秩组件（LRCs）和非低秩组件（N-LRCs）。我们的梯度视角和广泛实验表明，LRCs往往具有更好的微调能力，并且可以紧密模仿（有时甚至超过）全微调的训练损失轨迹和性能，同时显著减少内存和计算足迹。例如，仅使用LRCs（WeLore）中的一小部分参数微调一个压缩50%的LLaMa-2 7B模型，可以超过其全微调，具有约3倍的吞吐量和约0.6倍的GPU需求。我们的代码可在[https://github.com/VITA-Group/welore](https://github.com/VITA-Group/welore)获取。
[Arxiv](https://arxiv.org/abs/2407.11239)
==========
# 探究大型语言模型的内在机制，并探讨其在金融服务领域的应用潜力。
发布时间：2024年07月15日
`LLM应用` `人工智能`
> Mechanistic interpretability of large language models with applications to the financial services industry
# 摘要
> GPTs等大型语言模型在多领域表现出色，但其复杂性使得内部决策过程难以解读。在金融领域，这种不透明性尤为关键，因为偏见、公平性和可靠性的问责至关重要。本文中，我们首次运用机制性可解释性，深入剖析大型语言模型在金融服务中的运作机制。我们展示了如何设计算法任务以支持合规监控，特别是分析GPT-2 Small在识别潜在公平贷款违规时的注意力模式。通过逻辑归因分析，我们揭示了各层及注意力头对决策的影响。此外，我们通过设计不同提示并采用激活修补技术，精准定位了任务完成的关键组件，发现特定注意力头在任务中扮演重要角色。
[Arxiv](https://arxiv.org/abs/2407.11215)
==========
# 电信领域问答中 RAG 指标的评估
发布时间：2024年07月15日
`RAG` `问答系统`
> Evaluation of RAG Metrics for Question Answering in the Telecom Domain
# 摘要
> RAG 广泛应用于使 LLM 在多领域执行 QA 任务，但基于开源 LLM 的 RAG 在专业领域评估生成响应方面面临挑战。RAGAS 是文献中流行的评估框架，但其数值推导细节不足。我们改进了 RAGAS，通过 LLM 提供中间输出，涵盖了忠实度、上下文相关性等关键指标。分析显示，在电信领域使用 RAGAS 存在挑战，且正确检索时某些指标值更高。我们还探讨了预训练与微调对指标的影响。最终，我们评估了这些指标在实际电信 QA 任务中的适用性与挑战。
[Arxiv](https://arxiv.org/abs/2407.12873)
==========
# MetaTool：借助元任务增强，助力大型语言模型精通工具使用
发布时间：2024年07月15日
`Agent` `人工智能` `自动化`
> MetaTool: Facilitating Large Language Models to Master Tools with Meta-task Augmentation
# 摘要
> 在现实场景中，利用LLM掌握复杂工具是AI代理的关键能力。本文提出的MetaTool方法，通过自监督数据增强和元任务设计，使LLM深入理解工具，提升任务完成效率。该方法不仅超越了传统模型，还在多个工具任务上与顶尖模型相媲美。
[Arxiv](https://arxiv.org/abs/2407.12871)
==========
# GenSco：问题分解基础上的段落对齐，能否提升问答效果？
发布时间：2024年07月14日
`RAG` `问答系统` `人工智能`
> GenSco: Can Question Decomposition based Passage Alignment improve Question Answering?
# 摘要
> 在问答任务中，使用大型语言模型进行检索增强生成时，提供相关上下文至关重要。然而，生成过程中常出现不准确或幻觉，主要原因包括上下文不足或分散注意力，以及模型无法有效推理事实。本文探讨了通过精心选择的段落序列提供对齐上下文是否能提升多跳问答的答案生成质量。我们提出了一种新方法 "GenSco"，该方法基于对问题的预测分解来选择段落。框架包含两个LLM：生成器LLM用于问题分解和答案生成，辅助开源LLM作为评分器，指导段落选择。生成器仅调用一次，实现了高效且经济的答案生成。在三个多跳问答数据集上的评估显示，与最佳基线相比，我们在MuSiQue和2WikiMultiHop上分别取得了15.1和5.9点的精确匹配分数提升。
[Arxiv](https://arxiv.org/abs/2407.10245)
==========
# 本研究旨在通过决策边界感知图对比学习，提升推荐的鲁棒性。
发布时间：2024年07月14日
`Agent` `推荐系统` `人工智能`
> Towards Robust Recommendation via Decision Boundary-aware Graph Contrastive Learning
# 摘要
> 近年来，图对比学习 (GCL) 在推荐系统中因其有效减少数据稀疏性引起的偏差而受到越来越多的关注。然而，大多数现有的 GCL 模型依赖于启发式方法，并且在构建对比视图时通常假设实体独立性。我们认为这些方法在动态训练过程中难以在语义不变性和视图难度之间取得平衡，这两者都是图对比学习中的关键因素。  为了解决上述问题，我们提出了一种新的基于 GCL 的推荐框架 RGCL，该框架有效地保持了对比对的语义不变性，并随着训练过程中模型能力的演变动态适应。具体来说，RGCL 首先引入决策边界感知的对抗性扰动来约束对比增强视图的探索空间，避免任务特定信息的减少。此外，为了纳入全局用户-用户和项目-项目协作关系以指导硬对比视图的生成，我们提出了一种对抗性对比学习目标来构建关系感知的视图生成器。此外，考虑到无监督 GCL 可能会缩小数据点与决策边界之间的差距，导致模型鲁棒性降低，我们引入了基于最大扰动的对抗性示例来实现边际最大化。我们还对我们的设计效果进行了理论分析。通过在五个公共数据集上进行广泛的实验，我们证明了 RGCL 相对于十二个基线模型的优越性。
[Arxiv](https://arxiv.org/abs/2407.10184)
==========
# LAB-Bench：评估语言模型在生物学研究领域的实力
发布时间：2024年07月14日
`Agent` `生物学`
> LAB-Bench: Measuring Capabilities of Language Models for Biology Research
# 摘要
> 前沿大型语言模型（LLMs）及其增强系统被普遍认为能迅速推动跨学科科学发现。尽管现有众多基准测试LLM在教科书式科学问题上的表现，但针对科学研究实际需求，如文献检索、实验设计及数据分析等任务的评估工具却寥寥无几。为此，我们推出了语言代理生物学基准（LAB-Bench），一个涵盖2,400多道选择题的全面数据集，旨在检验AI在生物学研究中的实际应用能力，包括文献理解、图表解析、数据库操作及DNA与蛋白质序列处理等。与传统科学基准不同，我们期待能在LAB-Bench高难度任务中表现卓越的AI，成为科研人员在文献检索和分子克隆等领域的得力助手。我们已对数个前沿语言模型进行了初步评估，并将其表现与生物学专家进行对比。LAB-Bench将持续更新扩充，有望成为推动自动化科研系统发展的关键工具。LAB-Bench的公共子集已开放使用，详情请访问：https://huggingface.co/datasets/futurehouse/lab-bench。
[Arxiv](https://arxiv.org/abs/2407.10362)
==========
# 条条大路通罗马：探索推荐系统在大型语言模型时代的发展路径
发布时间：2024年07月14日
`Agent` `推荐系统` `个性化技术`
> All Roads Lead to Rome: Unveiling the Trajectory of Recommender Systems Across the LLM Era
# 摘要
> 推荐系统在应对信息过载和提供个性化内容方面扮演着关键角色。随着大型语言模型的兴起，我们迎来了重新定义推荐系统的新机遇，这些模型拥有丰富的知识和强大的推理能力。我们致力于将推荐系统融入更宏大的研究蓝图，并为未来的研究探索更全面的解决方案。首先，我们详细回顾了推荐系统的技术演进，特别聚焦于语言基础模型在推荐领域的应用。我们识别出两条推荐系统的演进路径：列表式推荐和对话式推荐，这两者最终汇聚于具备高级记忆、反思和工具智能的LLM代理。沿着这两条路径，我们发现推荐的信息效率提升，同时用户的信息获取成本降低。我们对每个发展阶段的技术特点、研究方法和挑战进行了深入分析，从传统列表式推荐到LLM增强推荐，再到LLM代理推荐。最后，我们指出了几个对未来个性化技术发展至关重要的未解难题，并对未来发展进行了展望。
[Arxiv](https://arxiv.org/abs/2407.10081)
==========
# 行人检测与多模态学习的结合，催生了通才模型与基准数据集的诞生。
发布时间：2024年07月14日
`LLM应用`
> When Pedestrian Detection Meets Multi-Modal Learning: Generalist Model and Benchmark Dataset
# 摘要
> 近年来，行人检测领域借助RGB、IR、深度、LiDAR和事件等多种传感器模态的研究日益增多。然而，构建一个能有效处理这些多样模态的统一模型仍具挑战。本文提出的MMPedestron模型，不同于以往专注于单一或成对模态的专家模型，能处理多模态输入及其动态组合。该模型包含一个统一的模态表示与融合编码器和一个通用的行人检测头部，并引入了MAA和MAF两个可学习令牌以实现自适应多模态特征融合。此外，我们创建了首个多模态行人检测的大规模基准MMPD数据集，涵盖RGB、IR、深度、LiDAR和事件等多种模态。通过多模态联合训练，MMPedestron在多个行人检测基准上表现卓越，超越了针对特定模态的顶尖模型，如在COCO-Persons和LLVIP上分别达到71.1 AP和72.6 AP。特别地，在CrowdHuman数据集上，MMPedestron以仅30分之一的参数量，与InternImage-H模型性能相当。相关代码和数据已公开于https://github.com/BubblyYi/MMPedestron。
[Arxiv](https://arxiv.org/abs/2407.10125)
==========
# 视觉提示引导的强化学习
发布时间：2024年07月14日
`Agent` `机器人` `人工智能`
> Affordance-Guided Reinforcement Learning via Visual Prompting
# 摘要
> 配备强化学习的机器人能够仅通过奖励信号学习多种技能，但为通用操作任务获取稳定且丰富的奖励信号仍具挑战。现有学习方法依赖大量数据，如成功与失败的示范，以构建特定任务的奖励函数。近期，大型多模态基础模型在机器人领域的应用日益增多，这些模型能进行物理环境下的视觉推理，并生成各类操作任务的初步机器人动作。受此启发，我们探索了视觉-语言模型（VLM）塑造的奖励机制。顶尖的VLM在零-shot环境下通过关键点进行affordances推理的能力突出，我们借此为机器人学习设计密集奖励。在自然语言描述的实际操作任务中，这些奖励显著提升了自主强化学习的效率，使任务在2万次在线微调中顺利完成。同时，该方法对预训练中示范数量的减少表现出强健性，在3.5万次在线微调中保持同等性能。
[Arxiv](https://arxiv.org/abs/2407.10341)
==========
# AI检测器在西方墨点分类中的表现不尽如人意，本研究探讨了其准确性与预测值的问题。
发布时间：2024年07月14日
`LLM应用` `学术诚信` `科学研究`
> AI Detectors are Poor Western Blot Classifiers: A Study of Accuracy and Predictive Values
# 摘要
> 生成式人工智能（GenAI）的兴起为学术诚信带来了新挑战。本研究测试了三种免费网络AI检测器在识别AI生成的Western blot图像上的效果。结果显示，这些检测器的敏感性和特异性差异显著，且阳性预测值普遍较低。减少Western blot的条带数虽调整了敏感性和特异性，但并未大幅提升整体准确性。这表明，当前的免费AI检测器不足以有效识别伪造的科学图像，迫切需要更专业的工具来应对这一挑战。
[Arxiv](https://arxiv.org/abs/2407.10308)
==========
# 遵循规则：运用大型语言模型进行视频异常检测的推理方法
发布时间：2024年07月14日
`LLM应用` `安全监控` `自动驾驶`
> Follow the Rules: Reasoning for Video Anomaly Detection with Large Language Models
# 摘要
> 视频异常检测 (VAD) 对安全监控和自动驾驶等应用至关重要，但现有方法在解释检测结果方面存在不足，影响了公众信任。本文采用推理框架处理 VAD，尽管大型语言模型 (LLM) 推理能力强大，但其直接应用于 VAD 效果不佳，因其预训练知识侧重通用上下文，难以适应具体场景。为此，我们提出 AnomalyRuler，一个基于规则的推理框架，结合 LLM 进行 VAD。该框架包括归纳和演绎两个阶段：首先，LLM 通过少量正常样本归纳出检测规则；随后，根据这些规则在测试视频中识别异常帧。此外，通过规则聚合、感知平滑和鲁棒推理策略，进一步提升了 AnomalyRuler 的鲁棒性。作为首个针对单类 VAD 任务的推理方法，AnomalyRuler 仅需少量正常样本提示，无需完整训练，能快速适应不同场景。实验证明，AnomalyRuler 在多个 VAD 基准上表现卓越，兼具高检测性能和强推理能力。
[Arxiv](https://arxiv.org/abs/2407.10299)
==========
# 跨语言多跳知识编辑：基准测试、深入分析与基于对比学习的简易方法
发布时间：2024年07月14日
`LLM应用` `人工智能` `语言技术`
> Cross-Lingual Multi-Hop Knowledge Editing - Benchmarks, Analysis and a Simple Contrastive Learning based Approach
# 摘要
> 大型语言模型需不断适应新知识，而知识编辑技术旨在通过最小改动高效更新模型知识。尽管新信息可能来自全球任何语言，但多数研究仍聚焦于英语单语知识编辑。为此，我们提出跨语言多跳知识编辑范式，创建了CROLIN-MQUAKE基准，以评估跨语言环境下知识编辑技术的性能。分析显示，跨语言与英语中心设置间存在显著性能差距。基于此，我们开发了CLEVER-CKE系统，采用检索、验证、生成框架，通过语言感知和硬负例对比目标，显著提升了跨语言和细粒度事实检索验证过程。实验表明，CLEVER-CKE在多个LLM、语言和数据集上，性能提升高达30%。
[Arxiv](https://arxiv.org/abs/2407.10275)
==========
# 半挂车的非线性双轨模型，经实验证实其横向与垂直轮胎力的有效性
发布时间：2024年07月14日
`Agent`
> Nonlinear Two-Track Model of a Semitrailer with Experimental Validation of Lateral and Vertical Tire Forces
# 摘要
> 随着商用车自动化的发展，辅助系统日益增多。半挂车因其载荷多变且在总质量中占比大，在满载时对行驶动力学影响显著。本文提出一种双轨模型，涵盖半挂车的横向与翻滚动力学，为未来开发难以测量的车辆状态与参数估计技术奠定基础。我们采用粒子群优化算法进行模型参数的离线识别，并通过测试车辆的实测数据验证模型，重点关注半挂车的轮胎横向与垂直力。
[Arxiv](https://arxiv.org/abs/2407.10270)
==========
# 安全微调的成与败：机制探究
发布时间：2024年07月14日
`LLM理论` `人工智能` `网络安全`
> What Makes and Breaks Safety Fine-tuning? Mechanistic Study
# 摘要
> 安全微调有助于确保大型语言模型 (LLM) 符合人类对其安全部署的期望。为深入探究安全微调背后的关键因素，我们构建了一个合成数据生成框架，通过模拟模型执行任务与其具体应用概念间的互动，精准捕捉不安全输入的特征。我们深入分析了三种主流安全微调技术——监督微调、偏好优化及遗忘策略，并发现这些方法通过微调 MLP 权重，巧妙地将潜在风险输入转化为安全模式，实现输入安全性的智能聚类。面对对抗性输入时，模型能将其激活状态调整至接近安全样本，从而确保其处理过程的安全性。我们在真实模型 Llama-2 7B 和 Llama-3 8B 上验证了这些发现，展现了安全微调的实际应用价值。
[Arxiv](https://arxiv.org/abs/2407.10264)
==========
# BiasAlert：一款专为大型语言模型设计的社会偏见检测工具，操作简便，即插即用。
发布时间：2024年07月14日
`LLM应用` `人工智能` `社会科学`
> BiasAlert: A Plug-and-play Tool for Social Bias Detection in LLMs
# 摘要
> 随着大型语言模型的迅速发展，评估其中的偏见变得愈发关键。然而，现有评估方法局限于固定输出格式，难以适应 LLM 灵活的开放文本生成环境，如句子补全和问答。为此，我们推出了 BiasAlert，一款即插即用的工具，专门用于检测 LLM 生成文本中的社会偏见。BiasAlert 融合了外部人类知识与模型自身的推理能力，确保偏见检测的可靠性。实验证明，BiasAlert 在偏见检测上远超现有顶尖技术，如 GPT4-as-A-Judge。此外，应用研究显示，BiasAlert 在不同场景下均能有效评估和缓解 LLM 偏见。相关模型和代码将公开共享。
[Arxiv](https://arxiv.org/abs/2407.10241)
==========
# KAT：结合大型语言模型，实现依赖性感知的自动化API测试
发布时间：2024年07月14日
`LLM应用` `软件开发` `测试工具`
> KAT: Dependency-aware Automated API Testing with Large Language Models
# 摘要
> 随着API测试需求的增长，软件公司寻求更高效的测试工具。传统的API测试工具虽能处理特定依赖，但受限于手动操作或启发式算法的局限性。本文介绍的KAT（Katalon API测试），采用AI驱动，结合GPT大型语言模型和先进提示技术，自动生成RESTful API的测试用例。我们的策略涵盖从OpenAPI规范构建依赖图到生成各类测试脚本和数据的全过程。实证研究显示，KAT在提升测试覆盖率、发现更多未记录状态码及减少误报方面表现优异，证明了大型语言模型在API测试中的应用价值。
[Arxiv](https://arxiv.org/abs/2407.10227)
==========
# 大规模语言模型的实用遗忘技术
发布时间：2024年07月14日
`LLM应用` `人工智能` `网络安全`
> Practical Unlearning for Large Language Models
# 摘要
> 尽管大型语言模型（LLMs）在多领域表现卓越，但其安全问题日益严峻。机器遗忘（MU）应运而生，旨在剔除不良数据影响，同时保持模型效用。然而，现有方法常低估能力间的复杂关联，忽视数据访问的实际限制，且未充分应对现实中不断出现的遗忘需求。为此，我们提出O3框架，包含分布外检测器和正交低秩适配器（LoRA），前者用创新对比熵损失训练，后者确保遗忘请求间的参数独立。实验证明，O3在遗忘与效用间找到理想平衡，尤其在持续遗忘场景中表现突出，且不依赖任何保留数据。
[Arxiv](https://arxiv.org/abs/2407.10223)
==========
# 大型语言模型的关键点驱动数学推理蒸馏
发布时间：2024年07月14日
`LLM应用` `人工智能`
> Key-Point-Driven Mathematical Reasoning Distillation of Large Language Model
# 摘要
> 大型语言模型 (LLM) 因其庞大的参数和广泛的数据训练，在数学推理任务中表现卓越。然而，高计算需求限制了其部署。为此，我们将 LLM 的数学推理提炼至小型语言模型 (SLM)，虽解决了部分问题，但 SLM 在计算和语义理解上仍有不足。为此，我们提出关键点驱动的数学推理提炼 (KPDD)，通过分解问题解决过程为三个阶段，显著提升 SLM 的推理性能。实验表明，KPDD-CoT 大幅提升推理能力，而 KPDD-PoT 则在数学推理任务中达到顶尖水平。这一方法有效减少了误解错误，推动了高效且强大的 SLM 的实际应用。
[Arxiv](https://arxiv.org/abs/2407.10167)
==========
# ChatLogic：融合逻辑编程与大型语言模型，助力多步骤推理
发布时间：2024年07月14日
`LLM应用` `人工智能` `软件开发`
> ChatLogic: Integrating Logic Programming with Large Language Models for Multi-Step Reasoning
# 摘要
> ChatGPT和GPT-4等大型语言模型在多项生成任务中表现卓越，但长期记忆的局限性常导致其在长时间交互中易受攻击和偏见影响。为此，我们推出了ChatLogic框架，专为提升LLM在复杂推理任务中的表现而设计。该框架通过融合逻辑编程，使语言模型成为系统核心，有效参与每一操作环节。我们创新地将逻辑问题转化为符号推理，充分利用模型的情境感知与模仿能力，并通过符号记忆强化推理过程。实证结果表明，ChatLogic大幅增强了LLM的连续推理能力。相关代码与数据已公开于\url{https://github.com/Strong-AI-Lab/ChatLogic}。
[Arxiv](https://arxiv.org/abs/2407.10162)
==========
# 深入探索，揭秘 LLMs 幻觉之谜：因果视角解析
发布时间：2024年07月14日
`LLM理论` `人工智能`
> Look Within, Why LLMs Hallucinate: A Causal Perspective
# 摘要
> 大型语言模型（LLM）的崛起标志着生成式人工智能的重大进步，尤其在文本理解和生成方面表现卓越。然而，尽管 LLM 在众多应用中大放异彩，其严重的幻觉问题却限制了实际应用的步伐。当前研究多聚焦于数据质量，而对自注意力机制与幻觉现象的关联探究甚少。为此，我们尝试从因果关系入手，探索干预自注意力层以减轻幻觉的新途径。通过在多个开源 LLM 中禁用特定自注意力层，并对比其幻觉程度，我们发现调整某些关键层的策略能有效缓解幻觉。这一发现不仅深化了对 LLM 幻觉机制的理解，也为未来减轻此类问题提供了创新思路。
[Arxiv](https://arxiv.org/abs/2407.10153)
==========
# TokenSHAP：通过蒙特卡洛 Shapley 值估计来解读大型语言模型
发布时间：2024年07月14日
`LLM理论` `人工智能`
> TokenSHAP: Interpreting Large Language Models with Monte Carlo Shapley Value Estimation
# 摘要
> 随着 LLM 在关键领域的普及，可解释 AI 的需求日益增长。我们提出的 TokenSHAP 方法，通过评估输入提示中各标记或子串的重要性，为解释 LLM 提供了新视角。该方法借鉴合作博弈理论中的 Shapley 值，为 NLP 领域带来了严谨的分析框架，揭示了输入各部分对模型输出的贡献。借助高效的蒙特卡洛采样，TokenSHAP 提供了量化且易于理解的标记重要性评估。在多种提示和模型架构中，TokenSHAP 均展现出优于传统方法的性能，更符合人类判断，忠实于模型行为，且保持一致性。TokenSHAP 深入解析标记间的交互，为 LLM 的运作机制提供了深刻洞察，不仅提升了模型的透明度，优化了提示设计，还助力构建更为可靠的 AI 系统。这一创新方法，是推动 AI 向更透明、可问责、可信赖方向发展的重要一步。
[Arxiv](https://arxiv.org/abs/2407.10114)
==========
# DistillSeq：利用知识蒸馏技术，为大型语言模型设计的安全对齐测试框架
发布时间：2024年07月14日
`LLM应用` `人工智能` `网络安全`
> DistillSeq: A Framework for Safety Alignment Testing in Large Language Models using Knowledge Distillation
# 摘要
> 大型语言模型（LLM）在自然语言理解、翻译乃至代码生成等多个领域展现了非凡能力。然而，LLM 产生有害内容的风险不容忽视，这要求我们对其进行严格测试和全面评估，确保其安全且负责任地使用。但大规模测试 LLM 耗资巨大，因此，在测试阶段寻找节约成本的策略至关重要。我们的方法首先将审查知识从大型模型转移至小型模型，然后采用两种策略生成恶意查询：一是基于语法树的方法，二是利用 LLM 的方法。最后，我们设计了一个顺序过滤-测试流程，以识别易引发有毒反应的测试案例。研究显示，DistillSeq 在 GPT-3.5、GPT-4.0、Vicuna-13B 和 Llama-13B 上的应用，使得攻击成功率显著提升，平均增加了 93.0%。这表明 DistillSeq 在减少测试 LLM 所需时间和资源方面具有显著优势。
[Arxiv](https://arxiv.org/abs/2407.10106)
==========
# 提升新闻标题情感预测：ChatGPT 与 Seq2Seq 模型在自由文本生成中的新视角
发布时间：2024年07月14日
`LLM应用` `情感分析`
> Enhancing Emotion Prediction in News Headlines: Insights from ChatGPT and Seq2Seq Models for Free-Text Generation
# 摘要
> 预测新闻标题引发的情感颇具挑战，因受制于人们多样的解读与背景。过往研究多直接从标题分类情感。我们另辟蹊径，利用读者自由文本的情感解释，揭示阅读标题后的内心感受。通过BU-NEmo+数据集，我们发现这些解释与标题主导情感高度相关，且蕴含更丰富的情感语境，更适合作为情感分类模型的输入。为此，我们训练了序列到序列的transformer模型，并借助ChatGPT（GPT-4）生成情感解释，进而用于情感分类。同时，我们还尝试先训练T5模型生成解释，再微调进行情感分类。经McNemar检验，结合GPT生成的解释的方法在情感分类上显著优于仅用标题的方法（P值<0.05），凸显了在标题情感预测中引入自由文本解释的重要性。
[Arxiv](https://arxiv.org/abs/2407.10091)
==========
# 快速生物医学研究分类：大流行病 PACT 高级分类引擎
发布时间：2024年07月14日
`LLM应用` `生物医学` `公共卫生`
> Rapid Biomedical Research Classification: The Pandemic PACT Advanced Categorisation Engine
# 摘要
> 本文推出大流行病PACT高级分类引擎（PPACE）及其关联数据集，该引擎专为自动分类生物医学项目摘要而设计，确保与WHO研究优先级一致。此功能对监测研究动向、填补全球卫生应对空白至关重要。我们基于人工标注项目，利用大型语言模型生成标注理由，进而用这些增强数据微调更高效的小型模型。PPACE作为大流行病PACT项目一环，助力科研资助者、政策制定者及独立研究者做出明智决策。我们不仅介绍PPACE，还公开其训练模型及数据集。评估表明，PPACE性能远超基准。PPACE及其数据集的发布，为多标签生物医学文档分类研究提供宝贵资源，推动生物医学研究与全球卫生关键优先级的协同发展。
[Arxiv](https://arxiv.org/abs/2407.10086)
==========
# 借助大型语言模型，我们致力于通过语义理解和数据插补来提升推荐系统的速度。
发布时间：2024年07月14日
`LLM应用` `推荐系统` `用户体验`
> Semantic Understanding and Data Imputation using Large Language Model to Accelerate Recommendation System
# 摘要
> 本文针对推荐系统中稀疏和缺失数据的难题，提出了一种创新方法：微调大型语言模型（LLM）以智能填补数据空缺。LLM的广泛文本训练使其能深入理解数据关系，从而生成更精准、个性化的推荐，优化用户体验。我们在多种推荐任务中验证了LLM插补法的优越性，证实了其在提升推荐系统性能方面的潜力。
[Arxiv](https://arxiv.org/abs/2407.10078)
==========
# 以我之眼：借助视觉提示，通过传感器数据为多模态大型语言模型提供坚实基础
发布时间：2024年07月14日
`LLM应用` `自动化` `传感器技术`
> By My Eyes: Grounding Multimodal Large Language Models with Sensor Data via Visual Prompting
# 摘要
> 尽管大型语言模型在多领域表现出色，但在处理长传感器数据序列时，传统文本提示方法的性能显著下降，限制了其在普遍感知应用中的应用。为此，我们创新性地提出了基于多模态 LLM 的视觉提示方法，通过设计视觉提示，有效结合可视化传感器数据与任务描述，提升了处理效率。同时，我们开发的可视化生成器，能够自动优化特定任务的可视化效果，无需预先掌握专业知识。实验结果显示，与传统文本提示相比，我们的方法在九项感知任务中平均准确率提升10%，且成本降低15.8倍，充分展现了视觉提示在多模态 LLM 中的高效与经济优势。
[Arxiv](https://arxiv.org/abs/2407.10385)
==========
# 借助多级摘要技术，提升 LLMs 在 Verilog 生成方面的能力
发布时间：2024年07月14日
`LLM应用` `半导体` `自动化设计`
> Empowering LLMs for Verilog Generation through Multi-Level Summarization
# 摘要
> 随着处理器设计复杂性和成本的增加，对自动化设计工具的需求激增。尽管指令调优的LLMs在生成Python等编程语言代码方面表现卓越，但在Verilog这类硬件描述语言上却因缺乏高质量数据而表现不佳。我们发现，现实世界中的Verilog代码质量更高，且LLMs如GPT-3.5更擅长总结而非生成Verilog代码。为此，我们推出了CodeV，一系列开源的Verilog生成LLMs，通过多级总结直接从Verilog代码生成自然语言描述。实验表明，CodeV在性能上显著超越了以往的开源和商业SOTA，分别提升了14.4%、11.3%和22.1%。
[Arxiv](https://arxiv.org/abs/2407.10424)
==========
# LLM 代理正引领桥梁运维革新，本文概述其应用与洞察。
发布时间：2024年07月13日
`Agent` `桥梁运维` `人工智能`
> Revolutionizing Bridge Operation and maintenance with LLM-based Agents: An Overview of Applications and Insights
# 摘要
> 在人类社会发展的多个工业领域，人们不断探索解放劳动力的方法。基于LLM构建的代理被视为实现这一目标的有效工具。代理作为具备感知、规划、决策和行动能力的人工智能实体，在多个领域创造了显著的生产价值。然而，桥梁运维领域的智能化水平相对较低。尽管如此，该领域已发展出多种智能检测设备、机器学习算法及自主评估决策方法，为人工智能在该领域的突破提供了基础。本研究旨在探讨基于大规模语言模型的AI体对桥梁运维领域的影响，并分析其对核心任务的潜在挑战与机遇。通过深入研究，本文期望为理解该领域智能体的应用提供更全面的视角。
[Arxiv](https://arxiv.org/abs/2407.10064)
==========
# AtomAgents：利用物理感知的多模态多智能体AI技术，推动合金设计和发现的革新。
发布时间：2024年07月13日
`Agent` `材料科学` `人工智能`
> AtomAgents: Alloy design and discovery through physics-aware multi-modal multi-agent artificial intelligence
# 摘要
> 合金设计涉及多尺度问题，传统上依赖人类专家进行全面处理，包括知识检索、计算方法应用、实验验证及结果分析。机器学习通过深度代理模型加速这一流程，但现有模型灵活性有限，难以应对新挑战。我们通过多AI代理在动态环境中的自主协作，克服了这些限制。提出的AtomAgents平台结合了大型语言模型的智能与跨领域AI代理的协作，涵盖知识检索、数据集成、物理模拟及结果分析，实现了复杂材料设计问题的解决，例如自主设计性能更优的金属合金。我们的研究不仅准确预测了合金特性，还强调了固溶合金化的重要性，提升了多目标设计任务的效率，并为多个领域如生物医学、可再生能源和环境可持续性开辟了新路径。
[Arxiv](https://arxiv.org/abs/2407.10022)
==========
# 连贯对话：提升多代理模拟对话的真实性
发布时间：2024年07月13日
`Agent` `人工智能` `虚拟现实`
> Cohesive Conversations: Enhancing Authenticity in Multi-Agent Simulated Dialogues
# 摘要
> 本文深入探讨了 LLM 驱动模拟中多智能体对话的质量，特别是在 Park 等人的研究中，25 个智能体全天模拟生活，展现出复杂互动。研究发现，对话中存在重复、不一致和幻觉等问题，且错误信息传播加剧了这些问题。为此，我们创新性地提出了 SDR 框架，通过即时问题识别、历史对话证据收集和 LLM 分析，有效检测并修正话语错误。经 GPT-4 和人类评估验证，SDR 框架显著提升了对话的一致性、多样性，并减少了虚假信息。这一研究为提升多智能体模拟中的对话质量开辟了新路径，为未来研究树立了新标杆。
[Arxiv](https://arxiv.org/abs/2407.09897)
==========
# 知识密集型任务中的协同多智能体框架与轨迹学习
发布时间：2024年07月13日
`Agent` `人工智能`
> Synergistic Multi-Agent Framework with Trajectory Learning for Knowledge-Intensive Tasks
# 摘要
> 大型语言模型 (LLM) 的最新进展在多种自然语言处理任务中取得了重大突破。然而，在知识密集型场景中生成事实一致的响应仍面临挑战，如幻觉现象、长尾知识获取困难及内存扩展限制。为此，本文引入了 SMART，一个创新的多智能体框架，通过整合外部知识提升 LLM 生成内容的可解释性与事实一致性。SMART 框架包含四个专业智能体，各自负责特定子任务，共同应对复杂知识密集型挑战。我们提出的多智能体协同训练模式——长轨迹与短轨迹学习，不仅确保了智能体间的协同效应，还维持了每个智能体的精细操作。经过 5 项任务的广泛实验验证，SMART 展现出超越传统方法的卓越性能。
[Arxiv](https://arxiv.org/abs/2407.09893)
==========
# Speech-Copilot：借助任务分解、模块化及程序生成技术，运用大型语言模型提升语音处理效率
发布时间：2024年07月13日
`Agent` `语音处理` `人工智能`
> Speech-Copilot: Leveraging Large Language Models for Speech Processing via Task Decomposition, Modularization, and Program Generation
# 摘要
> 我们推出的 Speech-Copilot 框架，专为简化语音处理任务而设计，通过模块化方式大幅减少了工具集构建的人力需求。不同于依赖大型音频-语言模型的端到端解决方案，Speech-Copilot 通过精细分析任务指令，将复杂任务拆解为易于管理的子任务，从而构建出针对性的语音处理工具集。该框架的核心是一个灵活的代理系统，它基于大型语言模型，能够通过自动生成程序来执行任务。在 Dynamic-SUPERB 基准测试中，我们的方法表现卓越，证明了其在多种语音处理任务中的高效性。主要创新点包括：1) 创新性地构建了语音处理专用工具集，2) 利用大型语言模型打造了高性能代理，3) 为处理复杂的指令导向语音任务提供了新思路。此外，我们的方法无需额外的训练过程，为语音处理领域提供了一个既灵活又可扩展的解决方案。
[Arxiv](https://arxiv.org/abs/2407.09886)
==========
# 开放世界任务规划的语言增强符号规划器
发布时间：2024年07月13日
`Agent` `机器人学` `人工智能`
> Language-Augmented Symbolic Planner for Open-World Task Planning
# 摘要
> 长期以来，让机器人代理执行复杂的长期任务一直是机器人学和人工智能领域的追求。尽管大型语言模型（LLM）展现出潜力，但其规划能力仍局限于短期任务，无法替代传统的符号规划方法。而符号规划器在开放世界环境中可能因对完整领域知识的假设而遭遇执行错误。为此，我们提出了一种语言增强的符号规划器（LASP），它融合了预训练的LLM，使传统符号规划器能在知识不完全的开源环境中运作。当遇到执行错误时，LASP能借助LLM根据观察诊断错误原因，并通过与环境的互动逐步构建完成任务所需的知识库。实验证明，LASP在开放世界环境中解决规划问题表现优异，即便在知识存在多处缺口的情况下也能应对自如。
[Arxiv](https://arxiv.org/abs/2407.09792)
==========
# 密集多模态对齐助力开放词汇表的3D场景深度理解
发布时间：2024年07月13日
`LLM应用` `计算机视觉` `人工智能`
> Dense Multimodal Alignment for Open-Vocabulary 3D Scene Understanding
# 摘要
> 近期，视觉-语言预训练模型在零-shot识别任务中表现出色。然而，以往的开放词汇3D场景理解方法往往只依赖单一模态的监督，忽视了多模态融合的潜力。为此，我们提出了密集多模态对齐（DMA）框架，旨在将不同模态紧密融合至同一空间，以发挥其协同效应。我们不仅利用大型视觉-语言模型提取详尽的类别信息和场景描述，还通过图像模态构建点-像素-文本的紧密联系。同时，为提升2D模型在3D任务中的泛化能力，我们采用了双路径集成策略，融合了固定的CLIP视觉特征与可调整的掩码特征。实验结果显示，DMA方法在室内外多种任务中均展现出卓越的开放词汇分割性能。
[Arxiv](https://arxiv.org/abs/2407.09781)
==========
# 大型语言模型蒸馏中的多粒度语义修订
发布时间：2024年07月13日
`LLM理论` `人工智能` `软件工程`
> Multi-Granularity Semantic Revision for Large Language Model Distillation
# 摘要
> 知识蒸馏在压缩大型语言模型（LLM）中至关重要，它通过大型教师模型的引导提升小型学生模型的性能。然而，现有方法过于依赖学生生成的输出，可能引入错误并误导蒸馏过程。此外，先前的蒸馏损失函数难以对齐LLM输出中最具信息量的部分。为此，我们提出了一种多粒度语义修正方法。在序列级别，我们采用序列校正与重新生成（SCRG）策略，通过计算教师与学生的语义差异来检测并校正错误标记，从而减少生成错误并增强多样性。在标记级别，我们设计了分布自适应剪裁Kullback-Leibler（DAC-KL）损失，利用可学习子网络自适应提取语义密集区域，避免冗余信息干扰。在跨度级别，我们利用跨度先验计算概率相关性，并确保教师与学生的一致性，进一步增强语义信息传递。广泛实验表明，我们的方法在不同模型家族中表现优异，参数范围涵盖0.1B至13B。
[Arxiv](https://arxiv.org/abs/2407.10068)
==========
# 学会拒绝：致力于缓解 LLMs 中的隐私风险
发布时间：2024年07月13日
`LLM应用` `隐私保护`
> Learning to Refuse: Towards Mitigating Privacy Risks in LLMs
# 摘要
> 大型语言模型 (LLM) 在自然语言处理方面表现出色，但可能无意中泄露私人信息，存在隐私风险。本研究针对这一问题，提出了一种无需全面重训即可保护个人数据的方法。我们创建了 \return 数据集，包含 2,492 名维基百科用户的问答对，用于评估机器遗忘技术。同时，我们设计了名称感知遗忘框架 (NAUF)，确保模型能识别并保护特定个人信息，而不影响其对其他无关信息的处理能力。实验结果显示，NAUF 在遗忘性能上领先现有方法 5.65 分，既能有效保护隐私，又不损模型整体性能。
[Arxiv](https://arxiv.org/abs/2407.10058)
==========
# LeanQuant：借助损失-误差-感知网格，精准量化大型语言模型
发布时间：2024年07月13日
`LLM理论` `计算机科学` `人工智能`
> LeanQuant: Accurate Large Language Model Quantization with Loss-Error-Aware Grid
# 摘要
> 大型语言模型虽应用广泛，但其高计算和内存需求成为部署难题。权重量化技术能有效降低解码延迟和内存需求，但现有方法在低位宽下质量损失严重。我们基于 OBQ 框架，发现其均匀量化网格的不足，并提出 LeanQuant，通过学习损失错误感知的量化网格，显著提升效率和准确性。实证显示，LeanQuant 能在 6 小时内完成 700 亿参数模型的量化，且在低比特区域表现卓越。
[Arxiv](https://arxiv.org/abs/2407.10032)
==========
# 利用大型语言模型从医学文本中提取因果关系
发布时间：2024年07月13日
`LLM应用` `人工智能`
> Causality extraction from medical text using Large Language Models (LLMs)
# 摘要
> 本研究首次展示了从妊娠糖尿病临床实践指南中提取因果关系的能力，通过使用BERT变体和大型语言模型如GPT-4和LLAMA2进行实验。结果显示，BioBERT以0.72的平均F1分数领先，而GPT-4和LLAMA2虽表现相近，但一致性稍逊。此外，我们还公开了相关代码和注释语料库，以供进一步研究。
[Arxiv](https://arxiv.org/abs/2407.10020)
==========
# TOP：一项针对目标受众的内容释义新任务
发布时间：2024年07月13日
`LLM应用` `数字营销` `内容创作`
> TOP:A New Target-Audience Oriented Content Paraphrase Task
# 摘要
> 推荐系统常向用户推荐现有内容，但动态调整推荐逻辑以适应用户兴趣偏好，可能吸引更多用户。为此，我们提出“目标受众导向内容改述”任务，旨在生成更贴合用户偏好的定制内容。本文详细介绍了任务定义、框架及数据集创建方法，并利用LLMs和LVMs实现TOP框架，提供基准结果。
[Arxiv](https://arxiv.org/abs/2407.09992)
==========
# PFPs：借助大型视觉与语言模型，通过提示引导实现灵活的病理分割，适用于多样化的潜在结果分析。
发布时间：2024年07月13日
`LLM应用` `人工智能`
> PFPs: Prompt-guided Flexible Pathological Segmentation for Diverse Potential Outcomes Using Large Vision and Language Models
# 摘要
> Vision Foundation Model 在医学图像分析中崭露头角，其零-shot 学习能力不仅加速了 AI 部署，还提升了临床应用的泛化性。但在分割病理图像时，对分割目标的灵活性要求尤为突出。例如，在 Whole Slide Image (WSI) 上的单次点击可能代表不同层次的复杂性。现有模型虽能预测结果，却难以适应医生的灵活输入。本文中，我们通过结合大型语言模型 (LLM) 和传统任务令牌，探索了提升分割模型灵活性的新途径。我们的研究成果包括：(1) 构建了一个高效计算的流水线，利用微调的语言提示实现灵活的多类别分割；(2) 对比了固定提示与自由文本的分割效果；(3) 设计了多任务的肾脏病理分割数据集及相应的自由文本提示；(4) 在肾脏病理数据集上验证了我们的方法，考察了其在处理新病例时的能力。
[Arxiv](https://arxiv.org/abs/2407.09979)
==========
# 精简基于 PLM 的少样本意图检测器
发布时间：2024年07月13日
`LLM应用` `移动设备` `人工智能`
> Minimizing PLM-Based Few-Shot Intent Detectors
# 摘要
> 近期研究展示了在有限标注数据下，基于预训练模型训练高效意图检测器的可能性。但这些大型检测器在移动设备等资源受限环境中的部署面临挑战。为此，我们探索了减小模型尺寸的技术，包括利用LLM进行数据增强、采用尖端压缩技术进行知识蒸馏及设计V-Prune词汇剪枝机制。这些创新举措不仅将模型内存使用压缩了21倍，且在四大实际基准测试中性能几乎未损。
[Arxiv](https://arxiv.org/abs/2407.09943)
==========
# 利用 Llama3 大型语言模型实现自主导航的语音引导顺序规划
发布时间：2024年07月13日
`Agent` `机器人技术` `社交互动`
> Speech-Guided Sequential Planning for Autonomous Navigation using Large Language Model Meta AI 3 (Llama3)
# 摘要
> 社交机器人领域致力于让机器人更自然地与人类互动。借助GPTs和Llamas等先进LLMs，机器人已能更好地理解自然语言。本文提出一个语音引导的自主导航系统，结合Llama3和ROS，通过解析语音命令并转化为顺序动作，实现高效的任务执行。该系统在物体取送等场景中尤为关键。我们通过DRL-VO策略，使机器人在复杂社交环境中自主导航。模拟实验和硬件测试均证实了系统的实用性，尤其在需要机器人灵活互动的实际应用中展现出巨大潜力。
[Arxiv](https://arxiv.org/abs/2407.09890)
==========
# 通过反向苏格拉底合成，我们为 LLM 的优化建模和推理能力设立了基准测试。
发布时间：2024年07月13日
`LLM应用` `人工智能`
> Benchmarking LLMs for Optimization Modeling and Enhancing Reasoning via Reverse Socratic Synthesis
# 摘要
> 大型语言模型 (LLM) 在数学推理中展现了其问题解决能力。然而，当前的 OPT 基准仅解决线性规划，远不能满足复杂现实情况。为此，我们提出了 E-OPT，一个具有人类可读输入和输出的端到端优化问题解决基准，包含丰富的优化问题，全面评估 LLM 的解决能力。此外，为了缓解数据稀缺性，并缩小开源与闭源 LLM 之间的差距，我们提出了 ReSocratic 数据合成方法，通过逐步合成优化场景并反向翻译成问题，构建了 ReSocratic-29k 数据集。实验表明，Llama3-8b 在 E-OPT 上的表现显著提升至 51.7%，DeepSeek-V2 达到 61.0%，接近 GPT-4 的 65.5%。
[Arxiv](https://arxiv.org/abs/2407.09887)
==========
# 构建针对 INDIC 语言的预训练 LLM 数据集：印地语案例研究
发布时间：2024年07月13日
`LLM应用` `语言技术`
> Building pre-train LLM Dataset for the INDIC Languages: a case study on Hindi
# 摘要
> 大型语言模型（LLM）在自动响应人类指令的应用中展现了革命性能力，但构建这些模型，尤其是在印度语系中，面临的主要难题是高质量基础数据集的稀缺。本文中，我们提出了一款专为印度语系中的Hindi语言设计的大型预训练数据集，涵盖了多个领域及主要方言，共计12.8亿词元。我们详细阐述了数据采集、预处理及预训练应用的完整流程。此方法不仅适用于其他印度语种及低资源语言，还将无偿开放，助力LLM的预训练与研究。
[Arxiv](https://arxiv.org/abs/2407.09855)
==========
# 探索 Transformer 语言模型中的低秩训练，分析其效率与规模效应。
发布时间：2024年07月13日
`LLM理论` `人工智能` `计算机科学`
> Investigating Low-Rank Training in Transformer Language Models: Efficiency and Scaling Analysis
# 摘要
> 当前最先进的 LLM 依赖于高计算成本的规模，激发了减少参数数量和成本的研究。我们专注于基于 Transformer 的 LLM，特别是对计算密集型的前馈网络（FFN）应用低秩参数化。与以往不同，我们（i）大规模探索低秩参数化，高达 1.3B 参数；（ii）在 Transformer 而非卷积架构中；（iii）从零开始训练。实验显示，低秩参数化在训练中高效且有效。这些结构化 FFN 的缩放曲线比原始模型更陡峭。基于此，我们开发的宽结构网络在性能上超越了现有的大型 Transformer。
[Arxiv](https://arxiv.org/abs/2407.09835)
==========
# NativQA：为 LLM 设计的多语言、文化对齐的自然查询系统
发布时间：2024年07月13日
`LLM应用` `人工智能` `语言学`
> NativQA: Multilingual Culturally-Aligned Natural Query for LLMs
# 摘要
> 自然问题回答 (QA) 数据集对于评估和提升大型语言模型 (LLM) 的实际应用能力至关重要。然而，现有数据集大多缺乏区域和文化特定性，这限制了 LLM 在这些方面的基准测试。为此，我们提出了 NativQA 框架，旨在构建与特定文化和区域相符的母语 QA 数据集，以优化 LLM 的评估和调整。此外，我们创建了 MultiNativQA 数据集，包含约 72K 个多语言 QA 对，覆盖从高到极低资源语言，基于 18 个主题的母语者查询。我们通过对比开源和闭源 LLM 对该数据集的性能进行了基准测试，并将 NativQA 框架和 MultiNativQA 数据集公开，供社区使用。(https://nativqa.gitlab.io)
[Arxiv](https://arxiv.org/abs/2407.09823)
==========
# IoT-LM：专为物联网设计的大型多感官语言模型
发布时间：2024年07月13日
`LLM应用` `物联网` `智能城市`
> IoT-LM: Large Multisensory Language Models for the Internet of Things
# 摘要
> 物联网网络，融合了数十亿智能设备，这些设备内置传感器、软件及通信技术，正迅速成为现代社会的关键支柱。IoT生态系统提供多样化的现实数据，如运动、热能、位置、图像、深度、传感器信号及音频，助力识别人与物的状态。机器学习技术在此领域大放异彩，能高效处理海量IoT数据，进而深入洞察人类福祉、精准操控设备、并促进智能城市间的互联互通。为此，我们推出了IoT-LM——一款专为IoT环境设计的开源大型多感官语言模型。IoT-LM的诞生得益于两大技术突破：首先是MultiIoT数据集，它汇聚了超过115万份样本，涵盖12种模态与8项任务，为多感官预训练与指令调优奠定基础；其次是创新的多感官多任务适配器层，它让预训练的大型语言模型能更好地适应多感官IoT数据。IoT-LM在8项IoT分类任务中表现卓越，更展现出基于IoT传感器的全新交互式问答、推理及对话功能。我们已公开IoT-LM的数据源及多感官语言建模框架，以飨研究者。
[Arxiv](https://arxiv.org/abs/2407.09801)
==========
# 探究神经代码生成模型的不足之处
发布时间：2024年07月13日
`LLM应用` `软件开发` `人工智能`
> Uncovering Weaknesses in Neural Code Generation
# 摘要
> 代码生成技术在预训练大型语言模型（PLMs）的推动下取得了长足进步。然而，关于基准测试和生成代码的弱点分类尚不完善，这可能导致研究焦点偏移。为此，我们评估了五个顶尖PLMs，包括三个大型模型（CodeGen2.5、CodeGeeX2、GPT-4 Turbo）和两个小型模型（UnixCoder、CodeT5 base），在CoNaLa、HumanEval Plus和DS-1000数据集上进行测试。我们通过匹配和执行指标评估代码质量，并进行了主题分析，识别出九种弱点类型。研究发现：1. 不准确的提示在CoNaLa中导致大型模型失败率高达26.84%，小型模型更甚，达40%；2. 关键语义缺失在各基准测试中普遍存在，如CoNaLa中65.78%的任务、HumanEval Plus中66.09%、DS-1000中80.51%；3. 所有模型在API使用上都面临挑战，尤其是面对模糊或复杂的提示。这些发现旨在引导研究方向，同时我们的注释也为深入分析提供了针对性的基准子集。
[Arxiv](https://arxiv.org/abs/2407.09793)
==========
# 利用知识库引导生成技术，实现文档级临床实体与关系的精准抽取。
发布时间：2024年07月13日
`LLM应用` `人工智能`
> Document-level Clinical Entity and Relation Extraction via Knowledge Base-Guided Generation
# 摘要
> GPT模型因其精确的抽取和上下文理解能力，在临床实体和关系抽取任务中表现出色。我们通过整合统一医学语言系统（UMLS）知识库，进一步提升了文档级临床实体和关系的识别精度。我们的框架通过筛选与文本相关的UMLS概念，并将其融入提示中，引导语言模型更精准地抽取实体。实验结果显示，这种结合UMLS的概念映射方法，相较于未使用UMLS的通用语言模型，在少样本抽取任务中表现更优。同时，我们的方法也超越了传统的检索增强生成（RAG）技术。总体来看，将UMLS与GPT模型结合，不仅提升了实体和关系的识别效率，也为医疗等专业领域的方法应用开辟了新路径。
[Arxiv](https://arxiv.org/abs/2407.10021)
==========
# 深入探讨上下文线性估计的细粒度分析，涵盖数据、架构及其他相关因素。
发布时间：2024年07月13日
`LLM理论` `人工智能` `机器学习`
> Fine-grained Analysis of In-context Linear Estimation: Data, Architecture, and Beyond
# 摘要
> 最新研究显示，通过线性估计器和梯度下降步骤，采用线性注意力的Transformer能够实现上下文学习（ICL）。然而，现有优化分析仅限于理想化场景，其中任务与特征向量独立同分布，且注意力权重完全参数化。本研究深入探讨了ICL的优化与泛化机制，通过以下创新：（1）分析了单层线性注意及H3状态空间模型的优化特性，证明在特定条件下两者均能执行一步预处理梯度下降，且H3凭借其内置卷积滤波器，在适当场景下可实现样本加权并超越线性注意。（2）针对检索增强生成（RAG）与任务-特征对齐，提出新的风险边界，揭示了分布对齐如何降低ICL的样本复杂度。（3）推导了低秩参数化注意力权重的最优风险，并阐释了LoRA如何通过捕捉任务协方差变化适应新分布。实验验证了理论成果，全面深化了对ICL机制的理解。
[Arxiv](https://arxiv.org/abs/2407.10005)
==========
# 缓解大型语言模型中的实体级幻觉问题
发布时间：2024年07月12日
`LLM应用` `信息检索` `人工智能`
> Mitigating Entity-Level Hallucination in Large Language Models
# 摘要
> 随着大型语言模型 (LLM) 的兴起，用户获取信息的方式已从传统搜索引擎转向与 LLM 的直接问答交互。然而，LLM 的普及也暴露出一个严重问题——幻觉现象，即生成看似合理但事实错误的信息。这引发了用户对基于 LLM 的信息检索系统的疑虑。为此，本文提出了一种基于幻觉检测的动态检索增强方法 (DRAD)，旨在有效识别并修正 LLM 中的幻觉。DRAD 通过实时幻觉检测 (RHD) 和基于外部知识的自我修正 (SEK) 两大核心机制，动态优化检索过程，显著提升了幻觉检测与修正的效率。实验证明，DRAD 在这两方面均表现卓越。相关代码与数据已开源，详见 https://github.com/oneal2000/EntityHallucination。
[Arxiv](https://arxiv.org/abs/2407.09417)
==========
# PersonaRAG：借助以用户为中心的代理，提升检索增强生成系统的性能
发布时间：2024年07月12日
`RAG` `信息检索` `个性化服务`
> PersonaRAG: Enhancing Retrieval-Augmented Generation Systems with User-Centric Agents
# 摘要
> 大型语言模型因知识陈旧和产生幻觉而难以提供可靠输出。RAG 模型虽通过结合外部知识改善了这一问题，但个性化检索方面仍有不足。本文提出的 PersonaRAG 框架，通过集成以用户为核心的代理，实时根据用户数据和互动调整检索与生成策略，显著提升了问答任务中的表现，为用户提供精准答案。这一成果预示着个性化信息检索系统的广阔前景。
[Arxiv](https://arxiv.org/abs/2407.09394)
==========
# RAG 中，上下文嵌入助力高效答案生成
发布时间：2024年07月12日
`RAG` `人工智能` `软件开发`
> Context Embeddings for Efficient Answer Generation in RAG
# 摘要
> RAG 通过引入外部信息扩展输入，突破了 LLMs 的知识局限。然而，这使得上下文输入变长，直接延长了用户的等待时间。为此，我们推出了 COCOM，一种高效的上下文压缩技术，将冗长的上下文精简为几个关键嵌入，大幅缩短生成时间。COCOM 允许根据需求调整压缩率，平衡解码速度与答案质量。相较于传统方法，COCOM 在处理复杂上下文时更为出色，显著提升了处理长输入的效率。实验表明，我们的方法在保持高性能的同时，最高可实现 5.69 倍的加速。
[Arxiv](https://arxiv.org/abs/2407.09252)
==========
# 移动设备多模态代理安全矩阵：系统性研究与概念验证
发布时间：2024年07月12日
`Agent` `移动设备` `网络安全`
> Security Matrix for Multimodal Agents on Mobile Devices: A Systematic and Proof of Concept Study
# 摘要
> 多模态大型语言模型（MLLMs）的推理能力飞速提升，催生了移动设备上的自主代理系统。这些系统集感知、推理、记忆与多代理协作于一体，仅凭自然语言和设备截图就能自动解析用户指令，构建任务流程。然而，尽管人机交互效率大增，这些系统的安全风险却未被深入探讨。当前的安全评估多聚焦于网络环境，而针对移动代理场景的攻击手段也相对有限。为此，本文构建了一个移动代理安全矩阵，覆盖了系统的三大核心模块，并设计了四种实际攻击路径，通过八种攻击手段进行验证。研究显示，这些系统不仅面临传统攻击的威胁，还引发了新的安全隐忧。本文强调，在设计基于MLLM的系统时，必须提升安全意识，为未来的攻防研究奠定基础。
[Arxiv](https://arxiv.org/abs/2407.09295)
==========
# 虚拟环境中，指令遵循与目标条件强化学习相结合
发布时间：2024年07月12日
`Agent` `人工智能`
> Instruction Following with Goal-Conditioned Reinforcement Learning in Virtual Environments
# 摘要
> 本研究旨在让AI代理在虚拟环境中顺利执行复杂语言指令。我们设计了一个分层框架，融合了大型语言模型的深度理解和强化学习代理的灵活行动能力。语言模块将指令转化为行动蓝图，由强化学习代理执行。我们在IGLU和Crafter两个环境中验证了这一方法的有效性，无论是构建结构还是执行任务与环境互动，均表现出色。
[Arxiv](https://arxiv.org/abs/2407.09287)
==========
# SPIQA 数据集：专为科学论文的多模态问答设计
发布时间：2024年07月12日
`LLM应用` `科学研究` `计算机科学`
> SPIQA: A Dataset for Multimodal Question Answering on Scientific Papers
# 摘要
> 在长篇科学研究文章中寻找答案是一个关键的研究领域，有助于读者快速解决他们的疑问。然而，基于科学论文的现有问答（QA）数据集规模有限，且仅关注文本内容。为此，我们推出了SPIQA（科学论文图像问答），这是首个专门设计用于解读科学研究文章中复杂图表和表格的大规模QA数据集，涵盖计算机科学各个领域。我们利用多模态大型语言模型（MLLMs）的广泛专业知识和理解图表的能力，通过自动和手动筛选创建了这一数据集。SPIQA包含27万个问题，分为训练、验证和三种不同的评估分组。通过与12个著名基础模型的广泛实验，我们评估了当前多模态系统理解研究文章细微差别的能力。此外，我们提出了一种带有上下文检索的思维链（CoT）评估策略，允许逐步细致评估并提高模型性能。我们还探讨了通过额外文本信息提升性能的上限，强调了其对未来研究和数据集在革新我们与科学文献互动方式方面的潜在影响。
[Arxiv](https://arxiv.org/abs/2407.09413)
==========
# HelixProtX 大型多模态模型整合序列、结构与描述，实现任意蛋白质间的生成。
发布时间：2024年07月12日
`LLM应用` `生物学` `蛋白质研究`
> Unifying Sequences, Structures, and Descriptions for Any-to-Any Protein Generation with the Large Multimodal Model HelixProtX
# 摘要
> 蛋白质作为生物系统的基石，可通过序列、结构和文本等多种形式展现其特性。尽管深度学习与大型科学语言模型在蛋白质研究领域取得了显著进展，但现有方法多聚焦于单一任务，如从一种形式预测另一种。这些方法局限了对多模态蛋白质数据的深入理解与生成。相反，大型多模态模型已展现出跨领域生成内容的潜力，如文本、图像和视频，极大地丰富了用户交互体验。将此类多模态技术融入蛋白质研究，有望革新我们对蛋白质的认知方式。为此，我们推出了HelixProtX系统，该系统基于大型多模态模型，旨在通过支持任意蛋白质形式的转换，为蛋白质研究提供全面解决方案。实验表明，HelixProtX不仅能够从氨基酸序列生成功能描述，还能根据文本描述设计蛋白质序列和结构，其性能在多项任务中超越了现有顶尖模型。通过整合多模态大型模型，HelixProtX为蛋白质生物学研究开辟了新路径，有望推动科学发现的加速。
[Arxiv](https://arxiv.org/abs/2407.09274)
==========
# DART 是一个全自动的物体检测流程，集成了数据多样化、开放词汇的边界框标注、伪标签审核以及模型训练。
发布时间：2024年07月12日
`LLM应用` `工业安全`
> DART: An Automated End-to-End Object Detection Pipeline with Data Diversification, Open-Vocabulary Bounding Box Annotation, Pseudo-Label Review, and Model Training
# 摘要
> 在工业应用中，如建筑工地的安全监控，快速准确地检测特定对象至关重要。传统方法依赖繁琐的手动标注和数据收集，难以适应多变的环境和新对象。为此，我们提出了DART，一个自动化端到端流程，简化对象检测的全流程，无需人工标注和大量数据收集，适应性强。DART通过主题驱动的图像生成模块（DreamBooth with SDXL）丰富数据，再由开放词汇对象检测（Grounding DINO）生成标注，经大型多模态模型（GPT-4o）审核后，用于训练实时检测器（YOLO）。我们在自建的建筑机械数据集Liebherr Product上应用DART，显著提升平均精度（AP）至0.832。DART的模块化设计确保了未来算法的升级、新类别的无缝集成及定制环境的适应性。相关代码和数据集已公开于https://github.com/chen-xin-94/DART。
[Arxiv](https://arxiv.org/abs/2407.09174)
==========
# AI 赋能的沉浸式辅助，助力工业环境中的交互任务执行
发布时间：2024年07月12日
`LLM应用` `制造业` `虚拟现实`
> AI-Powered Immersive Assistance for Interactive Task Execution in Industrial Environments
# 摘要
> 许多行业依赖熟练员工操作复杂机械。我们开发了一款AI辅助系统，通过VR模拟果汁混合场景，帮助用户在工业环境中完成复杂任务。该系统模拟了制药等行业中用于混合原料的复杂机械，并配备了多种设备和传感器。在受控环境中，这一设置不仅展示了系统的功能，也为更广泛的应用提供了概念验证。我们的AI助手结合了大型语言模型和语音识别技术，通过分析专家在VR中的操作视频，为用户提供详细指导。这一创新展示了AI助手在减轻认知负担、提升效率和保障安全方面的巨大潜力。
[Arxiv](https://arxiv.org/abs/2407.09147)
==========
# 多模态大型语言模型中拒绝安全提示
发布时间：2024年07月12日
`LLM应用` `人工智能` `计算机视觉`
> Refusing Safe Prompts for Multi-modal Large Language Models
# 摘要
> 多模态大型语言模型（MLLMs）已成为生成式AI领域的核心，激发了科技界的热烈竞争。本研究聚焦于MLLM在处理包含图像和问题的提示时的响应机制，特别引入了MLLM-Refusal方法，旨在对安全提示进行拒绝。通过优化微妙的图像扰动，我们的方法能使目标MLLM对安全提示产生拒绝反应。这一创新不仅为模型提供商带来了竞争优势，还通过实验证明了其在多个模型和数据集上的有效性。尽管存在一些反制措施，如添加噪声或对抗训练，但这些方法在减轻拒绝效果的同时，也影响了模型的性能。详细代码已公开在GitHub上，供进一步研究与应用。
[Arxiv](https://arxiv.org/abs/2407.09050)
==========
# FairyLandAI：借助 ChatGPT 与 DALLE-3，打造专属童话世界
发布时间：2024年07月12日
`LLM应用`
> FairyLandAI: Personalized Fairy Tales utilizing ChatGPT and DALLE-3
# 摘要
> 在AI叙事的丰富世界中，我们有机会通过定制和个性化的故事吸引年轻观众。本文介绍的FairyLandAI，是一款通过OpenAI的API精心打造的大型语言模型，专为儿童创作个性化童话。FairyLandAI的独特之处在于其双重功能：它不仅能生成适合儿童年龄、反映多元文化的引人故事，还能自动生成激发高级图像工具如GenAI和Dalle-3创造力的提示，从而丰富叙事体验。该模型特别设计，以契合儿童的想象世界，提供既寓教于乐又符合不同年龄道德观的叙事。其独特之处在于根据儿童的个人喜好和文化背景定制故事，开启了个性化叙事的新篇章。同时，它与图像生成技术的结合，为儿童提供了全面的叙事体验，激发他们的语言和视觉创造力。实证研究表明，FairyLandAI能有效创作出既娱乐又富含多元文化价值观的故事。对于家长和教育者而言，FairyLandAI是一个宝贵的工具，帮助他们通过吸引人的故事传递深刻的道德教育。该模型标志着利用LLM，特别是通过OpenAI的API，进行教育和文化提升的创新步伐，使复杂的道德叙事对年轻、富有想象力的儿童变得既易懂又享受。
[Arxiv](https://arxiv.org/abs/2407.09467)
==========
# 为无限上下文 LLM 设计类人情节记忆
发布时间：2024年07月12日
`LLM应用` `人工智能` `认知科学`
> Human-like Episodic Memory for Infinite Context LLMs
# 摘要
> 尽管大型语言模型 (LLM) 展现了卓越能力，但在处理广泛上下文时仍显不足，影响了长序列的连贯性与准确性。相比之下，人脑在组织和检索一生中的情节体验方面表现出色。为此，我们提出了 EM-LLM，一种创新方法，将人类情节记忆与事件认知融入 LLM，使其能高效处理无限长度的上下文。EM-LLM 利用贝叶斯惊奇与图论边界细化在线组织令牌序列为连贯情节事件，并通过两阶段记忆过程，结合相似性与时间连续性检索，实现类人高效信息访问。实验表明，EM-LLM 在 LongBench 数据集上超越了 InfLLM 模型，总体性能提升 4.3%，尤其在 PassageRetrieval 任务上提高了 33%。分析还显示，EM-LLM 的事件分割与人类感知高度一致，架起了人工与生物系统的桥梁。此研究不仅增强了 LLM 的上下文处理能力，还为探索人类记忆机制提供了计算框架，推动了 AI 与认知科学的交叉研究。
[Arxiv](https://arxiv.org/abs/2407.09450)
==========
# ASTPrompter：通过弱监督自动化手段，对语言模型进行红队测试，以识别潜在的有毒提示。
发布时间：2024年07月12日
`LLM应用` `软件测试` `人工智能安全`
> ASTPrompter: Weakly Supervised Automated Language Model Red-Teaming to Identify Likely Toxic Prompts
# 摘要
> 我们提出了一种强化学习方法，用于自动化测试大型语言模型（LLM）的安全性，专注于发现既能触发有毒输出又能保持低困惑度的提示。这种方法通过在 GPT-2 和 GPT-2 XL 模型上应用一种新颖的在线和弱监督的身份偏好优化（IPO）变体来实现。我们的策略不仅能生成可能的提示，还能触发有毒性，从而在正常使用模型时更可能出现。我们还对学习到的策略、可能性和有毒性之间的权衡进行了定性分析，并讨论了其潜在影响。项目源代码已公开，可在 GitHub 上获取。
[Arxiv](https://arxiv.org/abs/2407.09447)
==========
# MUSCLE：一种促进 LLM 兼容进化的模型更新策略
发布时间：2024年07月12日
`LLM理论` `软件开发` `人工智能`
> MUSCLE: A Model Update Strategy for Compatible LLM Evolution
# 摘要
> 大型语言模型 (LLM) 因数据或架构的改进而频繁更新，以提升性能。然而，开发者往往更注重提升性能指标，而忽视了与旧版本的兼容性。用户在与模型互动时会形成心理模型，每次更新都需调整，这可能导致不满。实际应用中，微调的下游任务模型依赖于预训练的 LLM 基础模型，更新后常出现实例回归或预测错误。我们的工作旨在通过两种方式实现无缝更新：首先，我们提供兼容性评估指标，特别针对生成任务；其次，我们提出训练策略，通过兼容性模型减少不一致性，从 Llama 1 到 Llama 2 减少高达 40% 的负面翻转。
[Arxiv](https://arxiv.org/abs/2407.09435)
==========
# 临床大型语言模型对指令的表述方式颇为敏感。
发布时间：2024年07月12日
`LLM应用` `人工智能`
> Open (Clinical) LLMs are Sensitive to Instruction Phrasings
# 摘要
> 指令调整的 LLM 虽能执行多样任务，但对其指令的表述极为敏感。在医疗领域，这一问题尤为突出，因为临床医生通常不具备设计精准指令的技能，而错误输出的风险在此领域尤为严重。  我们面临的实际问题是：这些模型对临床任务指令的自然变化有多强的适应性？我们收集了来自医生们的各种任务提示，并评估了七种 LLM（包括通用与专业模型）对自然指令表述的敏感度。结果显示，所有模型的性能差异显著，且令人意外的是，那些专门针对临床数据训练的模型尤为脆弱，相比之下，通用模型表现更为稳健。此外，指令表述的微小差异也可能影响模型的公平性，例如，针对死亡率预测的不同但合理的指令，不仅在整体性能上有所差异，还可能导致不同群体间的结果偏差。
[Arxiv](https://arxiv.org/abs/2407.09429)
==========
# TelecomGPT：打造电信专属大型语言模型的框架
发布时间：2024年07月12日
`LLM应用` `人工智能`
> TelecomGPT: A Framework to Build Telecom-Specfic Large Language Models
# 摘要
> 大型语言模型 (LLM) 有望革新第六代 (6G) 通信网络，但当前主流 LLM 普遍缺乏电信专业知识。本文首次提出了一种将通用 LLM 转化为电信特定 LLM 的流程，通过构建专用数据集进行持续预训练、指令调整和校准调整。针对电信领域缺乏评估基准的问题，我们扩展了现有基准并新增了电信数学建模、开放问答和代码任务三大基准，全面评估 LLM 在电信领域的各项能力。经微调的 TelecomGPT 在电信数学建模基准上显著超越现有最先进模型，并在多个评估基准上表现卓越。
[Arxiv](https://arxiv.org/abs/2407.09424)
==========
# GAVEL：借助进化与语言模型创造游戏
发布时间：2024年07月12日
`Agent` `游戏开发` `人工智能`
> GAVEL: Generating Games Via Evolution and Language Models
# 摘要
> 自动生成新颖有趣的游戏充满挑战，涉及规则表示、潜在游戏搜索及原创性与质量评估。过往研究多聚焦于有限规则并依赖特定领域启发。我们则利用Ludii游戏描述语言，涵盖千种棋盘游戏规则，结合大型语言模型与进化计算，训练智能变异与重组游戏机制的模型。实验证明，我们能创造新颖游戏，拓展规则空间边界，部分成果已在线开放体验。
[Arxiv](https://arxiv.org/abs/2407.09388)
==========
# 对比学习是否已足够？探讨其在 AI 生成文本检测与归因中的应用。
发布时间：2024年07月12日
`LLM应用` `网络安全`
> Is Contrasting All You Need? Contrastive Learning for the Detection and Attribution of AI-generated Text
# 摘要
> 大型语言模型的进步使得人机文本界限愈发模糊。AI文本的泛滥及其难以识别性，给社会带来新挑战。本文中，我们提出WhosAI框架，通过三元组网络对比学习，不仅能判断文本来源（人或AI），还能揭示作者身份。与传统方法不同，WhosAI从多生成器中同步学习语义表示，兼顾检测与归属。此外，WhosAI不依赖特定模型，能随新AI模型发布而扩展。实验表明，在TuringBench的20万新闻文章测试中，WhosAI在图灵测试与作者归属任务上表现卓越，超越了所有现有方法。
[Arxiv](https://arxiv.org/abs/2407.09364)
==========
# 本研究初步探索了利用分解框架和可推断特征实现灵活歌唱声音合成的方法。
发布时间：2024年07月12日
`LLM应用` `语音合成`
> A Preliminary Investigation on Flexible Singing Voice Synthesis Through Decomposed Framework with Inferrable Features
# 摘要
> 我们探索了通过分解框架提升歌唱声音合成（SVS）系统灵活性的可行性。传统的SVS系统受限于直接的乐谱到波形映射，仅能合成特定语言或歌手的声音。考虑到大规模标记歌唱数据集的收集成本，我们提出了一种分解SVS系统并推断歌唱声音特征的新方法。该系统被分解为语言、音高和合成三个模块，直接从音频中提取语言内容、音高、声音状态、歌手特征和响度等特征。这一分解框架不仅减轻了对标记数据集的依赖，还能适应多种语言和歌手，并填补歌唱声音的歌词内容。研究表明，尽管增加了功能和灵活性，该框架仍有潜力达到SVS领域的顶尖水平。对当前框架能力的全面分析为实现一个灵活且多功能的SVS系统提供了研究方向。
[Arxiv](https://arxiv.org/abs/2407.09346)
==========
# 善意的创新，风险并存：评估 AI 在移动与穿戴设备中利弊的方法
发布时间：2024年07月12日
`LLM应用` `移动设备` `可穿戴设备`
> Good Intentions, Risky Inventions: A Method for Assessing the Risks and Benefits of AI in Mobile and Wearable Uses
# 摘要
> 将AI融入移动设备和可穿戴设备，不仅带来多重益处，也引发了对新兴风险的关切。传统的风险与利益评估零散且成本高昂。我们创新了一种半自动方法，借助LLMs识别AI应用，依据欧盟AI法案分类风险，并确保利益符合全球可持续发展目标。经移动与可穿戴技术、法律合规专家及法律背景人士的手动验证，该方法准确率超85%。我们揭示了移动计算在提升福祉、安全与社会平等方面潜力巨大，但这些应用也伴随着敏感数据、弱势群体与自动化决策的风险。为避免错失这些虽有风险但极具影响力的应用，我们为移动HCI社区设计了风险评估清单。
[Arxiv](https://arxiv.org/abs/2407.09322)
==========
# 大型语言模型在贝叶斯网络结构启发中的可扩展性：创新方法论与对比分析
发布时间：2024年07月12日
`LLM应用` `人工智能` `数据分析`
> Scalability of Bayesian Network Structure Elicitation with Large Language Models: a Novel Methodology and Comparative Analysis
# 摘要
> 本研究提出一种创新方法，通过初始化多个经验各异的 LLM，独立构建贝叶斯网络 (BN) 结构，并采用多数投票确定最终结构。我们对比了该方法与另一种替代方案在不同规模和知名度的 BN 上的表现，并探讨了它们的可扩展性。此外，我们开发了一种检测 LLM 中 BN 污染的方法，发现某些知名 BN 不适用于评估 LLM 在 BN 结构诱导中的应用。实验还揭示，由于节点名称难以区分，部分 BN 不适合此类实验。对其他 BN 的测试显示，我们的方法在某一 LLM 上优于现有技术，但两种方法的性能均随 BN 规模增大而显著下降。
[Arxiv](https://arxiv.org/abs/2407.09311)
==========
# Transformer 层如同画家
发布时间：2024年07月12日
`LLM理论` `人工智能` `计算机科学`
> Transformer Layers as Painters
# 摘要
> 尽管transformer在大型语言模型中广泛应用，但其内部机制仍是个谜。我们旨在深入探究在预训练transformer中移除或重组信息的影响，这不仅能优化现有模型的使用，还能通过架构创新带来新变体。我们的实证研究发现，预训练transformer的底层和顶层与中间层存在差异，而中间层却展现出惊人的一致性。此外，我们发现某些问题类型对层跳过、非顺序运行或并行处理具有鲁棒性。这些观察暗示，即使是冻结的预训练模型，也能通过层跳过或并行处理，优雅地平衡准确性与延迟。
[Arxiv](https://arxiv.org/abs/2407.09298)
==========
# CEIPA：针对大型语言模型的反事实可解释增量提示攻击分析
发布时间：2024年07月12日
`LLM应用` `网络安全` `人工智能`
> CEIPA: Counterfactual Explainable Incremental Prompt Attack Analysis on Large Language Models
# 摘要
> 本研究揭示了在大型语言模型（如GPT-4和LLaMA-2）中加强安全和隐私措施的紧迫性，通过识别并缓解提示攻击中的漏洞。我们创新性地提出了“反事实可解释增量提示攻击（CEIPA）”技术，通过特定引导方式，量化攻击效果并探索模型内置防御机制。我们的方法通过增量反事实分析，深入解析了LLM生成有害响应的根源。将提示修改细分为四个递进层次（单词、句子、字符及复合组合），我们全面剖析了LLM的内在脆弱性。研究成果不仅深化了反事实解释，更显著提升了攻击提示的效力。
[Arxiv](https://arxiv.org/abs/2407.09292)
==========
# 利用大型语言模型构建历史文件真实性评估框架
发布时间：2024年07月12日
`LLM应用` `历史学` `语义网`
> Structuring Authenticity Assessments on Historical Documents using LLMs
# 摘要
> 历史上的伪造行为广泛存在，学者们持续评估历史文件的真实性。但在线目录仅提供描述性元数据，使得真实性讨论难以系统研究。本研究通过自然语言文本生成结构化数据，利用大型语言模型（LLM）自动选择、提取和分类相关声明，结合语义网技术进行结构化和验证。最终产出包含争议文件及其学者意见的目录，为深入分析历史辩论提供可能。
[Arxiv](https://arxiv.org/abs/2407.09290)
==========
# DAHRS：一种偏差感知型幻觉修正语义角色标注投影技术
发布时间：2024年07月12日
`LLM应用` `机器翻译`
> DAHRS: Divergence-Aware Hallucination-Remediated SRL Projection
# 摘要
> 语义角色标注（SRL）广泛应用于机器翻译、问答、摘要及立场检测等下游任务。然而，多语言SRL模型的构建因语义注释语料库的稀缺而颇具挑战。基于大型语言模型的SRL投影（XSRL）虽先进，但输出常含虚假角色标签，且因模型缺乏解释性，修复不易。我们发现，这些幻觉标签与自然语言中的偏差类型有关，这些偏差影响了初始对齐。为此，我们开发了偏差感知幻觉修复SRL投影（DAHRS），通过语言学引导的对齐修复和先到先得的贪婪投影，DAHRS在不增加复杂机制的情况下提升了投影准确性，超越了XSRL，并扩展至短语级SRL投影（如EN-FR、EN-ES）。以CoNLL-2009为基准，DAHRS在词级F1得分上显著提升，分别为87.6%（EN-FR）和89.0%（EN-ES），人类评估的短语级准确率亦高达89.1%（EN-FR）和91.0%（EN-ES）。此外，我们还引入了一个偏差度量，以便将此方法应用于其他语言对，如英语与他加禄语。
[Arxiv](https://arxiv.org/abs/2407.09283)
==========
# 探索人类行为决策的预测与理解，结合大型语言模型与认知实例学习的洞见
发布时间：2024年07月12日
`LLM应用` `人工智能` `心理学`
> Predicting and Understanding Human Action Decisions: Insights from Large Language Models and Cognitive Instance-Based Learning
# 摘要
> 大型语言模型（LLM）在多种任务中展现了卓越能力，从语言翻译到复杂推理。然而，这些模型能否理解和预测人类行为及偏见，对AI辅助系统至关重要，仍待解答。本文利用LLM的推理与生成能力，预测了两个连续决策任务中的人类行为，填补了这一研究空白。这些任务要求在利用与探索之间取得平衡，并处理延迟反馈，这对模拟真实决策过程至关重要。我们比较了LLM与模仿人类经验的认知实例-based learning（IBL）模型的性能。结果显示，LLM能迅速整合反馈，提升预测准确性；而认知IBL模型更佳地捕捉了人类的探索行为及损失厌恶偏差，即倾向于选择步骤成本较低的次优目标，而非探索最佳选择，即便经验有限。研究强调了LLM与认知架构结合的优势，预示这种结合能深化对复杂人类决策模式的理解与建模。
[Arxiv](https://arxiv.org/abs/2407.09281)
==========
# FedsLLM：通信网络中大型语言模型的联邦分割学习
发布时间：2024年07月12日
`LLM应用` `无线通信` `联邦学习`
> FedsLLM: Federated Split Learning for Large Language Models over Communication Networks
# 摘要
> 本文针对无线通信网络中部署大型语言模型的挑战，创新性地结合低秩适应技术（LoRA）与分割联邦学习框架，提出了FedsLLM框架。该方法通过LoRA技术划分网络，减轻处理负载，并利用联邦服务器整合更新客户端模型。由于训练数据在无线网络中传输，训练延迟受学习精度和带宽分配影响。本文通过计算与通信优化，将优化问题简化为凸问题，寻求最优解，并提出精确解的引理。仿真显示，该优化算法平均降低延迟达47.63%，显著提升效率。
[Arxiv](https://arxiv.org/abs/2407.09250)
==========
# 语言模型的社会语言学根基
发布时间：2024年07月12日
`LLM理论` `社会语言学` `人工智能`
> The Sociolinguistic Foundations of Language Modeling
# 摘要
> 本文从社会语言学角度探讨语言建模，指出大型语言模型本质上是多种语言的体现。我们探讨了这一观点如何助力大型语言模型的发展与应用，并详细阐述了语言变体的技术定义。此外，我们分析了这一视角在应对语言建模五大挑战——社会偏见、领域适应、对齐、语言变化及规模方面的潜力。最终，我们强调，为提升大型语言模型的性能与社会价值，精确构建代表特定语言变体的训练语料库至关重要。
[Arxiv](https://arxiv.org/abs/2407.09241)
==========
# 先提示，后收尾
发布时间：2024年07月12日
`LLM应用` `计算机科学`
> Prompts First, Finally
# 摘要
> 生成式AI（GenAI），尤其是大型语言模型，正深刻影响着计算机科学教育。它们在众多挑战中展现出日益增强的能力，引发了一些教育者的担忧，认为它们可能威胁到计算机教育，甚至主张在课堂上禁用。然而，在探讨这些未解问题的同时，审视计算机科学的整体发展趋势或许更为重要。自学科诞生之初，我们便不断追求在每种新表示中提升抽象层次，从硬件拨码开关到专用语言，再到流程图，直至现今的“自然语言”。GenAI的到来，使学生能够将问题抽象至他们熟悉的“语言”层面，这正是我们编程抽象的终极目标——自然语言。因此，本文主张，现在是时候在计算机科学教育中推行“提示优先”策略了。
[Arxiv](https://arxiv.org/abs/2407.09231)
==========
# 多模态大型语言模型在发音评估中的应用
发布时间：2024年07月12日
`LLM应用` `语言学习`
> Pronunciation Assessment with Multi-modal Large Language Models
# 摘要
> 大型语言模型 (LLM) 因其卓越的对话能力在教育领域备受推崇，尤其是在语言学习的自动化智能教学系统中。本文提出了一种基于 LLM 的评分系统，灵感源自其在文本评分任务中的显著成效。系统首先通过语音编码器将学习者语音转化为上下文特征，再由适配器层调整这些特征以匹配文本嵌入。随后，结合评估任务前缀和提示文本，LLM 能够精准预测语音的准确性与流畅度。实验结果显示，该评分系统在 Speechocean762 数据集上表现优异。此外，通过消融研究，我们进一步探究了提示文本和训练策略对系统性能的影响。
[Arxiv](https://arxiv.org/abs/2407.09209)
==========
# TAPI：针对代码大型语言模型的目标特定与对抗性提示注入策略
发布时间：2024年07月12日
`LLM应用` `软件开发` `网络安全`
> TAPI: Towards Target-Specific and Adversarial Prompt Injection against Code LLMs
# 摘要
> 近期，面向代码的大型语言模型（Code LLMs）在简化编程方面表现出色，使开发者能轻松生成完整功能代码。然而，这些模型也暴露出对后门和对抗性攻击的脆弱性。为融合这两种攻击的优势，本文引入了针对特定目标和对抗性提示注入（TAPI）的新攻击范式。TAPI巧妙地将恶意指令隐藏于不可读注释中，作为触发器嵌入源代码。一旦用户使用Code LLMs处理含触发器的代码，模型便会生成特定恶意代码。实验表明，TAPI攻击成功率高（达89.3%）且隐蔽性强（触发器设计节省53.1%令牌），甚至成功攻击了知名代码完成工具如CodeGeex和Github Copilot，凸显其现实威胁。
[Arxiv](https://arxiv.org/abs/2407.09164)
==========
# 幻觉生成与检测：LLM 的双重角色
发布时间：2024年07月12日
`LLM应用` `人工智能` `语言模型`
> The Two Sides of the Coin: Hallucination Generation and Detection with LLMs as Evaluators for LLMs
# 摘要
> 确保大型语言模型的可靠性，幻觉检测至关重要。我们参与了 CLEF ELOQUENT HalluciGen 共享任务，旨在开发幻觉内容生成与检测的评估器。通过探索 Llama 3、Gemma、GPT-3.5 Turbo 和 GPT-4 这四个模型的能力，并运用集成多数投票技术，我们综合利用这些模型进行幻觉检测。研究结果揭示了这些模型在幻觉生成与检测任务中的优劣，为我们提供了宝贵的洞察。
[Arxiv](https://arxiv.org/abs/2407.09152)
==========
# 准确性并非唯一追求
发布时间：2024年07月12日
`LLM理论` `计算机科学` `人工智能`
> Accuracy is Not All You Need
# 摘要
> 在压缩大型语言模型时，通常通过比较压缩前后模型在基准测试上的准确性来验证压缩技术的有效性。然而，即使准确性相近，我们也发现了一个有趣的现象——“翻转”，即答案在正确与错误之间转换。通过跨多种技术、模型和数据集的深入分析，我们揭示了压缩模型与原始模型在实际应用中的行为差异。此外，通过 MT-Bench 的评估，我们发现压缩模型在自由生成任务中的表现远不如原始模型。因此，我们建议在评估压缩技术时，除了准确性，还应考虑如 KL-散度等距离度量。我们提出的这两种度量方法显示出良好的相关性，为评估提供了新的视角。
[Arxiv](https://arxiv.org/abs/2407.09141)
==========
# 通过大型语言模型导师，逐步验证并纠正学生的推理错误
发布时间：2024年07月12日
`LLM应用` `人工智能`
> Stepwise Verification and Remediation of Student Reasoning Errors with Large Language Model Tutors
# 摘要
> 大型语言模型（LLM）为普及高质量个性化教育提供了契机。构建对话式辅导模型，辅助学生解决问题的策略颇具前景。尽管LLM在解答推理题上表现出色，但在精准识别学生错误并据此调整反馈方面仍有不足。借鉴现实教学中教师识别错误并个性化回应的做法，我们聚焦于验证学生解题方案，并证明这种验证能提升辅导反馈的质量。我们创建了一个包含1000条逐步数学推理链的数据集，首次错误由教师标记。实证显示，当前模型在学生解题中找错颇具挑战。我们设计并评估了多种错误检测验证器。通过自动与人工评估，证实这些验证器能引导生成模型针对学生错误提供精准反馈，较之现有方法，正确率更高，幻觉更少。
[Arxiv](https://arxiv.org/abs/2407.09136)
==========
# 在感到不安全时勇敢说“不”：通过解耦拒绝训练策略，提升 LLM 的安全性。
发布时间：2024年07月12日
`LLM应用` `网络安全` `人工智能`
> Refuse Whenever You Feel Unsafe: Improving Safety in LLMs via Decoupled Refusal Training
# 摘要
> 本研究针对大型语言模型（LLM）安全调优中的关键问题，通过解决安全数据中的拒绝偏差，提升了模型拒绝生成不安全内容的能力。我们提出的解耦拒绝训练（DeRTa）方法，通过两个创新技术——有害响应前缀的最大似然估计和强化过渡优化，增强了模型在面对有害提示时的安全响应能力。实证测试显示，DeRTa不仅提升了安全性，还在防御攻击方面超越了GPT-4等模型，有效抵御了如CodeAttack等高级攻击。详细代码和数据已公开在GitHub上。
[Arxiv](https://arxiv.org/abs/2407.09121)
==========
# AI加速器上基础模型的推理优化
发布时间：2024年07月12日
`LLM应用` `人工智能` `计算机硬件`
> Inference Optimization of Foundation Models on AI Accelerators
# 摘要
> Transformer架构的大型语言模型（LLMs）等强大基础模型，已引领生成式AI进入各行业的新时代。基于这些模型的应用层出不穷，涵盖问答、客户服务、图像视频生成及代码补全等。但模型参数激增至数千亿，导致实际部署成本高昂、延迟显著。因此，高效利用AI加速器进行快速推理的需求日益迫切。本教程深入探讨AI加速器在推理优化中的应用，从Transformer基础架构与深度学习系统出发，详述快速内存高效注意力计算的优化策略，并展示其在加速器上的高效实现。此外，教程还剖析了加速Transformer推理的核心架构要素，并探讨了模型压缩与快速解码的多重策略。
[Arxiv](https://arxiv.org/abs/2407.09111)
==========
# STD-LLM：借助 LLM 深入探索空间-时间数据的时空特性
发布时间：2024年07月12日
`LLM应用` `智能交通` `城市规划`
> STD-LLM: Understanding Both Spatial and Temporal Properties of Spatial-Temporal Data with LLMs
# 摘要
> 时空预测与插补在智能交通、城市规划及公共卫生等领域至关重要。现有方法多针对单一任务设计，且在零-shot和少-shot学习中表现不佳。尽管大型语言模型（LLM）在多种任务中展现出卓越的模式识别与推理能力，但其对时空数据的理解受限于对复杂相关性的建模不足。为此，我们提出STD-LLM，旨在通过LLM深入理解时空数据的时空特性，并实现预测与插补的双重任务。STD-LLM借助精心设计的空间与时间标记器及虚拟节点，洞察时空关联。同时，我们引入拓扑感知节点嵌入，助力LLM把握数据拓扑结构。为捕捉更复杂的非成对及高阶相关性，我们还设计了超图学习模块，以提升性能与效率。实验证明，STD-LLM在各类数据集的预测与插补任务中表现出色，且在少-shot与零-shot学习中亦有亮眼表现。
[Arxiv](https://arxiv.org/abs/2407.09096)
==========
# Lomics：借助大型语言模型，我们生成通路和基因集，以助力转录组分析的深入探索。
发布时间：2024年07月12日
`LLM应用` `生物信息学` `转录组分析`
> Lomics: Generation of Pathways and Gene Sets using Large Language Models for Transcriptomic Analysis
# 摘要
> 生物途径的探究是omics数据分析的核心。借助大型语言模型（LLMs），我们能定制针对特定科学问题的生物途径和基因集，这些定制集远小于传统途径富集库，有效减少多重假设检验，提升统计效力。Lomics v1.0，一款基于Python的生物信息学工具，优化了转录组分析中的途径与基因集生成流程，通过三步操作：根据研究问题推导途径、生成有效基因集、输出.GMX文件，并附带途径选择解释。通过迭代、格式验证及基因符号核对，确保结果的准确与一致。Lomics不仅为LLMs在omics研究中的应用打下基础，更可能提升途径分析的精准与效率。
[Arxiv](https://arxiv.org/abs/2407.09089)
==========
# 开放词汇多标签视频分类技术
发布时间：2024年07月12日
`LLM应用` `计算机视觉` `视频处理`
> Open Vocabulary Multi-Label Video Classification
# 摘要
> 预训练的视觉-语言模型（VLMs）在图像分类、目标检测等开放词汇计算机视觉任务中取得了显著进展。近期研究还将VLMs应用于视频中的开放词汇单标签动作分类。然而，在需要同时识别视频中多个动作和实体的全面视频理解方面，现有方法尚显不足。为此，我们提出了开放词汇多标签视频分类问题，并设计了一种方法，使预训练的VLM（如CLIP）能够适应这一挑战。我们借助大型语言模型（LLMs）为VLM提供类别标签的语义指导，以提升其开放词汇性能。具体来说，我们设计了一种端到端架构，引导LLM生成软属性，帮助CLIP文本编码器识别新类别；同时，我们为CLIP视觉编码器引入了时间建模模块，有效捕捉视频概念的时空动态，并通过一种新颖的正则化微调技术，确保视频领域中卓越的开放词汇分类性能。实验结果表明，我们的方法在多个基准数据集上表现出色。
[Arxiv](https://arxiv.org/abs/2407.09073)
==========
# 直接偏好优化的新要求
发布时间：2024年07月12日
`LLM理论` `人工智能` `机器学习`
> New Desiderata for Direct Preference Optimization
# 摘要
> 过去，大型语言模型常借助人类反馈的强化学习（RLHF）来调整输出以符合人类偏好。但RLHF实施中的不稳定性促使近期采用重新参数化技术，避免独立学习奖励模型，而是通过简化训练目标直接优化人类偏好，即直接偏好优化（DPO）。尽管DPO在某些场景中表现出色，我们提出的新评估标准揭示了其在融合预训练模型与人类偏好间的不足，以及在响应质量和约束处理上的权衡。基于这些洞察，我们设计了一种改进的DPO式损失函数，有效缓解了上述问题，并通过实证验证了其优势。
[Arxiv](https://arxiv.org/abs/2407.09072)
==========
# 通过共享潜在变量，结合机器人运动学习与大型语言模型，探讨感觉运动注意与基于语言的回归机制。
发布时间：2024年07月12日
`Agent` `机器人学` `人工智能`
> Sensorimotor Attention and Language-based Regressions in Shared Latent Variables for Integrating Robot Motion Learning and LLM
# 摘要
> 近年来，大型语言模型 (LLM) 与机器人学的结合研究日益活跃，但多数研究忽视了机器人运动生成中的端到端反馈。鉴于深度神经网络预测的固有误差，本研究提出一种创新集成方法，通过共享潜在变量将机器人运动学习模型与 LLM 紧密结合。该方法在生成机器人运动时，根据传感器反馈和任务指令的预测误差动态调整共享参数，从而高效地优化适合特定任务的潜在参数。通过多任务模拟实验，我们的方法在位置泛化和语言指令泛化方面展现了显著优势。
[Arxiv](https://arxiv.org/abs/2407.09044)
==========
# SpreadsheetLLM：将电子表格编码以供大型语言模型使用
发布时间：2024年07月12日
`LLM应用` `电子表格` `人工智能`
> SpreadsheetLLM: Encoding Spreadsheets for Large Language Models
# 摘要
> 电子表格因其复杂的两维网格、多变的布局和丰富的格式选项，对大型语言模型（LLMs）构成了挑战。为此，我们推出了SpreadsheetLLM，采用一种高效编码方法，旨在充分发挥LLMs在电子表格上的理解和推理能力。我们最初尝试了一种简单的序列化方法，结合单元格地址、值和格式，但受限于LLMs的标记限制，实用性有限。为解决这一问题，我们创新性地开发了SheetCompressor框架，通过三个模块——基于结构锚的压缩、逆索引转换和数据格式感知的聚合，有效压缩电子表格，显著提升了表格检测任务的性能，在GPT4的上下文学习设置中，性能比简单方法高出25.6%。此外，经过SheetCompressor微调的LLM，平均压缩比达25倍，F1分数高达78.9%，超越了现有最佳模型12.3%。最后，我们提出了电子表格链（Chain of Spreadsheet），用于电子表格理解和验证的新颖且具有挑战性的电子表格QA任务，系统地利用了电子表格的固有布局和结构，证明了SpreadsheetLLM在各种电子表格任务中的高效性。
[Arxiv](https://arxiv.org/abs/2407.09025)
==========
# 以对象为中心的异常检测面临多重挑战，涉及维度问题及领域知识的关键角色。
发布时间：2024年07月12日
`LLM应用` `业务流程管理` `异常检测`
> Challenges of Anomaly Detection in the Object-Centric Setting: Dimensions and the Role of Domain Knowledge
# 摘要
> 以对象为中心的事件日志能够自然地展现业务流程的执行，如 ERP 和 CRM。然而，这类复杂信息的建模需要创新的过程挖掘技术，并可能产生复杂的约束集合。本文探讨了以对象为中心的异常检测方法，利用对象间的生命周期和交互，无需预设模型即可识别异常模式。同时，我们分析了领域知识在方法中的作用，以及大型语言模型在提供领域知识方面的优势与局限。基于实际 P2P 流程的经验，我们还探讨了算法组合（降维与异常检测）的应用，提出了预处理建议，并讨论了特征传播的重要性。
[Arxiv](https://arxiv.org/abs/2407.09023)
==========
# 利用大型语言模型提升少量样本下的股票趋势预测能力
发布时间：2024年07月12日
`LLM应用`
> Enhancing Few-Shot Stock Trend Prediction with Large Language Models
# 摘要
> 股票趋势预测旨在预见市场未来走向，助力明智投资。传统方法依赖大量标注数据，但人工标注成本高昂且数据难求。借鉴大型语言模型（LLM）的少样本学习能力，我们提出在少样本场景下利用LLM，以缓解标签数据稀缺问题，使预测更贴近投资者需求。过往研究常合并财经新闻进行预测，这给LLM应用带来两大难题：新闻合并带来的噪音和输入限制导致的性能下降。为此，我们创新提出“去噪然后投票”的两步策略：首先引入“无关”类别，对单条新闻进行趋势预测，再通过多数投票整合预测结果。此法两大亮点：一是剔除噪音新闻对预测的干扰，二是规避LLM输入长度限制。实测显示，我们的方法在S&P 500、CSI-100及香港股市预测中准确率分别达66.59%、62.17%和61.17%，较传统少样本方法提升显著，且与顶尖监督方法不相上下。
[Arxiv](https://arxiv.org/abs/2407.09003)
==========
# LLM 在面对文本扰动时的稳健性
发布时间：2024年07月12日
`LLM应用` `数据科学`
> Robustness of LLMs to Perturbations in Text
# 摘要
> 在NLP领域，一个“干净”的数据集常被视为基石。但现实中，规范文本难得一见，这一假设往往站不住脚。近期，大型语言模型（LLMs）虽表现抢眼，却面临现实数据噪声的考验。本研究深入探讨了LLMs对文本形态变异的抗噪能力。我们精心设计，在各类数据集中注入不同噪声，系统检验LLMs的稳健性。结果出人意料，生成型LLMs对文本噪声的抵抗力颇强，与BERT等模型对噪声敏感的表现形成鲜明对比。此外，我们在模拟真实错误的基准测试中，LLMs仅凭少量提示便刷新了GEC和LSC任务的纪录。为推动后续研究，我们公开了人类偏好标注数据集及复现代码，助力学术探索。
[Arxiv](https://arxiv.org/abs/2407.08989)
==========
# 通过基于语法的解释，我们致力于让代码的 LLM 更加可靠和易于理解。
发布时间：2024年07月12日
`LLM应用` `软件开发` `数据科学`
> Towards More Trustworthy and Interpretable LLMs for Code through Syntax-Grounded Explanations
# 摘要
> LLMs的可信度与可解释性紧密相连。模型越透明，其可信度越高。然而，当前解释代码任务中LLM的技术多聚焦于准确性、模型对变化的响应或单任务表现，而非预测时所需的细致解释。为此，我们提出了ASTRust，一种基于模型置信度与编程语言语法结构关系的解释方法。ASTRust利用抽象语法树，在语法类别背景下阐释代码，助力开发者深入理解模型预测，无论是局部代码片段还是全局代码集。通过将置信度分数赋予AST中的常见语法结构，我们的方法超越了传统的令牌级置信度映射，提供了一种与开发者熟悉的编程概念直接对齐的模型置信度视图。实践中，我们开发了自动可视化工具，展示模型置信度分数在语法结构上的叠加，包括序列、热图和图形视觉。通过在精选GitHub仓库上对12个流行LLMs的数据科学研究和人类研究，我们验证了ASTRust的实际效益和有用性。
[Arxiv](https://arxiv.org/abs/2407.08983)
==========
# 借助大型语言模型，我们迈向了章节间上下文感知的文学翻译新境界。
发布时间：2024年07月12日
`LLM应用`
> Towards Chapter-to-Chapter Context-Aware Literary Translation via Large Language Models
# 摘要
> 现有文档级翻译数据集中的语篇现象稀少，成为开发上下文感知机器翻译模型的障碍。多数方法依赖于不切实际的句子级对齐假设。为此，我们策划了包含160本复杂语篇结构的中英文文学数据集，并提出更具挑战性的章节到章节（Ch2Ch）翻译设置，研究常用模型的性能。我们还探索了在Ch2Ch文学翻译领域微调大型语言模型的方法，显著提升了性能。分析表明，Ch2Ch文学翻译在模型学习和解码算法方面均具挑战性。
[Arxiv](https://arxiv.org/abs/2407.08978)
==========
# CompAct：为问答任务主动压缩检索文档
发布时间：2024年07月12日
`RAG` `问答系统` `信息检索`
> CompAct: Compressing Retrieved Documents Actively for Question Answering
# 摘要
> 检索增强生成帮助语言模型通过外部上下文巩固事实基础，但面对海量信息时，模型效能常受挑战。上下文压缩虽能滤除无关信息，但在现实场景中，关键信息难以一蹴而就。为此，我们创新推出CompAct框架，以主动策略精简文档，确保信息不失真。实验显示，CompAct在多跳问答基准上，性能与压缩率双双提升。它如灵活的插件，与各类检索器或阅读器无缝对接，压缩效率高达47倍，成本效益显著。
[Arxiv](https://arxiv.org/abs/2407.09014)
==========
# ICCV23 视觉对话情感解释挑战：SEU_309 团队技术报告
发布时间：2024年07月12日
`RAG` `人工智能`
> ICCV23 Visual-Dialog Emotion Explanation Challenge: SEU_309 Team Technical Report
# 摘要
> 我们通过结合尖端的多模态技术，如语言模型和大型视觉语言模型，在基于视觉对话的情感解释生成挑战中脱颖而出。这一创新方法不仅超越了行业标准，更在ICCV23挑战赛中荣登榜首，成为视觉与语言闭环研讨会（CLCV）的亮点。在F1和BLEU评分上的显著成绩，证明了我们方法在精准捕捉艺术情感方面的非凡实力，深化了我们对艺术情感表达的理解。
[Arxiv](https://arxiv.org/abs/2407.09760)
==========
# 通过多令牌联合推测解码技术，我们旨在加速大型语言模型的推理过程。
发布时间：2024年07月12日
`LLM理论` `人工智能`
> Multi-Token Joint Speculative Decoding for Accelerating Large Language Model Inference
# 摘要
> 基于Transformer的LLM在多任务中展现了强大实力，但其推理过程耗时耗能。推测性解码通过小模型预提令牌，再由大模型批量验证，相比自回归解码，以更少运行次数生成等量令牌，提速1-2倍。然而，贪婪解码在输出质量上并非最优。为追求更高输出质量和效率，我们提出多令牌联合贪婪解码（MJGD），每步基于联合困惑度生成多令牌，提升整体输出质量。但MJGD计算成本过高。为此，我们创新多令牌联合推测性解码（MJSD），通过小模型近似大模型联合分布并验证，结合束解码加速序列生成。MJSD不仅近似MJGD，提升输出质量，还通过联合似然验证，优化令牌前缀选择，增强效率...
[Arxiv](https://arxiv.org/abs/2407.09722)
==========
# GOFA：一款全能型生成模型，专为联合图语言建模设计。
发布时间：2024年07月12日
`LLM应用` `图数据` `人工智能`
> GOFA: A Generative One-For-All Model for Joint Graph Language Modeling
# 摘要
> 基础模型，如LLM和LVM，已成为各自领域的强大工具。然而，图数据的非结构化特性为开发GFM带来了挑战。现有方法要么将图数据转换为语言格式，要么依赖LLM辅助的GNN模型，但无法同时兼顾任务多样性和结构捕捉。本文提出GFM的三个关键属性：自监督预训练、任务适应性和图意识。为此，我们创新性地将语言建模扩展至图领域，并设计了GOFA模型，通过将GNN层与预训练LLM结合，实现了语义与结构的融合。GOFA在图级任务上预训练，并在下游任务上微调，展现了在零-shot场景中解决复杂问题的能力。代码已公开，供研究者参考。
[Arxiv](https://arxiv.org/abs/2407.09709)
==========
# 多语言大型语言模型在不同语言中展现出相似的偏见，宛如一座优雅的桥梁，连接着语言的多样性与偏见的共性。
发布时间：2024年07月12日
`LLM应用` `语言学` `人工智能`
> What an Elegant Bridge: Multilingual LLMs are Biased Similarly in Different Languages
# 摘要
> 本文从语法性别的角度探讨了大型语言模型的偏见。受心理语言学中性别对语言感知影响的启发，我们利用多语种 LLM 重新审视并扩展了 Boroditsky (2003) 的实验。通过引导模型用不同语言的形容词描述名词，特别是那些具有语法性别的语言，我们观察形容词在不同性别和语言中的共现情况，并训练分类器预测语法性别。令人惊讶的是，简单的分类器不仅能准确预测名词性别，还展现出跨语言的适用性。研究表明，尽管 LLM 在不同语言中的描述方式各异，但其偏见却惊人地一致。
[Arxiv](https://arxiv.org/abs/2407.09704)
==========
# 利用大型语言模型整合健康社会决定因素数据：心力衰竭30天再入院预测案例研究
发布时间：2024年07月12日
`LLM应用` `社会科学`
> Large Language Models for Integrating Social Determinant of Health Data: A Case Study on Heart Failure 30-Day Readmission Prediction
# 摘要
> 健康社会决定因素（SDOH）对健康结果有重要影响，但现有模型多仅使用SDOH的代理特征。开放数据倡议提供了构建更全面SDOH视图的机会，但随着数据量和多样性的增加，手动整合相关数据变得更具挑战性。大型语言模型（LLMs）在自动注释结构化数据方面显示出潜力。我们进行了一项端到端研究，评估LLMs整合SDOH数据的可行性及其在临床预测中的实用性。我们首先手动将700多个变量分类到五个SDOH语义类别，然后测试了9个开源LLMs的分类性能。接着，我们训练模型预测心力衰竭患者30天再入院，并比较了SDOH变量与标准临床变量的预测性能。此外，我们研究了少量样本提示对LLM注释性能的影响，并进行了元数据消融研究，以确定哪些信息有助于准确注释。研究发现，某些开源LLMs无需微调即可通过零-shot提示有效注释SDOH变量。当与标准临床特征结合时，LLM注释的邻里和建筑环境子集在预测心力衰竭患者30天再入院方面表现最佳。
[Arxiv](https://arxiv.org/abs/2407.09688)
==========
# 利用 API 文档减轻代码 LLM 的幻觉问题
发布时间：2024年07月12日
`LLM应用` `软件工程` `人工智能`
> On Mitigating Code LLM Hallucinations with API Documentation
# 摘要
> 本研究聚焦于软件工程中的API幻觉问题，并推出了CloudAPIBench基准，用于量化API幻觉现象。该基准还提供了公共领域API频率的详细注释，助力我们在不同频率层面深入探究API幻觉。研究发现，代码LLM在处理低频API时表现不佳，如GPT-4o仅能实现38.58%的有效调用。通过引入文档增强生成（DAG），我们显著提升了低频API的性能至47.94%，但若检索器选择不当，高频API性能会大幅下降39.02%。为此，我们提出智能触发DAG策略，通过API索引或LLM置信度分数进行精准检索，以平衡高低频API性能，最终实现更可靠的API调用，GPT-4o在CloudAPIBench上的性能提升了8.20%。
[Arxiv](https://arxiv.org/abs/2407.09726)
==========
# 探索 LLM 在上下文增强下的投票助理角色：2024 年欧洲议会选举实证研究
发布时间：2024年07月11日
`LLM应用`
> Investigating LLMs as Voting Assistants via Contextual Augmentation: A Case Study on the European Parliament Elections 2024
# 摘要
> 指令微调的大型语言模型在自然语言理解方面表现卓越。针对2024年欧洲议会选举，我们探讨了LLMs作为投票建议应用的可能性，并评估了MISTRAL和MIXTRAL模型的预测准确性。通过RAG和自省技术增强输入上下文，我们发现MIXTRAL平均准确率达82%，而专家信息能进一步提升约9%，这对自动化仍是一大挑战。
[Arxiv](https://arxiv.org/abs/2407.08495)
==========
# GTA：通用工具代理的评测标杆
发布时间：2024年07月11日
`Agent` `人工智能` `软件开发`
> GTA: A Benchmark for General Tool Agents
# 摘要
> 在开发通用代理的过程中，大型语言模型（LLM）与多种工具的整合备受关注，这对LLM的工具使用能力构成了挑战。然而，现有评估与实际应用之间存在显著差距。目前的评估方法多采用AI生成的查询、单一任务、模拟工具及纯文本交互，未能充分展现代理在现实问题解决中的能力。为此，我们推出了GTA基准，专注于三个核心领域：（i）真实用户查询：包含简单现实目标但需隐含工具使用的人类编写查询，要求LLM进行工具选择与解决方案规划。（ii）真实部署工具：一个集成了感知、操作、逻辑和创造力工具的评估平台，用以检验代理的实际任务执行力。（iii）真实多模态输入：包括空间场景、网页截图、表格、代码片段及印刷/手写材料等真实图像文件，作为查询背景，以贴近现实情境。我们设计了229个现实任务及可执行工具链，对主流LLM进行了评估。结果显示，现实用户查询对现有LLM构成挑战，GPT-4完成率不足50%，多数LLM完成率低于25%。此次评估揭示了LLM在实际应用中工具使用能力的局限，为未来通用工具代理的发展指明了方向。相关代码和数据集已公开于https://github.com/open-compass/GTA。
[Arxiv](https://arxiv.org/abs/2407.08713)
==========
# 整合大型语言模型至生产系统，提升任务自动化与灵活性
发布时间：2024年07月11日
`Agent` `制造业` `自动化`
> Incorporating Large Language Models into Production Systems for Enhanced Task Automation and Flexibility
# 摘要
> 本文提出了一种创新方法，将大型语言模型（LLM）代理融入自动化生产系统，以提升任务自动化与灵活性。我们采用基于自动化金字塔的层级框架来组织生产操作，将原子操作功能建模为微服务，并通过专用数字孪生系统进行接口调用执行，从而构建了一个可扩展且灵活的生产流程编排基础。在该数字孪生系统中，硬件特定的低级数据经过语义增强，变得对LLM可解释，用于生产规划与控制。LLM代理系统地解读这些生产特定数据与知识，并在接收到用户请求或触发事件后，生成过程计划，随后分解为一系列原子操作，作为微服务在实际自动化系统中执行。我们在实验室的自动化模块化生产设施上实施了这一方法，通过具体案例展示了LLM在生产规划与控制中的应用，实现了更高级别的任务自动化与灵活性。同时，我们也指出了在自主系统中充分发挥LLM潜力的局限与前景。相关研究演示可访问：https://github.com/YuchenXia/GPT4IndustrialAutomation。
[Arxiv](https://arxiv.org/abs/2407.08550)
==========
# 融合范式：符号与连接主义 AI 在 LLM 赋能自主代理中的协同效应
发布时间：2024年07月11日
`LLM理论` `人工智能` `语言模型`
> Converging Paradigms: The Synergy of Symbolic and Connectionist AI in LLM-Empowered Autonomous Agents
# 摘要
> 本文深入探讨了连接主义与符号AI的融合历程，从早期的理论辩论到现今的技术突破。传统上，连接主义AI侧重于神经网络的构建，而符号AI则强调符号与逻辑的运用。随着ChatGPT和GPT-4等大型语言模型的兴起，连接主义架构在处理语言符号方面展现出巨大潜力。研究指出，由LLM驱动的自主代理（LAAs）正是这一融合趋势的体现。LAAs通过LLM进行文本知识建模，巧妙融合了神经与符号AI的精髓，显著提升了推理与决策能力。与知识图谱相比，LAAs在模拟人类推理、高效处理大数据集及无需重训练即可利用上下文信息方面展现出独特优势。研究还揭示了神经向量符号集成、指令编码及隐式推理等领域的广阔前景，旨在持续强化LAA的性能。通过梳理神经符号AI的发展脉络并展望未来研究方向，本文为AI技术的深化与拓展提供了宝贵见解。
[Arxiv](https://arxiv.org/abs/2407.08516)
==========
# 探究大型语言模型在遵循规则方面的表现，超越了简单的指令执行。
发布时间：2024年07月11日
`LLM应用` `人工智能` `软件开发`
> Beyond Instruction Following: Evaluating Rule Following of Large Language Models
# 摘要
> 尽管 LLMs 在遵循指令方面表现出色，但在现实应用中，它们还需通过规则来确保安全和响应的准确性。然而，目前对 LLMs 规则遵循能力的评估尚不充分，且未能明确区分规则与指令遵循的场景。为此，本文首先明确了规则遵循的概念，并创建了全面基准 RuleBench，以评估 LLMs 在多种规则遵循任务中的表现。实验表明，LLMs 在规则遵循方面仍有提升空间。我们的深入分析为 LLMs 向更优秀的规则遵循智能代理的改进提供了方向。相关数据和代码已公开，详情请访问：https://anonymous.4open.science/r/llm-rule-following-B3E3/
[Arxiv](https://arxiv.org/abs/2407.08440)
==========
# PrefCLM：利用众包大型语言模型提升基于偏好的强化学习效果
发布时间：2024年07月11日
`LLM应用` `机器人` `人机交互`
> PrefCLM: Enhancing Preference-based Reinforcement Learning with Crowdsourced Large Language Models
# 摘要
> 基于偏好的强化学习（PbRL）正成为一种通过人类比较反馈教授机器人的创新方法，避免了复杂的奖励设计。然而，现有方法对大量反馈的依赖往往转向脚本教师生成的合成反馈，这再次需要精细的奖励设计，并难以适应人类-机器人交互（HRI）中用户对任务的独特期望。为此，我们提出了PrefCLM框架，利用众包大型语言模型（LLMs）作为模拟教师，通过Dempster-Shafer理论融合多个LLM代理的偏好，有效整合多样性与集体智慧。同时，我们设计了包含人在回路的流程，以用户交互反馈为基础进行集体优化。实验表明，PrefCLM在通用RL任务中与传统脚本教师相比表现优异，并能促进更自然高效的行为。一项实际用户研究（N=10）进一步验证了其根据用户个性化需求定制机器人行为的能力，显著提升了HRI场景中的用户满意度。
[Arxiv](https://arxiv.org/abs/2407.08213)
==========
# SEED-Story：利用大型语言模型创作多模态长篇故事
发布时间：2024年07月11日
`LLM应用` `媒体与娱乐`
> SEED-Story: Multimodal Long Story Generation with Large Language Model
# 摘要
> 随着图像与文本生成技术的飞速发展，交错式图像-文本内容的创作正变得愈发引人入胜。多模态故事生成，即以交错方式融合叙事文本与生动图像，已成为一项极具价值且实用的任务，应用前景广阔。然而，这一任务极具挑战性，因为它要求深刻理解文本与图像间的复杂互动，并能生成连贯且上下文相关的大量文本与视觉内容。为此，我们推出了SEED-Story，一种基于多模态大型语言模型（MLLM）的创新方法，旨在生成丰富的多模态故事。我们的模型依托MLLM的深厚理解力，不仅能预测文本元素，还能生成视觉元素，再通过特制的视觉去标记器，产出风格与角色一致的图像。此外，我们引入了多模态注意力下沉机制，使得模型能以高效的自回归方式，生成多达25个序列的故事（训练中仅用10个序列）。同时，我们还发布了大规模高分辨率数据集StoryStream，用于模型的训练与多模态故事生成任务的全面定量评估。
[Arxiv](https://arxiv.org/abs/2407.08683)
==========
# 图像-文本表示中涌现的视觉-语义层次结构
发布时间：2024年07月11日
`LLM应用` `计算机视觉`
> Emergent Visual-Semantic Hierarchies in Image-Text Representations
# 摘要
> 尽管如CLIP这样的视觉与语言模型在分析文本和图像方面表现出色，但它们并未明确考虑描述图像的文本集合的分层结构。相反，传统多模态分层学习方法需从零开始训练，未能利用现有先进模型的知识。我们研究发现，这些模型虽未专门训练，却能自发理解视觉-语义层次。为此，我们提出径向嵌入框架，并创建HierarCaps数据集，助力分层知识研究。实验表明，基础模型在无需专门训练的情况下，其分层理解能力超越了传统模型。此外，通过仅文本微调，这些模型能更好地适应分层推理，同时保留预训练知识。
[Arxiv](https://arxiv.org/abs/2407.08521)
==========
# DenseFusion-1M：汇聚视觉专家之力，打造全面多模态感知新境界
发布时间：2024年07月11日
`LLM应用` `计算机视觉` `人工智能`
> DenseFusion-1M: Merging Vision Experts for Comprehensive Multimodal Perception
# 摘要
> 多模态大型语言模型 (MLLMs) 正日益注重对复杂视觉元素的深入理解，包括多对象、文本信息及空间关系。这些模型的全面视觉感知能力，依赖于提供多样化视觉元素和详尽图像描述的高质量图像-文本数据集。然而，这类超详细数据集的稀缺，成为 MLLM 领域发展的瓶颈。问题在于现有字幕引擎的感知能力不足，无法提供完整准确的注释。为此，我们提出“感知融合”方案，采用低成本高效能的字幕引擎，实现完整准确的图像描述。该方案整合了多元感知专家的图像先验信息，并利用高效 MLLM 核心，模拟高级 MLLMs 的感知能力。我们从 LAION 数据集中精选了 100 万张代表性图像，通过我们的引擎生成密集描述，命名为 DenseFusion-1M。实验证明，我们的引擎性能卓越，生成的数据集大幅提升了 MLLMs 在多样视觉语言任务中的感知与认知能力，尤其在高分辨率图像输入时表现突出。相关数据集与代码已公开，详见 https://github.com/baaivision/DenseFusion。
[Arxiv](https://arxiv.org/abs/2407.08303)
==========
# GeNet：一款基于多模态大型语言模型的网络拓扑与配置辅助工具
发布时间：2024年07月11日
`Agent` `企业通信` `网络工程`
> GeNet: A Multimodal LLM-Based Co-Pilot for Network Topology and Configuration
# 摘要
> 传统的企业通信网络工程既复杂又耗时，且易出错。尽管网络工程自动化研究多聚焦于配置合成，却常忽略物理拓扑的变动。本文推出的GeNet，作为企业网络工程师的得力助手，采用多模态技术，借助大型语言模型精简网络设计流程。它通过视觉与文本双模态，根据用户意图智能解读并调整网络拓扑与设备配置。在思科认证练习改编的场景测试中，GeNet展现了其精准解析网络拓扑图的能力，有望大幅减轻工程师负担，提速网络设计。同时，我们也强调了在处理拓扑变更需求时，精准拓扑理解的关键性。
[Arxiv](https://arxiv.org/abs/2407.08249)
==========
# 通过组织学图像预测空间基因表达，我们采用了多模态对比学习方法。
发布时间：2024年07月11日
`LLM应用` `生物技术`
> Multimodal contrastive learning for spatial gene expression prediction using histology images
# 摘要
> 近年来，空间转录组学技术为探索复杂生物系统中的基因表达模式开辟了新天地。然而，高昂的成本限制了其在大型研究中的应用。为此，我们提出了一种经济高效的方案：利用人工智能，通过H&E染色的全切片图像预测基因表达。本文中，我们引入了**mclSTExp**，一种结合Transformer和Densenet-121编码器的多模态对比学习方法，用于精准预测空间转录组表达。我们将每个点比作“单词”，通过Transformer的自注意力机制，巧妙融合其内在特征与空间环境。通过对比学习，进一步强化了图像特征的整合，大幅提升了预测准确性。在乳腺癌和皮肤鳞状细胞癌数据集上的测试表明，mclSTExp不仅在基因表达预测上表现卓越，还能深入解析癌症特异性基因、免疫相关基因，并精准识别由专家注释的特定空间区域。源代码已公开，供研究者参考使用。
[Arxiv](https://arxiv.org/abs/2407.08216)
==========
# SoupLM：融合大型语言与多模态模型中的模型集成技术
发布时间：2024年07月11日
`LLM理论` `人工智能` `多模态学习`
> SoupLM: Model Integration in Large Language and Multi-Modal Models
# 摘要
> 训练大型语言模型和多模态模型需要庞大的计算资源，而现有的公开模型通常在多样化的私人精选数据集上进行预训练。例如，LLaMA、Vicuna 和 LLaVA 这三种模型，虽然都基于 LLaMA 基础模型，但采用了截然不同的训练方法、任务和数据模态。随着这些变体的训练成本和复杂性迅速增加，我们提出了一种经济高效的“汤策略”，将这些变体融合成一个泛化能力强的多模态模型 SoupLM。通过这种策略，我们可以将不同领域和数据模态的知识和专长整合起来，避免重复训练的计算成本。此外，我们还提出了一系列策略，系统地评估不同配置下的性能提升，并探索在插值空间中基础模型间的汤行为。
[Arxiv](https://arxiv.org/abs/2407.08196)
==========
# MAVIS：数学视觉指令的微调
发布时间：2024年07月11日
`LLM应用` `人工智能`
> MAVIS: Mathematical Visual Instruction Tuning
# 摘要
> 多模态大型语言模型 (MLLMs) 近期备受学术界与工业界瞩目。虽然它们在多模态场景中表现卓越，但在视觉环境下的数学解题能力仍有待深入探索。我们指出了 MLLMs 需改进的三大关键领域：数学图表的视觉编码、图表与语言的精准对齐以及数学推理技能的提升。这促使我们迫切需要大规模、高质量的视觉数学数据集及训练流程。本文中，我们首创了 MAVIS，首个针对 MLLMs 的数学视觉指令调优框架，涵盖一系列数学视觉数据集与定制 MLLMs。MAVIS 针对上述三大问题，设计了三个递进的训练阶段。首先，通过 558K 图表-标题对组成的 MAVIS-Caption，利用对比学习微调专为数学设计的视觉编码器 CLIP-Math，优化图表视觉编码。其次，借助 MAVIS-Caption，通过投影层实现 CLIP-Math 与大型语言模型的对齐，强化数学领域的视觉-语言融合。最后，引入包含 900K 精心收集与标注的视觉数学问题的 MAVIS-Instruct，通过此数据集最终调优 MLLM，以培养其强大的数学推理能力。在 MAVIS-Instruct 中，我们为每个问题嵌入了完整的思维链推理，并精简文本冗余，使模型更专注于视觉信息。相关数据与模型已公开于 https://github.com/ZrrSkywalker/MAVIS。
[Arxiv](https://arxiv.org/abs/2407.08739)
==========
# 大型语言模型在实时异常检测与反应性规划中的应用
发布时间：2024年07月11日
`LLM应用` `机器人` `自动驾驶`
> Real-Time Anomaly Detection and Reactive Planning with Large Language Models
# 摘要
> 基础模型，如大型语言模型 (LLM)，在海量互联网数据上训练，具备零-shot 泛化能力，有望检测并缓解机器人系统的异常行为。但要充分发挥其潜力，需克服两大难题：一是降低其高昂的计算成本，以便实时应用；二是将其对异常的判断融入安全控制框架。为此，我们设计了一个两阶段推理框架：首阶段是快速异常检测器，在 LLM 嵌入空间中分析数据，一旦发现异常，即启动次阶段的慢速回退机制，利用生成 LLM 的深度推理能力。这一设计确保了模型预测控制策略的灵活性与安全性，即便在异常检测后也能维持多重回退方案的可行性。实验表明，我们的快速异常检测器性能超越了顶尖 GPT 模型的自回归推理，即使在小型语言模型上也能实现。这使得我们的实时监控系统在资源与时间受限的情况下，仍能提升如四旋翼无人机或自动驾驶汽车等动态机器人系统的可靠性。相关模拟与实测视频已发布于项目页面：https://sites.google.com/view/aesop-llm。
[Arxiv](https://arxiv.org/abs/2407.08735)
==========
# 你的模型是否真的擅长数学推理？通过检查清单来评估其数学推理能力。
发布时间：2024年07月11日
`LLM应用` `人工智能`
> Is Your Model Really A Good Math Reasoner? Evaluating Mathematical Reasoning with Checklist
# 摘要
> 大型语言模型（LLM）的卓越数学推理能力是其核心优势之一。然而，如何全面评估这些能力，并在实际应用中体现用户体验，成为了一个亟待解决的问题。当前的评估标准过于侧重问题解决，可能导致模型过拟合，无法真实反映其数学推理水平。为此，我们提出了MATHCHECK，一个专为测试任务泛化和推理鲁棒性设计的检查清单，以及一个高效的自动生成工具。MATHCHECK涵盖多种数学推理任务和鲁棒性测试，旨在全面评估模型的数学推理能力和行为表现。我们基于MATHCHECK开发了MATHCHECK-GSM和MATHCHECK-GEO，分别针对数学文本和多模态推理进行评估，是对现有基准如GSM8k、GeoQA等的升级。通过这些工具，我们评估了超过20个LLM和11个MLLM的综合数学推理能力。结果显示，尽管如GPT-4o等前沿模型在多项测试中表现出色，但其他模型家族的表现则显著下滑。进一步实验证明，MATHCHECK相比传统基准更能准确反映模型的真实数学能力，并更线性地展现数学智能，验证了我们的设计理念。借助MATHCHECK，我们能够深入进行模型行为分析，全面探究其数学推理能力。
[Arxiv](https://arxiv.org/abs/2407.08733)
==========
# 大型语言模型数据污染的分类体系
发布时间：2024年07月11日
`LLM理论` `人工智能` `数据安全`
> A Taxonomy for Data Contamination in Large Language Models
# 摘要
> 大型语言模型在广泛网络语料库上的预训练表现出色，但数据污染问题日益凸显。评估数据集可能被预训练语料库包含，导致性能虚高。去污染虽是解决方案，但污染物可能变形逃逸检测。我们分类了预训练中的污染类型，并评估其风险。此外，我们深入分析了污染对摘要和问答任务的影响，揭示了污染如何左右评估结果。
[Arxiv](https://arxiv.org/abs/2407.08716)
==========
# HiRes-LLaVA：修复高分辨率视觉-语言模型中的碎片输入
发布时间：2024年07月11日
`LLM应用` `计算机视觉` `文档处理`
> HiRes-LLaVA: Restoring Fragmentation Input in High-Resolution Large Vision-Language Models
# 摘要
> 高分辨率输入让大型视觉-语言模型（LVLMs）能捕捉更细腻的视觉细节，提升理解力。为减少高分辨率输入带来的高昂训练和计算成本，我们采用滑动窗口将输入分割成统一块，每个块匹配已训练视觉编码器的输入尺寸。然而，这种分割方法导致原始输入的碎片化，即上下文连续性和空间几何在块间断裂，影响跨块上下文感知和定位任务。为此，我们设计了HiRes-LLaVA框架，它能高效处理任意大小的高分辨率输入，同时保持原始上下文和几何信息不变。HiRes-LLaVA包含两大创新组件：SliceRestore适配器将分割块还原为原始形态，通过下-上采样和卷积层高效提取全局与局部特征；Self-Mining采样器则基于自身压缩视觉令牌，保留原始上下文和位置信息，降低训练负担。我们构建了EntityGrid-QA基准，涵盖边缘和位置相关任务，以评估上下文碎片化处理能力。实验显示，HiRes-LLaVA在现有基准和EntityGrid-QA上均表现卓越，尤其在文档处理任务上，为高分辨率输入处理设定了新标杆。
[Arxiv](https://arxiv.org/abs/2407.08706)
==========
# Live2Diff：利用视频扩散模型中的单向注意力技术，实现直播流的实时翻译。
发布时间：2024年07月11日
`LLM应用` `视频处理` `实时翻译`
> Live2Diff: Live Stream Translation via Uni-directional Attention in Video Diffusion Models
# 摘要
> 大型语言模型凭借其单向时间注意力机制，在生成文本和音频等流数据方面表现出色。然而，视频流处理领域仍有待深入探索，尤其是在实时视频处理需求日益增长的背景下。现有的视频扩散模型采用双向时间注意力，这限制了它们处理流视频的能力。为此，我们创新性地提出了Live2Diff模型，该模型采用单向时间注意力，专门针对实时视频翻译设计。我们的方法通过关联当前帧与历史帧及初始帧，确保了视频翻译的时间一致性和平滑性，无需依赖未来帧。同时，我们引入了高效的降噪技术，结合KV-缓存和流水线处理，实现了高帧率下的实时视频翻译。实验结果显示，我们的方法在时间平滑性和效率方面均优于现有技术。
[Arxiv](https://arxiv.org/abs/2407.08701)
==========
# 利用模型合并策略，有效缓解语言迁移过程中的灾难性遗忘问题。
发布时间：2024年07月11日
`LLM应用` `语言处理` `机器学习`
> Mitigating Catastrophic Forgetting in Language Transfer via Model Merging
# 摘要
> 随着LLM在英语任务中的表现日益卓越，业界希望将这些模型应用于其他语言。然而，语言适应过程中常伴随着对原模型能力的严重遗忘，降低了新模型的实用性。为此，我们提出了Branch-and-Merge（BaM）方法，通过迭代合并多个微调模型来优化适应过程，确保权重变化虽小但质量更高，从而减少对源领域的遗忘并维持对目标领域的学习效果。实证研究表明，BaM不仅有效减少了遗忘现象，还在保加利亚语和德语等语言中，与传统预训练和微调方法相比，实现了目标领域性能的匹配甚至提升。
[Arxiv](https://arxiv.org/abs/2407.08699)
==========
# 云图：结合语言模型与因果洞察，实现云系统故障的精准定位。
发布时间：2024年07月11日
`LLM应用` `云计算` `故障诊断`
> Cloud Atlas: Efficient Fault Localization for Cloud Systems using Language Models and Causal Insight
# 摘要
> 在现代云系统中，运行时故障和性能下降屡见不鲜。云服务提供商急需自动定位故障根源，以确保系统的高可靠性和可用性。近期研究提出使用因果图进行因果推理，以揭示性能指标间的关联。然而，构建准确的因果图既耗时又具挑战性，尤其在大规模动态系统中，且需专业知识。同时，数据驱动方法因事件罕见而效果有限。为此，我们推出Atlas，一种自动合成因果图的新方法。Atlas借助大型语言模型，整合系统文档、遥测及部署反馈，生成因果图。它与数据驱动技术相辅相成，并通过数据验证进一步强化。实证表明，Atlas在多种故障定位场景中表现卓越，生成的因果图不仅可扩展且泛化性强，性能远超传统算法，与真实基准相媲美。
[Arxiv](https://arxiv.org/abs/2407.08694)
==========
# 机器人控制：基于具身思维链的智能推理
发布时间：2024年07月11日
`Agent` `机器人学` `人工智能`
> Robotic Control via Embodied Chain-of-Thought Reasoning
# 摘要
> 学习型机器人控制策略面临的一大挑战是难以泛化至训练数据之外。近期，视觉-语言-动作模型（VLAs）的研究显示，采用互联网预训练的大型视觉-语言模型作为核心，能大幅提升策略的鲁棒性与泛化力。然而，大型视觉-语言模型在其他领域的一大亮点——迭代解决复杂问题的能力，能否应用于机器人学，让策略在执行前通过任务推理提升性能？由于标准VLAs训练示例相对简单，直接采用“思维链”（CoT）式提示效果不佳。此外，常规CoT中对子任务的纯语义推理，对于需基于感官与状态进行推理的机器人策略而言，并不充分。为此，我们提出了具身思维链推理（ECoT），训练VLAs在行动前对计划、子任务、运动及视觉基础特征（如物体边界框与末端执行器位置）进行多步推理。我们设计了可扩展的流水线，为ECoT在大规模机器人数据集上生成合成训练数据。实验表明，ECoT在不增加额外训练数据的情况下，将最强开源VLA策略OpenVLA在泛化任务中的成功率提升了28%。同时，ECoT也便于人类理解策略失败原因，并使用自然语言进行行为修正。
[Arxiv](https://arxiv.org/abs/2407.08693)
==========
# 在医学问答领域，大型语言模型的不确定性评估
发布时间：2024年07月11日
`LLM应用` `生物医学`
> Uncertainty Estimation of Large Language Models in Medical Question Answering
# 摘要
> 在医疗领域，大型语言模型（LLM）虽在自然语言生成方面潜力巨大，但亦有生成事实错误之风险。为此，医疗问答应用中的LLM部署亟需可靠的不确定性估计（UE）方法以识别幻觉现象。本研究针对不同规模的模型，在医疗问答数据集上对主流UE方法进行了基准测试。结果表明，现有方法在此领域表现普遍欠佳，凸显了医疗应用中UE的挑战性。同时，我们发现模型规模与UE可靠性存在正相关。为应对这些挑战，我们创新性地提出了“两阶段验证”这一无概率UE方法。该方法首先要求LLM在给出答案的同时，提供详尽的推理过程，并据此设计验证问题以核实事实准确性。模型需独立及参照推理过程各回答一次，通过对比两次答案的不一致性来评估原始答案的不确定性。在三个生物医学问答数据集上，我们采用Llama 2 Chat模型对本方法进行了评估，并与基准方法进行了对比。结果表明，“两阶段验证”方法在各类数据集及模型规模下均展现出卓越的整体准确性与稳定性，且其性能随模型规模的扩大而增强。
[Arxiv](https://arxiv.org/abs/2407.08662)
==========
# 探索通过系统1与系统2的融合，打造专才与通才兼备的AI之路
发布时间：2024年07月11日
`LLM理论` `人工智能` `通用人工智能`
> Towards Building Specialized Generalist AI with System 1 and System 2 Fusion
# 摘要
> 本文引入了专业通才型人工智能（SGAI 或 SGI）的概念，作为迈向通用人工智能（AGI）的重要步骤。SGI 不仅在特定任务上超越人类专家，还保持了通用能力，这种融合路径使其快速进入高价值领域。我们将其发展分为三个阶段，并探讨了 SGI 在解决大型语言模型问题中的必要性。此外，我们提出一个整合系统 1 和系统 2 认知优势的开发框架，包含三个层次和四个关键部分，旨在提升个人能力并促进协同进化。最后，我们概述了潜在挑战并展望未来方向，期待 SGI 为 AGI 的研究和应用提供新视角。
[Arxiv](https://arxiv.org/abs/2407.08642)
==========
# 动态 $β$ 直接偏好优化（$β$-DPO）
发布时间：2024年07月11日
`LLM理论` `人工智能` `数据科学`
> $β$-DPO: Direct Preference Optimization with Dynamic $β$
# 摘要
> Direct Preference Optimization (DPO) 已成为训练大型语言模型 (LLM) 遵循人类偏好的有力方法。但 DPO 性能对 $β$ 参数的微调和数据质量极为敏感。我们研究发现，最佳 $β$ 值因数据信息量而异。为此，我们提出动态调整 $β$ 的新框架，并结合 $β$ 引导的数据过滤，有效提升 DPO 性能，增强模型对人类反馈的适应性。实证显示，该技术在多模型和数据集上表现卓越。代码已公开，详见 \url{https://github.com/junkangwu/beta-DPO}。
[Arxiv](https://arxiv.org/abs/2407.08639)
==========
# RoboMorph：借助大型语言模型，探索机器人形态的进化之路
发布时间：2024年07月11日
`LLM应用` `机器人` `自动化设计`
> RoboMorph: Evolving Robot Morphology using Large Language Models
# 摘要
> 我们推出了 RoboMorph，一种结合大型语言模型和进化算法，自动生成并优化模块化机器人设计的创新方法。在此框架下，每个机器人设计被视为一种语法，借助 LLM 的力量，我们能够高效探索传统方法难以企及的广阔设计领域。通过融合自动提示设计和强化学习控制算法，RoboMorph 通过迭代反馈不断精进设计。实验证明，RoboMorph 不仅能创造出适应特定地形的复杂机器人，还能在连续进化中优化其形态。这一方法不仅展示了 LLM 在机器人设计领域的应用潜力，也为其他拥有相似设计需求的领域提供了可借鉴的路径。
[Arxiv](https://arxiv.org/abs/2407.08626)
==========
# 泰米尔语计算：现状展望与未来趋势
发布时间：2024年07月11日
`LLM应用` `人机交互` `语言学`
> Tamil Language Computing: the Present and the Future
# 摘要
> 本文深入分析了语言计算中的文本处理技术，这些技术使计算机能够理解和生成人类语言。涵盖的任务包括语音识别、机器翻译、情感分析等，语言计算融合了语言学、计算机科学等多个领域，旨在提升人机交互的质量。随着深度学习的发展，计算机在独立学习和适应方面取得了显著进步。本文特别强调了编码技术的进步，例如泰米尔语从ASCII到Unicode的转变，这极大地促进了数字通信。同时，文章讨论了构建有效语言处理所需的计算资源，如数据、词典和语法规则，并指出了语言注释和大型语言模型训练中的挑战。此外，本文强调了开发泰米尔语等语言的实际应用的重要性，以填补现有技术空白，并呼吁加强研究合作和数字化历史文献，以全面推进泰米尔语处理技术的发展，从而增强全球通信和数字服务的普及。
[Arxiv](https://arxiv.org/abs/2407.08618)
==========
# FlashAttention-3：借助异步处理与低精度计算，实现高效且精准的注意力机制。
发布时间：2024年07月11日
`LLM理论` `半导体` `高性能计算`
> FlashAttention-3: Fast and Accurate Attention with Asynchrony and Low-precision
# 摘要
> 注意力机制，作为Transformer架构的核心，已成为大型语言模型和长上下文应用的瓶颈。FlashAttention通过减少内存读写操作，提升了GPU上的注意力计算速度。然而，FlashAttention-2在最新的H100 GPU上仅达到35%的利用率，未能充分利用新硬件的潜力。为此，我们研发了三项关键技术，以进一步加速Hopper GPU上的注意力计算：首先，通过张量核心和TMA的异步特性，实现计算与数据移动的重叠；其次，交错执行块状矩阵乘法和softmax操作；最后，利用硬件对FP8低精度的支持，进行块量化和不连贯处理。实验表明，我们的FlashAttention-3方法在H100 GPU上实现了1.5至2.0倍的加速，FP16精度下达到740 TFLOPs/s（75%利用率），FP8精度下接近1.2 PFLOPs/s。此外，FP8 FlashAttention-3相比基准FP8注意力，数值误差降低了2.6倍。
[Arxiv](https://arxiv.org/abs/2407.08608)
==========
# 基于心理指标的回合级共情预测
发布时间：2024年07月11日
`LLM应用` `心理健康` `人工智能`
> Turn-Level Empathy Prediction Using Psychological Indicators
# 摘要
> 在 WASSA 2024 同理心与人格预测任务中，我们创新性地将同理心细分为六个心理维度：情感表达、换位思考、同情心、外向、开放与和善。借助大型语言模型丰富文本，再通过 DeBERTA 微调，我们的方法在同理心检测上大幅提升了相关性和准确度，成效显著。最终，我们的系统在 CONV-turn 赛道中荣获第 7 名。
[Arxiv](https://arxiv.org/abs/2407.08607)
==========
# 数据与多模态大型语言模型的协同效应：协同开发视角的探索
发布时间：2024年07月11日
`LLM应用` `人工智能` `数据科学`
> The Synergy between Data and Multi-Modal Large Language Models: A Survey from Co-Development Perspective
# 摘要
> 近年来，大型语言模型（LLMs）的迅猛发展引人瞩目。多模态LLMs（MLLMs）在此基础上，将应用领域从文本扩展至更广阔的范畴，因其广泛的应用场景而备受关注。LLMs和MLLMs的成功，离不开庞大的模型参数和数据支持，这使得数据的重要性日益凸显。通过追踪近期以数据为核心的MLLMs研究，我们发现模型与数据的发展实则相辅相成。一方面，更丰富、更优质的数据能提升MLLMs的性能；另一方面，MLLMs的发展也能推动数据进步。为了实现多模态数据与MLLMs的协同发展，我们需要明确：在MLLMs的不同发展阶段，如何运用数据中心方法来增强特定能力；以及模型如何通过其能力与角色，为多模态数据的发展贡献力量。为此，我们系统梳理了从数据与模型协同发展视角出发的相关研究，并提供了一个定期更新的项目链接，供MLLM社区参考：https://github.com/modelscope/data-juicer/blob/main/docs/awesome_llm_data.md。
[Arxiv](https://arxiv.org/abs/2407.08583)
==========
# 探索 LLM 内部的真实性普遍性
发布时间：2024年07月11日
`LLM理论` `人工智能` `数据科学`
> On the Universal Truthfulness Hyperplane Inside LLMs
# 摘要
> 尽管 LLM 在多领域表现出色，幻觉问题仍是一大难题。最新研究通过分析内部表征，尝试解读 LLM 对事实的忠实度。但这些方法常难以适应新数据，引发了对内部表征是否真正反映事实意识，还是仅过度适应特定数据集的疑虑。本研究探索模型中是否存在一个普遍的真理超平面，能区分正确与错误输出。我们扩大训练数据集至40多个，全面评估其泛化能力。结果显示，数据集多样性提升显著增强性能，而数据量影响较小。这支持了模型内可能存在普遍真理超平面的乐观假设，为未来研究指明方向。
[Arxiv](https://arxiv.org/abs/2407.08582)
==========
# 探究大型语言模型的职业倾向
发布时间：2024年07月11日
`LLM应用` `人力资源` `职业发展`
> The Career Interests of Large Language Models
# 摘要
> 随着大型语言模型 (LLMs) 能力的显著提升，从简单文本生成到复杂人机交互，探索其作为专业助理的潜力变得尤为重要。本研究模拟人类参与，运用职业兴趣分析工具，考察 LLMs 的潜在职业兴趣与能力，并分析这些兴趣如何随语言和模型发展而变化。通过高级统计方法，我们发现 LLMs 在社会和艺术领域展现出独特兴趣，但这些兴趣与其高能力职业并不匹配。这一创新方法不仅揭示了 LLMs 融入职场的全新视角，也强调了其类人特质，促使我们重新审视 LLMs 在职场中的自我认知与能力匹配。
[Arxiv](https://arxiv.org/abs/2407.08564)
==========
# 民意即AI之声？借助语言模型洞察德国民意
发布时间：2024年07月11日
`LLM应用` `市场研究`
> Vox Populi, Vox AI? Using Language Models to Estimate German Public Opinion
# 摘要
> 随着大型语言模型 (LLM) 的进步，人们开始探讨 LLM 生成的“合成样本”是否能替代传统调查。一些美国研究显示，LLM 模拟的调查响应与实际数据相符。但这种匹配的可推广性受限于目标人群与 LLM 训练数据的关系。本研究探索 LLM 在德国的公众意见预测能力，特别是投票选择。我们使用 GPT-3.5 生成与德国选举研究受访者特征相符的合成样本，并预测其投票选择，发现 GPT-3.5 对绿党和左派有偏见，虽能捕捉典型选民趋势，但未能全面理解影响个体选择的复杂因素。这项研究揭示了 LLM 在公众意见研究中的局限，强调了其应用的挑战。
[Arxiv](https://arxiv.org/abs/2407.08563)
==========
# 利用大型语言模型对解释型恶意软件的 TTPs 进行零-shot 生成研究
发布时间：2024年07月11日
`LLM应用` `软件安全` `人工智能`
> Tactics, Techniques, and Procedures (TTPs) in Interpreted Malware: A Zero-Shot Generation with Large Language Models
# 摘要
> 当前，开源软件生态正面临软件供应链攻击的安全挑战。解释型开源软件恶意代码在供应链攻击中尤为关键，因其为犯罪分子提供了多种手段诱导用户安装并执行恶意行为。本文中，我们借鉴MITRE ATT&CK框架中的战术、技术和程序（TTPs），将其应用于解释型恶意软件分析，以揭示攻击过程的各个阶段。我们创新性地提出了GENTTP方法，利用大型语言模型（LLMs）实现零-shot学习，自动从恶意软件包中提取TTP。该方法以恶意软件包为输入，输出攻击向量的欺骗与执行战术。为验证GENTTP的性能，我们收集了两个数据集：一个标注真实标签，另一个来自实际环境。实验表明，GENTTP能高效准确地生成TTP。此外，我们基于3700多个PyPI恶意软件的TTP，构建了一个基于LLM的聊天机器人，并进行了大规模的TTP定量分析。研究发现：（1）尽管恶意软件数量激增，许多恶意包的TTP仍保持稳定；（2）TTP揭示了恶意攻击的特性；（3）TTP与攻击者的意图紧密相关。
[Arxiv](https://arxiv.org/abs/2407.08532)
==========
# 1500万面部图像与文本多模态数据集
发布时间：2024年07月11日
`LLM应用

解释：这篇论文主要介绍了FaceCaption-15M数据集的开发和应用，这是一个用于面部图像与自然语言描述匹配的大规模数据集。论文中提到的FLIP模型是基于这个数据集训练的预训练模型，用于面部图像与文本的对齐。虽然论文涉及到了多模态深度学习模型，但其核心关注点在于应用层面，即如何利用这些模型和数据集来提升面部相关任务的性能。因此，这篇论文更适合归类于LLM应用，而不是专注于理论探讨或代理技术（Agent）和检索增强生成（RAG）技术。` `人工智能` `面部识别`
> 15M Multimodal Facial Image-Text Dataset
# 摘要
> 当前，图像与文本结合的多模态深度学习模型在多个领域展现出显著潜力，特别是在面部图像相关的任务中，其应用前景广阔。本文推出的 **FaceCaption-15M** 数据集，集大规模、多样性与高质量于一体，为面部图像匹配自然语言描述，旨在推动面部相关任务的研究。该数据集包含超过 1500 万对面部图像与描述，规模空前。通过深入分析图像质量、文本自然度、复杂度及与图像的相关性，FaceCaption-15M 的优越性得以彰显。为验证其效能，我们训练了面部图像与文本对齐的预训练模型 FLIP，并在此基础上，通过图像与文本编码器的协同及线性层的微调，在两项面部任务中刷新了性能纪录。我们公开了所有资源，以期推动面部任务研究的进一步发展。详情请访问：https://huggingface.co/datasets/OpenFace-CQUPT/FaceCaption-15M
[Arxiv](https://arxiv.org/abs/2407.08515)
==========
# Lynx：一款开源的幻觉评估工具
发布时间：2024年07月11日
`LLM应用` `人工智能`
> Lynx: An Open Source Hallucination Evaluation Model
# 摘要
> RAG 技术旨在减少 LLM 中的幻觉现象，但 LLM 仍可能输出与检索内容不符的信息。为此，我们推出了 LYNX，一款尖端的幻觉检测 LLM，能在复杂的现实幻觉情境中进行深度推理。为验证 LYNX 的性能，我们创建了 HaluBench，一个涵盖多领域约 15,000 样本的全面幻觉评估基准。实验表明，LYNX 在 HaluBench 上的表现超越了 GPT-4o、Claude-3-Sonnet 等模型。我们已将 LYNX、HaluBench 及评估代码公开，供公众使用。
[Arxiv](https://arxiv.org/abs/2407.08488)
==========
# 从构建视角深入探讨公共微调数据集的现状与挑战
发布时间：2024年07月11日
`LLM理论` `人工智能` `数据科学`
> Investigating Public Fine-Tuning Datasets: A Complex Review of Current Practices from a Construction Perspective
# 摘要
> 随着大型模型领域的迅猛发展，微调研究也取得了显著进步。本文从数据构建视角，全面回顾了公共微调数据集，探讨了其演变与分类，并详细介绍了构建技术和方法，如数据生成和增强。我们通过抽象出数据生成技术的类别树，助力研究人员深入理解微调数据集的构建维度。此外，本文还总结了当前实践中不同数据准备阶段的构建特征，为未来研究提供全面概览。最后，我们展望了微调数据集的未来构建与发展，提出了深刻见解与思考。
[Arxiv](https://arxiv.org/abs/2407.08475)
==========
# DIDUP：为 UI 原型设计带来动态迭代开发
发布时间：2024年07月11日
`LLM应用` `软件开发` `用户体验`
> DIDUP: Dynamic Iterative Development for UI Prototyping
# 摘要
> 大型语言模型（LLM）在编码方面表现卓越。其中，基于代码的用户界面原型设计是人类与LLM合作的一个亮点，它让用户能全面参与并体验界面。我们研究了GPT Pilot，发现其一旦启动开发便难以适应变化，这在故障预防和动态规划上显得不足，其工作流程类似传统的瀑布模型。为此，我们推出了DIDUP，一个采用迭代螺旋模型的系统，能灵活应对开发中的变化。我们还提出了三项创新机制：适应性规划，让计划随实施动态调整；代码注入，减少重写，帮助用户理解代码演变；轻量级状态管理，简化版本控制，便于用户快速回溯。这些功能共同助力用户高效迭代原型。
[Arxiv](https://arxiv.org/abs/2407.08474)
==========
# 仅凭自然语言远远不够：我们正在为 Verilog 生成任务，对多模态生成 AI 进行基准测试。
发布时间：2024年07月11日
`LLM应用` `硬件设计` `人工智能`
> Natural language is not enough: Benchmarking multi-modal generative AI for Verilog generation
# 摘要
> 自然语言接口在自动生成Verilog方面潜力巨大，但本文指出，视觉表示对于空间复杂的硬件设计至关重要，可能优于纯语言输入。为此，我们推出了一个开源的多模态生成模型基准，专门用于从视觉-语言输入合成Verilog，涵盖简单与复杂模块。同时，我们开发了一个开源的视觉与自然语言Verilog查询框架，以简化多模态查询。通过与仅使用自然语言的方法对比，我们的多模态生成Verilog在准确性上显著提升。我们期待在大规模硬件设计时代，推动硬件设计方法的多样化和高效化。
[Arxiv](https://arxiv.org/abs/2407.08473)
==========
# 模型指引合并时机：为长上下文任务中的LLMs量身定制的KV缓存智能合并策略
发布时间：2024年07月11日
`LLM应用` `计算机科学` `人工智能`
> Model Tells You Where to Merge: Adaptive KV Cache Merging for LLMs on Long-Context Tasks
# 摘要
> 随着大型语言模型（LLMs）在自回归生成中的高计算成本，如何高效服务这些模型变得至关重要。为此，LLMs常采用KV缓存技术提升生成速度，但这也带来了显著的内存需求，尤其是在长上下文场景中。本文提出了一种创新的KV缓存合并方法KVMerger，旨在不牺牲性能的前提下，实现长上下文任务的KV缓存自适应压缩。我们基于观察到单序列内键状态在令牌级别的高度相似性，开发了合并集识别算法，并进一步提出了高斯核加权合并算法。实验证明，KVMerger在受限内存预算下，相比其他技术如H2O和CaM，在Llama2-7B-chat和Llama2-13B-chat等模型上，均实现了更优的性能。
[Arxiv](https://arxiv.org/abs/2407.08454)
==========
# 大型语言模型真的无偏见吗？通过“越狱”提示评估对抗性鲁健对偏见引发的挑战。
发布时间：2024年07月11日
`LLM理论` `人工智能` `社会科学`
> Are Large Language Models Really Bias-Free? Jailbreak Prompts for Assessing Adversarial Robustness to Bias Elicitation
# 摘要
> 大型语言模型（LLM）在人工智能领域展现了惊人的计算与语言能力，但它们也易受训练数据中的多种偏见影响，如选择、语言和确认偏见，以及性别、种族、性取向等刻板印象。本研究深入分析了最新LLM在回答中体现的这些偏见，及其对模型公平性与可靠性的影响。同时，我们探索了如何利用提示工程技术揭示LLM的隐性偏见，并测试其对抗越狱提示的鲁棒性。通过广泛实验，我们发现即便LLM具备高级功能与精密对齐流程，仍可能被诱导产生偏颇或不当回应。因此，强化偏见缓解技术，对于构建更可持续、更包容的人工智能至关重要。
[Arxiv](https://arxiv.org/abs/2407.08441)
==========
# 算术推理中的语言模型自我训练
发布时间：2024年07月11日
`LLM理论` `人工智能` `机器学习`
> Self-training Language Models for Arithmetic Reasoning
# 摘要
> 语言模型在复杂推理任务中表现出色，但通常需要大量标注数据来提升性能。本研究探索了无需新数据，仅通过自动反馈验证预测有效性（自我训练）来提升模型能力的方法。实验表明，无论是在单轮（离线）还是在线自我训练中，模型均有显著进步。离线时，监督方法与偏好优化效果相当；而在线自我训练中，偏好优化因其对新问题的稳定性和鲁棒性，远超监督训练。
[Arxiv](https://arxiv.org/abs/2407.08400)
==========
# 探讨大型语言模型的信心归属问题
发布时间：2024年07月11日
`LLM理论` `人工智能`
> On the attribution of confidence to large language models
# 摘要
> 在LLM评估的实证研究中，对LLM的信念归属颇为常见，但其理论基础尚不明朗。我们提出三点论断：首先，从语义角度看，LLM信念归属应被理解为科学家对LLM信念事实的真实信念表达；其次，从形而上学角度，LLM信念的存在虽证据不足，但至少是合理的；最后，从认识论角度，实证文献中的LLM信念归属面临实质性的怀疑，因为评估LLM信念的实验方法可能并不准确，导致这些归属可能普遍失真。
[Arxiv](https://arxiv.org/abs/2407.08388)
==========
# Skywork-Math：探究大型语言模型中数学推理的数据缩放规律，故事仍在继续。
发布时间：2024年07月11日
`LLM应用` `人工智能`
> Skywork-Math: Data Scaling Laws for Mathematical Reasoning in Large Language Models -- The Story Goes On
# 摘要
> 本文深入探讨了提升大型语言模型（LLM）数学推理能力的潜在因素。我们指出，现代LLM的数学推理能力数据缩放规律远未饱和，突显了数据量增加对模型质量的积极影响。为此，我们推出了Skywork-Math模型系列，该系列在7B LLM上利用2.5M实例的Skywork-MathQA数据集进行监督微调（SFT）。Skywork-Math 7B在MATH基准测试中取得了51.2%的准确率，在GSM8K基准测试中达到了83.9%，超越了早期GPT-4在MATH上的表现。这一成就得益于我们创新的两阶段数据合成与模型SFT流程，涵盖三种增强方法及多样化的种子问题集，确保了Skywork-MathQA数据集在各难度级别上的高质量与丰富性。此外，我们还提供了实用的建议，以提升LLM在数学推理方面的能力，适用于研究和工业领域。
[Arxiv](https://arxiv.org/abs/2407.08348)
==========
# 探索大型语言模型在可解释进化策略中的应用
发布时间：2024年07月11日
`LLM应用` `优化算法` `人工智能`
> Towards Explainable Evolution Strategies with Large Language Models
# 摘要
> 本文通过结合自适应进化策略 (ES) 和大型语言模型 (LLM)，提出了一种增强复杂优化过程可解释性的方法。我们利用带有重启机制的自适应 ES，成功探索了基准函数的复杂领域，并记录了优化过程中的关键细节。随后，LLM 处理这些日志，生成简洁易懂的总结，突出了收敛行为、最佳适应度及局部最优等关键点。针对 Rastrigin 函数的案例研究显示，我们的方法使 ES 优化的复杂性变得透明且易于理解。这一研究强调了 LLM 在提升高级优化算法可解释性方面的潜力。
[Arxiv](https://arxiv.org/abs/2407.08331)
==========
# 借助 GPT 技术，我们致力于生成跨平台的社交媒体数据集，以支持广泛的研究工作。
发布时间：2024年07月11日
`LLM应用` `社交媒体` `数据分析`
> Leveraging GPT for the Generation of Multi-Platform Social Media Datasets for Research
# 摘要
> 社交媒体数据集对研究虚假信息、影响力操作等关键议题至关重要，但受限于成本和平台规定，获取跨平台数据集颇具挑战。本文探索了大型语言模型在多平台上创建高质量社交媒体数据集的潜力。我们利用ChatGPT从两个真实数据集生成合成数据，并评估其词汇和语义属性。实证研究表明，大型语言模型在生成多平台社交媒体数据方面前景广阔，但仍需进一步优化以提升数据质量。
[Arxiv](https://arxiv.org/abs/2407.08323)
==========
# Q-GaLore：结合 INT4 投影与层适应低秩梯度的量化 GaLore技术
发布时间：2024年07月11日
`LLM理论` `计算机科学` `人工智能`
> Q-GaLore: Quantized GaLore with INT4 Projection and Layer-Adaptive Low-Rank Gradients
# 摘要
> 训练大型语言模型因大量参数和优化状态而内存密集。新方法 GaLore 通过将权重梯度投影到低秩子空间来减少内存使用，但依赖耗时的 SVD 操作且频繁更新导致训练时间开销大。与 LoRA 相比，GaLore 在准确性和效率上的改进有限。为此，我们提出 Q-Galore，结合量化和低秩投影，显著减少内存使用，超越 GaLore。基于两个关键观察：梯度子空间多样性及投影矩阵对低比特量化的弹性，Q-Galore 自适应更新梯度子空间，减少 SVD 操作，保持投影矩阵在 INT4 格式，权重在 INT8 格式，结合随机舍入捕捉梯度信息，实现高精度训练。在预训练中，Q-Galore 使 LLaMA-7B 模型能在单个 NVIDIA RTX 4060 Ti 上从头开始训练，仅需 16 GB 内存。在微调中，与 LoRA 和 GaLore 相比，内存消耗减少高达 50%，且在相同内存成本下始终优于 QLoRA。
[Arxiv](https://arxiv.org/abs/2407.08296)
==========
# 在资源有限的环境下，持续探索将视觉概念与大型语言模型相连接的学习之道。
发布时间：2024年07月11日
`LLM应用` `嵌入式设备` `计算机视觉`
> Continually Learn to Map Visual Concepts to Large Language Models in Resource-constrained Environments
# 摘要
> 在深度学习领域，从非独立同分布数据流中持续学习是一大难题，尤其在资源受限的嵌入式设备中更为严峻。传统的视觉模型通过监督学习更新时，常面临过拟合、灾难性遗忘和偏见表示的问题。相比之下，大型语言模型因其包含的多概念及其关系，能促进更稳健的学习过程。本研究提出持续视觉映射（CVM），通过将视觉表示与固定语言模型提取的知识空间对接，不断训练小而高效的视觉模型。CVM不仅在五个基准测试中超越现有方法，更为计算受限设备中的持续学习泛化问题提供了新思路。
[Arxiv](https://arxiv.org/abs/2407.08279)
==========
# RB-SQL：一款基于检索的 LLM 框架，专为文本转 SQL 设计。
发布时间：2024年07月11日
`LLM应用` `数据库` `软件开发`
> RB-SQL: A Retrieval-based LLM Framework for Text-to-SQL
# 摘要
> 通过上下文学习，大型语言模型 (LLM) 在文本到 SQL 任务上取得了显著进步。尽管以往研究多聚焦于通过专用 SQL 生成提示提升 LLM 推理能力，但这些方法往往难以应对包含众多表和列的大型数据库，且忽略了数据库预处理和信息提取对高效提示设计的重要性。为此，我们创新性地提出了 RB-SQL 框架，该框架通过三个模块，智能检索简洁的表和列结构及针对性的学习示例，以优化上下文提示工程。实验证明，RB-SQL 在 BIRD 和 Spider 等公共数据集上表现卓越，超越了多个竞争模型。
[Arxiv](https://arxiv.org/abs/2407.08273)
==========
# 让漫画触手可及：为视障读者开辟新世界
发布时间：2024年07月11日
`LLM应用` `出版业`
> Toward accessible comics for blind and low vision readers
# 摘要
> 本研究探索了如何利用提示工程技术结合上下文信息来微调大型语言模型，生成详尽的文本描述，以便无缝对接现成的语音合成工具。我们提出采用计算机视觉和光学字符识别技术，从漫画图像中提取关键元素，如面板、角色、文本及其关联，构建丰富的上下文环境。随后，我们进行角色识别，并创作包含角色特征、情感和对话的漫画剧本。我们坚信，这种内容丰富的描述将为制作多角色配音、带字幕和音效的有声书和电子书提供便利。
[Arxiv](https://arxiv.org/abs/2407.08248)
==========
# 借助 LLM，我们能通过智能手机的传感器特征来预测情感状态。
发布时间：2024年07月11日
`LLM应用` `心理健康` `数字表型学`
> Leveraging LLMs to Predict Affective States via Smartphone Sensor Features
# 摘要
> 年轻成人心理健康问题的紧迫性催生了日常数字情绪监测的需求，以实现早期发现。数字表型学领域通过分析个人数字设备数据，如智能手机和可穿戴设备，来洞察行为和心理健康。传统上，这些数据依赖统计和机器学习方法分析，但大型语言模型（LLMs）的崛起为此提供了新视角。尽管LLMs在多领域表现出色，但在数字心理健康领域，尤其是整合移动传感器数据方面，其应用尚属初步。我们的研究利用LLMs，基于大学生智能手机数据预测情感状态，展示了零-shot和少-shot LLMs在推断福祉方面的有效性。研究结果表明，LLMs能仅凭智能手机数据做出精准的情感预测，揭示了智能手机行为与情感状态间的紧密联系。这是首次将LLMs应用于情感预测和数字表型学任务，展现了其在心理健康领域的广阔前景。
[Arxiv](https://arxiv.org/abs/2407.08240)
==========
# DALL-M：利用大型语言模型实现上下文感知的临床数据增强
发布时间：2024年07月11日
`LLM应用` `人工智能`
> DALL-M: Context-Aware Clinical Data Augmentation with LLMs
# 摘要
> X射线在医学诊断中扮演关键角色，但缺乏临床背景限制了其效能。放射科医生常需更多临床信息来准确诊断。我们创新地利用临床表格数据增强技术，提升X射线诊断的准确性与可靠性。通过大型语言模型生成患者合成数据，不仅保护了真实数据，还通过相关合成特征丰富了数据集，大幅提升模型性能。DALL-M的三阶段特征生成流程，包括临床上下文存储、专家查询生成和上下文感知特征增强，有效整合了X射线图像与报告，为799个案例生成了91个增强特征。这是首次在数据增强中结合患者报告、性别和年龄，生成新旧特征的上下文值，并创造新知识。实证测试显示，包括决策树、随机森林等模型，性能显著提升，F1分数增加16.5%，精确度和召回率提升约25%。DALL-M填补了临床数据增强的空白，为生成丰富上下文的数据集提供了坚实框架。
[Arxiv](https://arxiv.org/abs/2407.08227)
==========
# 推测性RAG：借助草稿增强检索生成能力
发布时间：2024年07月11日
`RAG` `人工智能` `信息技术`
> Speculative RAG: Enhancing Retrieval Augmented Generation through Drafting
# 摘要
> 检索增强生成（RAG）通过结合大型语言模型（LLM）的生成能力与外部知识源，提供更精准、更及时的响应。最新进展通过迭代LLM改进或自我批评能力提升检索效果。我们提出的推测性RAG框架，利用大型通才LM高效验证小型专业LM并行生成的多个RAG草稿，每个草稿基于不同检索文档子集，提供多样视角并减少输入令牌数。此方法加深对各子集理解，减少长上下文偏差。通过将草稿任务交给小型专业LM，大型通才LM进行单次验证，加速RAG流程。实验显示，推测性RAG在多个基准测试中达到顶尖性能，显著提升准确性（高达12.97%）并大幅降低延迟（51%）。
[Arxiv](https://arxiv.org/abs/2407.08223)
==========
# 不仅仅是基准测试：探讨增强检索生成系统中嵌入模型相似性的评估方法
发布时间：2024年07月11日
`RAG` `信息技术` `数据检索`
> Beyond Benchmarks: Evaluating Embedding Model Similarity for Retrieval Augmented Generation Systems
# 摘要
> 在设计检索增强生成（RAG）系统时，选择嵌入模型至关重要。面对众多选项，识别相似模型集群有助于简化选择过程。仅依赖基准分数难以全面评估模型相似性。因此，本研究从两个角度评估RAG系统中嵌入模型的相似性：首先，通过中心核对齐在成对级别上比较嵌入；其次，利用Jaccard和排名相似性评估检索结果的相似性。我们对比了包括专有模型在内的不同系列模型，涉及五个BEIR数据集。实验发现，模型集群不仅限于同一家族，还存在跨家族集群。此外，top-k检索相似性分析显示低k值时的高方差。研究还揭示了Mistral作为OpenAI模型的开源替代品的潜力。
[Arxiv](https://arxiv.org/abs/2407.08275)
==========
# 大型语言模型在生物医学领域作为假设生成器的表现，我们将进行一次全面评估。
发布时间：2024年07月11日
`LLM应用` `生物医学` `人工智能`
> Large Language Models as Biomedical Hypothesis Generators: A Comprehensive Evaluation
# 摘要
> 随着生物医学知识的迅猛增长，我们提取洞见和生成新假设的能力显得力不从心。大型语言模型（LLMs）应运而生，成为革新知识交互、加速生物医学发现的希望之光。本文深入探讨了LLMs在生物医学假设生成中的应用，构建了背景与假设对的数据集，并精心划分以避免数据污染。我们通过零-shot、少-shot及微调场景，检验了顶尖模型的假设生成力。为深化对科学发现中不确定性这一关键要素的探索，我们引入了工具使用与多代理交互机制。同时，基于详尽文献回顾，我们提出了四项创新指标，旨在从LLM与人类视角双重评估假设质量。实验揭示两大要点：LLMs即便面对训练中未遇文献，亦能产出新颖且经证实的假设；而通过多代理协作与工具辅助提升不确定性，可激发创意涌现，优化零-shot假设生成。但值得注意的是，少-shot学习与工具引入虽增益知识整合，却未必总能提升性能，凸显了对外部知识类型与范围审慎考量的必要性。这些成果不仅彰显了LLMs在生物医学假设生成领域的强大潜能，更为后续研究指明了方向。
[Arxiv](https://arxiv.org/abs/2407.08940)
==========
# GPT-4 在变形的图灵测试中，其表现超越人类，被评定为更具人性。
发布时间：2024年07月11日
`LLM应用` `人工智能` `网络安全`
> GPT-4 is judged more human than humans in displaced and inverted Turing tests
# 摘要
> 在日常的在线对话中，区分人类与AI变得至关重要。我们通过改良版的图灵测试——反转与移位测试，评估了人类与大型语言模型（如GPT-3.5和GPT-4）的辨别能力。结果显示，无论是AI还是经过移位训练的人类裁判，其判断准确性均不及直接互动的审讯者，且总体表现甚至低于随机水平。更有趣的是，这些裁判往往更倾向于认为表现出色的GPT-4更像人类。这一发现强调了在非互动情境下，人类与AI难以区分彼此，从而凸显了开发更精准AI检测工具的紧迫性。
[Arxiv](https://arxiv.org/abs/2407.08853)
==========
# CXR-Agent：结合视觉与语言模型，专为胸部X光解读设计，能生成包含不确定性信息的放射学报告。
发布时间：2024年07月11日
`Agent` `人工智能`
> CXR-Agent: Vision-language models for chest X-ray interpretation with uncertainty aware radiology reporting
# 摘要
> 近期，大型视觉-语言模型在解析复杂图像并运用高级推理生成自然语言描述方面展现出潜力。医学领域天然融合了扫描图像与文本病史，撰写报告的过程使其成为AI技术进步的理想受益者。我们评估了当前最先进的公开可用基础视觉-语言模型在多个胸部X射线数据集上的表现。通过线性探针测试，CheXagent的视觉变换器和Q-former等组件在众多数据集上超越了业界标杆Torch X-ray Vision模型，显示出卓越的泛化能力。然而，我们发现这些模型有时会自信地生成不实信息，影响临床解读速度。为此，我们采用基于代理的视觉-语言方法，结合CheXagent的线性探针与BioViL-T的短语定位工具，旨在产出包含病理位置及概率描述的、具备不确定性意识的放射报告。我们通过构建评估平台，综合运用NLP指标、胸部X射线基准及临床专家评估，对视觉-语言代理进行了全面测试。结果表明，AI生成的报告在准确性、可解释性与安全性上均有显著提升。我们强调，应分别评估正常与异常扫描结果。同时，呼吁扩充配对数据集并实施数据增强策略，以应对大型视觉-语言模型中的过拟合挑战。
[Arxiv](https://arxiv.org/abs/2407.08811)
==========
# 大型模型究竟模拟了什么？我们不应将工程上的成就与人类的语言能力混为一谈。
发布时间：2024年07月11日
`LLM理论` `人工智能` `认知科学`
> Large Models of What? Mistaking Engineering Achievements for Human Linguistic Agency
# 摘要
> 本文指出，关于大型语言模型（LLMs）语言能力的夸大且误导性声明，主要基于两个未经证实的假设：语言完整性和数据完整性。前者认为“自然语言”是一个独特且完整的实体，其本质可被LLM全面模拟；后者则相信语言能通过数据完全量化。然而，认知科学的能动观点表明，语言实为行动的一种方式，无法全面建模。我们发现，LLMs缺乏能动语言的三个关键特征：体现、参与和脆弱性，这与当前模型架构原则不符。因此，LLMs无法成为人类那样的语言主体。通过“算法语言”现象，我们进一步阐释了这一观点。最终，我们断言，关于LLM能力的夸大声明，实则源于对人类语言和LLM本质的深刻误解。
[Arxiv](https://arxiv.org/abs/2407.08790)
==========
# 多模态大型语言模型驱动的神经矩阵分解推荐系统
发布时间：2024年07月11日
`Agent` `信息搜索` `推荐系统`
> A Neural Matrix Decomposition Recommender System Model based on the Multimodal Large Language Model
# 摘要
> 推荐系统已成为信息搜索的关键解决方案。我们提出的BoNMF模型，融合了BoBERTa的自然语言处理能力、ViT的计算机视觉技术及神经矩阵分解，有效捕捉用户与项目的深层特征。通过与低维用户-项目ID矩阵的交互，神经网络精准输出推荐。实验证明，BoNMF在大型数据集上表现卓越，大幅提升推荐精度。
[Arxiv](https://arxiv.org/abs/2407.08942)
==========
# 大型多模态模型（LMM）为视觉障碍者提供的辅助手段正不断涌现，这些实践为设计领域带来了新的启示。
发布时间：2024年07月11日
`Agent` `辅助技术` `视觉障碍`
> Emerging Practices for Large Multimodal Model (LMM) Assistance for People with Visual Impairments: Implications for Design
# 摘要
> 视觉障碍者借助 AI 辅助工具，通过非视觉方式感知世界，获取视觉信息的文本描述。最新 AI 工具如 Be My AI，能更好地理解自然语言查询，并以可听文本描述场景，但其对视觉障碍用户的实际效用尚待深入研究。本文通过与 14 名视觉障碍用户的合作，揭示了他们如何自然地适应这些工具，不仅简化复杂互动，更扩展了认知边界，仿佛认知与视觉信息融为一体。尽管这些工具目前缺乏目标导向性，用户却能灵活适应，广泛应用其功能。这些发现启发我们设计更具目标导向性、实时性和可靠性的 AI 辅助技术。
[Arxiv](https://arxiv.org/abs/2407.08882)
==========
# Detect Llama：利用大型语言模型，精准定位智能合约中的潜在漏洞。
发布时间：2024年07月11日
`LLM应用` `软件开发`
> Detect Llama -- Finding Vulnerabilities in Smart Contracts using Large Language Models
# 摘要
> 本文探讨了一个假设：尽管 OpenAI 的 GPT-4 表现不俗，但通过微调开源模型，我们能在智能合约漏洞检测上超越它。我们微调了 Meta 的 Code Llama 中的两个模型及一个 17k 提示的数据集，即 Detect Llama - Foundation 和 Detect Llama - Instruct，同时也微调了 OpenAI 的 GPT-3.5 Turbo 模型（GPT-3.5FT）。接着，我们评估了这些模型及一个随机基准模型，在我们开发的测试集上与 GPT-4 和 GPT-4 Turbo 的检测能力进行对比，涵盖八个漏洞及两个最常被识别的漏洞及其加权 F1 分数。结果显示，在二元分类（即，该智能合约是否存在漏洞？）中，GPT-3.5FT 和 Detect Llama - Foundation 分别以 $0.776$ 和 $0.68$ 的 F1 分数领先于 GPT-4 和 GPT-4 Turbo 的 $0.66$ 和 $0.675$。在单个漏洞识别的评估中，GPT-3.5FT 和 Detect Llama - Foundation 在所有漏洞的加权 F1 分数（分别为 $0.61$ 和 $0.56$，对比 GPT-4 的 $0.218$ 和 GPT-4 Turbo 的 $0.243$）及最常被识别的两个漏洞的加权 F1 分数（GPT-3.5FT 为 $0.719$，Detect Llama - Foundation 为 $0.674$，对比 GPT-4 的 $0.363$ 和 GPT-4 Turbo 的 $0.429$）方面均显著优于 GPT-4 和 GPT-4 Turbo。
[Arxiv](https://arxiv.org/abs/2407.08969)
==========
# 结合传统关系抽取技术与大型语言模型，提升少样本关系抽取的效能。
发布时间：2024年07月11日
`LLM应用` `机器学习`
> Empowering Few-Shot Relation Extraction with The Integration of Traditional RE Methods and Large Language Models
# 摘要
> Few-Shot Relation Extraction (FSRE) 因其能在极低资源环境下提取文本信息而备受 NLP 研究者青睐。主要方法包括基于预训练语言模型的微调和提示调优。随着大型语言模型的兴起，许多研究者开始通过 In-Context Learning 探索 FSRE。然而，传统 RE 模型缺乏先验知识，而 LLMs 在 RE 任务上表现不佳。为此，我们提出了双系统增强的关系提取器 (DSARE)，它巧妙结合了传统 RE 模型与 LLMs，不仅将 LLMs 的先验知识融入传统模型，还通过关系提取增强提升了 LLMs 的 RE 任务能力。通过集成预测模块，DSARE 综合两种预测得出最终结果。实验证明，我们的方法卓有成效。
[Arxiv](https://arxiv.org/abs/2407.08967)
==========
# 实用且高效的自动化程序修复，助力调试工作
发布时间：2024年07月11日
`Agent` `软件开发` `调试工具`
> Towards Practical and Useful Automated Program Repair for Debugging
# 摘要
> 目前的自动化程序修复技术尚未达到实用水平，无法满足现实调试的需求。这些技术依赖于不切实际的假设，如需要全面的测试用例集和频繁的程序重启来验证补丁，且修复复杂错误的能力有限。我们致力于提升APR的实用性与效率，助力开发者调试。为此，我们设计了PracAPR，一个在IDE中运行的交互式修复系统，旨在提供高效的调试修复建议。PracAPR无需测试集或程序重启，它假设开发者在使用IDE调试器时，程序已暂停在问题点。通过与开发者互动获取问题描述，PracAPR进行无测试的流分析故障定位，结合大型语言模型与定制策略进行局部与全局修复，并基于模拟跟踪比较进行无需重启的补丁验证，从而提出修复方案。PracAPR的引入，有望使APR成为日常调试的得力助手。
[Arxiv](https://arxiv.org/abs/2407.08958)
==========
# 我们提出了一种基于大型语言模型的新框架，通过检测、调查、判断和确定四个步骤，有效进行少样本假新闻检测。
发布时间：2024年07月11日
`LLM应用` `社交媒体` `新闻检测`
> Detect, Investigate, Judge and Determine: A Novel LLM-based Framework for Few-shot Fake News Detection
# 摘要
> Few-Shot Fake News Detection (FS-FND) 旨在极低资源环境下识别假新闻。随着假新闻在社交媒体上的泛滥，这一任务备受瞩目。大型语言模型 (LLM) 凭借其先验知识和上下文学习能力，表现出色。但现有方法受限于理解歧义和信息稀缺，限制了 LLM 的潜力。为此，我们提出了双视角增强的假新闻检测 (DAFND) 模型，从内外两方面强化 LLM。DAFND 首先通过检测模块提取新闻关键词，再通过创新的调查模块搜集相关内外信息，最后由判断模块得出两个预测结果，并由决定模块整合得出最终结论。实验证明，DAFND 在低资源环境下表现优异。
[Arxiv](https://arxiv.org/abs/2407.08952)
==========
# NinjaLLM：借助 Amazon SageMaker 与 AWS Trainium 和 Inferentia2，实现高效、可扩展且经济的 RAG 解决方案。
发布时间：2024年07月11日
`RAG` `云计算` `人工智能`
> NinjaLLM: Fast, Scalable and Cost-effective RAG using Amazon SageMaker and AWS Trainium and Inferentia2
# 摘要
> 本文针对大型语言模型（LLM），在 AWS Trainium 和 Inferentia2 AI 芯片上通过 SageMaker 进行微调与托管，提出了一系列对 RAG 技术的改进。这些芯片不仅经济实惠，而且具有出色的弹性与高效性能。改进措施包括提升工具使用效率、增加引用功能，以及减少因上下文偏差引发的问题。在 Natural Questions 和 HotPotQA 数据集上的测试显示，我们的 RAG 系统准确率分别达到 62% 和 59%，优于同类模型。
[Arxiv](https://arxiv.org/abs/2407.12057)
==========
# 构建基于检索增强生成的聊天机器人要点解析
发布时间：2024年07月10日
`RAG` `人工智能`
> FACTS About Building Retrieval Augmented Generation-based Chatbots
# 摘要
> 生成式AI驱动的企业聊天机器人正成为提升员工效率的关键工具。构建这类机器人，关键在于运用RAG、LLMs及Langchain、Llamaindex等框架，但过程复杂，需精心设计RAG管道。这涉及嵌入与模型的微调、文档提取、查询重述、结果重排、提示设计、访问控制、简洁响应、引用添加、隐私保护及编排代理构建。我们基于NVIDIA三个聊天机器人的实践，提出了一套框架。主要贡献有三：一是FACTS框架的引入，二是十五个RAG控制点的展示，三是大型与小型LLMs在准确性与延迟上的实证对比。据我们所知，这是首篇全面探讨构建安全企业级聊天机器人要素与方案的论文。
[Arxiv](https://arxiv.org/abs/2407.07858)
==========
# 在基于LLM的多智能体社区中，操纵知识的泛滥现象
发布时间：2024年07月10日
`LLM应用` `网络安全` `人工智能`
> Flooding Spread of Manipulated Knowledge in LLM-Based Multi-Agent Communities
# 摘要
> 大型语言模型（LLM）在多代理系统中的广泛应用，如协作问题解决和自主协商，展示了其卓越能力。然而，这些系统的安全问题，尤其是操纵知识的传播，尚未得到充分探讨。本文通过构建详尽的威胁模型和模拟环境，深入研究了这一问题。我们提出了一种两阶段攻击方法，包括说服性注入和操纵知识注入，旨在探索无需直接提示操纵的知识传播。我们的方法揭示了LLM在处理世界知识时的内在漏洞，攻击者可借此无意识地传播虚假信息。实验证明，这种攻击能有效诱导LLM代理传播反事实和有毒知识，且不影响其基本通信能力。此外，操纵知识能通过检索增强生成框架持续存在，影响未来的交互。这表明，即使交互结束，良性代理仍可能受操纵知识影响。我们的研究强调了加强防御措施的必要性，如引入“守护者”代理和高级事实核查工具，以应对这些安全风险。
[Arxiv](https://arxiv.org/abs/2407.07791)
==========
# 基于基础模型的自我解析机制在自然语言处理中的应用
发布时间：2024年07月10日
`Agent` `人工智能`
> Natural Language Mechanisms via Self-Resolution with Foundation Models
# 摘要
> 我们提出了一种新机制，允许代理以自然语言报告，并借助LLM的世界建模能力来决定结果和报酬分配。这种机制在LLM作为优秀世界模型和强信息过度确定条件下，既能激励兼容又高效。我们还展示了这种基于语言模型的机制在预测市场失效的情况下，如何成功整合信息。
[Arxiv](https://arxiv.org/abs/2407.07845)
==========
# WorldAPIs：探寻世界的API价值，一场思想实验之旅
发布时间：2024年07月10日
`Agent` `人工智能` `软件开发`
> WorldAPIs: The World Is Worth How Many APIs? A Thought Experiment
# 摘要
> AI系统通过API调用的基本动作在现实世界中做决策。然而，现有模拟器提供的API有限，引发了一个问题：多功能代理需要多少API？我们通过思想实验探讨：假设wikiHow涵盖广泛任务，所需的API空间是什么？我们提出框架，通过结合wikiHow指令与代理策略，迭代生成新API。借鉴LLM的成功，我们用少样本提示引导GPT-4生成Python程序，通过重用种子API和必要时创建新API，构建API宇宙。实验重点在于定义API而非执行。我们应用此流程于wikiHow指令，发现0.5%教程需300+API。分析显示，流程有效重用和创建API。审查表明，现有模拟器仅支持部分诱导API，推动了开发丰富动作的具身环境。
[Arxiv](https://arxiv.org/abs/2407.07778)
==========
# 通过公理化训练，引导 Transformer 掌握因果推理的艺术。
发布时间：2024年07月10日
`Agent` `人工智能` `因果推理`
> Teaching Transformers Causal Reasoning through Axiomatic Training
# 摘要
> 在现实世界中，基于文本的AI系统需要具备因果推理能力。由于生成干预性数据成本高昂，我们探讨了AI代理从被动数据中学习因果推理的潜力。我们采用了一种公理化训练方法，让代理通过观察因果公理的多个实例来学习，而非直接将公理融入模型或从数据中推断。我们的核心问题是，代理能否将这些公理实例泛化应用到新情境中。例如，若一个transformer模型在小型图上学习了因果传递性公理，它能否在大型图上同样适用？我们的研究表明，这种泛化是可行的。我们关注的是在给定因果图结构下，判断变量间的因果关系。实验显示，一个6700万参数的transformer模型，经过线性因果链及相关变体的训练后，能有效泛化至更复杂图结构，包括长链、逆序链及分支图，即便未针对这些情况专门训练。该模型性能与GPT-4、Gemini Pro和Phi-3等大型语言模型不相上下，甚至更优。这一公理化训练框架为从被动数据中学习因果推理开辟了新途径，只要能提供充足的公理实例，即可应用于任意公理的学习。
[Arxiv](https://arxiv.org/abs/2407.07612)
==========
# LLaVA-NeXT-Interleave 技术旨在解决大规模多模态模型中的多图像、视频及3D内容处理问题。
发布时间：2024年07月10日
`LLM应用` `计算机视觉` `人工智能`
> LLaVA-NeXT-Interleave: Tackling Multi-image, Video, and 3D in Large Multimodal Models
# 摘要
> 视觉指令调优大幅提升了大型多模态模型（LMMs）的性能。尽管如此，现有LMMs多聚焦于单图像任务，对多图像场景的应用探索不足。此外，以往研究各自为政，难以实现跨场景能力的新突破。为此，我们推出了LLaVA-NeXT-Interleave，它全面应对LMMs中的多图像、视频、3D及单图像多补丁场景。我们采用交错数据格式作为通用模板，构建了包含1,177.6万样本的M4-Instruct数据集，横跨四大领域、14项任务及41个数据集。同时，我们精心打造了LLaVA-Interleave Bench，全面评估LMMs在多图像场景的表现。实验表明，LLaVA-NeXT-Interleave在多图像、视频和3D领域表现卓越，单图像任务性能亦保持领先。此外，该模型还展现出跨设置和模态的任务转移等新兴能力。代码已开放，详见https://github.com/LLaVA-VL/LLaVA-NeXT。
[Arxiv](https://arxiv.org/abs/2407.07895)
==========
# AffectGPT：一个专为可解释多模态情感识别设计的数据集与框架
发布时间：2024年07月10日
`LLM应用` `情感识别` `人工智能`
> AffectGPT: Dataset and Framework for Explainable Multimodal Emotion Recognition
# 摘要
> 可解释的多模态情感识别（EMER）旨在实现可靠且准确的情感识别，但高昂的标注成本导致现有数据集（EMER-Fine）规模有限，难以进行有效的监督训练。为此，我们回顾并简化了数据集构建流程，采用开源模型替代闭源模型，成功构建了大规模粗略标注数据集EMER-Coarse。此外，我们提出了两阶段训练框架AffectGPT，第一阶段利用EMER-Coarse进行粗略映射学习，第二阶段结合EMER-Fine以更好地对齐人工检查结果。实验证明，我们的方法在EMER任务上表现出色。为推动后续研究，我们将公开代码和数据集，详情请访问：https://github.com/zeroQiaoba/AffectGPT。
[Arxiv](https://arxiv.org/abs/2407.07653)
==========
# InstructLayout：融合语义图先验的指令驱动二维与三维布局合成技术
发布时间：2024年07月10日
`LLM应用` `计算机图形学` `人工智能`
> InstructLayout: Instruction-Driven 2D and 3D Layout Synthesis with Semantic Graph Prior
# 摘要
> 理解自然语言指令为2D和3D布局合成系统增添了魅力。然而，现有方法通过隐式建模对象关系，限制了生成的可控性。为此，我们推出了InstructLayout框架，该框架结合语义图先验与布局解码器，显著提升了布局合成的可控性与真实感。该框架的语义图先验能同时学习布局特征与对象分布，以零-shot方式灵活应对各类下游任务。此外，我们精心构建了两个高质量数据集，助力文本驱动场景合成的基准测试。实验证明，我们的方法在2D和3D布局合成领域大幅领先现有技术。深入的消融研究也验证了关键设计元素的有效性。
[Arxiv](https://arxiv.org/abs/2407.07580)
==========
# 大型视觉-语言模型面临的攻击：资源、进展与未来展望
发布时间：2024年07月10日
`LLM应用` `计算机视觉` `网络安全`
> A Survey of Attacks on Large Vision-Language Models: Resources, Advances, and Future Trends
# 摘要
> 随着大型模型的快速发展，大型视觉-语言模型（LVLMs）在跨模态理解和推理任务中表现出色。与传统LLMs相比，LVLMs因更贴近现实多资源应用和复杂的多模态处理而充满潜力与挑战。但其脆弱性尚未充分研究，日常使用中潜藏安全风险。本文全面梳理了LVLM攻击的多种形式，从攻击背景到方法发展，再到未来研究方向，旨在揭示LVLM漏洞现状，激发更多研究关注并解决LVLM发展中的安全问题。最新LVLM攻击论文持续更新于https://github.com/liudaizong/Awesome-LVLM-Attack。
[Arxiv](https://arxiv.org/abs/2407.07403)
==========
# 在测试任务上训练，评估与结果的混淆随之而来。
发布时间：2024年07月10日
`LLM理论` `人工智能` `软件工程`
> Training on the Test Task Confounds Evaluation and Emergence
# 摘要
> 我们探讨了一个大型语言模型评估中的核心问题——“测试任务训练”。这一概念并非指不当行为，而是描述了在预训练阶段融入任务相关数据的一系列技术。我们发现，这种做法可能扭曲模型间的相对评估和涌现能力的判断。为此，我们提出了一种方法，通过在相同任务数据上微调模型，以校正“测试任务训练”的影响。结果显示，调整后，许多所谓的涌现行为现象显著减少，甚至包括那些无法仅通过评估指标解释的情况。我们的研究为大型语言模型的评估带来了新的视角，对基准制定和涌现能力研究具有深远影响。
[Arxiv](https://arxiv.org/abs/2407.07890)
==========
# 致力于提升语言模型的对齐稳健性：通过分布式稳健化方法优化直接偏好
发布时间：2024年07月10日
`LLM理论` `人工智能`
> Towards Robust Alignment of Language Models: Distributionally Robustifying Direct Preference Optimization
# 摘要
> 本研究针对DPO训练数据集中的噪声问题，提出了一种增强LLM与人类偏好对齐的方法。我们区分了点态噪声和成对噪声，并利用DRO技术提升DPO的抗噪能力。理论分析表明，DPO天然具备DRO特性，特别是正则化系数$β$对抗噪至关重要。进一步，我们创新性地提出了Dr. DPO，通过优化最差成对情况，增强成对鲁棒性。Dr. DPO中的$β'$参数精细调控数据对可靠性，实现噪声环境下的探索与利用平衡。实证结果显示，Dr. DPO在各类环境下均显著提升文本质量和响应准确性。相关代码已公开于https://github.com/junkangwu/Dr_DPO。
[Arxiv](https://arxiv.org/abs/2407.07880)
==========
# OpenDiLoCo：一款开源框架，专为全球分布式低通信训练设计。
发布时间：2024年07月10日
`LLM应用` `人工智能` `开源项目`
> OpenDiLoCo: An Open-Source Framework for Globally Distributed Low-Communication Training
# 摘要
> OpenDiLoCo 是一个开源项目，旨在实现和复现用于大型语言模型的 Distributed Low-Communication (DiLoCo) 训练方法。我们提供了一个基于 Hivemind 库的可扩展、去中心化训练框架中的 DiLoCo 实验可复现实现。通过在跨越两大洲和三国的环境中训练模型，并保持高达 95% 的计算利用率，我们验证了其高效性。此外，我们的消融研究深入探讨了算法的计算效率和工作者的可扩展性，并证实了使用 FP16 进行梯度全减少的可行性，不会影响性能。最后，我们将 OpenDiLoCo 规模扩大至原始工作的三倍，充分展示了其对处理十亿参数模型的能力。
[Arxiv](https://arxiv.org/abs/2407.07852)
==========
# OV-DINO：结合语言感知选择性融合的统一开放词汇检测技术
发布时间：2024年07月10日
`LLM应用` `计算机视觉` `机器学习`
> OV-DINO: Unified Open-Vocabulary Detection with Language-Aware Selective Fusion
# 摘要
> 开放词汇检测因其需根据类别名称识别未见过的物体而颇具挑战。现有技术虽通过广泛预训练展现零-shot检测实力，但仍需克服两大难题：整合多元数据源进行端到端训练，以及运用语言感知力深化区域级跨模态理解。为此，我们创新推出OV-DINO方法，通过语言感知融合在统一框架下预训练于多样大数据集。我们设计了UniDI流水线，实现数据源整合，净化伪标签噪声，聚焦检测核心。同时，LASF模块通过语言感知查询与融合，强化模型语言理解力。OV-DINO在COCO与LVIS数据集上以零-shot模式创下佳绩，彰显其卓越泛化性。微调后，其在COCO上更以58.4%的AP超越众多同类方法。OV-DINO代码即将在\href{https://github.com/wanghao9610/OV-DINO}{GitHub}发布。
[Arxiv](https://arxiv.org/abs/2407.07844)
==========
# 大规模语言模型中的 Transformer 对齐
发布时间：2024年07月10日
`LLM理论` `机器学习`
> Transformer Alignment in Large Language Models
# 摘要
> 大型语言模型 (LLMs) 在自然语言处理领域取得了显著成就，深入理解其内部运作机制至关重要。我们将 LLMs 视为高维离散、耦合、非线性动力学系统中的嵌入转换。这一视角促使我们追踪单个令牌在通过转换器块时的轨迹，并通过雅可比矩阵沿这些轨迹线性化系统。通过对 38 个公开可用的 LLMs 的分析，我们发现了残差雅可比矩阵的左上和右上奇异向量的对齐，以及线性和层级指数增长的涌现。特别地，我们发现对齐程度的增加与模型性能呈正相关。训练后评估的指标显示，与随机初始化权重相比，有显著提升，凸显了训练在转换器中的重要影响。这些发现揭示了一个先前被忽视的显著规律性，强化了动力学解释，并为更深入理解和优化 LLM 架构开辟了道路。
[Arxiv](https://arxiv.org/abs/2407.07810)
==========
# ROSA：通过随机子空间适应实现高效微调
发布时间：2024年07月10日
`LLM理论` `机器学习`
> ROSA: Random Subspace Adaptation for Efficient Fine-Tuning
# 摘要
> 模型训练所需的内存远超推理。参数高效微调（PEFT）方法通过减少内存使用，帮助大型模型适应下游任务。然而，现有方法如适配器、提示调优或低秩适应（LoRA）要么在推理时增加延迟，要么在性能上不及全量微调。我们提出的随机子空间适应（ROSA）方法，不仅在性能上大幅超越以往PEFT方法，且在推理时无额外延迟。ROSA能适应任意大小的子空间，更接近全量微调的效果。理论与实验均证明，ROSA在运行时无需额外内存，表达力却强于LoRA。在自然语言处理领域，全量微调成本高昂，我们在NLG和NLU任务中使用GPT-2和RoBERTa评估ROSA，结果显示ROSA在GLUE任务和NLG任务中均显著优于LoRA。代码已公开在https://github.com/rosa-paper/rosa。
[Arxiv](https://arxiv.org/abs/2407.07802)
==========
# 大型语言模型：长文档的得力助手还是选择放弃？
发布时间：2024年07月10日
`LLM应用` `文档处理` `人工智能`
> Attribute or Abstain: Large Language Models as Long Document Assistants
# 摘要
> 大型语言模型（LLM）虽能辅助长文档处理，但常产生不实信息。通过归因，即LLM提供支持其回答的证据，可增强其回答的可信度。然而，现有归因方法仅在RAG环境下评估，未考虑长文档场景，其中无需检索。为此，我们推出LAB基准，涵盖6项长文档任务，并测试4种不同规模LLM的归因方法，包括提示与微调。实验显示，“引用”策略（一步完成回答与证据提取）效果最佳。我们还探讨了归因中的“中间迷失”现象，未见其存在。此外，证据质量能预测简单回答的优劣，但对复杂回答则不然，因模型难以提供复杂声明的证据。我们公开了相关代码与数据，供后续深入研究。
[Arxiv](https://arxiv.org/abs/2407.07799)
==========
# 通过基于网格的游戏竞赛评估大型语言模型：打造一个可扩展的 LLM 基准与排行榜
发布时间：2024年07月10日
`LLM应用` `人工智能`
> Evaluating Large Language Models with Grid-Based Game Competitions: An Extensible LLM Benchmark and Leaderboard
# 摘要
> 我们为大型语言模型（LLM）创建了一个新颖且可扩展的基准，通过井字棋、四子棋和五子棋等网格游戏进行测试。开源的游戏模拟代码可在GitHub上获取，支持LLM竞争，并生成用于排行榜和分析的详细数据文件。我们展示了包括Anthropic、Google、OpenAI和Meta在内的领先LLM之间的游戏结果。总共模拟了2,310场比赛，涉及三种游戏和三种提示类型。结果显示LLM在不同游戏和提示类型中的表现差异显著，详细分析了胜率、淘汰率、错失机会和无效移动。排行榜和结果数据的详细信息已在GitHub上公开。这项研究加深了我们对LLM在未专门训练的游戏中能力的理解，评估了其规则理解和战略思维。在追求人工通用智能（AGI）的道路上，这项研究为探索LLM在复杂决策场景中的应用奠定了基础，揭示了其战略思维能力，并为未来研究提供了方向。
[Arxiv](https://arxiv.org/abs/2407.07796)
==========
# ChatGPT 能否在计算理论课程中取得及格？
发布时间：2024年07月10日
`LLM应用` `计算机科学`
> Can ChatGPT Pass a Theory of Computing Course?
# 摘要
> 大型语言模型在处理数学问题，尤其是计算理论课程中的问题时，表现不佳。本文通过两个实验，探讨了 ChatGPT 在 ToC 课程中的表现。首先，我们测试了 ChatGPT 通过 ToC 考试的能力；其次，我们构建了一个 ToC 问题数据库，以便其他课程参考。实验结果显示，ChatGPT 能通过 ToC 考试，擅长处理选择题等基础题型，但在开放式证明题中常出现逻辑错误。
[Arxiv](https://arxiv.org/abs/2407.07757)
==========
# 针对大型语言模型进行微调，同时确保用户级差分隐私。
发布时间：2024年07月10日
`LLM理论` `人工智能` `隐私保护`
> Fine-Tuning Large Language Models with User-Level Differential Privacy
# 摘要
> 我们探索了结合用户级差分隐私的实用且可扩展的 LLM 训练算法，旨在保护每位用户的所有贡献。我们分析了两种 DP-SGD 变体：示例级采样与梯度裁剪，以及用户级采样与梯度裁剪。我们创新地提出了用户级 DP 会计方法，为示例级采样提供了严格的隐私保障。实验表明，尽管在特定场景下示例级采样可能更优，但用户级采样在用户示例多样性高时表现更佳。通过在固定计算资源下的合成均值估计和 LLM 微调任务中验证，我们发现用户级采样在强隐私需求或高计算预算环境下显著占优。我们的研究重点在于与 LLM 兼容的训练算法，能够支持数亿参数的模型和数十万用户的规模。
[Arxiv](https://arxiv.org/abs/2407.07737)
==========
# 我们提出了一种名为 S.C.O.R.E. 的评估框架，旨在从安全性、共识、客观性、可重复性和可解释性五个维度全面评估大型语言模型。
发布时间：2024年07月10日
`LLM理论` `人工智能`
> A Proposed S.C.O.R.E. Evaluation Framework for Large Language Models : Safety, Consensus, Objectivity, Reproducibility and Explainability
# 摘要
> 在医疗领域，我们需要一个超越传统量化指标的全面评估框架来审视大型语言模型 (LLM)。为此，我们提出了五个评估维度：安全性、共识性、客观性、可重复性和可解释性 (S.C.O.R.E.)。我们相信，S.C.O.R.E. 将成为未来医疗用 LLM 模型评估的基石，确保其在临床应用中的安全、可靠、可信与伦理合规。
[Arxiv](https://arxiv.org/abs/2407.07666)
==========
# 通过提示对齐优化候选标签的视觉-语言模型
发布时间：2024年07月10日
`LLM应用` `计算机视觉`
> Tuning Vision-Language Models with Candidate Labels by Prompt Alignment
# 摘要
> 视觉-语言模型 (VLMs) 能从海量图像-文本对中提炼出高质量表示。提示学习，作为微调 VLM 以适应特定任务的热门手段，虽表现出色，却受限于对标注数据的依赖。现实中，数据隐私或敏感性常使我们仅能触及候选标签而非真实标签。本文首开先河，探讨了 VLMs 在候选标签下的提示学习。实证显示，面对候选标签，提示学习优于其他微调策略，但标签歧义加剧时性能下滑。为此，我们设计了一个简洁高效的框架，巧妙运用 VLMs 的先验知识，以候选标签引领学习之旅。该框架通过模型输出与混合类别后验的精准对齐，消解标签歧义，并兼容多样化的训练目标，助力候选标签学习，进一步提升性能。实验广泛验证了这一框架的卓越成效。
[Arxiv](https://arxiv.org/abs/2407.07638)
==========
# 大规模网络挖掘语料库在大型语言模型预训练中的挑战概览
发布时间：2024年07月10日
`LLM理论` `人工智能` `网络安全`
> A Review of the Challenges with Massive Web-mined Corpora Used in Large Language Models Pre-Training
# 摘要
> 本文全面探讨了利用网络挖掘的大规模语料库进行 LLM 预训练时遇到的难题，如噪声、内容重复、信息质量低下、偏见及敏感个人信息的包含等。解决这些挑战对于构建准确、可靠且符合伦理的语言模型至关重要。我们通过分析现有的数据处理和偏见管理技术，指出了现有方法的不足，并提出了未来研究的方向，旨在推动更先进、更符合伦理的 LLM 的发展。
[Arxiv](https://arxiv.org/abs/2407.07630)
==========
# IDA-VLM：借助 ID-Aware 大型视觉-语言模型，迈向电影深度理解
发布时间：2024年07月10日
`LLM应用` `人工智能`
> IDA-VLM: Towards Movie Understanding via ID-Aware Large Vision-Language Model
# 摘要
> 随着大型视觉-语言模型（LVLMs）的迅猛发展，一系列新兴能力得以展现。然而，这些模型目前仅限于分析单一情景的视觉内容，对于跨场景实例关联的能力尚未开发，这对理解复杂视觉内容如电影至关重要。为了深入电影理解，LVLMs需首先提升跨场景角色身份的记忆与识别能力。为此，我们提出ID参考的视觉指令调整，并创新开发了IDA-VLM模型。同时，我们引入了MM-ID基准，从匹配、定位、问答和字幕四个维度全面评估LVLMs的实例ID处理能力。研究揭示了现有模型在ID参考下识别与关联实例的不足。本文为未来AI系统处理多身份视觉输入奠定了基础，助力复杂视觉叙事如电影的深入理解。
[Arxiv](https://arxiv.org/abs/2407.07577)
==========
# HebDB：专为希伯来语语音处理设计的弱监督数据集
发布时间：2024年07月10日
`LLM应用` `语音处理`
> HebDB: a Weakly Supervised Dataset for Hebrew Speech Processing
# 摘要
> 我们推出了 HebDB，一个专为希伯来语口语处理设计的弱监督数据集，收录了约 2500 小时自然即兴的语音资料，涵盖多样化的说话者和话题。该数据集不仅提供原始音频，还包括预处理和过滤版本，旨在推动希伯来语口语处理技术的研究与开发。此外，我们构建了两个 ASR 基准系统：一是自监督模型，二是全监督模型，并在 HebDB 上对其性能进行了优化，与现有多语言 ASR 方案进行了对比。结果显示，在同等模型规模下，我们的方法性能更优。所有资源均已公开，访问地址为 https://pages.cs.huji.ac.il/adiyoss-lab/HebDB/。
[Arxiv](https://arxiv.org/abs/2407.07566)
==========
# 代码生成评估数据集的泄露问题
发布时间：2024年07月10日
`LLM应用` `软件开发` `人工智能`
> On Leakage of Code Generation Evaluation Datasets
# 摘要
> 本文探讨了代码生成测试集在现代大型语言模型中的污染问题，并揭示了三种污染源：直接数据泄露、合成数据引发的间接泄露及模型选择时的评估集过度拟合。核心发现基于一个新发布的包含161个编程问题及其Python解答的数据集，详情可访问https://huggingface.co/datasets/CohereForAI/lbpp。
[Arxiv](https://arxiv.org/abs/2407.07565)
==========
# 大型语言模型助力阿拉伯自动故事生成
发布时间：2024年07月10日
`LLM应用`
> Arabic Automatic Story Generation with Large Language Models
# 摘要
> 大型语言模型 (LLM) 近期在多种语言生成任务中展现出强大能力，但在阿拉伯语领域进展较慢。本研究聚焦于利用 LLM 生成故事，采用机器翻译 (MT) 和 GPT-4 获取训练故事。针对 MT 数据，我们设计了确保故事质量的精细流程；对于 GPT-4 数据，我们设计了适应阿拉伯语环境的提示，涵盖现代标准阿拉伯语及埃及、摩洛哥方言。例如，我们为多个阿拉伯国家定制了涵盖广泛主题的故事。手动评估表明，经过微调的模型能生成符合指令的连贯故事。此外，我们通过自动和人工评估，将模型与顶尖的专有及开源模型进行对比。所有数据集和模型将在 https: //github.com/UBC-NLP/arastories 公开。
[Arxiv](https://arxiv.org/abs/2407.07551)
==========
# 跳出基准测试框架，我们提出了一种评估大型语言模型的新范式。
发布时间：2024年07月10日
`LLM理论` `人工智能`
> Beyond Benchmarking: A New Paradigm for Evaluation and Assessment of Large Language Models
# 摘要
> 当前的 LLM 评估基准存在诸多问题，如内容限制、更新滞后和缺乏优化指导。为此，我们提出了一种全新的评估范式：基准测试-评估-评估。这一范式将 LLM 的评估环境从“考场”转变为“医院”，通过“体检”方式，以特定任务解决为核心，深入剖析并优化 LLM 中的问题。
[Arxiv](https://arxiv.org/abs/2407.07531)
==========
# SHERL：针对资源受限的迁移学习，实现高准确度与内存效率的合成
发布时间：2024年07月10日
`LLM应用` `人工智能` `机器学习`
> SHERL: Synthesizing High Accuracy and Efficient Memory for Resource-Limited Transfer Learning
# 摘要
> 参数高效的迁移学习（PETL）领域正蓬勃发展，旨在将大型预训练模型适应到下游任务，同时减少可训练参数并应对微调中的内存挑战。为解决这一难题，我们提出了创新的METL策略SHERL，特别适用于资源有限场景。SHERL将适应过程分为两个互补阶段：首先，通过反冗余操作优化中间输出，提升其后续交互的兼容性；随后，利用少量后期预训练层，有效减轻内存压力，并将灵活特征转化为对新领域更具适应性的强大表示。实验证明，SHERL在视觉与语言及仅语言任务中，以较低内存开销实现了与传统PETL方法相当或更优的性能。代码已公开发布于：https://github.com/Paranioar/SHERL。
[Arxiv](https://arxiv.org/abs/2407.07523)
==========
# 仅需 Bucket 预训练，一切尽在掌握
发布时间：2024年07月10日
`LLM理论` `机器学习`
> Bucket Pre-training is All You Need
# 摘要
> 大型语言模型在众多自然语言处理任务中表现卓越，但传统固定长度的预训练数据组合策略，通过文档的拼接和分割，可能引入噪声并限制模型对长距离依赖的捕捉。为此，我们首先提出了三个评估数据组合质量的指标：填充比、截断比和连接比。接着，我们提出了一种多桶数据组合方法，突破固定长度限制，提供更灵活高效的预训练途径。实验证明，该方法能显著提升预训练的效率和效果，不仅减少噪声、保留上下文，还加速了训练过程，为大型语言模型的预训练开辟了新的可能。
[Arxiv](https://arxiv.org/abs/2407.07495)
==========
# Review-LLM：借助大型语言模型，打造个性化评论生成工具
发布时间：2024年07月10日
`LLM应用` `推荐系统` `电子商务`
> Review-LLM: Harnessing Large Language Models for Personalized Review Generation
# 摘要
> 产品评论生成在推荐系统中至关重要，能为推荐增添解释与说服力。近期，大型语言模型如ChatGPT展现了出色的文本建模与生成能力，有望应用于评论生成领域。然而，直接利用这些模型可能因“礼貌”现象而难以产出个性化评论，如负面评价。为此，我们提出Review-LLM，专为个性化评论生成定制。首先，通过整合用户历史行为（含项目标题与评论）构建输入提示，助模型捕捉用户兴趣与评论风格。其次，引入评分作为满意度指标，深化模型对用户偏好的理解及评论情感控制。最终，借助监督微调，使模型针对特定用户与项目生成个性化评论。实验表明，我们的模型在真实数据集上表现优于现有闭源LLMs，评论生成效果更佳。
[Arxiv](https://arxiv.org/abs/2407.07487)
==========
# Rectifier：利用 LLM 实现代码翻译与校正
发布时间：2024年07月10日
`LLM应用` `软件开发` `人工智能`
> Rectifier: Code Translation with Corrector via LLMs
# 摘要
> 随着软件与社会的进步，软件迁移日益受到重视。早期研究多依赖手工规则进行语言间的代码转换，这一过程既易错又耗时。近年来，研究者开始尝试利用预训练的大型语言模型（LLM）进行代码翻译，但此复杂任务中LLM常犯的错误包括编译、运行时、功能性及非终止执行错误。这些错误的根源相似，如包导入失败、循环边界失误、操作符错误等。为此，我们提出了通用校正器Rectifier，一个微型且普适的错误修复模型，它能从LLM的错误中学习，并广泛应用于纠正各类LLM的翻译错误。实验表明，Rectifier在C++、Java与Python间的代码翻译中展现了出色的修复能力，交叉实验亦证实了其方法的稳健性。
[Arxiv](https://arxiv.org/abs/2407.07472)
==========
# GLBench：专为大型语言模型设计的图处理全面基准
发布时间：2024年07月10日
`LLM应用` `人工智能` `数据科学`
> GLBench: A Comprehensive Benchmark for Graph with Large Language Models
# 摘要
> 大型语言模型（LLM）的兴起，催生了与图表交互的新范式——GraphLLM。尽管GraphLLM技术日新月异，但因缺乏统一标准的测试平台，其发展现状仍显模糊。为此，我们推出了GLBench，这是首个针对GraphLLM方法在监督与零-shot环境下进行全面评估的基准。GLBench不仅公正地评测了各类GraphLLM技术，还涵盖了图神经网络等传统基线。通过在真实数据集上实施标准化实验，我们获得了重要洞察：在监督模式下，GraphLLM技术普遍超越传统方法，特别是作为增强器的LLM表现最为稳定；但作为预测器时，LLM则表现不佳，常引发输出失控问题。此外，我们发现GraphLLM尚无明确的规模效应规律。同时，结构与语义在零-shot迁移中扮演关键角色，我们提出的简易基线甚至能击败一些专为零-shot设计的复杂模型。GLBench的资源已公开于https://github.com/NineAbyss/GLBench。
[Arxiv](https://arxiv.org/abs/2407.07457)
==========
# 通过思维链提示实现可控的导航指令生成
发布时间：2024年07月10日
`LLM应用` `人工智能` `导航系统`
> Controllable Navigation Instruction Generation with Chain of Thought Prompting
# 摘要
> 指令生成是一个跨学科研究热点，应用广泛。传统模型受限于单一数据集的风格，且无法灵活控制生成内容。我们借助大型语言模型（LLM），创新推出C-Instructor，通过思维链提示实现风格与内容的双重可控。我们首创地标思维链（CoTL）机制，引导模型精准识别地标，生成详尽指令，提升易用性与操作灵活性。同时，我们设计空间拓扑建模任务，深化环境理解。最后，通过风格混合训练策略，C-Instructor在单一模型内实现多风格指令生成。实验证明，C-Instructor在文本质量、导航指导及用户体验等多方面超越现有技术。
[Arxiv](https://arxiv.org/abs/2407.07433)
==========
# CHOP：融合 ChatGPT 于 EFL 口语展示训练
发布时间：2024年07月10日
`LLM应用` `语言学习`
> CHOP: Integrating ChatGPT into EFL Oral Presentation Practice
# 摘要
> EFL 学生在进行口头报告时，常因资源匮乏和教师反馈效果有限而感到挑战。大型语言模型（LLM）通过实时反馈，为提升学生口头报告能力开辟了新途径。本文探讨了如何将 ChatGPT 有效融入 EFL 口头报告练习，提供定制化反馈。我们创新性地推出了 CHOP 平台——一个基于 ChatGPT 的互动学习工具，并通过对 13 名 EFL 学生的实证研究，评估了其效能。通过分析学生与 ChatGPT 的互动数据及专家对反馈质量的评价，我们揭示了 CHOP 平台的优缺点。同时，我们深入剖析了学习者的体验和关键设计要素。基于这些发现，我们为教育领域提出了未来发展方向和设计优化建议。
[Arxiv](https://arxiv.org/abs/2407.07393)
==========
# 恶意路径操纵：利用视觉-语言导航系统的表示漏洞
发布时间：2024年07月10日
`LLM应用` `机器人` `计算机视觉`
> Malicious Path Manipulations via Exploitation of Representation Vulnerabilities of Vision-Language Navigation Systems
# 摘要
> 借助大型语言模型在命令理解和多模态视觉-语言转换器的零-shot识别方面的强大能力，视觉语言导航（VLN）已成为解决机器人导航自然语言接口挑战的有效途径。然而，这些模型因底层嵌入空间缺乏语义意义而显得脆弱。我们利用一种新型的基于梯度的优化技术，展示了如何微妙地调整图像，使其在视觉-语言模型中与完全不同的图像和文本相匹配。基于此，我们设计了算法，仅需少量图像的对抗性修改，就能引导机器人按照特定路径执行多地标命令。实验表明，通过最新的VLN系统，机器人可被诱导至完全不同的路线。此外，我们还开发了一种高效算法，通过识别对抗性修改图像对高斯噪声的高度敏感性，来可靠地检测这些恶意篡改。
[Arxiv](https://arxiv.org/abs/2407.07392)
==========
# LokiLM 技术报告
发布时间：2024年07月10日
`LLM理论` `人工智能`
> LokiLM: Technical Report
# 摘要
> 我们推出的 LokiLM，一个 1.4B 参数的 LLM，经过 500B 令牌的训练，在自然语言推理任务中表现卓越，成为参数 1.5B 以下的佼佼者。通过多教师知识蒸馏和精选训练数据，LokiLM 的基准成绩可与更大规模的模型媲美。我们通过一系列措施，确保了开发过程中避免基准污染和过拟合。然而，LokiLM 在产生幻觉和 TruthfulQA 测试中表现不佳，因此我们决定暂不公开发布。
[Arxiv](https://arxiv.org/abs/2407.07370)
==========
# 探索由 LLM 驱动的虚拟代理在酒精使用咨询中的动机性访谈应用。
发布时间：2024年07月10日
`Agent` `心理健康`
> Virtual Agents for Alcohol Use Counseling: Exploring LLM-Powered Motivational Interviewing
# 摘要
> 我们创新性地运用大型语言模型 (LLM) 开发了一款虚拟顾问，专为酒精使用咨询中的动机性访谈 (MI) 设计。面对物质滥用领域有效咨询的稀缺，虚拟代理凭借 LLM 的强大能力，模拟 MI 中的精细沟通技巧，展现出解决问题的潜力。我们的方法融合了提示工程与用户友好平台的集成，旨在实现真实且富有同理心的交流。通过一系列研究，我们专注于复制 MI 技巧及人类顾问的对话，评估虚拟代理的有效性。初步结果显示，该 LLM 驱动的虚拟代理在同理心与对话适应性上媲美人类顾问，为虚拟健康咨询领域带来突破，并深入探讨了基于 LLM 的治疗互动的设计与实施。
[Arxiv](https://arxiv.org/abs/2407.08095)
==========
# RoLoRA：通过微调无异常值的旋转 LLM，实现高效的权重-激活量化。
发布时间：2024年07月10日
`LLM理论` `人工智能` `机器学习`
> RoLoRA: Fine-tuning Rotated Outlier-free LLMs for Effective Weight-Activation Quantization
# 摘要
> LoRA 通过仅调整 LLM 中少量权重，显著提升训练效率，而近期仅权重量化技术也被用于减少 LoRA 微调的内存需求。然而，权重-激活量化在 LoRA 中的应用尚浅，主要因激活异常值导致性能下降。为此，我们提出 RoLoRA，首个基于 LoRA 的权重-激活量化方案，通过旋转消除异常值并进行旋转感知微调，保持旋转后 LLM 的无异常值特性。实验表明，RoLoRA 在低比特设置下稳定提升 LoRA 收敛及量化鲁棒性。在 LLaMA2-7B/13B 和 LLaMA3-8B 模型上，RoLoRA 在常识推理任务中较 LoRA 基线提升高达 29.5% 的精度。此外，其在大型多模态模型 LLaVA-1.5-7B 上也表现出色。代码已公开于 https://github.com/HuangOwen/RoLoRA。
[Arxiv](https://arxiv.org/abs/2407.08044)
==========
# 探索无人机语音控制：从语音识别到大型语言模型，再到直接分类与孪生网络的应用。
发布时间：2024年07月10日
`Agent` `无人机` `人机交互`
> Evaluating Voice Command Pipelines for Drone Control: From STT and LLM to Direct Classification and Siamese Networks
# 摘要
> 本文探讨了三种利用语音识别和深度学习技术控制Tello无人机的语音命令管道，旨在通过直观的语音控制提升人机交互体验。这些管道包括：传统STT结合LLM、直接语音到功能映射以及基于孪生神经网络的系统。我们基于推理时间、准确性、效率和灵活性对这些管道进行了详细评估，并提供了全面的方法论、数据集准备和评估指标，深入分析了各管道在不同应用场景中的优势和适用性。
[Arxiv](https://arxiv.org/abs/2407.08658)
==========
# EfficientQAT：为大型语言模型提供高效量化感知训练
发布时间：2024年07月10日
`LLM理论` `人工智能`
> EfficientQAT: Efficient Quantization-Aware Training for Large Language Models
# 摘要
> 大型语言模型（LLM）在现代自然语言处理和人工智能领域扮演着关键角色，但其庞大的内存需求成为一大挑战。为此，我们引入了高效量化感知训练（EfficientQAT），一种创新的量化技术，旨在压缩这些模型。EfficientQAT 通过两个连续阶段实现：首先是分块训练所有参数（Block-AP），然后是端到端训练量化参数（E2E-QP）。Block-AP 通过分块重建，逐一进行量化感知训练，避免了全模型训练的高成本。接着，E2E-QP 仅针对量化参数进行端到端训练，固定量化骨干并减少可训练参数，从而提升效率。实验结果显示，EfficientQAT 在多种模型上均超越了以往的量化方法，包括基础 LLM、指令调优 LLM 和多模态 LLM，参数规模从 7B 到 70B，量化比特数各异。例如，在单个 A100-80GB GPU 上，EfficientQAT 仅用 41 小时就完成了 2 比特 Llama-2-70B 模型的训练，精度损失控制在 3% 以内（69.48 vs. 72.41）。特别地，这个 INT2 量化的 70B 模型在内存需求减少的情况下（19.2GB vs. 24.2GB），相比 Llama-2-13B 模型，精度提升了 1.67（69.48 vs. 67.81）。相关代码已公开在 https://github.com/OpenGVLab/EfficientQAT。
[Arxiv](https://arxiv.org/abs/2407.11062)
==========
# 互联网代理网络：构建一个多元化的代理网络，以促进智能协作
发布时间：2024年07月09日
`Agent` `人工智能` `互联网`
> Internet of Agents: Weaving a Web of Heterogeneous Agents for Collaborative Intelligence
# 摘要
> 随着大型语言模型的飞速进步，高度自主的智能代理应运而生。然而，现有框架在整合第三方代理和模拟分布式环境方面存在局限，且通信方式僵化。为此，我们创新性地提出了“代理互联网”(IoA) 框架，它不仅灵活可扩展，还引入了即时通讯风格的架构和动态协作机制。实验证明，IoA 在各类任务中表现卓越，有效促进了异构代理间的协同。这一框架如同互联网般，让代理们无缝协作，共同迈向更高智能。项目代码已公开于 \url{https://github.com/OpenBMB/IoA}。
[Arxiv](https://arxiv.org/abs/2407.07061)
==========
# PEER 利用多代理框架与调优方法，精通特定领域任务。
发布时间：2024年07月09日
`Agent` `人工智能`
> PEER: Expertizing Domain-Specific Tasks with a Multi-Agent Framework and Tuning Methods
# 摘要
> 在特定领域应用中，GPT-4结合精确提示或RAG技术展现出巨大潜力，但同时也面临着性能、成本和数据隐私的三重挑战。为解决这一难题，我们创新性地提出了PEER多代理框架，通过精确问题分解、高级信息检索、全面总结和严格自我评估，系统化处理特定领域任务。面对成本和数据隐私的压力，企业正逐步从依赖GPT-4转向开发定制模型，以平衡成本、安全性和性能。我们通过利用在线数据和用户反馈，开发了高效的模型调优实践。本研究不仅为特定领域问题解决提供了多代理系统的应用指南，还为实施有效的代理调优策略提供了实证支持。特别是在金融问答领域，我们的方法不仅达到了GPT-4性能的95.0%，更在成本控制和数据隐私保护方面表现出色。
[Arxiv](https://arxiv.org/abs/2407.06985)
==========
# 假设心灵：借助大型语言模型，为多智能体任务构建心灵理论的支撑框架
发布时间：2024年07月09日
`Agent` `人工智能`
> Hypothetical Minds: Scaffolding Theory of Mind for Multi-Agent Tasks with Large Language Models
# 摘要
> 多智能体强化学习 (MARL) 在处理系统非平稳性时遇到挑战，且难以与新智能体在线适应学习。我们利用大型语言模型 (LLM) 开发了自主智能体“假设思维”，其受认知启发的架构包含感知、记忆及双层抽象规划模块。引入的“心智理论”模块通过自然语言生成其他智能体策略假设，评估并优化这些假设，以强化正确预测。在 Melting Pot 基准测试中，假设思维在竞争、混合动机及协作领域显著超越以往 LLM-智能体和 RL 基线。对比分析显示，假设评估与优化对复杂场景成功至关重要。
[Arxiv](https://arxiv.org/abs/2407.07086)
==========
# FinCon：一款集成了概念性语言强化技术的合成 LLM 多智能体系统，旨在提升财务决策的精准度。
发布时间：2024年07月09日
`Agent` `投资管理`
> FinCon: A Synthesized LLM Multi-Agent System with Conceptual Verbal Reinforcement for Enhanced Financial Decision Making
# 摘要
> 大型语言模型（LLM）在处理复杂任务方面潜力巨大，广泛应用于金融领域。然而，高质量的连续金融投资决策依然充满挑战。这些任务要求智能系统与波动市场多次互动，以最大化回报并管理风险。尽管LLM已助力开发出超越人类的投资代理系统，但通过经验改进优化决策、增强信息合成的潜力尚未充分挖掘。为此，我们推出了FinCon，一个专为金融任务设计的LLM多代理框架，融入概念性口头强化。借鉴现实投资公司的有效组织结构，FinCon采用经理-分析师沟通层级，通过自然语言实现跨职能代理的协同合作，并赋予代理更大记忆容量。框架内置风险控制机制，定期自我批评以更新投资信念，提升决策质量。这些概念化信念作为未来行为的强化，精准传递至需更新的节点，既提升性能又降低通信成本。FinCon在单一股票交易和投资组合管理等金融任务中展现出卓越的泛化能力。
[Arxiv](https://arxiv.org/abs/2407.06567)
==========
# 多模态自我指导：借助语言模型，合成抽象图像并进行视觉推理指导
发布时间：2024年07月09日
`LLM应用` `人工智能` `计算机视觉`
> Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model
# 摘要
> 当前大型多模态模型 (LMMs) 虽能理解自然场景和肖像，但对抽象图像如图表、地图的理解及视觉推理能力尚显稚嫩。它们在日常任务如读时钟、理解流程图或规划路线时往往力不从心。为此，我们设计了多模态自指导方法，结合大型语言模型与代码能力，合成日常场景中的抽象图像与视觉推理指令。我们创建的多模态基准包含 11,193 条指令，覆盖图表、表格等八种视觉场景，揭示了先进 LMMs 在抽象图像理解等方面的不足。通过使用合成数据微调 LMM，我们验证了数据质量，提升了图表理解与地图导航性能，并展示了在其他视觉推理任务中的潜力。代码已公开在 \url{https://github.com/zwq2018/Multi-modal-Self-instruct}。
[Arxiv](https://arxiv.org/abs/2407.07053)
==========
# 在非言语社交互动中，显式建模心智理论以预测信念
发布时间：2024年07月09日
`Agent` `人工智能` `社交互动`
> Explicit Modelling of Theory of Mind for Belief Prediction in Nonverbal Social Interactions
# 摘要
> 我们创新性地提出了 MToMnet，这是一种心智理论神经网络，旨在从多模态输入中预测人类社交互动中的信念及其变化。ToM 在非言语沟通和协作中扮演关键角色，但现有信念建模方法往往忽视了 ToM 的显式建模，或仅限于少数模态。MToMnet 巧妙地整合了场景视频、物体位置等上下文线索与个人注视、身体语言等特定信息，为每个人构建独立的 MindNet。借鉴社交认知与计算 ToM 的研究，我们设计了三种 MToMnet 变体，涵盖潜在表示融合与分类分数重排序等策略。在两个真实世界数据集上的评估显示，MToMnet 不仅大幅领先现有方法，且参数需求显著降低。这一成果为未来人工智能系统在非言语行为中精准预测人类信念、提升协作效率指明了光明道路。
[Arxiv](https://arxiv.org/abs/2407.06762)
==========
# Richelieu：自进化 LLM 驱动的 AI 外交智能体
发布时间：2024年07月09日
`Agent` `人工智能`
> Richelieu: Self-Evolving LLM-Based Agents for AI Diplomacy
# 摘要
> 外交，这一人类社会中的高深活动，涉及多方互动与复杂能力，如社会推理、谈判技巧和长期战略规划。尽管过往AI代理在多代理任务中展现了处理复杂游戏与广阔动作空间的能力，但外交的决策空间尤为庞大，尤其是在谈判阶段。近期，LLM代理虽在某些领域拓展了AI的边界，却仍难以应对复杂多代理环境中的长期规划。我们借助前沿LLM技术，首次尝试探索AI在高度综合多代理任务中的潜力，通过融合三大核心能力，打造更强大的社会代理：战略规划与反思、目标导向的社交谈判、以及通过自我对弈实现的无人在环自进化。
[Arxiv](https://arxiv.org/abs/2407.06813)
==========
# AnyTaskTune：借助任务微调，打造高级领域定制方案
发布时间：2024年07月09日
`LLM应用` `医疗保健`
> AnyTaskTune: Advanced Domain-Specific Solutions through Task-Fine-Tuning
# 摘要
> 大型语言模型（LLM）在各行业的广泛应用往往忽略了个人和小型组织的精细需求，这些需求更倾向于那些针对其特定业务环境精确定制的模型。为此，我们引入了**AnyTaskTune**，一种名为**任务精细微调**的新颖微调方法，旨在提升模型在多样化的特定领域任务上的性能。该方法通过细致地识别和定义领域内的目标子任务，并创建专门的增强数据集进行微调，从而优化特定任务的模型性能。我们在法律、金融、医疗保健等多个领域进行了全面的微调实验，涵盖了超过二十种不同的子任务。为了证实我们的方法并促进社区参与，我们将开源这些双语任务数据集。研究结果显示，使用**任务精细微调**方法微调的模型不仅在这些特定任务上表现卓越，而且在各自领域内显著优于具有更高通用能力的模型。我们的工作已在[GitHub](https://github.com/PandaVT/DataTager)上公开。
[Arxiv](https://arxiv.org/abs/2407.07094)
==========
# FBI-LLM：借助自回归蒸馏技术，从零起步全面扩展二值化大型语言模型。
发布时间：2024年07月09日
`LLM理论` `计算机科学` `人工智能`
> FBI-LLM: Scaling Up Fully Binarized LLMs from Scratch via Autoregressive Distillation
# 摘要
> 本研究首次展示了如何从头开始训练全二值化大型语言模型（FBI-LLM），使其性能与基于transformer的全精度LLM相媲美。通过自回归蒸馏损失，我们保持了与常规LLM相同的模型规模和数据量，同时在困惑度和任务效果上表现出色。令人惊讶的是，预训练权重并非训练二值化LLM的必需品。这一发现不仅开启了新的计算框架，还可能推动未来为1位LLM定制硬件的设计。我们公开了所有模型、代码和数据集，以促进更广泛的研究探索。
[Arxiv](https://arxiv.org/abs/2407.07093)
==========
# 将 LLM 适应于希伯来语：揭秘 DictaLM 2.0，其词汇与指令能力得到增强
发布时间：2024年07月09日
`LLM应用` `多语言技术`
> Adapting LLMs to Hebrew: Unveiling DictaLM 2.0 with Enhanced Vocabulary and Instruction Capabilities
# 摘要
> 在希伯来语等低资源语言中训练大型语言模型 (LLM) 充满挑战。本文推出了 DictaLM2.0 和 DictaLM2.0-Instruct，这两款 LLM 基于 Mistral 模型，在包含约 2000 亿词元的希伯来语和英语语料库上进行了训练。将预训练模型适应新语言需要特殊技术，这与从头开始训练或在英语等资源丰富语言上进一步训练现有模型大相径庭。我们详细介绍了这些创新的训练方法，它们有效促进了模型对希伯来语特性的学习和适应。此外，我们还对 DictaLM2.0-Instruct 进行了微调，以提升其处理特定任务指令的能力。为了全面评估我们的模型，我们创建了一套新的希伯来语 LLM 评估基准，涵盖问答、情感分析、Winograd 模式挑战、翻译和摘要等多种任务。我们的研究不仅解决了低资源语言中训练 LLM 的难题，还提出了一种通用框架，可用于将其他 LLM 适应到多种非英语语言，推动了多语言 NLP 领域的发展。
[Arxiv](https://arxiv.org/abs/2407.07080)
==========
# Lookback Lens：借助注意力图，我们能检测并缓解大型语言模型中的上下文幻觉问题。
发布时间：2024年07月09日
`LLM应用` `人工智能`
> Lookback Lens: Detecting and Mitigating Contextual Hallucinations in Large Language Models Using Only Attention Maps
# 摘要
> 大型语言模型 (LLM) 在根据文本总结或回答问题时，有时会生成与上下文不符的虚假细节。本文介绍了一种简便的上下文幻觉检测方法。我们推测，幻觉的产生与模型对原始上下文与新生成内容的注意力分配有关。据此，我们设计了一个基于注意力权重比的简单检测模型。实验表明，这种基于回溯比率的检测器（回溯镜头）不仅在不同任务间通用，还能跨模型应用，例如，一个在 7B 模型上训练的检测器可直接用于 13B 模型。此外，通过分类器引导的解码策略，我们成功减少了幻觉现象，如在 XSum 摘要任务中降低了 9.6% 的幻觉率。
[Arxiv](https://arxiv.org/abs/2407.07071)
==========
# 探索安全代码生成的提示技术：系统性研究
发布时间：2024年07月09日
`LLM应用` `软件开发` `网络安全`
> Prompting Techniques for Secure Code Generation: A Systematic Investigation
# 摘要
> 随着提示驱动编程的兴起，大型语言模型 (LLM) 在软件开发领域日益受到关注，使开发者能够通过自然语言指令编写代码。然而，这些模型生成安全代码的能力受到质疑，进而影响了提示生成软件的质量。为此，多种精心设计的提示技术应运而生，旨在从 LLM 中获取最佳响应。尽管如此，这些提示策略与安全代码生成之间的关系仍待深入探索。本研究旨在探讨不同提示技术对 LLM 生成的代码安全性的影响。我们首先进行了系统的文献回顾，筛选出适用于代码生成任务的提示技术，并在 GPT-3、GPT-3.5 和 GPT-4 模型上对其进行安全代码生成的评估。通过使用包含 150 个与安全相关的自然语言代码生成提示的数据集，我们的研究发现，通过分类和评估一系列提示技术，特别是在采用递归批评与改进 (RCI) 技术后，显著减少了测试 LLM 中的安全弱点，为 LLM 生成代码安全性的研究提供了重要见解。
[Arxiv](https://arxiv.org/abs/2407.07064)
==========
# 研究自训练方法在开放词汇时间动作定位任务中的扩展能力
发布时间：2024年07月09日
`LLM应用` `视频分析` `人工智能`
> Exploring Scalability of Self-Training for Open-Vocabulary Temporal Action Localization
# 摘要
> 时序动作定位 (TAL) 因缺乏大规模标注数据集而受限。为此，我们引入预训练视觉-语言模型 (如 CLIP) 进行开放词汇 TAL (OV-TAL)。但现有方法仍依赖小规模标注数据集。本文探索了利用未标注 YouTube 视频进行自训练的可扩展性，分两阶段：首先，训练类别无关定位器生成伪标签；然后，结合伪标签与标注数据集训练定位器。实验证明，利用网络视频自训练显著提升定位器泛化能力。同时，我们改进了评估方案。代码已发布。
[Arxiv](https://arxiv.org/abs/2407.07024)
==========
# 利用大型语言模型，从文本政策中生成健康保险的智能合约
发布时间：2024年07月09日
`LLM应用` `区块链`
> Using Large Language Models for Generating Smart Contracts for Health Insurance from Textual Policies
# 摘要
> 我们利用大型语言模型 (LLM) 从文本保险政策中自动生成健康保险流程的应用代码。选择基于区块链的智能合约，因其具备不可变性、可验证性、可扩展性和无需信任的特性。我们的方法分三个层次生成输出：(1) 文本摘要，(2) 声明性决策逻辑，(3) 带单元测试的智能合约代码。LLM 在生成文本摘要方面表现优异，结构化输出对后续验证任务至关重要。声明性语言常用于医疗政策形式化，但在区块链上执行复杂。我们尝试通过智能合约直接自动化流程。评估指标包括完整性、正确性、清晰度、语法和功能代码。实验采用三种难度递增的保险政策场景，涉及多种模型。结果显示，尽管 LLM 在生成摘要方面表现出色，但后续任务仍需人工监督，且复杂场景的挑战依然存在。实验证明了 LLM 在将文本流程转化为智能合约方面的潜力。
[Arxiv](https://arxiv.org/abs/2407.07019)
==========
# 从非结构化自然语言数据中进行端到端因果效应估计
发布时间：2024年07月09日
`LLM应用` `数据分析`
> End-To-End Causal Effect Estimation from Unstructured Natural Language Data
# 摘要
> 了解干预效果对决策至关重要，但现有因果效应估计方法依赖手动数据处理，增加了成本和时间。我们利用大型语言模型（LLM）挖掘多样化的文本数据，提出NATURAL，一种新型因果效应估计器，能在非结构化文本上运行，辅助经典因果效应计算。我们克服技术难题，如自动化数据整理和填补信息缺失。通过六个数据集（含随机对照试验），我们系统评估了NATURAL的性能，结果显示其估计值与真实情况高度一致，甚至在III/IV期临床试验中表现优异。这表明非结构化文本数据富含因果信息，NATURAL是开发自动化资源利用管道的关键一步。
[Arxiv](https://arxiv.org/abs/2407.07018)
==========
# 大型语言模型能否独步天下，预测晶体结构的合成潜力及其前驱体？
发布时间：2024年07月09日
`LLM应用` `材料科学` `人工智能`
> Is Large Language Model All You Need to Predict the Synthesizability and Precursors of Crystal Structures?
# 摘要
> 为了弥合理论设计与实际合成之间的鸿沟，我们推出了晶体合成大型语言模型（CSLLM）框架。该框架包含三个LLM，分别用于预测晶体结构的合成能力、合成方法和前驱体。我们构建了一个涵盖140,120个晶体结构的详尽数据集，并创新了一种高效的晶体结构文本表示法，以优化LLM性能。合成能力LLM以98.6%的准确率领先，显著超越了传统基于热力学和动力学稳定性的筛选方法。方法LLM分类准确率达91.02%，前驱体LLM在预测前驱体方面成功率为80.2%。此外，我们设计了一个便捷的图形界面，支持从晶体结构文件自动预测合成能力和前驱体，助力新型功能材料的快速发现。
[Arxiv](https://arxiv.org/abs/2407.07016)
==========
# 诱导头：上下文学习中模式匹配的核心机制
发布时间：2024年07月09日
`LLM理论` `人工智能`
> Induction Heads as an Essential Mechanism for Pattern Matching in In-context Learning
# 摘要
> 大型语言模型 (LLM) 通过 in-context learning (ICL) 展现了出色的学习和执行复杂任务的能力。然而，其内部机制的全面理解仍有待深入。本文深入探讨了 few-shot ICL 中 induction heads 的关键作用。我们针对 Llama-3-8B 和 InternLM2-20B 这两大顶尖模型，在抽象模式识别和 NLP 任务上进行了细致分析。结果表明，即便轻微调整 induction heads，也会导致抽象模式识别任务的 ICL 性能大幅下滑至接近随机水平，高达 ~32%。在 NLP 任务中，这种调整同样显著削弱了模型从示例中学习的能力，使得 few-shot ICL 性能与零-shot prompts 相当。此外，我们通过 attention knockout 技术，精准禁用特定 induction 模式，从而揭示了 induction 机制在 ICL 中的具体作用。
[Arxiv](https://arxiv.org/abs/2407.07011)
==========
# Metron：全面评估 LLM 推理系统性能的框架
发布时间：2024年07月09日
`LLM应用` `软件开发` `用户体验`
> Metron: Holistic Performance Evaluation Framework for LLM Inference Systems
# 摘要
> 在生产环境中部署 LLM 成本高昂，推动了推理系统优化的发展。然而，现有评估指标（如 TTFT、TBT 等）未能全面反映 LLM 推理的复杂性，导致实时应用（如聊天和翻译）的用户体验评估不完整。本文首先揭示了当前评估指标的不足，随后提出 Metron 框架，引入流动性指数这一新指标，更精准地衡量 LLM 推理对用户体验的影响。最后，我们利用 Metron 对多个开源平台和模型服务进行了评估，并分析了各自的优劣。Metron 框架已开放源代码，供业界参考使用。
[Arxiv](https://arxiv.org/abs/2407.07000)
==========
# 从对抗与分布外视角探讨鲁棒神经信息检索
发布时间：2024年07月09日
`LLM应用` `搜索引擎` `信息检索`
> Robust Neural Information Retrieval: An Adversarial and Out-of-distribution Perspective
# 摘要
> 神经信息检索模型在多种任务中的效能因最新进展而大幅提升，但其鲁棒性，即在实际应用中的可靠性，同样备受瞩目。当前，我们正处在一个整合现有研究、汲取经验并为未来铺路的黄金时期。鲁棒性不仅关乎模型抵御攻击的能力，还涉及其在分布外场景和性能波动中的表现。我们深入探讨了密集检索与神经排序模型在对抗与分布外情境下的鲁棒性策略，并详细分析了现有方法、数据集及评估标准，为大语言模型时代指明了前进方向。这是首次对神经IR模型鲁棒性进行的全面调查，我们将在SIGIR 2024上首次展示相关教程。此外，我们推出了鲁棒IR的异构评估基准BestIR，旨在为未来研究提供助力，推动可信赖搜索引擎的发展。
[Arxiv](https://arxiv.org/abs/2407.06992)
==========
# 预训练模型中的基于片段的交互式机器翻译
发布时间：2024年07月09日
`LLM应用` `机器翻译` `交互式系统`
> Segment-Based Interactive Machine Translation for Pre-trained Models
# 摘要
> 预训练的大型语言模型 (LLM) 正逐渐在众多应用中得到广泛应用。本研究聚焦于这些模型在交互式机器翻译 (IMT) 环境中的应用，特别选用了 mBART 和 mT5 进行实验。系统通过用户反馈，在每次交互中生成精准翻译。神经机器翻译 (NMT) 模型依据反馈提出初步翻译假设，用户则验证并修正单词，直至翻译准确无误。我们在基准数据集上对比了 mBART、mT5 与最先进 (SoTA) 机器翻译模型的性能，评估了用户努力、单词敲击比 (WSR)、关键敲击比 (KSR) 和鼠标动作比 (MAR)。实验显示，mBART 性能与 SoTA 模型不相上下，表明其在 IMT 领域具有应用潜力。这一发现还启示我们，为交互式环境开发新机器翻译模型时，应考虑利用这些预训练模型，它们在特定领域展现出与 SoTA 相当的性能，凸显了定制化调整的潜在优势。
[Arxiv](https://arxiv.org/abs/2407.06990)
==========
# 倾听与公平发声：探究语音集成大型语言模型中的性别语义偏见
发布时间：2024年07月09日
`LLM应用` `语音技术` `人工智能`
> Listen and Speak Fairly: A Study on Semantic Gender Bias in Speech Integrated Large Language Models
# 摘要
> SILLMs 通过结合大型语言模型与语音感知，展现了强大的通用音频理解能力，能执行从情感识别到说话者验证的多样任务。然而，这些模型可能加剧训练数据中的偏见，影响边缘化群体的信息获取。为此，我们开发了一套精选的口语偏见评估工具包及数据集，并在四个语义相关任务中检测了性别偏见。研究发现，偏见程度与语言及评估方法密切相关。这些发现强调了多角度评估 SILLMs 偏见的重要性，为构建更公平的语音集成模型提供了指导。
[Arxiv](https://arxiv.org/abs/2407.06957)
==========
# ICLGuard：调控 In-Context Learning 行为，确保适用性授权
发布时间：2024年07月09日
`LLM应用` `人工智能` `网络安全`
> ICLGuard: Controlling In-Context Learning Behavior for Applicability Authorization
# 摘要
> ICL 是 LLM 的一项创新功能，允许用户无需更新模型即可执行新任务。用户通过结合少量示例和测试输入，在推理时完成任务，这种方式比传统微调更灵活。但这也带来了风险，如用户可能无限制地使用模型处理敏感内容，这可能违反政策或损害所有者利益。因此，我们提出了“适用性授权”概念和 ICLGuard 框架，帮助模型所有者控制 ICL 行为。ICLGuard 通过微调少量参数，确保 LLM 在特定数据上停用 ICL 功能，同时不影响其在其他数据上的表现和整体性能。
[Arxiv](https://arxiv.org/abs/2407.06955)
==========
# 一致性基础中的域理论 I：探讨有向完备偏序集与 Scott 的 $D_\infty$
发布时间：2024年07月09日
`LLM理论` `编程语言` `拓扑学`
> Domain theory in univalent foundations I: Directed complete posets and Scott's $D_\infty$
# 摘要
> 我们基于构造性和预测性一致基础（即同伦类型理论）开发了领域理论。我们不采用Voevodsky的命题大小调整公理，也不依赖排中律或选择公理，确保了工作的构造性。领域理论专注于有向完全偏序集（dcpos）及其间的Scott连续映射，广泛应用于编程语言语义、高类型可计算性和拓扑学等领域。在预测性基础中，我们通常采用信息系统、抽象基或形式拓扑来处理大小问题，而非直接使用dcpos和Scott连续函数。然而，在我们的类型理论方法中，我们承认dcpos可能规模庞大，并利用类型宇宙来应对这一挑战。尽管先验上可能认为dcpos的迭代构造需要不断扩大的宇宙，且在预测性上难以实现，但我们通过精确追踪类型宇宙参数，证明了这类构造在预测性环境中是可行的。特别是，我们成功地在预测性框架下重建了Scott的$D_\infty$模型，该模型用于未类型化的$λ$-演算。这一成果在Agda证明助手中得到了形式化，其自动推断宇宙级别的功能对我们的研究至关重要。
[Arxiv](https://arxiv.org/abs/2407.06952)
==========
# 场景与事件的音-语数据集综述
发布时间：2024年07月09日
`LLM应用` `音频处理` `数据科学`
> Audio-Language Datasets of Scenes and Events: A Survey
# 摘要
> 音频-语言模型 (ALM) 通过处理声音，为声音产生的事件和场景提供语言描述。随着计算能力的提升和数据集的丰富，这一领域取得了显著进展。本文聚焦于训练 ALM 所用的数据集，特别强调了利用大型、多样化数据集提升模型性能的趋势。Freesound 平台和 AudioSet 等关键资源，推动了该领域的迅猛发展。与以往侧重技术与训练细节的调查不同，本文对众多数据集进行了细致的分类与评估，涵盖其来源、特性及应用场景。此外，还进行了数据泄露分析，以确保数据集的完整性并减少偏差。本调查基于截至 2023 年 12 月的研究论文，未涉及此后发表的文献。
[Arxiv](https://arxiv.org/abs/2407.06947)
==========
# Jenny 和 Jingzhen，谁在数学上更胜一筹？探索大型语言模型中的刻板印象。
发布时间：2024年07月09日
`LLM应用` `社会科学` `人工智能伦理`
> Who is better at math, Jenny or Jingzhen? Uncovering Stereotypes in Large Language Models
# 摘要
> 大型语言模型 (LLM) 已被证实会传播和放大有害的刻板印象，尤其是那些不成比例地影响边缘化群体的刻板印象。为了更全面地理解这些刻板印象的影响，我们引入了 GlobalBias 数据集，该数据集包含 876k 个句子，涵盖 40 个不同的性别-种族群体及偏见文献中常用的描述符，使我们能够研究全球范围内的广泛刻板印象。我们通过困惑度直接探测一系列 LLM，以此作为代理来确定某些刻板印象在模型的内部表示中的表现方式。接着，我们根据给定的名字生成角色简介，并评估模型输出中刻板印象的普遍性。研究发现，与各种刻板印象相关的群体在模型概率和模型输出中保持一致。此外，更大的模型即使在明确指示不要这样做的情况下，也始终显示出更高水平的刻板印象输出。
[Arxiv](https://arxiv.org/abs/2407.06917)
==========
# 大型语言模型中的宗教：探讨其偏见、刻板印象、污名化及情感表达
发布时间：2024年07月09日
`LLM应用` `社会文化`
> Divine LLaMAs: Bias, Stereotypes, Stigmatization, and Emotion Representation of Religion in Large Language Models
# 摘要
> 情感不仅揭示我们的价值观，还指导我们的行动，在我们的生活中扮演着至关重要的角色。研究发现，LLMs在情感归属上存在性别偏见，而宗教作为社会文化体系，为其追随者规定了信仰和价值观，培养特定情感。我们通过情感归属分析了LLMs中不同宗教的表现，发现美国和欧洲的主要宗教表现出更多细微差别，而东方宗教如印度教和佛教则被刻板化，犹太教和伊斯兰教则被污名化。这归因于LLMs中的文化偏见和关于宗教的NLP文献稀缺。在极少数讨论宗教的情况下，它往往与有毒语言相关联，加剧了这些宗教本质上是有毒的看法。这一发现强调了迫切需要解决和纠正这些偏见。我们的研究再次证明了情感在我们生活中的关键作用以及我们的价值观如何影响它们。
[Arxiv](https://arxiv.org/abs/2407.06908)
==========
# 众包噪声标签学习：信号处理新视角
发布时间：2024年07月09日
`LLM应用` `人工智能` `机器学习`
> Learning From Crowdsourced Noisy Labels: A Signal Processing Perspective
# 摘要
> AI与ML的迅猛发展得益于海量精选数据集的普及。众包作为一种常见手段，将数据分发给众多标注者，其产出标签随后融合，支撑下游学习与推理任务。然而，由于标注者专业性或可靠性不足等原因，此过程常产生噪声标签。因此，众包的核心任务之一便是研发策略，有效缓解标签噪声对学习任务的负面影响。本文聚焦于从噪声众包标签中学习的最新进展，涵盖从经典统计模型到深度学习方法的关键众包模型及其方法论，强调分析洞察与算法创新。特别地，本文探讨了信号处理理论与方法，如张量与非负矩阵分解的可识别性，以及针对众包长期难题的新颖解决方案，揭示了信号处理视角如何引领该领域的前进。同时，本文还触及了强化学习中的人类反馈（RLHF）与直接偏好优化（DPO）等前沿议题，这些技术对于微调大型语言模型（LLMs）至关重要。
[Arxiv](https://arxiv.org/abs/2407.06902)
==========
# 通过 Few-Shot Learning 评估 ESG 基金披露的可持续性意图
发布时间：2024年07月09日
`LLM应用` `可持续发展`
> Measuring Sustainability Intention of ESG Fund Disclosure using Few-Shot Learning
# 摘要
> 全球可持续基金领域涵盖了声称专注于环境、社会和治理（ESG）的开放式基金和交易所交易基金（ETF）。然而，这些声明的真实性需通过文本披露的审查来验证。目前，ESG产品领域缺乏强制性的可持续性法规。本文提出了一种新颖的方法和系统，旨在通过分析招股说明书中的语言具体性和透明度，对可持续基金进行分类和评分。我们利用少量样本学习技术，识别与可持续投资相关的具体、模糊或通用语言，并构建比率指标来评分和评级，以量化可持续性声明并优化产品排名。此外，我们在Hugging Face上发布了超过1K的ESG文本声明的手动注释数据集，供研究使用。实验表明，少量样本微调技术在处理未见过的ESG语言时，性能显著优于零样本模型。本文旨在为可持续基金的可持续性意图提供一种量化评估的系统化方法，帮助监管机构、投资者和顾问更有效地筛选和评估ESG基金。
[Arxiv](https://arxiv.org/abs/2407.06893)
==========
# 不仅仅是美学：探讨文本到图像模型中的文化素养
发布时间：2024年07月09日
`LLM应用` `文化艺术` `人工智能`
> Beyond Aesthetics: Cultural Competence in Text-to-Image Models
# 摘要
> 文本到图像（T2I）模型在全球多元社区中日益流行，它们为各自独特的文化创造了视觉表现。然而，当前的T2I基准主要关注生成图像的忠实度、美学和真实感，却忽视了文化能力这一关键维度。为此，我们引入了一个框架，用于评估T2I模型在文化意识和文化多样性这两个关键维度上的文化能力，并提出了一种可扩展的方法，结合结构化知识库和大型语言模型构建了一个大型文化文物数据集，以支持这种评估。特别是，我们应用这种方法构建了CUBE（文本到图像模型的文化基准），这是首个评估T2I模型文化能力的基准。CUBE涵盖了与8个不同地理文化区域的国家的文化文物，涉及三个概念：美食、地标和艺术。CUBE包括1）CUBE-1K，一组高质量的提示，用于评估文化意识；2）CUBE-CSpace，一个更大的文化文物数据集，用于评估文化多样性。我们还引入了文化多样性作为T2I评估的新组件，利用质量加权的Vendi得分。我们的评估揭示了现有模型在各国文化意识方面的显著差距，并为未明确提示的T2I输出提供了关于文化多样性的宝贵见解。我们的方法可扩展到其他文化区域和概念，有助于开发更好地服务于全球人口的T2I模型。
[Arxiv](https://arxiv.org/abs/2407.06863)
==========
# Safe-Embed：揭秘句子编码器的安全核心知识
发布时间：2024年07月09日
`LLM应用` `网络安全` `人工智能`
> Safe-Embed: Unveiling the Safety-Critical Knowledge of Sentence Encoders
# 摘要
> 尽管大型语言模型 (LLM) 在多任务处理中表现出色，但其对不安全提示的敏感性仍是一个棘手问题。这些提示可能诱导 LLM 生成涉及非法或敏感话题的内容，严重威胁其安全与伦理应用。现有解决方案虽尝试通过分类模型应对，却存在诸多不足。随着不安全提示的日益复杂，基于相似性搜索的技术因其能精准识别不安全特征，成为解决这一难题的更佳途径。本文探讨了句子编码器在区分安全与不安全提示方面的潜力，并评估了其依据安全分类法对不安全提示进行分类的能力。我们创新性地引入了成对数据集和分类纯度 (CP) 指标以量化这一能力。研究结果不仅展示了现有句子编码器的成效与局限，更为提升其作为高效安全检测器的性能指明了改进方向。相关代码已公开于 https://github.com/JwdanielJung/Safe-Embed。
[Arxiv](https://arxiv.org/abs/2407.06851)
==========
# Chat-Edit-3D：借助文本提示实现互动式3D场景编辑
发布时间：2024年07月09日
`LLM应用` `3D建模` `计算机视觉`
> Chat-Edit-3D: Interactive 3D Scene Editing via Text Prompts
# 摘要
> 近期，基于视觉-语言预训练模型的图像内容操作技术已成功应用于文本驱动的3D场景编辑。尽管如此，现有3D场景编辑方案仍存在局限，如固定输入模式限制了用户灵活性，单一2D视觉模型制约了编辑能力，且复杂的集成设计增加了难度。为此，我们推出了基于对话的3D场景编辑方法CE3D，该方法依托大型语言模型，支持用户自由文本输入并智能解读意图，自动调用相应视觉模型。我们还创新性地采用Hash-Atlas技术，将3D场景编辑简化为2D图集图像操作，实现了2D编辑与3D重建的彻底分离，使CE3D能灵活整合各类2D或3D视觉模型，无需复杂融合设计。实验证实，CE3D能有效集成多视觉模型，实现丰富编辑效果，展现出卓越的场景理解和多轮对话能力。代码已公开，详见<a href="https://sk-fun.fun/CE3D">此链接</a>。
[Arxiv](https://arxiv.org/abs/2407.06842)
==========
# VRDSynth：助力多语言视觉丰富文档信息提取的程序合成工具
发布时间：2024年07月09日
`LLM应用`
> VRDSynth: Synthesizing Programs for Multilingual Visually Rich Document Information Extraction
# 摘要
> 企业决策常需查询视觉丰富的文档，如收据、医疗记录和保险表格。现有技术在处理新布局时力不从心，或需大量预训练数据。我们推出的VRDSynth，无需预训练，能自动从多语言VRD中提取实体关系。为应对VRD的复杂性，我们设计了专门的领域语言（DSL），捕捉空间与文本关系，并结合新的合成算法，提升覆盖率。在FUNSD和XFUND基准测试中，VRDSynth在多语言环境下表现卓越，尤其在英语中，F1分数提升显著。我们还通过自动表格识别增强了VRDSynth，使其在多语言比较中脱颖而出。此外，VRDSynth在内存效率上亦有显著优势，同时保持了高效的时间性能。
[Arxiv](https://arxiv.org/abs/2407.06826)
==========
# AI撰写的文件，律师们总觉得不靠谱：探讨律师对LLM与人类作者文件的偏好差异
发布时间：2024年07月09日
`LLM应用` `人工智能`
> It Cannot Be Right If It Was Written by AI: On Lawyers' Preferences of Documents Perceived as Authored by an LLM vs a Human
# 摘要
> 大型语言模型（LLM）预示着一个未来，其中某些法律文件可能实现自动化生成。这不仅有望简化法律流程、降低服务成本，还能大幅提升司法可及性。尽管众多研究者致力于开发和评估基于LLM的法律应用，但鲜有研究探讨法律专业人士对AI生成内容的看法。这一视角至关重要，因为过度依赖或无端怀疑可能影响这些文件的法律效力。本研究深入探讨了75名律师对法律文件的感知，分析了他们基于文件来源（人工或AI）的不同评价。结果显示，律师们更偏爱人工制作的文件，尽管他们也期待未来文件的自动化生成。这些见解为法律界、政策制定者及立法者提供了宝贵的参考，有助于他们负责任地采纳新技术，并推动法律流程的现代化改革。
[Arxiv](https://arxiv.org/abs/2407.06798)
==========
# 借助预训练的LLM和提示工程技术，我们能够高效解答生物医学领域的疑问。
发布时间：2024年07月09日
`LLM应用` `生物医学` `问答系统`
> Using Pretrained Large Language Model with Prompt Engineering to Answer Biomedical Questions
# 摘要
> 我们团队参与了 BioASQ 2024 的 Task12b 和 Synergy 任务，目标是打造一个能够从 PubMed 数据库中检索相关资料并生成精准答案的生物医学问答系统。我们设计了一个基于预训练 LLM 的两级检索与问答架构，特别注重提示工程和响应优化。通过构建含少量示例的上下文提示，并采用重采样和异常响应检测等技术，我们评估了 Mixtral、OpenAI GPT 和 Llama2 等多种 LLM 模型在此任务中的表现。最终，我们的系统在文档和片段检索、是/否问题、事实问题及列表问题等多个指标上均取得了优异成绩。
[Arxiv](https://arxiv.org/abs/2407.06779)
==========
# 图查询语言的关系视角探析
发布时间：2024年07月09日
`LLM理论` `数据库` `图数据库`
> Relational Perspective on Graph Query Languages
# 摘要
> 我们探讨了图数据库查询的关系视角，这一视角虽为多种图数据库系统的基础，但理论研究甚少。该视角构建了一个强大且统一的框架，用于研究图数据库查询，其算法与复杂性源自经典理论。我们展示了两个具体应用：  首先，我们查询属性图。属性图数据模型超越了以往的图模型，并支撑了新的图查询语言标准GQL。我们证明，该标准主要可通过关系演算的扩展来表达，包括传递闭包算子（FO[TC]）和存在二阶量词（ESO），从而获得最优数据复杂度界限及模式验证等扩展。  其次，我们将具体领域数据（如数字）融入图数据库查询。利用嵌入的有限模型理论及FO[TC]和ESO的通用受限量词崩溃（RQC）结果，我们为含算术与比较的GQL设定了最优数据复杂度界限。同时，我们揭示了在嵌入有限图上，通过数据操作的常规数据路径查询可在FO[TC]中实现，且保持非确定性对数空间的数据复杂度。
[Arxiv](https://arxiv.org/abs/2407.06766)
==========
# 借助 LVLM 的多模态表示学习在视觉地点识别中的应用
发布时间：2024年07月09日
`LLM应用` `计算机视觉` `自动驾驶`
> LVLM-empowered Multi-modal Representation Learning for Visual Place Recognition
# 摘要
> 视觉地点识别（VPR）因视角和外观的显著变化而充满挑战。主流方法通过将深度特征转化为鲁健紧凑的全局表示来应对。然而，在复杂条件下，这些方法难以取得理想效果。我们另辟蹊径，尝试通过融合图像与场景描述的文本，构建更具辨别力的全局表示。这一创新基于两大动机：一是大型视觉-语言模型（LVLMs）在视觉指令跟随中展现出卓越能力，能高效生成图像描述；二是文本描述提供的高级场景理解对环境变化具有强鲁棒性。尽管前景光明，但高效融合多模态数据仍是一大挑战，且LVLMs生成的描述可能存在不准确性。为此，我们提出了一种创新的多模态VPR方案。该方案首先利用预训练的视觉与语言模型提取图像和文本特征，再通过特征组合器相互增强。特征组合器核心包括令牌级注意力块和交叉注意力融合模块，前者根据文本与图像的相关性自适应调整，后者高效跨模态传播信息。最终，增强的多模态特征被压缩成特征描述符，用于检索。实验表明，我们的方法在更小的图像描述符维度下，显著超越了现有技术。
[Arxiv](https://arxiv.org/abs/2407.06730)
==========
# 一种基于角色安全和权限级别，结合检索增强生成或专家混合技术的企业级大型语言模型应用简易架构。
发布时间：2024年07月09日
`LLM应用`
> A Simple Architecture for Enterprise Large Language Model Applications based on Role based security and Clearance Levels using Retrieval-Augmented Generation or Mixture of Experts
# 摘要
> 本研究设计了一种简洁的企业应用架构，专为大型语言模型（LLM）在基于角色的安全性和北约清关级别上使用。该架构旨在克服当前LLM在安全和信息访问管理上的不足。它兼容检索增强生成（RAG）和专家模型混合（MoE）的微调，可单独或组合使用。通过用户的角色和安全级别，对RAG文档和MoE专家进行筛选，有效防止信息泄露。
[Arxiv](https://arxiv.org/abs/2407.06718)
==========
# 探索 DenseQuest：专为挑选自定义集合的最佳密集检索器而设计的系统
发布时间：2024年07月09日
`LLM应用` `信息检索` `云计算`
> Embark on DenseQuest: A System for Selecting the Best Dense Retriever for a Custom Collection
# 摘要
> 本次演示介绍了一款基于网络的应用，名为 DenseQuest，专为选择适用于私有数据集的预训练密集检索器而设计。DenseQuest 通过无监督选择与排序，从众多密集检索器中精准预测最适合特定上传数据集的选项。它融合了多种先进技术，包括一种无需查询或相关性判断、由大型语言模型驱动的高效方法。系统界面直观易用，旨在帮助信息检索领域的工程师和研究者快速找到适合新私有数据集的通用密集检索模型。演示中还展示了系统在云端的架构及多种应用场景，确保了广泛的可访问性和实用性。DenseQuest 系统可通过 https://densequest.ielab.io 访问。
[Arxiv](https://arxiv.org/abs/2407.06685)
==========
# SoftDedup：加速语言模型预训练的高效数据重加权方法
发布时间：2024年07月09日
`LLM理论` `人工智能` `数据处理`
> SoftDedup: an Efficient Data Reweighting Method for Speeding Up Language Model Pre-training
# 摘要
> 大型语言模型 (LLM) 常因预训练数据集中的重复数据而受限。传统方法侧重于简单地检测和移除重复，这不仅可能遗失重要信息，还忽视了重复程度的多变性。为此，我们创新性地提出了软去重策略，既保护数据完整性，又智能降低高频重复数据的采样权重。核心在于我们首创的“数据共性”指标，通过 n-gram 模型量化样本重复度。实证表明，此法大幅提升训练效率，减少至少 26% 的训练步骤，同时困惑度得分相当。更妙的是，同等训练下，下游任务的少样本准确率提升 1.77%。即便在严格去重的数据集上，性能依然提升，预示着其有望成为 LLM 预训练的新标准。
[Arxiv](https://arxiv.org/abs/2407.06654)
==========
# 熵定律揭秘：数据压缩与大型语言模型性能的内在联系
发布时间：2024年07月09日
`LLM理论` `数据科学` `机器学习`
> Entropy Law: The Story Behind Data Compression and LLM Performance
# 摘要
> 数据虽为大型语言模型的基石，但并非所有数据皆具价值。精选数据能更有效地激发模型潜能，同时大幅降低计算成本。当前方法多聚焦于单个样本质量评估，却忽视了样本间的组合效应。即便单个样本质量上乘，其组合可能因内在同质性或矛盾而影响模型教学效果。本文旨在探索模型性能与数据选择间的深层联系。受模型信息压缩特性启发，我们揭示了“熵定律”，将模型性能与数据压缩比及首轮训练损失相联系，分别反映数据冗余与知识掌握程度。理论与实证研究显示，模型性能与数据压缩比呈负相关，常伴随较低训练损失。基于此，我们提出高效通用的数据选择方法**ZIP**，优先选取低压缩比数据子集。借助多阶段贪婪算法选择多样化数据，我们得以构建兼具满意多样性的优质数据子集。广泛实验验证了熵定律及ZIP方法在不同模型架构与训练阶段的优势。此外，熵定律的应用还能在训练初期预警潜在性能风险。
[Arxiv](https://arxiv.org/abs/2407.06645)
==========
# 视觉语言模型如同失明一般。
发布时间：2024年07月09日
`LLM应用` `计算机视觉` `人工智能`
> Vision language models are blind
# 摘要
> 尽管具有视觉能力的大型语言模型（如 GPT-4o 和 Gemini 1.5 Pro）在图像-文本应用和视觉理解基准测试中表现出色，但它们在处理一些对人类而言极其简单的视觉任务时却表现糟糕。例如，这些模型无法准确识别两个圆是否重叠、两条线是否相交、单词中哪个字母被圈出，或计算类似奥运标志中圆圈的数量。这表明，这些模型的视觉能力可能仅限于模糊地识别细节，甚至可能像一个聪明但失明的人在猜测。相关代码已公开，详情请访问：https://vlmsareblind.github.io/
[Arxiv](https://arxiv.org/abs/2407.06581)
==========
# 借助丰富的背景故事，为语言模型赋予生动的虚拟角色。
发布时间：2024年07月09日
`LLM应用` `行为研究` `社会科学`
> Virtual Personas for Language Models via an Anthology of Backstories
# 摘要
> 大型语言模型 (LLM) 汲取了数百万作者的丰富文本，展现了人类特质的多样性。虽然这些模型有望在行为研究中模拟人类，但先前的工作在使模型响应与个体用户匹配方面存在局限。为此，我们提出了 "Anthology" 方法，通过开放式的生活叙事（即 "背景故事"）来定制 LLM 的虚拟人格。实验表明，这种方法不仅提升了实验结果的一致性和可靠性，还更好地代表了多样化的子群体。在皮尤研究中心的三项全国代表性调查中，Anthology 在匹配人类响应分布和提高一致性方面分别实现了 18% 和 27% 的提升。相关代码和背景故事已公开在 https://github.com/CannyLab/anthology。
[Arxiv](https://arxiv.org/abs/2407.06576)
==========
# 融合知识图谱与大型语言模型
发布时间：2024年07月09日
`LLM应用` `人工智能`
> Combining Knowledge Graphs and Large Language Models
# 摘要
> 近年来，NLP 在 AI 应用中扮演了关键角色，如聊天机器人和语言翻译。LLM 的崛起显著提升了这些应用的性能，尤其在语言理解和生成方面。然而，LLM 仍面临幻觉和领域知识不足等挑战，这些问题可通过结合知识图谱（KGs）来缓解，KGs 以结构化方式捕捉实体间关系。LLM 与 KGs 的互补性推动了两者结合的趋势，以提升 AI 应用的可靠性。本研究分析了 28 篇相关论文，系统比较了基于 KG 的 LLM、LLM 驱动的 KGs 及混合方法，旨在为新入行的研究人员和希望深化理解 LLM 与 KGs 结合策略的学者提供全面视角，揭示关键趋势、创新技术及共同挑战。
[Arxiv](https://arxiv.org/abs/2407.06564)
==========
# OffsetBias：借助去偏数据优化评估器调整
发布时间：2024年07月09日
`LLM应用` `人工智能` `数据科学`
> OffsetBias: Leveraging Debiased Data for Tuning Evaluators
# 摘要
> 利用 LLM 评估生成内容的质量，如通过提示调整模型或微调评判模型，已成为主流评估手段。然而，这些评估工具易受偏见影响，比如偏爱长篇大论。尽管解决这一问题至关重要，但偏见的具体表现仍待深入探究。本研究中，我们识别了六类判断模型中的固有偏见，并创建了 EvalBiasBench 作为针对这些偏见的定制测试集。同时，我们提出了去偏数据集构建法及配套的 OffsetBias 偏好集。实验显示，基于我们的数据集进行微调能大幅提升评判模型的抗偏见能力，并优化其在多场景下的表现。我们已将相关数据集和微调模型公开。
[Arxiv](https://arxiv.org/abs/2407.06551)
==========
# LETS-C：借助语言嵌入技术，革新时间序列分类方法
发布时间：2024年07月09日
`LLM应用` `时间序列分析` `机器学习`
> LETS-C: Leveraging Language Embedding for Time Series Classification
# 摘要
> 近期，语言模型在处理时间序列数据方面展现出显著成效。特别是，通过微调预训练的大型语言模型（LLM）进行时间序列分类，已在多项基准测试中达到顶尖水平。但这些模型因庞大的参数规模（数百万可训练参数）而显得笨重。为此，我们提出新策略：采用语言嵌入模型处理时间序列，并结合卷积神经网络（CNN）与多层感知器（MLP）构成的简洁分类头。实验证明，LETS-C不仅在准确度上超越现有最佳模型，更以平均仅14.5%的参数量，实现了轻量化。这表明，结合语言编码器与高效分类头，是实现高效且轻巧时间序列分类的可行路径。
[Arxiv](https://arxiv.org/abs/2407.06533)
==========
# 多语言融合：评估 LLM 安全对齐与语言混合
发布时间：2024年07月09日
`LLM应用` `人工智能` `语言处理`
> Multilingual Blending: LLM Safety Alignment Evaluation with Language Mixture
# 摘要
> 在大型语言模型（LLMs）的开发过程中，安全性始终是核心关注点。为此，研究者和业界专家正日益致力于确保LLM行为符合人类偏好与伦理标准。LLMs通过广泛的多语言数据训练，展现出跨语言和领域的强大泛化能力。然而，当前的安全对齐措施主要针对单一语言场景，其在复杂多语言环境中的效果，尤其是混合语言格式，尚未得到充分研究。本研究提出了“多语言混合”策略，通过混合语言的查询-响应模式，评估在复杂多语言环境下，如GPT-4o、GPT-3.5和Llama3等先进LLMs的安全对齐情况。我们深入探讨了语言可用性、形态学和语言家族等因素如何影响多语言混合策略的有效性。实验表明，缺乏精心设计的提示模板时，多语言混合会显著加剧恶意查询的风险，导致安全对齐的绕过率大幅上升（GPT-3.5为67.23%，GPT-4o为40.34%），远超单一语言场景。此外，不同语言的内在属性也影响多语言混合的表现，形态学和语言家族的差异使得某些语言更易规避安全对齐。这些发现凸显了在多语言复杂环境中评估和优化LLMs安全对齐策略的重要性，以充分发挥其跨语言泛化能力。
[Arxiv](https://arxiv.org/abs/2407.07342)
==========
# MixSumm：利用 LLM 为低资源抽取式文本摘要提供主题基础的数据增强方法
发布时间：2024年07月09日
`LLM应用` `文本摘要` `数据增强`
> MixSumm: Topic-based Data Augmentation using LLMs for Low-resource Extractive Text Summarization
# 摘要
> 低资源抽取式文本摘要是一个关键但研究不足的领域。以往研究多聚焦于生成式摘要或直接利用大型模型如GPT-3生成摘要。我们提出MixSumm，通过提示开源模型LLaMA-3-70b生成混合多主题的文档，而非单一主题，进而训练摘要模型。我们采用ROUGE评分和基于LLaMA-3的无参考评估方法L-Eval来评估摘要质量。在包含TweetSumm、WikiHow和ArXiv/PubMed的挑战性基准测试中，我们的数据增强框架显著超越了现有提示方法。此外，实验还验证了从LLaMA-3-70b到小型BERT抽取式摘要器的知识有效转移。
[Arxiv](https://arxiv.org/abs/2407.07341)
==========
# 双重推理大型语言模型助力可解释的差异诊断
发布时间：2024年07月09日
`LLM应用` `人工智能`
> Interpretable Differential Diagnosis with Dual-Inference Large Language Models
# 摘要
> 在临床推理和决策支持应用中，自动化生成鉴别诊断（DDx）至关重要。然而，为DDx提供解释更具价值。得益于大型语言模型（LLMs）的强大语言处理能力，我们探索了其在此领域的应用。我们首先创建了一个包含570份临床笔记的DDx数据集，并附有专家解释。接着，我们提出了Dual-Inf框架，使LLMs能够进行双向推理，从而提供解释。评估结果显示，Dual-Inf在预测和解释诊断方面表现出色，性能提升显著，且在罕见疾病诊断方面展现出潜力。
[Arxiv](https://arxiv.org/abs/2407.07330)
==========
# 大型语言模型中的同质性偏见，其脆弱性在不同化的概率中显露无疑。
发布时间：2024年07月09日
`LLM理论` `人工智能` `社会科学`
> Probability of Differentiation Reveals Brittleness of Homogeneity Bias in Large Language Models
# 摘要
> 大型语言模型 (LLM) 存在同质化偏差，即倾向于将某些群体的表征与其他群体同质化。以往研究多使用编码器模型，可能无意中引入了偏差。为此，我们让 GPT-4 根据 18 个情境线索生成单字/表达完成，并比较其变异性，直接从模型输出评估同质化偏差，绕过了编码器模型。研究发现，同质化偏差在不同情境线索和提示中波动大，暗示过去的偏差研究可能更多反映了编码器模型的偏差而非 LLM。此外，提示的微小变化就能显著影响偏差表达，显示 LLM 中的同质化偏差较为脆弱。未来研究应深入探讨长文本生成中句法和主题选择的变化如何影响 LLM 的同质化偏差。
[Arxiv](https://arxiv.org/abs/2407.07329)
==========
# 探究前沿大型语言模型在环境审查文件理解中的表现：RAG 与长上下文的对比研究
发布时间：2024年07月09日
`LLM应用` `环境政策`
> RAG vs. Long Context: Examining Frontier Large Language Models for Environmental Review Document Comprehension
# 摘要
> 大型语言模型（LLM）已广泛应用于多个领域的研究问题。其中，LLM 构建的问答系统能够服务于不同领域的用户。在流行和公共领域（如琐事和文学）中，基于 LLM 的问答系统已证明其有效性。然而，在需要专业知识的特定领域，其表现尚未得到充分验证。为此，我们创建了 NEPAQuAD1.0 基准，旨在评估 Claude Sonnet、Gemini 和 GPT-4 这三个前沿 LLM 在处理来自美国联邦政府根据《国家环境政策法》(NEPA) 编写的环境影响声明中的问题时的表现。我们特别关注 LLM 在不同情境下理解 NEPA 文件中法律、技术和合规信息的细微差别的能力。通过无上下文的问题测试 LLM 的 NEPA 知识，并评估其综合长文档上下文以辅助问答的能力。结果显示，RAG 驱动模型在回答准确性上显著优于长上下文模型，尤其是在处理封闭式问题时表现更佳。
[Arxiv](https://arxiv.org/abs/2407.07321)
==========
# CosmoCLIP：拓展大型视觉-语言模型至天文影像领域
发布时间：2024年07月09日
`LLM应用` `天文学` `机器学习`
> CosmoCLIP: Generalizing Large Vision-Language Models for Astronomical Imaging
# 摘要
> 现有的视觉-文本对比学习模型通过匹配图像与标题的嵌入并分离无关对来提升表示的可迁移性，支持零-shot预测。然而，天文图像-标签数据集规模远小于互联网上的通用数据集。为此，我们推出了CosmoCLIP，一个基于SpaceNet和BLIP标题的预训练CLIP模型的天文图像-文本对比学习框架。SpaceNet包含约13,000张分布优化的图像，而BLIP则作为知识丰富的提取器。通过对比学习这些描述中的丰富语义，CosmoCLIP在多种任务中展现出卓越的泛化能力。实验结果显示，CosmoCLIP框架简洁高效，在零-shot分类和图像-文本检索任务中大幅超越CLIP。
[Arxiv](https://arxiv.org/abs/2407.07315)
==========
# ESM+：探索大规模语言模型时代下文本到SQL评估的新视角
发布时间：2024年07月09日
`LLM应用` `数据库`
> ESM+: Modern Insights into Perspective on Text-to-SQL Evaluation in the Age of Large Language Models
# 摘要
> Text-to-SQL 任务让用户能用自然语言从 SQL 数据库中提取信息。尽管挑战重重，基于 LLM 的模型在此领域已取得显著进步。值得注意的是，未经微调的 LLM 模型展现出与微调模型不同的特性，使得现有评估指标难以准确衡量其性能。为此，我们深入分析了 EXE 和 ESM 两大评估指标，并提出了改进版 ESM+，以提升评估的稳定性。实验表明，相较于 EXE 和原始 ESM 的高误报率和漏报率，ESM+ 的误报和漏报率大幅降低至 0.1% 和 2.6%。我们已将 ESM+ 脚本开源，期待社区共同参与，共同推动 Text-to-SQL 评估的可靠性。
[Arxiv](https://arxiv.org/abs/2407.07313)
==========
# ViTime：一款基于视觉智能的时间序列预测基础模型
发布时间：2024年07月09日
`LLM应用` `时间序列分析` `人工智能`
> ViTime: A Visual Intelligence-Based Foundation Model for Time Series Forecasting
# 摘要
> 大型预训练模型在NLP和CV领域的成功，为TSF基础模型的构建带来了新思路。传统TSF模型依赖数值拟合，而人脑则擅长通过视觉序列预测未来。从仿生学视角看，直接处理数值序列可能并非AGI的最佳路径。本文提出的ViTime模型，通过视觉数据处理和创新的数据合成方法RealTS，突破了数值拟合的限制。实验显示，ViTime在多个新数据集上实现了顶尖的零-shot性能，甚至在某些情况下超越了最佳监督模型。这表明视觉智能能大幅提升时间序列分析与预测，为更先进、多功能的模型开辟了道路。ViTime框架代码已公开在https://github.com/IkeYang/ViTime。
[Arxiv](https://arxiv.org/abs/2407.07311)
==========
# CPU环境下大型语言模型的推理性能优化
发布时间：2024年07月09日
`LLM应用` `计算机硬件` `软件优化`
> Inference Performance Optimization for Large Language Models on CPUs
# 摘要
> 大型语言模型（LLM）在多任务中表现卓越，但在资源有限的环境中部署高性能LLM备受关注。面对GPU资源限制，我们转向CPU寻求解决方案。本文提出一种简便的推理性能优化方案，旨在CPU上加速LLM，通过精简KV缓存同时保持精度。我们采用分布式推理优化策略，并依托oneAPI集体通信库实现。此外，针对常用模型进行定制优化，相关代码已在GitHub开源，地址为https://github.com/intel/xFasterTransformer。
[Arxiv](https://arxiv.org/abs/2407.07304)
==========
# 大型语言模型助力放射治疗中治疗目标体积的自动勾画
发布时间：2024年07月09日
`LLM应用` `人工智能`
> Large Language Model-Augmented Auto-Delineation of Treatment Target Volume in Radiation Therapy
# 摘要
> 放射治疗（RT）作为癌症治疗的有效手段，其成功关键在于目标的精准描绘。然而，这一过程目前仍依赖于专家的手动操作，不仅耗时费力，还存在观察者间的差异。尽管AI技术在正常组织自动描绘方面取得了显著进展，但RT目标体积的准确描绘仍面临挑战。为此，我们研发了Radformer，一种基于视觉语言模型的自动描绘网络。Radformer采用层次化视觉变换器架构，并融入大型语言模型，从临床数据中提取丰富文本特征。通过视觉语言注意力模块（VLAM），Radformer能有效整合视觉与语言信息，实现语言感知的视觉编码。在包含2985名头颈癌患者的RT数据集上，Radformer的性能通过DSC、IOU和HD95等指标进行了定量评估，结果显示其分割性能优于现有顶尖模型，展现了在RT实践中的广阔应用前景。
[Arxiv](https://arxiv.org/abs/2407.07296)
==========
# ConvNLP：探索基于图像的AI文本检测技术
发布时间：2024年07月09日
`LLM应用` `人工智能`
> ConvNLP: Image-based AI Text Detection
# 摘要
> 生成式AI技术，如大型语言模型（LLMs），在革新教育领域的潜力受到其滥用导致的伦理问题的削弱，这加剧了学术不诚实的问题。LLMs如GPT-4和Llama 2在生成复杂内容和回答问题方面变得越来越强大，从撰写学术论文到解决复杂数学问题。学生依赖这些LLMs完成作业，从而损害了学术诚信。检测LLM生成文本的解决方案计算密集且往往缺乏泛化能力。本文提出了一种新颖的方法，使用词嵌入的视觉表示来检测LLM生成的AI文本。我们设计了一种新颖的卷积神经网络，称为ZigZag ResNet，以及一个名为ZigZag Scheduler的调度器，以提高泛化能力。通过使用由六种不同最先进的LLMs生成的文本数据集进行广泛评估，我们的模型展示了强大的域内和域间泛化能力。我们的最佳模型在域内和域间测试数据上的平均检测率达到了88.35%。通过详尽的消融研究，我们的ZigZag ResNet和ZigZag Scheduler相比原始ResNet提供了近4%的性能提升。我们的模型的端到端推理延迟每句话低于2.5毫秒。我们的解决方案提供了一种轻量级、计算高效且更快的替代方案，用于检测AI生成的文本，具有更好的泛化性能。它可以帮助学术机构在学术环境中对抗LLMs的滥用。通过这项工作，我们旨在保护学术诚信的原则，并确保在先进LLMs时代学生工作的可信度。
[Arxiv](https://arxiv.org/abs/2407.07225)
==========
# 大型语言模型在可穿戴传感器领域的人类活动识别、健康监测及行为建模中的应用：探索早期发展、数据集及面临的挑战
发布时间：2024年07月09日
`LLM应用` `可穿戴技术`
> Large Language Models for Wearable Sensor-Based Human Activity Recognition, Health Monitoring, and Behavioral Modeling: A Survey of Early Trends, Datasets, and Challenges
# 摘要
> 随着可穿戴技术的兴起，海量传感器数据为健康监测、活动识别和个性化医疗带来了新机遇。然而，这些数据的复杂性和规模也给数据建模和分析带来了挑战，这些挑战通过时间序列建模和深度学习等技术得到了解决。当前，大型语言模型（LLMs）如GPT-4和Llama正被用于通过可穿戴传感器数据分析、建模和理解人类行为。本调查深入探讨了LLMs在基于传感器的活动识别和行为建模中的应用趋势和挑战。我们分析了可穿戴传感器数据的特性，LLMs的建模能力及其局限，以及它们与传统机器学习技术的结合。同时，我们也指出了数据质量、计算需求、可解释性和隐私等关键问题。通过案例研究，我们展示了LLMs在提升可穿戴传感器数据分析和解释能力方面的潜力。最后，我们提出了未来研究方向，强调预处理技术的改进、模型效率和可扩展性的提升，以及跨学科合作的重要性。本调查旨在全面概述可穿戴传感器数据与LLMs的融合，为这一新兴领域的发展提供洞见。
[Arxiv](https://arxiv.org/abs/2407.07196)
==========
# TrackFormers：探索高亮度LHC时代基于Transformer的粒子跟踪技术
发布时间：2024年07月09日
`LLM应用` `高能物理` `机器学习`
> TrackFormers: In Search of Transformer-Based Particle Tracking for the High-Luminosity LHC Era
# 摘要
> 随着高能物理实验的每一次迭代，数据量激增，高亮度LHC升级亦是如此。这一趋势迫使数据处理流程的每个环节都需重新考量，尤其是粒子轨迹重建（跟踪）这一环节。机器学习辅助方案有望大幅提升效率，因为跟踪中最耗时的环节正是命中点与粒子或轨迹候选的匹配。本文即聚焦于此。我们借鉴大型语言模型的思路，探索了两种策略：预测轨迹中的下一个命中点，以及一次性预测整个事件的命中点。通过深入设计，我们测试了基于Transformer的三种模型和基于U-Net的一种模型，针对碰撞事件的命中点进行轨迹关联预测。评估过程中，我们从简单到复杂逐步推进，及时淘汰表现不佳的设计。实验结果详尽，涵盖预测准确性与计算效率。我们借助REDVID模拟框架及TrackML数据集的简化处理，构建了五个难度递增的数据集进行实验。结果表明，不同设计在预测准确性和计算性能上各有千秋，凸显了我们方法的高效性。尤为关键的是，实验证实了一次性编码器-分类器基于Transformer方案在跟踪任务中的实用性。
[Arxiv](https://arxiv.org/abs/2407.07179)
==========
# 大型语言模型存在偏见，更偏爱自身生成的内容。
发布时间：2024年07月09日
`LLM应用` `人工智能` `社会科学`
> AI AI Bias: Large Language Models Favor Their Own Generated Content
# 摘要
> 我们通过模拟就业歧视研究的实验设计，测试了 GPT-3.5 和 GPT4 等 LLM 在二选一情境下的偏好。结果发现，这些 AI 系统在相同条件下更偏爱由自己生成的内容而非人类创作的，这可能意味着 AI 在无形中对人类存在偏见，从而获得不公平的优势。
[Arxiv](https://arxiv.org/abs/2407.12856)
==========
# GenArtist：一款多模态 LLM，作为统一图像生成与编辑的智能代理
发布时间：2024年07月08日
`Agent` `图像处理` `人工智能`
> GenArtist: Multimodal LLM as an Agent for Unified Image Generation and Editing
# 摘要
> 尽管现有图像生成和编辑技术已取得一定成就，但面对复杂文本提示等难题，以及缺乏验证和自校正机制，现有模型仍显不足。此外，单一模型往往局限于特定任务，难以全面满足用户需求。为此，我们推出了GenArtist系统，该系统由多模态大型语言模型（MLLM）代理统一调度，集成了广泛的现有模型工具库。面对复杂任务，MLLM代理能将其拆解为简单子问题，并构建树状结构，系统化地规划生成、编辑及自校正流程，每一步都经过严格验证。通过自动补全位置相关输入并融入位置信息，系统能精准选用工具，高效解决各子问题。实验结果显示，GenArtist在多种生成和编辑任务中表现卓越，性能超越了SDXL和DALL-E 3等现有模型，详情可见图1。项目详情页：https://zhenyuw16.github.io/GenArtist_page。
[Arxiv](https://arxiv.org/abs/2407.05600)
==========
# 随机循环向量在多标签学习中的应用
发布时间：2024年07月08日
`LLM应用` `机器学习` `数据挖掘`
> Multi-label Learning with Random Circular Vectors
# 摘要
> 极端多标签分类 (XMC) 任务旨在训练一个分类器，从庞大的标签库中筛选出与特定数据最匹配的标签子集。尽管深度神经网络 (DNNs) 在此领域已取得显著成就，但面对海量输出标签，DNN 的训练成本依然高昂。本文提出了一种创新方法，利用随机圆形向量（每个分量以复数振幅表示）来优化这一难题。在我们的框架下，通过构建一个全连接的最终输出层，直接预测低维圆形向量，该向量编码了数据实例的标签集，从而为 DNN 设计了适用于 XMC 的输出层和损失函数。实验表明，圆形向量在标签编码和检索方面优于传统实值向量。进一步在真实 XMC 数据集上的测试证实，圆形向量的这些优势不仅显著提升了任务性能，还将输出层规模缩减了高达 99%。
[Arxiv](https://arxiv.org/abs/2407.05656)
==========
# GenFollower：借助大型语言模型提升车辆跟随预测的精准度
发布时间：2024年07月08日
`LLM应用` `交通管理` `自动驾驶`
> GenFollower: Enhancing Car-Following Prediction with Large Language Models
# 摘要
> 在交通管理和自动驾驶领域，准确模拟跟车行为至关重要。然而，现有方法常受限于对数据质量的敏感和缺乏解释性。为此，我们研发了 GenFollower，一种利用大型语言模型的零-shot 提示技术，将跟车行为转化为语言模型问题，并整合多源输入至结构化提示中。实验表明，GenFollower 不仅提升了预测准确性，还增强了模型的解释力，为理解跟车行为提供了新视角，推动了交通管理与自动驾驶技术的发展。
[Arxiv](https://arxiv.org/abs/2407.05611)
==========
# 极弱监督下的开放世界多标签文本分类
发布时间：2024年07月08日
`LLM应用` `文本分类` `数据挖掘`
> Open-world Multi-label Text Classification with Extremely Weak Supervision
# 摘要
> 在极弱监督下，我们探索了开放世界的多标签文本分类，用户仅提供简要描述而无需任何标签。我们发现多数文档有一个主导类，而长尾标签偶尔也会成为主导。基于此，我们利用用户描述引导大型语言模型提取关键词，通过聚类构建标签空间，并运用零-shot分类器精确定位文档，以发现更多长尾标签。这一迭代过程最终形成了X-MLClass方法，显著提升了标签空间覆盖率，如在AAPD数据集上提升了40%，并实现了顶尖的多标签分类准确性。
[Arxiv](https://arxiv.org/abs/2407.05609)
==========
# 揭秘气候谣言的生成式方法
发布时间：2024年07月08日
`LLM应用` `气候变化` `信息安全`
> Generative Debunking of Climate Misinformation
# 摘要
> 气候变化错误信息带来的负面影响众多，亟需纠正。心理学研究虽提供了减少其影响的策略，如“事实-神话-谬误-事实”结构，但大规模实施纠正措施仍具挑战。本研究探索了通过自动检测与纠正错误信息来应对这一问题，开发了能接受气候神话输入并按“真相三明治”结构生成反驳的大型语言模型。我们融合了开放与专有LLM，并运用多样的提示策略进行实验，发现结合结构化提示的GPT-4和Mixtral性能显著。同时，我们揭示了反驳生成及评估的难题，并指明了未来研究方向。此外，我们公开了高质量反驳数据集、源码及系统演示，以供进一步探索与应用。
[Arxiv](https://arxiv.org/abs/2407.05599)
==========
# iLLM-TSC：融合强化学习与大型语言模型，优化交通信号控制策略
发布时间：2024年07月08日
`LLM应用` `智能交通系统`
> iLLM-TSC: Integration reinforcement learning and large language model for traffic signal control policy improvement
# 摘要
> 城市拥堵问题依旧严峻，而交通信号控制（TSC）被视为一种有力对策。尽管RL已被证实有效，但现有基于RL的TSC系统常忽视通信退化导致的不完美观察及奖励函数未涵盖的罕见事件。为此，我们创新性地结合LLM与RL，旨在填补奖励函数中的空白并优化RL策略。在我们的方法中，RL先基于数据做决策，LLM则评估其合理性，必要时进行调整。此集成方法无需修改即可融入现有TSC系统。测试表明，在通信退化环境下，我们的方法使平均等待时间减少了17.5%，凸显了其在智能交通系统中推广RL应用的潜力。相关代码详见\url{https://github.com/Traffic-Alpha/iLLM-TSC}。
[Arxiv](https://arxiv.org/abs/2407.06025)
==========
# ANOLE 是一个开放且自回归的原生大型多模态模型，专为交错图像与文本生成而设计。
发布时间：2024年07月08日
`LLM应用` `人工智能` `开源软件`
> ANOLE: An Open, Autoregressive, Native Large Multimodal Models for Interleaved Image-Text Generation
# 摘要
> 先前的开源大型多模态模型存在一些问题，如缺乏原生集成、仅支持单模态生成，以及依赖独立扩散模型进行视觉处理。为此，我们推出了 Anole，这是一个开放、自回归的原生多模态模型，专为图像与文本交错生成设计。基于 Meta AI 的 Chameleon，我们采用了一种创新的微调方法，既高效利用数据又节省参数。Anole 能够生成高质量且连贯的多模态内容。我们已将模型、训练框架及调优数据全部开源。
[Arxiv](https://arxiv.org/abs/2407.06135)
==========
# 通过跨域少样本上下文学习提升交通标志识别能力
发布时间：2024年07月08日
`LLM应用` `自动驾驶`
> Cross-domain Few-shot In-context Learning for Enhancing Traffic Sign Recognition
# 摘要
> 近期，多模态大型语言模型如GPT-4o和GPT-4v在自动驾驶领域展现出显著潜力。本文提出了一种基于MLLM的跨领域少样本上下文学习策略，旨在提升交通标志识别（TSR）能力。我们首先构建了一个基于Vision Transformer Adapter的交通标志检测网络，并设计了一个提取模块，从原始道路图像中精准提取交通标志。为减少对大量训练数据的依赖，并增强跨领域TSR的稳定性，我们创新性地引入了基于MLLM的跨领域少样本上下文学习技术。此外，为进一步提升MLLM对交通标志的细粒度识别能力，我们利用模板交通标志生成富含形状、颜色及构成等关键信息的描述文本，有效激发MLLM对细粒度交通标志类别的感知力。通过这些描述文本，我们成功缩小了模板与实际交通标志间的跨领域差异。值得一提的是，我们的方法仅需简单统一的文本指示，无需庞大的交通标志图像库和标签集。我们在德国、比利时的标准数据集以及日本的真实世界数据集上进行了详尽评估，实验结果表明，我们的方法在TSR性能上取得了显著提升。
[Arxiv](https://arxiv.org/abs/2407.05814)
==========
# 多模态大型语言模型在医学图像与自由文本报告数据挖掘中的应用潜力
发布时间：2024年07月08日
`LLM应用` `人工智能`
> Potential of Multimodal Large Language Models for Data Mining of Medical Images and Free-text Reports
# 摘要
> 医学图像与放射报告对诊断至关重要，定量分析在此尤为关键。然而，数据多样性与跨源异质性对现有数据挖掘方法的泛化能力构成挑战。多模态大型语言模型（MLLMs）如Gemini与GPT-4，已在多个领域引发变革，医疗领域亦受其深远影响。本研究全面评估了Gemini、GPT-4及四款流行大型模型在14个医学影像数据集上的表现，涵盖五类影像（皮肤病、放射、牙科、眼科、内窥镜）及三类报告数据集，涉及疾病分类、病变分割、解剖定位、疾病诊断、报告生成与病变检测等多项任务。实验显示，Gemini系列在报告生成与病变检测上表现卓越，但在疾病分类与解剖定位上存在挑战；GPT系列则在病变分割与解剖定位上表现优异，但在疾病诊断与病变检测上遇到难题。此外，Gemini与GPT系列均有模型展现出高效的生成能力。尽管这些模型有望减轻医生负担、缓解医疗资源压力并促进医工合作，但在临床应用前，仍需进行重大改进与全面验证。
[Arxiv](https://arxiv.org/abs/2407.05758)
==========
# 视觉-语言模型中的多对象幻觉现象
发布时间：2024年07月08日
`LLM应用` `计算机视觉` `人工智能`
> Multi-Object Hallucination in Vision-Language Models
# 摘要
> 大型视觉语言模型 (LVLMs) 常因对象幻觉而产生图像中不存在的对象。本研究深入探讨了多对象幻觉现象，特别是在模型同时处理多个对象时可能出现的误感知问题。为此，我们提出了基于识别的对象探测评估 (ROPE)，一种自动化评估方法，它考虑图像内对象类别的分布，并通过视觉指向提示来减少歧义。实证研究表明：(1) LVLMs 在处理多对象时幻觉更频繁。(2) 对象类别的分布影响幻觉行为，暗示模型可能依赖捷径和虚假相关性。(3) 幻觉行为受数据特性和模型内在因素的影响。我们旨在提升 LVLMs 对现实场景中多对象的识别与推理能力，并量化我们在解决幻觉问题上的进展。
[Arxiv](https://arxiv.org/abs/2407.06192)
==========
# Video-STaR：通过自训练，视频指令调优可利用任意监督方式进行。
发布时间：2024年07月08日
`LLM应用` `视频处理` `人工智能`
> Video-STaR: Self-Training Enables Video Instruction Tuning with Any Supervision
# 摘要
> 大型视觉语言模型 (LVLMs) 的性能受其训练数据集的大小和质量影响。现有视频指令调优数据集因依赖于通过视频字幕生成问答对而缺乏多样性，多为描述性内容。同时，虽有许多标记视频数据集具备多样标签和监督，但其整合至 LVLMs 并非简单任务。为此，我们首创了增强推理的视频自训练方法 (Video-STaR)，它允许利用任何标记视频数据集进行指令调优。Video-STaR 通过在指令生成与微调间循环，不仅提升视频理解能力，还能使模型适应新下游任务。在生成阶段，模型提出答案后，仅保留含原始视频标签的答案进行再训练，以此利用现有视频标签作为弱监督。实验显示，Video-STaR 增强的 LVLMs 在一般视频问答中性能提升显著，如 TempCompass 性能提高 10%，在下游任务如 Kinetics700-QA 准确性提升 20%，FineDiving 动作质量评估提升 15%。
[Arxiv](https://arxiv.org/abs/2407.06189)
==========
# CrowdMoGen：引领零-Shot 文本驱动的集体运动创新
发布时间：2024年07月08日
`LLM应用` `城市规划`
> CrowdMoGen: Zero-Shot Text-Driven Collective Motion Generation
# 摘要
> 人群运动生成在娱乐和战略领域至关重要，如动画、游戏、城市模拟和规划。这一新任务要求在特定约束下精细整合控制与生成，以真实合成人群动态，其挑战尚待深入探索。现有模型多关注个体行为，忽视集体复杂性；而多人运动生成方法则依赖预设场景，局限于固定少数互动，实用性受限。为此，我们推出CrowdMoGen框架，借助大型语言模型（LLM），将集体智慧融入生成过程，实现无需配对数据的泛化人群运动规划与生成。框架包含两大核心组件：人群场景规划器，根据场景或扰动协调运动；集体运动生成器，高效合成集体运动。实验证明，该框架不仅填补了关键技术空白，提供可扩展、可泛化解决方案，更实现了高度真实与灵活性。
[Arxiv](https://arxiv.org/abs/2407.06188)
==========
# 文化与包容视角下的视觉语言模型研究
发布时间：2024年07月08日
`LLM应用` `辅助技术` `多元文化`
> Vision-Language Models under Cultural and Inclusive Considerations
# 摘要
> 大型视觉-语言模型（VLMs）能通过描述日常图像辅助视障人士。然而，现有评估数据集未能充分体现多元文化背景和实际使用情境。为此，我们设计了一项调查以了解字幕偏好，并基于VizWiz数据集（由盲人拍摄的图像组成）构建了一个文化导向的评估基准。随后，我们对多个VLMs进行了评估，探究其在多元文化环境中的可靠性。尽管最先进模型的表现令人鼓舞，但我们也发现了幻觉现象和自动评估与人类判断不一致等问题。所有相关资源，包括调查、数据、代码及模型输出，均已公开。
[Arxiv](https://arxiv.org/abs/2407.06177)
==========
# 加速语言模型评估之道
发布时间：2024年07月08日
`LLM理论` `计算机科学` `人工智能`
> On Speeding Up Language Model Evaluation
# 摘要
> 大型语言模型（LLM）在自然语言处理（NLP）领域独领风骚，横扫各类任务的顶尖水平。然而，从训练到推理的每一步，都需精心抉择，构成一场复杂的组合搜索。例如，为求任务之巅，我们常需在全测试集上逐一试炼预训练模型、提示语及超参数。此番全面评估，既耗时又耗资，因LLM的推理与评估皆需大量资源。本文直面这一挑战，旨在有限预算内寻觅最佳评估之道。我们巧妙运用多臂老虎机框架，循序渐进地挑选待评对，结合多臂老虎机算法与低秩分解，大幅削减资源需求。实验证明，我们的算法仅以5-15%的常规资源，便能慧眼识珠，将成本削减至85-95%。
[Arxiv](https://arxiv.org/abs/2407.06172)
==========
# 大型语言模型所编代码，问题何在？深入探究。
发布时间：2024年07月08日
`LLM应用` `软件开发` `人工智能`
> What's Wrong with Your Code Generated by Large Language Models? An Extensive Study
# 摘要
> 大型语言模型（LLMs）在代码生成领域的迅猛发展备受瞩目。为提升其代码生成能力，研究重点多放在高质量数据集的收集与多样化训练技术的应用上。然而，现有方法的局限性却鲜有深入探讨。为此，我们展开了一项全面实证研究，对比了三大闭源与四大开源LLM在常用基准上的表现。研究发现，这些模型在应对复杂问题时，生成的代码虽短却更复杂，且与标准方案存在差距。我们还构建了错误分类体系，深入剖析了常见错误的根源。为更贴近实际应用，我们精心设计了包含140项任务的实战基准，揭示了实际与理论基准间的错误分布差异。最终，我们创新提出了一种无需额外训练的迭代方法，通过自我批判机制，使模型能根据错误类型与编译反馈自我修正。实验显示，该方法能大幅降低错误率，两次迭代后通过率提升29.2%，展现了LLM在处理复杂问题上的广阔前景。
[Arxiv](https://arxiv.org/abs/2407.06153)
==========
# 通过语法掩蔽技术，我们确保了 LLM 建模任务中的句法正确性。
发布时间：2024年07月08日
`LLM应用` `软件工程` `人工智能`
> Using Grammar Masking to Ensure Syntactic Validity in LLM-based Modeling Tasks
# 摘要
> 我们提出了一种名为“语法掩蔽”的方法，旨在引导大型语言模型（LLM）生成符合特定上下文无关语法的正确模型。尽管少样本学习或引导等提示工程方法能提高LLM生成正确语法的几率，但随着语法复杂度的增加，这些方法的效率和效果都会大打折扣。以往研究多聚焦于语言模型训练或提示工程。本研究则通过约束解码，将模型输出限定在特定语法范围内，确保输出语法的正确性。我们利用MontiCore构建的多种DSL，并测试了多个LLM在有无约束解码情况下的表现。通过解析器验证模型语法的正确性，结果显示，语法掩蔽能显著提升LLM的建模能力，降低对精细提示的依赖，并提高生成正确模型的概率。
[Arxiv](https://arxiv.org/abs/2407.06146)
==========
# 探究 LLM 在数据可视化领域对自然语言表达的语义解析能力
发布时间：2024年07月08日
`LLM应用` `数据可视化` `人工智能`
> Evaluating the Semantic Profiling Abilities of LLMs for Natural Language Utterances in Data Visualization
# 摘要
> 自动生成数据可视化以响应人类对数据集的表述，需要深入理解数据表述的语义，包括对数据属性的隐含和显式引用、可视化任务及数据准备步骤。尽管数据可视化的自然语言接口（NLIs）已探索推断此类信息的方法，但人类语言的不确定性仍带来挑战。大型语言模型（LLMs）的最新进展为解决这些挑战提供了可能，但其提取相关语义信息的能力尚未明确。本研究评估了四个公开可用的LLMs（GPT-4、Gemini-Pro、Llama3和Mixtral），探讨它们在不确定性存在时理解表述的能力，并识别相关数据上下文和可视化任务。研究发现，LLMs对表述中的不确定性敏感，但仍能提取相关数据上下文，而在推断可视化任务方面则面临挑战。基于此，我们提出了利用LLMs进行可视化生成的未来研究方向。
[Arxiv](https://arxiv.org/abs/2407.06129)
==========
# 利用大型语言模型，结合文本与视听信息，精准检测与分析抑郁症
发布时间：2024年07月08日
`LLM应用` `人工智能`
> Depression Detection and Analysis using Large Language Models on Textual and Audio-Visual Modalities
# 摘要
> 抑郁症已成为影响深远的公共卫生难题，对个体心理健康造成严重冲击。未被识别的抑郁症可能引发一系列严重健康问题，甚至导致自杀。传统上，抑郁症的诊断依赖于半结构化访谈和补充问卷，如患者健康问卷（PHQ），这些方法高度依赖医生的专业判断，易受个人偏见影响。由于抑郁症的内在机制尚在探索中，医生在早期诊断和治疗时面临诸多挑战。近年来，人工神经计算在处理文本、图像和语音等多领域问题方面取得显著进展。我们利用这些尖端模型进行实验，旨在通过多模态分析实现更优结果。实验基于2019年音频/视觉情感挑战（AVEC）中的扩展困境分析访谈语料库（E-DAIC）。我们的解决方案通过专有和开源大型语言模型（LLMs）在文本模态上实现了3.98的RMSE，超越了AVEC 2019的基线和现有SOTA回归架构。此外，分类任务的准确率达到了71.43%。论文还介绍了一种创新的音频-视觉多模态网络，能够以6.51的RMSE预测PHQ-8分数。
[Arxiv](https://arxiv.org/abs/2407.06125)
==========
# 人工直觉：科学摘要的高效分类
发布时间：2024年07月08日
`LLM应用` `科学研究` `信息管理`
> Artificial Intuition: Efficient Classification of Scientific Abstracts
# 摘要
> 为了战略洞察或研究组合管理，对短科学文本进行粗略分类是理想的。这些文本高效地向专家传递密集信息，但因其简短和缺乏上下文，自动化难度大。为此，我们创新了一种方法，生成并分配领域特定标签。通过LLM，我们模拟了人类直觉的补充知识增强过程，并设计了工作流程。试点研究中，我们采用NASA的资助摘要语料库，并结合传统性能指标，开发了新的评估工具。
[Arxiv](https://arxiv.org/abs/2407.06093)
==========
# 融合、集成与协作：大型语言模型时代协同策略探析
发布时间：2024年07月08日
`LLM理论` `人工智能`
> Merge, Ensemble, and Cooperate! A Survey on Collaborative Strategies in the Era of Large Language Models
# 摘要
> 大型语言模型（LLM）的卓越成就引领自然语言处理（NLP）研究进入新纪元。尽管LLM能力各异，但不同语料库训练的模型各有千秋，这为提升其整体效能和灵活性带来挑战。为此，近期研究聚焦于LLM间的协作策略。本文全面梳理这一前沿领域，阐释协作的深层动机。我们将其策略细分为合并、集成与合作三大类：合并通过参数融合多模型，集成整合各模型输出，合作则让不同模型在特定任务中各展所长。我们深入剖析这些策略，并展望其应用前景。同时，勾勒未来研究蓝图，期望推动LLM协作研究，助力NLP技术飞跃。
[Arxiv](https://arxiv.org/abs/2407.06089)
==========
# 当不确定性来袭，语言模型从循环往复走向“哎呀”时刻，探索其在未知中的回退策略。
发布时间：2024年07月08日
`LLM理论` `人工智能`
> From Loops to Oops: Fallback Behaviors of Language Models Under Uncertainty
# 摘要
> 大型语言模型（LLM）常出现幻觉和序列重复等不良行为。我们将其视为模型在不确定性下的回退，并探究其关联。我们将这些行为分为序列重复、退化文本和幻觉，并在不同预训练程度和参数量的模型中深入分析。实验显示，LLM越先进（训练更多、参数更多、指令调优），其回退行为依次从序列重复转为退化文本，再到幻觉。即使在最佳模型中，随着不确定性上升，生成顺序也从幻觉变为退化文本，最终是序列重复。此外，我们发现随机采样等解码技术虽能减轻序列重复，却可能增加难以察觉的幻觉。
[Arxiv](https://arxiv.org/abs/2407.06071)
==========
# Vision-Braille：一款端到端的中文盲文图像转文本工具
发布时间：2024年07月08日
`LLM应用` `特殊教育` `辅助技术`
> Vision-Braille: An End-to-End Tool for Chinese Braille Image-to-Text Translation
# 摘要
> 视觉障碍者依赖盲文进行读写，但特殊教育资源的匮乏成为他们教育的瓶颈。教育公平是社会文明与个人尊严的体现，改善他们的学习渠道至关重要。由于缺乏精准的盲文翻译系统，尤其是中文中的声调标记问题，视力正常的教师难以理解他们的盲文作业。过去的算法在提取上下文信息方面表现不佳，导致翻译准确性低下。本项目通过微调mT5模型，成功创建了盲文到中文的转换系统，显著提高了翻译的清晰度，验证集和测试集的BLEU分数分别达到了62.4和62.3。这一创新系统不仅为视觉障碍学生及其家庭提供了便利，助力他们实现大学梦想，也是首个公开可用的盲文翻译工具。我们的主页上提供了演示，欢迎体验。
[Arxiv](https://arxiv.org/abs/2407.06048)
==========
# MST5 —— 知识图谱上的多语言问答系统
发布时间：2024年07月08日
`LLM应用` `知识图谱`
> MST5 -- Multilingual Question Answering over Knowledge Graphs
# 摘要
> 知识图谱问答 (KGQA) 利用自然语言简化了海量知识的查询过程，但研究多聚焦于英语，对非英语使用者不利。现有多语言 KGQA 系统在性能上难以匹敌英语系统，凸显了多语言生成 SPARQL 查询的挑战。本研究提出一种简化方法，通过直接整合语言上下文和实体信息至语言模型处理流程，增强多语言 KGQA 系统。我们采用单一预训练多语言变压器模型，统一处理主输入与辅助数据，显著提升自然语言到 SPARQL 查询的转换准确性。该方法在最新 QALD 数据集上表现优异，并首次在中文和日语上进行评估，拓宽了数据集的语言多样性。
[Arxiv](https://arxiv.org/abs/2407.06041)
==========
# PAS：一款数据高效、即插即用的提示增强系统
发布时间：2024年07月08日
`LLM应用` `人工智能` `软件开发`
> PAS: Data-Efficient Plug-and-Play Prompt Augmentation System
# 摘要
> 随着大型语言模型（LLM）的兴起，即插即用AI系统的需求日益增长。在众多AI技术中，提示工程尤为关键。然而，用户在编写提示时往往面临学习难度大和时间成本高的问题，现有的自动提示工程（APE）模型也难以操作。为此，我们推出了PAS，一个基于LLM的即插即用APE系统。PAS通过在高质量自动生成的提示互补数据集上训练LLM，展现出卓越性能。在全面基准测试中，PAS超越以往APE模型，平均提升6.09分，且仅需9000数据点即可达到顶尖性能。PAS还能自主生成提示增强数据，无需额外人力，并兼容所有LLM，适用于多种任务。在人类评估中，PAS表现优异，凸显其作为用户插件的优越性。PAS集高性能、高效率与灵活性于一身，极大地提升了LLM的可用性与效果，是改进提示工程的宝贵工具。
[Arxiv](https://arxiv.org/abs/2407.06027)
==========
# 系统2向系统1的精炼转化
发布时间：2024年07月08日
`LLM理论` `人工智能` `机器学习`
> Distilling System 2 into System 1
# 摘要
> 大型语言模型在推理时通过额外计算生成中间思维，从而提升最终响应质量。自 Chain-of-Thought 提出后，多种 System 2 技术如 Rephrase and Respond、System 2 Attention 和 Branch-Solve-Merge 相继涌现。本研究探索自监督方法，将这些 System 2 技术的高质量输出提炼回 LLM，无需中间推理步骤，因为推理已融入 System 1。实验表明，这些技术提炼后不仅性能提升，且推理成本降低。我们预见，这种 System 2 提炼将成为未来 AI 系统持续学习的关键，使其能更高效地运用 System 2 能力于尚需改进的推理任务。
[Arxiv](https://arxiv.org/abs/2407.06023)
==========
# Igea：专为意大利语生物医学文本生成设计的解码器语言模型
发布时间：2024年07月08日
`LLM应用` `生物医学`
> Igea: a Decoder-Only Language Model for Biomedical Text Generation in Italian
# 摘要
> 领域特定语言模型在生物医学等专业领域的自然语言处理应用中取得了显著进展，但多聚焦于英语模型，忽视了资源较少的语言如意大利语。本文引入了Igea，首个专为意大利语生物医学文本生成设计的仅解码器语言模型。基于Minerva模型，并在丰富的意大利医学文本上持续预训练，Igea提供三种规模：3.5亿、10亿和30亿参数，旨在兼顾计算效率与性能，应对意大利语医学术语的独特挑战。我们通过结合专业与通用评估基准，验证了Igea在特定训练后仍能有效保留通用知识。本文详细探讨了Igea的开发与评估，为意大利生物医学NLP的未来发展奠定了基础。
[Arxiv](https://arxiv.org/abs/2407.06011)
==========
# 从感知到信念：探究大型语言模型中心智理论的先导推断
发布时间：2024年07月08日
`LLM理论` `人工智能` `心理学`
> Perceptions to Beliefs: Exploring Precursory Inferences for Theory of Mind in Large Language Models
# 摘要
> 人类自然地发展出理解他人心理状态和信念的心智理论 (ToM)，但大型语言模型 (LLM) 在这方面表现不佳。我们通过评估 LLM 中的关键 ToM 先驱——感知推理和感知到信念推理，来深化对 LLM 的 ToM 能力的理解。为此，我们创建了两个数据集，Percept-ToMi 和 Percept-FANToM，分别注释角色的感知，以评估这些先驱推理。评估显示，LLM 在感知推理上表现良好，但在感知到信念推理上能力有限。基于此，我们提出了 PercepToM，一种结合 LLM 强大感知推理能力并增强其感知到信念推理的新方法。实验证明，PercepToM 显著提升了 LLM 在错误信念场景中的性能。
[Arxiv](https://arxiv.org/abs/2407.06004)
==========
# 探究人类与 LLM 对话中的心理模型及毒性源头
发布时间：2024年07月08日
`LLM应用` `人工智能` `社会科学`
> Exploring Human-LLM Conversations: Mental Models and the Originator of Toxicity
# 摘要
> 本研究深入探讨了人类在自由多样的环境中与大型语言模型（LLM）的互动，与以往专注于特定任务的道德修剪模型研究形成鲜明对比。我们旨在揭示毒性内容的根源。研究发现，虽然LLM常被指责传播有害信息，但这往往源于人类的需求或至少是他们的挑衅。通过手动分析数百个被标记为有毒的对话，我们质疑了当前拒绝回答用户请求的做法。此外，基于多项实证数据，我们推测人类在与LLM互动时，心理模式正从机器互动转向更接近人类互动。
[Arxiv](https://arxiv.org/abs/2407.05977)
==========
# LLaMAX：拓展LLM的语言边界，强化超百种语言的翻译实力
发布时间：2024年07月08日
`LLM应用` `多语言处理`
> LLaMAX: Scaling Linguistic Horizons of LLM by Enhancing Translation Capabilities Beyond 100 Languages
# 摘要
> 在高资源语言任务中，大型语言模型（LLMs）的翻译能力令人瞩目，但在低资源语言中，由于预训练数据不足，性能受限。为此，我们投入大量资源，对LLaMA系列模型进行多语言持续预训练，支持百余种语言的翻译。通过优化训练策略，如词汇扩展和数据增强，我们打造了LLaMAX。LLaMAX不仅保持了强大的泛化能力，还在翻译性能上大幅超越现有开源LLMs，与专业翻译模型在Flores-101基准上不相上下。实验证实，LLaMAX可作为稳健的多语言基础模型。相关代码和模型已公开，供公众使用。
[Arxiv](https://arxiv.org/abs/2407.05975)
==========
# 探索优化与评估：结合 LLM 与人工反馈的增强型检索问答聊天机器人
发布时间：2024年07月08日
`LLM应用` `人力资源` `人工智能`
> Towards Optimizing and Evaluating a Retrieval Augmented QA Chatbot using LLMs with Human in the Loop
# 摘要
> 我们与SAP SE的专家携手，打造了一款HR支持聊天机器人，旨在高效解决员工疑问。在开发过程中，我们在数据集构建、提示优化及输出评估等环节融入了人工参与。此举不仅提升了聊天机器人的回复质量，还探索了新的检索策略，使之成为HR领域高效、灵活且可扩展的利器。实验表明，GPT-4凭借其卓越性能和内部推理能力，有效应对了数据不一致的挑战。同时，G-Eval和Prometheus等无参考评估指标，经专家验证，其可靠性已接近人类评估水平。
[Arxiv](https://arxiv.org/abs/2407.05925)
==========
# 利用大型语言模型生成并去识别化印度临床出院总结
发布时间：2024年07月08日
`LLM应用` `数据安全`
> Generation and De-Identification of Indian Clinical Discharge Summaries using LLMs
# 摘要
> 医疗数据泄露的后果对患者、提供者和支付者都可能是毁灭性的，平均财务影响近1000万美元。在印度，快速数字化与数据治理程序的建立并行，这对医疗机构尤为关键。去标识化系统易受数据漂移影响，跨机构应用时常无效。因此，对现有去标识化系统进行严格评估，以支持印度数字健康举措的安全采用至关重要。本研究利用印度医疗机构提供的去标识化患者出院总结，揭示了基于非印度数据集训练的去标识化算法在跨机构泛化上的不足。同时，现成的去标识化系统也存在潜在风险。为解决数据稀缺问题，我们通过在大语言模型上进行上下文学习，生成合成临床报告，实验证明这是一种有效策略，可创建具有良好泛化能力的高性能去标识化系统。
[Arxiv](https://arxiv.org/abs/2407.05887)
==========
# KG-FPQ：通过基于知识图的错误前提问题，评估 LLM 中的事实性幻觉问题。
发布时间：2024年07月08日
`LLM应用` `知识图谱` `人工智能`
> KG-FPQ: Evaluating Factuality Hallucination in LLMs with Knowledge Graph-based False Premise Questions
# 摘要
> 最新研究发现，大型语言模型 (LLMs) 易受错误前提问题 (FPQs) 影响，产生事实幻觉。现有评估方法因手动构建而受限。为此，我们开发了基于知识图谱 (KGs) 的自动化流程，首先修改真实三元组创造错误前提，再利用 GPT 生成语义丰富的 FPQs。我们提出的 KG-FPQ 基准涵盖约 178k 个 FPQs，跨越三个领域，六个混淆级别，两种任务格式。通过 KG-FPQ，我们对多个 LLMs 进行了深入评估，并揭示了关键见解。KG-FPQ 数据集和代码已公开，详见 https://github.com/yanxuzhu/KG-FPQ。
[Arxiv](https://arxiv.org/abs/2407.05868)
==========
# 借助mllm-NPU，实现设备上LLM每秒高效预填充1000个令牌。
发布时间：2024年07月08日
`LLM应用` `移动应用` `人工智能`
> Empowering 1000 tokens/second on-device LLM prefilling with mllm-NPU
# 摘要
> 设备上的大型语言模型（LLM）正推动着创新的移动应用，如界面任务自动化和个性化邮件自动回复，同时保护用户隐私。然而，这些模型仍受困于过长的推理延迟，尤其是在首次生成令牌时。为了解决这一难题，我们推出了mllm-NPU，这一开创性的LLM推理系统巧妙地利用了设备上的神经处理单元（NPU）。mllm-NPU通过算法与系统的深度融合，有效弥合了LLM架构与现代NPU设计间的语义鸿沟。它通过三个层面的创新重构提示与模型：首先，在提示层面，将可变长度提示分割为固定大小块，保持数据依赖；其次，在张量层面，识别并并行处理关键异常值，降低开销；最后，在块层面，根据硬件特性与准确性需求，灵活调度Transformer块。相较于现有技术，mllm-NPU在预填充速度上提升了22.4倍，能耗节省达30.7倍，实际应用中加速高达32.8倍。这一突破首次实现了十亿级模型每秒预填充超过1,000个令牌，为设备上LLM的实用化开辟了新纪元。
[Arxiv](https://arxiv.org/abs/2407.05858)
==========
# 语言模型中词汇扩展与初始化方法的实证对比研究
发布时间：2024年07月08日
`LLM理论` `机器学习`
> An Empirical Comparison of Vocabulary Expansion and Initialization Approaches for Language Models
# 摘要
> 尽管语言模型在英语处理中表现卓越，但在其他多数语言中性能却有所下降。通常，这一难题通过持续的预训练和微调来解决。然而，原始模型分词器的词汇覆盖不足，导致新语言的表达力受限，进而需要扩展分词器。此外，新词汇的嵌入初始化也是一个挑战。当前方法依赖于跨语言嵌入，且缺乏坚实的理论支撑和强有力的比较基准。本文中，我们首先从理论上论证了在现有嵌入的凸包内进行初始化是有效的，随后提出了一种新颖且简便的方法——约束 Word2Vec (CW2V)，无需跨语言嵌入。我们的研究在四种语言和五项任务中评估了不同的初始化方法，结果表明 CW2V 的表现与高级技术不相上下，甚至更优。同时，简单的多元初始化方法也显示出与这些高级技术相当的性能，这表明即使采用简单的初始化方法，也能实现高效的大规模多语言持续预训练。
[Arxiv](https://arxiv.org/abs/2407.05841)
==========
# HyCIR 技术通过合成标签，显著提升了零-shot组合图像检索的性能。
发布时间：2024年07月08日
`LLM应用` `图像检索` `机器学习`
> HyCIR: Boosting Zero-Shot Composed Image Retrieval with Synthetic Labels
# 摘要
> 组合图像检索（CIR）旨在根据带有文本的查询图像检索图像。当前的零样本CIR（ZS-CIR）方法试图在不使用昂贵的三元组标记训练数据集的情况下解决CIR任务。然而，ZS-CIR与三元组监督的CIR之间的差距仍然很大。在这项工作中，我们提出了混合CIR（HyCIR），它使用合成标签来提升ZS-CIR的性能。我们提出了一种新的CIR标签合成流程（SynCir），其中仅需要未标记的图像。首先，基于视觉相似性提取图像对。其次，基于视觉-语言模型和LLM为每个图像对生成查询文本。第三，基于语义相似性在语言空间中进一步过滤数据。为了提高ZS-CIR性能，我们提出了一种混合训练策略，结合ZS-CIR监督和合成CIR三元组。采用了两种对比学习方法。一种是使用大规模未标记图像数据集学习具有良好泛化的图像到文本映射。另一种是使用合成CIR三元组学习更适合CIR任务的映射。我们的方法在常见的CIR基准测试（CIRR和CIRCO）上实现了SOTA的零样本性能。
[Arxiv](https://arxiv.org/abs/2407.05795)
==========
# 司法实体提取领域的大型语言模型比较研究
发布时间：2024年07月08日
`LLM应用`
> Large Language Models for Judicial Entity Extraction: A Comparative Study
# 摘要
> 领域特定实体识别在法律领域至关重要，支持多种应用，如问答系统、文本摘要等，特别是在案例法文档中。最新进展显示，大型语言模型在自然语言处理中表现出色，能从专业文本中精准识别和分类特定实体。本研究聚焦于大型语言模型在案例法文档中识别特定实体的能力，特别是处理语言复杂性和上下文变化的能力。研究评估了包括Meta AI 3、Mistral和Gemma在内的先进模型，在提取印度司法文本相关事实方面的表现。Mistral和Gemma表现卓越，精确度和召回率均衡，对实体识别至关重要。这些成果不仅证实了大型语言模型在司法领域的价值，还展示了它们如何通过生成精确、有序的数据，加速科学研究，为深入分析提供支持。
[Arxiv](https://arxiv.org/abs/2407.05786)
==========
# Hecaton：借助可扩展的小芯片系统，高效训练与微调大型语言模型。
发布时间：2024年07月08日
`LLM理论` `半导体` `人工智能`
> Hecaton: Training and Finetuning Large Language Models with Scalable Chiplet Systems
# 摘要
> 大型语言模型 (LLM) 在多领域取得显著成就，但其训练与微调对计算和内存需求巨大，导致并行化带来高额通信成本。随着封装技术的发展，chiplet 架构应运而生，它集成了计算能力，并通过优化封装内链接，提供更佳的信号完整性、高带宽和低能耗。然而，现有 chiplet 研究多聚焦于 DNN 推理，直接应用于 LLM 训练则引发大量 DRAM 访问和封装内网络 (NoP) 开销，使先进 chiplet 设计失效，揭示了研究缺口。  本研究提出 Hecaton，一个专为 LLM 训练与微调设计的可扩展、高性价比 chiplet 系统。我们首先构建了一个定制调度的 chiplet 架构，显著减少 DRAM 访问。接着，我们设计了一种高效的分布式训练策略，降低 NoP 通信复杂性，并放宽对 SRAM 容量和布局的限制。理论分析显示，该系统实现了弱扩展：工作负载与硬件资源同比例增长时，计算与通信比率几乎恒定。实验证明，Hecaton 在 Llama2-70B 上相较于 Megatron 的张量并行，实现了 $4.98\times$ 的性能提升和 $2.35\times$ 的能耗节省。据我们所知，这是首个专为 LLM 训练或微调设计的 chiplet 架构，确保了性能的稳定性，不受问题规模影响。
[Arxiv](https://arxiv.org/abs/2407.05784)
==========
# 何时一致的预测更可能是正确的？
发布时间：2024年07月08日
`LLM理论` `人工智能`
> When is the consistent prediction likely to be a correct prediction?
# 摘要
> 自我一致性理论（Wang et al., 2023）认为，大型语言模型（LLM）中最一致的答案更可能是正确答案。然而，我们对此提出质疑，并进行了细致的修正。我们发现，通过更多计算，即更长的推理文本，而非简单地选择所有输出中最一致的答案，得出的结果更可能正确。这是因为LLM能在无特殊提示下，自主生成链式思维（CoT）风格的推理，尤其是在生成较长响应时，这使得预测更为一致且准确。在零-shot场景下，通过多次采样Mixtral-8x7B模型并关注较长响应，我们在GSM8K和MultiArith数据集上达到了零-shot CoT提示下自我一致性性能的86%。此外，我们指出LLM生成较长响应的概率较低，这凸显了根据输出长度调整解码策略的重要性。
[Arxiv](https://arxiv.org/abs/2407.05778)
==========
# 大型语言模型具备理解布局的能力。
发布时间：2024年07月08日
`LLM应用` `人工智能` `视觉问答`
> Large Language Models Understand Layouts
# 摘要
> 大型语言模型 (LLMs) 在众多 NLP 任务中表现卓越。本文揭示，LLMs 不仅能理解文本，还能处理空间标记指示的文本布局，解答涉及空间感知的问题。然而，去除空间标记会导致性能大幅下降。我们通过 GPT-3.5、Baichuan2、Llama2 和 ChatGLM3 在布局敏感数据集上的实验，发现布局理解能力源自预训练数据，并在指令调优中强化。利用创新文本游戏自动生成数据，可进一步增强布局理解。此外，这种能力对构建高效的视觉问答 (VQA) 系统大有裨益。
[Arxiv](https://arxiv.org/abs/2407.05750)
==========
# 多语言大型语言模型能否缓解刻板印象偏见？
发布时间：2024年07月08日
`LLM理论` `人工智能` `语言处理`
> Do Multilingual Large Language Models Mitigate Stereotype Bias?
# 摘要
> 初步研究表明，多语言大型语言模型（LLMs）的偏差较单语言模型少。然而，关于多语言训练如何有效减少偏差，我们知之甚少。本研究通过训练六个相同规模（2.6B参数）和架构的LLMs，包括五个单语言模型（英语、德语、法语、意大利语和西班牙语）和一个涵盖这些语言的多语言模型，来深入探讨这一问题。为确保评估的准确性，我们将标准偏差测试自动翻译成五种语言，并由专家验证其翻译质量和偏差保留情况。研究结果显示，多语言训练不仅能有效减少偏差，还能提升预测准确性，优于同等条件下的单语言模型。
[Arxiv](https://arxiv.org/abs/2407.05740)
==========
# 探究对话型聊天机器人中的对称推理实证研究
发布时间：2024年07月08日
`LLM应用` `人工智能` `语言处理`
> Empirical Study of Symmetrical Reasoning in Conversational Chatbots
# 摘要
> 本研究探索了大型语言模型 (LLM) 驱动的对话聊天机器人在理解谓词对称性方面的能力，这是一种传统上被视为人类独有的认知语言功能。通过利用上下文学习 (ICL) 这一创新方法，我们评估了 ChatGPT 4、Huggingface 聊天 AI、微软 Copilot AI、Perplexity 的 LLaMA 和 Gemini Advanced 这五款聊天机器人的对称推理能力。我们采用 Tanchip 等人 (2020) 的 Symmetry Inference Sentence (SIS) 数据集，对比聊天机器人的响应与人类评估，以检验它们对谓词对称性的理解。实验结果显示，各聊天机器人的表现参差不齐，部分已接近人类推理水平。例如，Gemini 与人类评分相关性高达 0.85，且每次评估均提供合理解释。此研究凸显了 LLM 在模拟对称推理等复杂认知过程中的潜力与局限。
[Arxiv](https://arxiv.org/abs/2407.05734)
==========
# GPT-4 能否独立胜任自动作文评分？本研究采用基于评分者认知的比较判断方法，探讨其可行性。
发布时间：2024年07月08日
`LLM应用` `人工智能`
> Is GPT-4 Alone Sufficient for Automated Essay Scoring?: A Comparative Judgment Approach Based on Rater Cognition
# 摘要
> 尽管大型语言模型在自动作文评分领域展现出潜力，但其零-shot 和少-shot 性能仍不及顶尖模型和人类评分者。鉴于实际教育场景中作文题目和评分标准的多样性，逐一微调模型并不现实。为此，本研究创新性地结合了 LLM 与比较判断技术，通过零-shot 提示在两篇作文间做出选择，结果显示，这种方法在 LLM 辅助的作文评分中，显著优于传统评分标准。
[Arxiv](https://arxiv.org/abs/2407.05733)
==========
# PsycoLLM：提升 LLM 的心理理解和评估能力
发布时间：2024年07月08日
`LLM应用` `心理健康` `人工智能`
> PsycoLLM: Enhancing LLM for Psychological Understanding and Evaluation
# 摘要
> 近年来，心理健康备受瞩目，LLM凭借其出色的文本理解和对话能力，成为缓解这一问题的有力工具。然而，现有研究常因数据集缺乏关键先验知识、评估方法不全面而受限。为此，我们推出了PsycoLLM，一款专为心理学设计的大型语言模型，它基于一个精心构建的高质量心理学数据集进行训练，涵盖单轮问答、多轮对话及富含先验知识的问答。为评估PsycoLLM的性能，我们依据中国权威心理咨询考试，打造了一个全面的心理学基准，包括专业伦理、理论熟练度和案例分析的考核。实验结果表明，PsycoLLM在各项测试中表现卓越，远超其他LLM。
[Arxiv](https://arxiv.org/abs/2407.05721)
==========
# InverseCoder：借助 Inverse-Instruct 技术，释放指令调优代码大型模型（LLM）的潜能。
发布时间：2024年07月08日
`LLM应用` `软件开发` `人工智能`
> InverseCoder: Unleashing the Power of Instruction-Tuned Code LLMs with Inverse-Instruct
# 摘要
> 近期，开源代码大型语言模型 (LLM) 通过在由 GPT-3.5 和 GPT-4 等闭源 LLM 生成的数据上进行指令调优，展现了卓越的编码能力。本文探讨了如何通过从自身生成数据而非依赖闭源 LLM 来进一步提升指令调优的代码 LLM。我们发现，将代码（正式语言）翻译为自然语言（非正式语言）比反向翻译更为直接。基于此，我们提出 INVERSE-INSTRUCT 方法，从代码片段中提取指令而非相反。具体而言，我们利用代码 LLM 对原始语料库进行代码摘要和自我评估，生成高质量指令，进而结合原始与新生成的语料库对基础 LLM 进行微调，得到更强大的指令调优 LLM。我们推出的 InverseCoder 系列模型，在 Python 文本到代码生成、多语言编码及数据科学代码生成等多项基准测试中，性能超越了原始代码 LLM。
[Arxiv](https://arxiv.org/abs/2407.05700)
==========
# Sub-SA：借助子模块选择性注释强化上下文学习
发布时间：2024年07月08日
`LLM应用` `人工智能` `数据注释`
> Sub-SA: Strengthen In-context Learning via Submodular Selective Annotation
# 摘要
> ICL 通过上下文示例作为 LLM 预测的提示，这些提示对实现高性能至关重要。然而，从众多标记示例中挑选合适提示往往成本高昂。为此，我们引入了 Sub-SA，一种基于子模块的选择性注释方法，旨在降低成本、提升示例质量并简化选择流程。Sub-SA 设计了子模块函数，助力高效注释子集选择，并从理论层面展现其单调与子模块特性。我们进一步提出 RPR，通过奖励与惩罚机制平衡数据多样性与代表性。基于此，我们采用简单高效的贪婪算法进行注释选择。最终，通过相似性提示检索为 ICL 提供示例。
[Arxiv](https://arxiv.org/abs/2407.05693)
==========
# 精简大型语言模型至模块内低秩结构，结合过渡激活技术
发布时间：2024年07月08日
`LLM理论` `计算机科学` `人工智能`
> Pruning Large Language Models to Intra-module Low-rank Architecture with Transitional Activations
# 摘要
> 结构化剪枝技术有效降低了大型语言模型的计算和内存负担，为终端部署提供了可行方案。剪枝后的模型保持高密度和高精度，便于后续调优和压缩。然而，粗粒度剪枝对模型的损害较大，实现高压缩比仍具挑战。本文提出了一种任务无关的结构化剪枝方法TransAct，结合紧凑Transformer架构，减少MHA和MLP模块内的激活，同时保护模块间敏感激活。这使得LLM转化为低秩架构，大幅减少权重和计算。在LLaMA模型上的实验表明，TransAct在保持高效性和性能的同时，实现了高压缩比。消融研究进一步证实了激活引导剪枝的有效性，并分析了MHA和MLP模块的冗余。
[Arxiv](https://arxiv.org/abs/2407.05690)
==========
# 汲取过往失误中的上下文原则
发布时间：2024年07月08日
`LLM应用` `人工智能`
> Retrieved In-Context Principles from Previous Mistakes
# 摘要
> In-context learning (ICL) 在 LLM 适应下游任务中扮演关键角色，但现有方法在定制化和错误覆盖上存在不足。为此，我们引入了 Retrieval In-Context Principles (RICP)，一个创新的师生框架。RICP 通过教师模型分析学生模型的错误，生成针对性的改进建议，并根据错误原因进行分类，提升原则的错误覆盖率。在推理时，系统会为每个问题定制相关原则，无需教师模型介入。实验表明，RICP 能有效提升多种提示策略的性能，跨越七个推理基准。
[Arxiv](https://arxiv.org/abs/2407.05682)
==========
# DebUnc：利用不确定性估计，有效减少大型语言模型代理通信中的幻觉现象。
发布时间：2024年07月08日
`LLM应用` `人工智能` `软件开发`
> DebUnc: Mitigating Hallucinations in Large Language Model Agent Communication with Uncertainty Estimations
# 摘要
> 为了提升 LLM 的性能，我们引入了多智能体辩论机制，让多个 LLM 通过多轮辩论共同探讨解决方案。但 LLM 常给出看似自信的错误答案，可能误导其他智能体。为此，我们开发了 DebUnc 框架，通过不确定性度量来评估智能体的信心水平。我们改进了 LLM 的注意力机制，根据信心调整令牌权重，并尝试用文本提示传达信心。评估结果表明，基于注意力的方法效果显著，且随着不确定性度量的改进，性能将持续提升。代码已公开在 https://github.com/lukeyoffe/debunc。
[Arxiv](https://arxiv.org/abs/2407.06426)
==========
# SimPal：构建元对话框架，深入解析 K-12 物理教学中教师的指导目标
发布时间：2024年07月08日
`Agent` `人工智能`
> SimPal: Towards a Meta-Conversational Framework to Understand Teacher's Instructional Goals for K-12 Physics
# 摘要
> 在小学科学教育中，模拟教学广受欢迎，常辅以对话式AI代理，为学生提供实时实验支持。然而，每个AI代理都针对特定模拟定制，预设教学目标（IGs）固定，教师难以调整，且对新模拟持保留态度。为此，我们研发了SimPal，一款基于大型语言模型的元对话代理，旨在弥合AI与教学法间的鸿沟。教师通过与SimPal的自然交流，阐述期望的IGs，SimPal据此识别相关物理变量及其关系，构建符号表示，进而优化原始AI代理的提示设计，以更精准地匹配期望IGs。我们通过ChatGPT-3.5和PaLM 2对63个物理模拟进行了实证测试，并利用TELeR分类法探究了提示技术对LLM性能的影响。结果显示，SimPal在明确提示下能高效准确地完成任务。
[Arxiv](https://arxiv.org/abs/2407.06241)
==========
# 利用 ChatGPT 进行多模态思维链推理，守护儿童远离不适龄应用的侵害
发布时间：2024年07月08日
`LLM应用` `儿童保护` `数字市场`
> Multimodal Chain-of-Thought Reasoning via ChatGPT to Protect Children from Age-Inappropriate Apps
# 摘要
> 移动应用可能让儿童接触不适内容，如色情、暴力和毒品。成熟度评级为家长提供快速有效的评估工具。在数字市场，确保评级准确性对儿童保护至关重要。现有方法或不准确，或成本高昂。本文提出一种新框架，利用ChatGPT-4 Vision等多模态大型语言模型，通过链式思维推理，系统处理应用的文本描述和截图，逐步推理至成熟度评级。实验显示，该方法性能卓越，超越其他模型和策略。
[Arxiv](https://arxiv.org/abs/2407.06309)
==========
# VIMI：借助多模态指令，奠定视频生成之基石
发布时间：2024年07月08日
`LLM应用` `视频制作` `人工智能`
> VIMI: Grounding Video Generation through Multi-modal Instruction
# 摘要
> 现有的文本到视频模型因缺乏大规模多模态数据集而受限，我们通过构建新数据集和两阶段训练策略，提升了模型的多模态理解和视频生成能力。VIMI不仅能生成内容丰富、个性化的视频，还在UCF101基准测试中达到了顶尖水平。
[Arxiv](https://arxiv.org/abs/2407.06304)
==========
# VQA-Diff 技术结合视觉问答与扩散模型，为自动驾驶领域带来零-shot 图像至 3D 车辆资产的生成能力。
发布时间：2024年07月08日
`LLM应用` `自动驾驶` `汽车制造`
> VQA-Diff: Exploiting VQA and Diffusion for Zero-Shot Image-to-3D Vehicle Asset Generation in Autonomous Driving
# 摘要
> 在自动驾驶领域，从自然场景中捕捉的图像生成3D车辆模型至关重要。然而，传统方法仅依赖图像RGB信息，未能深入理解车辆的细节，如车型和制造商，导致在复杂现实场景中的零-shot预测能力不足。为此，我们创新性地提出了VQA-Diff框架，它结合了视觉问答模型中的大型语言模型知识，以及扩散模型中的丰富图像先验，共同打造逼真的3D车辆模型。通过多专家扩散模型策略和主题驱动的结构控制生成机制，VQA-Diff无需依赖大规模真实数据集，便能实现强大的零-shot图像到新视角生成能力。实验结果显示，VQA-Diff在多个数据集上均超越了现有顶尖技术，无论是在视觉效果还是性能指标上。
[Arxiv](https://arxiv.org/abs/2407.06516)
==========
# 本研究旨在通过识别和探究任务特定神经元，深入理解 LLMs 在多任务学习中的泛化能力。
发布时间：2024年07月08日
`LLM理论` `人工智能`
> Towards Understanding Multi-Task Learning (Generalization) of LLMs via Detecting and Exploring Task-Specific Neurons
# 摘要
> 大型语言模型 (LLMs) 虽展现出卓越的多任务能力，但其学习机制的理解仍具挑战。本文从神经元视角切入，通过梯度归因在特定任务数据上识别任务敏感神经元，并证实其与任务的高度相关性，即特定任务神经元。借助这些神经元，我们探讨了多任务学习中的泛化和灾难性遗忘问题，发现神经元重叠与任务间泛化及专业化紧密相关。LLMs 某些层中神经元参数的高度相似性亦与泛化性能相关。基于此，我们提出神经元级连续微调法，仅微调当前任务神经元，实验证明其有效性。本研究深化了 LLMs 在多任务学习中的可解释性认识。
[Arxiv](https://arxiv.org/abs/2407.06488)
==========
# 利用大型语言模型进行情景模拟，以实现决策的最优化。
发布时间：2024年07月08日
`LLM应用` `软件开发` `旅游规划`
> Optimal Decision Making Through Scenario Simulations Using Large Language Models
# 摘要
> 大型语言模型（LLM）的迅猛发展极大地拓宽了其在各领域的应用，重塑了我们处理复杂问题的方式。这些模型最初仅用于预测文本中的下一个词，如今已能深入理解并回应查询的语境。现在，LLM 能够轻松完成撰写论文、创作诗歌、编写故事甚至开发软件代码等曾经艰巨的任务。随着其能力的不断提升，人们对它们在更高级领域的表现也寄予厚望。然而，LLM 在需要精细决策的场景中仍面临挑战，如旅行规划或多个选项的选择。这些任务要求对多种结果有深刻理解，并能预测不同选择的后果，而这超出了 LLM 的常规能力范围。本文提出了一种创新方法，通过让 LLM 向用户请求多个潜在选项及其参数，引入了一个集成了优化函数的动态决策框架。该函数能分析选项、模拟结果，并根据预设标准选出最佳方案。借助此方法，LLM 能为复杂的多变量问题提供定制的最优解，大幅提升其实际应用的效能。这一方法不仅扩展了 LLM 的功能边界，还为构建能支持复杂决策的更智能系统奠定了基础。
[Arxiv](https://arxiv.org/abs/2407.06486)
==========
# 语言模型的可组合干预策略
发布时间：2024年07月08日
`LLM理论` `人工智能` `软件工程`
> Composable Interventions for Language Models
# 摘要
> 语言模型在测试时的干预不仅能提升事实准确性，还能减少有害输出并增强模型效率，且无需重新训练。然而，尽管新方法层出不穷，各类干预措施却大多各自为政。实践中，我们需对同一模型依次施加多种干预，却缺乏研究其相互作用的标准化途径。为此，我们引入了“可组合干预”框架，旨在探索多重干预在同一模型上的效果，并配备了新指标和统一代码库。借助此框架，我们广泛实验，将知识编辑、模型压缩和机器遗忘这三类新兴干预方法进行组合。结果显示，压缩会妨碍编辑与遗忘，干预顺序至关重要，而现有通用指标在评估可组合性上尚显不足。这些发现揭示了可组合性领域的明显短板，呼吁新的多目标干预策略。所有相关代码已公开于：https://github.com/hartvigsen-group/composable-interventions。
[Arxiv](https://arxiv.org/abs/2407.06483)
==========
# MUSE：语言模型的机器遗忘六维评估
发布时间：2024年07月08日
`LLM应用` `隐私保护` `数据安全`
> MUSE: Machine Unlearning Six-Way Evaluation for Language Models
# 摘要
> 语言模型在处理大量文本数据时，可能涉及隐私和版权问题。数据所有者出于这些考虑，可能要求从模型中删除特定数据。然而，现代模型中精确遗忘特定数据点是不可行的，这促使了近似遗忘算法的发展。传统上，这些算法的评估范围有限，未能全面衡量其成功和实用性。为此，我们提出了MUSE基准，该基准定义了遗忘模型应具备的六项特性，包括防止记忆、保护隐私、保持效用等。我们测试了八种算法在遗忘《哈利·波特》和新闻文章时的表现，发现多数算法能防止记忆，但仅一种能有效避免隐私泄露。现有算法普遍未能满足部署者的期望，因其常降低模型效用，且难以应对连续或大规模的遗忘请求。我们的研究揭示了现有算法的关键问题，并发布了评估基准以推动进一步研究。
[Arxiv](https://arxiv.org/abs/2407.06460)
==========
# 揭秘隐私漏洞：针对 LLM 对齐过程中的偏好数据进行的成员推理攻击
发布时间：2024年07月08日
`LLM应用` `人工智能` `隐私保护`
> Exposing Privacy Gaps: Membership Inference Attack on Preference Data for LLM Alignment
# 摘要
> 大型语言模型（LLM）因其出色的自然语言处理能力而广受欢迎。但在实际应用中，确保其生成的文本符合人类标准至关重要。近端策略优化（PPO）和直接偏好优化（DPO）等方法利用人类偏好数据对 LLM 进行了显著改进，但这些数据带来的隐私问题尚未得到充分探讨。本文探讨了基于人类偏好数据集对齐的 LLM 对成员推理攻击（MIA）的脆弱性，并指出了现有 MIA 方法在处理偏好数据方面的缺陷。我们的研究主要贡献有两点：一是引入了针对偏好数据的新型参考攻击框架 PREMIA；二是实证表明 DPO 模型比 PPO 模型更易受 MIA 影响。这些发现揭示了当前 LLM 对齐过程中隐私保护措施的不足。
[Arxiv](https://arxiv.org/abs/2407.06443)
==========
# 单一 Transformer 实现视觉与语言模型的可扩展性
发布时间：2024年07月08日
`LLM应用` `计算机视觉` `人工智能`
> A Single Transformer for Scalable Vision-Language Modeling
# 摘要
> 我们推出了 SOLO，一种单一 Transformer 架构，专为可扩展的视觉语言模型设计。当前的 LVLMs 如 LLaVA 多采用异构架构，结合预训练视觉编码器与 LLMs，虽性能卓越，但存在四大可扩展性挑战：视觉能力受限、架构复杂、缩放分析困难、图像处理受限。SOLO 通过统一架构有效应对这些挑战，但普及受限于缺乏平衡视觉与语言、确保大型模型稳定训练的可靠方法。本文首次公开 SOLO 训练方法，利用适中资源打造 7B LVLM，通过 LLMs 初始化、多阶段预训练及高质量数据集微调，实现与 LLaVA-v1.5-7B 媲美的性能，尤其在视觉数学推理上表现卓越。
[Arxiv](https://arxiv.org/abs/2407.06438)
==========
# ORAN-Bench-13K：一款开源基准，专为评估大型语言模型在开放无线接入网络中的表现而设计。
发布时间：2024年07月08日
`LLM应用` `网络分析`
> ORAN-Bench-13K: An Open Source Benchmark for Assessing LLMs in Open Radio Access Networks
# 摘要
> 大型语言模型 (LLM) 通过提升网络分析、异常检测和代码生成能力，显著增强了开放无线接入网络 (O-RAN) 的效率和可靠性，从而革新了其部署与运营方式。本文介绍了首个针对 O-RAN 背景下 LLM 性能评估的综合基准——ORAN-Bench-13K，包含从 116 份规范文档中精选的 13,952 道多选题。我们采用创新的三阶段 LLM 框架，将问题按难度分类，全面覆盖 ORAN 知识。通过评估 Gemini、Chat-GPT 和 Mistral 等顶尖 LLM，我们发现当前主流模型在 O-RAN 领域表现不佳，凸显了定制模型的需求。引入基于 RAG 的 ORANSight 管道后，性能显著提升，宏精度与加权精度分别达到 0.784 和 0.776，平均优于其他 LLM 21.55% 和 22.59%。
[Arxiv](https://arxiv.org/abs/2407.06245)
==========
# 大型语言模型群体中的集体创新
发布时间：2024年07月07日
`Agent` `人工智能` `游戏开发`
> Collective Innovation in Groups of Large Language Models
# 摘要
> 人类文化根植于集体创新，即我们不断探索如何将环境中的现有元素重新组合以创造新事物的能力。语言在这一过程中被认为起着核心作用，它不仅推动个体认知发展，还塑造了我们的交流方式。然而，大多数集体创新模型并未考虑代理的认知或语言能力。为此，我们开展了一项计算研究，其中代理是大型语言模型（LLM），它们参与《小炼金术2》这款创意游戏，该游戏能有效模拟创新环境中的关键要素。我们首先单独分析了一个LLM的表现，发现它既有显著技能也存在明显局限。随后，我们考察了共享信息的LLM群体，并深入探讨了社交连接对集体创新表现的影响。研究结果显示，具有动态连接的群体在创新竞赛中超越了完全连接的群体，这与先前的研究相呼应。我们的研究不仅揭示了未来探索集体创新的新机遇，也指出了面临的挑战，特别是在生成式人工智能与人类共同创新的背景下，这些发现显得尤为重要。
[Arxiv](https://arxiv.org/abs/2407.05377)
==========
# MINDECHO：专为关键意见领袖打造的角色扮演语言代理
发布时间：2024年07月07日
`Agent` `社交媒体` `网络红人`
> MINDECHO: Role-Playing Language Agents for Key Opinion Leaders
# 摘要
> 大型语言模型在众多应用中表现卓越，尤其是角色扮演语言代理，深受用户喜爱。如今，代表关键意见领袖（即网络红人，他们主导着各自领域的潮流和观点）的 RPLAs 需求日益增长。然而，相关研究尚显不足。为此，我们提出了 MINDECHO 框架，旨在全面支持 KOL RPLAs 的开发与评估。MINDECHO 从多领域网络视频中采集 KOL 数据，并借助 GPT-4 模拟其对话。随后，这些对话与转录文本分别用于定制化模型训练与实时推理。我们的评估体系兼顾通用标准（如知识深度与语调）与粉丝视角。实验结果充分证明了 MINDECHO 在 KOL RPLAs 开发与评估中的高效性。
[Arxiv](https://arxiv.org/abs/2407.05305)
==========
# WorkArena++：探索基于组合规划与推理的通用知识工作任务
发布时间：2024年07月07日
`Agent` `人工智能`
> WorkArena++: Towards Compositional Planning and Reasoning-based Common Knowledge Work Tasks
# 摘要
> 大型语言模型 (LLM) 模仿人类智能的能力催生了基于 LLM 的自主代理的兴起。尽管这些模型在用户指令下展现出规划和推理的能力，但它们在实际任务解决中的应用效果仍有待深入探索，尤其是在企业环境中。为此，我们推出了 WorkArena++，这是一个包含 682 个真实工作流程任务的基准测试，旨在全面评估网络代理的各项能力。我们的研究发现，这些模型在成为高效工作助手方面仍面临挑战。此外，我们还开发了一种机制，可轻松生成大量真实数据，用于模型的微调。我们期待这项工作能为社区在自主代理领域的发展提供有力支持。基准测试详情请访问：https://github.com/ServiceNow/WorkArena/tree/workarena-plus-plus。
[Arxiv](https://arxiv.org/abs/2407.05291)
==========
# 特定领域程序视频摘要的多模态语言模型
发布时间：2024年07月07日
`LLM应用`
> Multimodal Language Models for Domain-Specific Procedural Video Summarization
# 摘要
> 视频不仅是传达思想和故事的强大工具，还能通过长教程提供详尽指导。然而，这些教程因其长度和密集内容可能令人望而生畏。观众往往需要特定信息，如精确测量或详细步骤，因此高效提取和总结关键片段至关重要。一个能够总结和检测长视频亮点的智能助手备受追捧。多模态大型语言模型的最新进展为此类助手开发提供了希望。我们研究如何利用这些模型增强视频总结和特定领域内逐步指导生成。这些模型需理解视频帧间的时间事件和动作关系。我们专注于微调TimeChat，以提升其在烹饪和医疗程序等领域的性能。通过在特定领域数据集上训练模型，我们旨在增强其生成简洁、准确教程视频总结的能力。我们精心挑选和重组数据集，创建高质量视频指导数据。研究表明，在特定领域程序数据上微调后，TimeChat能显著提升长视频中关键步骤的提取和总结。这项研究展示了专门多模态模型通过提供个性化、逐步指导来协助实际任务的潜力。
[Arxiv](https://arxiv.org/abs/2407.05419)
==========
# VideoCoT：一款集成了主动注释工具的视频思维链数据集
发布时间：2024年07月07日
`LLM应用` `视频处理` `人工智能`
> VideoCoT: A Video Chain-of-Thought Dataset with Active Annotation Tool
# 摘要
> 多模态大型语言模型 (MLLMs) 正蓬勃发展，但对视频的关注不如图像，尤其是在提示工程、视频链-of-思维 (CoT) 和视频指令调整等领域。为此，我们探索视频中的 CoT 数据集，旨在推动视频 OpenQA 并增强 MLLMs 的推理能力。然而，构建视频 CoT 数据集颇具挑战。考虑到人工标注成本高且繁琐，机器生成又因幻觉问题不可靠，我们开发了结合机器与人类专家的自动标注工具，采用主动学习策略。该策略通过模型与专家的互动，既减轻了人工负担，又确保了数据质量。借助此工具，我们贡献了 VideoCoT、TopicQA 和 TopicCoT 三个数据集。此外，我们基于这些数据集提出了一个简单高效的基准，旨在通过 CoT 最大化 MLLMs 的复杂推理能力。实验结果充分验证了我们方法的有效性。
[Arxiv](https://arxiv.org/abs/2407.05355)
==========
# 利用大型语言模型，我们致力于设计既安全又高效的强化学习成本函数。
发布时间：2024年07月07日
`LLM应用` `人工智能`
> : Towards Effective and Efficient Cost Function Design for Safe Reinforcement Learning via Large Language Model
# 摘要
> 在满足不同安全需求的场景中，各类安全强化学习算法表现出色，但它们通常只能应对特定场景，无法通用。此外，这些算法的优化目标往往与实际任务需求脱节。为此，我们设计了 $\mathrm{E^{2}CFD}$ 框架，它借助大型语言模型的理解力，针对不同安全场景生成定制的代价函数，并通过快速性能评估方法实现快速迭代优化。实验结果显示，该框架训练出的策略性能超越了传统方法和人工设计的代价函数。
[Arxiv](https://arxiv.org/abs/2407.05580)
==========
# LLMBox：大型语言模型的综合库
发布时间：2024年07月07日
`LLM应用` `软件开发` `人工智能`
> LLMBox: A Comprehensive Library for Large Language Models
# 摘要
> 本文推出 LLMBox，一个全面且统一的库，旨在简化大型语言模型 (LLM) 的开发、使用和评估。该库三大亮点：(1) 灵活的统一数据接口，(2) 广泛任务、数据集和模型的全面评估，(3) 强调用户友好与效率。借助 LLMBox，用户能轻松复现、训练并比较模型性能。我们通过多样化实验验证了其有效性与效率。详情及指南请访问 https://github.com/RUCAIBox/LLMBox。
[Arxiv](https://arxiv.org/abs/2407.05563)
==========
# 《伪多语者》：探究多语言大型模型中的信息鸿沟
发布时间：2024年07月07日
`RAG` `信息搜索` `多语言处理`
> Faux Polyglot: A Study on Information Disparity in Multilingual Large Language Models
# 摘要
> 大型语言模型（LLMs）通过检索增强生成（RAG）技术，在信息搜索领域发挥着核心作用，并已在全球普及。尽管LLMs的多语言特性为跨越语言障碍带来新希望，但这些特性是否能在多语言环境中有效应对语言隔阂和知识冲突，仍是一个疑问。我们的研究发现，LLMs在基于RAG的信息搜索中，对与查询语言相同的信息表现出系统性偏好，尤其在查询语言信息稀缺时，更倾向于高资源语言的文档，从而强化了主流观点。这种偏见在事实性和观点性查询中均存在。我们的研究揭示了多语言LLMs在信息搜索中的语言隔阂问题，指出其看似有益的多语言能力可能加剧信息不平等，通过强化特定语言的信息茧房或过滤气泡，进一步边缘化低资源观点。
[Arxiv](https://arxiv.org/abs/2407.05502)
==========
# 双读法：助力循环语言模型提升召回率
发布时间：2024年07月07日
`LLM理论` `人工智能`
> Just read twice: closing the recall gap for recurrent language models
# 摘要
> 循环大型语言模型正迅速崛起，与Transformer在语言模型困惑度上展开竞争。这些模型在推理时仅使用固定内存，但受限于此，它们难以充分利用长上下文信息，导致上下文学习质量不稳定。高效语言模型的关键在于精准选择存储与丢弃的信息。我们发现，信息呈现的顺序直接影响选择难度。通过将问题简化为集合不相交问题，我们揭示了循环模型在处理不同顺序集合时的内存需求变化。为减少对数据顺序的依赖，我们提出两种方案：JRT-Prompt重复展示上下文，全面展示数据顺序，平均提升11.0±1.3点，生成预填充吞吐量提升11.9倍；JRT-RNN采用非因果前缀线性注意力处理提示，以360M参数和30B令牌达到99%的Transformer质量，预填充吞吐量提升19.2倍。
[Arxiv](https://arxiv.org/abs/2407.05483)
==========
# 结合大型语言模型与UMLS启发式方法的生物医学嵌套NER研究
发布时间：2024年07月07日
`LLM应用` `生物医学`
> Biomedical Nested NER with Large Language Model and UMLS Heuristics
# 摘要
> 本文介绍了一个专为 BioNNE 英语赛道设计的系统，旨在从生物医学文本中提取 8 种嵌套命名实体。我们结合大型语言模型（Mixtral 8x7B instruct）和 ScispaCy NER 模型进行实体识别，并利用 UMLS 语义类型定制分类策略。文章还探讨了系统的性能与局限，并展望了未来的优化方向。该系统在验证集和测试集上的 F1 分数分别为 0.39 和 0.348。
[Arxiv](https://arxiv.org/abs/2407.05480)
==========
# 利用基于扰动的合成数据生成技术，提升系统响应中幻觉检测的效能。
发布时间：2024年07月07日
`LLM应用` `人工智能`
> Enhancing Hallucination Detection through Perturbation-Based Synthetic Data Generation in System Responses
# 摘要
> 检测 LLM 输出中的幻觉至关重要，但传统微调方法因昂贵且迅速过时的标注过程而受阻。本研究提出一种新方法，通过重写系统响应自动生成忠实与幻觉输出。实验显示，微调后的 T5-base 模型在准确性与速度上均优于现有技术，证明了我们方法的有效性。
[Arxiv](https://arxiv.org/abs/2407.05474)
==========
# 探索机器学习在真实性实验中的应用：通过光谱分析与可解释分类，揭示合成、虚假与真实信息的奥秘。
发布时间：2024年07月07日
`LLM应用` `社会科学` `信息技术`
> Experiments with truth using Machine Learning: Spectral analysis and explainable classification of synthetic, false, and genuine information
# 摘要
> 错误信息仍是社会难题，大型语言模型 (LLM) 的兴起更使其雪上加霜。本文通过光谱分析、可视化及可解释性视角，深入探讨合成、虚假与真实文本信息的复杂关系，揭示为何多年研究与众多解决方案仍未能彻底解决问题。我们采用多数据集上的多种嵌入技术，运用 t-SNE、PCA 及 VAEs 等方法进行分析，并借助 LIME、SHAP 和集成梯度等工具解释分类结果。研究显示，错误信息与真实信息紧密交织，机器学习算法在分离二者方面效果有限，与文献中的乐观声称相悖。
[Arxiv](https://arxiv.org/abs/2407.05464)
==========
# 利用基于检索的蒸馏技术培养任务专家
发布时间：2024年07月07日
`LLM应用` `人工智能` `数据科学`
> Training Task Experts through Retrieval Based Distillation
# 摘要
> 构建专用任务的可部署模型，最可靠途径之一是获取大量高质量的特定任务数据。然而，这类数据集往往稀缺。现有技术通过从大型语言模型（LLM）中生成数据并提炼至小型模型来应对，但受限于LLM输出质量，常产生重复或错误数据。我们提出的基于检索的提炼（ReBase）方法，首先从丰富在线资源中检索数据，再转化为领域特定数据，极大提升数据多样性。ReBase还能生成思维链推理，提炼LLM的推理能力。在四个基准测试中，我们的方法在SQuAD上性能提升高达7.8%，MNLI上提升1.37%，BigBench-Hard上提升1.94%。
[Arxiv](https://arxiv.org/abs/2407.05463)
==========
# 利用 LLM 提升编程教育：探索 Python 代码生成中的高效提示设计
发布时间：2024年07月07日
`LLM应用` `计算机编程`
> Enhancing Computer Programming Education with LLMs: A Study on Effective Prompt Engineering for Python Code Generation
# 摘要
> 大型语言模型（LLM）与提示工程相结合，为个性化计算机编程教育开辟了新天地。本文深入探讨了这一领域，聚焦于三个核心问题：如何系统地分类适用于不同教育背景的提示工程策略、如何扩展LLM解决复杂问题的能力，以及如何构建一个稳固的评估与实施框架。我们通过根据教育需求对编程问题进行分类，运用多样化的提示策略，并评估LLM的响应效果，来实施研究。实验结果显示，在LeetCode和USACO等数据集上，GPT-4o模型凭借其“多步骤”提示策略，表现尤为突出。研究证实，量身定制的提示策略能大幅提升LLM的表现，并为不同学习阶段推荐了相应的策略。本研究凸显了提示工程在提升LLM教育价值中的重要性，并提供了一个全面的框架，助力教育者和学生优化基于LLM的学习过程。未来研究应致力于精进这些策略，并克服LLM的现有局限，以期在计算机编程教育领域取得更大突破。
[Arxiv](https://arxiv.org/abs/2407.05437)
==========
# LTLBench：专为评估大型语言模型中的时间逻辑推理而设计的基准测试
发布时间：2024年07月07日
`LLM应用` `人工智能` `时间推理`
> LTLBench: Towards Benchmarks for Evaluating Temporal Logic Reasoning in Large Language Models
# 摘要
> 时间推理（TR）是AI的核心，涉及时间信息与事件关系的理解与处理。为探索LLMs的TR能力，我们创新性地结合随机有向图、LTL公式和NuSMV模型检查器，设计了一套数据集构建流程。据此，我们打造了包含2,000个挑战的LTLBench基准，并测试了六款LLMs。实验揭示，尽管LLMs在TR任务上有所进步，但复杂问题仍令其困扰。此研究不仅深化了对LLMs TR能力的理解，更为未来评估提供了有力工具。
[Arxiv](https://arxiv.org/abs/2407.05434)
==========
# SBoRA：通过区域权重更新实现低秩适应
发布时间：2024年07月07日
`LLM理论` `人工智能` `计算机科学`
> SBoRA: Low-Rank Adaptation with Regional Weight Updates
# 摘要
> 本文引入了 Standard Basis LoRA (SBoRA)，这是一种创新的参数高效微调技术，适用于大型语言模型，基于 Low-Rank Adaptation (LoRA) 和 Orthogonal Adaptation 的先驱研究。SBoRA 不仅减少了 LoRA 的计算和内存负担，还提升了学习效率。通过使用正交标准基向量初始化低秩矩阵（A 或 B），SBoRA 实现了针对性的权重更新和内存高效微调。这一方法衍生出两种变体，SBoRA-FA 和 SBoRA-FB，它们分别更新一个矩阵，形成稀疏的更新矩阵，大部分为零行或零列。因此，微调后的模型权重大多保持与预训练状态一致。SBoRA 的这种区域权重更新特性，类似于人脑的模块化适应机制，能够高效应对新任务。实证研究显示，在常识推理和算术推理等微调任务中，SBoRA-FA 表现优于 LoRA。此外，我们还评估了 QSBoRA 在不同规模量化 LLaMA 模型上的适应性，凸显了其在新任务上的高效适应潜力。相关代码已公开在 https://github.com/CityUHK-AI/SBoRA。
[Arxiv](https://arxiv.org/abs/2407.05413)
==========
# 通过中间语言评估代码生成
发布时间：2024年07月07日
`LLM应用` `软件开发` `人工智能`
> Assessing Code Generation with Intermediate Languages
# 摘要
> 本研究通过思维链等中间步骤方法，探讨了多种中间语言（如编程语言、自然语言及伪代码）对大型语言模型在代码生成任务中性能的影响。实验涉及 CodeLlama、GPT 和 Mistral 系列的多款模型及新发布的小型模型。结果显示，自然语言作为中间表示在各目标语言中表现最佳，但未发现适用于所有模型和语言的通用有效中间语言。此外，中间解决方案的正确性与最终生成结果的关联较弱，暗示性能提升更多来自思维链效应而非特定语言的传递。特别地，GPT 系列模型在无明确自我修正指令下多次提示，可显著提升性能。
[Arxiv](https://arxiv.org/abs/2407.05411)
==========
# CosyVoice：一款基于监督语义令牌的，可扩展的多语言零-shot 文本转语音合成器。
发布时间：2024年07月07日
`LLM应用` `语音技术` `人工智能`
> CosyVoice: A Scalable Multilingual Zero-shot Text-to-speech Synthesizer based on Supervised Semantic Tokens
# 摘要
> 近年来，基于大型语言模型的文本到语音技术因其高自然度和零-shot能力而成为主流。我们提出用监督语义令牌表示语音，并基于此开发了可扩展的零-shot TTS合成器CosyVoice。实验表明，监督语义令牌在零-shot语音克隆中表现更优，且利用大规模数据可进一步提升合成性能。这是首次尝试将监督语音令牌引入TTS模型。
[Arxiv](https://arxiv.org/abs/2407.05407)
==========
# ElecBench：大型语言模型电力调度评估的基准
发布时间：2024年07月07日
`LLM应用`
> ElecBench: a Power Dispatch Evaluation Benchmark for Large Language Models
# 摘要
> 随着电网稳定性的迫切需求和可再生能源整合、电力市场动态带来的挑战，电力行业正寻求创新技术解决方案。大型语言模型（LLMs）因其卓越的自然语言处理、逻辑推理和泛化能力，成为推动电力行业智能化的关键技术。然而，缺乏针对电力行业的LLM性能评估基准限制了其应用。为此，我们推出了“ElecBench”，一个专为电力行业设计的LLM评估基准，旨在全面覆盖行业场景、深化专业知识测试并提升决策精度。ElecBench将场景分为通用知识和专业业务，细化为六个核心指标和24个子指标，深入分析LLM在电力行业的应用潜力。我们公开了完整测试集，评估了八种LLM在多场景下的性能。ElecBench致力于成为电力行业LLM应用的标准，支持持续更新，推动技术与应用的发展。
[Arxiv](https://arxiv.org/abs/2407.05365)
==========
# Emilia 数据集，涵盖广泛、多语言且多样化，专为大规模语音生成设计。
发布时间：2024年07月07日
`LLM应用` `语音技术` `数据集`
> Emilia: An Extensive, Multilingual, and Diverse Speech Dataset for Large-Scale Speech Generation
# 摘要
> 近期，语音生成模型借助大规模训练数据取得了长足进步。然而，由于缺乏大规模、多样且自然的语音数据，研究者们难以创造出高度自然和类人的语音。为此，我们推出了 \textit{Emilia}，首个基于自然环境语音的多语言生成数据集，以及 Emilia-Pipe，一个开源预处理工具，能将自然语音转化为高质量的训练数据。Emilia 包含超过 101,000 小时的六种语言语音，风格多样。Emilia-Pipe 能在几分钟内处理一小时的原始语音，为模型训练做好准备，助力研究社区共同推进大规模语音生成研究。实验证实了 Emilia 的有效性。演示可访问：https://emilia-dataset.github.io/Emilia-Demo-Page/。
[Arxiv](https://arxiv.org/abs/2407.05361)
==========
# 从排队理论视角出发，解析大型语言模型在可变令牌长度下的低延迟推理
发布时间：2024年07月07日
`LLM应用` `人工智能` `计算机科学`
> A Queueing Theoretic Perspective on Low-Latency LLM Inference with Variable Token Length
# 摘要
> 大型语言模型（LLM）如 ChatGPT 推动了交互式 AI 应用的繁荣，但这些模型在推理时既计算密集又内存密集，不当的参数配置可能延长推理时间。本文探讨了 LLM 输出令牌分布对推理排队延迟的影响，并引入了最大令牌剪裁和批量推理策略。通过构建 M/G/1 模型，我们发现对少数请求设置最大输出令牌限制能显著减少排队延迟，并有助于选择最佳限制。对于批量推理，我们将其服务过程视为受批量大小和内部最大令牌大小影响的批量队列。我们分析了动态、固定和弹性三种批处理方式的排队延迟，实验结果验证了我们的数学模型与实际模拟的一致性。
[Arxiv](https://arxiv.org/abs/2407.05347)
==========
# 模型不确定性是否能代表多项选择题的难度？
发布时间：2024年07月07日
`LLM应用` `人工智能`
> Can Model Uncertainty Function as a Proxy for Multiple-Choice Question Item Difficulty?
# 摘要
> 估计多项选择题的难度对教育者和学习者都极为有益。然而，监督方法在难度估计上的表现参差不齐。本研究巧妙利用生成模型在回答问题时的不确定性，探索其与学生实际反应分布间的关联。我们发现，尽管相关性不强，但模型在答对与答错时的行为迥异，且不同题型的相关性差异显著。基于这些发现，我们提出，进一步挖掘模型不确定性，或能为评估题目难度提供新的视角。
[Arxiv](https://arxiv.org/abs/2407.05327)
==========
# 利用文本引导的扩散模型，提升医学图像分割的标签效率
发布时间：2024年07月07日
`LLM应用` `图像处理`
> Enhancing Label-efficient Medical Image Segmentation with Text-guided Diffusion Models
# 摘要
> 去噪扩散概率模型 (DPM) 不仅在医学图像生成领域表现卓越，还能作为表示学习器捕捉语义信息，为下游任务如图像分割提供支持。但这些语义表示依赖于繁琐的像素级注释，限制了其在医学图像分割中的应用。为此，我们提出了 TextDiff 模型，通过结合廉价的医学文本注释，显著提升了语义表示的质量，并建立了与语言的直接联系。TextDiff 利用预训练模型中的中间激活，结合诊断文本信息学习专家知识，同时冻结多模态结构，仅通过优化交叉注意力机制和像素分类器，实现了语义特征与诊断描述的精准对齐。实验证明，TextDiff 在仅使用少量样本的情况下，大幅超越了现有最先进的多模态分割方法。
[Arxiv](https://arxiv.org/abs/2407.05323)
==========
# 探究AI教育领域：大型语言模型如何解释物理学中的动量守恒
发布时间：2024年07月07日
`LLM应用` `物理学`
> Exploring the Educational Landscape of AI: Large Language Models' Approaches to Explaining Conservation of Momentum in Physics
# 摘要
> 大型语言模型（LLMs）在教育领域的应用，尤其是在物理学这样需要精确概念理解的领域，既充满机遇也面临挑战。本研究聚焦于六种顶尖LLMs解释动量守恒定律的能力，这是物理学的核心原理。我们通过分析模型对日语简单提示的响应，评估了它们的解释深度、适应性及教育层面的适用性。综合分析显示，模型在解释风格上存在显著差异：ChatGPT4.0和Coral提供详尽技术解释，Gemini模型则更侧重直观说明。研究发现，模型在处理关键物理概念和强调数学严谨性与实际应用方面各有侧重。这表明，不同模型适用于不同教育阶段，从基础到高级。ChatGPT4.0和Coral适合深入讨论，Gemini模型则更适于基础教学。研究强调，教育者在利用这些AI工具时的重要性，因为模型在传达物理原理的细微差别方面能力各异。此研究为LLMs在物理教育中的应用提供了基础，并为教育者整合这些工具提供了指导。同时，它也指出了在STEM领域进一步探索AI辅助学习的必要性，为AI在物理教育中的更高级应用奠定了基础。
[Arxiv](https://arxiv.org/abs/2407.05308)
==========
# UltraEdit：大规模基于指令的精细图像编辑
发布时间：2024年07月07日
`LLM应用` `图像处理` `人工智能`
> UltraEdit: Instruction-based Fine-Grained Image Editing at Scale
# 摘要
> 本文推出 UltraEdit，一个自动生成的大规模图像编辑数据集，约含 400 万样本。旨在克服现有数据集的不足，系统化生成高质量编辑样本。UltraEdit 的优势包括：1）结合 LLM 创造力和人类示例，扩展编辑指令；2）基于真实图像，提升多样性，减少偏见；3）支持区域编辑，借助自动高质量区域注释。实验显示，基于 UltraEdit 训练的扩散编辑模型在 MagicBrush 和 Emu-Edit 测试中刷新纪录。分析强调了真实图像和区域编辑数据的重要性。相关资源可访问 https://ultra-editing.github.io。
[Arxiv](https://arxiv.org/abs/2407.05282)
==========
# 揭秘 LLM 中的性别偏见：从无性别标签的名字预测出发
发布时间：2024年07月07日
`LLM应用` `性别研究` `人工智能`
> Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions
# 摘要
> 传统上，基于名字的性别预测采用二元分类系统，将个人简单划分为女性或男性。然而，这种做法在处理性别中性名字时显得力不从心，且忽视了性别多样性。为此，我们新增“中性”类别，旨在探索并纠正大型语言模型（LLM）中的性别偏见。我们测试了多个基础及大型模型仅凭名字进行性别预测的能力，并探讨了加入出生年份对预测准确性的影响，以适应名字与性别关联的时代变迁。结果显示，多数LLM在识别传统性别名字时准确率超过80%，但对性别中性名字的识别率不足40%，且英语名字的预测准确性优于非英语名字。实验还表明，引入出生年份并未显著提升预测准确性，尤其是对性别含义随时间变化的名字。因此，我们建议在涉及非二元性别标签的下游任务中，使用LLM进行性别识别时应持谨慎态度。
[Arxiv](https://arxiv.org/abs/2407.05271)
==========
# RULE：医学视觉语言模型中事实性的可靠多模态 RAG
发布时间：2024年07月06日
`RAG` `人工智能`
> RULE: Reliable Multimodal RAG for Factuality in Medical Vision Language Models
# 摘要
> 近期，医疗大型视觉语言模型（Med-LVLMs）在医疗诊断领域崭露头角，但它们在生成与医学事实不符的回答时屡见不鲜。检索增强生成（RAG）虽能借助外部知识提升事实准确性，却也带来了两大难题：一是检索内容可能不足或过多，导致信息不全或干扰生成；二是过度依赖检索内容，反而可能引发错误。为此，我们设计了RULE系统，通过精准控制检索数量来降低事实风险，并利用错误样本构建数据集进行模型微调，以平衡固有知识与检索内容的依赖。实验表明，RULE在三个医疗VQA数据集上平均提升了20.8%的事实准确性，相关基准和代码已公开于https://github.com/richard-peng-xia/RULE。
[Arxiv](https://arxiv.org/abs/2407.05131)
==========
# 提升文本主导型多模态对齐的稳健性
发布时间：2024年07月06日
`LLM应用` `人工智能` `多模态系统`
> Enhance the Robustness of Text-Centric Multimodal Alignments
# 摘要
> 在多模态模型对齐中，将不同模态数据转换为通用文本输入是一种常见策略，尤其在成对数据有限时。这种方法通过利用文本的独特性，将多样输入统一为文本形式，便于下游模型处理。然而，研究显示，现有方法在面对数据缺失、噪声或模态不全时，下游鲁棒性受损。为此，我们提出了一种新方法，显著提升了在各种模态和场景下的鲁棒性。这一进展不仅增强了多模态系统的适应性，也为复杂现实应用提供了有力支持。
[Arxiv](https://arxiv.org/abs/2407.05036)
==========
# LogicVista：一项针对视觉环境中多模态大型语言模型的逻辑推理基准测试
发布时间：2024年07月06日
`LLM应用` `人工智能`
> LogicVista: Multimodal LLM Logical Reasoning Benchmark in Visual Contexts
# 摘要
> 我们推出了 LogicVista 评估基准，旨在全面检验多模态大型语言模型 (MLLMs) 在视觉环境中的逻辑推理能力。随着 MLLMs 技术的进步，它们已能从图像中创作诗歌，甚至进行数学推理。但针对这些模型在逻辑推理任务上的表现，尤其是对导航和解谜等关键活动的影响，仍缺乏系统性评估。为此，我们设计了包含 448 道多选题的测试集，覆盖 5 大逻辑推理任务和 9 项不同能力，每个问题附有正确答案及人类推理解释，便于开放式和多选题评估。LogicVista 已对 8 个 MLLMs 进行了详尽测试，相关代码和数据已公开于 https://github.com/Yijia-Xiao/LogicVista。
[Arxiv](https://arxiv.org/abs/2407.04973)
==========
# CLIMB：一项针对大型语言模型中临床偏差的基准研究
发布时间：2024年07月06日
`LLM应用` `人工智能`
> CLIMB: A Benchmark of Clinical Bias in Large Language Models
# 摘要
> 大型语言模型（LLM）在临床决策中的应用日益增多，但其潜在的偏见问题对临床公平性构成威胁。目前，系统评估LLM临床偏见的基准尚缺。尽管在下游任务中，通过模型回答“我不确定...”等方式可规避部分偏见，但模型内部的隐性偏见仍待深入探究。为此，我们推出了CLIMB（大型语言模型临床偏见基准），这一创新性基准旨在全面评估LLM在临床决策中的内在与外在偏见。针对内在偏见，我们创新性地提出了AssocMAD指标，用以衡量LLM在不同人群间的差异。同时，我们采用反事实干预法，对临床诊断预测任务中的外在偏见进行评估。通过对Mistral和LLaMA系列等流行医学适应LLM的实验，我们揭示了普遍存在的内在与外在偏见现象。此项研究强调了减轻临床偏见的重要性，并为未来LLM临床偏见的评估树立了新标杆。
[Arxiv](https://arxiv.org/abs/2407.05250)
==========
# 大型语言模型在评估作业方面提供了宝贵的见解和反馈，但在处理超过1000名学生的课程时也面临挑战。
发布时间：2024年07月06日
`LLM应用` `人工智能`
> Large Language Model as an Assignment Evaluator: Insights, Feedback, and Challenges in a 1000+ Student Course
# 摘要
> 在 NLP 研究中，利用大型语言模型 (LLM) 进行自动评估已变得至关重要。但这些基于 LLM 的评估器能否在实际课堂中用于学生作业评估尚存疑问。本报告展示了我们如何在一门包含 1,028 名学生的课程中运用 GPT-4 进行自动作业评估。调查显示，当学生能自由使用这些评估工具时，它们颇受欢迎。不过，学生也反映 LLM 有时会偏离评估指南。更有甚者，学生发现通过操控评估器输出特定内容，即便未达标也能获得高分。结合学生意见与实践经验，我们提出了一系列建议，旨在优化未来课堂中 LLM 评估器的应用。
[Arxiv](https://arxiv.org/abs/2407.05216)
==========
# BadCLM：电子健康记录中临床语言模型的后门攻击
发布时间：2024年07月06日
`LLM应用` `网络安全`
> BadCLM: Backdoor Attack in Clinical Language Models for Electronic Health Records
# 摘要
> 临床语言模型融入电子健康记录（EHR），助力临床决策，是一大进步。然而，这些模型的潜在弱点尚未充分探索。本文探讨了针对临床语言模型的后门攻击，引入了基于注意力的BadCLM攻击方法。该方法在模型中秘密植入后门，使其在特定触发下产生错误预测，平时则正常运作。通过MIMIC III数据集的院内死亡率预测任务，我们验证了BadCLM的威胁性。研究揭示了临床决策支持系统的安全风险，并为强化模型防御指明了方向。
[Arxiv](https://arxiv.org/abs/2407.05213)
==========
# 驾驭 LLM 之力：自动生成高性能计算的单元测试
发布时间：2024年07月06日
`LLM应用` `软件工程` `高性能计算`
> Harnessing the Power of LLMs: Automating Unit Test Generation for High-Performance Computing
# 摘要
> 单元测试在软件工程中至关重要，但在并行和高性能计算软件中使用较少，尤其是科学应用，因其用户基础小且逻辑复杂。这使得单元测试既具挑战性又成本高昂，需要专业知识且现有工具常无效。为此，我们提出了一种自动化方法，针对这类软件的独特特性如复杂逻辑和并行处理，生成单元测试。近期，大型语言模型（LLMs）在编码和测试领域展现出潜力。我们研究了Davinci和ChatGPT在C++并行程序单元测试生成中的应用，发现它们能生成大部分正确且全面的测试，但也有局限，如重复断言和空白测试用例。
[Arxiv](https://arxiv.org/abs/2407.05202)
==========
# LLMCloudHunter：借助 LLM 之力，自动化提炼云端 CTI 的检测规则
发布时间：2024年07月06日
`LLM应用` `网络安全` `云计算`
> LLMCloudHunter: Harnessing LLMs for Automated Extraction of Detection Rules from Cloud-Based CTI
# 摘要
> 随着网络攻击的增多和复杂化，威胁狩猎在主动安全中变得至关重要，它能在威胁造成重大损害前进行主动检测和缓解。开源网络威胁情报（OS-CTI）虽为威胁猎人提供了宝贵资源，但常以非结构化形式出现，需手动分析。以往研究在自动化OSCTI分析方面存在局限，如未能提供可操作输出、未利用图像信息、忽视云环境重要性。为此，我们提出LLMCloudHunter框架，利用大型语言模型从文本和视觉OSCTI数据中自动生成检测规则候选。通过12份真实云威胁报告的评估，该框架在提取API调用和IoCs方面分别达到92%精确度和98%召回率，以及99%精确度和98%召回率。此外，99.18%的规则候选成功转换为Splunk查询。
[Arxiv](https://arxiv.org/abs/2407.05194)
==========
# FlowLearn：评估大型视觉-语言模型在流程图理解方面的表现
发布时间：2024年07月06日
`LLM应用` `科学研究`
> FlowLearn: Evaluating Large Vision-Language Models on Flowchart Understanding
# 摘要
> 流程图，作为简化复杂概念的视觉工具，本文引入了FlowLearn数据集，旨在深化对流程图的理解。该数据集不仅收录了3,858个来自科学文献的复杂流程图，还包含了10,000个模拟流程图。通过详尽的视觉组件、OCR、Mermaid代码及VQA问答对标注，FlowLearn为研究提供了丰富资源。尽管大型视觉-语言模型（LVLMs）在视觉理解领域表现卓越，但其在解读科学交流核心——流程图——的能力仍待全面探索。FlowLearn测试集正是为此设计，用以检验LVLMs在流程图理解上的表现。我们的研究不仅全面评估了当前最先进的LVLMs，揭示了其局限性，更为这一领域未来的发展奠定了基础。例如，GPT-4V在模拟流程图节点计数中准确率高达58%，而Claude在OCR任务中准确率则达到83%。然而，没有任何模型能在FlowLearn框架的所有任务中独占鳌头，这无疑为未来的研究与开发提供了广阔空间。
[Arxiv](https://arxiv.org/abs/2407.05183)
==========
# 安卓应用的反馈驱动自动化错误报告重现
发布时间：2024年07月06日
`LLM应用` `软件开发` `移动应用`
> Feedback-Driven Automated Whole Bug Report Reproduction for Android Apps
# 摘要
> 在软件开发领域，错误报告的重现一直是个难题。本文提出的 ReBL 方法，借助 GPT-4 这一大型语言模型，能自动重现 Android 错误报告，且无需依赖传统的“重现步骤”实体。通过全面利用错误报告文本并创新提示设计，ReBL 的上下文推理能力更强，灵活性和准确性也更高。不仅限于崩溃报告，ReBL 还能处理非崩溃错误报告。实验表明，ReBL 在 96 份报告中成功重现了 90.63%，平均处理时间仅 74.98 秒，且在成功率和速度上均超越了三种现有工具。
[Arxiv](https://arxiv.org/abs/2407.05165)
==========
# Lucy：运用思考与推理，攻克 Text-to-SQL 难题
发布时间：2024年07月06日
`LLM应用` `数据库`
> Lucy: Think and Reason to Solve Text-to-SQL
# 摘要
> LLM 在自然语言数据库查询方面取得了显著进展，但在处理大型企业数据库时性能受限。这些数据库的复杂关系对 LLM 构成了挑战。为此，我们提出了一种结合 LLM 理解能力与自动化推理技术的新方案，有效应对了这些复杂约束。基于此，我们开发的新框架在复杂基准测试中表现卓越，超越了现有技术。
[Arxiv](https://arxiv.org/abs/2407.05153)
==========
# Ripplet下的涡旋：RAG应用实证研究
发布时间：2024年07月06日
`LLM应用` `软件开发` `人工智能`
> Vortex under Ripplet: An Empirical Study of RAG-enabled Applications
# 摘要
> RAG增强的LLM在多种应用场景中表现出色，但开发者在集成过程中遇到诸多难题，如接口规范缺失、软件环境要求复杂等。我们深入分析了100个开源应用案例，发现几乎所有应用都存在集成缺陷，影响软件性能。为此，我们归纳了19种常见缺陷，并提供了解决方案。期待这些发现能助力LLM技术在软件开发中的应用，并推动相关领域的进一步研究。
[Arxiv](https://arxiv.org/abs/2407.05138)
==========
# 大型语言模型能否破解包含多于两个未知数的复杂数学难题？这一挑战正待揭晓。
发布时间：2024年07月06日
`LLM应用`
> Solving for X and Beyond: Can Large Language Models Solve Complex Math Problems with More-Than-Two Unknowns?
# 摘要
> 大型语言模型 (LLM) 在解决数学问题方面表现出色，但现有基准多聚焦于简单问题，未能充分考验其推理能力。为此，我们推出了 BeyondX 基准，通过引入多未知数问题来挑战 LLM。利用自动化流程，我们逐步增加问题复杂度，发现即使经过数学任务微调的 LLM，其性能也随未知数增多而大幅下降。针对这一难题，我们提出了 Formulate-and-Solve 策略，有效应对任意未知数问题。实证显示，该策略不仅提升了 LLM 在 BeyondX 上的表现，更深化了对 LLM 应对复杂数学挑战时计算极限的理解。
[Arxiv](https://arxiv.org/abs/2407.05134)
==========
# SHINE：基于显著性感知的层次负排序技术，用于组合时态定位任务
发布时间：2024年07月06日
`LLM应用` `视频处理`
> SHINE: Saliency-aware HIerarchical NEgative Ranking for Compositional Temporal Grounding
# 摘要
> 时间定位（视频时刻检索）旨在找到与查询句子匹配的视频片段。自然语言的组合特性使得定位超越预设事件成为可能，但也对现有方法的组合泛化能力构成挑战。近期研究通过分解-重建方式建立视频与查询的关联，以实现组合泛化。然而，这些研究仅关注主导原语，并通过随机采样与重组构建负查询，导致语义上不合理的负样本，妨碍模型学习合理组合。此外，基于DETR的方法在处理组合时间定位时仍显不足，面对与正查询细微不同的负查询时，显示出不合逻辑的显著性响应。为克服这些局限，我们首先提出一种利用GPT-3.5-Turbo生成语义合理硬负查询的大型语言模型驱动方法。接着，我们引入从粗到细的显著性排序策略，促使模型学习视频与层次化负查询间的多粒度语义关系，从而增强组合泛化能力。在两个挑战性基准上的广泛实验证实了我们方法的有效性与泛化性。代码已公开于https://github.com/zxccade/SHINE。
[Arxiv](https://arxiv.org/abs/2407.05118)
==========
# 借助 LLM 中的任务特定知识，实现半监督式 3D 医学图像分割
发布时间：2024年07月06日
`LLM应用` `人工智能`
> Leveraging Task-Specific Knowledge from LLM for Semi-Supervised 3D Medical Image Segmentation
# 摘要
> 传统的3D医学图像分割需要大量体素级标注，耗时且成本高昂。半监督学习（SSL）虽能缓解这一问题，但现有SSL模型仍难以充分挖掘未标注数据的潜力。为此，我们推出了LLM-SegNet，该模型借助大型语言模型（LLM）将专业知识融入协同训练框架，助力模型深入理解感兴趣区域（ROI）特征，实现更精准的分割。同时，我们设计了一种统一的分割损失函数，通过优化模型在自信与不确定区域的预测，进一步降低分割错误。在Left Atrium、Pancreas-CT和Brats-19等公开数据集上的实验显示，LLM-SegNet性能卓越，超越了现有顶尖模型。此外，消融研究也证实了LLM-SegNet各模块及损失函数的有效性。
[Arxiv](https://arxiv.org/abs/2407.05088)
==========
# 精简代码，强化对齐：利用数据修剪提升代码生成的 LLM 微调效率
发布时间：2024年07月06日
`LLM应用` `软件开发` `人工智能`
> Code Less, Align More: Efficient LLM Fine-tuning for Code Generation with Data Pruning
# 摘要
> 最新研究表明，通过合成代码生成增加训练数据量，大型语言模型在代码生成方面表现卓越。本文探讨了提高代码 LLM 训练效率的数据修剪方法，提出集成多种聚类和修剪指标的技术，确保在减少训练数据的同时，不牺牲生成代码的准确性和功能性。实验发现，仅用10%的数据训练即可大致保持基准性能，适度修剪训练数据还能持续提升基准结果。这些策略不仅节省计算资源，还提升了代码生成的质量。
[Arxiv](https://arxiv.org/abs/2407.05040)
==========
# 个性化生成推荐中的偏好蒸馏
发布时间：2024年07月06日
`LLM应用` `推荐系统` `个性化服务`
> Preference Distillation for Personalized Generative Recommendation
# 摘要
> 近期，研究者们探索了大型语言模型（LLM）在推荐系统中的应用。现有基于LLM的推荐模型通过在离散模板中加入用户和物品ID进行训练，但ID与自然语言的脱节限制了LLM学习用户关系的能力。为此，我们提出了个性化提示蒸馏（PeaPOD）方法，将用户偏好转化为个性化软提示。鉴于用户偏好的复杂性，我们采用一组动态加权的可学习提示，以组合方式构建个性化提示。实验表明，PeaPOD模型在序列推荐、top-n推荐及解释生成等任务中表现出色。
[Arxiv](https://arxiv.org/abs/2407.05033)
==========
# 如何得知？引导生成语言模型参照生物医学问题的答案
发布时间：2024年07月06日
`RAG` `生物医学` `搜索引擎`
> How do you know that? Teaching Generative Language Models to Reference Answers to Biomedical Questions
# 摘要
> 大型语言模型 (LLM) 已成为在线解答用户疑问的首选，但其答案的准确性和可靠性在生物医学等敏感领域尤为关键。为此，我们设计了一种生物医学检索增强生成 (RAG) 系统，通过微调 LLM 并结合 PubMed 相关摘要，确保答案的可靠性。用户可直接验证每条陈述的来源。与 PubMed 搜索引擎相比，我们的系统性能提升了 23%。在小规模评估中，我们的微调 LLM 在摘要引用方面与 GPT-4 Turbo 表现相当。我们还公开了微调所需的数据集及模型。
[Arxiv](https://arxiv.org/abs/2407.05015)
==========
# 是进步还是退步？训练后的自我提升出现了逆转现象。
发布时间：2024年07月06日
`LLM理论` `人工智能`
> Progress or Regress? Self-Improvement Reversal in Post-training
# 摘要
> 迭代偏好学习等训练后方法的自我改进，无需人工干预就能提升LLM的解题能力，如数学推理，备受赞誉。但深入探究后，我们需评估这些进步是否真能应对更难题，或可能导致意外退步。为此，我们设计了超越表面指标的全面评估框架，深入剖析训练后自我改进的实质。实验分析显示，“自我改进逆转”现象：虽在基准测试中表现提升，模型却在输出多样性和OOD泛化等关键能力上退步。这表明，当前训练后自我改进尚不足以应对复杂问题，并凸显了我们评估指标在区分LLM自我改进中进步与退步的必要性。
[Arxiv](https://arxiv.org/abs/2407.05013)
==========
# 探索视觉提示在多模态大型语言模型中的新角色，并研究外部知识如何增强其效能。
发布时间：2024年07月05日
`RAG` `计算机视觉` `人工智能`
> Rethinking Visual Prompting for Multimodal Large Language Models with External Knowledge
# 摘要
> 近年来，多模态大型语言模型 (MLLMs) 在处理图像方面取得了显著进展，但文本在传达细粒度或空间密集信息（如掩码）方面的局限性，限制了它们在理解详细视觉元素方面的能力。本文受检索增强生成 (RAG) 概念启发，提出一种新视觉提示方法，将专业视觉模型的细粒度知识融入 MLLMs，这是一个有前景但未充分探索的提升方向。与将外部知识转化为文本提示的方法不同，我们直接将细粒度知识嵌入空间嵌入图，作为视觉提示，可轻松融入多种 MLLMs，如 LLaVA 和 Mipha，大幅提升视觉理解性能。实验证明，我们的方法在九个基准上有效提升 MLLM 的细粒度上下文感知能力。
[Arxiv](https://arxiv.org/abs/2407.04681)
==========
# GPT 与 RETRO：探寻检索与高效参数微调的融合之道
发布时间：2024年07月05日
`RAG` `人工智能` `计算机科学`
> GPT vs RETRO: Exploring the Intersection of Retrieval and Parameter-Efficient Fine-Tuning
# 摘要
> 参数高效微调 (PEFT) 和检索增强生成 (RAG) 已成为适应大型语言模型同时降低计算需求的流行方法。本文中，我们采用 PEFT 方法（包括 P-tuning、Adapters 和 LoRA）对不同规模的修改版 RETRO 和基准 GPT 模型进行调整，参数范围从 8.23 亿到 480 亿。结果显示，RETRO 模型因其独特预训练过程在零-shot 环境下表现更佳，而 GPT 模型通过 PEFT 展现出更高性能潜力。研究还发现，80 亿参数模型在成本与性能间取得最佳平衡，P-tuning 则稍逊于其他 PEFT 技术。此外，我们对比了 PEFT 在指令调整 RETRO 模型与基础 RETRO 模型上的应用效果。本研究首次全面比较了 PEFT 与 RAG 结合在 GPT 和 RETRO 模型上的表现，凸显了各方法的相对优势。
[Arxiv](https://arxiv.org/abs/2407.04528)
==========
# EventChat：一款由大型语言模型驱动，专为中小企业背景下探索休闲活动而设计的对话推荐系统，其核心在于实现与用户为中心的评估。
发布时间：2024年07月05日
`LLM应用` `中小企业` `电子商务`
> EventChat: Implementation and user-centric evaluation of a large language model-driven conversational recommender system for exploring leisure events in an SME context
# 摘要
> 大型语言模型（LLM）在对话推荐系统（CRS）的战略潜力方面取得了显著进展。然而，当前研究主要聚焦于技术实施，而非终端用户评估或企业战略影响，尤其是对构成全球经济基石的中小型企业（SME）。本文详细阐述了LLM驱动的CRS在SME环境中的设计及其现场表现，结合客观系统指标与主观用户评价。同时，我们提出了一种简化的修订版ResQue模型，以促进这一快速发展领域的可复制性。研究显示，尽管用户体验良好（推荐准确率达85.5%），但延迟、成本和质量问题仍制约着商业可行性。例如，每次交互成本中位数为$0.04，延迟达5.7秒，凸显了成本效益与响应时间的重要性。此外，依赖基于提示的学习与ChatGPT等方法，在实际生产环境中难以确保高质量输出。针对SME部署LLM驱动的CRS，本文提出了战略考量，特别是在当前技术环境下的权衡选择。
[Arxiv](https://arxiv.org/abs/2407.04472)
==========
# AriGraph：利用情景记忆为 LLM 代理学习知识图谱世界模型，以增强其性能
发布时间：2024年07月05日
`Agent` `人工智能` `游戏开发`
> AriGraph: Learning Knowledge Graph World Models with Episodic Memory for LLM Agents
# 摘要
> 生成式AI的发展为大型语言模型（LLM）在自主代理开发中的应用开辟了新天地。要实现真正的自主，关键在于积累并更新从环境互动中获得的知识，并有效运用。目前，基于LLM的方法通过利用完整的观察历史、总结或检索增强来借鉴过往经验。然而，这些非结构化的记忆方式并不利于复杂决策所需的推理和规划。为此，我们提出了AriGraph方法，代理在探索环境的同时构建一个融合语义与情节记忆的图结构。这种图结构能高效地关联检索与代理当前状态和目标相关的概念，从而形成一个强大的环境模型，提升代理的探索与规划能力。实验证明，配备此记忆架构的Ariadne LLM代理，在TextWorld环境中以零-shot方式出色地完成了复杂任务，包括烹饪挑战、房屋清洁及拼图寻宝等，显著超越了传统方法。
[Arxiv](https://arxiv.org/abs/2407.04363)
==========
# 探讨如何利用较弱的LLMs来监督更强的LLMs，实现监督的可扩展性。
发布时间：2024年07月05日
`LLM应用` `人工智能`
> On scalable oversight with weak LLMs judging strong LLMs
# 摘要
> 本文探讨了可扩展监督协议，旨在帮助人类有效监管超人AI。我们通过辩论、咨询和直接问答三种模式进行研究。在辩论中，两个AI竞争说服裁判；在咨询中，单个AI回答裁判提问；而直接问答则不涉及AI。我们利用大型语言模型（LLM）模拟AI和人类裁判，发现辩论在所有任务中均优于咨询，尤其是在信息不对称的抽取式QA任务中。然而，在其他任务中，结果不一。此外，允许AI选择辩护答案时，辩论中裁判被错误答案误导的情况较少。更强的辩论者模型虽能提升裁判准确性，但效果不如预期显著。
[Arxiv](https://arxiv.org/abs/2407.04622)
==========
# VRSD：在大规模语言模型中，重新审视检索的相似性与多样性
发布时间：2024年07月05日
`LLM理论` `人工智能` `数据检索`
> VRSD: Rethinking Similarity and Diversity for Retrieval in Large Language Models
# 摘要
> 在大型语言模型（LLM）领域，向量检索算法对语义查询至关重要。同时满足相似性和多样性的向量检索，能显著提升LLM代理的能力。尽管最大边际相关性（MMR）在需要相关性和多样性的检索场景中广泛应用，但其参数$λ$的变化导致优化轨迹难以确定，进而影响增强方向的明确性。此外，对于检索过程中相似性和多样性的约束，理论分析尚显不足。本文通过总向量与查询向量之间的关系，巧妙地描述了这两种约束：向量的接近性确保了相似性，而总向量中各向量与查询向量的发散对齐则满足了多样性。我们还提出了一项新的组合优化挑战，即从候选集中选择$k$个向量，使总向量与查询向量最大程度对齐，并证明这是一个NP完全问题。这不仅揭示了同时追求相似性和多样性的难度，也为后续研究奠定了理论基础。此外，我们提出的启发式算法VRSD，不仅目标明确、无需预设参数，还在时间复杂度上优于MMR。实证验证显示，VRSD在多个数据集上均显著超越MMR。
[Arxiv](https://arxiv.org/abs/2407.04573)
==========
# LLM 参与“电话游戏”时，迭代文化传播中显现出累积变化与吸引子现象。
发布时间：2024年07月05日
`LLM应用` `人工智能` `通信技术`
> When LLMs Play the Telephone Game: Cumulative Changes and Attractors in Iterated Cultural Transmissions
# 摘要
> 随着 LLM 间的互动日益频繁，线上文本生成量激增，深入探究信息在 LLM 间传递时的变化显得尤为关键。尽管单个 LLM 的行为已得到广泛研究，但集体行为及信息扭曲在迭代交互中的影响却鲜被关注。微小的偏差，在单次输出中或许无足轻重，但在迭代交互中可能被放大，进而推动内容向特定状态演化。通过一系列电话游戏实验，我们借鉴人类文化进化理论，构建了传递链模型：LLM 代理依次接收、生成并传递文本。我们追踪了文本在传递过程中的毒性、积极性、难度和长度变化，揭示了偏差与吸引态的存在，并探讨了它们与初始文本、指令、模型类型及规模的关联。例如，开放式指令比约束性任务更易引发强吸引效应。此外，不同文本属性对吸引效应的敏感度各异，毒性比长度更易形成强吸引态。这些发现凸显了多步传输动态研究的重要性，为全面理解 LLM 文化动态奠定了基础。
[Arxiv](https://arxiv.org/abs/2407.04503)
==========
# 大型语言模型能否成为战略决策者？本研究探讨了在双人非零和游戏中，这些模型的表现及其潜在偏差。
发布时间：2024年07月05日
`LLM理论` `人工智能` `博弈论`
> Are Large Language Models Strategic Decision Makers? A Study of Performance and Bias in Two-Player Non-Zero-Sum Games
# 摘要
> 大型语言模型（LLM）在实际应用中日益增多，但其战略决策能力尚未充分挖掘。博弈论为评估LLM在与其他代理互动时的决策能力提供了有效框架。虽然先前研究显示，LLM能通过精心设计的提示解决特定任务，但面对变化的问题设置或提示时，它们往往表现不佳。本研究深入探讨了LLM在猎鹿游戏和囚徒困境等战略游戏中的行为，揭示了在不同游戏设置和提示下性能的波动。研究发现，最先进的LLM至少存在以下一种系统偏差：位置偏差、收益偏差或行为偏差。当游戏配置与这些偏差不匹配时，LLM的性能显著下降。性能评估依据于选择符合双方玩家偏好行为的正确行动，而一致性则指LLM的偏差是否与正确行动相符。例如，GPT-4o在偏差不一致时性能下降达34%。此外，“越大越新越好”的普遍观念在此并不适用，GPT-4o（目前表现最佳的LLM）性能下降最为严重。最后，尽管思维链提示能一定程度上减轻偏差影响，但仍未能从根本上解决问题。
[Arxiv](https://arxiv.org/abs/2407.04467)
==========
# MobileFlow：专为移动界面代理设计的多模态大型语言模型
发布时间：2024年07月05日
`LLM应用` `移动应用` `人工智能`
> MobileFlow: A Multimodal LLM For Mobile GUI Agent
# 摘要
> 移动图形用户界面（GUIs）已深入人们的日常生活。随着GPT-4v、Qwen-VL-Max等多模态大型模型的进步，智能GUI助手的潜力日益凸显。然而，现有GUI代理通过系统API获取布局信息的方式存在隐私隐患，且低分辨率固定可能导致细节丢失。此外，这些模型对中文GUI的理解和决策能力不足，难以广泛应用。为此，我们推出了MobileFlow，一款专为移动GUI代理设计的多模态大型语言模型。基于Qwen-VL-Chat，MobileFlow拥有约210亿参数，并引入混合视觉编码器，支持多语言和可变分辨率图像输入。通过专家混合（MoE）扩展及创新训练策略，MobileFlow能精准解读图像并理解用户指令，优化GUI交互。在评估中，MobileFlow超越了Qwen-VL-Max和GPT-4v，并已在实际商业场景中成功应用，展现了其强大的实用价值。
[Arxiv](https://arxiv.org/abs/2407.04346)
==========
# WOMD-Reasoning：专为交互与驾驶意图推理设计的大规模语言数据集
发布时间：2024年07月05日
`LLM应用` `自动驾驶`
> WOMD-Reasoning: A Large-Scale Language Dataset for Interaction and Driving Intentions Reasoning
# 摘要
> 我们推出了Waymo开放运动数据集-推理（WOMD-Reasoning），这是一个专注于驾驶场景中交互与意图描述和推理的语言标注数据集。与以往主要关注近距离交互的数据集不同，WOMD-Reasoning深入探讨了由交通规则和人类意图引发的远距离交互，这些交互虽常见但更具挑战性。数据集包含409k个Q&A，全面覆盖各类交互。此外，WOMD-Reasoning拥有约300万个Q&A，是目前最大的真实驾驶场景问答数据集，内容涵盖自动驾驶的多个方面，如地图描述、运动状态、交互行为及意图分析等。这些丰富的文本数据有助于微调大型语言模型（LLMs），提升其在场景描述、预测和规划等领域的应用能力。实验证明，结合WOMD-Reasoning的交互与意图信息后，最先进的轨迹预测模型Multipath++在性能上显著提升，$MR_6$和$minFDE_6$分别提高了10.14%和6.90%。我们期待WOMD-Reasoning能助力LLMs在驾驶领域实现更精准的交互理解和行为推理。数据集已开放下载，网址为https://waymo.com/open/download。
[Arxiv](https://arxiv.org/abs/2407.04281)
==========
# VCoME：融合多模态编辑效果的口头视频创作
发布时间：2024年07月05日
`LLM应用` `视频制作` `多媒体`
> VCoME: Verbal Video Composition with Multimodal Editing Effects
# 摘要
> 本文介绍了一项新颖任务——带有编辑效果的口头视频构图，旨在通过整合多模态编辑效果，创造出既连贯又吸引眼球的口头视频。我们构建了一个大规模视频效果数据集，并将任务定义为生成问题，涉及内容中适当位置的识别及相应编辑效果的推荐。为此，我们设计了VCoME框架，利用大型多模态模型智能生成编辑效果，支持灵活的构图控制。实验证明，VCoME不仅效果显著，而且效率惊人，比专业编辑快85倍，同时保持了专业级的视频质量。
[Arxiv](https://arxiv.org/abs/2407.04697)
==========
# 通过智能手机感应实现设备上 LLM 的个性化
发布时间：2024年07月05日
`LLM应用` `智能手机` `医疗保健`
> Enabling On-Device LLMs Personalization with Smartphone Sensing
# 摘要
> 本演示介绍了一种创新的端到端框架，它将设备上的大型语言模型（LLM）与智能手机传感技术相结合，旨在提供情境感知和个性化的服务。该框架通过在智能手机上部署LLM并结合多模态传感器数据和定制提示工程，有效解决了基于云的LLM在隐私、延迟和成本等方面的局限性。通过一个大学学生的案例研究，我们验证了该框架能够提供定制化的推荐服务。此外，该框架在隐私保护、性能、延迟、成本和能源消耗等方面实现了设备上与云LLM之间的最佳平衡。未来，我们将进一步整合更多样化的传感器数据，并开展大规模用户研究，以持续优化个性化服务。我们期待该框架能够在用户设备上提供安全、高效且情境感知的交互，从而在医疗保健、生产力和娱乐等多个领域显著提升用户体验。
[Arxiv](https://arxiv.org/abs/2407.04418)
==========
# WSDM2023 Toloka 视觉问答挑战亚军方案
发布时间：2024年07月05日
`LLM应用

解释：这篇论文描述了一个针对特定挑战赛的三阶段解决方案，其中使用了多模态预训练模型（可能是大型语言模型的一种应用）来处理视觉问答任务。尽管论文中没有直接提到“大型语言模型”（LLM），但使用了多模态预训练模型，这可以被视为LLM在特定应用场景中的使用。因此，我将这篇论文分类为“LLM应用”。` `计算机视觉` `人工智能`
> Second Place Solution of WSDM2023 Toloka Visual Question Answering Challenge
# 摘要
> 本文中，我们针对WSDM2023 Toloka视觉问答挑战赛，提出了一套三阶段的解决方案。借鉴多模态预训练模型在多种下游任务中的应用，我们将比赛视为视觉定位任务，通过图像和问题引导模型以边界框形式回答问题。首先，我们构建了一个大规模合成数据集，对OFA模型进行粗调，学习通用语义信息。接着，将任务转换为视觉定位，加载前阶段权重，在竞赛数据集上进一步微调，迁移语义知识。最后，通过边界框匹配替换策略优化预测结果。我们团队在排行榜上以76.342分位列第二。
[Arxiv](https://arxiv.org/abs/2407.04255)
==========
# 我、自我与AI：为LLM量身打造的情境意识数据集（SAD）
发布时间：2024年07月05日
`LLM理论` `人工智能` `数据分析`
> Me, Myself, and AI: The Situational Awareness Dataset (SAD) for LLMs
# 摘要
> AI助手如ChatGPT在回应用户时自称“我是一个大型语言模型”，这引发了疑问：这些模型是否真正了解自己的身份，并据此行动？它们是否意识到自己被公众使用的情境？我们将这种自我认知和环境感知称为“情境意识”。为了量化大型语言模型（LLM）的情境意识，我们设计了一系列基于问答和指令遵循的测试，形成了包含7大类任务和超过13,000个问题的情境意识数据集（SAD）。SAD测试了LLM的多项能力，如识别自身生成文本、预测行为、区分评估与实际部署环境、遵循基于自我认知的指令等。我们对16个LLM进行了SAD评估，包括预训练和聊天模型。尽管所有模型表现均优于随机水平，但即便是表现最佳的Claude 3 Opus，在某些任务上仍远未达到人类基准。我们还发现，SAD表现与一般知识指标（如MMLU）的相关性有限。经过微调以服务为AI助手的聊天模型，在SAD上表现优于其基础模型，但在一般知识任务上则不然。SAD旨在通过量化分析，深化对LLM情境意识的理解。情境意识至关重要，因为它提升了模型的自主规划与行动能力，虽为自动化带来潜在益处，但也带来了与AI安全和控制相关的新风险。相关代码和最新结果可访问https://situational-awareness-dataset.org。
[Arxiv](https://arxiv.org/abs/2407.04694)
==========
# ANAH-v2：大型语言模型分析幻觉标注的扩展研究
发布时间：2024年07月05日
`LLM应用` `人工智能`
> ANAH-v2: Scaling Analytical Hallucination Annotation of Large Language Models
# 摘要
> 大型语言模型在长篇问答任务中常出现幻觉现象，而现有的幻觉检测数据集因成本高和可靠性不足难以扩展。为此，本文提出一个迭代自训练框架，通过逐步扩大注释数据集和提升注释器准确性，有效监督 LLM 幻觉。实验显示，该框架训练出的 7B 参数注释器性能超越 GPT-4，在 HaluEval 和 HalluQA 上实现顶尖幻觉检测，并能提升 NLI 指标至 37%，助力减轻 LLM 幻觉问题。
[Arxiv](https://arxiv.org/abs/2407.04693)
==========
# Seed-ASR：借助 LLM 技术，深入探索多样语音与复杂上下文的识别奥秘
发布时间：2024年07月05日
`LLM应用` `语音识别` `人工智能`
> Seed-ASR: Understanding Diverse Speech and Contexts with LLM-based Speech Recognition
# 摘要
> 现代ASR模型需精准转录多样的语音信号，涵盖不同领域、语言及口音，并在多变场景中结合特定上下文信息。传统端到端模型虽与额外语言模型结合表现不俗，但主要局限于数据匹配场景，渐显瓶颈。为此，我们推出Seed-ASR，一款基于大型语言模型的语音识别系统。Seed-ASR依托音频条件LLM框架，通过整合连续语音与上下文信息至LLM，充分发挥其潜能。经过分阶段大规模训练及上下文感知能力激发，Seed-ASR在跨领域、口音/方言及多语言的综合评测中，显著超越端到端模型。更值得一提的是，Seed-ASR无需额外语言模型即可灵活适应各类场景特定需求。相较于近期问世的大型ASR模型，Seed-ASR在中英文公共测试集上，将词（或汉字）错误率大幅降低10%-40%，实力尽显。
[Arxiv](https://arxiv.org/abs/2407.04675)
==========
# Lazarus：通过自适应专家部署，实现混合专家模型的弹性与韧性训练。
发布时间：2024年07月05日
`LLM应用` `云计算` `人工智能`
> Lazarus: Resilient and Elastic Training of Mixture-of-Experts Models with Adaptive Expert Placement
# 摘要
> 稀疏激活的混合专家（MoE）架构因其对计算成本的次线性缩放特性，正被广泛用于扩展大型语言模型（LLM）。然而，随着训练规模的扩大，频繁的失败问题依然严峻。每一次失败都可能导致所有GPU空闲等待，直至问题解决，进而可能丢失大量训练进度。现有高效容错训练方案或缺乏弹性，或依赖于流水线并行中的弹性构建，但这些方案因MoE架构的专家并行策略而无法适用。为此，我们推出了Lazarus系统，专为MoE模型的弹性训练设计。Lazarus通过自适应分配专家副本，有效应对专家工作负载的不平衡，并加速训练进程。同时，我们开发了一种最优专家放置算法，以最大化失败时的恢复概率。借助自适应专家放置和灵活的令牌调度器，Lazarus能在失败后充分利用所有可用节点，确保无GPU空闲。评估结果表明，在频繁节点失败和真实现货实例环境下，Lazarus的性能分别比现有MoE训练系统高出5.7倍和3.4倍。
[Arxiv](https://arxiv.org/abs/2407.04656)
==========
# 实体分解结合过滤技术，开创了一种零-shot 临床命名实体识别的新框架。
发布时间：2024年07月05日
`LLM应用` `人工智能`
> Entity Decomposition with Filtering: A Zero-Shot Clinical Named Entity Recognition Framework
# 摘要
> 临床命名实体识别 (NER) 旨在从临床叙述中提取关键信息。最新研究表明，大型语言模型 (LLM) 在此领域表现出色。本文聚焦于开放 NER LLM，探讨其在临床 NER 中的应用。我们提出了一种创新框架——带过滤的实体分解 (EDF)，通过将任务分解为子实体类型检索，并结合过滤机制剔除错误实体，显著提升了识别准确性。实验证明，EDF 在各项评估中均表现优异。此外，我们进行了详尽的错误分析，为后续研究奠定了基础。
[Arxiv](https://arxiv.org/abs/2407.04629)
==========
# ARM：通过自回归奖励模型实现高效引导解码
发布时间：2024年07月05日
`LLM应用` `人工智能` `数据安全`
> ARM: Efficient Guided Decoding with Autoregressive Reward Models
# 摘要
> 为了确保在大量数据上训练的语言模型能够安全应用于现实世界，我们需要对其进行细致的调整。我们重新探讨了引导解码的方法，旨在通过任务特定奖励模型的分数来优化基础语言模型的输出。我们设计了一种既简单又高效的自动回归奖励模型参数化方案，使得引导解码既迅速又有效。实验表明，在去毒化和情感控制等任务中，我们的方法与效率较低但功能强大的RAD方法表现不相上下。
[Arxiv](https://arxiv.org/abs/2407.04615)
==========
# 大型语言模型在综合卫星-空中-地面网络中的应用：探索最新进展与未来发展方向
发布时间：2024年07月05日
`LLM应用` `网络管理`
> Leveraging Large Language Models for Integrated Satellite-Aerial-Terrestrial Networks: Recent Advances and Future Directions
# 摘要
> 集成卫星、航空和地面网络（ISATNs）通过融合多种通信技术，确保了不同高度和平台间的无缝连接。本文探讨了将大型语言模型（LLMs）融入ISATNs的变革潜力，借助先进的人工智能和机器学习技术，提升网络性能。我们概述了ISATNs的架构，并强调LLMs在优化数据流、信号处理和网络管理中的关键作用，助力5G/6G通信技术的发展。通过全面分析ISATN组件，我们评估了LLMs如何突破传统数据传输和处理的瓶颈。本文还深入探讨了ISATNs中的网络管理挑战，强调了复杂资源分配、流量路由和安全管理的必要性，以确保在各种条件下实现无缝连接和最佳性能。同时，我们考察了LLMs集成中的技术难题，如数据集成、可扩展性、决策延迟及系统健壮性和容错设计。研究还指出了未来研究方向，以充分发挥LLMs在ISATNs中的潜力，这对于提升网络可靠性、优化性能及构建真正互联智能的全球网络系统至关重要。
[Arxiv](https://arxiv.org/abs/2407.04581)
==========
# PoPreRo：一款专为预测罗马尼亚 Reddit 帖子热度而设计的新数据集
发布时间：2024年07月05日
`LLM应用` `社交媒体` `数据分析`
> PoPreRo: A New Dataset for Popularity Prediction of Romanian Reddit Posts
# 摘要
> 我们推出了PoPreRo，首个专注于Reddit上罗马尼亚帖子流行度预测的数据集，涵盖了五个不同子版块的28,107个样本。此外，我们还提供了一系列基准模型，供未来研究参考。测试结果显示，最佳模型的准确率达61.35%，宏观F1分数为60.60%，凸显了该任务的难度。通过少样本提示Falcon-7B大型语言模型的研究也证实了这一点。PoPreRo因此成为评估罗马尼亚社交媒体帖子流行度预测模型的重要资源，数据集已公开于https://github.com/ana-rogoz/PoPreRo。
[Arxiv](https://arxiv.org/abs/2407.04541)
==========
# Dude：一种双分布感知上下文提示学习方法，专为大型视觉-语言模型设计。
发布时间：2024年07月05日
`LLM应用` `计算机视觉` `机器学习`
> Dude: Dual Distribution-Aware Context Prompt Learning For Large Vision-Language Model
# 摘要
> 提示学习方法因其灵活性而备受瞩目，它利用预训练知识和小量数据就能将大型视觉-语言模型适应新领域。然而，现有方法在细粒度分类上常因识别属性不足而受限。为此，我们提出一个双重上下文框架，结合通用与特定类别的上下文，后者由GPT等LLM生成，以提升特征表达。我们还引入非平衡最优传输（UOT）理论，量化提示与视觉标记的关联，通过部分匹配优化对齐，有效处理噪声，并确保传输灵活性。UOT与图像增强结合，扩大样本池，同时保持输入间的合理距离。实验证明，我们的模型在少样本分类等任务中超越了现有顶尖技术。
[Arxiv](https://arxiv.org/abs/2407.04489)
==========
# 借助图结构，我们能够精准检测大型语言模型中的幻觉现象。
发布时间：2024年07月05日
`LLM应用` `客户服务`
> Leveraging Graph Structures to Detect Hallucinations in Large Language Models
# 摘要
> 大型语言模型在多个领域大显身手，如客户服务、内容创作、教育辅导和财务指导。但它们有个顽疾——容易产生“幻觉”，这严重影响了信息的可靠性，进而动摇了用户的信任和决策。为此，我们研发了一种新方法，通过分析潜在空间的结构，识别幻觉与真实生成之间的关联。我们构建了一个图结构，将嵌入空间中相近的生成内容相连。同时，我们运用图注意力网络，通过消息传递机制整合邻近节点的信息，并根据相关性赋予不同节点不同的权重。研究显示：1) 潜在空间中确实存在区分幻觉与真实生成的结构；2) 图注意力网络能学习并泛化这一结构至新内容；3) 结合对比学习能进一步提升方法的稳健性。在基于证据的测试中，即便不依赖搜索方法，我们的模型表现依旧出色。
[Arxiv](https://arxiv.org/abs/2407.04485)
==========
# 操控“耳语”：针对语音基础模型的通用声学对抗策略
发布时间：2024年07月05日
`LLM应用` `语音识别`
> Controlling Whisper: Universal Acoustic Adversarial Attacks to Control Speech Foundation Models
# 摘要
> 语音基础模型，无论是灵活的语音识别系统还是音频提示的大型语言模型（LLM），正日益流行。这些模型的独特之处在于，它们能通过适当提示执行自动语音识别（ASR）之外的任务，如OpenAI的Whisper模型既能转录音频也能翻译语音。随着音频提示LLM的发展，我们有望获得更多控制选项。然而，本研究揭示了这种灵活性可能使系统易受模型控制对抗攻击的影响。即使不接触模型提示，通过调整音频输入，也能改变系统行为。我们通过实验证明，只需在任何语音信号前添加一个短的通用对抗声学段，就能覆盖ASR基础模型的提示设置，例如让Whisper无视设定，始终执行语音翻译。这项研究揭示了多任务语音基础模型面临的新型对抗攻击，提醒我们在部署此类模型前需谨慎考虑。
[Arxiv](https://arxiv.org/abs/2407.04482)
==========
# LoCo：专为大规模模型训练设计的低比特通信适配器
发布时间：2024年07月05日
`LLM理论` `计算机科学` `人工智能`
> LoCo: Low-Bit Communication Adaptor for Large-scale Model Training
# 摘要
> 为了提升大规模模型的训练效率，我们引入了低比特通信适配器（LoCo），通过在压缩前补偿本地GPU节点的梯度，确保高效的梯度同步且不牺牲训练质量。LoCo利用历史补偿误差的移动平均值来稳定估计并补偿当前梯度压缩，实现了更优的压缩效果。这一创新机制不仅与通用优化器和分片策略兼容，还通过理论分析证实了其对优化器收敛速度的正面影响。实验证明，LoCo在大规模模型训练中显著提升了通信效率，例如，在不影响性能的前提下，将Adam的训练速度提升了14%至40%。
[Arxiv](https://arxiv.org/abs/2407.04480)
==========
# 通用型与专家型：探究大型语言模型在乌尔都语领域的评估
发布时间：2024年07月05日
`LLM应用` `机器学习`
> Generalists vs. Specialists: Evaluating Large Language Models for Urdu
# 摘要
> 本文对比了通用预训练模型 GPT-4-Turbo 和 Llama-3-8b-Instruct，以及针对特定任务微调的专用模型 XLM-Roberta-large、mT5-large 和 Llama-3-8b-Instruct，在乌尔都语的七项分类和六项生成任务上的表现。乌尔都语虽有 7000 万母语者，但在 NLP 领域仍显不足。尽管 LLMs 不断进步，其在低资源语言如乌尔都语的表现仍待探索。我们还进行了生成任务的人工评估，并与 GPT-4-Turbo 和 Llama-3-8b-Instruct 的评估结果对比。结果显示，专用模型在各任务中表现更佳，且 GPT-4-Turbo 的生成任务评估更贴近人工评估。本文通过探讨通用与专用 LLMs 对低资源语言的有效性，为 NLP 社区提供了宝贵见解。
[Arxiv](https://arxiv.org/abs/2407.04459)
==========
# XLSR-Transducer：为自监督预训练模型设计的流式自动语音识别技术
发布时间：2024年07月05日
`LLM应用` `语音识别` `人工智能`
> XLSR-Transducer: Streaming ASR for Self-Supervised Pretrained Models
# 摘要
> 自监督预训练模型在自动语音识别的微调中表现出色，即便训练数据有限。但这些流行的预训练模型因采用全注意力上下文训练而不适用于流式ASR。本文中，我们提出了XLSR-Transducer，利用XLSR-53模型作为转录器编码器。实验显示，XLSR-Transducer在AMI数据集上分别比Whisper large-v2和从头训练的Zipformer转录器模型提升了4%和8%的WER。为实现流式处理，我们探索了XLSR-53模型变换器层中不同的注意力掩蔽模式。在低资源环境下，XLSR-Transducer在AMI及CommonVoice的五种语言上表现优异。通过引入注意力汇聚点，我们不仅将左上下文减半，还实现了WER相对提升12%。
[Arxiv](https://arxiv.org/abs/2407.04439)
==========
# 从“Showgirls”到“Performers”：通过性别包容性语言的微调，减少 LLMs 中的偏见
发布时间：2024年07月05日
`LLM应用` `人工智能` `性别研究`
> From 'Showgirls' to 'Performers': Fine-tuning with Gender-inclusive Language for Bias Reduction in LLMs
# 摘要
> 性别偏见不仅在大型语言模型（LLM）及其训练数据中普遍存在，还深植于语言结构之中。为此，我们专注于调整LLM训练数据中的语言结构，以促进性别包容性，使模型中的性别表示更加多元。我们特别关注英语中的性别排他性词缀，如'show-girl'或'man-cave'，这些词缀可能强化性别刻板印象和二元性别观念。通过编制一个包含692个性别排他性词汇及其性别中性变体的目录，我们开发了名为'Tiny Heap'的性别包容性微调数据集。使用此数据集对三个不同LLM进行微调后，我们发现模型中的性别刻板印象有所减少。这一方法不仅为提升LLM训练数据的性别包容性提供了实用途径，还为在NLP偏见缓解研究中融入酷儿女性主义语言行动主义做出了贡献。
[Arxiv](https://arxiv.org/abs/2407.04434)
==========
# cosmosage：专为宇宙学家打造的自然语言助手
发布时间：2024年07月05日
`LLM应用` `宇宙学`
> cosmosage: A Natural-Language Assistant for Cosmologists
# 摘要
> cosmosage，一款面向各层次用户的自然语言助手，从宇宙学爱好者到专业人士，都提供了独特的知识获取与推理途径。借助强大的大型语言模型，它从众多开放资源中汲取智慧，涵盖教科书与学术论文。在解答宇宙学问题方面，cosmosage 表现卓越，超越了其他通用模型，其模型参数与代码均已公开。
[Arxiv](https://arxiv.org/abs/2407.04420)
==========
# 利用视觉增强字幕提升音频生成效果
发布时间：2024年07月05日
`LLM应用` `音频处理` `数据集构建`
> Improving Audio Generation with Visual Enhanced Caption
# 摘要
> 生成模型在音频生成领域取得了显著进展，但在处理复杂细节时仍显不足。我们认为，这主要归咎于训练数据的质与量。为此，我们构建了一个大规模音频数据集，配备详尽描述，旨在提升模型性能。通过自动化流程，我们利用大型语言模型将视觉、音频描述及标签转化为全面描述，创造了Sound-VECaps数据集，包含166万对高质量音频描述，涵盖事件顺序、地点及环境等丰富信息。实验表明，该数据集能显著增强模型对复杂输入的理解与生成能力，提升整体性能。此外，消融研究显示其在音频-文本学习领域的广阔前景。相关资源已在线开放。
[Arxiv](https://arxiv.org/abs/2407.04416)
==========
# Waterfall：一个专为文本水印设计的稳健且可扩展的框架
发布时间：2024年07月05日
`LLM应用` `知识产权保护` `网络安全`
> Waterfall: Framework for Robust and Scalable Text Watermarking
# 摘要
> 随着复杂攻击手段的出现，如利用大型语言模型（LLM）进行文本改述或未经授权训练LLM侵犯版权，保护文章和代码等文本的知识产权变得尤为关键。然而，现有文本水印技术在抵御这些攻击和扩展至大规模用户方面存在不足。为此，我们推出了Waterfall，首个无需训练的强大且可扩展的文本水印框架，支持多种文本类型和语言。Waterfall的创新之处在于利用LLM进行水印处理，并巧妙结合多项技术，有效提升可验证性和可扩展性。实证研究表明，Waterfall在可扩展性、可验证性和计算效率上均优于现有技术，并可直接应用于代码水印。
[Arxiv](https://arxiv.org/abs/2407.04411)
==========
# 探索色觉缺陷的上下文感知支持：融合 LLM 与 AR 的创新途径
发布时间：2024年07月05日
`LLM应用` `辅助技术`
> Towards Context-aware Support for Color Vision Deficiency: An Approach Integrating LLM and AR
# 摘要
> 色觉缺陷者在区分红绿等颜色时常常遇到困难，这使得日常任务变得复杂，需要借助辅助工具或调整环境。目前，辅助工具多聚焦于呈现层面的帮助，例如iPhone的色觉模式。然而，提供情境感知支持，如判断肉类熟度，仍是一大挑战，因为特定任务的解决方案难以覆盖所有场景。为此，我们提出了一款结合增强现实界面和多模态大型语言模型推理器的应用程序，旨在提供情境感知和自主辅助。初步实验显示，该应用在多种场景下均表现出色，有效辅助了色觉缺陷者的日常生活。
[Arxiv](https://arxiv.org/abs/2407.04362)
==========
# 精雕细琢，打造更具透明度的大型语言模型
发布时间：2024年07月05日
`LLM理论` `人工智能` `语言模型`
> Crafting Large Language Models for Enhanced Interpretability
# 摘要
> 我们推出了概念瓶颈大型语言模型 (CB-LLM)，这是一种创新方法，旨在构建本质上可解释的 LLM。与依赖后验解释的传统黑箱模型不同，CB-LLM 通过内置的可解释性、可扩展性和提供清晰准确解释的能力，树立了新标杆。这一创新不仅提升了语言模型的透明度，还增强了其效能。我们的自动概念校正 (ACC) 策略有效缩小了与传统黑箱模型的性能差距，使 CB-LLM 成为兼具高准确性和清晰可解释性的模型，这是现有 LLM 所缺乏的显著特点。
[Arxiv](https://arxiv.org/abs/2407.04307)
==========
# 大型语言模型面临的越狱攻击及其防御策略：全面调查
发布时间：2024年07月05日
`LLM理论` `网络安全` `人工智能`
> Jailbreak Attacks and Defenses Against Large Language Models: A Survey
# 摘要
> 大型语言模型在多项文本生成任务中表现卓越，但过度辅助也带来了“越狱”风险，即通过对抗性提示诱导模型产生违规的恶意回应。随着越狱攻击手段的多样化，安全防护措施也在不断进化。本文中，我们详尽地分类了越狱攻击与防御策略，如根据模型透明度划分的黑盒与白盒攻击，以及提示级与模型级的防御措施。我们进一步细分这些策略，并通过图表清晰展示其关联。此外，我们还审视了现有的评估方法，并进行了多角度比较。我们的研究旨在启发未来在提升 LLM 安全性方面的探索与实践。尽管越狱问题仍备受关注，我们相信本研究深化了对此领域的认识，并为构建更安全的语言模型奠定了基础。
[Arxiv](https://arxiv.org/abs/2407.04295)
==========
# Corki：借助算法与架构的协同设计，赋能实时具身AI机器人。
发布时间：2024年07月05日
`LLM应用` `机器人` `制造业`
> Corki: Enabling Real-time Embodied AI Robots via Algorithm-Architecture Co-Design
# 摘要
> 具身AI机器人有望彻底改变人类的生活与制造方式。在利用大型语言模型控制机器人的前沿领域，高效计算基底是持续进步的关键。当前的计算系统仅考虑算法开发者需求，将机器人动作分割为离散帧，导致高延迟和高能耗。为此，我们提出Corki框架，通过解耦LLM推理、机器人控制和数据通信，优化具身AI机器人的实时控制。Corki预测未来轨迹而非单帧动作，大幅降低LLM推理频率，最高可达8倍，速度提升3.6倍，成功率提高17.3%。代码已公开，便于复现。https://github.com/hyy0613/Corki
[Arxiv](https://arxiv.org/abs/2407.04292)
==========
# BiosERC：结合 LLM 辅助的传记演讲者，提升 ERC 任务表现
发布时间：2024年07月05日
`LLM应用` `情感分析` `对话系统`
> BiosERC: Integrating Biography Speakers Supported by LLMs for ERC Tasks
# 摘要
> 在对话情感识别领域，最新研究通过注意力机制深入剖析了说话者间及内部的语句关系，以捕捉情感交流。然而，说话者的个性特质等要素尚未得到充分挖掘，且在跨任务应用和模型架构兼容性方面面临挑战。为此，我们推出了BiosERC框架，专注于对话中的说话者特征研究。借助大型语言模型，我们提取对话中的说话者“传记信息”，将其作为辅助知识融入模型，以精准分类语句情感。该方法在IEMOCAP、MELD和EmoryNLP三大权威数据集上创下佳绩，彰显了模型的卓越性能与广泛适用性，预示着其在多样对话分析任务中的广阔前景。源代码已公开，详见https://github.com/yingjie7/BiosERC。
[Arxiv](https://arxiv.org/abs/2407.04279)
==========
# MMSci：专为博士级科学理解设计的多模态多学科数据集
发布时间：2024年07月05日
`LLM应用` `科学研究` `人工智能`
> MMSci: A Multimodal Multi-Discipline Dataset for PhD-Level Scientific Comprehension
# 摘要
> 随着大型语言模型（LLM）和大型多模态模型（LMM）的迅猛发展，市场对能够深入理解科学文献和图表的AI助手需求日益增长。然而，在评估模型对高难度科学内容的理解能力方面，现有数据集和基准仍显不足。为此，我们从《自然通讯》期刊中精选了一个跨72个学科的多模态数据集，旨在全面评估LMM在科学领域的应用能力。我们的研究发现，这些任务难度极大，众多开源模型表现不佳，GPT-4V和GPT-4o也遭遇挑战。此外，我们利用该数据集进行模型训练，成功提升了7B LLaVA模型在特定任务上的表现，并探索了预训练方法以进一步优化模型性能。所有相关资源，包括文章、图表、基准测试和训练数据，均已公开，以促进科学AI领域的发展。
[Arxiv](https://arxiv.org/abs/2407.04903)
==========
# MJ-Bench 质疑：你的多模态奖励模型在文本到图像生成领域是否真的称职？
发布时间：2024年07月05日
`LLM应用` `人工智能` `图像处理`
> MJ-Bench: Is Your Multimodal Reward Model Really a Good Judge for Text-to-Image Generation?
# 摘要
> 随着DALLE-3和Stable Diffusion等文本到图像模型的快速增长，它们面临的幻觉、偏见和低质量输出问题日益凸显。为应对这些挑战，根据多模态反馈调整模型行为显得尤为关键。然而，现有多模态判断的评估往往不足，可能导致调整失误和安全风险。为此，我们推出了MJ-Bench基准，通过全面的首选项数据集，从对齐、安全、图像质量和偏见四个维度评估多模态判断的反馈质量。实验显示，闭源VLM如GPT-4o在反馈质量上领先，而小型评分模型在文本-图像对齐和图像质量方面表现更佳。此外，VLM在安全性和偏见反馈上更为精准。研究还发现，VLM在自然语言反馈上比数值反馈更为准确稳定。最终，基于多模态判断的独立反馈进行的模型评估，进一步验证了MJ-Bench的有效性。相关资源已公开在https://huggingface.co/MJ-Bench。
[Arxiv](https://arxiv.org/abs/2407.04842)
==========
# RAMO：通过检索增强生成技术，提升 MOOCs 推荐效果
发布时间：2024年07月05日
`LLM应用` `在线学习`
> RAMO: Retrieval-Augmented Generation for Enhancing MOOCs Recommendations
# 摘要
> MOOCs通过提供多样课程，打破了地理、经济和时间的限制，极大地提升了教育普及率。然而，学生在面对海量课程时往往感到迷茫，尤其是在涉足新领域时。为此，研究者们开发了课程推荐系统，旨在根据个人学习倾向和职业目标提供定制化建议。这些系统在解决新用户“冷启动”问题上存在挑战。最新技术进展显示，将LLMs融入推荐流程能提升个性化推荐并解决“冷启动”问题。基于此，我们推出了RAMO系统，该系统结合LLMs和RAG技术，通过对话式界面提供课程推荐，致力于优化在线学习体验。
[Arxiv](https://arxiv.org/abs/2407.04925)
==========
# 元提示优化检索增强生成技术
发布时间：2024年07月04日
`RAG` `问答系统` `人工智能`
> Meta-prompting Optimized Retrieval-augmented Generation
# 摘要
> 检索增强生成通过利用外部检索内容提升大型语言模型在下游任务中的表现。然而，检索内容过多或分散可能导致负面效果。为此，我们提出一种通过元提示优化精炼检索内容的方法，以提升生成质量。在StrategyQA数据集的多跳问答任务中，该方法表现优于传统检索增强系统30%以上。
[Arxiv](https://arxiv.org/abs/2407.03955)
==========
# TongGu：借助知识驱动的大型语言模型，精通古典中文理解
发布时间：2024年07月04日
`LLM应用`
> TongGu: Mastering Classical Chinese Understanding with Knowledge-Grounded Large Language Models
# 摘要
> 古典中文，承载着古代中国的深厚文化和智慧，但其复杂性常令现代人望而却步。尽管大型语言模型在自然语言处理领域表现出色，但在古典中文理解这一领域，尤其是在数据密集和知识要求高的任务中，仍显不足。为此，我们推出了首个专为古典中文理解设计的LLM——**通古**，它基于三大核心创新。首先，我们创建了一个两阶段指令调优数据集ACCN-INS，源自丰富的古典中文语料，旨在充分挖掘LLM在古典中文理解方面的潜能。其次，我们引入了冗余感知调优（RAT）策略，确保通古在掌握新技能的同时，不忘基础知识。最后，我们开发了基于知识支撑的CCU检索增强生成技术（CCU-RAG），有效减少信息失真。通过24项多样化的CCU任务测试，通古展现了其卓越性能，证明了RAT和CCU-RAG技术的有效性。通古模型及其数据集将向公众开放。
[Arxiv](https://arxiv.org/abs/2407.03937)
==========
# 利用大型语言模型实现 C/C++ 程序在高级综合中的自动化修复
发布时间：2024年07月04日
`RAG` `半导体` `软件开发`
> Automated C/C++ Program Repair for High-Level Synthesis via Large Language Models
# 摘要
> 在高级综合（HLS）领域，将C/C++程序转换为HLS-C程序仍需大量人工操作。虽然已有多种脚本尝试自动化这一过程，但生成的代码往往问题频发，需开发者手动修正。鉴于大型语言模型（LLMs）在代码生成方面的潜力，它们也被探索用于HLS程序的自动修复。然而，LLMs在同时处理硬件与软件方面的训练不足，可能导致修复过程中的“幻觉”现象，进而引发编译失败。此外，LLMs的迭代修复成本也相对较高。为此，我们设计了一个由LLM驱动的程序修复框架，该框架能自动将C/C++代码转换为HLS-C代码，并尽量减少人工干预。为减少LLMs的幻觉并提升修复质量，我们采用了检索增强生成（RAG）方法来引导LLMs进行准确修复。同时，利用LLMs进行静态位宽优化，以确定变量的最佳位宽。我们还引入了LLM驱动的HLS优化策略，通过调整HLS-C程序中的编译指示来优化电路性能。实验显示，与传统脚本及直接使用LLMs修复相比，我们的自动化框架在24个实际应用中显著提高了修复成功率。
[Arxiv](https://arxiv.org/abs/2407.03889)
==========
# 借助约束引导的多智能体系统，破解斑马谜题
发布时间：2024年07月04日
`Agent` `人工智能`
> Solving Zebra Puzzles Using Constraint-Guided Multi-Agent Systems
# 摘要
> 以往的研究通过思维链提示或符号表示等技术，提升了大型语言模型 (LLM) 解决逻辑谜题的能力。然而，这些方法在处理如 Zebra 谜题这类复杂逻辑问题时仍显不足。为此，我们开发了多智能体系统 ZPS，它结合 LLM 与现成的定理证明器，通过问题分解、生成 SMT 代码及智能体间反馈循环，有效解决复杂谜题。此外，我们设计了自动网格谜题评分器，确保解决方案的正确性，并通过用户研究验证其可靠性。实验表明，我们的方法在所有测试的 LLM 中均有显著提升，GPT-4 的完全正确解决方案数量提升了 166%。
[Arxiv](https://arxiv.org/abs/2407.03956)
==========
# MobileExperts：移动设备中的动态工具化代理团队
发布时间：2024年07月04日
`Agent` `移动计算` `人工智能`
> MobileExperts: A Dynamic Tool-Enabled Agent Team in Mobile Devices
# 摘要
> 移动计算设备的自主操作一直是人类的追求目标。随着LLMs和VLMs的进步，这一梦想正逐步成真。尽管VLMs已能自动化简单任务，但在复杂任务处理和推理成本降低方面仍有巨大提升空间。本文提出的MobileExperts，首次通过工具制定和多智能体协作应对这些挑战。它根据智能体与人类需求匹配度动态组队，每个智能体独立探索并成长为专家，再通过双层规划机制实现专家间的高效协作。为验证其效能，我们设计了分层智能级别的新基准，实验显示MobileExperts在各级别表现优异，推理成本降低约22%，充分证明了其设计的优越性。
[Arxiv](https://arxiv.org/abs/2407.03913)
==========
# 利用大型语言模型规划对话代理
发布时间：2024年07月04日
`Agent` `对话系统`
> Planning with Large Language Models for Conversational Agents
# 摘要
> 自主对话代理（CAs）的核心在于可控性与主动性。可控性意味着CAs需遵循标准操作流程（SOPs），如激活信用卡前的身份验证；主动性则要求CAs在用户不配合时引导对话达成目标，如进行说服性交流。当前研究难以兼顾这三者：可控性、主动性与低成本的手动标注。为此，我们创新性地提出了一个基于计划的大型语言模型（LLMs）驱动的对话代理框架（PCA），仅需人类设定任务与目标。对话前，LLM离线制定关键SOP；对话中，LLM在线依据SOP规划最优行动，确保对话过程的可控。此外，我们构建了半自动对话数据生成框架，并精心打造了高质量对话数据集（PCA-D）。我们还研发了多种PCA变体及评估标准，如采用蒙特卡洛树搜索（PCA-M）的规划方法，该方法在遵守SOP的同时，寻找最优对话策略，增强对话的主动性。实验表明，经PCA-D微调的LLMs性能大幅提升，且能适应新领域。PCA-M在多个维度上超越传统基线，适用于实际工业对话场景。相关数据集与代码已公开于XXXX。
[Arxiv](https://arxiv.org/abs/2407.03884)
==========
# 超越混沌边缘？过度复杂性成为人工通用智能之路的绊脚石
发布时间：2024年07月04日
`LLM理论` `人工智能` `复杂性理论`
> Over the Edge of Chaos? Excess Complexity as a Roadblock to Artificial General Intelligence
# 摘要
> 本研究通过复杂性理论视角，深入探讨了AI系统的演进路径。我们质疑了传统上对AI向AGI发展的线性和指数预测，并提出了AI性能在达到某个复杂性临界点后可能停滞或变得不稳定的观点。通过基于代理的建模，我们模拟了AI系统在特定条件下的演化，以基准性能衡量其能力和复杂度。模拟结果显示，AI系统复杂度的增加可能导致性能行为的不可预测性。此外，我们提出了一种实用方法，利用模拟数据和随机梯度下降技术来识别这些关键阈值。这项研究为理解AI发展提供了新视角，特别强调了在评估AI潜力时需谨慎，并呼吁建立更全面的AI性能评估标准。
[Arxiv](https://arxiv.org/abs/2407.03652)
==========
# M$\mathbf5$ 是一个多元化基准，旨在全面评估大型多模态模型在跨语言和文化视觉-语言任务中的表现。
发布时间：2024年07月04日
`LLM应用` `人工智能` `多模态学习`
> M$\mathbf5$ -- A Diverse Benchmark to Assess the Performance of Large Multimodal Models Across Multilingual and Multicultural Vision-Language Tasks
# 摘要
> 自ChatGPT问世以来，自然语言处理领域飞速进步，特别是在大型语言模型（LLMs）和大型多模态模型（LMMs）方面。尽管这些模型能力出众，但在不同语言和文化环境中，其性能差异显著，这在纯文本基准测试中可见一斑。然而，针对多模态视觉语言环境的研究却缺乏相应的基准。为此，我们推出了M5，这是首个全面评估LMMs在多语言和文化背景下视觉语言任务的基准。M5包含八个数据集，覆盖五个任务和41种语言，特别关注那些代表性不足的语言和具有文化多样性的图像。同时，我们新增了两个数据集M5-VGR和M5-VLOD，并引入了一项新的视觉语言异常检测任务，结果显示，所有评估的开源模型均未能显著超越随机基准。通过深入评估和分析，我们揭示了高资源和低资源语言之间在任务无关的性能差异。此外，我们还发现，在多语言环境中，模型的大小并非决定性能的关键因素。
[Arxiv](https://arxiv.org/abs/2407.03791)
==========
# MRIR：融合多模态洞察，实现基于扩散技术的真实图像修复
发布时间：2024年07月04日
`LLM应用` `计算机视觉` `图像处理`
> MRIR: Integrating Multimodal Insights for Diffusion-based Realistic Image Restoration
# 摘要
> 图像修复在计算机视觉领域至关重要，而基于扩散模型的应用因其逼真效果备受瞩目。尽管如此，图像质量因退化严重和模型不可控而面临挑战。我们探索预训练稳定扩散的潜力，提出MRIR方法，从文本和视觉两方面入手。文本层面，我们借助多模态大型语言模型提取低质量图像的语义信息；视觉层面，我们通过像素级处理器和ControlNet精细控制图像结构。最终，通过多级注意力机制，我们将这些控制信息融入去噪U-Net，实现多模态视角下的可控图像修复。实验证明，我们的方法在合成与真实数据集上均超越现有顶尖技术。
[Arxiv](https://arxiv.org/abs/2407.03635)
==========
# 护理笔记的自监督摘要，由查询引导
发布时间：2024年07月04日
`LLM应用` `临床护理`
> Query-Guided Self-Supervised Summarization of Nursing Notes
# 摘要
> 护理记录作为电子健康记录的关键部分，记录了患者护理期间的健康进展。通过文本摘要技术提炼这些记录中的关键信息，能显著提升临床医生理解患者状况的效率。然而，现有临床摘要方法常忽略护理记录，且需耗时创建参考摘要。为此，我们提出了QGSumm框架，利用患者相关临床查询引导，生成高质量、以患者为中心的摘要，无需参考摘要。经自动与临床专家手动评估，我们的方法在零-shot和few-shot环境下均优于顶尖大型语言模型。这一创新为条件文本摘要开辟了新视角，更贴合临床人员的实际需求。
[Arxiv](https://arxiv.org/abs/2407.04125)
==========
# 幻觉检测：在大规模语言模型中，如何稳健地识别出可靠答案，是一项关键任务。
发布时间：2024年07月04日
`LLM应用` `人工智能`
> Hallucination Detection: Robustly Discerning Reliable Answers in Large Language Models
# 摘要
> 大型语言模型（LLM）在问答和对话系统等自然语言处理任务中广受欢迎，但其幻觉问题——生成与输入不符的内容——却带来了严重问题。为此，我们设计了名为 RelD 的鲁棒判别器，专门用于检测 LLM 生成的答案中的幻觉。RelD 基于我们构建的双语问答对话数据集 RelQA 进行训练，并结合了 LLM 生成的答案及一系列全面指标。实验显示，RelD 能有效识别不同 LLM 生成的答案中的幻觉，无论数据来源如何。同时，我们对幻觉类型进行了深入分析，揭示了宝贵见解。这项研究不仅提升了 LLM 生成答案的可靠性检测，也为未来减轻幻觉问题提供了重要启示。
[Arxiv](https://arxiv.org/abs/2407.04121)
==========
# MAPO 技术通过模型自适应提示优化，显著提升大型语言模型的性能。
发布时间：2024年07月04日
`LLM应用` `人工智能`
> MAPO: Boosting Large Language Model Performance with Model-Adaptive Prompt Optimization
# 摘要
> Prompt engineering 作为利用大型语言模型的有效手段，备受研究界瞩目。现有研究侧重于将提示适配特定任务而非特定模型。然而，优质提示不仅取决于措辞，还与模型特性紧密相关。本研究首先通过定量分析，证明不同提示应针对不同模型进行优化，以提升其在 NLP 各类下游任务中的表现。接着，我们创新提出模型自适应提示优化器 (MAPO)，专门针对各模型优化提示。实验证明，该方法能显著提升模型在下游任务中的性能。
[Arxiv](https://arxiv.org/abs/2407.04118)
==========
# 未来事件可能成为 LLM 的后门触发器，本研究深入探讨这些模型中的时间脆弱性。
发布时间：2024年07月04日
`LLM应用` `人工智能安全` `网络安全`
> Future Events as Backdoor Triggers: Investigating Temporal Vulnerabilities in LLMs
# 摘要
> 后门行为在AI系统部署后才会显现，恶意设计者需确保其在训练和评估阶段不激活。由于这些阶段的数据通常仅涉及已发生事件，一个简单的后门触发机制可能是模型识别未来数据。我们的实验显示，大型语言模型能以90%的准确率区分过去与未来事件。我们训练的模型在接触到训练截止日期之后的新闻标题时会触发后门。尽管在有益、无害和诚实数据上的微调对简单后门效果有限，但对我们的后门模型却颇为有效，尤其是对于较小规模的模型。此外，模型内部对日期的表示方式也影响后门激活频率。这些发现表明，对于适度规模的模型，常规安全措施足以消除这些后门。我们已公开所有相关资源，包括代码、数据集和模型。
[Arxiv](https://arxiv.org/abs/2407.04108)
==========
# MiniGPT-Med：将大型语言模型打造为放射学诊断的多面手
发布时间：2024年07月04日
`LLM应用` `放射学`
> MiniGPT-Med: Large Language Model as a General Interface for Radiology Diagnosis
# 摘要
> AI在医疗领域的最新进展，特别是在诊断流程的优化上，取得了重大突破。然而，过往研究多受限于功能单一。本研究推出的MiniGPT-Med，是一款专为医疗定制的视觉-语言模型，源自大型语言模型。该模型在X光、CT和MRI等多种影像模式中展现出卓越的多功能性，极大提升了应用价值。它能完成医疗报告生成、视觉问答及影像内疾病识别等任务，通过整合图像与文本数据，显著提升诊断精准度。实测表明，MiniGPT-Med在疾病定位、报告生成及问答测试中表现卓越，大幅缩小了辅助放射学实践的差距。其在医疗报告生成上的准确率更是领先同行19%，预示着它将成为放射学诊断的通用平台，全面提升医疗影像诊断的效率。
[Arxiv](https://arxiv.org/abs/2407.04106)
==========
# Stephanie：通过逐步对话，巧妙模仿社交场合中的人类互动
发布时间：2024年07月04日
`LLM应用` `聊天机器人`
> Stephanie: Step-by-Step Dialogues for Mimicking Human Interactions in Social Conversations
# 摘要
> 在自然语言处理领域，对话系统多采用单一步骤对话模式，虽高效但缺乏自然互动的深度与流畅性。为此，我们创新性地提出了**步骤**-by-步骤对话范式（Stephanie），模拟人类对话的动态过程。通过双重学习策略与细分后编辑技术，我们构建了高质量的步骤-by-步骤对话数据集，并用于微调大型语言模型，使其能进行更自然的对话。我们详细介绍了Stephanie，并通过定制评估验证了其优于传统范式的效果。未来，我们将公开代码、数据集及模型，助力聊天机器人技术的进步。
[Arxiv](https://arxiv.org/abs/2407.04093)
==========
# DotaMath：借助代码辅助与自我修正，实现数学推理思维的精细分解
发布时间：2024年07月04日
`LLM应用`
> DotaMath: Decomposition of Thought with Code Assistance and Self-correction for Mathematical Reasoning
# 摘要
> 大型语言模型（LLM）在简单数学问题上取得了显著进步，但在处理更复杂、更具挑战性的数学任务时仍显不足。本文介绍了一种名为 DotaMath 的 LLM 系列，通过代码辅助和自我修正的思维分解方法，将复杂数学任务分解为简单逻辑子任务，利用代码解决，并进行自我反思和修正。我们通过注释多样化的工具使用轨迹，在 GSM8K 和 MATH 数据集上生成包含 574K 查询-响应对的 DotaMathQA 数据集，并使用模仿学习训练 LLM。DotaMath 模型在各类基准测试中表现卓越，特别是在 MATH 数据集上达到 64.8%，在 GSM8K 上达到 86.7%，平均竞争力为 80.1%。我们期待 DotaMath 范式为解决复杂数学问题开辟新途径，相关代码已公开发布。
[Arxiv](https://arxiv.org/abs/2407.04078)
==========
# 本文系统探讨并批判性分析了评估大型语言模型的挑战与局限，并提出了相应建议。
发布时间：2024年07月04日
`LLM理论` `人工智能` `软件工程`
> A Systematic Survey and Critical Review on Evaluating Large Language Models: Challenges, Limitations, and Recommendations
# 摘要
> 近期，大型语言模型因其跨领域执行多样化任务的卓越能力而备受瞩目。但在实际应用前，对其进行全面评估是确保性能可靠的关键。尽管评估 LLM 的重要性已成共识，评估过程的复杂性却导致了评估方法的多样性，进而引发了结果和解释的不一致。为此，我们深入探讨了造成这些不一致和评估不可靠的主要难题与局限，并基于此，提出了确保 LLM 评估具备可重复性、可靠性和健壮性的见解与建议。
[Arxiv](https://arxiv.org/abs/2407.04069)
==========
# 在 LLM 时代，语义图在句法简化中的应用值得重新审视。
发布时间：2024年07月04日
`LLM应用` `人工智能`
> Semantic Graphs for Syntactic Simplification: A Revisit from the Age of LLM
# 摘要
> AMR等符号句子意义表示提供了结构化的语义图，本应简化NLP任务，但LLMs的指令遵循能力却提供了更直接的解决方案，使得语义图的实用性受到质疑。同时，将意义表示仅作为LLMs的辅助也面临挑战。我们重新评估了语义图在句法简化任务中的作用，并提出了AMRS$^3$方法，展示了其在简化方法中的竞争优势和独特价值。通过AMRS$^3$，我们发现语义图在LLM提示中对句法简化任务有积极作用。进一步，我们提出AMRCoC提示方法，引导LLMs在AMR图上进行符号推理，有望提升LLM在句法简化等语义任务中的表现。
[Arxiv](https://arxiv.org/abs/2407.04067)
==========
# 探索基础模型排行榜中的操作流程与问题：排行榜操作 (LBOps) 的深入研究
发布时间：2024年07月04日
`LLM应用` `软件工程` `云计算`
> On the Workflows and Smells of Leaderboard Operations (LBOps): An Exploratory Study of Foundation Model Leaderboards
# 摘要
> 大型语言模型等基础模型在软件工程任务中展现出卓越的适应性，推动了FM排行榜在云平台上的重要性。然而，评估和比较指南的缺失影响了排行榜的透明度，限制了有效选择。我们的研究首先探索了排行榜的实际运作和潜在问题，通过文献综述和运营商沟通，揭示了五种工作流程模式和八类问题。通过解决这些问题，我们旨在提升排行榜的透明度和责任感，构建一个更健康、更负责任的FM选择环境。
[Arxiv](https://arxiv.org/abs/2407.04065)
==========
# FunAudioLLM：助力人机自然对话的语音理解与生成基础模型
发布时间：2024年07月04日
`LLM应用` `语音交互` `媒体娱乐`
> FunAudioLLM: Voice Understanding and Generation Foundation Models for Natural Interaction Between Humans and LLMs
# 摘要
> 本报告介绍的 FunAudioLLM 模型家族，旨在提升人类与 LLM 间的自然语音交互。核心包含两个创新模型：SenseVoice 处理多语言语音识别、情感识别及音频事件检测；CosyVoice 则通过调控多语言、音色、说话风格和说话者身份，实现自然语音生成。SenseVoice-Small 为五种语言提供超低延迟 ASR，而 SenseVoice-Large 支持五十多种语言的高精度 ASR。CosyVoice 在多语言语音生成、零-shot 上下文学习、跨语言语音克隆及指令遵循方面表现卓越。相关模型已在 Modelscope 和 Huggingface 开源，训练、推理及微调代码亦在 GitHub 发布。结合 LLM，FunAudioLLM 推动了语音到语音翻译、情感语音聊天、互动播客及有声书叙述等应用的发展，拓展了语音交互技术的边界。演示与代码分别可在 https://fun-audio-llm.github.io 和 https://github.com/FunAudioLLM 获取。
[Arxiv](https://arxiv.org/abs/2407.04051)
==========
# 利用无监督的文本转语音合成进行数据增强，提升带口音语音的识别效果
发布时间：2024年07月04日
`LLM应用` `语音识别` `数据增强`
> Improving Accented Speech Recognition using Data Augmentation based on Unsupervised Text-to-Speech Synthesis
# 摘要
> 本文探讨了无监督文本到语音合成（TTS）作为数据增强手段，以提升带口音语音识别的性能。TTS系统利用少量带口音语音数据及其自动生成的伪标签进行训练，无需人工转录，实现了无监督学习。这种方法使得带口音语音数据能够直接用于数据增强，提升识别效果。通过TTS系统生成的合成带口音语音数据与非带口音语音数据结合，用于训练ASR系统。实验采用自监督学习框架，使用预训练的Wav2vec2.0模型，该模型在大量无监督带口音语音数据上进行了预训练。训练数据包括朗读语音，选自L2-ARCTIC和British Isles语料库，而评估数据则为Edinburgh国际英语口音语料库中的自发对话语音。实验结果表明，通过无监督TTS生成的合成带口音语音数据微调的Wav2vec2.0模型，相比使用Librispeech语料库中非带口音语音数据微调的基线模型，相对词错误率降低了6.1%。
[Arxiv](https://arxiv.org/abs/2407.04047)
==========
# 大型语言模型在系统性任务探索中的应用：引文文本生成研究
发布时间：2024年07月04日
`LLM应用` `学术研究`
> Systematic Task Exploration with LLMs: A Study in Citation Text Generation
# 摘要
> LLM 在处理创造性 NLG 任务时展现出前所未有的灵活性，但也带来了新的挑战。为此，我们设计了一个包含系统输入操作、参考数据和输出测量的三部分研究框架，以探索引用文本生成这一学术 NLP 任务。该任务定义和评估标准尚无共识，且在 LLM 范式中未被触及。我们的研究发现，在引导 LLM 时，系统地调整任务指令和输入配置至关重要，并揭示了不同评估指标间的复杂关系。通过人工生成和评估实验，我们为该任务提供了新的定性见解，以推动未来研究。我们已公开相关代码和数据。
[Arxiv](https://arxiv.org/abs/2407.04046)
==========
# LLMAEL：大型语言模型在实体链接中扮演着优秀的上下文增强角色。
发布时间：2024年07月04日
`LLM应用` `实体链接`
> LLMAEL: Large Language Models are Good Context Augmenters for Entity Linking
# 摘要
> 实体链接模型虽擅长将提及与上下文中的实体对应，但在处理长尾实体时因数据有限而力不从心。大型语言模型虽能更好地解读罕见提及，却因缺乏针对性训练而在生成准确实体ID上表现欠佳。训练LLM进行实体链接成本高昂。为此，我们提出LLM增强型实体链接（LLMAEL），通过LLM数据增强实现即插即用，提升实体链接性能。我们利用LLM生成以提及为中心的描述作为补充输入，同时结合传统EL模型的任务特定处理。实验结果显示，LLMAEL在多数情况下超越了传统EL模型，而经过微调的版本更是在所有6个基准测试中刷新了记录。
[Arxiv](https://arxiv.org/abs/2407.04020)
==========
# 离线模式下，LLM 服务追求能量最优：针对异构系统中 LLM 推理，我们构建了基于工作负载的能量模型。
发布时间：2024年07月04日
`LLM应用` `信息技术`
> Offline Energy-Optimal LLM Serving: Workload-Based Energy Models for LLM Inference on Heterogeneous Systems
# 摘要
> 随着大型语言模型 (LLM) 的广泛应用，自然语言处理和文本生成领域取得了巨大进展。但 LLM 推理过程中的高能耗仍是可持续 AI 发展的瓶颈。为此，我们针对异构 GPU-CPU 系统，构建了基于工作负载的 LLM 推理能耗与运行时间模型。通过深入分析多个领先 LLM 在不同输入输出规模下的能耗与运行表现，我们建立了高度精确 (R^2>0.96) 的模型。基于此，我们设计了一种离线、能耗最优的 LLM 任务调度框架，并通过实证研究，验证了其在能效与准确性方面的显著优势，超越了当前的行业最佳实践。
[Arxiv](https://arxiv.org/abs/2407.04014)
==========
# 探索模型合并技术在低资源语言中的应用潜力
发布时间：2024年07月04日
`LLM应用` `人工智能` `语言技术`
> Unlocking the Potential of Model Merging for Low-Resource Languages
# 摘要
> 将 LLM 适应新语言通常采用持续预训练后进行监督微调的方式。但在低资源语言中，这种先预训练再微调的方法难以平衡语言建模与任务解决能力。为此，我们提出模型合并策略，无需额外训练即可将不同能力的模型融合，为低资源语言打造任务解决型 LLM。基于 Llama-2-7B 的实验显示，模型合并在数据极度匮乏的情况下，仍能有效提升 LLM 的任务解决能力，超越传统预训练加微调的方法。我们还发现，随着训练令牌增加，模型合并性能趋于饱和，因此引入松弛变量优化合并算法，减少关键参数损失，进一步提升性能。我们期待模型合并能以更高的数据效率，助力更多数据稀缺的语言。
[Arxiv](https://arxiv.org/abs/2407.03994)
==========
# 自然语言反事实生成研究综述
发布时间：2024年07月04日
`LLM理论` `人工智能`
> A Survey on Natural Language Counterfactual Generation
# 摘要
> 自然语言反事实生成通过微调文本，使其被重新分类，揭示了模型预测的关键因素。这些反事实不仅有助于识别模型偏见，还能通过丰富训练数据提升模型稳定性。当前，众多研究致力于探索不同NLP任务中的反事实生成技术。面对该领域的迅猛发展，进行一次系统性回顾显得尤为重要。本次调查深入探讨了基于大型语言模型的文本反事实生成方法，并创新性地将其分为四类，详细阐述了评估生成质量的标准。最后，我们分析了当前研究面临的挑战，并指出了未来研究的可能方向。
[Arxiv](https://arxiv.org/abs/2407.03993)
==========
# 复杂指令遵循与多重约束组合的基准测试
发布时间：2024年07月04日
`LLM应用` `人工智能` `软件开发`
> Benchmarking Complex Instruction-Following with Multiple Constraints Composition
# 摘要
> 随着大规模语言模型（LLM）能力的不断提升，它们在处理现实场景中的复杂指令方面发挥着越来越重要的作用。然而，评估LLM遵循复杂指令的能力仍是一个挑战。为此，我们推出了ComplexBench，这是一个专为全面评估LLM处理多约束复杂指令能力而设计的基准。我们精心设计了一个包含4种约束类型、19个约束维度和4种组合类型的分层分类法，并手动构建了一个高质量数据集。通过规则增强的LLM评估器，我们确保了评估的可靠性，并根据不同组合类型的依赖结构得出最终评分。ComplexBench揭示了现有LLM在应对复杂多约束指令时的明显不足。
[Arxiv](https://arxiv.org/abs/2407.03978)
==========
# LLM 角色扮演：模拟人与聊天机器人的互动
发布时间：2024年07月04日
`LLM应用` `人工智能` `聊天机器人`
> LLM Roleplay: Simulating Human-Chatbot Interaction
# 摘要
> 开发聊天机器人需收集大量人机对话，以涵盖用户多样化的社会背景和交流目的。但这类研究的资源成本高昂，常限于特定对话目标和用户群体的狭窄分析。为此，我们提出LLM-Roleplay方法：一种基于角色、目标导向的技术，能自动生成多样化的多轮对话，模拟真实的人机互动。该方法适用于各类聊天机器人，并利用大型语言模型（LLMs）扮演文本描述的角色。为验证其有效性，我们收集了来自不同社会群体的真实人机对话，并通过人类评估对比了真实对话与生成对话。结果显示，我们的方法能高度逼真地模拟人机对话，难以区分真伪。
[Arxiv](https://arxiv.org/abs/2407.03974)
==========
# 借助大型语言模型的背景知识，我们致力于提升强化学习的样本效率。
发布时间：2024年07月04日
`LLM应用` `人工智能` `游戏开发`
> Improving Sample Efficiency of Reinforcement Learning with Background Knowledge from Large Language Models
# 摘要
> 强化学习中的低样本效率一直是个难题。借助多功能大型语言模型，我们尝试通过注入常识知识来加速策略学习。但这种定制化指导往往缺乏通用性。为此，我们设计了一个框架，利用LLMs提取环境背景知识，为多种RL任务提供一次性知识支持。通过预先收集的经验，我们让LLMs描述环境背景，并将这些知识转化为潜力函数，确保策略最优性。我们通过编写代码、注释偏好和分配目标三种方式，引导LLMs生成背景知识。实验证明，这些方法在多个领域如Minigrid和Crafter的下游任务中，大幅提升了样本效率。
[Arxiv](https://arxiv.org/abs/2407.03964)
==========
# LLM-jp 项目旨在跨组织合作，推动完全开放的日本大型语言模型的研究与开发。
发布时间：2024年07月04日
`LLM应用` `学术界` `工业界`
> LLM-jp: A Cross-organizational Project for the Research and Development of Fully Open Japanese LLMs
# 摘要
> 本文详述了 LLM-jp 项目，这是一个跨越学术与工业界的合作，致力于研发开源且性能卓越的日本大型语言模型。目前，已有超过 1,500 名参与者携手推进这一目标。文章不仅回顾了 LLM-jp 的成立背景和活动概览，还提供了其开发模型的技术细节。欲获取最新动态，请访问官方网站：https://llm-jp.nii.ac.jp/en/。
[Arxiv](https://arxiv.org/abs/2407.03963)
==========
# 构建一个框架，旨在注释并建模隐喻使用背后的意图。
发布时间：2024年07月04日
`LLM应用` `语言学`
> A framework for annotating and modelling intentions behind metaphor use
# 摘要
> 隐喻不仅是日常语言的基石，更是我们理解世界的桥梁。在交流中，隐喻的多重角色使其成为语言模型的一大难题。虽然研究已将隐喻与个人意图紧密相连，但适用于NLP的全面意图分类仍付阙如。本文中，我们创新性地提出了一个包含九大类别的隐喻意图分类，并首次发布了一个标注了隐喻使用意图的数据集。通过此数据集，我们检验了大型语言模型在零-shot和few-shot情境下解读隐喻意图的能力，结果显示，这仍是LLMs面临的挑战。
[Arxiv](https://arxiv.org/abs/2407.03952)
==========
# 基于不确定性的优化策略在大规模语言模型搜索树上的应用
发布时间：2024年07月04日
`LLM理论` `人工智能` `机器学习`
> Uncertainty-Guided Optimization on Large Language Model Search Trees
# 摘要
> Beam search 虽为寻找最大似然序列的标准树搜索算法，却因忽视从根至叶的全路径而显得短视。此外，它对先验知识视而不见，例如，未考虑最大化目标的似然性及其在单位区间内的界定特性。我们采用概率视角，为LLM的转换概率设定先验信念，并在每次迭代中更新最有希望路径的后验信念。这些信念助力我们构建一个非短视、类似贝叶斯优化的获取函数，实现比标准波束搜索更高效的数据探索。通过选择合适的先验，并在包含Llama-2-7b的最新大语言模型上进行实验，我们验证了此方法在扩展更少节点的同时，达到了相同甚至更高的似然性，显著提升了效率。
[Arxiv](https://arxiv.org/abs/2407.03951)
==========
# 通过合成数据探索多样且精细的指令遵循能力
发布时间：2024年07月04日
`LLM应用` `人工智能` `数据集`
> Diverse and Fine-Grained Instruction-Following Ability Exploration with Synthetic Data
# 摘要
> 指令遵循对于 LLM 满足多样用户需求至关重要。尽管现有研究在使 LLM 与人类偏好对齐方面有所进展，但评估其在复杂多变的实际指令中的表现仍具挑战。现有评估方法虽关注通用技能，却存在两大短板：缺乏细粒度任务级评估及依赖单一指令表达。为此，本文推出 DINGO 数据集，该集以精细多级类别树为基础，含 130 节点，源自真实用户请求，并融合 GPT-4 与专家智慧生成多样指令。实验表明，DINGO 不仅为 LLM 提供更全面挑战的评估，还细化了任务级指导，助力 LLM 进一步提升。
[Arxiv](https://arxiv.org/abs/2407.03942)
==========
# 精简版 Transformer：基于 Starcoder 的 Java 语言模型，专为桌面设计
发布时间：2024年07月04日
`LLM应用` `软件开发` `人工智能`
> Narrow Transformer: Starcoder-Based Java-LM For Desktop
# 摘要
> 本文推出 NT-Java-1.1B，一款专为 Java 编程量身打造的开源代码语言模型，基于 StarCoderBase-1.1B 构建。NT-Java-1.1B 在 MultiPL-E Java 代码基准测试中表现卓越，超越了基础模型及同类模型。虽然大型通用预训练模型已用于提升 Python 等语言的编程能力，但针对其他编程语言的小型模型研究尚显不足。鉴于大型模型需依赖 GPU 等专用硬件，本文聚焦于开发 NT-Java-1.1B 及其量化版本，这些模型在性能上与 1.1B 规模的开放模型相媲美，非常适合桌面部署，为 NT 系列模型的多样化发展奠定了基础。
[Arxiv](https://arxiv.org/abs/2407.03941)
==========
# 无需预设概念的概念瓶颈模型
发布时间：2024年07月04日
`LLM应用` `人工智能` `计算机视觉`
> Concept Bottleneck Models Without Predefined Concepts
# 摘要
> 近期，概念瓶颈模型（CBMs）等基于可解释概念的模型备受瞩目，它们先预测可理解的概念，再映射至输出类别。为减少对人工标注概念的依赖，现有研究将预训练的黑箱模型事后转化为可解释的CBMs。然而，这些方法预设了一组概念，假定黑箱模型已编码了这些概念。我们通过无监督概念发现，自动提取概念，无需人工标注或预设概念集，消除了这一假设。此外，我们引入了输入依赖的概念选择机制，确保在所有类别中仅使用少量关键概念。实验表明，我们的方法不仅提升了下游性能，还缩小了与黑箱模型的性能差距，同时大幅减少了所需概念数量。最后，我们展示了大型视觉-语言模型如何通过干预最终模型权重来纠正错误。
[Arxiv](https://arxiv.org/abs/2407.03921)
==========
# AutoBench：借助 LLM 实现 HDL 设计的自动化测试台生成与评估
发布时间：2024年07月04日
`LLM应用` `电子工程` `硬件验证`
> AutoBench: Automatic Testbench Generation and Evaluation Using LLMs for HDL Design
# 摘要
> 在数字电路设计领域，测试平台是硬件验证的基石。传统方法在生成测试平台时仍依赖部分手动操作，这不仅效率低下，还耗费设计师大量时间。为此，我们推出了AutoBench，这是首个基于大型语言模型（LLM）的自动化测试平台生成器，仅需待测设计的描述即可自动创建全面测试平台。AutoBench通过LLM实现了混合结构和自检系统，并引入了一个自动评估框架，从多角度评估测试平台质量。实验显示，AutoBench在通过率上比传统方法提升了57%，对75个顺序电路的测试平台通过率更是基线的3.36倍。所有源代码和实验结果已在GitHub开源。
[Arxiv](https://arxiv.org/abs/2407.03891)
==========
# DART：深度对抗技术助力 LLM 安全，实现自动红队测试
发布时间：2024年07月04日
`LLM应用` `网络安全` `人工智能`
> DART: Deep Adversarial Automated Red Teaming for LLM Safety
# 摘要
> 手动红队虽常用于发现大型语言模型（LLM）的漏洞，但成本高昂且难以扩展。自动化红队则通过红色LLM自动生成对抗提示，为安全漏洞检测提供了可扩展的解决方案。然而，构建强大的自动化红色LLM面临挑战，因为目标LLM的安全漏洞随其发展而动态变化。为此，我们设计了深度对抗自动化红队（DART）框架，使红色LLM与目标LLM在迭代中深度动态交互。每次迭代中，红色LLM不仅依据目标LLM的反馈，还通过监控多轮攻击的全球多样性来调整攻击策略，以最大化成功攻击的数量。同时，目标LLM通过基于主动学习的数据选择机制增强安全性，以应对动态变化的安全漏洞。实验显示，DART大幅降低了目标LLM的安全风险。在Anthropic Harmless数据集的人类评估中，DART相比指令调优的目标LLM，违规风险降低了53.4%。我们即将发布DART的数据集和代码。
[Arxiv](https://arxiv.org/abs/2407.03876)
==========
# 探讨人类中心主义偏见与人工认知的潜在可能
发布时间：2024年07月04日
`LLM理论` `人工智能` `认知科学`
> Anthropocentric bias and the possibility of artificial cognition
# 摘要
> 评估LLM的认知能力，需超越拟人化与人类中心主义的偏见。本文揭示了两种常被忽视的偏见：一是忽略辅助因素在LLM能力充足时对其性能的阻碍（I型），二是误将LLM独特的机械策略视为非真正能力（II型）。为减少这些偏见，我们需采用实证驱动、迭代的方法，通过精心设计的行为实验与机制研究相结合，精准映射认知任务至LLM的特定能力和机制。
[Arxiv](https://arxiv.org/abs/2407.03859)
==========
# Q-Adapter：训练 LLM Adapter 成为残差 Q-Function
发布时间：2024年07月04日
`LLM应用` `人工智能` `机器学习`
> Q-Adapter: Training Your LLM Adapter as a Residual Q-Function
# 摘要
> 本文探讨了如何将通过人类反馈强化学习预训练的 LLM 适应到下游偏好数据，提出了一种名为 Q-Adapter 的新方法。该方法通过学习一个新模块，近似于残差 Q-函数，从而在保留 LLM 原有能力的同时实现定制化。实验证明，Q-Adapter 在防止知识遗忘和适应新偏好方面表现出色。
[Arxiv](https://arxiv.org/abs/2407.03856)
==========
# HYBRINFOX 在 CheckThat! 2024 的任务 1 中，旨在通过整合结构化信息来提升语言模型的可核查性估计能力。
发布时间：2024年07月04日
`LLM应用` `人工智能`
> HYBRINFOX at CheckThat! 2024 -- Task 1: Enhancing Language Models with Structured Information for Check-Worthiness Estimation
# 摘要
> HYBRINFOX团队在CheckThat! 2024竞赛中探索了通过三元组嵌入增强语言模型（如RoBERTa）的方法。分析表明，此法能提升模型性能，尤其在英语中表现突出，F1分数达71.1，位列第12。然而，在荷兰语和阿拉伯语中表现不一。未来研究将聚焦于将此流程优化以适配更先进的巨型语言模型。
[Arxiv](https://arxiv.org/abs/2407.03850)
==========
# 大型语言模型在开放域对话评估中的基准测试研究
发布时间：2024年07月04日
`LLM应用` `人工智能`
> On the Benchmarking of LLMs for Open-Domain Dialogue Evaluation
# 摘要
> LLM 在 NLP 任务中表现卓越，尤其在自动开放域对话评估中，它们与人类评估共同构成了评估的核心。但现有基准多依赖过时数据集，仅评估流畅性和相关性，未能全面反映现代聊天机器人的真实能力。本文深入分析了这些基准的不足，并通过 SODA 数据集的实验表明，即使是先进的 LLM 评估器如 GPT-4，也难以准确识别当前聊天机器人对话中的缺陷。
[Arxiv](https://arxiv.org/abs/2407.03841)
==========
# 基于脚手架的大型语言模型在认知建模中的应用：指代表达生成研究案例
发布时间：2024年07月04日
`LLM应用` `人工智能` `语言处理`
> Cognitive Modeling with Scaffolded LLMs: A Case Study of Referential Expression Generation
# 摘要
> 本文探讨了LLMs在语言生成认知模型中的应用，通过神经符号方法实现了Dale & Reiter（1995）的指代表达生成模型。我们设计的迭代过程结合了符号与gpt-3.5-turbo模块，与简化模型及一次性LLM基线在A3DS数据集上进行了对比。结果显示，我们的混合方法不仅在认知上合理，且在复杂情境中表现优异，为语言生成提供了更广阔、更开放的建模空间。
[Arxiv](https://arxiv.org/abs/2407.03805)
==========
# 探究开发者对代码可读性共识的评估
发布时间：2024年07月04日
`LLM应用` `软件开发` `人工智能`
> Assessing Consensus of Developers' Views on Code Readability
# 摘要
> 随着大型语言模型（LLM）的兴起，如 Copilot 和 JetBrains AI 助手等工具已显著提升开发者效率。然而，开发者如今更多时间用于代码审查而非编写，凸显了代码可读性的关键作用。我们的先前研究揭示现有模型未能准确反映开发者对可读性的理解，且开发者间共识不足，这促使我们深入探索。  为此，我们调研了10位经验相当的 Java 开发者，旨在探求他们对代码可读性的共识。结果显示，开发者们在评估可读性时展现出高度一致，并明确了影响可读性的关键代码特征。本研究不仅阐明了 LLM 环境下的代码可读性问题，更为模型如何契合开发者认知提供了洞见，助力 AI 时代软件开发的优化。
[Arxiv](https://arxiv.org/abs/2407.03790)
==========
# 视频-语言表示学习的元优化角度边缘对比框架
发布时间：2024年07月04日
`LLM应用` `视频处理` `人工智能`
> Meta-optimized Angular Margin Contrastive Framework for Video-Language Representation Learning
# 摘要
> 数据质量是视频-语言表示学习有效性的关键。然而，以往的视频-文本对往往无法完美匹配，导致跨模态语义反映不准确。同时，概念分布的不均也影响了特定主题的下游表现。为此，我们引入了带有减法角边距的对比目标，以优化跨模态表示的相似性。针对概念分布的不均，我们设计了由MLP参数化的权重函数，动态调整模型关注点。在无偏元数据和大型视觉-语言模型生成数据的辅助下，我们显著提升了视频-语言表示的质量，并在视频问答和文本-视频检索等任务中取得了卓越成绩。
[Arxiv](https://arxiv.org/abs/2407.03788)
==========
# 大型语言模型助力 AI 从数据解读到常识推理，为可解释 AI 开辟新径。
发布时间：2024年07月04日
`LLM应用` `人工智能`
> From Data to Commonsense Reasoning: The Use of Large Language Models for Explainable AI
# 摘要
> 常识推理对计算机而言颇具挑战，但对AI至关重要。它通过赋予AI模型提供直观、类人解释的能力，增强了模型的可解释性。这在问答（QA）等众多领域尤为关键，QA是自然语言处理（NLP）的核心任务。随着时间推移，多种方法应运而生，如基于形式逻辑或语言分析的知识库方法，以解决常识推理难题。本文探讨了大型语言模型（LLMs）在不同QA任务中的表现，特别关注其推理与可解释性。我们分析了GPT-3.5、Gemma和Llama 3三个模型，并通过问卷评估了它们的表现。结果显示，LLMs在利用常识推理方面超越了人类，GPT-3.5在多个QA基准上的准确率介于56%至93%，而Llama 3在十一个数据集上的平均准确率达90%，平均超越人类21%。此外，GPT-3.5在可解释性方面表现出色，66%的受访者认为其解释“良好”或“优秀”。这些发现不仅深化了我们对当前LLMs的理解，也为未来推理与可解释性的研究奠定了基础。
[Arxiv](https://arxiv.org/abs/2407.03778)
==========
# 边缘部署蜂窝网络测试中，卷积神经网络与大型语言模型在软件日志分类上的较量
发布时间：2024年07月04日
`LLM应用` `人工智能`
> Convolutional vs Large Language Models for Software Log Classification in Edge-Deployable Cellular Network Testing
# 摘要
> 电信行业中，复杂的网络模拟器如VIAVI TM500生成的软件日志极为繁琐，包含数万行与自然语言相去甚远的文本。唯有专业工程师能解读这些日志，解决测试中的缺陷。AI虽提供了自动化缺陷分类的希望，能大幅节省公司收入，但现有大型语言模型（LLMs）在此领域仍显不足，如上下文窗口受限、对非自然语言文本的适用性有限及高推理成本。为此，我们设计了一种紧凑的卷积神经网络（CNN）架构，其上下文窗口可达20万字符，分类电信协议栈日志准确率超96%（F1>0.9）。该模型能自动识别并分类测试缺陷至相关部门，取代了以往需专家知识的手动流程。我们测试了多种LLMs，如LLaMA2-7B、Mixtral 8x7B等，并验证了它们在特定应用中的局限。尽管轻巧，我们的CNN在电信日志分类上远胜LLM方法，同时降低了成本。此AI模型无需专用硬件，即可在边缘设备上部署，广泛适用于各行业软件日志。
[Arxiv](https://arxiv.org/abs/2407.03759)
==========
# 在数据稀缺的情境下，论证挖掘借助跨语言迁移和少量样本技术，探索新的可能性。
发布时间：2024年07月04日
`LLM理论` `机器学习`
> Argument Mining in Data Scarce Settings: Cross-lingual Transfer and Few-shot Techniques
# 摘要
> 近期研究探索了多种策略以解决全球多数语言缺乏手动标注数据的问题，其中最有效的方法包括多语言预训练模型的跨语言迁移、数据翻译与标签投影以及基于提示的少样本学习。以往研究表明，模型迁移胜过数据迁移，且提示式少样本学习优于模型微调。然而，本文通过论证挖掘任务的实证分析发现，这些先前的结论并不适用。我们发现，在论证挖掘中，数据迁移效果优于模型迁移，且微调技术超越了少样本学习。数据集的领域特性对数据迁移至关重要，而任务的复杂性与采样策略则对少样本学习影响显著。
[Arxiv](https://arxiv.org/abs/2407.03748)
==========
# Text2TimeSeries：借助大型语言模型的事件驱动洞察，实时更新时间序列预测，助力财务预测更精准。
发布时间：2024年07月04日
`LLM应用` `时间序列分析`
> Text2TimeSeries: Enhancing Financial Forecasting through Time Series Prediction Updates with Event-Driven Insights from Large Language Models
# 摘要
> 时间序列模型通常基于数值数据预测未来，但现实中的时间序列数据常受非数值因素影响。例如，股票价格受全球随机事件影响，每个事件对价格产生独特影响。传统方法要么侧重于价格序列的时间序列分析，要么进行情感分析，判断新闻事件对股价的正面或负面影响。为更全面地预测时间序列，我们提出一种结合文本信息的协作建模框架，利用大型语言模型对未来变化的洞察，优化实数时间序列预测。我们在金融市场数据上验证了这一方法的有效性。
[Arxiv](https://arxiv.org/abs/2407.03689)
==========
# STOC-TOT：一种结合约束解码的随机思维树方法，专为多跳问答中的复杂推理设计。
发布时间：2024年07月04日
`LLM应用` `问答系统` `人工智能`
> STOC-TOT: Stochastic Tree-of-Thought with Constrained Decoding for Complex Reasoning in Multi-Hop Question Answering
# 摘要
> 多跳问答（MHQA）任务要求模型从多个段落中检索并整合信息，以解答复杂问题。近期研究结合大型语言模型的能力，通过集成证据检索与推理提示（如思维链推理）来提升MHQA的表现。然而，问题类型（如桥梁问题与比较问题）及推理方式（顺序或并行）的多样性，促使我们探索更精细的提示策略，以在零-shot环境下优化MHQA性能。本文提出的STOC-TOT方法，通过随机思维树推理与约束解码，有效应对了这一挑战。我们构建了树状推理结构，引导模型将复杂问题分解为子问题，形成多条推理路径，并在每一步推理中评估各路径的概率。实验结果表明，STOC-TOT在两个MHQA数据集与五个大型语言模型上的表现，均显著超越了现有推理提示方法。
[Arxiv](https://arxiv.org/abs/2407.03687)
==========
# 借助概率标记化技术，提升大型语言模型中的自我一致性
发布时间：2024年07月04日
`LLM理论` `人工智能`
> Improving Self Consistency in LLMs through Probabilistic Tokenization
# 摘要
> 先前研究表明，通过在训练阶段对同一输入采用多种分词方式的概率性方法，可以显著提升语言模型的性能。然而，现代大型语言模型 (LLM) 尚未充分利用这一技术。本研究提出一种新方法，旨在通过利用 LLM 分词器的多分词能力，增强其在推理任务中的自我一致性。实验显示，概率性分词不仅增加了语言多样性，还促进了逻辑上多样化的推理路径。我们通过在多个 LLM 系列和推理基准上的实验，深入探讨了这一方法，并揭示了其对自我一致性改进的机制。
[Arxiv](https://arxiv.org/abs/2407.03678)
==========
# GPT-4 与人类翻译者的较量：全面评估翻译质量在多语言、多领域及不同专业水平的表现
发布时间：2024年07月04日
`LLM应用` `翻译行业` `人工智能`
> GPT-4 vs. Human Translators: A Comprehensive Evaluation of Translation Quality Across Languages, Domains, and Expertise Levels
# 摘要
> 本研究全面对比了GPT-4与不同水平的人类翻译者在多语言多领域的翻译质量。研究发现，GPT-4在错误总数上与初级翻译者相当，但不及中级和高级翻译者。GPT-4在资源丰富的语言方向表现较好，而在资源匮乏的方向则逐渐减弱。此外，GPT-4倾向于字面翻译，而人类翻译者有时会过度解读背景信息。这是首次系统比较LLM与人类翻译的差异，为理解当前基于LLM的翻译技术及其局限性提供了重要视角。
[Arxiv](https://arxiv.org/abs/2407.03658)
==========
# WildDESED：一款由 LLM 赋能的数据集，专为家庭环境中的声音事件检测系统设计。
发布时间：2024年07月04日
`LLM应用` `家庭环境` `声音事件检测`
> WildDESED: An LLM-Powered Dataset for Wild Domestic Environment Sound Event Detection System
# 摘要
> 本研究通过引入由大型语言模型支持的新数据集 WildDESED，旨在推动声音事件检测研究。作为 DESED 的扩展，WildDESED 反映了家庭环境中的声学多样性和复杂噪音。我们利用 LLM 生成了八种家庭场景，并精心混合了来自 AudioSet 的噪音，确保与目标声音无重叠。采用卷积神经循环网络分析 WildDESED，揭示其挑战性。通过逐步增加噪音复杂性的课程学习，我们提升了模型在不同噪音环境下的泛化能力。实验结果表明，在嘈杂环境中性能提升，证实了 WildDESED 在推动噪音鲁棒 SED 技术发展中的有效性。
[Arxiv](https://arxiv.org/abs/2407.03656)
==========
# 交互式多模态查询应答系统，搭载检索增强型大型语言模型
发布时间：2024年07月04日
`RAG` `多媒体` `搜索引擎`
> An Interactive Multi-modal Query Answering System with Retrieval-Augmented Large Language Models
# 摘要
> 检索增强型大型语言模型 (LLM) 彻底改变了传统查询-回答系统，提供前所未有的用户体验。然而，现有检索技术在处理多模态查询时面临挑战。本文介绍的交互式多模态查询回答 (MQA) 系统，借助新开发的多模态检索框架和导航图索引，与顶尖 LLM 无缝集成。系统包含数据预处理、向量表示、索引构建、查询执行和答案生成五大核心模块，由专用协调器确保数据流畅。MQA 利用对比学习评估模态重要性，精准衡量多模态信息相似度。通过先进的导航图索引和计算修剪技术，实现高效检索。系统还具备可插拔处理框架，轻松集成嵌入模型、图索引和 LLM，为用户提供多样化的知识库洞察选择。MQA 初步介绍视频见 https://youtu.be/xvUuo2ZIqWk。
[Arxiv](https://arxiv.org/abs/2407.04217)
==========
# DSLR 技术通过句子级重排序与重建，优化文档，从而提升检索增强生成的质量。
发布时间：2024年07月04日
`RAG` `问答系统`
> DSLR: Document Refinement with Sentence-Level Re-ranking and Reconstruction to Enhance Retrieval-Augmented Generation
# 摘要
> 大型语言模型 (LLM) 在自然语言处理 (NLP) 任务中的表现因最新进展而显著提升。然而，受限于参数记忆，LLM 在生成非事实性响应时仍显不足。检索增强生成 (RAG) 系统通过整合外部知识与检索模块来应对这一难题。尽管成效显著，当前 RAG 系统仍受困于检索失败及 LLM 筛选无关信息能力的局限。为此，我们提出 **DSLR**（文档细化与句子级重排重建），一个无监督框架，它将检索文档拆解为句子，剔除无关内容，再重组为连贯段落。实验证明，**DSLR** 在开放域 QA 数据集上大幅超越传统固定段落方法，提升 RAG 性能。此外，**DSLR** 无需额外训练，便能在特定现实场景中优化性能，为 RAG 系统中的文档精炼提供了一个既高效又有效的解决方案。
[Arxiv](https://arxiv.org/abs/2407.03627)
==========
# Slice-100K：一款专为挤出式3D打印设计的多模态数据集
发布时间：2024年07月04日
`LLM应用` `制造业` `3D打印`
> Slice-100K: A Multimodal Dataset for Extrusion-based 3D Printing
# 摘要
> G-code，即几何代码 RS-274，是计算机数控（CNC）和 3D 打印领域最常用的编程语言。它主要用于指导 3D 打印机的运动，包括喷嘴、平台和材料挤出。目前，尚未有一个包含大量精选 CAD 模型及其对应 G-code 文件的增材制造资源库。为此，我们推出了 SLICE-100K，这是一个创新数据集，包含超过 100,000 个 G-code 文件，以及相应的镶嵌 CAD 模型、LVIS 类别、几何属性和渲染图。该数据集基于 Objaverse-XL 和 Thingi10K 的三角网格构建。我们通过微调 GPT-2 模型，展示了该数据集在将旧版 G-code 格式（如 Sailfish）转换为现代格式（如 Marlin）方面的应用。SLICE-100K 的推出，标志着开发数字制造多模态基础模型的第一步。
[Arxiv](https://arxiv.org/abs/2407.04180)
==========
# 半监督学习助力代码转换ASR，结合大型语言模型过滤器
发布时间：2024年07月04日
`LLM应用` `语音识别` `半监督学习`
> Semi-supervised Learning for Code-Switching ASR with Large Language Model Filter
# 摘要
> 代码切换现象，即不同语言的词汇在同一句话中交替出现，由于相关数据稀缺，构建高效的自动语音识别系统颇具挑战。本文提出，在半监督学习框架下，利用丰富的无监督单语语音数据来强化CS-ASR系统，尤其是在CS数据有限的情况下。我们构建了一个通用范式，将噪声学生训练应用于CS-ASR任务，并引入了LLM-Filter，通过设计精妙的提示模板，激活大型语言模型在单语数据筛选和伪标签优化中的校正功能。实验结果显示，我们的方法在CS任务上不仅大幅超越了传统监督与半监督学习方法，甚至在CS英语部分的表现也优于全监督的基准上限。此外，我们还探讨了口音对AESRC数据集的影响，发现当单语数据包含特定语言特征时，我们的方法能带来额外优势。
[Arxiv](https://arxiv.org/abs/2407.04219)
==========
# HAF-RM：奖励模型训练的混合对齐新框架
发布时间：2024年07月04日
`LLM理论` `人工智能` `语言模型`
> HAF-RM: A Hybrid Alignment Framework for Reward Model Training
# 摘要
> 奖励模型在LLM的对齐与评估中日益关键。传统上，研究者通过数据优化来提升奖励模型，直接针对预测奖励进行训练。本文中，我们创新性地提出了HaF-RM框架，不仅优化奖励分数，还额外约束了令牌级策略概率，实现了令牌级偏好模型的监督与序列级映射层的优化。理论与实验双重验证了该框架在提升奖励模型质量上的卓越效果。通过分离奖励建模步骤并引入混合监督，HaF-RM为增强奖励模型的性能与对齐提供了一条高效且有原则的路径，对语言模型的负责任发展至关重要。代码已公开于https://haf-rm.github.io。
[Arxiv](https://arxiv.org/abs/2407.04185)
==========
# 窥探AI视角：LLMs在应用维基百科中立性规范时的得与失
发布时间：2024年07月04日
`LLM应用` `人工智能`
> Seeing Like an AI: How LLMs Apply (and Misapply) Wikipedia Neutrality Norms
# 摘要
> 大型语言模型（LLM）虽在广泛语料库上训练，但应用于特定规范社区时，仅提供社区规则是否足够？我们测试了LLM识别与修正维基百科编辑偏差的能力，依据中立观点（NPOV）政策。LLM在偏差识别上准确率仅64%，显示出对中立性的不同理解。在生成内容时，LLM能移除79%的编辑删除词，但常做出超出简单中立化的额外改动，导致编辑质量高召回但低精度。有趣的是，AI重写被认为比编辑版本更中立和流畅。定性分析显示，LLM有时比编辑更全面应用NPOV，但也常进行无关的语法调整。LLM的应用可能符合公众期待，却与专家意见相左。尽管在内容生成上表现可能有效，LLM的使用可能削弱编辑自主权并增加审核负担。即便规则明确，让LLM如同社区成员般应用它们仍具挑战。
[Arxiv](https://arxiv.org/abs/2407.04183)
==========
# 个性化调配大型语言模型
发布时间：2024年07月04日
`LLM应用` `个性化服务` `人工智能`
> Orchestrating LLMs with Different Personalizations
# 摘要
> 本文介绍了一种创新方法，旨在将大型语言模型（LLM）与个人偏好精准对接，这种方法被称为个性化人类反馈强化学习（RLPHF）。我们的目标是在不重新训练的前提下，打造一个能够完美契合用户在帮助性、简洁性或幽默感等多维度偏好的LLM。我们从专门针对单一偏好维度训练的专家LLM出发，提出了一种在标记级别上融合它们输出的黑箱技术。同时，我们训练了一个轻巧的偏好控制模型（PCM），它能根据当前上下文动态调整偏好描述，转化为下一个标记的预测权重。通过在标记级别上整合专家模型的输出，我们的方法能够动态生成符合用户偏好的文本。实证测试显示，我们的方法在偏好合并技术上表现卓越，为个性化LLM微调提供了一种高效且可扩展的解决方案。
[Arxiv](https://arxiv.org/abs/2407.04181)
==========
# 防御通过标记替换实施的句法文本后门攻击
发布时间：2024年07月04日
`LLM应用` `网络安全` `人工智能`
> Defense Against Syntactic Textual Backdoor Attacks with Token Substitution
# 摘要
> 文本后门攻击对 LLM 构成严重威胁，通过在训练阶段植入特定触发器，诱导模型对含相同触发器的输入做出错误预测。传统防御方法多聚焦于特殊标记触发器，对语法触发器防范不足。为此，本文提出一种新型在线防御算法，既能抵御语法触发器，也能应对特殊标记触发器。该算法通过替换句子中的语义词，同时保留语法结构或特殊标记，对比替换前后预测结果，以识别潜在触发器。实验证明，该算法对这两类触发器均有效，为模型安全提供全方位保护。
[Arxiv](https://arxiv.org/abs/2407.04179)
==========
# 探究表格型LLM在模型多样性下的预测一致性
发布时间：2024年07月04日
`LLM理论`
> Quantifying Prediction Consistency Under Model Multiplicity in Tabular LLMs
# 摘要
> 在分类任务中，对大型语言模型进行有限表格数据的微调可能导致“微调多重性”，即不同训练过程下的模型对相同输入做出不同预测。这引发了关于表格 LLM 在高风险决策中的稳健性和可靠性的担忧。为此，我们正式化了这一挑战，并提出了一种新指标，通过分析模型在嵌入空间中的局部行为，无需重新训练模型即可量化预测的稳健性。我们利用伯恩斯坦不等式，证明了高稳健性预测将以高概率保持一致，并通过实证评估支持了这一理论。我们的工作强调了解决微调不稳定性的重要性，以确保 LLM 在高风险和安全关键应用中的可信部署。
[Arxiv](https://arxiv.org/abs/2407.04173)
==========
# VoxAct-B：一种基于体素的双臂操作动作与稳定策略
发布时间：2024年07月04日
`Agent` `机器人` `自动化`
> VoxAct-B: Voxel-Based Acting and Stabilizing Policy for Bimanual Manipulation
# 摘要
> 双手操作在机器人领域至关重要。与单臂操作相比，双手操作因其高维动作空间而更具挑战性。以往方法依赖大量数据和基础动作，但存在样本效率低和泛化能力有限的问题。为此，我们提出VoxAct-B，一种结合语言条件和体素技术的方法，利用视觉语言模型优先处理关键场景区域并构建体素网格。该网格用于指导双手操作策略，学习有效动作和稳定技巧，从而提高策略学习效率并增强任务泛化能力。模拟实验表明，VoxAct-B在精细双手操作任务中表现优异。此外，我们通过两台UR5机器人，在实际环境中成功演示了抽屉和罐子的开启任务。相关代码、数据及演示视频将在https://voxact-b.github.io发布。
[Arxiv](https://arxiv.org/abs/2407.04152)
==========
# 强化多轮对话语言模型，抵御分布式后门触发威胁
发布时间：2024年07月04日
`LLM应用` `网络安全` `人工智能安全`
> Securing Multi-turn Conversational Language Models Against Distributed Backdoor Triggers
# 摘要
> 尽管多轮对话大型语言模型 (LLM) 的应用广泛，但其安全性研究却相对滞后。LLM 特别容易受到数据中毒后门攻击，这种攻击通过操纵训练数据，使模型对特定触发器产生恶意响应。在多轮对话场景中，后门触发器可能跨越多个话语，增加了攻击的隐蔽性和危害性。本文介绍了一种新颖的分布式后门触发器攻击，这种攻击可以与其他单轮攻击策略灵活结合，对现有防御机制构成挑战。实验表明，这种攻击对针对单轮交互设计的防御策略具有鲁棒性，因此我们提出了一种新的多轮对话防御策略，并探索了一种基于对比解码的防御方法，以低计算代价有效缓解后门攻击。
[Arxiv](https://arxiv.org/abs/2407.04151)
==========
# 探索可控学习：揭秘信息检索领域的技术与应用
发布时间：2024年07月04日
`LLM理论` `信息检索` `机器学习`
> A Survey of Controllable Learning: Methods and Applications in Information Retrieval
# 摘要
> 可控学习（CL）是构建可信机器学习的核心，它确保学习系统能精准达成预定目标，并随目标变化灵活调整，无需重新训练。我们为CL下了定义，并探讨了其在信息检索（IR）领域的应用，这里的信息需求多变且复杂。我们根据控制主体（用户或平台）、可控要素（如检索目标、用户行为、环境适应性）、控制方式（基于规则、帕累托优化、超网络等）及实施环节（预处理、处理中、后处理）对CL进行了分类。同时，我们指出了CL在训练、评估、任务设计及在线部署中遇到的挑战，并展望了其在理论深化、计算优化、大型语言模型赋能、应用拓展及评估体系构建等方面的潜力。
[Arxiv](https://arxiv.org/abs/2407.06083)
==========
# CaseGPT：一种结合语言模型与检索增强技术的案例推理框架
发布时间：2024年07月04日
`RAG`
> CaseGPT: a case reasoning framework based on language models and retrieval-augmented generation
# 摘要
> 本文介绍的 CaseGPT 创新地将 LLM 与 RAG 技术结合，旨在提升医疗和法律领域的案例推理效率。通过模糊搜索技术，CaseGPT 克服了传统数据库查询的局限，大幅提升了数据检索的精准度和可用性。它不仅能高效检索相关案例，还能基于案例数据的模式，提供深入的建议和策略，这对于医疗诊断和法律研究等任务尤为关键。实验数据显示，CaseGPT 在精确度、召回率和效率上均超越了传统系统。本文详细探讨了其技术原理、应用效果及未来发展潜力。
[Arxiv](https://arxiv.org/abs/2407.07913)
==========
# 当语言模型意见分歧时，如何是好？本文探讨了应用于文本与视觉问答任务的黑盒模型集成方法。
发布时间：2024年07月04日
`LLM应用` `人工智能` `计算机视觉`
> What to do if language models disagree? Black-box model ensembling for textual and visual question answering
# 摘要
> 针对文本和视觉问答任务，我们开发了如ChatGPT和BLIP等多样化的LLMs和VQA模型。然而，这些模型在特定任务数据集上的应用面临挑战，微调要么因API访问而困难重重，要么因参数众多而成本高昂。为此，我们创新性地提出了InfoSel方法，这是一种高效且轻量的集成技术，它能从现有黑箱模型中智能挑选出最佳预测模型。不同于传统依赖预测概率或置信度的集成方法，InfoSel在黑箱模型中也能游刃有余。实验显示，在四个数据集上，我们的方法相较于单一LLMs，F1分数提升了高达5.27%，且仅用1K训练样本和110M参数就实现了这一突破。
[Arxiv](https://arxiv.org/abs/2407.12841)
==========
# NutriBench 数据集：专为评估 LLM 从餐食描述中估算碳水化合物含量而设计
发布时间：2024年07月04日
`LLM应用` `食品行业` `营养学`
> NutriBench: A Dataset for Evaluating Large Language Models in Carbohydrate Estimation from Meal Descriptions
# 摘要
> 我们推出的NutriBench，作为首个基于自然语言餐食描述的公开养分基准，包含5,000条人工验证的餐食描述及宏量营养标签。数据分为15个复杂度不同的子集。我们评估了包括GPT-3.5在内的七种LLMs，发现它们在复杂查询中能提供更精准快速的预测。通过详细分析，我们揭示了LLMs在实际养分估算中的潜力与挑战。NutriBench现已公开，网址为：https://mehak126.github.io/nutribench.html。
[Arxiv](https://arxiv.org/abs/2407.12843)
==========
# Cactus：借助认知行为理论，迈向心理咨询对话的新领域
发布时间：2024年07月03日
`LLM应用` `心理健康` `人工智能`
> Cactus: Towards Psychological Counseling Conversations using Cognitive Behavioral Theory
# 摘要
> 随着心理健康问题的关注度上升，心理咨询需求激增，推动了利用大型语言模型（LLM）作为咨询师的应用。然而，保护客户隐私的同时，开源LLM的训练面临数据集缺失的难题。为此，我们推出了Cactus数据集，模拟真实对话，结合认知行为疗法（CBT）的结构化方法。通过设定多样化的客户角色和系统化的CBT应用，我们构建了一个真实且多元的数据集。为确保数据质量，我们依据专业心理评估标准进行验证。实验显示，基于Cactus训练的Camel模型在咨询技能上表现卓越，展现了其作为咨询工具的潜力。我们公开了所有相关资源，以促进心理咨询技术的发展。
[Arxiv](https://arxiv.org/abs/2407.03103)
==========
# 利用多模态大型语言模型实现视觉驱动的移动GUI自动化测试
发布时间：2024年07月03日
`LLM应用` `软件测试` `移动应用`
> Vision-driven Automated Mobile GUI Testing via Multimodal Large Language Model
# 摘要
> 随着软件渲染技术的提升，移动应用的GUI页面如今承载了丰富的视觉信息，这些视觉语义对应用逻辑至关重要，同时也为软件测试带来了新挑战。尽管自动化GUI测试有所进步，但由于缺乏有效的测试预言，其效果仍局限于识别明显的崩溃错误。然而，许多非崩溃错误，如意外行为或界面错位，往往难以被现有技术捕捉。这些错误虽可能通过视觉线索提供潜在的测试预言，但检测它们需要深入理解GUI页面间的操作逻辑，这对传统技术构成挑战。鉴于多模态大型语言模型（MLLM）在视觉与语言理解上的卓越能力，本文提出了一种基于视觉的自动化GUI测试方法——VisionDroid，旨在利用MLLM检测非崩溃功能错误。该方法首先提取GUI文本信息并结合截图形成视觉提示，使MLLM能理解GUI上下文。随后，功能感知探索器引导MLLM进行深入且面向功能的GUI页面探索，而逻辑感知错误检测器则将探索历史按逻辑分段，并引导MLLM进行错误检测。我们在三个数据集上验证了VisionDroid，并对比了10个基线方法，证实了其优异性能。消融研究进一步凸显了各模块的贡献。此外，VisionDroid在Google Play上发现了29个新错误，其中19个已获确认并得到修复。
[Arxiv](https://arxiv.org/abs/2407.03037)
==========
# VIVA：一个结合视觉与人类价值观的决策制定基准
发布时间：2024年07月03日
`LLM应用` `人工智能` `计算机视觉`
> VIVA: A Benchmark for Vision-Grounded Decision-Making with Human Values
# 摘要
> 本文推出 VIVA 基准，专注于考察视觉-语言模型在基于人类价值观进行决策的能力。与传统 VLM 不同，VIVA 通过 1,062 张现实情境图片及相应的手动标注决策，挑战模型在视觉情境下选择合适行动并阐释其背后的人类价值观和理由。实验表明，VLM 在运用人类价值观进行复杂决策上存在局限，而深入分析则揭示了考虑行动后果和预测价值观的潜在优势。
[Arxiv](https://arxiv.org/abs/2407.03000)
==========
# MedPix 2.0：一款集大成的多模态生物医学数据集，专为尖端AI应用打造
发布时间：2024年07月03日
`LLM应用` `人工智能`
> MedPix 2.0: A Comprehensive Multimodal Biomedical Dataset for Advanced AI Applications
# 摘要
> 随着医疗领域对AI应用的兴趣日益增长，高质量数据集的缺乏成为一大难题，主要原因是隐私问题。同时，多模态大型语言模型（MLLM）的兴起，使得我们需要结合临床报告与CT或MR扫描的多模态医疗数据集。本文详细介绍了构建MedPix 2.0数据集的全过程。我们从广泛用于继续医学教育的MedPix\textsuperscript{\textregistered}数据集出发，通过半自动化流程提取视觉与文本信息，并手动剔除噪声样本，最终构建了一个MongoDB数据库。此外，我们还设计了一个图形用户界面（GUI），方便用户高效访问数据库，并轻松获取用于训练或微调MLLM的原始数据。为了展示其应用潜力，我们基于MedPix 2.0训练了一个CLIP模型，用于扫描分类任务。
[Arxiv](https://arxiv.org/abs/2407.02994)
==========
# MindBench：全面评估思维导图结构识别与分析的基准
发布时间：2024年07月03日
`LLM应用` `文档分析` `人工智能`
> MindBench: A Comprehensive Benchmark for Mind Map Structure Recognition and Analysis
# 摘要
> 多模态大型语言模型在文档分析领域取得了显著进展，但现有基准往往忽视了结构化文档中元素间的复杂交互。为此，我们推出了新基准 MindBench，它不仅包含精心构建的双语图像、详细注释和评估体系，还特别设计了五类结构化理解和解析任务，涵盖文本识别、空间意识等关键领域。实验表明，当前模型在处理结构化文档信息方面仍有巨大潜力。我们期待 MindBench 能推动结构化文档分析技术的研究与应用。MindBench 现已上线，访问地址为：https://miasanlei.github.io/MindBench.github.io/。
[Arxiv](https://arxiv.org/abs/2407.02842)
==========
# 通过结合基于抽象语法树的排序和模式剪枝技术，提升检索增强型文本到SQL的转换效率。
发布时间：2024年07月03日
`LLM应用` `商业智能` `数据库`
> Improving Retrieval-augmented Text-to-SQL with AST-based Ranking and Schema Pruning
# 摘要
> 我们聚焦于大型语言模型视角下的 Text-to-SQL 语义解析。鉴于商业数据库模式庞大与商业智能解决方案的可部署性挑战，我们提出动态检索数据库信息，并利用抽象语法树精选少量样本进行上下文学习。同时，我们探索并行语义解析器在生成预期 SQL 查询近似版本中的应用，以支持检索。我们甚至将此方法推向极致，调整一个仅含 5 亿参数的模型，使其成为高效近似器，并赋予其并行处理模式的能力。在单语与跨语语义解析基准测试中，我们的方法超越了现有最佳基线。详尽实验不仅凸显了检索增强生成设置中各模块的贡献，更为未来研究指明了新方向。
[Arxiv](https://arxiv.org/abs/2407.03227)
==========
# 量化对多语言LLM的影响如何？
发布时间：2024年07月03日
`LLM应用` `人工智能`
> How Does Quantization Affect Multilingual LLMs?
# 摘要
> 量化技术常用于提升大型语言模型的推理速度和部署效率。尽管已有研究探讨了量化对英语任务的影响，但跨语言的量化效应尚未被深入研究。我们针对多语言LLM进行了详尽分析，特别关注其在不同语言和规模下的表现。通过自动基准测试、LLM-as-a-Judge方法及人类评估，我们发现：（1）量化在人类评估中显示出明显负面影响，自动指标低估了其损害程度；（2）不同语言对量化的敏感度各异，非拉丁文字语言受影响尤为严重；（3）数学推理等复杂任务受量化影响最大。鉴于低计算模型在全球NLP技术推广中的重要性，我们的研究强调了多语言性能作为高效模型评估关键标准的重要性。
[Arxiv](https://arxiv.org/abs/2407.03211)
==========
# TheoremLlama：让通用 LLM 成为 Lean4 领域的专家
发布时间：2024年07月03日
`LLM应用` `计算机科学`
> TheoremLlama: Transforming General-Purpose LLMs into Lean4 Experts
# 摘要
> 利用计算机可验证的形式语言（如Lean）证明数学定理，极大地推动了数学推理的发展。其中一种方法是通过大型语言模型（LLM）基于自然语言（NL）证明生成完整证明，这种方法在代码生成领域已显示出潜力。然而，由于自然语言与形式语言（FL）定理证明数据的对齐不足，现代LLM的性能普遍受限。这种不足导致了训练LLM的方法和充分利用其在形式证明中能力的技术匮乏。为此，本文提出了**TheoremLlama**框架，旨在将通用LLM训练成Lean4专家。该框架涵盖了NL-FL对齐数据集生成、LLM形式定理证明器训练及Lean4证明写作技术。我们通过数据集生成方法，提供了*Open Bootstrapped Theorems*（OBT），这是一个NL-FL对齐且自举的数据集。框架的核心创新在于NL-FL自举方法，将NL证明融入Lean4代码，利用LLM的NL推理能力进行形式推理。**TheoremLlama**在MiniF2F-Valid和Test数据集上的累积准确率分别达到36.48%和33.61%，超越了GPT-4的22.95%和25.41%基线。此外，我们还开源了模型检查点和生成的数据集，并将很快公开所有代码。
[Arxiv](https://arxiv.org/abs/2407.03203)
==========
# 采用多样化的思维链进行微调，能显著提升语言模型通过自我纠错机制进行推理的能力。
发布时间：2024年07月03日
`LLM应用` `人工智能`
> Fine-Tuning with Divergent Chains of Thought Boosts Reasoning Through Self-Correction in Language Models
# 摘要
> 我们发现，要求大型语言模型生成中间推理步骤能显著提升性能。为此，我们创新性地提出了Divergent CoT（DCoT）方法，即在生成答案前比较多个推理链。实验证明，对DCoT数据集进行指令调整不仅能提升大型模型性能，还能使更小、更易获取的LLM受益。跨越多样任务的严格实验显示，DCoT微调始终优于传统方法，且性能提升源自模型在单步推理中展现的多链发散能力，这标志着语言模型自我修正能力的增强。相关代码和数据已公开，详见https://github.com/UKPLab/arxiv2024-divergent-cot。
[Arxiv](https://arxiv.org/abs/2407.03181)
==========
# 探索仅解码器大型语言模型在语音转文本翻译中的应用
发布时间：2024年07月03日
`LLM应用` `语音识别` `机器翻译`
> Investigating Decoder-only Large Language Models for Speech-to-text Translation
# 摘要
> 大型语言模型 (LLM) 因其卓越的推理能力和跨领域的流畅性，为提升语音相关任务展现了光明前景。本文聚焦于将仅解码器的 LLM 应用于语音到文本翻译 (S2TT) 任务。我们设计了一种仅解码器架构，使 LLM 能直接处理语音编码并输出文本翻译。同时，我们探讨了参数高效微调技术和任务设计的效用。在没有使用专有数据训练的模型中，我们的模型在 CoVoST 2 和 FLEURS 上表现卓越。此外，我们通过分析验证了模型设计的合理性，并为 LLM 在 S2TT 任务中的应用提供了新视角。
[Arxiv](https://arxiv.org/abs/2407.03169)
==========
# 紧急呼叫！针对开源大型语言模型的软提示攻击
发布时间：2024年07月03日
`LLM应用` `网络安全` `人工智能`
> SOS! Soft Prompt Attack Against Open-Source Large Language Models
# 摘要
> 开源大型语言模型（LLM）因其可定制、微调及免费使用的特性，在公众和业界广受欢迎。然而，部分开源LLM需经批准方可使用，促使第三方推出更易获取的版本。同时，这些LLM的微调或量化版本也由第三方发布，因其便捷性和较低的计算资源需求而备受青睐。这一趋势却增加了训练期间的攻击风险，威胁到LLM的完整性与安全性。为此，我们提出了一种新型训练时攻击——SOS，该攻击计算需求低，无需清洁数据或修改模型权重，确保模型功能不受影响。SOS能有效应对多种安全威胁，如后门、越狱及提示窃取攻击。实验证明，SOS在所有测试目标上均表现出色。此外，我们还引入了SOS技术的另一创新——版权标记，允许用户为其版权内容打上标记，防止模型滥用。
[Arxiv](https://arxiv.org/abs/2407.03160)
==========
# 代码 LLM 在你修改代码时，也能自我修正。
发布时间：2024年07月03日
`LLM应用` `软件开发` `人工智能`
> Let the Code LLM Edit Itself When You Edit the Code
# 摘要
> 在本研究中，我们探讨了一个代码生成的典型场景：开发者在实时编辑代码时，请求代码助手（如大型语言模型）即时预测下一个代码片段。传统的做法是LLM需重新编码整个KV缓存，这在长序列时计算成本高昂。我们通过引入**位置完整性编码（PIE）**，解决了这一效率与准确性的难题。PIE通过优化旋转位置编码，确保了令牌间位置关系的正确性，并大幅降低了计算需求。实验证明，PIE在多个实际编码任务中，相比传统方法，计算开销减少了85%以上，同时保持了模型性能。
[Arxiv](https://arxiv.org/abs/2407.03157)
==========
# 借助蛋白质语言模型，强化学习在序列设计领域大放异彩。
发布时间：2024年07月03日
`Agent` `药物发现` `生物信息学`
> Reinforcement Learning for Sequence Design Leveraging Protein Language Models
# 摘要
> 蛋白质序列设计的核心在于氨基酸序列，这对药物发现中的蛋白质工程至关重要。传统方法如进化策略或蒙特卡洛方法虽被采用，但未能充分挖掘组合搜索空间的结构，也难以适应新序列。在大规模搜索空间中，利用强化学习学习突变策略生成新序列的方法引人注目。近期，蛋白质语言模型（PLMs）的发展，通过评估蛋白质的生物学合理性（如TM-score），为解决这一难题提供了新思路。我们提出将PLMs作为奖励函数来设计新序列，但考虑到其庞大的计算需求，我们创新性地提出了一种优化策略，即在一个定期微调的小型代理模型上进行评分，同时学习突变策略。通过广泛的实验，我们验证了基于RL的方法在生物学合理性和多样性方面的优势，证实了RL在生物序列设计中的潜力。此外，我们提供的开源模块化实现，易于集成到RL训练流程中，并支持替换奖励模型，旨在推动该领域的深入研究。所有实验代码均已公开。
[Arxiv](https://arxiv.org/abs/2407.03154)
==========
# 借助平行数据的持续预训练，我们能够显著提升大型语言模型的翻译精准度。
发布时间：2024年07月03日
`LLM应用` `机器学习`
> Enhancing Translation Accuracy of Large Language Models through Continual Pre-Training on Parallel Data
# 摘要
> 本文提出了一种两阶段训练策略，先在平行数据上对大型预训练语言模型进行持续预训练，再以少量高质量平行数据进行监督微调。我们通过3.8B参数模型和八种平行数据格式验证了此方法的有效性，并在日英和英日翻译的十三组测试集上进行了评估。实验表明，持续预训练中交替使用源句和目标句至关重要，且翻译准确性仅在预训练与推理的句子顺序一致时提升。此外，基于LLM的翻译模型在处理口语时更稳健，且在较少训练数据下优于传统监督模型。我们还发现，当预训练数据包含交错源句和目标句，并给源句添加标签时，翻译准确性最高。
[Arxiv](https://arxiv.org/abs/2407.03145)
==========
# 评估大型语言模型的社会偏见，需借助多样化的提示手段。
发布时间：2024年07月03日
`LLM理论` `社会科学` `人工智能`
> Social Bias Evaluation for Large Language Models Requires Prompt Variations
# 摘要
> 警告：本文涉及刻板印象和偏见的内容。大型语言模型 (LLM) 存在显著的社会偏见，相关研究正努力准确评估并缓解这些偏见。以往研究通过下游任务提示来检测社会偏见的程度，但这些研究往往依赖于有限的提示类型。本文探讨了 LLM 在改变不同提示（包括任务指令、少样本示例及去偏提示）时的敏感性，并发现 LLM 对提示极为敏感，甚至影响模型在任务性能和社会偏见方面的排名。同时，提示设置中的偏见减少可能导致性能下降，而实例的模糊性也是 LLM 对提示敏感的原因之一。因此，我们建议采用多样化的提示来评估其对 LLM 社会偏见的影响。
[Arxiv](https://arxiv.org/abs/2407.03129)
==========
# KeyVideoLLM：探索大规模视频关键帧的精选之道
发布时间：2024年07月03日
`LLM应用` `视频处理` `人工智能`
> KeyVideoLLM: Towards Large-scale Video Keyframe Selection
# 摘要
> 随着网络视频的兴起，大规模视频数据集的管理与理解变得愈发关键。视频大型语言模型（VideoLLMs）因其卓越的视频理解能力而崭露头角，但其对海量数据的需求给数据管理带来了挑战，尤其是在效率、鲁棒性和有效性方面。为此，我们推出了KeyVideoLLM，一种基于文本-视频帧相似性的关键帧选择方法，旨在高效、稳健且有效地管理VideoLLM数据。KeyVideoLLM不仅实现了高达60.9倍的数据压缩率，大幅节省了存储空间，还保持了100%的选择成功率，并在处理速度上比现有方法快200倍，且无需调整超参数。此外，它在视频问答任务中显著提升了模型性能，并在多个数据集上持续刷新最先进（SoTA）的实验记录。
[Arxiv](https://arxiv.org/abs/2407.03104)
==========
# ScreenTK：通过持续监控移动屏幕文本，精准捕捉消磨时光的瞬间
发布时间：2024年07月03日
`LLM应用` `智能手机` `用户体验`
> ScreenTK: Seamless Detection of Time-Killing Moments Using Continuous Mobile Screen Text Monitoring
# 摘要
> 智能手机已成为数字生活的必需品，不断提供信息和连接。然而，这种持续的信息流有时会让用户只是打发时间而非真正参与。因此，识别这些“消磨时间”时刻并优化通知传递方式变得尤为重要。现有方法通过每5秒截屏来检测消磨时间活动，但常遗漏间隔间的使用情况。我们发现，这种方法可能漏检高达50%的消磨时间实例，导致对用户行为的理解存在显著漏洞。为此，我们提出ScreenTK方法，通过持续监控屏幕文本和利用设备上的大型语言模型（LLMs）来更准确地检测消磨时间时刻。屏幕文本提供了比截图更丰富的信息，使LLMs能更详细地总结手机使用情况。我们通过六名参与者的实验，记录了1,034条消磨时间时刻的数据，初步结果表明，我们的框架在案例研究中比现有最佳方案提升了38%。
[Arxiv](https://arxiv.org/abs/2407.03063)
==========
# ALTER：大型表格推理的增强方案
发布时间：2024年07月03日
`LLM应用` `数据分析` `人工智能`
> ALTER: Augmentation for Large-Table-Based Reasoning
# 摘要
> 尽管已有研究尝试利用大型语言模型 (LLM) 进行基于表格的推理，但多数方法在处理大型表格时面临可扩展性挑战。为此，我们推出了 ALTER 框架，该框架通过查询增强器和表格增强器，有效利用自然语言问题和半结构化表格数据的潜在增强能力。ALTER 通过精选表格数据子集并结合预增强的信息，显著提升了基于表格推理任务的性能。此外，我们还深入分析了大型表格应用场景，对比了多种方法和分区策略。在这些复杂场景中，ALTER 不仅表现卓越，还展现了出色的鲁棒性和效率。
[Arxiv](https://arxiv.org/abs/2407.03061)
==========
# 借助直接偏好对齐，我们致力于提升量化大型语言模型在对话中的表现。
发布时间：2024年07月03日
`LLM应用` `人工智能` `对话系统`
> Improving Conversational Abilities of Quantized Large Language Models via Direct Preference Alignment
# 摘要
> 随着大型语言模型 (LLM) 的飞速进步，它们已进化为能够捕捉语境细节并生成恰当语句的对话机器人，通过指令调优和基于人类反馈的强化学习 (RLHF) 等技术，它们越来越贴近人类价值观。但 LLM 所需的计算效率，尤其是通过后训练量化 (PTQ) 等技术实现的效率，带来了令牌翻转等挑战，可能影响聊天机器人的性能。为此，我们创新性地提出了量化感知直接偏好优化 (QDPO)，这一方法有效对齐了量化 LLM 与全精度模型，显著提升了对话能力。在多语言环境下对两种指令调优的 LLM 进行评估，QDPO 在提升对话能力方面超越了传统的 PTQ 和知识蒸馏微调技术，为高效且强大的对话 LLM 的发展开辟了新篇章。
[Arxiv](https://arxiv.org/abs/2407.03051)
==========
# JailbreakHunter：一种视觉分析方法，旨在从大规模人类与 LLM 的对话数据集中发现越狱提示。
发布时间：2024年07月03日
`LLM应用` `网络安全` `人工智能`
> JailbreakHunter: A Visual Analytics Approach for Jailbreak Prompts Discovery from Large-Scale Human-LLM Conversational Datasets
# 摘要
> 大型语言模型（LLM）备受瞩目，但滥用风险也引发担忧。越狱提示作为针对LLM的对抗性攻击手段，不断演化以突破安全防线。为应对这一挑战，LLM定期更新安全补丁，但恶意用户常保密成功提示以利用模型。为此，我们需深入分析大规模对话数据，以揭示那些仍能绕过防御的提示。面对数据量庞大、提示多样且藏匿于复杂对话中的挑战，我们推出了JailbreakHunter，一种可视化分析工具，用于在大规模人-LLM对话中识别越狱提示。该工具通过组级、对话级和轮次级三个层次的分析，帮助用户掌握对话分布、理解对话进展，并探索提示间的语义联系，从而发现新的越狱策略。通过案例研究和专家评估，我们验证了该工具的有效性和实用性。
[Arxiv](https://arxiv.org/abs/2407.03045)
==========
# 仅需原始文本：为大型语言模型进行知识密集型多轮指令调优
发布时间：2024年07月03日
`LLM应用` `人工智能`
> Raw Text is All you Need: Knowledge-intensive Multi-turn Instruction Tuning for Large Language Model
# 摘要
> 指令调优技术使大型语言模型 (LLM) 的输出更符合人类偏好，但如何从原始文档生成季节性多轮对话仍待探索。本文介绍的 R2S 框架，通过 CoD-对话逻辑链，指导 LLM 生成知识密集型多轮对话。我们整合了多领域的原始文档，如维基百科、科学和文物，构建了 K-BENCH 基准。首先确定对话逻辑，再引导 LLM 生成关键短语，以此创建 G I NSTRUCT 数据集，保留原始文档知识于对话中。通过微调 GLLM 模型，将原始文档转化为结构化多轮对话，注入领域知识，增强指令调优效果。这项研究推动了 LLM 在多领域生成更精准、上下文敏感响应的能力。
[Arxiv](https://arxiv.org/abs/2407.03040)
==========
# 探讨联邦学习环境下，客户端对 LLM 微调的偏好
发布时间：2024年07月03日
`LLM应用` `人工智能` `隐私保护`
> On the Client Preference of LLM Fine-tuning in Federated Learning
# 摘要
> 利用人类反馈的强化学习（RLHF）通过偏好数据集对预训练的大型语言模型（LLM）进行微调，使其输出更符合人类偏好。考虑到这些敏感的偏好数据集由不同客户持有，我们需在联邦学习（FL）框架内实施RLHF，以保护客户因隐私顾虑而不愿共享数据。为此，我们提出一个框架，客户通过我们设计的FedBis协作训练一个二元选择器。借助训练有素的选择器，我们能进一步优化LLM，使其生成更符合人类偏好的内容。此外，我们创新算法FedBiscuit，通过根据客户偏好将他们分组为平衡且独立的集群，训练多个选择器。实验显示，FedBiscuit在模拟成对完成的偏好方面表现更佳，且在处理联邦人类偏好数据集时，不仅超越FedBis，甚至优于传统集中式训练。
[Arxiv](https://arxiv.org/abs/2407.03038)
==========
# SAFT：致力于在微调过程中实现分布外的泛化能力
发布时间：2024年07月03日
`LLM应用` `机器学习` `计算机视觉`
> SAFT: Towards Out-of-Distribution Generalization in Fine-Tuning
# 摘要
> 在机器学习领域，处理训练数据中的分布偏移（OOD泛化）是一个重大挑战。尽管CLIP等预训练模型在零-shot任务中表现出色，但适应下游任务时却可能导致OOD数据的性能下降。为此，我们提出了稀疏适应微调（SAFT），一种防止微调过程中遗忘预训练模型通用知识的方法。SAFT仅更新关键参数，保持其他参数不变，实现简单且效果显著。实验证明，仅需调整0.1%的模型参数，SAFT就能大幅提升CLIP性能，并在多个基准测试中超越传统方法。在ImageNet及其变体的少样本学习基准上，SAFT在OOD设置下平均提升了5.15%。
[Arxiv](https://arxiv.org/abs/2407.03036)
==========
# 通过视频对齐与答案聚合，实现组合推理，提升视频问答的准确性。
发布时间：2024年07月03日
`LLM应用` `视频处理` `问答系统`
> Align and Aggregate: Compositional Reasoning with Video Alignment and Answer Aggregation for Video Question-Answering
# 摘要
> 尽管视频问答 (VideoQA) 领域近期有所进展，但这些方法常作为黑箱，难以理解其推理过程和保持组合推理的一致性。为此，我们设计了一个模型无关的视频对齐与答案聚合框架 (VA$^{3}$)，通过整合视频对齐器和答案聚合器，提升现有 VidQA 方法的组合一致性和准确性。视频对齐器根据问题筛选相关视频片段，答案聚合器则依据子问题推导答案，确保组合一致性。我们在 AGQA-Decomp 数据集上进行了评估，并引入了新指标来全面衡量组合一致性。此外，我们利用大型语言模型 (LLM) 开发了自动问题分解流程，扩展了 MSVD 和 NExT-QA 数据集，以广泛评估 VA$^3$ 框架。实验结果显示，该框架有效提升了方法的组合一致性和准确性，使实际 VidQA 模型更具解释性。
[Arxiv](https://arxiv.org/abs/2407.03008)
==========
# 工具学习的稳定性受何影响？本研究深入探讨了工具学习框架的鲁棒性。
发布时间：2024年07月03日
`LLM应用` `人工智能` `软件开发`
> What Affects the Stability of Tool Learning? An Empirical Study on the Robustness of Tool Learning Frameworks
# 摘要
> 工具学习方法提升了 LLM 与现实应用的互动能力，但性能受任务、数据集、训练设置和算法影响，导致结果不一、部署低效和工具使用欠佳。本文深入分析了这些内外因素，通过实验揭示了 LLM 在更多尝试和探索中能显著提升性能。我们的研究为工具学习领域带来了新视角。
[Arxiv](https://arxiv.org/abs/2407.03007)
==========
# SemioLLM：探究大型语言模型在癫痫研究符号学分析中的应用潜力
发布时间：2024年07月03日
`LLM应用` `人工智能`
> SemioLLM: Assessing Large Language Models for Semiological Analysis in Epilepsy Research
# 摘要
> 大型语言模型在医学问答数据集中展现了出色的知识编码能力，但在临床应用中仍需在特定任务上验证。在 semioLLM 研究中，我们评估了 GPT-3.5、GPT-4 等先进模型在癫痫诊断中的表现。通过分析一个包含 1269 条数据的临床数据库，我们探索了模型如何从非结构化文本中推断癫痫相关信息。尽管模型在精心设计的提示下表现出色，接近临床水平，但仍存在过度自信和引用错误等问题。本研究首次为医学领域的 LLM 提供了详尽基准，强调了它们在辅助诊断中的潜力。
[Arxiv](https://arxiv.org/abs/2407.03004)
==========
# 大型语言模型在处理价值导向问题时，其一致性如何？
发布时间：2024年07月03日
`LLM理论` `人工智能` `社会科学`
> Are Large Language Models Consistent over Value-laden Questions?
# 摘要
> 大型语言模型 (LLM) 在回答调查时似乎倾向于某些特定价值观。然而，有人质疑这些模型是否足够一致以模拟特定价值观。为了探讨这一问题，我们将价值一致性定义为在不同情境下的答案相似度：包括同一问题的不同表述、同一主题下的相关问题、选择题与开放式问题的答案，以及多语言翻译后的答案。我们评估了包括 llama-3 和 gpt-4o 在内的大型开放 LLM，使用了跨越 300 多个主题的八千个问题。研究发现，模型在不同情境下表现出较高的一致性，尽管在争议性主题上仍存在不一致。基础模型在一致性上优于微调模型，且在各主题上的一致性更为均匀，而微调模型在某些敏感主题上的一致性较低，这与人类受试者的表现相似。
[Arxiv](https://arxiv.org/abs/2407.02996)
==========
# 机器人辅助的科学文本分析在观测站提案中的应用
发布时间：2024年07月03日
`LLM应用` `科学研究` `人工智能`
> Scientific Text Analysis with Robots applied to observatory proposals
# 摘要
> ESO 针对 P112 提案征集进行了一项实验，旨在探索 AI 转换器（如 ChatGPT）及其大型语言模型对提案审查和评分过程的影响。实验结果显示，ChatGPT 调整的提案评分普遍较低，且其提供的科学参考准确性有待提高。最新版本的 ChatGPT 虽有改进，但仍不完美。此外，ChatGPT 在总结提案内容方面表现出色，但在识别提案弱点上则不尽如人意。值得注意的是，ChatGPT 给出的评分往往高于人类，且更偏爱由其自身生成的提案。这些发现有助于决策者更好地理解 AI 在提案审查中的应用。
[Arxiv](https://arxiv.org/abs/2407.02992)
==========
# LoRA-Guard：为大型语言模型提供参数高效的内容审核护栏适应方案
发布时间：2024年07月03日
`LLM应用` `移动设备` `内容审核`
> LoRA-Guard: Parameter-Efficient Guardrail Adaptation for Content Moderation of Large Language Models
# 摘要
> 护栏作为大型语言模型内容审核的安全对齐替代方案崭露头角。然而，现有基于模型的护栏设计并未考虑资源受限的便携设备，如手机，这些设备正越来越多地运行本地 LLM 应用。为此，我们推出了 LoRA-Guard，一种高效利用参数的护栏适应方法，它通过 LLM 与护栏模型间的知识共享，提取语言特征并借助低秩适配器进行内容审核，同时采用双路径设计确保生成任务性能不受影响。实验表明，LoRA-Guard 在保持高准确率的同时，参数开销大幅降低，为设备端内容审核提供了新可能。
[Arxiv](https://arxiv.org/abs/2407.02987)
==========
# Mast Kalandar 参与 SemEval-2024 任务 8，探索文本源头：采用 RoBERTa-BiLSTM 方法，精准识别 AI 生成文本。
发布时间：2024年07月03日
`LLM应用`
> Mast Kalandar at SemEval-2024 Task 8: On the Trail of Textual Origins: RoBERTa-BiLSTM Approach to Detect AI-Generated Text
# 摘要
> 大型语言模型 (LLM) 在生成流畅的用户查询响应方面表现出色，但其在新闻、教育和学术领域的潜在滥用引发了关注。SemEval 2024 的 Multigenerator、Multidomain 和 Multilingual Black-Box Machine-Generated Text Detection 任务，旨在开发自动识别和防范机器生成文本滥用的系统。本文提出了一种基于 RoBERTa-BiLSTM 的分类器，用于区分 AI 和人类生成的文本，并通过对比研究验证了其有效性。我们的工作有助于提升自动文本检测技术，以应对机器生成文本滥用的挑战。在 125 个参赛者中，我们的架构以 80.83% 的准确率位列第 46 名。
[Arxiv](https://arxiv.org/abs/2407.02978)
==========
# 大型语言模型：科学综合的评判者
发布时间：2024年07月03日
`LLM应用` `科学研究` `人工智能`
> Large Language Models as Evaluators for Scientific Synthesis
# 摘要
> 本研究深入探讨了GPT-4和Mistral等尖端大型语言模型在评估科学综合质量方面的表现，并将其与人类专家的评价进行对比。我们采用了一个包含100个研究问题及其综合的数据集，这些综合由GPT-4从五篇相关论文的摘要中生成，并与人类质量评级进行核对。初步数据显示，尽管LLMs能提供逻辑上合理的解释，这些解释在一定程度上与人类评级相符，但进一步的统计分析揭示了LLM与人类评级之间的弱相关性，这凸显了LLMs在科学综合评估中的潜力与当前局限。
[Arxiv](https://arxiv.org/abs/2407.02977)
==========
# FSM：一种基于有限状态机的零-shot 提示方法，专为多跳问题回答设计
发布时间：2024年07月03日
`LLM应用` `人工智能`
> FSM: A Finite State Machine Based Zero-Shot Prompting Paradigm for Multi-Hop Question Answering
# 摘要
> 结合思维链提示的大型语言模型在简单推理任务上表现卓越，但在多跳问答任务中因幻觉、错误传播等问题表现欠佳。为此，我们引入了有限状态机提示法，通过迭代分解问题并实时自校，显著提升复杂任务的推理精度和可信度。实验表明，该方法在挑战性数据集上超越基线，有效缓解了中间错误导致的幻觉问题，并强化了模型遵循输出格式的能力，大幅简化了答案解读与格式调整的复杂性。
[Arxiv](https://arxiv.org/abs/2407.02964)
==========
# GraCoRe：评估大型语言模型中的图表理解和复杂推理能力
发布时间：2024年07月03日
`LLM应用` `数据分析`
> GraCoRe: Benchmarking Graph Comprehension and Complex Reasoning in Large Language Models
# 摘要
> 评估 LLMs 的图表理解和推理能力颇具挑战，现有基准多聚焦于纯图表理解，缺乏全面评估。为此，我们推出了 GraCoRe 基准，采用三层分类法，涵盖纯图表与异构图表，细分为 10 大能力领域，通过 19 项任务进行测试。该基准包含 11 个数据集，共 5,140 个图表。我们评估了 10 个 LLMs，深入分析了其能力和任务表现。研究发现，语义丰富性可提升推理性能，节点顺序对任务成功有影响，而处理长文本的能力并不必然提升图表理解或推理能力。GraCoRe 已开源，详情见 https://github.com/ZIKEYUAN/GraCoRe。
[Arxiv](https://arxiv.org/abs/2407.02936)
==========
# GPTQT：通过两次量化大型语言模型，推动效率提升
发布时间：2024年07月03日
`LLM理论` `计算机科学` `人工智能`
> GPTQT: Quantize Large Language Models Twice to Push the Efficiency
# 摘要
> 生成式大型语言模型 (LLM) 因其规模庞大，对计算和存储资源需求巨大。本文提出的 GPTQT 方法，通过将权重量化为 3bit/2bit，有效减少了内存占用并提升了处理速度。实践中发现，单纯减少量化误差易导致过拟合，GPTQT 因此采用两步渐进策略：先以较高位线性量化权重，再将其转换为低位的二进制编码。此外，引入重新探索策略优化初始缩放因子，推理时合并步骤为纯二进制编码，计算效率显著提升。跨模型与数据集的测试显示，GPTQT 在 opt-66B 上降低困惑度 4.01，在 opt-30b 上提速 1.24 倍，成为当前针对此类 LLM 的最佳二进制编码量化方法。
[Arxiv](https://arxiv.org/abs/2407.02891)
==========
# CogErgLLM：从认知工效学角度探究大型语言模型的系统设计
发布时间：2024年07月03日
`LLM理论` `人机交互` `伦理开发`
> CogErgLLM: Exploring Large Language Model Systems Design Perspective Using Cognitive Ergonomics
# 摘要
> 将认知工效学融入 LLM 设计，对于提升人机交互的安全性、可靠性和用户满意度至关重要。然而，当前 LLM 设计往往忽视了这一点，导致系统与人类认知能力不匹配。缺乏对认知科学方法的整合，不仅加剧了 LLM 输出的偏见，还导致了用户体验的不佳。为此，我们的立场文件深入探讨了如何将认知工效学原则融入 LLM 设计，旨在构建一个全面的伦理开发框架和实用指南。我们的目标是推动认知工效学在 LLM 系统中的应用，从而促进更安全、更可靠且符合伦理的人机交互。
[Arxiv](https://arxiv.org/abs/2407.02885)
==========
# LANE：实现非调优大型语言模型与在线推荐系统的逻辑对齐，旨在生成可解释的推理。
发布时间：2024年07月03日
`LLM应用` `推荐系统` `用户体验`
> LANE: Logic Alignment of Non-tuning Large Language Models and Online Recommendation Systems for Explainable Reason Generation
# 摘要
> 推荐系统的透明度是提升用户信任与满意度的关键。借助大型语言模型（LLM），我们迎来了全面推荐逻辑生成的新契机。然而，现有研究在为推荐任务微调LLM时，面临高昂计算成本及与现有系统对齐的难题，这限制了如GPT-4等专有/闭源LLM模型的应用前景。为此，我们创新性地提出了LANE策略，无需额外微调即可实现LLM与在线推荐系统的无缝对接，既降低了成本，又增强了可解释性。该策略通过语义嵌入、零-shot提示下的用户多偏好提取、语义对齐及思维链（CoT）提示下的可解释推荐生成等关键环节，确保了用户偏好与候选项目的语义一致性，从而提供连贯且贴合用户需求的推荐。实验结果显示，我们的方法不仅保障了推荐质量，更以直观易懂的方式呈现了推荐逻辑，赢得了用户的广泛认可。
[Arxiv](https://arxiv.org/abs/2407.02833)
==========
# 探究 LLM 在代码变更任务中的潜能
发布时间：2024年07月03日
`LLM应用` `软件开发` `人工智能`
> Exploring the Capabilities of LLMs for Code Change Related Tasks
# 摘要
> 开发者日常处理代码变更任务，如代码审查。预训练模型已助力此类工作。近期，大型语言模型（LLMs）在代码任务中表现出色，但主要关注通用代码特性，而非版本差异。我们通过实证研究，利用超10亿参数的LLMs，针对代码审查生成等三项任务，结合上下文学习和参数高效微调（PEFT），发现无示例时性能不佳，示例增多性能提升，但并非越多越好。LoRA微调的LLMs与顶尖小型模型性能相当，大模型未必更优，但Llama 2和Code Llama系列始终领先。最佳LLMs在注释修改上超越小型模型，其他变更中表现相当。未来研究应聚焦于指导LLMs掌握代码变更的特定知识，而非仅注释相关。
[Arxiv](https://arxiv.org/abs/2407.02824)
==========
# 通过紧凑一致的下一词分布，实现语言模型的高效训练
发布时间：2024年07月03日
`LLM理论` `人工智能`
> Efficient Training of Language Models with Compact and Consistent Next Token Distributions
# 摘要
> 在预训练语言模型中，最大化下一个词元的似然性是一个既定且统计上合理的优化目标。本文通过预先聚合具有压缩 $n$-gram 分布的语料库，展示了如何更快地训练出更优秀的模型。尽管先前研究提出将语料库级别的 $n$-gram 统计作为正则化器，但其构建和查询过程若处理不当，成本高昂且显著阻碍训练速度，限制了其在大型语言模型预训练中的应用。为此，我们引入了一种紧凑的替代表示方法，该方法在期望上与完整 $n$-gram 分布一致，同时显著减少了小批量间的方差。实证结果显示，无论是 $n$-gram 正则化模型还是我们的近似方法，都显著提升了模型质量和收敛速度。此外，我们的近似方法相较于直接的 $n$-gram 正则化，更有利于在大规模数据集和模型上扩展这些增益。
[Arxiv](https://arxiv.org/abs/2407.02819)
==========
# InternLM-XComposer-2.5：一款多功能大型视觉语言模型，专为长上下文输入与输出设计。
发布时间：2024年07月03日
`LLM应用` `网页制作` `媒体创作`
> InternLM-XComposer-2.5: A Versatile Large Vision Language Model Supporting Long-Contextual Input and Output
# 摘要
> 我们推出了 InternLM-XComposer-2.5（IXC-2.5），一款支持长上下文输入输出的多功能大型视觉语言模型。IXC-2.5 在文本图像理解和合成领域表现卓越，仅凭 7B LLM 后端即达到 GPT-4V 级性能。经过 24K 交错图像文本上下文的训练，它能通过 RoPE 外推无缝扩展至 96K 长上下文，从而在需要大量上下文的任务中大放异彩。相较于 2.0 版本，IXC-2.5 在视觉语言理解方面实现了三大飞跃：超高分辨率理解、细粒度视频理解及多轮多图像对话。此外，IXC-2.5 利用额外 LoRA 参数，拓展至两大创新应用：网页制作与高质量文本图像文章创作。在 28 个基准测试中，IXC-2.5 在 16 个项目上超越了现有开源顶尖模型，并在 16 个关键任务上与 GPT-4V 和 Gemini Pro 一较高下。该模型已公开，访问地址为 https://github.com/InternLM/InternLM-XComposer。
[Arxiv](https://arxiv.org/abs/2407.03320)
==========
# 图灵程序在通用长度泛化中的应用
发布时间：2024年07月03日
`LLM理论` `人工智能` `计算机科学`
> Universal Length Generalization with Turing Programs
# 摘要
> 长度泛化能力，即从短序列训练到长序列测试的外推能力，是大型语言模型面临的一大挑战。虽然已有研究尝试通过改变架构或数据格式来解决这一问题，但这些方法往往局限于特定任务。我们基于先前的scratchpad和Chain-of-Thought（CoT）技术，创新性地提出了Turing Programs策略，将算法任务分解为模拟图灵机计算的步骤。这一策略不仅通用性强，适用于任何算法任务，而且操作简便，仅需对上下文文本进行小幅修改。实验表明，采用Turing Programs策略，我们在加法、乘法及上下文SGD等多项算法任务上实现了稳健的长度泛化。进一步研究发现，transformer模型在处理随机Turing Programs时也能实现长度泛化，这表明任何算法任务都有可能实现这一目标。最后，我们从理论层面证明了transformer模型能够执行Turing Programs，并构建了一个模拟任意图灵机的简单RASP程序。
[Arxiv](https://arxiv.org/abs/2407.03310)
==========
# 利用大型语言模型进行 JSON 模式探索
发布时间：2024年07月03日
`LLM应用` `数据管理`
> Large Language Models for JSON Schema Discovery
# 摘要
> JSON 等半结构化数据格式因其灵活性在应用中广受欢迎，但缺乏关系数据中的固定模式。为此，我们研发了一种新方法，利用大型语言模型和人工编写的 JSON Schema 文档，自动为发现的模式添加语义信息，生成自然语言描述和有意义的定义名称，并区分有用与无用的属性。该方法在文本生成评估中表现优异，与人类判断高度一致。
[Arxiv](https://arxiv.org/abs/2407.03286)
==========
# LLM 的内部状态暴露了在面对查询时可能产生的幻觉风险。
发布时间：2024年07月03日
`LLM理论` `人工智能`
> LLM Internal States Reveal Hallucination Risk Faced With a Query
# 摘要
> 大型语言模型的幻觉问题严重影响了其可靠性和可信度。借鉴人类的自我意识，我们研究了模型在生成回答前能否预估幻觉风险。通过分析训练数据和15种NLG任务，我们发现模型内部状态能揭示其是否见过查询及是否可能产生幻觉。进一步探索关键神经元和激活层，我们利用模型自我评估，实现了高达84.32%的幻觉风险实时准确预估。
[Arxiv](https://arxiv.org/abs/2407.03282)
==========
# AgentInstruct：迈向结合生成教学与代理流的新境界
发布时间：2024年07月03日
`Agent` `人工智能`
> AgentInstruct: Toward Generative Teaching with Agentic Flows
# 摘要
> 合成数据在推动语言模型发展中扮演着日益关键的角色。尽管其应用已取得一些成功，但模型崩溃和模仿缺陷的问题也引起了关注。这些问题的根源在于合成数据的质量和多样性参差不齐。要有效利用合成数据，往往需要大量的人工筛选。我们专注于利用合成数据进行模型后训练，即通过高级模型生成数据，传授新技能给其他模型，这一过程我们称之为“生成教学”。为此，我们开发了AgentInstruct框架，它能自动生成大量高质量且多样化的合成数据。该框架仅需文本和代码等原始数据作为种子，即可生成提示和响应。我们通过构建一个包含2500万对的数据集，展示了AgentInstruct的实际应用，该数据集涵盖了文本编辑、创意写作、工具操作、编程和阅读理解等多种技能。这一数据集可广泛应用于各类基础模型的指令微调。我们利用这些数据对Mistral-7b进行了后训练，结果显示，与基于相同基础模型的Mistral-7b-Instruct相比，新模型Orca-3在多项基准测试中取得了显著进步，如在AGIEval上提升了40%，在MMLU上提升了19%，在GSM8K上提升了54%，在BBH上提升了38%，在AlpacaEval上提升了45%。此外，Orca-3在性能上持续超越了LLAMA-8B-instruct和GPT-3.5-turbo等其他模型。
[Arxiv](https://arxiv.org/abs/2407.03502)
==========
# 借助大型语言模型，通过深入理解对话内容，我们提升了图像选择的精准度，实现了对话的可视化呈现。
发布时间：2024年07月03日
`LLM应用` `人工智能` `图像处理`
> Visualizing Dialogues: Enhancing Image Selection through Dialogue Understanding with Large Language Models
# 摘要
> 对话系统的最新进展强调了整合多模态响应的重要性，这种响应方式通过多种模态传达思想，不仅提升了沟通效率，还增强了对话体验。然而，现有的对话到图像检索方法受限于预训练视觉语言模型（VLM）在理解复杂对话方面的不足。为此，我们提出了一种新方法，利用大型语言模型（LLM）的强大推理能力生成精确的对话相关视觉描述符，实现与图像的无缝连接。基准数据上的实验证实了我们的方法在生成简洁准确视觉描述符方面的有效性，显著提升了检索性能。研究还表明，该方法在不同视觉线索、LLM和数据集上的通用性，凸显了其在实际应用中的实用性和潜在影响。
[Arxiv](https://arxiv.org/abs/2407.03615)
==========
# LLMcap：一款专为无监督 PCAP 故障检测设计的大型语言模型
发布时间：2024年07月03日
`LLM应用` `网络服务`
> LLMcap: Large Language Model for Unsupervised PCAP Failure Detection
# 摘要
> 随着先进技术融入电信网络，故障排查变得更加复杂，手动识别PCAP数据中的错误变得困难重重。传统的手动方法在大规模应用时资源消耗巨大，难以实施。虽然机器学习方法提供了替代方案，但标记数据的稀缺性限制了其准确性。本研究提出了一种基于大型语言模型的自监督方法LLMcap，用于PCAP故障检测。LLMcap运用语言学习技巧，通过掩码语言建模掌握语法、上下文和结构。在多种PCAP数据上进行严格测试后，即使训练时缺乏标记数据，LLMcap仍展现出高准确性，为网络分析的高效性提供了新的希望。关键词：网络故障排查，PCAP数据分析，自监督学习，大型语言模型，网络服务质量，网络性能。
[Arxiv](https://arxiv.org/abs/2407.06085)
==========
# 大型语言模型代理助力提升行为改变干预的参与度，特别应用于数字正念领域。
发布时间：2024年07月03日
`LLM应用` `健康科技`
> Large Language Model Agents for Improving Engagement with Behavior Change Interventions: Application to Digital Mindfulness
# 摘要
> 虽然自我导向的健康练习参与度随时间下降，但融入教练等社会支持可维持其参与。传统支持因高成本和复杂性而难以触及，而大型语言模型（LLMs）通过提供类人对话，有望模拟社会支持。我们对LLMs在行为改变支持方面的深入研究尚显不足。为此，我们开展了两次随机实验，评估LLM代理对正念练习参与度的影响。首次实验涉及502名众包工作者，进行单次会话；第二次实验为期三周，包含54名参与者。我们测试了两类LLM代理：信息提供型和自我反思促进型。两者均增强了用户练习正念的意愿，但仅信息提供型LLM，以其友好角色，显著提升了练习参与度。研究结果暗示，特定LLM代理或能在数字健康干预中填补社会支持的空白。
[Arxiv](https://arxiv.org/abs/2407.13067)
==========
# 机器，你懂我的话吗？
发布时间：2024年07月02日
`Agent` `人工智能` `对话系统`
> Talking to Machines: do you read me?
# 摘要
> 本论文旨在引领读者深入对话研究领域，特别是我自博士论文以来的学术探索。从模块化架构到端到端深度神经网络，我不仅分享了作为研究助理的经验，还展示了近年来我所指导的研究成果。简述当前对话代理的研究前沿后，我重点介绍了在任务导向对话（TOD）中的个人贡献，并深入探讨了对话问答领域，包括Thibault Cordier、Sebastien Montella和Quentin Brabant的研究工作。最后，我详述了关于大型语言模型在任务导向对话及多模态任务导向对话中的科学项目。
[Arxiv](https://arxiv.org/abs/2407.02354)
==========
# 移动机器人中的具身AI：借助大型语言模型实现高效覆盖路径规划
发布时间：2024年07月02日
`Agent` `自动化` `机器人`
> Embodied AI in Mobile Robots: Coverage Path Planning with Large Language Models
# 摘要
> 近年来，大型语言模型（LLM）在数学问题解决方面表现出色，促进了多领域的发展。我们设计了一种移动代理的LLM路径规划框架，专注于高级覆盖路径规划和低级控制。该框架采用多层架构，在路径规划阶段融合提示LLM与移动代理的执行器。为评估LLM性能，我们引入了覆盖加权路径规划指标。实验表明，该框架增强了LLM的空间推理能力，通过利用其自然语言处理能力，显著提升了任务效率和准确性。实验还显示，该框架能增强LLM的二维推理能力，并有效完成全覆盖路径规划。我们测试了三种LLM内核：gpt-4o、gemini-1.5-flash和claude-3.5-sonnet，结果显示claude-3.5在不同场景下的覆盖规划任务中表现更优。
[Arxiv](https://arxiv.org/abs/2407.02220)
==========
# TokenPacker：专为多模态 LLM 设计的高效视觉投影工具
发布时间：2024年07月02日
`LLM应用` `计算机视觉` `人工智能`
> TokenPacker: Efficient Visual Projector for Multimodal LLM
# 摘要
> 在多模态大型语言模型（MLLM）中，视觉投影仪是连接视觉编码器与大型语言模型（LLM）的关键桥梁。传统方法通过简单MLP保留视觉上下文，但处理高分辨率图像时，视觉令牌冗余增加，影响效率。近期改进虽减少令牌数量，却牺牲了细节和推理能力。我们提出新视觉投影仪，采用由粗到细策略，注入丰富特征生成浓缩令牌。首先，将视觉特征插值为低分辨率点查询，奠定整体视觉基础；接着，通过区域到点注入模块，利用高分辨率、多层次区域线索，在局部上下文区域充分吸收，有效更新点查询，为LLM推理提供丰富信息。实验显示，我们的方法大幅压缩令牌（75%~89%），在多样化基准测试中性能卓越，效率显著提升。源代码见https://github.com/CircleRadon/TokenPacker。
[Arxiv](https://arxiv.org/abs/2407.02392)
==========
# 构建综合框架，助力三维脑CT报告生成中的多模态大型语言模型发展
发布时间：2024年07月02日
`LLM应用` `放射学`
> Towards a Holistic Framework for Multimodal Large Language Models in Three-dimensional Brain CT Report Generation
# 摘要
> 多模态大型语言模型（MLLMs）在医疗领域的应用，尤其是放射学报告生成方面，已展现出巨大潜力。然而，二维放射学字幕的初步成功并不能完全反映三维解剖学中的实际诊断挑战。为此，我们针对现有文献中的三大限制——数据复杂性、模型容量和评估指标的忠实度，收集了18,885个文本-扫描对的3D-BrainCT数据集，并采用临床视觉指令调优（CVIT）训练BrainGPT模型，以生成高质量的3D脑CT报告。内部测试显示，BrainGPT在多项指标上表现优异，如BLEU-1得分44.35，BLEU-4得分20.38，METEOR得分30.13，ROUGE-L得分47.6，CIDEr-R得分211.77，并在外部验证CQ500数据集上的字幕中线偏移准确性达到0.91。我们发现，传统评估指标仅能衡量文本表面相似性，未能深入评估诊断信息密度。因此，我们提出了创新的面向特征的放射学任务评估（FORTE），以更准确地衡量报告的临床相关性。BrainGPT模型在FORTE评估中平均F1-分数达到0.71，显示出其在病变特征和地标识别方面的优异性能。此外，通过图灵测试，我们证实了BrainGPT模型生成的报告与人类编写的报告难以区分，证明了其生成类似人类放射学报告的能力。我们的研究不仅展示了3D脑CT数据集的策划经验，还推动了解剖学敏感语言模型的微调及放射学评估指标的创新。
[Arxiv](https://arxiv.org/abs/2407.02235)
==========
# 多模态问题生成的合成技术
发布时间：2024年07月02日
`RAG`
> Synthetic Multimodal Question Generation
# 摘要
> 多模态检索增强生成（MMRAG）在多模态文档问答领域表现卓越，但评估其性能时面临高质量数据集的稀缺问题。为此，我们设计了SMMQG合成数据生成框架，该框架巧妙结合检索器、大型语言模型（LLM）和大型多模态模型（LMM），直接从多模态文档中生成符合特定风格和模态的问题与答案。我们利用SMMQG构建了一个包含1024个问题的MMRAG数据集，覆盖维基百科文档，并据此评估前沿模型，揭示了仅凭风格和模态特定数据才能洞察的模型性能。进一步地，我们通过人类研究验证了SMMQG生成数据的质量，结果显示其与MMQA众包基准不相上下，且下游评估结果高度吻合。
[Arxiv](https://arxiv.org/abs/2407.02233)
==========
# 大陆交汇处：借助大型多模态模型实现文化适应的自动文物提取
发布时间：2024年07月02日
`LLM应用` `文化研究` `人工智能`
> Crossroads of Continents: Automated Artifact Extraction for Cultural Adaptation with Large Multimodal Models
# 摘要
> 本研究通过三阶段全面考察了大型多模态模型（LMMs）在文化识别、文化表征准确性及跨文化内容适应能力方面的表现。首先，我们推出了Dalle Street数据集，由DALL-E 3生成并经人工验证，涵盖67国及10类概念的9,935张图片。研究发现，无论是开放还是闭源模型，在次区域文化理解上均存在差异。随后，通过文物提取任务深入评估模型文化理解力，识别出逾18,000件各国相关文物。最终，我们设计了CultureAdapt流水线，实现图像的跨文化适应。研究揭示了LMMs在文化处理上的细微差别，凸显了构建文化感知系统的重要性。相关数据集与代码已公开于https://github.com/iamshnoo/crossroads。
[Arxiv](https://arxiv.org/abs/2407.02067)
==========
# 利用大型语言模型实现端到端语音摘要
发布时间：2024年07月02日
`LLM应用` `语音处理`
> An End-to-End Speech Summarization Using Large Language Model
# 摘要
> 抽象语音摘要（SSum）旨在从口语内容中提炼出类人文本摘要，但处理长语音输入和捕捉跨模态复杂映射仍是一大挑战。本文提出一种端到端SSum模型，通过Q-Former连接音频与文本模态，并借助LLMs直接从语音特征生成摘要。我们采用多阶段训练策略，包括基于LLM的ASR和TSum任务，以对齐特征空间并增强处理长语音的能力。通过课程学习，模型顺利从TSum过渡到SSum，最终在How-2数据集上展现出优异性能。
[Arxiv](https://arxiv.org/abs/2407.02005)
==========
# 探索不确定性：多模态认知与偶然性意识的评估基准与度量
发布时间：2024年07月02日
`LLM理论` `人工智能` `计算机视觉`
> Certainly Uncertain: A Benchmark and Metric for Multimodal Epistemic and Aleatoric Awareness
# 摘要
> AI系统的真实可靠性建立在对知识与推理中必然存在的不确定性的认识上。本文精心构建了视觉-语言AI系统的不确定性分类，细分为信息不足的认知不确定性和本质难测的偶然不确定性，并深入探索其细分领域。据此，我们打造了CertainlyUncertain数据集，内含178K对比式VQA样本，通过图像修复与语言模型提示，巧妙地将可答问题转化为不可答。同时，我们创新性地提出了置信度加权准确率这一新指标，有效结合了准确性与校准误差，旨在弥补传统指标的缺陷。
[Arxiv](https://arxiv.org/abs/2407.01942)
==========
# 视频水印技术：保护您的视频内容，防止基于视频的 LLM 进行未经授权的注释。
发布时间：2024年07月02日
`LLM应用` `视频安全` `数字版权保护`
> Video Watermarking: Safeguarding Your Video from (Unauthorized) Annotations by Video-based LLMs
# 摘要
> 随着基于视频的 LLM 的兴起，视频理解能力得到了显著提升，但同时也带来了数据保护的安全隐患。本文提出的视频水印技术，通过在关键帧中巧妙嵌入水印，有效防止了未经授权的标注行为，尤其针对视频内容和描述。该技术不仅保持了视频的观赏体验，还通过多模态流式损失确保了水印的隐秘性和鲁棒性。实验证明，视频水印能显著降低 LLM 对视频的理解能力，为视频内容的安全提供了坚实保障，确保了其在不断进步的 LLM 技术中的完整性和保密性。
[Arxiv](https://arxiv.org/abs/2407.02411)
==========
# CEB：大型语言模型公平性的组合评估基准
发布时间：2024年07月02日
`LLM应用` `社会科学`
> CEB: Compositional Evaluation Benchmark for Fairness in Large Language Models
# 摘要
> 随着 LLM 在 NLP 任务中的广泛应用，其生成内容可能带来的社会负面影响也引起了关注。为评估 LLM 的偏见，研究者们提出了多种数据集，但现有评估多聚焦于单一偏见类型，且指标不统一，导致跨数据集和模型的比较困难。为此，我们收集了多样的偏见评估数据集，并提出 CEB，一个覆盖不同社会群体和任务的多类型偏见组合评估基准。CEB 基于我们新创的组合分类法构建，该分类法从偏见类型、社会群体和任务三个维度对数据集进行全面描述。通过整合这三个维度，我们设计了一套全面的 LLM 偏见评估策略。实验显示，偏见程度在各维度间存在差异，为针对性偏见缓解方法的开发提供了方向。
[Arxiv](https://arxiv.org/abs/2407.02408)
==========
# 探究大型语言模型在代码克隆检测方面的能力
发布时间：2024年07月02日
`LLM应用` `软件工程` `人工智能`
> Assessing the Code Clone Detection Capability of Large Language Models
# 摘要
> 本研究评估了 GPT-3.5 和 GPT-4 在代码克隆检测中的表现，发现 GPT-4 在所有克隆类型上均优于 GPT-3.5。研究还揭示了 GPT 模型在识别复杂 Type-4 克隆时的不足，以及在处理 LLM 生成代码时相对较高的性能。尽管如此，GPT 模型的准确性仍有待提高。这些发现强调了 LLM 在代码克隆识别和避免自我生成克隆方面的持续改进需求，特别是在软件工程师广泛使用 LLM 辅助工具的背景下。
[Arxiv](https://arxiv.org/abs/2407.02402)
==========
# 精炼学习：借助细粒度自然语言反馈
发布时间：2024年07月02日
`LLM应用` `人工智能`
> Learning to Refine with Fine-Grained Natural Language Feedback
# 摘要
> 近期研究探索了大型语言模型（LLM）在识别并修正自身生成内容中的错误方面的能力。尽管这些改进策略常聚焦于模型大小与问题类型的匹配，却较少关注何种反馈形式最为有效。本研究将反馈驱动的改进分解为三项LLM核心技能：（1）不良生成识别；（2）细致入微的自然语言反馈构建；（3）基于精细反馈的优化。首项技能可由高效判别模型实现，后两项则可通过提示或微调LLM达成。此法之精髓在于，第二步的批评模型能提供针对错误的细致反馈，得益于第一步将判别任务独立处理。实证表明，不同性能级别的模型均能通过此法在提升文档摘要的事实一致性上获益。总体而言，我们所提方法在性能上持续超越传统端到端改进及未专门针对事实核查微调的现存模型。
[Arxiv](https://arxiv.org/abs/2407.02397)
==========
# AI 编写的代码，真的无懈可击吗？通过 CodeSecEval 工具，我们评估了大型语言模型在安全代码生成方面的表现。
发布时间：2024年07月02日
`LLM应用` `软件工程` `网络安全`
> Is Your AI-Generated Code Really Secure? Evaluating Large Language Models on Secure Code Generation with CodeSecEval
# 摘要
> 大型语言模型（LLM）在代码生成与修复领域取得了显著进展，惠及了从初学者到资深开发者的广泛群体。然而，这些模型在训练过程中使用来自开源平台如GitHub的未净化数据，无形中增加了传播安全漏洞的风险。尽管已有研究探讨了代码LLM的安全性，但全面提升其安全性能仍面临挑战。为此，我们开展了一项全面研究，旨在精确评估并强化代码LLM的安全特性。我们精心设计了CodeSecEval数据集，涵盖44种关键漏洞类型，包含180个样本，为代码生成与修复任务中的模型安全评估奠定了基础。实验表明，现有模型在代码生成与修复过程中往往忽视安全问题，导致易受攻击代码的产生。为此，我们提出了一系列策略，通过利用漏洞感知信息与不安全代码解释，有效缓解安全风险。研究还揭示，某些特定类型的漏洞对模型性能构成较大挑战，影响其在实际应用中的表现。基于这些发现，我们预期本研究将对软件工程领域产生积极影响，推动开发更安全、更可靠的LLM训练与应用方法。
[Arxiv](https://arxiv.org/abs/2407.02395)
==========
# Pelican 通过声明分解和思维程序验证，有效纠正了视觉-LLMs中的幻觉问题。
发布时间：2024年07月02日
`LLM应用` `计算机视觉` `人工智能`
> Pelican: Correcting Hallucination in Vision-LLMs via Claim Decomposition and Program of Thought Verification
# 摘要
> 大型视觉语言模型 (LVLMs) 在处理视觉指令任务时易产生幻觉，影响了其可靠性和实际应用。为此，我们设计了 Pelican 框架，通过声明验证来识别并减少幻觉。Pelican 先将视觉声明拆解为一系列基于一阶谓词的子声明，这些子声明如同计算图的节点，由 (谓词, 问题) 对构成。接着，我们运用 Program-of-Thought 提示技术，生成灵活组合外部工具的 Python 代码来解答这些问题。Pelican 的创新之处在于：(1) 引入中间变量精确锁定对象实例，(2) 共享计算资源以应对子问题，从而进行自适应调整和识别不一致性。最终，我们借助 LLM 的推理能力，通过分析每个子声明中 (问题, 答案) 对的一致性和置信度来验证声明的准确性。实验表明，Pelican 在多个基准测试中将幻觉率降低了 8%-32%，相较于 MMHal-Bench 上的幻觉缓解方法，效果提升了 27%。其他两个基准测试的结果也支持了我们的结论。
[Arxiv](https://arxiv.org/abs/2407.02352)
==========
# 自动化事实核查中的生成式大型语言模型：综述
发布时间：2024年07月02日
`LLM应用` `信息技术`
> Generative Large Language Models in Automated Fact-Checking: A Survey
# 摘要
> 虚假信息在网络上的泛滥已成为社会的一大难题，亟需强有力的信息验证手段。虽然人工核查不可或缺，但海量虚假信息的涌现呼唤自动化解决方案。大型语言模型（LLM）凭借其广博的知识和强大的推理能力，为事实核查提供了新的助力。本篇调查论文深入探讨了LLM在事实核查领域的应用，详细介绍了多种应用方法及微调技巧。通过梳理现有研究，本文旨在深化对LLM在事实核查中作用的认识，并推动该领域的发展。
[Arxiv](https://arxiv.org/abs/2407.02351)
==========
# MORPHEUS 项目旨在通过探索和利用潜在空间，从个性化对话历史中精准建模角色。
发布时间：2024年07月02日
`LLM应用` `人工智能` `对话系统`
> MORPHEUS: Modeling Role from Personalized Dialogue History by Exploring and Utilizing Latent Space
# 摘要
> 个性化对话生成 (PDG) 旨在根据角色特征创造连贯回应。传统方法依赖外部角色数据，常因稀缺和隐私问题受限。我们提出的 MORPHEUS 框架，通过三阶段训练，从对话历史中探索并利用潜在空间的角色信息，创建角色代码本，有效构建角色信息分布，使模型能泛化至新角色，生成个性化对话。实验证明，MORPHEUS 不仅提升角色信息提取，还优化了回应生成，无需外部角色数据，并可高效微调大型语言模型。
[Arxiv](https://arxiv.org/abs/2407.02345)
==========
# RVISA：隐式情感分析中的推理与验证
发布时间：2024年07月02日
`LLM应用` `情感分析` `人工智能`
> RVISA: Reasoning and Verification for Implicit Sentiment Analysis
# 摘要
> 随着细粒度情感分析需求的增加，隐式情感分析在没有明显线索词的表达中面临挑战。本研究提出RVISA框架，结合DO LLM的生成能力和ED LLM的推理能力，通过三跳推理提示法明确提供情感元素，微调ED LLM成为熟练推理器，并设计简单有效的验证机制确保推理可靠性。在两个基准数据集上，我们的方法在ISA性能上达到了最先进水平。
[Arxiv](https://arxiv.org/abs/2407.02340)
==========
# 阿塞拜疆语言的开放基础模型
发布时间：2024年07月02日
`LLM应用` `语言技术` `开源软件`
> Open foundation models for Azerbaijani language
# 摘要
> 随着多语言大型语言模型的兴起，阿塞拜疆语的理解与生成系统得到了发展，但多数生产级系统仍依赖GPT-4等云解决方案。虽然已有尝试为阿塞拜疆语构建开放基础模型，但因缺乏系统性基准测试而未广泛应用。本文致力于推广阿塞拜疆语的开源基础模型，并介绍了大型文本语料库、仅编码器语言模型、评估用标记数据集及全面的开源模型评估。
[Arxiv](https://arxiv.org/abs/2407.02337)
==========
# 实现高效稀疏注意力，关键在于自适应释放令牌。
发布时间：2024年07月02日
`LLM理论` `计算机科学` `人工智能`
> Efficient Sparse Attention needs Adaptive Token Release
# 摘要
> 近年来，大型语言模型在众多文本任务中表现卓越，但其庞大的规模带来了计算和存储上的重大挑战，尤其是在处理 transformer 的关键-值状态时，限制了其广泛应用。为此，我们提出一种自适应资源释放策略，通过轻量级控制器模块实现理想的 top-$K$ 稀疏注意力，保留高权重令牌并重建必要但被丢弃的令牌，以备未来解码所需。实验表明，我们的方法不仅在性能上与全注意力相当，还显著提升了吞吐量，高达 221.8%。复现代码已公开在 https://github.com/WHUIR/ADORE。
[Arxiv](https://arxiv.org/abs/2407.02328)
==========
# 研究音译在非拉丁文字低资源语言上下文学习中的角色
发布时间：2024年07月02日
`LLM应用` `语言技术`
> Exploring the Role of Transliteration in In-Context Learning for Low-resource Languages Written in Non-Latin Scripts
# 摘要
> 仅解码器的 LLM 在高资源语言的多种任务中通过少样本或零样本的 ICL 表现卓越，但其在低资源语言，尤其是非拉丁文字语言上的表现往往不佳。借鉴近期利用音译提升仅编码器模型性能的研究，我们探索音译是否同样能提升非拉丁文字低资源语言的 LLM 性能。为此，我们设计了三种提示模板，分别以原始文字、拉丁文字或两者兼备的形式呈现目标语言文本。在文本分类和序列标注等任务中，我们测试了这些方法在不同大小的 LLM 上的效果。结果显示，音译的效果因任务和模型大小而异，例如，所有模型在序列标注任务中均因音译而显著提升（最高达 25%）。
[Arxiv](https://arxiv.org/abs/2407.02320)
==========
# 探究 LLMs 在语义感知过程挖掘任务中的表现
发布时间：2024年07月02日
`LLM应用` `流程挖掘` `人工智能`
> Evaluating the Ability of LLMs to Solve Semantics-Aware Process Mining Tasks
# 摘要
> 流程挖掘领域近期发现，大型语言模型（LLMs）在处理多种流程挖掘任务上展现出巨大潜力。初期研究显示，LLMs不仅能辅助流程分析，甚至在一定程度上能推理流程运作机制。这一特性暗示LLMs可用于那些需要理解流程行为的任务，如（语义）异常检测和下一活动预测，这些任务均需考虑活动含义及其关联。本文探讨了LLMs在处理这类需语义理解的流程挖掘任务上的能力。不同于多数研究仅测试LLMs的即用性能，我们更系统地评估了LLMs在流程挖掘中的应用，包括通过上下文学习和监督微调获取流程挖掘知识的能力。我们定义了三个依赖流程语义理解的挖掘任务，并为其提供了详尽的基准数据集。实验结果显示：（1）LLMs在未微调情况下难以应对复杂流程挖掘任务，即便提供少量示例亦然；（2）然而，经过针对性微调后，LLMs表现出色，持续优于小型编码器基语言模型。
[Arxiv](https://arxiv.org/abs/2407.02310)
==========
# CFinBench：为大型语言模型打造的中文金融全面基准
发布时间：2024年07月02日
`LLM应用` `人工智能`
> CFinBench: A Comprehensive Chinese Financial Benchmark for Large Language Models
# 摘要
> 大型语言模型（LLMs）在NLP任务上表现卓越，但在金融等特定领域的应用潜力仍待挖掘。本文介绍的CFinBench，是一个专为评估LLMs在中国金融知识掌握程度而设计的全面基准。我们根据中国金融从业者的职业路径，从四个维度构建评估体系：金融学科知识、资格认证、实践操作和法律法规。CFinBench包含99,100道题目，覆盖43个细分领域，题型多样。实验结果表明，GPT4及部分中国定制模型表现突出，最高平均准确率达60.16%，凸显了CFinBench的挑战性。数据集与评估代码已公开，详情访问https://cfinbench.github.io/。
[Arxiv](https://arxiv.org/abs/2407.02301)
==========
# 在无线网络的战略需求规划中，生成式人工智能能否成为频谱和能源的救星？
发布时间：2024年07月02日
`LLM应用` `无线通信` `人工智能`
> Strategic Demand-Planning in Wireless Networks: Can Generative-AI Save Spectrum and Energy?
# 摘要
> 无线通信与人工智能携手共进，彼此促进，共同发展。特别是在6G技术的研发中，这种协同效应尤为显著，6G被设想为AI原生技术。生成式AI（GenAI）作为一种新兴技术，能够创造多样化的输出，如文本、图像和视频，为无线通信带来巨大潜力。传统AI技术主要用于预测、分类和优化，而GenAI则展现出更多可能性。本文探讨了通过需求标签化、塑造和重新安排的战略需求规划，特别是提出GenAI作为推动无线网络需求塑造的有力工具。具体而言，GenAI能够压缩和转换内容，例如将视频转换为文本，从而在多种场景下提升网络性能，包括小区切换、用户关联、负载平衡、干扰管理和灾难管理。这使得GenAI在节能和节省频谱方面发挥作用。随着AI技术的进步，包括大型语言模型和专为AI设计的强大硬件，如AI加速器，通过GenAI进行需求塑造的概念变得更加重要。同时，GenAI在用户终端上的应用也使得这一概念的实施更为直接和可行。
[Arxiv](https://arxiv.org/abs/2407.02292)
==========
# 语言模型面临的多语言电车难题
发布时间：2024年07月02日
`LLM应用` `人工智能伦理` `跨文化研究`
> Multilingual Trolley Problems for Language Models
# 摘要
> 随着 LLM 在现实应用中的普及，探究其在道德困境中的决策变得至关重要。借鉴“道德机器实验”这一跨文化大型研究，我们为 LLM 设计了相同的道德选择挑战。通过将 1K 个道德困境情景翻译成 100 多种语言，我们揭示了 LLM 在各语言中的偏好，并对比了其与 4000 万人类道德判断的异同。结果显示，LLM 在英语、韩语、匈牙利语和中国语中与人类偏好更为契合，而在印地语和索马里语中则稍显偏离。进一步分析 LLM 的道德选择解释，我们发现公平性是 GPT-4 的主要决策依据，而 GPT-3 则更倾向于功利主义。此外，我们还识别出道德决策中存在的“语言不平等”现象，即模型在不同语言中的发展水平差异。
[Arxiv](https://arxiv.org/abs/2407.02273)
==========
# GlyphDraw2：结合扩散模型与大型语言模型，自动创作复杂字形海报。
发布时间：2024年07月02日
`LLM应用`
> GlyphDraw2: Automatic Generation of Complex Glyph Posters with Diffusion Models and Large Language Models
# 摘要
> 海报在营销和广告中至关重要，通过提升视觉传达和品牌曝光，对工业设计贡献巨大。随着可控文本到图像技术的进步，合成图像中的文本渲染成为研究焦点。尽管文本渲染精度提升，端到端海报生成仍待深入探索。这一挑战要求在文本准确性和布局自动化间找到平衡，以产出高分辨率、多宽高比的海报。为此，我们设计了基于对齐学习的三重交叉注意力机制，旨在精细背景中精准渲染海报文本。同时，我们推出了超1024像素的高分辨率数据集，并采用SDXL架构。实验证明，我们的方法能生成背景丰富、细节精致的海报。相关代码将在GitHub上公开。
[Arxiv](https://arxiv.org/abs/2407.02252)
==========
# MIREncoder：一种基于多模态信息检索的预训练嵌入技术，旨在实现性能优化。
发布时间：2024年07月02日
`LLM应用` `高性能计算` `软件工程`
> MIREncoder: Multi-modal IR-based Pretrained Embeddings for Performance Optimizations
# 摘要
> 在高性能计算领域，提升并行任务性能是研究焦点。当前，深度学习在源代码优化中常通过LLVM中间表示（IRs）提取特征。多数研究聚焦特定任务或依赖预设启发式规则。尽管预训练模型在此领域尚属罕见，但其潜力已引发广泛探讨，尤其是模仿大型语言模型（LLMs）的方案，尽管训练成本高昂。本文提出MIREncoder，一种基于多模态IR的自编码器，预训练后可生成嵌入空间，助力机器学习下游任务。多模态策略强化了从可编译程序中提取特征的能力，优化了代码语法、语义和结构的建模。在代码性能优化中，这些特征至关重要。预训练模型隐含支持迁移学习，减少对特定任务模型的依赖。此外，用于性能优化的预训练模型应低开销且易用。基于此，我们设计了一种兼顾代码理解、迁移学习支持及轻量易用性的建模方法。评估表明，该方法在降低开销的同时，性能超越了现有技术。
[Arxiv](https://arxiv.org/abs/2407.02238)
==========
# PromptIntern：在大语言模型微调过程中，通过内部化循环提示，有效节省推理成本。
发布时间：2024年07月02日
`LLM应用` `软件开发`
> PromptIntern: Saving Inference Costs by Internalizing Recurrent Prompt during Large Language Model Fine-tuning
# 摘要
> 大型语言模型（LLM）凭借强大的提示技术，在多种自然语言处理任务中发挥着关键作用。然而，在实际应用中，重复查询的相似提示组件常导致推理时的计算负担加重。尽管现有方法如提示压缩和直接微调试图解决这一问题，但在成本与性能的平衡上，尤其是在复杂的 NL2Code 任务中，仍显不足。为此，我们提出了 PromptIntern 方法，通过渐进式微调将提示知识融入模型参数，模拟人类学习新任务的过程，逐步内化并淘汰提示中的模板和示例。实验结果显示，该方法不仅大幅减少了推理令牌，提升了推理速度，还显著降低了成本。
[Arxiv](https://arxiv.org/abs/2407.02211)
==========
# 大型语言模型中的生成单一文化现象
发布时间：2024年07月02日
`LLM理论` `人工智能` `出版业`
> Generative Monoculture in Large Language Models
# 摘要
> 我们提出“生成单一文化”现象，即大型语言模型在特定任务中输出多样性大幅缩减，如仅产出正面书评，即便书籍评价参差不齐。此现象虽在某些领域提升效率，如代码生成，但在需要多元观点的场合，风险倍增。随着LLM在关键领域的广泛应用，维护输出多样性变得尤为重要，以保障信息的多元性。我们通过实验揭示了这一现象的普遍性，并指出传统对策效果有限。研究还表明，问题的根源可能在于模型的对齐过程，因此，开发能促进多样性的微调方法势在必行。
[Arxiv](https://arxiv.org/abs/2407.02209)
==========
# 利用大型语言模型实现自动适应规则的优化
发布时间：2024年07月02日
`LLM应用` `自动化` `软件工程`
> Automatic Adaptation Rule Optimization via Large Language Models
# 摘要
> 基于规则的自适应方法因其易读性和快速响应而成为自适应的基础。然而，构建高效且稳健的适应规则颇具挑战，因其需在复杂变量空间中寻找最佳设计。本文尝试借助大型语言模型（LLM）的常识与推理能力，将其作为优化工具来构建和优化适应规则。初步实验结果显示，该方法在SWIM中既展现了其有效性，也揭示了其局限性。
[Arxiv](https://arxiv.org/abs/2407.02203)
==========
# 复杂适应系统的数学定义，以交互空间为视角
发布时间：2024年07月02日
`LLM理论` `复杂系统` `数学建模`
> A mathematical definition of complex adaptive system as interaction space
# 摘要
> 我们基于G.K. Zipf的最小努力原则，提出了一种复杂适应系统的数学定义，这一原则在复杂系统建模中广为流传。我们将这种交互空间理论的数学概念称为广义进化原则。借鉴Mandelbrot的思想，我们进一步证明了许多此类系统遵循幂律。通过一个类似Von Thünen的模型，我们展示了复杂适应系统的概念，该模型易于推广至其他复杂系统，并揭示了涌现模式的形成。每个概念均通过丰富的实例进行直观阐述，并辅以现代数学语言的精确表达。
[Arxiv](https://arxiv.org/abs/2407.02181)
==========
# FineCLIPER：一款结合多模态细粒度 CLIP 技术与适应性调整器的系统，专为动态面部表情识别设计。
发布时间：2024年07月02日
`LLM应用` `人工智能` `计算机视觉`
> FineCLIPER: Multi-modal Fine-grained CLIP for Dynamic Facial Expression Recognition with AdaptERs
# 摘要
> 动态面部表情识别（DFER）对理解人类行为至关重要，但现有方法因高质量数据稀缺、面部动态利用不足及表情语义模糊等问题表现受限。为此，我们创新性地提出了“FineCLIPER”框架，该框架通过以下设计提升性能：首先，通过扩展类别标签为正负文本描述，并利用CLIP模型计算跨模态相似性，以更好地区分相似表情；其次，采用分层策略，从视频帧中提取面部掩码和地标，并借助MLLM生成详细面部变化描述，从而有效挖掘视频中的有用线索。此外，通过参数高效微调（PEFT），我们实现了对大型预训练模型（如CLIP）的高效适应。FineCLIPER在多个数据集上，无论是在有监督还是零-shot环境下，均以少量参数达到了顶尖性能，并通过分析和消融研究进一步证实了其有效性。
[Arxiv](https://arxiv.org/abs/2407.02157)
==========
# LlamAr 与 GemmAr：借助阿拉伯语指令调优提升大型语言模型性能
发布时间：2024年07月02日
`LLM应用` `阿拉伯语`
> LlamAr & GemmAr: Enhancing LLMs Through Arabic Instruction-Tuning
# 摘要
> 大型语言模型（LLMs）在自然语言处理（NLP）领域，尤其是在英语方面，展现了显著的影响力。这些模型不仅理解力强，还能生成逼真的文本。然而，模型的成功极大地依赖于高质量的指令数据集，这些数据集包含了详尽的任务描述和相应的回答，对训练模型应对多样化的提示至关重要。尽管在英语中表现出色，但由于缺乏针对阿拉伯语的微调数据集，模型在阿拉伯语任务上往往表现不佳。为此，我们推出了InstAr-500k，一个全新的阿拉伯语指令数据集，涵盖了多个领域和指令类型。通过在多个下游任务上微调Llama-3-8B-Instruct和Gemma-7B-IT这两个开源模型，我们评估了该数据集的效果，并实现了功能的显著提升。评估结果显示，我们的微调模型在阿拉伯语NLP基准测试中达到了顶尖水平，凸显了该数据集在提升阿拉伯语模型性能方面的强大作用。通过提供丰富的资源，我们的数据集有效缩小了英语与阿拉伯语模型之间的性能差距，并在此基础上，我们进一步开发了LlamAr-8B和GemmAr-7B这两款专为阿拉伯语NLP任务优化的顶尖模型。
[Arxiv](https://arxiv.org/abs/2407.02147)
==========
# 通过在线策略与主动学习构建经济高效的代理奖励模型
发布时间：2024年07月02日
`LLM应用` `人工智能` `机器学习`
> Cost-Effective Proxy Reward Model Construction with On-Policy and Active Learning
# 摘要
> 人类反馈强化学习（RLHF）在大型语言模型中应用广泛，但其效果受限于人类偏好数据量。传统方法依赖离线数据集，而新方法转向在线模式，利用少量标记数据和大量未标记提示，通过自我生成响应和高品质反馈迭代构建新数据。然而，现有在线算法在策略更新时仍依赖给定反馈预言机进行偏好标记，导致高昂的专家查询成本。我们率先探索了成本效益高的代理奖励预言机构建策略，以在有限数据和预算下进行偏好或奖励标记。我们的创新包括：策略内查询避免数据问题，以及主动学习选择关键数据。通过这些方法，我们用最少专家数据训练评估模型，有效标记九倍偏好对，用于RLHF训练。例如，使用DPO的模型在多个测试中平均提升约1%，仅消耗1.7K查询成本。我们的方法与其他专家查询策略正交，有望进一步降低成本。
[Arxiv](https://arxiv.org/abs/2407.02119)
==========
# 跨越语言界限：大规模实施跨语言持续预训练
发布时间：2024年07月02日
`LLM理论` `人工智能` `计算机科学`
> Breaking Language Barriers: Cross-Lingual Continual Pre-Training at Scale
# 摘要
> 近年来，大型语言模型（LLM）在迈向人工通用智能方面取得了显著进展。然而，从头开始训练这些模型需要庞大的计算资源和海量文本数据。本文探索了一种替代方法：通过从现有预训练 LLM 中不断预训练（CPT）来构建新语言的 LLM，而非使用随机初始化参数。通过在 40 种不同模型大小（从 40M 到 5B 参数）上的并行实验，我们发现：1) CPT 收敛更快，并以可扩展方式节省大量资源；2) CPT 遵循 Hoffmann 等人（2022）提出的扩展缩放定律，包含联合数据-参数缩放项；3) 根据我们估计的缩放因子，CPT 的计算最优数据-参数分配显著不同；4) 大规模迁移的有效性受训练持续时间和语言特性影响，而对数据重放具有鲁棒性，这是一种有效缓解 CPT 中灾难性遗忘的方法。我们希望这些发现能为研究社区提供关于大规模 LLM 可迁移性的更深入见解。
[Arxiv](https://arxiv.org/abs/2407.02118)
==========
# 是助手还是促进者？探讨角色对语言模型行为的影响。
发布时间：2024年07月02日
`LLM应用` `人工智能`
> Helpful assistant or fruitful facilitator? Investigating how personas affect language model behavior
# 摘要
> 为了个性化和引导大型语言模型的生成内容，一种有效方法是赋予特定角色，如“有帮助的助手”或“教师”。本文深入探讨了这些角色如何影响模型的多方面行为。我们为七个大型语言模型分配了162个角色，涵盖性别、性取向和职业等12个类别。通过回答涵盖数学、历史等客观问题及信仰、价值观等主观问题的五个数据集，我们分析了角色对模型输出的影响。此外，我们通过对比“有帮助的助手”的30种不同表述和无角色的基线设置，发现角色不仅增加了输出的多样性，某些角色行为特征还具有跨模型的普遍性。
[Arxiv](https://arxiv.org/abs/2407.02099)
==========
# GPTCast：一款专为降水实时预报设计的天气语言模型
发布时间：2024年07月02日
`LLM应用` `气象学`
> GPTCast: a weather language model for precipitation nowcasting
# 摘要
> GPTCast 是一种创新的深度学习方法，用于基于雷达的降水集合临近预报，灵感源自大型语言模型的进步。我们利用 GPT 模型通过标记化的雷达图像学习降水的时空动态。标记器采用量化变分自编码器，并引入一种新的重建损失，专门针对降水的偏斜分布，确保对高降雨率的准确重建。该方法不仅生成逼真的集合预报，还提供精确的不确定性估计。模型训练完全基于数据，无需随机性，所有变异性均从数据中学习并在推理时展现，以生成集合。通过在意大利北部艾米利亚-罗马涅地区 6 年的雷达数据集上训练和测试，GPTCast 展现出超越现有集合外推方法的优越性能。
[Arxiv](https://arxiv.org/abs/2407.02089)
==========
# Theseus 项目致力于为大型语言模型优化晶圆级芯片设计，提升探索效率。
发布时间：2024年07月02日
`LLM应用` `半导体` `人工智能`
> Theseus: Towards High-Efficiency Wafer-Scale Chip Design Space Exploration for Large Language Models
# 摘要
> 随着大型语言模型（LLM）的兴起，对计算能力、内存和通信带宽的需求激增，远超芯片设计的进步。为此，设计师们正致力于开发晶圆级芯片（WSCs），以突破单芯片的性能极限。现有研究表明，WSCs在支持LLM方面具有巨大潜力。然而，探索WSCs的早期设计空间充满挑战，涉及复杂的设计选项、耗时的评估过程和低效的探索策略。为此，我们推出了Theseus框架，旨在高效探索WSCs的设计空间。我们结合WSCs的特性，构建了多约束的设计空间，并采用多保真贝叶斯优化，以加速设计探索。评估显示，Theseus找到的最优设计在LLM训练中性能和能效分别提升高达62.8%/73.7%和38.6%/42.4%，在推理任务中性能和能效更是分别提升至23.2倍和15.7倍。此外，我们还通过案例研究，深入分析了WSCs的设计权衡，为未来LLM的WSC设计提供了宝贵见解。
[Arxiv](https://arxiv.org/abs/2407.02079)
==========
# 利用大型视觉-语言模型，我们致力于假新闻的检测与操纵行为的推理。
发布时间：2024年07月02日
`LLM应用` `信息安全`
> Fake News Detection and Manipulation Reasoning via Large Vision-Language Models
# 摘要
> 随着媒体操纵的泛滥，假新闻已成为信息安全的一大隐患。学术界对假新闻检测的关注日益增加。传统模型虽在真伪分类上表现优异，但基于新闻内容推理伪造细节的能力尚待挖掘。此外，因缺乏外部知识，现有方法在处理事实相关新闻时的表现存疑，其实际应用效果不明。为此，我们提出“操纵推理”这一新课题，旨在通过新闻内容揭示操纵行为。为此，我们创建了以人为本、事实关联为核心的假新闻基准（HFFN），并详细标注。HFFN涵盖四个现实领域，通过三种操纵手法生成假新闻样本。我们还设计了多模态新闻检测与推理模型（M-DRUM），不仅能判断新闻真伪，还能分析潜在操纵。在特征提取上，我们采用交叉注意力机制，从多模态输入中提炼精细特征。推理方面，则依托大型视觉语言模型（LVLM）进行事实推理。通过两阶段训练框架，我们有效提升了模型的识别与推理能力。实验证明，M-DRUM在假新闻检测领域超越了现有顶尖模型，包括GPT-4和LLaVA。
[Arxiv](https://arxiv.org/abs/2407.02042)
==========
# 大型语言模型文本标注中的提示稳定性评分
发布时间：2024年07月02日
`LLM应用` `文本标注` `软件开发`
> Prompt Stability Scoring for Text Annotation with Large Language Models
# 摘要
> 研究人员正越来越多地利用语言模型进行文本标注，这些方法仅依赖于一个提示来指导模型输出。然而，提示设计的微小变化可能影响输出的可重复性，从而引发对分类程序可复制性的质疑。为应对这一挑战，我们提出了一种通用框架，通过调整传统可靠性评分方法来评估提示稳定性，并命名为提示稳定性得分 (PSS)。我们开发的 Python 包 PromptStability 可用于此评估。通过分析六个数据集和十二个结果，我们对超过 15 万行数据进行了分类，旨在揭示提示稳定性的不足并展示该包的实用性。最后，我们为应用研究人员提供了最佳实践建议。
[Arxiv](https://arxiv.org/abs/2407.02039)
==========
# 破除偏见，搭建沟通之桥：利用接触假设评估并减轻 LLMs 中的社会偏见
发布时间：2024年07月02日
`LLM应用` `社会心理学` `人工智能`
> Breaking Bias, Building Bridges: Evaluation and Mitigation of Social Biases in LLMs via Contact Hypothesis
# 摘要
> 大型语言模型（LLM）不仅反映训练数据中的偏见，还加剧了社会刻板印象和不平等。我们借鉴社会心理学的接触假设，探索其在减少LLM偏见方面的应用。通过模拟不同形式的社会接触，我们评估了这些接触对模型偏见的影响，类似于群体间互动在现实世界中减少偏见的效果。我们精心设计了包含108,000个提示的数据集，涵盖13个社会偏见维度，用于评估LLaMA 2、Tulu和NousHermes三个模型。我们创新性地提出了社会接触去偏见（SCD）技术，通过无偏见的响应对模型进行调优。研究显示，尽管LLM在接触探测下表现出偏见，但通过我们的SCD策略，一个周期的调优即可显著减少高达40%的偏见。相关代码和数据已公开在https://github.com/chahatraj/breakingbias。
[Arxiv](https://arxiv.org/abs/2407.02030)
==========
# 为何 in-context learning 有时会失效？探讨其在开放与封闭问题上的表现。
发布时间：2024年07月02日
`LLM理论` `科学研究`
> Why does in-context learning fail sometimes? Evaluating in-context learning on open and closed questions
# 摘要
> 我们评估了in-context learning在开放与封闭问题中的表现，考虑了任务的新颖性和难度。为此，我们设计了一个包含复杂科学问题的创新基准，每个问题都附有不同相关性的背景信息。令人意外的是，与主题更契合的背景信息并不总是优于相关性较低的背景。这一现象在开放性问题和高难度或新颖问题中尤为显著。这一发现凸显了大型语言模型在处理不同类型问题时的根本差异，并强调了对in-context learning进行更全面评估的必要性。同时，这也引发了一个新问题：如何在检索增强生成（RAG）系统中为大型语言模型选择最优背景信息。我们的研究暗示，这一问题的答案可能高度依赖于具体应用，并可能受问题格式、难度感知以及信息的新颖性或流行度等因素影响。
[Arxiv](https://arxiv.org/abs/2407.02028)
==========
# ViG-Bias：通过视觉基础技术发现并缓解偏见
发布时间：2024年07月02日
`LLM应用` `计算机视觉` `人工智能`
> ViG-Bias: Visually Grounded Bias Discovery and Mitigation
# 摘要
> 机器学习模型在关键决策中的广泛应用，使得偏差的发现与缓解变得尤为重要。然而，偏差背后的原因往往隐藏在难以察觉的虚假相关性中，不易识别。传统方法通过分析模型在具有共同属性（如性别或种族）的子组中的表现来进行偏差审计。但视觉识别系统的失败模式往往难以预知。近期研究提出利用大型视觉语言模型，通过提取跨模态嵌入和生成文本描述来发现模型表现不佳的子组。我们提出，结合视觉解释（如热图）能有效提升偏差发现与缓解框架的性能。为此，我们开发了视觉基础偏差发现与缓解技术（ViG-Bias），该技术简单高效，可集成于多种框架，显著提升性能。在多个挑战性数据集上的全面评估表明，视觉解释的引入显著增强了现有技术，如 DOMINO、FACTS 和 Bias-to-Text。
[Arxiv](https://arxiv.org/abs/2407.01996)
==========
# 你的大型语言模型是真才实学，还是仅仅在选择题上作弊？
发布时间：2024年07月02日
`LLM应用` `人工智能`
> Is Your Large Language Model Knowledgeable or a Choices-Only Cheater?
# 摘要
> 最新研究发现，大型语言模型 (LLMs) 能仅凭选项解答多项选择题，但这会否导致其在 MCQA 排行榜上的名次主要取决于仅选项的能力？为探究此问题，我们运用图挖掘技术，从现有 MCQA 数据集中提取对比集，以检测 LLMs 是否过度依赖仅选项的捷径。与以往依赖人工标注或可能偏差的模型生成数据不同，我们在 UnifiedQA 上构建了一个包含 820 个问题的对比集，该数据集涵盖六个高仅选项准确性的常识推理数据集。经过验证，我们测试了 12 个 LLMs，结果显示这些模型在同时提供问题和选项时并未过度依赖仅选项捷径。因此，尽管 MCQA 对高仅选项准确性敏感，我们认为 LLMs 在 MCQA 排行榜上的高排名并非仅因它们能利用仅选项的捷径。
[Arxiv](https://arxiv.org/abs/2407.01992)
==========
# SADL：组合视觉问答中一种高效的上下文学习策略
发布时间：2024年07月02日
`LLM应用` `计算机视觉` `人工智能`
> SADL: An Effective In-Context Learning Method for Compositional Visual QA
# 摘要
> 大型视觉-语言模型（LVLMs）在视觉问答（Visual QA）中展现了一种创新的上下文学习能力。通过少量图像-问题-答案三元组的演示，LVLMs能够识别潜在模式，并将这些隐性知识应用于回答未见图像的新问题，无需昂贵的监督微调。然而，设计针对组合性问题的有效视觉-语言提示仍是一个挑战。由于视觉内容与语言结构存在差异，仅依赖语言的ICL技术可能不适用。为此，本文提出了SADL，一个结合采样、深思和伪标签的视觉-语言提示框架。该框架通过从训练数据中选取语义相近的图像-问题对，分解复杂问题为子问题，并逐步生成伪标签，以应对视觉问答任务。在OpenFlamingo平台上对GQA、GQA-OOD、CLEVR和CRIC等数据集的实验表明，采样、问题分解和标签配对是关键因素。这些发现为视觉-语言领域的ICL提供了新的视角。
[Arxiv](https://arxiv.org/abs/2407.01983)
==========
# 每个边界框等同于一个令牌，通过在大规模语言模型中交错布局与文本，我们实现了对文档的深入理解。
发布时间：2024年07月02日
`LLM应用` `文档处理` `视觉问答`
> A Bounding Box is Worth One Token: Interleaving Layout and Text in a Large Language Model for Document Understanding
# 摘要
> 近期研究显示，结合OCR文本和空间布局的LLMs在文档理解任务中表现出色。然而，现有方法在整合这两者时存在不足，如产生冗长文本或未能充分发挥LLMs的自回归优势。为此，我们提出了LayTextLLM，它通过将每个边界框映射为一个嵌入并与文本交错，巧妙规避了长序列问题，同时强化了自回归特性。LayTextLLM不仅优化了布局与文本的交互，还在KIE和VQA任务中展现了显著的性能提升。基准测试表明，与现有最先进模型相比，LayTextLLM在KIE任务上提升了27.0%，在VQA任务上提升了24.1%，同时在基于OCR的LLMs的KIE任务上也有15.5%的进步。
[Arxiv](https://arxiv.org/abs/2407.01976)
==========
# MeMemo：实现设备端检索增强，助力私密且个性化的文本生成
发布时间：2024年07月02日
`RAG` `软件开发` `网络安全`
> MeMemo: On-device Retrieval Augmentation for Private and Personalized Text Generation
# 摘要
> RAG 通过从外部知识库检索信息，有效解决了 LLM 的幻觉问题。但现有方法依赖专用服务器，限制了其在高度隐私敏感领域的应用。为此，我们推出了 MeMemo，首个开源 JavaScript 工具包，将 HNSW 技术引入浏览器环境。借助现代 Web 技术，MeMemo 利用客户端硬件，支持在浏览器中高效处理高维向量搜索，为私密个性化内容创作和交互式原型设计等新机遇铺平道路。MeMemo 已在 GitHub 上发布，我们同时探讨了设备上密集检索的机遇与挑战。
[Arxiv](https://arxiv.org/abs/2407.01972)
==========
# 大型语言模型中的判别推理助力法律判决预测
发布时间：2024年07月02日
`LLM应用`
> Enabling Discriminative Reasoning in Large Language Models for Legal Judgment Prediction
# 摘要
> 法律判决预测对提升司法效率至关重要。我们发现，大型语言模型（LLM）在理解案件复杂性和区分相似指控方面存在不足。为此，我们设计了Ask-Discriminate-Predict（ADAPT）框架，模拟人类司法推理过程，通过分解案件事实、区分指控并预测判决，提升LLM在法律领域的应用效果。通过多任务合成轨迹的微调，我们进一步优化了ADAPT框架，使其在处理复杂案件时表现更佳。实验结果显示，ADAPT框架在法律判决预测中展现出显著优势，特别是在应对复杂指控时。
[Arxiv](https://arxiv.org/abs/2407.01964)
==========
# 本研究旨在构建一个无监督的多语言电话通话说话人日志系统，该系统结合了预训练的 Whisper 模型与稀疏自编码器的混合技术。
发布时间：2024年07月02日
`LLM应用` `语音识别`
> Towards Unsupervised Speaker Diarization System for Multilingual Telephone Calls Using Pre-trained Whisper Model and Mixture of Sparse Autoencoders
# 摘要
> 当前的说话人日志系统依赖于大量手动标注数据，这在实际应用中既耗时又困难。此外，语言特定的限制大大限制了这些系统在多语言环境中的应用。为此，我们提出了一种基于聚类的多语言电话说话人日志系统，该系统支持多种语言，无需大规模标注数据，通过多语言Whisper模型提取说话人特征，并采用创新的Mix-SAE网络架构进行无监督聚类。实验表明，Mix-SAE在效率上超越了其他自编码器聚类方法。我们的系统不仅在有限标注数据下展现出巨大潜力，还能有效融入复杂度低的多任务语音分析系统，涵盖语音转文本、语言识别和说话人日志等功能。
[Arxiv](https://arxiv.org/abs/2407.01963)
==========
# S2D：通过排序推测解码，提升嵌套大型语言模型的部署效率
发布时间：2024年07月02日
`LLM应用` `人工智能` `云计算`
> S2D: Sorted Speculative Decoding For More Efficient Deployment of Nested Large Language Models
# 摘要
> 自回归大型语言模型的部署成本高昂，且随着模型规模的扩大，相关成本愈发显著。为此，业界提出了多种方法来加速令牌生成并降低成本。其中，推测解码 (SD) 通过并行验证多个令牌并利用辅助的小型草稿模型生成可能的令牌，成为加速 LLM 解码过程的佼佼者。通常，一个草稿模型服务于一个特定的目标模型，但现实中 LLM 种类繁多，我们可能需要同时处理多个目标模型。这种情况下，选择合适的草稿模型变得复杂，而搜索或定制草稿模型可能进一步增加部署成本。本文中，我们首先提出了一种新颖的多目标场景，用于草稿模型的快速推理部署。接着，我们介绍了一种更高效的排序推测解码机制，该机制在多目标环境中表现优于传统基准。我们在包括 Vicuna 7B、13B 和 LLama Chat 70B 在内的多种模型上验证了我们的方法，结果显示，我们的草稿模型在同时处理多个目标模型时，性能超越了基准。
[Arxiv](https://arxiv.org/abs/2407.01955)
==========
# CatMemo在FinLLM挑战中，通过数据融合技术，优化金融应用中的大型语言模型微调。
发布时间：2024年07月02日
`LLM应用`
> CatMemo at the FinLLM Challenge Task: Fine-Tuning Large Language Models using Data Fusion in Financial Applications
# 摘要
> 在 NLP 社区中，LLM 在金融分析领域的应用备受瞩目。本文针对 IJCAI-2024 FinLLM 挑战赛，探讨了 LLM 在金融分类、文本摘要和股票交易三大关键领域的应用。我们选用 Llama3-8B 和 Mistral-7B 模型，通过 PEFT 和 LoRA 技术进行精细调整，并融合任务 1 与任务 2 的数据集以增强性能。我们的方法全面整合，旨在展示 LLM 在处理复杂金融任务时，如何提升准确性与决策力。
[Arxiv](https://arxiv.org/abs/2407.01953)
==========
# 借助大型语言模型与医学知识，我们致力于提升放射学文本的表达力。
发布时间：2024年07月02日
`LLM应用` `人工智能`
> Extracting and Encoding: Leveraging Large Language Models and Medical Knowledge to Enhance Radiological Text Representation
# 摘要
> 在医学等专业领域，由于缺乏专家注释，表示学习的进步面临挑战。为此，我们设计了一个两阶段框架，从放射学报告中提取高质量事实，以优化文本编码器的性能。首先，我们利用LLM从精选数据集中提取事实。接着，我们基于BERT模型，通过特定目标函数微调，引入CXRFE编码器。此外，我们还开发了CXRFEScore度量，用于评估胸部X射线文本生成系统。实验表明，我们的方法在多个任务中超越了现有技术，且CXRFEScore比传统度量更稳健有效。项目代码已公开在\url{https://github.com/PabloMessina/CXR-Fact-Encoder}。
[Arxiv](https://arxiv.org/abs/2407.01948)
==========
# RankRAG：整合上下文排序与检索增强生成于大型语言模型中
发布时间：2024年07月02日
`RAG` `生物医学` `人工智能`
> RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs
# 摘要
> 我们提出了一种名为 RankRAG 的创新指令微调框架，该框架使单个 LLM 能够同时进行上下文排序和答案生成，显著提升了 RAG 的性能。通过在训练中融入少量排序数据，RankRAG 不仅超越了专门优化的排序模型，还在生成任务上表现卓越，击败了包括 GPT-4 在内的多个顶尖模型。特别是在知识密集型和生物医学领域的基准测试中，RankRAG 展现了其强大的泛化能力，无需特定领域的微调即可与 GPT-4 媲美。
[Arxiv](https://arxiv.org/abs/2407.02485)
==========
# MMedAgent：掌握医疗工具的多模态学习代理
发布时间：2024年07月02日
`Agent` `人工智能`
> MMedAgent: Learning to Use Medical Tools with Multi-modal Agent
# 摘要
> 尽管多模态大型语言模型 (MLLMs) 取得了成功，但其通用性有限，与专业模型相比常显不足。为此，基于 LLM 的代理应运而生，它们能根据用户输入选择合适的专业模型作为工具。然而，这一进步在医学领域尚未深入探索。为此，本文首次推出了专为医学领域设计的代理——**M**ulti-modal **Med**ical **Agent** (MMedAgent)。我们构建了一个包含六种医疗工具解决七项任务的指令调优数据集，使 MMedAgent 能精准选择工具。实验证明，MMedAgent 在多种医疗任务中的表现超越了顶尖的开源方法和 GPT-4o 等闭源模型，且在更新和集成新工具方面极为高效。
[Arxiv](https://arxiv.org/abs/2407.02483)
==========
# MInference 1.0 通过动态稀疏注意力机制，加速了长上下文大型语言模型的预填充过程。
发布时间：2024年07月02日
`LLM应用` `人工智能` `高性能计算`
> MInference 1.0: Accelerating Pre-filling for Long-Context LLMs via Dynamic Sparse Attention
# 摘要
> 大型语言模型（LLM）的推理计算挑战，尤其是在提示长度不断增加的情况下，仍是广泛部署的重大障碍。由于注意力计算的二次复杂性，处理1M令牌的提示在单个A100 GPU上需时30分钟。为解决现有方法在长上下文LLM中难以保持准确性与效率的问题，我们推出了MInference，一种专为加速长序列预填充设计的稀疏计算方法。我们识别了三种独特的注意力矩阵模式——A形、垂直斜线和块稀疏，这些模式可用于GPU上的高效稀疏计算。我们离线确定每个注意力头的最佳模式，并在推理时动态构建稀疏索引。通过这些模式和索引，我们利用优化的GPU内核进行高效稀疏注意力计算，显著减少长上下文LLM预填充阶段的延迟。我们的技术可直接应用于现有LLM，无需修改预训练设置或额外微调。通过在多个下游任务和模型中进行评估，我们证明了MInference能有效减少A100上的预填充推理延迟高达10倍，同时保持准确性。代码已公开，可访问https://aka.ms/MInference获取。
[Arxiv](https://arxiv.org/abs/2407.02490)
==========
# Neurocache：实现长距离语言建模的高效向量检索技术
发布时间：2024年07月02日
`LLM应用` `人工智能` `软件开发`
> Neurocache: Efficient Vector Retrieval for Long-range Language Modeling
# 摘要
> 本文提出 Neurocache，一种利用外部向量缓存存储模型历史状态，从而扩展 LLM 上下文大小的创新方法。Neurocache 采用高效的 kNN 算法，快速检索并整合相关历史状态至注意力机制中，从而实现以下优化：(1) 压缩状态存储，减小缓存空间；(2) 单次检索操作每令牌，加速推理过程；(3) 扩展检索范围至邻近状态，提升语言模型及下游任务准确性。实验证明，无论是全新训练还是预训练模型（如 Llama2-7B 和 Mistral-7B），Neurocache 均能显著提升性能。此外，与传统文本检索相比，Neurocache 在单文档问答和少样本学习任务中表现更优。源代码已公开于：https://github.com/alisafaya/neurocache
[Arxiv](https://arxiv.org/abs/2407.02486)
==========
# 探究多模态LLM中的对齐机制：一项深入研究
发布时间：2024年07月02日
`LLM应用` `人工智能` `计算机视觉`
> Understanding Alignment in Multimodal LLMs: A Comprehensive Study
# 摘要
> 偏好对齐在提升大型语言模型性能中扮演着关键角色，但在多模态大型语言模型中的应用仍待深入探索。多模态模型在图像理解任务中同样面临幻觉挑战，不仅可能因错误信息，还可能因与图像不符的回应。对齐的主要目标之一是使模型回应更贴合图像信息。近期研究引入了多种对齐方法和数据集，但各数据集和方法的差异使得具体改进因素尚不明朗。本文中，我们深入分析了多模态模型中偏好对齐的各个方面，分类并探讨了离线和在线对齐算法的结合效果，回顾了多模态偏好数据集的构建细节及其对性能的影响。基于此，我们创新性地提出了无需额外注释或外部模型的偏差驱动的幻觉采样方法，该方法在多模态模型性能上表现出色，与现有对齐技术相媲美。
[Arxiv](https://arxiv.org/abs/2407.02477)
==========
# 开放场景图助力开放世界中的对象目标导航
发布时间：2024年07月02日
`Agent` `机器人` `人工智能`
> Open Scene Graphs for Open World Object-Goal Navigation
# 摘要
> 我们如何打造能在开放世界中进行语义导航的机器人，比如在新环境中寻找特定物品？基础模型虽具备丰富的知识和泛化能力，但还需一个恰当的场景表示来构建完整的机器人系统。我们采用 Open Scene Graphs (OSGs)，这是一种结合拓扑与语义的表示方法，能有效组织并保留开放场景信息，并可根据不同环境灵活调整。我们将基础模型与 OSGs 融合进 OpenSearch 系统，使其能在自然语言指引下，搜索任意指定物品，并在多变的环境和实体中实现零-shot 泛化。OSGs 与大型语言模型的结合，提升了对象目标导航的鲁棒性，超越了现有 LLM 方法。通过模拟与实境测试，我们证实了 OpenSearch 在多样环境、机器人及新指令中的广泛适用性。
[Arxiv](https://arxiv.org/abs/2407.02473)
==========
# 利用生成式AI评估信息检索的可靠置信区间
发布时间：2024年07月02日
`LLM应用` `信息检索` `数据评估`
> Reliable Confidence Intervals for Information Retrieval Evaluation Using Generative A.I
# 摘要
> 传统的信息检索系统评估因依赖人类专家的手动标注而成本高昂。随着大型语言模型（LLMs）的发展，我们能在低成本下大规模生成相关性标注，有望降低评估成本，惠及众多低资源应用。然而，这些生成的标注存在系统性错误，直接用于评估会导致结果不可靠。为此，我们提出了两种方法：预测驱动推理和一致性风险控制，利用计算机生成的标注为评估指标设定可靠的置信区间（CIs）。这些方法仅需少量可靠标注，即可统计分析生成标注的错误，进而为评估指标设定具有强理论保证的CIs。与传统方法不同，我们的一致性风险控制方法专为排名指标设计，能根据每个查询和文档灵活调整CIs。实验表明，我们的CIs能更准确地捕捉评估中的方差和偏差。我们期待这些贡献能为众多IR应用带来可靠的评估。
[Arxiv](https://arxiv.org/abs/2407.02464)
==========
# 通过多模态大型语言模型提升视觉叙事效果
发布时间：2024年07月02日
`LLM应用`
> Improving Visual Storytelling with Multimodal Large Language Models
# 摘要
> 视觉叙事，这一新兴领域融合图像与叙事，旨在编织引人入胜、情境丰富的故事。然而，视觉与文本信息的复杂对齐，使得创造连贯且情感共鸣的视觉故事颇具挑战。本文创新性地结合大型语言模型（LLMs）与视觉-语言模型（LVLMs），并引入指令调优，以应对这一难题。我们构建了一个包含多样化视觉故事的详尽数据集，辅以多模态元素。通过监督学习与强化学习的协同微调，我们的模型叙事生成能力得以显著提升。GPT-4的定量评估与人类定性评价双重验证，我们的方法在叙事连贯性、相关性、情感深度及整体质量上均超越现有模型。这一成果不仅彰显了指令调优的效力，更揭示了LLMs/LVLMs在视觉叙事领域的广阔前景。
[Arxiv](https://arxiv.org/abs/2407.02586)
==========
# 基于模型增强的 LLM 驱动，对 VPA 应用进行 VUI 测试
发布时间：2024年07月02日
`LLM应用` `智能家居` `语音助手`
> Model-Enhanced LLM-Driven VUI Testing of VPA Apps
# 摘要
> 围绕语音助手（如Amazon Alexa）的繁荣生态系统催生了大量VPA应用。尽管这些应用广受欢迎，但其开放性和易获取性也引发了安全、隐私和质量方面的担忧。为此，研究者提出了多种测试方法来系统评估VPA应用。针对VPA应用缺乏可视界面的特点，测试中采用了聊天机器人式和基于模型的两种策略。然而，前者在扩展搜索空间上缺乏有效指导，后者则在构建精确全面的行为模型上存在局限。为此，我们推出了Elevate框架，它结合了大型语言模型（LLM）的强大自然语言处理能力，以弥补基于模型测试中的语义信息损失。Elevate通过引导LLM从应用输出中提取状态并生成上下文相关输入，逐步构建行为模型，从而提高发现新状态的可能性。通过创新地将行为模型融入提示和基于上下文选择输入，Elevate有效连接了LLM与行为模型。在4,000个真实Alexa技能的测试中，Elevate相较于Vitas在状态空间覆盖率上提升了15%，并在效率上取得了显著进步。
[Arxiv](https://arxiv.org/abs/2407.02791)
==========
# 从 52B 到 1T：Tele-FLM 系列中的经验启示
发布时间：2024年07月02日
`LLM理论` `人工智能` `机器学习`
> 52B to 1T: Lessons Learned via Tele-FLM Series
# 摘要
> 大型语言模型 (LLM) 是通往通用人工智能的关键进展。随着模型规模的扩大，学术界对超过 500 亿参数的 LLM 研究日益深入。本报告基于我们与 Tele-FLM（FLM-2）的合作，该模型拥有 520 亿参数。我们探讨了两个核心领域：首先，我们发现 Tele-FLM-52B 上的监督微调 (SFT) 支持“少即是多”的数据构建策略；其次，我们展示了如何从 520 亿逐步扩展到 1 万亿参数的最佳实践。为推动研究，我们将公开 Tele-FLM-1T 模型。
[Arxiv](https://arxiv.org/abs/2407.02783)
==========
# 知识图谱嵌入的可裁剪性
发布时间：2024年07月02日
`LLM应用` `人工智能` `知识图谱`
> Croppable Knowledge Graph Embedding
# 摘要
> 知识图谱嵌入（KGE）是知识图谱服务于多种AI任务的常用技术。然而，每当需要新的嵌入维度时，就必须从头开始训练新的KGE模型，这不仅增加了成本，还限制了KGE的效率和灵活性。为此，我们推出了MED框架，只需一次训练，即可生成适用于不同维度需求的可裁剪KGE模型。MED框架内含相互学习、进化改进和动态损失权重三大机制，确保了模型的高效性和灵活性。实验证明，MED在多个数据集和实际应用场景中表现出色，且能无缝扩展至BERT等语言模型。
[Arxiv](https://arxiv.org/abs/2407.02779)
==========
# 大型语言模型、物理建模与实验测量，三者共同构成了聚合物特性数据稀缺学习的核心。
发布时间：2024年07月02日
`LLM应用` `材料科学` `物理学`
> Large language models, physics-based modeling, experimental measurements: the trinity of data-scarce learning of polymer properties
# 摘要
> 大型语言模型 (LLM) 在材料建模领域展现出高效且精准的潜力，但其庞大的参数规模要求海量数据以确保准确性并防止过拟合。然而，实验数据的获取往往受限且成本高昂，难以满足微调需求。为此，我们设计了一套基于物理学的训练流程，专门应对数据稀缺的挑战。核心在于一个基于物理的建模框架，它能生成大量合成数据，确保 LLM 在微调前处于与物理事实一致的初始状态。我们的训练框架分为两个阶段：首先，利用大量但精度稍逊的合成数据进行监督预训练；其次，用有限的实验数据对预训练模型进行微调。通过研究聚合物可燃性指标（其中锥形量热仪数据稀缺），我们实证了监督预训练对于获得精准微调 LLM 的关键作用。
[Arxiv](https://arxiv.org/abs/2407.02770)
==========
# 通过学习简化，我们致力于提升大型语言模型在处理结构化数据时的表现。
发布时间：2024年07月02日
`LLM应用` `人工智能` `数据分析`
> Learning to Reduce: Towards Improving Performance of Large Language Models on Structured Data
# 摘要
> 尽管大型语言模型 (LLM) 在众多下游任务中表现出色，但在结构化数据推理方面仍面临挑战。本文提出的“学习去减少”框架，通过策略学习微调语言模型，有效简化了输入数据，不仅性能卓越，还展现了跨数据集的泛化能力。此外，该框架微调的模型在长上下文的表格问答任务中表现尤为出色，为 LLM 的应用拓展了新的可能。
[Arxiv](https://arxiv.org/abs/2407.02750)
==========
# 比较 DSL 代码生成的两种方法：微调与优化检索增强
发布时间：2024年07月02日
`RAG` `软件开发` `人工智能`
> A Comparative Study of DSL Code Generation: Fine-Tuning vs. Optimized Retrieval Augmentation
# 摘要
> 近年来，随着大型语言模型（LLM）的发展，自然语言到代码生成取得了显著进步。尽管在C、C++和Python等通用语言的生成方面有了显著提升，LLM在处理特定领域语言（DSL）中的自定义函数名称时仍显不足，导致幻觉率和语法错误增加，尤其是对于那些包含大量自定义函数名称的DSL。此外，函数名称的不断更新也带来了挑战，要求LLM保持最新状态。本文中，我们针对使用检索增强生成（RAG）与LLM进行DSL生成的优化方法进行了探讨，并通过消融研究比较了这些策略的效果。我们创建了一个包含大约700个公共领域API的自动化任务的DSL训练和测试数据集，并使用该训练集对Codex模型进行了微调。结果表明，微调模型在代码相似度指标上表现最佳。通过RAG优化，我们在相似度指标上达到了同等水平。然而，编译率显示两种模型在语法上仍有多次错误，RAG方法略胜一筹。在幻觉率方面，RAG模型在API名称和参数键上稍显落后。最终我们得出结论，经过优化的RAG模型不仅能与微调模型相媲美，还能为处理新的、未见过的API提供优势。
[Arxiv](https://arxiv.org/abs/2407.02742)
==========
# MentalAgora：借助多代理辩论与属性控制，开启心理健康高级个性化护理之门
发布时间：2024年07月02日
`Agent` `心理健康` `数字医疗`
> MentalAgora: A Gateway to Advanced Personalized Care in Mental Health through Multi-Agent Debating and Attribute Control
# 摘要
> 随着全球心理健康问题的日益严重，急需先进的数字支持系统。我们推出的MentalAgora框架，通过多代理交互增强的大型语言模型，提供个性化心理健康支持。该框架通过战略辩论、定制咨询师创建和响应生成三个阶段，根据用户偏好和治疗需求动态调整响应。实验表明，MentalAgora生成的响应既符合专家标准，又强化了用户偏好。评估结果显示，MentalAgora不仅符合专业标准，还能有效满足用户需求，为数字心理健康干预树立了新标杆。
[Arxiv](https://arxiv.org/abs/2407.02736)
==========
# 借助预训练语言模型，实现跨语言与跨项目的错误定位支持。
发布时间：2024年07月02日
`LLM应用` `软件开发` `人工智能`
> Supporting Cross-language Cross-project Bug Localization Using Pre-trained Language Models
# 摘要
> 在大型代码库中自动定位错误对开发者而言仍是一大挑战。现有技术因依赖特定应用数据和大型模型而难以通用和部署。本文提出一种基于预训练语言模型的创新技术，突破项目和语言限制，通过对比学习强化错误报告与源代码的表征，并结合提交信息与代码段进行精准排名。同时，引入知识蒸馏技术，在不损性能的前提下缩小模型尺寸，便于实际应用。本技术通过融合代码段与提交消息分析，提升错误定位精度，且在通用性上表现卓越，能有效识别新代码库中的错误。为应对计算限制，我们设计了CPU兼容方案。总之，这项技术高效、通用，极具实际应用潜力。
[Arxiv](https://arxiv.org/abs/2407.02732)
==========
# MedVH：探索在医学领域中，如何系统评估大型视觉语言模型的幻觉问题。
发布时间：2024年07月02日
`LLM应用` `人工智能`
> MedVH: Towards Systematic Evaluation of Hallucination for Large Vision Language Models in the Medical Context
# 摘要
> 近期，大型视觉语言模型（LVLMs）在处理自然图像和文本数据的多项任务中表现卓越，引发了大量关于其微调和训练的研究。然而，针对较小数据集微调时，这些模型对幻觉的鲁棒性研究却相对匮乏。为此，我们推出了医学视觉幻觉测试（MedVH）这一新基准数据集，旨在评估特定领域LVLMs的幻觉现象。MedVH通过五个任务，全面考察医学背景下LVLMs对文本和视觉输入的理解及长文本响应生成能力。实验结果显示，尽管医学LVLMs在标准医学任务中表现优异，但其幻觉倾向尤为严重，甚至超过通用模型，这对其可靠性提出了严峻挑战。要使医学LVLMs在实际应用中发挥真正价值，不仅需精准融合医学知识，更需强化推理能力，以防幻觉产生。我们的研究为未来相关评估奠定了基础。
[Arxiv](https://arxiv.org/abs/2407.02730)
==========
# LLM-Select：借助大型语言模型实现特征选择
发布时间：2024年07月02日
`LLM应用` `数据科学`
> LLM-Select: Feature Selection with Large Language Models
# 摘要
> 本研究揭示了大型语言模型（LLM）的一项惊人能力：仅凭输入特征名称和预测任务描述，LLM便能精准挑选出最具预测性的特征，其表现堪比数据科学领域的标准工具。这些模型在多种查询机制下均展现出此能力，例如，通过零-shot提示，LLM能直接输出特定特征（如“血压”）对预测目标（如“心脏病”）的数值重要性评分，无需额外上下文。最新模型如GPT-4，无论查询方式如何变化，均能稳定识别关键特征，适应多种提示策略。我们在真实数据上的实验证实，基于LLM的特征选择持续展现出与LASSO等数据驱动方法相媲美的性能，即便未接触下游训练数据。此发现不仅预示LLM在训练特征选择上的应用潜力，更可能指导实际操作中应优先收集哪些特征，特别是在数据收集成本高昂的医疗保健等领域，具有重要实践价值。
[Arxiv](https://arxiv.org/abs/2407.02694)
==========
# KGym 是一个专为 Linux 内核崩溃解决而设计，用于评估大型语言模型性能的平台和数据集。
发布时间：2024年07月02日
`LLM应用` `软件工程` `机器学习`
> KGym: A Platform and Dataset to Benchmark Large Language Models on Linux Kernel Crash Resolution
# 摘要
> 大型语言模型（LLM）在处理日益复杂的软件工程任务中不断取得进展。在实际软件开发中，大量精力投入于构建如Linux内核这样的基础系统软件。与应用软件不同，Linux代码库庞大（超2000万行）、多语言（C/汇编/Bash/Rust）、关键性高（影响全球数十亿设备）且高度并发。为评估ML模型在此类大规模系统软件开发中的实用性，我们推出了kGym平台和kBench数据集。kGym支持在多个虚拟机上并行编译、运行Linux内核，并进行操作检测、崩溃分析、日志审查及代码库查询与修补。我们利用kGym对kBench（基于真实Linux内核错误的崩溃解决基准）进行评估。kBench中的错误案例包括崩溃堆栈、重现文件、开发者修复方案等。通过提示LLM解决内核崩溃问题，我们发现最佳模型在无辅助与有辅助（错误文件公开）场景下分别达到0.72%和5.38%的解决率。这凸显了提升模型在软件工程任务中性能的研究需求。提升kBench性能要求模型精通新技能，如崩溃原因分析、故障修复、内存安全与硬件感知代码编写及并发理解。此研究在机器学习与系统软件的交叉领域开启了新的探索方向。
[Arxiv](https://arxiv.org/abs/2407.02680)
==========
# 大型语言模型推理：几何视角探析
发布时间：2024年07月02日
`LLM理论` `人工智能` `机器学习`
> Reasoning in Large Language Models: A Geometric Perspective
# 摘要
> 提升大型语言模型（LLM）的推理能力对其在实际应用中的发展至关重要。本研究通过几何视角深入探讨了LLM的推理能力，揭示了LLM表达力与自注意力图密度间的内在联系。分析显示，这些图的密度直接影响了输入到MLP块的内在维度，进而决定了LLM的表达能力。通过理论与实例验证，我们证实了内在维度越高，LLM的表达力越强。此外，我们还提供了实证，将这一几何框架与近期旨在提升LLM推理能力的方法进展相联系。
[Arxiv](https://arxiv.org/abs/2407.02678)
==========
# KV缓存压缩：我们需付出何种代价？长上下文能力方法的全面基准测试
发布时间：2024年07月01日
`LLM理论` `软件开发` `人工智能`
> KV Cache Compression, But What Must We Give in Return? A Comprehensive Benchmark of Long Context Capable Approaches
# 摘要
> 大型语言模型（LLM）的长上下文能力至关重要，它减轻了人类阅读长篇文本的负担，使得书籍摘要、代码辅助等复杂任务成为可能。然而，基于transformer的LLM在处理长上下文时面临挑战，如KV缓存膨胀和输入处理的复杂性。为此，业界提出了多种高效方法，如KV缓存量化和混合架构，以提升模型性能。尽管如此，这些方法尚未在统一环境中得到全面评估。本研究填补了这一空白，通过分类法评估了七大类长上下文任务的10多种前沿方法，揭示了新现象，并为未来LLM的发展提供了见解和工作平台。源代码将在GitHub上公开。
[Arxiv](https://arxiv.org/abs/2407.01527)
==========
# 赋予 3D 视觉定位推理能力
发布时间：2024年07月01日
`LLM应用` `计算机视觉` `机器人技术`
> Empowering 3D Visual Grounding with Reasoning Capabilities
# 摘要
> 尽管3D视觉定位已取得显著进展，但现有模型仍依赖显式文本描述，且难以从隐含指令中解读人类意图。为此，我们提出了“3D推理定位”新任务，并创建了ScanReason基准，包含10K+问题-答案-位置对，涵盖五种需推理与定位协同的类型。我们的ReGround3D方法结合了MLLM增强的视觉推理模块和3D定位模块，通过精细解析3D场景细节来精确定位对象。此外，我们创新的链式定位机制在推理中交替进行推理与定位，显著提升了性能。大量实验证实了该方法的有效性。
[Arxiv](https://arxiv.org/abs/2407.01525)
==========
# MMLongBench-Doc：借助可视化工具，对长篇文档理解进行基准测试
发布时间：2024年07月01日
`LLM应用` `文档处理` `人工智能`
> MMLongBench-Doc: Benchmarking Long-context Document Understanding with Visualizations
# 摘要
> 理解复杂布局和多模态内容的文档是一项传统且实用的任务。最新的大型视觉-语言模型（LVLMs）在单页文档理解方面取得了显著进步，但在长篇文档理解方面仍面临挑战。我们提出的MMLongBench-Doc基准，包含1,062个专家注释问题，基于130个长篇PDF文档，平均每篇49.4页，文本标记达20,971个。该基准强调了从不同来源和位置获取证据的重要性，其中33.2%的问题需要跨页证据，22.8%的问题设计为无法回答以检测模型幻觉。实验显示，即使是表现最佳的模型GPT-4o，F1分数也仅为42.7%，表明长篇文档理解对当前模型极具挑战性。这些发现强调了开发更强大的长上下文LVLMs的迫切需求。项目详情见：https://mayubo2333.github.io/MMLongBench-Doc
[Arxiv](https://arxiv.org/abs/2407.01523)
==========
# MIA-Bench：旨在提升多模态 LLM 指令遵循能力的评估工具
发布时间：2024年07月01日
`LLM应用` `人工智能` `计算机视觉`
> MIA-Bench: Towards Better Instruction Following Evaluation of Multimodal LLMs
# 摘要
> 我们推出了 MIA-Bench，一个专为测试多模态大型语言模型 (MLLM) 严格遵守复杂指令能力而设计的新基准。该基准包含 400 个精心设计的图像-提示对，旨在考验模型在生成符合特定模式的准确响应时，能否遵循多层次的指令。评估显示，不同 MLLM 的性能差异显著，指出了提升指令执行准确性的关键领域。同时，我们通过增加训练数据和实施监督微调，旨在提升模型遵循指令的能力，同时保持其在其他任务上的表现。我们期待 MIA-Bench 不仅能作为评估工具，还能引领 MLLM 训练方法的未来进步。
[Arxiv](https://arxiv.org/abs/2407.01509)
==========
# 大型语言模型中的自我认知探索研究
发布时间：2024年07月01日
`LLM理论` `人工智能` `语言模型`
> Self-Cognition in Large Language Models: An Exploratory Study
# 摘要
> 大型语言模型 (LLMs) 虽在多领域大放异彩，但其自我认知能力亦引发关注。本研究首开先河，深入探索 LLMs 的自我认知现象。我们精心设计了一系列自我认知指令提示及四项量化原则，以评估 LLMs 的自我认知表现。研究发现，Chatbot Arena 中的四款模型——Command R、Claude3-Opus、Llama-3-70b-Instruct 和 Reka-core——展现出可检测的自我认知迹象。模型规模与训练数据质量的提升，似乎与自我认知水平的增强呈正相关。此外，我们发现处于自我认知状态的 LLMs 在创意写作等特定任务上表现更佳。本研究成果，有望为 LLMs 自我认知领域的深入探索提供新思路。
[Arxiv](https://arxiv.org/abs/2407.01505)
==========
# RegMix：以数据混合为手段，通过回归进行语言模型预训练
发布时间：2024年07月01日
`LLM理论` `人工智能` `数据科学`
> RegMix: Data Mixture as Regression for Language Model Pre-training
# 摘要
> 大型语言模型预训练中的数据混合对性能影响重大，但如何确定有效混合仍是个谜。我们提出RegMix，通过将其视为回归任务，自动识别高性能数据混合。RegMix通过多样数据混合训练小型模型，并拟合回归模型预测性能。利用此模型，我们模拟最佳混合，训练计算量巨大的大型模型。为验证RegMix，我们训练512个1M参数模型，用于1B令牌的不同混合，拟合回归模型并找到最佳混合。使用此混合，我们训练1B参数模型，用于25B令牌，表现优于64个候选模型。此外，RegMix超越人工选择，与DoReMi相媲美或更优，且仅用10%计算预算。实验显示：（1）数据混合显著影响性能，单任务性能变化达14.6%；（2）网络语料库与下游性能正相关最强；（3）领域交互复杂，需自动方法；（4）数据混合效应超越缩放定律，我们方法考虑所有领域捕捉复杂性。代码见https://github.com/sail-sg/regmix。
[Arxiv](https://arxiv.org/abs/2407.01492)
==========
# 通过缓慢级联学习，实现大型模型的低秩适应，兼具表达性与泛化能力。
发布时间：2024年07月01日
`LLM理论` `人工智能` `机器学习`
> Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning
# 摘要
> 在现代大型模型中，高效微调至关重要，而低秩适应方法尤为引人注目。然而，现有LoRA方法存在表达力不足、易过拟合及对超参数敏感等问题。为此，我们创新性地提出了LoRA慢级联学习（LoRASC）技术，旨在提升LoRA的表达与泛化能力，同时保持高效训练。通过级联学习策略，我们实现了混合低秩适应，增强了模型捕捉复杂模式的能力。此外，引入的慢-快更新机制和级联噪声调整进一步强化了泛化性能。实验结果显示，LoRASC不仅大幅超越现有方法，还显著改善了过拟合、模型稳定性和OOD鲁棒性。相关代码即将在GitHub上发布。
[Arxiv](https://arxiv.org/abs/2407.01491)
==========
# LLM 观察，LLM 行动：引导数据生成，瞄准非可微目标
发布时间：2024年07月01日
`LLM理论` `人工智能` `数据科学`
> LLM See, LLM Do: Guiding Data Generation to Target Non-Differentiable Objectives
# 摘要
> 合成数据的普及引发了一个新问题：数据生成模型如何通过精炼数据影响其他大型语言模型。我们的研究深入探讨了模型属性被动继承的影响，并全面分析了合成数据整合的后果。我们提供了迄今为止最详尽的研究，揭示了合成数据来源如何影响模型的内部偏见、校准以及文本生成属性和偏好。令人惊讶的是，即使合成数据提示看似中性，模型对某些属性的敏感度依然显著，这引发了是否可以善用这种敏感性的疑问。我们的研究还提出了一个新问题：我们能否在测试时通过操控数据生成过程，明确引导模型朝着我们期望的属性发展？过去，由于收集特定特征或目标数据的成本高昂，这被视为不可能。但随着合成数据质量的提升和通用模型的兴起，这一问题变得尤为重要。我们引入了“主动继承”这一概念，用以描述根据不可微目标有意识地约束合成数据的行为。我们展示了如何通过主动继承，引导模型的生成特征朝着高词汇多样性或低毒性等理想属性发展。
[Arxiv](https://arxiv.org/abs/2407.01490)
==========
# 无代理模式：探索基于LLM的软件工程代理之谜
发布时间：2024年07月01日
`Agent` `软件开发` `人工智能`
> Agentless: Demystifying LLM-based Software Engineering Agents
# 摘要
> 大型语言模型的最新进展极大地推动了软件开发自动化的进程，涵盖了代码合成、程序修复和测试生成等多个方面。近期，研究者和业界专家开发了多种自主LLM代理，以完成端到端的软件开发任务。这些代理不仅能够使用工具、执行命令，还能从环境反馈中学习并规划未来的行动。然而，这些基于代理的方法的复杂性，以及当前LLM能力的局限，引发了一个问题：我们是否真的需要依赖复杂的自主软件代理？为了探索这一问题，我们提出了Agentless——一种无需代理的解决方案，旨在自动解决软件开发中的难题。与依赖复杂工具和决策的代理方法相比，Agentless采用了一种简洁的两阶段流程：先定位问题，再进行修复，避免了LLM进行复杂操作或决策的需要。在SWE-bench Lite这一广受欢迎的基准测试中，Agentless的表现令人瞩目，不仅达到了最高的性能（27.33%），还实现了最低的成本（$0.34），超越了所有现有的开源软件代理。此外，我们通过手动分类SWE-bench Lite中的问题，识别出了一些具有确切解决方案或描述不准确的问题，并据此构建了SWE-bench Lite-S，以进行更为严格的评估和比较。我们的研究揭示了简单、可解释技术在自主软件开发中的巨大潜力，希望Agentless能够为自主软件代理的发展设定新的基准和方向，并激发更多相关领域的研究。
[Arxiv](https://arxiv.org/abs/2407.01489)
==========
# LEXI：大型语言模型实验平台
发布时间：2024年07月01日
`LLM应用` `社交互动` `人机交互`
> LEXI: Large Language Models Experimentation Interface
# 摘要
> 大型语言模型 (LLM) 的最新进展，为人工代理的社交互动研究带来了重大突破。这些代理广泛应用于多种场景，对用户产生深远影响。然而，由 LLM 驱动的代理的社交互动研究尚处于初级阶段，面临技术与数据访问的限制、标准化接口的缺失以及使用商业平台建立受控实验的挑战。为此，我们推出了 LEXI，一个开源的 LLM 实验接口，旨在促进社交互动行为实验中人工代理的部署。LEXI 通过直观的图形界面，让研究人员能够轻松构建和部署代理，同时收集详尽的互动数据。该工具不仅提升了人-代理交互 (HAI) 研究的实证方法，还为不同背景的研究者提供了便捷的实验平台。可用性测试显示，LEXI 具有极高的实用性和用户友好性，且认知负荷极低，跨学科应用效果显著。一项概念验证研究证实了 LEXI 在评估社交 HAI 中的高效性，产生了高质量的数据。研究还发现，人们更偏爱同理心代理，并倾向于向其发送更长、更积极的讯息。
[Arxiv](https://arxiv.org/abs/2407.01488)
==========
# DogeRM：借助模型合并技术，为奖励模型注入领域智慧
发布时间：2024年07月01日
`LLM应用` `人工智能` `机器学习`
> DogeRM: Equipping Reward Models with Domain Knowledge through Model Merging
# 摘要
> 强化学习从人类反馈（RLHF）是调整大型语言模型（LLM）行为的热门方法。奖励建模在RLHF中至关重要，但收集训练奖励模型所需的配对偏好数据往往费时费力，尤其是特定领域偏好需专家注释时。为此，我们创新性地提出了DogeRM框架，通过模型合并技术将领域知识融入通用奖励模型。实验结果显示，DogeRM在多个基准测试中性能显著提升，并深入分析了模型合并的影响，展现了其在促进模型对齐方面的广阔前景。
[Arxiv](https://arxiv.org/abs/2407.01470)
==========
# 多语言环境下的检索增强生成
发布时间：2024年07月01日
`RAG` `人工智能` `多语言处理`
> Retrieval-augmented generation in multilingual settings
# 摘要
> RAG作为一种创新的解决方案，旨在将最新或特定领域的知识融入大型语言模型（LLM），并提升其事实性，但目前主要在英语环境中研究。我们探索了多语言环境下的RAG（mRAG），涉及13种语言的用户查询和数据存储，并探讨了构建高效mRAG流水线的关键组件和必要调整。研究发现，尽管现有高质量多语言工具丰富，但任务特定的提示工程对于实现用户语言生成至关重要。同时，评估指标需适应多语言特性，考虑命名实体的拼写差异。未来挑战包括非拉丁字母语言中的代码切换频繁、流畅性问题、文档解读错误及无关检索等。我们已在https://github.com/naver/bergen分享了mRAG基线流水线的代码，供未来研究参考。
[Arxiv](https://arxiv.org/abs/2407.01463)
==========
# 利用强化学习优化查询，提升大型语言模型的性能与稳定性
发布时间：2024年07月01日
`LLM应用` `人工智能` `网络安全`
> Enhancing the Capability and Robustness of Large Language Models through Reinforcement Learning-Driven Query Refinement
# 摘要
> 大型语言模型（LLM）的回应质量深受用户提示的影响，但这些提示往往简短且模糊，限制了LLM的潜力。此外，恶意用户可能精心设计有害提示，试图破解LLM，导致其输出有害内容。为提升LLM的性能并增强其对抗恶意输入的鲁棒性，本研究提出了一种灵活的框架，用于优化用户提示。该框架通过提升查询质量，使LLM生成更真实、无害且有用的回应。我们引入了一个轻量级模型，采用创新的强化学习方法进行训练，旨在强化LLM的特定能力。实验证明，该模型不仅提升了回应质量，还增强了其抵御破解攻击的能力。相关代码已公开，详见：https://github.com/Huangzisu/query-refinement。
[Arxiv](https://arxiv.org/abs/2407.01461)
==========
# 时间空间，即 TimeToM，是揭开大型语言模型心智理论奥秘的关键。
发布时间：2024年07月01日
`LLM应用` `社交互动` `人工智能`
> TimeToM: Temporal Space is the Key to Unlocking the Door of Large Language Models' Theory-of-Mind
# 摘要
> ToM，即理解自我与他人心理状态的能力，是社交互动的基石。尽管人类天生具备这一能力，但即使是顶尖的大型语言模型（LLM）也难以应对。由于ToM推理中的复杂逻辑，尤其是高阶ToM问题，传统的推理方法如思维链（CoT）无法有效提升LLM的ToM能力。为此，我们引入了TimeToM，通过构建时间空间，在多场景中增强LLM的ToM推理能力。我们为每个角色构建时间信念状态链（TBSC），并借鉴社会世界模型的认知视角，将TBSC细分为自我世界信念与社会世界信念，分别对应一阶和高阶ToM问题。同时，我们设计了一种创新的信念解决工具，通过角色间在时间空间中的信念交流，实现高阶信念向初阶信念的转换。实验显示，TimeToM大幅提升了LLM在ToM问题上的推理性能，并朝着实现连贯且稳健的ToM推理迈出了重要一步。
[Arxiv](https://arxiv.org/abs/2407.01455)
==========
# FastCLIP：一套优化技术，专为在资源有限的情况下加速 CLIP 训练而设计
发布时间：2024年07月01日
`LLM应用` `计算机科学` `人工智能`
> FastCLIP: A Suite of Optimization Techniques to Accelerate CLIP Training with Limited Resources
# 摘要
> 现有研究在大型数据集上训练CLIP模型需要大量GPU资源，这对大多数人来说难以企及。尽管组合优化技术已证明能有效减少对大批次的需求，但它们在大规模数据上的性能仍有待优化。本文探讨了在有限资源下进行CLIP训练的多个方面。我们提出了FastCLIP框架，该框架基于先进的组合优化技术，专为分布式环境设计，通过高效的梯度减少策略降低通信开销。此外，我们从优化角度研究了框架的关键组成部分，以进一步提升训练效率。实验结果显示，FastCLIP在资源有限的环境中显著优于现有基准。FastCLIP的代码已公开发布，供进一步研究和应用。
[Arxiv](https://arxiv.org/abs/2407.01445)
==========
# 大型语言模型中基于内存的难题
发布时间：2024年07月01日
`LLM应用` `人工智能` `软件开发`
> Needle in the Haystack for Memory Based Large Language Models
# 摘要
> 本文通过案例研究 LARIMAR，展示了增强记忆的 LLM 架构在提升长上下文事实回忆能力方面的优势。LARIMAR 通过外部关联记忆强化了 LLM 解码器，在多项长上下文回忆任务中表现出色，如密钥传递和海中捞针测试。实验表明，该架构能在测试时灵活适应更长上下文，同时确保解码器识别记忆输出，且不增加 GPU 内存负担。相较于参数相当的替代架构，LARIMAR 无需特定任务训练即可维持卓越性能。
[Arxiv](https://arxiv.org/abs/2407.01437)
==========
# 知识图谱问答中的动态少样本学习
发布时间：2024年07月01日
`LLM应用` `知识图谱` `问答系统`
> Dynamic Few-Shot Learning for Knowledge Graph Question Answering
# 摘要
> 大型语言模型为KGQA带来了创新机遇，但它们并非专为查询生成设计。为此，我们提出了动态少样本学习（DFSL），它融合了上下文学习的效率与语义相似性，为KGQA提供了一种性能卓越的通用方案。我们在多样的数据集和架构配置上进行了全面评估，验证了其有效性。
[Arxiv](https://arxiv.org/abs/2407.01409)
==========
# 借助知识图谱和适配器，让多语言LLMs轻松适应低资源语言
发布时间：2024年07月01日
`LLM应用` `人工智能`
> Adapting Multilingual LLMs to Low-Resource Languages with Knowledge Graphs via Adapters
# 摘要
> 本文通过适配器将语言本体的图知识融入多语言大型语言模型 (LLM)，旨在提升低资源语言 (LRL) 在情感分析 (SA) 和命名实体识别 (NER) 的表现。借鉴 K-ADAPTER 和 MAD-X 等参数高效微调技术，我们提出新方法，利用多语言图知识，通过语言关系连接不同语言概念，增强多语言 LLM 对 LRL 的支持。我们特别关注八种 LRL，包括马耳他语、保加利亚语等，并使用特定语言适配器，基于 ConceptNet 特定语言部分的数据进行微调，促进知识跨语言转移。通过比较不同微调策略，如标准 MLM、全词掩码 MLM 和目标掩码 MLM，我们分析了它们在整合图数据方面的效果。实证评估显示，结构化图知识显著影响多语言 LLM 在 LRL 的 SA 和 NER 性能，揭示了适应低资源场景的语言模型的潜在优势。
[Arxiv](https://arxiv.org/abs/2407.01406)
==========
# 优化检索增强生成上下文，结合异常检测技术
发布时间：2024年07月01日
`LLM应用` `问答系统` `人工智能`
> Optimization of Retrieval-Augmented Generation Context with Outlier Detection
# 摘要
> 本文探讨了如何精简问题回答系统中提示上下文的大小并提升其质量。增加检索文档数量以扩充上下文虽能丰富信息，但也可能加重处理负担，影响LLM的响应效率。我们深知，大量检索文档中常混杂无关信息，易引发答案失真。为此，我们力求筛选出语义最相关的文档，视其余为异常。我们创新性地提出并验证了利用嵌入向量距离识别异常值的方法，通过与GPT-4o模型的基准答案对比，评估了这些方法的有效性。实验显示，随着问答复杂度的提升，我们的方法带来了显著的性能提升。
[Arxiv](https://arxiv.org/abs/2407.01403)
==========
# Gloss2Text：借助 LLMs 与语义感知标签平滑技术，实现手语词汇的精准翻译
发布时间：2024年07月01日
`LLM应用` `手语翻译` `人工智能`
> Gloss2Text: Sign Language Gloss translation using LLMs and Semantically Aware Label Smoothing
# 摘要
> 手语从视频到口语文本的翻译因独特的语法、表达细节及视觉多样性而充满挑战。我们聚焦于 {\em Gloss2Text} 翻译环节，借助预训练 LLM、数据增强及创新标签平滑损失函数，有效利用 gloss 翻译的歧义，大幅提升现有技术的性能。在 PHOENIX Weather 2014T 数据集上的深入实验与分析显示，我们的方法在 {\em Gloss2Text} 翻译领域超越了前沿水平，不仅验证了其在手语翻译中的高效性，也为未来研究开辟了新路径。
[Arxiv](https://arxiv.org/abs/2407.01394)
==========
# 在可读性控制下生成自由文本理由
发布时间：2024年07月01日
`LLM应用` `人工智能`
> Free-text Rationale Generation under Readability Level Control
# 摘要
> 自由文本理由以自然语言阐释模型决策，因此在多种任务的解释方法中备受欢迎且易于理解。然而，其有效性可能因误解和幻觉而受限。我们通过扰动测试探究了大型语言模型（LLM）在可读性水平控制下，即针对特定专业水平（如六年级或大学）提供理由时，如何执行自然语言解释（NLE）任务。研究发现，解释能适应指令，但请求的可读性与文本复杂性常不匹配。质量评估显示，LLM对理由的评价与NLG中的偏好模式相似。人类评估则表明，各可读性水平的理由普遍令人满意，高中水平尤为受欢迎。
[Arxiv](https://arxiv.org/abs/2407.01384)
==========
# 探究大型语言模型中基于知识的跨语言不一致问题
发布时间：2024年07月01日
`LLM应用` `多语言技术`
> Evaluating Knowledge-based Cross-lingual Inconsistency in Large Language Models
# 摘要
> 本文探讨了大型语言模型（如ChatGPT、Llama和Baichuan）在跨语言处理中的不一致现象。这些模型虽在NLP任务中表现卓越，但在处理不同语言的相同概念时却常显差异。研究围绕三个核心问题：LLMs跨语言不一致的存在、具体表现及与多语言能力的关联。为此，我们创新性地采用LaBSE模型评估跨语言语义一致性（xSC），并引入跨语言准确性一致性（xAC）和跨语言时效性一致性（xTC）指标，全面衡量模型在语义、准确性和时效性上的不一致。通过整合这些指标，我们为LLMs的跨语言一致性提供了全面评估。研究旨在深化对LLMs多语言能力和可解释性的认识，推动构建更强大、可靠的多语言模型。
[Arxiv](https://arxiv.org/abs/2407.01358)
==========
# 免费提升模型容量：一种简便的参数高效微调方法
发布时间：2024年07月01日
`LLM理论` `机器学习`
> Increasing Model Capacity for Free: A Simple Strategy for Parameter Efficient Fine-tuning
# 摘要
> 近期，微调如175B GPT-3这样的大型预训练模型在下游任务中备受瞩目。尽管参数高效的微调方法已被证明有效，但其性能仍受限于增量模块的容量，尤其是在参数预算有限时。为此，我们推出了CapaBoost策略，通过在目标层中并行权重模块的低秩更新，简单而有效地提升模型容量。通过静态随机掩码的应用，CapaBoost构建了多样化的权重矩阵，有效提升增量权重秩，且不增加参数。此方法能无缝融入现有参数高效微调技术。我们在自然语言理解、问答及图像分类等多样下游任务中验证了CapaBoost的显著效果，且无额外计算或存储负担。代码已公开在[GitHub](https://github.com/LINs-lab/CapaBoost)。
[Arxiv](https://arxiv.org/abs/2407.01320)
==========
# 预训练语言模型在开放域对话中，从高资源到低资源语言的语言可移植性策略研究
发布时间：2024年07月01日
`LLM应用` `对话系统` `语言处理`
> Language Portability Strategies for Open-domain Dialogue with Pre-trained Language Models from High to Low Resource Languages
# 摘要
> 本文探讨了大型预训练语言模型（PLMs）在高资源语言开放领域对话系统中的语言可移植性策略。我们以法语模拟低资源目标语言（L_T），因其缺乏特定任务资源，便于进行人类评估，而源语言（L_S）为英语。当前，这类模型多以英语开发，但为每种目标语言定制PLMs需收集新数据，成本高昂。因此，我们尝试整合L_S与L_T的现有资源，评估在L_T中通过不同方法的性能。我们评估了两种NMT应用：TrainOnTarget先翻译L_S数据集再在L_T中微调；TestOnSource则在推理时结合L_S模型与NMT模块。BLOOM[2]作为首个开放访问的多语言大型PLM，开启了新方法的探索，不仅利用其全面可访问性，还发挥其多语言和翻译能力。我们首先在L_S中学习任务，再通过MAD-X Adapter架构[16]适应至L_T。实验中，模型在口语对话环境下接受评估，人类评估者可比较不同策略在交互质量上的表现。
[Arxiv](https://arxiv.org/abs/2407.01315)
==========
# 大型语言模型的协同性能预测
发布时间：2024年07月01日
`LLM理论` `人工智能`
> Collaborative Performance Prediction for Large Language Models
# 摘要
> 在NLP研究中，全面且准确地预测大型语言模型在各种下游任务中的表现已成为一项核心挑战。虽然早期的规模法则揭示了模型家族内的相似性，并据此进行性能预测，但它们忽略了家族间的相似性，仅依赖于原始法则中的设计因素。为此，我们提出了协同性能预测（CPP）框架，该框架通过整合模型历史表现和其他设计因素，大幅提升了预测精度。此外，我们收集了包含历史性能和设计因素的在线数据，支持CPP不仅在预测LLM性能上超越传统法则，还深入分析了各因素的重要性，填补了以往研究的空白。
[Arxiv](https://arxiv.org/abs/2407.01300)
==========
# 轻量级零-shot 文本转语音技术采用适配器混合方法
发布时间：2024年07月01日
`LLM应用` `语音技术` `人工智能`
> Lightweight Zero-shot Text-to-Speech with Mixture of Adapters
# 摘要
> 基于大规模模型的零-shot 文本到语音技术虽已展现高保真度，但模型体积过大，不便日常使用。为此，我们创新性地提出了一种轻量级零-shot TTS 方法，采用适配器混合技术 (MoA)。该方法通过将 MoA 模块嵌入非自回归 TTS 模型的解码器和变异适配器，实现了对多样说话者特征的精准适配。仅需少量额外参数，便能合成高质量语音。经客观与主观双重评估，我们的方法在参数减少 40% 的同时，推理速度提升 1.9 倍，性能超越基线。欢迎访问我们的演示页面 (https://ntt-hilab-gensp.github.io/is2024lightweightTTS/) 试听音频样本。
[Arxiv](https://arxiv.org/abs/2407.01291)
==========
# We-Math：探寻大型多模态模型是否已具备人类般的数学推理能力。
发布时间：2024年07月01日
`LLM应用` `人工智能`
> We-Math: Does Your Large Multimodal Model Achieve Human-like Mathematical Reasoning?
# 摘要
> 视觉数学推理作为一项基础能力，备受大型多模态模型（LMMs）社区瞩目。然而，现有基准如MathVista和MathVerse过于侧重结果，忽略了知识获取与泛化的深层原理。受人类数学推理启发，我们推出WE-MATH，首个专注于探索问题解决原则的基准。我们精心整理了6.5K个视觉数学问题，涵盖67个知识层次与五层知识粒度，并根据知识需求分解复合问题为子问题。我们创新引入四维指标——知识不足（IK）、泛化不足（IG）、完全掌握（CM）和机械记忆（RM），以层次化评估LMMs推理过程。通过WE-MATH，我们全面评估了现有LMMs，并发现解决步骤与问题性能呈负相关。我们证实，通过知识增强策略可有效改善LMMs的IK问题。尤为突出的是，GPT-4o已从IK转向IG，成为首个迈向知识泛化阶段的LMM。而其他LMMs则倾向于机械记忆，虽能解决复合问题，却未能解答子问题。我们期待WE-MATH为LMMs在视觉数学推理领域的进步开辟新路。WE-MATH数据与评估代码已公开于https://github.com/We-Math/We-Math。
[Arxiv](https://arxiv.org/abs/2407.01284)
==========
# 人机互学：基于情感语言交互与差异化训练成果 [预印版]
发布时间：2024年07月01日
`Agent`
> Human-Robot Mutual Learning through Affective-Linguistic Interaction and Differential Outcomes Training [Pre-Print]
# 摘要
> 随着大型语言模型的兴起，现代AI更多地聚焦于与人类的语言交流，而对人机间的非语言沟通关注不足。本文探讨了情感语言交流结合差异结果训练对人机互动中相互学习的影响。借鉴儿童与看护者的互动模式，我们设计了一个模拟场景：机器人学习如何有效表达其内部需求，而人类“看护者”则学习如何准确响应这些需求。通过对比不同训练和学习策略，我们评估了相互学习的准确性和效率。实验表明，采用差异结果训练（DOT）的机器人学习效果显著优于对照组，且探索-利用策略的选择进一步提升了学习成效。这些成果为社会辅助机器人在治疗和教育领域的应用提供了新视角。
[Arxiv](https://arxiv.org/abs/2407.01280)
==========
# 借助大型语言模型，为讲师提供具有操作性的课程评估学生反馈
发布时间：2024年07月01日
`LLM应用` `人工智能`
> Leveraging Large Language Models for Actionable Course Evaluation Student Feedback to Lecturers
# 摘要
> 学期末的学生教学评估是反馈教学实践的主要途径。然而，对于大型课程，海量反馈使得传统工具难以应对。本文探索了利用开源生成AI，从众多调查反馈中提炼出事实准确、操作性强且恰如其分的总结。我们分析了742份学生反馈，涉及计算机科学系的75门课程。每门课程，我们都生成了评估摘要和教师可执行的建议。研究结果表明，这一方法为提升课堂教学质量开辟了新途径。我们的创新之处在于，展示了生成AI为教师提供深刻反馈的可行性，为教育发展提供了经济高效的解决方案。总体而言，我们的研究凸显了生成AI在课堂环境中为教师提供精准、实用且恰当反馈的潜力。
[Arxiv](https://arxiv.org/abs/2407.01274)
==========
# 精简展示，强化指导：通过定义与指南提升零-shot NER 的提示质量
发布时间：2024年07月01日
`LLM应用` `人工智能`
> Show Less, Instruct More: Enriching Prompts with Definitions and Guidelines for Zero-Shot NER
# 摘要
> 近期，针对命名实体识别 (NER) 的专用指令调整大型语言模型 (LLM) 崭露头角，其泛化能力超越传统方法。传统 LLM 多聚焦于域外零-shot NER，依赖于与测试集高度重叠的大量实体类别进行微调。而我们提出的 SLIMER 方法，则通过精简示例指导和丰富提示中的定义与指南，有效应对新出现的命名实体标签。实验显示，这种方法不仅提升了性能，还加速并强化了学习过程，尤其在处理未知命名实体时表现突出。此外，SLIMER 在域外零-shot NER 任务中与顶尖方法不相上下，且训练标签集更为精简。
[Arxiv](https://arxiv.org/abs/2407.01272)
==========
# 非洲女性，节奏与灵魂的化身：探索隐性偏见在开放式生成中的表现
发布时间：2024年07月01日
`LLM理论` `人工智能伦理` `心理学`
> The African Woman is Rhythmic and Soulful: Evaluation of Open-ended Generation for Implicit Biases
# 摘要
> 本研究深入探讨了大型语言模型（LLM）中不易察觉的隐性偏见，这些偏见即便在通过显性测试后，仍可能隐晦地显现，类似于那些自称平等主义者却潜藏偏见的人。随着LLM的专有化加深，对关键内部机制如嵌入的访问受限，这使得传统偏见测量方法面临更大挑战。为此，本研究创新性地引入了基于心理学方法的偏见测量：LLM隐性联想测试（IAT）偏见和LLM决策偏见。前者通过模拟心理学IAT揭示LLM的隐性偏见，后者则专注于检测LLM在决策中的微妙歧视。实验结果显示，LLM在性别和种族领域存在从分类歧视到异国情调化的偏见。研究证实，基于提示的隐性偏见测量不仅与传统方法相关，还能更精准地预测下游行为，凸显了相对评估在偏见评估中的重要性。这项研究不仅增进了对AI伦理的理解，还为持续优化和减少AI系统中的偏见提供了方向，强调了定性和下游分析的重要性。
[Arxiv](https://arxiv.org/abs/2407.01270)
==========
# SignCLIP：借助对比学习，架起文本与手语之间的桥梁
发布时间：2024年07月01日
`LLM应用` `手语识别` `语言学`
> SignCLIP: Connecting Text and Sign Language by Contrastive Learning
# 摘要
> 我们开发了 SignCLIP，通过重新利用 CLIP 技术，将口语和手语这两种不同模态的语言融合至同一空间。SignCLIP 高效地从多语言视频-文本对中提取手语视觉特征，无需针对特定手语或任务进行优化。我们在包含 44 种手语的 Spreadthesign 词典上预训练模型，并在多个下游任务中验证其性能。SignCLIP 在手语识别中展现出高精度的文本-视频互检能力，并在其他领域任务中表现优异，仅需少量学习或微调。此外，我们探索了口语与手语间的潜在空间，揭示了新的语言视角。相关代码和模型已公开分享。
[Arxiv](https://arxiv.org/abs/2407.01264)
==========
# uDistil-Whisper：利用大规模伪标签技术，实现知识蒸馏中的无标签数据过滤。
发布时间：2024年07月01日
`LLM应用` `语音识别` `模型优化`
> uDistil-Whisper: Label-Free Data Filtering for Knowledge Distillation via Large-Scale Pseudo Labelling
# 摘要
> 近期研究通过伪标签将 Whisper 的知识精炼至小型模型，不仅性能出色，还成功缩减了模型体积达50%。这些模型虽小巧却高效且专注。然而，提炼过程中的关键一环——筛选高质量预测，依赖于真实数据进行不良示例的过滤，这使得整个流程带有监督性质。此外，大量数据需求也限制了其在资源匮乏环境中的应用。为此，我们创新性地提出了一个无需标签的无监督提炼框架，彻底摆脱了对标记数据的依赖。实验结果显示，我们的最佳提炼模型在WER指标上超越了原教师模型5-7分，且与采用监督数据筛选的模型相比，性能不相上下甚至更优。随着数据规模的扩大，我们的模型在性能上显著领先于所有零-shot和监督模型。本研究成果表明，无需任何标记数据，即可将庞大的Whisper模型精炼为更小巧的版本，同时保持甚至提升其性能，实现计算与内存效率的显著提升。
[Arxiv](https://arxiv.org/abs/2407.01257)
==========
# SINKT：结合大型语言模型的结构感知归纳知识追踪模型
发布时间：2024年07月01日
`LLM应用` `智能辅导系统`
> SINKT: A Structure-Aware Inductive Knowledge Tracing Model with Large Language Model
# 摘要
> 知识追踪 (KT) 是智能辅导系统中的关键任务，旨在预测学生能否正确回答下一个问题。然而，传统基于转导 ID 的方法常受数据稀疏和冷启动问题困扰，且未能直接建模概念与问题间的复杂关系。为此，我们提出结构感知归纳知识追踪模型 SINKT，首次结合大型语言模型 (LLM) 实现归纳知识追踪。SINKT 通过 LLM 构建概念间的结构关系和异构图，并融入语义信息以提升预测准确性。最终，通过与学生知识状态和问题表示的交互，SINKT 预测学生对新问题的回答。实验显示，SINKT 在多个数据集上超越现有模型，达到最优性能，并深入分析了其在归纳 KT 任务中的表现。
[Arxiv](https://arxiv.org/abs/2407.01245)
==========
# 大型语言模型能够零-shot 识别日常活动
发布时间：2024年07月01日
`LLM应用` `智能家居` `医疗保健`
> Large Language Models are Zero-Shot Recognizers for Activities of Daily Living
# 摘要
> 在智能家居环境中，基于传感器的日常活动（ADLs）识别技术为能源管理、安全、福祉和医疗保健等领域带来了多种应用。虽然ADLs识别通常依赖于需要大量数据训练的深度学习方法，但近期研究表明，大型语言模型（LLMs）能够有效捕捉人类活动的常识知识。尽管如此，LLMs在智能家居ADLs识别中的实际效果仍需深入探讨。为此，我们开发了ADL-LLM，一个创新的基于LLM的ADLs识别系统。该系统将传感器数据转化为文本形式，再由LLM进行处理，实现零-shot ADLs识别。同时，在拥有少量标记数据的情况下，ADL-LLM还能通过少量提示进一步提升性能。我们在两个公开数据集上的实验证明了ADL-LLM在这一领域的有效性。
[Arxiv](https://arxiv.org/abs/2407.01238)
==========
# 大型语言模型的独特印记
发布时间：2024年07月01日
`LLM理论` `知识产权保护` `人工智能`
> A Fingerprint for Large Language Models
# 摘要
> 随着预训练语言模型的扩展在众多下游任务中达到顶尖性能，大型语言模型 (LLMs) 已成为人工智能研究的热点。然而，鉴于从头训练 LLMs 的高资源需求，保护其知识产权刻不容缓。为此，本文提出了一种无需训练或微调的黑盒指纹技术。我们首先证实 LLMs 的输出构成了独特的向量空间。将所有权认证视为比较受害者与嫌疑模型输出空间相似度的任务，我们设计了两种方案：一是快速验证嫌疑模型输出是否与受害者模型同处一空间，二是重建向量空间并集以应对参数高效微调攻击。实验显示，该技术在所有权验证及抗攻击方面表现卓越。这项研究不仅揭示了 LLMs 的本质特征，还为黑盒环境下的所有权验证提供了高效、通用且实用的解决方案。
[Arxiv](https://arxiv.org/abs/2407.01235)
==========
# MIRAI：评估大型语言模型代理在事件预测中的效能
发布时间：2024年07月01日
`Agent` `国际关系` `政策制定`
> MIRAI: Evaluating LLM Agents for Event Forecasting
# 摘要
> 大型语言模型 (LLM) 的进步赋予了 LLM 代理自主收集全球信息并进行推理解决复杂问题的能力。因此，利用 LLM 代理预测国际事件的兴趣日益浓厚，这些预测能影响全球决策和政策制定。然而，关于 LLM 代理预测能力的严格基准尚缺。为此，我们推出了 MIRAI，一个专为系统评估 LLM 代理在国际事件预测中表现的新基准。MIRAI 提供了一个包含丰富历史和新闻数据的代理环境，并通过精细处理 GDELT 数据库，设计了涵盖短期到长期预测的任务，全面测试 LLM 代理的能力。此外，我们还开发了 API，使代理能通过代码接口灵活使用工具。MIRAI 从三个维度评估代理：自主整合全球信息、编写专用代码使用工具、结合多元历史知识精准预测未来。通过这一全面基准，我们旨在构建一个可靠框架，推动开发更精准可信的国际关系分析模型。
[Arxiv](https://arxiv.org/abs/2407.01231)
==========
# 探寻检索增强生成领域的最佳实践
发布时间：2024年07月01日
`RAG` `专业领域` `多模态内容生成`
> Searching for Best Practices in Retrieval-Augmented Generation
# 摘要
> RAG技术在整合最新信息、减少幻觉和提升响应质量方面表现出色，尤其是在专业领域。然而，尽管有许多依赖查询的检索方法被提出以增强大型语言模型，这些方法的复杂实现和较长响应时间仍是问题。我们深入研究了现有RAG方法及其组合，旨在找出最佳实践。通过大量实验，我们推荐了几种既能保证性能又能提高效率的RAG部署策略。此外，我们还展示了多模态检索技术如何显著提升对视觉内容的问答能力，并通过“检索即生成”策略加速多模态内容的生成。
[Arxiv](https://arxiv.org/abs/2407.01219)
==========
# EconNLI：探究大型语言模型在经济学推理领域的评估
发布时间：2024年07月01日
`LLM应用`
> EconNLI: Evaluating Large Language Models on Economics Reasoning
# 摘要
> 尽管大型语言模型 (LLM) 在撰写经济分析报告和提供财务建议方面应用广泛，但其对经济知识的理解和推理特定经济事件结果的能力尚未得到系统评估。为此，我们推出了经济事件自然语言推理 (EconNLI) 数据集，旨在全面检验 LLM 在经济领域的推理能力。实验结果显示，LLM 在经济推理上存在不足，可能给出错误或虚构的答案。这一发现提醒我们，在依赖 LLM 进行涉及经济分析的关键决策时需谨慎。EconNLI 数据集及代码已公开，供进一步研究使用。
[Arxiv](https://arxiv.org/abs/2407.01212)
==========
# TCSR-SQL：借助自检索技术，实现对表格内容的智能感知，进而生成SQL语句。
发布时间：2024年07月01日
`LLM应用` `数据库` `软件开发`
> TCSR-SQL: Towards Table Content-aware Text-to-SQL with Self-retrieval
# 摘要
> 基于大型语言模型的Text-to-SQL方法在生成实际应用的SQL查询方面取得了显著进展。然而，面对现实场景中涉及表格内容的复杂问题时，问题中含糊的关键词和不存在的数据库列名常导致现有方法性能不佳。为此，我们创新性地提出了表格内容感知Text-to-SQL自检索（TCSR-SQL）方法，巧妙利用LLM的上下文学习能力，精准提取问题中的数据关键词，并推断相关数据库模式，进而生成种子SQL进行模糊搜索。搜索结果再通过精心设计的编码知识表进行确认，最终通过多轮生成-执行-修订流程，输出精确SQL。为验证这一方法的有效性，我们构建了一个包含1,692对问题-SQL的基准数据集。实验结果显示，TCSR-SQL在执行准确率上比现有顶尖方法提升了至少13.7%，表现卓越。
[Arxiv](https://arxiv.org/abs/2407.01183)
==========
# 语言建模中的显式记忆技术
发布时间：2024年07月01日
`LLM理论` `人工智能`
> : Language Modeling with Explicit Memory
# 摘要
> 受人类大脑记忆层次的启发，我们通过为大型语言模型（LLM）配备显式记忆，有效降低了训练和推理的高昂成本。这种显式记忆不仅成本低于模型参数和文本检索增强生成（RAG），还能使LLM在保持较小参数规模的同时，降低训练和推理成本。我们成功训练了一个2.4B参数的LLM，名为$\text{Memory}^3$，其性能超越了更大规模的LLM和RAG模型，且解码速度更快。此外，我们提出了一种记忆电路理论和相关技术，如记忆稀疏化机制和两阶段预训练方案，以支持知识的外部化和记忆的形成。
[Arxiv](https://arxiv.org/abs/2407.01178)
==========
# GazeNoter：一种协同增强现实笔记工具，通过目光选择大型语言模型建议，精准匹配用户意图。
发布时间：2024年07月01日
`LLM应用` `增强现实`
> GazeNoter: Co-Piloted AR Note-Taking via Gaze Selection of LLM Suggestions to Match Users' Intentions
# 摘要
> 在演讲和讨论中，记笔记不仅有助于后续的总结和整理，还能在问答环节中实时提醒问题和意见，或在讨论中及时表达观点。然而，在智能手机上手动打字记笔记可能会分散注意力，增加认知负担。尽管大型语言模型（LLM）能自动生成总结和重点，但缺乏用户互动可能导致AI生成的内容与用户意图不符。为此，我们设计了GazeNoter，一个AI辅助的增强现实（AR）系统，用户通过AR头显上的注视快速选择LLM生成的建议，实现实时笔记记录。GazeNoter让用户能快速调整LLM输出，形成一个包含用户的AI系统，适用于各种笔记场景。我们通过两项用户研究，验证了GazeNoter在静态和移动条件下的实用性。
[Arxiv](https://arxiv.org/abs/2407.01161)
==========
# 探索与选择学习：覆盖条件下的检索增强生成
发布时间：2024年07月01日
`LLM应用` `信息技术` `人工智能`
> Learning to Explore and Select for Coverage-Conditioned Retrieval-Augmented Generation
# 摘要
> 与数十亿参数的大型语言模型交互时，长篇回复常见，这归功于其强大的参数能力和检索增强功能。虽然详细回复提供了深入见解，但往往包含冗余内容，难以吸引用户。本研究聚焦于用户请求特定信息时查询概述的作用，即在$C^2$场景中。我们构建了QTree，包含10K组多视角信息查询，用于模拟此类场景。利用QTree，我们训练了QPlanner，一个7B模型，生成定制查询概述，遵循覆盖条件。通过自动和人工评估，我们分析了这些概述在增强检索生成中的有效性。实验显示，经过对齐训练的QPlanner能提供满足多样化用户需求的概述。资源已公开在https://github.com/youngerous/qtree。
[Arxiv](https://arxiv.org/abs/2407.01158)
==========
# CPT：实现黑盒优化中一致性的代理调优方法
发布时间：2024年07月01日
`Agent` `人工智能` `机器学习`
> CPT: Consistent Proxy Tuning for Black-box Optimization
# 摘要
> 近期，黑盒调优因高级专有模型的不可访问性而备受瞩目。代理调优通过调整小规模白盒“代理”模型来优化黑盒模型的输出，但仅限于解码阶段，可能导致训练与测试的不一致。为此，我们提出了一致性代理调优（CPT），一种高效的黑盒调优策略。CPT不仅利用了冻结的大型黑盒模型，还结合了小型白盒模型，确保了训练与测试的一致性，从而提升了模型性能。我们的方法专注于对数级计算，具有模型无关性，适用于任何涉及对数分类的任务。实验证明，CPT在大型语言模型和视觉语言模型的黑盒调优中表现卓越。代码已公开，详见https://github.com/chunmeifeng/CPT。
[Arxiv](https://arxiv.org/abs/2407.01155)
==========
# 大型语言模型经过校准，专为二元问答设计
发布时间：2024年07月01日
`LLM理论` `人工智能`
> Calibrated Large Language Models for Binary Question Answering
# 摘要
> 在二元文本分类任务中，如何量化大型语言模型 (LLM) 预测的不确定性仍是一大难题。我们提出的新方法，利用归纳 Venn-Abers 预测器 (IVAP) 来校准二元标签对应的输出令牌概率，不仅在 BoolQ 数据集上超越了传统温度缩放方法，还确保了预测的高质量和概率的准确校准。这一进展不仅深化了我们对 LLM 校准技术的理解，更为二元问答任务中的不确定性评估提供了实用方案，从而提升了 LLM 预测的可解释性和可靠性。
[Arxiv](https://arxiv.org/abs/2407.01122)
==========
# 大型语言模型与世界级小说作者在创意写作上的较量：Pron vs Prompt，究竟谁能胜出？
发布时间：2024年07月01日
`LLM应用` `人工智能`
> Pron vs Prompt: Can Large Language Models already Challenge a World-Class Fiction Author at Creative Text Writing?
# 摘要
> 在众多语言任务中，大型语言模型（LLMs）超越普通人类已成为常态，创意写作也不例外。然而，我们不禁要问：LLMs能否与顶尖小说家一较高下？为此，我们举办了一场AI与人类的创意对决，邀请了获奖小说家Patricio Pron与顶尖模型GPT-4同台竞技。双方各自构思三十个标题，并据此创作故事。我们借鉴Boden的创造力定义制定了评估标准，并收集了5,400份文学专家的评价。结果显示，LLMs在创意写作领域仍远未达到人类顶尖水平，仅凭扩大模型规模或许难以实现这一飞跃。
[Arxiv](https://arxiv.org/abs/2407.01119)
==========
# BERGEN：一款专为检索增强生成技术打造的基准库
发布时间：2024年07月01日
`RAG` `问答系统` `开源软件`
> BERGEN: A Benchmarking Library for Retrieval-Augmented Generation
# 摘要
> Retrieval-Augmented Generation（RAG）通过外部知识增强了大型语言模型。随着生成型 LLM 的兴起，众多 RAG 方法涌现，涵盖了评估数据集、集合、指标、检索器和 LLM 等多种配置。然而，基准测试的不一致性为方法比较和组件影响理解带来了挑战。本研究探索了 RAG 系统评估的最佳实践，并推出了 BERGEN，一个标准化 RAG 实验的端到端开源库。在专注于问答的深入研究中，我们评估了各类顶尖检索器、重排序器和 LLM，并分析了现有 RAG 指标和数据集。BERGEN 库已开放源代码，访问地址为 \url{https://github.com/naver/bergen}。
[Arxiv](https://arxiv.org/abs/2407.01102)
==========
# IBSEN 系统通过导演与演员代理的协作，实现了可控且互动的戏剧剧本生成。
发布时间：2024年07月01日
`Agent` `人工智能`
> IBSEN: Director-Actor Agent Collaboration for Controllable and Interactive Drama Script Generation
# 摘要
> 大型语言模型在故事创作和角色扮演方面表现出色，但现有代理主要关注个体行为合理性，难以全局控制故事发展。为此，我们提出IBSEN框架，通过导演与演员代理的协作，生成可控的戏剧剧本。导演代理根据用户需求编写情节大纲，指导演员代理进行角色扮演，并根据人类玩家参与情况调整情节，确保故事向预定目标推进。我们通过创建新戏剧情节并观察代理互动来评估框架，结果表明，该框架能从简要大纲生成丰富多样的完整剧本，同时保持角色特性。相关代码和资源已公开在https://github.com/OpenDFM/ibsen。
[Arxiv](https://arxiv.org/abs/2407.01093)
==========
# 重新审视基于LLM的偏好评估方法
发布时间：2024年07月01日
`LLM理论` `人工智能`
> Rethinking LLM-based Preference Evaluation
# 摘要
> 近期，基于大型语言模型的偏好评估广泛用于比较模型响应对，但存在对长响应的偏差，质疑其可靠性。我们通过控制实验发现，胜率受期望性和信息量两大因素影响，前者与长度无关，后者与长度相关。长度通过信息量影响评估，但可靠指标应独立于长度等无关因素。为此，我们提出AdapAlpaca调整方法，通过匹配参考与测试答案长度，确保评估公平，提升可靠性。
[Arxiv](https://arxiv.org/abs/2407.01085)
==========
# 2023年全球AI技术创新大赛第一赛道冠军方案
发布时间：2024年07月01日
`LLM应用` `人工智能`
> First Place Solution of 2023 Global Artificial Intelligence Technology Innovation Competition Track 1
# 摘要
> 本文介绍了我们在全球人工智能技术创新竞赛第一赛道——医学影像诊断报告生成中的冠军方案。我们选用CPT-BASE作为基础模型，在预训练阶段，我们摒弃了传统的掩码语言建模，转而采用跨度掩码策略，逐步提升掩码比例，进行去噪自编码预训练。微调阶段，我们创新性地引入了迭代检索增强和噪声感知相似度桶提示策略，构建迷你知识库，丰富模型输入，同时通过相似度桶精准识别噪声，引导模型生成更优质的诊断报告。最终，我们的单模型在A榜上斩获2.321分，多模型融合更是在A、B榜上分别取得2.362和2.320的高分，稳居榜首。
[Arxiv](https://arxiv.org/abs/2407.01271)
==========
# SecGenAI：提升澳大利亚关键技术领域内云端生成式AI应用的安全防护
发布时间：2024年07月01日
`RAG` `云计算`
> SecGenAI: Enhancing Security of Cloud-based Generative AI Applications within Australian Critical Technologies of National Interest
# 摘要
> 生成式AI技术的迅猛发展，为澳大利亚的关键技术领域带来了革新机遇，同时也引发了独特的安全挑战。本文提出的SecGenAI框架，专注于云端GenAI应用，特别是检索增强生成系统，全面涵盖功能、基础设施和治理层面的安全需求。通过整合端到端的安全分析，SecGenAI强调数据隐私、安全部署及共享责任，与澳大利亚的隐私和伦理原则及相关部门指南相契合，有效防范数据泄露、攻击和模型逆向等风险。该框架融合尖端机器学习与强效安全措施，确保合规性，提升GenAI系统的可靠性，为智能系统领域贡献了安全实施策略，推动AI创新，捍卫国家利益。
[Arxiv](https://arxiv.org/abs/2407.01110)
==========
# 解决语言模型中的位置偏差问题：一种机制性解决方案
发布时间：2024年07月01日
`LLM理论` `人工智能`
> Eliminating Position Bias of Language Models: A Mechanistic Approach
# 摘要
> 位置偏差已成为现代语言模型的一大难题，模型往往根据内容在上下文中的位置来优先处理。这种偏差不仅导致模型失灵，还影响了其在多领域的性能和可靠性。我们深入分析发现，几乎所有顶尖语言模型都采用的因果注意力和相对位置编码是位置偏差的根源。具体而言，因果注意力使模型偏爱远距离内容，而相对位置编码则倾向于近距离内容。此外，视觉-语言模型中也存在这一问题。为此，我们提出了一种无需训练的零-shot方法，通过改变因果注意力为段间双向注意力，并利用模型注意力值来重新排序段，从而在段级别实现位置不变推理（PINE）。这一创新方法有效消除了位置偏差，显著提升了模型在需要评估推理对的任务中的性能，甚至在某些情况下超越了GPT-4。
[Arxiv](https://arxiv.org/abs/2407.01100)
==========
# Face4RAG：评估中文检索增强生成的事实一致性工具
发布时间：2024年07月01日
`RAG` `人工智能`
> Face4RAG: Factual Consistency Evaluation for Retrieval Augmented Generation in Chinese
# 摘要
> 传统RAG模型中常见的事实不一致错误，催生了事实一致性评估（FCE）的研究。尽管已有多种FCE方法，但它们仅在特定LLM生成的数据集上评估，缺乏全面基准，导致这些方法在其他LLM或新错误类型上的表现未被探索。为此，我们提出了首个独立于LLM的RAG事实一致性评估基准Face4RAG，包含合成与真实数据集，支持特定错误类型与真实分布的评估。我们发现现有FCE方法无法识别逻辑谬误，即答案与参考间的逻辑结构不匹配。为此，我们提出了L-Face4RAG方法，通过逻辑保持答案分解与事实逻辑FCE设计，显著提升了事实不一致检测的性能，超越了最初的RAG任务。基准与方法均已公开。
[Arxiv](https://arxiv.org/abs/2407.01080)
==========
# 采用混合 RAG 增强的多模态 LLM，结合基于扩散的合同理论，为安全医疗数据管理提供创新解决方案。
发布时间：2024年07月01日
`RAG` `数据管理`
> Hybrid RAG-empowered Multi-modal LLM for Secure Healthcare Data Management: A Diffusion-based Contract Theory Approach
# 摘要
> 在医疗保健领域，安全的数据管理和有效的数据共享变得至关重要。生成式人工智能的发展使得多模态大型语言模型（MLLMs）成为管理医疗数据的关键工具。然而，开发医疗MLLMs仍面临挑战，如数据安全和新鲜度问题，这些问题影响MLLMs的输出质量。本文提出了一种混合检索增强生成（RAG）赋能的医疗MLLMs框架，用于医疗数据管理。该框架通过分层跨链架构确保安全数据训练，并通过混合RAG提高输出质量，该方法利用多模态指标过滤单模态RAG结果，并将这些结果作为额外输入纳入MLLMs。此外，我们使用信息年龄评估数据新鲜度影响，并利用契约理论激励数据持有者分享新鲜数据，减轻数据共享中的信息不对称。最后，我们利用基于生成扩散模型的强化学习算法来识别高效数据共享的最佳契约。数值结果证明了所提方案的有效性，实现了安全和高效的医疗数据管理。
[Arxiv](https://arxiv.org/abs/2407.00978)
==========
# 数据动态交易：基于常识AI代理的流量导向数据平台
发布时间：2024年07月01日
`LLM应用` `自动驾驶` `智慧城市`
> Data on the Move: Traffic-Oriented Data Trading Platform Powered by AI Agent with Common Sense
# 摘要
> 在数字化浪潮中，数据如黄金般珍贵，尤其在自动驾驶等尖端技术领域。然而，数据交易之路并非坦途，定价难题和信任缺失是其两大障碍。为此，我们创新推出Data on The Move（DTM）平台，它融合交通模拟、数据交易与AI智能，为数据价值评估和交易机制注入智慧。借助大型语言模型（LLMs）的洞察力，DTM通过多轮互动与模拟，精准定价交通数据。同时，通过模拟交通系统、多角色互动及市场中的个体行为多样性，DTM验证了定价方法的可靠性。在DTM的舞台上，各类交通实体如车联网车辆和交通灯控制器，共同参与信息采集、定价、交易与决策。模拟结果显示，基于AI代理的定价策略，不仅提升了数据交易的合理性，更显著提高了交通效率，彰显了DTM的实效与价值。这一创举，不仅首次将LLMs应用于数据定价，更在智能车联与智慧城市领域，引领了数据交易的新风潮。
[Arxiv](https://arxiv.org/abs/2407.00995)
==========
# 移动-Bench：一个针对基于 LLM 的移动代理的评估基准
发布时间：2024年07月01日
`Agent` `人机交互` `移动应用`
> Mobile-Bench: An Evaluation Benchmark for LLM-based Mobile Agents
# 摘要
> 随着LLM技术的飞速发展，基于LLM的智能代理在人机交互研究中备受瞩目。但遗憾的是，针对这些移动代理的基准测试却寥寥无几。这些测试面临三大难题：一是仅依赖界面操作的效率低下，二是单一应用内的指令无法全面评估代理的复杂推理与决策能力，三是现有评估标准难以准确衡量连续动作的执行过程。为此，我们创新性地推出了Mobile-Bench基准，旨在全面评估LLM移动代理的各项能力。我们通过引入103个API，优化了传统界面操作，大幅提升了任务执行效率。同时，我们精心收集了结合真实用户需求与LLM增强的评估数据，并将其细分为SAST、SAMT和MAMT三个层次，以适应不同难度的任务需求。Mobile-Bench共收录832项数据，其中200余项专为多应用协作场景设计。此外，我们还首创了CheckPoint评估指标，精准判断代理在规划与推理过程中的关键节点。
[Arxiv](https://arxiv.org/abs/2407.00993)
==========
# 多模态大型语言模型中，类人对象概念的表示自然而然地形成。
发布时间：2024年07月01日
`LLM理论` `认知科学` `神经科学`
> Human-like object concept representations emerge naturally in multimodal large language models
# 摘要
> 人类对自然物体的概念化与分类一直是认知科学和神经科学的研究热点，揭示了人类感知与认知的核心机制。随着大型语言模型（LLMs）的迅猛发展，一个引人入胜的问题浮现：这些模型能否通过海量语言与多模态数据的输入，形成类似人类的物体认知？本研究通过行为与神经影像分析，探索了LLMs中物体概念的表示与人类认知的契合度。我们收集了470万个来自LLM与多模态LLM（MLLM）的三元组判断，构建了1,854个自然物体的低维嵌入，这些66维嵌入不仅稳定且富有预测性，更呈现出与人类心理相似的语义聚类。令人瞩目的是，这些嵌入的维度清晰可解，暗示LLM与MLLM已形成类似人类的概念性物体认知。深入分析表明，模型嵌入与大脑多个功能区域的神经活动模式高度吻合，证实了LLMs的物体表示虽与人类不尽相同，却共享着反映人类概念知识核心结构的基本共性。这项研究深化了我们对机器智能的认识，并为构建更贴近人类的人工认知系统提供了宝贵洞见。
[Arxiv](https://arxiv.org/abs/2407.01067)
==========
# 共情基础探索：通过多模态交互与大型语言模型，与对话代理共同探索共情机制。
发布时间：2024年07月01日
`Agent` `人机交互` `情感计算`
> Empathic Grounding: Explorations using Multimodal Interaction and Large Language Models with Conversational Agents
# 摘要
> 我们提出了“共情基础”概念，扩展了Clark的对话基础理论，强调听众需理解说话者的情感状态。当说话者情绪突出时，共情基础尤为重要，它通过传递命题和情感理解，使沟通更高效可靠。情感表达和共情反应均可多模态化，涉及面部表情等非言语信号。因此，具身代理的共情模型应多模态化，以促进自然沟通。我们构建了一个多模态模型，结合用户的话语和面部表情，利用大型语言模型生成多模态的共情反应。此外，我们设计了一个测试平台，通过人形机器人访谈用户过去的痛苦经历，并由用户评价机器人的共情表现。实验对比显示，共情基础显著提升了用户对共情、理解、情绪智力和信任的感知。我们的研究凸显了情绪意识和多模态在对话代理中生成有效反应的重要性。
[Arxiv](https://arxiv.org/abs/2407.01824)
==========
# 每一句都夯实：通过交错引用与声明生成，提升检索增强型大型语言模型的性能
发布时间：2024年07月01日
`RAG` `问答系统` `知识密集型任务`
> Ground Every Sentence: Improving Retrieval-Augmented LLMs with Interleaved Reference-Claim Generation
# 摘要
> RAG 在知识密集型任务中广泛用于提升 LLM 性能。近期，ATG 通过提供引用支持模型响应，增强了生成内容可信度。传统方法多采用粗粒度归属，存在可验证性不足和核查时间成本高的问题。本文提出的 ReClaim 方法，通过细粒度引用，在长篇问答中为每个答案句子提供精确引用，实验证明其有效性。
[Arxiv](https://arxiv.org/abs/2407.01796)
==========
# 文本感知扩散在政策学习中的应用
发布时间：2024年07月01日
`Agent` `机器人` `人工智能`
> Text-Aware Diffusion for Policy Learning
# 摘要
> 通过强化学习训练代理实现特定目标或行为，尤其是在缺乏专家演示时，通常需要临时设计奖励函数，这很快变得复杂。为此，我们引入了文本感知扩散策略学习（TADPoLe），利用预训练的文本条件扩散模型生成零-shot奖励信号，促进文本对齐策略的学习。我们相信，大规模预训练模型蕴含的丰富先验知识，不仅能指导策略与文本一致，还能与互联网数据中提炼的自然性相契合。实验证明，TADPoLe能在不同环境中，无需真实奖励或专家演示，零-shot学习自然语言描述的新目标和连续运动行为，且在人类评估中表现更自然。此外，TADPoLe在机器人操作任务中也展现出竞争力。
[Arxiv](https://arxiv.org/abs/2407.01903)
==========
# GRASP：一款基于网格的基准测试，专为评估常识空间推理能力而设计。
发布时间：2024年07月01日
`Agent` `人工智能`
> GRASP: A Grid-Based Benchmark for Evaluating Commonsense Spatial Reasoning
# 摘要
> 空间推理，这一人类认知的关键能力，不仅应用广泛，而且是常识技能的核心组成部分，它超越了纯粹的语言依赖，要求一定程度的规划以达成可行（而非最优）方案。当前的常识空间推理（CSR）评估往往聚焦于大型语言模型（LLM）对文本空间描述的解读，而非直接检验其针对空间推理挑战所制定的计划。为此，我们创建了名为$\textbf{GRASP}$的大规模基准，涵盖16,000个网格环境，每个环境设定代理解决能量收集问题。这些环境细分为100个实例，每实例基于160种独特网格配置，涉及五类能量分布、两种起始位置、两类障碍布局及三种代理限制。通过GRASP，我们对比了传统方法（如随机游走与贪心搜索）与尖端LLM（如GPT-3.5-Turbo和GPT-4o）的表现。实验揭示，即便是最先进的LLM，在持续提供满意解方面也面临挑战。
[Arxiv](https://arxiv.org/abs/2407.01892)
==========
# 深入探索 LLMsuite 中的高级大型语言模型
发布时间：2024年07月01日
`LLM理论` `人工智能`
> Exploring Advanced Large Language Models with LLMsuite
# 摘要
> 本教程深入探讨了 ChatGPT 和 Gemini 等大型语言模型的发展，不仅揭示了其进步，也直面了挑战。针对时间知识截断、数学错误和信息生成不准确等固有限制，教程提出了创新的解决方案，如 RAG、PAL 和 ReAct、LangChain 框架。这些技术的融合显著提升了 LLM 在复杂推理和任务执行中的性能与可靠性。此外，教程还详细介绍了微调策略，涵盖了指令微调、LoRA 等高效参数方法，以及 RLHF 和 ReST 等强化学习技术。同时，对 LLM 的转换器架构和训练技术进行了全面梳理。所有这些技术的实现工具箱已在 GitHub 上公开，供大家自由使用。
[Arxiv](https://arxiv.org/abs/2407.12036)
==========
# AutoFlow：自动构建大型语言模型代理的工作流程
发布时间：2024年07月01日
`Agent` `人工智能` `软件开发`
> AutoFlow: Automated Workflow Generation for Large Language Model Agents
# 摘要
> 大型语言模型 (LLM) 在理解复杂自然语言方面取得了显著进展。其中，基于 LLM 的 AI 代理是一个重要应用，它结合 LLM 能力与外部工具解决复杂任务。为确保代理高效可靠，通常需手动设计工作流程。然而，这既耗时又依赖专业知识，限制了大规模应用。为此，我们推出 AutoFlow 框架，自动生成代理流程。该框架采用自然语言程序格式，并通过优化流程质量。此外，提供两种生成方法，适用于各类 LLM。实验证明，AutoFlow 能产出稳健可靠的流程。我们认为，自然语言流程的自动生成与解释，是应对复杂任务的新兴范式，尤其在 LLM 快速发展的背景下。项目源码已公开于 https://github.com/agiresearch/AutoFlow。
[Arxiv](https://arxiv.org/abs/2407.12821)
==========
# 大型语言模型在处理标记级别的临床命名实体识别任务时显得力不从心。
发布时间：2024年06月30日
`LLM应用` `信息学`
> Large Language Models Struggle in Token-Level Clinical Named Entity Recognition
# 摘要
> 大型语言模型（LLM）在医疗保健等领域的革新尤为显著，尤其是在罕见疾病的数据稀缺、复杂性和特异性挑战下。临床领域的命名实体识别（NER）是提取临床文本信息的关键任务。尽管LLM潜力巨大，但研究多聚焦于文档级NER，忽略了实体的精确位置。此外，ChatGPT在令牌级NER的适应性也受到关注。然而，本地开源LLM在临床文本令牌级NER的应用研究尚存空白。本研究通过对比专有与本地LLM在令牌级临床NER的有效性，填补了这一研究空白。我们通过零-shot、少-shot提示、RAG及指令微调等实验，深入分析了LLM在令牌级NER的挑战，特别是在罕见疾病领域，并提出了改进方向。这项研究不仅缩小了医疗信息学的研究差距，还为LLM在医疗保健领域的精细化应用提供了新视角。
[Arxiv](https://arxiv.org/abs/2407.00731)
==========
# CAMON：多对象导航中基于 LLM 对话的合作代理
发布时间：2024年06月30日
`Agent` `机器人` `智能家居`
> CAMON: Cooperative Agents for Multi-Object Navigation with LLM-based Conversations
# 摘要
> 家用服务机器人的视觉导航任务至关重要，随着任务复杂性增加，多机器人间的有效沟通与协作变得不可或缺。尽管大型语言模型（LLM）在实体代理中展现出卓越的理解与规划能力，但其在家庭环境中，特别是多代理通过协作完成复杂导航任务的应用，仍属未知领域。为此，本文提出一种基于LLM的分散式多代理导航框架，通过创新沟通触发动态领导结构，实现快速团队共识与高效沟通，显著提升导航与协作效率。该框架采用的新型沟通方案，确保在多对象导航任务中无冲突且稳定，即便团队规模扩大亦能保持性能。
[Arxiv](https://arxiv.org/abs/2407.00632)
==========
# 多模谐振器实现量子态传输
发布时间：2024年06月30日
`Agent` `量子计算` `通信技术`
> Quantum State Transfer via a Multimode Resonator
# 摘要
> 大规模容错超导量子计算要求快速量子通信连接不同芯片上的量子比特，并需要长程耦合器来执行高效的量子错误校正。为此，量子通道的最佳模型是介于单模腔和连续模式波导之间的多模谐振器。本文提出了一种量子态传输方法，其耦合强度与通道的自由光谱范围相当（$g\simΔ_{\text{fsr}}$）。该方案结合了基于STIRAP的单模腔方法和长波导抛接协议的优点，实现了低损耗和高速度的传输。
[Arxiv](https://arxiv.org/abs/2407.00683)
==========
# GenderBias-VL：利用反事实探针评估视觉语言模型中的性别偏见
发布时间：2024年06月30日
`LLM应用` `人工智能` `性别研究`
> GenderBias-\emph{VL}: Benchmarking Gender Bias in Vision Language Models via Counterfactual Probing
# 摘要
> 大型视觉-语言模型（LVLMs）虽广泛应用，却存在显著性别偏见。现有评估多聚焦于群体层面，忽视了个体公平性。本研究填补空白，首次推出GenderBias-VL基准，以反事实视觉问题深入剖析LVLMs的职业性别偏见。通过创新方法，我们构建了包含34,581对反事实的基准，覆盖177个职业，全面评估了15个开源模型及商业API。研究发现，LVLMs普遍偏见严重。我们的基准不仅提供详尽数据集和最新排行榜，更深化了对模型偏见的理解。
[Arxiv](https://arxiv.org/abs/2407.00600)
==========
# 利用大型语言模型预测宏观经济
发布时间：2024年06月30日
`LLM应用` `宏观经济` `时间序列分析`
> Macroeconomic Forecasting with Large Language Models
# 摘要
> 本文通过比较分析，探讨了大型语言模型（LLM）与传统宏观时间序列预测方法的准确性。LLM 因能捕捉复杂数据模式并快速适应不同领域，近年来在预测领域备受青睐。但与传统方法相比，LLM 在宏观经济时间序列预测的有效性仍待探讨。为此，我们以 FRED-MD 数据库为基准，对 LLM 与传统方法进行了严格对比。研究结果揭示了 LLM 在宏观经济预测中的优势与局限，为其在实际应用中的可行性提供了重要见解。
[Arxiv](https://arxiv.org/abs/2407.00890)
==========
# 大型语言模型无意中揭示真相，我们正利用其逻辑漏洞发起越狱攻击。
发布时间：2024年06月30日
`LLM应用` `人工智能`
> Large Language Models Are Involuntary Truth-Tellers: Exploiting Fallacy Failure for Jailbreak Attacks
# 摘要
> 语言模型在生成谬误和欺骗性推理时显得力不从心。面对生成欺骗性输出的任务，它们往往不经意间透露出真实信息，却误以为这些信息是虚假的。基于这一弱点，我们设计了一种“越狱”攻击策略，诱使对齐的语言模型输出恶意内容。具体操作是，让模型编造一个看似合理实则谬误的有害行为流程。由于LLM通常将谬误视为无害的虚假信息，这巧妙地避开了安全防护。然而，由于模型无法真正创造谬误，其提出的解决方案实际上是有害的。我们在五个安全对齐的大型语言模型上测试了这一方法，与四种现有越狱技术对比，结果显示我们的方法在产生更有害输出方面表现出色。这些发现不仅限于模型安全领域，还可能应用于自我验证和幻觉等领域。
[Arxiv](https://arxiv.org/abs/2407.00869)
==========
# 探索基于物理信息的决策转换器在配电系统恢复中的应用：方法与性能分析
发布时间：2024年06月30日
`LLM应用` `人工智能`
> Exploring a Physics-Informed Decision Transformer for Distribution System Restoration: Methodology and Performance Analysis
# 摘要
> 随着传感与计算技术的飞跃，基于深度强化学习的策略在应对复杂多变的配电系统恢复挑战中崭露头角。但DRL对数据的依赖性，为解决大规模复杂系统的DSR问题带来了难题。借鉴大型语言模型等基础模型在多领域的革新力量，本文提出了一种新思路，即借助LLMs的强大计算力，突破传统DRL在DSR中的可扩展性瓶颈。本研究首次尝试将LLMs等基础模型引入电力系统运营，以重塑DRL的应用。我们的创新点包括：1）开发了一个由LLM赋能的物理信息决策变换器框架，旨在革新传统DRL的DSR方法；2）在框架初创阶段，通过对比研究评估其解决DSR问题的性能。尽管本文聚焦于DSR操作，该PIDT框架同样适用于优化电力系统中的序列决策过程。
[Arxiv](https://arxiv.org/abs/2407.00808)
==========
# 通过步骤控制DPO，我们利用逐步错误来提升数学推理能力。
发布时间：2024年06月30日
`LLM应用` `软件开发`
> Step-Controlled DPO: Leveraging Stepwise Error for Enhanced Mathematical Reasoning
# 摘要
> 直接偏好优化 (DPO) 在提升大型语言模型 (LLM) 的推理和对齐能力方面已见成效。我们提出的步骤控制 DPO (SCDPO)，通过生成特定步骤开始出错的数学推理负样本来实现自动化的逐步错误监督，从而在 DPO 训练中帮助模型更精准地识别和纠正推理错误。实证研究表明，SCDPO 在代码集成和思维链解决方案中均优于传统 DPO，显著提升了三个 SFT 模型的性能。定性分析进一步证实了 SCDPO 在精准定位数学解题错误方面的优势。应用 SCDPO 于 InternLM2-20B 模型，使其在 GSM8K 和 MATH 测试中分别达到 88.5% 和 58.1% 的高分，彰显了我们方法的强大潜力。
[Arxiv](https://arxiv.org/abs/2407.00782)
==========
# 文本摘要质量评估方法比较研究
发布时间：2024年06月30日
`LLM应用` `文本摘要`
> A Comparative Study of Quality Evaluation Methods for Text Summarization
# 摘要
> 在 NLP 领域，评估文本摘要一直是个难题。依赖参考摘要的自动指标常不适用，而人工评估成本高昂。为此，我们提出了一种基于 LLM 的新方法。通过对比八种自动指标、人工评估及我们的 LLM 方法，我们评估了七种 SOTA 摘要模型。实验表明，LLM 评估与人工评估高度吻合，而常用自动指标如 ROUGE-2、BERTScore 和 SummaC 则表现不佳。基于这些发现，我们设计了一个 LLM 驱动的框架，旨在自动评估和提升文本摘要质量，预计将受到社区的广泛关注。
[Arxiv](https://arxiv.org/abs/2407.00747)
==========
# LLM4GEN：借助 LLM 的语义表征实现文本至图像的生成
发布时间：2024年06月30日
`LLM应用` `图像生成` `人工智能`
> LLM4GEN: Leveraging Semantic Representation of LLMs for Text-to-Image Generation
# 摘要
> 扩散模型在文本到图像生成领域取得了显著成就，但在处理复杂密集的提示时仍面临挑战。为此，我们提出了 **LLM4GEN** 框架，通过结合大型语言模型的语义表示，显著提升了文本到图像扩散模型的语义理解能力。借助特制的交叉适配器模块 (CAM)，LLM4GEN 能无缝融入各类扩散模型，实现即插即用的增强效果。为深化对复杂提示的理解，我们构建了 LAION-refined 数据集，包含百万级改进描述的文本-图像对，并引入了 DensePrompts 以全面评估生成任务。实验显示，仅用 ELLA 所需训练数据的 10%，LLM4GEN 便大幅提升了 SD1.5 和 SDXL 的语义对齐，颜色表现分别提升 7.69% 和 9.60%。在 DensePrompts 上的广泛测试进一步证明，LLM4GEN 在样本质量、图像-文本对齐及人类评估方面均超越了现有顶尖模型。项目详情请访问：\textcolor{magenta}{\url{https://xiaobul.github.io/LLM4GEN/}}
[Arxiv](https://arxiv.org/abs/2407.00737)
==========
# 利用 LLM 注释系统，我们能够扩展技术接受度的分析范围。
发布时间：2024年06月30日
`LLM应用` `技术产品` `市场研究`
> Scaling Technology Acceptance Analysis with Large Language Model (LLM) Annotation Systems
# 摘要
> 技术接受模型能有效预测用户对新技术产品的接受度。传统调查方法虽常用，但成本高且操作繁琐。我们探索了一种新方法：利用大型语言模型对在线用户生成内容（如评论）进行标注。基于接受与使用统一理论，我们设计了LLM标注系统，将评论数据化。通过两项研究，我们验证了该系统标注的一致性与准确性，发现其表现优异，甚至超越了人类专家的标注一致性。这表明LLM不仅能替代传统调查，还能为技术设计与采用提供更深入的见解。
[Arxiv](https://arxiv.org/abs/2407.00702)
==========
# BAPO：大型语言模型中个性化对齐的基础锚定偏好优化方法
发布时间：2024年06月30日
`LLM理论` `人工智能` `个性化服务`
> BAPO: Base-Anchored Preference Optimization for Personalized Alignment in Large Language Models
# 摘要
> 尽管将大型语言模型与人类偏好对齐已取得显著成效，但在满足多样化用户偏好的同时保留先前知识仍面临挑战。本文探讨了个性化偏好优化对 LLM 的影响，发现知识损失与偏好多样性密切相关。虽然现有方法通过 KL 约束来维持模型一致性，但在个性化偏好面前，这些方法难以保持知识与对齐的平衡。为此，我们提出了 Base-Anchored Preference Optimization (BAPO)，一种简便高效的方法，通过利用参考模型的初始响应，既减轻遗忘又适应个性化对齐。BAPO 在适应用户多样偏好的同时，对全局知识或对齐的影响微乎其微。实验结果显示，BAPO 在多种场景下均表现出色。
[Arxiv](https://arxiv.org/abs/2407.00693)
==========
# HRDE：一款专为中文健康谣言检测设计的检索增强型大型语言模型，兼具可解释性。
发布时间：2024年06月30日
`RAG` `健康信息`
> HRDE: Retrieval-Augmented Large Language Models for Chinese Health Rumor Detection and Explainability
# 摘要
> 随着健康意识的提升，互联网上的健康信息传播愈发迅速广泛。然而，真假难辨的健康谣言也悄然潜伏，对公众健康构成威胁。当前，中国健康谣言研究面临数据集匮乏和检测方法不足的挑战。为此，我们通过网络爬虫和数据处理，构建了包含112万条谣言的HealthRCN数据集，这是目前最大的中文健康谣言数据集。基于此，我们研发了检索增强型大型语言模型HRDE，它能精准识别谣言并提供解释，助力用户辨别信息真伪。实验表明，HRDE在谣言检测和回答质量上超越了包括GPT-4-1106-Preview在内的所有模型，准确率高达91.04%，F1分数达91.58%。
[Arxiv](https://arxiv.org/abs/2407.00668)
==========
# 知识链：借助知识图谱的学习，将知识推理融入大型语言模型，实现更深层次的智能整合。
发布时间：2024年06月30日
`LLM应用` `知识图谱`
> Chain-of-Knowledge: Integrating Knowledge Reasoning into Large Language Models by Learning from Knowledge Graphs
# 摘要
> 大型语言模型 (LLM) 在复杂的自然语言处理任务中表现卓越，尤其是在知识推理方面。尽管知识图谱 (KGs) 中的知识推理研究已相当成熟，但 LLM 中的这一领域仍有待深入探索。本文提出的 Chain-of-Knowledge 框架，不仅涵盖了数据集构建，还包括了创新的模型学习方法。我们通过规则挖掘在 KGs 上构建了 KnowReason 数据集，并针对模型学习中的过拟合问题，引入了模拟人类探索过程的试错机制，以提升 CoK 的性能。实验结果表明，CoK 不仅能提升 LLM 在知识推理上的表现，还能在一般推理任务中取得优异成绩。
[Arxiv](https://arxiv.org/abs/2407.00653)
==========
# DP-MLM：运用掩码语言模型实现差分隐私的文本改写
发布时间：2024年06月30日
`LLM应用` `网络安全` `数据隐私`
> DP-MLM: Differentially Private Text Rewriting Using Masked Language Models
# 摘要
> 近期，文本隐私化任务采用了$\textit{文本重写}$的形式，通过生成（大型）语言模型对输入文本进行混淆。虽然这些方法在隐私保护方面表现出色，但它们依赖的自回归模型缺乏上下文化重写过程的机制。为此，我们提出了$\textbf{DP-MLM}$，一种基于掩码语言模型（MLMs）的新方法，以语义相似且混淆的方式重写文本。我们采用逐标记重写的简单技术，发现与依赖大型解码器模型的方法相比，仅编码器的MLMs在低$\varepsilon$水平下效用保持更佳。此外，MLMs允许更灵活的重写机制定制。我们公开了$\textbf{DP-MLM}$的代码，可在https://github.com/sjmeis/DPMLM获取。
[Arxiv](https://arxiv.org/abs/2407.00637)
==========
# Tarsier：大型视频描述模型训练与评估的秘方
发布时间：2024年06月30日
`LLM应用` `视频处理` `人工智能`
> Tarsier: Recipes for Training and Evaluating Large Video Description Models
# 摘要
> 在视频理解领域，生成细粒度描述是一项基础挑战。我们推出的 Tarsier 系列模型，通过 CLIP-ViT 独立编码视频帧并利用 LLM 处理时间关系，展现了卓越的视频描述能力。经过精心设计的两阶段训练，Tarsier 在视频描述方面超越了所有开源模型，在人类评估中领先最强模型 $+51.4\%$。同时，它与顶尖专有模型不相上下，对 GPT-4V 领先 $+12.3\%$，对 Gemini 1.5 Pro 稍逊 $-6.7\%$。Tarsier 不仅在视频描述上表现出色，还刷新了九个公共基准的记录，涵盖多选 VQA、开放式 VQA 和零-shot 视频字幕等多个领域。此外，我们引入了新的视频描述模型评估基准，包含多样化且复杂度各异的视频数据集，以及专为细粒度视频描述质量评估设计的自动方法。所有模型和评估基准已在 \url{https://github.com/bytedance/tarsier} 公开。
[Arxiv](https://arxiv.org/abs/2407.00634)
==========
# 迭代纳什策略优化：借助无悔学习，使大型语言模型与广泛偏好相契合
发布时间：2024年06月30日
`LLM理论` `人工智能` `博弈论`
> Iterative Nash Policy Optimization: Aligning LLMs with General Preferences via No-Regret Learning
# 摘要
> 基于人类反馈的强化学习（RLHF）在使大型语言模型与人类偏好对齐方面取得了显著成就。然而，现有的基于奖励的RLHF方法，如遵循Bradley-Terry模型假设，可能未能充分捕捉人类偏好的复杂性。本文中，我们提出了一种新的博弈论视角下的RLHF方法，通过将问题建模为双人博弈，并引入迭代纳什策略优化（INPO）算法。该算法通过策略自我对抗学习，无需估计单个响应的胜率，从而降低了计算成本。我们在多个基准测试中验证了INPO的有效性，显著超越了现有方法。此外，研究还表明，结合KL正则化能有效提升响应长度控制的性能。
[Arxiv](https://arxiv.org/abs/2407.00617)
==========
# WallFacer：借助 N 体问题，引领 Transformer 模型训练摆脱长上下文的困境
发布时间：2024年06月30日
`LLM理论` `人工智能` `高性能计算`
> WallFacer: Guiding Transformer Model Training Out of the Long-Context Dark Forest with N-body Problem
# 摘要
> 近年来，基于Transformer的LLMs因其卓越性能备受瞩目，但长序列训练的效率与可扩展性仍是一大挑战。现有方法或受限于注意力头数量，或面临高通信开销。本文提出，注意力计算可视为n体问题的特例。基于此，我们推出WallFacer系统，采用创新的多维环序列并行技术，优化通信模式并提供更多调整空间。实验表明，WallFacer在多种环境下大幅领先现有技术，性能提升高达77.12%。
[Arxiv](https://arxiv.org/abs/2407.00611)
==========
# 在AI时代，我们需保持警觉，从创造内容到验证其真实性。
发布时间：2024年06月30日
`LLM应用`
> Staying vigilant in the Age of AI: From content generation to content authentication
# 摘要
> 本文呈现的长江海项目，是对抗生成式AI（GAI）虚假内容的一项创新举措。通过模拟学术会议平台上的实验，我们揭示了公众在辨识AI制造的虚假信息上的困境，尤其是GAI制造的逼真内容。为此，我们创新性地运用ChatGPT等大型语言模型进行真实性评估，并设计了一套工作流程，旨在提升公众识别虚假信息的能力。该流程已应用于Telegram的智能机器人，助力用户在对话中辨别文本真伪。项目采用双重策略：一方面生成虚假内容以洞察其机制，另一方面研发评估技术以削弱其影响。此外，我们还构想了以阅读眼镜和夹子形态的事实核查可穿戴设备。这一计算媒体艺术项目，深刻体现了技术进步、伦理考量与社会意识间的复杂交织。
[Arxiv](https://arxiv.org/abs/2407.00922)
==========
# 从内省到实践精华：探究多模态情境学习中演示的系统性分析
发布时间：2024年06月30日
`LLM应用` `人工智能` `计算机视觉`
> From Introspection to Best Practices: Principled Analysis of Demonstrations in Multimodal In-Context Learning
# 摘要
> 受 LLM 的 ICL 能力启发，多模态 LLM 在提供图像-文本对演示时也展现出类似 ICL 能力。然而，关于多模态 ICL 的工作原理研究较少。我们系统评估了不同规模模型在新颖关键任务上的多模态 ICL 表现。通过模态信息扰动，我们发现模态在不同任务中的重要性各异。基于此，我们采用模态驱动策略提升 ICL 性能，并发现演示选择与模型捕捉任务偏差的能力紧密相关。我们的分析全面揭示了演示在多模态 ICL 中的作用，为改进多模态 ICL 提供了有效途径，即使面对预训练数据中未见或矛盾的任务。
[Arxiv](https://arxiv.org/abs/2407.00902)
==========
# 利用大型语言模型系统解答实际临床难题
发布时间：2024年06月29日
`RAG` `人工智能`
> Answering real-world clinical questions using large language model based systems
# 摘要
> 在医疗决策中，由于缺乏相关且可信的文献，以及难以将现有研究应用于特定患者，证据往往受限。大型语言模型（LLM）通过总结文献或基于真实世界数据（RWD）生成新研究，有望解决这些难题。我们测试了五个LLM系统回答50个临床问题的能力，并由九名独立医生评估了答案的相关性、可靠性和可操作性。结果显示，通用型LLM（如ChatGPT-4、Claude 3 Opus、Gemini Pro 1.5）很少能提供相关且基于证据的答案（仅占2% - 10%）。相反，基于检索增强生成（RAG）和代理型LLM系统的表现更佳，能提供相关且基于证据的答案，占比从24%（OpenEvidence）到58%（ChatRWD）。特别是代理型ChatRWD，能回答更多新问题（65% vs. 0-9%）。这些发现表明，虽然不应直接使用通用型LLM，但专门设计的基于RAG的证据总结系统和协同工作的系统，将显著提升患者护理相关证据的可用性。
[Arxiv](https://arxiv.org/abs/2407.00541)
==========
# 机器人开口说话时：构建多模态人机对话与协作的基石
发布时间：2024年06月29日
`LLM应用` `机器人` `人工智能`
> When Robots Get Chatty: Grounding Multimodal Human-Robot Conversation and Collaboration
# 摘要
> 我们探索如何利用大型语言模型 (LLM) 赋予机器人类人的社交与认知能力，以实现开放式的人机对话与协作。为此，我们提出了一种模块化且可扩展的方法，将 LLM 与机器人的感知及功能相结合，并在系统架构中整合了多种深度学习模型。这些集成模型涵盖了语音识别、语音生成、物体检测、人体姿态估计及手势识别等功能，而 LLM 则作为核心的文本协调单元。实证研究表明，LLM 在自然且社交的交互中，为机器人提供了创新的认知能力与语言控制，展现出巨大的应用潜力。
[Arxiv](https://arxiv.org/abs/2407.00518)
==========
# 大型语言模型在电力调度中的应用：聚焦用户需求的方法
发布时间：2024年06月29日
`Agent`
> Large Language Models for Power Scheduling: A User-Centric Approach
# 摘要
> 传统优化与调度方案满足固定系统需求，而未来系统正转向用户驱动与个性化服务，追求高QoE与灵活性。无线与数字化能源网络中，用户需求因缺乏人机共同语言而常被忽视。大型语言模型（LLMs）的崛起，通过提供自然人机交互界面，标志着从系统中心向用户中心的转变。本文首次提出一种创新资源调度架构，利用三个LLM代理将用户语音请求（VRQ）转化为资源分配向量。我们设计了意图识别、参数识别及问题求解三个LLM代理，构建了电动汽车充电场景下的VRQ数据库，并使用Llama 3 8B进行概念验证。测试结果显示了该架构的高效性，分析揭示了候选OP数量增加可能因识别噪声而影响最终性能。所有成果与代码均已开源。
[Arxiv](https://arxiv.org/abs/2407.00476)
==========
# BioKGBench：生物医学领域AI代理的知识图谱验证基准
发布时间：2024年06月29日
`Agent` `生物医学` `知识图谱`
> BioKGBench: A Knowledge Graph Checking Benchmark of AI Agent for Biomedical Science
# 摘要
> AI Scientist 在生物医学领域的应用日益受到瞩目，其中一种常见策略是构建由大型语言模型 (LLM) 驱动的辅助代理。然而，评估这些系统的方法要么直接依赖 LLM 的问答 (QA)，要么采用生物医学实验方式。从 AI Scientist 的角度出发，如何精准地基准测试生物医学代理仍是一个未被充分探索的领域。受科学家核心能力——理解文献的启发，我们推出了 BioKGBench。与仅侧重于事实问答的传统基准不同，LLM 在此方面存在幻觉问题，我们将“理解文献”细分为两个基本能力：一是通过科学主张验证理解研究论文中的非结构化文本，二是与结构化知识图谱问答 (KGQA) 交互的能力。接着，我们设计了名为 KGCheck 的新代理任务，结合 KGQA 和基于领域的检索增强生成 (RAG) 来揭示现有大规模知识图谱数据库中的事实错误。我们为两个基本任务收集了超过两千个数据，并为代理任务准备了 225 个高质量注释数据。令人惊讶的是，顶尖的日常和生物医学代理在我们的基准测试中表现不佳。为此，我们提出了一个简单而有效的基线——BKGAgent。在广泛使用的热门知识图谱上，我们发现了超过 90 个事实错误，为代理提供了发现机会，并验证了我们方法的有效性。相关代码和数据已公开在 https://github.com/westlake-autolab/BioKGBench。
[Arxiv](https://arxiv.org/abs/2407.00466)
==========
# 金融知识大型语言模型
发布时间：2024年06月29日
`LLM应用` `人工智能`
> Financial Knowledge Large Language Model
# 摘要
> 人工智能正深刻影响金融业，革新数据处理与解读。大型语言模型（LLMs）尤为突出，通过自动化复杂任务、优化客户服务和深化财务分析，重塑金融服务。我们首先推出IDEA-FinBench，专为评估LLMs财务知识而设的基准，采纳全球权威金融考试题，全面检验LLMs应对金融领域考题的能力。接着，提出IDEA-FinKER框架，助力LLMs快速融入金融领域，采用基于检索的少样本学习，实时注入上下文知识，并配备高质量金融指令，微调通用LLMs。最后，呈现IDEA-FinQA系统，由LLMs驱动，聚焦实时知识注入与外部知识强化，包含数据收集、查询及功能性LLM代理三大模块。
[Arxiv](https://arxiv.org/abs/2407.00365)
==========
# 探索并缓解大型视觉-语言模型中多模态幻觉的累积效应
发布时间：2024年06月29日
`LLM应用` `计算机视觉` `人工智能`
> Investigating and Mitigating the Multimodal Hallucination Snowballing in Large Vision-Language Models
# 摘要
> 尽管大型视觉-语言模型（LVLMs）在理解视觉信息方面取得了显著进步，但它们仍面临多模态幻觉的问题。我们担心，在多模态交互中，这些幻觉可能误导LVLMs的后续生成。因此，我们提出疑问：面对与先前幻觉相关的查询时，即使基础视觉信息存在，LVLMs是否会被误导并给出错误答案？为此，我们设计了MMHalSnowball框架，评估LVLMs在幻觉情境下的反应。实验显示，开源LVLMs性能下降至少31%，表明它们易受幻觉影响，做出错误判断。这种现象我们称之为“多模态幻觉滚雪球”。为解决这一问题，我们提出无需额外训练的“残差视觉解码”方法，通过调整输出分布，使模型直接获取视觉信息，有效减少24%以上的幻觉影响，同时保持原有能力。
[Arxiv](https://arxiv.org/abs/2407.00569)
==========
# MMEvalPro：致力于校准多模态基准，确保评估的可信性与高效性。
发布时间：2024年06月29日
`LLM应用` `人工智能` `教育评估`
> MMEvalPro: Calibrating Multimodal Benchmarks Towards Trustworthy and Efficient Evaluation
# 摘要
> 大型多模态模型 (LMMs) 在跨模态理解和推理方面表现卓越，常通过包含图像的多项选择题 (MCQs) 进行评估。然而，现有基准普遍存在系统性偏差，甚至无视觉感知能力的 LLMs 也能取得不俗成绩，降低了评估的可信度。为此，我们推出了 MMEvalPro 基准，通过三阶段评估流程和严格指标，有效避免 I 型错误。该基准包含 $2,138$ 个问题三元组，共计 $6,414$ 个问题，其中三分之二由专家手工标注，其余源自现有基准。实验显示，MMEvalPro 不仅更具挑战性（最佳 LMM 与人类表现差距达 $31.73\%$），而且更可信（最佳 LLM 与最佳 LMM 差距为 $23.09\%$）。深入分析揭示了性能差距的原因，并证实了评估的可靠性，预示着其对未来研究的重大推动作用。
[Arxiv](https://arxiv.org/abs/2407.00468)
==========
# 训练事实验证器：探索多模态开放模型中的知识传递
发布时间：2024年06月29日
`LLM应用` `网络安全`
> How to Train Your Fact Verifier: Knowledge Transfer with Multimodal Open Models
# 摘要
> 随着新闻和社交媒体上错误信息的激增，我们急需能够实时有效验证新闻声明的系统。为此，基于大型语言或多模态模型的验证方法应运而生，旨在加强在线监管，遏制虚假和有害内容的传播。尽管这些方法有望减轻人工事实核查的负担，但基础模型训练数据的过时可能成为阻碍。在本研究中，我们探索了在不持续更新的前提下，通过知识转移提升基础模型性能的可能性，利用现有基准或大型语言模型生成的解释进行初步研究。我们在12个公共事实核查和错误信息检测基准以及两个与内容审核相关的任务上进行了评估。实验结果显示，在Mocheg和Fakeddit这两个多模态事实核查基准上，知识转移策略分别将性能提升了高达2.9%和1.7%，超越了当前最先进水平。
[Arxiv](https://arxiv.org/abs/2407.00369)
==========
# 通过文本概念阐释胸部X光病理模型
发布时间：2024年06月29日
`LLM应用` `人工智能`
> Explaining Chest X-ray Pathology Models using Textual Concepts
# 摘要
> 深度学习模型虽已革新医学影像诊断领域，但其不透明性却成为临床采纳和信任的障碍。在提升模型透明度的探索中，基于概念的解释力求提供简洁易懂的分类器解释。然而，这类方法常依赖大量手动标注概念的数据，这在医学领域尤为稀缺。为此，我们创新性地提出了CoCoX方法，它巧妙利用现有视觉-语言模型的联合嵌入空间，无需标注数据即可阐释黑盒分类器的结果。通过结合胸部放射报告中的文本概念与预训练的VLM，我们成功解释了三种常见胸腔疾病。实验表明，我们的解释不仅语义丰富，而且准确反映了潜在病理。
[Arxiv](https://arxiv.org/abs/2407.00557)
==========
# ConU：在大型语言模型中，通过正确性覆盖保证实现共形不确定性
发布时间：2024年06月29日
`LLM理论` `人工智能`
> ConU: Conformal Uncertainty in Large Language Models with Correctness Coverage Guarantees
# 摘要
> 自然语言生成任务中的不确定性量化仍是一大难题，尤其是随着大型语言模型的复杂性增加。本研究探索了将保形预测应用于黑箱LLM的方法，通过构建预测集将启发式的不确定性度量转化为严格的理论保证。我们提出了一种基于抽样的不确定性度量方法，结合自一致性，并设计了保形不确定性准则，确保与正确性一致。实验显示，我们的方法在性能上超越了现有技术。此外，我们在模型的答案分布中校准预测集，确保了在多个领域和模型中对正确覆盖率的严格控制，同时小规模的平均集大小也显示了方法的高效性，为实际应用提供了可靠的保障。
[Arxiv](https://arxiv.org/abs/2407.00499)
==========
# LLMs 作为导师：通过从错误中学习，迈向模型改进的自动化
发布时间：2024年06月29日
`LLM应用` `人工智能`
> LLMs-as-Instructors: Learning from Errors Toward Automating Model Improvement
# 摘要
> 本文提出创新的“LLMs-as-Instructors”框架，利用大型语言模型自主提升小型模型的训练效率。借鉴“从错误中学习”的理念，该框架通过指导性LLM深入分析目标模型的错误，实现精准高效的训练。我们采用两种策略：一是“从错误中学习”，专注于错误响应定制训练数据；二是“通过对比从错误中学习”，利用对比学习深入剖析错误。实证研究表明，该框架在数学推理、编码能力和事实知识等多个领域显著提升性能，改进后的Llama-3-8b-Instruction更是超越了ChatGPT。通过综合运用这两种策略，我们在各类基准测试中均实现了均衡的性能提升。相关代码已公开，详见https://yingjiahao14.github.io/LLMs-as-Instructors-pages/。
[Arxiv](https://arxiv.org/abs/2407.00497)
==========
# PFME：一种模块化方法，专为大型语言模型的细粒度幻觉检测与编辑设计。
发布时间：2024年06月29日
`LLM应用` `人工智能`
> PFME: A Modular Approach for Fine-grained Hallucination Detection and Editing of Large Language Models
# 摘要
> 大型语言模型 (LLM) 虽然流畅，但易产生“幻觉”——不准确的内容。本文提出了一套标准化流程，用于细粒度幻觉类型的分类，并创新性地设计了渐进式细粒度模型编辑器 (PFME)，旨在检测和修正 LLM 中的细粒度幻觉。PFME 由两个协同工作的模块组成：实时事实检索模块和细粒度幻觉检测与编辑模块。前者负责识别文档中的关键实体，并从可信来源获取最新事实证据；后者则将文档分解为句子级文本，依据相关证据和已编辑的上下文，精准识别、定位并修正每句中的幻觉。实验显示，PFME 在细粒度幻觉检测方面超越了现有技术，尤其是在 Llama3-8B-Instruct 模型辅助下，其性能较 ChatGPT 提升了 8.7 个百分点。此外，在编辑任务中，PFME 显著提高了 FActScore-Alpaca13B 和 FActScore-ChatGPT 数据集的 FActScore，分别增长了 16.2pp 和 4.6pp。
[Arxiv](https://arxiv.org/abs/2407.00488)
==========
# 变形时刻已至：借助多目标优化，激发多款大型语言模型的无限潜能
发布时间：2024年06月29日
`LLM理论` `人工智能` `软件工程`
> It's Morphing Time: Unleashing the Potential of Multiple LLMs via Multi-objective Optimization
# 摘要
> 本文提出了一种新颖的大型语言模型合并方法，通过黑盒多目标优化算法实现。我们的目标是将多个擅长不同任务的模型合并，创造出一个性能超越所有单一源模型的统一模型。模型合并面临两大难题：一是现有方法过度依赖人工直觉和定制策略；二是合并时常见参数冲突，尽管DARE等方法能缓解，但常随机丢弃参数，可能导致重要增量参数丢失。为此，我们提出MM-MO方法，利用多目标优化算法自动寻找最佳合并方案，无需人工干预。在搜索配置时，我们以多任务的估计性能为优化目标，有效避免参数冲突，保留关键增量参数。实验对比显示，我们的方法性能持续领先。更有趣的是，即使未明确优化的任务类型也见性能提升，表明我们的方法全面提升了模型潜力，而非仅针对特定任务过拟合。这一创新方法为模型合并技术带来显著进步，提供了一个强大且易用的解决方案，将多样模型整合为高效统一的模型。
[Arxiv](https://arxiv.org/abs/2407.00487)
==========
# VcLLM：视频编解码器，实为隐秘的张量编解码器
发布时间：2024年06月29日
`LLM理论` `计算机科学` `人工智能`
> VcLLM: Video Codecs are Secretly Tensor Codecs
# 摘要
> 随着 LLM 参数规模的不断增长，大量内存和高带宽的需求已成为其训练与推理的瓶颈。为此，我们探索了张量压缩技术，发现视频编解码器在张量压缩方面表现出色。我们展示了视频编解码器不仅多用途，还能在各类任务中实现顶尖的压缩效率。借助 GPU 上的硬件编解码模块，我们构建了一个框架，将视频编解码器用作张量编解码器，从而显著降低了对内存和带宽的需求，使得大型模型的训练与推理在消费级 GPU 上成为现实。
[Arxiv](https://arxiv.org/abs/2407.00467)
==========
# 开源对话AI：SpeechBrain 1.0登场
发布时间：2024年06月29日
`Agent` `语音处理` `人工智能`
> Open-Source Conversational AI with SpeechBrain 1.0
# 摘要
> SpeechBrain，一款基于 PyTorch 的开源对话 AI 工具包，专注于语音处理领域，涵盖语音识别、增强、说话人识别及文本转语音等多项任务。它通过公开预训练模型及完整训练“配方”，增强了透明度与可复制性。本文聚焦 SpeechBrain 1.0，标志着工具包的重大进展，现提供超 200 种任务配方及 100 多个 Hugging Face 上的模型。新版本不仅支持多样化学习模式、LLM 集成与高级解码策略，还引入了创新模型与任务。此外，新增的基准库为跨任务模型评估提供了统一平台。
[Arxiv](https://arxiv.org/abs/2407.00463)
==========
# 探究大规模语言模型中的编码风格不一致，超越功能正确性的局限。
发布时间：2024年06月29日
`LLM应用` `软件开发` `人工智能`
> Beyond Functional Correctness: Investigating Coding Style Inconsistencies in Large Language Models
# 摘要
> 大型语言模型 (LLM) 为代码生成领域带来了革命性的变化，有望优化软件开发流程。然而，以往研究多聚焦于代码生成的准确性，而 LLM 与人类开发者间的编码风格差异却鲜有探讨。本文通过实证分析，揭示了主流 Code LLM 与人类开发者编码风格的不一致性，并对其进行了分类总结。我们首先通过大量生成结果的手动分析，归纳了编码风格不一致的类型，随后从可读性、简洁性和健壮性角度对比了 Code LLM 与人类程序员的代码。研究发现，LLM 与开发者编码风格迥异。同时，我们探讨了这些差异的成因，并提出了缓解这些问题的策略。
[Arxiv](https://arxiv.org/abs/2407.00456)
==========
# 自译训练：一种简洁而高效的基线方法，专为大型语言模型的跨语言迁移设计。
发布时间：2024年06月29日
`LLM应用` `语言技术` `机器翻译`
> Self-Translate-Train: A Simple but Strong Baseline for Cross-lingual Transfer of Large Language Models
# 摘要
> 跨语言迁移技术前景广阔，但现有方法常依赖外部翻译系统或因过度依赖多语言模型的跨语言泛化而表现不佳。本研究提出了一种简便高效的方法——自翻译训练，该方法利用大型语言模型的翻译能力生成目标语言的合成训练数据，并以此数据微调模型。实验结果显示，该方法在多种非英语语言任务上取得了显著的性能提升。
[Arxiv](https://arxiv.org/abs/2407.00454)
==========
# 语言引导的物体中心扩散策略，助力机器人实现碰撞感知的精准操作
发布时间：2024年06月29日
`Agent` `机器人` `人工智能`
> Language-Guided Object-Centric Diffusion Policy for Collision-Aware Robotic Manipulation
# 摘要
> 为了克服从演示学习中的泛化难题和视觉变化的脆弱性，我们推出了Lan-o3dp——一种语言引导的、以对象为中心的扩散策略。该策略利用任务相关对象的3D表示，并通过成本函数在推理时确保安全。Lan-o3dp不仅在背景变化和视觉模糊性方面表现出色，还能有效规避演示中未曾遇到的新障碍。具体操作上，我们首先基于目标对象的点云训练扩散策略，再借助大型语言模型将用户指令细化分解为任务核心单元，这些单元既可作为策略网络的视觉输入，也可转化为成本函数，确保测试时轨迹生成避开碰撞区域。模拟实验证明，我们的方法训练效率高且成功率优于传统方法。实际应用中，Lan-o3dp在处理未见实例、复杂场景及多相似对象情况时，展现了卓越的泛化能力和无需额外训练的障碍规避特性。
[Arxiv](https://arxiv.org/abs/2407.00451)
==========
# 多语言大型语言模型的平行语料库利用指南
发布时间：2024年06月29日
`LLM应用` `机器翻译` `文本分类`
> A Recipe of Parallel Corpora Exploitation for Multilingual Large Language Models
# 摘要
> 近期研究凸显了平行语料库在提升多语种大型语言模型性能方面的潜力，不仅在双语任务如机器翻译中，也在通用任务如文本分类中表现出色。基于此，我们展开了一项全面研究，旨在探索利用平行语料库的最佳策略。我们深入分析了语料库的质量与数量、训练目标及模型规模对多语种大型语言模型性能的影响。研究发现：首先，有效过滤噪声翻译是关键，而语言识别和短句过滤则影响甚微；其次，仅10K平行句子的语料库即可媲美大型数据集的效果；再者，单一的机器翻译训练目标效果最佳；最后，大型模型因更强的跨任务迁移能力，从平行语料库中获益更多。本研究不仅为平行语料库的优化利用提供了新视角，还将先前研究的适用范围从特定语言和任务扩展至更广泛的应用场景。
[Arxiv](https://arxiv.org/abs/2407.00436)
==========
# 本研究探讨了在利用大型语言模型生成与SAPPhIRE模型相关技术内容时，参考知识选择的影响。
发布时间：2024年06月29日
`RAG` `软件开发` `技术文档`
> A Study on Effect of Reference Knowledge Choice in Generating Technical Content Relevant to SAPPhIRE Model Using Large Language Model
# 摘要
> 利用SAPPhIRE因果模型在设计中激发灵感，但构建此类模型需深入技术文档。本研究探索如何借助大型语言模型（LLM）精准产出相关技术内容。首篇论文聚焦于通过RAG与LLM结合抑制幻觉，确保生成的技术内容科学可靠。研究揭示，选择恰当的参考知识对LLM产出至关重要。此成果助力开发软件工具，高效构建技术系统的SAPPhIRE模型。
[Arxiv](https://arxiv.org/abs/2407.00396)
==========
# 多样性干预下的文本转图像生成面临事实性挑战，我们提出基准测试与事实增强干预策略。
发布时间：2024年06月29日
`LLM应用` `人工智能` `历史研究`
> The Factuality Tax of Diversity-Intervened Text-to-Image Generation: Benchmark and Fact-Augmented Intervention
# 摘要
> 我们提出了DoFaiR基准，用于评估T2I模型中多样性干预与事实性之间的平衡。通过756个事实核查的测试实例，我们发现多样性指令虽增加了DALLE-3生成中的多样性，但牺牲了历史人口分布的准确性。为此，我们设计了FAI方法，通过引导LLM整合历史事实信息，既保持多样性又提升事实性。
[Arxiv](https://arxiv.org/abs/2407.00377)
==========
# BMW Agents 框架：多代理协作驱动任务自动化
发布时间：2024年06月28日
`Agent` `自动化`
> BMW Agents -- A Framework For Task Automation Through Multi-agent Collaboration
# 摘要
> 大型语言模型（LLM）驱动的自主代理展现了自动化领域的巨大潜力。早期技术展示包括代理解决复杂任务、与外部系统互动以扩充知识及触发行动等。特别是，多代理协作解决复杂任务的工作流程，突显了它们在非严格定义环境中的运作能力。因此，多代理系统在工业应用中具有广泛前景，涵盖从复杂知识检索到下一代机器人流程自动化等多个领域。鉴于LLM的推理能力，处理复杂过程需采取多步骤策略，包括模块化任务规划。任务执行可由单一代理或代理群组完成，视复杂度而定。本研究聚焦于构建一个灵活的代理工程框架，注重规划与执行，以应对跨领域的复杂应用。该框架旨在提升工业应用的可靠性，并确保多代理协同工作的可扩展性、灵活性和协作性。
[Arxiv](https://arxiv.org/abs/2406.20041)
==========
# 利用大型语言模型代理模拟金融市场
发布时间：2024年06月28日
`Agent` `经济研究`
> Simulating Financial Market via Large Language Model based Agents
# 摘要
> 经济理论常假设市场参与者完全理性，并用数学模型模拟其行为。然而，人类行为多变且难以预测。本文提出基于代理的模拟金融市场（ASFM），构建了包含真实订单匹配系统的模拟市场，并设计了基于大型语言模型的智能交易代理，能全面理解市场动态与政策，做出符合策略的决策。实验证明，ASFM在可控场景下的反应与真实市场一致，且在经济学研究热点方向的实验中，其结论与现有研究相符。ASFM为经济研究开辟了新路径。
[Arxiv](https://arxiv.org/abs/2406.19966)
==========
# MetaDesigner：借助 AI 技术，以用户为中心，实现多语言艺术字体的创新合成，推动字体艺术的进步。
发布时间：2024年06月28日
`Agent` `艺术设计` `用户体验`
> MetaDesigner: Advancing Artistic Typography through AI-Driven, User-Centric, and Multilingual WordArt Synthesis
# 摘要
> MetaDesigner 借助 LLM 的力量，创新了艺术字体设计，聚焦于提升用户参与度。其核心的多代理系统，包括 Pipeline、Glyph 和 Texture，共同打造出从语义到纹理都个性化的 WordArt。通过整合多模态模型和用户反馈的全面机制，MetaDesigner 不断优化设计，精准调整参数以贴合用户的风格与主题需求，创作出既符合又超越期待的视觉作品。实证显示，MetaDesigner 在多样化的 WordArt 应用中，始终如一地输出美观且贴合情境的成果。
[Arxiv](https://arxiv.org/abs/2406.19859)
==========
# ROS-LLM：一款集任务反馈与结构化推理于一体的具身AI ROS框架
发布时间：2024年06月28日
`Agent` `机器人技术` `人工智能`
> ROS-LLM: A ROS framework for embodied AI with task feedback and structured reasoning
# 摘要
> 我们开发了一个直观的机器人编程框架，让非专业人士也能轻松上手，通过自然语言提示和ROS的上下文信息来实现。该系统融合了大型语言模型（LLMs），用户只需通过聊天界面描述任务需求。框架亮点包括：ROS与AI代理的结合，后者连接了丰富的开源和商业LLMs；自动从LLM输出中提炼行为并执行ROS指令；支持序列、行为树和状态机三种行为模式；通过模仿学习扩充机器人动作库；以及基于人机环境反馈的LLM自我反思。经过广泛测试，该框架在长时任务、桌面整理和远程监控等多种场景中表现出色，兼具鲁棒性、可扩展性和灵活性。为推动应用和结果复现，我们已将代码公开，详情请访问：https://github.com/huawei-noah/HEBO/tree/master/ROSLLM。
[Arxiv](https://arxiv.org/abs/2406.19741)
==========
# Web2Code：专为多模态大型语言模型设计的大规模网页转代码数据集及评估框架
发布时间：2024年06月28日
`LLM应用` `互联网` `软件开发`
> Web2Code: A Large-scale Webpage-to-Code Dataset and Evaluation Framework for Multimodal LLMs
# 摘要
> 多模态大型语言模型 (MLLMs) 在图像、视频和音频等多种任务中表现卓越，但在理解网页截图和生成 HTML 代码方面却表现不佳。为此，我们推出了 Web2Code 基准，包含一个大规模网页到代码数据集及评估框架，旨在提升 MLLMs 的网页理解和代码生成能力。我们利用预训练 LLMs 增强现有数据集并生成新网页图像，输入包括网页图像和指令，输出则是网页的 HTML 代码，并附带网页内容的自然语言 QA 对，以深化理解。实验证明，我们的数据集不仅优化了特定任务，也提升了视觉领域的性能。我们期待这项工作能推动适用于网页内容生成和自动化的通用 MLLMs 的发展。相关资源将在 https://github.com/MBZUAI-LLM/web2code 提供。
[Arxiv](https://arxiv.org/abs/2406.20098)
==========
# EVF-SAM：针对文本提示分割模型，采用早期视觉与语言融合技术
发布时间：2024年06月28日
`LLM应用` `计算机视觉`
> EVF-SAM: Early Vision-Language Fusion for Text-Prompted Segment Anything Model
# 摘要
> SAM 模型因其出色的视觉提示交互分割能力而广受瞩目，但文本提示方面的研究尚显不足。本文通过实证研究，探讨了哪些文本提示编码器（如 CLIP 或 LLM）能有效提升 SAM 在指代表达分割中的表现，并提出了基于早期视觉语言融合的 SAM（EVF-SAM）。EVF-SAM 利用图像与文本的多模态提示，结合预训练的视觉语言模型生成指代提示，再由 SAM 模型完成分割，简单而高效。我们发现，多模态提示与早期融合的视觉语言模型（如 BEIT-3）能显著提升 SAM 的指代分割精度。实验证明，基于 BEIT-3 的 EVF-SAM 在 RefCOCO/+/g 数据集上达到了业界领先水平，并凸显了早期视觉语言融合在提升 SAM 性能方面的优势。此外，EVF-SAM 在大幅减少参数（约 82%）的同时，性能显著提升，参数规模为 1.32B，远超以往基于大型多模态模型的 SAM 方法。
[Arxiv](https://arxiv.org/abs/2406.20076)
==========
# InfiniBench：一项全面的综合基准，旨在评估大型多模态模型在超长视频理解领域的性能。
发布时间：2024年06月28日
`LLM应用` `视频理解` `人工智能`
> InfiniBench: A Comprehensive Benchmark for Large Multimodal Models in Very Long Video Understanding
# 摘要
> 理解长视频（从数十分钟到数小时）在视频理解领域带来了独特挑战。尽管长视频内容日益重要，但现有基准多聚焦于短片段。为此，我们推出了InfiniBench，一个全面的长视频理解基准，涵盖最长视频时长（平均76.34分钟）、最多问答对（108.2K）、问题多样性（考察九种技能，含选择题与开放式问题），以及人本设计（视频源自电影与日常节目，如需批判思维的电影剧透题）。我们利用InfiniBench全面评估了多模态大型模型（LMMs），包括商业与开源模型，发现其在我们基准上表现不佳，最佳AI模型平均准确率仅42.72%，平均得分2.71（满分5）。我们期待此基准能推动LMMs社区深入长视频与人类级别理解的研究。基准链接：https://vision-cair.github.io/InfiniBench/。
[Arxiv](https://arxiv.org/abs/2406.19875)
==========
# MM-Instruct：打造视觉指令，助力大型多模态模型精准对齐
发布时间：2024年06月28日
`LLM应用` `人工智能` `计算机视觉`
> MM-Instruct: Generated Visual Instructions for Large Multimodal Model Alignment
# 摘要
> 本文推出 MM-Instruct，一个大规模、多样且高质量的视觉指令数据集，旨在提升大型多模态模型（LMMs）的指令遵循能力。现有视觉指令数据集多聚焦于问答，难以适应创意写作、摘要或图像分析等更广泛场景。为此，我们创新构建 MM-Instruct，借助现有 LLMs 的强大指令遵循能力，从传统图像字幕数据集中生成新视觉指令数据。MM-Instruct 先利用 ChatGPT 从小规模种子指令中自动生成多样化指令，再与图像匹配，并借助开源 LLM 生成连贯答案，确保指令数据一致性。此外，我们基于此数据集设立基准，评估 LMMs 的指令遵循能力。实验证明，基于 MM-Instruct 训练的 LLaVA-Instruct 模型在指令遵循能力上显著优于 LLaVA-1.5。MM-Instruct 数据集、基准及预训练模型已开放于 https://github.com/jihaonew/MM-Instruct。
[Arxiv](https://arxiv.org/abs/2406.19736)
==========
# 多模态 LLM 能否胜任家庭机器人的“大脑”角色？
发布时间：2024年06月28日
`LLM应用` `机器人` `人工智能`
> MMRo: Are Multimodal LLMs Eligible as the Brain for In-Home Robotics?
# 摘要
> 在人类环境中，机器人要成为得力助手，必须克服感知、语言理解、推理和规划等一系列挑战。多模态大型语言模型（MLLMs）的最新进展显示了其在复杂数学问题解决和抽象推理方面的卓越能力，因此被用作机器人系统的大脑，进行高级规划。然而，这些模型是否可靠地担任机器人大脑的角色尚存疑问。为此，我们推出了首个多模态LLM用于机器人的（MMRo）基准，旨在评估MLLMs在机器人应用中的能力。我们确定了四种关键能力：感知、任务规划、视觉推理和安全措施，并为此设计了14项评估指标。实验结果显示，没有单一模型在所有领域表现卓越，表明当前MLLMs尚不足以成为机器人的认知核心。详细数据可访问https://mm-robobench.github.io/。
[Arxiv](https://arxiv.org/abs/2406.19693)
==========
# 提升放射诊断：融合AI与专家智慧，共同修正视觉遗漏，实现诊断协作新高度。
发布时间：2024年06月28日
`Agent` `放射学`
> Enhancing Radiological Diagnosis: A Collaborative Approach Integrating AI and Human Expertise for Visual Miss Correction
# 摘要
> 本研究首次探索了人类与AI在识别和纠正胸部X光片感知错误方面的协作。我们开发的CoRaX系统，通过融合眼动数据和放射报告，精准定位并优化诊断决策，显著提升了胸部放射学的诊断准确性。在公开数据集上，CoRaX展现了其高效性，成功纠正了模拟数据集中21%的遗漏异常，且在与放射科医生的互动中，84%的诊断准确性得分超过0.40。CoRaX不仅优化了转诊流程，更在教育和培训新手放射科医生方面展现出巨大潜力。
[Arxiv](https://arxiv.org/abs/2406.19686)
==========
# LLaRA：为视觉-语言策略注入强大动力的机器人学习数据
发布时间：2024年06月28日
`Agent` `机器人技术` `人工智能`
> LLaRA: Supercharging Robot Learning Data for Vision-Language Policy
# 摘要
> 本文提出 LLaRA 框架，通过将机器人行动策略转化为对话形式，并利用辅助数据提升响应质量，展示了大型语言模型在处理跨领域任务时的强大能力。特别是视觉语言模型，能够结合视觉信息生成策略决策。我们通过自动化流程，从现有数据中提取高质量指令，进一步优化了机器人任务的表现。实验证明，LLaRA 在多环境中的表现卓越。相关资源已公开在 GitHub 上。
[Arxiv](https://arxiv.org/abs/2406.20095)
==========
# 利用十亿个人物角色扩展合成数据的生成
发布时间：2024年06月28日
`LLM应用` `人工智能` `数据科学`
> Scaling Synthetic Data Creation with 1,000,000,000 Personas
# 摘要
> 我们创新性地提出了一种基于人格驱动的数据合成方法，该方法通过大型语言模型 (LLM) 中的多重视角，生成多样化的合成数据。为实现这一方法的大规模应用，我们创建了 Persona Hub，这是一个包含 10 亿多样化人格的集合，这些人格从网络数据中自动筛选而出。这些人格（约占全球人口的 13%）作为世界知识的分布式载体，能够触及 LLM 中的几乎所有视角，从而大规模地促进多样化合成数据的创建，适用于多种场景。通过展示 Persona Hub 在合成高质量数学和逻辑推理问题、用户指令、知识丰富的文本、游戏角色和工具等方面的大规模应用，我们证明了基于人格驱动的数据合成方法的多功能性、可扩展性、灵活性和易用性，有望推动合成数据领域的范式变革，对 LLM 的研究与开发产生深远影响。
[Arxiv](https://arxiv.org/abs/2406.20094)
==========
# LLaVolta：采用阶段式视觉上下文压缩技术，打造高效多模态模型。
发布时间：2024年06月28日
`LLM应用` `多模态学习` `计算机视觉`
> LLaVolta: Efficient Multi-modal Models via Stage-wise Visual Context Compression
# 摘要
> 尽管文本嵌入的压缩在大型语言模型中取得了显著进展，但视觉令牌的压缩在大型多模态模型中仍被忽视。我们研究发现，通过简单平均池化，测试阶段可消除高达70%的视觉令牌，仅轻微影响GQA基准上的视觉问答准确性，揭示了视觉上下文的冗余。为此，我们设计了视觉上下文压缩器，通过在训练中减少视觉令牌来提升效率，同时不损性能。为避免压缩导致的信息损失，我们创新了LLaVolta轻量训练方案，采用渐进式压缩，确保训练结束时无压缩，测试无信息丢失。实验证明，我们的方法不仅大幅降低训练成本，还显著提升了多模态模型在图像与视频语言理解上的性能。代码已公开在GitHub。
[Arxiv](https://arxiv.org/abs/2406.20092)
==========
# ProgressGym：与千年道德进步的同步发展
发布时间：2024年06月28日
`LLM理论` `人工智能` `道德伦理`
> ProgressGym: Alignment with a Millennium of Moral Progress
# 摘要
> 前沿AI系统，尤其是大型语言模型（LLMs），正日益影响人类用户的认识论。这种影响可能强化社会主流价值观，甚至可能导致错误道德信念的固化，进而广泛延续有问题的道德实践。为应对这一风险，我们提出了“进步对齐”技术方案。该方案通过学习人类道德进步的机制，有效解决了现有对齐方法对当代道德盲点的敏感问题。为推动这一研究，我们开发了ProgressGym实验框架，该框架允许从历史中学习道德进步机制，助力未来现实世界道德决策的进步。通过整合9个世纪的历史文本和18个历史LLMs，ProgressGym将现实世界的进步对齐挑战具体化为基准。我们特别提出了三个核心挑战：跟踪价值演变（PG-Follow），预先预测道德进步（PG-Predict），以及调节人类与AI价值转变间的反馈回路（PG-Coevolve）。针对这些挑战，我们提出了终身学习和外推算法作为基线方法，并设立了一个开放的排行榜，征集创新算法和挑战。ProgressGym框架和排行榜详情可分别访问https://github.com/PKU-Alignment/ProgressGym和https://huggingface.co/spaces/PKU-Alignment/ProgressGym-LeaderBoard。
[Arxiv](https://arxiv.org/abs/2406.20087)
==========
# 自动精选者：借助语言驱动的高质量生成数据进行学习
发布时间：2024年06月28日
`LLM应用` `视觉感知` `多模态语言模型`
> Auto Cherry-Picker: Learning from High-quality Generative Data Driven by Language
# 摘要
> 基于扩散的模型在生成多样化高质量图像方面潜力巨大，有助于下游感知任务。然而，完全自动的布局生成及多实例评估指标尚待深入探索。为此，我们推出Auto Cherry-Picker（ACP）框架，旨在通过自然语言概念列表驱动LLM，生成详尽描述与合理布局，进而利用文本到图像模型产出多幅图像，并借助精心设计的复合布局和图像分数（CLIS）指标优化生成质量。实验证实，ACP能显著提升模型性能，尤其在应对长尾分布与数据不平衡挑战时表现突出。此外，CLIS与性能提升间的正相关性揭示了其在视觉感知与多模态语言模型任务中的评估潜力。相关代码即将开放。
[Arxiv](https://arxiv.org/abs/2406.20085)
==========
# 分子事实：LLM 事实验证中的去上下文化需求
发布时间：2024年06月28日
`LLM应用` `信息验证` `人工智能`
> Molecular Facts: Desiderata for Decontextualization in LLM Fact Verification
# 摘要
> 随着对抗幻觉的需求增加，大型语言模型生成的自动事实验证应用日益广泛。然而，事实检查的粒度问题成为研究焦点：大段文本难以验证，而过于细碎的事实又可能缺乏必要的上下文。本研究聚焦于原子事实中的上下文作用，提出“分子事实”概念，强调其独立性和信息量的最小化。通过量化分析和基准方法的开发，我们旨在找到信息量与验证准确性的最佳平衡点，为复杂情境下的自动事实验证提供新思路。
[Arxiv](https://arxiv.org/abs/2406.20079)
==========
# BioMNER：专为生物医学方法实体识别设计的数据集
发布时间：2024年06月28日
`LLM应用` `生物医学`
> BioMNER: A Dataset for Biomedical Method Entity Recognition
# 摘要
> 命名实体识别（NER）是自然语言处理中的核心任务，尤其在生物医学领域，由于专业术语的不断涌现，这一任务更具挑战性。当前生物医学方法NER研究因方法概念的复杂性而资源稀缺。为此，我们创建了一个新的数据集，并利用自动化系统辅助人工标注。同时，我们探索了多种NER方法，包括定制的大型语言模型。实验表明，大型模型参数反而不利于生物医学方法实体的提取，而结合CRF的小型ALBERT模型则达到了顶尖性能。
[Arxiv](https://arxiv.org/abs/2406.20038)
==========
# LEMoE：专为大型语言模型设计的终身编辑工具，采用先进的多专家混合适配技术。
发布时间：2024年06月28日
`LLM应用` `人工智能` `软件开发`
> LEMoE: Advanced Mixture of Experts Adaptor for Lifelong Model Editing of Large Language Models
# 摘要
> 为了跟上瞬息万变的世界，大型语言模型 (LLM) 需要不断更新知识，这催生了终身模型编辑任务。尽管已有多种编辑技术，但在终身编辑场景中，它们往往力不从心。为此，我们推出了 LEMoE，一种创新的专家混合 (MoE) 适配器，专为终身编辑设计。我们深入剖析了传统 MoE 适配器在终身编辑中的局限，如灾难性遗忘、路由不一致及顺序敏感等问题。基于此，我们提出了一种定制化的模块插入策略，通过引入 KV 锚路由提升训练与推理阶段的路由一致性，并采用基于聚类的编辑顺序规划，简洁高效。实验证明，我们的方法在终身编辑领域表现卓越，不仅超越了现有技术，还在批量编辑任务中展现了出色的性能。相关代码即将开放。
[Arxiv](https://arxiv.org/abs/2406.20030)
==========
# ToolBeHonest：针对工具增强型大型语言模型的多层次幻觉诊断基准
发布时间：2024年06月28日
`LLM应用` `人工智能` `软件开发`
> ToolBeHonest: A Multi-level Hallucination Diagnostic Benchmark for Tool-Augmented Large Language Models
# 摘要
> 工具增强的LLM正迅速融入实际应用，但社区对这些模型中的幻觉问题理解尚浅。为此，我们推出了全面诊断基准ToolBH，从深度与广度双重视角评估LLM幻觉。深度诊断涵盖可解性检测、解决方案规划及缺失工具分析；广度则涉及缺失必要工具、潜在工具与功能受限工具三种情景。我们设计七项任务，收集700样本，揭示ToolBH的挑战性：Gemini-1.5-Pro与GPT-4o得分仅45.3与37.0（满分100）。大参数非性能保证，训练数据与响应策略同样关键。诊断显示，错误主因在于任务可解性评估；开放权重模型遇冗长回复性能下滑，专有模型则长推理更优。
[Arxiv](https://arxiv.org/abs/2406.20015)
==========
# SIFo 基准旨在探究大型语言模型在遵循顺序指令方面的能力。
发布时间：2024年06月28日
`LLM应用` `人工智能` `软件开发`
> The SIFo Benchmark: Investigating the Sequential Instruction Following Ability of Large Language Models
# 摘要
> 大型语言模型（LLM）能够遵循多个指令是一项关键能力，但评估这一能力充满挑战，包括指令间连贯性不足、指令顺序影响性能以及缺乏客观验证任务。为此，我们设计了一个基准，通过顺序指令遵循（SIFo）任务来评估模型能力。在SIFo任务中，只需检查最终指令即可验证多个指令的完成情况。基准包含四个任务（文本修改、问答、数学和安全规则遵循），分别评估指令遵循的不同方面。评估显示，较新且规模更大的模型在SIFo任务上表现更佳，证明了基准的有效性。然而，所有模型在处理指令序列时均显露不足，揭示了当前语言模型在鲁棒性方面的欠缺。
[Arxiv](https://arxiv.org/abs/2406.19999)
==========
# 单亲家庭：源自单一预训练模型的多样化家庭成员谱系
发布时间：2024年06月28日
`LLM理论` `人工智能` `能源效率`
> Single Parent Family: A Spectrum of Family Members from a Single Pre-Trained Foundation Model
# 摘要
> 本文提出了一种创新的渐进低秩分解（PLRD）技术，专为大型语言模型压缩设计。该方法通过预训练模型逐步分解，降低秩以减小模型尺寸，从而大幅减少计算和能源消耗，且无需重新训练。PLRD通过战略性降低张量秩，优化了性能与资源使用的平衡。实验表明，PLRD训练的模型在仅用1B令牌的情况下，性能与传统模型相当，且仅耗用0.1%的令牌。PLRD的灵活性体现在能从单一基础模型生成多种尺寸，适应不同计算和内存需求。研究显示，PLRD有望成为LLMs高效扩展的新标杆，推动高级AI在多平台上的应用。
[Arxiv](https://arxiv.org/abs/2406.19995)
==========
# ScaleBiO：为 LLM 数据重加权提供可扩展的双层优化方案
发布时间：2024年06月28日
`LLM应用` `机器学习` `大规模数据处理`
> ScaleBiO: Scalable Bilevel Optimization for LLM Data Reweighting
# 摘要
> 双层优化在机器学习领域展现出广泛应用，但多数算法依赖二阶信息，限制了其扩展性。近期，一阶算法范式崭露头角，有效应对双层优化挑战。本文首创可扩展实例ScaleBiO，聚焦于大规模LLM数据重权重的双层优化。结合高效训练技术LISA，新算法在八块A40 GPU上成功扩展至340亿参数LLM，首次在实际场景中应用双层优化。实证实验表明，ScaleBiO对不同规模模型如GPT-2、LLaMA-3-8B、GPT-NeoX-20B和Yi-34B均有效，成功筛选关键数据。理论层面，ScaleBiO确保数据权重最优，并提供与传统一阶范式相匹配的收敛保证，适用于平滑且强凸目标函数。
[Arxiv](https://arxiv.org/abs/2406.19976)
==========
# STLLaVA-Med：医学领域的自训练大型语言与视觉助手
发布时间：2024年06月28日
`LLM应用` `人工智能`
> STLLaVA-Med: Self-Training Large Language and Vision Assistant for Medical
# 摘要
> 大型视觉-语言模型 (LVLMs) 在辅助医疗诊断方面潜力巨大，但医疗图像理解和推理的进步依赖于高质量视觉指导数据的构建，这在医疗领域尤为昂贵且劳动密集。为此，我们推出了自训练大型语言与视觉助手用于医疗 (STLLaVA-Med)，旨在通过直接偏好优化 (DPO) 引导，训练策略模型自动生成医疗视觉指导数据，提高数据效率。我们引入更强大的 LVLM (如 GPT-4o) 作为生物医学专家，监督策略模型与人类偏好高效对齐。实验证明，STLLaVA-Med 在三大医疗 VQA 基准上表现优异，仅用 9% 的医疗数据即展现出竞争性的零-shot 性能。
[Arxiv](https://arxiv.org/abs/2406.19973)
==========
# HumanVLA 项目旨在通过物理人形机器人，实现视觉与语言共同引导的物体重新排列。
发布时间：2024年06月28日
`Agent` `机器人` `人工智能`
> HumanVLA: Towards Vision-Language Directed Object Rearrangement by Physical Humanoid
# 摘要
> 物理人-场景交互 (HSI) 在众多领域中至关重要。然而，现有技术受限于特定物体动态和特权信息，限制了更广泛应用的发展。为此，我们推出了 HumanVLA，一个由视觉和语言引导的通用物体重新排列系统。我们采用教师-学生框架，首先通过目标条件强化学习和对抗性运动先验训练教师策略，再通过行为克隆将其转化为视觉-语言-动作模型。我们还提出了关键见解，以优化大规模学习。为支持人形机器人进行多样化的物体重新排列，我们创建了 Human-in-the-Room 数据集。通过详尽的实验和分析，我们验证了该方法的有效性。
[Arxiv](https://arxiv.org/abs/2406.19972)
==========
# 探索未知：为新环境打造地理空间描述
发布时间：2024年06月28日
`LLM应用` `地理信息系统` `人工智能`
> Into the Unknown: Generating Geospatial Descriptions for New Environments
# 摘要
> 类似于视觉-语言导航任务，新提出的 Rendezvous 任务需要利用非顺序指令和地图，对独立于观察者视角的空间关系进行推理。然而，在新环境中，缺乏训练数据导致性能大幅下降。我们利用带有坐标的开源描述（如维基百科）提供训练数据，但受限于空间文本的不足，地理位置分辨率较低。为此，我们提出了一种大规模数据增强方法，利用现有地理空间数据为新环境生成高质量合成数据。该方法构建了一个基于知识的图谱，捕捉实体间的空间关系。通过生成大量上下文无关文法模板并结合大型语言模型，我们能够生成具体的导航指令。实验表明，我们的方法在不熟悉环境中将导航精度提高了45.83%。此外，基于上下文无关文法的增强方法在未见和已见环境中均优于基于大型语言模型的增强方法。这表明，在处理基于文本的地理空间推理时，明确结构化空间信息对于解锁数据稀缺场景具有重要意义。
[Arxiv](https://arxiv.org/abs/2406.19967)
==========
# BESTOW：融合 GPT 与 T5 双重优势，打造高效且支持流式传输的语音语言模型。
发布时间：2024年06月28日
`LLM应用` `语音识别` `人工智能`
> BESTOW: Efficient and Streamable Speech Language Model with the Best of Two Worlds in GPT and T5
# 摘要
> 将语音理解融入预训练大型语言模型已成为关键研究领域。过往架构如GPT风格和T5风格各有特点，但缺乏流式通用解决方案。我们创新的BESTOW架构，高效整合双世界精华，强化多任务处理。通过将流式SpeechLLM重塑为读写策略问题，BESTOW统一了研究范式，首次推出开源、支持大规模流式与多任务的SpeechLLM，性能卓越，成本效益高，并验证了LLM知识向语音领域的迁移能力。
[Arxiv](https://arxiv.org/abs/2406.19954)
==========
# 通过优化思维树上的偏好，我们校准 LLM，以在科学问题评分中生成更合理的解释。
发布时间：2024年06月28日
`LLM应用` `人工智能`
> Calibrating LLMs with Preference Optimization on Thought Trees for Generating Rationale in Science Question Scoring
# 摘要
> 为了提升自动化评分系统的可解释性，我们提出了一种新框架，该框架不仅能生成更真实合理的理由，还能与基于分类器的评分系统媲美。我们通过模拟人类评估过程，利用大型语言模型生成思维树，并从中提炼出合成理由和偏好数据。通过监督微调和偏好优化两步训练，我们的框架在QWK评分上比以往提升了38%，并产出更受认可的高质量理由。这一成果展示了合成偏好数据在优化评估中的潜力。
[Arxiv](https://arxiv.org/abs/2406.19949)
==========
# 解决大型视觉-语言模型中混合专家系统令牌梯度冲突的难题
发布时间：2024年06月28日
`LLM应用` `计算机视觉`
> Solving Token Gradient Conflict in Mixture-of-Experts for Large Vision-Language Model
# 摘要
> 在大型视觉-语言模型 (LVLMs) 的研究中，Mixture-of-Experts (MoE) 备受瞩目。通过稀疏模型替代密集模型，MoE 在保持性能的同时大幅降低推理成本。然而，现有方法基于样本特征的路由预测未能真正揭示令牌的优化方向，可能导致专家内部令牌间的优化冲突。为此，我们提出了一种基于令牌级梯度分析的新方法，通过识别和消除专家内部令牌冲突，提升模型性能。该方法兼容多种 LVLMs，实验证明其有效性。相关代码将在 GitHub 上公开。
[Arxiv](https://arxiv.org/abs/2406.19905)
==========
# 释义类型激发了提示工程的潜能
发布时间：2024年06月28日
`LLM理论` `人工智能`
> Paraphrase Types Elicit Prompt Engineering Capabilities
# 摘要
> 现代语言模型的成功很大程度上依赖于找到合适的提示来指导模型。然而，提示的语言表达变化如何影响模型至今仍是个谜。本研究通过分析120个任务和六种释义类型，系统地探索了语言特征对模型的影响。我们发现，当提示采用特定的释义类型时，模型性能有所提升，尤其是在形态学和词汇方面的变化。这些发现为构建更强大的语言模型提供了新思路，使其能更好地应对语言表达的多样性。
[Arxiv](https://arxiv.org/abs/2406.19898)
==========
# 探索无界网络：自动辨识多语言语境
发布时间：2024年06月28日
`LLM应用` `计算语言学` `网络数据分析`
> Untangling the Unrestricted Web: Automatic Identification of Multilingual Registers
# 摘要
> 本文深入研究了用于自动识别16种语言网络数据集中文本类型的深度学习模型。网络文本类型识别对于理解大规模网络数据集至关重要，这些数据集在计算语言学领域扮演着重要角色。尽管已有进展，但在多语言和无限制网络环境下，文本类型分类器的潜力仍待充分挖掘。我们利用多语言CORE语料库，通过详细的层次化分类法，对16种语言进行了深度学习模型的实验。结果显示，这些模型达到了业界领先水平，证明了层次化多标签设置中详细分类法的有效性。然而，所有模型在约80%的F1分数处遇到了瓶颈，这源于网络文本类型的非离散性和标注的不确定性。通过剔除模糊示例，模型性能提升至90%以上。多语言模型在训练数据较少的语言中表现更佳，零-shot设置虽平均降低7%性能，但性能下降与特定文本类型或语言无关，而是显示出跨语言的文本类型相似性。
[Arxiv](https://arxiv.org/abs/2406.19892)
==========
# YuLan：一款开源的大型语言模型
发布时间：2024年06月28日
`LLM理论` `人工智能`
> YuLan: An Open-source Large Language Model
# 摘要
> 大型语言模型 (LLM) 已成为众多应用的基石，凭借其强大的自然语言处理和理解能力。尽管已有许多开源 LLM 发布，但训练细节的缺失限制了研究的深入。本文介绍了 YuLan 系列，这是一组拥有 12 亿参数的开源 LLM。YuLan 的基础模型在包含大量英语、中文及多语言文本的多样化语料库上进行了约 1.7 万亿词元的预训练。我们采用三阶段预训练策略，以全面提升 YuLan 的能力。后续训练融合了指令调优与人类对齐，利用了大量优质合成数据。为助力复杂及长尾知识的学习，我们设计了贯穿各阶段的课程学习框架，使 LLM 能循序渐进地掌握知识。YuLan 于 2024 年 1 月完成训练，并在多语种基准测试中展现了顶尖性能。本文详细阐述了 LLM 开发的完整技术路径。模型与代码已公开于 https://github.com/RUC-GSAI/YuLan-Chat。
[Arxiv](https://arxiv.org/abs/2406.19853)
==========
# 虚拟上下文：利用特殊标记注入提升越狱攻击效果
发布时间：2024年06月28日
`LLM应用` `网络安全` `人工智能安全`
> Virtual Context: Enhancing Jailbreak Attacks with Special Token Injection
# 摘要
> 针对大型语言模型的越狱攻击，旨在诱导模型生成违法或不道德的内容，严重威胁模型安全。目前，这类攻击面临两大难题：防御措施导致成功率低下，以及制作特定攻击指令的高成本。本文提出的“虚拟上下文”技术，利用了以往在模型安全领域被忽视的特殊标记，有效提升了越狱攻击的效率。该技术不仅大幅提高了现有攻击手段的成功率，而且对目标模型的背景知识要求极低，使得在黑盒环境下也能高效运作，无需额外投入。实验表明，“虚拟上下文”能将四种主流越狱方法的成功率提升约40%，且在保持原有恶意行为的基础上，仍能产生显著的越狱效果。我们的研究强调了特殊标记在越狱攻击中的重要性，并建议将其纳入安全测试，以全面提升大型语言模型的安全性。
[Arxiv](https://arxiv.org/abs/2406.19845)
==========
# AnomaLLMy —— 通过低置信单令牌预测，在黑盒 LLM 中识别异常令牌
发布时间：2024年06月28日
`LLM应用` `人工智能` `软件开发`
> AnomaLLMy -- Detecting anomalous tokens in black-box LLMs through low-confidence single-token predictions
# 摘要
> 本文引入了 AnomaLLMy 技术，该技术能自动检测仅通过 API 访问的 LLM 中的异常标记。通过低置信度的单标记预测，AnomaLLMy 有效识别模型行为中的异常，从而提升模型质量和可靠性。在 GPT-4 的 cl100k_base 数据集上，该技术成功检测出 413 个主要和 65 个次要异常，且成本仅为 24.39 美元。这些发现有望进一步增强 LLM 的鲁棒性和准确性，尤其是在标记器的开发与评估领域。
[Arxiv](https://arxiv.org/abs/2406.19840)
==========
# 探索稳定且存储高效的数据集蒸馏方法：通过匹配凸化轨迹实现优化
发布时间：2024年06月28日
`LLM理论` `人工智能` `数据科学`
> Towards Stable and Storage-efficient Dataset Distillation: Matching Convexified Trajectory
# 摘要
> 随着深度学习和大型语言模型的迅猛发展，对训练数据的需求激增，推动了数据集蒸馏技术的发展。其中，匹配训练轨迹（MTT）方法通过合成数据集模拟专家网络的训练过程，但存在三大问题：专家轨迹的不稳定、蒸馏速度慢和高存储成本。为此，我们提出新视角，通过目标函数变换深入理解数据集蒸馏和MTT，并创新引入匹配凸化轨迹（MCT）方法。MCT利用神经正切核的线性动态特性，构建专家轨迹的凸组合，引导学生网络快速稳定收敛，且更易存储，支持连续采样，确保全面学习专家轨迹。实验证明，MCT在多个公共数据集上优于传统MTT方法。
[Arxiv](https://arxiv.org/abs/2406.19827)
==========
# BeamAggR：多源知识驱动下的多跳问答光束聚合推理
发布时间：2024年06月28日
`LLM应用` `问答系统` `人工智能`
> BeamAggR: Beam Aggregation Reasoning over Multi-source Knowledge for Multi-hop Question Answering
# 摘要
> 尽管大型语言模型 (LLM) 在推理方面表现出色，但在处理知识密集型任务时仍会出现事实错误。为此，我们提出了 Beam Aggregation Reasoning (BeamAggR)，这是一种针对知识密集型多跳问答的推理框架。BeamAggR 通过将复杂问题分解为树状结构，并采用自底向上的推理方法，有效探索并优先考虑每个问题环节中的潜在答案。实验结果显示，我们的方法在四个开放域多跳推理数据集上显著超越了现有技术水平，提升了 8.5%。分析进一步表明，BeamAggR 能更有效地促进知识间的协作与答案的聚合。
[Arxiv](https://arxiv.org/abs/2406.19820)
==========
# 可扩展且跨领域的抽象命题分割技术
发布时间：2024年06月28日
`LLM应用` `人工智能`
> Scalable and Domain-General Abstractive Proposition Segmentation
# 摘要
> 细粒度文本分割对NLP应用至关重要，但传统的句子分割常显不足。我们专注于抽象命题分割，旨在将文本转化为简洁、自包含的句子。尽管近期研究显示命题分割在下游任务中的潜力，但其扩展性和完整性仍有限。本文中，我们首先定义了评估指标，随后提出了一种高效且可扩展的命题分割模型。通过监督学习，我们在注释数据集上训练LLM，显著提升性能。此外，我们利用微调LLM生成大量合成数据，训练小型模型，实现相似效果。实验证明，该技术在未见领域同样有效。最后，我们提供了一个便捷的API，助力NLP实践。
[Arxiv](https://arxiv.org/abs/2406.19803)
==========
# NLPerturbator：探究代码 LLM 在自然语言变异中的稳健性
发布时间：2024年06月28日
`LLM应用` `软件开发` `人工智能`
> NLPerturbator: Studying the Robustness of Code LLMs to Natural Language Variations
# 摘要
> 大型语言模型（LLM）在根据自然语言描述生成代码方面表现出色，已广泛应用于开源和商业产品中，助力日常编程。然而，提示中的自然语言描述对模型理解用户意图至关重要，且模型对提示的微小变化极为敏感。现实中，这些描述常因格式、语法或用词不同而异。以往研究多基于随机扰动，但这些扰动在现实中未必发生。本文深入探讨了代码LLM在实际应用中对自然语言描述变化的鲁棒性，总结了18种扰动类型及3种组合，并提出了自动化框架NLPerturbator。实验表明，扰动提示可显著影响代码生成性能，凸显了提升LLM鲁棒性和精心设计提示的重要性。
[Arxiv](https://arxiv.org/abs/2406.19783)
==========
# 大型语言模型的直接偏好知识蒸馏
发布时间：2024年06月28日
`LLM理论` `人工智能`
> Direct Preference Knowledge Distillation for Large Language Models
# 摘要
> 在大型语言模型领域，知识蒸馏技术至关重要，但现有方法在效率和测量能力上存在局限。我们提出直接偏好知识蒸馏 (DPKD)，通过分布散度优化隐式奖励和输出偏好，显著提升模型性能。实验证明，DPKD 在多个数据集上表现优异，代码和数据已公开。
[Arxiv](https://arxiv.org/abs/2406.19774)
==========
# 信念修正是大型语言模型推理适应性的关键，它使模型能够灵活调整其推理过程以适应新的信息或环境变化。
发布时间：2024年06月28日
`LLM应用` `人工智能`
> Belief Revision: The Adaptability of Large Language Models Reasoning
# 摘要
> 在现实NLP应用中，从文本中推理的能力至关重要。面对不完整或变化的数据，人们会更新自己的信念和理解。然而，现有评估多假设语言模型（LMs）在一致信息下运作。为此，我们推出了Belief-R数据集，测试LMs在新证据下的信念修正能力。该任务在delta推理（$ΔR$）框架内进行，模拟了LMs需重新考虑先前结论的场景。我们评估了约30个LMs，发现它们普遍难以根据新信息适当修正信念。同时，擅长更新的模型在不需更新的场景中表现不佳，凸显了适应性与准确性之间的权衡。这强调了提升LMs对变化信息的适应性的重要性，是构建更可靠AI系统的重要一步。
[Arxiv](https://arxiv.org/abs/2406.19764)
==========
# 利用知识引导的案例重构，实现法律案例检索的可解释性学习
发布时间：2024年06月28日
`LLM应用`
> Learning Interpretable Legal Case Retrieval via Knowledge-Guided Case Reformulation
# 摘要
> 在维护司法公正中，法律案例检索至关重要。不同于普通网页搜索，法律案例检索需处理冗长、复杂的专业文件。现有方法常忽略法律专家知识的重要性，影响检索效果。本文提出KELLER，一种基于LLM的法律知识引导案例重构方法，通过整合专业法律知识，将案例精炼为关键子事实，显著提升检索性能和鲁棒性。实验证明，KELLER在复杂查询中表现卓越。
[Arxiv](https://arxiv.org/abs/2406.19760)
==========
# 利用凸包分析在大语言模型中量化不确定性
发布时间：2024年06月28日
`LLM理论` `人工智能` `数据分析`
> Uncertainty Quantification in Large Language Models Through Convex Hull Analysis
# 摘要
> 在大语言模型 (LLM) 中，特别是在高风险应用中，不确定性量化方法变得尤为关键。然而，传统的概率模型和集成技术在处理 LLM 生成输出的复杂性和高维度时面临挑战。本研究提出了一种新颖的几何方法，通过凸包分析来量化不确定性。该方法利用响应嵌入的空间属性，测量模型输出的分散度和变异性。提示分为“简单”、“中等”和“混淆”三类，以不同温度设置下的 LLM 生成多个响应。这些响应通过 BERT 模型转换为高维嵌入，并使用 PCA 投影到二维空间。DBSCAN 算法用于聚类嵌入并计算每个聚类的凸包。实验结果显示，LLM 模型的不确定性受提示复杂性、模型和温度设置的影响。
[Arxiv](https://arxiv.org/abs/2406.19712)
==========
# InfiniGen：利用动态KV缓存管理技术，提升大型语言模型生成推理的效率
发布时间：2024年06月28日
`LLM应用` `文本生成`
> InfiniGen: Efficient Generative Inference of Large Language Models with Dynamic KV Cache Management
# 摘要
> 基于Transformer的LLMs在多种NLP任务中表现卓越。然而，生成长内容时的LLM推理因KV缓存的大内存需求而受限。本文介绍的InfiniGen框架，专为长文本生成设计，与现代卸载系统协同，通过最小演练预测关键令牌，仅预取必要缓存，大幅提升系统性能至3倍，同时保持高模型准确性。
[Arxiv](https://arxiv.org/abs/2406.19707)
==========
# 探索超越人类偏好的领域，利用 LLMs 对强化学习轨迹进行评估与提升。
发布时间：2024年06月28日
`LLM应用` `人工智能`
> Beyond Human Preferences: Exploring Reinforcement Learning Trajectory Evaluation and Improvement through LLMs
# 摘要
> 强化学习在复杂游戏任务中评估策略轨迹时，因难以设计精确的奖励函数而受限。基于偏好的强化学习通过利用人类偏好作为奖励信号，避免了精细的奖励设计。但获取专家偏好数据成本高昂且效率低下。为此，我们提出了 LLM4PG 框架，利用大型语言模型自动生成偏好，优化奖励函数，加速学习进程。实验表明，该方法有效提升了强化学习在复杂任务中的表现，减少了对专业知识的依赖，展现了 LLMs 在复杂环境中增强 RL 效能的潜力。
[Arxiv](https://arxiv.org/abs/2406.19644)
==========
# Web2Code：一款大规模的网页转代码数据集与评估框架，专为多模态大型语言模型设计。
发布时间：2024年06月28日
`LLM应用` `网页开发` `自动化`
> Web2Code: A Large-scale Webpage-to-Code Dataset and Evaluation Framework for Multimodal LLMs
# 摘要
> 摘要：多模态大型语言模型（MLLMs）在跨图像、视频和音频等多种任务中表现卓越。然而，它们在理解网页截图和生成HTML代码方面却表现不佳。为此，我们提出Web2Code，包含一个大规模网页到代码数据集和评估框架，旨在提升MLLMs在这两方面的能力。我们利用预训练LLMs增强现有数据集并生成多样网页图像，输入为网页图像和指令，输出为HTML代码，并加入网页内容的自然语言QA对以深化理解。我们还开发了评估框架来测试MLLMs在这两方面的能力。实验证明，我们的数据集不仅提升了我们提出的任务性能，也在一般视觉领域表现更佳。我们期待这项工作能推动适用于网页内容生成和自动化的通用MLLMs的发展。相关数据和代码将在指定链接提供。
[Arxiv](https://arxiv.org//pdf/2406.20098)
==========
# BMW Agents 框架：通过多代理协作推动任务自动化
发布时间：2024年06月28日
`Agent` `自动化` `机器人流程自动化`
> BMW Agents -- A Framework For Task Automation Through Multi-agent Collaboration
# 摘要
> 摘要：大型语言模型（LLM）驱动的自主代理展现了自动化领域的巨大潜力。早期技术展示包括代理解决复杂任务、与外部系统互动以丰富知识及触发行动。特别是，多代理协作解决复杂任务的工作流程，突显了它们在非严格定义环境中的运作能力。因此，多代理方法在从复杂知识检索到下一代机器人流程自动化的众多工业应用中，具有成为核心架构的潜力。鉴于LLM的推理能力，复杂过程需采用包含模块化任务计划的逐步方法。任务执行可由单一代理或代理群组完成，视复杂度而定。本研究聚焦于设计一个灵活的代理工程框架，注重规划与执行，以应对跨领域的复杂应用。该框架旨在确保工业应用的可靠性，并提供技术支持，实现多自主代理间的可扩展、灵活及协作的工作流程。
[Arxiv](https://arxiv.org//pdf/2406.20041)
==========
# 利用十亿个人设扩展合成数据生成
发布时间：2024年06月28日
`LLM应用` `人工智能` `数据科学`
> Scaling Synthetic Data Creation with 1,000,000,000 Personas
# 摘要
> 我们创新性地提出了一种基于人格驱动的数据合成方法，该方法通过大型语言模型（LLM）中的多重视角，生成多样化的合成数据。为了实现这一方法的大规模应用，我们创建了Persona Hub，这是一个包含10亿多样化人格的集合，这些人格从网络数据中自动筛选而来，相当于世界人口的13%。这些人格作为知识的分布式载体，能够触及LLM中的几乎所有视角，从而助力大规模多样化合成数据的生成，广泛适用于各种场景。通过实例展示Persona Hub在生成高质量数学和逻辑问题、用户指令、知识密集型文本、游戏角色和工具等方面的大规模应用，我们证实了基于人格的数据合成方法的多功能性、可扩展性、灵活性和易用性，有望引领合成数据领域的范式变革，对LLM的研究与开发产生深远影响。
[Arxiv](https://arxiv.org//pdf/2406.20094)
==========
# PathGen-1.6M：借助多代理协作，成功生成160万对病理图像与文本。
发布时间：2024年06月28日
`LLM应用` `病理学`
> PathGen-1.6M: 1.6 Million Pathology Image-text Pairs Generation through Multi-agent Collaboration
# 摘要
> CLIP等视觉语言模型在病理学领域备受瞩目，不仅支撑着零-shot图像分类和全切片图像分析等应用，还能与大型语言模型结合，拓展更多功能。然而，现有病理学VLMs的训练数据多来自PubMed、YouTube和Twitter，数据量有限且质量参差不齐。我们通过利用TCGA等大规模WSI数据集，提取高质量图像块，并训练多模态模型生成标题，构建了PathGen-1.6M数据集，包含160万对高质量图像-标题。通过多代理模型协作，我们进一步提升了图像-文本对的质量。实验证明，结合这些高质量数据训练的PathGen-CLIP模型，在多项病理学图像分析任务中表现卓越。此外，我们还构建了20万条指令调优数据，将PathGen-CLIP与Vicuna LLM结合，通过指令调优提升多模态模型的性能。这一研究不仅为病理学领域提供了高质量数据生成的可扩展途径，也为未来通用病理学模型的发展奠定了基础。
[Arxiv](https://arxiv.org/abs/2407.00203)
==========
# ShortcutsBench：一款大型真实世界基准，专为基于 API 的代理设计。
发布时间：2024年06月28日
`Agent` `软件开发` `人工智能`
> ShortcutsBench: A Large-Scale Real-world Benchmark for API-based Agents
# 摘要
> 近年来，大型语言模型（LLMs）与应用程序编程接口（APIs）的结合在学术界和工业界备受瞩目。这些基于API的智能代理，凭借LLMs的强大自主规划能力，能高效应对多步骤任务。然而，它们在处理复杂多变的任务和现实需求方面的能力尚待探索。为此，我们推出了\textsc{ShortcutsBench}，一个全面评估API代理的大规模基准，涵盖不同难度、多样任务及现实需求。该基准集成了苹果系统的真实API、精炼用户查询、高质量动作序列及精确参数填充，旨在揭示代理在复杂查询处理上的局限。通过评估5个开源及4个闭源LLMs构建的代理，我们发现其在API选择、参数填充及信息请求方面存在明显不足，凸显了其在应对真实复杂查询时的挑战。相关数据集、代码及结果将在\url{https://github.com/eachsheep/shortcutsbench}公开。
[Arxiv](https://arxiv.org/abs/2407.00132)
==========
# 多模态学习与放射学认知：MedGaze在胸部X光扫描路径预测中的应用
发布时间：2024年06月28日
`LLM应用` `计算机视觉`
> Multimodal Learning and Cognitive Processes in Radiology: MedGaze for Chest X-ray Scanpath Prediction
# 摘要
> 在计算机视觉领域，预测人类的注视行为对于构建能够预判用户注意力的交互系统至关重要，同时也为认知科学的基本问题提供了解决方案，并对HCI和AR/VR系统等领域产生深远影响。尽管已有方法用于模拟人类的眼睛注视行为，但在医学影像领域应用这些模型进行扫描路径预测的研究尚属空白。我们提出的系统致力于从放射学报告和CXR图像中预测眼睛注视序列，有望简化数据收集流程，并利用更大数据集提升AI系统的性能。然而，预测医学图像上的扫描路径因异常区域的多样性而充满挑战。我们的模型在预测关键的固定坐标和持续时间方面表现卓越，超越了计算机视觉领域的现有模型。通过采用两阶段训练流程和利用大型公开数据集，我们的方法能够生成与放射学报告相匹配的静态热图和眼睛注视视频，从而促进深入分析。我们通过对比最先进方法的性能并评估其在不同放射科医生间的泛化能力来验证我们的方法，并创新性地模拟了放射科医生在CXR图像诊断时的搜索模式。根据放射科医生的评价，MedGaze能够生成高度聚焦于CXR图像上相关区域的人类样注视序列，甚至在扫描路径的冗余和随机性方面有时超越人类表现。
[Arxiv](https://arxiv.org/abs/2407.00129)
==========
# LLM4DESIGN：建筑与环境设计的自动化多模态解决方案
发布时间：2024年06月28日
`LLM应用` `建筑设计` `城市规划`
> LLM4DESIGN: An Automated Multi-Modal System for Architectural and Environmental Design
# 摘要
> 本研究推出 LLM4DESIGN，一个高度自动化的设计提案生成系统。该系统仅依赖场地条件和设计要求，通过多代理系统激发创造力，利用检索增强生成确保设计现实性，并借助视觉语言模型同步所有信息，产出连贯且多元的设计方案。LLM4DESIGN 不仅满足叙事与绘图的双重需求，其创新性与实用性也通过广泛实验得到验证，尤其在城市更新设计领域表现卓越。此外，我们还建立了首个跨模态设计方案数据集，涵盖建筑、景观、室内及城市设计，为未来研究提供丰富资源。
[Arxiv](https://arxiv.org/abs/2407.12025)
==========
# 探究信息检索中的关键神经元：采用集成梯度方法解析交叉编码器的奥秘
发布时间：2024年06月27日
`RAG

这篇论文主要关注检索增强生成（RAG）技术中的信息检索（IR）模型，特别是探讨了神经元在IR模型中的作用，并通过剪枝实验来验证这些发现。因此，它属于RAG分类，因为它专注于RAG框架内的信息检索机制的研究和理解。` `信息检索` `机器学习`
> Which Neurons Matter in IR? Applying Integrated Gradients-based Methods to Understand Cross-Encoders
# 摘要
> 随着检索增强生成（RAG）的引入，信息检索（IR）的重要性与日俱增。然而，对于IR模型的内部运作机制，我们的理解仍显不足。本文中，我们尝试采用基于集成梯度的方法，在IR领域中揭示单个神经元的作用，特别是那些我们称之为“相关性”神经元的角色，以及它们如何应对未知数据。最后，我们通过详尽的剪枝实验来验证这些发现。
[Arxiv](https://arxiv.org/abs/2406.19309)
==========
# 从人工针到真实干草堆：通过微调合成数据，提升大型语言模型的检索能力
发布时间：2024年06月27日
`LLM应用

这篇论文探讨了通过合成数据集微调大型语言模型（LLMs）以提高其在长上下文环境中的信息检索和推理能力。研究结果显示，特定的微调策略能够显著提升模型在实际任务中的表现，同时保持模型在通用基准测试中的稳定性。这种方法特别关注了数值键值检索任务，并展示了从合成任务到实际应用的良好技能转移。因此，这项工作属于LLM应用类别，因为它专注于实际应用中的模型性能改进。` `信息检索`
> From Artificial Needles to Real Haystacks: Improving Retrieval Capabilities in LLMs by Finetuning on Synthetic Data
# 摘要
> 最新研究表明，大型语言模型（LLMs）在处理长篇输入时，信息检索和推理能力面临挑战。为此，我们提出了一种基于合成数据集的微调策略，该数据集专为数值键值检索任务设计。实验结果显示，如GPT-3.5 Turbo和Mistral 7B等模型通过此数据集微调后，在长上下文环境中的信息检索和推理能力显著提升。我们进一步分析了这些微调模型的表现，发现它们在实际任务评估中展现出了从合成任务到实际应用的良好技能转移（例如，GPT-3.5 Turbo在处理20份文档的MDQA任务中，位置10的性能提升了10.5%）。同时，微调后的LLMs在通用基准测试中的表现保持稳定，而使用其他长上下文增强数据集的模型可能会出现性能下降，甚至产生幻觉（例如，在TriviaQA测试中，Mistral 7B微调我们的合成数据未见性能下降，而其他数据集可能导致性能下降2.33%至6.19%）。本研究凸显了通过合成数据微调提升LLMs在长上下文任务中性能的巨大潜力。
[Arxiv](https://arxiv.org/abs/2406.19292)
==========
# AutoRAG-HP：自动在线优化检索增强生成模型的超参数
发布时间：2024年06月27日
`RAG

这篇论文主要关注的是检索增强生成（RAG）系统中的自动机器学习（AutoML）问题，特别是超参数优化和在线适应的挑战。论文提出了一种名为AutoRAG-HP的框架，该框架将超参数调整视为在线多臂老虎机（MAB）问题，并采用了双层层次MAB（Hier-MAB）方法来优化RAG系统的性能。这与Agent、LLM应用和LLM理论分类不符，因为它专注于RAG系统的具体技术实现和优化，而不是代理行为、LLM的具体应用或理论基础。因此，最合适的分类是RAG。` `机器学习` `问答系统`
> AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for Retrieval-Augmented Generation
# 摘要
> 大型语言模型的进步将机器学习和人工智能的开发推向新高度，促使我们重新审视检索增强生成（RAG）系统的自动机器学习（AutoML）原则。面对RAG系统中超参数优化和在线适应的挑战，我们开发了AutoRAG-HP框架，将超参数调整视为在线多臂老虎机（MAB）问题，并创新性地采用了双层层次MAB（Hier-MAB）方法，以高效探索庞大的搜索空间。我们在ALCE-ASQA和Natural Questions数据集上进行了深入实验，调整了包括检索文档前k个、提示压缩比率和嵌入方法在内的超参数。评估结果表明，通过联合优化这三个关键超参数，基于MAB的在线学习方法在搜索空间梯度显著的场景下，Recall@5可达约0.8，仅消耗网格搜索方法所需LLM API调用的20%。此外，我们的Hier-MAB方法在更复杂的优化场景中表现出色，超越了其他基线。相关代码将在https://aka.ms/autorag公开。
[Arxiv](https://arxiv.org/abs/2406.19251)
==========
# 眼见为实：揭秘增强检索生成模型的黑盒成员推断攻击
发布时间：2024年06月27日
`RAG

该论文主要探讨了Retrieval-Augmented Generation (RAG) 技术中的安全隐私问题，特别是通过成员推理攻击 (MIA) 来检测样本是否属于 RAG 系统的知识库。这涉及到对 RAG 系统的安全性和隐私保护的研究，因此属于RAG分类。` `信息安全` `机器学习`
> Seeing Is Believing: Black-Box Membership Inference Attacks Against Retrieval Augmented Generation
# 摘要
> Retrieval-Augmented Generation (RAG) 技术通过从外部数据库检索知识，提升了大型语言模型 (LLMs) 的性能，有效缓解了幻觉和知识过时等问题。尽管 RAG 系统已知存在安全隐私风险，但外部数据库的安全性研究仍显不足。本文利用成员推理攻击 (MIA)，通过黑盒 API 访问，探究样本是否属于 RAG 系统的知识库。我们假设，若样本属于知识库，其与 RAG 生成的文本将高度相似。为此，我们通过计算余弦相似度和模型困惑度，构建了成员评分机制。进一步，我们提出了两种创新攻击策略：基于阈值和基于机器学习的攻击，以精确识别成员。实验结果显示，我们的方法达到了 82% 的 ROC AUC。
[Arxiv](https://arxiv.org/abs/2406.19234)
==========
# SeaKR：自适应知识检索增强生成，实现智能知识检索与应用
发布时间：2024年06月27日
`RAG

理由：这篇论文介绍了一种名为“自感知知识检索（SeaKR）”的新型自适应RAG模型，该模型能够从大型语言模型内部捕捉其自我感知的不确定性，并据此进行知识检索和信息优先级排序。这种技术专注于改进RAG模型的性能，特别是在处理不确定性时的表现。因此，它属于RAG分类，因为它主要关注的是RAG模型的改进和应用。` `问答系统`
> SeaKR: Self-aware Knowledge Retrieval for Adaptive Retrieval Augmented Generation
# 摘要
> 本文创新性地提出了自感知知识检索（SeaKR），一种能够从大型语言模型内部捕捉其自我感知不确定性的自适应RAG模型。当模型在生成任务中表现出不确定性时，SeaKR会启动知识检索，并根据模型的不确定性程度对检索到的信息进行优先级排序，确保最有助于降低不确定性的信息被优先使用。此外，SeaKR还能根据任务的复杂性，智能选择合适的推理策略。实验证明，无论是面对复杂还是简单的问答任务，SeaKR均超越了现有的自适应RAG技术。我们已将相关代码公开于https://github.com/THU-KEG/SeaKR，供大家参考。
[Arxiv](https://arxiv.org/abs/2406.19215)
==========
# 任意位置阅读助手：采用树形透镜定位技术的布局感知图形用户界面屏幕阅读方案
发布时间：2024年06月27日
`Agent

理由：这篇论文介绍了一种名为“透镜树”（ToL）的代理，专门设计用于屏幕点读任务（SPR）。该代理通过创新的ToL接地机制，能够处理输入的点坐标和GUI截图，构建出层次布局树，并解读指定区域的内容以及元素间的布局与空间关系。这种专门针对特定任务（SPR）的代理设计和实现，以及其在实际GUI理解任务中的应用，符合Agent类别的定义。` `人机交互` `辅助技术`
> Read Anywhere Pointed: Layout-aware GUI Screen Reading with Tree-of-Lens Grounding
# 摘要
> 图形用户界面（GUIs）是我们与数字设备互动的关键。近期，针对各种GUI理解任务的模型构建工作日益增多，但一个重要的任务——基于用户指定点的屏幕阅读（我们称之为屏幕点读任务，SPR）却被忽视。目前，这一任务主要依赖于刚性的辅助工具，亟需借助多模态大型语言模型（MLLMs）的新技术。本文提出了一种名为“透镜树”（ToL）的代理，它采用创新的ToL接地机制，专门针对SPR任务。通过输入点坐标和GUI截图，ToL代理构建出层次布局树，不仅能解读指定区域的内容，还能清晰展示元素间的布局与空间关系。这种布局信息的精确解读，使ToL代理在众多屏幕阅读工具中独树一帜。我们在新设的SPR基准上，对比了ToL代理与其他模型，涵盖了移动、网页及操作系统中的GUIs。此外，ToL代理在移动GUI导航任务中的应用，也证明了其在识别执行路径中错误动作方面的有效性。更多代码和数据，请访问：screen-point-and-read.github.io。
[Arxiv](https://arxiv.org/abs/2406.19263)
==========
# 借助LLM赋能的代理，模拟课堂教育场景
发布时间：2024年06月27日
`Agent

这篇论文主要介绍了SimClass框架，这是一个结合用户参与的多代理模拟课堂系统。它通过定义关键的课堂角色和设计自动课堂控制机制，利用大型语言模型（LLMs）在多代理协作环境中模拟真实课堂。研究通过用户实验验证了系统的效果，并展示了LLMs如何有效模拟传统课堂互动，提升用户体验。此外，论文还观察到系统中代理间自发形成的协作行为，这些行为旨在通过课堂互动促进学习过程。因此，这篇论文更符合Agent分类，因为它主要关注的是多代理系统的设计和应用，以及这些代理如何在模拟课堂环境中协作。` `虚拟教学`
> Simulating Classroom Education with LLM-Empowered Agents
# 摘要
> 大型语言模型（LLMs）在智能教育领域已广泛应用，但其在多代理协作环境中模拟真实课堂的潜力尚未充分挖掘。本研究推出了SimClass框架，这是一个结合用户参与的多代理模拟课堂系统。我们定义了关键的课堂角色，并创新性地设计了自动课堂控制机制，通过在两门真实课程中进行用户实验来验证其效果。借助Flanders互动分析系统和探究社区理论，我们展示了LLMs如何有效模拟传统课堂互动，并提升用户体验。此外，我们还观察到SimClass中代理间自发形成的协作行为，这些行为旨在通过课堂互动促进学习过程。我们期望这项研究能够引领LLM赋能的多代理系统在虚拟教学中的新应用。
[Arxiv](https://arxiv.org/abs/2406.19226)
==========
# CELLO：探究大型视觉-语言模型的因果效应评估
发布时间：2024年06月27日
`Agent

这篇论文主要关注的是大型视觉-语言模型（LVLMs）在因果推理方面的应用，特别是在具身代理等应用中的表现。论文提出了一种新的因果定义和数据集（CELLO），并通过实验展示了如何通过特定的策略（CELLO-CoT）提升LVLMs在因果推理上的表现。这些内容主要涉及如何增强模型在特定任务（如具身代理）中的因果推理能力，因此更适合归类于Agent分类，即关注模型在代理行为和决策中的应用。` `人工智能` `数据集`
> CELLO: Causal Evaluation of Large Vision-Language Models
# 摘要
> 因果推理是人类智能的基石，对于在现实世界中做出明智决策至关重要。尽管大型视觉-语言模型（LVLMs）取得了进展，但它们对因果关系的理解仍是一个谜。以往研究多聚焦于事件或行动间的常识因果，这对于具身代理等应用来说远远不够，且缺乏正式因果推理所需的明确因果图。为此，我们提出了一种涉及人与物体交互的细粒度因果定义，并据此创建了CELLO数据集，包含14,094个涵盖四个因果层次的问题，并通过明确的因果图详细描绘了人与物体的互动。实验显示，LVLMs在因果推理上仍显吃力，但通过我们提出的CELLO-CoT策略——一种受因果启发的思维链提示方法，它们能显著提升表现。本研究不仅提供了定量分析，还通过定性分析为未来研究指明了方向。项目详情请访问https://github.com/OpenCausaLab/CELLO。
[Arxiv](https://arxiv.org/abs/2406.19131)
==========
# EmPO：理论驱动下的共情响应生成数据集构建——偏好优化之道
发布时间：2024年06月27日
`Agent

这篇论文主要关注的是会话代理（Agent）中的共情响应生成问题，并提出了一种创新方法来优化大型语言模型（LLMs）以提高共情性和模型的泛化能力。虽然涉及到了LLMs的应用，但其核心在于提升会话代理的情感智能，因此更符合Agent分类。` `会话代理` `情感智能`
> EmPO: Theory-Driven Dataset Construction for Empathetic Response Generation through Preference Optimization
# 摘要
> 共情响应生成对于提升会话代理的吸引力与情感智能至关重要，它能够促进人与机器间的深入对话。尽管大型语言模型在此领域已取得进展，但如何确保响应的共情性与模型的泛化能力仍是挑战。本文提出了一种创新方法：通过构建理论驱动的偏好数据集，并运用偏好优化算法来优化LLMs，以应对这些难题。我们采用EmpatheticDialogues数据集，并结合diff-EPITOME与BERTscore指标来评估共情表现，同时在MMLU基准上检验模型的泛化能力。所有相关数据集、代码及模型均已公开。
[Arxiv](https://arxiv.org/abs/2406.19071)
==========
# UniGen：大型语言模型驱动下的文本数据集生成统一框架
发布时间：2024年06月27日
`LLM应用

这篇论文介绍了一个名为UniGen的框架，该框架由大型语言模型（LLMs）驱动，旨在生成多样、准确且高度可控的文本数据集。UniGen的设计目标是解决现有生成框架在泛化、可控性、多样性和真实性方面的挑战。它通过创新的机制，如属性引导的生成模块和组检查功能，以及基于代码的数学评估和检索增强的生成技术，来优化数据生成过程。此外，用户可以通过指定约束来定制数据生成过程。实验结果表明，UniGen生成的数据质量高，且在多个领域提升了LLM的性能。因此，这篇论文属于LLM应用分类，因为它专注于开发和应用LLM技术来解决实际问题。` `数据增强` `人工智能`
> UniGen: A Unified Framework for Textual Dataset Generation Using Large Language Models
# 摘要
> GPT-4和Llama3等大型语言模型（LLMs）通过高质量的合成数据生成，显著减少了对昂贵人工数据集的依赖，从而在多个领域产生了深远影响。然而，现有生成框架在泛化、可控、多样性和真实性方面仍存在挑战。为此，我们提出了UniGen，一个由LLM驱动的全面框架，旨在生成多样、准确且高度可控的数据集。UniGen灵活支持各类文本数据集，并通过创新机制优化生成过程。它通过属性引导的生成模块和组检查功能增强数据多样性，利用基于代码的数学评估和检索增强的生成技术确保数据准确性。用户还可通过指定约束来定制数据生成过程。实验证明，UniGen生成的数据质量卓越，各模块均发挥关键作用。在LLMs基准测试和数据增强的实际应用中，UniGen展现了其支持动态基准测试的能力，并在多个领域，包括代理导向能力和推理技能，提升了LLM的性能。
[Arxiv](https://arxiv.org/abs/2406.18966)
==========
# 不仅仅是文字，更要捕捉心灵：通过融入个性指示数据，我们能够提升角色扮演语言模型的表现力。
发布时间：2024年06月27日
`Agent

这篇论文主要关注的是角色扮演代理（RPA）在大型语言模型（LLMs）中的应用，特别是在小型角色扮演语言模型（RPLMs）中增强角色心理理解的方面。论文提出了一种方法，通过心理量表问题和高级RPA的对话生成技术来增强RPLMs，以提高其在角色扮演中的表现。这与Agent分类相关，因为Agent通常指的是能够执行特定任务或模拟特定角色的智能实体，而RPA在这里可以被视为一种特定类型的Agent，专注于角色扮演和心理理解。因此，这篇论文更适合归类于Agent。` `角色扮演` `对话系统`
> Capturing Minds, Not Just Words: Enhancing Role-Playing Language Models with Personality-Indicative Data
# 摘要
> 角色扮演代理（RPA）在大型语言模型（LLMs）中备受瞩目，吸引了工业界和学术界的广泛关注。尽管现有RPA能准确描绘角色的知识和语气，但在捕捉角色心理方面，尤其是小型角色扮演语言模型（RPLMs），仍显不足。本文提出利用心理量表问题和高级RPA的对话生成技术，通过个性指示数据增强RPLMs，以更深入地理解角色心理。实验证明，采用我们数据集训练的RPLMs在通用及个性相关评估中均展现出卓越的角色扮演能力。相关代码和数据已公开于\href{https://github.com/alienet1109/RolePersonality}{此链接}。
[Arxiv](https://arxiv.org/abs/2406.18921)
==========
# ReXTime：视频跨时间推理的基准套件
发布时间：2024年06月27日
`Agent

这篇论文主要介绍了ReXTime基准，这是一个专门设计来测试AI模型在视频事件中进行时间推理能力的基准。它特别关注跨时间推理，即模拟人类在问题和答案出现在不同视频片段时的理解方式。这种高级推理涉及对视频片段间因果关系的深刻理解，对多模态大型语言模型来说是一个挑战。论文中提到，他们开发了一套自动化系统来生成时间推理的问题与答案，并建立了一个包含多个样本的训练数据集。这个工作更偏向于Agent的范畴，因为它涉及创建和评估能够进行复杂时间推理的AI模型，这些模型可以被视为智能Agent，能够在特定任务（如视频理解）中执行复杂的推理和决策。` `视频分析` `人工智能`
> ReXTime: A Benchmark Suite for Reasoning-Across-Time in Videos
# 摘要
> 我们推出了ReXTime基准，专门设计来考验AI模型在视频事件中进行时间推理的能力。ReXTime特别关注跨时间推理，即模拟人类在问题和答案出现在不同视频片段时的理解方式。这种高级推理，涉及对视频片段间因果关系的深刻理解，对最尖端的多模态大型语言模型也是一大挑战。为此，我们开发了一套自动化系统，用于生成时间推理的问题与答案，大幅减少了对人工标注的依赖。我们的基准包含921个精挑细选的验证样本和2,143个测试样本，均由人工精心校对以确保其准确性和相关性。评估结果表明，尽管前沿的大型语言模型在性能上超越了学术模型，但与人类相比，它们在准确性上仍有14.3%的差距。此外，我们的系统还生成了一个包含9,695个样本的训练数据集，无需人工介入，实证研究显示，通过微调可以显著提升跨时间推理的能力。
[Arxiv](https://arxiv.org/abs/2406.19392)
==========
# OMG-LLaVA：融合图像、对象与像素级的推理与理解之桥
发布时间：2024年06月27日
`LLM应用

这篇论文介绍了一个名为OMG-LLaVA的框架，该框架结合了像素级视觉理解和推理能力，能够灵活地响应视觉和文本提示。它使用通用分割技术作为视觉编码器，将图像信息、感知先验和视觉提示转化为LLM的视觉令牌，而LLM则负责解析文本指令并提供文本反馈及像素级分割结果。这种方法在单一模型中实现了图像、对象及像素级别的推理与理解，并在多个测试基准上展示了优异的性能。因此，这篇论文属于LLM应用类别，因为它展示了如何将LLM应用于具体的视觉理解和推理任务中。` `计算机视觉`
> OMG-LLaVA: Bridging Image-level, Object-level, Pixel-level Reasoning and Understanding
# 摘要
> 当前的通用分割技术虽在像素级别的图像和视频理解上表现出色，却缺乏推理能力，且无法通过文本指令操控。相反，大型视觉-语言模型虽具备强大的视觉对话和推理能力，但在像素级别理解和灵活接受视觉提示方面存在局限。本文推出的OMG-LLaVA框架，巧妙融合了像素级视觉理解和推理能力，能灵活响应各类视觉和文本提示。我们采用通用分割技术作为视觉编码器，将图像信息、感知先验与视觉提示转化为LLM的视觉令牌。LLM则负责解析文本指令，并基于视觉信息提供文本反馈及像素级分割结果。通过引入感知先验嵌入，我们优化了感知先验与图像特征的融合。OMG-LLaVA在单一模型中实现了图像、对象及像素级别的推理与理解，性能在多个测试基准上与专业方法相媲美甚至超越。我们不依赖LLM连接各专家，而是通过一个编码器、一个解码器和一个LLM实现端到端训练。代码和模型已公开，以促进后续研究。
[Arxiv](https://arxiv.org/abs/2406.19389)
==========
# HuatuoGPT-Vision：大规模注入医学视觉知识至多模态LLMs的探索
发布时间：2024年06月27日
`LLM应用

理由：这篇论文主要讨论了如何利用GPT-4V等大型多模态语言模型（MLLMs）来处理和改进医疗领域的多模态数据，特别是通过构建和优化PubMedVision数据集来提升医疗多模态任务的表现。论文中提到的具体应用包括数据去噪、重构以及训练新的医疗MLLM模型（HuatuoGPT-Vision），这些都是在实际应用场景中对LLM技术的具体应用，而非理论研究或Agent、RAG相关的研究。因此，将其归类为LLM应用是合适的。` `多模态学习`
> HuatuoGPT-Vision, Towards Injecting Medical Visual Knowledge into Multimodal LLMs at Scale
# 摘要
> 随着GPT-4V等MLLMs的迅猛发展，医疗领域的多模态能力取得了显著进步，但仍受限于医疗视觉-文本数据的稀缺与质量问题，这主要归咎于数据隐私和高昂的标注成本。尽管有研究利用PubMed的大规模去标识化医疗图像-文本对来弥补这一缺陷，但数据噪声问题依旧存在。为此，我们精心筛选了PubMed的医疗图像-文本对，并运用GPT-4V以“非盲”模式进行数据去噪和重构，成功构建了包含130万医疗VQA样本的PubMedVision数据集。验证结果显示：(1) PubMedVision极大地提升了现有MLLMs在医疗多模态任务中的表现，尤其是在MMMU健康与医学赛道等基准测试中；(2) 医学专家的审核及实证分析均证实，我们的数据集在质量上超越了其他同类构建方法。基于PubMedVision，我们训练出了34B参数的医疗MLLM HuatuoGPT-Vision，其在开源MLLMs中展现出了卓越的医疗多模态应用能力。
[Arxiv](https://arxiv.org/abs/2406.19280)
==========
# RAVEN：多任务增强的视觉-语言学习，通过检索技术提升学习效果。
发布时间：2024年06月27日
`RAG

理由：这篇论文主要探讨了检索增强生成（RAG）在视觉-语言模型（VLMs）中的应用，特别是通过介绍RAVEN框架来强化基础VLMs，并通过任务特异性高效微调来整合检索增强样本。论文的重点在于展示RAG方法在VLMs中的有效性，以及其在多任务中的性能提升，这与RAG技术的应用和发展紧密相关。因此，将其归类为RAG是合适的。` `视觉-语言模型` `多模态学习`
> RAVEN: Multitask Retrieval Augmented Vision-Language Learning
# 摘要
> 将大型语言模型扩展至包含全球知识于参数中已证明不可持续，且加剧了资源限制。检索增强生成（RAG）虽提供了解决方案，但其在视觉-语言模型（VLMs）中的应用尚待深入研究。现有方法多针对单一任务模型，且受限于资源密集预训练、额外参数需求、模态优先级未明及对非检索基准优势不明显。本文推出的RAVEN框架，通过任务特异性高效微调，强化了基础VLMs。无需额外检索参数，RAVEN成功整合检索增强样本，使模型在多任务中展现出高效的检索能力。在图像标注与VQA任务上的广泛测试表明，与非检索基准相比，性能显著提升，分别在MSCOCO和NoCaps上提升了+1和+4 CIDEr，特定VQA问题类型准确率提升近+3%。这证实了RAG方法在VLMs中的有效性，为更高效、可及的多模态学习开辟了新路径。
[Arxiv](https://arxiv.org/abs/2406.19150)
==========
# DocKylin：一款大型多模态模型，专为视觉文档理解设计，通过高效的视觉瘦身技术提升性能。
发布时间：2024年06月27日
`LLM应用

理由：这篇论文介绍了一种名为DocKylin的多模态大型语言模型（MLLM），专门设计用于处理视觉文档理解（VDU）任务。论文中提到的DocKylin通过自适应像素精简（APS）和动态令牌精简（DTS）模块，有效地解决了高分辨率文档图像处理中的挑战，如计算成本和长上下文处理能力。这些创新点展示了LLM在特定应用场景下的优化和改进，因此属于LLM应用类别。` `文档处理` `视觉文档理解`
> DocKylin: A Large Multimodal Model for Visual Document Understanding with Efficient Visual Slimming
# 摘要
> 多模态大型语言模型（MLLMs）在处理高分辨率、文本密集且布局复杂的文档图像时，面临着视觉文档理解（VDU）任务的重大挑战。这些特性对MLLMs的细节感知能力提出了高要求。尽管提高输入分辨率有助于细节感知，但同时也增加了视觉令牌序列的长度，导致计算成本上升，并考验模型处理长上下文的能力。为此，我们推出了DocKylin，一种专为文档设计的MLLM，它通过在像素和令牌级别进行视觉内容精简，有效缩短了VDU场景中的令牌序列长度。DocKylin采用自适应像素精简（APS）预处理模块，提升信息像素的比重，并引入动态令牌精简（DTS）模块，筛选关键令牌，剔除非必要令牌，形成一个紧凑且自适应的视觉序列。实验结果显示，DocKylin在多个VDU基准测试中表现卓越。特别值得一提的是，APS和DTS模块均无需额外参数，易于整合进现有MLLMs，展现出广泛的应用前景。
[Arxiv](https://arxiv.org/abs/2406.19101)
==========
# 多模态AI的公平与偏见：深度探索
发布时间：2024年06月27日
`LLM理论

理由：这篇论文主要探讨了大型多模态模型（LMMs）和大型语言模型（LLMs）中的公平性与偏见问题，并提出了一种新的量化偏见的方法。这些问题和方法论的研究属于对LLM理论层面的探讨，而非具体的应用、Agent设计或RAG技术。因此，将其归类为LLM理论是合适的。` `人工智能` `数据分析`
> Fairness and Bias in Multimodal AI: A Survey
# 摘要
> AI系统中的公平性与偏见问题至关重要，近年来主流媒体对此类事件的报道不绝于耳。本调查填补了大型多模态模型（LMMs）与大型语言模型（LLMs）中公平性与偏见研究的空白，列举了50个数据集与模型实例及其面临的挑战，并新增了一种量化偏见的方法（preuse），与文献中已有的内在与外在偏见类别并列。我们深入探讨了研究者们应对这些挑战的不同策略。通过在Google Scholar上进行的两个略有差异的搜索，我们发现“大型多模态模型中的公平性与偏见”和“大型语言模型中的公平性与偏见”分别关联到33,400和538,000个链接。我们坚信，这项研究不仅填补了知识空白，还为研究人员及利益相关者提供了应对多模态AI领域公平性与偏见挑战的宝贵洞见。
[Arxiv](https://arxiv.org/abs/2406.19097)
==========
# 揭秘互动深度学习企业（No-IDLE）的内在奥秘
发布时间：2024年06月27日
`Agent

解析：这篇论文摘要主要描述了No-IDLE系统，这是一个旨在扩展非专家用户对交互式深度学习技术的接触的项目。它强调了多模态交互在交互式机器学习中的应用，并预期这种方法将在与未来神经网络和大型语言模型中的半智能机器交互时发挥关键作用。这表明该系统是一个智能代理（Agent），它通过交互式学习来理解和适应用户的行为、需求与目标。因此，这篇论文应归类为Agent。` `机器学习` `交互式系统`
> A look under the hood of the Interactive Deep Learning Enterprise (No-IDLE)
# 摘要
> DFKI的这份技术报告深入剖析了No-IDLE系统，该系统由德国联邦教育和研究部资助，不仅推动了交互式机器学习的基础研究，还深入洞察了用户的行为、需求与目标。我们期望机器学习和深度学习能普及至广大用户。No-IDLE项目旨在扩展非专家用户对交互式深度学习技术的接触，其科学挑战即围绕此目标展开。报告中的一个核心创新是结合多模态交互的交互式机器学习方法，这一方法将在我们与未来神经网络和大型语言模型中的半智能机器交互时发挥关键作用。
[Arxiv](https://arxiv.org/abs/2406.19054)
==========
# 大型语言模型（LLMs）展现出惊人的鲁棒性，其推理过程究竟经历了哪些阶段？
发布时间：2024年06月27日
`LLM理论

这篇论文的摘要主要探讨了大型语言模型（LLM）的内部结构和鲁棒性，通过实验分析了模型层级结构的变化对模型性能的影响，并提出了模型推理的四个普遍阶段。这些内容更偏向于对LLM理论层面的研究和理解，因此应归类为LLM理论。` `模型鲁棒性`
> The Remarkable Robustness of LLMs: Stages of Inference?
# 摘要
> 我们通过删除和交换相邻层，揭示了大型语言模型的非凡鲁棒性。实验表明，即使不进行微调，这些操作也能保持模型72-95%的预测准确性，且层数越多的模型鲁棒性越强。基于层级干预的实验结果，我们推测所有模型都经历了四个普遍的推理阶段：解标记化、特征工程、预测集成和残差锐化。首先，模型整合局部信息，提升原始标记至高级上下文表示；随后，对任务和实体特定特征进行迭代优化；接着，模型后半部分经历相变，隐藏表示与词汇空间对齐；最后，通过消除过时特征，最后一层精炼了后续标记的分布，减少了预测中的噪声。
[Arxiv](https://arxiv.org/abs/2406.19384)
==========
# 大型语言模型时代下的跨语言情感分析：一场模型间的较量研究
发布时间：2024年06月27日
`LLM应用

这篇论文主要探讨了大型语言模型（LLM）在跨语言情感分析中的应用和性能比较。研究通过对比不同规模和类型的模型（如XLM-R、mT5、Llama-3等）在多种语言（英语、西班牙语、法语和中文）的情感分析任务中的表现，分析了它们在零-shot和少-shot设置下的性能差异。这表明了LLM在特定应用场景下的潜力和局限性，属于LLM应用的范畴。` `情感分析`
> The Model Arena for Cross-lingual Sentiment Analysis: A Comparative Study in the Era of Large Language Models
# 摘要
> 情感分析在NLP中扮演着核心角色，而多语言预训练模型如XLM-R和mT5的进步和大型语言模型（LLM）的兴起，更是推动了跨语言情感分析的研究热潮。尽管LLM在通用NLP任务中表现出色，但其在跨语言情感分析上的潜力尚未完全挖掘。本研究通过实证分析，对比了公共小型多语言模型（如XLM-R）与以英语为中心的大型模型（如Llama-3）在英语、西班牙语、法语和中文情感分析中的跨语言表现。结果显示，SMLM在零-shot跨语言性能上优于LLM，而在少-shot设置中，LLM则展现出更强的适应性。此外，专有模型GPT-3.5和GPT-4虽在零-shot跨语言能力上领先，但在少-shot情况下，公共模型表现更佳。
[Arxiv](https://arxiv.org/abs/2406.19358)
==========
# DiVERT：数学多选题中，以文本形式呈现变分误差的干扰项生成技术
发布时间：2024年06月27日
`LLM应用

理由：这篇论文介绍了一种名为DiVERT的新方法，用于自动生成数学多选题中的干扰项，并提供了可解释的错误表示。该方法利用了大型语言模型（LLMs），并展示了在实际数据集上的有效性。这种方法的应用性质明显，因为它专注于解决实际问题（即生成高质量的干扰项），并且是在现有的LLM技术基础上进行创新。因此，它属于LLM应用类别。`
> DiVERT: Distractor Generation with Variational Errors Represented as Text for Math Multiple-choice Questions
# 摘要
> 在多选题（MCQs）中，高质量的干扰项对于评估和教学至关重要，但手动制作能准确反映学生知识漏洞或误解的干扰项实属不易。即便借助大型语言模型（LLMs），自动生成数学题的干扰项依旧充满挑战。关键在于，我们不仅要创造出看似合理的干扰项，还需洞察其背后的错误逻辑。本文推出的DiVERT（Distractor Generation with Variational Errors Represented as Text），采用了一种创新的变分方法，旨在为数学MCQs中的干扰项错误提供可解释的表示。实验基于一个包含1,434个问题的真实数学MCQ数据集，该数据集曾服务于数十万学生，结果显示，尽管DiVERT所依托的是一个基础的开源LLM，拥有70亿参数，但在干扰项生成方面，它超越了依赖GPT-4o的顶尖方法。此外，通过数学教育者的评估，我们发现DiVERT生成的错误标签质量与人工编写的相媲美。
[Arxiv](https://arxiv.org/abs/2406.19356)
==========
# IndoToxic2024：印尼语言仇恨言论与毒性类型的人口统计学丰富数据集
发布时间：2024年06月27日
`Agent

理由：这篇论文主要关注的是开发和评估一个针对印尼语的仇恨言论检测系统，其中包括创建新的数据集（IndoToxic2024）和使用微调的模型（IndoBERTweet）以及gpt-3.5-turbo模型来提升检测性能。这个工作更侧重于应用现有的技术（如BERT和GPT-3.5）来解决特定的问题（仇恨言论检测），并且涉及到了模型的微调和数据集的构建，这些都是Agent类工作的特点，即利用现有技术解决实际问题。因此，将其归类为Agent更为合适。` `社交媒体` `仇恨言论检测`
> IndoToxic2024: A Demographically-Enriched Dataset of Hate Speech and Toxicity Types for Indonesian Language
# 摘要
> 仇恨言论严重威胁社会和谐，印度尼西亚过去两年在线仇恨言论激增十倍，急需有效检测机制。但因缺乏印尼语文本标注数据，进展受阻。特别是对于什叶派、LGBTQ等少数群体，仇恨言论常被忽视，检测工具也难以理解。现有数据集对主观性的忽视更添难题。为此，我们推出IndoToxic2024数据集，包含43,692条针对印尼弱势群体的文本，由19位不同个体标注，特别关注总统选举期间的仇恨言论。我们为七个二元分类任务设定了基准，使用微调的IndoBERTweet模型达到0.78的宏观F1分数。我们还展示了如何通过整合人口统计信息提升gpt-3.5-turbo模型的零样本性能，但同时警告，过度依赖人口统计信息可能导致数据碎片化，影响微调模型的性能。
[Arxiv](https://arxiv.org/abs/2406.19349)
==========
# 借助LLM生成的先验知识，快速启动多臂老虎机策略
发布时间：2024年06月27日
`Agent

理由：这篇论文探讨了如何将大型语言模型（LLMs）与情境多臂老虎机框架结合，以模拟人类行为并优化推荐系统。这种结合涉及到创建一个能够根据用户情境做出决策的智能体（Agent），该智能体利用LLMs来生成近似人类偏好的预训练数据集，从而减少在线学习遗憾和数据收集成本。因此，这篇论文的内容更符合Agent分类，因为它涉及到了智能体的创建和应用。` `推荐系统` `在线学习`
> Jump Starting Bandits with LLM-Generated Prior Knowledge
# 摘要
> 我们展示了将大型语言模型（LLMs）与情境多臂老虎机框架结合的显著优势。情境多臂老虎机在推荐系统中广泛应用，能根据用户情境提供个性化建议。我们发现，通过丰富的人类知识与偏好预训练的LLMs，能精准模拟人类行为，有效启动情境多臂老虎机，降低在线学习遗憾。我们提出了一种新的初始化算法，利用LLMs生成近似人类偏好的预训练数据集，大幅减少了在线学习遗憾及数据收集成本。通过两组实验，我们的方法得到了验证：一组实验中LLMs作为预言机，另一组则使用了来自联合调查实验的真实数据。
[Arxiv](https://arxiv.org/abs/2406.19317)
==========
# MCNC：流形约束下的网络压缩技术
发布时间：2024年06月27日
`LLM理论

理由：这篇论文主要探讨了大型基础模型（如LLM）的压缩方法，提出了一种名为MCNC的新型压缩技术。这种技术通过将参数空间约束在预设的低维非线性流形上来实现模型压缩。论文的研究重点在于理论层面的模型压缩和优化，而不是具体的应用场景或Agent的行为，也不是RAG（Retrieval-Augmented Generation）相关的研究。因此，它更符合LLM理论的分类。` `计算机视觉`
> MCNC: Manifold Constrained Network Compression
# 摘要
> 大型基础模型在多样的任务中表现卓越，从计算机视觉到语音和自然语言处理，这大大增加了对其的需求。然而，由于其庞大的体积（如GPT-3的350GB），存储和传输这些模型面临巨大挑战。近期研究聚焦于通过压缩原始权重或减少微调所需参数来简化这些模型。这些方法通常通过限制参数空间，例如采用低秩重参数化（LoRA）或量化（QLoRA）技术来实现。本文中，我们提出了一种名为MCNC的新型压缩方法，它将参数空间约束在预设的低维非线性流形上，这些流形是冻结的，能有效覆盖整个空间。鉴于深度神经网络中过度参数化带来的良好解决方案的普遍性，我们发现通过将参数空间限制在我们提出的流形上，不仅能在多种任务中实现前所未有的压缩率，还能找到高质量的解决方案。通过在计算机视觉和自然语言处理任务上的广泛实验，我们展示了MCNC方法在压缩、准确性和模型重建时间方面均显著超越了现有技术水平。
[Arxiv](https://arxiv.org/abs/2406.19301)
==========
# PhysioLLM：结合可穿戴设备与大型语言模型，助力个性化健康洞察
发布时间：2024年06月27日
`LLM应用

理由：这篇论文介绍了一个名为PhysioLLM的系统，该系统利用大型语言模型（LLMs）来整合和分析可穿戴设备的生理数据，并提供个性化的健康洞察。这个系统展示了LLMs在实际应用中的能力，特别是在健康领域的应用，通过自然语言处理技术帮助用户理解和改善他们的健康状况。因此，这篇论文属于LLM应用类别。` `健康管理` `可穿戴设备`
> PhysioLLM: Supporting Personalized Health Insights with Wearables and Large Language Models
# 摘要
> 我们推出了PhysioLLM，这是一个交互式系统，它利用LLMs整合可穿戴设备的生理数据与上下文信息，为用户提供个性化的健康洞察。与市面上的健康应用不同，PhysioLLM具备全面的统计分析功能，能揭示用户数据中的关联与趋势，使用户能以自然语言提问并获得定制化的健康建议，帮助他们设定并达成个人健康目标。我们以改善睡眠质量为例，展示了PhysioLLM如何通过生理数据量化睡眠并提升整体福祉。在一项包含24名Fitbit用户的研究中，PhysioLLM在深化个性化健康理解和支持实现个人健康目标方面，显著优于Fitbit应用和通用LLM聊天机器人。
[Arxiv](https://arxiv.org/abs/2406.19283)
==========
# AutoPureData：为大型语言模型微调自动化筛选网络数据
发布时间：2024年06月27日
`LLM应用

这篇论文主要讨论了如何通过系统收集网络数据，并利用现有的可信AI模型自动过滤掉不受欢迎的内容，以保证数据的质量和安全性，这对于构建可靠的大型语言模型（LLMs）至关重要。因此，这篇论文的内容更偏向于LLM的应用层面，即如何处理和优化数据以支持LLM的训练和部署。` `数据净化` `人工智能`
> AutoPureData: Automated Filtering of Web Data for LLM Fine-tuning
# 摘要
> 最新可靠的大型语言模型（LLMs）一直是研究的热点。这些模型通常基于固定数据集进行训练和部署，但数据集会随时间而过时。使用网络数据自动训练AI时，数据质量和安全性成为关键问题，因为网络数据中可能包含偏见、垃圾信息等不安全或不受欢迎的内容。纯净的数据是构建可靠模型的基石。若在污染的数据上训练，模型可能会产生不良结果。本研究提出了一种系统，它能够收集网络数据，并借助现有的可信AI模型自动过滤掉不受欢迎的内容。实验中，通过处理一小部分网络数据，该系统展示了其在数据净化方面的有效性。
[Arxiv](https://arxiv.org/abs/2406.19271)
==========