# 本周RAG论文汇总 20240818
## WeKnow-RAG：融合网络搜索与知识图谱，实现检索增强生成的自适应策略
发布时间：2024年08月14日

> WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs
>
> 大型语言模型（LLM）在推动智能代理发展方面功不可没，被视为通往人工通用智能（AGI）的关键路径。但它们常生成不实信息，甚至“幻影”内容，严重威胁其可靠性，限制了实际应用。为此，我们创新提出WeKnow-RAG方法，融合网络搜索与知识图谱，构建“检索增强生成”系统，提升LLM响应的精准与可信。通过特定领域知识图谱与多阶段检索技术，我们优化了事实信息与复杂推理任务的表现，并巧妙平衡了检索效率与准确性。此外，引入自我评估机制，确保LLM生成答案的可靠性。实践证明，我们的方法在众多实验与应用中表现卓越。
>
> https://arxiv.org/abs/2408.07611

## 针对网络攻击调查与归因，我们提出了一种基于 RAG 的问答解决方案。
发布时间：2024年08月12日

> A RAG-Based Question-Answering Solution for Cyber-Attack Investigation and Attribution
>
> 在网络安全领域，分析师需紧跟最新攻击动态和相关信息，以助力网络攻击的调查与归因。我们首创的问答（QA）模型，结合检索增强生成（RAG）技术与大型语言模型（LLM），为专家提供精准的网络攻击调查与归因信息。该模型依据我们的知识库（KB）或用户外部资源，高效解答各类问题。与OpenAI的GPT模型相比，我们的QA模型不仅提供答案来源，更克服了GPT模型的幻觉限制，对网络攻击调查与归因至关重要。研究显示，RAG QA模型在提供少量示例而非零-shot指令时，答案质量更佳。
>
> https://arxiv.org/abs/2408.06272

## 本研究聚焦于优化汽车行业PDF聊天机器人的RAG技术，通过本地部署Ollama模型进行案例分析。
发布时间：2024年08月12日

> Optimizing RAG Techniques for Automotive Industry PDF Chatbots: A Case Study with Locally Deployed Ollama Models
>
> 随着汽车工业对离线PDF聊天机器人需求的增长，优化大型语言模型在本地低性能环境中的部署变得至关重要。本研究聚焦于利用本地Ollama模型提升处理复杂汽车行业文档的RAG技术。基于Langchain框架，我们提出了一种多维优化策略，针对Ollama的本地RAG实现。我们的方法解决了汽车文档处理中的关键问题，如多列布局和技术规格。我们改进了PDF处理、检索机制和上下文压缩，以适应汽车行业文档的独特性。此外，我们还设计了支持嵌入流程的自定义类和一个基于最佳实践的自RAG代理。为了评估我们的方法，我们构建了一个包含典型汽车行业文档的专有数据集，并在三个数据集上进行了比较。结果显示，在上下文精度、召回率、答案相关性和忠实度方面有显著提升，特别是在汽车行业数据集上表现卓越。我们的优化方案为汽车行业部署本地RAG系统提供了有效途径，满足了工业生产环境中PDF聊天机器人的特定需求。这项研究对推进汽车行业的信息处理和智能生产具有深远影响。
>
> https://arxiv.org/abs/2408.05933

## 利用增强检索功能的大型语言模型生成攻击图
发布时间：2024年08月11日

> Using Retriever Augmented Large Language Models for Attack Graph Generation
>
> 随着系统复杂性日益增加，评估其安全性的重要性也随之提升。攻击图作为网络安全专家的重要工具，能全面展示系统内潜在的攻击路径。传统方法依赖专家知识与手动操作，难以覆盖不断变化的威胁全貌。本文探索了利用大型语言模型（如ChatGPT）自动生成攻击图的新途径，通过智能链接漏洞信息（CVEs），并展示了如何从威胁报告中构建攻击图。
>
> https://arxiv.org/abs/2408.05855

![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2408.05855/CVE_Description.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2408.05855/SolarwindsAttack.png)

## 借助 RAG 技术与自我微调，我们开创了一种生成指令数据集的新方法。
发布时间：2024年08月11日

> A New Pipeline For Generating Instruction Dataset via RAG and Self Fine-Tuning
>
> 随着大型语言模型的迅猛发展，针对企业和组织独特需求的领域特定代理的需求日益增长。本研究提出了一种流程，利用LLM和检索增强生成框架，通过自定义文档集合在特定领域构建高质量指令数据集进行微调。该流程通过摄入领域特定文档，生成相关且上下文适当的指令，有效创建全面数据集，克服了传统方法的局限。我们的流程提供动态解决方案，快速适应文档更新，无需完全重新训练，并解决数据稀缺问题，适用于数据集稀缺的专业领域。作为案例研究，我们将其应用于精神病学领域，展示了所提出方法的可行性，并强调了其在各个行业和领域中广泛采用的潜力。
>
> https://arxiv.org/abs/2408.05911

## RAGAS：实现检索增强生成的自动化评估
发布时间：2023年09月26日

> RAGAS: Automated Evaluation of Retrieval Augmented Generation
>
> 我们推出 RAGAs 框架，用于无参考评估 RAG 系统。RAG 系统结合检索与 LLM 生成模块，让 LLM 从文本数据库获取知识，充当用户与数据库间的自然语言接口，减少幻觉风险。评估 RAG 架构颇具挑战，需考量多维度：检索系统筛选相关上下文的能力、LLM 忠实利用这些上下文的能力及生成质量。RAGAs 提出一套无需依赖人工注释的评估指标，助力 RAG 架构的快速迭代，这对 LLM 的广泛应用至关重要。
>
> https://arxiv.org/pdf/2309.15217

## HybridRAG 结合知识图谱与向量检索增强生成技术，旨在提升信息提取的效率。
发布时间：2024年08月09日

> HybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction
>
> 在金融领域，从财报电话会议记录等非结构化文本中提取复杂信息对大型语言模型（LLM）构成挑战，即便采用先进的检索增强生成（RAG）技术。为此，我们创新性地提出了HybridRAG方法，融合了基于知识图谱的GraphRAG和VectorRAG技术，旨在提升金融文档问答系统的信息提取能力，生成精准且上下文贴切的答案。实验证明，HybridRAG在检索和生成阶段均超越了单一的VectorRAG和GraphRAG技术，不仅在金融领域，该技术还具有广泛的应用潜力。
>
> https://arxiv.org/abs/2408.04948

## 混合RAG系统，全面提升复杂推理能力
发布时间：2024年08月09日

> A Hybrid RAG System with Comprehensive Enhancement on Complex Reasoning
>
> RAG 框架通过整合外部知识库，助力大型语言模型提升准确性并减少幻觉。本文介绍的混合 RAG 系统，经过一系列全面优化，大幅提升了检索质量、推理能力和数值计算精度。我们优化了网页文本和表格，引入属性预测器减少幻觉，实施了知识提取和知识图谱提取，最终构建了包含所有参考的推理策略。在 CRAG 数据集上的评估显示，我们的系统在复杂推理方面表现卓越。无论是本地还是在线评估，都证实了我们的系统在准确性和错误率上均有显著提升，且在泛化能力上表现出色。系统源代码已公开发布于 \url{https://gitlab.aicrowd.com/shizueyy/crag-new}。
>
> https://arxiv.org/abs/2408.05141

## Rag and Roll：探索基于 LLM 应用框架中，间接提示操作的全面评估之旅
发布时间：2024年08月12日

> Rag and Roll: An End-to-End Evaluation of Indirect Prompt Manipulations in LLM-based Application Frameworks
>
> RAG技术通过收集、索引、检索和提供信息，为模型赋予了分布外知识。尽管因其灵活性和低成本而日益流行，但其安全问题却鲜有研究。本文探讨了RAG系统面对端到端间接提示操纵的脆弱性。我们首先分析了现有RAG框架，识别出关键配置参数，并回顾了攻击者可能利用的技术。通过实施Rag n Roll框架，我们评估了攻击效果，发现尽管攻击者能提升恶意文档排名，但成功率仅约40%，若将模糊答案视为成功，则可达60%。使用未优化文档的攻击者，通过部署多个文档，也能达到类似效果。此外，调整RAG配置虽能略微阻碍攻击，但最有效的组合却严重影响了系统功能。
>
> https://arxiv.org/abs/2408.05025

## 利用少量示例演示提取基于 LLM 的 MOFs 合成条件
发布时间：2024年08月06日

> LLM-based MOFs Synthesis Condition Extraction using Few-Shot Demonstrations
>
> 提取金属有机框架（MOFs）的合成条件，一直是科研难题，对设计新型MOFs至关重要。大型语言模型（LLMs）的兴起，为这一难题带来了革命性解决方案，最新研究显示，从MOFs文献中提取条件的准确率超过90%。然而，我们发现，多数现有方法仍依赖于基础的零-shot学习，缺乏专业知识可能导致性能下降。为此，我们创新性地引入了少-shot情境学习范式，优化了LLM在材料合成条件提取中的应用。首先，我们设计了人机协同的数据筛选流程，确保少-shot学习的高质量示例。接着，我们采用基于RAG技术的BM25算法，智能挑选适用于每个MOF提取的少-shot示例。实验结果显示，在随机抽取的84,898个MOFs数据集中，我们的少-shot方法在自动评估下，相比原生零-shot LLM，平均F1性能提升了14.8%，且评估更为客观。此外，实际材料实验验证，我们的方法在MOFs结构推断性能上，较基准零-shot LLM平均提升了29.4%。
>
> https://arxiv.org/abs/2408.04665

![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2408.04665/x1.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2408.04665/x2.png)

<hr />

- 论文原文: [https://arxiv.org/abs/2408.04665](https://arxiv.org/abs/2408.04665)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)