# 本周Agent应用论文汇总 20240831
## AgentMove：借助大型语言模型的代理框架，精准预测全球人类流动性。
发布时间：2024年08月25日

```Agent``` ```城市规划```

> AgentMove: Predicting Human Mobility Anywhere Using Large Language Model based Agentic Framework
>
> 人类流动性预测在众多实际应用中至关重要。尽管深度学习模型在过去十年中表现出色，但其对大量私人数据和零-shot预测能力的依赖限制了进一步发展。近期，尝试将大型语言模型（LLMs）应用于移动预测，但由于缺乏系统的工作流程设计，性能受限。为此，我们提出了AgentMove框架，通过分解任务、设计模块（包括时空记忆、全球知识生成器和集体知识提取器）并结合推理步骤，实现全球城市的通用移动预测。实验表明，AgentMove在多个指标上优于现有最佳方法8%以上，且在不同LLMs基础上表现稳健，城市间地理偏见较小。详细代码和数据请访问：https://github.com/tsinghua-fib-lab/AgentMove。
>
> https://arxiv.org/abs/2408.13986

## DrugAgent：一款基于大型语言模型推理的药物再利用代理，具备可解释性。
发布时间：2024年08月23日

```Agent``` ```药物开发``` ```生物医学```

> DrugAgent: Explainable Drug Repurposing Agent with Large Language Model-based Reasoning
>
> 药物再利用为加速药物开发提供了新途径，通过挖掘现有药物的新治疗潜力。本文提出了一种多智能体框架，结合尖端机器学习技术和知识整合，优化药物再利用流程。框架内含多个专业智能体：AI智能体构建强健的药物-靶点相互作用模型；知识图谱智能体整合DGIdb、DrugBank等数据库，系统提取DTI信息；搜索智能体则与生物医学文献互动，验证并注释预测结果。通过智能体间的协同，系统有效整合多源数据，推荐可行再利用候选药物。初步成果表明，该方法不仅能预测药物与疾病的关联，还能缩短传统药物发现的时间和成本。本文凸显了多智能体系统在生物医学领域的扩展性及其在药物再利用创新中的关键作用。我们的方法不仅在预测潜力上超越现有技术，更提供了解释性结果，为更高效、经济的药物发现开辟了道路。
>
> https://arxiv.org/abs/2408.13378

## AppAgent v2：灵活移动交互的高级代理
发布时间：2024年08月23日

```Agent``` ```移动设备``` ```软件开发```

> AppAgent v2: Advanced Agent for Flexible Mobile Interactions
>
> 随着多模态大型语言模型的发展，LLM 驱动的视觉代理正日益影响着软件界面，尤其是图形用户界面。我们提出了一种创新的基于 LLM 的多模态移动设备代理框架，该框架能模拟人类交互并导航移动设备。代理通过构建灵活的动作空间，提升了在解析器、文本和视觉描述等多种应用中的适应性。其运作分为探索和部署两个阶段：探索阶段通过代理或手动方式，将用户界面元素功能记录于定制知识库；部署阶段则利用 RAG 技术高效检索和更新知识库，使代理能精准执行复杂多步骤操作，展现框架的适应性与精确性。实验结果表明，该框架在多个基准测试中表现卓越，证实了其在实际应用中的有效性。代码即将开源。
>
> https://arxiv.org/abs/2408.11824

![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2408.11824/x1.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2408.11824/x2.png)

## MEDCO：医学教育中的多智能体协作框架
发布时间：2024年08月22日

```Agent```

> MEDCO: Medical Education Copilots Based on A Multi-Agent Framework
>
> 大型语言模型（LLM）在医学和医疗保健等多个研究领域的影响深远，但其作为医学教育助手的潜力尚待挖掘。现有的AI辅助教育工具因单一学习模式和无法模拟实际医学培训的多学科互动特性而受限。为此，我们推出了MEDCO（医学教育副驾驶），一个基于多代理的创新系统，旨在模拟真实的医学培训环境。MEDCO系统包括自主患者、专家医生和放射科医生三个核心代理，共同营造一个多模式、互动的学习环境。我们的框架着重于培养学生的提问技巧、跨学科协作和同伴交流。实验表明，接受MEDCO训练的虚拟学生不仅在性能上大幅提升，媲美先进模型，还展现出类似人类的学习行为和进步，学习样本数量也有所增加。这项研究通过引入互动协作的学习助手，为医学教育领域带来了新思路，并深入探讨了AI集成培训模式的有效性。
>
> https://arxiv.org/abs/2408.12496

![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2408.12496/demonstration.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2408.12496/framework.png)

## MuMA-ToM：探索多模态环境下的多智能体心智理论
发布时间：2024年08月25日

```Agent``` ```社交互动``` ```人工智能```

> MuMA-ToM: Multi-modal Multi-Agent Theory of Mind
>
> 在复杂现实场景中理解人们的社交互动，需要深入的心理推理。为了洞察人们互动的深层原因和方式，我们必须揭示驱动这些互动的内在心理状态，即多主体互动中的心智理论推理。社交互动的多模态特性——观察、聆听和阅读——要求AI系统不仅理解个体心理状态，还要基于多模态信息推断彼此的心理状态。为此，我们推出了MuMA-ToM，首个评估具身多主体互动中心理推理的多模态心智理论基准。通过提供真实家庭环境中的多模态行为描述，MuMA-ToM引导我们探索人们的目标、信念及对他人目标的认知。在人类实验中验证MuMA-ToM并设定人类基线后，我们创新性地提出了LIMP模型，该模型在性能上显著超越了包括GPT-4o和BIP-ALM在内的顶尖模型。
>
> https://arxiv.org/abs/2408.12574

![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2408.12574/x1.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2408.12574/x2.png)

<hr />

- 论文原文: [https://arxiv.org/abs/2408.12574](https://arxiv.org/abs/2408.12574)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)