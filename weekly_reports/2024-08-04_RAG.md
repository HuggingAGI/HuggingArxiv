# 本周RAG论文汇总 20240804
## 通过迭代提问，提升医学领域检索增强生成的质量
发布时间：2024年08月01日

> Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions
>
> 大型语言模型 (LLM) 在解决医学问题方面展现出巨大潜力，尽管它们拥有丰富的医学知识，但在知识更新方面仍显僵化。为应对复杂的多轮信息需求场景，我们创新性地提出了医学领域的迭代 RAG (i-MedRAG)，使 LLM 能够基于先前信息寻求尝试，迭代提出后续查询。实验表明，i-MedRAG 在处理复杂医学问题时，显著提升了 LLM 的性能，并在 GPT-3.5 上以零-shot 方式超越了现有技术，实现了 69.68% 的准确率。此外，我们深入分析了 i-MedRAG 的扩展特性，并通过案例研究展示了其灵活构建推理链的能力，为医学问题提供了深入见解。这是首次探索将后续查询融入医学 RAG 的研究。
>
> https://arxiv.org/abs/2408.00727

## 借助 RAG 增强的 LLM，实现从特征重要性到自然语言解释的转变
发布时间：2024年07月30日

> From Feature Importance to Natural Language Explanations Using LLMs with RAG
>
> 随着机器学习在人类交互的自主决策中扮演越来越重要的角色，通过对话理解模型输出的需求日益增长。最新研究探索了基础模型作为事后解释者的潜力，为揭示预测模型的决策机制开辟了新途径。本研究引入了一种可追踪的问答机制，借助外部知识库为大型语言模型（LLM）在场景理解任务中的用户查询提供精准响应。知识库详细记录了模型输出的上下文信息，包括高级特征、特征重要性及替代概率。通过减法反事实推理，我们计算特征重要性，分析语义特征分解导致的输出变化。为确保对话连贯，我们将社会科学中的四大解释特征——社会性、因果性、选择性和对比性——融入单次提示，引导响应生成。评估结果显示，LLM生成的解释成功融合了这些要素，有效弥合了模型复杂输出与自然语言表达之间的鸿沟。
>
> https://arxiv.org/abs/2407.20990

## QAEA-DR：一款专为密集检索设计的统一文本增强框架
发布时间：2024年07月29日

> QAEA-DR: A Unified Text Augmentation Framework for Dense Retrieval
>
> 在密集检索中，长文本嵌入密集向量可能引发信息丢失，影响查询-文本匹配的准确性。同时，噪声过多或关键信息稀疏的低质量文本难以与相关查询有效对齐。近期研究多聚焦于改进句子嵌入模型或检索流程。本研究提出一种创新的文本增强框架，通过将原始文档转换为信息密集的文本格式，补充原始文本，有效应对上述挑战，无需调整嵌入或检索方法。我们利用大型语言模型（LLM）的零-shot提示，生成问答对和元素驱动的事件两种文本表示，并命名为QAEA-DR，旨在统一问答生成与事件提取，优化密集检索的文本增强。此外，我们引入基于评分的评估与再生机制，进一步提升生成文本质量。理论分析与实证实验均证实QAEA-DR模型对密集检索的积极贡献。
>
> https://arxiv.org/abs/2407.20207

## 本研究探讨了如何利用图技术实现基于代理的高级RAG系统。
发布时间：2024年07月29日

> A Study on the Implementation Method of an Agent-Based Advanced RAG System Using Graph
>
> 本研究通过改进现有RAG模型，利用图技术构建了一个先进的RAG系统，旨在提升知识型问答系统的质量。现有RAG模型虽准确流畅，但依赖预加载知识且无法整合实时数据，导致准确性和上下文理解受限。新系统通过LangGraph评估信息可靠性，综合多源数据生成更精准的回答。研究还详细阐述了系统运作、关键步骤及实例，加深了对RAG技术的理解，为企业实施先进RAG系统提供了实用指南。
>
> https://arxiv.org/abs/2407.19994

## 为 RAG 引入新超参数：上下文窗口利用率
发布时间：2024年07月29日

> Introducing a new hyper-parameter for RAG: Context Window Utilization
>
> 本文提出了一种名为“上下文窗口利用率”的新超参数，用于优化检索增强生成（RAG）系统。RAG系统通过整合外部知识库的相关信息，显著提升了生成内容的事实准确性和上下文相关性。本研究聚焦于确定最佳文本块大小，以最大化答案生成的质量。通过一系列实验，我们深入分析了不同块大小对RAG系统效率和效果的影响。研究结果显示，最佳块大小能够在提供充足上下文的同时，有效减少无关信息的干扰。这一发现对于优化RAG系统的设计与实施具有重要意义，强调了选择合适块大小以提升系统性能的关键作用。
>
> https://arxiv.org/abs/2407.19794

## 借助检索增强生成技术，少量样本学习能有效提升语言模型中的代码翻译能力。
发布时间：2024年07月28日

> Enhancing Code Translation in Language Models with Few-Shot Learning via Retrieval-Augmented Generation
>
> 大型语言模型 (LLM) 的兴起极大地推动了代码翻译领域，实现了编程语言间的自动化转换。然而，这些模型在处理复杂任务时，因上下文理解不足而常显疲态。本文提出了一种创新方法，结合少样本学习和基于检索的技术，通过动态利用现有代码翻译库中的相关示例，指导模型进行新代码段的翻译。基于检索增强生成 (RAG) 的方法，通过实时提供的上下文示例，大幅提升了翻译质量。相较于传统微调方法，RAG 能利用现有代码库或本地代码语料库，无需大规模重新训练即可适应多样翻译任务。在包括 Starcoder、Llama3-70B Instruct 等开源模型及 GPT-3.5 Turbo 等商业模型在内的多样化数据集上进行的实验，显示了我们的方法在 Fortran 和 CPP 翻译中的显著优势。此外，我们还测试了不同数量的示例和嵌入模型，以验证方法的鲁棒性和有效性。
>
> https://arxiv.org/abs/2407.19619

<hr />

- 论文原文: [https://arxiv.org/abs/2407.18752](https://arxiv.org/abs/2407.18752)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)