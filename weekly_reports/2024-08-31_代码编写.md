# 本周代码编写论文汇总 20240831
## LLMSecCode：探究大型语言模型在安全编码领域的评估
发布时间：2024年08月28日

```软件开发``` ```LLM应用``` ```网络安全```

> LLMSecCode: Evaluating Large Language Models for Secure Coding
>
> 在快速部署大型语言模型 (LLM) 时，必须慎重考虑其对网络安全的影响。我们的研究聚焦于优化适合安全编码 (SC) 的 LLM 选择流程。为此，我们提出了几个关键研究问题：如何简化 LLM 评估？评估应侧重哪些方面？如何确保评估的公正性？为解答这些问题，我们开发了开源框架 LLMSecCode，旨在客观评估 LLM 的 SC 能力。实验表明，参数和提示的变化分别导致 10% 和 9% 的性能差异。与外部权威结果对比，差异仅为 5%。我们致力于提升框架的易用性，并欢迎外部贡献以推动其发展。借助 LLMSecCode，我们期望推动安全编码领域 LLM 能力的标准化与基准测试。
>
> https://arxiv.org/abs/2408.16100

![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2408.16100/correction_chain.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2408.16100/Flow_chart.jpg)

## CodeRefine：一条流水线，旨在提升 LLM 生成的研究论文代码质量
发布时间：2024年08月23日

```软件开发``` ```LLM应用``` ```人工智能```

> CodeRefine: A Pipeline for Enhancing LLM-Generated Code Implementations of Research Papers
>
> 本文提出 CodeRefine 框架，通过 LLM 自动将研究方法转化为功能代码。该框架首先提取论文关键信息，分析其代码相关性，并构建知识图谱。随后，生成代码并通过回顾性检索增强生成方法进行优化。CodeRefine 有效连接理论与实践，提供比零-shot 提示更精准的解决方案。评估显示，该框架能提升代码质量，加速前沿算法在实际中的应用。
>
> https://arxiv.org/abs/2408.13366

![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2408.13366/x1.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2408.13366/x2.png)

## SQL-GEN：借助合成数据与模型融合，跨越文本转SQL的方言鸿沟
发布时间：2024年08月22日

```软件开发``` ```LLM应用``` ```数据库```

> SQL-GEN: Bridging the Dialect Gap for Text-to-SQL Via Synthetic Data And Model Merging
>
> Text-to-SQL 系统在 SQLite 方言上取得了显著进展，但适应其他方言如 BigQuery 和 PostgreSQL 仍具挑战。为此，我们推出了 SQL-GEN 框架，通过方言特定教程生成高质量合成数据，有效支持多方言训练数据集的创建。该方法性能提升高达 20%，并缩小了与人工标注数据集的差距。结合合成与人工标注数据，性能再提升 3.3% 至 5.6%。此外，我们创新的专家混合（MoE）初始化方法，通过整合自注意力层和方言关键词，进一步优化了跨方言性能。
>
> https://arxiv.org/abs/2408.12733

![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2408.12733/dialect_specific_queries.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2408.12733/data_generation_pipeline.png)

## 生成式AI是否将成为网络威胁者的战术新宠？探讨AI驱动网络攻击的潜在深远影响。
发布时间：2024年08月22日

```LLM应用``` ```人工智能``` ```网络安全```

> Is Generative AI the Next Tactical Cyber Weapon For Threat Actors? Unforeseen Implications of AI Generated Cyber Attacks
>
> 在数字威胁日益精密的当下，人工智能与网络安全的结合既带来了希望，也潜藏着风险。本文深入分析了AI滥用，尤其是通过大型语言模型（LLMs），所引发的威胁升级。研究揭示了网络犯罪分子如何利用切换方法和角色扮演等技术，自动化生成网络攻击。实验证明，这些模型能被操纵，绕过伦理和隐私防线，制造社会工程、恶意代码等攻击。通过在实际系统中测试这些AI攻击，研究揭示了其效力和利用的漏洞，突显了AI对关键设施的潜在风险。此外，我们引入了Occupy AI，一个专为自动化网络攻击设计的微调LLM。这种AI工具精于策划网络威胁，如钓鱼和系统入侵。研究强调了伦理AI实践、强健网络安全和监管的必要性，以应对AI威胁。本文旨在提升网络安全界对动态威胁的认识，倡导前瞻性防御和负责任AI开发，以抵御新兴威胁。
>
> https://arxiv.org/abs/2408.12806

## AutoTest：借助测试用例，进化选择代码解决方案
发布时间：2024年08月22日

```软件开发``` ```LLM应用``` ```自动化测试```

> AutoTest: Evolutionary Code Solution Selection with Test Cases
>
> 随着代码生成技术的进步，从众多候选方案中挑选出最佳代码解决方案变得尤为关键。本研究引入AutoTest技术，它巧妙结合自动化测试用例生成与代码执行，借助进化遗传算法精炼选择流程。AutoTest首先借助codegen-16B等大型预训练模型，提供代码方案及对应测试用例。随后，通过执行这些方案并评估其在测试用例上的表现，形成共识集。借助进化遗传算法的选择、变异与交叉机制，结合alpha和beta参数的微调，实现精准排序，最终选出最优代码方案。在HumanEval基准测试中，AutoTest表现卓越，该数据集涵盖164个编程难题，AutoTest在pass@1评分上较基线方法提升了约10%。
>
> https://arxiv.org/abs/2408.12125

![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2408.12125/PAPER-new.jpg)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2408.12125/genetic_algorithm.jpg)

<hr />

- 论文原文: [https://arxiv.org/abs/2408.12125](https://arxiv.org/abs/2408.12125)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)