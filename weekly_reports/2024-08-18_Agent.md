# 本周Agent论文汇总 20240818
## 基于视觉语言模型的多智能体协同规划
发布时间：2024年08月10日

> Multi-agent Planning using Visual Language Models
>
> 大型语言模型 (LLM) 和视觉语言模型 (VLM) 因其跨领域的性能提升和应用而备受瞩目。然而，在需要深入理解问题领域时，这些模型可能产生错误结果，尤其是在同时进行规划和感知时，因难以整合多模态信息而受困。为解决此问题，我们提出了一种无需特定数据结构的多智能体实体任务规划架构，仅使用环境图像并借助常识知识处理自由领域。此外，我们引入了全自动评估程序 PG2S，以更精准地评估计划质量。通过 ALFRED 数据集的验证，我们将 PG2S 与 KAS 指标对比，进一步评估了生成计划的质量。
>
> https://arxiv.org/abs/2408.05478

## TrustAgent：致力于构建基于大型语言模型的安全可信代理，通过制定代理宪法来实现这一目标。
发布时间：2024年08月10日

> TrustAgent: Towards Safe and Trustworthy LLM-based Agents through Agent Constitution
>
> 大型语言模型（LLM）驱动的代理因其互动能力而备受瞩目，但其可信性尚未得到充分研究。鉴于这些代理能直接与物理世界交互，其可靠性与安全性尤为关键。本文介绍了一种名为TrustAgent的代理框架，旨在初步探讨如何提升LLM代理的安全性，从而增强其可信度。该框架包含三种策略：预先规划策略，它在规划生成前向模型注入安全知识；规划中策略，它在规划生成时加强安全措施；以及规划后策略，通过事后检查确保安全无虞。实验分析表明，这些方法能有效提升LLM代理的安全性，通过识别和预防潜在风险。文章还深入探讨了安全性与实用性之间的微妙关系，以及模型推理能力与其作为安全代理效能之间的联系。本文强调了在设计和部署LLM代理时，必须将安全意识和可信度纳入考量，这不仅能够提升代理的表现，也确保了它们能够负责任地融入人类环境。相关数据和代码可在 https://github.com/agiresearch/TrustAgent 查看。
>
> https://arxiv.org/abs/2402.01586

<hr />

- 论文原文: [https://arxiv.org/abs/2402.01586](https://arxiv.org/abs/2402.01586)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)