# 本周RAG论文汇总 20240810
## EfficientRAG：专为多跳问答设计的高效检索工具
发布时间：2024年08月08日

> EfficientRAG: Efficient Retriever for Multi-Hop Question Answering
>
> 面对多跳查询这类复杂问题，RAG方法显得力不从心。尽管迭代检索能通过收集更多信息提升性能，但现有方法往往需多次调用大型语言模型（LLM）。本文推出的EfficientRAG，作为多跳问答的高效检索器，能在迭代中自主生成新查询，无需LLM介入，并有效剔除无关信息。实验显示，EfficientRAG在三大开放域多跳问答数据集上，性能超越了现有RAG方法。
>
> https://arxiv.org/abs/2408.04259

## 医疗图谱增强生成（Medical Graph RAG）：借助图谱检索增强技术，构建安全可靠的医疗大型语言模型。
发布时间：2024年08月07日

> Medical Graph RAG: Towards Safe Medical Large Language Model via Graph Retrieval-Augmented Generation
>
> 我们推出了一款专为医疗领域定制的基于图的 RAG 框架——**MedGraphRAG**，旨在提升大型语言模型的性能，并确保生成结果的证据基础，从而在处理敏感医疗数据时增强安全性和可靠性。我们的流程从一种创新的混合静态-语义文档分块技术开始，大幅提升了上下文捕捉能力。通过提取的实体构建了一个三层级的层次图，这些实体与医学文献和词典中的基础知识相连接。随后，这些实体相互关联形成元图，并基于语义相似性合并成一个全面的全球图，支持精准的信息检索和响应生成。检索过程中采用的 U-retrieve 方法有效平衡了全局意识和索引效率。通过全面的消融研究，我们的方法在多个医学问答基准上持续超越现有模型，并确保生成的响应包含原始文档，极大增强了医疗 LLM 的实际应用可靠性。代码即将发布于：https://github.com/MedicineToken/Medical-Graph-RAG/tree/main
>
> https://arxiv.org/abs/2408.04187

## 探究大型语言模型中基于 RAG 的漏洞增强技术
发布时间：2024年08月07日

> Exploring RAG-based Vulnerability Augmentation with LLMs
>
> 检测软件漏洞对于保障系统安全至关重要。近年来，基于深度学习的漏洞检测模型虽已普及，但受限于训练数据不足。数据增强虽有望缓解此问题，但生成含漏洞代码颇具挑战。为此，我们利用大型语言模型（LLM），探索了变异、注入和扩展三种策略，以增强单语句和多语句漏洞。实验表明，我们的注入式聚类增强RAG方法在f1-score上显著优于现有技术，尤其在大规模数据增强方面，仅需1.88美元即可生成1K样本，展现了其高效与经济性。
>
> https://arxiv.org/abs/2408.04125

![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2408.04125/x1.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2408.04125/x2.png)

## 突破大型语言模型的限制：探索检索增强生成的分类体系
发布时间：2024年08月07日

> Wiping out the limitations of Large Language Models -- A Taxonomy for Retrieval Augmented Generation
>
> 当前RAGs研究跨足多学科，因其技术飞速进步，研究焦点多在技术创新而非商业应用。为此，我们致力于构建一个分类体系，全面梳理RAG应用的本质特征，助力其在信息系统领域的推广。目前，尚无RAG应用的分类体系问世。我们详述了分类体系的构建方法，涵盖论文筛选标准、借助大型语言模型（LLM）提取特征的合理性，以及分类体系概念化的系统流程。分类体系构建历经四轮迭代，旨在深化对RAG核心维度的认识与表达。我们共设定了五个元维度与十六个维度，力求全面把握检索增强生成（RAG）应用的精髓。在成果探讨中，我们亦指明了具体研究方向，并提出关键问题，引领未来信息系统研究者深入探索RAG系统的新兴议题。
>
> https://arxiv.org/abs/2408.02854

## 通过检索助力生成，提升代码注释的质量
发布时间：2024年08月07日

> Improving Retrieval-Augmented Code Comment Generation by Retrieving for Generation
>
> 代码注释生成旨在自动从源代码中提取高质量注释，这一领域已有多年的研究。最新研究通过结合信息检索技术和神经生成模型，提出了检索增强的注释生成（RACG）方法，并取得了显著成果。然而，以往的检索器与生成器是独立构建的，这导致检索到的示例不一定最有利于注释生成，限制了方法的性能。为此，我们提出了一种新的训练策略，使检索器能够从生成器的反馈中学习，从而检索出更有助于提升注释质量的示例。具体而言，在训练中，我们通过检索器获取前k个示例并计算其检索分数，同时利用生成器计算基于这些示例的生成损失。通过将高检索分数的示例与低生成损失的示例对齐，检索器能够学会选择最优示例。基于此策略，我们开发了名为JOINTCOM的新RACG方法，并在两个真实数据集上进行了测试。实验结果显示，JOINTCOM在多个指标上显著超越了现有最先进方法。此外，人工评估也证实了JOINTCOM生成的注释在自然性、信息量和实用性方面均优于其他方法。
>
> https://arxiv.org/abs/2408.03623

## RAGEval：专为特定场景设计的 RAG 评估数据集生成框架
发布时间：2024年08月02日

> RAGEval: Scenario Specific RAG Evaluation Dataset Generation Framework
>
> RAG 系统在减轻 LLM 幻觉方面表现出色，但现有基准主要评估一般知识回答的准确性，未能全面评估其在不同垂直领域数据处理的有效性。为此，我们推出了 RAGEval 框架，自动生成评估数据集，以多维度评估 LLM 在各种场景下的知识运用能力。RAGEval 通过种子文档生成多样化文档并构建问答对，并引入 Completeness、Hallucination 和 Irrelevance 三个新指标，精准评估 LLM 响应。该框架在垂直领域对 RAG 模型进行基准测试，有效区分知识来源，无论是参数化记忆还是检索，从而更全面地评估 LLM 的知识使用能力。
>
> https://arxiv.org/abs/2408.01262

## BioRAG：专为生物学问题推理设计的 RAG-LLM 框架
发布时间：2024年08月02日

> BioRAG: A RAG-LLM Framework for Biological Question Reasoning
>
> 生命科学领域的问答系统面临快速发现、见解演变及知识实体复杂交互的挑战，需维护全面知识库与精准检索。为此，我们推出BioRAG，结合大型语言模型的检索增强生成框架。首先，我们解析、索引并分割2200万篇论文，构建基础知识库，并训练特定领域嵌入模型。通过融入领域知识层次，我们优化向量检索，解析查询与上下文间复杂关系。对于时效性强的查询，BioRAG拆解问题，借助搜索引擎进行迭代检索与推理。实验证明，BioRAG在多项生命科学问答任务中表现卓越，超越了微调LLM、集成搜索引擎的LLM及其他科学RAG框架。
>
> https://arxiv.org/abs/2408.01107

![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2408.01107/motivation.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2408.01107/x1.png)

## 针对噪声上下文的处理，检索增强生成采用了自适应对比解码技术。
发布时间：2024年08月02日

> Adaptive Contrastive Decoding in Retrieval-Augmented Generation for Handling Noisy Contexts
>
> 在开放领域问答等知识密集型任务中，大型语言模型（LLM）借助外部上下文，能更好地融合外部与内部知识。近期研究通过对比解码技术，强化了上下文知识的作用。然而，这些技术在噪声环境下表现欠佳。为此，我们拓展研究范围，引入噪声上下文，并提出自适应对比解码（ACD）策略，有效提升上下文利用效率。实验表明，ACD在开放领域问答任务中，不仅性能超越传统方法，更在噪声环境下展现出更强的稳定性。
>
> https://arxiv.org/abs/2408.01084

![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2408.01084/x1.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2408.01084/x2.png)

## Golden-Retriever：专为工业知识库设计的高保真、智能增强检索生成系统
发布时间：2024年07月20日

> Golden-Retriever: High-Fidelity Agentic Retrieval Augmented Generation for Industrial Knowledge Base
>
> 本文推出的 Golden-Retriever 工具，专为高效穿越庞大的工业知识库而设计，有效解决了传统 LLM 微调和 RAG 框架在处理专业术语和上下文理解上的难题。Golden-Retriever 在检索文档前，通过识别并澄清术语含义，增强问题表达，确保检索的准确性。具体操作包括提取术语、匹配上下文、查询详细定义，从而为 RAG 框架提供清晰且无歧义的检索环境，大幅提升检索效果。在特定领域问答数据集上的测试表明，Golden-Retriever 性能卓越，为工业知识库的高效整合与查询提供了坚实的技术支持。
>
> https://arxiv.org/abs/2408.00798

![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2408.00798/x1.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2408.00798/x2.png)

<hr />

- 论文原文: [https://arxiv.org/abs/2408.00798](https://arxiv.org/abs/2408.00798)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)