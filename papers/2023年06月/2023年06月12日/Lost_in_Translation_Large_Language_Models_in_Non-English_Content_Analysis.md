# 在非英语内容分析中，大型语言模型的应用有时会遇到“翻译中的迷失”。

发布时间：2023年06月12日

`分类：LLM应用` `人工智能` `语言处理`

> Lost in Translation: Large Language Models in Non-English Content Analysis

# 摘要

> 近期，诸如Open AI的GPT-4、Meta的LLaMa、Google的PaLM等大型语言模型，已成为在线分析和生成语言的AI系统建设的主流方法。但这些日益增多的自动化系统，如聊天机器人、内容审核系统和搜索引擎，主要针对英语设计，其效果远超过其他7000种语言。技术企业和研究者正尝试通过创建多语言语言模型，将这些大型模型的应用扩展到英语之外。本文将阐述多语言语言模型的运作机制及其能力与局限。第一部分简明扼要地解释了大型语言模型的工作原理，英语与其他语言在数据获取上的差异，以及多语言模型如何努力缩小这一差距。第二部分讨论了使用大型语言模型，尤其是多语言模型进行内容分析时面临的挑战。第三部分则为有意研究、开发和部署大型及多语言语言模型的公司、研究者和政策制定者提供了实用的建议。

> In recent years, large language models (e.g., Open AI's GPT-4, Meta's LLaMa, Google's PaLM) have become the dominant approach for building AI systems to analyze and generate language online. However, the automated systems that increasingly mediate our interactions online -- such as chatbots, content moderation systems, and search engines -- are primarily designed for and work far more effectively in English than in the world's other 7,000 languages. Recently, researchers and technology companies have attempted to extend the capabilities of large language models into languages other than English by building what are called multilingual language models.
  In this paper, we explain how these multilingual language models work and explore their capabilities and limits. Part I provides a simple technical explanation of how large language models work, why there is a gap in available data between English and other languages, and how multilingual language models attempt to bridge that gap. Part II accounts for the challenges of doing content analysis with large language models in general and multilingual language models in particular. Part III offers recommendations for companies, researchers, and policymakers to keep in mind when considering researching, developing and deploying large and multilingual language models.

[Arxiv](https://arxiv.org/abs/2306.07377)