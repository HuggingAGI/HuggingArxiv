# 大型语言模型与语言的递归性（及其缺失）

发布时间：2023年06月12日

`分类：LLM理论

这篇论文探讨了大型语言模型（LLM）在语言和非语言层面上的递归行为，特别是GPT-4模型的元语言能力。它涉及到对LLM的认知特性的研究，因此属于LLM理论分类。` `人工智能` `认知科学`

> Large language models and (non-)linguistic recursion

# 摘要

> 递归是语言的显著特征，尽管动物的交流系统展现出语言的多种设计特征，但递归却不在其中。研究指出，GPT-4是首个展现元语言能力的超大型语言模型（LLM）（Beguš, Dąbkowski, 和 Rhodes 2023）。本文提出了几种提示设计，用以激发并分析LLMs在语言和非语言层面上的递归行为。我们证实，在明确引导下，GPT-4能够生成和解析递归结构。因此，本研究首次探讨了具有大量参数的变换器，如GPT-4，是否能够发展出对递归的元语言意识——这一人类独有的认知特性。

> Recursion is one of the hallmarks of human language. While many design features of language have been shown to exist in animal communication systems, recursion has not. Previous research shows that GPT-4 is the first large language model (LLM) to exhibit metalinguistic abilities (Beguš, Dąbkowski, and Rhodes 2023). Here, we propose several prompt designs aimed at eliciting and analyzing recursive behavior in LLMs, both linguistic and non-linguistic. We demonstrate that when explicitly prompted, GPT-4 can both produce and analyze recursive structures. Thus, we present one of the first studies investigating whether meta-linguistic awareness of recursion -- a uniquely human cognitive property -- can emerge in transformers with a high number of parameters such as GPT-4.

[Arxiv](https://arxiv.org/abs/2306.07195)