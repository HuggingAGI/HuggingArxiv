# 借助丰富的背景故事，为语言模型赋予生动的虚拟角色。

发布时间：2024年07月09日

`LLM应用` `行为研究` `社会科学`

> Virtual Personas for Language Models via an Anthology of Backstories

# 摘要

> 大型语言模型 (LLM) 汲取了数百万作者的丰富文本，展现了人类特质的多样性。虽然这些模型有望在行为研究中模拟人类，但先前的工作在使模型响应与个体用户匹配方面存在局限。为此，我们提出了 "Anthology" 方法，通过开放式的生活叙事（即 "背景故事"）来定制 LLM 的虚拟人格。实验表明，这种方法不仅提升了实验结果的一致性和可靠性，还更好地代表了多样化的子群体。在皮尤研究中心的三项全国代表性调查中，Anthology 在匹配人类响应分布和提高一致性方面分别实现了 18% 和 27% 的提升。相关代码和背景故事已公开在 https://github.com/CannyLab/anthology。

> Large language models (LLMs) are trained from vast repositories of text authored by millions of distinct authors, reflecting an enormous diversity of human traits. While these models bear the potential to be used as approximations of human subjects in behavioral studies, prior efforts have been limited in steering model responses to match individual human users. In this work, we introduce "Anthology", a method for conditioning LLMs to particular virtual personas by harnessing open-ended life narratives, which we refer to as "backstories." We show that our methodology enhances the consistency and reliability of experimental outcomes while ensuring better representation of diverse sub-populations. Across three nationally representative human surveys conducted as part of Pew Research Center's American Trends Panel (ATP), we demonstrate that Anthology achieves up to 18% improvement in matching the response distributions of human respondents and 27% improvement in consistency metrics. Our code and generated backstories are available at https://github.com/CannyLab/anthology.

[Arxiv](https://arxiv.org/abs/2407.06576)