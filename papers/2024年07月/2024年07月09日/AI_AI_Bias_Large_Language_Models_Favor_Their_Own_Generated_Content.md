# 大型语言模型存在偏见，更偏爱自身生成的内容。

发布时间：2024年07月09日

`LLM应用` `人工智能` `社会科学`

> AI AI Bias: Large Language Models Favor Their Own Generated Content

# 摘要

> 我们通过模拟就业歧视研究的实验设计，测试了 GPT-3.5 和 GPT4 等广泛使用的 LLM，在二选一的情境下，让它们在人类或 LLM 描述的商品和学术论文中做出选择。结果显示，这些 AI 更偏爱由 LLM 生成的内容，这可能意味着 AI 系统在无形中对人类存在偏见，从而给予 AI 代理不公平的优势。

> Are large language models (LLMs) biased towards text generated by LLMs over text authored by humans, leading to possible anti-human bias? Utilizing a classical experimental design inspired by employment discrimination studies, we tested widely-used LLMs, including GPT-3.5 and GPT4, in binary-choice scenarios. These involved LLM-based agents selecting between products and academic papers described either by humans or LLMs under identical conditions. Our results show a consistent tendency for LLM-based AIs to prefer LLM-generated content. This suggests the possibility of AI systems implicitly discriminating against humans, giving AI agents an unfair advantage.

![大型语言模型存在偏见，更偏爱自身生成的内容。](../../../paper_images/2407.12856/x1.png)

[Arxiv](https://arxiv.org/abs/2407.12856)