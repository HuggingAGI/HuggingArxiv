# Futga 项目旨在通过时间增强的生成增强技术，深入理解音乐的细微之处。

发布时间：2024年07月29日

`LLM应用` `人工智能`

> Futga: Towards Fine-grained Music Understanding through Temporally-enhanced Generative Augmentation

# 摘要

> 现有的音乐描述方法仅能生成简短片段的概括性描述，未能捕捉音乐的细腻变化和时间特性。为此，我们推出了FUTGA模型，该模型通过学习时间组合的生成增强，具备深入理解音乐细节的能力。我们结合现有音乐描述数据集和大型语言模型，为全长歌曲生成包含结构和时间信息的细致描述。FUTGA不仅能识别音乐关键转折点的时间变化和音乐功能，还能为每个片段提供详尽描述。此外，我们发布了由FUTGA生成的全长音乐描述数据集，作为现有数据集的补充。实验显示，FUTGA在音乐生成和检索等下游任务中表现卓越。相关代码和数据集已公开，详情请访问\href{https://huggingface.co/JoshuaW1997/FUTGA}{\textcolor{blue}{https://huggingface.co/JoshuaW1997/FUTGA}}。

> Existing music captioning methods are limited to generating concise global descriptions of short music clips, which fail to capture fine-grained musical characteristics and time-aware musical changes. To address these limitations, we propose FUTGA, a model equipped with fined-grained music understanding capabilities through learning from generative augmentation with temporal compositions. We leverage existing music caption datasets and large language models (LLMs) to synthesize fine-grained music captions with structural descriptions and time boundaries for full-length songs. Augmented by the proposed synthetic dataset, FUTGA is enabled to identify the music's temporal changes at key transition points and their musical functions, as well as generate detailed descriptions for each music segment. We further introduce a full-length music caption dataset generated by FUTGA, as the augmentation of the MusicCaps and the Song Describer datasets. We evaluate the automatically generated captions on several downstream tasks, including music generation and retrieval. The experiments demonstrate the quality of the generated captions and the better performance in various downstream tasks achieved by the proposed music captioning approach. Our code and datasets can be found in \href{https://huggingface.co/JoshuaW1997/FUTGA}{\textcolor{blue}{https://huggingface.co/JoshuaW1997/FUTGA}}.

[Arxiv](https://arxiv.org/abs/2407.20445)