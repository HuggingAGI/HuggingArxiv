# 是助手还是促进者？探讨角色对语言模型行为的影响。

发布时间：2024年07月02日

`LLM应用` `人工智能`

> Helpful assistant or fruitful facilitator? Investigating how personas affect language model behavior

# 摘要

> 为了个性化和引导大型语言模型的生成内容，一种有效方法是赋予特定角色，如“有帮助的助手”或“教师”。本文深入探讨了这些角色如何影响模型的多方面行为。我们为七个大型语言模型分配了162个角色，涵盖性别、性取向和职业等12个类别。通过回答涵盖数学、历史等客观问题及信仰、价值观等主观问题的五个数据集，我们分析了角色对模型输出的影响。此外，我们通过对比“有帮助的助手”的30种不同表述和无角色的基线设置，发现角色不仅增加了输出的多样性，某些角色行为特征还具有跨模型的普遍性。

> One way to personalize and steer generations from large language models (LLM) is to assign a persona: a role that describes how the user expects the LLM to behave (e.g., a helpful assistant, a teacher, a woman). This paper investigates how personas affect diverse aspects of model behavior. We assign to seven LLMs 162 personas from 12 categories spanning variables like gender, sexual orientation, and occupation. We prompt them to answer questions from five datasets covering objective (e.g., questions about math and history) and subjective tasks (e.g., questions about beliefs and values). We also compare persona's generations to two baseline settings: a control persona setting with 30 paraphrases of "a helpful assistant" to control for models' prompt sensitivity, and an empty persona setting where no persona is assigned. We find that for all models and datasets, personas show greater variability than the control setting and that some measures of persona behavior generalize across models.

[Arxiv](https://arxiv.org/abs/2407.02099)