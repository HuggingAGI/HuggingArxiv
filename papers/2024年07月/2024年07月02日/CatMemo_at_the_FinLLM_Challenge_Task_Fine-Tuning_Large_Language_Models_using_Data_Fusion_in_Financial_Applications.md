# CatMemo在FinLLM挑战中，通过数据融合技术，优化金融应用中的大型语言模型微调。

发布时间：2024年07月02日

`LLM应用`

> CatMemo at the FinLLM Challenge Task: Fine-Tuning Large Language Models using Data Fusion in Financial Applications

# 摘要

> 在 NLP 社区中，LLM 在金融分析领域的应用备受瞩目。本文针对 IJCAI-2024 FinLLM 挑战赛，探讨了 LLM 在金融分类、文本摘要和股票交易三大关键领域的应用。我们选用 Llama3-8B 和 Mistral-7B 模型，通过 PEFT 和 LoRA 技术进行精细调整，并融合任务 1 与任务 2 的数据集以增强性能。我们的方法全面整合，旨在展示 LLM 在处理复杂金融任务时，如何提升准确性与决策力。

> The integration of Large Language Models (LLMs) into financial analysis has garnered significant attention in the NLP community. This paper presents our solution to IJCAI-2024 FinLLM challenge, investigating the capabilities of LLMs within three critical areas of financial tasks: financial classification, financial text summarization, and single stock trading. We adopted Llama3-8B and Mistral-7B as base models, fine-tuning them through Parameter Efficient Fine-Tuning (PEFT) and Low-Rank Adaptation (LoRA) approaches. To enhance model performance, we combine datasets from task 1 and task 2 for data fusion. Our approach aims to tackle these diverse tasks in a comprehensive and integrated manner, showcasing LLMs' capacity to address diverse and complex financial tasks with improved accuracy and decision-making capabilities.

[Arxiv](https://arxiv.org/abs/2407.01953)