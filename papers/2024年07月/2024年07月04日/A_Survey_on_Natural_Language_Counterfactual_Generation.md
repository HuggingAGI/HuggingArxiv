# 自然语言反事实生成研究综述

发布时间：2024年07月04日

`LLM理论` `人工智能`

> A Survey on Natural Language Counterfactual Generation

# 摘要

> 自然语言反事实生成通过微调文本，使其被重新分类，揭示了模型预测的关键因素。这些反事实不仅有助于识别模型偏见，还能通过丰富训练数据提升模型稳定性。当前，众多研究致力于探索不同NLP任务中的反事实生成技术。面对该领域的迅猛发展，进行一次系统性回顾显得尤为重要。本次调查深入探讨了基于大型语言模型的文本反事实生成方法，并创新性地将其分为四类，详细阐述了评估生成质量的标准。最后，我们分析了当前研究面临的挑战，并指出了未来研究的可能方向。

> Natural Language Counterfactual generation aims to minimally modify a given text such that the modified text will be classified into a different class. The generated counterfactuals provide insight into the reasoning behind a model's predictions by highlighting which words significantly influence the outcomes. Additionally, they can be used to detect model fairness issues or augment the training data to enhance the model's robustness. A substantial amount of research has been conducted to generate counterfactuals for various NLP tasks, employing different models and methodologies. With the rapid growth of studies in this field, a systematic review is crucial to guide future researchers and developers. To bridge this gap, this survey comprehensively overview textual counterfactual generation methods, particularly including those based on Large Language Models. We propose a new taxonomy that categorizes the generation methods into four groups and systematically summarize the metrics for evaluating the generation quality. Finally, we discuss ongoing research challenges and outline promising directions for future work.

[Arxiv](https://arxiv.org/abs/2407.03993)