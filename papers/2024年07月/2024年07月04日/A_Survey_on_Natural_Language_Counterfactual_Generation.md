# 自然语言反事实生成研究综述

发布时间：2024年07月04日

`LLM应用` `人工智能`

> A Survey on Natural Language Counterfactual Generation

# 摘要

> 自然语言反事实生成通过微调文本，使其被重新分类，揭示了模型预测的关键因素。这些反事实不仅有助于识别模型偏见，还能强化训练数据，提升模型稳定性。当前，众多研究致力于探索不同NLP任务中的反事实生成技术。面对该领域的快速发展，进行一次全面的综述显得尤为重要，旨在为后续研究提供方向。本次调查深入探讨了基于大型语言模型的文本反事实生成方法，并创新性地将其分为四类，同时详细阐述了评估生成质量的标准。最后，我们指出了当前研究的难点，并展望了未来可能的发展方向。

> Natural Language Counterfactual generation aims to minimally modify a given text such that the modified text will be classified into a different class. The generated counterfactuals provide insight into the reasoning behind a model's predictions by highlighting which words significantly influence the outcomes. Additionally, they can be used to detect model fairness issues or augment the training data to enhance the model's robustness. A substantial amount of research has been conducted to generate counterfactuals for various NLP tasks, employing different models and methodologies. With the rapid growth of studies in this field, a systematic review is crucial to guide future researchers and developers. To bridge this gap, this survey comprehensively overview textual counterfactual generation methods, particularly including those based on Large Language Models. We propose a new taxonomy that categorizes the generation methods into four groups and systematically summarize the metrics for evaluating the generation quality. Finally, we discuss ongoing research challenges and outline promising directions for future work.

[Arxiv](https://arxiv.org/abs/2407.03993)