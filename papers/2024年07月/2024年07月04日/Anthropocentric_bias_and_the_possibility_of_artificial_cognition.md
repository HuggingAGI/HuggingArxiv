# 探讨人类中心主义偏见与人工认知的潜在可能

发布时间：2024年07月04日

`LLM理论` `人工智能` `认知科学`

> Anthropocentric bias and the possibility of artificial cognition

# 摘要

> 评估LLM的认知能力，需超越拟人化与人类中心主义的偏见。本文揭示了两种常被忽视的偏见：一是忽略辅助因素在LLM能力充足时对其性能的阻碍（I型），二是误将LLM独特的机械策略视为非真正能力（II型）。为减少这些偏见，我们需采用实证驱动、迭代的方法，通过精心设计的行为实验与机制研究相结合，精准映射认知任务至LLM的特定能力和机制。

> Evaluating the cognitive capacities of large language models (LLMs) requires overcoming not only anthropomorphic but also anthropocentric biases. This article identifies two types of anthropocentric bias that have been neglected: overlooking how auxiliary factors can impede LLM performance despite competence (Type-I), and dismissing LLM mechanistic strategies that differ from those of humans as not genuinely competent (Type-II). Mitigating these biases necessitates an empirically-driven, iterative approach to mapping cognitive tasks to LLM-specific capacities and mechanisms, which can be done by supplementing carefully designed behavioral experiments with mechanistic studies.

[Arxiv](https://arxiv.org/abs/2407.03859)