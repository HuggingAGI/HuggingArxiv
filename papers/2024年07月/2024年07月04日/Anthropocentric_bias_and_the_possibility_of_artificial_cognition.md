# 探讨人类中心主义偏见与人工认知的潜在可能

发布时间：2024年07月04日

`LLM理论` `人工智能` `认知科学`

> Anthropocentric bias and the possibility of artificial cognition

# 摘要

> 评估 LLM 的认知能力，需超越人类中心主义的偏见。本文揭示了两种常被忽视的偏见：一是忽视辅助因素在 LLM 能力存在时对其性能的阻碍（I 型），二是将 LLM 的非人类机制策略视为无效（II 型）。要纠正这些偏见，需采用经验驱动、迭代的方法，结合精心设计的行为实验和机制研究，将认知任务与 LLM 的特定能力和机制相匹配。

> Evaluating the cognitive capacities of large language models (LLMs) requires overcoming not only anthropomorphic but also anthropocentric biases. This article identifies two types of anthropocentric bias that have been neglected: overlooking how auxiliary factors can impede LLM performance despite competence (Type-I), and dismissing LLM mechanistic strategies that differ from those of humans as not genuinely competent (Type-II). Mitigating these biases necessitates an empirically-driven, iterative approach to mapping cognitive tasks to LLM-specific capacities and mechanisms, which can be done by supplementing carefully designed behavioral experiments with mechanistic studies.

[Arxiv](https://arxiv.org/abs/2407.03859)