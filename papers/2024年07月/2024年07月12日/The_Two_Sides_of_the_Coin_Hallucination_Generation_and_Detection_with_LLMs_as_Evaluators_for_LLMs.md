# 幻觉生成与检测：LLM 的双重角色

发布时间：2024年07月12日

`LLM应用` `人工智能` `语言模型`

> The Two Sides of the Coin: Hallucination Generation and Detection with LLMs as Evaluators for LLMs

# 摘要

> 确保大型语言模型的可靠性，幻觉检测至关重要。我们参与了 CLEF ELOQUENT HalluciGen 共享任务，旨在开发幻觉内容生成与检测的评估器。通过探索 Llama 3、Gemma、GPT-3.5 Turbo 和 GPT-4 这四个模型的能力，并运用集成多数投票技术，我们综合利用这些模型进行幻觉检测。研究结果揭示了这些模型在幻觉生成与检测任务中的优劣，为我们提供了宝贵的洞察。

> Hallucination detection in Large Language Models (LLMs) is crucial for ensuring their reliability. This work presents our participation in the CLEF ELOQUENT HalluciGen shared task, where the goal is to develop evaluators for both generating and detecting hallucinated content. We explored the capabilities of four LLMs: Llama 3, Gemma, GPT-3.5 Turbo, and GPT-4, for this purpose. We also employed ensemble majority voting to incorporate all four models for the detection task. The results provide valuable insights into the strengths and weaknesses of these LLMs in handling hallucination generation and detection tasks.

[Arxiv](https://arxiv.org/abs/2407.09152)