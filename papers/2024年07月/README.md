# 2024年07月

2024年07月03日

- [Cactus: Towards Psychological Counseling Conversations using Cognitive Behavioral Theory](2024年07月03日/Cactus_Towards_Psychological_Counseling_Conversations_using_Cognitive_Behavioral_Theory.md)

    - [翻译: Cactus：借助认知行为理论，迈向心理咨询对话的新领域](2024年07月03日/Cactus_Towards_Psychological_Counseling_Conversations_using_Cognitive_Behavioral_Theory.md)

- [Vision-driven Automated Mobile GUI Testing via Multimodal Large Language Model](2024年07月03日/Vision-driven_Automated_Mobile_GUI_Testing_via_Multimodal_Large_Language_Model.md)

    - [翻译: 利用多模态大型语言模型实现视觉驱动的移动GUI自动化测试](2024年07月03日/Vision-driven_Automated_Mobile_GUI_Testing_via_Multimodal_Large_Language_Model.md)

- [VIVA: A Benchmark for Vision-Grounded Decision-Making with Human Values](2024年07月03日/VIVA_A_Benchmark_for_Vision-Grounded_Decision-Making_with_Human_Values.md)

    - [翻译: VIVA：一个结合视觉与人类价值观的决策制定基准](2024年07月03日/VIVA_A_Benchmark_for_Vision-Grounded_Decision-Making_with_Human_Values.md)

- [MedPix 2.0: A Comprehensive Multimodal Biomedical Dataset for Advanced AI Applications](2024年07月03日/MedPix_2.0_A_Comprehensive_Multimodal_Biomedical_Dataset_for_Advanced_AI_Applications.md)

    - [翻译: MedPix 2.0：一款集大成的多模态生物医学数据集，专为尖端AI应用打造](2024年07月03日/MedPix_2.0_A_Comprehensive_Multimodal_Biomedical_Dataset_for_Advanced_AI_Applications.md)

- [MindBench: A Comprehensive Benchmark for Mind Map Structure Recognition and Analysis](2024年07月03日/MindBench_A_Comprehensive_Benchmark_for_Mind_Map_Structure_Recognition_and_Analysis.md)

    - [翻译: MindBench：全面评估思维导图结构识别与分析的基准](2024年07月03日/MindBench_A_Comprehensive_Benchmark_for_Mind_Map_Structure_Recognition_and_Analysis.md)

- [Improving Retrieval-augmented Text-to-SQL with AST-based Ranking and Schema Pruning](2024年07月03日/Improving_Retrieval-augmented_Text-to-SQL_with_AST-based_Ranking_and_Schema_Pruning.md)

    - [翻译: 通过结合基于抽象语法树的排序和模式剪枝技术，提升检索增强型文本到SQL的转换效率。](2024年07月03日/Improving_Retrieval-augmented_Text-to-SQL_with_AST-based_Ranking_and_Schema_Pruning.md)

- [How Does Quantization Affect Multilingual LLMs?](2024年07月03日/How_Does_Quantization_Affect_Multilingual_LLMs.md)

    - [翻译: 量化对多语言LLM的影响如何？](2024年07月03日/How_Does_Quantization_Affect_Multilingual_LLMs.md)

- [TheoremLlama: Transforming General-Purpose LLMs into Lean4 Experts](2024年07月03日/TheoremLlama_Transforming_General-Purpose_LLMs_into_Lean4_Experts.md)

    - [翻译: TheoremLlama：让通用 LLM 成为 Lean4 领域的专家](2024年07月03日/TheoremLlama_Transforming_General-Purpose_LLMs_into_Lean4_Experts.md)

- [Fine-Tuning with Divergent Chains of Thought Boosts Reasoning Through Self-Correction in Language Models](2024年07月03日/Fine-Tuning_with_Divergent_Chains_of_Thought_Boosts_Reasoning_Through_Self-Correction_in_Language_Models.md)

    - [翻译: 采用多样化的思维链进行微调，能显著提升语言模型通过自我纠错机制进行推理的能力。](2024年07月03日/Fine-Tuning_with_Divergent_Chains_of_Thought_Boosts_Reasoning_Through_Self-Correction_in_Language_Models.md)

- [Investigating Decoder-only Large Language Models for Speech-to-text Translation](2024年07月03日/Investigating_Decoder-only_Large_Language_Models_for_Speech-to-text_Translation.md)

    - [翻译: 探索仅解码器大型语言模型在语音转文本翻译中的应用](2024年07月03日/Investigating_Decoder-only_Large_Language_Models_for_Speech-to-text_Translation.md)

- [SOS! Soft Prompt Attack Against Open-Source Large Language Models](2024年07月03日/SOS!_Soft_Prompt_Attack_Against_Open-Source_Large_Language_Models.md)

    - [翻译: 紧急呼叫！针对开源大型语言模型的软提示攻击](2024年07月03日/SOS!_Soft_Prompt_Attack_Against_Open-Source_Large_Language_Models.md)

- [Let the Code LLM Edit Itself When You Edit the Code](2024年07月03日/Let_the_Code_LLM_Edit_Itself_When_You_Edit_the_Code.md)

    - [翻译: 代码 LLM 在你修改代码时，也能自我修正。](2024年07月03日/Let_the_Code_LLM_Edit_Itself_When_You_Edit_the_Code.md)

- [Reinforcement Learning for Sequence Design Leveraging Protein Language Models](2024年07月03日/Reinforcement_Learning_for_Sequence_Design_Leveraging_Protein_Language_Models.md)

    - [翻译: 借助蛋白质语言模型，强化学习在序列设计领域大放异彩。](2024年07月03日/Reinforcement_Learning_for_Sequence_Design_Leveraging_Protein_Language_Models.md)

- [Enhancing Translation Accuracy of Large Language Models through Continual Pre-Training on Parallel Data](2024年07月03日/Enhancing_Translation_Accuracy_of_Large_Language_Models_through_Continual_Pre-Training_on_Parallel_Data.md)

    - [翻译: 借助平行数据的持续预训练，我们能够显著提升大型语言模型的翻译精准度。](2024年07月03日/Enhancing_Translation_Accuracy_of_Large_Language_Models_through_Continual_Pre-Training_on_Parallel_Data.md)

- [Social Bias Evaluation for Large Language Models Requires Prompt Variations](2024年07月03日/Social_Bias_Evaluation_for_Large_Language_Models_Requires_Prompt_Variations.md)

    - [翻译: 评估大型语言模型的社会偏见，需借助多样化的提示手段。](2024年07月03日/Social_Bias_Evaluation_for_Large_Language_Models_Requires_Prompt_Variations.md)

- [KeyVideoLLM: Towards Large-scale Video Keyframe Selection](2024年07月03日/KeyVideoLLM_Towards_Large-scale_Video_Keyframe_Selection.md)

    - [翻译: KeyVideoLLM：探索大规模视频关键帧的精选之道](2024年07月03日/KeyVideoLLM_Towards_Large-scale_Video_Keyframe_Selection.md)

- [ScreenTK: Seamless Detection of Time-Killing Moments Using Continuous Mobile Screen Text Monitoring](2024年07月03日/ScreenTK_Seamless_Detection_of_Time-Killing_Moments_Using_Continuous_Mobile_Screen_Text_Monitoring.md)

    - [翻译: ScreenTK：通过持续监控移动屏幕文本，精准捕捉消磨时光的瞬间](2024年07月03日/ScreenTK_Seamless_Detection_of_Time-Killing_Moments_Using_Continuous_Mobile_Screen_Text_Monitoring.md)

- [ALTER: Augmentation for Large-Table-Based Reasoning](2024年07月03日/ALTER_Augmentation_for_Large-Table-Based_Reasoning.md)

    - [翻译: ALTER：大型表格推理的增强方案](2024年07月03日/ALTER_Augmentation_for_Large-Table-Based_Reasoning.md)

- [Improving Conversational Abilities of Quantized Large Language Models via Direct Preference Alignment](2024年07月03日/Improving_Conversational_Abilities_of_Quantized_Large_Language_Models_via_Direct_Preference_Alignment.md)

    - [翻译: 借助直接偏好对齐，我们致力于提升量化大型语言模型在对话中的表现。](2024年07月03日/Improving_Conversational_Abilities_of_Quantized_Large_Language_Models_via_Direct_Preference_Alignment.md)

- [JailbreakHunter: A Visual Analytics Approach for Jailbreak Prompts Discovery from Large-Scale Human-LLM Conversational Datasets](2024年07月03日/JailbreakHunter_A_Visual_Analytics_Approach_for_Jailbreak_Prompts_Discovery_from_Large-Scale_Human-LLM_Conversational_Datasets.md)

    - [翻译: JailbreakHunter：一种视觉分析方法，旨在从大规模人类与 LLM 的对话数据集中发现越狱提示。](2024年07月03日/JailbreakHunter_A_Visual_Analytics_Approach_for_Jailbreak_Prompts_Discovery_from_Large-Scale_Human-LLM_Conversational_Datasets.md)

- [Raw Text is All you Need: Knowledge-intensive Multi-turn Instruction Tuning for Large Language Model](2024年07月03日/Raw_Text_is_All_you_Need_Knowledge-intensive_Multi-turn_Instruction_Tuning_for_Large_Language_Model.md)

    - [翻译: 仅需原始文本：为大型语言模型进行知识密集型多轮指令调优](2024年07月03日/Raw_Text_is_All_you_Need_Knowledge-intensive_Multi-turn_Instruction_Tuning_for_Large_Language_Model.md)

- [On the Client Preference of LLM Fine-tuning in Federated Learning](2024年07月03日/On_the_Client_Preference_of_LLM_Fine-tuning_in_Federated_Learning.md)

    - [翻译: 探讨联邦学习环境下，客户端对 LLM 微调的偏好](2024年07月03日/On_the_Client_Preference_of_LLM_Fine-tuning_in_Federated_Learning.md)

- [SAFT: Towards Out-of-Distribution Generalization in Fine-Tuning](2024年07月03日/SAFT_Towards_Out-of-Distribution_Generalization_in_Fine-Tuning.md)

    - [翻译: SAFT：致力于在微调过程中实现分布外的泛化能力](2024年07月03日/SAFT_Towards_Out-of-Distribution_Generalization_in_Fine-Tuning.md)

- [Align and Aggregate: Compositional Reasoning with Video Alignment and Answer Aggregation for Video Question-Answering](2024年07月03日/Align_and_Aggregate_Compositional_Reasoning_with_Video_Alignment_and_Answer_Aggregation_for_Video_Question-Answering.md)

    - [翻译: 通过视频对齐与答案聚合，实现组合推理，提升视频问答的准确性。](2024年07月03日/Align_and_Aggregate_Compositional_Reasoning_with_Video_Alignment_and_Answer_Aggregation_for_Video_Question-Answering.md)

- [What Affects the Stability of Tool Learning? An Empirical Study on the Robustness of Tool Learning Frameworks](2024年07月03日/What_Affects_the_Stability_of_Tool_Learning_An_Empirical_Study_on_the_Robustness_of_Tool_Learning_Frameworks.md)

    - [翻译: 工具学习的稳定性受何影响？本研究深入探讨了工具学习框架的鲁棒性。](2024年07月03日/What_Affects_the_Stability_of_Tool_Learning_An_Empirical_Study_on_the_Robustness_of_Tool_Learning_Frameworks.md)

- [SemioLLM: Assessing Large Language Models for Semiological Analysis in Epilepsy Research](2024年07月03日/SemioLLM_Assessing_Large_Language_Models_for_Semiological_Analysis_in_Epilepsy_Research.md)

    - [翻译: SemioLLM：探究大型语言模型在癫痫研究符号学分析中的应用潜力](2024年07月03日/SemioLLM_Assessing_Large_Language_Models_for_Semiological_Analysis_in_Epilepsy_Research.md)

- [Are Large Language Models Consistent over Value-laden Questions?](2024年07月03日/Are_Large_Language_Models_Consistent_over_Value-laden_Questions.md)

    - [翻译: 大型语言模型在处理价值导向问题时，其一致性如何？](2024年07月03日/Are_Large_Language_Models_Consistent_over_Value-laden_Questions.md)

- [Scientific Text Analysis with Robots applied to observatory proposals](2024年07月03日/Scientific_Text_Analysis_with_Robots_applied_to_observatory_proposals.md)

    - [翻译: 机器人辅助的科学文本分析在观测站提案中的应用](2024年07月03日/Scientific_Text_Analysis_with_Robots_applied_to_observatory_proposals.md)

- [LoRA-Guard: Parameter-Efficient Guardrail Adaptation for Content Moderation of Large Language Models](2024年07月03日/LoRA-Guard_Parameter-Efficient_Guardrail_Adaptation_for_Content_Moderation_of_Large_Language_Models.md)

    - [翻译: LoRA-Guard：为大型语言模型提供参数高效的内容审核护栏适应方案](2024年07月03日/LoRA-Guard_Parameter-Efficient_Guardrail_Adaptation_for_Content_Moderation_of_Large_Language_Models.md)

- [Mast Kalandar at SemEval-2024 Task 8: On the Trail of Textual Origins: RoBERTa-BiLSTM Approach to Detect AI-Generated Text](2024年07月03日/Mast_Kalandar_at_SemEval-2024_Task_8_On_the_Trail_of_Textual_Origins_RoBERTa-BiLSTM_Approach_to_Detect_AI-Generated_Text.md)

    - [翻译: Mast Kalandar 参与 SemEval-2024 任务 8，探索文本源头：采用 RoBERTa-BiLSTM 方法，精准识别 AI 生成文本。](2024年07月03日/Mast_Kalandar_at_SemEval-2024_Task_8_On_the_Trail_of_Textual_Origins_RoBERTa-BiLSTM_Approach_to_Detect_AI-Generated_Text.md)

- [Large Language Models as Evaluators for Scientific Synthesis](2024年07月03日/Large_Language_Models_as_Evaluators_for_Scientific_Synthesis.md)

    - [翻译: 大型语言模型：科学综合的评判者](2024年07月03日/Large_Language_Models_as_Evaluators_for_Scientific_Synthesis.md)

- [FSM: A Finite State Machine Based Zero-Shot Prompting Paradigm for Multi-Hop Question Answering](2024年07月03日/FSM_A_Finite_State_Machine_Based_Zero-Shot_Prompting_Paradigm_for_Multi-Hop_Question_Answering.md)

    - [翻译: FSM：一种基于有限状态机的零-shot 提示方法，专为多跳问题回答设计](2024年07月03日/FSM_A_Finite_State_Machine_Based_Zero-Shot_Prompting_Paradigm_for_Multi-Hop_Question_Answering.md)

- [GraCoRe: Benchmarking Graph Comprehension and Complex Reasoning in Large Language Models](2024年07月03日/GraCoRe_Benchmarking_Graph_Comprehension_and_Complex_Reasoning_in_Large_Language_Models.md)

    - [翻译: GraCoRe：评估大型语言模型中的图表理解和复杂推理能力](2024年07月03日/GraCoRe_Benchmarking_Graph_Comprehension_and_Complex_Reasoning_in_Large_Language_Models.md)

- [GPTQT: Quantize Large Language Models Twice to Push the Efficiency](2024年07月03日/GPTQT_Quantize_Large_Language_Models_Twice_to_Push_the_Efficiency.md)

    - [翻译: GPTQT：通过两次量化大型语言模型，推动效率提升](2024年07月03日/GPTQT_Quantize_Large_Language_Models_Twice_to_Push_the_Efficiency.md)

- [CogErgLLM: Exploring Large Language Model Systems Design Perspective Using Cognitive Ergonomics](2024年07月03日/CogErgLLM_Exploring_Large_Language_Model_Systems_Design_Perspective_Using_Cognitive_Ergonomics.md)

    - [翻译: CogErgLLM：从认知工效学角度探究大型语言模型的系统设计](2024年07月03日/CogErgLLM_Exploring_Large_Language_Model_Systems_Design_Perspective_Using_Cognitive_Ergonomics.md)

- [LANE: Logic Alignment of Non-tuning Large Language Models and Online Recommendation Systems for Explainable Reason Generation](2024年07月03日/LANE_Logic_Alignment_of_Non-tuning_Large_Language_Models_and_Online_Recommendation_Systems_for_Explainable_Reason_Generation.md)

    - [翻译: LANE：实现非调优大型语言模型与在线推荐系统的逻辑对齐，旨在生成可解释的推理。](2024年07月03日/LANE_Logic_Alignment_of_Non-tuning_Large_Language_Models_and_Online_Recommendation_Systems_for_Explainable_Reason_Generation.md)

- [Exploring the Capabilities of LLMs for Code Change Related Tasks](2024年07月03日/Exploring_the_Capabilities_of_LLMs_for_Code_Change_Related_Tasks.md)

    - [翻译: 探究 LLM 在代码变更任务中的潜能](2024年07月03日/Exploring_the_Capabilities_of_LLMs_for_Code_Change_Related_Tasks.md)

- [Efficient Training of Language Models with Compact and Consistent Next Token Distributions](2024年07月03日/Efficient_Training_of_Language_Models_with_Compact_and_Consistent_Next_Token_Distributions.md)

    - [翻译: 通过紧凑一致的下一词分布，实现语言模型的高效训练](2024年07月03日/Efficient_Training_of_Language_Models_with_Compact_and_Consistent_Next_Token_Distributions.md)

2024年07月02日

- [Talking to Machines: do you read me?](2024年07月02日/Talking_to_Machines_do_you_read_me.md)

    - [翻译: 机器，你懂我的话吗？](2024年07月02日/Talking_to_Machines_do_you_read_me.md)

- [Embodied AI in Mobile Robots: Coverage Path Planning with Large Language Models](2024年07月02日/Embodied_AI_in_Mobile_Robots_Coverage_Path_Planning_with_Large_Language_Models.md)

    - [翻译: 移动机器人中的具身AI：借助大型语言模型实现高效覆盖路径规划](2024年07月02日/Embodied_AI_in_Mobile_Robots_Coverage_Path_Planning_with_Large_Language_Models.md)

- [TokenPacker: Efficient Visual Projector for Multimodal LLM](2024年07月02日/TokenPacker_Efficient_Visual_Projector_for_Multimodal_LLM.md)

    - [翻译: TokenPacker：专为多模态 LLM 设计的高效视觉投影工具](2024年07月02日/TokenPacker_Efficient_Visual_Projector_for_Multimodal_LLM.md)

- [Towards a Holistic Framework for Multimodal Large Language Models in Three-dimensional Brain CT Report Generation](2024年07月02日/Towards_a_Holistic_Framework_for_Multimodal_Large_Language_Models_in_Three-dimensional_Brain_CT_Report_Generation.md)

    - [翻译: 构建综合框架，助力三维脑CT报告生成中的多模态大型语言模型发展](2024年07月02日/Towards_a_Holistic_Framework_for_Multimodal_Large_Language_Models_in_Three-dimensional_Brain_CT_Report_Generation.md)

- [Synthetic Multimodal Question Generation](2024年07月02日/Synthetic_Multimodal_Question_Generation.md)

    - [翻译: 多模态问题生成的合成技术](2024年07月02日/Synthetic_Multimodal_Question_Generation.md)

- [Crossroads of Continents: Automated Artifact Extraction for Cultural Adaptation with Large Multimodal Models](2024年07月02日/Crossroads_of_Continents_Automated_Artifact_Extraction_for_Cultural_Adaptation_with_Large_Multimodal_Models.md)

    - [翻译: 大陆交汇处：借助大型多模态模型实现文化适应的自动文物提取](2024年07月02日/Crossroads_of_Continents_Automated_Artifact_Extraction_for_Cultural_Adaptation_with_Large_Multimodal_Models.md)

- [An End-to-End Speech Summarization Using Large Language Model](2024年07月02日/An_End-to-End_Speech_Summarization_Using_Large_Language_Model.md)

    - [翻译: 利用大型语言模型实现端到端语音摘要](2024年07月02日/An_End-to-End_Speech_Summarization_Using_Large_Language_Model.md)

- [Certainly Uncertain: A Benchmark and Metric for Multimodal Epistemic and Aleatoric Awareness](2024年07月02日/Certainly_Uncertain_A_Benchmark_and_Metric_for_Multimodal_Epistemic_and_Aleatoric_Awareness.md)

    - [翻译: 探索不确定性：多模态认知与偶然性意识的评估基准与度量](2024年07月02日/Certainly_Uncertain_A_Benchmark_and_Metric_for_Multimodal_Epistemic_and_Aleatoric_Awareness.md)

- [Video Watermarking: Safeguarding Your Video from (Unauthorized) Annotations by Video-based LLMs](2024年07月02日/Video_Watermarking_Safeguarding_Your_Video_from_(Unauthorized)_Annotations_by_Video-based_LLMs.md)

    - [翻译: 视频水印技术：保护您的视频内容，防止基于视频的 LLM 进行未经授权的注释。](2024年07月02日/Video_Watermarking_Safeguarding_Your_Video_from_(Unauthorized)_Annotations_by_Video-based_LLMs.md)

- [CEB: Compositional Evaluation Benchmark for Fairness in Large Language Models](2024年07月02日/CEB_Compositional_Evaluation_Benchmark_for_Fairness_in_Large_Language_Models.md)

    - [翻译: CEB：大型语言模型公平性的组合评估基准](2024年07月02日/CEB_Compositional_Evaluation_Benchmark_for_Fairness_in_Large_Language_Models.md)

- [Assessing the Code Clone Detection Capability of Large Language Models](2024年07月02日/Assessing_the_Code_Clone_Detection_Capability_of_Large_Language_Models.md)

    - [翻译: 探究大型语言模型在代码克隆检测方面的能力](2024年07月02日/Assessing_the_Code_Clone_Detection_Capability_of_Large_Language_Models.md)

- [Learning to Refine with Fine-Grained Natural Language Feedback](2024年07月02日/Learning_to_Refine_with_Fine-Grained_Natural_Language_Feedback.md)

    - [翻译: 精炼学习：借助细粒度自然语言反馈](2024年07月02日/Learning_to_Refine_with_Fine-Grained_Natural_Language_Feedback.md)

- [Is Your AI-Generated Code Really Secure? Evaluating Large Language Models on Secure Code Generation with CodeSecEval](2024年07月02日/Is_Your_AI-Generated_Code_Really_Secure_Evaluating_Large_Language_Models_on_Secure_Code_Generation_with_CodeSecEval.md)

    - [翻译: AI 编写的代码，真的无懈可击吗？通过 CodeSecEval 工具，我们评估了大型语言模型在安全代码生成方面的表现。](2024年07月02日/Is_Your_AI-Generated_Code_Really_Secure_Evaluating_Large_Language_Models_on_Secure_Code_Generation_with_CodeSecEval.md)

- [Pelican: Correcting Hallucination in Vision-LLMs via Claim Decomposition and Program of Thought Verification](2024年07月02日/Pelican_Correcting_Hallucination_in_Vision-LLMs_via_Claim_Decomposition_and_Program_of_Thought_Verification.md)

    - [翻译: Pelican 通过声明分解和思维程序验证，有效纠正了视觉-LLMs中的幻觉问题。](2024年07月02日/Pelican_Correcting_Hallucination_in_Vision-LLMs_via_Claim_Decomposition_and_Program_of_Thought_Verification.md)

- [Generative Large Language Models in Automated Fact-Checking: A Survey](2024年07月02日/Generative_Large_Language_Models_in_Automated_Fact-Checking_A_Survey.md)

    - [翻译: 自动化事实核查中的生成式大型语言模型：综述](2024年07月02日/Generative_Large_Language_Models_in_Automated_Fact-Checking_A_Survey.md)

- [MORPHEUS: Modeling Role from Personalized Dialogue History by Exploring and Utilizing Latent Space](2024年07月02日/MORPHEUS_Modeling_Role_from_Personalized_Dialogue_History_by_Exploring_and_Utilizing_Latent_Space.md)

    - [翻译: MORPHEUS 项目旨在通过探索和利用潜在空间，从个性化对话历史中精准建模角色。](2024年07月02日/MORPHEUS_Modeling_Role_from_Personalized_Dialogue_History_by_Exploring_and_Utilizing_Latent_Space.md)

- [RVISA: Reasoning and Verification for Implicit Sentiment Analysis](2024年07月02日/RVISA_Reasoning_and_Verification_for_Implicit_Sentiment_Analysis.md)

    - [翻译: RVISA：隐式情感分析中的推理与验证](2024年07月02日/RVISA_Reasoning_and_Verification_for_Implicit_Sentiment_Analysis.md)

- [Open foundation models for Azerbaijani language](2024年07月02日/Open_foundation_models_for_Azerbaijani_language.md)

    - [翻译: 阿塞拜疆语言的开放基础模型](2024年07月02日/Open_foundation_models_for_Azerbaijani_language.md)

- [Efficient Sparse Attention needs Adaptive Token Release](2024年07月02日/Efficient_Sparse_Attention_needs_Adaptive_Token_Release.md)

    - [翻译: 实现高效稀疏注意力，关键在于自适应释放令牌。](2024年07月02日/Efficient_Sparse_Attention_needs_Adaptive_Token_Release.md)

- [Exploring the Role of Transliteration in In-Context Learning for Low-resource Languages Written in Non-Latin Scripts](2024年07月02日/Exploring_the_Role_of_Transliteration_in_In-Context_Learning_for_Low-resource_Languages_Written_in_Non-Latin_Scripts.md)

    - [翻译: 研究音译在非拉丁文字低资源语言上下文学习中的角色](2024年07月02日/Exploring_the_Role_of_Transliteration_in_In-Context_Learning_for_Low-resource_Languages_Written_in_Non-Latin_Scripts.md)

- [Evaluating the Ability of LLMs to Solve Semantics-Aware Process Mining Tasks](2024年07月02日/Evaluating_the_Ability_of_LLMs_to_Solve_Semantics-Aware_Process_Mining_Tasks.md)

    - [翻译: 探究 LLMs 在语义感知过程挖掘任务中的表现](2024年07月02日/Evaluating_the_Ability_of_LLMs_to_Solve_Semantics-Aware_Process_Mining_Tasks.md)

- [CFinBench: A Comprehensive Chinese Financial Benchmark for Large Language Models](2024年07月02日/CFinBench_A_Comprehensive_Chinese_Financial_Benchmark_for_Large_Language_Models.md)

    - [翻译: CFinBench：为大型语言模型打造的中文金融全面基准](2024年07月02日/CFinBench_A_Comprehensive_Chinese_Financial_Benchmark_for_Large_Language_Models.md)

- [Strategic Demand-Planning in Wireless Networks: Can Generative-AI Save Spectrum and Energy?](2024年07月02日/Strategic_Demand-Planning_in_Wireless_Networks_Can_Generative-AI_Save_Spectrum_and_Energy.md)

    - [翻译: 在无线网络的战略需求规划中，生成式人工智能能否成为频谱和能源的救星？](2024年07月02日/Strategic_Demand-Planning_in_Wireless_Networks_Can_Generative-AI_Save_Spectrum_and_Energy.md)

- [Multilingual Trolley Problems for Language Models](2024年07月02日/Multilingual_Trolley_Problems_for_Language_Models.md)

    - [翻译: 语言模型面临的多语言电车难题](2024年07月02日/Multilingual_Trolley_Problems_for_Language_Models.md)

- [GlyphDraw2: Automatic Generation of Complex Glyph Posters with Diffusion Models and Large Language Models](2024年07月02日/GlyphDraw2_Automatic_Generation_of_Complex_Glyph_Posters_with_Diffusion_Models_and_Large_Language_Models.md)

    - [翻译: GlyphDraw2：结合扩散模型与大型语言模型，自动创作复杂字形海报。](2024年07月02日/GlyphDraw2_Automatic_Generation_of_Complex_Glyph_Posters_with_Diffusion_Models_and_Large_Language_Models.md)

- [MIREncoder: Multi-modal IR-based Pretrained Embeddings for Performance Optimizations](2024年07月02日/MIREncoder_Multi-modal_IR-based_Pretrained_Embeddings_for_Performance_Optimizations.md)

    - [翻译: MIREncoder：一种基于多模态信息检索的预训练嵌入技术，旨在实现性能优化。](2024年07月02日/MIREncoder_Multi-modal_IR-based_Pretrained_Embeddings_for_Performance_Optimizations.md)

- [PromptIntern: Saving Inference Costs by Internalizing Recurrent Prompt during Large Language Model Fine-tuning](2024年07月02日/PromptIntern_Saving_Inference_Costs_by_Internalizing_Recurrent_Prompt_during_Large_Language_Model_Fine-tuning.md)

    - [翻译: PromptIntern：在大语言模型微调过程中，通过内部化循环提示，有效节省推理成本。](2024年07月02日/PromptIntern_Saving_Inference_Costs_by_Internalizing_Recurrent_Prompt_during_Large_Language_Model_Fine-tuning.md)

- [Generative Monoculture in Large Language Models](2024年07月02日/Generative_Monoculture_in_Large_Language_Models.md)

    - [翻译: 大型语言模型中的生成单一文化现象](2024年07月02日/Generative_Monoculture_in_Large_Language_Models.md)

- [Automatic Adaptation Rule Optimization via Large Language Models](2024年07月02日/Automatic_Adaptation_Rule_Optimization_via_Large_Language_Models.md)

    - [翻译: 利用大型语言模型实现自动适应规则的优化](2024年07月02日/Automatic_Adaptation_Rule_Optimization_via_Large_Language_Models.md)

- [A mathematical definition of complex adaptive system as interaction space](2024年07月02日/A_mathematical_definition_of_complex_adaptive_system_as_interaction_space.md)

    - [翻译: 复杂适应系统的数学定义，以交互空间为视角](2024年07月02日/A_mathematical_definition_of_complex_adaptive_system_as_interaction_space.md)

- [FineCLIPER: Multi-modal Fine-grained CLIP for Dynamic Facial Expression Recognition with AdaptERs](2024年07月02日/FineCLIPER_Multi-modal_Fine-grained_CLIP_for_Dynamic_Facial_Expression_Recognition_with_AdaptERs.md)

    - [翻译: FineCLIPER：一款结合多模态细粒度 CLIP 技术与适应性调整器的系统，专为动态面部表情识别设计。](2024年07月02日/FineCLIPER_Multi-modal_Fine-grained_CLIP_for_Dynamic_Facial_Expression_Recognition_with_AdaptERs.md)

- [LlamAr & GemmAr: Enhancing LLMs Through Arabic Instruction-Tuning](2024年07月02日/LlamAr_&_GemmAr_Enhancing_LLMs_Through_Arabic_Instruction-Tuning.md)

    - [翻译: LlamAr 与 GemmAr：借助阿拉伯语指令调优提升大型语言模型性能](2024年07月02日/LlamAr_&_GemmAr_Enhancing_LLMs_Through_Arabic_Instruction-Tuning.md)

- [Cost-Effective Proxy Reward Model Construction with On-Policy and Active Learning](2024年07月02日/Cost-Effective_Proxy_Reward_Model_Construction_with_On-Policy_and_Active_Learning.md)

    - [翻译: 通过在线策略与主动学习构建经济高效的代理奖励模型](2024年07月02日/Cost-Effective_Proxy_Reward_Model_Construction_with_On-Policy_and_Active_Learning.md)

- [Breaking Language Barriers: Cross-Lingual Continual Pre-Training at Scale](2024年07月02日/Breaking_Language_Barriers_Cross-Lingual_Continual_Pre-Training_at_Scale.md)

    - [翻译: 跨越语言界限：大规模实施跨语言持续预训练](2024年07月02日/Breaking_Language_Barriers_Cross-Lingual_Continual_Pre-Training_at_Scale.md)

- [Helpful assistant or fruitful facilitator? Investigating how personas affect language model behavior](2024年07月02日/Helpful_assistant_or_fruitful_facilitator_Investigating_how_personas_affect_language_model_behavior.md)

    - [翻译: 是助手还是促进者？探讨角色对语言模型行为的影响。](2024年07月02日/Helpful_assistant_or_fruitful_facilitator_Investigating_how_personas_affect_language_model_behavior.md)

- [GPTCast: a weather language model for precipitation nowcasting](2024年07月02日/GPTCast_a_weather_language_model_for_precipitation_nowcasting.md)

    - [翻译: GPTCast：一款专为降水实时预报设计的天气语言模型](2024年07月02日/GPTCast_a_weather_language_model_for_precipitation_nowcasting.md)

- [Theseus: Towards High-Efficiency Wafer-Scale Chip Design Space Exploration for Large Language Models](2024年07月02日/Theseus_Towards_High-Efficiency_Wafer-Scale_Chip_Design_Space_Exploration_for_Large_Language_Models.md)

    - [翻译: Theseus 项目致力于为大型语言模型优化晶圆级芯片设计，提升探索效率。](2024年07月02日/Theseus_Towards_High-Efficiency_Wafer-Scale_Chip_Design_Space_Exploration_for_Large_Language_Models.md)

- [Fake News Detection and Manipulation Reasoning via Large Vision-Language Models](2024年07月02日/Fake_News_Detection_and_Manipulation_Reasoning_via_Large_Vision-Language_Models.md)

    - [翻译: 利用大型视觉-语言模型，我们致力于假新闻的检测与操纵行为的推理。](2024年07月02日/Fake_News_Detection_and_Manipulation_Reasoning_via_Large_Vision-Language_Models.md)

- [Prompt Stability Scoring for Text Annotation with Large Language Models](2024年07月02日/Prompt_Stability_Scoring_for_Text_Annotation_with_Large_Language_Models.md)

    - [翻译: 大型语言模型文本标注中的提示稳定性评分](2024年07月02日/Prompt_Stability_Scoring_for_Text_Annotation_with_Large_Language_Models.md)

- [Breaking Bias, Building Bridges: Evaluation and Mitigation of Social Biases in LLMs via Contact Hypothesis](2024年07月02日/Breaking_Bias,_Building_Bridges_Evaluation_and_Mitigation_of_Social_Biases_in_LLMs_via_Contact_Hypothesis.md)

    - [翻译: 破除偏见，搭建沟通之桥：利用接触假设评估并减轻 LLMs 中的社会偏见](2024年07月02日/Breaking_Bias,_Building_Bridges_Evaluation_and_Mitigation_of_Social_Biases_in_LLMs_via_Contact_Hypothesis.md)

- [Why does in-context learning fail sometimes? Evaluating in-context learning on open and closed questions](2024年07月02日/Why_does_in-context_learning_fail_sometimes_Evaluating_in-context_learning_on_open_and_closed_questions.md)

    - [翻译: 为何 in-context learning 有时会失效？探讨其在开放与封闭问题上的表现。](2024年07月02日/Why_does_in-context_learning_fail_sometimes_Evaluating_in-context_learning_on_open_and_closed_questions.md)

- [ViG-Bias: Visually Grounded Bias Discovery and Mitigation](2024年07月02日/ViG-Bias_Visually_Grounded_Bias_Discovery_and_Mitigation.md)

    - [翻译: ViG-Bias：通过视觉基础技术发现并缓解偏见](2024年07月02日/ViG-Bias_Visually_Grounded_Bias_Discovery_and_Mitigation.md)

- [Is Your Large Language Model Knowledgeable or a Choices-Only Cheater?](2024年07月02日/Is_Your_Large_Language_Model_Knowledgeable_or_a_Choices-Only_Cheater.md)

    - [翻译: 你的大型语言模型是真才实学，还是仅仅在选择题上作弊？](2024年07月02日/Is_Your_Large_Language_Model_Knowledgeable_or_a_Choices-Only_Cheater.md)

- [SADL: An Effective In-Context Learning Method for Compositional Visual QA](2024年07月02日/SADL_An_Effective_In-Context_Learning_Method_for_Compositional_Visual_QA.md)

    - [翻译: SADL：组合视觉问答中一种高效的上下文学习策略](2024年07月02日/SADL_An_Effective_In-Context_Learning_Method_for_Compositional_Visual_QA.md)

- [A Bounding Box is Worth One Token: Interleaving Layout and Text in a Large Language Model for Document Understanding](2024年07月02日/A_Bounding_Box_is_Worth_One_Token_Interleaving_Layout_and_Text_in_a_Large_Language_Model_for_Document_Understanding.md)

    - [翻译: 每个边界框等同于一个令牌，通过在大规模语言模型中交错布局与文本，我们实现了对文档的深入理解。](2024年07月02日/A_Bounding_Box_is_Worth_One_Token_Interleaving_Layout_and_Text_in_a_Large_Language_Model_for_Document_Understanding.md)

- [MeMemo: On-device Retrieval Augmentation for Private and Personalized Text Generation](2024年07月02日/MeMemo_On-device_Retrieval_Augmentation_for_Private_and_Personalized_Text_Generation.md)

    - [翻译: MeMemo：实现设备端检索增强，助力私密且个性化的文本生成](2024年07月02日/MeMemo_On-device_Retrieval_Augmentation_for_Private_and_Personalized_Text_Generation.md)

- [Enabling Discriminative Reasoning in Large Language Models for Legal Judgment Prediction](2024年07月02日/Enabling_Discriminative_Reasoning_in_Large_Language_Models_for_Legal_Judgment_Prediction.md)

    - [翻译: 大型语言模型中的判别推理助力法律判决预测](2024年07月02日/Enabling_Discriminative_Reasoning_in_Large_Language_Models_for_Legal_Judgment_Prediction.md)

- [Towards Unsupervised Speaker Diarization System for Multilingual Telephone Calls Using Pre-trained Whisper Model and Mixture of Sparse Autoencoders](2024年07月02日/Towards_Unsupervised_Speaker_Diarization_System_for_Multilingual_Telephone_Calls_Using_Pre-trained_Whisper_Model_and_Mixture_of_Sparse_Autoencoders.md)

    - [翻译: 本研究旨在构建一个无监督的多语言电话通话说话人日志系统，该系统结合了预训练的 Whisper 模型与稀疏自编码器的混合技术。](2024年07月02日/Towards_Unsupervised_Speaker_Diarization_System_for_Multilingual_Telephone_Calls_Using_Pre-trained_Whisper_Model_and_Mixture_of_Sparse_Autoencoders.md)

- [S2D: Sorted Speculative Decoding For More Efficient Deployment of Nested Large Language Models](2024年07月02日/S2D_Sorted_Speculative_Decoding_For_More_Efficient_Deployment_of_Nested_Large_Language_Models.md)

    - [翻译: S2D：通过排序推测解码，提升嵌套大型语言模型的部署效率](2024年07月02日/S2D_Sorted_Speculative_Decoding_For_More_Efficient_Deployment_of_Nested_Large_Language_Models.md)

- [CatMemo at the FinLLM Challenge Task: Fine-Tuning Large Language Models using Data Fusion in Financial Applications](2024年07月02日/CatMemo_at_the_FinLLM_Challenge_Task_Fine-Tuning_Large_Language_Models_using_Data_Fusion_in_Financial_Applications.md)

    - [翻译: CatMemo在FinLLM挑战中，通过数据融合技术，优化金融应用中的大型语言模型微调。](2024年07月02日/CatMemo_at_the_FinLLM_Challenge_Task_Fine-Tuning_Large_Language_Models_using_Data_Fusion_in_Financial_Applications.md)

- [Extracting and Encoding: Leveraging Large Language Models and Medical Knowledge to Enhance Radiological Text Representation](2024年07月02日/Extracting_and_Encoding_Leveraging_Large_Language_Models_and_Medical_Knowledge_to_Enhance_Radiological_Text_Representation.md)

    - [翻译: 借助大型语言模型与医学知识，我们致力于提升放射学文本的表达力。](2024年07月02日/Extracting_and_Encoding_Leveraging_Large_Language_Models_and_Medical_Knowledge_to_Enhance_Radiological_Text_Representation.md)

- [RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs](2024年07月02日/RankRAG_Unifying_Context_Ranking_with_Retrieval-Augmented_Generation_in_LLMs.md)

    - [翻译: RankRAG：整合上下文排序与检索增强生成于大型语言模型中](2024年07月02日/RankRAG_Unifying_Context_Ranking_with_Retrieval-Augmented_Generation_in_LLMs.md)

- [MMedAgent: Learning to Use Medical Tools with Multi-modal Agent](2024年07月02日/MMedAgent_Learning_to_Use_Medical_Tools_with_Multi-modal_Agent.md)

    - [翻译: MMedAgent：掌握医疗工具的多模态学习代理](2024年07月02日/MMedAgent_Learning_to_Use_Medical_Tools_with_Multi-modal_Agent.md)

- [MInference 1.0: Accelerating Pre-filling for Long-Context LLMs via Dynamic Sparse Attention](2024年07月02日/MInference_1.0_Accelerating_Pre-filling_for_Long-Context_LLMs_via_Dynamic_Sparse_Attention.md)

    - [翻译: MInference 1.0 通过动态稀疏注意力机制，加速了长上下文大型语言模型的预填充过程。](2024年07月02日/MInference_1.0_Accelerating_Pre-filling_for_Long-Context_LLMs_via_Dynamic_Sparse_Attention.md)

- [Neurocache: Efficient Vector Retrieval for Long-range Language Modeling](2024年07月02日/Neurocache_Efficient_Vector_Retrieval_for_Long-range_Language_Modeling.md)

    - [翻译: Neurocache：实现长距离语言建模的高效向量检索技术](2024年07月02日/Neurocache_Efficient_Vector_Retrieval_for_Long-range_Language_Modeling.md)

- [Understanding Alignment in Multimodal LLMs: A Comprehensive Study](2024年07月02日/Understanding_Alignment_in_Multimodal_LLMs_A_Comprehensive_Study.md)

    - [翻译: 探究多模态LLM中的对齐机制：一项深入研究](2024年07月02日/Understanding_Alignment_in_Multimodal_LLMs_A_Comprehensive_Study.md)

- [Open Scene Graphs for Open World Object-Goal Navigation](2024年07月02日/Open_Scene_Graphs_for_Open_World_Object-Goal_Navigation.md)

    - [翻译: 开放场景图助力开放世界中的对象目标导航](2024年07月02日/Open_Scene_Graphs_for_Open_World_Object-Goal_Navigation.md)

- [Reliable Confidence Intervals for Information Retrieval Evaluation Using Generative A.I](2024年07月02日/Reliable_Confidence_Intervals_for_Information_Retrieval_Evaluation_Using_Generative_A.I.md)

    - [翻译: 利用生成式AI评估信息检索的可靠置信区间](2024年07月02日/Reliable_Confidence_Intervals_for_Information_Retrieval_Evaluation_Using_Generative_A.I.md)

- [Improving Visual Storytelling with Multimodal Large Language Models](2024年07月02日/Improving_Visual_Storytelling_with_Multimodal_Large_Language_Models.md)

    - [翻译: 通过多模态大型语言模型提升视觉叙事效果](2024年07月02日/Improving_Visual_Storytelling_with_Multimodal_Large_Language_Models.md)

- [Model-Enhanced LLM-Driven VUI Testing of VPA Apps](2024年07月02日/Model-Enhanced_LLM-Driven_VUI_Testing_of_VPA_Apps.md)

    - [翻译: 基于模型增强的 LLM 驱动，对 VPA 应用进行 VUI 测试](2024年07月02日/Model-Enhanced_LLM-Driven_VUI_Testing_of_VPA_Apps.md)

- [52B to 1T: Lessons Learned via Tele-FLM Series](2024年07月02日/52B_to_1T_Lessons_Learned_via_Tele-FLM_Series.md)

    - [翻译: 从 52B 到 1T：Tele-FLM 系列中的经验启示](2024年07月02日/52B_to_1T_Lessons_Learned_via_Tele-FLM_Series.md)

- [Croppable Knowledge Graph Embedding](2024年07月02日/Croppable_Knowledge_Graph_Embedding.md)

    - [翻译: 知识图谱嵌入的可裁剪性](2024年07月02日/Croppable_Knowledge_Graph_Embedding.md)

- [Large language models, physics-based modeling, experimental measurements: the trinity of data-scarce learning of polymer properties](2024年07月02日/Large_language_models,_physics-based_modeling,_experimental_measurements_the_trinity_of_data-scarce_learning_of_polymer_properties.md)

    - [翻译: 大型语言模型、物理建模与实验测量，三者共同构成了聚合物特性数据稀缺学习的核心。](2024年07月02日/Large_language_models,_physics-based_modeling,_experimental_measurements_the_trinity_of_data-scarce_learning_of_polymer_properties.md)

- [Learning to Reduce: Towards Improving Performance of Large Language Models on Structured Data](2024年07月02日/Learning_to_Reduce_Towards_Improving_Performance_of_Large_Language_Models_on_Structured_Data.md)

    - [翻译: 探索优化之道：提升大型语言模型在结构化数据处理中的表现](2024年07月02日/Learning_to_Reduce_Towards_Improving_Performance_of_Large_Language_Models_on_Structured_Data.md)

- [A Comparative Study of DSL Code Generation: Fine-Tuning vs. Optimized Retrieval Augmentation](2024年07月02日/A_Comparative_Study_of_DSL_Code_Generation_Fine-Tuning_vs._Optimized_Retrieval_Augmentation.md)

    - [翻译: 比较 DSL 代码生成的两种方法：微调与优化检索增强](2024年07月02日/A_Comparative_Study_of_DSL_Code_Generation_Fine-Tuning_vs._Optimized_Retrieval_Augmentation.md)

- [MentalAgora: A Gateway to Advanced Personalized Care in Mental Health through Multi-Agent Debating and Attribute Control](2024年07月02日/MentalAgora_A_Gateway_to_Advanced_Personalized_Care_in_Mental_Health_through_Multi-Agent_Debating_and_Attribute_Control.md)

    - [翻译: MentalAgora：借助多智能体辩论与属性控制，开启心理健康高级个性化护理之门](2024年07月02日/MentalAgora_A_Gateway_to_Advanced_Personalized_Care_in_Mental_Health_through_Multi-Agent_Debating_and_Attribute_Control.md)

- [Supporting Cross-language Cross-project Bug Localization Using Pre-trained Language Models](2024年07月02日/Supporting_Cross-language_Cross-project_Bug_Localization_Using_Pre-trained_Language_Models.md)

    - [翻译: 借助预训练语言模型，实现跨语言与跨项目的错误定位支持。](2024年07月02日/Supporting_Cross-language_Cross-project_Bug_Localization_Using_Pre-trained_Language_Models.md)

- [MedVH: Towards Systematic Evaluation of Hallucination for Large Vision Language Models in the Medical Context](2024年07月02日/MedVH_Towards_Systematic_Evaluation_of_Hallucination_for_Large_Vision_Language_Models_in_the_Medical_Context.md)

    - [翻译: MedVH：系统评估医疗场景下大型视觉语言模型的幻觉问题](2024年07月02日/MedVH_Towards_Systematic_Evaluation_of_Hallucination_for_Large_Vision_Language_Models_in_the_Medical_Context.md)

- [LLM-Select: Feature Selection with Large Language Models](2024年07月02日/LLM-Select_Feature_Selection_with_Large_Language_Models.md)

    - [翻译: LLM-Select：借助大型语言模型实现特征选择](2024年07月02日/LLM-Select_Feature_Selection_with_Large_Language_Models.md)

- [KGym: A Platform and Dataset to Benchmark Large Language Models on Linux Kernel Crash Resolution](2024年07月02日/KGym_A_Platform_and_Dataset_to_Benchmark_Large_Language_Models_on_Linux_Kernel_Crash_Resolution.md)

    - [翻译: KGym 是一个专为 Linux 内核崩溃解决而设计，用于评估大型语言模型性能的平台和数据集。](2024年07月02日/KGym_A_Platform_and_Dataset_to_Benchmark_Large_Language_Models_on_Linux_Kernel_Crash_Resolution.md)

- [Reasoning in Large Language Models: A Geometric Perspective](2024年07月02日/Reasoning_in_Large_Language_Models_A_Geometric_Perspective.md)

    - [翻译: 大型语言模型推理：几何视角探析](2024年07月02日/Reasoning_in_Large_Language_Models_A_Geometric_Perspective.md)

2024年07月01日

- [KV Cache Compression, But What Must We Give in Return? A Comprehensive Benchmark of Long Context Capable Approaches](2024年07月01日/KV_Cache_Compression,_But_What_Must_We_Give_in_Return_A_Comprehensive_Benchmark_of_Long_Context_Capable_Approaches.md)

    - [翻译: KV缓存压缩：我们需付出何种代价？长上下文能力方法的全面基准测试](2024年07月01日/KV_Cache_Compression,_But_What_Must_We_Give_in_Return_A_Comprehensive_Benchmark_of_Long_Context_Capable_Approaches.md)

- [Empowering 3D Visual Grounding with Reasoning Capabilities](2024年07月01日/Empowering_3D_Visual_Grounding_with_Reasoning_Capabilities.md)

    - [翻译: 赋予 3D 视觉定位推理能力](2024年07月01日/Empowering_3D_Visual_Grounding_with_Reasoning_Capabilities.md)

- [MMLongBench-Doc: Benchmarking Long-context Document Understanding with Visualizations](2024年07月01日/MMLongBench-Doc_Benchmarking_Long-context_Document_Understanding_with_Visualizations.md)

    - [翻译: MMLongBench-Doc：借助可视化工具，对长篇文档理解进行基准测试](2024年07月01日/MMLongBench-Doc_Benchmarking_Long-context_Document_Understanding_with_Visualizations.md)

- [MIA-Bench: Towards Better Instruction Following Evaluation of Multimodal LLMs](2024年07月01日/MIA-Bench_Towards_Better_Instruction_Following_Evaluation_of_Multimodal_LLMs.md)

    - [翻译: MIA-Bench：旨在提升多模态 LLM 指令遵循能力的评估工具](2024年07月01日/MIA-Bench_Towards_Better_Instruction_Following_Evaluation_of_Multimodal_LLMs.md)

- [Self-Cognition in Large Language Models: An Exploratory Study](2024年07月01日/Self-Cognition_in_Large_Language_Models_An_Exploratory_Study.md)

    - [翻译: 大型语言模型中的自我认知探索研究](2024年07月01日/Self-Cognition_in_Large_Language_Models_An_Exploratory_Study.md)

- [RegMix: Data Mixture as Regression for Language Model Pre-training](2024年07月01日/RegMix_Data_Mixture_as_Regression_for_Language_Model_Pre-training.md)

    - [翻译: RegMix：以数据混合为手段，通过回归进行语言模型预训练](2024年07月01日/RegMix_Data_Mixture_as_Regression_for_Language_Model_Pre-training.md)

- [Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning](2024年07月01日/Expressive_and_Generalizable_Low-rank_Adaptation_for_Large_Models_via_Slow_Cascaded_Learning.md)

    - [翻译: 通过缓慢级联学习，实现大型模型的低秩适应，兼具表达性与泛化能力。](2024年07月01日/Expressive_and_Generalizable_Low-rank_Adaptation_for_Large_Models_via_Slow_Cascaded_Learning.md)

- [LLM See, LLM Do: Guiding Data Generation to Target Non-Differentiable Objectives](2024年07月01日/LLM_See,_LLM_Do_Guiding_Data_Generation_to_Target_Non-Differentiable_Objectives.md)

    - [翻译: LLM 观察，LLM 行动：引导数据生成，瞄准非可微目标](2024年07月01日/LLM_See,_LLM_Do_Guiding_Data_Generation_to_Target_Non-Differentiable_Objectives.md)

- [Agentless: Demystifying LLM-based Software Engineering Agents](2024年07月01日/Agentless_Demystifying_LLM-based_Software_Engineering_Agents.md)

    - [翻译: 无代理模式：探索基于LLM的软件工程代理之谜](2024年07月01日/Agentless_Demystifying_LLM-based_Software_Engineering_Agents.md)

- [LEXI: Large Language Models Experimentation Interface](2024年07月01日/LEXI_Large_Language_Models_Experimentation_Interface.md)

    - [翻译: LEXI：大型语言模型实验平台](2024年07月01日/LEXI_Large_Language_Models_Experimentation_Interface.md)

- [DogeRM: Equipping Reward Models with Domain Knowledge through Model Merging](2024年07月01日/DogeRM_Equipping_Reward_Models_with_Domain_Knowledge_through_Model_Merging.md)

    - [翻译: DogeRM：借助模型合并技术，为奖励模型注入领域智慧](2024年07月01日/DogeRM_Equipping_Reward_Models_with_Domain_Knowledge_through_Model_Merging.md)

- [Retrieval-augmented generation in multilingual settings](2024年07月01日/Retrieval-augmented_generation_in_multilingual_settings.md)

    - [翻译: 多语言环境下的检索增强生成](2024年07月01日/Retrieval-augmented_generation_in_multilingual_settings.md)

- [Enhancing the Capability and Robustness of Large Language Models through Reinforcement Learning-Driven Query Refinement](2024年07月01日/Enhancing_the_Capability_and_Robustness_of_Large_Language_Models_through_Reinforcement_Learning-Driven_Query_Refinement.md)

    - [翻译: 利用强化学习优化查询，提升大型语言模型的性能与稳定性](2024年07月01日/Enhancing_the_Capability_and_Robustness_of_Large_Language_Models_through_Reinforcement_Learning-Driven_Query_Refinement.md)

- [TimeToM: Temporal Space is the Key to Unlocking the Door of Large Language Models' Theory-of-Mind](2024年07月01日/TimeToM_Temporal_Space_is_the_Key_to_Unlocking_the_Door_of_Large_Language_Models'_Theory-of-Mind.md)

    - [翻译: 时间空间，即 TimeToM，是揭开大型语言模型心智理论奥秘的关键。](2024年07月01日/TimeToM_Temporal_Space_is_the_Key_to_Unlocking_the_Door_of_Large_Language_Models'_Theory-of-Mind.md)

- [FastCLIP: A Suite of Optimization Techniques to Accelerate CLIP Training with Limited Resources](2024年07月01日/FastCLIP_A_Suite_of_Optimization_Techniques_to_Accelerate_CLIP_Training_with_Limited_Resources.md)

    - [翻译: FastCLIP：一套优化技术，专为在资源有限的情况下加速 CLIP 训练而设计](2024年07月01日/FastCLIP_A_Suite_of_Optimization_Techniques_to_Accelerate_CLIP_Training_with_Limited_Resources.md)

- [Needle in the Haystack for Memory Based Large Language Models](2024年07月01日/Needle_in_the_Haystack_for_Memory_Based_Large_Language_Models.md)

    - [翻译: 大型语言模型中基于内存的难题](2024年07月01日/Needle_in_the_Haystack_for_Memory_Based_Large_Language_Models.md)

- [Dynamic Few-Shot Learning for Knowledge Graph Question Answering](2024年07月01日/Dynamic_Few-Shot_Learning_for_Knowledge_Graph_Question_Answering.md)

    - [翻译: 知识图谱问答中的动态少样本学习](2024年07月01日/Dynamic_Few-Shot_Learning_for_Knowledge_Graph_Question_Answering.md)

- [Adapting Multilingual LLMs to Low-Resource Languages with Knowledge Graphs via Adapters](2024年07月01日/Adapting_Multilingual_LLMs_to_Low-Resource_Languages_with_Knowledge_Graphs_via_Adapters.md)

    - [翻译: 借助知识图谱和适配器，让多语言LLMs轻松适应低资源语言](2024年07月01日/Adapting_Multilingual_LLMs_to_Low-Resource_Languages_with_Knowledge_Graphs_via_Adapters.md)

- [Optimization of Retrieval-Augmented Generation Context with Outlier Detection](2024年07月01日/Optimization_of_Retrieval-Augmented_Generation_Context_with_Outlier_Detection.md)

    - [翻译: 优化检索增强生成上下文，结合异常检测技术](2024年07月01日/Optimization_of_Retrieval-Augmented_Generation_Context_with_Outlier_Detection.md)

- [Gloss2Text: Sign Language Gloss translation using LLMs and Semantically Aware Label Smoothing](2024年07月01日/Gloss2Text_Sign_Language_Gloss_translation_using_LLMs_and_Semantically_Aware_Label_Smoothing.md)

    - [翻译: Gloss2Text：借助 LLMs 与语义感知标签平滑技术，实现手语词汇的精准翻译](2024年07月01日/Gloss2Text_Sign_Language_Gloss_translation_using_LLMs_and_Semantically_Aware_Label_Smoothing.md)

- [Free-text Rationale Generation under Readability Level Control](2024年07月01日/Free-text_Rationale_Generation_under_Readability_Level_Control.md)

    - [翻译: 在可读性控制下生成自由文本理由](2024年07月01日/Free-text_Rationale_Generation_under_Readability_Level_Control.md)

- [Evaluating Knowledge-based Cross-lingual Inconsistency in Large Language Models](2024年07月01日/Evaluating_Knowledge-based_Cross-lingual_Inconsistency_in_Large_Language_Models.md)

    - [翻译: 探究大型语言模型中基于知识的跨语言不一致问题](2024年07月01日/Evaluating_Knowledge-based_Cross-lingual_Inconsistency_in_Large_Language_Models.md)

- [Increasing Model Capacity for Free: A Simple Strategy for Parameter Efficient Fine-tuning](2024年07月01日/Increasing_Model_Capacity_for_Free_A_Simple_Strategy_for_Parameter_Efficient_Fine-tuning.md)

    - [翻译: 免费提升模型容量：一种简便的参数高效微调方法](2024年07月01日/Increasing_Model_Capacity_for_Free_A_Simple_Strategy_for_Parameter_Efficient_Fine-tuning.md)

- [Language Portability Strategies for Open-domain Dialogue with Pre-trained Language Models from High to Low Resource Languages](2024年07月01日/Language_Portability_Strategies_for_Open-domain_Dialogue_with_Pre-trained_Language_Models_from_High_to_Low_Resource_Languages.md)

    - [翻译: 预训练语言模型在开放域对话中，从高资源到低资源语言的语言可移植性策略研究](2024年07月01日/Language_Portability_Strategies_for_Open-domain_Dialogue_with_Pre-trained_Language_Models_from_High_to_Low_Resource_Languages.md)

- [Collaborative Performance Prediction for Large Language Models](2024年07月01日/Collaborative_Performance_Prediction_for_Large_Language_Models.md)

    - [翻译: 大型语言模型的协同性能预测](2024年07月01日/Collaborative_Performance_Prediction_for_Large_Language_Models.md)

- [Lightweight Zero-shot Text-to-Speech with Mixture of Adapters](2024年07月01日/Lightweight_Zero-shot_Text-to-Speech_with_Mixture_of_Adapters.md)

    - [翻译: 轻量级零-shot 文本转语音技术采用适配器混合方法](2024年07月01日/Lightweight_Zero-shot_Text-to-Speech_with_Mixture_of_Adapters.md)

- [We-Math: Does Your Large Multimodal Model Achieve Human-like Mathematical Reasoning?](2024年07月01日/We-Math_Does_Your_Large_Multimodal_Model_Achieve_Human-like_Mathematical_Reasoning.md)

    - [翻译: We-Math：探寻大型多模态模型是否已具备人类般的数学推理能力。](2024年07月01日/We-Math_Does_Your_Large_Multimodal_Model_Achieve_Human-like_Mathematical_Reasoning.md)

- [Human-Robot Mutual Learning through Affective-Linguistic Interaction and Differential Outcomes Training [Pre-Print]](2024年07月01日/Human-Robot_Mutual_Learning_through_Affective-Linguistic_Interaction_and_Differential_Outcomes_Training_[Pre-Print].md)

    - [翻译: 人机互学：基于情感语言交互与差异化训练成果 [预印版]](2024年07月01日/Human-Robot_Mutual_Learning_through_Affective-Linguistic_Interaction_and_Differential_Outcomes_Training_[Pre-Print].md)

- [Leveraging Large Language Models for Actionable Course Evaluation Student Feedback to Lecturers](2024年07月01日/Leveraging_Large_Language_Models_for_Actionable_Course_Evaluation_Student_Feedback_to_Lecturers.md)

    - [翻译: 借助大型语言模型，为讲师提供具有操作性的课程评估学生反馈](2024年07月01日/Leveraging_Large_Language_Models_for_Actionable_Course_Evaluation_Student_Feedback_to_Lecturers.md)

- [Show Less, Instruct More: Enriching Prompts with Definitions and Guidelines for Zero-Shot NER](2024年07月01日/Show_Less,_Instruct_More_Enriching_Prompts_with_Definitions_and_Guidelines_for_Zero-Shot_NER.md)

    - [翻译: 精简展示，强化指导：通过定义与指南提升零-shot NER 的提示质量](2024年07月01日/Show_Less,_Instruct_More_Enriching_Prompts_with_Definitions_and_Guidelines_for_Zero-Shot_NER.md)

- [The African Woman is Rhythmic and Soulful: Evaluation of Open-ended Generation for Implicit Biases](2024年07月01日/The_African_Woman_is_Rhythmic_and_Soulful_Evaluation_of_Open-ended_Generation_for_Implicit_Biases.md)

    - [翻译: 非洲女性，节奏与灵魂的化身：探索隐性偏见在开放式生成中的表现](2024年07月01日/The_African_Woman_is_Rhythmic_and_Soulful_Evaluation_of_Open-ended_Generation_for_Implicit_Biases.md)

- [SignCLIP: Connecting Text and Sign Language by Contrastive Learning](2024年07月01日/SignCLIP_Connecting_Text_and_Sign_Language_by_Contrastive_Learning.md)

    - [翻译: SignCLIP：借助对比学习，架起文本与手语之间的桥梁](2024年07月01日/SignCLIP_Connecting_Text_and_Sign_Language_by_Contrastive_Learning.md)

- [uDistil-Whisper: Label-Free Data Filtering for Knowledge Distillation via Large-Scale Pseudo Labelling](2024年07月01日/uDistil-Whisper_Label-Free_Data_Filtering_for_Knowledge_Distillation_via_Large-Scale_Pseudo_Labelling.md)

    - [翻译: uDistil-Whisper：利用大规模伪标签技术，实现知识蒸馏中的无标签数据过滤。](2024年07月01日/uDistil-Whisper_Label-Free_Data_Filtering_for_Knowledge_Distillation_via_Large-Scale_Pseudo_Labelling.md)

- [SINKT: A Structure-Aware Inductive Knowledge Tracing Model with Large Language Model](2024年07月01日/SINKT_A_Structure-Aware_Inductive_Knowledge_Tracing_Model_with_Large_Language_Model.md)

    - [翻译: SINKT：结合大型语言模型的结构感知归纳知识追踪模型](2024年07月01日/SINKT_A_Structure-Aware_Inductive_Knowledge_Tracing_Model_with_Large_Language_Model.md)

- [Large Language Models are Zero-Shot Recognizers for Activities of Daily Living](2024年07月01日/Large_Language_Models_are_Zero-Shot_Recognizers_for_Activities_of_Daily_Living.md)

    - [翻译: 大型语言模型能够零-shot 识别日常活动](2024年07月01日/Large_Language_Models_are_Zero-Shot_Recognizers_for_Activities_of_Daily_Living.md)

- [A Fingerprint for Large Language Models](2024年07月01日/A_Fingerprint_for_Large_Language_Models.md)

    - [翻译: 大型语言模型的独特印记](2024年07月01日/A_Fingerprint_for_Large_Language_Models.md)

- [MIRAI: Evaluating LLM Agents for Event Forecasting](2024年07月01日/MIRAI_Evaluating_LLM_Agents_for_Event_Forecasting.md)

    - [翻译: MIRAI：评估大型语言模型代理在事件预测中的效能](2024年07月01日/MIRAI_Evaluating_LLM_Agents_for_Event_Forecasting.md)

- [Searching for Best Practices in Retrieval-Augmented Generation](2024年07月01日/Searching_for_Best_Practices_in_Retrieval-Augmented_Generation.md)

    - [翻译: 探寻检索增强生成领域的最佳实践](2024年07月01日/Searching_for_Best_Practices_in_Retrieval-Augmented_Generation.md)

- [EconNLI: Evaluating Large Language Models on Economics Reasoning](2024年07月01日/EconNLI_Evaluating_Large_Language_Models_on_Economics_Reasoning.md)

    - [翻译: EconNLI：探究大型语言模型在经济学推理领域的评估](2024年07月01日/EconNLI_Evaluating_Large_Language_Models_on_Economics_Reasoning.md)

- [TCSR-SQL: Towards Table Content-aware Text-to-SQL with Self-retrieval](2024年07月01日/TCSR-SQL_Towards_Table_Content-aware_Text-to-SQL_with_Self-retrieval.md)

    - [翻译: TCSR-SQL：借助自检索技术，实现对表格内容的智能感知，进而生成SQL语句。](2024年07月01日/TCSR-SQL_Towards_Table_Content-aware_Text-to-SQL_with_Self-retrieval.md)

- [: Language Modeling with Explicit Memory](2024年07月01日/_Language_Modeling_with_Explicit_Memory.md)

    - [翻译: 语言建模中的显式记忆技术](2024年07月01日/_Language_Modeling_with_Explicit_Memory.md)

- [GazeNoter: Co-Piloted AR Note-Taking via Gaze Selection of LLM Suggestions to Match Users' Intentions](2024年07月01日/GazeNoter_Co-Piloted_AR_Note-Taking_via_Gaze_Selection_of_LLM_Suggestions_to_Match_Users'_Intentions.md)

    - [翻译: GazeNoter：一种协同增强现实笔记工具，通过目光选择大型语言模型建议，精准匹配用户意图。](2024年07月01日/GazeNoter_Co-Piloted_AR_Note-Taking_via_Gaze_Selection_of_LLM_Suggestions_to_Match_Users'_Intentions.md)

- [Learning to Explore and Select for Coverage-Conditioned Retrieval-Augmented Generation](2024年07月01日/Learning_to_Explore_and_Select_for_Coverage-Conditioned_Retrieval-Augmented_Generation.md)

    - [翻译: 探索与选择学习：覆盖条件下的检索增强生成](2024年07月01日/Learning_to_Explore_and_Select_for_Coverage-Conditioned_Retrieval-Augmented_Generation.md)

- [CPT: Consistent Proxy Tuning for Black-box Optimization](2024年07月01日/CPT_Consistent_Proxy_Tuning_for_Black-box_Optimization.md)

    - [翻译: CPT：实现黑盒优化中一致性的代理调优方法](2024年07月01日/CPT_Consistent_Proxy_Tuning_for_Black-box_Optimization.md)

- [Calibrated Large Language Models for Binary Question Answering](2024年07月01日/Calibrated_Large_Language_Models_for_Binary_Question_Answering.md)

    - [翻译: 大型语言模型经过校准，专为二元问答设计](2024年07月01日/Calibrated_Large_Language_Models_for_Binary_Question_Answering.md)

- [Pron vs Prompt: Can Large Language Models already Challenge a World-Class Fiction Author at Creative Text Writing?](2024年07月01日/Pron_vs_Prompt_Can_Large_Language_Models_already_Challenge_a_World-Class_Fiction_Author_at_Creative_Text_Writing.md)

    - [翻译: 大型语言模型与世界级小说作者在创意写作上的较量：Pron vs Prompt，究竟谁能胜出？](2024年07月01日/Pron_vs_Prompt_Can_Large_Language_Models_already_Challenge_a_World-Class_Fiction_Author_at_Creative_Text_Writing.md)

- [BERGEN: A Benchmarking Library for Retrieval-Augmented Generation](2024年07月01日/BERGEN_A_Benchmarking_Library_for_Retrieval-Augmented_Generation.md)

    - [翻译: BERGEN：一款专为检索增强生成技术打造的基准库](2024年07月01日/BERGEN_A_Benchmarking_Library_for_Retrieval-Augmented_Generation.md)

- [IBSEN: Director-Actor Agent Collaboration for Controllable and Interactive Drama Script Generation](2024年07月01日/IBSEN_Director-Actor_Agent_Collaboration_for_Controllable_and_Interactive_Drama_Script_Generation.md)

    - [翻译: IBSEN 系统通过导演与演员代理的协作，实现了可控且互动的戏剧剧本生成。](2024年07月01日/IBSEN_Director-Actor_Agent_Collaboration_for_Controllable_and_Interactive_Drama_Script_Generation.md)

- [Rethinking LLM-based Preference Evaluation](2024年07月01日/Rethinking_LLM-based_Preference_Evaluation.md)

    - [翻译: 重新审视基于LLM的偏好评估方法](2024年07月01日/Rethinking_LLM-based_Preference_Evaluation.md)

- [First Place Solution of 2023 Global Artificial Intelligence Technology Innovation Competition Track 1](2024年07月01日/First_Place_Solution_of_2023_Global_Artificial_Intelligence_Technology_Innovation_Competition_Track_1.md)

    - [翻译: 2023年全球AI技术创新大赛第一赛道冠军方案](2024年07月01日/First_Place_Solution_of_2023_Global_Artificial_Intelligence_Technology_Innovation_Competition_Track_1.md)

- [SecGenAI: Enhancing Security of Cloud-based Generative AI Applications within Australian Critical Technologies of National Interest](2024年07月01日/SecGenAI_Enhancing_Security_of_Cloud-based_Generative_AI_Applications_within_Australian_Critical_Technologies_of_National_Interest.md)

    - [翻译: SecGenAI：提升澳大利亚关键技术领域内云端生成式AI应用的安全防护](2024年07月01日/SecGenAI_Enhancing_Security_of_Cloud-based_Generative_AI_Applications_within_Australian_Critical_Technologies_of_National_Interest.md)

- [Eliminating Position Bias of Language Models: A Mechanistic Approach](2024年07月01日/Eliminating_Position_Bias_of_Language_Models_A_Mechanistic_Approach.md)

    - [翻译: 解决语言模型中的位置偏差问题：一种机制性解决方案](2024年07月01日/Eliminating_Position_Bias_of_Language_Models_A_Mechanistic_Approach.md)

- [Face4RAG: Factual Consistency Evaluation for Retrieval Augmented Generation in Chinese](2024年07月01日/Face4RAG_Factual_Consistency_Evaluation_for_Retrieval_Augmented_Generation_in_Chinese.md)

    - [翻译: Face4RAG：评估中文检索增强生成的事实一致性工具](2024年07月01日/Face4RAG_Factual_Consistency_Evaluation_for_Retrieval_Augmented_Generation_in_Chinese.md)

- [Hybrid RAG-empowered Multi-modal LLM for Secure Healthcare Data Management: A Diffusion-based Contract Theory Approach](2024年07月01日/Hybrid_RAG-empowered_Multi-modal_LLM_for_Secure_Healthcare_Data_Management_A_Diffusion-based_Contract_Theory_Approach.md)

    - [翻译: 采用混合 RAG 增强的多模态 LLM，结合基于扩散的合同理论，为安全医疗数据管理提供创新解决方案。](2024年07月01日/Hybrid_RAG-empowered_Multi-modal_LLM_for_Secure_Healthcare_Data_Management_A_Diffusion-based_Contract_Theory_Approach.md)

- [Data on the Move: Traffic-Oriented Data Trading Platform Powered by AI Agent with Common Sense](2024年07月01日/Data_on_the_Move_Traffic-Oriented_Data_Trading_Platform_Powered_by_AI_Agent_with_Common_Sense.md)

    - [翻译: 数据动态交易：基于常识AI代理的流量导向数据平台](2024年07月01日/Data_on_the_Move_Traffic-Oriented_Data_Trading_Platform_Powered_by_AI_Agent_with_Common_Sense.md)

- [Mobile-Bench: An Evaluation Benchmark for LLM-based Mobile Agents](2024年07月01日/Mobile-Bench_An_Evaluation_Benchmark_for_LLM-based_Mobile_Agents.md)

    - [翻译: 移动-Bench：一个针对基于 LLM 的移动代理的评估基准](2024年07月01日/Mobile-Bench_An_Evaluation_Benchmark_for_LLM-based_Mobile_Agents.md)

- [Human-like object concept representations emerge naturally in multimodal large language models](2024年07月01日/Human-like_object_concept_representations_emerge_naturally_in_multimodal_large_language_models.md)

    - [翻译: 多模态大型语言模型中，类人对象概念的表示自然而然地形成。](2024年07月01日/Human-like_object_concept_representations_emerge_naturally_in_multimodal_large_language_models.md)

- [Empathic Grounding: Explorations using Multimodal Interaction and Large Language Models with Conversational Agents](2024年07月01日/Empathic_Grounding_Explorations_using_Multimodal_Interaction_and_Large_Language_Models_with_Conversational_Agents.md)

    - [翻译: 共情基础探索：通过多模态交互与大型语言模型，与对话代理共同探索共情机制。](2024年07月01日/Empathic_Grounding_Explorations_using_Multimodal_Interaction_and_Large_Language_Models_with_Conversational_Agents.md)

- [Ground Every Sentence: Improving Retrieval-Augmented LLMs with Interleaved Reference-Claim Generation](2024年07月01日/Ground_Every_Sentence_Improving_Retrieval-Augmented_LLMs_with_Interleaved_Reference-Claim_Generation.md)

    - [翻译: 每一句都夯实：通过交错引用与声明生成，提升检索增强型大型语言模型的性能](2024年07月01日/Ground_Every_Sentence_Improving_Retrieval-Augmented_LLMs_with_Interleaved_Reference-Claim_Generation.md)

- [Text-Aware Diffusion for Policy Learning](2024年07月01日/Text-Aware_Diffusion_for_Policy_Learning.md)

    - [翻译: 文本感知扩散在政策学习中的应用](2024年07月01日/Text-Aware_Diffusion_for_Policy_Learning.md)

- [GRASP: A Grid-Based Benchmark for Evaluating Commonsense Spatial Reasoning](2024年07月01日/GRASP_A_Grid-Based_Benchmark_for_Evaluating_Commonsense_Spatial_Reasoning.md)

    - [翻译: GRASP：一款基于网格的基准测试，专为评估常识空间推理能力而设计。](2024年07月01日/GRASP_A_Grid-Based_Benchmark_for_Evaluating_Commonsense_Spatial_Reasoning.md)