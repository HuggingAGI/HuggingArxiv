# 2024年07月

2024年07月09日

- [Internet of Agents: Weaving a Web of Heterogeneous Agents for Collaborative Intelligence](2024年07月09日/Internet_of_Agents_Weaving_a_Web_of_Heterogeneous_Agents_for_Collaborative_Intelligence.md)

    - [翻译: 互联网代理网络：构建一个多元化的代理网络，以促进智能协作](2024年07月09日/Internet_of_Agents_Weaving_a_Web_of_Heterogeneous_Agents_for_Collaborative_Intelligence.md)

- [PEER: Expertizing Domain-Specific Tasks with a Multi-Agent Framework and Tuning Methods](2024年07月09日/PEER_Expertizing_Domain-Specific_Tasks_with_a_Multi-Agent_Framework_and_Tuning_Methods.md)

    - [翻译: PEER 利用多代理框架与调优方法，精通特定领域任务。](2024年07月09日/PEER_Expertizing_Domain-Specific_Tasks_with_a_Multi-Agent_Framework_and_Tuning_Methods.md)

- [Hypothetical Minds: Scaffolding Theory of Mind for Multi-Agent Tasks with Large Language Models](2024年07月09日/Hypothetical_Minds_Scaffolding_Theory_of_Mind_for_Multi-Agent_Tasks_with_Large_Language_Models.md)

    - [翻译: 假设心灵：借助大型语言模型，为多智能体任务构建心灵理论的支撑框架](2024年07月09日/Hypothetical_Minds_Scaffolding_Theory_of_Mind_for_Multi-Agent_Tasks_with_Large_Language_Models.md)

- [FinCon: A Synthesized LLM Multi-Agent System with Conceptual Verbal Reinforcement for Enhanced Financial Decision Making](2024年07月09日/FinCon_A_Synthesized_LLM_Multi-Agent_System_with_Conceptual_Verbal_Reinforcement_for_Enhanced_Financial_Decision_Making.md)

    - [翻译: FinCon：一款集成了概念性语言强化技术的合成 LLM 多智能体系统，旨在提升财务决策的精准度。](2024年07月09日/FinCon_A_Synthesized_LLM_Multi-Agent_System_with_Conceptual_Verbal_Reinforcement_for_Enhanced_Financial_Decision_Making.md)

- [Multimodal Self-Instruct: Synthetic Abstract Image and Visual Reasoning Instruction Using Language Model](2024年07月09日/Multimodal_Self-Instruct_Synthetic_Abstract_Image_and_Visual_Reasoning_Instruction_Using_Language_Model.md)

    - [翻译: 多模态自我指导：借助语言模型，合成抽象图像并进行视觉推理指导](2024年07月09日/Multimodal_Self-Instruct_Synthetic_Abstract_Image_and_Visual_Reasoning_Instruction_Using_Language_Model.md)

- [Explicit Modelling of Theory of Mind for Belief Prediction in Nonverbal Social Interactions](2024年07月09日/Explicit_Modelling_of_Theory_of_Mind_for_Belief_Prediction_in_Nonverbal_Social_Interactions.md)

    - [翻译: 在非言语社交互动中，显式建模心智理论以预测信念](2024年07月09日/Explicit_Modelling_of_Theory_of_Mind_for_Belief_Prediction_in_Nonverbal_Social_Interactions.md)

- [Richelieu: Self-Evolving LLM-Based Agents for AI Diplomacy](2024年07月09日/Richelieu_Self-Evolving_LLM-Based_Agents_for_AI_Diplomacy.md)

    - [翻译: Richelieu：自进化 LLM 驱动的 AI 外交智能体](2024年07月09日/Richelieu_Self-Evolving_LLM-Based_Agents_for_AI_Diplomacy.md)

2024年07月08日

- [GenArtist: Multimodal LLM as an Agent for Unified Image Generation and Editing](2024年07月08日/GenArtist_Multimodal_LLM_as_an_Agent_for_Unified_Image_Generation_and_Editing.md)

    - [翻译: GenArtist：一款多模态 LLM，作为统一图像生成与编辑的智能代理](2024年07月08日/GenArtist_Multimodal_LLM_as_an_Agent_for_Unified_Image_Generation_and_Editing.md)

- [Multi-label Learning with Random Circular Vectors](2024年07月08日/Multi-label_Learning_with_Random_Circular_Vectors.md)

    - [翻译: 随机循环向量在多标签学习中的应用](2024年07月08日/Multi-label_Learning_with_Random_Circular_Vectors.md)

- [GenFollower: Enhancing Car-Following Prediction with Large Language Models](2024年07月08日/GenFollower_Enhancing_Car-Following_Prediction_with_Large_Language_Models.md)

    - [翻译: GenFollower：借助大型语言模型提升车辆跟随预测的精准度](2024年07月08日/GenFollower_Enhancing_Car-Following_Prediction_with_Large_Language_Models.md)

- [Open-world Multi-label Text Classification with Extremely Weak Supervision](2024年07月08日/Open-world_Multi-label_Text_Classification_with_Extremely_Weak_Supervision.md)

    - [翻译: 极弱监督下的开放世界多标签文本分类](2024年07月08日/Open-world_Multi-label_Text_Classification_with_Extremely_Weak_Supervision.md)

- [Generative Debunking of Climate Misinformation](2024年07月08日/Generative_Debunking_of_Climate_Misinformation.md)

    - [翻译: 揭秘气候谣言的生成式方法](2024年07月08日/Generative_Debunking_of_Climate_Misinformation.md)

- [iLLM-TSC: Integration reinforcement learning and large language model for traffic signal control policy improvement](2024年07月08日/iLLM-TSC_Integration_reinforcement_learning_and_large_language_model_for_traffic_signal_control_policy_improvement.md)

    - [翻译: iLLM-TSC：融合强化学习与大型语言模型，优化交通信号控制策略](2024年07月08日/iLLM-TSC_Integration_reinforcement_learning_and_large_language_model_for_traffic_signal_control_policy_improvement.md)

- [ANOLE: An Open, Autoregressive, Native Large Multimodal Models for Interleaved Image-Text Generation](2024年07月08日/ANOLE_An_Open,_Autoregressive,_Native_Large_Multimodal_Models_for_Interleaved_Image-Text_Generation.md)

    - [翻译: ANOLE 是一个开放且自回归的原生大型多模态模型，专为交错图像与文本生成而设计。](2024年07月08日/ANOLE_An_Open,_Autoregressive,_Native_Large_Multimodal_Models_for_Interleaved_Image-Text_Generation.md)

- [Cross-domain Few-shot In-context Learning for Enhancing Traffic Sign Recognition](2024年07月08日/Cross-domain_Few-shot_In-context_Learning_for_Enhancing_Traffic_Sign_Recognition.md)

    - [翻译: 通过跨域少样本上下文学习提升交通标志识别能力](2024年07月08日/Cross-domain_Few-shot_In-context_Learning_for_Enhancing_Traffic_Sign_Recognition.md)

- [Potential of Multimodal Large Language Models for Data Mining of Medical Images and Free-text Reports](2024年07月08日/Potential_of_Multimodal_Large_Language_Models_for_Data_Mining_of_Medical_Images_and_Free-text_Reports.md)

    - [翻译: 多模态大型语言模型在医学图像与自由文本报告数据挖掘中的应用潜力](2024年07月08日/Potential_of_Multimodal_Large_Language_Models_for_Data_Mining_of_Medical_Images_and_Free-text_Reports.md)

- [Multi-Object Hallucination in Vision-Language Models](2024年07月08日/Multi-Object_Hallucination_in_Vision-Language_Models.md)

    - [翻译: 视觉-语言模型中的多对象幻觉现象](2024年07月08日/Multi-Object_Hallucination_in_Vision-Language_Models.md)

- [Video-STaR: Self-Training Enables Video Instruction Tuning with Any Supervision](2024年07月08日/Video-STaR_Self-Training_Enables_Video_Instruction_Tuning_with_Any_Supervision.md)

    - [翻译: Video-STaR：通过自训练，视频指令调优可利用任意监督方式进行。](2024年07月08日/Video-STaR_Self-Training_Enables_Video_Instruction_Tuning_with_Any_Supervision.md)

- [CrowdMoGen: Zero-Shot Text-Driven Collective Motion Generation](2024年07月08日/CrowdMoGen_Zero-Shot_Text-Driven_Collective_Motion_Generation.md)

    - [翻译: CrowdMoGen：引领零-Shot 文本驱动的集体运动创新](2024年07月08日/CrowdMoGen_Zero-Shot_Text-Driven_Collective_Motion_Generation.md)

- [Vision-Language Models under Cultural and Inclusive Considerations](2024年07月08日/Vision-Language_Models_under_Cultural_and_Inclusive_Considerations.md)

    - [翻译: 文化与包容视角下的视觉语言模型研究](2024年07月08日/Vision-Language_Models_under_Cultural_and_Inclusive_Considerations.md)

- [On Speeding Up Language Model Evaluation](2024年07月08日/On_Speeding_Up_Language_Model_Evaluation.md)

    - [翻译: 加速语言模型评估之道](2024年07月08日/On_Speeding_Up_Language_Model_Evaluation.md)

- [What's Wrong with Your Code Generated by Large Language Models? An Extensive Study](2024年07月08日/What's_Wrong_with_Your_Code_Generated_by_Large_Language_Models_An_Extensive_Study.md)

    - [翻译: 大型语言模型所编代码，问题何在？深入探究。](2024年07月08日/What's_Wrong_with_Your_Code_Generated_by_Large_Language_Models_An_Extensive_Study.md)

- [Using Grammar Masking to Ensure Syntactic Validity in LLM-based Modeling Tasks](2024年07月08日/Using_Grammar_Masking_to_Ensure_Syntactic_Validity_in_LLM-based_Modeling_Tasks.md)

    - [翻译: 通过语法掩蔽技术，我们确保了 LLM 建模任务中的句法正确性。](2024年07月08日/Using_Grammar_Masking_to_Ensure_Syntactic_Validity_in_LLM-based_Modeling_Tasks.md)

- [Evaluating the Semantic Profiling Abilities of LLMs for Natural Language Utterances in Data Visualization](2024年07月08日/Evaluating_the_Semantic_Profiling_Abilities_of_LLMs_for_Natural_Language_Utterances_in_Data_Visualization.md)

    - [翻译: 探究 LLM 在数据可视化领域对自然语言表达的语义解析能力](2024年07月08日/Evaluating_the_Semantic_Profiling_Abilities_of_LLMs_for_Natural_Language_Utterances_in_Data_Visualization.md)

- [Depression Detection and Analysis using Large Language Models on Textual and Audio-Visual Modalities](2024年07月08日/Depression_Detection_and_Analysis_using_Large_Language_Models_on_Textual_and_Audio-Visual_Modalities.md)

    - [翻译: 利用大型语言模型，结合文本与视听信息，精准检测与分析抑郁症](2024年07月08日/Depression_Detection_and_Analysis_using_Large_Language_Models_on_Textual_and_Audio-Visual_Modalities.md)

- [Artificial Intuition: Efficient Classification of Scientific Abstracts](2024年07月08日/Artificial_Intuition_Efficient_Classification_of_Scientific_Abstracts.md)

    - [翻译: 人工直觉：科学摘要的高效分类](2024年07月08日/Artificial_Intuition_Efficient_Classification_of_Scientific_Abstracts.md)

- [Merge, Ensemble, and Cooperate! A Survey on Collaborative Strategies in the Era of Large Language Models](2024年07月08日/Merge,_Ensemble,_and_Cooperate!_A_Survey_on_Collaborative_Strategies_in_the_Era_of_Large_Language_Models.md)

    - [翻译: 融合、集成与协作：大型语言模型时代协同策略探析](2024年07月08日/Merge,_Ensemble,_and_Cooperate!_A_Survey_on_Collaborative_Strategies_in_the_Era_of_Large_Language_Models.md)

- [From Loops to Oops: Fallback Behaviors of Language Models Under Uncertainty](2024年07月08日/From_Loops_to_Oops_Fallback_Behaviors_of_Language_Models_Under_Uncertainty.md)

    - [翻译: 当不确定性来袭，语言模型从循环往复走向“哎呀”时刻，探索其在未知中的回退策略。](2024年07月08日/From_Loops_to_Oops_Fallback_Behaviors_of_Language_Models_Under_Uncertainty.md)

- [Vision-Braille: An End-to-End Tool for Chinese Braille Image-to-Text Translation](2024年07月08日/Vision-Braille_An_End-to-End_Tool_for_Chinese_Braille_Image-to-Text_Translation.md)

    - [翻译: Vision-Braille：一款端到端的中文盲文图像转文本工具](2024年07月08日/Vision-Braille_An_End-to-End_Tool_for_Chinese_Braille_Image-to-Text_Translation.md)

- [MST5 -- Multilingual Question Answering over Knowledge Graphs](2024年07月08日/MST5_--_Multilingual_Question_Answering_over_Knowledge_Graphs.md)

    - [翻译: MST5 —— 知识图谱上的多语言问答系统](2024年07月08日/MST5_--_Multilingual_Question_Answering_over_Knowledge_Graphs.md)

- [PAS: Data-Efficient Plug-and-Play Prompt Augmentation System](2024年07月08日/PAS_Data-Efficient_Plug-and-Play_Prompt_Augmentation_System.md)

    - [翻译: PAS：一款数据高效、即插即用的提示增强系统](2024年07月08日/PAS_Data-Efficient_Plug-and-Play_Prompt_Augmentation_System.md)

- [Distilling System 2 into System 1](2024年07月08日/Distilling_System_2_into_System_1.md)

    - [翻译: 系统2向系统1的精炼转化](2024年07月08日/Distilling_System_2_into_System_1.md)

- [Igea: a Decoder-Only Language Model for Biomedical Text Generation in Italian](2024年07月08日/Igea_a_Decoder-Only_Language_Model_for_Biomedical_Text_Generation_in_Italian.md)

    - [翻译: Igea：专为意大利语生物医学文本生成设计的解码器语言模型](2024年07月08日/Igea_a_Decoder-Only_Language_Model_for_Biomedical_Text_Generation_in_Italian.md)

- [Perceptions to Beliefs: Exploring Precursory Inferences for Theory of Mind in Large Language Models](2024年07月08日/Perceptions_to_Beliefs_Exploring_Precursory_Inferences_for_Theory_of_Mind_in_Large_Language_Models.md)

    - [翻译: 从感知到信念：探究大型语言模型中心智理论的先导推断](2024年07月08日/Perceptions_to_Beliefs_Exploring_Precursory_Inferences_for_Theory_of_Mind_in_Large_Language_Models.md)

- [Exploring Human-LLM Conversations: Mental Models and the Originator of Toxicity](2024年07月08日/Exploring_Human-LLM_Conversations_Mental_Models_and_the_Originator_of_Toxicity.md)

    - [翻译: 探究人类与 LLM 对话中的心理模型及毒性源头](2024年07月08日/Exploring_Human-LLM_Conversations_Mental_Models_and_the_Originator_of_Toxicity.md)

- [LLaMAX: Scaling Linguistic Horizons of LLM by Enhancing Translation Capabilities Beyond 100 Languages](2024年07月08日/LLaMAX_Scaling_Linguistic_Horizons_of_LLM_by_Enhancing_Translation_Capabilities_Beyond_100_Languages.md)

    - [翻译: LLaMAX：拓展LLM的语言边界，强化超百种语言的翻译实力](2024年07月08日/LLaMAX_Scaling_Linguistic_Horizons_of_LLM_by_Enhancing_Translation_Capabilities_Beyond_100_Languages.md)

- [Towards Optimizing and Evaluating a Retrieval Augmented QA Chatbot using LLMs with Human in the Loop](2024年07月08日/Towards_Optimizing_and_Evaluating_a_Retrieval_Augmented_QA_Chatbot_using_LLMs_with_Human_in_the_Loop.md)

    - [翻译: 探索优化与评估：结合 LLM 与人工反馈的增强型检索问答聊天机器人](2024年07月08日/Towards_Optimizing_and_Evaluating_a_Retrieval_Augmented_QA_Chatbot_using_LLMs_with_Human_in_the_Loop.md)

- [Generation and De-Identification of Indian Clinical Discharge Summaries using LLMs](2024年07月08日/Generation_and_De-Identification_of_Indian_Clinical_Discharge_Summaries_using_LLMs.md)

    - [翻译: 利用大型语言模型生成并去识别化印度临床出院总结](2024年07月08日/Generation_and_De-Identification_of_Indian_Clinical_Discharge_Summaries_using_LLMs.md)

- [KG-FPQ: Evaluating Factuality Hallucination in LLMs with Knowledge Graph-based False Premise Questions](2024年07月08日/KG-FPQ_Evaluating_Factuality_Hallucination_in_LLMs_with_Knowledge_Graph-based_False_Premise_Questions.md)

    - [翻译: KG-FPQ：通过基于知识图的错误前提问题，评估 LLM 中的事实性幻觉问题。](2024年07月08日/KG-FPQ_Evaluating_Factuality_Hallucination_in_LLMs_with_Knowledge_Graph-based_False_Premise_Questions.md)

- [Empowering 1000 tokens/second on-device LLM prefilling with mllm-NPU](2024年07月08日/Empowering_1000_tokenssecond_on-device_LLM_prefilling_with_mllm-NPU.md)

    - [翻译: 借助mllm-NPU，实现设备上LLM每秒高效预填充1000个令牌。](2024年07月08日/Empowering_1000_tokenssecond_on-device_LLM_prefilling_with_mllm-NPU.md)

- [An Empirical Comparison of Vocabulary Expansion and Initialization Approaches for Language Models](2024年07月08日/An_Empirical_Comparison_of_Vocabulary_Expansion_and_Initialization_Approaches_for_Language_Models.md)

    - [翻译: 语言模型中词汇扩展与初始化方法的实证对比研究](2024年07月08日/An_Empirical_Comparison_of_Vocabulary_Expansion_and_Initialization_Approaches_for_Language_Models.md)

- [HyCIR: Boosting Zero-Shot Composed Image Retrieval with Synthetic Labels](2024年07月08日/HyCIR_Boosting_Zero-Shot_Composed_Image_Retrieval_with_Synthetic_Labels.md)

    - [翻译: HyCIR 技术通过合成标签，显著提升了零-shot组合图像检索的性能。](2024年07月08日/HyCIR_Boosting_Zero-Shot_Composed_Image_Retrieval_with_Synthetic_Labels.md)

- [Large Language Models for Judicial Entity Extraction: A Comparative Study](2024年07月08日/Large_Language_Models_for_Judicial_Entity_Extraction_A_Comparative_Study.md)

    - [翻译: 司法实体提取领域的大型语言模型比较研究](2024年07月08日/Large_Language_Models_for_Judicial_Entity_Extraction_A_Comparative_Study.md)

- [Hecaton: Training and Finetuning Large Language Models with Scalable Chiplet Systems](2024年07月08日/Hecaton_Training_and_Finetuning_Large_Language_Models_with_Scalable_Chiplet_Systems.md)

    - [翻译: Hecaton：借助可扩展的小芯片系统，高效训练与微调大型语言模型。](2024年07月08日/Hecaton_Training_and_Finetuning_Large_Language_Models_with_Scalable_Chiplet_Systems.md)

- [When is the consistent prediction likely to be a correct prediction?](2024年07月08日/When_is_the_consistent_prediction_likely_to_be_a_correct_prediction.md)

    - [翻译: 何时一致的预测更可能是正确的？](2024年07月08日/When_is_the_consistent_prediction_likely_to_be_a_correct_prediction.md)

- [Large Language Models Understand Layouts](2024年07月08日/Large_Language_Models_Understand_Layouts.md)

    - [翻译: 大型语言模型具备理解布局的能力。](2024年07月08日/Large_Language_Models_Understand_Layouts.md)

- [Do Multilingual Large Language Models Mitigate Stereotype Bias?](2024年07月08日/Do_Multilingual_Large_Language_Models_Mitigate_Stereotype_Bias.md)

    - [翻译: 多语言大型语言模型能否缓解刻板印象偏见？](2024年07月08日/Do_Multilingual_Large_Language_Models_Mitigate_Stereotype_Bias.md)

- [Empirical Study of Symmetrical Reasoning in Conversational Chatbots](2024年07月08日/Empirical_Study_of_Symmetrical_Reasoning_in_Conversational_Chatbots.md)

    - [翻译: 探究对话型聊天机器人中的对称推理实证研究](2024年07月08日/Empirical_Study_of_Symmetrical_Reasoning_in_Conversational_Chatbots.md)

- [Is GPT-4 Alone Sufficient for Automated Essay Scoring?: A Comparative Judgment Approach Based on Rater Cognition](2024年07月08日/Is_GPT-4_Alone_Sufficient_for_Automated_Essay_Scoring_A_Comparative_Judgment_Approach_Based_on_Rater_Cognition.md)

    - [翻译: GPT-4 能否独立胜任自动作文评分？本研究采用基于评分者认知的比较判断方法，探讨其可行性。](2024年07月08日/Is_GPT-4_Alone_Sufficient_for_Automated_Essay_Scoring_A_Comparative_Judgment_Approach_Based_on_Rater_Cognition.md)

- [PsycoLLM: Enhancing LLM for Psychological Understanding and Evaluation](2024年07月08日/PsycoLLM_Enhancing_LLM_for_Psychological_Understanding_and_Evaluation.md)

    - [翻译: PsycoLLM：提升 LLM 的心理理解和评估能力](2024年07月08日/PsycoLLM_Enhancing_LLM_for_Psychological_Understanding_and_Evaluation.md)

- [InverseCoder: Unleashing the Power of Instruction-Tuned Code LLMs with Inverse-Instruct](2024年07月08日/InverseCoder_Unleashing_the_Power_of_Instruction-Tuned_Code_LLMs_with_Inverse-Instruct.md)

    - [翻译: InverseCoder：借助 Inverse-Instruct 技术，释放指令调优代码大型模型（LLM）的潜能。](2024年07月08日/InverseCoder_Unleashing_the_Power_of_Instruction-Tuned_Code_LLMs_with_Inverse-Instruct.md)

- [Sub-SA: Strengthen In-context Learning via Submodular Selective Annotation](2024年07月08日/Sub-SA_Strengthen_In-context_Learning_via_Submodular_Selective_Annotation.md)

    - [翻译: Sub-SA：借助子模块选择性注释强化上下文学习](2024年07月08日/Sub-SA_Strengthen_In-context_Learning_via_Submodular_Selective_Annotation.md)

- [Pruning Large Language Models to Intra-module Low-rank Architecture with Transitional Activations](2024年07月08日/Pruning_Large_Language_Models_to_Intra-module_Low-rank_Architecture_with_Transitional_Activations.md)

    - [翻译: 精简大型语言模型至模块内低秩结构，结合过渡激活技术](2024年07月08日/Pruning_Large_Language_Models_to_Intra-module_Low-rank_Architecture_with_Transitional_Activations.md)

- [Retrieved In-Context Principles from Previous Mistakes](2024年07月08日/Retrieved_In-Context_Principles_from_Previous_Mistakes.md)

    - [翻译: 汲取过往失误中的上下文原则](2024年07月08日/Retrieved_In-Context_Principles_from_Previous_Mistakes.md)

- [DebUnc: Mitigating Hallucinations in Large Language Model Agent Communication with Uncertainty Estimations](2024年07月08日/DebUnc_Mitigating_Hallucinations_in_Large_Language_Model_Agent_Communication_with_Uncertainty_Estimations.md)

    - [翻译: DebUnc：利用不确定性估计，有效减少大型语言模型代理通信中的幻觉现象。](2024年07月08日/DebUnc_Mitigating_Hallucinations_in_Large_Language_Model_Agent_Communication_with_Uncertainty_Estimations.md)

- [SimPal: Towards a Meta-Conversational Framework to Understand Teacher's Instructional Goals for K-12 Physics](2024年07月08日/SimPal_Towards_a_Meta-Conversational_Framework_to_Understand_Teacher's_Instructional_Goals_for_K-12_Physics.md)

    - [翻译: SimPal：构建元对话框架，深入解析 K-12 物理教学中教师的指导目标](2024年07月08日/SimPal_Towards_a_Meta-Conversational_Framework_to_Understand_Teacher's_Instructional_Goals_for_K-12_Physics.md)

- [Multimodal Chain-of-Thought Reasoning via ChatGPT to Protect Children from Age-Inappropriate Apps](2024年07月08日/Multimodal_Chain-of-Thought_Reasoning_via_ChatGPT_to_Protect_Children_from_Age-Inappropriate_Apps.md)

    - [翻译: 利用 ChatGPT 进行多模态思维链推理，守护儿童远离不适龄应用的侵害](2024年07月08日/Multimodal_Chain-of-Thought_Reasoning_via_ChatGPT_to_Protect_Children_from_Age-Inappropriate_Apps.md)

- [VIMI: Grounding Video Generation through Multi-modal Instruction](2024年07月08日/VIMI_Grounding_Video_Generation_through_Multi-modal_Instruction.md)

    - [翻译: VIMI：借助多模态指令，奠定视频生成之基石](2024年07月08日/VIMI_Grounding_Video_Generation_through_Multi-modal_Instruction.md)

2024年07月07日

- [Collective Innovation in Groups of Large Language Models](2024年07月07日/Collective_Innovation_in_Groups_of_Large_Language_Models.md)

    - [翻译: 大型语言模型群体中的集体创新](2024年07月07日/Collective_Innovation_in_Groups_of_Large_Language_Models.md)

- [MINDECHO: Role-Playing Language Agents for Key Opinion Leaders](2024年07月07日/MINDECHO_Role-Playing_Language_Agents_for_Key_Opinion_Leaders.md)

    - [翻译: MINDECHO：专为关键意见领袖打造的角色扮演语言代理](2024年07月07日/MINDECHO_Role-Playing_Language_Agents_for_Key_Opinion_Leaders.md)

- [WorkArena++: Towards Compositional Planning and Reasoning-based Common Knowledge Work Tasks](2024年07月07日/WorkArena++_Towards_Compositional_Planning_and_Reasoning-based_Common_Knowledge_Work_Tasks.md)

    - [翻译: WorkArena++：探索基于组合规划与推理的通用知识工作任务](2024年07月07日/WorkArena++_Towards_Compositional_Planning_and_Reasoning-based_Common_Knowledge_Work_Tasks.md)

- [Multimodal Language Models for Domain-Specific Procedural Video Summarization](2024年07月07日/Multimodal_Language_Models_for_Domain-Specific_Procedural_Video_Summarization.md)

    - [翻译: 特定领域程序视频摘要的多模态语言模型](2024年07月07日/Multimodal_Language_Models_for_Domain-Specific_Procedural_Video_Summarization.md)

- [VideoCoT: A Video Chain-of-Thought Dataset with Active Annotation Tool](2024年07月07日/VideoCoT_A_Video_Chain-of-Thought_Dataset_with_Active_Annotation_Tool.md)

    - [翻译: VideoCoT：一款集成了主动注释工具的视频思维链数据集](2024年07月07日/VideoCoT_A_Video_Chain-of-Thought_Dataset_with_Active_Annotation_Tool.md)

- [: Towards Effective and Efficient Cost Function Design for Safe Reinforcement Learning via Large Language Model](2024年07月07日/_Towards_Effective_and_Efficient_Cost_Function_Design_for_Safe_Reinforcement_Learning_via_Large_Language_Model.md)

    - [翻译: 利用大型语言模型，我们致力于设计既安全又高效的强化学习成本函数。](2024年07月07日/_Towards_Effective_and_Efficient_Cost_Function_Design_for_Safe_Reinforcement_Learning_via_Large_Language_Model.md)

- [LLMBox: A Comprehensive Library for Large Language Models](2024年07月07日/LLMBox_A_Comprehensive_Library_for_Large_Language_Models.md)

    - [翻译: LLMBox：大型语言模型的综合库](2024年07月07日/LLMBox_A_Comprehensive_Library_for_Large_Language_Models.md)

- [Faux Polyglot: A Study on Information Disparity in Multilingual Large Language Models](2024年07月07日/Faux_Polyglot_A_Study_on_Information_Disparity_in_Multilingual_Large_Language_Models.md)

    - [翻译: 《伪多语者》：探究多语言大型模型中的信息鸿沟](2024年07月07日/Faux_Polyglot_A_Study_on_Information_Disparity_in_Multilingual_Large_Language_Models.md)

- [Just read twice: closing the recall gap for recurrent language models](2024年07月07日/Just_read_twice_closing_the_recall_gap_for_recurrent_language_models.md)

    - [翻译: 双读法：助力循环语言模型提升召回率](2024年07月07日/Just_read_twice_closing_the_recall_gap_for_recurrent_language_models.md)

- [Biomedical Nested NER with Large Language Model and UMLS Heuristics](2024年07月07日/Biomedical_Nested_NER_with_Large_Language_Model_and_UMLS_Heuristics.md)

    - [翻译: 结合大型语言模型与UMLS启发式方法的生物医学嵌套NER研究](2024年07月07日/Biomedical_Nested_NER_with_Large_Language_Model_and_UMLS_Heuristics.md)

- [Enhancing Hallucination Detection through Perturbation-Based Synthetic Data Generation in System Responses](2024年07月07日/Enhancing_Hallucination_Detection_through_Perturbation-Based_Synthetic_Data_Generation_in_System_Responses.md)

    - [翻译: 利用基于扰动的合成数据生成技术，提升系统响应中幻觉检测的效能。](2024年07月07日/Enhancing_Hallucination_Detection_through_Perturbation-Based_Synthetic_Data_Generation_in_System_Responses.md)

- [Experiments with truth using Machine Learning: Spectral analysis and explainable classification of synthetic, false, and genuine information](2024年07月07日/Experiments_with_truth_using_Machine_Learning_Spectral_analysis_and_explainable_classification_of_synthetic,_false,_and_genuine_information.md)

    - [翻译: 探索机器学习在真实性实验中的应用：通过光谱分析与可解释分类，揭示合成、虚假与真实信息的奥秘。](2024年07月07日/Experiments_with_truth_using_Machine_Learning_Spectral_analysis_and_explainable_classification_of_synthetic,_false,_and_genuine_information.md)

- [Training Task Experts through Retrieval Based Distillation](2024年07月07日/Training_Task_Experts_through_Retrieval_Based_Distillation.md)

    - [翻译: 利用基于检索的蒸馏技术培养任务专家](2024年07月07日/Training_Task_Experts_through_Retrieval_Based_Distillation.md)

- [Enhancing Computer Programming Education with LLMs: A Study on Effective Prompt Engineering for Python Code Generation](2024年07月07日/Enhancing_Computer_Programming_Education_with_LLMs_A_Study_on_Effective_Prompt_Engineering_for_Python_Code_Generation.md)

    - [翻译: 利用 LLM 提升编程教育：探索 Python 代码生成中的高效提示设计](2024年07月07日/Enhancing_Computer_Programming_Education_with_LLMs_A_Study_on_Effective_Prompt_Engineering_for_Python_Code_Generation.md)

- [LTLBench: Towards Benchmarks for Evaluating Temporal Logic Reasoning in Large Language Models](2024年07月07日/LTLBench_Towards_Benchmarks_for_Evaluating_Temporal_Logic_Reasoning_in_Large_Language_Models.md)

    - [翻译: LTLBench：专为评估大型语言模型中的时间逻辑推理而设计的基准测试](2024年07月07日/LTLBench_Towards_Benchmarks_for_Evaluating_Temporal_Logic_Reasoning_in_Large_Language_Models.md)

- [SBoRA: Low-Rank Adaptation with Regional Weight Updates](2024年07月07日/SBoRA_Low-Rank_Adaptation_with_Regional_Weight_Updates.md)

    - [翻译: SBoRA：通过区域权重更新实现低秩适应](2024年07月07日/SBoRA_Low-Rank_Adaptation_with_Regional_Weight_Updates.md)

- [Assessing Code Generation with Intermediate Languages](2024年07月07日/Assessing_Code_Generation_with_Intermediate_Languages.md)

    - [翻译: 通过中间语言评估代码生成](2024年07月07日/Assessing_Code_Generation_with_Intermediate_Languages.md)

- [CosyVoice: A Scalable Multilingual Zero-shot Text-to-speech Synthesizer based on Supervised Semantic Tokens](2024年07月07日/CosyVoice_A_Scalable_Multilingual_Zero-shot_Text-to-speech_Synthesizer_based_on_Supervised_Semantic_Tokens.md)

    - [翻译: CosyVoice：一款基于监督语义令牌的，可扩展的多语言零-shot 文本转语音合成器。](2024年07月07日/CosyVoice_A_Scalable_Multilingual_Zero-shot_Text-to-speech_Synthesizer_based_on_Supervised_Semantic_Tokens.md)

- [ElecBench: a Power Dispatch Evaluation Benchmark for Large Language Models](2024年07月07日/ElecBench_a_Power_Dispatch_Evaluation_Benchmark_for_Large_Language_Models.md)

    - [翻译: ElecBench：大型语言模型电力调度评估的基准](2024年07月07日/ElecBench_a_Power_Dispatch_Evaluation_Benchmark_for_Large_Language_Models.md)

- [Emilia: An Extensive, Multilingual, and Diverse Speech Dataset for Large-Scale Speech Generation](2024年07月07日/Emilia_An_Extensive,_Multilingual,_and_Diverse_Speech_Dataset_for_Large-Scale_Speech_Generation.md)

    - [翻译: Emilia 数据集，涵盖广泛、多语言且多样化，专为大规模语音生成设计。](2024年07月07日/Emilia_An_Extensive,_Multilingual,_and_Diverse_Speech_Dataset_for_Large-Scale_Speech_Generation.md)

- [A Queueing Theoretic Perspective on Low-Latency LLM Inference with Variable Token Length](2024年07月07日/A_Queueing_Theoretic_Perspective_on_Low-Latency_LLM_Inference_with_Variable_Token_Length.md)

    - [翻译: 从排队理论视角出发，解析大型语言模型在可变令牌长度下的低延迟推理](2024年07月07日/A_Queueing_Theoretic_Perspective_on_Low-Latency_LLM_Inference_with_Variable_Token_Length.md)

- [Can Model Uncertainty Function as a Proxy for Multiple-Choice Question Item Difficulty?](2024年07月07日/Can_Model_Uncertainty_Function_as_a_Proxy_for_Multiple-Choice_Question_Item_Difficulty.md)

    - [翻译: 模型不确定性是否能代表多项选择题的难度？](2024年07月07日/Can_Model_Uncertainty_Function_as_a_Proxy_for_Multiple-Choice_Question_Item_Difficulty.md)

- [Enhancing Label-efficient Medical Image Segmentation with Text-guided Diffusion Models](2024年07月07日/Enhancing_Label-efficient_Medical_Image_Segmentation_with_Text-guided_Diffusion_Models.md)

    - [翻译: 利用文本引导的扩散模型，提升医学图像分割的标签效率](2024年07月07日/Enhancing_Label-efficient_Medical_Image_Segmentation_with_Text-guided_Diffusion_Models.md)

- [Exploring the Educational Landscape of AI: Large Language Models' Approaches to Explaining Conservation of Momentum in Physics](2024年07月07日/Exploring_the_Educational_Landscape_of_AI_Large_Language_Models'_Approaches_to_Explaining_Conservation_of_Momentum_in_Physics.md)

    - [翻译: 探究AI教育领域：大型语言模型如何解释物理学中的动量守恒](2024年07月07日/Exploring_the_Educational_Landscape_of_AI_Large_Language_Models'_Approaches_to_Explaining_Conservation_of_Momentum_in_Physics.md)

- [UltraEdit: Instruction-based Fine-Grained Image Editing at Scale](2024年07月07日/UltraEdit_Instruction-based_Fine-Grained_Image_Editing_at_Scale.md)

    - [翻译: UltraEdit：大规模基于指令的精细图像编辑](2024年07月07日/UltraEdit_Instruction-based_Fine-Grained_Image_Editing_at_Scale.md)

- [Beyond Binary Gender Labels: Revealing Gender Biases in LLMs through Gender-Neutral Name Predictions](2024年07月07日/Beyond_Binary_Gender_Labels_Revealing_Gender_Biases_in_LLMs_through_Gender-Neutral_Name_Predictions.md)

    - [翻译: 揭秘 LLM 中的性别偏见：从无性别标签的名字预测出发](2024年07月07日/Beyond_Binary_Gender_Labels_Revealing_Gender_Biases_in_LLMs_through_Gender-Neutral_Name_Predictions.md)

2024年07月06日

- [RULE: Reliable Multimodal RAG for Factuality in Medical Vision Language Models](2024年07月06日/RULE_Reliable_Multimodal_RAG_for_Factuality_in_Medical_Vision_Language_Models.md)

    - [翻译: RULE：医学视觉语言模型中事实性的可靠多模态 RAG](2024年07月06日/RULE_Reliable_Multimodal_RAG_for_Factuality_in_Medical_Vision_Language_Models.md)

- [Enhance the Robustness of Text-Centric Multimodal Alignments](2024年07月06日/Enhance_the_Robustness_of_Text-Centric_Multimodal_Alignments.md)

    - [翻译: 提升文本主导型多模态对齐的稳健性](2024年07月06日/Enhance_the_Robustness_of_Text-Centric_Multimodal_Alignments.md)

- [LogicVista: Multimodal LLM Logical Reasoning Benchmark in Visual Contexts](2024年07月06日/LogicVista_Multimodal_LLM_Logical_Reasoning_Benchmark_in_Visual_Contexts.md)

    - [翻译: LogicVista：一项针对视觉环境中多模态大型语言模型的逻辑推理基准测试](2024年07月06日/LogicVista_Multimodal_LLM_Logical_Reasoning_Benchmark_in_Visual_Contexts.md)

- [CLIMB: A Benchmark of Clinical Bias in Large Language Models](2024年07月06日/CLIMB_A_Benchmark_of_Clinical_Bias_in_Large_Language_Models.md)

    - [翻译: CLIMB：一项针对大型语言模型中临床偏差的基准研究](2024年07月06日/CLIMB_A_Benchmark_of_Clinical_Bias_in_Large_Language_Models.md)

- [Large Language Model as an Assignment Evaluator: Insights, Feedback, and Challenges in a 1000+ Student Course](2024年07月06日/Large_Language_Model_as_an_Assignment_Evaluator_Insights,_Feedback,_and_Challenges_in_a_1000+_Student_Course.md)

    - [翻译: 大型语言模型在评估作业方面提供了宝贵的见解和反馈，但在处理超过1000名学生的课程时也面临挑战。](2024年07月06日/Large_Language_Model_as_an_Assignment_Evaluator_Insights,_Feedback,_and_Challenges_in_a_1000+_Student_Course.md)

- [BadCLM: Backdoor Attack in Clinical Language Models for Electronic Health Records](2024年07月06日/BadCLM_Backdoor_Attack_in_Clinical_Language_Models_for_Electronic_Health_Records.md)

    - [翻译: BadCLM：电子健康记录中临床语言模型的后门攻击](2024年07月06日/BadCLM_Backdoor_Attack_in_Clinical_Language_Models_for_Electronic_Health_Records.md)

- [Harnessing the Power of LLMs: Automating Unit Test Generation for High-Performance Computing](2024年07月06日/Harnessing_the_Power_of_LLMs_Automating_Unit_Test_Generation_for_High-Performance_Computing.md)

    - [翻译: 驾驭 LLM 之力：自动生成高性能计算的单元测试](2024年07月06日/Harnessing_the_Power_of_LLMs_Automating_Unit_Test_Generation_for_High-Performance_Computing.md)

- [LLMCloudHunter: Harnessing LLMs for Automated Extraction of Detection Rules from Cloud-Based CTI](2024年07月06日/LLMCloudHunter_Harnessing_LLMs_for_Automated_Extraction_of_Detection_Rules_from_Cloud-Based_CTI.md)

    - [翻译: LLMCloudHunter：借助 LLM 之力，自动化提炼云端 CTI 的检测规则](2024年07月06日/LLMCloudHunter_Harnessing_LLMs_for_Automated_Extraction_of_Detection_Rules_from_Cloud-Based_CTI.md)

- [FlowLearn: Evaluating Large Vision-Language Models on Flowchart Understanding](2024年07月06日/FlowLearn_Evaluating_Large_Vision-Language_Models_on_Flowchart_Understanding.md)

    - [翻译: FlowLearn：评估大型视觉-语言模型在流程图理解方面的表现](2024年07月06日/FlowLearn_Evaluating_Large_Vision-Language_Models_on_Flowchart_Understanding.md)

- [Feedback-Driven Automated Whole Bug Report Reproduction for Android Apps](2024年07月06日/Feedback-Driven_Automated_Whole_Bug_Report_Reproduction_for_Android_Apps.md)

    - [翻译: 安卓应用的反馈驱动自动化错误报告重现](2024年07月06日/Feedback-Driven_Automated_Whole_Bug_Report_Reproduction_for_Android_Apps.md)

- [Lucy: Think and Reason to Solve Text-to-SQL](2024年07月06日/Lucy_Think_and_Reason_to_Solve_Text-to-SQL.md)

    - [翻译: Lucy：运用思考与推理，攻克 Text-to-SQL 难题](2024年07月06日/Lucy_Think_and_Reason_to_Solve_Text-to-SQL.md)

- [Vortex under Ripplet: An Empirical Study of RAG-enabled Applications](2024年07月06日/Vortex_under_Ripplet_An_Empirical_Study_of_RAG-enabled_Applications.md)

    - [翻译: Ripplet下的涡旋：RAG应用实证研究](2024年07月06日/Vortex_under_Ripplet_An_Empirical_Study_of_RAG-enabled_Applications.md)

- [Solving for X and Beyond: Can Large Language Models Solve Complex Math Problems with More-Than-Two Unknowns?](2024年07月06日/Solving_for_X_and_Beyond_Can_Large_Language_Models_Solve_Complex_Math_Problems_with_More-Than-Two_Unknowns.md)

    - [翻译: 大型语言模型能否破解包含多于两个未知数的复杂数学难题？这一挑战正待揭晓。](2024年07月06日/Solving_for_X_and_Beyond_Can_Large_Language_Models_Solve_Complex_Math_Problems_with_More-Than-Two_Unknowns.md)

- [SHINE: Saliency-aware HIerarchical NEgative Ranking for Compositional Temporal Grounding](2024年07月06日/SHINE_Saliency-aware_HIerarchical_NEgative_Ranking_for_Compositional_Temporal_Grounding.md)

    - [翻译: SHINE：基于显著性感知的层次负排序技术，用于组合时态定位任务](2024年07月06日/SHINE_Saliency-aware_HIerarchical_NEgative_Ranking_for_Compositional_Temporal_Grounding.md)

- [Leveraging Task-Specific Knowledge from LLM for Semi-Supervised 3D Medical Image Segmentation](2024年07月06日/Leveraging_Task-Specific_Knowledge_from_LLM_for_Semi-Supervised_3D_Medical_Image_Segmentation.md)

    - [翻译: 借助 LLM 中的任务特定知识，实现半监督式 3D 医学图像分割](2024年07月06日/Leveraging_Task-Specific_Knowledge_from_LLM_for_Semi-Supervised_3D_Medical_Image_Segmentation.md)

- [Code Less, Align More: Efficient LLM Fine-tuning for Code Generation with Data Pruning](2024年07月06日/Code_Less,_Align_More_Efficient_LLM_Fine-tuning_for_Code_Generation_with_Data_Pruning.md)

    - [翻译: 精简代码，强化对齐：利用数据修剪提升代码生成的 LLM 微调效率](2024年07月06日/Code_Less,_Align_More_Efficient_LLM_Fine-tuning_for_Code_Generation_with_Data_Pruning.md)

- [Preference Distillation for Personalized Generative Recommendation](2024年07月06日/Preference_Distillation_for_Personalized_Generative_Recommendation.md)

    - [翻译: 个性化生成推荐中的偏好蒸馏](2024年07月06日/Preference_Distillation_for_Personalized_Generative_Recommendation.md)

- [How do you know that? Teaching Generative Language Models to Reference Answers to Biomedical Questions](2024年07月06日/How_do_you_know_that_Teaching_Generative_Language_Models_to_Reference_Answers_to_Biomedical_Questions.md)

    - [翻译: 如何得知？引导生成语言模型参照生物医学问题的答案](2024年07月06日/How_do_you_know_that_Teaching_Generative_Language_Models_to_Reference_Answers_to_Biomedical_Questions.md)

- [Progress or Regress? Self-Improvement Reversal in Post-training](2024年07月06日/Progress_or_Regress_Self-Improvement_Reversal_in_Post-training.md)

    - [翻译: 是进步还是退步？训练后的自我提升出现了逆转现象。](2024年07月06日/Progress_or_Regress_Self-Improvement_Reversal_in_Post-training.md)

2024年07月05日

- [Rethinking Visual Prompting for Multimodal Large Language Models with External Knowledge](2024年07月05日/Rethinking_Visual_Prompting_for_Multimodal_Large_Language_Models_with_External_Knowledge.md)

    - [翻译: 探索视觉提示在多模态大型语言模型中的新角色，并研究外部知识如何增强其效能。](2024年07月05日/Rethinking_Visual_Prompting_for_Multimodal_Large_Language_Models_with_External_Knowledge.md)

- [GPT vs RETRO: Exploring the Intersection of Retrieval and Parameter-Efficient Fine-Tuning](2024年07月05日/GPT_vs_RETRO_Exploring_the_Intersection_of_Retrieval_and_Parameter-Efficient_Fine-Tuning.md)

    - [翻译: GPT 与 RETRO：探寻检索与高效参数微调的融合之道](2024年07月05日/GPT_vs_RETRO_Exploring_the_Intersection_of_Retrieval_and_Parameter-Efficient_Fine-Tuning.md)

- [EventChat: Implementation and user-centric evaluation of a large language model-driven conversational recommender system for exploring leisure events in an SME context](2024年07月05日/EventChat_Implementation_and_user-centric_evaluation_of_a_large_language_model-driven_conversational_recommender_system_for_exploring_leisure_events_in_an_SME_context.md)

    - [翻译: EventChat：一款由大型语言模型驱动，专为中小企业背景下探索休闲活动而设计的对话推荐系统，其核心在于实现与用户为中心的评估。](2024年07月05日/EventChat_Implementation_and_user-centric_evaluation_of_a_large_language_model-driven_conversational_recommender_system_for_exploring_leisure_events_in_an_SME_context.md)

- [AriGraph: Learning Knowledge Graph World Models with Episodic Memory for LLM Agents](2024年07月05日/AriGraph_Learning_Knowledge_Graph_World_Models_with_Episodic_Memory_for_LLM_Agents.md)

    - [翻译: AriGraph：利用情景记忆为 LLM 代理学习知识图谱世界模型，以增强其性能](2024年07月05日/AriGraph_Learning_Knowledge_Graph_World_Models_with_Episodic_Memory_for_LLM_Agents.md)

- [On scalable oversight with weak LLMs judging strong LLMs](2024年07月05日/On_scalable_oversight_with_weak_LLMs_judging_strong_LLMs.md)

    - [翻译: 探讨如何利用较弱的LLMs来监督更强的LLMs，实现监督的可扩展性。](2024年07月05日/On_scalable_oversight_with_weak_LLMs_judging_strong_LLMs.md)

- [VRSD: Rethinking Similarity and Diversity for Retrieval in Large Language Models](2024年07月05日/VRSD_Rethinking_Similarity_and_Diversity_for_Retrieval_in_Large_Language_Models.md)

    - [翻译: VRSD：在大规模语言模型中，重新审视检索的相似性与多样性](2024年07月05日/VRSD_Rethinking_Similarity_and_Diversity_for_Retrieval_in_Large_Language_Models.md)

- [When LLMs Play the Telephone Game: Cumulative Changes and Attractors in Iterated Cultural Transmissions](2024年07月05日/When_LLMs_Play_the_Telephone_Game_Cumulative_Changes_and_Attractors_in_Iterated_Cultural_Transmissions.md)

    - [翻译: LLM 参与“电话游戏”时，迭代文化传播中显现出累积变化与吸引子现象。](2024年07月05日/When_LLMs_Play_the_Telephone_Game_Cumulative_Changes_and_Attractors_in_Iterated_Cultural_Transmissions.md)

- [Are Large Language Models Strategic Decision Makers? A Study of Performance and Bias in Two-Player Non-Zero-Sum Games](2024年07月05日/Are_Large_Language_Models_Strategic_Decision_Makers_A_Study_of_Performance_and_Bias_in_Two-Player_Non-Zero-Sum_Games.md)

    - [翻译: 大型语言模型能否成为战略决策者？本研究探讨了在双人非零和游戏中，这些模型的表现及其潜在偏差。](2024年07月05日/Are_Large_Language_Models_Strategic_Decision_Makers_A_Study_of_Performance_and_Bias_in_Two-Player_Non-Zero-Sum_Games.md)

- [MobileFlow: A Multimodal LLM For Mobile GUI Agent](2024年07月05日/MobileFlow_A_Multimodal_LLM_For_Mobile_GUI_Agent.md)

    - [翻译: MobileFlow：专为移动界面代理设计的多模态大型语言模型](2024年07月05日/MobileFlow_A_Multimodal_LLM_For_Mobile_GUI_Agent.md)

- [WOMD-Reasoning: A Large-Scale Language Dataset for Interaction and Driving Intentions Reasoning](2024年07月05日/WOMD-Reasoning_A_Large-Scale_Language_Dataset_for_Interaction_and_Driving_Intentions_Reasoning.md)

    - [翻译: WOMD-Reasoning：专为交互与驾驶意图推理设计的大规模语言数据集](2024年07月05日/WOMD-Reasoning_A_Large-Scale_Language_Dataset_for_Interaction_and_Driving_Intentions_Reasoning.md)

- [VCoME: Verbal Video Composition with Multimodal Editing Effects](2024年07月05日/VCoME_Verbal_Video_Composition_with_Multimodal_Editing_Effects.md)

    - [翻译: VCoME：融合多模态编辑效果的口头视频创作](2024年07月05日/VCoME_Verbal_Video_Composition_with_Multimodal_Editing_Effects.md)

- [Enabling On-Device LLMs Personalization with Smartphone Sensing](2024年07月05日/Enabling_On-Device_LLMs_Personalization_with_Smartphone_Sensing.md)

    - [翻译: 通过智能手机感应实现设备上 LLM 的个性化](2024年07月05日/Enabling_On-Device_LLMs_Personalization_with_Smartphone_Sensing.md)

- [Second Place Solution of WSDM2023 Toloka Visual Question Answering Challenge](2024年07月05日/Second_Place_Solution_of_WSDM2023_Toloka_Visual_Question_Answering_Challenge.md)

    - [翻译: WSDM2023 Toloka 视觉问答挑战亚军方案](2024年07月05日/Second_Place_Solution_of_WSDM2023_Toloka_Visual_Question_Answering_Challenge.md)

- [Me, Myself, and AI: The Situational Awareness Dataset (SAD) for LLMs](2024年07月05日/Me,_Myself,_and_AI_The_Situational_Awareness_Dataset_(SAD)_for_LLMs.md)

    - [翻译: 我、自我与AI：为LLM量身打造的情境意识数据集（SAD）](2024年07月05日/Me,_Myself,_and_AI_The_Situational_Awareness_Dataset_(SAD)_for_LLMs.md)

- [ANAH-v2: Scaling Analytical Hallucination Annotation of Large Language Models](2024年07月05日/ANAH-v2_Scaling_Analytical_Hallucination_Annotation_of_Large_Language_Models.md)

    - [翻译: ANAH-v2：大型语言模型分析幻觉标注的扩展研究](2024年07月05日/ANAH-v2_Scaling_Analytical_Hallucination_Annotation_of_Large_Language_Models.md)

- [Seed-ASR: Understanding Diverse Speech and Contexts with LLM-based Speech Recognition](2024年07月05日/Seed-ASR_Understanding_Diverse_Speech_and_Contexts_with_LLM-based_Speech_Recognition.md)

    - [翻译: Seed-ASR：借助 LLM 技术，深入探索多样语音与复杂上下文的识别奥秘](2024年07月05日/Seed-ASR_Understanding_Diverse_Speech_and_Contexts_with_LLM-based_Speech_Recognition.md)

- [Lazarus: Resilient and Elastic Training of Mixture-of-Experts Models with Adaptive Expert Placement](2024年07月05日/Lazarus_Resilient_and_Elastic_Training_of_Mixture-of-Experts_Models_with_Adaptive_Expert_Placement.md)

    - [翻译: Lazarus：通过自适应专家部署，实现混合专家模型的弹性与韧性训练。](2024年07月05日/Lazarus_Resilient_and_Elastic_Training_of_Mixture-of-Experts_Models_with_Adaptive_Expert_Placement.md)

- [Entity Decomposition with Filtering: A Zero-Shot Clinical Named Entity Recognition Framework](2024年07月05日/Entity_Decomposition_with_Filtering_A_Zero-Shot_Clinical_Named_Entity_Recognition_Framework.md)

    - [翻译: 实体分解结合过滤技术，开创了一种零-shot 临床命名实体识别的新框架。](2024年07月05日/Entity_Decomposition_with_Filtering_A_Zero-Shot_Clinical_Named_Entity_Recognition_Framework.md)

- [ARM: Efficient Guided Decoding with Autoregressive Reward Models](2024年07月05日/ARM_Efficient_Guided_Decoding_with_Autoregressive_Reward_Models.md)

    - [翻译: ARM：通过自回归奖励模型实现高效引导解码](2024年07月05日/ARM_Efficient_Guided_Decoding_with_Autoregressive_Reward_Models.md)

- [Leveraging Large Language Models for Integrated Satellite-Aerial-Terrestrial Networks: Recent Advances and Future Directions](2024年07月05日/Leveraging_Large_Language_Models_for_Integrated_Satellite-Aerial-Terrestrial_Networks_Recent_Advances_and_Future_Directions.md)

    - [翻译: 大型语言模型在综合卫星-空中-地面网络中的应用：探索最新进展与未来发展方向](2024年07月05日/Leveraging_Large_Language_Models_for_Integrated_Satellite-Aerial-Terrestrial_Networks_Recent_Advances_and_Future_Directions.md)

- [PoPreRo: A New Dataset for Popularity Prediction of Romanian Reddit Posts](2024年07月05日/PoPreRo_A_New_Dataset_for_Popularity_Prediction_of_Romanian_Reddit_Posts.md)

    - [翻译: PoPreRo：一款专为预测罗马尼亚 Reddit 帖子热度而设计的新数据集](2024年07月05日/PoPreRo_A_New_Dataset_for_Popularity_Prediction_of_Romanian_Reddit_Posts.md)

- [Dude: Dual Distribution-Aware Context Prompt Learning For Large Vision-Language Model](2024年07月05日/Dude_Dual_Distribution-Aware_Context_Prompt_Learning_For_Large_Vision-Language_Model.md)

    - [翻译: Dude：一种双分布感知上下文提示学习方法，专为大型视觉-语言模型设计。](2024年07月05日/Dude_Dual_Distribution-Aware_Context_Prompt_Learning_For_Large_Vision-Language_Model.md)

- [Leveraging Graph Structures to Detect Hallucinations in Large Language Models](2024年07月05日/Leveraging_Graph_Structures_to_Detect_Hallucinations_in_Large_Language_Models.md)

    - [翻译: 借助图结构，我们能够精准检测大型语言模型中的幻觉现象。](2024年07月05日/Leveraging_Graph_Structures_to_Detect_Hallucinations_in_Large_Language_Models.md)

- [Controlling Whisper: Universal Acoustic Adversarial Attacks to Control Speech Foundation Models](2024年07月05日/Controlling_Whisper_Universal_Acoustic_Adversarial_Attacks_to_Control_Speech_Foundation_Models.md)

    - [翻译: 操控“耳语”：针对语音基础模型的通用声学对抗策略](2024年07月05日/Controlling_Whisper_Universal_Acoustic_Adversarial_Attacks_to_Control_Speech_Foundation_Models.md)

- [LoCo: Low-Bit Communication Adaptor for Large-scale Model Training](2024年07月05日/LoCo_Low-Bit_Communication_Adaptor_for_Large-scale_Model_Training.md)

    - [翻译: LoCo：专为大规模模型训练设计的低比特通信适配器](2024年07月05日/LoCo_Low-Bit_Communication_Adaptor_for_Large-scale_Model_Training.md)

- [Generalists vs. Specialists: Evaluating Large Language Models for Urdu](2024年07月05日/Generalists_vs._Specialists_Evaluating_Large_Language_Models_for_Urdu.md)

    - [翻译: 通用型与专家型：探究大型语言模型在乌尔都语领域的评估](2024年07月05日/Generalists_vs._Specialists_Evaluating_Large_Language_Models_for_Urdu.md)

- [XLSR-Transducer: Streaming ASR for Self-Supervised Pretrained Models](2024年07月05日/XLSR-Transducer_Streaming_ASR_for_Self-Supervised_Pretrained_Models.md)

    - [翻译: XLSR-Transducer：为自监督预训练模型设计的流式自动语音识别技术](2024年07月05日/XLSR-Transducer_Streaming_ASR_for_Self-Supervised_Pretrained_Models.md)

- [From 'Showgirls' to 'Performers': Fine-tuning with Gender-inclusive Language for Bias Reduction in LLMs](2024年07月05日/From_'Showgirls'_to_'Performers'_Fine-tuning_with_Gender-inclusive_Language_for_Bias_Reduction_in_LLMs.md)

    - [翻译: 从“Showgirls”到“Performers”：通过性别包容性语言的微调，减少 LLMs 中的偏见](2024年07月05日/From_'Showgirls'_to_'Performers'_Fine-tuning_with_Gender-inclusive_Language_for_Bias_Reduction_in_LLMs.md)

- [cosmosage: A Natural-Language Assistant for Cosmologists](2024年07月05日/cosmosage_A_Natural-Language_Assistant_for_Cosmologists.md)

    - [翻译: cosmosage：专为宇宙学家打造的自然语言助手](2024年07月05日/cosmosage_A_Natural-Language_Assistant_for_Cosmologists.md)

- [Improving Audio Generation with Visual Enhanced Caption](2024年07月05日/Improving_Audio_Generation_with_Visual_Enhanced_Caption.md)

    - [翻译: 利用视觉增强字幕提升音频生成效果](2024年07月05日/Improving_Audio_Generation_with_Visual_Enhanced_Caption.md)

- [Waterfall: Framework for Robust and Scalable Text Watermarking](2024年07月05日/Waterfall_Framework_for_Robust_and_Scalable_Text_Watermarking.md)

    - [翻译: Waterfall：一个专为文本水印设计的稳健且可扩展的框架](2024年07月05日/Waterfall_Framework_for_Robust_and_Scalable_Text_Watermarking.md)

- [Towards Context-aware Support for Color Vision Deficiency: An Approach Integrating LLM and AR](2024年07月05日/Towards_Context-aware_Support_for_Color_Vision_Deficiency_An_Approach_Integrating_LLM_and_AR.md)

    - [翻译: 探索色觉缺陷的上下文感知支持：融合 LLM 与 AR 的创新途径](2024年07月05日/Towards_Context-aware_Support_for_Color_Vision_Deficiency_An_Approach_Integrating_LLM_and_AR.md)

- [Crafting Large Language Models for Enhanced Interpretability](2024年07月05日/Crafting_Large_Language_Models_for_Enhanced_Interpretability.md)

    - [翻译: 精雕细琢，打造更具透明度的大型语言模型](2024年07月05日/Crafting_Large_Language_Models_for_Enhanced_Interpretability.md)

- [Jailbreak Attacks and Defenses Against Large Language Models: A Survey](2024年07月05日/Jailbreak_Attacks_and_Defenses_Against_Large_Language_Models_A_Survey.md)

    - [翻译: 大型语言模型面临的越狱攻击及其防御策略：全面调查](2024年07月05日/Jailbreak_Attacks_and_Defenses_Against_Large_Language_Models_A_Survey.md)

- [Corki: Enabling Real-time Embodied AI Robots via Algorithm-Architecture Co-Design](2024年07月05日/Corki_Enabling_Real-time_Embodied_AI_Robots_via_Algorithm-Architecture_Co-Design.md)

    - [翻译: Corki：借助算法与架构的协同设计，赋能实时具身AI机器人。](2024年07月05日/Corki_Enabling_Real-time_Embodied_AI_Robots_via_Algorithm-Architecture_Co-Design.md)

- [BiosERC: Integrating Biography Speakers Supported by LLMs for ERC Tasks](2024年07月05日/BiosERC_Integrating_Biography_Speakers_Supported_by_LLMs_for_ERC_Tasks.md)

    - [翻译: BiosERC：结合 LLM 辅助的传记演讲者，提升 ERC 任务表现](2024年07月05日/BiosERC_Integrating_Biography_Speakers_Supported_by_LLMs_for_ERC_Tasks.md)

- [MMSci: A Multimodal Multi-Discipline Dataset for PhD-Level Scientific Comprehension](2024年07月05日/MMSci_A_Multimodal_Multi-Discipline_Dataset_for_PhD-Level_Scientific_Comprehension.md)

    - [翻译: MMSci：专为博士级科学理解设计的多模态多学科数据集](2024年07月05日/MMSci_A_Multimodal_Multi-Discipline_Dataset_for_PhD-Level_Scientific_Comprehension.md)

- [MJ-Bench: Is Your Multimodal Reward Model Really a Good Judge for Text-to-Image Generation?](2024年07月05日/MJ-Bench_Is_Your_Multimodal_Reward_Model_Really_a_Good_Judge_for_Text-to-Image_Generation.md)

    - [翻译: MJ-Bench 质疑：你的多模态奖励模型在文本到图像生成领域是否真的称职？](2024年07月05日/MJ-Bench_Is_Your_Multimodal_Reward_Model_Really_a_Good_Judge_for_Text-to-Image_Generation.md)

- [RAMO: Retrieval-Augmented Generation for Enhancing MOOCs Recommendations](2024年07月05日/RAMO_Retrieval-Augmented_Generation_for_Enhancing_MOOCs_Recommendations.md)

    - [翻译: RAMO：通过检索增强生成技术，提升 MOOCs 推荐效果](2024年07月05日/RAMO_Retrieval-Augmented_Generation_for_Enhancing_MOOCs_Recommendations.md)

2024年07月04日

- [Meta-prompting Optimized Retrieval-augmented Generation](2024年07月04日/Meta-prompting_Optimized_Retrieval-augmented_Generation.md)

    - [翻译: 元提示优化检索增强生成技术](2024年07月04日/Meta-prompting_Optimized_Retrieval-augmented_Generation.md)

- [TongGu: Mastering Classical Chinese Understanding with Knowledge-Grounded Large Language Models](2024年07月04日/TongGu_Mastering_Classical_Chinese_Understanding_with_Knowledge-Grounded_Large_Language_Models.md)

    - [翻译: TongGu：借助知识驱动的大型语言模型，精通古典中文理解](2024年07月04日/TongGu_Mastering_Classical_Chinese_Understanding_with_Knowledge-Grounded_Large_Language_Models.md)

- [Automated C/C++ Program Repair for High-Level Synthesis via Large Language Models](2024年07月04日/Automated_CC++_Program_Repair_for_High-Level_Synthesis_via_Large_Language_Models.md)

    - [翻译: 利用大型语言模型实现 C/C++ 程序在高级综合中的自动化修复](2024年07月04日/Automated_CC++_Program_Repair_for_High-Level_Synthesis_via_Large_Language_Models.md)

- [Solving Zebra Puzzles Using Constraint-Guided Multi-Agent Systems](2024年07月04日/Solving_Zebra_Puzzles_Using_Constraint-Guided_Multi-Agent_Systems.md)

    - [翻译: 借助约束引导的多智能体系统，破解斑马谜题](2024年07月04日/Solving_Zebra_Puzzles_Using_Constraint-Guided_Multi-Agent_Systems.md)

- [MobileExperts: A Dynamic Tool-Enabled Agent Team in Mobile Devices](2024年07月04日/MobileExperts_A_Dynamic_Tool-Enabled_Agent_Team_in_Mobile_Devices.md)

    - [翻译: MobileExperts：移动设备中的动态工具化代理团队](2024年07月04日/MobileExperts_A_Dynamic_Tool-Enabled_Agent_Team_in_Mobile_Devices.md)

- [Planning with Large Language Models for Conversational Agents](2024年07月04日/Planning_with_Large_Language_Models_for_Conversational_Agents.md)

    - [翻译: 利用大型语言模型规划对话代理](2024年07月04日/Planning_with_Large_Language_Models_for_Conversational_Agents.md)

- [Over the Edge of Chaos? Excess Complexity as a Roadblock to Artificial General Intelligence](2024年07月04日/Over_the_Edge_of_Chaos_Excess_Complexity_as_a_Roadblock_to_Artificial_General_Intelligence.md)

    - [翻译: 超越混沌边缘？过度复杂性成为人工通用智能之路的绊脚石](2024年07月04日/Over_the_Edge_of_Chaos_Excess_Complexity_as_a_Roadblock_to_Artificial_General_Intelligence.md)

- [M$\mathbf5$ -- A Diverse Benchmark to Assess the Performance of Large Multimodal Models Across Multilingual and Multicultural Vision-Language Tasks](2024年07月04日/M$\mathbf5$_--_A_Diverse_Benchmark_to_Assess_the_Performance_of_Large_Multimodal_Models_Across_Multilingual_and_Multicultural_Vision-Language_Tasks.md)

    - [翻译: M$\mathbf5$ 是一个多元化基准，旨在全面评估大型多模态模型在跨语言和文化视觉-语言任务中的表现。](2024年07月04日/M$\mathbf5$_--_A_Diverse_Benchmark_to_Assess_the_Performance_of_Large_Multimodal_Models_Across_Multilingual_and_Multicultural_Vision-Language_Tasks.md)

- [MRIR: Integrating Multimodal Insights for Diffusion-based Realistic Image Restoration](2024年07月04日/MRIR_Integrating_Multimodal_Insights_for_Diffusion-based_Realistic_Image_Restoration.md)

    - [翻译: MRIR：融合多模态洞察，实现基于扩散技术的真实图像修复](2024年07月04日/MRIR_Integrating_Multimodal_Insights_for_Diffusion-based_Realistic_Image_Restoration.md)

- [Query-Guided Self-Supervised Summarization of Nursing Notes](2024年07月04日/Query-Guided_Self-Supervised_Summarization_of_Nursing_Notes.md)

    - [翻译: 护理笔记的自监督摘要，由查询引导](2024年07月04日/Query-Guided_Self-Supervised_Summarization_of_Nursing_Notes.md)

- [Hallucination Detection: Robustly Discerning Reliable Answers in Large Language Models](2024年07月04日/Hallucination_Detection_Robustly_Discerning_Reliable_Answers_in_Large_Language_Models.md)

    - [翻译: 幻觉检测：在大规模语言模型中，如何稳健地识别出可靠答案，是一项关键任务。](2024年07月04日/Hallucination_Detection_Robustly_Discerning_Reliable_Answers_in_Large_Language_Models.md)

- [MAPO: Boosting Large Language Model Performance with Model-Adaptive Prompt Optimization](2024年07月04日/MAPO_Boosting_Large_Language_Model_Performance_with_Model-Adaptive_Prompt_Optimization.md)

    - [翻译: MAPO 技术通过模型自适应提示优化，显著提升大型语言模型的性能。](2024年07月04日/MAPO_Boosting_Large_Language_Model_Performance_with_Model-Adaptive_Prompt_Optimization.md)

- [Future Events as Backdoor Triggers: Investigating Temporal Vulnerabilities in LLMs](2024年07月04日/Future_Events_as_Backdoor_Triggers_Investigating_Temporal_Vulnerabilities_in_LLMs.md)

    - [翻译: 未来事件可能成为 LLM 的后门触发器，本研究深入探讨这些模型中的时间脆弱性。](2024年07月04日/Future_Events_as_Backdoor_Triggers_Investigating_Temporal_Vulnerabilities_in_LLMs.md)

- [MiniGPT-Med: Large Language Model as a General Interface for Radiology Diagnosis](2024年07月04日/MiniGPT-Med_Large_Language_Model_as_a_General_Interface_for_Radiology_Diagnosis.md)

    - [翻译: MiniGPT-Med：将大型语言模型打造为放射学诊断的多面手](2024年07月04日/MiniGPT-Med_Large_Language_Model_as_a_General_Interface_for_Radiology_Diagnosis.md)

- [Stephanie: Step-by-Step Dialogues for Mimicking Human Interactions in Social Conversations](2024年07月04日/Stephanie_Step-by-Step_Dialogues_for_Mimicking_Human_Interactions_in_Social_Conversations.md)

    - [翻译: Stephanie：通过逐步对话，巧妙模仿社交场合中的人类互动](2024年07月04日/Stephanie_Step-by-Step_Dialogues_for_Mimicking_Human_Interactions_in_Social_Conversations.md)

- [DotaMath: Decomposition of Thought with Code Assistance and Self-correction for Mathematical Reasoning](2024年07月04日/DotaMath_Decomposition_of_Thought_with_Code_Assistance_and_Self-correction_for_Mathematical_Reasoning.md)

    - [翻译: DotaMath：借助代码辅助与自我修正，实现数学推理思维的精细分解](2024年07月04日/DotaMath_Decomposition_of_Thought_with_Code_Assistance_and_Self-correction_for_Mathematical_Reasoning.md)

- [A Systematic Survey and Critical Review on Evaluating Large Language Models: Challenges, Limitations, and Recommendations](2024年07月04日/A_Systematic_Survey_and_Critical_Review_on_Evaluating_Large_Language_Models_Challenges,_Limitations,_and_Recommendations.md)

    - [翻译: 本文系统探讨并批判性分析了评估大型语言模型的挑战与局限，并提出了相应建议。](2024年07月04日/A_Systematic_Survey_and_Critical_Review_on_Evaluating_Large_Language_Models_Challenges,_Limitations,_and_Recommendations.md)

- [Semantic Graphs for Syntactic Simplification: A Revisit from the Age of LLM](2024年07月04日/Semantic_Graphs_for_Syntactic_Simplification_A_Revisit_from_the_Age_of_LLM.md)

    - [翻译: 在 LLM 时代，语义图在句法简化中的应用值得重新审视。](2024年07月04日/Semantic_Graphs_for_Syntactic_Simplification_A_Revisit_from_the_Age_of_LLM.md)

- [On the Workflows and Smells of Leaderboard Operations (LBOps): An Exploratory Study of Foundation Model Leaderboards](2024年07月04日/On_the_Workflows_and_Smells_of_Leaderboard_Operations_(LBOps)_An_Exploratory_Study_of_Foundation_Model_Leaderboards.md)

    - [翻译: 探索基础模型排行榜中的操作流程与问题：排行榜操作 (LBOps) 的深入研究](2024年07月04日/On_the_Workflows_and_Smells_of_Leaderboard_Operations_(LBOps)_An_Exploratory_Study_of_Foundation_Model_Leaderboards.md)

- [FunAudioLLM: Voice Understanding and Generation Foundation Models for Natural Interaction Between Humans and LLMs](2024年07月04日/FunAudioLLM_Voice_Understanding_and_Generation_Foundation_Models_for_Natural_Interaction_Between_Humans_and_LLMs.md)

    - [翻译: FunAudioLLM：助力人机自然对话的语音理解与生成基础模型](2024年07月04日/FunAudioLLM_Voice_Understanding_and_Generation_Foundation_Models_for_Natural_Interaction_Between_Humans_and_LLMs.md)

- [Improving Accented Speech Recognition using Data Augmentation based on Unsupervised Text-to-Speech Synthesis](2024年07月04日/Improving_Accented_Speech_Recognition_using_Data_Augmentation_based_on_Unsupervised_Text-to-Speech_Synthesis.md)

    - [翻译: 利用无监督的文本转语音合成进行数据增强，提升带口音语音的识别效果](2024年07月04日/Improving_Accented_Speech_Recognition_using_Data_Augmentation_based_on_Unsupervised_Text-to-Speech_Synthesis.md)

- [Systematic Task Exploration with LLMs: A Study in Citation Text Generation](2024年07月04日/Systematic_Task_Exploration_with_LLMs_A_Study_in_Citation_Text_Generation.md)

    - [翻译: 大型语言模型在系统性任务探索中的应用：引文文本生成研究](2024年07月04日/Systematic_Task_Exploration_with_LLMs_A_Study_in_Citation_Text_Generation.md)

- [LLMAEL: Large Language Models are Good Context Augmenters for Entity Linking](2024年07月04日/LLMAEL_Large_Language_Models_are_Good_Context_Augmenters_for_Entity_Linking.md)

    - [翻译: LLMAEL：大型语言模型在实体链接中扮演着优秀的上下文增强角色。](2024年07月04日/LLMAEL_Large_Language_Models_are_Good_Context_Augmenters_for_Entity_Linking.md)

- [Offline Energy-Optimal LLM Serving: Workload-Based Energy Models for LLM Inference on Heterogeneous Systems](2024年07月04日/Offline_Energy-Optimal_LLM_Serving_Workload-Based_Energy_Models_for_LLM_Inference_on_Heterogeneous_Systems.md)

    - [翻译: 离线模式下，LLM 服务追求能量最优：针对异构系统中 LLM 推理，我们构建了基于工作负载的能量模型。](2024年07月04日/Offline_Energy-Optimal_LLM_Serving_Workload-Based_Energy_Models_for_LLM_Inference_on_Heterogeneous_Systems.md)

- [Unlocking the Potential of Model Merging for Low-Resource Languages](2024年07月04日/Unlocking_the_Potential_of_Model_Merging_for_Low-Resource_Languages.md)

    - [翻译: 探索模型合并技术在低资源语言中的应用潜力](2024年07月04日/Unlocking_the_Potential_of_Model_Merging_for_Low-Resource_Languages.md)

- [A Survey on Natural Language Counterfactual Generation](2024年07月04日/A_Survey_on_Natural_Language_Counterfactual_Generation.md)

    - [翻译: 自然语言反事实生成研究综述](2024年07月04日/A_Survey_on_Natural_Language_Counterfactual_Generation.md)

- [Benchmarking Complex Instruction-Following with Multiple Constraints Composition](2024年07月04日/Benchmarking_Complex_Instruction-Following_with_Multiple_Constraints_Composition.md)

    - [翻译: 复杂指令遵循与多重约束组合的基准测试](2024年07月04日/Benchmarking_Complex_Instruction-Following_with_Multiple_Constraints_Composition.md)

- [LLM Roleplay: Simulating Human-Chatbot Interaction](2024年07月04日/LLM_Roleplay_Simulating_Human-Chatbot_Interaction.md)

    - [翻译: LLM 角色扮演：模拟人与聊天机器人的互动](2024年07月04日/LLM_Roleplay_Simulating_Human-Chatbot_Interaction.md)

- [Improving Sample Efficiency of Reinforcement Learning with Background Knowledge from Large Language Models](2024年07月04日/Improving_Sample_Efficiency_of_Reinforcement_Learning_with_Background_Knowledge_from_Large_Language_Models.md)

    - [翻译: 借助大型语言模型的背景知识，我们致力于提升强化学习的样本效率。](2024年07月04日/Improving_Sample_Efficiency_of_Reinforcement_Learning_with_Background_Knowledge_from_Large_Language_Models.md)

- [LLM-jp: A Cross-organizational Project for the Research and Development of Fully Open Japanese LLMs](2024年07月04日/LLM-jp_A_Cross-organizational_Project_for_the_Research_and_Development_of_Fully_Open_Japanese_LLMs.md)

    - [翻译: LLM-jp 项目旨在跨组织合作，推动完全开放的日本大型语言模型的研究与开发。](2024年07月04日/LLM-jp_A_Cross-organizational_Project_for_the_Research_and_Development_of_Fully_Open_Japanese_LLMs.md)

- [A framework for annotating and modelling intentions behind metaphor use](2024年07月04日/A_framework_for_annotating_and_modelling_intentions_behind_metaphor_use.md)

    - [翻译: 构建一个框架，旨在注释并建模隐喻使用背后的意图。](2024年07月04日/A_framework_for_annotating_and_modelling_intentions_behind_metaphor_use.md)

- [Uncertainty-Guided Optimization on Large Language Model Search Trees](2024年07月04日/Uncertainty-Guided_Optimization_on_Large_Language_Model_Search_Trees.md)

    - [翻译: 基于不确定性的优化策略在大规模语言模型搜索树上的应用](2024年07月04日/Uncertainty-Guided_Optimization_on_Large_Language_Model_Search_Trees.md)

- [Diverse and Fine-Grained Instruction-Following Ability Exploration with Synthetic Data](2024年07月04日/Diverse_and_Fine-Grained_Instruction-Following_Ability_Exploration_with_Synthetic_Data.md)

    - [翻译: 通过合成数据探索多样且精细的指令遵循能力](2024年07月04日/Diverse_and_Fine-Grained_Instruction-Following_Ability_Exploration_with_Synthetic_Data.md)

- [Narrow Transformer: Starcoder-Based Java-LM For Desktop](2024年07月04日/Narrow_Transformer_Starcoder-Based_Java-LM_For_Desktop.md)

    - [翻译: 精简版 Transformer：基于 Starcoder 的 Java 语言模型，专为桌面设计](2024年07月04日/Narrow_Transformer_Starcoder-Based_Java-LM_For_Desktop.md)

- [Concept Bottleneck Models Without Predefined Concepts](2024年07月04日/Concept_Bottleneck_Models_Without_Predefined_Concepts.md)

    - [翻译: 无需预设概念的概念瓶颈模型](2024年07月04日/Concept_Bottleneck_Models_Without_Predefined_Concepts.md)

- [AutoBench: Automatic Testbench Generation and Evaluation Using LLMs for HDL Design](2024年07月04日/AutoBench_Automatic_Testbench_Generation_and_Evaluation_Using_LLMs_for_HDL_Design.md)

    - [翻译: AutoBench：借助 LLM 实现 HDL 设计的自动化测试台生成与评估](2024年07月04日/AutoBench_Automatic_Testbench_Generation_and_Evaluation_Using_LLMs_for_HDL_Design.md)

- [DART: Deep Adversarial Automated Red Teaming for LLM Safety](2024年07月04日/DART_Deep_Adversarial_Automated_Red_Teaming_for_LLM_Safety.md)

    - [翻译: DART：深度对抗技术助力 LLM 安全，实现自动红队测试](2024年07月04日/DART_Deep_Adversarial_Automated_Red_Teaming_for_LLM_Safety.md)

- [Anthropocentric bias and the possibility of artificial cognition](2024年07月04日/Anthropocentric_bias_and_the_possibility_of_artificial_cognition.md)

    - [翻译: 探讨人类中心主义偏见与人工认知的潜在可能](2024年07月04日/Anthropocentric_bias_and_the_possibility_of_artificial_cognition.md)

- [Q-Adapter: Training Your LLM Adapter as a Residual Q-Function](2024年07月04日/Q-Adapter_Training_Your_LLM_Adapter_as_a_Residual_Q-Function.md)

    - [翻译: Q-Adapter：训练 LLM Adapter 成为残差 Q-Function](2024年07月04日/Q-Adapter_Training_Your_LLM_Adapter_as_a_Residual_Q-Function.md)

- [HYBRINFOX at CheckThat! 2024 -- Task 1: Enhancing Language Models with Structured Information for Check-Worthiness Estimation](2024年07月04日/HYBRINFOX_at_CheckThat!_2024_--_Task_1_Enhancing_Language_Models_with_Structured_Information_for_Check-Worthiness_Estimation.md)

    - [翻译: HYBRINFOX 在 CheckThat! 2024 的任务 1 中，旨在通过整合结构化信息来提升语言模型的可核查性估计能力。](2024年07月04日/HYBRINFOX_at_CheckThat!_2024_--_Task_1_Enhancing_Language_Models_with_Structured_Information_for_Check-Worthiness_Estimation.md)

- [On the Benchmarking of LLMs for Open-Domain Dialogue Evaluation](2024年07月04日/On_the_Benchmarking_of_LLMs_for_Open-Domain_Dialogue_Evaluation.md)

    - [翻译: 大型语言模型在开放域对话评估中的基准测试研究](2024年07月04日/On_the_Benchmarking_of_LLMs_for_Open-Domain_Dialogue_Evaluation.md)

- [Cognitive Modeling with Scaffolded LLMs: A Case Study of Referential Expression Generation](2024年07月04日/Cognitive_Modeling_with_Scaffolded_LLMs_A_Case_Study_of_Referential_Expression_Generation.md)

    - [翻译: 基于脚手架的大型语言模型在认知建模中的应用：指代表达生成研究案例](2024年07月04日/Cognitive_Modeling_with_Scaffolded_LLMs_A_Case_Study_of_Referential_Expression_Generation.md)

- [Assessing Consensus of Developers' Views on Code Readability](2024年07月04日/Assessing_Consensus_of_Developers'_Views_on_Code_Readability.md)

    - [翻译: 探究开发者对代码可读性共识的评估](2024年07月04日/Assessing_Consensus_of_Developers'_Views_on_Code_Readability.md)

- [Meta-optimized Angular Margin Contrastive Framework for Video-Language Representation Learning](2024年07月04日/Meta-optimized_Angular_Margin_Contrastive_Framework_for_Video-Language_Representation_Learning.md)

    - [翻译: 视频-语言表示学习的元优化角度边缘对比框架](2024年07月04日/Meta-optimized_Angular_Margin_Contrastive_Framework_for_Video-Language_Representation_Learning.md)

- [From Data to Commonsense Reasoning: The Use of Large Language Models for Explainable AI](2024年07月04日/From_Data_to_Commonsense_Reasoning_The_Use_of_Large_Language_Models_for_Explainable_AI.md)

    - [翻译: 大型语言模型助力 AI 从数据解读到常识推理，为可解释 AI 开辟新径。](2024年07月04日/From_Data_to_Commonsense_Reasoning_The_Use_of_Large_Language_Models_for_Explainable_AI.md)

- [Convolutional vs Large Language Models for Software Log Classification in Edge-Deployable Cellular Network Testing](2024年07月04日/Convolutional_vs_Large_Language_Models_for_Software_Log_Classification_in_Edge-Deployable_Cellular_Network_Testing.md)

    - [翻译: 边缘部署蜂窝网络测试中，卷积神经网络与大型语言模型在软件日志分类上的较量](2024年07月04日/Convolutional_vs_Large_Language_Models_for_Software_Log_Classification_in_Edge-Deployable_Cellular_Network_Testing.md)

- [Argument Mining in Data Scarce Settings: Cross-lingual Transfer and Few-shot Techniques](2024年07月04日/Argument_Mining_in_Data_Scarce_Settings_Cross-lingual_Transfer_and_Few-shot_Techniques.md)

    - [翻译: 在数据稀缺的情境下，论证挖掘借助跨语言迁移和少量样本技术，探索新的可能性。](2024年07月04日/Argument_Mining_in_Data_Scarce_Settings_Cross-lingual_Transfer_and_Few-shot_Techniques.md)

- [Text2TimeSeries: Enhancing Financial Forecasting through Time Series Prediction Updates with Event-Driven Insights from Large Language Models](2024年07月04日/Text2TimeSeries_Enhancing_Financial_Forecasting_through_Time_Series_Prediction_Updates_with_Event-Driven_Insights_from_Large_Language_Models.md)

    - [翻译: Text2TimeSeries：借助大型语言模型的事件驱动洞察，实时更新时间序列预测，助力财务预测更精准。](2024年07月04日/Text2TimeSeries_Enhancing_Financial_Forecasting_through_Time_Series_Prediction_Updates_with_Event-Driven_Insights_from_Large_Language_Models.md)

- [STOC-TOT: Stochastic Tree-of-Thought with Constrained Decoding for Complex Reasoning in Multi-Hop Question Answering](2024年07月04日/STOC-TOT_Stochastic_Tree-of-Thought_with_Constrained_Decoding_for_Complex_Reasoning_in_Multi-Hop_Question_Answering.md)

    - [翻译: STOC-TOT：一种结合约束解码的随机思维树方法，专为多跳问答中的复杂推理设计。](2024年07月04日/STOC-TOT_Stochastic_Tree-of-Thought_with_Constrained_Decoding_for_Complex_Reasoning_in_Multi-Hop_Question_Answering.md)

- [Improving Self Consistency in LLMs through Probabilistic Tokenization](2024年07月04日/Improving_Self_Consistency_in_LLMs_through_Probabilistic_Tokenization.md)

    - [翻译: 借助概率标记化技术，提升大型语言模型中的自我一致性](2024年07月04日/Improving_Self_Consistency_in_LLMs_through_Probabilistic_Tokenization.md)

- [GPT-4 vs. Human Translators: A Comprehensive Evaluation of Translation Quality Across Languages, Domains, and Expertise Levels](2024年07月04日/GPT-4_vs._Human_Translators_A_Comprehensive_Evaluation_of_Translation_Quality_Across_Languages,_Domains,_and_Expertise_Levels.md)

    - [翻译: GPT-4 与人类翻译者的较量：全面评估翻译质量在多语言、多领域及不同专业水平的表现](2024年07月04日/GPT-4_vs._Human_Translators_A_Comprehensive_Evaluation_of_Translation_Quality_Across_Languages,_Domains,_and_Expertise_Levels.md)

- [WildDESED: An LLM-Powered Dataset for Wild Domestic Environment Sound Event Detection System](2024年07月04日/WildDESED_An_LLM-Powered_Dataset_for_Wild_Domestic_Environment_Sound_Event_Detection_System.md)

    - [翻译: WildDESED：一款由 LLM 赋能的数据集，专为家庭环境中的声音事件检测系统设计。](2024年07月04日/WildDESED_An_LLM-Powered_Dataset_for_Wild_Domestic_Environment_Sound_Event_Detection_System.md)

- [An Interactive Multi-modal Query Answering System with Retrieval-Augmented Large Language Models](2024年07月04日/An_Interactive_Multi-modal_Query_Answering_System_with_Retrieval-Augmented_Large_Language_Models.md)

    - [翻译: 交互式多模态查询应答系统，搭载检索增强型大型语言模型](2024年07月04日/An_Interactive_Multi-modal_Query_Answering_System_with_Retrieval-Augmented_Large_Language_Models.md)

- [DSLR: Document Refinement with Sentence-Level Re-ranking and Reconstruction to Enhance Retrieval-Augmented Generation](2024年07月04日/DSLR_Document_Refinement_with_Sentence-Level_Re-ranking_and_Reconstruction_to_Enhance_Retrieval-Augmented_Generation.md)

    - [翻译: DSLR 技术通过句子级重排序与重建，优化文档，从而提升检索增强生成的质量。](2024年07月04日/DSLR_Document_Refinement_with_Sentence-Level_Re-ranking_and_Reconstruction_to_Enhance_Retrieval-Augmented_Generation.md)

- [Slice-100K: A Multimodal Dataset for Extrusion-based 3D Printing](2024年07月04日/Slice-100K_A_Multimodal_Dataset_for_Extrusion-based_3D_Printing.md)

    - [翻译: Slice-100K：一款专为挤出式3D打印设计的多模态数据集](2024年07月04日/Slice-100K_A_Multimodal_Dataset_for_Extrusion-based_3D_Printing.md)

- [Semi-supervised Learning for Code-Switching ASR with Large Language Model Filter](2024年07月04日/Semi-supervised_Learning_for_Code-Switching_ASR_with_Large_Language_Model_Filter.md)

    - [翻译: 半监督学习助力代码转换ASR，结合大型语言模型过滤器](2024年07月04日/Semi-supervised_Learning_for_Code-Switching_ASR_with_Large_Language_Model_Filter.md)

- [HAF-RM: A Hybrid Alignment Framework for Reward Model Training](2024年07月04日/HAF-RM_A_Hybrid_Alignment_Framework_for_Reward_Model_Training.md)

    - [翻译: HAF-RM：奖励模型训练的混合对齐新框架](2024年07月04日/HAF-RM_A_Hybrid_Alignment_Framework_for_Reward_Model_Training.md)

- [Seeing Like an AI: How LLMs Apply (and Misapply) Wikipedia Neutrality Norms](2024年07月04日/Seeing_Like_an_AI_How_LLMs_Apply_(and_Misapply)_Wikipedia_Neutrality_Norms.md)

    - [翻译: 窥探AI视角：LLMs在应用维基百科中立性规范时的得与失](2024年07月04日/Seeing_Like_an_AI_How_LLMs_Apply_(and_Misapply)_Wikipedia_Neutrality_Norms.md)

- [Orchestrating LLMs with Different Personalizations](2024年07月04日/Orchestrating_LLMs_with_Different_Personalizations.md)

    - [翻译: 个性化调配大型语言模型](2024年07月04日/Orchestrating_LLMs_with_Different_Personalizations.md)

- [Defense Against Syntactic Textual Backdoor Attacks with Token Substitution](2024年07月04日/Defense_Against_Syntactic_Textual_Backdoor_Attacks_with_Token_Substitution.md)

    - [翻译: 防御通过标记替换实施的句法文本后门攻击](2024年07月04日/Defense_Against_Syntactic_Textual_Backdoor_Attacks_with_Token_Substitution.md)

- [Quantifying Prediction Consistency Under Model Multiplicity in Tabular LLMs](2024年07月04日/Quantifying_Prediction_Consistency_Under_Model_Multiplicity_in_Tabular_LLMs.md)

    - [翻译: 探究表格型LLM在模型多样性下的预测一致性](2024年07月04日/Quantifying_Prediction_Consistency_Under_Model_Multiplicity_in_Tabular_LLMs.md)

- [VoxAct-B: Voxel-Based Acting and Stabilizing Policy for Bimanual Manipulation](2024年07月04日/VoxAct-B_Voxel-Based_Acting_and_Stabilizing_Policy_for_Bimanual_Manipulation.md)

    - [翻译: VoxAct-B：一种基于体素的双臂操作动作与稳定策略](2024年07月04日/VoxAct-B_Voxel-Based_Acting_and_Stabilizing_Policy_for_Bimanual_Manipulation.md)

- [Securing Multi-turn Conversational Language Models Against Distributed Backdoor Triggers](2024年07月04日/Securing_Multi-turn_Conversational_Language_Models_Against_Distributed_Backdoor_Triggers.md)

    - [翻译: 强化多轮对话语言模型，抵御分布式后门触发威胁](2024年07月04日/Securing_Multi-turn_Conversational_Language_Models_Against_Distributed_Backdoor_Triggers.md)

- [A Survey of Controllable Learning: Methods and Applications in Information Retrieval](2024年07月04日/A_Survey_of_Controllable_Learning_Methods_and_Applications_in_Information_Retrieval.md)

    - [翻译: 探索可控学习：揭秘信息检索领域的技术与应用](2024年07月04日/A_Survey_of_Controllable_Learning_Methods_and_Applications_in_Information_Retrieval.md)

2024年07月03日

- [Cactus: Towards Psychological Counseling Conversations using Cognitive Behavioral Theory](2024年07月03日/Cactus_Towards_Psychological_Counseling_Conversations_using_Cognitive_Behavioral_Theory.md)

    - [翻译: Cactus：借助认知行为理论，迈向心理咨询对话的新领域](2024年07月03日/Cactus_Towards_Psychological_Counseling_Conversations_using_Cognitive_Behavioral_Theory.md)

- [Vision-driven Automated Mobile GUI Testing via Multimodal Large Language Model](2024年07月03日/Vision-driven_Automated_Mobile_GUI_Testing_via_Multimodal_Large_Language_Model.md)

    - [翻译: 利用多模态大型语言模型实现视觉驱动的移动GUI自动化测试](2024年07月03日/Vision-driven_Automated_Mobile_GUI_Testing_via_Multimodal_Large_Language_Model.md)

- [VIVA: A Benchmark for Vision-Grounded Decision-Making with Human Values](2024年07月03日/VIVA_A_Benchmark_for_Vision-Grounded_Decision-Making_with_Human_Values.md)

    - [翻译: VIVA：一个结合视觉与人类价值观的决策制定基准](2024年07月03日/VIVA_A_Benchmark_for_Vision-Grounded_Decision-Making_with_Human_Values.md)

- [MedPix 2.0: A Comprehensive Multimodal Biomedical Dataset for Advanced AI Applications](2024年07月03日/MedPix_2.0_A_Comprehensive_Multimodal_Biomedical_Dataset_for_Advanced_AI_Applications.md)

    - [翻译: MedPix 2.0：一款集大成的多模态生物医学数据集，专为尖端AI应用打造](2024年07月03日/MedPix_2.0_A_Comprehensive_Multimodal_Biomedical_Dataset_for_Advanced_AI_Applications.md)

- [MindBench: A Comprehensive Benchmark for Mind Map Structure Recognition and Analysis](2024年07月03日/MindBench_A_Comprehensive_Benchmark_for_Mind_Map_Structure_Recognition_and_Analysis.md)

    - [翻译: MindBench：全面评估思维导图结构识别与分析的基准](2024年07月03日/MindBench_A_Comprehensive_Benchmark_for_Mind_Map_Structure_Recognition_and_Analysis.md)

- [Improving Retrieval-augmented Text-to-SQL with AST-based Ranking and Schema Pruning](2024年07月03日/Improving_Retrieval-augmented_Text-to-SQL_with_AST-based_Ranking_and_Schema_Pruning.md)

    - [翻译: 通过结合基于抽象语法树的排序和模式剪枝技术，提升检索增强型文本到SQL的转换效率。](2024年07月03日/Improving_Retrieval-augmented_Text-to-SQL_with_AST-based_Ranking_and_Schema_Pruning.md)

- [How Does Quantization Affect Multilingual LLMs?](2024年07月03日/How_Does_Quantization_Affect_Multilingual_LLMs.md)

    - [翻译: 量化对多语言LLM的影响如何？](2024年07月03日/How_Does_Quantization_Affect_Multilingual_LLMs.md)

- [TheoremLlama: Transforming General-Purpose LLMs into Lean4 Experts](2024年07月03日/TheoremLlama_Transforming_General-Purpose_LLMs_into_Lean4_Experts.md)

    - [翻译: TheoremLlama：让通用 LLM 成为 Lean4 领域的专家](2024年07月03日/TheoremLlama_Transforming_General-Purpose_LLMs_into_Lean4_Experts.md)

- [Fine-Tuning with Divergent Chains of Thought Boosts Reasoning Through Self-Correction in Language Models](2024年07月03日/Fine-Tuning_with_Divergent_Chains_of_Thought_Boosts_Reasoning_Through_Self-Correction_in_Language_Models.md)

    - [翻译: 采用多样化的思维链进行微调，能显著提升语言模型通过自我纠错机制进行推理的能力。](2024年07月03日/Fine-Tuning_with_Divergent_Chains_of_Thought_Boosts_Reasoning_Through_Self-Correction_in_Language_Models.md)

- [Investigating Decoder-only Large Language Models for Speech-to-text Translation](2024年07月03日/Investigating_Decoder-only_Large_Language_Models_for_Speech-to-text_Translation.md)

    - [翻译: 探索仅解码器大型语言模型在语音转文本翻译中的应用](2024年07月03日/Investigating_Decoder-only_Large_Language_Models_for_Speech-to-text_Translation.md)

- [SOS! Soft Prompt Attack Against Open-Source Large Language Models](2024年07月03日/SOS!_Soft_Prompt_Attack_Against_Open-Source_Large_Language_Models.md)

    - [翻译: 紧急呼叫！针对开源大型语言模型的软提示攻击](2024年07月03日/SOS!_Soft_Prompt_Attack_Against_Open-Source_Large_Language_Models.md)

- [Let the Code LLM Edit Itself When You Edit the Code](2024年07月03日/Let_the_Code_LLM_Edit_Itself_When_You_Edit_the_Code.md)

    - [翻译: 代码 LLM 在你修改代码时，也能自我修正。](2024年07月03日/Let_the_Code_LLM_Edit_Itself_When_You_Edit_the_Code.md)

- [Reinforcement Learning for Sequence Design Leveraging Protein Language Models](2024年07月03日/Reinforcement_Learning_for_Sequence_Design_Leveraging_Protein_Language_Models.md)

    - [翻译: 借助蛋白质语言模型，强化学习在序列设计领域大放异彩。](2024年07月03日/Reinforcement_Learning_for_Sequence_Design_Leveraging_Protein_Language_Models.md)

- [Enhancing Translation Accuracy of Large Language Models through Continual Pre-Training on Parallel Data](2024年07月03日/Enhancing_Translation_Accuracy_of_Large_Language_Models_through_Continual_Pre-Training_on_Parallel_Data.md)

    - [翻译: 借助平行数据的持续预训练，我们能够显著提升大型语言模型的翻译精准度。](2024年07月03日/Enhancing_Translation_Accuracy_of_Large_Language_Models_through_Continual_Pre-Training_on_Parallel_Data.md)

- [Social Bias Evaluation for Large Language Models Requires Prompt Variations](2024年07月03日/Social_Bias_Evaluation_for_Large_Language_Models_Requires_Prompt_Variations.md)

    - [翻译: 评估大型语言模型的社会偏见，需借助多样化的提示手段。](2024年07月03日/Social_Bias_Evaluation_for_Large_Language_Models_Requires_Prompt_Variations.md)

- [KeyVideoLLM: Towards Large-scale Video Keyframe Selection](2024年07月03日/KeyVideoLLM_Towards_Large-scale_Video_Keyframe_Selection.md)

    - [翻译: KeyVideoLLM：探索大规模视频关键帧的精选之道](2024年07月03日/KeyVideoLLM_Towards_Large-scale_Video_Keyframe_Selection.md)

- [ScreenTK: Seamless Detection of Time-Killing Moments Using Continuous Mobile Screen Text Monitoring](2024年07月03日/ScreenTK_Seamless_Detection_of_Time-Killing_Moments_Using_Continuous_Mobile_Screen_Text_Monitoring.md)

    - [翻译: ScreenTK：通过持续监控移动屏幕文本，精准捕捉消磨时光的瞬间](2024年07月03日/ScreenTK_Seamless_Detection_of_Time-Killing_Moments_Using_Continuous_Mobile_Screen_Text_Monitoring.md)

- [ALTER: Augmentation for Large-Table-Based Reasoning](2024年07月03日/ALTER_Augmentation_for_Large-Table-Based_Reasoning.md)

    - [翻译: ALTER：大型表格推理的增强方案](2024年07月03日/ALTER_Augmentation_for_Large-Table-Based_Reasoning.md)

- [Improving Conversational Abilities of Quantized Large Language Models via Direct Preference Alignment](2024年07月03日/Improving_Conversational_Abilities_of_Quantized_Large_Language_Models_via_Direct_Preference_Alignment.md)

    - [翻译: 借助直接偏好对齐，我们致力于提升量化大型语言模型在对话中的表现。](2024年07月03日/Improving_Conversational_Abilities_of_Quantized_Large_Language_Models_via_Direct_Preference_Alignment.md)

- [JailbreakHunter: A Visual Analytics Approach for Jailbreak Prompts Discovery from Large-Scale Human-LLM Conversational Datasets](2024年07月03日/JailbreakHunter_A_Visual_Analytics_Approach_for_Jailbreak_Prompts_Discovery_from_Large-Scale_Human-LLM_Conversational_Datasets.md)

    - [翻译: JailbreakHunter：一种视觉分析方法，旨在从大规模人类与 LLM 的对话数据集中发现越狱提示。](2024年07月03日/JailbreakHunter_A_Visual_Analytics_Approach_for_Jailbreak_Prompts_Discovery_from_Large-Scale_Human-LLM_Conversational_Datasets.md)

- [Raw Text is All you Need: Knowledge-intensive Multi-turn Instruction Tuning for Large Language Model](2024年07月03日/Raw_Text_is_All_you_Need_Knowledge-intensive_Multi-turn_Instruction_Tuning_for_Large_Language_Model.md)

    - [翻译: 仅需原始文本：为大型语言模型进行知识密集型多轮指令调优](2024年07月03日/Raw_Text_is_All_you_Need_Knowledge-intensive_Multi-turn_Instruction_Tuning_for_Large_Language_Model.md)

- [On the Client Preference of LLM Fine-tuning in Federated Learning](2024年07月03日/On_the_Client_Preference_of_LLM_Fine-tuning_in_Federated_Learning.md)

    - [翻译: 探讨联邦学习环境下，客户端对 LLM 微调的偏好](2024年07月03日/On_the_Client_Preference_of_LLM_Fine-tuning_in_Federated_Learning.md)

- [SAFT: Towards Out-of-Distribution Generalization in Fine-Tuning](2024年07月03日/SAFT_Towards_Out-of-Distribution_Generalization_in_Fine-Tuning.md)

    - [翻译: SAFT：致力于在微调过程中实现分布外的泛化能力](2024年07月03日/SAFT_Towards_Out-of-Distribution_Generalization_in_Fine-Tuning.md)

- [Align and Aggregate: Compositional Reasoning with Video Alignment and Answer Aggregation for Video Question-Answering](2024年07月03日/Align_and_Aggregate_Compositional_Reasoning_with_Video_Alignment_and_Answer_Aggregation_for_Video_Question-Answering.md)

    - [翻译: 通过视频对齐与答案聚合，实现组合推理，提升视频问答的准确性。](2024年07月03日/Align_and_Aggregate_Compositional_Reasoning_with_Video_Alignment_and_Answer_Aggregation_for_Video_Question-Answering.md)

- [What Affects the Stability of Tool Learning? An Empirical Study on the Robustness of Tool Learning Frameworks](2024年07月03日/What_Affects_the_Stability_of_Tool_Learning_An_Empirical_Study_on_the_Robustness_of_Tool_Learning_Frameworks.md)

    - [翻译: 工具学习的稳定性受何影响？本研究深入探讨了工具学习框架的鲁棒性。](2024年07月03日/What_Affects_the_Stability_of_Tool_Learning_An_Empirical_Study_on_the_Robustness_of_Tool_Learning_Frameworks.md)

- [SemioLLM: Assessing Large Language Models for Semiological Analysis in Epilepsy Research](2024年07月03日/SemioLLM_Assessing_Large_Language_Models_for_Semiological_Analysis_in_Epilepsy_Research.md)

    - [翻译: SemioLLM：探究大型语言模型在癫痫研究符号学分析中的应用潜力](2024年07月03日/SemioLLM_Assessing_Large_Language_Models_for_Semiological_Analysis_in_Epilepsy_Research.md)

- [Are Large Language Models Consistent over Value-laden Questions?](2024年07月03日/Are_Large_Language_Models_Consistent_over_Value-laden_Questions.md)

    - [翻译: 大型语言模型在处理价值导向问题时，其一致性如何？](2024年07月03日/Are_Large_Language_Models_Consistent_over_Value-laden_Questions.md)

- [Scientific Text Analysis with Robots applied to observatory proposals](2024年07月03日/Scientific_Text_Analysis_with_Robots_applied_to_observatory_proposals.md)

    - [翻译: 机器人辅助的科学文本分析在观测站提案中的应用](2024年07月03日/Scientific_Text_Analysis_with_Robots_applied_to_observatory_proposals.md)

- [LoRA-Guard: Parameter-Efficient Guardrail Adaptation for Content Moderation of Large Language Models](2024年07月03日/LoRA-Guard_Parameter-Efficient_Guardrail_Adaptation_for_Content_Moderation_of_Large_Language_Models.md)

    - [翻译: LoRA-Guard：为大型语言模型提供参数高效的内容审核护栏适应方案](2024年07月03日/LoRA-Guard_Parameter-Efficient_Guardrail_Adaptation_for_Content_Moderation_of_Large_Language_Models.md)

- [Mast Kalandar at SemEval-2024 Task 8: On the Trail of Textual Origins: RoBERTa-BiLSTM Approach to Detect AI-Generated Text](2024年07月03日/Mast_Kalandar_at_SemEval-2024_Task_8_On_the_Trail_of_Textual_Origins_RoBERTa-BiLSTM_Approach_to_Detect_AI-Generated_Text.md)

    - [翻译: Mast Kalandar 参与 SemEval-2024 任务 8，探索文本源头：采用 RoBERTa-BiLSTM 方法，精准识别 AI 生成文本。](2024年07月03日/Mast_Kalandar_at_SemEval-2024_Task_8_On_the_Trail_of_Textual_Origins_RoBERTa-BiLSTM_Approach_to_Detect_AI-Generated_Text.md)

- [Large Language Models as Evaluators for Scientific Synthesis](2024年07月03日/Large_Language_Models_as_Evaluators_for_Scientific_Synthesis.md)

    - [翻译: 大型语言模型：科学综合的评判者](2024年07月03日/Large_Language_Models_as_Evaluators_for_Scientific_Synthesis.md)

- [FSM: A Finite State Machine Based Zero-Shot Prompting Paradigm for Multi-Hop Question Answering](2024年07月03日/FSM_A_Finite_State_Machine_Based_Zero-Shot_Prompting_Paradigm_for_Multi-Hop_Question_Answering.md)

    - [翻译: FSM：一种基于有限状态机的零-shot 提示方法，专为多跳问题回答设计](2024年07月03日/FSM_A_Finite_State_Machine_Based_Zero-Shot_Prompting_Paradigm_for_Multi-Hop_Question_Answering.md)

- [GraCoRe: Benchmarking Graph Comprehension and Complex Reasoning in Large Language Models](2024年07月03日/GraCoRe_Benchmarking_Graph_Comprehension_and_Complex_Reasoning_in_Large_Language_Models.md)

    - [翻译: GraCoRe：评估大型语言模型中的图表理解和复杂推理能力](2024年07月03日/GraCoRe_Benchmarking_Graph_Comprehension_and_Complex_Reasoning_in_Large_Language_Models.md)

- [GPTQT: Quantize Large Language Models Twice to Push the Efficiency](2024年07月03日/GPTQT_Quantize_Large_Language_Models_Twice_to_Push_the_Efficiency.md)

    - [翻译: GPTQT：通过两次量化大型语言模型，推动效率提升](2024年07月03日/GPTQT_Quantize_Large_Language_Models_Twice_to_Push_the_Efficiency.md)

- [CogErgLLM: Exploring Large Language Model Systems Design Perspective Using Cognitive Ergonomics](2024年07月03日/CogErgLLM_Exploring_Large_Language_Model_Systems_Design_Perspective_Using_Cognitive_Ergonomics.md)

    - [翻译: CogErgLLM：从认知工效学角度探究大型语言模型的系统设计](2024年07月03日/CogErgLLM_Exploring_Large_Language_Model_Systems_Design_Perspective_Using_Cognitive_Ergonomics.md)

- [LANE: Logic Alignment of Non-tuning Large Language Models and Online Recommendation Systems for Explainable Reason Generation](2024年07月03日/LANE_Logic_Alignment_of_Non-tuning_Large_Language_Models_and_Online_Recommendation_Systems_for_Explainable_Reason_Generation.md)

    - [翻译: LANE：实现非调优大型语言模型与在线推荐系统的逻辑对齐，旨在生成可解释的推理。](2024年07月03日/LANE_Logic_Alignment_of_Non-tuning_Large_Language_Models_and_Online_Recommendation_Systems_for_Explainable_Reason_Generation.md)

- [Exploring the Capabilities of LLMs for Code Change Related Tasks](2024年07月03日/Exploring_the_Capabilities_of_LLMs_for_Code_Change_Related_Tasks.md)

    - [翻译: 探究 LLM 在代码变更任务中的潜能](2024年07月03日/Exploring_the_Capabilities_of_LLMs_for_Code_Change_Related_Tasks.md)

- [Efficient Training of Language Models with Compact and Consistent Next Token Distributions](2024年07月03日/Efficient_Training_of_Language_Models_with_Compact_and_Consistent_Next_Token_Distributions.md)

    - [翻译: 通过紧凑一致的下一词分布，实现语言模型的高效训练](2024年07月03日/Efficient_Training_of_Language_Models_with_Compact_and_Consistent_Next_Token_Distributions.md)

- [InternLM-XComposer-2.5: A Versatile Large Vision Language Model Supporting Long-Contextual Input and Output](2024年07月03日/InternLM-XComposer-2.5_A_Versatile_Large_Vision_Language_Model_Supporting_Long-Contextual_Input_and_Output.md)

    - [翻译: InternLM-XComposer-2.5：一款多功能大型视觉语言模型，专为长上下文输入与输出设计。](2024年07月03日/InternLM-XComposer-2.5_A_Versatile_Large_Vision_Language_Model_Supporting_Long-Contextual_Input_and_Output.md)

- [Universal Length Generalization with Turing Programs](2024年07月03日/Universal_Length_Generalization_with_Turing_Programs.md)

    - [翻译: 图灵程序在通用长度泛化中的应用](2024年07月03日/Universal_Length_Generalization_with_Turing_Programs.md)

- [Large Language Models for JSON Schema Discovery](2024年07月03日/Large_Language_Models_for_JSON_Schema_Discovery.md)

    - [翻译: 利用大型语言模型进行 JSON 模式探索](2024年07月03日/Large_Language_Models_for_JSON_Schema_Discovery.md)

- [LLM Internal States Reveal Hallucination Risk Faced With a Query](2024年07月03日/LLM_Internal_States_Reveal_Hallucination_Risk_Faced_With_a_Query.md)

    - [翻译: LLM 的内部状态暴露了在面对查询时可能产生的幻觉风险。](2024年07月03日/LLM_Internal_States_Reveal_Hallucination_Risk_Faced_With_a_Query.md)

- [AgentInstruct: Toward Generative Teaching with Agentic Flows](2024年07月03日/AgentInstruct_Toward_Generative_Teaching_with_Agentic_Flows.md)

    - [翻译: AgentInstruct：迈向结合生成教学与代理流的新境界](2024年07月03日/AgentInstruct_Toward_Generative_Teaching_with_Agentic_Flows.md)

- [Visualizing Dialogues: Enhancing Image Selection through Dialogue Understanding with Large Language Models](2024年07月03日/Visualizing_Dialogues_Enhancing_Image_Selection_through_Dialogue_Understanding_with_Large_Language_Models.md)

    - [翻译: 借助大型语言模型，通过深入理解对话内容，我们提升了图像选择的精准度，实现了对话的可视化呈现。](2024年07月03日/Visualizing_Dialogues_Enhancing_Image_Selection_through_Dialogue_Understanding_with_Large_Language_Models.md)

- [LLMcap: Large Language Model for Unsupervised PCAP Failure Detection](2024年07月03日/LLMcap_Large_Language_Model_for_Unsupervised_PCAP_Failure_Detection.md)

    - [翻译: LLMcap：一款专为无监督 PCAP 故障检测设计的大型语言模型](2024年07月03日/LLMcap_Large_Language_Model_for_Unsupervised_PCAP_Failure_Detection.md)

2024年07月02日

- [Talking to Machines: do you read me?](2024年07月02日/Talking_to_Machines_do_you_read_me.md)

    - [翻译: 机器，你懂我的话吗？](2024年07月02日/Talking_to_Machines_do_you_read_me.md)

- [Embodied AI in Mobile Robots: Coverage Path Planning with Large Language Models](2024年07月02日/Embodied_AI_in_Mobile_Robots_Coverage_Path_Planning_with_Large_Language_Models.md)

    - [翻译: 移动机器人中的具身AI：借助大型语言模型实现高效覆盖路径规划](2024年07月02日/Embodied_AI_in_Mobile_Robots_Coverage_Path_Planning_with_Large_Language_Models.md)

- [TokenPacker: Efficient Visual Projector for Multimodal LLM](2024年07月02日/TokenPacker_Efficient_Visual_Projector_for_Multimodal_LLM.md)

    - [翻译: TokenPacker：专为多模态 LLM 设计的高效视觉投影工具](2024年07月02日/TokenPacker_Efficient_Visual_Projector_for_Multimodal_LLM.md)

- [Towards a Holistic Framework for Multimodal Large Language Models in Three-dimensional Brain CT Report Generation](2024年07月02日/Towards_a_Holistic_Framework_for_Multimodal_Large_Language_Models_in_Three-dimensional_Brain_CT_Report_Generation.md)

    - [翻译: 构建综合框架，助力三维脑CT报告生成中的多模态大型语言模型发展](2024年07月02日/Towards_a_Holistic_Framework_for_Multimodal_Large_Language_Models_in_Three-dimensional_Brain_CT_Report_Generation.md)

- [Synthetic Multimodal Question Generation](2024年07月02日/Synthetic_Multimodal_Question_Generation.md)

    - [翻译: 多模态问题生成的合成技术](2024年07月02日/Synthetic_Multimodal_Question_Generation.md)

- [Crossroads of Continents: Automated Artifact Extraction for Cultural Adaptation with Large Multimodal Models](2024年07月02日/Crossroads_of_Continents_Automated_Artifact_Extraction_for_Cultural_Adaptation_with_Large_Multimodal_Models.md)

    - [翻译: 大陆交汇处：借助大型多模态模型实现文化适应的自动文物提取](2024年07月02日/Crossroads_of_Continents_Automated_Artifact_Extraction_for_Cultural_Adaptation_with_Large_Multimodal_Models.md)

- [An End-to-End Speech Summarization Using Large Language Model](2024年07月02日/An_End-to-End_Speech_Summarization_Using_Large_Language_Model.md)

    - [翻译: 利用大型语言模型实现端到端语音摘要](2024年07月02日/An_End-to-End_Speech_Summarization_Using_Large_Language_Model.md)

- [Certainly Uncertain: A Benchmark and Metric for Multimodal Epistemic and Aleatoric Awareness](2024年07月02日/Certainly_Uncertain_A_Benchmark_and_Metric_for_Multimodal_Epistemic_and_Aleatoric_Awareness.md)

    - [翻译: 探索不确定性：多模态认知与偶然性意识的评估基准与度量](2024年07月02日/Certainly_Uncertain_A_Benchmark_and_Metric_for_Multimodal_Epistemic_and_Aleatoric_Awareness.md)

- [Video Watermarking: Safeguarding Your Video from (Unauthorized) Annotations by Video-based LLMs](2024年07月02日/Video_Watermarking_Safeguarding_Your_Video_from_(Unauthorized)_Annotations_by_Video-based_LLMs.md)

    - [翻译: 视频水印技术：保护您的视频内容，防止基于视频的 LLM 进行未经授权的注释。](2024年07月02日/Video_Watermarking_Safeguarding_Your_Video_from_(Unauthorized)_Annotations_by_Video-based_LLMs.md)

- [CEB: Compositional Evaluation Benchmark for Fairness in Large Language Models](2024年07月02日/CEB_Compositional_Evaluation_Benchmark_for_Fairness_in_Large_Language_Models.md)

    - [翻译: CEB：大型语言模型公平性的组合评估基准](2024年07月02日/CEB_Compositional_Evaluation_Benchmark_for_Fairness_in_Large_Language_Models.md)

- [Assessing the Code Clone Detection Capability of Large Language Models](2024年07月02日/Assessing_the_Code_Clone_Detection_Capability_of_Large_Language_Models.md)

    - [翻译: 探究大型语言模型在代码克隆检测方面的能力](2024年07月02日/Assessing_the_Code_Clone_Detection_Capability_of_Large_Language_Models.md)

- [Learning to Refine with Fine-Grained Natural Language Feedback](2024年07月02日/Learning_to_Refine_with_Fine-Grained_Natural_Language_Feedback.md)

    - [翻译: 精炼学习：借助细粒度自然语言反馈](2024年07月02日/Learning_to_Refine_with_Fine-Grained_Natural_Language_Feedback.md)

- [Is Your AI-Generated Code Really Secure? Evaluating Large Language Models on Secure Code Generation with CodeSecEval](2024年07月02日/Is_Your_AI-Generated_Code_Really_Secure_Evaluating_Large_Language_Models_on_Secure_Code_Generation_with_CodeSecEval.md)

    - [翻译: AI 编写的代码，真的无懈可击吗？通过 CodeSecEval 工具，我们评估了大型语言模型在安全代码生成方面的表现。](2024年07月02日/Is_Your_AI-Generated_Code_Really_Secure_Evaluating_Large_Language_Models_on_Secure_Code_Generation_with_CodeSecEval.md)

- [Pelican: Correcting Hallucination in Vision-LLMs via Claim Decomposition and Program of Thought Verification](2024年07月02日/Pelican_Correcting_Hallucination_in_Vision-LLMs_via_Claim_Decomposition_and_Program_of_Thought_Verification.md)

    - [翻译: Pelican 通过声明分解和思维程序验证，有效纠正了视觉-LLMs中的幻觉问题。](2024年07月02日/Pelican_Correcting_Hallucination_in_Vision-LLMs_via_Claim_Decomposition_and_Program_of_Thought_Verification.md)

- [Generative Large Language Models in Automated Fact-Checking: A Survey](2024年07月02日/Generative_Large_Language_Models_in_Automated_Fact-Checking_A_Survey.md)

    - [翻译: 自动化事实核查中的生成式大型语言模型：综述](2024年07月02日/Generative_Large_Language_Models_in_Automated_Fact-Checking_A_Survey.md)

- [MORPHEUS: Modeling Role from Personalized Dialogue History by Exploring and Utilizing Latent Space](2024年07月02日/MORPHEUS_Modeling_Role_from_Personalized_Dialogue_History_by_Exploring_and_Utilizing_Latent_Space.md)

    - [翻译: MORPHEUS 项目旨在通过探索和利用潜在空间，从个性化对话历史中精准建模角色。](2024年07月02日/MORPHEUS_Modeling_Role_from_Personalized_Dialogue_History_by_Exploring_and_Utilizing_Latent_Space.md)

- [RVISA: Reasoning and Verification for Implicit Sentiment Analysis](2024年07月02日/RVISA_Reasoning_and_Verification_for_Implicit_Sentiment_Analysis.md)

    - [翻译: RVISA：隐式情感分析中的推理与验证](2024年07月02日/RVISA_Reasoning_and_Verification_for_Implicit_Sentiment_Analysis.md)

- [Open foundation models for Azerbaijani language](2024年07月02日/Open_foundation_models_for_Azerbaijani_language.md)

    - [翻译: 阿塞拜疆语言的开放基础模型](2024年07月02日/Open_foundation_models_for_Azerbaijani_language.md)

- [Efficient Sparse Attention needs Adaptive Token Release](2024年07月02日/Efficient_Sparse_Attention_needs_Adaptive_Token_Release.md)

    - [翻译: 实现高效稀疏注意力，关键在于自适应释放令牌。](2024年07月02日/Efficient_Sparse_Attention_needs_Adaptive_Token_Release.md)

- [Exploring the Role of Transliteration in In-Context Learning for Low-resource Languages Written in Non-Latin Scripts](2024年07月02日/Exploring_the_Role_of_Transliteration_in_In-Context_Learning_for_Low-resource_Languages_Written_in_Non-Latin_Scripts.md)

    - [翻译: 研究音译在非拉丁文字低资源语言上下文学习中的角色](2024年07月02日/Exploring_the_Role_of_Transliteration_in_In-Context_Learning_for_Low-resource_Languages_Written_in_Non-Latin_Scripts.md)

- [Evaluating the Ability of LLMs to Solve Semantics-Aware Process Mining Tasks](2024年07月02日/Evaluating_the_Ability_of_LLMs_to_Solve_Semantics-Aware_Process_Mining_Tasks.md)

    - [翻译: 探究 LLMs 在语义感知过程挖掘任务中的表现](2024年07月02日/Evaluating_the_Ability_of_LLMs_to_Solve_Semantics-Aware_Process_Mining_Tasks.md)

- [CFinBench: A Comprehensive Chinese Financial Benchmark for Large Language Models](2024年07月02日/CFinBench_A_Comprehensive_Chinese_Financial_Benchmark_for_Large_Language_Models.md)

    - [翻译: CFinBench：为大型语言模型打造的中文金融全面基准](2024年07月02日/CFinBench_A_Comprehensive_Chinese_Financial_Benchmark_for_Large_Language_Models.md)

- [Strategic Demand-Planning in Wireless Networks: Can Generative-AI Save Spectrum and Energy?](2024年07月02日/Strategic_Demand-Planning_in_Wireless_Networks_Can_Generative-AI_Save_Spectrum_and_Energy.md)

    - [翻译: 在无线网络的战略需求规划中，生成式人工智能能否成为频谱和能源的救星？](2024年07月02日/Strategic_Demand-Planning_in_Wireless_Networks_Can_Generative-AI_Save_Spectrum_and_Energy.md)

- [Multilingual Trolley Problems for Language Models](2024年07月02日/Multilingual_Trolley_Problems_for_Language_Models.md)

    - [翻译: 语言模型面临的多语言电车难题](2024年07月02日/Multilingual_Trolley_Problems_for_Language_Models.md)

- [GlyphDraw2: Automatic Generation of Complex Glyph Posters with Diffusion Models and Large Language Models](2024年07月02日/GlyphDraw2_Automatic_Generation_of_Complex_Glyph_Posters_with_Diffusion_Models_and_Large_Language_Models.md)

    - [翻译: GlyphDraw2：结合扩散模型与大型语言模型，自动创作复杂字形海报。](2024年07月02日/GlyphDraw2_Automatic_Generation_of_Complex_Glyph_Posters_with_Diffusion_Models_and_Large_Language_Models.md)

- [MIREncoder: Multi-modal IR-based Pretrained Embeddings for Performance Optimizations](2024年07月02日/MIREncoder_Multi-modal_IR-based_Pretrained_Embeddings_for_Performance_Optimizations.md)

    - [翻译: MIREncoder：一种基于多模态信息检索的预训练嵌入技术，旨在实现性能优化。](2024年07月02日/MIREncoder_Multi-modal_IR-based_Pretrained_Embeddings_for_Performance_Optimizations.md)

- [PromptIntern: Saving Inference Costs by Internalizing Recurrent Prompt during Large Language Model Fine-tuning](2024年07月02日/PromptIntern_Saving_Inference_Costs_by_Internalizing_Recurrent_Prompt_during_Large_Language_Model_Fine-tuning.md)

    - [翻译: PromptIntern：在大语言模型微调过程中，通过内部化循环提示，有效节省推理成本。](2024年07月02日/PromptIntern_Saving_Inference_Costs_by_Internalizing_Recurrent_Prompt_during_Large_Language_Model_Fine-tuning.md)

- [Generative Monoculture in Large Language Models](2024年07月02日/Generative_Monoculture_in_Large_Language_Models.md)

    - [翻译: 大型语言模型中的生成单一文化现象](2024年07月02日/Generative_Monoculture_in_Large_Language_Models.md)

- [Automatic Adaptation Rule Optimization via Large Language Models](2024年07月02日/Automatic_Adaptation_Rule_Optimization_via_Large_Language_Models.md)

    - [翻译: 利用大型语言模型实现自动适应规则的优化](2024年07月02日/Automatic_Adaptation_Rule_Optimization_via_Large_Language_Models.md)

- [A mathematical definition of complex adaptive system as interaction space](2024年07月02日/A_mathematical_definition_of_complex_adaptive_system_as_interaction_space.md)

    - [翻译: 复杂适应系统的数学定义，以交互空间为视角](2024年07月02日/A_mathematical_definition_of_complex_adaptive_system_as_interaction_space.md)

- [FineCLIPER: Multi-modal Fine-grained CLIP for Dynamic Facial Expression Recognition with AdaptERs](2024年07月02日/FineCLIPER_Multi-modal_Fine-grained_CLIP_for_Dynamic_Facial_Expression_Recognition_with_AdaptERs.md)

    - [翻译: FineCLIPER：一款结合多模态细粒度 CLIP 技术与适应性调整器的系统，专为动态面部表情识别设计。](2024年07月02日/FineCLIPER_Multi-modal_Fine-grained_CLIP_for_Dynamic_Facial_Expression_Recognition_with_AdaptERs.md)

- [LlamAr & GemmAr: Enhancing LLMs Through Arabic Instruction-Tuning](2024年07月02日/LlamAr_&_GemmAr_Enhancing_LLMs_Through_Arabic_Instruction-Tuning.md)

    - [翻译: LlamAr 与 GemmAr：借助阿拉伯语指令调优提升大型语言模型性能](2024年07月02日/LlamAr_&_GemmAr_Enhancing_LLMs_Through_Arabic_Instruction-Tuning.md)

- [Cost-Effective Proxy Reward Model Construction with On-Policy and Active Learning](2024年07月02日/Cost-Effective_Proxy_Reward_Model_Construction_with_On-Policy_and_Active_Learning.md)

    - [翻译: 通过在线策略与主动学习构建经济高效的代理奖励模型](2024年07月02日/Cost-Effective_Proxy_Reward_Model_Construction_with_On-Policy_and_Active_Learning.md)

- [Breaking Language Barriers: Cross-Lingual Continual Pre-Training at Scale](2024年07月02日/Breaking_Language_Barriers_Cross-Lingual_Continual_Pre-Training_at_Scale.md)

    - [翻译: 跨越语言界限：大规模实施跨语言持续预训练](2024年07月02日/Breaking_Language_Barriers_Cross-Lingual_Continual_Pre-Training_at_Scale.md)

- [Helpful assistant or fruitful facilitator? Investigating how personas affect language model behavior](2024年07月02日/Helpful_assistant_or_fruitful_facilitator_Investigating_how_personas_affect_language_model_behavior.md)

    - [翻译: 是助手还是促进者？探讨角色对语言模型行为的影响。](2024年07月02日/Helpful_assistant_or_fruitful_facilitator_Investigating_how_personas_affect_language_model_behavior.md)

- [GPTCast: a weather language model for precipitation nowcasting](2024年07月02日/GPTCast_a_weather_language_model_for_precipitation_nowcasting.md)

    - [翻译: GPTCast：一款专为降水实时预报设计的天气语言模型](2024年07月02日/GPTCast_a_weather_language_model_for_precipitation_nowcasting.md)

- [Theseus: Towards High-Efficiency Wafer-Scale Chip Design Space Exploration for Large Language Models](2024年07月02日/Theseus_Towards_High-Efficiency_Wafer-Scale_Chip_Design_Space_Exploration_for_Large_Language_Models.md)

    - [翻译: Theseus 项目致力于为大型语言模型优化晶圆级芯片设计，提升探索效率。](2024年07月02日/Theseus_Towards_High-Efficiency_Wafer-Scale_Chip_Design_Space_Exploration_for_Large_Language_Models.md)

- [Fake News Detection and Manipulation Reasoning via Large Vision-Language Models](2024年07月02日/Fake_News_Detection_and_Manipulation_Reasoning_via_Large_Vision-Language_Models.md)

    - [翻译: 利用大型视觉-语言模型，我们致力于假新闻的检测与操纵行为的推理。](2024年07月02日/Fake_News_Detection_and_Manipulation_Reasoning_via_Large_Vision-Language_Models.md)

- [Prompt Stability Scoring for Text Annotation with Large Language Models](2024年07月02日/Prompt_Stability_Scoring_for_Text_Annotation_with_Large_Language_Models.md)

    - [翻译: 大型语言模型文本标注中的提示稳定性评分](2024年07月02日/Prompt_Stability_Scoring_for_Text_Annotation_with_Large_Language_Models.md)

- [Breaking Bias, Building Bridges: Evaluation and Mitigation of Social Biases in LLMs via Contact Hypothesis](2024年07月02日/Breaking_Bias,_Building_Bridges_Evaluation_and_Mitigation_of_Social_Biases_in_LLMs_via_Contact_Hypothesis.md)

    - [翻译: 破除偏见，搭建沟通之桥：利用接触假设评估并减轻 LLMs 中的社会偏见](2024年07月02日/Breaking_Bias,_Building_Bridges_Evaluation_and_Mitigation_of_Social_Biases_in_LLMs_via_Contact_Hypothesis.md)

- [Why does in-context learning fail sometimes? Evaluating in-context learning on open and closed questions](2024年07月02日/Why_does_in-context_learning_fail_sometimes_Evaluating_in-context_learning_on_open_and_closed_questions.md)

    - [翻译: 为何 in-context learning 有时会失效？探讨其在开放与封闭问题上的表现。](2024年07月02日/Why_does_in-context_learning_fail_sometimes_Evaluating_in-context_learning_on_open_and_closed_questions.md)

- [ViG-Bias: Visually Grounded Bias Discovery and Mitigation](2024年07月02日/ViG-Bias_Visually_Grounded_Bias_Discovery_and_Mitigation.md)

    - [翻译: ViG-Bias：通过视觉基础技术发现并缓解偏见](2024年07月02日/ViG-Bias_Visually_Grounded_Bias_Discovery_and_Mitigation.md)

- [Is Your Large Language Model Knowledgeable or a Choices-Only Cheater?](2024年07月02日/Is_Your_Large_Language_Model_Knowledgeable_or_a_Choices-Only_Cheater.md)

    - [翻译: 你的大型语言模型是真才实学，还是仅仅在选择题上作弊？](2024年07月02日/Is_Your_Large_Language_Model_Knowledgeable_or_a_Choices-Only_Cheater.md)

- [SADL: An Effective In-Context Learning Method for Compositional Visual QA](2024年07月02日/SADL_An_Effective_In-Context_Learning_Method_for_Compositional_Visual_QA.md)

    - [翻译: SADL：组合视觉问答中一种高效的上下文学习策略](2024年07月02日/SADL_An_Effective_In-Context_Learning_Method_for_Compositional_Visual_QA.md)

- [A Bounding Box is Worth One Token: Interleaving Layout and Text in a Large Language Model for Document Understanding](2024年07月02日/A_Bounding_Box_is_Worth_One_Token_Interleaving_Layout_and_Text_in_a_Large_Language_Model_for_Document_Understanding.md)

    - [翻译: 每个边界框等同于一个令牌，通过在大规模语言模型中交错布局与文本，我们实现了对文档的深入理解。](2024年07月02日/A_Bounding_Box_is_Worth_One_Token_Interleaving_Layout_and_Text_in_a_Large_Language_Model_for_Document_Understanding.md)

- [MeMemo: On-device Retrieval Augmentation for Private and Personalized Text Generation](2024年07月02日/MeMemo_On-device_Retrieval_Augmentation_for_Private_and_Personalized_Text_Generation.md)

    - [翻译: MeMemo：实现设备端检索增强，助力私密且个性化的文本生成](2024年07月02日/MeMemo_On-device_Retrieval_Augmentation_for_Private_and_Personalized_Text_Generation.md)

- [Enabling Discriminative Reasoning in Large Language Models for Legal Judgment Prediction](2024年07月02日/Enabling_Discriminative_Reasoning_in_Large_Language_Models_for_Legal_Judgment_Prediction.md)

    - [翻译: 大型语言模型中的判别推理助力法律判决预测](2024年07月02日/Enabling_Discriminative_Reasoning_in_Large_Language_Models_for_Legal_Judgment_Prediction.md)

- [Towards Unsupervised Speaker Diarization System for Multilingual Telephone Calls Using Pre-trained Whisper Model and Mixture of Sparse Autoencoders](2024年07月02日/Towards_Unsupervised_Speaker_Diarization_System_for_Multilingual_Telephone_Calls_Using_Pre-trained_Whisper_Model_and_Mixture_of_Sparse_Autoencoders.md)

    - [翻译: 本研究旨在构建一个无监督的多语言电话通话说话人日志系统，该系统结合了预训练的 Whisper 模型与稀疏自编码器的混合技术。](2024年07月02日/Towards_Unsupervised_Speaker_Diarization_System_for_Multilingual_Telephone_Calls_Using_Pre-trained_Whisper_Model_and_Mixture_of_Sparse_Autoencoders.md)

- [S2D: Sorted Speculative Decoding For More Efficient Deployment of Nested Large Language Models](2024年07月02日/S2D_Sorted_Speculative_Decoding_For_More_Efficient_Deployment_of_Nested_Large_Language_Models.md)

    - [翻译: S2D：通过排序推测解码，提升嵌套大型语言模型的部署效率](2024年07月02日/S2D_Sorted_Speculative_Decoding_For_More_Efficient_Deployment_of_Nested_Large_Language_Models.md)

- [CatMemo at the FinLLM Challenge Task: Fine-Tuning Large Language Models using Data Fusion in Financial Applications](2024年07月02日/CatMemo_at_the_FinLLM_Challenge_Task_Fine-Tuning_Large_Language_Models_using_Data_Fusion_in_Financial_Applications.md)

    - [翻译: CatMemo在FinLLM挑战中，通过数据融合技术，优化金融应用中的大型语言模型微调。](2024年07月02日/CatMemo_at_the_FinLLM_Challenge_Task_Fine-Tuning_Large_Language_Models_using_Data_Fusion_in_Financial_Applications.md)

- [Extracting and Encoding: Leveraging Large Language Models and Medical Knowledge to Enhance Radiological Text Representation](2024年07月02日/Extracting_and_Encoding_Leveraging_Large_Language_Models_and_Medical_Knowledge_to_Enhance_Radiological_Text_Representation.md)

    - [翻译: 借助大型语言模型与医学知识，我们致力于提升放射学文本的表达力。](2024年07月02日/Extracting_and_Encoding_Leveraging_Large_Language_Models_and_Medical_Knowledge_to_Enhance_Radiological_Text_Representation.md)

- [RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs](2024年07月02日/RankRAG_Unifying_Context_Ranking_with_Retrieval-Augmented_Generation_in_LLMs.md)

    - [翻译: RankRAG：整合上下文排序与检索增强生成于大型语言模型中](2024年07月02日/RankRAG_Unifying_Context_Ranking_with_Retrieval-Augmented_Generation_in_LLMs.md)

- [MMedAgent: Learning to Use Medical Tools with Multi-modal Agent](2024年07月02日/MMedAgent_Learning_to_Use_Medical_Tools_with_Multi-modal_Agent.md)

    - [翻译: MMedAgent：掌握医疗工具的多模态学习代理](2024年07月02日/MMedAgent_Learning_to_Use_Medical_Tools_with_Multi-modal_Agent.md)

- [MInference 1.0: Accelerating Pre-filling for Long-Context LLMs via Dynamic Sparse Attention](2024年07月02日/MInference_1.0_Accelerating_Pre-filling_for_Long-Context_LLMs_via_Dynamic_Sparse_Attention.md)

    - [翻译: MInference 1.0 通过动态稀疏注意力机制，加速了长上下文大型语言模型的预填充过程。](2024年07月02日/MInference_1.0_Accelerating_Pre-filling_for_Long-Context_LLMs_via_Dynamic_Sparse_Attention.md)

- [Neurocache: Efficient Vector Retrieval for Long-range Language Modeling](2024年07月02日/Neurocache_Efficient_Vector_Retrieval_for_Long-range_Language_Modeling.md)

    - [翻译: Neurocache：实现长距离语言建模的高效向量检索技术](2024年07月02日/Neurocache_Efficient_Vector_Retrieval_for_Long-range_Language_Modeling.md)

- [Understanding Alignment in Multimodal LLMs: A Comprehensive Study](2024年07月02日/Understanding_Alignment_in_Multimodal_LLMs_A_Comprehensive_Study.md)

    - [翻译: 探究多模态LLM中的对齐机制：一项深入研究](2024年07月02日/Understanding_Alignment_in_Multimodal_LLMs_A_Comprehensive_Study.md)

- [Open Scene Graphs for Open World Object-Goal Navigation](2024年07月02日/Open_Scene_Graphs_for_Open_World_Object-Goal_Navigation.md)

    - [翻译: 开放场景图助力开放世界中的对象目标导航](2024年07月02日/Open_Scene_Graphs_for_Open_World_Object-Goal_Navigation.md)

- [Reliable Confidence Intervals for Information Retrieval Evaluation Using Generative A.I](2024年07月02日/Reliable_Confidence_Intervals_for_Information_Retrieval_Evaluation_Using_Generative_A.I.md)

    - [翻译: 利用生成式AI评估信息检索的可靠置信区间](2024年07月02日/Reliable_Confidence_Intervals_for_Information_Retrieval_Evaluation_Using_Generative_A.I.md)

- [Improving Visual Storytelling with Multimodal Large Language Models](2024年07月02日/Improving_Visual_Storytelling_with_Multimodal_Large_Language_Models.md)

    - [翻译: 通过多模态大型语言模型提升视觉叙事效果](2024年07月02日/Improving_Visual_Storytelling_with_Multimodal_Large_Language_Models.md)

- [Model-Enhanced LLM-Driven VUI Testing of VPA Apps](2024年07月02日/Model-Enhanced_LLM-Driven_VUI_Testing_of_VPA_Apps.md)

    - [翻译: 基于模型增强的 LLM 驱动，对 VPA 应用进行 VUI 测试](2024年07月02日/Model-Enhanced_LLM-Driven_VUI_Testing_of_VPA_Apps.md)

- [52B to 1T: Lessons Learned via Tele-FLM Series](2024年07月02日/52B_to_1T_Lessons_Learned_via_Tele-FLM_Series.md)

    - [翻译: 从 52B 到 1T：Tele-FLM 系列中的经验启示](2024年07月02日/52B_to_1T_Lessons_Learned_via_Tele-FLM_Series.md)

- [Croppable Knowledge Graph Embedding](2024年07月02日/Croppable_Knowledge_Graph_Embedding.md)

    - [翻译: 知识图谱嵌入的可裁剪性](2024年07月02日/Croppable_Knowledge_Graph_Embedding.md)

- [Large language models, physics-based modeling, experimental measurements: the trinity of data-scarce learning of polymer properties](2024年07月02日/Large_language_models,_physics-based_modeling,_experimental_measurements_the_trinity_of_data-scarce_learning_of_polymer_properties.md)

    - [翻译: 大型语言模型、物理建模与实验测量，三者共同构成了聚合物特性数据稀缺学习的核心。](2024年07月02日/Large_language_models,_physics-based_modeling,_experimental_measurements_the_trinity_of_data-scarce_learning_of_polymer_properties.md)

- [Learning to Reduce: Towards Improving Performance of Large Language Models on Structured Data](2024年07月02日/Learning_to_Reduce_Towards_Improving_Performance_of_Large_Language_Models_on_Structured_Data.md)

    - [翻译: 通过学习简化，我们致力于提升大型语言模型在处理结构化数据时的表现。](2024年07月02日/Learning_to_Reduce_Towards_Improving_Performance_of_Large_Language_Models_on_Structured_Data.md)

- [A Comparative Study of DSL Code Generation: Fine-Tuning vs. Optimized Retrieval Augmentation](2024年07月02日/A_Comparative_Study_of_DSL_Code_Generation_Fine-Tuning_vs._Optimized_Retrieval_Augmentation.md)

    - [翻译: 比较 DSL 代码生成的两种方法：微调与优化检索增强](2024年07月02日/A_Comparative_Study_of_DSL_Code_Generation_Fine-Tuning_vs._Optimized_Retrieval_Augmentation.md)

- [MentalAgora: A Gateway to Advanced Personalized Care in Mental Health through Multi-Agent Debating and Attribute Control](2024年07月02日/MentalAgora_A_Gateway_to_Advanced_Personalized_Care_in_Mental_Health_through_Multi-Agent_Debating_and_Attribute_Control.md)

    - [翻译: MentalAgora：借助多代理辩论与属性控制，开启心理健康高级个性化护理之门](2024年07月02日/MentalAgora_A_Gateway_to_Advanced_Personalized_Care_in_Mental_Health_through_Multi-Agent_Debating_and_Attribute_Control.md)

- [Supporting Cross-language Cross-project Bug Localization Using Pre-trained Language Models](2024年07月02日/Supporting_Cross-language_Cross-project_Bug_Localization_Using_Pre-trained_Language_Models.md)

    - [翻译: 借助预训练语言模型，实现跨语言与跨项目的错误定位支持。](2024年07月02日/Supporting_Cross-language_Cross-project_Bug_Localization_Using_Pre-trained_Language_Models.md)

- [MedVH: Towards Systematic Evaluation of Hallucination for Large Vision Language Models in the Medical Context](2024年07月02日/MedVH_Towards_Systematic_Evaluation_of_Hallucination_for_Large_Vision_Language_Models_in_the_Medical_Context.md)

    - [翻译: MedVH：探索在医学领域中，如何系统评估大型视觉语言模型的幻觉问题。](2024年07月02日/MedVH_Towards_Systematic_Evaluation_of_Hallucination_for_Large_Vision_Language_Models_in_the_Medical_Context.md)

- [LLM-Select: Feature Selection with Large Language Models](2024年07月02日/LLM-Select_Feature_Selection_with_Large_Language_Models.md)

    - [翻译: LLM-Select：借助大型语言模型实现特征选择](2024年07月02日/LLM-Select_Feature_Selection_with_Large_Language_Models.md)

- [KGym: A Platform and Dataset to Benchmark Large Language Models on Linux Kernel Crash Resolution](2024年07月02日/KGym_A_Platform_and_Dataset_to_Benchmark_Large_Language_Models_on_Linux_Kernel_Crash_Resolution.md)

    - [翻译: KGym 是一个专为 Linux 内核崩溃解决而设计，用于评估大型语言模型性能的平台和数据集。](2024年07月02日/KGym_A_Platform_and_Dataset_to_Benchmark_Large_Language_Models_on_Linux_Kernel_Crash_Resolution.md)

- [Reasoning in Large Language Models: A Geometric Perspective](2024年07月02日/Reasoning_in_Large_Language_Models_A_Geometric_Perspective.md)

    - [翻译: 大型语言模型推理：几何视角探析](2024年07月02日/Reasoning_in_Large_Language_Models_A_Geometric_Perspective.md)

2024年07月01日

- [KV Cache Compression, But What Must We Give in Return? A Comprehensive Benchmark of Long Context Capable Approaches](2024年07月01日/KV_Cache_Compression,_But_What_Must_We_Give_in_Return_A_Comprehensive_Benchmark_of_Long_Context_Capable_Approaches.md)

    - [翻译: KV缓存压缩：我们需付出何种代价？长上下文能力方法的全面基准测试](2024年07月01日/KV_Cache_Compression,_But_What_Must_We_Give_in_Return_A_Comprehensive_Benchmark_of_Long_Context_Capable_Approaches.md)

- [Empowering 3D Visual Grounding with Reasoning Capabilities](2024年07月01日/Empowering_3D_Visual_Grounding_with_Reasoning_Capabilities.md)

    - [翻译: 赋予 3D 视觉定位推理能力](2024年07月01日/Empowering_3D_Visual_Grounding_with_Reasoning_Capabilities.md)

- [MMLongBench-Doc: Benchmarking Long-context Document Understanding with Visualizations](2024年07月01日/MMLongBench-Doc_Benchmarking_Long-context_Document_Understanding_with_Visualizations.md)

    - [翻译: MMLongBench-Doc：借助可视化工具，对长篇文档理解进行基准测试](2024年07月01日/MMLongBench-Doc_Benchmarking_Long-context_Document_Understanding_with_Visualizations.md)

- [MIA-Bench: Towards Better Instruction Following Evaluation of Multimodal LLMs](2024年07月01日/MIA-Bench_Towards_Better_Instruction_Following_Evaluation_of_Multimodal_LLMs.md)

    - [翻译: MIA-Bench：旨在提升多模态 LLM 指令遵循能力的评估工具](2024年07月01日/MIA-Bench_Towards_Better_Instruction_Following_Evaluation_of_Multimodal_LLMs.md)

- [Self-Cognition in Large Language Models: An Exploratory Study](2024年07月01日/Self-Cognition_in_Large_Language_Models_An_Exploratory_Study.md)

    - [翻译: 大型语言模型中的自我认知探索研究](2024年07月01日/Self-Cognition_in_Large_Language_Models_An_Exploratory_Study.md)

- [RegMix: Data Mixture as Regression for Language Model Pre-training](2024年07月01日/RegMix_Data_Mixture_as_Regression_for_Language_Model_Pre-training.md)

    - [翻译: RegMix：以数据混合为手段，通过回归进行语言模型预训练](2024年07月01日/RegMix_Data_Mixture_as_Regression_for_Language_Model_Pre-training.md)

- [Expressive and Generalizable Low-rank Adaptation for Large Models via Slow Cascaded Learning](2024年07月01日/Expressive_and_Generalizable_Low-rank_Adaptation_for_Large_Models_via_Slow_Cascaded_Learning.md)

    - [翻译: 通过缓慢级联学习，实现大型模型的低秩适应，兼具表达性与泛化能力。](2024年07月01日/Expressive_and_Generalizable_Low-rank_Adaptation_for_Large_Models_via_Slow_Cascaded_Learning.md)

- [LLM See, LLM Do: Guiding Data Generation to Target Non-Differentiable Objectives](2024年07月01日/LLM_See,_LLM_Do_Guiding_Data_Generation_to_Target_Non-Differentiable_Objectives.md)

    - [翻译: LLM 观察，LLM 行动：引导数据生成，瞄准非可微目标](2024年07月01日/LLM_See,_LLM_Do_Guiding_Data_Generation_to_Target_Non-Differentiable_Objectives.md)

- [Agentless: Demystifying LLM-based Software Engineering Agents](2024年07月01日/Agentless_Demystifying_LLM-based_Software_Engineering_Agents.md)

    - [翻译: 无代理模式：探索基于LLM的软件工程代理之谜](2024年07月01日/Agentless_Demystifying_LLM-based_Software_Engineering_Agents.md)

- [LEXI: Large Language Models Experimentation Interface](2024年07月01日/LEXI_Large_Language_Models_Experimentation_Interface.md)

    - [翻译: LEXI：大型语言模型实验平台](2024年07月01日/LEXI_Large_Language_Models_Experimentation_Interface.md)

- [DogeRM: Equipping Reward Models with Domain Knowledge through Model Merging](2024年07月01日/DogeRM_Equipping_Reward_Models_with_Domain_Knowledge_through_Model_Merging.md)

    - [翻译: DogeRM：借助模型合并技术，为奖励模型注入领域智慧](2024年07月01日/DogeRM_Equipping_Reward_Models_with_Domain_Knowledge_through_Model_Merging.md)

- [Retrieval-augmented generation in multilingual settings](2024年07月01日/Retrieval-augmented_generation_in_multilingual_settings.md)

    - [翻译: 多语言环境下的检索增强生成](2024年07月01日/Retrieval-augmented_generation_in_multilingual_settings.md)

- [Enhancing the Capability and Robustness of Large Language Models through Reinforcement Learning-Driven Query Refinement](2024年07月01日/Enhancing_the_Capability_and_Robustness_of_Large_Language_Models_through_Reinforcement_Learning-Driven_Query_Refinement.md)

    - [翻译: 利用强化学习优化查询，提升大型语言模型的性能与稳定性](2024年07月01日/Enhancing_the_Capability_and_Robustness_of_Large_Language_Models_through_Reinforcement_Learning-Driven_Query_Refinement.md)

- [TimeToM: Temporal Space is the Key to Unlocking the Door of Large Language Models' Theory-of-Mind](2024年07月01日/TimeToM_Temporal_Space_is_the_Key_to_Unlocking_the_Door_of_Large_Language_Models'_Theory-of-Mind.md)

    - [翻译: 时间空间，即 TimeToM，是揭开大型语言模型心智理论奥秘的关键。](2024年07月01日/TimeToM_Temporal_Space_is_the_Key_to_Unlocking_the_Door_of_Large_Language_Models'_Theory-of-Mind.md)

- [FastCLIP: A Suite of Optimization Techniques to Accelerate CLIP Training with Limited Resources](2024年07月01日/FastCLIP_A_Suite_of_Optimization_Techniques_to_Accelerate_CLIP_Training_with_Limited_Resources.md)

    - [翻译: FastCLIP：一套优化技术，专为在资源有限的情况下加速 CLIP 训练而设计](2024年07月01日/FastCLIP_A_Suite_of_Optimization_Techniques_to_Accelerate_CLIP_Training_with_Limited_Resources.md)

- [Needle in the Haystack for Memory Based Large Language Models](2024年07月01日/Needle_in_the_Haystack_for_Memory_Based_Large_Language_Models.md)

    - [翻译: 大型语言模型中基于内存的难题](2024年07月01日/Needle_in_the_Haystack_for_Memory_Based_Large_Language_Models.md)

- [Dynamic Few-Shot Learning for Knowledge Graph Question Answering](2024年07月01日/Dynamic_Few-Shot_Learning_for_Knowledge_Graph_Question_Answering.md)

    - [翻译: 知识图谱问答中的动态少样本学习](2024年07月01日/Dynamic_Few-Shot_Learning_for_Knowledge_Graph_Question_Answering.md)

- [Adapting Multilingual LLMs to Low-Resource Languages with Knowledge Graphs via Adapters](2024年07月01日/Adapting_Multilingual_LLMs_to_Low-Resource_Languages_with_Knowledge_Graphs_via_Adapters.md)

    - [翻译: 借助知识图谱和适配器，让多语言LLMs轻松适应低资源语言](2024年07月01日/Adapting_Multilingual_LLMs_to_Low-Resource_Languages_with_Knowledge_Graphs_via_Adapters.md)

- [Optimization of Retrieval-Augmented Generation Context with Outlier Detection](2024年07月01日/Optimization_of_Retrieval-Augmented_Generation_Context_with_Outlier_Detection.md)

    - [翻译: 优化检索增强生成上下文，结合异常检测技术](2024年07月01日/Optimization_of_Retrieval-Augmented_Generation_Context_with_Outlier_Detection.md)

- [Gloss2Text: Sign Language Gloss translation using LLMs and Semantically Aware Label Smoothing](2024年07月01日/Gloss2Text_Sign_Language_Gloss_translation_using_LLMs_and_Semantically_Aware_Label_Smoothing.md)

    - [翻译: Gloss2Text：借助 LLMs 与语义感知标签平滑技术，实现手语词汇的精准翻译](2024年07月01日/Gloss2Text_Sign_Language_Gloss_translation_using_LLMs_and_Semantically_Aware_Label_Smoothing.md)

- [Free-text Rationale Generation under Readability Level Control](2024年07月01日/Free-text_Rationale_Generation_under_Readability_Level_Control.md)

    - [翻译: 在可读性控制下生成自由文本理由](2024年07月01日/Free-text_Rationale_Generation_under_Readability_Level_Control.md)

- [Evaluating Knowledge-based Cross-lingual Inconsistency in Large Language Models](2024年07月01日/Evaluating_Knowledge-based_Cross-lingual_Inconsistency_in_Large_Language_Models.md)

    - [翻译: 探究大型语言模型中基于知识的跨语言不一致问题](2024年07月01日/Evaluating_Knowledge-based_Cross-lingual_Inconsistency_in_Large_Language_Models.md)

- [Increasing Model Capacity for Free: A Simple Strategy for Parameter Efficient Fine-tuning](2024年07月01日/Increasing_Model_Capacity_for_Free_A_Simple_Strategy_for_Parameter_Efficient_Fine-tuning.md)

    - [翻译: 免费提升模型容量：一种简便的参数高效微调方法](2024年07月01日/Increasing_Model_Capacity_for_Free_A_Simple_Strategy_for_Parameter_Efficient_Fine-tuning.md)

- [Language Portability Strategies for Open-domain Dialogue with Pre-trained Language Models from High to Low Resource Languages](2024年07月01日/Language_Portability_Strategies_for_Open-domain_Dialogue_with_Pre-trained_Language_Models_from_High_to_Low_Resource_Languages.md)

    - [翻译: 预训练语言模型在开放域对话中，从高资源到低资源语言的语言可移植性策略研究](2024年07月01日/Language_Portability_Strategies_for_Open-domain_Dialogue_with_Pre-trained_Language_Models_from_High_to_Low_Resource_Languages.md)

- [Collaborative Performance Prediction for Large Language Models](2024年07月01日/Collaborative_Performance_Prediction_for_Large_Language_Models.md)

    - [翻译: 大型语言模型的协同性能预测](2024年07月01日/Collaborative_Performance_Prediction_for_Large_Language_Models.md)

- [Lightweight Zero-shot Text-to-Speech with Mixture of Adapters](2024年07月01日/Lightweight_Zero-shot_Text-to-Speech_with_Mixture_of_Adapters.md)

    - [翻译: 轻量级零-shot 文本转语音技术采用适配器混合方法](2024年07月01日/Lightweight_Zero-shot_Text-to-Speech_with_Mixture_of_Adapters.md)

- [We-Math: Does Your Large Multimodal Model Achieve Human-like Mathematical Reasoning?](2024年07月01日/We-Math_Does_Your_Large_Multimodal_Model_Achieve_Human-like_Mathematical_Reasoning.md)

    - [翻译: We-Math：探寻大型多模态模型是否已具备人类般的数学推理能力。](2024年07月01日/We-Math_Does_Your_Large_Multimodal_Model_Achieve_Human-like_Mathematical_Reasoning.md)

- [Human-Robot Mutual Learning through Affective-Linguistic Interaction and Differential Outcomes Training [Pre-Print]](2024年07月01日/Human-Robot_Mutual_Learning_through_Affective-Linguistic_Interaction_and_Differential_Outcomes_Training_[Pre-Print].md)

    - [翻译: 人机互学：基于情感语言交互与差异化训练成果 [预印版]](2024年07月01日/Human-Robot_Mutual_Learning_through_Affective-Linguistic_Interaction_and_Differential_Outcomes_Training_[Pre-Print].md)

- [Leveraging Large Language Models for Actionable Course Evaluation Student Feedback to Lecturers](2024年07月01日/Leveraging_Large_Language_Models_for_Actionable_Course_Evaluation_Student_Feedback_to_Lecturers.md)

    - [翻译: 借助大型语言模型，为讲师提供具有操作性的课程评估学生反馈](2024年07月01日/Leveraging_Large_Language_Models_for_Actionable_Course_Evaluation_Student_Feedback_to_Lecturers.md)

- [Show Less, Instruct More: Enriching Prompts with Definitions and Guidelines for Zero-Shot NER](2024年07月01日/Show_Less,_Instruct_More_Enriching_Prompts_with_Definitions_and_Guidelines_for_Zero-Shot_NER.md)

    - [翻译: 精简展示，强化指导：通过定义与指南提升零-shot NER 的提示质量](2024年07月01日/Show_Less,_Instruct_More_Enriching_Prompts_with_Definitions_and_Guidelines_for_Zero-Shot_NER.md)

- [The African Woman is Rhythmic and Soulful: Evaluation of Open-ended Generation for Implicit Biases](2024年07月01日/The_African_Woman_is_Rhythmic_and_Soulful_Evaluation_of_Open-ended_Generation_for_Implicit_Biases.md)

    - [翻译: 非洲女性，节奏与灵魂的化身：探索隐性偏见在开放式生成中的表现](2024年07月01日/The_African_Woman_is_Rhythmic_and_Soulful_Evaluation_of_Open-ended_Generation_for_Implicit_Biases.md)

- [SignCLIP: Connecting Text and Sign Language by Contrastive Learning](2024年07月01日/SignCLIP_Connecting_Text_and_Sign_Language_by_Contrastive_Learning.md)

    - [翻译: SignCLIP：借助对比学习，架起文本与手语之间的桥梁](2024年07月01日/SignCLIP_Connecting_Text_and_Sign_Language_by_Contrastive_Learning.md)

- [uDistil-Whisper: Label-Free Data Filtering for Knowledge Distillation via Large-Scale Pseudo Labelling](2024年07月01日/uDistil-Whisper_Label-Free_Data_Filtering_for_Knowledge_Distillation_via_Large-Scale_Pseudo_Labelling.md)

    - [翻译: uDistil-Whisper：利用大规模伪标签技术，实现知识蒸馏中的无标签数据过滤。](2024年07月01日/uDistil-Whisper_Label-Free_Data_Filtering_for_Knowledge_Distillation_via_Large-Scale_Pseudo_Labelling.md)

- [SINKT: A Structure-Aware Inductive Knowledge Tracing Model with Large Language Model](2024年07月01日/SINKT_A_Structure-Aware_Inductive_Knowledge_Tracing_Model_with_Large_Language_Model.md)

    - [翻译: SINKT：结合大型语言模型的结构感知归纳知识追踪模型](2024年07月01日/SINKT_A_Structure-Aware_Inductive_Knowledge_Tracing_Model_with_Large_Language_Model.md)

- [Large Language Models are Zero-Shot Recognizers for Activities of Daily Living](2024年07月01日/Large_Language_Models_are_Zero-Shot_Recognizers_for_Activities_of_Daily_Living.md)

    - [翻译: 大型语言模型能够零-shot 识别日常活动](2024年07月01日/Large_Language_Models_are_Zero-Shot_Recognizers_for_Activities_of_Daily_Living.md)

- [A Fingerprint for Large Language Models](2024年07月01日/A_Fingerprint_for_Large_Language_Models.md)

    - [翻译: 大型语言模型的独特印记](2024年07月01日/A_Fingerprint_for_Large_Language_Models.md)

- [MIRAI: Evaluating LLM Agents for Event Forecasting](2024年07月01日/MIRAI_Evaluating_LLM_Agents_for_Event_Forecasting.md)

    - [翻译: MIRAI：评估大型语言模型代理在事件预测中的效能](2024年07月01日/MIRAI_Evaluating_LLM_Agents_for_Event_Forecasting.md)

- [Searching for Best Practices in Retrieval-Augmented Generation](2024年07月01日/Searching_for_Best_Practices_in_Retrieval-Augmented_Generation.md)

    - [翻译: 探寻检索增强生成领域的最佳实践](2024年07月01日/Searching_for_Best_Practices_in_Retrieval-Augmented_Generation.md)

- [EconNLI: Evaluating Large Language Models on Economics Reasoning](2024年07月01日/EconNLI_Evaluating_Large_Language_Models_on_Economics_Reasoning.md)

    - [翻译: EconNLI：探究大型语言模型在经济学推理领域的评估](2024年07月01日/EconNLI_Evaluating_Large_Language_Models_on_Economics_Reasoning.md)

- [TCSR-SQL: Towards Table Content-aware Text-to-SQL with Self-retrieval](2024年07月01日/TCSR-SQL_Towards_Table_Content-aware_Text-to-SQL_with_Self-retrieval.md)

    - [翻译: TCSR-SQL：借助自检索技术，实现对表格内容的智能感知，进而生成SQL语句。](2024年07月01日/TCSR-SQL_Towards_Table_Content-aware_Text-to-SQL_with_Self-retrieval.md)

- [: Language Modeling with Explicit Memory](2024年07月01日/_Language_Modeling_with_Explicit_Memory.md)

    - [翻译: 语言建模中的显式记忆技术](2024年07月01日/_Language_Modeling_with_Explicit_Memory.md)

- [GazeNoter: Co-Piloted AR Note-Taking via Gaze Selection of LLM Suggestions to Match Users' Intentions](2024年07月01日/GazeNoter_Co-Piloted_AR_Note-Taking_via_Gaze_Selection_of_LLM_Suggestions_to_Match_Users'_Intentions.md)

    - [翻译: GazeNoter：一种协同增强现实笔记工具，通过目光选择大型语言模型建议，精准匹配用户意图。](2024年07月01日/GazeNoter_Co-Piloted_AR_Note-Taking_via_Gaze_Selection_of_LLM_Suggestions_to_Match_Users'_Intentions.md)

- [Learning to Explore and Select for Coverage-Conditioned Retrieval-Augmented Generation](2024年07月01日/Learning_to_Explore_and_Select_for_Coverage-Conditioned_Retrieval-Augmented_Generation.md)

    - [翻译: 探索与选择学习：覆盖条件下的检索增强生成](2024年07月01日/Learning_to_Explore_and_Select_for_Coverage-Conditioned_Retrieval-Augmented_Generation.md)

- [CPT: Consistent Proxy Tuning for Black-box Optimization](2024年07月01日/CPT_Consistent_Proxy_Tuning_for_Black-box_Optimization.md)

    - [翻译: CPT：实现黑盒优化中一致性的代理调优方法](2024年07月01日/CPT_Consistent_Proxy_Tuning_for_Black-box_Optimization.md)

- [Calibrated Large Language Models for Binary Question Answering](2024年07月01日/Calibrated_Large_Language_Models_for_Binary_Question_Answering.md)

    - [翻译: 大型语言模型经过校准，专为二元问答设计](2024年07月01日/Calibrated_Large_Language_Models_for_Binary_Question_Answering.md)

- [Pron vs Prompt: Can Large Language Models already Challenge a World-Class Fiction Author at Creative Text Writing?](2024年07月01日/Pron_vs_Prompt_Can_Large_Language_Models_already_Challenge_a_World-Class_Fiction_Author_at_Creative_Text_Writing.md)

    - [翻译: 大型语言模型与世界级小说作者在创意写作上的较量：Pron vs Prompt，究竟谁能胜出？](2024年07月01日/Pron_vs_Prompt_Can_Large_Language_Models_already_Challenge_a_World-Class_Fiction_Author_at_Creative_Text_Writing.md)

- [BERGEN: A Benchmarking Library for Retrieval-Augmented Generation](2024年07月01日/BERGEN_A_Benchmarking_Library_for_Retrieval-Augmented_Generation.md)

    - [翻译: BERGEN：一款专为检索增强生成技术打造的基准库](2024年07月01日/BERGEN_A_Benchmarking_Library_for_Retrieval-Augmented_Generation.md)

- [IBSEN: Director-Actor Agent Collaboration for Controllable and Interactive Drama Script Generation](2024年07月01日/IBSEN_Director-Actor_Agent_Collaboration_for_Controllable_and_Interactive_Drama_Script_Generation.md)

    - [翻译: IBSEN 系统通过导演与演员代理的协作，实现了可控且互动的戏剧剧本生成。](2024年07月01日/IBSEN_Director-Actor_Agent_Collaboration_for_Controllable_and_Interactive_Drama_Script_Generation.md)

- [Rethinking LLM-based Preference Evaluation](2024年07月01日/Rethinking_LLM-based_Preference_Evaluation.md)

    - [翻译: 重新审视基于LLM的偏好评估方法](2024年07月01日/Rethinking_LLM-based_Preference_Evaluation.md)

- [First Place Solution of 2023 Global Artificial Intelligence Technology Innovation Competition Track 1](2024年07月01日/First_Place_Solution_of_2023_Global_Artificial_Intelligence_Technology_Innovation_Competition_Track_1.md)

    - [翻译: 2023年全球AI技术创新大赛第一赛道冠军方案](2024年07月01日/First_Place_Solution_of_2023_Global_Artificial_Intelligence_Technology_Innovation_Competition_Track_1.md)

- [SecGenAI: Enhancing Security of Cloud-based Generative AI Applications within Australian Critical Technologies of National Interest](2024年07月01日/SecGenAI_Enhancing_Security_of_Cloud-based_Generative_AI_Applications_within_Australian_Critical_Technologies_of_National_Interest.md)

    - [翻译: SecGenAI：提升澳大利亚关键技术领域内云端生成式AI应用的安全防护](2024年07月01日/SecGenAI_Enhancing_Security_of_Cloud-based_Generative_AI_Applications_within_Australian_Critical_Technologies_of_National_Interest.md)

- [Eliminating Position Bias of Language Models: A Mechanistic Approach](2024年07月01日/Eliminating_Position_Bias_of_Language_Models_A_Mechanistic_Approach.md)

    - [翻译: 解决语言模型中的位置偏差问题：一种机制性解决方案](2024年07月01日/Eliminating_Position_Bias_of_Language_Models_A_Mechanistic_Approach.md)

- [Face4RAG: Factual Consistency Evaluation for Retrieval Augmented Generation in Chinese](2024年07月01日/Face4RAG_Factual_Consistency_Evaluation_for_Retrieval_Augmented_Generation_in_Chinese.md)

    - [翻译: Face4RAG：评估中文检索增强生成的事实一致性工具](2024年07月01日/Face4RAG_Factual_Consistency_Evaluation_for_Retrieval_Augmented_Generation_in_Chinese.md)

- [Hybrid RAG-empowered Multi-modal LLM for Secure Healthcare Data Management: A Diffusion-based Contract Theory Approach](2024年07月01日/Hybrid_RAG-empowered_Multi-modal_LLM_for_Secure_Healthcare_Data_Management_A_Diffusion-based_Contract_Theory_Approach.md)

    - [翻译: 采用混合 RAG 增强的多模态 LLM，结合基于扩散的合同理论，为安全医疗数据管理提供创新解决方案。](2024年07月01日/Hybrid_RAG-empowered_Multi-modal_LLM_for_Secure_Healthcare_Data_Management_A_Diffusion-based_Contract_Theory_Approach.md)

- [Data on the Move: Traffic-Oriented Data Trading Platform Powered by AI Agent with Common Sense](2024年07月01日/Data_on_the_Move_Traffic-Oriented_Data_Trading_Platform_Powered_by_AI_Agent_with_Common_Sense.md)

    - [翻译: 数据动态交易：基于常识AI代理的流量导向数据平台](2024年07月01日/Data_on_the_Move_Traffic-Oriented_Data_Trading_Platform_Powered_by_AI_Agent_with_Common_Sense.md)

- [Mobile-Bench: An Evaluation Benchmark for LLM-based Mobile Agents](2024年07月01日/Mobile-Bench_An_Evaluation_Benchmark_for_LLM-based_Mobile_Agents.md)

    - [翻译: 移动-Bench：一个针对基于 LLM 的移动代理的评估基准](2024年07月01日/Mobile-Bench_An_Evaluation_Benchmark_for_LLM-based_Mobile_Agents.md)

- [Human-like object concept representations emerge naturally in multimodal large language models](2024年07月01日/Human-like_object_concept_representations_emerge_naturally_in_multimodal_large_language_models.md)

    - [翻译: 多模态大型语言模型中，类人对象概念的表示自然而然地形成。](2024年07月01日/Human-like_object_concept_representations_emerge_naturally_in_multimodal_large_language_models.md)

- [Empathic Grounding: Explorations using Multimodal Interaction and Large Language Models with Conversational Agents](2024年07月01日/Empathic_Grounding_Explorations_using_Multimodal_Interaction_and_Large_Language_Models_with_Conversational_Agents.md)

    - [翻译: 共情基础探索：通过多模态交互与大型语言模型，与对话代理共同探索共情机制。](2024年07月01日/Empathic_Grounding_Explorations_using_Multimodal_Interaction_and_Large_Language_Models_with_Conversational_Agents.md)

- [Ground Every Sentence: Improving Retrieval-Augmented LLMs with Interleaved Reference-Claim Generation](2024年07月01日/Ground_Every_Sentence_Improving_Retrieval-Augmented_LLMs_with_Interleaved_Reference-Claim_Generation.md)

    - [翻译: 每一句都夯实：通过交错引用与声明生成，提升检索增强型大型语言模型的性能](2024年07月01日/Ground_Every_Sentence_Improving_Retrieval-Augmented_LLMs_with_Interleaved_Reference-Claim_Generation.md)

- [Text-Aware Diffusion for Policy Learning](2024年07月01日/Text-Aware_Diffusion_for_Policy_Learning.md)

    - [翻译: 文本感知扩散在政策学习中的应用](2024年07月01日/Text-Aware_Diffusion_for_Policy_Learning.md)

- [GRASP: A Grid-Based Benchmark for Evaluating Commonsense Spatial Reasoning](2024年07月01日/GRASP_A_Grid-Based_Benchmark_for_Evaluating_Commonsense_Spatial_Reasoning.md)

    - [翻译: GRASP：一款基于网格的基准测试，专为评估常识空间推理能力而设计。](2024年07月01日/GRASP_A_Grid-Based_Benchmark_for_Evaluating_Commonsense_Spatial_Reasoning.md)