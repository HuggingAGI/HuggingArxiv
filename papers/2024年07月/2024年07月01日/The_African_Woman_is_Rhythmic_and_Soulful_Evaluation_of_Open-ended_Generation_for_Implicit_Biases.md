# 非洲女性，节奏与灵魂的化身：探索隐性偏见在开放式生成中的表现

发布时间：2024年07月01日

`LLM理论` `人工智能伦理` `心理学`

> The African Woman is Rhythmic and Soulful: Evaluation of Open-ended Generation for Implicit Biases

# 摘要

> 本研究深入探讨了大型语言模型（LLM）中不易察觉的隐性偏见，这些偏见即便在通过显性测试后，仍可能隐晦地显现，类似于那些自称平等主义者却潜藏偏见的人。随着LLM的专有化加深，对关键内部机制如嵌入的访问受限，这使得传统偏见测量方法面临更大挑战。为此，本研究创新性地引入了基于心理学方法的偏见测量：LLM隐性联想测试（IAT）偏见和LLM决策偏见。前者通过模拟心理学IAT揭示LLM的隐性偏见，后者则专注于检测LLM在决策中的微妙歧视。实验结果显示，LLM在性别和种族领域存在从分类歧视到异国情调化的偏见。研究证实，基于提示的隐性偏见测量不仅与传统方法相关，还能更精准地预测下游行为，凸显了相对评估在偏见评估中的重要性。这项研究不仅增进了对AI伦理的理解，还为持续优化和减少AI系统中的偏见提供了方向，强调了定性和下游分析的重要性。

> This study investigates the subtle and often concealed biases present in Large Language Models (LLMs), which, despite passing explicit bias tests, can still exhibit implicit biases akin to those observed in humans who profess egalitarian beliefs yet demonstrate underlying prejudices. The challenge of measuring such biases is exacerbated as LLMs become increasingly proprietary, restricting access to their internal mechanisms such as embeddings, which are crucial for applying traditional bias measures. To tackle these issues, this study introduces innovative measures of bias inspired by psychological methodologies: the LLM Implicit Association Test (IAT) Bias and the LLM Decision Bias. The LLM IAT Bias is a prompt-based method designed to unearth implicit biases by simulating the well-known psychological IAT but adapted for use with LLMs. The LLM Decision Bias measure is developed to detect subtle discrimination in decision-making tasks, focusing on how LLMs choose between individuals in various scenarios. Open-ended generation is also utilised through thematic analysis of word generations and storytelling. The experiments revealed biases across gender and racial domains, from discriminatory categorisations to exoticisation. Our findings indicate that the prompt-based measure of implicit bias not only correlates with traditional embedding-based methods but also more effectively predicts downstream behaviors, which are crucially measured by the LLM Decision Bias. This relationship underscores the importance of relative, rather than absolute, evaluations in assessing implicit biases, reflecting psychological insights into human bias assessment. This research contributes to the broader understanding of AI ethics and provides suggestions for continually assessing and mitigating biases in advanced AI systems, emphasising the need for more qualitative and downstream focus.

[Arxiv](https://arxiv.org/abs/2407.01270)