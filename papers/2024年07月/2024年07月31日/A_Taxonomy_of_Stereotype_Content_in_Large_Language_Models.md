# 大型语言模型中刻板印象内容的分类研究

发布时间：2024年07月31日

`LLM理论` `人工智能` `社会科学`

> A Taxonomy of Stereotype Content in Large Language Models

# 摘要

> 本研究创新性地提出了一种针对现代大型语言模型（LLM）中刻板印象内容的分类体系。我们针对 ChatGPT 3.5、Llama 3 和 Mixtral 8x7B 这三款广泛应用的 LLM，探讨了与 87 个社会类别相关的特征，并识别出 14 个刻板印象维度，涵盖了 LLM 刻板印象关联的约 90%。其中，“温暖”与“能力”最为常见，其他维度也普遍存在。尽管 LLM 中的刻板印象整体偏向积极，但在不同类别和维度上仍存在显著差异。此外，该分类体系还能预测 LLM 对社会类别的内部评价，凸显了多维分类法在刻画 LLM 刻板印象中的重要性。研究结果提示，LLM 中映射的高维人类刻板印象，在 AI 审计和去偏过程中不容忽视，以避免因低维视角导致的潜在伤害。

> This study introduces a taxonomy of stereotype content in contemporary large language models (LLMs). We prompt ChatGPT 3.5, Llama 3, and Mixtral 8x7B, three powerful and widely used LLMs, for the characteristics associated with 87 social categories (e.g., gender, race, occupations). We identify 14 stereotype dimensions (e.g., Morality, Ability, Health, Beliefs, Emotions), accounting for ~90% of LLM stereotype associations. Warmth and Competence facets were the most frequent content, but all other dimensions were significantly prevalent. Stereotypes were more positive in LLMs (vs. humans), but there was significant variability across categories and dimensions. Finally, the taxonomy predicted the LLMs' internal evaluations of social categories (e.g., how positively/negatively the categories were represented), supporting the relevance of a multidimensional taxonomy for characterizing LLM stereotypes. Our findings suggest that high-dimensional human stereotypes are reflected in LLMs and must be considered in AI auditing and debiasing to minimize unidentified harms from reliance in low-dimensional views of bias in LLMs.

[Arxiv](https://arxiv.org/abs/2408.00162)