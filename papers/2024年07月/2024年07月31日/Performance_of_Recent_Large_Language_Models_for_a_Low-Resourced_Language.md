# 探讨近期大型语言模型在低资源语言领域的性能表现

发布时间：2024年07月31日

`LLM应用` `人工智能` `语言处理`

> Performance of Recent Large Language Models for a Low-Resourced Language

# 摘要

> 过去一年，大型语言模型（LLM）取得了显著进展，包括新版GPT和Llama在内的多种模型相继问世，其中不乏开放源码的版本。然而，这些多语言模型在处理僧伽罗语等低资源语言时表现欠佳。我们针对四种最新LLM进行了僧伽罗语直接应用及英译中转的测试，并考察了它们在小规模微调数据下的适应性。结果显示，Claude和GPT 4o无需额外调整即表现出色，较旧版本有显著提升；而Llama和Mistral虽初始表现平平，但通过微调展现了改进空间。

> Large Language Models (LLMs) have shown significant advances in the past year. In addition to new versions of GPT and Llama, several other LLMs have been introduced recently. Some of these are open models available for download and modification.
  Although multilingual large language models have been available for some time, their performance on low-resourced languages such as Sinhala has been poor. We evaluated four recent LLMs on their performance directly in the Sinhala language, and by translation to and from English. We also evaluated their fine-tunability with a small amount of fine-tuning data. Claude and GPT 4o perform well out-of-the-box and do significantly better than previous versions. Llama and Mistral perform poorly but show some promise of improvement with fine tuning.

[Arxiv](https://arxiv.org/abs/2407.21330)