# BRIGHT：一个真实且充满挑战的基准，专为推理密集型检索任务设计。

发布时间：2024年07月16日

`LLM应用` `信息检索` `人工智能`

> BRIGHT: A Realistic and Challenging Benchmark for Reasoning-Intensive Retrieval

# 摘要

> 现有的检索基准多聚焦于简单的信息查询，但面对复杂查询时，深入推理变得至关重要。为此，我们推出了BRIGHT，首个要求深度推理的文本检索基准。BRIGHT汇集了来自多个领域的1,398个真实查询，挑战了现有模型的极限。评估显示，顶尖模型在BRIGHT上的表现也大幅下滑。通过引入大型语言模型的思维链推理，我们提升了检索性能，同时确保了基准的鲁棒性。BRIGHT不仅为检索研究开辟了新路径，还提供了代码和数据供社区使用。

> Existing retrieval benchmarks primarily consist of information-seeking queries (e.g., aggregated questions from search engines) where keyword or semantic-based retrieval is usually sufficient. However, many complex real-world queries require in-depth reasoning to identify relevant documents that go beyond surface form matching. For example, finding documentation for a coding question requires understanding the logic and syntax of the functions involved. To better benchmark retrieval on such challenging queries, we introduce BRIGHT, the first text retrieval benchmark that requires intensive reasoning to retrieve relevant documents. BRIGHT is constructed from the 1,398 real-world queries collected from diverse domains (such as economics, psychology, robotics, software engineering, earth sciences, etc.), sourced from naturally occurring or carefully curated human data. Extensive evaluation reveals that even state-of-the-art retrieval models perform poorly on BRIGHT. The leading model on the MTEB leaderboard [38 ], which achieves a score of 59.0 nDCG@10,2 produces a score of nDCG@10 of 18.0 on BRIGHT. We further demonstrate that augmenting queries with Chain-of-Thought reasoning generated by large language models (LLMs) improves performance by up to 12.2 points. Moreover, BRIGHT is robust against data leakage during pretraining of the benchmarked models as we validate by showing similar performance even when documents from the benchmark are included in the training data. We believe that BRIGHT paves the way for future research on retrieval systems in more realistic and challenging settings. Our code and data are available at https://brightbenchmark.github.io.

[Arxiv](https://arxiv.org/abs/2407.12883)