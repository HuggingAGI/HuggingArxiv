# 计算模型：自动化识别还是辅助分析？探讨其在美资本审判笔录性别话语中的角色。

发布时间：2024年07月17日

`LLM应用` `人工智能`

> Automate or Assist? The Role of Computational Models in Identifying Gendered Discourse in US Capital Trial Transcripts

# 摘要

> 长期以来，美国刑事审判中使用的语言因其潜在的偏见而受到关注。然而，由于偏见的复杂性和法律专业知识的必要性，系统性地研究高风险审判中的偏见一直颇具挑战。新兴的大型语言模型为自动化注释带来了希望，有望节省时间和成本。但要确保这些方法的有效性，不仅需要高水平的性能，还需深入理解它们如何融入现有工作流程及其真正的价值所在。本文通过一个案例研究，探讨了在识别针对女性被告的性别偏见语言这一高风险问题中引入自动化系统的可行性。我们的团队由资深死刑律师和NLP专家组成，分三阶段进行研究：先手动注释，再训练评估模型，最后对比人工与模型的结果。与常规NLP任务不同，对长时间死刑审判中的性别偏见进行注释极为复杂，涉及众多个人判断。法律专家发现，计算模型在挑战个人偏见、促进注释规则的完善与共识构建方面尤为有效。这表明，完全依赖模型取代专家既不现实也不可取，计算模型应作为辅助工具，为法律专家提供支持。

> The language used by US courtroom actors in criminal trials has long been studied for biases. However, systematic studies for bias in high-stakes court trials have been difficult, due to the nuanced nature of bias and the legal expertise required. New large language models offer the possibility to automate annotation, saving time and cost. But validating these approaches requires both high quantitative performance as well as an understanding of how automated methods fit in existing workflows, and what they really offer. In this paper we present a case study of adding an automated system to a complex and high-stakes problem: identifying gender-biased language in US capital trials for women defendants. Our team of experienced death-penalty lawyers and NLP technologists pursued a three-phase study: first annotating manually, then training and evaluating computational models, and finally comparing human annotations to model predictions. Unlike many typical NLP tasks, annotating for gender bias in months-long capital trials was a complicated task that involves with many individual judgment calls. In contrast to standard arguments for automation that are based on efficiency and scalability, legal experts found the computational models most useful in challenging their personal bias in annotation and providing opportunities to refine and build consensus on rules for annotation. This suggests that seeking to replace experts with computational models is both unrealistic and undesirable. Rather, computational models offer valuable opportunities to assist the legal experts in annotation-based studies.

[Arxiv](https://arxiv.org/abs/2407.12500)