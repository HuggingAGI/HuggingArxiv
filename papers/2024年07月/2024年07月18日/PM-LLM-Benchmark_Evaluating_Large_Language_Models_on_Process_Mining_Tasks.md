# PM-LLM-Benchmark：评估大型语言模型在过程挖掘任务上的表现

发布时间：2024年07月18日

`LLM应用` `制造业` `信息技术`

> PM-LLM-Benchmark: Evaluating Large Language Models on Process Mining Tasks

# 摘要

> 大型语言模型 (LLMs) 在半自动化过程挖掘 (PM) 分析方面展现出潜力。尽管商业模型已能胜任众多分析任务，但开源 LLMs 在 PM 领域的竞争实力仍待揭晓。本文首创 PM-LLM-Benchmark，聚焦于领域知识（过程挖掘与过程特定知识）及实施策略的多样性。同时，我们也探讨了构建此类基准的挑战，包括数据公开性与 LLMs 评估偏差。研究发现，多数 LLMs 能较好地完成部分 PM 任务，但适用于边缘设备的小型模型仍显不足。此外，我们强调，该基准虽有助于筛选适合 PM 任务的 LLMs，但消除评估偏差、全面评估竞争性 LLMs 仍需深入研究。

> Large Language Models (LLMs) have the potential to semi-automate some process mining (PM) analyses. While commercial models are already adequate for many analytics tasks, the competitive level of open-source LLMs in PM tasks is unknown. In this paper, we propose PM-LLM-Benchmark, the first comprehensive benchmark for PM focusing on domain knowledge (process-mining-specific and process-specific) and on different implementation strategies. We focus also on the challenges in creating such a benchmark, related to the public availability of the data and on evaluation biases by the LLMs. Overall, we observe that most of the considered LLMs can perform some process mining tasks at a satisfactory level, but tiny models that would run on edge devices are still inadequate. We also conclude that while the proposed benchmark is useful for identifying LLMs that are adequate for process mining tasks, further research is needed to overcome the evaluation biases and perform a more thorough ranking of the competitive LLMs.

[Arxiv](https://arxiv.org/abs/2407.13244)