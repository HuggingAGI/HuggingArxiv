# 大规模网络挖掘语料库在大型语言模型预训练中的挑战概览

发布时间：2024年07月10日

`LLM理论` `人工智能` `网络安全`

> A Review of the Challenges with Massive Web-mined Corpora Used in Large Language Models Pre-Training

# 摘要

> 本文全面探讨了利用网络挖掘的大规模语料库进行 LLM 预训练时遇到的难题，如噪声、内容重复、信息质量低下、偏见及敏感个人信息的包含等。解决这些挑战对于构建准确、可靠且符合伦理的语言模型至关重要。我们通过分析现有的数据处理和偏见管理技术，指出了现有方法的不足，并提出了未来研究的方向，旨在推动更先进、更符合伦理的 LLM 的发展。

> This article presents a comprehensive review of the challenges associated with using massive web-mined corpora for the pre-training of large language models (LLMs). This review identifies key challenges in this domain, including challenges such as noise (irrelevant or misleading information), duplication of content, the presence of low-quality or incorrect information, biases, and the inclusion of sensitive or personal information in web-mined corpora. Addressing these issues is crucial for the development of accurate, reliable, and ethically responsible language models. Through an examination of current methodologies for data cleaning, pre-processing, bias detection and mitigation, we highlight the gaps in existing approaches and suggest directions for future research. Our discussion aims to catalyze advancements in developing more sophisticated and ethically responsible LLMs.

[Arxiv](https://arxiv.org/abs/2407.07630)