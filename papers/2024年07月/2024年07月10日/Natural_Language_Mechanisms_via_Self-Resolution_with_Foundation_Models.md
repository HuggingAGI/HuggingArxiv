# 基于基础模型的自我解析机制在自然语言处理中的应用

发布时间：2024年07月10日

`Agent` `人工智能`

> Natural Language Mechanisms via Self-Resolution with Foundation Models

# 摘要

> 我们提出了一种新机制，允许代理以自然语言报告，并借助LLM的世界建模能力来决定结果和报酬分配。这种机制在LLM作为优秀世界模型和强信息过度确定条件下，既能激励兼容又高效。我们还展示了这种基于语言模型的机制在预测市场失效的情况下，如何成功整合信息。

> Practical mechanisms often limit agent reports to constrained formats like trades or orderings, potentially limiting the information agents can express. We propose a novel class of mechanisms that elicit agent reports in natural language and leverage the world-modeling capabilities of large language models (LLMs) to select outcomes and assign payoffs. We identify sufficient conditions for these mechanisms to be incentive-compatible and efficient as the LLM being a good enough world model and a strong inter-agent information over-determination condition. We show situations where these LM-based mechanisms can successfully aggregate information in signal structures on which prediction markets fail.

[Arxiv](https://arxiv.org/abs/2407.07845)