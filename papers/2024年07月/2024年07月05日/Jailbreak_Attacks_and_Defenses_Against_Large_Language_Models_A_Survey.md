# 大型语言模型面临的越狱攻击及其防御策略：全面调查

发布时间：2024年07月05日

`LLM理论` `网络安全` `人工智能`

> Jailbreak Attacks and Defenses Against Large Language Models: A Survey

# 摘要

> 大型语言模型在多项文本生成任务中表现卓越，但过度辅助也带来了“越狱”风险，即通过对抗性提示诱导模型产生违规的恶意回应。随着越狱攻击手段的多样化，安全防护措施也在不断进化。本文中，我们详尽地分类了越狱攻击与防御策略，如根据模型透明度划分的黑盒与白盒攻击，以及提示级与模型级的防御措施。我们进一步细分这些策略，并通过图表清晰展示其关联。此外，我们还审视了现有的评估方法，并进行了多角度比较。我们的研究旨在启发未来在提升 LLM 安全性方面的探索与实践。尽管越狱问题仍备受关注，我们相信本研究深化了对此领域的认识，并为构建更安全的语言模型奠定了基础。

> Large Language Models (LLMs) have performed exceptionally in various text-generative tasks, including question answering, translation, code completion, etc. However, the over-assistance of LLMs has raised the challenge of "jailbreaking", which induces the model to generate malicious responses against the usage policy and society by designing adversarial prompts. With the emergence of jailbreak attack methods exploiting different vulnerabilities in LLMs, the corresponding safety alignment measures are also evolving. In this paper, we propose a comprehensive and detailed taxonomy of jailbreak attack and defense methods. For instance, the attack methods are divided into black-box and white-box attacks based on the transparency of the target model. Meanwhile, we classify defense methods into prompt-level and model-level defenses. Additionally, we further subdivide these attack and defense methods into distinct sub-classes and present a coherent diagram illustrating their relationships. We also conduct an investigation into the current evaluation methods and compare them from different perspectives. Our findings aim to inspire future research and practical implementations in safeguarding LLMs against adversarial attacks. Above all, although jailbreak remains a significant concern within the community, we believe that our work enhances the understanding of this domain and provides a foundation for developing more secure LLMs.

![大型语言模型面临的越狱攻击及其防御策略：全面调查](../../../paper_images/2407.04295/x1.png)

![大型语言模型面临的越狱攻击及其防御策略：全面调查](../../../paper_images/2407.04295/x2.png)

![大型语言模型面临的越狱攻击及其防御策略：全面调查](../../../paper_images/2407.04295/x3.png)

![大型语言模型面临的越狱攻击及其防御策略：全面调查](../../../paper_images/2407.04295/x4.png)

![大型语言模型面临的越狱攻击及其防御策略：全面调查](../../../paper_images/2407.04295/x5.png)

![大型语言模型面临的越狱攻击及其防御策略：全面调查](../../../paper_images/2407.04295/x6.png)

[Arxiv](https://arxiv.org/abs/2407.04295)