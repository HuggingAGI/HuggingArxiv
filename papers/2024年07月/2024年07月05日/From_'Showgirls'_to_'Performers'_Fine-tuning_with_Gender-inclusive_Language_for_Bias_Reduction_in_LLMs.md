# 从“Showgirls”到“Performers”：通过性别包容性语言的微调，减少 LLM 中的偏见

发布时间：2024年07月05日

`LLM应用` `人工智能` `性别研究`

> From 'Showgirls' to 'Performers': Fine-tuning with Gender-inclusive Language for Bias Reduction in LLMs

# 摘要

> 性别偏见不仅在大型语言模型（LLM）及其训练数据中普遍存在，还深植于语言结构之中。为此，我们专注于调整LLM训练数据，以增强性别包容性，使模型中的性别表达更加多元。我们特别关注英语中的性别排他性词缀，如'show-girl'和'man-cave'，这些词缀强化了性别刻板印象和二元性别观。通过构建包含692个性别排他词汇及其中性替代的目录，我们开发了名为'Tiny Heap'的性别包容微调数据集。实验表明，使用该数据集微调LLM后，模型中的性别刻板印象显著减少。这一方法不仅提升了LLM训练数据的性别包容性，还为NLP领域的偏见缓解研究引入了酷儿女性主义语言行动主义。

> Gender bias is not only prevalent in Large Language Models (LLMs) and their training data, but also firmly ingrained into the structural aspects of language itself. Therefore, adapting linguistic structures within LLM training data to promote gender-inclusivity can make gender representations within the model more inclusive. The focus of our work are gender-exclusive affixes in English, such as in 'show-girl' or 'man-cave', which can perpetuate gender stereotypes and binary conceptions of gender. We use an LLM training dataset to compile a catalogue of 692 gender-exclusive terms along with gender-neutral variants and from this, develop a gender-inclusive fine-tuning dataset, the 'Tiny Heap'. Fine-tuning three different LLMs with this dataset, we observe an overall reduction in gender-stereotyping tendencies across the models. Our approach provides a practical method for enhancing gender inclusivity in LLM training data and contributes to incorporating queer-feminist linguistic activism in bias mitigation research in NLP.

[Arxiv](https://arxiv.org/abs/2407.04434)