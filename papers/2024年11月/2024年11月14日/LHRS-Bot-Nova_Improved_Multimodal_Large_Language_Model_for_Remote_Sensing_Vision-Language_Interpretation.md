# LHRS-Bot-Nova：用于遥感视觉语言解读的优化多模态大型语言模型

发布时间：2024年11月14日

`LLM应用` `地球观测`

> LHRS-Bot-Nova: Improved Multimodal Large Language Model for Remote Sensing Vision-Language Interpretation

# 摘要

> 自动且迅速地理解地球表面，对我们掌控生活环境和做出明智决策意义重大。这凸显出我们需要一个具备全面分析地球表面能力的统一系统，以满足人类的广泛需求。多模态大型语言模型（MLLMs）的出现，在提升智能地球观测的效率和便利性方面潜力巨大。这些模型能像人类一样交流，充当理解图像的统一平台，遵循各类指令，并给出有价值的反馈。在本研究中，我们介绍了 LHRS-Bot-Nova，这是一个专注于理解遥感（RS）图像的 MLLM，能够出色地完成与人类指令相符的众多 RS 理解任务。LHRS-Bot-Nova 配备了增强的视觉编码器和新颖的桥接层，可实现高效的视觉压缩以及更优的语言 - 视觉对齐。为进一步强化面向 RS 的视觉 - 语言对齐，我们提出了一个通过特征引导的图像重新描述生成的大规模 RS 图像 - 标题数据集。此外，我们引入了专门用于提升空间识别能力的指令数据集。大量实验表明，LHRS-Bot-Nova 在各类 RS 图像理解任务中表现卓越。我们还通过复杂的多项选择问题评估基准，评估了不同 MLLM 在复杂的 RS 感知和指令遵循方面的性能，为未来的模型选择和改进提供了可靠指引。数据、代码和模型可在 https://github.com/NJU-LHRS/LHRS-Bot 获取。

> Automatically and rapidly understanding Earth's surface is fundamental to our grasp of the living environment and informed decision-making. This underscores the need for a unified system with comprehensive capabilities in analyzing Earth's surface to address a wide range of human needs. The emergence of multimodal large language models (MLLMs) has great potential in boosting the efficiency and convenience of intelligent Earth observation. These models can engage in human-like conversations, serve as unified platforms for understanding images, follow diverse instructions, and provide insightful feedbacks. In this study, we introduce LHRS-Bot-Nova, an MLLM specialized in understanding remote sensing (RS) images, designed to expertly perform a wide range of RS understanding tasks aligned with human instructions. LHRS-Bot-Nova features an enhanced vision encoder and a novel bridge layer, enabling efficient visual compression and better language-vision alignment. To further enhance RS-oriented vision-language alignment, we propose a large-scale RS image-caption dataset, generated through feature-guided image recaptioning. Additionally, we introduce an instruction dataset specifically designed to improve spatial recognition abilities. Extensive experiments demonstrate superior performance of LHRS-Bot-Nova across various RS image understanding tasks. We also evaluate different MLLM performances in complex RS perception and instruction following using a complicated multi-choice question evaluation benchmark, providing a reliable guide for future model selection and improvement. Data, code, and models will be available at https://github.com/NJU-LHRS/LHRS-Bot.

[Arxiv](https://arxiv.org/abs/2411.09301)