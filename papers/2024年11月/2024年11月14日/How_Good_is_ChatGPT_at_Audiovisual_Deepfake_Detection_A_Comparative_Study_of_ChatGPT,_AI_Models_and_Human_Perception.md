# ChatGPT 在视听深度伪造检测中的表现究竟怎样：关于 ChatGPT、AI 模型与人类感知的比较研究

发布时间：2024年11月14日

`LLM应用` `多媒体`

> How Good is ChatGPT at Audiovisual Deepfake Detection: A Comparative Study of ChatGPT, AI Models and Human Perception

# 摘要

> 涉及视听操纵的多模态深度伪造正成为日益严峻的威胁，因其难以凭肉眼或单模态基于深度学习的伪造检测手段察觉。视听取证模型虽比单模态模型更强，但需要庞大的训练数据集，且训练和推理的计算成本颇高。而且，这些模型缺乏可解释性，对未曾见过的操纵通常泛化能力不佳。本研究考查了大型语言模型（LLM）（比如 ChatGPT）的检测能力，以识别并阐释视听深度伪造内容中可能存在的任何视觉和听觉伪影及操纵。在基准多模态深度伪造数据集的视频上开展了大量实验，评估 ChatGPT 的检测性能，并与最先进的多模态取证模型及人类的检测能力作对比。实验结果显示，领域知识和提示工程对于利用 LLM 完成视频伪造检测任务至关重要。和基于端到端学习的方法不同，ChatGPT 能够解释可能存在于模态内部或跨模态的空间和时空伪影及不一致性。另外，我们还探讨了 ChatGPT 在多媒体取证任务中的局限性。

> Multimodal deepfakes involving audiovisual manipulations are a growing threat because they are difficult to detect with the naked eye or using unimodal deep learningbased forgery detection methods. Audiovisual forensic models, while more capable than unimodal models, require large training datasets and are computationally expensive for training and inference. Furthermore, these models lack interpretability and often do not generalize well to unseen manipulations. In this study, we examine the detection capabilities of a large language model (LLM) (i.e., ChatGPT) to identify and account for any possible visual and auditory artifacts and manipulations in audiovisual deepfake content. Extensive experiments are conducted on videos from a benchmark multimodal deepfake dataset to evaluate the detection performance of ChatGPT and compare it with the detection capabilities of state-of-the-art multimodal forensic models and humans. Experimental results demonstrate the importance of domain knowledge and prompt engineering for video forgery detection tasks using LLMs. Unlike approaches based on end-to-end learning, ChatGPT can account for spatial and spatiotemporal artifacts and inconsistencies that may exist within or across modalities. Additionally, we discuss the limitations of ChatGPT for multimedia forensic tasks.

[Arxiv](https://arxiv.org/abs/2411.09266)