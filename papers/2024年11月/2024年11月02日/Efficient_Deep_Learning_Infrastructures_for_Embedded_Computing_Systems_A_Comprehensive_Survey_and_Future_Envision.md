# 关于嵌入式计算系统的高效深度学习基础设施：全面调研与未来展望

发布时间：2024年11月02日

`其他` `嵌入式计算`

> Efficient Deep Learning Infrastructures for Embedded Computing Systems: A Comprehensive Survey and Future Envision

# 摘要

> 深神经网络（DNNs）近来在众多现实世界的视觉和语言处理任务中成绩斐然，从图像分类到物体检测、跟踪及分割等不一而足。然而，此前已成熟的DNNs，虽能保持超高的准确率，却也在朝着更深更宽的方向发展，这就必然需要大量的计算资源用于训练和推理。此趋势进一步拉大了计算密集型DNNs与资源受限的嵌入式计算系统之间的计算差距，致使在现实世界的嵌入式计算系统上部署强大的DNNs以实现无所不在的嵌入式智能困难重重。为了缩小上述计算差距并达成无所不在的嵌入式智能，在本次调研中，我们着重探讨了近期面向嵌入式计算系统的高效深度学习基础设施，包括从训练到推理，从手动到自动，从卷积神经网络到变形器，从变形器到视觉变形器，从视觉模型到大型语言模型，从软件到硬件，从算法到应用。具体来说，我们从以下几个方面探讨了面向嵌入式计算系统的近期高效深度学习基础设施：（1）嵌入式计算系统的高效手动网络设计，（2）嵌入式计算系统的高效自动网络设计，（3）嵌入式计算系统的高效网络压缩，（4）嵌入式计算系统的高效设备端学习，（5）嵌入式计算系统的高效大型语言模型，（6）嵌入式计算系统的高效深度学习软硬件，（7）嵌入式计算系统的高效智能应用。

> Deep neural networks (DNNs) have recently achieved impressive success across a wide range of real-world vision and language processing tasks, spanning from image classification to many other downstream vision tasks, such as object detection, tracking, and segmentation. However, previous well-established DNNs, despite being able to maintain superior accuracy, have also been evolving to be deeper and wider and thus inevitably necessitate prohibitive computational resources for both training and inference. This trend further enlarges the computational gap between computation-intensive DNNs and resource-constrained embedded computing systems, making it challenging to deploy powerful DNNs upon real-world embedded computing systems towards ubiquitous embedded intelligence. To alleviate the above computational gap and enable ubiquitous embedded intelligence, we, in this survey, focus on discussing recent efficient deep learning infrastructures for embedded computing systems, spanning from training to inference, from manual to automated, from convolutional neural networks to transformers, from transformers to vision transformers, from vision models to large language models, from software to hardware, and from algorithms to applications. Specifically, we discuss recent efficient deep learning infrastructures for embedded computing systems from the lens of (1) efficient manual network design for embedded computing systems, (2) efficient automated network design for embedded computing systems, (3) efficient network compression for embedded computing systems, (4) efficient on-device learning for embedded computing systems, (5) efficient large language models for embedded computing systems, (6) efficient deep learning software and hardware for embedded computing systems, and (7) efficient intelligent applications for embedded computing systems.

[Arxiv](https://arxiv.org/abs/2411.01431)