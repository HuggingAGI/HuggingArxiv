# 在动物福利评估中，通过多模态的声学和语言数据信息融合来解码奶牛的发声

发布时间：2024年11月01日

`其他` `畜牧业` `动物福利`

> Multi Modal Information Fusion of Acoustic and Linguistic Data for Decoding Dairy Cow Vocalizations in Animal Welfare Assessment

# 摘要

> 通过多源数据融合来理解动物的叫声，对于在精准畜牧业中评估动物的情绪状态、提升动物福利意义重大。本研究致力于运用多模态数据融合技术来解读奶牛的接触叫声，融合转录、语义分析、上下文与情绪评估以及声学特征提取等手段。我们借助自然语言处理模型，把奶牛叫声的音频记录转为文字形式。将多个声学特征（频率、时长和强度）与转录的文本数据相融合，构建出奶牛叫声的综合表征。在自行开发的本体中进行数据融合，把叫声分为与痛苦或兴奋相关的高频叫声，以及与满足或平静相关的低频叫声。分析融合后的多维数据，我们明确了显示情绪困扰的焦虑相关特征，包括特定的频率测量值和频谱结果。评估 20 头个体奶牛叫声的情绪和声学特征，得以确定叫声模式和情绪状态的差异。运用先进的机器学习算法，如随机森林、支持向量机和循环神经网络，我们高效地处理和融合多源数据，对奶牛叫声进行分类。这些模型经过优化，能够应对实际农场环境中固有的计算需求和数据质量挑战。我们的研究成果表明，多源数据融合和智能处理技术在动物福利监测中成效显著。本研究在动物福利评估领域取得重大突破，突显了创新融合技术在理解和改善奶牛情绪健康方面的重要作用。

> Understanding animal vocalizations through multi-source data fusion is crucial for assessing emotional states and enhancing animal welfare in precision livestock farming. This study aims to decode dairy cow contact calls by employing multi-modal data fusion techniques, integrating transcription, semantic analysis, contextual and emotional assessment, and acoustic feature extraction. We utilized the Natural Language Processing model to transcribe audio recordings of cow vocalizations into written form. By fusing multiple acoustic features frequency, duration, and intensity with transcribed textual data, we developed a comprehensive representation of cow vocalizations. Utilizing data fusion within a custom-developed ontology, we categorized vocalizations into high frequency calls associated with distress or arousal, and low frequency calls linked to contentment or calmness. Analyzing the fused multi dimensional data, we identified anxiety related features indicative of emotional distress, including specific frequency measurements and sound spectrum results. Assessing the sentiment and acoustic features of vocalizations from 20 individual cows allowed us to determine differences in calling patterns and emotional states. Employing advanced machine learning algorithms, Random Forest, Support Vector Machine, and Recurrent Neural Networks, we effectively processed and fused multi-source data to classify cow vocalizations. These models were optimized to handle computational demands and data quality challenges inherent in practical farm environments. Our findings demonstrate the effectiveness of multi-source data fusion and intelligent processing techniques in animal welfare monitoring. This study represents a significant advancement in animal welfare assessment, highlighting the role of innovative fusion technologies in understanding and improving the emotional wellbeing of dairy cows.

[Arxiv](https://arxiv.org/abs/2411.00477)