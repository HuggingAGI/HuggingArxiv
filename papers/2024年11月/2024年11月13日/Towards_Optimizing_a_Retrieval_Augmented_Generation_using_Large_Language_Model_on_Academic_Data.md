# 朝着在学术数据上使用大型语言模型优化检索增强生成的方向发展

发布时间：2024年11月13日

`RAG`

> Towards Optimizing a Retrieval Augmented Generation using Large Language Model on Academic Data

# 摘要

> 鉴于许多组织将检索增强生成（RAG）纳入其运营的趋势日益增长，我们在特定领域的数据上评估 RAG，并在各种优化技术下测试最先进的模型。我们纳入了四种优化；多查询、子父检索器、集成检索器和上下文学习，以增强学术领域的功能和性能。我们专注于数据检索，特别是针对一所大型技术大学的各种学习项目。我们还引入了一种新颖的评估方法，即 RAG 混淆矩阵，旨在评估 RAG 框架内各种配置的有效性。通过探索开源（例如，Llama2、Mistral）和闭源（GPT-3.5 和 GPT-4）大型语言模型的集成，我们为特定领域中 RAG 框架的应用和优化提供了有价值的见解。我们的实验表明，在检索阶段包含多查询时性能显著提高。

> Given the growing trend of many organizations integrating Retrieval Augmented Generation (RAG) into their operations, we assess RAG on domain-specific data and test state-of-the-art models across various optimization techniques. We incorporate four optimizations; Multi-Query, Child-Parent-Retriever, Ensemble Retriever, and In-Context-Learning, to enhance the functionality and performance in the academic domain. We focus on data retrieval, specifically targeting various study programs at a large technical university. We additionally introduce a novel evaluation approach, the RAG Confusion Matrix designed to assess the effectiveness of various configurations within the RAG framework. By exploring the integration of both open-source (e.g., Llama2, Mistral) and closed-source (GPT-3.5 and GPT-4) Large Language Models, we offer valuable insights into the application and optimization of RAG frameworks in domain-specific contexts. Our experiments show a significant performance increase when including multi-query in the retrieval phase.

[Arxiv](https://arxiv.org/abs/2411.08438)