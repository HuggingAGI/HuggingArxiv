# UniMat：通过多模态学习统一材料嵌入

发布时间：2024年11月13日

`其他` `材料科学` `多模态学习`

> UniMat: Unifying Materials Embeddings through Multi-modal Learning

# 摘要

> 材料科学数据集本质上是异质的，并且以不同的形式可用，例如表征光谱、原子结构、微观图像和基于文本的合成条件。多模态学习的进步，特别是在视觉和语言模型方面，为整合不同形式的数据开辟了新的途径。在这项工作中，我们评估了多模态学习（对齐和融合）中的常见技术，以统一材料科学中一些最重要的模态：原子结构、X 射线衍射图谱（XRD）和成分。我们表明，通过与 XRD 图谱对齐，可以增强结构图形模态。此外，我们表明，在各种任务中，对齐和融合更多实验可访问的数据格式，如 XRD 图谱和成分，可以创建比单个模态更强大的联合嵌入。这为未来旨在充分利用材料科学中多模态数据的全部潜力、促进材料设计和发现中更明智的决策制定的研究奠定了基础。

> Materials science datasets are inherently heterogeneous and are available in different modalities such as characterization spectra, atomic structures, microscopic images, and text-based synthesis conditions. The advancements in multi-modal learning, particularly in vision and language models, have opened new avenues for integrating data in different forms. In this work, we evaluate common techniques in multi-modal learning (alignment and fusion) in unifying some of the most important modalities in materials science: atomic structure, X-ray diffraction patterns (XRD), and composition. We show that structure graph modality can be enhanced by aligning with XRD patterns. Additionally, we show that aligning and fusing more experimentally accessible data formats, such as XRD patterns and compositions, can create more robust joint embeddings than individual modalities across various tasks. This lays the groundwork for future studies aiming to exploit the full potential of multi-modal data in materials science, facilitating more informed decision-making in materials design and discovery.

[Arxiv](https://arxiv.org/abs/2411.08664)