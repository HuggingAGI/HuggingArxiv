# 构建值得信赖的人工智能：通过大型语言模型、本体论和逻辑推理实现透明的人工智能系统（TranspNet）

发布时间：2024年11月13日

`LLM应用`

> Building Trustworthy AI: Transparent AI Systems via Large Language Models, Ontologies, and Logical Reasoning (TranspNet)

# 摘要

> 对人工智能缺乏透明度的担忧日益增加，特别是在医疗保健和金融等高风险领域，推动了对可解释和值得信赖的系统的需求。虽然大型语言模型（LLMs）在生成准确的输出方面表现出色，但它们的“黑箱”性质对透明度和信任构成了重大挑战。为了解决这个问题，本文提出了 TranspNet 管道，它将符号人工智能与 LLMs 集成在一起。通过利用领域专家知识、检索增强生成（RAG）和像答案集编程（ASP）这样的正式推理框架，TranspNet 用结构化推理和验证增强了 LLM 的输出。这种方法确保人工智能系统不仅提供准确的结果，而且提供可解释和值得信赖的结果，满足透明度和问责制的监管要求。TranspNet 为开发可靠和可解释的人工智能系统提供了一个全面的解决方案，使其适用于信任至关重要的实际应用。

> Growing concerns over the lack of transparency in AI, particularly in high-stakes fields like healthcare and finance, drive the need for explainable and trustworthy systems. While Large Language Models (LLMs) perform exceptionally well in generating accurate outputs, their "black box" nature poses significant challenges to transparency and trust. To address this, the paper proposes the TranspNet pipeline, which integrates symbolic AI with LLMs. By leveraging domain expert knowledge, retrieval-augmented generation (RAG), and formal reasoning frameworks like Answer Set Programming (ASP), TranspNet enhances LLM outputs with structured reasoning and verification. This approach ensures that AI systems deliver not only accurate but also explainable and trustworthy results, meeting regulatory demands for transparency and accountability. TranspNet provides a comprehensive solution for developing AI systems that are reliable and interpretable, making it suitable for real-world applications where trust is critical.

[Arxiv](https://arxiv.org/abs/2411.08469)