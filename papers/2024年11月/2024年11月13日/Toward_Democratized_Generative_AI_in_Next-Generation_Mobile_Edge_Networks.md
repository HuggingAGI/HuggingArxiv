# 朝着下一代移动边缘网络中的民主化生成式 AI 迈进

发布时间：2024年11月13日

`LLM应用` `移动网络` `人工智能`

> Toward Democratized Generative AI in Next-Generation Mobile Edge Networks

# 摘要

> 生成式人工智能技术（涵盖大型语言模型（LLM））的迅猛发展为众多领域带来了变革性转变。但因高计算、内存、通信及能源需求，在移动和边缘设备上部署这类先进模型颇具挑战。为应对此难题，我们提出了一个以模型为核心的框架，以推动生成式人工智能在移动和边缘网络中的普及部署。首先，我们全面梳理了关键的紧凑模型策略，像量化、模型剪枝和知识蒸馏，并给出了优化生成式人工智能用于移动部署的关键性能指标。接着，我们重点回顾了移动和边缘网络，突出了这些环境的特定挑战与要求。我们还开展了案例研究，通过在真实的移动边缘设备上部署 LLM 来验证这些策略的有效性。实验结果彰显了普及化 LLM 的实用价值，在泛化精度、幻觉率、可访问性及资源消耗等方面均有显著改善。最后，我们探讨了潜在的研究方向，以进一步促进生成式人工智能在资源受限环境中的部署。

> The rapid development of generative AI technologies, including large language models (LLMs), has brought transformative changes to various fields. However, deploying such advanced models on mobile and edge devices remains challenging due to their high computational, memory, communication, and energy requirements. To address these challenges, we propose a model-centric framework for democratizing generative AI deployment on mobile and edge networks. First, we comprehensively review key compact model strategies, such as quantization, model pruning, and knowledge distillation, and present key performance metrics to optimize generative AI for mobile deployment. Next, we provide a focused review of mobile and edge networks, emphasizing the specific challenges and requirements of these environments. We further conduct a case study demonstrating the effectiveness of these strategies by deploying LLMs on real mobile edge devices. Experimental results highlight the practicality of democratized LLMs, with significant improvements in generalization accuracy, hallucination rate, accessibility, and resource consumption. Finally, we discuss potential research directions to further advance the deployment of generative AI in resource-constrained environments.

[Arxiv](https://arxiv.org/abs/2411.09148)