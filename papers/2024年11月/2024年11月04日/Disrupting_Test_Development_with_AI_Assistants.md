# 用人工智能助手扰乱测试开发

发布时间：2024年11月04日

`LLM应用` `软件开发` `软件测试`

> Disrupting Test Development with AI Assistants

# 摘要

> 大型语言模型的最新进展，包括 GPT-4 及其变体，以及像 GitHub Copilot、ChatGPT 和 Tabnine 这样的生成式 AI 辅助编码工具，已经显著改变了软件开发。本文分析了这些创新如何影响生产力和软件测试开发指标。这些工具使开发人员能够在部署前以最少的人工干预生成完整的软件程序。然而，开发人员的彻底审查和测试仍然至关重要。利用将测试分为单元、集成和端到端测试的测试金字塔概念，我们通过生成和比较开源模块的单元测试来评估三个流行的 AI 编码助手。我们的发现表明，AI 生成的测试与原始测试质量相当，突出了这些工具在使用和结果方面的差异。这项研究增强了对 AI 辅助工具在自动化测试中的理解和能力。

> Recent advancements in large language models, including GPT-4 and its variants, and Generative AI-assisted coding tools like GitHub Copilot, ChatGPT, and Tabnine, have significantly transformed software development. This paper analyzes how these innovations impact productivity and software test development metrics. These tools enable developers to generate complete software programs with minimal human intervention before deployment. However, thorough review and testing by developers are still crucial. Utilizing the Test Pyramid concept, which categorizes tests into unit, integration, and end-to-end tests, we evaluate three popular AI coding assistants by generating and comparing unit tests for opensource modules. Our findings show that AI-generated tests are of equivalent quality to original tests, highlighting differences in usage and results among the tools. This research enhances the understanding and capabilities of AI-assistant tools in automated testing.

[Arxiv](https://arxiv.org/abs/2411.02328)