# LLM 语言网络：一种用于识别因果任务相关单元的神经科学方法

发布时间：2024年11月04日

`LLM理论` `神经科学` `语言模型`

> The LLM Language Network: A Neuroscientific Approach for Identifying Causally Task-Relevant Units

# 摘要

> 大型语言模型（LLMs）不仅在语言任务上表现出显著的能力，而且在各种非语言性质的任务上也表现出色，例如逻辑推理和社会推断。在人脑中，神经科学已经确定了一个核心语言系统，有选择地和因果性地支持语言处理。我们在这里询问在大型语言模型中是否出现了类似的语言专业化。我们使用与神经科学相同的定位方法，在 18 个流行的大型语言模型中识别出语言选择性单元。然后，我们通过证明消融大型语言模型的语言选择性单元（而不是随机单元）会导致语言任务中的严重缺陷，从而确立了这些单元的因果作用。相应地，语言选择性的大型语言模型单元比随机单元更符合人类语言系统的大脑记录。最后，我们研究我们的定位方法是否扩展到其他认知领域：虽然我们在一些大型语言模型中发现了用于推理和社交能力的专门网络，但模型之间存在很大差异。这些发现为大型语言模型的专业化提供了功能和因果证据，并突出了与大脑功能组织的相似之处。

> Large language models (LLMs) exhibit remarkable capabilities on not just language tasks, but also various tasks that are not linguistic in nature, such as logical reasoning and social inference. In the human brain, neuroscience has identified a core language system that selectively and causally supports language processing. We here ask whether similar specialization for language emerges in LLMs. We identify language-selective units within 18 popular LLMs, using the same localization approach that is used in neuroscience. We then establish the causal role of these units by demonstrating that ablating LLM language-selective units -- but not random units -- leads to drastic deficits in language tasks. Correspondingly, language-selective LLM units are more aligned to brain recordings from the human language system than random units. Finally, we investigate whether our localization method extends to other cognitive domains: while we find specialized networks in some LLMs for reasoning and social capabilities, there are substantial differences among models. These findings provide functional and causal evidence for specialization in large language models, and highlight parallels with the functional organization in the brain.

[Arxiv](https://arxiv.org/abs/2411.02280)