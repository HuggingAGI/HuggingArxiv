# 大型语言模型能够像人类一样推广类比解决问题的能力吗？

发布时间：2024年11月04日

`LLM应用` `人工智能`

> Can Large Language Models generalize analogy solving like people can?

# 摘要

> 当我们解决类比问题时，我们通过抽象规则和关系相似性将信息从已知的情境转移到新的情境。在人类中，解决诸如“身体 : 脚 :: 桌子 : ？”这样的类比的能力在童年时期就出现了，并且似乎很容易转移到其他领域，例如视觉领域“( : ) :: < : ？”。最近的研究表明，大型语言模型（LLM）可以解决各种形式的类比。然而，LLM 能否像人类一样将类比解决推广到新的领域呢？为了研究这个问题，我们让儿童、成人和 LLM 解决一系列拉丁字母中的字母串类比（例如，a b : a c :: j k : ？），在近迁移领域（希腊字母）和远迁移领域（符号列表）。正如预期的那样，儿童和成人很容易将他们的知识推广到不熟悉的领域，而 LLM 则不能。人类和人工智能表现的这一关键差异证明，这些 LLM 在像人类一样强大的类比迁移方面仍然存在困难。

> When we solve an analogy we transfer information from a known context to a new one through abstract rules and relational similarity. In people, the ability to solve analogies such as "body : feet :: table : ?" emerges in childhood, and appears to transfer easily to other domains, such as the visual domain "( : ) :: < : ?". Recent research shows that large language models (LLMs) can solve various forms of analogies. However, can LLMs generalize analogy solving to new domains like people can? To investigate this, we had children, adults, and LLMs solve a series of letter-string analogies (e.g., a b : a c :: j k : ?) in the Latin alphabet, in a near transfer domain (Greek alphabet), and a far transfer domain (list of symbols). As expected, children and adults easily generalized their knowledge to unfamiliar domains, whereas LLMs did not. This key difference between human and AI performance is evidence that these LLMs still struggle with robust human-like analogical transfer.

[Arxiv](https://arxiv.org/abs/2411.02348)