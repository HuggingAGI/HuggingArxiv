# 使用多模态大型语言模型的漫画的上下文告知机器翻译

发布时间：2024年11月04日

`LLM应用`

> Context-Informed Machine Translation of Manga using Multimodal Large Language Models

# 摘要

> 由于手工翻译需要大量的时间和精力，大多数漫画从未离开日本国内市场。自动漫画翻译是一个有前途的潜在解决方案。然而，这是一个新兴且不发达的领域，由于需要将视觉元素有效地纳入翻译过程以解决模糊性，其复杂性甚至比标准翻译中的还要大。在这项工作中，我们研究了多模态大型语言模型（LLM）在多大程度上能够提供有效的漫画翻译，从而帮助漫画作者和出版商接触更广泛的受众。具体来说，我们提出了一种利用多模态 LLM 的视觉组件来提高翻译质量的方法，并评估了翻译单元大小、上下文长度的影响，并提出了一种用于漫画翻译的令牌高效方法。此外，我们引入了一个新的评估数据集——第一个日波平行漫画翻译数据集——作为未来研究中使用的基准的一部分。最后，我们贡献了一个开源软件套件，使其他人能够为漫画翻译对 LLM 进行基准测试。我们的研究结果表明，我们提出的方法在日英翻译方面取得了最先进的结果，并为日波翻译设定了新的标准。

> Due to the significant time and effort required for handcrafting translations, most manga never leave the domestic Japanese market. Automatic manga translation is a promising potential solution. However, it is a budding and underdeveloped field and presents complexities even greater than those found in standard translation due to the need to effectively incorporate visual elements into the translation process to resolve ambiguities. In this work, we investigate to what extent multimodal large language models (LLMs) can provide effective manga translation, thereby assisting manga authors and publishers in reaching wider audiences. Specifically, we propose a methodology that leverages the vision component of multimodal LLMs to improve translation quality and evaluate the impact of translation unit size, context length, and propose a token efficient approach for manga translation. Moreover, we introduce a new evaluation dataset -- the first parallel Japanese-Polish manga translation dataset -- as part of a benchmark to be used in future research. Finally, we contribute an open-source software suite, enabling others to benchmark LLMs for manga translation. Our findings demonstrate that our proposed methods achieve state-of-the-art results for Japanese-English translation and set a new standard for Japanese-Polish.

[Arxiv](https://arxiv.org/abs/2411.02589)