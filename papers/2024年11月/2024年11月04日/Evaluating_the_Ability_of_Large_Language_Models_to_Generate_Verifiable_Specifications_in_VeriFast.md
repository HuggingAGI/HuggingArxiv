# 评估大型语言模型在 VeriFast 中生成可验证规范的能力

发布时间：2024年11月04日

`LLM应用` `软件工程` `静态验证`

> Evaluating the Ability of Large Language Models to Generate Verifiable Specifications in VeriFast

# 摘要

> 静态验证是提高软件质量的一种强大方法，但它需要大量的人力和资源。对于使用所有权逻辑来推理堆操作程序的静态验证器来说，尤其如此。LLM 在许多软件工程活动中显示出了前景，包括代码生成、测试生成、定理证明器的证明生成以及静态验证器的规范生成。然而，之前的工作尚未探索 LLM 在基于所有权逻辑（如分离逻辑）为规范生成方面的表现如何。

为了弥补这一差距，本文探讨了大型语言模型（LLM），特别是 OpenAI 的 GPT 模型，在为 VeriFast 中人工编写的程序基于分离逻辑生成完全正确的静态验证规范方面的有效性。我们的第一个实验采用了传统的提示工程，第二个实验使用了思维链（CoT）提示来识别和解决 GPT 模型生成的常见错误。结果表明，GPT 模型能够成功地为使用 VeriFast 验证堆操作代码生成规范。此外，虽然 CoT 提示显著减少了 GPT 模型生成的语法错误，但与提示工程相比，它并没有大大降低验证错误率。

> Static verification is a powerful method for enhancing software quality, but it demands significant human labor and resources. This is particularly true of static verifiers that reason about heap manipulating programs using an ownership logic. LLMs have shown promise in a number of software engineering activities, including code generation, test generation, proof generation for theorem provers, and specification generation for static verifiers. However, prior work has not explored how well LLMs can perform specification generation for specifications based in an ownership logic, such as separation logic.
  To address this gap, this paper explores the effectiveness of large language models (LLMs), specifically OpenAI's GPT models, in generating fully correct specifications based on separation logic for static verification of human-written programs in VeriFast. Our first experiment employed traditional prompt engineering and the second used Chain-of-Thought (CoT) Prompting to identify and address common errors generated across the GPT models. The results indicate that GPT models can successfully generate specifications for verifying heap manipulating code with VeriFast. Furthermore, while CoT prompting significantly reduces syntax errors generated by the GPT models, it does not greatly improve verification error rates compared to prompt engineering.

[Arxiv](https://arxiv.org/abs/2411.02318)