# 1-800-SHARED-TASKS @ 天城文脚本语言的自然语言理解：使用大型语言模型检测语言、仇恨言论和目标

发布时间：2024年11月11日

`LLM应用` `天城文脚本语言`

> 1-800-SHARED-TASKS @ NLU of Devanagari Script Languages: Detection of Language, Hate Speech, and Targets using LLMs

# 摘要

> 本文详细介绍了我们参加 2025 年 CHiPSAL 共享任务的参赛系统，重点关注天城文脚本语言中的语言检测、仇恨言论识别和目标检测。我们尝试了大型语言模型及其集成的组合，包括 MuRIL、IndicBERT 和 Gemma-2，并利用了诸如焦点损失之类的独特技术来应对天城文语言自然理解中的挑战，例如多语言处理和类别不平衡。我们的方法在所有任务中都取得了有竞争力的结果：子任务 A、B 和 C 的 F1 分别为 0.9980、0.7652 和 0.6804。这项工作为在具有特定领域和语言挑战的任务中转换器模型的有效性提供了见解，以及未来迭代中潜在的改进领域。

> This paper presents a detailed system description of our entry for the CHiPSAL 2025 shared task, focusing on language detection, hate speech identification, and target detection in Devanagari script languages. We experimented with a combination of large language models and their ensembles, including MuRIL, IndicBERT, and Gemma-2, and leveraged unique techniques like focal loss to address challenges in the natural understanding of Devanagari languages, such as multilingual processing and class imbalance. Our approach achieved competitive results across all tasks: F1 of 0.9980, 0.7652, and 0.6804 for Sub-tasks A, B, and C respectively. This work provides insights into the effectiveness of transformer models in tasks with domain-specific and linguistic challenges, as well as areas for potential improvement in future iterations.

[Arxiv](https://arxiv.org/abs/2411.06850)