# 大型语言模型的说服力：一项调查

发布时间：2024年11月11日

`LLM应用`

> Persuasion with Large Language Models: a Survey

# 摘要

> 大型语言模型（LLMs）的迅速崛起为有说服力的交流创造了新的颠覆性可能性，能够以前所未有的规模实现全自动个性化和交互式内容生成。在本文中，我们对由此产生的基于 LLM 的说服研究领域进行了调查。我们首先探讨了 LLM 系统用于影响人类态度和行为的不同模式。在政治、营销、公共卫生、电子商务和慈善捐赠等领域，此类 LLM 系统已经达到了人类水平甚至超人类的说服力。我们确定了影响其有效性的关键因素，例如个性化方式以及内容是否被标记为人工智能生成。我们还总结了用于评估进展的实验设计。我们的调查表明，基于 LLM 的说服的当前和未来潜力带来了深刻的伦理和社会风险，包括错误信息的传播、偏见的放大和隐私的侵犯。这些风险强调了迫切需要道德准则和更新的监管框架，以避免不负责任和有害的 LLM 系统的广泛部署。

> The rapid rise of Large Language Models (LLMs) has created new disruptive possibilities for persuasive communication, by enabling fully-automated personalized and interactive content generation at an unprecedented scale. In this paper, we survey the research field of LLM-based persuasion that has emerged as a result. We begin by exploring the different modes in which LLM Systems are used to influence human attitudes and behaviors. In areas such as politics, marketing, public health, e-commerce, and charitable giving, such LLM Systems have already achieved human-level or even super-human persuasiveness. We identify key factors influencing their effectiveness, such as the manner of personalization and whether the content is labelled as AI-generated. We also summarize the experimental designs that have been used to evaluate progress. Our survey suggests that the current and future potential of LLM-based persuasion poses profound ethical and societal risks, including the spread of misinformation, the magnification of biases, and the invasion of privacy. These risks underscore the urgent need for ethical guidelines and updated regulatory frameworks to avoid the widespread deployment of irresponsible and harmful LLM Systems.

[Arxiv](https://arxiv.org/abs/2411.06837)