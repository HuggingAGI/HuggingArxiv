# 《中文 SimpleQA：针对大型语言模型的中文真实性评估》

发布时间：2024年11月11日

`LLM应用` `语言模型` `评估基准`

> Chinese SimpleQA: A Chinese Factuality Evaluation for Large Language Models

# 摘要

> 新的 LLM 评估基准对于与大型语言模型（LLM）的快速发展保持一致非常重要。在这项工作中，我们提出了 Chinese SimpleQA，这是第一个全面的评估语言模型回答短问题的真实性能力的中文基准，并且 Chinese SimpleQA 主要有五个属性（即中文、多样、高质量、静态、易于评估）。具体来说，首先，我们专注于涵盖 6 个主要主题和 99 个不同子主题的中文。其次，我们进行了全面的质量控制过程，以实现高质量的问题和答案，其中参考答案是静态的，不会随时间改变。第三，遵循 SimpleQA，问题和答案都非常短，并且基于 OpenAI API 的评分过程易于评估。基于 Chinese SimpleQA，我们对现有 LLM 的真实性能力进行了全面评估。最后，我们希望 Chinese SimpleQA 能够引导开发人员更好地了解其模型的中文真实性能力，并促进基础模型的发展。

> New LLM evaluation benchmarks are important to align with the rapid development of Large Language Models (LLMs). In this work, we present Chinese SimpleQA, the first comprehensive Chinese benchmark to evaluate the factuality ability of language models to answer short questions, and Chinese SimpleQA mainly has five properties (i.e., Chinese, Diverse, High-quality, Static, Easy-to-evaluate). Specifically, first, we focus on the Chinese language over 6 major topics with 99 diverse subtopics. Second, we conduct a comprehensive quality control process to achieve high-quality questions and answers, where the reference answers are static and cannot be changed over time. Third, following SimpleQA, the questions and answers are very short, and the grading process is easy-to-evaluate based on OpenAI API. Based on Chinese SimpleQA, we perform a comprehensive evaluation on the factuality abilities of existing LLMs. Finally, we hope that Chinese SimpleQA could guide the developers to better understand the Chinese factuality abilities of their models and facilitate the growth of foundation models.

[Arxiv](https://arxiv.org/abs/2411.07140)