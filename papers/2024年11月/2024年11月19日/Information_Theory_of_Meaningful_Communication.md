# 有意义交流的信息论

发布时间：2024年11月19日

`LLM理论` `信息论`

> Information Theory of Meaningful Communication

# 摘要

> 在香农的开创性论文里，把印刷英语当作平稳随机过程，其熵约为每个字符 1 比特。然而，作为交流方式，语言和其印刷形式差异显著：（i）信息单元并非字符甚至单词，而是从句，即最短的有意义的词性部分；（ii）传递的主要是所说或所写内容的含义，而用于传达含义的精确表述通常被忽略。在本研究中，我们指出，能够借助近期研发的大型语言模型，按照每个从句的意义比特数来量化有意义叙述中传递的信息。

> In Shannon's seminal paper, entropy of printed English, treated as a stationary stochastic process, was estimated to be roughly 1 bit per character. However, considered as a means of communication, language differs considerably from its printed form: (i) the units of information are not characters or even words but clauses, i.e. shortest meaningful parts of speech; and (ii) what is transmitted is principally the meaning of what is being said or written, while the precise phrasing that was used to communicate the meaning is typically ignored. In this study, we show that one can leverage recently developed large language models to quantify information communicated in meaningful narratives in terms of bits of meaning per clause.

[Arxiv](https://arxiv.org/abs/2411.12728)