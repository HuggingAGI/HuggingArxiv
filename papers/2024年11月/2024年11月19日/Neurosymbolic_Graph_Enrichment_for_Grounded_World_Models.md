# 用于接地世界模型的神经符号图丰富方法

发布时间：2024年11月19日

`LLM应用` `人工智能`

> Neurosymbolic Graph Enrichment for Grounded World Models

# 摘要

> 人工智能系统若要能够理解和推理复杂的现实世界场景，其发展面临重大挑战。在本项工作中，我们提出了一种新颖的办法来增强并利用LLM的反应能力，以应对复杂问题，并深度阐释现实世界的上下文意义。我们引入了一种方法和工具，用于创建多模态、知识增强的意义形式化表征，它融合了大型语言模型的长处与结构化的语义表征。我们的方法始于图像输入，借助最先进的大型语言模型生成自然语言描述。接着，将此描述转化为抽象意义表示（AMR）图，该图经形式化处理，并借助逻辑设计模式以及源自语言和事实知识库的分层语义得以丰富。所得之图再反馈至LLM，通过复杂的启发式学习激活的隐性知识进行拓展，涵盖语义蕴含、道德价值、具身认知和隐喻表示等。通过弥合非结构化语言模型与形式语义结构之间的鸿沟，我们的方法为解决自然语言理解和推理中的复杂难题开辟了新路径。

> The development of artificial intelligence systems capable of understanding and reasoning about complex real-world scenarios is a significant challenge. In this work we present a novel approach to enhance and exploit LLM reactive capability to address complex problems and interpret deeply contextual real-world meaning. We introduce a method and a tool for creating a multimodal, knowledge-augmented formal representation of meaning that combines the strengths of large language models with structured semantic representations. Our method begins with an image input, utilizing state-of-the-art large language models to generate a natural language description. This description is then transformed into an Abstract Meaning Representation (AMR) graph, which is formalized and enriched with logical design patterns, and layered semantics derived from linguistic and factual knowledge bases. The resulting graph is then fed back into the LLM to be extended with implicit knowledge activated by complex heuristic learning, including semantic implicatures, moral values, embodied cognition, and metaphorical representations. By bridging the gap between unstructured language models and formal semantic structures, our method opens new avenues for tackling intricate problems in natural language understanding and reasoning.

[Arxiv](https://arxiv.org/abs/2411.12671)