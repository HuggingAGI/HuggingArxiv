# 网络边缘的 AI 流

发布时间：2024年11月19日

`LLM应用` `人工智能`

> AI Flow at the Network Edge

# 摘要

> 近期，大型语言模型（LLMs）及其多模态变体取得了重大进展，在众多领域表现出色，彰显出令人瞩目的能力和空前的潜力。在万物互联的时代，借助通信网络来分配智能是一种变革性理念，畅想在网络边缘就能获取人工智能服务。然而，把大型模型从云端推向资源受限的环境面临严峻挑战。在低端设备上进行模型推理会产生过长的延迟和性能瓶颈，在有限带宽网络上传送原始数据会带来高额的通信开销。本文推出了 AI Flow 框架，它通过协同利用设备、边缘节点和云服务器的异构资源来优化推理过程，让智能在网络中畅流。为促进多个计算节点的协作，该框架探索了通信网络系统设计从信息流传输到智能流传输的范式转变，通信目标以任务为导向并融入推理过程。实验结果通过图像字幕的应用案例证明了所提框架的有效性，展现出在保持高质量字幕的同时降低响应延迟的能力。本文作为立场文件，明确了 AI Flow 的动机、挑战和原则。

> Recent advancements in large language models (LLMs) and their multimodal variants have led to remarkable progress across various domains, demonstrating impressive capabilities and unprecedented potential. In the era of ubiquitous connectivity, leveraging communication networks to distribute intelligence is a transformative concept, envisioning AI-powered services accessible at the network edge. However, pushing large models from the cloud to resource-constrained environments faces critical challenges. Model inference on low-end devices leads to excessive latency and performance bottlenecks, while raw data transmission over limited bandwidth networks causes high communication overhead. This article presents AI Flow, a framework that streamlines the inference process by jointly leveraging the heterogeneous resources available across devices, edge nodes, and cloud servers, making intelligence flow across networks. To facilitate cooperation among multiple computational nodes, the proposed framework explores a paradigm shift in the design of communication network systems from transmitting information flow to intelligence flow, where the goal of communications is task-oriented and folded into the inference process. Experimental results demonstrate the effectiveness of the proposed framework through an image captioning use case, showcasing the ability to reduce response latency while maintaining high-quality captions. This article serves as a position paper for identifying the motivation, challenges, and principles of AI Flow.

[Arxiv](https://arxiv.org/abs/2411.12469)