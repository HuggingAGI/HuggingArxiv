# 说出你从所看到的内容中听到的东西——通过文本实现从视频到音频的生成

发布时间：2024年11月08日

`LLM应用` `多媒体` `多模态生成`

> Tell What You Hear From What You See -- Video to Audio Generation Through Text

# 摘要

> 视觉和音频场景的内容是多方面的，以至于一个视频可以与各种音频配对，反之亦然。因此，在视频到音频生成任务中，引入控制生成音频的引导方法是至关重要的。虽然视频到音频生成是一个成熟的生成任务，但现有方法缺乏这种可控性。在这项工作中，我们提出了 VATT，这是一个多模态生成框架，它以视频和可选的文本提示作为输入，并生成音频和音频的可选文本描述。这样的框架有两个优点：i）视频到音频的生成过程可以通过补充视觉信息上下文的文本进行细化和控制，ii）该模型可以通过生成音频字幕来建议为视频生成什么样的音频。VATT 由两个关键模块组成：VATT 转换器，这是一个为指令微调的 LLM，包括一个将视频特征映射到 LLM 向量空间的投影层；以及 VATT 音频，这是一个使用迭代并行解码从视觉帧和可选文本提示生成音频标记的转换器。音频标记通过预训练的神经编解码器转换为波形。实验表明，当在客观指标中将 VATT 与现有的视频到音频生成方法进行比较时，如果不提供音频字幕，它能取得有竞争力的性能。当提供音频字幕作为提示时，VATT 实现了更精细的性能（最低 KLD 分数为 1.41）。此外，主观研究表明，与现有方法生成的音频相比，VATT 音频被选为更受欢迎的生成音频。VATT 通过文本实现了可控的视频到音频生成，并通过音频字幕为视频建议文本提示，开启了诸如文本引导的视频到音频生成和视频到音频字幕等新应用。

> The content of visual and audio scenes is multi-faceted such that a video can be paired with various audio and vice-versa. Thereby, in video-to-audio generation task, it is imperative to introduce steering approaches for controlling the generated audio. While Video-to-Audio generation is a well-established generative task, existing methods lack such controllability. In this work, we propose VATT, a multi-modal generative framework that takes a video and an optional text prompt as input, and generates audio and optional textual description of the audio. Such a framework has two advantages: i) Video-to-Audio generation process can be refined and controlled via text which complements the context of visual information, and ii) The model can suggest what audio to generate for the video by generating audio captions. VATT consists of two key modules: VATT Converter, a LLM that is fine-tuned for instructions and includes a projection layer that maps video features to the LLM vector space; and VATT Audio, a transformer that generates audio tokens from visual frames and from optional text prompt using iterative parallel decoding. The audio tokens are converted to a waveform by pretrained neural codec. Experiments show that when VATT is compared to existing video-to-audio generation methods in objective metrics, it achieves competitive performance when the audio caption is not provided. When the audio caption is provided as a prompt, VATT achieves even more refined performance (lowest KLD score of 1.41). Furthermore, subjective studies show that VATT Audio has been chosen as preferred generated audio than audio generated by existing methods. VATT enables controllable video-to-audio generation through text as well as suggesting text prompts for videos through audio captions, unlocking novel applications such as text-guided video-to-audio generation and video-to-audio captioning.

[Arxiv](https://arxiv.org/abs/2411.05679)