# 评估大型语言模型在越南事实核查数据生成中的能力

发布时间：2024年11月08日

`LLM应用` `语言数据生成` `越南语`

> Evaluating Large Language Model Capability in Vietnamese Fact-Checking Data Generation

# 摘要

> 大型语言模型（LLMs），其阅读理解和推理能力逐渐提高，正被应用于一系列复杂的语言任务，包括为各种目的自动生成语言数据。然而，关于将 LLMs 应用于像越南语这样的低资源语言的自动数据生成的研究仍不发达，并且缺乏全面评估。在本文中，我们探索将 LLMs 用于越南语事实核查任务的自动数据生成，该任务面临着显著的数据限制。具体来说，我们专注于从多个证据句子合成声明的事实核查数据，以评估 LLMs 的信息合成能力。我们使用 LLMs 上的简单提示技术开发了一个自动数据构建过程，并探索了几种提高生成数据质量的方法。为了评估 LLMs 生成的数据的质量，我们进行了手动质量评估和使用语言模型的性能评估。实验结果和手动评估表明，虽然通过微调技术生成的数据质量有了显著提高，但 LLMs 仍然无法与人类生成的数据质量相匹配。

> Large Language Models (LLMs), with gradually improving reading comprehension and reasoning capabilities, are being applied to a range of complex language tasks, including the automatic generation of language data for various purposes. However, research on applying LLMs for automatic data generation in low-resource languages like Vietnamese is still underdeveloped and lacks comprehensive evaluation. In this paper, we explore the use of LLMs for automatic data generation for the Vietnamese fact-checking task, which faces significant data limitations. Specifically, we focus on fact-checking data where claims are synthesized from multiple evidence sentences to assess the information synthesis capabilities of LLMs. We develop an automatic data construction process using simple prompt techniques on LLMs and explore several methods to improve the quality of the generated data. To evaluate the quality of the data generated by LLMs, we conduct both manual quality assessments and performance evaluations using language models. Experimental results and manual evaluations illustrate that while the quality of the generated data has significantly improved through fine-tuning techniques, LLMs still cannot match the data quality produced by humans.

[Arxiv](https://arxiv.org/abs/2411.05641)