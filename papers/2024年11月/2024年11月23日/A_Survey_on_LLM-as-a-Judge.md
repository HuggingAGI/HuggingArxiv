# A Survey on LLM-as-a-Judge
关于 LLM 充当裁判的调研

发布时间：2024年11月23日

`LLM应用` `大型语言模型`

> A Survey on LLM-as-a-Judge

# 摘要

> 摘要：准确且一致的评估在众多领域的决策中至关重要，然而因其固有的主观性、多变性和规模性，这始终是一项艰巨的任务。大型语言模型（LLMs）在多个领域成绩斐然，催生了“LLM 充当评判者”这一现象，即让 LLMs 成为复杂任务的评估者。LLMs 能够处理各类数据类型，还能提供可扩展、成本效益高且一致的评估，为传统的专家驱动评估提供了极具吸引力的替代方案。不过，确保“LLM 作为评判者”系统的可靠性仍是重大挑战，需要精心规划和标准化。本文对“LLM 作为评判者”展开了全面调研，围绕核心问题——如何构建可靠的“LLM 作为评判者”系统展开探讨。我们研究了提升可靠性的策略，涵盖提高一致性、减少偏差以及适应多样的评估场景。另外，我们提出了评估“LLM 作为评判者”系统可靠性的方法，并为此专门设计了新的基准。为推动“LLM 作为评判者”系统的开发和实际应用，我们还探讨了实际应用情况、面临的挑战以及未来的发展方向。此次调研为这个迅速发展领域的研究人员和从业者提供了基础性参考。

> 
Abstract:Accurate and consistent evaluation is crucial for decision-making across numerous fields, yet it remains a challenging task due to inherent subjectivity, variability, and scale. Large Language Models (LLMs) have achieved remarkable success across diverse domains, leading to the emergence of "LLM-as-a-Judge," where LLMs are employed as evaluators for complex tasks. With their ability to process diverse data types and provide scalable, cost-effective, and consistent assessments, LLMs present a compelling alternative to traditional expert-driven evaluations. However, ensuring the reliability of LLM-as-a-Judge systems remains a significant challenge that requires careful design and standardization. This paper provides a comprehensive survey of LLM-as-a-Judge, addressing the core question: How can reliable LLM-as-a-Judge systems be built? We explore strategies to enhance reliability, including improving consistency, mitigating biases, and adapting to diverse assessment scenarios. Additionally, we propose methodologies for evaluating the reliability of LLM-as-a-Judge systems, supported by a novel benchmark designed for this purpose. To advance the development and real-world deployment of LLM-as-a-Judge systems, we also discussed practical applications, challenges, and future directions. This survey serves as a foundational reference for researchers and practitioners in this rapidly evolving field.
    

[Arxiv](https://arxiv.org/pdf/2411.15594)