# 《关于时间：动作理解的发展、挑战与展望》

发布时间：2024年11月22日

`其他` `动作理解`

> About Time: Advances, Challenges, and Outlooks of Action Understanding

# 摘要

> 我们见证了视频动作理解领域令人瞩目的进步。数据集规模增大、变异性增强以及计算能力提升，促使性能大幅提升，任务也更加多样化。当下的系统能够对视频场景进行粗细粒度的描述，提取与查询对应的片段，合成视频中未观测的部分，还能预测上下文。本次调研全面梳理了一系列任务中单一和多模态动作理解的进展。我们聚焦常见挑战，概述了广泛采用的数据集，并审视了具有开创性的成果，重点关注近期进展。我们大致划分了三个时间范畴：（1）对完整观测到的动作的识别任务；（2）对正在进行且部分观测到的动作的预测任务；（3）对后续未观测到的动作的预测任务。这种划分有助于我们明确特定的动作建模和视频表示方面的挑战。最后，我们勾勒出未来的方向，以应对当前的不足。

> We have witnessed impressive advances in video action understanding. Increased dataset sizes, variability, and computation availability have enabled leaps in performance and task diversification. Current systems can provide coarse- and fine-grained descriptions of video scenes, extract segments corresponding to queries, synthesize unobserved parts of videos, and predict context. This survey comprehensively reviews advances in uni- and multi-modal action understanding across a range of tasks. We focus on prevalent challenges, overview widely adopted datasets, and survey seminal works with an emphasis on recent advances. We broadly distinguish between three temporal scopes: (1) recognition tasks of actions observed in full, (2) prediction tasks for ongoing partially observed actions, and (3) forecasting tasks for subsequent unobserved action. This division allows us to identify specific action modeling and video representation challenges. Finally, we outline future directions to address current shortcomings.

[Arxiv](https://arxiv.org/abs/2411.15106)