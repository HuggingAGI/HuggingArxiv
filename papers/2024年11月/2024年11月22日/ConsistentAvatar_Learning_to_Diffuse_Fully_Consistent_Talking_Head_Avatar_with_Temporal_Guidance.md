# ConsistentAvatar：学习在时间引导下生成完全一致的会说话的头部虚拟形象

发布时间：2024年11月22日

`其他` `多媒体` `计算机图形学`

> ConsistentAvatar: Learning to Diffuse Fully Consistent Talking Head Avatar with Temporal Guidance

# 摘要

> 扩散模型在说话头像生成领域展现出了非凡的潜力。虽说获得了不错的外观和说话效果，可由于误差累积以及单图像生成能力的固有局限，这些方法在时间、3D 或表情的一致性上仍存在问题。本文中，我们提出了 ConsistentAvatar，这是一个用于实现完全一致且高保真说话头像生成的全新框架。我们的方法并非直接把多模态条件用于扩散过程，而是先学习为时间表征建模以保证相邻帧之间的稳定性。具体而言，我们提出了一个时间敏感细节（TSD）图，它包含沿时间轴变化显著的高频特征和轮廓。通过时间一致扩散模块，我们将初始结果的 TSD 与视频帧的真实情况进行对齐。最终的头像由完全一致的扩散模块生成，其条件为对齐的 TSD、粗糙的头部法线以及情感提示嵌入。我们发现，代表时间模式的对齐 TSD 能约束扩散过程生成时间稳定的说话头像。而且，它可靠的引导弥补了其他条件的不精确之处，抑制了累积误差，同时提升了各方面的一致性。大量实验表明，ConsistentAvatar 在生成的外观、3D、表情和时间一致性上都超越了最先进的方法。项目页面：https://njust-yang.github.io/ConsistentAvatar.github.io/

> Diffusion models have shown impressive potential on talking head generation. While plausible appearance and talking effect are achieved, these methods still suffer from temporal, 3D or expression inconsistency due to the error accumulation and inherent limitation of single-image generation ability. In this paper, we propose ConsistentAvatar, a novel framework for fully consistent and high-fidelity talking avatar generation. Instead of directly employing multi-modal conditions to the diffusion process, our method learns to first model the temporal representation for stability between adjacent frames. Specifically, we propose a Temporally-Sensitive Detail (TSD) map containing high-frequency feature and contours that vary significantly along the time axis. Using a temporal consistent diffusion module, we learn to align TSD of the initial result to that of the video frame ground truth. The final avatar is generated by a fully consistent diffusion module, conditioned on the aligned TSD, rough head normal, and emotion prompt embedding. We find that the aligned TSD, which represents the temporal patterns, constrains the diffusion process to generate temporally stable talking head. Further, its reliable guidance complements the inaccuracy of other conditions, suppressing the accumulated error while improving the consistency on various aspects. Extensive experiments demonstrate that ConsistentAvatar outperforms the state-of-the-art methods on the generated appearance, 3D, expression and temporal consistency. Project page: https://njust-yang.github.io/ConsistentAvatar.github.io/

[Arxiv](https://arxiv.org/abs/2411.15436)