# 生成式人工智能或许会给反言论带来负面作用

发布时间：2024年11月22日

`LLM应用` `社交媒体` `在线言论`

> Generative AI may backfire for counterspeech

# 摘要

> 在线仇恨言论严重威胁着个人的幸福和社会的凝聚力。遏制在线仇恨言论的一个颇具前景的办法是反驳言论，其旨在通过直接回复，促使用户重新思考那些充满仇恨的帖子。但当下的方法要么因需要人工介入而缺乏扩展性，要么难以适应帖子的特定语境。一个可能的解决办法是运用生成式人工智能，尤其是大型语言模型（LLMs）来创作定制化的反驳言论消息。在本文中，我们研究了由顶尖的LLMs生成的情境化反驳言论对遏制在线仇恨言论是否有效。为此，我们在社交媒体平台Twitter/X上开展了大规模、预先注册的实地实验（N=2664）。实验采用了2x2的被试间设计，另外还设置了无反驳言论的控制组。一方面，在Twitter/X上发布仇恨内容的用户被随机分配接收（a）情境化反驳言论或（b）非情境化反驳言论。其中，前者由LLMs生成，后者则依赖预先设定的通用消息。另一方面，我们测试了两种反驳言论策略：（a）增进同理心和（b）警示网络不当行为的后果。随后，我们衡量了用户是否删除了最初的仇恨性帖子，以及在反驳言论干预后他们的行为是否有所改变（比如，用户是否使用了毒性更低的语言）。我们发现，采用警示后果策略的非情境化反驳言论能显著减少在线仇恨言论。然而，由LLMs生成的情境化反驳言论不仅无效，甚至可能产生反效果。

> Online hate speech poses a serious threat to individual well-being and societal cohesion. A promising solution to curb online hate speech is counterspeech. Counterspeech is aimed at encouraging users to reconsider hateful posts by direct replies. However, current methods lack scalability due to the need for human intervention or fail to adapt to the specific context of the post. A potential remedy is the use of generative AI, specifically large language models (LLMs), to write tailored counterspeech messages. In this paper, we analyze whether contextualized counterspeech generated by state-of-the-art LLMs is effective in curbing online hate speech. To do so, we conducted a large-scale, pre-registered field experiment (N=2,664) on the social media platform Twitter/X. Our experiment followed a 2x2 between-subjects design and, additionally, a control condition with no counterspeech. On the one hand, users posting hateful content on Twitter/X were randomly assigned to receive either (a) contextualized counterspeech or (b) non-contextualized counterspeech. Here, the former is generated through LLMs, while the latter relies on predefined, generic messages. On the other hand, we tested two counterspeech strategies: (a) promoting empathy and (b) warning about the consequences of online misbehavior. We then measured whether users deleted their initial hateful posts and whether their behavior changed after the counterspeech intervention (e.g., whether users adopted a less toxic language). We find that non-contextualized counterspeech employing a warning-of-consequence strategy significantly reduces online hate speech. However, contextualized counterspeech generated by LLMs proves ineffective and may even backfire.

[Arxiv](https://arxiv.org/abs/2411.14986)