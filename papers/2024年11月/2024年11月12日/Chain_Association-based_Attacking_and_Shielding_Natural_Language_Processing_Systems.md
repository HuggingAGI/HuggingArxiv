# 基于链关联的攻击和防护自然语言处理系统

发布时间：2024年11月12日

`LLM应用` `对抗性攻击`

> Chain Association-based Attacking and Shielding Natural Language Processing Systems

# 摘要

> 作为礼物的联想使人们不必用完全直白的话语提及某事，并允许他人理解他们打算提及的内容。在本文中，我们针对自然语言处理系统提出了一种基于链联想的对抗性攻击，利用了人与机器之间的理解差距。我们首先根据联想范式为汉字生成链联想图，以构建潜在对抗性示例的搜索空间。然后，我们引入一种离散粒子群优化算法来搜索最优对抗性示例。我们进行了全面的实验，并表明先进的自然语言处理模型和应用，包括大型语言模型，都容易受到我们的攻击，而人类似乎善于理解被干扰的文本。我们还探索了两种方法，包括对抗训练和基于联想图的恢复，以保护系统免受基于链联想的攻击。由于有一些使用贬损性术语的例子，本文包含可能对某些人具有冒犯性或令人不安的材料。

> Association as a gift enables people do not have to mention something in completely straightforward words and allows others to understand what they intend to refer to. In this paper, we propose a chain association-based adversarial attack against natural language processing systems, utilizing the comprehension gap between humans and machines. We first generate a chain association graph for Chinese characters based on the association paradigm for building search space of potential adversarial examples. Then, we introduce an discrete particle swarm optimization algorithm to search for the optimal adversarial examples. We conduct comprehensive experiments and show that advanced natural language processing models and applications, including large language models, are vulnerable to our attack, while humans appear good at understanding the perturbed text. We also explore two methods, including adversarial training and associative graph-based recovery, to shield systems from chain association-based attack. Since a few examples that use some derogatory terms, this paper contains materials that may be offensive or upsetting to some people.

[Arxiv](https://arxiv.org/abs/2411.07843)