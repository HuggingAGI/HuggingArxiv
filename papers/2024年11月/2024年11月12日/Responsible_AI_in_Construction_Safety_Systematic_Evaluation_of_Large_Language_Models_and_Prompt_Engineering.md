# 建筑安全中的负责任人工智能：大型语言模型和提示工程的系统评估

发布时间：2024年11月12日

`LLM应用` `安全管理`

> Responsible AI in Construction Safety: Systematic Evaluation of Large Language Models and Prompt Engineering

# 摘要

> 建筑仍然是最危险的行业之一。人工智能的最新进展，特别是大型语言模型（LLM），为提高工作场所的安全性提供了有希望的机会。然而，负责任地整合 LLM 需要系统评估，因为在不了解其能力和局限性的情况下部署它们有产生不准确信息、培养错误信心和危及工人安全的风险。本研究评估了两种广泛使用的 LLM，GPT-3.5 和 GPT-4o，在由认证安全专业人员委员会（BCSP）管理的三项标准化考试中的表现。使用涵盖七个安全知识领域的 385 个问题，该研究分析了模型的准确性、一致性和可靠性。结果表明，这两个模型都始终超过 BCSP 基准，GPT-4o 的准确率达到 84.6％，GPT-3.5 达到 73.8％。两个模型在安全管理系统以及危险识别和控制方面表现出色，但在科学、数学、应急响应和防火方面存在不足。错误分析确定了影响 LLM 性能的四个主要限制：知识缺乏、推理缺陷、记忆问题和计算错误。我们的研究还强调了提示工程策略的影响，GPT-3.5 的准确率变化达到 13.5％，GPT-4o 达到 7.9％。然而，没有单一的提示配置被证明是普遍有效的。这项研究在三个方面推进了知识：通过确定 LLM 可以支持安全实践的领域以及人类监督仍然必不可少的领域，通过提供通过提示工程改进 LLM 实施的实用见解，以及通过为未来的研究和开发提供基于证据的方向。这些贡献支持在建筑安全管理中负责任地整合人工智能，以实现零伤害。

> Construction remains one of the most hazardous sectors. Recent advancements in AI, particularly Large Language Models (LLMs), offer promising opportunities for enhancing workplace safety. However, responsible integration of LLMs requires systematic evaluation, as deploying them without understanding their capabilities and limitations risks generating inaccurate information, fostering misplaced confidence, and compromising worker safety. This study evaluates the performance of two widely used LLMs, GPT-3.5 and GPT-4o, across three standardized exams administered by the Board of Certified Safety Professionals (BCSP). Using 385 questions spanning seven safety knowledge areas, the study analyzes the models' accuracy, consistency, and reliability. Results show that both models consistently exceed the BCSP benchmark, with GPT-4o achieving an accuracy rate of 84.6% and GPT-3.5 reaching 73.8%. Both models demonstrate strengths in safety management systems and hazard identification and control, but exhibit weaknesses in science, mathematics, emergency response, and fire prevention. An error analysis identifies four primary limitations affecting LLM performance: lack of knowledge, reasoning flaws, memory issues, and calculation errors. Our study also highlights the impact of prompt engineering strategies, with variations in accuracy reaching 13.5% for GPT-3.5 and 7.9% for GPT-4o. However, no single prompt configuration proves universally effective. This research advances knowledge in three ways: by identifying areas where LLMs can support safety practices and where human oversight remains essential, by offering practical insights into improving LLM implementation through prompt engineering, and by providing evidence-based direction for future research and development. These contributions support the responsible integration of AI in construction safety management toward achieving zero injuries.

[Arxiv](https://arxiv.org/abs/2411.08320)