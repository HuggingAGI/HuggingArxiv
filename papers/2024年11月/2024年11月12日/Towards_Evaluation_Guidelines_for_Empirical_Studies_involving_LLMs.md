# 走向涉及大型语言模型的实证研究评估指南

发布时间：2024年11月12日

`LLM应用` `软件工程` `语言模型`

> Towards Evaluation Guidelines for Empirical Studies involving LLMs

# 摘要

> 自 2022 年 11 月 ChatGPT 发布以来的短短时间里，大型语言模型（LLMs）改变了软件工程研究的局面。尽管利用 LLMs 来助力研究或软件工程任务的机会众多，但扎实的科学研究需要严格的实证评估。然而，迄今为止，在软件工程研究中针对涉及 LLMs 的研究开展和评估，尚无特定的指导方针。我们聚焦于将 LLMs 作为研究过程一部分（比如用于数据标注）的实证研究，或者对基于 LLMs 的现有或新工具进行评估的研究。本文为此类研究提供了首套指导方针。我们旨在于软件工程研究社区开启讨论，以就涉及 LLMs 的高质量实证研究的社区标准达成共识。

> In the short period since the release of ChatGPT in November 2022, large language models (LLMs) have changed the software engineering research landscape. While there are numerous opportunities to use LLMs for supporting research or software engineering tasks, solid science needs rigorous empirical evaluations. However, so far, there are no specific guidelines for conducting and assessing studies involving LLMs in software engineering research. Our focus is on empirical studies that either use LLMs as part of the research process (e.g., for data annotation) or studies that evaluate existing or new tools that are based on LLMs. This paper contributes the first set of guidelines for such studies. Our goal is to start a discussion in the software engineering research community to reach a common understanding of what our community standards are for high-quality empirical studies involving LLMs.

[Arxiv](https://arxiv.org/abs/2411.07668)