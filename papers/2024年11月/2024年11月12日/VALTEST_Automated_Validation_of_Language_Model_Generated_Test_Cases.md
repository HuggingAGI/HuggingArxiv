# VALTEST：语言模型生成的测试用例的自动验证

发布时间：2024年11月12日

`LLM应用` `软件测试` `机器学习`

> VALTEST: Automated Validation of Language Model Generated Test Cases

# 摘要

> 大型语言模型（LLMs）在自动化软件测试方面，特别是在生成单元测试用例方面，已经展现出巨大的潜力。然而，对 LLM 生成的测试用例的验证仍然是一个挑战，特别是在没有真实基准的情况下。本文介绍了 VALTEST，这是一个通过利用标记概率来自动验证 LLM 生成的测试用例的新框架。我们使用从三个数据集（HumanEval、MBPP 和 LeetCode）生成的九个测试套件，在三个 LLM（GPT-4o、GPT-3.5-turbo 和 LLama3.1 8b）上对 VALTEST 进行评估。通过从标记概率中提取统计特征，我们训练了一个机器学习模型来预测测试用例的有效性。VALTEST 根据数据集和 LLM 的不同，将测试用例的有效率提高了 6.2%至 24%。我们的结果表明，标记概率是区分有效和无效测试用例的可靠指标，为提高软件测试中 LLM 生成的测试用例的正确性提供了一个强大的解决方案。此外，我们发现，通过 VALTEST 替换已识别的无效测试用例，并使用思维链提示，在保持高有效率的同时，会产生更有效的测试套件。

> Large Language Models (LLMs) have demonstrated significant potential in automating software testing, specifically in generating unit test cases. However, the validation of LLM-generated test cases remains a challenge, particularly when the ground truth is unavailable. This paper introduces VALTEST, a novel framework designed to automatically validate test cases generated by LLMs by leveraging token probabilities. We evaluate VALTEST using nine test suites generated from three datasets (HumanEval, MBPP, and LeetCode) across three LLMs (GPT-4o, GPT-3.5-turbo, and LLama3.1 8b). By extracting statistical features from token probabilities, we train a machine learning model to predict test case validity. VALTEST increases the validity rate of test cases by 6.2% to 24%, depending on the dataset and LLM. Our results suggest that token probabilities are reliable indicators for distinguishing between valid and invalid test cases, which provides a robust solution for improving the correctness of LLM-generated test cases in software testing. In addition, we found that replacing the identified invalid test cases by VALTEST, using a Chain-of-Thought prompting results in a more effective test suite while keeping the high validity rates.

[Arxiv](https://arxiv.org/abs/2411.08254)