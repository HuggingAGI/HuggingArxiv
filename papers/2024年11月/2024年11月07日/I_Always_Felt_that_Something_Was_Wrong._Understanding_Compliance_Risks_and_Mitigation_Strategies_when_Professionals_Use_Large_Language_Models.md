# “我总是觉得有些不对劲。”：理解专业人员使用大型语言模型时的合规风险和缓解策略

发布时间：2024年11月07日

`LLM应用` `医疗保健`

> "I Always Felt that Something Was Wrong.": Understanding Compliance Risks and Mitigation Strategies when Professionals Use Large Language Models

# 摘要

> 大型语言模型（LLMs）已越来越多地被专业人员用于工作任务。然而，使用 LLMs 也会带来与隐私、伦理和法规相关的合规风险。本研究调查了专业人员对使用 LLMs 所感知到的合规风险以及他们的风险缓解策略。对 24 位来自法律、医疗保健和学术界的专业人员进行了半结构化访谈。结果表明，主要的合规担忧集中在通过 LLMs 可能暴露敏感的客户/患者信息。为应对风险，专业人员报告称会主动输入扭曲的数据以保护隐私。然而，鉴于用户输入、LLM 行为和法规之间的复杂相互作用，完全合规被证明具有挑战性。这项研究为设计具有内置隐私和风险控制的 LLMs 提供了有价值的见解，以支持专业人员在履行合规义务的同时评估和采用新兴的人工智能技术。

> Large Language Models (LLMs) have been increasingly adopted by professionals for work tasks. However, using LLMs also introduces compliance risks relating to privacy, ethics, and regulations. This study investigated the compliance risks professionals perceive with LLM use and their risk mitigation strategies. Semi-structured interviews were conducted with 24 law, healthcare, and academia professionals. Results showed that the main compliance concerns centered around potential exposure to sensitive customer/patient information through LLMs. To address risks, professionals reported proactively inputting distorted data to preserve privacy. However, full compliance proved challenging, given the complex interactions between user inputs, LLM behaviors, and regulations. This research provides valuable insights into designing LLMs with built-in privacy and risk controls to support professionals' evaluation and adoption of emerging AI technologies while meeting compliance obligations.

[Arxiv](https://arxiv.org/abs/2411.04576)