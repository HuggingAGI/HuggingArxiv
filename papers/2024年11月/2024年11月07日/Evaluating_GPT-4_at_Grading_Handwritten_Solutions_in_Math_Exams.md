# 对 GPT-4 在数学考试中手写答案的评分情况进行评估

发布时间：2024年11月07日

`LLM应用` `人工智能评估`

> Evaluating GPT-4 at Grading Handwritten Solutions in Math Exams

# 摘要

> 近期生成式人工智能（AI）的进步展现出在精准评定开放式学生回答方面的潜力。然而，此前因数据缺乏以及融合视觉与文本信息存在困难，鲜少有人研究手写回答的评分。在本项工作中，我们借助顶尖的多模态 AI 模型，尤其是 GPT-4o，对大学水平数学考试的手写回答进行自动评分。通过真实学生在概率论考试中对问题的回答，我们运用多种提示技术来评估 GPT-4o 与人类评分者给出的真实分数的契合度。我们发现，尽管提供评分准则能增强契合度，但该模型的整体准确率在实际应用中仍过低，这表明此任务还有很大的进步空间。

> Recent advances in generative artificial intelligence (AI) have shown promise in accurately grading open-ended student responses. However, few prior works have explored grading handwritten responses due to a lack of data and the challenge of combining visual and textual information. In this work, we leverage state-of-the-art multi-modal AI models, in particular GPT-4o, to automatically grade handwritten responses to college-level math exams. Using real student responses to questions in a probability theory exam, we evaluate GPT-4o's alignment with ground-truth scores from human graders using various prompting techniques. We find that while providing rubrics improves alignment, the model's overall accuracy is still too low for real-world settings, showing there is significant room for growth in this task.

[Arxiv](https://arxiv.org/abs/2411.05231)