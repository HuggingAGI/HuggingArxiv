# 探索 JPEG AI 的对抗鲁棒性：方法论、比较及新手段

发布时间：2024年11月18日

`LLM应用` `计算机视觉` `神经网络`

> Exploring adversarial robustness of JPEG AI: methodology, comparison and new methods

# 摘要

> 神经网络的对抗鲁棒性是一个愈发重要的研究领域，涵盖了对计算机视觉模型、大型语言模型（LLMs）等的研究。随着端到端神经图像压缩（NIC）方法的首个标准 JPEG AI 的发布，其鲁棒性问题变得极为关键。JPEG AI 是首批嵌入消费设备的基于神经网络模型的国际实际应用之一。但此前对 NIC 鲁棒性的研究仅局限于开源编解码器和有限的攻击类型。本文提出了一种衡量 NIC 对抗攻击鲁棒性的新方法。我们首次对 JPEG AI 的鲁棒性进行了大规模评估，并与其他 NIC 模型做了对比。我们的评估结果和代码已在网上公开（链接因盲审暂隐）。

> Adversarial robustness of neural networks is an increasingly important area of research, combining studies on computer vision models, large language models (LLMs), and others. With the release of JPEG AI - the first standard for end-to-end neural image compression (NIC) methods - the question of its robustness has become critically significant. JPEG AI is among the first international, real-world applications of neural-network-based models to be embedded in consumer devices. However, research on NIC robustness has been limited to open-source codecs and a narrow range of attacks. This paper proposes a new methodology for measuring NIC robustness to adversarial attacks. We present the first large-scale evaluation of JPEG AI's robustness, comparing it with other NIC models. Our evaluation results and code are publicly available online (link is hidden for a blind review).

[Arxiv](https://arxiv.org/abs/2411.11795)