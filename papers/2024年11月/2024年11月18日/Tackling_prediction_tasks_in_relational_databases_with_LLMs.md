# 利用大型语言模型应对关系数据库中的预测任务

发布时间：2024年11月18日

`LLM应用` `数据库` `机器学习`

> Tackling prediction tasks in relational databases with LLMs

# 摘要

> 尽管大型语言模型（LLMs）在诸多问题上表现非凡，但其在关系数据库预测任务中的应用却基本未被涉足。在本研究中，我们针对因关系数据库中相互关联的表、复杂的关系以及异构的数据类型，导致 LLMs 无法在关系数据库上取得满意结果这一观点进行了探讨。借助近期推出的 RelBench 基准，我们表明，即便是对 LLMs 的直接应用，在这些任务上也能获得颇具竞争力的性能。这些发现使 LLMs 成为关系数据库上机器学习颇具前景的新基准，并激励着该方向的进一步研究。

> Though large language models (LLMs) have demonstrated exceptional performance across numerous problems, their application to predictive tasks in relational databases remains largely unexplored. In this work, we address the notion that LLMs cannot yield satisfactory results on relational databases due to their interconnected tables, complex relationships, and heterogeneous data types. Using the recently introduced RelBench benchmark, we demonstrate that even a straightforward application of LLMs achieves competitive performance on these tasks. These findings establish LLMs as a promising new baseline for ML on relational databases and encourage further research in this direction.

[Arxiv](https://arxiv.org/abs/2411.11829)