# 《众多的力量：文化图像字幕的多智能体多模态模型》

发布时间：2024年11月18日

`Agent` `多模态` `跨文化研究`

> The Power of Many: Multi-Agent Multimodal Models for Cultural Image Captioning

# 摘要

> 大型多模态模型（LMMs）在各类多模态任务中表现抢眼。不过，由于多数数据和模型主要以西方为中心，其在跨文化情境中的成效有限。与此相反，多智能体模型在解决复杂任务时展现出强大能力。我们的研究对 LMMs 在多智能体交互场景下针对文化图像字幕这一全新任务的整体表现进行了评估。我们的贡献有：（1）引入了 MosAIC，这是一个多智能体框架，借助具有不同文化角色的 LMMs 来强化跨文化图像字幕；（2）为来自中国、印度和罗马尼亚的图像提供了一个英语的富含文化元素的图像字幕数据集，涵盖了 GeoDE、GD-VCR、CVQA 这三个数据集；（3）提出了一种适应文化的指标，用于评估图像字幕中的文化信息；（4）表明在不同指标下，多智能体交互优于单智能体模型，并为后续研究提供了宝贵见解。我们的数据集和模型可在 https://github.com/MichiganNLP/MosAIC 获取。

> Large Multimodal Models (LMMs) exhibit impressive performance across various multimodal tasks. However, their effectiveness in cross-cultural contexts remains limited due to the predominantly Western-centric nature of most data and models. Conversely, multi-agent models have shown significant capability in solving complex tasks. Our study evaluates the collective performance of LMMs in a multi-agent interaction setting for the novel task of cultural image captioning. Our contributions are as follows: (1) We introduce MosAIC, a Multi-Agent framework to enhance cross-cultural Image Captioning using LMMs with distinct cultural personas; (2) We provide a dataset of culturally enriched image captions in English for images from China, India, and Romania across three datasets: GeoDE, GD-VCR, CVQA; (3) We propose a culture-adaptable metric for evaluating cultural information within image captions; and (4) We show that the multi-agent interaction outperforms single-agent models across different metrics, and offer valuable insights for future research. Our dataset and models can be accessed at https://github.com/MichiganNLP/MosAIC.

[Arxiv](https://arxiv.org/abs/2411.11758)