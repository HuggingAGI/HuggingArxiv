# 评估“宪法”于从人工智能反馈进行学习所起的作用

发布时间：2024年11月15日

`LLM应用` `人工智能`

> Evaluating the role of `Constitutions' for learning from AI feedback

# 摘要

> 大型语言模型（LLMs）能力的日益提升，使其能够替代人类反馈，用于训练和评估其他 LLMs。这些方法往往依赖“章程”，也就是批评模型用于提供反馈和改进生成的书面准则。我们通过采用四种不同的章程来优化医疗访谈中的以患者为中心的沟通，探究了章程的选择对反馈质量的影响。在 215 名人类评估者进行的成对比较中，我们发现详细的章程在情感品质方面效果更佳。但在学习与信息收集和提供相关的更实用的技能方面，没有一种章程能超越基线。我们的发现表明，尽管应优先选择详细的章程，但在某些领域，人工智能反馈作为奖励信号的有效性可能存在局限。

> The growing capabilities of large language models (LLMs) have led to their use as substitutes for human feedback for training and assessing other LLMs. These methods often rely on `constitutions', written guidelines which a critic model uses to provide feedback and improve generations. We investigate how the choice of constitution affects feedback quality by using four different constitutions to improve patient-centered communication in medical interviews. In pairwise comparisons conducted by 215 human raters, we found that detailed constitutions led to better results regarding emotive qualities. However, none of the constitutions outperformed the baseline in learning more practically-oriented skills related to information gathering and provision. Our findings indicate that while detailed constitutions should be prioritised, there are possible limitations to the effectiveness of AI feedback as a reward signal in certain areas.

[Arxiv](https://arxiv.org/abs/2411.10168)