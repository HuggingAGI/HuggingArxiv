# 2024年11月

2024年11月07日

- [An Empirical Study on the Potential of LLMs in Automated Software Refactoring](2024年11月07日/An_Empirical_Study_on_the_Potential_of_LLMs_in_Automated_Software_Refactoring.md)

    - [翻译: 关于大型语言模型在自动化软件重构中的潜力的实证研究](2024年11月07日/An_Empirical_Study_on_the_Potential_of_LLMs_in_Automated_Software_Refactoring.md)

- [Automatic Identification of Political Hate Articles from Social Media using Recurrent Neural Networks](2024年11月07日/Automatic_Identification_of_Political_Hate_Articles_from_Social_Media_using_Recurrent_Neural_Networks.md)

    - [翻译: 使用循环神经网络从社交媒体中自动识别政治仇恨文章](2024年11月07日/Automatic_Identification_of_Political_Hate_Articles_from_Social_Media_using_Recurrent_Neural_Networks.md)

- [AutoProteinEngine: A Large Language Model Driven Agent Framework for Multimodal AutoML in Protein Engineering](2024年11月07日/AutoProteinEngine_A_Large_Language_Model_Driven_Agent_Framework_for_Multimodal_AutoML_in_Protein_Engineering.md)

    - [翻译: AutoProteinEngine：用于蛋白质工程中多模态自动机器学习的大型语言模型驱动的代理框架](2024年11月07日/AutoProteinEngine_A_Large_Language_Model_Driven_Agent_Framework_for_Multimodal_AutoML_in_Protein_Engineering.md)

- [AWARE Narrator and the Utilization of Large Language Models to Extract Behavioral Insights from Smartphone Sensing Data](2024年11月07日/AWARE_Narrator_and_the_Utilization_of_Large_Language_Models_to_Extract_Behavioral_Insights_from_Smartphone_Sensing_Data.md)

    - [翻译: AWARE 叙述者和利用大型语言模型从智能手机传感数据中提取行为洞察](2024年11月07日/AWARE_Narrator_and_the_Utilization_of_Large_Language_Models_to_Extract_Behavioral_Insights_from_Smartphone_Sensing_Data.md)

- [Best Practices for Distilling Large Language Models into BERT for Web Search Ranking](2024年11月07日/Best_Practices_for_Distilling_Large_Language_Models_into_BERT_for_Web_Search_Ranking.md)

    - [翻译: 将大型语言模型提炼为 BERT 用于网络搜索排名的最佳实践](2024年11月07日/Best_Practices_for_Distilling_Large_Language_Models_into_BERT_for_Web_Search_Ranking.md)

- [CAD-MLLM: Unifying Multimodality-Conditioned CAD Generation With MLLM](2024年11月07日/CAD-MLLM_Unifying_Multimodality-Conditioned_CAD_Generation_With_MLLM.md)

    - [翻译: CAD-MLLM：用 MLLM 统一多模态条件下的 CAD 生成](2024年11月07日/CAD-MLLM_Unifying_Multimodality-Conditioned_CAD_Generation_With_MLLM.md)

- [CaPo: Cooperative Plan Optimization for Efficient Embodied Multi-Agent Cooperation](2024年11月07日/CaPo_Cooperative_Plan_Optimization_for_Efficient_Embodied_Multi-Agent_Cooperation.md)

    - [翻译: CaPo：用于高效具身多智能体合作的协同计划优化](2024年11月07日/CaPo_Cooperative_Plan_Optimization_for_Efficient_Embodied_Multi-Agent_Cooperation.md)

- [CUIfy the XR: An Open-Source Package to Embed LLM-powered Conversational Agents in XR](2024年11月07日/CUIfy_the_XR_An_Open-Source_Package_to_Embed_LLM-powered_Conversational_Agents_in_XR.md)

    - [翻译: CUIfy 扩展现实（XR）：一个将由大型语言模型（LLM）驱动的会话代理嵌入扩展现实的开源软件包](2024年11月07日/CUIfy_the_XR_An_Open-Source_Package_to_Embed_LLM-powered_Conversational_Agents_in_XR.md)

- [Diff-2-in-1: Bridging Generation and Dense Perception with Diffusion Models](2024年11月07日/Diff-2-in-1_Bridging_Generation_and_Dense_Perception_with_Diffusion_Models.md)

    - [翻译: Diff-2-in-1：用扩散模型架起生成和密集感知的桥梁](2024年11月07日/Diff-2-in-1_Bridging_Generation_and_Dense_Perception_with_Diffusion_Models.md)

- [Distinguishing LLM-generated from Human-written Code by Contrastive Learning](2024年11月07日/Distinguishing_LLM-generated_from_Human-written_Code_by_Contrastive_Learning.md)

    - [翻译: 通过对比学习区分大型语言模型生成的代码和人类编写的代码](2024年11月07日/Distinguishing_LLM-generated_from_Human-written_Code_by_Contrastive_Learning.md)

- [Enhancing Reverse Engineering: Investigating and Benchmarking Large Language Models for Vulnerability Analysis in Decompiled Binaries](2024年11月07日/Enhancing_Reverse_Engineering_Investigating_and_Benchmarking_Large_Language_Models_for_Vulnerability_Analysis_in_Decompiled_Binaries.md)

    - [翻译: 增强逆向工程：为在反编译二进制文件中的漏洞分析研究和基准测试大型语言模型](2024年11月07日/Enhancing_Reverse_Engineering_Investigating_and_Benchmarking_Large_Language_Models_for_Vulnerability_Analysis_in_Decompiled_Binaries.md)

- [Explainable Search and Discovery of Visual Cultural Heritage Collections with Multimodal Large Language Models](2024年11月07日/Explainable_Search_and_Discovery_of_Visual_Cultural_Heritage_Collections_with_Multimodal_Large_Language_Models.md)

    - [翻译: 利用多模态大型语言模型对视觉文化遗产收藏进行可解释的搜索和发现](2024年11月07日/Explainable_Search_and_Discovery_of_Visual_Cultural_Heritage_Collections_with_Multimodal_Large_Language_Models.md)

- [Exploring Hierarchical Molecular Graph Representation in Multimodal LLMs](2024年11月07日/Exploring_Hierarchical_Molecular_Graph_Representation_in_Multimodal_LLMs.md)

    - [翻译: 探索多模态大型语言模型中的分层分子图表示](2024年11月07日/Exploring_Hierarchical_Molecular_Graph_Representation_in_Multimodal_LLMs.md)

- [Gradient Localization Improves Lifelong Pretraining of Language Models](2024年11月07日/Gradient_Localization_Improves_Lifelong_Pretraining_of_Language_Models.md)

    - [翻译: 梯度本地化改进了语言模型的终身预训练。](2024年11月07日/Gradient_Localization_Improves_Lifelong_Pretraining_of_Language_Models.md)

- [GUI Agents with Foundation Models: A Comprehensive Survey](2024年11月07日/GUI_Agents_with_Foundation_Models_A_Comprehensive_Survey.md)

    - [翻译: 带有基础模型的图形用户界面代理：一项综合调查](2024年11月07日/GUI_Agents_with_Foundation_Models_A_Comprehensive_Survey.md)

- ["I Always Felt that Something Was Wrong.": Understanding Compliance Risks and Mitigation Strategies when Professionals Use Large Language Models](2024年11月07日/I_Always_Felt_that_Something_Was_Wrong._Understanding_Compliance_Risks_and_Mitigation_Strategies_when_Professionals_Use_Large_Language_Models.md)

    - [翻译: “我总是觉得有些不对劲。”：理解专业人员使用大型语言模型时的合规风险和缓解策略](2024年11月07日/I_Always_Felt_that_Something_Was_Wrong._Understanding_Compliance_Risks_and_Mitigation_Strategies_when_Professionals_Use_Large_Language_Models.md)

- [ICH-SCNet: Intracerebral Hemorrhage Segmentation and Prognosis Classification Network Using CLIP-guided SAM mechanism](2024年11月07日/ICH-SCNet_Intracerebral_Hemorrhage_Segmentation_and_Prognosis_Classification_Network_Using_CLIP-guided_SAM_mechanism.md)

    - [翻译: ICH-SCNet：使用 CLIP 引导的 SAM 机制的脑出血分割和预后分类网络](2024年11月07日/ICH-SCNet_Intracerebral_Hemorrhage_Segmentation_and_Prognosis_Classification_Network_Using_CLIP-guided_SAM_mechanism.md)

- [LLM2CLIP: Powerful Language Model Unlock Richer Visual Representation](2024年11月07日/LLM2CLIP_Powerful_Language_Model_Unlock_Richer_Visual_Representation.md)

    - [翻译: LLM2CLIP：强大的语言模型解锁更丰富的视觉表示](2024年11月07日/LLM2CLIP_Powerful_Language_Model_Unlock_Richer_Visual_Representation.md)

- [LLM-R: A Framework for Domain-Adaptive Maintenance Scheme Generation Combining Hierarchical Agents and RAG](2024年11月07日/LLM-R_A_Framework_for_Domain-Adaptive_Maintenance_Scheme_Generation_Combining_Hierarchical_Agents_and_RAG.md)

    - [翻译: LLM-R：一个结合分层代理和 RAG 用于生成领域自适应维护方案的框架](2024年11月07日/LLM-R_A_Framework_for_Domain-Adaptive_Maintenance_Scheme_Generation_Combining_Hierarchical_Agents_and_RAG.md)

- [LuxBank: The First Universal Dependency Treebank for Luxembourgish](2024年11月07日/LuxBank_The_First_Universal_Dependency_Treebank_for_Luxembourgish.md)

    - [翻译: LuxBank：卢森堡语的第一个通用依存树库](2024年11月07日/LuxBank_The_First_Universal_Dependency_Treebank_for_Luxembourgish.md)

- [M3DocRAG: Multi-modal Retrieval is What You Need for Multi-page Multi-document Understanding](2024年11月07日/M3DocRAG_Multi-modal_Retrieval_is_What_You_Need_for_Multi-page_Multi-document_Understanding.md)

    - [翻译: M3DocRAG：多模态检索是您理解多页多文档所需要的。](2024年11月07日/M3DocRAG_Multi-modal_Retrieval_is_What_You_Need_for_Multi-page_Multi-document_Understanding.md)

- [Measure-to-measure interpolation using Transformers](2024年11月07日/Measure-to-measure_interpolation_using_Transformers.md)

    - [翻译: 使用 Transformer 的度量到度量插值](2024年11月07日/Measure-to-measure_interpolation_using_Transformers.md)

- [Meta-Reasoning Improves Tool Use in Large Language Models](2024年11月07日/Meta-Reasoning_Improves_Tool_Use_in_Large_Language_Models.md)

    - [翻译: 元推理在大型语言模型中提高了工具的使用。](2024年11月07日/Meta-Reasoning_Improves_Tool_Use_in_Large_Language_Models.md)

- [Mixture-of-Transformers: A Sparse and Scalable Architecture for Multi-Modal Foundation Models](2024年11月07日/Mixture-of-Transformers_A_Sparse_and_Scalable_Architecture_for_Multi-Modal_Foundation_Models.md)

    - [翻译: 混合 Transformer：一种用于多模态基础模型的稀疏且可扩展的架构](2024年11月07日/Mixture-of-Transformers_A_Sparse_and_Scalable_Architecture_for_Multi-Modal_Foundation_Models.md)

- [ML-Promise: A Multilingual Dataset for Corporate Promise Verification](2024年11月07日/ML-Promise_A_Multilingual_Dataset_for_Corporate_Promise_Verification.md)

    - [翻译: ML-Promise：一个用于企业承诺验证的多语言数据集](2024年11月07日/ML-Promise_A_Multilingual_Dataset_for_Corporate_Promise_Verification.md)

- [Needle Threading: Can LLMs Follow Threads through Near-Million-Scale Haystacks?](2024年11月07日/Needle_Threading_Can_LLMs_Follow_Threads_through_Near-Million-Scale_Haystacks.md)

    - [翻译: 穿针引线：大型语言模型能否在近百万规模的干草堆中循线而行？](2024年11月07日/Needle_Threading_Can_LLMs_Follow_Threads_through_Near-Million-Scale_Haystacks.md)

- [OpenCoder: The Open Cookbook for Top-Tier Code Large Language Models](2024年11月07日/OpenCoder_The_Open_Cookbook_for_Top-Tier_Code_Large_Language_Models.md)

    - [翻译: OpenCoder：顶级代码大型语言模型的开放食谱](2024年11月07日/OpenCoder_The_Open_Cookbook_for_Top-Tier_Code_Large_Language_Models.md)

- [PIAST: A Multimodal Piano Dataset with Audio, Symbolic and Text](2024年11月07日/PIAST_A_Multimodal_Piano_Dataset_with_Audio,_Symbolic_and_Text.md)

    - [翻译: PIAST：一个具有音频、符号和文本的多模态钢琴数据集](2024年11月07日/PIAST_A_Multimodal_Piano_Dataset_with_Audio,_Symbolic_and_Text.md)

- [Position Paper On Diagnostic Uncertainty Estimation from Large Language Models: Next-Word Probability Is Not Pre-test Probability](2024年11月07日/Position_Paper_On_Diagnostic_Uncertainty_Estimation_from_Large_Language_Models_Next-Word_Probability_Is_Not_Pre-test_Probability.md)

    - [翻译: 关于大型语言模型诊断不确定性估计的立场文件：下一个词的概率不是预测试概率](2024年11月07日/Position_Paper_On_Diagnostic_Uncertainty_Estimation_from_Large_Language_Models_Next-Word_Probability_Is_Not_Pre-test_Probability.md)

- [Prompt-Guided Internal States for Hallucination Detection of Large Language Models](2024年11月07日/Prompt-Guided_Internal_States_for_Hallucination_Detection_of_Large_Language_Models.md)

    - [翻译: 提示引导的内部状态用于大型语言模型的幻觉检测](2024年11月07日/Prompt-Guided_Internal_States_for_Hallucination_Detection_of_Large_Language_Models.md)

- [Rethinking Bradley-Terry Models in Preference-Based Reward Modeling: Foundations, Theory, and Alternatives](2024年11月07日/Rethinking_Bradley-Terry_Models_in_Preference-Based_Reward_Modeling_Foundations,_Theory,_and_Alternatives.md)

    - [翻译: 在基于偏好的奖励建模中重新思考布拉德利-特里模型：基础、理论和替代方案](2024年11月07日/Rethinking_Bradley-Terry_Models_in_Preference-Based_Reward_Modeling_Foundations,_Theory,_and_Alternatives.md)

- [SaSR-Net: Source-Aware Semantic Representation Network for Enhancing Audio-Visual Question Answering](2024年11月07日/SaSR-Net_Source-Aware_Semantic_Representation_Network_for_Enhancing_Audio-Visual_Question_Answering.md)

    - [翻译: SaSR-Net：用于增强视听问答的源感知语义表示网络](2024年11月07日/SaSR-Net_Source-Aware_Semantic_Representation_Network_for_Enhancing_Audio-Visual_Question_Answering.md)

- [Self-Calibrated Listwise Reranking with Large Language Models](2024年11月07日/Self-Calibrated_Listwise_Reranking_with_Large_Language_Models.md)

    - [翻译: 具有大型语言模型的自校准列表式重排序](2024年11月07日/Self-Calibrated_Listwise_Reranking_with_Large_Language_Models.md)

- [SpectraFM: Tuning into Stellar Foundation Models](2024年11月07日/SpectraFM_Tuning_into_Stellar_Foundation_Models.md)

    - [翻译: SpectraFM：调谐到恒星基础模型](2024年11月07日/SpectraFM_Tuning_into_Stellar_Foundation_Models.md)

- [SVDQunat: Absorbing Outliers by Low-Rank Components for 4-Bit Diffusion Models](2024年11月07日/SVDQunat_Absorbing_Outliers_by_Low-Rank_Components_for_4-Bit_Diffusion_Models.md)

    - [翻译: SVDQunat：通过低秩分量吸收 4 位扩散模型中的异常值](2024年11月07日/SVDQunat_Absorbing_Outliers_by_Low-Rank_Components_for_4-Bit_Diffusion_Models.md)

- [TexLiverNet: Leveraging Medical Knowledge and Spatial-Frequency Perception for Enhanced Liver Tumor Segmentation](2024年11月07日/TexLiverNet_Leveraging_Medical_Knowledge_and_Spatial-Frequency_Perception_for_Enhanced_Liver_Tumor_Segmentation.md)

    - [翻译: TexLiverNet：利用医学知识和空间频率感知来增强肝脏肿瘤分割](2024年11月07日/TexLiverNet_Leveraging_Medical_Knowledge_and_Spatial-Frequency_Perception_for_Enhanced_Liver_Tumor_Segmentation.md)

- [Thanos: Enhancing Conversational Agents with Skill-of-Mind-Infused Large Language Model](2024年11月07日/Thanos_Enhancing_Conversational_Agents_with_Skill-of-Mind-Infused_Large_Language_Model.md)

    - [翻译: 萨诺斯：用注入思维技能的大型语言模型增强会话代理](2024年11月07日/Thanos_Enhancing_Conversational_Agents_with_Skill-of-Mind-Infused_Large_Language_Model.md)

- [The Semantic Hub Hypothesis: Language Models Share Semantic Representations Across Languages and Modalities](2024年11月07日/The_Semantic_Hub_Hypothesis_Language_Models_Share_Semantic_Representations_Across_Languages_and_Modalities.md)

    - [翻译: 《语义中心假说：语言模型在不同语言和模态之间共享语义表示》](2024年11月07日/The_Semantic_Hub_Hypothesis_Language_Models_Share_Semantic_Representations_Across_Languages_and_Modalities.md)

- [Vision Language Models are In-Context Value Learners](2024年11月07日/Vision_Language_Models_are_In-Context_Value_Learners.md)

    - [翻译: 视觉语言模型是上下文价值学习者](2024年11月07日/Vision_Language_Models_are_In-Context_Value_Learners.md)

- [VTechAGP: An Academic-to-General-Audience Text Paraphrase Dataset and Benchmark Models](2024年11月07日/VTechAGP_An_Academic-to-General-Audience_Text_Paraphrase_Dataset_and_Benchmark_Models.md)

    - [翻译: VTechAGP：一个从学术到大众的文本释义数据集和基准模型](2024年11月07日/VTechAGP_An_Academic-to-General-Audience_Text_Paraphrase_Dataset_and_Benchmark_Models.md)

2024年11月06日

- [A Bayesian Approach to Data Point Selection](2024年11月06日/A_Bayesian_Approach_to_Data_Point_Selection.md)

    - [翻译: 一种用于数据点选择的贝叶斯方法](2024年11月06日/A_Bayesian_Approach_to_Data_Point_Selection.md)

- [A Comparative Study of Recent Large Language Models on Generating Hospital Discharge Summaries for Lung Cancer Patients](2024年11月06日/A_Comparative_Study_of_Recent_Large_Language_Models_on_Generating_Hospital_Discharge_Summaries_for_Lung_Cancer_Patients.md)

    - [翻译: 关于近期大型语言模型在为肺癌患者生成出院小结方面的比较研究](2024年11月06日/A_Comparative_Study_of_Recent_Large_Language_Models_on_Generating_Hospital_Discharge_Summaries_for_Lung_Cancer_Patients.md)

- [Automated Update of Android Deprecated API Usages with Large Language Models](2024年11月06日/Automated_Update_of_Android_Deprecated_API_Usages_with_Large_Language_Models.md)

    - [翻译: 使用大型语言模型对 Android 已弃用 API 用法进行自动更新](2024年11月06日/Automated_Update_of_Android_Deprecated_API_Usages_with_Large_Language_Models.md)

- [Automating Exploratory Proteomics Research via Language Models](2024年11月06日/Automating_Exploratory_Proteomics_Research_via_Language_Models.md)

    - [翻译: 通过语言模型实现探索性蛋白质组学研究的自动化](2024年11月06日/Automating_Exploratory_Proteomics_Research_via_Language_Models.md)

- [Bayesian Calibration of Win Rate Estimation with LLM Evaluators](2024年11月06日/Bayesian_Calibration_of_Win_Rate_Estimation_with_LLM_Evaluators.md)

    - [翻译: 贝叶斯校准具有 LLM 评估器的胜率估计](2024年11月06日/Bayesian_Calibration_of_Win_Rate_Estimation_with_LLM_Evaluators.md)

- [Benchmarking Multimodal Retrieval Augmented Generation with Dynamic VQA Dataset and Self-adaptive Planning Agent](2024年11月06日/Benchmarking_Multimodal_Retrieval_Augmented_Generation_with_Dynamic_VQA_Dataset_and_Self-adaptive_Planning_Agent.md)

    - [翻译: 使用动态 VQA 数据集和自适应规划代理对多模态检索增强生成进行基准测试](2024年11月06日/Benchmarking_Multimodal_Retrieval_Augmented_Generation_with_Dynamic_VQA_Dataset_and_Self-adaptive_Planning_Agent.md)

- [Bio-xLSTM: Generative modeling, representation and in-context learning of biological and chemical sequences](2024年11月06日/Bio-xLSTM_Generative_modeling,_representation_and_in-context_learning_of_biological_and_chemical_sequences.md)

    - [翻译: Bio-xLSTM：生物和化学序列的生成建模、表示和上下文学习](2024年11月06日/Bio-xLSTM_Generative_modeling,_representation_and_in-context_learning_of_biological_and_chemical_sequences.md)

- [CodeTree: Agent-guided Tree Search for Code Generation with Large Language Models](2024年11月06日/CodeTree_Agent-guided_Tree_Search_for_Code_Generation_with_Large_Language_Models.md)

    - [翻译: CodeTree：使用大型语言模型进行代码生成的代理引导树搜索](2024年11月06日/CodeTree_Agent-guided_Tree_Search_for_Code_Generation_with_Large_Language_Models.md)

- [Customized Multiple Clustering via Multi-Modal Subspace Proxy Learning](2024年11月06日/Customized_Multiple_Clustering_via_Multi-Modal_Subspace_Proxy_Learning.md)

    - [翻译: 通过多模态子空间代理学习的定制多聚类](2024年11月06日/Customized_Multiple_Clustering_via_Multi-Modal_Subspace_Proxy_Learning.md)

- [DELIFT: Data Efficient Language model Instruction Fine Tuning](2024年11月06日/DELIFT_Data_Efficient_Language_model_Instruction_Fine_Tuning.md)

    - [翻译: DELIFT：数据高效语言模型指令微调](2024年11月06日/DELIFT_Data_Efficient_Language_model_Instruction_Fine_Tuning.md)

- [Enhancing classroom teaching with LLMs and RAG](2024年11月06日/Enhancing_classroom_teaching_with_LLMs_and_RAG.md)

    - [翻译: 用大型语言模型和检索增强生成改善课堂教学](2024年11月06日/Enhancing_classroom_teaching_with_LLMs_and_RAG.md)

- [Evaluation data contamination in LLMs: how do we measure it and (when) does it matter?](2024年11月06日/Evaluation_data_contamination_in_LLMs_how_do_we_measure_it_and_(when)_does_it_matter.md)

    - [翻译: 大型语言模型中的评估数据污染：我们如何测量它以及（何时）它重要？](2024年11月06日/Evaluation_data_contamination_in_LLMs_how_do_we_measure_it_and_(when)_does_it_matter.md)

- [EXPLORA: Efficient Exemplar Subset Selection for Complex Reasoning](2024年11月06日/EXPLORA_Efficient_Exemplar_Subset_Selection_for_Complex_Reasoning.md)

    - [翻译: EXPLORA：用于复杂推理的高效示例子集选择](2024年11月06日/EXPLORA_Efficient_Exemplar_Subset_Selection_for_Complex_Reasoning.md)

- [Fine-Grained Guidance for Retrievers: Leveraging LLMs' Feedback in Retrieval-Augmented Generation](2024年11月06日/Fine-Grained_Guidance_for_Retrievers_Leveraging_LLMs'_Feedback_in_Retrieval-Augmented_Generation.md)

    - [翻译: 细粒度的检索器指导：在检索增强生成中利用大型语言模型的反馈](2024年11月06日/Fine-Grained_Guidance_for_Retrievers_Leveraging_LLMs'_Feedback_in_Retrieval-Augmented_Generation.md)

- [From Novice to Expert: LLM Agent Policy Optimization via Step-wise Reinforcement Learning](2024年11月06日/From_Novice_to_Expert_LLM_Agent_Policy_Optimization_via_Step-wise_Reinforcement_Learning.md)

    - [翻译: 从新手到专家：通过逐步强化学习实现 LLM 代理策略优化](2024年11月06日/From_Novice_to_Expert_LLM_Agent_Policy_Optimization_via_Step-wise_Reinforcement_Learning.md)

- [Interactions Across Blocks in Post-Training Quantization of Large Language Models](2024年11月06日/Interactions_Across_Blocks_in_Post-Training_Quantization_of_Large_Language_Models.md)

    - [翻译: 大型语言模型训练后量化中跨块的交互](2024年11月06日/Interactions_Across_Blocks_in_Post-Training_Quantization_of_Large_Language_Models.md)

- [Large Generative Model-assisted Talking-face Semantic Communication System](2024年11月06日/Large_Generative_Model-assisted_Talking-face_Semantic_Communication_System.md)

    - [翻译: 大型生成模型辅助的说话人脸语义通信系统](2024年11月06日/Large_Generative_Model-assisted_Talking-face_Semantic_Communication_System.md)

- [LidaRefer: Outdoor 3D Visual Grounding for Autonomous Driving with Transformers](2024年11月06日/LidaRefer_Outdoor_3D_Visual_Grounding_for_Autonomous_Driving_with_Transformers.md)

    - [翻译: LidaRefer：使用 Transformer 实现自动驾驶的户外 3D 视觉定位](2024年11月06日/LidaRefer_Outdoor_3D_Visual_Grounding_for_Autonomous_Driving_with_Transformers.md)

- [Long-Form Text-to-Music Generation with Adaptive Prompts: A Case of Study in Tabletop Role-Playing Games Soundtracks](2024年11月06日/Long-Form_Text-to-Music_Generation_with_Adaptive_Prompts_A_Case_of_Study_in_Tabletop_Role-Playing_Games_Soundtracks.md)

    - [翻译: 具有自适应提示的长篇文本到音乐生成：桌面角色扮演游戏配乐的案例研究](2024年11月06日/Long-Form_Text-to-Music_Generation_with_Adaptive_Prompts_A_Case_of_Study_in_Tabletop_Role-Playing_Games_Soundtracks.md)

- [M3SciQA: A Multi-Modal Multi-Document Scientific QA Benchmark for Evaluating Foundation Models](2024年11月06日/M3SciQA_A_Multi-Modal_Multi-Document_Scientific_QA_Benchmark_for_Evaluating_Foundation_Models.md)

    - [翻译: M3SciQA：用于评估基础模型的多模态多文档科学问答基准](2024年11月06日/M3SciQA_A_Multi-Modal_Multi-Document_Scientific_QA_Benchmark_for_Evaluating_Foundation_Models.md)

- [MEG: Medical Knowledge-Augmented Large Language Models for Question Answering](2024年11月06日/MEG_Medical_Knowledge-Augmented_Large_Language_Models_for_Question_Answering.md)

    - [翻译: MEG：用于问答的医学知识增强型大型语言模型](2024年11月06日/MEG_Medical_Knowledge-Augmented_Large_Language_Models_for_Question_Answering.md)

- [Multi-Modal Intelligent Channel Modeling: A New Modeling Paradigm via Synesthesia of Machines](2024年11月06日/Multi-Modal_Intelligent_Channel_Modeling_A_New_Modeling_Paradigm_via_Synesthesia_of_Machines.md)

    - [翻译: 多模态智能信道建模：通过机器的联觉的一种新的建模范例](2024年11月06日/Multi-Modal_Intelligent_Channel_Modeling_A_New_Modeling_Paradigm_via_Synesthesia_of_Machines.md)

- [Multi-Reward as Condition for Instruction-based Image Editing](2024年11月06日/Multi-Reward_as_Condition_for_Instruction-based_Image_Editing.md)

    - [翻译: 多奖励作为基于指令的图像编辑的条件](2024年11月06日/Multi-Reward_as_Condition_for_Instruction-based_Image_Editing.md)

- [Multi-Scale and Multimodal Species Distribution Modeling](2024年11月06日/Multi-Scale_and_Multimodal_Species_Distribution_Modeling.md)

    - [翻译: 多尺度和多模态物种分布建模](2024年11月06日/Multi-Scale_and_Multimodal_Species_Distribution_Modeling.md)

- [NeurIPS 2023 Competition: Privacy Preserving Federated Learning Document VQA](2024年11月06日/NeurIPS_2023_Competition_Privacy_Preserving_Federated_Learning_Document_VQA.md)

    - [翻译: NeurIPS 2023 竞赛：保护隐私的联邦学习文档 VQA](2024年11月06日/NeurIPS_2023_Competition_Privacy_Preserving_Federated_Learning_Document_VQA.md)

- [One fish, two fish, but not the whole sea: Alignment reduces language models' conceptual diversity](2024年11月06日/One_fish,_two_fish,_but_not_the_whole_sea_Alignment_reduces_language_models'_conceptual_diversity.md)

    - [翻译: 一条鱼，两条鱼，但不是整个海洋：对齐降低了语言模型的概念多样性](2024年11月06日/One_fish,_two_fish,_but_not_the_whole_sea_Alignment_reduces_language_models'_conceptual_diversity.md)

- [Polynomial Composition Activations: Unleashing the Dynamics of Large Language Models](2024年11月06日/Polynomial_Composition_Activations_Unleashing_the_Dynamics_of_Large_Language_Models.md)

    - [翻译: 多项式组合激活：释放大型语言模型的动态](2024年11月06日/Polynomial_Composition_Activations_Unleashing_the_Dynamics_of_Large_Language_Models.md)

- [Prompt Engineering Using GPT for Word-Level Code-Mixed Language Identification in Low-Resource Dravidian Languages](2024年11月06日/Prompt_Engineering_Using_GPT_for_Word-Level_Code-Mixed_Language_Identification_in_Low-Resource_Dravidian_Languages.md)

    - [翻译: 使用 GPT 进行提示工程以用于低资源达罗毗荼语言中的单词级代码混合语言识别](2024年11月06日/Prompt_Engineering_Using_GPT_for_Word-Level_Code-Mixed_Language_Identification_in_Low-Resource_Dravidian_Languages.md)

- [Robust and Efficient Fine-tuning of LLMs with Bayesian Reparameterization of Low-Rank Adaptation](2024年11月06日/Robust_and_Efficient_Fine-tuning_of_LLMs_with_Bayesian_Reparameterization_of_Low-Rank_Adaptation.md)

    - [翻译: 利用低秩适应的贝叶斯重新参数化对大型语言模型进行稳健且高效的微调](2024年11月06日/Robust_and_Efficient_Fine-tuning_of_LLMs_with_Bayesian_Reparameterization_of_Low-Rank_Adaptation.md)

- [TableGPT2: A Large Multimodal Model with Tabular Data Integration](2024年11月06日/TableGPT2_A_Large_Multimodal_Model_with_Tabular_Data_Integration.md)

    - [翻译: TableGPT2：一个具有表格数据集成的大型多模态模型](2024年11月06日/TableGPT2_A_Large_Multimodal_Model_with_Tabular_Data_Integration.md)

- [Textual Decomposition Then Sub-motion-space Scattering for Open-Vocabulary Motion Generation](2024年11月06日/Textual_Decomposition_Then_Sub-motion-space_Scattering_for_Open-Vocabulary_Motion_Generation.md)

    - [翻译: 用于开放词汇运动生成的文本分解然后子运动空间散射](2024年11月06日/Textual_Decomposition_Then_Sub-motion-space_Scattering_for_Open-Vocabulary_Motion_Generation.md)

- [The Root Shapes the Fruit: On the Persistence of Gender-Exclusive Harms in Aligned Language Models](2024年11月06日/The_Root_Shapes_the_Fruit_On_the_Persistence_of_Gender-Exclusive_Harms_in_Aligned_Language_Models.md)

    - [翻译: 根塑造果实：关于对齐语言模型中性别排他性危害的持续性](2024年11月06日/The_Root_Shapes_the_Fruit_On_the_Persistence_of_Gender-Exclusive_Harms_in_Aligned_Language_Models.md)

- [Unfair Alignment: Examining Safety Alignment Across Vision Encoder Layers in Vision-Language Models](2024年11月06日/Unfair_Alignment_Examining_Safety_Alignment_Across_Vision_Encoder_Layers_in_Vision-Language_Models.md)

    - [翻译: 不公平对齐：检查视觉语言模型中视觉编码器层的安全对齐](2024年11月06日/Unfair_Alignment_Examining_Safety_Alignment_Across_Vision_Encoder_Layers_in_Vision-Language_Models.md)

- [Unlearning in- vs. out-of-distribution data in LLMs under gradient-based method](2024年11月06日/Unlearning_in-_vs._out-of-distribution_data_in_LLMs_under_gradient-based_method.md)

    - [翻译: 在基于梯度的方法下，大型语言模型中分布内与分布外数据的遗忘](2024年11月06日/Unlearning_in-_vs._out-of-distribution_data_in_LLMs_under_gradient-based_method.md)

- [VQA$^2$:Visual Question Answering for Video Quality Assessment](2024年11月06日/VQA$^2$Visual_Question_Answering_for_Video_Quality_Assessment.md)

    - [翻译: VQA$^2$:用于视频质量评估的视觉问答](2024年11月06日/VQA$^2$Visual_Question_Answering_for_Video_Quality_Assessment.md)

- [What Really is Commonsense Knowledge?](2024年11月06日/What_Really_is_Commonsense_Knowledge.md)

    - [翻译: 什么才是真正的常识知识？](2024年11月06日/What_Really_is_Commonsense_Knowledge.md)

2024年11月04日

- [Complete Classification of Integrability and Non-integrability for Spin-1/2 Chain with Symmetric Nearest-Neighbor Interaction](2024年11月04日/Complete_Classification_of_Integrability_and_Non-integrability_for_Spin-12_Chain_with_Symmetric_Nearest-Neighbor_Interaction.md)

    - [翻译: 具有对称近邻相互作用的自旋 1/2 链的可积性和不可积性的完全分类](2024年11月04日/Complete_Classification_of_Integrability_and_Non-integrability_for_Spin-12_Chain_with_Symmetric_Nearest-Neighbor_Interaction.md)