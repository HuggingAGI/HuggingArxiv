# 大型语言模型驱动的 GUI 代理：一项调研

发布时间：2024年11月27日

`LLM应用` `人机交互` `图形用户界面`

> Large Language Model-Brained GUI Agents: A Survey

# 摘要

> 图形用户界面（GUIs）长久以来都是人机交互的核心所在，以直观且视觉驱动的方式，让人能够访问并与数字系统交互。大型语言模型（LLMs）的出现，尤其是多模态模型，开启了图形用户界面自动化的崭新时代。它们在自然语言理解、代码生成以及视觉处理等方面展现出非凡能力，为新一代具备 LLM 大脑的图形用户界面代理铺平了道路。这些代理能够解读复杂的图形用户界面元素，并依据自然语言指令自主执行操作。它们代表了一种范式转变，使用户能通过简单的对话指令完成复杂的多步骤任务。其应用涵盖网络导航、移动应用交互和桌面自动化等领域，带来了变革性的用户体验，彻底改变了个人与软件的交互方式。这一新兴领域发展迅速，在研究和产业方面均取得重大进展。

为了对这一趋势形成结构化的认识，本文对具有 LLM 大脑的图形用户界面代理展开全面调研，探究其历史演进、核心组件和先进技术。我们处理了诸如现有的图形用户界面代理框架、用于训练专门图形用户界面代理的数据收集与利用、针对图形用户界面任务定制的大型动作模型的开发，以及评估其有效性所需的评估指标和基准等研究问题。此外，我们还对由这些代理驱动的新兴应用加以研究。通过详尽分析，此次调研明确了关键的研究空白，并勾勒出该领域未来发展的路线图。通过整合基础知识和前沿进展，这项工作旨在引导研究人员和从业者攻克难题，充分释放具有 LLM 大脑的图形用户界面代理的全部潜能。

> GUIs have long been central to human-computer interaction, providing an intuitive and visually-driven way to access and interact with digital systems. The advent of LLMs, particularly multimodal models, has ushered in a new era of GUI automation. They have demonstrated exceptional capabilities in natural language understanding, code generation, and visual processing. This has paved the way for a new generation of LLM-brained GUI agents capable of interpreting complex GUI elements and autonomously executing actions based on natural language instructions. These agents represent a paradigm shift, enabling users to perform intricate, multi-step tasks through simple conversational commands. Their applications span across web navigation, mobile app interactions, and desktop automation, offering a transformative user experience that revolutionizes how individuals interact with software. This emerging field is rapidly advancing, with significant progress in both research and industry.
  To provide a structured understanding of this trend, this paper presents a comprehensive survey of LLM-brained GUI agents, exploring their historical evolution, core components, and advanced techniques. We address research questions such as existing GUI agent frameworks, the collection and utilization of data for training specialized GUI agents, the development of large action models tailored for GUI tasks, and the evaluation metrics and benchmarks necessary to assess their effectiveness. Additionally, we examine emerging applications powered by these agents. Through a detailed analysis, this survey identifies key research gaps and outlines a roadmap for future advancements in the field. By consolidating foundational knowledge and state-of-the-art developments, this work aims to guide both researchers and practitioners in overcoming challenges and unlocking the full potential of LLM-brained GUI agents.

[Arxiv](https://arxiv.org/abs/2411.18279)