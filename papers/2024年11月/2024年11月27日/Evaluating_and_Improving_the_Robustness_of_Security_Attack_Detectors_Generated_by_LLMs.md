# 评估并增强由大型语言模型所生成的安全攻击检测器的稳健性

发布时间：2024年11月27日

`RAG` `软件开发` `网络安全`

> Evaluating and Improving the Robustness of Security Attack Detectors Generated by LLMs

# 摘要

> 大型语言模型（LLMs）在软件开发中愈发常用于生成诸如攻击检测器等实现安全要求的功能。但 LLMs 难以生成精准的代码，比如在实际运用中，致使攻击检测器遗漏了广为人知的攻击。这极有可能是因为 LLM 对某些现存攻击缺乏了解，且生成的代码未在真实使用场景中予以评估。我们提出了一种新的方法，将检索增强生成（RAG）和自排名融入 LLM 流程。RAG 借助结合外部知识源增强了输出的稳健性，而自排名技术，受自我一致性概念的启发，生成多个推理路径并创建排名，以选出最强大的检测器。我们广泛的实证研究针对 LLMs 生成的用于检测网络安全中两种常见注入攻击（跨站脚本 XSS 和 SQL 注入 SQLi）的代码。结果显示，相较于基线，检测性能有显著提升，XSS 和 SQLi 检测的 F2 分数分别提高了多达 71%和 37%。

> Large Language Models (LLMs) are increasingly used in software development to generate functions, such as attack detectors, that implement security requirements. However, LLMs struggle to generate accurate code, resulting, e.g., in attack detectors that miss well-known attacks when used in practice. This is most likely due to the LLM lacking knowledge about some existing attacks and to the generated code being not evaluated in real usage scenarios. We propose a novel approach integrating Retrieval Augmented Generation (RAG) and Self-Ranking into the LLM pipeline. RAG enhances the robustness of the output by incorporating external knowledge sources, while the Self-Ranking technique, inspired to the concept of Self-Consistency, generates multiple reasoning paths and creates ranks to select the most robust detector. Our extensive empirical study targets code generated by LLMs to detect two prevalent injection attacks in web security: Cross-Site Scripting (XSS) and SQL injection (SQLi). Results show a significant improvement in detection performance compared to baselines, with an increase of up to 71%pt and 37%pt in the F2-Score for XSS and SQLi detection, respectively.

[Arxiv](https://arxiv.org/abs/2411.18216)