# SAGEval：基于满意代理的无参考开放式文本的 NLG 评估前沿

发布时间：2024年11月24日

`LLM应用` `办公软件` `自然语言生成`

> SAGEval: The frontiers of Satisfactory Agent based NLG Evaluation for reference-free open-ended text

# 摘要

> 大型语言模型（LLM）融入 Microsoft365 套件和 Google Workspace 这类应用中，用于创建/处理文档、邮件、演示文稿等，显著提升了生产力并节省了时间。然而，随着这些融合愈发复杂，保证 LLM 融合应用的输出质量相关且适宜使用就变得极为重要。由于需要为自然语言生成开发强有力的评估方法，而在其中参考/基础标签缺失或不足，本文推出了一个名为“SAGEval”的新框架，它借助批评代理为 LLM 评估器生成的分数给予反馈。我们指出，在缺乏参考/真实基础标签的情况下，批评代理能够矫正 LLM 评估器的分数，进而降低了对有标记数据的需求，哪怕是在复杂的 NLG 评估场景中，比如生成具有不同风格响应（如多项选择、李克特评级、单项选择问题等）的 JSON 结构化表单/调查。

> Large Language Model (LLM) integrations into applications like Microsoft365 suite and Google Workspace for creating/processing documents, emails, presentations, etc. has led to considerable enhancements in productivity and time savings. But as these integrations become more more complex, it is paramount to ensure that the quality of output from the LLM-integrated applications are relevant and appropriate for use. Identifying the need to develop robust evaluation approaches for natural language generation, wherein references/ground labels doesn't exist or isn't amply available, this paper introduces a novel framework called "SAGEval" which utilizes a critiquing Agent to provide feedback on scores generated by LLM evaluators. We show that the critiquing Agent is able to rectify scores from LLM evaluators, in absence of references/ground-truth labels, thereby reducing the need for labeled data even for complex NLG evaluation scenarios, like the generation of JSON-structured forms/surveys with responses in different styles like multiple choice, likert ratings, single choice questions, etc.

[Arxiv](https://arxiv.org/abs/2411.16077)