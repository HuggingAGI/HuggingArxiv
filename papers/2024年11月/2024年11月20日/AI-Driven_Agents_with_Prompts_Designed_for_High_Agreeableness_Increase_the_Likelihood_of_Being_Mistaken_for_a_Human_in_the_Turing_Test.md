# 具有高宜人性设计提示的 AI 驱动代理在图灵测试中更有可能被误认为是人类。

发布时间：2024年11月20日

`Agent` `人工智能` `心理学`

> AI-Driven Agents with Prompts Designed for High Agreeableness Increase the Likelihood of Being Mistaken for a Human in the Turing Test

# 摘要

> 基于转换器算法的大型语言模型实现了与机器类似人类对话的言语交互，从而给人工智能带来了革命性的变化。这些人工智能代理已超越图灵测试，混淆率高达 50%。不过，挑战依旧存在，尤其是随着机器人的出现以及让机器更具人性化以优化人机协作的需求。在此实验中，基于大五人格量表，具有不同亲和度（不亲和、中立、亲和）的三个 GPT 代理接受了图灵测试。所有代理的混淆率均超 50%，其中高度亲和的人工智能代理更是超过 60%。该代理还被认为展现出了最类人的特质。文献中的诸多解释阐述了为何这些 GPT 代理被视作人类，涵盖了用于理解拟人化的心理学框架。这些发现凸显了人格工程作为人工智能新兴学科的重要性，呼吁与心理学合作开发符合人体工程学的心理模型，以增强协作活动中的系统适应性。

> Large Language Models based on transformer algorithms have revolutionized Artificial Intelligence by enabling verbal interaction with machines akin to human conversation. These AI agents have surpassed the Turing Test, achieving confusion rates up to 50%. However, challenges persist, especially with the advent of robots and the need to humanize machines for improved Human-AI collaboration. In this experiment, three GPT agents with varying levels of agreeableness (disagreeable, neutral, agreeable) based on the Big Five Inventory were tested in a Turing Test. All exceeded a 50% confusion rate, with the highly agreeable AI agent surpassing 60%. This agent was also recognized as exhibiting the most human-like traits. Various explanations in the literature address why these GPT agents were perceived as human, including psychological frameworks for understanding anthropomorphism. These findings highlight the importance of personality engineering as an emerging discipline in artificial intelligence, calling for collaboration with psychology to develop ergonomic psychological models that enhance system adaptability in collaborative activities.

[Arxiv](https://arxiv.org/abs/2411.13749)