# 写作风格至关重要：探究信息检索系统中的偏差与公平

发布时间：2024年11月20日

`LLM应用` `信息检索` `语言模型`

> Writing Style Matters: An Examination of Bias and Fairness in Information Retrieval Systems

# 摘要

> 语言模型技术的迅猛发展既带来新机遇，也带来与偏见和公平相关的新挑战。本文深入探究了信息检索（IR）系统中，前沿通用文本嵌入模型针对特定文档和查询写作风格存在的潜在偏见这一未知领域。我们的研究表明，不同嵌入模型对文档写作风格有不同偏好，多数嵌入模型不太青睐更非正式和情绪化的风格。就查询写作风格而言，许多嵌入模型倾向于让查询风格与检索到的文档风格匹配，但有些则对特定风格有一贯的偏好。基于大型语言模型（LLM）生成的合成数据进行微调的文本嵌入模型，对某些生成数据的风格有一致偏好。文本嵌入的IR系统中的这些偏见，可能会在不经意间压制或边缘化某些交流风格，从而对信息检索的公平性构成重大威胁。最后，我们还比较了基于不同LLM的检索增强生成（RAG）系统的答案风格，发现当作为答案正确性的评估指标时，大多数文本嵌入模型偏向于LLM的答案风格。此项研究揭示了IR系统中基于写作风格的偏见这一关键问题，为开发更公平、更强大的模型提供了宝贵见解。

> The rapid advancement of Language Model technologies has opened new opportunities, but also introduced new challenges related to bias and fairness. This paper explores the uncharted territory of potential biases in state-of-the-art universal text embedding models towards specific document and query writing styles within Information Retrieval (IR) systems. Our investigation reveals that different embedding models exhibit different preferences of document writing style, while more informal and emotive styles are less favored by most embedding models. In terms of query writing styles, many embedding models tend to match the style of the query with the style of the retrieved documents, but some show a consistent preference for specific styles. Text embedding models fine-tuned on synthetic data generated by LLMs display a consistent preference for certain style of generated data. These biases in text embedding based IR systems can inadvertently silence or marginalize certain communication styles, thereby posing a significant threat to fairness in information retrieval. Finally, we also compare the answer styles of Retrieval Augmented Generation (RAG) systems based on different LLMs and find out that most text embedding models are biased towards LLM's answer styles when used as evaluation metrics for answer correctness. This study sheds light on the critical issue of writing style based bias in IR systems, offering valuable insights for the development of more fair and robust models.

[Arxiv](https://arxiv.org/abs/2411.13173)