# 关于在复杂环境中强化学习增强的调研：来自人类与大型语言模型反馈的洞察

发布时间：2024年11月20日

`Agent` `机器学习`

> A Survey On Enhancing Reinforcement Learning in Complex Environments: Insights from Human and LLM Feedback

# 摘要

> 强化学习（RL）乃机器学习的活跃领域之一，在应对现实世界挑战时展现出非凡潜力。虽说前景光明，但此方法遭遇诸多问题与挑战，致使其难以达至最优性能。尤其在应对大观测空间的环境导航和任务解决时，这些方法表现不佳，常致样本效率低、学习耗时久。这一常被称作维度诅咒的问题，让 RL 代理的决策变得棘手，需在注意力与决策间精细平衡。当 RL 代理获得人类或大型语言模型（LLMs）的反馈强化，可能会呈现出韧性与适应性，进而提升性能、加快学习。此类通过包括自然语言在内的各种形式或粒度传递的反馈，成为 RL 代理的指引，助其识别相关环境线索、优化决策流程。在这篇综述论文中，我们重点关注两方面问题：其一，聚焦人类或 LLMs 的协助，探究这些实体与 RL 代理合作以促成最佳行为和加速学习的途径；其二，深入钻研致力于解决大观测空间环境复杂性的研究论文。

> Reinforcement learning (RL) is one of the active fields in machine learning, demonstrating remarkable potential in tackling real-world challenges. Despite its promising prospects, this methodology has encountered with issues and challenges, hindering it from achieving the best performance. In particular, these approaches lack decent performance when navigating environments and solving tasks with large observation space, often resulting in sample-inefficiency and prolonged learning times. This issue, commonly referred to as the curse of dimensionality, complicates decision-making for RL agents, necessitating a careful balance between attention and decision-making. RL agents, when augmented with human or large language models' (LLMs) feedback, may exhibit resilience and adaptability, leading to enhanced performance and accelerated learning. Such feedback, conveyed through various modalities or granularities including natural language, serves as a guide for RL agents, aiding them in discerning relevant environmental cues and optimizing decision-making processes. In this survey paper, we mainly focus on problems of two-folds: firstly, we focus on humans or an LLMs assistance, investigating the ways in which these entities may collaborate with the RL agent in order to foster optimal behavior and expedite learning; secondly, we delve into the research papers dedicated to addressing the intricacies of environments characterized by large observation space.

[Arxiv](https://arxiv.org/abs/2411.13410)