# 基于量子核的长短期记忆

发布时间：2024年11月20日

`其他` `量子计算` `机器学习`

> Quantum Kernel-Based Long Short-term Memory

# 摘要

> 量子计算融入经典机器学习架构已成为提升模型效率和计算能力的极具前景的途径。在本研究中，我们推出了基于量子核的长短期记忆（QK-LSTM）网络，它在经典 LSTM 框架内借助量子核函数捕捉顺序数据中的复杂非线性模式。通过将输入数据嵌入高维量子特征空间，QK-LSTM 模型降低了对大型参数集的依赖，在序列建模任务中实现有效压缩的同时保持了准确性。这种量子增强架构呈现出高效的收敛性、出色的损失最小化能力和模型紧凑性，适用于边缘计算环境和资源受限的量子设备（尤其在 NISQ 时代）。基准对比显示，QK-LSTM 取得了与经典 LSTM 模型相当的性能，且参数更少，凸显了其在自然语言处理及其他需要高效处理时间数据的领域推动量子机器学习应用的潜力。

> The integration of quantum computing into classical machine learning architectures has emerged as a promising approach to enhance model efficiency and computational capacity. In this work, we introduce the Quantum Kernel-Based Long Short-Term Memory (QK-LSTM) network, which utilizes quantum kernel functions within the classical LSTM framework to capture complex, non-linear patterns in sequential data. By embedding input data into a high-dimensional quantum feature space, the QK-LSTM model reduces the reliance on large parameter sets, achieving effective compression while maintaining accuracy in sequence modeling tasks. This quantum-enhanced architecture demonstrates efficient convergence, robust loss minimization, and model compactness, making it suitable for deployment in edge computing environments and resource-limited quantum devices (especially in the NISQ era). Benchmark comparisons reveal that QK-LSTM achieves performance on par with classical LSTM models, yet with fewer parameters, underscoring its potential to advance quantum machine learning applications in natural language processing and other domains requiring efficient temporal data processing.

[Arxiv](https://arxiv.org/abs/2411.13225)