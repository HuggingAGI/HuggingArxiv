# RTL-Breaker：评估 LLMs 在 HDL 代码生成方面抵御后门攻击的安全性

发布时间：2024年11月26日

`LLM应用` `硬件设计` `代码生成`

> RTL-Breaker: Assessing the Security of LLMs against Backdoor Attacks on HDL Code Generation

# 摘要

> 大型语言模型（LLMs）在硬件设计的代码生成及完成任务上展现出非凡潜力。实际上，基于LLM的硬件描述语言（HDL）代码生成让行业能更迅速地实现复杂设计，大幅缩减开发周期所需的时间与精力。然而，对这类自动化的依赖度不断提高，也带来了重大安全风险。要特别指出的是，由于LLMs得在通常源自公开可用的存储库（往往未经过全面验证）的海量代码数据集上训练，所以LLMs容易遭受所谓的数据中毒或后门攻击。在此，攻击者向训练数据注入恶意代码，这可能会被带入LLMs生成的HDL代码里。这种威胁因素可能危及整个硬件系统的安全性与完整性。在这项工作中，我们提出了RTL-Breaker，这是一个针对基于LLM的HDL代码生成的新型后门攻击框架。RTL-Breaker对这一新问题的关键方面展开了深入剖析：1. 各种触发机制以及它们插入恶意修改的有效性；2. 后门攻击对代码生成的一般副作用，比如对代码质量的影响。RTL-Breaker强调，迫切需要更有力的措施来抵御此类攻击。为此，我们将框架及所有数据开源。

> Large language models (LLMs) have demonstrated remarkable potential with code generation/completion tasks for hardware design. In fact, LLM-based hardware description language (HDL) code generation has enabled the industry to realize complex designs more quickly, reducing the time and effort required in the development cycle. However, the increased reliance on such automation introduces critical security risks. Notably, given that LLMs have to be trained on vast datasets of codes that are typically sourced from publicly available repositories (often without thorough validation), LLMs are susceptible to so-called data poisoning or backdoor attacks. Here, attackers inject malicious code for the training data, which can be carried over into the HDL code generated by LLMs. This threat vector can compromise the security and integrity of entire hardware systems. In this work, we propose RTL-Breaker, a novel backdoor attack framework on LLM-based HDL code generation. RTL-Breaker provides an in-depth analysis for essential aspects of this novel problem: 1) various trigger mechanisms versus their effectiveness for inserting malicious modifications, and 2) side-effects by backdoor attacks on code generation in general, i.e., impact on code quality. RTL-Breaker emphasizes the urgent need for more robust measures to safeguard against such attacks. Toward that end, we open-source our framework and all data.

[Arxiv](https://arxiv.org/abs/2411.17569)