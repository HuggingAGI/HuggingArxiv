# Beemo：专家编辑的机器生成输出的基准

发布时间：2024年11月06日

`LLM应用` `文本编辑`

> Beemo: Benchmark of Expert-edited Machine-generated Outputs

# 摘要

> 大型语言模型（LLM）的迅速扩散增加了机器生成文本（MGT）的数量，并在各个领域模糊了文本的作者身份。然而，大多数现有的 MGT 基准包括单一作者的文本（人类撰写和机器生成）。这种传统设计未能捕捉到更实际的多作者场景，在这些场景中，用户为了自然流畅、连贯和事实正确性而优化 LLM 的响应。我们的论文介绍了专家编辑的机器生成输出基准（Beemo），其中包括 6500 篇由人类撰写、由十个指令微调的 LLM 生成，并由专家针对从创意写作到总结等各种用例进行编辑的文本。Beemo 还包括 13100 篇机器生成和 LLM 编辑的文本，允许在各种编辑类型中进行多样化的 MGT 检测评估。我们记录了 Beemo 的创建协议，并展示了在不同实验设置中对 33 种 MGT 检测器配置进行基准测试的结果。我们发现基于专家的编辑能够逃避 MGT 检测，而 LLM 编辑的文本不太可能被认为是人类撰写的。Beemo 及所有材料均公开可用。

> The rapid proliferation of large language models (LLMs) has increased the volume of machine-generated texts (MGTs) and blurred text authorship in various domains. However, most existing MGT benchmarks include single-author texts (human-written and machine-generated). This conventional design fails to capture more practical multi-author scenarios, where the user refines the LLM response for natural flow, coherence, and factual correctness. Our paper introduces the Benchmark of Expert-edited Machine-generated Outputs (Beemo), which includes 6.5k texts written by humans, generated by ten instruction-finetuned LLMs, and edited by experts for various use cases, ranging from creative writing to summarization. Beemo additionally comprises 13.1k machine-generated and LLM-edited texts, allowing for diverse MGT detection evaluation across various edit types. We document Beemo's creation protocol and present the results of benchmarking 33 configurations of MGT detectors in different experimental setups. We find that expert-based editing evades MGT detection, while LLM-edited texts are unlikely to be recognized as human-written. Beemo and all materials are publicly available.

[Arxiv](https://arxiv.org/abs/2411.04032)