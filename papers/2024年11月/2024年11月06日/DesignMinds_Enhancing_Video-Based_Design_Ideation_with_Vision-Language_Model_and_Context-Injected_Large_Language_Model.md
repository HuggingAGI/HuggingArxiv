# DesignMinds：使用视觉语言模型和上下文注入的大型语言模型增强基于视频的设计构思

发布时间：2024年11月06日

`LLM应用` `人工智能`

> DesignMinds: Enhancing Video-Based Design Ideation with Vision-Language Model and Context-Injected Large Language Model

# 摘要

> 构思是基于视频的设计（VBD）的关键组成部分，其中视频是设计探索和灵感的主要媒介。生成式人工智能的出现为通过简化视频分析和促进创意生成来增强这一过程提供了相当大的潜力。在本文中，我们提出了 DesignMinds，这是一个将最先进的视觉语言模型（VLM）与上下文增强的大型语言模型（LLM）集成在一起的原型，以支持 VBD 中的构思。为了评估 DesignMinds，我们对 35 名设计从业者进行了一项受试者间研究，将其性能与基线条件进行比较。我们的结果表明，DesignMinds 显著提高了构思的灵活性和原创性，同时也增加了任务参与度。重要的是，这项技术的引入没有对用户体验、技术接受度或可用性产生负面影响。

> Ideation is a critical component of video-based design (VBD), where videos serve as the primary medium for design exploration and inspiration. The emergence of generative AI offers considerable potential to enhance this process by streamlining video analysis and facilitating idea generation. In this paper, we present DesignMinds, a prototype that integrates a state-of-the-art Vision-Language Model (VLM) with a context-enhanced Large Language Model (LLM) to support ideation in VBD. To evaluate DesignMinds, we conducted a between-subject study with 35 design practitioners, comparing its performance to a baseline condition. Our results demonstrate that DesignMinds significantly enhances the flexibility and originality of ideation, while also increasing task engagement. Importantly, the introduction of this technology did not negatively impact user experience, technology acceptance, or usability.

[Arxiv](https://arxiv.org/abs/2411.03827)