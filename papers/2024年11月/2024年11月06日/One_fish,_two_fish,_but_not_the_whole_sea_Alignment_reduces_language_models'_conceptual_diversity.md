# 一条鱼，两条鱼，但不是整个海洋：对齐降低了语言模型的概念多样性

发布时间：2024年11月06日

`LLM应用` `社会科学` `心理学`

> One fish, two fish, but not the whole sea: Alignment reduces language models' conceptual diversity

# 摘要

> 社会科学和心理学领域的研究人员最近提议在行为研究中使用大型语言模型（LLM）来替代人类。除了关于LLM是否准确捕捉人口层面模式的争论外，这也引发了关于LLM是否捕捉到类似人类的概念多样性的问题。另外，关于训练后对齐（RLHF 或 RLAIF）是否影响模型的内部多样性也存在争议。受人类研究的启发，我们通过将模拟个体的内部变异性与人口层面的变异性联系起来，使用一种新的方法来测量合成生成的LLM“群体”的概念多样性。我们使用这种方法在具有丰富人类行为数据的两个领域评估未对齐和已对齐的LLM。虽然没有模型达到类似人类的多样性，但已对齐的模型通常比其指令微调的对应模型显示出更少的多样性。我们的研究结果突出了在增加模型的价值对齐和减少其概念表示的多样性之间潜在的权衡。

> Researchers in social science and psychology have recently proposed using large language models (LLMs) as replacements for humans in behavioral research. In addition to arguments about whether LLMs accurately capture population-level patterns, this has raised questions about whether LLMs capture human-like conceptual diversity. Separately, it is debated whether post-training alignment (RLHF or RLAIF) affects models' internal diversity. Inspired by human studies, we use a new way of measuring the conceptual diversity of synthetically-generated LLM "populations" by relating the internal variability of simulated individuals to the population-level variability. We use this approach to evaluate non-aligned and aligned LLMs on two domains with rich human behavioral data. While no model reaches human-like diversity, aligned models generally display less diversity than their instruction fine-tuned counterparts. Our findings highlight potential trade-offs between increasing models' value alignment and decreasing the diversity of their conceptual representations.

[Arxiv](https://arxiv.org/abs/2411.04427)