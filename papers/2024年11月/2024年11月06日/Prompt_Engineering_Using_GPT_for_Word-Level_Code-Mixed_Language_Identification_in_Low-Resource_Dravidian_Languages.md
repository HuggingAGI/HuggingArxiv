# 使用 GPT 进行提示工程以用于低资源达罗毗荼语言中的单词级代码混合语言识别

发布时间：2024年11月06日

`LLM应用` `语言识别`

> Prompt Engineering Using GPT for Word-Level Code-Mixed Language Identification in Low-Resource Dravidian Languages

# 摘要

> 语言识别（LI）对于各种自然语言处理任务至关重要，是诸如情感分析、机器翻译和信息检索等应用中的基础步骤。在像印度这样的多语言社会中，特别是在参与社交媒体的年轻人中，文本经常表现出代码混合，在不同的语言层面上将当地语言与英语混合。这种现象给 LI 系统带来了巨大的挑战，尤其是当语言在单个单词内混合时。在印度南部流行的达罗毗荼语拥有丰富的形态结构，但在数字平台上的代表性不足，导致采用罗马或混合文字进行交流。本文为旨在解决达罗毗荼语中单词级 LI 挑战的共享任务引入了一种基于提示的方法。在这项工作中，我们利用 GPT-3.5 Turbo 来了解大型语言模型是否能够将单词正确分类到正确的类别。我们的研究结果表明，卡纳达语模型在大多数指标上始终优于泰米尔语模型，表明在识别和分类卡纳达语实例方面具有更高的准确性和可靠性。相比之下，泰米尔语模型表现中等，特别是在精度和召回率方面需要改进。

> Language Identification (LI) is crucial for various natural language processing tasks, serving as a foundational step in applications such as sentiment analysis, machine translation, and information retrieval. In multilingual societies like India, particularly among the youth engaging on social media, text often exhibits code-mixing, blending local languages with English at different linguistic levels. This phenomenon presents formidable challenges for LI systems, especially when languages intermingle within single words. Dravidian languages, prevalent in southern India, possess rich morphological structures yet suffer from under-representation in digital platforms, leading to the adoption of Roman or hybrid scripts for communication. This paper introduces a prompt based method for a shared task aimed at addressing word-level LI challenges in Dravidian languages. In this work, we leveraged GPT-3.5 Turbo to understand whether the large language models is able to correctly classify words into correct categories. Our findings show that the Kannada model consistently outperformed the Tamil model across most metrics, indicating a higher accuracy and reliability in identifying and categorizing Kannada language instances. In contrast, the Tamil model showed moderate performance, particularly needing improvement in precision and recall.

[Arxiv](https://arxiv.org/abs/2411.04025)