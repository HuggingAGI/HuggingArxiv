# 使用大型语言模型检测科学文献中的参考文献错误

发布时间：2024年11月09日

`LLM应用` `科学出版` `人工智能`

> Detecting Reference Errors in Scientific Literature with Large Language Models

# 摘要

> 参考错误，如引用和引语错误，在科学论文中很常见。这些错误可能导致不准确信息的传播，但检测起来困难且耗时，给科学出版带来了重大挑战。为支持参考错误的自动检测，这项工作评估了 OpenAI 的 GPT 系列大型语言模型检测引语错误的能力。具体来说，我们从期刊文章中准备了一个由专家注释的通用领域的陈述-参考对数据集。在不同的设置中对大型语言模型进行了评估，通过检索增强提供了不同数量的参考信息。我们的结果表明，大型语言模型能够在有限的上下文且无需微调的情况下检测错误引用。这项研究为越来越多寻求利用人工智能协助科学论文的写作、审查和出版的文献做出了贡献。还讨论了此任务中进一步改进的潜在途径。

> Reference errors, such as citation and quotation errors, are common in scientific papers. Such errors can result in the propagation of inaccurate information, but are difficult and time-consuming to detect, posing a significant challenge to scientific publishing. To support automatic detection of reference errors, this work evaluated the ability of large language models in OpenAI's GPT family to detect quotation errors. Specifically, we prepared an expert-annotated, general-domain dataset of statement-reference pairs from journal articles. Large language models were evaluated in different settings with varying amounts of reference information provided by retrieval augmentation. Our results showed that large language models are able to detect erroneous citations with limited context and without fine-tuning. This study contributes to the growing literature that seeks to utilize artificial intelligence to assist in the writing, reviewing, and publishing of scientific papers. Potential avenues for further improvements in this task are also discussed.

[Arxiv](https://arxiv.org/abs/2411.06101)