# 构建一个利用 Rust 中的多处理设计的针对伊斯兰领域的高效多语言非营利性信息检索系统

发布时间：2024年11月09日

`LLM应用` `信息检索`

> Building an Efficient Multilingual Non-Profit IR System for the Islamic Domain Leveraging Multiprocessing Design in Rust

# 摘要

> 大型语言模型（LLMs）的广泛使用极大地改进了自然语言处理（NLP）的许多应用，包括信息检索（IR）。然而，不受商业利益驱动的领域在受益于人工智能驱动的解决方案方面往往落后。宗教和遗产语料库就是这样一个领域。与类似领域一样，伊斯兰文献具有重要的文化价值，并经常被学者和公众利用。浏览如此大量的文本具有挑战性，目前没有统一的资源允许使用先进的人工智能工具轻松搜索此数据。这项工作侧重于为伊斯兰领域开发一个多语言非营利性 IR 系统。这个过程带来了一些重大挑战，例如在某些语言的数据有限时准备多语言特定领域的语料库，在资源受限的设备上部署模型，以及在有限的预算下实现快速搜索。通过采用诸如针对领域适应的持续预训练和语言缩减以减小模型大小等方法，准备了一个轻量级的多语言检索模型，与在一般领域数据上预训练的较大模型相比，表现出优越的性能。此外，评估利用 Rust 语言能力的所提出的架构显示了在低资源环境中实现高效语义搜索的可能性。

> The widespread use of large language models (LLMs) has dramatically improved many applications of Natural Language Processing (NLP), including Information Retrieval (IR). However, domains that are not driven by commercial interest often lag behind in benefiting from AI-powered solutions. One such area is religious and heritage corpora. Alongside similar domains, Islamic literature holds significant cultural value and is regularly utilized by scholars and the general public. Navigating this extensive amount of text is challenging, and there is currently no unified resource that allows for easy searching of this data using advanced AI tools. This work focuses on the development of a multilingual non-profit IR system for the Islamic domain. This process brings a few major challenges, such as preparing multilingual domain-specific corpora when data is limited in certain languages, deploying a model on resource-constrained devices, and enabling fast search on a limited budget. By employing methods like continued pre-training for domain adaptation and language reduction to decrease model size, a lightweight multilingual retrieval model was prepared, demonstrating superior performance compared to larger models pre-trained on general domain data. Furthermore, evaluating the proposed architecture that utilizes Rust Language capabilities shows the possibility of implementing efficient semantic search in a low-resource setting.

[Arxiv](https://arxiv.org/abs/2411.06151)