# 通过第三方 LLM 集成来增强多智能体共识：剖析大型语言模型中的不确定性并缓解幻觉

发布时间：2024年11月25日

`Agent` `语言模型` `多代理系统`

> Enhancing Multi-Agent Consensus through Third-Party LLM Integration: Analyzing Uncertainty and Mitigating Hallucinations in Large Language Models

# 摘要

> 大型语言模型（LLMs）在应对复杂推理任务时，常面临难题，会产生幻觉，这限制了其实际应用。为减轻此问题，本文提出了一种新方法，将不同的LLMs加以整合，以拓展知识边界，降低对单个模型的依赖，并推动代理间的深度探讨。其主要贡献有：1）引入第三方LLMs，借不确定性估计和置信度分析来调整代理的注意力权重，优化多代理系统中的共识形成；2）在算术数据集上开展的实验证实了该方法的有效性，超越了传统的多代理基线。此项研究为大型模型处理复杂任务时缓解幻觉现象提供了新视角。

> Large Language Models (LLMs) still face challenges when dealing with complex reasoning tasks, often resulting in hallucinations, which limit the practical application of LLMs. To alleviate this issue, this paper proposes a new method that integrates different LLMs to expand the knowledge boundary, reduce dependence on a single model, and promote in-depth debate among agents. The main contributions include: 1) Introducing third-party LLMs to adjust the attention weights of agents through uncertainty estimation and confidence analysis, optimizing consensus formation in multi-agent systems; 2) Experiments on arithmetic datasets have validated the effectiveness of the method, surpassing traditional multi-agent baselines. This research provides a new perspective for large models to alleviate hallucination phenomena when dealing with complex tasks.

[Arxiv](https://arxiv.org/abs/2411.16189)