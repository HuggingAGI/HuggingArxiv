# 探索多模态语言模型于化学和材料研究中的局限性

发布时间：2024年11月25日

`LLM应用` `材料科学`

> Probing the limitations of multimodal language models for chemistry and materials research

# 摘要

> 近期人工智能的进步激起了人们对科学助手的兴趣，这些助手能在科学工作流程的全流程中为研究人员提供支持，涵盖从文献综述到实验设计以及数据分析。此类系统的关键能力在于能够处理和推理视觉及文本形式的科学信息，比如解释光谱数据、理解实验室设置等。在此，我们推出 MaCBench，这一综合基准用于评估视觉语言模型在处理现实世界化学和材料科学任务的三个核心方面的表现：数据提取、实验理解以及结果阐释。通过对领先模型的系统性评估，我们发现，尽管这些系统在基础感知任务中展现出良好的能力，在设备识别和标准化数据提取方面几近完美，但在空间推理、跨模态信息合成以及多步逻辑推理方面存在根本局限。我们的见解在化学和材料科学领域之外也颇具意义，意味着开发可靠的多模态人工智能科学助手或许需要在整理适宜的训练数据以及训练模型的方法上取得突破。

> Recent advancements in artificial intelligence have sparked interest in scientific assistants that could support researchers across the full spectrum of scientific workflows, from literature review to experimental design and data analysis. A key capability for such systems is the ability to process and reason about scientific information in both visual and textual forms - from interpreting spectroscopic data to understanding laboratory setups. Here, we introduce MaCBench, a comprehensive benchmark for evaluating how vision-language models handle real-world chemistry and materials science tasks across three core aspects: data extraction, experimental understanding, and results interpretation. Through a systematic evaluation of leading models, we find that while these systems show promising capabilities in basic perception tasks - achieving near-perfect performance in equipment identification and standardized data extraction - they exhibit fundamental limitations in spatial reasoning, cross-modal information synthesis, and multi-step logical inference. Our insights have important implications beyond chemistry and materials science, suggesting that developing reliable multimodal AI scientific assistants may require advances in curating suitable training data and approaches to training those models.

[Arxiv](https://arxiv.org/abs/2411.16955)