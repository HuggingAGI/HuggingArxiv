# LLMs 中的特征偏差：上下文词嵌入里的刻板印象维度

发布时间：2024年11月25日

`LLM应用` `人工智能` `社会心理学`

> Profiling Bias in LLMs: Stereotype Dimensions in Contextual Word Embeddings

# 摘要

> 大型语言模型（LLMs）是当下人工智能（AI）取得成功的基石，不过，它们难免存在偏差。要想有效地传达风险并推动缓解举措，这些模型需要针对其歧视性属性给出充分且直观的描述，以适应所有AI受众。我们依据社会心理学研究中的词典提出了有关刻板印象维度的偏差概况。沿着这些维度，我们探究了上下文嵌入中的性别偏差，涵盖不同的上下文和层级，并为十二种不同的LLMs生成了刻板印象概况，展现了其在揭示和可视化偏差方面的直观性及用例。

> Large language models (LLMs) are the foundation of the current successes of artificial intelligence (AI), however, they are unavoidably biased. To effectively communicate the risks and encourage mitigation efforts these models need adequate and intuitive descriptions of their discriminatory properties, appropriate for all audiences of AI. We suggest bias profiles with respect to stereotype dimensions based on dictionaries from social psychology research. Along these dimensions we investigate gender bias in contextual embeddings, across contexts and layers, and generate stereotype profiles for twelve different LLMs, demonstrating their intuition and use case for exposing and visualizing bias.

[Arxiv](https://arxiv.org/abs/2411.16527)