# 多模态检索增强的多模态生成：一个基准、评估指标及强大基线

发布时间：2024年11月25日

`RAG` `多模态`

> Multi-modal Retrieval Augmented Multi-modal Generation: A Benchmark, Evaluate Metrics and Strong Baselines

# 摘要

> 这篇论文对多模态检索增强多模态生成（M$^2$RAG）这一有趣任务展开了研究。该任务要求基础模型浏览有混合文本与图像的多模态网页，并生成多模态响应来解答用户的查询，具有更好的信息密度和可读性。由于 M$^2$RAG 任务尚处于早期研究阶段，缺少系统的研究与分析。为此，我们为 M$^2$RAG 任务构建了一个基准，配备了一系列文本模态指标和多模态指标，用于分析现有基础模型的能力。另外，依据我们基准的综合评估结果，我们还为基础模型提出了几种完成此任务的有效办法。大量实验结果揭示了几个值得深入研究的有趣现象。

> This paper investigates an intriguing task of Multi-modal Retrieval Augmented Multi-modal Generation (M$^2$RAG). This task requires foundation models to browse multi-modal web pages, with mixed text and images, and generate multi-modal responses for solving user queries, which exhibits better information density and readability. Given the early researching stage of M$^2$RAG task, there is a lack of systematic studies and analysis. To fill this gap, we construct a benchmark for M$^2$RAG task, equipped with a suite of text-modal metrics and multi-modal metrics to analyze the capabilities of existing foundation models. Besides, we also propose several effective methods for foundation models to accomplish this task, based on the comprehensive evaluation results on our benchmark. Extensive experimental results reveal several intriguing phenomena worth further research.

[Arxiv](https://arxiv.org/abs/2411.16365)