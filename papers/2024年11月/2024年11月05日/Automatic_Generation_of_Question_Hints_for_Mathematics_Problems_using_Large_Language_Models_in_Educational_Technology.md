# 在教育技术中使用大型语言模型为数学问题自动生成问题提示

发布时间：2024年11月05日

`LLM应用` `智能辅导系统`

> Automatic Generation of Question Hints for Mathematics Problems using Large Language Models in Educational Technology

# 摘要

> 大型语言模型（LLMs）在智能辅导系统（ITSs）内自动生成提示已显示出增强学生学习的潜力。然而，生成在教学上合理、解决学生误解并符合特定教育目标的提示仍然具有挑战性。这项工作探索使用 LLMs（GPT-4o 和 Llama-3-8B-instruct）作为教师，为通过 LLMs（GPT-3.5-turbo、Llama-3-8B-Instruct 或 Mistral-7B-instruct-v0.3）模拟的学生生成应对为人类高中生设计的数学练习的有效提示，并依据认知科学原理进行设计。我们在此呈现几个维度的研究：1）识别模拟学生在高中数学练习中出现的错误模式；2）为作为教师的 GPT-4o 开发各种提示，并评估它们在生成能使模拟学生自我纠正的提示方面的有效性；3）基于其产生相关提示和促进错误纠正的能力，用 Llama-3-8B-Instruct 作为教师测试表现最佳的提示，以便与 GPT-4o 进行性能比较。结果表明，模型错误随着温度设置的升高而增加。值得注意的是，当提示由 GPT-4o 生成时，最有效的提示包括针对特定错误的提示以及基于常见数学错误提供的一般提示。有趣的是，作为教师的 Llama-3-8B-Instruct 总体表现优于 GPT-4o。而且作为学生的 LLMs，特别是 GPT-3.5-turbo 的问题解决和响应修订能力在收到提示后显著提高，尤其是在较低温度设置下。然而，像 Mistral-7B-Instruct 这样的模型随着温度的升高表现下降。

> The automatic generation of hints by Large Language Models (LLMs) within Intelligent Tutoring Systems (ITSs) has shown potential to enhance student learning. However, generating pedagogically sound hints that address student misconceptions and adhere to specific educational objectives remains challenging. This work explores using LLMs (GPT-4o and Llama-3-8B-instruct) as teachers to generate effective hints for students simulated through LLMs (GPT-3.5-turbo, Llama-3-8B-Instruct, or Mistral-7B-instruct-v0.3) tackling math exercises designed for human high-school students, and designed using cognitive science principles. We present here the study of several dimensions: 1) identifying error patterns made by simulated students on secondary-level math exercises; 2) developing various prompts for GPT-4o as a teacher and evaluating their effectiveness in generating hints that enable simulated students to self-correct; and 3) testing the best-performing prompts, based on their ability to produce relevant hints and facilitate error correction, with Llama-3-8B-Instruct as the teacher, allowing for a performance comparison with GPT-4o. The results show that model errors increase with higher temperature settings. Notably, when hints are generated by GPT-4o, the most effective prompts include prompts tailored to specific errors as well as prompts providing general hints based on common mathematical errors. Interestingly, Llama-3-8B-Instruct as a teacher showed better overall performance than GPT-4o. Also the problem-solving and response revision capabilities of the LLMs as students, particularly GPT-3.5-turbo, improved significantly after receiving hints, especially at lower temperature settings. However, models like Mistral-7B-Instruct demonstrated a decline in performance as the temperature increased.

[Arxiv](https://arxiv.org/abs/2411.03495)