# 通过多元框架评估跨大型语言模型的道德信念

发布时间：2024年11月05日

`LLM应用` `语言模型` `道德评估`

> Evaluating Moral Beliefs across LLMs through a Pluralistic Framework

# 摘要

> 正确的道德信念对于语言模型来说是基础的，但评估这些信念构成了重大挑战。本研究引入了一个新颖的三模块框架来评估四个著名的大型语言模型的道德信念。最初，我们构建了一个包含 472 个中文道德选择场景的数据集，这些场景源自道德词汇。模型在这些场景中的决策过程揭示了它们的道德原则偏好。通过对这些道德选择进行排名，我们辨别出不同语言模型所拥有的不同道德信念。此外，通过道德辩论，我们调查了这些模型对其道德选择的坚定程度。我们的研究结果表明，英语语言模型，即 ChatGPT 和 Gemini，紧密反映了中国大学生样本的道德决策，显示出对其选择的强烈坚持和对个人主义道德信念的偏好。相比之下，像 Ernie 和 ChatGLM 这样的中文模型倾向于集体主义道德信念，在其道德选择和辩论中表现出模糊性。本研究还揭示了所有被研究的语言模型的道德信念中嵌入的性别偏见。我们的方法提供了一种创新的手段来评估人工智能和人类智能中的道德信念，促进了不同文化之间道德价值观的比较。

> Proper moral beliefs are fundamental for language models, yet assessing these beliefs poses a significant challenge. This study introduces a novel three-module framework to evaluate the moral beliefs of four prominent large language models. Initially, we constructed a dataset containing 472 moral choice scenarios in Chinese, derived from moral words. The decision-making process of the models in these scenarios reveals their moral principle preferences. By ranking these moral choices, we discern the varying moral beliefs held by different language models. Additionally, through moral debates, we investigate the firmness of these models to their moral choices. Our findings indicate that English language models, namely ChatGPT and Gemini, closely mirror moral decisions of the sample of Chinese university students, demonstrating strong adherence to their choices and a preference for individualistic moral beliefs. In contrast, Chinese models such as Ernie and ChatGLM lean towards collectivist moral beliefs, exhibiting ambiguity in their moral choices and debates. This study also uncovers gender bias embedded within the moral beliefs of all examined language models. Our methodology offers an innovative means to assess moral beliefs in both artificial and human intelligence, facilitating a comparison of moral values across different cultures.

[Arxiv](https://arxiv.org/abs/2411.03665)