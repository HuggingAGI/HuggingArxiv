# 逻辑增强式生成

发布时间：2024年11月21日

`LLM应用`

> Logic Augmented Generation

# 摘要

> 语义知识图谱（SKG）在可扩展性、灵活性、上下文理解以及处理非结构化或模糊信息时遭遇难题。但它们凭借推理和查询，能提供正式且结构化的知识，从而达成高度可解释和可靠的成果。大型语言模型（LLM）突破了这些局限，使其适用于开放式任务和非结构化环境。然而，LLM既难以解释，也不可靠。为化解LLM和SKG之间的分歧，我们构想了逻辑增强生成（LAG），它融合了二者的优点。LAG把LLM当作反应式连续知识图谱，能够按需生成潜在的无限关系和隐性知识。SKG对于注入具有清晰逻辑和事实边界的离散启发式维度极为关键。我们在集体智能的两个任务，即医疗诊断和气候预测中对LAG进行了示例说明。了解LAG的特性和限制（目前大多未知）对于完成涉及隐性知识的各类任务，从而提供可解释且有效的结果，具有极其重要的意义。

> Semantic Knowledge Graphs (SKG) face challenges with scalability, flexibility, contextual understanding, and handling unstructured or ambiguous information. However, they offer formal and structured knowledge enabling highly interpretable and reliable results by means of reasoning and querying. Large Language Models (LLMs) overcome those limitations making them suitable in open-ended tasks and unstructured environments. Nevertheless, LLMs are neither interpretable nor reliable. To solve the dichotomy between LLMs and SKGs we envision Logic Augmented Generation (LAG) that combines the benefits of the two worlds. LAG uses LLMs as Reactive Continuous Knowledge Graphs that can generate potentially infinite relations and tacit knowledge on-demand. SKGs are key for injecting a discrete heuristic dimension with clear logical and factual boundaries. We exemplify LAG in two tasks of collective intelligence, i.e., medical diagnostics and climate projections. Understanding the properties and limitations of LAG, which are still mostly unknown, is of utmost importance for enabling a variety of tasks involving tacit knowledge in order to provide interpretable and effective results.

[Arxiv](https://arxiv.org/abs/2411.14012)