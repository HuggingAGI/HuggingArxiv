# 自然语言强化式学习

发布时间：2024年11月21日

`LLM应用`

> Natural Language Reinforcement Learning

# 摘要

> 强化学习（RL）通过马尔可夫决策过程（MDP）对决策制定进行数学化表述。依靠 MDP，研究人员在诸如游戏、机器人以及语言模型等众多领域实现了显著突破。本文探索一种新的可能——自然语言强化学习（NLRL），将传统的 MDP 拓展至基于自然语言的表示空间。具体来说，NLRL 创造性地把包括任务目标、策略、价值函数、贝尔曼方程和策略迭代等 RL 原则重新定义为对应的语言形式。随着大型语言模型（LLMs）的最新发展，NLRL 能够通过纯提示或者基于梯度的训练，切实达成类似 RL 的策略和价值提升。在迷宫、突破和井字棋等游戏中的实验，展现了 NLRL 框架在各类用例中的有效性、高效性和可解释性。我们的代码将在 https://github.com/waterhorse1/Natural-language-RL 发布。

> Reinforcement Learning (RL) mathematically formulates decision-making with Markov Decision Process (MDP). With MDPs, researchers have achieved remarkable breakthroughs across various domains, including games, robotics, and language models. This paper seeks a new possibility, Natural Language Reinforcement Learning (NLRL), by extending traditional MDP to natural language-based representation space. Specifically, NLRL innovatively redefines RL principles, including task objectives, policy, value function, Bellman equation, and policy iteration, into their language counterparts. With recent advancements in large language models (LLMs), NLRL can be practically implemented to achieve RL-like policy and value improvement by either pure prompting or gradient-based training. Experiments over Maze, Breakthrough, and Tic-Tac-Toe games demonstrate the effectiveness, efficiency, and interpretability of the NLRL framework among diverse use cases. Our code will be released at https://github.com/waterhorse1/Natural-language-RL.

[Arxiv](https://arxiv.org/abs/2411.14251)