# 知识图谱、大型语言模型与幻觉：从自然语言处理的视角来看

发布时间：2024年11月21日

`LLM应用` `知识图谱`

> Knowledge Graphs, Large Language Models, and Hallucinations: An NLP Perspective

# 摘要

> 大型语言模型（LLMs）给基于自然语言处理（NLP）的应用带来了革命性变化，像自动文本生成、问答、聊天机器人等等。但它们面临着一个严峻挑战——幻觉，也就是模型会给出看似合理实则错误的回答。这损害了信任，限制了LLMs在不同领域的应用。而知识图谱（KGs）呢，提供了结构化的相互关联的事实集合，表现为实体（节点）和它们的关系（边）。在近期研究里，KGs被用来提供上下文，能填补LLM对某些主题理解的空缺，为缓解LLMs的幻觉提供了很有前景的办法，增强了其可靠性和准确性，还得益于其广泛适用性。不过，这仍是个活跃的研究领域，存在诸多未解决的开放问题。在本文中，我们探讨了这些开放挑战，涵盖了前沿的数据集和基准，还有知识集成及评估幻觉的方法。在讨论中，我们考虑了KGs在LLM系统中的当下运用，并明确了每个挑战中的未来走向。

> Large Language Models (LLMs) have revolutionized Natural Language Processing (NLP) based applications including automated text generation, question answering, chatbots, and others. However, they face a significant challenge: hallucinations, where models produce plausible-sounding but factually incorrect responses. This undermines trust and limits the applicability of LLMs in different domains. Knowledge Graphs (KGs), on the other hand, provide a structured collection of interconnected facts represented as entities (nodes) and their relationships (edges). In recent research, KGs have been leveraged to provide context that can fill gaps in an LLM understanding of certain topics offering a promising approach to mitigate hallucinations in LLMs, enhancing their reliability and accuracy while benefiting from their wide applicability. Nonetheless, it is still a very active area of research with various unresolved open problems. In this paper, we discuss these open challenges covering state-of-the-art datasets and benchmarks as well as methods for knowledge integration and evaluating hallucinations. In our discussion, we consider the current use of KGs in LLM systems and identify future directions within each of these challenges.

[Arxiv](https://arxiv.org/abs/2411.14258)