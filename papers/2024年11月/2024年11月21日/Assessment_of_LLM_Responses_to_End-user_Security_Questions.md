# 关于大型语言模型对终端用户安全问题响应的评估

发布时间：2024年11月21日

`LLM应用` `语言模型`

> Assessment of LLM Responses to End-user Security Questions

# 摘要

> 回答终端用户的安全问题颇具挑战。尽管像 GPT、LLAMA 和 Gemini 这类大型语言模型并非毫无差错，但它们在回答安全领域之外的各类问题时已展现出潜力。我们针对 900 个系统收集的终端用户安全问题，对 3 个热门的大型语言模型进行了定性评估，以此探究其在终端用户安全方面的表现。
  虽然大型语言模型展现出了有关终端用户安全信息的广泛“通识”，但其中存在错误和局限的模式，涵盖过时且不准确的答案，以及间接或无回应的沟通风格，所有这些都影响了所接收信息的质量。基于这些模式，我们为模型改进指明了方向，并为用户在寻求安全协助时与大型语言模型互动推荐了策略。

> Answering end user security questions is challenging. While large language models (LLMs) like GPT, LLAMA, and Gemini are far from error-free, they have shown promise in answering a variety of questions outside of security. We studied LLM performance in the area of end user security by qualitatively evaluating 3 popular LLMs on 900 systematically collected end user security questions.
  While LLMs demonstrate broad generalist ``knowledge'' of end user security information, there are patterns of errors and limitations across LLMs consisting of stale and inaccurate answers, and indirect or unresponsive communication styles, all of which impacts the quality of information received. Based on these patterns, we suggest directions for model improvement and recommend user strategies for interacting with LLMs when seeking assistance with security.

[Arxiv](https://arxiv.org/abs/2411.14571)