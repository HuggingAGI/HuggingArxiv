# 全球安全可靠的大型语言模型挑战之赛道 1

发布时间：2024年11月21日

`LLM应用` `人工智能` `公共管理`

> Global Challenge for Safe and Secure LLMs Track 1

# 摘要

> 本文介绍了由新加坡人工智能（AISG）和网络新加坡研发计划办公室（CRPO）组织的“全球安全可靠大型语言模型（LLMs）挑战”这一开创性活动，其旨在推动针对自动越狱攻击的先进防御机制的发展。随着LLMs在医疗、金融和公共管理等关键领域的不断融合，确保这些模型能抵御对抗性攻击，对于防止滥用和坚守道德标准至关重要。此次竞赛聚焦于两条不同的赛道，以评估和增强LLM安全框架的稳固性。赛道1要求参与者开发自动方法，通过引出不良响应来探测LLM的漏洞，切实测试LLM中现有安全协议的限度。参与者需要设计能够在从攻击性语言到错误信息和非法活动等各类场景中绕过内容防护措施的技术。通过这一过程，赛道1旨在加深对LLM漏洞的认识，并为创建更具韧性的模型提供思路。

> This paper introduces the Global Challenge for Safe and Secure Large Language Models (LLMs), a pioneering initiative organized by AI Singapore (AISG) and the CyberSG R&D Programme Office (CRPO) to foster the development of advanced defense mechanisms against automated jailbreaking attacks. With the increasing integration of LLMs in critical sectors such as healthcare, finance, and public administration, ensuring these models are resilient to adversarial attacks is vital for preventing misuse and upholding ethical standards. This competition focused on two distinct tracks designed to evaluate and enhance the robustness of LLM security frameworks. Track 1 tasked participants with developing automated methods to probe LLM vulnerabilities by eliciting undesirable responses, effectively testing the limits of existing safety protocols within LLMs. Participants were challenged to devise techniques that could bypass content safeguards across a diverse array of scenarios, from offensive language to misinformation and illegal activities. Through this process, Track 1 aimed to deepen the understanding of LLM vulnerabilities and provide insights for creating more resilient models.

[Arxiv](https://arxiv.org/abs/2411.14502)