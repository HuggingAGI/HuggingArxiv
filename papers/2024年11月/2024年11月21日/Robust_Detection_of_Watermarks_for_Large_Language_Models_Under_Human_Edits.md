# 针对人类编辑下大型语言模型的水印进行稳健检测

发布时间：2024年11月21日

`LLM应用` `语言模型` `水印技术`

> Robust Detection of Watermarks for Large Language Models Under Human Edits

# 摘要

> 水印技术为区分大型语言模型（LLMs）生成的文本与人类撰写的文本提供了行之有效的办法。然而，人类对LLM生成的文本的大量编辑稀释了水印信号，致使现有方法的检测性能大幅下降。在本文中，通过用混合模型检测来对人类编辑进行建模，我们引入了一种新方法——截断拟合优度检验，用于检测经人类编辑的水印文本，我们称之为Tr-GoF。我们证明，在大量文本修改和水印信号渐弱的特定渐近情形下，Tr-GoF检验在鲁棒检测Gumbel-max水印时达到了最优。关键在于，与最优但不实用的（Neyman--Pearson）似然比检验不同，Tr-GoF检验能自适应地达成最优，因为它无需精确知晓人类编辑水平或LLMs的概率规格。另外，我们确定在一定程度的适度文本修改情形下，Tr-GoF检验能实现最高的检测效率。形成鲜明对比的是，我们指出现有方法采用的基于求和的检测规则在这两种情形下都无法实现最优的鲁棒性，因为其统计的加法性质对编辑引发的噪声抵御能力较弱。最后，我们在合成数据以及OPT和LLaMA系列的开源LLMs上展示了Tr-GoF检验具有竞争力且有时更出色的实际性能。

> Watermarking has offered an effective approach to distinguishing text generated by large language models (LLMs) from human-written text. However, the pervasive presence of human edits on LLM-generated text dilutes watermark signals, thereby significantly degrading detection performance of existing methods. In this paper, by modeling human edits through mixture model detection, we introduce a new method in the form of a truncated goodness-of-fit test for detecting watermarked text under human edits, which we refer to as Tr-GoF. We prove that the Tr-GoF test achieves optimality in robust detection of the Gumbel-max watermark in a certain asymptotic regime of substantial text modifications and vanishing watermark signals. Importantly, Tr-GoF achieves this optimality \textit{adaptively} as it does not require precise knowledge of human edit levels or probabilistic specifications of the LLMs, in contrast to the optimal but impractical (Neyman--Pearson) likelihood ratio test. Moreover, we establish that the Tr-GoF test attains the highest detection efficiency rate in a certain regime of moderate text modifications. In stark contrast, we show that sum-based detection rules, as employed by existing methods, fail to achieve optimal robustness in both regimes because the additive nature of their statistics is less resilient to edit-induced noise. Finally, we demonstrate the competitive and sometimes superior empirical performance of the Tr-GoF test on both synthetic data and open-source LLMs in the OPT and LLaMA families.

[Arxiv](https://arxiv.org/abs/2411.13868)