# EthioLLM 是一款专为埃塞俄比亚多种语言设计的大型多语种语言模型，并通过详尽的任务评估展示了其性能。

发布时间：2024年03月20日

`LLM应用` `低资源语言`

> EthioLLM: Multilingual Large Language Models for Ethiopian Languages with Task Evaluation

> 近期大放异彩的LLMs凭借其在各领域下游NLP任务中的优异表现为人们所热捧，但受限于训练资源稀缺，低资源语言在NLP尖端技术发展中仍处于滞后状态。具有丰富语言多样性的埃塞俄比亚语系包含了大量独特的文字体系，承载着深远的宗教与文化底蕴。本文介绍了一款名为EthioLLM的多语言大型模型，它涵盖了五种埃塞俄比亚语言（阿姆哈拉语、 Geez语、奥罗莫语、索马里语和提格雷尼亚语）以及英语，并且推出了全新的下游NLP任务基准数据集——Ethiobenchmark。我们对这些模型在五个不同的下游NLP任务上的表现进行了综合评测，并公开了多语言模型、各类下游任务新基准数据集以及针对性微调后的语言模型，同时深入探讨了模型的性能表现。所有数据集和模型均可在https://huggingface.co/EthioNLP库中找到。

> Large language models (LLMs) have gained popularity recently due to their outstanding performance in various downstream Natural Language Processing (NLP) tasks. However, low-resource languages are still lagging behind current state-of-the-art (SOTA) developments in the field of NLP due to insufficient resources to train LLMs. Ethiopian languages exhibit remarkable linguistic diversity, encompassing a wide array of scripts, and are imbued with profound religious and cultural significance. This paper introduces EthioLLM -- multilingual large language models for five Ethiopian languages (Amharic, Ge'ez, Afan Oromo, Somali, and Tigrinya) and English, and Ethiobenchmark -- a new benchmark dataset for various downstream NLP tasks. We evaluate the performance of these models across five downstream NLP tasks. We open-source our multilingual language models, new benchmark datasets for various downstream tasks, and task-specific fine-tuned language models and discuss the performance of the models. Our dataset and models are available at the https://huggingface.co/EthioNLP repository.

[Arxiv](https://arxiv.org/abs/2403.13737)