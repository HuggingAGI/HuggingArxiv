# [优化大型语言模型内部的概念理解能力步骤 1 翻译：编辑大型语言模型 (LLM) 中的概念知识。步骤 2 优化翻译：本研究探讨如何编辑和优化大型语言模型所承载的概念性知识结构，以提升其内在认知能力和表达精准度。](https://arxiv.org/abs/2403.06259)

发布时间：2024年03月10日

`LLM应用`

> Editing Conceptual Knowledge for Large Language Models

> 近期，对LLMs进行知识编辑的兴趣日益增长，然而现有研究仅停留在实例层面的编辑探讨，对于LLMs能否修改概念知识尚未明晰。本论文创新性地构建了名为ConceptEdit的基准数据集，并提出了一套全新的评估标准，首开对LLMs概念知识编辑能力的研究之先河。实验揭示，虽然现行编辑手段能在一定范围内有效调整概念定义，但也可能无意间扭曲LLMs中的相关实例知识，从而影响整体表现。我们期待这一研究成果能激发对LLMs更深层次理解的研究热潮，项目主页现已上线，地址为https://zjunlp.github.io/project/ConceptEdit。

> Recently, there has been a growing interest in knowledge editing for Large Language Models (LLMs). Current approaches and evaluations merely explore the instance-level editing, while whether LLMs possess the capability to modify concepts remains unclear. This paper pioneers the investigation of editing conceptual knowledge for LLMs, by constructing a novel benchmark dataset ConceptEdit and establishing a suite of new metrics for evaluation. The experimental results reveal that, although existing editing methods can efficiently modify concept-level definition to some extent, they also have the potential to distort the related instantial knowledge in LLMs, leading to poor performance. We anticipate this can inspire further progress in better understanding LLMs. Our project homepage is available at https://zjunlp.github.io/project/ConceptEdit.

[Arxiv](https://arxiv.org/abs/2403.06259)