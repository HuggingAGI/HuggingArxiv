# [ERA-CoT 是一种创新方法，它借助实体关系分析技术来提升思维链（Chain-of-Thought）的表现。该方法旨在深入理解并优化大型语言模型在解决复杂问题时的内在逻辑推理过程。](https://arxiv.org/abs/2403.06932)

发布时间：2024年03月11日

`LLM应用`

> ERA-CoT: Improving Chain-of-Thought through Entity Relationship Analysis

> 尽管 LLM 在各领域表现卓越，但在处理涉及多重实体的复杂情境时，仍需面对严峻考验，原因在于此类情境下蕴含着要求多步骤推理的隐性关系。为此，本研究提出了名为 ERA-CoT 的新颖方案，它能通过捕捉实体间关系来辅助 LLM 更好地理解语境，并运用“链式思考”(Chain-of-Thought, CoT) 支持多元任务的深度推理。实验证明，ERA-CoT 方法在与现有 CoT 提示技术比较时，展现出了卓越性能，使得 GPT3.5 平均提升5.1\%，远超以往 SOTA 水准。深入分析显示，ERA-CoT 显著提升了 LLM 对实体关联的认知水平，大幅提高了问题解答准确性，并有效增强了 LLM 的逻辑推理能力。

> Large language models (LLMs) have achieved commendable accomplishments in various natural language processing tasks. However, LLMs still encounter significant challenges when dealing with complex scenarios involving multiple entities. These challenges arise from the presence of implicit relationships that demand multi-step reasoning. In this paper, we propose a novel approach ERA-CoT, which aids LLMs in understanding context by capturing relationships between entities and supports the reasoning of diverse tasks through Chain-of-Thoughts (CoT). Experimental results show that ERA-CoT demonstrates the superior performance of our proposed method compared to current CoT prompting methods, achieving a significant improvement of an average of 5.1\% on GPT3.5 compared to previous SOTA baselines. Our analysis indicates that ERA-CoT increases the LLM's understanding of entity relationships, significantly improves the accuracy of question answering, and enhances the reasoning ability of LLMs.