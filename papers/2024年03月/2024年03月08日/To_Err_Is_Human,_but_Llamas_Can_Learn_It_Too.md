# [犯错误是人类的天性，然而羊驼也同样具有学习犯错的能力。]

发布时间：2024年03月08日

`LLM应用`

> To Err Is Human, but Llamas Can Learn It Too

> 本研究创新性地运用基于Llama 2的语言模型进行人工错误生成，成功模拟出类似真实人类错误的合成错误，以期提升语法错误纠正（GEC）技术。经过微调后的模型在德语、乌克兰语和爱沙尼亚语等测试语言中，结合这些人工生成的错误训练GEC Llama模型，性能显著超越了先前的顶级纠错模型，增益范围为0.8至6 F0.5点。另外，实验还验证了通过微调小型序列到序列模型及引导大型商用LM（例如GPT-3.5和GPT-4）生成错误的方式，也能有效促进错误生成模型的学习效果。

> This study explores enhancing grammatical error correction (GEC) through artificial error generation (AEG) using language models (LMs). Specifically, we fine-tune Llama 2-based LMs for error generation and find that this approach yields synthetic errors akin to human errors. Next, we train GEC Llama models with the help of these artificial errors and outperform previous state-of-the-art error correction models, with gains ranging between 0.8 and 6 F0.5 points across all tested languages (German, Ukrainian, and Estonian). Moreover, we demonstrate that generating errors by fine-tuning smaller sequence-to-sequence models and prompting large commercial LMs (GPT-3.5 and GPT-4) also results in synthetic errors beneficially affecting error generation models.

[Arxiv](https://arxiv.org/abs/2403.05493)