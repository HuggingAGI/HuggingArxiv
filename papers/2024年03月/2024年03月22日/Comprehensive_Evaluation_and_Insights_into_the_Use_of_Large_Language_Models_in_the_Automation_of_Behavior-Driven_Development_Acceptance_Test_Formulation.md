# 深入探索大型语言模型在自动化行为驱动开发验收测试设计中的应用及其全面评估

发布时间：2024年03月22日

`LLM应用` `软件工程` `自动化测试`

> Comprehensive Evaluation and Insights into the Use of Large Language Models in the Automation of Behavior-Driven Development Acceptance Test Formulation

> 行为驱动开发（BDD）作为一种强化多方合作的敏捷测试策略，在本文中，我们提出一种新颖方法，借助大型语言模型（LLMs）自动化生成验收测试，以优化BDD实践。我们使用零样本与少量样本提示法评估包括GPT-3.5、GPT-4、Llama-2-13B和PaLM-2在内的多种LLMs。论文详述了一套包括数据集选取、提示技术运用、LLMs应用及评估流程在内的全面方法论。实验结果显示，GPT-3.5和GPT-4成功地生成高质量、无误的BDD验收测试，且表现卓越。其中，少量样本提示法通过融入上下文学习实例，显著提高了测试生成的精准度。研究进一步通过对LLMs的语法错误检测、验证准确率比较分析，有力证明了它们在提升BDD实践效能上的作用。尽管如此，我们亦承认当前方法尚存局限。但此方法无疑能够助力于协同BDD流程，并为未来基于LLMs开展自动化BDD验收测试生成的研究开辟新的探索空间。

> Behavior-driven development (BDD) is an Agile testing methodology fostering collaboration among developers, QA analysts, and stakeholders. In this manuscript, we propose a novel approach to enhance BDD practices using large language models (LLMs) to automate acceptance test generation. Our study uses zero and few-shot prompts to evaluate LLMs such as GPT-3.5, GPT-4, Llama-2-13B, and PaLM-2. The paper presents a detailed methodology that includes the dataset, prompt techniques, LLMs, and the evaluation process. The results demonstrate that GPT-3.5 and GPT-4 generate error-free BDD acceptance tests with better performance. The few-shot prompt technique highlights its ability to provide higher accuracy by incorporating examples for in-context learning. Furthermore, the study examines syntax errors, validation accuracy, and comparative analysis of LLMs, revealing their effectiveness in enhancing BDD practices. However, our study acknowledges that there are limitations to the proposed approach. We emphasize that this approach can support collaborative BDD processes and create opportunities for future research into automated BDD acceptance test generation using LLMs.

[Arxiv](https://arxiv.org/abs/2403.14965)