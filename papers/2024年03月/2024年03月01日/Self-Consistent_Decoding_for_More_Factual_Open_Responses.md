# [为了生成更为事实准确的开放式回答，我们采用“自我一致性解码”方法。](https://arxiv.org/abs/2403.00696)

发布时间：2024年03月01日

`LLM应用`

> Self-Consistent Decoding for More Factual Open Responses

> 自我一致性技术被证实能显著提升大型语言模型生成短答案的准确度。但以往仅关注由模型产出文本解析出的最终答案质量。本次研究将其理念延伸至开放型回复生成领域，并创新性地将投票机制融入解码流程。该“采样&选择”方法依据简洁的令牌重叠得分，根据之前的选择从多个候选样本中挑选输出句子。我们对比了此方法与贪婪解码、束搜索、核抽样及近期提出的DoLA、P-CRR和S-CRR等避免虚构内容的解码器，在使用FRANK基准的CNN/DM和XSum子集上基于NLI的评估中，“采样&选择”方法在保证与参考摘要相近的ROUGE-1 F1评分的同时，其事实准确性提升了30%的相对优势。通过人工验证生成的摘要内容，进一步证实了我们方法在事实性上的卓越表现。

> Self-consistency has emerged as a powerful method for improving the accuracy of short answers generated by large language models. As previously defined, it only concerns the accuracy of a final answer parsed from generated text. In this work, we extend the idea to open response generation, by integrating voting into the decoding method. Each output sentence is selected from among multiple samples, conditioning on the previous selections, based on a simple token overlap score. We compare this "Sample & Select" method to greedy decoding, beam search, nucleus sampling, and the recently introduced hallucination avoiding decoders of DoLA, P-CRR, and S-CRR. We show that Sample & Select improves factuality by a 30% relative margin against these decoders in NLI-based evaluation on the subsets of CNN/DM and XSum used in the FRANK benchmark, while maintaining comparable ROUGE-1 F1 scores against reference summaries. We collect human verifications of the generated summaries, confirming the factual superiority of our method.

[Arxiv](https://arxiv.org/abs/2403.00696)