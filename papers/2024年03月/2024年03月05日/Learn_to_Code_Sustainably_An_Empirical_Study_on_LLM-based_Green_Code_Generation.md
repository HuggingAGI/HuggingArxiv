# [探究如何实现可持续编程，本研究通过实证方法考察了基于大型语言模型（LLM）的绿色代码生成技术。]

发布时间：2024年03月05日

`LLM应用`

> Learn to Code Sustainably: An Empirical Study on LLM-based Green Code Generation

> 随着信息技术的广泛应用，数据中心能源消耗与碳排放的比例不断攀升，且在大数据分析需求增强、数字化进程加速以及大型AI模型研发的驱动下，这一趋势有望持续增长。为应对软件开发对环境造成的影响，业界对绿色编程的关注度日益提高，甚至有人认为AI模型的应用可助力实现能源效率提升。本文通过实证研究探讨了绿色代码及其相关实践，并综述了用于评估AI模型可持续性的各项指标。我们特别针对由GitHub Copilot、OpenAI ChatGPT-3和Amazon CodeWhisperer等商业生成式AI语言模型所生成的自动生成代码进行了可持续性评估。在研究方法中，我们创新性地根据特定可持续性标准定义了“代码绿色能力”概念，以此来量化各AI模型的可持续意识水平。进一步地，我们将人类编写的代码与三种AI语言模型针对不同难度问题生成的代码，在性能与绿色能力两个维度上进行对比分析。研究结果显示了当前AI模型在推动可持续软件开发方面的实际效能。

> The increasing use of information technology has led to a significant share of energy consumption and carbon emissions from data centers. These contributions are expected to rise with the growing demand for big data analytics, increasing digitization, and the development of large artificial intelligence (AI) models. The need to address the environmental impact of software development has led to increased interest in green (sustainable) coding and claims that the use of AI models can lead to energy efficiency gains. Here, we provide an empirical study on green code and an overview of green coding practices, as well as metrics used to quantify the sustainability awareness of AI models. In this framework, we evaluate the sustainability of auto-generated code. The auto-generate codes considered in this study are produced by generative commercial AI language models, GitHub Copilot, OpenAI ChatGPT-3, and Amazon CodeWhisperer. Within our methodology, in order to quantify the sustainability awareness of these AI models, we propose a definition of the code's "green capacity", based on certain sustainability metrics. We compare the performance and green capacity of human-generated code and code generated by the three AI language models in response to easy-to-hard problem statements. Our findings shed light on the current capacity of AI models to contribute to sustainable software development.

[Arxiv](https://arxiv.org/abs/2403.03344)