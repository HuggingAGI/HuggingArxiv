# [“对话即学习”：探索无预设用户画像的个性化对话，借助于对话过程中的实时学习技术](https://arxiv.org/abs/2403.03102)

发布时间：2024年03月05日

`LLM应用`

> "In Dialogues We Learn": Towards Personalized Dialogue Without Pre-defined Profiles through In-Dialogue Learning

> 近年来，因能贴合不同个性进行回应，个性化对话系统备受瞩目，但现有技术大多受限于预先设定且制作繁琐、不够灵活的人物档案。为此，我们创新提出“对话中学习”（IDL）这一微调方案，让预训练的大型语言模型通过对话历史动态捕捉人物特性，进而无需预设档案就能出色完成个性化对话生成任务。实验证明IDL成效卓著，在三个数据集上BLEU和ROUGE得分分别提升了最高达200%和247%，并且经过人工评估，进一步证实了IDL方法的有效性和优越性。

> Personalized dialogue systems have gained significant attention in recent years for their ability to generate responses in alignment with different personas. However, most existing approaches rely on pre-defined personal profiles, which are not only time-consuming and labor-intensive to create but also lack flexibility. We propose In-Dialogue Learning (IDL), a fine-tuning framework that enhances the ability of pre-trained large language models to leverage dialogue history to characterize persona for completing personalized dialogue generation tasks without pre-defined profiles. Our experiments on three datasets demonstrate that IDL brings substantial improvements, with BLEU and ROUGE scores increasing by up to 200% and 247%, respectively. Additionally, the results of human evaluations further validate the efficacy of our proposed method.