# 自我一致性框架：专为语言模型量身定制，旨在调和多元观点，寻求共识。通过精细调整，该框架助力语言模型在多样化的意见中寻找共同点。

发布时间：2023年05月19日

`Agent` `多智能体系统`

> Self-Agreement: A Framework for Fine-tuning Language Models to Find Agreement among Diverse Opinions

# 摘要

> 在多智能体系统中达成共识是一项挑战，但大型语言模型（LLMs）凭借其卓越的理解和生成文本能力，为这一挑战提供了新的解决途径。尽管如此，它们通常需要依赖大量的人工标注数据。本文提出了“自我共识”框架，这是一个创新的方法，通过使用LLM自身生成的数据，训练LLM自主寻找共识。具体操作是，利用GPT-3生成针对问题库中每个问题的不同意见，并从中挑选出多个可能的共识选项。接着，基于BERT的模型对每个选项进行共识评分，挑选出得分最高的共识。这一过程形成了一个包含问题、意见和共识的数据集，用于微调预训练的LLM，以便在多元意见中寻找共识。令人印象深刻的是，使用自我共识框架微调的LLM在参数量仅为GPT-3的1/25的情况下，性能却可与之媲美，这证明了它在无需人工标注数据的情况下，依然能够有效识别不同意见中的共识点。

> Finding an agreement among diverse opinions is a challenging topic in multiagent systems. Recently, large language models (LLMs) have shown great potential in addressing this challenge due to their remarkable capabilities in comprehending human opinions and generating human-like text. However, they typically rely on extensive human-annotated data. In this paper, we propose Self-Agreement, a novel framework for fine-tuning LLMs to autonomously find agreement using data generated by LLM itself. Specifically, our approach employs the generative pre-trained transformer-3 (GPT-3) to generate multiple opinions for each question in a question dataset and create several agreement candidates among these opinions. Then, a bidirectional encoder representations from transformers (BERT)-based model evaluates the agreement score of each agreement candidate and selects the one with the highest agreement score. This process yields a dataset of question-opinion-agreements, which we use to fine-tune a pre-trained LLM for discovering agreements among diverse opinions. Remarkably, a pre-trained LLM fine-tuned by our Self-Agreement framework achieves comparable performance to GPT-3 with only 1/25 of its parameters, showcasing its ability to identify agreement among various opinions without the need for human-annotated data.

[Arxiv](https://arxiv.org/abs/2305.11460)