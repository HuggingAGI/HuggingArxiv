# 2024年01月

2024年01月24日

- ["Medium" LMs of Code in the Era of LLMs: Lessons From StackOverflow](2024年01月24日/Medium_LMs_of_Code_in_the_Era_of_LLMs_Lessons_From_StackOverflow.md)

    - [翻译: 在大型语言模型（LLMs）盛行的时代，我们探讨了“中等规模”的代码语言模型（"Medium" LMs of Code），并从 StackOverflow 的经验中汲取教训。](2024年01月24日/Medium_LMs_of_Code_in_the_Era_of_LLMs_Lessons_From_StackOverflow.md)

- [TrojanPuzzle: Covertly Poisoning Code-Suggestion Models](2024年01月24日/TrojanPuzzle_Covertly_Poisoning_Code-Suggestion_Models.md)

    - [翻译: TrojanPuzzle：暗中污染代码推荐模型](2024年01月24日/TrojanPuzzle_Covertly_Poisoning_Code-Suggestion_Models.md)

2024年01月23日

- [Quality of Answers of Generative Large Language Models vs Peer Patients for Interpreting Lab Test Results for Lay Patients: Evaluation Study](2024年01月23日/Quality_of_Answers_of_Generative_Large_Language_Models_vs_Peer_Patients_for_Interpreting_Lab_Test_Results_for_Lay_Patients_Evaluation_Study.md)

    - [翻译: 生成式大型语言模型与病友在解读普通患者实验室检测结果时答案质量的比较：一项评估研究](2024年01月23日/Quality_of_Answers_of_Generative_Large_Language_Models_vs_Peer_Patients_for_Interpreting_Lab_Test_Results_for_Lay_Patients_Evaluation_Study.md)

- [Meta-Prompting: Enhancing Language Models with Task-Agnostic Scaffolding](2024年01月23日/Meta-Prompting_Enhancing_Language_Models_with_Task-Agnostic_Scaffolding.md)

    - [翻译: 元提示：为语言模型注入通用性支撑，提升其性能](2024年01月23日/Meta-Prompting_Enhancing_Language_Models_with_Task-Agnostic_Scaffolding.md)

2024年01月12日

- [NHANES-GCP: Leveraging the Google Cloud Platform and BigQuery ML for reproducible machine learning with data from the National Health and Nutrition Examination Survey](2024年01月12日/NHANES-GCP_Leveraging_the_Google_Cloud_Platform_and_BigQuery_ML_for_reproducible_machine_learning_with_data_from_the_National_Health_and_Nutrition_Examination_Survey.md)

    - [翻译: NHANES-GCP：借助Google Cloud Platform与BigQuery ML，我们能够对国家健康与营养检查调查的数据进行高效且可重复的机器学习。](2024年01月12日/NHANES-GCP_Leveraging_the_Google_Cloud_Platform_and_BigQuery_ML_for_reproducible_machine_learning_with_data_from_the_National_Health_and_Nutrition_Examination_Survey.md)

2024年01月11日

- [Designing Heterogeneous LLM Agents for Financial Sentiment Analysis](2024年01月11日/Designing_Heterogeneous_LLM_Agents_for_Financial_Sentiment_Analysis.md)

    - [翻译: 本文旨在探讨如何设计多样化的大型语言模型代理，以提升金融情绪分析的准确性和效率。](2024年01月11日/Designing_Heterogeneous_LLM_Agents_for_Financial_Sentiment_Analysis.md)

2024年01月10日

- [KwaiAgents: Generalized Information-seeking Agent System with Large Language Models](2024年01月10日/KwaiAgents_Generalized_Information-seeking_Agent_System_with_Large_Language_Models.md)

    - [翻译: KwaiAgents：结合大型语言模型的全能信息搜寻代理系统](2024年01月10日/KwaiAgents_Generalized_Information-seeking_Agent_System_with_Large_Language_Models.md)

2024年01月03日

- [Evaluating LLMs on Document-Based QA: Exact Answer Selection and Numerical Extraction using Cogtale dataset](2024年01月03日/Evaluating_LLMs_on_Document-Based_QA_Exact_Answer_Selection_and_Numerical_Extraction_using_Cogtale_dataset.md)

    - [翻译: 本文探讨了如何利用 Cogtale 数据集对大型语言模型进行基于文档的问答能力的评估，包括精确答案的选择和数值信息的提取。](2024年01月03日/Evaluating_LLMs_on_Document-Based_QA_Exact_Answer_Selection_and_Numerical_Extraction_using_Cogtale_dataset.md)

2024年01月02日

- [LLM Harmony: Multi-Agent Communication for Problem Solving](2024年01月02日/LLM_Harmony_Multi-Agent_Communication_for_Problem_Solving.md)

    - [翻译: LLM Harmony：协同多代理通信，助力问题解决](2024年01月02日/LLM_Harmony_Multi-Agent_Communication_for_Problem_Solving.md)

2024年01月01日

- [The Cambridge Law Corpus: A Dataset for Legal AI Research](2024年01月01日/The_Cambridge_Law_Corpus_A_Dataset_for_Legal_AI_Research.md)

    - [翻译: 剑桥法律语料库：为法律AI研究提供的数据集。](2024年01月01日/The_Cambridge_Law_Corpus_A_Dataset_for_Legal_AI_Research.md)