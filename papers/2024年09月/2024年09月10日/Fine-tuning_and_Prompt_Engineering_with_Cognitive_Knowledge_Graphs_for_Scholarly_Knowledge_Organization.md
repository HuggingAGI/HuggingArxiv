# 借助认知知识图谱，通过微调和提示工程优化学术知识的组织。

发布时间：2024年09月10日

`LLM应用` `学术研究` `知识图谱`

> Fine-tuning and Prompt Engineering with Cognitive Knowledge Graphs for Scholarly Knowledge Organization

# 摘要

> 每年发表的学术文章数量激增至250万篇以上，给研究人员带来了跟上科学进展的挑战。将这些文章的贡献整合到新型认知知识图谱（CKG）中，将成为访问和组织学术知识的关键，超越标题和摘要的局限。本研究利用大型语言模型（LLM），以结构化和可比的方式分类和描述学术文章的贡献，有效传达结构化学术知识。虽然先前研究局限于特定领域，但LLM捕获的广泛领域无关知识为生成结构化CKG描述提供了巨大潜力。此外，LLM通过提示工程或微调提供定制路径，便于利用高效、经济、环保的小型LLM。我们结合LLM知识和领域专家验证的CKG数据，显著提升LLM性能，特别是在学术文章分类和谓词推荐任务中。通过CKG知识微调LLM，并采用新颖提示技术注入CKG知识，大幅提高学术知识提取准确性。我们将此方法集成到开放研究知识图谱（ORKG），实现对组织化学术知识的精确访问，促进领域无关的学术知识交流和传播，惠及政策制定者、工业从业者和公众。

> The increasing amount of published scholarly articles, exceeding 2.5 million yearly, raises the challenge for researchers in following scientific progress. Integrating the contributions from scholarly articles into a novel type of cognitive knowledge graph (CKG) will be a crucial element for accessing and organizing scholarly knowledge, surpassing the insights provided by titles and abstracts. This research focuses on effectively conveying structured scholarly knowledge by utilizing large language models (LLMs) to categorize scholarly articles and describe their contributions in a structured and comparable manner. While previous studies explored language models within specific research domains, the extensive domain-independent knowledge captured by LLMs offers a substantial opportunity for generating structured contribution descriptions as CKGs. Additionally, LLMs offer customizable pathways through prompt engineering or fine-tuning, thus facilitating to leveraging of smaller LLMs known for their efficiency, cost-effectiveness, and environmental considerations. Our methodology involves harnessing LLM knowledge, and complementing it with domain expert-verified scholarly data sourced from a CKG. This strategic fusion significantly enhances LLM performance, especially in tasks like scholarly article categorization and predicate recommendation. Our method involves fine-tuning LLMs with CKG knowledge and additionally injecting knowledge from a CKG with a novel prompting technique significantly increasing the accuracy of scholarly knowledge extraction. We integrated our approach in the Open Research Knowledge Graph (ORKG), thus enabling precise access to organized scholarly knowledge, crucially benefiting domain-independent scholarly knowledge exchange and dissemination among policymakers, industrial practitioners, and the general public.

[Arxiv](https://arxiv.org/abs/2409.06433)