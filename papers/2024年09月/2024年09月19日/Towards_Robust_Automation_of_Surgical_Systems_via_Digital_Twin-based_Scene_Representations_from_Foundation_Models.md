# 借助基础模型的数字孪生场景表示，迈向外科系统稳健自动化的未来

发布时间：2024年09月19日

`Agent` `自动化`

> Towards Robust Automation of Surgical Systems via Digital Twin-based Scene Representations from Foundation Models

# 摘要

> 基于大型语言模型的智能代理，凭借其规划复杂动作序列的能力，正成为具身智能的强大推手。在众多任务领域，尤其是手术自动化中，稳健的自动化离不开精准的规划。这些代理依赖于详尽的自然语言场景描述。因此，为充分发挥其在手术规划中的潜力，开发同样强大的感知算法，从视觉输入中构建详尽的环境模型，势在必行。过往研究多聚焦于任务规划，感知方案虽简便却局限，难以适应更灵活的环境。我们提出一种基于数字孪生的感知新方法，借助最新视觉基础模型的卓越性能与泛化能力。通过将数字孪生场景与LLM代理规划结合于dVRK平台，我们构建了具身智能系统，并在插销转移与纱布回收任务中验证其稳健性。该方法展现出优异的任务执行能力与环境适应性。然而，这仅是迈向全面数字孪生框架的第一步。未来研究需进一步完善框架，以提升手术中具身智能的可解释性与泛化能力。

> Large language model-based (LLM) agents are emerging as a powerful enabler of robust embodied intelligence due to their capability of planning complex action sequences. Sound planning ability is necessary for robust automation in many task domains, but especially in surgical automation. These agents rely on a highly detailed natural language representation of the scene. Thus, to leverage the emergent capabilities of LLM agents for surgical task planning, developing similarly powerful and robust perception algorithms is necessary to derive a detailed scene representation of the environment from visual input. Previous research has focused primarily on enabling LLM-based task planning while adopting simple yet severely limited perception solutions to meet the needs for bench-top experiments but lack the critical flexibility to scale to less constrained settings. In this work, we propose an alternate perception approach -- a digital twin-based machine perception approach that capitalizes on the convincing performance and out-of-the-box generalization of recent vision foundation models. Integrating our digital twin-based scene representation and LLM agent for planning with the dVRK platform, we develop an embodied intelligence system and evaluate its robustness in performing peg transfer and gauze retrieval tasks. Our approach shows strong task performance and generalizability to varied environment settings. Despite convincing performance, this work is merely a first step towards the integration of digital twin-based scene representations. Future studies are necessary for the realization of a comprehensive digital twin framework to improve the interpretability and generalizability of embodied intelligence in surgery.

[Arxiv](https://arxiv.org/abs/2409.13107)