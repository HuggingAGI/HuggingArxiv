# 尼日利亚软件工程师与美国数据科学家，谁更受青睐？大语言模型在 GitHub 个人资料招聘中的偏见探究。

发布时间：2024年09月19日

`LLM应用` `软件工程` `人力资源`

> Nigerian Software Engineer or American Data Scientist? GitHub Profile Recruitment Bias in Large Language Models

# 摘要

> 大型语言模型（LLM）不仅在自动化日常任务上表现出色，还能在软件工程任务中展现一定水平。然而，其“黑箱”特性隐藏了内部机制，可能导致社会偏见。本文通过实证研究，探讨了 LLM 在为多元化的软件团队自动化招聘中的表现。我们利用 OpenAI 的 ChatGPT，分析了 2019 至 2023 年间来自四个地区的 3,657 份 GitHub 用户档案，旨在组建一个六人开发团队。研究发现，ChatGPT 对某些地区有偏好，甚至在交换档案位置信息后依然如此。此外，它更倾向于将特定角色分配给某些国家的开发者，显示出隐性偏见。这项研究不仅揭示了 LLM 的内部运作，也为减少其社会偏见提供了启示。

> Large Language Models (LLMs) have taken the world by storm, demonstrating their ability not only to automate tedious tasks, but also to show some degree of proficiency in completing software engineering tasks. A key concern with LLMs is their "black-box" nature, which obscures their internal workings and could lead to societal biases in their outputs. In the software engineering context, in this early results paper, we empirically explore how well LLMs can automate recruitment tasks for a geographically diverse software team. We use OpenAI's ChatGPT to conduct an initial set of experiments using GitHub User Profiles from four regions to recruit a six-person software development team, analyzing a total of 3,657 profiles over a five-year period (2019-2023). Results indicate that ChatGPT shows preference for some regions over others, even when swapping the location strings of two profiles (counterfactuals). Furthermore, ChatGPT was more likely to assign certain developer roles to users from a specific country, revealing an implicit bias. Overall, this study reveals insights into the inner workings of LLMs and has implications for mitigating such societal biases in these models.

[Arxiv](https://arxiv.org/abs/2409.12544)