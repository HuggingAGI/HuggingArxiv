# Text2Traj2Text：一种通过合成学习来描述人类运动轨迹的上下文框架

发布时间：2024年09月19日

`LLM应用`

> Text2Traj2Text: Learning-by-Synthesis Framework for Contextual Captioning of Human Movement Trajectories

# 摘要

> 本文推出 Text2Traj2Text，一个创新的合成学习框架，旨在解读零售店中顾客轨迹背后的情境。此框架将提升定向广告和库存管理等零售应用的客户理解。核心在于利用大型语言模型生成多样且真实的情境描述及相应轨迹。即使基于合成数据训练，模型仍能有效应用于真实顾客数据。系统评估显示，在 ROUGE 和 BERT Score 指标上，该框架优于其他方法。

> This paper presents Text2Traj2Text, a novel learning-by-synthesis framework for captioning possible contexts behind shopper's trajectory data in retail stores. Our work will impact various retail applications that need better customer understanding, such as targeted advertising and inventory management. The key idea is leveraging large language models to synthesize a diverse and realistic collection of contextual captions as well as the corresponding movement trajectories on a store map. Despite learned from fully synthesized data, the captioning model can generalize well to trajectories/captions created by real human subjects. Our systematic evaluation confirmed the effectiveness of the proposed framework over competitive approaches in terms of ROUGE and BERT Score metrics.

[Arxiv](https://arxiv.org/abs/2409.12670)