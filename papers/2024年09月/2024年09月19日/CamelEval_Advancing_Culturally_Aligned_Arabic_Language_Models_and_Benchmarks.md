# CamelEval：推动文化契合的阿拉伯语模型与基准发展

发布时间：2024年09月19日

`LLM应用` `人工智能` `语言技术`

> CamelEval: Advancing Culturally Aligned Arabic Language Models and Benchmarks

# 摘要

> 本文介绍了一款名为 Juhaina 的阿拉伯语-英语双语大型语言模型 (LLM)，该模型专为阿拉伯语使用者设计，旨在与其价值观和偏好保持一致。Juhaina 具备指令跟随、开放式问答、信息提供和文本处理等高级功能，拥有 92.4 亿参数，并在 8192 个标记的上下文窗口上进行训练。本文详细描述了 Juhaina 的开发过程，并进行了广泛的实证评估。同时，我们指出了现有 Open Arabic LLM Leaderboard (OALL) 的不足，并提出了新的评估基准 CamelEval。研究显示，Juhaina 在阿拉伯语响应生成、地区信息准确性及文化理解方面，均优于同类 LLM，如 Llama 和 Gemma 系列。我们期望 Juhaina 能普及先进 AI 技术，为 4 亿阿拉伯语使用者提供不仅语言相通，更文化相融的 LLM。所有模型已在 Huggingface 公开发布，访问地址为 \url{https://huggingface.co/elmrc}。

> Large Language Models (LLMs) are the cornerstones of modern artificial intelligence systems. This paper introduces Juhaina, a Arabic-English bilingual LLM specifically designed to align with the values and preferences of Arabic speakers. Juhaina inherently supports advanced functionalities such as instruction following, open-ended question answering, information provisioning, and text processing. Our model contains 9.24 billion parameters and is trained on a context window of up to 8,192 tokens. This paper details the creation process of Juhaina and provides an extensive empirical evaluation. Furthermore, we identify the limitations of widely-adopted Open Arabic LLM Leaderboard (OALL) and propose a new evaluation benchmark, CamelEval. Our findings demonstrate that Juhaina surpasses existing LLMs of comparable sizes, such as the Llama and Gemma families, in generating helpful responses in Arabic, providing factually accurate information about the region, and understanding nuanced cultural aspects. We aspire for Juhaina to democratize cutting-edge AI technologies, serving over 400 million Arabic speakers by offering LLMs that not only communicate in their language but also comprehend their culture. We publicly release all models on Huggingface \url{https://huggingface.co/elmrc}.

[Arxiv](https://arxiv.org/abs/2409.12623)