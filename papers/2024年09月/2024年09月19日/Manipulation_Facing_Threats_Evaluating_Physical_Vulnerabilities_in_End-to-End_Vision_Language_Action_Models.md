# 面对威胁的操作：评估端到端视觉语言动作模型中的物理脆弱性

发布时间：2024年09月19日

`Agent` `机器人`

> Manipulation Facing Threats: Evaluating Physical Vulnerabilities in End-to-End Vision Language Action Models

# 摘要

> 随着多模态大型语言模型 (MLLM) 的进步，视觉语言动作模型 (VLAM) 应运而生，旨在提升机器人操作任务在开放词汇场景中的表现。然而，操作任务涉及与物理世界的直接交互，确保任务执行中的鲁棒性和安全性至关重要。本文通过整合 MLLM 的安全研究与操作任务的实际应用，全面评估了 VLAM 在面对物理威胁时的表现。我们提出了物理脆弱性评估管道 (PVEP)，该管道涵盖了多种视觉模态的物理威胁，如分布外、基于排版的视觉提示和对抗性补丁攻击。通过对比攻击前后 VLAM 的性能变化，我们深入分析了 VLAM 对不同物理安全威胁的响应机制。

> Recently, driven by advancements in Multimodal Large Language Models (MLLMs), Vision Language Action Models (VLAMs) are being proposed to achieve better performance in open-vocabulary scenarios for robotic manipulation tasks. Since manipulation tasks involve direct interaction with the physical world, ensuring robustness and safety during the execution of this task is always a very critical issue. In this paper, by synthesizing current safety research on MLLMs and the specific application scenarios of the manipulation task in the physical world, we comprehensively evaluate VLAMs in the face of potential physical threats. Specifically, we propose the Physical Vulnerability Evaluating Pipeline (PVEP) that can incorporate as many visual modal physical threats as possible for evaluating the physical robustness of VLAMs. The physical threats in PVEP specifically include Out-of-Distribution, Typography-based Visual Prompt, and Adversarial Patch Attacks. By comparing the performance fluctuations of VLAMs before and after being attacked, we provide generalizable \textbf{\textit{Analyses}} of how VLAMs respond to different physical security threats.

[Arxiv](https://arxiv.org/abs/2409.13174)