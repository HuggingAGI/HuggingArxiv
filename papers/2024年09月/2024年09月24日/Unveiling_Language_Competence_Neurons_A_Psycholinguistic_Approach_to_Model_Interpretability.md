# 揭秘语言能力神经元：心理语言学视角下的模型可解释性研究

发布时间：2024年09月24日

`LLM理论` `心理语言学` `人工智能`

> Unveiling Language Competence Neurons: A Psycholinguistic Approach to Model Interpretability

# 摘要

> 随着 LLM 的语言能力不断提升，我们对其如何捕捉语言能力的理解仍面临挑战。本研究通过心理语言学范式，深入探索了 LLM 在声音-形状、声音-性别和隐含因果三个任务中的神经元级表现。研究发现，GPT-2-XL 在声音-形状任务上表现不佳，但在声音-性别和隐含因果任务上展现出人类般的能力。通过神经元消融和激活操纵，我们发现 GPT-2-XL 的语言能力与其特定神经元的存在密切相关。这项研究首次在神经元层面利用心理语言学实验，为 LLM 的解释性和内部机制提供了新的视角。

> As large language models (LLMs) become advance in their linguistic capacity, understanding how they capture aspects of language competence remains a significant challenge. This study therefore employs psycholinguistic paradigms, which are well-suited for probing deeper cognitive aspects of language processing, to explore neuron-level representations in language model across three tasks: sound-shape association, sound-gender association, and implicit causality. Our findings indicate that while GPT-2-XL struggles with the sound-shape task, it demonstrates human-like abilities in both sound-gender association and implicit causality. Targeted neuron ablation and activation manipulation reveal a crucial relationship: when GPT-2-XL displays a linguistic ability, specific neurons correspond to that competence; conversely, the absence of such an ability indicates a lack of specialized neurons. This study is the first to utilize psycholinguistic experiments to investigate deep language competence at the neuron level, providing a new level of granularity in model interpretability and insights into the internal mechanisms driving language ability in transformer based LLMs.

[Arxiv](https://arxiv.org/abs/2409.15827)