# LLM 回声室：定制化与自动化的虚假信息传播

发布时间：2024年09月24日

`LLM应用` `社交媒体` `信息安全`

> LLM Echo Chamber: personalized and automated disinformation

# 摘要

> 近期，GPT4和Llama2等大型语言模型在总结、翻译和内容审查等任务中表现出色。然而，其广泛应用也引发了担忧，尤其是它们可能大规模传播具有说服力的错误信息，进而影响公众意见。本研究聚焦于LLMs传播错误信息的风险，构建了一个模拟社交媒体聊天室的数字环境——LLM回声室，以研究错误信息的传播。通过分析恶意机器人在此环境中的行为，我们能更深入地理解这一现象。我们回顾了现有LLMs，探讨了错误信息风险，并采用了最新的微调技术。利用微软的phi2模型，结合自定义数据集进行微调，我们生成了有害内容以构建回声室。经GPT4评估其说服力和有害性后，揭示了LLMs的伦理问题，并强调了加强防护措施以对抗错误信息的必要性。

> Recent advancements have showcased the capabilities of Large Language Models like GPT4 and Llama2 in tasks such as summarization, translation, and content review. However, their widespread use raises concerns, particularly around the potential for LLMs to spread persuasive, humanlike misinformation at scale, which could significantly influence public opinion. This study examines these risks, focusing on LLMs ability to propagate misinformation as factual. To investigate this, we built the LLM Echo Chamber, a controlled digital environment simulating social media chatrooms, where misinformation often spreads. Echo chambers, where individuals only interact with like minded people, further entrench beliefs. By studying malicious bots spreading misinformation in this environment, we can better understand this phenomenon. We reviewed current LLMs, explored misinformation risks, and applied sota finetuning techniques. Using Microsoft phi2 model, finetuned with our custom dataset, we generated harmful content to create the Echo Chamber. This setup, evaluated by GPT4 for persuasiveness and harmfulness, sheds light on the ethical concerns surrounding LLMs and emphasizes the need for stronger safeguards against misinformation.

[Arxiv](https://arxiv.org/abs/2409.16241)