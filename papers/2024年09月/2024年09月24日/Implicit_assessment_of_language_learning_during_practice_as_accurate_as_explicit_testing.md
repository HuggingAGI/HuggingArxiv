# 练习中的隐性语言学习评估与显性测试同样精准

发布时间：2024年09月24日

`LLM应用` `语言学习`

> Implicit assessment of language learning during practice as accurate as explicit testing

# 摘要

> 在智能辅导系统中，评估学习者的熟练程度至关重要。我们利用项目反应理论（IRT）在计算机辅助语言学习中，分别在测试和练习环节评估学生的能力。虽然全面测试能详尽展现熟练度，但出于多种原因可能并不理想。因此，我们首先尝试用高效且准确的适应性测试替代全面测试。通过在不完美条件下收集的全面测试数据，我们训练了 IRT 模型以指导适应性测试，模拟和实验结果证实了其高效性和准确性。其次，我们探索是否能直接从练习中准确估算学习者的能力，而无需测试。我们将练习数据转换为适合 IRT 建模的形式，通过将练习与语言构造关联，这些构造在 IRT 中被视为“项目”。大规模研究结果显示，使用教师评估作为基准，IRT 模型能基于练习数据提供准确的能力估算。

> Assessment of proficiency of the learner is an essential part of Intelligent Tutoring Systems (ITS). We use Item Response Theory (IRT) in computer-aided language learning for assessment of student ability in two contexts: in test sessions, and in exercises during practice sessions. Exhaustive testing across a wide range of skills can provide a detailed picture of proficiency, but may be undesirable for a number of reasons. Therefore, we first aim to replace exhaustive tests with efficient but accurate adaptive tests. We use learner data collected from exhaustive tests under imperfect conditions, to train an IRT model to guide adaptive tests. Simulations and experiments with real learner data confirm that this approach is efficient and accurate. Second, we explore whether we can accurately estimate learner ability directly from the context of practice with exercises, without testing. We transform learner data collected from exercise sessions into a form that can be used for IRT modeling. This is done by linking the exercises to {\em linguistic constructs}; the constructs are then treated as "items" within IRT. We present results from large-scale studies with thousands of learners. Using teacher assessments of student ability as "ground truth," we compare the estimates obtained from tests vs. those from exercises. The experiments confirm that the IRT models can produce accurate ability estimation based on exercises.

[Arxiv](https://arxiv.org/abs/2409.16133)