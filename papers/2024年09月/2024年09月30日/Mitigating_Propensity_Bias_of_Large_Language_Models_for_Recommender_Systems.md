# 缓解大型语言模型在推荐系统中的倾向性偏差

发布时间：2024年09月30日

`LLM应用` `推荐系统` `人工智能`

> Mitigating Propensity Bias of Large Language Models for Recommender Systems

# 摘要

> LLM 的迅猛发展为推荐系统开辟了新天地，尤其是通过利用这些模型生成的侧面信息（如项目描述和分析）。然而，将这些信息与历史交互数据对齐却充满挑战。LLM 的内在偏见可能导致推荐失真，用户体验不公。此外，倾向性偏差使得侧面信息倾向于在低维空间中表示所有输入，引发维度崩溃，严重制约了推荐系统捕捉用户偏好和行为的能力。为此，我们提出了反事实 LLM 推荐 (CLLMR) 框架。该框架通过基于光谱的侧面信息编码器，巧妙地将历史交互的结构信息融入侧面信息，避免了维度崩溃。同时，CLLMR 深入挖掘 LLM 推荐系统中的因果关系，利用反事实推理抵消偏见。实验证明，CLLMR 显著提升了推荐模型的性能。

> The rapid development of Large Language Models (LLMs) creates new opportunities for recommender systems, especially by exploiting the side information (e.g., descriptions and analyses of items) generated by these models. However, aligning this side information with collaborative information from historical interactions poses significant challenges. The inherent biases within LLMs can skew recommendations, resulting in distorted and potentially unfair user experiences. On the other hand, propensity bias causes side information to be aligned in such a way that it often tends to represent all inputs in a low-dimensional subspace, leading to a phenomenon known as dimensional collapse, which severely restricts the recommender system's ability to capture user preferences and behaviours. To address these issues, we introduce a novel framework named Counterfactual LLM Recommendation (CLLMR). Specifically, we propose a spectrum-based side information encoder that implicitly embeds structural information from historical interactions into the side information representation, thereby circumventing the risk of dimension collapse. Furthermore, our CLLMR approach explores the causal relationships inherent in LLM-based recommender systems. By leveraging counterfactual inference, we counteract the biases introduced by LLMs. Extensive experiments demonstrate that our CLLMR approach consistently enhances the performance of various recommender models.

[Arxiv](https://arxiv.org/abs/2409.20052)