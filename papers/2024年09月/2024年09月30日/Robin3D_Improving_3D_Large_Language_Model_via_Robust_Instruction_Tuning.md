# Robin3D：通过强化指令调优提升 3D 大型语言模型的性能

发布时间：2024年09月30日

`Agent` `人工智能` `机器人`

> Robin3D: Improving 3D Large Language Model via Robust Instruction Tuning

# 摘要

> 3D大型语言模型（3DLLM）在构建3D世界通用代理方面展现出巨大潜力，但高质量指令数据的缺乏限制了其辨别与泛化能力。本文推出的Robin3D，通过我们创新的鲁棒指令生成引擎（RIG），训练于百万级指令数据，包括增强辨别力的对抗性数据和提升泛化性的多样性数据。为应对复杂指令，Robin3D融合关系增强投影器提升空间理解，并通过ID-特征绑定强化对象定位。在五大3D多模态基准测试中，Robin3D无需微调即超越以往方法，尤其在定位与描述任务中分别提升7.8%和6.9%。

> Recent advancements in 3D Large Language Models (3DLLMs) have highlighted their potential in building general-purpose agents in the 3D real world, yet challenges remain due to the lack of high-quality robust instruction-following data, leading to limited discriminative power and generalization of 3DLLMs. In this paper, we introduce Robin3D, a powerful 3DLLM trained on large-scale instruction-following data generated by our novel data engine, Robust Instruction Generation (RIG) engine. RIG generates two key instruction data: 1) the Adversarial Instruction-following data, which features mixed negative and positive samples to enhance the model's discriminative understanding. 2) the Diverse Instruction-following data, which contains various instruction styles to enhance model's generalization. As a result, we construct 1 million instruction-following data, consisting of 344K Adversarial samples, 508K Diverse samples, and 165K benchmark training set samples. To better handle these complex instructions, Robin3D first incorporates Relation-Augmented Projector to enhance spatial understanding, and then strengthens the object referring and grounding ability through ID-Feature Bonding. Robin3D consistently outperforms previous methods across five widely-used 3D multimodal learning benchmarks, without the need for task-specific fine-tuning. Notably, we achieve a 7.8\% improvement in the grounding task (Multi3DRefer) and a 6.9\% improvement in the captioning task (Scan2Cap).

[Arxiv](https://arxiv.org/abs/2410.00255)