# 大型语言模型能否替代 Neil deGrasse Tyson？探讨其在科学传播中的可靠性。

发布时间：2024年09月21日

`LLM应用` `科学传播` `人工智能`

> Can LLMs replace Neil deGrasse Tyson? Evaluating the Reliability of LLMs as Science Communicators

# 摘要

> 大型语言模型（LLMs）及其驱动的 AI 助手在专业和业余用户中的使用量正飞速增长。我们专注于评估这些模型作为科学传播者的可靠性，不同于现有基准，我们强调在需要细致理解和答案意识的科学问答任务上进行评估。我们推出了新数据集 SCiPS-QA，包含 742 个嵌入复杂科学概念的是/否问题，并设计了评估 LLMs 正确性和一致性的基准套件。我们测试了 OpenAI GPT 家族的三个专有模型和 Meta Llama-2、Llama-3 及 Mistral 家族的 13 个开放模型。尽管多数开放模型表现不如 GPT-4 Turbo，但 Llama-3-70B 表现出色，常在多方面超越 GPT-4 Turbo。我们还发现，即使是 GPT 模型在验证响应可靠性方面也存在不足，且人类评估者易被 GPT-4 Turbo 的错误响应误导。

> Large Language Models (LLMs) and AI assistants driven by these models are experiencing exponential growth in usage among both expert and amateur users. In this work, we focus on evaluating the reliability of current LLMs as science communicators. Unlike existing benchmarks, our approach emphasizes assessing these models on scientific questionanswering tasks that require a nuanced understanding and awareness of answerability. We introduce a novel dataset, SCiPS-QA, comprising 742 Yes/No queries embedded in complex scientific concepts, along with a benchmarking suite that evaluates LLMs for correctness and consistency across various criteria. We benchmark three proprietary LLMs from the OpenAI GPT family and 13 open-access LLMs from the Meta Llama-2, Llama-3, and Mistral families. While most open-access models significantly underperform compared to GPT-4 Turbo, our experiments identify Llama-3-70B as a strong competitor, often surpassing GPT-4 Turbo in various evaluation aspects. We also find that even the GPT models exhibit a general incompetence in reliably verifying LLM responses. Moreover, we observe an alarming trend where human evaluators are deceived by incorrect responses from GPT-4 Turbo.

[Arxiv](https://arxiv.org/abs/2409.14037)