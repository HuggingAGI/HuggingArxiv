# 人机协作风险标注：携手 CHAIRA 共同识别网络不文明现象

发布时间：2024年09月21日

`LLM应用` `社交媒体` `人工智能`

> Collaborative Human-AI Risk Annotation: Co-Annotating Online Incivility with CHAIRA

# 摘要

> 协同人机标注在大规模复杂数据任务中展现出巨大潜力。本文介绍的 CHAIRA 工具，通过结合大型语言模型 (LLM) 和四种提示策略，实现了人机协作在线标注不文明行为。在 457 条评论的测试中，CHAIRA 在人机一致性上表现出色，甚至能捕捉到人类编码者忽略的微妙不文明行为。研究不仅揭示了 AI 在标注中的优势与挑战，还为人机协作标注提供了宝贵的设计建议和实践指南。

> Collaborative human-AI annotation is a promising approach for various tasks with large-scale and complex data. Tools and methods to support effective human-AI collaboration for data annotation are an important direction for research. In this paper, we present CHAIRA: a Collaborative Human-AI Risk Annotation tool that enables human and AI agents to collaboratively annotate online incivility. We leveraged Large Language Models (LLMs) to facilitate the interaction between human and AI annotators and examine four different prompting strategies. The developed CHAIRA system combines multiple prompting approaches with human-AI collaboration for online incivility data annotation. We evaluated CHAIRA on 457 user comments with ground truth labels based on the inter-rater agreement between human and AI coders. We found that the most collaborative prompt supported a high level of agreement between a human agent and AI, comparable to that of two human coders. While the AI missed some implicit incivility that human coders easily identified, it also spotted politically nuanced incivility that human coders overlooked. Our study reveals the benefits and challenges of using AI agents for incivility annotation and provides design implications and best practices for human-AI collaboration in subjective data annotation.

[Arxiv](https://arxiv.org/abs/2409.14223)