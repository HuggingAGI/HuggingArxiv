# 利用反事实 LLM 推理提升强化学习的安全性

发布时间：2024年09月16日

`Agent` `人工智能`

> Enhancing RL Safety with Counterfactual LLM Reasoning

# 摘要

> 强化学习策略可能存在不安全行为且难以解释。我们通过反事实大型语言模型推理，在训练后提升 RL 策略的安全性。实验表明，这种方法不仅提高了安全性，还增强了策略的可解释性。

> Reinforcement learning (RL) policies may exhibit unsafe behavior and are hard to explain. We use counterfactual large language model reasoning to enhance RL policy safety post-training. We show that our approach improves and helps to explain the RL policy safety.

[Arxiv](https://arxiv.org/abs/2409.10188)