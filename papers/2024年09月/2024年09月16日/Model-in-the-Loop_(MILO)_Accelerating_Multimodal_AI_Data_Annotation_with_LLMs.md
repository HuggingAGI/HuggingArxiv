# MILO：借助 LLM 加速多模态 AI 数据标注

发布时间：2024年09月16日

`LLM应用` `人工智能` `数据标注`

> Model-in-the-Loop (MILO): Accelerating Multimodal AI Data Annotation with LLMs

# 摘要

> 随着AI训练数据需求的激增，数据标注已成为全球产业。然而，传统的人工标注方法既耗时又费力，且质量参差不齐。为此，我们推出了Model-in-the-Loop (MILO)框架，将AI/ML模型融入标注流程。MILO结合了专业标注者的精准与大型语言模型(LLM)的智能，通过LLM的预标注和实时辅助，以及对标注结果的智能评判，实现了人机高效互动。三项多模态数据标注实验证明，MILO不仅缩短了处理时间，还提升了数据质量，优化了标注体验。此外，我们还制定了灵活的质量评估标准，为开放式标注提供细致反馈。MILO的推出，有望加速AI/ML的发展，减少对人工标注的依赖，并促进人机价值观的和谐共融。

> The growing demand for AI training data has transformed data annotation into a global industry, but traditional approaches relying on human annotators are often time-consuming, labor-intensive, and prone to inconsistent quality. We propose the Model-in-the-Loop (MILO) framework, which integrates AI/ML models into the annotation process. Our research introduces a collaborative paradigm that leverages the strengths of both professional human annotators and large language models (LLMs). By employing LLMs as pre-annotation and real-time assistants, and judges on annotator responses, MILO enables effective interaction patterns between human annotators and LLMs. Three empirical studies on multimodal data annotation demonstrate MILO's efficacy in reducing handling time, improving data quality, and enhancing annotator experiences. We also introduce quality rubrics for flexible evaluation and fine-grained feedback on open-ended annotations. The MILO framework has implications for accelerating AI/ML development, reducing reliance on human annotation alone, and promoting better alignment between human and machine values.

[Arxiv](https://arxiv.org/abs/2409.10702)