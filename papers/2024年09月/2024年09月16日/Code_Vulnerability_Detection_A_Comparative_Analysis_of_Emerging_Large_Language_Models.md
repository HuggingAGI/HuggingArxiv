# 代码漏洞检测：探索新兴大型语言模型的性能对比

发布时间：2024年09月16日

`LLM应用` `软件开发` `网络安全`

> Code Vulnerability Detection: A Comparative Analysis of Emerging Large Language Models

# 摘要

> 随着对开源项目的依赖增加，软件开发中的漏洞问题日益严重，引发了广泛关注。本文探讨了 LLM 在代码漏洞检测中的应用，特别关注了 LLM 技术的最新进展。通过对比分析，我们评估了 Llama、CodeLlama、Gemma 和 CodeGemma 等新兴 LLM 的性能，并与 BERT、RoBERTa 和 GPT-3 等成熟模型进行了比较。研究旨在揭示 LLM 在漏洞检测中的潜力，助力提升开源软件的安全性。结果显示，CodeGemma 在检测软件漏洞方面表现出色，F1 分数高达 58%，召回率达到 87%。

> The growing trend of vulnerability issues in software development as a result of a large dependence on open-source projects has received considerable attention recently. This paper investigates the effectiveness of Large Language Models (LLMs) in identifying vulnerabilities within codebases, with a focus on the latest advancements in LLM technology. Through a comparative analysis, we assess the performance of emerging LLMs, specifically Llama, CodeLlama, Gemma, and CodeGemma, alongside established state-of-the-art models such as BERT, RoBERTa, and GPT-3. Our study aims to shed light on the capabilities of LLMs in vulnerability detection, contributing to the enhancement of software security practices across diverse open-source repositories. We observe that CodeGemma achieves the highest F1-score of 58\ and a Recall of 87\, amongst the recent additions of large language models to detect software security vulnerabilities.

[Arxiv](https://arxiv.org/abs/2409.10490)