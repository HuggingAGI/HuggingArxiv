# 薛定谔的记忆：探索大型语言模型

发布时间：2024年09月16日

`LLM理论` `人工智能` `认知科学`

> Schrodinger's Memory: Large Language Models

# 摘要

> 记忆是 LLM 的基石，但过往研究对其记忆机制的探讨尚浅。本文运用 UAT 理论解析 LLM 的记忆原理，并提出一种通过对比不同模型记忆容量来评估性能的新方法。经过大量实验验证，我们不仅证实了理论，还展示了 LLM 的记忆实力。最后，我们对比了人脑与 LLM 的工作机制，揭示了它们的异同。

> Memory is the foundation of LLMs' functionality, yet past research has lacked an in-depth exploration of their memory capabilities and underlying theory. In this paper, we apply UAT theory to explain the memory mechanism of LLMs and propose a new approach for evaluating LLM performance by comparing the memory capacities of different models. Through extensive experiments, we validate our theory and the memory abilities of LLMs. Finally, we compare the capabilities of the human brain and LLMs, highlighting both their similarities and differences in terms of working mechanisms.

[Arxiv](https://arxiv.org/abs/2409.10482)