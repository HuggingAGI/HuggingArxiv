# IRIS：专为 3D 功能分析设计的交互式智能分割系统

发布时间：2024年09月16日

`Agent` `机器人` `人机交互`

> IRIS: Interactive Responsive Intelligent Segmentation for 3D Affordance Analysis

# 摘要

> 近期，大规模语言和视觉-语言模型的进步大幅提升了多模态理解能力，但将高级语言指令转化为3D空间中的精确机器人动作仍是一大挑战。为此，本文推出了IRIS（交互式响应智能分割），一个无需训练的多模态系统，专用于3D可供性分割，并附带一个评估日常环境中交互式语言引导可供性的基准。IRIS巧妙结合了大型多模态模型与3D视觉网络，实现了2D与3D视觉及语言理解的完美融合。我们还提供了一个包含10个典型室内环境的数据集，每环境50张图像标注了对象动作与3D可供性分割，以支持评估。实验表明，IRIS在处理多样化的交互式3D可供性分割任务中表现出色，各项指标均具竞争力。这不仅展示了IRIS在复杂室内环境中基于可供性理解提升人机交互的潜力，也推动了更直观、高效的机器人系统在实际应用中的发展。

> Recent advancements in large language and vision-language models have significantly enhanced multimodal understanding, yet translating high-level linguistic instructions into precise robotic actions in 3D space remains challenging. This paper introduces IRIS (Interactive Responsive Intelligent Segmentation), a novel training-free multimodal system for 3D affordance segmentation, alongside a benchmark for evaluating interactive language-guided affordance in everyday environments. IRIS integrates a large multimodal model with a specialized 3D vision network, enabling seamless fusion of 2D and 3D visual understanding with language comprehension. To facilitate evaluation, we present a dataset of 10 typical indoor environments, each with 50 images annotated for object actions and 3D affordance segmentation. Extensive experiments demonstrate IRIS's capability in handling interactive 3D affordance segmentation tasks across diverse settings, showcasing competitive performance across various metrics. Our results highlight IRIS's potential for enhancing human-robot interaction based on affordance understanding in complex indoor environments, advancing the development of more intuitive and efficient robotic systems for real-world applications.

[Arxiv](https://arxiv.org/abs/2409.10078)