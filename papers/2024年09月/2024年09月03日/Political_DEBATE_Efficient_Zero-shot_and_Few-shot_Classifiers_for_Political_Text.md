# 政治文本分类新视角：高效零-shot 与少-shot 分类器

发布时间：2024年09月03日

`LLM应用` `社会科学`

> Political DEBATE: Efficient Zero-shot and Few-shot Classifiers for Political Text

# 摘要

> 社会科学家因大型语言模型无需监督训练即可注释文档的能力（即零-shot学习）而迅速采纳它们。然而，这些模型的计算需求、成本及专有性质常与复制和开放科学标准相悖。本文推出的Political DEBATE模型，专为政治文档的零-shot和少-shot分类设计，不仅性能卓越，且效率更高，完全开源。通过简单随机样本训练，这些模型便能超越传统监督分类器及复杂提示的先进生成模型。同时，我们公开了PolNLI数据集，内含超200,000份政治文档，覆盖800余分类任务，标签准确度极高。

> Social scientists quickly adopted large language models due to their ability to annotate documents without supervised training, an ability known as zero-shot learning. However, due to their compute demands, cost, and often proprietary nature, these models are often at odds with replication and open science standards. This paper introduces the Political DEBATE (DeBERTa Algorithm for Textual Entailment) language models for zero-shot and few-shot classification of political documents. These models are not only as good, or better than, state-of-the art large language models at zero and few-shot classification, but are orders of magnitude more efficient and completely open source. By training the models on a simple random sample of 10-25 documents, they can outperform supervised classifiers trained on hundreds or thousands of documents and state-of-the-art generative models with complex, engineered prompts. Additionally, we release the PolNLI dataset used to train these models -- a corpus of over 200,000 political documents with highly accurate labels across over 800 classification tasks.

[Arxiv](https://arxiv.org/abs/2409.02078)