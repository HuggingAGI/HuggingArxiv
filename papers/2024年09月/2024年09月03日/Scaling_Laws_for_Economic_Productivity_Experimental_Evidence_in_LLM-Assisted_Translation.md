# 经济生产力的规模法则：基于LLM辅助翻译的实验研究

发布时间：2024年09月03日

`LLM理论` `翻译行业`

> Scaling Laws for Economic Productivity: Experimental Evidence in LLM-Assisted Translation

# 摘要

> 本文揭示了大型语言模型（LLM）训练计算量与经济效益间的“规模法则”。实验中，300名专业翻译使用13种不同计算量的LLM完成任务。结果表明，模型规模每扩大10倍，翻译效率提升12.3%，评分提高0.18个标准差，收入增加16.1%。尤其对技能较低的工人，模型规模扩大使任务完成速度提升4倍。这预示着，当前每年模型规模预计增长4倍的趋势，将对经济产生深远影响。

> This paper derives 'scaling laws' -- empirical relationships between the amount of training compute used for a Large Language Model (LLM) and its performance -- for economic outcomes. In a preregistered experiment, 300 professional translators completed 1800 tasks with access to one of thirteen LLMs with differing model training compute sizes (or a control). Our results show that model scaling substantially raises productivity: for every 10x increase in model compute, translators completed tasks 12.3% quicker, received 0.18 s.d. higher grades, and earned 16.1% more per minute (including bonus payments). Further, the gains from model scaling are much higher for lower-skilled workers who gain a 4x larger improvement in task completion speed. These results imply further frontier model scaling -- which is currently estimated at 4x increase per year -- may have significant economic implications.

[Arxiv](https://arxiv.org/abs/2409.02391)