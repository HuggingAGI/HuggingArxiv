# 打造领域专属的大型语言模型：微调在模拟公众意见中的核心地位

发布时间：2024年09月28日

`LLM应用` `环境政策` `社会科学`

> Designing Domain-Specific Large Language Models: The Critical Role of Fine-Tuning in Public Opinion Simulation

# 摘要

> LLM 在 NLP 领域的广泛应用虽已显著，但在特定领域如环境政策意见模拟中，其通用性却成了瓶颈。本文通过利用英国住户纵向研究数据，提出了一种微调 LLM 的方法，通过结合年龄、收入、教育及地区等社会人口因素，显著提升了意见生成的精准度。微调后的模型能更细腻地捕捉不同群体间的差异，超越了预训练模型的表现。卡方、余弦相似度、Jaccard 指数及 KL 散度等指标均显示，合成意见与真实数据高度吻合。此方法不仅展示了微调 LLM 在环境议题上提供更深入、更具代表性及伦理考量的公众情感分析的潜力，更强调了为特定社会环境量身定制 LLM 的重要性，以实现更精准且合乎伦理的政策模拟。

> Large language models (LLMs) have transformed natural language processing across diverse fields, yet their general-purpose design limits their effectiveness in specialized domains, such as simulating opinions on environmental policies. This paper presents an approach for fine-tuning LLMs using data from the UK Household Longitudinal Study, improving the accuracy of opinion generation by conditioning models on socio-demographic factors like age, income, education, and region. By emulating diverse synthetic profiles, fine-tuned models capture the subtle differences across demographic groups more effectively than pre-trained versions. Metrics such as Chi-Squared, Cosine Similarity, Jaccard Index, and KL-divergence, demonstrate a strong alignment between synthetic and real-world opinion data. This approach highlights the potential of fine-tuning LLMs to provide more informed, representative, and ethical insights into public sentiments on environmental issues. The findings underscore the importance of tailoring LLMs to specific societal contexts for more accurate and ethical policy simulations.

[Arxiv](https://arxiv.org/abs/2409.19308)