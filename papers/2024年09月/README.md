# 2024年09月

2024年09月26日

- [AI Delegates with a Dual Focus: Ensuring Privacy and Strategic Self-Disclosure](2024年09月26日/AI_Delegates_with_a_Dual_Focus_Ensuring_Privacy_and_Strategic_Self-Disclosure.md)

    - [翻译: AI 代表的双重使命：保护隐私与策略性自我披露](2024年09月26日/AI_Delegates_with_a_Dual_Focus_Ensuring_Privacy_and_Strategic_Self-Disclosure.md)

- [A Multimodal Single-Branch Embedding Network for Recommendation in Cold-Start and Missing Modality Scenarios](2024年09月26日/A_Multimodal_Single-Branch_Embedding_Network_for_Recommendation_in_Cold-Start_and_Missing_Modality_Scenarios.md)

    - [翻译: 本文提出了一种单分支嵌入多模态网络，专为冷启动和模态缺失场景下的推荐任务设计。](2024年09月26日/A_Multimodal_Single-Branch_Embedding_Network_for_Recommendation_in_Cold-Start_and_Missing_Modality_Scenarios.md)

- [An Adversarial Perspective on Machine Unlearning for AI Safety](2024年09月26日/An_Adversarial_Perspective_on_Machine_Unlearning_for_AI_Safety.md)

    - [翻译: 从对抗视角探讨机器遗忘在 AI 安全中的应用](2024年09月26日/An_Adversarial_Perspective_on_Machine_Unlearning_for_AI_Safety.md)

- [AssistantX: An LLM-Powered Proactive Assistant in Collaborative Human-Populated Environment](2024年09月26日/AssistantX_An_LLM-Powered_Proactive_Assistant_in_Collaborative_Human-Populated_Environment.md)

    - [翻译: AssistantX：一款由 LLM 驱动、在协作环境中主动协助人类的智能助手](2024年09月26日/AssistantX_An_LLM-Powered_Proactive_Assistant_in_Collaborative_Human-Populated_Environment.md)

- [BEATS: Optimizing LLM Mathematical Capabilities with BackVerify and Adaptive Disambiguate based Efficient Tree Search](2024年09月26日/BEATS_Optimizing_LLM_Mathematical_Capabilities_with_BackVerify_and_Adaptive_Disambiguate_based_Efficient_Tree_Search.md)

    - [翻译: BEATS：利用 BackVerify 和 Adaptive Disambiguate 的高效树搜索，提升 LLM 的数学能力](2024年09月26日/BEATS_Optimizing_LLM_Mathematical_Capabilities_with_BackVerify_and_Adaptive_Disambiguate_based_Efficient_Tree_Search.md)

- [Compositional Hardness of Code in Large Language Models -- A Probabilistic Perspective](2024年09月26日/Compositional_Hardness_of_Code_in_Large_Language_Models_--_A_Probabilistic_Perspective.md)

    - [翻译: 大型语言模型中的代码组合难题——从概率角度解析](2024年09月26日/Compositional_Hardness_of_Code_in_Large_Language_Models_--_A_Probabilistic_Perspective.md)

- [Control Industrial Automation System with Large Language Models](2024年09月26日/Control_Industrial_Automation_System_with_Large_Language_Models.md)

    - [翻译: 利用大型语言模型驾驭工业自动化系统](2024年09月26日/Control_Industrial_Automation_System_with_Large_Language_Models.md)

- [DualAD: Dual-Layer Planning for Reasoning in Autonomous Driving](2024年09月26日/DualAD_Dual-Layer_Planning_for_Reasoning_in_Autonomous_Driving.md)

    - [翻译: DualAD：双层规划助力自动驾驶推理](2024年09月26日/DualAD_Dual-Layer_Planning_for_Reasoning_in_Autonomous_Driving.md)

- [EAGLE: Egocentric AGgregated Language-video Engine](2024年09月26日/EAGLE_Egocentric_AGgregated_Language-video_Engine.md)

    - [翻译: EAGLE：一款以自我为中心的语言与视频聚合引擎](2024年09月26日/EAGLE_Egocentric_AGgregated_Language-video_Engine.md)

- [EgoLM: Multi-Modal Language Model of Egocentric Motions](2024年09月26日/EgoLM_Multi-Modal_Language_Model_of_Egocentric_Motions.md)

    - [翻译: EgoLM：探索以自我为中心运动的多模态语言模型](2024年09月26日/EgoLM_Multi-Modal_Language_Model_of_Egocentric_Motions.md)

- [EMMA-500: Enhancing Massively Multilingual Adaptation of Large Language Models](2024年09月26日/EMMA-500_Enhancing_Massively_Multilingual_Adaptation_of_Large_Language_Models.md)

    - [翻译: EMMA-500：提升大型语言模型在海量多语言环境中的适应能力](2024年09月26日/EMMA-500_Enhancing_Massively_Multilingual_Adaptation_of_Large_Language_Models.md)

- [Episodic Memory Verbalization using Hierarchical Representations of Life-Long Robot Experience](2024年09月26日/Episodic_Memory_Verbalization_using_Hierarchical_Representations_of_Life-Long_Robot_Experience.md)

    - [翻译: 利用机器人终身经验的层次结构，实现情景记忆的言语表达](2024年09月26日/Episodic_Memory_Verbalization_using_Hierarchical_Representations_of_Life-Long_Robot_Experience.md)

- [Extracting Affect Aggregates from Longitudinal Social Media Data with Temporal Adapters for Large Language Models](2024年09月26日/Extracting_Affect_Aggregates_from_Longitudinal_Social_Media_Data_with_Temporal_Adapters_for_Large_Language_Models.md)

    - [翻译: 利用时间适配器从长期社交媒体数据中提取情感聚合，应用于大型语言模型](2024年09月26日/Extracting_Affect_Aggregates_from_Longitudinal_Social_Media_Data_with_Temporal_Adapters_for_Large_Language_Models.md)

- [Few-shot Pairwise Rank Prompting: An Effective Non-Parametric Retrieval Model](2024年09月26日/Few-shot_Pairwise_Rank_Prompting_An_Effective_Non-Parametric_Retrieval_Model.md)

    - [翻译: 少样本成对排序提示：一种高效的非参数检索模型](2024年09月26日/Few-shot_Pairwise_Rank_Prompting_An_Effective_Non-Parametric_Retrieval_Model.md)

- [Graph Reasoning with Large Language Models via Pseudo-code Prompting](2024年09月26日/Graph_Reasoning_with_Large_Language_Models_via_Pseudo-code_Prompting.md)

    - [翻译: 利用伪代码提示实现大型语言模型的图推理](2024年09月26日/Graph_Reasoning_with_Large_Language_Models_via_Pseudo-code_Prompting.md)

- [GSON: A Group-based Social Navigation Framework with Large Multimodal Model](2024年09月26日/GSON_A_Group-based_Social_Navigation_Framework_with_Large_Multimodal_Model.md)

    - [翻译: GSON：结合大型多模态模型的群体社交导航框架](2024年09月26日/GSON_A_Group-based_Social_Navigation_Framework_with_Large_Multimodal_Model.md)

- [Infering Alt-text For UI Icons With Large Language Models During App Development](2024年09月26日/Infering_Alt-text_For_UI_Icons_With_Large_Language_Models_During_App_Development.md)

    - [翻译: 在应用开发中，借助大型语言模型为 UI 图标生成替代文本](2024年09月26日/Infering_Alt-text_For_UI_Icons_With_Large_Language_Models_During_App_Development.md)

- [Integrating Hierarchical Semantic into Iterative Generation Model for Entailment Tree Explanation](2024年09月26日/Integrating_Hierarchical_Semantic_into_Iterative_Generation_Model_for_Entailment_Tree_Explanation.md)

    - [翻译: 融合分层语义至迭代生成模型，解析蕴涵树的奥秘](2024年09月26日/Integrating_Hierarchical_Semantic_into_Iterative_Generation_Model_for_Entailment_Tree_Explanation.md)

- [Language Models as Zero-shot Lossless Gradient Compressors: Towards General Neural Parameter Prior Models](2024年09月26日/Language_Models_as_Zero-shot_Lossless_Gradient_Compressors_Towards_General_Neural_Parameter_Prior_Models.md)

    - [翻译: 语言模型：零-shot 无损梯度压缩器，引领通用神经参数先验模型的发展](2024年09月26日/Language_Models_as_Zero-shot_Lossless_Gradient_Compressors_Towards_General_Neural_Parameter_Prior_Models.md)

- [LLaVA-3D: A Simple yet Effective Pathway to Empowering LMMs with 3D-awareness](2024年09月26日/LLaVA-3D_A_Simple_yet_Effective_Pathway_to_Empowering_LMMs_with_3D-awareness.md)

    - [翻译: LLaVA-3D：为大型多模态模型赋予3D感知能力的简易而高效之道](2024年09月26日/LLaVA-3D_A_Simple_yet_Effective_Pathway_to_Empowering_LMMs_with_3D-awareness.md)

- [LLM4Brain: Training a Large Language Model for Brain Video Understanding](2024年09月26日/LLM4Brain_Training_a_Large_Language_Model_for_Brain_Video_Understanding.md)

    - [翻译: LLM4Brain：打造专为脑视频理解而生的大型语言模型](2024年09月26日/LLM4Brain_Training_a_Large_Language_Model_for_Brain_Video_Understanding.md)

- [MIO: A Foundation Model on Multimodal Tokens](2024年09月26日/MIO_A_Foundation_Model_on_Multimodal_Tokens.md)

    - [翻译: MIO：多模态令牌的基础模型](2024年09月26日/MIO_A_Foundation_Model_on_Multimodal_Tokens.md)

- [MoJE: Mixture of Jailbreak Experts, Naive Tabular Classifiers as Guard for Prompt Attacks](2024年09月26日/MoJE_Mixture_of_Jailbreak_Experts,_Naive_Tabular_Classifiers_as_Guard_for_Prompt_Attacks.md)

    - [翻译: MoJE：混合越狱专家，以朴素表格分类器守护提示攻击](2024年09月26日/MoJE_Mixture_of_Jailbreak_Experts,_Naive_Tabular_Classifiers_as_Guard_for_Prompt_Attacks.md)

- [P4Q: Learning to Prompt for Quantization in Visual-language Models](2024年09月26日/P4Q_Learning_to_Prompt_for_Quantization_in_Visual-language_Models.md)

    - [翻译: P4Q：视觉-语言模型中通过提示学习实现量化](2024年09月26日/P4Q_Learning_to_Prompt_for_Quantization_in_Visual-language_Models.md)

- [Robotic-CLIP: Fine-tuning CLIP on Action Data for Robotic Applications](2024年09月26日/Robotic-CLIP_Fine-tuning_CLIP_on_Action_Data_for_Robotic_Applications.md)

    - [翻译: Robotic-CLIP：为机器人应用量身定制，通过动作数据微调 CLIP。](2024年09月26日/Robotic-CLIP_Fine-tuning_CLIP_on_Action_Data_for_Robotic_Applications.md)

- [T3: A Novel Zero-shot Transfer Learning Framework Iteratively Training on an Assistant Task for a Target Task](2024年09月26日/T3_A_Novel_Zero-shot_Transfer_Learning_Framework_Iteratively_Training_on_an_Assistant_Task_for_a_Target_Task.md)

    - [翻译: T3：一种创新的零-shot 迁移学习框架，通过在辅助任务上迭代训练，最终实现目标任务。](2024年09月26日/T3_A_Novel_Zero-shot_Transfer_Learning_Framework_Iteratively_Training_on_an_Assistant_Task_for_a_Target_Task.md)

- [TA-Cleaner: A Fine-grained Text Alignment Backdoor Defense Strategy for Multimodal Contrastive Learning](2024年09月26日/TA-Cleaner_A_Fine-grained_Text_Alignment_Backdoor_Defense_Strategy_for_Multimodal_Contrastive_Learning.md)

    - [翻译: TA-Cleaner：一种针对多模态对比学习的细粒度文本对齐后门防御策略](2024年09月26日/TA-Cleaner_A_Fine-grained_Text_Alignment_Backdoor_Defense_Strategy_for_Multimodal_Contrastive_Learning.md)

- [TestBench: Evaluating Class-Level Test Case Generation Capability of Large Language Models](2024年09月26日/TestBench_Evaluating_Class-Level_Test_Case_Generation_Capability_of_Large_Language_Models.md)

    - [翻译: TestBench：评估大型语言模型在类级别测试用例的生成能力](2024年09月26日/TestBench_Evaluating_Class-Level_Test_Case_Generation_Capability_of_Large_Language_Models.md)

- [Weak-To-Strong Backdoor Attacks for LLMs with Contrastive Knowledge Distillation](2024年09月26日/Weak-To-Strong_Backdoor_Attacks_for_LLMs_with_Contrastive_Knowledge_Distillation.md)

    - [翻译: 针对 LLM 的弱-强后门攻击与对比知识蒸馏](2024年09月26日/Weak-To-Strong_Backdoor_Attacks_for_LLMs_with_Contrastive_Knowledge_Distillation.md)