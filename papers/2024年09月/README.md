# 2024年09月

2024年09月17日

- [A Comprehensive Evaluation of Quantized Instruction-Tuned Large Language Models: An Experimental Analysis up to 405B](2024年09月17日/A_Comprehensive_Evaluation_of_Quantized_Instruction-Tuned_Large_Language_Models_An_Experimental_Analysis_up_to_405B.md)

    - [翻译: 全面评估了高达 405B 的量化指令调优大型语言模型，通过实验分析揭示其性能。](2024年09月17日/A_Comprehensive_Evaluation_of_Quantized_Instruction-Tuned_Large_Language_Models_An_Experimental_Analysis_up_to_405B.md)

- [AI Suggestions Homogenize Writing Toward Western Styles and Diminish Cultural Nuances](2024年09月17日/AI_Suggestions_Homogenize_Writing_Toward_Western_Styles_and_Diminish_Cultural_Nuances.md)

    - [翻译: AI 建议让写作趋向西方风格，削弱文化细节](2024年09月17日/AI_Suggestions_Homogenize_Writing_Toward_Western_Styles_and_Diminish_Cultural_Nuances.md)

- [AraDiCE: Benchmarks for Dialectal and Cultural Capabilities in LLMs](2024年09月17日/AraDiCE_Benchmarks_for_Dialectal_and_Cultural_Capabilities_in_LLMs.md)

    - [翻译: AraDiCE：评估 LLM 方言与文化能力的基准](2024年09月17日/AraDiCE_Benchmarks_for_Dialectal_and_Cultural_Capabilities_in_LLMs.md)

- [Attention-Seeker: Dynamic Self-Attention Scoring for Unsupervised Keyphrase Extraction](2024年09月17日/Attention-Seeker_Dynamic_Self-Attention_Scoring_for_Unsupervised_Keyphrase_Extraction.md)

    - [翻译: Attention-Seeker：动态自注意力评分，助力无监督关键词提取](2024年09月17日/Attention-Seeker_Dynamic_Self-Attention_Scoring_for_Unsupervised_Keyphrase_Extraction.md)

- [CoCA: Regaining Safety-awareness of Multimodal Large Language Models with Constitutional Calibration](2024年09月17日/CoCA_Regaining_Safety-awareness_of_Multimodal_Large_Language_Models_with_Constitutional_Calibration.md)

    - [翻译: CoCA：借助宪法校准，重塑多模态大型语言模型的安全意识](2024年09月17日/CoCA_Regaining_Safety-awareness_of_Multimodal_Large_Language_Models_with_Constitutional_Calibration.md)

- [CREAM: Comparison-Based Reference-Free ELO-Ranked Automatic Evaluation for Meeting Summarization](2024年09月17日/CREAM_Comparison-Based_Reference-Free_ELO-Ranked_Automatic_Evaluation_for_Meeting_Summarization.md)

    - [翻译: CREAM：一种基于比较的无参考 ELO 排名方法，用于自动评估会议摘要。](2024年09月17日/CREAM_Comparison-Based_Reference-Free_ELO-Ranked_Automatic_Evaluation_for_Meeting_Summarization.md)

- [Cross-lingual transfer of multilingual models on low resource African Languages](2024年09月17日/Cross-lingual_transfer_of_multilingual_models_on_low_resource_African_Languages.md)

    - [翻译: 多语言模型在非洲低资源语言中的跨语言迁移](2024年09月17日/Cross-lingual_transfer_of_multilingual_models_on_low_resource_African_Languages.md)

- [Diversify and Conquer: Diversity-Centric Data Selection with Iterative Refinement](2024年09月17日/Diversify_and_Conquer_Diversity-Centric_Data_Selection_with_Iterative_Refinement.md)

    - [翻译: 多样化征服：聚焦多样性的数据选择与迭代优化](2024年09月17日/Diversify_and_Conquer_Diversity-Centric_Data_Selection_with_Iterative_Refinement.md)

- [Diversity-grounded Channel Prototypical Learning for Out-of-Distribution Intent Detection](2024年09月17日/Diversity-grounded_Channel_Prototypical_Learning_for_Out-of-Distribution_Intent_Detection.md)

    - [翻译: 基于多样性的通道原型学习，助力分布外意图检测](2024年09月17日/Diversity-grounded_Channel_Prototypical_Learning_for_Out-of-Distribution_Intent_Detection.md)

- [Enhancing Low-Resource Language and Instruction Following Capabilities of Audio Language Models](2024年09月17日/Enhancing_Low-Resource_Language_and_Instruction_Following_Capabilities_of_Audio_Language_Models.md)

    - [翻译: 提升音频语言模型在低资源语言和指令跟随方面的能力](2024年09月17日/Enhancing_Low-Resource_Language_and_Instruction_Following_Capabilities_of_Audio_Language_Models.md)

- [Enhancing Multilingual Speech Generation and Recognition Abilities in LLMs with Constructed Code-switched Data](2024年09月17日/Enhancing_Multilingual_Speech_Generation_and_Recognition_Abilities_in_LLMs_with_Constructed_Code-switched_Data.md)

    - [翻译: 利用构建的代码转换数据，提升 LLM 在多语言语音生成与识别方面的表现](2024年09月17日/Enhancing_Multilingual_Speech_Generation_and_Recognition_Abilities_in_LLMs_with_Constructed_Code-switched_Data.md)

- [Evaluating the Impact of Compression Techniques on Task-Specific Performance of Large Language Models](2024年09月17日/Evaluating_the_Impact_of_Compression_Techniques_on_Task-Specific_Performance_of_Large_Language_Models.md)

    - [翻译: 探究压缩技术如何影响大型语言模型的任务表现](2024年09月17日/Evaluating_the_Impact_of_Compression_Techniques_on_Task-Specific_Performance_of_Large_Language_Models.md)

- [Exploring ChatGPT-based Augmentation Strategies for Contrastive Aspect-based Sentiment Analysis](2024年09月17日/Exploring_ChatGPT-based_Augmentation_Strategies_for_Contrastive_Aspect-based_Sentiment_Analysis.md)

    - [翻译: 探索基于 ChatGPT 的增强策略，应用于对比方面情感分析](2024年09月17日/Exploring_ChatGPT-based_Augmentation_Strategies_for_Contrastive_Aspect-based_Sentiment_Analysis.md)

- [GEIC: Universal and Multilingual Named Entity Recognition with Large Language Models](2024年09月17日/GEIC_Universal_and_Multilingual_Named_Entity_Recognition_with_Large_Language_Models.md)

    - [翻译: GEIC：借助大型语言模型实现通用且多语言的命名实体识别](2024年09月17日/GEIC_Universal_and_Multilingual_Named_Entity_Recognition_with_Large_Language_Models.md)

- [GenCRF: Generative Clustering and Reformulation Framework for Enhanced Intent-Driven Information Retrieval](2024年09月17日/GenCRF_Generative_Clustering_and_Reformulation_Framework_for_Enhanced_Intent-Driven_Information_Retrieval.md)

    - [翻译: GenCRF：一个旨在提升意图驱动信息检索的生成聚类与重构框架](2024年09月17日/GenCRF_Generative_Clustering_and_Reformulation_Framework_for_Enhanced_Intent-Driven_Information_Retrieval.md)

- [Hackphyr: A Local Fine-Tuned LLM Agent for Network Security Environments](2024年09月17日/Hackphyr_A_Local_Fine-Tuned_LLM_Agent_for_Network_Security_Environments.md)

    - [翻译: Hackphyr：专为网络安全环境定制的本地微调 LLM 代理](2024年09月17日/Hackphyr_A_Local_Fine-Tuned_LLM_Agent_for_Network_Security_Environments.md)

- [Hierarchical Narrative Analysis: Unraveling Perceptions of Generative AI](2024年09月17日/Hierarchical_Narrative_Analysis_Unraveling_Perceptions_of_Generative_AI.md)

    - [翻译: 分层叙事分析：揭示生成性 AI 的深层感知](2024年09月17日/Hierarchical_Narrative_Analysis_Unraveling_Perceptions_of_Generative_AI.md)

- [Improving the Efficiency of Visually Augmented Language Models](2024年09月17日/Improving_the_Efficiency_of_Visually_Augmented_Language_Models.md)

    - [翻译: 提升视觉增强语言模型的效率](2024年09月17日/Improving_the_Efficiency_of_Visually_Augmented_Language_Models.md)

- [Investigating Context-Faithfulness in Large Language Models: The Roles of Memory Strength and Evidence Style](2024年09月17日/Investigating_Context-Faithfulness_in_Large_Language_Models_The_Roles_of_Memory_Strength_and_Evidence_Style.md)

    - [翻译: 探索大型语言模型中的上下文忠实度：记忆强度与证据风格的影响](2024年09月17日/Investigating_Context-Faithfulness_in_Large_Language_Models_The_Roles_of_Memory_Strength_and_Evidence_Style.md)

- [KVPruner: Structural Pruning for Faster and Memory-Efficient Large Language Models](2024年09月17日/KVPruner_Structural_Pruning_for_Faster_and_Memory-Efficient_Large_Language_Models.md)

    - [翻译: KVPruner：为大型语言模型带来更快处理速度和更高内存效率的结构化剪枝技术](2024年09月17日/KVPruner_Structural_Pruning_for_Faster_and_Memory-Efficient_Large_Language_Models.md)

- [Large Language Models are Good Multi-lingual Learners : When LLMs Meet Cross-lingual Prompts](2024年09月17日/Large_Language_Models_are_Good_Multi-lingual_Learners__When_LLMs_Meet_Cross-lingual_Prompts.md)

    - [翻译: 大型语言模型在多语言学习中表现出色：当 LLM 遇到跨语言提示时，它们展现了卓越的学习能力。](2024年09月17日/Large_Language_Models_are_Good_Multi-lingual_Learners__When_LLMs_Meet_Cross-lingual_Prompts.md)

- [Less is More: A Simple yet Effective Token Reduction Method for Efficient Multi-modal LLMs](2024年09月17日/Less_is_More_A_Simple_yet_Effective_Token_Reduction_Method_for_Efficient_Multi-modal_LLMs.md)

    - [翻译: 少即是多：一种简洁高效的标记减少方法，助力多模态大型语言模型更上一层楼。](2024年09月17日/Less_is_More_A_Simple_yet_Effective_Token_Reduction_Method_for_Efficient_Multi-modal_LLMs.md)

- [Leveraging Distillation Techniques for Document Understanding: A Case Study with FLAN-T5](2024年09月17日/Leveraging_Distillation_Techniques_for_Document_Understanding_A_Case_Study_with_FLAN-T5.md)

    - [翻译: 通过蒸馏技术提升文档理解：FLAN-T5 案例研究](2024年09月17日/Leveraging_Distillation_Techniques_for_Document_Understanding_A_Case_Study_with_FLAN-T5.md)

- [Leveraging Reviewer Experience in Code Review Comment Generation](2024年09月17日/Leveraging_Reviewer_Experience_in_Code_Review_Comment_Generation.md)

    - [翻译: 借助评审者经验，优化代码评审评论生成](2024年09月17日/Leveraging_Reviewer_Experience_in_Code_Review_Comment_Generation.md)

- [LLM-as-a-Judge & Reward Model: What They Can and Cannot Do](2024年09月17日/LLM-as-a-Judge_&_Reward_Model_What_They_Can_and_Cannot_Do.md)

    - [翻译: LLM 作为评判者与奖励模型：它们的能与不能](2024年09月17日/LLM-as-a-Judge_&_Reward_Model_What_They_Can_and_Cannot_Do.md)

- [LOLA -- An Open-Source Massively Multilingual Large Language Model](2024年09月17日/LOLA_--_An_Open-Source_Massively_Multilingual_Large_Language_Model.md)

    - [翻译: LOLA，一款开源的大规模多语言大型语言模型，正引领着语言技术的新潮流。](2024年09月17日/LOLA_--_An_Open-Source_Massively_Multilingual_Large_Language_Model.md)

- [Measuring and Enhancing Trustworthiness of LLMs in RAG through Grounded Attributions and Learning to Refuse](2024年09月17日/Measuring_and_Enhancing_Trustworthiness_of_LLMs_in_RAG_through_Grounded_Attributions_and_Learning_to_Refuse.md)

    - [翻译: 通过基于证据的归因和学习拒绝，我们旨在提升 LLMs 在 RAG 中的可信度。](2024年09月17日/Measuring_and_Enhancing_Trustworthiness_of_LLMs_in_RAG_through_Grounded_Attributions_and_Learning_to_Refuse.md)

- [MoDex: Planning High-Dimensional Dexterous Control via Learning Neural Hand Models](2024年09月17日/MoDex_Planning_High-Dimensional_Dexterous_Control_via_Learning_Neural_Hand_Models.md)

    - [翻译: MoDex：借助神经手模型学习，实现高维灵巧控制规划](2024年09月17日/MoDex_Planning_High-Dimensional_Dexterous_Control_via_Learning_Neural_Hand_Models.md)

- [Multi-Floor Zero-Shot Object Navigation Policy](2024年09月17日/Multi-Floor_Zero-Shot_Object_Navigation_Policy.md)

    - [翻译: 多层零-shot 物体导航策略](2024年09月17日/Multi-Floor_Zero-Shot_Object_Navigation_Policy.md)

- [Multi-OCT-SelfNet: Integrating Self-Supervised Learning with Multi-Source Data Fusion for Enhanced Multi-Class Retinal Disease Classification](2024年09月17日/Multi-OCT-SelfNet_Integrating_Self-Supervised_Learning_with_Multi-Source_Data_Fusion_for_Enhanced_Multi-Class_Retinal_Disease_Classification.md)

    - [翻译: Multi-OCT-SelfNet：融合自监督学习与多源数据，提升多类视网膜疾病分类效果](2024年09月17日/Multi-OCT-SelfNet_Integrating_Self-Supervised_Learning_with_Multi-Source_Data_Fusion_for_Enhanced_Multi-Class_Retinal_Disease_Classification.md)

- [NVLM: Open Frontier-Class Multimodal LLMs](2024年09月17日/NVLM_Open_Frontier-Class_Multimodal_LLMs.md)

    - [翻译: NVLM：探索多模态大型语言模型的前沿](2024年09月17日/NVLM_Open_Frontier-Class_Multimodal_LLMs.md)

- [Phidias: A Generative Model for Creating 3D Content from Text, Image, and 3D Conditions with Reference-Augmented Diffusion](2024年09月17日/Phidias_A_Generative_Model_for_Creating_3D_Content_from_Text,_Image,_and_3D_Conditions_with_Reference-Augmented_Diffusion.md)

    - [翻译: Phidias：一款结合文本、图像和 3D 条件，通过参考增强扩散技术生成 3D 内容的创新模型。](2024年09月17日/Phidias_A_Generative_Model_for_Creating_3D_Content_from_Text,_Image,_and_3D_Conditions_with_Reference-Augmented_Diffusion.md)

- [P-RAG: Progressive Retrieval Augmented Generation For Planning on Embodied Everyday Task](2024年09月17日/P-RAG_Progressive_Retrieval_Augmented_Generation_For_Planning_on_Embodied_Everyday_Task.md)

    - [翻译: P-RAG：渐进式检索增强生成，专为实体日常任务规划而生](2024年09月17日/P-RAG_Progressive_Retrieval_Augmented_Generation_For_Planning_on_Embodied_Everyday_Task.md)

- [Prompt Obfuscation for Large Language Models](2024年09月17日/Prompt_Obfuscation_for_Large_Language_Models.md)

    - [翻译: 大型语言模型的提示混淆技术](2024年09月17日/Prompt_Obfuscation_for_Large_Language_Models.md)

- [Promptriever: Instruction-Trained Retrievers Can Be Prompted Like Language Models](2024年09月17日/Promptriever_Instruction-Trained_Retrievers_Can_Be_Prompted_Like_Language_Models.md)

    - [翻译: Promptriever：经过指令训练的检索器，也能像语言模型一样灵活响应提示。](2024年09月17日/Promptriever_Instruction-Trained_Retrievers_Can_Be_Prompted_Like_Language_Models.md)

- [Propulsion: Steering LLM with Tiny Fine-Tuning](2024年09月17日/Propulsion_Steering_LLM_with_Tiny_Fine-Tuning.md)

    - [翻译: 微调驱动：引领大型语言模型前行](2024年09月17日/Propulsion_Steering_LLM_with_Tiny_Fine-Tuning.md)

- [Reasoning Graph Enhanced Exemplars Retrieval for In-Context Learning](2024年09月17日/Reasoning_Graph_Enhanced_Exemplars_Retrieval_for_In-Context_Learning.md)

    - [翻译: 通过增强推理图进行示例检索，助力上下文学习](2024年09月17日/Reasoning_Graph_Enhanced_Exemplars_Retrieval_for_In-Context_Learning.md)

- [SAGED: A Holistic Bias-Benchmarking Pipeline for Language Models with Customisable Fairness Calibration](2024年09月17日/SAGED_A_Holistic_Bias-Benchmarking_Pipeline_for_Language_Models_with_Customisable_Fairness_Calibration.md)

    - [翻译: SAGED：一个全面且可定制的语言模型偏见基准测试与公平校准管道](2024年09月17日/SAGED_A_Holistic_Bias-Benchmarking_Pipeline_for_Language_Models_with_Customisable_Fairness_Calibration.md)

- [Says Who? Effective Zero-Shot Annotation of Focalization](2024年09月17日/Says_Who_Effective_Zero-Shot_Annotation_of_Focalization.md)

    - [翻译: 谁说了算？聚焦标注的零-shot 高效实践](2024年09月17日/Says_Who_Effective_Zero-Shot_Annotation_of_Focalization.md)

- [Scheme Pearl: Quantum Continuations](2024年09月17日/Scheme_Pearl_Quantum_Continuations.md)

    - [翻译: Scheme 珍宝：量子延续](2024年09月17日/Scheme_Pearl_Quantum_Continuations.md)

- [Self-Evolutionary Large Language Models through Uncertainty-Enhanced Preference Optimization](2024年09月17日/Self-Evolutionary_Large_Language_Models_through_Uncertainty-Enhanced_Preference_Optimization.md)

    - [翻译: 大型语言模型通过不确定性增强的偏好优化实现自进化](2024年09月17日/Self-Evolutionary_Large_Language_Models_through_Uncertainty-Enhanced_Preference_Optimization.md)

- [SOAP: Improving and Stabilizing Shampoo using Adam](2024年09月17日/SOAP_Improving_and_Stabilizing_Shampoo_using_Adam.md)

    - [翻译: SOAP：借助 Adam 优化 Shampoo，提升其稳定性和效果](2024年09月17日/SOAP_Improving_and_Stabilizing_Shampoo_using_Adam.md)

- [Strategic Insights in Human and Large Language Model Tactics at Word Guessing Games](2024年09月17日/Strategic_Insights_in_Human_and_Large_Language_Model_Tactics_at_Word_Guessing_Games.md)

    - [翻译: 猜词游戏中的人类与大语言模型战术策略解析](2024年09月17日/Strategic_Insights_in_Human_and_Large_Language_Model_Tactics_at_Word_Guessing_Games.md)

- [SuperCoder2.0: Technical Report on Exploring the feasibility of LLMs as Autonomous Programmer](2024年09月17日/SuperCoder2.0_Technical_Report_on_Exploring_the_feasibility_of_LLMs_as_Autonomous_Programmer.md)

    - [翻译: SuperCoder2.0：探究 LLM 成为自主程序员可能性的技术报告](2024年09月17日/SuperCoder2.0_Technical_Report_on_Exploring_the_feasibility_of_LLMs_as_Autonomous_Programmer.md)

- [Task Arithmetic for Language Expansion in Speech Translation](2024年09月17日/Task_Arithmetic_for_Language_Expansion_in_Speech_Translation.md)

    - [翻译: 语音翻译中的语言扩展任务算术](2024年09月17日/Task_Arithmetic_for_Language_Expansion_in_Speech_Translation.md)

- [THaMES: An End-to-End Tool for Hallucination Mitigation and Evaluation in Large Language Models](2024年09月17日/THaMES_An_End-to-End_Tool_for_Hallucination_Mitigation_and_Evaluation_in_Large_Language_Models.md)

    - [翻译: THaMES：一款专为大型语言模型设计的端到端工具，旨在缓解幻觉问题并进行性能评估。](2024年09月17日/THaMES_An_End-to-End_Tool_for_Hallucination_Mitigation_and_Evaluation_in_Large_Language_Models.md)

- [Towards Effective User Attribution for Latent Diffusion Models via Watermark-Informed Blending](2024年09月17日/Towards_Effective_User_Attribution_for_Latent_Diffusion_Models_via_Watermark-Informed_Blending.md)

    - [翻译: 利用水印信息混合技术，实现潜在扩散模型的用户归属优化](2024年09月17日/Towards_Effective_User_Attribution_for_Latent_Diffusion_Models_via_Watermark-Informed_Blending.md)

- [Towards Ethical Personal AI Applications: Practical Considerations for AI Assistants with Long-Term Memory](2024年09月17日/Towards_Ethical_Personal_AI_Applications_Practical_Considerations_for_AI_Assistants_with_Long-Term_Memory.md)

    - [翻译: 探索道德个人 AI 应用：为具备长期记忆的 AI 助手提供实用指南](2024年09月17日/Towards_Ethical_Personal_AI_Applications_Practical_Considerations_for_AI_Assistants_with_Long-Term_Memory.md)

- [Towards No-Code Programming of Cobots: Experiments with Code Synthesis by Large Code Models for Conversational Programming](2024年09月17日/Towards_No-Code_Programming_of_Cobots_Experiments_with_Code_Synthesis_by_Large_Code_Models_for_Conversational_Programming.md)

    - [翻译: 无代码协作机器人编程新探索：借助大型代码模型实现对话式代码生成实验](2024年09月17日/Towards_No-Code_Programming_of_Cobots_Experiments_with_Code_Synthesis_by_Large_Code_Models_for_Conversational_Programming.md)

- [Towards Novel Malicious Packet Recognition: A Few-Shot Learning Approach](2024年09月17日/Towards_Novel_Malicious_Packet_Recognition_A_Few-Shot_Learning_Approach.md)

    - [翻译: 探索新型恶意数据包识别：一种少样本学习策略](2024年09月17日/Towards_Novel_Malicious_Packet_Recognition_A_Few-Shot_Learning_Approach.md)

- [Towards Time Series Reasoning with LLMs](2024年09月17日/Towards_Time_Series_Reasoning_with_LLMs.md)

    - [翻译: 迈向 LLM 驱动的时间序列推理](2024年09月17日/Towards_Time_Series_Reasoning_with_LLMs.md)

- [WER We Stand: Benchmarking Urdu ASR Models](2024年09月17日/WER_We_Stand_Benchmarking_Urdu_ASR_Models.md)

    - [翻译: 乌尔都语 ASR 模型基准测试：WER 我们站](2024年09月17日/WER_We_Stand_Benchmarking_Urdu_ASR_Models.md)

2024年09月16日

- [AutoSafeCoder: A Multi-Agent Framework for Securing LLM Code Generation through Static Analysis and Fuzz Testing](2024年09月16日/AutoSafeCoder_A_Multi-Agent_Framework_for_Securing_LLM_Code_Generation_through_Static_Analysis_and_Fuzz_Testing.md)

    - [翻译: AutoSafeCoder：通过静态分析与模糊测试，为 LLM 代码生成提供安全保障的多代理框架](2024年09月16日/AutoSafeCoder_A_Multi-Agent_Framework_for_Securing_LLM_Code_Generation_through_Static_Analysis_and_Fuzz_Testing.md)

- [Model-in-the-Loop (MILO): Accelerating Multimodal AI Data Annotation with LLMs](2024年09月16日/Model-in-the-Loop_(MILO)_Accelerating_Multimodal_AI_Data_Annotation_with_LLMs.md)

    - [翻译: MILO：借助 LLM 加速多模态 AI 数据标注](2024年09月16日/Model-in-the-Loop_(MILO)_Accelerating_Multimodal_AI_Data_Annotation_with_LLMs.md)

- [Video Token Sparsification for Efficient Multimodal LLMs in Autonomous Driving](2024年09月16日/Video_Token_Sparsification_for_Efficient_Multimodal_LLMs_in_Autonomous_Driving.md)

    - [翻译: 通过视频令牌稀疏化，提升自动驾驶中多模态大型语言模型的效率](2024年09月16日/Video_Token_Sparsification_for_Efficient_Multimodal_LLMs_in_Autonomous_Driving.md)

2024年09月15日

- [Language Models and Retrieval Augmented Generation for Automated Structured Data Extraction from Diagnostic Reports](2024年09月15日/Language_Models_and_Retrieval_Augmented_Generation_for_Automated_Structured_Data_Extraction_from_Diagnostic_Reports.md)

    - [翻译: 语言模型与检索增强生成技术联手，自动从诊断报告中提取结构化数据。](2024年09月15日/Language_Models_and_Retrieval_Augmented_Generation_for_Automated_Structured_Data_Extraction_from_Diagnostic_Reports.md)

2024年09月14日

- [On the limits of agency in agent-based models](2024年09月14日/On_the_limits_of_agency_in_agent-based_models.md)

    - [翻译: 探讨基于代理模型中代理的局限性](2024年09月14日/On_the_limits_of_agency_in_agent-based_models.md)