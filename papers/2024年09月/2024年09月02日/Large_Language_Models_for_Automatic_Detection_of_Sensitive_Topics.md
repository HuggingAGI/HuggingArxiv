# 利用大型语言模型自动识别敏感话题

发布时间：2024年09月02日

`LLM应用` `心理健康` `内容审核`

> Large Language Models for Automatic Detection of Sensitive Topics

# 摘要

> 在内容审核中，敏感信息检测是确保在线社区安全的关键。通过协助传统的手动审核过程，大型语言模型（LLMs）能够减轻人类审核员的负担，使他们能更专注于处理潜在风险内容。本研究评估了五种LLMs在心理健康领域检测敏感信息的能力，并分析了它们在多个性能指标上的表现。结果显示，LLMs如GPT-4o，以其高达99.5%的准确率和0.99的F1分数，展现了作为高效检测工具的潜力。我们探讨了LLMs在审核工作中的应用优势及面临的挑战，并强调未来研究需关注其伦理影响。

> Sensitive information detection is crucial in content moderation to maintain safe online communities. Assisting in this traditionally manual process could relieve human moderators from overwhelming and tedious tasks, allowing them to focus solely on flagged content that may pose potential risks. Rapidly advancing large language models (LLMs) are known for their capability to understand and process natural language and so present a potential solution to support this process. This study explores the capabilities of five LLMs for detecting sensitive messages in the mental well-being domain within two online datasets and assesses their performance in terms of accuracy, precision, recall, F1 scores, and consistency. Our findings indicate that LLMs have the potential to be integrated into the moderation workflow as a convenient and precise detection tool. The best-performing model, GPT-4o, achieved an average accuracy of 99.5\% and an F1-score of 0.99. We discuss the advantages and potential challenges of using LLMs in the moderation workflow and suggest that future research should address the ethical considerations of utilising this technology.

[Arxiv](https://arxiv.org/abs/2409.00940)