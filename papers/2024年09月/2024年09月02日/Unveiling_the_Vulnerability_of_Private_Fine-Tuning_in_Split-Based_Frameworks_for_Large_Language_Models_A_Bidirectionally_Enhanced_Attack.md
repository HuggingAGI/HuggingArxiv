# 揭秘大型语言模型分割框架中私有微调的脆弱性：一种双向增强的攻击策略

发布时间：2024年09月02日

`LLM应用` `网络安全` `人工智能`

> Unveiling the Vulnerability of Private Fine-Tuning in Split-Based Frameworks for Large Language Models: A Bidirectionally Enhanced Attack

# 摘要

> 预训练大型语言模型的进步深刻影响了多个领域。然而，为特定任务微调这些模型时，隐私和计算资源的限制成为挑战。拆分学习 (SL) 作为一种解决方案，通过分割模型并仅传输中间激活，平衡了隐私和资源需求。尽管如此，本文揭示了 SL 与 LLM 微调结合时的重大安全漏洞。我们提出的双向半白盒重建 (BiSR) 攻击，利用预训练权重，结合学习与优化方法，有效重建数据。实验证明 BiSR 在多种 LLM 和设置下的领先性能，并展示了其突破多种防御机制的能力。

> Recent advancements in pre-trained large language models (LLMs) have significantly influenced various domains. Adapting these models for specific tasks often involves fine-tuning (FT) with private, domain-specific data. However, privacy concerns keep this data undisclosed, and the computational demands for deploying LLMs pose challenges for resource-limited data holders. This has sparked interest in split learning (SL), a Model-as-a-Service (MaaS) paradigm that divides LLMs into smaller segments for distributed training and deployment, transmitting only intermediate activations instead of raw data. SL has garnered substantial interest in both industry and academia as it aims to balance user data privacy, model ownership, and resource challenges in the private fine-tuning of LLMs. Despite its privacy claims, this paper reveals significant vulnerabilities arising from the combination of SL and LLM-FT: the Not-too-far property of fine-tuning and the auto-regressive nature of LLMs. Exploiting these vulnerabilities, we propose Bidirectional Semi-white-box Reconstruction (BiSR), the first data reconstruction attack (DRA) designed to target both the forward and backward propagation processes of SL. BiSR utilizes pre-trained weights as prior knowledge, combining a learning-based attack with a bidirectional optimization-based approach for highly effective data reconstruction. Additionally, it incorporates a Noise-adaptive Mixture of Experts (NaMoE) model to enhance reconstruction performance under perturbation. We conducted systematic experiments on various mainstream LLMs and different setups, empirically demonstrating BiSR's state-of-the-art performance. Furthermore, we thoroughly examined three representative defense mechanisms, showcasing our method's capability to reconstruct private data even in the presence of these defenses.

[Arxiv](https://arxiv.org/abs/2409.00960)