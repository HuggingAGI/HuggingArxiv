# 基于大型语言模型的合成音频对话生成框架

发布时间：2024年09月02日

`LLM应用` `音频处理` `人工智能`

> A Framework for Synthetic Audio Conversations Generation using Large Language Models

# 摘要

> 本文介绍的 ConversaSynth 框架，利用 LLM 的多重人格设置，生成多样且连贯的文本对话，再通过 TTS 系统转换为音频。实验证明，该框架能高效产出高质量的合成音频数据集，极大地提升了音频处理相关模型的训练与评估效果。生成的数据集不仅多样且逼真，为构建强大且灵活的音频 AI 系统提供了理想素材。

> In this paper, we introduce ConversaSynth, a framework designed to generate synthetic conversation audio using large language models (LLMs) with multiple persona settings. The framework first creates diverse and coherent text-based dialogues across various topics, which are then converted into audio using text-to-speech (TTS) systems. Our experiments demonstrate that ConversaSynth effectively generates highquality synthetic audio datasets, which can significantly enhance the training and evaluation of models for audio tagging, audio classification, and multi-speaker speech recognition. The results indicate that the synthetic datasets generated by ConversaSynth exhibit substantial diversity and realism, making them suitable for developing robust, adaptable audio-based AI systems.

[Arxiv](https://arxiv.org/abs/2409.00946)