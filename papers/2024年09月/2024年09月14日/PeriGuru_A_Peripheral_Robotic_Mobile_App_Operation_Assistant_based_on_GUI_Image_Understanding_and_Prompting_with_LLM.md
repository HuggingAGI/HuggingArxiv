# PeriGuru：一款基于 GUI 图像理解和 LLM 提示的外围机器人移动应用操作助手

发布时间：2024年09月14日

`LLM应用` `机器人`

> PeriGuru: A Peripheral Robotic Mobile App Operation Assistant based on GUI Image Understanding and Prompting with LLM

# 摘要

> 智能手机已成为我们日常学习、沟通和娱乐的重要工具。然而，老年人和残疾人等群体在使用智能手机时面临困难，因此需要移动应用操作助手。我们设计并开发了 PeriGuru，这是一种基于 GUI 图像理解和大型语言模型（LLM）的外围机器人助手。PeriGuru 通过计算机视觉技术分析应用界面截图，并利用 LLM 做出操作决策，由机器人手臂执行。在测试中，PeriGuru 的成功率高达 81.94%，远超传统方法。我们的代码已公开在 https://github.com/Z2sJ4t/PeriGuru。

> Smartphones have significantly enhanced our daily learning, communication, and entertainment, becoming an essential component of modern life. However, certain populations, including the elderly and individuals with disabilities, encounter challenges in utilizing smartphones, thus necessitating mobile app operation assistants, a.k.a. mobile app agent. With considerations for privacy, permissions, and cross-platform compatibility issues, we endeavor to devise and develop PeriGuru in this work, a peripheral robotic mobile app operation assistant based on GUI image understanding and prompting with Large Language Model (LLM). PeriGuru leverages a suite of computer vision techniques to analyze GUI screenshot images and employs LLM to inform action decisions, which are then executed by robotic arms. PeriGuru achieves a success rate of 81.94% on the test task set, which surpasses by more than double the method without PeriGuru's GUI image interpreting and prompting design. Our code is available on https://github.com/Z2sJ4t/PeriGuru.

[Arxiv](https://arxiv.org/abs/2409.09354)