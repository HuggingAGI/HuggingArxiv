# 让 AI 辅助人类：以人为本的生成式 AI 自动标注

发布时间：2024年09月14日

`LLM应用` `社交媒体` `数据标注`

> Keeping Humans in the Loop: Human-Centered Automated Annotation with Generative AI

# 摘要

> 自动化文本标注是 LLM 在社交媒体研究中的重要应用。尽管 LLM 在标注任务上表现出色，但现有研究多依赖公共数据集，存在污染风险。我们采用以人为中心的框架，使用 GPT-4 在 11 个受保护数据集上复制了 27 项标注任务，并将其与人工标注和微调模型进行对比。结果显示，LLM 标注质量虽高，但任务间表现差异显著。这凸显了以人为本的工作流程和严格评估标准的必要性：自动化标注在多种情况下仍与人类判断有显著差异。因此，基于人类验证标签的自动化标注是负责任评估的关键。

> Automated text annotation is a compelling use case for generative large language models (LLMs) in social media research. Recent work suggests that LLMs can achieve strong performance on annotation tasks; however, these studies evaluate LLMs on a small number of tasks and likely suffer from contamination due to a reliance on public benchmark datasets. Here, we test a human-centered framework for responsibly evaluating artificial intelligence tools used in automated annotation. We use GPT-4 to replicate 27 annotation tasks across 11 password-protected datasets from recently published computational social science articles in high-impact journals. For each task, we compare GPT-4 annotations against human-annotated ground-truth labels and against annotations from separate supervised classification models fine-tuned on human-generated labels. Although the quality of LLM labels is generally high, we find significant variation in LLM performance across tasks, even within datasets. Our findings underscore the importance of a human-centered workflow and careful evaluation standards: Automated annotations significantly diverge from human judgment in numerous scenarios, despite various optimization strategies such as prompt tuning. Grounding automated annotation in validation labels generated by humans is essential for responsible evaluation.

[Arxiv](https://arxiv.org/abs/2409.09467)