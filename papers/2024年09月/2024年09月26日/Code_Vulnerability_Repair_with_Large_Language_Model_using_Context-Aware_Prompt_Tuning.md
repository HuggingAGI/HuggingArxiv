# 利用上下文感知提示调整，大型语言模型助力代码漏洞修复

发布时间：2024年09月26日

`LLM应用` `软件开发` `网络安全`

> Code Vulnerability Repair with Large Language Model using Context-Aware Prompt Tuning

# 摘要

> LLM 在检测和修复代码漏洞方面面临挑战，尤其是在处理复杂漏洞时。我们使用 GitHub Copilot 研究缓冲区溢出漏洞，发现其检测率为 76%，但修复率仅为 15%。为此，我们提出上下文感知的提示调整技术，通过注入领域知识，成功将修复率提升至 63%，效果显著提升。

> Large Language Models (LLMs) have shown significant challenges in detecting and repairing vulnerable code, particularly when dealing with vulnerabilities involving multiple aspects, such as variables, code flows, and code structures. In this study, we utilize GitHub Copilot as the LLM and focus on buffer overflow vulnerabilities. Our experiments reveal a notable gap in Copilot's abilities when dealing with buffer overflow vulnerabilities, with a 76% vulnerability detection rate but only a 15% vulnerability repair rate. To address this issue, we propose context-aware prompt tuning techniques designed to enhance LLM performance in repairing buffer overflow. By injecting a sequence of domain knowledge about the vulnerability, including various security and code contexts, we demonstrate that Copilot's successful repair rate increases to 63%, representing more than four times the improvement compared to repairs without domain knowledge.

[Arxiv](https://arxiv.org/abs/2409.18395)