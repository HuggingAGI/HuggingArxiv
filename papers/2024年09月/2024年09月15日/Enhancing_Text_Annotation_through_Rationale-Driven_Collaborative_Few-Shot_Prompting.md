# 借助基于理由的协作少样本提示，提升文本标注效果

发布时间：2024年09月15日

`LLM应用` `数据标注`

> Enhancing Text Annotation through Rationale-Driven Collaborative Few-Shot Prompting

# 摘要

> 传统数据标注过程既费力又耗时，还容易受人类偏见影响，管理复杂数据集时尤为棘手。本研究探索了大型语言模型 (LLM) 作为自动化标注工具的潜力，旨在提升标注效率与一致性。我们采用基于理由的协作少样本提示技术，以期提升 LLM 在文本标注中的表现。通过在四个基准数据集上对六个 LLM 进行严格评估，并比较七种不同方法，我们发现协作方法在复杂标注任务中始终优于传统少样本技术及其他基线方法。这项研究为利用协作学习方法应对高难度文本标注任务提供了宝贵见解与坚实框架。

> The traditional data annotation process is often labor-intensive, time-consuming, and susceptible to human bias, which complicates the management of increasingly complex datasets. This study explores the potential of large language models (LLMs) as automated data annotators to improve efficiency and consistency in annotation tasks. By employing rationale-driven collaborative few-shot prompting techniques, we aim to improve the performance of LLMs in text annotation. We conduct a rigorous evaluation of six LLMs across four benchmark datasets, comparing seven distinct methodologies. Our results demonstrate that collaborative methods consistently outperform traditional few-shot techniques and other baseline approaches, particularly in complex annotation tasks. Our work provides valuable insights and a robust framework for leveraging collaborative learning methods to tackle challenging text annotation tasks.

[Arxiv](https://arxiv.org/abs/2409.09615)