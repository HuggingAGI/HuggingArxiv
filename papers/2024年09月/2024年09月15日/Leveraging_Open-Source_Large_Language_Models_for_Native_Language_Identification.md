# 借助开源大型语言模型，我们能够更精准地识别母语。

发布时间：2024年09月15日

`LLM应用` `法医学` `市场营销`

> Leveraging Open-Source Large Language Models for Native Language Identification

# 摘要

> 母语识别 (NLI) 是一项根据第二语言写作识别母语的任务，广泛应用于法医学、市场营销和语言学习。传统机器学习方法曾在此领域表现优异，但近期闭源大型语言模型如 GPT-4 在零-shot 设置下展示了惊人的 NLI 能力。然而，闭源模型的高成本和数据不透明性限制了其应用。本研究探索了开源 LLM 在 NLI 中的潜力，发现开源模型在未经微调时性能不及闭源模型，但通过微调，其表现可与商业模型媲美。

> Native Language Identification (NLI) - the task of identifying the native language (L1) of a person based on their writing in the second language (L2) - has applications in forensics, marketing, and second language acquisition. Historically, conventional machine learning approaches that heavily rely on extensive feature engineering have outperformed transformer-based language models on this task. Recently, closed-source generative large language models (LLMs), e.g., GPT-4, have demonstrated remarkable performance on NLI in a zero-shot setting, including promising results in open-set classification. However, closed-source LLMs have many disadvantages, such as high costs and undisclosed nature of training data. This study explores the potential of using open-source LLMs for NLI. Our results indicate that open-source LLMs do not reach the accuracy levels of closed-source LLMs when used out-of-the-box. However, when fine-tuned on labeled training data, open-source LLMs can achieve performance comparable to that of commercial LLMs.

[Arxiv](https://arxiv.org/abs/2409.09659)