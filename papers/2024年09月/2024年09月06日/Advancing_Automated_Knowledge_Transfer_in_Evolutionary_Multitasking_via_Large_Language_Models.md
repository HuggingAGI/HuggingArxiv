# 利用大型语言模型，推动进化多任务中的知识自动化转移。

发布时间：2024年09月06日

`LLM应用` `人工智能`

> Advancing Automated Knowledge Transfer in Evolutionary Multitasking via Large Language Models

# 摘要

> 进化多任务优化 (EMTO) 通过跨任务的知识转移提升搜索性能。为提升 EMTO 效果，已开发多种知识转移模型，但设计这些模型需大量专家知识。近期，大型语言模型 (LLM) 在自主编程领域取得突破，旨在为特定问题生成高效求解器。本研究引入基于 LLM 的优化范式，构建自主模型工厂，生成知识转移模型，确保跨任务的高效知识转移。通过全面实证研究，对比 LLM 生成的模型与现有最先进方法，结果显示，LLM 生成的模型在效率和效果上均表现优异，甚至超越手工设计的模型。

> Evolutionary Multi-task Optimization (EMTO) is a paradigm that leverages knowledge transfer across simultaneously optimized tasks for enhanced search performance. To facilitate EMTO's performance, various knowledge transfer models have been developed for specific optimization tasks. However, designing these models often requires substantial expert knowledge. Recently, large language models (LLMs) have achieved remarkable success in autonomous programming, aiming to produce effective solvers for specific problems. In this work, a LLM-based optimization paradigm is introduced to establish an autonomous model factory for generating knowledge transfer models, ensuring effective and efficient knowledge transfer across various optimization tasks. To evaluate the performance of the proposed method, we conducted comprehensive empirical studies comparing the knowledge transfer model generated by the LLM with existing state-of-the-art knowledge transfer methods. The results demonstrate that the generated model is able to achieve superior or competitive performance against hand-crafted knowledge transfer models in terms of both efficiency and effectiveness.

[Arxiv](https://arxiv.org/abs/2409.04270)