# 揭秘 GitHub 用户隐私意识：实证研究之旅

发布时间：2024年09月06日

`LLM应用` `软件开发` `隐私保护`

> Exploring User Privacy Awareness on GitHub: An Empirical Study

# 摘要

> GitHub 为开发者提供了一个实用的平台，用于分发源代码和协作开发项目。为了提升账户安全和隐私，GitHub 提供了管理访问权限、审查日志和启用双重验证等功能。然而，尽管不断努力，平台仍面临诸多隐私问题。本文深入研究了 GitHub 生态系统，重点探讨了隐私设置的使用情况和用户披露的敏感信息。通过分析 6,132 名开发者的活动，我们发现用户积极使用隐私设置，但仍有不少私人信息在拉取请求评论中被披露。这促使我们利用大型语言模型和 BERT 进行敏感信息检测，以开发个性化隐私助手。我们的研究不仅揭示了现有隐私工具的使用情况和局限性，还为推动该领域的研究提供了新思路。

> GitHub provides developers with a practical way to distribute source code and collaboratively work on common projects. To enhance account security and privacy, GitHub allows its users to manage access permissions, review audit logs, and enable two-factor authentication. However, despite the endless effort, the platform still faces various issues related to the privacy of its users. This paper presents an empirical study delving into the GitHub ecosystem. Our focus is on investigating the utilization of privacy settings on the platform and identifying various types of sensitive information disclosed by users. Leveraging a dataset comprising 6,132 developers, we report and analyze their activities by means of comments on pull requests. Our findings indicate an active engagement by users with the available privacy settings on GitHub. Notably, we observe the disclosure of different forms of private information within pull request comments. This observation has prompted our exploration into sensitivity detection using a large language model and BERT, to pave the way for a personalized privacy assistant. Our work provides insights into the utilization of existing privacy protection tools, such as privacy settings, along with their inherent limitations. Essentially, we aim to advance research in this field by providing both the motivation for creating such privacy protection tools and a proposed methodology for personalizing them.

[Arxiv](https://arxiv.org/abs/2409.04048)