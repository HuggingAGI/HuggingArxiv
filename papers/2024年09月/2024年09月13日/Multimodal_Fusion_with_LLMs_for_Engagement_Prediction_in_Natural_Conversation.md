# 结合多模态数据与 LLM，预测自然对话中的参与度

发布时间：2024年09月13日

`LLM应用` `人工智能`

> Multimodal Fusion with LLMs for Engagement Prediction in Natural Conversation

# 摘要

> 过去十年，智能眼镜在技术上突飞猛进，为高密度人类行为数据分析打开了新的大门。这些眼镜配备的摄像头，让我们能在自然互动中捕捉非语言行为。我们的研究聚焦于通过语言和非语言线索预测双人互动中的参与度，旨在识别不感兴趣或困惑的信号。这种分析有望革新我们对人类交流的理解，提升职场合作效率，通过虚拟互动提供更贴心的精神健康支持，并帮助有沟通障碍的人士。我们收集了34名参与者进行休闲对话的数据集，并引入了一种创新的融合策略，利用大型语言模型将多模态数据整合成“多模态转录”，用于行为推理。初步结果显示，这种方法与现有技术不相上下，显示出巨大的研究潜力。这是首次尝试通过语言模型“推理”现实世界的人类行为。智能眼镜为我们提供了无干扰收集高密度数据的能力，为理解和改善人类交流开辟了新路径，具有深远的社会意义。研究数据将公开，以推动更多探索。

> Over the past decade, wearable computing devices (``smart glasses'') have undergone remarkable advancements in sensor technology, design, and processing power, ushering in a new era of opportunity for high-density human behavior data. Equipped with wearable cameras, these glasses offer a unique opportunity to analyze non-verbal behavior in natural settings as individuals interact. Our focus lies in predicting engagement in dyadic interactions by scrutinizing verbal and non-verbal cues, aiming to detect signs of disinterest or confusion. Leveraging such analyses may revolutionize our understanding of human communication, foster more effective collaboration in professional environments, provide better mental health support through empathetic virtual interactions, and enhance accessibility for those with communication barriers.
  In this work, we collect a dataset featuring 34 participants engaged in casual dyadic conversations, each providing self-reported engagement ratings at the end of each conversation. We introduce a novel fusion strategy using Large Language Models (LLMs) to integrate multiple behavior modalities into a ``multimodal transcript'' that can be processed by an LLM for behavioral reasoning tasks. Remarkably, this method achieves performance comparable to established fusion techniques even in its preliminary implementation, indicating strong potential for further research and optimization. This fusion method is one of the first to approach ``reasoning'' about real-world human behavior through a language model. Smart glasses provide us the ability to unobtrusively gather high-density multimodal data on human behavior, paving the way for new approaches to understanding and improving human communication with the potential for important societal benefits. The features and data collected during the studies will be made publicly available to promote further research.

[Arxiv](https://arxiv.org/abs/2409.09135)