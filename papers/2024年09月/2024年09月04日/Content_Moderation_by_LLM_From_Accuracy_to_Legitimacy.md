# LLM 内容审核：从准确性迈向合法性

发布时间：2024年09月04日

`LLM应用` `在线平台` `内容审核`

> Content Moderation by LLM: From Accuracy to Legitimacy

# 摘要

> LLM 在在线平台内容审核中的应用备受关注。当前研究多聚焦于准确性，即 LLM 决策的正确性。然而，本文指出，仅关注准确性是片面的，因为它忽略了简单与复杂案例的区别及提高准确性时的权衡。实际上，内容审核是平台治理的核心，合法性至关重要。LLM 的目标应是使审核决策合法，而非仅追求正确。为此，本文提出从单一的准确性评估转向基于合法性的框架。对于简单案例，重点在于准确、快速和透明；对于复杂案例，则需合理理由和用户参与。在此框架下，LLM 的真正价值不在于提高准确性，而在于筛选复杂案例、提供高质量解释、辅助人类审核者获取更多信息及促进用户互动参与。本文运用法学和社会科学的规范理论，旨在重新定义 LLM 在内容审核中的角色，并引导该领域的研究方向。

> One trending application of LLM (large language model) is to use it for content moderation in online platforms. Most current studies on this application have focused on the metric of accuracy - the extent to which LLM makes correct decisions about content. This article argues that accuracy is insufficient and misleading, because it fails to grasp the distinction between easy cases and hard cases as well as the inevitable trade-offs in achieving higher accuracy. Closer examination reveals that content moderation is a constitutive part of platform governance, the key of which is to gain and enhance legitimacy. Instead of making moderation decisions correct, the chief goal of LLM is to make them legitimate. In this regard, this article proposes a paradigm shift from the single benchmark of accuracy towards a legitimacy-based framework of evaluating the performance of LLM moderators. The framework suggests that for easy cases, the key is to ensure accuracy, speed and transparency, while for hard cases, what matters is reasoned justification and user participation. Examined under this framework, LLM's real potential in moderation is not accuracy improvement. Rather, LLM can better contribute in four other aspects: to conduct screening of hard cases from easy cases, to provide quality explanations for moderation decisions, to assist human reviewers in getting more contextual information, and to facilitate user participation in a more interactive way. Using normative theories from law and social sciences to critically assess the new technological application, this article seeks to redefine LLM's role in content moderation and redirect relevant research in this field.

[Arxiv](https://arxiv.org/abs/2409.03219)