# 过度剖析语言令人畏惧，通过论证理论引导的提示，我们能揭示其中隐含的厌女逻辑。

发布时间：2024年09月04日

`LLM应用` `社会科学` `人工智能`

> Language is Scary when Over-Analyzed: Unpacking Implied Misogynistic Reasoning with Argumentation Theory-Driven Prompts

# 摘要

> 我们将厌恶女性的言论检测定义为论证推理任务，并探索大型语言模型（LLMs）在理解意大利语和英语中隐含的厌恶女性言论的能力。我们的核心目标是填补消息与隐含的厌恶女性意义之间的推理空白。基于论证理论，我们设计了一系列零-shot和少-shot的提示，结合了思维链推理和增强知识等技术。研究结果显示，LLMs在处理厌恶女性的评论时，更多依赖于内化的女性刻板印象，而非归纳推理，显示出推理能力的不足。

> We propose misogyny detection as an Argumentative Reasoning task and we investigate the capacity of large language models (LLMs) to understand the implicit reasoning used to convey misogyny in both Italian and English. The central aim is to generate the missing reasoning link between a message and the implied meanings encoding the misogyny. Our study uses argumentation theory as a foundation to form a collection of prompts in both zero-shot and few-shot settings. These prompts integrate different techniques, including chain-of-thought reasoning and augmented knowledge. Our findings show that LLMs fall short on reasoning capabilities about misogynistic comments and that they mostly rely on their implicit knowledge derived from internalized common stereotypes about women to generate implied assumptions, rather than on inductive reasoning.

[Arxiv](https://arxiv.org/abs/2409.02519)