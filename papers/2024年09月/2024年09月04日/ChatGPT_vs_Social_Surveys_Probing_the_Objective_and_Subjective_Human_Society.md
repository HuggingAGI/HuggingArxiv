# ChatGPT 对决社会调查：深入探究人类社会的客观与主观层面

发布时间：2024年09月04日

`LLM应用` `社会调查` `人工智能`

> ChatGPT vs Social Surveys: Probing the Objective and Subjective Human Society

# 摘要

> 大型语言模型（LLM）在模拟社会调查数据生成过程中的能力尚不明确。现有研究未充分评估语言模型中社会人口统计学群体的潜在偏差。此外，LLM的主观世界与其回答与人类受访者群体的匹配度存在不一致。本文利用ChatGPT-3.5模拟抽样过程，从2020年美国人口中提取了六个社会经济特征，并分析了关于收入不平等和性别角色的问卷回答，以探究GPT的主观态度。通过重复随机抽样，我们构建了抽样分布，识别GPT生成人口的参数，并与人口普查数据对比。研究发现，GPT在性别和年龄平均值上与实际美国人口有一定一致性，但在种族和教育群体分布上存在差异。GPT的回答分布与人类自我报告态度有显著差异，尽管其收入态度总体点估计偶尔与人口平均值一致，但其回答分布遵循与人类不同的正态分布。在性别关系问题上，GPT的回答倾向于集中在最常回答的类别，显示出确定性模式。我们强调LLM与社会调查在设计哲学上的差异：LLM追求预测最合适的答案，而社会调查旨在揭示社会群体的异质性。

> The extent to which Large Language Models (LLMs) can simulate the data-generating process for social surveys remains unclear. Current research has not thoroughly assessed potential biases in the sociodemographic population represented within the language model's framework. Additionally, the subjective worlds of LLMs often show inconsistencies in how closely their responses match those of groups of human respondents. In this paper, we used ChatGPT-3.5 to simulate the sampling process and generated six socioeconomic characteristics from the 2020 US population. We also analyzed responses to questions about income inequality and gender roles to explore GPT's subjective attitudes. By using repeated random sampling, we created a sampling distribution to identify the parameters of the GPT-generated population and compared these with Census data. Our findings show some alignment in gender and age means with the actual 2020 US population, but we also found mismatches in the distributions of racial and educational groups. Furthermore, there were significant differences between the distribution of GPT's responses and human self-reported attitudes. While the overall point estimates of GPT's income attitudinal responses seem to align with the mean of the population occasionally, their response distributions follow a normal distribution that diverges from human responses. In terms of gender relations, GPT's answers tend to cluster in the most frequently answered category, demonstrating a deterministic pattern. We conclude by emphasizing the distinct design philosophies of LLMs and social surveys: LLMs aim to predict the most suitable answers, while social surveys seek to reveal the heterogeneity among social groups.

[Arxiv](https://arxiv.org/abs/2409.02601)