# 利用 LLM 生成多语言单元测试

发布时间：2024年09月04日

`LLM应用` `软件工程` `自动化测试`

> Multi-language Unit Test Generation using LLMs

# 摘要

> 自动化单元测试虽重要，但耗时。开发人员需大量时间编写测试，以防应用出错。为助其事，软件工程研究多年致力于自动化测试生成技术。然而，现有工具仅支持 Java、C、C# 和最近的 Python。且研究发现，自动生成测试可读性差，与人工编写不符。本文探讨大型语言模型 (LLM) 如何填补这一空白。我们设计了结合静态分析的通用管道，指导 LLM 生成高质量测试。此管道适用于 Java 和 Python，甚至复杂软件。我们通过实证研究评估生成测试的质量，涵盖覆盖率、变异分数和自然性，涉及标准和企业 Java 应用及大型 Python 基准。结果显示，在静态分析辅助下，LLM 生成的测试在覆盖率上可媲美甚至超越现有技术，且更自然易读。我们还与 161 名专业开发者进行用户研究，验证了测试的自然性。

> Implementing automated unit tests is an important but time consuming activity in software development. Developers dedicate substantial time to writing tests for validating an application and preventing regressions. To support developers in this task, software engineering research over the past few decades has developed many techniques for automating unit test generation. However, despite this effort, usable tools exist for very few programming languages -- mainly Java, C, and C# and, more recently, for Python. Moreover, studies have found that automatically generated tests suffer poor readability and often do not resemble developer-written tests. In this work, we present a rigorous investigation of how large language models (LLMs) can help bridge the gap. We describe a generic pipeline that incorporates static analysis to guide LLMs in generating compilable and high-coverage test cases. We illustrate how the pipeline can be applied to different programming languages, specifically Java and Python, and to complex software requiring environment mocking. We conducted a through empirical study to assess the quality of the generated tests in terms of coverage, mutation score, and test naturalness -- evaluating them on standard as well as enterprise Java applications and a large Python benchmark. Our results demonstrate that LLM-based test generation, when guided by static analysis, can be competitive with, and even outperform, state-of-the-art test-generation techniques in coverage achieved while also producing considerably more natural test cases that developers find easy to read and understand. We also present the results of a user study, conducted with 161 professional developers, that highlights the naturalness characteristics of the tests generated by our approach.

[Arxiv](https://arxiv.org/abs/2409.03093)