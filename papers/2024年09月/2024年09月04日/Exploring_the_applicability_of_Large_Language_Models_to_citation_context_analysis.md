# 探究大型语言模型在引用上下文分析领域的应用潜力

发布时间：2024年09月04日

`LLM应用` `学术研究` `出版业`

> Exploring the applicability of Large Language Models to citation context analysis

# 摘要

> 不同于传统引用分析将所有引用视为等同，引用上下文分析更注重单个引用的上下文信息。但这种分析依赖于大量标注数据，限制了其普及。本研究对比了LLMs与人工标注的结果，探索了ChatGPT等大型语言模型在引用上下文分析中的应用。研究发现，LLMs在标注一致性上不逊于甚至优于人工，但在预测性能上表现不佳。因此，直接用LLMs替代人工标注并不妥当。不过，在整合多个人工标注结果时，LLMs的标注可作为参考；或在人工标注者不足时，LLMs可作为补充。这项研究为引用上下文分析的未来发展奠定了基础。

> Unlike traditional citation analysis -- which assumes that all citations in a paper are equivalent -- citation context analysis considers the contextual information of individual citations. However, citation context analysis requires creating large amounts of data through annotation, which hinders the widespread use of this methodology. This study explored the applicability of Large Language Models (LLMs) -- particularly ChatGPT -- to citation context analysis by comparing LLMs and human annotation results. The results show that the LLMs annotation is as good as or better than the human annotation in terms of consistency but poor in terms of predictive performance. Thus, having LLMs immediately replace human annotators in citation context analysis is inappropriate. However, the annotation results obtained by LLMs can be used as reference information when narrowing the annotation results obtained by multiple human annotators to one, or LLMs can be used as one of the annotators when it is difficult to prepare sufficient human annotators. This study provides basic findings important for the future development of citation context analyses.

[Arxiv](https://arxiv.org/abs/2409.02443)