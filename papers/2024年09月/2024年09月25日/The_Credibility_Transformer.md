# 信任的变革者

发布时间：2024年09月25日

`LLM应用` `数据分析`

> The Credibility Transformer

# 摘要

> 受Transformer在大型语言模型中的成功启发，我们将其应用于表格数据，并通过嵌入技术使其结构与时间序列数据相似。我们创新地引入了一种可信度机制，该机制基于一个特殊标记，融合了先验信息和观察信息。实验证明，这种机制不仅稳定了训练过程，还使我们的可信度Transformer模型在预测性能上超越了当前最先进的深度学习模型。

> Inspired by the large success of Transformers in Large Language Models, these architectures are increasingly applied to tabular data. This is achieved by embedding tabular data into low-dimensional Euclidean spaces resulting in similar structures as time-series data. We introduce a novel credibility mechanism to this Transformer architecture. This credibility mechanism is based on a special token that should be seen as an encoder that consists of a credibility weighted average of prior information and observation based information. We demonstrate that this novel credibility mechanism is very beneficial to stabilize training, and our Credibility Transformer leads to predictive models that are superior to state-of-the-art deep learning models.

[Arxiv](https://arxiv.org/abs/2409.16653)