# 探索 OCR-敏感神经元，提升历史文档中的实体识别效果

发布时间：2024年09月25日

`LLM应用` `出版业` `文化遗产`

> Investigating OCR-Sensitive Neurons to Improve Entity Recognition in Historical Documents

# 摘要

> 本文探讨了 Transformer 架构中 OCR-sensitive 神经元的存在及其对历史文档 NER 性能的影响。通过分析神经元对干净和噪声文本的激活模式，我们识别并中和这些神经元，从而提升模型性能。基于 Llama2 和 Mistral 两个开放访问的 LLM，实验证实了 OCR-sensitive 区域的存在，并展示了在历史报纸和古典评论上的 NER 性能提升，凸显了针对性神经元调制在提升模型处理噪声文本性能方面的潜力。

> This paper investigates the presence of OCR-sensitive neurons within the Transformer architecture and their influence on named entity recognition (NER) performance on historical documents. By analysing neuron activation patterns in response to clean and noisy text inputs, we identify and then neutralise OCR-sensitive neurons to improve model performance. Based on two open access large language models (Llama2 and Mistral), experiments demonstrate the existence of OCR-sensitive regions and show improvements in NER performance on historical newspapers and classical commentaries, highlighting the potential of targeted neuron modulation to improve models' performance on noisy text.

[Arxiv](https://arxiv.org/abs/2409.16934)