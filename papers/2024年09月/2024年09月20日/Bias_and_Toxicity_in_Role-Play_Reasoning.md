# 角色扮演推理中的偏见与毒性

发布时间：2024年09月20日

`LLM应用` `人工智能`

> Bias and Toxicity in Role-Play Reasoning

# 摘要

> 在大语言模型中，角色扮演技术至关重要，它帮助模型从特定视角出发，生成更相关、更准确的回答。通过模拟不同角色，模型在各种 NLP 任务中的推理能力得到提升，输出更贴合多样场景。然而，我们发现角色扮演也潜藏风险。通过让模型扮演不同角色并在包含刻板印象和有害问题的基准测试中进行评估，我们发现角色扮演往往增加了生成刻板印象和有害内容的可能性，尽管实验结果波动较大。

> Role-play in the Large Language Model (LLM) is a crucial technique that enables models to adopt specific perspectives, enhancing their ability to generate contextually relevant and accurate responses. By simulating different roles, theis approach improves reasoning capabilities across various NLP benchmarks, making the model's output more aligned with diverse scenarios. However, in this work, we demonstrate that role-play also carries potential risks. We systematically evaluate the impact of role-play by asking the language model to adopt different roles and testing it on multiple benchmarks that contain stereotypical and harmful questions. Despite the significant fluctuations in the benchmark results in different experiments, we find that applying role-play often increases the overall likelihood of generating stereotypical and harmful outputs.

[Arxiv](https://arxiv.org/abs/2409.13979)