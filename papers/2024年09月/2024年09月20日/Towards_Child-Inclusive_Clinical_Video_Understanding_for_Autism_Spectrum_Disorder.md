# 探索自闭症谱系障碍儿童的临床视频理解

发布时间：2024年09月20日

`LLM应用` `人工智能`

> Towards Child-Inclusive Clinical Video Understanding for Autism Spectrum Disorder

# 摘要

> 自闭症谱系障碍的临床视频通常记录了儿童与护理人员或临床专业人员之间的长时间互动，涉及复杂的言语和非言语行为。通过客观分析这些视频，可以为自闭症儿童的行为研究提供深入见解。然而，手动编码这些视频既耗时又需要专业知识。因此，计算方法捕捉这些互动显得尤为重要，它不仅能减轻人工负担，还能辅助诊断。我们在这项研究中，探索了在语音、视频和文本三种模态中使用基础模型来分析儿童互动。我们提出了一种结合多模态数据的方法，利用大型语言模型作为推理工具。通过在活动识别和异常行为检测两个任务上的评估，我们发现多模态方法不仅增强了模型的鲁棒性，还在临床视频分析中表现出色，优于单模态分析。

> Clinical videos in the context of Autism Spectrum Disorder are often long-form interactions between children and caregivers/clinical professionals, encompassing complex verbal and non-verbal behaviors. Objective analyses of these videos could provide clinicians and researchers with nuanced insights into the behavior of children with Autism Spectrum Disorder. Manually coding these videos is a time-consuming task and requires a high level of domain expertise. Hence, the ability to capture these interactions computationally can augment the manual effort and enable supporting the diagnostic procedure. In this work, we investigate the use of foundation models across three modalities: speech, video, and text, to analyse child-focused interaction sessions. We propose a unified methodology to combine multiple modalities by using large language models as reasoning agents. We evaluate their performance on two tasks with different information granularity: activity recognition and abnormal behavior detection. We find that the proposed multimodal pipeline provides robustness to modality-specific limitations and improves performance on the clinical video analysis compared to unimodal settings.

[Arxiv](https://arxiv.org/abs/2409.13606)