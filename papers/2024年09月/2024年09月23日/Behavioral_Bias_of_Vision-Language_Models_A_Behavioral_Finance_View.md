# 视觉-语言模型的行为偏差：从行为金融的角度探讨

发布时间：2024年09月23日

`LLM应用` `心理学`

> Behavioral Bias of Vision-Language Models: A Behavioral Finance View

# 摘要

> 随着 LLMs 融入视觉模块，LVLMs 迅速进化，旨在打造更人性化的模型。然而，我们需谨慎评估其在各领域的应用，因其可能潜藏不受欢迎的偏见。本研究从行为金融视角出发，探讨 LVLMs 的行为偏见，这一跨学科领域融合了金融与心理学。我们构建了从数据采集到新评估指标的端到端框架，以剖析 LVLMs 的推理能力及在近期与权威偏见中的动态表现。评估显示，如 LLaVA-NeXT 等开源 LVLMs 深受这两种偏见影响，而 GPT-4o 则几乎免疫。此发现为开源模型的改进指明了方向。相关代码已公开于 https://github.com/mydcxiao/vlm_behavioral_fin。

> Large Vision-Language Models (LVLMs) evolve rapidly as Large Language Models (LLMs) was equipped with vision modules to create more human-like models. However, we should carefully evaluate their applications in different domains, as they may possess undesired biases. Our work studies the potential behavioral biases of LVLMs from a behavioral finance perspective, an interdisciplinary subject that jointly considers finance and psychology. We propose an end-to-end framework, from data collection to new evaluation metrics, to assess LVLMs' reasoning capabilities and the dynamic behaviors manifested in two established human financial behavioral biases: recency bias and authority bias. Our evaluations find that recent open-source LVLMs such as LLaVA-NeXT, MobileVLM-V2, Mini-Gemini, MiniCPM-Llama3-V 2.5 and Phi-3-vision-128k suffer significantly from these two biases, while the proprietary model GPT-4o is negligibly impacted. Our observations highlight directions in which open-source models can improve. The code is available at https://github.com/mydcxiao/vlm_behavioral_fin.

[Arxiv](https://arxiv.org/abs/2409.15256)