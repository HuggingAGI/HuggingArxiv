# 大型语言模型的端到端图展平技术

发布时间：2024年09月23日

`LLM应用` `图数据处理` `人工智能`

> End-to-End Graph Flattening Method for Large Language Models

# 摘要

> 近年来，LLM 的突破为图数据处理带来了新思路。常见的图展平方法虽然泛化性和可解释性良好，但在长距离场景理解中表现不佳。借鉴人类认知习惯，我们提出了端到端 DAG 路径提示 (EEDP) 方法。实验证明，EEDP 不仅在长距离场景中提升了 LLM 的推理能力，还在短距离场景中保持了优异表现，展现了出色的鲁棒性。

> In recent years, the breakthrough of Large Language Models (LLMs) offers new ideas for achieving universal methods on graph data. The common practice of converting graphs into natural language for LLMs, which refers to graph flattening, exhibits good generalizability and interpretability. However, the poor organization of the textual format results in poor performance in long-distance scenario understanding. Inspired by human cognitive reasoning habits, we propose a novel method for graph flattening to fit LLMs, termed as End-to-End DAG-Path prompting (EEDP). Experiments on real-world datasets show that EEDP enhances the reasoning performance of LLMs in long-distance scenarios while maintaining excellent performance in short-distance scenarios, demonstrating good robustness in the face of distance variations.

[Arxiv](https://arxiv.org/abs/2409.14880)