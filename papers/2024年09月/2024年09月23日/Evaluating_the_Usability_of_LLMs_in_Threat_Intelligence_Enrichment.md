# 探究大型语言模型在威胁情报增强中的实用性

发布时间：2024年09月23日

`LLM应用` `网络安全` `威胁情报`

> Evaluating the Usability of LLMs in Threat Intelligence Enrichment

# 摘要

> 大型语言模型 (LLM) 通过自动化威胁数据的收集、预处理和分析，有望大幅提升威胁情报能力。然而，这些工具的易用性对于安全专业人员的有效采用至关重要。尽管 LLM 技术先进，但其可靠性、准确性及可能生成错误信息的问题仍令人担忧。本研究针对 ChatGPT、Gemini、Cohere、Copilot 和 Meta AI 五个 LLM，从用户界面设计、错误处理、学习曲线、性能及与现有工具的集成等方面，进行了全面的可用性评估。通过启发式演练和用户研究，我们揭示了关键的可用性问题，并提出了改进建议。我们的目标是通过提升 LLM 的用户友好性和可靠性，推动更高效、准确的威胁情报实践。

> Large Language Models (LLMs) have the potential to significantly enhance threat intelligence by automating the collection, preprocessing, and analysis of threat data. However, the usability of these tools is critical to ensure their effective adoption by security professionals. Despite the advanced capabilities of LLMs, concerns about their reliability, accuracy, and potential for generating inaccurate information persist. This study conducts a comprehensive usability evaluation of five LLMs ChatGPT, Gemini, Cohere, Copilot, and Meta AI focusing on their user interface design, error handling, learning curve, performance, and integration with existing tools in threat intelligence enrichment. Utilizing a heuristic walkthrough and a user study methodology, we identify key usability issues and offer actionable recommendations for improvement. Our findings aim to bridge the gap between LLM functionality and user experience, thereby promoting more efficient and accurate threat intelligence practices by ensuring these tools are user-friendly and reliable.

[Arxiv](https://arxiv.org/abs/2409.15072)