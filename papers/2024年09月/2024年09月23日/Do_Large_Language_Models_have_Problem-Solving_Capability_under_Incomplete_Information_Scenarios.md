# 大型语言模型在信息缺失时，是否仍能解决问题？

发布时间：2024年09月23日

`LLM应用` `人工智能`

> Do Large Language Models have Problem-Solving Capability under Incomplete Information Scenarios?

# 摘要

> 在不完全信息场景下，大型语言模型（LLM）的问题解决能力评估日益重要，涉及提问、知识搜索、错误检测和路径规划等多方面。现有研究多聚焦于“二十问”等游戏，但这些游戏未涉及识别误导线索，而这是不完全信息场景中的关键。此外，“谁是卧底”等游戏主观性强，评估难度大。为此，我们设计了基于“谁是卧底”和“二十问”的新游戏——BrainKing，用于评估LLM在不完全信息场景下的能力。BrainKing要求LLM通过有限的“是或否”问题和潜在误导答案识别目标实体，并设有简单、中等、困难三种难度模式，全面评估LLM表现。研究结果揭示了LLM在BrainKing中的优劣，为LLM问题解决能力提供了宝贵见解。

> The evaluation of the problem-solving capability under incomplete information scenarios of Large Language Models (LLMs) is increasingly important, encompassing capabilities such as questioning, knowledge search, error detection, and path planning. Current research mainly focus on LLMs' problem-solving capability such as ``Twenty Questions''. However, these kinds of games do not require recognizing misleading cues which are necessary in the incomplete information scenario. Moreover, the existing game such as ``Who is undercover'' are highly subjective, making it challenging for evaluation. Therefore, in this paper, we introduce a novel game named BrainKing based on the ``Who is undercover'' and ``Twenty Questions'' for evaluating LLM capabilities under incomplete information scenarios. It requires LLMs to identify target entities with limited yes-or-no questions and potential misleading answers. By setting up easy, medium, and hard difficulty modes, we comprehensively assess the performance of LLMs across various aspects. Our results reveal the capabilities and limitations of LLMs in BrainKing, providing significant insights of LLM problem-solving levels.

[Arxiv](https://arxiv.org/abs/2409.14762)