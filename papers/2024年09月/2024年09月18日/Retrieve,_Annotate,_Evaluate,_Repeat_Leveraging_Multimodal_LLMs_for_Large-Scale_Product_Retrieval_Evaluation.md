# 检索、注释、评估、循环：借助多模态 LLM 实现大规模产品检索的精准评估

发布时间：2024年09月18日

`LLM应用` `质量控制`

> Retrieve, Annotate, Evaluate, Repeat: Leveraging Multimodal LLMs for Large-Scale Product Retrieval Evaluation

# 摘要

> 评估大规模生产级检索系统虽关键但具挑战，因训练有素的人类注释者稀缺。大型语言模型 (LLM) 有望解决此问题，成为注释任务的可行替代。本文提出框架，利用多模态 LLM 评估电商产品搜索引擎，生成定制注释指南并执行注释任务。经大型电商平台验证，该方法质量媲美人类，大幅节省时间成本，助力快速问题发现，为大规模生产级质量控制提供有效方案。

> Evaluating production-level retrieval systems at scale is a crucial yet challenging task due to the limited availability of a large pool of well-trained human annotators. Large Language Models (LLMs) have the potential to address this scaling issue and offer a viable alternative to humans for the bulk of annotation tasks. In this paper, we propose a framework for assessing the product search engines in a large-scale e-commerce setting, leveraging Multimodal LLMs for (i) generating tailored annotation guidelines for individual queries, and (ii) conducting the subsequent annotation task. Our method, validated through deployment on a large e-commerce platform, demonstrates comparable quality to human annotations, significantly reduces time and cost, facilitates rapid problem discovery, and provides an effective solution for production-level quality control at scale.

[Arxiv](https://arxiv.org/abs/2409.11860)