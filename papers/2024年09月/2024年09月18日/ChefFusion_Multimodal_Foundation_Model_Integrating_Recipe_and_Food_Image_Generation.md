# ChefFusion：一款融合食谱与食物图像生成的多模态基础模型

发布时间：2024年09月18日

`LLM应用` `人工智能`

> ChefFusion: Multimodal Foundation Model Integrating Recipe and Food Image Generation

# 摘要

> 尽管食品计算领域已有大量研究，但大多集中在单一任务上，如从食品标题和成分生成指令（t2t）、从图像生成食谱（i2t）或从食谱生成图像（t2i）。为填补这一空白，我们推出了一个真正多模态的食品计算基础模型，涵盖 t2t、t2i、i2t、it2t 和 t2ti 等多项任务。借助大型语言模型（LLM）和预训练的图像编码器与解码器，该模型能处理食品理解、识别、食谱生成及图像生成等多样化任务。相较于以往模型，ChefFusion 展现出更广泛的应用能力，尤其在食品图像和食谱生成方面表现卓越。我们已在 GitHub 上开源 ChefFusion。

> Significant work has been conducted in the domain of food computing, yet these studies typically focus on single tasks such as t2t (instruction generation from food titles and ingredients), i2t (recipe generation from food images), or t2i (food image generation from recipes). None of these approaches integrate all modalities simultaneously. To address this gap, we introduce a novel food computing foundation model that achieves true multimodality, encompassing tasks such as t2t, t2i, i2t, it2t, and t2ti. By leveraging large language models (LLMs) and pre-trained image encoder and decoder models, our model can perform a diverse array of food computing-related tasks, including food understanding, food recognition, recipe generation, and food image generation. Compared to previous models, our foundation model demonstrates a significantly broader range of capabilities and exhibits superior performance, particularly in food image generation and recipe generation tasks. We open-sourced ChefFusion at GitHub.

[Arxiv](https://arxiv.org/abs/2409.12010)