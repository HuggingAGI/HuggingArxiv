# AraDiCE：评估 LLM 方言与文化能力的基准

发布时间：2024年09月17日

`LLM应用` `语言学` `人工智能`

> AraDiCE: Benchmarks for Dialectal and Cultural Capabilities in LLMs

# 摘要

> 阿拉伯语的丰富方言多样性在大语言模型中仍未得到充分体现，尤其是在方言变体方面。为此，我们引入了七个合成数据集，涵盖现代标准阿拉伯语（MSA）及多种方言，这些数据集通过机器翻译与人工后期编辑相结合创建。我们推出了AraDiCE，一个专为阿拉伯方言和文化评估设计的基准。我们特别关注低资源阿拉伯方言，评估LLM在方言理解和生成方面的表现。此外，我们还首次推出了细粒度基准，用于评估海湾、埃及和黎凡特地区的文化意识，为LLM评估增添了新维度。研究显示，尽管阿拉伯语特定模型如Jais和AceGPT在方言任务上表现优异，但在方言识别、生成和翻译方面仍面临挑战。本研究贡献了约45K个后期编辑样本及一个文化基准，强调了定制训练对于提升LLM捕捉阿拉伯方言和文化细微差别的重要性。我们将公开本研究中的方言翻译模型和基准。

> Arabic, with its rich diversity of dialects, remains significantly underrepresented in Large Language Models, particularly in dialectal variations. We address this gap by introducing seven synthetic datasets in dialects alongside Modern Standard Arabic (MSA), created using Machine Translation (MT) combined with human post-editing. We present AraDiCE, a benchmark for Arabic Dialect and Cultural Evaluation. We evaluate LLMs on dialect comprehension and generation, focusing specifically on low-resource Arabic dialects. Additionally, we introduce the first-ever fine-grained benchmark designed to evaluate cultural awareness across the Gulf, Egypt, and Levant regions, providing a novel dimension to LLM evaluation. Our findings demonstrate that while Arabic-specific models like Jais and AceGPT outperform multilingual models on dialectal tasks, significant challenges persist in dialect identification, generation, and translation. This work contributes ~45K post-edited samples, a cultural benchmark, and highlights the importance of tailored training to improve LLM performance in capturing the nuances of diverse Arabic dialects and cultural contexts. We will release the dialectal translation models and benchmarks curated in this study.

[Arxiv](https://arxiv.org/abs/2409.11404)