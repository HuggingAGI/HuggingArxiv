# 多模态复合编辑与检索综述

发布时间：2024年09月09日

`LLM应用` `信息检索` `多模态学习`

> A Survey of Multimodal Composite Editing and Retrieval

# 摘要

> 在信息丰富多样的现实世界中，如何利用各种数据类型提升检索系统性能，是研究的核心课题。多模态复合检索通过整合文本、图像、音频等多种模态，提供更精准、个性化且上下文相关的结果。为深入探讨这一前沿领域，本调查详细分析了多模态复合编辑与检索，包括图像-文本复合编辑、检索等。我们系统梳理了应用场景、方法、基准、实验及未来方向。多模态学习在大模型时代备受瞩目，已有相关调查发表于PAMI期刊。据我们所知，本调查首次全面回顾了多模态复合检索文献，是对现有评论的及时补充。为方便读者追踪，我们特设项目页面，详见https://github.com/fuxianghuang1/Multimodal-Composite-Editing-and-Retrieval。

> In the real world, where information is abundant and diverse across different modalities, understanding and utilizing various data types to improve retrieval systems is a key focus of research. Multimodal composite retrieval integrates diverse modalities such as text, image and audio, etc. to provide more accurate, personalized, and contextually relevant results. To facilitate a deeper understanding of this promising direction, this survey explores multimodal composite editing and retrieval in depth, covering image-text composite editing, image-text composite retrieval, and other multimodal composite retrieval. In this survey, we systematically organize the application scenarios, methods, benchmarks, experiments, and future directions. Multimodal learning is a hot topic in large model era, and have also witnessed some surveys in multimodal learning and vision-language models with transformers published in the PAMI journal. To the best of our knowledge, this survey is the first comprehensive review of the literature on multimodal composite retrieval, which is a timely complement of multimodal fusion to existing reviews. To help readers' quickly track this field, we build the project page for this survey, which can be found at https://github.com/fuxianghuang1/Multimodal-Composite-Editing-and-Retrieval.

[Arxiv](https://arxiv.org/abs/2409.05405)