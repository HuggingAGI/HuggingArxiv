# 大型语言模型会威胁编程平台吗？这是一项探索性研究。

发布时间：2024年09月09日

`LLM应用` `软件开发`

> Are Large Language Models a Threat to Programming Platforms? An Exploratory Study

# 摘要

> 竞争性编程平台如 LeetCode、Codeforces 和 HackerRank 常用于评估编程技能，招聘者也常借此筛选人才。随着 ChatGPT、Gemini 和 Meta AI 等高级 LLM 的崛起，它们在这些平台上的表现值得关注。本研究测试了 LLM 在不同难度平台上的编程挑战能力，分析了它们的实时与离线表现，并与人类程序员进行了对比。我们测试了 LeetCode 的 98 道题和 Codeforces 的 126 道题，涵盖 15 个类别。通过在 Codeforces 和 LeetCode 上的九次在线比赛以及 HackerRank 的两次认证测试，评估了 LLM 的实时性能。我们使用提示和反馈机制引导 LLM，并分析了不同场景下的表现。LLM 如 ChatGPT（在 LeetCode 上成功率为 71.43%）在 LeetCode 和 HackerRank 认证中表现优异，但在虚拟比赛中，尤其是在 Codeforces 上表现不佳。尽管在 LeetCode 档案中表现优于人类，时间和内存效率出色，但在更难的 Codeforces 比赛中表现欠佳。虽然目前 LLM 的表现尚不构成直接威胁，但其潜力和未来改进仍需关注。

> Competitive programming platforms like LeetCode, Codeforces, and HackerRank evaluate programming skills, often used by recruiters for screening. With the rise of advanced Large Language Models (LLMs) such as ChatGPT, Gemini, and Meta AI, their problem-solving ability on these platforms needs assessment. This study explores LLMs' ability to tackle diverse programming challenges across platforms with varying difficulty, offering insights into their real-time and offline performance and comparing them with human programmers.
  We tested 98 problems from LeetCode, 126 from Codeforces, covering 15 categories. Nine online contests from Codeforces and LeetCode were conducted, along with two certification tests on HackerRank, to assess real-time performance. Prompts and feedback mechanisms were used to guide LLMs, and correlations were explored across different scenarios.
  LLMs, like ChatGPT (71.43% success on LeetCode), excelled in LeetCode and HackerRank certifications but struggled in virtual contests, particularly on Codeforces. They performed better than users in LeetCode archives, excelling in time and memory efficiency but underperforming in harder Codeforces contests. While not immediately threatening, LLMs performance on these platforms is concerning, and future improvements will need addressing.

[Arxiv](https://arxiv.org/abs/2409.05824)