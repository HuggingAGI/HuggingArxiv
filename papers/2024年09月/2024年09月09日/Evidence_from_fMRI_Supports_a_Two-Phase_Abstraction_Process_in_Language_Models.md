# fMRI 研究揭示，语言模型采用两阶段抽象过程，这一发现为理解语言处理机制提供了新视角。

发布时间：2024年09月09日

`LLM理论` `神经科学` `人工智能`

> Evidence from fMRI Supports a Two-Phase Abstraction Process in Language Models

# 摘要

> 研究表明，大型语言模型的中间隐藏状态能精准预测大脑对自然语言的反应。然而，这种高预测性能背后的表示特性仍鲜为人知。为何是中间层而非输出层最能胜任这一独特且通用的任务？我们通过fMRI数据发现，LLMs中存在一个两阶段抽象过程。利用流形学习，我们揭示了这一过程在训练中自然形成，且“组合”阶段随训练深入被压缩。最终，我们发现层级编码性能与表示的内在维度密切相关，这主要归因于LLMs的组合性，而非其预测能力。

> Research has repeatedly demonstrated that intermediate hidden states extracted from large language models are able to predict measured brain response to natural language stimuli. Yet, very little is known about the representation properties that enable this high prediction performance. Why is it the intermediate layers, and not the output layers, that are most capable for this unique and highly general transfer task? In this work, we show that evidence from language encoding models in fMRI supports the existence of a two-phase abstraction process within LLMs. We use manifold learning methods to show that this abstraction process naturally arises over the course of training a language model and that the first "composition" phase of this abstraction process is compressed into fewer layers as training continues. Finally, we demonstrate a strong correspondence between layerwise encoding performance and the intrinsic dimensionality of representations from LLMs. We give initial evidence that this correspondence primarily derives from the inherent compositionality of LLMs and not their next-word prediction properties.

[Arxiv](https://arxiv.org/abs/2409.05771)