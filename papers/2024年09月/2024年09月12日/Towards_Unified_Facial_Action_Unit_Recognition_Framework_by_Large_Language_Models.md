# 借助大型语言模型，迈向统一的面部动作单元识别框架

发布时间：2024年09月12日

`LLM应用` `情感计算` `面部识别`

> Towards Unified Facial Action Unit Recognition Framework by Large Language Models

# 摘要

> 面部动作单元 (AUs) 在情感计算中至关重要。我们提出了 AU-LLaVA，首个基于大型语言模型 (LLM) 的统一 AU 识别框架。AU-LLaVA 结合了视觉编码器、线性投影层和预训练 LLM，通过精心设计的文本描述和多数据集微调，能生成多样化的 AU 识别结果。在 BP4D 和 DISFA 数据集上，AU-LLaVA 在近半数 AUs 上表现最佳，特定 AU 识别的 F1-score 提升高达 11.4%。在 FEAFA 数据集上，所有 24 个 AUs 的识别效果均显著提升。AU-LLaVA 在 AU 识别领域展现了卓越性能和广泛适用性。

> Facial Action Units (AUs) are of great significance in the realm of affective computing. In this paper, we propose AU-LLaVA, the first unified AU recognition framework based on the Large Language Model (LLM). AU-LLaVA consists of a visual encoder, a linear projector layer, and a pre-trained LLM. We meticulously craft the text descriptions and fine-tune the model on various AU datasets, allowing it to generate different formats of AU recognition results for the same input image. On the BP4D and DISFA datasets, AU-LLaVA delivers the most accurate recognition results for nearly half of the AUs. Our model achieves improvements of F1-score up to 11.4% in specific AU recognition compared to previous benchmark results. On the FEAFA dataset, our method achieves significant improvements over all 24 AUs compared to previous benchmark results. AU-LLaVA demonstrates exceptional performance and versatility in AU recognition.

[Arxiv](https://arxiv.org/abs/2409.08444)