# ToolACE：掌握 LLM 功能调用的制胜要素

发布时间：2024年09月01日

`LLM应用` `软件开发` `人工智能`

> ToolACE: Winning the Points of LLM Function Calling

# 摘要

> 函数调用极大地拓宽了大型语言模型的应用领域，高质量且多样化的训练数据是解锁这一能力的关键。然而，真实函数调用数据的收集与标注极具挑战性，合成数据又常因覆盖度和准确性不足而受限。为此，我们推出了ToolACE，一个自动化的数据生成管道，旨在产出精确、复杂且多元的工具学习数据。ToolACE通过独特的自进化合成机制，构建了一个包含26,507个多样API的全面资源池。对话生成则通过多代理间的互动，并遵循严谨的思考流程来实现。为确保数据质量，我们采用了基于规则与模型的双重验证体系。实验表明，即便参数仅为8B的模型，在经过我们合成数据训练后，也能在伯克利函数调用排行榜上与GPT-4并驾齐驱。相关模型及部分数据已公开于https://huggingface.co/Team-ACE。

> Function calling significantly extends the application boundary of large language models, where high-quality and diverse training data is critical for unlocking this capability. However, real function-calling data is quite challenging to collect and annotate, while synthetic data generated by existing pipelines tends to lack coverage and accuracy. In this paper, we present ToolACE, an automatic agentic pipeline designed to generate accurate, complex, and diverse tool-learning data. ToolACE leverages a novel self-evolution synthesis process to curate a comprehensive API pool of 26,507 diverse APIs. Dialogs are further generated through the interplay among multiple agents, guided by a formalized thinking process. To ensure data accuracy, we implement a dual-layer verification system combining rule-based and model-based checks. We demonstrate that models trained on our synthesized data, even with only 8B parameters, achieve state-of-the-art performance on the Berkeley Function-Calling Leaderboard, rivaling the latest GPT-4 models. Our model and a subset of the data are publicly available at https://huggingface.co/Team-ACE.

[Arxiv](https://arxiv.org/abs/2409.00920)