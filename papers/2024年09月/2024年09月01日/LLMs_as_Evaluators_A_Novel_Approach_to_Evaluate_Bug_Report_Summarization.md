# 利用 LLM 评估错误报告摘要：一种创新方法

发布时间：2024年09月01日

`LLM应用` `软件工程` `人工智能`

> LLMs as Evaluators: A Novel Approach to Evaluate Bug Report Summarization

# 摘要

> 软件工件的总结是一个备受关注的研究领域。尽管人类判断在评估软件摘要方法中仍被视为黄金标准，但其耗时且易使评估者疲劳，限制了其可扩展性和可复制性。大型语言模型（LLMs）在软件工程任务中的出色表现，激发了我们探索其作为自动评估工具的潜力。本研究聚焦于LLMs是否能有效评估错误报告摘要。我们设计了一项实验，让一组人类评估者和三个LLMs（GPT-4o、LLaMA-3、Gemini）共同面对一系列错误摘要问题，任务是从多个选项中挑选出正确的错误报告标题和摘要。实验结果表明，LLMs在评估错误报告摘要方面表现出色，尤其是GPT-4o。同时，尽管人类和LLMs的决策一致，但人类的疲劳感随时间推移影响了其准确性。这表明LLMs有潜力成为自动化评估工具，不仅能够扩大评估规模，还能减轻人类评估者的负担和疲劳。

> Summarizing software artifacts is an important task that has been thoroughly researched. For evaluating software summarization approaches, human judgment is still the most trusted evaluation. However, it is time-consuming and fatiguing for evaluators, making it challenging to scale and reproduce. Large Language Models (LLMs) have demonstrated remarkable capabilities in various software engineering tasks, motivating us to explore their potential as automatic evaluators for approaches that aim to summarize software artifacts. In this study, we investigate whether LLMs can evaluate bug report summarization effectively. We conducted an experiment in which we presented the same set of bug summarization problems to humans and three LLMs (GPT-4o, LLaMA-3, and Gemini) for evaluation on two tasks: selecting the correct bug report title and bug report summary from a set of options. Our results show that LLMs performed generally well in evaluating bug report summaries, with GPT-4o outperforming the other LLMs. Additionally, both humans and LLMs showed consistent decision-making, but humans experienced fatigue, impacting their accuracy over time. Our results indicate that LLMs demonstrate potential for being considered as automated evaluators for bug report summarization, which could allow scaling up evaluations while reducing human evaluators effort and fatigue.

[Arxiv](https://arxiv.org/abs/2409.00630)