# LLM 增强的编程错误消息并非万能，实际效果不佳。

发布时间：2024年09月27日

`LLM应用` `软件开发`

> Not the Silver Bullet: LLM-enhanced Programming Error Messages are Ineffective in Practice

# 摘要

> ChatGPT 等大型语言模型的出现，彻底改变了计算教育领域。这些模型不仅能高效生成 CS1 和 CS2 问题的正确代码，还能成为编程初学者的得力助手。最新研究发现，LLM 在解释和解决编译错误方面表现尤为出色，这是编程学习中长期以来的痛点。然而，LLM 生成的错误解释仅在受控环境下由专家评估。本研究旨在探索新手程序员在真实情境下如何应对编程错误。我们邀请 106 名学生参与实验，要求他们修复六个有缺陷的 C 程序。每个程序的修复任务随机分配为使用标准编译错误、专家手写错误或 GPT-4 生成的错误解释。尽管 GPT-4 在合成测试中表现优异，但在实际任务中，其错误解释仅在一项任务中优于传统编译错误。手写解释在客观和主观评价中均表现更佳。

> The sudden emergence of large language models (LLMs) such as ChatGPT has had a disruptive impact throughout the computing education community. LLMs have been shown to excel at producing correct code to CS1 and CS2 problems, and can even act as friendly assistants to students learning how to code. Recent work shows that LLMs demonstrate unequivocally superior results in being able to explain and resolve compiler error messages -- for decades, one of the most frustrating parts of learning how to code. However, LLM-generated error message explanations have only been assessed by expert programmers in artificial conditions. This work sought to understand how novice programmers resolve programming error messages (PEMs) in a more realistic scenario. We ran a within-subjects study with $n$ = 106 participants in which students were tasked to fix six buggy C programs. For each program, participants were randomly assigned to fix the problem using either a stock compiler error message, an expert-handwritten error message, or an error message explanation generated by GPT-4. Despite promising evidence on synthetic benchmarks, we found that GPT-4 generated error messages outperformed conventional compiler error messages in only 1 of the 6 tasks, measured by students' time-to-fix each problem. Handwritten explanations still outperform LLM and conventional error messages, both on objective and subjective measures.

[Arxiv](https://arxiv.org/abs/2409.18661)