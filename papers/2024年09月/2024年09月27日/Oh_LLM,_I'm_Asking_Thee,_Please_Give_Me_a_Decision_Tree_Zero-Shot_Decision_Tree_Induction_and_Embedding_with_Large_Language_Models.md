# “LLM，请赐我一棵决策树”：利用大型语言模型实现零-shot 决策树的归纳与嵌入

发布时间：2024年09月27日

`LLM理论` `机器学习` `数据科学`

> "Oh LLM, I'm Asking Thee, Please Give Me a Decision Tree": Zero-Shot Decision Tree Induction and Embedding with Large Language Models

# 摘要

> 在数据稀缺时，LLM 能利用先验知识进行预测建模。我们展示了 LLM 如何在不使用训练数据的情况下，生成可解释的决策树模型。这些零-shot 决策树在一些小型数据集上表现优异，其嵌入效果与数据驱动的方法相当。因此，我们的知识驱动方法为低数据环境下的机器学习提供了强有力的基准。

> Large language models (LLMs) provide powerful means to leverage prior knowledge for predictive modeling when data is limited. In this work, we demonstrate how LLMs can use their compressed world knowledge to generate intrinsically interpretable machine learning models, i.e., decision trees, without any training data. We find that these zero-shot decision trees can surpass data-driven trees on some small-sized tabular datasets and that embeddings derived from these trees perform on par with data-driven tree-based embeddings on average. Our knowledge-driven decision tree induction and embedding approaches therefore serve as strong new baselines for data-driven machine learning methods in the low-data regime.

[Arxiv](https://arxiv.org/abs/2409.18594)