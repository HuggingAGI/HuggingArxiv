# 大型语言模型在软件漏洞检测中的应用：一次深入全面的基准研究

发布时间：2024年05月24日

`LLM应用

理由：这篇论文主要探讨了如何利用大型语言模型（LLMs）来辅助源代码漏洞的发现，评估了多种顶尖 LLMs 的性能，并探索了最佳提示策略以最大化 LLMs 的价值。这与 LLM 在实际应用中的使用直接相关，特别是在软件开发和安全分析领域，因此属于LLM应用分类。` `软件开发` `网络安全`

> Harnessing Large Language Models for Software Vulnerability Detection: A Comprehensive Benchmarking Study

# 摘要

> 尽管检测漏洞的方法多种多样，但报告的漏洞数量却逐年攀升，暗示着许多问题在代码发布前未能被捕捉。这可能源于意识不足、现有工具效能有限或用户体验不佳。为此，我们提出利用大型语言模型（LLMs）来辅助源代码漏洞的发现。LLMs 在理解和生成代码方面的能力令人瞩目，预示着其在代码任务中的巨大潜力。我们的研究旨在评估多种顶尖 LLMs，并探索最佳提示策略，以最大化 LLMs 的价值。我们分析了基于 LLM 的方法的优劣，并与传统静态分析工具进行了对比。结果显示，LLMs 在发现漏洞方面远超传统工具，无论是在召回率还是 F1 分数上均表现出色。这些发现无疑将为确保代码安全的软件开发者和安全分析师带来裨益。

> Despite various approaches being employed to detect vulnerabilities, the number of reported vulnerabilities shows an upward trend over the years. This suggests the problems are not caught before the code is released, which could be caused by many factors, like lack of awareness, limited efficacy of the existing vulnerability detection tools or the tools not being user-friendly. To help combat some issues with traditional vulnerability detection tools, we propose using large language models (LLMs) to assist in finding vulnerabilities in source code. LLMs have shown a remarkable ability to understand and generate code, underlining their potential in code-related tasks. The aim is to test multiple state-of-the-art LLMs and identify the best prompting strategies, allowing extraction of the best value from the LLMs. We provide an overview of the strengths and weaknesses of the LLM-based approach and compare the results to those of traditional static analysis tools. We find that LLMs can pinpoint many more issues than traditional static analysis tools, outperforming traditional tools in terms of recall and F1 scores. The results should benefit software developers and security analysts responsible for ensuring that the code is free of vulnerabilities.

[Arxiv](https://arxiv.org/abs/2405.15614)