# 构建论辩型大型语言模型，旨在实现决策过程的可解释性和可争议性。

发布时间：2024年05月03日

`LLM应用` `决策支持系统` `人工智能`

> Argumentative Large Language Models for Explainable and Contestable Decision-Making

# 摘要

> 大型语言模型（LLMs）蕴含的丰富知识及其在多种情境下零样本应用这些知识的能力，让它们在决策领域展现出巨大潜力。然而，它们目前还无法稳定地提供既合理又可辩驳的输出结果。本文提出了一种新方法，旨在通过引入论证推理来弥补LLMs的这一不足。具体而言，我们提出了论证性LLMs的概念，这是一种利用LLMs构建论证框架的技术，这些框架随后成为决策过程中正式推理的基础。由于论证框架的透明性和推理过程的规范性，补充后的LLM所做出的决策可以被人类自然而然地理解和质疑。我们在决策领域的索赔验证任务中对论证性LLMs进行了实验验证，结果显示其效果与现有最先进技术相媲美，甚至在某些情况下更胜一筹。

> The diversity of knowledge encoded in large language models (LLMs) and their ability to apply this knowledge zero-shot in a range of settings makes them a promising candidate for use in decision-making. However, they are currently limited by their inability to reliably provide outputs which are explainable and contestable. In this paper, we attempt to reconcile these strengths and weaknesses by introducing a method for supplementing LLMs with argumentative reasoning. Concretely, we introduce argumentative LLMs, a method utilising LLMs to construct argumentation frameworks, which then serve as the basis for formal reasoning in decision-making. The interpretable nature of these argumentation frameworks and formal reasoning means that any decision made by the supplemented LLM may be naturally explained to, and contested by, humans. We demonstrate the effectiveness of argumentative LLMs experimentally in the decision-making task of claim verification. We obtain results that are competitive with, and in some cases surpass, comparable state-of-the-art techniques.

[Arxiv](https://arxiv.org/abs/2405.02079)