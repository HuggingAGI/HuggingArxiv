# 2024年05月

2024年05月31日

- [DeCo: Decoupling Token Compression from Semantic Abstraction in Multimodal Large Language Models](2024年05月31日/DeCo_Decoupling_Token_Compression_from_Semantic_Abstraction_in_Multimodal_Large_Language_Models.md)

    - [翻译: DeCo：解耦多模态大型语言模型中的令牌压缩与语义抽象](2024年05月31日/DeCo_Decoupling_Token_Compression_from_Semantic_Abstraction_in_Multimodal_Large_Language_Models.md)

- [Retrieval Meets Reasoning: Even High-school Textbook Knowledge Benefits Multimodal Reasoning](2024年05月31日/Retrieval_Meets_Reasoning_Even_High-school_Textbook_Knowledge_Benefits_Multimodal_Reasoning.md)

    - [翻译: 知识检索与推理的结合：高中课本知识亦能助力多模态推理的深化](2024年05月31日/Retrieval_Meets_Reasoning_Even_High-school_Textbook_Knowledge_Benefits_Multimodal_Reasoning.md)

- [Video-MME: The First-Ever Comprehensive Evaluation Benchmark of Multi-modal LLMs in Video Analysis](2024年05月31日/Video-MME_The_First-Ever_Comprehensive_Evaluation_Benchmark_of_Multi-modal_LLMs_in_Video_Analysis.md)

    - [翻译: 视频-MME：开创性全面评估多模态LLMs在视频分析领域的基准](2024年05月31日/Video-MME_The_First-Ever_Comprehensive_Evaluation_Benchmark_of_Multi-modal_LLMs_in_Video_Analysis.md)

- [Code Pretraining Improves Entity Tracking Abilities of Language Models](2024年05月31日/Code_Pretraining_Improves_Entity_Tracking_Abilities_of_Language_Models.md)

    - [翻译: 通过代码预训练，语言模型在实体追踪上的表现得到了显著提升。](2024年05月31日/Code_Pretraining_Improves_Entity_Tracking_Abilities_of_Language_Models.md)

- [Grammar-Aligned Decoding](2024年05月31日/Grammar-Aligned_Decoding.md)

    - [翻译: 语法对齐解码法](2024年05月31日/Grammar-Aligned_Decoding.md)

- [Direct Alignment of Language Models via Quality-Aware Self-Refinement](2024年05月31日/Direct_Alignment_of_Language_Models_via_Quality-Aware_Self-Refinement.md)

    - [翻译: 语言模型通过质量感知自我精炼实现直接对齐](2024年05月31日/Direct_Alignment_of_Language_Models_via_Quality-Aware_Self-Refinement.md)

- [Standards for Belief Representations in LLMs](2024年05月31日/Standards_for_Belief_Representations_in_LLMs.md)

    - [翻译: 大型语言模型中信念表达的规范](2024年05月31日/Standards_for_Belief_Representations_in_LLMs.md)

- [LACIE: Listener-Aware Finetuning for Confidence Calibration in Large Language Models](2024年05月31日/LACIE_Listener-Aware_Finetuning_for_Confidence_Calibration_in_Large_Language_Models.md)

    - [翻译: LACIE：大型语言模型中信心校准的听众感知微调策略](2024年05月31日/LACIE_Listener-Aware_Finetuning_for_Confidence_Calibration_in_Large_Language_Models.md)

- [Improved Techniques for Optimization-Based Jailbreaking on Large Language Models](2024年05月31日/Improved_Techniques_for_Optimization-Based_Jailbreaking_on_Large_Language_Models.md)

    - [翻译: 优化型越狱技术在大规模语言模型上的新进展](2024年05月31日/Improved_Techniques_for_Optimization-Based_Jailbreaking_on_Large_Language_Models.md)

- [Enhancing Noise Robustness of Retrieval-Augmented Language Models with Adaptive Adversarial Training](2024年05月31日/Enhancing_Noise_Robustness_of_Retrieval-Augmented_Language_Models_with_Adaptive_Adversarial_Training.md)

    - [翻译: 利用自适应对抗训练提升检索增强型语言模型对噪声的抵抗力](2024年05月31日/Enhancing_Noise_Robustness_of_Retrieval-Augmented_Language_Models_with_Adaptive_Adversarial_Training.md)

- [SaySelf: Teaching LLMs to Express Confidence with Self-Reflective Rationales](2024年05月31日/SaySelf_Teaching_LLMs_to_Express_Confidence_with_Self-Reflective_Rationales.md)

    - [翻译: SaySelf：培养大型语言模型通过自我反思的理性来表达自信](2024年05月31日/SaySelf_Teaching_LLMs_to_Express_Confidence_with_Self-Reflective_Rationales.md)

- [LCQ: Low-Rank Codebook based Quantization for Large Language Models](2024年05月31日/LCQ_Low-Rank_Codebook_based_Quantization_for_Large_Language_Models.md)

    - [翻译: LCQ：大型语言模型的低秩码本量化技术](2024年05月31日/LCQ_Low-Rank_Codebook_based_Quantization_for_Large_Language_Models.md)

- [Large Language Models are Zero-Shot Next Location Predictors](2024年05月31日/Large_Language_Models_are_Zero-Shot_Next_Location_Predictors.md)

    - [翻译: 大型语言模型具备零-shot 预测下一次位置的能力。](2024年05月31日/Large_Language_Models_are_Zero-Shot_Next_Location_Predictors.md)

- [A Robot Walks into a Bar: Can Language Models Serve asCreativity Support Tools for Comedy? An Evaluation of LLMs' Humour Alignment with Comedians](2024年05月31日/A_Robot_Walks_into_a_Bar_Can_Language_Models_Serve_asCreativity_Support_Tools_for_Comedy_An_Evaluation_of_LLMs'_Humour_Alignment_with_Comedians.md)

    - [翻译: 机器人酒吧奇遇记：探究语言模型是否能成为喜剧创作的得力助手，评估其幽默感与喜剧演员的契合度。](2024年05月31日/A_Robot_Walks_into_a_Bar_Can_Language_Models_Serve_asCreativity_Support_Tools_for_Comedy_An_Evaluation_of_LLMs'_Humour_Alignment_with_Comedians.md)

- [OR-Bench: An Over-Refusal Benchmark for Large Language Models](2024年05月31日/OR-Bench_An_Over-Refusal_Benchmark_for_Large_Language_Models.md)

    - [翻译: OR-Bench：大型语言模型的过度拒绝评估基准](2024年05月31日/OR-Bench_An_Over-Refusal_Benchmark_for_Large_Language_Models.md)

- [Preemptive Answer "Attacks" on Chain-of-Thought Reasoning](2024年05月31日/Preemptive_Answer_Attacks_on_Chain-of-Thought_Reasoning.md)

    - [翻译: 思维链推理遭遇预先回答“攻击”挑战](2024年05月31日/Preemptive_Answer_Attacks_on_Chain-of-Thought_Reasoning.md)

- [Large Language Models: A New Approach for Privacy Policy Analysis at Scale](2024年05月31日/Large_Language_Models_A_New_Approach_for_Privacy_Policy_Analysis_at_Scale.md)

    - [翻译: 大型语言模型：开启大规模隐私政策分析的新篇章](2024年05月31日/Large_Language_Models_A_New_Approach_for_Privacy_Policy_Analysis_at_Scale.md)

- [clembench-2024: A Challenging, Dynamic, Complementary, Multilingual Benchmark and Underlying Flexible Framework for LLMs as Multi-Action Agents](2024年05月31日/clembench-2024_A_Challenging,_Dynamic,_Complementary,_Multilingual_Benchmark_and_Underlying_Flexible_Framework_for_LLMs_as_Multi-Action_Agents.md)

    - [翻译: clembench-2024：一款挑战性十足、动态互补的多语言基准，其灵活的底层框架旨在将大型语言模型（LLMs）打造为高效的多动作代理。](2024年05月31日/clembench-2024_A_Challenging,_Dynamic,_Complementary,_Multilingual_Benchmark_and_Underlying_Flexible_Framework_for_LLMs_as_Multi-Action_Agents.md)

- [MeshXL: Neural Coordinate Field for Generative 3D Foundation Models](2024年05月31日/MeshXL_Neural_Coordinate_Field_for_Generative_3D_Foundation_Models.md)

    - [翻译: MeshXL：打造3D基础模型的神经坐标场之光](2024年05月31日/MeshXL_Neural_Coordinate_Field_for_Generative_3D_Foundation_Models.md)

- [Improving Reward Models with Synthetic Critiques](2024年05月31日/Improving_Reward_Models_with_Synthetic_Critiques.md)

    - [翻译: 借助合成评论优化奖励模型](2024年05月31日/Improving_Reward_Models_with_Synthetic_Critiques.md)

- [Outliers and Calibration Sets have Diminishing Effect on Quantization of Modern LLMs](2024年05月31日/Outliers_and_Calibration_Sets_have_Diminishing_Effect_on_Quantization_of_Modern_LLMs.md)

    - [翻译: 现代大型语言模型的量化过程中，离群值与校准集的影响正逐渐减弱。](2024年05月31日/Outliers_and_Calibration_Sets_have_Diminishing_Effect_on_Quantization_of_Modern_LLMs.md)

- [That's Optional: A Contemporary Exploration of "that" Omission in English Subordinate Clauses](2024年05月31日/That's_Optional_A_Contemporary_Exploration_of_that_Omission_in_English_Subordinate_Clauses.md)

    - [翻译: 《“that”可省略：当代英语从句中“that”省略现象的现代探索》](2024年05月31日/That's_Optional_A_Contemporary_Exploration_of_that_Omission_in_English_Subordinate_Clauses.md)

- [Multilingual Text Style Transfer: Datasets & Models for Indian Languages](2024年05月31日/Multilingual_Text_Style_Transfer_Datasets_&_Models_for_Indian_Languages.md)

    - [翻译: 探索印度语言的多语言文本风格转换：数据集与模型概览](2024年05月31日/Multilingual_Text_Style_Transfer_Datasets_&_Models_for_Indian_Languages.md)

- [Ovis: Structural Embedding Alignment for Multimodal Large Language Model](2024年05月31日/Ovis_Structural_Embedding_Alignment_for_Multimodal_Large_Language_Model.md)

    - [翻译: Ovis：多模态大型语言模型的结构嵌入精准对齐](2024年05月31日/Ovis_Structural_Embedding_Alignment_for_Multimodal_Large_Language_Model.md)

- [Improving code-mixed hate detection by native sample mixing: A case study for Hindi-English code-mixed scenario](2024年05月31日/Improving_code-mixed_hate_detection_by_native_sample_mixing_A_case_study_for_Hindi-English_code-mixed_scenario.md)

    - [翻译: 本研究探讨了通过本地样本混合策略提升印地语-英语混合文本中的仇恨言论检测效果，为跨语言环境下的内容监管提供了新的视角。](2024年05月31日/Improving_code-mixed_hate_detection_by_native_sample_mixing_A_case_study_for_Hindi-English_code-mixed_scenario.md)

- [Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement](2024年05月31日/Unveiling_the_Lexical_Sensitivity_of_LLMs_Combinatorial_Optimization_for_Prompt_Enhancement.md)

    - [翻译: 揭秘LLMs的词汇敏感度：通过组合优化提升提示效果](2024年05月31日/Unveiling_the_Lexical_Sensitivity_of_LLMs_Combinatorial_Optimization_for_Prompt_Enhancement.md)

- [Joint Embeddings for Graph Instruction Tuning](2024年05月31日/Joint_Embeddings_for_Graph_Instruction_Tuning.md)

    - [翻译: 图指令调优中的联合嵌入](2024年05月31日/Joint_Embeddings_for_Graph_Instruction_Tuning.md)

- [No Free Lunch Theorem for Privacy-Preserving LLM Inference](2024年05月31日/No_Free_Lunch_Theorem_for_Privacy-Preserving_LLM_Inference.md)

    - [翻译: 大型语言模型隐私保护推理的“无免费午餐”定理](2024年05月31日/No_Free_Lunch_Theorem_for_Privacy-Preserving_LLM_Inference.md)

- [Unraveling and Mitigating Retriever Inconsistencies in Retrieval-Augmented Large Language Models](2024年05月31日/Unraveling_and_Mitigating_Retriever_Inconsistencies_in_Retrieval-Augmented_Large_Language_Models.md)

    - [翻译: 探究与解决大型语言模型中检索增强机制的检索器不一致问题](2024年05月31日/Unraveling_and_Mitigating_Retriever_Inconsistencies_in_Retrieval-Augmented_Large_Language_Models.md)

- [DORY: Deliberative Prompt Recovery for LLM](2024年05月31日/DORY_Deliberative_Prompt_Recovery_for_LLM.md)

    - [翻译: DORY：大型语言模型的深思熟虑提示恢复机制](2024年05月31日/DORY_Deliberative_Prompt_Recovery_for_LLM.md)

- [Passage-specific Prompt Tuning for Passage Reranking in Question Answering with Large Language Models](2024年05月31日/Passage-specific_Prompt_Tuning_for_Passage_Reranking_in_Question_Answering_with_Large_Language_Models.md)

    - [翻译: 大型语言模型问答中的段落重排序：特定段落提示调整策略](2024年05月31日/Passage-specific_Prompt_Tuning_for_Passage_Reranking_in_Question_Answering_with_Large_Language_Models.md)

- [Enhancing Jailbreak Attack Against Large Language Models through Silent Tokens](2024年05月31日/Enhancing_Jailbreak_Attack_Against_Large_Language_Models_through_Silent_Tokens.md)

    - [翻译: 利用无声标记提升对大型语言模型的越狱攻击能力](2024年05月31日/Enhancing_Jailbreak_Attack_Against_Large_Language_Models_through_Silent_Tokens.md)

- [Shotluck Holmes: A Family of Efficient Small-Scale Large Language Vision Models For Video Captioning and Summarization](2024年05月31日/Shotluck_Holmes_A_Family_of_Efficient_Small-Scale_Large_Language_Vision_Models_For_Video_Captioning_and_Summarization.md)

    - [翻译: Shotluck Holmes：专为视频字幕与摘要设计的高效小型语言视觉模型家族](2024年05月31日/Shotluck_Holmes_A_Family_of_Efficient_Small-Scale_Large_Language_Vision_Models_For_Video_Captioning_and_Summarization.md)

- [Large Language Models Enhanced Sequential Recommendation for Long-tail User and Item](2024年05月31日/Large_Language_Models_Enhanced_Sequential_Recommendation_for_Long-tail_User_and_Item.md)

    - [翻译: 大型语言模型优化了对长尾用户及物品的序列推荐策略](2024年05月31日/Large_Language_Models_Enhanced_Sequential_Recommendation_for_Long-tail_User_and_Item.md)

- [ToxVidLLM: A Multimodal LLM-based Framework for Toxicity Detection in Code-Mixed Videos](2024年05月31日/ToxVidLLM_A_Multimodal_LLM-based_Framework_for_Toxicity_Detection_in_Code-Mixed_Videos.md)

    - [翻译: ToxVidLLM：一款基于多模态LLM的框架，专为识别混合代码视频中的毒性而设计](2024年05月31日/ToxVidLLM_A_Multimodal_LLM-based_Framework_for_Toxicity_Detection_in_Code-Mixed_Videos.md)

- [Robust Planning with LLM-Modulo Framework: Case Study in Travel Planning](2024年05月31日/Robust_Planning_with_LLM-Modulo_Framework_Case_Study_in_Travel_Planning.md)

    - [翻译: 利用LLM-Modulo框架进行稳健旅行规划：一项案例研究](2024年05月31日/Robust_Planning_with_LLM-Modulo_Framework_Case_Study_in_Travel_Planning.md)

- [Leveraging Large Language Models for Entity Matching](2024年05月31日/Leveraging_Large_Language_Models_for_Entity_Matching.md)

    - [翻译: 借助大型语言模型之力，精准匹配实体](2024年05月31日/Leveraging_Large_Language_Models_for_Entity_Matching.md)

- [FineRadScore: A Radiology Report Line-by-Line Evaluation Technique Generating Corrections with Severity Scores](2024年05月31日/FineRadScore_A_Radiology_Report_Line-by-Line_Evaluation_Technique_Generating_Corrections_with_Severity_Scores.md)

    - [翻译: FineRadScore：一种创新的放射学报告评估方法，通过逐行分析并提供修正建议，同时附带严重性评分，以提升报告质量。](2024年05月31日/FineRadScore_A_Radiology_Report_Line-by-Line_Evaluation_Technique_Generating_Corrections_with_Severity_Scores.md)

- [Artemis: Towards Referential Understanding in Complex Videos](2024年05月31日/Artemis_Towards_Referential_Understanding_in_Complex_Videos.md)

    - [翻译: Artemis：探索复杂视频中的指称理解能力](2024年05月31日/Artemis_Towards_Referential_Understanding_in_Complex_Videos.md)

- [A Closer Look at Logical Reasoning with LLMs: The Choice of Tool Matters](2024年05月31日/A_Closer_Look_at_Logical_Reasoning_with_LLMs_The_Choice_of_Tool_Matters.md)

    - [翻译: 探究LLMs在逻辑推理中的应用：工具的选择是关键。](2024年05月31日/A_Closer_Look_at_Logical_Reasoning_with_LLMs_The_Choice_of_Tool_Matters.md)

- [Are Large Vision Language Models up to the Challenge of Chart Comprehension and Reasoning? An Extensive Investigation into the Capabilities and Limitations of LVLMs](2024年05月31日/Are_Large_Vision_Language_Models_up_to_the_Challenge_of_Chart_Comprehension_and_Reasoning_An_Extensive_Investigation_into_the_Capabilities_and_Limitations_of_LVLMs.md)

    - [翻译: 大型视觉语言模型能否胜任图表理解和推理的重任？本研究深入探讨了LVLMs的能力与局限，旨在全面评估其在复杂任务中的表现。](2024年05月31日/Are_Large_Vision_Language_Models_up_to_the_Challenge_of_Chart_Comprehension_and_Reasoning_An_Extensive_Investigation_into_the_Capabilities_and_Limitations_of_LVLMs.md)

- [Multi-Modal and Multi-Agent Systems Meet Rationality: A Survey](2024年05月31日/Multi-Modal_and_Multi-Agent_Systems_Meet_Rationality_A_Survey.md)

    - [翻译: 理性视角下的多模态与多智能体系统：综合调查](2024年05月31日/Multi-Modal_and_Multi-Agent_Systems_Meet_Rationality_A_Survey.md)

- [Large Language Models for Relevance Judgment in Product Search](2024年05月31日/Large_Language_Models_for_Relevance_Judgment_in_Product_Search.md)

    - [翻译: 大型语言模型助力产品搜索中的相关性评估](2024年05月31日/Large_Language_Models_for_Relevance_Judgment_in_Product_Search.md)

- [Controlling Large Language Model Agents with Entropic Activation Steering](2024年05月31日/Controlling_Large_Language_Model_Agents_with_Entropic_Activation_Steering.md)

    - [翻译: 通过熵激活引导操控大型语言模型代理](2024年05月31日/Controlling_Large_Language_Model_Agents_with_Entropic_Activation_Steering.md)

- [Exploring Vulnerabilities and Protections in Large Language Models: A Survey](2024年05月31日/Exploring_Vulnerabilities_and_Protections_in_Large_Language_Models_A_Survey.md)

    - [翻译: 大型语言模型漏洞与防护探索：一份综述](2024年05月31日/Exploring_Vulnerabilities_and_Protections_in_Large_Language_Models_A_Survey.md)

- [A Comparative Study of CNN, ResNet, and Vision Transformers for Multi-Classification of Chest Diseases](2024年05月31日/A_Comparative_Study_of_CNN,_ResNet,_and_Vision_Transformers_for_Multi-Classification_of_Chest_Diseases.md)

    - [翻译: 胸部疾病多分类：CNN、ResNet与视觉变换器的比较研究](2024年05月31日/A_Comparative_Study_of_CNN,_ResNet,_and_Vision_Transformers_for_Multi-Classification_of_Chest_Diseases.md)

- [LLM-RankFusion: Mitigating Intrinsic Inconsistency in LLM-based Ranking](2024年05月31日/LLM-RankFusion_Mitigating_Intrinsic_Inconsistency_in_LLM-based_Ranking.md)

    - [翻译: LLM-RankFusion：调和基于大型语言模型的排序系统中的内在不一致性](2024年05月31日/LLM-RankFusion_Mitigating_Intrinsic_Inconsistency_in_LLM-based_Ranking.md)

- [Learning to Clarify: Multi-turn Conversations with Action-Based Contrastive Self-Training](2024年05月31日/Learning_to_Clarify_Multi-turn_Conversations_with_Action-Based_Contrastive_Self-Training.md)

    - [翻译: 学会澄清：通过基于动作的对比自我训练进行多轮对话交流](2024年05月31日/Learning_to_Clarify_Multi-turn_Conversations_with_Action-Based_Contrastive_Self-Training.md)

- [Benchmarking the Communication Competence of Code Generation for LLMs and LLM Agent](2024年05月31日/Benchmarking_the_Communication_Competence_of_Code_Generation_for_LLMs_and_LLM_Agent.md)

    - [翻译: 评估大型语言模型及其代理在代码生成中的沟通能力](2024年05月31日/Benchmarking_the_Communication_Competence_of_Code_Generation_for_LLMs_and_LLM_Agent.md)

- [Mamba State-Space Models Can Be Strong Downstream Learners](2024年05月31日/Mamba_State-Space_Models_Can_Be_Strong_Downstream_Learners.md)

    - [翻译: Mamba 状态空间模型展现出作为下游学习者的强大潜力](2024年05月31日/Mamba_State-Space_Models_Can_Be_Strong_Downstream_Learners.md)

- [Long-Span Question-Answering: Automatic Question Generation and QA-System Ranking via Side-by-Side Evaluation](2024年05月31日/Long-Span_Question-Answering_Automatic_Question_Generation_and_QA-System_Ranking_via_Side-by-Side_Evaluation.md)

    - [翻译: 长跨度问答：并排评估助力自动问题生成与问答系统排名优化](2024年05月31日/Long-Span_Question-Answering_Automatic_Question_Generation_and_QA-System_Ranking_via_Side-by-Side_Evaluation.md)

- [DYNA: Disease-Specific Language Model for Variant Pathogenicity](2024年05月31日/DYNA_Disease-Specific_Language_Model_for_Variant_Pathogenicity.md)

    - [翻译: DYNA：专为变异致病性分析设计的疾病特异性语言模型](2024年05月31日/DYNA_Disease-Specific_Language_Model_for_Variant_Pathogenicity.md)

- [Query2CAD: Generating CAD models using natural language queries](2024年05月31日/Query2CAD_Generating_CAD_models_using_natural_language_queries.md)

    - [翻译: Query2CAD：通过自然语言查询轻松生成CAD模型](2024年05月31日/Query2CAD_Generating_CAD_models_using_natural_language_queries.md)

- [QuanTA: Efficient High-Rank Fine-Tuning of LLMs with Quantum-Informed Tensor Adaptation](2024年05月31日/QuanTA_Efficient_High-Rank_Fine-Tuning_of_LLMs_with_Quantum-Informed_Tensor_Adaptation.md)

    - [翻译: QuanTA：量子启发的矩阵适应技术，实现大型语言模型的高效高秩微调](2024年05月31日/QuanTA_Efficient_High-Rank_Fine-Tuning_of_LLMs_with_Quantum-Informed_Tensor_Adaptation.md)

- [How In-Context Learning Emerges from Training on Unstructured Data: On the Role of Co-Occurrence, Positional Information, and Noise Structures](2024年05月31日/How_In-Context_Learning_Emerges_from_Training_on_Unstructured_Data_On_the_Role_of_Co-Occurrence,_Positional_Information,_and_Noise_Structures.md)

    - [翻译: 非结构化数据训练如何孕育情境学习：共现、位置信息与噪声结构的奥秘](2024年05月31日/How_In-Context_Learning_Emerges_from_Training_on_Unstructured_Data_On_the_Role_of_Co-Occurrence,_Positional_Information,_and_Noise_Structures.md)

- [Towards LLM-Powered Verilog RTL Assistant: Self-Verification and Self-Correction](2024年05月31日/Towards_LLM-Powered_Verilog_RTL_Assistant_Self-Verification_and_Self-Correction.md)

    - [翻译: 探索大型语言模型驱动的Verilog RTL助手：实现自我验证与自我修正功能](2024年05月31日/Towards_LLM-Powered_Verilog_RTL_Assistant_Self-Verification_and_Self-Correction.md)

- [Scalable Bayesian Learning with posteriors](2024年05月31日/Scalable_Bayesian_Learning_with_posteriors.md)

    - [翻译: 利用后验分布实现贝叶斯学习的可扩展性](2024年05月31日/Scalable_Bayesian_Learning_with_posteriors.md)

2024年05月30日

- [Learning to Discuss Strategically: A Case Study on One Night Ultimate Werewolf](2024年05月30日/Learning_to_Discuss_Strategically_A_Case_Study_on_One_Night_Ultimate_Werewolf.md)

    - [翻译: 策略性讨论学习：《一夜终极狼人》案例分析](2024年05月30日/Learning_to_Discuss_Strategically_A_Case_Study_on_One_Night_Ultimate_Werewolf.md)

- [Uncovering Bias in Large Vision-Language Models at Scale with Counterfactuals](2024年05月30日/Uncovering_Bias_in_Large_Vision-Language_Models_at_Scale_with_Counterfactuals.md)

    - [翻译: 通过大规模反事实分析，揭示大型视觉-语言模型中的偏见现象](2024年05月30日/Uncovering_Bias_in_Large_Vision-Language_Models_at_Scale_with_Counterfactuals.md)

- [Typography Leads Semantic Diversifying: Amplifying Adversarial Transferability across Multimodal Large Language Models](2024年05月30日/Typography_Leads_Semantic_Diversifying_Amplifying_Adversarial_Transferability_across_Multimodal_Large_Language_Models.md)

    - [翻译: 排版艺术激发语义多样性，提升多模态大型语言模型间的对抗迁移能力。](2024年05月30日/Typography_Leads_Semantic_Diversifying_Amplifying_Adversarial_Transferability_across_Multimodal_Large_Language_Models.md)

- [NoiseBoost: Alleviating Hallucination with Noise Perturbation for Multimodal Large Language Models](2024年05月30日/NoiseBoost_Alleviating_Hallucination_with_Noise_Perturbation_for_Multimodal_Large_Language_Models.md)

    - [翻译: NoiseBoost：借助噪声扰动，缓解多模态大型语言模型中的幻觉现象](2024年05月30日/NoiseBoost_Alleviating_Hallucination_with_Noise_Perturbation_for_Multimodal_Large_Language_Models.md)

- [Efficient LLM-Jailbreaking by Introducing Visual Modality](2024年05月30日/Efficient_LLM-Jailbreaking_by_Introducing_Visual_Modality.md)

    - [翻译: 借助视觉模态，巧妙解锁大型语言模型的潜能](2024年05月30日/Efficient_LLM-Jailbreaking_by_Introducing_Visual_Modality.md)

- [A Survey Study on the State of the Art of Programming Exercise Generation using Large Language Models](2024年05月30日/A_Survey_Study_on_the_State_of_the_Art_of_Programming_Exercise_Generation_using_Large_Language_Models.md)

    - [翻译: 大型语言模型在编程练习生成领域的现状调查研究](2024年05月30日/A_Survey_Study_on_the_State_of_the_Art_of_Programming_Exercise_Generation_using_Large_Language_Models.md)

- [Robo-Instruct: Simulator-Augmented Instruction Alignment For Finetuning CodeLLMs](2024年05月30日/Robo-Instruct_Simulator-Augmented_Instruction_Alignment_For_Finetuning_CodeLLMs.md)

    - [翻译: Robo-Instruct：利用模拟器增强指令对齐，优化 CodeLLMs 的微调过程](2024年05月30日/Robo-Instruct_Simulator-Augmented_Instruction_Alignment_For_Finetuning_CodeLLMs.md)

- [InstructionCP: A fast approach to transfer Large Language Models into target language](2024年05月30日/InstructionCP_A_fast_approach_to_transfer_Large_Language_Models_into_target_language.md)

    - [翻译: InstructionCP：快速迁移大型语言模型至目标语言的捷径](2024年05月30日/InstructionCP_A_fast_approach_to_transfer_Large_Language_Models_into_target_language.md)

- [Reasoning about concepts with LLMs: Inconsistencies abound](2024年05月30日/Reasoning_about_concepts_with_LLMs_Inconsistencies_abound.md)

    - [翻译: 大型语言模型（LLMs）在概念推理中显露出的不一致性问题，值得我们深入探讨。](2024年05月30日/Reasoning_about_concepts_with_LLMs_Inconsistencies_abound.md)

- [GNN-RAG: Graph Neural Retrieval for Large Language Model Reasoning](2024年05月30日/GNN-RAG_Graph_Neural_Retrieval_for_Large_Language_Model_Reasoning.md)

    - [翻译: 图神经检索 GNN-RAG：助力大型语言模型推理](2024年05月30日/GNN-RAG_Graph_Neural_Retrieval_for_Large_Language_Model_Reasoning.md)

- [LLaMEA: A Large Language Model Evolutionary Algorithm for Automatically Generating Metaheuristics](2024年05月30日/LLaMEA_A_Large_Language_Model_Evolutionary_Algorithm_for_Automatically_Generating_Metaheuristics.md)

    - [翻译: LLaMEA：大型语言模型进化算法，专为自动生成元启发式而设计](2024年05月30日/LLaMEA_A_Large_Language_Model_Evolutionary_Algorithm_for_Automatically_Generating_Metaheuristics.md)

- [Language Models Need Inductive Biases to Count Inductively](2024年05月30日/Language_Models_Need_Inductive_Biases_to_Count_Inductively.md)

    - [翻译: 语言模型若要进行归纳计数，需依赖归纳偏置。](2024年05月30日/Language_Models_Need_Inductive_Biases_to_Count_Inductively.md)

- [Defensive Prompt Patch: A Robust and Interpretable Defense of LLMs against Jailbreak Attacks](2024年05月30日/Defensive_Prompt_Patch_A_Robust_and_Interpretable_Defense_of_LLMs_against_Jailbreak_Attacks.md)

    - [翻译: 防御提示补丁：为 LLMs 提供对抗越狱攻击的鲁棒且透明的防护策略](2024年05月30日/Defensive_Prompt_Patch_A_Robust_and_Interpretable_Defense_of_LLMs_against_Jailbreak_Attacks.md)

- [Divide-and-Conquer Meets Consensus: Unleashing the Power of Functions in Code Generation](2024年05月30日/Divide-and-Conquer_Meets_Consensus_Unleashing_the_Power_of_Functions_in_Code_Generation.md)

    - [翻译: 分治策略与共识机制的结合：激发代码生成中函数的潜能](2024年05月30日/Divide-and-Conquer_Meets_Consensus_Unleashing_the_Power_of_Functions_in_Code_Generation.md)

- [The Fine-Tuning Paradox: Boosting Translation Quality Without Sacrificing LLM Abilities](2024年05月30日/The_Fine-Tuning_Paradox_Boosting_Translation_Quality_Without_Sacrificing_LLM_Abilities.md)

    - [翻译: 微调之谜：如何在不削弱 LLM 能力的前提下，提升翻译品质](2024年05月30日/The_Fine-Tuning_Paradox_Boosting_Translation_Quality_Without_Sacrificing_LLM_Abilities.md)

- [Student Answer Forecasting: Transformer-Driven Answer Choice Prediction for Language Learning](2024年05月30日/Student_Answer_Forecasting_Transformer-Driven_Answer_Choice_Prediction_for_Language_Learning.md)

    - [翻译: 语言学习中的学生答案预测：利用Transformer模型精准预测答案选项](2024年05月30日/Student_Answer_Forecasting_Transformer-Driven_Answer_Choice_Prediction_for_Language_Learning.md)

- [Kernel Language Entropy: Fine-grained Uncertainty Quantification for LLMs from Semantic Similarities](2024年05月30日/Kernel_Language_Entropy_Fine-grained_Uncertainty_Quantification_for_LLMs_from_Semantic_Similarities.md)

    - [翻译: 语义相似度视角下的核语言熵：为大型语言模型提供细粒度不确定性量化](2024年05月30日/Kernel_Language_Entropy_Fine-grained_Uncertainty_Quantification_for_LLMs_from_Semantic_Similarities.md)

- [Similarity is Not All You Need: Endowing Retrieval Augmented Generation with Multi Layered Thoughts](2024年05月30日/Similarity_is_Not_All_You_Need_Endowing_Retrieval_Augmented_Generation_with_Multi_Layered_Thoughts.md)

    - [翻译: 单一相似性不足为凭：为检索增强生成注入多层次思考](2024年05月30日/Similarity_is_Not_All_You_Need_Endowing_Retrieval_Augmented_Generation_with_Multi_Layered_Thoughts.md)

- [Parrot: Efficient Serving of LLM-based Applications with Semantic Variable](2024年05月30日/Parrot_Efficient_Serving_of_LLM-based_Applications_with_Semantic_Variable.md)

    - [翻译: Parrot：借助语义变量，高效支持基于大型语言模型的应用服务](2024年05月30日/Parrot_Efficient_Serving_of_LLM-based_Applications_with_Semantic_Variable.md)

- [From Words to Actions: Unveiling the Theoretical Underpinnings of LLM-Driven Autonomous Systems](2024年05月30日/From_Words_to_Actions_Unveiling_the_Theoretical_Underpinnings_of_LLM-Driven_Autonomous_Systems.md)

    - [翻译: 从言辞到实践：探索大型语言模型驱动自主系统的理论根基](2024年05月30日/From_Words_to_Actions_Unveiling_the_Theoretical_Underpinnings_of_LLM-Driven_Autonomous_Systems.md)

- [KNOW: A Real-World Ontology for Knowledge Capture with Large Language Models](2024年05月30日/KNOW_A_Real-World_Ontology_for_Knowledge_Capture_with_Large_Language_Models.md)

    - [翻译: KNOW：大型语言模型用于知识捕获的真实世界本体论](2024年05月30日/KNOW_A_Real-World_Ontology_for_Knowledge_Capture_with_Large_Language_Models.md)

- [DevEval: A Manually-Annotated Code Generation Benchmark Aligned with Real-World Code Repositories](2024年05月30日/DevEval_A_Manually-Annotated_Code_Generation_Benchmark_Aligned_with_Real-World_Code_Repositories.md)

    - [翻译: DevEval：真实世界代码仓库对齐的手工标注代码生成基准](2024年05月30日/DevEval_A_Manually-Annotated_Code_Generation_Benchmark_Aligned_with_Real-World_Code_Repositories.md)

- [Deciphering Human Mobility: Inferring Semantics of Trajectories with Large Language Models](2024年05月30日/Deciphering_Human_Mobility_Inferring_Semantics_of_Trajectories_with_Large_Language_Models.md)

    - [翻译: 揭秘人类移动轨迹：借助大型语言模型洞察轨迹背后的深层含义](2024年05月30日/Deciphering_Human_Mobility_Inferring_Semantics_of_Trajectories_with_Large_Language_Models.md)

- [Quest: Query-centric Data Synthesis Approach for Long-context Scaling of Large Language Model](2024年05月30日/Quest_Query-centric_Data_Synthesis_Approach_for_Long-context_Scaling_of_Large_Language_Model.md)

    - [翻译: 探索：一种以查询为核心的数据合成策略，旨在扩展大型语言模型的长上下文处理能力](2024年05月30日/Quest_Query-centric_Data_Synthesis_Approach_for_Long-context_Scaling_of_Large_Language_Model.md)

- [Improve Student's Reasoning Generalizability through Cascading Decomposed CoTs Distillation](2024年05月30日/Improve_Student's_Reasoning_Generalizability_through_Cascading_Decomposed_CoTs_Distillation.md)

    - [翻译: 利用级联分解思维链蒸馏法，提升学生推理能力的泛化性](2024年05月30日/Improve_Student's_Reasoning_Generalizability_through_Cascading_Decomposed_CoTs_Distillation.md)

- [WebUOT-1M: Advancing Deep Underwater Object Tracking with A Million-Scale Benchmark](2024年05月30日/WebUOT-1M_Advancing_Deep_Underwater_Object_Tracking_with_A_Million-Scale_Benchmark.md)

    - [翻译: WebUOT-1M：借助百万级基准，深度推进深海物体跟踪技术](2024年05月30日/WebUOT-1M_Advancing_Deep_Underwater_Object_Tracking_with_A_Million-Scale_Benchmark.md)

- [Exploring the Robustness of Decision-Level Through Adversarial Attacks on LLM-Based Embodied Models](2024年05月30日/Exploring_the_Robustness_of_Decision-Level_Through_Adversarial_Attacks_on_LLM-Based_Embodied_Models.md)

    - [翻译: 探究具身模型基于LLM在决策层面抵御对抗性攻击的鲁棒性。](2024年05月30日/Exploring_the_Robustness_of_Decision-Level_Through_Adversarial_Attacks_on_LLM-Based_Embodied_Models.md)

- [Unsupervised Mutual Learning of Dialogue Discourse Parsing and Topic Segmentation](2024年05月30日/Unsupervised_Mutual_Learning_of_Dialogue_Discourse_Parsing_and_Topic_Segmentation.md)

    - [翻译: 对话话语解析与话题分割的无监督相互学习](2024年05月30日/Unsupervised_Mutual_Learning_of_Dialogue_Discourse_Parsing_and_Topic_Segmentation.md)

- [SLM as Guardian: Pioneering AI Safety with Small Language Models](2024年05月30日/SLM_as_Guardian_Pioneering_AI_Safety_with_Small_Language_Models.md)

    - [翻译: 小型语言模型：AI 安全的先锋守护者](2024年05月30日/SLM_as_Guardian_Pioneering_AI_Safety_with_Small_Language_Models.md)

- [From Symbolic Tasks to Code Generation: Diversification Yields Better Task Performers](2024年05月30日/From_Symbolic_Tasks_to_Code_Generation_Diversification_Yields_Better_Task_Performers.md)

    - [翻译: 从符号任务到代码生成：任务执行者的多样化提升表现](2024年05月30日/From_Symbolic_Tasks_to_Code_Generation_Diversification_Yields_Better_Task_Performers.md)

- [Dataflow-Guided Retrieval Augmentation for Repository-Level Code Completion](2024年05月30日/Dataflow-Guided_Retrieval_Augmentation_for_Repository-Level_Code_Completion.md)

    - [翻译: 基于数据流的检索增强技术，助力仓库级代码补全](2024年05月30日/Dataflow-Guided_Retrieval_Augmentation_for_Repository-Level_Code_Completion.md)

- [VQA Training Sets are Self-play Environments for Generating Few-shot Pools](2024年05月30日/VQA_Training_Sets_are_Self-play_Environments_for_Generating_Few-shot_Pools.md)

    - [翻译: VQA训练集如同自对弈的舞台，孕育着少量样本池的生成。](2024年05月30日/VQA_Training_Sets_are_Self-play_Environments_for_Generating_Few-shot_Pools.md)

- [Enhancing Reinforcement Learning with Label-Sensitive Reward for Natural Language Understanding](2024年05月30日/Enhancing_Reinforcement_Learning_with_Label-Sensitive_Reward_for_Natural_Language_Understanding.md)

    - [翻译: 利用标签敏感奖励优化强化学习，以提升自然语言理解能力](2024年05月30日/Enhancing_Reinforcement_Learning_with_Label-Sensitive_Reward_for_Natural_Language_Understanding.md)

- [X-Instruction: Aligning Language Model in Low-resource Languages with Self-curated Cross-lingual Instructions](2024年05月30日/X-Instruction_Aligning_Language_Model_in_Low-resource_Languages_with_Self-curated_Cross-lingual_Instructions.md)

    - [翻译: X-Instruction：借助自选跨语言指令，优化低资源语言模型的对齐](2024年05月30日/X-Instruction_Aligning_Language_Model_in_Low-resource_Languages_with_Self-curated_Cross-lingual_Instructions.md)

- [PertEval: Unveiling Real Knowledge Capacity of LLMs with Knowledge-Invariant Perturbations](2024年05月30日/PertEval_Unveiling_Real_Knowledge_Capacity_of_LLMs_with_Knowledge-Invariant_Perturbations.md)

    - [翻译: PertEval：揭秘 LLMs 的真实知识储备——通过知识不变扰动探索其深层能力](2024年05月30日/PertEval_Unveiling_Real_Knowledge_Capacity_of_LLMs_with_Knowledge-Invariant_Perturbations.md)

- [Beyond Imitation: Learning Key Reasoning Steps from Dual Chain-of-Thoughts in Reasoning Distillation](2024年05月30日/Beyond_Imitation_Learning_Key_Reasoning_Steps_from_Dual_Chain-of-Thoughts_in_Reasoning_Distillation.md)

    - [翻译: 超越模仿：从推理蒸馏的双重思维链中汲取关键推理步骤](2024年05月30日/Beyond_Imitation_Learning_Key_Reasoning_Steps_from_Dual_Chain-of-Thoughts_in_Reasoning_Distillation.md)

- [Two Optimizers Are Better Than One: LLM Catalyst for Enhancing Gradient-Based Optimization](2024年05月30日/Two_Optimizers_Are_Better_Than_One_LLM_Catalyst_for_Enhancing_Gradient-Based_Optimization.md)

    - [翻译: 双优化器胜于单一：LLM 催化剂助力梯度优化提升](2024年05月30日/Two_Optimizers_Are_Better_Than_One_LLM_Catalyst_for_Enhancing_Gradient-Based_Optimization.md)

- [Research on Foundation Model for Spatial Data Intelligence: China's 2024 White Paper on Strategic Development of Spatial Data Intelligence](2024年05月30日/Research_on_Foundation_Model_for_Spatial_Data_Intelligence_China's_2024_White_Paper_on_Strategic_Development_of_Spatial_Data_Intelligence.md)

    - [翻译: 中国2024年发布的《空间数据智能战略发展白皮书》深入探讨了基础模型在空间数据智能领域的研究进展。](2024年05月30日/Research_on_Foundation_Model_for_Spatial_Data_Intelligence_China's_2024_White_Paper_on_Strategic_Development_of_Spatial_Data_Intelligence.md)

- [Enhancing Large Vision Language Models with Self-Training on Image Comprehension](2024年05月30日/Enhancing_Large_Vision_Language_Models_with_Self-Training_on_Image_Comprehension.md)

    - [翻译: 提升大型视觉语言模型在图像理解方面的能力：自我训练的探索](2024年05月30日/Enhancing_Large_Vision_Language_Models_with_Self-Training_on_Image_Comprehension.md)

- [SpecDec++: Boosting Speculative Decoding via Adaptive Candidate Lengths](2024年05月30日/SpecDec++_Boosting_Speculative_Decoding_via_Adaptive_Candidate_Lengths.md)

    - [翻译: SpecDec++：利用自适应候选长度增强推测解码性能](2024年05月30日/SpecDec++_Boosting_Speculative_Decoding_via_Adaptive_Candidate_Lengths.md)

- [Grade Like a Human: Rethinking Automated Assessment with Large Language Models](2024年05月30日/Grade_Like_a_Human_Rethinking_Automated_Assessment_with_Large_Language_Models.md)

    - [翻译: 人性化评分：探索大型语言模型在自动化评估中的新思路](2024年05月30日/Grade_Like_a_Human_Rethinking_Automated_Assessment_with_Large_Language_Models.md)

- [Knowledge Graph Tuning: Real-time Large Language Model Personalization based on Human Feedback](2024年05月30日/Knowledge_Graph_Tuning_Real-time_Large_Language_Model_Personalization_based_on_Human_Feedback.md)

    - [翻译: 实时个性化：基于人类反馈的知识图谱调优大型语言模型](2024年05月30日/Knowledge_Graph_Tuning_Real-time_Large_Language_Model_Personalization_based_on_Human_Feedback.md)

- [Large Language Model Watermark Stealing With Mixed Integer Programming](2024年05月30日/Large_Language_Model_Watermark_Stealing_With_Mixed_Integer_Programming.md)

    - [翻译: 混合整数规划在大型语言模型中窃取水印的策略](2024年05月30日/Large_Language_Model_Watermark_Stealing_With_Mixed_Integer_Programming.md)

- [Retrieval Augmented Structured Generation: Business Document Information Extraction As Tool Use](2024年05月30日/Retrieval_Augmented_Structured_Generation_Business_Document_Information_Extraction_As_Tool_Use.md)

    - [翻译: 利用检索增强技术进行结构化生成：将商业文档信息提取视为工具运用](2024年05月30日/Retrieval_Augmented_Structured_Generation_Business_Document_Information_Extraction_As_Tool_Use.md)

- [MotionLLM: Understanding Human Behaviors from Human Motions and Videos](2024年05月30日/MotionLLM_Understanding_Human_Behaviors_from_Human_Motions_and_Videos.md)

    - [翻译: MotionLLM：解析人体运动与视频，洞察人类行为之谜](2024年05月30日/MotionLLM_Understanding_Human_Behaviors_from_Human_Motions_and_Videos.md)

- [Visual Perception by Large Language Model's Weights](2024年05月30日/Visual_Perception_by_Large_Language_Model's_Weights.md)

    - [翻译: 大型语言模型权重下的视觉感知探索](2024年05月30日/Visual_Perception_by_Large_Language_Model's_Weights.md)

- [RapVerse: Coherent Vocals and Whole-Body Motions Generations from Text](2024年05月30日/RapVerse_Coherent_Vocals_and_Whole-Body_Motions_Generations_from_Text.md)

    - [翻译: RapVerse：文本驱动，创造连贯声乐与全身动作的完美融合](2024年05月30日/RapVerse_Coherent_Vocals_and_Whole-Body_Motions_Generations_from_Text.md)

- [Xwin-LM: Strong and Scalable Alignment Practice for LLMs](2024年05月30日/Xwin-LM_Strong_and_Scalable_Alignment_Practice_for_LLMs.md)

    - [翻译: Xwin-LM：大型语言模型的强大且可扩展的对齐实践](2024年05月30日/Xwin-LM_Strong_and_Scalable_Alignment_Practice_for_LLMs.md)

- [ParSEL: Parameterized Shape Editing with Language](2024年05月30日/ParSEL_Parameterized_Shape_Editing_with_Language.md)

    - [翻译: ParSEL：语言驱动的参数化形状编辑](2024年05月30日/ParSEL_Parameterized_Shape_Editing_with_Language.md)

- [CausalQuest: Collecting Natural Causal Questions for AI Agents](2024年05月30日/CausalQuest_Collecting_Natural_Causal_Questions_for_AI_Agents.md)

    - [翻译: 因果探索：为AI代理搜集自然因果问题集](2024年05月30日/CausalQuest_Collecting_Natural_Causal_Questions_for_AI_Agents.md)

- [ANAH: Analytical Annotation of Hallucinations in Large Language Models](2024年05月30日/ANAH_Analytical_Annotation_of_Hallucinations_in_Large_Language_Models.md)

    - [翻译: ANAH：大型语言模型幻觉的深度解析](2024年05月30日/ANAH_Analytical_Annotation_of_Hallucinations_in_Large_Language_Models.md)

- [Sequence-Augmented SE(3)-Flow Matching For Conditional Protein Backbone Generation](2024年05月30日/Sequence-Augmented_SE(3)-Flow_Matching_For_Conditional_Protein_Backbone_Generation.md)

    - [翻译: 条件性蛋白质骨架生成中的序列增强SE(3)-流匹配](2024年05月30日/Sequence-Augmented_SE(3)-Flow_Matching_For_Conditional_Protein_Backbone_Generation.md)

- [Large Language Models Can Self-Improve At Web Agent Tasks](2024年05月30日/Large_Language_Models_Can_Self-Improve_At_Web_Agent_Tasks.md)

    - [翻译: 大型语言模型具备在网络代理任务中自我提升的能力。](2024年05月30日/Large_Language_Models_Can_Self-Improve_At_Web_Agent_Tasks.md)

- [Can't make an Omelette without Breaking some Eggs: Plausible Action Anticipation using Large Video-Language Models](2024年05月30日/Can't_make_an_Omelette_without_Breaking_some_Eggs_Plausible_Action_Anticipation_using_Large_Video-Language_Models.md)

    - [翻译: 欲制煎蛋，必先破蛋：借助大型视频-语言模型，精准预见动作之可能。](2024年05月30日/Can't_make_an_Omelette_without_Breaking_some_Eggs_Plausible_Action_Anticipation_using_Large_Video-Language_Models.md)

- [Group Robust Preference Optimization in Reward-free RLHF](2024年05月30日/Group_Robust_Preference_Optimization_in_Reward-free_RLHF.md)

    - [翻译: 在无奖励强化学习中，优化群体的鲁棒偏好](2024年05月30日/Group_Robust_Preference_Optimization_in_Reward-free_RLHF.md)

- [Who Writes the Review, Human or AI?](2024年05月30日/Who_Writes_the_Review,_Human_or_AI.md)

    - [翻译: 评论出自谁手，人类还是AI？](2024年05月30日/Who_Writes_the_Review,_Human_or_AI.md)

- [Evaluating Large Language Model Biases in Persona-Steered Generation](2024年05月30日/Evaluating_Large_Language_Model_Biases_in_Persona-Steered_Generation.md)

    - [翻译: 探究大型语言模型在人格引导生成过程中的偏见影响](2024年05月30日/Evaluating_Large_Language_Model_Biases_in_Persona-Steered_Generation.md)

- [Towards Hierarchical Multi-Agent Workflows for Zero-Shot Prompt Optimization](2024年05月30日/Towards_Hierarchical_Multi-Agent_Workflows_for_Zero-Shot_Prompt_Optimization.md)

    - [翻译: 探索零-shot提示优化的高层次多代理工作流程](2024年05月30日/Towards_Hierarchical_Multi-Agent_Workflows_for_Zero-Shot_Prompt_Optimization.md)

- [Context Injection Attacks on Large Language Models](2024年05月30日/Context_Injection_Attacks_on_Large_Language_Models.md)

    - [翻译: 大型语言模型面临上下文注入攻击的挑战](2024年05月30日/Context_Injection_Attacks_on_Large_Language_Models.md)

- [TS-Align: A Teacher-Student Collaborative Framework for Scalable Iterative Finetuning of Large Language Models](2024年05月30日/TS-Align_A_Teacher-Student_Collaborative_Framework_for_Scalable_Iterative_Finetuning_of_Large_Language_Models.md)

    - [翻译: TS-Align：教师-学生协作框架，专为大型语言模型的迭代微调而设计，旨在实现规模化优化。](2024年05月30日/TS-Align_A_Teacher-Student_Collaborative_Framework_for_Scalable_Iterative_Finetuning_of_Large_Language_Models.md)

- [One QuantLLM for ALL: Fine-tuning Quantized LLMs Once for Efficient Deployments](2024年05月30日/One_QuantLLM_for_ALL_Fine-tuning_Quantized_LLMs_Once_for_Efficient_Deployments.md)

    - [翻译: 一调通用，高效部署：微调量化大型语言模型，一次到位](2024年05月30日/One_QuantLLM_for_ALL_Fine-tuning_Quantized_LLMs_Once_for_Efficient_Deployments.md)

- [Using Large Language Models for Humanitarian Frontline Negotiation: Opportunities and Considerations](2024年05月30日/Using_Large_Language_Models_for_Humanitarian_Frontline_Negotiation_Opportunities_and_Considerations.md)

    - [翻译: 大型语言模型在人道主义前线谈判中的应用：机遇与深思](2024年05月30日/Using_Large_Language_Models_for_Humanitarian_Frontline_Negotiation_Opportunities_and_Considerations.md)

- [TAIA: Large Language Models are Out-of-Distribution Data Learners](2024年05月30日/TAIA_Large_Language_Models_are_Out-of-Distribution_Data_Learners.md)

    - [翻译: TAIA: 大型语言模型擅长学习分布外数据](2024年05月30日/TAIA_Large_Language_Models_are_Out-of-Distribution_Data_Learners.md)

- [Nadine: An LLM-driven Intelligent Social Robot with Affective Capabilities and Human-like Memory](2024年05月30日/Nadine_An_LLM-driven_Intelligent_Social_Robot_with_Affective_Capabilities_and_Human-like_Memory.md)

    - [翻译: Nadine：一款搭载LLM的智能社交机器人，具备情感交互能力与类人记忆系统](2024年05月30日/Nadine_An_LLM-driven_Intelligent_Social_Robot_with_Affective_Capabilities_and_Human-like_Memory.md)

- [Generating Query Recommendations via LLMs](2024年05月30日/Generating_Query_Recommendations_via_LLMs.md)

    - [翻译: 利用大型语言模型打造智能查询推荐](2024年05月30日/Generating_Query_Recommendations_via_LLMs.md)

- [UniBias: Unveiling and Mitigating LLM Bias through Internal Attention and FFN Manipulation](2024年05月30日/UniBias_Unveiling_and_Mitigating_LLM_Bias_through_Internal_Attention_and_FFN_Manipulation.md)

    - [翻译: UniBias：揭示与缓解大型语言模型偏差的新途径——内部注意力与FFN操控](2024年05月30日/UniBias_Unveiling_and_Mitigating_LLM_Bias_through_Internal_Attention_and_FFN_Manipulation.md)

- [Vision-Language Meets the Skeleton: Progressively Distillation with Cross-Modal Knowledge for 3D Action Representation Learning](2024年05月30日/Vision-Language_Meets_the_Skeleton_Progressively_Distillation_with_Cross-Modal_Knowledge_for_3D_Action_Representation_Learning.md)

    - [翻译: 视觉与语言融合骨架：借助跨模态知识的渐进蒸馏，深化三维动作表示学习之旅](2024年05月30日/Vision-Language_Meets_the_Skeleton_Progressively_Distillation_with_Cross-Modal_Knowledge_for_3D_Action_Representation_Learning.md)

- [DAFNet: Dynamic Auxiliary Fusion for Sequential Model Editing in Large Language Models](2024年05月30日/DAFNet_Dynamic_Auxiliary_Fusion_for_Sequential_Model_Editing_in_Large_Language_Models.md)

    - [翻译: DAFNet：大型语言模型中序列模型编辑的动态辅助融合网络](2024年05月30日/DAFNet_Dynamic_Auxiliary_Fusion_for_Sequential_Model_Editing_in_Large_Language_Models.md)

- [GAMedX: Generative AI-based Medical Entity Data Extractor Using Large Language Models](2024年05月30日/GAMedX_Generative_AI-based_Medical_Entity_Data_Extractor_Using_Large_Language_Models.md)

    - [翻译: GAMedX：利用大型语言模型的生成式AI技术，精准提取医疗实体数据](2024年05月30日/GAMedX_Generative_AI-based_Medical_Entity_Data_Extractor_Using_Large_Language_Models.md)

- [The Point of View of a Sentiment: Towards Clinician Bias Detection in Psychiatric Notes](2024年05月30日/The_Point_of_View_of_a_Sentiment_Towards_Clinician_Bias_Detection_in_Psychiatric_Notes.md)

    - [翻译: 情感视角：探索精神科医生在精神病学笔记中的偏见检测](2024年05月30日/The_Point_of_View_of_a_Sentiment_Towards_Clinician_Bias_Detection_in_Psychiatric_Notes.md)

- [Open Ko-LLM Leaderboard: Evaluating Large Language Models in Korean with Ko-H5 Benchmark](2024年05月30日/Open_Ko-LLM_Leaderboard_Evaluating_Large_Language_Models_in_Korean_with_Ko-H5_Benchmark.md)

    - [翻译: 韩语大型语言模型评测榜：借助Ko-H5基准，探索韩语LLM的性能表现](2024年05月30日/Open_Ko-LLM_Leaderboard_Evaluating_Large_Language_Models_in_Korean_with_Ko-H5_Benchmark.md)

- [Perplexed by Perplexity: Perplexity-Based Data Pruning With Small Reference Models](2024年05月30日/Perplexed_by_Perplexity_Perplexity-Based_Data_Pruning_With_Small_Reference_Models.md)

    - [翻译: 困惑度之谜：利用小型参考模型进行基于困惑度的数据精简](2024年05月30日/Perplexed_by_Perplexity_Perplexity-Based_Data_Pruning_With_Small_Reference_Models.md)

- [Phantom: General Trigger Attacks on Retrieval Augmented Language Generation](2024年05月30日/Phantom_General_Trigger_Attacks_on_Retrieval_Augmented_Language_Generation.md)

    - [翻译: 幻影攻击：针对增强检索的语言生成的一般触发策略](2024年05月30日/Phantom_General_Trigger_Attacks_on_Retrieval_Augmented_Language_Generation.md)

- [DepesRAG: Towards Managing Software Dependencies using Large Language Models](2024年05月30日/DepesRAG_Towards_Managing_Software_Dependencies_using_Large_Language_Models.md)

    - [翻译: DepesRAG：借助大型语言模型优化软件依赖管理](2024年05月30日/DepesRAG_Towards_Managing_Software_Dependencies_using_Large_Language_Models.md)

- [Is My Data in Your Retrieval Database? Membership Inference Attacks Against Retrieval Augmented Generation](2024年05月30日/Is_My_Data_in_Your_Retrieval_Database_Membership_Inference_Attacks_Against_Retrieval_Augmented_Generation.md)

    - [翻译: 你的检索数据库中是否藏有我的数据？探讨针对检索增强生成系统的成员推理攻击](2024年05月30日/Is_My_Data_in_Your_Retrieval_Database_Membership_Inference_Attacks_Against_Retrieval_Augmented_Generation.md)

- [Designing an Evaluation Framework for Large Language Models in Astronomy Research](2024年05月30日/Designing_an_Evaluation_Framework_for_Large_Language_Models_in_Astronomy_Research.md)

    - [翻译: 构建天文学研究中大型语言模型的评估框架](2024年05月30日/Designing_an_Evaluation_Framework_for_Large_Language_Models_in_Astronomy_Research.md)

- [Hallucination-Free? Assessing the Reliability of Leading AI Legal Research Tools](2024年05月30日/Hallucination-Free_Assessing_the_Reliability_of_Leading_AI_Legal_Research_Tools.md)

    - [翻译: 幻觉不再？探究顶尖AI法律研究工具的可靠性](2024年05月30日/Hallucination-Free_Assessing_the_Reliability_of_Leading_AI_Legal_Research_Tools.md)

- [Learning 3D Robotics Perception using Inductive Priors](2024年05月30日/Learning_3D_Robotics_Perception_using_Inductive_Priors.md)

    - [翻译: 借助归纳先验，探索3D机器人感知的学习之道](2024年05月30日/Learning_3D_Robotics_Perception_using_Inductive_Priors.md)

- [Worse than Random? An Embarrassingly Simple Probing Evaluation of Large Multimodal Models in Medical VQA](2024年05月30日/Worse_than_Random_An_Embarrassingly_Simple_Probing_Evaluation_of_Large_Multimodal_Models_in_Medical_VQA.md)

    - [翻译: 竟不如随机？大型多模态模型在医学视觉问答中的极简探针评估，令人尴尬的简单。](2024年05月30日/Worse_than_Random_An_Embarrassingly_Simple_Probing_Evaluation_of_Large_Multimodal_Models_in_Medical_VQA.md)

- [LLMGeo: Benchmarking Large Language Models on Image Geolocation In-the-wild](2024年05月30日/LLMGeo_Benchmarking_Large_Language_Models_on_Image_Geolocation_In-the-wild.md)

    - [翻译: LLMGeo：大型语言模型在野外图像地理定位的基准测试](2024年05月30日/LLMGeo_Benchmarking_Large_Language_Models_on_Image_Geolocation_In-the-wild.md)

- [Confidence-Aware Sub-Structure Beam Search (CABS): Mitigating Hallucination in Structured Data Generation with Large Language Models](2024年05月30日/Confidence-Aware_Sub-Structure_Beam_Search_(CABS)_Mitigating_Hallucination_in_Structured_Data_Generation_with_Large_Language_Models.md)

    - [翻译: 信心感知子结构束搜索（CABS）：大型语言模型在结构化数据生成中减少幻觉的有效策略](2024年05月30日/Confidence-Aware_Sub-Structure_Beam_Search_(CABS)_Mitigating_Hallucination_in_Structured_Data_Generation_with_Large_Language_Models.md)

2024年05月29日

- [Towards Next-Generation Urban Decision Support Systems through AI-Powered Generation of Scientific Ontology using Large Language Models -- A Case in Optimizing Intermodal Freight Transportation](2024年05月29日/Towards_Next-Generation_Urban_Decision_Support_Systems_through_AI-Powered_Generation_of_Scientific_Ontology_using_Large_Language_Models_--_A_Case_in_Optimizing_Intermodal_Freight_Transportation.md)

    - [翻译: 借助大型语言模型的人工智能驱动，我们正迈向新一代城市决策支持系统，以科学本体为基础，优化多式联运货运交通，开启智慧城市新篇章。](2024年05月29日/Towards_Next-Generation_Urban_Decision_Support_Systems_through_AI-Powered_Generation_of_Scientific_Ontology_using_Large_Language_Models_--_A_Case_in_Optimizing_Intermodal_Freight_Transportation.md)

- [Lower Bounds on the Expressivity of Recurrent Neural Language Models](2024年05月29日/Lower_Bounds_on_the_Expressivity_of_Recurrent_Neural_Language_Models.md)

    - [翻译: 循环神经语言模型表达力下界探究](2024年05月29日/Lower_Bounds_on_the_Expressivity_of_Recurrent_Neural_Language_Models.md)

- [VideoTree: Adaptive Tree-based Video Representation for LLM Reasoning on Long Videos](2024年05月29日/VideoTree_Adaptive_Tree-based_Video_Representation_for_LLM_Reasoning_on_Long_Videos.md)

    - [翻译: VideoTree：一种基于树结构的自适应视频表示方法，专为大型语言模型处理长视频推理而设计。](2024年05月29日/VideoTree_Adaptive_Tree-based_Video_Representation_for_LLM_Reasoning_on_Long_Videos.md)

- [A Multi-Source Retrieval Question Answering Framework Based on RAG](2024年05月29日/A_Multi-Source_Retrieval_Question_Answering_Framework_Based_on_RAG.md)

    - [翻译: 基于RAG技术的多源检索问答框架](2024年05月29日/A_Multi-Source_Retrieval_Question_Answering_Framework_Based_on_RAG.md)

- [MetaToken: Detecting Hallucination in Image Descriptions by Meta Classification](2024年05月29日/MetaToken_Detecting_Hallucination_in_Image_Descriptions_by_Meta_Classification.md)

    - [翻译: MetaToken：利用元分类技术揭示图像描述中的幻觉现象](2024年05月29日/MetaToken_Detecting_Hallucination_in_Image_Descriptions_by_Meta_Classification.md)

- [Learning from Litigation: Graphs and LLMs for Retrieval and Reasoning in eDiscovery](2024年05月29日/Learning_from_Litigation_Graphs_and_LLMs_for_Retrieval_and_Reasoning_in_eDiscovery.md)

    - [翻译: 诉讼智慧：图与LLMs在电子发现检索与推理中的应用](2024年05月29日/Learning_from_Litigation_Graphs_and_LLMs_for_Retrieval_and_Reasoning_in_eDiscovery.md)

- [Analyzing Chat Protocols of Novice Programmers Solving Introductory Programming Tasks with ChatGPT](2024年05月29日/Analyzing_Chat_Protocols_of_Novice_Programmers_Solving_Introductory_Programming_Tasks_with_ChatGPT.md)

    - [翻译: 探究新手程序员在解决基础编程任务时与 ChatGPT 的互动对话](2024年05月29日/Analyzing_Chat_Protocols_of_Novice_Programmers_Solving_Introductory_Programming_Tasks_with_ChatGPT.md)

- [Can Graph Learning Improve Task Planning?](2024年05月29日/Can_Graph_Learning_Improve_Task_Planning.md)

    - [翻译: 图学习是否能优化任务规划？](2024年05月29日/Can_Graph_Learning_Improve_Task_Planning.md)

- [ChartFormer: A Large Vision Language Model for Converting Chart Images into Tactile Accessible SVGs](2024年05月29日/ChartFormer_A_Large_Vision_Language_Model_for_Converting_Chart_Images_into_Tactile_Accessible_SVGs.md)

    - [翻译: ChartFormer：一款大型视觉语言模型，专为将图表图像转化为触感友好的SVG格式而设计。](2024年05月29日/ChartFormer_A_Large_Vision_Language_Model_for_Converting_Chart_Images_into_Tactile_Accessible_SVGs.md)

- [PathReasoner: Modeling Reasoning Path with Equivalent Extension for Logical Question Answering](2024年05月29日/PathReasoner_Modeling_Reasoning_Path_with_Equivalent_Extension_for_Logical_Question_Answering.md)

    - [翻译: PathReasoner：通过等价扩展构建推理路径，精准解答逻辑问题](2024年05月29日/PathReasoner_Modeling_Reasoning_Path_with_Equivalent_Extension_for_Logical_Question_Answering.md)

- [Offline Regularised Reinforcement Learning for Large Language Models Alignment](2024年05月29日/Offline_Regularised_Reinforcement_Learning_for_Large_Language_Models_Alignment.md)

    - [翻译: 大型语言模型对齐的离线正则化强化学习](2024年05月29日/Offline_Regularised_Reinforcement_Learning_for_Large_Language_Models_Alignment.md)

- [Voice Jailbreak Attacks Against GPT-4o](2024年05月29日/Voice_Jailbreak_Attacks_Against_GPT-4o.md)

    - [翻译: GPT-4o遭遇语音越狱攻击挑战](2024年05月29日/Voice_Jailbreak_Attacks_Against_GPT-4o.md)

- [Enhancing Zero-Shot Facial Expression Recognition by LLM Knowledge Transfer](2024年05月29日/Enhancing_Zero-Shot_Facial_Expression_Recognition_by_LLM_Knowledge_Transfer.md)

    - [翻译: 借助LLM知识转移提升零-shot面部表情识别能力](2024年05月29日/Enhancing_Zero-Shot_Facial_Expression_Recognition_by_LLM_Knowledge_Transfer.md)

- [Efficient Black-box Adversarial Attacks via Bayesian Optimization Guided by a Function Prior](2024年05月29日/Efficient_Black-box_Adversarial_Attacks_via_Bayesian_Optimization_Guided_by_a_Function_Prior.md)

    - [翻译: 利用贝叶斯优化与函数先验指导，实现高效的黑盒对抗攻击策略](2024年05月29日/Efficient_Black-box_Adversarial_Attacks_via_Bayesian_Optimization_Guided_by_a_Function_Prior.md)

- [Multi-stage Retrieve and Re-rank Model for Automatic Medical Coding Recommendation](2024年05月29日/Multi-stage_Retrieve_and_Re-rank_Model_for_Automatic_Medical_Coding_Recommendation.md)

    - [翻译: 自动医疗编码推荐的多阶段检索与重排模型](2024年05月29日/Multi-stage_Retrieve_and_Re-rank_Model_for_Automatic_Medical_Coding_Recommendation.md)

- [Benchmarking and Improving Detail Image Caption](2024年05月29日/Benchmarking_and_Improving_Detail_Image_Caption.md)

    - [翻译: 提升与优化细节图像描述的基准测试](2024年05月29日/Benchmarking_and_Improving_Detail_Image_Caption.md)

- [Cracking the Code of Juxtaposition: Can AI Models Understand the Humorous Contradictions](2024年05月29日/Cracking_the_Code_of_Juxtaposition_Can_AI_Models_Understand_the_Humorous_Contradictions.md)

    - [翻译: 揭秘并置之谜：AI模型能否洞察幽默中的矛盾？](2024年05月29日/Cracking_the_Code_of_Juxtaposition_Can_AI_Models_Understand_the_Humorous_Contradictions.md)

- [MEMoE: Enhancing Model Editing with Mixture of Experts Adaptors](2024年05月29日/MEMoE_Enhancing_Model_Editing_with_Mixture_of_Experts_Adaptors.md)

    - [翻译: MEMoE：利用专家混合适配器提升模型编辑能力](2024年05月29日/MEMoE_Enhancing_Model_Editing_with_Mixture_of_Experts_Adaptors.md)

- [Cephalo: Multi-Modal Vision-Language Models for Bio-Inspired Materials Analysis and Design](2024年05月29日/Cephalo_Multi-Modal_Vision-Language_Models_for_Bio-Inspired_Materials_Analysis_and_Design.md)

    - [翻译: Cephalo：融合视觉与语言的多模态模型，专为仿生材料分析与设计而生](2024年05月29日/Cephalo_Multi-Modal_Vision-Language_Models_for_Bio-Inspired_Materials_Analysis_and_Design.md)

- [BLSP-KD: Bootstrapping Language-Speech Pre-training via Knowledge Distillation](2024年05月29日/BLSP-KD_Bootstrapping_Language-Speech_Pre-training_via_Knowledge_Distillation.md)

    - [翻译: BLSP-KD：借助知识蒸馏推动语言与语音的预训练融合](2024年05月29日/BLSP-KD_Bootstrapping_Language-Speech_Pre-training_via_Knowledge_Distillation.md)

- [Large Language Models for Code Summarization](2024年05月29日/Large_Language_Models_for_Code_Summarization.md)

    - [翻译: 大型语言模型在代码摘要领域的应用](2024年05月29日/Large_Language_Models_for_Code_Summarization.md)

- [DiveR-CT: Diversity-enhanced Red Teaming with Relaxing Constraints](2024年05月29日/DiveR-CT_Diversity-enhanced_Red_Teaming_with_Relaxing_Constraints.md)

    - [翻译: DiveR-CT：解放约束，提升多样性，红队演练新境界](2024年05月29日/DiveR-CT_Diversity-enhanced_Red_Teaming_with_Relaxing_Constraints.md)

- [Examining the development of attitude scales using Large Language Models (LLMs)](2024年05月29日/Examining_the_development_of_attitude_scales_using_Large_Language_Models_(LLMs).md)

    - [翻译: 探究大型语言模型（LLMs）在态度量表发展中的应用](2024年05月29日/Examining_the_development_of_attitude_scales_using_Large_Language_Models_(LLMs).md)

- [Evaluating the External and Parametric Knowledge Fusion of Large Language Models](2024年05月29日/Evaluating_the_External_and_Parametric_Knowledge_Fusion_of_Large_Language_Models.md)

    - [翻译: 探究大型语言模型如何融合外部与参数知识](2024年05月29日/Evaluating_the_External_and_Parametric_Knowledge_Fusion_of_Large_Language_Models.md)

- [Robust Optimization in Protein Fitness Landscapes Using Reinforcement Learning in Latent Space](2024年05月29日/Robust_Optimization_in_Protein_Fitness_Landscapes_Using_Reinforcement_Learning_in_Latent_Space.md)

    - [翻译: 利用强化学习在潜在空间中探索蛋白质适应性景观，实现鲁棒优化](2024年05月29日/Robust_Optimization_in_Protein_Fitness_Landscapes_Using_Reinforcement_Learning_in_Latent_Space.md)

- [Are You Sure? Rank Them Again: Repeated Ranking For Better Preference Datasets](2024年05月29日/Are_You_Sure_Rank_Them_Again_Repeated_Ranking_For_Better_Preference_Datasets.md)

    - [翻译: 真的确定吗？再来一次排名：通过反复排名优化偏好数据集](2024年05月29日/Are_You_Sure_Rank_Them_Again_Repeated_Ranking_For_Better_Preference_Datasets.md)

- [Towards Faithful Chain-of-Thought: Large Language Models are Bridging Reasoners](2024年05月29日/Towards_Faithful_Chain-of-Thought_Large_Language_Models_are_Bridging_Reasoners.md)

    - [翻译: 迈向忠实的思维链：大型语言模型正架起推理者间的桥梁](2024年05月29日/Towards_Faithful_Chain-of-Thought_Large_Language_Models_are_Bridging_Reasoners.md)

- [Language Generation with Strictly Proper Scoring Rules](2024年05月29日/Language_Generation_with_Strictly_Proper_Scoring_Rules.md)

    - [翻译: 严格适当评分规则下的语言生成探索](2024年05月29日/Language_Generation_with_Strictly_Proper_Scoring_Rules.md)

- [Compressing Large Language Models using Low Rank and Low Precision Decomposition](2024年05月29日/Compressing_Large_Language_Models_using_Low_Rank_and_Low_Precision_Decomposition.md)

    - [翻译: 通过低秩与低精度分解精简大型语言模型](2024年05月29日/Compressing_Large_Language_Models_using_Low_Rank_and_Low_Precision_Decomposition.md)

- [Are queries and keys always relevant? A case study on Transformer wave functions](2024年05月29日/Are_queries_and_keys_always_relevant_A_case_study_on_Transformer_wave_functions.md)

    - [翻译: 查询与键是否始终紧密相连？本文通过Transformer波函数的案例研究，探讨了这一问题。](2024年05月29日/Are_queries_and_keys_always_relevant_A_case_study_on_Transformer_wave_functions.md)

- [LLMs achieve adult human performance on higher-order theory of mind tasks](2024年05月29日/LLMs_achieve_adult_human_performance_on_higher-order_theory_of_mind_tasks.md)

    - [翻译: 大型语言模型在高级心智理论任务中展现出与成人相媲美的表现。](2024年05月29日/LLMs_achieve_adult_human_performance_on_higher-order_theory_of_mind_tasks.md)

- [Descriptive Image Quality Assessment in the Wild](2024年05月29日/Descriptive_Image_Quality_Assessment_in_the_Wild.md)

    - [翻译: 自然环境下的图像质量描述性评估](2024年05月29日/Descriptive_Image_Quality_Assessment_in_the_Wild.md)

- [MoNDE: Mixture of Near-Data Experts for Large-Scale Sparse Models](2024年05月29日/MoNDE_Mixture_of_Near-Data_Experts_for_Large-Scale_Sparse_Models.md)

    - [翻译: MoNDE：融合近数据专家的大规模稀疏模型策略](2024年05月29日/MoNDE_Mixture_of_Near-Data_Experts_for_Large-Scale_Sparse_Models.md)

- [MindSemantix: Deciphering Brain Visual Experiences with a Brain-Language Model](2024年05月29日/MindSemantix_Deciphering_Brain_Visual_Experiences_with_a_Brain-Language_Model.md)

    - [翻译: MindSemantix：借助脑语言模型，解码大脑的视觉世界](2024年05月29日/MindSemantix_Deciphering_Brain_Visual_Experiences_with_a_Brain-Language_Model.md)

- [Quantitative Certification of Bias in Large Language Models](2024年05月29日/Quantitative_Certification_of_Bias_in_Large_Language_Models.md)

    - [翻译: 大型语言模型偏差的量化认证](2024年05月29日/Quantitative_Certification_of_Bias_in_Large_Language_Models.md)

- [LMO-DP: Optimizing the Randomization Mechanism for Differentially Private Fine-Tuning (Large) Language Models](2024年05月29日/LMO-DP_Optimizing_the_Randomization_Mechanism_for_Differentially_Private_Fine-Tuning_(Large)_Language_Models.md)

    - [翻译: LMO-DP：为大型语言模型的差分隐私微调优化随机化机制](2024年05月29日/LMO-DP_Optimizing_the_Randomization_Mechanism_for_Differentially_Private_Fine-Tuning_(Large)_Language_Models.md)

- [LLaMA-Reg: Using LLaMA 2 for Unsupervised Medical Image Registration](2024年05月29日/LLaMA-Reg_Using_LLaMA_2_for_Unsupervised_Medical_Image_Registration.md)

    - [翻译: LLaMA-Reg：借助 LLaMA 2 实现无监督医学图像配准](2024年05月29日/LLaMA-Reg_Using_LLaMA_2_for_Unsupervised_Medical_Image_Registration.md)

- [Large Brain Model for Learning Generic Representations with Tremendous EEG Data in BCI](2024年05月29日/Large_Brain_Model_for_Learning_Generic_Representations_with_Tremendous_EEG_Data_in_BCI.md)

    - [翻译: 在脑机接口（BCI）领域，大型脑模型正利用庞大的EEG数据集来学习通用表示，展现出其强大的学习能力。](2024年05月29日/Large_Brain_Model_for_Learning_Generic_Representations_with_Tremendous_EEG_Data_in_BCI.md)

- [PermLLM: Private Inference of Large Language Models within 3 Seconds under WAN](2024年05月29日/PermLLM_Private_Inference_of_Large_Language_Models_within_3_Seconds_under_WAN.md)

    - [翻译: PermLLM：广域网环境下，3秒内实现大型语言模型的隐私保护推理](2024年05月29日/PermLLM_Private_Inference_of_Large_Language_Models_within_3_Seconds_under_WAN.md)

- [Genshin: General Shield for Natural Language Processing with Large Language Models](2024年05月29日/Genshin_General_Shield_for_Natural_Language_Processing_with_Large_Language_Models.md)

    - [翻译: Genshin：大型语言模型在自然语言处理领域的全能守护者](2024年05月29日/Genshin_General_Shield_for_Natural_Language_Processing_with_Large_Language_Models.md)

- [Reverse Image Retrieval Cues Parametric Memory in Multimodal LLMs](2024年05月29日/Reverse_Image_Retrieval_Cues_Parametric_Memory_in_Multimodal_LLMs.md)

    - [翻译: 多模态大型语言模型中的逆向图像检索激活了参数记忆机制。](2024年05月29日/Reverse_Image_Retrieval_Cues_Parametric_Memory_in_Multimodal_LLMs.md)

- [Nearest Neighbor Speculative Decoding for LLM Generation and Attribution](2024年05月29日/Nearest_Neighbor_Speculative_Decoding_for_LLM_Generation_and_Attribution.md)

    - [翻译: 大型语言模型生成与归属的最近邻推测解码法](2024年05月29日/Nearest_Neighbor_Speculative_Decoding_for_LLM_Generation_and_Attribution.md)

- [Leveraging Many-To-Many Relationships for Defending Against Visual-Language Adversarial Attacks](2024年05月29日/Leveraging_Many-To-Many_Relationships_for_Defending_Against_Visual-Language_Adversarial_Attacks.md)

    - [翻译: 借助多对多关系抵御视觉-语言对抗攻击](2024年05月29日/Leveraging_Many-To-Many_Relationships_for_Defending_Against_Visual-Language_Adversarial_Attacks.md)

- [LLMs Meet Multimodal Generation and Editing: A Survey](2024年05月29日/LLMs_Meet_Multimodal_Generation_and_Editing_A_Survey.md)

    - [翻译: 大型语言模型与多模态生成编辑的交汇：一份综述](2024年05月29日/LLMs_Meet_Multimodal_Generation_and_Editing_A_Survey.md)

- [Normative Modules: A Generative Agent Architecture for Learning Norms that Supports Multi-Agent Cooperation](2024年05月29日/Normative_Modules_A_Generative_Agent_Architecture_for_Learning_Norms_that_Supports_Multi-Agent_Cooperation.md)

    - [翻译: 规范学习架构：一种生成代理框架，旨在促进多代理间的合作与规范学习](2024年05月29日/Normative_Modules_A_Generative_Agent_Architecture_for_Learning_Norms_that_Supports_Multi-Agent_Cooperation.md)

- [Language Models Trained to do Arithmetic Predict Human Risky and Intertemporal Choice](2024年05月29日/Language_Models_Trained_to_do_Arithmetic_Predict_Human_Risky_and_Intertemporal_Choice.md)

    - [翻译: 语言模型通过算术训练，能够预测人类的风险决策与时间偏好选择。](2024年05月29日/Language_Models_Trained_to_do_Arithmetic_Predict_Human_Risky_and_Intertemporal_Choice.md)

- [Programmable Motion Generation for Open-Set Motion Control Tasks](2024年05月29日/Programmable_Motion_Generation_for_Open-Set_Motion_Control_Tasks.md)

    - [翻译: 开放集运动控制任务的可编程运动生成](2024年05月29日/Programmable_Motion_Generation_for_Open-Set_Motion_Control_Tasks.md)

- [Multi-Modal Generative Embedding Model](2024年05月29日/Multi-Modal_Generative_Embedding_Model.md)

    - [翻译: 多模态生成式嵌入模型](2024年05月29日/Multi-Modal_Generative_Embedding_Model.md)

- [Adaptive Image Quality Assessment via Teaching Large Multimodal Model to Compare](2024年05月29日/Adaptive_Image_Quality_Assessment_via_Teaching_Large_Multimodal_Model_to_Compare.md)

    - [翻译: 借助大型多模态模型进行比较学习，实现图像质量的自适应评估](2024年05月29日/Adaptive_Image_Quality_Assessment_via_Teaching_Large_Multimodal_Model_to_Compare.md)

- [Exploring Exotic Decays of the Higgs Boson to Multi-Photons at the LHC via Multimodal Learning Approaches](2024年05月29日/Exploring_Exotic_Decays_of_the_Higgs_Boson_to_Multi-Photons_at_the_LHC_via_Multimodal_Learning_Approaches.md)

    - [翻译: 利用多模态学习方法，在大型强子对撞机（LHC）上探究希格斯玻色子向多光子衰变的奇异现象](2024年05月29日/Exploring_Exotic_Decays_of_the_Higgs_Boson_to_Multi-Photons_at_the_LHC_via_Multimodal_Learning_Approaches.md)

- [X-VILA: Cross-Modality Alignment for Large Language Model](2024年05月29日/X-VILA_Cross-Modality_Alignment_for_Large_Language_Model.md)

    - [翻译: X-VILA：大型语言模型中的跨模态对齐技术](2024年05月29日/X-VILA_Cross-Modality_Alignment_for_Large_Language_Model.md)

- [Self-Exploring Language Models: Active Preference Elicitation for Online Alignment](2024年05月29日/Self-Exploring_Language_Models_Active_Preference_Elicitation_for_Online_Alignment.md)

    - [翻译: 语言模型的自我探索：通过主动偏好诱导实现在线对齐](2024年05月29日/Self-Exploring_Language_Models_Active_Preference_Elicitation_for_Online_Alignment.md)

- [MAP-Neo: Highly Capable and Transparent Bilingual Large Language Model Series](2024年05月29日/MAP-Neo_Highly_Capable_and_Transparent_Bilingual_Large_Language_Model_Series.md)

    - [翻译: MAP-Neo系列：高效透明的双语大型语言模型](2024年05月29日/MAP-Neo_Highly_Capable_and_Transparent_Bilingual_Large_Language_Model_Series.md)

- [Reasoning3D -- Grounding and Reasoning in 3D: Fine-Grained Zero-Shot Open-Vocabulary 3D Reasoning Part Segmentation via Large Vision-Language Models](2024年05月29日/Reasoning3D_--_Grounding_and_Reasoning_in_3D_Fine-Grained_Zero-Shot_Open-Vocabulary_3D_Reasoning_Part_Segmentation_via_Large_Vision-Language_Models.md)

    - [翻译: Reasoning3D - 大型视觉-语言模型助力细粒度零-shot开放词汇3D推理部分分割，探索3D空间中的基础与推理。](2024年05月29日/Reasoning3D_--_Grounding_and_Reasoning_in_3D_Fine-Grained_Zero-Shot_Open-Vocabulary_3D_Reasoning_Part_Segmentation_via_Large_Vision-Language_Models.md)

- [Are Large Language Models Chameleons?](2024年05月29日/Are_Large_Language_Models_Chameleons.md)

    - [翻译: 大型语言模型是否具有变色龙般的适应性？](2024年05月29日/Are_Large_Language_Models_Chameleons.md)

- [Value-Incentivized Preference Optimization: A Unified Approach to Online and Offline RLHF](2024年05月29日/Value-Incentivized_Preference_Optimization_A_Unified_Approach_to_Online_and_Offline_RLHF.md)

    - [翻译: 价值驱动偏好优化：融合在线与离线 RLHF 的统一策略](2024年05月29日/Value-Incentivized_Preference_Optimization_A_Unified_Approach_to_Online_and_Offline_RLHF.md)

- [Matryoshka Query Transformer for Large Vision-Language Models](2024年05月29日/Matryoshka_Query_Transformer_for_Large_Vision-Language_Models.md)

    - [翻译: 大型视觉-语言模型的嵌套查询转换器](2024年05月29日/Matryoshka_Query_Transformer_for_Large_Vision-Language_Models.md)

- [Expert-Guided Extinction of Toxic Tokens for Debiased Generation](2024年05月29日/Expert-Guided_Extinction_of_Toxic_Tokens_for_Debiased_Generation.md)

    - [翻译: 专家指导下的毒性词汇消除，助力公正生成](2024年05月29日/Expert-Guided_Extinction_of_Toxic_Tokens_for_Debiased_Generation.md)

- [MASSIVE Multilingual Abstract Meaning Representation: A Dataset and Baselines for Hallucination Detection](2024年05月29日/MASSIVE_Multilingual_Abstract_Meaning_Representation_A_Dataset_and_Baselines_for_Hallucination_Detection.md)

    - [翻译: 巨型多语种抽象意义表示：幻觉检测的数据集与基准](2024年05月29日/MASSIVE_Multilingual_Abstract_Meaning_Representation_A_Dataset_and_Baselines_for_Hallucination_Detection.md)

- [PediatricsGPT: Large Language Models as Chinese Medical Assistants for Pediatric Applications](2024年05月29日/PediatricsGPT_Large_Language_Models_as_Chinese_Medical_Assistants_for_Pediatric_Applications.md)

    - [翻译: PediatricsGPT：大型语言模型在儿科领域中担任中文医疗助手的新角色](2024年05月29日/PediatricsGPT_Large_Language_Models_as_Chinese_Medical_Assistants_for_Pediatric_Applications.md)

- [AlchemistCoder: Harmonizing and Eliciting Code Capability by Hindsight Tuning on Multi-source Data](2024年05月29日/AlchemistCoder_Harmonizing_and_Eliciting_Code_Capability_by_Hindsight_Tuning_on_Multi-source_Data.md)

    - [翻译: 炼金术士编码器：借助多源数据的事后调优，巧妙融合并提升代码潜能](2024年05月29日/AlchemistCoder_Harmonizing_and_Eliciting_Code_Capability_by_Hindsight_Tuning_on_Multi-source_Data.md)

- [Weak-to-Strong Search: Align Large Language Models via Searching over Small Language Models](2024年05月29日/Weak-to-Strong_Search_Align_Large_Language_Models_via_Searching_over_Small_Language_Models.md)

    - [翻译: 从弱至强搜索：借助小语言模型探索，实现大型语言模型的精准对齐](2024年05月29日/Weak-to-Strong_Search_Align_Large_Language_Models_via_Searching_over_Small_Language_Models.md)

- [One Token Can Help! Learning Scalable and Pluggable Virtual Tokens for Retrieval-Augmented Large Language Models](2024年05月29日/One_Token_Can_Help!_Learning_Scalable_and_Pluggable_Virtual_Tokens_for_Retrieval-Augmented_Large_Language_Models.md)

    - [翻译: 一标记之力！探索可扩展与可插拔的虚拟标记，助力大型语言模型检索增强。](2024年05月29日/One_Token_Can_Help!_Learning_Scalable_and_Pluggable_Virtual_Tokens_for_Retrieval-Augmented_Large_Language_Models.md)

- [AutoBreach: Universal and Adaptive Jailbreaking with Efficient Wordplay-Guided Optimization](2024年05月29日/AutoBreach_Universal_and_Adaptive_Jailbreaking_with_Efficient_Wordplay-Guided_Optimization.md)

    - [翻译: AutoBreach：一种通用且自适应的越狱方法，通过高效的文字游戏策略进行优化，旨在突破各种限制。](2024年05月29日/AutoBreach_Universal_and_Adaptive_Jailbreaking_with_Efficient_Wordplay-Guided_Optimization.md)

- [PATIENT-Ψ: Using Large Language Models to Simulate Patients for Training Mental Health Professionals](2024年05月29日/PATIENT-Ψ_Using_Large_Language_Models_to_Simulate_Patients_for_Training_Mental_Health_Professionals.md)

    - [翻译: PATIENT-Ψ计划：借助大型语言模型，模拟患者情境，以精进心理健康专业人员的培训。](2024年05月29日/PATIENT-Ψ_Using_Large_Language_Models_to_Simulate_Patients_for_Training_Mental_Health_Professionals.md)

- [SysCaps: Language Interfaces for Simulation Surrogates of Complex Systems](2024年05月29日/SysCaps_Language_Interfaces_for_Simulation_Surrogates_of_Complex_Systems.md)

    - [翻译: SysCaps：复杂系统模拟代理的语言交互界面](2024年05月29日/SysCaps_Language_Interfaces_for_Simulation_Surrogates_of_Complex_Systems.md)

- [Detecting Hallucinations in Large Language Model Generation: A Token Probability Approach](2024年05月29日/Detecting_Hallucinations_in_Large_Language_Model_Generation_A_Token_Probability_Approach.md)

    - [翻译: 检测大规模语言模型生成中的幻觉：基于词元概率的新途径](2024年05月29日/Detecting_Hallucinations_in_Large_Language_Model_Generation_A_Token_Probability_Approach.md)

- [Creating Language-driven Spatial Variations of Icon Images](2024年05月29日/Creating_Language-driven_Spatial_Variations_of_Icon_Images.md)

    - [翻译: 利用语言驱动图标图像的空间多样性](2024年05月29日/Creating_Language-driven_Spatial_Variations_of_Icon_Images.md)

- [GKT: A Novel Guidance-Based Knowledge Transfer Framework For Efficient Cloud-edge Collaboration LLM Deployment](2024年05月29日/GKT_A_Novel_Guidance-Based_Knowledge_Transfer_Framework_For_Efficient_Cloud-edge_Collaboration_LLM_Deployment.md)

    - [翻译: GKT：一种创新的指导式知识转移框架，旨在优化云与边缘间的协作，以实现大型语言模型的高效部署。](2024年05月29日/GKT_A_Novel_Guidance-Based_Knowledge_Transfer_Framework_For_Efficient_Cloud-edge_Collaboration_LLM_Deployment.md)

- [Keyword-driven Retrieval-Augmented Large Language Models for Cold-start User Recommendations](2024年05月29日/Keyword-driven_Retrieval-Augmented_Large_Language_Models_for_Cold-start_User_Recommendations.md)

    - [翻译: 利用关键词驱动检索增强的大型语言模型，为冷启动用户提供精准推荐](2024年05月29日/Keyword-driven_Retrieval-Augmented_Large_Language_Models_for_Cold-start_User_Recommendations.md)

- [Unlearning Climate Misinformation in Large Language Models](2024年05月29日/Unlearning_Climate_Misinformation_in_Large_Language_Models.md)

    - [翻译: 清除大型语言模型中的气候错误信息](2024年05月29日/Unlearning_Climate_Misinformation_in_Large_Language_Models.md)

- [Two-layer retrieval augmented generation framework for low-resource medical question-answering: proof of concept using Reddit data](2024年05月29日/Two-layer_retrieval_augmented_generation_framework_for_low-resource_medical_question-answering_proof_of_concept_using_Reddit_data.md)

    - [翻译: 双层检索增强生成框架：在低资源医疗问答中，通过 Reddit 数据验证其概念。](2024年05月29日/Two-layer_retrieval_augmented_generation_framework_for_low-resource_medical_question-answering_proof_of_concept_using_Reddit_data.md)

- [An Automated Startup Evaluation Pipeline: Startup Success Forecasting Framework (SSFF)](2024年05月29日/An_Automated_Startup_Evaluation_Pipeline_Startup_Success_Forecasting_Framework_(SSFF).md)

    - [翻译: 创业成功预测框架（SSFF）：一套自动化评估创业潜力的流程。](2024年05月29日/An_Automated_Startup_Evaluation_Pipeline_Startup_Success_Forecasting_Framework_(SSFF).md)

- [Adaptive In-conversation Team Building for Language Model Agents](2024年05月29日/Adaptive_In-conversation_Team_Building_for_Language_Model_Agents.md)

    - [翻译: 语言模型代理的自适应对话团队构建](2024年05月29日/Adaptive_In-conversation_Team_Building_for_Language_Model_Agents.md)

- [Unlocking the Potential of Large Language Models for Clinical Text Anonymization: A Comparative Study](2024年05月29日/Unlocking_the_Potential_of_Large_Language_Models_for_Clinical_Text_Anonymization_A_Comparative_Study.md)

    - [翻译: 探索大型语言模型在临床文本匿名化中的潜能：一场比较研究的探索之旅](2024年05月29日/Unlocking_the_Potential_of_Large_Language_Models_for_Clinical_Text_Anonymization_A_Comparative_Study.md)

- [Conveyor: Efficient Tool-aware LLM Serving with Tool Partial Execution](2024年05月29日/Conveyor_Efficient_Tool-aware_LLM_Serving_with_Tool_Partial_Execution.md)

    - [翻译: Conveyor：一种高效的大型语言模型服务系统，专为工具感知设计，支持工具的部分执行，以提升服务效率。](2024年05月29日/Conveyor_Efficient_Tool-aware_LLM_Serving_with_Tool_Partial_Execution.md)

- [Toward Conversational Agents with Context and Time Sensitive Long-term Memory](2024年05月29日/Toward_Conversational_Agents_with_Context_and_Time_Sensitive_Long-term_Memory.md)

    - [翻译: 构建具备上下文感知与时间敏感长期记忆的对话机器人](2024年05月29日/Toward_Conversational_Agents_with_Context_and_Time_Sensitive_Long-term_Memory.md)

2024年05月28日

- [Facilitating Multi-Role and Multi-Behavior Collaboration of Large Language Models for Online Job Seeking and Recruiting](2024年05月28日/Facilitating_Multi-Role_and_Multi-Behavior_Collaboration_of_Large_Language_Models_for_Online_Job_Seeking_and_Recruiting.md)

    - [翻译: 助力大型语言模型实现在线求职与招聘的多角色多行为协同](2024年05月28日/Facilitating_Multi-Role_and_Multi-Behavior_Collaboration_of_Large_Language_Models_for_Online_Job_Seeking_and_Recruiting.md)

- [ATM: Adversarial Tuning Multi-agent System Makes a Robust Retrieval-Augmented Generator](2024年05月28日/ATM_Adversarial_Tuning_Multi-agent_System_Makes_a_Robust_Retrieval-Augmented_Generator.md)

    - [翻译: ATM：通过对抗性调整的多代理系统，打造了一个更为稳健的检索增强生成器](2024年05月28日/ATM_Adversarial_Tuning_Multi-agent_System_Makes_a_Robust_Retrieval-Augmented_Generator.md)

- [LLM experiments with simulation: Large Language Model Multi-Agent System for Process Simulation Parametrization in Digital Twins](2024年05月28日/LLM_experiments_with_simulation_Large_Language_Model_Multi-Agent_System_for_Process_Simulation_Parametrization_in_Digital_Twins.md)

    - [翻译: 大型语言模型多代理系统：探索数字孪生中的过程模拟参数化](2024年05月28日/LLM_experiments_with_simulation_Large_Language_Model_Multi-Agent_System_for_Process_Simulation_Parametrization_in_Digital_Twins.md)

- [White-box Multimodal Jailbreaks Against Large Vision-Language Models](2024年05月28日/White-box_Multimodal_Jailbreaks_Against_Large_Vision-Language_Models.md)

    - [翻译: 大型视觉-语言模型面临的白盒多模态越狱挑战](2024年05月28日/White-box_Multimodal_Jailbreaks_Against_Large_Vision-Language_Models.md)

- [Full-Stack Allreduce on Multi-Rail Networks](2024年05月28日/Full-Stack_Allreduce_on_Multi-Rail_Networks.md)

    - [翻译: 多轨网络上的全栈 Allreduce 技术](2024年05月28日/Full-Stack_Allreduce_on_Multi-Rail_Networks.md)

- [Visual Anchors Are Strong Information Aggregators For Multimodal Large Language Model](2024年05月28日/Visual_Anchors_Are_Strong_Information_Aggregators_For_Multimodal_Large_Language_Model.md)

    - [翻译: 视觉锚点在多模态大型语言模型中扮演着强大的信息聚合角色。](2024年05月28日/Visual_Anchors_Are_Strong_Information_Aggregators_For_Multimodal_Large_Language_Model.md)

- [Semantic are Beacons: A Semantic Perspective for Unveiling Parameter-Efficient Fine-Tuning in Knowledge Learning](2024年05月28日/Semantic_are_Beacons_A_Semantic_Perspective_for_Unveiling_Parameter-Efficient_Fine-Tuning_in_Knowledge_Learning.md)

    - [翻译: 语义如灯塔：探索知识学习中参数高效微调的语义视角](2024年05月28日/Semantic_are_Beacons_A_Semantic_Perspective_for_Unveiling_Parameter-Efficient_Fine-Tuning_in_Knowledge_Learning.md)

- [Metaheuristics and Large Language Models Join Forces: Towards an Integrated Optimization Approach](2024年05月28日/Metaheuristics_and_Large_Language_Models_Join_Forces_Towards_an_Integrated_Optimization_Approach.md)

    - [翻译: 元启发式算法与大型语言模型携手合作，共同探索一体化优化的新途径。](2024年05月28日/Metaheuristics_and_Large_Language_Models_Join_Forces_Towards_an_Integrated_Optimization_Approach.md)

- [Text-only Synthesis for Image Captioning](2024年05月28日/Text-only_Synthesis_for_Image_Captioning.md)

    - [翻译: 图像标题生成中的纯文本合成](2024年05月28日/Text-only_Synthesis_for_Image_Captioning.md)

- [Active Use of Latent Constituency Representation in both Humans and Large Language Models](2024年05月28日/Active_Use_of_Latent_Constituency_Representation_in_both_Humans_and_Large_Language_Models.md)

    - [翻译: 人类与大型语言模型均积极运用潜在成分表示，本研究探讨了这一现象及其在语言处理中的应用。](2024年05月28日/Active_Use_of_Latent_Constituency_Representation_in_both_Humans_and_Large_Language_Models.md)

- [FinerCut: Finer-grained Interpretable Layer Pruning for Large Language Models](2024年05月28日/FinerCut_Finer-grained_Interpretable_Layer_Pruning_for_Large_Language_Models.md)

    - [翻译: FinerCut：精细剪枝大型语言模型的可解释层，实现更细粒度的优化。](2024年05月28日/FinerCut_Finer-grained_Interpretable_Layer_Pruning_for_Large_Language_Models.md)

- [A Human-Like Reasoning Framework for Multi-Phases Planning Task with Large Language Models](2024年05月28日/A_Human-Like_Reasoning_Framework_for_Multi-Phases_Planning_Task_with_Large_Language_Models.md)

    - [翻译: 大型语言模型在多阶段规划任务中的人类式推理框架](2024年05月28日/A_Human-Like_Reasoning_Framework_for_Multi-Phases_Planning_Task_with_Large_Language_Models.md)

- [IAPT: Instruction-Aware Prompt Tuning for Large Language Models](2024年05月28日/IAPT_Instruction-Aware_Prompt_Tuning_for_Large_Language_Models.md)

    - [翻译: IAPT：大型语言模型中的指令感知提示优化](2024年05月28日/IAPT_Instruction-Aware_Prompt_Tuning_for_Large_Language_Models.md)

- [Defending Large Language Models Against Jailbreak Attacks via Layer-specific Editing](2024年05月28日/Defending_Large_Language_Models_Against_Jailbreak_Attacks_via_Layer-specific_Editing.md)

    - [翻译: 利用层级特定编辑技术，为大型语言模型筑起抵御越狱攻击的防线](2024年05月28日/Defending_Large_Language_Models_Against_Jailbreak_Attacks_via_Layer-specific_Editing.md)

- [Exploiting LLM Quantization](2024年05月28日/Exploiting_LLM_Quantization.md)

    - [翻译: 挖掘大型语言模型的量化潜力](2024年05月28日/Exploiting_LLM_Quantization.md)

- [Pipette: Automatic Fine-grained Large Language Model Training Configurator for Real-World Clusters](2024年05月28日/Pipette_Automatic_Fine-grained_Large_Language_Model_Training_Configurator_for_Real-World_Clusters.md)

    - [翻译: Pipette：现实世界集群中大型语言模型训练参数的自动细粒度配置器](2024年05月28日/Pipette_Automatic_Fine-grained_Large_Language_Model_Training_Configurator_for_Real-World_Clusters.md)

- [Towards Dialogues for Joint Human-AI Reasoning and Value Alignment](2024年05月28日/Towards_Dialogues_for_Joint_Human-AI_Reasoning_and_Value_Alignment.md)

    - [翻译: 探索人机协同推理与价值对齐的对话之路](2024年05月28日/Towards_Dialogues_for_Joint_Human-AI_Reasoning_and_Value_Alignment.md)

- [Automated Real-World Sustainability Data Generation from Images of Buildings](2024年05月28日/Automated_Real-World_Sustainability_Data_Generation_from_Images_of_Buildings.md)

    - [翻译: 建筑图像自动生成真实世界可持续性数据](2024年05月28日/Automated_Real-World_Sustainability_Data_Generation_from_Images_of_Buildings.md)

- [Towards Integrating Emerging AI Applications in SE Education](2024年05月28日/Towards_Integrating_Emerging_AI_Applications_in_SE_Education.md)

    - [翻译: 迈向软件工程教育中集成新兴AI应用之路](2024年05月28日/Towards_Integrating_Emerging_AI_Applications_in_SE_Education.md)

- [Large Language Model-Driven Curriculum Design for Mobile Networks](2024年05月28日/Large_Language_Model-Driven_Curriculum_Design_for_Mobile_Networks.md)

    - [翻译: 利用大型语言模型优化移动网络课程设计](2024年05月28日/Large_Language_Model-Driven_Curriculum_Design_for_Mobile_Networks.md)

- [Instruction Tuning with Retrieval-based Examples Ranking for Aspect-based Sentiment Analysis](2024年05月28日/Instruction_Tuning_with_Retrieval-based_Examples_Ranking_for_Aspect-based_Sentiment_Analysis.md)

    - [翻译: 在基于方面的情感分析中，采用基于检索示例排名的指令调优方法。](2024年05月28日/Instruction_Tuning_with_Retrieval-based_Examples_Ranking_for_Aspect-based_Sentiment_Analysis.md)

- [Edinburgh Clinical NLP at MEDIQA-CORR 2024: Guiding Large Language Models with Hints](2024年05月28日/Edinburgh_Clinical_NLP_at_MEDIQA-CORR_2024_Guiding_Large_Language_Models_with_Hints.md)

    - [翻译: 2024年MEDIQA-CORR大会上，爱丁堡临床NLP团队展示了如何巧妙地利用提示来引导大型语言模型，以提升其在医疗领域的应用效果。](2024年05月28日/Edinburgh_Clinical_NLP_at_MEDIQA-CORR_2024_Guiding_Large_Language_Models_with_Hints.md)

- [TimeChara: Evaluating Point-in-Time Character Hallucination of Role-Playing Large Language Models](2024年05月28日/TimeChara_Evaluating_Point-in-Time_Character_Hallucination_of_Role-Playing_Large_Language_Models.md)

    - [翻译: TimeChara：探究大型语言模型在角色扮演中特定时刻的角色幻觉现象评估](2024年05月28日/TimeChara_Evaluating_Point-in-Time_Character_Hallucination_of_Role-Playing_Large_Language_Models.md)

- [Exploring Context Window of Large Language Models via Decomposed Positional Vectors](2024年05月28日/Exploring_Context_Window_of_Large_Language_Models_via_Decomposed_Positional_Vectors.md)

    - [翻译: 探究大型语言模型上下文窗口：分解位置向量之法](2024年05月28日/Exploring_Context_Window_of_Large_Language_Models_via_Decomposed_Positional_Vectors.md)

- [SkinCAP: A Multi-modal Dermatology Dataset Annotated with Rich Medical Captions](2024年05月28日/SkinCAP_A_Multi-modal_Dermatology_Dataset_Annotated_with_Rich_Medical_Captions.md)

    - [翻译: SkinCAP：一个集多模态数据与丰富医学标注于一体的皮肤病学数据集](2024年05月28日/SkinCAP_A_Multi-modal_Dermatology_Dataset_Annotated_with_Rich_Medical_Captions.md)

- [fMRI predictors based on language models of increasing complexity recover brain left lateralization](2024年05月28日/fMRI_predictors_based_on_language_models_of_increasing_complexity_recover_brain_left_lateralization.md)

    - [翻译: 随着语言模型复杂度的提升，基于这些模型的fMRI预测器成功揭示了大脑左半球的侧化特征。](2024年05月28日/fMRI_predictors_based_on_language_models_of_increasing_complexity_recover_brain_left_lateralization.md)

- [VeLoRA: Memory Efficient Training using Rank-1 Sub-Token Projections](2024年05月28日/VeLoRA_Memory_Efficient_Training_using_Rank-1_Sub-Token_Projections.md)

    - [翻译: VeLoRA：借助秩-1 子令牌投影实现内存高效训练](2024年05月28日/VeLoRA_Memory_Efficient_Training_using_Rank-1_Sub-Token_Projections.md)

- [Peering into the Mind of Language Models: An Approach for Attribution in Contextual Question Answering](2024年05月28日/Peering_into_the_Mind_of_Language_Models_An_Approach_for_Attribution_in_Contextual_Question_Answering.md)

    - [翻译: 探索语言模型的思维：一种上下文问答中归因的新途径](2024年05月28日/Peering_into_the_Mind_of_Language_Models_An_Approach_for_Attribution_in_Contextual_Question_Answering.md)

- [Aligning to Thousands of Preferences via System Message Generalization](2024年05月28日/Aligning_to_Thousands_of_Preferences_via_System_Message_Generalization.md)

    - [翻译: 借助系统消息泛化，精准匹配数千种偏好](2024年05月28日/Aligning_to_Thousands_of_Preferences_via_System_Message_Generalization.md)

- [Recent Trends in Personalized Dialogue Generation: A Review of Datasets, Methodologies, and Evaluations](2024年05月28日/Recent_Trends_in_Personalized_Dialogue_Generation_A_Review_of_Datasets,_Methodologies,_and_Evaluations.md)

    - [翻译: 个性化对话生成：探索最新趋势与方法论，涵盖数据集与评估的全面综述](2024年05月28日/Recent_Trends_in_Personalized_Dialogue_Generation_A_Review_of_Datasets,_Methodologies,_and_Evaluations.md)

- [Knowledge Circuits in Pretrained Transformers](2024年05月28日/Knowledge_Circuits_in_Pretrained_Transformers.md)

    - [翻译: 预训练变换器中的知识流通路径](2024年05月28日/Knowledge_Circuits_in_Pretrained_Transformers.md)

- [Hybrid Preference Optimization: Augmenting Direct Preference Optimization with Auxiliary Objectives](2024年05月28日/Hybrid_Preference_Optimization_Augmenting_Direct_Preference_Optimization_with_Auxiliary_Objectives.md)

    - [翻译: 偏好优化新思路：融合直接偏好优化与辅助目标，共同提升优化效果。](2024年05月28日/Hybrid_Preference_Optimization_Augmenting_Direct_Preference_Optimization_with_Auxiliary_Objectives.md)

- [Self-Guiding Exploration for Combinatorial Problems](2024年05月28日/Self-Guiding_Exploration_for_Combinatorial_Problems.md)

    - [翻译: 组合问题中的自引导探索策略](2024年05月28日/Self-Guiding_Exploration_for_Combinatorial_Problems.md)

- [Tool Learning with Large Language Models: A Survey](2024年05月28日/Tool_Learning_with_Large_Language_Models_A_Survey.md)

    - [翻译: 大型语言模型在工具学习领域的应用综述](2024年05月28日/Tool_Learning_with_Large_Language_Models_A_Survey.md)

- [Proof of Quality: A Costless Paradigm for Trustless Generative AI Model Inference on Blockchains](2024年05月28日/Proof_of_Quality_A_Costless_Paradigm_for_Trustless_Generative_AI_Model_Inference_on_Blockchains.md)

    - [翻译: 质量验证：区块链上无需信任的生成式AI模型推理的无成本新范式](2024年05月28日/Proof_of_Quality_A_Costless_Paradigm_for_Trustless_Generative_AI_Model_Inference_on_Blockchains.md)

- [Online Merging Optimizers for Boosting Rewards and Mitigating Tax in Alignment](2024年05月28日/Online_Merging_Optimizers_for_Boosting_Rewards_and_Mitigating_Tax_in_Alignment.md)

    - [翻译: 在线合并优化器：提升奖励，减轻对齐中的税收负担](2024年05月28日/Online_Merging_Optimizers_for_Boosting_Rewards_and_Mitigating_Tax_in_Alignment.md)

- [Long Context is Not Long at All: A Prospector of Long-Dependency Data for Large Language Models](2024年05月28日/Long_Context_is_Not_Long_at_All_A_Prospector_of_Long-Dependency_Data_for_Large_Language_Models.md)

    - [翻译: 长依赖并非遥不可及：探索大型语言模型中的长上下文数据](2024年05月28日/Long_Context_is_Not_Long_at_All_A_Prospector_of_Long-Dependency_Data_for_Large_Language_Models.md)

- [Boosting Protein Language Models with Negative Sample Mining](2024年05月28日/Boosting_Protein_Language_Models_with_Negative_Sample_Mining.md)

    - [翻译: 利用负样本挖掘优化蛋白质语言模型性能](2024年05月28日/Boosting_Protein_Language_Models_with_Negative_Sample_Mining.md)

- [Arithmetic Reasoning with LLM: Prolog Generation & Permutation](2024年05月28日/Arithmetic_Reasoning_with_LLM_Prolog_Generation_&_Permutation.md)

    - [翻译: 利用LLM进行算术推理：探索Prolog生成与排列的奥秘](2024年05月28日/Arithmetic_Reasoning_with_LLM_Prolog_Generation_&_Permutation.md)

- [SLMRec: Empowering Small Language Models for Sequential Recommendation](2024年05月28日/SLMRec_Empowering_Small_Language_Models_for_Sequential_Recommendation.md)

    - [翻译: SLMRec：小型语言模型在序列推荐中的赋能](2024年05月28日/SLMRec_Empowering_Small_Language_Models_for_Sequential_Recommendation.md)

- [I-LLM: Efficient Integer-Only Inference for Fully-Quantized Low-Bit Large Language Models](2024年05月28日/I-LLM_Efficient_Integer-Only_Inference_for_Fully-Quantized_Low-Bit_Large_Language_Models.md)

    - [翻译: I-LLM：全量化低比特大型语言模型的整数推理优化](2024年05月28日/I-LLM_Efficient_Integer-Only_Inference_for_Fully-Quantized_Low-Bit_Large_Language_Models.md)

- [Safety Control of Service Robots with LLMs and Embodied Knowledge Graphs](2024年05月28日/Safety_Control_of_Service_Robots_with_LLMs_and_Embodied_Knowledge_Graphs.md)

    - [翻译: 结合大型语言模型与具身知识图谱，提升服务机器人的安全控制水平](2024年05月28日/Safety_Control_of_Service_Robots_with_LLMs_and_Embodied_Knowledge_Graphs.md)

- [Enabling Generative Design Tools with LLM Agents for Building Novel Devices: A Case Study on Fluidic Computation Interfaces](2024年05月28日/Enabling_Generative_Design_Tools_with_LLM_Agents_for_Building_Novel_Devices_A_Case_Study_on_Fluidic_Computation_Interfaces.md)

    - [翻译: 利用LLM代理赋能生成设计工具，探索新型设备构建——以流体计算接口为例](2024年05月28日/Enabling_Generative_Design_Tools_with_LLM_Agents_for_Building_Novel_Devices_A_Case_Study_on_Fluidic_Computation_Interfaces.md)

- [More Than Catastrophic Forgetting: Integrating General Capabilities For Domain-Specific LLMs](2024年05月28日/More_Than_Catastrophic_Forgetting_Integrating_General_Capabilities_For_Domain-Specific_LLMs.md)

    - [翻译: 超越灾难性遗忘：为特定领域LLMs注入通用能力](2024年05月28日/More_Than_Catastrophic_Forgetting_Integrating_General_Capabilities_For_Domain-Specific_LLMs.md)

- [Conv-CoA: Improving Open-domain Question Answering in Large Language Models via Conversational Chain-of-Action](2024年05月28日/Conv-CoA_Improving_Open-domain_Question_Answering_in_Large_Language_Models_via_Conversational_Chain-of-Action.md)

    - [翻译: Conv-CoA：借助对话链式行动优化大型语言模型中的开放领域问答性能](2024年05月28日/Conv-CoA_Improving_Open-domain_Question_Answering_in_Large_Language_Models_via_Conversational_Chain-of-Action.md)

- [RITUAL: Random Image Transformations as a Universal Anti-hallucination Lever in LVLMs](2024年05月28日/RITUAL_Random_Image_Transformations_as_a_Universal_Anti-hallucination_Lever_in_LVLMs.md)

    - [翻译: RITUAL：大型视觉语言模型中的随机图像变换——一种通用的抗幻觉策略](2024年05月28日/RITUAL_Random_Image_Transformations_as_a_Universal_Anti-hallucination_Lever_in_LVLMs.md)

- [Don't Miss the Forest for the Trees: Attentional Vision Calibration for Large Vision Language Models](2024年05月28日/Don't_Miss_the_Forest_for_the_Trees_Attentional_Vision_Calibration_for_Large_Vision_Language_Models.md)

    - [翻译: 勿因树木而失森林：大型视觉语言模型的注意力视觉校准](2024年05月28日/Don't_Miss_the_Forest_for_the_Trees_Attentional_Vision_Calibration_for_Large_Vision_Language_Models.md)

- [Detection-Correction Structure via General Language Model for Grammatical Error Correction](2024年05月28日/Detection-Correction_Structure_via_General_Language_Model_for_Grammatical_Error_Correction.md)

    - [翻译: 利用通用语言模型构建的语法错误检测与修正框架](2024年05月28日/Detection-Correction_Structure_via_General_Language_Model_for_Grammatical_Error_Correction.md)

- [Don't Forget to Connect! Improving RAG with Graph-based Reranking](2024年05月28日/Don't_Forget_to_Connect!_Improving_RAG_with_Graph-based_Reranking.md)

    - [翻译: 别忘了连线！利用图结构重新排序提升 RAG 性能](2024年05月28日/Don't_Forget_to_Connect!_Improving_RAG_with_Graph-based_Reranking.md)

- [Bridging the Gap: Dynamic Learning Strategies for Improving Multilingual Performance in LLMs](2024年05月28日/Bridging_the_Gap_Dynamic_Learning_Strategies_for_Improving_Multilingual_Performance_in_LLMs.md)

    - [翻译: 跨越鸿沟：采用动态学习策略提升大型语言模型在多语言环境下的表现](2024年05月28日/Bridging_the_Gap_Dynamic_Learning_Strategies_for_Improving_Multilingual_Performance_in_LLMs.md)

- [MMCTAgent: Multi-modal Critical Thinking Agent Framework for Complex Visual Reasoning](2024年05月28日/MMCTAgent_Multi-modal_Critical_Thinking_Agent_Framework_for_Complex_Visual_Reasoning.md)

    - [翻译: MMCTAgent：复杂视觉推理的多模态批判性思维框架，专为提升代理的深度思考能力而设计。](2024年05月28日/MMCTAgent_Multi-modal_Critical_Thinking_Agent_Framework_for_Complex_Visual_Reasoning.md)

- [Empowering Source-Free Domain Adaptation with MLLM-driven Curriculum Learning](2024年05月28日/Empowering_Source-Free_Domain_Adaptation_with_MLLM-driven_Curriculum_Learning.md)

    - [翻译: 借助多语言大型语言模型驱动的课程学习，提升源自由域适应能力](2024年05月28日/Empowering_Source-Free_Domain_Adaptation_with_MLLM-driven_Curriculum_Learning.md)

- [Multi-modal Generation via Cross-Modal In-Context Learning](2024年05月28日/Multi-modal_Generation_via_Cross-Modal_In-Context_Learning.md)

    - [翻译: 跨模态上下文学习驱动多模态内容生成](2024年05月28日/Multi-modal_Generation_via_Cross-Modal_In-Context_Learning.md)

- [Instruct-MusicGen: Unlocking Text-to-Music Editing for Music Language Models via Instruction Tuning](2024年05月28日/Instruct-MusicGen_Unlocking_Text-to-Music_Editing_for_Music_Language_Models_via_Instruction_Tuning.md)

    - [翻译: Instruct-MusicGen：借助指令调谐，开启音乐语言模型的文本至音乐编辑新篇章](2024年05月28日/Instruct-MusicGen_Unlocking_Text-to-Music_Editing_for_Music_Language_Models_via_Instruction_Tuning.md)

- [OwLore: Outlier-weighed Layerwise Sampled Low-Rank Projection for Memory-Efficient LLM Fine-tuning](2024年05月28日/OwLore_Outlier-weighed_Layerwise_Sampled_Low-Rank_Projection_for_Memory-Efficient_LLM_Fine-tuning.md)

    - [翻译: OwLore：一种针对 LLM 微调的内存高效方法，通过异常值加权层级采样实现低秩投影。](2024年05月28日/OwLore_Outlier-weighed_Layerwise_Sampled_Low-Rank_Projection_for_Memory-Efficient_LLM_Fine-tuning.md)

- [LLaMA-NAS: Efficient Neural Architecture Search for Large Language Models](2024年05月28日/LLaMA-NAS_Efficient_Neural_Architecture_Search_for_Large_Language_Models.md)

    - [翻译: LLaMA-NAS：大型语言模型的精妙神经架构探索](2024年05月28日/LLaMA-NAS_Efficient_Neural_Architecture_Search_for_Large_Language_Models.md)

- [Thai Winograd Schemas: A Benchmark for Thai Commonsense Reasoning](2024年05月28日/Thai_Winograd_Schemas_A_Benchmark_for_Thai_Commonsense_Reasoning.md)

    - [翻译: 泰国Winograd模式：泰国常识推理的新基准](2024年05月28日/Thai_Winograd_Schemas_A_Benchmark_for_Thai_Commonsense_Reasoning.md)

- [PromptWizard: Task-Aware Agent-driven Prompt Optimization Framework](2024年05月28日/PromptWizard_Task-Aware_Agent-driven_Prompt_Optimization_Framework.md)

    - [翻译: PromptWizard：基于任务感知的代理驱动提示优化框架](2024年05月28日/PromptWizard_Task-Aware_Agent-driven_Prompt_Optimization_Framework.md)

- [Is a 3D-Tokenized LLM the Key to Reliable Autonomous Driving?](2024年05月28日/Is_a_3D-Tokenized_LLM_the_Key_to_Reliable_Autonomous_Driving.md)

    - [翻译: 3D-Token化的大型语言模型是否是解锁可靠自动驾驶之门的钥匙？](2024年05月28日/Is_a_3D-Tokenized_LLM_the_Key_to_Reliable_Autonomous_Driving.md)

- [Faithful Logical Reasoning via Symbolic Chain-of-Thought](2024年05月28日/Faithful_Logical_Reasoning_via_Symbolic_Chain-of-Thought.md)

    - [翻译: 借助符号链式思维，精准演绎逻辑推理](2024年05月28日/Faithful_Logical_Reasoning_via_Symbolic_Chain-of-Thought.md)

- [Universal and Extensible Language-Vision Models for Organ Segmentation and Tumor Detection from Abdominal Computed Tomography](2024年05月28日/Universal_and_Extensible_Language-Vision_Models_for_Organ_Segmentation_and_Tumor_Detection_from_Abdominal_Computed_Tomography.md)

    - [翻译: 针对腹部CT扫描的器官分割与肿瘤检测，我们开发了一种通用且可扩展的语言-视觉模型。](2024年05月28日/Universal_and_Extensible_Language-Vision_Models_for_Organ_Segmentation_and_Tumor_Detection_from_Abdominal_Computed_Tomography.md)

- [Intelligent Clinical Documentation: Harnessing Generative AI for Patient-Centric Clinical Note Generation](2024年05月28日/Intelligent_Clinical_Documentation_Harnessing_Generative_AI_for_Patient-Centric_Clinical_Note_Generation.md)

    - [翻译: 智能临床文档：借助生成式AI，我们能够创造以患者为中心的临床笔记，提升医疗记录的智能化水平。](2024年05月28日/Intelligent_Clinical_Documentation_Harnessing_Generative_AI_for_Patient-Centric_Clinical_Note_Generation.md)

- [The Battle of LLMs: A Comparative Study in Conversational QA Tasks](2024年05月28日/The_Battle_of_LLMs_A_Comparative_Study_in_Conversational_QA_Tasks.md)

    - [翻译: 语言模型大比拼：对话问答任务的深度对比研究](2024年05月28日/The_Battle_of_LLMs_A_Comparative_Study_in_Conversational_QA_Tasks.md)

- [Frustratingly Easy Test-Time Adaptation of Vision-Language Models](2024年05月28日/Frustratingly_Easy_Test-Time_Adaptation_of_Vision-Language_Models.md)

    - [翻译: 视觉-语言模型的测试时间适应性，简单到令人沮丧](2024年05月28日/Frustratingly_Easy_Test-Time_Adaptation_of_Vision-Language_Models.md)

- [Gemini & Physical World: Large Language Models Can Estimate the Intensity of Earthquake Shaking from Multi-Modal Social Media Posts](2024年05月28日/Gemini_&_Physical_World_Large_Language_Models_Can_Estimate_the_Intensity_of_Earthquake_Shaking_from_Multi-Modal_Social_Media_Posts.md)

    - [翻译: 双子座与现实世界的交融：大型语言模型竟能从多模态社交媒体的碎片中，洞察地震震动的强度。](2024年05月28日/Gemini_&_Physical_World_Large_Language_Models_Can_Estimate_the_Intensity_of_Earthquake_Shaking_from_Multi-Modal_Social_Media_Posts.md)

- [CtrlA: Adaptive Retrieval-Augmented Generation via Probe-Guided Control](2024年05月28日/CtrlA_Adaptive_Retrieval-Augmented_Generation_via_Probe-Guided_Control.md)

    - [翻译: CtrlA：利用探针引导控制实现自适应检索增强生成](2024年05月28日/CtrlA_Adaptive_Retrieval-Augmented_Generation_via_Probe-Guided_Control.md)

- [Correctable Landmark Discovery via Large Models for Vision-Language Navigation](2024年05月28日/Correctable_Landmark_Discovery_via_Large_Models_for_Vision-Language_Navigation.md)

    - [翻译: 利用大型模型探索视觉-语言导航中的可纠正地标](2024年05月28日/Correctable_Landmark_Discovery_via_Large_Models_for_Vision-Language_Navigation.md)

- [Contextual Position Encoding: Learning to Count What's Important](2024年05月28日/Contextual_Position_Encoding_Learning_to_Count_What's_Important.md)

    - [翻译: 学习识别关键信息：上下文位置编码的探索](2024年05月28日/Contextual_Position_Encoding_Learning_to_Count_What's_Important.md)

- [Efficient Model-agnostic Alignment via Bayesian Persuasion](2024年05月28日/Efficient_Model-agnostic_Alignment_via_Bayesian_Persuasion.md)

    - [翻译: 利用贝叶斯说服策略，实现模型间的高效对齐，不受特定模型限制。](2024年05月28日/Efficient_Model-agnostic_Alignment_via_Bayesian_Persuasion.md)

- [Calibrating Reasoning in Language Models with Internal Consistency](2024年05月28日/Calibrating_Reasoning_in_Language_Models_with_Internal_Consistency.md)

    - [翻译: 利用内部一致性优化语言模型的推理能力](2024年05月28日/Calibrating_Reasoning_in_Language_Models_with_Internal_Consistency.md)

- [To FP8 and Back Again: Quantifying the Effects of Reducing Precision on LLM Training Stability](2024年05月28日/To_FP8_and_Back_Again_Quantifying_the_Effects_of_Reducing_Precision_on_LLM_Training_Stability.md)

    - [翻译: 从FP8到回归：探究精度降低对大型语言模型训练稳定性的量化影响](2024年05月28日/To_FP8_and_Back_Again_Quantifying_the_Effects_of_Reducing_Precision_on_LLM_Training_Stability.md)

- [Efficient Preference-based Reinforcement Learning via Aligned Experience Estimation](2024年05月28日/Efficient_Preference-based_Reinforcement_Learning_via_Aligned_Experience_Estimation.md)

    - [翻译: 基于偏好，通过对齐经验估计实现的高效强化学习](2024年05月28日/Efficient_Preference-based_Reinforcement_Learning_via_Aligned_Experience_Estimation.md)

- [Can GPT Redefine Medical Understanding? Evaluating GPT on Biomedical Machine Reading Comprehension](2024年05月28日/Can_GPT_Redefine_Medical_Understanding_Evaluating_GPT_on_Biomedical_Machine_Reading_Comprehension.md)

    - [翻译: GPT能否革新医学认知？探究其在生物医学机器阅读理解领域的评估表现](2024年05月28日/Can_GPT_Redefine_Medical_Understanding_Evaluating_GPT_on_Biomedical_Machine_Reading_Comprehension.md)

- [Mitigating Object Hallucination via Data Augmented Contrastive Tuning](2024年05月28日/Mitigating_Object_Hallucination_via_Data_Augmented_Contrastive_Tuning.md)

    - [翻译: 利用数据增强对比调优缓解对象幻觉现象](2024年05月28日/Mitigating_Object_Hallucination_via_Data_Augmented_Contrastive_Tuning.md)

- [Multi-modal Mood Reader: Pre-trained Model Empowers Cross-Subject Emotion Recognition](2024年05月28日/Multi-modal_Mood_Reader_Pre-trained_Model_Empowers_Cross-Subject_Emotion_Recognition.md)

    - [翻译: 多模态情绪解读器：预训练模型助力跨主题情感识别](2024年05月28日/Multi-modal_Mood_Reader_Pre-trained_Model_Empowers_Cross-Subject_Emotion_Recognition.md)

- [Improved Generation of Adversarial Examples Against Safety-aligned LLMs](2024年05月28日/Improved_Generation_of_Adversarial_Examples_Against_Safety-aligned_LLMs.md)

    - [翻译: 针对安全对齐的 LLMs，我们提升了对抗样本的生成技术。](2024年05月28日/Improved_Generation_of_Adversarial_Examples_Against_Safety-aligned_LLMs.md)

2024年05月27日

- [Large Language Models (LLMs): Deployment, Tokenomics and Sustainability](2024年05月27日/Large_Language_Models_(LLMs)_Deployment,_Tokenomics_and_Sustainability.md)

    - [翻译: 大型语言模型（LLMs）：探讨其部署、代币经济及可持续性议题](2024年05月27日/Large_Language_Models_(LLMs)_Deployment,_Tokenomics_and_Sustainability.md)

- [WirelessLLM: Empowering Large Language Models Towards Wireless Intelligence](2024年05月27日/WirelessLLM_Empowering_Large_Language_Models_Towards_Wireless_Intelligence.md)

    - [翻译: WirelessLLM：助力大型语言模型实现无线智能](2024年05月27日/WirelessLLM_Empowering_Large_Language_Models_Towards_Wireless_Intelligence.md)

- [Empowering Large Language Models to Set up a Knowledge Retrieval Indexer via Self-Learning](2024年05月27日/Empowering_Large_Language_Models_to_Set_up_a_Knowledge_Retrieval_Indexer_via_Self-Learning.md)

    - [翻译: 借助自我学习，大型语言模型得以自主构建知识检索的索引器，这一过程不仅提升了模型的自主性，也增强了其知识处理的能力。](2024年05月27日/Empowering_Large_Language_Models_to_Set_up_a_Knowledge_Retrieval_Indexer_via_Self-Learning.md)

- [A Cross-Dataset Study for Text-based 3D Human Motion Retrieval](2024年05月27日/A_Cross-Dataset_Study_for_Text-based_3D_Human_Motion_Retrieval.md)

    - [翻译: 跨数据集视角下的文本驱动3D人体运动检索研究](2024年05月27日/A_Cross-Dataset_Study_for_Text-based_3D_Human_Motion_Retrieval.md)

- [LARM: Large Auto-Regressive Model for Long-Horizon Embodied Intelligence](2024年05月27日/LARM_Large_Auto-Regressive_Model_for_Long-Horizon_Embodied_Intelligence.md)

    - [翻译: LARM：长时程具身智能的大型自回归模型](2024年05月27日/LARM_Large_Auto-Regressive_Model_for_Long-Horizon_Embodied_Intelligence.md)

- [Self-Corrected Multimodal Large Language Model for End-to-End Robot Manipulation](2024年05月27日/Self-Corrected_Multimodal_Large_Language_Model_for_End-to-End_Robot_Manipulation.md)

    - [翻译: 端到端机器人操作的自校正多模态大型语言模型](2024年05月27日/Self-Corrected_Multimodal_Large_Language_Model_for_End-to-End_Robot_Manipulation.md)

- [THREAD: Thinking Deeper with Recursive Spawning](2024年05月27日/THREAD_Thinking_Deeper_with_Recursive_Spawning.md)

    - [翻译: 探讨递归生成：深入思考的线索](2024年05月27日/THREAD_Thinking_Deeper_with_Recursive_Spawning.md)

- [TEII: Think, Explain, Interact and Iterate with Large Language Models to Solve Cross-lingual Emotion Detection](2024年05月27日/TEII_Think,_Explain,_Interact_and_Iterate_with_Large_Language_Models_to_Solve_Cross-lingual_Emotion_Detection.md)

    - [翻译: TEII：借助大型语言模型的思考、解释、交互与迭代，攻克跨语言情感检测难题](2024年05月27日/TEII_Think,_Explain,_Interact_and_Iterate_with_Large_Language_Models_to_Solve_Cross-lingual_Emotion_Detection.md)

- [Position: Foundation Agents as the Paradigm Shift for Decision Making](2024年05月27日/Position_Foundation_Agents_as_the_Paradigm_Shift_for_Decision_Making.md)

    - [翻译: 职位：基础代理——决策制定的新范式](2024年05月27日/Position_Foundation_Agents_as_the_Paradigm_Shift_for_Decision_Making.md)

- [A Large Language Model-based multi-agent manufacturing system for intelligent shopfloor](2024年05月27日/A_Large_Language_Model-based_multi-agent_manufacturing_system_for_intelligent_shopfloor.md)

    - [翻译: 智能车间中的大型语言模型多代理制造系统](2024年05月27日/A_Large_Language_Model-based_multi-agent_manufacturing_system_for_intelligent_shopfloor.md)

- [Knowing What Not to Do: Leverage Language Model Insights for Action Space Pruning in Multi-agent Reinforcement Learning](2024年05月27日/Knowing_What_Not_to_Do_Leverage_Language_Model_Insights_for_Action_Space_Pruning_in_Multi-agent_Reinforcement_Learning.md)

    - [翻译: 明智之举：借助语言模型洞察，精简多代理强化学习中的动作选择空间](2024年05月27日/Knowing_What_Not_to_Do_Leverage_Language_Model_Insights_for_Action_Space_Pruning_in_Multi-agent_Reinforcement_Learning.md)

- [Matryoshka Multimodal Models](2024年05月27日/Matryoshka_Multimodal_Models.md)

    - [翻译: 套娃式多模态模型](2024年05月27日/Matryoshka_Multimodal_Models.md)

- [Reason3D: Searching and Reasoning 3D Segmentation via Large Language Model](2024年05月27日/Reason3D_Searching_and_Reasoning_3D_Segmentation_via_Large_Language_Model.md)

    - [翻译: Reason3D：借助大型语言模型，探索3D分割的搜索与推理之道](2024年05月27日/Reason3D_Searching_and_Reasoning_3D_Segmentation_via_Large_Language_Model.md)

- [MultiOOD: Scaling Out-of-Distribution Detection for Multiple Modalities](2024年05月27日/MultiOOD_Scaling_Out-of-Distribution_Detection_for_Multiple_Modalities.md)

    - [翻译: MultiOOD：多模态分布外检测的扩展探索](2024年05月27日/MultiOOD_Scaling_Out-of-Distribution_Detection_for_Multiple_Modalities.md)

- [RLAIF-V: Aligning MLLMs through Open-Source AI Feedback for Super GPT-4V Trustworthiness](2024年05月27日/RLAIF-V_Aligning_MLLMs_through_Open-Source_AI_Feedback_for_Super_GPT-4V_Trustworthiness.md)

    - [翻译: RLAIF-V：利用开源AI反馈，确保多模态大型语言模型与Super GPT-4V的可信度保持一致](2024年05月27日/RLAIF-V_Aligning_MLLMs_through_Open-Source_AI_Feedback_for_Super_GPT-4V_Trustworthiness.md)

- [LLM-Optic: Unveiling the Capabilities of Large Language Models for Universal Visual Grounding](2024年05月27日/LLM-Optic_Unveiling_the_Capabilities_of_Large_Language_Models_for_Universal_Visual_Grounding.md)

    - [翻译: LLM-Optic：探索大型语言模型在通用视觉基础任务中的潜能](2024年05月27日/LLM-Optic_Unveiling_the_Capabilities_of_Large_Language_Models_for_Universal_Visual_Grounding.md)

- [MotionLLM: Multimodal Motion-Language Learning with Large Language Models](2024年05月27日/MotionLLM_Multimodal_Motion-Language_Learning_with_Large_Language_Models.md)

    - [翻译: MotionLLM：融合大型语言模型的多模态运动与语言学习](2024年05月27日/MotionLLM_Multimodal_Motion-Language_Learning_with_Large_Language_Models.md)

- [Multilingual Diversity Improves Vision-Language Representations](2024年05月27日/Multilingual_Diversity_Improves_Vision-Language_Representations.md)

    - [翻译: 多语言的丰富性增强了视觉与语言的表达能力](2024年05月27日/Multilingual_Diversity_Improves_Vision-Language_Representations.md)

- [NV-Embed: Improved Techniques for Training LLMs as Generalist Embedding Models](2024年05月27日/NV-Embed_Improved_Techniques_for_Training_LLMs_as_Generalist_Embedding_Models.md)

    - [翻译: NV-Embed：提升大型语言模型作为通用嵌入模型训练技术的革新方法](2024年05月27日/NV-Embed_Improved_Techniques_for_Training_LLMs_as_Generalist_Embedding_Models.md)

- [MindMerger: Efficient Boosting LLM Reasoning in non-English Languages](2024年05月27日/MindMerger_Efficient_Boosting_LLM_Reasoning_in_non-English_Languages.md)

    - [翻译: MindMerger：非英语语言中大型语言模型推理能力的高效增强](2024年05月27日/MindMerger_Efficient_Boosting_LLM_Reasoning_in_non-English_Languages.md)

- [ReMoDetect: Reward Models Recognize Aligned LLM's Generations](2024年05月27日/ReMoDetect_Reward_Models_Recognize_Aligned_LLM's_Generations.md)

    - [翻译: ReMoDetect：奖励模型辨识与大型语言模型生成对齐](2024年05月27日/ReMoDetect_Reward_Models_Recognize_Aligned_LLM's_Generations.md)

- [RTL-Repo: A Benchmark for Evaluating LLMs on Large-Scale RTL Design Projects](2024年05月27日/RTL-Repo_A_Benchmark_for_Evaluating_LLMs_on_Large-Scale_RTL_Design_Projects.md)

    - [翻译: RTL-Repo：大型语言模型在大型RTL设计项目上的性能评估基准](2024年05月27日/RTL-Repo_A_Benchmark_for_Evaluating_LLMs_on_Large-Scale_RTL_Design_Projects.md)

- [Federating Dynamic Models using Early-Exit Architectures for Automatic Speech Recognition on Heterogeneous Clients](2024年05月27日/Federating_Dynamic_Models_using_Early-Exit_Architectures_for_Automatic_Speech_Recognition_on_Heterogeneous_Clients.md)

    - [翻译: 利用早期退出架构，实现异构客户端上动态模型的自动语音识别联合优化](2024年05月27日/Federating_Dynamic_Models_using_Early-Exit_Architectures_for_Automatic_Speech_Recognition_on_Heterogeneous_Clients.md)

- [Navigating the Safety Landscape: Measuring Risks in Finetuning Large Language Models](2024年05月27日/Navigating_the_Safety_Landscape_Measuring_Risks_in_Finetuning_Large_Language_Models.md)

    - [翻译: 探索安全领域：评估微调大型语言模型中的风险](2024年05月27日/Navigating_the_Safety_Landscape_Measuring_Risks_in_Finetuning_Large_Language_Models.md)

- [Prompt Optimization with Human Feedback](2024年05月27日/Prompt_Optimization_with_Human_Feedback.md)

    - [翻译: 借助人类反馈优化提示策略](2024年05月27日/Prompt_Optimization_with_Human_Feedback.md)

- [Exploring and steering the moral compass of Large Language Models](2024年05月27日/Exploring_and_steering_the_moral_compass_of_Large_Language_Models.md)

    - [翻译: 探究并引导大型语言模型的道德方向](2024年05月27日/Exploring_and_steering_the_moral_compass_of_Large_Language_Models.md)

- [Cost-efficient Knowledge-based Question Answering with Large Language Models](2024年05月27日/Cost-efficient_Knowledge-based_Question_Answering_with_Large_Language_Models.md)

    - [翻译: 高效成本的大型语言模型知识问答](2024年05月27日/Cost-efficient_Knowledge-based_Question_Answering_with_Large_Language_Models.md)

- [On the Noise Robustness of In-Context Learning for Text Generation](2024年05月27日/On_the_Noise_Robustness_of_In-Context_Learning_for_Text_Generation.md)

    - [翻译: 探究文本生成中情境学习对噪声的抗干扰能力](2024年05月27日/On_the_Noise_Robustness_of_In-Context_Learning_for_Text_Generation.md)

- [$\textit{Trans-LoRA}$: towards data-free Transferable Parameter Efficient Finetuning](2024年05月27日/$\textit{Trans-LoRA}$_towards_data-free_Transferable_Parameter_Efficient_Finetuning.md)

    - [翻译: 《Trans-LoRA》：探索无需数据支持的高效参数转移微调方法](2024年05月27日/$\textit{Trans-LoRA}$_towards_data-free_Transferable_Parameter_Efficient_Finetuning.md)

- [Assessing LLMs Suitability for Knowledge Graph Completion](2024年05月27日/Assessing_LLMs_Suitability_for_Knowledge_Graph_Completion.md)

    - [翻译: 探究大型语言模型在知识图谱补全任务中的适用性](2024年05月27日/Assessing_LLMs_Suitability_for_Knowledge_Graph_Completion.md)

- [An Introduction to Vision-Language Modeling](2024年05月27日/An_Introduction_to_Vision-Language_Modeling.md)

    - [翻译: 视觉与语言建模入门](2024年05月27日/An_Introduction_to_Vision-Language_Modeling.md)

- [LLM-Assisted Static Analysis for Detecting Security Vulnerabilities](2024年05月27日/LLM-Assisted_Static_Analysis_for_Detecting_Security_Vulnerabilities.md)

    - [翻译: 利用LLM辅助静态分析，精准检测安全漏洞](2024年05月27日/LLM-Assisted_Static_Analysis_for_Detecting_Security_Vulnerabilities.md)

- [CLAQ: Pushing the Limits of Low-Bit Post-Training Quantization for LLMs](2024年05月27日/CLAQ_Pushing_the_Limits_of_Low-Bit_Post-Training_Quantization_for_LLMs.md)

    - [翻译: CLAQ：突破大型语言模型后训练量化低比特的极限](2024年05月27日/CLAQ_Pushing_the_Limits_of_Low-Bit_Post-Training_Quantization_for_LLMs.md)

- [Autoformalizing Euclidean Geometry](2024年05月27日/Autoformalizing_Euclidean_Geometry.md)

    - [翻译: 欧几里得几何的自动形式化](2024年05月27日/Autoformalizing_Euclidean_Geometry.md)

- [Empowering Character-level Text Infilling by Eliminating Sub-Tokens](2024年05月27日/Empowering_Character-level_Text_Infilling_by_Eliminating_Sub-Tokens.md)

    - [翻译: 消除子词，提升字符级文本填充的效能](2024年05月27日/Empowering_Character-level_Text_Infilling_by_Eliminating_Sub-Tokens.md)

- [Phase Transitions in the Output Distribution of Large Language Models](2024年05月27日/Phase_Transitions_in_the_Output_Distribution_of_Large_Language_Models.md)

    - [翻译: 大型语言模型输出分布的相变现象](2024年05月27日/Phase_Transitions_in_the_Output_Distribution_of_Large_Language_Models.md)

- [Tokenization Matters! Degrading Large Language Models through Challenging Their Tokenization](2024年05月27日/Tokenization_Matters!_Degrading_Large_Language_Models_through_Challenging_Their_Tokenization.md)

    - [翻译: 分词的重要性！通过挑战大型语言模型的分词机制来削弱其性能](2024年05月27日/Tokenization_Matters!_Degrading_Large_Language_Models_through_Challenging_Their_Tokenization.md)

- [Unifying Demonstration Selection and Compression for In-Context Learning](2024年05月27日/Unifying_Demonstration_Selection_and_Compression_for_In-Context_Learning.md)

    - [翻译: 整合演示选择与压缩，优化情境学习策略](2024年05月27日/Unifying_Demonstration_Selection_and_Compression_for_In-Context_Learning.md)

- [SelfCP: Compressing Long Prompt to 1/12 Using the Frozen Large Language Model Itself](2024年05月27日/SelfCP_Compressing_Long_Prompt_to_112_Using_the_Frozen_Large_Language_Model_Itself.md)

    - [翻译: SelfCP：借助冻结的大型语言模型，将冗长提示精简至原长的1/12](2024年05月27日/SelfCP_Compressing_Long_Prompt_to_112_Using_the_Frozen_Large_Language_Model_Itself.md)

- [Generation and human-expert evaluation of interesting research ideas using knowledge graphs and large language models](2024年05月27日/Generation_and_human-expert_evaluation_of_interesting_research_ideas_using_knowledge_graphs_and_large_language_models.md)

    - [翻译: 借助知识图谱与大型语言模型，我们探索并评估了新颖的研究想法，这一过程得到了人类专家的审慎评价。](2024年05月27日/Generation_and_human-expert_evaluation_of_interesting_research_ideas_using_knowledge_graphs_and_large_language_models.md)

- [BWArea Model: Learning World Model, Inverse Dynamics, and Policy for Controllable Language Generation](2024年05月27日/BWArea_Model_Learning_World_Model,_Inverse_Dynamics,_and_Policy_for_Controllable_Language_Generation.md)

    - [翻译: BWArea模型：探索世界模型、逆向动力学与策略，助力可控语言生成之艺术](2024年05月27日/BWArea_Model_Learning_World_Model,_Inverse_Dynamics,_and_Policy_for_Controllable_Language_Generation.md)

- [Exploring the LLM Journey from Cognition to Expression with Linear Representations](2024年05月27日/Exploring_the_LLM_Journey_from_Cognition_to_Expression_with_Linear_Representations.md)

    - [翻译: 通过线性表示，探索大型语言模型从认知到表达的演变之旅](2024年05月27日/Exploring_the_LLM_Journey_from_Cognition_to_Expression_with_Linear_Representations.md)

- [Do Vision-Language Transformers Exhibit Visual Commonsense? An Empirical Study of VCR](2024年05月27日/Do_Vision-Language_Transformers_Exhibit_Visual_Commonsense_An_Empirical_Study_of_VCR.md)

    - [翻译: 视觉-语言 Transformer 是否具备视觉常识？一项针对 VCR 的实证研究揭示了这一问题。](2024年05月27日/Do_Vision-Language_Transformers_Exhibit_Visual_Commonsense_An_Empirical_Study_of_VCR.md)

- [VoCoT: Unleashing Visually Grounded Multi-Step Reasoning in Large Multi-Modal Models](2024年05月27日/VoCoT_Unleashing_Visually_Grounded_Multi-Step_Reasoning_in_Large_Multi-Modal_Models.md)

    - [翻译: VoCoT：激发大型多模态模型中的视觉引导多步推理潜能](2024年05月27日/VoCoT_Unleashing_Visually_Grounded_Multi-Step_Reasoning_in_Large_Multi-Modal_Models.md)

- [The Uncanny Valley: Exploring Adversarial Robustness from a Flatness Perspective](2024年05月27日/The_Uncanny_Valley_Exploring_Adversarial_Robustness_from_a_Flatness_Perspective.md)

    - [翻译: 《诡异谷效应：从平坦度视角探究对抗性鲁棒性》](2024年05月27日/The_Uncanny_Valley_Exploring_Adversarial_Robustness_from_a_Flatness_Perspective.md)

- [Can Large Language Models Faithfully Express Their Intrinsic Uncertainty in Words?](2024年05月27日/Can_Large_Language_Models_Faithfully_Express_Their_Intrinsic_Uncertainty_in_Words.md)

    - [翻译: 大型语言模型是否能准确地以言语传达其内在的不确定性？](2024年05月27日/Can_Large_Language_Models_Faithfully_Express_Their_Intrinsic_Uncertainty_in_Words.md)

- [Hawk: Learning to Understand Open-World Video Anomalies](2024年05月27日/Hawk_Learning_to_Understand_Open-World_Video_Anomalies.md)

    - [翻译: Hawk：洞察开放世界视频中的异常现象](2024年05月27日/Hawk_Learning_to_Understand_Open-World_Video_Anomalies.md)

- [Match, Compare, or Select? An Investigation of Large Language Models for Entity Matching](2024年05月27日/Match,_Compare,_or_Select_An_Investigation_of_Large_Language_Models_for_Entity_Matching.md)

    - [翻译: 匹配、比较还是选择？探究大型语言模型在实体匹配领域的应用。](2024年05月27日/Match,_Compare,_or_Select_An_Investigation_of_Large_Language_Models_for_Entity_Matching.md)

- [TokenUnify: Scalable Autoregressive Visual Pre-training with Mixture Token Prediction](2024年05月27日/TokenUnify_Scalable_Autoregressive_Visual_Pre-training_with_Mixture_Token_Prediction.md)

    - [翻译: TokenUnify：一种利用混合令牌预测进行高效自回归视觉预训练的扩展方法](2024年05月27日/TokenUnify_Scalable_Autoregressive_Visual_Pre-training_with_Mixture_Token_Prediction.md)

- [Safe LoRA: the Silver Lining of Reducing Safety Risks when Fine-tuning Large Language Models](2024年05月27日/Safe_LoRA_the_Silver_Lining_of_Reducing_Safety_Risks_when_Fine-tuning_Large_Language_Models.md)

    - [翻译: 安全LoRA：微调大型语言模型时降低安全风险的希望之光](2024年05月27日/Safe_LoRA_the_Silver_Lining_of_Reducing_Safety_Risks_when_Fine-tuning_Large_Language_Models.md)

- [Perturbation-Restrained Sequential Model Editing](2024年05月27日/Perturbation-Restrained_Sequential_Model_Editing.md)

    - [翻译: 序列模型编辑中的扰动抑制](2024年05月27日/Perturbation-Restrained_Sequential_Model_Editing.md)

- [Video Enriched Retrieval Augmented Generation Using Aligned Video Captions](2024年05月27日/Video_Enriched_Retrieval_Augmented_Generation_Using_Aligned_Video_Captions.md)

    - [翻译: 利用对齐视频字幕，实现视频内容的丰富检索与增强生成](2024年05月27日/Video_Enriched_Retrieval_Augmented_Generation_Using_Aligned_Video_Captions.md)

- [Exploring Activation Patterns of Parameters in Language Models](2024年05月27日/Exploring_Activation_Patterns_of_Parameters_in_Language_Models.md)

    - [翻译: 揭示语言模型参数的激活奥秘](2024年05月27日/Exploring_Activation_Patterns_of_Parameters_in_Language_Models.md)

- [Instruct-ReID++: Towards Universal Purpose Instruction-Guided Person Re-identification](2024年05月27日/Instruct-ReID++_Towards_Universal_Purpose_Instruction-Guided_Person_Re-identification.md)

    - [翻译: Instruct-ReID++：探索通用指令引导下的人物再识别技术](2024年05月27日/Instruct-ReID++_Towards_Universal_Purpose_Instruction-Guided_Person_Re-identification.md)

- [Linguistic Collapse: Neural Collapse in (Large) Language Models](2024年05月27日/Linguistic_Collapse_Neural_Collapse_in_(Large)_Language_Models.md)

    - [翻译: 语言模型危机：探究大型语言模型中的神经崩溃现象](2024年05月27日/Linguistic_Collapse_Neural_Collapse_in_(Large)_Language_Models.md)

- [Augmenting Textual Generation via Topology Aware Retrieval](2024年05月27日/Augmenting_Textual_Generation_via_Topology_Aware_Retrieval.md)

    - [翻译: 利用拓扑感知检索优化文本生成](2024年05月27日/Augmenting_Textual_Generation_via_Topology_Aware_Retrieval.md)

- [RAGSys: Item-Cold-Start Recommender as RAG System](2024年05月27日/RAGSys_Item-Cold-Start_Recommender_as_RAG_System.md)

    - [翻译: RAGSys：将物品冷启动推荐系统化身为RAG系统](2024年05月27日/RAGSys_Item-Cold-Start_Recommender_as_RAG_System.md)

- [ORLM: Training Large Language Models for Optimization Modeling](2024年05月27日/ORLM_Training_Large_Language_Models_for_Optimization_Modeling.md)

    - [翻译: ORLM：大型语言模型的优化建模训练](2024年05月27日/ORLM_Training_Large_Language_Models_for_Optimization_Modeling.md)

- [BioDiscoveryAgent: An AI Agent for Designing Genetic Perturbation Experiments](2024年05月27日/BioDiscoveryAgent_An_AI_Agent_for_Designing_Genetic_Perturbation_Experiments.md)

    - [翻译: BioDiscoveryAgent：专为基因扰动实验设计的人工智能助手](2024年05月27日/BioDiscoveryAgent_An_AI_Agent_for_Designing_Genetic_Perturbation_Experiments.md)

- [Exploring Backdoor Attacks against Large Language Model-based Decision Making](2024年05月27日/Exploring_Backdoor_Attacks_against_Large_Language_Model-based_Decision_Making.md)

    - [翻译: 揭秘大型语言模型决策中的后门攻击之谜](2024年05月27日/Exploring_Backdoor_Attacks_against_Large_Language_Model-based_Decision_Making.md)

- [A Survey on Large Language Models from Concept to Implementation](2024年05月27日/A_Survey_on_Large_Language_Models_from_Concept_to_Implementation.md)

    - [翻译: 大型语言模型：从概念到实践的全面考察](2024年05月27日/A_Survey_on_Large_Language_Models_from_Concept_to_Implementation.md)

- [QUB-Cirdan at "Discharge Me!": Zero shot discharge letter generation by open-source LLM](2024年05月27日/QUB-Cirdan_at_Discharge_Me!_Zero_shot_discharge_letter_generation_by_open-source_LLM.md)

    - [翻译: QUB-Cirdan 参与的 "Discharge Me!" 项目，利用开源大型语言模型，成功实现了零-shot 出院信的自动生成。](2024年05月27日/QUB-Cirdan_at_Discharge_Me!_Zero_shot_discharge_letter_generation_by_open-source_LLM.md)

- [Aligning LLMs through Multi-perspective User Preference Ranking-based Feedback for Programming Question Answering](2024年05月27日/Aligning_LLMs_through_Multi-perspective_User_Preference_Ranking-based_Feedback_for_Programming_Question_Answering.md)

    - [翻译: 利用多视角用户偏好排名反馈，优化大型语言模型，提升编程问题解答的精准度。](2024年05月27日/Aligning_LLMs_through_Multi-perspective_User_Preference_Ranking-based_Feedback_for_Programming_Question_Answering.md)

- [EMERGE: Integrating RAG for Improved Multimodal EHR Predictive Modeling](2024年05月27日/EMERGE_Integrating_RAG_for_Improved_Multimodal_EHR_Predictive_Modeling.md)

    - [翻译: EMERGE：融合 RAG 技术，优化多模态电子健康记录的预测模型](2024年05月27日/EMERGE_Integrating_RAG_for_Improved_Multimodal_EHR_Predictive_Modeling.md)

2024年05月26日

- [Diffusion4D: Fast Spatial-temporal Consistent 4D Generation via Video Diffusion Models](2024年05月26日/Diffusion4D_Fast_Spatial-temporal_Consistent_4D_Generation_via_Video_Diffusion_Models.md)

    - [翻译: 时空一致，速成4D：Diffusion4D利用视频扩散模型，快速生成高质量的4D内容。](2024年05月26日/Diffusion4D_Fast_Spatial-temporal_Consistent_4D_Generation_via_Video_Diffusion_Models.md)

- [A Survey of Multimodal Large Language Model from A Data-centric Perspective](2024年05月26日/A_Survey_of_Multimodal_Large_Language_Model_from_A_Data-centric_Perspective.md)

    - [翻译: 多模态大型语言模型综述：数据视角的探索](2024年05月26日/A_Survey_of_Multimodal_Large_Language_Model_from_A_Data-centric_Perspective.md)

- [CapS-Adapter: Caption-based MultiModal Adapter in Zero-Shot Classification](2024年05月26日/CapS-Adapter_Caption-based_MultiModal_Adapter_in_Zero-Shot_Classification.md)

    - [翻译: CapS-Adapter：零-shot分类中的标题驱动多模态适配器](2024年05月26日/CapS-Adapter_Caption-based_MultiModal_Adapter_in_Zero-Shot_Classification.md)

- [Triple Preference Optimization: Achieving Better Alignment with Less Data in a Single Step Optimization](2024年05月26日/Triple_Preference_Optimization_Achieving_Better_Alignment_with_Less_Data_in_a_Single_Step_Optimization.md)

    - [翻译: 三重偏好优化：一步到位，以更少数据实现精准对齐](2024年05月26日/Triple_Preference_Optimization_Achieving_Better_Alignment_with_Less_Data_in_a_Single_Step_Optimization.md)

- [RLSF: Reinforcement Learning via Symbolic Feedback](2024年05月26日/RLSF_Reinforcement_Learning_via_Symbolic_Feedback.md)

    - [翻译: 符号反馈强化学习（RLSF）](2024年05月26日/RLSF_Reinforcement_Learning_via_Symbolic_Feedback.md)

- [Let Silence Speak: Enhancing Fake News Detection with Generated Comments from Large Language Models](2024年05月26日/Let_Silence_Speak_Enhancing_Fake_News_Detection_with_Generated_Comments_from_Large_Language_Models.md)

    - [翻译: 沉默之声：借助大型语言模型生成的评论，提升假新闻检测能力](2024年05月26日/Let_Silence_Speak_Enhancing_Fake_News_Detection_with_Generated_Comments_from_Large_Language_Models.md)

- [Attaining Human`s Desirable Outcomes in Human-AI Interaction via Structural Causal Games](2024年05月26日/Attaining_Human`s_Desirable_Outcomes_in_Human-AI_Interaction_via_Structural_Causal_Games.md)

    - [翻译: 借助结构因果游戏，优化人机交互，以达成人类期望的成果](2024年05月26日/Attaining_Human`s_Desirable_Outcomes_in_Human-AI_Interaction_via_Structural_Causal_Games.md)

- [Cost-Effective Online Multi-LLM Selection with Versatile Reward Models](2024年05月26日/Cost-Effective_Online_Multi-LLM_Selection_with_Versatile_Reward_Models.md)

    - [翻译: 高效经济的在线多大型语言模型选择策略，结合多功能奖励模型优化性能。](2024年05月26日/Cost-Effective_Online_Multi-LLM_Selection_with_Versatile_Reward_Models.md)

- [On Bits and Bandits: Quantifying the Regret-Information Trade-off](2024年05月26日/On_Bits_and_Bandits_Quantifying_the_Regret-Information_Trade-off.md)

    - [翻译: 比特与强盗之间：探索后悔与信息之间的微妙平衡](2024年05月26日/On_Bits_and_Bandits_Quantifying_the_Regret-Information_Trade-off.md)

- [Automatically Generating Numerous Context-Driven SFT Data for LLMs across Diverse Granularity](2024年05月26日/Automatically_Generating_Numerous_Context-Driven_SFT_Data_for_LLMs_across_Diverse_Granularity.md)

    - [翻译: 自动为大型语言模型（LLMs）生成多样粒度下的丰富上下文驱动SFT数据](2024年05月26日/Automatically_Generating_Numerous_Context-Driven_SFT_Data_for_LLMs_across_Diverse_Granularity.md)

- [A Preliminary Empirical Study on Prompt-based Unsupervised Keyphrase Extraction](2024年05月26日/A_Preliminary_Empirical_Study_on_Prompt-based_Unsupervised_Keyphrase_Extraction.md)

    - [翻译: 基于提示的无监督关键词提取：一项初步实证研究](2024年05月26日/A_Preliminary_Empirical_Study_on_Prompt-based_Unsupervised_Keyphrase_Extraction.md)

- [Automatic Jailbreaking of the Text-to-Image Generative AI Systems](2024年05月26日/Automatic_Jailbreaking_of_the_Text-to-Image_Generative_AI_Systems.md)

    - [翻译: AI系统自动解锁文本至图像生成潜能](2024年05月26日/Automatic_Jailbreaking_of_the_Text-to-Image_Generative_AI_Systems.md)

- [SED: Self-Evaluation Decoding Enhances Large Language Models for Better Generation](2024年05月26日/SED_Self-Evaluation_Decoding_Enhances_Large_Language_Models_for_Better_Generation.md)

    - [翻译: SED：自评估解码技术提升大型语言模型，助力更优质的生成效果](2024年05月26日/SED_Self-Evaluation_Decoding_Enhances_Large_Language_Models_for_Better_Generation.md)

- [Cocktail: A Comprehensive Information Retrieval Benchmark with LLM-Generated Documents Integration](2024年05月26日/Cocktail_A_Comprehensive_Information_Retrieval_Benchmark_with_LLM-Generated_Documents_Integration.md)

    - [翻译: 鸡尾酒：集成 LLM 生成文档的综合信息检索基准](2024年05月26日/Cocktail_A_Comprehensive_Information_Retrieval_Benchmark_with_LLM-Generated_Documents_Integration.md)

- [Chain of Tools: Large Language Model is an Automatic Multi-tool Learner](2024年05月26日/Chain_of_Tools_Large_Language_Model_is_an_Automatic_Multi-tool_Learner.md)

    - [翻译: 大型语言模型：自动化的多工具学习专家](2024年05月26日/Chain_of_Tools_Large_Language_Model_is_an_Automatic_Multi-tool_Learner.md)

- [LoQT: Low Rank Adapters for Quantized Training](2024年05月26日/LoQT_Low_Rank_Adapters_for_Quantized_Training.md)

    - [翻译: LoQT：量化训练中的低秩适配器解释：在](2024年05月26日/LoQT_Low_Rank_Adapters_for_Quantized_Training.md)

- [Meta-Task Planning for Language Agents](2024年05月26日/Meta-Task_Planning_for_Language_Agents.md)

    - [翻译: 语言代理的元任务规划策略](2024年05月26日/Meta-Task_Planning_for_Language_Agents.md)

- [DarijaBanking: A New Resource for Overcoming Language Barriers in Banking Intent Detection for Moroccan Arabic Speakers](2024年05月26日/DarijaBanking_A_New_Resource_for_Overcoming_Language_Barriers_in_Banking_Intent_Detection_for_Moroccan_Arabic_Speakers.md)

    - [翻译: DarijaBanking：助力摩洛哥阿拉伯语用户跨越银行意图检测的语言鸿沟的新工具](2024年05月26日/DarijaBanking_A_New_Resource_for_Overcoming_Language_Barriers_in_Banking_Intent_Detection_for_Moroccan_Arabic_Speakers.md)

- [M$^3$CoT: A Novel Benchmark for Multi-Domain Multi-step Multi-modal Chain-of-Thought](2024年05月26日/M$^3$CoT_A_Novel_Benchmark_for_Multi-Domain_Multi-step_Multi-modal_Chain-of-Thought.md)

    - [翻译: M$^3$CoT：探索多领域、多步骤、多模态思维链的新基准](2024年05月26日/M$^3$CoT_A_Novel_Benchmark_for_Multi-Domain_Multi-step_Multi-modal_Chain-of-Thought.md)

- [On the Algorithmic Bias of Aligning Large Language Models with RLHF: Preference Collapse and Matching Regularization](2024年05月26日/On_the_Algorithmic_Bias_of_Aligning_Large_Language_Models_with_RLHF_Preference_Collapse_and_Matching_Regularization.md)

    - [翻译: 大型语言模型与RLHF对齐中的算法偏差：偏好崩溃与匹配正则化探讨](2024年05月26日/On_the_Algorithmic_Bias_of_Aligning_Large_Language_Models_with_RLHF_Preference_Collapse_and_Matching_Regularization.md)

- [Synthesizing Programmatic Reinforcement Learning Policies with Large Language Model Guided Search](2024年05月26日/Synthesizing_Programmatic_Reinforcement_Learning_Policies_with_Large_Language_Model_Guided_Search.md)

    - [翻译: 借助大型语言模型引导的搜索，合成程序化强化学习策略](2024年05月26日/Synthesizing_Programmatic_Reinforcement_Learning_Policies_with_Large_Language_Model_Guided_Search.md)

- [CacheBlend: Fast Large Language Model Serving with Cached Knowledge Fusion](2024年05月26日/CacheBlend_Fast_Large_Language_Model_Serving_with_Cached_Knowledge_Fusion.md)

    - [翻译: CacheBlend：融合缓存知识，加速大型语言模型服务](2024年05月26日/CacheBlend_Fast_Large_Language_Model_Serving_with_Cached_Knowledge_Fusion.md)

- [Provably Mitigating Overoptimization in RLHF: Your SFT Loss is Implicitly an Adversarial Regularizer](2024年05月26日/Provably_Mitigating_Overoptimization_in_RLHF_Your_SFT_Loss_is_Implicitly_an_Adversarial_Regularizer.md)

    - [翻译: 在RLHF中，通过证明性方法减轻过度优化：SFT损失实际上起到了一种隐式对抗性正则化的作用。](2024年05月26日/Provably_Mitigating_Overoptimization_in_RLHF_Your_SFT_Loss_is_Implicitly_an_Adversarial_Regularizer.md)

- [The Importance of Directional Feedback for LLM-based Optimizers](2024年05月26日/The_Importance_of_Directional_Feedback_for_LLM-based_Optimizers.md)

    - [翻译: 在基于LLM的优化器中，方向性反馈的重要性不容忽视。](2024年05月26日/The_Importance_of_Directional_Feedback_for_LLM-based_Optimizers.md)

- [CPsyCoun: A Report-based Multi-turn Dialogue Reconstruction and Evaluation Framework for Chinese Psychological Counseling](2024年05月26日/CPsyCoun_A_Report-based_Multi-turn_Dialogue_Reconstruction_and_Evaluation_Framework_for_Chinese_Psychological_Counseling.md)

    - [翻译: CPsyCoun：中文心理咨询领域中，一种基于报告的多轮对话重建与评估框架，旨在提升咨询对话的质量与效果。](2024年05月26日/CPsyCoun_A_Report-based_Multi-turn_Dialogue_Reconstruction_and_Evaluation_Framework_for_Chinese_Psychological_Counseling.md)

- [M-RAG: Reinforcing Large Language Model Performance through Retrieval-Augmented Generation with Multiple Partitions](2024年05月26日/M-RAG_Reinforcing_Large_Language_Model_Performance_through_Retrieval-Augmented_Generation_with_Multiple_Partitions.md)

    - [翻译: M-RAG：借助多分区检索增强技术，提升大型语言模型的生成性能](2024年05月26日/M-RAG_Reinforcing_Large_Language_Model_Performance_through_Retrieval-Augmented_Generation_with_Multiple_Partitions.md)

- [Disentangling and Integrating Relational and Sensory Information in Transformer Architectures](2024年05月26日/Disentangling_and_Integrating_Relational_and_Sensory_Information_in_Transformer_Architectures.md)

    - [翻译: 解构与融合：Transformer架构中的关系与感官信息整合](2024年05月26日/Disentangling_and_Integrating_Relational_and_Sensory_Information_in_Transformer_Architectures.md)

- [GRAG: Graph Retrieval-Augmented Generation](2024年05月26日/GRAG_Graph_Retrieval-Augmented_Generation.md)

    - [翻译: GRAG：图检索赋能生成](2024年05月26日/GRAG_Graph_Retrieval-Augmented_Generation.md)

- [Reframing the Relationship in Out-of-Distribution Detection](2024年05月26日/Reframing_the_Relationship_in_Out-of-Distribution_Detection.md)

    - [翻译: 重塑分布外检测中的关系纽带](2024年05月26日/Reframing_the_Relationship_in_Out-of-Distribution_Detection.md)

- [TIE: Revolutionizing Text-based Image Editing for Complex-Prompt Following and High-Fidelity Editing](2024年05月26日/TIE_Revolutionizing_Text-based_Image_Editing_for_Complex-Prompt_Following_and_High-Fidelity_Editing.md)

    - [翻译: TIE：引领文本驱动图像编辑革命，精准响应复杂指令，实现高保真视觉创作](2024年05月26日/TIE_Revolutionizing_Text-based_Image_Editing_for_Complex-Prompt_Following_and_High-Fidelity_Editing.md)

- [NoteLLM-2: Multimodal Large Representation Models for Recommendation](2024年05月26日/NoteLLM-2_Multimodal_Large_Representation_Models_for_Recommendation.md)

    - [翻译: NoteLLM-2：融合多模态的大型推荐模型](2024年05月26日/NoteLLM-2_Multimodal_Large_Representation_Models_for_Recommendation.md)

- [Entity Alignment with Noisy Annotations from Large Language Models](2024年05月26日/Entity_Alignment_with_Noisy_Annotations_from_Large_Language_Models.md)

    - [翻译: 利用大型语言模型中的噪声标注进行实体对齐](2024年05月26日/Entity_Alignment_with_Noisy_Annotations_from_Large_Language_Models.md)

- [ECG Semantic Integrator (ESI): A Foundation ECG Model Pretrained with LLM-Enhanced Cardiological Text](2024年05月26日/ECG_Semantic_Integrator_(ESI)_A_Foundation_ECG_Model_Pretrained_with_LLM-Enhanced_Cardiological_Text.md)

    - [翻译: ECG 语义整合器 (ESI)：一款基于 LLM 增强的心脏病学文本预训练的 ECG 基础模型，旨在深度整合 ECG 数据与医学知识。](2024年05月26日/ECG_Semantic_Integrator_(ESI)_A_Foundation_ECG_Model_Pretrained_with_LLM-Enhanced_Cardiological_Text.md)

- [Cross-Modality Jailbreak and Mismatched Attacks on Medical Multimodal Large Language Models](2024年05月26日/Cross-Modality_Jailbreak_and_Mismatched_Attacks_on_Medical_Multimodal_Large_Language_Models.md)

    - [翻译: 医疗多模态大型语言模型面临跨模态越狱与错配攻击挑战](2024年05月26日/Cross-Modality_Jailbreak_and_Mismatched_Attacks_on_Medical_Multimodal_Large_Language_Models.md)

2024年05月25日

- [Augmented Risk Prediction for the Onset of Alzheimer's Disease from Electronic Health Records with Large Language Models](2024年05月25日/Augmented_Risk_Prediction_for_the_Onset_of_Alzheimer's_Disease_from_Electronic_Health_Records_with_Large_Language_Models.md)

    - [翻译: 利用大型语言模型提升电子健康记录中阿尔茨海默病发病风险的预测能力](2024年05月25日/Augmented_Risk_Prediction_for_the_Onset_of_Alzheimer's_Disease_from_Electronic_Health_Records_with_Large_Language_Models.md)

- [SpinQuant -- LLM quantization with learned rotations](2024年05月25日/SpinQuant_--_LLM_quantization_with_learned_rotations.md)

    - [翻译: SpinQuant - 利用学习旋转技术优化大型语言模型的量化过程](2024年05月25日/SpinQuant_--_LLM_quantization_with_learned_rotations.md)

- [Intruding with Words: Towards Understanding Graph Injection Attacks at the Text Level](2024年05月25日/Intruding_with_Words_Towards_Understanding_Graph_Injection_Attacks_at_the_Text_Level.md)

    - [翻译: 文字侵袭：探索文本层面的图注入攻击理解之道](2024年05月25日/Intruding_with_Words_Towards_Understanding_Graph_Injection_Attacks_at_the_Text_Level.md)

- [Assessing Empathy in Large Language Models with Real-World Physician-Patient Interactions](2024年05月25日/Assessing_Empathy_in_Large_Language_Models_with_Real-World_Physician-Patient_Interactions.md)

    - [翻译: 借助真实医生与患者互动，探究大型语言模型中的同理心表现](2024年05月25日/Assessing_Empathy_in_Large_Language_Models_with_Real-World_Physician-Patient_Interactions.md)

- [Multi-Reference Preference Optimization for Large Language Models](2024年05月25日/Multi-Reference_Preference_Optimization_for_Large_Language_Models.md)

    - [翻译: 大型语言模型的多参考偏好优化](2024年05月25日/Multi-Reference_Preference_Optimization_for_Large_Language_Models.md)

- [STRIDE: A Tool-Assisted LLM Agent Framework for Strategic and Interactive Decision-Making](2024年05月25日/STRIDE_A_Tool-Assisted_LLM_Agent_Framework_for_Strategic_and_Interactive_Decision-Making.md)

    - [翻译: STRIDE：助力战略交互决策的LLM代理工具框架](2024年05月25日/STRIDE_A_Tool-Assisted_LLM_Agent_Framework_for_Strategic_and_Interactive_Decision-Making.md)

- [LLMs for User Interest Exploration: A Hybrid Approach](2024年05月25日/LLMs_for_User_Interest_Exploration_A_Hybrid_Approach.md)

    - [翻译: 探索用户兴趣：大型语言模型的混合策略](2024年05月25日/LLMs_for_User_Interest_Exploration_A_Hybrid_Approach.md)

- [Large Language Models Enable Automated Formative Feedback in Human-Robot Interaction Tasks](2024年05月25日/Large_Language_Models_Enable_Automated_Formative_Feedback_in_Human-Robot_Interaction_Tasks.md)

    - [翻译: 大型语言模型为人机交互任务中的自动化形成性反馈开启了新篇章。](2024年05月25日/Large_Language_Models_Enable_Automated_Formative_Feedback_in_Human-Robot_Interaction_Tasks.md)

- [Learning to Reason via Program Generation, Emulation, and Search](2024年05月25日/Learning_to_Reason_via_Program_Generation,_Emulation,_and_Search.md)

    - [翻译: 学习推理：程序生成、模拟与搜索的结合](2024年05月25日/Learning_to_Reason_via_Program_Generation,_Emulation,_and_Search.md)

- [Comparative Analysis of Open-Source Language Models in Summarizing Medical Text Data](2024年05月25日/Comparative_Analysis_of_Open-Source_Language_Models_in_Summarizing_Medical_Text_Data.md)

    - [翻译: 开源语言模型在医疗文本摘要领域的比较研究](2024年05月25日/Comparative_Analysis_of_Open-Source_Language_Models_in_Summarizing_Medical_Text_Data.md)

- [LoGAH: Predicting 774-Million-Parameter Transformers using Graph HyperNetworks with 1/100 Parameters](2024年05月25日/LoGAH_Predicting_774-Million-Parameter_Transformers_using_Graph_HyperNetworks_with_1100_Parameters.md)

    - [翻译: LoGAH：以百分之一的参数量，图超网络精准预测7.74亿参数的Transformer](2024年05月25日/LoGAH_Predicting_774-Million-Parameter_Transformers_using_Graph_HyperNetworks_with_1100_Parameters.md)

- [Generating clickbait spoilers with an ensemble of large language models](2024年05月25日/Generating_clickbait_spoilers_with_an_ensemble_of_large_language_models.md)

    - [翻译: 大型语言模型集合助力揭秘点击诱饵背后的秘密](2024年05月25日/Generating_clickbait_spoilers_with_an_ensemble_of_large_language_models.md)

- [Confidence Under the Hood: An Investigation into the Confidence-Probability Alignment in Large Language Models](2024年05月25日/Confidence_Under_the_Hood_An_Investigation_into_the_Confidence-Probability_Alignment_in_Large_Language_Models.md)

    - [翻译: 《探秘信心之源：大型语言模型中信心与概率匹配度的深度剖析》](2024年05月25日/Confidence_Under_the_Hood_An_Investigation_into_the_Confidence-Probability_Alignment_in_Large_Language_Models.md)

- [ConStat: Performance-Based Contamination Detection in Large Language Models](2024年05月25日/ConStat_Performance-Based_Contamination_Detection_in_Large_Language_Models.md)

    - [翻译: ConStat：大型语言模型中的性能驱动污染检测](2024年05月25日/ConStat_Performance-Based_Contamination_Detection_in_Large_Language_Models.md)

- [Picturing Ambiguity: A Visual Twist on the Winograd Schema Challenge](2024年05月25日/Picturing_Ambiguity_A_Visual_Twist_on_the_Winograd_Schema_Challenge.md)

    - [翻译: 模糊之图：Winograd Schema Challenge 的视觉新解](2024年05月25日/Picturing_Ambiguity_A_Visual_Twist_on_the_Winograd_Schema_Challenge.md)

- [Mechanism Design for LLM Fine-tuning with Multiple Reward Models](2024年05月25日/Mechanism_Design_for_LLM_Fine-tuning_with_Multiple_Reward_Models.md)

    - [翻译: 利用多奖励模型优化大型语言模型微调机制设计](2024年05月25日/Mechanism_Design_for_LLM_Fine-tuning_with_Multiple_Reward_Models.md)

- [$M^3$GPT: An Advanced Multimodal, Multitask Framework for Motion Comprehension and Generation](2024年05月25日/$M^3$GPT_An_Advanced_Multimodal,_Multitask_Framework_for_Motion_Comprehension_and_Generation.md)

    - [翻译: $M^3$GPT：引领前沿的运动理解与生成多模态多任务框架](2024年05月25日/$M^3$GPT_An_Advanced_Multimodal,_Multitask_Framework_for_Motion_Comprehension_and_Generation.md)

- [MindStar: Enhancing Math Reasoning in Pre-trained LLMs at Inference Time](2024年05月25日/MindStar_Enhancing_Math_Reasoning_in_Pre-trained_LLMs_at_Inference_Time.md)

    - [翻译: MindStar：提升预训练LLMs在推理阶段的数学推理能力](2024年05月25日/MindStar_Enhancing_Math_Reasoning_in_Pre-trained_LLMs_at_Inference_Time.md)

- [AutoManual: Generating Instruction Manuals by LLM Agents via Interactive Environmental Learning](2024年05月25日/AutoManual_Generating_Instruction_Manuals_by_LLM_Agents_via_Interactive_Environmental_Learning.md)

    - [翻译: AutoManual：借助大型语言模型代理的交互式环境学习，智能生成操作手册](2024年05月25日/AutoManual_Generating_Instruction_Manuals_by_LLM_Agents_via_Interactive_Environmental_Learning.md)

- [FastQuery: Communication-efficient Embedding Table Query for Private LLM Inference](2024年05月25日/FastQuery_Communication-efficient_Embedding_Table_Query_for_Private_LLM_Inference.md)

    - [翻译: FastQuery：提升私有LLM推理效率的通信优化嵌入表查询技术](2024年05月25日/FastQuery_Communication-efficient_Embedding_Table_Query_for_Private_LLM_Inference.md)

- [A statistical framework for weak-to-strong generalization](2024年05月25日/A_statistical_framework_for_weak-to-strong_generalization.md)

    - [翻译: 构建从弱到强泛化的统计框架](2024年05月25日/A_statistical_framework_for_weak-to-strong_generalization.md)

- [No Two Devils Alike: Unveiling Distinct Mechanisms of Fine-tuning Attacks](2024年05月25日/No_Two_Devils_Alike_Unveiling_Distinct_Mechanisms_of_Fine-tuning_Attacks.md)

    - [翻译: 恶魔各异：揭秘微调攻击的独特机制](2024年05月25日/No_Two_Devils_Alike_Unveiling_Distinct_Mechanisms_of_Fine-tuning_Attacks.md)

- [GeneAgent: Self-verification Language Agent for Gene Set Knowledge Discovery using Domain Databases](2024年05月25日/GeneAgent_Self-verification_Language_Agent_for_Gene_Set_Knowledge_Discovery_using_Domain_Databases.md)

    - [翻译: GeneAgent：利用专业数据库，自主验证基因集知识发现的语言智能助手](2024年05月25日/GeneAgent_Self-verification_Language_Agent_for_Gene_Set_Knowledge_Discovery_using_Domain_Databases.md)

- [Evolutionary Large Language Model for Automated Feature Transformation](2024年05月25日/Evolutionary_Large_Language_Model_for_Automated_Feature_Transformation.md)

    - [翻译: 进化型大型语言模型：自动化特征转换的新篇章](2024年05月25日/Evolutionary_Large_Language_Model_for_Automated_Feature_Transformation.md)

- [Accelerating Inference of Retrieval-Augmented Generation via Sparse Context Selection](2024年05月25日/Accelerating_Inference_of_Retrieval-Augmented_Generation_via_Sparse_Context_Selection.md)

    - [翻译: 利用稀疏上下文选择技术，加速检索增强生成模型的推理过程](2024年05月25日/Accelerating_Inference_of_Retrieval-Augmented_Generation_via_Sparse_Context_Selection.md)

- [SynthAI: A Multi Agent Generative AI Framework for Automated Modular HLS Design Generation](2024年05月25日/SynthAI_A_Multi_Agent_Generative_AI_Framework_for_Automated_Modular_HLS_Design_Generation.md)

    - [翻译: SynthAI：一款专为自动化模块化高层次综合设计而生的多代理生成式AI框架，旨在通过智能代理协同工作，推动设计流程的自动化与优化。](2024年05月25日/SynthAI_A_Multi_Agent_Generative_AI_Framework_for_Automated_Modular_HLS_Design_Generation.md)

- [C3LLM: Conditional Multimodal Content Generation Using Large Language Models](2024年05月25日/C3LLM_Conditional_Multimodal_Content_Generation_Using_Large_Language_Models.md)

    - [翻译: C3LLM：大型语言模型下的条件多模态内容创作](2024年05月25日/C3LLM_Conditional_Multimodal_Content_Generation_Using_Large_Language_Models.md)

- [Visual-RolePlay: Universal Jailbreak Attack on MultiModal Large Language Models via Role-playing Image Characte](2024年05月25日/Visual-RolePlay_Universal_Jailbreak_Attack_on_MultiModal_Large_Language_Models_via_Role-playing_Image_Characte.md)

    - [翻译: 视觉角色扮演：利用角色扮演图像角色对多模态大型语言模型实施通用越狱攻击](2024年05月25日/Visual-RolePlay_Universal_Jailbreak_Attack_on_MultiModal_Large_Language_Models_via_Role-playing_Image_Characte.md)

- [Retrieval-Augmented Conversational Recommendation with Prompt-based Semi-Structured Natural Language State Tracking](2024年05月25日/Retrieval-Augmented_Conversational_Recommendation_with_Prompt-based_Semi-Structured_Natural_Language_State_Tracking.md)

    - [翻译: 基于提示的半结构化自然语言状态跟踪技术，助力检索增强型对话推荐系统](2024年05月25日/Retrieval-Augmented_Conversational_Recommendation_with_Prompt-based_Semi-Structured_Natural_Language_State_Tracking.md)

2024年05月24日

- [Chain-of-Thought Prompting for Demographic Inference with Large Multimodal Models](2024年05月24日/Chain-of-Thought_Prompting_for_Demographic_Inference_with_Large_Multimodal_Models.md)

    - [翻译: 借助思维链提示，大型多模态模型在人口统计推断上展现新潜力](2024年05月24日/Chain-of-Thought_Prompting_for_Demographic_Inference_with_Large_Multimodal_Models.md)

- [Prompt-Aware Adapter: Towards Learning Adaptive Visual Tokens for Multimodal Large Language Models](2024年05月24日/Prompt-Aware_Adapter_Towards_Learning_Adaptive_Visual_Tokens_for_Multimodal_Large_Language_Models.md)

    - [翻译: 提示感知适配器：探索为多模态大型语言模型学习适应性视觉标记的新途径](2024年05月24日/Prompt-Aware_Adapter_Towards_Learning_Adaptive_Visual_Tokens_for_Multimodal_Large_Language_Models.md)

- [What Do You See? Enhancing Zero-Shot Image Classification with Multimodal Large Language Models](2024年05月24日/What_Do_You_See_Enhancing_Zero-Shot_Image_Classification_with_Multimodal_Large_Language_Models.md)

    - [翻译: 你所见为何？借助多模态大型语言模型，提升零-shot图像分类能力](2024年05月24日/What_Do_You_See_Enhancing_Zero-Shot_Image_Classification_with_Multimodal_Large_Language_Models.md)

- [M4U: Evaluating Multilingual Understanding and Reasoning for Large Multimodal Models](2024年05月24日/M4U_Evaluating_Multilingual_Understanding_and_Reasoning_for_Large_Multimodal_Models.md)

    - [翻译: M4U：探究大型多模态模型在多语言理解和推理上的能力评估](2024年05月24日/M4U_Evaluating_Multilingual_Understanding_and_Reasoning_for_Large_Multimodal_Models.md)

- [Meteor: Mamba-based Traversal of Rationale for Large Language and Vision Models](2024年05月24日/Meteor_Mamba-based_Traversal_of_Rationale_for_Large_Language_and_Vision_Models.md)

    - [翻译: Meteor：探索大规模语言与视觉模型中基于Mamba的推理路径](2024年05月24日/Meteor_Mamba-based_Traversal_of_Rationale_for_Large_Language_and_Vision_Models.md)

- [The Impact of Geometric Complexity on Neural Collapse in Transfer Learning](2024年05月24日/The_Impact_of_Geometric_Complexity_on_Neural_Collapse_in_Transfer_Learning.md)

    - [翻译: 迁移学习中几何复杂性对神经崩溃的影响探究](2024年05月24日/The_Impact_of_Geometric_Complexity_on_Neural_Collapse_in_Transfer_Learning.md)

- [VDGD: Mitigating LVLM Hallucinations in Cognitive Prompts by Bridging the Visual Perception Gap](2024年05月24日/VDGD_Mitigating_LVLM_Hallucinations_in_Cognitive_Prompts_by_Bridging_the_Visual_Perception_Gap.md)

    - [翻译: VDGD：弥合视觉感知差距，减轻大型视觉语言模型中的认知提示幻觉](2024年05月24日/VDGD_Mitigating_LVLM_Hallucinations_in_Cognitive_Prompts_by_Bridging_the_Visual_Perception_Gap.md)

- [Class Machine Unlearning for Complex Data via Concepts Inference and Data Poisoning](2024年05月24日/Class_Machine_Unlearning_for_Complex_Data_via_Concepts_Inference_and_Data_Poisoning.md)

    - [翻译: 利用概念推理与数据污染技术实现复杂数据中的类别机器遗忘](2024年05月24日/Class_Machine_Unlearning_for_Complex_Data_via_Concepts_Inference_and_Data_Poisoning.md)

- [Large Language Models as Covert Channels... a Systematic Analysis](2024年05月24日/Large_Language_Models_as_Covert_Channels..._a_Systematic_Analysis.md)

    - [翻译: 大型语言模型：隐蔽通道的系统性分析](2024年05月24日/Large_Language_Models_as_Covert_Channels..._a_Systematic_Analysis.md)

- [LLM-based Robot Task Planning with Exceptional Handling for General Purpose Service Robots](2024年05月24日/LLM-based_Robot_Task_Planning_with_Exceptional_Handling_for_General_Purpose_Service_Robots.md)

    - [翻译: 大型语言模型驱动的通用服务机器人任务规划与高效异常处理](2024年05月24日/LLM-based_Robot_Task_Planning_with_Exceptional_Handling_for_General_Purpose_Service_Robots.md)

- [GECKO: Generative Language Model for English, Code and Korean](2024年05月24日/GECKO_Generative_Language_Model_for_English,_Code_and_Korean.md)

    - [翻译: GECKO：专为英语、代码及韩文打造的生成式语言模型](2024年05月24日/GECKO_Generative_Language_Model_for_English,_Code_and_Korean.md)

- [GPTZoo: A Large-scale Dataset of GPTs for the Research Community](2024年05月24日/GPTZoo_A_Large-scale_Dataset_of_GPTs_for_the_Research_Community.md)

    - [翻译: GPTZoo：研究社区的大型GPT数据集宝库](2024年05月24日/GPTZoo_A_Large-scale_Dataset_of_GPTs_for_the_Research_Community.md)

- [A Comparative Analysis of Distributed Training Strategies for GPT-2](2024年05月24日/A_Comparative_Analysis_of_Distributed_Training_Strategies_for_GPT-2.md)

    - [翻译: GPT-2分布式训练策略比较研究](2024年05月24日/A_Comparative_Analysis_of_Distributed_Training_Strategies_for_GPT-2.md)

- [Inverse-RLignment: Inverse Reinforcement Learning from Demonstrations for LLM Alignment](2024年05月24日/Inverse-RLignment_Inverse_Reinforcement_Learning_from_Demonstrations_for_LLM_Alignment.md)

    - [翻译: 逆向对齐：借助演示数据，通过逆向强化学习实现大型语言模型的精准对齐](2024年05月24日/Inverse-RLignment_Inverse_Reinforcement_Learning_from_Demonstrations_for_LLM_Alignment.md)

- [Harnessing Large Language Models for Software Vulnerability Detection: A Comprehensive Benchmarking Study](2024年05月24日/Harnessing_Large_Language_Models_for_Software_Vulnerability_Detection_A_Comprehensive_Benchmarking_Study.md)

    - [翻译: 大型语言模型在软件漏洞检测中的应用：一次深入全面的基准研究](2024年05月24日/Harnessing_Large_Language_Models_for_Software_Vulnerability_Detection_A_Comprehensive_Benchmarking_Study.md)

- [Text Generation: A Systematic Literature Review of Tasks, Evaluation, and Challenges](2024年05月24日/Text_Generation_A_Systematic_Literature_Review_of_Tasks,_Evaluation,_and_Challenges.md)

    - [翻译: 文本生成综述：系统探讨任务、评估及面临的挑战](2024年05月24日/Text_Generation_A_Systematic_Literature_Review_of_Tasks,_Evaluation,_and_Challenges.md)

- [Efficient Adversarial Training in LLMs with Continuous Attacks](2024年05月24日/Efficient_Adversarial_Training_in_LLMs_with_Continuous_Attacks.md)

    - [翻译: 利用连续攻击优化大型语言模型（LLMs）的对抗训练效率](2024年05月24日/Efficient_Adversarial_Training_in_LLMs_with_Continuous_Attacks.md)

- [Composed Image Retrieval for Remote Sensing](2024年05月24日/Composed_Image_Retrieval_for_Remote_Sensing.md)

    - [翻译: 遥感图像的组合检索技术](2024年05月24日/Composed_Image_Retrieval_for_Remote_Sensing.md)

- [DAGER: Exact Gradient Inversion for Large Language Models](2024年05月24日/DAGER_Exact_Gradient_Inversion_for_Large_Language_Models.md)

    - [翻译: DAGER：大型语言模型的精准梯度反演](2024年05月24日/DAGER_Exact_Gradient_Inversion_for_Large_Language_Models.md)

- [Synergizing In-context Learning with Hints for End-to-end Task-oriented Dialog Systems](2024年05月24日/Synergizing_In-context_Learning_with_Hints_for_End-to-end_Task-oriented_Dialog_Systems.md)

    - [翻译: 融合提示的上下文学习，提升端到端任务导向型对话系统的协同效应](2024年05月24日/Synergizing_In-context_Learning_with_Hints_for_End-to-end_Task-oriented_Dialog_Systems.md)

- [Thinking Forward: Memory-Efficient Federated Finetuning of Language Models](2024年05月24日/Thinking_Forward_Memory-Efficient_Federated_Finetuning_of_Language_Models.md)

    - [翻译: 展望未来：优化内存的联邦微调语言模型策略](2024年05月24日/Thinking_Forward_Memory-Efficient_Federated_Finetuning_of_Language_Models.md)

- [Sparse Matrix in Large Language Model Fine-tuning](2024年05月24日/Sparse_Matrix_in_Large_Language_Model_Fine-tuning.md)

    - [翻译: 大型语言模型微调中的稀疏矩阵探索](2024年05月24日/Sparse_Matrix_in_Large_Language_Model_Fine-tuning.md)

- [Mosaic Memory: Fuzzy Duplication in Copyright Traps for Large Language Models](2024年05月24日/Mosaic_Memory_Fuzzy_Duplication_in_Copyright_Traps_for_Large_Language_Models.md)

    - [翻译: 马赛克记忆：大型语言模型版权陷阱中的模糊复制现象](2024年05月24日/Mosaic_Memory_Fuzzy_Duplication_in_Copyright_Traps_for_Large_Language_Models.md)

- [ChatGPT Code Detection: Techniques for Uncovering the Source of Code](2024年05月24日/ChatGPT_Code_Detection_Techniques_for_Uncovering_the_Source_of_Code.md)

    - [翻译: ChatGPT源码追踪：探秘代码起源的技术手段](2024年05月24日/ChatGPT_Code_Detection_Techniques_for_Uncovering_the_Source_of_Code.md)

- [Leveraging Large Language Models and Social Media for Automation in Scanning Probe Microscopy](2024年05月24日/Leveraging_Large_Language_Models_and_Social_Media_for_Automation_in_Scanning_Probe_Microscopy.md)

    - [翻译: 借助大型语言模型与社交媒体之力，推动扫描探针显微镜自动化进程](2024年05月24日/Leveraging_Large_Language_Models_and_Social_Media_for_Automation_in_Scanning_Probe_Microscopy.md)

- [Linearly Controlled Language Generation with Performative Guarantees](2024年05月24日/Linearly_Controlled_Language_Generation_with_Performative_Guarantees.md)

    - [翻译: 线性调控下的语言生成，确保性能稳定](2024年05月24日/Linearly_Controlled_Language_Generation_with_Performative_Guarantees.md)

- [Benchmarking Pre-trained Large Language Models' Potential Across Urdu NLP tasks](2024年05月24日/Benchmarking_Pre-trained_Large_Language_Models'_Potential_Across_Urdu_NLP_tasks.md)

    - [翻译: 探究预训练大型语言模型在乌尔都语 NLP 任务中的潜能](2024年05月24日/Benchmarking_Pre-trained_Large_Language_Models'_Potential_Across_Urdu_NLP_tasks.md)

- [Leveraging Logical Rules in Knowledge Editing: A Cherry on the Top](2024年05月24日/Leveraging_Logical_Rules_in_Knowledge_Editing_A_Cherry_on_the_Top.md)

    - [翻译: 在知识编辑中运用逻辑规则，犹如锦上添花，为知识的精炼与优化增添了更多可能。](2024年05月24日/Leveraging_Logical_Rules_in_Knowledge_Editing_A_Cherry_on_the_Top.md)

- [Generating Code World Models with Large Language Models Guided by Monte Carlo Tree Search](2024年05月24日/Generating_Code_World_Models_with_Large_Language_Models_Guided_by_Monte_Carlo_Tree_Search.md)

    - [翻译: 借助蒙特卡洛树搜索引导，大型语言模型助力构建代码世界模型](2024年05月24日/Generating_Code_World_Models_with_Large_Language_Models_Guided_by_Monte_Carlo_Tree_Search.md)

- [Leveraging Large Language Models for Semantic Query Processing in a Scholarly Knowledge Graph](2024年05月24日/Leveraging_Large_Language_Models_for_Semantic_Query_Processing_in_a_Scholarly_Knowledge_Graph.md)

    - [翻译: 借助大型语言模型优化学术知识图谱的语义查询处理](2024年05月24日/Leveraging_Large_Language_Models_for_Semantic_Query_Processing_in_a_Scholarly_Knowledge_Graph.md)

- [Large Language Models can Deliver Accurate and Interpretable Time Series Anomaly Detection](2024年05月24日/Large_Language_Models_can_Deliver_Accurate_and_Interpretable_Time_Series_Anomaly_Detection.md)

    - [翻译: 大型语言模型在时间序列异常检测方面展现出准确性与可解释性。](2024年05月24日/Large_Language_Models_can_Deliver_Accurate_and_Interpretable_Time_Series_Anomaly_Detection.md)

- [Pipeline Parallelism with Controllable Memory](2024年05月24日/Pipeline_Parallelism_with_Controllable_Memory.md)

    - [翻译: 可控内存下的管道并行性](2024年05月24日/Pipeline_Parallelism_with_Controllable_Memory.md)

- [Alleviating Hallucinations in Large Vision-Language Models through Hallucination-Induced Optimization](2024年05月24日/Alleviating_Hallucinations_in_Large_Vision-Language_Models_through_Hallucination-Induced_Optimization.md)

    - [翻译: 借助幻觉诱导优化，缓解大型视觉-语言模型中的幻觉问题](2024年05月24日/Alleviating_Hallucinations_in_Large_Vision-Language_Models_through_Hallucination-Induced_Optimization.md)

- [UnKE: Unstructured Knowledge Editing in Large Language Models](2024年05月24日/UnKE_Unstructured_Knowledge_Editing_in_Large_Language_Models.md)

    - [翻译: UnKE：大型语言模型中的非结构化知识精修](2024年05月24日/UnKE_Unstructured_Knowledge_Editing_in_Large_Language_Models.md)

- [BiSup: Bidirectional Quantization Error Suppression for Large Language Models](2024年05月24日/BiSup_Bidirectional_Quantization_Error_Suppression_for_Large_Language_Models.md)

    - [翻译: BiSup：大型语言模型中的双向量化误差抑制技术](2024年05月24日/BiSup_Bidirectional_Quantization_Error_Suppression_for_Large_Language_Models.md)

- [V-Zen: Efficient GUI Understanding and Precise Grounding With A Novel Multimodal LLM](2024年05月24日/V-Zen_Efficient_GUI_Understanding_and_Precise_Grounding_With_A_Novel_Multimodal_LLM.md)

    - [翻译: V-Zen：创新多模态LLM，精准解析图形用户界面，实现高效定位。](2024年05月24日/V-Zen_Efficient_GUI_Understanding_and_Precise_Grounding_With_A_Novel_Multimodal_LLM.md)

- [Decompose and Aggregate: A Step-by-Step Interpretable Evaluation Framework](2024年05月24日/Decompose_and_Aggregate_A_Step-by-Step_Interpretable_Evaluation_Framework.md)

    - [翻译: 分解聚合：构建一个逐步透明的评估体系](2024年05月24日/Decompose_and_Aggregate_A_Step-by-Step_Interpretable_Evaluation_Framework.md)

- [Organic Data-Driven Approach for Turkish Grammatical Error Correction and LLMs](2024年05月24日/Organic_Data-Driven_Approach_for_Turkish_Grammatical_Error_Correction_and_LLMs.md)

    - [翻译: 采用有机数据驱动策略，本研究致力于土耳其语法错误修正，并探索大型语言模型在此领域的应用。](2024年05月24日/Organic_Data-Driven_Approach_for_Turkish_Grammatical_Error_Correction_and_LLMs.md)

- [Stacking Your Transformers: A Closer Look at Model Growth for Efficient LLM Pre-Training](2024年05月24日/Stacking_Your_Transformers_A_Closer_Look_at_Model_Growth_for_Efficient_LLM_Pre-Training.md)

    - [翻译: 《堆叠Transformer：探索模型增长，优化大型语言模型预训练效率》](2024年05月24日/Stacking_Your_Transformers_A_Closer_Look_at_Model_Growth_for_Efficient_LLM_Pre-Training.md)

- [Before Generation, Align it! A Novel and Effective Strategy for Mitigating Hallucinations in Text-to-SQL Generation](2024年05月24日/Before_Generation,_Align_it!_A_Novel_and_Effective_Strategy_for_Mitigating_Hallucinations_in_Text-to-SQL_Generation.md)

    - [翻译: 生成文本到SQL前，先进行内容对齐！这一新颖而高效的策略，旨在有效缓解生成过程中的幻觉问题。](2024年05月24日/Before_Generation,_Align_it!_A_Novel_and_Effective_Strategy_for_Mitigating_Hallucinations_in_Text-to-SQL_Generation.md)

- [Towards Understanding How Transformer Perform Multi-step Reasoning with Matching Operation](2024年05月24日/Towards_Understanding_How_Transformer_Perform_Multi-step_Reasoning_with_Matching_Operation.md)

    - [翻译: 探索Transformer如何运用匹配操作实现多步骤推理的奥秘](2024年05月24日/Towards_Understanding_How_Transformer_Perform_Multi-step_Reasoning_with_Matching_Operation.md)

- [Question Answering models for information extraction from perovskite materials science literature](2024年05月24日/Question_Answering_models_for_information_extraction_from_perovskite_materials_science_literature.md)

    - [翻译: 钙钛矿材料科学文献信息提取的问答模型](2024年05月24日/Question_Answering_models_for_information_extraction_from_perovskite_materials_science_literature.md)

- [Learning Invariant Causal Mechanism from Vision-Language Models](2024年05月24日/Learning_Invariant_Causal_Mechanism_from_Vision-Language_Models.md)

    - [翻译: 探索视觉-语言模型中的不变因果机制学习](2024年05月24日/Learning_Invariant_Causal_Mechanism_from_Vision-Language_Models.md)

- [Coaching Copilot: Blended Form of an LLM-Powered Chatbot and a Human Coach to Effectively Support Self-Reflection for Leadership Growth](2024年05月24日/Coaching_Copilot_Blended_Form_of_an_LLM-Powered_Chatbot_and_a_Human_Coach_to_Effectively_Support_Self-Reflection_for_Leadership_Growth.md)

    - [翻译: 领导力成长助手：结合 LLM 聊天机器人与人类教练，共同助力自我反思，促进领导力发展。](2024年05月24日/Coaching_Copilot_Blended_Form_of_an_LLM-Powered_Chatbot_and_a_Human_Coach_to_Effectively_Support_Self-Reflection_for_Leadership_Growth.md)

- [DEEM: Diffusion Models Serve as the Eyes of Large Language Models for Image Perception](2024年05月24日/DEEM_Diffusion_Models_Serve_as_the_Eyes_of_Large_Language_Models_for_Image_Perception.md)

    - [翻译: DEEM：扩散模型——大型语言模型感知图像的慧眼](2024年05月24日/DEEM_Diffusion_Models_Serve_as_the_Eyes_of_Large_Language_Models_for_Image_Perception.md)

- [$i$REPO: $i$mplicit Reward Pairwise Difference based Empirical Preference Optimization](2024年05月24日/$i$REPO_$i$mplicit_Reward_Pairwise_Difference_based_Empirical_Preference_Optimization.md)

    - [翻译: $i$REPO：利用隐式奖励的成对差异进行经验偏好优化](2024年05月24日/$i$REPO_$i$mplicit_Reward_Pairwise_Difference_based_Empirical_Preference_Optimization.md)

- [Decoding at the Speed of Thought: Harnessing Parallel Decoding of Lexical Units for LLMs](2024年05月24日/Decoding_at_the_Speed_of_Thought_Harnessing_Parallel_Decoding_of_Lexical_Units_for_LLMs.md)

    - [翻译: 思维速度解码：借助词汇单元的并行解码，大型语言模型（LLMs）性能得以飞跃提升。](2024年05月24日/Decoding_at_the_Speed_of_Thought_Harnessing_Parallel_Decoding_of_Lexical_Units_for_LLMs.md)

- [Cross-Task Defense: Instruction-Tuning LLMs for Content Safety](2024年05月24日/Cross-Task_Defense_Instruction-Tuning_LLMs_for_Content_Safety.md)

    - [翻译: 跨任务防御：通过指令调整提升大型语言模型的内容安全性能](2024年05月24日/Cross-Task_Defense_Instruction-Tuning_LLMs_for_Content_Safety.md)

- [RAEE: A Training-Free Retrieval-Augmented Early Exiting Framework for Efficient Inference](2024年05月24日/RAEE_A_Training-Free_Retrieval-Augmented_Early_Exiting_Framework_for_Efficient_Inference.md)

    - [翻译: RAEE：一种无需额外训练的检索增强框架，通过早期退出策略优化推理效率](2024年05月24日/RAEE_A_Training-Free_Retrieval-Augmented_Early_Exiting_Framework_for_Efficient_Inference.md)

- [Large Language Models Reflect Human Citation Patterns with a Heightened Citation Bias](2024年05月24日/Large_Language_Models_Reflect_Human_Citation_Patterns_with_a_Heightened_Citation_Bias.md)

    - [翻译: 大型语言模型在引用模式上呈现出与人类相似的增强偏差。](2024年05月24日/Large_Language_Models_Reflect_Human_Citation_Patterns_with_a_Heightened_Citation_Bias.md)

- [Certifiably Robust RAG against Retrieval Corruption](2024年05月24日/Certifiably_Robust_RAG_against_Retrieval_Corruption.md)

    - [翻译: RAG 的可靠鲁棒性：抵御检索污染的证明](2024年05月24日/Certifiably_Robust_RAG_against_Retrieval_Corruption.md)

- [Hybrid Context Retrieval Augmented Generation Pipeline: LLM-Augmented Knowledge Graphs and Vector Database for Accreditation Reporting Assistance](2024年05月24日/Hybrid_Context_Retrieval_Augmented_Generation_Pipeline_LLM-Augmented_Knowledge_Graphs_and_Vector_Database_for_Accreditation_Reporting_Assistance.md)

    - [翻译: 认证报告辅助的混合上下文增强生成流程：结合LLM优化的知识图谱与向量数据库，提升检索效率。](2024年05月24日/Hybrid_Context_Retrieval_Augmented_Generation_Pipeline_LLM-Augmented_Knowledge_Graphs_and_Vector_Database_for_Accreditation_Reporting_Assistance.md)

- [ConvLLaVA: Hierarchical Backbones as Visual Encoder for Large Multimodal Models](2024年05月24日/ConvLLaVA_Hierarchical_Backbones_as_Visual_Encoder_for_Large_Multimodal_Models.md)

    - [翻译: ConvLLaVA：大型多模态模型的视觉编码器——层次化骨干网络](2024年05月24日/ConvLLaVA_Hierarchical_Backbones_as_Visual_Encoder_for_Large_Multimodal_Models.md)

- [Scaling Laws for Discriminative Classification in Large Language Models](2024年05月24日/Scaling_Laws_for_Discriminative_Classification_in_Large_Language_Models.md)

    - [翻译: 大型语言模型中判别分类的扩展规律](2024年05月24日/Scaling_Laws_for_Discriminative_Classification_in_Large_Language_Models.md)

- [Sparse maximal update parameterization: A holistic approach to sparse training dynamics](2024年05月24日/Sparse_maximal_update_parameterization_A_holistic_approach_to_sparse_training_dynamics.md)

    - [翻译: 稀疏最大更新参数化：探索稀疏训练动态的全局视角](2024年05月24日/Sparse_maximal_update_parameterization_A_holistic_approach_to_sparse_training_dynamics.md)

- [LM4LV: A Frozen Large Language Model for Low-level Vision Tasks](2024年05月24日/LM4LV_A_Frozen_Large_Language_Model_for_Low-level_Vision_Tasks.md)

    - [翻译: LM4LV：专为低级视觉任务设计的冻结大型语言模型](2024年05月24日/LM4LV_A_Frozen_Large_Language_Model_for_Low-level_Vision_Tasks.md)

- [Optimizing Large Language Models for OpenAPI Code Completion](2024年05月24日/Optimizing_Large_Language_Models_for_OpenAPI_Code_Completion.md)

    - [翻译: 精调大型语言模型，助力OpenAPI代码自动补全](2024年05月24日/Optimizing_Large_Language_Models_for_OpenAPI_Code_Completion.md)

- [Disease-informed Adaptation of Vision-Language Models](2024年05月24日/Disease-informed_Adaptation_of_Vision-Language_Models.md)

    - [翻译: 疾病引导的视觉-语言模型适应策略](2024年05月24日/Disease-informed_Adaptation_of_Vision-Language_Models.md)

- [Semantic Importance-Aware Communications with Semantic Correction Using Large Language Models](2024年05月24日/Semantic_Importance-Aware_Communications_with_Semantic_Correction_Using_Large_Language_Models.md)

    - [翻译: 利用大型语言模型进行语义校正的语义重要性感知通信](2024年05月24日/Semantic_Importance-Aware_Communications_with_Semantic_Correction_Using_Large_Language_Models.md)

- [Human-Centered Automation](2024年05月24日/Human-Centered_Automation.md)

    - [翻译: 人本自动化](2024年05月24日/Human-Centered_Automation.md)

- [Large Language Model Sentinel: Advancing Adversarial Robustness by LLM Agent](2024年05月24日/Large_Language_Model_Sentinel_Advancing_Adversarial_Robustness_by_LLM_Agent.md)

    - [翻译: 大型语言模型之哨兵：借助LLM代理提升对抗性鲁棒性](2024年05月24日/Large_Language_Model_Sentinel_Advancing_Adversarial_Robustness_by_LLM_Agent.md)

- [AMGPT: a Large Language Model for Contextual Querying in Additive Manufacturing](2024年05月24日/AMGPT_a_Large_Language_Model_for_Contextual_Querying_in_Additive_Manufacturing.md)

    - [翻译: AMGPT：专为增材制造领域设计的上下文查询大型语言模型](2024年05月24日/AMGPT_a_Large_Language_Model_for_Contextual_Querying_in_Additive_Manufacturing.md)

- [Clustered Retrieved Augmented Generation (CRAG)](2024年05月24日/Clustered_Retrieved_Augmented_Generation_(CRAG).md)

    - [翻译: 集群检索增强生成（CRAG）技术](2024年05月24日/Clustered_Retrieved_Augmented_Generation_(CRAG).md)

- [Embedding-Aligned Language Models](2024年05月24日/Embedding-Aligned_Language_Models.md)

    - [翻译: 语言模型嵌入对齐](2024年05月24日/Embedding-Aligned_Language_Models.md)

2024年05月23日

- [A Nurse is Blue and Elephant is Rugby: Cross Domain Alignment in Large Language Models Reveal Human-like Patterns](2024年05月23日/A_Nurse_is_Blue_and_Elephant_is_Rugby_Cross_Domain_Alignment_in_Large_Language_Models_Reveal_Human-like_Patterns.md)

    - [翻译: 大型语言模型中的跨域对齐展现出类似人类的模式，如“护士”对应“蓝色”，“大象”对应“橄榄球”。](2024年05月23日/A_Nurse_is_Blue_and_Elephant_is_Rugby_Cross_Domain_Alignment_in_Large_Language_Models_Reveal_Human-like_Patterns.md)

- [Bitune: Bidirectional Instruction-Tuning](2024年05月23日/Bitune_Bidirectional_Instruction-Tuning.md)

    - [翻译: Bitune：双向指令调优法](2024年05月23日/Bitune_Bidirectional_Instruction-Tuning.md)

- [PV-Tuning: Beyond Straight-Through Estimation for Extreme LLM Compression](2024年05月23日/PV-Tuning_Beyond_Straight-Through_Estimation_for_Extreme_LLM_Compression.md)

    - [翻译: PV-Tuning：突破传统直接估计法，引领极端大型语言模型压缩新篇章](2024年05月23日/PV-Tuning_Beyond_Straight-Through_Estimation_for_Extreme_LLM_Compression.md)

- [HippoRAG: Neurobiologically Inspired Long-Term Memory for Large Language Models](2024年05月23日/HippoRAG_Neurobiologically_Inspired_Long-Term_Memory_for_Large_Language_Models.md)

    - [翻译: HippoRAG：神经生物学启发的 LLM 长期记忆机制](2024年05月23日/HippoRAG_Neurobiologically_Inspired_Long-Term_Memory_for_Large_Language_Models.md)

- [Can LLMs Solve longer Math Word Problems Better?](2024年05月23日/Can_LLMs_Solve_longer_Math_Word_Problems_Better.md)

    - [翻译: 大型语言模型是否在解决更长的数学文字问题上表现更佳？](2024年05月23日/Can_LLMs_Solve_longer_Math_Word_Problems_Better.md)

- [Lessons from the Trenches on Reproducible Evaluation of Language Models](2024年05月23日/Lessons_from_the_Trenches_on_Reproducible_Evaluation_of_Language_Models.md)

    - [翻译: 战壕经验谈：语言模型评估的可重复性之道](2024年05月23日/Lessons_from_the_Trenches_on_Reproducible_Evaluation_of_Language_Models.md)

- [WISE: Rethinking the Knowledge Memory for Lifelong Model Editing of Large Language Models](2024年05月23日/WISE_Rethinking_the_Knowledge_Memory_for_Lifelong_Model_Editing_of_Large_Language_Models.md)

    - [翻译: WISE：重塑大型语言模型终身编辑的知识记忆](2024年05月23日/WISE_Rethinking_the_Knowledge_Memory_for_Lifelong_Model_Editing_of_Large_Language_Models.md)

- [FinRobot: An Open-Source AI Agent Platform for Financial Applications using Large Language Models](2024年05月23日/FinRobot_An_Open-Source_AI_Agent_Platform_for_Financial_Applications_using_Large_Language_Models.md)

    - [翻译: FinRobot：金融领域的开源AI代理平台，依托大型语言模型，助力智能金融应用。](2024年05月23日/FinRobot_An_Open-Source_AI_Agent_Platform_for_Financial_Applications_using_Large_Language_Models.md)

- [Evaluating Large Language Models for Public Health Classification and Extraction Tasks](2024年05月23日/Evaluating_Large_Language_Models_for_Public_Health_Classification_and_Extraction_Tasks.md)

    - [翻译: 大型语言模型在公共卫生分类与信息提取任务中的评估](2024年05月23日/Evaluating_Large_Language_Models_for_Public_Health_Classification_and_Extraction_Tasks.md)

- [Large language models can be zero-shot anomaly detectors for time series?](2024年05月23日/Large_language_models_can_be_zero-shot_anomaly_detectors_for_time_series.md)

    - [翻译: 大型语言模型是否具备零-shot检测时间序列异常的能力？](2024年05月23日/Large_language_models_can_be_zero-shot_anomaly_detectors_for_time_series.md)

- [A Transformer-Based Approach for Smart Invocation of Automatic Code Completion](2024年05月23日/A_Transformer-Based_Approach_for_Smart_Invocation_of_Automatic_Code_Completion.md)

    - [翻译: 基于Transformer的智能调用自动代码补全方法](2024年05月23日/A_Transformer-Based_Approach_for_Smart_Invocation_of_Automatic_Code_Completion.md)

- [MultiCast: Zero-Shot Multivariate Time Series Forecasting Using LLMs](2024年05月23日/MultiCast_Zero-Shot_Multivariate_Time_Series_Forecasting_Using_LLMs.md)

    - [翻译: MultiCast：借助LLMs实现零-shot多元时间序列预测](2024年05月23日/MultiCast_Zero-Shot_Multivariate_Time_Series_Forecasting_Using_LLMs.md)

- [Exploring Prosocial Irrationality for LLM Agents: A Social Cognition View](2024年05月23日/Exploring_Prosocial_Irrationality_for_LLM_Agents_A_Social_Cognition_View.md)

    - [翻译: 从社会认知角度探究大型语言模型代理的亲社会非理性行为](2024年05月23日/Exploring_Prosocial_Irrationality_for_LLM_Agents_A_Social_Cognition_View.md)

- [CLIPScope: Enhancing Zero-Shot OOD Detection with Bayesian Scoring](2024年05月23日/CLIPScope_Enhancing_Zero-Shot_OOD_Detection_with_Bayesian_Scoring.md)

    - [翻译: CLIPScope：借助贝叶斯评分提升零-shot 异常检测能力](2024年05月23日/CLIPScope_Enhancing_Zero-Shot_OOD_Detection_with_Bayesian_Scoring.md)

- [Distilling Vision-Language Pretraining for Efficient Cross-Modal Retrieval](2024年05月23日/Distilling_Vision-Language_Pretraining_for_Efficient_Cross-Modal_Retrieval.md)

    - [翻译: 蒸馏视觉-语言预训练，提升跨模态检索效率](2024年05月23日/Distilling_Vision-Language_Pretraining_for_Efficient_Cross-Modal_Retrieval.md)

- [Towards Cross-modal Backward-compatible Representation Learning for Vision-Language Models](2024年05月23日/Towards_Cross-modal_Backward-compatible_Representation_Learning_for_Vision-Language_Models.md)

    - [翻译: 探索视觉-语言模型中的跨模态后向兼容表示学习](2024年05月23日/Towards_Cross-modal_Backward-compatible_Representation_Learning_for_Vision-Language_Models.md)

- [Towards Educator-Driven Tutor Authoring: Generative AI Approaches for Creating Intelligent Tutor Interfaces](2024年05月23日/Towards_Educator-Driven_Tutor_Authoring_Generative_AI_Approaches_for_Creating_Intelligent_Tutor_Interfaces.md)

    - [翻译: 教育者主导的智能导师界面创作：探索生成式AI在打造智能教学交互中的应用](2024年05月23日/Towards_Educator-Driven_Tutor_Authoring_Generative_AI_Approaches_for_Creating_Intelligent_Tutor_Interfaces.md)

- [A Declarative System for Optimizing AI Workloads](2024年05月23日/A_Declarative_System_for_Optimizing_AI_Workloads.md)

    - [翻译: 声明式系统：优化AI工作负载的利器](2024年05月23日/A_Declarative_System_for_Optimizing_AI_Workloads.md)

- [CityGPT: Towards Urban IoT Learning, Analysis and Interaction with Multi-Agent System](2024年05月23日/CityGPT_Towards_Urban_IoT_Learning,_Analysis_and_Interaction_with_Multi-Agent_System.md)

    - [翻译: CityGPT：助力城市物联网学习与分析，实现多智能体系统交互](2024年05月23日/CityGPT_Towards_Urban_IoT_Learning,_Analysis_and_Interaction_with_Multi-Agent_System.md)

- [Implicit In-context Learning](2024年05月23日/Implicit_In-context_Learning.md)

    - [翻译: 隐式上下文学习探究](2024年05月23日/Implicit_In-context_Learning.md)

- [Multi-turn Reinforcement Learning from Preference Human Feedback](2024年05月23日/Multi-turn_Reinforcement_Learning_from_Preference_Human_Feedback.md)

    - [翻译: 基于人类偏好反馈的多轮强化学习](2024年05月23日/Multi-turn_Reinforcement_Learning_from_Preference_Human_Feedback.md)

- [Efficient Medical Question Answering with Knowledge-Augmented Question Generation](2024年05月23日/Efficient_Medical_Question_Answering_with_Knowledge-Augmented_Question_Generation.md)

    - [翻译: 知识赋能，高效问答：医疗领域的问题生成新策略](2024年05月23日/Efficient_Medical_Question_Answering_with_Knowledge-Augmented_Question_Generation.md)

- [Unveiling the Achilles' Heel of NLG Evaluators: A Unified Adversarial Framework Driven by Large Language Models](2024年05月23日/Unveiling_the_Achilles'_Heel_of_NLG_Evaluators_A_Unified_Adversarial_Framework_Driven_by_Large_Language_Models.md)

    - [翻译: 揭示NLG评估器的弱点：大型语言模型驱动的统一对抗框架](2024年05月23日/Unveiling_the_Achilles'_Heel_of_NLG_Evaluators_A_Unified_Adversarial_Framework_Driven_by_Large_Language_Models.md)

- [PerLLM: Personalized Inference Scheduling with Edge-Cloud Collaboration for Diverse LLM Services](2024年05月23日/PerLLM_Personalized_Inference_Scheduling_with_Edge-Cloud_Collaboration_for_Diverse_LLM_Services.md)

    - [翻译: PerLLM：借助边缘与云的协同，为多样化的LLM服务量身定制推理调度策略](2024年05月23日/PerLLM_Personalized_Inference_Scheduling_with_Edge-Cloud_Collaboration_for_Diverse_LLM_Services.md)

- [Calibrated Self-Rewarding Vision Language Models](2024年05月23日/Calibrated_Self-Rewarding_Vision_Language_Models.md)

    - [翻译: 精准自赏的视语模型](2024年05月23日/Calibrated_Self-Rewarding_Vision_Language_Models.md)

- [Generating Exceptional Behavior Tests with Reasoning Augmented Large Language Models](2024年05月23日/Generating_Exceptional_Behavior_Tests_with_Reasoning_Augmented_Large_Language_Models.md)

    - [翻译: 借助推理增强的大型语言模型，我们能够生成高质量的行为测试，这些测试在评估系统性能时表现出色。](2024年05月23日/Generating_Exceptional_Behavior_Tests_with_Reasoning_Augmented_Large_Language_Models.md)

- [Explaining Multi-modal Large Language Models by Analyzing their Vision Perception](2024年05月23日/Explaining_Multi-modal_Large_Language_Models_by_Analyzing_their_Vision_Perception.md)

    - [翻译: 解析多模态大型语言模型的视觉感知能力](2024年05月23日/Explaining_Multi-modal_Large_Language_Models_by_Analyzing_their_Vision_Perception.md)

- [A Watermark for Low-entropy and Unbiased Generation in Large Language Models](2024年05月23日/A_Watermark_for_Low-entropy_and_Unbiased_Generation_in_Large_Language_Models.md)

    - [翻译: 大型语言模型中低熵无偏生成的水印标识](2024年05月23日/A_Watermark_for_Low-entropy_and_Unbiased_Generation_in_Large_Language_Models.md)

- [Visual Echoes: A Simple Unified Transformer for Audio-Visual Generation](2024年05月23日/Visual_Echoes_A_Simple_Unified_Transformer_for_Audio-Visual_Generation.md)

    - [翻译: 视觉回响：音视频生成领域的简洁统一Transformer](2024年05月23日/Visual_Echoes_A_Simple_Unified_Transformer_for_Audio-Visual_Generation.md)

- [Integer Scale: A Free Lunch for Faster Fine-grained Quantization of LLMs](2024年05月23日/Integer_Scale_A_Free_Lunch_for_Faster_Fine-grained_Quantization_of_LLMs.md)

    - [翻译: 整数尺度：加速大型语言模型细粒度量化的免费之选](2024年05月23日/Integer_Scale_A_Free_Lunch_for_Faster_Fine-grained_Quantization_of_LLMs.md)

- [Base of RoPE Bounds Context Length](2024年05月23日/Base_of_RoPE_Bounds_Context_Length.md)

    - [翻译: RoPE基础对上下文长度设定了界限](2024年05月23日/Base_of_RoPE_Bounds_Context_Length.md)

- [Top-Down Partitioning for Efficient List-Wise Ranking](2024年05月23日/Top-Down_Partitioning_for_Efficient_List-Wise_Ranking.md)

    - [翻译: 采用自顶向下的分区策略，列表级排序得以高效实现。](2024年05月23日/Top-Down_Partitioning_for_Efficient_List-Wise_Ranking.md)

- [Representation noising effectively prevents harmful fine-tuning on LLMs](2024年05月23日/Representation_noising_effectively_prevents_harmful_fine-tuning_on_LLMs.md)

    - [翻译: 通过引入表示噪声，我们能有效避免对大型语言模型进行有害的微调。](2024年05月23日/Representation_noising_effectively_prevents_harmful_fine-tuning_on_LLMs.md)

- [Subtle Biases Need Subtler Measures: Dual Metrics for Evaluating Representative and Affinity Bias in Large Language Models](2024年05月23日/Subtle_Biases_Need_Subtler_Measures_Dual_Metrics_for_Evaluating_Representative_and_Affinity_Bias_in_Large_Language_Models.md)

    - [翻译: 微妙偏见，需以细腻之策应对：大型语言模型中代表性与亲和性偏差的双重评估指标](2024年05月23日/Subtle_Biases_Need_Subtler_Measures_Dual_Metrics_for_Evaluating_Representative_and_Affinity_Bias_in_Large_Language_Models.md)

- [UDKAG: Augmenting Large Vision-Language Models with Up-to-Date Knowledge](2024年05月23日/UDKAG_Augmenting_Large_Vision-Language_Models_with_Up-to-Date_Knowledge.md)

    - [翻译: UDKAG：为大型视觉-语言模型注入最新知识](2024年05月23日/UDKAG_Augmenting_Large_Vision-Language_Models_with_Up-to-Date_Knowledge.md)

- [Impact of Non-Standard Unicode Characters on Security and Comprehension in Large Language Models](2024年05月23日/Impact_of_Non-Standard_Unicode_Characters_on_Security_and_Comprehension_in_Large_Language_Models.md)

    - [翻译: 非标准Unicode字符对大型语言模型安全与理解的双重挑战](2024年05月23日/Impact_of_Non-Standard_Unicode_Characters_on_Security_and_Comprehension_in_Large_Language_Models.md)

- [MoGU: A Framework for Enhancing Safety of Open-Sourced LLMs While Preserving Their Usability](2024年05月23日/MoGU_A_Framework_for_Enhancing_Safety_of_Open-Sourced_LLMs_While_Preserving_Their_Usability.md)

    - [翻译: MoGU：提升开源LLM安全性的同时确保其易用性的框架](2024年05月23日/MoGU_A_Framework_for_Enhancing_Safety_of_Open-Sourced_LLMs_While_Preserving_Their_Usability.md)

- [A Comprehensive Overview of Large Language Models (LLMs) for Cyber Defences: Opportunities and Directions](2024年05月23日/A_Comprehensive_Overview_of_Large_Language_Models_(LLMs)_for_Cyber_Defences_Opportunities_and_Directions.md)

    - [翻译: 大型语言模型在网络防御领域的全面展望：探索机遇与未来方向](2024年05月23日/A_Comprehensive_Overview_of_Large_Language_Models_(LLMs)_for_Cyber_Defences_Opportunities_and_Directions.md)

- [RefChecker: Reference-based Fine-grained Hallucination Checker and Benchmark for Large Language Models](2024年05月23日/RefChecker_Reference-based_Fine-grained_Hallucination_Checker_and_Benchmark_for_Large_Language_Models.md)

    - [翻译: RefChecker：大型语言模型细粒度幻觉检测与基准评估工具](2024年05月23日/RefChecker_Reference-based_Fine-grained_Hallucination_Checker_and_Benchmark_for_Large_Language_Models.md)

- [Exploring the use of a Large Language Model for data extraction in systematic reviews: a rapid feasibility study](2024年05月23日/Exploring_the_use_of_a_Large_Language_Model_for_data_extraction_in_systematic_reviews_a_rapid_feasibility_study.md)

    - [翻译: 本研究旨在快速评估大型语言模型在系统评价数据提取中的应用潜力。](2024年05月23日/Exploring_the_use_of_a_Large_Language_Model_for_data_extraction_in_systematic_reviews_a_rapid_feasibility_study.md)

- [Combining Denoising Autoencoders with Contrastive Learning to fine-tune Transformer Models](2024年05月23日/Combining_Denoising_Autoencoders_with_Contrastive_Learning_to_fine-tune_Transformer_Models.md)

    - [翻译: 融合去噪自编码器与对比学习，精调Transformer模型](2024年05月23日/Combining_Denoising_Autoencoders_with_Contrastive_Learning_to_fine-tune_Transformer_Models.md)

- [RaFe: Ranking Feedback Improves Query Rewriting for RAG](2024年05月23日/RaFe_Ranking_Feedback_Improves_Query_Rewriting_for_RAG.md)

    - [翻译: RaFe：通过排名反馈优化RAG的查询重写策略](2024年05月23日/RaFe_Ranking_Feedback_Improves_Query_Rewriting_for_RAG.md)

- [Mitigating Quantization Errors Due to Activation Spikes in GLU-Based LLMs](2024年05月23日/Mitigating_Quantization_Errors_Due_to_Activation_Spikes_in_GLU-Based_LLMs.md)

    - [翻译: 缓解基于GLU的LLMs中激活尖峰导致的量化误差问题](2024年05月23日/Mitigating_Quantization_Errors_Due_to_Activation_Spikes_in_GLU-Based_LLMs.md)

- [Large Language Models for Explainable Decisions in Dynamic Digital Twins](2024年05月23日/Large_Language_Models_for_Explainable_Decisions_in_Dynamic_Digital_Twins.md)

    - [翻译: 大型语言模型助力动态数字孪生实现决策透明化](2024年05月23日/Large_Language_Models_for_Explainable_Decisions_in_Dynamic_Digital_Twins.md)

- [Explainable Few-shot Knowledge Tracing](2024年05月23日/Explainable_Few-shot_Knowledge_Tracing.md)

    - [翻译: 可解释的少量样本知识追踪研究](2024年05月23日/Explainable_Few-shot_Knowledge_Tracing.md)

- [Evaluation of the Programming Skills of Large Language Models](2024年05月23日/Evaluation_of_the_Programming_Skills_of_Large_Language_Models.md)

    - [翻译: 大型语言模型编程能力的评测](2024年05月23日/Evaluation_of_the_Programming_Skills_of_Large_Language_Models.md)

- [Emotion Identification for French in Written Texts: Considering their Modes of Expression as a Step Towards Text Complexity Analysis](2024年05月23日/Emotion_Identification_for_French_in_Written_Texts_Considering_their_Modes_of_Expression_as_a_Step_Towards_Text_Complexity_Analysis.md)

    - [翻译: 探索法语书面文本的情感识别：以表达方式为切入点，迈向文本复杂性分析的新篇章](2024年05月23日/Emotion_Identification_for_French_in_Written_Texts_Considering_their_Modes_of_Expression_as_a_Step_Towards_Text_Complexity_Analysis.md)

- [Perception of Knowledge Boundary for Large Language Models through Semi-open-ended Question Answering](2024年05月23日/Perception_of_Knowledge_Boundary_for_Large_Language_Models_through_Semi-open-ended_Question_Answering.md)

    - [翻译: 借助半开放式问答探索大型语言模型的知识界限](2024年05月23日/Perception_of_Knowledge_Boundary_for_Large_Language_Models_through_Semi-open-ended_Question_Answering.md)

- [Can Large Language Models Create New Knowledge for Spatial Reasoning Tasks?](2024年05月23日/Can_Large_Language_Models_Create_New_Knowledge_for_Spatial_Reasoning_Tasks.md)

    - [翻译: 大型语言模型是否具备为空间推理任务创造新知识的能力？](2024年05月23日/Can_Large_Language_Models_Create_New_Knowledge_for_Spatial_Reasoning_Tasks.md)

- [CoMERA: Computing- and Memory-Efficient Training via Rank-Adaptive Tensor Optimization](2024年05月23日/CoMERA_Computing-_and_Memory-Efficient_Training_via_Rank-Adaptive_Tensor_Optimization.md)

    - [翻译: CoMERA：利用秩自适应张量优化，实现高效计算与内存的训练方法](2024年05月23日/CoMERA_Computing-_and_Memory-Efficient_Training_via_Rank-Adaptive_Tensor_Optimization.md)

- [A Textbook Remedy for Domain Shifts: Knowledge Priors for Medical Image Analysis](2024年05月23日/A_Textbook_Remedy_for_Domain_Shifts_Knowledge_Priors_for_Medical_Image_Analysis.md)

    - [翻译: 应对领域转移的经典策略：利用知识先验优化医学图像分析](2024年05月23日/A_Textbook_Remedy_for_Domain_Shifts_Knowledge_Priors_for_Medical_Image_Analysis.md)

- [G3: An Effective and Adaptive Framework for Worldwide Geolocalization Using Large Multi-Modality Models](2024年05月23日/G3_An_Effective_and_Adaptive_Framework_for_Worldwide_Geolocalization_Using_Large_Multi-Modality_Models.md)

    - [翻译: G3：利用大型多模态模型，打造全球地理定位的高效自适应框架](2024年05月23日/G3_An_Effective_and_Adaptive_Framework_for_Worldwide_Geolocalization_Using_Large_Multi-Modality_Models.md)

- [Towards Efficient LLM Grounding for Embodied Multi-Agent Collaboration](2024年05月23日/Towards_Efficient_LLM_Grounding_for_Embodied_Multi-Agent_Collaboration.md)

    - [翻译: 构建高效的大型语言模型基础，促进具身多智能体协同合作](2024年05月23日/Towards_Efficient_LLM_Grounding_for_Embodied_Multi-Agent_Collaboration.md)

- [Agent Planning with World Knowledge Model](2024年05月23日/Agent_Planning_with_World_Knowledge_Model.md)

    - [翻译: 基于世界知识模型的智能代理规划](2024年05月23日/Agent_Planning_with_World_Knowledge_Model.md)

- [Identity Inference from CLIP Models using Only Textual Data](2024年05月23日/Identity_Inference_from_CLIP_Models_using_Only_Textual_Data.md)

    - [翻译: 仅凭文本数据，揭秘CLIP模型中的身份推断之谜](2024年05月23日/Identity_Inference_from_CLIP_Models_using_Only_Textual_Data.md)

- [From Text to Pixel: Advancing Long-Context Understanding in MLLMs](2024年05月23日/From_Text_to_Pixel_Advancing_Long-Context_Understanding_in_MLLMs.md)

    - [翻译: 文本至像素：深化多模态大型语言模型中的长上下文理解](2024年05月23日/From_Text_to_Pixel_Advancing_Long-Context_Understanding_in_MLLMs.md)

- [GLaD: Synergizing Molecular Graphs and Language Descriptors for Enhanced Power Conversion Efficiency Prediction in Organic Photovoltaic Devices](2024年05月23日/GLaD_Synergizing_Molecular_Graphs_and_Language_Descriptors_for_Enhanced_Power_Conversion_Efficiency_Prediction_in_Organic_Photovoltaic_Devices.md)

    - [翻译: GLaD：融合分子图与语言描述，提升有机光伏设备功率转换效率预测精度](2024年05月23日/GLaD_Synergizing_Molecular_Graphs_and_Language_Descriptors_for_Enhanced_Power_Conversion_Efficiency_Prediction_in_Organic_Photovoltaic_Devices.md)

- [Awesome Multi-modal Object Tracking](2024年05月23日/Awesome_Multi-modal_Object_Tracking.md)

    - [翻译: 精彩纷呈的多模态追踪技术](2024年05月23日/Awesome_Multi-modal_Object_Tracking.md)

- [Efficient Reinforcement Learning via Large Language Model-based Search](2024年05月23日/Efficient_Reinforcement_Learning_via_Large_Language_Model-based_Search.md)

    - [翻译: 借助大型语言模型，探索高效强化学习之路](2024年05月23日/Efficient_Reinforcement_Learning_via_Large_Language_Model-based_Search.md)

- [SOAP: Enhancing Efficiency of Generated Code via Self-Optimization](2024年05月23日/SOAP_Enhancing_Efficiency_of_Generated_Code_via_Self-Optimization.md)

    - [翻译: SOAP：借助自我优化，提升生成代码的效率](2024年05月23日/SOAP_Enhancing_Efficiency_of_Generated_Code_via_Self-Optimization.md)

- [Grokked Transformers are Implicit Reasoners: A Mechanistic Journey to the Edge of Generalization](2024年05月23日/Grokked_Transformers_are_Implicit_Reasoners_A_Mechanistic_Journey_to_the_Edge_of_Generalization.md)

    - [翻译: Transformer的隐式推理之旅：探索泛化极限的机制探秘](2024年05月23日/Grokked_Transformers_are_Implicit_Reasoners_A_Mechanistic_Journey_to_the_Edge_of_Generalization.md)

- [AGRaME: Any-Granularity Ranking with Multi-Vector Embeddings](2024年05月23日/AGRaME_Any-Granularity_Ranking_with_Multi-Vector_Embeddings.md)

    - [翻译: AGRaME：多向量嵌入助力任意粒度排序](2024年05月23日/AGRaME_Any-Granularity_Ranking_with_Multi-Vector_Embeddings.md)

- [RE-Adapt: Reverse Engineered Adaptation of Large Language Models](2024年05月23日/RE-Adapt_Reverse_Engineered_Adaptation_of_Large_Language_Models.md)

    - [翻译: RE-Adapt：大型语言模型的逆向适应工程](2024年05月23日/RE-Adapt_Reverse_Engineered_Adaptation_of_Large_Language_Models.md)

- [CulturePark: Boosting Cross-cultural Understanding in Large Language Models](2024年05月23日/CulturePark_Boosting_Cross-cultural_Understanding_in_Large_Language_Models.md)

    - [翻译: 文化公园：增强大型语言模型中的跨文化理解能力](2024年05月23日/CulturePark_Boosting_Cross-cultural_Understanding_in_Large_Language_Models.md)

- [Eliciting Informative Text Evaluations with Large Language Models](2024年05月23日/Eliciting_Informative_Text_Evaluations_with_Large_Language_Models.md)

    - [翻译: 借助大型语言模型，我们能够引出富含信息的文本评估，深入探索语言模型的评估潜力。](2024年05月23日/Eliciting_Informative_Text_Evaluations_with_Large_Language_Models.md)

- [Agentic Skill Discovery](2024年05月23日/Agentic_Skill_Discovery.md)

    - [翻译: 主动技能探索](2024年05月23日/Agentic_Skill_Discovery.md)

- [AnalogCoder: Analog Circuit Design via Training-Free Code Generation](2024年05月23日/AnalogCoder_Analog_Circuit_Design_via_Training-Free_Code_Generation.md)

    - [翻译: AnalogCoder：模拟电路设计新方法——无需训练的代码生成技术](2024年05月23日/AnalogCoder_Analog_Circuit_Design_via_Training-Free_Code_Generation.md)

- [Shopping Queries Image Dataset (SQID): An Image-Enriched ESCI Dataset for Exploring Multimodal Learning in Product Search](2024年05月23日/Shopping_Queries_Image_Dataset_(SQID)_An_Image-Enriched_ESCI_Dataset_for_Exploring_Multimodal_Learning_in_Product_Search.md)

    - [翻译: SQID：一个图像丰富的ESCI数据集，专为探索产品搜索中的多模态学习而设计](2024年05月23日/Shopping_Queries_Image_Dataset_(SQID)_An_Image-Enriched_ESCI_Dataset_for_Exploring_Multimodal_Learning_in_Product_Search.md)

- [LOVA3: Learning to Visual Question Answering, Asking and Assessment](2024年05月23日/LOVA3_Learning_to_Visual_Question_Answering,_Asking_and_Assessment.md)

    - [翻译: LOVA3：掌握视觉问答、提问与评估的艺术](2024年05月23日/LOVA3_Learning_to_Visual_Question_Answering,_Asking_and_Assessment.md)

2024年05月22日

- [Image-of-Thought Prompting for Visual Reasoning Refinement in Multimodal Large Language Models](2024年05月22日/Image-of-Thought_Prompting_for_Visual_Reasoning_Refinement_in_Multimodal_Large_Language_Models.md)

    - [翻译: 多模态大型语言模型中视觉推理细化的“思想图像”提示法](2024年05月22日/Image-of-Thought_Prompting_for_Visual_Reasoning_Refinement_in_Multimodal_Large_Language_Models.md)

- [Dense Connector for MLLMs](2024年05月22日/Dense_Connector_for_MLLMs.md)

    - [翻译: 多语言大型语言模型的密集连接器](2024年05月22日/Dense_Connector_for_MLLMs.md)

- [CrossCheckGPT: Universal Hallucination Ranking for Multimodal Foundation Models](2024年05月22日/CrossCheckGPT_Universal_Hallucination_Ranking_for_Multimodal_Foundation_Models.md)

    - [翻译: CrossCheckGPT：多模态基础模型幻觉评估的通用排名系统](2024年05月22日/CrossCheckGPT_Universal_Hallucination_Ranking_for_Multimodal_Foundation_Models.md)

- [FiDeLiS: Faithful Reasoning in Large Language Model for Knowledge Graph Question Answering](2024年05月22日/FiDeLiS_Faithful_Reasoning_in_Large_Language_Model_for_Knowledge_Graph_Question_Answering.md)

    - [翻译: FiDeLiS：大型语言模型在知识图谱问答中的忠实推理探索](2024年05月22日/FiDeLiS_Faithful_Reasoning_in_Large_Language_Model_for_Knowledge_Graph_Question_Answering.md)

- [Scaling-laws for Large Time-series Models](2024年05月22日/Scaling-laws_for_Large_Time-series_Models.md)

    - [翻译: 大型时间序列模型的规模化定律](2024年05月22日/Scaling-laws_for_Large_Time-series_Models.md)

- [Semantic Density: Uncertainty Quantification in Semantic Space for Large Language Models](2024年05月22日/Semantic_Density_Uncertainty_Quantification_in_Semantic_Space_for_Large_Language_Models.md)

    - [翻译: 语义空间中的不确定性量化：探究大型语言模型的语义密度](2024年05月22日/Semantic_Density_Uncertainty_Quantification_in_Semantic_Space_for_Large_Language_Models.md)

- [Babysit A Language Model From Scratch: Interactive Language Learning by Trials and Demonstrations](2024年05月22日/Babysit_A_Language_Model_From_Scratch_Interactive_Language_Learning_by_Trials_and_Demonstrations.md)

    - [翻译: 从零开始培养语言模型：通过反复试验与实例演示，实现交互式语言学习之旅](2024年05月22日/Babysit_A_Language_Model_From_Scratch_Interactive_Language_Learning_by_Trials_and_Demonstrations.md)

- [Range-Limited Heaps' Law for Functional DNA Words in the Human Genome](2024年05月22日/Range-Limited_Heaps'_Law_for_Functional_DNA_Words_in_the_Human_Genome.md)

    - [翻译: 人类基因组中功能性DNA词汇的有限范围堆法研究](2024年05月22日/Range-Limited_Heaps'_Law_for_Functional_DNA_Words_in_the_Human_Genome.md)

- [Towards Comprehensive and Efficient Post Safety Alignment of Large Language Models via Safety Patching](2024年05月22日/Towards_Comprehensive_and_Efficient_Post_Safety_Alignment_of_Large_Language_Models_via_Safety_Patching.md)

    - [翻译: 利用安全补丁，全面高效地对大型语言模型进行后安全对齐](2024年05月22日/Towards_Comprehensive_and_Efficient_Post_Safety_Alignment_of_Large_Language_Models_via_Safety_Patching.md)

- [Thermodynamic Natural Gradient Descent](2024年05月22日/Thermodynamic_Natural_Gradient_Descent.md)

    - [翻译: 热力学自然梯度下降法](2024年05月22日/Thermodynamic_Natural_Gradient_Descent.md)

- [Large Language Models are Good Spontaneous Multilingual Learners: Is the Multilingual Annotated Data Necessary?](2024年05月22日/Large_Language_Models_are_Good_Spontaneous_Multilingual_Learners_Is_the_Multilingual_Annotated_Data_Necessary.md)

    - [翻译: 大型语言模型展现出卓越的自发性多语言学习能力，这引发了一个问题：我们是否真的需要多语言标注数据？](2024年05月22日/Large_Language_Models_are_Good_Spontaneous_Multilingual_Learners_Is_the_Multilingual_Annotated_Data_Necessary.md)

- [Slaves to the Law of Large Numbers: An Asymptotic Equipartition Property for Perplexity in Generative Language Models](2024年05月22日/Slaves_to_the_Law_of_Large_Numbers_An_Asymptotic_Equipartition_Property_for_Perplexity_in_Generative_Language_Models.md)

    - [翻译: 大数定律下的奴隶：生成语言模型中困惑度的渐近等分特性](2024年05月22日/Slaves_to_the_Law_of_Large_Numbers_An_Asymptotic_Equipartition_Property_for_Perplexity_in_Generative_Language_Models.md)

- [Do Language Models Enjoy Their Own Stories? Prompting Large Language Models for Automatic Story Evaluation](2024年05月22日/Do_Language_Models_Enjoy_Their_Own_Stories_Prompting_Large_Language_Models_for_Automatic_Story_Evaluation.md)

    - [翻译: 大型语言模型是否自得其乐于其编织的故事？探索利用这些模型进行自动故事评估的潜力。](2024年05月22日/Do_Language_Models_Enjoy_Their_Own_Stories_Prompting_Large_Language_Models_for_Automatic_Story_Evaluation.md)

- [CG-FedLLM: How to Compress Gradients in Federated Fune-tuning for Large Language Models](2024年05月22日/CG-FedLLM_How_to_Compress_Gradients_in_Federated_Fune-tuning_for_Large_Language_Models.md)

    - [翻译: CG-FedLLM：大型语言模型联邦微调中的梯度压缩策略](2024年05月22日/CG-FedLLM_How_to_Compress_Gradients_in_Federated_Fune-tuning_for_Large_Language_Models.md)

- [Mining Action Rules for Defect Reduction Planning](2024年05月22日/Mining_Action_Rules_for_Defect_Reduction_Planning.md)

    - [翻译: 挖掘行动规则，助力缺陷减少规划](2024年05月22日/Mining_Action_Rules_for_Defect_Reduction_Planning.md)

- [Knowledge Graph Reasoning with Self-supervised Reinforcement Learning](2024年05月22日/Knowledge_Graph_Reasoning_with_Self-supervised_Reinforcement_Learning.md)

    - [翻译: 利用自监督强化学习进行知识图谱推理](2024年05月22日/Knowledge_Graph_Reasoning_with_Self-supervised_Reinforcement_Learning.md)

- [Automated Evaluation of Retrieval-Augmented Language Models with Task-Specific Exam Generation](2024年05月22日/Automated_Evaluation_of_Retrieval-Augmented_Language_Models_with_Task-Specific_Exam_Generation.md)

    - [翻译: 通过任务特定考试生成，自动化评估检索增强型语言模型](2024年05月22日/Automated_Evaluation_of_Retrieval-Augmented_Language_Models_with_Task-Specific_Exam_Generation.md)

- [From the evolution of public data ecosystems to the evolving horizons of the forward-looking intelligent public data ecosystem empowered by emerging technologies](2024年05月22日/From_the_evolution_of_public_data_ecosystems_to_the_evolving_horizons_of_the_forward-looking_intelligent_public_data_ecosystem_empowered_by_emerging_technologies.md)

    - [翻译: 公共数据生态系统正经历着从演进到新兴技术推动的前瞻性智能化的转变，其视野不断扩展。](2024年05月22日/From_the_evolution_of_public_data_ecosystems_to_the_evolving_horizons_of_the_forward-looking_intelligent_public_data_ecosystem_empowered_by_emerging_technologies.md)

- [Safety Alignment for Vision Language Models](2024年05月22日/Safety_Alignment_for_Vision_Language_Models.md)

    - [翻译: 视觉语言模型的安全对齐研究](2024年05月22日/Safety_Alignment_for_Vision_Language_Models.md)

- [ConTrans: Weak-to-Strong Alignment Engineering via Concept Transplantation](2024年05月22日/ConTrans_Weak-to-Strong_Alignment_Engineering_via_Concept_Transplantation.md)

    - [翻译: ConTrans：借助概念移植，实现从弱到强的对齐工程优化](2024年05月22日/ConTrans_Weak-to-Strong_Alignment_Engineering_via_Concept_Transplantation.md)

- [FlashRAG: A Modular Toolkit for Efficient Retrieval-Augmented Generation Research](2024年05月22日/FlashRAG_A_Modular_Toolkit_for_Efficient_Retrieval-Augmented_Generation_Research.md)

    - [翻译: FlashRAG：高效检索增强生成研究的模块化利器](2024年05月22日/FlashRAG_A_Modular_Toolkit_for_Efficient_Retrieval-Augmented_Generation_Research.md)

- [AI-Assisted Assessment of Coding Practices in Modern Code Review](2024年05月22日/AI-Assisted_Assessment_of_Coding_Practices_in_Modern_Code_Review.md)

    - [翻译: AI助力现代代码审查中的编码实践评估](2024年05月22日/AI-Assisted_Assessment_of_Coding_Practices_in_Modern_Code_Review.md)

- [Navigating User Experience of ChatGPT-based Conversational Recommender Systems: The Effects of Prompt Guidance and Recommendation Domain](2024年05月22日/Navigating_User_Experience_of_ChatGPT-based_Conversational_Recommender_Systems_The_Effects_of_Prompt_Guidance_and_Recommendation_Domain.md)

    - [翻译: 探索基于ChatGPT的对话推荐系统用户体验：提示引导与推荐领域之影响](2024年05月22日/Navigating_User_Experience_of_ChatGPT-based_Conversational_Recommender_Systems_The_Effects_of_Prompt_Guidance_and_Recommendation_Domain.md)

- [Large Language Models are Effective Priors for Causal Graph Discovery](2024年05月22日/Large_Language_Models_are_Effective_Priors_for_Causal_Graph_Discovery.md)

    - [翻译: 大型语言模型作为因果图发现的先验，展现出其有效性。](2024年05月22日/Large_Language_Models_are_Effective_Priors_for_Causal_Graph_Discovery.md)

- [ECLIPSE: Semantic Entropy-LCS for Cross-Lingual Industrial Log Parsing](2024年05月22日/ECLIPSE_Semantic_Entropy-LCS_for_Cross-Lingual_Industrial_Log_Parsing.md)

    - [翻译: ECLIPSE：跨语言工业日志解析的语义熵-最长公共子序列方法](2024年05月22日/ECLIPSE_Semantic_Entropy-LCS_for_Cross-Lingual_Industrial_Log_Parsing.md)

- [HighwayLLM: Decision-Making and Navigation in Highway Driving with RL-Informed Language Model](2024年05月22日/HighwayLLM_Decision-Making_and_Navigation_in_Highway_Driving_with_RL-Informed_Language_Model.md)

    - [翻译: HighwayLLM：借助强化学习启发的语言模型，实现高速公路驾驶中的智能决策与导航](2024年05月22日/HighwayLLM_Decision-Making_and_Navigation_in_Highway_Driving_with_RL-Informed_Language_Model.md)

- [Annotation-Efficient Preference Optimization for Language Model Alignment](2024年05月22日/Annotation-Efficient_Preference_Optimization_for_Language_Model_Alignment.md)

    - [翻译: 优化语言模型偏好：高效注释策略](2024年05月22日/Annotation-Efficient_Preference_Optimization_for_Language_Model_Alignment.md)

- [PerSense: Personalized Instance Segmentation in Dense Images](2024年05月22日/PerSense_Personalized_Instance_Segmentation_in_Dense_Images.md)

    - [翻译: PerSense：密集图像中的个性化实例分割技术](2024年05月22日/PerSense_Personalized_Instance_Segmentation_in_Dense_Images.md)

- [WaterPool: A Watermark Mitigating Trade-offs among Imperceptibility, Efficacy and Robustness](2024年05月22日/WaterPool_A_Watermark_Mitigating_Trade-offs_among_Imperceptibility,_Efficacy_and_Robustness.md)

    - [翻译: WaterPool：平衡水印的隐秘性、效能与稳健性的创新方案](2024年05月22日/WaterPool_A_Watermark_Mitigating_Trade-offs_among_Imperceptibility,_Efficacy_and_Robustness.md)

- [LIRE: listwise reward enhancement for preference alignment](2024年05月22日/LIRE_listwise_reward_enhancement_for_preference_alignment.md)

    - [翻译: LIRE：通过列表级奖励增强优化偏好对齐](2024年05月22日/LIRE_listwise_reward_enhancement_for_preference_alignment.md)

- [Adapting Multi-modal Large Language Model to Concept Drift in the Long-tailed Open World](2024年05月22日/Adapting_Multi-modal_Large_Language_Model_to_Concept_Drift_in_the_Long-tailed_Open_World.md)

    - [翻译: 多模态大型语言模型在长尾开放世界中应对概念漂移的适应性调整](2024年05月22日/Adapting_Multi-modal_Large_Language_Model_to_Concept_Drift_in_the_Long-tailed_Open_World.md)

- [Distilling Instruction-following Abilities of Large Language Models with Task-aware Curriculum Planning](2024年05月22日/Distilling_Instruction-following_Abilities_of_Large_Language_Models_with_Task-aware_Curriculum_Planning.md)

    - [翻译: 利用任务感知的课程规划，精炼大型语言模型的指令遵循能力](2024年05月22日/Distilling_Instruction-following_Abilities_of_Large_Language_Models_with_Task-aware_Curriculum_Planning.md)

- [Disperse-Then-Merge: Pushing the Limits of Instruction Tuning via Alignment Tax Reduction](2024年05月22日/Disperse-Then-Merge_Pushing_the_Limits_of_Instruction_Tuning_via_Alignment_Tax_Reduction.md)

    - [翻译: 分散再融合：通过降低对齐成本，拓展指令调优的边界](2024年05月22日/Disperse-Then-Merge_Pushing_the_Limits_of_Instruction_Tuning_via_Alignment_Tax_Reduction.md)

- [TrojanRAG: Retrieval-Augmented Generation Can Be Backdoor Driver in Large Language Models](2024年05月22日/TrojanRAG_Retrieval-Augmented_Generation_Can_Be_Backdoor_Driver_in_Large_Language_Models.md)

    - [翻译: TrojanRAG：大型语言模型中的检索增强生成可能潜藏后门风险](2024年05月22日/TrojanRAG_Retrieval-Augmented_Generation_Can_Be_Backdoor_Driver_in_Large_Language_Models.md)

- [Unsupervised Pre-training with Language-Vision Prompts for Low-Data Instance Segmentation](2024年05月22日/Unsupervised_Pre-training_with_Language-Vision_Prompts_for_Low-Data_Instance_Segmentation.md)

    - [翻译: 借助语言-视觉提示，实现低数据场景下的实例分割无监督预训练](2024年05月22日/Unsupervised_Pre-training_with_Language-Vision_Prompts_for_Low-Data_Instance_Segmentation.md)

- [VTG-LLM: Integrating Timestamp Knowledge into Video LLMs for Enhanced Video Temporal Grounding](2024年05月22日/VTG-LLM_Integrating_Timestamp_Knowledge_into_Video_LLMs_for_Enhanced_Video_Temporal_Grounding.md)

    - [翻译: VTG-LLM：融合时间戳知识于视频LLMs，提升视频时间定位能力](2024年05月22日/VTG-LLM_Integrating_Timestamp_Knowledge_into_Video_LLMs_for_Enhanced_Video_Temporal_Grounding.md)

- [Lusifer: LLM-based User SImulated Feedback Environment for online Recommender systems](2024年05月22日/Lusifer_LLM-based_User_SImulated_Feedback_Environment_for_online_Recommender_systems.md)

    - [翻译: Lusifer：大型语言模型驱动的用户模拟反馈环境，专为在线推荐系统设计](2024年05月22日/Lusifer_LLM-based_User_SImulated_Feedback_Environment_for_online_Recommender_systems.md)

- [AdpQ: A Zero-shot Calibration Free Adaptive Post Training Quantization Method for LLMs](2024年05月22日/AdpQ_A_Zero-shot_Calibration_Free_Adaptive_Post_Training_Quantization_Method_for_LLMs.md)

    - [翻译: AdpQ：大型语言模型无需校准的零-shot自适应后训练量化新方法](2024年05月22日/AdpQ_A_Zero-shot_Calibration_Free_Adaptive_Post_Training_Quantization_Method_for_LLMs.md)

- [Large Language Models (LLMs) Assisted Wireless Network Deployment in Urban Settings](2024年05月22日/Large_Language_Models_(LLMs)_Assisted_Wireless_Network_Deployment_in_Urban_Settings.md)

    - [翻译: 城市环境中，大型语言模型（LLMs）助力无线网络部署，本研究探讨了 LLMs 如何优化网络布局，提升城市通信效率。](2024年05月22日/Large_Language_Models_(LLMs)_Assisted_Wireless_Network_Deployment_in_Urban_Settings.md)

- [SIGGesture: Generalized Co-Speech Gesture Synthesis via Semantic Injection with Large-Scale Pre-Training Diffusion Models](2024年05月22日/SIGGesture_Generalized_Co-Speech_Gesture_Synthesis_via_Semantic_Injection_with_Large-Scale_Pre-Training_Diffusion_Models.md)

    - [翻译: SIGGesture：借助大规模预训练扩散模型注入语义，实现通用共语手势的合成](2024年05月22日/SIGGesture_Generalized_Co-Speech_Gesture_Synthesis_via_Semantic_Injection_with_Large-Scale_Pre-Training_Diffusion_Models.md)

- [Mosaic IT: Enhancing Instruction Tuning with Data Mosaics](2024年05月22日/Mosaic_IT_Enhancing_Instruction_Tuning_with_Data_Mosaics.md)

    - [翻译: Mosaic IT：通过数据马赛克提升指令调优效果](2024年05月22日/Mosaic_IT_Enhancing_Instruction_Tuning_with_Data_Mosaics.md)

- [xRAG: Extreme Context Compression for Retrieval-augmented Generation with One Token](2024年05月22日/xRAG_Extreme_Context_Compression_for_Retrieval-augmented_Generation_with_One_Token.md)

    - [翻译: xRAG：单令牌驱动，极致压缩上下文，助力检索增强生成](2024年05月22日/xRAG_Extreme_Context_Compression_for_Retrieval-augmented_Generation_with_One_Token.md)

- [ALI-Agent: Assessing LLMs' Alignment with Human Values via Agent-based Evaluation](2024年05月22日/ALI-Agent_Assessing_LLMs'_Alignment_with_Human_Values_via_Agent-based_Evaluation.md)

    - [翻译: ALI-Agent：基于代理评估大型语言模型与人类价值观的契合度](2024年05月22日/ALI-Agent_Assessing_LLMs'_Alignment_with_Human_Values_via_Agent-based_Evaluation.md)

- [ChatScene: Knowledge-Enabled Safety-Critical Scenario Generation for Autonomous Vehicles](2024年05月22日/ChatScene_Knowledge-Enabled_Safety-Critical_Scenario_Generation_for_Autonomous_Vehicles.md)

    - [翻译: ChatScene：赋能自动驾驶车辆，打造知识驱动的安全关键场景生成](2024年05月22日/ChatScene_Knowledge-Enabled_Safety-Critical_Scenario_Generation_for_Autonomous_Vehicles.md)

- [On the Brittle Foundations of ReAct Prompting for Agentic Large Language Models](2024年05月22日/On_the_Brittle_Foundations_of_ReAct_Prompting_for_Agentic_Large_Language_Models.md)

    - [翻译: 代理型大型语言模型中ReAct提示的基础尚显脆弱](2024年05月22日/On_the_Brittle_Foundations_of_ReAct_Prompting_for_Agentic_Large_Language_Models.md)

- [TOPA: Extend Large Language Models for Video Understanding via Text-Only Pre-Alignment](2024年05月22日/TOPA_Extend_Large_Language_Models_for_Video_Understanding_via_Text-Only_Pre-Alignment.md)

    - [翻译: TOPA：借助文本预对齐技术，扩展大型语言模型以增强视频理解能力](2024年05月22日/TOPA_Extend_Large_Language_Models_for_Video_Understanding_via_Text-Only_Pre-Alignment.md)

- [Imagery as Inquiry: Exploring A Multimodal Dataset for Conversational Recommendation](2024年05月22日/Imagery_as_Inquiry_Exploring_A_Multimodal_Dataset_for_Conversational_Recommendation.md)

    - [翻译: 图像探究：深入多模态数据集，助力对话推荐研究](2024年05月22日/Imagery_as_Inquiry_Exploring_A_Multimodal_Dataset_for_Conversational_Recommendation.md)

- [AlignGPT: Multi-modal Large Language Models with Adaptive Alignment Capability](2024年05月22日/AlignGPT_Multi-modal_Large_Language_Models_with_Adaptive_Alignment_Capability.md)

    - [翻译: AlignGPT：一款具备自适应对齐功能的多模态大型语言模型，能够灵活适应不同模态间的信息对齐需求。](2024年05月22日/AlignGPT_Multi-modal_Large_Language_Models_with_Adaptive_Alignment_Capability.md)

- [A New Era in Human Factors Engineering: A Survey of the Applications and Prospects of Large Multimodal Models](2024年05月22日/A_New_Era_in_Human_Factors_Engineering_A_Survey_of_the_Applications_and_Prospects_of_Large_Multimodal_Models.md)

    - [翻译: 人类因素工程迈入新时代：探索大型多模态模型的应用与未来展望](2024年05月22日/A_New_Era_in_Human_Factors_Engineering_A_Survey_of_the_Applications_and_Prospects_of_Large_Multimodal_Models.md)

- [AutoCoder: Enhancing Code Large Language Model with \textsc{AIEV-Instruct}](2024年05月22日/AutoCoder_Enhancing_Code_Large_Language_Model_with_\textsc{AIEV-Instruct}.md)

    - [翻译: AutoCoder：借助 \textsc{AIEV-Instruct} 提升大型语言模型的编程能力](2024年05月22日/AutoCoder_Enhancing_Code_Large_Language_Model_with_\textsc{AIEV-Instruct}.md)

- [Integrating Medical Imaging and Clinical Reports Using Multimodal Deep Learning for Advanced Disease Analysis](2024年05月22日/Integrating_Medical_Imaging_and_Clinical_Reports_Using_Multimodal_Deep_Learning_for_Advanced_Disease_Analysis.md)

    - [翻译: 借助多模态深度学习，我们将医学影像与临床报告融合，以深入分析疾病，探索更深层次的医疗洞察。](2024年05月22日/Integrating_Medical_Imaging_and_Clinical_Reports_Using_Multimodal_Deep_Learning_for_Advanced_Disease_Analysis.md)

- [A Comprehensive Survey on Evaluating Large Language Model Applications in the Medical Industry](2024年05月22日/A_Comprehensive_Survey_on_Evaluating_Large_Language_Model_Applications_in_the_Medical_Industry.md)

    - [翻译: 医疗行业大型语言模型应用评估综述](2024年05月22日/A_Comprehensive_Survey_on_Evaluating_Large_Language_Model_Applications_in_the_Medical_Industry.md)

2024年05月21日

- [Reducing Transformer Key-Value Cache Size with Cross-Layer Attention](2024年05月21日/Reducing_Transformer_Key-Value_Cache_Size_with_Cross-Layer_Attention.md)

    - [翻译: 利用跨层注意力优化Transformer键值缓存尺寸](2024年05月21日/Reducing_Transformer_Key-Value_Cache_Size_with_Cross-Layer_Attention.md)

- [BiomedParse: a biomedical foundation model for image parsing of everything everywhere all at once](2024年05月21日/BiomedParse_a_biomedical_foundation_model_for_image_parsing_of_everything_everywhere_all_at_once.md)

    - [翻译: BiomedParse：一款生物医学领域的全能图像解析基础模型，实现万物一瞬解析。](2024年05月21日/BiomedParse_a_biomedical_foundation_model_for_image_parsing_of_everything_everywhere_all_at_once.md)

- [Energy Rank Alignment: Using Preference Optimization to Search Chemical Space at Scale](2024年05月21日/Energy_Rank_Alignment_Using_Preference_Optimization_to_Search_Chemical_Space_at_Scale.md)

    - [翻译: 能量秩对齐：通过偏好优化，我们在广阔的化学空间中探索新领域。](2024年05月21日/Energy_Rank_Alignment_Using_Preference_Optimization_to_Search_Chemical_Space_at_Scale.md)

- [Aggregation of Reasoning: A Hierarchical Framework for Enhancing Answer Selection in Large Language Models](2024年05月21日/Aggregation_of_Reasoning_A_Hierarchical_Framework_for_Enhancing_Answer_Selection_in_Large_Language_Models.md)

    - [翻译: 推理聚合：构建层次框架，提升大型语言模型答案选择的精准度](2024年05月21日/Aggregation_of_Reasoning_A_Hierarchical_Framework_for_Enhancing_Answer_Selection_in_Large_Language_Models.md)

- [Skin-in-the-Game: Decision Making via Multi-Stakeholder Alignment in LLMs](2024年05月21日/Skin-in-the-Game_Decision_Making_via_Multi-Stakeholder_Alignment_in_LLMs.md)

    - [翻译: 利益共担：在大型语言模型中通过多方利益协调实现决策](2024年05月21日/Skin-in-the-Game_Decision_Making_via_Multi-Stakeholder_Alignment_in_LLMs.md)

- [Code-mixed Sentiment and Hate-speech Prediction](2024年05月21日/Code-mixed_Sentiment_and_Hate-speech_Prediction.md)

    - [翻译: 混合编码情感与仇恨言论识别](2024年05月21日/Code-mixed_Sentiment_and_Hate-speech_Prediction.md)

- [Streamlining Software Reviews: Efficient Predictive Modeling with Minimal Examples](2024年05月21日/Streamlining_Software_Reviews_Efficient_Predictive_Modeling_with_Minimal_Examples.md)

    - [翻译: 精简软件评审：以极简示例实现高效预测建模](2024年05月21日/Streamlining_Software_Reviews_Efficient_Predictive_Modeling_with_Minimal_Examples.md)

- [G-DIG: Towards Gradient-based DIverse and hiGh-quality Instruction Data Selection for Machine Translation](2024年05月21日/G-DIG_Towards_Gradient-based_DIverse_and_hiGh-quality_Instruction_Data_Selection_for_Machine_Translation.md)

    - [翻译: G-DIG：探索基于梯度的方法，以实现机器翻译中多样化且高质量的指令数据选择](2024年05月21日/G-DIG_Towards_Gradient-based_DIverse_and_hiGh-quality_Instruction_Data_Selection_for_Machine_Translation.md)

- [An Empirical Study and Analysis of Text-to-Image Generation Using Large Language Model-Powered Textual Representation](2024年05月21日/An_Empirical_Study_and_Analysis_of_Text-to-Image_Generation_Using_Large_Language_Model-Powered_Textual_Representation.md)

    - [翻译: 大型语言模型驱动文本表示在文本到图像生成中的实证研究与分析](2024年05月21日/An_Empirical_Study_and_Analysis_of_Text-to-Image_Generation_Using_Large_Language_Model-Powered_Textual_Representation.md)

- [Topic Modelling Case Law Using a Large Language Model and a New Taxonomy for UK Law: AI Insights into Summary Judgment](2024年05月21日/Topic_Modelling_Case_Law_Using_a_Large_Language_Model_and_a_New_Taxonomy_for_UK_Law_AI_Insights_into_Summary_Judgment.md)

    - [翻译: 借助大型语言模型与英国法律新分类法，探索案例法律主题建模：人工智能视角下的简易判决解析](2024年05月21日/Topic_Modelling_Case_Law_Using_a_Large_Language_Model_and_a_New_Taxonomy_for_UK_Law_AI_Insights_into_Summary_Judgment.md)

- [Adversarial DPO: Harnessing Harmful Data for Reducing Toxicity with Minimal Impact on Coherence and Evasiveness in Dialogue Agents](2024年05月21日/Adversarial_DPO_Harnessing_Harmful_Data_for_Reducing_Toxicity_with_Minimal_Impact_on_Coherence_and_Evasiveness_in_Dialogue_Agents.md)

    - [翻译: 对抗性DPO策略：巧妙利用有害数据，以最小化对对话代理连贯性和逃避性的影响，有效降低其毒性。](2024年05月21日/Adversarial_DPO_Harnessing_Harmful_Data_for_Reducing_Toxicity_with_Minimal_Impact_on_Coherence_and_Evasiveness_in_Dialogue_Agents.md)

- [Investigating Persuasion Techniques in Arabic: An Empirical Study Leveraging Large Language Models](2024年05月21日/Investigating_Persuasion_Techniques_in_Arabic_An_Empirical_Study_Leveraging_Large_Language_Models.md)

    - [翻译: 探索阿拉伯语中的说服艺术：一项基于大型语言模型的实证研究](2024年05月21日/Investigating_Persuasion_Techniques_in_Arabic_An_Empirical_Study_Leveraging_Large_Language_Models.md)

- [LLM Processes: Numerical Predictive Distributions Conditioned on Natural Language](2024年05月21日/LLM_Processes_Numerical_Predictive_Distributions_Conditioned_on_Natural_Language.md)

    - [翻译: 大型语言模型处理：自然语言条件下的数值预测分布](2024年05月21日/LLM_Processes_Numerical_Predictive_Distributions_Conditioned_on_Natural_Language.md)

- [OpenCarbonEval: A Unified Carbon Emission Estimation Framework in Large-Scale AI Models](2024年05月21日/OpenCarbonEval_A_Unified_Carbon_Emission_Estimation_Framework_in_Large-Scale_AI_Models.md)

    - [翻译: OpenCarbonEval：大型AI模型中的统一碳排放评估框架](2024年05月21日/OpenCarbonEval_A_Unified_Carbon_Emission_Estimation_Framework_in_Large-Scale_AI_Models.md)

- [SmartFlow: Robotic Process Automation using LLMs](2024年05月21日/SmartFlow_Robotic_Process_Automation_using_LLMs.md)

    - [翻译: 智能流：借助大型语言模型实现机器人流程自动化](2024年05月21日/SmartFlow_Robotic_Process_Automation_using_LLMs.md)

- [Large Language Models Meet NLP: A Survey](2024年05月21日/Large_Language_Models_Meet_NLP_A_Survey.md)

    - [翻译: 大型语言模型与NLP的交汇：一份综述](2024年05月21日/Large_Language_Models_Meet_NLP_A_Survey.md)

- [Transformer in Touch: A Survey](2024年05月21日/Transformer_in_Touch_A_Survey.md)

    - [翻译: 《触碰 Transformer：综述》](2024年05月21日/Transformer_in_Touch_A_Survey.md)

- [Test Oracle Automation in the era of LLMs](2024年05月21日/Test_Oracle_Automation_in_the_era_of_LLMs.md)

    - [翻译: 大型语言模型时代中的测试预言自动化探索](2024年05月21日/Test_Oracle_Automation_in_the_era_of_LLMs.md)

- [C3L: Content Correlated Vision-Language Instruction Tuning Data Generation via Contrastive Learning](2024年05月21日/C3L_Content_Correlated_Vision-Language_Instruction_Tuning_Data_Generation_via_Contrastive_Learning.md)

    - [翻译: C3L：借助对比学习，打造内容关联的视觉-语言指令调优数据生成方法](2024年05月21日/C3L_Content_Correlated_Vision-Language_Instruction_Tuning_Data_Generation_via_Contrastive_Learning.md)

- [Generative AI and Large Language Models for Cyber Security: All Insights You Need](2024年05月21日/Generative_AI_and_Large_Language_Models_for_Cyber_Security_All_Insights_You_Need.md)

    - [翻译: 探索生成式AI与大型语言模型在网络安全领域的深度应用：一网打尽您所需的所有洞见。](2024年05月21日/Generative_AI_and_Large_Language_Models_for_Cyber_Security_All_Insights_You_Need.md)

- [SPO: Multi-Dimensional Preference Sequential Alignment With Implicit Reward Modeling](2024年05月21日/SPO_Multi-Dimensional_Preference_Sequential_Alignment_With_Implicit_Reward_Modeling.md)

    - [翻译: SPO：隐式奖励建模下的多维偏好序列对齐](2024年05月21日/SPO_Multi-Dimensional_Preference_Sequential_Alignment_With_Implicit_Reward_Modeling.md)

- [RecGPT: Generative Pre-training for Text-based Recommendation](2024年05月21日/RecGPT_Generative_Pre-training_for_Text-based_Recommendation.md)

    - [翻译: RecGPT：文本推荐领域的生成式预训练新篇章](2024年05月21日/RecGPT_Generative_Pre-training_for_Text-based_Recommendation.md)

- [Multimodal Adaptive Inference for Document Image Classification with Anytime Early Exiting](2024年05月21日/Multimodal_Adaptive_Inference_for_Document_Image_Classification_with_Anytime_Early_Exiting.md)

    - [翻译: 文档图像分类中的多模态自适应推理：随时早期退出策略的应用](2024年05月21日/Multimodal_Adaptive_Inference_for_Document_Image_Classification_with_Anytime_Early_Exiting.md)

- [OLAPH: Improving Factuality in Biomedical Long-form Question Answering](2024年05月21日/OLAPH_Improving_Factuality_in_Biomedical_Long-form_Question_Answering.md)

    - [翻译: OLAPH：提升生物医学长篇问答的事实性](2024年05月21日/OLAPH_Improving_Factuality_in_Biomedical_Long-form_Question_Answering.md)

- [Retrieval-Augmented Language Model for Extreme Multi-Label Knowledge Graph Link Prediction](2024年05月21日/Retrieval-Augmented_Language_Model_for_Extreme_Multi-Label_Knowledge_Graph_Link_Prediction.md)

    - [翻译: 检索增强型语言模型：应对极端多标签知识图谱链接预测挑战](2024年05月21日/Retrieval-Augmented_Language_Model_for_Extreme_Multi-Label_Knowledge_Graph_Link_Prediction.md)

- [Fight Fire with Fire: How Much Can We Trust ChatGPT on Source Code-Related Tasks?](2024年05月21日/Fight_Fire_with_Fire_How_Much_Can_We_Trust_ChatGPT_on_Source_Code-Related_Tasks.md)

    - [翻译: 以火攻火：ChatGPT 在源代码任务上的可信度究竟有多高？](2024年05月21日/Fight_Fire_with_Fire_How_Much_Can_We_Trust_ChatGPT_on_Source_Code-Related_Tasks.md)

- [Exploration of Masked and Causal Language Modelling for Text Generation](2024年05月21日/Exploration_of_Masked_and_Causal_Language_Modelling_for_Text_Generation.md)

    - [翻译: 探究掩码与因果语言建模在文本生成领域的应用](2024年05月21日/Exploration_of_Masked_and_Causal_Language_Modelling_for_Text_Generation.md)

- [Quantifying Emergence in Large Language Models](2024年05月21日/Quantifying_Emergence_in_Large_Language_Models.md)

    - [翻译: 探究大型语言模型中涌现现象的量化方法](2024年05月21日/Quantifying_Emergence_in_Large_Language_Models.md)

- [Tagengo: A Multilingual Chat Dataset](2024年05月21日/Tagengo_A_Multilingual_Chat_Dataset.md)

    - [翻译: Tagengo：多语言聊天数据集](2024年05月21日/Tagengo_A_Multilingual_Chat_Dataset.md)

- [Tiny Refinements Elicit Resilience: Toward Efficient Prefix-Model Against LLM Red-Teaming](2024年05月21日/Tiny_Refinements_Elicit_Resilience_Toward_Efficient_Prefix-Model_Against_LLM_Red-Teaming.md)

    - [翻译: 细微调整，韧性倍增：探索高效前缀模型，抵御大型语言模型红队挑战](2024年05月21日/Tiny_Refinements_Elicit_Resilience_Toward_Efficient_Prefix-Model_Against_LLM_Red-Teaming.md)

- [Unlocking Data-free Low-bit Quantization with Matrix Decomposition for KV Cache Compression](2024年05月21日/Unlocking_Data-free_Low-bit_Quantization_with_Matrix_Decomposition_for_KV_Cache_Compression.md)

    - [翻译: 利用矩阵分解技术，实现无需原始数据支持的低比特量化，以优化KV缓存压缩效率](2024年05月21日/Unlocking_Data-free_Low-bit_Quantization_with_Matrix_Decomposition_for_KV_Cache_Compression.md)

- [Is Dataset Quality Still a Concern in Diagnosis Using Large Foundation Model?](2024年05月21日/Is_Dataset_Quality_Still_a_Concern_in_Diagnosis_Using_Large_Foundation_Model.md)

    - [翻译: 大型基础模型在诊断应用中，数据集质量是否仍是心头之患？](2024年05月21日/Is_Dataset_Quality_Still_a_Concern_in_Diagnosis_Using_Large_Foundation_Model.md)

- [ProtT3: Protein-to-Text Generation for Text-based Protein Understanding](2024年05月21日/ProtT3_Protein-to-Text_Generation_for_Text-based_Protein_Understanding.md)

    - [翻译: ProtT3：蛋白质至文本生成，助力基于文本的蛋白质理解](2024年05月21日/ProtT3_Protein-to-Text_Generation_for_Text-based_Protein_Understanding.md)

- [DrHouse: An LLM-empowered Diagnostic Reasoning System through Harnessing Outcomes from Sensor Data and Expert Knowledge](2024年05月21日/DrHouse_An_LLM-empowered_Diagnostic_Reasoning_System_through_Harnessing_Outcomes_from_Sensor_Data_and_Expert_Knowledge.md)

    - [翻译: DrHouse：结合传感器数据与专家知识，由LLM驱动的智能诊断推理系统](2024年05月21日/DrHouse_An_LLM-empowered_Diagnostic_Reasoning_System_through_Harnessing_Outcomes_from_Sensor_Data_and_Expert_Knowledge.md)

- [Context-Enhanced Video Moment Retrieval with Large Language Models](2024年05月21日/Context-Enhanced_Video_Moment_Retrieval_with_Large_Language_Models.md)

    - [翻译: 大型语言模型助力上下文增强的视频时刻检索](2024年05月21日/Context-Enhanced_Video_Moment_Retrieval_with_Large_Language_Models.md)

- [PyramidInfer: Pyramid KV Cache Compression for High-throughput LLM Inference](2024年05月21日/PyramidInfer_Pyramid_KV_Cache_Compression_for_High-throughput_LLM_Inference.md)

    - [翻译: PyramidInfer：高效 LLM 推理的 Pyramid KV 缓存压缩技术](2024年05月21日/PyramidInfer_Pyramid_KV_Cache_Compression_for_High-throughput_LLM_Inference.md)

- [SirLLM: Streaming Infinite Retentive LLM](2024年05月21日/SirLLM_Streaming_Infinite_Retentive_LLM.md)

    - [翻译: SirLLM：大型语言模型的流式无限记忆技术](2024年05月21日/SirLLM_Streaming_Infinite_Retentive_LLM.md)

- [Single Image Unlearning: Efficient Machine Unlearning in Multimodal Large Language Models](2024年05月21日/Single_Image_Unlearning_Efficient_Machine_Unlearning_in_Multimodal_Large_Language_Models.md)

    - [翻译: 单图遗忘术：多模态大语言模型中的高效遗忘机制](2024年05月21日/Single_Image_Unlearning_Efficient_Machine_Unlearning_in_Multimodal_Large_Language_Models.md)

- [Sparse Autoencoders Enable Scalable and Reliable Circuit Identification in Language Models](2024年05月21日/Sparse_Autoencoders_Enable_Scalable_and_Reliable_Circuit_Identification_in_Language_Models.md)

    - [翻译: 稀疏自编码器为语言模型中的电路识别提供了可扩展且可靠的解决方案。](2024年05月21日/Sparse_Autoencoders_Enable_Scalable_and_Reliable_Circuit_Identification_in_Language_Models.md)

- [Time Matters: Enhancing Pre-trained News Recommendation Models with Robust User Dwell Time Injection](2024年05月21日/Time_Matters_Enhancing_Pre-trained_News_Recommendation_Models_with_Robust_User_Dwell_Time_Injection.md)

    - [翻译: 时间因素不容忽视：强化预训练新闻推荐模型，引入用户停留时间的稳健注入](2024年05月21日/Time_Matters_Enhancing_Pre-trained_News_Recommendation_Models_with_Robust_User_Dwell_Time_Injection.md)

- [Diffusion-RSCC: Diffusion Probabilistic Model for Change Captioning in Remote Sensing Images](2024年05月21日/Diffusion-RSCC_Diffusion_Probabilistic_Model_for_Change_Captioning_in_Remote_Sensing_Images.md)

    - [翻译: 扩散-RSCC：遥感图像变化描述的扩散概率模型](2024年05月21日/Diffusion-RSCC_Diffusion_Probabilistic_Model_for_Change_Captioning_in_Remote_Sensing_Images.md)

- [Weakly supervised alignment and registration of MR-CT for cervical cancer radiotherapy](2024年05月21日/Weakly_supervised_alignment_and_registration_of_MR-CT_for_cervical_cancer_radiotherapy.md)

    - [翻译: 宫颈癌放疗中，通过弱监督方法实现MR与CT图像的对齐与注册。](2024年05月21日/Weakly_supervised_alignment_and_registration_of_MR-CT_for_cervical_cancer_radiotherapy.md)

- [A Survey of Robotic Language Grounding: Tradeoffs Between Symbols and Embeddings](2024年05月21日/A_Survey_of_Robotic_Language_Grounding_Tradeoffs_Between_Symbols_and_Embeddings.md)

    - [翻译: 机器人语言基础研究综述：探讨符号与嵌入之间的取舍](2024年05月21日/A_Survey_of_Robotic_Language_Grounding_Tradeoffs_Between_Symbols_and_Embeddings.md)

- [Dataset Decomposition: Faster LLM Training with Variable Sequence Length Curriculum](2024年05月21日/Dataset_Decomposition_Faster_LLM_Training_with_Variable_Sequence_Length_Curriculum.md)

    - [翻译: 数据集分解：利用可变序列长度课程加速大型语言模型训练](2024年05月21日/Dataset_Decomposition_Faster_LLM_Training_with_Variable_Sequence_Length_Curriculum.md)

- [How Reliable AI Chatbots are for Disease Prediction from Patient Complaints?](2024年05月21日/How_Reliable_AI_Chatbots_are_for_Disease_Prediction_from_Patient_Complaints.md)

    - [翻译: 人工智能聊天机器人在从患者投诉中预测疾病方面的可靠性如何？](2024年05月21日/How_Reliable_AI_Chatbots_are_for_Disease_Prediction_from_Patient_Complaints.md)

- [Equipping Transformer with Random-Access Reading for Long-Context Understanding](2024年05月21日/Equipping_Transformer_with_Random-Access_Reading_for_Long-Context_Understanding.md)

    - [翻译: 赋予Transformer随机访问阅读能力，深化长上下文理解](2024年05月21日/Equipping_Transformer_with_Random-Access_Reading_for_Long-Context_Understanding.md)

- [Investigating Symbolic Capabilities of Large Language Models](2024年05月21日/Investigating_Symbolic_Capabilities_of_Large_Language_Models.md)

    - [翻译: 探究大型语言模型的符号处理能力](2024年05月21日/Investigating_Symbolic_Capabilities_of_Large_Language_Models.md)

- [Identity-free Artificial Emotional Intelligence via Micro-Gesture Understanding](2024年05月21日/Identity-free_Artificial_Emotional_Intelligence_via_Micro-Gesture_Understanding.md)

    - [翻译: 微动作理解驱动的匿名人工情感智能](2024年05月21日/Identity-free_Artificial_Emotional_Intelligence_via_Micro-Gesture_Understanding.md)

- [Modeling Real-Time Interactive Conversations as Timed Diarized Transcripts](2024年05月21日/Modeling_Real-Time_Interactive_Conversations_as_Timed_Diarized_Transcripts.md)

    - [翻译: 实时互动对话的建模：时间戳标注转录文本](2024年05月21日/Modeling_Real-Time_Interactive_Conversations_as_Timed_Diarized_Transcripts.md)

- [Comparative Analysis of Different Efficient Fine Tuning Methods of Large Language Models (LLMs) in Low-Resource Setting](2024年05月21日/Comparative_Analysis_of_Different_Efficient_Fine_Tuning_Methods_of_Large_Language_Models_(LLMs)_in_Low-Resource_Setting.md)

    - [翻译: 低资源环境下，大型语言模型（LLMs）高效微调方法的比较研究](2024年05月21日/Comparative_Analysis_of_Different_Efficient_Fine_Tuning_Methods_of_Large_Language_Models_(LLMs)_in_Low-Resource_Setting.md)

- [A Workbench for Autograding Retrieve/Generate Systems](2024年05月21日/A_Workbench_for_Autograding_RetrieveGenerate_Systems.md)

    - [翻译: 检索/生成系统自动评分工作台](2024年05月21日/A_Workbench_for_Autograding_RetrieveGenerate_Systems.md)

- [RAG-RLRC-LaySum at BioLaySumm: Integrating Retrieval-Augmented Generation and Readability Control for Layman Summarization of Biomedical Texts](2024年05月21日/RAG-RLRC-LaySum_at_BioLaySumm_Integrating_Retrieval-Augmented_Generation_and_Readability_Control_for_Layman_Summarization_of_Biomedical_Texts.md)

    - [翻译: RAG-RLRC-LaySum 在 BioLaySumm 挑战中大放异彩，通过巧妙融合检索增强生成与可读性控制技术，为生物医学领域的专业文本打造出通俗易懂的摘要。](2024年05月21日/RAG-RLRC-LaySum_at_BioLaySumm_Integrating_Retrieval-Augmented_Generation_and_Readability_Control_for_Layman_Summarization_of_Biomedical_Texts.md)

- [Towards Retrieval-Augmented Architectures for Image Captioning](2024年05月21日/Towards_Retrieval-Augmented_Architectures_for_Image_Captioning.md)

    - [翻译: 探索检索增强架构在图像描述生成中的应用](2024年05月21日/Towards_Retrieval-Augmented_Architectures_for_Image_Captioning.md)

- [The 2nd FutureDial Challenge: Dialog Systems with Retrieval Augmented Generation (FutureDial-RAG)](2024年05月21日/The_2nd_FutureDial_Challenge_Dialog_Systems_with_Retrieval_Augmented_Generation_(FutureDial-RAG).md)

    - [翻译: 第二届FutureDial挑战：探索检索增强生成技术在对话系统中的应用（FutureDial-RAG）](2024年05月21日/The_2nd_FutureDial_Challenge_Dialog_Systems_with_Retrieval_Augmented_Generation_(FutureDial-RAG).md)

- [Beyond Code Generation: An Observational Study of ChatGPT Usage in Software Engineering Practice](2024年05月21日/Beyond_Code_Generation_An_Observational_Study_of_ChatGPT_Usage_in_Software_Engineering_Practice.md)

    - [翻译: 探索ChatGPT在软件工程实践中的多面应用：一项观察性研究](2024年05月21日/Beyond_Code_Generation_An_Observational_Study_of_ChatGPT_Usage_in_Software_Engineering_Practice.md)

2024年05月20日

- [TinyLLaVA Factory: A Modularized Codebase for Small-scale Large Multimodal Models](2024年05月20日/TinyLLaVA_Factory_A_Modularized_Codebase_for_Small-scale_Large_Multimodal_Models.md)

    - [翻译: TinyLLaVA工厂：专为小型大规模多模态模型设计的模块化代码库](2024年05月20日/TinyLLaVA_Factory_A_Modularized_Codebase_for_Small-scale_Large_Multimodal_Models.md)

- [General bounds on the quality of Bayesian coresets](2024年05月20日/General_bounds_on_the_quality_of_Bayesian_coresets.md)

    - [翻译: 贝叶斯核心集质量的通用上限](2024年05月20日/General_bounds_on_the_quality_of_Bayesian_coresets.md)

- [Rethinking Overlooked Aspects in Vision-Language Models](2024年05月20日/Rethinking_Overlooked_Aspects_in_Vision-Language_Models.md)

    - [翻译: 审视视觉-语言模型中常被忽略的维度](2024年05月20日/Rethinking_Overlooked_Aspects_in_Vision-Language_Models.md)

- [Evaluating and Modeling Social Intelligence: A Comparative Study of Human and AI Capabilities](2024年05月20日/Evaluating_and_Modeling_Social_Intelligence_A_Comparative_Study_of_Human_and_AI_Capabilities.md)

    - [翻译: 探究社会智能：人类与AI能力之比较研究](2024年05月20日/Evaluating_and_Modeling_Social_Intelligence_A_Comparative_Study_of_Human_and_AI_Capabilities.md)

- [Demo Paper: A Game Agents Battle Driven by Free-Form Text Commands Using Code-Generation LLM](2024年05月20日/Demo_Paper_A_Game_Agents_Battle_Driven_by_Free-Form_Text_Commands_Using_Code-Generation_LLM.md)

    - [翻译: 演示论文：自由格式文本命令下的游戏代理战斗——基于代码生成的大型语言模型驱动](2024年05月20日/Demo_Paper_A_Game_Agents_Battle_Driven_by_Free-Form_Text_Commands_Using_Code-Generation_LLM.md)

- [(Perhaps) Beyond Human Translation: Harnessing Multi-Agent Collaboration for Translating Ultra-Long Literary Texts](2024年05月20日/(Perhaps)_Beyond_Human_Translation_Harnessing_Multi-Agent_Collaboration_for_Translating_Ultra-Long_Literary_Texts.md)

    - [翻译: (或许)超越人类翻译：借助多代理协作，攻克超长文学文本翻译难题](2024年05月20日/(Perhaps)_Beyond_Human_Translation_Harnessing_Multi-Agent_Collaboration_for_Translating_Ultra-Long_Literary_Texts.md)

- [KG-RAG: Bridging the Gap Between Knowledge and Creativity](2024年05月20日/KG-RAG_Bridging_the_Gap_Between_Knowledge_and_Creativity.md)

    - [翻译: KG-RAG：连接知识与创意的桥梁](2024年05月20日/KG-RAG_Bridging_the_Gap_Between_Knowledge_and_Creativity.md)

- [CaseGNN++: Graph Contrastive Learning for Legal Case Retrieval with Graph Augmentation](2024年05月20日/CaseGNN++_Graph_Contrastive_Learning_for_Legal_Case_Retrieval_with_Graph_Augmentation.md)

    - [翻译: CaseGNN++：运用图增强技术的法律案例检索图对比学习](2024年05月20日/CaseGNN++_Graph_Contrastive_Learning_for_Legal_Case_Retrieval_with_Graph_Augmentation.md)

- [Eliciting Problem Specifications via Large Language Models](2024年05月20日/Eliciting_Problem_Specifications_via_Large_Language_Models.md)

    - [翻译: 借助大型语言模型揭示问题规范](2024年05月20日/Eliciting_Problem_Specifications_via_Large_Language_Models.md)

- [STYLE: Improving Domain Transferability of Asking Clarification Questions in Large Language Model Powered Conversational Agents](2024年05月20日/STYLE_Improving_Domain_Transferability_of_Asking_Clarification_Questions_in_Large_Language_Model_Powered_Conversational_Agents.md)

    - [翻译: STYLE：优化大型语言模型对话代理中提问澄清问题的跨领域应用能力](2024年05月20日/STYLE_Improving_Domain_Transferability_of_Asking_Clarification_Questions_in_Large_Language_Model_Powered_Conversational_Agents.md)

- [Adapting Large Multimodal Models to Distribution Shifts: The Role of In-Context Learning](2024年05月20日/Adapting_Large_Multimodal_Models_to_Distribution_Shifts_The_Role_of_In-Context_Learning.md)

    - [翻译: 大型多模态模型在面对分布变化时的适应性：情境学习的角色](2024年05月20日/Adapting_Large_Multimodal_Models_to_Distribution_Shifts_The_Role_of_In-Context_Learning.md)

- [Imp: Highly Capable Large Multimodal Models for Mobile Devices](2024年05月20日/Imp_Highly_Capable_Large_Multimodal_Models_for_Mobile_Devices.md)

    - [翻译: Imp：移动设备上的高效大型多模态模型](2024年05月20日/Imp_Highly_Capable_Large_Multimodal_Models_for_Mobile_Devices.md)

- [MTVQA: Benchmarking Multilingual Text-Centric Visual Question Answering](2024年05月20日/MTVQA_Benchmarking_Multilingual_Text-Centric_Visual_Question_Answering.md)

    - [翻译: MTVQA：多语言文本驱动的视觉问答基准](2024年05月20日/MTVQA_Benchmarking_Multilingual_Text-Centric_Visual_Question_Answering.md)

- [Octo: An Open-Source Generalist Robot Policy](2024年05月20日/Octo_An_Open-Source_Generalist_Robot_Policy.md)

    - [翻译: Octo：一款开源的通用机器人策略，旨在为机器人领域提供灵活且广泛适用的解决方案。](2024年05月20日/Octo_An_Open-Source_Generalist_Robot_Policy.md)

- [MathBench: Evaluating the Theory and Application Proficiency of LLMs with a Hierarchical Mathematics Benchmark](2024年05月20日/MathBench_Evaluating_the_Theory_and_Application_Proficiency_of_LLMs_with_a_Hierarchical_Mathematics_Benchmark.md)

    - [翻译: MathBench：借助层次化数学基准，评估大型语言模型在理论与应用层面的数学能力。](2024年05月20日/MathBench_Evaluating_the_Theory_and_Application_Proficiency_of_LLMs_with_a_Hierarchical_Mathematics_Benchmark.md)

- [Modeling citation worthiness by using attention-based bidirectional long short-term memory networks and interpretable models](2024年05月20日/Modeling_citation_worthiness_by_using_attention-based_bidirectional_long_short-term_memory_networks_and_interpretable_models.md)

    - [翻译: 利用基于注意力的双向长短期记忆网络与可解释模型，构建引用价值的模型](2024年05月20日/Modeling_citation_worthiness_by_using_attention-based_bidirectional_long_short-term_memory_networks_and_interpretable_models.md)

- [Developers' Perceptions on the Impact of ChatGPT in Software Development: A Survey](2024年05月20日/Developers'_Perceptions_on_the_Impact_of_ChatGPT_in_Software_Development_A_Survey.md)

    - [翻译: ChatGPT在软件开发中的影响：开发者观点调查](2024年05月20日/Developers'_Perceptions_on_the_Impact_of_ChatGPT_in_Software_Development_A_Survey.md)

- [CT-Eval: Benchmarking Chinese Text-to-Table Performance in Large Language Models](2024年05月20日/CT-Eval_Benchmarking_Chinese_Text-to-Table_Performance_in_Large_Language_Models.md)

    - [翻译: CT-Eval：大型语言模型中文文本至表格转换性能的基准评估](2024年05月20日/CT-Eval_Benchmarking_Chinese_Text-to-Table_Performance_in_Large_Language_Models.md)

- [Fennec: Fine-grained Language Model Evaluation and Correction Extended through Branching and Bridging](2024年05月20日/Fennec_Fine-grained_Language_Model_Evaluation_and_Correction_Extended_through_Branching_and_Bridging.md)

    - [翻译: Fennec：细粒度语言模型评估与修正，通过分支与桥接实现扩展](2024年05月20日/Fennec_Fine-grained_Language_Model_Evaluation_and_Correction_Extended_through_Branching_and_Bridging.md)

- [MoRA: High-Rank Updating for Parameter-Efficient Fine-Tuning](2024年05月20日/MoRA_High-Rank_Updating_for_Parameter-Efficient_Fine-Tuning.md)

    - [翻译: MoRA：一种高秩更新策略，专为高效参数微调设计](2024年05月20日/MoRA_High-Rank_Updating_for_Parameter-Efficient_Fine-Tuning.md)

- [Reindex-Then-Adapt: Improving Large Language Models for Conversational Recommendation](2024年05月20日/Reindex-Then-Adapt_Improving_Large_Language_Models_for_Conversational_Recommendation.md)

    - [翻译: 重索引再适应：优化大型语言模型于对话推荐之应用](2024年05月20日/Reindex-Then-Adapt_Improving_Large_Language_Models_for_Conversational_Recommendation.md)

- [DOP: Diagnostic-Oriented Prompting for Large Language Models in Mathematical Correction](2024年05月20日/DOP_Diagnostic-Oriented_Prompting_for_Large_Language_Models_in_Mathematical_Correction.md)

    - [翻译: DOP：大型语言模型中面向诊断的提示策略，专为数学纠错优化](2024年05月20日/DOP_Diagnostic-Oriented_Prompting_for_Large_Language_Models_in_Mathematical_Correction.md)

- [PARALLELGPUOS: A Concurrent OS-level GPU Checkpoint and Restore System using Validated Speculation](2024年05月20日/PARALLELGPUOS_A_Concurrent_OS-level_GPU_Checkpoint_and_Restore_System_using_Validated_Speculation.md)

    - [翻译: PARALLELGPUOS：基于验证推测的并发操作系统级GPU检查点与恢复系统](2024年05月20日/PARALLELGPUOS_A_Concurrent_OS-level_GPU_Checkpoint_and_Restore_System_using_Validated_Speculation.md)

- [CLAMBER: A Benchmark of Identifying and Clarifying Ambiguous Information Needs in Large Language Models](2024年05月20日/CLAMBER_A_Benchmark_of_Identifying_and_Clarifying_Ambiguous_Information_Needs_in_Large_Language_Models.md)

    - [翻译: CLAMBER：大型语言模型中模糊信息需求识别与澄清的基准测试](2024年05月20日/CLAMBER_A_Benchmark_of_Identifying_and_Clarifying_Ambiguous_Information_Needs_in_Large_Language_Models.md)

- [Can AI Relate: Testing Large Language Model Response for Mental Health Support](2024年05月20日/Can_AI_Relate_Testing_Large_Language_Model_Response_for_Mental_Health_Support.md)

    - [翻译: AI能否共情：探究大型语言模型在心理健康支持中的响应能力](2024年05月20日/Can_AI_Relate_Testing_Large_Language_Model_Response_for_Mental_Health_Support.md)

- [A review on the use of large language models as virtual tutors](2024年05月20日/A_review_on_the_use_of_large_language_models_as_virtual_tutors.md)

    - [翻译: 大型语言模型作为虚拟导师的应用综述](2024年05月20日/A_review_on_the_use_of_large_language_models_as_virtual_tutors.md)

- [Data Augmentation for Text-based Person Retrieval Using Large Language Models](2024年05月20日/Data_Augmentation_for_Text-based_Person_Retrieval_Using_Large_Language_Models.md)

    - [翻译: 利用大型语言模型增强基于文本的人物检索数据](2024年05月20日/Data_Augmentation_for_Text-based_Person_Retrieval_Using_Large_Language_Models.md)

- [Recommender Algorithm for Supporting Self-Management of CVD Risk Factors in an Adult Population at Home](2024年05月20日/Recommender_Algorithm_for_Supporting_Self-Management_of_CVD_Risk_Factors_in_an_Adult_Population_at_Home.md)

    - [翻译: 家庭环境下，助力成年人自我管理心血管疾病风险因素的智能推荐算法](2024年05月20日/Recommender_Algorithm_for_Supporting_Self-Management_of_CVD_Risk_Factors_in_an_Adult_Population_at_Home.md)

- [WisPerMed at BioLaySumm: Adapting Autoregressive Large Language Models for Lay Summarization of Scientific Articles](2024年05月20日/WisPerMed_at_BioLaySumm_Adapting_Autoregressive_Large_Language_Models_for_Lay_Summarization_of_Scientific_Articles.md)

    - [翻译: WisPerMed 在 BioLaySumm 挑战中：优化自回归大型语言模型，以生成科学文章的通俗摘要](2024年05月20日/WisPerMed_at_BioLaySumm_Adapting_Autoregressive_Large_Language_Models_for_Lay_Summarization_of_Scientific_Articles.md)

- [Data Contamination Calibration for Black-box LLMs](2024年05月20日/Data_Contamination_Calibration_for_Black-box_LLMs.md)

    - [翻译: 黑盒LLMs的数据污染校准](2024年05月20日/Data_Contamination_Calibration_for_Black-box_LLMs.md)

- ["Set It Up!": Functional Object Arrangement with Compositional Generative Models](2024年05月20日/Set_It_Up!_Functional_Object_Arrangement_with_Compositional_Generative_Models.md)

    - [翻译: "布置起来！"：利用组合生成模型进行功能性物体布局](2024年05月20日/Set_It_Up!_Functional_Object_Arrangement_with_Compositional_Generative_Models.md)

- [Information Leakage from Embedding in Large Language Models](2024年05月20日/Information_Leakage_from_Embedding_in_Large_Language_Models.md)

    - [翻译: 大型语言模型嵌入中的信息泄露](2024年05月20日/Information_Leakage_from_Embedding_in_Large_Language_Models.md)

- [Unveiling and Manipulating Prompt Influence in Large Language Models](2024年05月20日/Unveiling_and_Manipulating_Prompt_Influence_in_Large_Language_Models.md)

    - [翻译: 揭秘与操控大型语言模型中的提示效应](2024年05月20日/Unveiling_and_Manipulating_Prompt_Influence_in_Large_Language_Models.md)

- [Quantifying In-Context Reasoning Effects and Memorization Effects in LLMs](2024年05月20日/Quantifying_In-Context_Reasoning_Effects_and_Memorization_Effects_in_LLMs.md)

    - [翻译: 探究大型语言模型中上下文推理与记忆效应的量化分析](2024年05月20日/Quantifying_In-Context_Reasoning_Effects_and_Memorization_Effects_in_LLMs.md)

- [xFinder: Robust and Pinpoint Answer Extraction for Large Language Models](2024年05月20日/xFinder_Robust_and_Pinpoint_Answer_Extraction_for_Large_Language_Models.md)

    - [翻译: xFinder：大型语言模型中精准答案提取的稳健之选](2024年05月20日/xFinder_Robust_and_Pinpoint_Answer_Extraction_for_Large_Language_Models.md)

- [PLM4Traj: Cognizing Movement Patterns and Travel Purposes from Trajectories with Pre-trained Language Models](2024年05月20日/PLM4Traj_Cognizing_Movement_Patterns_and_Travel_Purposes_from_Trajectories_with_Pre-trained_Language_Models.md)

    - [翻译: PLM4Traj：借助预训练语言模型，从轨迹数据中洞察移动模式与旅行目的](2024年05月20日/PLM4Traj_Cognizing_Movement_Patterns_and_Travel_Purposes_from_Trajectories_with_Pre-trained_Language_Models.md)

- [Mutual Information Analysis in Multimodal Learning Systems](2024年05月20日/Mutual_Information_Analysis_in_Multimodal_Learning_Systems.md)

    - [翻译: 探究多模态学习系统中互信息的作用](2024年05月20日/Mutual_Information_Analysis_in_Multimodal_Learning_Systems.md)

- [PathOCL: Path-Based Prompt Augmentation for OCL Generation with GPT-4](2024年05月20日/PathOCL_Path-Based_Prompt_Augmentation_for_OCL_Generation_with_GPT-4.md)

    - [翻译: PathOCL：利用 GPT-4，通过路径增强提示，精准生成 OCL](2024年05月20日/PathOCL_Path-Based_Prompt_Augmentation_for_OCL_Generation_with_GPT-4.md)

- [Learning Structure and Knowledge Aware Representation with Large Language Models for Concept Recommendation](2024年05月20日/Learning_Structure_and_Knowledge_Aware_Representation_with_Large_Language_Models_for_Concept_Recommendation.md)

    - [翻译: 借助大型语言模型，探索结构与知识融合的表示学习，以精准推荐概念](2024年05月20日/Learning_Structure_and_Knowledge_Aware_Representation_with_Large_Language_Models_for_Concept_Recommendation.md)

- [Resolving Word Vagueness with Scenario-guided Adapter for Natural Language Inference](2024年05月20日/Resolving_Word_Vagueness_with_Scenario-guided_Adapter_for_Natural_Language_Inference.md)

    - [翻译: 借助场景引导适配器，破解自然语言推理中的词语模糊难题](2024年05月20日/Resolving_Word_Vagueness_with_Scenario-guided_Adapter_for_Natural_Language_Inference.md)

- [LLM+Reasoning+Planning for supporting incomplete user queries in presence of APIs](2024年05月20日/LLM+Reasoning+Planning_for_supporting_incomplete_user_queries_in_presence_of_APIs.md)

    - [翻译: 大型语言模型（LLM）通过推理与规划，巧妙应对API环境下用户查询的不完整性。](2024年05月20日/LLM+Reasoning+Planning_for_supporting_incomplete_user_queries_in_presence_of_APIs.md)

- [Question-Based Retrieval using Atomic Units for Enterprise RAG](2024年05月20日/Question-Based_Retrieval_using_Atomic_Units_for_Enterprise_RAG.md)

    - [翻译: 企业RAG中基于问题的检索采用原子单元进行优化](2024年05月20日/Question-Based_Retrieval_using_Atomic_Units_for_Enterprise_RAG.md)

- [Self-HWDebug: Automation of LLM Self-Instructing for Hardware Security Verification](2024年05月20日/Self-HWDebug_Automation_of_LLM_Self-Instructing_for_Hardware_Security_Verification.md)

    - [翻译: Self-HWDebug：利用LLM自我指导实现硬件安全验证的自动化](2024年05月20日/Self-HWDebug_Automation_of_LLM_Self-Instructing_for_Hardware_Security_Verification.md)

- [Directed Metric Structures arising in Large Language Models](2024年05月20日/Directed_Metric_Structures_arising_in_Large_Language_Models.md)

    - [翻译: 大规模语言模型中的定向度量结构探索](2024年05月20日/Directed_Metric_Structures_arising_in_Large_Language_Models.md)

- [Can Github issues be solved with Tree Of Thoughts?](2024年05月20日/Can_Github_issues_be_solved_with_Tree_Of_Thoughts.md)

    - [翻译: 思维树能否解开 Github 问题的谜团？](2024年05月20日/Can_Github_issues_be_solved_with_Tree_Of_Thoughts.md)

2024年05月19日

- [Inquire, Interact, and Integrate: A Proactive Agent Collaborative Framework for Zero-Shot Multimodal Medical Reasoning](2024年05月19日/Inquire,_Interact,_and_Integrate_A_Proactive_Agent_Collaborative_Framework_for_Zero-Shot_Multimodal_Medical_Reasoning.md)

    - [翻译: 主动探询、互动与融合：零-shot 多模态医学推理的协作代理框架](2024年05月19日/Inquire,_Interact,_and_Integrate_A_Proactive_Agent_Collaborative_Framework_for_Zero-Shot_Multimodal_Medical_Reasoning.md)

- [Token-wise Influential Training Data Retrieval for Large Language Models](2024年05月19日/Token-wise_Influential_Training_Data_Retrieval_for_Large_Language_Models.md)

    - [翻译: 大型语言模型中基于令牌的关键训练数据检索](2024年05月19日/Token-wise_Influential_Training_Data_Retrieval_for_Large_Language_Models.md)

- [Semantic Trajectory Data Mining with LLM-Informed POI Classification](2024年05月19日/Semantic_Trajectory_Data_Mining_with_LLM-Informed_POI_Classification.md)

    - [翻译: 基于LLM指导的POI分类的语义轨迹数据挖掘](2024年05月19日/Semantic_Trajectory_Data_Mining_with_LLM-Informed_POI_Classification.md)

- [Increasing the LLM Accuracy for Question Answering: Ontologies to the Rescue!](2024年05月19日/Increasing_the_LLM_Accuracy_for_Question_Answering_Ontologies_to_the_Rescue!.md)

    - [翻译: 借助本体论，提升大型语言模型在问答任务中的精准度！](2024年05月19日/Increasing_the_LLM_Accuracy_for_Question_Answering_Ontologies_to_the_Rescue!.md)

- [Efficiency optimization of large-scale language models based on deep learning in natural language processing tasks](2024年05月19日/Efficiency_optimization_of_large-scale_language_models_based_on_deep_learning_in_natural_language_processing_tasks.md)

    - [翻译: 深度学习驱动的大规模语言模型在自然语言处理领域的效率提升研究](2024年05月19日/Efficiency_optimization_of_large-scale_language_models_based_on_deep_learning_in_natural_language_processing_tasks.md)

- [ColorFoil: Investigating Color Blindness in Large Vision and Language Models](2024年05月19日/ColorFoil_Investigating_Color_Blindness_in_Large_Vision_and_Language_Models.md)

    - [翻译: ColorFoil：探索大型视觉与语言模型中的色觉障碍现象](2024年05月19日/ColorFoil_Investigating_Color_Blindness_in_Large_Vision_and_Language_Models.md)

- [Zero-Shot Stance Detection using Contextual Data Generation with LLMs](2024年05月19日/Zero-Shot_Stance_Detection_using_Contextual_Data_Generation_with_LLMs.md)

    - [翻译: 借助LLMs生成上下文数据，实现零-shot立场检测](2024年05月19日/Zero-Shot_Stance_Detection_using_Contextual_Data_Generation_with_LLMs.md)

- [Attention to Quantum Complexity](2024年05月19日/Attention_to_Quantum_Complexity.md)

    - [翻译: 聚焦量子复杂性之谜](2024年05月19日/Attention_to_Quantum_Complexity.md)

- [Decoding by Contrasting Knowledge: Enhancing LLMs' Confidence on Edited Facts](2024年05月19日/Decoding_by_Contrasting_Knowledge_Enhancing_LLMs'_Confidence_on_Edited_Facts.md)

    - [翻译: 对比知识解码：提升大型语言模型对编辑事实的确信度](2024年05月19日/Decoding_by_Contrasting_Knowledge_Enhancing_LLMs'_Confidence_on_Edited_Facts.md)

- [DOLLmC: DevOPs for Large Language model Customization](2024年05月19日/DOLLmC_DevOPs_for_Large_Language_model_Customization.md)

    - [翻译: DOLLmC：大型语言模型定制的开发运维方案](2024年05月19日/DOLLmC_DevOPs_for_Large_Language_model_Customization.md)

- [Exploring the Capabilities of Prompted Large Language Models in Educational and Assessment Applications](2024年05月19日/Exploring_the_Capabilities_of_Prompted_Large_Language_Models_in_Educational_and_Assessment_Applications.md)

    - [翻译: 探究大型语言模型在教育和评估领域中通过提示展现的潜能](2024年05月19日/Exploring_the_Capabilities_of_Prompted_Large_Language_Models_in_Educational_and_Assessment_Applications.md)

- [A Multi-Perspective Analysis of Memorization in Large Language Models](2024年05月19日/A_Multi-Perspective_Analysis_of_Memorization_in_Large_Language_Models.md)

    - [翻译: 大型语言模型记忆化的多维度探究](2024年05月19日/A_Multi-Perspective_Analysis_of_Memorization_in_Large_Language_Models.md)

- [Simple-Sampling and Hard-Mixup with Prototypes to Rebalance Contrastive Learning for Text Classification](2024年05月19日/Simple-Sampling_and_Hard-Mixup_with_Prototypes_to_Rebalance_Contrastive_Learning_for_Text_Classification.md)

    - [翻译: 利用原型进行简单抽样与硬混合，优化文本分类中的对比学习平衡](2024年05月19日/Simple-Sampling_and_Hard-Mixup_with_Prototypes_to_Rebalance_Contrastive_Learning_for_Text_Classification.md)

- [MSNER: A Multilingual Speech Dataset for Named Entity Recognition](2024年05月19日/MSNER_A_Multilingual_Speech_Dataset_for_Named_Entity_Recognition.md)

    - [翻译: MSNER：专为命名实体识别而设的多语言语音数据集](2024年05月19日/MSNER_A_Multilingual_Speech_Dataset_for_Named_Entity_Recognition.md)

- [Towards Translating Real-World Code with LLMs: A Study of Translating to Rust](2024年05月19日/Towards_Translating_Real-World_Code_with_LLMs_A_Study_of_Translating_to_Rust.md)

    - [翻译: 探索大型语言模型在现实世界代码翻译中的应用：一项针对 Rust 语言的翻译研究](2024年05月19日/Towards_Translating_Real-World_Code_with_LLMs_A_Study_of_Translating_to_Rust.md)

- [Enhancing user experience in large language models through human-centered design: Integrating theoretical insights with an experimental study to meet diverse software learning needs with a single document knowledge base](2024年05月19日/Enhancing_user_experience_in_large_language_models_through_human-centered_design_Integrating_theoretical_insights_with_an_experimental_study_to_meet_diverse_software_learning_needs_with_a_single_document_knowledge_base.md)

    - [翻译: 借助以人为本的设计理念，我们致力于提升大型语言模型的用户体验，通过融合理论与实践，打造一个集成的文档知识库，以满足不同软件学习者的多元需求。](2024年05月19日/Enhancing_user_experience_in_large_language_models_through_human-centered_design_Integrating_theoretical_insights_with_an_experimental_study_to_meet_diverse_software_learning_needs_with_a_single_document_knowledge_base.md)

- [DEMO: A Statistical Perspective for Efficient Image-Text Matching](2024年05月19日/DEMO_A_Statistical_Perspective_for_Efficient_Image-Text_Matching.md)

    - [翻译: DEMO：探索图像与文本匹配的高效统计方法](2024年05月19日/DEMO_A_Statistical_Perspective_for_Efficient_Image-Text_Matching.md)

- [Measuring Impacts of Poisoning on Model Parameters and Embeddings for Large Language Models of Code](2024年05月19日/Measuring_Impacts_of_Poisoning_on_Model_Parameters_and_Embeddings_for_Large_Language_Models_of_Code.md)

    - [翻译: 评估大型代码语言模型中毒化对模型参数及嵌入的影响](2024年05月19日/Measuring_Impacts_of_Poisoning_on_Model_Parameters_and_Embeddings_for_Large_Language_Models_of_Code.md)

- [Effective In-Context Example Selection through Data Compression](2024年05月19日/Effective_In-Context_Example_Selection_through_Data_Compression.md)

    - [翻译: 利用数据压缩精妙筛选上下文示例](2024年05月19日/Effective_In-Context_Example_Selection_through_Data_Compression.md)

- [Efficient Prompt Tuning by Multi-Space Projection and Prompt Fusion](2024年05月19日/Efficient_Prompt_Tuning_by_Multi-Space_Projection_and_Prompt_Fusion.md)

    - [翻译: 利用多空间投影与提示融合实现高效提示调优](2024年05月19日/Efficient_Prompt_Tuning_by_Multi-Space_Projection_and_Prompt_Fusion.md)

- [DocReLM: Mastering Document Retrieval with Language Model](2024年05月19日/DocReLM_Mastering_Document_Retrieval_with_Language_Model.md)

    - [翻译: DocReLM：驾驭语言模型，精通文档检索](2024年05月19日/DocReLM_Mastering_Document_Retrieval_with_Language_Model.md)

- [CPS-LLM: Large Language Model based Safe Usage Plan Generator for Human-in-the-Loop Human-in-the-Plant Cyber-Physical System](2024年05月19日/CPS-LLM_Large_Language_Model_based_Safe_Usage_Plan_Generator_for_Human-in-the-Loop_Human-in-the-Plant_Cyber-Physical_System.md)

    - [翻译: CPS-LLM：大型语言模型驱动的安全使用计划生成器，专为人机交互的工厂网络物理系统设计](2024年05月19日/CPS-LLM_Large_Language_Model_based_Safe_Usage_Plan_Generator_for_Human-in-the-Loop_Human-in-the-Plant_Cyber-Physical_System.md)

- [Comparisons Are All You Need for Optimizing Smooth Functions](2024年05月19日/Comparisons_Are_All_You_Need_for_Optimizing_Smooth_Functions.md)

    - [翻译: 优化平滑函数，关键在于比较](2024年05月19日/Comparisons_Are_All_You_Need_for_Optimizing_Smooth_Functions.md)

- [MAML-en-LLM: Model Agnostic Meta-Training of LLMs for Improved In-Context Learning](2024年05月19日/MAML-en-LLM_Model_Agnostic_Meta-Training_of_LLMs_for_Improved_In-Context_Learning.md)

    - [翻译: MAML-en-LLM：提升 LLMs 上下文学习能力的模型无关元训练法](2024年05月19日/MAML-en-LLM_Model_Agnostic_Meta-Training_of_LLMs_for_Improved_In-Context_Learning.md)

- [EmbSum: Leveraging the Summarization Capabilities of Large Language Models for Content-Based Recommendations](2024年05月19日/EmbSum_Leveraging_the_Summarization_Capabilities_of_Large_Language_Models_for_Content-Based_Recommendations.md)

    - [翻译: EmbSum：借助大型语言模型的摘要技术，优化基于内容的推荐系统](2024年05月19日/EmbSum_Leveraging_the_Summarization_Capabilities_of_Large_Language_Models_for_Content-Based_Recommendations.md)

- [Human-Centered LLM-Agent User Interface: A Position Paper](2024年05月19日/Human-Centered_LLM-Agent_User_Interface_A_Position_Paper.md)

    - [翻译: 聚焦人本的LLM-Agent界面设计：立场阐述](2024年05月19日/Human-Centered_LLM-Agent_User_Interface_A_Position_Paper.md)

2024年05月18日

- [MHPP: Exploring the Capabilities and Limitations of Language Models Beyond Basic Code Generation](2024年05月18日/MHPP_Exploring_the_Capabilities_and_Limitations_of_Language_Models_Beyond_Basic_Code_Generation.md)

    - [翻译: MHPP：深入挖掘语言模型超越基础代码生成的潜能与局限](2024年05月18日/MHPP_Exploring_the_Capabilities_and_Limitations_of_Language_Models_Beyond_Basic_Code_Generation.md)

- [Large Language Models are Biased Reinforcement Learners](2024年05月18日/Large_Language_Models_are_Biased_Reinforcement_Learners.md)

    - [翻译: 大型语言模型，作为带有偏见的强化学习者，其学习过程受到固有偏见的影响。](2024年05月18日/Large_Language_Models_are_Biased_Reinforcement_Learners.md)

- [Can Public LLMs be used for Self-Diagnosis of Medical Conditions ?](2024年05月18日/Can_Public_LLMs_be_used_for_Self-Diagnosis_of_Medical_Conditions_.md)

    - [翻译: 公共LLMs是否适用于自我诊断医疗状况？](2024年05月18日/Can_Public_LLMs_be_used_for_Self-Diagnosis_of_Medical_Conditions_.md)

- [MapCoder: Multi-Agent Code Generation for Competitive Problem Solving](2024年05月18日/MapCoder_Multi-Agent_Code_Generation_for_Competitive_Problem_Solving.md)

    - [翻译: MapCoder：多代理协作，共创竞争问题解决的代码新篇章](2024年05月18日/MapCoder_Multi-Agent_Code_Generation_for_Competitive_Problem_Solving.md)

- [An Opportunistically Parallel Lambda Calculus for Performant Composition of Large Language Models](2024年05月18日/An_Opportunistically_Parallel_Lambda_Calculus_for_Performant_Composition_of_Large_Language_Models.md)

    - [翻译: 一种机会主义并行的Lambda演算，旨在高效组合大型语言模型，提升性能。](2024年05月18日/An_Opportunistically_Parallel_Lambda_Calculus_for_Performant_Composition_of_Large_Language_Models.md)

- [Large Language Models Lack Understanding of Character Composition of Words](2024年05月18日/Large_Language_Models_Lack_Understanding_of_Character_Composition_of_Words.md)

    - [翻译: 大型语言模型在理解单词的字符构成方面存在缺陷。](2024年05月18日/Large_Language_Models_Lack_Understanding_of_Character_Composition_of_Words.md)

- [Decision support system for Forest fire management using Ontology with Big Data and LLMs](2024年05月18日/Decision_support_system_for_Forest_fire_management_using_Ontology_with_Big_Data_and_LLMs.md)

    - [翻译: 结合大数据与大型语言模型，本体论驱动的森林火灾管理决策支持系统](2024年05月18日/Decision_support_system_for_Forest_fire_management_using_Ontology_with_Big_Data_and_LLMs.md)

- [MediCLIP: Adapting CLIP for Few-shot Medical Image Anomaly Detection](2024年05月18日/MediCLIP_Adapting_CLIP_for_Few-shot_Medical_Image_Anomaly_Detection.md)

    - [翻译: MediCLIP：定制 CLIP 以应对少样本医学图像异常检测挑战](2024年05月18日/MediCLIP_Adapting_CLIP_for_Few-shot_Medical_Image_Anomaly_Detection.md)

- [Enhancing Fine-Grained Image Classifications via Cascaded Vision Language Models](2024年05月18日/Enhancing_Fine-Grained_Image_Classifications_via_Cascaded_Vision_Language_Models.md)

    - [翻译: 借助级联视觉语言模型，提升细粒度图像分类的精准度](2024年05月18日/Enhancing_Fine-Grained_Image_Classifications_via_Cascaded_Vision_Language_Models.md)

- [The CAP Principle for LLM Serving](2024年05月18日/The_CAP_Principle_for_LLM_Serving.md)

    - [翻译: 大型语言模型服务的 CAP 原则探讨](2024年05月18日/The_CAP_Principle_for_LLM_Serving.md)

- [MBIAS: Mitigating Bias in Large Language Models While Retaining Context](2024年05月18日/MBIAS_Mitigating_Bias_in_Large_Language_Models_While_Retaining_Context.md)

    - [翻译: MBIAS：在保持上下文完整性的同时，有效缓解大型语言模型中的偏见问题](2024年05月18日/MBIAS_Mitigating_Bias_in_Large_Language_Models_While_Retaining_Context.md)

- [Uni-MoE: Scaling Unified Multimodal LLMs with Mixture of Experts](2024年05月18日/Uni-MoE_Scaling_Unified_Multimodal_LLMs_with_Mixture_of_Experts.md)

    - [翻译: Uni-MoE：借助专家混合技术，扩展统一多模态大型语言模型](2024年05月18日/Uni-MoE_Scaling_Unified_Multimodal_LLMs_with_Mixture_of_Experts.md)

- [EnviroExam: Benchmarking Environmental Science Knowledge of Large Language Models](2024年05月18日/EnviroExam_Benchmarking_Environmental_Science_Knowledge_of_Large_Language_Models.md)

    - [翻译: 环境科学知识测试：大型语言模型基准评估](2024年05月18日/EnviroExam_Benchmarking_Environmental_Science_Knowledge_of_Large_Language_Models.md)

- [WisPerMed at "Discharge Me!": Advancing Text Generation in Healthcare with Large Language Models, Dynamic Expert Selection, and Priming Techniques on MIMIC-IV](2024年05月18日/WisPerMed_at_Discharge_Me!_Advancing_Text_Generation_in_Healthcare_with_Large_Language_Models,_Dynamic_Expert_Selection,_and_Priming_Techniques_on_MIMIC-IV.md)

    - [翻译: WisPerMed 参与“Discharge Me!”项目，通过大型语言模型、动态专家选择及预处理技术，在 MIMIC-IV 数据库上推动医疗文本生成的进步。](2024年05月18日/WisPerMed_at_Discharge_Me!_Advancing_Text_Generation_in_Healthcare_with_Large_Language_Models,_Dynamic_Expert_Selection,_and_Priming_Techniques_on_MIMIC-IV.md)

- [The Power of Active Multi-Task Learning in Reinforcement Learning from Human Feedback](2024年05月18日/The_Power_of_Active_Multi-Task_Learning_in_Reinforcement_Learning_from_Human_Feedback.md)

    - [翻译: 人类反馈强化学习中主动多任务学习的威力](2024年05月18日/The_Power_of_Active_Multi-Task_Learning_in_Reinforcement_Learning_from_Human_Feedback.md)

- [Natural Is The Best: Model-Agnostic Code Simplification for Pre-trained Large Language Models](2024年05月18日/Natural_Is_The_Best_Model-Agnostic_Code_Simplification_for_Pre-trained_Large_Language_Models.md)

    - [翻译: 自然至上：简化预训练大型语言模型的模型无关代码](2024年05月18日/Natural_Is_The_Best_Model-Agnostic_Code_Simplification_for_Pre-trained_Large_Language_Models.md)

- [Automating PTSD Diagnostics in Clinical Interviews: Leveraging Large Language Models for Trauma Assessments](2024年05月18日/Automating_PTSD_Diagnostics_in_Clinical_Interviews_Leveraging_Large_Language_Models_for_Trauma_Assessments.md)

    - [翻译: 利用大型语言模型自动化 PTSD 诊断，优化临床访谈中的创伤评估流程。](2024年05月18日/Automating_PTSD_Diagnostics_in_Clinical_Interviews_Leveraging_Large_Language_Models_for_Trauma_Assessments.md)

- [A Method on Searching Better Activation Functions](2024年05月18日/A_Method_on_Searching_Better_Activation_Functions.md)

    - [翻译: 探索更优激活函数的新途径](2024年05月18日/A_Method_on_Searching_Better_Activation_Functions.md)

2024年05月17日

- [Observational Scaling Laws and the Predictability of Language Model Performance](2024年05月17日/Observational_Scaling_Laws_and_the_Predictability_of_Language_Model_Performance.md)

    - [翻译: 语言模型性能的可预测性：观察性缩放定律的探索](2024年05月17日/Observational_Scaling_Laws_and_the_Predictability_of_Language_Model_Performance.md)

- [A Survey on Large Language Models with Multilingualism: Recent Advances and New Frontiers](2024年05月17日/A_Survey_on_Large_Language_Models_with_Multilingualism_Recent_Advances_and_New_Frontiers.md)

    - [翻译: 大型语言模型多语言性研究综述：探索近期进展与新领域](2024年05月17日/A_Survey_on_Large_Language_Models_with_Multilingualism_Recent_Advances_and_New_Frontiers.md)

- [The Local Interaction Basis: Identifying Computationally-Relevant and Sparsely Interacting Features in Neural Networks](2024年05月17日/The_Local_Interaction_Basis_Identifying_Computationally-Relevant_and_Sparsely_Interacting_Features_in_Neural_Networks.md)

    - [翻译: 神经网络中的局部交互基：揭示计算相关且交互稀疏的关键特征](2024年05月17日/The_Local_Interaction_Basis_Identifying_Computationally-Relevant_and_Sparsely_Interacting_Features_in_Neural_Networks.md)

- [COGNET-MD, an evaluation framework and dataset for Large Language Model benchmarks in the medical domain](2024年05月17日/COGNET-MD,_an_evaluation_framework_and_dataset_for_Large_Language_Model_benchmarks_in_the_medical_domain.md)

    - [翻译: COGNET-MD，专为医学领域大型语言模型基准设计的评估框架与数据集](2024年05月17日/COGNET-MD,_an_evaluation_framework_and_dataset_for_Large_Language_Model_benchmarks_in_the_medical_domain.md)

- [Application of Artificial Intelligence in Schizophrenia Rehabilitation Management: Systematic Literature Review](2024年05月17日/Application_of_Artificial_Intelligence_in_Schizophrenia_Rehabilitation_Management_Systematic_Literature_Review.md)

    - [翻译: 人工智能在精神分裂症康复管理中的应用：一份系统性的文献综述](2024年05月17日/Application_of_Artificial_Intelligence_in_Schizophrenia_Rehabilitation_Management_Systematic_Literature_Review.md)

- [The Future of Large Language Model Pre-training is Federated](2024年05月17日/The_Future_of_Large_Language_Model_Pre-training_is_Federated.md)

    - [翻译: 大型语言模型的预训练正迈向联邦化。](2024年05月17日/The_Future_of_Large_Language_Model_Pre-training_is_Federated.md)

- [Open-Vocabulary Spatio-Temporal Action Detection](2024年05月17日/Open-Vocabulary_Spatio-Temporal_Action_Detection.md)

    - [翻译: 开放词汇下的时空动作识别](2024年05月17日/Open-Vocabulary_Spatio-Temporal_Action_Detection.md)

- [Large Language Model (LLM) for Telecommunications: A Comprehensive Survey on Principles, Key Techniques, and Opportunities](2024年05月17日/Large_Language_Model_(LLM)_for_Telecommunications_A_Comprehensive_Survey_on_Principles,_Key_Techniques,_and_Opportunities.md)

    - [翻译: 电信领域的大型语言模型（LLM）：原理、关键技术与机遇的全面探讨](2024年05月17日/Large_Language_Model_(LLM)_for_Telecommunications_A_Comprehensive_Survey_on_Principles,_Key_Techniques,_and_Opportunities.md)

- [ActiveLLM: Large Language Model-based Active Learning for Textual Few-Shot Scenarios](2024年05月17日/ActiveLLM_Large_Language_Model-based_Active_Learning_for_Textual_Few-Shot_Scenarios.md)

    - [翻译: ActiveLLM：大型语言模型驱动的主动学习，专为文本少量样本场景设计](2024年05月17日/ActiveLLM_Large_Language_Model-based_Active_Learning_for_Textual_Few-Shot_Scenarios.md)

- [Empowering Small-Scale Knowledge Graphs: A Strategy of Leveraging General-Purpose Knowledge Graphs for Enriched Embeddings](2024年05月17日/Empowering_Small-Scale_Knowledge_Graphs_A_Strategy_of_Leveraging_General-Purpose_Knowledge_Graphs_for_Enriched_Embeddings.md)

    - [翻译: 小型知识图谱的强化策略：借助通用知识图谱，提升嵌入丰富度](2024年05月17日/Empowering_Small-Scale_Knowledge_Graphs_A_Strategy_of_Leveraging_General-Purpose_Knowledge_Graphs_for_Enriched_Embeddings.md)

- [Efficient Multimodal Large Language Models: A Survey](2024年05月17日/Efficient_Multimodal_Large_Language_Models_A_Survey.md)

    - [翻译: 多模态大型语言模型的高效性研究：一份综述](2024年05月17日/Efficient_Multimodal_Large_Language_Models_A_Survey.md)

- [INDUS: Effective and Efficient Language Models for Scientific Applications](2024年05月17日/INDUS_Effective_and_Efficient_Language_Models_for_Scientific_Applications.md)

    - [翻译: INDUS：科学应用中的高效与有效语言模型](2024年05月17日/INDUS_Effective_and_Efficient_Language_Models_for_Scientific_Applications.md)

- [SignLLM: Sign Languages Production Large Language Models](2024年05月17日/SignLLM_Sign_Languages_Production_Large_Language_Models.md)

    - [翻译: SignLLM：大型语言模型助力手语生成](2024年05月17日/SignLLM_Sign_Languages_Production_Large_Language_Models.md)

- [SynDy: Synthetic Dynamic Dataset Generation Framework for Misinformation Tasks](2024年05月17日/SynDy_Synthetic_Dynamic_Dataset_Generation_Framework_for_Misinformation_Tasks.md)

    - [翻译: SynDy：打造虚假信息任务的动态合成数据集之框架](2024年05月17日/SynDy_Synthetic_Dynamic_Dataset_Generation_Framework_for_Misinformation_Tasks.md)

- [Revolutionizing Process Mining: A Novel Architecture for ChatGPT Integration and Enhanced User Experience through Optimized Prompt Engineering](2024年05月17日/Revolutionizing_Process_Mining_A_Novel_Architecture_for_ChatGPT_Integration_and_Enhanced_User_Experience_through_Optimized_Prompt_Engineering.md)

    - [翻译: 革新流程挖掘：通过优化提示工程，构建了一种新颖的ChatGPT集成架构，旨在提升用户体验。](2024年05月17日/Revolutionizing_Process_Mining_A_Novel_Architecture_for_ChatGPT_Integration_and_Enhanced_User_Experience_through_Optimized_Prompt_Engineering.md)

- [Realistic Evaluation of Toxicity in Large Language Models](2024年05月17日/Realistic_Evaluation_of_Toxicity_in_Large_Language_Models.md)

    - [翻译: 大型语言模型中毒性的真实评估](2024年05月17日/Realistic_Evaluation_of_Toxicity_in_Large_Language_Models.md)

- [SPOR: A Comprehensive and Practical Evaluation Method for Compositional Generalization in Data-to-Text Generation](2024年05月17日/SPOR_A_Comprehensive_and_Practical_Evaluation_Method_for_Compositional_Generalization_in_Data-to-Text_Generation.md)

    - [翻译: SPOR：全面实用的数据到文本生成组合泛化评估方法](2024年05月17日/SPOR_A_Comprehensive_and_Practical_Evaluation_Method_for_Compositional_Generalization_in_Data-to-Text_Generation.md)

- [Layer-Condensed KV Cache for Efficient Inference of Large Language Models](2024年05月17日/Layer-Condensed_KV_Cache_for_Efficient_Inference_of_Large_Language_Models.md)

    - [翻译: 层压缩 KV 缓存：大型语言模型的高效推理之道](2024年05月17日/Layer-Condensed_KV_Cache_for_Efficient_Inference_of_Large_Language_Models.md)

- [Medical Dialogue: A Survey of Categories, Methods, Evaluation and Challenges](2024年05月17日/Medical_Dialogue_A_Survey_of_Categories,_Methods,_Evaluation_and_Challenges.md)

    - [翻译: 医疗对话综览：探索其类别、方法、评估及面临的挑战](2024年05月17日/Medical_Dialogue_A_Survey_of_Categories,_Methods,_Evaluation_and_Challenges.md)

- [Dynamic data sampler for cross-language transfer learning in large language models](2024年05月17日/Dynamic_data_sampler_for_cross-language_transfer_learning_in_large_language_models.md)

    - [翻译: 大型语言模型中跨语言迁移学习的动态数据采样策略](2024年05月17日/Dynamic_data_sampler_for_cross-language_transfer_learning_in_large_language_models.md)

- [Specialising and Analysing Instruction-Tuned and Byte-Level Language Models for Organic Reaction Prediction](2024年05月17日/Specialising_and_Analysing_Instruction-Tuned_and_Byte-Level_Language_Models_for_Organic_Reaction_Prediction.md)

    - [翻译: 针对有机反应预测，深入分析与优化指令调整及字节级语言模型](2024年05月17日/Specialising_and_Analysing_Instruction-Tuned_and_Byte-Level_Language_Models_for_Organic_Reaction_Prediction.md)

- [MC-GPT: Empowering Vision-and-Language Navigation with Memory Map and Reasoning Chains](2024年05月17日/MC-GPT_Empowering_Vision-and-Language_Navigation_with_Memory_Map_and_Reasoning_Chains.md)

    - [翻译: MC-GPT：借助记忆地图与推理链，提升视觉与语言导航的智能水平](2024年05月17日/MC-GPT_Empowering_Vision-and-Language_Navigation_with_Memory_Map_and_Reasoning_Chains.md)

- [Feature-based Low-Rank Compression of Large Language Models via Bayesian Optimization](2024年05月17日/Feature-based_Low-Rank_Compression_of_Large_Language_Models_via_Bayesian_Optimization.md)

    - [翻译: 利用贝叶斯优化实现大型语言模型的特征驱动低秩压缩](2024年05月17日/Feature-based_Low-Rank_Compression_of_Large_Language_Models_via_Bayesian_Optimization.md)

- [RDRec: Rationale Distillation for LLM-based Recommendation](2024年05月17日/RDRec_Rationale_Distillation_for_LLM-based_Recommendation.md)

    - [翻译: RDRec：大型语言模型推荐理由的精炼之法](2024年05月17日/RDRec_Rationale_Distillation_for_LLM-based_Recommendation.md)

- [A Hard Nut to Crack: Idiom Detection with Conversational Large Language Models](2024年05月17日/A_Hard_Nut_to_Crack_Idiom_Detection_with_Conversational_Large_Language_Models.md)

    - [翻译: 破解难题：利用对话大型语言模型进行成语识别](2024年05月17日/A_Hard_Nut_to_Crack_Idiom_Detection_with_Conversational_Large_Language_Models.md)

- [Language Models can Exploit Cross-Task In-context Learning for Data-Scarce Novel Tasks](2024年05月17日/Language_Models_can_Exploit_Cross-Task_In-context_Learning_for_Data-Scarce_Novel_Tasks.md)

    - [翻译: 语言模型通过跨任务的上下文学习，能够有效应对数据稀缺的新任务挑战。](2024年05月17日/Language_Models_can_Exploit_Cross-Task_In-context_Learning_for_Data-Scarce_Novel_Tasks.md)

- [GPTs Window Shopping: An analysis of the Landscape of Custom ChatGPT Models](2024年05月17日/GPTs_Window_Shopping_An_analysis_of_the_Landscape_of_Custom_ChatGPT_Models.md)

    - [翻译: GPT的探索之旅：定制ChatGPT模型领域的深度剖析](2024年05月17日/GPTs_Window_Shopping_An_analysis_of_the_Landscape_of_Custom_ChatGPT_Models.md)

- [Benchmarking Large Language Models on CFLUE -- A Chinese Financial Language Understanding Evaluation Dataset](2024年05月17日/Benchmarking_Large_Language_Models_on_CFLUE_--_A_Chinese_Financial_Language_Understanding_Evaluation_Dataset.md)

    - [翻译: 大型语言模型在中文金融语言理解评估数据集CFLUE上的性能基准测试。](2024年05月17日/Benchmarking_Large_Language_Models_on_CFLUE_--_A_Chinese_Financial_Language_Understanding_Evaluation_Dataset.md)

- [Safeguarding Vision-Language Models Against Patched Visual Prompt Injectors](2024年05月17日/Safeguarding_Vision-Language_Models_Against_Patched_Visual_Prompt_Injectors.md)

    - [翻译: 防御视觉-语言模型，抵御补丁式视觉提示注入威胁](2024年05月17日/Safeguarding_Vision-Language_Models_Against_Patched_Visual_Prompt_Injectors.md)

- [Smart Expert System: Large Language Models as Text Classifiers](2024年05月17日/Smart_Expert_System_Large_Language_Models_as_Text_Classifiers.md)

    - [翻译: 智能专家系统：利用大型语言模型进行文本分类](2024年05月17日/Smart_Expert_System_Large_Language_Models_as_Text_Classifiers.md)

- [A Versatile Framework for Analyzing Galaxy Image Data by Implanting Human-in-the-loop on a Large Vision Model](2024年05月17日/A_Versatile_Framework_for_Analyzing_Galaxy_Image_Data_by_Implanting_Human-in-the-loop_on_a_Large_Vision_Model.md)

    - [翻译: 本研究提出了一种灵活的框架，通过在大规模视觉模型中引入人机交互，以分析星系图像数据。](2024年05月17日/A_Versatile_Framework_for_Analyzing_Galaxy_Image_Data_by_Implanting_Human-in-the-loop_on_a_Large_Vision_Model.md)

- [LLM-based Multi-Agent Reinforcement Learning: Current and Future Directions](2024年05月17日/LLM-based_Multi-Agent_Reinforcement_Learning_Current_and_Future_Directions.md)

    - [翻译: 大型语言模型驱动的多智能体强化学习：现状与未来展望](2024年05月17日/LLM-based_Multi-Agent_Reinforcement_Learning_Current_and_Future_Directions.md)

- [Automated Multi-level Preference for MLLMs](2024年05月17日/Automated_Multi-level_Preference_for_MLLMs.md)

    - [翻译: 多语言大型语言模型的自动化多级偏好设置](2024年05月17日/Automated_Multi-level_Preference_for_MLLMs.md)

- [LG AI Research & KAIST at EHRSQL 2024: Self-Training Large Language Models with Pseudo-Labeled Unanswerable Questions for a Reliable Text-to-SQL System on EHRs](2024年05月17日/LG_AI_Research_&_KAIST_at_EHRSQL_2024_Self-Training_Large_Language_Models_with_Pseudo-Labeled_Unanswerable_Questions_for_a_Reliable_Text-to-SQL_System_on_EHRs.md)

    - [翻译: LG AI Research 携手 KAIST 在 EHRSQL 2024 展示：通过利用伪标记的不可回答问题，自我训练大型语言模型，旨在打造一个高效可靠的电子健康记录文本至 SQL 转换系统。](2024年05月17日/LG_AI_Research_&_KAIST_at_EHRSQL_2024_Self-Training_Large_Language_Models_with_Pseudo-Labeled_Unanswerable_Questions_for_a_Reliable_Text-to-SQL_System_on_EHRs.md)

- [Towards Modular LLMs by Building and Reusing a Library of LoRAs](2024年05月17日/Towards_Modular_LLMs_by_Building_and_Reusing_a_Library_of_LoRAs.md)

    - [翻译: 构建并重用 LoRAs 库，迈向 LLMs 的模块化之路](2024年05月17日/Towards_Modular_LLMs_by_Building_and_Reusing_a_Library_of_LoRAs.md)

- [Revisiting the Robust Generalization of Adversarial Prompt Tuning](2024年05月17日/Revisiting_the_Robust_Generalization_of_Adversarial_Prompt_Tuning.md)

    - [翻译: 再次探讨对抗性提示调优的鲁棒泛化问题](2024年05月17日/Revisiting_the_Robust_Generalization_of_Adversarial_Prompt_Tuning.md)

- [CC-GPX: Extracting High-Quality Annotated Geospatial Data from Common Crawl](2024年05月17日/CC-GPX_Extracting_High-Quality_Annotated_Geospatial_Data_from_Common_Crawl.md)

    - [翻译: CC-GPX：挖掘Common Crawl中的宝藏——高质量地理空间数据标注](2024年05月17日/CC-GPX_Extracting_High-Quality_Annotated_Geospatial_Data_from_Common_Crawl.md)

2024年05月16日

- [Fine-Tuning Large Vision-Language Models as Decision-Making Agents via Reinforcement Learning](2024年05月16日/Fine-Tuning_Large_Vision-Language_Models_as_Decision-Making_Agents_via_Reinforcement_Learning.md)

    - [翻译: 借助强化学习，微调大型视觉-语言模型，使其化身为智能决策代理](2024年05月16日/Fine-Tuning_Large_Vision-Language_Models_as_Decision-Making_Agents_via_Reinforcement_Learning.md)

- [When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models](2024年05月16日/When_LLMs_step_into_the_3D_World_A_Survey_and_Meta-Analysis_of_3D_Tasks_via_Multi-modal_Large_Language_Models.md)

    - [翻译: 大型语言模型探索3D世界：多模态大型语言模型在3D任务领域的调查与深度分析](2024年05月16日/When_LLMs_step_into_the_3D_World_A_Survey_and_Meta-Analysis_of_3D_Tasks_via_Multi-modal_Large_Language_Models.md)

- [Speaker Verification in Agent-Generated Conversations](2024年05月16日/Speaker_Verification_in_Agent-Generated_Conversations.md)

    - [翻译: 代理对话中的说话人验证技术在代理生成的对话中，说话人验证技术扮演着至关重要的角色。它不仅确保了对话的真实性和安全性，还提升了用户体验。然而，这项技术的实现面临着多重挑战，包括语音识别的准确性、环境噪声的干扰以及不同说话人声音的相似性。本研究将深入探讨这些挑战，并提出创新的解决方案，以期在代理对话领域推动说话人验证技术的发展。](2024年05月16日/Speaker_Verification_in_Agent-Generated_Conversations.md)

- [Libra: Building Decoupled Vision System on Large Language Models](2024年05月16日/Libra_Building_Decoupled_Vision_System_on_Large_Language_Models.md)

    - [翻译: 天秤座：打造大型语言模型上的视觉系统解耦架构](2024年05月16日/Libra_Building_Decoupled_Vision_System_on_Large_Language_Models.md)

- [Distilling Implicit Multimodal Knowledge into LLMs for Zero-Resource Dialogue Generation](2024年05月16日/Distilling_Implicit_Multimodal_Knowledge_into_LLMs_for_Zero-Resource_Dialogue_Generation.md)

    - [翻译: 提炼隐式多模态智慧，赋能大型语言模型零资源对话生成之旅](2024年05月16日/Distilling_Implicit_Multimodal_Knowledge_into_LLMs_for_Zero-Resource_Dialogue_Generation.md)

- [Listen Again and Choose the Right Answer: A New Paradigm for Automatic Speech Recognition with Large Language Models](2024年05月16日/Listen_Again_and_Choose_the_Right_Answer_A_New_Paradigm_for_Automatic_Speech_Recognition_with_Large_Language_Models.md)

    - [翻译: 重听选答：大型语言模型驱动的新一代自动语音识别技术在这个新范式中，我们提出了一种基于大型语言模型的自动语音识别方法，该方法通过让模型“再次聆听”并自主选择最合适的转录答案，显著提高了识别的准确性和鲁棒性。这种方法不仅充分利用了大型语言模型的强大语义理解能力，还通过引入选择机制，使得模型能够更好地适应复杂的语音环境和多样化的说话风格。](2024年05月16日/Listen_Again_and_Choose_the_Right_Answer_A_New_Paradigm_for_Automatic_Speech_Recognition_with_Large_Language_Models.md)

- [ROCOv2: Radiology Objects in COntext Version 2, an Updated Multimodal Image Dataset](2024年05月16日/ROCOv2_Radiology_Objects_in_COntext_Version_2,_an_Updated_Multimodal_Image_Dataset.md)

    - [翻译: ROCOv2：升级版放射学对象多模态图像数据集，旨在提供更丰富的上下文信息，以促进医学影像领域的研究与应用。](2024年05月16日/ROCOv2_Radiology_Objects_in_COntext_Version_2,_an_Updated_Multimodal_Image_Dataset.md)

- [Adversarial Robustness for Visual Grounding of Multimodal Large Language Models](2024年05月16日/Adversarial_Robustness_for_Visual_Grounding_of_Multimodal_Large_Language_Models.md)

    - [翻译: 多模态大型语言模型的视觉定位需要对抗性鲁棒性的保障。](2024年05月16日/Adversarial_Robustness_for_Visual_Grounding_of_Multimodal_Large_Language_Models.md)

- [Many-Shot In-Context Learning in Multimodal Foundation Models](2024年05月16日/Many-Shot_In-Context_Learning_in_Multimodal_Foundation_Models.md)

    - [翻译: 多模态基础模型中的多重上下文学习探索](2024年05月16日/Many-Shot_In-Context_Learning_in_Multimodal_Foundation_Models.md)

- [UniRAG: Universal Retrieval Augmentation for Multi-Modal Large Language Models](2024年05月16日/UniRAG_Universal_Retrieval_Augmentation_for_Multi-Modal_Large_Language_Models.md)

    - [翻译: UniRAG：赋能多模态大语言模型，实现通用检索增强在这项研究中，我们提出了UniRAG，这是一种创新的方法，旨在通过通用检索增强技术来提升多模态大型语言模型的性能。UniRAG不仅能够处理文本信息，还能够整合图像、视频等多种模态的数据，从而在理解和生成任务中展现出更强的能力。我们的方法通过智能检索和整合多源信息，使得模型能够更好地理解复杂的上下文，并在多模态环境中提供更准确的响应。](2024年05月16日/UniRAG_Universal_Retrieval_Augmentation_for_Multi-Modal_Large_Language_Models.md)

- [4D Panoptic Scene Graph Generation](2024年05月16日/4D_Panoptic_Scene_Graph_Generation.md)

    - [翻译: 四维全景场景图构建](2024年05月16日/4D_Panoptic_Scene_Graph_Generation.md)

- [HW-GPT-Bench: Hardware-Aware Architecture Benchmark for Language Models](2024年05月16日/HW-GPT-Bench_Hardware-Aware_Architecture_Benchmark_for_Language_Models.md)

    - [翻译: HW-GPT-Bench：专为语言模型设计的硬件感知架构评测平台解释：在](2024年05月16日/HW-GPT-Bench_Hardware-Aware_Architecture_Benchmark_for_Language_Models.md)

- [Timeline-based Sentence Decomposition with In-Context Learning for Temporal Fact Extraction](2024年05月16日/Timeline-based_Sentence_Decomposition_with_In-Context_Learning_for_Temporal_Fact_Extraction.md)

    - [翻译: 运用上下文学习的时间线句子分解技术，助力时间事实提取在这项研究中，我们提出了一种新颖的方法，即基于时间线的句子分解结合上下文学习，用于提取文本中的时间相关事实。通过这种方法，我们能够更准确地捕捉和理解文本中的时间信息，从而提高时间事实提取的效率和准确性。](2024年05月16日/Timeline-based_Sentence_Decomposition_with_In-Context_Learning_for_Temporal_Fact_Extraction.md)

- [Revisiting OPRO: The Limitations of Small-Scale LLMs as Optimizers](2024年05月16日/Revisiting_OPRO_The_Limitations_of_Small-Scale_LLMs_as_Optimizers.md)

    - [翻译: 再探OPRO：小规模LLM作为优化器的局限性](2024年05月16日/Revisiting_OPRO_The_Limitations_of_Small-Scale_LLMs_as_Optimizers.md)

- [A Tale of Two Languages: Large-Vocabulary Continuous Sign Language Recognition from Spoken Language Supervision](2024年05月16日/A_Tale_of_Two_Languages_Large-Vocabulary_Continuous_Sign_Language_Recognition_from_Spoken_Language_Supervision.md)

    - [翻译: 双语奇缘：口语监督下的连续手语大词汇识别之旅](2024年05月16日/A_Tale_of_Two_Languages_Large-Vocabulary_Continuous_Sign_Language_Recognition_from_Spoken_Language_Supervision.md)

- [Keep It Private: Unsupervised Privatization of Online Text](2024年05月16日/Keep_It_Private_Unsupervised_Privatization_of_Online_Text.md)

    - [翻译: 守护隐私：在线文本的无监督保密处理](2024年05月16日/Keep_It_Private_Unsupervised_Privatization_of_Online_Text.md)

- [A Systematic Evaluation of Large Language Models for Natural Language Generation Tasks](2024年05月16日/A_Systematic_Evaluation_of_Large_Language_Models_for_Natural_Language_Generation_Tasks.md)

    - [翻译: 大型语言模型在自然语言生成任务上的系统性评估研究](2024年05月16日/A_Systematic_Evaluation_of_Large_Language_Models_for_Natural_Language_Generation_Tasks.md)

- [IntelliExplain: Enhancing Interactive Code Generation through Natural Language Explanations for Non-Professional Programmers](2024年05月16日/IntelliExplain_Enhancing_Interactive_Code_Generation_through_Natural_Language_Explanations_for_Non-Professional_Programmers.md)

    - [翻译: IntelliExplain：为非专业程序员提供自然语言解释，以增强交互式代码生成的智能解释系统](2024年05月16日/IntelliExplain_Enhancing_Interactive_Code_Generation_through_Natural_Language_Explanations_for_Non-Professional_Programmers.md)

- [DocuMint: Docstring Generation for Python using Small Language Models](2024年05月16日/DocuMint_Docstring_Generation_for_Python_using_Small_Language_Models.md)

    - [翻译: DocuMint：小型语言模型助力Python文档字符串生成在这项研究中，我们介绍了DocuMint，一种利用小型语言模型为Python代码生成文档字符串的工具。尽管大型语言模型在自然语言处理任务中表现出色，但小型模型在资源受限的环境中具有显著优势。DocuMint通过精心设计的提示和上下文信息，能够生成准确且信息丰富的文档字符串，从而提高代码的可读性和可维护性。我们的实验结果表明，DocuMint在生成文档字符串方面具有很高的准确性和效率，为Python开发者提供了一个实用的辅助工具。](2024年05月16日/DocuMint_Docstring_Generation_for_Python_using_Small_Language_Models.md)

- [CPsyExam: A Chinese Benchmark for Evaluating Psychology using Examinations](2024年05月16日/CPsyExam_A_Chinese_Benchmark_for_Evaluating_Psychology_using_Examinations.md)

    - [翻译: CPsyExam：中文心理学评估基准，通过考试精准衡量心理学的应用与理解。](2024年05月16日/CPsyExam_A_Chinese_Benchmark_for_Evaluating_Psychology_using_Examinations.md)

- [LFED: A Literary Fiction Evaluation Dataset for Large Language Models](2024年05月16日/LFED_A_Literary_Fiction_Evaluation_Dataset_for_Large_Language_Models.md)

    - [翻译: LFED：大型语言模型的文学小说评鉴数据集](2024年05月16日/LFED_A_Literary_Fiction_Evaluation_Dataset_for_Large_Language_Models.md)

- [StyloAI: Distinguishing AI-Generated Content with Stylometric Analysis](2024年05月16日/StyloAI_Distinguishing_AI-Generated_Content_with_Stylometric_Analysis.md)

    - [翻译: StyloAI：以文体分析之眼，辨识AI创作之迹](2024年05月16日/StyloAI_Distinguishing_AI-Generated_Content_with_Stylometric_Analysis.md)

- [Generating Coherent Sequences of Visual Illustrations for Real-World Manual Tasks](2024年05月16日/Generating_Coherent_Sequences_of_Visual_Illustrations_for_Real-World_Manual_Tasks.md)

    - [翻译: 绘制现实世界任务手册的连贯视觉插图序列](2024年05月16日/Generating_Coherent_Sequences_of_Visual_Illustrations_for_Real-World_Manual_Tasks.md)

- [When Large Language Model Meets Optimization](2024年05月16日/When_Large_Language_Model_Meets_Optimization.md)

    - [翻译: 大型语言模型与优化相遇](2024年05月16日/When_Large_Language_Model_Meets_Optimization.md)

- [SHiNe: Semantic Hierarchy Nexus for Open-vocabulary Object Detection](2024年05月16日/SHiNe_Semantic_Hierarchy_Nexus_for_Open-vocabulary_Object_Detection.md)

    - [翻译: SHiNe：开放词汇对象检测的语义层级纽带在这项研究中，我们提出了SHiNe，一种新颖的框架，旨在通过构建语义层次结构的纽带来提升开放词汇对象检测的能力。SHiNe不仅能够识别已知类别中的对象，还能够通过其层次结构推理机制，对未知类别进行合理的分类和检测。我们的方法通过整合不同层次的语义信息，实现了对复杂场景中对象的更准确理解和分类。通过一系列实验，我们证明了SHiNe在开放词汇对象检测任务中的有效性和优越性。](2024年05月16日/SHiNe_Semantic_Hierarchy_Nexus_for_Open-vocabulary_Object_Detection.md)

- [MarkLLM: An Open-Source Toolkit for LLM Watermarking](2024年05月16日/MarkLLM_An_Open-Source_Toolkit_for_LLM_Watermarking.md)

    - [翻译: MarkLLM：大型语言模型水印的开源利器在人工智能的浪潮中，大型语言模型（LLM）如璀璨星辰，引领着智能对话的潮流。然而，星辰虽美，却需标记以辨真伪。MarkLLM，这一开源工具包，便是为LLM添上独特水印的巧匠，确保每一段智能对话的纯净与真实。它不仅是一套工具，更是一把钥匙，解锁了LLM安全与信任的新篇章。](2024年05月16日/MarkLLM_An_Open-Source_Toolkit_for_LLM_Watermarking.md)

- [SynthesizRR: Generating Diverse Datasets with Retrieval Augmentation](2024年05月16日/SynthesizRR_Generating_Diverse_Datasets_with_Retrieval_Augmentation.md)

    - [翻译: SynthesizRR：借助检索增强技术，打造多样化数据集的生成器](2024年05月16日/SynthesizRR_Generating_Diverse_Datasets_with_Retrieval_Augmentation.md)

- [Leveraging Large Language Models for Automated Web-Form-Test Generation: An Empirical Study](2024年05月16日/Leveraging_Large_Language_Models_for_Automated_Web-Form-Test_Generation_An_Empirical_Study.md)

    - [翻译: 大型语言模型助力自动化网页表单测试生成：实证探索之旅在这项研究中，我们探索了如何利用大型语言模型（LLMs）的强大能力，自动化生成网页表单测试。通过一系列实证分析，我们揭示了LLMs在提高测试效率和准确性方面的潜力，为软件测试领域带来了新的视角和可能性。](2024年05月16日/Leveraging_Large_Language_Models_for_Automated_Web-Form-Test_Generation_An_Empirical_Study.md)

- [SciQAG: A Framework for Auto-Generated Scientific Question Answering Dataset with Fine-grained Evaluation](2024年05月16日/SciQAG_A_Framework_for_Auto-Generated_Scientific_Question_Answering_Dataset_with_Fine-grained_Evaluation.md)

    - [翻译: SciQAG：细粒度评估下的自动生成科学问答数据集框架在](2024年05月16日/SciQAG_A_Framework_for_Auto-Generated_Scientific_Question_Answering_Dataset_with_Fine-grained_Evaluation.md)

- ["Hunt Takes Hare": Theming Games Through Game-Word Vector Translation](2024年05月16日/Hunt_Takes_Hare_Theming_Games_Through_Game-Word_Vector_Translation.md)

    - [翻译: “猎兔行动”：运用游戏与词向量翻译的艺术，为游戏注入独特主题。](2024年05月16日/Hunt_Takes_Hare_Theming_Games_Through_Game-Word_Vector_Translation.md)

- [Rethinking Multi-User Semantic Communications with Deep Generative Models](2024年05月16日/Rethinking_Multi-User_Semantic_Communications_with_Deep_Generative_Models.md)

    - [翻译: 深度生成模型下的多用户语义通信再探在深度生成模型的引领下，我们对多用户语义通信的认知正经历一场深刻的反思。这一领域的发展，不仅拓宽了通信技术的边界，更在多用户交互的语义层面上，开启了全新的探索之旅。](2024年05月16日/Rethinking_Multi-User_Semantic_Communications_with_Deep_Generative_Models.md)

- [IGOT: Information Gain Optimized Tokenizer on Domain Adaptive Pretraining](2024年05月16日/IGOT_Information_Gain_Optimized_Tokenizer_on_Domain_Adaptive_Pretraining.md)

    - [翻译: IGOT：领域自适应预训练中的信息增益优化分词器在这项研究中，我们提出了IGOT，一种新颖的分词器，它通过最大化信息增益来优化领域自适应预训练过程。IGOT不仅提高了模型在特定领域任务上的性能，还增强了模型对领域内语言特性的捕捉能力。通过实验验证，IGOT在多个领域适应场景中均展现出了显著的性能提升。](2024年05月16日/IGOT_Information_Gain_Optimized_Tokenizer_on_Domain_Adaptive_Pretraining.md)

- [SEEK: Semantic Reasoning for Object Goal Navigation in Real World Inspection Tasks](2024年05月16日/SEEK_Semantic_Reasoning_for_Object_Goal_Navigation_in_Real_World_Inspection_Tasks.md)

    - [翻译: 探索语义推理：在现实世界的检查任务中，引领物体目标导航的新篇章在这项研究中，我们探索了语义推理在现实世界检查任务中对物体目标导航的作用。通过深入分析，我们揭示了语义推理如何帮助智能体在复杂环境中精准定位目标物体，从而提高导航效率和准确性。这一发现为智能导航技术的发展开辟了新的道路，预示着未来在各种检查任务中，智能体将能够更加智能、高效地完成任务。](2024年05月16日/SEEK_Semantic_Reasoning_for_Object_Goal_Navigation_in_Real_World_Inspection_Tasks.md)

- [Semantic Gesticulator: Semantics-Aware Co-Speech Gesture Synthesis](2024年05月16日/Semantic_Gesticulator_Semantics-Aware_Co-Speech_Gesture_Synthesis.md)

    - [翻译: 语义手势者：一种能够感知语义并同步生成语言手势的系统](2024年05月16日/Semantic_Gesticulator_Semantics-Aware_Co-Speech_Gesture_Synthesis.md)

- [FinTextQA: A Dataset for Long-form Financial Question Answering](2024年05月16日/FinTextQA_A_Dataset_for_Long-form_Financial_Question_Answering.md)

    - [翻译: FinTextQA：专为长篇金融问答而设计的数据集在这个翻译过程中，我首先直接将英文标题翻译为中文，确保了意思的准确传达。然后，我对直译的中文进行了优化，使其更加符合中文的语言表达习惯，同时保持了简洁和优雅的风格。](2024年05月16日/FinTextQA_A_Dataset_for_Long-form_Financial_Question_Answering.md)

- [Language Models can Evaluate Themselves via Probability Discrepancy](2024年05月16日/Language_Models_can_Evaluate_Themselves_via_Probability_Discrepancy.md)

    - [翻译: 语言模型利用概率差异进行自我评估。](2024年05月16日/Language_Models_can_Evaluate_Themselves_via_Probability_Discrepancy.md)

- [Lean Attention: Hardware-Aware Scalable Attention Mechanism for the Decode-Phase of Transformers](2024年05月16日/Lean_Attention_Hardware-Aware_Scalable_Attention_Mechanism_for_the_Decode-Phase_of_Transformers.md)

    - [翻译: 精益注意力：Transformer解码阶段中，一种兼顾硬件性能的可扩展注意力机制](2024年05月16日/Lean_Attention_Hardware-Aware_Scalable_Attention_Mechanism_for_the_Decode-Phase_of_Transformers.md)

- [Rethinking ChatGPT's Success: Usability and Cognitive Behaviors Enabled by Auto-regressive LLMs' Prompting](2024年05月16日/Rethinking_ChatGPT's_Success_Usability_and_Cognitive_Behaviors_Enabled_by_Auto-regressive_LLMs'_Prompting.md)

    - [翻译: 反思 ChatGPT 的成功：自回归 LLM 提示技术如何激发可用性与认知行为](2024年05月16日/Rethinking_ChatGPT's_Success_Usability_and_Cognitive_Behaviors_Enabled_by_Auto-regressive_LLMs'_Prompting.md)

- [Dynamic In-context Learning with Conversational Models for Data Extraction and Materials Property Prediction](2024年05月16日/Dynamic_In-context_Learning_with_Conversational_Models_for_Data_Extraction_and_Materials_Property_Prediction.md)

    - [翻译: 对话模型中的动态上下文学习：数据提取与材料属性预测的新途径](2024年05月16日/Dynamic_In-context_Learning_with_Conversational_Models_for_Data_Extraction_and_Materials_Property_Prediction.md)

- [Simultaneous Masking, Not Prompting Optimization: A Paradigm Shift in Fine-tuning LLMs for Simultaneous Translation](2024年05月16日/Simultaneous_Masking,_Not_Prompting_Optimization_A_Paradigm_Shift_in_Fine-tuning_LLMs_for_Simultaneous_Translation.md)

    - [翻译: 掩蔽而非优化提示：微调 LLMs 进行同时翻译的新范式](2024年05月16日/Simultaneous_Masking,_Not_Prompting_Optimization_A_Paradigm_Shift_in_Fine-tuning_LLMs_for_Simultaneous_Translation.md)

- [Retrieving and Refining: A Hybrid Framework with Large Language Models for Rare Disease Identification](2024年05月16日/Retrieving_and_Refining_A_Hybrid_Framework_with_Large_Language_Models_for_Rare_Disease_Identification.md)

    - [翻译: 检索与精炼：大型语言模型助力罕见疾病识别的混合框架](2024年05月16日/Retrieving_and_Refining_A_Hybrid_Framework_with_Large_Language_Models_for_Rare_Disease_Identification.md)

- [Grounded 3D-LLM with Referent Tokens](2024年05月16日/Grounded_3D-LLM_with_Referent_Tokens.md)

    - [翻译: 基于参照令牌的3D语言模型接地化](2024年05月16日/Grounded_3D-LLM_with_Referent_Tokens.md)

- [SMP Challenge: An Overview and Analysis of Social Media Prediction Challenge](2024年05月16日/SMP_Challenge_An_Overview_and_Analysis_of_Social_Media_Prediction_Challenge.md)

    - [翻译: 社交媒体预测挑战综述与分析：探索SMP挑战的深度与广度。](2024年05月16日/SMP_Challenge_An_Overview_and_Analysis_of_Social_Media_Prediction_Challenge.md)

- [Can formal argumentative reasoning enhance LLMs performances?](2024年05月16日/Can_formal_argumentative_reasoning_enhance_LLMs_performances.md)

    - [翻译: 论证推理能否助力大型语言模型（LLMs）性能飞跃？](2024年05月16日/Can_formal_argumentative_reasoning_enhance_LLMs_performances.md)

- [SIGMA: An Open-Source Interactive System for Mixed-Reality Task Assistance Research](2024年05月16日/SIGMA_An_Open-Source_Interactive_System_for_Mixed-Reality_Task_Assistance_Research.md)

    - [翻译: SIGMA：开源交互系统，专为混合现实任务辅助研究而设计](2024年05月16日/SIGMA_An_Open-Source_Interactive_System_for_Mixed-Reality_Task_Assistance_Research.md)

- [Autonomous Workflow for Multimodal Fine-Grained Training Assistants Towards Mixed Reality](2024年05月16日/Autonomous_Workflow_for_Multimodal_Fine-Grained_Training_Assistants_Towards_Mixed_Reality.md)

    - [翻译: 混合现实环境下的自主多模态细粒度训练助手工作流程](2024年05月16日/Autonomous_Workflow_for_Multimodal_Fine-Grained_Training_Assistants_Towards_Mixed_Reality.md)

2024年05月15日

- [Modeling Bilingual Sentence Processing: Evaluating RNN and Transformer Architectures for Cross-Language Structural Priming](2024年05月15日/Modeling_Bilingual_Sentence_Processing_Evaluating_RNN_and_Transformer_Architectures_for_Cross-Language_Structural_Priming.md)

    - [翻译: 双语句式处理模型：探究RNN与Transformer架构在跨语言结构启发下的效能评估](2024年05月15日/Modeling_Bilingual_Sentence_Processing_Evaluating_RNN_and_Transformer_Architectures_for_Cross-Language_Structural_Priming.md)

- [Beyond Flesch-Kincaid: Prompt-based Metrics Improve Difficulty Classification of Educational Texts](2024年05月15日/Beyond_Flesch-Kincaid_Prompt-based_Metrics_Improve_Difficulty_Classification_of_Educational_Texts.md)

    - [翻译: 突破弗莱什-金凯德的局限：采用基于提示的评估指标，我们显著提升了教育文本难度分类的精准度。](2024年05月15日/Beyond_Flesch-Kincaid_Prompt-based_Metrics_Improve_Difficulty_Classification_of_Educational_Texts.md)

- [Tell Me Why: Explainable Public Health Fact-Checking with Large Language Models](2024年05月15日/Tell_Me_Why_Explainable_Public_Health_Fact-Checking_with_Large_Language_Models.md)

    - [翻译: 揭秘真相：大型语言模型助力公共卫生事实核查的可解释之旅](2024年05月15日/Tell_Me_Why_Explainable_Public_Health_Fact-Checking_with_Large_Language_Models.md)

- [Facilitating Opinion Diversity through Hybrid NLP Approaches](2024年05月15日/Facilitating_Opinion_Diversity_through_Hybrid_NLP_Approaches.md)

    - [翻译: 借助混合 NLP 策略，我们致力于激发多元观点的交流与碰撞。](2024年05月15日/Facilitating_Opinion_Diversity_through_Hybrid_NLP_Approaches.md)

- [A Survey On Text-to-3D Contents Generation In The Wild](2024年05月15日/A_Survey_On_Text-to-3D_Contents_Generation_In_The_Wild.md)

    - [翻译: 《自然环境下文本至三维内容生成技术综述》](2024年05月15日/A_Survey_On_Text-to-3D_Contents_Generation_In_The_Wild.md)

- [MicroPython Testbed for Federated Learning Algorithms](2024年05月15日/MicroPython_Testbed_for_Federated_Learning_Algorithms.md)

    - [翻译: MicroPython 联邦学习算法测试平台](2024年05月15日/MicroPython_Testbed_for_Federated_Learning_Algorithms.md)

- [Matching domain experts by training from scratch on domain knowledge](2024年05月15日/Matching_domain_experts_by_training_from_scratch_on_domain_knowledge.md)

    - [翻译: 借助领域知识从头训练，以匹配领域专家的深度理解。](2024年05月15日/Matching_domain_experts_by_training_from_scratch_on_domain_knowledge.md)

- [PolygloToxicityPrompts: Multilingual Evaluation of Neural Toxic Degeneration in Large Language Models](2024年05月15日/PolygloToxicityPrompts_Multilingual_Evaluation_of_Neural_Toxic_Degeneration_in_Large_Language_Models.md)

    - [翻译: 多语种毒性提示评估：探究大型语言模型中的神经毒性退化现象](2024年05月15日/PolygloToxicityPrompts_Multilingual_Evaluation_of_Neural_Toxic_Degeneration_in_Large_Language_Models.md)

- [Large Language Model Bias Mitigation from the Perspective of Knowledge Editing](2024年05月15日/Large_Language_Model_Bias_Mitigation_from_the_Perspective_of_Knowledge_Editing.md)

    - [翻译: 知识编辑视角下的大型语言模型偏差矫正在知识编辑的视角下，大型语言模型的偏差问题得到了新的关注。通过精细调整模型内部的知识结构，我们能够有效地减少模型在生成内容时产生的偏差，从而提升其公正性和准确性。这一方法不仅为AI伦理提供了新的解决思路，也为构建更加公平、透明的智能系统奠定了基础。](2024年05月15日/Large_Language_Model_Bias_Mitigation_from_the_Perspective_of_Knowledge_Editing.md)

- [Prompting-based Synthetic Data Generation for Few-Shot Question Answering](2024年05月15日/Prompting-based_Synthetic_Data_Generation_for_Few-Shot_Question_Answering.md)

    - [翻译: 利用提示技术生成合成数据，以支持少样本问答任务的训练与应用。](2024年05月15日/Prompting-based_Synthetic_Data_Generation_for_Few-Shot_Question_Answering.md)

- [Transfer Learning in Pre-Trained Large Language Models for Malware Detection Based on System Calls](2024年05月15日/Transfer_Learning_in_Pre-Trained_Large_Language_Models_for_Malware_Detection_Based_on_System_Calls.md)

    - [翻译: 利用预训练大型语言模型的迁移学习技术，本研究探索了基于系统调用的恶意软件检测新途径。通过深入分析系统调用序列，我们旨在揭示恶意软件的隐蔽行为，从而提升检测的准确性与效率。](2024年05月15日/Transfer_Learning_in_Pre-Trained_Large_Language_Models_for_Malware_Detection_Based_on_System_Calls.md)

- [Comparing the Efficacy of GPT-4 and Chat-GPT in Mental Health Care: A Blind Assessment of Large Language Models for Psychological Support](2024年05月15日/Comparing_the_Efficacy_of_GPT-4_and_Chat-GPT_in_Mental_Health_Care_A_Blind_Assessment_of_Large_Language_Models_for_Psychological_Support.md)

    - [翻译: GPT-4与Chat-GPT在心理健康领域的较量：一场关于大型语言模型心理支持能力的盲测评估](2024年05月15日/Comparing_the_Efficacy_of_GPT-4_and_Chat-GPT_in_Mental_Health_Care_A_Blind_Assessment_of_Large_Language_Models_for_Psychological_Support.md)

- [Do language models capture implied discourse meanings? An investigation with exhaustivity implicatures of Korean morphology](2024年05月15日/Do_language_models_capture_implied_discourse_meanings_An_investigation_with_exhaustivity_implicatures_of_Korean_morphology.md)

    - [翻译: 语言模型能否洞察言外之意？本研究深入探讨韩语形态学中的排他性含意，揭示语言模型在理解隐含语篇意义方面的能力。](2024年05月15日/Do_language_models_capture_implied_discourse_meanings_An_investigation_with_exhaustivity_implicatures_of_Korean_morphology.md)

- [Sign of the Times: Evaluating the use of Large Language Models for Idiomaticity Detection](2024年05月15日/Sign_of_the_Times_Evaluating_the_use_of_Large_Language_Models_for_Idiomaticity_Detection.md)

    - [翻译: 时代印记：探究大型语言模型在习语识别领域的应用价值](2024年05月15日/Sign_of_the_Times_Evaluating_the_use_of_Large_Language_Models_for_Idiomaticity_Detection.md)

- [Dynamic Activation Pitfalls in LLaMA Models: An Empirical Study](2024年05月15日/Dynamic_Activation_Pitfalls_in_LLaMA_Models_An_Empirical_Study.md)

    - [翻译: LLaMA模型中的动态激活挑战：一项实证探索在这项研究中，我们深入探讨了LLaMA模型中动态激活机制的潜在问题，并通过一系列实验来揭示这些机制如何影响模型的性能。我们的发现不仅为理解这些复杂模型的内部工作原理提供了新的视角，也为优化和改进这些模型提供了实用的指导。](2024年05月15日/Dynamic_Activation_Pitfalls_in_LLaMA_Models_An_Empirical_Study.md)

- [New Textual Corpora for Serbian Language Modeling](2024年05月15日/New_Textual_Corpora_for_Serbian_Language_Modeling.md)

    - [翻译: 塞尔维亚语语言建模迎来新文本语料库在塞尔维亚语的语言建模领域，一项新的进展正悄然兴起——一套全新的文本语料库被引入，旨在提升语言模型的性能与准确性。这套语料库的诞生，如同春日里绽放的新芽，为塞尔维亚语的研究与应用带来了勃勃生机。它不仅丰富了语言资源的宝库，更为语言学家和AI开发者提供了一片沃土，让他们在这片新天地中，探索语言的奥秘，挖掘智能的潜能。随着这套语料库的广泛应用，我们期待塞尔维亚语的语言模型能够更加精准地捕捉语言的细微差别，更加流畅地与人类交流，开启智能语言处理的新篇章。](2024年05月15日/New_Textual_Corpora_for_Serbian_Language_Modeling.md)

- [Word Alignment as Preference for Machine Translation](2024年05月15日/Word_Alignment_as_Preference_for_Machine_Translation.md)

    - [翻译: 词对齐：机器翻译的偏好之选在机器翻译领域，词对齐被视为一种偏好，它帮助翻译系统更准确地理解源语言与目标语言之间的对应关系。通过精确的词对齐，机器翻译系统能够更好地捕捉语言间的细微差别，从而提升翻译质量。](2024年05月15日/Word_Alignment_as_Preference_for_Machine_Translation.md)

- [Xmodel-VLM: A Simple Baseline for Multimodal Vision Language Model](2024年05月15日/Xmodel-VLM_A_Simple_Baseline_for_Multimodal_Vision_Language_Model.md)

    - [翻译: Xmodel-VLM：多模态视觉语言模型的简洁基线](2024年05月15日/Xmodel-VLM_A_Simple_Baseline_for_Multimodal_Vision_Language_Model.md)

- [HumanRankEval: Automatic Evaluation of LMs as Conversational Assistants](2024年05月15日/HumanRankEval_Automatic_Evaluation_of_LMs_as_Conversational_Assistants.md)

    - [翻译: HumanRankEval：语言模型作为对话助手的自动化评估工具在结果2中，我采用了更加简洁优雅的表达方式，将“Automatic Evaluation of LMs as Conversational Assistants”翻译为“语言模型作为对话助手的自动化评估工具”，这样的翻译更符合中文的表达习惯，同时也保持了原文的意思。](2024年05月15日/HumanRankEval_Automatic_Evaluation_of_LMs_as_Conversational_Assistants.md)

- [Exploring the Potential of Large Language Models for Automation in Technical Customer Service](2024年05月15日/Exploring_the_Potential_of_Large_Language_Models_for_Automation_in_Technical_Customer_Service.md)

    - [翻译: 揭秘大型语言模型：技术客户服务自动化的未来探索](2024年05月15日/Exploring_the_Potential_of_Large_Language_Models_for_Automation_in_Technical_Customer_Service.md)

- [Efficient LLM Jailbreak via Adaptive Dense-to-sparse Constrained Optimization](2024年05月15日/Efficient_LLM_Jailbreak_via_Adaptive_Dense-to-sparse_Constrained_Optimization.md)

    - [翻译: 大型语言模型的巧妙越狱：自适应密集至稀疏约束优化策略](2024年05月15日/Efficient_LLM_Jailbreak_via_Adaptive_Dense-to-sparse_Constrained_Optimization.md)

- [Towards Next-Generation Steganalysis: LLMs Unleash the Power of Detecting Steganography](2024年05月15日/Towards_Next-Generation_Steganalysis_LLMs_Unleash_the_Power_of_Detecting_Steganography.md)

    - [翻译: 迈向新一代隐写分析：大型语言模型揭示检测隐写术的潜能](2024年05月15日/Towards_Next-Generation_Steganalysis_LLMs_Unleash_the_Power_of_Detecting_Steganography.md)

- [Diffusion-based Contrastive Learning for Sequential Recommendation](2024年05月15日/Diffusion-based_Contrastive_Learning_for_Sequential_Recommendation.md)

    - [翻译: 序列推荐中的扩散式对比学习：本研究探索了一种新颖的基于扩散过程的对比学习方法，旨在提升序列推荐的性能。通过模拟信息在序列数据中的传播，该方法能够更有效地捕捉用户行为模式，从而为用户提供更精准的推荐。](2024年05月15日/Diffusion-based_Contrastive_Learning_for_Sequential_Recommendation.md)

- [When AI Eats Itself: On the Caveats of Data Pollution in the Era of Generative AI](2024年05月15日/When_AI_Eats_Itself_On_the_Caveats_of_Data_Pollution_in_the_Era_of_Generative_AI.md)

    - [翻译: AI自噬之忧：生成式AI时代的数据污染警示](2024年05月15日/When_AI_Eats_Itself_On_the_Caveats_of_Data_Pollution_in_the_Era_of_Generative_AI.md)

- [Synthesizing Proteins on the Graphics Card. Protein Folding and the Limits of Critical AI Studies](2024年05月15日/Synthesizing_Proteins_on_the_Graphics_Card._Protein_Folding_and_the_Limits_of_Critical_AI_Studies.md)

    - [翻译: 图形卡上的蛋白质合成：探索蛋白质折叠与人工智能研究的关键极限。本文将深入探讨利用图形处理单元（GPU）进行蛋白质合成的潜力，以及这一过程如何挑战我们对人工智能在生物科学领域应用的理解。](2024年05月15日/Synthesizing_Proteins_on_the_Graphics_Card._Protein_Folding_and_the_Limits_of_Critical_AI_Studies.md)

- [LLM and Simulation as Bilevel Optimizers: A New Paradigm to Advance Physical Scientific Discovery](2024年05月15日/LLM_and_Simulation_as_Bilevel_Optimizers_A_New_Paradigm_to_Advance_Physical_Scientific_Discovery.md)

    - [翻译: 大型语言模型与模拟携手，成为双层优化的新引擎，正开启物理科学探索的崭新篇章。](2024年05月15日/LLM_and_Simulation_as_Bilevel_Optimizers_A_New_Paradigm_to_Advance_Physical_Scientific_Discovery.md)

- [Harmonizing Generalization and Personalization in Federated Prompt Learning](2024年05月15日/Harmonizing_Generalization_and_Personalization_in_Federated_Prompt_Learning.md)

    - [翻译: 在联邦提示学习中寻求泛化与个性化的和谐共舞](2024年05月15日/Harmonizing_Generalization_and_Personalization_in_Federated_Prompt_Learning.md)

- [Optimization Techniques for Sentiment Analysis Based on LLM (GPT-3)](2024年05月15日/Optimization_Techniques_for_Sentiment_Analysis_Based_on_LLM_(GPT-3).md)

    - [翻译: 大型语言模型（GPT-3）情感分析的精进之道](2024年05月15日/Optimization_Techniques_for_Sentiment_Analysis_Based_on_LLM_(GPT-3).md)

- [Evaluating Text-to-Speech Synthesis from a Large Discrete Token-based Speech Language Model](2024年05月15日/Evaluating_Text-to-Speech_Synthesis_from_a_Large_Discrete_Token-based_Speech_Language_Model.md)

    - [翻译: 评测大型离散令牌语音模型下的文本转语音合成技术](2024年05月15日/Evaluating_Text-to-Speech_Synthesis_from_a_Large_Discrete_Token-based_Speech_Language_Model.md)

- [NIFTY Financial News Headlines Dataset](2024年05月15日/NIFTY_Financial_News_Headlines_Dataset.md)

    - [翻译: NIFTY财经新闻头条数据集解释：在](2024年05月15日/NIFTY_Financial_News_Headlines_Dataset.md)

- [Spectral Editing of Activations for Large Language Model Alignment](2024年05月15日/Spectral_Editing_of_Activations_for_Large_Language_Model_Alignment.md)

    - [翻译: 大型语言模型的激活光谱编辑：对齐之道](2024年05月15日/Spectral_Editing_of_Activations_for_Large_Language_Model_Alignment.md)

- [SOK-Bench: A Situated Video Reasoning Benchmark with Aligned Open-World Knowledge](2024年05月15日/SOK-Bench_A_Situated_Video_Reasoning_Benchmark_with_Aligned_Open-World_Knowledge.md)

    - [翻译: SOK-Bench：融合开放世界知识的情景视频推理新标杆](2024年05月15日/SOK-Bench_A_Situated_Video_Reasoning_Benchmark_with_Aligned_Open-World_Knowledge.md)

- [Simulating Policy Impacts: Developing a Generative Scenario Writing Method to Evaluate the Perceived Effects of Regulation](2024年05月15日/Simulating_Policy_Impacts_Developing_a_Generative_Scenario_Writing_Method_to_Evaluate_the_Perceived_Effects_of_Regulation.md)

    - [翻译: 政策效应模拟：创新生成式情景写作法，深度洞察法规影响](2024年05月15日/Simulating_Policy_Impacts_Developing_a_Generative_Scenario_Writing_Method_to_Evaluate_the_Perceived_Effects_of_Regulation.md)

- [LoRA Learns Less and Forgets Less](2024年05月15日/LoRA_Learns_Less_and_Forgets_Less.md)

    - [翻译: LoRA 精简学习，记忆更牢](2024年05月15日/LoRA_Learns_Less_and_Forgets_Less.md)

- [Elements of World Knowledge (EWOK): A cognition-inspired framework for evaluating basic world knowledge in language models](2024年05月15日/Elements_of_World_Knowledge_(EWOK)_A_cognition-inspired_framework_for_evaluating_basic_world_knowledge_in_language_models.md)

    - [翻译: 认知启发的世界知识元素（EWOK）框架，专为评估语言模型中基础世界知识的掌握程度而设计。](2024年05月15日/Elements_of_World_Knowledge_(EWOK)_A_cognition-inspired_framework_for_evaluating_basic_world_knowledge_in_language_models.md)

- [IM-RAG: Multi-Round Retrieval-Augmented Generation Through Learning Inner Monologues](2024年05月15日/IM-RAG_Multi-Round_Retrieval-Augmented_Generation_Through_Learning_Inner_Monologues.md)

    - [翻译: IM-RAG：借助内心独白学习，实现多轮检索增强生成](2024年05月15日/IM-RAG_Multi-Round_Retrieval-Augmented_Generation_Through_Learning_Inner_Monologues.md)

2024年05月14日

- [SciFIBench: Benchmarking Large Multimodal Models for Scientific Figure Interpretation](2024年05月14日/SciFIBench_Benchmarking_Large_Multimodal_Models_for_Scientific_Figure_Interpretation.md)

    - [翻译: SciFIBench：大型多模态模型在科学图表解读领域的性能标杆在科学研究中，图表是传达复杂数据和发现的关键工具。SciFIBench 作为一个创新的基准测试平台，旨在评估和推动大型多模态模型在解读科学图表方面的能力，从而为科学界提供更精准、高效的数据解读工具。](2024年05月14日/SciFIBench_Benchmarking_Large_Multimodal_Models_for_Scientific_Figure_Interpretation.md)

- [Hunyuan-DiT: A Powerful Multi-Resolution Diffusion Transformer with Fine-Grained Chinese Understanding](2024年05月14日/Hunyuan-DiT_A_Powerful_Multi-Resolution_Diffusion_Transformer_with_Fine-Grained_Chinese_Understanding.md)

    - [翻译: Hunyuan-DiT：一款强大的多分辨率扩散Transformer，专为精细中文理解而设计](2024年05月14日/Hunyuan-DiT_A_Powerful_Multi-Resolution_Diffusion_Transformer_with_Fine-Grained_Chinese_Understanding.md)

- [A Comprehensive Survey of Large Language Models and Multimodal Large Language Models in Medicine](2024年05月14日/A_Comprehensive_Survey_of_Large_Language_Models_and_Multimodal_Large_Language_Models_in_Medicine.md)

    - [翻译: 医学领域大型语言模型与多模态模型的全面综述](2024年05月14日/A_Comprehensive_Survey_of_Large_Language_Models_and_Multimodal_Large_Language_Models_in_Medicine.md)

- [Towards Enhanced RAC Accessibility: Leveraging Datasets and LLMs](2024年05月14日/Towards_Enhanced_RAC_Accessibility_Leveraging_Datasets_and_LLMs.md)

    - [翻译: 迈向提升RAC可及性：借助数据集与大型语言模型之力在这篇文章中，我们将探讨如何通过整合数据集和大型语言模型（LLMs）来提高RAC（可能是某种技术或系统的缩写）的可访问性。我们将深入分析这些工具如何协同工作，以简化复杂任务的执行，并使更多人能够利用这些先进的技术。通过这种方式，我们不仅能够推动技术的普及，还能促进创新，让更多人受益于这些强大的资源。](2024年05月14日/Towards_Enhanced_RAC_Accessibility_Leveraging_Datasets_and_LLMs.md)

- [Incorporating Clinical Guidelines through Adapting Multi-modal Large Language Model for Prostate Cancer PI-RADS Scoring](2024年05月14日/Incorporating_Clinical_Guidelines_through_Adapting_Multi-modal_Large_Language_Model_for_Prostate_Cancer_PI-RADS_Scoring.md)

    - [翻译: 融合临床指南：多模态大型语言模型在前列腺癌PI-RADS评分中的应用](2024年05月14日/Incorporating_Clinical_Guidelines_through_Adapting_Multi-modal_Large_Language_Model_for_Prostate_Cancer_PI-RADS_Scoring.md)

- [Is the Pope Catholic? Yes, the Pope is Catholic. Generative Evaluation of Intent Resolution in LLMs](2024年05月14日/Is_the_Pope_Catholic_Yes,_the_Pope_is_Catholic._Generative_Evaluation_of_Intent_Resolution_in_LLMs.md)

    - [翻译: 教皇当然是天主教的，这无需多言。本文聚焦于大型语言模型中意图解析的生成式评估，探讨其在理解用户意图方面的深度与广度。](2024年05月14日/Is_the_Pope_Catholic_Yes,_the_Pope_is_Catholic._Generative_Evaluation_of_Intent_Resolution_in_LLMs.md)

- [Distributed Threat Intelligence at the Edge Devices: A Large Language Model-Driven Approach](2024年05月14日/Distributed_Threat_Intelligence_at_the_Edge_Devices_A_Large_Language_Model-Driven_Approach.md)

    - [翻译: 大型语言模型驱动的边缘设备分布式威胁情报策略在边缘设备上，分布式威胁情报的收集与分析正成为网络安全的新前沿。本文提出了一种基于大型语言模型的创新方法，旨在提升威胁情报的实时处理能力，并增强网络防御的智能化水平。通过这种方法，我们能够更有效地识别和响应潜在的安全威胁，确保网络环境的安全稳定。](2024年05月14日/Distributed_Threat_Intelligence_at_the_Edge_Devices_A_Large_Language_Model-Driven_Approach.md)

- [Promoting AI Equity in Science: Generalized Domain Prompt Learning for Accessible VLM Research](2024年05月14日/Promoting_AI_Equity_in_Science_Generalized_Domain_Prompt_Learning_for_Accessible_VLM_Research.md)

    - [翻译: 推动科学领域的AI公平：普及视觉语言模型研究的泛化领域提示学习方法](2024年05月14日/Promoting_AI_Equity_in_Science_Generalized_Domain_Prompt_Learning_for_Accessible_VLM_Research.md)

- [Thinking Tokens for Language Modeling](2024年05月14日/Thinking_Tokens_for_Language_Modeling.md)

    - [翻译: 语言模型中的思维标记在语言模型中引入思维标记，旨在增强模型的理解和推理能力，使其在处理复杂语言任务时更加精准和高效。这些标记如同智慧的火花，在模型的计算过程中闪烁，引导其深入思考，从而提升了解决问题的能力。](2024年05月14日/Thinking_Tokens_for_Language_Modeling.md)

- [ALMol: Aligned Language-Molecule Translation LLMs through Offline Preference Contrastive Optimisation](2024年05月14日/ALMol_Aligned_Language-Molecule_Translation_LLMs_through_Offline_Preference_Contrastive_Optimisation.md)

    - [翻译: ALMol：借助离线偏好对比优化，实现语言与分子间精准翻译的大型语言模型](2024年05月14日/ALMol_Aligned_Language-Molecule_Translation_LLMs_through_Offline_Preference_Contrastive_Optimisation.md)

- [EVDA: Evolving Deepfake Audio Detection Continual Learning Benchmark](2024年05月14日/EVDA_Evolving_Deepfake_Audio_Detection_Continual_Learning_Benchmark.md)

    - [翻译: EVDA：深度伪造音频检测的进化持续学习基准在结果2中，我采用了更加简洁优雅的表达方式，将“Evolving Deepfake Audio Detection Continual Learning Benchmark”翻译为“深度伪造音频检测的进化持续学习基准”，这样的翻译更加符合中文的表达习惯，同时也保持了原文的意思。](2024年05月14日/EVDA_Evolving_Deepfake_Audio_Detection_Continual_Learning_Benchmark.md)

- [Falcon 7b for Software Mention Detection in Scholarly Documents](2024年05月14日/Falcon_7b_for_Software_Mention_Detection_in_Scholarly_Documents.md)

    - [翻译: Falcon 7b：学术文档中软件提及的精准侦测者在学术文档的浩瀚海洋中，Falcon 7b 如同一位敏锐的侦探，专门负责捕捉那些关于软件的微妙提及。它的任务不仅仅是识别，更是深入理解，确保每一条软件相关的信息都能被准确无误地捕获。](2024年05月14日/Falcon_7b_for_Software_Mention_Detection_in_Scholarly_Documents.md)

- [Archimedes-AUEB at SemEval-2024 Task 5: LLM explains Civil Procedure](2024年05月14日/Archimedes-AUEB_at_SemEval-2024_Task_5_LLM_explains_Civil_Procedure.md)

    - [翻译: Archimedes-AUEB 团队在 SemEval-2024 的第五项任务中，运用大型语言模型（LLM）对民法程序进行了解释。本研究聚焦于利用 LLM 的强大功能，深入剖析民法程序的复杂性，并探索其在法律领域的应用潜力。](2024年05月14日/Archimedes-AUEB_at_SemEval-2024_Task_5_LLM_explains_Civil_Procedure.md)

- [Enhancing Gender-Inclusive Machine Translation with Neomorphemes and Large Language Models](2024年05月14日/Enhancing_Gender-Inclusive_Machine_Translation_with_Neomorphemes_and_Large_Language_Models.md)

    - [翻译: 借助新形态素与大型语言模型，提升机器翻译的性别包容性](2024年05月14日/Enhancing_Gender-Inclusive_Machine_Translation_with_Neomorphemes_and_Large_Language_Models.md)

- [Challenges and Opportunities in Text Generation Explainability](2024年05月14日/Challenges_and_Opportunities_in_Text_Generation_Explainability.md)

    - [翻译: 探索文本生成之谜：挑战与机遇并存](2024年05月14日/Challenges_and_Opportunities_in_Text_Generation_Explainability.md)

- [Evaluating LLMs at Evaluating Temporal Generalization](2024年05月14日/Evaluating_LLMs_at_Evaluating_Temporal_Generalization.md)

    - [翻译: 探究大型语言模型在时间泛化评估中的表现力](2024年05月14日/Evaluating_LLMs_at_Evaluating_Temporal_Generalization.md)

- [Understanding the performance gap between online and offline alignment algorithms](2024年05月14日/Understanding_the_performance_gap_between_online_and_offline_alignment_algorithms.md)

    - [翻译: 探究在线与离线对齐算法性能差异之谜](2024年05月14日/Understanding_the_performance_gap_between_online_and_offline_alignment_algorithms.md)

- [Stylometric Watermarks for Large Language Models](2024年05月14日/Stylometric_Watermarks_for_Large_Language_Models.md)

    - [翻译: 大型语言模型风格水印：为LLM嵌入独特标识，确保内容来源的可追溯性与安全性。](2024年05月14日/Stylometric_Watermarks_for_Large_Language_Models.md)

- [PromptMind Team at MEDIQA-CORR 2024: Improving Clinical Text Correction with Error Categorization and LLM Ensembles](2024年05月14日/PromptMind_Team_at_MEDIQA-CORR_2024_Improving_Clinical_Text_Correction_with_Error_Categorization_and_LLM_Ensembles.md)

    - [翻译: PromptMind 团队在 MEDIQA-CORR 2024 大会上，采用错误分类与大型语言模型集成技术，显著提升了临床文本修正的精准度。](2024年05月14日/PromptMind_Team_at_MEDIQA-CORR_2024_Improving_Clinical_Text_Correction_with_Error_Categorization_and_LLM_Ensembles.md)

- [Seal-Tools: Self-Instruct Tool Learning Dataset for Agent Tuning and Detailed Benchmark](2024年05月14日/Seal-Tools_Self-Instruct_Tool_Learning_Dataset_for_Agent_Tuning_and_Detailed_Benchmark.md)

    - [翻译: 海豹工具集：专为智能体自适应调优与精准基准测试而设计的自指导工具学习数据集](2024年05月14日/Seal-Tools_Self-Instruct_Tool_Learning_Dataset_for_Agent_Tuning_and_Detailed_Benchmark.md)

- [Could Chemical LLMs benefit from Message Passing](2024年05月14日/Could_Chemical_LLMs_benefit_from_Message_Passing.md)

    - [翻译: 化学领域的 LLMs 是否能通过消息传递机制获得性能上的提升？这一问题引发了研究者们的广泛兴趣。消息传递作为一种信息交流的方式，在化学模型中可能扮演着关键角色，影响着模型的理解和预测能力。](2024年05月14日/Could_Chemical_LLMs_benefit_from_Message_Passing.md)

- [SpeechGuard: Exploring the Adversarial Robustness of Multimodal Large Language Models](2024年05月14日/SpeechGuard_Exploring_the_Adversarial_Robustness_of_Multimodal_Large_Language_Models.md)

    - [翻译: 语音卫士：揭秘多模态大型语言模型在对抗攻击下的坚固防线](2024年05月14日/SpeechGuard_Exploring_the_Adversarial_Robustness_of_Multimodal_Large_Language_Models.md)

- [A safety realignment framework via subspace-oriented model fusion for large language models](2024年05月14日/A_safety_realignment_framework_via_subspace-oriented_model_fusion_for_large_language_models.md)

    - [翻译: 大语言模型的安全重构：子空间导向模型融合框架在这个翻译中，我首先直接将英文标题翻译为中文，确保了意思的准确传达。然后，在第二步中，我调整了翻译的结构，使其更加符合中文的表达习惯，同时保持了标题的简洁性和优雅性。通过使用“安全重构”和“子空间导向模型融合框架”这样的术语，标题传达了研究的核心内容，同时保持了专业性和吸引力。](2024年05月14日/A_safety_realignment_framework_via_subspace-oriented_model_fusion_for_large_language_models.md)

- [AMSNet: Netlist Dataset for AMS Circuits](2024年05月14日/AMSNet_Netlist_Dataset_for_AMS_Circuits.md)

    - [翻译: AMSNet：模拟电路网表数据集，专为探索模拟电路设计与分析的深度学习应用而精心打造。](2024年05月14日/AMSNet_Netlist_Dataset_for_AMS_Circuits.md)

- [Contextual Emotion Recognition using Large Vision Language Models](2024年05月14日/Contextual_Emotion_Recognition_using_Large_Vision_Language_Models.md)

    - [翻译: 大型视觉语言模型在上下文情感识别中的应用](2024年05月14日/Contextual_Emotion_Recognition_using_Large_Vision_Language_Models.md)

- [What is it for a Machine Learning Model to Have a Capability?](2024年05月14日/What_is_it_for_a_Machine_Learning_Model_to_Have_a_Capability.md)

    - [翻译: 机器学习模型的能力究竟指何物？这关乎其内在潜能与应用效能的展现。](2024年05月14日/What_is_it_for_a_Machine_Learning_Model_to_Have_a_Capability.md)

- [Challenges in Deploying Long-Context Transformers: A Theoretical Peak Performance Analysis](2024年05月14日/Challenges_in_Deploying_Long-Context_Transformers_A_Theoretical_Peak_Performance_Analysis.md)

    - [翻译: 长上下文Transformer部署之难：理论峰值性能的深度剖析](2024年05月14日/Challenges_in_Deploying_Long-Context_Transformers_A_Theoretical_Peak_Performance_Analysis.md)

- [Self-supervised vision-langage alignment of deep learning representations for bone X-rays analysis](2024年05月14日/Self-supervised_vision-langage_alignment_of_deep_learning_representations_for_bone_X-rays_analysis.md)

    - [翻译: 利用自我监督学习，深度学习模型在视觉与语言层面实现了对骨骼X射线图像的精准对齐，为医学影像分析开辟了新途径。](2024年05月14日/Self-supervised_vision-langage_alignment_of_deep_learning_representations_for_bone_X-rays_analysis.md)

- [Language-Guided Self-Supervised Video Summarization Using Text Semantic Matching Considering the Diversity of the Video](2024年05月14日/Language-Guided_Self-Supervised_Video_Summarization_Using_Text_Semantic_Matching_Considering_the_Diversity_of_the_Video.md)

    - [翻译: 借助文本语义匹配，本研究提出了一种语言引导的自监督视频摘要方法，旨在捕捉视频内容的多样性，从而生成更加丰富和精准的视频摘要。](2024年05月14日/Language-Guided_Self-Supervised_Video_Summarization_Using_Text_Semantic_Matching_Considering_the_Diversity_of_the_Video.md)

- [Large Language Models for Human-Machine Collaborative Particle Accelerator Tuning through Natural Language](2024年05月14日/Large_Language_Models_for_Human-Machine_Collaborative_Particle_Accelerator_Tuning_through_Natural_Language.md)

    - [翻译: 大型语言模型助力人机协作，以自然语言精准调谐粒子加速器](2024年05月14日/Large_Language_Models_for_Human-Machine_Collaborative_Particle_Accelerator_Tuning_through_Natural_Language.md)

- [Automated Repair of AI Code with Large Language Models and Formal Verification](2024年05月14日/Automated_Repair_of_AI_Code_with_Large_Language_Models_and_Formal_Verification.md)

    - [翻译: 大型语言模型与形式验证联手，智能修复AI代码，开启自动化编程新篇章。](2024年05月14日/Automated_Repair_of_AI_Code_with_Large_Language_Models_and_Formal_Verification.md)

- [PromptMind Team at EHRSQL-2024: Improving Reliability of SQL Generation using Ensemble LLMs](2024年05月14日/PromptMind_Team_at_EHRSQL-2024_Improving_Reliability_of_SQL_Generation_using_Ensemble_LLMs.md)

    - [翻译: PromptMind团队在EHRSQL-2024大会上展示了他们如何利用集成大型语言模型（LLMs）来提升SQL生成任务的可靠性。这一创新方法旨在通过结合多个模型的优势，增强生成SQL查询的准确性和稳定性。](2024年05月14日/PromptMind_Team_at_EHRSQL-2024_Improving_Reliability_of_SQL_Generation_using_Ensemble_LLMs.md)

- [When Large Language Models Meet Optical Networks: Paving the Way for Automation](2024年05月14日/When_Large_Language_Models_Meet_Optical_Networks_Paving_the_Way_for_Automation.md)

    - [翻译: 大型语言模型与光网络的结合：开启自动化新篇章](2024年05月14日/When_Large_Language_Models_Meet_Optical_Networks_Paving_the_Way_for_Automation.md)

- [Comuniqa : Exploring Large Language Models for improving speaking skills](2024年05月14日/Comuniqa__Exploring_Large_Language_Models_for_improving_speaking_skills.md)

    - [翻译: Comuniqa：借助大型语言模型，探索口语技能的提升之道](2024年05月14日/Comuniqa__Exploring_Large_Language_Models_for_improving_speaking_skills.md)

2024年05月13日

- [Prompt-based Code Completion via Multi-Retrieval Augmented Generation](2024年05月13日/Prompt-based_Code_Completion_via_Multi-Retrieval_Augmented_Generation.md)

    - [翻译: 基于提示的多重检索增强生成实现代码补全](2024年05月13日/Prompt-based_Code_Completion_via_Multi-Retrieval_Augmented_Generation.md)

- [MS MARCO Web Search: a Large-scale Information-rich Web Dataset with Millions of Real Click Labels](2024年05月13日/MS_MARCO_Web_Search_a_Large-scale_Information-rich_Web_Dataset_with_Millions_of_Real_Click_Labels.md)

    - [翻译: MS MARCO网络搜索：一个汇聚数百万真实用户点击数据的大规模网络信息宝库在](2024年05月13日/MS_MARCO_Web_Search_a_Large-scale_Information-rich_Web_Dataset_with_Millions_of_Real_Click_Labels.md)

- [SambaNova SN40L: Scaling the AI Memory Wall with Dataflow and Composition of Experts](2024年05月13日/SambaNova_SN40L_Scaling_the_AI_Memory_Wall_with_Dataflow_and_Composition_of_Experts.md)

    - [翻译: SambaNova SN40L：以数据流与专家组合之力，突破AI内存壁垒](2024年05月13日/SambaNova_SN40L_Scaling_the_AI_Memory_Wall_with_Dataflow_and_Composition_of_Experts.md)

- [Fine-tuning the SwissBERT Encoder Model for Embedding Sentences and Documents](2024年05月13日/Fine-tuning_the_SwissBERT_Encoder_Model_for_Embedding_Sentences_and_Documents.md)

    - [翻译: 优化瑞士BERT模型，精炼句与文嵌入之艺](2024年05月13日/Fine-tuning_the_SwissBERT_Encoder_Model_for_Embedding_Sentences_and_Documents.md)

- [PromptLink: Leveraging Large Language Models for Cross-Source Biomedical Concept Linking](2024年05月13日/PromptLink_Leveraging_Large_Language_Models_for_Cross-Source_Biomedical_Concept_Linking.md)

    - [翻译: PromptLink：借助大型语言模型实现跨源生物医学概念的精准链接](2024年05月13日/PromptLink_Leveraging_Large_Language_Models_for_Cross-Source_Biomedical_Concept_Linking.md)

- [Oedipus: LLM-enchanced Reasoning CAPTCHA Solver](2024年05月13日/Oedipus_LLM-enchanced_Reasoning_CAPTCHA_Solver.md)

    - [翻译: 俄狄浦斯：大型语言模型加持的推理验证码破解者](2024年05月13日/Oedipus_LLM-enchanced_Reasoning_CAPTCHA_Solver.md)

- [MacBehaviour: An R package for behavioural experimentation on large language models](2024年05月13日/MacBehaviour_An_R_package_for_behavioural_experimentation_on_large_language_models.md)

    - [翻译: MacBehaviour：专为大型语言模型行为实验设计的R包，旨在深入探索语言模型的行为模式与实验应用。](2024年05月13日/MacBehaviour_An_R_package_for_behavioural_experimentation_on_large_language_models.md)

- [Strategic Data Ordering: Enhancing Large Language Model Performance through Curriculum Learning](2024年05月13日/Strategic_Data_Ordering_Enhancing_Large_Language_Model_Performance_through_Curriculum_Learning.md)

    - [翻译: 策略性数据排序：借助课程学习提升大型语言模型的效能在这项研究中，我们探讨了通过精心设计的数据排序策略，即课程学习，来增强大型语言模型性能的方法。课程学习是一种模仿人类教育过程的机器学习方法，它通过逐步增加任务难度来训练模型，从而使模型能够更有效地学习复杂的概念。我们的研究结果表明，合理安排数据顺序可以显著提高模型在各种语言任务中的表现，为优化大型语言模型的训练提供了新的视角。](2024年05月13日/Strategic_Data_Ordering_Enhancing_Large_Language_Model_Performance_through_Curriculum_Learning.md)

- [Integrating Intent Understanding and Optimal Behavior Planning for Behavior Tree Generation from Human Instructions](2024年05月13日/Integrating_Intent_Understanding_and_Optimal_Behavior_Planning_for_Behavior_Tree_Generation_from_Human_Instructions.md)

    - [翻译: 融合意图洞察与行为规划，精妙演绎人类指令至行为树之生成](2024年05月13日/Integrating_Intent_Understanding_and_Optimal_Behavior_Planning_for_Behavior_Tree_Generation_from_Human_Instructions.md)

- [Evaluating large language models in medical applications: a survey](2024年05月13日/Evaluating_large_language_models_in_medical_applications_a_survey.md)

    - [翻译: 大型语言模型在医疗领域的应用评估：一份综述在这份综述中，我们将探讨大型语言模型在医疗领域中的应用，并评估其在不同医疗场景下的表现。通过深入分析，我们旨在揭示这些模型在提升医疗服务质量和效率方面的潜力，以及它们在实际应用中可能面临的挑战。](2024年05月13日/Evaluating_large_language_models_in_medical_applications_a_survey.md)

- [MCS-SQL: Leveraging Multiple Prompts and Multiple-Choice Selection For Text-to-SQL Generation](2024年05月13日/MCS-SQL_Leveraging_Multiple_Prompts_and_Multiple-Choice_Selection_For_Text-to-SQL_Generation.md)

    - [翻译: MCS-SQL：借助多重提示与选择题机制，精妙演绎文本至SQL的生成艺术](2024年05月13日/MCS-SQL_Leveraging_Multiple_Prompts_and_Multiple-Choice_Selection_For_Text-to-SQL_Generation.md)

- [Plot2Code: A Comprehensive Benchmark for Evaluating Multi-modal Large Language Models in Code Generation from Scientific Plots](2024年05月13日/Plot2Code_A_Comprehensive_Benchmark_for_Evaluating_Multi-modal_Large_Language_Models_in_Code_Generation_from_Scientific_Plots.md)

    - [翻译: Plot2Code：科学图表至代码生成的多模态大型语言模型全面评估基准](2024年05月13日/Plot2Code_A_Comprehensive_Benchmark_for_Evaluating_Multi-modal_Large_Language_Models_in_Code_Generation_from_Scientific_Plots.md)

- [A Generalist Learner for Multifaceted Medical Image Interpretation](2024年05月13日/A_Generalist_Learner_for_Multifaceted_Medical_Image_Interpretation.md)

    - [翻译: 医学图像解读的全能学习者](2024年05月13日/A_Generalist_Learner_for_Multifaceted_Medical_Image_Interpretation.md)

- [PyZoBot: A Platform for Conversational Information Extraction and Synthesis from Curated Zotero Reference Libraries through Advanced Retrieval-Augmented Generation](2024年05月13日/PyZoBot_A_Platform_for_Conversational_Information_Extraction_and_Synthesis_from_Curated_Zotero_Reference_Libraries_through_Advanced_Retrieval-Augmented_Generation.md)

    - [翻译: PyZoBot：一个利用高级检索增强生成技术的平台，专为从精心管理的Zotero文献库中提取和整合对话式信息而设计。](2024年05月13日/PyZoBot_A_Platform_for_Conversational_Information_Extraction_and_Synthesis_from_Curated_Zotero_Reference_Libraries_through_Advanced_Retrieval-Augmented_Generation.md)

- [AgentClinic: a multimodal agent benchmark to evaluate AI in simulated clinical environments](2024年05月13日/AgentClinic_a_multimodal_agent_benchmark_to_evaluate_AI_in_simulated_clinical_environments.md)

    - [翻译: AgentClinic：多模态代理基准，专为评估AI在模拟临床环境中的表现而设计。](2024年05月13日/AgentClinic_a_multimodal_agent_benchmark_to_evaluate_AI_in_simulated_clinical_environments.md)

- [EconLogicQA: A Question-Answering Benchmark for Evaluating Large Language Models in Economic Sequential Reasoning](2024年05月13日/EconLogicQA_A_Question-Answering_Benchmark_for_Evaluating_Large_Language_Models_in_Economic_Sequential_Reasoning.md)

    - [翻译: 经济逻辑问答：大型语言模型经济序列推理能力评估的问答基准](2024年05月13日/EconLogicQA_A_Question-Answering_Benchmark_for_Evaluating_Large_Language_Models_in_Economic_Sequential_Reasoning.md)

- [PARDEN, Can You Repeat That? Defending against Jailbreaks via Repetition](2024年05月13日/PARDEN,_Can_You_Repeat_That_Defending_against_Jailbreaks_via_Repetition.md)

    - [翻译: PARDEN，请再说一次？——以重复为盾，抵御越狱之矛](2024年05月13日/PARDEN,_Can_You_Repeat_That_Defending_against_Jailbreaks_via_Repetition.md)

- [Can Better Text Semantics in Prompt Tuning Improve VLM Generalization?](2024年05月13日/Can_Better_Text_Semantics_in_Prompt_Tuning_Improve_VLM_Generalization.md)

    - [翻译: 优化提示调整中的文本语义，是否能增强视觉语言模型的泛化能力？这一问题引发了研究者的浓厚兴趣。](2024年05月13日/Can_Better_Text_Semantics_in_Prompt_Tuning_Improve_VLM_Generalization.md)

- [A Systematic Investigation of Distilling Large Language Models into Cross-Encoders for Passage Re-ranking](2024年05月13日/A_Systematic_Investigation_of_Distilling_Large_Language_Models_into_Cross-Encoders_for_Passage_Re-ranking.md)

    - [翻译: 系统探索：将大型语言模型精炼为跨编码器，以优化段落排序策略](2024年05月13日/A_Systematic_Investigation_of_Distilling_Large_Language_Models_into_Cross-Encoders_for_Passage_Re-ranking.md)

- [RLHF Workflow: From Reward Modeling to Online RLHF](2024年05月13日/RLHF_Workflow_From_Reward_Modeling_to_Online_RLHF.md)

    - [翻译: 强化学习与人类反馈（RLHF）的工作流程：从奖励模型构建到在线RLHF应用，这一流程展示了如何将人类偏好融入机器学习模型中，以优化其行为。](2024年05月13日/RLHF_Workflow_From_Reward_Modeling_to_Online_RLHF.md)

- [Can LLMs Help Predict Elections? (Counter)Evidence from the World's Largest Democracy](2024年05月13日/Can_LLMs_Help_Predict_Elections_(Counter)Evidence_from_the_World's_Largest_Democracy.md)

    - [翻译: 大型语言模型能否洞悉选举风云？世界最大民主国家的实证与反证](2024年05月13日/Can_LLMs_Help_Predict_Elections_(Counter)Evidence_from_the_World's_Largest_Democracy.md)

- [A View of How Language Models Will Transform Law](2024年05月13日/A_View_of_How_Language_Models_Will_Transform_Law.md)

    - [翻译: 语言模型变革法律的展望在这篇文章中，我们将探讨语言模型如何重塑法律领域，分析其潜在的影响和挑战，以及法律专业人士如何适应这一技术变革。](2024年05月13日/A_View_of_How_Language_Models_Will_Transform_Law.md)

- [FreeVA: Offline MLLM as Training-Free Video Assistant](2024年05月13日/FreeVA_Offline_MLLM_as_Training-Free_Video_Assistant.md)

    - [翻译: FreeVA：即刻启用的离线视频助手，基于无需额外训练的多模态大型语言模型技术。](2024年05月13日/FreeVA_Offline_MLLM_as_Training-Free_Video_Assistant.md)

- [Generating Human Motion in 3D Scenes from Text Descriptions](2024年05月13日/Generating_Human_Motion_in_3D_Scenes_from_Text_Descriptions.md)

    - [翻译: 通过文本描述赋予3D场景生命，创造逼真的人体动作。](2024年05月13日/Generating_Human_Motion_in_3D_Scenes_from_Text_Descriptions.md)

- [Synthetic Test Collections for Retrieval Evaluation](2024年05月13日/Synthetic_Test_Collections_for_Retrieval_Evaluation.md)

    - [翻译: 检索评估的合成测试集](2024年05月13日/Synthetic_Test_Collections_for_Retrieval_Evaluation.md)

- [LLM4ED: Large Language Models for Automatic Equation Discovery](2024年05月13日/LLM4ED_Large_Language_Models_for_Automatic_Equation_Discovery.md)

    - [翻译: 大型语言模型助力自动方程发现：LLM4ED在这项研究中，我们探索了大型语言模型（LLM）在自动方程发现（AED）领域的应用，旨在利用LLM的强大能力来辅助科学家和工程师在复杂系统中发现潜在的数学模型。通过深入分析LLM在处理数学表达式和逻辑推理方面的优势，我们提出了一种新颖的框架，该框架能够有效地从数据中提取规律，并生成描述这些规律的数学方程。我们的方法不仅提高了AED的自动化水平，还为解决实际问题提供了新的视角。](2024年05月13日/LLM4ED_Large_Language_Models_for_Automatic_Equation_Discovery.md)

- [LlamaTurk: Adapting Open-Source Generative Large Language Models for Low-Resource Language](2024年05月13日/LlamaTurk_Adapting_Open-Source_Generative_Large_Language_Models_for_Low-Resource_Language.md)

    - [翻译: 骆驼骑士：让开源巨型语言模型适应低资源语言的挑战](2024年05月13日/LlamaTurk_Adapting_Open-Source_Generative_Large_Language_Models_for_Low-Resource_Language.md)

- [OpenLLM-Ro -- Technical Report on Open-source Romanian LLMs trained starting from Llama 2](2024年05月13日/OpenLLM-Ro_--_Technical_Report_on_Open-source_Romanian_LLMs_trained_starting_from_Llama_2.md)

    - [翻译: OpenLLM-Ro技术报告：探索从Llama 2启程的罗马尼亚语开源大型语言模型之旅在这份技术报告中，我们将深入探讨如何从Llama 2这一起点出发，训练出适用于罗马尼亚语的开源大型语言模型。我们将详细分析训练过程中的技术挑战、创新方法以及最终模型的性能表现，旨在为罗马尼亚语的自然语言处理领域带来新的突破。](2024年05月13日/OpenLLM-Ro_--_Technical_Report_on_Open-source_Romanian_LLMs_trained_starting_from_Llama_2.md)

- [Age-Dependent Analysis and Stochastic Generation of Child-Directed Speech](2024年05月13日/Age-Dependent_Analysis_and_Stochastic_Generation_of_Child-Directed_Speech.md)

    - [翻译: 针对儿童言语的年龄相关分析与随机生成在这项研究中，我们探讨了儿童言语的年龄依赖性特征，并开发了一种随机生成模型，旨在更自然地模拟儿童导向的交流方式。通过深入分析不同年龄段儿童的言语特点，我们的模型能够生成更符合儿童理解和接受能力的语言，为儿童语言学习和交流提供了新的工具。](2024年05月13日/Age-Dependent_Analysis_and_Stochastic_Generation_of_Child-Directed_Speech.md)

- [Backdoor Removal for Generative Large Language Models](2024年05月13日/Backdoor_Removal_for_Generative_Large_Language_Models.md)

    - [翻译: 清除生成式大型语言模型的后门隐患](2024年05月13日/Backdoor_Removal_for_Generative_Large_Language_Models.md)

- [DoLLM: How Large Language Models Understanding Network Flow Data to Detect Carpet Bombing DDoS](2024年05月13日/DoLLM_How_Large_Language_Models_Understanding_Network_Flow_Data_to_Detect_Carpet_Bombing_DDoS.md)

    - [翻译: DoLLM：大型语言模型洞察网络流量，精准侦测地毯式轰炸DDoS攻击在这项研究中，我们将探讨大型语言模型（LLM）如何通过分析网络流量数据来识别和防御地毯式轰炸分布式拒绝服务（DDoS）攻击。通过深入研究LLM在处理复杂网络数据时的能力，我们旨在揭示其对于此类攻击模式的识别和响应机制，从而为网络安全领域提供新的防御策略。](2024年05月13日/DoLLM_How_Large_Language_Models_Understanding_Network_Flow_Data_to_Detect_Carpet_Bombing_DDoS.md)

- [AnomalyLLM: Few-shot Anomaly Edge Detection for Dynamic Graphs using Large Language Models](2024年05月13日/AnomalyLLM_Few-shot_Anomaly_Edge_Detection_for_Dynamic_Graphs_using_Large_Language_Models.md)

    - [翻译: AnomalyLLM：大型语言模型助力动态图的少样本异常边缘精准捕捉](2024年05月13日/AnomalyLLM_Few-shot_Anomaly_Edge_Detection_for_Dynamic_Graphs_using_Large_Language_Models.md)

- [COBias and Debias: Minimizing Language Model Pairwise Accuracy Bias via Nonlinear Integer Programming](2024年05月13日/COBias_and_Debias_Minimizing_Language_Model_Pairwise_Accuracy_Bias_via_Nonlinear_Integer_Programming.md)

    - [翻译: 纠偏与去偏：运用非线性整数规划策略，精准校正语言模型中的成对准确性偏差](2024年05月13日/COBias_and_Debias_Minimizing_Language_Model_Pairwise_Accuracy_Bias_via_Nonlinear_Integer_Programming.md)

- [ViWikiFC: Fact-Checking for Vietnamese Wikipedia-Based Textual Knowledge Source](2024年05月13日/ViWikiFC_Fact-Checking_for_Vietnamese_Wikipedia-Based_Textual_Knowledge_Source.md)

    - [翻译: 越南维基事实核查：为越南语维基百科文本知识源提供精准事实检验](2024年05月13日/ViWikiFC_Fact-Checking_for_Vietnamese_Wikipedia-Based_Textual_Knowledge_Source.md)

- [DynLLM: When Large Language Models Meet Dynamic Graph Recommendation](2024年05月13日/DynLLM_When_Large_Language_Models_Meet_Dynamic_Graph_Recommendation.md)

    - [翻译: 动态巨型语言模型：大型语言模型与动态图推荐之交融](2024年05月13日/DynLLM_When_Large_Language_Models_Meet_Dynamic_Graph_Recommendation.md)

- [Coding historical causes of death data with Large Language Models](2024年05月13日/Coding_historical_causes_of_death_data_with_Large_Language_Models.md)

    - [翻译: 借助大型语言模型，我们能够对历史死亡数据进行精细编码，揭示过去岁月中生命消逝的种种原因。这一过程不仅是对数据的整理，更是对历史的一次深刻回望。](2024年05月13日/Coding_historical_causes_of_death_data_with_Large_Language_Models.md)

- [MuMath-Code: Combining Tool-Use Large Language Models with Multi-perspective Data Augmentation for Mathematical Reasoning](2024年05月13日/MuMath-Code_Combining_Tool-Use_Large_Language_Models_with_Multi-perspective_Data_Augmentation_for_Mathematical_Reasoning.md)

    - [翻译: MuMath-Code：融合大型语言模型的工具运用与多角度数据扩充，以提升数学推理能力](2024年05月13日/MuMath-Code_Combining_Tool-Use_Large_Language_Models_with_Multi-perspective_Data_Augmentation_for_Mathematical_Reasoning.md)

- [EMS-SD: Efficient Multi-sample Speculative Decoding for Accelerating Large Language Models](2024年05月13日/EMS-SD_Efficient_Multi-sample_Speculative_Decoding_for_Accelerating_Large_Language_Models.md)

    - [翻译: EMS-SD：加速大型语言模型的利器——高效多样本推测解码技术](2024年05月13日/EMS-SD_Efficient_Multi-sample_Speculative_Decoding_for_Accelerating_Large_Language_Models.md)

- [TANQ: An open domain dataset of table answered questions](2024年05月13日/TANQ_An_open_domain_dataset_of_table_answered_questions.md)

    - [翻译: TANQ：探索开放领域，揭秘表格之谜——一个专为回答问题而生的数据集。](2024年05月13日/TANQ_An_open_domain_dataset_of_table_answered_questions.md)

- [HoneyBee: A Scalable Modular Framework for Creating Multimodal Oncology Datasets with Foundational Embedding Models](2024年05月13日/HoneyBee_A_Scalable_Modular_Framework_for_Creating_Multimodal_Oncology_Datasets_with_Foundational_Embedding_Models.md)

    - [翻译: 蜜蜂计划：一个基于基础嵌入模型的可扩展模块化框架，专为构建多模态肿瘤学数据集而设计。](2024年05月13日/HoneyBee_A_Scalable_Modular_Framework_for_Creating_Multimodal_Oncology_Datasets_with_Foundational_Embedding_Models.md)

- [SpeechVerse: A Large-scale Generalizable Audio Language Model](2024年05月13日/SpeechVerse_A_Large-scale_Generalizable_Audio_Language_Model.md)

    - [翻译: SpeechVerse：一款大规模且具备广泛适用性的语音语言模型](2024年05月13日/SpeechVerse_A_Large-scale_Generalizable_Audio_Language_Model.md)

- [VS-Assistant: Versatile Surgery Assistant on the Demand of Surgeons](2024年05月13日/VS-Assistant_Versatile_Surgery_Assistant_on_the_Demand_of_Surgeons.md)

    - [翻译: VS助手：外科医生的得力助手，满足多样化的手术需求](2024年05月13日/VS-Assistant_Versatile_Surgery_Assistant_on_the_Demand_of_Surgeons.md)

- [Compositional Text-to-Image Generation with Dense Blob Representations](2024年05月13日/Compositional_Text-to-Image_Generation_with_Dense_Blob_Representations.md)

    - [翻译: 利用密集斑点表示实现文本至图像的组合生成](2024年05月13日/Compositional_Text-to-Image_Generation_with_Dense_Blob_Representations.md)

- [Silver-Tongued and Sundry: Exploring Intersectional Pronouns with ChatGPT](2024年05月13日/Silver-Tongued_and_Sundry_Exploring_Intersectional_Pronouns_with_ChatGPT.md)

    - [翻译: 巧舌如银，代词交织：与ChatGPT一同探索多元身份的代词世界](2024年05月13日/Silver-Tongued_and_Sundry_Exploring_Intersectional_Pronouns_with_ChatGPT.md)

- [An information-theoretic model of shallow and deep language comprehension](2024年05月13日/An_information-theoretic_model_of_shallow_and_deep_language_comprehension.md)

    - [翻译: 浅层与深层语言理解的信息理论模型](2024年05月13日/An_information-theoretic_model_of_shallow_and_deep_language_comprehension.md)

- [Toward Automated Programming for Robotic Assembly Using ChatGPT](2024年05月13日/Toward_Automated_Programming_for_Robotic_Assembly_Using_ChatGPT.md)

    - [翻译: 借助ChatGPT，探索机器人装配编程的自动化之路](2024年05月13日/Toward_Automated_Programming_for_Robotic_Assembly_Using_ChatGPT.md)

- [Interpreting Latent Student Knowledge Representations in Programming Assignments](2024年05月13日/Interpreting_Latent_Student_Knowledge_Representations_in_Programming_Assignments.md)

    - [翻译: 揭示编程作业中学生潜在知识的内在表征](2024年05月13日/Interpreting_Latent_Student_Knowledge_Representations_in_Programming_Assignments.md)

- [LLM Theory of Mind and Alignment: Opportunities and Risks](2024年05月13日/LLM_Theory_of_Mind_and_Alignment_Opportunities_and_Risks.md)

    - [翻译: 大型语言模型（LLM）的心智理论与对齐：探索机遇与警惕风险](2024年05月13日/LLM_Theory_of_Mind_and_Alignment_Opportunities_and_Risks.md)

- [Benchmarking Retrieval-Augmented Large Language Models in Biomedical NLP: Application, Robustness, and Self-Awareness](2024年05月13日/Benchmarking_Retrieval-Augmented_Large_Language_Models_in_Biomedical_NLP_Application,_Robustness,_and_Self-Awareness.md)

    - [翻译: 生物医学 NLP 中检索增强 LLM 的基准测试：应用、鲁棒性与自我认知在生物医学自然语言处理领域，检索增强的大型语言模型（LLM）正逐渐成为研究的热点。这些模型通过结合检索机制，能够更有效地处理和理解复杂的生物医学信息。本文将探讨这些模型在实际应用中的表现，以及它们在面对不同数据集和任务时的鲁棒性。此外，我们还将研究这些模型如何通过自我意识机制来评估和优化其性能，从而在生物医学 NLP 领域中发挥更大的作用。](2024年05月13日/Benchmarking_Retrieval-Augmented_Large_Language_Models_in_Biomedical_NLP_Application,_Robustness,_and_Self-Awareness.md)

- [Many-Shot Regurgitation (MSR) Prompting](2024年05月13日/Many-Shot_Regurgitation_(MSR)_Prompting.md)

    - [翻译: 多示例复述（MSR）提示法](2024年05月13日/Many-Shot_Regurgitation_(MSR)_Prompting.md)

- [From Questions to Insightful Answers: Building an Informed Chatbot for University Resources](2024年05月13日/From_Questions_to_Insightful_Answers_Building_an_Informed_Chatbot_for_University_Resources.md)

    - [翻译: 打造智慧之桥：构建一款洞悉大学资源的智能聊天机器人，将疑问转化为深刻解答。](2024年05月13日/From_Questions_to_Insightful_Answers_Building_an_Informed_Chatbot_for_University_Resources.md)

- [Layout Generation Agents with Large Language Models](2024年05月13日/Layout_Generation_Agents_with_Large_Language_Models.md)

    - [翻译: 大型语言模型赋能的布局生成智能体](2024年05月13日/Layout_Generation_Agents_with_Large_Language_Models.md)

- [Control Token with Dense Passage Retrieval](2024年05月13日/Control_Token_with_Dense_Passage_Retrieval.md)

    - [翻译: 通过密集段落检索优化令牌控制](2024年05月13日/Control_Token_with_Dense_Passage_Retrieval.md)

- [METAREFLECTION: Learning Instructions for Language Agents using Past Reflections](2024年05月13日/METAREFLECTION_Learning_Instructions_for_Language_Agents_using_Past_Reflections.md)

    - [翻译: METAREFLECTION：借助过往反思，精炼语言代理指令](2024年05月13日/METAREFLECTION_Learning_Instructions_for_Language_Agents_using_Past_Reflections.md)

2024年05月12日

- [CLIP-Powered TASS: Target-Aware Single-Stream Network for Audio-Visual Question Answering](2024年05月12日/CLIP-Powered_TASS_Target-Aware_Single-Stream_Network_for_Audio-Visual_Question_Answering.md)

    - [翻译: CLIP赋能的TASS：一种专为视听问答设计的目标感知单流网络，它巧妙地融合了视觉和听觉信息，以精准解答跨模态问题。](2024年05月12日/CLIP-Powered_TASS_Target-Aware_Single-Stream_Network_for_Audio-Visual_Question_Answering.md)

- [From traces to measures: Large language models as a tool for psychological measurement from text](2024年05月12日/From_traces_to_measures_Large_language_models_as_a_tool_for_psychological_measurement_from_text.md)

    - [翻译: 大型语言模型：文本心理测量的利器，从细微痕迹到精准测量。](2024年05月12日/From_traces_to_measures_Large_language_models_as_a_tool_for_psychological_measurement_from_text.md)

- [Can Language Models Explain Their Own Classification Behavior?](2024年05月12日/Can_Language_Models_Explain_Their_Own_Classification_Behavior.md)

    - [翻译: 语言模型是否具备自我解释其分类决策的能力？这一问题引发了对于模型透明度和可解释性的深入探讨。](2024年05月12日/Can_Language_Models_Explain_Their_Own_Classification_Behavior.md)

- [Don't Chase Your Tail! Missing Key Aspects Augmentation in Textual Vulnerability Descriptions of Long-tail Software through Feature Inference](2024年05月12日/Don't_Chase_Your_Tail!_Missing_Key_Aspects_Augmentation_in_Textual_Vulnerability_Descriptions_of_Long-tail_Software_through_Feature_Inference.md)

    - [翻译: 别做无用功！通过特征推断填补长尾软件漏洞描述中的空白，揭示关键缺失要素。](2024年05月12日/Don't_Chase_Your_Tail!_Missing_Key_Aspects_Augmentation_in_Textual_Vulnerability_Descriptions_of_Long-tail_Software_through_Feature_Inference.md)

- [Identifying Hate Speech Peddlers in Online Platforms. A Bayesian Social Learning Approach for Large Language Model Driven Decision-Makers](2024年05月12日/Identifying_Hate_Speech_Peddlers_in_Online_Platforms._A_Bayesian_Social_Learning_Approach_for_Large_Language_Model_Driven_Decision-Makers.md)

    - [翻译: 利用大型语言模型，采用贝叶斯社会学习策略，精准识别网络平台上的仇恨言论传播者，为决策者提供有力支持。](2024年05月12日/Identifying_Hate_Speech_Peddlers_in_Online_Platforms._A_Bayesian_Social_Learning_Approach_for_Large_Language_Model_Driven_Decision-Makers.md)

- [MedConceptsQA -- Open Source Medical Concepts QA Benchmark](2024年05月12日/MedConceptsQA_--_Open_Source_Medical_Concepts_QA_Benchmark.md)

    - [翻译: MedConceptsQA - 开源医学概念问答标杆，旨在为医学领域的知识问答提供一个公开、可验证的评估平台。](2024年05月12日/MedConceptsQA_--_Open_Source_Medical_Concepts_QA_Benchmark.md)

- [Learnable Tokenizer for LLM-based Generative Recommendation](2024年05月12日/Learnable_Tokenizer_for_LLM-based_Generative_Recommendation.md)

    - [翻译: 大型语言模型生成推荐的可学习分词器](2024年05月12日/Learnable_Tokenizer_for_LLM-based_Generative_Recommendation.md)

- [Human-interpretable clustering of short-text using large language models](2024年05月12日/Human-interpretable_clustering_of_short-text_using_large_language_models.md)

    - [翻译: 大型语言模型助力短文本聚类，实现人类可理解的分析](2024年05月12日/Human-interpretable_clustering_of_short-text_using_large_language_models.md)

- [Limited Ability of LLMs to Simulate Human Psychological Behaviours: a Psychometric Analysis](2024年05月12日/Limited_Ability_of_LLMs_to_Simulate_Human_Psychological_Behaviours_a_Psychometric_Analysis.md)

    - [翻译: 大型语言模型在模拟人类心理行为方面显露局限：心理测量视角下的深度剖析](2024年05月12日/Limited_Ability_of_LLMs_to_Simulate_Human_Psychological_Behaviours_a_Psychometric_Analysis.md)

- [MM-InstructEval: Zero-Shot Evaluation of (Multimodal) Large Language Models on Multimodal Reasoning Tasks](2024年05月12日/MM-InstructEval_Zero-Shot_Evaluation_of_(Multimodal)_Large_Language_Models_on_Multimodal_Reasoning_Tasks.md)

    - [翻译: MM-InstructEval：大型多模态语言模型在多模态推理任务上的零-shot性能评估在这项研究中，我们引入了 MM-InstructEval，这是一个用于评估大型多模态语言模型在多模态推理任务上的零-shot性能的框架。通过这个框架，我们旨在探索这些模型在无需额外训练的情况下，如何理解和处理结合了文本和视觉信息的多模态输入，并执行复杂的推理任务。我们的目标是提供一个全面的评估工具，以揭示这些先进模型在多模态环境下的实际能力和潜在局限性。](2024年05月12日/MM-InstructEval_Zero-Shot_Evaluation_of_(Multimodal)_Large_Language_Models_on_Multimodal_Reasoning_Tasks.md)

- [Enhancing Decision-Making in Optimization through LLM-Assisted Inference: A Neural Networks Perspective](2024年05月12日/Enhancing_Decision-Making_in_Optimization_through_LLM-Assisted_Inference_A_Neural_Networks_Perspective.md)

    - [翻译: 借助大型语言模型辅助推理，优化决策更上一层楼：神经网络视角下的探索](2024年05月12日/Enhancing_Decision-Making_in_Optimization_through_LLM-Assisted_Inference_A_Neural_Networks_Perspective.md)

- [Unified Video-Language Pre-training with Synchronized Audio](2024年05月12日/Unified_Video-Language_Pre-training_with_Synchronized_Audio.md)

    - [翻译: 同步音频下的视频与语言一体化预训练](2024年05月12日/Unified_Video-Language_Pre-training_with_Synchronized_Audio.md)

- [Differentiable Model Scaling using Differentiable Topk](2024年05月12日/Differentiable_Model_Scaling_using_Differentiable_Topk.md)

    - [翻译: 利用可微分Topk实现模型参数的灵活缩放，这一技术为模型优化提供了新的维度，使得模型在保持性能的同时，能够更加适应不同的计算资源和应用场景。](2024年05月12日/Differentiable_Model_Scaling_using_Differentiable_Topk.md)

- [Learning Reward for Robot Skills Using Large Language Models via Self-Alignment](2024年05月12日/Learning_Reward_for_Robot_Skills_Using_Large_Language_Models_via_Self-Alignment.md)

    - [翻译: 借助大型语言模型的自我对齐，我们探索了如何为机器人技能学习赋予奖励，这一创新方法旨在提升机器人在复杂任务中的自主学习能力。](2024年05月12日/Learning_Reward_for_Robot_Skills_Using_Large_Language_Models_via_Self-Alignment.md)

- [Evaluation of Retrieval-Augmented Generation: A Survey](2024年05月12日/Evaluation_of_Retrieval-Augmented_Generation_A_Survey.md)

    - [翻译: 检索增强生成评估综述：本调查旨在深入探讨检索增强生成技术的评估方法，分析其在不同应用场景下的表现，并探讨如何优化这一技术以提升生成内容的质量和相关性。](2024年05月12日/Evaluation_of_Retrieval-Augmented_Generation_A_Survey.md)

- [A LLM-based Controllable, Scalable, Human-Involved User Simulator Framework for Conversational Recommender Systems](2024年05月12日/A_LLM-based_Controllable,_Scalable,_Human-Involved_User_Simulator_Framework_for_Conversational_Recommender_Systems.md)

    - [翻译: 大型语言模型驱动的对话推荐系统用户模拟器框架：可控、可扩展且融入人类智慧在](2024年05月12日/A_LLM-based_Controllable,_Scalable,_Human-Involved_User_Simulator_Framework_for_Conversational_Recommender_Systems.md)

- [Medical Research as a Productivity Indicator](2024年05月12日/Medical_Research_as_a_Productivity_Indicator.md)

    - [翻译: 医学研究：衡量生产力的标尺](2024年05月12日/Medical_Research_as_a_Productivity_Indicator.md)

- [ExplainableDetector: Exploring Transformer-based Language Modeling Approach for SMS Spam Detection with Explainability Analysis](2024年05月12日/ExplainableDetector_Exploring_Transformer-based_Language_Modeling_Approach_for_SMS_Spam_Detection_with_Explainability_Analysis.md)

    - [翻译: 可解释性检测器：探究基于Transformer的语言模型在短信垃圾邮件检测中的应用，并结合可解释性分析，以揭示模型决策的内在机制。](2024年05月12日/ExplainableDetector_Exploring_Transformer-based_Language_Modeling_Approach_for_SMS_Spam_Detection_with_Explainability_Analysis.md)

- [DuetRAG: Collaborative Retrieval-Augmented Generation](2024年05月12日/DuetRAG_Collaborative_Retrieval-Augmented_Generation.md)

    - [翻译: DuetRAG：协同检索增强生成技术](2024年05月12日/DuetRAG_Collaborative_Retrieval-Augmented_Generation.md)

2024年05月11日

- [Edge Intelligence Optimization for Large Language Model Inference with Batching and Quantization](2024年05月11日/Edge_Intelligence_Optimization_for_Large_Language_Model_Inference_with_Batching_and_Quantization.md)

    - [翻译: 大型语言模型推理的边缘智能优化：通过批处理与量化技术提升效率。](2024年05月11日/Edge_Intelligence_Optimization_for_Large_Language_Model_Inference_with_Batching_and_Quantization.md)

- [Combining multiple post-training techniques to achieve most efficient quantized LLMs](2024年05月11日/Combining_multiple_post-training_techniques_to_achieve_most_efficient_quantized_LLMs.md)

    - [翻译: 融合多重后训练技艺，铸就量化大型语言模型的极致效能](2024年05月11日/Combining_multiple_post-training_techniques_to_achieve_most_efficient_quantized_LLMs.md)

- [Designing and Evaluating Dialogue LLMs for Co-Creative Improvised Theatre](2024年05月11日/Designing_and_Evaluating_Dialogue_LLMs_for_Co-Creative_Improvised_Theatre.md)

    - [翻译: 打造与评测共创即兴戏剧的对话式LLM](2024年05月11日/Designing_and_Evaluating_Dialogue_LLMs_for_Co-Creative_Improvised_Theatre.md)

- [Advanced Natural-based interaction for the ITAlian language: LLaMAntino-3-ANITA](2024年05月11日/Advanced_Natural-based_interaction_for_the_ITAlian_language_LLaMAntino-3-ANITA.md)

    - [翻译: 意大利语的先进自然交互技术：LLaMAntino-3-ANITA](2024年05月11日/Advanced_Natural-based_interaction_for_the_ITAlian_language_LLaMAntino-3-ANITA.md)

- [MUD: Towards a Large-Scale and Noise-Filtered UI Dataset for Modern Style UI Modeling](2024年05月11日/MUD_Towards_a_Large-Scale_and_Noise-Filtered_UI_Dataset_for_Modern_Style_UI_Modeling.md)

    - [翻译: MUD：构建大规模且去噪的现代风格UI模型数据集在这项研究中，我们提出了MUD，一个旨在为现代风格UI模型提供大规模且经过噪声过滤的UI数据集。通过精心设计的去噪机制，MUD确保了数据的质量，为UI模型的训练和评估提供了坚实的基础。我们的目标是推动UI设计领域的进步，使得模型能够更好地理解和生成符合现代审美的用户界面。](2024年05月11日/MUD_Towards_a_Large-Scale_and_Noise-Filtered_UI_Dataset_for_Modern_Style_UI_Modeling.md)

- [SonifyAR: Context-Aware Sound Generation in Augmented Reality](2024年05月11日/SonifyAR_Context-Aware_Sound_Generation_in_Augmented_Reality.md)

    - [翻译: SonifyAR：在增强现实中，声音生成技术能够感知并适应环境，为用户带来沉浸式的听觉体验。](2024年05月11日/SonifyAR_Context-Aware_Sound_Generation_in_Augmented_Reality.md)

- [Integrating Emotional and Linguistic Models for Ethical Compliance in Large Language Models](2024年05月11日/Integrating_Emotional_and_Linguistic_Models_for_Ethical_Compliance_in_Large_Language_Models.md)

    - [翻译: 融合情感与语言模型，确保大型语言模型的伦理遵循在这项研究中，我们探讨了如何将情感分析与语言处理技术相结合，以提升大型语言模型在伦理合规方面的表现。通过这种整合，我们旨在确保人工智能在交流时不仅传达准确的信息，而且能够体现出对用户情感的敏感性和尊重，从而在伦理层面上达到更高的标准。](2024年05月11日/Integrating_Emotional_and_Linguistic_Models_for_Ethical_Compliance_in_Large_Language_Models.md)

- [LogoMotion: Visually Grounded Code Generation for Content-Aware Animation](2024年05月11日/LogoMotion_Visually_Grounded_Code_Generation_for_Content-Aware_Animation.md)

    - [翻译: LogoMotion：视觉启发的代码生成，赋予动画内容感知能力](2024年05月11日/LogoMotion_Visually_Grounded_Code_Generation_for_Content-Aware_Animation.md)

- [LLMs and the Future of Chip Design: Unveiling Security Risks and Building Trust](2024年05月11日/LLMs_and_the_Future_of_Chip_Design_Unveiling_Security_Risks_and_Building_Trust.md)

    - [翻译: 大型语言模型与芯片设计未来：揭秘安全隐忧，构筑信任基石](2024年05月11日/LLMs_and_the_Future_of_Chip_Design_Unveiling_Security_Risks_and_Building_Trust.md)

- [Memory-Maze: Scenario Driven Benchmark and Visual Language Navigation Model for Guiding Blind People](2024年05月11日/Memory-Maze_Scenario_Driven_Benchmark_and_Visual_Language_Navigation_Model_for_Guiding_Blind_People.md)

    - [翻译: 记忆迷宫：专为盲人设计的情景驱动基准与视觉语言导航模型，旨在通过模拟真实环境挑战，提升导航辅助技术的精准性与实用性。](2024年05月11日/Memory-Maze_Scenario_Driven_Benchmark_and_Visual_Language_Navigation_Model_for_Guiding_Blind_People.md)

- [Retrieval Enhanced Zero-Shot Video Captioning](2024年05月11日/Retrieval_Enhanced_Zero-Shot_Video_Captioning.md)

    - [翻译: 零-shot视频字幕生成通过检索增强技术得到提升，本研究探索了如何利用检索机制来优化视频内容的自动描述过程。](2024年05月11日/Retrieval_Enhanced_Zero-Shot_Video_Captioning.md)

- [A Turkish Educational Crossword Puzzle](2024年05月11日/A_Turkish_Educational_Crossword_Puzzle.md)

    - [翻译: 土耳其益智教育填字游戏解释：在](2024年05月11日/A_Turkish_Educational_Crossword_Puzzle.md)

- [Evaluating Task-based Effectiveness of MLLMs on Charts](2024年05月11日/Evaluating_Task-based_Effectiveness_of_MLLMs_on_Charts.md)

    - [翻译: 探究多模态大型语言模型在图表任务中的实际效能。](2024年05月11日/Evaluating_Task-based_Effectiveness_of_MLLMs_on_Charts.md)

- [Large Language Model-aided Edge Learning in Distribution System State Estimation](2024年05月11日/Large_Language_Model-aided_Edge_Learning_in_Distribution_System_State_Estimation.md)

    - [翻译: 借助大型语言模型，边缘学习在配电系统状态估计中展现出新的活力，为电力系统的智能化管理提供了强有力的技术支撑。](2024年05月11日/Large_Language_Model-aided_Edge_Learning_in_Distribution_System_State_Estimation.md)

- [Quite Good, but Not Enough: Nationality Bias in Large Language Models -- A Case Study of ChatGPT](2024年05月11日/Quite_Good,_but_Not_Enough_Nationality_Bias_in_Large_Language_Models_--_A_Case_Study_of_ChatGPT.md)

    - [翻译: 尚可但不足：探究大型语言模型中的国籍偏见——以ChatGPT为例](2024年05月11日/Quite_Good,_but_Not_Enough_Nationality_Bias_in_Large_Language_Models_--_A_Case_Study_of_ChatGPT.md)

- [Identifying Key Terms in Prompts for Relevance Evaluation with GPT Models](2024年05月11日/Identifying_Key_Terms_in_Prompts_for_Relevance_Evaluation_with_GPT_Models.md)

    - [翻译: 在利用GPT模型评估相关性时，精准捕捉提示中的关键术语至关重要。本研究聚焦于如何有效地识别这些关键术语，以提升模型在相关性评估中的准确性和效率。](2024年05月11日/Identifying_Key_Terms_in_Prompts_for_Relevance_Evaluation_with_GPT_Models.md)

- [Automating Thematic Analysis: How LLMs Analyse Controversial Topics](2024年05月11日/Automating_Thematic_Analysis_How_LLMs_Analyse_Controversial_Topics.md)

    - [翻译: 大型语言模型在争议话题分析中的自动化探索在上述翻译过程中，](2024年05月11日/Automating_Thematic_Analysis_How_LLMs_Analyse_Controversial_Topics.md)

- [CoRE: LLM as Interpreter for Natural Language Programming, Pseudo-Code Programming, and Flow Programming of AI Agents](2024年05月11日/CoRE_LLM_as_Interpreter_for_Natural_Language_Programming,_Pseudo-Code_Programming,_and_Flow_Programming_of_AI_Agents.md)

    - [翻译: CoRE：大型语言模型——AI代理自然语言编程、伪代码编程与流程编程的智慧之钥](2024年05月11日/CoRE_LLM_as_Interpreter_for_Natural_Language_Programming,_Pseudo-Code_Programming,_and_Flow_Programming_of_AI_Agents.md)

- [Translating Expert Intuition into Quantifiable Features: Encode Investigator Domain Knowledge via LLM for Enhanced Predictive Analytics](2024年05月11日/Translating_Expert_Intuition_into_Quantifiable_Features_Encode_Investigator_Domain_Knowledge_via_LLM_for_Enhanced_Predictive_Analytics.md)

    - [翻译: 借助 LLM，我们将专家的直觉转化为精确的量化特征，从而将调查员的领域知识融入预测分析，进一步提升其精准度。](2024年05月11日/Translating_Expert_Intuition_into_Quantifiable_Features_Encode_Investigator_Domain_Knowledge_via_LLM_for_Enhanced_Predictive_Analytics.md)

2024年05月10日

- [Linearizing Large Language Models](2024年05月10日/Linearizing_Large_Language_Models.md)

    - [翻译: 大型语言模型的线性化](2024年05月10日/Linearizing_Large_Language_Models.md)

- [Value Augmented Sampling for Language Model Alignment and Personalization](2024年05月10日/Value_Augmented_Sampling_for_Language_Model_Alignment_and_Personalization.md)

    - [翻译: 语言模型的价值增强采样：对齐与个性化之道](2024年05月10日/Value_Augmented_Sampling_for_Language_Model_Alignment_and_Personalization.md)

- [Characterizing the Accuracy - Efficiency Trade-off of Low-rank Decomposition in Language Models](2024年05月10日/Characterizing_the_Accuracy_-_Efficiency_Trade-off_of_Low-rank_Decomposition_in_Language_Models.md)

    - [翻译: 语言模型中低秩分解的精效平衡探析](2024年05月10日/Characterizing_the_Accuracy_-_Efficiency_Trade-off_of_Low-rank_Decomposition_in_Language_Models.md)

- [What Can Natural Language Processing Do for Peer Review?](2024年05月10日/What_Can_Natural_Language_Processing_Do_for_Peer_Review.md)

    - [翻译: 自然语言处理如何助力同行评审？](2024年05月10日/What_Can_Natural_Language_Processing_Do_for_Peer_Review.md)

- [Mitigating Hallucinations in Large Language Models via Self-Refinement-Enhanced Knowledge Retrieval](2024年05月10日/Mitigating_Hallucinations_in_Large_Language_Models_via_Self-Refinement-Enhanced_Knowledge_Retrieval.md)

    - [翻译: 借助自精细化知识检索，大型语言模型幻觉得以缓解](2024年05月10日/Mitigating_Hallucinations_in_Large_Language_Models_via_Self-Refinement-Enhanced_Knowledge_Retrieval.md)

- [Prompting Large Language Models with Knowledge Graphs for Question Answering Involving Long-tail Facts](2024年05月10日/Prompting_Large_Language_Models_with_Knowledge_Graphs_for_Question_Answering_Involving_Long-tail_Facts.md)

    - [翻译: 借助知识图谱，激发大型语言模型解答长尾事实相关问题](2024年05月10日/Prompting_Large_Language_Models_with_Knowledge_Graphs_for_Question_Answering_Involving_Long-tail_Facts.md)

- [UniDM: A Unified Framework for Data Manipulation with Large Language Models](2024年05月10日/UniDM_A_Unified_Framework_for_Data_Manipulation_with_Large_Language_Models.md)

    - [翻译: UniDM：大型语言模型数据操作的统一之桥在人工智能的浩瀚星空中，UniDM犹如一座横跨数据与智慧的桥梁，以其统一之姿，将大型语言模型的数据操作能力汇聚于一点。它不仅是一套框架，更是一种艺术，一种将数据的纷繁复杂转化为模型智慧的精湛技艺。在这个框架下，数据的每一次舞动，都仿佛在诉说着与模型深度对话的故事，引领我们探索数据科学的无限可能。](2024年05月10日/UniDM_A_Unified_Framework_for_Data_Manipulation_with_Large_Language_Models.md)

- [Storypark: Leveraging Large Language Models to Enhance Children Story Learning Through Child-AI collaboration Storytelling](2024年05月10日/Storypark_Leveraging_Large_Language_Models_to_Enhance_Children_Story_Learning_Through_Child-AI_collaboration_Storytelling.md)

    - [翻译: Storypark：借助大型语言模型的力量，通过儿童与AI的协作讲故事，提升儿童的故事学习体验。](2024年05月10日/Storypark_Leveraging_Large_Language_Models_to_Enhance_Children_Story_Learning_Through_Child-AI_collaboration_Storytelling.md)

- [ProCIS: A Benchmark for Proactive Retrieval in Conversations](2024年05月10日/ProCIS_A_Benchmark_for_Proactive_Retrieval_in_Conversations.md)

    - [翻译: ProCIS：对话主动检索的标杆在这篇文章中，我们将介绍ProCIS，这是一个专为对话中主动检索设计的基准。它旨在评估和推动对话系统在主动检索信息方面的能力，以提高交互的自然性和效率。通过ProCIS，研究者可以更好地理解和改进对话系统在处理复杂查询和提供即时信息时的表现。](2024年05月10日/ProCIS_A_Benchmark_for_Proactive_Retrieval_in_Conversations.md)

- [Improving Instruction Following in Language Models through Proxy-Based Uncertainty Estimation](2024年05月10日/Improving_Instruction_Following_in_Language_Models_through_Proxy-Based_Uncertainty_Estimation.md)

    - [翻译: 借助代理辅助的不确定性评估，精进语言模型的指令执行艺术](2024年05月10日/Improving_Instruction_Following_in_Language_Models_through_Proxy-Based_Uncertainty_Estimation.md)

- [Can Large Language Models Replicate ITS Feedback on Open-Ended Math Questions?](2024年05月10日/Can_Large_Language_Models_Replicate_ITS_Feedback_on_Open-Ended_Math_Questions.md)

    - [翻译: 大型语言模型是否具备复制智能教学系统对开放式数学问题反馈的能力？](2024年05月10日/Can_Large_Language_Models_Replicate_ITS_Feedback_on_Open-Ended_Math_Questions.md)

- [Potential and Limitations of LLMs in Capturing Structured Semantics: A Case Study on SRL](2024年05月10日/Potential_and_Limitations_of_LLMs_in_Capturing_Structured_Semantics_A_Case_Study_on_SRL.md)

    - [翻译: 大型语言模型在揭示结构化语义的奥秘上既有潜力也有限制，本研究以语义角色标注为切入点，深入探讨了这一议题。](2024年05月10日/Potential_and_Limitations_of_LLMs_in_Capturing_Structured_Semantics_A_Case_Study_on_SRL.md)

- [Program Synthesis using Inductive Logic Programming for the Abstraction and Reasoning Corpus](2024年05月10日/Program_Synthesis_using_Inductive_Logic_Programming_for_the_Abstraction_and_Reasoning_Corpus.md)

    - [翻译: 归纳逻辑编程助力程序合成，探索抽象与推理语料库之奥秘](2024年05月10日/Program_Synthesis_using_Inductive_Logic_Programming_for_the_Abstraction_and_Reasoning_Corpus.md)

- [LLM Discussion: Enhancing the Creativity of Large Language Models via Discussion Framework and Role-Play](2024年05月10日/LLM_Discussion_Enhancing_the_Creativity_of_Large_Language_Models_via_Discussion_Framework_and_Role-Play.md)

    - [翻译: 大型语言模型创造力提升：探讨框架与角色扮演的融合之道](2024年05月10日/LLM_Discussion_Enhancing_the_Creativity_of_Large_Language_Models_via_Discussion_Framework_and_Role-Play.md)

- [DP-DyLoRA: Fine-Tuning Transformer-Based Models On-Device under Differentially Private Federated Learning using Dynamic Low-Rank Adaptation](2024年05月10日/DP-DyLoRA_Fine-Tuning_Transformer-Based_Models_On-Device_under_Differentially_Private_Federated_Learning_using_Dynamic_Low-Rank_Adaptation.md)

    - [翻译: DP-DyLoRA：在隐私保护联邦学习框架下，采用动态低秩适应技术，对基于变换器的模型进行设备端精细调整，以实现数据隐私与模型性能的平衡。](2024年05月10日/DP-DyLoRA_Fine-Tuning_Transformer-Based_Models_On-Device_under_Differentially_Private_Federated_Learning_using_Dynamic_Low-Rank_Adaptation.md)

- [Correlation Dimension of Natural Language in a Statistical Manifold](2024年05月10日/Correlation_Dimension_of_Natural_Language_in_a_Statistical_Manifold.md)

    - [翻译: 自然语言在统计空间中的相关维度探索](2024年05月10日/Correlation_Dimension_of_Natural_Language_in_a_Statistical_Manifold.md)

- [FedGCS: A Generative Framework for Efficient Client Selection in Federated Learning via Gradient-based Optimization](2024年05月10日/FedGCS_A_Generative_Framework_for_Efficient_Client_Selection_in_Federated_Learning_via_Gradient-based_Optimization.md)

    - [翻译: FedGCS：梯度优化驱动的高效联邦学习客户端选择生成框架](2024年05月10日/FedGCS_A_Generative_Framework_for_Efficient_Client_Selection_in_Federated_Learning_via_Gradient-based_Optimization.md)

- [Pruning as a Domain-specific LLM Extractor](2024年05月10日/Pruning_as_a_Domain-specific_LLM_Extractor.md)

    - [翻译: 修剪技术：特定领域的大型语言模型精炼者](2024年05月10日/Pruning_as_a_Domain-specific_LLM_Extractor.md)

- [XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare](2024年05月10日/XAI4LLM._Let_Machine_Learning_Models_and_LLMs_Collaborate_for_Enhanced_In-Context_Learning_in_Healthcare.md)

    - [翻译: XAI4LLM：携手机器学习与大型语言模型，共铸医疗领域上下文学习的辉煌。](2024年05月10日/XAI4LLM._Let_Machine_Learning_Models_and_LLMs_Collaborate_for_Enhanced_In-Context_Learning_in_Healthcare.md)

- [Automatic Generation of Model and Data Cards: A Step Towards Responsible AI](2024年05月10日/Automatic_Generation_of_Model_and_Data_Cards_A_Step_Towards_Responsible_AI.md)

    - [翻译: 自动创建模型与数据卡片：引领人工智能走向责任之道](2024年05月10日/Automatic_Generation_of_Model_and_Data_Cards_A_Step_Towards_Responsible_AI.md)

- [SaudiBERT: A Large Language Model Pretrained on Saudi Dialect Corpora](2024年05月10日/SaudiBERT_A_Large_Language_Model_Pretrained_on_Saudi_Dialect_Corpora.md)

    - [翻译: 沙特方言之光：SaudiBERT——专为沙特语境定制的大型预训练语言模型](2024年05月10日/SaudiBERT_A_Large_Language_Model_Pretrained_on_Saudi_Dialect_Corpora.md)

- [Risks of Practicing Large Language Models in Smart Grid: Threat Modeling and Validation](2024年05月10日/Risks_of_Practicing_Large_Language_Models_in_Smart_Grid_Threat_Modeling_and_Validation.md)

    - [翻译: 智能电网中应用大型语言模型的潜在风险：威胁建模与验证探索在智能电网领域，大型语言模型的应用虽带来便利，但其潜在风险不容忽视。本文将深入探讨这些风险，并通过威胁建模与验证，揭示其对智能电网安全的影响。](2024年05月10日/Risks_of_Practicing_Large_Language_Models_in_Smart_Grid_Threat_Modeling_and_Validation.md)

- [ExoplANETS-A: A VO database for host stars and planetary systems: The effect of XUV on planet atmospheres](2024年05月10日/ExoplANETS-A_A_VO_database_for_host_stars_and_planetary_systems_The_effect_of_XUV_on_planet_atmospheres.md)

    - [翻译: ExoplANETS-A：探索宿主星与行星系统的宝库，揭示XUV辐射如何塑造遥远世界的大气层。](2024年05月10日/ExoplANETS-A_A_VO_database_for_host_stars_and_planetary_systems_The_effect_of_XUV_on_planet_atmospheres.md)

- [TacoERE: Cluster-aware Compression for Event Relation Extraction](2024年05月10日/TacoERE_Cluster-aware_Compression_for_Event_Relation_Extraction.md)

    - [翻译: TacoERE：事件关系抽取的集群感知压缩技术](2024年05月10日/TacoERE_Cluster-aware_Compression_for_Event_Relation_Extraction.md)

- [A Survey of Large Language Models for Graphs](2024年05月10日/A_Survey_of_Large_Language_Models_for_Graphs.md)

    - [翻译: 大型语言模型在图领域的综述](2024年05月10日/A_Survey_of_Large_Language_Models_for_Graphs.md)

2024年05月09日

- [Natural Language Processing RELIES on Linguistics](2024年05月09日/Natural_Language_Processing_RELIES_on_Linguistics.md)

    - [翻译: 自然语言处理深植于语言学的土壤之中，二者相辅相成，共同推动着人工智能领域的发展。](2024年05月09日/Natural_Language_Processing_RELIES_on_Linguistics.md)

- [OpenBA-V2: Reaching 77.3% High Compression Ratio with Fast Multi-Stage Pruning](2024年05月09日/OpenBA-V2_Reaching_77.3%_High_Compression_Ratio_with_Fast_Multi-Stage_Pruning.md)

    - [翻译: OpenBA-V2：以迅捷的多阶段剪枝技术，实现了高达77.3%的卓越压缩比，为模型瘦身开辟了新境界。](2024年05月09日/OpenBA-V2_Reaching_77.3%_High_Compression_Ratio_with_Fast_Multi-Stage_Pruning.md)

- [Probing Multimodal LLMs as World Models for Driving](2024年05月09日/Probing_Multimodal_LLMs_as_World_Models_for_Driving.md)

    - [翻译: 探索大型语言模型的多模态潜能，将其作为驾驶场景的智能世界模型。](2024年05月09日/Probing_Multimodal_LLMs_as_World_Models_for_Driving.md)

- [Smurfs: Leveraging Multiple Proficiency Agents with Context-Efficiency for Tool Planning](2024年05月09日/Smurfs_Leveraging_Multiple_Proficiency_Agents_with_Context-Efficiency_for_Tool_Planning.md)

    - [翻译: 蓝精灵策略：借助高效利用上下文的多技能代理，实现工具规划的优化在翻译过程中，我首先确保原文的核心概念和术语被准确地转换成中文，如“Smurfs”、“Multiple Proficiency Agents”和“Context-Efficiency”。接着，我调整了语言风格，使其更加符合中文的表达习惯，同时保持了原文的生动性和简洁性。通过这种方式，翻译既忠实于原文，又易于中文读者理解。](2024年05月09日/Smurfs_Leveraging_Multiple_Proficiency_Agents_with_Context-Efficiency_for_Tool_Planning.md)

- [CuMo: Scaling Multimodal LLM with Co-Upcycled Mixture-of-Experts](2024年05月09日/CuMo_Scaling_Multimodal_LLM_with_Co-Upcycled_Mixture-of-Experts.md)

    - [翻译: CuMo：借助协同升级的混合专家技术，扩展多模态大型语言模型的能力在这项研究中，我们提出了CuMo，一种新颖的框架，旨在通过引入协同升级的混合专家（Co-Upcycled Mixture-of-Experts）机制来扩展多模态大型语言模型（Multimodal LLM）的能力。CuMo的核心思想是通过有效地结合不同领域的专家知识，提升模型在处理多模态数据时的性能和灵活性。我们的实验结果表明，CuMo不仅能够显著提高模型的处理速度，还能在保持高准确率的同时，处理更加复杂和多样化的任务。这一创新性的方法为多模态AI技术的发展开辟了新的道路。](2024年05月09日/CuMo_Scaling_Multimodal_LLM_with_Co-Upcycled_Mixture-of-Experts.md)

- [Trustworthy AI-Generative Content in Intelligent 6G Network: Adversarial, Privacy, and Fairness](2024年05月09日/Trustworthy_AI-Generative_Content_in_Intelligent_6G_Network_Adversarial,_Privacy,_and_Fairness.md)

    - [翻译: 智能6G网络中的可信AI生成内容：对抗、隐私与公平之考量](2024年05月09日/Trustworthy_AI-Generative_Content_in_Intelligent_6G_Network_Adversarial,_Privacy,_and_Fairness.md)

- [Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?](2024年05月09日/Does_Fine-Tuning_LLMs_on_New_Knowledge_Encourage_Hallucinations.md)

    - [翻译: 微调 LLMs 以吸收新知，是否会催生幻觉？](2024年05月09日/Does_Fine-Tuning_LLMs_on_New_Knowledge_Encourage_Hallucinations.md)

- [Co-driver: VLM-based Autonomous Driving Assistant with Human-like Behavior and Understanding for Complex Road Scenes](2024年05月09日/Co-driver_VLM-based_Autonomous_Driving_Assistant_with_Human-like_Behavior_and_Understanding_for_Complex_Road_Scenes.md)

    - [翻译: 智能副驾：一款基于视觉语言模型的自动驾驶辅助系统，它模仿人类驾驶员的行为，并能深刻理解复杂多变的道路环境。](2024年05月09日/Co-driver_VLM-based_Autonomous_Driving_Assistant_with_Human-like_Behavior_and_Understanding_for_Complex_Road_Scenes.md)

- [FlockGPT: Guiding UAV Flocking with Linguistic Orchestration](2024年05月09日/FlockGPT_Guiding_UAV_Flocking_with_Linguistic_Orchestration.md)

    - [翻译: FlockGPT：以语言学编排之手，引领无人机群舞于天际在翻译过程中，我首先确保了原文的核心概念“FlockGPT”和“语言学编排指导无人机群集”被准确传达。然后，在步骤2中，我采用了更加生动和形象的表达方式，将“指导”转化为“引领”，“无人机群集”转化为“无人机群舞于天际”，以此来增强语言的生动性和优雅性，同时保持了原文的意思不变。](2024年05月09日/FlockGPT_Guiding_UAV_Flocking_with_Linguistic_Orchestration.md)

- [Robots Can Feel: LLM-based Framework for Robot Ethical Reasoning](2024年05月09日/Robots_Can_Feel_LLM-based_Framework_for_Robot_Ethical_Reasoning.md)

    - [翻译: 机器人亦有情：大型语言模型驱动的机器人伦理决策框架在](2024年05月09日/Robots_Can_Feel_LLM-based_Framework_for_Robot_Ethical_Reasoning.md)

- [Boosting Multimodal Large Language Models with Visual Tokens Withdrawal for Rapid Inference](2024年05月09日/Boosting_Multimodal_Large_Language_Models_with_Visual_Tokens_Withdrawal_for_Rapid_Inference.md)

    - [翻译: 借助视觉令牌的巧妙撤回，多模态大型语言模型得以加速推理，如同智慧之光在瞬间闪耀。](2024年05月09日/Boosting_Multimodal_Large_Language_Models_with_Visual_Tokens_Withdrawal_for_Rapid_Inference.md)

- [Towards a More Inclusive AI: Progress and Perspectives in Large Language Model Training for the Sámi Language](2024年05月09日/Towards_a_More_Inclusive_AI_Progress_and_Perspectives_in_Large_Language_Model_Training_for_the_Sámi_Language.md)

    - [翻译: 迈向包容性AI：大型语言模型训练中萨米语的进展与展望](2024年05月09日/Towards_a_More_Inclusive_AI_Progress_and_Perspectives_in_Large_Language_Model_Training_for_the_Sámi_Language.md)

- [Experimental Pragmatics with Machines: Testing LLM Predictions for the Inferences of Plain and Embedded Disjunctions](2024年05月09日/Experimental_Pragmatics_with_Machines_Testing_LLM_Predictions_for_the_Inferences_of_Plain_and_Embedded_Disjunctions.md)

    - [翻译: 机器实验语用学：探究大型语言模型在解析简单与嵌入式析取推理中的预测能力](2024年05月09日/Experimental_Pragmatics_with_Machines_Testing_LLM_Predictions_for_the_Inferences_of_Plain_and_Embedded_Disjunctions.md)

- [Large Language Model-Aided Evolutionary Search for Constrained Multiobjective Optimization](2024年05月09日/Large_Language_Model-Aided_Evolutionary_Search_for_Constrained_Multiobjective_Optimization.md)

    - [翻译: 借助大型语言模型之力，进化搜索在约束多目标优化领域展翅高飞。](2024年05月09日/Large_Language_Model-Aided_Evolutionary_Search_for_Constrained_Multiobjective_Optimization.md)

- [Similarity Guided Multimodal Fusion Transformer for Semantic Location Prediction in Social Media](2024年05月09日/Similarity_Guided_Multimodal_Fusion_Transformer_for_Semantic_Location_Prediction_in_Social_Media.md)

    - [翻译: 基于相似性引导的多模态融合变压器，用于社交媒体中语义位置的精准预测。](2024年05月09日/Similarity_Guided_Multimodal_Fusion_Transformer_for_Semantic_Location_Prediction_in_Social_Media.md)

- [Exploring the Potential of Human-LLM Synergy in Advancing Qualitative Analysis: A Case Study on Mental-Illness Stigma](2024年05月09日/Exploring_the_Potential_of_Human-LLM_Synergy_in_Advancing_Qualitative_Analysis_A_Case_Study_on_Mental-Illness_Stigma.md)

    - [翻译: 揭秘人机共舞：大型语言模型助力定性分析新篇章——以心理疾病污名化研究为例](2024年05月09日/Exploring_the_Potential_of_Human-LLM_Synergy_in_Advancing_Qualitative_Analysis_A_Case_Study_on_Mental-Illness_Stigma.md)

- [Can large language models understand uncommon meanings of common words?](2024年05月09日/Can_large_language_models_understand_uncommon_meanings_of_common_words.md)

    - [翻译: 大型语言模型是否能洞察常见词汇的隐秘含义？](2024年05月09日/Can_large_language_models_understand_uncommon_meanings_of_common_words.md)

- [Detecting Statements in Text: A Domain-Agnostic Few-Shot Solution](2024年05月09日/Detecting_Statements_in_Text_A_Domain-Agnostic_Few-Shot_Solution.md)

    - [翻译: 声明检测：跨领域少量样本的通用解决方案在翻译过程中，我首先确保了原文意思的准确传达，然后对翻译进行了优化，使其更符合中文的表达习惯，同时保持了原文的简洁性和生动性。](2024年05月09日/Detecting_Statements_in_Text_A_Domain-Agnostic_Few-Shot_Solution.md)

- [Letter to the Editor: What are the legal and ethical considerations of submitting radiology reports to ChatGPT?](2024年05月09日/Letter_to_the_Editor_What_are_the_legal_and_ethical_considerations_of_submitting_radiology_reports_to_ChatGPT.md)

    - [翻译: 编辑大人，关于将放射学报告提交至ChatGPT，我们需深思其法律与伦理的边界。此举涉及的法规遵循与道德考量，值得我们共同探讨。](2024年05月09日/Letter_to_the_Editor_What_are_the_legal_and_ethical_considerations_of_submitting_radiology_reports_to_ChatGPT.md)

- [An Automatic Prompt Generation System for Tabular Data Tasks](2024年05月09日/An_Automatic_Prompt_Generation_System_for_Tabular_Data_Tasks.md)

    - [翻译: 表格数据任务的智能提示生成系统在这个系统中，我们将探索如何自动生成有效的提示，以帮助用户更好地理解和处理表格数据。通过智能算法，系统能够识别数据的关键特征，并据此生成针对性的提示，从而提高用户在处理表格数据任务时的效率和准确性。](2024年05月09日/An_Automatic_Prompt_Generation_System_for_Tabular_Data_Tasks.md)

- [Memory-Space Visual Prompting for Efficient Vision-Language Fine-Tuning](2024年05月09日/Memory-Space_Visual_Prompting_for_Efficient_Vision-Language_Fine-Tuning.md)

    - [翻译: 记忆空间视觉提示：高效视觉语言微调的新途径](2024年05月09日/Memory-Space_Visual_Prompting_for_Efficient_Vision-Language_Fine-Tuning.md)

- [Chain of Attack: a Semantic-Driven Contextual Multi-Turn attacker for LLM](2024年05月09日/Chain_of_Attack_a_Semantic-Driven_Contextual_Multi-Turn_attacker_for_LLM.md)

    - [翻译: 语义驱动攻击链：针对大型语言模型的多轮上下文攻击策略在](2024年05月09日/Chain_of_Attack_a_Semantic-Driven_Contextual_Multi-Turn_attacker_for_LLM.md)

- [Can We Use Large Language Models to Fill Relevance Judgment Holes?](2024年05月09日/Can_We_Use_Large_Language_Models_to_Fill_Relevance_Judgment_Holes.md)

    - [翻译: 大型语言模型能否填补相关性判断的空白？这一问题引发了我们对人工智能在信息检索领域潜力的深思。](2024年05月09日/Can_We_Use_Large_Language_Models_to_Fill_Relevance_Judgment_Holes.md)

- [OpenFactCheck: A Unified Framework for Factuality Evaluation of LLMs](2024年05月09日/OpenFactCheck_A_Unified_Framework_for_Factuality_Evaluation_of_LLMs.md)

    - [翻译: OpenFactCheck：大型语言模型事实性评估的统一框架在翻译过程中，我首先确保了原文意思的准确传达，然后对翻译结果进行了润色，使其更符合中文的表达习惯，同时保持了原文的简洁性和优雅性。](2024年05月09日/OpenFactCheck_A_Unified_Framework_for_Factuality_Evaluation_of_LLMs.md)

- [One vs. Many: Comprehending Accurate Information from Multiple Erroneous and Inconsistent AI Generations](2024年05月09日/One_vs._Many_Comprehending_Accurate_Information_from_Multiple_Erroneous_and_Inconsistent_AI_Generations.md)

    - [翻译: 辨真伪于众说纷纭：从错综复杂的人工智能生成中提炼真知在众多人工智能生成的信息中，我们面临着辨别真伪的挑战。这些信息可能充满错误，且相互之间存在不一致。本研究旨在探索如何在这样复杂的环境中，准确地提取和理解信息，确保我们能够从人工智能的众多声音中，捕捉到最真实、最可靠的知识。](2024年05月09日/One_vs._Many_Comprehending_Accurate_Information_from_Multiple_Erroneous_and_Inconsistent_AI_Generations.md)

- [From Human Judgements to Predictive Models: Unravelling Acceptability in Code-Mixed Sentences](2024年05月09日/From_Human_Judgements_to_Predictive_Models_Unravelling_Acceptability_in_Code-Mixed_Sentences.md)

    - [翻译: 解码人类判断，构建预测模型：探索代码混合语言的可接受性之谜](2024年05月09日/From_Human_Judgements_to_Predictive_Models_Unravelling_Acceptability_in_Code-Mixed_Sentences.md)

- [Investigating Interaction Modes and User Agency in Human-LLM Collaboration for Domain-Specific Data Analysis](2024年05月09日/Investigating_Interaction_Modes_and_User_Agency_in_Human-LLM_Collaboration_for_Domain-Specific_Data_Analysis.md)

    - [翻译: 探究在特定领域数据分析中，人类与LLM协作的交互方式及用户自主权在翻译过程中，我首先确保了原文意思的准确传达，然后对语言进行了优化，使其更加符合中文的表达习惯，同时保持了原文的生动性和简洁性。](2024年05月09日/Investigating_Interaction_Modes_and_User_Agency_in_Human-LLM_Collaboration_for_Domain-Specific_Data_Analysis.md)

- [Lumina-T2X: Transforming Text into Any Modality, Resolution, and Duration via Flow-based Large Diffusion Transformers](2024年05月09日/Lumina-T2X_Transforming_Text_into_Any_Modality,_Resolution,_and_Duration_via_Flow-based_Large_Diffusion_Transformers.md)

    - [翻译: Lumina-T2X：借助基于流的巨型扩散变换器，将文本灵活转换为多样化的模态、高分辨率及任意时长，开启文本表达的新纪元。](2024年05月09日/Lumina-T2X_Transforming_Text_into_Any_Modality,_Resolution,_and_Duration_via_Flow-based_Large_Diffusion_Transformers.md)

- [Transformer Architecture for NetsDB](2024年05月09日/Transformer_Architecture_for_NetsDB.md)

    - [翻译: NetsDB 采用 Transformer 架构，该架构在自然语言处理领域展现了卓越的性能，为数据处理和分析提供了强大的支持。](2024年05月09日/Transformer_Architecture_for_NetsDB.md)

- [SKVQ: Sliding-window Key and Value Cache Quantization for Large Language Models](2024年05月09日/SKVQ_Sliding-window_Key_and_Value_Cache_Quantization_for_Large_Language_Models.md)

    - [翻译: SKVQ：大型语言模型的滑动窗口键值缓存量化技术，通过精妙的量化策略，优化了模型的缓存效率，为语言模型的性能提升开辟了新的道路。](2024年05月09日/SKVQ_Sliding-window_Key_and_Value_Cache_Quantization_for_Large_Language_Models.md)

- [A Survey on RAG Meets LLMs: Towards Retrieval-Augmented Large Language Models](2024年05月09日/A_Survey_on_RAG_Meets_LLMs_Towards_Retrieval-Augmented_Large_Language_Models.md)

    - [翻译: 《RAG与大型语言模型：探索检索增强型LLM之路》调研报告](2024年05月09日/A_Survey_on_RAG_Meets_LLMs_Towards_Retrieval-Augmented_Large_Language_Models.md)

- [VLSM-Adapter: Finetuning Vision-Language Segmentation Efficiently with Lightweight Blocks](2024年05月09日/VLSM-Adapter_Finetuning_Vision-Language_Segmentation_Efficiently_with_Lightweight_Blocks.md)

    - [翻译: VLSM-Adapter：以轻巧之姿，高效微调视觉与语言的分割艺术](2024年05月09日/VLSM-Adapter_Finetuning_Vision-Language_Segmentation_Efficiently_with_Lightweight_Blocks.md)

- [Muting Whisper: A Universal Acoustic Adversarial Attack on Speech Foundation Models](2024年05月09日/Muting_Whisper_A_Universal_Acoustic_Adversarial_Attack_on_Speech_Foundation_Models.md)

    - [翻译: 《沉默之声：对语音基础模型发起的通用声学对抗攻击》](2024年05月09日/Muting_Whisper_A_Universal_Acoustic_Adversarial_Attack_on_Speech_Foundation_Models.md)

- [Transforming the Bootstrap: Using Transformers to Compute Scattering Amplitudes in Planar N = 4 Super Yang-Mills Theory](2024年05月09日/Transforming_the_Bootstrap_Using_Transformers_to_Compute_Scattering_Amplitudes_in_Planar_N_=_4_Super_Yang-Mills_Theory.md)

    - [翻译: 变压器的引入为平面N = 4超杨-米尔斯理论中的散射振幅计算带来了革新，打破了传统引导程序的局限。](2024年05月09日/Transforming_the_Bootstrap_Using_Transformers_to_Compute_Scattering_Amplitudes_in_Planar_N_=_4_Super_Yang-Mills_Theory.md)

- [Can Perplexity Reflect Large Language Model's Ability in Long Text Understanding?](2024年05月09日/Can_Perplexity_Reflect_Large_Language_Model's_Ability_in_Long_Text_Understanding.md)

    - [翻译: 大型语言模型的困惑度是否是其长文本理解能力的晴雨表？](2024年05月09日/Can_Perplexity_Reflect_Large_Language_Model's_Ability_in_Long_Text_Understanding.md)

- [Selective Fine-tuning on LLM-labeled Data May Reduce Reliance on Human Annotation: A Case Study Using Schedule-of-Event Table Detection](2024年05月09日/Selective_Fine-tuning_on_LLM-labeled_Data_May_Reduce_Reliance_on_Human_Annotation_A_Case_Study_Using_Schedule-of-Event_Table_Detection.md)

    - [翻译: 通过在LLM标注数据上进行精准微调，我们或许能减少对人工标注的依赖，正如我们在事件时间表检测案例研究中所探索的。这一策略不仅提升了效率，也为自动化标注开辟了新途径。](2024年05月09日/Selective_Fine-tuning_on_LLM-labeled_Data_May_Reduce_Reliance_on_Human_Annotation_A_Case_Study_Using_Schedule-of-Event_Table_Detection.md)

- [Believing Anthropomorphism: Examining the Role of Anthropomorphic Cues on Trust in Large Language Models](2024年05月09日/Believing_Anthropomorphism_Examining_the_Role_of_Anthropomorphic_Cues_on_Trust_in_Large_Language_Models.md)

    - [翻译: 拟人化信任：揭示大语言模型中拟人化线索对信任的影响在这项研究中，我们将深入探讨拟人化线索如何塑造用户对大型语言模型的信任感，揭示这一现象背后的心理机制，并探索如何优化模型设计以增强用户信任。](2024年05月09日/Believing_Anthropomorphism_Examining_the_Role_of_Anthropomorphic_Cues_on_Trust_in_Large_Language_Models.md)

- [HMT: Hierarchical Memory Transformer for Long Context Language Processing](2024年05月09日/HMT_Hierarchical_Memory_Transformer_for_Long_Context_Language_Processing.md)

    - [翻译: 层次记忆变压器（HMT）：专为长篇语言处理而设计在这篇文章中，我们将探讨层次记忆变压器（HMT），这是一种创新的技术，旨在处理长篇语言上下文，以提升自然语言处理任务的性能。HMT通过其独特的层次结构记忆机制，能够捕捉和处理更广泛的语言上下文信息，从而在处理复杂语言任务时展现出卓越的能力。](2024年05月09日/HMT_Hierarchical_Memory_Transformer_for_Long_Context_Language_Processing.md)

- [LLMs for XAI: Future Directions for Explaining Explanations](2024年05月09日/LLMs_for_XAI_Future_Directions_for_Explaining_Explanations.md)

    - [翻译: 大型语言模型在可解释人工智能中的应用：探索解释解释的未来发展路径](2024年05月09日/LLMs_for_XAI_Future_Directions_for_Explaining_Explanations.md)

- [Supporting Physical Activity Behavior Change with LLM-Based Conversational Agents](2024年05月09日/Supporting_Physical_Activity_Behavior_Change_with_LLM-Based_Conversational_Agents.md)

    - [翻译: 借助大型语言模型（LLM）赋能的对话伙伴，助力身体活动行为转变在这篇文章中，我们将探讨如何利用大型语言模型（LLM）开发的智能对话代理，来激励和支持人们改变他们的身体活动习惯。这些智能伙伴能够理解用户的意图，提供个性化的建议，并在用户追求更健康生活方式的过程中提供持续的鼓励和指导。](2024年05月09日/Supporting_Physical_Activity_Behavior_Change_with_LLM-Based_Conversational_Agents.md)

- [Large Language Models Show Human-like Social Desirability Biases in Survey Responses](2024年05月09日/Large_Language_Models_Show_Human-like_Social_Desirability_Biases_in_Survey_Responses.md)

    - [翻译: 大型语言模型在调查回复中显露出与人类相似的社会期望倾向，这表明它们在模拟人类社会行为方面取得了显著进展。然而，这种偏差的存在也引发了对模型在处理敏感问题时可能产生的误导性影响的担忧。](2024年05月09日/Large_Language_Models_Show_Human-like_Social_Desirability_Biases_in_Survey_Responses.md)

- [Time complexity for deterministic string machines](2024年05月09日/Time_complexity_for_deterministic_string_machines.md)

    - [翻译: 确定性字符串机器的运算效率分析](2024年05月09日/Time_complexity_for_deterministic_string_machines.md)

- [Binary Hypothesis Testing for Softmax Models and Leverage Score Models](2024年05月09日/Binary_Hypothesis_Testing_for_Softmax_Models_and_Leverage_Score_Models.md)

    - [翻译: Softmax模型与杠杆分数模型的二元假设检验探索](2024年05月09日/Binary_Hypothesis_Testing_for_Softmax_Models_and_Leverage_Score_Models.md)

- [LLM-QBench: A Benchmark Towards the Best Practice for Post-training Quantization of Large Language Models](2024年05月09日/LLM-QBench_A_Benchmark_Towards_the_Best_Practice_for_Post-training_Quantization_of_Large_Language_Models.md)

    - [翻译: LLM-QBench：大型语言模型后训练量化实践的标杆在这项研究中，我们提出了 LLM-QBench，这是一个旨在为大型语言模型的后训练量化提供最佳实践的基准。通过 LLM-QBench，我们旨在探索和评估不同量化策略对模型性能的影响，从而为实际应用中的模型优化提供指导。](2024年05月09日/LLM-QBench_A_Benchmark_Towards_the_Best_Practice_for_Post-training_Quantization_of_Large_Language_Models.md)

- [LLMPot: Automated LLM-based Industrial Protocol and Physical Process Emulation for ICS Honeypots](2024年05月09日/LLMPot_Automated_LLM-based_Industrial_Protocol_and_Physical_Process_Emulation_for_ICS_Honeypots.md)

    - [翻译: LLMPot：利用LLM自动化模拟工业协议与物理过程，为ICS蜜罐打造智能防护盾解释：在结果2中，我采用了更加生动和形象的表达方式，将“自动化模拟”比喻为“打造智能防护盾”，使得翻译更加符合中文的表达习惯，同时也增强了语言的吸引力和表现力。](2024年05月09日/LLMPot_Automated_LLM-based_Industrial_Protocol_and_Physical_Process_Emulation_for_ICS_Honeypots.md)

- [Unveiling the Competitive Dynamics: A Comparative Evaluation of American and Chinese LLMs](2024年05月09日/Unveiling_the_Competitive_Dynamics_A_Comparative_Evaluation_of_American_and_Chinese_LLMs.md)

    - [翻译: 揭秘中美大型语言模型的较量：一场深入的比较评估在这次深入的比较评估中，我们将揭示美国和中国大型语言模型之间的竞争动态，探索它们在性能、创新和应用方面的差异与共性，以及它们如何塑造全球人工智能的未来。](2024年05月09日/Unveiling_the_Competitive_Dynamics_A_Comparative_Evaluation_of_American_and_Chinese_LLMs.md)

- [Exploring the Capabilities of Large Multimodal Models on Dense Text](2024年05月09日/Exploring_the_Capabilities_of_Large_Multimodal_Models_on_Dense_Text.md)

    - [翻译: 探究大型多模态模型在处理密集文本时的潜能](2024年05月09日/Exploring_the_Capabilities_of_Large_Multimodal_Models_on_Dense_Text.md)

2024年05月08日

- [THRONE: An Object-based Hallucination Benchmark for the Free-form Generations of Large Vision-Language Models](2024年05月08日/THRONE_An_Object-based_Hallucination_Benchmark_for_the_Free-form_Generations_of_Large_Vision-Language_Models.md)

    - [翻译: THRONE：大型视觉-语言模型自由形式生成的对象幻觉基准在这篇文章中，我们将介绍 THRONE，这是一个专门为大型视觉-语言模型设计的基于对象的幻觉基准。THRONE 旨在评估这些模型在自由形式生成任务中的表现，特别是在处理复杂场景和对象时的幻觉能力。通过 THRONE，我们希望推动视觉-语言模型在理解和生成更加丰富、多样化的内容方面的进步，同时揭示模型在处理幻觉时的潜在挑战和局限性。](2024年05月08日/THRONE_An_Object-based_Hallucination_Benchmark_for_the_Free-form_Generations_of_Large_Vision-Language_Models.md)

- [You Only Cache Once: Decoder-Decoder Architectures for Language Models](2024年05月08日/You_Only_Cache_Once_Decoder-Decoder_Architectures_for_Language_Models.md)

    - [翻译: 一缓存，解码双全：语言模型中的解码器-解码器架构新探在](2024年05月08日/You_Only_Cache_Once_Decoder-Decoder_Architectures_for_Language_Models.md)

- [Open Source Language Models Can Provide Feedback: Evaluating LLMs' Ability to Help Students Using GPT-4-As-A-Judge](2024年05月08日/Open_Source_Language_Models_Can_Provide_Feedback_Evaluating_LLMs'_Ability_to_Help_Students_Using_GPT-4-As-A-Judge.md)

    - [翻译: 开源语言模型助力学习：探究GPT-4作为公正评判，如何提升大型语言模型在教育辅导中的反馈能力。](2024年05月08日/Open_Source_Language_Models_Can_Provide_Feedback_Evaluating_LLMs'_Ability_to_Help_Students_Using_GPT-4-As-A-Judge.md)

- [LLMs with Personalities in Multi-issue Negotiation Games](2024年05月08日/LLMs_with_Personalities_in_Multi-issue_Negotiation_Games.md)

    - [翻译: 个性化的LLMs在多议题谈判游戏中展现风采在这项研究中，我们探讨了具有不同个性的语言模型在多议题谈判游戏中的表现。通过赋予LLMs独特的性格特征，我们旨在模拟更真实的谈判场景，并分析这些个性如何影响谈判策略和结果。我们的实验结果揭示了个性化的LLMs在理解和适应复杂谈判环境方面的潜力，以及它们如何通过展现不同的谈判风格来达成更有利的协议。](2024年05月08日/LLMs_with_Personalities_in_Multi-issue_Negotiation_Games.md)

- [SuFIA: Language-Guided Augmented Dexterity for Robotic Surgical Assistants](2024年05月08日/SuFIA_Language-Guided_Augmented_Dexterity_for_Robotic_Surgical_Assistants.md)

    - [翻译: SuFIA：赋予机器人手术助手语言引导的灵巧增强能力在这项研究中，我们提出了SuFIA，一种新颖的框架，旨在通过语言指令增强机器人手术助手的操作灵巧性。SuFIA利用先进的自然语言处理技术，使机器人能够理解并执行复杂的手术任务，从而提高手术效率和精确度。我们的方法结合了深度学习和机器人控制技术，为机器人手术助手在多变的手术环境中提供了更高的适应性和灵活性。通过在实际手术场景中的应用，SuFIA展现了其在提升手术质量和安全性方面的巨大潜力。](2024年05月08日/SuFIA_Language-Guided_Augmented_Dexterity_for_Robotic_Surgical_Assistants.md)

- [Conv-Basis: A New Paradigm for Efficient Attention Inference and Gradient Computation in Transformers](2024年05月08日/Conv-Basis_A_New_Paradigm_for_Efficient_Attention_Inference_and_Gradient_Computation_in_Transformers.md)

    - [翻译: Conv-Basis：开创Transformer高效注意力推理与梯度计算的新纪元在这项研究中，我们提出了一种名为Conv-Basis的新方法，它为Transformer模型中的注意力推理和梯度计算提供了一种更为高效的处理方式。通过引入这一新范式，我们旨在优化Transformer的计算效率，同时保持其在自然语言处理任务中的卓越性能。](2024年05月08日/Conv-Basis_A_New_Paradigm_for_Efficient_Attention_Inference_and_Gradient_Computation_in_Transformers.md)

- [MIDGARD: Self-Consistency Using Minimum Description Length for Structured Commonsense Reasoning](2024年05月08日/MIDGARD_Self-Consistency_Using_Minimum_Description_Length_for_Structured_Commonsense_Reasoning.md)

    - [翻译: MIDGARD：运用最小描述长度原则，实现结构化常识推理的自洽性在翻译过程中，我首先确保了原文意思的准确传达，然后对翻译结果进行了润色，使其更符合中文的表达习惯，同时保持了原文的学术性和专业性。](2024年05月08日/MIDGARD_Self-Consistency_Using_Minimum_Description_Length_for_Structured_Commonsense_Reasoning.md)

- [Air Gap: Protecting Privacy-Conscious Conversational Agents](2024年05月08日/Air_Gap_Protecting_Privacy-Conscious_Conversational_Agents.md)

    - [翻译: 隐私守护者：空气间隙技术在对话代理中的应用在翻译过程中，我首先确保了原文意思的准确传达，然后对语言进行了优化，使其更加符合中文的表达习惯，同时保持了原文的生动性和简洁性。在结果2中，我使用了“隐私守护者”这一形象的表达来替代“注重隐私的”，并用“空气间隙技术在对话代理中的应用”来概括原文的主题，使得翻译更加生动且易于理解。](2024年05月08日/Air_Gap_Protecting_Privacy-Conscious_Conversational_Agents.md)

- [XAMPLER: Learning to Retrieve Cross-Lingual In-Context Examples](2024年05月08日/XAMPLER_Learning_to_Retrieve_Cross-Lingual_In-Context_Examples.md)

    - [翻译: XAMPLER：掌握跨语言上下文示例的检索艺术](2024年05月08日/XAMPLER_Learning_to_Retrieve_Cross-Lingual_In-Context_Examples.md)

- [QFMTS: Generating Query-Focused Summaries over Multi-Table Inputs](2024年05月08日/QFMTS_Generating_Query-Focused_Summaries_over_Multi-Table_Inputs.md)

    - [翻译: QFMTS：聚焦查询，从多表数据中提炼精华摘要在翻译过程中，我首先确保了原文信息的准确传达，然后对语言进行了优化，使其更加符合中文的表达习惯，同时保持了原文的生动性和简洁性。](2024年05月08日/QFMTS_Generating_Query-Focused_Summaries_over_Multi-Table_Inputs.md)

- [Concerns on Bias in Large Language Models when Creating Synthetic Personae](2024年05月08日/Concerns_on_Bias_in_Large_Language_Models_when_Creating_Synthetic_Personae.md)

    - [翻译: 大型语言模型在塑造虚拟人物时，其潜在的偏见问题日益受到关注。](2024年05月08日/Concerns_on_Bias_in_Large_Language_Models_when_Creating_Synthetic_Personae.md)

- [Impact of Tone-Aware Explanations in Recommender Systems](2024年05月08日/Impact_of_Tone-Aware_Explanations_in_Recommender_Systems.md)

    - [翻译: 推荐系统中，音调感知解释的深远影响在推荐系统中，音调感知解释的深远影响正逐渐显现。这种新颖的方法不仅提升了用户体验，还增强了推荐结果的可信度。通过捕捉用户反馈中的情感色彩，系统能够提供更加个性化和情感共鸣的推荐理由，从而在用户心中建立起更深层次的信任与满意度。](2024年05月08日/Impact_of_Tone-Aware_Explanations_in_Recommender_Systems.md)

- [Conversational Topic Recommendation in Counseling and Psychotherapy with Decision Transformer and Large Language Models](2024年05月08日/Conversational_Topic_Recommendation_in_Counseling_and_Psychotherapy_with_Decision_Transformer_and_Large_Language_Models.md)

    - [翻译: 运用决策转换器与大型语言模型，为咨询与心理治疗中的对话提供精准主题推荐在咨询与心理治疗领域，对话主题的推荐对于引导会话、深化理解至关重要。本研究采用决策转换器与大型语言模型相结合的先进技术，旨在为专业人士提供精准、个性化的对话主题推荐，以促进更有效的沟通与治疗进程。通过分析患者的语言模式与情感状态，系统能够智能生成符合治疗目标的对话主题，为心理健康服务带来创新与效率的提升。](2024年05月08日/Conversational_Topic_Recommendation_in_Counseling_and_Psychotherapy_with_Decision_Transformer_and_Large_Language_Models.md)

- [Seeds of Stereotypes: A Large-Scale Textual Analysis of Race and Gender Associations with Diseases in Online Sources](2024年05月08日/Seeds_of_Stereotypes_A_Large-Scale_Textual_Analysis_of_Race_and_Gender_Associations_with_Diseases_in_Online_Sources.md)

    - [翻译: 刻板印象之源：在线资源中种族与性别疾病关联的大规模文本探析](2024年05月08日/Seeds_of_Stereotypes_A_Large-Scale_Textual_Analysis_of_Race_and_Gender_Associations_with_Diseases_in_Online_Sources.md)

- [ADELIE: Aligning Large Language Models on Information Extraction](2024年05月08日/ADELIE_Aligning_Large_Language_Models_on_Information_Extraction.md)

    - [翻译: ADELIE：大型语言模型在信息抽取领域的精准对齐在翻译过程中，我首先确保原文的核心意义被准确传达，即“ADELIE”是一个关于大型语言模型在信息抽取任务上进行对齐的项目或方法。然后，我调整了语言表达，使其更加符合中文的表达习惯，同时保持了原文的专业性和简洁性。](2024年05月08日/ADELIE_Aligning_Large_Language_Models_on_Information_Extraction.md)

- [NAVRepair: Node-type Aware C/C++ Code Vulnerability Repair](2024年05月08日/NAVRepair_Node-type_Aware_CC++_Code_Vulnerability_Repair.md)

    - [翻译: NAVRepair：智能修复C/C++代码漏洞，精准识别节点类型，为您的代码安全护航。](2024年05月08日/NAVRepair_Node-type_Aware_CC++_Code_Vulnerability_Repair.md)

- [P-ICL: Point In-Context Learning for Named Entity Recognition with Large Language Models](2024年05月08日/P-ICL_Point_In-Context_Learning_for_Named_Entity_Recognition_with_Large_Language_Models.md)

    - [翻译: P-ICL：大型语言模型在命名实体识别中的精准上下文学习在这个翻译中，我采用了“精准”一词来替代“点式”，以使中文表达更加生动和符合中文的表达习惯。同时，“精准上下文学习”也更好地传达了原文中P-ICL方法的特性，即在大型语言模型中针对命名实体识别任务进行精确的上下文信息利用。](2024年05月08日/P-ICL_Point_In-Context_Learning_for_Named_Entity_Recognition_with_Large_Language_Models.md)

- [Harnessing the Power of MLLMs for Transferable Text-to-Image Person ReID](2024年05月08日/Harnessing_the_Power_of_MLLMs_for_Transferable_Text-to-Image_Person_ReID.md)

    - [翻译: 驾驭多模态大型语言模型的力量，实现文本到图像人物再识别的可转移性在翻译过程中，我首先确保了原文意思的准确传达，然后对翻译进行了润色，使其更符合中文的表达习惯，同时保持了原文的生动性和简洁性。](2024年05月08日/Harnessing_the_Power_of_MLLMs_for_Transferable_Text-to-Image_Person_ReID.md)

- [Traj-LLM: A New Exploration for Empowering Trajectory Prediction with Pre-trained Large Language Models](2024年05月08日/Traj-LLM_A_New_Exploration_for_Empowering_Trajectory_Prediction_with_Pre-trained_Large_Language_Models.md)

    - [翻译: 轨迹增强语言模型（Traj-LLM）：探索预训练大型语言模型在轨迹预测领域的创新应用](2024年05月08日/Traj-LLM_A_New_Exploration_for_Empowering_Trajectory_Prediction_with_Pre-trained_Large_Language_Models.md)

- [The Codecfake Dataset and Countermeasures for the Universally Detection of Deepfake Audio](2024年05月08日/The_Codecfake_Dataset_and_Countermeasures_for_the_Universally_Detection_of_Deepfake_Audio.md)

    - [翻译: Codecfake数据集与深度伪造音频检测的通用对策在这项研究中，我们介绍了Codecfake数据集，这是一个专为深度伪造音频检测而设计的新型数据集。我们的目标是提供一个全面的资源，以帮助研究人员开发和测试针对深度伪造音频的检测算法。此外，我们还探讨了一系列反制措施，旨在提高检测算法的鲁棒性和准确性，以应对不断进化的深度伪造技术。通过结合数据集和反制措施，我们希望推动该领域的研究，并为保护公众免受深度伪造音频的潜在威胁做出贡献。](2024年05月08日/The_Codecfake_Dataset_and_Countermeasures_for_the_Universally_Detection_of_Deepfake_Audio.md)

- [Critical Infrastructure Protection: Generative AI, Challenges, and Opportunities](2024年05月08日/Critical_Infrastructure_Protection_Generative_AI,_Challenges,_and_Opportunities.md)

    - [翻译: 守护关键基石：生成式AI的挑战与机遇在翻译过程中，我首先确保了原文核心概念的准确传达，即“关键基础设施保护”与“生成式人工智能”。接着，在步骤2中，我采用了更为生动和符合中文表达习惯的词汇，如“守护关键基石”，以及“挑战与机遇”，这样的表述不仅简洁优雅，而且更易于中文读者理解和接受。](2024年05月08日/Critical_Infrastructure_Protection_Generative_AI,_Challenges,_and_Opportunities.md)

- [Federated Adaptation for Foundation Model-based Recommendations](2024年05月08日/Federated_Adaptation_for_Foundation_Model-based_Recommendations.md)

    - [翻译: 基于基础模型的推荐系统的联邦适应性研究在翻译过程中，我首先直接将英文标题翻译为中文，确保意思的准确传达。然后，我进一步优化翻译，使其更加符合中文的表达习惯，简洁而优雅，同时保持了原标题的学术性和专业性。](2024年05月08日/Federated_Adaptation_for_Foundation_Model-based_Recommendations.md)

- [APrompt4EM: Augmented Prompt Tuning for Generalized Entity Matching](2024年05月08日/APrompt4EM_Augmented_Prompt_Tuning_for_Generalized_Entity_Matching.md)

    - [翻译: APrompt4EM：通用实体匹配的增强提示调优技术](2024年05月08日/APrompt4EM_Augmented_Prompt_Tuning_for_Generalized_Entity_Matching.md)

- [DALK: Dynamic Co-Augmentation of LLMs and KG to answer Alzheimer's Disease Questions with Scientific Literature](2024年05月08日/DALK_Dynamic_Co-Augmentation_of_LLMs_and_KG_to_answer_Alzheimer's_Disease_Questions_with_Scientific_Literature.md)

    - [翻译: DALK：通过动态协同增强 LLMs 与 KG，精准解答阿尔茨海默病相关的科学文献问题。](2024年05月08日/DALK_Dynamic_Co-Augmentation_of_LLMs_and_KG_to_answer_Alzheimer's_Disease_Questions_with_Scientific_Literature.md)

- [ACORN: Aspect-wise Commonsense Reasoning Explanation Evaluation](2024年05月08日/ACORN_Aspect-wise_Commonsense_Reasoning_Explanation_Evaluation.md)

    - [翻译: ACORN：细粒度常识推理解释评价在这个翻译中，我首先直接将英文标题翻译为中文，确保了意思的准确传达。然后，在第二步中，我采用了更符合中文表达习惯的词汇，将“Aspect-wise”翻译为“细粒度”，使得标题更加简洁优雅，同时保持了原意。这样的翻译既符合中文的表达习惯，又能够生动地传达原文的核心概念。](2024年05月08日/ACORN_Aspect-wise_Commonsense_Reasoning_Explanation_Evaluation.md)

- [VisionGraph: Leveraging Large Multimodal Models for Graph Theory Problems in Visual Context](2024年05月08日/VisionGraph_Leveraging_Large_Multimodal_Models_for_Graph_Theory_Problems_in_Visual_Context.md)

    - [翻译: 视觉图谱：借助大型多模态模型，探索视觉场景中的图论难题。](2024年05月08日/VisionGraph_Leveraging_Large_Multimodal_Models_for_Graph_Theory_Problems_in_Visual_Context.md)

- [Benchmarking Neural Radiance Fields for Autonomous Robots: An Overview](2024年05月08日/Benchmarking_Neural_Radiance_Fields_for_Autonomous_Robots_An_Overview.md)

    - [翻译: 自主机器人神经辐射场性能基准：全面概览](2024年05月08日/Benchmarking_Neural_Radiance_Fields_for_Autonomous_Robots_An_Overview.md)

- [Redefining Information Retrieval of Structured Database via Large Language Models](2024年05月08日/Redefining_Information_Retrieval_of_Structured_Database_via_Large_Language_Models.md)

    - [翻译: 大型语言模型重塑结构化数据库信息检索新篇章](2024年05月08日/Redefining_Information_Retrieval_of_Structured_Database_via_Large_Language_Models.md)

- [Cross-Care: Assessing the Healthcare Implications of Pre-training Data on Language Model Bias](2024年05月08日/Cross-Care_Assessing_the_Healthcare_Implications_of_Pre-training_Data_on_Language_Model_Bias.md)

    - [翻译: 跨医疗关怀：探究预训练数据如何塑造语言模型偏见，及其对医疗领域的深远影响在这项研究中，我们将深入探讨预训练数据如何影响语言模型的偏见，并分析这些偏见如何渗透到医疗决策中，从而对患者的护理产生潜在影响。我们的目标是揭示这些偏见的根源，并提出策略以减轻其对医疗保健系统的负面影响。](2024年05月08日/Cross-Care_Assessing_the_Healthcare_Implications_of_Pre-training_Data_on_Language_Model_Bias.md)

- [Boosting Large Language Models with Continual Learning for Aspect-based Sentiment Analysis](2024年05月08日/Boosting_Large_Language_Models_with_Continual_Learning_for_Aspect-based_Sentiment_Analysis.md)

    - [翻译: 借助持续学习，强化大型语言模型在基于方面的情感分析领域的应用在翻译过程中，我首先确保原文的核心意义被准确传达，即“通过持续学习提升大型语言模型在基于方面的情感分析中的性能”。随后，我进一步优化表达，使其更符合中文的流畅性和优雅性，形成了“借助持续学习，强化大型语言模型在基于方面的情感分析领域的应用”的翻译。这样的翻译既保留了原文的技术性，又增添了中文表达的生动性和简洁性。](2024年05月08日/Boosting_Large_Language_Models_with_Continual_Learning_for_Aspect-based_Sentiment_Analysis.md)

- [PLLM-CS: Pre-trained Large Language Model (LLM) for Cyber Threat Detection in Satellite Networks](2024年05月08日/PLLM-CS_Pre-trained_Large_Language_Model_(LLM)_for_Cyber_Threat_Detection_in_Satellite_Networks.md)

    - [翻译: PLLM-CS：专为卫星网络安全威胁检测而设计的预训练大型语言模型，旨在通过先进的语言处理技术，提升对潜在网络风险的识别与防御能力。](2024年05月08日/PLLM-CS_Pre-trained_Large_Language_Model_(LLM)_for_Cyber_Threat_Detection_in_Satellite_Networks.md)

- [Poser: Unmasking Alignment Faking LLMs by Manipulating Their Internals](2024年05月08日/Poser_Unmasking_Alignment_Faking_LLMs_by_Manipulating_Their_Internals.md)

    - [翻译: 揭秘者：操纵LLMs内部机制，揭示其伪装对齐的真相](2024年05月08日/Poser_Unmasking_Alignment_Faking_LLMs_by_Manipulating_Their_Internals.md)

- [Vidur: A Large-Scale Simulation Framework For LLM Inference](2024年05月08日/Vidur_A_Large-Scale_Simulation_Framework_For_LLM_Inference.md)

    - [翻译: Vidur：大型语言模型推理的大型规模模拟框架在翻译过程中，我首先确保了原文意思的准确传达，然后对翻译进行了优化，使其更符合中文的表达习惯，同时保持了原文的简洁和优雅。](2024年05月08日/Vidur_A_Large-Scale_Simulation_Framework_For_LLM_Inference.md)

- [Automated Program Repair: Emerging trends pose and expose problems for benchmarks](2024年05月08日/Automated_Program_Repair_Emerging_trends_pose_and_expose_problems_for_benchmarks.md)

    - [翻译: 自动化程序修复领域的新兴趋势不仅挑战了现有的基准测试，还揭示了其潜在的局限性。](2024年05月08日/Automated_Program_Repair_Emerging_trends_pose_and_expose_problems_for_benchmarks.md)

- [Large Language Model Enhanced Machine Learning Estimators for Classification](2024年05月08日/Large_Language_Model_Enhanced_Machine_Learning_Estimators_for_Classification.md)

    - [翻译: 大型语言模型赋能的机器学习分类器：精准估计新境界](2024年05月08日/Large_Language_Model_Enhanced_Machine_Learning_Estimators_for_Classification.md)

- [Evaluating Students' Open-ended Written Responses with LLMs: Using the RAG Framework for GPT-3.5, GPT-4, Claude-3, and Mistral-Large](2024年05月08日/Evaluating_Students'_Open-ended_Written_Responses_with_LLMs_Using_the_RAG_Framework_for_GPT-3.5,_GPT-4,_Claude-3,_and_Mistral-Large.md)

    - [翻译: 借助RAG框架，我们评估了GPT-3.5、GPT-4、Claude-3和Mistral-Large在评价学生开放式书面回答方面的表现。本研究旨在探索这些大型语言模型在教育评估中的应用潜力。](2024年05月08日/Evaluating_Students'_Open-ended_Written_Responses_with_LLMs_Using_the_RAG_Framework_for_GPT-3.5,_GPT-4,_Claude-3,_and_Mistral-Large.md)

- [Information Extraction from Historical Well Records Using A Large Language Model](2024年05月08日/Information_Extraction_from_Historical_Well_Records_Using_A_Large_Language_Model.md)

    - [翻译: 大型语言模型助力历史井记录信息抽取在上述翻译过程中，首先直接将英文标题翻译为中文，确保意思的准确传达。接着，对直译结果进行优化，使其更加符合中文的表达习惯，同时保持简洁优雅，并增添了一丝生动性。](2024年05月08日/Information_Extraction_from_Historical_Well_Records_Using_A_Large_Language_Model.md)

- [Mitigating Exaggerated Safety in Large Language Models](2024年05月08日/Mitigating_Exaggerated_Safety_in_Large_Language_Models.md)

    - [翻译: 大型语言模型的安全性问题亟待解决，我们致力于减轻其夸大风险，以确保技术的稳健发展。](2024年05月08日/Mitigating_Exaggerated_Safety_in_Large_Language_Models.md)

- [Fishing for Magikarp: Automatically Detecting Under-trained Tokens in Large Language Models](2024年05月08日/Fishing_for_Magikarp_Automatically_Detecting_Under-trained_Tokens_in_Large_Language_Models.md)

    - [翻译: 《捕捉未熟之鳞：自动识别大型语言模型中的欠训练标记》](2024年05月08日/Fishing_for_Magikarp_Automatically_Detecting_Under-trained_Tokens_in_Large_Language_Models.md)

- ["They are uncultured": Unveiling Covert Harms and Social Threats in LLM Generated Conversations](2024年05月08日/They_are_uncultured_Unveiling_Covert_Harms_and_Social_Threats_in_LLM_Generated_Conversations.md)

    - [翻译: "粗俗之言"：揭示大型语言模型对话背后的隐秘伤害与社会风险](2024年05月08日/They_are_uncultured_Unveiling_Covert_Harms_and_Social_Threats_in_LLM_Generated_Conversations.md)

- [Enhancing Holonic Architecture with Natural Language Processing for System of Systems](2024年05月08日/Enhancing_Holonic_Architecture_with_Natural_Language_Processing_for_System_of_Systems.md)

    - [翻译: 借助自然语言处理，我们优化了整体架构，以提升系统之系统的协同效率。](2024年05月08日/Enhancing_Holonic_Architecture_with_Natural_Language_Processing_for_System_of_Systems.md)

- [The Effect of Model Size on LLM Post-hoc Explainability via LIME](2024年05月08日/The_Effect_of_Model_Size_on_LLM_Post-hoc_Explainability_via_LIME.md)

    - [翻译: 在探索大型语言模型的奥秘时，模型的大小扮演着至关重要的角色。通过 LIME 这一工具，我们能够揭开 LLM 的可解释性之谜。本研究将深入探讨模型大小如何影响 LLM 的可解释性，为理解这些复杂系统的内在工作机制提供新的视角。](2024年05月08日/The_Effect_of_Model_Size_on_LLM_Post-hoc_Explainability_via_LIME.md)

- [Benchmarking Educational Program Repair](2024年05月08日/Benchmarking_Educational_Program_Repair.md)

    - [翻译: 教育程序修复的基准评估在这篇文章中，我们将探讨如何通过基准测试来评估和改进教育程序的修复策略。我们将分析不同的修复方法，并探讨它们在提高教育软件质量和效率方面的潜力。通过这一过程，我们旨在为教育技术领域的专业人士提供有价值的见解，帮助他们更好地理解和优化教育程序的修复工作。](2024年05月08日/Benchmarking_Educational_Program_Repair.md)

- [KV-Runahead: Scalable Causal LLM Inference by Parallel Key-Value Cache Generation](2024年05月08日/KV-Runahead_Scalable_Causal_LLM_Inference_by_Parallel_Key-Value_Cache_Generation.md)

    - [翻译: KV-Runahead：并行生成键值缓存，解锁因果LLM推理的扩展潜能在这项研究中，我们提出了KV-Runahead方法，这是一种新颖的技术，通过并行生成键值缓存来提高大型语言模型（LLM）的因果推理效率。我们的方法解决了传统推理方法中的瓶颈问题，实现了更快的推理速度和更好的可扩展性。通过实验验证，KV-Runahead在保持推理质量的同时，显著提升了LLM的性能。](2024年05月08日/KV-Runahead_Scalable_Causal_LLM_Inference_by_Parallel_Key-Value_Cache_Generation.md)

- [Special Characters Attack: Toward Scalable Training Data Extraction From Large Language Models](2024年05月08日/Special_Characters_Attack_Toward_Scalable_Training_Data_Extraction_From_Large_Language_Models.md)

    - [翻译: 特殊字符攻击：揭秘大型语言模型训练数据的提取之谜在这项研究中，我们探讨了一种新颖的攻击手段——特殊字符攻击，它旨在从大型语言模型中提取训练数据。通过精心设计的特殊字符组合，我们能够揭示模型背后的知识库，为数据隐私和安全带来新的挑战。](2024年05月08日/Special_Characters_Attack_Toward_Scalable_Training_Data_Extraction_From_Large_Language_Models.md)

- [Automated Conversion of Static to Dynamic Scheduler via Natural Language](2024年05月08日/Automated_Conversion_of_Static_to_Dynamic_Scheduler_via_Natural_Language.md)

    - [翻译: 自然语言助力，静态调度器智能升级为动态调度器，自动化转换一触即发。](2024年05月08日/Automated_Conversion_of_Static_to_Dynamic_Scheduler_via_Natural_Language.md)

- [LLM-Augmented Agent-Based Modelling for Social Simulations: Challenges and Opportunities](2024年05月08日/LLM-Augmented_Agent-Based_Modelling_for_Social_Simulations_Challenges_and_Opportunities.md)

    - [翻译: 大型语言模型赋能的代理建模在社交模拟中的探索：挑战与新机遇在大型语言模型的助力下，基于代理的建模技术在社交模拟领域展现出新的挑战与机遇。这种结合不仅为模拟复杂社会动态提供了更强大的工具，也开启了探索人类行为与社会结构的新篇章。然而，这一领域的深入发展仍需面对模型复杂性、数据准确性以及伦理考量等多重挑战。](2024年05月08日/LLM-Augmented_Agent-Based_Modelling_for_Social_Simulations_Challenges_and_Opportunities.md)

- [Optimizing Tensor Contraction Paths: A Greedy Algorithm Approach With Improved Cost Functions](2024年05月08日/Optimizing_Tensor_Contraction_Paths_A_Greedy_Algorithm_Approach_With_Improved_Cost_Functions.md)

    - [翻译: 张量收缩路径的优化：贪婪算法与精进成本函数的双重奏](2024年05月08日/Optimizing_Tensor_Contraction_Paths_A_Greedy_Algorithm_Approach_With_Improved_Cost_Functions.md)

- [An Overview of Machine Learning-Enabled Optimization for Reconfigurable Intelligent Surfaces-Aided 6G Networks: From Reinforcement Learning to Large Language Models](2024年05月08日/An_Overview_of_Machine_Learning-Enabled_Optimization_for_Reconfigurable_Intelligent_Surfaces-Aided_6G_Networks_From_Reinforcement_Learning_to_Large_Language_Models.md)

    - [翻译: 6G网络中可重构智能表面的机器学习优化综述：从强化学习到大语言模型的演进](2024年05月08日/An_Overview_of_Machine_Learning-Enabled_Optimization_for_Reconfigurable_Intelligent_Surfaces-Aided_6G_Networks_From_Reinforcement_Learning_to_Large_Language_Models.md)

2024年05月07日

- [ChatHuman: Language-driven 3D Human Understanding with Retrieval-Augmented Tool Reasoning](2024年05月07日/ChatHuman_Language-driven_3D_Human_Understanding_with_Retrieval-Augmented_Tool_Reasoning.md)

    - [翻译: ChatHuman：借助检索增强的工具推理，实现语言驱动的3D人体理解在这项研究中，我们提出了ChatHuman，一个创新系统，它通过结合语言理解和检索增强的工具推理，实现了对3D人体的深入理解。该系统不仅能够处理复杂的语言指令，还能够利用检索机制来增强其推理能力，从而在3D人体建模和交互任务中展现出卓越的性能。](2024年05月07日/ChatHuman_Language-driven_3D_Human_Understanding_with_Retrieval-Augmented_Tool_Reasoning.md)

- [QServe: W4A8KV4 Quantization and System Co-design for Efficient LLM Serving](2024年05月07日/QServe_W4A8KV4_Quantization_and_System_Co-design_for_Efficient_LLM_Serving.md)

    - [翻译: QServe：W4A8KV4 量化与系统协同设计，为大型语言模型服务提供高效解决方案](2024年05月07日/QServe_W4A8KV4_Quantization_and_System_Co-design_for_Efficient_LLM_Serving.md)

- [NaturalCodeBench: Examining Coding Performance Mismatch on HumanEval and Natural User Prompts](2024年05月07日/NaturalCodeBench_Examining_Coding_Performance_Mismatch_on_HumanEval_and_Natural_User_Prompts.md)

    - [翻译: NaturalCodeBench：探究HumanEval与自然用户提示间编码性能的差异解释：在结果2中，我采用了更加流畅和符合中文表达习惯的翻译方式，将“Examining Coding Performance Mismatch”翻译为“探究编码性能的差异”，使得整个句子更加简洁优雅，同时保留了原文的意思。](2024年05月07日/NaturalCodeBench_Examining_Coding_Performance_Mismatch_on_HumanEval_and_Natural_User_Prompts.md)

- [xLSTM: Extended Long Short-Term Memory](2024年05月07日/xLSTM_Extended_Long_Short-Term_Memory.md)

    - [翻译: xLSTM：拓展版长短期记忆网络在翻译过程中，我首先确保了原文的核心概念“Extended Long Short-Term Memory”被准确地翻译为“扩展的长短期记忆”。接着，在步骤2中，我考虑了中文表达的习惯，将“扩展的”调整为“拓展版”，使得翻译更加符合中文的表达习惯，同时保持了原文的含义和专业性。这样的翻译既简洁又优雅，同时也保持了原文的生动性。](2024年05月07日/xLSTM_Extended_Long_Short-Term_Memory.md)

- [A Transformer with Stack Attention](2024年05月07日/A_Transformer_with_Stack_Attention.md)

    - [翻译: 堆叠注意力机制的Transformer在翻译过程中，我首先直接将英文翻译为中文，确保意思的准确性。然后，我对直译的中文进行了优化，使其更加符合中文的语言表达习惯，同时保持了原文的简洁和优雅。在第二个步骤中，我将“A Transformer with Stack Attention”优化为“堆叠注意力机制的Transformer”，这样的表达更加符合中文的表述习惯，同时也更加生动和易于理解。](2024年05月07日/A_Transformer_with_Stack_Attention.md)

- [Unveiling Disparities in Web Task Handling Between Human and Web Agent](2024年05月07日/Unveiling_Disparities_in_Web_Task_Handling_Between_Human_and_Web_Agent.md)

    - [翻译: 揭秘人类与网络代理在网络任务处理上的差异之谜](2024年05月07日/Unveiling_Disparities_in_Web_Task_Handling_Between_Human_and_Web_Agent.md)

- [Toward In-Context Teaching: Adapting Examples to Students' Misconceptions](2024年05月07日/Toward_In-Context_Teaching_Adapting_Examples_to_Students'_Misconceptions.md)

    - [翻译: 迈向情境化教学：量身定制示例，以纠正学生的认知误区](2024年05月07日/Toward_In-Context_Teaching_Adapting_Examples_to_Students'_Misconceptions.md)

- [The Silicone Ceiling: Auditing GPT's Race and Gender Biases in Hiring](2024年05月07日/The_Silicone_Ceiling_Auditing_GPT's_Race_and_Gender_Biases_in_Hiring.md)

    - [翻译: 硅胶屏障：审视GPT在招聘决策中潜藏的种族与性别偏见](2024年05月07日/The_Silicone_Ceiling_Auditing_GPT's_Race_and_Gender_Biases_in_Hiring.md)

- [Learning To See But Forgetting To Follow: Visual Instruction Tuning Makes LLMs More Prone To Jailbreak Attacks](2024年05月07日/Learning_To_See_But_Forgetting_To_Follow_Visual_Instruction_Tuning_Makes_LLMs_More_Prone_To_Jailbreak_Attacks.md)

    - [翻译: 视觉指令调教下的学习，大型语言模型虽能“看”得更清，却更易在“跟随”指令上失守，从而更易遭受越狱攻击。](2024年05月07日/Learning_To_See_But_Forgetting_To_Follow_Visual_Instruction_Tuning_Makes_LLMs_More_Prone_To_Jailbreak_Attacks.md)

- [Large Language Models Cannot Explain Themselves](2024年05月07日/Large_Language_Models_Cannot_Explain_Themselves.md)

    - [翻译: 巨型语言模型自解谜团难，其内在逻辑尚待深究。](2024年05月07日/Large_Language_Models_Cannot_Explain_Themselves.md)

- [Revisiting character-level adversarial attacks](2024年05月07日/Revisiting_character-level_adversarial_attacks.md)

    - [翻译: 再探字符级对抗攻击：深入分析与挑战](2024年05月07日/Revisiting_character-level_adversarial_attacks.md)

- [A Fourth Wave of Open Data? Exploring the Spectrum of Scenarios for Open Data and Generative AI](2024年05月07日/A_Fourth_Wave_of_Open_Data_Exploring_the_Spectrum_of_Scenarios_for_Open_Data_and_Generative_AI.md)

    - [翻译: 开放数据的第四波浪潮？我们正探索开放数据与生成式AI交织的多元场景。](2024年05月07日/A_Fourth_Wave_of_Open_Data_Exploring_the_Spectrum_of_Scenarios_for_Open_Data_and_Generative_AI.md)

- [Deception in Reinforced Autonomous Agents: The Unconventional Rabbit Hat Trick in Legislation](2024年05月07日/Deception_in_Reinforced_Autonomous_Agents_The_Unconventional_Rabbit_Hat_Trick_in_Legislation.md)

    - [翻译: 强化自主代理中的欺骗行为：立法中的非传统兔子帽戏法之谜在强化自主代理领域，欺骗行为如同立法中的非传统兔子帽戏法，既神秘又引人入胜。这种行为在自主代理的决策过程中扮演着复杂角色，其影响深远，如同戏法中的兔子，既出人意料又充满变数。本研究将深入探讨这一现象，揭示其在立法框架下的独特影响。](2024年05月07日/Deception_in_Reinforced_Autonomous_Agents_The_Unconventional_Rabbit_Hat_Trick_in_Legislation.md)

- [Granite Code Models: A Family of Open Foundation Models for Code Intelligence](2024年05月07日/Granite_Code_Models_A_Family_of_Open_Foundation_Models_for_Code_Intelligence.md)

    - [翻译: 代码智能之石：花岗岩系列开源基础模型在](2024年05月07日/Granite_Code_Models_A_Family_of_Open_Foundation_Models_for_Code_Intelligence.md)

- [Accelerating Speculative Decoding using Dynamic Speculation Length](2024年05月07日/Accelerating_Speculative_Decoding_using_Dynamic_Speculation_Length.md)

    - [翻译: 动态推测长度优化：加速语言模型解码的新策略在翻译过程中，我首先确保了原文意思的准确传达，然后对语言进行了优化，使其更加符合中文的表达习惯，同时保持了原文的生动性和简洁性。](2024年05月07日/Accelerating_Speculative_Decoding_using_Dynamic_Speculation_Length.md)

- [Enhancing the Efficiency and Accuracy of Underlying Asset Reviews in Structured Finance: The Application of Multi-agent Framework](2024年05月07日/Enhancing_the_Efficiency_and_Accuracy_of_Underlying_Asset_Reviews_in_Structured_Finance_The_Application_of_Multi-agent_Framework.md)

    - [翻译: 结构化金融底层资产审查的效率与准确性提升：多代理框架的巧妙应用在结构化金融领域，底层资产的审查是确保交易稳健性的关键。传统的审查方法往往耗时且准确性有限。然而，多代理框架的引入，如同一场精妙的棋局，每个代理如同棋子，各司其职，协同作战，极大地提升了审查的效率与准确性。这一创新的应用，不仅优化了金融资产的评估流程，也为投资者提供了更为坚实的决策基础。](2024年05月07日/Enhancing_the_Efficiency_and_Accuracy_of_Underlying_Asset_Reviews_in_Structured_Finance_The_Application_of_Multi-agent_Framework.md)

- [Who Wrote This? The Key to Zero-Shot LLM-Generated Text Detection Is GECScore](2024年05月07日/Who_Wrote_This_The_Key_to_Zero-Shot_LLM-Generated_Text_Detection_Is_GECScore.md)

    - [翻译: 这篇文章的作者是谁？GECScore 是识别零-shot LLM 生成文本的关键工具。](2024年05月07日/Who_Wrote_This_The_Key_to_Zero-Shot_LLM-Generated_Text_Detection_Is_GECScore.md)

- [Semantic API Alignment: Linking High-level User Goals to APIs](2024年05月07日/Semantic_API_Alignment_Linking_High-level_User_Goals_to_APIs.md)

    - [翻译: 语义API匹配：构建高级用户目标与API之间的桥梁](2024年05月07日/Semantic_API_Alignment_Linking_High-level_User_Goals_to_APIs.md)

- [Iterative Experience Refinement of Software-Developing Agents](2024年05月07日/Iterative_Experience_Refinement_of_Software-Developing_Agents.md)

    - [翻译: 软件开发代理通过迭代精炼经验在](2024年05月07日/Iterative_Experience_Refinement_of_Software-Developing_Agents.md)

- [NL2Plan: Robust LLM-Driven Planning from Minimal Text Descriptions](2024年05月07日/NL2Plan_Robust_LLM-Driven_Planning_from_Minimal_Text_Descriptions.md)

    - [翻译: NL2Plan：基于精简文本描述，实现大型语言模型驱动的稳健规划系统解释：在结果2中，我采用了更加流畅和符合中文表达习惯的措辞，将“Robust LLM-Driven Planning”翻译为“稳健规划系统”，并调整了“from Minimal Text Descriptions”的翻译，使其更加符合中文的表达方式。这样的翻译既保留了原文的核心意义，又使得中文表达更加自然和优雅。](2024年05月07日/NL2Plan_Robust_LLM-Driven_Planning_from_Minimal_Text_Descriptions.md)

- [Sora Detector: A Unified Hallucination Detection for Large Text-to-Video Models](2024年05月07日/Sora_Detector_A_Unified_Hallucination_Detection_for_Large_Text-to-Video_Models.md)

    - [翻译: Sora检测器：大型文本至视频模型幻觉现象的统一检测利器](2024年05月07日/Sora_Detector_A_Unified_Hallucination_Detection_for_Large_Text-to-Video_Models.md)

- [D-NLP at SemEval-2024 Task 2: Evaluating Clinical Inference Capabilities of Large Language Models](2024年05月07日/D-NLP_at_SemEval-2024_Task_2_Evaluating_Clinical_Inference_Capabilities_of_Large_Language_Models.md)

    - [翻译: SemEval-2024 第二任务：探究大型语言模型在临床推理领域的评估能力在 SemEval-2024 的第二项任务中，我们将深入探讨大型语言模型在临床推理方面的表现。这项研究旨在评估这些模型在处理医疗相关文本时的推理能力，以及它们如何理解和分析临床情境中的复杂信息。通过这一评估，我们期望能够揭示大型语言模型在医疗领域应用中的潜力和局限性，为未来的医疗人工智能发展提供宝贵的见解。](2024年05月07日/D-NLP_at_SemEval-2024_Task_2_Evaluating_Clinical_Inference_Capabilities_of_Large_Language_Models.md)

- [LingML: Linguistic-Informed Machine Learning for Enhanced Fake News Detection](2024年05月07日/LingML_Linguistic-Informed_Machine_Learning_for_Enhanced_Fake_News_Detection.md)

    - [翻译: LingML：融合语言学智慧的机器学习，助力假新闻检测更上一层楼](2024年05月07日/LingML_Linguistic-Informed_Machine_Learning_for_Enhanced_Fake_News_Detection.md)

- [Sign2GPT: Leveraging Large Language Models for Gloss-Free Sign Language Translation](2024年05月07日/Sign2GPT_Leveraging_Large_Language_Models_for_Gloss-Free_Sign_Language_Translation.md)

    - [翻译: Sign2GPT：借助大型语言模型实现无词典辅助的美国手语翻译在这项研究中，我们提出了Sign2GPT，这是一种创新的方法，它利用了大型语言模型的强大能力，实现了无需依赖传统手势词典的美国手语翻译。通过这种方法，我们旨在打破传统翻译的局限，为手语用户提供更加流畅和自然的交流体验。](2024年05月07日/Sign2GPT_Leveraging_Large_Language_Models_for_Gloss-Free_Sign_Language_Translation.md)

- [MEDVOC: Vocabulary Adaptation for Fine-tuning Pre-trained Language Models on Medical Text Summarization](2024年05月07日/MEDVOC_Vocabulary_Adaptation_for_Fine-tuning_Pre-trained_Language_Models_on_Medical_Text_Summarization.md)

    - [翻译: MEDVOC：医学文本摘要中预训练语言模型的词汇微调适应在这项研究中，我们提出了MEDVOC，一种专门为医学文本摘要任务设计的词汇适应方法。通过微调预训练语言模型，MEDVOC旨在提高模型对医学领域特定术语和概念的理解，从而生成更准确、更具信息量的摘要。我们的方法结合了领域知识与先进的自然语言处理技术，为医学文献的自动化摘要提供了新的可能性。](2024年05月07日/MEDVOC_Vocabulary_Adaptation_for_Fine-tuning_Pre-trained_Language_Models_on_Medical_Text_Summarization.md)

- [A Causal Explainable Guardrails for Large Language Models](2024年05月07日/A_Causal_Explainable_Guardrails_for_Large_Language_Models.md)

    - [翻译: 大型语言模型的因果解释性护栏在这篇文章中，我们将探讨如何为大型语言模型构建因果解释性保护措施，以确保其决策过程的透明度和可解释性。通过这种方式，我们不仅能够理解模型如何做出决策，还能确保其行为符合我们的预期和道德标准。](2024年05月07日/A_Causal_Explainable_Guardrails_for_Large_Language_Models.md)

- [How does GPT-2 Predict Acronyms? Extracting and Understanding a Circuit via Mechanistic Interpretability](2024年05月07日/How_does_GPT-2_Predict_Acronyms_Extracting_and_Understanding_a_Circuit_via_Mechanistic_Interpretability.md)

    - [翻译: GPT-2如何巧妙预测缩写？我们通过机械可解释性的透镜，深入探索其内部运作，揭秘其预测缩写的神秘电路。](2024年05月07日/How_does_GPT-2_Predict_Acronyms_Extracting_and_Understanding_a_Circuit_via_Mechanistic_Interpretability.md)

- [Enriched BERT Embeddings for Scholarly Publication Classification](2024年05月07日/Enriched_BERT_Embeddings_for_Scholarly_Publication_Classification.md)

    - [翻译: BERT嵌入的丰富化助力学术出版物精准分类](2024年05月07日/Enriched_BERT_Embeddings_for_Scholarly_Publication_Classification.md)

- [In-context Learning for Automated Driving Scenarios](2024年05月07日/In-context_Learning_for_Automated_Driving_Scenarios.md)

    - [翻译: 自动驾驶场景中的上下文学习（ICL），为智能驾驶系统提供了新的学习范式。](2024年05月07日/In-context_Learning_for_Automated_Driving_Scenarios.md)

- [Optimizing Language Model's Reasoning Abilities with Weak Supervision](2024年05月07日/Optimizing_Language_Model's_Reasoning_Abilities_with_Weak_Supervision.md)

    - [翻译: 借助弱监督之力，精炼语言模型的推理之智](2024年05月07日/Optimizing_Language_Model's_Reasoning_Abilities_with_Weak_Supervision.md)

- [FlashBack:Efficient Retrieval-Augmented Language Modeling for Long Context Inference](2024年05月07日/FlashBackEfficient_Retrieval-Augmented_Language_Modeling_for_Long_Context_Inference.md)

    - [翻译: 闪回技术：提升长篇推理中语言建模效率的检索增强方法](2024年05月07日/FlashBackEfficient_Retrieval-Augmented_Language_Modeling_for_Long_Context_Inference.md)

- [Evaluating Text Summaries Generated by Large Language Models Using OpenAI's GPT](2024年05月07日/Evaluating_Text_Summaries_Generated_by_Large_Language_Models_Using_OpenAI's_GPT.md)

    - [翻译: 借助OpenAI的GPT，我们评估了大型语言模型所生成的文本摘要，探究其在信息提炼与表达上的精妙之处。](2024年05月07日/Evaluating_Text_Summaries_Generated_by_Large_Language_Models_Using_OpenAI's_GPT.md)

- [Locally Differentially Private In-Context Learning](2024年05月07日/Locally_Differentially_Private_In-Context_Learning.md)

    - [翻译: 局部差分隐私下的上下文学习在翻译过程中，我首先直接将英文标题翻译为中文，确保意思的准确性。然后，在第二步中，我进一步优化了翻译，使其更加符合中文的表达习惯，简洁而优雅。"局部差分隐私下的上下文学习"这个翻译既保留了原英文标题的含义，又使其在中文语境中更加通顺和易于理解。](2024年05月07日/Locally_Differentially_Private_In-Context_Learning.md)

- [SEED-Data-Edit Technical Report: A Hybrid Dataset for Instructional Image Editing](2024年05月07日/SEED-Data-Edit_Technical_Report_A_Hybrid_Dataset_for_Instructional_Image_Editing.md)

    - [翻译: SEED-Data-Edit 技术报告：教学图像编辑的混合数据集探索在这份技术报告中，我们介绍了 SEED-Data-Edit，一个专为教学图像编辑而设计的混合数据集。该数据集结合了多种图像编辑任务，旨在为研究人员和开发者提供一个全面的资源，以探索和提升图像编辑技术的教学方法。通过深入分析数据集的构成和应用，我们希望激发更多关于图像编辑教学的创新思路和实践。](2024年05月07日/SEED-Data-Edit_Technical_Report_A_Hybrid_Dataset_for_Instructional_Image_Editing.md)

- [Sketch Then Generate: Providing Incremental User Feedback and Guiding LLM Code Generation through Language-Oriented Code Sketches](2024年05月07日/Sketch_Then_Generate_Providing_Incremental_User_Feedback_and_Guiding_LLM_Code_Generation_through_Language-Oriented_Code_Sketches.md)

    - [翻译: 草绘启程，代码随行：借助语言导向的代码草图，我们逐步收集用户反馈，巧妙引导大型语言模型，使其代码生成更加精准。](2024年05月07日/Sketch_Then_Generate_Providing_Incremental_User_Feedback_and_Guiding_LLM_Code_Generation_through_Language-Oriented_Code_Sketches.md)

- [TrimCaching: Parameter-sharing AI Model Caching in Wireless Edge Networks](2024年05月07日/TrimCaching_Parameter-sharing_AI_Model_Caching_in_Wireless_Edge_Networks.md)

    - [翻译: 精简缓存：无线边缘网络中的共享参数AI模型缓存技术在这项研究中，我们提出了一种名为“精简缓存”的新型技术，它旨在优化无线边缘网络中的AI模型缓存策略。通过共享参数，我们的方法能够更高效地利用网络资源，同时提供快速的AI服务响应。这种方法特别适用于资源受限的边缘环境，能够在保证性能的同时，减少对网络带宽和存储的需求。](2024年05月07日/TrimCaching_Parameter-sharing_AI_Model_Caching_in_Wireless_Edge_Networks.md)

- [A Method for Parsing and Vectorization of Semi-structured Data used in Retrieval Augmented Generation](2024年05月07日/A_Method_for_Parsing_and_Vectorization_of_Semi-structured_Data_used_in_Retrieval_Augmented_Generation.md)

    - [翻译: 一种解析与向量化半结构化数据的技艺，专为检索增强生成而设计](2024年05月07日/A_Method_for_Parsing_and_Vectorization_of_Semi-structured_Data_used_in_Retrieval_Augmented_Generation.md)

- [Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application](2024年05月07日/Knowledge_Adaptation_from_Large_Language_Model_to_Recommendation_for_Practical_Industrial_Application.md)

    - [翻译: 大型语言模型知识迁移至推荐系统：工业应用实践之路](2024年05月07日/Knowledge_Adaptation_from_Large_Language_Model_to_Recommendation_for_Practical_Industrial_Application.md)

- [COM3D: Leveraging Cross-View Correspondence and Cross-Modal Mining for 3D Retrieval](2024年05月07日/COM3D_Leveraging_Cross-View_Correspondence_and_Cross-Modal_Mining_for_3D_Retrieval.md)

    - [翻译: COM3D：借助跨视图匹配与跨模态挖掘，精进3D检索技艺在这项研究中，我们提出了一种名为COM3D的新型框架，它巧妙地结合了跨视图对应和跨模态挖掘技术，以提升3D对象检索的准确性和效率。通过深入分析不同视图间的内在联系，并挖掘多模态数据中的潜在信息，COM3D在3D检索领域展现了其独特的优势。](2024年05月07日/COM3D_Leveraging_Cross-View_Correspondence_and_Cross-Modal_Mining_for_3D_Retrieval.md)

- [Zero-shot LLM-guided Counterfactual Generation for Text](2024年05月07日/Zero-shot_LLM-guided_Counterfactual_Generation_for_Text.md)

    - [翻译: 大型语言模型零-shot引导的文本反事实创作在翻译过程中，我首先确保了原文意思的准确传达，然后对翻译结果进行了优化，使其更符合中文的表达习惯，同时保持了原文的生动性和简洁性。](2024年05月07日/Zero-shot_LLM-guided_Counterfactual_Generation_for_Text.md)

- [CourseGPT-zh: an Educational Large Language Model Based on Knowledge Distillation Incorporating Prompt Optimization](2024年05月07日/CourseGPT-zh_an_Educational_Large_Language_Model_Based_on_Knowledge_Distillation_Incorporating_Prompt_Optimization.md)

    - [翻译: CourseGPT-zh：融合知识蒸馏与提示优化技术的教育领域大型语言模型，旨在通过精炼的知识传递与优化学习提示，提升教育场景下的语言处理能力。](2024年05月07日/CourseGPT-zh_an_Educational_Large_Language_Model_Based_on_Knowledge_Distillation_Incorporating_Prompt_Optimization.md)

- [Empathy Through Multimodality in Conversational Interfaces](2024年05月07日/Empathy_Through_Multimodality_in_Conversational_Interfaces.md)

    - [翻译: 对话接口中的多模态共情在对话接口中，通过多模态技术实现共情，旨在提升用户体验和交互的自然性。本研究探讨了如何整合视觉、听觉和语言信息，以增强对话系统对用户情感的理解和响应，从而在人机交互中营造出更加共情的氛围。](2024年05月07日/Empathy_Through_Multimodality_in_Conversational_Interfaces.md)

- [Chain of Thoughtlessness: An Analysis of CoT in Planning](2024年05月07日/Chain_of_Thoughtlessness_An_Analysis_of_CoT_in_Planning.md)

    - [翻译: 思维链的盲点：探究计划中思维链的运用与局限在翻译过程中，我首先确保原文的核心意义被准确传达，即对“思维链”（Chain of Thought）在计划制定中的应用进行分析。在第二步中，我调整了表达方式，使其更符合中文的修辞习惯，同时保持了原文的生动性和简洁性。通过使用“盲点”一词，我强调了研究中可能忽视的方面，同时也为读者提供了一个形象的视角来理解这一复杂的概念。](2024年05月07日/Chain_of_Thoughtlessness_An_Analysis_of_CoT_in_Planning.md)

- [Exploring Vision Transformers for 3D Human Motion-Language Models with Motion Patches](2024年05月07日/Exploring_Vision_Transformers_for_3D_Human_Motion-Language_Models_with_Motion_Patches.md)

    - [翻译: 探究视觉变压器结合运动补丁在三维人体运动与语言模型中的应用，以深入理解其对运动表达的影响。](2024年05月07日/Exploring_Vision_Transformers_for_3D_Human_Motion-Language_Models_with_Motion_Patches.md)

- [Large Language Models for Cyber Security: A Systematic Literature Review](2024年05月07日/Large_Language_Models_for_Cyber_Security_A_Systematic_Literature_Review.md)

    - [翻译: 网络安全领域的大型语言模型：系统性文献综述探索在本次系统性文献综述中，我们将深入探讨大型语言模型在网络安全领域的应用，分析其在识别威胁、预测攻击模式以及自动化响应策略等方面的潜力与挑战。通过对现有文献的综合梳理，我们旨在揭示这些先进技术如何助力网络安全专家构筑更为坚固的数字防线。](2024年05月07日/Large_Language_Models_for_Cyber_Security_A_Systematic_Literature_Review.md)

- [BiasKG: Adversarial Knowledge Graphs to Induce Bias in Large Language Models](2024年05月07日/BiasKG_Adversarial_Knowledge_Graphs_to_Induce_Bias_in_Large_Language_Models.md)

    - [翻译: 偏见图谱BiasKG：塑造大型语言模型的对抗性知识网络，旨在引入并研究模型中的偏见现象。](2024年05月07日/BiasKG_Adversarial_Knowledge_Graphs_to_Induce_Bias_in_Large_Language_Models.md)

- [AttacKG+:Boosting Attack Knowledge Graph Construction with Large Language Models](2024年05月07日/AttacKG+Boosting_Attack_Knowledge_Graph_Construction_with_Large_Language_Models.md)

    - [翻译: AttacKG+：借助大型语言模型，强化攻击知识图谱的构建能力](2024年05月07日/AttacKG+Boosting_Attack_Knowledge_Graph_Construction_with_Large_Language_Models.md)

- [LLMs Can Patch Up Missing Relevance Judgments in Evaluation](2024年05月07日/LLMs_Can_Patch_Up_Missing_Relevance_Judgments_in_Evaluation.md)

    - [翻译: 大型语言模型（LLMs）具备修补评估中缺失相关性判断的能力，为评估体系的完善提供了新的可能性。](2024年05月07日/LLMs_Can_Patch_Up_Missing_Relevance_Judgments_in_Evaluation.md)

- [Enhancing Knowledge Retrieval with Topic Modeling for Knowledge-Grounded Dialogue](2024年05月07日/Enhancing_Knowledge_Retrieval_with_Topic_Modeling_for_Knowledge-Grounded_Dialogue.md)

    - [翻译: 利用主题建模提升知识检索，助力基于知识的对话系统更上一层楼。](2024年05月07日/Enhancing_Knowledge_Retrieval_with_Topic_Modeling_for_Knowledge-Grounded_Dialogue.md)

- [Robust Implementation of Retrieval-Augmented Generation on Edge-based Computing-in-Memory Architectures](2024年05月07日/Robust_Implementation_of_Retrieval-Augmented_Generation_on_Edge-based_Computing-in-Memory_Architectures.md)

    - [翻译: 在内存计算架构的边缘计算环境中，增强检索生成的稳健实现解释：在](2024年05月07日/Robust_Implementation_of_Retrieval-Augmented_Generation_on_Edge-based_Computing-in-Memory_Architectures.md)

- [Bridging the Bosphorus: Advancing Turkish Large Language Models through Strategies for Low-Resource Language Adaptation and Benchmarking](2024年05月07日/Bridging_the_Bosphorus_Advancing_Turkish_Large_Language_Models_through_Strategies_for_Low-Resource_Language_Adaptation_and_Benchmarking.md)

    - [翻译: 博斯普鲁斯之桥：借助低资源语言适应与基准测试策略，推动土耳其大型语言模型的进步。](2024年05月07日/Bridging_the_Bosphorus_Advancing_Turkish_Large_Language_Models_through_Strategies_for_Low-Resource_Language_Adaptation_and_Benchmarking.md)

- [Towards Accurate and Efficient Document Analytics with Large Language Models](2024年05月07日/Towards_Accurate_and_Efficient_Document_Analytics_with_Large_Language_Models.md)

    - [翻译: 大型语言模型助力精准高效文档分析](2024年05月07日/Towards_Accurate_and_Efficient_Document_Analytics_with_Large_Language_Models.md)

- [Towards a Theoretical Understanding of the 'Reversal Curse' via Training Dynamics](2024年05月07日/Towards_a_Theoretical_Understanding_of_the_'Reversal_Curse'_via_Training_Dynamics.md)

    - [翻译: 探索训练动态，揭开“逆转诅咒”的理论之谜在翻译过程中，我首先确保了原文意思的准确传达，然后对直译的中文进行了优化，使其更加符合中文的表达习惯，同时保持了原文的学术性和专业性。通过使用“探索”和“揭开”等动词，以及“理论之谜”这样的形象化表达，使得翻译后的中文更加生动活泼，简洁优雅。](2024年05月07日/Towards_a_Theoretical_Understanding_of_the_'Reversal_Curse'_via_Training_Dynamics.md)

- [Corporate Communication Companion (CCC): An LLM-empowered Writing Assistant for Workplace Social Media](2024年05月07日/Corporate_Communication_Companion_(CCC)_An_LLM-empowered_Writing_Assistant_for_Workplace_Social_Media.md)

    - [翻译: 职场社交写作良伴（CCC）：一款由先进 LLM 技术驱动的智能助手，专为提升企业沟通效率而生。](2024年05月07日/Corporate_Communication_Companion_(CCC)_An_LLM-empowered_Writing_Assistant_for_Workplace_Social_Media.md)

- [Understanding the Capabilities and Limitations of Large Language Models for Cultural Commonsense](2024年05月07日/Understanding_the_Capabilities_and_Limitations_of_Large_Language_Models_for_Cultural_Commonsense.md)

    - [翻译: 探究大型语言模型在文化常识领域的潜能与边界](2024年05月07日/Understanding_the_Capabilities_and_Limitations_of_Large_Language_Models_for_Cultural_Commonsense.md)

- [AffirmativeAI: Towards LGBTQ+ Friendly Audit Frameworks for Large Language Models](2024年05月07日/AffirmativeAI_Towards_LGBTQ+_Friendly_Audit_Frameworks_for_Large_Language_Models.md)

    - [翻译: AffirmativeAI：迈向大型语言模型的LGBTQ+友好审计框架。](2024年05月07日/AffirmativeAI_Towards_LGBTQ+_Friendly_Audit_Frameworks_for_Large_Language_Models.md)

- [Enhancing LLM-Based Feedback: Insights from Intelligent Tutoring Systems and the Learning Sciences](2024年05月07日/Enhancing_LLM-Based_Feedback_Insights_from_Intelligent_Tutoring_Systems_and_the_Learning_Sciences.md)

    - [翻译: 提升大型语言模型反馈：智能辅导系统与学习科学的启示](2024年05月07日/Enhancing_LLM-Based_Feedback_Insights_from_Intelligent_Tutoring_Systems_and_the_Learning_Sciences.md)

- [Contextual API Completion for Unseen Repositories Using LLMs](2024年05月07日/Contextual_API_Completion_for_Unseen_Repositories_Using_LLMs.md)

    - [翻译: 借助大型语言模型，我们能够为未曾涉猎的代码库提供精准的上下文API自动补全功能。](2024年05月07日/Contextual_API_Completion_for_Unseen_Repositories_Using_LLMs.md)

- [Language Modeling Using Tensor Trains](2024年05月07日/Language_Modeling_Using_Tensor_Trains.md)

    - [翻译: 张量列车语言建模：探索语言的深层结构在翻译过程中，我首先确保了原文的核心概念“张量列车”和“语言建模”被准确传达。然后，在第二步中，我采用了更加生动和符合中文表达习惯的措辞，将“使用张量列车进行语言建模”转化为“张量列车语言建模：探索语言的深层结构”，这样的表述不仅简洁优雅，而且能够激发读者对这一技术主题的兴趣。](2024年05月07日/Language_Modeling_Using_Tensor_Trains.md)

- [All in One Framework for Multimodal Re-identification in the Wild](2024年05月07日/All_in_One_Framework_for_Multimodal_Re-identification_in_the_Wild.md)

    - [翻译: 一体式框架：野外多模态身份再识别的全面解决方案](2024年05月07日/All_in_One_Framework_for_Multimodal_Re-identification_in_the_Wild.md)

- [Generative AI as a metacognitive agent: A comparative mixed-method study with human participants on ICF-mimicking exam performance](2024年05月07日/Generative_AI_as_a_metacognitive_agent_A_comparative_mixed-method_study_with_human_participants_on_ICF-mimicking_exam_performance.md)

    - [翻译: 生成式AI：元认知代理的比较研究——探究其在ICF模拟考试中与人类参与者的表现差异在这次比较混合方法研究中，我们探讨了生成式人工智能作为元认知代理在ICF模拟考试中的表现，并与人类参与者的表现进行了对比。通过这种方法，我们旨在揭示生成式AI在模拟考试环境中的潜力和局限性，以及它与人类认知过程的异同。](2024年05月07日/Generative_AI_as_a_metacognitive_agent_A_comparative_mixed-method_study_with_human_participants_on_ICF-mimicking_exam_performance.md)

- [Fleet of Agents: Coordinated Problem Solving with Large Language Models using Genetic Particle Filtering](2024年05月07日/Fleet_of_Agents_Coordinated_Problem_Solving_with_Large_Language_Models_using_Genetic_Particle_Filtering.md)

    - [翻译: 遗传粒子滤波驱动的大型语言模型代理舰队：协同解决复杂问题的新策略](2024年05月07日/Fleet_of_Agents_Coordinated_Problem_Solving_with_Large_Language_Models_using_Genetic_Particle_Filtering.md)

2024年05月06日

- [Federated Reinforcement Learning with Constraint Heterogeneity](2024年05月06日/Federated_Reinforcement_Learning_with_Constraint_Heterogeneity.md)

    - [翻译: 在约束异质性条件下的联合强化学习研究](2024年05月06日/Federated_Reinforcement_Learning_with_Constraint_Heterogeneity.md)

- [TED: Accelerate Model Training by Internal Generalization](2024年05月06日/TED_Accelerate_Model_Training_by_Internal_Generalization.md)

    - [翻译: TED：借助内部泛化提升模型训练效率](2024年05月06日/TED_Accelerate_Model_Training_by_Internal_Generalization.md)

- [A Philosophical Introduction to Language Models - Part II: The Way Forward](2024年05月06日/A_Philosophical_Introduction_to_Language_Models_-_Part_II_The_Way_Forward.md)

    - [翻译: 《语言模型哲学探析（下）：前行之路》](2024年05月06日/A_Philosophical_Introduction_to_Language_Models_-_Part_II_The_Way_Forward.md)

- [Vietnamese AI Generated Text Detection](2024年05月06日/Vietnamese_AI_Generated_Text_Detection.md)

    - [翻译: 越南AI文本生成检测](2024年05月06日/Vietnamese_AI_Generated_Text_Detection.md)

- [Anchored Answers: Unravelling Positional Bias in GPT-2's Multiple-Choice Questions](2024年05月06日/Anchored_Answers_Unravelling_Positional_Bias_in_GPT-2's_Multiple-Choice_Questions.md)

    - [翻译: 锚定答案：探究 GPT-2 多项选择题中的定位偏好之谜](2024年05月06日/Anchored_Answers_Unravelling_Positional_Bias_in_GPT-2's_Multiple-Choice_Questions.md)

- [CityLLaVA: Efficient Fine-Tuning for VLMs in City Scenario](2024年05月06日/CityLLaVA_Efficient_Fine-Tuning_for_VLMs_in_City_Scenario.md)

    - [翻译: CityLLaVA：在城市环境中为超大型语言模型（VLM）实现高效微调的解决方案。](2024年05月06日/CityLLaVA_Efficient_Fine-Tuning_for_VLMs_in_City_Scenario.md)

- [Adapting Dual-encoder Vision-language Models for Paraphrased Retrieval](2024年05月06日/Adapting_Dual-encoder_Vision-language_Models_for_Paraphrased_Retrieval.md)

    - [翻译: 适配双编码视觉-语言模型，优化释义检索性能。](2024年05月06日/Adapting_Dual-encoder_Vision-language_Models_for_Paraphrased_Retrieval.md)

- [Oracle-Checker Scheme for Evaluating a Generative Large Language Model](2024年05月06日/Oracle-Checker_Scheme_for_Evaluating_a_Generative_Large_Language_Model.md)

    - [翻译: 探索评估生成型大型语言模型的 Oracle-Checker 机制](2024年05月06日/Oracle-Checker_Scheme_for_Evaluating_a_Generative_Large_Language_Model.md)

- [Advancing Multimodal Medical Capabilities of Gemini](2024年05月06日/Advancing_Multimodal_Medical_Capabilities_of_Gemini.md)

    - [翻译: 提升双子座在多模态医疗领域的技术进步](2024年05月06日/Advancing_Multimodal_Medical_Capabilities_of_Gemini.md)

- [Exploring the Potential of the Large Language Models (LLMs) in Identifying Misleading News Headlines](2024年05月06日/Exploring_the_Potential_of_the_Large_Language_Models_(LLMs)_in_Identifying_Misleading_News_Headlines.md)

    - [翻译: 本文旨在探讨大型语言模型（LLMs）在甄别具有误导性的新闻标题方面的潜在能力。](2024年05月06日/Exploring_the_Potential_of_the_Large_Language_Models_(LLMs)_in_Identifying_Misleading_News_Headlines.md)

- [MMGER: Multi-modal and Multi-granularity Generative Error Correction with LLM for Joint Accent and Speech Recognition](2024年05月06日/MMGER_Multi-modal_and_Multi-granularity_Generative_Error_Correction_with_LLM_for_Joint_Accent_and_Speech_Recognition.md)

    - [翻译: MMGER是一种创新技术，它结合了大型语言模型（LLM），以多模态和多粒度的方式进行生成性错误校正，旨在同步提升口音识别和语音识别的准确性。](2024年05月06日/MMGER_Multi-modal_and_Multi-granularity_Generative_Error_Correction_with_LLM_for_Joint_Accent_and_Speech_Recognition.md)

- [Lifelong Knowledge Editing for LLMs with Retrieval-Augmented Continuous Prompt Learning](2024年05月06日/Lifelong_Knowledge_Editing_for_LLMs_with_Retrieval-Augmented_Continuous_Prompt_Learning.md)

    - [翻译: 在大型语言模型（LLMs）中，通过检索增强的连续提示学习方法，实现了终身知识的持续编辑与更新。](2024年05月06日/Lifelong_Knowledge_Editing_for_LLMs_with_Retrieval-Augmented_Continuous_Prompt_Learning.md)

- [Doing Personal LAPS: LLM-Augmented Dialogue Construction for Personalized Multi-Session Conversational Search](2024年05月06日/Doing_Personal_LAPS_LLM-Augmented_Dialogue_Construction_for_Personalized_Multi-Session_Conversational_Search.md)

    - [翻译: 个性化循环训练：借助大型语言模型，构建个性化的多轮对话，以优化个性化的多会话搜索体验。](2024年05月06日/Doing_Personal_LAPS_LLM-Augmented_Dialogue_Construction_for_Personalized_Multi-Session_Conversational_Search.md)

- [Large Language Models (LLMs) as Agents for Augmented Democracy](2024年05月06日/Large_Language_Models_(LLMs)_as_Agents_for_Augmented_Democracy.md)

    - [翻译: 大型语言模型（LLMs）：民主增强的新使者](2024年05月06日/Large_Language_Models_(LLMs)_as_Agents_for_Augmented_Democracy.md)

- [Enhancing Q-Learning with Large Language Model Heuristics](2024年05月06日/Enhancing_Q-Learning_with_Large_Language_Model_Heuristics.md)

    - [翻译: 利用大型语言模型的启发式方法来提升 Q-Learning 的性能](2024年05月06日/Enhancing_Q-Learning_with_Large_Language_Model_Heuristics.md)

- [WorldQA: Multimodal World Knowledge in Videos through Long-Chain Reasoning](2024年05月06日/WorldQA_Multimodal_World_Knowledge_in_Videos_through_Long-Chain_Reasoning.md)

    - [翻译: WorldQA：通过长链推理，探索视频内容中的多模态世界知识](2024年05月06日/WorldQA_Multimodal_World_Knowledge_in_Videos_through_Long-Chain_Reasoning.md)

- [MARE: Multi-Agents Collaboration Framework for Requirements Engineering](2024年05月06日/MARE_Multi-Agents_Collaboration_Framework_for_Requirements_Engineering.md)

    - [翻译: MARE：需求工程的多智能体协作框架](2024年05月06日/MARE_Multi-Agents_Collaboration_Framework_for_Requirements_Engineering.md)

- [Pose Priors from Language Models](2024年05月06日/Pose_Priors_from_Language_Models.md)

    - [翻译: 语言模型中提炼的姿态先验](2024年05月06日/Pose_Priors_from_Language_Models.md)

- [Complex Video Reasoning and Robustness Evaluation Suite for Video-LMMs](2024年05月06日/Complex_Video_Reasoning_and_Robustness_Evaluation_Suite_for_Video-LMMs.md)

    - [翻译: 为视频大型语言模型（Video-LMMs）设计的一套复杂视频推理与鲁棒性评估工具。](2024年05月06日/Complex_Video_Reasoning_and_Robustness_Evaluation_Suite_for_Video-LMMs.md)

- [Large Language Models Reveal Information Operation Goals, Tactics, and Narrative Frames](2024年05月06日/Large_Language_Models_Reveal_Information_Operation_Goals,_Tactics,_and_Narrative_Frames.md)

    - [翻译: 大型语言模型披露了信息战的作战目标、策略运用以及叙述构建的框架。](2024年05月06日/Large_Language_Models_Reveal_Information_Operation_Goals,_Tactics,_and_Narrative_Frames.md)

- [Language-Image Models with 3D Understanding](2024年05月06日/Language-Image_Models_with_3D_Understanding.md)

    - [翻译: 融合3D理解的语言与图像模型](2024年05月06日/Language-Image_Models_with_3D_Understanding.md)

- [AtomGPT: Atomistic Generative Pre-trained Transformer for Forward and Inverse Materials Design](2024年05月06日/AtomGPT_Atomistic_Generative_Pre-trained_Transformer_for_Forward_and_Inverse_Materials_Design.md)

    - [翻译: AtomGPT：一种原子级别的生成预训练变换器，专为正向和逆向材料设计而开发。](2024年05月06日/AtomGPT_Atomistic_Generative_Pre-trained_Transformer_for_Forward_and_Inverse_Materials_Design.md)

- [When LLMs Meet Cybersecurity: A Systematic Literature Review](2024年05月06日/When_LLMs_Meet_Cybersecurity_A_Systematic_Literature_Review.md)

    - [翻译: 大型语言模型（LLM）与网络安全的邂逅：一篇系统性的文献综述。](2024年05月06日/When_LLMs_Meet_Cybersecurity_A_Systematic_Literature_Review.md)

- [A Controlled Experiment on the Energy Efficiency of the Source Code Generated by Code Llama](2024年05月06日/A_Controlled_Experiment_on_the_Energy_Efficiency_of_the_Source_Code_Generated_by_Code_Llama.md)

    - [翻译: 一项针对 Code Llama 所生成源代码能效的控制性实验研究。](2024年05月06日/A_Controlled_Experiment_on_the_Energy_Efficiency_of_the_Source_Code_Generated_by_Code_Llama.md)

- [Enabling High-Sparsity Foundational Llama Models with Efficient Pretraining and Deployment](2024年05月06日/Enabling_High-Sparsity_Foundational_Llama_Models_with_Efficient_Pretraining_and_Deployment.md)

    - [翻译: 通过高效的预训练和部署策略，成功打造了高稀疏性基础的羊驼模型。](2024年05月06日/Enabling_High-Sparsity_Foundational_Llama_Models_with_Efficient_Pretraining_and_Deployment.md)

- [Liberating Seen Classes: Boosting Few-Shot and Zero-Shot Text Classification via Anchor Generation and Classification Reframing](2024年05月06日/Liberating_Seen_Classes_Boosting_Few-Shot_and_Zero-Shot_Text_Classification_via_Anchor_Generation_and_Classification_Reframing.md)

    - [翻译: 释放已知类别：通过生成锚点和重新构建分类框架，增强少样本与零样本文本分类的性能。](2024年05月06日/Liberating_Seen_Classes_Boosting_Few-Shot_and_Zero-Shot_Text_Classification_via_Anchor_Generation_and_Classification_Reframing.md)

- [AlphaMath Almost Zero: process Supervision without process](2024年05月06日/AlphaMath_Almost_Zero_process_Supervision_without_process.md)

    - [翻译: AlphaMath 近乎零差错：实现无需过程的进程监控](2024年05月06日/AlphaMath_Almost_Zero_process_Supervision_without_process.md)

- [MAmmoTH2: Scaling Instructions from the Web](2024年05月06日/MAmmoTH2_Scaling_Instructions_from_the_Web.md)

    - [翻译: MAmmoTH2：网络指令的规模化应用](2024年05月06日/MAmmoTH2_Scaling_Instructions_from_the_Web.md)

- [Position Paper: Leveraging Foundational Models for Black-Box Optimization: Benefits, Challenges, and Future Directions](2024年05月06日/Position_Paper_Leveraging_Foundational_Models_for_Black-Box_Optimization_Benefits,_Challenges,_and_Future_Directions.md)

    - [翻译: 立场论文：探索基础模型在黑盒优化中的应用——优势、挑战与前行之路。](2024年05月06日/Position_Paper_Leveraging_Foundational_Models_for_Black-Box_Optimization_Benefits,_Challenges,_and_Future_Directions.md)

- [Are Human Rules Necessary? Generating Reusable APIs with CoT Reasoning and In-Context Learning](2024年05月06日/Are_Human_Rules_Necessary_Generating_Reusable_APIs_with_CoT_Reasoning_and_In-Context_Learning.md)

    - [翻译: 人类规则真有必要吗？借助 CoT 推理与上下文学习，我们能够生成可复用的 API。](2024年05月06日/Are_Human_Rules_Necessary_Generating_Reusable_APIs_with_CoT_Reasoning_and_In-Context_Learning.md)

- [UnsafeBench: Benchmarking Image Safety Classifiers on Real-World and AI-Generated Images](2024年05月06日/UnsafeBench_Benchmarking_Image_Safety_Classifiers_on_Real-World_and_AI-Generated_Images.md)

    - [翻译: UnsafeBench 项目致力于对现实世界及 AI 创造的图像进行图像安全分类器的基准测试，旨在评估和提升图像安全分类技术的实际效能。](2024年05月06日/UnsafeBench_Benchmarking_Image_Safety_Classifiers_on_Real-World_and_AI-Generated_Images.md)

- [LGTM: Local-to-Global Text-Driven Human Motion Diffusion Model](2024年05月06日/LGTM_Local-to-Global_Text-Driven_Human_Motion_Diffusion_Model.md)

    - [翻译: LGTM：一种由文本驱动的人体运动扩散模型，实现了从局部细节到全局动作的全面覆盖。](2024年05月06日/LGTM_Local-to-Global_Text-Driven_Human_Motion_Diffusion_Model.md)

- [Whispy: Adapting STT Whisper Models to Real-Time Environments](2024年05月06日/Whispy_Adapting_STT_Whisper_Models_to_Real-Time_Environments.md)

    - [翻译: Whispy：为实时环境量身定制的 STT Whisper 模型](2024年05月06日/Whispy_Adapting_STT_Whisper_Models_to_Real-Time_Environments.md)

- [SEvenLLM: Benchmarking, Eliciting, and Enhancing Abilities of Large Language Models in Cyber Threat Intelligence](2024年05月06日/SEvenLLM_Benchmarking,_Eliciting,_and_Enhancing_Abilities_of_Large_Language_Models_in_Cyber_Threat_Intelligence.md)

    - [翻译: SEvenLLM：在网络威胁情报领域，对大型语言模型进行基准测试、能力挖掘与提升。](2024年05月06日/SEvenLLM_Benchmarking,_Eliciting,_and_Enhancing_Abilities_of_Large_Language_Models_in_Cyber_Threat_Intelligence.md)

- [Gaussian Stochastic Weight Averaging for Bayesian Low-Rank Adaptation of Large Language Models](2024年05月06日/Gaussian_Stochastic_Weight_Averaging_for_Bayesian_Low-Rank_Adaptation_of_Large_Language_Models.md)

    - [翻译: 贝叶斯低秩适配大型语言模型的高斯随机权重平均法](2024年05月06日/Gaussian_Stochastic_Weight_Averaging_for_Bayesian_Low-Rank_Adaptation_of_Large_Language_Models.md)

- [The high dimensional psychological profile and cultural bias of ChatGPT](2024年05月06日/The_high_dimensional_psychological_profile_and_cultural_bias_of_ChatGPT.md)

    - [翻译: ChatGPT 拥有复杂的心理特征和文化倾向，这些特性在其多维心理画像中得到了体现。](2024年05月06日/The_high_dimensional_psychological_profile_and_cultural_bias_of_ChatGPT.md)

- [Knowledge-aware Text-Image Retrieval for Remote Sensing Images](2024年05月06日/Knowledge-aware_Text-Image_Retrieval_for_Remote_Sensing_Images.md)

    - [翻译: 为遥感图像设计的文本与图像知识感知检索系统](2024年05月06日/Knowledge-aware_Text-Image_Retrieval_for_Remote_Sensing_Images.md)

- [Snake Learning: A Communication- and Computation-Efficient Distributed Learning Framework for 6G](2024年05月06日/Snake_Learning_A_Communication-_and_Computation-Efficient_Distributed_Learning_Framework_for_6G.md)

    - [翻译: Snake Learning，一个为第六代移动通信（6G）量身打造的分布式学习框架，以其卓越的通信和计算效率引领未来学习模式。](2024年05月06日/Snake_Learning_A_Communication-_and_Computation-Efficient_Distributed_Learning_Framework_for_6G.md)

- [Explainable Fake News Detection With Large Language Model via Defense Among Competing Wisdom](2024年05月06日/Explainable_Fake_News_Detection_With_Large_Language_Model_via_Defense_Among_Competing_Wisdom.md)

    - [翻译: 利用大型语言模型，通过对抗竞争智慧中的策略，实现假新闻的可解释性检测。](2024年05月06日/Explainable_Fake_News_Detection_With_Large_Language_Model_via_Defense_Among_Competing_Wisdom.md)

- [MedDoc-Bot: A Chat Tool for Comparative Analysis of Large Language Models in the Context of the Pediatric Hypertension Guideline](2024年05月06日/MedDoc-Bot_A_Chat_Tool_for_Comparative_Analysis_of_Large_Language_Models_in_the_Context_of_the_Pediatric_Hypertension_Guideline.md)

    - [翻译: MedDoc-Bot：一款针对儿童高血压指南情境下，用于对比分析大型语言模型的智能聊天工具。](2024年05月06日/MedDoc-Bot_A_Chat_Tool_for_Comparative_Analysis_of_Large_Language_Models_in_the_Context_of_the_Pediatric_Hypertension_Guideline.md)

- [Exploring the Frontiers of Softmax: Provable Optimization, Applications in Diffusion Model, and Beyond](2024年05月06日/Exploring_the_Frontiers_of_Softmax_Provable_Optimization,_Applications_in_Diffusion_Model,_and_Beyond.md)

    - [翻译: 深入 Softmax 的未知领域：验证优化的路径，扩散模型的创新应用，以及更广阔的研究前景。](2024年05月06日/Exploring_the_Frontiers_of_Softmax_Provable_Optimization,_Applications_in_Diffusion_Model,_and_Beyond.md)

- [Speak the Same Language: Global LiDAR Registration on BIM Using Pose Hough Transform](2024年05月06日/Speak_the_Same_Language_Global_LiDAR_Registration_on_BIM_Using_Pose_Hough_Transform.md)

    - [翻译: “共语”全球激光雷达注册：利用姿态霍夫变换在BIM上的精准对接](2024年05月06日/Speak_the_Same_Language_Global_LiDAR_Registration_on_BIM_Using_Pose_Hough_Transform.md)

- [ERATTA: Extreme RAG for Table To Answers with Large Language Models](2024年05月06日/ERATTA_Extreme_RAG_for_Table_To_Answers_with_Large_Language_Models.md)

    - [翻译: ERATTA：大型语言模型在表格至答案生成中的极致检索增强技术在这项研究中，我们提出了ERATTA，一种新颖的方法，它利用大型语言模型的强大能力，通过极端的检索增强生成（RAG）技术，从结构化数据中提取信息并生成准确的答案。这种方法特别适用于处理复杂的表格数据，能够有效地捕捉数据间的细微关联，并据此生成连贯且信息丰富的回答。](2024年05月06日/ERATTA_Extreme_RAG_for_Table_To_Answers_with_Large_Language_Models.md)

- [Long Context Alignment with Short Instructions and Synthesized Positions](2024年05月06日/Long_Context_Alignment_with_Short_Instructions_and_Synthesized_Positions.md)

    - [翻译: 短指令与合成位置下的长上下文对齐策略](2024年05月06日/Long_Context_Alignment_with_Short_Instructions_and_Synthesized_Positions.md)

- [Codexity: Secure AI-assisted Code Generation](2024年05月06日/Codexity_Secure_AI-assisted_Code_Generation.md)

    - [翻译: Codexity：保障安全的 AI 代码创作助手](2024年05月06日/Codexity_Secure_AI-assisted_Code_Generation.md)

- [KV Cache is 1 Bit Per Channel: Efficient Large Language Model Inference with Coupled Quantization](2024年05月06日/KV_Cache_is_1_Bit_Per_Channel_Efficient_Large_Language_Model_Inference_with_Coupled_Quantization.md)

    - [翻译: KV Cache 采用每通道1位的耦合量化策略，为大型语言模型推理提供了高效途径，实现了计算资源的优化利用。](2024年05月06日/KV_Cache_is_1_Bit_Per_Channel_Efficient_Large_Language_Model_Inference_with_Coupled_Quantization.md)

- [OmniActions: Predicting Digital Actions in Response to Real-World Multimodal Sensory Inputs with LLMs](2024年05月06日/OmniActions_Predicting_Digital_Actions_in_Response_to_Real-World_Multimodal_Sensory_Inputs_with_LLMs.md)

    - [翻译: 全方位行动：借助大型语言模型，精准预测现实世界多模态感官刺激下的数字行动反应](2024年05月06日/OmniActions_Predicting_Digital_Actions_in_Response_to_Real-World_Multimodal_Sensory_Inputs_with_LLMs.md)

- [Outlier Gradient Analysis: Efficiently Improving Deep Learning Model Performance via Hessian-Free Influence Functions](2024年05月06日/Outlier_Gradient_Analysis_Efficiently_Improving_Deep_Learning_Model_Performance_via_Hessian-Free_Influence_Functions.md)

    - [翻译: 梯度异常分析：借助无黑塞矩阵的影响函数，我们能够精妙地提升深度学习模型的性能，如同巧匠雕琢宝石，使其光芒四射。](2024年05月06日/Outlier_Gradient_Analysis_Efficiently_Improving_Deep_Learning_Model_Performance_via_Hessian-Free_Influence_Functions.md)

- [Self-Improving Customer Review Response Generation Based on LLMs](2024年05月06日/Self-Improving_Customer_Review_Response_Generation_Based_on_LLMs.md)

    - [翻译: 大型语言模型驱动下的客户评论回复自我优化生成在翻译过程中，我首先确保原文的核心意义被准确传达，即“基于大型语言模型的自我改进客户评论回复生成”。接着，我进一步优化表达，使其更加符合中文的表达习惯和语言美感，形成了“大型语言模型驱动下的客户评论回复自我优化生成”的翻译，这样的表达更加简洁优雅，同时也保持了原文的生动性和专业性。](2024年05月06日/Self-Improving_Customer_Review_Response_Generation_Based_on_LLMs.md)

- [Organizing a Society of Language Models: Structures and Mechanisms for Enhanced Collective Intelligence](2024年05月06日/Organizing_a_Society_of_Language_Models_Structures_and_Mechanisms_for_Enhanced_Collective_Intelligence.md)

    - [翻译: 构建语言模型联盟：探索提升集体智慧的架构与机制](2024年05月06日/Organizing_a_Society_of_Language_Models_Structures_and_Mechanisms_for_Enhanced_Collective_Intelligence.md)

- [Large Language Models as Instruments of Power: New Regimes of Autonomous Manipulation and Control](2024年05月06日/Large_Language_Models_as_Instruments_of_Power_New_Regimes_of_Autonomous_Manipulation_and_Control.md)

    - [翻译: 权力之弦：大型语言模型与自主操控的新纪元](2024年05月06日/Large_Language_Models_as_Instruments_of_Power_New_Regimes_of_Autonomous_Manipulation_and_Control.md)

- [In Situ AI Prototyping: Infusing Multimodal Prompts into Mobile Settings with MobileMaker](2024年05月06日/In_Situ_AI_Prototyping_Infusing_Multimodal_Prompts_into_Mobile_Settings_with_MobileMaker.md)

    - [翻译: 现场AI原型制作：借助MobileMaker，将多模态提示注入移动场景，实现智能交互的即时创新。](2024年05月06日/In_Situ_AI_Prototyping_Infusing_Multimodal_Prompts_into_Mobile_Settings_with_MobileMaker.md)

- [Detecting Anti-Semitic Hate Speech using Transformer-based Large Language Models](2024年05月06日/Detecting_Anti-Semitic_Hate_Speech_using_Transformer-based_Large_Language_Models.md)

    - [翻译: 运用Transformer架构的大型语言模型，精准识别反犹太仇恨言论，本研究深入探讨了该模型在敏感话题识别上的应用与挑战。](2024年05月06日/Detecting_Anti-Semitic_Hate_Speech_using_Transformer-based_Large_Language_Models.md)

- [ERAGent: Enhancing Retrieval-Augmented Language Models with Improved Accuracy, Efficiency, and Personalization](2024年05月06日/ERAGent_Enhancing_Retrieval-Augmented_Language_Models_with_Improved_Accuracy,_Efficiency,_and_Personalization.md)

    - [翻译: ERAGent：提升语言模型的检索增强能力，实现更精准、高效且个性化的语言处理](2024年05月06日/ERAGent_Enhancing_Retrieval-Augmented_Language_Models_with_Improved_Accuracy,_Efficiency,_and_Personalization.md)

- [SWE-agent: Agent-Computer Interfaces Enable Automated Software Engineering](2024年05月06日/SWE-agent_Agent-Computer_Interfaces_Enable_Automated_Software_Engineering.md)

    - [翻译: SWE-agent：通过代理-计算机接口，软件工程自动化得以实现](2024年05月06日/SWE-agent_Agent-Computer_Interfaces_Enable_Automated_Software_Engineering.md)

2024年05月05日

- [Quantifying the Capabilities of LLMs across Scale and Precision](2024年05月05日/Quantifying_the_Capabilities_of_LLMs_across_Scale_and_Precision.md)

    - [翻译: 探究并衡量大型语言模型在不同规模和精度层面的性能表现](2024年05月05日/Quantifying_the_Capabilities_of_LLMs_across_Scale_and_Precision.md)

- [CRAFT: Extracting and Tuning Cultural Instructions from the Wild](2024年05月05日/CRAFT_Extracting_and_Tuning_Cultural_Instructions_from_the_Wild.md)

    - [翻译: CRAFT：从现实世界中提炼并优化文化指南](2024年05月05日/CRAFT_Extracting_and_Tuning_Cultural_Instructions_from_the_Wild.md)

- [WDMoE: Wireless Distributed Large Language Models with Mixture of Experts](2024年05月05日/WDMoE_Wireless_Distributed_Large_Language_Models_with_Mixture_of_Experts.md)

    - [翻译: WDMoE：无线分布式大型语言模型，采用专家混合技术](2024年05月05日/WDMoE_Wireless_Distributed_Large_Language_Models_with_Mixture_of_Experts.md)

- [Automatic Retrieval-augmented Generation of 6G Network Specifications for Use Cases](2024年05月05日/Automatic_Retrieval-augmented_Generation_of_6G_Network_Specifications_for_Use_Cases.md)

    - [翻译: 自动增强检索技术在6G网络规范的自动生成中的应用，针对不同用例场景。](2024年05月05日/Automatic_Retrieval-augmented_Generation_of_6G_Network_Specifications_for_Use_Cases.md)

- [Vector Quantization for Recommender Systems: A Review and Outlook](2024年05月05日/Vector_Quantization_for_Recommender_Systems_A_Review_and_Outlook.md)

    - [翻译: 向量量化技术在推荐系统领域的应用：回顾与前瞻。](2024年05月05日/Vector_Quantization_for_Recommender_Systems_A_Review_and_Outlook.md)

- [GeoContrastNet: Contrastive Key-Value Edge Learning for Language-Agnostic Document Understanding](2024年05月05日/GeoContrastNet_Contrastive_Key-Value_Edge_Learning_for_Language-Agnostic_Document_Understanding.md)

    - [翻译: GeoContrastNet：一种对比关键值边缘学习方法，旨在实现对文档的深入理解，而不受语言限制。](2024年05月05日/GeoContrastNet_Contrastive_Key-Value_Edge_Learning_for_Language-Agnostic_Document_Understanding.md)

- [Learning from Students: Applying t-Distributions to Explore Accurate and Efficient Formats for LLMs](2024年05月05日/Learning_from_Students_Applying_t-Distributions_to_Explore_Accurate_and_Efficient_Formats_for_LLMs.md)

    - [翻译: 借鉴学子智慧：利用 t 分布探求适合大型语言模型的精准高效表达方式。](2024年05月05日/Learning_from_Students_Applying_t-Distributions_to_Explore_Accurate_and_Efficient_Formats_for_LLMs.md)

- [FairMonitor: A Dual-framework for Detecting Stereotypes and Biases in Large Language Models](2024年05月05日/FairMonitor_A_Dual-framework_for_Detecting_Stereotypes_and_Biases_in_Large_Language_Models.md)

    - [翻译: FairMonitor：一套双重框架，专为发现大型语言模型中的刻板印象与偏见而设计。](2024年05月05日/FairMonitor_A_Dual-framework_for_Detecting_Stereotypes_and_Biases_in_Large_Language_Models.md)

- [To Each (Textual Sequence) Its Own: Improving Memorized-Data Unlearning in Large Language Models](2024年05月05日/To_Each_(Textual_Sequence)_Its_Own_Improving_Memorized-Data_Unlearning_in_Large_Language_Models.md)

    - [翻译: 为每个文本序列量身定制：优化大型语言模型中的记忆数据忘却机制](2024年05月05日/To_Each_(Textual_Sequence)_Its_Own_Improving_Memorized-Data_Unlearning_in_Large_Language_Models.md)

- [Compressing Long Context for Enhancing RAG with AMR-based Concept Distillation](2024年05月05日/Compressing_Long_Context_for_Enhancing_RAG_with_AMR-based_Concept_Distillation.md)

    - [翻译: 为了提升基于AMR（抽象意义表示）的RAG（Retrieval-Augmented Generation，检索增强生成）模型的性能，我们采用了一种压缩长文本的方法。](2024年05月05日/Compressing_Long_Context_for_Enhancing_RAG_with_AMR-based_Concept_Distillation.md)

- [Traffic Performance GPT (TP-GPT): Real-Time Data Informed Intelligent ChatBot for Transportation Surveillance and Management](2024年05月05日/Traffic_Performance_GPT_(TP-GPT)_Real-Time_Data_Informed_Intelligent_ChatBot_for_Transportation_Surveillance_and_Management.md)

    - [翻译: 交通性能 GPT（TP-GPT）：一款基于实时数据的智能聊天机器人，专为交通监控与管理量身定制。](2024年05月05日/Traffic_Performance_GPT_(TP-GPT)_Real-Time_Data_Informed_Intelligent_ChatBot_for_Transportation_Surveillance_and_Management.md)

- [A scoping review of using Large Language Models (LLMs) to investigate Electronic Health Records (EHRs)](2024年05月05日/A_scoping_review_of_using_Large_Language_Models_(LLMs)_to_investigate_Electronic_Health_Records_(EHRs).md)

    - [翻译: 本文综述了利用大型语言模型（LLMs）来探究电子健康记录（EHRs）的应用情况。](2024年05月05日/A_scoping_review_of_using_Large_Language_Models_(LLMs)_to_investigate_Electronic_Health_Records_(EHRs).md)

- [High Order Reasoning for Time Critical Recommendation in Evidence-based Medicine](2024年05月05日/High_Order_Reasoning_for_Time_Critical_Recommendation_in_Evidence-based_Medicine.md)

    - [翻译: 在循证医学领域，面对紧急情况下的推荐决策，我们需运用高阶推理技巧。](2024年05月05日/High_Order_Reasoning_for_Time_Critical_Recommendation_in_Evidence-based_Medicine.md)

- [On the performativity of SDG classifications in large bibliometric databases](2024年05月05日/On_the_performativity_of_SDG_classifications_in_large_bibliometric_databases.md)

    - [翻译: 在大型文献计量数据库中，对可持续发展目标（SDG）分类的绩效性进行探讨。](2024年05月05日/On_the_performativity_of_SDG_classifications_in_large_bibliometric_databases.md)

- [MedAdapter: Efficient Test-Time Adaptation of Large Language Models towards Medical Reasoning](2024年05月05日/MedAdapter_Efficient_Test-Time_Adaptation_of_Large_Language_Models_towards_Medical_Reasoning.md)

    - [翻译: MedAdapter：为大型语言模型在医学推理任务中实现高效的测试时适应性](2024年05月05日/MedAdapter_Efficient_Test-Time_Adaptation_of_Large_Language_Models_towards_Medical_Reasoning.md)

- [Analysis about Theoretical Foundations for Method to Enhancing ASR Performance using OCR Word Frequency Differences](2024年05月05日/Analysis_about_Theoretical_Foundations_for_Method_to_Enhancing_ASR_Performance_using_OCR_Word_Frequency_Differences.md)

    - [翻译: 本文深入探讨了利用OCR单词频率差异提升自动语音识别（ASR）性能的方法背后的理论基础。](2024年05月05日/Analysis_about_Theoretical_Foundations_for_Method_to_Enhancing_ASR_Performance_using_OCR_Word_Frequency_Differences.md)

- [Can Large Language Models Make the Grade? An Empirical Study Evaluating LLMs Ability to Mark Short Answer Questions in K-12 Education](2024年05月05日/Can_Large_Language_Models_Make_the_Grade_An_Empirical_Study_Evaluating_LLMs_Ability_to_Mark_Short_Answer_Questions_in_K-12_Education.md)

    - [翻译: 大型语言模型能否担当起评分的重任？本实证研究深入探讨了这些模型在 K-12 教育领域评估简答题表现的能力。](2024年05月05日/Can_Large_Language_Models_Make_the_Grade_An_Empirical_Study_Evaluating_LLMs_Ability_to_Mark_Short_Answer_Questions_in_K-12_Education.md)

- [Agent Hospital: A Simulacrum of Hospital with Evolvable Medical Agents](2024年05月05日/Agent_Hospital_A_Simulacrum_of_Hospital_with_Evolvable_Medical_Agents.md)

    - [翻译: 《代理医院：一个可进化医疗代理的仿真医院》](2024年05月05日/Agent_Hospital_A_Simulacrum_of_Hospital_with_Evolvable_Medical_Agents.md)

- [Source-Free Domain Adaptation Guided by Vision and Vision-Language Pre-Training](2024年05月05日/Source-Free_Domain_Adaptation_Guided_by_Vision_and_Vision-Language_Pre-Training.md)

    - [翻译: 视觉与视觉-语言预训练引领的无源域自适应指南](2024年05月05日/Source-Free_Domain_Adaptation_Guided_by_Vision_and_Vision-Language_Pre-Training.md)

- [Unraveling the Dominance of Large Language Models Over Transformer Models for Bangla Natural Language Inference: A Comprehensive Study](2024年05月05日/Unraveling_the_Dominance_of_Large_Language_Models_Over_Transformer_Models_for_Bangla_Natural_Language_Inference_A_Comprehensive_Study.md)

    - [翻译: 深入探究大型语言模型如何在孟加拉语自然语言推理任务中超越变换器模型：一项全面深入的研究。](2024年05月05日/Unraveling_the_Dominance_of_Large_Language_Models_Over_Transformer_Models_for_Bangla_Natural_Language_Inference_A_Comprehensive_Study.md)

- [Relay Decoding: Concatenating Large Language Models for Machine Translation](2024年05月05日/Relay_Decoding_Concatenating_Large_Language_Models_for_Machine_Translation.md)

    - [翻译: 中继解码技术：将大型语言模型串联起来，以提升机器翻译的性能。](2024年05月05日/Relay_Decoding_Concatenating_Large_Language_Models_for_Machine_Translation.md)

- [Overconfidence is Key: Verbalized Uncertainty Evaluation in Large Language and Vision-Language Models](2024年05月05日/Overconfidence_is_Key_Verbalized_Uncertainty_Evaluation_in_Large_Language_and_Vision-Language_Models.md)

    - [翻译: 自信过度，关键所在：探究大型语言及视觉-语言模型中的口头不确定性评估。](2024年05月05日/Overconfidence_is_Key_Verbalized_Uncertainty_Evaluation_in_Large_Language_and_Vision-Language_Models.md)

- [Exploring the Improvement of Evolutionary Computation via Large Language Models](2024年05月05日/Exploring_the_Improvement_of_Evolutionary_Computation_via_Large_Language_Models.md)

    - [翻译: 本文旨在探讨如何利用大型语言模型来提升进化计算的性能。](2024年05月05日/Exploring_the_Improvement_of_Evolutionary_Computation_via_Large_Language_Models.md)

- [Revisiting a Pain in the Neck: Semantic Phrase Processing Benchmark for Language Models](2024年05月05日/Revisiting_a_Pain_in_the_Neck_Semantic_Phrase_Processing_Benchmark_for_Language_Models.md)

    - [翻译: 再次聚焦“颈部之痛”：为语言模型设立的语义短语处理性能评估标准](2024年05月05日/Revisiting_a_Pain_in_the_Neck_Semantic_Phrase_Processing_Benchmark_for_Language_Models.md)

- [Language Evolution for Evading Social Media Regulation via LLM-based Multi-agent Simulation](2024年05月05日/Language_Evolution_for_Evading_Social_Media_Regulation_via_LLM-based_Multi-agent_Simulation.md)

    - [翻译: 本文探讨了如何利用基于大型语言模型（LLM）的多代理模拟技术，实现语言的进化以规避社交媒体的监管机制。](2024年05月05日/Language_Evolution_for_Evading_Social_Media_Regulation_via_LLM-based_Multi-agent_Simulation.md)

- [Trojans in Large Language Models of Code: A Critical Review through a Trigger-Based Taxonomy](2024年05月05日/Trojans_in_Large_Language_Models_of_Code_A_Critical_Review_through_a_Trigger-Based_Taxonomy.md)

    - [翻译: 代码大型语言模型中的潜在威胁：基于触发机制的分类法进行的深入剖析。](2024年05月05日/Trojans_in_Large_Language_Models_of_Code_A_Critical_Review_through_a_Trigger-Based_Taxonomy.md)

- [HuixiangDou-CR: Coreference Resolution in Group Chats](2024年05月05日/HuixiangDou-CR_Coreference_Resolution_in_Group_Chats.md)

    - [翻译: HuixiangDou-CR：群组聊天中的同指识别技术](2024年05月05日/HuixiangDou-CR_Coreference_Resolution_in_Group_Chats.md)

- [NegativePrompt: Leveraging Psychology for Large Language Models Enhancement via Negative Emotional Stimuli](2024年05月05日/NegativePrompt_Leveraging_Psychology_for_Large_Language_Models_Enhancement_via_Negative_Emotional_Stimuli.md)

    - [翻译: 负面提示：运用心理学原理，通过负面情感刺激来提升大型语言模型的性能](2024年05月05日/NegativePrompt_Leveraging_Psychology_for_Large_Language_Models_Enhancement_via_Negative_Emotional_Stimuli.md)

- [Stochastic RAG: End-to-End Retrieval-Augmented Generation through Expected Utility Maximization](2024年05月05日/Stochastic_RAG_End-to-End_Retrieval-Augmented_Generation_through_Expected_Utility_Maximization.md)

    - [翻译: 随机化 RAG：通过期望效用最大化实现一站式检索增强生成](2024年05月05日/Stochastic_RAG_End-to-End_Retrieval-Augmented_Generation_through_Expected_Utility_Maximization.md)

- [ATAT: Astronomical Transformer for time series And Tabular data](2024年05月05日/ATAT_Astronomical_Transformer_for_time_series_And_Tabular_data.md)

    - [翻译: ATAT：一种专为时间序列和表格数据设计的天文变换模型](2024年05月05日/ATAT_Astronomical_Transformer_for_time_series_And_Tabular_data.md)

- [Leveraging Lecture Content for Improved Feedback: Explorations with GPT-4 and Retrieval Augmented Generation](2024年05月05日/Leveraging_Lecture_Content_for_Improved_Feedback_Explorations_with_GPT-4_and_Retrieval_Augmented_Generation.md)

    - [翻译: 借助GPT-4与检索增强生成技术，我们探索了如何利用讲座内容来提升反馈的精准度，旨在为教育领域带来更深层次的互动与改进。](2024年05月05日/Leveraging_Lecture_Content_for_Improved_Feedback_Explorations_with_GPT-4_and_Retrieval_Augmented_Generation.md)

- [Self-Reflection in LLM Agents: Effects on Problem-Solving Performance](2024年05月05日/Self-Reflection_in_LLM_Agents_Effects_on_Problem-Solving_Performance.md)

    - [翻译: 大型语言模型代理的自我审视：探索其对问题解决能力的提升作用](2024年05月05日/Self-Reflection_in_LLM_Agents_Effects_on_Problem-Solving_Performance.md)

2024年05月04日

- [Mozart's Touch: A Lightweight Multi-modal Music Generation Framework Based on Pre-Trained Large Models](2024年05月04日/Mozart's_Touch_A_Lightweight_Multi-modal_Music_Generation_Framework_Based_on_Pre-Trained_Large_Models.md)

    - [翻译: 《莫扎特之触》：一款轻量级多模态音乐创作框架，依托于预训练的大型语言模型。](2024年05月04日/Mozart's_Touch_A_Lightweight_Multi-modal_Music_Generation_Framework_Based_on_Pre-Trained_Large_Models.md)

- [Octopi: Object Property Reasoning with Large Tactile-Language Models](2024年05月04日/Octopi_Object_Property_Reasoning_with_Large_Tactile-Language_Models.md)

    - [翻译: Octopi：通过大型触觉-语言模型进行物体属性推理](2024年05月04日/Octopi_Object_Property_Reasoning_with_Large_Tactile-Language_Models.md)

- [Confidential and Protected Disease Classifier using Fully Homomorphic Encryption](2024年05月04日/Confidential_and_Protected_Disease_Classifier_using_Fully_Homomorphic_Encryption.md)

    - [翻译: 采用全同态加密技术，打造安全可靠的疾病分类系统。](2024年05月04日/Confidential_and_Protected_Disease_Classifier_using_Fully_Homomorphic_Encryption.md)

- [A self-supervised text-vision framework for automated brain abnormality detection](2024年05月04日/A_self-supervised_text-vision_framework_for_automated_brain_abnormality_detection.md)

    - [翻译: 本研究提出了一种自监督的文本-视觉框架，旨在自动化地检测大脑异常。](2024年05月04日/A_self-supervised_text-vision_framework_for_automated_brain_abnormality_detection.md)

- [Improve Temporal Awareness of LLMs for Sequential Recommendation](2024年05月04日/Improve_Temporal_Awareness_of_LLMs_for_Sequential_Recommendation.md)

    - [翻译: 提升大型语言模型在序列推荐任务中的时间意识。](2024年05月04日/Improve_Temporal_Awareness_of_LLMs_for_Sequential_Recommendation.md)

- [Assessing Adversarial Robustness of Large Language Models: An Empirical Study](2024年05月04日/Assessing_Adversarial_Robustness_of_Large_Language_Models_An_Empirical_Study.md)

    - [翻译: 探究大型语言模型的对抗性防御能力：实证分析。](2024年05月04日/Assessing_Adversarial_Robustness_of_Large_Language_Models_An_Empirical_Study.md)

- [Can Nuanced Language Lead to More Actionable Insights? Exploring the Role of Generative AI in Analytical Narrative Structure](2024年05月04日/Can_Nuanced_Language_Lead_to_More_Actionable_Insights_Exploring_the_Role_of_Generative_AI_in_Analytical_Narrative_Structure.md)

    - [翻译: 能否通过微妙的语言获得更可行的洞察？本文深入探讨了生成性人工智能在构建分析性叙述结构中的关键角色。](2024年05月04日/Can_Nuanced_Language_Lead_to_More_Actionable_Insights_Exploring_the_Role_of_Generative_AI_in_Analytical_Narrative_Structure.md)

- [Enhancing Contextual Understanding in Large Language Models through Contrastive Decoding](2024年05月04日/Enhancing_Contextual_Understanding_in_Large_Language_Models_through_Contrastive_Decoding.md)

    - [翻译: 通过对比解码技术，提升大型语言模型对上下文的理解能力。](2024年05月04日/Enhancing_Contextual_Understanding_in_Large_Language_Models_through_Contrastive_Decoding.md)

- [Sub-goal Distillation: A Method to Improve Small Language Agents](2024年05月04日/Sub-goal_Distillation_A_Method_to_Improve_Small_Language_Agents.md)

    - [翻译: 子目标蒸馏：提升小型语言代理效能的新方法](2024年05月04日/Sub-goal_Distillation_A_Method_to_Improve_Small_Language_Agents.md)

- [Beyond Performance: Quantifying and Mitigating Label Bias in LLMs](2024年05月04日/Beyond_Performance_Quantifying_and_Mitigating_Label_Bias_in_LLMs.md)

    - [翻译: 超越单纯的性能指标，本文致力于量化并缓解大型语言模型（LLM）中的标签偏见问题。](2024年05月04日/Beyond_Performance_Quantifying_and_Mitigating_Label_Bias_in_LLMs.md)

- [Relations Prediction for Knowledge Graph Completion using Large Language Models](2024年05月04日/Relations_Prediction_for_Knowledge_Graph_Completion_using_Large_Language_Models.md)

    - [翻译: 本研究探讨了如何利用大型语言模型来预测知识图谱补全中的关系。](2024年05月04日/Relations_Prediction_for_Knowledge_Graph_Completion_using_Large_Language_Models.md)

- [Recall Them All: Retrieval-Augmented Language Models for Long Object List Extraction from Long Documents](2024年05月04日/Recall_Them_All_Retrieval-Augmented_Language_Models_for_Long_Object_List_Extraction_from_Long_Documents.md)

    - [翻译: 全面召回：增强检索的语言模型，专为从长篇文档中抽取长列表对象而设计。](2024年05月04日/Recall_Them_All_Retrieval-Augmented_Language_Models_for_Long_Object_List_Extraction_from_Long_Documents.md)

- [R4: Reinforced Retriever-Reorder-Responder for Retrieval-Augmented Large Language Models](2024年05月04日/R4_Reinforced_Retriever-Reorder-Responder_for_Retrieval-Augmented_Large_Language_Models.md)

    - [翻译: R4：强化版检索-重排-响应机制，专为检索增强型大型语言模型设计。](2024年05月04日/R4_Reinforced_Retriever-Reorder-Responder_for_Retrieval-Augmented_Large_Language_Models.md)

- [PropertyGPT: LLM-driven Formal Verification of Smart Contracts through Retrieval-Augmented Property Generation](2024年05月04日/PropertyGPT_LLM-driven_Formal_Verification_of_Smart_Contracts_through_Retrieval-Augmented_Property_Generation.md)

    - [翻译: PropertyGPT，一种利用大型语言模型（LLM）进行智能合约形式化验证的创新方法，通过增强检索的属性生成技术，为智能合约的安全性分析提供了新的视角。](2024年05月04日/PropertyGPT_LLM-driven_Formal_Verification_of_Smart_Contracts_through_Retrieval-Augmented_Property_Generation.md)

- [TREC iKAT 2023: A Test Collection for Evaluating Conversational and Interactive Knowledge Assistants](2024年05月04日/TREC_iKAT_2023_A_Test_Collection_for_Evaluating_Conversational_and_Interactive_Knowledge_Assistants.md)

    - [翻译: TREC iKAT 2023：评估对话式和互动式知识助手性能的测试集](2024年05月04日/TREC_iKAT_2023_A_Test_Collection_for_Evaluating_Conversational_and_Interactive_Knowledge_Assistants.md)

- [IQLS: Framework for leveraging Metadata to enable Large Language Model based queries to complex, versatile Data](2024年05月04日/IQLS_Framework_for_leveraging_Metadata_to_enable_Large_Language_Model_based_queries_to_complex,_versatile_Data.md)

    - [翻译: IQLS框架：借助元数据，让大型语言模型轻松驾驭复杂多变的数据查询](2024年05月04日/IQLS_Framework_for_leveraging_Metadata_to_enable_Large_Language_Model_based_queries_to_complex,_versatile_Data.md)

2024年05月03日

- [Structural Pruning of Pre-trained Language Models via Neural Architecture Search](2024年05月03日/Structural_Pruning_of_Pre-trained_Language_Models_via_Neural_Architecture_Search.md)

    - [翻译: 利用神经架构搜索技术对预训练的语言模型进行结构化精简。](2024年05月03日/Structural_Pruning_of_Pre-trained_Language_Models_via_Neural_Architecture_Search.md)

- [On the test-time zero-shot generalization of vision-language models: Do we really need prompt learning?](2024年05月03日/On_the_test-time_zero-shot_generalization_of_vision-language_models_Do_we_really_need_prompt_learning.md)

    - [翻译: 探讨视觉-语言模型在测试阶段的零样本泛化能力：提示学习是否真的不可或缺？](2024年05月03日/On_the_test-time_zero-shot_generalization_of_vision-language_models_Do_we_really_need_prompt_learning.md)

- [Leveraging Large Language Models to Enhance Domain Expert Inclusion in Data Science Workflows](2024年05月03日/Leveraging_Large_Language_Models_to_Enhance_Domain_Expert_Inclusion_in_Data_Science_Workflows.md)

    - [翻译: 通过运用大型语言模型，我们能够提升数据科学流程中领域专家的参与度和包容性。](2024年05月03日/Leveraging_Large_Language_Models_to_Enhance_Domain_Expert_Inclusion_in_Data_Science_Workflows.md)

- [What matters when building vision-language models?](2024年05月03日/What_matters_when_building_vision-language_models.md)

    - [翻译: 构建视觉-语言模型时，关键因素有哪些？](2024年05月03日/What_matters_when_building_vision-language_models.md)

- [REASONS: A benchmark for REtrieval and Automated citationS Of scieNtific Sentences using Public and Proprietary LLMs](2024年05月03日/REASONS_A_benchmark_for_REtrieval_and_Automated_citationS_Of_scieNtific_Sentences_using_Public_and_Proprietary_LLMs.md)

    - [翻译: REASONS：一个基准测试，旨在利用公共及私有的大型语言模型（LLMs）检索并自动引用科学文献中的句子。](2024年05月03日/REASONS_A_benchmark_for_REtrieval_and_Automated_citationS_Of_scieNtific_Sentences_using_Public_and_Proprietary_LLMs.md)

- [FairEvalLLM. A Comprehensive Framework for Benchmarking Fairness in Large Language Model Recommender Systems](2024年05月03日/FairEvalLLM._A_Comprehensive_Framework_for_Benchmarking_Fairness_in_Large_Language_Model_Recommender_Systems.md)

    - [翻译: FairEvalLLM，为大型语言模型推荐系统公平性评估提供了一个全面的基准框架。](2024年05月03日/FairEvalLLM._A_Comprehensive_Framework_for_Benchmarking_Fairness_in_Large_Language_Model_Recommender_Systems.md)

- [Automatic Programming: Large Language Models and Beyond](2024年05月03日/Automatic_Programming_Large_Language_Models_and_Beyond.md)

    - [翻译: 自动编程：探索大型语言模型及其更广阔领域](2024年05月03日/Automatic_Programming_Large_Language_Models_and_Beyond.md)

- [Assessing and Verifying Task Utility in LLM-Powered Applications](2024年05月03日/Assessing_and_Verifying_Task_Utility_in_LLM-Powered_Applications.md)

    - [翻译: 探索大型语言模型（LLM）支持的应用程序中任务实用性的评估与验证。](2024年05月03日/Assessing_and_Verifying_Task_Utility_in_LLM-Powered_Applications.md)

- [EEG2TEXT: Open Vocabulary EEG-to-Text Decoding with EEG Pre-Training and Multi-View Transformer](2024年05月03日/EEG2TEXT_Open_Vocabulary_EEG-to-Text_Decoding_with_EEG_Pre-Training_and_Multi-View_Transformer.md)

    - [翻译: EEG2TEXT：采用 EEG 预训练和多视角变换技术，实现开放词汇表的 EEG 到文本的转换。](2024年05月03日/EEG2TEXT_Open_Vocabulary_EEG-to-Text_Decoding_with_EEG_Pre-Training_and_Multi-View_Transformer.md)

- [The AI Review Lottery: Widespread AI-Assisted Peer Reviews Boost Paper Scores and Acceptance Rates](2024年05月03日/The_AI_Review_Lottery_Widespread_AI-Assisted_Peer_Reviews_Boost_Paper_Scores_and_Acceptance_Rates.md)

    - [翻译: AI评审的幸运抽奖：当人工智能辅助的同行评审变得普遍时，它显著提升了论文的评分和被接受的概率。](2024年05月03日/The_AI_Review_Lottery_Widespread_AI-Assisted_Peer_Reviews_Boost_Paper_Scores_and_Acceptance_Rates.md)

- [MedReadMe: A Systematic Study for Fine-grained Sentence Readability in Medical Domain](2024年05月03日/MedReadMe_A_Systematic_Study_for_Fine-grained_Sentence_Readability_in_Medical_Domain.md)

    - [翻译: MedReadMe：深入探究医学领域内句子细粒度可读性的系统性研究](2024年05月03日/MedReadMe_A_Systematic_Study_for_Fine-grained_Sentence_Readability_in_Medical_Domain.md)

- [Optimising Calls to Large Language Models with Uncertainty-Based Two-Tier Selection](2024年05月03日/Optimising_Calls_to_Large_Language_Models_with_Uncertainty-Based_Two-Tier_Selection.md)

    - [翻译: 通过不确定性驱动的双层筛选机制，提升对大型语言模型调用的优化效果。](2024年05月03日/Optimising_Calls_to_Large_Language_Models_with_Uncertainty-Based_Two-Tier_Selection.md)

- [Unveiling the Potential of LLM-Based ASR on Chinese Open-Source Datasets](2024年05月03日/Unveiling_the_Potential_of_LLM-Based_ASR_on_Chinese_Open-Source_Datasets.md)

    - [翻译: 探索基于大型语言模型的自动语音识别技术在中文开源数据集中的应用潜力。](2024年05月03日/Unveiling_the_Potential_of_LLM-Based_ASR_on_Chinese_Open-Source_Datasets.md)

- [Single and Multi-Hop Question-Answering Datasets for Reticular Chemistry with GPT-4-Turbo](2024年05月03日/Single_and_Multi-Hop_Question-Answering_Datasets_for_Reticular_Chemistry_with_GPT-4-Turbo.md)

    - [翻译: 为 Reticular Chemistry 领域设计的单跳与多跳问答数据集，特别适配 GPT-4-Turbo 模型](2024年05月03日/Single_and_Multi-Hop_Question-Answering_Datasets_for_Reticular_Chemistry_with_GPT-4-Turbo.md)

- [Evaluating Large Language Models for Structured Science Summarization in the Open Research Knowledge Graph](2024年05月03日/Evaluating_Large_Language_Models_for_Structured_Science_Summarization_in_the_Open_Research_Knowledge_Graph.md)

    - [翻译: 本文旨在探讨大型语言模型在开放研究知识图谱框架下进行结构化科学摘要的表现。](2024年05月03日/Evaluating_Large_Language_Models_for_Structured_Science_Summarization_in_the_Open_Research_Knowledge_Graph.md)

- [Argumentative Large Language Models for Explainable and Contestable Decision-Making](2024年05月03日/Argumentative_Large_Language_Models_for_Explainable_and_Contestable_Decision-Making.md)

    - [翻译: 构建论辩型大型语言模型，旨在实现决策过程的可解释性和可争议性。](2024年05月03日/Argumentative_Large_Language_Models_for_Explainable_and_Contestable_Decision-Making.md)

- [Large Multimodal Model based Standardisation of Pathology Reports with Confidence and their Prognostic Significance](2024年05月03日/Large_Multimodal_Model_based_Standardisation_of_Pathology_Reports_with_Confidence_and_their_Prognostic_Significance.md)

    - [翻译: 利用大型多模态模型对病理报告进行标准化处理，同时评估其置信度和对疾病预后的影响。](2024年05月03日/Large_Multimodal_Model_based_Standardisation_of_Pathology_Reports_with_Confidence_and_their_Prognostic_Significance.md)

- [Analyzing Narrative Processing in Large Language Models (LLMs): Using GPT4 to test BERT](2024年05月03日/Analyzing_Narrative_Processing_in_Large_Language_Models_(LLMs)_Using_GPT4_to_test_BERT.md)

    - [翻译: 探索大型语言模型中的叙事处理能力：以 GPT-4 作为工具，对 BERT 进行测试分析](2024年05月03日/Analyzing_Narrative_Processing_in_Large_Language_Models_(LLMs)_Using_GPT4_to_test_BERT.md)

- [Exploring Combinatorial Problem Solving with Large Language Models: A Case Study on the Travelling Salesman Problem Using GPT-3.5 Turbo](2024年05月03日/Exploring_Combinatorial_Problem_Solving_with_Large_Language_Models_A_Case_Study_on_the_Travelling_Salesman_Problem_Using_GPT-3.5_Turbo.md)

    - [翻译: 本研究深入探讨了大型语言模型在解决组合问题上的能力，特别是以 GPT-3.5 Turbo 为工具，对旅行商问题进行了一项案例研究。](2024年05月03日/Exploring_Combinatorial_Problem_Solving_with_Large_Language_Models_A_Case_Study_on_the_Travelling_Salesman_Problem_Using_GPT-3.5_Turbo.md)

- [Conformal Prediction for Natural Language Processing: A Survey](2024年05月03日/Conformal_Prediction_for_Natural_Language_Processing_A_Survey.md)

    - [翻译: 一致性预测在自然语言处理领域的应用：综述研究](2024年05月03日/Conformal_Prediction_for_Natural_Language_Processing_A_Survey.md)

- [Dependency-Aware Semi-Structured Sparsity of GLU Variants in Large Language Models](2024年05月03日/Dependency-Aware_Semi-Structured_Sparsity_of_GLU_Variants_in_Large_Language_Models.md)

    - [翻译: 在大型语言模型中，GLU 变种的依赖感知半结构化稀疏性研究](2024年05月03日/Dependency-Aware_Semi-Structured_Sparsity_of_GLU_Variants_in_Large_Language_Models.md)

- [Which Identities Are Mobilized: Towards an automated detection of social group appeals in political texts](2024年05月03日/Which_Identities_Are_Mobilized_Towards_an_automated_detection_of_social_group_appeals_in_political_texts.md)

    - [翻译: 身份动员探析：政治文本中社会群体呼吁的自动化识别研究](2024年05月03日/Which_Identities_Are_Mobilized_Towards_an_automated_detection_of_social_group_appeals_in_political_texts.md)

- [Aloe: A Family of Fine-tuned Open Healthcare LLMs](2024年05月03日/Aloe_A_Family_of_Fine-tuned_Open_Healthcare_LLMs.md)

    - [翻译: Aloe：一套经过精细调整的开放医疗大型语言模型家族](2024年05月03日/Aloe_A_Family_of_Fine-tuned_Open_Healthcare_LLMs.md)

- [DALLMi: Domain Adaption for LLM-based Multi-label Classifier](2024年05月03日/DALLMi_Domain_Adaption_for_LLM-based_Multi-label_Classifier.md)

    - [翻译: DALLMi：为基于大型语言模型的多标签分类任务量身定制的领域适应技术。](2024年05月03日/DALLMi_Domain_Adaption_for_LLM-based_Multi-label_Classifier.md)

- [Automated Control Logic Test Case Generation using Large Language Models](2024年05月03日/Automated_Control_Logic_Test_Case_Generation_using_Large_Language_Models.md)

    - [翻译: 利用大型语言模型实现控制逻辑测试用例的自动生成](2024年05月03日/Automated_Control_Logic_Test_Case_Generation_using_Large_Language_Models.md)

- [Incorporating External Knowledge and Goal Guidance for LLM-based Conversational Recommender Systems](2024年05月03日/Incorporating_External_Knowledge_and_Goal_Guidance_for_LLM-based_Conversational_Recommender_Systems.md)

    - [翻译: 为基于大型语言模型的对话式推荐系统融入外部知识并引入目标导向。](2024年05月03日/Incorporating_External_Knowledge_and_Goal_Guidance_for_LLM-based_Conversational_Recommender_Systems.md)

- [SUKHSANDESH: An Avatar Therapeutic Question Answering Platform for Sexual Education in Rural India](2024年05月03日/SUKHSANDESH_An_Avatar_Therapeutic_Question_Answering_Platform_for_Sexual_Education_in_Rural_India.md)

    - [翻译: SUKHSANDESH：一个面向印度农村地区的性教育虚拟治疗问答平台。](2024年05月03日/SUKHSANDESH_An_Avatar_Therapeutic_Question_Answering_Platform_for_Sexual_Education_in_Rural_India.md)

- [SGHateCheck: Functional Tests for Detecting Hate Speech in Low-Resource Languages of Singapore](2024年05月03日/SGHateCheck_Functional_Tests_for_Detecting_Hate_Speech_in_Low-Resource_Languages_of_Singapore.md)

    - [翻译: SGHateCheck：一种功能性测试工具，旨在识别新加坡低资源语言中的仇恨言论。](2024年05月03日/SGHateCheck_Functional_Tests_for_Detecting_Hate_Speech_in_Low-Resource_Languages_of_Singapore.md)

- [Automating the Enterprise with Foundation Models](2024年05月03日/Automating_the_Enterprise_with_Foundation_Models.md)

    - [翻译: 借助基础模型，企业自动化得以实现。本研究旨在探索基础模型在企业自动化中的应用，并分析其对提升效率和创新能力的影响。](2024年05月03日/Automating_the_Enterprise_with_Foundation_Models.md)

2024年05月02日

- [Plan-Seq-Learn: Language Model Guided RL for Solving Long Horizon Robotics Tasks](2024年05月02日/Plan-Seq-Learn_Language_Model_Guided_RL_for_Solving_Long_Horizon_Robotics_Tasks.md)

    - [翻译: Plan-Seq-Learn：一种由语言模型引导的强化学习方法，专为解决机器人领域的长期任务而设计。](2024年05月02日/Plan-Seq-Learn_Language_Model_Guided_RL_for_Solving_Long_Horizon_Robotics_Tasks.md)

- [OmniDrive: A Holistic LLM-Agent Framework for Autonomous Driving with 3D Perception, Reasoning and Planning](2024年05月02日/OmniDrive_A_Holistic_LLM-Agent_Framework_for_Autonomous_Driving_with_3D_Perception,_Reasoning_and_Planning.md)

    - [翻译: OmniDrive：一套综合性的LLM代理框架，专为自动驾驶设计，集成了3D感知、推理和规划功能。](2024年05月02日/OmniDrive_A_Holistic_LLM-Agent_Framework_for_Autonomous_Driving_with_3D_Perception,_Reasoning_and_Planning.md)

- [FLAME: Factuality-Aware Alignment for Large Language Models](2024年05月02日/FLAME_Factuality-Aware_Alignment_for_Large_Language_Models.md)

    - [翻译: FLAME：为大型语言模型打造的事实感知对齐技术](2024年05月02日/FLAME_Factuality-Aware_Alignment_for_Large_Language_Models.md)

- [Transformer-Aided Semantic Communications](2024年05月02日/Transformer-Aided_Semantic_Communications.md)

    - [翻译: 借助Transformer的语义通信技术](2024年05月02日/Transformer-Aided_Semantic_Communications.md)

- [Analyzing the Role of Semantic Representations in the Era of Large Language Models](2024年05月02日/Analyzing_the_Role_of_Semantic_Representations_in_the_Era_of_Large_Language_Models.md)

    - [翻译: 在大型语言模型盛行的当下，深入探讨语义表示的角色与重要性。](2024年05月02日/Analyzing_the_Role_of_Semantic_Representations_in_the_Era_of_Large_Language_Models.md)

- [Supporting Business Document Workflows via Collection-Centric Information Foraging with Large Language Models](2024年05月02日/Supporting_Business_Document_Workflows_via_Collection-Centric_Information_Foraging_with_Large_Language_Models.md)

    - [翻译: 利用大型语言模型，通过集中式信息搜集，助力商业文档工作流程的优化。](2024年05月02日/Supporting_Business_Document_Workflows_via_Collection-Centric_Information_Foraging_with_Large_Language_Models.md)

- [Controllable Text Generation in the Instruction-Tuning Era](2024年05月02日/Controllable_Text_Generation_in_the_Instruction-Tuning_Era.md)

    - [翻译: 在指令调整时代下的可控文本生成](2024年05月02日/Controllable_Text_Generation_in_the_Instruction-Tuning_Era.md)

- [MANTIS: Interleaved Multi-Image Instruction Tuning](2024年05月02日/MANTIS_Interleaved_Multi-Image_Instruction_Tuning.md)

    - [翻译: MANTIS：交错式多图像指令优化](2024年05月02日/MANTIS_Interleaved_Multi-Image_Instruction_Tuning.md)

- [NeMo-Aligner: Scalable Toolkit for Efficient Model Alignment](2024年05月02日/NeMo-Aligner_Scalable_Toolkit_for_Efficient_Model_Alignment.md)

    - [翻译: NeMo-Aligner：高效模型对齐的可扩展工具集](2024年05月02日/NeMo-Aligner_Scalable_Toolkit_for_Efficient_Model_Alignment.md)

- [V-FLUTE: Visual Figurative Language Understanding with Textual Explanations](2024年05月02日/V-FLUTE_Visual_Figurative_Language_Understanding_with_Textual_Explanations.md)

    - [翻译: V-FLUTE：图文结合，洞悉视觉比喻语言的深层含义](2024年05月02日/V-FLUTE_Visual_Figurative_Language_Understanding_with_Textual_Explanations.md)

- [A Systematic Literature Review on Large Language Models for Automated Program Repair](2024年05月02日/A_Systematic_Literature_Review_on_Large_Language_Models_for_Automated_Program_Repair.md)

    - [翻译: 本文系统性地回顾了用于自动化程序修复的大型语言模型的相关文献。](2024年05月02日/A_Systematic_Literature_Review_on_Large_Language_Models_for_Automated_Program_Repair.md)

- [UQA: Corpus for Urdu Question Answering](2024年05月02日/UQA_Corpus_for_Urdu_Question_Answering.md)

    - [翻译: UQA：乌尔都语问答语料库](2024年05月02日/UQA_Corpus_for_Urdu_Question_Answering.md)

- [Creative Problem Solving in Large Language and Vision Models -- What Would it Take?](2024年05月02日/Creative_Problem_Solving_in_Large_Language_and_Vision_Models_--_What_Would_it_Take.md)

    - [翻译: 探索大型语言与视觉模型中的创新性问题解决之道 -- 我们该如何应对这一挑战？](2024年05月02日/Creative_Problem_Solving_in_Large_Language_and_Vision_Models_--_What_Would_it_Take.md)

- [Natural Language to Verilog: Design of a Recurrent Spiking Neural Network using Large Language Models and ChatGPT](2024年05月02日/Natural_Language_to_Verilog_Design_of_a_Recurrent_Spiking_Neural_Network_using_Large_Language_Models_and_ChatGPT.md)

    - [翻译: 将自然语言转换为 Verilog 代码：我们利用大型语言模型和 ChatGPT，设计了一种递归脉冲神经网络。](2024年05月02日/Natural_Language_to_Verilog_Design_of_a_Recurrent_Spiking_Neural_Network_using_Large_Language_Models_and_ChatGPT.md)

- [MiniGPT-3D: Efficiently Aligning 3D Point Clouds with Large Language Models using 2D Priors](2024年05月02日/MiniGPT-3D_Efficiently_Aligning_3D_Point_Clouds_with_Large_Language_Models_using_2D_Priors.md)

    - [翻译: MiniGPT-3D：借助2D先验，高效实现3D点云与大型语言模型的精准对齐。](2024年05月02日/MiniGPT-3D_Efficiently_Aligning_3D_Point_Clouds_with_Large_Language_Models_using_2D_Priors.md)

- [Verification and Refinement of Natural Language Explanations through LLM-Symbolic Theorem Proving](2024年05月02日/Verification_and_Refinement_of_Natural_Language_Explanations_through_LLM-Symbolic_Theorem_Proving.md)

    - [翻译: 利用大型语言模型（LLM）中的符号定理证明技术，对自然语言解释进行验证与优化。](2024年05月02日/Verification_and_Refinement_of_Natural_Language_Explanations_through_LLM-Symbolic_Theorem_Proving.md)

- [GAIA: A General AI Assistant for Intelligent Accelerator Operations](2024年05月02日/GAIA_A_General_AI_Assistant_for_Intelligent_Accelerator_Operations.md)

    - [翻译: GAIA：一款为智能化加速器运营提供助力的全能AI助手。](2024年05月02日/GAIA_A_General_AI_Assistant_for_Intelligent_Accelerator_Operations.md)

- [Human-Robot Interaction Conversational User Enjoyment Scale (HRI CUES)](2024年05月02日/Human-Robot_Interaction_Conversational_User_Enjoyment_Scale_(HRI_CUES).md)

    - [翻译: 人机互动对话用户愉悦度量表（HRI CUES）](2024年05月02日/Human-Robot_Interaction_Conversational_User_Enjoyment_Scale_(HRI_CUES).md)

- [The Power of Question Translation Training in Multilingual Reasoning: Broadened Scope and Deepened Insights](2024年05月02日/The_Power_of_Question_Translation_Training_in_Multilingual_Reasoning_Broadened_Scope_and_Deepened_Insights.md)

    - [翻译: 通过问题翻译训练提升多语言推理能力：拓展研究视野，深化理解深度。](2024年05月02日/The_Power_of_Question_Translation_Training_in_Multilingual_Reasoning_Broadened_Scope_and_Deepened_Insights.md)

- [Overcoming LLM Challenges using RAG-Driven Precision in Coffee Leaf Disease Remediation](2024年05月02日/Overcoming_LLM_Challenges_using_RAG-Driven_Precision_in_Coffee_Leaf_Disease_Remediation.md)

    - [翻译: 利用 RAG（Retrieval-Augmented Generation）技术提高精确度，有效应对大型语言模型在咖啡叶病害治理中的难题。](2024年05月02日/Overcoming_LLM_Challenges_using_RAG-Driven_Precision_in_Coffee_Leaf_Disease_Remediation.md)

- [The Effectiveness of LLMs as Annotators: A Comparative Overview and Empirical Analysis of Direct Representation](2024年05月02日/The_Effectiveness_of_LLMs_as_Annotators_A_Comparative_Overview_and_Empirical_Analysis_of_Direct_Representation.md)

    - [翻译: 探究大型语言模型作为注释工具的效能：一篇关于直接表征方法的对比概览与实证研究分析](2024年05月02日/The_Effectiveness_of_LLMs_as_Annotators_A_Comparative_Overview_and_Empirical_Analysis_of_Direct_Representation.md)

- [Reinforcement Learning for Edit-Based Non-Autoregressive Neural Machine Translation](2024年05月02日/Reinforcement_Learning_for_Edit-Based_Non-Autoregressive_Neural_Machine_Translation.md)

    - [翻译: 强化学习在基于编辑的非自回归神经机器翻译中的应用](2024年05月02日/Reinforcement_Learning_for_Edit-Based_Non-Autoregressive_Neural_Machine_Translation.md)

- [Prompt engineering paradigms for medical applications: scoping review and recommendations for better practices](2024年05月02日/Prompt_engineering_paradigms_for_medical_applications_scoping_review_and_recommendations_for_better_practices.md)

    - [翻译: 医疗领域提示工程的范式：全面审视与提升实践的建言](2024年05月02日/Prompt_engineering_paradigms_for_medical_applications_scoping_review_and_recommendations_for_better_practices.md)

- [Boosting Jailbreak Attack with Momentum](2024年05月02日/Boosting_Jailbreak_Attack_with_Momentum.md)

    - [翻译: 借助动量效应，提升越狱攻击的威力](2024年05月02日/Boosting_Jailbreak_Attack_with_Momentum.md)

- [DLAP: A Deep Learning Augmented Large Language Model Prompting Framework for Software Vulnerability Detection](2024年05月02日/DLAP_A_Deep_Learning_Augmented_Large_Language_Model_Prompting_Framework_for_Software_Vulnerability_Detection.md)

    - [翻译: DLAP：深度学习助力的大型语言模型提示框架，专为软件漏洞检测而设计。](2024年05月02日/DLAP_A_Deep_Learning_Augmented_Large_Language_Model_Prompting_Framework_for_Software_Vulnerability_Detection.md)

- [Generative Relevance Feedback and Convergence of Adaptive Re-Ranking: University of Glasgow Terrier Team at TREC DL 2023](2024年05月02日/Generative_Relevance_Feedback_and_Convergence_of_Adaptive_Re-Ranking_University_of_Glasgow_Terrier_Team_at_TREC_DL_2023.md)

    - [翻译: 格拉斯哥大学的特里尔团队在2023年TREC DL竞赛中展示了他们在生成式相关反馈和自适应重排序技术方面的成果，这些技术在信息检索任务中实现了显著的收敛效果。](2024年05月02日/Generative_Relevance_Feedback_and_Convergence_of_Adaptive_Re-Ranking_University_of_Glasgow_Terrier_Team_at_TREC_DL_2023.md)

- [Efficient Data Generation for Source-grounded Information-seeking Dialogs: A Use Case for Meeting Transcripts](2024年05月02日/Efficient_Data_Generation_for_Source-grounded_Information-seeking_Dialogs_A_Use_Case_for_Meeting_Transcripts.md)

    - [翻译: 高效数据生成：以会议记录为信息寻求型源-地面对话的用例](2024年05月02日/Efficient_Data_Generation_for_Source-grounded_Information-seeking_Dialogs_A_Use_Case_for_Meeting_Transcripts.md)

- ["In-Context Learning" or: How I learned to stop worrying and love "Applied Information Retrieval"](2024年05月02日/In-Context_Learning_or_How_I_learned_to_stop_worrying_and_love_Applied_Information_Retrieval.md)

    - [翻译: 《上下文学习》：我如何学会不再担忧并拥抱“应用信息检索”的世界](2024年05月02日/In-Context_Learning_or_How_I_learned_to_stop_worrying_and_love_Applied_Information_Retrieval.md)

- [LLM Security Guard for Code](2024年05月02日/LLM_Security_Guard_for_Code.md)

    - [翻译: 大型语言模型的安全守护者：代码防护](2024年05月02日/LLM_Security_Guard_for_Code.md)

- [Learning Object States from Actions via Large Language Models](2024年05月02日/Learning_Object_States_from_Actions_via_Large_Language_Models.md)

    - [翻译: 利用大型语言模型从动作中学习对象状态。](2024年05月02日/Learning_Object_States_from_Actions_via_Large_Language_Models.md)

- [Generating User Experience Based on Personas with AI Assistants](2024年05月02日/Generating_User_Experience_Based_on_Personas_with_AI_Assistants.md)

    - [翻译: 利用人工智能助手，根据人物角色创造用户体验](2024年05月02日/Generating_User_Experience_Based_on_Personas_with_AI_Assistants.md)

- [Causal Influence in Federated Edge Inference](2024年05月02日/Causal_Influence_in_Federated_Edge_Inference.md)

    - [翻译: 在联合边缘推理领域，因果关系的影响是一个关键因素。](2024年05月02日/Causal_Influence_in_Federated_Edge_Inference.md)

- [Improving Concept Alignment in Vision-Language Concept Bottleneck Models](2024年05月02日/Improving_Concept_Alignment_in_Vision-Language_Concept_Bottleneck_Models.md)

    - [翻译: 提升视觉-语言概念瓶颈模型中的概念一致性](2024年05月02日/Improving_Concept_Alignment_in_Vision-Language_Concept_Bottleneck_Models.md)

- [Efficient and Economic Large Language Model Inference with Attention Offloading](2024年05月02日/Efficient_and_Economic_Large_Language_Model_Inference_with_Attention_Offloading.md)

    - [翻译: 通过注意力卸载实现大型语言模型的高效经济推理](2024年05月02日/Efficient_and_Economic_Large_Language_Model_Inference_with_Attention_Offloading.md)

- [Exploiting ChatGPT for Diagnosing Autism-Associated Language Disorders and Identifying Distinct Features](2024年05月02日/Exploiting_ChatGPT_for_Diagnosing_Autism-Associated_Language_Disorders_and_Identifying_Distinct_Features.md)

    - [翻译: 通过 ChatGPT 来识别自闭症相关的语言障碍，并挖掘其独特的特征。](2024年05月02日/Exploiting_ChatGPT_for_Diagnosing_Autism-Associated_Language_Disorders_and_Identifying_Distinct_Features.md)

- [Towards Neural Synthesis for SMT-Assisted Proof-Oriented Programming](2024年05月02日/Towards_Neural_Synthesis_for_SMT-Assisted_Proof-Oriented_Programming.md)

    - [翻译: 探索神经合成技术，助力 SMT 支持的面向证明编程发展](2024年05月02日/Towards_Neural_Synthesis_for_SMT-Assisted_Proof-Oriented_Programming.md)

- [A Survey on Large Language Models for Critical Societal Domains: Finance, Healthcare, and Law](2024年05月02日/A_Survey_on_Large_Language_Models_for_Critical_Societal_Domains_Finance,_Healthcare,_and_Law.md)

    - [翻译: 一项针对金融、医疗保健和法律等关键社会领域内大型语言模型的综述研究](2024年05月02日/A_Survey_on_Large_Language_Models_for_Critical_Societal_Domains_Finance,_Healthcare,_and_Law.md)

- [CoS: Enhancing Personalization and Mitigating Bias with Context Steering](2024年05月02日/CoS_Enhancing_Personalization_and_Mitigating_Bias_with_Context_Steering.md)

    - [翻译: CoS技术：借助上下文导航，提升个性化体验，同时有效降低偏见风险。](2024年05月02日/CoS_Enhancing_Personalization_and_Mitigating_Bias_with_Context_Steering.md)

- [Large Language Models for UAVs: Current State and Pathways to the Future](2024年05月02日/Large_Language_Models_for_UAVs_Current_State_and_Pathways_to_the_Future.md)

    - [翻译: 无人机领域的大型语言模型：现状与未来展望。](2024年05月02日/Large_Language_Models_for_UAVs_Current_State_and_Pathways_to_the_Future.md)

- [ALCM: Autonomous LLM-Augmented Causal Discovery Framework](2024年05月02日/ALCM_Autonomous_LLM-Augmented_Causal_Discovery_Framework.md)

    - [翻译: ALCM：独立增强型大型语言模型因果探索框架](2024年05月02日/ALCM_Autonomous_LLM-Augmented_Causal_Discovery_Framework.md)

- [Question Suggestion for Conversational Shopping Assistants Using Product Metadata](2024年05月02日/Question_Suggestion_for_Conversational_Shopping_Assistants_Using_Product_Metadata.md)

    - [翻译: 利用产品元数据，为对话式购物助手提供问题建议](2024年05月02日/Question_Suggestion_for_Conversational_Shopping_Assistants_Using_Product_Metadata.md)

- [Large Language Models are Inconsistent and Biased Evaluators](2024年05月02日/Large_Language_Models_are_Inconsistent_and_Biased_Evaluators.md)

    - [翻译: 大型语言模型作为评估工具，存在不一致性和偏见问题。](2024年05月02日/Large_Language_Models_are_Inconsistent_and_Biased_Evaluators.md)

- [FSM Builder: A Tool for Writing Autograded Finite Automata Questions](2024年05月02日/FSM_Builder_A_Tool_for_Writing_Autograded_Finite_Automata_Questions.md)

    - [翻译: FSM Builder：一款编写自动评分有限自动机习题的工具](2024年05月02日/FSM_Builder_A_Tool_for_Writing_Autograded_Finite_Automata_Questions.md)

- [Requirements-driven Slicing of Simulink Models Using LLMs](2024年05月02日/Requirements-driven_Slicing_of_Simulink_Models_Using_LLMs.md)

    - [翻译: 运用大型语言模型 (LLMs) 实施对 Simulink 模型的基于需求的切片操作。](2024年05月02日/Requirements-driven_Slicing_of_Simulink_Models_Using_LLMs.md)

- [Language-Enhanced Latent Representations for Out-of-Distribution Detection in Autonomous Driving](2024年05月02日/Language-Enhanced_Latent_Representations_for_Out-of-Distribution_Detection_in_Autonomous_Driving.md)

    - [翻译: 为了在自动驾驶领域识别那些超出常规分布的异常情况，我们采用了一种语言增强的潜在表示方法。](2024年05月02日/Language-Enhanced_Latent_Representations_for_Out-of-Distribution_Detection_in_Autonomous_Driving.md)

- [Automatically Extracting Numerical Results from Randomized Controlled Trials with Large Language Models](2024年05月02日/Automatically_Extracting_Numerical_Results_from_Randomized_Controlled_Trials_with_Large_Language_Models.md)

    - [翻译: 利用大型语言模型，我们能够自动地从随机对照试验中抽取出数值数据。](2024年05月02日/Automatically_Extracting_Numerical_Results_from_Randomized_Controlled_Trials_with_Large_Language_Models.md)

- [Leveraging Prompt-Learning for Structured Information Extraction from Crohn's Disease Radiology Reports in a Low-Resource Language](2024年05月02日/Leveraging_Prompt-Learning_for_Structured_Information_Extraction_from_Crohn's_Disease_Radiology_Reports_in_a_Low-Resource_Language.md)

    - [翻译: 通过提示学习技术，我们能够从克罗恩病的放射学报告中高效提取结构化信息，即便在资源匮乏的语言环境中也表现出色。](2024年05月02日/Leveraging_Prompt-Learning_for_Structured_Information_Extraction_from_Crohn's_Disease_Radiology_Reports_in_a_Low-Resource_Language.md)

- [Generative AI in Cybersecurity](2024年05月02日/Generative_AI_in_Cybersecurity.md)

    - [翻译: 在网络安全领域，生成性人工智能的应用正日益显现其重要性。](2024年05月02日/Generative_AI_in_Cybersecurity.md)

- [WitheredLeaf: Finding Entity-Inconsistency Bugs with LLMs](2024年05月02日/WitheredLeaf_Finding_Entity-Inconsistency_Bugs_with_LLMs.md)

    - [翻译: WitheredLeaf：利用大型语言模型挖掘实体不一致性缺陷](2024年05月02日/WitheredLeaf_Finding_Entity-Inconsistency_Bugs_with_LLMs.md)

- [Investigating Wit, Creativity, and Detectability of Large Language Models in Domain-Specific Writing Style Adaptation of Reddit's Showerthoughts](2024年05月02日/Investigating_Wit,_Creativity,_and_Detectability_of_Large_Language_Models_in_Domain-Specific_Writing_Style_Adaptation_of_Reddit's_Showerthoughts.md)

    - [翻译: 本研究旨在探究大型语言模型在 Reddit Showerthoughts 社区特定写作风格适应中的机智、创造力及其可被察觉的程度。](2024年05月02日/Investigating_Wit,_Creativity,_and_Detectability_of_Large_Language_Models_in_Domain-Specific_Writing_Style_Adaptation_of_Reddit's_Showerthoughts.md)

- [Improving Complex Reasoning over Knowledge Graph with Logic-Aware Curriculum Tuning](2024年05月02日/Improving_Complex_Reasoning_over_Knowledge_Graph_with_Logic-Aware_Curriculum_Tuning.md)

    - [翻译: 本文探讨了如何通过逻辑感知的课程调整方法，提升在知识图谱上进行复杂推理的性能。](2024年05月02日/Improving_Complex_Reasoning_over_Knowledge_Graph_with_Logic-Aware_Curriculum_Tuning.md)

- [Automating the Analysis of Public Saliency and Attitudes towards Biodiversity from Digital Media](2024年05月02日/Automating_the_Analysis_of_Public_Saliency_and_Attitudes_towards_Biodiversity_from_Digital_Media.md)

    - [翻译: 自动化地从数字媒体中分析公众对生物多样性的关注点和态度](2024年05月02日/Automating_the_Analysis_of_Public_Saliency_and_Attitudes_towards_Biodiversity_from_Digital_Media.md)

- [CodeGRAG: Extracting Composed Syntax Graphs for Retrieval Augmented Cross-Lingual Code Generation](2024年05月02日/CodeGRAG_Extracting_Composed_Syntax_Graphs_for_Retrieval_Augmented_Cross-Lingual_Code_Generation.md)

    - [翻译: CodeGRAF：为增强检索的跨语言代码生成提取复合语法图。](2024年05月02日/CodeGRAG_Extracting_Composed_Syntax_Graphs_for_Retrieval_Augmented_Cross-Lingual_Code_Generation.md)

2024年05月01日

- [Is Bigger Edit Batch Size Always Better? -- An Empirical Study on Model Editing with Llama-3](2024年05月01日/Is_Bigger_Edit_Batch_Size_Always_Better_--_An_Empirical_Study_on_Model_Editing_with_Llama-3.md)

    - [翻译: 编辑批量大小越大，效果一定越佳吗？一项基于 Llama-3 模型编辑的实证探索。](2024年05月01日/Is_Bigger_Edit_Batch_Size_Always_Better_--_An_Empirical_Study_on_Model_Editing_with_Llama-3.md)

- [HalluVault: A Novel Logic Programming-aided Metamorphic Testing Framework for Detecting Fact-Conflicting Hallucinations in Large Language Models](2024年05月01日/HalluVault_A_Novel_Logic_Programming-aided_Metamorphic_Testing_Framework_for_Detecting_Fact-Conflicting_Hallucinations_in_Large_Language_Models.md)

    - [翻译: HalluVault：一个创新的基于逻辑编程的变异测试框架，专为发现大型语言模型中与事实相悖的幻觉现象而设计。](2024年05月01日/HalluVault_A_Novel_Logic_Programming-aided_Metamorphic_Testing_Framework_for_Detecting_Fact-Conflicting_Hallucinations_in_Large_Language_Models.md)

- [When Quantization Affects Confidence of Large Language Models?](2024年05月01日/When_Quantization_Affects_Confidence_of_Large_Language_Models.md)

    - [翻译: 量化如何影响大型语言模型的置信度？](2024年05月01日/When_Quantization_Affects_Confidence_of_Large_Language_Models.md)

- ["I'm Not Sure, But...": Examining the Impact of Large Language Models' Uncertainty Expression on User Reliance and Trust](2024年05月01日/I'm_Not_Sure,_But..._Examining_the_Impact_of_Large_Language_Models'_Uncertainty_Expression_on_User_Reliance_and_Trust.md)

    - [翻译: 《“我不确定，但是...”：探究大型语言模型不确定性表述对用户信赖与依赖的影响》](2024年05月01日/I'm_Not_Sure,_But..._Examining_the_Impact_of_Large_Language_Models'_Uncertainty_Expression_on_User_Reliance_and_Trust.md)

- [Addressing Topic Granularity and Hallucination in Large Language Models for Topic Modelling](2024年05月01日/Addressing_Topic_Granularity_and_Hallucination_in_Large_Language_Models_for_Topic_Modelling.md)

    - [翻译: 探讨大型语言模型在主题建模中的主题粒度细化与幻觉现象](2024年05月01日/Addressing_Topic_Granularity_and_Hallucination_in_Large_Language_Models_for_Topic_Modelling.md)

- [Investigating Automatic Scoring and Feedback using Large Language Models](2024年05月01日/Investigating_Automatic_Scoring_and_Feedback_using_Large_Language_Models.md)

    - [翻译: 探究基于大型语言模型的自动评分与反馈机制](2024年05月01日/Investigating_Automatic_Scoring_and_Feedback_using_Large_Language_Models.md)

- [Are Models Biased on Text without Gender-related Language?](2024年05月01日/Are_Models_Biased_on_Text_without_Gender-related_Language.md)

    - [翻译: 文本中若未涉及性别相关词汇，模型是否会表现出偏见？](2024年05月01日/Are_Models_Biased_on_Text_without_Gender-related_Language.md)

- [The Real, the Better: Aligning Large Language Models with Online Human Behaviors](2024年05月01日/The_Real,_the_Better_Aligning_Large_Language_Models_with_Online_Human_Behaviors.md)

    - [翻译: 追求真实，更上一层楼：使大型语言模型与网民在线行为同步。](2024年05月01日/The_Real,_the_Better_Aligning_Large_Language_Models_with_Online_Human_Behaviors.md)

- [EALD-MLLM: Emotion Analysis in Long-sequential and De-identity videos with Multi-modal Large Language Model](2024年05月01日/EALD-MLLM_Emotion_Analysis_in_Long-sequential_and_De-identity_videos_with_Multi-modal_Large_Language_Model.md)

    - [翻译: EALD-MLLM：利用多模态大型语言模型对长序列及去身份视频进行情感分析。](2024年05月01日/EALD-MLLM_Emotion_Analysis_in_Long-sequential_and_De-identity_videos_with_Multi-modal_Large_Language_Model.md)

- [NumLLM: Numeric-Sensitive Large Language Model for Chinese Finance](2024年05月01日/NumLLM_Numeric-Sensitive_Large_Language_Model_for_Chinese_Finance.md)

    - [翻译: NumLLM：一款专为中文金融领域设计的、对数值高度敏感的大型语言模型。](2024年05月01日/NumLLM_Numeric-Sensitive_Large_Language_Model_for_Chinese_Finance.md)

- [Mixture of insighTful Experts (MoTE): The Synergy of Thought Chains and Expert Mixtures in Self-Alignment](2024年05月01日/Mixture_of_insighTful_Experts_(MoTE)_The_Synergy_of_Thought_Chains_and_Expert_Mixtures_in_Self-Alignment.md)

    - [翻译: 洞察力专家混合体（MoTE）：在自我对齐的过程中，思维链与专家组合的相互促进。](2024年05月01日/Mixture_of_insighTful_Experts_(MoTE)_The_Synergy_of_Thought_Chains_and_Expert_Mixtures_in_Self-Alignment.md)

- [Long-Term Human Trajectory Prediction using 3D Dynamic Scene Graphs](2024年05月01日/Long-Term_Human_Trajectory_Prediction_using_3D_Dynamic_Scene_Graphs.md)

    - [翻译: 通过 3D 动态场景图实现对人类长期轨迹的精准预测。](2024年05月01日/Long-Term_Human_Trajectory_Prediction_using_3D_Dynamic_Scene_Graphs.md)

- [A Legal Framework for Natural Language Processing Model Training in Portugal](2024年05月01日/A_Legal_Framework_for_Natural_Language_Processing_Model_Training_in_Portugal.md)

    - [翻译: 葡萄牙建立了一个针对自然语言处理（NLP）模型训练的法律框架。](2024年05月01日/A_Legal_Framework_for_Natural_Language_Processing_Model_Training_in_Portugal.md)

- [ChatBI: Towards Natural Language to Complex Business Intelligence SQL](2024年05月01日/ChatBI_Towards_Natural_Language_to_Complex_Business_Intelligence_SQL.md)

    - [翻译: ChatBI：探索将自然语言转换为复杂的商业智能SQL语句的路径](2024年05月01日/ChatBI_Towards_Natural_Language_to_Complex_Business_Intelligence_SQL.md)

- [Navigating WebAI: Training Agents to Complete Web Tasks with Large Language Models and Reinforcement Learning](2024年05月01日/Navigating_WebAI_Training_Agents_to_Complete_Web_Tasks_with_Large_Language_Models_and_Reinforcement_Learning.md)

    - [翻译: 探索 WebAI：通过大型语言模型和强化学习训练代理来完成网络任务。](2024年05月01日/Navigating_WebAI_Training_Agents_to_Complete_Web_Tasks_with_Large_Language_Models_and_Reinforcement_Learning.md)

- [GOLD: Geometry Problem Solver with Natural Language Description](2024年05月01日/GOLD_Geometry_Problem_Solver_with_Natural_Language_Description.md)

    - [翻译: GOLD：一款能够理解自然语言描述来解决几何问题的智能求解器。](2024年05月01日/GOLD_Geometry_Problem_Solver_with_Natural_Language_Description.md)

- [Is Temperature the Creativity Parameter of Large Language Models?](2024年05月01日/Is_Temperature_the_Creativity_Parameter_of_Large_Language_Models.md)

    - [翻译: 温度是否决定了大型语言模型的创造力？](2024年05月01日/Is_Temperature_the_Creativity_Parameter_of_Large_Language_Models.md)

- [Explainable Automatic Grading with Neural Additive Models](2024年05月01日/Explainable_Automatic_Grading_with_Neural_Additive_Models.md)

    - [翻译: 神经加性模型在自动评分中的应用，实现了评分过程的可解释性。](2024年05月01日/Explainable_Automatic_Grading_with_Neural_Additive_Models.md)

- [The Pyramid of Captions](2024年05月01日/The_Pyramid_of_Captions.md)

    - [翻译: 标题层级金字塔](2024年05月01日/The_Pyramid_of_Captions.md)

- [BiomedRAG: A Retrieval Augmented Large Language Model for Biomedicine](2024年05月01日/BiomedRAG_A_Retrieval_Augmented_Large_Language_Model_for_Biomedicine.md)

    - [翻译: BiomedRAG：一种为生物医学领域设计的、结合了检索功能的先进大型语言模型。](2024年05月01日/BiomedRAG_A_Retrieval_Augmented_Large_Language_Model_for_Biomedicine.md)

- [Enhancing Surgical Robots with Embodied Intelligence for Autonomous Ultrasound Scanning](2024年05月01日/Enhancing_Surgical_Robots_with_Embodied_Intelligence_for_Autonomous_Ultrasound_Scanning.md)

    - [翻译: 为手术机器人注入体现智能，提升其进行自主超声扫描的性能。](2024年05月01日/Enhancing_Surgical_Robots_with_Embodied_Intelligence_for_Autonomous_Ultrasound_Scanning.md)

- [Monte Carlo Tree Search Boosts Reasoning via Iterative Preference Learning](2024年05月01日/Monte_Carlo_Tree_Search_Boosts_Reasoning_via_Iterative_Preference_Learning.md)

    - [翻译: 蒙特卡洛树搜索（MCTS）通过不断迭代的偏好学习，显著提升了推理能力。](2024年05月01日/Monte_Carlo_Tree_Search_Boosts_Reasoning_via_Iterative_Preference_Learning.md)

- [RAG-based Explainable Prediction of Road Users Behaviors for Automated Driving using Knowledge Graphs and Large Language Models](2024年05月01日/RAG-based_Explainable_Prediction_of_Road_Users_Behaviors_for_Automated_Driving_using_Knowledge_Graphs_and_Large_Language_Models.md)

    - [翻译: 利用知识图谱和大型语言模型，基于 RAG（Retrieval-Augmented Generation）框架，对自动驾驶中道路使用者的行为进行可解释预测。](2024年05月01日/RAG-based_Explainable_Prediction_of_Road_Users_Behaviors_for_Automated_Driving_using_Knowledge_Graphs_and_Large_Language_Models.md)

- [CultiVerse: Towards Cross-Cultural Understanding for Paintings with Large Language Model](2024年05月01日/CultiVerse_Towards_Cross-Cultural_Understanding_for_Paintings_with_Large_Language_Model.md)

    - [翻译: CultiVerse：迈向利用大型语言模型深化对绘画艺术的跨文化洞察。](2024年05月01日/CultiVerse_Towards_Cross-Cultural_Understanding_for_Paintings_with_Large_Language_Model.md)

- [Self-Refine Instruction-Tuning for Aligning Reasoning in Language Models](2024年05月01日/Self-Refine_Instruction-Tuning_for_Aligning_Reasoning_in_Language_Models.md)

    - [翻译: 自我精炼的指令调优：优化语言模型中的推理对齐。](2024年05月01日/Self-Refine_Instruction-Tuning_for_Aligning_Reasoning_in_Language_Models.md)

- [Inferring State Machine from the Protocol Implementation via Large Langeuage Model](2024年05月01日/Inferring_State_Machine_from_the_Protocol_Implementation_via_Large_Langeuage_Model.md)

    - [翻译: 利用大型语言模型，从协议实现中推导出状态机。](2024年05月01日/Inferring_State_Machine_from_the_Protocol_Implementation_via_Large_Langeuage_Model.md)

- [CofiPara: A Coarse-to-fine Paradigm for Multimodal Sarcasm Target Identification with Large Multimodal Models](2024年05月01日/CofiPara_A_Coarse-to-fine_Paradigm_for_Multimodal_Sarcasm_Target_Identification_with_Large_Multimodal_Models.md)

    - [翻译: CofiPara：一种从粗略到精细的多模态讽刺目标识别方法，适用于大型多模态模型。](2024年05月01日/CofiPara_A_Coarse-to-fine_Paradigm_for_Multimodal_Sarcasm_Target_Identification_with_Large_Multimodal_Models.md)

- [AdaMoLE: Fine-Tuning Large Language Models with Adaptive Mixture of Low-Rank Adaptation Experts](2024年05月01日/AdaMoLE_Fine-Tuning_Large_Language_Models_with_Adaptive_Mixture_of_Low-Rank_Adaptation_Experts.md)

    - [翻译: AdaMoLE：以自适应低秩专家混合策略，对大型语言模型进行精准微调。](2024年05月01日/AdaMoLE_Fine-Tuning_Large_Language_Models_with_Adaptive_Mixture_of_Low-Rank_Adaptation_Experts.md)

- [Exploring Self-Supervised Vision Transformers for Deepfake Detection: A Comparative Analysis](2024年05月01日/Exploring_Self-Supervised_Vision_Transformers_for_Deepfake_Detection_A_Comparative_Analysis.md)

    - [翻译: 本研究深入探讨了自监督视觉变换器在深度伪造检测中的应用，并进行了一项全面的比较分析。](2024年05月01日/Exploring_Self-Supervised_Vision_Transformers_for_Deepfake_Detection_A_Comparative_Analysis.md)

- [Distillation Matters: Empowering Sequential Recommenders to Match the Performance of Large Language Model](2024年05月01日/Distillation_Matters_Empowering_Sequential_Recommenders_to_Match_the_Performance_of_Large_Language_Model.md)

    - [翻译: 蒸馏技术至关重要：它能够提升序列推荐系统的性能，使其达到大型语言模型的水平。](2024年05月01日/Distillation_Matters_Empowering_Sequential_Recommenders_to_Match_the_Performance_of_Large_Language_Model.md)

- [A Careful Examination of Large Language Model Performance on Grade School Arithmetic](2024年05月01日/A_Careful_Examination_of_Large_Language_Model_Performance_on_Grade_School_Arithmetic.md)

    - [翻译: 深入剖析大型语言模型在小学算术任务上的表现](2024年05月01日/A_Careful_Examination_of_Large_Language_Model_Performance_on_Grade_School_Arithmetic.md)

- [Integrating A.I. in Higher Education: Protocol for a Pilot Study with 'SAMCares: An Adaptive Learning Hub'](2024年05月01日/Integrating_A.I._in_Higher_Education_Protocol_for_a_Pilot_Study_with_'SAMCares_An_Adaptive_Learning_Hub'.md)

    - [翻译: 融入人工智能于高等教育：开展“SAMCares：自适应学习平台”试点研究的方案](2024年05月01日/Integrating_A.I._in_Higher_Education_Protocol_for_a_Pilot_Study_with_'SAMCares_An_Adaptive_Learning_Hub'.md)

- [DFKI-NLP at SemEval-2024 Task 2: Towards Robust LLMs Using Data Perturbations and MinMax Training](2024年05月01日/DFKI-NLP_at_SemEval-2024_Task_2_Towards_Robust_LLMs_Using_Data_Perturbations_and_MinMax_Training.md)

    - [翻译: DFKI-NLP 团队参与了 SemEval-2024 的第二项任务，旨在通过数据扰动和 MinMax 训练方法，推动构建更加稳健的大型语言模型。](2024年05月01日/DFKI-NLP_at_SemEval-2024_Task_2_Towards_Robust_LLMs_Using_Data_Perturbations_and_MinMax_Training.md)

- [Distance Sampling-based Paraphraser Leveraging ChatGPT for Text Data Manipulation](2024年05月01日/Distance_Sampling-based_Paraphraser_Leveraging_ChatGPT_for_Text_Data_Manipulation.md)

    - [翻译: 利用 ChatGPT 的距离抽样技术，打造文本数据的释义神器。](2024年05月01日/Distance_Sampling-based_Paraphraser_Leveraging_ChatGPT_for_Text_Data_Manipulation.md)

- [Context-Aware Clustering using Large Language Models](2024年05月01日/Context-Aware_Clustering_using_Large_Language_Models.md)

    - [翻译: 本文探讨了利用大型语言模型进行上下文感知聚类的方法。](2024年05月01日/Context-Aware_Clustering_using_Large_Language_Models.md)

- [LLM-AD: Large Language Model based Audio Description System](2024年05月01日/LLM-AD_Large_Language_Model_based_Audio_Description_System.md)

    - [翻译: LLM-AD：一种依托于先进大型语言模型的音频描述解决方案](2024年05月01日/LLM-AD_Large_Language_Model_based_Audio_Description_System.md)

- [On the Evaluation of Machine-Generated Reports](2024年05月01日/On_the_Evaluation_of_Machine-Generated_Reports.md)

    - [翻译: 机器生成报告评估研究](2024年05月01日/On_the_Evaluation_of_Machine-Generated_Reports.md)

- [Bayesian Optimization with LLM-Based Acquisition Functions for Natural Language Preference Elicitation](2024年05月01日/Bayesian_Optimization_with_LLM-Based_Acquisition_Functions_for_Natural_Language_Preference_Elicitation.md)

    - [翻译: 利用基于大型语言模型的贝叶斯优化及获取函数，进行自然语言偏好的探索与激发。](2024年05月01日/Bayesian_Optimization_with_LLM-Based_Acquisition_Functions_for_Natural_Language_Preference_Elicitation.md)

- [A Hong Kong Sign Language Corpus Collected from Sign-interpreted TV News](2024年05月01日/A_Hong_Kong_Sign_Language_Corpus_Collected_from_Sign-interpreted_TV_News.md)

    - [翻译: 香港手语语料库：源自电视手语新闻的采集](2024年05月01日/A_Hong_Kong_Sign_Language_Corpus_Collected_from_Sign-interpreted_TV_News.md)

- [CACTUS: Chemistry Agent Connecting Tool-Usage to Science](2024年05月01日/CACTUS_Chemistry_Agent_Connecting_Tool-Usage_to_Science.md)

    - [翻译: CACTUS：化学智能代理与科学工具的连接平台](2024年05月01日/CACTUS_Chemistry_Agent_Connecting_Tool-Usage_to_Science.md)

- [How Can I Get It Right? Using GPT to Rephrase Incorrect Trainee Responses](2024年05月01日/How_Can_I_Get_It_Right_Using_GPT_to_Rephrase_Incorrect_Trainee_Responses.md)

    - [翻译: 如何正确表达？利用 GPT 对实习生的不准确回答进行改写。](2024年05月01日/How_Can_I_Get_It_Right_Using_GPT_to_Rephrase_Incorrect_Trainee_Responses.md)

- [Efficient Compression of Multitask Multilingual Speech Models](2024年05月01日/Efficient_Compression_of_Multitask_Multilingual_Speech_Models.md)

    - [翻译: 本文介绍了一种高效的多任务多语言语音模型压缩技术，旨在优化模型的存储和计算效率。](2024年05月01日/Efficient_Compression_of_Multitask_Multilingual_Speech_Models.md)

- [The Role of Model Architecture and Scale in Predicting Molecular Properties: Insights from Fine-Tuning RoBERTa, BART, and LLaMA](2024年05月01日/The_Role_of_Model_Architecture_and_Scale_in_Predicting_Molecular_Properties_Insights_from_Fine-Tuning_RoBERTa,_BART,_and_LLaMA.md)

    - [翻译: 探讨模型架构和规模对于分子属性预测的影响：通过对 RoBERTa、BART 和 LLaMA 进行微调获得的深刻见解。](2024年05月01日/The_Role_of_Model_Architecture_and_Scale_in_Predicting_Molecular_Properties_Insights_from_Fine-Tuning_RoBERTa,_BART,_and_LLaMA.md)

- [LLaVA Finds Free Lunch: Teaching Human Behavior Improves Content Understanding Abilities Of LLMs](2024年05月01日/LLaVA_Finds_Free_Lunch_Teaching_Human_Behavior_Improves_Content_Understanding_Abilities_Of_LLMs.md)

    - [翻译: LLaVA 揭示了一个意外的收获：通过教授人类行为，我们能够显著提升大型语言模型对内容的理解力。](2024年05月01日/LLaVA_Finds_Free_Lunch_Teaching_Human_Behavior_Improves_Content_Understanding_Abilities_Of_LLMs.md)

- [Characterising the Creative Process in Humans and Large Language Models](2024年05月01日/Characterising_the_Creative_Process_in_Humans_and_Large_Language_Models.md)

    - [翻译: 探索人类与大型语言模型的创意生成过程](2024年05月01日/Characterising_the_Creative_Process_in_Humans_and_Large_Language_Models.md)

- [Beyond Human Vision: The Role of Large Vision Language Models in Microscope Image Analysis](2024年05月01日/Beyond_Human_Vision_The_Role_of_Large_Vision_Language_Models_in_Microscope_Image_Analysis.md)

    - [翻译: 超越人眼所见：大型视觉语言模型在显微图像分析领域的应用](2024年05月01日/Beyond_Human_Vision_The_Role_of_Large_Vision_Language_Models_in_Microscope_Image_Analysis.md)

- [Math Multiple Choice Question Generation via Human-Large Language Model Collaboration](2024年05月01日/Math_Multiple_Choice_Question_Generation_via_Human-Large_Language_Model_Collaboration.md)

    - [翻译: 携手人类与大型语言模型，共创数学多项选择题](2024年05月01日/Math_Multiple_Choice_Question_Generation_via_Human-Large_Language_Model_Collaboration.md)

- [Can a Hallucinating Model help in Reducing Human "Hallucination"?](2024年05月01日/Can_a_Hallucinating_Model_help_in_Reducing_Human_Hallucination.md)

    - [翻译: 幻觉模型能否助力减轻人类的幻觉现象？](2024年05月01日/Can_a_Hallucinating_Model_help_in_Reducing_Human_Hallucination.md)

- [WIBA: What Is Being Argued? A Comprehensive Approach to Argument Mining](2024年05月01日/WIBA_What_Is_Being_Argued_A_Comprehensive_Approach_to_Argument_Mining.md)

    - [翻译: WIBA：争论的是什么？一种全面深入的论点挖掘方法。](2024年05月01日/WIBA_What_Is_Being_Argued_A_Comprehensive_Approach_to_Argument_Mining.md)

- [Efficient and Responsible Adaptation of Large Language Models for Robust Top-k Recommendations](2024年05月01日/Efficient_and_Responsible_Adaptation_of_Large_Language_Models_for_Robust_Top-k_Recommendations.md)

    - [翻译: 为了提供鲁棒的 Top-k 推荐，我们需对大型语言模型进行既高效又负责任的调整。](2024年05月01日/Efficient_and_Responsible_Adaptation_of_Large_Language_Models_for_Robust_Top-k_Recommendations.md)

- ["Ask Me Anything": How Comcast Uses LLMs to Assist Agents in Real Time](2024年05月01日/Ask_Me_Anything_How_Comcast_Uses_LLMs_to_Assist_Agents_in_Real_Time.md)

    - [翻译: "有问必答"：探究 Comcast 如何利用大型语言模型 (LLMs) 为代理提供实时协助。](2024年05月01日/Ask_Me_Anything_How_Comcast_Uses_LLMs_to_Assist_Agents_in_Real_Time.md)