# 2024年05月

2024年05月02日

- [Plan-Seq-Learn: Language Model Guided RL for Solving Long Horizon Robotics Tasks](2024年05月02日/Plan-Seq-Learn_Language_Model_Guided_RL_for_Solving_Long_Horizon_Robotics_Tasks.md)

    - [翻译: Plan-Seq-Learn：一种由语言模型引导的强化学习方法，专为解决机器人领域的长期任务而设计。](2024年05月02日/Plan-Seq-Learn_Language_Model_Guided_RL_for_Solving_Long_Horizon_Robotics_Tasks.md)

- [OmniDrive: A Holistic LLM-Agent Framework for Autonomous Driving with 3D Perception, Reasoning and Planning](2024年05月02日/OmniDrive_A_Holistic_LLM-Agent_Framework_for_Autonomous_Driving_with_3D_Perception,_Reasoning_and_Planning.md)

    - [翻译: OmniDrive：一套综合性的LLM代理框架，专为自动驾驶设计，集成了3D感知、推理和规划功能。](2024年05月02日/OmniDrive_A_Holistic_LLM-Agent_Framework_for_Autonomous_Driving_with_3D_Perception,_Reasoning_and_Planning.md)

- [FLAME: Factuality-Aware Alignment for Large Language Models](2024年05月02日/FLAME_Factuality-Aware_Alignment_for_Large_Language_Models.md)

    - [翻译: FLAME：为大型语言模型打造的事实感知对齐技术](2024年05月02日/FLAME_Factuality-Aware_Alignment_for_Large_Language_Models.md)

- [Transformer-Aided Semantic Communications](2024年05月02日/Transformer-Aided_Semantic_Communications.md)

    - [翻译: 借助Transformer的语义通信技术](2024年05月02日/Transformer-Aided_Semantic_Communications.md)

- [Analyzing the Role of Semantic Representations in the Era of Large Language Models](2024年05月02日/Analyzing_the_Role_of_Semantic_Representations_in_the_Era_of_Large_Language_Models.md)

    - [翻译: 在大型语言模型盛行的当下，深入探讨语义表示的角色与重要性。](2024年05月02日/Analyzing_the_Role_of_Semantic_Representations_in_the_Era_of_Large_Language_Models.md)

- [Supporting Business Document Workflows via Collection-Centric Information Foraging with Large Language Models](2024年05月02日/Supporting_Business_Document_Workflows_via_Collection-Centric_Information_Foraging_with_Large_Language_Models.md)

    - [翻译: 利用大型语言模型，通过集中式信息搜集，助力商业文档工作流程的优化。](2024年05月02日/Supporting_Business_Document_Workflows_via_Collection-Centric_Information_Foraging_with_Large_Language_Models.md)

- [Controllable Text Generation in the Instruction-Tuning Era](2024年05月02日/Controllable_Text_Generation_in_the_Instruction-Tuning_Era.md)

    - [翻译: 在指令调整时代下的可控文本生成](2024年05月02日/Controllable_Text_Generation_in_the_Instruction-Tuning_Era.md)

- [MANTIS: Interleaved Multi-Image Instruction Tuning](2024年05月02日/MANTIS_Interleaved_Multi-Image_Instruction_Tuning.md)

    - [翻译: MANTIS：交错式多图像指令优化](2024年05月02日/MANTIS_Interleaved_Multi-Image_Instruction_Tuning.md)

- [NeMo-Aligner: Scalable Toolkit for Efficient Model Alignment](2024年05月02日/NeMo-Aligner_Scalable_Toolkit_for_Efficient_Model_Alignment.md)

    - [翻译: NeMo-Aligner：高效模型对齐的可扩展工具集](2024年05月02日/NeMo-Aligner_Scalable_Toolkit_for_Efficient_Model_Alignment.md)

- [V-FLUTE: Visual Figurative Language Understanding with Textual Explanations](2024年05月02日/V-FLUTE_Visual_Figurative_Language_Understanding_with_Textual_Explanations.md)

    - [翻译: V-FLUTE：图文结合，洞悉视觉比喻语言的深层含义](2024年05月02日/V-FLUTE_Visual_Figurative_Language_Understanding_with_Textual_Explanations.md)

- [A Systematic Literature Review on Large Language Models for Automated Program Repair](2024年05月02日/A_Systematic_Literature_Review_on_Large_Language_Models_for_Automated_Program_Repair.md)

    - [翻译: 本文系统性地回顾了用于自动化程序修复的大型语言模型的相关文献。](2024年05月02日/A_Systematic_Literature_Review_on_Large_Language_Models_for_Automated_Program_Repair.md)

- [UQA: Corpus for Urdu Question Answering](2024年05月02日/UQA_Corpus_for_Urdu_Question_Answering.md)

    - [翻译: UQA：乌尔都语问答语料库](2024年05月02日/UQA_Corpus_for_Urdu_Question_Answering.md)

- [Creative Problem Solving in Large Language and Vision Models -- What Would it Take?](2024年05月02日/Creative_Problem_Solving_in_Large_Language_and_Vision_Models_--_What_Would_it_Take.md)

    - [翻译: 探索大型语言与视觉模型中的创新性问题解决之道 -- 我们该如何应对这一挑战？](2024年05月02日/Creative_Problem_Solving_in_Large_Language_and_Vision_Models_--_What_Would_it_Take.md)

- [Natural Language to Verilog: Design of a Recurrent Spiking Neural Network using Large Language Models and ChatGPT](2024年05月02日/Natural_Language_to_Verilog_Design_of_a_Recurrent_Spiking_Neural_Network_using_Large_Language_Models_and_ChatGPT.md)

    - [翻译: 将自然语言转换为 Verilog 代码：我们利用大型语言模型和 ChatGPT，设计了一种递归脉冲神经网络。](2024年05月02日/Natural_Language_to_Verilog_Design_of_a_Recurrent_Spiking_Neural_Network_using_Large_Language_Models_and_ChatGPT.md)

- [MiniGPT-3D: Efficiently Aligning 3D Point Clouds with Large Language Models using 2D Priors](2024年05月02日/MiniGPT-3D_Efficiently_Aligning_3D_Point_Clouds_with_Large_Language_Models_using_2D_Priors.md)

    - [翻译: MiniGPT-3D：借助2D先验，高效实现3D点云与大型语言模型的精准对齐。](2024年05月02日/MiniGPT-3D_Efficiently_Aligning_3D_Point_Clouds_with_Large_Language_Models_using_2D_Priors.md)

- [Verification and Refinement of Natural Language Explanations through LLM-Symbolic Theorem Proving](2024年05月02日/Verification_and_Refinement_of_Natural_Language_Explanations_through_LLM-Symbolic_Theorem_Proving.md)

    - [翻译: 利用大型语言模型（LLM）中的符号定理证明技术，对自然语言解释进行验证与优化。](2024年05月02日/Verification_and_Refinement_of_Natural_Language_Explanations_through_LLM-Symbolic_Theorem_Proving.md)

- [GAIA: A General AI Assistant for Intelligent Accelerator Operations](2024年05月02日/GAIA_A_General_AI_Assistant_for_Intelligent_Accelerator_Operations.md)

    - [翻译: GAIA：一款为智能化加速器运营提供助力的全能AI助手。](2024年05月02日/GAIA_A_General_AI_Assistant_for_Intelligent_Accelerator_Operations.md)

- [Human-Robot Interaction Conversational User Enjoyment Scale (HRI CUES)](2024年05月02日/Human-Robot_Interaction_Conversational_User_Enjoyment_Scale_(HRI_CUES).md)

    - [翻译: 人机互动对话用户愉悦度量表（HRI CUES）](2024年05月02日/Human-Robot_Interaction_Conversational_User_Enjoyment_Scale_(HRI_CUES).md)

- [The Power of Question Translation Training in Multilingual Reasoning: Broadened Scope and Deepened Insights](2024年05月02日/The_Power_of_Question_Translation_Training_in_Multilingual_Reasoning_Broadened_Scope_and_Deepened_Insights.md)

    - [翻译: 通过问题翻译训练提升多语言推理能力：拓展研究视野，深化理解深度。](2024年05月02日/The_Power_of_Question_Translation_Training_in_Multilingual_Reasoning_Broadened_Scope_and_Deepened_Insights.md)

- [Overcoming LLM Challenges using RAG-Driven Precision in Coffee Leaf Disease Remediation](2024年05月02日/Overcoming_LLM_Challenges_using_RAG-Driven_Precision_in_Coffee_Leaf_Disease_Remediation.md)

    - [翻译: 利用 RAG（Retrieval-Augmented Generation）技术提高精确度，有效应对大型语言模型在咖啡叶病害治理中的难题。](2024年05月02日/Overcoming_LLM_Challenges_using_RAG-Driven_Precision_in_Coffee_Leaf_Disease_Remediation.md)

- [The Effectiveness of LLMs as Annotators: A Comparative Overview and Empirical Analysis of Direct Representation](2024年05月02日/The_Effectiveness_of_LLMs_as_Annotators_A_Comparative_Overview_and_Empirical_Analysis_of_Direct_Representation.md)

    - [翻译: 探究大型语言模型作为注释工具的效能：一篇关于直接表征方法的对比概览与实证研究分析](2024年05月02日/The_Effectiveness_of_LLMs_as_Annotators_A_Comparative_Overview_and_Empirical_Analysis_of_Direct_Representation.md)

- [Reinforcement Learning for Edit-Based Non-Autoregressive Neural Machine Translation](2024年05月02日/Reinforcement_Learning_for_Edit-Based_Non-Autoregressive_Neural_Machine_Translation.md)

    - [翻译: 强化学习在基于编辑的非自回归神经机器翻译中的应用](2024年05月02日/Reinforcement_Learning_for_Edit-Based_Non-Autoregressive_Neural_Machine_Translation.md)

- [Prompt engineering paradigms for medical applications: scoping review and recommendations for better practices](2024年05月02日/Prompt_engineering_paradigms_for_medical_applications_scoping_review_and_recommendations_for_better_practices.md)

    - [翻译: 医疗领域提示工程的范式：全面审视与提升实践的建言](2024年05月02日/Prompt_engineering_paradigms_for_medical_applications_scoping_review_and_recommendations_for_better_practices.md)

- [Boosting Jailbreak Attack with Momentum](2024年05月02日/Boosting_Jailbreak_Attack_with_Momentum.md)

    - [翻译: 借助动量效应，提升越狱攻击的威力](2024年05月02日/Boosting_Jailbreak_Attack_with_Momentum.md)

- [DLAP: A Deep Learning Augmented Large Language Model Prompting Framework for Software Vulnerability Detection](2024年05月02日/DLAP_A_Deep_Learning_Augmented_Large_Language_Model_Prompting_Framework_for_Software_Vulnerability_Detection.md)

    - [翻译: DLAP：深度学习助力的大型语言模型提示框架，专为软件漏洞检测而设计。](2024年05月02日/DLAP_A_Deep_Learning_Augmented_Large_Language_Model_Prompting_Framework_for_Software_Vulnerability_Detection.md)

- [Generative Relevance Feedback and Convergence of Adaptive Re-Ranking: University of Glasgow Terrier Team at TREC DL 2023](2024年05月02日/Generative_Relevance_Feedback_and_Convergence_of_Adaptive_Re-Ranking_University_of_Glasgow_Terrier_Team_at_TREC_DL_2023.md)

    - [翻译: 格拉斯哥大学的特里尔团队在2023年TREC DL竞赛中展示了他们在生成式相关反馈和自适应重排序技术方面的成果，这些技术在信息检索任务中实现了显著的收敛效果。](2024年05月02日/Generative_Relevance_Feedback_and_Convergence_of_Adaptive_Re-Ranking_University_of_Glasgow_Terrier_Team_at_TREC_DL_2023.md)

- [Efficient Data Generation for Source-grounded Information-seeking Dialogs: A Use Case for Meeting Transcripts](2024年05月02日/Efficient_Data_Generation_for_Source-grounded_Information-seeking_Dialogs_A_Use_Case_for_Meeting_Transcripts.md)

    - [翻译: 高效数据生成：以会议记录为信息寻求型源-地面对话的用例](2024年05月02日/Efficient_Data_Generation_for_Source-grounded_Information-seeking_Dialogs_A_Use_Case_for_Meeting_Transcripts.md)

- ["In-Context Learning" or: How I learned to stop worrying and love "Applied Information Retrieval"](2024年05月02日/In-Context_Learning_or_How_I_learned_to_stop_worrying_and_love_Applied_Information_Retrieval.md)

    - [翻译: 《上下文学习》：我如何学会不再担忧并拥抱“应用信息检索”的世界](2024年05月02日/In-Context_Learning_or_How_I_learned_to_stop_worrying_and_love_Applied_Information_Retrieval.md)

- [LLM Security Guard for Code](2024年05月02日/LLM_Security_Guard_for_Code.md)

    - [翻译: 大型语言模型的安全守护者：代码防护](2024年05月02日/LLM_Security_Guard_for_Code.md)

- [Learning Object States from Actions via Large Language Models](2024年05月02日/Learning_Object_States_from_Actions_via_Large_Language_Models.md)

    - [翻译: 利用大型语言模型从动作中学习对象状态。](2024年05月02日/Learning_Object_States_from_Actions_via_Large_Language_Models.md)

- [Generating User Experience Based on Personas with AI Assistants](2024年05月02日/Generating_User_Experience_Based_on_Personas_with_AI_Assistants.md)

    - [翻译: 利用人工智能助手，根据人物角色创造用户体验](2024年05月02日/Generating_User_Experience_Based_on_Personas_with_AI_Assistants.md)

2024年05月01日

- [Is Bigger Edit Batch Size Always Better? -- An Empirical Study on Model Editing with Llama-3](2024年05月01日/Is_Bigger_Edit_Batch_Size_Always_Better_--_An_Empirical_Study_on_Model_Editing_with_Llama-3.md)

    - [翻译: 编辑批量大小越大，效果一定越佳吗？一项基于 Llama-3 模型编辑的实证探索。](2024年05月01日/Is_Bigger_Edit_Batch_Size_Always_Better_--_An_Empirical_Study_on_Model_Editing_with_Llama-3.md)

- [HalluVault: A Novel Logic Programming-aided Metamorphic Testing Framework for Detecting Fact-Conflicting Hallucinations in Large Language Models](2024年05月01日/HalluVault_A_Novel_Logic_Programming-aided_Metamorphic_Testing_Framework_for_Detecting_Fact-Conflicting_Hallucinations_in_Large_Language_Models.md)

    - [翻译: HalluVault：一个创新的基于逻辑编程的变异测试框架，专为发现大型语言模型中与事实相悖的幻觉现象而设计。](2024年05月01日/HalluVault_A_Novel_Logic_Programming-aided_Metamorphic_Testing_Framework_for_Detecting_Fact-Conflicting_Hallucinations_in_Large_Language_Models.md)

- [When Quantization Affects Confidence of Large Language Models?](2024年05月01日/When_Quantization_Affects_Confidence_of_Large_Language_Models.md)

    - [翻译: 量化如何影响大型语言模型的置信度？](2024年05月01日/When_Quantization_Affects_Confidence_of_Large_Language_Models.md)

- ["I'm Not Sure, But...": Examining the Impact of Large Language Models' Uncertainty Expression on User Reliance and Trust](2024年05月01日/I'm_Not_Sure,_But..._Examining_the_Impact_of_Large_Language_Models'_Uncertainty_Expression_on_User_Reliance_and_Trust.md)

    - [翻译: 《“我不确定，但是...”：探究大型语言模型不确定性表述对用户信赖与依赖的影响》](2024年05月01日/I'm_Not_Sure,_But..._Examining_the_Impact_of_Large_Language_Models'_Uncertainty_Expression_on_User_Reliance_and_Trust.md)

- [Addressing Topic Granularity and Hallucination in Large Language Models for Topic Modelling](2024年05月01日/Addressing_Topic_Granularity_and_Hallucination_in_Large_Language_Models_for_Topic_Modelling.md)

    - [翻译: 探讨大型语言模型在主题建模中的主题粒度细化与幻觉现象](2024年05月01日/Addressing_Topic_Granularity_and_Hallucination_in_Large_Language_Models_for_Topic_Modelling.md)

- [Investigating Automatic Scoring and Feedback using Large Language Models](2024年05月01日/Investigating_Automatic_Scoring_and_Feedback_using_Large_Language_Models.md)

    - [翻译: 探究基于大型语言模型的自动评分与反馈机制](2024年05月01日/Investigating_Automatic_Scoring_and_Feedback_using_Large_Language_Models.md)

- [Are Models Biased on Text without Gender-related Language?](2024年05月01日/Are_Models_Biased_on_Text_without_Gender-related_Language.md)

    - [翻译: 文本中若未涉及性别相关词汇，模型是否会表现出偏见？](2024年05月01日/Are_Models_Biased_on_Text_without_Gender-related_Language.md)

- [The Real, the Better: Aligning Large Language Models with Online Human Behaviors](2024年05月01日/The_Real,_the_Better_Aligning_Large_Language_Models_with_Online_Human_Behaviors.md)

    - [翻译: 追求真实，更上一层楼：使大型语言模型与网民在线行为同步。](2024年05月01日/The_Real,_the_Better_Aligning_Large_Language_Models_with_Online_Human_Behaviors.md)

- [EALD-MLLM: Emotion Analysis in Long-sequential and De-identity videos with Multi-modal Large Language Model](2024年05月01日/EALD-MLLM_Emotion_Analysis_in_Long-sequential_and_De-identity_videos_with_Multi-modal_Large_Language_Model.md)

    - [翻译: EALD-MLLM：利用多模态大型语言模型对长序列及去身份视频进行情感分析。](2024年05月01日/EALD-MLLM_Emotion_Analysis_in_Long-sequential_and_De-identity_videos_with_Multi-modal_Large_Language_Model.md)

- [NumLLM: Numeric-Sensitive Large Language Model for Chinese Finance](2024年05月01日/NumLLM_Numeric-Sensitive_Large_Language_Model_for_Chinese_Finance.md)

    - [翻译: NumLLM：一款专为中文金融领域设计的、对数值高度敏感的大型语言模型。](2024年05月01日/NumLLM_Numeric-Sensitive_Large_Language_Model_for_Chinese_Finance.md)

- [Mixture of insighTful Experts (MoTE): The Synergy of Thought Chains and Expert Mixtures in Self-Alignment](2024年05月01日/Mixture_of_insighTful_Experts_(MoTE)_The_Synergy_of_Thought_Chains_and_Expert_Mixtures_in_Self-Alignment.md)

    - [翻译: 洞察力专家混合体（MoTE）：在自我对齐的过程中，思维链与专家组合的相互促进。](2024年05月01日/Mixture_of_insighTful_Experts_(MoTE)_The_Synergy_of_Thought_Chains_and_Expert_Mixtures_in_Self-Alignment.md)

- [Long-Term Human Trajectory Prediction using 3D Dynamic Scene Graphs](2024年05月01日/Long-Term_Human_Trajectory_Prediction_using_3D_Dynamic_Scene_Graphs.md)

    - [翻译: 通过 3D 动态场景图实现对人类长期轨迹的精准预测。](2024年05月01日/Long-Term_Human_Trajectory_Prediction_using_3D_Dynamic_Scene_Graphs.md)

- [A Legal Framework for Natural Language Processing Model Training in Portugal](2024年05月01日/A_Legal_Framework_for_Natural_Language_Processing_Model_Training_in_Portugal.md)

    - [翻译: 葡萄牙建立了一个针对自然语言处理（NLP）模型训练的法律框架。](2024年05月01日/A_Legal_Framework_for_Natural_Language_Processing_Model_Training_in_Portugal.md)

- [ChatBI: Towards Natural Language to Complex Business Intelligence SQL](2024年05月01日/ChatBI_Towards_Natural_Language_to_Complex_Business_Intelligence_SQL.md)

    - [翻译: ChatBI：探索将自然语言转换为复杂的商业智能SQL语句的路径](2024年05月01日/ChatBI_Towards_Natural_Language_to_Complex_Business_Intelligence_SQL.md)

- [Navigating WebAI: Training Agents to Complete Web Tasks with Large Language Models and Reinforcement Learning](2024年05月01日/Navigating_WebAI_Training_Agents_to_Complete_Web_Tasks_with_Large_Language_Models_and_Reinforcement_Learning.md)

    - [翻译: 探索 WebAI：通过大型语言模型和强化学习训练代理来完成网络任务。](2024年05月01日/Navigating_WebAI_Training_Agents_to_Complete_Web_Tasks_with_Large_Language_Models_and_Reinforcement_Learning.md)

- [GOLD: Geometry Problem Solver with Natural Language Description](2024年05月01日/GOLD_Geometry_Problem_Solver_with_Natural_Language_Description.md)

    - [翻译: GOLD：一款能够理解自然语言描述来解决几何问题的智能求解器。](2024年05月01日/GOLD_Geometry_Problem_Solver_with_Natural_Language_Description.md)

- [Is Temperature the Creativity Parameter of Large Language Models?](2024年05月01日/Is_Temperature_the_Creativity_Parameter_of_Large_Language_Models.md)

    - [翻译: 温度是否决定了大型语言模型的创造力？](2024年05月01日/Is_Temperature_the_Creativity_Parameter_of_Large_Language_Models.md)

- [Explainable Automatic Grading with Neural Additive Models](2024年05月01日/Explainable_Automatic_Grading_with_Neural_Additive_Models.md)

    - [翻译: 神经加性模型在自动评分中的应用，实现了评分过程的可解释性。](2024年05月01日/Explainable_Automatic_Grading_with_Neural_Additive_Models.md)

- [The Pyramid of Captions](2024年05月01日/The_Pyramid_of_Captions.md)

    - [翻译: 标题层级金字塔](2024年05月01日/The_Pyramid_of_Captions.md)

- [BiomedRAG: A Retrieval Augmented Large Language Model for Biomedicine](2024年05月01日/BiomedRAG_A_Retrieval_Augmented_Large_Language_Model_for_Biomedicine.md)

    - [翻译: BiomedRAG：一种为生物医学领域设计的、结合了检索功能的先进大型语言模型。](2024年05月01日/BiomedRAG_A_Retrieval_Augmented_Large_Language_Model_for_Biomedicine.md)

- [Enhancing Surgical Robots with Embodied Intelligence for Autonomous Ultrasound Scanning](2024年05月01日/Enhancing_Surgical_Robots_with_Embodied_Intelligence_for_Autonomous_Ultrasound_Scanning.md)

    - [翻译: 为手术机器人注入体现智能，提升其进行自主超声扫描的性能。](2024年05月01日/Enhancing_Surgical_Robots_with_Embodied_Intelligence_for_Autonomous_Ultrasound_Scanning.md)

- [Monte Carlo Tree Search Boosts Reasoning via Iterative Preference Learning](2024年05月01日/Monte_Carlo_Tree_Search_Boosts_Reasoning_via_Iterative_Preference_Learning.md)

    - [翻译: 蒙特卡洛树搜索（MCTS）通过不断迭代的偏好学习，显著提升了推理能力。](2024年05月01日/Monte_Carlo_Tree_Search_Boosts_Reasoning_via_Iterative_Preference_Learning.md)

- [RAG-based Explainable Prediction of Road Users Behaviors for Automated Driving using Knowledge Graphs and Large Language Models](2024年05月01日/RAG-based_Explainable_Prediction_of_Road_Users_Behaviors_for_Automated_Driving_using_Knowledge_Graphs_and_Large_Language_Models.md)

    - [翻译: 利用知识图谱和大型语言模型，基于 RAG（Retrieval-Augmented Generation）框架，对自动驾驶中道路使用者的行为进行可解释预测。](2024年05月01日/RAG-based_Explainable_Prediction_of_Road_Users_Behaviors_for_Automated_Driving_using_Knowledge_Graphs_and_Large_Language_Models.md)

- [CultiVerse: Towards Cross-Cultural Understanding for Paintings with Large Language Model](2024年05月01日/CultiVerse_Towards_Cross-Cultural_Understanding_for_Paintings_with_Large_Language_Model.md)

    - [翻译: CultiVerse：迈向利用大型语言模型深化对绘画艺术的跨文化洞察。](2024年05月01日/CultiVerse_Towards_Cross-Cultural_Understanding_for_Paintings_with_Large_Language_Model.md)

- [Self-Refine Instruction-Tuning for Aligning Reasoning in Language Models](2024年05月01日/Self-Refine_Instruction-Tuning_for_Aligning_Reasoning_in_Language_Models.md)

    - [翻译: 自我精炼的指令调优：优化语言模型中的推理对齐。](2024年05月01日/Self-Refine_Instruction-Tuning_for_Aligning_Reasoning_in_Language_Models.md)

- [Inferring State Machine from the Protocol Implementation via Large Langeuage Model](2024年05月01日/Inferring_State_Machine_from_the_Protocol_Implementation_via_Large_Langeuage_Model.md)

    - [翻译: 利用大型语言模型，从协议实现中推导出状态机。](2024年05月01日/Inferring_State_Machine_from_the_Protocol_Implementation_via_Large_Langeuage_Model.md)

- [CofiPara: A Coarse-to-fine Paradigm for Multimodal Sarcasm Target Identification with Large Multimodal Models](2024年05月01日/CofiPara_A_Coarse-to-fine_Paradigm_for_Multimodal_Sarcasm_Target_Identification_with_Large_Multimodal_Models.md)

    - [翻译: CofiPara：一种从粗略到精细的多模态讽刺目标识别方法，适用于大型多模态模型。](2024年05月01日/CofiPara_A_Coarse-to-fine_Paradigm_for_Multimodal_Sarcasm_Target_Identification_with_Large_Multimodal_Models.md)

- [AdaMoLE: Fine-Tuning Large Language Models with Adaptive Mixture of Low-Rank Adaptation Experts](2024年05月01日/AdaMoLE_Fine-Tuning_Large_Language_Models_with_Adaptive_Mixture_of_Low-Rank_Adaptation_Experts.md)

    - [翻译: AdaMoLE：以自适应低秩专家混合策略，对大型语言模型进行精准微调。](2024年05月01日/AdaMoLE_Fine-Tuning_Large_Language_Models_with_Adaptive_Mixture_of_Low-Rank_Adaptation_Experts.md)

- [Exploring Self-Supervised Vision Transformers for Deepfake Detection: A Comparative Analysis](2024年05月01日/Exploring_Self-Supervised_Vision_Transformers_for_Deepfake_Detection_A_Comparative_Analysis.md)

    - [翻译: 本研究深入探讨了自监督视觉变换器在深度伪造检测中的应用，并进行了一项全面的比较分析。](2024年05月01日/Exploring_Self-Supervised_Vision_Transformers_for_Deepfake_Detection_A_Comparative_Analysis.md)

- [Distillation Matters: Empowering Sequential Recommenders to Match the Performance of Large Language Model](2024年05月01日/Distillation_Matters_Empowering_Sequential_Recommenders_to_Match_the_Performance_of_Large_Language_Model.md)

    - [翻译: 蒸馏技术至关重要：它能够提升序列推荐系统的性能，使其达到大型语言模型的水平。](2024年05月01日/Distillation_Matters_Empowering_Sequential_Recommenders_to_Match_the_Performance_of_Large_Language_Model.md)

- [A Careful Examination of Large Language Model Performance on Grade School Arithmetic](2024年05月01日/A_Careful_Examination_of_Large_Language_Model_Performance_on_Grade_School_Arithmetic.md)

    - [翻译: 深入剖析大型语言模型在小学算术任务上的表现](2024年05月01日/A_Careful_Examination_of_Large_Language_Model_Performance_on_Grade_School_Arithmetic.md)

- [Integrating A.I. in Higher Education: Protocol for a Pilot Study with 'SAMCares: An Adaptive Learning Hub'](2024年05月01日/Integrating_A.I._in_Higher_Education_Protocol_for_a_Pilot_Study_with_'SAMCares_An_Adaptive_Learning_Hub'.md)

    - [翻译: 融入人工智能于高等教育：开展“SAMCares：自适应学习平台”试点研究的方案](2024年05月01日/Integrating_A.I._in_Higher_Education_Protocol_for_a_Pilot_Study_with_'SAMCares_An_Adaptive_Learning_Hub'.md)

- [DFKI-NLP at SemEval-2024 Task 2: Towards Robust LLMs Using Data Perturbations and MinMax Training](2024年05月01日/DFKI-NLP_at_SemEval-2024_Task_2_Towards_Robust_LLMs_Using_Data_Perturbations_and_MinMax_Training.md)

    - [翻译: DFKI-NLP 团队参与了 SemEval-2024 的第二项任务，旨在通过数据扰动和 MinMax 训练方法，推动构建更加稳健的大型语言模型。](2024年05月01日/DFKI-NLP_at_SemEval-2024_Task_2_Towards_Robust_LLMs_Using_Data_Perturbations_and_MinMax_Training.md)

- [Distance Sampling-based Paraphraser Leveraging ChatGPT for Text Data Manipulation](2024年05月01日/Distance_Sampling-based_Paraphraser_Leveraging_ChatGPT_for_Text_Data_Manipulation.md)

    - [翻译: 利用 ChatGPT 的距离抽样技术，打造文本数据的释义神器。](2024年05月01日/Distance_Sampling-based_Paraphraser_Leveraging_ChatGPT_for_Text_Data_Manipulation.md)

- [Context-Aware Clustering using Large Language Models](2024年05月01日/Context-Aware_Clustering_using_Large_Language_Models.md)

    - [翻译: 本文探讨了利用大型语言模型进行上下文感知聚类的方法。](2024年05月01日/Context-Aware_Clustering_using_Large_Language_Models.md)

- [LLM-AD: Large Language Model based Audio Description System](2024年05月01日/LLM-AD_Large_Language_Model_based_Audio_Description_System.md)

    - [翻译: LLM-AD：一种依托于先进大型语言模型的音频描述解决方案](2024年05月01日/LLM-AD_Large_Language_Model_based_Audio_Description_System.md)

- [On the Evaluation of Machine-Generated Reports](2024年05月01日/On_the_Evaluation_of_Machine-Generated_Reports.md)

    - [翻译: 机器生成报告评估研究](2024年05月01日/On_the_Evaluation_of_Machine-Generated_Reports.md)

- [Bayesian Optimization with LLM-Based Acquisition Functions for Natural Language Preference Elicitation](2024年05月01日/Bayesian_Optimization_with_LLM-Based_Acquisition_Functions_for_Natural_Language_Preference_Elicitation.md)

    - [翻译: 利用基于大型语言模型的贝叶斯优化及获取函数，进行自然语言偏好的探索与激发。](2024年05月01日/Bayesian_Optimization_with_LLM-Based_Acquisition_Functions_for_Natural_Language_Preference_Elicitation.md)

- [A Hong Kong Sign Language Corpus Collected from Sign-interpreted TV News](2024年05月01日/A_Hong_Kong_Sign_Language_Corpus_Collected_from_Sign-interpreted_TV_News.md)

    - [翻译: 香港手语语料库：源自电视手语新闻的采集](2024年05月01日/A_Hong_Kong_Sign_Language_Corpus_Collected_from_Sign-interpreted_TV_News.md)

- [CACTUS: Chemistry Agent Connecting Tool-Usage to Science](2024年05月01日/CACTUS_Chemistry_Agent_Connecting_Tool-Usage_to_Science.md)

    - [翻译: CACTUS：化学智能代理与科学工具的连接平台](2024年05月01日/CACTUS_Chemistry_Agent_Connecting_Tool-Usage_to_Science.md)

- [How Can I Get It Right? Using GPT to Rephrase Incorrect Trainee Responses](2024年05月01日/How_Can_I_Get_It_Right_Using_GPT_to_Rephrase_Incorrect_Trainee_Responses.md)

    - [翻译: 如何正确表达？利用 GPT 对实习生的不准确回答进行改写。](2024年05月01日/How_Can_I_Get_It_Right_Using_GPT_to_Rephrase_Incorrect_Trainee_Responses.md)

- [Efficient Compression of Multitask Multilingual Speech Models](2024年05月01日/Efficient_Compression_of_Multitask_Multilingual_Speech_Models.md)

    - [翻译: 本文介绍了一种高效的多任务多语言语音模型压缩技术，旨在优化模型的存储和计算效率。](2024年05月01日/Efficient_Compression_of_Multitask_Multilingual_Speech_Models.md)

- [The Role of Model Architecture and Scale in Predicting Molecular Properties: Insights from Fine-Tuning RoBERTa, BART, and LLaMA](2024年05月01日/The_Role_of_Model_Architecture_and_Scale_in_Predicting_Molecular_Properties_Insights_from_Fine-Tuning_RoBERTa,_BART,_and_LLaMA.md)

    - [翻译: 探讨模型架构和规模对于分子属性预测的影响：通过对 RoBERTa、BART 和 LLaMA 进行微调获得的深刻见解。](2024年05月01日/The_Role_of_Model_Architecture_and_Scale_in_Predicting_Molecular_Properties_Insights_from_Fine-Tuning_RoBERTa,_BART,_and_LLaMA.md)

- [LLaVA Finds Free Lunch: Teaching Human Behavior Improves Content Understanding Abilities Of LLMs](2024年05月01日/LLaVA_Finds_Free_Lunch_Teaching_Human_Behavior_Improves_Content_Understanding_Abilities_Of_LLMs.md)

    - [翻译: LLaVA 揭示了一个意外的收获：通过教授人类行为，我们能够显著提升大型语言模型对内容的理解力。](2024年05月01日/LLaVA_Finds_Free_Lunch_Teaching_Human_Behavior_Improves_Content_Understanding_Abilities_Of_LLMs.md)

- [Characterising the Creative Process in Humans and Large Language Models](2024年05月01日/Characterising_the_Creative_Process_in_Humans_and_Large_Language_Models.md)

    - [翻译: 探索人类与大型语言模型的创意生成过程](2024年05月01日/Characterising_the_Creative_Process_in_Humans_and_Large_Language_Models.md)

- [Beyond Human Vision: The Role of Large Vision Language Models in Microscope Image Analysis](2024年05月01日/Beyond_Human_Vision_The_Role_of_Large_Vision_Language_Models_in_Microscope_Image_Analysis.md)

    - [翻译: 超越人眼所见：大型视觉语言模型在显微图像分析领域的应用](2024年05月01日/Beyond_Human_Vision_The_Role_of_Large_Vision_Language_Models_in_Microscope_Image_Analysis.md)

- [Math Multiple Choice Question Generation via Human-Large Language Model Collaboration](2024年05月01日/Math_Multiple_Choice_Question_Generation_via_Human-Large_Language_Model_Collaboration.md)

    - [翻译: 携手人类与大型语言模型，共创数学多项选择题](2024年05月01日/Math_Multiple_Choice_Question_Generation_via_Human-Large_Language_Model_Collaboration.md)

- [Can a Hallucinating Model help in Reducing Human "Hallucination"?](2024年05月01日/Can_a_Hallucinating_Model_help_in_Reducing_Human_Hallucination.md)

    - [翻译: 幻觉模型能否助力减轻人类的幻觉现象？](2024年05月01日/Can_a_Hallucinating_Model_help_in_Reducing_Human_Hallucination.md)

- [WIBA: What Is Being Argued? A Comprehensive Approach to Argument Mining](2024年05月01日/WIBA_What_Is_Being_Argued_A_Comprehensive_Approach_to_Argument_Mining.md)

    - [翻译: WIBA：争论的是什么？一种全面深入的论点挖掘方法。](2024年05月01日/WIBA_What_Is_Being_Argued_A_Comprehensive_Approach_to_Argument_Mining.md)

- [Efficient and Responsible Adaptation of Large Language Models for Robust Top-k Recommendations](2024年05月01日/Efficient_and_Responsible_Adaptation_of_Large_Language_Models_for_Robust_Top-k_Recommendations.md)

    - [翻译: 为了提供鲁棒的 Top-k 推荐，我们需对大型语言模型进行既高效又负责任的调整。](2024年05月01日/Efficient_and_Responsible_Adaptation_of_Large_Language_Models_for_Robust_Top-k_Recommendations.md)

- ["Ask Me Anything": How Comcast Uses LLMs to Assist Agents in Real Time](2024年05月01日/Ask_Me_Anything_How_Comcast_Uses_LLMs_to_Assist_Agents_in_Real_Time.md)

    - [翻译: "有问必答"：探究 Comcast 如何利用大型语言模型 (LLMs) 为代理提供实时协助。](2024年05月01日/Ask_Me_Anything_How_Comcast_Uses_LLMs_to_Assist_Agents_in_Real_Time.md)