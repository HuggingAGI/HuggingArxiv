# 2024年05月

2024年05月13日

- [Prompt-based Code Completion via Multi-Retrieval Augmented Generation](2024年05月13日/Prompt-based_Code_Completion_via_Multi-Retrieval_Augmented_Generation.md)

    - [翻译: 基于提示的多重检索增强生成实现代码补全](2024年05月13日/Prompt-based_Code_Completion_via_Multi-Retrieval_Augmented_Generation.md)

- [MS MARCO Web Search: a Large-scale Information-rich Web Dataset with Millions of Real Click Labels](2024年05月13日/MS_MARCO_Web_Search_a_Large-scale_Information-rich_Web_Dataset_with_Millions_of_Real_Click_Labels.md)

    - [翻译: MS MARCO网络搜索：一个汇聚数百万真实用户点击数据的大规模网络信息宝库在](2024年05月13日/MS_MARCO_Web_Search_a_Large-scale_Information-rich_Web_Dataset_with_Millions_of_Real_Click_Labels.md)

- [SambaNova SN40L: Scaling the AI Memory Wall with Dataflow and Composition of Experts](2024年05月13日/SambaNova_SN40L_Scaling_the_AI_Memory_Wall_with_Dataflow_and_Composition_of_Experts.md)

    - [翻译: SambaNova SN40L：以数据流与专家组合之力，突破AI内存壁垒](2024年05月13日/SambaNova_SN40L_Scaling_the_AI_Memory_Wall_with_Dataflow_and_Composition_of_Experts.md)

- [Fine-tuning the SwissBERT Encoder Model for Embedding Sentences and Documents](2024年05月13日/Fine-tuning_the_SwissBERT_Encoder_Model_for_Embedding_Sentences_and_Documents.md)

    - [翻译: 优化瑞士BERT模型，精炼句与文嵌入之艺](2024年05月13日/Fine-tuning_the_SwissBERT_Encoder_Model_for_Embedding_Sentences_and_Documents.md)

- [PromptLink: Leveraging Large Language Models for Cross-Source Biomedical Concept Linking](2024年05月13日/PromptLink_Leveraging_Large_Language_Models_for_Cross-Source_Biomedical_Concept_Linking.md)

    - [翻译: PromptLink：借助大型语言模型实现跨源生物医学概念的精准链接](2024年05月13日/PromptLink_Leveraging_Large_Language_Models_for_Cross-Source_Biomedical_Concept_Linking.md)

- [Oedipus: LLM-enchanced Reasoning CAPTCHA Solver](2024年05月13日/Oedipus_LLM-enchanced_Reasoning_CAPTCHA_Solver.md)

    - [翻译: 俄狄浦斯：大型语言模型加持的推理验证码破解者](2024年05月13日/Oedipus_LLM-enchanced_Reasoning_CAPTCHA_Solver.md)

- [MacBehaviour: An R package for behavioural experimentation on large language models](2024年05月13日/MacBehaviour_An_R_package_for_behavioural_experimentation_on_large_language_models.md)

    - [翻译: MacBehaviour：专为大型语言模型行为实验设计的R包，旨在深入探索语言模型的行为模式与实验应用。](2024年05月13日/MacBehaviour_An_R_package_for_behavioural_experimentation_on_large_language_models.md)

- [Strategic Data Ordering: Enhancing Large Language Model Performance through Curriculum Learning](2024年05月13日/Strategic_Data_Ordering_Enhancing_Large_Language_Model_Performance_through_Curriculum_Learning.md)

    - [翻译: 策略性数据排序：借助课程学习提升大型语言模型的效能在这项研究中，我们探讨了通过精心设计的数据排序策略，即课程学习，来增强大型语言模型性能的方法。课程学习是一种模仿人类教育过程的机器学习方法，它通过逐步增加任务难度来训练模型，从而使模型能够更有效地学习复杂的概念。我们的研究结果表明，合理安排数据顺序可以显著提高模型在各种语言任务中的表现，为优化大型语言模型的训练提供了新的视角。](2024年05月13日/Strategic_Data_Ordering_Enhancing_Large_Language_Model_Performance_through_Curriculum_Learning.md)

- [Integrating Intent Understanding and Optimal Behavior Planning for Behavior Tree Generation from Human Instructions](2024年05月13日/Integrating_Intent_Understanding_and_Optimal_Behavior_Planning_for_Behavior_Tree_Generation_from_Human_Instructions.md)

    - [翻译: 融合意图洞察与行为规划，精妙演绎人类指令至行为树之生成](2024年05月13日/Integrating_Intent_Understanding_and_Optimal_Behavior_Planning_for_Behavior_Tree_Generation_from_Human_Instructions.md)

- [Evaluating large language models in medical applications: a survey](2024年05月13日/Evaluating_large_language_models_in_medical_applications_a_survey.md)

    - [翻译: 大型语言模型在医疗领域的应用评估：一份综述在这份综述中，我们将探讨大型语言模型在医疗领域中的应用，并评估其在不同医疗场景下的表现。通过深入分析，我们旨在揭示这些模型在提升医疗服务质量和效率方面的潜力，以及它们在实际应用中可能面临的挑战。](2024年05月13日/Evaluating_large_language_models_in_medical_applications_a_survey.md)

- [MCS-SQL: Leveraging Multiple Prompts and Multiple-Choice Selection For Text-to-SQL Generation](2024年05月13日/MCS-SQL_Leveraging_Multiple_Prompts_and_Multiple-Choice_Selection_For_Text-to-SQL_Generation.md)

    - [翻译: MCS-SQL：借助多重提示与选择题机制，精妙演绎文本至SQL的生成艺术](2024年05月13日/MCS-SQL_Leveraging_Multiple_Prompts_and_Multiple-Choice_Selection_For_Text-to-SQL_Generation.md)

- [Plot2Code: A Comprehensive Benchmark for Evaluating Multi-modal Large Language Models in Code Generation from Scientific Plots](2024年05月13日/Plot2Code_A_Comprehensive_Benchmark_for_Evaluating_Multi-modal_Large_Language_Models_in_Code_Generation_from_Scientific_Plots.md)

    - [翻译: Plot2Code：科学图表至代码生成的多模态大型语言模型全面评估基准](2024年05月13日/Plot2Code_A_Comprehensive_Benchmark_for_Evaluating_Multi-modal_Large_Language_Models_in_Code_Generation_from_Scientific_Plots.md)

- [A Generalist Learner for Multifaceted Medical Image Interpretation](2024年05月13日/A_Generalist_Learner_for_Multifaceted_Medical_Image_Interpretation.md)

    - [翻译: 医学图像解读的全能学习者](2024年05月13日/A_Generalist_Learner_for_Multifaceted_Medical_Image_Interpretation.md)

- [PyZoBot: A Platform for Conversational Information Extraction and Synthesis from Curated Zotero Reference Libraries through Advanced Retrieval-Augmented Generation](2024年05月13日/PyZoBot_A_Platform_for_Conversational_Information_Extraction_and_Synthesis_from_Curated_Zotero_Reference_Libraries_through_Advanced_Retrieval-Augmented_Generation.md)

    - [翻译: PyZoBot：一个利用高级检索增强生成技术的平台，专为从精心管理的Zotero文献库中提取和整合对话式信息而设计。](2024年05月13日/PyZoBot_A_Platform_for_Conversational_Information_Extraction_and_Synthesis_from_Curated_Zotero_Reference_Libraries_through_Advanced_Retrieval-Augmented_Generation.md)

- [AgentClinic: a multimodal agent benchmark to evaluate AI in simulated clinical environments](2024年05月13日/AgentClinic_a_multimodal_agent_benchmark_to_evaluate_AI_in_simulated_clinical_environments.md)

    - [翻译: AgentClinic：多模态代理基准，专为评估AI在模拟临床环境中的表现而设计。](2024年05月13日/AgentClinic_a_multimodal_agent_benchmark_to_evaluate_AI_in_simulated_clinical_environments.md)

- [EconLogicQA: A Question-Answering Benchmark for Evaluating Large Language Models in Economic Sequential Reasoning](2024年05月13日/EconLogicQA_A_Question-Answering_Benchmark_for_Evaluating_Large_Language_Models_in_Economic_Sequential_Reasoning.md)

    - [翻译: 经济逻辑问答：大型语言模型经济序列推理能力评估的问答基准](2024年05月13日/EconLogicQA_A_Question-Answering_Benchmark_for_Evaluating_Large_Language_Models_in_Economic_Sequential_Reasoning.md)

- [PARDEN, Can You Repeat That? Defending against Jailbreaks via Repetition](2024年05月13日/PARDEN,_Can_You_Repeat_That_Defending_against_Jailbreaks_via_Repetition.md)

    - [翻译: PARDEN，请再说一次？——以重复为盾，抵御越狱之矛](2024年05月13日/PARDEN,_Can_You_Repeat_That_Defending_against_Jailbreaks_via_Repetition.md)

- [Can Better Text Semantics in Prompt Tuning Improve VLM Generalization?](2024年05月13日/Can_Better_Text_Semantics_in_Prompt_Tuning_Improve_VLM_Generalization.md)

    - [翻译: 优化提示调整中的文本语义，是否能增强视觉语言模型的泛化能力？这一问题引发了研究者的浓厚兴趣。](2024年05月13日/Can_Better_Text_Semantics_in_Prompt_Tuning_Improve_VLM_Generalization.md)

- [A Systematic Investigation of Distilling Large Language Models into Cross-Encoders for Passage Re-ranking](2024年05月13日/A_Systematic_Investigation_of_Distilling_Large_Language_Models_into_Cross-Encoders_for_Passage_Re-ranking.md)

    - [翻译: 系统探索：将大型语言模型精炼为跨编码器，以优化段落排序策略](2024年05月13日/A_Systematic_Investigation_of_Distilling_Large_Language_Models_into_Cross-Encoders_for_Passage_Re-ranking.md)

- [RLHF Workflow: From Reward Modeling to Online RLHF](2024年05月13日/RLHF_Workflow_From_Reward_Modeling_to_Online_RLHF.md)

    - [翻译: 强化学习与人类反馈（RLHF）的工作流程：从奖励模型构建到在线RLHF应用，这一流程展示了如何将人类偏好融入机器学习模型中，以优化其行为。](2024年05月13日/RLHF_Workflow_From_Reward_Modeling_to_Online_RLHF.md)

- [Can LLMs Help Predict Elections? (Counter)Evidence from the World's Largest Democracy](2024年05月13日/Can_LLMs_Help_Predict_Elections_(Counter)Evidence_from_the_World's_Largest_Democracy.md)

    - [翻译: 大型语言模型能否洞悉选举风云？世界最大民主国家的实证与反证](2024年05月13日/Can_LLMs_Help_Predict_Elections_(Counter)Evidence_from_the_World's_Largest_Democracy.md)

- [A View of How Language Models Will Transform Law](2024年05月13日/A_View_of_How_Language_Models_Will_Transform_Law.md)

    - [翻译: 语言模型变革法律的展望在这篇文章中，我们将探讨语言模型如何重塑法律领域，分析其潜在的影响和挑战，以及法律专业人士如何适应这一技术变革。](2024年05月13日/A_View_of_How_Language_Models_Will_Transform_Law.md)

- [FreeVA: Offline MLLM as Training-Free Video Assistant](2024年05月13日/FreeVA_Offline_MLLM_as_Training-Free_Video_Assistant.md)

    - [翻译: FreeVA：即刻启用的离线视频助手，基于无需额外训练的多模态大型语言模型技术。](2024年05月13日/FreeVA_Offline_MLLM_as_Training-Free_Video_Assistant.md)

- [Generating Human Motion in 3D Scenes from Text Descriptions](2024年05月13日/Generating_Human_Motion_in_3D_Scenes_from_Text_Descriptions.md)

    - [翻译: 通过文本描述赋予3D场景生命，创造逼真的人体动作。](2024年05月13日/Generating_Human_Motion_in_3D_Scenes_from_Text_Descriptions.md)

- [Synthetic Test Collections for Retrieval Evaluation](2024年05月13日/Synthetic_Test_Collections_for_Retrieval_Evaluation.md)

    - [翻译: 检索评估的合成测试集](2024年05月13日/Synthetic_Test_Collections_for_Retrieval_Evaluation.md)

- [LLM4ED: Large Language Models for Automatic Equation Discovery](2024年05月13日/LLM4ED_Large_Language_Models_for_Automatic_Equation_Discovery.md)

    - [翻译: 大型语言模型助力自动方程发现：LLM4ED在这项研究中，我们探索了大型语言模型（LLM）在自动方程发现（AED）领域的应用，旨在利用LLM的强大能力来辅助科学家和工程师在复杂系统中发现潜在的数学模型。通过深入分析LLM在处理数学表达式和逻辑推理方面的优势，我们提出了一种新颖的框架，该框架能够有效地从数据中提取规律，并生成描述这些规律的数学方程。我们的方法不仅提高了AED的自动化水平，还为解决实际问题提供了新的视角。](2024年05月13日/LLM4ED_Large_Language_Models_for_Automatic_Equation_Discovery.md)

- [LlamaTurk: Adapting Open-Source Generative Large Language Models for Low-Resource Language](2024年05月13日/LlamaTurk_Adapting_Open-Source_Generative_Large_Language_Models_for_Low-Resource_Language.md)

    - [翻译: 骆驼骑士：让开源巨型语言模型适应低资源语言的挑战](2024年05月13日/LlamaTurk_Adapting_Open-Source_Generative_Large_Language_Models_for_Low-Resource_Language.md)

- [OpenLLM-Ro -- Technical Report on Open-source Romanian LLMs trained starting from Llama 2](2024年05月13日/OpenLLM-Ro_--_Technical_Report_on_Open-source_Romanian_LLMs_trained_starting_from_Llama_2.md)

    - [翻译: OpenLLM-Ro技术报告：探索从Llama 2启程的罗马尼亚语开源大型语言模型之旅在这份技术报告中，我们将深入探讨如何从Llama 2这一起点出发，训练出适用于罗马尼亚语的开源大型语言模型。我们将详细分析训练过程中的技术挑战、创新方法以及最终模型的性能表现，旨在为罗马尼亚语的自然语言处理领域带来新的突破。](2024年05月13日/OpenLLM-Ro_--_Technical_Report_on_Open-source_Romanian_LLMs_trained_starting_from_Llama_2.md)

- [Age-Dependent Analysis and Stochastic Generation of Child-Directed Speech](2024年05月13日/Age-Dependent_Analysis_and_Stochastic_Generation_of_Child-Directed_Speech.md)

    - [翻译: 针对儿童言语的年龄相关分析与随机生成在这项研究中，我们探讨了儿童言语的年龄依赖性特征，并开发了一种随机生成模型，旨在更自然地模拟儿童导向的交流方式。通过深入分析不同年龄段儿童的言语特点，我们的模型能够生成更符合儿童理解和接受能力的语言，为儿童语言学习和交流提供了新的工具。](2024年05月13日/Age-Dependent_Analysis_and_Stochastic_Generation_of_Child-Directed_Speech.md)

- [Backdoor Removal for Generative Large Language Models](2024年05月13日/Backdoor_Removal_for_Generative_Large_Language_Models.md)

    - [翻译: 清除生成式大型语言模型的后门隐患](2024年05月13日/Backdoor_Removal_for_Generative_Large_Language_Models.md)

- [DoLLM: How Large Language Models Understanding Network Flow Data to Detect Carpet Bombing DDoS](2024年05月13日/DoLLM_How_Large_Language_Models_Understanding_Network_Flow_Data_to_Detect_Carpet_Bombing_DDoS.md)

    - [翻译: DoLLM：大型语言模型洞察网络流量，精准侦测地毯式轰炸DDoS攻击在这项研究中，我们将探讨大型语言模型（LLM）如何通过分析网络流量数据来识别和防御地毯式轰炸分布式拒绝服务（DDoS）攻击。通过深入研究LLM在处理复杂网络数据时的能力，我们旨在揭示其对于此类攻击模式的识别和响应机制，从而为网络安全领域提供新的防御策略。](2024年05月13日/DoLLM_How_Large_Language_Models_Understanding_Network_Flow_Data_to_Detect_Carpet_Bombing_DDoS.md)

- [AnomalyLLM: Few-shot Anomaly Edge Detection for Dynamic Graphs using Large Language Models](2024年05月13日/AnomalyLLM_Few-shot_Anomaly_Edge_Detection_for_Dynamic_Graphs_using_Large_Language_Models.md)

    - [翻译: AnomalyLLM：大型语言模型助力动态图的少样本异常边缘精准捕捉](2024年05月13日/AnomalyLLM_Few-shot_Anomaly_Edge_Detection_for_Dynamic_Graphs_using_Large_Language_Models.md)

- [COBias and Debias: Minimizing Language Model Pairwise Accuracy Bias via Nonlinear Integer Programming](2024年05月13日/COBias_and_Debias_Minimizing_Language_Model_Pairwise_Accuracy_Bias_via_Nonlinear_Integer_Programming.md)

    - [翻译: 纠偏与去偏：运用非线性整数规划策略，精准校正语言模型中的成对准确性偏差](2024年05月13日/COBias_and_Debias_Minimizing_Language_Model_Pairwise_Accuracy_Bias_via_Nonlinear_Integer_Programming.md)

- [ViWikiFC: Fact-Checking for Vietnamese Wikipedia-Based Textual Knowledge Source](2024年05月13日/ViWikiFC_Fact-Checking_for_Vietnamese_Wikipedia-Based_Textual_Knowledge_Source.md)

    - [翻译: 越南维基事实核查：为越南语维基百科文本知识源提供精准事实检验](2024年05月13日/ViWikiFC_Fact-Checking_for_Vietnamese_Wikipedia-Based_Textual_Knowledge_Source.md)

- [DynLLM: When Large Language Models Meet Dynamic Graph Recommendation](2024年05月13日/DynLLM_When_Large_Language_Models_Meet_Dynamic_Graph_Recommendation.md)

    - [翻译: 动态巨型语言模型：大型语言模型与动态图推荐之交融](2024年05月13日/DynLLM_When_Large_Language_Models_Meet_Dynamic_Graph_Recommendation.md)

- [Coding historical causes of death data with Large Language Models](2024年05月13日/Coding_historical_causes_of_death_data_with_Large_Language_Models.md)

    - [翻译: 借助大型语言模型，我们能够对历史死亡数据进行精细编码，揭示过去岁月中生命消逝的种种原因。这一过程不仅是对数据的整理，更是对历史的一次深刻回望。](2024年05月13日/Coding_historical_causes_of_death_data_with_Large_Language_Models.md)

- [MuMath-Code: Combining Tool-Use Large Language Models with Multi-perspective Data Augmentation for Mathematical Reasoning](2024年05月13日/MuMath-Code_Combining_Tool-Use_Large_Language_Models_with_Multi-perspective_Data_Augmentation_for_Mathematical_Reasoning.md)

    - [翻译: MuMath-Code：融合大型语言模型的工具运用与多角度数据扩充，以提升数学推理能力](2024年05月13日/MuMath-Code_Combining_Tool-Use_Large_Language_Models_with_Multi-perspective_Data_Augmentation_for_Mathematical_Reasoning.md)

- [EMS-SD: Efficient Multi-sample Speculative Decoding for Accelerating Large Language Models](2024年05月13日/EMS-SD_Efficient_Multi-sample_Speculative_Decoding_for_Accelerating_Large_Language_Models.md)

    - [翻译: EMS-SD：加速大型语言模型的利器——高效多样本推测解码技术](2024年05月13日/EMS-SD_Efficient_Multi-sample_Speculative_Decoding_for_Accelerating_Large_Language_Models.md)

- [TANQ: An open domain dataset of table answered questions](2024年05月13日/TANQ_An_open_domain_dataset_of_table_answered_questions.md)

    - [翻译: TANQ：探索开放领域，揭秘表格之谜——一个专为回答问题而生的数据集。](2024年05月13日/TANQ_An_open_domain_dataset_of_table_answered_questions.md)

- [HoneyBee: A Scalable Modular Framework for Creating Multimodal Oncology Datasets with Foundational Embedding Models](2024年05月13日/HoneyBee_A_Scalable_Modular_Framework_for_Creating_Multimodal_Oncology_Datasets_with_Foundational_Embedding_Models.md)

    - [翻译: 蜜蜂计划：一个基于基础嵌入模型的可扩展模块化框架，专为构建多模态肿瘤学数据集而设计。](2024年05月13日/HoneyBee_A_Scalable_Modular_Framework_for_Creating_Multimodal_Oncology_Datasets_with_Foundational_Embedding_Models.md)

2024年05月12日

- [CLIP-Powered TASS: Target-Aware Single-Stream Network for Audio-Visual Question Answering](2024年05月12日/CLIP-Powered_TASS_Target-Aware_Single-Stream_Network_for_Audio-Visual_Question_Answering.md)

    - [翻译: CLIP赋能的TASS：一种专为视听问答设计的目标感知单流网络，它巧妙地融合了视觉和听觉信息，以精准解答跨模态问题。](2024年05月12日/CLIP-Powered_TASS_Target-Aware_Single-Stream_Network_for_Audio-Visual_Question_Answering.md)

- [From traces to measures: Large language models as a tool for psychological measurement from text](2024年05月12日/From_traces_to_measures_Large_language_models_as_a_tool_for_psychological_measurement_from_text.md)

    - [翻译: 大型语言模型：文本心理测量的利器，从细微痕迹到精准测量。](2024年05月12日/From_traces_to_measures_Large_language_models_as_a_tool_for_psychological_measurement_from_text.md)

- [Can Language Models Explain Their Own Classification Behavior?](2024年05月12日/Can_Language_Models_Explain_Their_Own_Classification_Behavior.md)

    - [翻译: 语言模型是否具备自我解释其分类决策的能力？这一问题引发了对于模型透明度和可解释性的深入探讨。](2024年05月12日/Can_Language_Models_Explain_Their_Own_Classification_Behavior.md)

- [Don't Chase Your Tail! Missing Key Aspects Augmentation in Textual Vulnerability Descriptions of Long-tail Software through Feature Inference](2024年05月12日/Don't_Chase_Your_Tail!_Missing_Key_Aspects_Augmentation_in_Textual_Vulnerability_Descriptions_of_Long-tail_Software_through_Feature_Inference.md)

    - [翻译: 别做无用功！通过特征推断填补长尾软件漏洞描述中的空白，揭示关键缺失要素。](2024年05月12日/Don't_Chase_Your_Tail!_Missing_Key_Aspects_Augmentation_in_Textual_Vulnerability_Descriptions_of_Long-tail_Software_through_Feature_Inference.md)

- [Identifying Hate Speech Peddlers in Online Platforms. A Bayesian Social Learning Approach for Large Language Model Driven Decision-Makers](2024年05月12日/Identifying_Hate_Speech_Peddlers_in_Online_Platforms._A_Bayesian_Social_Learning_Approach_for_Large_Language_Model_Driven_Decision-Makers.md)

    - [翻译: 利用大型语言模型，采用贝叶斯社会学习策略，精准识别网络平台上的仇恨言论传播者，为决策者提供有力支持。](2024年05月12日/Identifying_Hate_Speech_Peddlers_in_Online_Platforms._A_Bayesian_Social_Learning_Approach_for_Large_Language_Model_Driven_Decision-Makers.md)

- [MedConceptsQA -- Open Source Medical Concepts QA Benchmark](2024年05月12日/MedConceptsQA_--_Open_Source_Medical_Concepts_QA_Benchmark.md)

    - [翻译: MedConceptsQA - 开源医学概念问答标杆，旨在为医学领域的知识问答提供一个公开、可验证的评估平台。](2024年05月12日/MedConceptsQA_--_Open_Source_Medical_Concepts_QA_Benchmark.md)

- [Learnable Tokenizer for LLM-based Generative Recommendation](2024年05月12日/Learnable_Tokenizer_for_LLM-based_Generative_Recommendation.md)

    - [翻译: 大型语言模型生成推荐的可学习分词器](2024年05月12日/Learnable_Tokenizer_for_LLM-based_Generative_Recommendation.md)

- [Human-interpretable clustering of short-text using large language models](2024年05月12日/Human-interpretable_clustering_of_short-text_using_large_language_models.md)

    - [翻译: 大型语言模型助力短文本聚类，实现人类可理解的分析](2024年05月12日/Human-interpretable_clustering_of_short-text_using_large_language_models.md)

- [Limited Ability of LLMs to Simulate Human Psychological Behaviours: a Psychometric Analysis](2024年05月12日/Limited_Ability_of_LLMs_to_Simulate_Human_Psychological_Behaviours_a_Psychometric_Analysis.md)

    - [翻译: 大型语言模型在模拟人类心理行为方面显露局限：心理测量视角下的深度剖析](2024年05月12日/Limited_Ability_of_LLMs_to_Simulate_Human_Psychological_Behaviours_a_Psychometric_Analysis.md)

- [MM-InstructEval: Zero-Shot Evaluation of (Multimodal) Large Language Models on Multimodal Reasoning Tasks](2024年05月12日/MM-InstructEval_Zero-Shot_Evaluation_of_(Multimodal)_Large_Language_Models_on_Multimodal_Reasoning_Tasks.md)

    - [翻译: MM-InstructEval：大型多模态语言模型在多模态推理任务上的零-shot性能评估在这项研究中，我们引入了 MM-InstructEval，这是一个用于评估大型多模态语言模型在多模态推理任务上的零-shot性能的框架。通过这个框架，我们旨在探索这些模型在无需额外训练的情况下，如何理解和处理结合了文本和视觉信息的多模态输入，并执行复杂的推理任务。我们的目标是提供一个全面的评估工具，以揭示这些先进模型在多模态环境下的实际能力和潜在局限性。](2024年05月12日/MM-InstructEval_Zero-Shot_Evaluation_of_(Multimodal)_Large_Language_Models_on_Multimodal_Reasoning_Tasks.md)

- [Enhancing Decision-Making in Optimization through LLM-Assisted Inference: A Neural Networks Perspective](2024年05月12日/Enhancing_Decision-Making_in_Optimization_through_LLM-Assisted_Inference_A_Neural_Networks_Perspective.md)

    - [翻译: 借助大型语言模型辅助推理，优化决策更上一层楼：神经网络视角下的探索](2024年05月12日/Enhancing_Decision-Making_in_Optimization_through_LLM-Assisted_Inference_A_Neural_Networks_Perspective.md)

- [Unified Video-Language Pre-training with Synchronized Audio](2024年05月12日/Unified_Video-Language_Pre-training_with_Synchronized_Audio.md)

    - [翻译: 同步音频下的视频与语言一体化预训练](2024年05月12日/Unified_Video-Language_Pre-training_with_Synchronized_Audio.md)

- [Differentiable Model Scaling using Differentiable Topk](2024年05月12日/Differentiable_Model_Scaling_using_Differentiable_Topk.md)

    - [翻译: 利用可微分Topk实现模型参数的灵活缩放，这一技术为模型优化提供了新的维度，使得模型在保持性能的同时，能够更加适应不同的计算资源和应用场景。](2024年05月12日/Differentiable_Model_Scaling_using_Differentiable_Topk.md)

- [Learning Reward for Robot Skills Using Large Language Models via Self-Alignment](2024年05月12日/Learning_Reward_for_Robot_Skills_Using_Large_Language_Models_via_Self-Alignment.md)

    - [翻译: 借助大型语言模型的自我对齐，我们探索了如何为机器人技能学习赋予奖励，这一创新方法旨在提升机器人在复杂任务中的自主学习能力。](2024年05月12日/Learning_Reward_for_Robot_Skills_Using_Large_Language_Models_via_Self-Alignment.md)

- [Evaluation of Retrieval-Augmented Generation: A Survey](2024年05月12日/Evaluation_of_Retrieval-Augmented_Generation_A_Survey.md)

    - [翻译: 检索增强生成评估综述：本调查旨在深入探讨检索增强生成技术的评估方法，分析其在不同应用场景下的表现，并探讨如何优化这一技术以提升生成内容的质量和相关性。](2024年05月12日/Evaluation_of_Retrieval-Augmented_Generation_A_Survey.md)

2024年05月11日

- [Edge Intelligence Optimization for Large Language Model Inference with Batching and Quantization](2024年05月11日/Edge_Intelligence_Optimization_for_Large_Language_Model_Inference_with_Batching_and_Quantization.md)

    - [翻译: 大型语言模型推理的边缘智能优化：通过批处理与量化技术提升效率。](2024年05月11日/Edge_Intelligence_Optimization_for_Large_Language_Model_Inference_with_Batching_and_Quantization.md)

- [Combining multiple post-training techniques to achieve most efficient quantized LLMs](2024年05月11日/Combining_multiple_post-training_techniques_to_achieve_most_efficient_quantized_LLMs.md)

    - [翻译: 融合多重后训练技艺，铸就量化大型语言模型的极致效能](2024年05月11日/Combining_multiple_post-training_techniques_to_achieve_most_efficient_quantized_LLMs.md)

- [Designing and Evaluating Dialogue LLMs for Co-Creative Improvised Theatre](2024年05月11日/Designing_and_Evaluating_Dialogue_LLMs_for_Co-Creative_Improvised_Theatre.md)

    - [翻译: 打造与评测共创即兴戏剧的对话式LLM](2024年05月11日/Designing_and_Evaluating_Dialogue_LLMs_for_Co-Creative_Improvised_Theatre.md)

- [Advanced Natural-based interaction for the ITAlian language: LLaMAntino-3-ANITA](2024年05月11日/Advanced_Natural-based_interaction_for_the_ITAlian_language_LLaMAntino-3-ANITA.md)

    - [翻译: 意大利语的先进自然交互技术：LLaMAntino-3-ANITA](2024年05月11日/Advanced_Natural-based_interaction_for_the_ITAlian_language_LLaMAntino-3-ANITA.md)

- [MUD: Towards a Large-Scale and Noise-Filtered UI Dataset for Modern Style UI Modeling](2024年05月11日/MUD_Towards_a_Large-Scale_and_Noise-Filtered_UI_Dataset_for_Modern_Style_UI_Modeling.md)

    - [翻译: MUD：构建大规模且去噪的现代风格UI模型数据集在这项研究中，我们提出了MUD，一个旨在为现代风格UI模型提供大规模且经过噪声过滤的UI数据集。通过精心设计的去噪机制，MUD确保了数据的质量，为UI模型的训练和评估提供了坚实的基础。我们的目标是推动UI设计领域的进步，使得模型能够更好地理解和生成符合现代审美的用户界面。](2024年05月11日/MUD_Towards_a_Large-Scale_and_Noise-Filtered_UI_Dataset_for_Modern_Style_UI_Modeling.md)

- [SonifyAR: Context-Aware Sound Generation in Augmented Reality](2024年05月11日/SonifyAR_Context-Aware_Sound_Generation_in_Augmented_Reality.md)

    - [翻译: SonifyAR：在增强现实中，声音生成技术能够感知并适应环境，为用户带来沉浸式的听觉体验。](2024年05月11日/SonifyAR_Context-Aware_Sound_Generation_in_Augmented_Reality.md)

- [Integrating Emotional and Linguistic Models for Ethical Compliance in Large Language Models](2024年05月11日/Integrating_Emotional_and_Linguistic_Models_for_Ethical_Compliance_in_Large_Language_Models.md)

    - [翻译: 融合情感与语言模型，确保大型语言模型的伦理遵循在这项研究中，我们探讨了如何将情感分析与语言处理技术相结合，以提升大型语言模型在伦理合规方面的表现。通过这种整合，我们旨在确保人工智能在交流时不仅传达准确的信息，而且能够体现出对用户情感的敏感性和尊重，从而在伦理层面上达到更高的标准。](2024年05月11日/Integrating_Emotional_and_Linguistic_Models_for_Ethical_Compliance_in_Large_Language_Models.md)

- [LogoMotion: Visually Grounded Code Generation for Content-Aware Animation](2024年05月11日/LogoMotion_Visually_Grounded_Code_Generation_for_Content-Aware_Animation.md)

    - [翻译: LogoMotion：视觉启发的代码生成，赋予动画内容感知能力](2024年05月11日/LogoMotion_Visually_Grounded_Code_Generation_for_Content-Aware_Animation.md)

- [LLMs and the Future of Chip Design: Unveiling Security Risks and Building Trust](2024年05月11日/LLMs_and_the_Future_of_Chip_Design_Unveiling_Security_Risks_and_Building_Trust.md)

    - [翻译: 大型语言模型与芯片设计未来：揭秘安全隐忧，构筑信任基石](2024年05月11日/LLMs_and_the_Future_of_Chip_Design_Unveiling_Security_Risks_and_Building_Trust.md)

- [Memory-Maze: Scenario Driven Benchmark and Visual Language Navigation Model for Guiding Blind People](2024年05月11日/Memory-Maze_Scenario_Driven_Benchmark_and_Visual_Language_Navigation_Model_for_Guiding_Blind_People.md)

    - [翻译: 记忆迷宫：专为盲人设计的情景驱动基准与视觉语言导航模型，旨在通过模拟真实环境挑战，提升导航辅助技术的精准性与实用性。](2024年05月11日/Memory-Maze_Scenario_Driven_Benchmark_and_Visual_Language_Navigation_Model_for_Guiding_Blind_People.md)

- [Retrieval Enhanced Zero-Shot Video Captioning](2024年05月11日/Retrieval_Enhanced_Zero-Shot_Video_Captioning.md)

    - [翻译: 零-shot视频字幕生成通过检索增强技术得到提升，本研究探索了如何利用检索机制来优化视频内容的自动描述过程。](2024年05月11日/Retrieval_Enhanced_Zero-Shot_Video_Captioning.md)

- [A Turkish Educational Crossword Puzzle](2024年05月11日/A_Turkish_Educational_Crossword_Puzzle.md)

    - [翻译: 土耳其益智教育填字游戏解释：在](2024年05月11日/A_Turkish_Educational_Crossword_Puzzle.md)

- [Evaluating Task-based Effectiveness of MLLMs on Charts](2024年05月11日/Evaluating_Task-based_Effectiveness_of_MLLMs_on_Charts.md)

    - [翻译: 探究多模态大型语言模型在图表任务中的实际效能。](2024年05月11日/Evaluating_Task-based_Effectiveness_of_MLLMs_on_Charts.md)

- [Large Language Model-aided Edge Learning in Distribution System State Estimation](2024年05月11日/Large_Language_Model-aided_Edge_Learning_in_Distribution_System_State_Estimation.md)

    - [翻译: 借助大型语言模型，边缘学习在配电系统状态估计中展现出新的活力，为电力系统的智能化管理提供了强有力的技术支撑。](2024年05月11日/Large_Language_Model-aided_Edge_Learning_in_Distribution_System_State_Estimation.md)

- [Quite Good, but Not Enough: Nationality Bias in Large Language Models -- A Case Study of ChatGPT](2024年05月11日/Quite_Good,_but_Not_Enough_Nationality_Bias_in_Large_Language_Models_--_A_Case_Study_of_ChatGPT.md)

    - [翻译: 尚可但不足：探究大型语言模型中的国籍偏见——以ChatGPT为例](2024年05月11日/Quite_Good,_but_Not_Enough_Nationality_Bias_in_Large_Language_Models_--_A_Case_Study_of_ChatGPT.md)

- [Identifying Key Terms in Prompts for Relevance Evaluation with GPT Models](2024年05月11日/Identifying_Key_Terms_in_Prompts_for_Relevance_Evaluation_with_GPT_Models.md)

    - [翻译: 在利用GPT模型评估相关性时，精准捕捉提示中的关键术语至关重要。本研究聚焦于如何有效地识别这些关键术语，以提升模型在相关性评估中的准确性和效率。](2024年05月11日/Identifying_Key_Terms_in_Prompts_for_Relevance_Evaluation_with_GPT_Models.md)

- [Automating Thematic Analysis: How LLMs Analyse Controversial Topics](2024年05月11日/Automating_Thematic_Analysis_How_LLMs_Analyse_Controversial_Topics.md)

    - [翻译: 大型语言模型在争议话题分析中的自动化探索在上述翻译过程中，](2024年05月11日/Automating_Thematic_Analysis_How_LLMs_Analyse_Controversial_Topics.md)

- [CoRE: LLM as Interpreter for Natural Language Programming, Pseudo-Code Programming, and Flow Programming of AI Agents](2024年05月11日/CoRE_LLM_as_Interpreter_for_Natural_Language_Programming,_Pseudo-Code_Programming,_and_Flow_Programming_of_AI_Agents.md)

    - [翻译: CoRE：大型语言模型——AI代理自然语言编程、伪代码编程与流程编程的智慧之钥](2024年05月11日/CoRE_LLM_as_Interpreter_for_Natural_Language_Programming,_Pseudo-Code_Programming,_and_Flow_Programming_of_AI_Agents.md)

2024年05月10日

- [Linearizing Large Language Models](2024年05月10日/Linearizing_Large_Language_Models.md)

    - [翻译: 大型语言模型的线性化](2024年05月10日/Linearizing_Large_Language_Models.md)

- [Value Augmented Sampling for Language Model Alignment and Personalization](2024年05月10日/Value_Augmented_Sampling_for_Language_Model_Alignment_and_Personalization.md)

    - [翻译: 语言模型的价值增强采样：对齐与个性化之道](2024年05月10日/Value_Augmented_Sampling_for_Language_Model_Alignment_and_Personalization.md)

- [Characterizing the Accuracy - Efficiency Trade-off of Low-rank Decomposition in Language Models](2024年05月10日/Characterizing_the_Accuracy_-_Efficiency_Trade-off_of_Low-rank_Decomposition_in_Language_Models.md)

    - [翻译: 语言模型中低秩分解的精效平衡探析](2024年05月10日/Characterizing_the_Accuracy_-_Efficiency_Trade-off_of_Low-rank_Decomposition_in_Language_Models.md)

- [What Can Natural Language Processing Do for Peer Review?](2024年05月10日/What_Can_Natural_Language_Processing_Do_for_Peer_Review.md)

    - [翻译: 自然语言处理如何助力同行评审？](2024年05月10日/What_Can_Natural_Language_Processing_Do_for_Peer_Review.md)

- [Mitigating Hallucinations in Large Language Models via Self-Refinement-Enhanced Knowledge Retrieval](2024年05月10日/Mitigating_Hallucinations_in_Large_Language_Models_via_Self-Refinement-Enhanced_Knowledge_Retrieval.md)

    - [翻译: 借助自精细化知识检索，大型语言模型幻觉得以缓解](2024年05月10日/Mitigating_Hallucinations_in_Large_Language_Models_via_Self-Refinement-Enhanced_Knowledge_Retrieval.md)

- [Prompting Large Language Models with Knowledge Graphs for Question Answering Involving Long-tail Facts](2024年05月10日/Prompting_Large_Language_Models_with_Knowledge_Graphs_for_Question_Answering_Involving_Long-tail_Facts.md)

    - [翻译: 借助知识图谱，激发大型语言模型解答长尾事实相关问题](2024年05月10日/Prompting_Large_Language_Models_with_Knowledge_Graphs_for_Question_Answering_Involving_Long-tail_Facts.md)

- [UniDM: A Unified Framework for Data Manipulation with Large Language Models](2024年05月10日/UniDM_A_Unified_Framework_for_Data_Manipulation_with_Large_Language_Models.md)

    - [翻译: UniDM：大型语言模型数据操作的统一之桥在人工智能的浩瀚星空中，UniDM犹如一座横跨数据与智慧的桥梁，以其统一之姿，将大型语言模型的数据操作能力汇聚于一点。它不仅是一套框架，更是一种艺术，一种将数据的纷繁复杂转化为模型智慧的精湛技艺。在这个框架下，数据的每一次舞动，都仿佛在诉说着与模型深度对话的故事，引领我们探索数据科学的无限可能。](2024年05月10日/UniDM_A_Unified_Framework_for_Data_Manipulation_with_Large_Language_Models.md)

- [Storypark: Leveraging Large Language Models to Enhance Children Story Learning Through Child-AI collaboration Storytelling](2024年05月10日/Storypark_Leveraging_Large_Language_Models_to_Enhance_Children_Story_Learning_Through_Child-AI_collaboration_Storytelling.md)

    - [翻译: Storypark：借助大型语言模型的力量，通过儿童与AI的协作讲故事，提升儿童的故事学习体验。](2024年05月10日/Storypark_Leveraging_Large_Language_Models_to_Enhance_Children_Story_Learning_Through_Child-AI_collaboration_Storytelling.md)

- [ProCIS: A Benchmark for Proactive Retrieval in Conversations](2024年05月10日/ProCIS_A_Benchmark_for_Proactive_Retrieval_in_Conversations.md)

    - [翻译: ProCIS：对话主动检索的标杆在这篇文章中，我们将介绍ProCIS，这是一个专为对话中主动检索设计的基准。它旨在评估和推动对话系统在主动检索信息方面的能力，以提高交互的自然性和效率。通过ProCIS，研究者可以更好地理解和改进对话系统在处理复杂查询和提供即时信息时的表现。](2024年05月10日/ProCIS_A_Benchmark_for_Proactive_Retrieval_in_Conversations.md)

- [Improving Instruction Following in Language Models through Proxy-Based Uncertainty Estimation](2024年05月10日/Improving_Instruction_Following_in_Language_Models_through_Proxy-Based_Uncertainty_Estimation.md)

    - [翻译: 借助代理辅助的不确定性评估，精进语言模型的指令执行艺术](2024年05月10日/Improving_Instruction_Following_in_Language_Models_through_Proxy-Based_Uncertainty_Estimation.md)

- [Can Large Language Models Replicate ITS Feedback on Open-Ended Math Questions?](2024年05月10日/Can_Large_Language_Models_Replicate_ITS_Feedback_on_Open-Ended_Math_Questions.md)

    - [翻译: 大型语言模型是否具备复制智能教学系统对开放式数学问题反馈的能力？](2024年05月10日/Can_Large_Language_Models_Replicate_ITS_Feedback_on_Open-Ended_Math_Questions.md)

- [Potential and Limitations of LLMs in Capturing Structured Semantics: A Case Study on SRL](2024年05月10日/Potential_and_Limitations_of_LLMs_in_Capturing_Structured_Semantics_A_Case_Study_on_SRL.md)

    - [翻译: 大型语言模型在揭示结构化语义的奥秘上既有潜力也有限制，本研究以语义角色标注为切入点，深入探讨了这一议题。](2024年05月10日/Potential_and_Limitations_of_LLMs_in_Capturing_Structured_Semantics_A_Case_Study_on_SRL.md)

- [Program Synthesis using Inductive Logic Programming for the Abstraction and Reasoning Corpus](2024年05月10日/Program_Synthesis_using_Inductive_Logic_Programming_for_the_Abstraction_and_Reasoning_Corpus.md)

    - [翻译: 归纳逻辑编程助力程序合成，探索抽象与推理语料库之奥秘](2024年05月10日/Program_Synthesis_using_Inductive_Logic_Programming_for_the_Abstraction_and_Reasoning_Corpus.md)

- [LLM Discussion: Enhancing the Creativity of Large Language Models via Discussion Framework and Role-Play](2024年05月10日/LLM_Discussion_Enhancing_the_Creativity_of_Large_Language_Models_via_Discussion_Framework_and_Role-Play.md)

    - [翻译: 大型语言模型创造力提升：探讨框架与角色扮演的融合之道](2024年05月10日/LLM_Discussion_Enhancing_the_Creativity_of_Large_Language_Models_via_Discussion_Framework_and_Role-Play.md)

- [DP-DyLoRA: Fine-Tuning Transformer-Based Models On-Device under Differentially Private Federated Learning using Dynamic Low-Rank Adaptation](2024年05月10日/DP-DyLoRA_Fine-Tuning_Transformer-Based_Models_On-Device_under_Differentially_Private_Federated_Learning_using_Dynamic_Low-Rank_Adaptation.md)

    - [翻译: DP-DyLoRA：在隐私保护联邦学习框架下，采用动态低秩适应技术，对基于变换器的模型进行设备端精细调整，以实现数据隐私与模型性能的平衡。](2024年05月10日/DP-DyLoRA_Fine-Tuning_Transformer-Based_Models_On-Device_under_Differentially_Private_Federated_Learning_using_Dynamic_Low-Rank_Adaptation.md)

- [Correlation Dimension of Natural Language in a Statistical Manifold](2024年05月10日/Correlation_Dimension_of_Natural_Language_in_a_Statistical_Manifold.md)

    - [翻译: 自然语言在统计空间中的相关维度探索](2024年05月10日/Correlation_Dimension_of_Natural_Language_in_a_Statistical_Manifold.md)

- [FedGCS: A Generative Framework for Efficient Client Selection in Federated Learning via Gradient-based Optimization](2024年05月10日/FedGCS_A_Generative_Framework_for_Efficient_Client_Selection_in_Federated_Learning_via_Gradient-based_Optimization.md)

    - [翻译: FedGCS：梯度优化驱动的高效联邦学习客户端选择生成框架](2024年05月10日/FedGCS_A_Generative_Framework_for_Efficient_Client_Selection_in_Federated_Learning_via_Gradient-based_Optimization.md)

- [Pruning as a Domain-specific LLM Extractor](2024年05月10日/Pruning_as_a_Domain-specific_LLM_Extractor.md)

    - [翻译: 修剪技术：特定领域的大型语言模型精炼者](2024年05月10日/Pruning_as_a_Domain-specific_LLM_Extractor.md)

- [XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced In-Context Learning in Healthcare](2024年05月10日/XAI4LLM._Let_Machine_Learning_Models_and_LLMs_Collaborate_for_Enhanced_In-Context_Learning_in_Healthcare.md)

    - [翻译: XAI4LLM：携手机器学习与大型语言模型，共铸医疗领域上下文学习的辉煌。](2024年05月10日/XAI4LLM._Let_Machine_Learning_Models_and_LLMs_Collaborate_for_Enhanced_In-Context_Learning_in_Healthcare.md)

- [Automatic Generation of Model and Data Cards: A Step Towards Responsible AI](2024年05月10日/Automatic_Generation_of_Model_and_Data_Cards_A_Step_Towards_Responsible_AI.md)

    - [翻译: 自动创建模型与数据卡片：引领人工智能走向责任之道](2024年05月10日/Automatic_Generation_of_Model_and_Data_Cards_A_Step_Towards_Responsible_AI.md)

- [SaudiBERT: A Large Language Model Pretrained on Saudi Dialect Corpora](2024年05月10日/SaudiBERT_A_Large_Language_Model_Pretrained_on_Saudi_Dialect_Corpora.md)

    - [翻译: 沙特方言之光：SaudiBERT——专为沙特语境定制的大型预训练语言模型](2024年05月10日/SaudiBERT_A_Large_Language_Model_Pretrained_on_Saudi_Dialect_Corpora.md)

- [Risks of Practicing Large Language Models in Smart Grid: Threat Modeling and Validation](2024年05月10日/Risks_of_Practicing_Large_Language_Models_in_Smart_Grid_Threat_Modeling_and_Validation.md)

    - [翻译: 智能电网中应用大型语言模型的潜在风险：威胁建模与验证探索在智能电网领域，大型语言模型的应用虽带来便利，但其潜在风险不容忽视。本文将深入探讨这些风险，并通过威胁建模与验证，揭示其对智能电网安全的影响。](2024年05月10日/Risks_of_Practicing_Large_Language_Models_in_Smart_Grid_Threat_Modeling_and_Validation.md)

- [ExoplANETS-A: A VO database for host stars and planetary systems: The effect of XUV on planet atmospheres](2024年05月10日/ExoplANETS-A_A_VO_database_for_host_stars_and_planetary_systems_The_effect_of_XUV_on_planet_atmospheres.md)

    - [翻译: ExoplANETS-A：探索宿主星与行星系统的宝库，揭示XUV辐射如何塑造遥远世界的大气层。](2024年05月10日/ExoplANETS-A_A_VO_database_for_host_stars_and_planetary_systems_The_effect_of_XUV_on_planet_atmospheres.md)

- [TacoERE: Cluster-aware Compression for Event Relation Extraction](2024年05月10日/TacoERE_Cluster-aware_Compression_for_Event_Relation_Extraction.md)

    - [翻译: TacoERE：事件关系抽取的集群感知压缩技术](2024年05月10日/TacoERE_Cluster-aware_Compression_for_Event_Relation_Extraction.md)

2024年05月09日

- [Natural Language Processing RELIES on Linguistics](2024年05月09日/Natural_Language_Processing_RELIES_on_Linguistics.md)

    - [翻译: 自然语言处理深植于语言学的土壤之中，二者相辅相成，共同推动着人工智能领域的发展。](2024年05月09日/Natural_Language_Processing_RELIES_on_Linguistics.md)

- [OpenBA-V2: Reaching 77.3% High Compression Ratio with Fast Multi-Stage Pruning](2024年05月09日/OpenBA-V2_Reaching_77.3%_High_Compression_Ratio_with_Fast_Multi-Stage_Pruning.md)

    - [翻译: OpenBA-V2：以迅捷的多阶段剪枝技术，实现了高达77.3%的卓越压缩比，为模型瘦身开辟了新境界。](2024年05月09日/OpenBA-V2_Reaching_77.3%_High_Compression_Ratio_with_Fast_Multi-Stage_Pruning.md)

- [Probing Multimodal LLMs as World Models for Driving](2024年05月09日/Probing_Multimodal_LLMs_as_World_Models_for_Driving.md)

    - [翻译: 探索大型语言模型的多模态潜能，将其作为驾驶场景的智能世界模型。](2024年05月09日/Probing_Multimodal_LLMs_as_World_Models_for_Driving.md)

- [Smurfs: Leveraging Multiple Proficiency Agents with Context-Efficiency for Tool Planning](2024年05月09日/Smurfs_Leveraging_Multiple_Proficiency_Agents_with_Context-Efficiency_for_Tool_Planning.md)

    - [翻译: 蓝精灵策略：借助高效利用上下文的多技能代理，实现工具规划的优化在翻译过程中，我首先确保原文的核心概念和术语被准确地转换成中文，如“Smurfs”、“Multiple Proficiency Agents”和“Context-Efficiency”。接着，我调整了语言风格，使其更加符合中文的表达习惯，同时保持了原文的生动性和简洁性。通过这种方式，翻译既忠实于原文，又易于中文读者理解。](2024年05月09日/Smurfs_Leveraging_Multiple_Proficiency_Agents_with_Context-Efficiency_for_Tool_Planning.md)

- [CuMo: Scaling Multimodal LLM with Co-Upcycled Mixture-of-Experts](2024年05月09日/CuMo_Scaling_Multimodal_LLM_with_Co-Upcycled_Mixture-of-Experts.md)

    - [翻译: CuMo：借助协同升级的混合专家技术，扩展多模态大型语言模型的能力在这项研究中，我们提出了CuMo，一种新颖的框架，旨在通过引入协同升级的混合专家（Co-Upcycled Mixture-of-Experts）机制来扩展多模态大型语言模型（Multimodal LLM）的能力。CuMo的核心思想是通过有效地结合不同领域的专家知识，提升模型在处理多模态数据时的性能和灵活性。我们的实验结果表明，CuMo不仅能够显著提高模型的处理速度，还能在保持高准确率的同时，处理更加复杂和多样化的任务。这一创新性的方法为多模态AI技术的发展开辟了新的道路。](2024年05月09日/CuMo_Scaling_Multimodal_LLM_with_Co-Upcycled_Mixture-of-Experts.md)

- [Trustworthy AI-Generative Content in Intelligent 6G Network: Adversarial, Privacy, and Fairness](2024年05月09日/Trustworthy_AI-Generative_Content_in_Intelligent_6G_Network_Adversarial,_Privacy,_and_Fairness.md)

    - [翻译: 智能6G网络中的可信AI生成内容：对抗、隐私与公平之考量](2024年05月09日/Trustworthy_AI-Generative_Content_in_Intelligent_6G_Network_Adversarial,_Privacy,_and_Fairness.md)

- [Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?](2024年05月09日/Does_Fine-Tuning_LLMs_on_New_Knowledge_Encourage_Hallucinations.md)

    - [翻译: 微调 LLMs 以吸收新知，是否会催生幻觉？](2024年05月09日/Does_Fine-Tuning_LLMs_on_New_Knowledge_Encourage_Hallucinations.md)

- [Co-driver: VLM-based Autonomous Driving Assistant with Human-like Behavior and Understanding for Complex Road Scenes](2024年05月09日/Co-driver_VLM-based_Autonomous_Driving_Assistant_with_Human-like_Behavior_and_Understanding_for_Complex_Road_Scenes.md)

    - [翻译: 智能副驾：一款基于视觉语言模型的自动驾驶辅助系统，它模仿人类驾驶员的行为，并能深刻理解复杂多变的道路环境。](2024年05月09日/Co-driver_VLM-based_Autonomous_Driving_Assistant_with_Human-like_Behavior_and_Understanding_for_Complex_Road_Scenes.md)

- [FlockGPT: Guiding UAV Flocking with Linguistic Orchestration](2024年05月09日/FlockGPT_Guiding_UAV_Flocking_with_Linguistic_Orchestration.md)

    - [翻译: FlockGPT：以语言学编排之手，引领无人机群舞于天际在翻译过程中，我首先确保了原文的核心概念“FlockGPT”和“语言学编排指导无人机群集”被准确传达。然后，在步骤2中，我采用了更加生动和形象的表达方式，将“指导”转化为“引领”，“无人机群集”转化为“无人机群舞于天际”，以此来增强语言的生动性和优雅性，同时保持了原文的意思不变。](2024年05月09日/FlockGPT_Guiding_UAV_Flocking_with_Linguistic_Orchestration.md)

- [Robots Can Feel: LLM-based Framework for Robot Ethical Reasoning](2024年05月09日/Robots_Can_Feel_LLM-based_Framework_for_Robot_Ethical_Reasoning.md)

    - [翻译: 机器人亦有情：大型语言模型驱动的机器人伦理决策框架在](2024年05月09日/Robots_Can_Feel_LLM-based_Framework_for_Robot_Ethical_Reasoning.md)

- [Boosting Multimodal Large Language Models with Visual Tokens Withdrawal for Rapid Inference](2024年05月09日/Boosting_Multimodal_Large_Language_Models_with_Visual_Tokens_Withdrawal_for_Rapid_Inference.md)

    - [翻译: 借助视觉令牌的巧妙撤回，多模态大型语言模型得以加速推理，如同智慧之光在瞬间闪耀。](2024年05月09日/Boosting_Multimodal_Large_Language_Models_with_Visual_Tokens_Withdrawal_for_Rapid_Inference.md)

- [Towards a More Inclusive AI: Progress and Perspectives in Large Language Model Training for the Sámi Language](2024年05月09日/Towards_a_More_Inclusive_AI_Progress_and_Perspectives_in_Large_Language_Model_Training_for_the_Sámi_Language.md)

    - [翻译: 迈向包容性AI：大型语言模型训练中萨米语的进展与展望](2024年05月09日/Towards_a_More_Inclusive_AI_Progress_and_Perspectives_in_Large_Language_Model_Training_for_the_Sámi_Language.md)

- [Experimental Pragmatics with Machines: Testing LLM Predictions for the Inferences of Plain and Embedded Disjunctions](2024年05月09日/Experimental_Pragmatics_with_Machines_Testing_LLM_Predictions_for_the_Inferences_of_Plain_and_Embedded_Disjunctions.md)

    - [翻译: 机器实验语用学：探究大型语言模型在解析简单与嵌入式析取推理中的预测能力](2024年05月09日/Experimental_Pragmatics_with_Machines_Testing_LLM_Predictions_for_the_Inferences_of_Plain_and_Embedded_Disjunctions.md)

- [Large Language Model-Aided Evolutionary Search for Constrained Multiobjective Optimization](2024年05月09日/Large_Language_Model-Aided_Evolutionary_Search_for_Constrained_Multiobjective_Optimization.md)

    - [翻译: 借助大型语言模型之力，进化搜索在约束多目标优化领域展翅高飞。](2024年05月09日/Large_Language_Model-Aided_Evolutionary_Search_for_Constrained_Multiobjective_Optimization.md)

- [Similarity Guided Multimodal Fusion Transformer for Semantic Location Prediction in Social Media](2024年05月09日/Similarity_Guided_Multimodal_Fusion_Transformer_for_Semantic_Location_Prediction_in_Social_Media.md)

    - [翻译: 基于相似性引导的多模态融合变压器，用于社交媒体中语义位置的精准预测。](2024年05月09日/Similarity_Guided_Multimodal_Fusion_Transformer_for_Semantic_Location_Prediction_in_Social_Media.md)

- [Exploring the Potential of Human-LLM Synergy in Advancing Qualitative Analysis: A Case Study on Mental-Illness Stigma](2024年05月09日/Exploring_the_Potential_of_Human-LLM_Synergy_in_Advancing_Qualitative_Analysis_A_Case_Study_on_Mental-Illness_Stigma.md)

    - [翻译: 揭秘人机共舞：大型语言模型助力定性分析新篇章——以心理疾病污名化研究为例](2024年05月09日/Exploring_the_Potential_of_Human-LLM_Synergy_in_Advancing_Qualitative_Analysis_A_Case_Study_on_Mental-Illness_Stigma.md)

- [Can large language models understand uncommon meanings of common words?](2024年05月09日/Can_large_language_models_understand_uncommon_meanings_of_common_words.md)

    - [翻译: 大型语言模型是否能洞察常见词汇的隐秘含义？](2024年05月09日/Can_large_language_models_understand_uncommon_meanings_of_common_words.md)

- [Detecting Statements in Text: A Domain-Agnostic Few-Shot Solution](2024年05月09日/Detecting_Statements_in_Text_A_Domain-Agnostic_Few-Shot_Solution.md)

    - [翻译: 声明检测：跨领域少量样本的通用解决方案在翻译过程中，我首先确保了原文意思的准确传达，然后对翻译进行了优化，使其更符合中文的表达习惯，同时保持了原文的简洁性和生动性。](2024年05月09日/Detecting_Statements_in_Text_A_Domain-Agnostic_Few-Shot_Solution.md)

- [Letter to the Editor: What are the legal and ethical considerations of submitting radiology reports to ChatGPT?](2024年05月09日/Letter_to_the_Editor_What_are_the_legal_and_ethical_considerations_of_submitting_radiology_reports_to_ChatGPT.md)

    - [翻译: 编辑大人，关于将放射学报告提交至ChatGPT，我们需深思其法律与伦理的边界。此举涉及的法规遵循与道德考量，值得我们共同探讨。](2024年05月09日/Letter_to_the_Editor_What_are_the_legal_and_ethical_considerations_of_submitting_radiology_reports_to_ChatGPT.md)

- [An Automatic Prompt Generation System for Tabular Data Tasks](2024年05月09日/An_Automatic_Prompt_Generation_System_for_Tabular_Data_Tasks.md)

    - [翻译: 表格数据任务的智能提示生成系统在这个系统中，我们将探索如何自动生成有效的提示，以帮助用户更好地理解和处理表格数据。通过智能算法，系统能够识别数据的关键特征，并据此生成针对性的提示，从而提高用户在处理表格数据任务时的效率和准确性。](2024年05月09日/An_Automatic_Prompt_Generation_System_for_Tabular_Data_Tasks.md)

- [Memory-Space Visual Prompting for Efficient Vision-Language Fine-Tuning](2024年05月09日/Memory-Space_Visual_Prompting_for_Efficient_Vision-Language_Fine-Tuning.md)

    - [翻译: 记忆空间视觉提示：高效视觉语言微调的新途径](2024年05月09日/Memory-Space_Visual_Prompting_for_Efficient_Vision-Language_Fine-Tuning.md)

- [Chain of Attack: a Semantic-Driven Contextual Multi-Turn attacker for LLM](2024年05月09日/Chain_of_Attack_a_Semantic-Driven_Contextual_Multi-Turn_attacker_for_LLM.md)

    - [翻译: 语义驱动攻击链：针对大型语言模型的多轮上下文攻击策略在](2024年05月09日/Chain_of_Attack_a_Semantic-Driven_Contextual_Multi-Turn_attacker_for_LLM.md)

- [Can We Use Large Language Models to Fill Relevance Judgment Holes?](2024年05月09日/Can_We_Use_Large_Language_Models_to_Fill_Relevance_Judgment_Holes.md)

    - [翻译: 大型语言模型能否填补相关性判断的空白？这一问题引发了我们对人工智能在信息检索领域潜力的深思。](2024年05月09日/Can_We_Use_Large_Language_Models_to_Fill_Relevance_Judgment_Holes.md)

- [OpenFactCheck: A Unified Framework for Factuality Evaluation of LLMs](2024年05月09日/OpenFactCheck_A_Unified_Framework_for_Factuality_Evaluation_of_LLMs.md)

    - [翻译: OpenFactCheck：大型语言模型事实性评估的统一框架在翻译过程中，我首先确保了原文意思的准确传达，然后对翻译结果进行了润色，使其更符合中文的表达习惯，同时保持了原文的简洁性和优雅性。](2024年05月09日/OpenFactCheck_A_Unified_Framework_for_Factuality_Evaluation_of_LLMs.md)

- [One vs. Many: Comprehending Accurate Information from Multiple Erroneous and Inconsistent AI Generations](2024年05月09日/One_vs._Many_Comprehending_Accurate_Information_from_Multiple_Erroneous_and_Inconsistent_AI_Generations.md)

    - [翻译: 辨真伪于众说纷纭：从错综复杂的人工智能生成中提炼真知在众多人工智能生成的信息中，我们面临着辨别真伪的挑战。这些信息可能充满错误，且相互之间存在不一致。本研究旨在探索如何在这样复杂的环境中，准确地提取和理解信息，确保我们能够从人工智能的众多声音中，捕捉到最真实、最可靠的知识。](2024年05月09日/One_vs._Many_Comprehending_Accurate_Information_from_Multiple_Erroneous_and_Inconsistent_AI_Generations.md)

- [From Human Judgements to Predictive Models: Unravelling Acceptability in Code-Mixed Sentences](2024年05月09日/From_Human_Judgements_to_Predictive_Models_Unravelling_Acceptability_in_Code-Mixed_Sentences.md)

    - [翻译: 解码人类判断，构建预测模型：探索代码混合语言的可接受性之谜](2024年05月09日/From_Human_Judgements_to_Predictive_Models_Unravelling_Acceptability_in_Code-Mixed_Sentences.md)

- [Investigating Interaction Modes and User Agency in Human-LLM Collaboration for Domain-Specific Data Analysis](2024年05月09日/Investigating_Interaction_Modes_and_User_Agency_in_Human-LLM_Collaboration_for_Domain-Specific_Data_Analysis.md)

    - [翻译: 探究在特定领域数据分析中，人类与LLM协作的交互方式及用户自主权在翻译过程中，我首先确保了原文意思的准确传达，然后对语言进行了优化，使其更加符合中文的表达习惯，同时保持了原文的生动性和简洁性。](2024年05月09日/Investigating_Interaction_Modes_and_User_Agency_in_Human-LLM_Collaboration_for_Domain-Specific_Data_Analysis.md)

- [Lumina-T2X: Transforming Text into Any Modality, Resolution, and Duration via Flow-based Large Diffusion Transformers](2024年05月09日/Lumina-T2X_Transforming_Text_into_Any_Modality,_Resolution,_and_Duration_via_Flow-based_Large_Diffusion_Transformers.md)

    - [翻译: Lumina-T2X：借助基于流的巨型扩散变换器，将文本灵活转换为多样化的模态、高分辨率及任意时长，开启文本表达的新纪元。](2024年05月09日/Lumina-T2X_Transforming_Text_into_Any_Modality,_Resolution,_and_Duration_via_Flow-based_Large_Diffusion_Transformers.md)

- [Transformer Architecture for NetsDB](2024年05月09日/Transformer_Architecture_for_NetsDB.md)

    - [翻译: NetsDB 采用 Transformer 架构，该架构在自然语言处理领域展现了卓越的性能，为数据处理和分析提供了强大的支持。](2024年05月09日/Transformer_Architecture_for_NetsDB.md)

- [SKVQ: Sliding-window Key and Value Cache Quantization for Large Language Models](2024年05月09日/SKVQ_Sliding-window_Key_and_Value_Cache_Quantization_for_Large_Language_Models.md)

    - [翻译: SKVQ：大型语言模型的滑动窗口键值缓存量化技术，通过精妙的量化策略，优化了模型的缓存效率，为语言模型的性能提升开辟了新的道路。](2024年05月09日/SKVQ_Sliding-window_Key_and_Value_Cache_Quantization_for_Large_Language_Models.md)

- [A Survey on RAG Meets LLMs: Towards Retrieval-Augmented Large Language Models](2024年05月09日/A_Survey_on_RAG_Meets_LLMs_Towards_Retrieval-Augmented_Large_Language_Models.md)

    - [翻译: 《RAG与大型语言模型：探索检索增强型LLM之路》调研报告](2024年05月09日/A_Survey_on_RAG_Meets_LLMs_Towards_Retrieval-Augmented_Large_Language_Models.md)

- [VLSM-Adapter: Finetuning Vision-Language Segmentation Efficiently with Lightweight Blocks](2024年05月09日/VLSM-Adapter_Finetuning_Vision-Language_Segmentation_Efficiently_with_Lightweight_Blocks.md)

    - [翻译: VLSM-Adapter：以轻巧之姿，高效微调视觉与语言的分割艺术](2024年05月09日/VLSM-Adapter_Finetuning_Vision-Language_Segmentation_Efficiently_with_Lightweight_Blocks.md)

- [Muting Whisper: A Universal Acoustic Adversarial Attack on Speech Foundation Models](2024年05月09日/Muting_Whisper_A_Universal_Acoustic_Adversarial_Attack_on_Speech_Foundation_Models.md)

    - [翻译: 《沉默之声：对语音基础模型发起的通用声学对抗攻击》](2024年05月09日/Muting_Whisper_A_Universal_Acoustic_Adversarial_Attack_on_Speech_Foundation_Models.md)

- [Transforming the Bootstrap: Using Transformers to Compute Scattering Amplitudes in Planar N = 4 Super Yang-Mills Theory](2024年05月09日/Transforming_the_Bootstrap_Using_Transformers_to_Compute_Scattering_Amplitudes_in_Planar_N_=_4_Super_Yang-Mills_Theory.md)

    - [翻译: 变压器的引入为平面N = 4超杨-米尔斯理论中的散射振幅计算带来了革新，打破了传统引导程序的局限。](2024年05月09日/Transforming_the_Bootstrap_Using_Transformers_to_Compute_Scattering_Amplitudes_in_Planar_N_=_4_Super_Yang-Mills_Theory.md)

- [Can Perplexity Reflect Large Language Model's Ability in Long Text Understanding?](2024年05月09日/Can_Perplexity_Reflect_Large_Language_Model's_Ability_in_Long_Text_Understanding.md)

    - [翻译: 大型语言模型的困惑度是否是其长文本理解能力的晴雨表？](2024年05月09日/Can_Perplexity_Reflect_Large_Language_Model's_Ability_in_Long_Text_Understanding.md)

- [Selective Fine-tuning on LLM-labeled Data May Reduce Reliance on Human Annotation: A Case Study Using Schedule-of-Event Table Detection](2024年05月09日/Selective_Fine-tuning_on_LLM-labeled_Data_May_Reduce_Reliance_on_Human_Annotation_A_Case_Study_Using_Schedule-of-Event_Table_Detection.md)

    - [翻译: 通过在LLM标注数据上进行精准微调，我们或许能减少对人工标注的依赖，正如我们在事件时间表检测案例研究中所探索的。这一策略不仅提升了效率，也为自动化标注开辟了新途径。](2024年05月09日/Selective_Fine-tuning_on_LLM-labeled_Data_May_Reduce_Reliance_on_Human_Annotation_A_Case_Study_Using_Schedule-of-Event_Table_Detection.md)

- [Believing Anthropomorphism: Examining the Role of Anthropomorphic Cues on Trust in Large Language Models](2024年05月09日/Believing_Anthropomorphism_Examining_the_Role_of_Anthropomorphic_Cues_on_Trust_in_Large_Language_Models.md)

    - [翻译: 拟人化信任：揭示大语言模型中拟人化线索对信任的影响在这项研究中，我们将深入探讨拟人化线索如何塑造用户对大型语言模型的信任感，揭示这一现象背后的心理机制，并探索如何优化模型设计以增强用户信任。](2024年05月09日/Believing_Anthropomorphism_Examining_the_Role_of_Anthropomorphic_Cues_on_Trust_in_Large_Language_Models.md)

- [HMT: Hierarchical Memory Transformer for Long Context Language Processing](2024年05月09日/HMT_Hierarchical_Memory_Transformer_for_Long_Context_Language_Processing.md)

    - [翻译: 层次记忆变压器（HMT）：专为长篇语言处理而设计在这篇文章中，我们将探讨层次记忆变压器（HMT），这是一种创新的技术，旨在处理长篇语言上下文，以提升自然语言处理任务的性能。HMT通过其独特的层次结构记忆机制，能够捕捉和处理更广泛的语言上下文信息，从而在处理复杂语言任务时展现出卓越的能力。](2024年05月09日/HMT_Hierarchical_Memory_Transformer_for_Long_Context_Language_Processing.md)

- [LLMs for XAI: Future Directions for Explaining Explanations](2024年05月09日/LLMs_for_XAI_Future_Directions_for_Explaining_Explanations.md)

    - [翻译: 大型语言模型在可解释人工智能中的应用：探索解释解释的未来发展路径](2024年05月09日/LLMs_for_XAI_Future_Directions_for_Explaining_Explanations.md)

- [Supporting Physical Activity Behavior Change with LLM-Based Conversational Agents](2024年05月09日/Supporting_Physical_Activity_Behavior_Change_with_LLM-Based_Conversational_Agents.md)

    - [翻译: 借助大型语言模型（LLM）赋能的对话伙伴，助力身体活动行为转变在这篇文章中，我们将探讨如何利用大型语言模型（LLM）开发的智能对话代理，来激励和支持人们改变他们的身体活动习惯。这些智能伙伴能够理解用户的意图，提供个性化的建议，并在用户追求更健康生活方式的过程中提供持续的鼓励和指导。](2024年05月09日/Supporting_Physical_Activity_Behavior_Change_with_LLM-Based_Conversational_Agents.md)

- [Large Language Models Show Human-like Social Desirability Biases in Survey Responses](2024年05月09日/Large_Language_Models_Show_Human-like_Social_Desirability_Biases_in_Survey_Responses.md)

    - [翻译: 大型语言模型在调查回复中显露出与人类相似的社会期望倾向，这表明它们在模拟人类社会行为方面取得了显著进展。然而，这种偏差的存在也引发了对模型在处理敏感问题时可能产生的误导性影响的担忧。](2024年05月09日/Large_Language_Models_Show_Human-like_Social_Desirability_Biases_in_Survey_Responses.md)

- [Time complexity for deterministic string machines](2024年05月09日/Time_complexity_for_deterministic_string_machines.md)

    - [翻译: 确定性字符串机器的运算效率分析](2024年05月09日/Time_complexity_for_deterministic_string_machines.md)

- [Binary Hypothesis Testing for Softmax Models and Leverage Score Models](2024年05月09日/Binary_Hypothesis_Testing_for_Softmax_Models_and_Leverage_Score_Models.md)

    - [翻译: Softmax模型与杠杆分数模型的二元假设检验探索](2024年05月09日/Binary_Hypothesis_Testing_for_Softmax_Models_and_Leverage_Score_Models.md)

- [LLM-QBench: A Benchmark Towards the Best Practice for Post-training Quantization of Large Language Models](2024年05月09日/LLM-QBench_A_Benchmark_Towards_the_Best_Practice_for_Post-training_Quantization_of_Large_Language_Models.md)

    - [翻译: LLM-QBench：大型语言模型后训练量化实践的标杆在这项研究中，我们提出了 LLM-QBench，这是一个旨在为大型语言模型的后训练量化提供最佳实践的基准。通过 LLM-QBench，我们旨在探索和评估不同量化策略对模型性能的影响，从而为实际应用中的模型优化提供指导。](2024年05月09日/LLM-QBench_A_Benchmark_Towards_the_Best_Practice_for_Post-training_Quantization_of_Large_Language_Models.md)

- [LLMPot: Automated LLM-based Industrial Protocol and Physical Process Emulation for ICS Honeypots](2024年05月09日/LLMPot_Automated_LLM-based_Industrial_Protocol_and_Physical_Process_Emulation_for_ICS_Honeypots.md)

    - [翻译: LLMPot：利用LLM自动化模拟工业协议与物理过程，为ICS蜜罐打造智能防护盾解释：在结果2中，我采用了更加生动和形象的表达方式，将“自动化模拟”比喻为“打造智能防护盾”，使得翻译更加符合中文的表达习惯，同时也增强了语言的吸引力和表现力。](2024年05月09日/LLMPot_Automated_LLM-based_Industrial_Protocol_and_Physical_Process_Emulation_for_ICS_Honeypots.md)

- [Unveiling the Competitive Dynamics: A Comparative Evaluation of American and Chinese LLMs](2024年05月09日/Unveiling_the_Competitive_Dynamics_A_Comparative_Evaluation_of_American_and_Chinese_LLMs.md)

    - [翻译: 揭秘中美大型语言模型的较量：一场深入的比较评估在这次深入的比较评估中，我们将揭示美国和中国大型语言模型之间的竞争动态，探索它们在性能、创新和应用方面的差异与共性，以及它们如何塑造全球人工智能的未来。](2024年05月09日/Unveiling_the_Competitive_Dynamics_A_Comparative_Evaluation_of_American_and_Chinese_LLMs.md)

- [Exploring the Capabilities of Large Multimodal Models on Dense Text](2024年05月09日/Exploring_the_Capabilities_of_Large_Multimodal_Models_on_Dense_Text.md)

    - [翻译: 探究大型多模态模型在处理密集文本时的潜能](2024年05月09日/Exploring_the_Capabilities_of_Large_Multimodal_Models_on_Dense_Text.md)

2024年05月08日

- [THRONE: An Object-based Hallucination Benchmark for the Free-form Generations of Large Vision-Language Models](2024年05月08日/THRONE_An_Object-based_Hallucination_Benchmark_for_the_Free-form_Generations_of_Large_Vision-Language_Models.md)

    - [翻译: THRONE：大型视觉-语言模型自由形式生成的对象幻觉基准在这篇文章中，我们将介绍 THRONE，这是一个专门为大型视觉-语言模型设计的基于对象的幻觉基准。THRONE 旨在评估这些模型在自由形式生成任务中的表现，特别是在处理复杂场景和对象时的幻觉能力。通过 THRONE，我们希望推动视觉-语言模型在理解和生成更加丰富、多样化的内容方面的进步，同时揭示模型在处理幻觉时的潜在挑战和局限性。](2024年05月08日/THRONE_An_Object-based_Hallucination_Benchmark_for_the_Free-form_Generations_of_Large_Vision-Language_Models.md)

- [You Only Cache Once: Decoder-Decoder Architectures for Language Models](2024年05月08日/You_Only_Cache_Once_Decoder-Decoder_Architectures_for_Language_Models.md)

    - [翻译: 一缓存，解码双全：语言模型中的解码器-解码器架构新探在](2024年05月08日/You_Only_Cache_Once_Decoder-Decoder_Architectures_for_Language_Models.md)

- [Open Source Language Models Can Provide Feedback: Evaluating LLMs' Ability to Help Students Using GPT-4-As-A-Judge](2024年05月08日/Open_Source_Language_Models_Can_Provide_Feedback_Evaluating_LLMs'_Ability_to_Help_Students_Using_GPT-4-As-A-Judge.md)

    - [翻译: 开源语言模型助力学习：探究GPT-4作为公正评判，如何提升大型语言模型在教育辅导中的反馈能力。](2024年05月08日/Open_Source_Language_Models_Can_Provide_Feedback_Evaluating_LLMs'_Ability_to_Help_Students_Using_GPT-4-As-A-Judge.md)

- [LLMs with Personalities in Multi-issue Negotiation Games](2024年05月08日/LLMs_with_Personalities_in_Multi-issue_Negotiation_Games.md)

    - [翻译: 个性化的LLMs在多议题谈判游戏中展现风采在这项研究中，我们探讨了具有不同个性的语言模型在多议题谈判游戏中的表现。通过赋予LLMs独特的性格特征，我们旨在模拟更真实的谈判场景，并分析这些个性如何影响谈判策略和结果。我们的实验结果揭示了个性化的LLMs在理解和适应复杂谈判环境方面的潜力，以及它们如何通过展现不同的谈判风格来达成更有利的协议。](2024年05月08日/LLMs_with_Personalities_in_Multi-issue_Negotiation_Games.md)

- [SuFIA: Language-Guided Augmented Dexterity for Robotic Surgical Assistants](2024年05月08日/SuFIA_Language-Guided_Augmented_Dexterity_for_Robotic_Surgical_Assistants.md)

    - [翻译: SuFIA：赋予机器人手术助手语言引导的灵巧增强能力在这项研究中，我们提出了SuFIA，一种新颖的框架，旨在通过语言指令增强机器人手术助手的操作灵巧性。SuFIA利用先进的自然语言处理技术，使机器人能够理解并执行复杂的手术任务，从而提高手术效率和精确度。我们的方法结合了深度学习和机器人控制技术，为机器人手术助手在多变的手术环境中提供了更高的适应性和灵活性。通过在实际手术场景中的应用，SuFIA展现了其在提升手术质量和安全性方面的巨大潜力。](2024年05月08日/SuFIA_Language-Guided_Augmented_Dexterity_for_Robotic_Surgical_Assistants.md)

- [Conv-Basis: A New Paradigm for Efficient Attention Inference and Gradient Computation in Transformers](2024年05月08日/Conv-Basis_A_New_Paradigm_for_Efficient_Attention_Inference_and_Gradient_Computation_in_Transformers.md)

    - [翻译: Conv-Basis：开创Transformer高效注意力推理与梯度计算的新纪元在这项研究中，我们提出了一种名为Conv-Basis的新方法，它为Transformer模型中的注意力推理和梯度计算提供了一种更为高效的处理方式。通过引入这一新范式，我们旨在优化Transformer的计算效率，同时保持其在自然语言处理任务中的卓越性能。](2024年05月08日/Conv-Basis_A_New_Paradigm_for_Efficient_Attention_Inference_and_Gradient_Computation_in_Transformers.md)

- [MIDGARD: Self-Consistency Using Minimum Description Length for Structured Commonsense Reasoning](2024年05月08日/MIDGARD_Self-Consistency_Using_Minimum_Description_Length_for_Structured_Commonsense_Reasoning.md)

    - [翻译: MIDGARD：运用最小描述长度原则，实现结构化常识推理的自洽性在翻译过程中，我首先确保了原文意思的准确传达，然后对翻译结果进行了润色，使其更符合中文的表达习惯，同时保持了原文的学术性和专业性。](2024年05月08日/MIDGARD_Self-Consistency_Using_Minimum_Description_Length_for_Structured_Commonsense_Reasoning.md)

- [Air Gap: Protecting Privacy-Conscious Conversational Agents](2024年05月08日/Air_Gap_Protecting_Privacy-Conscious_Conversational_Agents.md)

    - [翻译: 隐私守护者：空气间隙技术在对话代理中的应用在翻译过程中，我首先确保了原文意思的准确传达，然后对语言进行了优化，使其更加符合中文的表达习惯，同时保持了原文的生动性和简洁性。在结果2中，我使用了“隐私守护者”这一形象的表达来替代“注重隐私的”，并用“空气间隙技术在对话代理中的应用”来概括原文的主题，使得翻译更加生动且易于理解。](2024年05月08日/Air_Gap_Protecting_Privacy-Conscious_Conversational_Agents.md)

- [XAMPLER: Learning to Retrieve Cross-Lingual In-Context Examples](2024年05月08日/XAMPLER_Learning_to_Retrieve_Cross-Lingual_In-Context_Examples.md)

    - [翻译: XAMPLER：掌握跨语言上下文示例的检索艺术](2024年05月08日/XAMPLER_Learning_to_Retrieve_Cross-Lingual_In-Context_Examples.md)

- [QFMTS: Generating Query-Focused Summaries over Multi-Table Inputs](2024年05月08日/QFMTS_Generating_Query-Focused_Summaries_over_Multi-Table_Inputs.md)

    - [翻译: QFMTS：聚焦查询，从多表数据中提炼精华摘要在翻译过程中，我首先确保了原文信息的准确传达，然后对语言进行了优化，使其更加符合中文的表达习惯，同时保持了原文的生动性和简洁性。](2024年05月08日/QFMTS_Generating_Query-Focused_Summaries_over_Multi-Table_Inputs.md)

- [Concerns on Bias in Large Language Models when Creating Synthetic Personae](2024年05月08日/Concerns_on_Bias_in_Large_Language_Models_when_Creating_Synthetic_Personae.md)

    - [翻译: 大型语言模型在塑造虚拟人物时，其潜在的偏见问题日益受到关注。](2024年05月08日/Concerns_on_Bias_in_Large_Language_Models_when_Creating_Synthetic_Personae.md)

- [Impact of Tone-Aware Explanations in Recommender Systems](2024年05月08日/Impact_of_Tone-Aware_Explanations_in_Recommender_Systems.md)

    - [翻译: 推荐系统中，音调感知解释的深远影响在推荐系统中，音调感知解释的深远影响正逐渐显现。这种新颖的方法不仅提升了用户体验，还增强了推荐结果的可信度。通过捕捉用户反馈中的情感色彩，系统能够提供更加个性化和情感共鸣的推荐理由，从而在用户心中建立起更深层次的信任与满意度。](2024年05月08日/Impact_of_Tone-Aware_Explanations_in_Recommender_Systems.md)

- [Conversational Topic Recommendation in Counseling and Psychotherapy with Decision Transformer and Large Language Models](2024年05月08日/Conversational_Topic_Recommendation_in_Counseling_and_Psychotherapy_with_Decision_Transformer_and_Large_Language_Models.md)

    - [翻译: 运用决策转换器与大型语言模型，为咨询与心理治疗中的对话提供精准主题推荐在咨询与心理治疗领域，对话主题的推荐对于引导会话、深化理解至关重要。本研究采用决策转换器与大型语言模型相结合的先进技术，旨在为专业人士提供精准、个性化的对话主题推荐，以促进更有效的沟通与治疗进程。通过分析患者的语言模式与情感状态，系统能够智能生成符合治疗目标的对话主题，为心理健康服务带来创新与效率的提升。](2024年05月08日/Conversational_Topic_Recommendation_in_Counseling_and_Psychotherapy_with_Decision_Transformer_and_Large_Language_Models.md)

- [Seeds of Stereotypes: A Large-Scale Textual Analysis of Race and Gender Associations with Diseases in Online Sources](2024年05月08日/Seeds_of_Stereotypes_A_Large-Scale_Textual_Analysis_of_Race_and_Gender_Associations_with_Diseases_in_Online_Sources.md)

    - [翻译: 刻板印象之源：在线资源中种族与性别疾病关联的大规模文本探析](2024年05月08日/Seeds_of_Stereotypes_A_Large-Scale_Textual_Analysis_of_Race_and_Gender_Associations_with_Diseases_in_Online_Sources.md)

- [ADELIE: Aligning Large Language Models on Information Extraction](2024年05月08日/ADELIE_Aligning_Large_Language_Models_on_Information_Extraction.md)

    - [翻译: ADELIE：大型语言模型在信息抽取领域的精准对齐在翻译过程中，我首先确保原文的核心意义被准确传达，即“ADELIE”是一个关于大型语言模型在信息抽取任务上进行对齐的项目或方法。然后，我调整了语言表达，使其更加符合中文的表达习惯，同时保持了原文的专业性和简洁性。](2024年05月08日/ADELIE_Aligning_Large_Language_Models_on_Information_Extraction.md)

- [NAVRepair: Node-type Aware C/C++ Code Vulnerability Repair](2024年05月08日/NAVRepair_Node-type_Aware_CC++_Code_Vulnerability_Repair.md)

    - [翻译: NAVRepair：智能修复C/C++代码漏洞，精准识别节点类型，为您的代码安全护航。](2024年05月08日/NAVRepair_Node-type_Aware_CC++_Code_Vulnerability_Repair.md)

- [P-ICL: Point In-Context Learning for Named Entity Recognition with Large Language Models](2024年05月08日/P-ICL_Point_In-Context_Learning_for_Named_Entity_Recognition_with_Large_Language_Models.md)

    - [翻译: P-ICL：大型语言模型在命名实体识别中的精准上下文学习在这个翻译中，我采用了“精准”一词来替代“点式”，以使中文表达更加生动和符合中文的表达习惯。同时，“精准上下文学习”也更好地传达了原文中P-ICL方法的特性，即在大型语言模型中针对命名实体识别任务进行精确的上下文信息利用。](2024年05月08日/P-ICL_Point_In-Context_Learning_for_Named_Entity_Recognition_with_Large_Language_Models.md)

- [Harnessing the Power of MLLMs for Transferable Text-to-Image Person ReID](2024年05月08日/Harnessing_the_Power_of_MLLMs_for_Transferable_Text-to-Image_Person_ReID.md)

    - [翻译: 驾驭多模态大型语言模型的力量，实现文本到图像人物再识别的可转移性在翻译过程中，我首先确保了原文意思的准确传达，然后对翻译进行了润色，使其更符合中文的表达习惯，同时保持了原文的生动性和简洁性。](2024年05月08日/Harnessing_the_Power_of_MLLMs_for_Transferable_Text-to-Image_Person_ReID.md)

- [Traj-LLM: A New Exploration for Empowering Trajectory Prediction with Pre-trained Large Language Models](2024年05月08日/Traj-LLM_A_New_Exploration_for_Empowering_Trajectory_Prediction_with_Pre-trained_Large_Language_Models.md)

    - [翻译: 轨迹增强语言模型（Traj-LLM）：探索预训练大型语言模型在轨迹预测领域的创新应用](2024年05月08日/Traj-LLM_A_New_Exploration_for_Empowering_Trajectory_Prediction_with_Pre-trained_Large_Language_Models.md)

- [The Codecfake Dataset and Countermeasures for the Universally Detection of Deepfake Audio](2024年05月08日/The_Codecfake_Dataset_and_Countermeasures_for_the_Universally_Detection_of_Deepfake_Audio.md)

    - [翻译: Codecfake数据集与深度伪造音频检测的通用对策在这项研究中，我们介绍了Codecfake数据集，这是一个专为深度伪造音频检测而设计的新型数据集。我们的目标是提供一个全面的资源，以帮助研究人员开发和测试针对深度伪造音频的检测算法。此外，我们还探讨了一系列反制措施，旨在提高检测算法的鲁棒性和准确性，以应对不断进化的深度伪造技术。通过结合数据集和反制措施，我们希望推动该领域的研究，并为保护公众免受深度伪造音频的潜在威胁做出贡献。](2024年05月08日/The_Codecfake_Dataset_and_Countermeasures_for_the_Universally_Detection_of_Deepfake_Audio.md)

- [Critical Infrastructure Protection: Generative AI, Challenges, and Opportunities](2024年05月08日/Critical_Infrastructure_Protection_Generative_AI,_Challenges,_and_Opportunities.md)

    - [翻译: 守护关键基石：生成式AI的挑战与机遇在翻译过程中，我首先确保了原文核心概念的准确传达，即“关键基础设施保护”与“生成式人工智能”。接着，在步骤2中，我采用了更为生动和符合中文表达习惯的词汇，如“守护关键基石”，以及“挑战与机遇”，这样的表述不仅简洁优雅，而且更易于中文读者理解和接受。](2024年05月08日/Critical_Infrastructure_Protection_Generative_AI,_Challenges,_and_Opportunities.md)

- [Federated Adaptation for Foundation Model-based Recommendations](2024年05月08日/Federated_Adaptation_for_Foundation_Model-based_Recommendations.md)

    - [翻译: 基于基础模型的推荐系统的联邦适应性研究在翻译过程中，我首先直接将英文标题翻译为中文，确保意思的准确传达。然后，我进一步优化翻译，使其更加符合中文的表达习惯，简洁而优雅，同时保持了原标题的学术性和专业性。](2024年05月08日/Federated_Adaptation_for_Foundation_Model-based_Recommendations.md)

- [APrompt4EM: Augmented Prompt Tuning for Generalized Entity Matching](2024年05月08日/APrompt4EM_Augmented_Prompt_Tuning_for_Generalized_Entity_Matching.md)

    - [翻译: APrompt4EM：通用实体匹配的增强提示调优技术](2024年05月08日/APrompt4EM_Augmented_Prompt_Tuning_for_Generalized_Entity_Matching.md)

- [DALK: Dynamic Co-Augmentation of LLMs and KG to answer Alzheimer's Disease Questions with Scientific Literature](2024年05月08日/DALK_Dynamic_Co-Augmentation_of_LLMs_and_KG_to_answer_Alzheimer's_Disease_Questions_with_Scientific_Literature.md)

    - [翻译: DALK：通过动态协同增强 LLMs 与 KG，精准解答阿尔茨海默病相关的科学文献问题。](2024年05月08日/DALK_Dynamic_Co-Augmentation_of_LLMs_and_KG_to_answer_Alzheimer's_Disease_Questions_with_Scientific_Literature.md)

- [ACORN: Aspect-wise Commonsense Reasoning Explanation Evaluation](2024年05月08日/ACORN_Aspect-wise_Commonsense_Reasoning_Explanation_Evaluation.md)

    - [翻译: ACORN：细粒度常识推理解释评价在这个翻译中，我首先直接将英文标题翻译为中文，确保了意思的准确传达。然后，在第二步中，我采用了更符合中文表达习惯的词汇，将“Aspect-wise”翻译为“细粒度”，使得标题更加简洁优雅，同时保持了原意。这样的翻译既符合中文的表达习惯，又能够生动地传达原文的核心概念。](2024年05月08日/ACORN_Aspect-wise_Commonsense_Reasoning_Explanation_Evaluation.md)

- [VisionGraph: Leveraging Large Multimodal Models for Graph Theory Problems in Visual Context](2024年05月08日/VisionGraph_Leveraging_Large_Multimodal_Models_for_Graph_Theory_Problems_in_Visual_Context.md)

    - [翻译: 视觉图谱：借助大型多模态模型，探索视觉场景中的图论难题。](2024年05月08日/VisionGraph_Leveraging_Large_Multimodal_Models_for_Graph_Theory_Problems_in_Visual_Context.md)

- [Benchmarking Neural Radiance Fields for Autonomous Robots: An Overview](2024年05月08日/Benchmarking_Neural_Radiance_Fields_for_Autonomous_Robots_An_Overview.md)

    - [翻译: 自主机器人神经辐射场性能基准：全面概览](2024年05月08日/Benchmarking_Neural_Radiance_Fields_for_Autonomous_Robots_An_Overview.md)

- [Redefining Information Retrieval of Structured Database via Large Language Models](2024年05月08日/Redefining_Information_Retrieval_of_Structured_Database_via_Large_Language_Models.md)

    - [翻译: 大型语言模型重塑结构化数据库信息检索新篇章](2024年05月08日/Redefining_Information_Retrieval_of_Structured_Database_via_Large_Language_Models.md)

- [Cross-Care: Assessing the Healthcare Implications of Pre-training Data on Language Model Bias](2024年05月08日/Cross-Care_Assessing_the_Healthcare_Implications_of_Pre-training_Data_on_Language_Model_Bias.md)

    - [翻译: 跨医疗关怀：探究预训练数据如何塑造语言模型偏见，及其对医疗领域的深远影响在这项研究中，我们将深入探讨预训练数据如何影响语言模型的偏见，并分析这些偏见如何渗透到医疗决策中，从而对患者的护理产生潜在影响。我们的目标是揭示这些偏见的根源，并提出策略以减轻其对医疗保健系统的负面影响。](2024年05月08日/Cross-Care_Assessing_the_Healthcare_Implications_of_Pre-training_Data_on_Language_Model_Bias.md)

- [Boosting Large Language Models with Continual Learning for Aspect-based Sentiment Analysis](2024年05月08日/Boosting_Large_Language_Models_with_Continual_Learning_for_Aspect-based_Sentiment_Analysis.md)

    - [翻译: 借助持续学习，强化大型语言模型在基于方面的情感分析领域的应用在翻译过程中，我首先确保原文的核心意义被准确传达，即“通过持续学习提升大型语言模型在基于方面的情感分析中的性能”。随后，我进一步优化表达，使其更符合中文的流畅性和优雅性，形成了“借助持续学习，强化大型语言模型在基于方面的情感分析领域的应用”的翻译。这样的翻译既保留了原文的技术性，又增添了中文表达的生动性和简洁性。](2024年05月08日/Boosting_Large_Language_Models_with_Continual_Learning_for_Aspect-based_Sentiment_Analysis.md)

- [PLLM-CS: Pre-trained Large Language Model (LLM) for Cyber Threat Detection in Satellite Networks](2024年05月08日/PLLM-CS_Pre-trained_Large_Language_Model_(LLM)_for_Cyber_Threat_Detection_in_Satellite_Networks.md)

    - [翻译: PLLM-CS：专为卫星网络安全威胁检测而设计的预训练大型语言模型，旨在通过先进的语言处理技术，提升对潜在网络风险的识别与防御能力。](2024年05月08日/PLLM-CS_Pre-trained_Large_Language_Model_(LLM)_for_Cyber_Threat_Detection_in_Satellite_Networks.md)

- [Poser: Unmasking Alignment Faking LLMs by Manipulating Their Internals](2024年05月08日/Poser_Unmasking_Alignment_Faking_LLMs_by_Manipulating_Their_Internals.md)

    - [翻译: 揭秘者：操纵LLMs内部机制，揭示其伪装对齐的真相](2024年05月08日/Poser_Unmasking_Alignment_Faking_LLMs_by_Manipulating_Their_Internals.md)

- [Vidur: A Large-Scale Simulation Framework For LLM Inference](2024年05月08日/Vidur_A_Large-Scale_Simulation_Framework_For_LLM_Inference.md)

    - [翻译: Vidur：大型语言模型推理的大型规模模拟框架在翻译过程中，我首先确保了原文意思的准确传达，然后对翻译进行了优化，使其更符合中文的表达习惯，同时保持了原文的简洁和优雅。](2024年05月08日/Vidur_A_Large-Scale_Simulation_Framework_For_LLM_Inference.md)

- [Automated Program Repair: Emerging trends pose and expose problems for benchmarks](2024年05月08日/Automated_Program_Repair_Emerging_trends_pose_and_expose_problems_for_benchmarks.md)

    - [翻译: 自动化程序修复领域的新兴趋势不仅挑战了现有的基准测试，还揭示了其潜在的局限性。](2024年05月08日/Automated_Program_Repair_Emerging_trends_pose_and_expose_problems_for_benchmarks.md)

- [Large Language Model Enhanced Machine Learning Estimators for Classification](2024年05月08日/Large_Language_Model_Enhanced_Machine_Learning_Estimators_for_Classification.md)

    - [翻译: 大型语言模型赋能的机器学习分类器：精准估计新境界](2024年05月08日/Large_Language_Model_Enhanced_Machine_Learning_Estimators_for_Classification.md)

- [Evaluating Students' Open-ended Written Responses with LLMs: Using the RAG Framework for GPT-3.5, GPT-4, Claude-3, and Mistral-Large](2024年05月08日/Evaluating_Students'_Open-ended_Written_Responses_with_LLMs_Using_the_RAG_Framework_for_GPT-3.5,_GPT-4,_Claude-3,_and_Mistral-Large.md)

    - [翻译: 借助RAG框架，我们评估了GPT-3.5、GPT-4、Claude-3和Mistral-Large在评价学生开放式书面回答方面的表现。本研究旨在探索这些大型语言模型在教育评估中的应用潜力。](2024年05月08日/Evaluating_Students'_Open-ended_Written_Responses_with_LLMs_Using_the_RAG_Framework_for_GPT-3.5,_GPT-4,_Claude-3,_and_Mistral-Large.md)

- [Information Extraction from Historical Well Records Using A Large Language Model](2024年05月08日/Information_Extraction_from_Historical_Well_Records_Using_A_Large_Language_Model.md)

    - [翻译: 大型语言模型助力历史井记录信息抽取在上述翻译过程中，首先直接将英文标题翻译为中文，确保意思的准确传达。接着，对直译结果进行优化，使其更加符合中文的表达习惯，同时保持简洁优雅，并增添了一丝生动性。](2024年05月08日/Information_Extraction_from_Historical_Well_Records_Using_A_Large_Language_Model.md)

- [Mitigating Exaggerated Safety in Large Language Models](2024年05月08日/Mitigating_Exaggerated_Safety_in_Large_Language_Models.md)

    - [翻译: 大型语言模型的安全性问题亟待解决，我们致力于减轻其夸大风险，以确保技术的稳健发展。](2024年05月08日/Mitigating_Exaggerated_Safety_in_Large_Language_Models.md)

- [Fishing for Magikarp: Automatically Detecting Under-trained Tokens in Large Language Models](2024年05月08日/Fishing_for_Magikarp_Automatically_Detecting_Under-trained_Tokens_in_Large_Language_Models.md)

    - [翻译: 《捕捉未熟之鳞：自动识别大型语言模型中的欠训练标记》](2024年05月08日/Fishing_for_Magikarp_Automatically_Detecting_Under-trained_Tokens_in_Large_Language_Models.md)

- ["They are uncultured": Unveiling Covert Harms and Social Threats in LLM Generated Conversations](2024年05月08日/They_are_uncultured_Unveiling_Covert_Harms_and_Social_Threats_in_LLM_Generated_Conversations.md)

    - [翻译: "粗俗之言"：揭示大型语言模型对话背后的隐秘伤害与社会风险](2024年05月08日/They_are_uncultured_Unveiling_Covert_Harms_and_Social_Threats_in_LLM_Generated_Conversations.md)

- [Enhancing Holonic Architecture with Natural Language Processing for System of Systems](2024年05月08日/Enhancing_Holonic_Architecture_with_Natural_Language_Processing_for_System_of_Systems.md)

    - [翻译: 借助自然语言处理，我们优化了整体架构，以提升系统之系统的协同效率。](2024年05月08日/Enhancing_Holonic_Architecture_with_Natural_Language_Processing_for_System_of_Systems.md)

- [The Effect of Model Size on LLM Post-hoc Explainability via LIME](2024年05月08日/The_Effect_of_Model_Size_on_LLM_Post-hoc_Explainability_via_LIME.md)

    - [翻译: 在探索大型语言模型的奥秘时，模型的大小扮演着至关重要的角色。通过 LIME 这一工具，我们能够揭开 LLM 的可解释性之谜。本研究将深入探讨模型大小如何影响 LLM 的可解释性，为理解这些复杂系统的内在工作机制提供新的视角。](2024年05月08日/The_Effect_of_Model_Size_on_LLM_Post-hoc_Explainability_via_LIME.md)

- [Benchmarking Educational Program Repair](2024年05月08日/Benchmarking_Educational_Program_Repair.md)

    - [翻译: 教育程序修复的基准评估在这篇文章中，我们将探讨如何通过基准测试来评估和改进教育程序的修复策略。我们将分析不同的修复方法，并探讨它们在提高教育软件质量和效率方面的潜力。通过这一过程，我们旨在为教育技术领域的专业人士提供有价值的见解，帮助他们更好地理解和优化教育程序的修复工作。](2024年05月08日/Benchmarking_Educational_Program_Repair.md)

- [KV-Runahead: Scalable Causal LLM Inference by Parallel Key-Value Cache Generation](2024年05月08日/KV-Runahead_Scalable_Causal_LLM_Inference_by_Parallel_Key-Value_Cache_Generation.md)

    - [翻译: KV-Runahead：并行生成键值缓存，解锁因果LLM推理的扩展潜能在这项研究中，我们提出了KV-Runahead方法，这是一种新颖的技术，通过并行生成键值缓存来提高大型语言模型（LLM）的因果推理效率。我们的方法解决了传统推理方法中的瓶颈问题，实现了更快的推理速度和更好的可扩展性。通过实验验证，KV-Runahead在保持推理质量的同时，显著提升了LLM的性能。](2024年05月08日/KV-Runahead_Scalable_Causal_LLM_Inference_by_Parallel_Key-Value_Cache_Generation.md)

- [Special Characters Attack: Toward Scalable Training Data Extraction From Large Language Models](2024年05月08日/Special_Characters_Attack_Toward_Scalable_Training_Data_Extraction_From_Large_Language_Models.md)

    - [翻译: 特殊字符攻击：揭秘大型语言模型训练数据的提取之谜在这项研究中，我们探讨了一种新颖的攻击手段——特殊字符攻击，它旨在从大型语言模型中提取训练数据。通过精心设计的特殊字符组合，我们能够揭示模型背后的知识库，为数据隐私和安全带来新的挑战。](2024年05月08日/Special_Characters_Attack_Toward_Scalable_Training_Data_Extraction_From_Large_Language_Models.md)

- [Automated Conversion of Static to Dynamic Scheduler via Natural Language](2024年05月08日/Automated_Conversion_of_Static_to_Dynamic_Scheduler_via_Natural_Language.md)

    - [翻译: 自然语言助力，静态调度器智能升级为动态调度器，自动化转换一触即发。](2024年05月08日/Automated_Conversion_of_Static_to_Dynamic_Scheduler_via_Natural_Language.md)

- [LLM-Augmented Agent-Based Modelling for Social Simulations: Challenges and Opportunities](2024年05月08日/LLM-Augmented_Agent-Based_Modelling_for_Social_Simulations_Challenges_and_Opportunities.md)

    - [翻译: 大型语言模型赋能的代理建模在社交模拟中的探索：挑战与新机遇在大型语言模型的助力下，基于代理的建模技术在社交模拟领域展现出新的挑战与机遇。这种结合不仅为模拟复杂社会动态提供了更强大的工具，也开启了探索人类行为与社会结构的新篇章。然而，这一领域的深入发展仍需面对模型复杂性、数据准确性以及伦理考量等多重挑战。](2024年05月08日/LLM-Augmented_Agent-Based_Modelling_for_Social_Simulations_Challenges_and_Opportunities.md)

2024年05月07日

- [ChatHuman: Language-driven 3D Human Understanding with Retrieval-Augmented Tool Reasoning](2024年05月07日/ChatHuman_Language-driven_3D_Human_Understanding_with_Retrieval-Augmented_Tool_Reasoning.md)

    - [翻译: ChatHuman：借助检索增强的工具推理，实现语言驱动的3D人体理解在这项研究中，我们提出了ChatHuman，一个创新系统，它通过结合语言理解和检索增强的工具推理，实现了对3D人体的深入理解。该系统不仅能够处理复杂的语言指令，还能够利用检索机制来增强其推理能力，从而在3D人体建模和交互任务中展现出卓越的性能。](2024年05月07日/ChatHuman_Language-driven_3D_Human_Understanding_with_Retrieval-Augmented_Tool_Reasoning.md)

- [QServe: W4A8KV4 Quantization and System Co-design for Efficient LLM Serving](2024年05月07日/QServe_W4A8KV4_Quantization_and_System_Co-design_for_Efficient_LLM_Serving.md)

    - [翻译: QServe：W4A8KV4 量化与系统协同设计，为大型语言模型服务提供高效解决方案](2024年05月07日/QServe_W4A8KV4_Quantization_and_System_Co-design_for_Efficient_LLM_Serving.md)

- [NaturalCodeBench: Examining Coding Performance Mismatch on HumanEval and Natural User Prompts](2024年05月07日/NaturalCodeBench_Examining_Coding_Performance_Mismatch_on_HumanEval_and_Natural_User_Prompts.md)

    - [翻译: NaturalCodeBench：探究HumanEval与自然用户提示间编码性能的差异解释：在结果2中，我采用了更加流畅和符合中文表达习惯的翻译方式，将“Examining Coding Performance Mismatch”翻译为“探究编码性能的差异”，使得整个句子更加简洁优雅，同时保留了原文的意思。](2024年05月07日/NaturalCodeBench_Examining_Coding_Performance_Mismatch_on_HumanEval_and_Natural_User_Prompts.md)

- [xLSTM: Extended Long Short-Term Memory](2024年05月07日/xLSTM_Extended_Long_Short-Term_Memory.md)

    - [翻译: xLSTM：拓展版长短期记忆网络在翻译过程中，我首先确保了原文的核心概念“Extended Long Short-Term Memory”被准确地翻译为“扩展的长短期记忆”。接着，在步骤2中，我考虑了中文表达的习惯，将“扩展的”调整为“拓展版”，使得翻译更加符合中文的表达习惯，同时保持了原文的含义和专业性。这样的翻译既简洁又优雅，同时也保持了原文的生动性。](2024年05月07日/xLSTM_Extended_Long_Short-Term_Memory.md)

- [A Transformer with Stack Attention](2024年05月07日/A_Transformer_with_Stack_Attention.md)

    - [翻译: 堆叠注意力机制的Transformer在翻译过程中，我首先直接将英文翻译为中文，确保意思的准确性。然后，我对直译的中文进行了优化，使其更加符合中文的语言表达习惯，同时保持了原文的简洁和优雅。在第二个步骤中，我将“A Transformer with Stack Attention”优化为“堆叠注意力机制的Transformer”，这样的表达更加符合中文的表述习惯，同时也更加生动和易于理解。](2024年05月07日/A_Transformer_with_Stack_Attention.md)

- [Unveiling Disparities in Web Task Handling Between Human and Web Agent](2024年05月07日/Unveiling_Disparities_in_Web_Task_Handling_Between_Human_and_Web_Agent.md)

    - [翻译: 揭秘人类与网络代理在网络任务处理上的差异之谜](2024年05月07日/Unveiling_Disparities_in_Web_Task_Handling_Between_Human_and_Web_Agent.md)

- [Toward In-Context Teaching: Adapting Examples to Students' Misconceptions](2024年05月07日/Toward_In-Context_Teaching_Adapting_Examples_to_Students'_Misconceptions.md)

    - [翻译: 迈向情境化教学：量身定制示例，以纠正学生的认知误区](2024年05月07日/Toward_In-Context_Teaching_Adapting_Examples_to_Students'_Misconceptions.md)

- [The Silicone Ceiling: Auditing GPT's Race and Gender Biases in Hiring](2024年05月07日/The_Silicone_Ceiling_Auditing_GPT's_Race_and_Gender_Biases_in_Hiring.md)

    - [翻译: 硅胶屏障：审视GPT在招聘决策中潜藏的种族与性别偏见](2024年05月07日/The_Silicone_Ceiling_Auditing_GPT's_Race_and_Gender_Biases_in_Hiring.md)

- [Learning To See But Forgetting To Follow: Visual Instruction Tuning Makes LLMs More Prone To Jailbreak Attacks](2024年05月07日/Learning_To_See_But_Forgetting_To_Follow_Visual_Instruction_Tuning_Makes_LLMs_More_Prone_To_Jailbreak_Attacks.md)

    - [翻译: 视觉指令调教下的学习，大型语言模型虽能“看”得更清，却更易在“跟随”指令上失守，从而更易遭受越狱攻击。](2024年05月07日/Learning_To_See_But_Forgetting_To_Follow_Visual_Instruction_Tuning_Makes_LLMs_More_Prone_To_Jailbreak_Attacks.md)

- [Large Language Models Cannot Explain Themselves](2024年05月07日/Large_Language_Models_Cannot_Explain_Themselves.md)

    - [翻译: 巨型语言模型自解谜团难，其内在逻辑尚待深究。](2024年05月07日/Large_Language_Models_Cannot_Explain_Themselves.md)

- [Revisiting character-level adversarial attacks](2024年05月07日/Revisiting_character-level_adversarial_attacks.md)

    - [翻译: 再探字符级对抗攻击：深入分析与挑战](2024年05月07日/Revisiting_character-level_adversarial_attacks.md)

- [A Fourth Wave of Open Data? Exploring the Spectrum of Scenarios for Open Data and Generative AI](2024年05月07日/A_Fourth_Wave_of_Open_Data_Exploring_the_Spectrum_of_Scenarios_for_Open_Data_and_Generative_AI.md)

    - [翻译: 开放数据的第四波浪潮？我们正探索开放数据与生成式AI交织的多元场景。](2024年05月07日/A_Fourth_Wave_of_Open_Data_Exploring_the_Spectrum_of_Scenarios_for_Open_Data_and_Generative_AI.md)

- [Deception in Reinforced Autonomous Agents: The Unconventional Rabbit Hat Trick in Legislation](2024年05月07日/Deception_in_Reinforced_Autonomous_Agents_The_Unconventional_Rabbit_Hat_Trick_in_Legislation.md)

    - [翻译: 强化自主代理中的欺骗行为：立法中的非传统兔子帽戏法之谜在强化自主代理领域，欺骗行为如同立法中的非传统兔子帽戏法，既神秘又引人入胜。这种行为在自主代理的决策过程中扮演着复杂角色，其影响深远，如同戏法中的兔子，既出人意料又充满变数。本研究将深入探讨这一现象，揭示其在立法框架下的独特影响。](2024年05月07日/Deception_in_Reinforced_Autonomous_Agents_The_Unconventional_Rabbit_Hat_Trick_in_Legislation.md)

- [Granite Code Models: A Family of Open Foundation Models for Code Intelligence](2024年05月07日/Granite_Code_Models_A_Family_of_Open_Foundation_Models_for_Code_Intelligence.md)

    - [翻译: 代码智能之石：花岗岩系列开源基础模型在](2024年05月07日/Granite_Code_Models_A_Family_of_Open_Foundation_Models_for_Code_Intelligence.md)

- [Accelerating Speculative Decoding using Dynamic Speculation Length](2024年05月07日/Accelerating_Speculative_Decoding_using_Dynamic_Speculation_Length.md)

    - [翻译: 动态推测长度优化：加速语言模型解码的新策略在翻译过程中，我首先确保了原文意思的准确传达，然后对语言进行了优化，使其更加符合中文的表达习惯，同时保持了原文的生动性和简洁性。](2024年05月07日/Accelerating_Speculative_Decoding_using_Dynamic_Speculation_Length.md)

- [Enhancing the Efficiency and Accuracy of Underlying Asset Reviews in Structured Finance: The Application of Multi-agent Framework](2024年05月07日/Enhancing_the_Efficiency_and_Accuracy_of_Underlying_Asset_Reviews_in_Structured_Finance_The_Application_of_Multi-agent_Framework.md)

    - [翻译: 结构化金融底层资产审查的效率与准确性提升：多代理框架的巧妙应用在结构化金融领域，底层资产的审查是确保交易稳健性的关键。传统的审查方法往往耗时且准确性有限。然而，多代理框架的引入，如同一场精妙的棋局，每个代理如同棋子，各司其职，协同作战，极大地提升了审查的效率与准确性。这一创新的应用，不仅优化了金融资产的评估流程，也为投资者提供了更为坚实的决策基础。](2024年05月07日/Enhancing_the_Efficiency_and_Accuracy_of_Underlying_Asset_Reviews_in_Structured_Finance_The_Application_of_Multi-agent_Framework.md)

- [Who Wrote This? The Key to Zero-Shot LLM-Generated Text Detection Is GECScore](2024年05月07日/Who_Wrote_This_The_Key_to_Zero-Shot_LLM-Generated_Text_Detection_Is_GECScore.md)

    - [翻译: 这篇文章的作者是谁？GECScore 是识别零-shot LLM 生成文本的关键工具。](2024年05月07日/Who_Wrote_This_The_Key_to_Zero-Shot_LLM-Generated_Text_Detection_Is_GECScore.md)

- [Semantic API Alignment: Linking High-level User Goals to APIs](2024年05月07日/Semantic_API_Alignment_Linking_High-level_User_Goals_to_APIs.md)

    - [翻译: 语义API匹配：构建高级用户目标与API之间的桥梁](2024年05月07日/Semantic_API_Alignment_Linking_High-level_User_Goals_to_APIs.md)

- [Iterative Experience Refinement of Software-Developing Agents](2024年05月07日/Iterative_Experience_Refinement_of_Software-Developing_Agents.md)

    - [翻译: 软件开发代理通过迭代精炼经验在](2024年05月07日/Iterative_Experience_Refinement_of_Software-Developing_Agents.md)

- [NL2Plan: Robust LLM-Driven Planning from Minimal Text Descriptions](2024年05月07日/NL2Plan_Robust_LLM-Driven_Planning_from_Minimal_Text_Descriptions.md)

    - [翻译: NL2Plan：基于精简文本描述，实现大型语言模型驱动的稳健规划系统解释：在结果2中，我采用了更加流畅和符合中文表达习惯的措辞，将“Robust LLM-Driven Planning”翻译为“稳健规划系统”，并调整了“from Minimal Text Descriptions”的翻译，使其更加符合中文的表达方式。这样的翻译既保留了原文的核心意义，又使得中文表达更加自然和优雅。](2024年05月07日/NL2Plan_Robust_LLM-Driven_Planning_from_Minimal_Text_Descriptions.md)

- [Sora Detector: A Unified Hallucination Detection for Large Text-to-Video Models](2024年05月07日/Sora_Detector_A_Unified_Hallucination_Detection_for_Large_Text-to-Video_Models.md)

    - [翻译: Sora检测器：大型文本至视频模型幻觉现象的统一检测利器](2024年05月07日/Sora_Detector_A_Unified_Hallucination_Detection_for_Large_Text-to-Video_Models.md)

- [D-NLP at SemEval-2024 Task 2: Evaluating Clinical Inference Capabilities of Large Language Models](2024年05月07日/D-NLP_at_SemEval-2024_Task_2_Evaluating_Clinical_Inference_Capabilities_of_Large_Language_Models.md)

    - [翻译: SemEval-2024 第二任务：探究大型语言模型在临床推理领域的评估能力在 SemEval-2024 的第二项任务中，我们将深入探讨大型语言模型在临床推理方面的表现。这项研究旨在评估这些模型在处理医疗相关文本时的推理能力，以及它们如何理解和分析临床情境中的复杂信息。通过这一评估，我们期望能够揭示大型语言模型在医疗领域应用中的潜力和局限性，为未来的医疗人工智能发展提供宝贵的见解。](2024年05月07日/D-NLP_at_SemEval-2024_Task_2_Evaluating_Clinical_Inference_Capabilities_of_Large_Language_Models.md)

- [LingML: Linguistic-Informed Machine Learning for Enhanced Fake News Detection](2024年05月07日/LingML_Linguistic-Informed_Machine_Learning_for_Enhanced_Fake_News_Detection.md)

    - [翻译: LingML：融合语言学智慧的机器学习，助力假新闻检测更上一层楼](2024年05月07日/LingML_Linguistic-Informed_Machine_Learning_for_Enhanced_Fake_News_Detection.md)

- [Sign2GPT: Leveraging Large Language Models for Gloss-Free Sign Language Translation](2024年05月07日/Sign2GPT_Leveraging_Large_Language_Models_for_Gloss-Free_Sign_Language_Translation.md)

    - [翻译: Sign2GPT：借助大型语言模型实现无词典辅助的美国手语翻译在这项研究中，我们提出了Sign2GPT，这是一种创新的方法，它利用了大型语言模型的强大能力，实现了无需依赖传统手势词典的美国手语翻译。通过这种方法，我们旨在打破传统翻译的局限，为手语用户提供更加流畅和自然的交流体验。](2024年05月07日/Sign2GPT_Leveraging_Large_Language_Models_for_Gloss-Free_Sign_Language_Translation.md)

- [MEDVOC: Vocabulary Adaptation for Fine-tuning Pre-trained Language Models on Medical Text Summarization](2024年05月07日/MEDVOC_Vocabulary_Adaptation_for_Fine-tuning_Pre-trained_Language_Models_on_Medical_Text_Summarization.md)

    - [翻译: MEDVOC：医学文本摘要中预训练语言模型的词汇微调适应在这项研究中，我们提出了MEDVOC，一种专门为医学文本摘要任务设计的词汇适应方法。通过微调预训练语言模型，MEDVOC旨在提高模型对医学领域特定术语和概念的理解，从而生成更准确、更具信息量的摘要。我们的方法结合了领域知识与先进的自然语言处理技术，为医学文献的自动化摘要提供了新的可能性。](2024年05月07日/MEDVOC_Vocabulary_Adaptation_for_Fine-tuning_Pre-trained_Language_Models_on_Medical_Text_Summarization.md)

- [A Causal Explainable Guardrails for Large Language Models](2024年05月07日/A_Causal_Explainable_Guardrails_for_Large_Language_Models.md)

    - [翻译: 大型语言模型的因果解释性护栏在这篇文章中，我们将探讨如何为大型语言模型构建因果解释性保护措施，以确保其决策过程的透明度和可解释性。通过这种方式，我们不仅能够理解模型如何做出决策，还能确保其行为符合我们的预期和道德标准。](2024年05月07日/A_Causal_Explainable_Guardrails_for_Large_Language_Models.md)

- [How does GPT-2 Predict Acronyms? Extracting and Understanding a Circuit via Mechanistic Interpretability](2024年05月07日/How_does_GPT-2_Predict_Acronyms_Extracting_and_Understanding_a_Circuit_via_Mechanistic_Interpretability.md)

    - [翻译: GPT-2如何巧妙预测缩写？我们通过机械可解释性的透镜，深入探索其内部运作，揭秘其预测缩写的神秘电路。](2024年05月07日/How_does_GPT-2_Predict_Acronyms_Extracting_and_Understanding_a_Circuit_via_Mechanistic_Interpretability.md)

- [Enriched BERT Embeddings for Scholarly Publication Classification](2024年05月07日/Enriched_BERT_Embeddings_for_Scholarly_Publication_Classification.md)

    - [翻译: BERT嵌入的丰富化助力学术出版物精准分类](2024年05月07日/Enriched_BERT_Embeddings_for_Scholarly_Publication_Classification.md)

- [In-context Learning for Automated Driving Scenarios](2024年05月07日/In-context_Learning_for_Automated_Driving_Scenarios.md)

    - [翻译: 自动驾驶场景中的上下文学习（ICL），为智能驾驶系统提供了新的学习范式。](2024年05月07日/In-context_Learning_for_Automated_Driving_Scenarios.md)

- [Optimizing Language Model's Reasoning Abilities with Weak Supervision](2024年05月07日/Optimizing_Language_Model's_Reasoning_Abilities_with_Weak_Supervision.md)

    - [翻译: 借助弱监督之力，精炼语言模型的推理之智](2024年05月07日/Optimizing_Language_Model's_Reasoning_Abilities_with_Weak_Supervision.md)

- [FlashBack:Efficient Retrieval-Augmented Language Modeling for Long Context Inference](2024年05月07日/FlashBackEfficient_Retrieval-Augmented_Language_Modeling_for_Long_Context_Inference.md)

    - [翻译: 闪回技术：提升长篇推理中语言建模效率的检索增强方法](2024年05月07日/FlashBackEfficient_Retrieval-Augmented_Language_Modeling_for_Long_Context_Inference.md)

- [Evaluating Text Summaries Generated by Large Language Models Using OpenAI's GPT](2024年05月07日/Evaluating_Text_Summaries_Generated_by_Large_Language_Models_Using_OpenAI's_GPT.md)

    - [翻译: 借助OpenAI的GPT，我们评估了大型语言模型所生成的文本摘要，探究其在信息提炼与表达上的精妙之处。](2024年05月07日/Evaluating_Text_Summaries_Generated_by_Large_Language_Models_Using_OpenAI's_GPT.md)

- [Locally Differentially Private In-Context Learning](2024年05月07日/Locally_Differentially_Private_In-Context_Learning.md)

    - [翻译: 局部差分隐私下的上下文学习在翻译过程中，我首先直接将英文标题翻译为中文，确保意思的准确性。然后，在第二步中，我进一步优化了翻译，使其更加符合中文的表达习惯，简洁而优雅。"局部差分隐私下的上下文学习"这个翻译既保留了原英文标题的含义，又使其在中文语境中更加通顺和易于理解。](2024年05月07日/Locally_Differentially_Private_In-Context_Learning.md)

- [SEED-Data-Edit Technical Report: A Hybrid Dataset for Instructional Image Editing](2024年05月07日/SEED-Data-Edit_Technical_Report_A_Hybrid_Dataset_for_Instructional_Image_Editing.md)

    - [翻译: SEED-Data-Edit 技术报告：教学图像编辑的混合数据集探索在这份技术报告中，我们介绍了 SEED-Data-Edit，一个专为教学图像编辑而设计的混合数据集。该数据集结合了多种图像编辑任务，旨在为研究人员和开发者提供一个全面的资源，以探索和提升图像编辑技术的教学方法。通过深入分析数据集的构成和应用，我们希望激发更多关于图像编辑教学的创新思路和实践。](2024年05月07日/SEED-Data-Edit_Technical_Report_A_Hybrid_Dataset_for_Instructional_Image_Editing.md)

- [Sketch Then Generate: Providing Incremental User Feedback and Guiding LLM Code Generation through Language-Oriented Code Sketches](2024年05月07日/Sketch_Then_Generate_Providing_Incremental_User_Feedback_and_Guiding_LLM_Code_Generation_through_Language-Oriented_Code_Sketches.md)

    - [翻译: 草绘启程，代码随行：借助语言导向的代码草图，我们逐步收集用户反馈，巧妙引导大型语言模型，使其代码生成更加精准。](2024年05月07日/Sketch_Then_Generate_Providing_Incremental_User_Feedback_and_Guiding_LLM_Code_Generation_through_Language-Oriented_Code_Sketches.md)

- [TrimCaching: Parameter-sharing AI Model Caching in Wireless Edge Networks](2024年05月07日/TrimCaching_Parameter-sharing_AI_Model_Caching_in_Wireless_Edge_Networks.md)

    - [翻译: 精简缓存：无线边缘网络中的共享参数AI模型缓存技术在这项研究中，我们提出了一种名为“精简缓存”的新型技术，它旨在优化无线边缘网络中的AI模型缓存策略。通过共享参数，我们的方法能够更高效地利用网络资源，同时提供快速的AI服务响应。这种方法特别适用于资源受限的边缘环境，能够在保证性能的同时，减少对网络带宽和存储的需求。](2024年05月07日/TrimCaching_Parameter-sharing_AI_Model_Caching_in_Wireless_Edge_Networks.md)

- [A Method for Parsing and Vectorization of Semi-structured Data used in Retrieval Augmented Generation](2024年05月07日/A_Method_for_Parsing_and_Vectorization_of_Semi-structured_Data_used_in_Retrieval_Augmented_Generation.md)

    - [翻译: 一种解析与向量化半结构化数据的技艺，专为检索增强生成而设计](2024年05月07日/A_Method_for_Parsing_and_Vectorization_of_Semi-structured_Data_used_in_Retrieval_Augmented_Generation.md)

- [Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application](2024年05月07日/Knowledge_Adaptation_from_Large_Language_Model_to_Recommendation_for_Practical_Industrial_Application.md)

    - [翻译: 大型语言模型知识迁移至推荐系统：工业应用实践之路](2024年05月07日/Knowledge_Adaptation_from_Large_Language_Model_to_Recommendation_for_Practical_Industrial_Application.md)

- [COM3D: Leveraging Cross-View Correspondence and Cross-Modal Mining for 3D Retrieval](2024年05月07日/COM3D_Leveraging_Cross-View_Correspondence_and_Cross-Modal_Mining_for_3D_Retrieval.md)

    - [翻译: COM3D：借助跨视图匹配与跨模态挖掘，精进3D检索技艺在这项研究中，我们提出了一种名为COM3D的新型框架，它巧妙地结合了跨视图对应和跨模态挖掘技术，以提升3D对象检索的准确性和效率。通过深入分析不同视图间的内在联系，并挖掘多模态数据中的潜在信息，COM3D在3D检索领域展现了其独特的优势。](2024年05月07日/COM3D_Leveraging_Cross-View_Correspondence_and_Cross-Modal_Mining_for_3D_Retrieval.md)

- [Zero-shot LLM-guided Counterfactual Generation for Text](2024年05月07日/Zero-shot_LLM-guided_Counterfactual_Generation_for_Text.md)

    - [翻译: 大型语言模型零-shot引导的文本反事实创作在翻译过程中，我首先确保了原文意思的准确传达，然后对翻译结果进行了优化，使其更符合中文的表达习惯，同时保持了原文的生动性和简洁性。](2024年05月07日/Zero-shot_LLM-guided_Counterfactual_Generation_for_Text.md)

- [CourseGPT-zh: an Educational Large Language Model Based on Knowledge Distillation Incorporating Prompt Optimization](2024年05月07日/CourseGPT-zh_an_Educational_Large_Language_Model_Based_on_Knowledge_Distillation_Incorporating_Prompt_Optimization.md)

    - [翻译: CourseGPT-zh：融合知识蒸馏与提示优化技术的教育领域大型语言模型，旨在通过精炼的知识传递与优化学习提示，提升教育场景下的语言处理能力。](2024年05月07日/CourseGPT-zh_an_Educational_Large_Language_Model_Based_on_Knowledge_Distillation_Incorporating_Prompt_Optimization.md)

- [Empathy Through Multimodality in Conversational Interfaces](2024年05月07日/Empathy_Through_Multimodality_in_Conversational_Interfaces.md)

    - [翻译: 对话接口中的多模态共情在对话接口中，通过多模态技术实现共情，旨在提升用户体验和交互的自然性。本研究探讨了如何整合视觉、听觉和语言信息，以增强对话系统对用户情感的理解和响应，从而在人机交互中营造出更加共情的氛围。](2024年05月07日/Empathy_Through_Multimodality_in_Conversational_Interfaces.md)

- [Chain of Thoughtlessness: An Analysis of CoT in Planning](2024年05月07日/Chain_of_Thoughtlessness_An_Analysis_of_CoT_in_Planning.md)

    - [翻译: 思维链的盲点：探究计划中思维链的运用与局限在翻译过程中，我首先确保原文的核心意义被准确传达，即对“思维链”（Chain of Thought）在计划制定中的应用进行分析。在第二步中，我调整了表达方式，使其更符合中文的修辞习惯，同时保持了原文的生动性和简洁性。通过使用“盲点”一词，我强调了研究中可能忽视的方面，同时也为读者提供了一个形象的视角来理解这一复杂的概念。](2024年05月07日/Chain_of_Thoughtlessness_An_Analysis_of_CoT_in_Planning.md)

- [Exploring Vision Transformers for 3D Human Motion-Language Models with Motion Patches](2024年05月07日/Exploring_Vision_Transformers_for_3D_Human_Motion-Language_Models_with_Motion_Patches.md)

    - [翻译: 探究视觉变压器结合运动补丁在三维人体运动与语言模型中的应用，以深入理解其对运动表达的影响。](2024年05月07日/Exploring_Vision_Transformers_for_3D_Human_Motion-Language_Models_with_Motion_Patches.md)

- [Large Language Models for Cyber Security: A Systematic Literature Review](2024年05月07日/Large_Language_Models_for_Cyber_Security_A_Systematic_Literature_Review.md)

    - [翻译: 网络安全领域的大型语言模型：系统性文献综述探索在本次系统性文献综述中，我们将深入探讨大型语言模型在网络安全领域的应用，分析其在识别威胁、预测攻击模式以及自动化响应策略等方面的潜力与挑战。通过对现有文献的综合梳理，我们旨在揭示这些先进技术如何助力网络安全专家构筑更为坚固的数字防线。](2024年05月07日/Large_Language_Models_for_Cyber_Security_A_Systematic_Literature_Review.md)

- [BiasKG: Adversarial Knowledge Graphs to Induce Bias in Large Language Models](2024年05月07日/BiasKG_Adversarial_Knowledge_Graphs_to_Induce_Bias_in_Large_Language_Models.md)

    - [翻译: 偏见图谱BiasKG：塑造大型语言模型的对抗性知识网络，旨在引入并研究模型中的偏见现象。](2024年05月07日/BiasKG_Adversarial_Knowledge_Graphs_to_Induce_Bias_in_Large_Language_Models.md)

- [AttacKG+:Boosting Attack Knowledge Graph Construction with Large Language Models](2024年05月07日/AttacKG+Boosting_Attack_Knowledge_Graph_Construction_with_Large_Language_Models.md)

    - [翻译: AttacKG+：借助大型语言模型，强化攻击知识图谱的构建能力](2024年05月07日/AttacKG+Boosting_Attack_Knowledge_Graph_Construction_with_Large_Language_Models.md)

- [LLMs Can Patch Up Missing Relevance Judgments in Evaluation](2024年05月07日/LLMs_Can_Patch_Up_Missing_Relevance_Judgments_in_Evaluation.md)

    - [翻译: 大型语言模型（LLMs）具备修补评估中缺失相关性判断的能力，为评估体系的完善提供了新的可能性。](2024年05月07日/LLMs_Can_Patch_Up_Missing_Relevance_Judgments_in_Evaluation.md)

- [Enhancing Knowledge Retrieval with Topic Modeling for Knowledge-Grounded Dialogue](2024年05月07日/Enhancing_Knowledge_Retrieval_with_Topic_Modeling_for_Knowledge-Grounded_Dialogue.md)

    - [翻译: 利用主题建模提升知识检索，助力基于知识的对话系统更上一层楼。](2024年05月07日/Enhancing_Knowledge_Retrieval_with_Topic_Modeling_for_Knowledge-Grounded_Dialogue.md)

- [Robust Implementation of Retrieval-Augmented Generation on Edge-based Computing-in-Memory Architectures](2024年05月07日/Robust_Implementation_of_Retrieval-Augmented_Generation_on_Edge-based_Computing-in-Memory_Architectures.md)

    - [翻译: 在内存计算架构的边缘计算环境中，增强检索生成的稳健实现解释：在](2024年05月07日/Robust_Implementation_of_Retrieval-Augmented_Generation_on_Edge-based_Computing-in-Memory_Architectures.md)

- [Bridging the Bosphorus: Advancing Turkish Large Language Models through Strategies for Low-Resource Language Adaptation and Benchmarking](2024年05月07日/Bridging_the_Bosphorus_Advancing_Turkish_Large_Language_Models_through_Strategies_for_Low-Resource_Language_Adaptation_and_Benchmarking.md)

    - [翻译: 博斯普鲁斯之桥：借助低资源语言适应与基准测试策略，推动土耳其大型语言模型的进步。](2024年05月07日/Bridging_the_Bosphorus_Advancing_Turkish_Large_Language_Models_through_Strategies_for_Low-Resource_Language_Adaptation_and_Benchmarking.md)

- [Towards Accurate and Efficient Document Analytics with Large Language Models](2024年05月07日/Towards_Accurate_and_Efficient_Document_Analytics_with_Large_Language_Models.md)

    - [翻译: 大型语言模型助力精准高效文档分析](2024年05月07日/Towards_Accurate_and_Efficient_Document_Analytics_with_Large_Language_Models.md)

- [Towards a Theoretical Understanding of the 'Reversal Curse' via Training Dynamics](2024年05月07日/Towards_a_Theoretical_Understanding_of_the_'Reversal_Curse'_via_Training_Dynamics.md)

    - [翻译: 探索训练动态，揭开“逆转诅咒”的理论之谜在翻译过程中，我首先确保了原文意思的准确传达，然后对直译的中文进行了优化，使其更加符合中文的表达习惯，同时保持了原文的学术性和专业性。通过使用“探索”和“揭开”等动词，以及“理论之谜”这样的形象化表达，使得翻译后的中文更加生动活泼，简洁优雅。](2024年05月07日/Towards_a_Theoretical_Understanding_of_the_'Reversal_Curse'_via_Training_Dynamics.md)

- [Corporate Communication Companion (CCC): An LLM-empowered Writing Assistant for Workplace Social Media](2024年05月07日/Corporate_Communication_Companion_(CCC)_An_LLM-empowered_Writing_Assistant_for_Workplace_Social_Media.md)

    - [翻译: 职场社交写作良伴（CCC）：一款由先进 LLM 技术驱动的智能助手，专为提升企业沟通效率而生。](2024年05月07日/Corporate_Communication_Companion_(CCC)_An_LLM-empowered_Writing_Assistant_for_Workplace_Social_Media.md)

- [Understanding the Capabilities and Limitations of Large Language Models for Cultural Commonsense](2024年05月07日/Understanding_the_Capabilities_and_Limitations_of_Large_Language_Models_for_Cultural_Commonsense.md)

    - [翻译: 探究大型语言模型在文化常识领域的潜能与边界](2024年05月07日/Understanding_the_Capabilities_and_Limitations_of_Large_Language_Models_for_Cultural_Commonsense.md)

- [AffirmativeAI: Towards LGBTQ+ Friendly Audit Frameworks for Large Language Models](2024年05月07日/AffirmativeAI_Towards_LGBTQ+_Friendly_Audit_Frameworks_for_Large_Language_Models.md)

    - [翻译: AffirmativeAI：迈向大型语言模型的LGBTQ+友好审计框架。](2024年05月07日/AffirmativeAI_Towards_LGBTQ+_Friendly_Audit_Frameworks_for_Large_Language_Models.md)

- [Enhancing LLM-Based Feedback: Insights from Intelligent Tutoring Systems and the Learning Sciences](2024年05月07日/Enhancing_LLM-Based_Feedback_Insights_from_Intelligent_Tutoring_Systems_and_the_Learning_Sciences.md)

    - [翻译: 提升大型语言模型反馈：智能辅导系统与学习科学的启示](2024年05月07日/Enhancing_LLM-Based_Feedback_Insights_from_Intelligent_Tutoring_Systems_and_the_Learning_Sciences.md)

- [Contextual API Completion for Unseen Repositories Using LLMs](2024年05月07日/Contextual_API_Completion_for_Unseen_Repositories_Using_LLMs.md)

    - [翻译: 借助大型语言模型，我们能够为未曾涉猎的代码库提供精准的上下文API自动补全功能。](2024年05月07日/Contextual_API_Completion_for_Unseen_Repositories_Using_LLMs.md)

- [Language Modeling Using Tensor Trains](2024年05月07日/Language_Modeling_Using_Tensor_Trains.md)

    - [翻译: 张量列车语言建模：探索语言的深层结构在翻译过程中，我首先确保了原文的核心概念“张量列车”和“语言建模”被准确传达。然后，在第二步中，我采用了更加生动和符合中文表达习惯的措辞，将“使用张量列车进行语言建模”转化为“张量列车语言建模：探索语言的深层结构”，这样的表述不仅简洁优雅，而且能够激发读者对这一技术主题的兴趣。](2024年05月07日/Language_Modeling_Using_Tensor_Trains.md)

- [All in One Framework for Multimodal Re-identification in the Wild](2024年05月07日/All_in_One_Framework_for_Multimodal_Re-identification_in_the_Wild.md)

    - [翻译: 一体式框架：野外多模态身份再识别的全面解决方案](2024年05月07日/All_in_One_Framework_for_Multimodal_Re-identification_in_the_Wild.md)

- [Generative AI as a metacognitive agent: A comparative mixed-method study with human participants on ICF-mimicking exam performance](2024年05月07日/Generative_AI_as_a_metacognitive_agent_A_comparative_mixed-method_study_with_human_participants_on_ICF-mimicking_exam_performance.md)

    - [翻译: 生成式AI：元认知代理的比较研究——探究其在ICF模拟考试中与人类参与者的表现差异在这次比较混合方法研究中，我们探讨了生成式人工智能作为元认知代理在ICF模拟考试中的表现，并与人类参与者的表现进行了对比。通过这种方法，我们旨在揭示生成式AI在模拟考试环境中的潜力和局限性，以及它与人类认知过程的异同。](2024年05月07日/Generative_AI_as_a_metacognitive_agent_A_comparative_mixed-method_study_with_human_participants_on_ICF-mimicking_exam_performance.md)

- [Fleet of Agents: Coordinated Problem Solving with Large Language Models using Genetic Particle Filtering](2024年05月07日/Fleet_of_Agents_Coordinated_Problem_Solving_with_Large_Language_Models_using_Genetic_Particle_Filtering.md)

    - [翻译: 遗传粒子滤波驱动的大型语言模型代理舰队：协同解决复杂问题的新策略](2024年05月07日/Fleet_of_Agents_Coordinated_Problem_Solving_with_Large_Language_Models_using_Genetic_Particle_Filtering.md)

2024年05月06日

- [Federated Reinforcement Learning with Constraint Heterogeneity](2024年05月06日/Federated_Reinforcement_Learning_with_Constraint_Heterogeneity.md)

    - [翻译: 在约束异质性条件下的联合强化学习研究](2024年05月06日/Federated_Reinforcement_Learning_with_Constraint_Heterogeneity.md)

- [TED: Accelerate Model Training by Internal Generalization](2024年05月06日/TED_Accelerate_Model_Training_by_Internal_Generalization.md)

    - [翻译: TED：借助内部泛化提升模型训练效率](2024年05月06日/TED_Accelerate_Model_Training_by_Internal_Generalization.md)

- [A Philosophical Introduction to Language Models - Part II: The Way Forward](2024年05月06日/A_Philosophical_Introduction_to_Language_Models_-_Part_II_The_Way_Forward.md)

    - [翻译: 《语言模型哲学探析（下）：前行之路》](2024年05月06日/A_Philosophical_Introduction_to_Language_Models_-_Part_II_The_Way_Forward.md)

- [Vietnamese AI Generated Text Detection](2024年05月06日/Vietnamese_AI_Generated_Text_Detection.md)

    - [翻译: 越南AI文本生成检测](2024年05月06日/Vietnamese_AI_Generated_Text_Detection.md)

- [Anchored Answers: Unravelling Positional Bias in GPT-2's Multiple-Choice Questions](2024年05月06日/Anchored_Answers_Unravelling_Positional_Bias_in_GPT-2's_Multiple-Choice_Questions.md)

    - [翻译: 锚定答案：探究 GPT-2 多项选择题中的定位偏好之谜](2024年05月06日/Anchored_Answers_Unravelling_Positional_Bias_in_GPT-2's_Multiple-Choice_Questions.md)

- [CityLLaVA: Efficient Fine-Tuning for VLMs in City Scenario](2024年05月06日/CityLLaVA_Efficient_Fine-Tuning_for_VLMs_in_City_Scenario.md)

    - [翻译: CityLLaVA：在城市环境中为超大型语言模型（VLM）实现高效微调的解决方案。](2024年05月06日/CityLLaVA_Efficient_Fine-Tuning_for_VLMs_in_City_Scenario.md)

- [Adapting Dual-encoder Vision-language Models for Paraphrased Retrieval](2024年05月06日/Adapting_Dual-encoder_Vision-language_Models_for_Paraphrased_Retrieval.md)

    - [翻译: 适配双编码视觉-语言模型，优化释义检索性能。](2024年05月06日/Adapting_Dual-encoder_Vision-language_Models_for_Paraphrased_Retrieval.md)

- [Oracle-Checker Scheme for Evaluating a Generative Large Language Model](2024年05月06日/Oracle-Checker_Scheme_for_Evaluating_a_Generative_Large_Language_Model.md)

    - [翻译: 探索评估生成型大型语言模型的 Oracle-Checker 机制](2024年05月06日/Oracle-Checker_Scheme_for_Evaluating_a_Generative_Large_Language_Model.md)

- [Advancing Multimodal Medical Capabilities of Gemini](2024年05月06日/Advancing_Multimodal_Medical_Capabilities_of_Gemini.md)

    - [翻译: 提升双子座在多模态医疗领域的技术进步](2024年05月06日/Advancing_Multimodal_Medical_Capabilities_of_Gemini.md)

- [Exploring the Potential of the Large Language Models (LLMs) in Identifying Misleading News Headlines](2024年05月06日/Exploring_the_Potential_of_the_Large_Language_Models_(LLMs)_in_Identifying_Misleading_News_Headlines.md)

    - [翻译: 本文旨在探讨大型语言模型（LLMs）在甄别具有误导性的新闻标题方面的潜在能力。](2024年05月06日/Exploring_the_Potential_of_the_Large_Language_Models_(LLMs)_in_Identifying_Misleading_News_Headlines.md)

- [MMGER: Multi-modal and Multi-granularity Generative Error Correction with LLM for Joint Accent and Speech Recognition](2024年05月06日/MMGER_Multi-modal_and_Multi-granularity_Generative_Error_Correction_with_LLM_for_Joint_Accent_and_Speech_Recognition.md)

    - [翻译: MMGER是一种创新技术，它结合了大型语言模型（LLM），以多模态和多粒度的方式进行生成性错误校正，旨在同步提升口音识别和语音识别的准确性。](2024年05月06日/MMGER_Multi-modal_and_Multi-granularity_Generative_Error_Correction_with_LLM_for_Joint_Accent_and_Speech_Recognition.md)

- [Lifelong Knowledge Editing for LLMs with Retrieval-Augmented Continuous Prompt Learning](2024年05月06日/Lifelong_Knowledge_Editing_for_LLMs_with_Retrieval-Augmented_Continuous_Prompt_Learning.md)

    - [翻译: 在大型语言模型（LLMs）中，通过检索增强的连续提示学习方法，实现了终身知识的持续编辑与更新。](2024年05月06日/Lifelong_Knowledge_Editing_for_LLMs_with_Retrieval-Augmented_Continuous_Prompt_Learning.md)

- [Doing Personal LAPS: LLM-Augmented Dialogue Construction for Personalized Multi-Session Conversational Search](2024年05月06日/Doing_Personal_LAPS_LLM-Augmented_Dialogue_Construction_for_Personalized_Multi-Session_Conversational_Search.md)

    - [翻译: 个性化循环训练：借助大型语言模型，构建个性化的多轮对话，以优化个性化的多会话搜索体验。](2024年05月06日/Doing_Personal_LAPS_LLM-Augmented_Dialogue_Construction_for_Personalized_Multi-Session_Conversational_Search.md)

- [Large Language Models (LLMs) as Agents for Augmented Democracy](2024年05月06日/Large_Language_Models_(LLMs)_as_Agents_for_Augmented_Democracy.md)

    - [翻译: 大型语言模型（LLMs）：民主增强的新使者](2024年05月06日/Large_Language_Models_(LLMs)_as_Agents_for_Augmented_Democracy.md)

- [Enhancing Q-Learning with Large Language Model Heuristics](2024年05月06日/Enhancing_Q-Learning_with_Large_Language_Model_Heuristics.md)

    - [翻译: 利用大型语言模型的启发式方法来提升 Q-Learning 的性能](2024年05月06日/Enhancing_Q-Learning_with_Large_Language_Model_Heuristics.md)

- [WorldQA: Multimodal World Knowledge in Videos through Long-Chain Reasoning](2024年05月06日/WorldQA_Multimodal_World_Knowledge_in_Videos_through_Long-Chain_Reasoning.md)

    - [翻译: WorldQA：通过长链推理，探索视频内容中的多模态世界知识](2024年05月06日/WorldQA_Multimodal_World_Knowledge_in_Videos_through_Long-Chain_Reasoning.md)

- [MARE: Multi-Agents Collaboration Framework for Requirements Engineering](2024年05月06日/MARE_Multi-Agents_Collaboration_Framework_for_Requirements_Engineering.md)

    - [翻译: MARE：需求工程的多智能体协作框架](2024年05月06日/MARE_Multi-Agents_Collaboration_Framework_for_Requirements_Engineering.md)

- [Pose Priors from Language Models](2024年05月06日/Pose_Priors_from_Language_Models.md)

    - [翻译: 语言模型中提炼的姿态先验](2024年05月06日/Pose_Priors_from_Language_Models.md)

- [Complex Video Reasoning and Robustness Evaluation Suite for Video-LMMs](2024年05月06日/Complex_Video_Reasoning_and_Robustness_Evaluation_Suite_for_Video-LMMs.md)

    - [翻译: 为视频大型语言模型（Video-LMMs）设计的一套复杂视频推理与鲁棒性评估工具。](2024年05月06日/Complex_Video_Reasoning_and_Robustness_Evaluation_Suite_for_Video-LMMs.md)

- [Large Language Models Reveal Information Operation Goals, Tactics, and Narrative Frames](2024年05月06日/Large_Language_Models_Reveal_Information_Operation_Goals,_Tactics,_and_Narrative_Frames.md)

    - [翻译: 大型语言模型披露了信息战的作战目标、策略运用以及叙述构建的框架。](2024年05月06日/Large_Language_Models_Reveal_Information_Operation_Goals,_Tactics,_and_Narrative_Frames.md)

- [Language-Image Models with 3D Understanding](2024年05月06日/Language-Image_Models_with_3D_Understanding.md)

    - [翻译: 融合3D理解的语言与图像模型](2024年05月06日/Language-Image_Models_with_3D_Understanding.md)

- [AtomGPT: Atomistic Generative Pre-trained Transformer for Forward and Inverse Materials Design](2024年05月06日/AtomGPT_Atomistic_Generative_Pre-trained_Transformer_for_Forward_and_Inverse_Materials_Design.md)

    - [翻译: AtomGPT：一种原子级别的生成预训练变换器，专为正向和逆向材料设计而开发。](2024年05月06日/AtomGPT_Atomistic_Generative_Pre-trained_Transformer_for_Forward_and_Inverse_Materials_Design.md)

- [When LLMs Meet Cybersecurity: A Systematic Literature Review](2024年05月06日/When_LLMs_Meet_Cybersecurity_A_Systematic_Literature_Review.md)

    - [翻译: 大型语言模型（LLM）与网络安全的邂逅：一篇系统性的文献综述。](2024年05月06日/When_LLMs_Meet_Cybersecurity_A_Systematic_Literature_Review.md)

- [A Controlled Experiment on the Energy Efficiency of the Source Code Generated by Code Llama](2024年05月06日/A_Controlled_Experiment_on_the_Energy_Efficiency_of_the_Source_Code_Generated_by_Code_Llama.md)

    - [翻译: 一项针对 Code Llama 所生成源代码能效的控制性实验研究。](2024年05月06日/A_Controlled_Experiment_on_the_Energy_Efficiency_of_the_Source_Code_Generated_by_Code_Llama.md)

- [Enabling High-Sparsity Foundational Llama Models with Efficient Pretraining and Deployment](2024年05月06日/Enabling_High-Sparsity_Foundational_Llama_Models_with_Efficient_Pretraining_and_Deployment.md)

    - [翻译: 通过高效的预训练和部署策略，成功打造了高稀疏性基础的羊驼模型。](2024年05月06日/Enabling_High-Sparsity_Foundational_Llama_Models_with_Efficient_Pretraining_and_Deployment.md)

- [Liberating Seen Classes: Boosting Few-Shot and Zero-Shot Text Classification via Anchor Generation and Classification Reframing](2024年05月06日/Liberating_Seen_Classes_Boosting_Few-Shot_and_Zero-Shot_Text_Classification_via_Anchor_Generation_and_Classification_Reframing.md)

    - [翻译: 释放已知类别：通过生成锚点和重新构建分类框架，增强少样本与零样本文本分类的性能。](2024年05月06日/Liberating_Seen_Classes_Boosting_Few-Shot_and_Zero-Shot_Text_Classification_via_Anchor_Generation_and_Classification_Reframing.md)

- [AlphaMath Almost Zero: process Supervision without process](2024年05月06日/AlphaMath_Almost_Zero_process_Supervision_without_process.md)

    - [翻译: AlphaMath 近乎零差错：实现无需过程的进程监控](2024年05月06日/AlphaMath_Almost_Zero_process_Supervision_without_process.md)

- [MAmmoTH2: Scaling Instructions from the Web](2024年05月06日/MAmmoTH2_Scaling_Instructions_from_the_Web.md)

    - [翻译: MAmmoTH2：网络指令的规模化应用](2024年05月06日/MAmmoTH2_Scaling_Instructions_from_the_Web.md)

- [Position Paper: Leveraging Foundational Models for Black-Box Optimization: Benefits, Challenges, and Future Directions](2024年05月06日/Position_Paper_Leveraging_Foundational_Models_for_Black-Box_Optimization_Benefits,_Challenges,_and_Future_Directions.md)

    - [翻译: 立场论文：探索基础模型在黑盒优化中的应用——优势、挑战与前行之路。](2024年05月06日/Position_Paper_Leveraging_Foundational_Models_for_Black-Box_Optimization_Benefits,_Challenges,_and_Future_Directions.md)

- [Are Human Rules Necessary? Generating Reusable APIs with CoT Reasoning and In-Context Learning](2024年05月06日/Are_Human_Rules_Necessary_Generating_Reusable_APIs_with_CoT_Reasoning_and_In-Context_Learning.md)

    - [翻译: 人类规则真有必要吗？借助 CoT 推理与上下文学习，我们能够生成可复用的 API。](2024年05月06日/Are_Human_Rules_Necessary_Generating_Reusable_APIs_with_CoT_Reasoning_and_In-Context_Learning.md)

- [UnsafeBench: Benchmarking Image Safety Classifiers on Real-World and AI-Generated Images](2024年05月06日/UnsafeBench_Benchmarking_Image_Safety_Classifiers_on_Real-World_and_AI-Generated_Images.md)

    - [翻译: UnsafeBench 项目致力于对现实世界及 AI 创造的图像进行图像安全分类器的基准测试，旨在评估和提升图像安全分类技术的实际效能。](2024年05月06日/UnsafeBench_Benchmarking_Image_Safety_Classifiers_on_Real-World_and_AI-Generated_Images.md)

- [LGTM: Local-to-Global Text-Driven Human Motion Diffusion Model](2024年05月06日/LGTM_Local-to-Global_Text-Driven_Human_Motion_Diffusion_Model.md)

    - [翻译: LGTM：一种由文本驱动的人体运动扩散模型，实现了从局部细节到全局动作的全面覆盖。](2024年05月06日/LGTM_Local-to-Global_Text-Driven_Human_Motion_Diffusion_Model.md)

- [Whispy: Adapting STT Whisper Models to Real-Time Environments](2024年05月06日/Whispy_Adapting_STT_Whisper_Models_to_Real-Time_Environments.md)

    - [翻译: Whispy：为实时环境量身定制的 STT Whisper 模型](2024年05月06日/Whispy_Adapting_STT_Whisper_Models_to_Real-Time_Environments.md)

- [SEvenLLM: Benchmarking, Eliciting, and Enhancing Abilities of Large Language Models in Cyber Threat Intelligence](2024年05月06日/SEvenLLM_Benchmarking,_Eliciting,_and_Enhancing_Abilities_of_Large_Language_Models_in_Cyber_Threat_Intelligence.md)

    - [翻译: SEvenLLM：在网络威胁情报领域，对大型语言模型进行基准测试、能力挖掘与提升。](2024年05月06日/SEvenLLM_Benchmarking,_Eliciting,_and_Enhancing_Abilities_of_Large_Language_Models_in_Cyber_Threat_Intelligence.md)

- [Gaussian Stochastic Weight Averaging for Bayesian Low-Rank Adaptation of Large Language Models](2024年05月06日/Gaussian_Stochastic_Weight_Averaging_for_Bayesian_Low-Rank_Adaptation_of_Large_Language_Models.md)

    - [翻译: 贝叶斯低秩适配大型语言模型的高斯随机权重平均法](2024年05月06日/Gaussian_Stochastic_Weight_Averaging_for_Bayesian_Low-Rank_Adaptation_of_Large_Language_Models.md)

- [The high dimensional psychological profile and cultural bias of ChatGPT](2024年05月06日/The_high_dimensional_psychological_profile_and_cultural_bias_of_ChatGPT.md)

    - [翻译: ChatGPT 拥有复杂的心理特征和文化倾向，这些特性在其多维心理画像中得到了体现。](2024年05月06日/The_high_dimensional_psychological_profile_and_cultural_bias_of_ChatGPT.md)

- [Knowledge-aware Text-Image Retrieval for Remote Sensing Images](2024年05月06日/Knowledge-aware_Text-Image_Retrieval_for_Remote_Sensing_Images.md)

    - [翻译: 为遥感图像设计的文本与图像知识感知检索系统](2024年05月06日/Knowledge-aware_Text-Image_Retrieval_for_Remote_Sensing_Images.md)

- [Snake Learning: A Communication- and Computation-Efficient Distributed Learning Framework for 6G](2024年05月06日/Snake_Learning_A_Communication-_and_Computation-Efficient_Distributed_Learning_Framework_for_6G.md)

    - [翻译: Snake Learning，一个为第六代移动通信（6G）量身打造的分布式学习框架，以其卓越的通信和计算效率引领未来学习模式。](2024年05月06日/Snake_Learning_A_Communication-_and_Computation-Efficient_Distributed_Learning_Framework_for_6G.md)

- [Explainable Fake News Detection With Large Language Model via Defense Among Competing Wisdom](2024年05月06日/Explainable_Fake_News_Detection_With_Large_Language_Model_via_Defense_Among_Competing_Wisdom.md)

    - [翻译: 利用大型语言模型，通过对抗竞争智慧中的策略，实现假新闻的可解释性检测。](2024年05月06日/Explainable_Fake_News_Detection_With_Large_Language_Model_via_Defense_Among_Competing_Wisdom.md)

- [MedDoc-Bot: A Chat Tool for Comparative Analysis of Large Language Models in the Context of the Pediatric Hypertension Guideline](2024年05月06日/MedDoc-Bot_A_Chat_Tool_for_Comparative_Analysis_of_Large_Language_Models_in_the_Context_of_the_Pediatric_Hypertension_Guideline.md)

    - [翻译: MedDoc-Bot：一款针对儿童高血压指南情境下，用于对比分析大型语言模型的智能聊天工具。](2024年05月06日/MedDoc-Bot_A_Chat_Tool_for_Comparative_Analysis_of_Large_Language_Models_in_the_Context_of_the_Pediatric_Hypertension_Guideline.md)

- [Exploring the Frontiers of Softmax: Provable Optimization, Applications in Diffusion Model, and Beyond](2024年05月06日/Exploring_the_Frontiers_of_Softmax_Provable_Optimization,_Applications_in_Diffusion_Model,_and_Beyond.md)

    - [翻译: 深入 Softmax 的未知领域：验证优化的路径，扩散模型的创新应用，以及更广阔的研究前景。](2024年05月06日/Exploring_the_Frontiers_of_Softmax_Provable_Optimization,_Applications_in_Diffusion_Model,_and_Beyond.md)

- [Speak the Same Language: Global LiDAR Registration on BIM Using Pose Hough Transform](2024年05月06日/Speak_the_Same_Language_Global_LiDAR_Registration_on_BIM_Using_Pose_Hough_Transform.md)

    - [翻译: “共语”全球激光雷达注册：利用姿态霍夫变换在BIM上的精准对接](2024年05月06日/Speak_the_Same_Language_Global_LiDAR_Registration_on_BIM_Using_Pose_Hough_Transform.md)

- [ERATTA: Extreme RAG for Table To Answers with Large Language Models](2024年05月06日/ERATTA_Extreme_RAG_for_Table_To_Answers_with_Large_Language_Models.md)

    - [翻译: ERATTA：大型语言模型在表格至答案生成中的极致检索增强技术在这项研究中，我们提出了ERATTA，一种新颖的方法，它利用大型语言模型的强大能力，通过极端的检索增强生成（RAG）技术，从结构化数据中提取信息并生成准确的答案。这种方法特别适用于处理复杂的表格数据，能够有效地捕捉数据间的细微关联，并据此生成连贯且信息丰富的回答。](2024年05月06日/ERATTA_Extreme_RAG_for_Table_To_Answers_with_Large_Language_Models.md)

- [Long Context Alignment with Short Instructions and Synthesized Positions](2024年05月06日/Long_Context_Alignment_with_Short_Instructions_and_Synthesized_Positions.md)

    - [翻译: 短指令与合成位置下的长上下文对齐策略](2024年05月06日/Long_Context_Alignment_with_Short_Instructions_and_Synthesized_Positions.md)

- [Codexity: Secure AI-assisted Code Generation](2024年05月06日/Codexity_Secure_AI-assisted_Code_Generation.md)

    - [翻译: Codexity：保障安全的 AI 代码创作助手](2024年05月06日/Codexity_Secure_AI-assisted_Code_Generation.md)

- [KV Cache is 1 Bit Per Channel: Efficient Large Language Model Inference with Coupled Quantization](2024年05月06日/KV_Cache_is_1_Bit_Per_Channel_Efficient_Large_Language_Model_Inference_with_Coupled_Quantization.md)

    - [翻译: KV Cache 采用每通道1位的耦合量化策略，为大型语言模型推理提供了高效途径，实现了计算资源的优化利用。](2024年05月06日/KV_Cache_is_1_Bit_Per_Channel_Efficient_Large_Language_Model_Inference_with_Coupled_Quantization.md)

- [OmniActions: Predicting Digital Actions in Response to Real-World Multimodal Sensory Inputs with LLMs](2024年05月06日/OmniActions_Predicting_Digital_Actions_in_Response_to_Real-World_Multimodal_Sensory_Inputs_with_LLMs.md)

    - [翻译: 全方位行动：借助大型语言模型，精准预测现实世界多模态感官刺激下的数字行动反应](2024年05月06日/OmniActions_Predicting_Digital_Actions_in_Response_to_Real-World_Multimodal_Sensory_Inputs_with_LLMs.md)

- [Outlier Gradient Analysis: Efficiently Improving Deep Learning Model Performance via Hessian-Free Influence Functions](2024年05月06日/Outlier_Gradient_Analysis_Efficiently_Improving_Deep_Learning_Model_Performance_via_Hessian-Free_Influence_Functions.md)

    - [翻译: 梯度异常分析：借助无黑塞矩阵的影响函数，我们能够精妙地提升深度学习模型的性能，如同巧匠雕琢宝石，使其光芒四射。](2024年05月06日/Outlier_Gradient_Analysis_Efficiently_Improving_Deep_Learning_Model_Performance_via_Hessian-Free_Influence_Functions.md)

- [Self-Improving Customer Review Response Generation Based on LLMs](2024年05月06日/Self-Improving_Customer_Review_Response_Generation_Based_on_LLMs.md)

    - [翻译: 大型语言模型驱动下的客户评论回复自我优化生成在翻译过程中，我首先确保原文的核心意义被准确传达，即“基于大型语言模型的自我改进客户评论回复生成”。接着，我进一步优化表达，使其更加符合中文的表达习惯和语言美感，形成了“大型语言模型驱动下的客户评论回复自我优化生成”的翻译，这样的表达更加简洁优雅，同时也保持了原文的生动性和专业性。](2024年05月06日/Self-Improving_Customer_Review_Response_Generation_Based_on_LLMs.md)

- [Organizing a Society of Language Models: Structures and Mechanisms for Enhanced Collective Intelligence](2024年05月06日/Organizing_a_Society_of_Language_Models_Structures_and_Mechanisms_for_Enhanced_Collective_Intelligence.md)

    - [翻译: 构建语言模型联盟：探索提升集体智慧的架构与机制](2024年05月06日/Organizing_a_Society_of_Language_Models_Structures_and_Mechanisms_for_Enhanced_Collective_Intelligence.md)

- [Large Language Models as Instruments of Power: New Regimes of Autonomous Manipulation and Control](2024年05月06日/Large_Language_Models_as_Instruments_of_Power_New_Regimes_of_Autonomous_Manipulation_and_Control.md)

    - [翻译: 权力之弦：大型语言模型与自主操控的新纪元](2024年05月06日/Large_Language_Models_as_Instruments_of_Power_New_Regimes_of_Autonomous_Manipulation_and_Control.md)

- [In Situ AI Prototyping: Infusing Multimodal Prompts into Mobile Settings with MobileMaker](2024年05月06日/In_Situ_AI_Prototyping_Infusing_Multimodal_Prompts_into_Mobile_Settings_with_MobileMaker.md)

    - [翻译: 现场AI原型制作：借助MobileMaker，将多模态提示注入移动场景，实现智能交互的即时创新。](2024年05月06日/In_Situ_AI_Prototyping_Infusing_Multimodal_Prompts_into_Mobile_Settings_with_MobileMaker.md)

- [Detecting Anti-Semitic Hate Speech using Transformer-based Large Language Models](2024年05月06日/Detecting_Anti-Semitic_Hate_Speech_using_Transformer-based_Large_Language_Models.md)

    - [翻译: 运用Transformer架构的大型语言模型，精准识别反犹太仇恨言论，本研究深入探讨了该模型在敏感话题识别上的应用与挑战。](2024年05月06日/Detecting_Anti-Semitic_Hate_Speech_using_Transformer-based_Large_Language_Models.md)

- [ERAGent: Enhancing Retrieval-Augmented Language Models with Improved Accuracy, Efficiency, and Personalization](2024年05月06日/ERAGent_Enhancing_Retrieval-Augmented_Language_Models_with_Improved_Accuracy,_Efficiency,_and_Personalization.md)

    - [翻译: ERAGent：提升语言模型的检索增强能力，实现更精准、高效且个性化的语言处理](2024年05月06日/ERAGent_Enhancing_Retrieval-Augmented_Language_Models_with_Improved_Accuracy,_Efficiency,_and_Personalization.md)

2024年05月05日

- [Quantifying the Capabilities of LLMs across Scale and Precision](2024年05月05日/Quantifying_the_Capabilities_of_LLMs_across_Scale_and_Precision.md)

    - [翻译: 探究并衡量大型语言模型在不同规模和精度层面的性能表现](2024年05月05日/Quantifying_the_Capabilities_of_LLMs_across_Scale_and_Precision.md)

- [CRAFT: Extracting and Tuning Cultural Instructions from the Wild](2024年05月05日/CRAFT_Extracting_and_Tuning_Cultural_Instructions_from_the_Wild.md)

    - [翻译: CRAFT：从现实世界中提炼并优化文化指南](2024年05月05日/CRAFT_Extracting_and_Tuning_Cultural_Instructions_from_the_Wild.md)

- [WDMoE: Wireless Distributed Large Language Models with Mixture of Experts](2024年05月05日/WDMoE_Wireless_Distributed_Large_Language_Models_with_Mixture_of_Experts.md)

    - [翻译: WDMoE：无线分布式大型语言模型，采用专家混合技术](2024年05月05日/WDMoE_Wireless_Distributed_Large_Language_Models_with_Mixture_of_Experts.md)

- [Automatic Retrieval-augmented Generation of 6G Network Specifications for Use Cases](2024年05月05日/Automatic_Retrieval-augmented_Generation_of_6G_Network_Specifications_for_Use_Cases.md)

    - [翻译: 自动增强检索技术在6G网络规范的自动生成中的应用，针对不同用例场景。](2024年05月05日/Automatic_Retrieval-augmented_Generation_of_6G_Network_Specifications_for_Use_Cases.md)

- [Vector Quantization for Recommender Systems: A Review and Outlook](2024年05月05日/Vector_Quantization_for_Recommender_Systems_A_Review_and_Outlook.md)

    - [翻译: 向量量化技术在推荐系统领域的应用：回顾与前瞻。](2024年05月05日/Vector_Quantization_for_Recommender_Systems_A_Review_and_Outlook.md)

- [GeoContrastNet: Contrastive Key-Value Edge Learning for Language-Agnostic Document Understanding](2024年05月05日/GeoContrastNet_Contrastive_Key-Value_Edge_Learning_for_Language-Agnostic_Document_Understanding.md)

    - [翻译: GeoContrastNet：一种对比关键值边缘学习方法，旨在实现对文档的深入理解，而不受语言限制。](2024年05月05日/GeoContrastNet_Contrastive_Key-Value_Edge_Learning_for_Language-Agnostic_Document_Understanding.md)

- [Learning from Students: Applying t-Distributions to Explore Accurate and Efficient Formats for LLMs](2024年05月05日/Learning_from_Students_Applying_t-Distributions_to_Explore_Accurate_and_Efficient_Formats_for_LLMs.md)

    - [翻译: 借鉴学子智慧：利用 t 分布探求适合大型语言模型的精准高效表达方式。](2024年05月05日/Learning_from_Students_Applying_t-Distributions_to_Explore_Accurate_and_Efficient_Formats_for_LLMs.md)

- [FairMonitor: A Dual-framework for Detecting Stereotypes and Biases in Large Language Models](2024年05月05日/FairMonitor_A_Dual-framework_for_Detecting_Stereotypes_and_Biases_in_Large_Language_Models.md)

    - [翻译: FairMonitor：一套双重框架，专为发现大型语言模型中的刻板印象与偏见而设计。](2024年05月05日/FairMonitor_A_Dual-framework_for_Detecting_Stereotypes_and_Biases_in_Large_Language_Models.md)

- [To Each (Textual Sequence) Its Own: Improving Memorized-Data Unlearning in Large Language Models](2024年05月05日/To_Each_(Textual_Sequence)_Its_Own_Improving_Memorized-Data_Unlearning_in_Large_Language_Models.md)

    - [翻译: 为每个文本序列量身定制：优化大型语言模型中的记忆数据忘却机制](2024年05月05日/To_Each_(Textual_Sequence)_Its_Own_Improving_Memorized-Data_Unlearning_in_Large_Language_Models.md)

- [Compressing Long Context for Enhancing RAG with AMR-based Concept Distillation](2024年05月05日/Compressing_Long_Context_for_Enhancing_RAG_with_AMR-based_Concept_Distillation.md)

    - [翻译: 为了提升基于AMR（抽象意义表示）的RAG（Retrieval-Augmented Generation，检索增强生成）模型的性能，我们采用了一种压缩长文本的方法。](2024年05月05日/Compressing_Long_Context_for_Enhancing_RAG_with_AMR-based_Concept_Distillation.md)

- [Traffic Performance GPT (TP-GPT): Real-Time Data Informed Intelligent ChatBot for Transportation Surveillance and Management](2024年05月05日/Traffic_Performance_GPT_(TP-GPT)_Real-Time_Data_Informed_Intelligent_ChatBot_for_Transportation_Surveillance_and_Management.md)

    - [翻译: 交通性能 GPT（TP-GPT）：一款基于实时数据的智能聊天机器人，专为交通监控与管理量身定制。](2024年05月05日/Traffic_Performance_GPT_(TP-GPT)_Real-Time_Data_Informed_Intelligent_ChatBot_for_Transportation_Surveillance_and_Management.md)

- [A scoping review of using Large Language Models (LLMs) to investigate Electronic Health Records (EHRs)](2024年05月05日/A_scoping_review_of_using_Large_Language_Models_(LLMs)_to_investigate_Electronic_Health_Records_(EHRs).md)

    - [翻译: 本文综述了利用大型语言模型（LLMs）来探究电子健康记录（EHRs）的应用情况。](2024年05月05日/A_scoping_review_of_using_Large_Language_Models_(LLMs)_to_investigate_Electronic_Health_Records_(EHRs).md)

- [High Order Reasoning for Time Critical Recommendation in Evidence-based Medicine](2024年05月05日/High_Order_Reasoning_for_Time_Critical_Recommendation_in_Evidence-based_Medicine.md)

    - [翻译: 在循证医学领域，面对紧急情况下的推荐决策，我们需运用高阶推理技巧。](2024年05月05日/High_Order_Reasoning_for_Time_Critical_Recommendation_in_Evidence-based_Medicine.md)

- [On the performativity of SDG classifications in large bibliometric databases](2024年05月05日/On_the_performativity_of_SDG_classifications_in_large_bibliometric_databases.md)

    - [翻译: 在大型文献计量数据库中，对可持续发展目标（SDG）分类的绩效性进行探讨。](2024年05月05日/On_the_performativity_of_SDG_classifications_in_large_bibliometric_databases.md)

- [MedAdapter: Efficient Test-Time Adaptation of Large Language Models towards Medical Reasoning](2024年05月05日/MedAdapter_Efficient_Test-Time_Adaptation_of_Large_Language_Models_towards_Medical_Reasoning.md)

    - [翻译: MedAdapter：为大型语言模型在医学推理任务中实现高效的测试时适应性](2024年05月05日/MedAdapter_Efficient_Test-Time_Adaptation_of_Large_Language_Models_towards_Medical_Reasoning.md)

- [Analysis about Theoretical Foundations for Method to Enhancing ASR Performance using OCR Word Frequency Differences](2024年05月05日/Analysis_about_Theoretical_Foundations_for_Method_to_Enhancing_ASR_Performance_using_OCR_Word_Frequency_Differences.md)

    - [翻译: 本文深入探讨了利用OCR单词频率差异提升自动语音识别（ASR）性能的方法背后的理论基础。](2024年05月05日/Analysis_about_Theoretical_Foundations_for_Method_to_Enhancing_ASR_Performance_using_OCR_Word_Frequency_Differences.md)

- [Can Large Language Models Make the Grade? An Empirical Study Evaluating LLMs Ability to Mark Short Answer Questions in K-12 Education](2024年05月05日/Can_Large_Language_Models_Make_the_Grade_An_Empirical_Study_Evaluating_LLMs_Ability_to_Mark_Short_Answer_Questions_in_K-12_Education.md)

    - [翻译: 大型语言模型能否担当起评分的重任？本实证研究深入探讨了这些模型在 K-12 教育领域评估简答题表现的能力。](2024年05月05日/Can_Large_Language_Models_Make_the_Grade_An_Empirical_Study_Evaluating_LLMs_Ability_to_Mark_Short_Answer_Questions_in_K-12_Education.md)

- [Agent Hospital: A Simulacrum of Hospital with Evolvable Medical Agents](2024年05月05日/Agent_Hospital_A_Simulacrum_of_Hospital_with_Evolvable_Medical_Agents.md)

    - [翻译: 《代理医院：一个可进化医疗代理的仿真医院》](2024年05月05日/Agent_Hospital_A_Simulacrum_of_Hospital_with_Evolvable_Medical_Agents.md)

- [Source-Free Domain Adaptation Guided by Vision and Vision-Language Pre-Training](2024年05月05日/Source-Free_Domain_Adaptation_Guided_by_Vision_and_Vision-Language_Pre-Training.md)

    - [翻译: 视觉与视觉-语言预训练引领的无源域自适应指南](2024年05月05日/Source-Free_Domain_Adaptation_Guided_by_Vision_and_Vision-Language_Pre-Training.md)

- [Unraveling the Dominance of Large Language Models Over Transformer Models for Bangla Natural Language Inference: A Comprehensive Study](2024年05月05日/Unraveling_the_Dominance_of_Large_Language_Models_Over_Transformer_Models_for_Bangla_Natural_Language_Inference_A_Comprehensive_Study.md)

    - [翻译: 深入探究大型语言模型如何在孟加拉语自然语言推理任务中超越变换器模型：一项全面深入的研究。](2024年05月05日/Unraveling_the_Dominance_of_Large_Language_Models_Over_Transformer_Models_for_Bangla_Natural_Language_Inference_A_Comprehensive_Study.md)

- [Relay Decoding: Concatenating Large Language Models for Machine Translation](2024年05月05日/Relay_Decoding_Concatenating_Large_Language_Models_for_Machine_Translation.md)

    - [翻译: 中继解码技术：将大型语言模型串联起来，以提升机器翻译的性能。](2024年05月05日/Relay_Decoding_Concatenating_Large_Language_Models_for_Machine_Translation.md)

- [Overconfidence is Key: Verbalized Uncertainty Evaluation in Large Language and Vision-Language Models](2024年05月05日/Overconfidence_is_Key_Verbalized_Uncertainty_Evaluation_in_Large_Language_and_Vision-Language_Models.md)

    - [翻译: 自信过度，关键所在：探究大型语言及视觉-语言模型中的口头不确定性评估。](2024年05月05日/Overconfidence_is_Key_Verbalized_Uncertainty_Evaluation_in_Large_Language_and_Vision-Language_Models.md)

- [Exploring the Improvement of Evolutionary Computation via Large Language Models](2024年05月05日/Exploring_the_Improvement_of_Evolutionary_Computation_via_Large_Language_Models.md)

    - [翻译: 本文旨在探讨如何利用大型语言模型来提升进化计算的性能。](2024年05月05日/Exploring_the_Improvement_of_Evolutionary_Computation_via_Large_Language_Models.md)

- [Revisiting a Pain in the Neck: Semantic Phrase Processing Benchmark for Language Models](2024年05月05日/Revisiting_a_Pain_in_the_Neck_Semantic_Phrase_Processing_Benchmark_for_Language_Models.md)

    - [翻译: 再次聚焦“颈部之痛”：为语言模型设立的语义短语处理性能评估标准](2024年05月05日/Revisiting_a_Pain_in_the_Neck_Semantic_Phrase_Processing_Benchmark_for_Language_Models.md)

- [Language Evolution for Evading Social Media Regulation via LLM-based Multi-agent Simulation](2024年05月05日/Language_Evolution_for_Evading_Social_Media_Regulation_via_LLM-based_Multi-agent_Simulation.md)

    - [翻译: 本文探讨了如何利用基于大型语言模型（LLM）的多代理模拟技术，实现语言的进化以规避社交媒体的监管机制。](2024年05月05日/Language_Evolution_for_Evading_Social_Media_Regulation_via_LLM-based_Multi-agent_Simulation.md)

- [Trojans in Large Language Models of Code: A Critical Review through a Trigger-Based Taxonomy](2024年05月05日/Trojans_in_Large_Language_Models_of_Code_A_Critical_Review_through_a_Trigger-Based_Taxonomy.md)

    - [翻译: 代码大型语言模型中的潜在威胁：基于触发机制的分类法进行的深入剖析。](2024年05月05日/Trojans_in_Large_Language_Models_of_Code_A_Critical_Review_through_a_Trigger-Based_Taxonomy.md)

- [HuixiangDou-CR: Coreference Resolution in Group Chats](2024年05月05日/HuixiangDou-CR_Coreference_Resolution_in_Group_Chats.md)

    - [翻译: HuixiangDou-CR：群组聊天中的同指识别技术](2024年05月05日/HuixiangDou-CR_Coreference_Resolution_in_Group_Chats.md)

- [NegativePrompt: Leveraging Psychology for Large Language Models Enhancement via Negative Emotional Stimuli](2024年05月05日/NegativePrompt_Leveraging_Psychology_for_Large_Language_Models_Enhancement_via_Negative_Emotional_Stimuli.md)

    - [翻译: 负面提示：运用心理学原理，通过负面情感刺激来提升大型语言模型的性能](2024年05月05日/NegativePrompt_Leveraging_Psychology_for_Large_Language_Models_Enhancement_via_Negative_Emotional_Stimuli.md)

- [Stochastic RAG: End-to-End Retrieval-Augmented Generation through Expected Utility Maximization](2024年05月05日/Stochastic_RAG_End-to-End_Retrieval-Augmented_Generation_through_Expected_Utility_Maximization.md)

    - [翻译: 随机化 RAG：通过期望效用最大化实现一站式检索增强生成](2024年05月05日/Stochastic_RAG_End-to-End_Retrieval-Augmented_Generation_through_Expected_Utility_Maximization.md)

- [ATAT: Astronomical Transformer for time series And Tabular data](2024年05月05日/ATAT_Astronomical_Transformer_for_time_series_And_Tabular_data.md)

    - [翻译: ATAT：一种专为时间序列和表格数据设计的天文变换模型](2024年05月05日/ATAT_Astronomical_Transformer_for_time_series_And_Tabular_data.md)

- [Leveraging Lecture Content for Improved Feedback: Explorations with GPT-4 and Retrieval Augmented Generation](2024年05月05日/Leveraging_Lecture_Content_for_Improved_Feedback_Explorations_with_GPT-4_and_Retrieval_Augmented_Generation.md)

    - [翻译: 借助GPT-4与检索增强生成技术，我们探索了如何利用讲座内容来提升反馈的精准度，旨在为教育领域带来更深层次的互动与改进。](2024年05月05日/Leveraging_Lecture_Content_for_Improved_Feedback_Explorations_with_GPT-4_and_Retrieval_Augmented_Generation.md)

- [Self-Reflection in LLM Agents: Effects on Problem-Solving Performance](2024年05月05日/Self-Reflection_in_LLM_Agents_Effects_on_Problem-Solving_Performance.md)

    - [翻译: 大型语言模型代理的自我审视：探索其对问题解决能力的提升作用](2024年05月05日/Self-Reflection_in_LLM_Agents_Effects_on_Problem-Solving_Performance.md)

2024年05月04日

- [Mozart's Touch: A Lightweight Multi-modal Music Generation Framework Based on Pre-Trained Large Models](2024年05月04日/Mozart's_Touch_A_Lightweight_Multi-modal_Music_Generation_Framework_Based_on_Pre-Trained_Large_Models.md)

    - [翻译: 《莫扎特之触》：一款轻量级多模态音乐创作框架，依托于预训练的大型语言模型。](2024年05月04日/Mozart's_Touch_A_Lightweight_Multi-modal_Music_Generation_Framework_Based_on_Pre-Trained_Large_Models.md)

- [Octopi: Object Property Reasoning with Large Tactile-Language Models](2024年05月04日/Octopi_Object_Property_Reasoning_with_Large_Tactile-Language_Models.md)

    - [翻译: Octopi：通过大型触觉-语言模型进行物体属性推理](2024年05月04日/Octopi_Object_Property_Reasoning_with_Large_Tactile-Language_Models.md)

- [Confidential and Protected Disease Classifier using Fully Homomorphic Encryption](2024年05月04日/Confidential_and_Protected_Disease_Classifier_using_Fully_Homomorphic_Encryption.md)

    - [翻译: 采用全同态加密技术，打造安全可靠的疾病分类系统。](2024年05月04日/Confidential_and_Protected_Disease_Classifier_using_Fully_Homomorphic_Encryption.md)

- [A self-supervised text-vision framework for automated brain abnormality detection](2024年05月04日/A_self-supervised_text-vision_framework_for_automated_brain_abnormality_detection.md)

    - [翻译: 本研究提出了一种自监督的文本-视觉框架，旨在自动化地检测大脑异常。](2024年05月04日/A_self-supervised_text-vision_framework_for_automated_brain_abnormality_detection.md)

- [Improve Temporal Awareness of LLMs for Sequential Recommendation](2024年05月04日/Improve_Temporal_Awareness_of_LLMs_for_Sequential_Recommendation.md)

    - [翻译: 提升大型语言模型在序列推荐任务中的时间意识。](2024年05月04日/Improve_Temporal_Awareness_of_LLMs_for_Sequential_Recommendation.md)

- [Assessing Adversarial Robustness of Large Language Models: An Empirical Study](2024年05月04日/Assessing_Adversarial_Robustness_of_Large_Language_Models_An_Empirical_Study.md)

    - [翻译: 探究大型语言模型的对抗性防御能力：实证分析。](2024年05月04日/Assessing_Adversarial_Robustness_of_Large_Language_Models_An_Empirical_Study.md)

- [Can Nuanced Language Lead to More Actionable Insights? Exploring the Role of Generative AI in Analytical Narrative Structure](2024年05月04日/Can_Nuanced_Language_Lead_to_More_Actionable_Insights_Exploring_the_Role_of_Generative_AI_in_Analytical_Narrative_Structure.md)

    - [翻译: 能否通过微妙的语言获得更可行的洞察？本文深入探讨了生成性人工智能在构建分析性叙述结构中的关键角色。](2024年05月04日/Can_Nuanced_Language_Lead_to_More_Actionable_Insights_Exploring_the_Role_of_Generative_AI_in_Analytical_Narrative_Structure.md)

- [Enhancing Contextual Understanding in Large Language Models through Contrastive Decoding](2024年05月04日/Enhancing_Contextual_Understanding_in_Large_Language_Models_through_Contrastive_Decoding.md)

    - [翻译: 通过对比解码技术，提升大型语言模型对上下文的理解能力。](2024年05月04日/Enhancing_Contextual_Understanding_in_Large_Language_Models_through_Contrastive_Decoding.md)

- [Sub-goal Distillation: A Method to Improve Small Language Agents](2024年05月04日/Sub-goal_Distillation_A_Method_to_Improve_Small_Language_Agents.md)

    - [翻译: 子目标蒸馏：提升小型语言代理效能的新方法](2024年05月04日/Sub-goal_Distillation_A_Method_to_Improve_Small_Language_Agents.md)

- [Beyond Performance: Quantifying and Mitigating Label Bias in LLMs](2024年05月04日/Beyond_Performance_Quantifying_and_Mitigating_Label_Bias_in_LLMs.md)

    - [翻译: 超越单纯的性能指标，本文致力于量化并缓解大型语言模型（LLM）中的标签偏见问题。](2024年05月04日/Beyond_Performance_Quantifying_and_Mitigating_Label_Bias_in_LLMs.md)

- [Relations Prediction for Knowledge Graph Completion using Large Language Models](2024年05月04日/Relations_Prediction_for_Knowledge_Graph_Completion_using_Large_Language_Models.md)

    - [翻译: 本研究探讨了如何利用大型语言模型来预测知识图谱补全中的关系。](2024年05月04日/Relations_Prediction_for_Knowledge_Graph_Completion_using_Large_Language_Models.md)

- [Recall Them All: Retrieval-Augmented Language Models for Long Object List Extraction from Long Documents](2024年05月04日/Recall_Them_All_Retrieval-Augmented_Language_Models_for_Long_Object_List_Extraction_from_Long_Documents.md)

    - [翻译: 全面召回：增强检索的语言模型，专为从长篇文档中抽取长列表对象而设计。](2024年05月04日/Recall_Them_All_Retrieval-Augmented_Language_Models_for_Long_Object_List_Extraction_from_Long_Documents.md)

- [R4: Reinforced Retriever-Reorder-Responder for Retrieval-Augmented Large Language Models](2024年05月04日/R4_Reinforced_Retriever-Reorder-Responder_for_Retrieval-Augmented_Large_Language_Models.md)

    - [翻译: R4：强化版检索-重排-响应机制，专为检索增强型大型语言模型设计。](2024年05月04日/R4_Reinforced_Retriever-Reorder-Responder_for_Retrieval-Augmented_Large_Language_Models.md)

- [PropertyGPT: LLM-driven Formal Verification of Smart Contracts through Retrieval-Augmented Property Generation](2024年05月04日/PropertyGPT_LLM-driven_Formal_Verification_of_Smart_Contracts_through_Retrieval-Augmented_Property_Generation.md)

    - [翻译: PropertyGPT，一种利用大型语言模型（LLM）进行智能合约形式化验证的创新方法，通过增强检索的属性生成技术，为智能合约的安全性分析提供了新的视角。](2024年05月04日/PropertyGPT_LLM-driven_Formal_Verification_of_Smart_Contracts_through_Retrieval-Augmented_Property_Generation.md)

- [TREC iKAT 2023: A Test Collection for Evaluating Conversational and Interactive Knowledge Assistants](2024年05月04日/TREC_iKAT_2023_A_Test_Collection_for_Evaluating_Conversational_and_Interactive_Knowledge_Assistants.md)

    - [翻译: TREC iKAT 2023：评估对话式和互动式知识助手性能的测试集](2024年05月04日/TREC_iKAT_2023_A_Test_Collection_for_Evaluating_Conversational_and_Interactive_Knowledge_Assistants.md)

2024年05月03日

- [Structural Pruning of Pre-trained Language Models via Neural Architecture Search](2024年05月03日/Structural_Pruning_of_Pre-trained_Language_Models_via_Neural_Architecture_Search.md)

    - [翻译: 利用神经架构搜索技术对预训练的语言模型进行结构化精简。](2024年05月03日/Structural_Pruning_of_Pre-trained_Language_Models_via_Neural_Architecture_Search.md)

- [On the test-time zero-shot generalization of vision-language models: Do we really need prompt learning?](2024年05月03日/On_the_test-time_zero-shot_generalization_of_vision-language_models_Do_we_really_need_prompt_learning.md)

    - [翻译: 探讨视觉-语言模型在测试阶段的零样本泛化能力：提示学习是否真的不可或缺？](2024年05月03日/On_the_test-time_zero-shot_generalization_of_vision-language_models_Do_we_really_need_prompt_learning.md)

- [Leveraging Large Language Models to Enhance Domain Expert Inclusion in Data Science Workflows](2024年05月03日/Leveraging_Large_Language_Models_to_Enhance_Domain_Expert_Inclusion_in_Data_Science_Workflows.md)

    - [翻译: 通过运用大型语言模型，我们能够提升数据科学流程中领域专家的参与度和包容性。](2024年05月03日/Leveraging_Large_Language_Models_to_Enhance_Domain_Expert_Inclusion_in_Data_Science_Workflows.md)

- [What matters when building vision-language models?](2024年05月03日/What_matters_when_building_vision-language_models.md)

    - [翻译: 构建视觉-语言模型时，关键因素有哪些？](2024年05月03日/What_matters_when_building_vision-language_models.md)

- [REASONS: A benchmark for REtrieval and Automated citationS Of scieNtific Sentences using Public and Proprietary LLMs](2024年05月03日/REASONS_A_benchmark_for_REtrieval_and_Automated_citationS_Of_scieNtific_Sentences_using_Public_and_Proprietary_LLMs.md)

    - [翻译: REASONS：一个基准测试，旨在利用公共及私有的大型语言模型（LLMs）检索并自动引用科学文献中的句子。](2024年05月03日/REASONS_A_benchmark_for_REtrieval_and_Automated_citationS_Of_scieNtific_Sentences_using_Public_and_Proprietary_LLMs.md)

- [FairEvalLLM. A Comprehensive Framework for Benchmarking Fairness in Large Language Model Recommender Systems](2024年05月03日/FairEvalLLM._A_Comprehensive_Framework_for_Benchmarking_Fairness_in_Large_Language_Model_Recommender_Systems.md)

    - [翻译: FairEvalLLM，为大型语言模型推荐系统公平性评估提供了一个全面的基准框架。](2024年05月03日/FairEvalLLM._A_Comprehensive_Framework_for_Benchmarking_Fairness_in_Large_Language_Model_Recommender_Systems.md)

- [Automatic Programming: Large Language Models and Beyond](2024年05月03日/Automatic_Programming_Large_Language_Models_and_Beyond.md)

    - [翻译: 自动编程：探索大型语言模型及其更广阔领域](2024年05月03日/Automatic_Programming_Large_Language_Models_and_Beyond.md)

- [Assessing and Verifying Task Utility in LLM-Powered Applications](2024年05月03日/Assessing_and_Verifying_Task_Utility_in_LLM-Powered_Applications.md)

    - [翻译: 探索大型语言模型（LLM）支持的应用程序中任务实用性的评估与验证。](2024年05月03日/Assessing_and_Verifying_Task_Utility_in_LLM-Powered_Applications.md)

- [EEG2TEXT: Open Vocabulary EEG-to-Text Decoding with EEG Pre-Training and Multi-View Transformer](2024年05月03日/EEG2TEXT_Open_Vocabulary_EEG-to-Text_Decoding_with_EEG_Pre-Training_and_Multi-View_Transformer.md)

    - [翻译: EEG2TEXT：采用 EEG 预训练和多视角变换技术，实现开放词汇表的 EEG 到文本的转换。](2024年05月03日/EEG2TEXT_Open_Vocabulary_EEG-to-Text_Decoding_with_EEG_Pre-Training_and_Multi-View_Transformer.md)

- [The AI Review Lottery: Widespread AI-Assisted Peer Reviews Boost Paper Scores and Acceptance Rates](2024年05月03日/The_AI_Review_Lottery_Widespread_AI-Assisted_Peer_Reviews_Boost_Paper_Scores_and_Acceptance_Rates.md)

    - [翻译: AI评审的幸运抽奖：当人工智能辅助的同行评审变得普遍时，它显著提升了论文的评分和被接受的概率。](2024年05月03日/The_AI_Review_Lottery_Widespread_AI-Assisted_Peer_Reviews_Boost_Paper_Scores_and_Acceptance_Rates.md)

- [MedReadMe: A Systematic Study for Fine-grained Sentence Readability in Medical Domain](2024年05月03日/MedReadMe_A_Systematic_Study_for_Fine-grained_Sentence_Readability_in_Medical_Domain.md)

    - [翻译: MedReadMe：深入探究医学领域内句子细粒度可读性的系统性研究](2024年05月03日/MedReadMe_A_Systematic_Study_for_Fine-grained_Sentence_Readability_in_Medical_Domain.md)

- [Optimising Calls to Large Language Models with Uncertainty-Based Two-Tier Selection](2024年05月03日/Optimising_Calls_to_Large_Language_Models_with_Uncertainty-Based_Two-Tier_Selection.md)

    - [翻译: 通过不确定性驱动的双层筛选机制，提升对大型语言模型调用的优化效果。](2024年05月03日/Optimising_Calls_to_Large_Language_Models_with_Uncertainty-Based_Two-Tier_Selection.md)

- [Unveiling the Potential of LLM-Based ASR on Chinese Open-Source Datasets](2024年05月03日/Unveiling_the_Potential_of_LLM-Based_ASR_on_Chinese_Open-Source_Datasets.md)

    - [翻译: 探索基于大型语言模型的自动语音识别技术在中文开源数据集中的应用潜力。](2024年05月03日/Unveiling_the_Potential_of_LLM-Based_ASR_on_Chinese_Open-Source_Datasets.md)

- [Single and Multi-Hop Question-Answering Datasets for Reticular Chemistry with GPT-4-Turbo](2024年05月03日/Single_and_Multi-Hop_Question-Answering_Datasets_for_Reticular_Chemistry_with_GPT-4-Turbo.md)

    - [翻译: 为 Reticular Chemistry 领域设计的单跳与多跳问答数据集，特别适配 GPT-4-Turbo 模型](2024年05月03日/Single_and_Multi-Hop_Question-Answering_Datasets_for_Reticular_Chemistry_with_GPT-4-Turbo.md)

- [Evaluating Large Language Models for Structured Science Summarization in the Open Research Knowledge Graph](2024年05月03日/Evaluating_Large_Language_Models_for_Structured_Science_Summarization_in_the_Open_Research_Knowledge_Graph.md)

    - [翻译: 本文旨在探讨大型语言模型在开放研究知识图谱框架下进行结构化科学摘要的表现。](2024年05月03日/Evaluating_Large_Language_Models_for_Structured_Science_Summarization_in_the_Open_Research_Knowledge_Graph.md)

- [Argumentative Large Language Models for Explainable and Contestable Decision-Making](2024年05月03日/Argumentative_Large_Language_Models_for_Explainable_and_Contestable_Decision-Making.md)

    - [翻译: 构建论辩型大型语言模型，旨在实现决策过程的可解释性和可争议性。](2024年05月03日/Argumentative_Large_Language_Models_for_Explainable_and_Contestable_Decision-Making.md)

- [Large Multimodal Model based Standardisation of Pathology Reports with Confidence and their Prognostic Significance](2024年05月03日/Large_Multimodal_Model_based_Standardisation_of_Pathology_Reports_with_Confidence_and_their_Prognostic_Significance.md)

    - [翻译: 利用大型多模态模型对病理报告进行标准化处理，同时评估其置信度和对疾病预后的影响。](2024年05月03日/Large_Multimodal_Model_based_Standardisation_of_Pathology_Reports_with_Confidence_and_their_Prognostic_Significance.md)

- [Analyzing Narrative Processing in Large Language Models (LLMs): Using GPT4 to test BERT](2024年05月03日/Analyzing_Narrative_Processing_in_Large_Language_Models_(LLMs)_Using_GPT4_to_test_BERT.md)

    - [翻译: 探索大型语言模型中的叙事处理能力：以 GPT-4 作为工具，对 BERT 进行测试分析](2024年05月03日/Analyzing_Narrative_Processing_in_Large_Language_Models_(LLMs)_Using_GPT4_to_test_BERT.md)

- [Exploring Combinatorial Problem Solving with Large Language Models: A Case Study on the Travelling Salesman Problem Using GPT-3.5 Turbo](2024年05月03日/Exploring_Combinatorial_Problem_Solving_with_Large_Language_Models_A_Case_Study_on_the_Travelling_Salesman_Problem_Using_GPT-3.5_Turbo.md)

    - [翻译: 本研究深入探讨了大型语言模型在解决组合问题上的能力，特别是以 GPT-3.5 Turbo 为工具，对旅行商问题进行了一项案例研究。](2024年05月03日/Exploring_Combinatorial_Problem_Solving_with_Large_Language_Models_A_Case_Study_on_the_Travelling_Salesman_Problem_Using_GPT-3.5_Turbo.md)

- [Conformal Prediction for Natural Language Processing: A Survey](2024年05月03日/Conformal_Prediction_for_Natural_Language_Processing_A_Survey.md)

    - [翻译: 一致性预测在自然语言处理领域的应用：综述研究](2024年05月03日/Conformal_Prediction_for_Natural_Language_Processing_A_Survey.md)

- [Dependency-Aware Semi-Structured Sparsity of GLU Variants in Large Language Models](2024年05月03日/Dependency-Aware_Semi-Structured_Sparsity_of_GLU_Variants_in_Large_Language_Models.md)

    - [翻译: 在大型语言模型中，GLU 变种的依赖感知半结构化稀疏性研究](2024年05月03日/Dependency-Aware_Semi-Structured_Sparsity_of_GLU_Variants_in_Large_Language_Models.md)

- [Which Identities Are Mobilized: Towards an automated detection of social group appeals in political texts](2024年05月03日/Which_Identities_Are_Mobilized_Towards_an_automated_detection_of_social_group_appeals_in_political_texts.md)

    - [翻译: 身份动员探析：政治文本中社会群体呼吁的自动化识别研究](2024年05月03日/Which_Identities_Are_Mobilized_Towards_an_automated_detection_of_social_group_appeals_in_political_texts.md)

- [Aloe: A Family of Fine-tuned Open Healthcare LLMs](2024年05月03日/Aloe_A_Family_of_Fine-tuned_Open_Healthcare_LLMs.md)

    - [翻译: Aloe：一套经过精细调整的开放医疗大型语言模型家族](2024年05月03日/Aloe_A_Family_of_Fine-tuned_Open_Healthcare_LLMs.md)

- [DALLMi: Domain Adaption for LLM-based Multi-label Classifier](2024年05月03日/DALLMi_Domain_Adaption_for_LLM-based_Multi-label_Classifier.md)

    - [翻译: DALLMi：为基于大型语言模型的多标签分类任务量身定制的领域适应技术。](2024年05月03日/DALLMi_Domain_Adaption_for_LLM-based_Multi-label_Classifier.md)

- [Automated Control Logic Test Case Generation using Large Language Models](2024年05月03日/Automated_Control_Logic_Test_Case_Generation_using_Large_Language_Models.md)

    - [翻译: 利用大型语言模型实现控制逻辑测试用例的自动生成](2024年05月03日/Automated_Control_Logic_Test_Case_Generation_using_Large_Language_Models.md)

- [Incorporating External Knowledge and Goal Guidance for LLM-based Conversational Recommender Systems](2024年05月03日/Incorporating_External_Knowledge_and_Goal_Guidance_for_LLM-based_Conversational_Recommender_Systems.md)

    - [翻译: 为基于大型语言模型的对话式推荐系统融入外部知识并引入目标导向。](2024年05月03日/Incorporating_External_Knowledge_and_Goal_Guidance_for_LLM-based_Conversational_Recommender_Systems.md)

- [SUKHSANDESH: An Avatar Therapeutic Question Answering Platform for Sexual Education in Rural India](2024年05月03日/SUKHSANDESH_An_Avatar_Therapeutic_Question_Answering_Platform_for_Sexual_Education_in_Rural_India.md)

    - [翻译: SUKHSANDESH：一个面向印度农村地区的性教育虚拟治疗问答平台。](2024年05月03日/SUKHSANDESH_An_Avatar_Therapeutic_Question_Answering_Platform_for_Sexual_Education_in_Rural_India.md)

- [SGHateCheck: Functional Tests for Detecting Hate Speech in Low-Resource Languages of Singapore](2024年05月03日/SGHateCheck_Functional_Tests_for_Detecting_Hate_Speech_in_Low-Resource_Languages_of_Singapore.md)

    - [翻译: SGHateCheck：一种功能性测试工具，旨在识别新加坡低资源语言中的仇恨言论。](2024年05月03日/SGHateCheck_Functional_Tests_for_Detecting_Hate_Speech_in_Low-Resource_Languages_of_Singapore.md)

- [Automating the Enterprise with Foundation Models](2024年05月03日/Automating_the_Enterprise_with_Foundation_Models.md)

    - [翻译: 借助基础模型，企业自动化得以实现。本研究旨在探索基础模型在企业自动化中的应用，并分析其对提升效率和创新能力的影响。](2024年05月03日/Automating_the_Enterprise_with_Foundation_Models.md)

2024年05月02日

- [Plan-Seq-Learn: Language Model Guided RL for Solving Long Horizon Robotics Tasks](2024年05月02日/Plan-Seq-Learn_Language_Model_Guided_RL_for_Solving_Long_Horizon_Robotics_Tasks.md)

    - [翻译: Plan-Seq-Learn：一种由语言模型引导的强化学习方法，专为解决机器人领域的长期任务而设计。](2024年05月02日/Plan-Seq-Learn_Language_Model_Guided_RL_for_Solving_Long_Horizon_Robotics_Tasks.md)

- [OmniDrive: A Holistic LLM-Agent Framework for Autonomous Driving with 3D Perception, Reasoning and Planning](2024年05月02日/OmniDrive_A_Holistic_LLM-Agent_Framework_for_Autonomous_Driving_with_3D_Perception,_Reasoning_and_Planning.md)

    - [翻译: OmniDrive：一套综合性的LLM代理框架，专为自动驾驶设计，集成了3D感知、推理和规划功能。](2024年05月02日/OmniDrive_A_Holistic_LLM-Agent_Framework_for_Autonomous_Driving_with_3D_Perception,_Reasoning_and_Planning.md)

- [FLAME: Factuality-Aware Alignment for Large Language Models](2024年05月02日/FLAME_Factuality-Aware_Alignment_for_Large_Language_Models.md)

    - [翻译: FLAME：为大型语言模型打造的事实感知对齐技术](2024年05月02日/FLAME_Factuality-Aware_Alignment_for_Large_Language_Models.md)

- [Transformer-Aided Semantic Communications](2024年05月02日/Transformer-Aided_Semantic_Communications.md)

    - [翻译: 借助Transformer的语义通信技术](2024年05月02日/Transformer-Aided_Semantic_Communications.md)

- [Analyzing the Role of Semantic Representations in the Era of Large Language Models](2024年05月02日/Analyzing_the_Role_of_Semantic_Representations_in_the_Era_of_Large_Language_Models.md)

    - [翻译: 在大型语言模型盛行的当下，深入探讨语义表示的角色与重要性。](2024年05月02日/Analyzing_the_Role_of_Semantic_Representations_in_the_Era_of_Large_Language_Models.md)

- [Supporting Business Document Workflows via Collection-Centric Information Foraging with Large Language Models](2024年05月02日/Supporting_Business_Document_Workflows_via_Collection-Centric_Information_Foraging_with_Large_Language_Models.md)

    - [翻译: 利用大型语言模型，通过集中式信息搜集，助力商业文档工作流程的优化。](2024年05月02日/Supporting_Business_Document_Workflows_via_Collection-Centric_Information_Foraging_with_Large_Language_Models.md)

- [Controllable Text Generation in the Instruction-Tuning Era](2024年05月02日/Controllable_Text_Generation_in_the_Instruction-Tuning_Era.md)

    - [翻译: 在指令调整时代下的可控文本生成](2024年05月02日/Controllable_Text_Generation_in_the_Instruction-Tuning_Era.md)

- [MANTIS: Interleaved Multi-Image Instruction Tuning](2024年05月02日/MANTIS_Interleaved_Multi-Image_Instruction_Tuning.md)

    - [翻译: MANTIS：交错式多图像指令优化](2024年05月02日/MANTIS_Interleaved_Multi-Image_Instruction_Tuning.md)

- [NeMo-Aligner: Scalable Toolkit for Efficient Model Alignment](2024年05月02日/NeMo-Aligner_Scalable_Toolkit_for_Efficient_Model_Alignment.md)

    - [翻译: NeMo-Aligner：高效模型对齐的可扩展工具集](2024年05月02日/NeMo-Aligner_Scalable_Toolkit_for_Efficient_Model_Alignment.md)

- [V-FLUTE: Visual Figurative Language Understanding with Textual Explanations](2024年05月02日/V-FLUTE_Visual_Figurative_Language_Understanding_with_Textual_Explanations.md)

    - [翻译: V-FLUTE：图文结合，洞悉视觉比喻语言的深层含义](2024年05月02日/V-FLUTE_Visual_Figurative_Language_Understanding_with_Textual_Explanations.md)

- [A Systematic Literature Review on Large Language Models for Automated Program Repair](2024年05月02日/A_Systematic_Literature_Review_on_Large_Language_Models_for_Automated_Program_Repair.md)

    - [翻译: 本文系统性地回顾了用于自动化程序修复的大型语言模型的相关文献。](2024年05月02日/A_Systematic_Literature_Review_on_Large_Language_Models_for_Automated_Program_Repair.md)

- [UQA: Corpus for Urdu Question Answering](2024年05月02日/UQA_Corpus_for_Urdu_Question_Answering.md)

    - [翻译: UQA：乌尔都语问答语料库](2024年05月02日/UQA_Corpus_for_Urdu_Question_Answering.md)

- [Creative Problem Solving in Large Language and Vision Models -- What Would it Take?](2024年05月02日/Creative_Problem_Solving_in_Large_Language_and_Vision_Models_--_What_Would_it_Take.md)

    - [翻译: 探索大型语言与视觉模型中的创新性问题解决之道 -- 我们该如何应对这一挑战？](2024年05月02日/Creative_Problem_Solving_in_Large_Language_and_Vision_Models_--_What_Would_it_Take.md)

- [Natural Language to Verilog: Design of a Recurrent Spiking Neural Network using Large Language Models and ChatGPT](2024年05月02日/Natural_Language_to_Verilog_Design_of_a_Recurrent_Spiking_Neural_Network_using_Large_Language_Models_and_ChatGPT.md)

    - [翻译: 将自然语言转换为 Verilog 代码：我们利用大型语言模型和 ChatGPT，设计了一种递归脉冲神经网络。](2024年05月02日/Natural_Language_to_Verilog_Design_of_a_Recurrent_Spiking_Neural_Network_using_Large_Language_Models_and_ChatGPT.md)

- [MiniGPT-3D: Efficiently Aligning 3D Point Clouds with Large Language Models using 2D Priors](2024年05月02日/MiniGPT-3D_Efficiently_Aligning_3D_Point_Clouds_with_Large_Language_Models_using_2D_Priors.md)

    - [翻译: MiniGPT-3D：借助2D先验，高效实现3D点云与大型语言模型的精准对齐。](2024年05月02日/MiniGPT-3D_Efficiently_Aligning_3D_Point_Clouds_with_Large_Language_Models_using_2D_Priors.md)

- [Verification and Refinement of Natural Language Explanations through LLM-Symbolic Theorem Proving](2024年05月02日/Verification_and_Refinement_of_Natural_Language_Explanations_through_LLM-Symbolic_Theorem_Proving.md)

    - [翻译: 利用大型语言模型（LLM）中的符号定理证明技术，对自然语言解释进行验证与优化。](2024年05月02日/Verification_and_Refinement_of_Natural_Language_Explanations_through_LLM-Symbolic_Theorem_Proving.md)

- [GAIA: A General AI Assistant for Intelligent Accelerator Operations](2024年05月02日/GAIA_A_General_AI_Assistant_for_Intelligent_Accelerator_Operations.md)

    - [翻译: GAIA：一款为智能化加速器运营提供助力的全能AI助手。](2024年05月02日/GAIA_A_General_AI_Assistant_for_Intelligent_Accelerator_Operations.md)

- [Human-Robot Interaction Conversational User Enjoyment Scale (HRI CUES)](2024年05月02日/Human-Robot_Interaction_Conversational_User_Enjoyment_Scale_(HRI_CUES).md)

    - [翻译: 人机互动对话用户愉悦度量表（HRI CUES）](2024年05月02日/Human-Robot_Interaction_Conversational_User_Enjoyment_Scale_(HRI_CUES).md)

- [The Power of Question Translation Training in Multilingual Reasoning: Broadened Scope and Deepened Insights](2024年05月02日/The_Power_of_Question_Translation_Training_in_Multilingual_Reasoning_Broadened_Scope_and_Deepened_Insights.md)

    - [翻译: 通过问题翻译训练提升多语言推理能力：拓展研究视野，深化理解深度。](2024年05月02日/The_Power_of_Question_Translation_Training_in_Multilingual_Reasoning_Broadened_Scope_and_Deepened_Insights.md)

- [Overcoming LLM Challenges using RAG-Driven Precision in Coffee Leaf Disease Remediation](2024年05月02日/Overcoming_LLM_Challenges_using_RAG-Driven_Precision_in_Coffee_Leaf_Disease_Remediation.md)

    - [翻译: 利用 RAG（Retrieval-Augmented Generation）技术提高精确度，有效应对大型语言模型在咖啡叶病害治理中的难题。](2024年05月02日/Overcoming_LLM_Challenges_using_RAG-Driven_Precision_in_Coffee_Leaf_Disease_Remediation.md)

- [The Effectiveness of LLMs as Annotators: A Comparative Overview and Empirical Analysis of Direct Representation](2024年05月02日/The_Effectiveness_of_LLMs_as_Annotators_A_Comparative_Overview_and_Empirical_Analysis_of_Direct_Representation.md)

    - [翻译: 探究大型语言模型作为注释工具的效能：一篇关于直接表征方法的对比概览与实证研究分析](2024年05月02日/The_Effectiveness_of_LLMs_as_Annotators_A_Comparative_Overview_and_Empirical_Analysis_of_Direct_Representation.md)

- [Reinforcement Learning for Edit-Based Non-Autoregressive Neural Machine Translation](2024年05月02日/Reinforcement_Learning_for_Edit-Based_Non-Autoregressive_Neural_Machine_Translation.md)

    - [翻译: 强化学习在基于编辑的非自回归神经机器翻译中的应用](2024年05月02日/Reinforcement_Learning_for_Edit-Based_Non-Autoregressive_Neural_Machine_Translation.md)

- [Prompt engineering paradigms for medical applications: scoping review and recommendations for better practices](2024年05月02日/Prompt_engineering_paradigms_for_medical_applications_scoping_review_and_recommendations_for_better_practices.md)

    - [翻译: 医疗领域提示工程的范式：全面审视与提升实践的建言](2024年05月02日/Prompt_engineering_paradigms_for_medical_applications_scoping_review_and_recommendations_for_better_practices.md)

- [Boosting Jailbreak Attack with Momentum](2024年05月02日/Boosting_Jailbreak_Attack_with_Momentum.md)

    - [翻译: 借助动量效应，提升越狱攻击的威力](2024年05月02日/Boosting_Jailbreak_Attack_with_Momentum.md)

- [DLAP: A Deep Learning Augmented Large Language Model Prompting Framework for Software Vulnerability Detection](2024年05月02日/DLAP_A_Deep_Learning_Augmented_Large_Language_Model_Prompting_Framework_for_Software_Vulnerability_Detection.md)

    - [翻译: DLAP：深度学习助力的大型语言模型提示框架，专为软件漏洞检测而设计。](2024年05月02日/DLAP_A_Deep_Learning_Augmented_Large_Language_Model_Prompting_Framework_for_Software_Vulnerability_Detection.md)

- [Generative Relevance Feedback and Convergence of Adaptive Re-Ranking: University of Glasgow Terrier Team at TREC DL 2023](2024年05月02日/Generative_Relevance_Feedback_and_Convergence_of_Adaptive_Re-Ranking_University_of_Glasgow_Terrier_Team_at_TREC_DL_2023.md)

    - [翻译: 格拉斯哥大学的特里尔团队在2023年TREC DL竞赛中展示了他们在生成式相关反馈和自适应重排序技术方面的成果，这些技术在信息检索任务中实现了显著的收敛效果。](2024年05月02日/Generative_Relevance_Feedback_and_Convergence_of_Adaptive_Re-Ranking_University_of_Glasgow_Terrier_Team_at_TREC_DL_2023.md)

- [Efficient Data Generation for Source-grounded Information-seeking Dialogs: A Use Case for Meeting Transcripts](2024年05月02日/Efficient_Data_Generation_for_Source-grounded_Information-seeking_Dialogs_A_Use_Case_for_Meeting_Transcripts.md)

    - [翻译: 高效数据生成：以会议记录为信息寻求型源-地面对话的用例](2024年05月02日/Efficient_Data_Generation_for_Source-grounded_Information-seeking_Dialogs_A_Use_Case_for_Meeting_Transcripts.md)

- ["In-Context Learning" or: How I learned to stop worrying and love "Applied Information Retrieval"](2024年05月02日/In-Context_Learning_or_How_I_learned_to_stop_worrying_and_love_Applied_Information_Retrieval.md)

    - [翻译: 《上下文学习》：我如何学会不再担忧并拥抱“应用信息检索”的世界](2024年05月02日/In-Context_Learning_or_How_I_learned_to_stop_worrying_and_love_Applied_Information_Retrieval.md)

- [LLM Security Guard for Code](2024年05月02日/LLM_Security_Guard_for_Code.md)

    - [翻译: 大型语言模型的安全守护者：代码防护](2024年05月02日/LLM_Security_Guard_for_Code.md)

- [Learning Object States from Actions via Large Language Models](2024年05月02日/Learning_Object_States_from_Actions_via_Large_Language_Models.md)

    - [翻译: 利用大型语言模型从动作中学习对象状态。](2024年05月02日/Learning_Object_States_from_Actions_via_Large_Language_Models.md)

- [Generating User Experience Based on Personas with AI Assistants](2024年05月02日/Generating_User_Experience_Based_on_Personas_with_AI_Assistants.md)

    - [翻译: 利用人工智能助手，根据人物角色创造用户体验](2024年05月02日/Generating_User_Experience_Based_on_Personas_with_AI_Assistants.md)

- [Causal Influence in Federated Edge Inference](2024年05月02日/Causal_Influence_in_Federated_Edge_Inference.md)

    - [翻译: 在联合边缘推理领域，因果关系的影响是一个关键因素。](2024年05月02日/Causal_Influence_in_Federated_Edge_Inference.md)

- [Improving Concept Alignment in Vision-Language Concept Bottleneck Models](2024年05月02日/Improving_Concept_Alignment_in_Vision-Language_Concept_Bottleneck_Models.md)

    - [翻译: 提升视觉-语言概念瓶颈模型中的概念一致性](2024年05月02日/Improving_Concept_Alignment_in_Vision-Language_Concept_Bottleneck_Models.md)

- [Efficient and Economic Large Language Model Inference with Attention Offloading](2024年05月02日/Efficient_and_Economic_Large_Language_Model_Inference_with_Attention_Offloading.md)

    - [翻译: 通过注意力卸载实现大型语言模型的高效经济推理](2024年05月02日/Efficient_and_Economic_Large_Language_Model_Inference_with_Attention_Offloading.md)

- [Exploiting ChatGPT for Diagnosing Autism-Associated Language Disorders and Identifying Distinct Features](2024年05月02日/Exploiting_ChatGPT_for_Diagnosing_Autism-Associated_Language_Disorders_and_Identifying_Distinct_Features.md)

    - [翻译: 通过 ChatGPT 来识别自闭症相关的语言障碍，并挖掘其独特的特征。](2024年05月02日/Exploiting_ChatGPT_for_Diagnosing_Autism-Associated_Language_Disorders_and_Identifying_Distinct_Features.md)

- [Towards Neural Synthesis for SMT-Assisted Proof-Oriented Programming](2024年05月02日/Towards_Neural_Synthesis_for_SMT-Assisted_Proof-Oriented_Programming.md)

    - [翻译: 探索神经合成技术，助力 SMT 支持的面向证明编程发展](2024年05月02日/Towards_Neural_Synthesis_for_SMT-Assisted_Proof-Oriented_Programming.md)

- [A Survey on Large Language Models for Critical Societal Domains: Finance, Healthcare, and Law](2024年05月02日/A_Survey_on_Large_Language_Models_for_Critical_Societal_Domains_Finance,_Healthcare,_and_Law.md)

    - [翻译: 一项针对金融、医疗保健和法律等关键社会领域内大型语言模型的综述研究](2024年05月02日/A_Survey_on_Large_Language_Models_for_Critical_Societal_Domains_Finance,_Healthcare,_and_Law.md)

- [CoS: Enhancing Personalization and Mitigating Bias with Context Steering](2024年05月02日/CoS_Enhancing_Personalization_and_Mitigating_Bias_with_Context_Steering.md)

    - [翻译: CoS技术：借助上下文导航，提升个性化体验，同时有效降低偏见风险。](2024年05月02日/CoS_Enhancing_Personalization_and_Mitigating_Bias_with_Context_Steering.md)

- [Large Language Models for UAVs: Current State and Pathways to the Future](2024年05月02日/Large_Language_Models_for_UAVs_Current_State_and_Pathways_to_the_Future.md)

    - [翻译: 无人机领域的大型语言模型：现状与未来展望。](2024年05月02日/Large_Language_Models_for_UAVs_Current_State_and_Pathways_to_the_Future.md)

- [ALCM: Autonomous LLM-Augmented Causal Discovery Framework](2024年05月02日/ALCM_Autonomous_LLM-Augmented_Causal_Discovery_Framework.md)

    - [翻译: ALCM：独立增强型大型语言模型因果探索框架](2024年05月02日/ALCM_Autonomous_LLM-Augmented_Causal_Discovery_Framework.md)

- [Question Suggestion for Conversational Shopping Assistants Using Product Metadata](2024年05月02日/Question_Suggestion_for_Conversational_Shopping_Assistants_Using_Product_Metadata.md)

    - [翻译: 利用产品元数据，为对话式购物助手提供问题建议](2024年05月02日/Question_Suggestion_for_Conversational_Shopping_Assistants_Using_Product_Metadata.md)

- [Large Language Models are Inconsistent and Biased Evaluators](2024年05月02日/Large_Language_Models_are_Inconsistent_and_Biased_Evaluators.md)

    - [翻译: 大型语言模型作为评估工具，存在不一致性和偏见问题。](2024年05月02日/Large_Language_Models_are_Inconsistent_and_Biased_Evaluators.md)

- [FSM Builder: A Tool for Writing Autograded Finite Automata Questions](2024年05月02日/FSM_Builder_A_Tool_for_Writing_Autograded_Finite_Automata_Questions.md)

    - [翻译: FSM Builder：一款编写自动评分有限自动机习题的工具](2024年05月02日/FSM_Builder_A_Tool_for_Writing_Autograded_Finite_Automata_Questions.md)

- [Requirements-driven Slicing of Simulink Models Using LLMs](2024年05月02日/Requirements-driven_Slicing_of_Simulink_Models_Using_LLMs.md)

    - [翻译: 运用大型语言模型 (LLMs) 实施对 Simulink 模型的基于需求的切片操作。](2024年05月02日/Requirements-driven_Slicing_of_Simulink_Models_Using_LLMs.md)

- [Language-Enhanced Latent Representations for Out-of-Distribution Detection in Autonomous Driving](2024年05月02日/Language-Enhanced_Latent_Representations_for_Out-of-Distribution_Detection_in_Autonomous_Driving.md)

    - [翻译: 为了在自动驾驶领域识别那些超出常规分布的异常情况，我们采用了一种语言增强的潜在表示方法。](2024年05月02日/Language-Enhanced_Latent_Representations_for_Out-of-Distribution_Detection_in_Autonomous_Driving.md)

- [Automatically Extracting Numerical Results from Randomized Controlled Trials with Large Language Models](2024年05月02日/Automatically_Extracting_Numerical_Results_from_Randomized_Controlled_Trials_with_Large_Language_Models.md)

    - [翻译: 利用大型语言模型，我们能够自动地从随机对照试验中抽取出数值数据。](2024年05月02日/Automatically_Extracting_Numerical_Results_from_Randomized_Controlled_Trials_with_Large_Language_Models.md)

- [Leveraging Prompt-Learning for Structured Information Extraction from Crohn's Disease Radiology Reports in a Low-Resource Language](2024年05月02日/Leveraging_Prompt-Learning_for_Structured_Information_Extraction_from_Crohn's_Disease_Radiology_Reports_in_a_Low-Resource_Language.md)

    - [翻译: 通过提示学习技术，我们能够从克罗恩病的放射学报告中高效提取结构化信息，即便在资源匮乏的语言环境中也表现出色。](2024年05月02日/Leveraging_Prompt-Learning_for_Structured_Information_Extraction_from_Crohn's_Disease_Radiology_Reports_in_a_Low-Resource_Language.md)

- [Generative AI in Cybersecurity](2024年05月02日/Generative_AI_in_Cybersecurity.md)

    - [翻译: 在网络安全领域，生成性人工智能的应用正日益显现其重要性。](2024年05月02日/Generative_AI_in_Cybersecurity.md)

- [WitheredLeaf: Finding Entity-Inconsistency Bugs with LLMs](2024年05月02日/WitheredLeaf_Finding_Entity-Inconsistency_Bugs_with_LLMs.md)

    - [翻译: WitheredLeaf：利用大型语言模型挖掘实体不一致性缺陷](2024年05月02日/WitheredLeaf_Finding_Entity-Inconsistency_Bugs_with_LLMs.md)

- [Investigating Wit, Creativity, and Detectability of Large Language Models in Domain-Specific Writing Style Adaptation of Reddit's Showerthoughts](2024年05月02日/Investigating_Wit,_Creativity,_and_Detectability_of_Large_Language_Models_in_Domain-Specific_Writing_Style_Adaptation_of_Reddit's_Showerthoughts.md)

    - [翻译: 本研究旨在探究大型语言模型在 Reddit Showerthoughts 社区特定写作风格适应中的机智、创造力及其可被察觉的程度。](2024年05月02日/Investigating_Wit,_Creativity,_and_Detectability_of_Large_Language_Models_in_Domain-Specific_Writing_Style_Adaptation_of_Reddit's_Showerthoughts.md)

- [Improving Complex Reasoning over Knowledge Graph with Logic-Aware Curriculum Tuning](2024年05月02日/Improving_Complex_Reasoning_over_Knowledge_Graph_with_Logic-Aware_Curriculum_Tuning.md)

    - [翻译: 本文探讨了如何通过逻辑感知的课程调整方法，提升在知识图谱上进行复杂推理的性能。](2024年05月02日/Improving_Complex_Reasoning_over_Knowledge_Graph_with_Logic-Aware_Curriculum_Tuning.md)

- [Automating the Analysis of Public Saliency and Attitudes towards Biodiversity from Digital Media](2024年05月02日/Automating_the_Analysis_of_Public_Saliency_and_Attitudes_towards_Biodiversity_from_Digital_Media.md)

    - [翻译: 自动化地从数字媒体中分析公众对生物多样性的关注点和态度](2024年05月02日/Automating_the_Analysis_of_Public_Saliency_and_Attitudes_towards_Biodiversity_from_Digital_Media.md)

- [CodeGRAG: Extracting Composed Syntax Graphs for Retrieval Augmented Cross-Lingual Code Generation](2024年05月02日/CodeGRAG_Extracting_Composed_Syntax_Graphs_for_Retrieval_Augmented_Cross-Lingual_Code_Generation.md)

    - [翻译: CodeGRAF：为增强检索的跨语言代码生成提取复合语法图。](2024年05月02日/CodeGRAG_Extracting_Composed_Syntax_Graphs_for_Retrieval_Augmented_Cross-Lingual_Code_Generation.md)

2024年05月01日

- [Is Bigger Edit Batch Size Always Better? -- An Empirical Study on Model Editing with Llama-3](2024年05月01日/Is_Bigger_Edit_Batch_Size_Always_Better_--_An_Empirical_Study_on_Model_Editing_with_Llama-3.md)

    - [翻译: 编辑批量大小越大，效果一定越佳吗？一项基于 Llama-3 模型编辑的实证探索。](2024年05月01日/Is_Bigger_Edit_Batch_Size_Always_Better_--_An_Empirical_Study_on_Model_Editing_with_Llama-3.md)

- [HalluVault: A Novel Logic Programming-aided Metamorphic Testing Framework for Detecting Fact-Conflicting Hallucinations in Large Language Models](2024年05月01日/HalluVault_A_Novel_Logic_Programming-aided_Metamorphic_Testing_Framework_for_Detecting_Fact-Conflicting_Hallucinations_in_Large_Language_Models.md)

    - [翻译: HalluVault：一个创新的基于逻辑编程的变异测试框架，专为发现大型语言模型中与事实相悖的幻觉现象而设计。](2024年05月01日/HalluVault_A_Novel_Logic_Programming-aided_Metamorphic_Testing_Framework_for_Detecting_Fact-Conflicting_Hallucinations_in_Large_Language_Models.md)

- [When Quantization Affects Confidence of Large Language Models?](2024年05月01日/When_Quantization_Affects_Confidence_of_Large_Language_Models.md)

    - [翻译: 量化如何影响大型语言模型的置信度？](2024年05月01日/When_Quantization_Affects_Confidence_of_Large_Language_Models.md)

- ["I'm Not Sure, But...": Examining the Impact of Large Language Models' Uncertainty Expression on User Reliance and Trust](2024年05月01日/I'm_Not_Sure,_But..._Examining_the_Impact_of_Large_Language_Models'_Uncertainty_Expression_on_User_Reliance_and_Trust.md)

    - [翻译: 《“我不确定，但是...”：探究大型语言模型不确定性表述对用户信赖与依赖的影响》](2024年05月01日/I'm_Not_Sure,_But..._Examining_the_Impact_of_Large_Language_Models'_Uncertainty_Expression_on_User_Reliance_and_Trust.md)

- [Addressing Topic Granularity and Hallucination in Large Language Models for Topic Modelling](2024年05月01日/Addressing_Topic_Granularity_and_Hallucination_in_Large_Language_Models_for_Topic_Modelling.md)

    - [翻译: 探讨大型语言模型在主题建模中的主题粒度细化与幻觉现象](2024年05月01日/Addressing_Topic_Granularity_and_Hallucination_in_Large_Language_Models_for_Topic_Modelling.md)

- [Investigating Automatic Scoring and Feedback using Large Language Models](2024年05月01日/Investigating_Automatic_Scoring_and_Feedback_using_Large_Language_Models.md)

    - [翻译: 探究基于大型语言模型的自动评分与反馈机制](2024年05月01日/Investigating_Automatic_Scoring_and_Feedback_using_Large_Language_Models.md)

- [Are Models Biased on Text without Gender-related Language?](2024年05月01日/Are_Models_Biased_on_Text_without_Gender-related_Language.md)

    - [翻译: 文本中若未涉及性别相关词汇，模型是否会表现出偏见？](2024年05月01日/Are_Models_Biased_on_Text_without_Gender-related_Language.md)

- [The Real, the Better: Aligning Large Language Models with Online Human Behaviors](2024年05月01日/The_Real,_the_Better_Aligning_Large_Language_Models_with_Online_Human_Behaviors.md)

    - [翻译: 追求真实，更上一层楼：使大型语言模型与网民在线行为同步。](2024年05月01日/The_Real,_the_Better_Aligning_Large_Language_Models_with_Online_Human_Behaviors.md)

- [EALD-MLLM: Emotion Analysis in Long-sequential and De-identity videos with Multi-modal Large Language Model](2024年05月01日/EALD-MLLM_Emotion_Analysis_in_Long-sequential_and_De-identity_videos_with_Multi-modal_Large_Language_Model.md)

    - [翻译: EALD-MLLM：利用多模态大型语言模型对长序列及去身份视频进行情感分析。](2024年05月01日/EALD-MLLM_Emotion_Analysis_in_Long-sequential_and_De-identity_videos_with_Multi-modal_Large_Language_Model.md)

- [NumLLM: Numeric-Sensitive Large Language Model for Chinese Finance](2024年05月01日/NumLLM_Numeric-Sensitive_Large_Language_Model_for_Chinese_Finance.md)

    - [翻译: NumLLM：一款专为中文金融领域设计的、对数值高度敏感的大型语言模型。](2024年05月01日/NumLLM_Numeric-Sensitive_Large_Language_Model_for_Chinese_Finance.md)

- [Mixture of insighTful Experts (MoTE): The Synergy of Thought Chains and Expert Mixtures in Self-Alignment](2024年05月01日/Mixture_of_insighTful_Experts_(MoTE)_The_Synergy_of_Thought_Chains_and_Expert_Mixtures_in_Self-Alignment.md)

    - [翻译: 洞察力专家混合体（MoTE）：在自我对齐的过程中，思维链与专家组合的相互促进。](2024年05月01日/Mixture_of_insighTful_Experts_(MoTE)_The_Synergy_of_Thought_Chains_and_Expert_Mixtures_in_Self-Alignment.md)

- [Long-Term Human Trajectory Prediction using 3D Dynamic Scene Graphs](2024年05月01日/Long-Term_Human_Trajectory_Prediction_using_3D_Dynamic_Scene_Graphs.md)

    - [翻译: 通过 3D 动态场景图实现对人类长期轨迹的精准预测。](2024年05月01日/Long-Term_Human_Trajectory_Prediction_using_3D_Dynamic_Scene_Graphs.md)

- [A Legal Framework for Natural Language Processing Model Training in Portugal](2024年05月01日/A_Legal_Framework_for_Natural_Language_Processing_Model_Training_in_Portugal.md)

    - [翻译: 葡萄牙建立了一个针对自然语言处理（NLP）模型训练的法律框架。](2024年05月01日/A_Legal_Framework_for_Natural_Language_Processing_Model_Training_in_Portugal.md)

- [ChatBI: Towards Natural Language to Complex Business Intelligence SQL](2024年05月01日/ChatBI_Towards_Natural_Language_to_Complex_Business_Intelligence_SQL.md)

    - [翻译: ChatBI：探索将自然语言转换为复杂的商业智能SQL语句的路径](2024年05月01日/ChatBI_Towards_Natural_Language_to_Complex_Business_Intelligence_SQL.md)

- [Navigating WebAI: Training Agents to Complete Web Tasks with Large Language Models and Reinforcement Learning](2024年05月01日/Navigating_WebAI_Training_Agents_to_Complete_Web_Tasks_with_Large_Language_Models_and_Reinforcement_Learning.md)

    - [翻译: 探索 WebAI：通过大型语言模型和强化学习训练代理来完成网络任务。](2024年05月01日/Navigating_WebAI_Training_Agents_to_Complete_Web_Tasks_with_Large_Language_Models_and_Reinforcement_Learning.md)

- [GOLD: Geometry Problem Solver with Natural Language Description](2024年05月01日/GOLD_Geometry_Problem_Solver_with_Natural_Language_Description.md)

    - [翻译: GOLD：一款能够理解自然语言描述来解决几何问题的智能求解器。](2024年05月01日/GOLD_Geometry_Problem_Solver_with_Natural_Language_Description.md)

- [Is Temperature the Creativity Parameter of Large Language Models?](2024年05月01日/Is_Temperature_the_Creativity_Parameter_of_Large_Language_Models.md)

    - [翻译: 温度是否决定了大型语言模型的创造力？](2024年05月01日/Is_Temperature_the_Creativity_Parameter_of_Large_Language_Models.md)

- [Explainable Automatic Grading with Neural Additive Models](2024年05月01日/Explainable_Automatic_Grading_with_Neural_Additive_Models.md)

    - [翻译: 神经加性模型在自动评分中的应用，实现了评分过程的可解释性。](2024年05月01日/Explainable_Automatic_Grading_with_Neural_Additive_Models.md)

- [The Pyramid of Captions](2024年05月01日/The_Pyramid_of_Captions.md)

    - [翻译: 标题层级金字塔](2024年05月01日/The_Pyramid_of_Captions.md)

- [BiomedRAG: A Retrieval Augmented Large Language Model for Biomedicine](2024年05月01日/BiomedRAG_A_Retrieval_Augmented_Large_Language_Model_for_Biomedicine.md)

    - [翻译: BiomedRAG：一种为生物医学领域设计的、结合了检索功能的先进大型语言模型。](2024年05月01日/BiomedRAG_A_Retrieval_Augmented_Large_Language_Model_for_Biomedicine.md)

- [Enhancing Surgical Robots with Embodied Intelligence for Autonomous Ultrasound Scanning](2024年05月01日/Enhancing_Surgical_Robots_with_Embodied_Intelligence_for_Autonomous_Ultrasound_Scanning.md)

    - [翻译: 为手术机器人注入体现智能，提升其进行自主超声扫描的性能。](2024年05月01日/Enhancing_Surgical_Robots_with_Embodied_Intelligence_for_Autonomous_Ultrasound_Scanning.md)

- [Monte Carlo Tree Search Boosts Reasoning via Iterative Preference Learning](2024年05月01日/Monte_Carlo_Tree_Search_Boosts_Reasoning_via_Iterative_Preference_Learning.md)

    - [翻译: 蒙特卡洛树搜索（MCTS）通过不断迭代的偏好学习，显著提升了推理能力。](2024年05月01日/Monte_Carlo_Tree_Search_Boosts_Reasoning_via_Iterative_Preference_Learning.md)

- [RAG-based Explainable Prediction of Road Users Behaviors for Automated Driving using Knowledge Graphs and Large Language Models](2024年05月01日/RAG-based_Explainable_Prediction_of_Road_Users_Behaviors_for_Automated_Driving_using_Knowledge_Graphs_and_Large_Language_Models.md)

    - [翻译: 利用知识图谱和大型语言模型，基于 RAG（Retrieval-Augmented Generation）框架，对自动驾驶中道路使用者的行为进行可解释预测。](2024年05月01日/RAG-based_Explainable_Prediction_of_Road_Users_Behaviors_for_Automated_Driving_using_Knowledge_Graphs_and_Large_Language_Models.md)

- [CultiVerse: Towards Cross-Cultural Understanding for Paintings with Large Language Model](2024年05月01日/CultiVerse_Towards_Cross-Cultural_Understanding_for_Paintings_with_Large_Language_Model.md)

    - [翻译: CultiVerse：迈向利用大型语言模型深化对绘画艺术的跨文化洞察。](2024年05月01日/CultiVerse_Towards_Cross-Cultural_Understanding_for_Paintings_with_Large_Language_Model.md)

- [Self-Refine Instruction-Tuning for Aligning Reasoning in Language Models](2024年05月01日/Self-Refine_Instruction-Tuning_for_Aligning_Reasoning_in_Language_Models.md)

    - [翻译: 自我精炼的指令调优：优化语言模型中的推理对齐。](2024年05月01日/Self-Refine_Instruction-Tuning_for_Aligning_Reasoning_in_Language_Models.md)

- [Inferring State Machine from the Protocol Implementation via Large Langeuage Model](2024年05月01日/Inferring_State_Machine_from_the_Protocol_Implementation_via_Large_Langeuage_Model.md)

    - [翻译: 利用大型语言模型，从协议实现中推导出状态机。](2024年05月01日/Inferring_State_Machine_from_the_Protocol_Implementation_via_Large_Langeuage_Model.md)

- [CofiPara: A Coarse-to-fine Paradigm for Multimodal Sarcasm Target Identification with Large Multimodal Models](2024年05月01日/CofiPara_A_Coarse-to-fine_Paradigm_for_Multimodal_Sarcasm_Target_Identification_with_Large_Multimodal_Models.md)

    - [翻译: CofiPara：一种从粗略到精细的多模态讽刺目标识别方法，适用于大型多模态模型。](2024年05月01日/CofiPara_A_Coarse-to-fine_Paradigm_for_Multimodal_Sarcasm_Target_Identification_with_Large_Multimodal_Models.md)

- [AdaMoLE: Fine-Tuning Large Language Models with Adaptive Mixture of Low-Rank Adaptation Experts](2024年05月01日/AdaMoLE_Fine-Tuning_Large_Language_Models_with_Adaptive_Mixture_of_Low-Rank_Adaptation_Experts.md)

    - [翻译: AdaMoLE：以自适应低秩专家混合策略，对大型语言模型进行精准微调。](2024年05月01日/AdaMoLE_Fine-Tuning_Large_Language_Models_with_Adaptive_Mixture_of_Low-Rank_Adaptation_Experts.md)

- [Exploring Self-Supervised Vision Transformers for Deepfake Detection: A Comparative Analysis](2024年05月01日/Exploring_Self-Supervised_Vision_Transformers_for_Deepfake_Detection_A_Comparative_Analysis.md)

    - [翻译: 本研究深入探讨了自监督视觉变换器在深度伪造检测中的应用，并进行了一项全面的比较分析。](2024年05月01日/Exploring_Self-Supervised_Vision_Transformers_for_Deepfake_Detection_A_Comparative_Analysis.md)

- [Distillation Matters: Empowering Sequential Recommenders to Match the Performance of Large Language Model](2024年05月01日/Distillation_Matters_Empowering_Sequential_Recommenders_to_Match_the_Performance_of_Large_Language_Model.md)

    - [翻译: 蒸馏技术至关重要：它能够提升序列推荐系统的性能，使其达到大型语言模型的水平。](2024年05月01日/Distillation_Matters_Empowering_Sequential_Recommenders_to_Match_the_Performance_of_Large_Language_Model.md)

- [A Careful Examination of Large Language Model Performance on Grade School Arithmetic](2024年05月01日/A_Careful_Examination_of_Large_Language_Model_Performance_on_Grade_School_Arithmetic.md)

    - [翻译: 深入剖析大型语言模型在小学算术任务上的表现](2024年05月01日/A_Careful_Examination_of_Large_Language_Model_Performance_on_Grade_School_Arithmetic.md)

- [Integrating A.I. in Higher Education: Protocol for a Pilot Study with 'SAMCares: An Adaptive Learning Hub'](2024年05月01日/Integrating_A.I._in_Higher_Education_Protocol_for_a_Pilot_Study_with_'SAMCares_An_Adaptive_Learning_Hub'.md)

    - [翻译: 融入人工智能于高等教育：开展“SAMCares：自适应学习平台”试点研究的方案](2024年05月01日/Integrating_A.I._in_Higher_Education_Protocol_for_a_Pilot_Study_with_'SAMCares_An_Adaptive_Learning_Hub'.md)

- [DFKI-NLP at SemEval-2024 Task 2: Towards Robust LLMs Using Data Perturbations and MinMax Training](2024年05月01日/DFKI-NLP_at_SemEval-2024_Task_2_Towards_Robust_LLMs_Using_Data_Perturbations_and_MinMax_Training.md)

    - [翻译: DFKI-NLP 团队参与了 SemEval-2024 的第二项任务，旨在通过数据扰动和 MinMax 训练方法，推动构建更加稳健的大型语言模型。](2024年05月01日/DFKI-NLP_at_SemEval-2024_Task_2_Towards_Robust_LLMs_Using_Data_Perturbations_and_MinMax_Training.md)

- [Distance Sampling-based Paraphraser Leveraging ChatGPT for Text Data Manipulation](2024年05月01日/Distance_Sampling-based_Paraphraser_Leveraging_ChatGPT_for_Text_Data_Manipulation.md)

    - [翻译: 利用 ChatGPT 的距离抽样技术，打造文本数据的释义神器。](2024年05月01日/Distance_Sampling-based_Paraphraser_Leveraging_ChatGPT_for_Text_Data_Manipulation.md)

- [Context-Aware Clustering using Large Language Models](2024年05月01日/Context-Aware_Clustering_using_Large_Language_Models.md)

    - [翻译: 本文探讨了利用大型语言模型进行上下文感知聚类的方法。](2024年05月01日/Context-Aware_Clustering_using_Large_Language_Models.md)

- [LLM-AD: Large Language Model based Audio Description System](2024年05月01日/LLM-AD_Large_Language_Model_based_Audio_Description_System.md)

    - [翻译: LLM-AD：一种依托于先进大型语言模型的音频描述解决方案](2024年05月01日/LLM-AD_Large_Language_Model_based_Audio_Description_System.md)

- [On the Evaluation of Machine-Generated Reports](2024年05月01日/On_the_Evaluation_of_Machine-Generated_Reports.md)

    - [翻译: 机器生成报告评估研究](2024年05月01日/On_the_Evaluation_of_Machine-Generated_Reports.md)

- [Bayesian Optimization with LLM-Based Acquisition Functions for Natural Language Preference Elicitation](2024年05月01日/Bayesian_Optimization_with_LLM-Based_Acquisition_Functions_for_Natural_Language_Preference_Elicitation.md)

    - [翻译: 利用基于大型语言模型的贝叶斯优化及获取函数，进行自然语言偏好的探索与激发。](2024年05月01日/Bayesian_Optimization_with_LLM-Based_Acquisition_Functions_for_Natural_Language_Preference_Elicitation.md)

- [A Hong Kong Sign Language Corpus Collected from Sign-interpreted TV News](2024年05月01日/A_Hong_Kong_Sign_Language_Corpus_Collected_from_Sign-interpreted_TV_News.md)

    - [翻译: 香港手语语料库：源自电视手语新闻的采集](2024年05月01日/A_Hong_Kong_Sign_Language_Corpus_Collected_from_Sign-interpreted_TV_News.md)

- [CACTUS: Chemistry Agent Connecting Tool-Usage to Science](2024年05月01日/CACTUS_Chemistry_Agent_Connecting_Tool-Usage_to_Science.md)

    - [翻译: CACTUS：化学智能代理与科学工具的连接平台](2024年05月01日/CACTUS_Chemistry_Agent_Connecting_Tool-Usage_to_Science.md)

- [How Can I Get It Right? Using GPT to Rephrase Incorrect Trainee Responses](2024年05月01日/How_Can_I_Get_It_Right_Using_GPT_to_Rephrase_Incorrect_Trainee_Responses.md)

    - [翻译: 如何正确表达？利用 GPT 对实习生的不准确回答进行改写。](2024年05月01日/How_Can_I_Get_It_Right_Using_GPT_to_Rephrase_Incorrect_Trainee_Responses.md)

- [Efficient Compression of Multitask Multilingual Speech Models](2024年05月01日/Efficient_Compression_of_Multitask_Multilingual_Speech_Models.md)

    - [翻译: 本文介绍了一种高效的多任务多语言语音模型压缩技术，旨在优化模型的存储和计算效率。](2024年05月01日/Efficient_Compression_of_Multitask_Multilingual_Speech_Models.md)

- [The Role of Model Architecture and Scale in Predicting Molecular Properties: Insights from Fine-Tuning RoBERTa, BART, and LLaMA](2024年05月01日/The_Role_of_Model_Architecture_and_Scale_in_Predicting_Molecular_Properties_Insights_from_Fine-Tuning_RoBERTa,_BART,_and_LLaMA.md)

    - [翻译: 探讨模型架构和规模对于分子属性预测的影响：通过对 RoBERTa、BART 和 LLaMA 进行微调获得的深刻见解。](2024年05月01日/The_Role_of_Model_Architecture_and_Scale_in_Predicting_Molecular_Properties_Insights_from_Fine-Tuning_RoBERTa,_BART,_and_LLaMA.md)

- [LLaVA Finds Free Lunch: Teaching Human Behavior Improves Content Understanding Abilities Of LLMs](2024年05月01日/LLaVA_Finds_Free_Lunch_Teaching_Human_Behavior_Improves_Content_Understanding_Abilities_Of_LLMs.md)

    - [翻译: LLaVA 揭示了一个意外的收获：通过教授人类行为，我们能够显著提升大型语言模型对内容的理解力。](2024年05月01日/LLaVA_Finds_Free_Lunch_Teaching_Human_Behavior_Improves_Content_Understanding_Abilities_Of_LLMs.md)

- [Characterising the Creative Process in Humans and Large Language Models](2024年05月01日/Characterising_the_Creative_Process_in_Humans_and_Large_Language_Models.md)

    - [翻译: 探索人类与大型语言模型的创意生成过程](2024年05月01日/Characterising_the_Creative_Process_in_Humans_and_Large_Language_Models.md)

- [Beyond Human Vision: The Role of Large Vision Language Models in Microscope Image Analysis](2024年05月01日/Beyond_Human_Vision_The_Role_of_Large_Vision_Language_Models_in_Microscope_Image_Analysis.md)

    - [翻译: 超越人眼所见：大型视觉语言模型在显微图像分析领域的应用](2024年05月01日/Beyond_Human_Vision_The_Role_of_Large_Vision_Language_Models_in_Microscope_Image_Analysis.md)

- [Math Multiple Choice Question Generation via Human-Large Language Model Collaboration](2024年05月01日/Math_Multiple_Choice_Question_Generation_via_Human-Large_Language_Model_Collaboration.md)

    - [翻译: 携手人类与大型语言模型，共创数学多项选择题](2024年05月01日/Math_Multiple_Choice_Question_Generation_via_Human-Large_Language_Model_Collaboration.md)

- [Can a Hallucinating Model help in Reducing Human "Hallucination"?](2024年05月01日/Can_a_Hallucinating_Model_help_in_Reducing_Human_Hallucination.md)

    - [翻译: 幻觉模型能否助力减轻人类的幻觉现象？](2024年05月01日/Can_a_Hallucinating_Model_help_in_Reducing_Human_Hallucination.md)

- [WIBA: What Is Being Argued? A Comprehensive Approach to Argument Mining](2024年05月01日/WIBA_What_Is_Being_Argued_A_Comprehensive_Approach_to_Argument_Mining.md)

    - [翻译: WIBA：争论的是什么？一种全面深入的论点挖掘方法。](2024年05月01日/WIBA_What_Is_Being_Argued_A_Comprehensive_Approach_to_Argument_Mining.md)

- [Efficient and Responsible Adaptation of Large Language Models for Robust Top-k Recommendations](2024年05月01日/Efficient_and_Responsible_Adaptation_of_Large_Language_Models_for_Robust_Top-k_Recommendations.md)

    - [翻译: 为了提供鲁棒的 Top-k 推荐，我们需对大型语言模型进行既高效又负责任的调整。](2024年05月01日/Efficient_and_Responsible_Adaptation_of_Large_Language_Models_for_Robust_Top-k_Recommendations.md)

- ["Ask Me Anything": How Comcast Uses LLMs to Assist Agents in Real Time](2024年05月01日/Ask_Me_Anything_How_Comcast_Uses_LLMs_to_Assist_Agents_in_Real_Time.md)

    - [翻译: "有问必答"：探究 Comcast 如何利用大型语言模型 (LLMs) 为代理提供实时协助。](2024年05月01日/Ask_Me_Anything_How_Comcast_Uses_LLMs_to_Assist_Agents_in_Real_Time.md)