# 2024年05月

2024年05月28日

- [Small volume bodies of constant width](2024年05月28日/Small_volume_bodies_of_constant_width.md)

    - [翻译: 微型恒宽体](2024年05月28日/Small_volume_bodies_of_constant_width.md)

2024年05月25日

- [A First Course in Monte Carlo Methods](2024年05月25日/A_First_Course_in_Monte_Carlo_Methods.md)

    - [翻译: 蒙特卡罗方法基础课程](2024年05月25日/A_First_Course_in_Monte_Carlo_Methods.md)

2024年05月23日

- [Embodied LLM Agents Learn to Cooperate in Organized Teams](2024年05月23日/Embodied_LLM_Agents_Learn_to_Cooperate_in_Organized_Teams.md)

    - [翻译: 具象化的 LLM 代理学会了在有组织的团队中协同合作。](2024年05月23日/Embodied_LLM_Agents_Learn_to_Cooperate_in_Organized_Teams.md)

2024年05月20日

- [Diffusion for World Modeling: Visual Details Matter in Atari](2024年05月20日/Diffusion_for_World_Modeling_Visual_Details_Matter_in_Atari.md)

    - [翻译: 在 Atari 游戏中，视觉细节对于世界建模的扩散过程至关重要。](2024年05月20日/Diffusion_for_World_Modeling_Visual_Details_Matter_in_Atari.md)

2024年05月07日

- [A Causal Explainable Guardrails for Large Language Models](2024年05月07日/A_Causal_Explainable_Guardrails_for_Large_Language_Models.md)

    - [翻译: 大型语言模型的因果解释性护栏在这篇文章中，我们将探讨如何为大型语言模型构建因果解释性保护措施，以确保其决策过程的透明度和可解释性。通过这种方式，我们不仅能够理解模型如何做出决策，还能确保其行为符合我们的预期和道德标准。](2024年05月07日/A_Causal_Explainable_Guardrails_for_Large_Language_Models.md)

- [Accelerating Speculative Decoding using Dynamic Speculation Length](2024年05月07日/Accelerating_Speculative_Decoding_using_Dynamic_Speculation_Length.md)

    - [翻译: 动态推测长度优化：加速语言模型解码的新策略在翻译过程中，我首先确保了原文意思的准确传达，然后对语言进行了优化，使其更加符合中文的表达习惯，同时保持了原文的生动性和简洁性。](2024年05月07日/Accelerating_Speculative_Decoding_using_Dynamic_Speculation_Length.md)

- [AffirmativeAI: Towards LGBTQ+ Friendly Audit Frameworks for Large Language Models](2024年05月07日/AffirmativeAI_Towards_LGBTQ+_Friendly_Audit_Frameworks_for_Large_Language_Models.md)

    - [翻译: AffirmativeAI：迈向大型语言模型的LGBTQ+友好审计框架。](2024年05月07日/AffirmativeAI_Towards_LGBTQ+_Friendly_Audit_Frameworks_for_Large_Language_Models.md)

- [A Fourth Wave of Open Data? Exploring the Spectrum of Scenarios for Open Data and Generative AI](2024年05月07日/A_Fourth_Wave_of_Open_Data_Exploring_the_Spectrum_of_Scenarios_for_Open_Data_and_Generative_AI.md)

    - [翻译: 开放数据的第四波浪潮？我们正探索开放数据与生成式AI交织的多元场景。](2024年05月07日/A_Fourth_Wave_of_Open_Data_Exploring_the_Spectrum_of_Scenarios_for_Open_Data_and_Generative_AI.md)

- [All in One Framework for Multimodal Re-identification in the Wild](2024年05月07日/All_in_One_Framework_for_Multimodal_Re-identification_in_the_Wild.md)

    - [翻译: 一体式框架：野外多模态身份再识别的全面解决方案](2024年05月07日/All_in_One_Framework_for_Multimodal_Re-identification_in_the_Wild.md)

- [A Method for Parsing and Vectorization of Semi-structured Data used in Retrieval Augmented Generation](2024年05月07日/A_Method_for_Parsing_and_Vectorization_of_Semi-structured_Data_used_in_Retrieval_Augmented_Generation.md)

    - [翻译: 一种解析与向量化半结构化数据的技艺，专为检索增强生成而设计](2024年05月07日/A_Method_for_Parsing_and_Vectorization_of_Semi-structured_Data_used_in_Retrieval_Augmented_Generation.md)

- [A Transformer with Stack Attention](2024年05月07日/A_Transformer_with_Stack_Attention.md)

    - [翻译: 堆叠注意力机制的Transformer在翻译过程中，我首先直接将英文翻译为中文，确保意思的准确性。然后，我对直译的中文进行了优化，使其更加符合中文的语言表达习惯，同时保持了原文的简洁和优雅。在第二个步骤中，我将“A Transformer with Stack Attention”优化为“堆叠注意力机制的Transformer”，这样的表达更加符合中文的表述习惯，同时也更加生动和易于理解。](2024年05月07日/A_Transformer_with_Stack_Attention.md)

- [AttacKG+:Boosting Attack Knowledge Graph Construction with Large Language Models](2024年05月07日/AttacKG+Boosting_Attack_Knowledge_Graph_Construction_with_Large_Language_Models.md)

    - [翻译: AttacKG+：借助大型语言模型，强化攻击知识图谱的构建能力](2024年05月07日/AttacKG+Boosting_Attack_Knowledge_Graph_Construction_with_Large_Language_Models.md)

- [BiasKG: Adversarial Knowledge Graphs to Induce Bias in Large Language Models](2024年05月07日/BiasKG_Adversarial_Knowledge_Graphs_to_Induce_Bias_in_Large_Language_Models.md)

    - [翻译: 偏见图谱BiasKG：塑造大型语言模型的对抗性知识网络，旨在引入并研究模型中的偏见现象。](2024年05月07日/BiasKG_Adversarial_Knowledge_Graphs_to_Induce_Bias_in_Large_Language_Models.md)

- [Bridging the Bosphorus: Advancing Turkish Large Language Models through Strategies for Low-Resource Language Adaptation and Benchmarking](2024年05月07日/Bridging_the_Bosphorus_Advancing_Turkish_Large_Language_Models_through_Strategies_for_Low-Resource_Language_Adaptation_and_Benchmarking.md)

    - [翻译: 博斯普鲁斯之桥：借助低资源语言适应与基准测试策略，推动土耳其大型语言模型的进步。](2024年05月07日/Bridging_the_Bosphorus_Advancing_Turkish_Large_Language_Models_through_Strategies_for_Low-Resource_Language_Adaptation_and_Benchmarking.md)

- [Chain of Thoughtlessness: An Analysis of CoT in Planning](2024年05月07日/Chain_of_Thoughtlessness_An_Analysis_of_CoT_in_Planning.md)

    - [翻译: 思维链的盲点：探究计划中思维链的运用与局限在翻译过程中，我首先确保原文的核心意义被准确传达，即对“思维链”（Chain of Thought）在计划制定中的应用进行分析。在第二步中，我调整了表达方式，使其更符合中文的修辞习惯，同时保持了原文的生动性和简洁性。通过使用“盲点”一词，我强调了研究中可能忽视的方面，同时也为读者提供了一个形象的视角来理解这一复杂的概念。](2024年05月07日/Chain_of_Thoughtlessness_An_Analysis_of_CoT_in_Planning.md)

- [ChatHuman: Language-driven 3D Human Understanding with Retrieval-Augmented Tool Reasoning](2024年05月07日/ChatHuman_Language-driven_3D_Human_Understanding_with_Retrieval-Augmented_Tool_Reasoning.md)

    - [翻译: ChatHuman：借助检索增强的工具推理，实现语言驱动的3D人体理解在这项研究中，我们提出了ChatHuman，一个创新系统，它通过结合语言理解和检索增强的工具推理，实现了对3D人体的深入理解。该系统不仅能够处理复杂的语言指令，还能够利用检索机制来增强其推理能力，从而在3D人体建模和交互任务中展现出卓越的性能。](2024年05月07日/ChatHuman_Language-driven_3D_Human_Understanding_with_Retrieval-Augmented_Tool_Reasoning.md)

- [COM3D: Leveraging Cross-View Correspondence and Cross-Modal Mining for 3D Retrieval](2024年05月07日/COM3D_Leveraging_Cross-View_Correspondence_and_Cross-Modal_Mining_for_3D_Retrieval.md)

    - [翻译: COM3D：借助跨视图匹配与跨模态挖掘，精进3D检索技艺在这项研究中，我们提出了一种名为COM3D的新型框架，它巧妙地结合了跨视图对应和跨模态挖掘技术，以提升3D对象检索的准确性和效率。通过深入分析不同视图间的内在联系，并挖掘多模态数据中的潜在信息，COM3D在3D检索领域展现了其独特的优势。](2024年05月07日/COM3D_Leveraging_Cross-View_Correspondence_and_Cross-Modal_Mining_for_3D_Retrieval.md)

- [Contextual API Completion for Unseen Repositories Using LLMs](2024年05月07日/Contextual_API_Completion_for_Unseen_Repositories_Using_LLMs.md)

    - [翻译: 借助大型语言模型，我们能够为未曾涉猎的代码库提供精准的上下文API自动补全功能。](2024年05月07日/Contextual_API_Completion_for_Unseen_Repositories_Using_LLMs.md)

- [Corporate Communication Companion (CCC): An LLM-empowered Writing Assistant for Workplace Social Media](2024年05月07日/Corporate_Communication_Companion_(CCC)_An_LLM-empowered_Writing_Assistant_for_Workplace_Social_Media.md)

    - [翻译: 职场社交写作良伴（CCC）：一款由先进 LLM 技术驱动的智能助手，专为提升企业沟通效率而生。](2024年05月07日/Corporate_Communication_Companion_(CCC)_An_LLM-empowered_Writing_Assistant_for_Workplace_Social_Media.md)

- [CourseGPT-zh: an Educational Large Language Model Based on Knowledge Distillation Incorporating Prompt Optimization](2024年05月07日/CourseGPT-zh_an_Educational_Large_Language_Model_Based_on_Knowledge_Distillation_Incorporating_Prompt_Optimization.md)

    - [翻译: CourseGPT-zh：融合知识蒸馏与提示优化技术的教育领域大型语言模型，旨在通过精炼的知识传递与优化学习提示，提升教育场景下的语言处理能力。](2024年05月07日/CourseGPT-zh_an_Educational_Large_Language_Model_Based_on_Knowledge_Distillation_Incorporating_Prompt_Optimization.md)

- [Deception in Reinforced Autonomous Agents: The Unconventional Rabbit Hat Trick in Legislation](2024年05月07日/Deception_in_Reinforced_Autonomous_Agents_The_Unconventional_Rabbit_Hat_Trick_in_Legislation.md)

    - [翻译: 强化自主代理中的欺骗行为：立法中的非传统兔子帽戏法之谜在强化自主代理领域，欺骗行为如同立法中的非传统兔子帽戏法，既神秘又引人入胜。这种行为在自主代理的决策过程中扮演着复杂角色，其影响深远，如同戏法中的兔子，既出人意料又充满变数。本研究将深入探讨这一现象，揭示其在立法框架下的独特影响。](2024年05月07日/Deception_in_Reinforced_Autonomous_Agents_The_Unconventional_Rabbit_Hat_Trick_in_Legislation.md)

- [D-NLP at SemEval-2024 Task 2: Evaluating Clinical Inference Capabilities of Large Language Models](2024年05月07日/D-NLP_at_SemEval-2024_Task_2_Evaluating_Clinical_Inference_Capabilities_of_Large_Language_Models.md)

    - [翻译: SemEval-2024 第二任务：探究大型语言模型在临床推理领域的评估能力在 SemEval-2024 的第二项任务中，我们将深入探讨大型语言模型在临床推理方面的表现。这项研究旨在评估这些模型在处理医疗相关文本时的推理能力，以及它们如何理解和分析临床情境中的复杂信息。通过这一评估，我们期望能够揭示大型语言模型在医疗领域应用中的潜力和局限性，为未来的医疗人工智能发展提供宝贵的见解。](2024年05月07日/D-NLP_at_SemEval-2024_Task_2_Evaluating_Clinical_Inference_Capabilities_of_Large_Language_Models.md)

- [Empathy Through Multimodality in Conversational Interfaces](2024年05月07日/Empathy_Through_Multimodality_in_Conversational_Interfaces.md)

    - [翻译: 对话接口中的多模态共情在对话接口中，通过多模态技术实现共情，旨在提升用户体验和交互的自然性。本研究探讨了如何整合视觉、听觉和语言信息，以增强对话系统对用户情感的理解和响应，从而在人机交互中营造出更加共情的氛围。](2024年05月07日/Empathy_Through_Multimodality_in_Conversational_Interfaces.md)

- [Enhancing Knowledge Retrieval with Topic Modeling for Knowledge-Grounded Dialogue](2024年05月07日/Enhancing_Knowledge_Retrieval_with_Topic_Modeling_for_Knowledge-Grounded_Dialogue.md)

    - [翻译: 利用主题建模提升知识检索，助力基于知识的对话系统更上一层楼。](2024年05月07日/Enhancing_Knowledge_Retrieval_with_Topic_Modeling_for_Knowledge-Grounded_Dialogue.md)

- [Enhancing LLM-Based Feedback: Insights from Intelligent Tutoring Systems and the Learning Sciences](2024年05月07日/Enhancing_LLM-Based_Feedback_Insights_from_Intelligent_Tutoring_Systems_and_the_Learning_Sciences.md)

    - [翻译: 提升大型语言模型反馈：智能辅导系统与学习科学的启示](2024年05月07日/Enhancing_LLM-Based_Feedback_Insights_from_Intelligent_Tutoring_Systems_and_the_Learning_Sciences.md)

- [Enhancing the Efficiency and Accuracy of Underlying Asset Reviews in Structured Finance: The Application of Multi-agent Framework](2024年05月07日/Enhancing_the_Efficiency_and_Accuracy_of_Underlying_Asset_Reviews_in_Structured_Finance_The_Application_of_Multi-agent_Framework.md)

    - [翻译: 结构化金融底层资产审查的效率与准确性提升：多代理框架的巧妙应用在结构化金融领域，底层资产的审查是确保交易稳健性的关键。传统的审查方法往往耗时且准确性有限。然而，多代理框架的引入，如同一场精妙的棋局，每个代理如同棋子，各司其职，协同作战，极大地提升了审查的效率与准确性。这一创新的应用，不仅优化了金融资产的评估流程，也为投资者提供了更为坚实的决策基础。](2024年05月07日/Enhancing_the_Efficiency_and_Accuracy_of_Underlying_Asset_Reviews_in_Structured_Finance_The_Application_of_Multi-agent_Framework.md)

- [Enriched BERT Embeddings for Scholarly Publication Classification](2024年05月07日/Enriched_BERT_Embeddings_for_Scholarly_Publication_Classification.md)

    - [翻译: BERT嵌入的丰富化助力学术出版物精准分类](2024年05月07日/Enriched_BERT_Embeddings_for_Scholarly_Publication_Classification.md)

- [Evaluating Text Summaries Generated by Large Language Models Using OpenAI's GPT](2024年05月07日/Evaluating_Text_Summaries_Generated_by_Large_Language_Models_Using_OpenAI's_GPT.md)

    - [翻译: 借助OpenAI的GPT，我们评估了大型语言模型所生成的文本摘要，探究其在信息提炼与表达上的精妙之处。](2024年05月07日/Evaluating_Text_Summaries_Generated_by_Large_Language_Models_Using_OpenAI's_GPT.md)

- [Exploring Vision Transformers for 3D Human Motion-Language Models with Motion Patches](2024年05月07日/Exploring_Vision_Transformers_for_3D_Human_Motion-Language_Models_with_Motion_Patches.md)

    - [翻译: 探究视觉变压器结合运动补丁在三维人体运动与语言模型中的应用，以深入理解其对运动表达的影响。](2024年05月07日/Exploring_Vision_Transformers_for_3D_Human_Motion-Language_Models_with_Motion_Patches.md)

- [FlashBack:Efficient Retrieval-Augmented Language Modeling for Long Context Inference](2024年05月07日/FlashBackEfficient_Retrieval-Augmented_Language_Modeling_for_Long_Context_Inference.md)

    - [翻译: 闪回技术：提升长篇推理中语言建模效率的检索增强方法](2024年05月07日/FlashBackEfficient_Retrieval-Augmented_Language_Modeling_for_Long_Context_Inference.md)

- [Fleet of Agents: Coordinated Problem Solving with Large Language Models using Genetic Particle Filtering](2024年05月07日/Fleet_of_Agents_Coordinated_Problem_Solving_with_Large_Language_Models_using_Genetic_Particle_Filtering.md)

    - [翻译: 遗传粒子滤波驱动的大型语言模型代理舰队：协同解决复杂问题的新策略](2024年05月07日/Fleet_of_Agents_Coordinated_Problem_Solving_with_Large_Language_Models_using_Genetic_Particle_Filtering.md)

- [Generative AI as a metacognitive agent: A comparative mixed-method study with human participants on ICF-mimicking exam performance](2024年05月07日/Generative_AI_as_a_metacognitive_agent_A_comparative_mixed-method_study_with_human_participants_on_ICF-mimicking_exam_performance.md)

    - [翻译: 生成式AI：元认知代理的比较研究——探究其在ICF模拟考试中与人类参与者的表现差异在这次比较混合方法研究中，我们探讨了生成式人工智能作为元认知代理在ICF模拟考试中的表现，并与人类参与者的表现进行了对比。通过这种方法，我们旨在揭示生成式AI在模拟考试环境中的潜力和局限性，以及它与人类认知过程的异同。](2024年05月07日/Generative_AI_as_a_metacognitive_agent_A_comparative_mixed-method_study_with_human_participants_on_ICF-mimicking_exam_performance.md)

- [Granite Code Models: A Family of Open Foundation Models for Code Intelligence](2024年05月07日/Granite_Code_Models_A_Family_of_Open_Foundation_Models_for_Code_Intelligence.md)

    - [翻译: 代码智能之石：花岗岩系列开源基础模型在](2024年05月07日/Granite_Code_Models_A_Family_of_Open_Foundation_Models_for_Code_Intelligence.md)

- [How does GPT-2 Predict Acronyms? Extracting and Understanding a Circuit via Mechanistic Interpretability](2024年05月07日/How_does_GPT-2_Predict_Acronyms_Extracting_and_Understanding_a_Circuit_via_Mechanistic_Interpretability.md)

    - [翻译: GPT-2如何巧妙预测缩写？我们通过机械可解释性的透镜，深入探索其内部运作，揭秘其预测缩写的神秘电路。](2024年05月07日/How_does_GPT-2_Predict_Acronyms_Extracting_and_Understanding_a_Circuit_via_Mechanistic_Interpretability.md)

- [In-context Learning for Automated Driving Scenarios](2024年05月07日/In-context_Learning_for_Automated_Driving_Scenarios.md)

    - [翻译: 自动驾驶场景中的上下文学习（ICL），为智能驾驶系统提供了新的学习范式。](2024年05月07日/In-context_Learning_for_Automated_Driving_Scenarios.md)

- [Iterative Experience Refinement of Software-Developing Agents](2024年05月07日/Iterative_Experience_Refinement_of_Software-Developing_Agents.md)

    - [翻译: 软件开发代理通过迭代精炼经验在](2024年05月07日/Iterative_Experience_Refinement_of_Software-Developing_Agents.md)

- [Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application](2024年05月07日/Knowledge_Adaptation_from_Large_Language_Model_to_Recommendation_for_Practical_Industrial_Application.md)

    - [翻译: 大型语言模型知识迁移至推荐系统：工业应用实践之路](2024年05月07日/Knowledge_Adaptation_from_Large_Language_Model_to_Recommendation_for_Practical_Industrial_Application.md)

- [Language Modeling Using Tensor Trains](2024年05月07日/Language_Modeling_Using_Tensor_Trains.md)

    - [翻译: 张量列车语言建模：探索语言的深层结构在翻译过程中，我首先确保了原文的核心概念“张量列车”和“语言建模”被准确传达。然后，在第二步中，我采用了更加生动和符合中文表达习惯的措辞，将“使用张量列车进行语言建模”转化为“张量列车语言建模：探索语言的深层结构”，这样的表述不仅简洁优雅，而且能够激发读者对这一技术主题的兴趣。](2024年05月07日/Language_Modeling_Using_Tensor_Trains.md)

- [Large Language Models Cannot Explain Themselves](2024年05月07日/Large_Language_Models_Cannot_Explain_Themselves.md)

    - [翻译: 巨型语言模型自解谜团难，其内在逻辑尚待深究。](2024年05月07日/Large_Language_Models_Cannot_Explain_Themselves.md)

- [Large Language Models for Cyber Security: A Systematic Literature Review](2024年05月07日/Large_Language_Models_for_Cyber_Security_A_Systematic_Literature_Review.md)

    - [翻译: 网络安全领域的大型语言模型：系统性文献综述探索在本次系统性文献综述中，我们将深入探讨大型语言模型在网络安全领域的应用，分析其在识别威胁、预测攻击模式以及自动化响应策略等方面的潜力与挑战。通过对现有文献的综合梳理，我们旨在揭示这些先进技术如何助力网络安全专家构筑更为坚固的数字防线。](2024年05月07日/Large_Language_Models_for_Cyber_Security_A_Systematic_Literature_Review.md)

- [Learning To See But Forgetting To Follow: Visual Instruction Tuning Makes LLMs More Prone To Jailbreak Attacks](2024年05月07日/Learning_To_See_But_Forgetting_To_Follow_Visual_Instruction_Tuning_Makes_LLMs_More_Prone_To_Jailbreak_Attacks.md)

    - [翻译: 视觉指令调教下的学习，大型语言模型虽能“看”得更清，却更易在“跟随”指令上失守，从而更易遭受越狱攻击。](2024年05月07日/Learning_To_See_But_Forgetting_To_Follow_Visual_Instruction_Tuning_Makes_LLMs_More_Prone_To_Jailbreak_Attacks.md)

- [LingML: Linguistic-Informed Machine Learning for Enhanced Fake News Detection](2024年05月07日/LingML_Linguistic-Informed_Machine_Learning_for_Enhanced_Fake_News_Detection.md)

    - [翻译: LingML：融合语言学智慧的机器学习，助力假新闻检测更上一层楼](2024年05月07日/LingML_Linguistic-Informed_Machine_Learning_for_Enhanced_Fake_News_Detection.md)

- [LLMs Can Patch Up Missing Relevance Judgments in Evaluation](2024年05月07日/LLMs_Can_Patch_Up_Missing_Relevance_Judgments_in_Evaluation.md)

    - [翻译: 大型语言模型（LLMs）具备修补评估中缺失相关性判断的能力，为评估体系的完善提供了新的可能性。](2024年05月07日/LLMs_Can_Patch_Up_Missing_Relevance_Judgments_in_Evaluation.md)

- [Locally Differentially Private In-Context Learning](2024年05月07日/Locally_Differentially_Private_In-Context_Learning.md)

    - [翻译: 局部差分隐私下的上下文学习在翻译过程中，我首先直接将英文标题翻译为中文，确保意思的准确性。然后，在第二步中，我进一步优化了翻译，使其更加符合中文的表达习惯，简洁而优雅。"局部差分隐私下的上下文学习"这个翻译既保留了原英文标题的含义，又使其在中文语境中更加通顺和易于理解。](2024年05月07日/Locally_Differentially_Private_In-Context_Learning.md)

- [MEDVOC: Vocabulary Adaptation for Fine-tuning Pre-trained Language Models on Medical Text Summarization](2024年05月07日/MEDVOC_Vocabulary_Adaptation_for_Fine-tuning_Pre-trained_Language_Models_on_Medical_Text_Summarization.md)

    - [翻译: MEDVOC：医学文本摘要中预训练语言模型的词汇微调适应在这项研究中，我们提出了MEDVOC，一种专门为医学文本摘要任务设计的词汇适应方法。通过微调预训练语言模型，MEDVOC旨在提高模型对医学领域特定术语和概念的理解，从而生成更准确、更具信息量的摘要。我们的方法结合了领域知识与先进的自然语言处理技术，为医学文献的自动化摘要提供了新的可能性。](2024年05月07日/MEDVOC_Vocabulary_Adaptation_for_Fine-tuning_Pre-trained_Language_Models_on_Medical_Text_Summarization.md)

- [NaturalCodeBench: Examining Coding Performance Mismatch on HumanEval and Natural User Prompts](2024年05月07日/NaturalCodeBench_Examining_Coding_Performance_Mismatch_on_HumanEval_and_Natural_User_Prompts.md)

    - [翻译: NaturalCodeBench：探究HumanEval与自然用户提示间编码性能的差异解释：在结果2中，我采用了更加流畅和符合中文表达习惯的翻译方式，将“Examining Coding Performance Mismatch”翻译为“探究编码性能的差异”，使得整个句子更加简洁优雅，同时保留了原文的意思。](2024年05月07日/NaturalCodeBench_Examining_Coding_Performance_Mismatch_on_HumanEval_and_Natural_User_Prompts.md)

- [NL2Plan: Robust LLM-Driven Planning from Minimal Text Descriptions](2024年05月07日/NL2Plan_Robust_LLM-Driven_Planning_from_Minimal_Text_Descriptions.md)

    - [翻译: NL2Plan：基于精简文本描述，实现大型语言模型驱动的稳健规划系统解释：在结果2中，我采用了更加流畅和符合中文表达习惯的措辞，将“Robust LLM-Driven Planning”翻译为“稳健规划系统”，并调整了“from Minimal Text Descriptions”的翻译，使其更加符合中文的表达方式。这样的翻译既保留了原文的核心意义，又使得中文表达更加自然和优雅。](2024年05月07日/NL2Plan_Robust_LLM-Driven_Planning_from_Minimal_Text_Descriptions.md)

- [Optimizing Language Model's Reasoning Abilities with Weak Supervision](2024年05月07日/Optimizing_Language_Model's_Reasoning_Abilities_with_Weak_Supervision.md)

    - [翻译: 借助弱监督之力，精炼语言模型的推理之智](2024年05月07日/Optimizing_Language_Model's_Reasoning_Abilities_with_Weak_Supervision.md)

- [QServe: W4A8KV4 Quantization and System Co-design for Efficient LLM Serving](2024年05月07日/QServe_W4A8KV4_Quantization_and_System_Co-design_for_Efficient_LLM_Serving.md)

    - [翻译: QServe：W4A8KV4 量化与系统协同设计，为大型语言模型服务提供高效解决方案](2024年05月07日/QServe_W4A8KV4_Quantization_and_System_Co-design_for_Efficient_LLM_Serving.md)

- [Revisiting character-level adversarial attacks](2024年05月07日/Revisiting_character-level_adversarial_attacks.md)

    - [翻译: 再探字符级对抗攻击：深入分析与挑战](2024年05月07日/Revisiting_character-level_adversarial_attacks.md)

- [Robust Implementation of Retrieval-Augmented Generation on Edge-based Computing-in-Memory Architectures](2024年05月07日/Robust_Implementation_of_Retrieval-Augmented_Generation_on_Edge-based_Computing-in-Memory_Architectures.md)

    - [翻译: 在内存计算架构的边缘计算环境中，增强检索生成的稳健实现解释：在](2024年05月07日/Robust_Implementation_of_Retrieval-Augmented_Generation_on_Edge-based_Computing-in-Memory_Architectures.md)

- [SEED-Data-Edit Technical Report: A Hybrid Dataset for Instructional Image Editing](2024年05月07日/SEED-Data-Edit_Technical_Report_A_Hybrid_Dataset_for_Instructional_Image_Editing.md)

    - [翻译: SEED-Data-Edit 技术报告：教学图像编辑的混合数据集探索在这份技术报告中，我们介绍了 SEED-Data-Edit，一个专为教学图像编辑而设计的混合数据集。该数据集结合了多种图像编辑任务，旨在为研究人员和开发者提供一个全面的资源，以探索和提升图像编辑技术的教学方法。通过深入分析数据集的构成和应用，我们希望激发更多关于图像编辑教学的创新思路和实践。](2024年05月07日/SEED-Data-Edit_Technical_Report_A_Hybrid_Dataset_for_Instructional_Image_Editing.md)

- [Semantic API Alignment: Linking High-level User Goals to APIs](2024年05月07日/Semantic_API_Alignment_Linking_High-level_User_Goals_to_APIs.md)

    - [翻译: 语义API匹配：构建高级用户目标与API之间的桥梁](2024年05月07日/Semantic_API_Alignment_Linking_High-level_User_Goals_to_APIs.md)

- [Sign2GPT: Leveraging Large Language Models for Gloss-Free Sign Language Translation](2024年05月07日/Sign2GPT_Leveraging_Large_Language_Models_for_Gloss-Free_Sign_Language_Translation.md)

    - [翻译: Sign2GPT：借助大型语言模型实现无词典辅助的美国手语翻译在这项研究中，我们提出了Sign2GPT，这是一种创新的方法，它利用了大型语言模型的强大能力，实现了无需依赖传统手势词典的美国手语翻译。通过这种方法，我们旨在打破传统翻译的局限，为手语用户提供更加流畅和自然的交流体验。](2024年05月07日/Sign2GPT_Leveraging_Large_Language_Models_for_Gloss-Free_Sign_Language_Translation.md)

- [Sketch Then Generate: Providing Incremental User Feedback and Guiding LLM Code Generation through Language-Oriented Code Sketches](2024年05月07日/Sketch_Then_Generate_Providing_Incremental_User_Feedback_and_Guiding_LLM_Code_Generation_through_Language-Oriented_Code_Sketches.md)

    - [翻译: 草绘启程，代码随行：借助语言导向的代码草图，我们逐步收集用户反馈，巧妙引导大型语言模型，使其代码生成更加精准。](2024年05月07日/Sketch_Then_Generate_Providing_Incremental_User_Feedback_and_Guiding_LLM_Code_Generation_through_Language-Oriented_Code_Sketches.md)

- [Sora Detector: A Unified Hallucination Detection for Large Text-to-Video Models](2024年05月07日/Sora_Detector_A_Unified_Hallucination_Detection_for_Large_Text-to-Video_Models.md)

    - [翻译: Sora检测器：大型文本至视频模型幻觉现象的统一检测利器](2024年05月07日/Sora_Detector_A_Unified_Hallucination_Detection_for_Large_Text-to-Video_Models.md)

- [The Silicone Ceiling: Auditing GPT's Race and Gender Biases in Hiring](2024年05月07日/The_Silicone_Ceiling_Auditing_GPT's_Race_and_Gender_Biases_in_Hiring.md)

    - [翻译: 硅胶屏障：审视GPT在招聘决策中潜藏的种族与性别偏见](2024年05月07日/The_Silicone_Ceiling_Auditing_GPT's_Race_and_Gender_Biases_in_Hiring.md)

- [Toward In-Context Teaching: Adapting Examples to Students' Misconceptions](2024年05月07日/Toward_In-Context_Teaching_Adapting_Examples_to_Students'_Misconceptions.md)

    - [翻译: 迈向情境化教学：量身定制示例，以纠正学生的认知误区](2024年05月07日/Toward_In-Context_Teaching_Adapting_Examples_to_Students'_Misconceptions.md)

- [Towards Accurate and Efficient Document Analytics with Large Language Models](2024年05月07日/Towards_Accurate_and_Efficient_Document_Analytics_with_Large_Language_Models.md)

    - [翻译: 大型语言模型助力精准高效文档分析](2024年05月07日/Towards_Accurate_and_Efficient_Document_Analytics_with_Large_Language_Models.md)

- [Towards a Theoretical Understanding of the 'Reversal Curse' via Training Dynamics](2024年05月07日/Towards_a_Theoretical_Understanding_of_the_'Reversal_Curse'_via_Training_Dynamics.md)

    - [翻译: 探索训练动态，揭开“逆转诅咒”的理论之谜在翻译过程中，我首先确保了原文意思的准确传达，然后对直译的中文进行了优化，使其更加符合中文的表达习惯，同时保持了原文的学术性和专业性。通过使用“探索”和“揭开”等动词，以及“理论之谜”这样的形象化表达，使得翻译后的中文更加生动活泼，简洁优雅。](2024年05月07日/Towards_a_Theoretical_Understanding_of_the_'Reversal_Curse'_via_Training_Dynamics.md)

- [TrimCaching: Parameter-sharing AI Model Caching in Wireless Edge Networks](2024年05月07日/TrimCaching_Parameter-sharing_AI_Model_Caching_in_Wireless_Edge_Networks.md)

    - [翻译: 精简缓存：无线边缘网络中的共享参数AI模型缓存技术在这项研究中，我们提出了一种名为“精简缓存”的新型技术，它旨在优化无线边缘网络中的AI模型缓存策略。通过共享参数，我们的方法能够更高效地利用网络资源，同时提供快速的AI服务响应。这种方法特别适用于资源受限的边缘环境，能够在保证性能的同时，减少对网络带宽和存储的需求。](2024年05月07日/TrimCaching_Parameter-sharing_AI_Model_Caching_in_Wireless_Edge_Networks.md)

- [Understanding the Capabilities and Limitations of Large Language Models for Cultural Commonsense](2024年05月07日/Understanding_the_Capabilities_and_Limitations_of_Large_Language_Models_for_Cultural_Commonsense.md)

    - [翻译: 探究大型语言模型在文化常识领域的潜能与边界](2024年05月07日/Understanding_the_Capabilities_and_Limitations_of_Large_Language_Models_for_Cultural_Commonsense.md)

- [Unveiling Disparities in Web Task Handling Between Human and Web Agent](2024年05月07日/Unveiling_Disparities_in_Web_Task_Handling_Between_Human_and_Web_Agent.md)

    - [翻译: 揭秘人类与网络代理在网络任务处理上的差异之谜](2024年05月07日/Unveiling_Disparities_in_Web_Task_Handling_Between_Human_and_Web_Agent.md)

- [Who Wrote This? The Key to Zero-Shot LLM-Generated Text Detection Is GECScore](2024年05月07日/Who_Wrote_This_The_Key_to_Zero-Shot_LLM-Generated_Text_Detection_Is_GECScore.md)

    - [翻译: 这篇文章的作者是谁？GECScore 是识别零-shot LLM 生成文本的关键工具。](2024年05月07日/Who_Wrote_This_The_Key_to_Zero-Shot_LLM-Generated_Text_Detection_Is_GECScore.md)

- [xLSTM: Extended Long Short-Term Memory](2024年05月07日/xLSTM_Extended_Long_Short-Term_Memory.md)

    - [翻译: xLSTM：拓展版长短期记忆网络在翻译过程中，我首先确保了原文的核心概念“Extended Long Short-Term Memory”被准确地翻译为“扩展的长短期记忆”。接着，在步骤2中，我考虑了中文表达的习惯，将“扩展的”调整为“拓展版”，使得翻译更加符合中文的表达习惯，同时保持了原文的含义和专业性。这样的翻译既简洁又优雅，同时也保持了原文的生动性。](2024年05月07日/xLSTM_Extended_Long_Short-Term_Memory.md)

- [Zero-shot LLM-guided Counterfactual Generation for Text](2024年05月07日/Zero-shot_LLM-guided_Counterfactual_Generation_for_Text.md)

    - [翻译: 大型语言模型零-shot引导的文本反事实创作在翻译过程中，我首先确保了原文意思的准确传达，然后对翻译结果进行了优化，使其更符合中文的表达习惯，同时保持了原文的生动性和简洁性。](2024年05月07日/Zero-shot_LLM-guided_Counterfactual_Generation_for_Text.md)

2024年05月06日

- [A Controlled Experiment on the Energy Efficiency of the Source Code Generated by Code Llama](2024年05月06日/A_Controlled_Experiment_on_the_Energy_Efficiency_of_the_Source_Code_Generated_by_Code_Llama.md)

    - [翻译: 一项针对 Code Llama 所生成源代码能效的控制性实验研究。](2024年05月06日/A_Controlled_Experiment_on_the_Energy_Efficiency_of_the_Source_Code_Generated_by_Code_Llama.md)

- [Adapting Dual-encoder Vision-language Models for Paraphrased Retrieval](2024年05月06日/Adapting_Dual-encoder_Vision-language_Models_for_Paraphrased_Retrieval.md)

    - [翻译: 适配双编码视觉-语言模型，优化释义检索性能。](2024年05月06日/Adapting_Dual-encoder_Vision-language_Models_for_Paraphrased_Retrieval.md)

- [Advancing Multimodal Medical Capabilities of Gemini](2024年05月06日/Advancing_Multimodal_Medical_Capabilities_of_Gemini.md)

    - [翻译: 提升双子座在多模态医疗领域的技术进步](2024年05月06日/Advancing_Multimodal_Medical_Capabilities_of_Gemini.md)

- [AlphaMath Almost Zero: process Supervision without process](2024年05月06日/AlphaMath_Almost_Zero_process_Supervision_without_process.md)

    - [翻译: AlphaMath 近乎零差错：实现无需过程的进程监控](2024年05月06日/AlphaMath_Almost_Zero_process_Supervision_without_process.md)

- [Anchored Answers: Unravelling Positional Bias in GPT-2's Multiple-Choice Questions](2024年05月06日/Anchored_Answers_Unravelling_Positional_Bias_in_GPT-2's_Multiple-Choice_Questions.md)

    - [翻译: 锚定答案：探究 GPT-2 多项选择题中的定位偏好之谜](2024年05月06日/Anchored_Answers_Unravelling_Positional_Bias_in_GPT-2's_Multiple-Choice_Questions.md)

- [A Philosophical Introduction to Language Models - Part II: The Way Forward](2024年05月06日/A_Philosophical_Introduction_to_Language_Models_-_Part_II_The_Way_Forward.md)

    - [翻译: 《语言模型哲学探析（下）：前行之路》](2024年05月06日/A_Philosophical_Introduction_to_Language_Models_-_Part_II_The_Way_Forward.md)

- [Are Human Rules Necessary? Generating Reusable APIs with CoT Reasoning and In-Context Learning](2024年05月06日/Are_Human_Rules_Necessary_Generating_Reusable_APIs_with_CoT_Reasoning_and_In-Context_Learning.md)

    - [翻译: 人类规则真有必要吗？借助 CoT 推理与上下文学习，我们能够生成可复用的 API。](2024年05月06日/Are_Human_Rules_Necessary_Generating_Reusable_APIs_with_CoT_Reasoning_and_In-Context_Learning.md)

- [AtomGPT: Atomistic Generative Pre-trained Transformer for Forward and Inverse Materials Design](2024年05月06日/AtomGPT_Atomistic_Generative_Pre-trained_Transformer_for_Forward_and_Inverse_Materials_Design.md)

    - [翻译: AtomGPT：一种原子级别的生成预训练变换器，专为正向和逆向材料设计而开发。](2024年05月06日/AtomGPT_Atomistic_Generative_Pre-trained_Transformer_for_Forward_and_Inverse_Materials_Design.md)

- [CityLLaVA: Efficient Fine-Tuning for VLMs in City Scenario](2024年05月06日/CityLLaVA_Efficient_Fine-Tuning_for_VLMs_in_City_Scenario.md)

    - [翻译: CityLLaVA：在城市环境中为超大型语言模型（VLM）实现高效微调的解决方案。](2024年05月06日/CityLLaVA_Efficient_Fine-Tuning_for_VLMs_in_City_Scenario.md)

- [Codexity: Secure AI-assisted Code Generation](2024年05月06日/Codexity_Secure_AI-assisted_Code_Generation.md)

    - [翻译: Codexity：保障安全的 AI 代码创作助手](2024年05月06日/Codexity_Secure_AI-assisted_Code_Generation.md)

- [Complex Video Reasoning and Robustness Evaluation Suite for Video-LMMs](2024年05月06日/Complex_Video_Reasoning_and_Robustness_Evaluation_Suite_for_Video-LMMs.md)

    - [翻译: 为视频大型语言模型（Video-LMMs）设计的一套复杂视频推理与鲁棒性评估工具。](2024年05月06日/Complex_Video_Reasoning_and_Robustness_Evaluation_Suite_for_Video-LMMs.md)

- [Detecting Anti-Semitic Hate Speech using Transformer-based Large Language Models](2024年05月06日/Detecting_Anti-Semitic_Hate_Speech_using_Transformer-based_Large_Language_Models.md)

    - [翻译: 运用Transformer架构的大型语言模型，精准识别反犹太仇恨言论，本研究深入探讨了该模型在敏感话题识别上的应用与挑战。](2024年05月06日/Detecting_Anti-Semitic_Hate_Speech_using_Transformer-based_Large_Language_Models.md)

- [Doing Personal LAPS: LLM-Augmented Dialogue Construction for Personalized Multi-Session Conversational Search](2024年05月06日/Doing_Personal_LAPS_LLM-Augmented_Dialogue_Construction_for_Personalized_Multi-Session_Conversational_Search.md)

    - [翻译: 个性化循环训练：借助大型语言模型，构建个性化的多轮对话，以优化个性化的多会话搜索体验。](2024年05月06日/Doing_Personal_LAPS_LLM-Augmented_Dialogue_Construction_for_Personalized_Multi-Session_Conversational_Search.md)

- [Enabling High-Sparsity Foundational Llama Models with Efficient Pretraining and Deployment](2024年05月06日/Enabling_High-Sparsity_Foundational_Llama_Models_with_Efficient_Pretraining_and_Deployment.md)

    - [翻译: 通过高效的预训练和部署策略，成功打造了高稀疏性基础的羊驼模型。](2024年05月06日/Enabling_High-Sparsity_Foundational_Llama_Models_with_Efficient_Pretraining_and_Deployment.md)

- [Enhancing Q-Learning with Large Language Model Heuristics](2024年05月06日/Enhancing_Q-Learning_with_Large_Language_Model_Heuristics.md)

    - [翻译: 利用大型语言模型的启发式方法来提升 Q-Learning 的性能](2024年05月06日/Enhancing_Q-Learning_with_Large_Language_Model_Heuristics.md)

- [ERAGent: Enhancing Retrieval-Augmented Language Models with Improved Accuracy, Efficiency, and Personalization](2024年05月06日/ERAGent_Enhancing_Retrieval-Augmented_Language_Models_with_Improved_Accuracy,_Efficiency,_and_Personalization.md)

    - [翻译: ERAGent：提升语言模型的检索增强能力，实现更精准、高效且个性化的语言处理](2024年05月06日/ERAGent_Enhancing_Retrieval-Augmented_Language_Models_with_Improved_Accuracy,_Efficiency,_and_Personalization.md)

- [ERATTA: Extreme RAG for Table To Answers with Large Language Models](2024年05月06日/ERATTA_Extreme_RAG_for_Table_To_Answers_with_Large_Language_Models.md)

    - [翻译: ERATTA：大型语言模型在表格至答案生成中的极致检索增强技术在这项研究中，我们提出了ERATTA，一种新颖的方法，它利用大型语言模型的强大能力，通过极端的检索增强生成（RAG）技术，从结构化数据中提取信息并生成准确的答案。这种方法特别适用于处理复杂的表格数据，能够有效地捕捉数据间的细微关联，并据此生成连贯且信息丰富的回答。](2024年05月06日/ERATTA_Extreme_RAG_for_Table_To_Answers_with_Large_Language_Models.md)

- [Explainable Fake News Detection With Large Language Model via Defense Among Competing Wisdom](2024年05月06日/Explainable_Fake_News_Detection_With_Large_Language_Model_via_Defense_Among_Competing_Wisdom.md)

    - [翻译: 利用大型语言模型，通过对抗竞争智慧中的策略，实现假新闻的可解释性检测。](2024年05月06日/Explainable_Fake_News_Detection_With_Large_Language_Model_via_Defense_Among_Competing_Wisdom.md)

- [Exploring the Frontiers of Softmax: Provable Optimization, Applications in Diffusion Model, and Beyond](2024年05月06日/Exploring_the_Frontiers_of_Softmax_Provable_Optimization,_Applications_in_Diffusion_Model,_and_Beyond.md)

    - [翻译: 深入 Softmax 的未知领域：验证优化的路径，扩散模型的创新应用，以及更广阔的研究前景。](2024年05月06日/Exploring_the_Frontiers_of_Softmax_Provable_Optimization,_Applications_in_Diffusion_Model,_and_Beyond.md)

- [Exploring the Potential of the Large Language Models (LLMs) in Identifying Misleading News Headlines](2024年05月06日/Exploring_the_Potential_of_the_Large_Language_Models_(LLMs)_in_Identifying_Misleading_News_Headlines.md)

    - [翻译: 本文旨在探讨大型语言模型（LLMs）在甄别具有误导性的新闻标题方面的潜在能力。](2024年05月06日/Exploring_the_Potential_of_the_Large_Language_Models_(LLMs)_in_Identifying_Misleading_News_Headlines.md)

- [Federated Reinforcement Learning with Constraint Heterogeneity](2024年05月06日/Federated_Reinforcement_Learning_with_Constraint_Heterogeneity.md)

    - [翻译: 在约束异质性条件下的联合强化学习研究](2024年05月06日/Federated_Reinforcement_Learning_with_Constraint_Heterogeneity.md)

- [Gaussian Stochastic Weight Averaging for Bayesian Low-Rank Adaptation of Large Language Models](2024年05月06日/Gaussian_Stochastic_Weight_Averaging_for_Bayesian_Low-Rank_Adaptation_of_Large_Language_Models.md)

    - [翻译: 贝叶斯低秩适配大型语言模型的高斯随机权重平均法](2024年05月06日/Gaussian_Stochastic_Weight_Averaging_for_Bayesian_Low-Rank_Adaptation_of_Large_Language_Models.md)

- [In Situ AI Prototyping: Infusing Multimodal Prompts into Mobile Settings with MobileMaker](2024年05月06日/In_Situ_AI_Prototyping_Infusing_Multimodal_Prompts_into_Mobile_Settings_with_MobileMaker.md)

    - [翻译: 现场AI原型制作：借助MobileMaker，将多模态提示注入移动场景，实现智能交互的即时创新。](2024年05月06日/In_Situ_AI_Prototyping_Infusing_Multimodal_Prompts_into_Mobile_Settings_with_MobileMaker.md)

- [Knowledge-aware Text-Image Retrieval for Remote Sensing Images](2024年05月06日/Knowledge-aware_Text-Image_Retrieval_for_Remote_Sensing_Images.md)

    - [翻译: 为遥感图像设计的文本与图像知识感知检索系统](2024年05月06日/Knowledge-aware_Text-Image_Retrieval_for_Remote_Sensing_Images.md)

- [KV Cache is 1 Bit Per Channel: Efficient Large Language Model Inference with Coupled Quantization](2024年05月06日/KV_Cache_is_1_Bit_Per_Channel_Efficient_Large_Language_Model_Inference_with_Coupled_Quantization.md)

    - [翻译: KV Cache 采用每通道1位的耦合量化策略，为大型语言模型推理提供了高效途径，实现了计算资源的优化利用。](2024年05月06日/KV_Cache_is_1_Bit_Per_Channel_Efficient_Large_Language_Model_Inference_with_Coupled_Quantization.md)

- [Language-Image Models with 3D Understanding](2024年05月06日/Language-Image_Models_with_3D_Understanding.md)

    - [翻译: 融合3D理解的语言与图像模型](2024年05月06日/Language-Image_Models_with_3D_Understanding.md)

- [Large Language Models as Instruments of Power: New Regimes of Autonomous Manipulation and Control](2024年05月06日/Large_Language_Models_as_Instruments_of_Power_New_Regimes_of_Autonomous_Manipulation_and_Control.md)

    - [翻译: 权力之弦：大型语言模型与自主操控的新纪元](2024年05月06日/Large_Language_Models_as_Instruments_of_Power_New_Regimes_of_Autonomous_Manipulation_and_Control.md)

- [Large Language Models (LLMs) as Agents for Augmented Democracy](2024年05月06日/Large_Language_Models_(LLMs)_as_Agents_for_Augmented_Democracy.md)

    - [翻译: 大型语言模型（LLMs）：民主增强的新使者](2024年05月06日/Large_Language_Models_(LLMs)_as_Agents_for_Augmented_Democracy.md)

- [Large Language Models Reveal Information Operation Goals, Tactics, and Narrative Frames](2024年05月06日/Large_Language_Models_Reveal_Information_Operation_Goals,_Tactics,_and_Narrative_Frames.md)

    - [翻译: 大型语言模型披露了信息战的作战目标、策略运用以及叙述构建的框架。](2024年05月06日/Large_Language_Models_Reveal_Information_Operation_Goals,_Tactics,_and_Narrative_Frames.md)

- [LGTM: Local-to-Global Text-Driven Human Motion Diffusion Model](2024年05月06日/LGTM_Local-to-Global_Text-Driven_Human_Motion_Diffusion_Model.md)

    - [翻译: LGTM：一种由文本驱动的人体运动扩散模型，实现了从局部细节到全局动作的全面覆盖。](2024年05月06日/LGTM_Local-to-Global_Text-Driven_Human_Motion_Diffusion_Model.md)

- [Liberating Seen Classes: Boosting Few-Shot and Zero-Shot Text Classification via Anchor Generation and Classification Reframing](2024年05月06日/Liberating_Seen_Classes_Boosting_Few-Shot_and_Zero-Shot_Text_Classification_via_Anchor_Generation_and_Classification_Reframing.md)

    - [翻译: 释放已知类别：通过生成锚点和重新构建分类框架，增强少样本与零样本文本分类的性能。](2024年05月06日/Liberating_Seen_Classes_Boosting_Few-Shot_and_Zero-Shot_Text_Classification_via_Anchor_Generation_and_Classification_Reframing.md)

- [Lifelong Knowledge Editing for LLMs with Retrieval-Augmented Continuous Prompt Learning](2024年05月06日/Lifelong_Knowledge_Editing_for_LLMs_with_Retrieval-Augmented_Continuous_Prompt_Learning.md)

    - [翻译: 在大型语言模型（LLMs）中，通过检索增强的连续提示学习方法，实现了终身知识的持续编辑与更新。](2024年05月06日/Lifelong_Knowledge_Editing_for_LLMs_with_Retrieval-Augmented_Continuous_Prompt_Learning.md)

- [Long Context Alignment with Short Instructions and Synthesized Positions](2024年05月06日/Long_Context_Alignment_with_Short_Instructions_and_Synthesized_Positions.md)

    - [翻译: 短指令与合成位置下的长上下文对齐策略](2024年05月06日/Long_Context_Alignment_with_Short_Instructions_and_Synthesized_Positions.md)

- [MAmmoTH2: Scaling Instructions from the Web](2024年05月06日/MAmmoTH2_Scaling_Instructions_from_the_Web.md)

    - [翻译: MAmmoTH2：网络指令的规模化应用](2024年05月06日/MAmmoTH2_Scaling_Instructions_from_the_Web.md)

- [MARE: Multi-Agents Collaboration Framework for Requirements Engineering](2024年05月06日/MARE_Multi-Agents_Collaboration_Framework_for_Requirements_Engineering.md)

    - [翻译: MARE：需求工程的多智能体协作框架](2024年05月06日/MARE_Multi-Agents_Collaboration_Framework_for_Requirements_Engineering.md)

- [MedDoc-Bot: A Chat Tool for Comparative Analysis of Large Language Models in the Context of the Pediatric Hypertension Guideline](2024年05月06日/MedDoc-Bot_A_Chat_Tool_for_Comparative_Analysis_of_Large_Language_Models_in_the_Context_of_the_Pediatric_Hypertension_Guideline.md)

    - [翻译: MedDoc-Bot：一款针对儿童高血压指南情境下，用于对比分析大型语言模型的智能聊天工具。](2024年05月06日/MedDoc-Bot_A_Chat_Tool_for_Comparative_Analysis_of_Large_Language_Models_in_the_Context_of_the_Pediatric_Hypertension_Guideline.md)

- [MMGER: Multi-modal and Multi-granularity Generative Error Correction with LLM for Joint Accent and Speech Recognition](2024年05月06日/MMGER_Multi-modal_and_Multi-granularity_Generative_Error_Correction_with_LLM_for_Joint_Accent_and_Speech_Recognition.md)

    - [翻译: MMGER是一种创新技术，它结合了大型语言模型（LLM），以多模态和多粒度的方式进行生成性错误校正，旨在同步提升口音识别和语音识别的准确性。](2024年05月06日/MMGER_Multi-modal_and_Multi-granularity_Generative_Error_Correction_with_LLM_for_Joint_Accent_and_Speech_Recognition.md)

- [OmniActions: Predicting Digital Actions in Response to Real-World Multimodal Sensory Inputs with LLMs](2024年05月06日/OmniActions_Predicting_Digital_Actions_in_Response_to_Real-World_Multimodal_Sensory_Inputs_with_LLMs.md)

    - [翻译: 全方位行动：借助大型语言模型，精准预测现实世界多模态感官刺激下的数字行动反应](2024年05月06日/OmniActions_Predicting_Digital_Actions_in_Response_to_Real-World_Multimodal_Sensory_Inputs_with_LLMs.md)

- [Oracle-Checker Scheme for Evaluating a Generative Large Language Model](2024年05月06日/Oracle-Checker_Scheme_for_Evaluating_a_Generative_Large_Language_Model.md)

    - [翻译: 探索评估生成型大型语言模型的 Oracle-Checker 机制](2024年05月06日/Oracle-Checker_Scheme_for_Evaluating_a_Generative_Large_Language_Model.md)

- [Organizing a Society of Language Models: Structures and Mechanisms for Enhanced Collective Intelligence](2024年05月06日/Organizing_a_Society_of_Language_Models_Structures_and_Mechanisms_for_Enhanced_Collective_Intelligence.md)

    - [翻译: 构建语言模型联盟：探索提升集体智慧的架构与机制](2024年05月06日/Organizing_a_Society_of_Language_Models_Structures_and_Mechanisms_for_Enhanced_Collective_Intelligence.md)

- [Outlier Gradient Analysis: Efficiently Improving Deep Learning Model Performance via Hessian-Free Influence Functions](2024年05月06日/Outlier_Gradient_Analysis_Efficiently_Improving_Deep_Learning_Model_Performance_via_Hessian-Free_Influence_Functions.md)

    - [翻译: 梯度异常分析：借助无黑塞矩阵的影响函数，我们能够精妙地提升深度学习模型的性能，如同巧匠雕琢宝石，使其光芒四射。](2024年05月06日/Outlier_Gradient_Analysis_Efficiently_Improving_Deep_Learning_Model_Performance_via_Hessian-Free_Influence_Functions.md)

- [Pose Priors from Language Models](2024年05月06日/Pose_Priors_from_Language_Models.md)

    - [翻译: 语言模型中提炼的姿态先验](2024年05月06日/Pose_Priors_from_Language_Models.md)

- [Position Paper: Leveraging Foundational Models for Black-Box Optimization: Benefits, Challenges, and Future Directions](2024年05月06日/Position_Paper_Leveraging_Foundational_Models_for_Black-Box_Optimization_Benefits,_Challenges,_and_Future_Directions.md)

    - [翻译: 立场论文：探索基础模型在黑盒优化中的应用——优势、挑战与前行之路。](2024年05月06日/Position_Paper_Leveraging_Foundational_Models_for_Black-Box_Optimization_Benefits,_Challenges,_and_Future_Directions.md)

- [Self-Improving Customer Review Response Generation Based on LLMs](2024年05月06日/Self-Improving_Customer_Review_Response_Generation_Based_on_LLMs.md)

    - [翻译: 大型语言模型驱动下的客户评论回复自我优化生成在翻译过程中，我首先确保原文的核心意义被准确传达，即“基于大型语言模型的自我改进客户评论回复生成”。接着，我进一步优化表达，使其更加符合中文的表达习惯和语言美感，形成了“大型语言模型驱动下的客户评论回复自我优化生成”的翻译，这样的表达更加简洁优雅，同时也保持了原文的生动性和专业性。](2024年05月06日/Self-Improving_Customer_Review_Response_Generation_Based_on_LLMs.md)

- [SEvenLLM: Benchmarking, Eliciting, and Enhancing Abilities of Large Language Models in Cyber Threat Intelligence](2024年05月06日/SEvenLLM_Benchmarking,_Eliciting,_and_Enhancing_Abilities_of_Large_Language_Models_in_Cyber_Threat_Intelligence.md)

    - [翻译: SEvenLLM：在网络威胁情报领域，对大型语言模型进行基准测试、能力挖掘与提升。](2024年05月06日/SEvenLLM_Benchmarking,_Eliciting,_and_Enhancing_Abilities_of_Large_Language_Models_in_Cyber_Threat_Intelligence.md)

- [Snake Learning: A Communication- and Computation-Efficient Distributed Learning Framework for 6G](2024年05月06日/Snake_Learning_A_Communication-_and_Computation-Efficient_Distributed_Learning_Framework_for_6G.md)

    - [翻译: Snake Learning，一个为第六代移动通信（6G）量身打造的分布式学习框架，以其卓越的通信和计算效率引领未来学习模式。](2024年05月06日/Snake_Learning_A_Communication-_and_Computation-Efficient_Distributed_Learning_Framework_for_6G.md)

- [Speak the Same Language: Global LiDAR Registration on BIM Using Pose Hough Transform](2024年05月06日/Speak_the_Same_Language_Global_LiDAR_Registration_on_BIM_Using_Pose_Hough_Transform.md)

    - [翻译: “共语”全球激光雷达注册：利用姿态霍夫变换在BIM上的精准对接](2024年05月06日/Speak_the_Same_Language_Global_LiDAR_Registration_on_BIM_Using_Pose_Hough_Transform.md)

- [SWE-agent: Agent-Computer Interfaces Enable Automated Software Engineering](2024年05月06日/SWE-agent_Agent-Computer_Interfaces_Enable_Automated_Software_Engineering.md)

    - [翻译: SWE-agent：通过代理-计算机接口，软件工程自动化得以实现](2024年05月06日/SWE-agent_Agent-Computer_Interfaces_Enable_Automated_Software_Engineering.md)

- [TED: Accelerate Model Training by Internal Generalization](2024年05月06日/TED_Accelerate_Model_Training_by_Internal_Generalization.md)

    - [翻译: TED：借助内部泛化提升模型训练效率](2024年05月06日/TED_Accelerate_Model_Training_by_Internal_Generalization.md)

- [The high dimensional psychological profile and cultural bias of ChatGPT](2024年05月06日/The_high_dimensional_psychological_profile_and_cultural_bias_of_ChatGPT.md)

    - [翻译: ChatGPT 拥有复杂的心理特征和文化倾向，这些特性在其多维心理画像中得到了体现。](2024年05月06日/The_high_dimensional_psychological_profile_and_cultural_bias_of_ChatGPT.md)

- [UnsafeBench: Benchmarking Image Safety Classifiers on Real-World and AI-Generated Images](2024年05月06日/UnsafeBench_Benchmarking_Image_Safety_Classifiers_on_Real-World_and_AI-Generated_Images.md)

    - [翻译: UnsafeBench 项目致力于对现实世界及 AI 创造的图像进行图像安全分类器的基准测试，旨在评估和提升图像安全分类技术的实际效能。](2024年05月06日/UnsafeBench_Benchmarking_Image_Safety_Classifiers_on_Real-World_and_AI-Generated_Images.md)

- [Vietnamese AI Generated Text Detection](2024年05月06日/Vietnamese_AI_Generated_Text_Detection.md)

    - [翻译: 越南AI文本生成检测](2024年05月06日/Vietnamese_AI_Generated_Text_Detection.md)

- [When LLMs Meet Cybersecurity: A Systematic Literature Review](2024年05月06日/When_LLMs_Meet_Cybersecurity_A_Systematic_Literature_Review.md)

    - [翻译: 大型语言模型（LLM）与网络安全的邂逅：一篇系统性的文献综述。](2024年05月06日/When_LLMs_Meet_Cybersecurity_A_Systematic_Literature_Review.md)

- [Whispy: Adapting STT Whisper Models to Real-Time Environments](2024年05月06日/Whispy_Adapting_STT_Whisper_Models_to_Real-Time_Environments.md)

    - [翻译: Whispy：为实时环境量身定制的 STT Whisper 模型](2024年05月06日/Whispy_Adapting_STT_Whisper_Models_to_Real-Time_Environments.md)

- [WorldQA: Multimodal World Knowledge in Videos through Long-Chain Reasoning](2024年05月06日/WorldQA_Multimodal_World_Knowledge_in_Videos_through_Long-Chain_Reasoning.md)

    - [翻译: WorldQA：通过长链推理，探索视频内容中的多模态世界知识](2024年05月06日/WorldQA_Multimodal_World_Knowledge_in_Videos_through_Long-Chain_Reasoning.md)

2024年05月05日

- [Agent Hospital: A Simulacrum of Hospital with Evolvable Medical Agents](2024年05月05日/Agent_Hospital_A_Simulacrum_of_Hospital_with_Evolvable_Medical_Agents.md)

    - [翻译: 《代理医院：一个可进化医疗代理的仿真医院》](2024年05月05日/Agent_Hospital_A_Simulacrum_of_Hospital_with_Evolvable_Medical_Agents.md)

- [Analysis about Theoretical Foundations for Method to Enhancing ASR Performance using OCR Word Frequency Differences](2024年05月05日/Analysis_about_Theoretical_Foundations_for_Method_to_Enhancing_ASR_Performance_using_OCR_Word_Frequency_Differences.md)

    - [翻译: 本文深入探讨了利用OCR单词频率差异提升自动语音识别（ASR）性能的方法背后的理论基础。](2024年05月05日/Analysis_about_Theoretical_Foundations_for_Method_to_Enhancing_ASR_Performance_using_OCR_Word_Frequency_Differences.md)

- [A scoping review of using Large Language Models (LLMs) to investigate Electronic Health Records (EHRs)](2024年05月05日/A_scoping_review_of_using_Large_Language_Models_(LLMs)_to_investigate_Electronic_Health_Records_(EHRs).md)

    - [翻译: 本文综述了利用大型语言模型（LLMs）来探究电子健康记录（EHRs）的应用情况。](2024年05月05日/A_scoping_review_of_using_Large_Language_Models_(LLMs)_to_investigate_Electronic_Health_Records_(EHRs).md)

- [ATAT: Astronomical Transformer for time series And Tabular data](2024年05月05日/ATAT_Astronomical_Transformer_for_time_series_And_Tabular_data.md)

    - [翻译: ATAT：一种专为时间序列和表格数据设计的天文变换模型](2024年05月05日/ATAT_Astronomical_Transformer_for_time_series_And_Tabular_data.md)

- [Automatic Retrieval-augmented Generation of 6G Network Specifications for Use Cases](2024年05月05日/Automatic_Retrieval-augmented_Generation_of_6G_Network_Specifications_for_Use_Cases.md)

    - [翻译: 自动增强检索技术在6G网络规范的自动生成中的应用，针对不同用例场景。](2024年05月05日/Automatic_Retrieval-augmented_Generation_of_6G_Network_Specifications_for_Use_Cases.md)

- [Can Large Language Models Make the Grade? An Empirical Study Evaluating LLMs Ability to Mark Short Answer Questions in K-12 Education](2024年05月05日/Can_Large_Language_Models_Make_the_Grade_An_Empirical_Study_Evaluating_LLMs_Ability_to_Mark_Short_Answer_Questions_in_K-12_Education.md)

    - [翻译: 大型语言模型能否担当起评分的重任？本实证研究深入探讨了这些模型在 K-12 教育领域评估简答题表现的能力。](2024年05月05日/Can_Large_Language_Models_Make_the_Grade_An_Empirical_Study_Evaluating_LLMs_Ability_to_Mark_Short_Answer_Questions_in_K-12_Education.md)

- [Compressing Long Context for Enhancing RAG with AMR-based Concept Distillation](2024年05月05日/Compressing_Long_Context_for_Enhancing_RAG_with_AMR-based_Concept_Distillation.md)

    - [翻译: 为了提升基于AMR（抽象意义表示）的RAG（Retrieval-Augmented Generation，检索增强生成）模型的性能，我们采用了一种压缩长文本的方法。](2024年05月05日/Compressing_Long_Context_for_Enhancing_RAG_with_AMR-based_Concept_Distillation.md)

- [CRAFT: Extracting and Tuning Cultural Instructions from the Wild](2024年05月05日/CRAFT_Extracting_and_Tuning_Cultural_Instructions_from_the_Wild.md)

    - [翻译: CRAFT：从现实世界中提炼并优化文化指南](2024年05月05日/CRAFT_Extracting_and_Tuning_Cultural_Instructions_from_the_Wild.md)

- [Exploring the Improvement of Evolutionary Computation via Large Language Models](2024年05月05日/Exploring_the_Improvement_of_Evolutionary_Computation_via_Large_Language_Models.md)

    - [翻译: 本文旨在探讨如何利用大型语言模型来提升进化计算的性能。](2024年05月05日/Exploring_the_Improvement_of_Evolutionary_Computation_via_Large_Language_Models.md)

- [FairMonitor: A Dual-framework for Detecting Stereotypes and Biases in Large Language Models](2024年05月05日/FairMonitor_A_Dual-framework_for_Detecting_Stereotypes_and_Biases_in_Large_Language_Models.md)

    - [翻译: FairMonitor：一套双重框架，专为发现大型语言模型中的刻板印象与偏见而设计。](2024年05月05日/FairMonitor_A_Dual-framework_for_Detecting_Stereotypes_and_Biases_in_Large_Language_Models.md)

- [GeoContrastNet: Contrastive Key-Value Edge Learning for Language-Agnostic Document Understanding](2024年05月05日/GeoContrastNet_Contrastive_Key-Value_Edge_Learning_for_Language-Agnostic_Document_Understanding.md)

    - [翻译: GeoContrastNet：一种对比关键值边缘学习方法，旨在实现对文档的深入理解，而不受语言限制。](2024年05月05日/GeoContrastNet_Contrastive_Key-Value_Edge_Learning_for_Language-Agnostic_Document_Understanding.md)

- [Graphical user interface agents optimization for visual instruction grounding using multi-modal artificial intelligence systems](2024年05月05日/Graphical_user_interface_agents_optimization_for_visual_instruction_grounding_using_multi-modal_artificial_intelligence_systems.md)

    - [翻译: 通过多模态AI系统优化图形用户界面的视觉指令接地](2024年05月05日/Graphical_user_interface_agents_optimization_for_visual_instruction_grounding_using_multi-modal_artificial_intelligence_systems.md)

- [High Order Reasoning for Time Critical Recommendation in Evidence-based Medicine](2024年05月05日/High_Order_Reasoning_for_Time_Critical_Recommendation_in_Evidence-based_Medicine.md)

    - [翻译: 在循证医学领域，面对紧急情况下的推荐决策，我们需运用高阶推理技巧。](2024年05月05日/High_Order_Reasoning_for_Time_Critical_Recommendation_in_Evidence-based_Medicine.md)

- [HuixiangDou-CR: Coreference Resolution in Group Chats](2024年05月05日/HuixiangDou-CR_Coreference_Resolution_in_Group_Chats.md)

    - [翻译: HuixiangDou-CR：群组聊天中的同指识别技术](2024年05月05日/HuixiangDou-CR_Coreference_Resolution_in_Group_Chats.md)

- [Language Evolution for Evading Social Media Regulation via LLM-based Multi-agent Simulation](2024年05月05日/Language_Evolution_for_Evading_Social_Media_Regulation_via_LLM-based_Multi-agent_Simulation.md)

    - [翻译: 本文探讨了如何利用基于大型语言模型（LLM）的多代理模拟技术，实现语言的进化以规避社交媒体的监管机制。](2024年05月05日/Language_Evolution_for_Evading_Social_Media_Regulation_via_LLM-based_Multi-agent_Simulation.md)

- [Learning from Students: Applying t-Distributions to Explore Accurate and Efficient Formats for LLMs](2024年05月05日/Learning_from_Students_Applying_t-Distributions_to_Explore_Accurate_and_Efficient_Formats_for_LLMs.md)

    - [翻译: 借鉴学子智慧：利用 t 分布探求适合大型语言模型的精准高效表达方式。](2024年05月05日/Learning_from_Students_Applying_t-Distributions_to_Explore_Accurate_and_Efficient_Formats_for_LLMs.md)

- [Leveraging Lecture Content for Improved Feedback: Explorations with GPT-4 and Retrieval Augmented Generation](2024年05月05日/Leveraging_Lecture_Content_for_Improved_Feedback_Explorations_with_GPT-4_and_Retrieval_Augmented_Generation.md)

    - [翻译: 借助GPT-4与检索增强生成技术，我们探索了如何利用讲座内容来提升反馈的精准度，旨在为教育领域带来更深层次的互动与改进。](2024年05月05日/Leveraging_Lecture_Content_for_Improved_Feedback_Explorations_with_GPT-4_and_Retrieval_Augmented_Generation.md)

- [MedAdapter: Efficient Test-Time Adaptation of Large Language Models towards Medical Reasoning](2024年05月05日/MedAdapter_Efficient_Test-Time_Adaptation_of_Large_Language_Models_towards_Medical_Reasoning.md)

    - [翻译: MedAdapter：为大型语言模型在医学推理任务中实现高效的测试时适应性](2024年05月05日/MedAdapter_Efficient_Test-Time_Adaptation_of_Large_Language_Models_towards_Medical_Reasoning.md)

- [NegativePrompt: Leveraging Psychology for Large Language Models Enhancement via Negative Emotional Stimuli](2024年05月05日/NegativePrompt_Leveraging_Psychology_for_Large_Language_Models_Enhancement_via_Negative_Emotional_Stimuli.md)

    - [翻译: 负面提示：运用心理学原理，通过负面情感刺激来提升大型语言模型的性能](2024年05月05日/NegativePrompt_Leveraging_Psychology_for_Large_Language_Models_Enhancement_via_Negative_Emotional_Stimuli.md)

- [On the performativity of SDG classifications in large bibliometric databases](2024年05月05日/On_the_performativity_of_SDG_classifications_in_large_bibliometric_databases.md)

    - [翻译: 在大型文献计量数据库中，对可持续发展目标（SDG）分类的绩效性进行探讨。](2024年05月05日/On_the_performativity_of_SDG_classifications_in_large_bibliometric_databases.md)

- [Overconfidence is Key: Verbalized Uncertainty Evaluation in Large Language and Vision-Language Models](2024年05月05日/Overconfidence_is_Key_Verbalized_Uncertainty_Evaluation_in_Large_Language_and_Vision-Language_Models.md)

    - [翻译: 自信过度，关键所在：探究大型语言及视觉-语言模型中的口头不确定性评估。](2024年05月05日/Overconfidence_is_Key_Verbalized_Uncertainty_Evaluation_in_Large_Language_and_Vision-Language_Models.md)

- [Quantifying the Capabilities of LLMs across Scale and Precision](2024年05月05日/Quantifying_the_Capabilities_of_LLMs_across_Scale_and_Precision.md)

    - [翻译: 探究并衡量大型语言模型在不同规模和精度层面的性能表现](2024年05月05日/Quantifying_the_Capabilities_of_LLMs_across_Scale_and_Precision.md)

- [Relay Decoding: Concatenating Large Language Models for Machine Translation](2024年05月05日/Relay_Decoding_Concatenating_Large_Language_Models_for_Machine_Translation.md)

    - [翻译: 中继解码技术：将大型语言模型串联起来，以提升机器翻译的性能。](2024年05月05日/Relay_Decoding_Concatenating_Large_Language_Models_for_Machine_Translation.md)

- [Revisiting a Pain in the Neck: Semantic Phrase Processing Benchmark for Language Models](2024年05月05日/Revisiting_a_Pain_in_the_Neck_Semantic_Phrase_Processing_Benchmark_for_Language_Models.md)

    - [翻译: 再次聚焦“颈部之痛”：为语言模型设立的语义短语处理性能评估标准](2024年05月05日/Revisiting_a_Pain_in_the_Neck_Semantic_Phrase_Processing_Benchmark_for_Language_Models.md)

- [Self-Reflection in LLM Agents: Effects on Problem-Solving Performance](2024年05月05日/Self-Reflection_in_LLM_Agents_Effects_on_Problem-Solving_Performance.md)

    - [翻译: 大型语言模型代理的自我审视：探索其对问题解决能力的提升作用](2024年05月05日/Self-Reflection_in_LLM_Agents_Effects_on_Problem-Solving_Performance.md)

- [Source-Free Domain Adaptation Guided by Vision and Vision-Language Pre-Training](2024年05月05日/Source-Free_Domain_Adaptation_Guided_by_Vision_and_Vision-Language_Pre-Training.md)

    - [翻译: 视觉与视觉-语言预训练引领的无源域自适应指南](2024年05月05日/Source-Free_Domain_Adaptation_Guided_by_Vision_and_Vision-Language_Pre-Training.md)

- [Stochastic RAG: End-to-End Retrieval-Augmented Generation through Expected Utility Maximization](2024年05月05日/Stochastic_RAG_End-to-End_Retrieval-Augmented_Generation_through_Expected_Utility_Maximization.md)

    - [翻译: 随机化 RAG：通过期望效用最大化实现一站式检索增强生成](2024年05月05日/Stochastic_RAG_End-to-End_Retrieval-Augmented_Generation_through_Expected_Utility_Maximization.md)

- [To Each (Textual Sequence) Its Own: Improving Memorized-Data Unlearning in Large Language Models](2024年05月05日/To_Each_(Textual_Sequence)_Its_Own_Improving_Memorized-Data_Unlearning_in_Large_Language_Models.md)

    - [翻译: 为每个文本序列量身定制：优化大型语言模型中的记忆数据忘却机制](2024年05月05日/To_Each_(Textual_Sequence)_Its_Own_Improving_Memorized-Data_Unlearning_in_Large_Language_Models.md)

- [Traffic Performance GPT (TP-GPT): Real-Time Data Informed Intelligent ChatBot for Transportation Surveillance and Management](2024年05月05日/Traffic_Performance_GPT_(TP-GPT)_Real-Time_Data_Informed_Intelligent_ChatBot_for_Transportation_Surveillance_and_Management.md)

    - [翻译: 交通性能 GPT（TP-GPT）：一款基于实时数据的智能聊天机器人，专为交通监控与管理量身定制。](2024年05月05日/Traffic_Performance_GPT_(TP-GPT)_Real-Time_Data_Informed_Intelligent_ChatBot_for_Transportation_Surveillance_and_Management.md)

- [Trojans in Large Language Models of Code: A Critical Review through a Trigger-Based Taxonomy](2024年05月05日/Trojans_in_Large_Language_Models_of_Code_A_Critical_Review_through_a_Trigger-Based_Taxonomy.md)

    - [翻译: 代码大型语言模型中的潜在威胁：基于触发机制的分类法进行的深入剖析。](2024年05月05日/Trojans_in_Large_Language_Models_of_Code_A_Critical_Review_through_a_Trigger-Based_Taxonomy.md)

- [Unraveling the Dominance of Large Language Models Over Transformer Models for Bangla Natural Language Inference: A Comprehensive Study](2024年05月05日/Unraveling_the_Dominance_of_Large_Language_Models_Over_Transformer_Models_for_Bangla_Natural_Language_Inference_A_Comprehensive_Study.md)

    - [翻译: 深入探究大型语言模型如何在孟加拉语自然语言推理任务中超越变换器模型：一项全面深入的研究。](2024年05月05日/Unraveling_the_Dominance_of_Large_Language_Models_Over_Transformer_Models_for_Bangla_Natural_Language_Inference_A_Comprehensive_Study.md)

- [Vector Quantization for Recommender Systems: A Review and Outlook](2024年05月05日/Vector_Quantization_for_Recommender_Systems_A_Review_and_Outlook.md)

    - [翻译: 向量量化技术在推荐系统领域的应用：回顾与前瞻。](2024年05月05日/Vector_Quantization_for_Recommender_Systems_A_Review_and_Outlook.md)

- [WDMoE: Wireless Distributed Large Language Models with Mixture of Experts](2024年05月05日/WDMoE_Wireless_Distributed_Large_Language_Models_with_Mixture_of_Experts.md)

    - [翻译: WDMoE：无线分布式大型语言模型，采用专家混合技术](2024年05月05日/WDMoE_Wireless_Distributed_Large_Language_Models_with_Mixture_of_Experts.md)

2024年05月04日

- [A self-supervised text-vision framework for automated brain abnormality detection](2024年05月04日/A_self-supervised_text-vision_framework_for_automated_brain_abnormality_detection.md)

    - [翻译: 本研究提出了一种自监督的文本-视觉框架，旨在自动化地检测大脑异常。](2024年05月04日/A_self-supervised_text-vision_framework_for_automated_brain_abnormality_detection.md)

- [Assessing Adversarial Robustness of Large Language Models: An Empirical Study](2024年05月04日/Assessing_Adversarial_Robustness_of_Large_Language_Models_An_Empirical_Study.md)

    - [翻译: 探究大型语言模型的对抗性防御能力：实证分析。](2024年05月04日/Assessing_Adversarial_Robustness_of_Large_Language_Models_An_Empirical_Study.md)

- [Beyond Performance: Quantifying and Mitigating Label Bias in LLMs](2024年05月04日/Beyond_Performance_Quantifying_and_Mitigating_Label_Bias_in_LLMs.md)

    - [翻译: 超越单纯的性能指标，本文致力于量化并缓解大型语言模型（LLM）中的标签偏见问题。](2024年05月04日/Beyond_Performance_Quantifying_and_Mitigating_Label_Bias_in_LLMs.md)

- [Can Nuanced Language Lead to More Actionable Insights? Exploring the Role of Generative AI in Analytical Narrative Structure](2024年05月04日/Can_Nuanced_Language_Lead_to_More_Actionable_Insights_Exploring_the_Role_of_Generative_AI_in_Analytical_Narrative_Structure.md)

    - [翻译: 能否通过微妙的语言获得更可行的洞察？本文深入探讨了生成性人工智能在构建分析性叙述结构中的关键角色。](2024年05月04日/Can_Nuanced_Language_Lead_to_More_Actionable_Insights_Exploring_the_Role_of_Generative_AI_in_Analytical_Narrative_Structure.md)

- [Confidential and Protected Disease Classifier using Fully Homomorphic Encryption](2024年05月04日/Confidential_and_Protected_Disease_Classifier_using_Fully_Homomorphic_Encryption.md)

    - [翻译: 采用全同态加密技术，打造安全可靠的疾病分类系统。](2024年05月04日/Confidential_and_Protected_Disease_Classifier_using_Fully_Homomorphic_Encryption.md)

- [Enhancing Contextual Understanding in Large Language Models through Contrastive Decoding](2024年05月04日/Enhancing_Contextual_Understanding_in_Large_Language_Models_through_Contrastive_Decoding.md)

    - [翻译: 通过对比解码技术，提升大型语言模型对上下文的理解能力。](2024年05月04日/Enhancing_Contextual_Understanding_in_Large_Language_Models_through_Contrastive_Decoding.md)

- [Improve Temporal Awareness of LLMs for Sequential Recommendation](2024年05月04日/Improve_Temporal_Awareness_of_LLMs_for_Sequential_Recommendation.md)

    - [翻译: 提升大型语言模型在序列推荐任务中的时间意识。](2024年05月04日/Improve_Temporal_Awareness_of_LLMs_for_Sequential_Recommendation.md)

- [IQLS: Framework for leveraging Metadata to enable Large Language Model based queries to complex, versatile Data](2024年05月04日/IQLS_Framework_for_leveraging_Metadata_to_enable_Large_Language_Model_based_queries_to_complex,_versatile_Data.md)

    - [翻译: IQLS框架：借助元数据，让大型语言模型轻松驾驭复杂多变的数据查询](2024年05月04日/IQLS_Framework_for_leveraging_Metadata_to_enable_Large_Language_Model_based_queries_to_complex,_versatile_Data.md)

- [Large Language Models estimate fine-grained human color-concept associations](2024年05月04日/Large_Language_Models_estimate_fine-grained_human_color-concept_associations.md)

    - [翻译: 大型语言模型精准捕捉人类颜色概念的微妙关联](2024年05月04日/Large_Language_Models_estimate_fine-grained_human_color-concept_associations.md)

- [Mozart's Touch: A Lightweight Multi-modal Music Generation Framework Based on Pre-Trained Large Models](2024年05月04日/Mozart's_Touch_A_Lightweight_Multi-modal_Music_Generation_Framework_Based_on_Pre-Trained_Large_Models.md)

    - [翻译: 《莫扎特之触》：一款轻量级多模态音乐创作框架，依托于预训练的大型语言模型。](2024年05月04日/Mozart's_Touch_A_Lightweight_Multi-modal_Music_Generation_Framework_Based_on_Pre-Trained_Large_Models.md)

- [Octopi: Object Property Reasoning with Large Tactile-Language Models](2024年05月04日/Octopi_Object_Property_Reasoning_with_Large_Tactile-Language_Models.md)

    - [翻译: Octopi：通过大型触觉-语言模型进行物体属性推理](2024年05月04日/Octopi_Object_Property_Reasoning_with_Large_Tactile-Language_Models.md)

- [PropertyGPT: LLM-driven Formal Verification of Smart Contracts through Retrieval-Augmented Property Generation](2024年05月04日/PropertyGPT_LLM-driven_Formal_Verification_of_Smart_Contracts_through_Retrieval-Augmented_Property_Generation.md)

    - [翻译: PropertyGPT，一种利用大型语言模型（LLM）进行智能合约形式化验证的创新方法，通过增强检索的属性生成技术，为智能合约的安全性分析提供了新的视角。](2024年05月04日/PropertyGPT_LLM-driven_Formal_Verification_of_Smart_Contracts_through_Retrieval-Augmented_Property_Generation.md)

- [R4: Reinforced Retriever-Reorder-Responder for Retrieval-Augmented Large Language Models](2024年05月04日/R4_Reinforced_Retriever-Reorder-Responder_for_Retrieval-Augmented_Large_Language_Models.md)

    - [翻译: R4：强化版检索-重排-响应机制，专为检索增强型大型语言模型设计。](2024年05月04日/R4_Reinforced_Retriever-Reorder-Responder_for_Retrieval-Augmented_Large_Language_Models.md)

- [Recall Them All: Retrieval-Augmented Language Models for Long Object List Extraction from Long Documents](2024年05月04日/Recall_Them_All_Retrieval-Augmented_Language_Models_for_Long_Object_List_Extraction_from_Long_Documents.md)

    - [翻译: 全面召回：增强检索的语言模型，专为从长篇文档中抽取长列表对象而设计。](2024年05月04日/Recall_Them_All_Retrieval-Augmented_Language_Models_for_Long_Object_List_Extraction_from_Long_Documents.md)

- [Relations Prediction for Knowledge Graph Completion using Large Language Models](2024年05月04日/Relations_Prediction_for_Knowledge_Graph_Completion_using_Large_Language_Models.md)

    - [翻译: 本研究探讨了如何利用大型语言模型来预测知识图谱补全中的关系。](2024年05月04日/Relations_Prediction_for_Knowledge_Graph_Completion_using_Large_Language_Models.md)

- [Sub-goal Distillation: A Method to Improve Small Language Agents](2024年05月04日/Sub-goal_Distillation_A_Method_to_Improve_Small_Language_Agents.md)

    - [翻译: 子目标蒸馏：提升小型语言代理效能的新方法](2024年05月04日/Sub-goal_Distillation_A_Method_to_Improve_Small_Language_Agents.md)

- [TREC iKAT 2023: A Test Collection for Evaluating Conversational and Interactive Knowledge Assistants](2024年05月04日/TREC_iKAT_2023_A_Test_Collection_for_Evaluating_Conversational_and_Interactive_Knowledge_Assistants.md)

    - [翻译: TREC iKAT 2023：评估对话式和互动式知识助手性能的测试集](2024年05月04日/TREC_iKAT_2023_A_Test_Collection_for_Evaluating_Conversational_and_Interactive_Knowledge_Assistants.md)

2024年05月03日

- [Aloe: A Family of Fine-tuned Open Healthcare LLMs](2024年05月03日/Aloe_A_Family_of_Fine-tuned_Open_Healthcare_LLMs.md)

    - [翻译: Aloe：一套经过精细调整的开放医疗大型语言模型家族](2024年05月03日/Aloe_A_Family_of_Fine-tuned_Open_Healthcare_LLMs.md)

- [Analyzing Narrative Processing in Large Language Models (LLMs): Using GPT4 to test BERT](2024年05月03日/Analyzing_Narrative_Processing_in_Large_Language_Models_(LLMs)_Using_GPT4_to_test_BERT.md)

    - [翻译: 探索大型语言模型中的叙事处理能力：以 GPT-4 作为工具，对 BERT 进行测试分析](2024年05月03日/Analyzing_Narrative_Processing_in_Large_Language_Models_(LLMs)_Using_GPT4_to_test_BERT.md)

- [Argumentative Large Language Models for Explainable and Contestable Decision-Making](2024年05月03日/Argumentative_Large_Language_Models_for_Explainable_and_Contestable_Decision-Making.md)

    - [翻译: 构建论辩型大型语言模型，旨在实现决策过程的可解释性和可争议性。](2024年05月03日/Argumentative_Large_Language_Models_for_Explainable_and_Contestable_Decision-Making.md)

- [Assessing and Verifying Task Utility in LLM-Powered Applications](2024年05月03日/Assessing_and_Verifying_Task_Utility_in_LLM-Powered_Applications.md)

    - [翻译: 探索大型语言模型（LLM）支持的应用程序中任务实用性的评估与验证。](2024年05月03日/Assessing_and_Verifying_Task_Utility_in_LLM-Powered_Applications.md)

- [Automated Control Logic Test Case Generation using Large Language Models](2024年05月03日/Automated_Control_Logic_Test_Case_Generation_using_Large_Language_Models.md)

    - [翻译: 利用大型语言模型实现控制逻辑测试用例的自动生成](2024年05月03日/Automated_Control_Logic_Test_Case_Generation_using_Large_Language_Models.md)

- [Automatic Programming: Large Language Models and Beyond](2024年05月03日/Automatic_Programming_Large_Language_Models_and_Beyond.md)

    - [翻译: 自动编程：探索大型语言模型及其更广阔领域](2024年05月03日/Automatic_Programming_Large_Language_Models_and_Beyond.md)

- [Automating the Enterprise with Foundation Models](2024年05月03日/Automating_the_Enterprise_with_Foundation_Models.md)

    - [翻译: 借助基础模型，企业自动化得以实现。本研究旨在探索基础模型在企业自动化中的应用，并分析其对提升效率和创新能力的影响。](2024年05月03日/Automating_the_Enterprise_with_Foundation_Models.md)

- [Conformal Prediction for Natural Language Processing: A Survey](2024年05月03日/Conformal_Prediction_for_Natural_Language_Processing_A_Survey.md)

    - [翻译: 一致性预测在自然语言处理领域的应用：综述研究](2024年05月03日/Conformal_Prediction_for_Natural_Language_Processing_A_Survey.md)

- [DALLMi: Domain Adaption for LLM-based Multi-label Classifier](2024年05月03日/DALLMi_Domain_Adaption_for_LLM-based_Multi-label_Classifier.md)

    - [翻译: DALLMi：为基于大型语言模型的多标签分类任务量身定制的领域适应技术。](2024年05月03日/DALLMi_Domain_Adaption_for_LLM-based_Multi-label_Classifier.md)

- [Dependency-Aware Semi-Structured Sparsity of GLU Variants in Large Language Models](2024年05月03日/Dependency-Aware_Semi-Structured_Sparsity_of_GLU_Variants_in_Large_Language_Models.md)

    - [翻译: 在大型语言模型中，GLU 变种的依赖感知半结构化稀疏性研究](2024年05月03日/Dependency-Aware_Semi-Structured_Sparsity_of_GLU_Variants_in_Large_Language_Models.md)

- [EEG2TEXT: Open Vocabulary EEG-to-Text Decoding with EEG Pre-Training and Multi-View Transformer](2024年05月03日/EEG2TEXT_Open_Vocabulary_EEG-to-Text_Decoding_with_EEG_Pre-Training_and_Multi-View_Transformer.md)

    - [翻译: EEG2TEXT：采用 EEG 预训练和多视角变换技术，实现开放词汇表的 EEG 到文本的转换。](2024年05月03日/EEG2TEXT_Open_Vocabulary_EEG-to-Text_Decoding_with_EEG_Pre-Training_and_Multi-View_Transformer.md)

- [Evaluating Large Language Models for Structured Science Summarization in the Open Research Knowledge Graph](2024年05月03日/Evaluating_Large_Language_Models_for_Structured_Science_Summarization_in_the_Open_Research_Knowledge_Graph.md)

    - [翻译: 本文旨在探讨大型语言模型在开放研究知识图谱框架下进行结构化科学摘要的表现。](2024年05月03日/Evaluating_Large_Language_Models_for_Structured_Science_Summarization_in_the_Open_Research_Knowledge_Graph.md)

- [Exploring Combinatorial Problem Solving with Large Language Models: A Case Study on the Travelling Salesman Problem Using GPT-3.5 Turbo](2024年05月03日/Exploring_Combinatorial_Problem_Solving_with_Large_Language_Models_A_Case_Study_on_the_Travelling_Salesman_Problem_Using_GPT-3.5_Turbo.md)

    - [翻译: 本研究深入探讨了大型语言模型在解决组合问题上的能力，特别是以 GPT-3.5 Turbo 为工具，对旅行商问题进行了一项案例研究。](2024年05月03日/Exploring_Combinatorial_Problem_Solving_with_Large_Language_Models_A_Case_Study_on_the_Travelling_Salesman_Problem_Using_GPT-3.5_Turbo.md)

- [FairEvalLLM. A Comprehensive Framework for Benchmarking Fairness in Large Language Model Recommender Systems](2024年05月03日/FairEvalLLM._A_Comprehensive_Framework_for_Benchmarking_Fairness_in_Large_Language_Model_Recommender_Systems.md)

    - [翻译: FairEvalLLM，为大型语言模型推荐系统公平性评估提供了一个全面的基准框架。](2024年05月03日/FairEvalLLM._A_Comprehensive_Framework_for_Benchmarking_Fairness_in_Large_Language_Model_Recommender_Systems.md)

- [Incorporating External Knowledge and Goal Guidance for LLM-based Conversational Recommender Systems](2024年05月03日/Incorporating_External_Knowledge_and_Goal_Guidance_for_LLM-based_Conversational_Recommender_Systems.md)

    - [翻译: 为基于大型语言模型的对话式推荐系统融入外部知识并引入目标导向。](2024年05月03日/Incorporating_External_Knowledge_and_Goal_Guidance_for_LLM-based_Conversational_Recommender_Systems.md)

- [Large Multimodal Model based Standardisation of Pathology Reports with Confidence and their Prognostic Significance](2024年05月03日/Large_Multimodal_Model_based_Standardisation_of_Pathology_Reports_with_Confidence_and_their_Prognostic_Significance.md)

    - [翻译: 利用大型多模态模型对病理报告进行标准化处理，同时评估其置信度和对疾病预后的影响。](2024年05月03日/Large_Multimodal_Model_based_Standardisation_of_Pathology_Reports_with_Confidence_and_their_Prognostic_Significance.md)

- [Leveraging Large Language Models to Enhance Domain Expert Inclusion in Data Science Workflows](2024年05月03日/Leveraging_Large_Language_Models_to_Enhance_Domain_Expert_Inclusion_in_Data_Science_Workflows.md)

    - [翻译: 通过运用大型语言模型，我们能够提升数据科学流程中领域专家的参与度和包容性。](2024年05月03日/Leveraging_Large_Language_Models_to_Enhance_Domain_Expert_Inclusion_in_Data_Science_Workflows.md)

- [MedReadMe: A Systematic Study for Fine-grained Sentence Readability in Medical Domain](2024年05月03日/MedReadMe_A_Systematic_Study_for_Fine-grained_Sentence_Readability_in_Medical_Domain.md)

    - [翻译: MedReadMe：深入探究医学领域内句子细粒度可读性的系统性研究](2024年05月03日/MedReadMe_A_Systematic_Study_for_Fine-grained_Sentence_Readability_in_Medical_Domain.md)

- [On the test-time zero-shot generalization of vision-language models: Do we really need prompt learning?](2024年05月03日/On_the_test-time_zero-shot_generalization_of_vision-language_models_Do_we_really_need_prompt_learning.md)

    - [翻译: 探讨视觉-语言模型在测试阶段的零样本泛化能力：提示学习是否真的不可或缺？](2024年05月03日/On_the_test-time_zero-shot_generalization_of_vision-language_models_Do_we_really_need_prompt_learning.md)

- [Optimising Calls to Large Language Models with Uncertainty-Based Two-Tier Selection](2024年05月03日/Optimising_Calls_to_Large_Language_Models_with_Uncertainty-Based_Two-Tier_Selection.md)

    - [翻译: 通过不确定性驱动的双层筛选机制，提升对大型语言模型调用的优化效果。](2024年05月03日/Optimising_Calls_to_Large_Language_Models_with_Uncertainty-Based_Two-Tier_Selection.md)

- [REASONS: A benchmark for REtrieval and Automated citationS Of scieNtific Sentences using Public and Proprietary LLMs](2024年05月03日/REASONS_A_benchmark_for_REtrieval_and_Automated_citationS_Of_scieNtific_Sentences_using_Public_and_Proprietary_LLMs.md)

    - [翻译: REASONS：一个基准测试，旨在利用公共及私有的大型语言模型（LLMs）检索并自动引用科学文献中的句子。](2024年05月03日/REASONS_A_benchmark_for_REtrieval_and_Automated_citationS_Of_scieNtific_Sentences_using_Public_and_Proprietary_LLMs.md)

- [SGHateCheck: Functional Tests for Detecting Hate Speech in Low-Resource Languages of Singapore](2024年05月03日/SGHateCheck_Functional_Tests_for_Detecting_Hate_Speech_in_Low-Resource_Languages_of_Singapore.md)

    - [翻译: SGHateCheck：一种功能性测试工具，旨在识别新加坡低资源语言中的仇恨言论。](2024年05月03日/SGHateCheck_Functional_Tests_for_Detecting_Hate_Speech_in_Low-Resource_Languages_of_Singapore.md)

- [Single and Multi-Hop Question-Answering Datasets for Reticular Chemistry with GPT-4-Turbo](2024年05月03日/Single_and_Multi-Hop_Question-Answering_Datasets_for_Reticular_Chemistry_with_GPT-4-Turbo.md)

    - [翻译: 为 Reticular Chemistry 领域设计的单跳与多跳问答数据集，特别适配 GPT-4-Turbo 模型](2024年05月03日/Single_and_Multi-Hop_Question-Answering_Datasets_for_Reticular_Chemistry_with_GPT-4-Turbo.md)

- [Structural Pruning of Pre-trained Language Models via Neural Architecture Search](2024年05月03日/Structural_Pruning_of_Pre-trained_Language_Models_via_Neural_Architecture_Search.md)

    - [翻译: 利用神经架构搜索技术对预训练的语言模型进行结构化精简。](2024年05月03日/Structural_Pruning_of_Pre-trained_Language_Models_via_Neural_Architecture_Search.md)

- [SUKHSANDESH: An Avatar Therapeutic Question Answering Platform for Sexual Education in Rural India](2024年05月03日/SUKHSANDESH_An_Avatar_Therapeutic_Question_Answering_Platform_for_Sexual_Education_in_Rural_India.md)

    - [翻译: SUKHSANDESH：一个面向印度农村地区的性教育虚拟治疗问答平台。](2024年05月03日/SUKHSANDESH_An_Avatar_Therapeutic_Question_Answering_Platform_for_Sexual_Education_in_Rural_India.md)

- [The AI Review Lottery: Widespread AI-Assisted Peer Reviews Boost Paper Scores and Acceptance Rates](2024年05月03日/The_AI_Review_Lottery_Widespread_AI-Assisted_Peer_Reviews_Boost_Paper_Scores_and_Acceptance_Rates.md)

    - [翻译: AI评审的幸运抽奖：当人工智能辅助的同行评审变得普遍时，它显著提升了论文的评分和被接受的概率。](2024年05月03日/The_AI_Review_Lottery_Widespread_AI-Assisted_Peer_Reviews_Boost_Paper_Scores_and_Acceptance_Rates.md)

- [Unveiling the Potential of LLM-Based ASR on Chinese Open-Source Datasets](2024年05月03日/Unveiling_the_Potential_of_LLM-Based_ASR_on_Chinese_Open-Source_Datasets.md)

    - [翻译: 探索基于大型语言模型的自动语音识别技术在中文开源数据集中的应用潜力。](2024年05月03日/Unveiling_the_Potential_of_LLM-Based_ASR_on_Chinese_Open-Source_Datasets.md)

- [What matters when building vision-language models?](2024年05月03日/What_matters_when_building_vision-language_models.md)

    - [翻译: 构建视觉-语言模型时，关键因素有哪些？](2024年05月03日/What_matters_when_building_vision-language_models.md)

- [Which Identities Are Mobilized: Towards an automated detection of social group appeals in political texts](2024年05月03日/Which_Identities_Are_Mobilized_Towards_an_automated_detection_of_social_group_appeals_in_political_texts.md)

    - [翻译: 身份动员探析：政治文本中社会群体呼吁的自动化识别研究](2024年05月03日/Which_Identities_Are_Mobilized_Towards_an_automated_detection_of_social_group_appeals_in_political_texts.md)

2024年05月02日

- [ALCM: Autonomous LLM-Augmented Causal Discovery Framework](2024年05月02日/ALCM_Autonomous_LLM-Augmented_Causal_Discovery_Framework.md)

    - [翻译: ALCM：独立增强型大型语言模型因果探索框架](2024年05月02日/ALCM_Autonomous_LLM-Augmented_Causal_Discovery_Framework.md)

- [Analyzing the Role of Semantic Representations in the Era of Large Language Models](2024年05月02日/Analyzing_the_Role_of_Semantic_Representations_in_the_Era_of_Large_Language_Models.md)

    - [翻译: 在大型语言模型盛行的当下，深入探讨语义表示的角色与重要性。](2024年05月02日/Analyzing_the_Role_of_Semantic_Representations_in_the_Era_of_Large_Language_Models.md)

- [A Survey on Large Language Models for Critical Societal Domains: Finance, Healthcare, and Law](2024年05月02日/A_Survey_on_Large_Language_Models_for_Critical_Societal_Domains_Finance,_Healthcare,_and_Law.md)

    - [翻译: 一项针对金融、医疗保健和法律等关键社会领域内大型语言模型的综述研究](2024年05月02日/A_Survey_on_Large_Language_Models_for_Critical_Societal_Domains_Finance,_Healthcare,_and_Law.md)

- [A Systematic Literature Review on Large Language Models for Automated Program Repair](2024年05月02日/A_Systematic_Literature_Review_on_Large_Language_Models_for_Automated_Program_Repair.md)

    - [翻译: 本文系统性地回顾了用于自动化程序修复的大型语言模型的相关文献。](2024年05月02日/A_Systematic_Literature_Review_on_Large_Language_Models_for_Automated_Program_Repair.md)

- [Automatically Extracting Numerical Results from Randomized Controlled Trials with Large Language Models](2024年05月02日/Automatically_Extracting_Numerical_Results_from_Randomized_Controlled_Trials_with_Large_Language_Models.md)

    - [翻译: 利用大型语言模型，我们能够自动地从随机对照试验中抽取出数值数据。](2024年05月02日/Automatically_Extracting_Numerical_Results_from_Randomized_Controlled_Trials_with_Large_Language_Models.md)

- [Automating the Analysis of Public Saliency and Attitudes towards Biodiversity from Digital Media](2024年05月02日/Automating_the_Analysis_of_Public_Saliency_and_Attitudes_towards_Biodiversity_from_Digital_Media.md)

    - [翻译: 自动化地从数字媒体中分析公众对生物多样性的关注点和态度](2024年05月02日/Automating_the_Analysis_of_Public_Saliency_and_Attitudes_towards_Biodiversity_from_Digital_Media.md)

- [Boosting Jailbreak Attack with Momentum](2024年05月02日/Boosting_Jailbreak_Attack_with_Momentum.md)

    - [翻译: 借助动量效应，提升越狱攻击的威力](2024年05月02日/Boosting_Jailbreak_Attack_with_Momentum.md)

- [Causal Influence in Federated Edge Inference](2024年05月02日/Causal_Influence_in_Federated_Edge_Inference.md)

    - [翻译: 在联合边缘推理领域，因果关系的影响是一个关键因素。](2024年05月02日/Causal_Influence_in_Federated_Edge_Inference.md)

- [CodeGRAG: Extracting Composed Syntax Graphs for Retrieval Augmented Cross-Lingual Code Generation](2024年05月02日/CodeGRAG_Extracting_Composed_Syntax_Graphs_for_Retrieval_Augmented_Cross-Lingual_Code_Generation.md)

    - [翻译: CodeGRAF：为增强检索的跨语言代码生成提取复合语法图。](2024年05月02日/CodeGRAG_Extracting_Composed_Syntax_Graphs_for_Retrieval_Augmented_Cross-Lingual_Code_Generation.md)

- [Controllable Text Generation in the Instruction-Tuning Era](2024年05月02日/Controllable_Text_Generation_in_the_Instruction-Tuning_Era.md)

    - [翻译: 在指令调整时代下的可控文本生成](2024年05月02日/Controllable_Text_Generation_in_the_Instruction-Tuning_Era.md)

- [CoS: Enhancing Personalization and Mitigating Bias with Context Steering](2024年05月02日/CoS_Enhancing_Personalization_and_Mitigating_Bias_with_Context_Steering.md)

    - [翻译: CoS技术：借助上下文导航，提升个性化体验，同时有效降低偏见风险。](2024年05月02日/CoS_Enhancing_Personalization_and_Mitigating_Bias_with_Context_Steering.md)

- [Creative Problem Solving in Large Language and Vision Models -- What Would it Take?](2024年05月02日/Creative_Problem_Solving_in_Large_Language_and_Vision_Models_--_What_Would_it_Take.md)

    - [翻译: 探索大型语言与视觉模型中的创新性问题解决之道 -- 我们该如何应对这一挑战？](2024年05月02日/Creative_Problem_Solving_in_Large_Language_and_Vision_Models_--_What_Would_it_Take.md)

- [DLAP: A Deep Learning Augmented Large Language Model Prompting Framework for Software Vulnerability Detection](2024年05月02日/DLAP_A_Deep_Learning_Augmented_Large_Language_Model_Prompting_Framework_for_Software_Vulnerability_Detection.md)

    - [翻译: DLAP：深度学习助力的大型语言模型提示框架，专为软件漏洞检测而设计。](2024年05月02日/DLAP_A_Deep_Learning_Augmented_Large_Language_Model_Prompting_Framework_for_Software_Vulnerability_Detection.md)

- [Efficient and Economic Large Language Model Inference with Attention Offloading](2024年05月02日/Efficient_and_Economic_Large_Language_Model_Inference_with_Attention_Offloading.md)

    - [翻译: 通过注意力卸载实现大型语言模型的高效经济推理](2024年05月02日/Efficient_and_Economic_Large_Language_Model_Inference_with_Attention_Offloading.md)

- [Efficient Data Generation for Source-grounded Information-seeking Dialogs: A Use Case for Meeting Transcripts](2024年05月02日/Efficient_Data_Generation_for_Source-grounded_Information-seeking_Dialogs_A_Use_Case_for_Meeting_Transcripts.md)

    - [翻译: 高效数据生成：以会议记录为信息寻求型源-地面对话的用例](2024年05月02日/Efficient_Data_Generation_for_Source-grounded_Information-seeking_Dialogs_A_Use_Case_for_Meeting_Transcripts.md)

- [Exploiting ChatGPT for Diagnosing Autism-Associated Language Disorders and Identifying Distinct Features](2024年05月02日/Exploiting_ChatGPT_for_Diagnosing_Autism-Associated_Language_Disorders_and_Identifying_Distinct_Features.md)

    - [翻译: 通过 ChatGPT 来识别自闭症相关的语言障碍，并挖掘其独特的特征。](2024年05月02日/Exploiting_ChatGPT_for_Diagnosing_Autism-Associated_Language_Disorders_and_Identifying_Distinct_Features.md)

- [FLAME: Factuality-Aware Alignment for Large Language Models](2024年05月02日/FLAME_Factuality-Aware_Alignment_for_Large_Language_Models.md)

    - [翻译: FLAME：为大型语言模型打造的事实感知对齐技术](2024年05月02日/FLAME_Factuality-Aware_Alignment_for_Large_Language_Models.md)

- [FSM Builder: A Tool for Writing Autograded Finite Automata Questions](2024年05月02日/FSM_Builder_A_Tool_for_Writing_Autograded_Finite_Automata_Questions.md)

    - [翻译: FSM Builder：一款编写自动评分有限自动机习题的工具](2024年05月02日/FSM_Builder_A_Tool_for_Writing_Autograded_Finite_Automata_Questions.md)

- [GAIA: A General AI Assistant for Intelligent Accelerator Operations](2024年05月02日/GAIA_A_General_AI_Assistant_for_Intelligent_Accelerator_Operations.md)

    - [翻译: GAIA：一款为智能化加速器运营提供助力的全能AI助手。](2024年05月02日/GAIA_A_General_AI_Assistant_for_Intelligent_Accelerator_Operations.md)

- [Generating User Experience Based on Personas with AI Assistants](2024年05月02日/Generating_User_Experience_Based_on_Personas_with_AI_Assistants.md)

    - [翻译: 利用人工智能助手，根据人物角色创造用户体验](2024年05月02日/Generating_User_Experience_Based_on_Personas_with_AI_Assistants.md)

- [Generative AI in Cybersecurity](2024年05月02日/Generative_AI_in_Cybersecurity.md)

    - [翻译: 在网络安全领域，生成性人工智能的应用正日益显现其重要性。](2024年05月02日/Generative_AI_in_Cybersecurity.md)

- [Generative Relevance Feedback and Convergence of Adaptive Re-Ranking: University of Glasgow Terrier Team at TREC DL 2023](2024年05月02日/Generative_Relevance_Feedback_and_Convergence_of_Adaptive_Re-Ranking_University_of_Glasgow_Terrier_Team_at_TREC_DL_2023.md)

    - [翻译: 格拉斯哥大学的特里尔团队在2023年TREC DL竞赛中展示了他们在生成式相关反馈和自适应重排序技术方面的成果，这些技术在信息检索任务中实现了显著的收敛效果。](2024年05月02日/Generative_Relevance_Feedback_and_Convergence_of_Adaptive_Re-Ranking_University_of_Glasgow_Terrier_Team_at_TREC_DL_2023.md)

- [Human-Robot Interaction Conversational User Enjoyment Scale (HRI CUES)](2024年05月02日/Human-Robot_Interaction_Conversational_User_Enjoyment_Scale_(HRI_CUES).md)

    - [翻译: 人机互动对话用户愉悦度量表（HRI CUES）](2024年05月02日/Human-Robot_Interaction_Conversational_User_Enjoyment_Scale_(HRI_CUES).md)

- [Improving Complex Reasoning over Knowledge Graph with Logic-Aware Curriculum Tuning](2024年05月02日/Improving_Complex_Reasoning_over_Knowledge_Graph_with_Logic-Aware_Curriculum_Tuning.md)

    - [翻译: 本文探讨了如何通过逻辑感知的课程调整方法，提升在知识图谱上进行复杂推理的性能。](2024年05月02日/Improving_Complex_Reasoning_over_Knowledge_Graph_with_Logic-Aware_Curriculum_Tuning.md)

- [Improving Concept Alignment in Vision-Language Concept Bottleneck Models](2024年05月02日/Improving_Concept_Alignment_in_Vision-Language_Concept_Bottleneck_Models.md)

    - [翻译: 提升视觉-语言概念瓶颈模型中的概念一致性](2024年05月02日/Improving_Concept_Alignment_in_Vision-Language_Concept_Bottleneck_Models.md)

- ["In-Context Learning" or: How I learned to stop worrying and love "Applied Information Retrieval"](2024年05月02日/In-Context_Learning_or_How_I_learned_to_stop_worrying_and_love_Applied_Information_Retrieval.md)

    - [翻译: 《上下文学习》：我如何学会不再担忧并拥抱“应用信息检索”的世界](2024年05月02日/In-Context_Learning_or_How_I_learned_to_stop_worrying_and_love_Applied_Information_Retrieval.md)

- [Investigating Wit, Creativity, and Detectability of Large Language Models in Domain-Specific Writing Style Adaptation of Reddit's Showerthoughts](2024年05月02日/Investigating_Wit,_Creativity,_and_Detectability_of_Large_Language_Models_in_Domain-Specific_Writing_Style_Adaptation_of_Reddit's_Showerthoughts.md)

    - [翻译: 本研究旨在探究大型语言模型在 Reddit Showerthoughts 社区特定写作风格适应中的机智、创造力及其可被察觉的程度。](2024年05月02日/Investigating_Wit,_Creativity,_and_Detectability_of_Large_Language_Models_in_Domain-Specific_Writing_Style_Adaptation_of_Reddit's_Showerthoughts.md)

- [Language-Enhanced Latent Representations for Out-of-Distribution Detection in Autonomous Driving](2024年05月02日/Language-Enhanced_Latent_Representations_for_Out-of-Distribution_Detection_in_Autonomous_Driving.md)

    - [翻译: 为了在自动驾驶领域识别那些超出常规分布的异常情况，我们采用了一种语言增强的潜在表示方法。](2024年05月02日/Language-Enhanced_Latent_Representations_for_Out-of-Distribution_Detection_in_Autonomous_Driving.md)

- [Large Language Models are Inconsistent and Biased Evaluators](2024年05月02日/Large_Language_Models_are_Inconsistent_and_Biased_Evaluators.md)

    - [翻译: 大型语言模型作为评估工具，存在不一致性和偏见问题。](2024年05月02日/Large_Language_Models_are_Inconsistent_and_Biased_Evaluators.md)

- [Large Language Models for UAVs: Current State and Pathways to the Future](2024年05月02日/Large_Language_Models_for_UAVs_Current_State_and_Pathways_to_the_Future.md)

    - [翻译: 无人机领域的大型语言模型：现状与未来展望。](2024年05月02日/Large_Language_Models_for_UAVs_Current_State_and_Pathways_to_the_Future.md)

- [Learning Object States from Actions via Large Language Models](2024年05月02日/Learning_Object_States_from_Actions_via_Large_Language_Models.md)

    - [翻译: 利用大型语言模型从动作中学习对象状态。](2024年05月02日/Learning_Object_States_from_Actions_via_Large_Language_Models.md)

- [Leveraging Prompt-Learning for Structured Information Extraction from Crohn's Disease Radiology Reports in a Low-Resource Language](2024年05月02日/Leveraging_Prompt-Learning_for_Structured_Information_Extraction_from_Crohn's_Disease_Radiology_Reports_in_a_Low-Resource_Language.md)

    - [翻译: 通过提示学习技术，我们能够从克罗恩病的放射学报告中高效提取结构化信息，即便在资源匮乏的语言环境中也表现出色。](2024年05月02日/Leveraging_Prompt-Learning_for_Structured_Information_Extraction_from_Crohn's_Disease_Radiology_Reports_in_a_Low-Resource_Language.md)

- [LLM Security Guard for Code](2024年05月02日/LLM_Security_Guard_for_Code.md)

    - [翻译: 大型语言模型的安全守护者：代码防护](2024年05月02日/LLM_Security_Guard_for_Code.md)

- [MANTIS: Interleaved Multi-Image Instruction Tuning](2024年05月02日/MANTIS_Interleaved_Multi-Image_Instruction_Tuning.md)

    - [翻译: MANTIS：交错式多图像指令优化](2024年05月02日/MANTIS_Interleaved_Multi-Image_Instruction_Tuning.md)

- [MiniGPT-3D: Efficiently Aligning 3D Point Clouds with Large Language Models using 2D Priors](2024年05月02日/MiniGPT-3D_Efficiently_Aligning_3D_Point_Clouds_with_Large_Language_Models_using_2D_Priors.md)

    - [翻译: MiniGPT-3D：借助2D先验，高效实现3D点云与大型语言模型的精准对齐。](2024年05月02日/MiniGPT-3D_Efficiently_Aligning_3D_Point_Clouds_with_Large_Language_Models_using_2D_Priors.md)

- [Natural Language to Verilog: Design of a Recurrent Spiking Neural Network using Large Language Models and ChatGPT](2024年05月02日/Natural_Language_to_Verilog_Design_of_a_Recurrent_Spiking_Neural_Network_using_Large_Language_Models_and_ChatGPT.md)

    - [翻译: 将自然语言转换为 Verilog 代码：我们利用大型语言模型和 ChatGPT，设计了一种递归脉冲神经网络。](2024年05月02日/Natural_Language_to_Verilog_Design_of_a_Recurrent_Spiking_Neural_Network_using_Large_Language_Models_and_ChatGPT.md)

- [NeMo-Aligner: Scalable Toolkit for Efficient Model Alignment](2024年05月02日/NeMo-Aligner_Scalable_Toolkit_for_Efficient_Model_Alignment.md)

    - [翻译: NeMo-Aligner：高效模型对齐的可扩展工具集](2024年05月02日/NeMo-Aligner_Scalable_Toolkit_for_Efficient_Model_Alignment.md)

- [OmniDrive: A Holistic LLM-Agent Framework for Autonomous Driving with 3D Perception, Reasoning and Planning](2024年05月02日/OmniDrive_A_Holistic_LLM-Agent_Framework_for_Autonomous_Driving_with_3D_Perception,_Reasoning_and_Planning.md)

    - [翻译: OmniDrive：一套综合性的LLM代理框架，专为自动驾驶设计，集成了3D感知、推理和规划功能。](2024年05月02日/OmniDrive_A_Holistic_LLM-Agent_Framework_for_Autonomous_Driving_with_3D_Perception,_Reasoning_and_Planning.md)

- [Overcoming LLM Challenges using RAG-Driven Precision in Coffee Leaf Disease Remediation](2024年05月02日/Overcoming_LLM_Challenges_using_RAG-Driven_Precision_in_Coffee_Leaf_Disease_Remediation.md)

    - [翻译: 利用 RAG（Retrieval-Augmented Generation）技术提高精确度，有效应对大型语言模型在咖啡叶病害治理中的难题。](2024年05月02日/Overcoming_LLM_Challenges_using_RAG-Driven_Precision_in_Coffee_Leaf_Disease_Remediation.md)

- [Plan-Seq-Learn: Language Model Guided RL for Solving Long Horizon Robotics Tasks](2024年05月02日/Plan-Seq-Learn_Language_Model_Guided_RL_for_Solving_Long_Horizon_Robotics_Tasks.md)

    - [翻译: Plan-Seq-Learn：一种由语言模型引导的强化学习方法，专为解决机器人领域的长期任务而设计。](2024年05月02日/Plan-Seq-Learn_Language_Model_Guided_RL_for_Solving_Long_Horizon_Robotics_Tasks.md)

- [Prompt engineering paradigms for medical applications: scoping review and recommendations for better practices](2024年05月02日/Prompt_engineering_paradigms_for_medical_applications_scoping_review_and_recommendations_for_better_practices.md)

    - [翻译: 医疗领域提示工程的范式：全面审视与提升实践的建言](2024年05月02日/Prompt_engineering_paradigms_for_medical_applications_scoping_review_and_recommendations_for_better_practices.md)

- [Question Suggestion for Conversational Shopping Assistants Using Product Metadata](2024年05月02日/Question_Suggestion_for_Conversational_Shopping_Assistants_Using_Product_Metadata.md)

    - [翻译: 利用产品元数据，为对话式购物助手提供问题建议](2024年05月02日/Question_Suggestion_for_Conversational_Shopping_Assistants_Using_Product_Metadata.md)

- [Reinforcement Learning for Edit-Based Non-Autoregressive Neural Machine Translation](2024年05月02日/Reinforcement_Learning_for_Edit-Based_Non-Autoregressive_Neural_Machine_Translation.md)

    - [翻译: 强化学习在基于编辑的非自回归神经机器翻译中的应用](2024年05月02日/Reinforcement_Learning_for_Edit-Based_Non-Autoregressive_Neural_Machine_Translation.md)

- [Requirements-driven Slicing of Simulink Models Using LLMs](2024年05月02日/Requirements-driven_Slicing_of_Simulink_Models_Using_LLMs.md)

    - [翻译: 运用大型语言模型 (LLMs) 实施对 Simulink 模型的基于需求的切片操作。](2024年05月02日/Requirements-driven_Slicing_of_Simulink_Models_Using_LLMs.md)

- [Supporting Business Document Workflows via Collection-Centric Information Foraging with Large Language Models](2024年05月02日/Supporting_Business_Document_Workflows_via_Collection-Centric_Information_Foraging_with_Large_Language_Models.md)

    - [翻译: 利用大型语言模型，通过集中式信息搜集，助力商业文档工作流程的优化。](2024年05月02日/Supporting_Business_Document_Workflows_via_Collection-Centric_Information_Foraging_with_Large_Language_Models.md)

- [The Effectiveness of LLMs as Annotators: A Comparative Overview and Empirical Analysis of Direct Representation](2024年05月02日/The_Effectiveness_of_LLMs_as_Annotators_A_Comparative_Overview_and_Empirical_Analysis_of_Direct_Representation.md)

    - [翻译: 探究大型语言模型作为注释工具的效能：一篇关于直接表征方法的对比概览与实证研究分析](2024年05月02日/The_Effectiveness_of_LLMs_as_Annotators_A_Comparative_Overview_and_Empirical_Analysis_of_Direct_Representation.md)

- [The Power of Question Translation Training in Multilingual Reasoning: Broadened Scope and Deepened Insights](2024年05月02日/The_Power_of_Question_Translation_Training_in_Multilingual_Reasoning_Broadened_Scope_and_Deepened_Insights.md)

    - [翻译: 通过问题翻译训练提升多语言推理能力：拓展研究视野，深化理解深度。](2024年05月02日/The_Power_of_Question_Translation_Training_in_Multilingual_Reasoning_Broadened_Scope_and_Deepened_Insights.md)

- [Towards Neural Synthesis for SMT-Assisted Proof-Oriented Programming](2024年05月02日/Towards_Neural_Synthesis_for_SMT-Assisted_Proof-Oriented_Programming.md)

    - [翻译: 探索神经合成技术，助力 SMT 支持的面向证明编程发展](2024年05月02日/Towards_Neural_Synthesis_for_SMT-Assisted_Proof-Oriented_Programming.md)

- [Transformer-Aided Semantic Communications](2024年05月02日/Transformer-Aided_Semantic_Communications.md)

    - [翻译: 借助Transformer的语义通信技术](2024年05月02日/Transformer-Aided_Semantic_Communications.md)

- [UQA: Corpus for Urdu Question Answering](2024年05月02日/UQA_Corpus_for_Urdu_Question_Answering.md)

    - [翻译: UQA：乌尔都语问答语料库](2024年05月02日/UQA_Corpus_for_Urdu_Question_Answering.md)

- [Verification and Refinement of Natural Language Explanations through LLM-Symbolic Theorem Proving](2024年05月02日/Verification_and_Refinement_of_Natural_Language_Explanations_through_LLM-Symbolic_Theorem_Proving.md)

    - [翻译: 利用大型语言模型（LLM）中的符号定理证明技术，对自然语言解释进行验证与优化。](2024年05月02日/Verification_and_Refinement_of_Natural_Language_Explanations_through_LLM-Symbolic_Theorem_Proving.md)

- [V-FLUTE: Visual Figurative Language Understanding with Textual Explanations](2024年05月02日/V-FLUTE_Visual_Figurative_Language_Understanding_with_Textual_Explanations.md)

    - [翻译: V-FLUTE：图文结合，洞悉视觉比喻语言的深层含义](2024年05月02日/V-FLUTE_Visual_Figurative_Language_Understanding_with_Textual_Explanations.md)

- [WitheredLeaf: Finding Entity-Inconsistency Bugs with LLMs](2024年05月02日/WitheredLeaf_Finding_Entity-Inconsistency_Bugs_with_LLMs.md)

    - [翻译: WitheredLeaf：利用大型语言模型挖掘实体不一致性缺陷](2024年05月02日/WitheredLeaf_Finding_Entity-Inconsistency_Bugs_with_LLMs.md)

2024年05月01日

- [A Careful Examination of Large Language Model Performance on Grade School Arithmetic](2024年05月01日/A_Careful_Examination_of_Large_Language_Model_Performance_on_Grade_School_Arithmetic.md)

    - [翻译: 深入剖析大型语言模型在小学算术任务上的表现](2024年05月01日/A_Careful_Examination_of_Large_Language_Model_Performance_on_Grade_School_Arithmetic.md)

- [AdaMoLE: Fine-Tuning Large Language Models with Adaptive Mixture of Low-Rank Adaptation Experts](2024年05月01日/AdaMoLE_Fine-Tuning_Large_Language_Models_with_Adaptive_Mixture_of_Low-Rank_Adaptation_Experts.md)

    - [翻译: AdaMoLE：以自适应低秩专家混合策略，对大型语言模型进行精准微调。](2024年05月01日/AdaMoLE_Fine-Tuning_Large_Language_Models_with_Adaptive_Mixture_of_Low-Rank_Adaptation_Experts.md)

- [Addressing Topic Granularity and Hallucination in Large Language Models for Topic Modelling](2024年05月01日/Addressing_Topic_Granularity_and_Hallucination_in_Large_Language_Models_for_Topic_Modelling.md)

    - [翻译: 探讨大型语言模型在主题建模中的主题粒度细化与幻觉现象](2024年05月01日/Addressing_Topic_Granularity_and_Hallucination_in_Large_Language_Models_for_Topic_Modelling.md)

- [A Hong Kong Sign Language Corpus Collected from Sign-interpreted TV News](2024年05月01日/A_Hong_Kong_Sign_Language_Corpus_Collected_from_Sign-interpreted_TV_News.md)

    - [翻译: 香港手语语料库：源自电视手语新闻的采集](2024年05月01日/A_Hong_Kong_Sign_Language_Corpus_Collected_from_Sign-interpreted_TV_News.md)

- [A Legal Framework for Natural Language Processing Model Training in Portugal](2024年05月01日/A_Legal_Framework_for_Natural_Language_Processing_Model_Training_in_Portugal.md)

    - [翻译: 葡萄牙建立了一个针对自然语言处理（NLP）模型训练的法律框架。](2024年05月01日/A_Legal_Framework_for_Natural_Language_Processing_Model_Training_in_Portugal.md)

- [Are Models Biased on Text without Gender-related Language?](2024年05月01日/Are_Models_Biased_on_Text_without_Gender-related_Language.md)

    - [翻译: 文本中若未涉及性别相关词汇，模型是否会表现出偏见？](2024年05月01日/Are_Models_Biased_on_Text_without_Gender-related_Language.md)

- ["Ask Me Anything": How Comcast Uses LLMs to Assist Agents in Real Time](2024年05月01日/Ask_Me_Anything_How_Comcast_Uses_LLMs_to_Assist_Agents_in_Real_Time.md)

    - [翻译: "有问必答"：探究 Comcast 如何利用大型语言模型 (LLMs) 为代理提供实时协助。](2024年05月01日/Ask_Me_Anything_How_Comcast_Uses_LLMs_to_Assist_Agents_in_Real_Time.md)

- [Bayesian Optimization with LLM-Based Acquisition Functions for Natural Language Preference Elicitation](2024年05月01日/Bayesian_Optimization_with_LLM-Based_Acquisition_Functions_for_Natural_Language_Preference_Elicitation.md)

    - [翻译: 利用基于大型语言模型的贝叶斯优化及获取函数，进行自然语言偏好的探索与激发。](2024年05月01日/Bayesian_Optimization_with_LLM-Based_Acquisition_Functions_for_Natural_Language_Preference_Elicitation.md)

- [Beyond Human Vision: The Role of Large Vision Language Models in Microscope Image Analysis](2024年05月01日/Beyond_Human_Vision_The_Role_of_Large_Vision_Language_Models_in_Microscope_Image_Analysis.md)

    - [翻译: 超越人眼所见：大型视觉语言模型在显微图像分析领域的应用](2024年05月01日/Beyond_Human_Vision_The_Role_of_Large_Vision_Language_Models_in_Microscope_Image_Analysis.md)

- [BiomedRAG: A Retrieval Augmented Large Language Model for Biomedicine](2024年05月01日/BiomedRAG_A_Retrieval_Augmented_Large_Language_Model_for_Biomedicine.md)

    - [翻译: BiomedRAG：一种为生物医学领域设计的、结合了检索功能的先进大型语言模型。](2024年05月01日/BiomedRAG_A_Retrieval_Augmented_Large_Language_Model_for_Biomedicine.md)

- [CACTUS: Chemistry Agent Connecting Tool-Usage to Science](2024年05月01日/CACTUS_Chemistry_Agent_Connecting_Tool-Usage_to_Science.md)

    - [翻译: CACTUS：化学智能代理与科学工具的连接平台](2024年05月01日/CACTUS_Chemistry_Agent_Connecting_Tool-Usage_to_Science.md)

- [Can a Hallucinating Model help in Reducing Human "Hallucination"?](2024年05月01日/Can_a_Hallucinating_Model_help_in_Reducing_Human_Hallucination.md)

    - [翻译: 幻觉模型能否助力减轻人类的幻觉现象？](2024年05月01日/Can_a_Hallucinating_Model_help_in_Reducing_Human_Hallucination.md)

- [Characterising the Creative Process in Humans and Large Language Models](2024年05月01日/Characterising_the_Creative_Process_in_Humans_and_Large_Language_Models.md)

    - [翻译: 探索人类与大型语言模型的创意生成过程](2024年05月01日/Characterising_the_Creative_Process_in_Humans_and_Large_Language_Models.md)

- [ChatBI: Towards Natural Language to Complex Business Intelligence SQL](2024年05月01日/ChatBI_Towards_Natural_Language_to_Complex_Business_Intelligence_SQL.md)

    - [翻译: ChatBI：探索将自然语言转换为复杂的商业智能SQL语句的路径](2024年05月01日/ChatBI_Towards_Natural_Language_to_Complex_Business_Intelligence_SQL.md)

- [CofiPara: A Coarse-to-fine Paradigm for Multimodal Sarcasm Target Identification with Large Multimodal Models](2024年05月01日/CofiPara_A_Coarse-to-fine_Paradigm_for_Multimodal_Sarcasm_Target_Identification_with_Large_Multimodal_Models.md)

    - [翻译: CofiPara：一种从粗略到精细的多模态讽刺目标识别方法，适用于大型多模态模型。](2024年05月01日/CofiPara_A_Coarse-to-fine_Paradigm_for_Multimodal_Sarcasm_Target_Identification_with_Large_Multimodal_Models.md)

- [Context-Aware Clustering using Large Language Models](2024年05月01日/Context-Aware_Clustering_using_Large_Language_Models.md)

    - [翻译: 本文探讨了利用大型语言模型进行上下文感知聚类的方法。](2024年05月01日/Context-Aware_Clustering_using_Large_Language_Models.md)

- [CourseAssist: Pedagogically Appropriate Question Answering System for Computer Science Education](2024年05月01日/CourseAssist_Pedagogically_Appropriate_Question_Answering_System_for_Computer_Science_Education.md)

    - [翻译: CourseAssist：专为计算机科学教育设计的教学适宜性问答系统](2024年05月01日/CourseAssist_Pedagogically_Appropriate_Question_Answering_System_for_Computer_Science_Education.md)

- [CultiVerse: Towards Cross-Cultural Understanding for Paintings with Large Language Model](2024年05月01日/CultiVerse_Towards_Cross-Cultural_Understanding_for_Paintings_with_Large_Language_Model.md)

    - [翻译: CultiVerse：迈向利用大型语言模型深化对绘画艺术的跨文化洞察。](2024年05月01日/CultiVerse_Towards_Cross-Cultural_Understanding_for_Paintings_with_Large_Language_Model.md)

- [DFKI-NLP at SemEval-2024 Task 2: Towards Robust LLMs Using Data Perturbations and MinMax Training](2024年05月01日/DFKI-NLP_at_SemEval-2024_Task_2_Towards_Robust_LLMs_Using_Data_Perturbations_and_MinMax_Training.md)

    - [翻译: DFKI-NLP 团队参与了 SemEval-2024 的第二项任务，旨在通过数据扰动和 MinMax 训练方法，推动构建更加稳健的大型语言模型。](2024年05月01日/DFKI-NLP_at_SemEval-2024_Task_2_Towards_Robust_LLMs_Using_Data_Perturbations_and_MinMax_Training.md)

- [Distance Sampling-based Paraphraser Leveraging ChatGPT for Text Data Manipulation](2024年05月01日/Distance_Sampling-based_Paraphraser_Leveraging_ChatGPT_for_Text_Data_Manipulation.md)

    - [翻译: 利用 ChatGPT 的距离抽样技术，打造文本数据的释义神器。](2024年05月01日/Distance_Sampling-based_Paraphraser_Leveraging_ChatGPT_for_Text_Data_Manipulation.md)

- [Distillation Matters: Empowering Sequential Recommenders to Match the Performance of Large Language Model](2024年05月01日/Distillation_Matters_Empowering_Sequential_Recommenders_to_Match_the_Performance_of_Large_Language_Model.md)

    - [翻译: 蒸馏技术至关重要：它能够提升序列推荐系统的性能，使其达到大型语言模型的水平。](2024年05月01日/Distillation_Matters_Empowering_Sequential_Recommenders_to_Match_the_Performance_of_Large_Language_Model.md)

- [EALD-MLLM: Emotion Analysis in Long-sequential and De-identity videos with Multi-modal Large Language Model](2024年05月01日/EALD-MLLM_Emotion_Analysis_in_Long-sequential_and_De-identity_videos_with_Multi-modal_Large_Language_Model.md)

    - [翻译: EALD-MLLM：利用多模态大型语言模型对长序列及去身份视频进行情感分析。](2024年05月01日/EALD-MLLM_Emotion_Analysis_in_Long-sequential_and_De-identity_videos_with_Multi-modal_Large_Language_Model.md)

- [Efficient and Responsible Adaptation of Large Language Models for Robust Top-k Recommendations](2024年05月01日/Efficient_and_Responsible_Adaptation_of_Large_Language_Models_for_Robust_Top-k_Recommendations.md)

    - [翻译: 为了提供鲁棒的 Top-k 推荐，我们需对大型语言模型进行既高效又负责任的调整。](2024年05月01日/Efficient_and_Responsible_Adaptation_of_Large_Language_Models_for_Robust_Top-k_Recommendations.md)

- [Efficient Compression of Multitask Multilingual Speech Models](2024年05月01日/Efficient_Compression_of_Multitask_Multilingual_Speech_Models.md)

    - [翻译: 本文介绍了一种高效的多任务多语言语音模型压缩技术，旨在优化模型的存储和计算效率。](2024年05月01日/Efficient_Compression_of_Multitask_Multilingual_Speech_Models.md)

- [Enhancing Surgical Robots with Embodied Intelligence for Autonomous Ultrasound Scanning](2024年05月01日/Enhancing_Surgical_Robots_with_Embodied_Intelligence_for_Autonomous_Ultrasound_Scanning.md)

    - [翻译: 为手术机器人注入体现智能，提升其进行自主超声扫描的性能。](2024年05月01日/Enhancing_Surgical_Robots_with_Embodied_Intelligence_for_Autonomous_Ultrasound_Scanning.md)

- [Explainable Automatic Grading with Neural Additive Models](2024年05月01日/Explainable_Automatic_Grading_with_Neural_Additive_Models.md)

    - [翻译: 神经加性模型在自动评分中的应用，实现了评分过程的可解释性。](2024年05月01日/Explainable_Automatic_Grading_with_Neural_Additive_Models.md)

- [Exploring Self-Supervised Vision Transformers for Deepfake Detection: A Comparative Analysis](2024年05月01日/Exploring_Self-Supervised_Vision_Transformers_for_Deepfake_Detection_A_Comparative_Analysis.md)

    - [翻译: 本研究深入探讨了自监督视觉变换器在深度伪造检测中的应用，并进行了一项全面的比较分析。](2024年05月01日/Exploring_Self-Supervised_Vision_Transformers_for_Deepfake_Detection_A_Comparative_Analysis.md)

- [GOLD: Geometry Problem Solver with Natural Language Description](2024年05月01日/GOLD_Geometry_Problem_Solver_with_Natural_Language_Description.md)

    - [翻译: GOLD：一款能够理解自然语言描述来解决几何问题的智能求解器。](2024年05月01日/GOLD_Geometry_Problem_Solver_with_Natural_Language_Description.md)

- [HalluVault: A Novel Logic Programming-aided Metamorphic Testing Framework for Detecting Fact-Conflicting Hallucinations in Large Language Models](2024年05月01日/HalluVault_A_Novel_Logic_Programming-aided_Metamorphic_Testing_Framework_for_Detecting_Fact-Conflicting_Hallucinations_in_Large_Language_Models.md)

    - [翻译: HalluVault：一个创新的基于逻辑编程的变异测试框架，专为发现大型语言模型中与事实相悖的幻觉现象而设计。](2024年05月01日/HalluVault_A_Novel_Logic_Programming-aided_Metamorphic_Testing_Framework_for_Detecting_Fact-Conflicting_Hallucinations_in_Large_Language_Models.md)

- [How Can I Get It Right? Using GPT to Rephrase Incorrect Trainee Responses](2024年05月01日/How_Can_I_Get_It_Right_Using_GPT_to_Rephrase_Incorrect_Trainee_Responses.md)

    - [翻译: 如何正确表达？利用 GPT 对实习生的不准确回答进行改写。](2024年05月01日/How_Can_I_Get_It_Right_Using_GPT_to_Rephrase_Incorrect_Trainee_Responses.md)

- ["I'm Not Sure, But...": Examining the Impact of Large Language Models' Uncertainty Expression on User Reliance and Trust](2024年05月01日/I'm_Not_Sure,_But..._Examining_the_Impact_of_Large_Language_Models'_Uncertainty_Expression_on_User_Reliance_and_Trust.md)

    - [翻译: 《“我不确定，但是...”：探究大型语言模型不确定性表述对用户信赖与依赖的影响》](2024年05月01日/I'm_Not_Sure,_But..._Examining_the_Impact_of_Large_Language_Models'_Uncertainty_Expression_on_User_Reliance_and_Trust.md)

- [Inferring State Machine from the Protocol Implementation via Large Langeuage Model](2024年05月01日/Inferring_State_Machine_from_the_Protocol_Implementation_via_Large_Langeuage_Model.md)

    - [翻译: 利用大型语言模型，从协议实现中推导出状态机。](2024年05月01日/Inferring_State_Machine_from_the_Protocol_Implementation_via_Large_Langeuage_Model.md)

- [Integrating A.I. in Higher Education: Protocol for a Pilot Study with 'SAMCares: An Adaptive Learning Hub'](2024年05月01日/Integrating_A.I._in_Higher_Education_Protocol_for_a_Pilot_Study_with_'SAMCares_An_Adaptive_Learning_Hub'.md)

    - [翻译: 融入人工智能于高等教育：开展“SAMCares：自适应学习平台”试点研究的方案](2024年05月01日/Integrating_A.I._in_Higher_Education_Protocol_for_a_Pilot_Study_with_'SAMCares_An_Adaptive_Learning_Hub'.md)

- [Investigating Automatic Scoring and Feedback using Large Language Models](2024年05月01日/Investigating_Automatic_Scoring_and_Feedback_using_Large_Language_Models.md)

    - [翻译: 探究基于大型语言模型的自动评分与反馈机制](2024年05月01日/Investigating_Automatic_Scoring_and_Feedback_using_Large_Language_Models.md)

- [Is Bigger Edit Batch Size Always Better? -- An Empirical Study on Model Editing with Llama-3](2024年05月01日/Is_Bigger_Edit_Batch_Size_Always_Better_--_An_Empirical_Study_on_Model_Editing_with_Llama-3.md)

    - [翻译: 编辑批量大小越大，效果一定越佳吗？一项基于 Llama-3 模型编辑的实证探索。](2024年05月01日/Is_Bigger_Edit_Batch_Size_Always_Better_--_An_Empirical_Study_on_Model_Editing_with_Llama-3.md)

- [Is Temperature the Creativity Parameter of Large Language Models?](2024年05月01日/Is_Temperature_the_Creativity_Parameter_of_Large_Language_Models.md)

    - [翻译: 温度是否决定了大型语言模型的创造力？](2024年05月01日/Is_Temperature_the_Creativity_Parameter_of_Large_Language_Models.md)

- [LLaVA Finds Free Lunch: Teaching Human Behavior Improves Content Understanding Abilities Of LLMs](2024年05月01日/LLaVA_Finds_Free_Lunch_Teaching_Human_Behavior_Improves_Content_Understanding_Abilities_Of_LLMs.md)

    - [翻译: LLaVA 揭示了一个意外的收获：通过教授人类行为，我们能够显著提升大型语言模型对内容的理解力。](2024年05月01日/LLaVA_Finds_Free_Lunch_Teaching_Human_Behavior_Improves_Content_Understanding_Abilities_Of_LLMs.md)

- [LLM-AD: Large Language Model based Audio Description System](2024年05月01日/LLM-AD_Large_Language_Model_based_Audio_Description_System.md)

    - [翻译: LLM-AD：一种依托于先进大型语言模型的音频描述解决方案](2024年05月01日/LLM-AD_Large_Language_Model_based_Audio_Description_System.md)

- [Long-Term Human Trajectory Prediction using 3D Dynamic Scene Graphs](2024年05月01日/Long-Term_Human_Trajectory_Prediction_using_3D_Dynamic_Scene_Graphs.md)

    - [翻译: 通过 3D 动态场景图实现对人类长期轨迹的精准预测。](2024年05月01日/Long-Term_Human_Trajectory_Prediction_using_3D_Dynamic_Scene_Graphs.md)

- [Math Multiple Choice Question Generation via Human-Large Language Model Collaboration](2024年05月01日/Math_Multiple_Choice_Question_Generation_via_Human-Large_Language_Model_Collaboration.md)

    - [翻译: 携手人类与大型语言模型，共创数学多项选择题](2024年05月01日/Math_Multiple_Choice_Question_Generation_via_Human-Large_Language_Model_Collaboration.md)

- [Mixture of insighTful Experts (MoTE): The Synergy of Thought Chains and Expert Mixtures in Self-Alignment](2024年05月01日/Mixture_of_insighTful_Experts_(MoTE)_The_Synergy_of_Thought_Chains_and_Expert_Mixtures_in_Self-Alignment.md)

    - [翻译: 洞察力专家混合体（MoTE）：在自我对齐的过程中，思维链与专家组合的相互促进。](2024年05月01日/Mixture_of_insighTful_Experts_(MoTE)_The_Synergy_of_Thought_Chains_and_Expert_Mixtures_in_Self-Alignment.md)

- [Monte Carlo Tree Search Boosts Reasoning via Iterative Preference Learning](2024年05月01日/Monte_Carlo_Tree_Search_Boosts_Reasoning_via_Iterative_Preference_Learning.md)

    - [翻译: 蒙特卡洛树搜索（MCTS）通过不断迭代的偏好学习，显著提升了推理能力。](2024年05月01日/Monte_Carlo_Tree_Search_Boosts_Reasoning_via_Iterative_Preference_Learning.md)

- [Navigating WebAI: Training Agents to Complete Web Tasks with Large Language Models and Reinforcement Learning](2024年05月01日/Navigating_WebAI_Training_Agents_to_Complete_Web_Tasks_with_Large_Language_Models_and_Reinforcement_Learning.md)

    - [翻译: 探索 WebAI：通过大型语言模型和强化学习训练代理来完成网络任务。](2024年05月01日/Navigating_WebAI_Training_Agents_to_Complete_Web_Tasks_with_Large_Language_Models_and_Reinforcement_Learning.md)

- [NumLLM: Numeric-Sensitive Large Language Model for Chinese Finance](2024年05月01日/NumLLM_Numeric-Sensitive_Large_Language_Model_for_Chinese_Finance.md)

    - [翻译: NumLLM：一款专为中文金融领域设计的、对数值高度敏感的大型语言模型。](2024年05月01日/NumLLM_Numeric-Sensitive_Large_Language_Model_for_Chinese_Finance.md)

- [On the Evaluation of Machine-Generated Reports](2024年05月01日/On_the_Evaluation_of_Machine-Generated_Reports.md)

    - [翻译: 机器生成报告评估研究](2024年05月01日/On_the_Evaluation_of_Machine-Generated_Reports.md)

- [RAG-based Explainable Prediction of Road Users Behaviors for Automated Driving using Knowledge Graphs and Large Language Models](2024年05月01日/RAG-based_Explainable_Prediction_of_Road_Users_Behaviors_for_Automated_Driving_using_Knowledge_Graphs_and_Large_Language_Models.md)

    - [翻译: 利用知识图谱和大型语言模型，基于 RAG（Retrieval-Augmented Generation）框架，对自动驾驶中道路使用者的行为进行可解释预测。](2024年05月01日/RAG-based_Explainable_Prediction_of_Road_Users_Behaviors_for_Automated_Driving_using_Knowledge_Graphs_and_Large_Language_Models.md)

- [Self-Refine Instruction-Tuning for Aligning Reasoning in Language Models](2024年05月01日/Self-Refine_Instruction-Tuning_for_Aligning_Reasoning_in_Language_Models.md)

    - [翻译: 自我精炼的指令调优：优化语言模型中的推理对齐。](2024年05月01日/Self-Refine_Instruction-Tuning_for_Aligning_Reasoning_in_Language_Models.md)

- [The Pyramid of Captions](2024年05月01日/The_Pyramid_of_Captions.md)

    - [翻译: 标题层级金字塔](2024年05月01日/The_Pyramid_of_Captions.md)

- [The Real, the Better: Aligning Large Language Models with Online Human Behaviors](2024年05月01日/The_Real,_the_Better_Aligning_Large_Language_Models_with_Online_Human_Behaviors.md)

    - [翻译: 追求真实，更上一层楼：使大型语言模型与网民在线行为同步。](2024年05月01日/The_Real,_the_Better_Aligning_Large_Language_Models_with_Online_Human_Behaviors.md)

- [The Role of Model Architecture and Scale in Predicting Molecular Properties: Insights from Fine-Tuning RoBERTa, BART, and LLaMA](2024年05月01日/The_Role_of_Model_Architecture_and_Scale_in_Predicting_Molecular_Properties_Insights_from_Fine-Tuning_RoBERTa,_BART,_and_LLaMA.md)

    - [翻译: 探讨模型架构和规模对于分子属性预测的影响：通过对 RoBERTa、BART 和 LLaMA 进行微调获得的深刻见解。](2024年05月01日/The_Role_of_Model_Architecture_and_Scale_in_Predicting_Molecular_Properties_Insights_from_Fine-Tuning_RoBERTa,_BART,_and_LLaMA.md)

- [When Quantization Affects Confidence of Large Language Models?](2024年05月01日/When_Quantization_Affects_Confidence_of_Large_Language_Models.md)

    - [翻译: 量化如何影响大型语言模型的置信度？](2024年05月01日/When_Quantization_Affects_Confidence_of_Large_Language_Models.md)

- [WIBA: What Is Being Argued? A Comprehensive Approach to Argument Mining](2024年05月01日/WIBA_What_Is_Being_Argued_A_Comprehensive_Approach_to_Argument_Mining.md)

    - [翻译: WIBA：争论的是什么？一种全面深入的论点挖掘方法。](2024年05月01日/WIBA_What_Is_Being_Argued_A_Comprehensive_Approach_to_Argument_Mining.md)