# 大型语言模型是否自得其乐于其编织的故事？探索利用这些模型进行自动故事评估的潜力。

发布时间：2024年05月22日

`LLM应用

这篇论文探讨了大型语言模型（LLM）在故事评估任务中的应用，分析了LLM评分与其他自动测量及人类标注之间的关联，并研究了提示方式对结果的影响及LLM行为的可解释性。虽然论文涉及了对LLM性能的评估和分析，但其核心关注点是LLM在特定应用场景（即故事评估）中的实际表现和局限性，因此属于LLM应用分类。` `社交互动`

> Do Language Models Enjoy Their Own Stories? Prompting Large Language Models for Automatic Story Evaluation

# 摘要

> 故事讲述是人类社交互动的核心，而自动故事评估与生成技术有望在多方面惠及社会，尽管这些任务对创造力、推理和深度理解等人类高级能力提出了挑战。如今，大型语言模型在众多NLP任务中已达到顶尖水平。本文探讨了LLM是否能替代人类进行故事评估。我们深入分析了LLM评分与其他自动测量及人类标注之间的关联，并研究了提示方式对结果的影响及LLM行为的可解释性。研究发现，尽管LLM在系统级评估中超越了现有自动测量，但在解释其评估依据方面仍显不足。

> Storytelling is an integral part of human experience and plays a crucial role in social interactions. Thus, Automatic Story Evaluation (ASE) and Generation (ASG) could benefit society in multiple ways, but they are challenging tasks which require high-level human abilities such as creativity, reasoning and deep understanding. Meanwhile, Large Language Models (LLM) now achieve state-of-the-art performance on many NLP tasks. In this paper, we study whether LLMs can be used as substitutes for human annotators for ASE. We perform an extensive analysis of the correlations between LLM ratings, other automatic measures, and human annotations, and we explore the influence of prompting on the results and the explainability of LLM behaviour. Most notably, we find that LLMs outperform current automatic measures for system-level evaluation but still struggle at providing satisfactory explanations for their answers.

[Arxiv](https://arxiv.org/abs/2405.13769)