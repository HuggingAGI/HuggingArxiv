# 智能电网中应用大型语言模型的潜在风险：威胁建模与验证探索在智能电网领域，大型语言模型的应用虽带来便利，但其潜在风险不容忽视。本文将深入探讨这些风险，并通过威胁建模与验证，揭示其对智能电网安全的影响。

发布时间：2024年05月10日

`Agent

这篇论文主要探讨了大型语言模型（LLM）在智能电网应用中可能面临的攻击风险，并分析了两种关键攻击类型及其威胁模型。虽然它涉及了LLM的应用，但其核心关注点是智能电网环境中LLM作为Agent可能遭受的攻击和安全威胁，因此更符合Agent分类，强调了LLM在特定应用场景中的行为和潜在风险。` `智能电网` `网络安全`

> Risks of Practicing Large Language Models in Smart Grid: Threat Modeling and Validation

# 摘要

> 大型语言模型（LLM）在AI领域取得了显著进展，为智能电网带来了广阔的应用前景。然而，AI技术面临的攻击风险不容忽视。本文深入探讨了LLM在智能电网应用中的潜在风险，并揭示了两种关键攻击类型及其威胁模型。通过实际智能电网数据和流行LLM的验证，我们证实了攻击者有能力在智能电网环境中操纵LLM，注入错误信息并窃取敏感知识。

> Large Language Model (LLM) is a significant breakthrough in artificial intelligence (AI) and holds considerable potential for application within smart grids. However, as demonstrated in previous literature, AI technologies are susceptible to various types of attacks. It is crucial to investigate and evaluate the risks associated with LLMs before deploying them in critical infrastructure like smart grids. In this paper, we systematically evaluate the vulnerabilities of LLMs and identify two major types of attacks relevant to smart grid LLM applications, along with presenting the corresponding threat models. We then validate these attacks using popular LLMs, utilizing real smart grid data. Our validation demonstrates that attackers are capable of injecting bad data and retrieving domain knowledge from LLMs employed in smart grid scenarios.

[Arxiv](https://arxiv.org/abs/2405.06237)