# 大型语言模型是否具备为空间推理任务创造新知识的能力？

发布时间：2024年05月23日

`LLM理论

理由：这篇论文探讨了大型语言模型（LLMs）在未曾直接接触的问题空间中展现的推理能力，以及这种能力如何证明了LLMs的理解深度和它们孕育新兴特性的潜力。这涉及到对LLMs内部机制和能力的理论分析，而不是具体的应用案例或Agent的设计，也不是关于检索增强生成（RAG）的研究。因此，它更符合LLM理论的分类。` `人工智能研究`

> Can Large Language Models Create New Knowledge for Spatial Reasoning Tasks?

# 摘要

> 大型语言模型（LLMs）生成新信息的能力为研究和创新开辟了新天地，但“新颖性”的验证却因难以追溯LLM训练中的接触内容而变得复杂。本文发现，即便面对未曾直接接触的空间问题，LLMs仍能展现精妙的推理能力。虽然并非无懈可击，这一发现凸显了当前顶尖LLMs的理解深度，为它们能孕育出显著的新兴特性提供了有力证据。其中，Claude 3的表现尤为抢眼。

> The potential for Large Language Models (LLMs) to generate new information offers a potential step change for research and innovation. This is challenging to assert as it can be difficult to determine what an LLM has previously seen during training, making "newness" difficult to substantiate. In this paper we observe that LLMs are able to perform sophisticated reasoning on problems with a spatial dimension, that they are unlikely to have previously directly encountered. While not perfect, this points to a significant level of understanding that state-of-the-art LLMs can now achieve, supporting the proposition that LLMs are able to yield significant emergent properties. In particular, Claude 3 is found to perform well in this regard.

[Arxiv](https://arxiv.org/abs/2405.14379)