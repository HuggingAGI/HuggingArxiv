# 从社会认知角度探究大型语言模型代理的亲社会非理性行为

发布时间：2024年05月23日

`Agent

这篇论文主要探讨了大型语言模型（LLMs）代理在复杂社会环境中的应用，特别是在模拟人类认知偏见和非理性行为方面的能力。论文提出了一个名为CogMir的框架，用于评估和提升LLM代理的社会智能，并通过实验展示了LLM代理在不确定情境下与人类的非理性和亲社会决策的高度一致性。因此，这篇论文更侧重于LLM代理的应用和行为研究，属于Agent分类。` `社会科学` `人工智能`

> Exploring Prosocial Irrationality for LLM Agents: A Social Cognition View

# 摘要

> 大型语言模型（LLMs）因训练数据中的人类偏见而常出现幻觉问题，但这些偏见是否影响LLM代理的决策过程尚不明确。随着LLM代理在复杂社会环境中的应用增多，一个关键问题随之而来：LLM代理能否通过幻觉模拟人类认知偏见，展现非理性的社会智能？本文结合社会科学实验与理论洞察，深入探讨了LLM代理的非理性行为。我们提出的CogMir框架，是一个利用幻觉特性评估和提升LLM代理社会智能的开放式多代理系统。实验表明，在不确定情境下，LLM代理与人类在非理性和亲社会决策上高度一致，凸显了LLM代理的社会亲和力及幻觉特性的重要性。CogMir框架不仅揭示了LLM代理的社会潜力，也为进一步研究提供了宝贵平台。

> Large language models (LLMs) have been shown to face hallucination issues due to the data they trained on often containing human bias; whether this is reflected in the decision-making process of LLM agents remains under-explored. As LLM Agents are increasingly employed in intricate social environments, a pressing and natural question emerges: Can LLM Agents leverage hallucinations to mirror human cognitive biases, thus exhibiting irrational social intelligence? In this paper, we probe the irrational behavior among contemporary LLM agents by melding practical social science experiments with theoretical insights. Specifically, We propose CogMir, an open-ended Multi-LLM Agents framework that utilizes hallucination properties to assess and enhance LLM Agents' social intelligence through cognitive biases. Experimental results on CogMir subsets show that LLM Agents and humans exhibit high consistency in irrational and prosocial decision-making under uncertain conditions, underscoring the prosociality of LLM Agents as social entities, and highlighting the significance of hallucination properties. Additionally, CogMir framework demonstrates its potential as a valuable platform for encouraging more research into the social intelligence of LLM Agents.

[Arxiv](https://arxiv.org/abs/2405.14744)