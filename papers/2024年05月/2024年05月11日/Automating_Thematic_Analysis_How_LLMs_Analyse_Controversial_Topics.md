# 大型语言模型在争议话题分析中的自动化探索在上述翻译过程中，

发布时间：2024年05月11日

`Agent

这篇论文探讨了大型语言模型（LLMs）如GPT-4和Llama 2在处理争议话题时的应用，特别是在分类新闻报道方面的表现。它强调了LLMs作为分析助手的潜力，并提出了它们在辅助话语分析中的价值。此外，论文还提出了一套创新的卡片工具，以帮助研究者和实践者更好地利用LLMs的分析能力。这些内容表明，论文主要关注的是LLMs作为智能代理（Agent）在特定任务中的应用，而不是LLMs的理论研究或RAG（Retrieval-Augmented Generation）框架的应用。因此，将其归类为Agent是合适的。` `社会科学研究` `新闻分析`

> Automating Thematic Analysis: How LLMs Analyse Controversial Topics

# 摘要

> 大型语言模型（LLMs）是强大的分析助手，它们通过分析海量数据，帮助我们洞察复杂世界的脉络，捕捉细微差别。本文通过一项初步实验，揭示了LLMs在处理争议话题时的潜力。我们对比了人类研究者与GPT-4和Llama 2这两大模型在分类澳大利亚Robodebt丑闻报道时的表现。实验结果既展现了人机在主题分类上的共鸣，也暴露了差异，指出了LLMs在辅助话语分析中的价值。我们强调，LLMs应作为人类智慧的延伸，而非替代。同时，我们为定性研究方法的自动化应用提供了新的方法论思考，并推出了一套创新的卡片工具，旨在帮助研究者和实践者更深入地探索LLMs的分析能力。

> Large Language Models (LLMs) are promising analytical tools. They can augment human epistemic, cognitive and reasoning abilities, and support 'sensemaking', making sense of a complex environment or subject by analysing large volumes of data with a sensitivity to context and nuance absent in earlier text processing systems. This paper presents a pilot experiment that explores how LLMs can support thematic analysis of controversial topics. We compare how human researchers and two LLMs GPT-4 and Llama 2 categorise excerpts from media coverage of the controversial Australian Robodebt scandal. Our findings highlight intriguing overlaps and variances in thematic categorisation between human and machine agents, and suggest where LLMs can be effective in supporting forms of discourse and thematic analysis. We argue LLMs should be used to augment, and not replace human interpretation, and we add further methodological insights and reflections to existing research on the application of automation to qualitative research methods. We also introduce a novel card-based design toolkit, for both researchers and practitioners to further interrogate LLMs as analytical tools.

[Arxiv](https://arxiv.org/abs/2405.06919)