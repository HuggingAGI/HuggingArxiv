# 在网络安全领域，生成性人工智能的应用正日益显现其重要性。

发布时间：2024年05月02日

`分类：LLM应用` `网络安全` `人工智能`

> Generative AI in Cybersecurity

# 摘要

> 随着生成性人工智能（GAI）的兴起，如生成预训练变换器（GPT）和大型语言模型（LLMs）等先进模型，数据领域迎来了革命性的变化，同时也带来了前所未有的网络安全挑战。GAI技术的迅猛发展超越了现有安全协议和法规的步伐，形成了一个悖论：旨在保护数字基础设施的技术创新，却也为网络犯罪分子提供了新的攻击手段。这些犯罪分子擅长迅速掌握并利用新技术，可能使用GAI来制造更加隐蔽和灵活的恶意软件，增加了传统网络安全工作的难度。GAI的快速发展为网络安全领域带来了双重影响：一方面，它为威胁检测和响应提供了强大的工具；另一方面，也为网络攻击者提供了制造更复杂恶意软件的手段。杜克大学普拉特工程学院、Coalfire和Safebreach的合作研究深入分析了恶意行为者如何利用GAI加强其攻击策略，突出了未来网络安全工作中一个至关重要的问题。研究强调了组织必须主动识别并构建更复杂的防御策略，以应对GAI在恶意软件制造中的高级应用。

> The dawn of Generative Artificial Intelligence (GAI), characterized by advanced models such as Generative Pre-trained Transformers (GPT) and other Large Language Models (LLMs), has been pivotal in reshaping the field of data analysis, pattern recognition, and decision-making processes. This surge in GAI technology has ushered in not only innovative opportunities for data processing and automation but has also introduced significant cybersecurity challenges.
  As GAI rapidly progresses, it outstrips the current pace of cybersecurity protocols and regulatory frameworks, leading to a paradox wherein the same innovations meant to safeguard digital infrastructures also enhance the arsenal available to cyber criminals. These adversaries, adept at swiftly integrating and exploiting emerging technologies, may utilize GAI to develop malware that is both more covert and adaptable, thus complicating traditional cybersecurity efforts.
  The acceleration of GAI presents an ambiguous frontier for cybersecurity experts, offering potent tools for threat detection and response, while concurrently providing cyber attackers with the means to engineer more intricate and potent malware. Through the joint efforts of Duke Pratt School of Engineering, Coalfire, and Safebreach, this research undertakes a meticulous analysis of how malicious agents are exploiting GAI to augment their attack strategies, emphasizing a critical issue for the integrity of future cybersecurity initiatives. The study highlights the critical need for organizations to proactively identify and develop more complex defensive strategies to counter the sophisticated employment of GAI in malware creation.

[Arxiv](https://arxiv.org/abs/2405.01674)