# 探索人机协同推理与价值对齐的对话之路

发布时间：2024年05月28日

`Agent

理由：这篇论文主要关注的是人机对话中的联合推理（即“探究”），并强调了基于逻辑的论证和对话模型。它提出了一份研究路线图，专注于探究对话，以支持具有伦理敏感性的联合人机推理任务。这种研究方向更侧重于开发和理解能够与人类进行有效交互的智能代理（Agent），而不是直接涉及大型语言模型（LLM）的理论研究或应用开发，也不是关于检索增强生成（RAG）的研究。因此，将其归类为Agent是合适的。` `人工智能` `伦理决策`

> Towards Dialogues for Joint Human-AI Reasoning and Value Alignment

# 摘要

> 我们认为，促进旨在支持联合推理（即“探究”）的人机对话对于确保AI决策符合人类价值观和偏好至关重要。我们特别强调了基于逻辑的论证和对话模型，并建议将研究重点从传统的说服对话转向探究对话，以及探究对话所特有的挑战。考虑到大型语言模型（LLMs）性能的显著提升及其在决策中应用的预期增长，我们提出了一份研究路线图，专注于探究对话，以支持那些具有伦理敏感性、要求决策与价值观一致的联合人机推理任务。

> We argue that enabling human-AI dialogue, purposed to support joint reasoning (i.e., 'inquiry'), is important for ensuring that AI decision making is aligned with human values and preferences. In particular, we point to logic-based models of argumentation and dialogue, and suggest that the traditional focus on persuasion dialogues be replaced by a focus on inquiry dialogues, and the distinct challenges that joint inquiry raises. Given recent dramatic advances in the performance of large language models (LLMs), and the anticipated increase in their use for decision making, we provide a roadmap for research into inquiry dialogues for supporting joint human-LLM reasoning tasks that are ethically salient, and that thereby require that decisions are value aligned.

[Arxiv](https://arxiv.org/abs/2405.18073)