# 大型语言模型在塑造虚拟人物时，其潜在的偏见问题日益受到关注。

发布时间：2024年05月08日

`Agent

理由：这篇论文探讨了在人机交互（HCI）研究中引入合成人格的问题，这涉及到创建能够模拟人类行为的智能代理（Agent）。论文特别关注了大型语言模型（LLMs）的局限性和偏见，并提出了调整这些偏见的策略，这些都是构建更智能、更个性化的Agent所必须考虑的因素。因此，这篇论文与Agent的构建和应用紧密相关。` `人机交互` `人工智能伦理`

> Concerns on Bias in Large Language Models when Creating Synthetic Personae

# 摘要

> 本文深入探讨了在人机交互研究中引入合成人格的利弊与伦理问题，特别聚焦于如何突破现有大型语言模型的局限，实现个性化定制。基于一项子研究的初步发现，我们通过情景案例揭示了黑盒LLMs中的偏见，并探索了调整这些偏见的策略。研究旨在为理解这些模型的挑战打下基础，并强调在为HCI研究创造合成人格之前，必须进行全面测试的重要性。

> This position paper explores the benefits, drawbacks, and ethical considerations of incorporating synthetic personae in HCI research, particularly focusing on the customization challenges beyond the limitations of current Large Language Models (LLMs). These perspectives are derived from the initial results of a sub-study employing vignettes to showcase the existence of bias within black-box LLMs and explore methods for manipulating them. The study aims to establish a foundation for understanding the challenges associated with these models, emphasizing the necessity of thorough testing before utilizing them to create synthetic personae for HCI research.

[Arxiv](https://arxiv.org/abs/2405.05080)