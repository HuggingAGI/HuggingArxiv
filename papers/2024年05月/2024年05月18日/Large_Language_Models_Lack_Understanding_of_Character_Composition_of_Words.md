# 大型语言模型在理解单词的字符构成方面存在缺陷。

发布时间：2024年05月18日

`LLM理论

这篇论文主要探讨了大型语言模型（LLMs）在理解单词字符构成方面的能力，并分析了它们在处理简单任务时的局限性。这属于对LLMs理论层面的研究，特别是关注其内部机制和理解能力的深度分析，因此应归类为LLM理论。` `机器学习`

> Large Language Models Lack Understanding of Character Composition of Words

# 摘要

> 大型语言模型（LLMs）在众多天然语言任务中表现出色，但它们的成功多限于单词、句子和文档层面，对于文本基本构成单位——字符的理解能力仍是个谜。本文深入探讨了LLMs在理解单词字符构成方面的能力，发现它们在处理人类轻松应对的简单任务时也常常力不从心。通过对比标记级别的性能，我们剖析了这些模型的行为，并展望了未来研究的新方向。

> Large language models (LLMs) have demonstrated remarkable performances on a wide range of natural language tasks. Yet, LLMs' successes have been largely restricted to tasks concerning words, sentences, or documents, and it remains questionable how much they understand the minimal units of text, namely characters. In this paper, we examine contemporary LLMs regarding their ability to understand character composition of words, and show that most of them fail to reliably carry out even the simple tasks that can be handled by humans with perfection. We analyze their behaviors with comparison to token level performances, and discuss the potential directions for future research.

[Arxiv](https://arxiv.org/abs/2405.11357)