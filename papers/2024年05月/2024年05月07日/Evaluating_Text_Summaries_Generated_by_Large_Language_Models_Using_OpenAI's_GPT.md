# 借助OpenAI的GPT，我们评估了大型语言模型所生成的文本摘要。本研究旨在探究GPT在生成精炼且信息丰富的摘要方面的能力，并分析其对不同类型文本的适应性。

发布时间：2024年05月07日

`LLM应用

这篇论文探讨了GPT模型在评估Hugging Face六种变压器模型生成的文本摘要方面的应用。它不仅使用了传统的评估指标，还创新性地将GPT作为评估工具，独立于固定指标之外进行评判。这种应用展示了GPT在自然语言处理领域中的实际用途，特别是在模型比较和摘要质量评估方面。因此，它属于大型语言模型（LLM）的应用范畴。` `文本摘要评估`

> Evaluating Text Summaries Generated by Large Language Models Using OpenAI's GPT

# 摘要

> 本研究探讨了GPT模型作为独立评估者对Hugging Face六种变压器模型生成的文本摘要的评估效果。我们依据高质量摘要的关键特性（简洁、相关、连贯、易读）进行评估，采用ROUGE和LSA等传统指标。此外，我们创新性地将GPT用作评估工具而非生成工具，使其在不依赖固定指标的情况下独立评判摘要质量。研究发现，GPT评估与传统指标高度相关，尤其在相关性和连贯性评估上。这表明GPT有望成为评估文本摘要的有力工具，为现有评估体系提供补充视角，并为自然语言处理领域中变压器模型的比较分析奠定基础。

> This research examines the effectiveness of OpenAI's GPT models as independent evaluators of text summaries generated by six transformer-based models from Hugging Face: DistilBART, BERT, ProphetNet, T5, BART, and PEGASUS. We evaluated these summaries based on essential properties of high-quality summary - conciseness, relevance, coherence, and readability - using traditional metrics such as ROUGE and Latent Semantic Analysis (LSA). Uniquely, we also employed GPT not as a summarizer but as an evaluator, allowing it to independently assess summary quality without predefined metrics. Our analysis revealed significant correlations between GPT evaluations and traditional metrics, particularly in assessing relevance and coherence. The results demonstrate GPT's potential as a robust tool for evaluating text summaries, offering insights that complement established metrics and providing a basis for comparative analysis of transformer-based models in natural language processing tasks.

[Arxiv](https://arxiv.org/abs/2405.04053)