# 借助OpenAI的GPT，我们评估了大型语言模型所生成的文本摘要，探究其在信息提炼与表达上的精妙之处。

发布时间：2024年05月07日

`LLM应用

这篇论文探讨了GPT模型在评估Hugging Face六种变压器模型生成的文本摘要质量方面的应用。它特别强调了GPT作为独立评估者的角色，而不是生成文本的角色，并且展示了GPT评估与传统指标（如ROUGE和LSA）的一致性。这种应用属于大型语言模型（LLM）的实际应用范畴，因此被归类为LLM应用。` `文本摘要评估`

> Evaluating Text Summaries Generated by Large Language Models Using OpenAI's GPT

# 摘要

> 本研究探讨了GPT模型作为独立评估者对Hugging Face六种变压器模型生成的文本摘要的评估效果。我们依据摘要的关键质量——简洁、相关、连贯和易读——采用ROUGE和LSA等传统指标进行评价。特别地，我们将GPT用作评估工具而非生成工具，使其在不依赖固定指标的情况下独立评判摘要质量。研究发现，GPT的评估与传统指标高度一致，尤其在相关性和连贯性方面。这表明GPT有望成为评估文本摘要的有力工具，为现有评价体系提供补充视角，并为自然语言处理领域内变压器模型的比较研究奠定基础。

> This research examines the effectiveness of OpenAI's GPT models as independent evaluators of text summaries generated by six transformer-based models from Hugging Face: DistilBART, BERT, ProphetNet, T5, BART, and PEGASUS. We evaluated these summaries based on essential properties of high-quality summary - conciseness, relevance, coherence, and readability - using traditional metrics such as ROUGE and Latent Semantic Analysis (LSA). Uniquely, we also employed GPT not as a summarizer but as an evaluator, allowing it to independently assess summary quality without predefined metrics. Our analysis revealed significant correlations between GPT evaluations and traditional metrics, particularly in assessing relevance and coherence. The results demonstrate GPT's potential as a robust tool for evaluating text summaries, offering insights that complement established metrics and providing a basis for comparative analysis of transformer-based models in natural language processing tasks.

[Arxiv](https://arxiv.org/abs/2405.04053)