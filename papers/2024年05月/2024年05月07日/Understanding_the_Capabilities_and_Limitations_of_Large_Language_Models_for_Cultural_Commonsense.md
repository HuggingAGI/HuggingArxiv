# 探究大型语言模型在文化常识领域的潜能与边界

发布时间：2024年05月07日

`LLM理论

这篇论文探讨了大型语言模型（LLMs）在处理文化常识任务时的表现，并分析了文化背景对LLMs常识理解能力的影响。它揭示了LLMs在文化理解上的内在偏差，并提出了构建更具文化敏感性的语言模型的建议。这些内容属于对LLMs理论层面的研究，特别是关于模型在特定领域（文化常识）的理解和偏差分析，因此归类为LLM理论。` `文化研究`

> Understanding the Capabilities and Limitations of Large Language Models for Cultural Commonsense

# 摘要

> 大型语言模型（LLMs）在常识理解方面表现出色，但在文化常识领域却鲜有探索。本文深入分析了数款顶尖LLMs在处理文化常识任务时的强项与短板。通过一系列通用与文化常识测试，我们揭示了LLMs在不同文化背景下的常识知识表现差异显著，文化背景对其通用常识能力有显著影响，且查询语言的选择会左右其在文化相关任务上的表现。本研究揭示了LLMs在文化理解上的内在偏差，并为构建更具文化敏感性的语言模型提供了启示。

> Large language models (LLMs) have demonstrated substantial commonsense understanding through numerous benchmark evaluations. However, their understanding of cultural commonsense remains largely unexamined. In this paper, we conduct a comprehensive examination of the capabilities and limitations of several state-of-the-art LLMs in the context of cultural commonsense tasks. Using several general and cultural commonsense benchmarks, we find that (1) LLMs have a significant discrepancy in performance when tested on culture-specific commonsense knowledge for different cultures; (2) LLMs' general commonsense capability is affected by cultural context; and (3) The language used to query the LLMs can impact their performance on cultural-related tasks. Our study points to the inherent bias in the cultural understanding of LLMs and provides insights that can help develop culturally aware language models.

[Arxiv](https://arxiv.org/abs/2405.04655)