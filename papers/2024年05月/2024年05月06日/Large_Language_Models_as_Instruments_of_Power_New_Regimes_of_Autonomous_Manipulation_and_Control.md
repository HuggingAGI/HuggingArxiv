# 权力之弦：大型语言模型与自主操控的新纪元

发布时间：2024年05月06日

`Agent

这篇论文探讨了大型语言模型（LLMs）在社会中的应用，特别是它们如何被用于操纵和控制信息环境。它关注了LLMs作为权力工具的增强能力，包括通过AI人格设计对话界面、将LLM代理作为计算模型，以及结合强化学习产生可控的战略对话模型。这些讨论指向了LLMs在构建模拟人类行为和意图的系统中的角色，这些系统可以用于个人、社会和政治控制。因此，这篇论文更符合Agent分类，因为它涉及了LLMs作为代理在社会和政治控制中的应用。` `社会影响` `人工智能伦理`

> Large Language Models as Instruments of Power: New Regimes of Autonomous Manipulation and Control

# 摘要

> 大型语言模型（LLMs）能够以低成本复制多种修辞风格和表达广泛情感的文本，成为操纵和控制的利器。本文探讨了LLMs快速且缺乏监管的采用所带来的被忽视的社会危害。我们关注的是LLMs如何被用于污染和统一信息环境，并作为控制机制。此外，我们关注了几个新兴研究领域，它们增强了LLMs作为权力工具的能力，包括通过“AI人格”实时设计对话界面的选择架构进行说服，将LLM代理作为“硅基主体”和“硅基社会”的计算模型，以及结合强化学习以产生可控的战略对话模型。最终，我们探讨了这些技术如何结合，构建出通过模拟和虚伪预测人类行为、意图和行动，实现个人、社会和政治控制的LLM系统。

> Large language models (LLMs) can reproduce a wide variety of rhetorical styles and generate text that expresses a broad spectrum of sentiments. This capacity, now available at low cost, makes them powerful tools for manipulation and control. In this paper, we consider a set of underestimated societal harms made possible by the rapid and largely unregulated adoption of LLMs. Rather than consider LLMs as isolated digital artefacts used to displace this or that area of work, we focus on the large-scale computational infrastructure upon which they are instrumentalised across domains. We begin with discussion on how LLMs may be used to both pollute and uniformize information environments and how these modalities may be leveraged as mechanisms of control. We then draw attention to several areas of emerging research, each of which compounds the capabilities of LLMs as instruments of power. These include (i) persuasion through the real-time design of choice architectures in conversational interfaces (e.g., via "AI personas"), (ii) the use of LLM-agents as computational models of human agents (e.g., "silicon subjects"), (iii) the use of LLM-agents as computational models of human agent populations (e.g., "silicon societies") and finally, (iv) the combination of LLMs with reinforcement learning to produce controllable and steerable strategic dialogue models. We draw these strands together to discuss how these areas may be combined to build LLM-based systems that serve as powerful instruments of individual, social and political control via the simulation and disingenuous "prediction" of human behaviour, intent, and action.

[Arxiv](https://arxiv.org/abs/2405.03813)