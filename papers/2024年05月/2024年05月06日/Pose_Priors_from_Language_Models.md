# 语言模型中提炼的姿态先验

发布时间：2024年05月06日

`LLM应用` `计算机视觉` `人工智能`

> Pose Priors from Language Models

# 摘要

> 本文介绍了一种无需训练的姿态优化技术，该技术在估算人体三维姿态时，能够确保精确的物理接触限制。核心观点在于，语言常用于描述物理互动，因此可以利用大型预训练文本模型作为姿态估计的参考依据。基于此，我们将大型多模态模型生成的自然语言描述转换为可操作的损失函数，以此来优化三维姿态。此方法虽然简便，却能生成极具说服力的人物姿态重建效果，精准捕捉社交和物理互动的细节。实验结果表明，该方法的效果可与那些需要人工标注接触点和专门模型训练的复杂先进方法相竞争。此外，与以往的研究相比，本方法提供了一个统一的解决方案，用以处理自我接触和人际接触的问题。

> We present a zero-shot pose optimization method that enforces accurate physical contact constraints when estimating the 3D pose of humans. Our central insight is that since language is often used to describe physical interaction, large pretrained text-based models can act as priors on pose estimation.
  We can thus leverage this insight to improve pose estimation by converting natural language descriptors, generated by a large multimodal model (LMM), into tractable losses to constrain the 3D pose optimization. Despite its simplicity, our method produces surprisingly compelling pose reconstructions of people in close contact, correctly capturing the semantics of the social and physical interactions. We demonstrate that our method rivals more complex state-of-the-art approaches that require expensive human annotation of contact points and training specialized models. Moreover, unlike previous approaches, our method provides a unified framework for resolving self-contact and person-to-person contact.

[Arxiv](https://arxiv.org/abs/2405.03689)