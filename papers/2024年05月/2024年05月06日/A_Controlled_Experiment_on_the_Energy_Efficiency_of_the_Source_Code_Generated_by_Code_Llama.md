# 一项针对 Code Llama 所生成源代码能效的控制性实验研究。

发布时间：2024年05月06日

`LLM应用` `软件开发` `能效评估`

> A Controlled Experiment on the Energy Efficiency of the Source Code Generated by Code Llama

# 摘要

> 如今，超过八成的软件开发者借助大型语言模型（LLMs）来编写代码，这些模型已成为提升开发效率、降低开发时间和成本的利器。开发者们利用 LLM 工具进行漏洞检测、修补，并将生成的代码融入软件之中。尽管如此，对于这些工具产出的源代码能效，尚缺乏客观评价。Code Llama 作为 2023 年 8 月推出的最新 LLM 工具，本研究旨在实证评估其与人工编写代码的能效对比。我们通过实验，选取了 C++、JavaScript 和 Python 三种语言编写的三个基准测试，让 Code Llama 根据不同的提示和温度生成相应的代码，并与人工编写的代码进行了能效对比分析。实验结果揭示，Code Llama 生成的代码能效与所用编程语言和特定代码问题紧密相关。总体而言，人工编写的代码在能效上更胜一筹，尤其是在 JavaScript 代码的生成上，机器生成的代码表现更佳。此外，即便是明确指示 Code Llama 生成节能代码，其结果也并未显示出能效上的优势，而且不同的温度设置似乎对生成代码的能效没有显著影响。综上所述，Code Llama 生成的代码并不自动等同于能效最优，开发人员在将这些代码融入开发中的软件系统前，必须先行评估其能效表现。

> Context. Nowadays, 83% of software developers use Large Language Models (LLMs) to generate code. LLMs recently became essential to increase the productivity of software developers and decrease the time and cost of software development. Developers ranging from novices to experts use LLM tools not only to detect and patch bugs, but also to integrate generated code into their software. However, as of today there is no objective assessment of the energy efficiency of the source code generated by LLM tools. Released in August 2023, Code Llama is one of the most recent LLM tools.
  Goal. In this paper, we present an empirical study that assesses the energy efficiency of Code Llama with respect to human-written source code.
  Method. We design an experiment involving three human-written benchmarks implemented in C++, JavaScript, and Python. We ask Code Llama to generate the code of the benchmarks using different prompts and temperatures. Therefore, we execute both implementations and profile their energy efficiency.
  Results. Our study shows that the energy efficiency of code generated by Code Llama is heavily-dependent on the chosen programming language and the specific code problem at hand. Also, human implementations tend to be more energy efficient overall, with generated JavaScript code outperforming its human counterpart. Moreover, explicitly asking Code Llama to generate energy-efficient code results in an equal or worse energy efficiency, as well as using different temperatures seems not to affect the energy efficiency of generated code.
  Conclusions. According to our results, code generated using Code Llama does not guarantee energy efficiency, even when prompted to do so. Therefore, software developers should evaluate the energy efficiency of generated code before integrating it into the software system under development.

[Arxiv](https://arxiv.org/abs/2405.03616)