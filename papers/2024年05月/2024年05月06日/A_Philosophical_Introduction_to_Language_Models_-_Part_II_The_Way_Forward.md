# 《语言模型哲学探析（下）：前行之路》

发布时间：2024年05月06日

`分类：LLM理论` `人工智能` `认知科学`

> A Philosophical Introduction to Language Models - Part II: The Way Forward

# 摘要

> 本文作为姊妹篇的续篇，深入探讨了大型语言模型（LLMs）的最新进展所引发的哲学新议题，超越了前篇讨论的传统争议。文章着重分析了可解释性问题，通过因果干预方法探究了LLMs内部表征和计算的本质。同时，讨论了LLMs的多模态和模块化扩展的意义，以及这些系统是否达到意识基本标准的近期讨论，并对LLM研究中的秘密性和可复制性问题表达了关切。文章最后探讨了，如果LLMs的架构特性和学习场景得到恰当的约束，它们是否可能对模拟人类认知的某些方面具有重要价值。

> In this paper, the second of two companion pieces, we explore novel philosophical questions raised by recent progress in large language models (LLMs) that go beyond the classical debates covered in the first part. We focus particularly on issues related to interpretability, examining evidence from causal intervention methods about the nature of LLMs' internal representations and computations. We also discuss the implications of multimodal and modular extensions of LLMs, recent debates about whether such systems may meet minimal criteria for consciousness, and concerns about secrecy and reproducibility in LLM research. Finally, we discuss whether LLM-like systems may be relevant to modeling aspects of human cognition, if their architectural characteristics and learning scenario are adequately constrained.

[Arxiv](https://arxiv.org/abs/2405.03207)