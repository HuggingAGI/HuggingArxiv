# AtomGPT：一种原子级别的生成预训练变换器，专为正向和逆向材料设计而开发。

发布时间：2024年05月06日

`LLM应用` `材料设计` `人工智能`

> AtomGPT: Atomistic Generative Pre-trained Transformer for Forward and Inverse Materials Design

# 摘要

> 大型语言模型（LLMs），例如生成预训练变换器（GPTs），在商业应用领域展现出巨大潜力，但其在材料设计领域的应用尚未被深入挖掘。本文介绍了 AtomGPT，这是一款专为材料设计量身定制的模型，基于变换器架构，旨在实现原子性质预测和结构生成。我们证明，结合化学和结构文本描述可以有效预测材料属性，准确度与图神经网络模型相当，包括形成能、两种方法计算的电子带隙以及超导转变温度。此外，AtomGPT 还能为设计新型超导体等任务生成原子结构，并通过密度泛函理论计算对预测结果进行了验证。这项研究为利用 LLMs 进行正向和逆向材料设计开辟了新途径，为材料的发现和优化提供了一种高效率的解决方案。

> Large language models (LLMs) such as generative pretrained transformers (GPTs) have shown potential for various commercial applications, but their applicability for materials design remains underexplored. In this article, we introduce AtomGPT, a model specifically developed for materials design based on transformer architectures, to demonstrate the capability for both atomistic property prediction and structure generation. We show that a combination of chemical and structural text descriptions can efficiently predict material properties with accuracy comparable to graph neural network models, including formation energies, electronic bandgaps from two different methods and superconducting transition temperatures. Furthermore, we demonstrate that AtomGPT can generate atomic structures for tasks such as designing new superconductors, with the predictions validated through density functional theory calculations. This work paves the way for leveraging LLMs in forward and inverse materials design, offering an efficient approach to the discovery and optimization of materials.

[Arxiv](https://arxiv.org/abs/2405.03680)