# 借助文本语义匹配，本研究提出了一种语言引导的自监督视频摘要方法，旨在捕捉视频内容的多样性，从而生成更加丰富和精准的视频摘要。

发布时间：2024年05月14日

`Agent

这篇论文探讨了如何利用大型语言模型（LLMs）来增强视频摘要技术，提出了一种创新的自我监督框架，该框架通过LLMs指导视频摘要生成。这种方法涉及自动生成视频帧的标题，然后使用LLMs将这些标题整合成文本摘要，并基于语义相似度选择帧来生成最终的视频摘要。这种应用可以被视为一个智能代理（Agent），因为它处理输入数据（视频帧）并生成有用的输出（视频摘要），同时利用了LLMs的能力来提高摘要的质量。因此，这篇论文属于Agent分类。` `视频摘要`

> Language-Guided Self-Supervised Video Summarization Using Text Semantic Matching Considering the Diversity of the Video

# 摘要

> 当前视频摘要技术依赖于监督学习，需要大量主观且耗时的手动标注。为了克服这一挑战，我们探索了将视频摘要任务转化为文本摘要，并借助大型语言模型（LLMs）增强效果的可能性。本文提出了一种创新的自我监督框架，利用LLMs指导视频摘要生成。首先，我们为视频帧自动生成标题，然后通过LLMs将这些标题整合成连贯的文本摘要。接着，我们测量帧标题与文本摘要之间的语义相似度，并设计了一种新的损失函数，以视频内容的多样性为依据优化模型。最终，我们通过挑选与文本摘要语义相近的帧来生成视频摘要。我们的模型在性能上与现有顶尖方法相媲美，为视频摘要领域开辟了新的研究方向。

> Current video summarization methods primarily depend on supervised computer vision techniques, which demands time-consuming manual annotations. Further, the annotations are always subjective which make this task more challenging. To address these issues, we analyzed the feasibility in transforming the video summarization into a text summary task and leverage Large Language Models (LLMs) to boost video summarization. This paper proposes a novel self-supervised framework for video summarization guided by LLMs. Our method begins by generating captions for video frames, which are then synthesized into text summaries by LLMs. Subsequently, we measure semantic distance between the frame captions and the text summary. It's worth noting that we propose a novel loss function to optimize our model according to the diversity of the video. Finally, the summarized video can be generated by selecting the frames whose captions are similar with the text summary. Our model achieves competitive results against other state-of-the-art methods and paves a novel pathway in video summarization.

[Arxiv](https://arxiv.org/abs/2405.08890)