# RecGPT：文本推荐领域的生成式预训练新篇章

发布时间：2024年05月21日

`LLM应用

理由：这篇论文介绍了专门为文本推荐任务设计的大型语言模型RecGPT-7B及其指令遵循版本RecGPT-7B-Instruct，并展示了它们在评分预测与序列推荐任务中的优越性能。此外，论文还公开了相关的预训练及微调数据集，以推动该领域的研究与应用。这些内容主要关注于大型语言模型在特定应用场景（文本推荐）中的实际应用和性能提升，因此属于LLM应用类别。` `推荐系统`

> RecGPT: Generative Pre-training for Text-based Recommendation

# 摘要

> 我们推出了首个专为文本推荐定制并全面训练的大型语言模型RecGPT-7B及其指令遵循版本RecGPT-7B-Instruct。实验证明，在评分预测与序列推荐任务中，RecGPT-7B-Instruct超越了以往的顶尖模型。为推动基于文本的推荐领域的研究与应用，我们已公开RecGPT系列模型的预训练及微调数据集。您可通过以下链接访问我们的RecGPT模型与数据集：https://github.com/VinAIResearch/RecGPT

> We present the first domain-adapted and fully-trained large language model, RecGPT-7B, and its instruction-following variant, RecGPT-7B-Instruct, for text-based recommendation. Experimental results on rating prediction and sequential recommendation tasks show that our model, RecGPT-7B-Instruct, outperforms previous strong baselines. We are releasing our RecGPT models as well as their pre-training and fine-tuning datasets to facilitate future research and downstream applications in text-based recommendation. Public "huggingface" links to our RecGPT models and datasets are available at: https://github.com/VinAIResearch/RecGPT

[Arxiv](https://arxiv.org/abs/2405.12715)