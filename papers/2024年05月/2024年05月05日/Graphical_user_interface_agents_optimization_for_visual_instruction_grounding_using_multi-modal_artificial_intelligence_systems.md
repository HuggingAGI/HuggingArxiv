# 通过多模态AI系统优化图形用户界面的视觉指令接地

发布时间：2024年05月05日

`Agent` `人工智能` `图形用户界面`

> Graphical user interface agents optimization for visual instruction grounding using multi-modal artificial intelligence systems

# 摘要

> 当前，多数实例感知与图像理解技术聚焦于自然图像，而合成图像，尤其是GUI图像的应用尚显不足，这限制了自主AI代理的发展。为此，我们推出了搜索指令坐标（SIC），一种专为GUI对象识别设计的多模态方案。具体而言，SIC能根据自然语言指令和GUI截图，精准定位执行指令的屏幕组件坐标。我们采用了两种创新方法：一是结合大型语言模型与对象检测模型的三部分架构；二是运用多模态基础模型。

> Most instance perception and image understanding solutions focus mainly on natural images. However, applications for synthetic images, and more specifically, images of Graphical User Interfaces (GUI) remain limited. This hinders the development of autonomous computer-vision-powered Artificial Intelligence (AI) agents. In this work, we present Search Instruction Coordinates or SIC, a multi-modal solution for object identification in a GUI. More precisely, given a natural language instruction and a screenshot of a GUI, SIC locates the coordinates of the component on the screen where the instruction would be executed. To this end, we develop two methods. The first method is a three-part architecture that relies on a combination of a Large Language Model (LLM) and an object detection model. The second approach uses a multi-modal foundation model.

[Arxiv](https://arxiv.org/abs/2407.01558)