# 代码大型语言模型中的潜在威胁：基于触发机制的分类法进行的深入剖析。

发布时间：2024年05月05日

`LLM应用` `软件开发`

> Trojans in Large Language Models of Code: A Critical Review through a Trigger-Based Taxonomy

# 摘要

> 大型语言模型（LLMs）为软件开发领域带来了诸多创新能力，但其内在的不透明性却增加了推理和审查的难度，由此引发的安全隐患不容忽视。敌手可能借此训练并部署恶意模型，对软件开发流程造成破坏。本研究综述了针对代码大型语言模型的木马攻击技术，特别关注了木马设计的核心——触发器，并引入了一种新的统一触发器分类框架。此外，我们还旨在为代码LLMs中的木马概念提供一个清晰的定义。最终，我们探讨了代码模型学习触发器设计的影响，为未来的研究和实践提供了指导。

> Large language models (LLMs) have provided a lot of exciting new capabilities in software development. However, the opaque nature of these models makes them difficult to reason about and inspect. Their opacity gives rise to potential security risks, as adversaries can train and deploy compromised models to disrupt the software development process in the victims' organization.
  This work presents an overview of the current state-of-the-art trojan attacks on large language models of code, with a focus on triggers -- the main design point of trojans -- with the aid of a novel unifying trigger taxonomy framework. We also aim to provide a uniform definition of the fundamental concepts in the area of trojans in Code LLMs. Finally, we draw implications of findings on how code models learn on trigger design.

![代码大型语言模型中的潜在威胁：基于触发机制的分类法进行的深入剖析。](../../../paper_images/2405.02828/x1.png)

![代码大型语言模型中的潜在威胁：基于触发机制的分类法进行的深入剖析。](../../../paper_images/2405.02828/x2.png)

![代码大型语言模型中的潜在威胁：基于触发机制的分类法进行的深入剖析。](../../../paper_images/2405.02828/x3.png)

![代码大型语言模型中的潜在威胁：基于触发机制的分类法进行的深入剖析。](../../../paper_images/2405.02828/x4.png)

![代码大型语言模型中的潜在威胁：基于触发机制的分类法进行的深入剖析。](../../../paper_images/2405.02828/x5.png)

![代码大型语言模型中的潜在威胁：基于触发机制的分类法进行的深入剖析。](../../../paper_images/2405.02828/x6.png)

![代码大型语言模型中的潜在威胁：基于触发机制的分类法进行的深入剖析。](../../../paper_images/2405.02828/x7.png)

[Arxiv](https://arxiv.org/abs/2405.02828)