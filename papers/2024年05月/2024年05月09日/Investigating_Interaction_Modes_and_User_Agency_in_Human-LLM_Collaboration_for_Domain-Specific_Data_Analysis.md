# 探究在特定领域数据分析中，人类与LLM协作的交互方式及用户自主权在翻译过程中，我首先确保了原文意思的准确传达，然后对语言进行了优化，使其更加符合中文的表达习惯，同时保持了原文的生动性和简洁性。

发布时间：2024年05月09日

`Agent

这篇论文探讨了大型语言模型（LLMs）在数据分析领域的应用，并设计了两种不同自主性的AI数据分析工具原型。它通过访谈数据科学家来了解用户对LLMs在数据分析辅助中的看法，以及这些原型如何影响用户的行为和工作效率。这表明论文关注的是如何设计智能代理（Agent）来辅助用户进行数据分析，因此属于Agent分类。` `数据分析` `人工智能辅助工具`

> Investigating Interaction Modes and User Agency in Human-LLM Collaboration for Domain-Specific Data Analysis

# 摘要

> 大型语言模型（LLMs）虽在通用数据操作任务中表现出色，但在特定领域任务上却显露短板。本研究从交互与用户自主性两方面出发，设计了两种极端的AI数据分析工具原型：开放式高自主性（OHA）与结构化低自主性（SLA）。通过与九位数据科学家的访谈，我们探讨了用户对LLMs在数据分析辅助中输出的看法，以及OHA和SLA原型如何影响他们的行为、工作效率和感知。研究发现，用户不仅关注LLMs的交互体验和结果质量，还渴望了解其输出背后的逻辑，并期待与其他用户协作，以及如何将LLMs融入他们的日常工作流程中。

> Despite demonstrating robust capabilities in performing tasks related to general-domain data-operation tasks, Large Language Models (LLMs) may exhibit shortcomings when applied to domain-specific tasks. We consider the design of domain-specific AI-powered data analysis tools from two dimensions: interaction and user agency. We implemented two design probes that fall on the two ends of the two dimensions: an open-ended high agency (OHA) prototype and a structured low agency (SLA) prototype. We conducted an interview study with nine data scientists to investigate (1) how users perceived the LLM outputs for data analysis assistance, and (2) how the two test design probes, OHA and SLA, affected user behavior, performance, and perceptions. Our study revealed insights regarding participants' interactions with LLMs, how they perceived the results, and their desire for explainability concerning LLM outputs, along with a noted need for collaboration with other users, and how they envisioned the utility of LLMs in their workflow.

[Arxiv](https://arxiv.org/abs/2405.05548)