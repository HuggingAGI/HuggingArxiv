# 编辑大人，关于将放射学报告提交至ChatGPT，我们需深思其法律与伦理的边界。此举涉及的法规遵循与道德考量，值得我们共同探讨。

发布时间：2024年05月09日

`LLM应用

这篇论文摘要讨论了大型语言模型（如GPT-4、Perplexity和Bard）在急诊放射学报告中识别关键信息的能力，以及相关的伦理和数据保护问题。这属于LLM在特定领域（医疗领域）的应用，因此归类为LLM应用。虽然文中提到了伦理和数据保护问题，但这些讨论是围绕LLM的应用展开的，而不是对LLM理论本身的探讨，因此不符合LLM理论分类。同时，文中没有提到Agent或RAG相关的概念，所以这两个分类也不适用。` `急诊放射学` `数据隐私保护`

> Letter to the Editor: What are the legal and ethical considerations of submitting radiology reports to ChatGPT?

# 摘要

> 本文深入探讨了Infante等人的研究，探讨了GPT-4、Perplexity和Bard等大型语言模型在急诊放射学报告中识别关键信息的能力。尽管这些模型在自动化标签生成方面展现出潜力，但文章也警示了未经患者同意使用其数据可能引发的伦理问题，并强调了在GDPR框架下实施严格数据保护的重要性。

> This letter critically examines the recent article by Infante et al. assessing the utility of large language models (LLMs) like GPT-4, Perplexity, and Bard in identifying urgent findings in emergency radiology reports. While acknowledging the potential of LLMs in generating labels for computer vision, concerns are raised about the ethical implications of using patient data without explicit approval, highlighting the necessity of stringent data protection measures under GDPR.

[Arxiv](https://arxiv.org/abs/2405.05647)