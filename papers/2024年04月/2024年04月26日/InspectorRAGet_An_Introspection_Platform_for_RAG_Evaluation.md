# InspectorRAGet：一个用于评估 RAG（Retrieval-Augmented Generation，检索增强生成）的内省式平台

发布时间：2024年04月26日

`RAG` `信息检索`

> InspectorRAGet: An Introspection Platform for RAG Evaluation

# 摘要

> 大型语言模型（LLM）在构建检索增强生成（RAG）系统方面备受青睐，为此，人们投入了大量精力来开发优秀的模型和评价标准。尽管对RAG系统进行严谨评估的需求日益增长，但目前能够超越模型输出生成和自动计算的工具却相当稀缺。我们推出了InspectorRAGet，这是一个用于评估RAG系统的深度分析平台。该平台支持用户通过人工和算法评价指标，以及评估注释者的质量，来深入分析RAG系统的综合和个体表现。InspectorRAGet适用于多种应用场景，并且已经向公众开放。相关演示视频可以在 https://youtu.be/MJhe8QIXcEc 观看。

> Large Language Models (LLM) have become a popular approach for implementing Retrieval Augmented Generation (RAG) systems, and a significant amount of effort has been spent on building good models and metrics. In spite of increased recognition of the need for rigorous evaluation of RAG systems, few tools exist that go beyond the creation of model output and automatic calculation. We present InspectorRAGet, an introspection platform for RAG evaluation. InspectorRAGet allows the user to analyze aggregate and instance-level performance of RAG systems, using both human and algorithmic metrics as well as annotator quality. InspectorRAGet is suitable for multiple use cases and is available publicly to the community. The demo video is available at https://youtu.be/MJhe8QIXcEc

[Arxiv](https://arxiv.org/abs/2404.17347)