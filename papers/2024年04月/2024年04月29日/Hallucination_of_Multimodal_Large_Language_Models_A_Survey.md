# 多模态大型语言模型幻觉现象研究综述

发布时间：2024年04月29日

`分类：LLM理论` `计算机视觉`

> Hallucination of Multimodal Large Language Models: A Survey

# 摘要

> 本篇综述深入探讨了多模态大型语言模型（MLLMs），亦称为大型视觉-语言模型（LVLMs），在多模态任务中虽取得显著进步，却常产生与视觉信息不符的幻觉现象，这一问题严重阻碍了它们的实际应用，并引发了对其在现实世界中可靠性的质疑。对此问题的关注日益增加，研究者们正努力识别和减轻这些幻觉。本文综述了识别、评估和缓解幻觉的最新进展，详细分析了幻觉的成因、评估标准、度量指标以及应对策略。同时，我们剖析了当前面临的挑战与限制，提出了未来研究可能的研究方向。本研究旨在通过细致的分类和分析幻觉成因、评估基准和缓解方法，深化对 MLLMs 中幻觉现象的理解，并推动该领域的进一步发展。我们的深入分析为提升 MLLMs 的鲁棒性和可信度提供了丰富的洞见和资源，为研究人员和实践者提供了宝贵的参考。相关资源可在 https://github.com/showlab/Awesome-MLLM-Hallucination 查看。

> This survey presents a comprehensive analysis of the phenomenon of hallucination in multimodal large language models (MLLMs), also known as Large Vision-Language Models (LVLMs), which have demonstrated significant advancements and remarkable abilities in multimodal tasks. Despite these promising developments, MLLMs often generate outputs that are inconsistent with the visual content, a challenge known as hallucination, which poses substantial obstacles to their practical deployment and raises concerns regarding their reliability in real-world applications. This problem has attracted increasing attention, prompting efforts to detect and mitigate such inaccuracies. We review recent advances in identifying, evaluating, and mitigating these hallucinations, offering a detailed overview of the underlying causes, evaluation benchmarks, metrics, and strategies developed to address this issue. Additionally, we analyze the current challenges and limitations, formulating open questions that delineate potential pathways for future research. By drawing the granular classification and landscapes of hallucination causes, evaluation benchmarks, and mitigation methods, this survey aims to deepen the understanding of hallucinations in MLLMs and inspire further advancements in the field. Through our thorough and in-depth review, we contribute to the ongoing dialogue on enhancing the robustness and reliability of MLLMs, providing valuable insights and resources for researchers and practitioners alike. Resources are available at: https://github.com/showlab/Awesome-MLLM-Hallucination.

[Arxiv](https://arxiv.org/abs/2404.18930)