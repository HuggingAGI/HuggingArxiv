# 大型语言模型（LLM）的道德推理与价值观念的一致性，取决于我们如何用语言引导它们。

发布时间：2024年04月29日

`分类：LLM应用

这篇论文研究了大型语言模型（LLMs）在不同语言环境下的伦理推理能力，以及他们的道德判断是否会随着使用语言的不同而变化。这属于LLM应用的范畴，因为它探讨了LLMs在实际应用中的表现和问题。论文并没有涉及到LLMs的理论基础，也没有讨论如何改进或构建LLMs，因此不属于LLM理论。同时，论文也没有涉及到智能代理（Agent）或知识检索（RAG）的相关内容。` `人工智能伦理` `语言模型`

> Ethical Reasoning and Moral Value Alignment of LLMs Depend on the Language we Prompt them in

# 摘要

> 伦理推理对于大型语言模型（LLMs）至关重要，但道德观念受语言与文化的影响而不尽相同。本研究考察了GPT-4、ChatGPT和Llama2-70B-Chat这三款主流LLMs在不同语言环境下的伦理推理能力，以及他们的道德判断是否会随着使用语言的不同而变化。我们依据Rao等人（2023年）的研究框架，将伦理困境和政策应用于LLMs的多语言测试，涵盖规范伦理学的三大分支：义务论、美德伦理和后果主义。实验涉及英语、西班牙语、俄语、中文、印地语和斯瓦希里语六种语言。研究结果显示，GPT-4在跨语言伦理推理中表现出最高的一致性和公正性，而ChatGPT和Llama2-70B-Chat在非英语环境下则表现出较大的道德价值偏差。值得注意的是，包括GPT-4在内的所有LLMs在不同语言中的偏差特性均有所不同。

> Ethical reasoning is a crucial skill for Large Language Models (LLMs). However, moral values are not universal, but rather influenced by language and culture. This paper explores how three prominent LLMs -- GPT-4, ChatGPT, and Llama2-70B-Chat -- perform ethical reasoning in different languages and if their moral judgement depend on the language in which they are prompted. We extend the study of ethical reasoning of LLMs by Rao et al. (2023) to a multilingual setup following their framework of probing LLMs with ethical dilemmas and policies from three branches of normative ethics: deontology, virtue, and consequentialism. We experiment with six languages: English, Spanish, Russian, Chinese, Hindi, and Swahili. We find that GPT-4 is the most consistent and unbiased ethical reasoner across languages, while ChatGPT and Llama2-70B-Chat show significant moral value bias when we move to languages other than English. Interestingly, the nature of this bias significantly vary across languages for all LLMs, including GPT-4.

[Arxiv](https://arxiv.org/abs/2404.18460)