# 多感官人工智能之基石

发布时间：2024年04月29日

`分类：Agent` `人工智能` `多模态交互`

> Foundations of Multisensory Artificial Intelligence

# 摘要

> 本研究致力于开发能够整合文本、语音、视频、传感器数据等多种感官信息的多感官人工智能系统，这些系统在促进人类健康、处理多媒体内容以及提升自主智能体性能等多个科学领域具有重要应用价值。本文首先构建了一个理论框架，阐释了不同感官模态如何相互交互以生成新信息，这些交互是解决多模态问题的关键，有助于深入理解数据集、设计学习交互的方法，并评估模型学习效果。接着，研究了一种实用的多模态基础模型，它能够跨越多种感官和任务，为大型语言模型与现实世界感官模态的结合提供了新途径。我们提出了MultiBench，一个覆盖广泛模态、任务和研究领域的大规模统一基准，以及支撑当前许多多模态基础模型的跨模态注意力和多模态变换器架构。通过在MultiBench上扩展这些架构，我们能够构建出通用的多感官AI系统，并探讨了如何将这些模型应用于情感计算、心理健康、癌症预后和机器人技术等领域，以实现现实世界的影响。最后，论文以讨论如何利用这些研究成果推动多感官AI向更通用、互动和安全方向发展作为结尾。

> Building multisensory AI systems that learn from multiple sensory inputs such as text, speech, video, real-world sensors, wearable devices, and medical data holds great promise for impact in many scientific areas with practical benefits, such as in supporting human health and well-being, enabling multimedia content processing, and enhancing real-world autonomous agents. By synthesizing a range of theoretical frameworks and application domains, this thesis aims to advance the machine learning foundations of multisensory AI. In the first part, we present a theoretical framework formalizing how modalities interact with each other to give rise to new information for a task. These interactions are the basic building blocks in all multimodal problems, and their quantification enables users to understand their multimodal datasets, design principled approaches to learn these interactions, and analyze whether their model has succeeded in learning. In the second part, we study the design of practical multimodal foundation models that generalize over many modalities and tasks, which presents a step toward grounding large language models to real-world sensory modalities. We introduce MultiBench, a unified large-scale benchmark across a wide range of modalities, tasks, and research areas, followed by the cross-modal attention and multimodal transformer architectures that now underpin many of today's multimodal foundation models. Scaling these architectures on MultiBench enables the creation of general-purpose multisensory AI systems, and we discuss our collaborative efforts in applying these models for real-world impact in affective computing, mental health, cancer prognosis, and robotics. Finally, we conclude this thesis by discussing how future work can leverage these ideas toward more general, interactive, and safe multisensory AI.

[Arxiv](https://arxiv.org/abs/2404.18976)