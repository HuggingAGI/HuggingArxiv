# GPT-4 是否能够胜任 L2 级别的分析性评估？

发布时间：2024年04月29日

`LLM应用` `自动评分系统`

> Can GPT-4 do L2 analytic assessment?

# 摘要

> 自动作文评分（AES）评估第二语言（L2）能力，已在教育领域应用多年。尽管整体评分技术在 AES 中取得了与人类评分相媲美甚至超越的进步，但分析性评分因承袭了人为评分的缺陷而仍面临挑战。大型语言模型的新兴为 L2 写作技能的自动化评估带来了新的机遇。本文通过 GPT-4 在一个标注了基于欧洲共同参考框架整体分数的公开数据集上进行了零样本实验，旨在深入挖掘其分析评分的潜在构成要素。研究发现，自动预测的分析评分与各个能力要素相关的多种特征之间呈现出显著的正相关性。

> Automated essay scoring (AES) to evaluate second language (L2) proficiency has been a firmly established technology used in educational contexts for decades. Although holistic scoring has seen advancements in AES that match or even exceed human performance, analytic scoring still encounters issues as it inherits flaws and shortcomings from the human scoring process. The recent introduction of large language models presents new opportunities for automating the evaluation of specific aspects of L2 writing proficiency. In this paper, we perform a series of experiments using GPT-4 in a zero-shot fashion on a publicly available dataset annotated with holistic scores based on the Common European Framework of Reference and aim to extract detailed information about their underlying analytic components. We observe significant correlations between the automatically predicted analytic scores and multiple features associated with the individual proficiency components.

[Arxiv](https://arxiv.org/abs/2404.18557)