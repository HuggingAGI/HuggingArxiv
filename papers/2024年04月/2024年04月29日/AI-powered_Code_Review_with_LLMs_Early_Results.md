# AI 助力代码审查：大型语言模型的初步成效

发布时间：2024年04月29日

`Agent` `软件工程` `人工智能`

> AI-powered Code Review with LLMs: Early Results

# 摘要

> 本文介绍了一种创新方法，利用大型语言模型（LLM）为基础的人工智能（AI）代理来提升软件质量和效能。该AI代理经过在庞大代码库上的培训，涵盖代码审查、缺陷报告和最佳实践文档，旨在识别代码异味、潜在缺陷，提供优化建议，并对代码进行优化。与传统静态代码分析工具相比，我们的LLM-AI代理能够预见代码中的未来风险，旨在提升代码品质和增进开发者对最佳实践与高效编码技巧的理解。此外，本研究还探讨了该模型在减少发布后缺陷和提升代码审查流程方面的建议效果，这一点通过分析开发者对LLM反馈的情绪得到了证实。展望未来，我们计划评估LLM生成的文档更新的准确性和效率，并与手工方法进行比较。这包括一项实证研究，专注于手工代码审查以识别代码异味和缺陷，同时评估最佳实践文档，并结合开发者讨论和代码审查的洞见。我们的目标是提升LLM工具的准确性，并强调其在通过预防性代码改进和教育来优化软件开发生命周期中的潜力。

> In this paper, we present a novel approach to improving software quality and efficiency through a Large Language Model (LLM)-based model designed to review code and identify potential issues. Our proposed LLM-based AI agent model is trained on large code repositories. This training includes code reviews, bug reports, and documentation of best practices. It aims to detect code smells, identify potential bugs, provide suggestions for improvement, and optimize the code. Unlike traditional static code analysis tools, our LLM-based AI agent has the ability to predict future potential risks in the code. This supports a dual goal of improving code quality and enhancing developer education by encouraging a deeper understanding of best practices and efficient coding techniques. Furthermore, we explore the model's effectiveness in suggesting improvements that significantly reduce post-release bugs and enhance code review processes, as evidenced by an analysis of developer sentiment toward LLM feedback. For future work, we aim to assess the accuracy and efficiency of LLM-generated documentation updates in comparison to manual methods. This will involve an empirical study focusing on manually conducted code reviews to identify code smells and bugs, alongside an evaluation of best practice documentation, augmented by insights from developer discussions and code reviews. Our goal is to not only refine the accuracy of our LLM-based tool but also to underscore its potential in streamlining the software development lifecycle through proactive code improvement and education.

[Arxiv](https://arxiv.org/abs/2404.18496)