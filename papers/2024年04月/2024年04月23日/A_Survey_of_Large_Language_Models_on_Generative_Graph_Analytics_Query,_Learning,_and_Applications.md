# 大型语言模型在生成性图分析领域的综述：探讨查询、学习及应用

发布时间：2024年04月23日

`LLM应用` `图数据研究`

> A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications

# 摘要

> 图作为核心数据模型，广泛用于描绘社会与自然中的实体及其错综复杂的联系，如社交网络、交通系统、金融体系和生物医学网络等。近期，大型语言模型（LLMs）在处理多样化的自然语言处理（NLP）任务和多模态任务方面展现出了卓越的泛化能力，能够响应用户的随机查询和特定领域的内容创造需求。相较于传统的图学习模型，LLMs在处理图任务时更具优势，它们省去了训练图学习模型的步骤，同时降低了人工注释的成本。本篇综述深入探讨了LLM在图数据研究领域的应用，概述了先进LLM模型解决的图分析任务，并指出了当前面临的挑战与未来的研究趋势。具体而言，我们聚焦于基于LLM的生成图分析（LLM-GGA）的三大关键议题：基于LLM的图查询处理（LLM-GQP）、基于LLM的图推理与学习（LLM-GIL），以及图与LLM结合的应用场景。LLM-GQP着重于图分析技术与LLM提示的融合，涵盖图理解及基于知识图谱的增强检索；LLM-GIL则专注于图上的学习与推理，包括图学习、图形态推理和图表示。我们归纳了LLM在处理各类图任务时采用的有效提示，并总结了LLM模型的评估方法、基准数据集/任务，并对LLM模型的利弊进行了深入分析。此外，我们还探讨了LLM与图分析这一跨学科研究领域的未解决问题和未来研究方向。

> A graph is a fundamental data model to represent various entities and their complex relationships in society and nature, such as social networks, transportation networks, financial networks, and biomedical systems. Recently, large language models (LLMs) have showcased a strong generalization ability to handle various NLP and multi-mode tasks to answer users' arbitrary questions and specific-domain content generation. Compared with graph learning models, LLMs enjoy superior advantages in addressing the challenges of generalizing graph tasks by eliminating the need for training graph learning models and reducing the cost of manual annotation. In this survey, we conduct a comprehensive investigation of existing LLM studies on graph data, which summarizes the relevant graph analytics tasks solved by advanced LLM models and points out the existing remaining challenges and future directions. Specifically, we study the key problems of LLM-based generative graph analytics (LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP), LLM-based graph inference and learning (LLM-GIL), and graph-LLM-based applications. LLM-GQP focuses on an integration of graph analytics techniques and LLM prompts, including graph understanding and knowledge graph (KG) based augmented retrieval, while LLM-GIL focuses on learning and reasoning over graphs, including graph learning, graph-formed reasoning and graph representation. We summarize the useful prompts incorporated into LLM to handle different graph downstream tasks. Moreover, we give a summary of LLM model evaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM models. We also explore open problems and future directions in this exciting interdisciplinary research area of LLMs and graph analytics.

[Arxiv](https://arxiv.org/abs/2404.14809)