# 大型语言模型能否领会对话中的隐含意义？——以一部中国情景喜剧为例进行探讨

发布时间：2024年04月30日

`分类：LLM应用

这篇论文主要研究了大型语言模型（LLMs）在理解中文对话含义方面的能力，并通过创建一个多轮对话数据集来测试不同LLMs的性能。论文的重点是评估和比较LLMs在特定任务上的表现，这属于LLM应用的范畴。` `对话系统` `人工智能`

> Do Large Language Models Understand Conversational Implicature -- A case study with a chinese sitcom

# 摘要

> 为了让大型语言模型（LLMs）更接近人类的社交沟通能力，理解话语的深层含义极为关键。本研究推出了SwordsmanImp，这是首个专注于中文对话含义的多轮对话数据集，源自中文情景喜剧《我的武林男友》。该数据集精心设计了200个问题，并对违反的格赖斯准则进行了标注。我们对八种封闭源和开源的大型语言模型（LLMs）进行了两项任务测试：多项选择问题和含义解释任务。测试结果显示，GPT-4在多项选择问题上达到了94%的人类水平准确率，而CausalLM紧随其后，准确率为78.5%。其他模型，包括GPT-3.5和一些开源模型，准确率则在20%到60%之间。我们还邀请了人类评估员对LLMs生成的含义解释进行合理性、逻辑性和流畅性评分。尽管所有模型都能生成流畅且一致的文本，但除了GPT-4外，其他模型在合理性上得分较低，表明大多数LLMs还未能提供令人满意的对话含义解释。此外，我们发现LLMs的性能并不因违反的格赖斯准则不同而有显著差异，这暗示LLMs在处理不同准则派生的含义时并没有表现出明显的差异。相关数据和代码已在 https://github.com/sjtu-compling/llm-pragmatics 上公开。

> Understanding the non-literal meaning of an utterance is critical for large language models (LLMs) to become human-like social communicators. In this work, we introduce SwordsmanImp, the first Chinese multi-turn-dialogue-based dataset aimed at conversational implicature, sourced from dialogues in the Chinese sitcom $\textit{My Own Swordsman}$. It includes 200 carefully handcrafted questions, all annotated on which Gricean maxims have been violated. We test eight close-source and open-source LLMs under two tasks: a multiple-choice question task and an implicature explanation task. Our results show that GPT-4 attains human-level accuracy (94%) on multiple-choice questions. CausalLM demonstrates a 78.5% accuracy following GPT-4. Other models, including GPT-3.5 and several open-source models, demonstrate a lower accuracy ranging from 20% to 60% on multiple-choice questions. Human raters were asked to rate the explanation of the implicatures generated by LLMs on their reasonability, logic and fluency. While all models generate largely fluent and self-consistent text, their explanations score low on reasonability except for GPT-4, suggesting that most LLMs cannot produce satisfactory explanations of the implicatures in the conversation. Moreover, we find LLMs' performance does not vary significantly by Gricean maxims, suggesting that LLMs do not seem to process implicatures derived from different maxims differently. Our data and code are available at https://github.com/sjtu-compling/llm-pragmatics.

[Arxiv](https://arxiv.org/abs/2404.19509)