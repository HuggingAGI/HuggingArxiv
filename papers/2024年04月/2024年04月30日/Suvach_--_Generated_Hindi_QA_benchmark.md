# Suvach -- 一个专为印地语设计的问答基准生成器

发布时间：2024年04月30日

`分类：LLM应用` `印度语言处理`

> Suvach -- Generated Hindi QA benchmark

# 摘要

> 现行的印度语言问答评估标准多依赖于将英文数据集进行机器翻译，这种方法存在偏见和翻译不准确的问题，无法真实反映印度语言问答模型的能力。本论文提出了一个新的评估基准，专为印地语问答模型量身定制，并探讨了如何为任何任务设计类似的方法。该方法利用大型语言模型在抽取式问答环境中生成高质量数据集，确保其与目标语言的紧密相关。我们认为，这一新资源将为印地语自然语言处理研究提供更精确、更可靠的评估工具，从而推动该领域的进步。

> Current evaluation benchmarks for question answering (QA) in Indic languages often rely on machine translation of existing English datasets. This approach suffers from bias and inaccuracies inherent in machine translation, leading to datasets that may not reflect the true capabilities of EQA models for Indic languages. This paper proposes a new benchmark specifically designed for evaluating Hindi EQA models and discusses the methodology to do the same for any task. This method leverages large language models (LLMs) to generate a high-quality dataset in an extractive setting, ensuring its relevance for the target language. We believe this new resource will foster advancements in Hindi NLP research by providing a more accurate and reliable evaluation tool.

[Arxiv](https://arxiv.org/abs/2404.19254)