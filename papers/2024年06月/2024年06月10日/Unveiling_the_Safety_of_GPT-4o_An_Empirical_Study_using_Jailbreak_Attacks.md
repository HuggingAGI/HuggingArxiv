# 探究GPT-4o的安全防线：通过越狱攻击进行的实证研究

发布时间：2024年06月10日

`LLM应用

理由：这篇论文主要关注的是GPT-4o模型的安全性评估，特别是在越狱攻击下的表现。它通过实验评估了模型在不同模态（文本、语音和图像）下的安全性，并讨论了模型的弱点和改进方向。虽然涉及到了模型的应用和安全性问题，但并没有深入探讨LLM的理论基础或Agent的设计与实现，也没有特别强调检索增强生成（RAG）技术。因此，将其归类为LLM应用是合适的。` `人工智能安全` `多模态处理`

> Unveiling the Safety of GPT-4o: An Empirical Study using Jailbreak Attacks

# 摘要

> GPT-4o的发布因其卓越的通用能力备受瞩目，但其安全性探讨不足。考虑到其可能产生的风险内容对社会的潜在影响，评估其安全性尤为关键。为此，本文首次深入评估了GPT-4o在越狱攻击下的安全性，采用多模态和单模态攻击，针对文本、语音和图像三种模态的四个常用基准，优化了4,000多个初始查询，并分析了GPT-4o上近8,000个响应。实验结果显示：GPT-4o在文本模态的安全性较前版本有所提升；新加入的音频模态为越狱攻击提供了新途径；现有黑盒多模态攻击对GPT-4o和GPT-4V效果不佳。这些发现强调了大型模型中对齐护栏的重要性，并提供了GPT-4o安全性的关键见解。相关代码已公开于\url{https://github.com/NY1024/Jailbreak_GPT4o}。

> The recent release of GPT-4o has garnered widespread attention due to its powerful general capabilities. While its impressive performance is widely acknowledged, its safety aspects have not been sufficiently explored. Given the potential societal impact of risky content generated by advanced generative AI such as GPT-4o, it is crucial to rigorously evaluate its safety. In response to this question, this paper for the first time conducts a rigorous evaluation of GPT-4o against jailbreak attacks. Specifically, this paper adopts a series of multi-modal and uni-modal jailbreak attacks on 4 commonly used benchmarks encompassing three modalities (\ie, text, speech, and image), which involves the optimization of over 4,000 initial text queries and the analysis and statistical evaluation of nearly 8,000+ response on GPT-4o. Our extensive experiments reveal several novel observations: (1) In contrast to the previous version (such as GPT-4V), GPT-4o has enhanced safety in the context of text modality jailbreak; (2) The newly introduced audio modality opens up new attack vectors for jailbreak attacks on GPT-4o; (3) Existing black-box multimodal jailbreak attack methods are largely ineffective against GPT-4o and GPT-4V. These findings provide critical insights into the safety implications of GPT-4o and underscore the need for robust alignment guardrails in large models. Our code is available at \url{https://github.com/NY1024/Jailbreak_GPT4o}.

![探究GPT-4o的安全防线：通过越狱攻击进行的实证研究](../../../paper_images/2406.06302/x1.png)

![探究GPT-4o的安全防线：通过越狱攻击进行的实证研究](../../../paper_images/2406.06302/x2.png)

![探究GPT-4o的安全防线：通过越狱攻击进行的实证研究](../../../paper_images/2406.06302/x3.png)

![探究GPT-4o的安全防线：通过越狱攻击进行的实证研究](../../../paper_images/2406.06302/x4.png)

![探究GPT-4o的安全防线：通过越狱攻击进行的实证研究](../../../paper_images/2406.06302/x5.png)

![探究GPT-4o的安全防线：通过越狱攻击进行的实证研究](../../../paper_images/2406.06302/x6.png)

[Arxiv](https://arxiv.org/abs/2406.06302)