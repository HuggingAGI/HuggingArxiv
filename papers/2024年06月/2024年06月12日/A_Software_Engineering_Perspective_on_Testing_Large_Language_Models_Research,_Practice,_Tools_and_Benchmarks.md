# 软件工程视角下的大型语言模型测试：探索研究、实践、工具与基准的融合之道

发布时间：2024年06月12日

`LLM应用

这篇论文主要关注大型语言模型（LLMs）的测试和安全性问题，特别是在软件工程领域的应用。它提出了一套LLM测试主题的分类体系，并评估了当前的研究进展、开源工具及基准。虽然涉及到了一些理论性的探讨，如分类体系的建立，但其核心目的是为了确保LLMs在未来的高风险或安全关键系统中的安全使用，这更偏向于应用层面。因此，将其归类为LLM应用是合适的。` `软件工程` `机器学习`

> A Software Engineering Perspective on Testing Large Language Models: Research, Practice, Tools and Benchmarks

# 摘要

> 大型语言模型（LLMs）正迅速成为无处不在的存在，既是独立工具，也是软件系统的重要组成部分。为了确保这些模型能在2030年的高风险或安全关键系统中安全使用，它们必须接受严格测试。软件工程（SE）领域对机器学习（ML）组件及其系统的测试研究已深入探讨了多个方面，包括测试输入生成和系统鲁棒性。我们认为，有关LLM测试的工具、基准、研究见解及实践者观点应得到系统化整理。为此，我们提出了一套LLM测试主题的分类体系，并开展了初步研究，评估了当前的研究进展、开源工具及基准，将研究成果与该分类体系相对应。我们的目标在于揭示研究与工程上的空白，激发LLM实践者与SE研究界之间的深入对话。

> Large Language Models (LLMs) are rapidly becoming ubiquitous both as stand-alone tools and as components of current and future software systems. To enable usage of LLMs in the high-stake or safety-critical systems of 2030, they need to undergo rigorous testing. Software Engineering (SE) research on testing Machine Learning (ML) components and ML-based systems has systematically explored many topics such as test input generation and robustness. We believe knowledge about tools, benchmarks, research and practitioner views related to LLM testing needs to be similarly organized. To this end, we present a taxonomy of LLM testing topics and conduct preliminary studies of state of the art and practice approaches to research, open-source tools and benchmarks for LLM testing, mapping results onto this taxonomy. Our goal is to identify gaps requiring more research and engineering effort and inspire a clearer communication between LLM practitioners and the SE research community.

[Arxiv](https://arxiv.org/abs/2406.08216)