# LLM作为评分者：探讨输出顺序如何影响对话评估

发布时间：2024年06月04日

`LLM应用

这篇论文的摘要讨论了如何通过提示设计来优化大型语言模型（LLMs）在对话评估中的应用。研究关注的是提示设计对LLMs性能的影响，特别是在对话评估这一特定应用场景中。这表明论文主要关注的是LLMs的实际应用，即如何通过改进提示设计来提高LLMs在特定任务（对话评估）中的表现。因此，这篇论文应归类于LLM应用。` `对话评估` `语言模型`

> LLM as a Scorer: The Impact of Output Order on Dialogue Evaluation

# 摘要

> 本研究深入分析了提示设计如何影响大型语言模型（LLMs）在对话评估中的应用。尽管LLMs在评分任务中日益普及，但设计出既能适应模型敏感性又能反映对话评估主观性的有效提示仍是一大挑战。我们的实验通过调整输出指令的顺序并加入解释性内容，探索了不同提示结构的效果。结果显示，采用“理由优先”的提示方式能显著提升LLMs的评估全面性，这对于优化基于LLM的评估系统的准确性和一致性具有重要意义。

> This research investigates the effect of prompt design on dialogue evaluation using large language models (LLMs). While LLMs are increasingly used for scoring various inputs, creating effective prompts for dialogue evaluation remains challenging due to model sensitivity and subjectivity in dialogue assessments. Our study experimented with different prompt structures, altering the sequence of output instructions and including explanatory reasons. We found that the order of presenting reasons and scores significantly influences LLMs' scoring, with a "reason-first" approach yielding more comprehensive evaluations. This insight is crucial for enhancing the accuracy and consistency of LLM-based evaluations.

![LLM作为评分者：探讨输出顺序如何影响对话评估](../../../paper_images/2406.02863/x1.png)

![LLM作为评分者：探讨输出顺序如何影响对话评估](../../../paper_images/2406.02863/x2.png)

![LLM作为评分者：探讨输出顺序如何影响对话评估](../../../paper_images/2406.02863/x3.png)

![LLM作为评分者：探讨输出顺序如何影响对话评估](../../../paper_images/2406.02863/x4.png)

![LLM作为评分者：探讨输出顺序如何影响对话评估](../../../paper_images/2406.02863/x5.png)

![LLM作为评分者：探讨输出顺序如何影响对话评估](../../../paper_images/2406.02863/x6.png)

![LLM作为评分者：探讨输出顺序如何影响对话评估](../../../paper_images/2406.02863/x7.png)

![LLM作为评分者：探讨输出顺序如何影响对话评估](../../../paper_images/2406.02863/x8.png)

[Arxiv](https://arxiv.org/abs/2406.02863)