# 科学大型语言模型综述：探索其在科学发现中的应用潜力

发布时间：2024年06月16日

`LLM应用

这篇论文摘要讨论了大型语言模型（LLMs）在科学领域的应用，包括它们如何处理不同类型的数据（如分子、蛋白质）以及它们在科学探索中的作用。文章通过分析超过250个科学LLMs，探讨了这些模型在不同科学领域中的共性和差异，并总结了预训练数据集与评估任务。此外，论文还探讨了LLMs如何被实际应用以助力科学发现。这些内容主要关注LLMs的实际应用和效果，因此适合归类为LLM应用。` `科学研究` `数据处理`

> A Comprehensive Survey of Scientific Large Language Models and Their Applications in Scientific Discovery

# 摘要

> 大型语言模型（LLMs）在众多科学领域中，不仅革新了处理文本及多种数据（如分子、蛋白质）的方式，更在多样的应用中展现了卓越性能，极大地推动了科学探索的进程。尽管如此，以往对科学LLMs的研究综述多局限于特定领域或单一数据模式。本文旨在通过揭示LLMs在不同科学领域间的架构与预训练技术的联系，提供一个更为全面的科研视角。我们深入分析了超过250个科学LLMs，探讨其共性与差异，并针对各领域和模态，总结了预训练数据集与评估任务。此外，我们还探究了LLMs如何被实际应用以助力科学发现。相关资源详见https://github.com/yuzhimanhua/Awesome-Scientific-Language-Models。

> In many scientific fields, large language models (LLMs) have revolutionized the way with which text and other modalities of data (e.g., molecules and proteins) are dealt, achieving superior performance in various applications and augmenting the scientific discovery process. Nevertheless, previous surveys on scientific LLMs often concentrate on one to two fields or a single modality. In this paper, we aim to provide a more holistic view of the research landscape by unveiling cross-field and cross-modal connections between scientific LLMs regarding their architectures and pre-training techniques. To this end, we comprehensively survey over 250 scientific LLMs, discuss their commonalities and differences, as well as summarize pre-training datasets and evaluation tasks for each field and modality. Moreover, we investigate how LLMs have been deployed to benefit scientific discovery. Resources related to this survey are available at https://github.com/yuzhimanhua/Awesome-Scientific-Language-Models.

![科学大型语言模型综述：探索其在科学发现中的应用潜力](../../../paper_images/2406.10833/x1.png)

[Arxiv](https://arxiv.org/abs/2406.10833)