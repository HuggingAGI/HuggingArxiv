# 从大型语言模型到多模态大型语言模型：揭秘多模态系统的解锁之旅

发布时间：2024年06月21日

`Agent

这篇论文主要关注的是针对大型语言模型（LLMs）和多模态大型语言模型（MLLMs）的对抗攻击，特别是越狱研究。它探讨了评估基准、攻击手段及防御策略，并指出了多模态领域的研究局限和未来的研究方向。虽然涉及到了LLMs和MLLMs的应用和安全性，但其核心在于探讨如何攻击和防御这些模型，这更偏向于Agent的范畴，即研究如何通过设计或改进模型来应对外部攻击，增强模型的鲁棒性和安全性。因此，将其归类为Agent更为合适。` `人工智能安全` `多模态学习`

> From LLMs to MLLMs: Exploring the Landscape of Multimodal Jailbreaking

# 摘要

> 随着LLMs和MLLMs的迅猛发展，它们对多种对抗攻击的脆弱性也日益显现。本文深入探讨了针对这些模型的越狱研究，突出了评估基准、攻击手段及防御策略的最新成就。尽管单模态越狱研究已相对成熟，多模态领域仍是一片待开发的沃土。我们梳理了多模态越狱研究的局限，并展望了未来的研究方向，以期推动MLLMs在鲁棒性和安全性上的进一步提升。

> The rapid development of Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs) has exposed vulnerabilities to various adversarial attacks. This paper provides a comprehensive overview of jailbreaking research targeting both LLMs and MLLMs, highlighting recent advancements in evaluation benchmarks, attack techniques and defense strategies. Compared to the more advanced state of unimodal jailbreaking, multimodal domain remains underexplored. We summarize the limitations and potential research directions of multimodal jailbreaking, aiming to inspire future research and further enhance the robustness and security of MLLMs.

![从大型语言模型到多模态大型语言模型：揭秘多模态系统的解锁之旅](../../../paper_images/2406.14859/x1.png)

![从大型语言模型到多模态大型语言模型：揭秘多模态系统的解锁之旅](../../../paper_images/2406.14859/x2.png)

[Arxiv](https://arxiv.org/abs/2406.14859)