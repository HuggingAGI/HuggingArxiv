# 利用多任务指令微调提升代码漏洞检测的泛化能力

发布时间：2024年06月05日

`LLM应用

理由：这篇论文介绍了一个名为VulLLM的创新框架，该框架结合了多任务学习和大型语言模型（LLMs）来深入挖掘软件漏洞的本质特征。它通过特定的辅助任务和生成式LLMs来提升漏洞检测的准确性和理解漏洞的根本原因。这种方法直接应用于实际的漏洞检测问题，因此属于LLM应用类别。` `软件安全` `漏洞检测`

> Generalization-Enhanced Code Vulnerability Detection via Multi-Task Instruction Fine-Tuning

# 摘要

> 近年来，基于代码预训练模型（CodePTMs）的漏洞检测取得了显著成效，但这些模型在泛化上遇到难题，因为它们往往只学习了源代码与标签间的表面联系，而非深入理解漏洞的根源。为此，我们推出了VulLLM，这一创新框架结合了多任务学习与大型语言模型（LLMs），旨在深入挖掘漏洞的本质特征。我们特别设计了两个辅助任务：一是通过漏洞补丁进行漏洞定位；二是利用GPT-4基于补丁提取的特征进行漏洞解释。VulLLM通过生成式LLMs深入解析复杂漏洞模式，不仅提升了漏洞分类的准确性，还促使模型专注于捕捉漏洞的根本原因，而非单一任务的表面特征。实验结果显示，VulLLM在六个大型数据集上的表现优于七个顶尖模型，展现出卓越的有效性、泛化能力和鲁棒性。

> Code Pre-trained Models (CodePTMs) based vulnerability detection have achieved promising results over recent years. However, these models struggle to generalize as they typically learn superficial mapping from source code to labels instead of understanding the root causes of code vulnerabilities, resulting in poor performance in real-world scenarios beyond the training instances. To tackle this challenge, we introduce VulLLM, a novel framework that integrates multi-task learning with Large Language Models (LLMs) to effectively mine deep-seated vulnerability features. Specifically, we construct two auxiliary tasks beyond the vulnerability detection task. First, we utilize the vulnerability patches to construct a vulnerability localization task. Second, based on the vulnerability features extracted from patches, we leverage GPT-4 to construct a vulnerability interpretation task. VulLLM innovatively augments vulnerability classification by leveraging generative LLMs to understand complex vulnerability patterns, thus compelling the model to capture the root causes of vulnerabilities rather than overfitting to spurious features of a single task. The experiments conducted on six large datasets demonstrate that VulLLM surpasses seven state-of-the-art models in terms of effectiveness, generalization, and robustness.

[Arxiv](https://arxiv.org/abs/2406.03718)