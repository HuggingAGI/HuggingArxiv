# 利用多任务指令微调提升代码漏洞检测的泛化能力

发布时间：2024年06月05日

`LLM应用

理由：这篇论文介绍了一个名为VulLLM的框架，它利用大型语言模型（LLMs）和多任务学习来深入理解代码漏洞的本质特征，并提高了漏洞检测的准确性。这个框架是针对特定应用场景（代码漏洞检测）开发的，因此属于LLM应用类别。论文中提到的使用GPT-4解析补丁中的漏洞特征，以及通过生成式LLMs深入理解漏洞模式，都是将LLM技术应用于实际问题解决的例子。` `软件安全` `漏洞检测`

> Generalization-Enhanced Code Vulnerability Detection via Multi-Task Instruction Fine-Tuning

# 摘要

> 基于CodePTMs的漏洞检测近年来成果斐然，但这些模型在泛化上遇到难题，因为它们往往只学习代码到标签的表面映射，而非洞悉漏洞的根源。为此，我们推出了VulLLM框架，它巧妙融合了多任务学习与LLMs，深入挖掘漏洞的本质特征。我们额外设计了两个任务：一是通过漏洞补丁进行定位，二是利用GPT-4解析补丁中的漏洞特征。VulLLM通过生成式LLMs深入理解漏洞模式，不仅提升了分类准确性，更让模型聚焦于漏洞的真正原因，而非单一任务的表面特征。实验结果显示，VulLLM在多个维度上超越了现有顶尖模型。

> Code Pre-trained Models (CodePTMs) based vulnerability detection have achieved promising results over recent years. However, these models struggle to generalize as they typically learn superficial mapping from source code to labels instead of understanding the root causes of code vulnerabilities, resulting in poor performance in real-world scenarios beyond the training instances. To tackle this challenge, we introduce VulLLM, a novel framework that integrates multi-task learning with Large Language Models (LLMs) to effectively mine deep-seated vulnerability features. Specifically, we construct two auxiliary tasks beyond the vulnerability detection task. First, we utilize the vulnerability patches to construct a vulnerability localization task. Second, based on the vulnerability features extracted from patches, we leverage GPT-4 to construct a vulnerability interpretation task. VulLLM innovatively augments vulnerability classification by leveraging generative LLMs to understand complex vulnerability patterns, thus compelling the model to capture the root causes of vulnerabilities rather than overfitting to spurious features of a single task. The experiments conducted on six large datasets demonstrate that VulLLM surpasses seven state-of-the-art models in terms of effectiveness, generalization, and robustness.

[Arxiv](https://arxiv.org/abs/2406.03718)