# 视觉与文本的精准对齐：优化视觉-语言模型中的相似度评分

发布时间：2024年06月05日

`RAG

理由：这篇论文主要关注的是视觉-语言模型的改进，特别是通过加权视觉-文本交叉对齐（WCA）方法来提升零-shot性能。这种方法涉及到对图像的局部区域与文本描述的对齐，以及基于加权相似度的评分函数的设计。这些内容更接近于RAG（Retrieval-Augmented Generation）的范畴，即通过检索增强生成过程，以提高模型的性能和准确性。虽然这种方法可能涉及到大型语言模型的应用，但其核心贡献在于提出了一个新的对齐和评分机制，这更符合RAG的研究方向。` `计算机视觉`

> Visual-Text Cross Alignment: Refining the Similarity Score in Vision-Language Models

# 摘要

> 最近研究表明，通过预训练的视觉-语言模型（如CLIP）将查询图像与大型语言模型生成的精细文本描述对齐，能大幅提升零-shot性能。但本文实证指出，这些描述更倾向于与图像的局部区域而非整体对齐，并通过理论分析证实了这一点。为此，我们提出了加权视觉-文本交叉对齐（WCA）方法，首先利用局部视觉提示技术定位图像中的关键区域，再通过预训练VLM构建相似度矩阵，实现这些区域与文本的精准对齐。我们进一步设计了一个基于加权相似度的评分函数，以评估图像与各类别的匹配度。实验结果显示，WCA方法在多个数据集上显著提升了零-shot性能，效果甚至媲美少-shot学习方法。

> It has recently been discovered that using a pre-trained vision-language model (VLM), e.g., CLIP, to align a whole query image with several finer text descriptions generated by a large language model can significantly enhance zero-shot performance. However, in this paper, we empirically find that the finer descriptions tend to align more effectively with local areas of the query image rather than the whole image, and then we theoretically validate this finding. Thus, we present a method called weighted visual-text cross alignment (WCA). This method begins with a localized visual prompting technique, designed to identify local visual areas within the query image. The local visual areas are then cross-aligned with the finer descriptions by creating a similarity matrix using the pre-trained VLM. To determine how well a query image aligns with each category, we develop a score function based on the weighted similarities in this matrix. Extensive experiments demonstrate that our method significantly improves zero-shot performance across various datasets, achieving results that are even comparable to few-shot learning methods.

![视觉与文本的精准对齐：优化视觉-语言模型中的相似度评分](../../../paper_images/2406.02915/x1.png)

![视觉与文本的精准对齐：优化视觉-语言模型中的相似度评分](../../../paper_images/2406.02915/x2.png)

![视觉与文本的精准对齐：优化视觉-语言模型中的相似度评分](../../../paper_images/2406.02915/x3.png)

![视觉与文本的精准对齐：优化视觉-语言模型中的相似度评分](../../../paper_images/2406.02915/x4.png)

![视觉与文本的精准对齐：优化视觉-语言模型中的相似度评分](../../../paper_images/2406.02915/x5.png)

![视觉与文本的精准对齐：优化视觉-语言模型中的相似度评分](../../../paper_images/2406.02915/x6.png)

![视觉与文本的精准对齐：优化视觉-语言模型中的相似度评分](../../../paper_images/2406.02915/x7.png)

![视觉与文本的精准对齐：优化视觉-语言模型中的相似度评分](../../../paper_images/2406.02915/x9.png)

![视觉与文本的精准对齐：优化视觉-语言模型中的相似度评分](../../../paper_images/2406.02915/x10.png)

![视觉与文本的精准对齐：优化视觉-语言模型中的相似度评分](../../../paper_images/2406.02915/x11.png)

![视觉与文本的精准对齐：优化视觉-语言模型中的相似度评分](../../../paper_images/2406.02915/x12.png)

![视觉与文本的精准对齐：优化视觉-语言模型中的相似度评分](../../../paper_images/2406.02915/x13.png)

![视觉与文本的精准对齐：优化视觉-语言模型中的相似度评分](../../../paper_images/2406.02915/eurosat_overview_small.jpg)

![视觉与文本的精准对齐：优化视觉-语言模型中的相似度评分](../../../paper_images/2406.02915/x14.png)

[Arxiv](https://arxiv.org/abs/2406.02915)