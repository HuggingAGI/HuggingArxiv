# 从泰山到托尔金：驾驭大型语言模型，定制内容生成的语言熟练度

发布时间：2024年06月05日

`LLM应用

这篇论文探讨了如何调整大型语言模型（LLMs）生成的文本难度，以适应语言学习者等非完全熟练用户的需求。研究涉及了多种方法，包括少量样本提示、监督微调及强化学习，并评估了这些方法在GPT-4及开源模型上的效果。最终，通过融合微调与强化学习对齐策略，开发出了CALM模型，该模型在成本效益和性能上都表现出色。这一研究直接应用于改进LLM以更好地服务于特定用户群体，因此属于LLM应用类别。` `语言学习` `教育技术`

> From Tarzan to Tolkien: Controlling the Language Proficiency Level of LLMs for Content Generation

# 摘要

> 我们探讨了如何调整大型语言模型（LLMs）生成的文本难度，以适应语言学习者等非完全熟练用户的需求。通过创新框架，我们评估了包括少量样本提示、监督微调及强化学习在内的多种方法的效果，涉及GPT-4及开源模型如LLama2-7B和Mistral-7B。研究发现，基于提示的策略下，GPT-4与开源模型性能差距显著。但我们通过巧妙融合微调与RL对齐，成功缩小了这一差距。我们的CALM模型（CEFR对齐语言模型）不仅成本低廉，更超越了GPT-4及其他方法的性能，并通过小规模人类研究验证了其卓越质量。

> We study the problem of controlling the difficulty level of text generated by Large Language Models (LLMs) for contexts where end-users are not fully proficient, such as language learners. Using a novel framework, we evaluate the effectiveness of several key approaches for this task, including few-shot prompting, supervised finetuning, and reinforcement learning (RL), utilising both GPT-4 and open source alternatives like LLama2-7B and Mistral-7B.
  Our findings reveal a large performance gap between GPT-4 and the open source models when using prompt-based strategies. However, we show how to bridge this gap with a careful combination of finetuning and RL alignment. Our best model, CALM (CEFR-Aligned Language Model), surpasses the performance of GPT-4 and other strategies, at only a fraction of the cost. We further validate the quality of our results through a small-scale human study.

![从泰山到托尔金：驾驭大型语言模型，定制内容生成的语言熟练度](../../../paper_images/2406.03030/gen_hists.png)

![从泰山到托尔金：驾驭大型语言模型，定制内容生成的语言熟练度](../../../paper_images/2406.03030/readability_metrics.png)

![从泰山到托尔金：驾驭大型语言模型，定制内容生成的语言熟练度](../../../paper_images/2406.03030/x1.png)

![从泰山到托尔金：驾驭大型语言模型，定制内容生成的语言熟练度](../../../paper_images/2406.03030/prof_human.png)

![从泰山到托尔金：驾驭大型语言模型，定制内容生成的语言熟练度](../../../paper_images/2406.03030/x2.png)

![从泰山到托尔金：驾驭大型语言模型，定制内容生成的语言熟练度](../../../paper_images/2406.03030/x3.png)

[Arxiv](https://arxiv.org/abs/2406.03030)