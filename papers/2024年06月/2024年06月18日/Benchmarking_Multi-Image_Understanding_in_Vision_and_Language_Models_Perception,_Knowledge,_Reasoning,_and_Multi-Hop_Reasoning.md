# 视觉与语言模型中的多图像理解基准：从感知到知识，再到推理与多跳推理的全面评估

发布时间：2024年06月18日

`LLM应用

理由：这篇论文主要关注的是多模态大型语言模型（LLMs）在处理视觉数据，特别是多图像理解方面的应用。它提出了一个新的评估基准（MIRB）来测试和推动视觉语言模型（VLMs）在多图像推理能力上的发展。这与LLM的应用直接相关，特别是在多模态理解和处理方面，因此归类为LLM应用。` `计算机视觉` `人工智能`

> Benchmarking Multi-Image Understanding in Vision and Language Models: Perception, Knowledge, Reasoning, and Multi-Hop Reasoning

# 摘要

> 随着大型语言模型（LLMs）技术的进步，自然语言处理的应用领域得到了极大的拓展，尤其是多模态LLMs，它们能够处理和解析视觉数据。然而，当前的视觉语言模型（VLMs）评估标准主要关注单图像输入，忽略了多图像理解的重要性。为此，我们推出了Multi-Image Relational Benchmark（MIRB），专门用于测试VLMs在多图像间的比较、分析及推理能力。MIRB包含感知、视觉知识、推理和多跳推理四个评估类别。通过广泛测试多种开源和闭源模型，我们发现，虽然开源VLMs在单图像任务上已接近GPT-4V的水平，但在多图像推理方面仍有明显差距。研究还显示，即便是最尖端的GPT-4V模型，在MIRB上也显露出挑战，这表明该领域亟需更多研究与创新。我们期望MIRB能成为推动下一代多模态模型发展的关键测试平台。

> The advancement of large language models (LLMs) has significantly broadened the scope of applications in natural language processing, with multi-modal LLMs extending these capabilities to integrate and interpret visual data. However, existing benchmarks for visual language models (VLMs) predominantly focus on single-image inputs, neglecting the crucial aspect of multi-image understanding. In this paper, we introduce a Multi-Image Relational Benchmark MIRB, designed to evaluate VLMs' ability to compare, analyze, and reason across multiple images. Our benchmark encompasses four categories: perception, visual world knowledge, reasoning, and multi-hop reasoning. Through a comprehensive evaluation of a wide range of open-source and closed-source models, we demonstrate that while open-source VLMs were shown to approach the performance of GPT-4V in single-image tasks, a significant performance gap remains in multi-image reasoning tasks. Our findings also reveal that even the state-of-the-art GPT-4V model struggles with our benchmark, underscoring the need for further research and development in this area. We believe our contribution of MIRB could serve as a testbed for developing the next-generation multi-modal models.

![视觉与语言模型中的多图像理解基准：从感知到知识，再到推理与多跳推理的全面评估](../../../paper_images/2406.12742/x1.png)

![视觉与语言模型中的多图像理解基准：从感知到知识，再到推理与多跳推理的全面评估](../../../paper_images/2406.12742/x2.png)

![视觉与语言模型中的多图像理解基准：从感知到知识，再到推理与多跳推理的全面评估](../../../paper_images/2406.12742/x3.png)

![视觉与语言模型中的多图像理解基准：从感知到知识，再到推理与多跳推理的全面评估](../../../paper_images/2406.12742/x4.png)

![视觉与语言模型中的多图像理解基准：从感知到知识，再到推理与多跳推理的全面评估](../../../paper_images/2406.12742/x5.png)

![视觉与语言模型中的多图像理解基准：从感知到知识，再到推理与多跳推理的全面评估](../../../paper_images/2406.12742/x6.png)

![视觉与语言模型中的多图像理解基准：从感知到知识，再到推理与多跳推理的全面评估](../../../paper_images/2406.12742/x7.png)

![视觉与语言模型中的多图像理解基准：从感知到知识，再到推理与多跳推理的全面评估](../../../paper_images/2406.12742/x8.png)

[Arxiv](https://arxiv.org/abs/2406.12742)