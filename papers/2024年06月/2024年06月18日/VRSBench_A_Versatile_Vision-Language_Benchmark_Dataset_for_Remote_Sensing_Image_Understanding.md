# VRSBench：遥感图像理解的多元化视觉-语言基准数据集

发布时间：2024年06月18日

`LLM应用

理由：这篇论文介绍了一个新的视觉-语言基准VRSBench，专门设计用于远程传感图像，以推动大规模模型的进步。它包含了大量的图像、对象引用和问答对，用于支持多种远程传感图像理解任务的模型训练与评估。这表明该论文是在应用层面上探讨如何利用大规模模型（如LLM）来解决具体的视觉-语言任务，因此属于LLM应用类别。` `视觉-语言模型`

> VRSBench: A Versatile Vision-Language Benchmark Dataset for Remote Sensing Image Understanding

# 摘要

> 我们推出VRSBench，一个专为远程传感图像设计的全新视觉-语言基准，旨在推动通用大规模模型的进步，弥补现有数据集在任务针对性、对象信息详尽度和质量控制上的不足。VRSBench包含近3万张图像，每张都有人工验证的详细描述，超过5万个对象引用，以及12万对问答，全面支持多种远程传感图像理解任务的模型训练与评估。我们还在此基准上对图像描述、视觉定位和视觉问答三个任务的顶尖模型进行了评估，旨在为远程传感领域的高级视觉-语言模型发展做出重要贡献。相关数据和代码已公开于https://github.com/lx709/VRSBench。

> We introduce a new benchmark designed to advance the development of general-purpose, large-scale vision-language models for remote sensing images. Although several vision-language datasets in remote sensing have been proposed to pursue this goal, existing datasets are typically tailored to single tasks, lack detailed object information, or suffer from inadequate quality control. Exploring these improvement opportunities, we present a Versatile vision-language Benchmark for Remote Sensing image understanding, termed VRSBench. This benchmark comprises 29,614 images, with 29,614 human-verified detailed captions, 52,472 object references, and 123,221 question-answer pairs. It facilitates the training and evaluation of vision-language models across a broad spectrum of remote sensing image understanding tasks. We further evaluated state-of-the-art models on this benchmark for three vision-language tasks: image captioning, visual grounding, and visual question answering. Our work aims to significantly contribute to the development of advanced vision-language models in the field of remote sensing. The data and code can be accessed at https://github.com/lx709/VRSBench.

![VRSBench：遥感图像理解的多元化视觉-语言基准数据集](../../../paper_images/2406.12384/x1.png)

![VRSBench：遥感图像理解的多元化视觉-语言基准数据集](../../../paper_images/2406.12384/x2.png)

![VRSBench：遥感图像理解的多元化视觉-语言基准数据集](../../../paper_images/2406.12384/cap_word_length.png)

![VRSBench：遥感图像理解的多元化视觉-语言基准数据集](../../../paper_images/2406.12384/cap_sentence_number.png)

![VRSBench：遥感图像理解的多元化视觉-语言基准数据集](../../../paper_images/2406.12384/ref_stats.png)

![VRSBench：遥感图像理解的多元化视觉-语言基准数据集](../../../paper_images/2406.12384/qa_stats.png)

![VRSBench：遥感图像理解的多元化视觉-语言基准数据集](../../../paper_images/2406.12384/x3.png)

![VRSBench：遥感图像理解的多元化视觉-语言基准数据集](../../../paper_images/2406.12384/x4.png)

![VRSBench：遥感图像理解的多元化视觉-语言基准数据集](../../../paper_images/2406.12384/08184_0000.png)

![VRSBench：遥感图像理解的多元化视觉-语言基准数据集](../../../paper_images/2406.12384/11276_0000.png)

![VRSBench：遥感图像理解的多元化视觉-语言基准数据集](../../../paper_images/2406.12384/05924_0000.png)

![VRSBench：遥感图像理解的多元化视觉-语言基准数据集](../../../paper_images/2406.12384/09322_0000.png)

![VRSBench：遥感图像理解的多元化视觉-语言基准数据集](../../../paper_images/2406.12384/P0974_0001.png)

![VRSBench：遥感图像理解的多元化视觉-语言基准数据集](../../../paper_images/2406.12384/P1273_0002.png)

![VRSBench：遥感图像理解的多元化视觉-语言基准数据集](../../../paper_images/2406.12384/07892_0000.png)

![VRSBench：遥感图像理解的多元化视觉-语言基准数据集](../../../paper_images/2406.12384/P2645_0011.png)

![VRSBench：遥感图像理解的多元化视觉-语言基准数据集](../../../paper_images/2406.12384/x5.png)

![VRSBench：遥感图像理解的多元化视觉-语言基准数据集](../../../paper_images/2406.12384/x6.png)

![VRSBench：遥感图像理解的多元化视觉-语言基准数据集](../../../paper_images/2406.12384/x7.png)

[Arxiv](https://arxiv.org/abs/2406.12384)