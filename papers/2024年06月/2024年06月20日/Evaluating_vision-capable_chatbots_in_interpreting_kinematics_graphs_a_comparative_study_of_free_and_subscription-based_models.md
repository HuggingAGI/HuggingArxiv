# 探究视觉聊天机器人在解析运动学图表上的能力：自由与订阅模式下的对比分析

发布时间：2024年06月20日

`LLM应用

这篇论文主要探讨了基于大型多模态模型的聊天机器人在特定测试（TUG-K）上的表现，特别是在STEM和医学领域的图表理解能力。研究评估了多种聊天机器人，并分析了它们在不同类型任务上的表现差异。这属于对大型语言模型（LLM）在特定应用场景下的实际表现和效能的研究，因此归类为LLM应用。`

> Evaluating vision-capable chatbots in interpreting kinematics graphs: a comparative study of free and subscription-based models

# 摘要

> 本研究探讨了八款基于大型多模态模型的聊天机器人在运动学图理解测试（TUG-K）上的表现，该测试是针对STEM和医学领域图表理解的研究工具。我们评估了包括免费版（如Gemini 1.0 Pro, Claude 3 Sonnet, Microsoft Copilot, ChatGPT-4o）和订阅版（如Gemini 1.0 Ultra, Gemini 1.5 Pro API, Claude 3 Opus, ChatGPT-4）在内的多种聊天机器人。结果显示，OpenAI的聊天机器人表现最佳，尤其是ChatGPT-4o。令人意外的是，Gemini和Claude 3的免费与订阅版本在整体表现上并无显著差异，仅Gemini 1.5 Pro API版例外。此外，研究发现，依赖语言输入的任务对聊天机器人来说相对容易，而视觉解释任务则更具挑战。此研究为LMM基础的聊天机器人在教育和医学领域的应用提供了参考，并为未来的研究指明了方向。

> This study investigates the performance of eight large multimodal model (LMM)-based chatbots on the Test of Understanding Graphs in Kinematics (TUG-K), a research-based concept inventory. Graphs are a widely used representation in STEM and medical fields, making them a relevant topic for exploring LMM-based chatbots' visual interpretation abilities. We evaluated both freely available chatbots (Gemini 1.0 Pro, Claude 3 Sonnet, Microsoft Copilot, and ChatGPT-4o) and subscription-based ones (Gemini 1.0 Ultra, Gemini 1.5 Pro API, Claude 3 Opus, and ChatGPT-4). We found that OpenAI's chatbots outperform all the others, with ChatGPT-4o showing the overall best performance. Contrary to expectations, we found no notable differences in the overall performance between freely available and subscription-based versions of Gemini and Claude 3 chatbots, with the exception of Gemini 1.5 Pro, available via API. In addition, we found that tasks relying more heavily on linguistic input were generally easier for chatbots than those requiring visual interpretation. The study provides a basis for considerations of LMM-based chatbot applications in STEM and medical education, and suggests directions for future research.

[Arxiv](https://arxiv.org/abs/2406.14685)