# “你懂罗马尼亚语吗？” 本指南教你如何利用英语指令，培育出强大的罗马尼亚语大型语言模型。

发布时间：2024年06月26日

`LLM应用

这篇论文主要介绍了为罗马尼亚语量身打造并发布开源的大型语言模型（LLMs），并通过多个领域的测试验证了其效果。这属于在特定语言环境下应用LLM技术的实例，因此归类为LLM应用。` `语言模型`

> "Vorbeşti Româneşte?" A Recipe to Train Powerful Romanian LLMs with English Instructions

# 摘要

> 近年来，大型语言模型（LLMs）在多任务处理上几乎与人类媲美。尽管部分模型接受了多语言训练，但英文数据仍占主导，使得它们在英文上的表现尤为突出。我们是首个为罗马尼亚语量身打造并发布开源LLMs的团队，通过收集、翻译大量文本及基准，并进行训练与评估。我们的方法在学术、MT-Bench（人工翻译）及专业定制的罗马尼亚历史、文化、社会基准等四个领域得到验证。我们通过全面取得顶尖成果，证明了RoLLMs的高效与优越。所有相关资源（包括数据、代码、模型）均已公开，旨在推动罗马尼亚语LLMs的研究，并为其他资源匮乏的语言提供通用方案。

> In recent years, Large Language Models (LLMs) have achieved almost human-like performance on various tasks. While some LLMs have been trained on multilingual data, most of the training data is in English; hence, their performance in English greatly exceeds other languages. To our knowledge, we are the first to collect and translate a large collection of texts, instructions, and benchmarks and train, evaluate, and release open-source LLMs tailored for Romanian. We evaluate our methods on four different categories, including academic benchmarks, MT-Bench (manually translated), and a professionally built historical, cultural, and social benchmark adapted to Romanian. We argue for the usefulness and high performance of RoLLMs by obtaining state-of-the-art results across the board. We publicly release all resources (i.e., data, training and evaluation code, models) to support and encourage research on Romanian LLMs while concurrently creating a generalizable recipe, adequate for other low or less-resourced languages.

[Arxiv](https://arxiv.org/abs/2406.18266)