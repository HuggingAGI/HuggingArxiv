# 2024年06月

2024年06月07日

- [3D-GRAND: Towards Better Grounding and Less Hallucination for 3D-LLMs](2024年06月07日/3D-GRAND_Towards_Better_Grounding_and_Less_Hallucination_for_3D-LLMs.md)

    - [翻译: 3D-GRAND：致力于提升3D大型语言模型的基础性并减少幻觉现象](2024年06月07日/3D-GRAND_Towards_Better_Grounding_and_Less_Hallucination_for_3D-LLMs.md)

- [BAMO at SemEval-2024 Task 9: BRAINTEASER: A Novel Task Defying Common Sense](2024年06月07日/BAMO_at_SemEval-2024_Task_9_BRAINTEASER_A_Novel_Task_Defying_Common_Sense.md)

    - [翻译: BAMO 亮相 SemEval-2024 任务 9，推出名为“BRAINTEASER”的新挑战，旨在颠覆传统常识认知。](2024年06月07日/BAMO_at_SemEval-2024_Task_9_BRAINTEASER_A_Novel_Task_Defying_Common_Sense.md)

- [An Empirical Study on Parameter-Efficient Fine-Tuning for MultiModal Large Language Models](2024年06月07日/An_Empirical_Study_on_Parameter-Efficient_Fine-Tuning_for_MultiModal_Large_Language_Models.md)

    - [翻译: 多模态大型语言模型参数高效微调的实证探索](2024年06月07日/An_Empirical_Study_on_Parameter-Efficient_Fine-Tuning_for_MultiModal_Large_Language_Models.md)

- [Towards Semantic Equivalence of Tokenization in Multimodal LLM](2024年06月07日/Towards_Semantic_Equivalence_of_Tokenization_in_Multimodal_LLM.md)

    - [翻译: 探索多模态LLM中标记化的语义等效性](2024年06月07日/Towards_Semantic_Equivalence_of_Tokenization_in_Multimodal_LLM.md)

- [RU-AI: A Large Multimodal Dataset for Machine Generated Content Detection](2024年06月07日/RU-AI_A_Large_Multimodal_Dataset_for_Machine_Generated_Content_Detection.md)

    - [翻译: RU-AI：专为机器生成内容检测而设计的大型多模态数据集](2024年06月07日/RU-AI_A_Large_Multimodal_Dataset_for_Machine_Generated_Content_Detection.md)

- [MGIMM: Multi-Granularity Instruction Multimodal Model for Attribute-Guided Remote Sensing Image Detailed Description](2024年06月07日/MGIMM_Multi-Granularity_Instruction_Multimodal_Model_for_Attribute-Guided_Remote_Sensing_Image_Detailed_Description.md)

    - [翻译: MGIMM：一种多粒度指令驱动的多模态模型，专为属性引导下的遥感图像详细描述而设计。](2024年06月07日/MGIMM_Multi-Granularity_Instruction_Multimodal_Model_for_Attribute-Guided_Remote_Sensing_Image_Detailed_Description.md)

- [AICoderEval: Improving AI Domain Code Generation of Large Language Models](2024年06月07日/AICoderEval_Improving_AI_Domain_Code_Generation_of_Large_Language_Models.md)

    - [翻译: AICoderEval：优化大型语言模型在AI领域的代码生成表现](2024年06月07日/AICoderEval_Improving_AI_Domain_Code_Generation_of_Large_Language_Models.md)

- [Large Generative Graph Models](2024年06月07日/Large_Generative_Graph_Models.md)

    - [翻译: 生成图模型巨擘](2024年06月07日/Large_Generative_Graph_Models.md)

- [LINX: A Language Driven Generative System for Goal-Oriented Automated Data Exploration](2024年06月07日/LINX_A_Language_Driven_Generative_System_for_Goal-Oriented_Automated_Data_Exploration.md)

    - [翻译: LINX：语言驱动的目标导向自动数据探索生成系统。](2024年06月07日/LINX_A_Language_Driven_Generative_System_for_Goal-Oriented_Automated_Data_Exploration.md)

- [Multi-Head RAG: Solving Multi-Aspect Problems with LLMs](2024年06月07日/Multi-Head_RAG_Solving_Multi-Aspect_Problems_with_LLMs.md)

    - [翻译: 多头部RAG：利用大型语言模型攻克多维度难题](2024年06月07日/Multi-Head_RAG_Solving_Multi-Aspect_Problems_with_LLMs.md)

- [Are Large Language Models More Empathetic than Humans?](2024年06月07日/Are_Large_Language_Models_More_Empathetic_than_Humans.md)

    - [翻译: 大型语言模型是否拥有超越人类的同理心？](2024年06月07日/Are_Large_Language_Models_More_Empathetic_than_Humans.md)

- [Robustness Assessment of Mathematical Reasoning in the Presence of Missing and Contradictory Conditions](2024年06月07日/Robustness_Assessment_of_Mathematical_Reasoning_in_the_Presence_of_Missing_and_Contradictory_Conditions.md)

    - [翻译: 评估数学推理在面对缺失与矛盾条件时的稳健性](2024年06月07日/Robustness_Assessment_of_Mathematical_Reasoning_in_the_Presence_of_Missing_and_Contradictory_Conditions.md)

- [Hints-In-Browser: Benchmarking Language Models for Programming Feedback Generation](2024年06月07日/Hints-In-Browser_Benchmarking_Language_Models_for_Programming_Feedback_Generation.md)

    - [翻译: 浏览器提示：评估语言模型在编程反馈生成中的基准测试](2024年06月07日/Hints-In-Browser_Benchmarking_Language_Models_for_Programming_Feedback_Generation.md)

- [A Tensor Decomposition Perspective on Second-order RNNs](2024年06月07日/A_Tensor_Decomposition_Perspective_on_Second-order_RNNs.md)

    - [翻译: 二阶RNN的张量分解视角](2024年06月07日/A_Tensor_Decomposition_Perspective_on_Second-order_RNNs.md)

- [Bootstrapping Referring Multi-Object Tracking](2024年06月07日/Bootstrapping_Referring_Multi-Object_Tracking.md)

    - [翻译: 自举式多目标引用跟踪](2024年06月07日/Bootstrapping_Referring_Multi-Object_Tracking.md)

- [Scenarios and Approaches for Situated Natural Language Explanations](2024年06月07日/Scenarios_and_Approaches_for_Situated_Natural_Language_Explanations.md)

    - [翻译: 自然语言解释的情境化场景与策略](2024年06月07日/Scenarios_and_Approaches_for_Situated_Natural_Language_Explanations.md)

- [CHIQ: Contextual History Enhancement for Improving Query Rewriting in Conversational Search](2024年06月07日/CHIQ_Contextual_History_Enhancement_for_Improving_Query_Rewriting_in_Conversational_Search.md)

    - [翻译: CHIQ：提升对话搜索查询重写效果的上下文历史增强技术](2024年06月07日/CHIQ_Contextual_History_Enhancement_for_Improving_Query_Rewriting_in_Conversational_Search.md)

- [MEFT: Memory-Efficient Fine-Tuning through Sparse Adapter](2024年06月07日/MEFT_Memory-Efficient_Fine-Tuning_through_Sparse_Adapter.md)

    - [翻译: MEFT：借助稀疏适配器，实现内存高效微调](2024年06月07日/MEFT_Memory-Efficient_Fine-Tuning_through_Sparse_Adapter.md)

- [CityCraft: A Real Crafter for 3D City Generation](2024年06月07日/CityCraft_A_Real_Crafter_for_3D_City_Generation.md)

    - [翻译: CityCraft：打造真实3D城市的匠心之作](2024年06月07日/CityCraft_A_Real_Crafter_for_3D_City_Generation.md)

- [Quantifying Geospatial in the Common Crawl Corpus](2024年06月07日/Quantifying_Geospatial_in_the_Common_Crawl_Corpus.md)

    - [翻译: 探索 Common Crawl 语料库中的地理空间数据量化](2024年06月07日/Quantifying_Geospatial_in_the_Common_Crawl_Corpus.md)

- [TCMD: A Traditional Chinese Medicine QA Dataset for Evaluating Large Language Models](2024年06月07日/TCMD_A_Traditional_Chinese_Medicine_QA_Dataset_for_Evaluating_Large_Language_Models.md)

    - [翻译: TCMD：专为大型语言模型评估设计的传统中医问答数据集](2024年06月07日/TCMD_A_Traditional_Chinese_Medicine_QA_Dataset_for_Evaluating_Large_Language_Models.md)

- [LLM-based speaker diarization correction: A generalizable approach](2024年06月07日/LLM-based_speaker_diarization_correction_A_generalizable_approach.md)

    - [翻译: 大型语言模型驱动的说话人日志校正：一种普适性解决方案](2024年06月07日/LLM-based_speaker_diarization_correction_A_generalizable_approach.md)

- [Through the Thicket: A Study of Number-Oriented LLMs derived from Random Forest Models](2024年06月07日/Through_the_Thicket_A_Study_of_Number-Oriented_LLMs_derived_from_Random_Forest_Models.md)

    - [翻译: 丛林探秘：随机森林启发的数字导向大型语言模型研究](2024年06月07日/Through_the_Thicket_A_Study_of_Number-Oriented_LLMs_derived_from_Random_Forest_Models.md)

- [Sexism Detection on a Data Diet](2024年06月07日/Sexism_Detection_on_a_Data_Diet.md)

    - [翻译: 精简数据下的性别歧视识别](2024年06月07日/Sexism_Detection_on_a_Data_Diet.md)

- [A Deep Dive into the Trade-Offs of Parameter-Efficient Preference Alignment Techniques](2024年06月07日/A_Deep_Dive_into_the_Trade-Offs_of_Parameter-Efficient_Preference_Alignment_Techniques.md)

    - [翻译: 深入分析参数高效偏好对齐技术的利弊](2024年06月07日/A_Deep_Dive_into_the_Trade-Offs_of_Parameter-Efficient_Preference_Alignment_Techniques.md)

- [ComplexTempQA: A Large-Scale Dataset for Complex Temporal Question Answering](2024年06月07日/ComplexTempQA_A_Large-Scale_Dataset_for_Complex_Temporal_Question_Answering.md)

    - [翻译: ComplexTempQA：专为复杂时间问答任务设计的大型数据集](2024年06月07日/ComplexTempQA_A_Large-Scale_Dataset_for_Complex_Temporal_Question_Answering.md)

- [Uncertainty Aware Learning for Language Model Alignment](2024年06月07日/Uncertainty_Aware_Learning_for_Language_Model_Alignment.md)

    - [翻译: 语言模型对齐中的不确定性感知学习](2024年06月07日/Uncertainty_Aware_Learning_for_Language_Model_Alignment.md)

- [FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large Language Models](2024年06月07日/FedLLM-Bench_Realistic_Benchmarks_for_Federated_Learning_of_Large_Language_Models.md)

    - [翻译: FedLLM-Bench：大型语言模型联合学习的真实场景基准测试](2024年06月07日/FedLLM-Bench_Realistic_Benchmarks_for_Federated_Learning_of_Large_Language_Models.md)

- [Revisiting Catastrophic Forgetting in Large Language Model Tuning](2024年06月07日/Revisiting_Catastrophic_Forgetting_in_Large_Language_Model_Tuning.md)

    - [翻译: 再探大型语言模型调优中的灾难性遗忘现象](2024年06月07日/Revisiting_Catastrophic_Forgetting_in_Large_Language_Model_Tuning.md)

- [FunBO: Discovering Acquisition Functions for Bayesian Optimization with FunSearch](2024年06月07日/FunBO_Discovering_Acquisition_Functions_for_Bayesian_Optimization_with_FunSearch.md)

    - [翻译: FunBO：利用FunSearch探索贝叶斯优化中的新颖获取函数](2024年06月07日/FunBO_Discovering_Acquisition_Functions_for_Bayesian_Optimization_with_FunSearch.md)

- [Experiences from Integrating Large Language Model Chatbots into the Classroom](2024年06月07日/Experiences_from_Integrating_Large_Language_Model_Chatbots_into_the_Classroom.md)

    - [翻译: 课堂中融入大型语言模型聊天机器人的实践经验](2024年06月07日/Experiences_from_Integrating_Large_Language_Model_Chatbots_into_the_Classroom.md)

- [Zero, Finite, and Infinite Belief History of Theory of Mind Reasoning in Large Language Models](2024年06月07日/Zero,_Finite,_and_Infinite_Belief_History_of_Theory_of_Mind_Reasoning_in_Large_Language_Models.md)

    - [翻译: 大语言模型中心智理论推理的零、有限与无限信念历史探索](2024年06月07日/Zero,_Finite,_and_Infinite_Belief_History_of_Theory_of_Mind_Reasoning_in_Large_Language_Models.md)

- [Enabling Efficient Batch Serving for LMaaS via Generation Length Prediction](2024年06月07日/Enabling_Efficient_Batch_Serving_for_LMaaS_via_Generation_Length_Prediction.md)

    - [翻译: 利用生成长度预测优化语言模型即服务（LMaaS）的批量服务效率](2024年06月07日/Enabling_Efficient_Batch_Serving_for_LMaaS_via_Generation_Length_Prediction.md)

- [SelfGoal: Your Language Agents Already Know How to Achieve High-level Goals](2024年06月07日/SelfGoal_Your_Language_Agents_Already_Know_How_to_Achieve_High-level_Goals.md)

    - [翻译: SelfGoal：你的语言助手已具备达成高阶目标的智慧](2024年06月07日/SelfGoal_Your_Language_Agents_Already_Know_How_to_Achieve_High-level_Goals.md)

- [WildBench: Benchmarking LLMs with Challenging Tasks from Real Users in the Wild](2024年06月07日/WildBench_Benchmarking_LLMs_with_Challenging_Tasks_from_Real_Users_in_the_Wild.md)

    - [翻译: WildBench：针对真实用户在实际场景中的挑战性任务，对大型语言模型进行性能评估的基准平台。](2024年06月07日/WildBench_Benchmarking_LLMs_with_Challenging_Tasks_from_Real_Users_in_the_Wild.md)

- [Think out Loud: Emotion Deducing Explanation in Dialogues](2024年06月07日/Think_out_Loud_Emotion_Deducing_Explanation_in_Dialogues.md)

    - [翻译: 畅谈心声：对话中情感的推理解析](2024年06月07日/Think_out_Loud_Emotion_Deducing_Explanation_in_Dialogues.md)

- [Sales Whisperer: A Human-Inconspicuous Attack on LLM Brand Recommendations](2024年06月07日/Sales_Whisperer_A_Human-Inconspicuous_Attack_on_LLM_Brand_Recommendations.md)

    - [翻译: 销售密语：针对LLM品牌推荐的无形人攻](2024年06月07日/Sales_Whisperer_A_Human-Inconspicuous_Attack_on_LLM_Brand_Recommendations.md)

- [CRiskEval: A Chinese Multi-Level Risk Evaluation Benchmark Dataset for Large Language Models](2024年06月07日/CRiskEval_A_Chinese_Multi-Level_Risk_Evaluation_Benchmark_Dataset_for_Large_Language_Models.md)

    - [翻译: CRiskEval：大型语言模型中文多级风险评估的基准数据集](2024年06月07日/CRiskEval_A_Chinese_Multi-Level_Risk_Evaluation_Benchmark_Dataset_for_Large_Language_Models.md)

- [CRAG -- Comprehensive RAG Benchmark](2024年06月07日/CRAG_--_Comprehensive_RAG_Benchmark.md)

    - [翻译: CRAG - 全面评估 RAG 性能的基准](2024年06月07日/CRAG_--_Comprehensive_RAG_Benchmark.md)

- [LLM-Vectorizer: LLM-based Verified Loop Vectorizer](2024年06月07日/LLM-Vectorizer_LLM-based_Verified_Loop_Vectorizer.md)

    - [翻译: LLM-Vectorizer：一款基于大型语言模型的验证循环向量化工具](2024年06月07日/LLM-Vectorizer_LLM-based_Verified_Loop_Vectorizer.md)

- [Mixture-of-Agents Enhances Large Language Model Capabilities](2024年06月07日/Mixture-of-Agents_Enhances_Large_Language_Model_Capabilities.md)

    - [翻译: 混合代理策略提升大型语言模型性能](2024年06月07日/Mixture-of-Agents_Enhances_Large_Language_Model_Capabilities.md)

- [LogiCode: an LLM-Driven Framework for Logical Anomaly Detection](2024年06月07日/LogiCode_an_LLM-Driven_Framework_for_Logical_Anomaly_Detection.md)

    - [翻译: 逻辑码：大型语言模型驱动的逻辑异常检测框架](2024年06月07日/LogiCode_an_LLM-Driven_Framework_for_Logical_Anomaly_Detection.md)

- [PPPR: Portable Plug-in Prompt Refiner for Text to Audio Generation](2024年06月07日/PPPR_Portable_Plug-in_Prompt_Refiner_for_Text_to_Audio_Generation.md)

    - [翻译: PPPR：文本至音频生成中的便携式插件提示精炼器](2024年06月07日/PPPR_Portable_Plug-in_Prompt_Refiner_for_Text_to_Audio_Generation.md)

- [DiNeR: a Large Realistic Dataset for Evaluating Compositional Generalization](2024年06月07日/DiNeR_a_Large_Realistic_Dataset_for_Evaluating_Compositional_Generalization.md)

    - [翻译: DiNeR：专为评估组合泛化能力而设计的大型真实数据集](2024年06月07日/DiNeR_a_Large_Realistic_Dataset_for_Evaluating_Compositional_Generalization.md)

- [LLM-POET: Evolving Complex Environments using Large Language Models](2024年06月07日/LLM-POET_Evolving_Complex_Environments_using_Large_Language_Models.md)

    - [翻译: LLM-POET：借助大型语言模型，探索复杂环境的演化之旅](2024年06月07日/LLM-POET_Evolving_Complex_Environments_using_Large_Language_Models.md)

- [LocLLM: Exploiting Generalizable Human Keypoint Localization via Large Language Model](2024年06月07日/LocLLM_Exploiting_Generalizable_Human_Keypoint_Localization_via_Large_Language_Model.md)

    - [翻译: LocLLM：借助大型语言模型，探索人体关键点定位的泛化能力](2024年06月07日/LocLLM_Exploiting_Generalizable_Human_Keypoint_Localization_via_Large_Language_Model.md)

- [LinkGPT: Teaching Large Language Models To Predict Missing Links](2024年06月07日/LinkGPT_Teaching_Large_Language_Models_To_Predict_Missing_Links.md)

    - [翻译: LinkGPT：训练大型语言模型，精准预测缺失链接](2024年06月07日/LinkGPT_Teaching_Large_Language_Models_To_Predict_Missing_Links.md)

- [Large Language Model-guided Document Selection](2024年06月07日/Large_Language_Model-guided_Document_Selection.md)

    - [翻译: 借助大型语言模型进行文档筛选](2024年06月07日/Large_Language_Model-guided_Document_Selection.md)

- [Scaling Automatic Extraction of Pseudocode](2024年06月07日/Scaling_Automatic_Extraction_of_Pseudocode.md)

    - [翻译: 提升伪代码自动提取的规模](2024年06月07日/Scaling_Automatic_Extraction_of_Pseudocode.md)

- [Boosting Diffusion Model for Spectrogram Up-sampling in Text-to-speech: An Empirical Study](2024年06月07日/Boosting_Diffusion_Model_for_Spectrogram_Up-sampling_in_Text-to-speech_An_Empirical_Study.md)

    - [翻译: 提升扩散模型在文本转语音中的频谱图上采样效果：一次实践探索](2024年06月07日/Boosting_Diffusion_Model_for_Spectrogram_Up-sampling_in_Text-to-speech_An_Empirical_Study.md)

- [Low-Resource Cross-Lingual Summarization through Few-Shot Learning with Large Language Models](2024年06月07日/Low-Resource_Cross-Lingual_Summarization_through_Few-Shot_Learning_with_Large_Language_Models.md)

    - [翻译: 借助大型语言模型的少样本学习，实现低资源条件下的跨语言摘要](2024年06月07日/Low-Resource_Cross-Lingual_Summarization_through_Few-Shot_Learning_with_Large_Language_Models.md)

- [Corpus Poisoning via Approximate Greedy Gradient Descent](2024年06月07日/Corpus_Poisoning_via_Approximate_Greedy_Gradient_Descent.md)

    - [翻译: 利用近似贪婪梯度下降策略进行语料库毒化](2024年06月07日/Corpus_Poisoning_via_Approximate_Greedy_Gradient_Descent.md)

2024年06月06日

- [AgentGym: Evolving Large Language Model-based Agents across Diverse Environments](2024年06月06日/AgentGym_Evolving_Large_Language_Model-based_Agents_across_Diverse_Environments.md)

    - [翻译: AgentGym：大型语言模型智能体在多元环境中的进化之旅](2024年06月06日/AgentGym_Evolving_Large_Language_Model-based_Agents_across_Diverse_Environments.md)

- [A Survey of Language-Based Communication in Robotics](2024年06月06日/A_Survey_of_Language-Based_Communication_in_Robotics.md)

    - [翻译: 机器人领域中基于语言的通信综述](2024年06月06日/A_Survey_of_Language-Based_Communication_in_Robotics.md)

- [BLSP-Emo: Towards Empathetic Large Speech-Language Models](2024年06月06日/BLSP-Emo_Towards_Empathetic_Large_Speech-Language_Models.md)

    - [翻译: BLSP-Emo：迈向富有同理心的大型语音-语言模型之旅](2024年06月06日/BLSP-Emo_Towards_Empathetic_Large_Speech-Language_Models.md)

- [MuJo: Multimodal Joint Feature Space Learning for Human Activity Recognition](2024年06月06日/MuJo_Multimodal_Joint_Feature_Space_Learning_for_Human_Activity_Recognition.md)

    - [翻译: MuJo：探索人体活动识别中的多模态联合特征空间学习](2024年06月06日/MuJo_Multimodal_Joint_Feature_Space_Learning_for_Human_Activity_Recognition.md)

- [Legal Documents Drafting with Fine-Tuned Pre-Trained Large Language Model](2024年06月06日/Legal_Documents_Drafting_with_Fine-Tuned_Pre-Trained_Large_Language_Model.md)

    - [翻译: 微调预训练大型语言模型助力法律文件起草](2024年06月06日/Legal_Documents_Drafting_with_Fine-Tuned_Pre-Trained_Large_Language_Model.md)

- [DICE: Detecting In-distribution Contamination in LLM's Fine-tuning Phase for Math Reasoning](2024年06月06日/DICE_Detecting_In-distribution_Contamination_in_LLM's_Fine-tuning_Phase_for_Math_Reasoning.md)

    - [翻译: DICE：检测 LLM 数学推理微调中的分布内污染问题](2024年06月06日/DICE_Detecting_In-distribution_Contamination_in_LLM's_Fine-tuning_Phase_for_Math_Reasoning.md)

- [Confabulation: The Surprising Value of Large Language Model Hallucinations](2024年06月06日/Confabulation_The_Surprising_Value_of_Large_Language_Model_Hallucinations.md)

    - [翻译: 虚构之美：探索大型语言模型幻觉的意外价值](2024年06月06日/Confabulation_The_Surprising_Value_of_Large_Language_Model_Hallucinations.md)

- [Pointer-Guided Pre-Training: Infusing Large Language Models with Paragraph-Level Contextual Awareness](2024年06月06日/Pointer-Guided_Pre-Training_Infusing_Large_Language_Models_with_Paragraph-Level_Contextual_Awareness.md)

    - [翻译: 指针引导预训练：赋予大型语言模型段落级上下文感知力](2024年06月06日/Pointer-Guided_Pre-Training_Infusing_Large_Language_Models_with_Paragraph-Level_Contextual_Awareness.md)

- [Every Answer Matters: Evaluating Commonsense with Probabilistic Measures](2024年06月06日/Every_Answer_Matters_Evaluating_Commonsense_with_Probabilistic_Measures.md)

    - [翻译: 每个答案皆关键：运用概率度量评估常识](2024年06月06日/Every_Answer_Matters_Evaluating_Commonsense_with_Probabilistic_Measures.md)

- [Do Language Models Understand Morality? Towards a Robust Detection of Moral Content](2024年06月06日/Do_Language_Models_Understand_Morality_Towards_a_Robust_Detection_of_Moral_Content.md)

    - [翻译: 语言模型是否能理解道德？探索道德内容的稳健检测方法](2024年06月06日/Do_Language_Models_Understand_Morality_Towards_a_Robust_Detection_of_Moral_Content.md)

- [STraDa: A Singer Traits Dataset](2024年06月06日/STraDa_A_Singer_Traits_Dataset.md)

    - [翻译: STraDa：歌手特质数据集](2024年06月06日/STraDa_A_Singer_Traits_Dataset.md)

- [Legal Judgment Reimagined: PredEx and the Rise of Intelligent AI Interpretation in Indian Courts](2024年06月06日/Legal_Judgment_Reimagined_PredEx_and_the_Rise_of_Intelligent_AI_Interpretation_in_Indian_Courts.md)

    - [翻译: 重塑法律判决：PredEx 引领印度法院智能 AI 解释的新潮流](2024年06月06日/Legal_Judgment_Reimagined_PredEx_and_the_Rise_of_Intelligent_AI_Interpretation_in_Indian_Courts.md)

- [Uncovering Limitations of Large Language Models in Information Seeking from Tables](2024年06月06日/Uncovering_Limitations_of_Large_Language_Models_in_Information_Seeking_from_Tables.md)

    - [翻译: 探究大型语言模型在表格信息检索中的局限性](2024年06月06日/Uncovering_Limitations_of_Large_Language_Models_in_Information_Seeking_from_Tables.md)

- [Scaling and evaluating sparse autoencoders](2024年06月06日/Scaling_and_evaluating_sparse_autoencoders.md)

    - [翻译: 探究与评估稀疏自编码器的扩展性能](2024年06月06日/Scaling_and_evaluating_sparse_autoencoders.md)

- [Federated TrustChain: Blockchain-Enhanced LLM Training and Unlearning](2024年06月06日/Federated_TrustChain_Blockchain-Enhanced_LLM_Training_and_Unlearning.md)

    - [翻译: 联邦信任链：利用区块链优化大型语言模型训练与遗忘机制](2024年06月06日/Federated_TrustChain_Blockchain-Enhanced_LLM_Training_and_Unlearning.md)

- [Ask LLMs Directly, "What shapes your bias?": Measuring Social Bias in Large Language Models](2024年06月06日/Ask_LLMs_Directly,_What_shapes_your_bias_Measuring_Social_Bias_in_Large_Language_Models.md)

    - [翻译: 探究大型语言模型偏见之源：“你的偏见由何塑造？”——大型语言模型社会偏见测量研究](2024年06月06日/Ask_LLMs_Directly,_What_shapes_your_bias_Measuring_Social_Bias_in_Large_Language_Models.md)

- [ActionReasoningBench: Reasoning about Actions with and without Ramification Constraints](2024年06月06日/ActionReasoningBench_Reasoning_about_Actions_with_and_without_Ramification_Constraints.md)

    - [翻译: 动作推理基准：探究在有无后果约束下的动作推理机制](2024年06月06日/ActionReasoningBench_Reasoning_about_Actions_with_and_without_Ramification_Constraints.md)

- [Jailbreak Vision Language Models via Bi-Modal Adversarial Prompt](2024年06月06日/Jailbreak_Vision_Language_Models_via_Bi-Modal_Adversarial_Prompt.md)

    - [翻译: 利用双模态对抗性提示破解视觉语言模型](2024年06月06日/Jailbreak_Vision_Language_Models_via_Bi-Modal_Adversarial_Prompt.md)

- [Assessing LLMs for Zero-shot Abstractive Summarization Through the Lens of Relevance Paraphrasing](2024年06月06日/Assessing_LLMs_for_Zero-shot_Abstractive_Summarization_Through_the_Lens_of_Relevance_Paraphrasing.md)

    - [翻译: 从相关性改写角度审视大型语言模型在零-shot抽象摘要上的表现](2024年06月06日/Assessing_LLMs_for_Zero-shot_Abstractive_Summarization_Through_the_Lens_of_Relevance_Paraphrasing.md)

- [On The Persona-based Summarization of Domain-Specific Documents](2024年06月06日/On_The_Persona-based_Summarization_of_Domain-Specific_Documents.md)

    - [翻译: 特定领域文档的人物角色化摘要研究](2024年06月06日/On_The_Persona-based_Summarization_of_Domain-Specific_Documents.md)

- [A + B: A General Generator-Reader Framework for Optimizing LLMs to Unleash Synergy Potential](2024年06月06日/A_+_B_A_General_Generator-Reader_Framework_for_Optimizing_LLMs_to_Unleash_Synergy_Potential.md)

    - [翻译: A + B：释放 LLMs 协同潜力的通用生成器-阅读器框架](2024年06月06日/A_+_B_A_General_Generator-Reader_Framework_for_Optimizing_LLMs_to_Unleash_Synergy_Potential.md)

- [UltraMedical: Building Specialized Generalists in Biomedicine](2024年06月06日/UltraMedical_Building_Specialized_Generalists_in_Biomedicine.md)

    - [翻译: UltraMedical：打造生物医学中的全能专家](2024年06月06日/UltraMedical_Building_Specialized_Generalists_in_Biomedicine.md)

- [HeSum: a Novel Dataset for Abstractive Text Summarization in Hebrew](2024年06月06日/HeSum_a_Novel_Dataset_for_Abstractive_Text_Summarization_in_Hebrew.md)

    - [翻译: HeSum：希伯来语抽象文本摘要领域的新星数据集](2024年06月06日/HeSum_a_Novel_Dataset_for_Abstractive_Text_Summarization_in_Hebrew.md)

- [Spontaneous Speech-Based Suicide Risk Detection Using Whisper and Large Language Models](2024年06月06日/Spontaneous_Speech-Based_Suicide_Risk_Detection_Using_Whisper_and_Large_Language_Models.md)

    - [翻译: 利用 Whisper 与大型语言模型进行自发语音的自杀风险检测](2024年06月06日/Spontaneous_Speech-Based_Suicide_Risk_Detection_Using_Whisper_and_Large_Language_Models.md)

- [LLplace: The 3D Indoor Scene Layout Generation and Editing via Large Language Model](2024年06月06日/LLplace_The_3D_Indoor_Scene_Layout_Generation_and_Editing_via_Large_Language_Model.md)

    - [翻译: LLplace：借助大型语言模型，实现三维室内场景布局的生成与编辑](2024年06月06日/LLplace_The_3D_Indoor_Scene_Layout_Generation_and_Editing_via_Large_Language_Model.md)

- [Performance of large language models in numerical vs. semantic medical knowledge: Benchmarking on evidence-based Q&As](2024年06月06日/Performance_of_large_language_models_in_numerical_vs._semantic_medical_knowledge_Benchmarking_on_evidence-based_Q&As.md)

    - [翻译: 大型语言模型在数值与语义医学知识领域的性能对比：基于证据的问答基准测试研究](2024年06月06日/Performance_of_large_language_models_in_numerical_vs._semantic_medical_knowledge_Benchmarking_on_evidence-based_Q&As.md)

- [Speculative Decoding via Early-exiting for Faster LLM Inference with Thompson Sampling Control Mechanism](2024年06月06日/Speculative_Decoding_via_Early-exiting_for_Faster_LLM_Inference_with_Thompson_Sampling_Control_Mechanism.md)

    - [翻译: 借助早期退出与汤普森采样机制，推测解码加速LLM推理](2024年06月06日/Speculative_Decoding_via_Early-exiting_for_Faster_LLM_Inference_with_Thompson_Sampling_Control_Mechanism.md)

- [Lean Workbook: A large-scale Lean problem set formalized from natural language math problems](2024年06月06日/Lean_Workbook_A_large-scale_Lean_problem_set_formalized_from_natural_language_math_problems.md)

    - [翻译: 精益实践手册：一本源自自然语言数学问题的大规模问题集，旨在系统化精益解题方法。](2024年06月06日/Lean_Workbook_A_large-scale_Lean_problem_set_formalized_from_natural_language_math_problems.md)

- [POEM: Interactive Prompt Optimization for Enhancing Multimodal Reasoning of Large Language Models](2024年06月06日/POEM_Interactive_Prompt_Optimization_for_Enhancing_Multimodal_Reasoning_of_Large_Language_Models.md)

    - [翻译: POEM：通过交互式提示优化提升大型语言模型的多模态推理能力](2024年06月06日/POEM_Interactive_Prompt_Optimization_for_Enhancing_Multimodal_Reasoning_of_Large_Language_Models.md)

- [PCART: Automated Repair of Python API Parameter Compatibility Issues](2024年06月06日/PCART_Automated_Repair_of_Python_API_Parameter_Compatibility_Issues.md)

    - [翻译: PCART：解决Python API参数兼容性问题的自动化修复方案](2024年06月06日/PCART_Automated_Repair_of_Python_API_Parameter_Compatibility_Issues.md)

- [Chaos with Keywords: Exposing Large Language Models Sycophancy to Misleading Keywords and Evaluating Defense Strategies](2024年06月06日/Chaos_with_Keywords_Exposing_Large_Language_Models_Sycophancy_to_Misleading_Keywords_and_Evaluating_Defense_Strategies.md)

    - [翻译: 关键词之乱：揭示大型语言模型对误导性关键词的盲从，并探讨防御之策](2024年06月06日/Chaos_with_Keywords_Exposing_Large_Language_Models_Sycophancy_to_Misleading_Keywords_and_Evaluating_Defense_Strategies.md)

- [Tool-Planner: Dynamic Solution Tree Planning for Large Language Model with Tool Clustering](2024年06月06日/Tool-Planner_Dynamic_Solution_Tree_Planning_for_Large_Language_Model_with_Tool_Clustering.md)

    - [翻译: 工具规划器：利用工具聚类，为大型语言模型打造动态解决方案树规划](2024年06月06日/Tool-Planner_Dynamic_Solution_Tree_Planning_for_Large_Language_Model_with_Tool_Clustering.md)

- [AutoJailbreak: Exploring Jailbreak Attacks and Defenses through a Dependency Lens](2024年06月06日/AutoJailbreak_Exploring_Jailbreak_Attacks_and_Defenses_through_a_Dependency_Lens.md)

    - [翻译: AutoJailbreak：透过依赖的镜头，深入探讨越狱攻击与防御的奥秘](2024年06月06日/AutoJailbreak_Exploring_Jailbreak_Attacks_and_Defenses_through_a_Dependency_Lens.md)

- [Light-PEFT: Lightening Parameter-Efficient Fine-Tuning via Early Pruning](2024年06月06日/Light-PEFT_Lightening_Parameter-Efficient_Fine-Tuning_via_Early_Pruning.md)

    - [翻译: Light-PEFT：借助早期剪枝，实现参数高效微调的轻量化方案](2024年06月06日/Light-PEFT_Lightening_Parameter-Efficient_Fine-Tuning_via_Early_Pruning.md)

- [Empirical Guidelines for Deploying LLMs onto Resource-constrained Edge Devices](2024年06月06日/Empirical_Guidelines_for_Deploying_LLMs_onto_Resource-constrained_Edge_Devices.md)

    - [翻译: 资源受限边缘设备上部署 LLMs 的实用指南](2024年06月06日/Empirical_Guidelines_for_Deploying_LLMs_onto_Resource-constrained_Edge_Devices.md)

- [XL-HeadTags: Leveraging Multimodal Retrieval Augmentation for the Multilingual Generation of News Headlines and Tags](2024年06月06日/XL-HeadTags_Leveraging_Multimodal_Retrieval_Augmentation_for_the_Multilingual_Generation_of_News_Headlines_and_Tags.md)

    - [翻译: XL-HeadTags：借助多模态检索增强，实现多语言新闻标题与标签的精准生成](2024年06月06日/XL-HeadTags_Leveraging_Multimodal_Retrieval_Augmentation_for_the_Multilingual_Generation_of_News_Headlines_and_Tags.md)

- [Enhancing In-Context Learning Performance with just SVD-Based Weight Pruning: A Theoretical Perspective](2024年06月06日/Enhancing_In-Context_Learning_Performance_with_just_SVD-Based_Weight_Pruning_A_Theoretical_Perspective.md)

    - [翻译: 基于SVD的权重剪枝：理论视角下的上下文学习性能提升之道](2024年06月06日/Enhancing_In-Context_Learning_Performance_with_just_SVD-Based_Weight_Pruning_A_Theoretical_Perspective.md)

- [RoboCoder: Robotic Learning from Basic Skills to General Tasks with Large Language Models](2024年06月06日/RoboCoder_Robotic_Learning_from_Basic_Skills_to_General_Tasks_with_Large_Language_Models.md)

    - [翻译: RoboCoder：借助大型语言模型，机器人从基础技能逐步掌握通用任务的学习之旅](2024年06月06日/RoboCoder_Robotic_Learning_from_Basic_Skills_to_General_Tasks_with_Large_Language_Models.md)

- [VisLTR: Visualization-in-the-Loop Table Reasoning](2024年06月06日/VisLTR_Visualization-in-the-Loop_Table_Reasoning.md)

    - [翻译: VisLTR：可视化驱动的表格推理循环](2024年06月06日/VisLTR_Visualization-in-the-Loop_Table_Reasoning.md)

- [NAP^2: A Benchmark for Naturalness and Privacy-Preserving Text Rewriting by Learning from Human](2024年06月06日/NAP^2_A_Benchmark_for_Naturalness_and_Privacy-Preserving_Text_Rewriting_by_Learning_from_Human.md)

    - [翻译: NAP^2：人类学习驱动的自然与隐私保护文本重写基准](2024年06月06日/NAP^2_A_Benchmark_for_Naturalness_and_Privacy-Preserving_Text_Rewriting_by_Learning_from_Human.md)

- [Efficient Knowledge Infusion via KG-LLM Alignment](2024年06月06日/Efficient_Knowledge_Infusion_via_KG-LLM_Alignment.md)

    - [翻译: 知识高效注入：KG-LLM对齐策略](2024年06月06日/Efficient_Knowledge_Infusion_via_KG-LLM_Alignment.md)

- [FastGAS: Fast Graph-based Annotation Selection for In-Context Learning](2024年06月06日/FastGAS_Fast_Graph-based_Annotation_Selection_for_In-Context_Learning.md)

    - [翻译: FastGAS：快速图解标注选择，助力上下文学习](2024年06月06日/FastGAS_Fast_Graph-based_Annotation_Selection_for_In-Context_Learning.md)

- [Buffer of Thoughts: Thought-Augmented Reasoning with Large Language Models](2024年06月06日/Buffer_of_Thoughts_Thought-Augmented_Reasoning_with_Large_Language_Models.md)

    - [翻译: 思维的缓冲：大型语言模型中的思维强化推理](2024年06月06日/Buffer_of_Thoughts_Thought-Augmented_Reasoning_with_Large_Language_Models.md)

- [Aligning Agents like Large Language Models](2024年06月06日/Aligning_Agents_like_Large_Language_Models.md)

    - [翻译: 使大型语言模型等代理对齐](2024年06月06日/Aligning_Agents_like_Large_Language_Models.md)

- [RoboMamba: Multimodal State Space Model for Efficient Robot Reasoning and Manipulation](2024年06月06日/RoboMamba_Multimodal_State_Space_Model_for_Efficient_Robot_Reasoning_and_Manipulation.md)

    - [翻译: RoboMamba：融合多模态信息的状态空间模型，助力机器人高效推理与操作](2024年06月06日/RoboMamba_Multimodal_State_Space_Model_for_Efficient_Robot_Reasoning_and_Manipulation.md)

- [DeepStack: Deeply Stacking Visual Tokens is Surprisingly Simple and Effective for LMMs](2024年06月06日/DeepStack_Deeply_Stacking_Visual_Tokens_is_Surprisingly_Simple_and_Effective_for_LMMs.md)

    - [翻译: DeepStack：通过深度堆叠视觉令牌，大型多模态模型（LMMs）的性能提升既简单又出乎意料地有效。](2024年06月06日/DeepStack_Deeply_Stacking_Visual_Tokens_is_Surprisingly_Simple_and_Effective_for_LMMs.md)

- [Morpho-Photometric Classification of KiDS DR5 Sources Based on Neural Networks: A Comprehensive Star-Quasar-Galaxy Catalog](2024年06月06日/Morpho-Photometric_Classification_of_KiDS_DR5_Sources_Based_on_Neural_Networks_A_Comprehensive_Star-Quasar-Galaxy_Catalog.md)

    - [翻译: 利用神经网络对KiDS DR5源进行形态-光度分类，构建了一个详尽的恒星-类星体-星系目录。](2024年06月06日/Morpho-Photometric_Classification_of_KiDS_DR5_Sources_Based_on_Neural_Networks_A_Comprehensive_Star-Quasar-Galaxy_Catalog.md)

- [Verbalized Machine Learning: Revisiting Machine Learning with Language Models](2024年06月06日/Verbalized_Machine_Learning_Revisiting_Machine_Learning_with_Language_Models.md)

    - [翻译: 语言模型视角下的机器学习再探：口头化机器学习](2024年06月06日/Verbalized_Machine_Learning_Revisiting_Machine_Learning_with_Language_Models.md)

- [Learning 1D Causal Visual Representation with De-focus Attention Networks](2024年06月06日/Learning_1D_Causal_Visual_Representation_with_De-focus_Attention_Networks.md)

    - [翻译: 借助去焦注意力网络，探索一维因果视觉表示的学习之道](2024年06月06日/Learning_1D_Causal_Visual_Representation_with_De-focus_Attention_Networks.md)

- [Coherent Zero-Shot Visual Instruction Generation](2024年06月06日/Coherent_Zero-Shot_Visual_Instruction_Generation.md)

    - [翻译: 零-shot视觉指令生成：连贯性探索](2024年06月06日/Coherent_Zero-Shot_Visual_Instruction_Generation.md)

- [PaCE: Parsimonious Concept Engineering for Large Language Models](2024年06月06日/PaCE_Parsimonious_Concept_Engineering_for_Large_Language_Models.md)

    - [翻译: PaCE：大型语言模型的精简概念工程](2024年06月06日/PaCE_Parsimonious_Concept_Engineering_for_Large_Language_Models.md)

- [ShareGPT4Video: Improving Video Understanding and Generation with Better Captions](2024年06月06日/ShareGPT4Video_Improving_Video_Understanding_and_Generation_with_Better_Captions.md)

    - [翻译: ShareGPT4Video：借助优质字幕，深化视频理解与创作](2024年06月06日/ShareGPT4Video_Improving_Video_Understanding_and_Generation_with_Better_Captions.md)

- [Step-aware Preference Optimization: Aligning Preference with Denoising Performance at Each Step](2024年06月06日/Step-aware_Preference_Optimization_Aligning_Preference_with_Denoising_Performance_at_Each_Step.md)

    - [翻译: 逐步偏好优化：确保每一步的去噪效果与用户偏好同步调整](2024年06月06日/Step-aware_Preference_Optimization_Aligning_Preference_with_Denoising_Performance_at_Each_Step.md)

- [Semantically Diverse Language Generation for Uncertainty Estimation in Language Models](2024年06月06日/Semantically_Diverse_Language_Generation_for_Uncertainty_Estimation_in_Language_Models.md)

    - [翻译: 语言模型中不确定性估计的语义多样性语言生成](2024年06月06日/Semantically_Diverse_Language_Generation_for_Uncertainty_Estimation_in_Language_Models.md)

- [Quixer: A Quantum Transformer Model](2024年06月06日/Quixer_A_Quantum_Transformer_Model.md)

    - [翻译: Quixer：量子Transformer新模型](2024年06月06日/Quixer_A_Quantum_Transformer_Model.md)

- [Text-to-Drive: Diverse Driving Behavior Synthesis via Large Language Models](2024年06月06日/Text-to-Drive_Diverse_Driving_Behavior_Synthesis_via_Large_Language_Models.md)

    - [翻译: 驾驭文字，驱动多样：大型语言模型助力驾驶行为多样化合成](2024年06月06日/Text-to-Drive_Diverse_Driving_Behavior_Synthesis_via_Large_Language_Models.md)

- [What Languages are Easy to Language-Model? A Perspective from Learning Probabilistic Regular Languages](2024年06月06日/What_Languages_are_Easy_to_Language-Model_A_Perspective_from_Learning_Probabilistic_Regular_Languages.md)

    - [翻译: 哪些语言适合语言建模？从概率正则语言学习的视角探讨](2024年06月06日/What_Languages_are_Easy_to_Language-Model_A_Perspective_from_Learning_Probabilistic_Regular_Languages.md)

- [Characterizing Similarities and Divergences in Conversational Tones in Humans and LLMs by Sampling with People](2024年06月06日/Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People.md)

    - [翻译: 通过人类采样，探究人类与LLMs在对话语调上的异同](2024年06月06日/Characterizing_Similarities_and_Divergences_in_Conversational_Tones_in_Humans_and_LLMs_by_Sampling_with_People.md)

- [Generative AI-in-the-loop: Integrating LLMs and GPTs into the Next Generation Networks](2024年06月06日/Generative_AI-in-the-loop_Integrating_LLMs_and_GPTs_into_the_Next_Generation_Networks.md)

    - [翻译: 下一代网络的融合：大型语言模型与GPTs的生成式AI集成](2024年06月06日/Generative_AI-in-the-loop_Integrating_LLMs_and_GPTs_into_the_Next_Generation_Networks.md)

- [Self-Play with Adversarial Critic: Provable and Scalable Offline Alignment for Language Models](2024年06月06日/Self-Play_with_Adversarial_Critic_Provable_and_Scalable_Offline_Alignment_for_Language_Models.md)

    - [翻译: 通过自我对抗批评的自我游戏，我们提出了一种可证明且可扩展的离线对齐方法，用于语言模型。](2024年06月06日/Self-Play_with_Adversarial_Critic_Provable_and_Scalable_Offline_Alignment_for_Language_Models.md)

- [Transformers need glasses! Information over-squashing in language tasks](2024年06月06日/Transformers_need_glasses!_Information_over-squashing_in_language_tasks.md)

    - [翻译: Transformer 模型或许需要一副“眼镜”，以应对语言任务中信息过度压缩的挑战。](2024年06月06日/Transformers_need_glasses!_Information_over-squashing_in_language_tasks.md)

- [A Survey on 3D Human Avatar Modeling -- From Reconstruction to Generation](2024年06月06日/A_Survey_on_3D_Human_Avatar_Modeling_--_From_Reconstruction_to_Generation.md)

    - [翻译: 《3D人体化身建模综述：从重建到生成》](2024年06月06日/A_Survey_on_3D_Human_Avatar_Modeling_--_From_Reconstruction_to_Generation.md)

- [Benchmark Data Contamination of Large Language Models: A Survey](2024年06月06日/Benchmark_Data_Contamination_of_Large_Language_Models_A_Survey.md)

    - [翻译: 大型语言模型基准数据污染问题：深度调查](2024年06月06日/Benchmark_Data_Contamination_of_Large_Language_Models_A_Survey.md)

- [Understanding Information Storage and Transfer in Multi-modal Large Language Models](2024年06月06日/Understanding_Information_Storage_and_Transfer_in_Multi-modal_Large_Language_Models.md)

    - [翻译: 探究多模态大型语言模型中信息存储与传输的奥秘](2024年06月06日/Understanding_Information_Storage_and_Transfer_in_Multi-modal_Large_Language_Models.md)

- [BEADs: Bias Evaluation Across Domains](2024年06月06日/BEADs_Bias_Evaluation_Across_Domains.md)

    - [翻译: 跨域偏差评估：BEADs](2024年06月06日/BEADs_Bias_Evaluation_Across_Domains.md)

- [What Do Language Models Learn in Context? The Structured Task Hypothesis](2024年06月06日/What_Do_Language_Models_Learn_in_Context_The_Structured_Task_Hypothesis.md)

    - [翻译: 语言模型在上下文中究竟学到了什么？这引出了结构化任务假设的探讨。](2024年06月06日/What_Do_Language_Models_Learn_in_Context_The_Structured_Task_Hypothesis.md)

- [ValueBench: Towards Comprehensively Evaluating Value Orientations and Understanding of Large Language Models](2024年06月06日/ValueBench_Towards_Comprehensively_Evaluating_Value_Orientations_and_Understanding_of_Large_Language_Models.md)

    - [翻译: ValueBench：全面审视大型语言模型的价值取向与理解深度](2024年06月06日/ValueBench_Towards_Comprehensively_Evaluating_Value_Orientations_and_Understanding_of_Large_Language_Models.md)

- [What do MLLMs hear? Examining reasoning with text and sound components in Multimodal Large Language Models](2024年06月06日/What_do_MLLMs_hear_Examining_reasoning_with_text_and_sound_components_in_Multimodal_Large_Language_Models.md)

    - [翻译: 多模态大型语言模型（MLLMs）如何通过文本与声音进行推理？](2024年06月06日/What_do_MLLMs_hear_Examining_reasoning_with_text_and_sound_components_in_Multimodal_Large_Language_Models.md)

- [MAIRA-2: Grounded Radiology Report Generation](2024年06月06日/MAIRA-2_Grounded_Radiology_Report_Generation.md)

    - [翻译: MAIRA-2：精准生成放射学报告](2024年06月06日/MAIRA-2_Grounded_Radiology_Report_Generation.md)

- [Optimizing Autonomous Driving for Safety: A Human-Centric Approach with LLM-Enhanced RLHF](2024年06月06日/Optimizing_Autonomous_Driving_for_Safety_A_Human-Centric_Approach_with_LLM-Enhanced_RLHF.md)

    - [翻译: 提升自动驾驶安全：以人为本，借助LLM强化RLHF技术](2024年06月06日/Optimizing_Autonomous_Driving_for_Safety_A_Human-Centric_Approach_with_LLM-Enhanced_RLHF.md)

- [On The Importance of Reasoning for Context Retrieval in Repository-Level Code Editing](2024年06月06日/On_The_Importance_of_Reasoning_for_Context_Retrieval_in_Repository-Level_Code_Editing.md)

    - [翻译: 在存储库级别的代码编辑中，推理对于上下文检索的重要性不容忽视。](2024年06月06日/On_The_Importance_of_Reasoning_for_Context_Retrieval_in_Repository-Level_Code_Editing.md)

2024年06月05日

- [The Good, the Bad, and the Hulk-like GPT: Analyzing Emotional Decisions of Large Language Models in Cooperation and Bargaining Games](2024年06月05日/The_Good,_the_Bad,_and_the_Hulk-like_GPT_Analyzing_Emotional_Decisions_of_Large_Language_Models_in_Cooperation_and_Bargaining_Games.md)

    - [翻译: 《情感博弈中的GPT：探究大型语言模型在合作与谈判中的决策》](2024年06月05日/The_Good,_the_Bad,_and_the_Hulk-like_GPT_Analyzing_Emotional_Decisions_of_Large_Language_Models_in_Cooperation_and_Bargaining_Games.md)

- [Identification of Stone Deterioration Patterns with Large Multimodal Models](2024年06月05日/Identification_of_Stone_Deterioration_Patterns_with_Large_Multimodal_Models.md)

    - [翻译: 借助大型多模态模型，精准识别石材退化模式](2024年06月05日/Identification_of_Stone_Deterioration_Patterns_with_Large_Multimodal_Models.md)

- [Foundation Models for Geophysics: Reviews and Perspectives](2024年06月05日/Foundation_Models_for_Geophysics_Reviews_and_Perspectives.md)

    - [翻译: 地球物理学基础模型：回顾与前瞻](2024年06月05日/Foundation_Models_for_Geophysics_Reviews_and_Perspectives.md)

- [Exploiting LMM-based knowledge for image classification tasks](2024年06月05日/Exploiting_LMM-based_knowledge_for_image_classification_tasks.md)

    - [翻译: 借助基于LMM的知识优化图像分类任务](2024年06月05日/Exploiting_LMM-based_knowledge_for_image_classification_tasks.md)

- [Enhancing Multimodal Large Language Models with Multi-instance Visual Prompt Generator for Visual Representation Enrichment](2024年06月05日/Enhancing_Multimodal_Large_Language_Models_with_Multi-instance_Visual_Prompt_Generator_for_Visual_Representation_Enrichment.md)

    - [翻译: 利用多实例视觉提示生成器，丰富多模态大型语言模型的视觉表示能力](2024年06月05日/Enhancing_Multimodal_Large_Language_Models_with_Multi-instance_Visual_Prompt_Generator_for_Visual_Representation_Enrichment.md)

- [Docs2KG: Unified Knowledge Graph Construction from Heterogeneous Documents Assisted by Large Language Models](2024年06月05日/Docs2KG_Unified_Knowledge_Graph_Construction_from_Heterogeneous_Documents_Assisted_by_Large_Language_Models.md)

    - [翻译: Docs2KG：借助大型语言模型，整合异构文档构建统一知识图谱](2024年06月05日/Docs2KG_Unified_Knowledge_Graph_Construction_from_Heterogeneous_Documents_Assisted_by_Large_Language_Models.md)

- [ChatDev: Communicative Agents for Software Development](2024年06月05日/ChatDev_Communicative_Agents_for_Software_Development.md)

    - [翻译: ChatDev：软件开发中的交流伙伴](2024年06月05日/ChatDev_Communicative_Agents_for_Software_Development.md)

- [Save It for the "Hot" Day: An LLM-Empowered Visual Analytics System for Heat Risk Management](2024年06月05日/Save_It_for_the_Hot_Day_An_LLM-Empowered_Visual_Analytics_System_for_Heat_Risk_Management.md)

    - [翻译: 炎夏备忘：基于LLM的热风险视觉分析系统](2024年06月05日/Save_It_for_the_Hot_Day_An_LLM-Empowered_Visual_Analytics_System_for_Heat_Risk_Management.md)

- [SpikeLM: Towards General Spike-Driven Language Modeling via Elastic Bi-Spiking Mechanisms](2024年06月05日/SpikeLM_Towards_General_Spike-Driven_Language_Modeling_via_Elastic_Bi-Spiking_Mechanisms.md)

    - [翻译: SpikeLM：借助弹性双脉冲机制，迈向通用脉冲驱动的语言建模新境界](2024年06月05日/SpikeLM_Towards_General_Spike-Driven_Language_Modeling_via_Elastic_Bi-Spiking_Mechanisms.md)

- [Enhancing Repository-Level Code Generation with Integrated Contextual Information](2024年06月05日/Enhancing_Repository-Level_Code_Generation_with_Integrated_Contextual_Information.md)

    - [翻译: 集成上下文信息，提升仓库级代码生成能力](2024年06月05日/Enhancing_Repository-Level_Code_Generation_with_Integrated_Contextual_Information.md)

- [Large Language Models as Evaluators for Recommendation Explanations](2024年06月05日/Large_Language_Models_as_Evaluators_for_Recommendation_Explanations.md)

    - [翻译: 大型语言模型：推荐解释的智能评估者](2024年06月05日/Large_Language_Models_as_Evaluators_for_Recommendation_Explanations.md)

- [Llumnix: Dynamic Scheduling for Large Language Model Serving](2024年06月05日/Llumnix_Dynamic_Scheduling_for_Large_Language_Model_Serving.md)

    - [翻译: Llumnix：大型语言模型服务的动态调度策略](2024年06月05日/Llumnix_Dynamic_Scheduling_for_Large_Language_Model_Serving.md)

- [Defending Large Language Models Against Attacks With Residual Stream Activation Analysis](2024年06月05日/Defending_Large_Language_Models_Against_Attacks_With_Residual_Stream_Activation_Analysis.md)

    - [翻译: 利用残差流激活分析，守护大型语言模型免遭攻击之扰](2024年06月05日/Defending_Large_Language_Models_Against_Attacks_With_Residual_Stream_Activation_Analysis.md)

- [Text-like Encoding of Collaborative Information in Large Language Models for Recommendation](2024年06月05日/Text-like_Encoding_of_Collaborative_Information_in_Large_Language_Models_for_Recommendation.md)

    - [翻译: 大规模语言模型中，采用类似文本的方式编码协作信息，以优化推荐系统。](2024年06月05日/Text-like_Encoding_of_Collaborative_Information_in_Large_Language_Models_for_Recommendation.md)

- [Missci: Reconstructing Fallacies in Misrepresented Science](2024年06月05日/Missci_Reconstructing_Fallacies_in_Misrepresented_Science.md)

    - [翻译: Missci：揭秘科学误解中的谬论](2024年06月05日/Missci_Reconstructing_Fallacies_in_Misrepresented_Science.md)

- [StatBot.Swiss: Bilingual Open Data Exploration in Natural Language](2024年06月05日/StatBot.Swiss_Bilingual_Open_Data_Exploration_in_Natural_Language.md)

    - [翻译: StatBot.Swiss：自然语言环境下的双语开放数据探索平台](2024年06月05日/StatBot.Swiss_Bilingual_Open_Data_Exploration_in_Natural_Language.md)

- [CSS: Contrastive Semantic Similarity for Uncertainty Quantification of LLMs](2024年06月05日/CSS_Contrastive_Semantic_Similarity_for_Uncertainty_Quantification_of_LLMs.md)

    - [翻译: CSS：大型语言模型不确定性量化中的对比语义相似性](2024年06月05日/CSS_Contrastive_Semantic_Similarity_for_Uncertainty_Quantification_of_LLMs.md)

- [Which Side Are You On? A Multi-task Dataset for End-to-End Argument Summarisation and Evaluation](2024年06月05日/Which_Side_Are_You_On_A_Multi-task_Dataset_for_End-to-End_Argument_Summarisation_and_Evaluation.md)

    - [翻译: 你支持哪一方？一款专为端到端论证摘要与评估打造的多任务数据集](2024年06月05日/Which_Side_Are_You_On_A_Multi-task_Dataset_for_End-to-End_Argument_Summarisation_and_Evaluation.md)

- [MESS: Modern Electronic Structure Simulations](2024年06月05日/MESS_Modern_Electronic_Structure_Simulations.md)

    - [翻译: MESS：现代电子结构模拟探索](2024年06月05日/MESS_Modern_Electronic_Structure_Simulations.md)

- [GET: A Generative EEG Transformer for continuous context-based neural](2024年06月05日/GET_A_Generative_EEG_Transformer_for_continuous_context-based_neural.md)

    - [翻译: GET：一种生成性脑电图Transformer，专为连续基于上下文的神经信号处理而设计。](2024年06月05日/GET_A_Generative_EEG_Transformer_for_continuous_context-based_neural.md)

- [FragRel: Exploiting Fragment-level Relations in the External Memory of Large Language Models](2024年06月05日/FragRel_Exploiting_Fragment-level_Relations_in_the_External_Memory_of_Large_Language_Models.md)

    - [翻译: FragRel：挖掘大型语言模型外部存储中片段间的深层联系](2024年06月05日/FragRel_Exploiting_Fragment-level_Relations_in_the_External_Memory_of_Large_Language_Models.md)

- [Exploring User Retrieval Integration towards Large Language Models for Cross-Domain Sequential Recommendation](2024年06月05日/Exploring_User_Retrieval_Integration_towards_Large_Language_Models_for_Cross-Domain_Sequential_Recommendation.md)

    - [翻译: 研究如何通过整合用户检索信息，提升大型语言模型在跨领域序列推荐中的性能](2024年06月05日/Exploring_User_Retrieval_Integration_towards_Large_Language_Models_for_Cross-Domain_Sequential_Recommendation.md)

- [Cryptocurrency Frauds for Dummies: How ChatGPT introduces us to fraud?](2024年06月05日/Cryptocurrency_Frauds_for_Dummies_How_ChatGPT_introduces_us_to_fraud.md)

    - [翻译: 加密货币欺诈简易指南：ChatGPT 如何揭露欺诈行为？](2024年06月05日/Cryptocurrency_Frauds_for_Dummies_How_ChatGPT_introduces_us_to_fraud.md)

- [Towards Detecting LLMs Hallucination via Markov Chain-based Multi-agent Debate Framework](2024年06月05日/Towards_Detecting_LLMs_Hallucination_via_Markov_Chain-based_Multi-agent_Debate_Framework.md)

    - [翻译: 利用基于马尔可夫链的多智能体辩论框架，探索检测大型语言模型幻觉的新途径](2024年06月05日/Towards_Detecting_LLMs_Hallucination_via_Markov_Chain-based_Multi-agent_Debate_Framework.md)

- [How Truncating Weights Improves Reasoning in Language Models](2024年06月05日/How_Truncating_Weights_Improves_Reasoning_in_Language_Models.md)

    - [翻译: 截断权重：提升语言模型推理能力的秘诀](2024年06月05日/How_Truncating_Weights_Improves_Reasoning_in_Language_Models.md)

- [RadBARTsum: Domain Specific Adaption of Denoising Sequence-to-Sequence Models for Abstractive Radiology Report Summarization](2024年06月05日/RadBARTsum_Domain_Specific_Adaption_of_Denoising_Sequence-to-Sequence_Models_for_Abstractive_Radiology_Report_Summarization.md)

    - [翻译: RadBARTsum：专为放射学报告摘要定制的去噪序列到序列模型领域适应方案](2024年06月05日/RadBARTsum_Domain_Specific_Adaption_of_Denoising_Sequence-to-Sequence_Models_for_Abstractive_Radiology_Report_Summarization.md)

- [From Tarzan to Tolkien: Controlling the Language Proficiency Level of LLMs for Content Generation](2024年06月05日/From_Tarzan_to_Tolkien_Controlling_the_Language_Proficiency_Level_of_LLMs_for_Content_Generation.md)

    - [翻译: 从泰山到托尔金：驾驭大型语言模型，定制内容生成的语言熟练度](2024年06月05日/From_Tarzan_to_Tolkien_Controlling_the_Language_Proficiency_Level_of_LLMs_for_Content_Generation.md)

- [Unveiling Selection Biases: Exploring Order and Token Sensitivity in Large Language Models](2024年06月05日/Unveiling_Selection_Biases_Exploring_Order_and_Token_Sensitivity_in_Large_Language_Models.md)

    - [翻译: 揭秘选择偏差：探究大型语言模型对顺序与令牌的敏感性](2024年06月05日/Unveiling_Selection_Biases_Exploring_Order_and_Token_Sensitivity_in_Large_Language_Models.md)

- [BadAgent: Inserting and Activating Backdoor Attacks in LLM Agents](2024年06月05日/BadAgent_Inserting_and_Activating_Backdoor_Attacks_in_LLM_Agents.md)

    - [翻译: BadAgent：潜入LLM代理的后门攻击激活术](2024年06月05日/BadAgent_Inserting_and_Activating_Backdoor_Attacks_in_LLM_Agents.md)

- [Evaluation of data inconsistency for multi-modal sentiment analysis](2024年06月05日/Evaluation_of_data_inconsistency_for_multi-modal_sentiment_analysis.md)

    - [翻译: 评估多模态情感分析中的数据一致性问题](2024年06月05日/Evaluation_of_data_inconsistency_for_multi-modal_sentiment_analysis.md)

- [Verified Code Transpilation with LLMs](2024年06月05日/Verified_Code_Transpilation_with_LLMs.md)

    - [翻译: 大型语言模型（LLMs）助力验证代码转译，确保代码转换的准确性与可靠性。](2024年06月05日/Verified_Code_Transpilation_with_LLMs.md)

- [Filtered not Mixed: Stochastic Filtering-Based Online Gating for Mixture of Large Language Models](2024年06月05日/Filtered_not_Mixed_Stochastic_Filtering-Based_Online_Gating_for_Mixture_of_Large_Language_Models.md)

    - [翻译: 随机过滤而非混合：大型语言模型的在线门控机制](2024年06月05日/Filtered_not_Mixed_Stochastic_Filtering-Based_Online_Gating_for_Mixture_of_Large_Language_Models.md)

- [Adversarial Moment-Matching Distillation of Large Language Models](2024年06月05日/Adversarial_Moment-Matching_Distillation_of_Large_Language_Models.md)

    - [翻译: 大型语言模型的对抗性时刻匹配蒸馏](2024年06月05日/Adversarial_Moment-Matching_Distillation_of_Large_Language_Models.md)

- [PrE-Text: Training Language Models on Private Federated Data in the Age of LLMs](2024年06月05日/PrE-Text_Training_Language_Models_on_Private_Federated_Data_in_the_Age_of_LLMs.md)

    - [翻译: PrE-Text：大型语言模型时代下的私有联邦数据语言模型训练](2024年06月05日/PrE-Text_Training_Language_Models_on_Private_Federated_Data_in_the_Age_of_LLMs.md)

- [The Task-oriented Queries Benchmark (ToQB)](2024年06月05日/The_Task-oriented_Queries_Benchmark_(ToQB).md)

    - [翻译: 任务导向查询基准（ToQB），专注于评估和提升针对特定任务的查询性能。](2024年06月05日/The_Task-oriented_Queries_Benchmark_(ToQB).md)

- [Addressing Index Collapse of Large-Codebook Speech Tokenizer with Dual-Decoding Product-Quantized Variational Auto-Encoder](2024年06月05日/Addressing_Index_Collapse_of_Large-Codebook_Speech_Tokenizer_with_Dual-Decoding_Product-Quantized_Variational_Auto-Encoder.md)

    - [翻译: 利用双解码产品量化变分自编码器，有效应对大型码本语音分词器中的索引崩溃挑战](2024年06月05日/Addressing_Index_Collapse_of_Large-Codebook_Speech_Tokenizer_with_Dual-Decoding_Product-Quantized_Variational_Auto-Encoder.md)

- [SYN2REAL: Leveraging Task Arithmetic for Mitigating Synthetic-Real Discrepancies in ASR Domain Adaptation](2024年06月05日/SYN2REAL_Leveraging_Task_Arithmetic_for_Mitigating_Synthetic-Real_Discrepancies_in_ASR_Domain_Adaptation.md)

    - [翻译: SYN2REAL：借助任务算术，缓解自动语音识别领域适应中的合成与真实数据差异](2024年06月05日/SYN2REAL_Leveraging_Task_Arithmetic_for_Mitigating_Synthetic-Real_Discrepancies_in_ASR_Domain_Adaptation.md)

- [Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large Language Models](2024年06月05日/Pruner-Zero_Evolving_Symbolic_Pruning_Metric_from_scratch_for_Large_Language_Models.md)

    - [翻译: Pruner-Zero：为大型语言模型量身定制，从零开始演化符号剪枝指标](2024年06月05日/Pruner-Zero_Evolving_Symbolic_Pruning_Metric_from_scratch_for_Large_Language_Models.md)

- [MultifacetEval: Multifaceted Evaluation to Probe LLMs in Mastering Medical Knowledge](2024年06月05日/MultifacetEval_Multifaceted_Evaluation_to_Probe_LLMs_in_Mastering_Medical_Knowledge.md)

    - [翻译: MultifacetEval：探究大型语言模型医学知识掌握度的多维度评估](2024年06月05日/MultifacetEval_Multifaceted_Evaluation_to_Probe_LLMs_in_Mastering_Medical_Knowledge.md)

- [Visual-Text Cross Alignment: Refining the Similarity Score in Vision-Language Models](2024年06月05日/Visual-Text_Cross_Alignment_Refining_the_Similarity_Score_in_Vision-Language_Models.md)

    - [翻译: 视觉与文本的精准对齐：提升视觉-语言模型中的相似度评分精度](2024年06月05日/Visual-Text_Cross_Alignment_Refining_the_Similarity_Score_in_Vision-Language_Models.md)

- [Zeroth-Order Fine-Tuning of LLMs with Extreme Sparsity](2024年06月05日/Zeroth-Order_Fine-Tuning_of_LLMs_with_Extreme_Sparsity.md)

    - [翻译: 极简稀疏下的零阶微调：大型语言模型的精炼之道](2024年06月05日/Zeroth-Order_Fine-Tuning_of_LLMs_with_Extreme_Sparsity.md)

- [Improving In-Context Learning with Prediction Feedback for Sentiment Analysis](2024年06月05日/Improving_In-Context_Learning_with_Prediction_Feedback_for_Sentiment_Analysis.md)

    - [翻译: 借助预测反馈优化情境学习，提升情感分析效果](2024年06月05日/Improving_In-Context_Learning_with_Prediction_Feedback_for_Sentiment_Analysis.md)

- [AD-H: Autonomous Driving with Hierarchical Agents](2024年06月05日/AD-H_Autonomous_Driving_with_Hierarchical_Agents.md)

    - [翻译: AD-H：分层代理驱动的自主驾驶技术](2024年06月05日/AD-H_Autonomous_Driving_with_Hierarchical_Agents.md)

- [Wings: Learning Multimodal LLMs without Text-only Forgetting](2024年06月05日/Wings_Learning_Multimodal_LLMs_without_Text-only_Forgetting.md)

    - [翻译: Wings：无文本遗忘的多模态LLM学习之旅](2024年06月05日/Wings_Learning_Multimodal_LLMs_without_Text-only_Forgetting.md)

- [Seq1F1B: Efficient Sequence-Level Pipeline Parallelism for Large Language Model Training](2024年06月05日/Seq1F1B_Efficient_Sequence-Level_Pipeline_Parallelism_for_Large_Language_Model_Training.md)

    - [翻译: Seq1F1B：大型语言模型训练的高效序列级流水线并行策略](2024年06月05日/Seq1F1B_Efficient_Sequence-Level_Pipeline_Parallelism_for_Large_Language_Model_Training.md)

- [Analyzing LLM Behavior in Dialogue Summarization: Unveiling Circumstantial Hallucination Trends](2024年06月05日/Analyzing_LLM_Behavior_in_Dialogue_Summarization_Unveiling_Circumstantial_Hallucination_Trends.md)

    - [翻译: 探究大型语言模型在对话摘要中的行为，揭秘情境性幻觉的演变趋势](2024年06月05日/Analyzing_LLM_Behavior_in_Dialogue_Summarization_Unveiling_Circumstantial_Hallucination_Trends.md)

- [BIPED: Pedagogically Informed Tutoring System for ESL Education](2024年06月05日/BIPED_Pedagogically_Informed_Tutoring_System_for_ESL_Education.md)

    - [翻译: BIPED：教育学指导下的英语二语教学系统](2024年06月05日/BIPED_Pedagogically_Informed_Tutoring_System_for_ESL_Education.md)

- [Does your data spark joy? Performance gains from domain upsampling at the end of training](2024年06月05日/Does_your_data_spark_joy_Performance_gains_from_domain_upsampling_at_the_end_of_training.md)

    - [翻译: 你的数据是否点燃了喜悦？在训练尾声通过领域上采样获得的性能飞跃](2024年06月05日/Does_your_data_spark_joy_Performance_gains_from_domain_upsampling_at_the_end_of_training.md)

- [What is the Best Way for ChatGPT to Translate Poetry?](2024年06月05日/What_is_the_Best_Way_for_ChatGPT_to_Translate_Poetry.md)

    - [翻译: 如何让ChatGPT最优雅地翻译诗歌？](2024年06月05日/What_is_the_Best_Way_for_ChatGPT_to_Translate_Poetry.md)

- [Pre-trained Large Language Models Use Fourier Features to Compute Addition](2024年06月05日/Pre-trained_Large_Language_Models_Use_Fourier_Features_to_Compute_Addition.md)

    - [翻译: 大型预训练语言模型采用傅里叶特征进行加法运算。](2024年06月05日/Pre-trained_Large_Language_Models_Use_Fourier_Features_to_Compute_Addition.md)

- [Cycles of Thought: Measuring LLM Confidence through Stable Explanations](2024年06月05日/Cycles_of_Thought_Measuring_LLM_Confidence_through_Stable_Explanations.md)

    - [翻译: 思维循环：借助稳定解释洞察 LLM 信心](2024年06月05日/Cycles_of_Thought_Measuring_LLM_Confidence_through_Stable_Explanations.md)

- [Interactive Text-to-Image Retrieval with Large Language Models: A Plug-and-Play Approach](2024年06月05日/Interactive_Text-to-Image_Retrieval_with_Large_Language_Models_A_Plug-and-Play_Approach.md)

    - [翻译: 大型语言模型下的交互式文本转图像检索：即插即用新策略](2024年06月05日/Interactive_Text-to-Image_Retrieval_with_Large_Language_Models_A_Plug-and-Play_Approach.md)

- [Automating Turkish Educational Quiz Generation Using Large Language Models](2024年06月05日/Automating_Turkish_Educational_Quiz_Generation_Using_Large_Language_Models.md)

    - [翻译: 利用大型语言模型自动生成土耳其教育测验内容](2024年06月05日/Automating_Turkish_Educational_Quiz_Generation_Using_Large_Language_Models.md)

- [Log Parsing with Self-Generated In-Context Learning and Self-Correction](2024年06月05日/Log_Parsing_with_Self-Generated_In-Context_Learning_and_Self-Correction.md)

    - [翻译: 利用自我生成的上下文学习与自我校正技术进行日志解析](2024年06月05日/Log_Parsing_with_Self-Generated_In-Context_Learning_and_Self-Correction.md)

- [IrokoBench: A New Benchmark for African Languages in the Age of Large Language Models](2024年06月05日/IrokoBench_A_New_Benchmark_for_African_Languages_in_the_Age_of_Large_Language_Models.md)

    - [翻译: IrokoBench：大型语言模型时代中非洲语言的新评测标杆](2024年06月05日/IrokoBench_A_New_Benchmark_for_African_Languages_in_the_Age_of_Large_Language_Models.md)

- [CLMASP: Coupling Large Language Models with Answer Set Programming for Robotic Task Planning](2024年06月05日/CLMASP_Coupling_Large_Language_Models_with_Answer_Set_Programming_for_Robotic_Task_Planning.md)

    - [翻译: CLMASP：结合大型语言模型与答案集编程，助力机器人任务规划](2024年06月05日/CLMASP_Coupling_Large_Language_Models_with_Answer_Set_Programming_for_Robotic_Task_Planning.md)

- [LLM-based Rewriting of Inappropriate Argumentation using Reinforcement Learning from Machine Feedback](2024年06月05日/LLM-based_Rewriting_of_Inappropriate_Argumentation_using_Reinforcement_Learning_from_Machine_Feedback.md)

    - [翻译: 利用大型语言模型（LLM）结合机器反馈的强化学习，重塑不当论证](2024年06月05日/LLM-based_Rewriting_of_Inappropriate_Argumentation_using_Reinforcement_Learning_from_Machine_Feedback.md)

- [LLMEmbed: Rethinking Lightweight LLM's Genuine Function in Text Classification](2024年06月05日/LLMEmbed_Rethinking_Lightweight_LLM's_Genuine_Function_in_Text_Classification.md)

    - [翻译: LLMEmbed：探索轻量级LLM在文本分类中的核心价值](2024年06月05日/LLMEmbed_Rethinking_Lightweight_LLM's_Genuine_Function_in_Text_Classification.md)

- [Generalization-Enhanced Code Vulnerability Detection via Multi-Task Instruction Fine-Tuning](2024年06月05日/Generalization-Enhanced_Code_Vulnerability_Detection_via_Multi-Task_Instruction_Fine-Tuning.md)

    - [翻译: 利用多任务指令微调提升代码漏洞检测的泛化能力](2024年06月05日/Generalization-Enhanced_Code_Vulnerability_Detection_via_Multi-Task_Instruction_Fine-Tuning.md)

- [Retrieval Augmented Generation in Prompt-based Text-to-Speech Synthesis with Context-Aware Contrastive Language-Audio Pretraining](2024年06月05日/Retrieval_Augmented_Generation_in_Prompt-based_Text-to-Speech_Synthesis_with_Context-Aware_Contrastive_Language-Audio_Pretraining.md)

    - [翻译: 在基于提示的文本到语音合成领域，通过上下文感知对比语言-音频预训练，实现了检索增强的生成技术。](2024年06月05日/Retrieval_Augmented_Generation_in_Prompt-based_Text-to-Speech_Synthesis_with_Context-Aware_Contrastive_Language-Audio_Pretraining.md)

- [A Survey on Medical Large Language Models: Technology, Application, Trustworthiness, and Future Directions](2024年06月05日/A_Survey_on_Medical_Large_Language_Models_Technology,_Application,_Trustworthiness,_and_Future_Directions.md)

    - [翻译: 医学大型语言模型综览：技术探索、应用实践、信任构建与未来展望](2024年06月05日/A_Survey_on_Medical_Large_Language_Models_Technology,_Application,_Trustworthiness,_and_Future_Directions.md)

- [What Should Embeddings Embed? Autoregressive Models Represent Latent Generating Distributions](2024年06月05日/What_Should_Embeddings_Embed_Autoregressive_Models_Represent_Latent_Generating_Distributions.md)

    - [翻译: 嵌入之问：自回归模型如何捕捉潜在生成之秘？](2024年06月05日/What_Should_Embeddings_Embed_Autoregressive_Models_Represent_Latent_Generating_Distributions.md)

- [Improving Audio Codec-based Zero-Shot Text-to-Speech Synthesis with Multi-Modal Context and Large Language Model](2024年06月05日/Improving_Audio_Codec-based_Zero-Shot_Text-to-Speech_Synthesis_with_Multi-Modal_Context_and_Large_Language_Model.md)

    - [翻译: 借助多模态上下文与大型语言模型，优化基于音频编解码器的零-shot文本到语音合成技术](2024年06月05日/Improving_Audio_Codec-based_Zero-Shot_Text-to-Speech_Synthesis_with_Multi-Modal_Context_and_Large_Language_Model.md)

- [Recognizing Everything from All Modalities at Once: Grounded Multimodal Universal Information Extraction](2024年06月05日/Recognizing_Everything_from_All_Modalities_at_Once_Grounded_Multimodal_Universal_Information_Extraction.md)

    - [翻译: 全面识别多模态信息：基于基础的多模态通用信息提取](2024年06月05日/Recognizing_Everything_from_All_Modalities_at_Once_Grounded_Multimodal_Universal_Information_Extraction.md)

- [M-QALM: A Benchmark to Assess Clinical Reading Comprehension and Knowledge Recall in Large Language Models via Question Answering](2024年06月05日/M-QALM_A_Benchmark_to_Assess_Clinical_Reading_Comprehension_and_Knowledge_Recall_in_Large_Language_Models_via_Question_Answering.md)

    - [翻译: M-QALM：大型语言模型临床阅读理解与知识回忆的问答评估基准。](2024年06月05日/M-QALM_A_Benchmark_to_Assess_Clinical_Reading_Comprehension_and_Knowledge_Recall_in_Large_Language_Models_via_Question_Answering.md)

- [Evaluating Durability: Benchmark Insights into Multimodal Watermarking](2024年06月05日/Evaluating_Durability_Benchmark_Insights_into_Multimodal_Watermarking.md)

    - [翻译: 探究耐久性：多模态水印技术的基准启示](2024年06月05日/Evaluating_Durability_Benchmark_Insights_into_Multimodal_Watermarking.md)

- [Shadow and Light: Digitally Reconstructed Radiographs for Disease Classification](2024年06月05日/Shadow_and_Light_Digitally_Reconstructed_Radiographs_for_Disease_Classification.md)

    - [翻译: 光影交织：数字重建放射图像助力疾病分类](2024年06月05日/Shadow_and_Light_Digitally_Reconstructed_Radiographs_for_Disease_Classification.md)

- [Ranking Manipulation for Conversational Search Engines](2024年06月05日/Ranking_Manipulation_for_Conversational_Search_Engines.md)

    - [翻译: 对话搜索引擎中的排名操控策略](2024年06月05日/Ranking_Manipulation_for_Conversational_Search_Engines.md)

- [Evaluating the World Model Implicit in a Generative Model](2024年06月05日/Evaluating_the_World_Model_Implicit_in_a_Generative_Model.md)

    - [翻译: 探究生成模型内含的世界模型之评估](2024年06月05日/Evaluating_the_World_Model_Implicit_in_a_Generative_Model.md)

- [Refactoring to Pythonic Idioms: A Hybrid Knowledge-Driven Approach Leveraging Large Language Models](2024年06月05日/Refactoring_to_Pythonic_Idioms_A_Hybrid_Knowledge-Driven_Approach_Leveraging_Large_Language_Models.md)

    - [翻译: 利用大型语言模型，探索 Pythonic 惯用法的重构之道：一种混合知识驱动的新途径](2024年06月05日/Refactoring_to_Pythonic_Idioms_A_Hybrid_Knowledge-Driven_Approach_Leveraging_Large_Language_Models.md)

- [Synthetic Oversampling: Theory and A Practical Approach Using LLMs to Address Data Imbalance](2024年06月05日/Synthetic_Oversampling_Theory_and_A_Practical_Approach_Using_LLMs_to_Address_Data_Imbalance.md)

    - [翻译: 合成过采样：理论与实践——利用大型语言模型应对数据不平衡挑战](2024年06月05日/Synthetic_Oversampling_Theory_and_A_Practical_Approach_Using_LLMs_to_Address_Data_Imbalance.md)

2024年06月04日

- [MARS: Benchmarking the Metaphysical Reasoning Abilities of Language Models with a Multi-task Evaluation Dataset](2024年06月04日/MARS_Benchmarking_the_Metaphysical_Reasoning_Abilities_of_Language_Models_with_a_Multi-task_Evaluation_Dataset.md)

    - [翻译: MARS：通过多任务评估数据集，衡量语言模型在形而上学推理上的能力](2024年06月04日/MARS_Benchmarking_the_Metaphysical_Reasoning_Abilities_of_Language_Models_with_a_Multi-task_Evaluation_Dataset.md)

- [Multimodal Reasoning with Multimodal Knowledge Graph](2024年06月04日/Multimodal_Reasoning_with_Multimodal_Knowledge_Graph.md)

    - [翻译: 融合多模态知识图谱的推理探索](2024年06月04日/Multimodal_Reasoning_with_Multimodal_Knowledge_Graph.md)

- [LlamaCare: A Large Medical Language Model for Enhancing Healthcare Knowledge Sharing](2024年06月04日/LlamaCare_A_Large_Medical_Language_Model_for_Enhancing_Healthcare_Knowledge_Sharing.md)

    - [翻译: LlamaCare：大型医学语言模型，助力医疗知识共享](2024年06月04日/LlamaCare_A_Large_Medical_Language_Model_for_Enhancing_Healthcare_Knowledge_Sharing.md)

- [Technical Language Processing for Telecommunications Specifications](2024年06月04日/Technical_Language_Processing_for_Telecommunications_Specifications.md)

    - [翻译: 电信规范中的技术语言处理](2024年06月04日/Technical_Language_Processing_for_Telecommunications_Specifications.md)

- [mCoT: Multilingual Instruction Tuning for Reasoning Consistency in Language Models](2024年06月04日/mCoT_Multilingual_Instruction_Tuning_for_Reasoning_Consistency_in_Language_Models.md)

    - [翻译: mCoT：通过多语言指令调优，确保语言模型推理的一致性](2024年06月04日/mCoT_Multilingual_Instruction_Tuning_for_Reasoning_Consistency_in_Language_Models.md)

- [A Study of Optimizations for Fine-tuning Large Language Models](2024年06月04日/A_Study_of_Optimizations_for_Fine-tuning_Large_Language_Models.md)

    - [翻译: 探索大型语言模型微调优化之道](2024年06月04日/A_Study_of_Optimizations_for_Fine-tuning_Large_Language_Models.md)

- [Prompting Large Language Models with Human Error Markings for Self-Correcting Machine Translation](2024年06月04日/Prompting_Large_Language_Models_with_Human_Error_Markings_for_Self-Correcting_Machine_Translation.md)

    - [翻译: 借助人类错误标记，引导大型语言模型自我修正机器翻译](2024年06月04日/Prompting_Large_Language_Models_with_Human_Error_Markings_for_Self-Correcting_Machine_Translation.md)

- [MidiCaps -- A large-scale MIDI dataset with text captions](2024年06月04日/MidiCaps_--_A_large-scale_MIDI_dataset_with_text_captions.md)

    - [翻译: MidiCaps —— 大型 MIDI 数据集，附带文本描述](2024年06月04日/MidiCaps_--_A_large-scale_MIDI_dataset_with_text_captions.md)

- [FedMKT: Federated Mutual Knowledge Transfer for Large and Small Language Models](2024年06月04日/FedMKT_Federated_Mutual_Knowledge_Transfer_for_Large_and_Small_Language_Models.md)

    - [翻译: FedMKT：大型与小型语言模型间的联邦互知识转移](2024年06月04日/FedMKT_Federated_Mutual_Knowledge_Transfer_for_Large_and_Small_Language_Models.md)

- [SLTrain: a sparse plus low-rank approach for parameter and memory efficient pretraining](2024年06月04日/SLTrain_a_sparse_plus_low-rank_approach_for_parameter_and_memory_efficient_pretraining.md)

    - [翻译: SLTrain：采用稀疏加低秩策略，实现参数与内存双重高效的预训练方法](2024年06月04日/SLTrain_a_sparse_plus_low-rank_approach_for_parameter_and_memory_efficient_pretraining.md)

- [Generative Pre-Trained Diffusion Paradigm for Zero-Shot Time Series Forecasting](2024年06月04日/Generative_Pre-Trained_Diffusion_Paradigm_for_Zero-Shot_Time_Series_Forecasting.md)

    - [翻译: 零-shot时间序列预测的生成预训练扩散范式](2024年06月04日/Generative_Pre-Trained_Diffusion_Paradigm_for_Zero-Shot_Time_Series_Forecasting.md)

- [Synergetic Event Understanding: A Collaborative Approach to Cross-Document Event Coreference Resolution with Large Language Models](2024年06月04日/Synergetic_Event_Understanding_A_Collaborative_Approach_to_Cross-Document_Event_Coreference_Resolution_with_Large_Language_Models.md)

    - [翻译: 协同事件理解：借助大型语言模型，探索跨文档事件共指消解的协作新途径](2024年06月04日/Synergetic_Event_Understanding_A_Collaborative_Approach_to_Cross-Document_Event_Coreference_Resolution_with_Large_Language_Models.md)

- [Reinforcement Tuning for Detecting Stances and Debunking Rumors Jointly with Large Language Models](2024年06月04日/Reinforcement_Tuning_for_Detecting_Stances_and_Debunking_Rumors_Jointly_with_Large_Language_Models.md)

    - [翻译: 利用强化调整，大型语言模型能同时检测立场并揭穿谣言](2024年06月04日/Reinforcement_Tuning_for_Detecting_Stances_and_Debunking_Rumors_Jointly_with_Large_Language_Models.md)

- [The current status of large language models in summarizing radiology report impressions](2024年06月04日/The_current_status_of_large_language_models_in_summarizing_radiology_report_impressions.md)

    - [翻译: 当前大型语言模型在提炼放射学报告核心印象方面的表现](2024年06月04日/The_current_status_of_large_language_models_in_summarizing_radiology_report_impressions.md)

- [Iteration Head: A Mechanistic Study of Chain-of-Thought](2024年06月04日/Iteration_Head_A_Mechanistic_Study_of_Chain-of-Thought.md)

    - [翻译: 探究思维链机制：迭代头研究](2024年06月04日/Iteration_Head_A_Mechanistic_Study_of_Chain-of-Thought.md)

- [Diver: Large Language Model Decoding with Span-Level Mutual Information Verification](2024年06月04日/Diver_Large_Language_Model_Decoding_with_Span-Level_Mutual_Information_Verification.md)

    - [翻译: Diver：利用跨度级互信息验证优化大型语言模型解码](2024年06月04日/Diver_Large_Language_Model_Decoding_with_Span-Level_Mutual_Information_Verification.md)

- [UniOQA: A Unified Framework for Knowledge Graph Question Answering with Large Language Models](2024年06月04日/UniOQA_A_Unified_Framework_for_Knowledge_Graph_Question_Answering_with_Large_Language_Models.md)

    - [翻译: UniOQA：大型语言模型下的知识图谱问答统一框架](2024年06月04日/UniOQA_A_Unified_Framework_for_Knowledge_Graph_Question_Answering_with_Large_Language_Models.md)

- [Exploring Mathematical Extrapolation of Large Language Models with Synthetic Data](2024年06月04日/Exploring_Mathematical_Extrapolation_of_Large_Language_Models_with_Synthetic_Data.md)

    - [翻译: 借助合成数据，探索大型语言模型的数学外推能力](2024年06月04日/Exploring_Mathematical_Extrapolation_of_Large_Language_Models_with_Synthetic_Data.md)

- [Assessing the Performance of Chinese Open Source Large Language Models in Information Extraction Tasks](2024年06月04日/Assessing_the_Performance_of_Chinese_Open_Source_Large_Language_Models_in_Information_Extraction_Tasks.md)

    - [翻译: 探究中国开源大型语言模型在信息提取领域的性能表现](2024年06月04日/Assessing_the_Performance_of_Chinese_Open_Source_Large_Language_Models_in_Information_Extraction_Tasks.md)

- [PyramidKV: Dynamic KV Cache Compression based on Pyramidal Information Funneling](2024年06月04日/PyramidKV_Dynamic_KV_Cache_Compression_based_on_Pyramidal_Information_Funneling.md)

    - [翻译: PyramidKV：利用金字塔信息汇聚实现动态KV缓存的高效压缩](2024年06月04日/PyramidKV_Dynamic_KV_Cache_Compression_based_on_Pyramidal_Information_Funneling.md)

- [Alice in Wonderland: Simple Tasks Showing Complete Reasoning Breakdown in State-Of-the-Art Large Language Models](2024年06月04日/Alice_in_Wonderland_Simple_Tasks_Showing_Complete_Reasoning_Breakdown_in_State-Of-the-Art_Large_Language_Models.md)

    - [翻译: 《爱丽丝梦游仙境》揭示：顶尖大型语言模型在简单任务上遭遇全面推理失效。](2024年06月04日/Alice_in_Wonderland_Simple_Tasks_Showing_Complete_Reasoning_Breakdown_in_State-Of-the-Art_Large_Language_Models.md)

- [I've got the "Answer"! Interpretation of LLMs Hidden States in Question Answering](2024年06月04日/I've_got_the_Answer!_Interpretation_of_LLMs_Hidden_States_in_Question_Answering.md)

    - [翻译: 揭秘“答案”：探索大型语言模型在问答任务中隐藏状态的奥秘](2024年06月04日/I've_got_the_Answer!_Interpretation_of_LLMs_Hidden_States_in_Question_Answering.md)

- [Analyzing Social Biases in Japanese Large Language Models](2024年06月04日/Analyzing_Social_Biases_in_Japanese_Large_Language_Models.md)

    - [翻译: 探究日本大型语言模型中的社会偏见现象](2024年06月04日/Analyzing_Social_Biases_in_Japanese_Large_Language_Models.md)

- [QROA: A Black-Box Query-Response Optimization Attack on LLMs](2024年06月04日/QROA_A_Black-Box_Query-Response_Optimization_Attack_on_LLMs.md)

    - [翻译: QROA：大型语言模型遭遇的黑盒查询-响应优化攻击](2024年06月04日/QROA_A_Black-Box_Query-Response_Optimization_Attack_on_LLMs.md)

- [Why Would You Suggest That? Human Trust in Language Model Responses](2024年06月04日/Why_Would_You_Suggest_That_Human_Trust_in_Language_Model_Responses.md)

    - [翻译: 为何如此建议？探讨人类对语言模型回答的信任度](2024年06月04日/Why_Would_You_Suggest_That_Human_Trust_in_Language_Model_Responses.md)

- [Position Debiasing Fine-Tuning for Causal Perception in Long-Term Dialogue](2024年06月04日/Position_Debiasing_Fine-Tuning_for_Causal_Perception_in_Long-Term_Dialogue.md)

    - [翻译: 长期对话中因果感知的位置去偏差微调](2024年06月04日/Position_Debiasing_Fine-Tuning_for_Causal_Perception_in_Long-Term_Dialogue.md)

- [RKLD: Reverse KL-Divergence-based Knowledge Distillation for Unlearning Personal Information in Large Language Models](2024年06月04日/RKLD_Reverse_KL-Divergence-based_Knowledge_Distillation_for_Unlearning_Personal_Information_in_Large_Language_Models.md)

    - [翻译: RKLD：利用反向KL散度进行知识蒸馏，助力大语言模型遗忘个人敏感信息](2024年06月04日/RKLD_Reverse_KL-Divergence-based_Knowledge_Distillation_for_Unlearning_Personal_Information_in_Large_Language_Models.md)

- [Zyda: A 1.3T Dataset for Open Language Modeling](2024年06月04日/Zyda_A_1.3T_Dataset_for_Open_Language_Modeling.md)

    - [翻译: Zyda：开放语言建模的巨型数据集，容量高达1.3万亿条数据](2024年06月04日/Zyda_A_1.3T_Dataset_for_Open_Language_Modeling.md)

- [DrEureka: Language Model Guided Sim-To-Real Transfer](2024年06月04日/DrEureka_Language_Model_Guided_Sim-To-Real_Transfer.md)

    - [翻译: DrEureka：借助语言模型实现模拟向真实世界的无缝转移](2024年06月04日/DrEureka_Language_Model_Guided_Sim-To-Real_Transfer.md)

- [Analyzing Temporal Complex Events with Large Language Models? A Benchmark towards Temporal, Long Context Understanding](2024年06月04日/Analyzing_Temporal_Complex_Events_with_Large_Language_Models_A_Benchmark_towards_Temporal,_Long_Context_Understanding.md)

    - [翻译: 探究大型语言模型如何应对时间复杂事件？这一基准旨在深入理解时间与长上下文的关系。](2024年06月04日/Analyzing_Temporal_Complex_Events_with_Large_Language_Models_A_Benchmark_towards_Temporal,_Long_Context_Understanding.md)

- [Enhancing Retrieval-Augmented LMs with a Two-stage Consistency Learning Compressor](2024年06月04日/Enhancing_Retrieval-Augmented_LMs_with_a_Two-stage_Consistency_Learning_Compressor.md)

    - [翻译: 利用两阶段一致性学习压缩技术，提升检索增强语言模型的性能](2024年06月04日/Enhancing_Retrieval-Augmented_LMs_with_a_Two-stage_Consistency_Learning_Compressor.md)

- [Understanding Retrieval Robustness for Retrieval-Augmented Image Captioning](2024年06月04日/Understanding_Retrieval_Robustness_for_Retrieval-Augmented_Image_Captioning.md)

    - [翻译: 探究检索增强图像描述生成系统的检索鲁棒性](2024年06月04日/Understanding_Retrieval_Robustness_for_Retrieval-Augmented_Image_Captioning.md)

- [TopViewRS: Vision-Language Models as Top-View Spatial Reasoners](2024年06月04日/TopViewRS_Vision-Language_Models_as_Top-View_Spatial_Reasoners.md)

    - [翻译: TopViewRS：视觉-语言模型在顶视图空间推理中的应用](2024年06月04日/TopViewRS_Vision-Language_Models_as_Top-View_Spatial_Reasoners.md)

- [Leveraging Visual Tokens for Extended Text Contexts in Multi-Modal Learning](2024年06月04日/Leveraging_Visual_Tokens_for_Extended_Text_Contexts_in_Multi-Modal_Learning.md)

    - [翻译: 借助视觉令牌，拓展多模态学习中的文本上下文](2024年06月04日/Leveraging_Visual_Tokens_for_Extended_Text_Contexts_in_Multi-Modal_Learning.md)

- [Parrot: Multilingual Visual Instruction Tuning](2024年06月04日/Parrot_Multilingual_Visual_Instruction_Tuning.md)

    - [翻译: 鹦鹉计划：多语言视觉指令调优](2024年06月04日/Parrot_Multilingual_Visual_Instruction_Tuning.md)

- [GrootVL: Tree Topology is All You Need in State Space Model](2024年06月04日/GrootVL_Tree_Topology_is_All_You_Need_in_State_Space_Model.md)

    - [翻译: GrootVL：在状态空间模型中，树状拓扑结构至关重要。](2024年06月04日/GrootVL_Tree_Topology_is_All_You_Need_in_State_Space_Model.md)

- [Learning to grok: Emergence of in-context learning and skill composition in modular arithmetic tasks](2024年06月04日/Learning_to_grok_Emergence_of_in-context_learning_and_skill_composition_in_modular_arithmetic_tasks.md)

    - [翻译: 领悟之道：模块化算术任务中上下文学习与技能融合的崭露头角](2024年06月04日/Learning_to_grok_Emergence_of_in-context_learning_and_skill_composition_in_modular_arithmetic_tasks.md)

- [To Believe or Not to Believe Your LLM](2024年06月04日/To_Believe_or_Not_to_Believe_Your_LLM.md)

    - [翻译: 是否信任你的大型语言模型（LLM）？这是一个值得深思的问题。](2024年06月04日/To_Believe_or_Not_to_Believe_Your_LLM.md)

- [Loki: Low-Rank Keys for Efficient Sparse Attention](2024年06月04日/Loki_Low-Rank_Keys_for_Efficient_Sparse_Attention.md)

    - [翻译: Loki：低秩键助力高效稀疏注意力](2024年06月04日/Loki_Low-Rank_Keys_for_Efficient_Sparse_Attention.md)

- [Mitigate Position Bias in Large Language Models via Scaling a Single Dimension](2024年06月04日/Mitigate_Position_Bias_in_Large_Language_Models_via_Scaling_a_Single_Dimension.md)

    - [翻译: 通过单一维度扩展，缓解大型语言模型中的位置偏差问题](2024年06月04日/Mitigate_Position_Bias_in_Large_Language_Models_via_Scaling_a_Single_Dimension.md)

- [SpecExec: Massively Parallel Speculative Decoding for Interactive LLM Inference on Consumer Devices](2024年06月04日/SpecExec_Massively_Parallel_Speculative_Decoding_for_Interactive_LLM_Inference_on_Consumer_Devices.md)

    - [翻译: SpecExec：消费级设备上交互式大型语言模型推理的大规模并行推测解码技术](2024年06月04日/SpecExec_Massively_Parallel_Speculative_Decoding_for_Interactive_LLM_Inference_on_Consumer_Devices.md)

- [Scalable MatMul-free Language Modeling](2024年06月04日/Scalable_MatMul-free_Language_Modeling.md)

    - [翻译: 无需矩阵乘法的可扩展语言建模](2024年06月04日/Scalable_MatMul-free_Language_Modeling.md)

- [CheckEmbed: Effective Verification of LLM Solutions to Open-Ended Tasks](2024年06月04日/CheckEmbed_Effective_Verification_of_LLM_Solutions_to_Open-Ended_Tasks.md)

    - [翻译: CheckEmbed：大型语言模型开放式任务解决方案的有效验证工具](2024年06月04日/CheckEmbed_Effective_Verification_of_LLM_Solutions_to_Open-Ended_Tasks.md)

- [RoboCasa: Large-Scale Simulation of Everyday Tasks for Generalist Robots](2024年06月04日/RoboCasa_Large-Scale_Simulation_of_Everyday_Tasks_for_Generalist_Robots.md)

    - [翻译: RoboCasa：通用机器人日常任务的大规模模拟研究](2024年06月04日/RoboCasa_Large-Scale_Simulation_of_Everyday_Tasks_for_Generalist_Robots.md)

- [Demystifying the Compression of Mixture-of-Experts Through a Unified Framework](2024年06月04日/Demystifying_the_Compression_of_Mixture-of-Experts_Through_a_Unified_Framework.md)

    - [翻译: 揭秘混合专家模型压缩：统一框架下的探索](2024年06月04日/Demystifying_the_Compression_of_Mixture-of-Experts_Through_a_Unified_Framework.md)

- [Hiding Text in Large Language Models: Introducing Unconditional Token Forcing Confusion](2024年06月04日/Hiding_Text_in_Large_Language_Models_Introducing_Unconditional_Token_Forcing_Confusion.md)

    - [翻译: 在大规模语言模型中隐藏文本：探索无条件令牌强制混淆机制](2024年06月04日/Hiding_Text_in_Large_Language_Models_Introducing_Unconditional_Token_Forcing_Confusion.md)

- [Meta-Designing Quantum Experiments with Language Models](2024年06月04日/Meta-Designing_Quantum_Experiments_with_Language_Models.md)

    - [翻译: 语言模型助力量子实验的元设计探索](2024年06月04日/Meta-Designing_Quantum_Experiments_with_Language_Models.md)

- [Representations as Language: An Information-Theoretic Framework for Interpretability](2024年06月04日/Representations_as_Language_An_Information-Theoretic_Framework_for_Interpretability.md)

    - [翻译: 语言化表示：基于信息理论的解释性框架](2024年06月04日/Representations_as_Language_An_Information-Theoretic_Framework_for_Interpretability.md)

- [Generative Active Learning for Long-tailed Instance Segmentation](2024年06月04日/Generative_Active_Learning_for_Long-tailed_Instance_Segmentation.md)

    - [翻译: 利用生成式主动学习优化长尾实例分割](2024年06月04日/Generative_Active_Learning_for_Long-tailed_Instance_Segmentation.md)

- [Seed-TTS: A Family of High-Quality Versatile Speech Generation Models](2024年06月04日/Seed-TTS_A_Family_of_High-Quality_Versatile_Speech_Generation_Models.md)

    - [翻译: Seed-TTS：一系列既高质量又多功能的语音生成模型，旨在满足各种语音合成需求。](2024年06月04日/Seed-TTS_A_Family_of_High-Quality_Versatile_Speech_Generation_Models.md)

- [Multiple Choice Questions and Large Languages Models: A Case Study with Fictional Medical Data](2024年06月04日/Multiple_Choice_Questions_and_Large_Languages_Models_A_Case_Study_with_Fictional_Medical_Data.md)

    - [翻译: 大型语言模型在多项选择题中的应用：虚构医疗数据案例探析](2024年06月04日/Multiple_Choice_Questions_and_Large_Languages_Models_A_Case_Study_with_Fictional_Medical_Data.md)

- [On the Intrinsic Self-Correction Capability of LLMs: Uncertainty and Latent Concept](2024年06月04日/On_the_Intrinsic_Self-Correction_Capability_of_LLMs_Uncertainty_and_Latent_Concept.md)

    - [翻译: 大型语言模型（LLMs）的内在自我校正能力探究：不确定性与潜在概念之谜](2024年06月04日/On_the_Intrinsic_Self-Correction_Capability_of_LLMs_Uncertainty_and_Latent_Concept.md)

- [XRec: Large Language Models for Explainable Recommendation](2024年06月04日/XRec_Large_Language_Models_for_Explainable_Recommendation.md)

    - [翻译: XRec：利用大型语言模型实现推荐系统的透明解析](2024年06月04日/XRec_Large_Language_Models_for_Explainable_Recommendation.md)

- [Retaining Key Information under High Compression Ratios: Query-Guided Compressor for LLMs](2024年06月04日/Retaining_Key_Information_under_High_Compression_Ratios_Query-Guided_Compressor_for_LLMs.md)

    - [翻译: 在极高压缩比下，如何确保关键信息不丢失？针对LLMs，我们提出了一种查询引导的压缩器，旨在优化信息保留。](2024年06月04日/Retaining_Key_Information_under_High_Compression_Ratios_Query-Guided_Compressor_for_LLMs.md)

- [Large Language Models Make Sample-Efficient Recommender Systems](2024年06月04日/Large_Language_Models_Make_Sample-Efficient_Recommender_Systems.md)

    - [翻译: 大型语言模型赋能推荐系统，使其在样本利用上更为高效。](2024年06月04日/Large_Language_Models_Make_Sample-Efficient_Recommender_Systems.md)

- [Language Models Do Hard Arithmetic Tasks Easily and Hardly Do Easy Arithmetic Tasks](2024年06月04日/Language_Models_Do_Hard_Arithmetic_Tasks_Easily_and_Hardly_Do_Easy_Arithmetic_Tasks.md)

    - [翻译: 语言模型轻松应对复杂算术挑战，却在简单算术任务上显得力不从心。](2024年06月04日/Language_Models_Do_Hard_Arithmetic_Tasks_Easily_and_Hardly_Do_Easy_Arithmetic_Tasks.md)

- [Open Grounded Planning: Challenges and Benchmark Construction](2024年06月04日/Open_Grounded_Planning_Challenges_and_Benchmark_Construction.md)

    - [翻译: 开放式基础规划：面临的挑战与基准建设](2024年06月04日/Open_Grounded_Planning_Challenges_and_Benchmark_Construction.md)

- [Scaling Laws for Reward Model Overoptimization in Direct Alignment Algorithms](2024年06月04日/Scaling_Laws_for_Reward_Model_Overoptimization_in_Direct_Alignment_Algorithms.md)

    - [翻译: 直接对齐算法中奖励模型过度优化的规模效应研究](2024年06月04日/Scaling_Laws_for_Reward_Model_Overoptimization_in_Direct_Alignment_Algorithms.md)

- [Language Model Can Do Knowledge Tracing: Simple but Effective Method to Integrate Language Model and Knowledge Tracing Task](2024年06月04日/Language_Model_Can_Do_Knowledge_Tracing_Simple_but_Effective_Method_to_Integrate_Language_Model_and_Knowledge_Tracing_Task.md)

    - [翻译: 语言模型助力知识追踪：一种简洁高效的方法，将语言模型与知识追踪任务巧妙结合](2024年06月04日/Language_Model_Can_Do_Knowledge_Tracing_Simple_but_Effective_Method_to_Integrate_Language_Model_and_Knowledge_Tracing_Task.md)

- [HYDRA: Model Factorization Framework for Black-Box LLM Personalization](2024年06月04日/HYDRA_Model_Factorization_Framework_for_Black-Box_LLM_Personalization.md)

    - [翻译: HYDRA：黑盒LLM个性化的大模型分解框架](2024年06月04日/HYDRA_Model_Factorization_Framework_for_Black-Box_LLM_Personalization.md)

- [PLaD: Preference-based Large Language Model Distillation with Pseudo-Preference Pairs](2024年06月04日/PLaD_Preference-based_Large_Language_Model_Distillation_with_Pseudo-Preference_Pairs.md)

    - [翻译: PLaD：利用伪偏好对进行基于偏好的大型语言模型蒸馏](2024年06月04日/PLaD_Preference-based_Large_Language_Model_Distillation_with_Pseudo-Preference_Pairs.md)

- [PosterLLaVa: Constructing a Unified Multi-modal Layout Generator with LLM](2024年06月04日/PosterLLaVa_Constructing_a_Unified_Multi-modal_Layout_Generator_with_LLM.md)

    - [翻译: PosterLLaVa：利用大型语言模型打造统一的多模态布局生成器](2024年06月04日/PosterLLaVa_Constructing_a_Unified_Multi-modal_Layout_Generator_with_LLM.md)

- [NUMCoT: Numerals and Units of Measurement in Chain-of-Thought Reasoning using Large Language Models](2024年06月04日/NUMCoT_Numerals_and_Units_of_Measurement_in_Chain-of-Thought_Reasoning_using_Large_Language_Models.md)

    - [翻译: NUMCoT：利用大型语言模型进行链式思维推理中的数字与测量单位处理](2024年06月04日/NUMCoT_Numerals_and_Units_of_Measurement_in_Chain-of-Thought_Reasoning_using_Large_Language_Models.md)

- [LLM as a Scorer: The Impact of Output Order on Dialogue Evaluation](2024年06月04日/LLM_as_a_Scorer_The_Impact_of_Output_Order_on_Dialogue_Evaluation.md)

    - [翻译: LLM作为评分者：探讨输出顺序如何影响对话评估](2024年06月04日/LLM_as_a_Scorer_The_Impact_of_Output_Order_on_Dialogue_Evaluation.md)

- [Exact Conversion of In-Context Learning to Model Weights](2024年06月04日/Exact_Conversion_of_In-Context_Learning_to_Model_Weights.md)

    - [翻译: 将上下文学习精准转化为模型权重](2024年06月04日/Exact_Conversion_of_In-Context_Learning_to_Model_Weights.md)

- [Chain of Agents: Large Language Models Collaborating on Long-Context Tasks](2024年06月04日/Chain_of_Agents_Large_Language_Models_Collaborating_on_Long-Context_Tasks.md)

    - [翻译: 代理链协作：大型语言模型共同应对长上下文任务挑战](2024年06月04日/Chain_of_Agents_Large_Language_Models_Collaborating_on_Long-Context_Tasks.md)

- [RATT: AThought Structure for Coherent and Correct LLMReasoning](2024年06月04日/RATT_AThought_Structure_for_Coherent_and_Correct_LLMReasoning.md)

    - [翻译: RATT：构建大型语言模型连贯且正确推理的思维框架](2024年06月04日/RATT_AThought_Structure_for_Coherent_and_Correct_LLMReasoning.md)

- [ST-DPGAN: A Privacy-preserving Framework for Spatiotemporal Data Generation](2024年06月04日/ST-DPGAN_A_Privacy-preserving_Framework_for_Spatiotemporal_Data_Generation.md)

    - [翻译: ST-DPGAN：时空数据生成的隐私保护框架](2024年06月04日/ST-DPGAN_A_Privacy-preserving_Framework_for_Spatiotemporal_Data_Generation.md)

2024年06月03日

- [Superhuman performance in urology board questions by an explainable large language model enabled for context integration of the European Association of Urology guidelines: the UroBot study](2024年06月03日/Superhuman_performance_in_urology_board_questions_by_an_explainable_large_language_model_enabled_for_context_integration_of_the_European_Association_of_Urology_guidelines_the_UroBot_study.md)

    - [翻译: UroBot研究展示了通过一个可解释的大型语言模型，在泌尿学委员会问题中达到超人性能，该模型巧妙地整合了欧洲泌尿学协会指南的上下文信息。](2024年06月03日/Superhuman_performance_in_urology_board_questions_by_an_explainable_large_language_model_enabled_for_context_integration_of_the_European_Association_of_Urology_guidelines_the_UroBot_study.md)

- [Demo: Soccer Information Retrieval via Natural Queries using SoccerRAG](2024年06月03日/Demo_Soccer_Information_Retrieval_via_Natural_Queries_using_SoccerRAG.md)

    - [翻译: 演示：借助 SoccerRAG，通过自然语言查询轻松检索足球信息](2024年06月03日/Demo_Soccer_Information_Retrieval_via_Natural_Queries_using_SoccerRAG.md)

- [SoccerRAG: Multimodal Soccer Information Retrieval via Natural Queries](2024年06月03日/SoccerRAG_Multimodal_Soccer_Information_Retrieval_via_Natural_Queries.md)

    - [翻译: SoccerRAG：自然查询驱动的多模态足球信息检索系统](2024年06月03日/SoccerRAG_Multimodal_Soccer_Information_Retrieval_via_Natural_Queries.md)

- [Decompose, Enrich, and Extract! Schema-aware Event Extraction using LLMs](2024年06月03日/Decompose,_Enrich,_and_Extract!_Schema-aware_Event_Extraction_using_LLMs.md)

    - [翻译: 分解、丰富、提取！利用 LLMs 进行模式感知的事件提取，深入挖掘事件的内在结构与丰富信息。](2024年06月03日/Decompose,_Enrich,_and_Extract!_Schema-aware_Event_Extraction_using_LLMs.md)

- [Luna: An Evaluation Foundation Model to Catch Language Model Hallucinations with High Accuracy and Low Cost](2024年06月03日/Luna_An_Evaluation_Foundation_Model_to_Catch_Language_Model_Hallucinations_with_High_Accuracy_and_Low_Cost.md)

    - [翻译: Luna：高效精准捕捉语言模型幻觉的评估基石](2024年06月03日/Luna_An_Evaluation_Foundation_Model_to_Catch_Language_Model_Hallucinations_with_High_Accuracy_and_Low_Cost.md)

- [How to Understand Whole Software Repository?](2024年06月03日/How_to_Understand_Whole_Software_Repository.md)

    - [翻译: 探索软件仓库全貌：一窥其奥秘。](2024年06月03日/How_to_Understand_Whole_Software_Repository.md)

- [AutoStudio: Crafting Consistent Subjects in Multi-turn Interactive Image Generation](2024年06月03日/AutoStudio_Crafting_Consistent_Subjects_in_Multi-turn_Interactive_Image_Generation.md)

    - [翻译: AutoStudio：打造多轮交互图像生成中连贯的主体形象](2024年06月03日/AutoStudio_Crafting_Consistent_Subjects_in_Multi-turn_Interactive_Image_Generation.md)

- [BELLS: A Framework Towards Future Proof Benchmarks for the Evaluation of LLM Safeguards](2024年06月03日/BELLS_A_Framework_Towards_Future_Proof_Benchmarks_for_the_Evaluation_of_LLM_Safeguards.md)

    - [翻译: BELLS：构建未来验证的基准，精准评估大型语言模型安全措施的框架](2024年06月03日/BELLS_A_Framework_Towards_Future_Proof_Benchmarks_for_the_Evaluation_of_LLM_Safeguards.md)

- [REvolve: Reward Evolution with Large Language Models for Autonomous Driving](2024年06月03日/REvolve_Reward_Evolution_with_Large_Language_Models_for_Autonomous_Driving.md)

    - [翻译: REvolve：大型语言模型驱动下的自动驾驶奖励进化策略](2024年06月03日/REvolve_Reward_Evolution_with_Large_Language_Models_for_Autonomous_Driving.md)

- [Mobile-Agent-v2: Mobile Device Operation Assistant with Effective Navigation via Multi-Agent Collaboration](2024年06月03日/Mobile-Agent-v2_Mobile_Device_Operation_Assistant_with_Effective_Navigation_via_Multi-Agent_Collaboration.md)

    - [翻译: Mobile-Agent-v2：多代理协作助力移动设备操作，实现精准导航](2024年06月03日/Mobile-Agent-v2_Mobile_Device_Operation_Assistant_with_Effective_Navigation_via_Multi-Agent_Collaboration.md)

- [Large Language Model Assisted Optimal Bidding of BESS in FCAS Market: An AI-agent based Approach](2024年06月03日/Large_Language_Model_Assisted_Optimal_Bidding_of_BESS_in_FCAS_Market_An_AI-agent_based_Approach.md)

    - [翻译: 借助大型语言模型，电池储能系统在辅助服务市场中的最优投标策略：基于AI代理的探索](2024年06月03日/Large_Language_Model_Assisted_Optimal_Bidding_of_BESS_in_FCAS_Market_An_AI-agent_based_Approach.md)

- [Evidence for five types of fixation during a random saccade eye tracking task: Implications for the study of oculomotor fatigue](2024年06月03日/Evidence_for_five_types_of_fixation_during_a_random_saccade_eye_tracking_task_Implications_for_the_study_of_oculomotor_fatigue.md)

    - [翻译: 随机扫视眼动追踪任务揭示了五种注视模式，为探究眼动疲劳提供了新的视角。](2024年06月03日/Evidence_for_five_types_of_fixation_during_a_random_saccade_eye_tracking_task_Implications_for_the_study_of_oculomotor_fatigue.md)

- [MultiMax: Sparse and Multi-Modal Attention Learning](2024年06月03日/MultiMax_Sparse_and_Multi-Modal_Attention_Learning.md)

    - [翻译: MultiMax：探索稀疏与多模态的注意力学习之道](2024年06月03日/MultiMax_Sparse_and_Multi-Modal_Attention_Learning.md)

- [UniQA: Unified Vision-Language Pre-training for Image Quality and Aesthetic Assessment](2024年06月03日/UniQA_Unified_Vision-Language_Pre-training_for_Image_Quality_and_Aesthetic_Assessment.md)

    - [翻译: UniQA：图像质量与美学评估的统一视觉-语言预训练模型](2024年06月03日/UniQA_Unified_Vision-Language_Pre-training_for_Image_Quality_and_Aesthetic_Assessment.md)

- [VIP: Versatile Image Outpainting Empowered by Multimodal Large Language Model](2024年06月03日/VIP_Versatile_Image_Outpainting_Empowered_by_Multimodal_Large_Language_Model.md)

    - [翻译: VIP：多模态大型语言模型驱动下的全能图像外延技术](2024年06月03日/VIP_Versatile_Image_Outpainting_Empowered_by_Multimodal_Large_Language_Model.md)

- [LLM and GNN are Complementary: Distilling LLM for Multimodal Graph Learning](2024年06月03日/LLM_and_GNN_are_Complementary_Distilling_LLM_for_Multimodal_Graph_Learning.md)

    - [翻译: 大型语言模型（LLM）与图神经网络（GNN）相辅相成：通过蒸馏技术，将 LLM 应用于多模态图学习，以提升学习效果。](2024年06月03日/LLM_and_GNN_are_Complementary_Distilling_LLM_for_Multimodal_Graph_Learning.md)

- [Dragonfly: Multi-Resolution Zoom Supercharges Large Visual-Language Model](2024年06月03日/Dragonfly_Multi-Resolution_Zoom_Supercharges_Large_Visual-Language_Model.md)

    - [翻译: Dragonfly：多分辨率缩放技术大幅提升大型视觉-语言模型的性能](2024年06月03日/Dragonfly_Multi-Resolution_Zoom_Supercharges_Large_Visual-Language_Model.md)

- [Understanding Token Probability Encoding in Output Embeddings](2024年06月03日/Understanding_Token_Probability_Encoding_in_Output_Embeddings.md)

    - [翻译: 解析输出嵌入中的令牌概率编码机制](2024年06月03日/Understanding_Token_Probability_Encoding_in_Output_Embeddings.md)

- [Understanding Preference Fine-Tuning Through the Lens of Coverage](2024年06月03日/Understanding_Preference_Fine-Tuning_Through_the_Lens_of_Coverage.md)

    - [翻译: 从覆盖率的角度洞察偏好微调的奥秘](2024年06月03日/Understanding_Preference_Fine-Tuning_Through_the_Lens_of_Coverage.md)

- [Differentially Private Tabular Data Synthesis using Large Language Models](2024年06月03日/Differentially_Private_Tabular_Data_Synthesis_using_Large_Language_Models.md)

    - [翻译: 利用大型语言模型实现差分隐私下的表格数据合成](2024年06月03日/Differentially_Private_Tabular_Data_Synthesis_using_Large_Language_Models.md)

- [LexMatcher: Dictionary-centric Data Collection for LLM-based Machine Translation](2024年06月03日/LexMatcher_Dictionary-centric_Data_Collection_for_LLM-based_Machine_Translation.md)

    - [翻译: LexMatcher：聚焦字典，优化基于大型语言模型的机器翻译数据收集](2024年06月03日/LexMatcher_Dictionary-centric_Data_Collection_for_LLM-based_Machine_Translation.md)

- [Editing the Mind of Giants: An In-Depth Exploration of Pitfalls of Knowledge Editing in Large Language Models](2024年06月03日/Editing_the_Mind_of_Giants_An_In-Depth_Exploration_of_Pitfalls_of_Knowledge_Editing_in_Large_Language_Models.md)

    - [翻译: 巨人思维的修编：深入剖析大型语言模型中知识编辑的潜在风险](2024年06月03日/Editing_the_Mind_of_Giants_An_In-Depth_Exploration_of_Pitfalls_of_Knowledge_Editing_in_Large_Language_Models.md)

- [ED-SAM: An Efficient Diffusion Sampling Approach to Domain Generalization in Vision-Language Foundation Models](2024年06月03日/ED-SAM_An_Efficient_Diffusion_Sampling_Approach_to_Domain_Generalization_in_Vision-Language_Foundation_Models.md)

    - [翻译: ED-SAM：一种高效的扩散采样策略，助力视觉-语言模型实现领域泛化](2024年06月03日/ED-SAM_An_Efficient_Diffusion_Sampling_Approach_to_Domain_Generalization_in_Vision-Language_Foundation_Models.md)

- [EAGLE: Efficient Adaptive Geometry-based Learning in Cross-view Understanding](2024年06月03日/EAGLE_Efficient_Adaptive_Geometry-based_Learning_in_Cross-view_Understanding.md)

    - [翻译: EAGLE：跨视图理解中的高效自适应几何学习法](2024年06月03日/EAGLE_Efficient_Adaptive_Geometry-based_Learning_in_Cross-view_Understanding.md)

- [Utilizing Large Language Models for Automating Technical Customer Support](2024年06月03日/Utilizing_Large_Language_Models_for_Automating_Technical_Customer_Support.md)

    - [翻译: 借助大型语言模型，实现技术客户支持的自动化](2024年06月03日/Utilizing_Large_Language_Models_for_Automating_Technical_Customer_Support.md)

- [PrivacyRestore: Privacy-Preserving Inference in Large Language Models via Privacy Removal and Restoration](2024年06月03日/PrivacyRestore_Privacy-Preserving_Inference_in_Large_Language_Models_via_Privacy_Removal_and_Restoration.md)

    - [翻译: 隐私恢复技术：在大型语言模型中实现隐私保护推理，通过移除和恢复隐私信息。](2024年06月03日/PrivacyRestore_Privacy-Preserving_Inference_in_Large_Language_Models_via_Privacy_Removal_and_Restoration.md)

- [Sparsity-Accelerated Training for Large Language Models](2024年06月03日/Sparsity-Accelerated_Training_for_Large_Language_Models.md)

    - [翻译: 利用稀疏性加速大型语言模型的训练](2024年06月03日/Sparsity-Accelerated_Training_for_Large_Language_Models.md)

- [Knowledge Graph in Astronomical Research with Large Language Models: Quantifying Driving Forces in Interdisciplinary Scientific Discovery](2024年06月03日/Knowledge_Graph_in_Astronomical_Research_with_Large_Language_Models_Quantifying_Driving_Forces_in_Interdisciplinary_Scientific_Discovery.md)

    - [翻译: 天文研究中，借助大语言模型构建的知识图谱，正量化着跨学科科学发现的驱动力。](2024年06月03日/Knowledge_Graph_in_Astronomical_Research_with_Large_Language_Models_Quantifying_Driving_Forces_in_Interdisciplinary_Scientific_Discovery.md)

- [Do Large Language Models Perform the Way People Expect? Measuring the Human Generalization Function](2024年06月03日/Do_Large_Language_Models_Perform_the_Way_People_Expect_Measuring_the_Human_Generalization_Function.md)

    - [翻译: 大型语言模型是否符合人们的期待？探究人类泛化能力的度量](2024年06月03日/Do_Large_Language_Models_Perform_the_Way_People_Expect_Measuring_the_Human_Generalization_Function.md)

- [D-CPT Law: Domain-specific Continual Pre-Training Scaling Law for Large Language Models](2024年06月03日/D-CPT_Law_Domain-specific_Continual_Pre-Training_Scaling_Law_for_Large_Language_Models.md)

    - [翻译: 特定领域持续预训练法则（D-CPT Law）：为大型语言模型量身定制的优化策略](2024年06月03日/D-CPT_Law_Domain-specific_Continual_Pre-Training_Scaling_Law_for_Large_Language_Models.md)

- [Privacy in LLM-based Recommendation: Recent Advances and Future Directions](2024年06月03日/Privacy_in_LLM-based_Recommendation_Recent_Advances_and_Future_Directions.md)

    - [翻译: 大型语言模型推荐系统中的隐私保护：最新进展与未来展望](2024年06月03日/Privacy_in_LLM-based_Recommendation_Recent_Advances_and_Future_Directions.md)

- [R2C2-Coder: Enhancing and Benchmarking Real-world Repository-level Code Completion Abilities of Code Large Language Models](2024年06月03日/R2C2-Coder_Enhancing_and_Benchmarking_Real-world_Repository-level_Code_Completion_Abilities_of_Code_Large_Language_Models.md)

    - [翻译: R2C2-Coder：提升并评估大型语言模型在真实仓库级代码补全中的性能](2024年06月03日/R2C2-Coder_Enhancing_and_Benchmarking_Real-world_Repository-level_Code_Completion_Abilities_of_Code_Large_Language_Models.md)

- [Probing Language Models for Pre-training Data Detection](2024年06月03日/Probing_Language_Models_for_Pre-training_Data_Detection.md)

    - [翻译: 探究语言模型，揭示预训练数据的踪迹](2024年06月03日/Probing_Language_Models_for_Pre-training_Data_Detection.md)

- [TabPedia: Towards Comprehensive Visual Table Understanding with Concept Synergy](2024年06月03日/TabPedia_Towards_Comprehensive_Visual_Table_Understanding_with_Concept_Synergy.md)

    - [翻译: TabPedia：借助概念协同，探索视觉表格理解的全面性](2024年06月03日/TabPedia_Towards_Comprehensive_Visual_Table_Understanding_with_Concept_Synergy.md)

- [FactGenius: Combining Zero-Shot Prompting and Fuzzy Relation Mining to Improve Fact Verification with Knowledge Graphs](2024年06月03日/FactGenius_Combining_Zero-Shot_Prompting_and_Fuzzy_Relation_Mining_to_Improve_Fact_Verification_with_Knowledge_Graphs.md)

    - [翻译: FactGenius：融合零-shot提示与模糊关系挖掘技术，借助知识图谱之力，显著提升事实验证的精准度。](2024年06月03日/FactGenius_Combining_Zero-Shot_Prompting_and_Fuzzy_Relation_Mining_to_Improve_Fact_Verification_with_Knowledge_Graphs.md)

- [Unsupervised Distractor Generation via Large Language Model Distilling and Counterfactual Contrastive Decoding](2024年06月03日/Unsupervised_Distractor_Generation_via_Large_Language_Model_Distilling_and_Counterfactual_Contrastive_Decoding.md)

    - [翻译: 利用大型语言模型蒸馏与反事实对比解码技术，实现无监督干扰生成](2024年06月03日/Unsupervised_Distractor_Generation_via_Large_Language_Model_Distilling_and_Counterfactual_Contrastive_Decoding.md)

- [When Can LLMs Actually Correct Their Own Mistakes? A Critical Survey of Self-Correction of LLMs](2024年06月03日/When_Can_LLMs_Actually_Correct_Their_Own_Mistakes_A_Critical_Survey_of_Self-Correction_of_LLMs.md)

    - [翻译: 大型语言模型何时能自我纠错？一份关于LLMs自我修正能力的深度审视](2024年06月03日/When_Can_LLMs_Actually_Correct_Their_Own_Mistakes_A_Critical_Survey_of_Self-Correction_of_LLMs.md)

- [Large Language Models as Recommender Systems: A Study of Popularity Bias](2024年06月03日/Large_Language_Models_as_Recommender_Systems_A_Study_of_Popularity_Bias.md)

    - [翻译: 大型语言模型在推荐系统中的应用：探究流行度偏差的影响](2024年06月03日/Large_Language_Models_as_Recommender_Systems_A_Study_of_Popularity_Bias.md)

- [The Dawn of Natural Language to SQL: Are We Fully Ready?](2024年06月03日/The_Dawn_of_Natural_Language_to_SQL_Are_We_Fully_Ready.md)

    - [翻译: 自然语言转SQL的时代已至，我们是否已做好万全准备？](2024年06月03日/The_Dawn_of_Natural_Language_to_SQL_Are_We_Fully_Ready.md)

- [Towards Scalable Automated Alignment of LLMs: A Survey](2024年06月03日/Towards_Scalable_Automated_Alignment_of_LLMs_A_Survey.md)

    - [翻译: 探索大型语言模型的可扩展自动对齐：一份综述](2024年06月03日/Towards_Scalable_Automated_Alignment_of_LLMs_A_Survey.md)

- [EffiQA: Efficient Question-Answering with Strategic Multi-Model Collaboration on Knowledge Graphs](2024年06月03日/EffiQA_Efficient_Question-Answering_with_Strategic_Multi-Model_Collaboration_on_Knowledge_Graphs.md)

    - [翻译: EffiQA：策略性多模型协作，知识图谱上的高效问答之道](2024年06月03日/EffiQA_Efficient_Question-Answering_with_Strategic_Multi-Model_Collaboration_on_Knowledge_Graphs.md)

- [Demonstration Augmentation for Zero-shot In-context Learning](2024年06月03日/Demonstration_Augmentation_for_Zero-shot_In-context_Learning.md)

    - [翻译: 零-shot 上下文学习中的演示增强策略](2024年06月03日/Demonstration_Augmentation_for_Zero-shot_In-context_Learning.md)

- [Are AI-Generated Text Detectors Robust to Adversarial Perturbations?](2024年06月03日/Are_AI-Generated_Text_Detectors_Robust_to_Adversarial_Perturbations.md)

    - [翻译: AI文本检测器能否抵御对抗性干扰？](2024年06月03日/Are_AI-Generated_Text_Detectors_Robust_to_Adversarial_Perturbations.md)

- [Two Tales of Persona in LLMs: A Survey of Role-Playing and Personalization](2024年06月03日/Two_Tales_of_Persona_in_LLMs_A_Survey_of_Role-Playing_and_Personalization.md)

    - [翻译: 大型语言模型中的双重角色探索：角色扮演与个性化研究综述](2024年06月03日/Two_Tales_of_Persona_in_LLMs_A_Survey_of_Role-Playing_and_Personalization.md)

- [Zero-Shot Out-of-Distribution Detection with Outlier Label Exposure](2024年06月03日/Zero-Shot_Out-of-Distribution_Detection_with_Outlier_Label_Exposure.md)

    - [翻译: 借助异常标签暴露实现零-shot分布外检测](2024年06月03日/Zero-Shot_Out-of-Distribution_Detection_with_Outlier_Label_Exposure.md)

- [How Ethical Should AI Be? How AI Alignment Shapes the Risk Preferences of LLMs](2024年06月03日/How_Ethical_Should_AI_Be_How_AI_Alignment_Shapes_the_Risk_Preferences_of_LLMs.md)

    - [翻译: AI的道德标准应如何界定？AI对齐如何影响LLMs的风险偏好？](2024年06月03日/How_Ethical_Should_AI_Be_How_AI_Alignment_Shapes_the_Risk_Preferences_of_LLMs.md)

- [DeepUniUSTransformer: Towards A Universal UltraSound Model with Prompted Guidance](2024年06月03日/DeepUniUSTransformer_Towards_A_Universal_UltraSound_Model_with_Prompted_Guidance.md)

    - [翻译: DeepUniUSTransformer：借助提示指导，迈向通用超声模型的探索之旅](2024年06月03日/DeepUniUSTransformer_Towards_A_Universal_UltraSound_Model_with_Prompted_Guidance.md)

- [Explore then Determine: A GNN-LLM Synergy Framework for Reasoning over Knowledge Graph](2024年06月03日/Explore_then_Determine_A_GNN-LLM_Synergy_Framework_for_Reasoning_over_Knowledge_Graph.md)

    - [翻译: 探索与确定：知识图谱推理中的GNN-LLM协同框架](2024年06月03日/Explore_then_Determine_A_GNN-LLM_Synergy_Framework_for_Reasoning_over_Knowledge_Graph.md)

- [Impact of Generative AI (Large Language Models) on the PRA model construction and maintenance, observations](2024年06月03日/Impact_of_Generative_AI_(Large_Language_Models)_on_the_PRA_model_construction_and_maintenance,_observations.md)

    - [翻译: 大型语言模型在生成式人工智能领域的应用，正深刻影响着PRA模型的构建与维护，其影响值得我们深入观察与探讨。](2024年06月03日/Impact_of_Generative_AI_(Large_Language_Models)_on_the_PRA_model_construction_and_maintenance,_observations.md)

- [TCMBench: A Comprehensive Benchmark for Evaluating Large Language Models in Traditional Chinese Medicine](2024年06月03日/TCMBench_A_Comprehensive_Benchmark_for_Evaluating_Large_Language_Models_in_Traditional_Chinese_Medicine.md)

    - [翻译: TCMBench：传统中医领域大型语言模型的全面评估基准](2024年06月03日/TCMBench_A_Comprehensive_Benchmark_for_Evaluating_Large_Language_Models_in_Traditional_Chinese_Medicine.md)

- [Latent Logic Tree Extraction for Event Sequence Explanation from LLMs](2024年06月03日/Latent_Logic_Tree_Extraction_for_Event_Sequence_Explanation_from_LLMs.md)

    - [翻译: 从大型语言模型中提取潜在逻辑树，揭示事件序列的内在逻辑](2024年06月03日/Latent_Logic_Tree_Extraction_for_Event_Sequence_Explanation_from_LLMs.md)

- [Synergizing Unsupervised and Supervised Learning: A Hybrid Approach for Accurate Natural Language Task Modeling](2024年06月03日/Synergizing_Unsupervised_and_Supervised_Learning_A_Hybrid_Approach_for_Accurate_Natural_Language_Task_Modeling.md)

    - [翻译: 融合无监督与监督学习：探索混合策略以精准塑造自然语言任务模型](2024年06月03日/Synergizing_Unsupervised_and_Supervised_Learning_A_Hybrid_Approach_for_Accurate_Natural_Language_Task_Modeling.md)

- [Nuclear Medicine Artificial Intelligence in Action: The Bethesda Report (AI Summit 2024)](2024年06月03日/Nuclear_Medicine_Artificial_Intelligence_in_Action_The_Bethesda_Report_(AI_Summit_2024).md)

    - [翻译: 核医学人工智能实践：2024年AI峰会贝塞斯达报告](2024年06月03日/Nuclear_Medicine_Artificial_Intelligence_in_Action_The_Bethesda_Report_(AI_Summit_2024).md)

- [Strengthened Symbol Binding Makes Large Language Models Reliable Multiple-Choice Selectors](2024年06月03日/Strengthened_Symbol_Binding_Makes_Large_Language_Models_Reliable_Multiple-Choice_Selectors.md)

    - [翻译: 通过增强符号绑定，大型语言模型得以转变为精准的多项选择筛选工具。](2024年06月03日/Strengthened_Symbol_Binding_Makes_Large_Language_Models_Reliable_Multiple-Choice_Selectors.md)

- [CLIP-Guided Attribute Aware Pretraining for Generalizable Image Quality Assessment](2024年06月03日/CLIP-Guided_Attribute_Aware_Pretraining_for_Generalizable_Image_Quality_Assessment.md)

    - [翻译: 利用CLIP引导的属性感知预训练，提升图像质量评估的泛化能力](2024年06月03日/CLIP-Guided_Attribute_Aware_Pretraining_for_Generalizable_Image_Quality_Assessment.md)

- [An Information Bottleneck Perspective for Effective Noise Filtering on Retrieval-Augmented Generation](2024年06月03日/An_Information_Bottleneck_Perspective_for_Effective_Noise_Filtering_on_Retrieval-Augmented_Generation.md)

    - [翻译: 在检索增强生成过程中，信息瓶颈视角揭示了有效噪声过滤的重要性。](2024年06月03日/An_Information_Bottleneck_Perspective_for_Effective_Noise_Filtering_on_Retrieval-Augmented_Generation.md)

- [PlanAgent: A Multi-modal Large Language Agent for Closed-loop Vehicle Motion Planning](2024年06月03日/PlanAgent_A_Multi-modal_Large_Language_Agent_for_Closed-loop_Vehicle_Motion_Planning.md)

    - [翻译: PlanAgent：专为闭环车辆运动规划设计的多模态大型语言智能代理](2024年06月03日/PlanAgent_A_Multi-modal_Large_Language_Agent_for_Closed-loop_Vehicle_Motion_Planning.md)

- [MMLU-Pro: A More Robust and Challenging Multi-Task Language Understanding Benchmark](2024年06月03日/MMLU-Pro_A_More_Robust_and_Challenging_Multi-Task_Language_Understanding_Benchmark.md)

    - [翻译: MMLU-Pro：打造更稳健、更具挑战性的多任务语言理解新标杆](2024年06月03日/MMLU-Pro_A_More_Robust_and_Challenging_Multi-Task_Language_Understanding_Benchmark.md)

- [Helix: Distributed Serving of Large Language Models via Max-Flow on Heterogeneous GPUs](2024年06月03日/Helix_Distributed_Serving_of_Large_Language_Models_via_Max-Flow_on_Heterogeneous_GPUs.md)

    - [翻译: Helix：异构GPU上最大流技术助力大型语言模型分布式服务](2024年06月03日/Helix_Distributed_Serving_of_Large_Language_Models_via_Max-Flow_on_Heterogeneous_GPUs.md)

- [LoFiT: Localized Fine-tuning on LLM Representations](2024年06月03日/LoFiT_Localized_Fine-tuning_on_LLM_Representations.md)

    - [翻译: LoFiT：针对LLM表示的局部精细调整](2024年06月03日/LoFiT_Localized_Fine-tuning_on_LLM_Representations.md)

- [What Are Large Language Models Mapping to in the Brain? A Case Against Over-Reliance on Brain Scores](2024年06月03日/What_Are_Large_Language_Models_Mapping_to_in_the_Brain_A_Case_Against_Over-Reliance_on_Brain_Scores.md)

    - [翻译: 大型语言模型在人脑中的映射究竟是什么？本文质疑了过度依赖脑部评分的现象。](2024年06月03日/What_Are_Large_Language_Models_Mapping_to_in_the_Brain_A_Case_Against_Over-Reliance_on_Brain_Scores.md)

- [Decoupled Alignment for Robust Plug-and-Play Adaptation](2024年06月03日/Decoupled_Alignment_for_Robust_Plug-and-Play_Adaptation.md)

    - [翻译: 实现稳健即插即用适应的解耦对齐策略](2024年06月03日/Decoupled_Alignment_for_Robust_Plug-and-Play_Adaptation.md)

- [The Geometry of Categorical and Hierarchical Concepts in Large Language Models](2024年06月03日/The_Geometry_of_Categorical_and_Hierarchical_Concepts_in_Large_Language_Models.md)

    - [翻译: 大型语言模型中分类与层次概念的几何探索](2024年06月03日/The_Geometry_of_Categorical_and_Hierarchical_Concepts_in_Large_Language_Models.md)

- [Bileve: Securing Text Provenance in Large Language Models Against Spoofing with Bi-level Signature](2024年06月03日/Bileve_Securing_Text_Provenance_in_Large_Language_Models_Against_Spoofing_with_Bi-level_Signature.md)

    - [翻译: Bileve：双层签名技术，为大型语言模型中的文本来源提供防伪安全保障](2024年06月03日/Bileve_Securing_Text_Provenance_in_Large_Language_Models_Against_Spoofing_with_Bi-level_Signature.md)

- [Enhancing Trust in LLMs: Algorithms for Comparing and Interpreting LLMs](2024年06月03日/Enhancing_Trust_in_LLMs_Algorithms_for_Comparing_and_Interpreting_LLMs.md)

    - [翻译: 提升对LLMs的信任：探索比较与解读LLMs的算法之道](2024年06月03日/Enhancing_Trust_in_LLMs_Algorithms_for_Comparing_and_Interpreting_LLMs.md)

- [Process-Driven Autoformalization in Lean 4](2024年06月03日/Process-Driven_Autoformalization_in_Lean_4.md)

    - [翻译: Lean 4中的过程驱动自动形式化](2024年06月03日/Process-Driven_Autoformalization_in_Lean_4.md)

- [Dishonesty in Helpful and Harmless Alignment](2024年06月03日/Dishonesty_in_Helpful_and_Harmless_Alignment.md)

    - [翻译: 有益无害对齐中的诚信缺失](2024年06月03日/Dishonesty_in_Helpful_and_Harmless_Alignment.md)

- [Enhancing Human-Robot Collaborative Assembly in Manufacturing Systems Using Large Language Models](2024年06月03日/Enhancing_Human-Robot_Collaborative_Assembly_in_Manufacturing_Systems_Using_Large_Language_Models.md)

    - [翻译: 借助大型语言模型，提升制造系统中人机协作装配的效率](2024年06月03日/Enhancing_Human-Robot_Collaborative_Assembly_in_Manufacturing_Systems_Using_Large_Language_Models.md)

- [HPE-CogVLM: New Head Pose Grounding Task Exploration on Vision Language Model](2024年06月03日/HPE-CogVLM_New_Head_Pose_Grounding_Task_Exploration_on_Vision_Language_Model.md)

    - [翻译: HPE-CogVLM：探索视觉语言模型上的头部姿态接地新任务](2024年06月03日/HPE-CogVLM_New_Head_Pose_Grounding_Task_Exploration_on_Vision_Language_Model.md)

- [ProGEO: Generating Prompts through Image-Text Contrastive Learning for Visual Geo-localization](2024年06月03日/ProGEO_Generating_Prompts_through_Image-Text_Contrastive_Learning_for_Visual_Geo-localization.md)

    - [翻译: ProGEO：利用图像与文本的对比学习，巧妙生成提示，助力视觉地理定位任务。](2024年06月03日/ProGEO_Generating_Prompts_through_Image-Text_Contrastive_Learning_for_Visual_Geo-localization.md)

- [Cross-Domain Graph Data Scaling: A Showcase with Diffusion Models](2024年06月03日/Cross-Domain_Graph_Data_Scaling_A_Showcase_with_Diffusion_Models.md)

    - [翻译: 跨域图数据扩展：以扩散模型为例的精彩展示](2024年06月03日/Cross-Domain_Graph_Data_Scaling_A_Showcase_with_Diffusion_Models.md)

- [Large Language Model-Enabled Multi-Agent Manufacturing Systems](2024年06月03日/Large_Language_Model-Enabled_Multi-Agent_Manufacturing_Systems.md)

    - [翻译: 大型语言模型赋能的多代理制造系统](2024年06月03日/Large_Language_Model-Enabled_Multi-Agent_Manufacturing_Systems.md)

- [HoneyGPT: Breaking the Trilemma in Terminal Honeypots with Large Language Model](2024年06月03日/HoneyGPT_Breaking_the_Trilemma_in_Terminal_Honeypots_with_Large_Language_Model.md)

    - [翻译: HoneyGPT：借助大型语言模型，破解终端蜜罐的三重难题](2024年06月03日/HoneyGPT_Breaking_the_Trilemma_in_Terminal_Honeypots_with_Large_Language_Model.md)

- [GRAM: Generative Retrieval Augmented Matching of Data Schemas in the Context of Data Security](2024年06月03日/GRAM_Generative_Retrieval_Augmented_Matching_of_Data_Schemas_in_the_Context_of_Data_Security.md)

    - [翻译: GRAM：数据安全背景下，通过生成式检索增强的数据模式匹配技术](2024年06月03日/GRAM_Generative_Retrieval_Augmented_Matching_of_Data_Schemas_in_the_Context_of_Data_Security.md)

- [Charting the Landscape of Nefarious Uses of Generative Artificial Intelligence for Online Election Interference](2024年06月03日/Charting_the_Landscape_of_Nefarious_Uses_of_Generative_Artificial_Intelligence_for_Online_Election_Interference.md)

    - [翻译: 描绘生成人工智能在网络选举干预中的恶意应用全景](2024年06月03日/Charting_the_Landscape_of_Nefarious_Uses_of_Generative_Artificial_Intelligence_for_Online_Election_Interference.md)

- [Eliciting the Priors of Large Language Models using Iterated In-Context Learning](2024年06月03日/Eliciting_the_Priors_of_Large_Language_Models_using_Iterated_In-Context_Learning.md)

    - [翻译: 通过迭代上下文学习揭示大型语言模型的先验知识](2024年06月03日/Eliciting_the_Priors_of_Large_Language_Models_using_Iterated_In-Context_Learning.md)

- [TruthEval: A Dataset to Evaluate LLM Truthfulness and Reliability](2024年06月03日/TruthEval_A_Dataset_to_Evaluate_LLM_Truthfulness_and_Reliability.md)

    - [翻译: TruthEval：专为评估大型语言模型真实性与可靠性而设计的数据集](2024年06月03日/TruthEval_A_Dataset_to_Evaluate_LLM_Truthfulness_and_Reliability.md)

- [L-MAGIC: Language Model Assisted Generation of Images with Coherence](2024年06月03日/L-MAGIC_Language_Model_Assisted_Generation_of_Images_with_Coherence.md)

    - [翻译: L-MAGIC：借助语言模型，生成连贯图像的魔法](2024年06月03日/L-MAGIC_Language_Model_Assisted_Generation_of_Images_with_Coherence.md)

- [Boosting Vision-Language Models with Transduction](2024年06月03日/Boosting_Vision-Language_Models_with_Transduction.md)

    - [翻译: 借助转导技术，我们能够进一步提升视觉-语言模型的性能。](2024年06月03日/Boosting_Vision-Language_Models_with_Transduction.md)

- [In-Context Learning of Physical Properties: Few-Shot Adaptation to Out-of-Distribution Molecular Graphs](2024年06月03日/In-Context_Learning_of_Physical_Properties_Few-Shot_Adaptation_to_Out-of-Distribution_Molecular_Graphs.md)

    - [翻译: 物理属性情境学习：快速适应分布外的分子图结构](2024年06月03日/In-Context_Learning_of_Physical_Properties_Few-Shot_Adaptation_to_Out-of-Distribution_Molecular_Graphs.md)

- [Contextualized Sequence Likelihood: Enhanced Confidence Scores for Natural Language Generation](2024年06月03日/Contextualized_Sequence_Likelihood_Enhanced_Confidence_Scores_for_Natural_Language_Generation.md)

    - [翻译: 增强自然语言生成置信度：上下文化序列可能性](2024年06月03日/Contextualized_Sequence_Likelihood_Enhanced_Confidence_Scores_for_Natural_Language_Generation.md)

- [TabMDA: Tabular Manifold Data Augmentation for Any Classifier using Transformers with In-context Subsetting](2024年06月03日/TabMDA_Tabular_Manifold_Data_Augmentation_for_Any_Classifier_using_Transformers_with_In-context_Subsetting.md)

    - [翻译: TabMDA：利用Transformer的上下文子集技术，为任意分类器提供表格流形数据增强方案](2024年06月03日/TabMDA_Tabular_Manifold_Data_Augmentation_for_Any_Classifier_using_Transformers_with_In-context_Subsetting.md)

- [OLoRA: Orthonormal Low-Rank Adaptation of Large Language Models](2024年06月03日/OLoRA_Orthonormal_Low-Rank_Adaptation_of_Large_Language_Models.md)

    - [翻译: OLoRA：大型语言模型的正交低秩自适应](2024年06月03日/OLoRA_Orthonormal_Low-Rank_Adaptation_of_Large_Language_Models.md)

- [LLMs Beyond English: Scaling the Multilingual Capability of LLMs with Cross-Lingual Feedback](2024年06月03日/LLMs_Beyond_English_Scaling_the_Multilingual_Capability_of_LLMs_with_Cross-Lingual_Feedback.md)

    - [翻译: 拓展LLMs的多语言疆界：借助跨语言反馈提升其全球适应性](2024年06月03日/LLMs_Beyond_English_Scaling_the_Multilingual_Capability_of_LLMs_with_Cross-Lingual_Feedback.md)

- [TSpec-LLM: An Open-source Dataset for LLM Understanding of 3GPP Specifications](2024年06月03日/TSpec-LLM_An_Open-source_Dataset_for_LLM_Understanding_of_3GPP_Specifications.md)

    - [翻译: TSpec-LLM：一款开源数据集，专为大型语言模型深入解读3GPP规范而设计](2024年06月03日/TSpec-LLM_An_Open-source_Dataset_for_LLM_Understanding_of_3GPP_Specifications.md)

2024年06月02日

- [An Early Investigation into the Utility of Multimodal Large Language Models in Medical Imaging](2024年06月02日/An_Early_Investigation_into_the_Utility_of_Multimodal_Large_Language_Models_in_Medical_Imaging.md)

    - [翻译: 早期探索：多模态大型语言模型在医学影像领域的应用潜力](2024年06月02日/An_Early_Investigation_into_the_Utility_of_Multimodal_Large_Language_Models_in_Medical_Imaging.md)

- [Topic Modeling for Short Texts with Large Language Models](2024年06月02日/Topic_Modeling_for_Short_Texts_with_Large_Language_Models.md)

    - [翻译: 大型语言模型在短文本主题建模中的应用](2024年06月02日/Topic_Modeling_for_Short_Texts_with_Large_Language_Models.md)

- [Cascade-CLIP: Cascaded Vision-Language Embeddings Alignment for Zero-Shot Semantic Segmentation](2024年06月02日/Cascade-CLIP_Cascaded_Vision-Language_Embeddings_Alignment_for_Zero-Shot_Semantic_Segmentation.md)

    - [翻译: Cascade-CLIP：级联视觉-语言嵌入对齐，助力零-shot 语义分割](2024年06月02日/Cascade-CLIP_Cascaded_Vision-Language_Embeddings_Alignment_for_Zero-Shot_Semantic_Segmentation.md)

- [Presence or Absence: Are Unknown Word Usages in Dictionaries?](2024年06月02日/Presence_or_Absence_Are_Unknown_Word_Usages_in_Dictionaries.md)

    - [翻译: 字典中是否收录了未知词汇的使用？这是一个关于存在与否的问题。](2024年06月02日/Presence_or_Absence_Are_Unknown_Word_Usages_in_Dictionaries.md)

- [Transforming Computer Security and Public Trust Through the Exploration of Fine-Tuning Large Language Models](2024年06月02日/Transforming_Computer_Security_and_Public_Trust_Through_the_Exploration_of_Fine-Tuning_Large_Language_Models.md)

    - [翻译: 探索微调大型语言模型，以提升计算机安全并增强公众信任](2024年06月02日/Transforming_Computer_Security_and_Public_Trust_Through_the_Exploration_of_Fine-Tuning_Large_Language_Models.md)

- [Prompt Framework for Role-playing: Generation and Evaluation](2024年06月02日/Prompt_Framework_for_Role-playing_Generation_and_Evaluation.md)

    - [翻译: 角色扮演提示框架：生成与评价](2024年06月02日/Prompt_Framework_for_Role-playing_Generation_and_Evaluation.md)

- [BadRAG: Identifying Vulnerabilities in Retrieval Augmented Generation of Large Language Models](2024年06月02日/BadRAG_Identifying_Vulnerabilities_in_Retrieval_Augmented_Generation_of_Large_Language_Models.md)

    - [翻译: BadRAG：揭示大型语言模型增强检索生成中的安全隐患](2024年06月02日/BadRAG_Identifying_Vulnerabilities_in_Retrieval_Augmented_Generation_of_Large_Language_Models.md)

- [Unveil the Duality of Retrieval-Augmented Generation: Theoretical Analysis and Practical Solution](2024年06月02日/Unveil_the_Duality_of_Retrieval-Augmented_Generation_Theoretical_Analysis_and_Practical_Solution.md)

    - [翻译: 揭秘检索增强生成技术的双重奥秘：理论剖析与实践指南](2024年06月02日/Unveil_the_Duality_of_Retrieval-Augmented_Generation_Theoretical_Analysis_and_Practical_Solution.md)

- [Are you still on track!? Catching LLM Task Drift with Activations](2024年06月02日/Are_you_still_on_track!_Catching_LLM_Task_Drift_with_Activations.md)

    - [翻译: 你是否还在正轨？利用激活监测大型语言模型的任务漂移。](2024年06月02日/Are_you_still_on_track!_Catching_LLM_Task_Drift_with_Activations.md)

- [COS-Mix: Cosine Similarity and Distance Fusion for Improved Information Retrieval](2024年06月02日/COS-Mix_Cosine_Similarity_and_Distance_Fusion_for_Improved_Information_Retrieval.md)

    - [翻译: COS-Mix：融合余弦相似度与距离，优化信息检索性能](2024年06月02日/COS-Mix_Cosine_Similarity_and_Distance_Fusion_for_Improved_Information_Retrieval.md)

- [OLIVE: Object Level In-Context Visual Embeddings](2024年06月02日/OLIVE_Object_Level_In-Context_Visual_Embeddings.md)

    - [翻译: OLIVE：对象级上下文视觉嵌入，一种新颖的视觉表示方法，旨在通过对象级别的上下文信息来增强视觉嵌入的表达能力。](2024年06月02日/OLIVE_Object_Level_In-Context_Visual_Embeddings.md)

- [Teams of LLM Agents can Exploit Zero-Day Vulnerabilities](2024年06月02日/Teams_of_LLM_Agents_can_Exploit_Zero-Day_Vulnerabilities.md)

    - [翻译: LLM 代理团队具备利用零日漏洞的能力。](2024年06月02日/Teams_of_LLM_Agents_can_Exploit_Zero-Day_Vulnerabilities.md)

- [Applying Fine-Tuned LLMs for Reducing Data Needs in Load Profile Analysis](2024年06月02日/Applying_Fine-Tuned_LLMs_for_Reducing_Data_Needs_in_Load_Profile_Analysis.md)

    - [翻译: 利用微调的大型语言模型，精简负载曲线分析的数据需求](2024年06月02日/Applying_Fine-Tuned_LLMs_for_Reducing_Data_Needs_in_Load_Profile_Analysis.md)

2024年06月01日

- [Improving Text Generation on Images with Synthetic Captions](2024年06月01日/Improving_Text_Generation_on_Images_with_Synthetic_Captions.md)

    - [翻译: 借助合成标题，提升图像文本生成能力](2024年06月01日/Improving_Text_Generation_on_Images_with_Synthetic_Captions.md)

- [Evaluating Uncertainty-based Failure Detection for Closed-Loop LLM Planners](2024年06月01日/Evaluating_Uncertainty-based_Failure_Detection_for_Closed-Loop_LLM_Planners.md)

    - [翻译: 评估闭环 LLM 规划器中基于不确定性的故障检测机制](2024年06月01日/Evaluating_Uncertainty-based_Failure_Detection_for_Closed-Loop_LLM_Planners.md)

- [HENASY: Learning to Assemble Scene-Entities for Egocentric Video-Language Model](2024年06月01日/HENASY_Learning_to_Assemble_Scene-Entities_for_Egocentric_Video-Language_Model.md)

    - [翻译: HENASY：掌握场景实体组装，赋能第一人称视频语言模型](2024年06月01日/HENASY_Learning_to_Assemble_Scene-Entities_for_Egocentric_Video-Language_Model.md)

- [LLMs Could Autonomously Learn Without External Supervision](2024年06月01日/LLMs_Could_Autonomously_Learn_Without_External_Supervision.md)

    - [翻译: 大型语言模型（LLMs）具备无监督自主学习的能力。](2024年06月01日/LLMs_Could_Autonomously_Learn_Without_External_Supervision.md)

- [LongSkywork: A Training Recipe for Efficiently Extending Context Length in Large Language Models](2024年06月01日/LongSkywork_A_Training_Recipe_for_Efficiently_Extending_Context_Length_in_Large_Language_Models.md)

    - [翻译: LongSkywork：大型语言模型上下文长度扩展的高效训练秘籍](2024年06月01日/LongSkywork_A_Training_Recipe_for_Efficiently_Extending_Context_Length_in_Large_Language_Models.md)

- [From Effectiveness to Efficiency: Comparative Evaluation of Code Generated by LCGMs for Bilingual Programming Questions](2024年06月01日/From_Effectiveness_to_Efficiency_Comparative_Evaluation_of_Code_Generated_by_LCGMs_for_Bilingual_Programming_Questions.md)

    - [翻译: 从有效性到效率：双语编程问题中，语言模型生成代码的比较评估](2024年06月01日/From_Effectiveness_to_Efficiency_Comparative_Evaluation_of_Code_Generated_by_LCGMs_for_Bilingual_Programming_Questions.md)

- [Artificial General Intelligence (AGI) for the oil and gas industry: a review](2024年06月01日/Artificial_General_Intelligence_(AGI)_for_the_oil_and_gas_industry_a_review.md)

    - [翻译: 石油与天然气行业中的AGI：一次深度探索](2024年06月01日/Artificial_General_Intelligence_(AGI)_for_the_oil_and_gas_industry_a_review.md)

- [A Blueprint Architecture of Compound AI Systems for Enterprise](2024年06月01日/A_Blueprint_Architecture_of_Compound_AI_Systems_for_Enterprise.md)

    - [翻译: 企业复合AI系统架构蓝图](2024年06月01日/A_Blueprint_Architecture_of_Compound_AI_Systems_for_Enterprise.md)

- [Guiding and Diversifying LLM-Based Story Generation via Answer Set Programming](2024年06月01日/Guiding_and_Diversifying_LLM-Based_Story_Generation_via_Answer_Set_Programming.md)

    - [翻译: 利用答案集编程，引导并丰富大型语言模型生成故事的多样性](2024年06月01日/Guiding_and_Diversifying_LLM-Based_Story_Generation_via_Answer_Set_Programming.md)

- [LIDAO: Towards Limited Interventions for Debiasing (Large) Language Models](2024年06月01日/LIDAO_Towards_Limited_Interventions_for_Debiasing_(Large)_Language_Models.md)

    - [翻译: LIDAO：探索有限干预策略，以减少大型语言模型的偏见](2024年06月01日/LIDAO_Towards_Limited_Interventions_for_Debiasing_(Large)_Language_Models.md)

- [Wav2Prompt: End-to-End Speech Prompt Generation and Tuning For LLM in Zero and Few-shot Learning](2024年06月01日/Wav2Prompt_End-to-End_Speech_Prompt_Generation_and_Tuning_For_LLM_in_Zero_and_Few-shot_Learning.md)

    - [翻译: Wav2Prompt：大型语言模型零样本与少样本学习中的端到端语音提示生成与优化](2024年06月01日/Wav2Prompt_End-to-End_Speech_Prompt_Generation_and_Tuning_For_LLM_in_Zero_and_Few-shot_Learning.md)

- [A Survey on Large Language Models for Code Generation](2024年06月01日/A_Survey_on_Large_Language_Models_for_Code_Generation.md)

    - [翻译: 大型语言模型在代码生成领域的综述](2024年06月01日/A_Survey_on_Large_Language_Models_for_Code_Generation.md)

- [Learning Background Prompts to Discover Implicit Knowledge for Open Vocabulary Object Detection](2024年06月01日/Learning_Background_Prompts_to_Discover_Implicit_Knowledge_for_Open_Vocabulary_Object_Detection.md)

    - [翻译: 探索背景提示，解锁开放词汇对象检测中的隐含知识宝库](2024年06月01日/Learning_Background_Prompts_to_Discover_Implicit_Knowledge_for_Open_Vocabulary_Object_Detection.md)

- [Prompt Chaining or Stepwise Prompt? Refinement in Text Summarization](2024年06月01日/Prompt_Chaining_or_Stepwise_Prompt_Refinement_in_Text_Summarization.md)

    - [翻译: 是采用提示链还是逐步提示？探讨文本摘要中的细化策略](2024年06月01日/Prompt_Chaining_or_Stepwise_Prompt_Refinement_in_Text_Summarization.md)

- [Effectiveness of Vision Language Models for Open-world Single Image Test Time Adaptation](2024年06月01日/Effectiveness_of_Vision_Language_Models_for_Open-world_Single_Image_Test_Time_Adaptation.md)

    - [翻译: 视觉语言模型在开放世界环境下，针对单张图像的测试时间适应能力展现出的有效性](2024年06月01日/Effectiveness_of_Vision_Language_Models_for_Open-world_Single_Image_Test_Time_Adaptation.md)

- [Task Planning for Object Rearrangement in Multi-room Environments](2024年06月01日/Task_Planning_for_Object_Rearrangement_in_Multi-room_Environments.md)

    - [翻译: 多房间环境下物体重新排列的任务规划](2024年06月01日/Task_Planning_for_Object_Rearrangement_in_Multi-room_Environments.md)

- [InterpreTabNet: Distilling Predictive Signals from Tabular Data by Salient Feature Interpretation](2024年06月01日/InterpreTabNet_Distilling_Predictive_Signals_from_Tabular_Data_by_Salient_Feature_Interpretation.md)

    - [翻译: InterpreTabNet：借助显著特征解释，精炼表格数据中的预测信号](2024年06月01日/InterpreTabNet_Distilling_Predictive_Signals_from_Tabular_Data_by_Salient_Feature_Interpretation.md)

- [The Best of Both Worlds: Toward an Honest and Helpful Large Language Model](2024年06月01日/The_Best_of_Both_Worlds_Toward_an_Honest_and_Helpful_Large_Language_Model.md)

    - [翻译: 《双赢之道：打造既诚实又实用的大型语言模型》](2024年06月01日/The_Best_of_Both_Worlds_Toward_an_Honest_and_Helpful_Large_Language_Model.md)

- [Beyond Metrics: Evaluating LLMs' Effectiveness in Culturally Nuanced, Low-Resource Real-World Scenarios](2024年06月01日/Beyond_Metrics_Evaluating_LLMs'_Effectiveness_in_Culturally_Nuanced,_Low-Resource_Real-World_Scenarios.md)

    - [翻译: 深入文化细微之处：探索大型语言模型在资源有限的真实世界场景中的实际效能](2024年06月01日/Beyond_Metrics_Evaluating_LLMs'_Effectiveness_in_Culturally_Nuanced,_Low-Resource_Real-World_Scenarios.md)

- [A Practice-Friendly Two-Stage LLM-Enhanced Paradigm in Sequential Recommendation](2024年06月01日/A_Practice-Friendly_Two-Stage_LLM-Enhanced_Paradigm_in_Sequential_Recommendation.md)

    - [翻译: 一种便于实践的两阶段大型语言模型增强序列推荐模式](2024年06月01日/A_Practice-Friendly_Two-Stage_LLM-Enhanced_Paradigm_in_Sequential_Recommendation.md)

- [Creative Text-to-Audio Generation via Synthesizer Programming](2024年06月01日/Creative_Text-to-Audio_Generation_via_Synthesizer_Programming.md)

    - [翻译: 借助合成器编程，创意文本转音频的生成得以实现](2024年06月01日/Creative_Text-to-Audio_Generation_via_Synthesizer_Programming.md)

- [SPAGHETTI: Open-Domain Question Answering from Heterogeneous Data Sources with Retrieval and Semantic Parsing](2024年06月01日/SPAGHETTI_Open-Domain_Question_Answering_from_Heterogeneous_Data_Sources_with_Retrieval_and_Semantic_Parsing.md)

    - [翻译: SPAGHETTI：融合检索与语义解析，从多元数据源中解锁开放域问答的奥秘](2024年06月01日/SPAGHETTI_Open-Domain_Question_Answering_from_Heterogeneous_Data_Sources_with_Retrieval_and_Semantic_Parsing.md)

- [Mix-of-Granularity: Optimize the Chunking Granularity for Retrieval-Augmented Generation](2024年06月01日/Mix-of-Granularity_Optimize_the_Chunking_Granularity_for_Retrieval-Augmented_Generation.md)

    - [翻译: 粒度混合优化：提升检索增强生成中的分块效率](2024年06月01日/Mix-of-Granularity_Optimize_the_Chunking_Granularity_for_Retrieval-Augmented_Generation.md)

- [Multimodal Deep Learning for Low-Resource Settings: A Vector Embedding Alignment Approach for Healthcare Applications](2024年06月01日/Multimodal_Deep_Learning_for_Low-Resource_Settings_A_Vector_Embedding_Alignment_Approach_for_Healthcare_Applications.md)

    - [翻译: 在资源有限的医疗保健领域，我们采用了一种新颖的多模态深度学习方法——向量嵌入对齐技术，以提升数据处理效率。](2024年06月01日/Multimodal_Deep_Learning_for_Low-Resource_Settings_A_Vector_Embedding_Alignment_Approach_for_Healthcare_Applications.md)