# 探究大型语言模型在安卓应用漏洞分析中的效能

发布时间：2024年06月27日

`RAG

理由：该论文摘要主要讨论了大型语言模型（LLMs）在检测Android应用中的安全漏洞方面的应用，并特别提到了通过检索增强生成（RAG）技术来增强上下文，以提升漏洞检测能力。这表明论文的重点在于使用RAG技术来改进LLMs在特定应用场景（即安全漏洞检测）中的性能，因此属于RAG分类。虽然论文也涉及了LLMs的应用，但主要焦点是RAG技术的应用，而不是LLMs的一般应用或理论研究。` `移动安全` `软件开发`

> Assessing the Effectiveness of LLMs in Android Application Vulnerability Analysis

# 摘要

> 随着Android应用遭受攻击的频率上升，以及大型语言模型（LLMs）的兴起，我们亟需深入了解这些模型在识别潜在安全漏洞方面的能力，这对于降低整体风险至关重要。本研究对比了九种顶尖LLMs在检测OWASP移动安全排行榜前十中的Android代码漏洞的能力。通过分析一个包含100多个漏洞代码样本（含混淆样本）的公开数据集，我们评估了各模型的关键漏洞识别能力。分析结果不仅揭示了各模型的强项与弱点，还指出了影响其性能的关键因素。此外，我们还探讨了如何通过检索增强生成（RAG）技术增强上下文，以提升Android代码漏洞的检测能力，进而推动更安全的应用开发。尽管研究结果显示了LLMs在代码漏洞分析方面的潜力，但也暴露了它们之间的显著差异。

> The increasing frequency of attacks on Android applications coupled with the recent popularity of large language models (LLMs) necessitates a comprehensive understanding of the capabilities of the latter in identifying potential vulnerabilities, which is key to mitigate the overall risk. To this end, the work at hand compares the ability of nine state-of-the-art LLMs to detect Android code vulnerabilities listed in the latest Open Worldwide Application Security Project (OWASP) Mobile Top 10. Each LLM was evaluated against an open dataset of over 100 vulnerable code samples, including obfuscated ones, assessing each model's ability to identify key vulnerabilities. Our analysis reveals the strengths and weaknesses of each LLM, identifying important factors that contribute to their performance. Additionally, we offer insights into context augmentation with retrieval-augmented generation (RAG) for detecting Android code vulnerabilities, which in turn may propel secure application development. Finally, while the reported findings regarding code vulnerability analysis show promise, they also reveal significant discrepancies among the different LLMs.

[Arxiv](https://arxiv.org/abs/2406.18894)