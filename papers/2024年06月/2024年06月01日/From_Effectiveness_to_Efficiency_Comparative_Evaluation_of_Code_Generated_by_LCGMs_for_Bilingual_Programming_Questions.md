# 从有效性到效率：双语编程问题中，语言模型生成代码的比较评估

发布时间：2024年06月01日

`LLM应用

这篇论文主要探讨了大型代码生成模型（LCGMs）在处理不同语言（特别是中文和英语）输入时的性能差异，并构建了相应的测试集来评估这些模型生成的代码质量。虽然涉及到语言模型的应用，但重点在于实际应用中的代码生成质量和性能评估，而不是理论研究或Agent的设计与应用。因此，这篇论文更适合归类于LLM应用。` `人工智能`

> From Effectiveness to Efficiency: Comparative Evaluation of Code Generated by LCGMs for Bilingual Programming Questions

# 摘要

> 大型代码生成模型（LCGMs）在编程领域备受瞩目，成绩斐然。但当输入非英语提示时，其性能引发疑虑，因这些模型多基于英语语料库训练，且编程语言令牌多与英语相似。现有评估标准多基于英语编程问题和少量手动测试，难以全面衡量LCGM生成的代码质量。本文聚焦中文与英语，探讨不同语言输入对代码有效性与效率的影响。双语输入下评估LCGM代码质量面临三大难题：缺乏优质双语编程数据集、单元测试不足、性能比较支持有限。为此，我们构建了包含52个双语编程问题的测试集，并开发了自动输入生成工具。通过扩大单元测试样本和分析执行时间随输入增大的变化，我们提升了正确性验证并评估了代码性能。对六款顶尖LCGMs的实证研究表明，LCGM生成的代码在10.5%的任务上双语正确性不一，39.5%的正确代码在双语性能上呈现差异。这表明LCGMs在不同语言间生成高质量代码的能力并不一致，为未来研究指明了方向。

> Large Code Generation Models (LCGMs) have garnered significant attention and achieved promising results across various programming tasks. However, concerns arise regarding performance when using non-English prompts, as these models are primarily trained on English-centric corpora, and most programming language tokens resemble English. Existing benchmarks often rely on English programming questions and limited manual unit test cases, inadequately assessing LCGM-generated code quality. This paper investigates code quality differences, specifically effectiveness and efficiency, when employing different natural languages as inputs, focusing on Chinese and English due to their prominent corpora and LCGM availability. Evaluating LCGM-generated code quality under bilingual inputs presents three challenges: (1) lack of high-quality bilingual programming question datasets, (2) insufficient unit test cases for comprehensive correctness verification, and (3) limited support for comparing generated code performance. To address these challenges, we curated a test suite of 52 bilingual programming questions and developed automated input generators for each. We enhanced correctness verification by sampling larger unit test cases and estimated code performance by profiling execution time relative to input size growth. Using this framework, we conducted an empirical study on six state-of-the-art LCGMs. The results revealed that LCGM-generated code exhibits varying bilingual correctness on an average of 10.5% of tasks, with 39.5% of correct code showing diverse bilingual performance differences. Our findings suggested LCGMs may not consistently generate high-quality code across different languages, providing insights for future research directions.

![从有效性到效率：双语编程问题中，语言模型生成代码的比较评估](../../../paper_images/2406.00602/x1.png)

![从有效性到效率：双语编程问题中，语言模型生成代码的比较评估](../../../paper_images/2406.00602/x2.png)

![从有效性到效率：双语编程问题中，语言模型生成代码的比较评估](../../../paper_images/2406.00602/x3.png)

![从有效性到效率：双语编程问题中，语言模型生成代码的比较评估](../../../paper_images/2406.00602/x4.png)

![从有效性到效率：双语编程问题中，语言模型生成代码的比较评估](../../../paper_images/2406.00602/x5.png)

![从有效性到效率：双语编程问题中，语言模型生成代码的比较评估](../../../paper_images/2406.00602/x6.png)

![从有效性到效率：双语编程问题中，语言模型生成代码的比较评估](../../../paper_images/2406.00602/x7.png)

[Arxiv](https://arxiv.org/abs/2406.00602)