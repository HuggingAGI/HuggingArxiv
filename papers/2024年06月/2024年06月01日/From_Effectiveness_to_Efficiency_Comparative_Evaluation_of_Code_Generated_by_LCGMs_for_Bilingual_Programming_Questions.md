# 从有效性到效率：双语编程问题中，语言模型生成代码的比较评估

发布时间：2024年06月01日

`LLM应用

这篇论文主要关注大型代码生成模型（LCGMs）在不同语言输入下的性能评估，特别是在中文和英语环境下的代码质量和效率。研究通过创建双语编程题测试集和开发自动输入生成工具，评估了LCGMs在双语环境下的代码生成能力。这种研究属于应用层面的探讨，因为它直接关注模型在实际应用中的表现，特别是跨语言环境下的代码生成质量，而不是理论模型的构建或Agent的设计。因此，它更适合归类为LLM应用。` `人工智能`

> From Effectiveness to Efficiency: Comparative Evaluation of Code Generated by LCGMs for Bilingual Programming Questions

# 摘要

> 大型代码生成模型（LCGMs）在编程领域备受瞩目，成绩斐然。但当输入非英语提示时，其性能引发疑虑，因这些模型多基于英语语料库训练，且编程语言与英语相似。现有评估多依赖英语编程题和少量手动测试，难以全面衡量LCGM代码质量。本文聚焦中文与英语，探讨不同语言输入下的代码质量差异，特别是其有效性与效率。双语输入下评估LCGM代码质量面临三大难题：缺乏优质双语编程题数据集、单元测试案例不足以验证全面正确性、比较代码性能的支持不足。为此，我们编制了52个双语编程题测试集，并开发了自动输入生成工具。通过扩大单元测试案例样本，我们强化了正确性验证，并通过执行时间与输入大小增长的关系评估了代码性能。基于此框架，我们对六款顶尖LCGMs进行了实证研究。结果表明，LCGM生成的代码在10.5%的任务上双语正确性不一，39.5%的正确代码在双语性能上呈现差异。这提示我们，LCGMs在不同语言中生成高质量代码的能力可能并不一致，为未来研究指明了方向。

> Large Code Generation Models (LCGMs) have garnered significant attention and achieved promising results across various programming tasks. However, concerns arise regarding performance when using non-English prompts, as these models are primarily trained on English-centric corpora, and most programming language tokens resemble English. Existing benchmarks often rely on English programming questions and limited manual unit test cases, inadequately assessing LCGM-generated code quality. This paper investigates code quality differences, specifically effectiveness and efficiency, when employing different natural languages as inputs, focusing on Chinese and English due to their prominent corpora and LCGM availability. Evaluating LCGM-generated code quality under bilingual inputs presents three challenges: (1) lack of high-quality bilingual programming question datasets, (2) insufficient unit test cases for comprehensive correctness verification, and (3) limited support for comparing generated code performance. To address these challenges, we curated a test suite of 52 bilingual programming questions and developed automated input generators for each. We enhanced correctness verification by sampling larger unit test cases and estimated code performance by profiling execution time relative to input size growth. Using this framework, we conducted an empirical study on six state-of-the-art LCGMs. The results revealed that LCGM-generated code exhibits varying bilingual correctness on an average of 10.5% of tasks, with 39.5% of correct code showing diverse bilingual performance differences. Our findings suggested LCGMs may not consistently generate high-quality code across different languages, providing insights for future research directions.

![从有效性到效率：双语编程问题中，语言模型生成代码的比较评估](../../../paper_images/2406.00602/x1.png)

![从有效性到效率：双语编程问题中，语言模型生成代码的比较评估](../../../paper_images/2406.00602/x2.png)

![从有效性到效率：双语编程问题中，语言模型生成代码的比较评估](../../../paper_images/2406.00602/x3.png)

![从有效性到效率：双语编程问题中，语言模型生成代码的比较评估](../../../paper_images/2406.00602/x4.png)

![从有效性到效率：双语编程问题中，语言模型生成代码的比较评估](../../../paper_images/2406.00602/x5.png)

![从有效性到效率：双语编程问题中，语言模型生成代码的比较评估](../../../paper_images/2406.00602/x6.png)

![从有效性到效率：双语编程问题中，语言模型生成代码的比较评估](../../../paper_images/2406.00602/x7.png)

[Arxiv](https://arxiv.org/abs/2406.00602)