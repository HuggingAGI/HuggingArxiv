# 在AI时代，我们需保持警觉，从创造内容到验证其真实性。

发布时间：2024年06月30日

`LLM应用`

> Staying vigilant in the Age of AI: From content generation to content authentication

# 摘要

> 本文呈现的长江海项目，是对抗生成式AI（GAI）虚假内容的一项创新举措。通过模拟学术会议平台上的实验，我们揭示了公众在辨识AI制造的虚假信息上的困境，尤其是GAI制造的逼真内容。为此，我们创新性地运用ChatGPT等大型语言模型进行真实性评估，并设计了一套工作流程，旨在提升公众识别虚假信息的能力。该流程已应用于Telegram的智能机器人，助力用户在对话中辨别文本真伪。项目采用双重策略：一方面生成虚假内容以洞察其机制，另一方面研发评估技术以削弱其影响。此外，我们还构想了以阅读眼镜和夹子形态的事实核查可穿戴设备。这一计算媒体艺术项目，深刻体现了技术进步、伦理考量与社会意识间的复杂交织。

> This paper presents the Yangtze Sea project, an initiative in the battle against Generative AI (GAI)-generated fake con-tent. Addressing a pressing issue in the digital age, we investigate public reactions to AI-created fabrications through a structured experiment on a simulated academic conference platform. Our findings indicate a profound public challenge in discerning such content, highlighted by GAI's capacity for realistic fabrications. To counter this, we introduce an innovative approach employing large language models like ChatGPT for truthfulness assess-ment. We detail a specific workflow for scrutinizing the authenticity of everyday digital content, aimed at boosting public awareness and capability in identifying fake mate-rials. We apply this workflow to an agent bot on Telegram to help users identify the authenticity of text content through conversations. Our project encapsulates a two-pronged strategy: generating fake content to understand its dynamics and developing assessment techniques to mitigate its impact. As part of that effort we propose the creation of speculative fact-checking wearables in the shape of reading glasses and a clip-on. As a computational media art initiative, this project under-scores the delicate interplay between technological progress, ethical consid-erations, and societal consciousness.

[Arxiv](https://arxiv.org/abs/2407.00922)