# 利用可解释的检查清单揭示评估者LLMs的盲点

发布时间：2024年06月19日

`LLM应用

这篇论文探讨了大型语言模型（LLMs）作为评估其他LLMs文本输出工具的有效性，并提出了一个专门的框架（FBI框架）来检验评估者LLMs在评估其他LLMs的四大核心能力上的表现。研究通过引入特定扰动来测试评估者LLMs是否能察觉到质量的下降，并通过对五大LLMs的深入研究，发现当前评估者LLMs在识别质量下降方面存在不足。这项研究直接关联到LLMs的应用层面，特别是在评估和改进LLMs性能方面的实际应用，因此属于LLM应用分类。` `模型评估`

> Finding Blind Spots in Evaluator LLMs with Interpretable Checklists

# 摘要

> 大型语言模型（LLMs）正日益成为评估其他LLMs文本输出的工具，进而影响着排行榜和发展决策。尽管如此，关于这些评估的准确性和可能引发的误导结论的担忧依旧存在。本研究探讨了LLMs在文本生成任务中作为评估者的有效性，并提出了FBI框架，专门用于检验评估者LLMs在评估其他LLMs四大核心能力上的表现：事实准确性、指令遵循、长篇写作的连贯性及推理能力。我们通过在LLMs生成的答案中引入特定扰动，这些扰动显著影响某一核心能力，来测试评估者LLMs是否能察觉到质量的下降。通过构建2400个扰动答案，涉及22种扰动类型，我们采用多种评估策略，对文献中常用的五大LLMs进行了深入研究。研究发现，当前评估者LLMs在平均超过50%的情况下未能识别出质量下降，单一答案和成对评估均显示出局限性，而基于参考的评估则表现较好。这些发现凸显了当前评估者LLMs的不稳定性，并建议在实际应用中应谨慎使用。相关代码和数据已发布于https://github.com/AI4Bharat/FBI。

> Large Language Models (LLMs) are increasingly relied upon to evaluate text outputs of other LLMs, thereby influencing leaderboards and development decisions. However, concerns persist over the accuracy of these assessments and the potential for misleading conclusions. In this work, we investigate the effectiveness of LLMs as evaluators for text generation tasks. We propose FBI, a novel framework designed to examine the proficiency of Evaluator LLMs in assessing four critical abilities in other LLMs: factual accuracy, instruction following, coherence in long-form writing, and reasoning proficiency. By introducing targeted perturbations in answers generated by LLMs, that clearly impact one of these key capabilities, we test whether an Evaluator LLM can detect these quality drops. By creating a total of 2400 perturbed answers covering 22 perturbation categories, we conduct a comprehensive study using different evaluation strategies on five prominent LLMs commonly used as evaluators in the literature. Our findings reveal significant shortcomings in current Evaluator LLMs, which failed to identify quality drops in over 50\% of cases on average. Single-answer and pairwise evaluations demonstrated notable limitations, whereas reference-based evaluations showed comparatively better performance. These results underscore the unreliable nature of current Evaluator LLMs and advocate for cautious implementation in practical applications. Code and data are available at https://github.com/AI4Bharat/FBI.

![利用可解释的检查清单揭示评估者LLMs的盲点](../../../paper_images/2406.13439/x1.png)

![利用可解释的检查清单揭示评估者LLMs的盲点](../../../paper_images/2406.13439/x2.png)

![利用可解释的检查清单揭示评估者LLMs的盲点](../../../paper_images/2406.13439/x3.png)

[Arxiv](https://arxiv.org/abs/2406.13439)