# AERA Chat：一个自动化且可解释的学生答案评估交互平台

发布时间：2024年10月12日

`LLM应用` `人工智能`

> AERA Chat: An Interactive Platform for Automated Explainable Student Answer Assessment

# 摘要

> 生成评分决策的理由已成为提升自动化评分系统透明度的有效途径。然而，公开理由数据的匮乏和高昂的标注成本，使得现有方法多依赖于 LLM 生成的嘈杂理由。为此，我们推出了 AERA Chat 平台，通过视觉化解释学生答案，简化理由验证。用户可输入问题和答案，获取 LLM 的自动化、可解释评估。平台创新的可视化功能和评估工具，不仅助力教育者评分，还便于研究人员评估不同 LLM 的评估性能和理由质量，或作为高效的标注工具。我们在平台上测试了三种理由生成方法，展示了其卓越性能。

> Generating rationales that justify scoring decisions has emerged as a promising approach to enhance explainability in the development of automated scoring systems. However, the scarcity of publicly available rationale data and the high cost of annotation have resulted in existing methods typically relying on noisy rationales generated by large language models (LLMs). To address these challenges, we have developed AERA Chat, an interactive platform, to provide visually explained assessment of student answers and streamline the verification of rationales. Users can input questions and student answers to obtain automated, explainable assessment results from LLMs. The platform's innovative visualization features and robust evaluation tools make it useful for educators to assist their marking process, and for researchers to evaluate assessment performance and quality of rationales generated by different LLMs, or as a tool for efficient annotation. We evaluated three rationale generation approaches on our platform to demonstrate its capability.

[Arxiv](https://arxiv.org/abs/2410.09507)