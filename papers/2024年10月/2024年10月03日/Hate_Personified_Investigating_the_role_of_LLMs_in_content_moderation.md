# 仇恨的化身：探究 LLM 在内容审核中的作用

发布时间：2024年10月03日

`LLM应用` `社会科学` `人工智能`

> Hate Personified: Investigating the role of LLMs in content moderation

# 摘要

> 在仇恨检测这类主观任务中，LLM 能否准确代表不同群体尚不明朗。我们通过在提示中加入更多上下文，深入研究了 LLM 对地理、人物属性和数值信息的敏感性，以评估其对多样群体需求的反映程度。研究发现，模仿人物属性会导致注释差异，而地理信号则能提升区域对齐效果。此外，LLM 对数值锚点敏感，显示出其能有效利用社区标记和应对对手的能力。我们的研究为在文化敏感场景中应用 LLM 提供了初步指导，并揭示了其中的复杂性。

> For subjective tasks such as hate detection, where people perceive hate differently, the Large Language Model's (LLM) ability to represent diverse groups is unclear. By including additional context in prompts, we comprehensively analyze LLM's sensitivity to geographical priming, persona attributes, and numerical information to assess how well the needs of various groups are reflected. Our findings on two LLMs, five languages, and six datasets reveal that mimicking persona-based attributes leads to annotation variability. Meanwhile, incorporating geographical signals leads to better regional alignment. We also find that the LLMs are sensitive to numerical anchors, indicating the ability to leverage community-based flagging efforts and exposure to adversaries. Our work provides preliminary guidelines and highlights the nuances of applying LLMs in culturally sensitive cases.

[Arxiv](https://arxiv.org/abs/2410.02657)