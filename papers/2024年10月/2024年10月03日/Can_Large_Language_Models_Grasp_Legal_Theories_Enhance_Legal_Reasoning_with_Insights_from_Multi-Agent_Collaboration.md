# 大型语言模型能否理解法律理论？通过多代理协作的洞察力，提升法律推理能力。

发布时间：2024年10月03日

`LLM应用` `人工智能`

> Can Large Language Models Grasp Legal Theories? Enhance Legal Reasoning with Insights from Multi-Agent Collaboration

# 摘要

> 大型语言模型（LLM）在理解和执行复杂法律推理任务方面可能面临挑战。为此，我们设计了一项名为“混淆指控预测”的挑战任务，以更精准地评估 LLM 的法律理论理解和推理能力。同时，我们提出了一个创新框架——多代理法律推理（MALR），通过非参数学习，引导 LLM 自动分解复杂法律任务，并模拟人类学习过程，从法律规则中汲取智慧，从而深化对法律理论的理解，提升法律推理能力。实验结果显示，MALR 在多个真实数据集上有效解决了复杂推理问题，为法律领域的可靠应用奠定了基础。

> Large Language Models (LLMs) could struggle to fully understand legal theories and perform complex legal reasoning tasks. In this study, we introduce a challenging task (confusing charge prediction) to better evaluate LLMs' understanding of legal theories and reasoning capabilities. We also propose a novel framework: Multi-Agent framework for improving complex Legal Reasoning capability (MALR). MALR employs non-parametric learning, encouraging LLMs to automatically decompose complex legal tasks and mimic human learning process to extract insights from legal rules, helping LLMs better understand legal theories and enhance their legal reasoning abilities. Extensive experiments on multiple real-world datasets demonstrate that the proposed framework effectively addresses complex reasoning issues in practical scenarios, paving the way for more reliable applications in the legal domain.

[Arxiv](https://arxiv.org/abs/2410.02507)