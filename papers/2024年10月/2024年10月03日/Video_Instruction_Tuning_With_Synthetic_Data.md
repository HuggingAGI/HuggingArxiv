# 视频指令调整：合成数据的力量

发布时间：2024年10月03日

`LLM应用` `视频处理` `人工智能`

> Video Instruction Tuning With Synthetic Data

# 摘要

> 视频大型多模态模型 (LMM) 的发展因获取高质量原始数据的困难而受阻。为此，我们创建了专用于视频指令跟随的高质量合成数据集 LLaVA-Video-178K，涵盖详细字幕、开放式问答和多项选择等任务。结合现有视觉指令数据进行训练，我们推出了 LLaVA-Video，一个新型视频 LMM。实验显示，LLaVA-Video 在多项视频基准测试中表现优异，证明了我们数据集的有效性。我们计划公开数据集、生成流程及模型检查点。

> The development of video large multimodal models (LMMs) has been hindered by the difficulty of curating large amounts of high-quality raw data from the web. To address this, we propose an alternative approach by creating a high-quality synthetic dataset specifically for video instruction-following, namely LLaVA-Video-178K. This dataset includes key tasks such as detailed captioning, open-ended question-answering (QA), and multiple-choice QA. By training on this dataset, in combination with existing visual instruction tuning data, we introduce LLaVA-Video, a new video LMM. Our experiments demonstrate that LLaVA-Video achieves strong performance across various video benchmarks, highlighting the effectiveness of our dataset. We plan to release the dataset, its generation pipeline, and the model checkpoints.

[Arxiv](https://arxiv.org/abs/2410.02713)