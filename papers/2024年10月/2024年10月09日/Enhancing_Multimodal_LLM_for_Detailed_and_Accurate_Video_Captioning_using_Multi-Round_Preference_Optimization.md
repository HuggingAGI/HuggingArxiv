# 通过多轮偏好优化，提升多模态 LLM 在视频字幕生成中的详细性和准确性。

发布时间：2024年10月09日

`LLM应用` `视频处理`

> Enhancing Multimodal LLM for Detailed and Accurate Video Captioning using Multi-Round Preference Optimization

# 摘要

> 视频蕴含丰富信息，生成详尽准确的自然语言描述是视频理解的核心。本文介绍的视频-SALMONN 2，是一款结合低秩适应（LoRA）的先进视听大型语言模型（LLM），通过定向偏好优化（DPO）提升视频（含音频）字幕质量。我们设计了新指标评估描述的完整性与准确性，并利用DPO优化。为进一步提升训练效果，我们创新了多轮DPO（mrDPO）方法，包括定期更新DPO模型、合并重置LoRA模块（每1,000步），并引入真实字幕指导以稳定训练。针对mrDPO可能导致的非字幕能力遗忘问题，我们提出“重生调优”，即用mrDPO生成字幕作为监督标签微调预DPO LLM。实验显示，mrDPO大幅提升视频-SALMONN 2的字幕准确性，分别降低全局和局部错误率40%和20%，重复率减少35%。最终的70亿参数模型在视频字幕任务中超越GPT-4o和Gemini-1.5-Pro等顶尖模型，同时在同类模型中保持视频问答基准的领先地位。代码、模型及数据将在接受后公开，演示可访问\href{https://video-salmonn-2.github.io}{https://video-salmonn-2.github.io}。

> Videos contain a wealth of information, and generating detailed and accurate descriptions in natural language is a key aspect of video understanding. In this paper, we present video-SALMONN 2, an advanced audio-visual large language model (LLM) with low-rank adaptation (LoRA) designed for enhanced video (with paired audio) captioning through directed preference optimization (DPO). We propose new metrics to evaluate the completeness and accuracy of video descriptions, which are optimized using DPO. To further improve training, we introduce a novel multi-round DPO (mrDPO) approach, which involves periodically updating the DPO reference model, merging and re-initializing the LoRA module as a proxy for parameter updates after each training round (1,000 steps), and incorporating guidance from ground-truth video captions to stabilize the process. To address potential catastrophic forgetting of non-captioning abilities due to mrDPO, we propose rebirth tuning, which finetunes the pre-DPO LLM by using the captions generated by the mrDPO-trained model as supervised labels. Experiments show that mrDPO significantly enhances video-SALMONN 2's captioning accuracy, reducing global and local error rates by 40\% and 20\%, respectively, while decreasing the repetition rate by 35\%. The final video-SALMONN 2 model, with just 7 billion parameters, surpasses leading models such as GPT-4o and Gemini-1.5-Pro in video captioning tasks, while maintaining competitive performance to the state-of-the-art on widely used video question-answering benchmark among models of similar size. Upon acceptance, we will release the code, model checkpoints, and training and test data. Demos are available at \href{https://video-salmonn-2.github.io}{https://video-salmonn-2.github.io}.

[Arxiv](https://arxiv.org/abs/2410.06682)