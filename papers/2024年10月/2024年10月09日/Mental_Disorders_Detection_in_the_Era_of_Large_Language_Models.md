# 大型语言模型时代的精神障碍检测

发布时间：2024年10月09日

`LLM应用` `心理健康`

> Mental Disorders Detection in the Era of Large Language Models

# 摘要

> 本文对比了传统机器学习、编码器模型和大型语言模型 (LLM) 在检测抑郁和焦虑方面的效果。我们分析了五个不同格式的数据集，测试了基于语言特征的 AutoML 模型、多种编码器变体（如 BERT）以及最先进的 LLM。结果显示，LLM 在嘈杂和小型数据集上表现尤为出色，但心理语言学特征和编码器模型在针对临床确诊抑郁的文本训练时，也能达到与 LLM 相当的性能，显示出其在临床应用中的潜力。

> This paper compares the effectiveness of traditional machine learning methods, encoder-based models, and large language models (LLMs) on the task of detecting depression and anxiety. Five datasets were considered, each differing in format and the method used to define the target pathology class. We tested AutoML models based on linguistic features, several variations of encoder-based Transformers such as BERT, and state-of-the-art LLMs as pathology classification models. The results demonstrated that LLMs outperform traditional methods, particularly on noisy and small datasets where training examples vary significantly in text length and genre. However, psycholinguistic features and encoder-based models can achieve performance comparable to language models when trained on texts from individuals with clinically confirmed depression, highlighting their potential effectiveness in targeted clinical applications.

[Arxiv](https://arxiv.org/abs/2410.07129)