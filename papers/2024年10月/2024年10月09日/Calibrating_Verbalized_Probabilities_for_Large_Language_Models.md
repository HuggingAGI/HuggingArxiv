# 优化大型语言模型的概率表达

发布时间：2024年10月09日

`LLM理论` `人工智能`

> Calibrating Verbalized Probabilities for Large Language Models

# 摘要

> 校准口头表达的概率为评估和利用黑箱 LLM 的输出提供了一种新途径。本文探讨了判别任务中概率分布的校准，发现 LLM 在生成类别标签概率方面表现出色，并通过 invert softmax 技巧有效解决了 re-softmax 问题，从而提升了后校准调整的效果。

> Calibrating verbalized probabilities presents a novel approach for reliably assessing and leveraging outputs from black-box Large Language Models (LLMs). Recent methods have demonstrated improved calibration by applying techniques like Platt scaling or temperature scaling to the confidence scores generated by LLMs. In this paper, we explore the calibration of verbalized probability distributions for discriminative tasks. First, we investigate the capability of LLMs to generate probability distributions over categorical labels. We theoretically and empirically identify the issue of re-softmax arising from the scaling of verbalized probabilities, and propose using the invert softmax trick to approximate the "logit" by inverting verbalized probabilities. Through extensive evaluation on three public datasets, we demonstrate: (1) the robust capability of LLMs in generating class distributions, and (2) the effectiveness of the invert softmax trick in estimating logits, which, in turn, facilitates post-calibration adjustments.

[Arxiv](https://arxiv.org/abs/2410.06707)