# 探索并增强基于 LLM 的自动化程序修复的鲁棒性，借助变异测试的力量。

发布时间：2024年10月09日

`LLM应用` `软件开发`

> Exploring and Lifting the Robustness of LLM-powered Automated Program Repair with Metamorphic Testing

# 摘要

> 近年来，大型语言模型驱动的自动化程序修复（LAPR）技术在错误修复方面表现卓越，广泛应用于工业和学术界。然而，LLM对输入提示极为敏感，语义等价的程序表达稍有不同就可能导致修复失败。因此，在实际部署前对LAPR进行鲁棒性测试至关重要，但相关研究匮乏。为此，我们提出了MT-LAPR，一个专为LAPR设计的变异测试框架，总结了开发者在标记、语句和块三个扰动级别上的九种变异关系（MRs）。这些MRs应用于缺陷代码生成测试用例，虽语义等价但影响LAPR推理。实验在Defect4J和QuixBugs数据集及四个最新LLM上进行，结果显示34.4% - 48.5%的测试用例暴露了LAPR的不稳定性，验证了MT-LAPR的有效性，并揭示了代码可读性与LAPR鲁棒性间的正相关。基于此，我们使用MT-LAPR生成的测试用例训练CodeT5代码编辑模型，提升代码可读性，并将其嵌入LAPR流程作为预处理步骤。实验表明，此方法最多可将LAPR鲁棒性提升49.32%。

> In recent years, Large language model-powered Automated Program Repair (LAPR) techniques have achieved state-of-the-art bug-fixing performance and have been pervasively applied and studied in both industry and academia. Nonetheless, LLMs were proved to be highly sensitive to input prompts, with slight differences in the expressions of semantically equivalent programs potentially causing repair failures. Therefore, it is crucial to conduct robustness testing on LAPR techniques before their practical deployment. However, related research is scarce. To this end, we propose MT-LAPR, a Metamorphic Testing framework exclusively for LAPR techniques, which summarizes nine widely-recognized Metamorphic Relations (MRs) by developers across three perturbation levels: token, statement, and block. Afterward, our proposed MRs are applied to buggy codes to generate test cases, which are semantically equivalent yet to affect the inference of LAPR. Experiments are carried out on two extensively examined bug-fixing datasets, i.e., Defect4J and QuixBugs, and four bug-fixing abled LLMs released recently, demonstrating that 34.4% - 48.5% of the test cases expose the instability of LAPR techniques on average, showing the effectiveness of MT-LAPR and uncovering a positive correlation between code readability and the robustness of LAPR techniques. Inspired by the above findings, this paper uses the test cases generated by MT-LAPR as samples to train a CodeT5-based code editing model aiming at improving code readability and then embeds it into the LAPR workflow as a data preprocessing step. Extensive experiments demonstrate that this approach significantly enhances the robustness of LAPR by 49.32% at most.

[Arxiv](https://arxiv.org/abs/2410.07516)