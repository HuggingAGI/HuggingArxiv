# 探究大型视觉-语言模型中，视觉与语言模态下的刻板印象偏差

发布时间：2024年10月09日

`LLM应用` `人工智能` `社会科学`

> : Measuring Stereotypical Bias in Large Vision-Language Models from Vision and Language Modalities

# 摘要

> 大型视觉-语言模型 (LVLMs) 在各领域迅速发展并广泛应用，但其潜在的刻板印象偏差却鲜为人知。我们提出了创新框架 $\texttt{ModSCAN}$，从视觉和语言两方面深入剖析 LVLMs 的刻板印象偏差。该框架针对职业、描述符和个人特质三种场景，评估了性别和种族两大刻板印象属性。研究发现：1) 当前流行的 LVLMs 普遍存在显著偏差，CogVLM 尤为严重；2) 偏差根源可能在于训练数据和预训练模型的固有偏见；3) 特定提示前缀能有效缓解偏差。我们的工作为理解和解决 LVLMs 的刻板印象偏差奠定了基础。

> Large vision-language models (LVLMs) have been rapidly developed and widely used in various fields, but the (potential) stereotypical bias in the model is largely unexplored. In this study, we present a pioneering measurement framework, $\texttt{ModSCAN}$, to $\underline{SCAN}$ the stereotypical bias within LVLMs from both vision and language $\underline{Mod}$alities. $\texttt{ModSCAN}$ examines stereotypical biases with respect to two typical stereotypical attributes (gender and race) across three kinds of scenarios: occupations, descriptors, and persona traits. Our findings suggest that 1) the currently popular LVLMs show significant stereotype biases, with CogVLM emerging as the most biased model; 2) these stereotypical biases may stem from the inherent biases in the training dataset and pre-trained models; 3) the utilization of specific prompt prefixes (from both vision and language modalities) performs well in reducing stereotypical biases. We believe our work can serve as the foundation for understanding and addressing stereotypical bias in LVLMs.

[Arxiv](https://arxiv.org/abs/2410.06967)