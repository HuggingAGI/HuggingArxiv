# SPA-Bench：智能手机代理评估的综合基准

发布时间：2024年10月19日

`Agent` `智能手机` `人工智能`

> SPA-Bench: A Comprehensive Benchmark for SmartPhone Agent Evaluation

# 摘要

> 智能手机代理在高效控制设备方面日益重要，基于 (多模态) 大型语言模型 (MLLM) 的方法成为关键竞争者。公平比较这些代理虽具挑战，但至关重要，需多样化任务、集成不同实现代理及可推广的评估管道。本文介绍 SPA-Bench，一个全面基准，旨在模拟真实世界条件的交互环境中评估 (M)LLM 代理。SPA-Bench 三大贡献：(1) 涵盖系统及第三方应用的多样化任务，涵盖英汉，聚焦日常常用功能；(2) 即插即用框架，使代理与 Android 设备实时交互，集成超十个代理，灵活添加更多；(3) 新颖评估管道，自动评估代理多维度性能，涵盖任务完成及资源消耗七指标。广泛实验揭示解释移动界面、动作基础、记忆保留及执行成本等挑战。提出未来研究方向，以缓解这些困难，更接近实际智能手机代理应用。

> Smartphone agents are increasingly important for helping users control devices efficiently, with (Multimodal) Large Language Model (MLLM)-based approaches emerging as key contenders. Fairly comparing these agents is essential but challenging, requiring a varied task scope, the integration of agents with different implementations, and a generalisable evaluation pipeline to assess their strengths and weaknesses. In this paper, we present SPA-Bench, a comprehensive SmartPhone Agent Benchmark designed to evaluate (M)LLM-based agents in an interactive environment that simulates real-world conditions. SPA-Bench offers three key contributions: (1) A diverse set of tasks covering system and third-party apps in both English and Chinese, focusing on features commonly used in daily routines; (2) A plug-and-play framework enabling real-time agent interaction with Android devices, integrating over ten agents with the flexibility to add more; (3) A novel evaluation pipeline that automatically assesses agent performance across multiple dimensions, encompassing seven metrics related to task completion and resource consumption. Our extensive experiments across tasks and agents reveal challenges like interpreting mobile user interfaces, action grounding, memory retention, and execution costs. We propose future research directions to ease these difficulties, moving closer to real-world smartphone agent applications.

[Arxiv](https://arxiv.org/abs/2410.15164)