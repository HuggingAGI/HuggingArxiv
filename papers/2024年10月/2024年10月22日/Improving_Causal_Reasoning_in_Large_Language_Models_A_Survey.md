# 改进大型语言模型中的因果推理：一项调查

发布时间：2024年10月22日

`LLM应用` `因果推理` `语言模型`

> Improving Causal Reasoning in Large Language Models: A Survey

# 摘要

> 因果推理（CR）是智力的一个关键方面，对于解决问题、决策和理解世界至关重要。虽然大型语言模型（LLMs）可以为其输出生成理由，但它们可靠地进行因果推理的能力仍然不确定，在需要深入理解因果关系的任务中常常表现不佳。在本次调查中，我们对旨在增强 LLMs 因果推理能力的研究进行了全面回顾。我们根据 LLMs 的作用对现有方法进行分类：要么作为推理引擎，要么作为向传统 CR 方法提供知识或数据的助手，然后对每个类别中的方法进行了详细讨论。然后，我们评估了 LLMs 在各种因果推理任务上的性能，提供了关键发现和深入分析。最后，我们从当前的研究中提供了见解，并强调了未来研究的有前途的方向。我们希望这项工作能作为一个全面的资源，促进 LLMs 在因果推理方面的进一步发展。资源可在 https://github.com/chendl02/Awesome-LLM-causal-reasoning 获得。

> Causal reasoning (CR) is a crucial aspect of intelligence, essential for problem-solving, decision-making, and understanding the world. While large language models (LLMs) can generate rationales for their outputs, their ability to reliably perform causal reasoning remains uncertain, often falling short in tasks requiring a deep understanding of causality. In this survey, we provide a comprehensive review of research aimed at enhancing LLMs for causal reasoning. We categorize existing methods based on the role of LLMs: either as reasoning engines or as helpers providing knowledge or data to traditional CR methods, followed by a detailed discussion of the methodologies in each category. We then evaluate the performance of LLMs on various causal reasoning tasks, providing key findings and in-depth analysis. Finally, we provide insights from current studies and highlight promising directions for future research. We aim for this work to serve as a comprehensive resource, fostering further advancements in causal reasoning with LLMs. Resources are available at https://github.com/chendl02/Awesome-LLM-causal-reasoning.

[Arxiv](https://arxiv.org/abs/2410.16676)