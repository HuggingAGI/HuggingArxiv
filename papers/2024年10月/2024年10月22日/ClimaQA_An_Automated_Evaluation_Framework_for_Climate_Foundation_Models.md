# ClimaQA：气候基础模型的一个自动评估框架

发布时间：2024年10月22日

`LLM应用` `气候科学` `基础模型`

> ClimaQA: An Automated Evaluation Framework for Climate Foundation Models

# 摘要

> 在气候科学中使用基础模型最近受到了极大的关注。然而，一个关键问题仍然存在：缺乏能够评估模型输出的质量和科学有效性的综合评估框架。为了解决这个问题，我们开发了 ClimaGen（气候问答生成器），这是一个自动化的算法框架，能够在气候科学家的参与下从研究生教材中生成问答对。因此，我们提出了 ClimaQA-Gold，这是一个由专家注释的基准数据集，以及 ClimaQA-Silver，这是一个大规模、全面的气候科学综合合成问答数据集。最后，我们制定了评估策略，并在我们的基准上比较了不同的大型语言模型（LLM）。我们的结果为用于增强气候基础模型的各种方法提供了新的见解。

> The use of foundation models in climate science has recently gained significant attention. However, a critical issue remains: the lack of a comprehensive evaluation framework capable of assessing the quality and scientific validity of model outputs. To address this issue, we develop ClimaGen (Climate QA Generator), an automated algorithmic framework that generates question-answer pairs from graduate textbooks with climate scientists in the loop. As a result, we present ClimaQA-Gold, an expert-annotated benchmark dataset alongside ClimaQA-Silver, a large-scale, comprehensive synthetic QA dataset for climate science. Finally, we develop evaluation strategies and compare different Large Language Models (LLMs) on our benchmarks. Our results offer novel insights into various approaches used to enhance climate foundation models.

[Arxiv](https://arxiv.org/abs/2410.16701)