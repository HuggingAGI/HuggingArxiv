# 《心灵迷宫：透过文字游戏揭示大型语言模型的心理奥秘》

发布时间：2024年10月02日

`LLM理论` `人工智能` `心理学`

> Mind Scramble: Unveiling Large Language Model Psychology Via Typoglycemia

# 摘要

> 研究 LLM 的外部行为和内部机制，发现其在解决现实世界复杂任务方面潜力巨大。例如，GPT-4 等强大模型已开始展现类似人类的认知能力，如规划、推理和反思。本文提出“LLM 心理学”研究方向，借鉴人类心理学实验，探索 LLM 的认知行为和机制。通过将心理学中的 Typoglycemia 现象应用于 LLM，我们发现：(I) LLM 在宏观上表现出类似人类的行为，如任务准确性较低和令牌/时间消耗较高；(II) LLM 对乱序输入的鲁棒性不同，Typoglycemia 成为无需新数据集的模型评估基准；(III) 复杂逻辑任务（如数学）在乱序形式下更具挑战性；(IV) 每个 LLM 在不同任务中表现出独特的、一致的“认知模式”，揭示了其心理学过程中的普遍机制。我们通过对隐藏层的深入分析来解释这些现象，为未来的 LLM 心理学研究和更深层次的可解释性铺平了道路。

> Research into the external behaviors and internal mechanisms of large language models (LLMs) has shown promise in addressing complex tasks in the physical world. Studies suggest that powerful LLMs, like GPT-4, are beginning to exhibit human-like cognitive abilities, including planning, reasoning, and reflection. In this paper, we introduce a research line and methodology called LLM Psychology, leveraging human psychology experiments to investigate the cognitive behaviors and mechanisms of LLMs. We migrate the Typoglycemia phenomenon from psychology to explore the "mind" of LLMs. Unlike human brains, which rely on context and word patterns to comprehend scrambled text, LLMs use distinct encoding and decoding processes. Through Typoglycemia experiments at the character, word, and sentence levels, we observe: (I) LLMs demonstrate human-like behaviors on a macro scale, such as lower task accuracy and higher token/time consumption; (II) LLMs exhibit varying robustness to scrambled input, making Typoglycemia a benchmark for model evaluation without new datasets; (III) Different task types have varying impacts, with complex logical tasks (e.g., math) being more challenging in scrambled form; (IV) Each LLM has a unique and consistent "cognitive pattern" across tasks, revealing general mechanisms in its psychology process. We provide an in-depth analysis of hidden layers to explain these phenomena, paving the way for future research in LLM Psychology and deeper interpretability.

[Arxiv](https://arxiv.org/abs/2410.01677)