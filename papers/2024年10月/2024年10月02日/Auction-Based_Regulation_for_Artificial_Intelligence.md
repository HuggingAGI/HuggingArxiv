# 人工智能的拍卖式监管

发布时间：2024年10月02日

`LLM理论` `人工智能`

> Auction-Based Regulation for Artificial Intelligence

# 摘要

> 在“快速行动，打破常规”的时代，监管机构在应对AI部署带来的安全、偏见和法律问题时显得有些迟缓。AI模型，如大型语言模型，能够传播错误信息并加剧社会分裂，因此监管机构必须采用一个能够减轻这些风险并确保用户安全的框架。尽管关于如何解决最先进AI模型的安全、偏见和法律问题的讨论很多，但用于监管AI安全的严格且现实的数学框架却很少。我们接受这一挑战，提出了一种基于拍卖的监管机制，该机制可以证明激励模型构建者（i）部署更安全的模型和（ii）参与监管过程。通过推导出的纳什均衡，我们证明了每个参与者的最佳策略是提交一个比规定的最低安全阈值更安全的模型。实证结果显示，我们的监管拍卖分别将安全性和参与率提高了20%和15%，优于仅执行最低安全标准的简单监管框架。

> In an era of "moving fast and breaking things", regulators have moved slowly to pick up the safety, bias, and legal pieces left in the wake of broken Artificial Intelligence (AI) deployment. Since AI models, such as large language models, are able to push misinformation and stoke division within our society, it is imperative for regulators to employ a framework that mitigates these dangers and ensures user safety. While there is much-warranted discussion about how to address the safety, bias, and legal woes of state-of-the-art AI models, the number of rigorous and realistic mathematical frameworks to regulate AI safety is lacking. We take on this challenge, proposing an auction-based regulatory mechanism that provably incentivizes model-building agents (i) to deploy safer models and (ii) to participate in the regulation process. We provably guarantee, via derived Nash Equilibria, that each participating agent's best strategy is to submit a model safer than a prescribed minimum-safety threshold. Empirical results show that our regulatory auction boosts safety and participation rates by 20% and 15% respectively, outperforming simple regulatory frameworks that merely enforce minimum safety standards.

[Arxiv](https://arxiv.org/abs/2410.01871)