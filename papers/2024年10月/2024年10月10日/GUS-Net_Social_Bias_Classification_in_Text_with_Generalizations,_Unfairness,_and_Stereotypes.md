# GUS-Net：通过识别泛化、不公平性和刻板印象，精准分类文本中的社会偏见。

发布时间：2024年10月10日

`LLM应用` `社会偏见检测`

> GUS-Net: Social Bias Classification in Text with Generalizations, Unfairness, and Stereotypes

# 摘要

> 在 NLP 领域，偏见检测尤为关键，尤其是在大型语言模型 (LLM) 广泛应用的背景下。本文推出的 GUS-Net 创新方法，聚焦于概括、不公平和刻板印象三种偏见。通过生成式 AI 和自动化代理，GUS-Net 构建了全面的合成数据集，实现了多标签令牌分类。结合预训练模型的上下文编码，GUS-Net 提升了传统检测方法的准确性和深度。实验表明，GUS-Net 在准确性、F1 分数和汉明损失方面均优于现有技术。其广泛捕捉偏见的能力，使其成为社会偏见检测的宝贵工具。本研究不仅助力 NLP 领域解决隐性偏见，还为未来多领域的研究和应用铺平了道路。相关 Jupyter 笔记本资源可访问：https://github.com/Ethical-Spectacle/fair-ly/tree/main/resources。阅读提示：本文包含可能有害的语言示例，请谨慎阅读。

> The detection of bias in natural language processing (NLP) is a critical challenge, particularly with the increasing use of large language models (LLMs) in various domains. This paper introduces GUS-Net, an innovative approach to bias detection that focuses on three key types of biases: (G)eneralizations, (U)nfairness, and (S)tereotypes. GUS-Net leverages generative AI and automated agents to create a comprehensive synthetic dataset, enabling robust multi-label token classification. Our methodology enhances traditional bias detection methods by incorporating the contextual encodings of pre-trained models, resulting in improved accuracy and depth in identifying biased entities. Through extensive experiments, we demonstrate that GUS-Net outperforms state-of-the-art techniques, achieving superior performance in terms of accuracy, F1-score, and Hamming Loss. The findings highlight GUS-Net's effectiveness in capturing a wide range of biases across diverse contexts, making it a valuable tool for social bias detection in text. This study contributes to the ongoing efforts in NLP to address implicit bias, providing a pathway for future research and applications in various fields. The Jupyter notebooks used to create the dataset and model are available at: https://github.com/Ethical-Spectacle/fair-ly/tree/main/resources.
  Warning: This paper contains examples of harmful language, and reader discretion is recommended.

[Arxiv](https://arxiv.org/abs/2410.08388)