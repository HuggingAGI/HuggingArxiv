# LLM 级联的多目标优化策略

发布时间：2024年10月10日

`LLM应用` `软件开发` `云计算`

> LLM Cascade with Multi-Objective Optimal Consideration

# 摘要

> LLM 在自然语言处理方面表现出色，但其高昂的部署成本限制了实际应用。级联本地和服务器模型为此提供了一种可行方案。现有研究多关注性能与成本的平衡，但现实需求更为复杂。本文提出了一种多目标优化的 LLM 级联策略，不仅考虑性能与成本，还兼顾隐私等额外目标，更贴合实际应用需求。通过三个基准测试的广泛实验，验证了该策略的有效性和优越性。

> Large Language Models (LLMs) have demonstrated exceptional capabilities in understanding and generating natural language. However, their high deployment costs often pose a barrier to practical applications, especially. Cascading local and server models offers a promising solution to this challenge. While existing studies on LLM cascades have primarily focused on the performance-cost trade-off, real-world scenarios often involve more complex requirements. This paper introduces a novel LLM Cascade strategy with Multi-Objective Optimization, enabling LLM cascades to consider additional objectives (e.g., privacy) and better align with the specific demands of real-world applications while maintaining their original cascading abilities. Extensive experiments on three benchmarks validate the effectiveness and superiority of our approach.

[Arxiv](https://arxiv.org/abs/2410.08014)