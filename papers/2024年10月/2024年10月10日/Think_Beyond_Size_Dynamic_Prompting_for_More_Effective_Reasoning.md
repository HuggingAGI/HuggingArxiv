# 超越尺寸，动态提示助力更高效推理

发布时间：2024年10月10日

`LLM理论` `人工智能`

> Think Beyond Size: Dynamic Prompting for More Effective Reasoning

# 摘要

> 本文提出“动态提示”框架，旨在提升大型语言模型的推理能力。与传统静态提示不同，动态提示能根据任务复杂度和模型表现，实时调整提示序列和步骤，从而减少错误和重复，提高问题解决效率，尤其在小型模型中效果显著。实证显示，动态提示让小型模型也能与大型模型一较高下，打破了模型大小决定推理效能的传统观念。

> This paper presents Dynamic Prompting, a novel framework aimed at improving the reasoning capabilities of Large Language Models (LLMs). In contrast to conventional static prompting methods, Dynamic Prompting enables the adaptive modification of prompt sequences and step counts based on real-time task complexity and model performance. This dynamic adaptation facilitates more efficient problem-solving, particularly in smaller models, by reducing hallucinations and repetitive cycles. Our empirical evaluations demonstrate that Dynamic Prompting allows smaller LLMs to perform competitively with much larger models, thereby challenging the conventional emphasis on model size as the primary determinant of reasoning efficacy.

[Arxiv](https://arxiv.org/abs/2410.08130)