# Conversate：借助交互模拟与对话反馈，助力面试练习中的反思学习

发布时间：2024年10月07日

`LLM应用` `人力资源` `教育培训`

> Conversate: Supporting Reflective Learning in Interview Practice Through Interactive Simulation and Dialogic Feedback

# 摘要

> 工作面试对职业生涯至关重要，但练习面试技巧却颇具挑战，尤其是在缺乏人类教练或同伴反馈的情况下。大型语言模型 (LLM) 的进步为此提供了新的可能性。然而，关于此类系统的有效性和用户感知，以及使用 LLM 进行面试练习的利弊，研究甚少。现有的 AI 工具虽展示了潜力，但多为单向反馈，用户仅能接收表现信息。相比之下，对话反馈则是一种双向互动过程，用户可通过互动对话深入学习。本文介绍的 Conversate 是一款基于网络的应用，利用 LLM 进行互动面试模拟和对话反馈，助力面试练习中的反思学习。用户只需输入职位名称，系统便会启动 LLM 代理，通过提问和后续问题进行模拟面试。面试后，系统分析用户回答并指出改进点，用户可注释笔录并撰写反思。最终，用户可与系统进行对话反馈，根据 LLM 代理的指导不断优化答案。

> Job interviews play a critical role in shaping one's career, yet practicing interview skills can be challenging, especially without access to human coaches or peers for feedback. Recent advancements in large language models (LLMs) present an opportunity to enhance the interview practice experience. Yet, little research has explored the effectiveness and user perceptions of such systems or the benefits and challenges of using LLMs for interview practice. Furthermore, while prior work and recent commercial tools have demonstrated the potential of AI to assist with interview practice, they often deliver one-way feedback, where users only receive information about their performance. By contrast, dialogic feedback, a concept developed in learning sciences, is a two-way interaction feedback process that allows users to further engage with and learn from the provided feedback through interactive dialogue. This paper introduces Conversate, a web-based application that supports reflective learning in job interview practice by leveraging large language models (LLMs) for interactive interview simulations and dialogic feedback. To start the interview session, the user provides the title of a job position (e.g., entry-level software engineer) in the system. Then, our system will initialize the LLM agent to start the interview simulation by asking the user an opening interview question and following up with questions carefully adapted to subsequent user responses. After the interview session, our back-end LLM framework will then analyze the user's responses and highlight areas for improvement. Users can then annotate the transcript by selecting specific sections and writing self-reflections. Finally, the user can interact with the system for dialogic feedback, conversing with the LLM agent to learn from and iteratively refine their answers based on the agent's guidance.

[Arxiv](https://arxiv.org/abs/2410.05570)