# 提升医疗应用中大型语言模型的公平性

发布时间：2024年10月07日

`LLM应用` `社会健康`

> Enhancing Equity in Large Language Models for Medical Applications

# 摘要

> 近期研究显示，LLM 在医疗领域的应用潜力巨大，尤其在自动化临床试验匹配和提供医学问答支持方面。然而，我们发现 LLM 的使用存在显著不平等，特别是对受健康社会因素影响的特定群体。若广泛应用，这些不平等可能加剧现有健康差距。为此，我们设计并评估了 EquityGuard 框架，旨在检测和缓解 LLM 医疗应用中的偏见。EquityGuard 通过其偏见检测机制，识别并修正不公平预测，从而提升结果公平性，促进多元群体的健康平等。

> Recent advancements have highlighted the potential of large language models (LLMs) in medical applications, notably in automating Clinical Trial Matching for translational research and providing medical question-answering for clinical decision support. However, our study reveals significant inequities in the use of LLMs, particularly for individuals from specific racial, gender, and underrepresented groups influenced by social determinants of health. These disparities could worsen existing health inequities if LLMs are broadly adopted in healthcare. To address this, we propose and evaluate a novel framework, EquityGuard, designed to detect and mitigate biases in LLM-based medical applications. EquityGuard incorporates a Bias Detection Mechanism capable of identifying and correcting unfair predictions, thus enhancing outcomes and promoting equity across diverse population groups.

[Arxiv](https://arxiv.org/abs/2410.05180)