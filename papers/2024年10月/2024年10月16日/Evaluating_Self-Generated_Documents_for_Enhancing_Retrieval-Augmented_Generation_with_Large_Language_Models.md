# 评估自生成文档，以提升大型语言模型在检索增强生成中的表现

发布时间：2024年10月16日

`RAG` `知识密集型任务` `问答系统`

> Evaluating Self-Generated Documents for Enhancing Retrieval-Augmented Generation with Large Language Models

# 摘要

> 在检索增强生成系统中，结合自生成文档 (SGDs) 与检索内容已成为提升大型语言模型性能的有效策略。然而，以往研究多聚焦于 SGDs 的优化使用，对其固有属性探索不足。本文深入分析了不同类型 SGDs，并在多种知识密集型任务中进行实验。基于系统功能语言学 (SFL)，我们构建了 SGDs 的分类体系，以探究不同类别 SGDs 的影响。研究结果揭示了哪些 SGDs 最能有效提升 LLM 性能，并为在 RAG 中更高效利用 SGDs 以推动知识驱动 QA 任务的进步提供了实用指南。

> In retrieval-augmented generation systems, the integration of self-generated documents (SGDs) alongside retrieved content has emerged as a promising strategy for enhancing the performance of large language model. However, previous research primarily focuses on optimizing the use of SGDs, with the inherent properties of SGDs remaining underexplored. Therefore, this paper conducts a comprehensive analysis of different types of SGDs and experiments on various knowledge-intensive tasks. We develop a taxonomy of SGDs grounded in Systemic Functional Linguistics (SFL) to compare the influence of different SGD categories. Our findings offer key insights into what kinds of SGDs most effectively contribute to improving LLM's performance. The results and further fusion methods based on SGD categories also provide practical guidelines for taking better advantage of SGDs to achieve significant advancements in knowledge-driven QA tasks with RAG.

[Arxiv](https://arxiv.org/abs/2410.13192)