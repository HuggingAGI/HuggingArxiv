# WorldMedQA-V：一款专为多模态语言模型评估设计的多语言、多模态医学考试数据集

发布时间：2024年10月16日

`LLM应用` `人工智能`

> WorldMedQA-V: a multilingual, multimodal medical examination dataset for multimodal language models evaluation

# 摘要

> 多模态/视觉语言模型 (VLMs) 在医疗领域的应用日益广泛，因此需要强大的基准来确保其安全性、有效性和公平性。虽然从国家医学考试中提取的多项选择题和答案 (QA) 数据集一直是宝贵的评估工具，但现有数据集大多是纯文本的，且仅在有限的语言和国家子集中可用。为此，我们推出了 WorldMedQA-V，这是一个多语言、多模态的基准数据集，专门用于评估医疗领域的 VLMs。WorldMedQA-V 包含来自四个国家（巴西、以色列、日本和西班牙）的 568 个带标签的多项选择 QA 与 568 张医学图像配对，涵盖原始语言和由本地临床医生验证的英语翻译。我们还提供了常见开源和闭源模型在本地语言和英语翻译下的基线性能，以及有无图像提供给模型的性能。WorldMedQA-V 旨在更好地匹配 AI 系统与多样化的医疗环境，推动更公平、有效和具有代表性的应用。

> Multimodal/vision language models (VLMs) are increasingly being deployed in healthcare settings worldwide, necessitating robust benchmarks to ensure their safety, efficacy, and fairness. Multiple-choice question and answer (QA) datasets derived from national medical examinations have long served as valuable evaluation tools, but existing datasets are largely text-only and available in a limited subset of languages and countries. To address these challenges, we present WorldMedQA-V, an updated multilingual, multimodal benchmarking dataset designed to evaluate VLMs in healthcare. WorldMedQA-V includes 568 labeled multiple-choice QAs paired with 568 medical images from four countries (Brazil, Israel, Japan, and Spain), covering original languages and validated English translations by native clinicians, respectively. Baseline performance for common open- and closed-source models are provided in the local language and English translations, and with and without images provided to the model. The WorldMedQA-V benchmark aims to better match AI systems to the diverse healthcare environments in which they are deployed, fostering more equitable, effective, and representative applications.

[Arxiv](https://arxiv.org/abs/2410.12722)