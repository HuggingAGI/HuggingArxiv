# 自供电 LLM 模态扩展，专为大型语音-文本模型设计

发布时间：2024年10月04日

`LLM应用` `语音识别` `人工智能`

> Self-Powered LLM Modality Expansion for Large Speech-Text Models

# 摘要

> 大型语言模型 (LLM) 在多任务中表现出色，显示出整合语音能力、扩展为大型语音-文本模型 (LSM) 的潜力。尽管语音-文本统一预训练和多模态数据指令微调带来诸多好处，但这些方法往往资源消耗巨大，且易过度适应特定任务。本研究通过改进普通指令微调的局限性，优化了语音数据集在 LSM 训练中的应用。我们发现，LSM 存在语音锚定偏差，即过度依赖语音输入，误将语音模态视为指令，忽视了文本指令。为此，我们提出自供电 LSM，利用模型生成的增强语音识别数据进行更有效的指令微调。实验证明，自供电 LSM 有效缓解了语音锚定偏差，提升了语音与文本模态的融合效果。相关数据、代码和脚本已公开，详见 https://github.com/ytf-philp/Self-powered-LSM。

> Large language models (LLMs) exhibit remarkable performance across diverse tasks, indicating their potential for expansion into large speech-text models (LSMs) by integrating speech capabilities. Although unified speech-text pre-training and multimodal data instruction-tuning offer considerable benefits, these methods generally entail significant resource demands and tend to overfit specific tasks. This study aims to refine the use of speech datasets for LSM training by addressing the limitations of vanilla instruction tuning. We explore the instruction-following dynamics within LSMs, identifying a critical issue termed speech anchor bias-a tendency for LSMs to over-rely on speech inputs, mistakenly interpreting the entire speech modality as directives, thereby neglecting textual instructions. To counteract this bias, we introduce a self-powered LSM that leverages augmented automatic speech recognition data generated by the model itself for more effective instruction tuning. Our experiments across a range of speech-based tasks demonstrate that self-powered LSM mitigates speech anchor bias and improves the fusion of speech and text modalities in LSMs. Data, code and scripts are freely available at https://github.com/ytf-philp/Self-powered-LSM.

[Arxiv](https://arxiv.org/abs/2410.03798)