# 移动平台上大型语言模型的性能基准测试：全面解析

发布时间：2024年10月04日

`LLM应用` `移动设备` `人工智能`

> Large Language Model Performance Benchmarking on Mobile Platforms: A Thorough Evaluation

# 摘要

> 随着 LLM 深入融入我们的生活，用户隐私问题催生了本地部署的趋势。轻量级 LLM 如 Gemini Nano 和 LLAMA2 7B 能在手机上运行，增强用户数据控制。我们关注其在商用手机上的性能，为此进行了全面测量。评估涵盖用户体验指标（如吞吐量、延迟、电池消耗）和开发者关注点（如资源利用、DVFS 策略、推理引擎）。我们还分析了硬件与系统动态对 LLM 性能的影响，助力开发者解决瓶颈。此外，比较了各大厂商的移动 SoC，揭示其在处理 LLM 任务时的性能差异。期望本研究能为设备上 LLM 开发及未来移动系统设计提供洞见。

> As large language models (LLMs) increasingly integrate into every aspect of our work and daily lives, there are growing concerns about user privacy, which push the trend toward local deployment of these models. There are a number of lightweight LLMs (e.g., Gemini Nano, LLAMA2 7B) that can run locally on smartphones, providing users with greater control over their personal data. As a rapidly emerging application, we are concerned about their performance on commercial-off-the-shelf mobile devices. To fully understand the current landscape of LLM deployment on mobile platforms, we conduct a comprehensive measurement study on mobile devices. We evaluate both metrics that affect user experience, including token throughput, latency, and battery consumption, as well as factors critical to developers, such as resource utilization, DVFS strategies, and inference engines. In addition, we provide a detailed analysis of how these hardware capabilities and system dynamics affect on-device LLM performance, which may help developers identify and address bottlenecks for mobile LLM applications. We also provide comprehensive comparisons across the mobile system-on-chips (SoCs) from major vendors, highlighting their performance differences in handling LLM workloads. We hope that this study can provide insights for both the development of on-device LLMs and the design for future mobile system architecture.

[Arxiv](https://arxiv.org/abs/2410.03613)