# 当大型语言模型走向网络：Web 赋能的 LLM 带来的新兴威胁

发布时间：2024年10月18日

`LLM应用` `网络安全` `人工智能`

> When LLMs Go Online: The Emerging Threat of Web-Enabled LLMs

# 摘要

> 大型语言模型 (LLM) 的进步使其成为能够规划和使用多种工具的智能系统。这些 LLM 代理常与网络工具结合，获取多样信息。尽管这些进步在多领域带来显著益处，但也增加了恶意使用的风险，尤其是在涉及个人信息的网络攻击中。我们研究了滥用 LLM 代理进行个人数据网络攻击的风险，探讨了 LLM 代理在网络攻击中的潜力、网络工具的增强作用，以及使用 LLM 代理发起攻击的便捷性。我们分析了三种攻击场景：收集个人身份信息 (PII)、生成冒充帖子和创建钓鱼邮件。实验显示，LLM 代理在这些攻击中表现出色：收集 PII 的准确率高达 95.9%，冒充帖子的真实性评估达 93.9%，钓鱼邮件的点击率高达 46.67%。此外，研究强调了现有防护措施的不足，迫切需要更强的安全措施来防止 LLM 代理的滥用。

> Recent advancements in Large Language Models (LLMs) have established them as agentic systems capable of planning and interacting with various tools. These LLM agents are often paired with web-based tools, enabling access to diverse sources and real-time information. Although these advancements offer significant benefits across various applications, they also increase the risk of malicious use, particularly in cyberattacks involving personal information. In this work, we investigate the risks associated with misuse of LLM agents in cyberattacks involving personal data. Specifically, we aim to understand: 1) how potent LLM agents can be when directed to conduct cyberattacks, 2) how cyberattacks are enhanced by web-based tools, and 3) how affordable and easy it becomes to launch cyberattacks using LLM agents. We examine three attack scenarios: the collection of Personally Identifiable Information (PII), the generation of impersonation posts, and the creation of spear-phishing emails. Our experiments reveal the effectiveness of LLM agents in these attacks: LLM agents achieved a precision of up to 95.9% in collecting PII, up to 93.9% of impersonation posts created by LLM agents were evaluated as authentic, and the click rate for links in spear phishing emails created by LLM agents reached up to 46.67%. Additionally, our findings underscore the limitations of existing safeguards in contemporary commercial LLMs, emphasizing the urgent need for more robust security measures to prevent the misuse of LLM agents.

[Arxiv](https://arxiv.org/abs/2410.14569)