# 跨语言声明验证中，多语言大型语言模型的翻译偏差与准确性比较研究

发布时间：2024年10月14日

`LLM应用` `信息安全`

> A Comparative Study of Translation Bias and Accuracy in Multilingual Large Language Models for Cross-Language Claim Verification

# 摘要

> 随着数字错误信息的增多，多语言大型语言模型 (LLM) 在事实核查中的应用备受关注。本研究针对 15 种语言（涵盖罗曼语、斯拉夫语、突厥语、印欧语和卡尔特维尔语），系统评估了翻译偏差及 LLM 的跨语言验证效果。通过 XFACT 数据集，我们比较了预翻译和自翻译两种方法对准确性和偏差的影响，并以 mBERT 在英语数据集上的表现为基准，分析各语言的准确性。研究发现，低资源语言因训练数据不足，直接推理准确性较低；而大型模型在自翻译中表现更佳，能提高翻译准确性并减少偏差。这表明，平衡多语言训练，尤其是低资源语言，对于确保事实核查工具的公平使用、降低错误信息传播风险至关重要。

> The rise of digital misinformation has heightened interest in using multilingual Large Language Models (LLMs) for fact-checking. This study systematically evaluates translation bias and the effectiveness of LLMs for cross-lingual claim verification across 15 languages from five language families: Romance, Slavic, Turkic, Indo-Aryan, and Kartvelian. Using the XFACT dataset to assess their impact on accuracy and bias, we investigate two distinct translation methods: pre-translation and self-translation. We use mBERT's performance on the English dataset as a baseline to compare language-specific accuracies. Our findings reveal that low-resource languages exhibit significantly lower accuracy in direct inference due to underrepresentation in the training data. Furthermore, larger models demonstrate superior performance in self-translation, improving translation accuracy and reducing bias. These results highlight the need for balanced multilingual training, especially in low-resource languages, to promote equitable access to reliable fact-checking tools and minimize the risk of spreading misinformation in different linguistic contexts.

[Arxiv](https://arxiv.org/abs/2410.10303)