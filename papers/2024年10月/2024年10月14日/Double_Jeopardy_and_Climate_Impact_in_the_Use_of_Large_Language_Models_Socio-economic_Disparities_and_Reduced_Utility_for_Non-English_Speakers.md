# 大型语言模型的双重风险与气候影响：社会经济差异及非英语使用者的效用下降

发布时间：2024年10月14日

`LLM应用` `人工智能` `社会公平`

> Double Jeopardy and Climate Impact in the Use of Large Language Models: Socio-economic Disparities and Reduced Utility for Non-English Speakers

# 摘要

> AI，尤其是 LLM，本应弥合语言和信息鸿沟，助力发展中国家经济。然而，数据分析显示，这些优势大多偏向英语使用者。低收入和中等偏下收入国家的语言使用者在使用 GPT 模型时，因 tokenization 机制，成本高出 4 至 6 倍。约 15 亿人因此陷入“双重困境”：高成本与低性能。LLM 的 tokenization 不仅加剧了不平等，还影响了气候。我们呼吁开发更公平的算法，让所有语言群体受益。

> Artificial Intelligence (AI), particularly large language models (LLMs), holds the potential to bridge language and information gaps, which can benefit the economies of developing nations. However, our analysis of FLORES-200, FLORES+, Ethnologue, and World Development Indicators data reveals that these benefits largely favor English speakers. Speakers of languages in low-income and lower-middle-income countries face higher costs when using OpenAI's GPT models via APIs because of how the system processes the input -- tokenization. Around 1.5 billion people, speaking languages primarily from lower-middle-income countries, could incur costs that are 4 to 6 times higher than those faced by English speakers. Disparities in LLM performance are significant, and tokenization in models priced per token amplifies inequalities in access, cost, and utility. Moreover, using the quality of translation tasks as a proxy measure, we show that LLMs perform poorly in low-resource languages, presenting a ``double jeopardy" of higher costs and poor performance for these users. We also discuss the direct impact of fragmentation in tokenizing low-resource languages on climate. This underscores the need for fairer algorithm development to benefit all linguistic groups.

[Arxiv](https://arxiv.org/abs/2410.10665)