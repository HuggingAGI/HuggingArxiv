# 探究大型语言模型在引用生成方面的潜力

发布时间：2024年10月14日

`RAG` `人工智能`

> On the Capacity of Citation Generation by Large Language Models

# 摘要

> RAG 作为一种有前景的方法，可以缓解 LLM 中的“幻觉”问题，因为它能将外部可追踪资源纳入响应生成。然而，现有研究大多关注提升响应质量，却忽略了准确归因来源的能力。本研究系统分析了 LLM 在响应生成中的引用能力，并引入新方法增强这一能力。我们在两个基准数据集上评估了七个常用 LLM 的引用质量，并提出新指标消除现有指标的过度惩罚。此外，我们提出了一种生成然后精炼的方法，在不改变响应文本的情况下优化引用。实验结果显示，我们的方法显著提升了 LLM 生成响应中的引用质量。

> Retrieval-augmented generation (RAG) appears as a promising method to alleviate the "hallucination" problem in large language models (LLMs), since it can incorporate external traceable resources for response generation. The essence of RAG in combating the hallucination issue lies in accurately attributing claims in responses to the corresponding retrieved documents. However, most of existing works focus on improving the quality of generated responses from the LLM, while largely overlooked its ability to attribute sources accurately. In this study, we conduct a systematic analysis about the capabilities of LLMs in generating citations within response generation, and further introduce a novel method to enhance their citation generation abilities. Specifically, we evaluate both the correctness and citation quality for seven widely-used LLMs on two benchmark datasets. Meanwhile, we introduce new citation evaluation metrics to eliminate the over-penalization of unnecessary and excessive citations in existing metrics. Furthermore, we propose a Generate-then-Refine method that completes relevant citations and removes irrelevant ones without altering the response text. The results on WebGLM-QA, ASQA and ELI5 datasets show that our method substantially improves the quality of citations in responses generated by LLMs.

[Arxiv](https://arxiv.org/abs/2410.11217)