# ProtocoLLM：专为特定科学领域协议制定任务设计的 LLM 自动评估框架

发布时间：2024年10月06日

`LLM应用` `生物技术`

> ProtocoLLM: Automatic Evaluation Framework of LLMs on Domain-Specific Scientific Protocol Formulation Tasks

# 摘要

> 自动生成机器人可执行的科学协议能大幅提速科研进程。LLM 在科学协议制定任务中表现优异，但评估其能力仍依赖人工。为此，我们设计了灵活的自动评估框架 ProtocoLLM，通过提示目标模型和 GPT-4 仅用预设实验室操作提取生物协议伪代码，并用 LLAM-EVAL 评估输出，GPT-4 伪代码作基线，Llama-3 作评判。LLAM-EVAL 方法灵活且免费，适用于多种评估模型、材料和标准。我们测试了 GPT 变体、Llama、Mixtral、Gemma、Cohere 和 Gemini，发现 GPT 和 Cohere 尤为出色。此外，我们推出了 BIOPROT 2.0 数据集，含生物协议及伪代码，助力 LLM 在协议制定与评估。此框架可扩展至各领域，评估 LLM 在特定目标协议生成任务中的表现。

> Automated generation of scientific protocols executable by robots can significantly accelerate scientific research processes. Large Language Models (LLMs) excel at Scientific Protocol Formulation Tasks (SPFT), but the evaluation of their capabilities rely on human evaluation. Here, we propose a flexible, automatic framework to evaluate LLM's capability on SPFT: ProtocoLLM. This framework prompts the target model and GPT-4 to extract pseudocode from biology protocols using only predefined lab actions and evaluates the output of target model using LLAM-EVAL, the pseudocode generated by GPT-4 serving as a baseline and Llama-3 acting as the evaluator. Our adaptable prompt-based evaluation method, LLAM-EVAL, offers significant flexibility in terms of evaluation model, material, criteria, and is free of cost. We evaluate GPT variations, Llama, Mixtral, Gemma, Cohere, and Gemini. Overall, we find that GPT and Cohere is a powerful scientific protocol formulators. We also introduce BIOPROT 2.0, a dataset with biology protocols and corresponding pseudocodes, which can aid LLMs in formulation and evaluation of SPFT. Our work is extensible to assess LLMs on SPFT across various domains and other fields that require protocol generation for specific goals.

[Arxiv](https://arxiv.org/abs/2410.04601)