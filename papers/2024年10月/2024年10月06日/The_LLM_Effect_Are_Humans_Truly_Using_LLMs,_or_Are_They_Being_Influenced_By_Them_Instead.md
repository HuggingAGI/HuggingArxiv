# LLM 效应：人类是在利用 LLM，还是反被其左右？

发布时间：2024年10月06日

`LLM应用` `政策研究` `人工智能`

> The LLM Effect: Are Humans Truly Using LLMs, or Are They Being Influenced By Them Instead?

# 摘要

> LLM 在分析任务中表现出色，接近人类水平，因此被用于复杂分析。但在政策研究等领域的专业任务中，其能力仍待验证。本文通过人-LLM 合作研究，探讨了 LLM 在专业任务中的效率与准确性。研究发现，LLM 生成的主题列表与人类结果高度一致，但偶尔遗漏特定主题。虽然 LLM 能加速任务，但也可能引入偏见，影响分析深度。这提出了效率与偏见风险之间的关键权衡问题。

> Large Language Models (LLMs) have shown capabilities close to human performance in various analytical tasks, leading researchers to use them for time and labor-intensive analyses. However, their capability to handle highly specialized and open-ended tasks in domains like policy studies remains in question. This paper investigates the efficiency and accuracy of LLMs in specialized tasks through a structured user study focusing on Human-LLM partnership. The study, conducted in two stages-Topic Discovery and Topic Assignment-integrates LLMs with expert annotators to observe the impact of LLM suggestions on what is usually human-only analysis. Results indicate that LLM-generated topic lists have significant overlap with human generated topic lists, with minor hiccups in missing document-specific topics. However, LLM suggestions may significantly improve task completion speed, but at the same time introduce anchoring bias, potentially affecting the depth and nuance of the analysis, raising a critical question about the trade-off between increased efficiency and the risk of biased analysis.

[Arxiv](https://arxiv.org/abs/2410.04699)