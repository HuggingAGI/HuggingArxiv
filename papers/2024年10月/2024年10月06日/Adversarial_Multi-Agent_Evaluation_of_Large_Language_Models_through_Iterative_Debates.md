# 大型语言模型通过迭代辩论进行对抗性多智能体评估

发布时间：2024年10月06日

`LLM应用` `人工智能`

> Adversarial Multi-Agent Evaluation of Large Language Models through Iterative Debates

# 摘要

> 本文探讨了利用 LLM 自身评估其输出的最佳架构。我们提出了一种创新框架，将 LLM 视为交互代理集合中的辩护者，通过法官和陪审团系统捍卫答案并得出结论。相较于传统的人类评估或自动化指标，这种方法更具动态性和全面性。我们深入探讨了框架的动机、核心组件及其优势。此外，我们构建了一个概率模型，用于评估迭代辩护系统带来的错误减少。最后，我们设计了实验以验证多辩护者架构的有效性，并展望了未来的研究方向。

> This paper explores optimal architectures for evaluating the outputs of large language models (LLMs) using LLMs themselves. We propose a novel framework that interprets LLMs as advocates within an ensemble of interacting agents, allowing them to defend their answers and reach conclusions through a judge and jury system. This approach offers a more dynamic and comprehensive evaluation process compared to traditional human-based assessments or automated metrics. We discuss the motivation behind this framework, its key components, and comparative advantages. We also present a probabilistic model to evaluate the error reduction achieved by iterative advocate systems. Finally, we outline experiments to validate the effectiveness of multi-advocate architectures and discuss future research directions.

[Arxiv](https://arxiv.org/abs/2410.04663)