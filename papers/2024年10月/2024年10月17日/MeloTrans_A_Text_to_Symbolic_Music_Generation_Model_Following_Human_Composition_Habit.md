# MeloTrans：一款模仿人类作曲习惯的文本转符号音乐生成模型

发布时间：2024年10月17日

`其他` `人工智能`

> MeloTrans: A Text to Symbolic Music Generation Model Following Human Composition Habit

# 摘要

> 当前，神经网络模型在序列预测方面表现出色，广泛应用于自动作曲。然而，人类作曲方式与神经网络截然不同。作曲家通常从创作音乐主题开始，通过一系列规则发展成完整的音乐作品，确保音乐具有特定结构和变化模式。神经网络难以从训练数据中学习这些作曲规则，导致生成音乐缺乏音乐性和多样性。本文提出，结合神经网络的学习能力与人类知识，可能带来更佳结果。为此，我们创建了POP909_M数据集，首次包含音乐主题及其变体的标签，为模仿人类作曲习惯奠定基础。基于此，我们提出MeloTrans模型，利用主题发展规则进行文本到音乐的作曲。实验显示，MeloTrans不仅超越现有音乐生成模型，甚至优于ChatGPT-4等大型语言模型。这强调了融合人类智慧与神经网络能力，对实现卓越符号音乐生成的重要性。

> At present, neural network models show powerful sequence prediction ability and are used in many automatic composition models. In comparison, the way humans compose music is very different from it. Composers usually start by creating musical motifs and then develop them into music through a series of rules. This process ensures that the music has a specific structure and changing pattern. However, it is difficult for neural network models to learn these composition rules from training data, which results in a lack of musicality and diversity in the generated music. This paper posits that integrating the learning capabilities of neural networks with human-derived knowledge may lead to better results. To archive this, we develop the POP909$\_$M dataset, the first to include labels for musical motifs and their variants, providing a basis for mimicking human compositional habits. Building on this, we propose MeloTrans, a text-to-music composition model that employs principles of motif development rules. Our experiments demonstrate that MeloTrans excels beyond existing music generation models and even surpasses Large Language Models (LLMs) like ChatGPT-4. This highlights the importance of merging human insights with neural network capabilities to achieve superior symbolic music generation.

[Arxiv](https://arxiv.org/abs/2410.13419)