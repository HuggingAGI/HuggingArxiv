# VL-GLUE：一套基础且具挑战性的视觉-语言推理任务集

发布时间：2024年10月17日

`其他` `人工智能` `计算机视觉`

> VL-GLUE: A Suite of Fundamental yet Challenging Visuo-Linguistic Reasoning Tasks

# 摘要

> 从图像、文本和音频等异构输入中进行推理，是人类日常任务的关键技能。同样，高级AI系统也需要这种能力。尽管当前最先进的模型在计算机视觉和NLP任务上已接近人类水平，但在需要视觉与文本联合推理的任务上仍显不足。受GLUE基准的启发，我们提出了VL-GLUE，一个包含超过10万个样本、涵盖七种任务的视觉-语言推理基准。该基准不仅涵盖了从合成图形到日常场景的多种图像类型，还包括了从烹饪到政治等多个领域的文本，突显了多模态理解在现实世界中的重要性。我们发现，现有的大规模视觉-语言模型在此基准上表现不佳，因此呼吁开发更强大的视觉-语言推理系统。

> Deriving inference from heterogeneous inputs (such as images, text, and audio) is an important skill for humans to perform day-to-day tasks. A similar ability is desirable for the development of advanced Artificial Intelligence (AI) systems. While state-of-the-art models are rapidly closing the gap with human-level performance on diverse computer vision and NLP tasks separately, they struggle to solve tasks that require joint reasoning over visual and textual modalities. Inspired by GLUE (Wang et. al., 2018)- a multitask benchmark for natural language understanding, we propose VL-GLUE in this paper. VL-GLUE consists of over 100k samples spanned across seven different tasks, which at their core require visuo-linguistic reasoning. Moreover, our benchmark comprises of diverse image types (from synthetically rendered figures, and day-to-day scenes to charts and complex diagrams) and includes a broad variety of domain-specific text (from cooking, politics, and sports to high-school curricula), demonstrating the need for multi-modal understanding in the real-world. We show that this benchmark is quite challenging for existing large-scale vision-language models and encourage development of systems that possess robust visuo-linguistic reasoning capabilities.

[Arxiv](https://arxiv.org/abs/2410.13666)