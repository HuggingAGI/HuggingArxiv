# BQA：专为视频大型语言模型设计的身体语言问答数据集

发布时间：2024年10月17日

`LLM应用` `人工智能` `情感分析`

> BQA: Body Language Question Answering Dataset for Video Large Language Models

# 摘要

> 人类交流中，非语言线索如面部表情、眼神接触和肢体语言起着重要作用。这些非语言交流缺乏正式规则，需要复杂的常识推理。让视频大型语言模型（VideoLLMs）准确解读肢体语言是一大挑战，因为人类的无意识动作易导致模型误解。为此，我们创建了BQA数据集，包含26种情感标签的肢体语言短视频片段，以测试模型解读情感的能力。评估结果显示，理解肢体语言颇具挑战，且某些VideoLLMs的答案存在年龄和种族偏见。该数据集现已开放使用。

> A large part of human communication relies on nonverbal cues such as facial expressions, eye contact, and body language. Unlike language or sign language, such nonverbal communication lacks formal rules, requiring complex reasoning based on commonsense understanding. Enabling current Video Large Language Models (VideoLLMs) to accurately interpret body language is a crucial challenge, as human unconscious actions can easily cause the model to misinterpret their intent. To address this, we propose a dataset, BQA, a body language question answering dataset, to validate whether the model can correctly interpret emotions from short clips of body language comprising 26 emotion labels of videos of body language. We evaluated various VideoLLMs on BQA and revealed that understanding body language is challenging, and our analyses of the wrong answers by VideoLLMs show that certain VideoLLMs made significantly biased answers depending on the age group and ethnicity of the individuals in the video. The dataset is available.

[Arxiv](https://arxiv.org/abs/2410.13206)