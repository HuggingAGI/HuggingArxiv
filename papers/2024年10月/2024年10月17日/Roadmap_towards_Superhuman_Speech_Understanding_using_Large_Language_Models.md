# 迈向超人类语音理解：大型语言模型的路线图

发布时间：2024年10月17日

`LLM应用` `语音识别` `人工智能`

> Roadmap towards Superhuman Speech Understanding using Large Language Models

# 摘要

> 大型语言模型 (LLM) 的成功激发了整合语音和音频数据的探索，旨在打造能处理文本与非文本输入的通用基础模型。近期如 GPT-4o 的突破，展示了端到端语音 LLM 的广阔前景，这些模型能保留非语义信息与世界知识，助力更深层次的语音理解。为推动语音 LLM 的发展，我们绘制了一条从基础自动语音识别 (ASR) 到整合非语义与抽象声学知识的高级超人类模型的五级路线图。同时，我们设计了 SAGI 基准，以标准化各级别任务的关键方面，揭示了抽象声学知识应用的挑战与能力完整性。研究发现，处理副语言线索与抽象声学知识仍存不足，并指明了未来研究方向。本文不仅勾勒了语音 LLM 的发展蓝图，还引入了评估基准，深入剖析了其当前瓶颈与未来潜力。

> The success of large language models (LLMs) has prompted efforts to integrate speech and audio data, aiming to create general foundation models capable of processing both textual and non-textual inputs. Recent advances, such as GPT-4o, highlight the potential for end-to-end speech LLMs, which preserves non-semantic information and world knowledge for deeper speech understanding. To guide the development of speech LLMs, we propose a five-level roadmap, ranging from basic automatic speech recognition (ASR) to advanced superhuman models capable of integrating non-semantic information with abstract acoustic knowledge for complex tasks. Moreover, we design a benchmark, SAGI Bechmark, that standardizes critical aspects across various tasks in these five levels, uncovering challenges in using abstract acoustic knowledge and completeness of capability. Our findings reveal gaps in handling paralinguistic cues and abstract acoustic knowledge, and we offer future directions. This paper outlines a roadmap for advancing speech LLMs, introduces a benchmark for evaluation, and provides key insights into their current limitations and potential.

[Arxiv](https://arxiv.org/abs/2410.13268)