# 大型语言模型易受迷惑：定量指标揭示其安全隐忧与类型学解析

发布时间：2024年10月17日

`LLM理论` `人工智能` `语言学`

> Large Language Models are Easily Confused: A Quantitative Metric, Security Implications and Typological Analysis

# 摘要

> 语言混乱是指大型语言模型 (LLM) 生成的文本既不符合预期语言，也不符合上下文要求。这种现象在 LLM 的文本生成中构成了重大挑战，常表现为不稳定和不可预测的行为。我们推测，LLM 的这种固有脆弱性中存在语言规律性，并揭示了跨 LLM 的语言混乱模式。为此，我们提出了一种新的度量标准——语言混乱熵，旨在基于语言类型学和词汇变异所提供的语言分布，直接测量和量化这种混乱。通过与语言混乱基准的综合比较，我们验证了该度量的有效性，揭示了跨 LLM 的语言混乱模式。此外，我们将语言混乱与 LLM 安全性联系起来，发现多语言嵌入反转攻击中的特定模式。我们的分析表明，语言类型学不仅提供了理论基础的解释，还为利用语言相似性提升 LLM 对齐和安全性提供了宝贵见解。

> Language Confusion is a phenomenon where Large Language Models (LLMs) generate text that is neither in the desired language, nor in a contextually appropriate language. This phenomenon presents a critical challenge in text generation by LLMs, often appearing as erratic and unpredictable behavior. We hypothesize that there are linguistic regularities to this inherent vulnerability in LLMs and shed light on patterns of language confusion across LLMs. We introduce a novel metric, Language Confusion Entropy, designed to directly measure and quantify this confusion, based on language distributions informed by linguistic typology and lexical variation. Comprehensive comparisons with the Language Confusion Benchmark (Marchisio et al., 2024) confirm the effectiveness of our metric, revealing patterns of language confusion across LLMs. We further link language confusion to LLM security, and find patterns in the case of multilingual embedding inversion attacks. Our analysis demonstrates that linguistic typology offers theoretically grounded interpretation, and valuable insights into leveraging language similarities as a prior for LLM alignment and security.

[Arxiv](https://arxiv.org/abs/2410.13237)