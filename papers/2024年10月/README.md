# 2024年10月

2024年10月17日

- [A Common Pitfall of Margin-based Language Model Alignment: Gradient Entanglement](2024年10月17日/A_Common_Pitfall_of_Margin-based_Language_Model_Alignment_Gradient_Entanglement.md)

    - [翻译: 语言模型对齐中的常见误区：边界依赖导致的梯度纠缠](2024年10月17日/A_Common_Pitfall_of_Margin-based_Language_Model_Alignment_Gradient_Entanglement.md)

- [A Comparative Study on Reasoning Patterns of OpenAI's o1 Model](2024年10月17日/A_Comparative_Study_on_Reasoning_Patterns_of_OpenAI's_o1_Model.md)

    - [翻译: 探究 OpenAI o1 模型推理模式的对比研究](2024年10月17日/A_Comparative_Study_on_Reasoning_Patterns_of_OpenAI's_o1_Model.md)

- [Active-Dormant Attention Heads: Mechanistically Demystifying Extreme-Token Phenomena in LLMs](2024年10月17日/Active-Dormant_Attention_Heads_Mechanistically_Demystifying_Extreme-Token_Phenomena_in_LLMs.md)

    - [翻译: 活跃与休眠的注意力头：揭秘 LLM 中的极端标记现象](2024年10月17日/Active-Dormant_Attention_Heads_Mechanistically_Demystifying_Extreme-Token_Phenomena_in_LLMs.md)

- [Advancing Large Language Model Attribution through Self-Improving](2024年10月17日/Advancing_Large_Language_Model_Attribution_through_Self-Improving.md)

    - [翻译: 通过自我提升，推动大型语言模型的归因技术进步。](2024年10月17日/Advancing_Large_Language_Model_Attribution_through_Self-Improving.md)

- [Aegis:An Advanced LLM-Based Multi-Agent for Intelligent Functional Safety Engineering](2024年10月17日/AegisAn_Advanced_LLM-Based_Multi-Agent_for_Intelligent_Functional_Safety_Engineering.md)

    - [翻译: Aegis：基于先进 LLM 的多智能体系统，专为智能功能安全工程设计](2024年10月17日/AegisAn_Advanced_LLM-Based_Multi-Agent_for_Intelligent_Functional_Safety_Engineering.md)

- [AgentOccam: A Simple Yet Strong Baseline for LLM-Based Web Agents](2024年10月17日/AgentOccam_A_Simple_Yet_Strong_Baseline_for_LLM-Based_Web_Agents.md)

    - [翻译: AgentOccam：一款简洁却不失强大的 LLM 基础 Web 代理基线](2024年10月17日/AgentOccam_A_Simple_Yet_Strong_Baseline_for_LLM-Based_Web_Agents.md)

- [Aggregation Artifacts in Subjective Tasks Collapse Large Language Models' Posteriors](2024年10月17日/Aggregation_Artifacts_in_Subjective_Tasks_Collapse_Large_Language_Models'_Posteriors.md)

    - [翻译: 主观任务中的聚合伪影使大型语言模型的后验概率崩溃](2024年10月17日/Aggregation_Artifacts_in_Subjective_Tasks_Collapse_Large_Language_Models'_Posteriors.md)

- [An Active Learning Framework for Inclusive Generation by Large Language Models](2024年10月17日/An_Active_Learning_Framework_for_Inclusive_Generation_by_Large_Language_Models.md)

    - [翻译: 大型语言模型包容性生成的主动学习框架](2024年10月17日/An_Active_Learning_Framework_for_Inclusive_Generation_by_Large_Language_Models.md)

- [Anchored Alignment for Self-Explanations Enhancement](2024年10月17日/Anchored_Alignment_for_Self-Explanations_Enhancement.md)

    - [翻译: 锚定对齐：自我解释的增强之道](2024年10月17日/Anchored_Alignment_for_Self-Explanations_Enhancement.md)

- [A Proposal for Uncovering Hidden Social Bots via Genetic Similarity](2024年10月17日/A_Proposal_for_Uncovering_Hidden_Social_Bots_via_Genetic_Similarity.md)

    - [翻译: 揭秘隐藏社交机器人的遗传相似性方案](2024年10月17日/A_Proposal_for_Uncovering_Hidden_Social_Bots_via_Genetic_Similarity.md)

- [AsymKV: Enabling 1-Bit Quantization of KV Cache with Layer-Wise Asymmetric Quantization Configurations](2024年10月17日/AsymKV_Enabling_1-Bit_Quantization_of_KV_Cache_with_Layer-Wise_Asymmetric_Quantization_Configurations.md)

    - [翻译: AsymKV：利用层级不对称量化配置，实现 KV Cache 的 1-Bit 量化。](2024年10月17日/AsymKV_Enabling_1-Bit_Quantization_of_KV_Cache_with_Layer-Wise_Asymmetric_Quantization_Configurations.md)

- [A Systematic Investigation of Knowledge Retrieval and Selection for Retrieval Augmented Generation](2024年10月17日/A_Systematic_Investigation_of_Knowledge_Retrieval_and_Selection_for_Retrieval_Augmented_Generation.md)

    - [翻译: 系统性探究知识检索与选择，助力增强生成技术](2024年10月17日/A_Systematic_Investigation_of_Knowledge_Retrieval_and_Selection_for_Retrieval_Augmented_Generation.md)

- [Atomic Calibration of LLMs in Long-Form Generations](2024年10月17日/Atomic_Calibration_of_LLMs_in_Long-Form_Generations.md)

    - [翻译: 长篇生成中 LLM 的原子校准](2024年10月17日/Atomic_Calibration_of_LLMs_in_Long-Form_Generations.md)

- [A Unified View of Delta Parameter Editing in Post-Trained Large-Scale Models](2024年10月17日/A_Unified_View_of_Delta_Parameter_Editing_in_Post-Trained_Large-Scale_Models.md)

    - [翻译: 大规模模型训练后 Delta 参数编辑的统一视角](2024年10月17日/A_Unified_View_of_Delta_Parameter_Editing_in_Post-Trained_Large-Scale_Models.md)

- [Automating IETF Insights generation with AI](2024年10月17日/Automating_IETF_Insights_generation_with_AI.md)

    - [翻译: AI 助力 IETF 洞察自动化生成](2024年10月17日/Automating_IETF_Insights_generation_with_AI.md)

- [BenTo: Benchmark Task Reduction with In-Context Transferability](2024年10月17日/BenTo_Benchmark_Task_Reduction_with_In-Context_Transferability.md)

    - [翻译: BenTo：利用上下文可迁移性进行基准任务的简化](2024年10月17日/BenTo_Benchmark_Task_Reduction_with_In-Context_Transferability.md)

- [Bias in the Mirror : Are LLMs opinions robust to their own adversarial attacks ?](2024年10月17日/Bias_in_the_Mirror__Are_LLMs_opinions_robust_to_their_own_adversarial_attacks_.md)

    - [翻译: 镜中偏见：LLM 的观点能否经受住自身的对抗性攻击？](2024年10月17日/Bias_in_the_Mirror__Are_LLMs_opinions_robust_to_their_own_adversarial_attacks_.md)

- [BQA: Body Language Question Answering Dataset for Video Large Language Models](2024年10月17日/BQA_Body_Language_Question_Answering_Dataset_for_Video_Large_Language_Models.md)

    - [翻译: BQA：专为视频大型语言模型设计的身体语言问答数据集](2024年10月17日/BQA_Body_Language_Question_Answering_Dataset_for_Video_Large_Language_Models.md)

- [Breaking Chains: Unraveling the Links in Multi-Hop Knowledge Unlearning](2024年10月17日/Breaking_Chains_Unraveling_the_Links_in_Multi-Hop_Knowledge_Unlearning.md)

    - [翻译: 破链而出：揭秘多跳知识遗忘中的关联](2024年10月17日/Breaking_Chains_Unraveling_the_Links_in_Multi-Hop_Knowledge_Unlearning.md)

- [Can Medical Vision-Language Pre-training Succeed with Purely Synthetic Data?](2024年10月17日/Can_Medical_Vision-Language_Pre-training_Succeed_with_Purely_Synthetic_Data.md)

    - [翻译: 医学视觉-语言预训练，能否仅凭纯合成数据大获成功？](2024年10月17日/Can_Medical_Vision-Language_Pre-training_Succeed_with_Purely_Synthetic_Data.md)

- [Can MLLMs Understand the Deep Implication Behind Chinese Images?](2024年10月17日/Can_MLLMs_Understand_the_Deep_Implication_Behind_Chinese_Images.md)

    - [翻译: MLLMs 能洞悉中文图像的深层含义吗？](2024年10月17日/Can_MLLMs_Understand_the_Deep_Implication_Behind_Chinese_Images.md)

- [CBT-Bench: Evaluating Large Language Models on Assisting Cognitive Behavior Therapy](2024年10月17日/CBT-Bench_Evaluating_Large_Language_Models_on_Assisting_Cognitive_Behavior_Therapy.md)

    - [翻译: CBT-Bench：衡量大型语言模型在辅助认知行为疗法中的效能](2024年10月17日/CBT-Bench_Evaluating_Large_Language_Models_on_Assisting_Cognitive_Behavior_Therapy.md)

- [Cerberus: Efficient Inference with Adaptive Parallel Decoding and Sequential Knowledge Enhancement](2024年10月17日/Cerberus_Efficient_Inference_with_Adaptive_Parallel_Decoding_and_Sequential_Knowledge_Enhancement.md)

    - [翻译: Cerberus：高效推理，结合自适应并行解码与顺序知识增强](2024年10月17日/Cerberus_Efficient_Inference_with_Adaptive_Parallel_Decoding_and_Sequential_Knowledge_Enhancement.md)

- [ChannelGPT: A Large Model to Generate Digital Twin Channel for 6G Environment Intelligence](2024年10月17日/ChannelGPT_A_Large_Model_to_Generate_Digital_Twin_Channel_for_6G_Environment_Intelligence.md)

    - [翻译: ChannelGPT：一款专为 6G 环境智能打造的大型模型，用于生成数字孪生通道。](2024年10月17日/ChannelGPT_A_Large_Model_to_Generate_Digital_Twin_Channel_for_6G_Environment_Intelligence.md)

- [CLaMP 2: Multimodal Music Information Retrieval Across 101 Languages Using Large Language Models](2024年10月17日/CLaMP_2_Multimodal_Music_Information_Retrieval_Across_101_Languages_Using_Large_Language_Models.md)

    - [翻译: CLaMP 2：借助大型语言模型，跨越 101 种语言的多模态音乐信息检索](2024年10月17日/CLaMP_2_Multimodal_Music_Information_Retrieval_Across_101_Languages_Using_Large_Language_Models.md)

- [CLEAR: Towards Contextual LLM-Empowered Privacy Policy Analysis and Risk Generation for Large Language Model Applications](2024年10月17日/CLEAR_Towards_Contextual_LLM-Empowered_Privacy_Policy_Analysis_and_Risk_Generation_for_Large_Language_Model_Applications.md)

    - [翻译: CLEAR：借助上下文 LLM 赋能，助力隐私政策分析与大型语言模型应用的风险生成](2024年10月17日/CLEAR_Towards_Contextual_LLM-Empowered_Privacy_Policy_Analysis_and_Risk_Generation_for_Large_Language_Model_Applications.md)

- [ClickAgent: Enhancing UI Location Capabilities of Autonomous Agents](2024年10月17日/ClickAgent_Enhancing_UI_Location_Capabilities_of_Autonomous_Agents.md)

    - [翻译: 提升自主代理的UI定位功能](2024年10月17日/ClickAgent_Enhancing_UI_Location_Capabilities_of_Autonomous_Agents.md)

- [Comparing the Utility, Preference, and Performance of Course Material Search Functionality and Retrieval-Augmented Generation Large Language Model (RAG-LLM) AI Chatbots in Information-Seeking Tasks](2024年10月17日/Comparing_the_Utility,_Preference,_and_Performance_of_Course_Material_Search_Functionality_and_Retrieval-Augmented_Generation_Large_Language_Model_(RAG-LLM)_AI_Chatbots_in_Information-Seeking_Tasks.md)

    - [翻译: 在信息搜索任务中，课程材料搜索功能与 RAG-LLM AI 聊天机器人的效用、偏好和性能比较](2024年10月17日/Comparing_the_Utility,_Preference,_and_Performance_of_Course_Material_Search_Functionality_and_Retrieval-Augmented_Generation_Large_Language_Model_(RAG-LLM)_AI_Chatbots_in_Information-Seeking_Tasks.md)

- [Deep Generative Models Unveil Patterns in Medical Images Through Vision-Language Conditioning](2024年10月17日/Deep_Generative_Models_Unveil_Patterns_in_Medical_Images_Through_Vision-Language_Conditioning.md)

    - [翻译: 深度生成模型借助视觉与语言的结合，揭开了医学图像中的奥秘。](2024年10月17日/Deep_Generative_Models_Unveil_Patterns_in_Medical_Images_Through_Vision-Language_Conditioning.md)

- [De-mark: Watermark Removal in Large Language Models](2024年10月17日/De-mark_Watermark_Removal_in_Large_Language_Models.md)

    - [翻译: De-mark：大型语言模型中的水印清除术](2024年10月17日/De-mark_Watermark_Removal_in_Large_Language_Models.md)

- [Do LLMs Have Political Correctness? Analyzing Ethical Biases and Jailbreak Vulnerabilities in AI Systems](2024年10月17日/Do_LLMs_Have_Political_Correctness_Analyzing_Ethical_Biases_and_Jailbreak_Vulnerabilities_in_AI_Systems.md)

    - [翻译: LLM 是否能做到政治正确？探讨 AI 系统中的伦理偏见与越狱风险](2024年10月17日/Do_LLMs_Have_Political_Correctness_Analyzing_Ethical_Biases_and_Jailbreak_Vulnerabilities_in_AI_Systems.md)

- [Do LLMs Overcome Shortcut Learning? An Evaluation of Shortcut Challenges in Large Language Models](2024年10月17日/Do_LLMs_Overcome_Shortcut_Learning_An_Evaluation_of_Shortcut_Challenges_in_Large_Language_Models.md)

    - [翻译: 大型语言模型是否解决了捷径学习问题？本文评估了这些模型在应对捷径挑战方面的表现。](2024年10月17日/Do_LLMs_Overcome_Shortcut_Learning_An_Evaluation_of_Shortcut_Challenges_in_Large_Language_Models.md)

- [DPLM-2: A Multimodal Diffusion Protein Language Model](2024年10月17日/DPLM-2_A_Multimodal_Diffusion_Protein_Language_Model.md)

    - [翻译: DPLM-2：一款多模态扩散蛋白语言模型](2024年10月17日/DPLM-2_A_Multimodal_Diffusion_Protein_Language_Model.md)

- [Enhancing LLM Trading Performance with Fact-Subjectivity Aware Reasoning](2024年10月17日/Enhancing_LLM_Trading_Performance_with_Fact-Subjectivity_Aware_Reasoning.md)

    - [翻译: 利用事实与主观性意识推理，提升 LLM 在交易中的表现](2024年10月17日/Enhancing_LLM_Trading_Performance_with_Fact-Subjectivity_Aware_Reasoning.md)

- [Enhancing Sentiment Analysis with Collaborative AI: Architecture, Predictions, and Deployment Strategies](2024年10月17日/Enhancing_Sentiment_Analysis_with_Collaborative_AI_Architecture,_Predictions,_and_Deployment_Strategies.md)

    - [翻译: 协作AI助力情感分析：架构设计、预测模型与部署策略](2024年10月17日/Enhancing_Sentiment_Analysis_with_Collaborative_AI_Architecture,_Predictions,_and_Deployment_Strategies.md)

- [Exploring the Design Space of Visual Context Representation in Video MLLMs](2024年10月17日/Exploring_the_Design_Space_of_Visual_Context_Representation_in_Video_MLLMs.md)

    - [翻译: 探索视频MLLMs中视觉上下文表示的设计空间](2024年10月17日/Exploring_the_Design_Space_of_Visual_Context_Representation_in_Video_MLLMs.md)

- [Failing Forward: Improving Generative Error Correction for ASR with Synthetic Data and Retrieval Augmentation](2024年10月17日/Failing_Forward_Improving_Generative_Error_Correction_for_ASR_with_Synthetic_Data_and_Retrieval_Augmentation.md)

    - [翻译: 向前失败：利用合成数据和检索增强技术提升 ASR 的生成错误校正能力](2024年10月17日/Failing_Forward_Improving_Generative_Error_Correction_for_ASR_with_Synthetic_Data_and_Retrieval_Augmentation.md)

- [FaithBench: A Diverse Hallucination Benchmark for Summarization by Modern LLMs](2024年10月17日/FaithBench_A_Diverse_Hallucination_Benchmark_for_Summarization_by_Modern_LLMs.md)

    - [翻译: FaithBench：一个专为现代 LLM 设计的多样化幻觉基准，用于评估其摘要能力。](2024年10月17日/FaithBench_A_Diverse_Hallucination_Benchmark_for_Summarization_by_Modern_LLMs.md)

- [Fine-Tuning Language Models on Multiple Datasets for Citation Intention Classification](2024年10月17日/Fine-Tuning_Language_Models_on_Multiple_Datasets_for_Citation_Intention_Classification.md)

    - [翻译: 微调语言模型于多数据集，精准分类引用意图](2024年10月17日/Fine-Tuning_Language_Models_on_Multiple_Datasets_for_Citation_Intention_Classification.md)

- [Fluid: Scaling Autoregressive Text-to-image Generative Models with Continuous Tokens](2024年10月17日/Fluid_Scaling_Autoregressive_Text-to-image_Generative_Models_with_Continuous_Tokens.md)

    - [翻译: Fluid：通过连续标记扩展自回归文本到图像生成模型的规模](2024年10月17日/Fluid_Scaling_Autoregressive_Text-to-image_Generative_Models_with_Continuous_Tokens.md)

- [FRAG: Toward Federated Vector Database Management for Collaborative and Secure Retrieval-Augmented Generation](2024年10月17日/FRAG_Toward_Federated_Vector_Database_Management_for_Collaborative_and_Secure_Retrieval-Augmented_Generation.md)

    - [翻译: FRAG：协作与安全检索增强生成的联邦向量数据库管理](2024年10月17日/FRAG_Toward_Federated_Vector_Database_Management_for_Collaborative_and_Secure_Retrieval-Augmented_Generation.md)

- [GDeR: Safeguarding Efficiency, Balancing, and Robustness via Prototypical Graph Pruning](2024年10月17日/GDeR_Safeguarding_Efficiency,_Balancing,_and_Robustness_via_Prototypical_Graph_Pruning.md)

    - [翻译: GDeR：通过原型图剪枝技术，实现效率、平衡性和鲁棒性的全面保障。](2024年10月17日/GDeR_Safeguarding_Efficiency,_Balancing,_and_Robustness_via_Prototypical_Graph_Pruning.md)

- [GeoCoder: Solving Geometry Problems by Generating Modular Code through Vision-Language Models](2024年10月17日/GeoCoder_Solving_Geometry_Problems_by_Generating_Modular_Code_through_Vision-Language_Models.md)

    - [翻译: GeoCoder：借助视觉-语言模型生成模块化代码，轻松解决几何难题](2024年10月17日/GeoCoder_Solving_Geometry_Problems_by_Generating_Modular_Code_through_Vision-Language_Models.md)

- [Harnessing Webpage UIs for Text-Rich Visual Understanding](2024年10月17日/Harnessing_Webpage_UIs_for_Text-Rich_Visual_Understanding.md)

    - [翻译: 借助网页UI，深入探索文本与视觉的丰富结合](2024年10月17日/Harnessing_Webpage_UIs_for_Text-Rich_Visual_Understanding.md)

- [HEALTH-PARIKSHA: Assessing RAG Models for Health Chatbots in Real-World Multilingual Settings](2024年10月17日/HEALTH-PARIKSHA_Assessing_RAG_Models_for_Health_Chatbots_in_Real-World_Multilingual_Settings.md)

    - [翻译: HEALTH-PARIKSHA：评估健康聊天机器人在多语言真实环境中的RAG模型表现](2024年10月17日/HEALTH-PARIKSHA_Assessing_RAG_Models_for_Health_Chatbots_in_Real-World_Multilingual_Settings.md)

- [Help Me Identify: Is an LLM+VQA System All We Need to Identify Visual Concepts?](2024年10月17日/Help_Me_Identify_Is_an_LLM+VQA_System_All_We_Need_to_Identify_Visual_Concepts.md)

    - [翻译: 我们真的需要一个 LLM+VQA 系统来识别视觉概念吗？](2024年10月17日/Help_Me_Identify_Is_an_LLM+VQA_System_All_We_Need_to_Identify_Visual_Concepts.md)

- [How Numerical Precision Affects Mathematical Reasoning Capabilities of LLMs](2024年10月17日/How_Numerical_Precision_Affects_Mathematical_Reasoning_Capabilities_of_LLMs.md)

    - [翻译: 数值精度对 LLMs 数学推理能力的影响](2024年10月17日/How_Numerical_Precision_Affects_Mathematical_Reasoning_Capabilities_of_LLMs.md)

- [Improving Multi-modal Large Language Model through Boosting Vision Capabilities](2024年10月17日/Improving_Multi-modal_Large_Language_Model_through_Boosting_Vision_Capabilities.md)

    - [翻译: 通过增强视觉能力，我们致力于提升多模态大型语言模型的性能。](2024年10月17日/Improving_Multi-modal_Large_Language_Model_through_Boosting_Vision_Capabilities.md)

- [Instruction-Driven Game Engine: A Poker Case Study](2024年10月17日/Instruction-Driven_Game_Engine_A_Poker_Case_Study.md)

    - [翻译: 指令驱动游戏引擎：扑克实战解析](2024年10月17日/Instruction-Driven_Game_Engine_A_Poker_Case_Study.md)

- [Integrating Large Language Models and Reinforcement Learning for Non-Linear Reasoning](2024年10月17日/Integrating_Large_Language_Models_and_Reinforcement_Learning_for_Non-Linear_Reasoning.md)

    - [翻译: 融合大型语言模型与强化学习，探索非线性推理的新路径](2024年10月17日/Integrating_Large_Language_Models_and_Reinforcement_Learning_for_Non-Linear_Reasoning.md)

- [Integrating Temporal Representations for Dynamic Memory Retrieval and Management in Large Language Models](2024年10月17日/Integrating_Temporal_Representations_for_Dynamic_Memory_Retrieval_and_Management_in_Large_Language_Models.md)

    - [翻译: 在大规模语言模型中，整合时间表示，实现动态记忆的检索与管理。](2024年10月17日/Integrating_Temporal_Representations_for_Dynamic_Memory_Retrieval_and_Management_in_Large_Language_Models.md)

- [Jailbreaking LLM-Controlled Robots](2024年10月17日/Jailbreaking_LLM-Controlled_Robots.md)

    - [翻译: 解锁大型语言模型操控的机器人](2024年10月17日/Jailbreaking_LLM-Controlled_Robots.md)

- [Knowledge-Aware Query Expansion with Large Language Models for Textual and Relational Retrieval](2024年10月17日/Knowledge-Aware_Query_Expansion_with_Large_Language_Models_for_Textual_and_Relational_Retrieval.md)

    - [翻译: 利用大型语言模型进行知识感知的查询扩展，应用于文本与关系检索](2024年10月17日/Knowledge-Aware_Query_Expansion_with_Large_Language_Models_for_Textual_and_Relational_Retrieval.md)

- [LAR-ECHR: A New Legal Argument Reasoning Task and Dataset for Cases of the European Court of Human Rights](2024年10月17日/LAR-ECHR_A_New_Legal_Argument_Reasoning_Task_and_Dataset_for_Cases_of_the_European_Court_of_Human_Rights.md)

    - [翻译: LAR-ECHR：欧洲人权法院案件的新法律论证推理任务与数据集](2024年10月17日/LAR-ECHR_A_New_Legal_Argument_Reasoning_Task_and_Dataset_for_Cases_of_the_European_Court_of_Human_Rights.md)

- [Large Language Models are Easily Confused: A Quantitative Metric, Security Implications and Typological Analysis](2024年10月17日/Large_Language_Models_are_Easily_Confused_A_Quantitative_Metric,_Security_Implications_and_Typological_Analysis.md)

    - [翻译: 大型语言模型易受迷惑：定量指标揭示其安全隐忧与类型学解析](2024年10月17日/Large_Language_Models_are_Easily_Confused_A_Quantitative_Metric,_Security_Implications_and_Typological_Analysis.md)

- [Large Language Models as Narrative-Driven Recommenders](2024年10月17日/Large_Language_Models_as_Narrative-Driven_Recommenders.md)

    - [翻译: 大型语言模型：叙事驱动的推荐引擎](2024年10月17日/Large_Language_Models_as_Narrative-Driven_Recommenders.md)

- [Learning to Route with Confidence Tokens](2024年10月17日/Learning_to_Route_with_Confidence_Tokens.md)

    - [翻译: 自信标记路由学习](2024年10月17日/Learning_to_Route_with_Confidence_Tokens.md)

- [LLM-based Unit Test Generation via Property Retrieval](2024年10月17日/LLM-based_Unit_Test_Generation_via_Property_Retrieval.md)

    - [翻译: 基于 LLM 的单元测试生成：属性检索法](2024年10月17日/LLM-based_Unit_Test_Generation_via_Property_Retrieval.md)

- [LLMOPT: Learning to Define and Solve General Optimization Problems from Scratch](2024年10月17日/LLMOPT_Learning_to_Define_and_Solve_General_Optimization_Problems_from_Scratch.md)

    - [翻译: LLMOPT：从零开始，学会定义并解决通用优化问题](2024年10月17日/LLMOPT_Learning_to_Define_and_Solve_General_Optimization_Problems_from_Scratch.md)

- [LLM-Rank: A Graph Theoretical Approach to Pruning Large Language Models](2024年10月17日/LLM-Rank_A_Graph_Theoretical_Approach_to_Pruning_Large_Language_Models.md)

    - [翻译: LLM-Rank：利用图论技术优化大语言模型剪枝的新思路](2024年10月17日/LLM-Rank_A_Graph_Theoretical_Approach_to_Pruning_Large_Language_Models.md)

- [LoLDU: Low-Rank Adaptation via Lower-Diag-Upper Decomposition for Parameter-Efficient Fine-Tuning](2024年10月17日/LoLDU_Low-Rank_Adaptation_via_Lower-Diag-Upper_Decomposition_for_Parameter-Efficient_Fine-Tuning.md)

    - [翻译: LoLDU：利用下-对角-上分解技术，实现低秩适应，从而进行参数高效的微调。](2024年10月17日/LoLDU_Low-Rank_Adaptation_via_Lower-Diag-Upper_Decomposition_for_Parameter-Efficient_Fine-Tuning.md)

- [Malleus: Straggler-Resilient Hybrid Parallel Training of Large-scale Models via Malleable Data and Model Parallelization](2024年10月17日/Malleus_Straggler-Resilient_Hybrid_Parallel_Training_of_Large-scale_Models_via_Malleable_Data_and_Model_Parallelization.md)

    - [翻译: Malleus：通过灵活的数据和模型并行化，实现大规模模型的抗滞后混合并行训练](2024年10月17日/Malleus_Straggler-Resilient_Hybrid_Parallel_Training_of_Large-scale_Models_via_Malleable_Data_and_Model_Parallelization.md)

- [MathGAP: Out-of-Distribution Evaluation on Problems with Arbitrarily Complex Proofs](2024年10月17日/MathGAP_Out-of-Distribution_Evaluation_on_Problems_with_Arbitrarily_Complex_Proofs.md)

    - [翻译: MathGAP：针对任意复杂证明问题的分布外评估](2024年10月17日/MathGAP_Out-of-Distribution_Evaluation_on_Problems_with_Arbitrarily_Complex_Proofs.md)

- [MedAide: Towards an Omni Medical Aide via Specialized LLM-based Multi-Agent Collaboration](2024年10月17日/MedAide_Towards_an_Omni_Medical_Aide_via_Specialized_LLM-based_Multi-Agent_Collaboration.md)

    - [翻译: MedAide：借助基于 LLM 的专门化多代理协作，迈向全方位医疗助手](2024年10月17日/MedAide_Towards_an_Omni_Medical_Aide_via_Specialized_LLM-based_Multi-Agent_Collaboration.md)

- [MeloTrans: A Text to Symbolic Music Generation Model Following Human Composition Habit](2024年10月17日/MeloTrans_A_Text_to_Symbolic_Music_Generation_Model_Following_Human_Composition_Habit.md)

    - [翻译: MeloTrans：一款模仿人类作曲习惯的文本转符号音乐生成模型](2024年10月17日/MeloTrans_A_Text_to_Symbolic_Music_Generation_Model_Following_Human_Composition_Habit.md)

- [Membership Testing for Semantic Regular Expressions](2024年10月17日/Membership_Testing_for_Semantic_Regular_Expressions.md)

    - [翻译: 语义正则表达式的成员资格检测](2024年10月17日/Membership_Testing_for_Semantic_Regular_Expressions.md)

- [MeNTi: Bridging Medical Calculator and LLM Agent with Nested Tool Calling](2024年10月17日/MeNTi_Bridging_Medical_Calculator_and_LLM_Agent_with_Nested_Tool_Calling.md)

    - [翻译: MeNTi：连接医疗计算器与 LLM 代理，通过嵌套工具调用实现无缝协作。](2024年10月17日/MeNTi_Bridging_Medical_Calculator_and_LLM_Agent_with_Nested_Tool_Calling.md)

- [Metacognitive Monitoring: A Human Ability Beyond Generative Artificial Intelligence](2024年10月17日/Metacognitive_Monitoring_A_Human_Ability_Beyond_Generative_Artificial_Intelligence.md)

    - [翻译: 元认知监控：超越生成式AI的人类独特能力](2024年10月17日/Metacognitive_Monitoring_A_Human_Ability_Beyond_Generative_Artificial_Intelligence.md)

- [MIRAGE-Bench: Automatic Multilingual Benchmark Arena for Retrieval-Augmented Generation Systems](2024年10月17日/MIRAGE-Bench_Automatic_Multilingual_Benchmark_Arena_for_Retrieval-Augmented_Generation_Systems.md)

    - [翻译: MIRAGE-Bench：检索增强生成系统的自动多语言基准竞技场](2024年10月17日/MIRAGE-Bench_Automatic_Multilingual_Benchmark_Arena_for_Retrieval-Augmented_Generation_Systems.md)

- [Mitigating Hallucinations in Large Vision-Language Models via Summary-Guided Decoding](2024年10月17日/Mitigating_Hallucinations_in_Large_Vision-Language_Models_via_Summary-Guided_Decoding.md)

    - [翻译: 借助摘要引导解码技术，有效缓解大型视觉语言模型中的幻觉问题。](2024年10月17日/Mitigating_Hallucinations_in_Large_Vision-Language_Models_via_Summary-Guided_Decoding.md)

- [MobA: A Two-Level Agent System for Efficient Mobile Task Automation](2024年10月17日/MobA_A_Two-Level_Agent_System_for_Efficient_Mobile_Task_Automation.md)

    - [翻译: MobA：一款高效移动任务自动化的双层代理系统](2024年10月17日/MobA_A_Two-Level_Agent_System_for_Efficient_Mobile_Task_Automation.md)

- [Modeling Future Conversation Turns to Teach LLMs to Ask Clarifying Questions](2024年10月17日/Modeling_Future_Conversation_Turns_to_Teach_LLMs_to_Ask_Clarifying_Questions.md)

    - [翻译: 通过模拟未来对话轮次，教导大型语言模型如何提出澄清问题。](2024年10月17日/Modeling_Future_Conversation_Turns_to_Teach_LLMs_to_Ask_Clarifying_Questions.md)

- [MoD: Exploring Mixture-of-Depth Adaptation for Multimodal Large Language Models](2024年10月17日/MoD_Exploring_Mixture-of-Depth_Adaptation_for_Multimodal_Large_Language_Models.md)

    - [翻译: MoD：探索多模态大型语言模型的深度混合适应策略](2024年10月17日/MoD_Exploring_Mixture-of-Depth_Adaptation_for_Multimodal_Large_Language_Models.md)

- [On the Role of Attention Heads in Large Language Model Safety](2024年10月17日/On_the_Role_of_Attention_Heads_in_Large_Language_Model_Safety.md)

    - [翻译: 探讨大规模语言模型中注意力头在安全性方面的作用](2024年10月17日/On_the_Role_of_Attention_Heads_in_Large_Language_Model_Safety.md)

- [Optimal Quantization for Matrix Multiplication](2024年10月17日/Optimal_Quantization_for_Matrix_Multiplication.md)

    - [翻译: 矩阵乘法中的最优量化](2024年10月17日/Optimal_Quantization_for_Matrix_Multiplication.md)

- [ORCHID: A Chinese Debate Corpus for Target-Independent Stance Detection and Argumentative Dialogue Summarization](2024年10月17日/ORCHID_A_Chinese_Debate_Corpus_for_Target-Independent_Stance_Detection_and_Argumentative_Dialogue_Summarization.md)

    - [翻译: ORCHID：一款专为独立目标立场检测与论证对话摘要设计的中文辩论语料库](2024年10月17日/ORCHID_A_Chinese_Debate_Corpus_for_Target-Independent_Stance_Detection_and_Argumentative_Dialogue_Summarization.md)

- [Persistent Pre-Training Poisoning of LLMs](2024年10月17日/Persistent_Pre-Training_Poisoning_of_LLMs.md)

    - [翻译: LLM 面临持续的预训练中毒威胁](2024年10月17日/Persistent_Pre-Training_Poisoning_of_LLMs.md)

- [PopAlign: Diversifying Contrasting Patterns for a More Comprehensive Alignment](2024年10月17日/PopAlign_Diversifying_Contrasting_Patterns_for_a_More_Comprehensive_Alignment.md)

    - [翻译: PopAlign：通过多样化对比模式，实现更全面的对齐](2024年10月17日/PopAlign_Diversifying_Contrasting_Patterns_for_a_More_Comprehensive_Alignment.md)

- [Probing-RAG: Self-Probing to Guide Language Models in Selective Document Retrieval](2024年10月17日/Probing-RAG_Self-Probing_to_Guide_Language_Models_in_Selective_Document_Retrieval.md)

    - [翻译: Probing-RAG：通过自我探测引导语言模型进行精准文档检索](2024年10月17日/Probing-RAG_Self-Probing_to_Guide_Language_Models_in_Selective_Document_Retrieval.md)

- [Prompt Compression for Large Language Models: A Survey](2024年10月17日/Prompt_Compression_for_Large_Language_Models_A_Survey.md)

    - [翻译: 大型语言模型的提示压缩：全面调查](2024年10月17日/Prompt_Compression_for_Large_Language_Models_A_Survey.md)

- [Proof Flow: Preliminary Study on Generative Flow Network Language Model Tuning for Formal Reasoning](2024年10月17日/Proof_Flow_Preliminary_Study_on_Generative_Flow_Network_Language_Model_Tuning_for_Formal_Reasoning.md)

    - [翻译: 证明流：形式推理中生成流网络语言模型调优的初步探索](2024年10月17日/Proof_Flow_Preliminary_Study_on_Generative_Flow_Network_Language_Model_Tuning_for_Formal_Reasoning.md)

- [PUMA: Empowering Unified MLLM with Multi-granular Visual Generation](2024年10月17日/PUMA_Empowering_Unified_MLLM_with_Multi-granular_Visual_Generation.md)

    - [翻译: PUMA：为统一的多模态语言模型注入多粒度视觉生成力量](2024年10月17日/PUMA_Empowering_Unified_MLLM_with_Multi-granular_Visual_Generation.md)

- [Quamba: A Post-Training Quantization Recipe for Selective State Space Models](2024年10月17日/Quamba_A_Post-Training_Quantization_Recipe_for_Selective_State_Space_Models.md)

    - [翻译: Quamba：专为选择性状态空间模型设计的后训练量化方案](2024年10月17日/Quamba_A_Post-Training_Quantization_Recipe_for_Selective_State_Space_Models.md)

- [Quantity vs. Quality of Monolingual Source Data in Automatic Text Translation: Can It Be Too Little If It Is Too Good?](2024年10月17日/Quantity_vs._Quality_of_Monolingual_Source_Data_in_Automatic_Text_Translation_Can_It_Be_Too_Little_If_It_Is_Too_Good.md)

    - [翻译: 在自动文本翻译中，单语源数据的数量与质量孰重孰轻？质量虽高，数量不足是否仍能胜任？](2024年10月17日/Quantity_vs._Quality_of_Monolingual_Source_Data_in_Automatic_Text_Translation_Can_It_Be_Too_Little_If_It_Is_Too_Good.md)

- [RAG-DDR: Optimizing Retrieval-Augmented Generation Using Differentiable Data Rewards](2024年10月17日/RAG-DDR_Optimizing_Retrieval-Augmented_Generation_Using_Differentiable_Data_Rewards.md)

    - [翻译: RAG-DDR：通过可微数据奖励优化检索增强生成](2024年10月17日/RAG-DDR_Optimizing_Retrieval-Augmented_Generation_Using_Differentiable_Data_Rewards.md)

- [Reference-Based Post-OCR Processing with LLM for Diacritic Languages](2024年10月17日/Reference-Based_Post-OCR_Processing_with_LLM_for_Diacritic_Languages.md)

    - [翻译: 基于参考的 OCR 后处理与 LLM 应用于变音符号语言](2024年10月17日/Reference-Based_Post-OCR_Processing_with_LLM_for_Diacritic_Languages.md)

- [Remember, Retrieve and Generate: Understanding Infinite Visual Concepts as Your Personalized Assistant](2024年10月17日/Remember,_Retrieve_and_Generate_Understanding_Infinite_Visual_Concepts_as_Your_Personalized_Assistant.md)

    - [翻译: 记住、检索并生成：将无限视觉概念化为您的个性化助手](2024年10月17日/Remember,_Retrieve_and_Generate_Understanding_Infinite_Visual_Concepts_as_Your_Personalized_Assistant.md)

- [Representation Learning of Structured Data for Medical Foundation Models](2024年10月17日/Representation_Learning_of_Structured_Data_for_Medical_Foundation_Models.md)

    - [翻译: 医疗基础模型中的结构化数据表示学习](2024年10月17日/Representation_Learning_of_Structured_Data_for_Medical_Foundation_Models.md)

- [Representing Model Weights with Language using Tree Experts](2024年10月17日/Representing_Model_Weights_with_Language_using_Tree_Experts.md)

    - [翻译: 借助树专家，以语言形式呈现模型权重](2024年10月17日/Representing_Model_Weights_with_Language_using_Tree_Experts.md)

- [RescueADI: Adaptive Disaster Interpretation in Remote Sensing Images with Autonomous Agents](2024年10月17日/RescueADI_Adaptive_Disaster_Interpretation_in_Remote_Sensing_Images_with_Autonomous_Agents.md)

    - [翻译: RescueADI：利用自主代理在遥感图像中实现灾难的自适应解读](2024年10月17日/RescueADI_Adaptive_Disaster_Interpretation_in_Remote_Sensing_Images_with_Autonomous_Agents.md)

- [Retrospective Learning from Interactions](2024年10月17日/Retrospective_Learning_from_Interactions.md)

    - [翻译: 从过往互动中汲取经验](2024年10月17日/Retrospective_Learning_from_Interactions.md)

- [Roadmap towards Superhuman Speech Understanding using Large Language Models](2024年10月17日/Roadmap_towards_Superhuman_Speech_Understanding_using_Large_Language_Models.md)

    - [翻译: 迈向超人类语音理解：大型语言模型的路线图](2024年10月17日/Roadmap_towards_Superhuman_Speech_Understanding_using_Large_Language_Models.md)

- [SBI-RAG: Enhancing Math Word Problem Solving for Students through Schema-Based Instruction and Retrieval-Augmented Generation](2024年10月17日/SBI-RAG_Enhancing_Math_Word_Problem_Solving_for_Students_through_Schema-Based_Instruction_and_Retrieval-Augmented_Generation.md)

    - [翻译: SBI-RAG：借助模式化教学与检索增强生成，提升学生数学应用题解题能力](2024年10月17日/SBI-RAG_Enhancing_Math_Word_Problem_Solving_for_Students_through_Schema-Based_Instruction_and_Retrieval-Augmented_Generation.md)

- [Scaling Wearable Foundation Models](2024年10月17日/Scaling_Wearable_Foundation_Models.md)

    - [翻译: 扩展可穿戴基础模型](2024年10月17日/Scaling_Wearable_Foundation_Models.md)

- [SeerAttention: Learning Intrinsic Sparse Attention in Your LLMs](2024年10月17日/SeerAttention_Learning_Intrinsic_Sparse_Attention_in_Your_LLMs.md)

    - [翻译: SeerAttention：让 LLMs 学会内在的稀疏注意力](2024年10月17日/SeerAttention_Learning_Intrinsic_Sparse_Attention_in_Your_LLMs.md)

- [SimLayerKV: A Simple Framework for Layer-Level KV Cache Reduction](2024年10月17日/SimLayerKV_A_Simple_Framework_for_Layer-Level_KV_Cache_Reduction.md)

    - [翻译: SimLayerKV：简化层级 KV 缓存减少的简易框架](2024年10月17日/SimLayerKV_A_Simple_Framework_for_Layer-Level_KV_Cache_Reduction.md)

- [SimpleToM: Exposing the Gap between Explicit ToM Inference and Implicit ToM Application in LLMs](2024年10月17日/SimpleToM_Exposing_the_Gap_between_Explicit_ToM_Inference_and_Implicit_ToM_Application_in_LLMs.md)

    - [翻译: SimpleToM：揭示了 LLM 中显式 ToM 推理与隐式 ToM 应用之间的差异](2024年10月17日/SimpleToM_Exposing_the_Gap_between_Explicit_ToM_Inference_and_Implicit_ToM_Application_in_LLMs.md)

- [SPIN: Self-Supervised Prompt INjection](2024年10月17日/SPIN_Self-Supervised_Prompt_INjection.md)

    - [翻译: SPIN：自监督提示注入技术](2024年10月17日/SPIN_Self-Supervised_Prompt_INjection.md)

- [Starbucks: Improved Training for 2D Matryoshka Embeddings](2024年10月17日/Starbucks_Improved_Training_for_2D_Matryoshka_Embeddings.md)

    - [翻译: 星巴克：优化了2D套娃嵌入的训练方法](2024年10月17日/Starbucks_Improved_Training_for_2D_Matryoshka_Embeddings.md)

- [Text-Guided Multi-Property Molecular Optimization with a Diffusion Language Model](2024年10月17日/Text-Guided_Multi-Property_Molecular_Optimization_with_a_Diffusion_Language_Model.md)

    - [翻译: 借助扩散语言模型，实现文本引导的多属性分子优化](2024年10月17日/Text-Guided_Multi-Property_Molecular_Optimization_with_a_Diffusion_Language_Model.md)

- [Think Thrice Before You Act: Progressive Thought Refinement in Large Language Models](2024年10月17日/Think_Thrice_Before_You_Act_Progressive_Thought_Refinement_in_Large_Language_Models.md)

    - [翻译: 在行动之前，三思而后行：探讨大型语言模型中的思维逐步细化过程。](2024年10月17日/Think_Thrice_Before_You_Act_Progressive_Thought_Refinement_in_Large_Language_Models.md)

- [Towards Hybrid Intelligence in Journalism: Findings and Lessons Learnt from a Collaborative Analysis of Greek Political Rhetoric by ChatGPT and Humans](2024年10月17日/Towards_Hybrid_Intelligence_in_Journalism_Findings_and_Lessons_Learnt_from_a_Collaborative_Analysis_of_Greek_Political_Rhetoric_by_ChatGPT_and_Humans.md)

    - [翻译: 新闻学中的混合智能探索：ChatGPT 与人类协作分析希腊政治修辞的发现与启示](2024年10月17日/Towards_Hybrid_Intelligence_in_Journalism_Findings_and_Lessons_Learnt_from_a_Collaborative_Analysis_of_Greek_Political_Rhetoric_by_ChatGPT_and_Humans.md)

- [Unconstrained Model Merging for Enhanced LLM Reasoning](2024年10月17日/Unconstrained_Model_Merging_for_Enhanced_LLM_Reasoning.md)

    - [翻译: 无约束模型合并：提升 LLM 推理能力](2024年10月17日/Unconstrained_Model_Merging_for_Enhanced_LLM_Reasoning.md)

- [VL-GLUE: A Suite of Fundamental yet Challenging Visuo-Linguistic Reasoning Tasks](2024年10月17日/VL-GLUE_A_Suite_of_Fundamental_yet_Challenging_Visuo-Linguistic_Reasoning_Tasks.md)

    - [翻译: VL-GLUE：一套基础且具挑战性的视觉-语言推理任务集](2024年10月17日/VL-GLUE_A_Suite_of_Fundamental_yet_Challenging_Visuo-Linguistic_Reasoning_Tasks.md)

- [Web Agents with World Models: Learning and Leveraging Environment Dynamics in Web Navigation](2024年10月17日/Web_Agents_with_World_Models_Learning_and_Leveraging_Environment_Dynamics_in_Web_Navigation.md)

    - [翻译: 网络代理通过世界模型学习并利用环境动态，以优化网络导航。](2024年10月17日/Web_Agents_with_World_Models_Learning_and_Leveraging_Environment_Dynamics_in_Web_Navigation.md)

2024年10月16日

- [3D Gaussian Splatting in Robotics: A Survey](2024年10月16日/3D_Gaussian_Splatting_in_Robotics_A_Survey.md)

    - [翻译: 机器人领域的3D高斯喷射技术调查](2024年10月16日/3D_Gaussian_Splatting_in_Robotics_A_Survey.md)

- [AdaSwitch: Adaptive Switching between Small and Large Agents for Effective Cloud-Local Collaborative Learning](2024年10月16日/AdaSwitch_Adaptive_Switching_between_Small_and_Large_Agents_for_Effective_Cloud-Local_Collaborative_Learning.md)

    - [翻译: AdaSwitch：智能切换小代理与大代理，实现高效的云与本地协作学习](2024年10月16日/AdaSwitch_Adaptive_Switching_between_Small_and_Large_Agents_for_Effective_Cloud-Local_Collaborative_Learning.md)

- [aiXcoder-7B: A Lightweight and Effective Large Language Model for Code Completion](2024年10月16日/aiXcoder-7B_A_Lightweight_and_Effective_Large_Language_Model_for_Code_Completion.md)

    - [翻译: aiXcoder-7B：一款轻巧高效的代码补全大型语言模型](2024年10月16日/aiXcoder-7B_A_Lightweight_and_Effective_Large_Language_Model_for_Code_Completion.md)

- [Automatic Mapping of Anatomical Landmarks from Free-Text Using Large Language Models: Insights from Llama-2](2024年10月16日/Automatic_Mapping_of_Anatomical_Landmarks_from_Free-Text_Using_Large_Language_Models_Insights_from_Llama-2.md)

    - [翻译: 借助 Llama-2 大型语言模型，自动从自由文本中识别解剖学标志，探索其背后的奥秘。](2024年10月16日/Automatic_Mapping_of_Anatomical_Landmarks_from_Free-Text_Using_Large_Language_Models_Insights_from_Llama-2.md)

- [Benchmarking Defeasible Reasoning with Large Language Models -- Initial Experiments and Future Directions](2024年10月16日/Benchmarking_Defeasible_Reasoning_with_Large_Language_Models_--_Initial_Experiments_and_Future_Directions.md)

    - [翻译: 大型语言模型的可废止推理基准测试——初探与展望](2024年10月16日/Benchmarking_Defeasible_Reasoning_with_Large_Language_Models_--_Initial_Experiments_and_Future_Directions.md)

- [Bridging the Language Gaps in Large Language Models with Inference-Time Cross-Lingual Intervention](2024年10月16日/Bridging_the_Language_Gaps_in_Large_Language_Models_with_Inference-Time_Cross-Lingual_Intervention.md)

    - [翻译: 通过推理时的跨语言干预，弥合大型语言模型中的语言鸿沟](2024年10月16日/Bridging_the_Language_Gaps_in_Large_Language_Models_with_Inference-Time_Cross-Lingual_Intervention.md)

- [Can We Reverse In-Context Knowledge Edits?](2024年10月16日/Can_We_Reverse_In-Context_Knowledge_Edits.md)

    - [翻译: 上下文知识编辑能否被逆转？](2024年10月16日/Can_We_Reverse_In-Context_Knowledge_Edits.md)

- [CCSBench: Evaluating Compositional Controllability in LLMs for Scientific Document Summarization](2024年10月16日/CCSBench_Evaluating_Compositional_Controllability_in_LLMs_for_Scientific_Document_Summarization.md)

    - [翻译: CCSBench：科学文档摘要中 LLM 组合可控性的评估工具](2024年10月16日/CCSBench_Evaluating_Compositional_Controllability_in_LLMs_for_Scientific_Document_Summarization.md)

- [Chain of Ideas: Revolutionizing Research in Novel Idea Development with LLM Agents](2024年10月16日/Chain_of_Ideas_Revolutionizing_Research_in_Novel_Idea_Development_with_LLM_Agents.md)

    - [翻译: Chain of Ideas：借助 LLM Agents 革新创意研发](2024年10月16日/Chain_of_Ideas_Revolutionizing_Research_in_Novel_Idea_Development_with_LLM_Agents.md)

- [CoFE-RAG: A Comprehensive Full-chain Evaluation Framework for Retrieval-Augmented Generation with Enhanced Data Diversity](2024年10月16日/CoFE-RAG_A_Comprehensive_Full-chain_Evaluation_Framework_for_Retrieval-Augmented_Generation_with_Enhanced_Data_Diversity.md)

    - [翻译: CoFE-RAG：一个全面的全链路评估框架，专为提升数据多样性的检索增强生成而设计。](2024年10月16日/CoFE-RAG_A_Comprehensive_Full-chain_Evaluation_Framework_for_Retrieval-Augmented_Generation_with_Enhanced_Data_Diversity.md)

- [Conformity in Large Language Models](2024年10月16日/Conformity_in_Large_Language_Models.md)

    - [翻译: 大型语言模型中的从众现象](2024年10月16日/Conformity_in_Large_Language_Models.md)

- [CREAM: Consistency Regularized Self-Rewarding Language Models](2024年10月16日/CREAM_Consistency_Regularized_Self-Rewarding_Language_Models.md)

    - [翻译: CREAM：一致性正则化自我奖励语言模型](2024年10月16日/CREAM_Consistency_Regularized_Self-Rewarding_Language_Models.md)

- [Cross-Modal Safety Mechanism Transfer in Large Vision-Language Models](2024年10月16日/Cross-Modal_Safety_Mechanism_Transfer_in_Large_Vision-Language_Models.md)

    - [翻译: 大规模视觉语言模型中的跨模态安全机制转移](2024年10月16日/Cross-Modal_Safety_Mechanism_Transfer_in_Large_Vision-Language_Models.md)

- [DocLayout-YOLO: Enhancing Document Layout Analysis through Diverse Synthetic Data and Global-to-Local Adaptive Perception](2024年10月16日/DocLayout-YOLO_Enhancing_Document_Layout_Analysis_through_Diverse_Synthetic_Data_and_Global-to-Local_Adaptive_Perception.md)

    - [翻译: DocLayout-YOLO：利用多样化合成数据和全局到局部的自适应感知，提升文档布局分析能力](2024年10月16日/DocLayout-YOLO_Enhancing_Document_Layout_Analysis_through_Diverse_Synthetic_Data_and_Global-to-Local_Adaptive_Perception.md)

- [Efficient and Effective Universal Adversarial Attack against Vision-Language Pre-training Models](2024年10月16日/Efficient_and_Effective_Universal_Adversarial_Attack_against_Vision-Language_Pre-training_Models.md)

    - [翻译: 针对视觉-语言预训练模型，我们提出了一种既高效又有效的通用对抗攻击方法。](2024年10月16日/Efficient_and_Effective_Universal_Adversarial_Attack_against_Vision-Language_Pre-training_Models.md)

- [Efficient Diffusion Models: A Comprehensive Survey from Principles to Practices](2024年10月16日/Efficient_Diffusion_Models_A_Comprehensive_Survey_from_Principles_to_Practices.md)

    - [翻译: 高效扩散模型：从理论到应用的全面解析](2024年10月16日/Efficient_Diffusion_Models_A_Comprehensive_Survey_from_Principles_to_Practices.md)

- [Embedding an Ethical Mind: Aligning Text-to-Image Synthesis via Lightweight Value Optimization](2024年10月16日/Embedding_an_Ethical_Mind_Aligning_Text-to-Image_Synthesis_via_Lightweight_Value_Optimization.md)

    - [翻译: 以伦理为导向：通过轻量级优化实现文本到图像合成的价值对齐](2024年10月16日/Embedding_an_Ethical_Mind_Aligning_Text-to-Image_Synthesis_via_Lightweight_Value_Optimization.md)

- [Enhancing LLM Agents for Code Generation with Possibility and Pass-rate Prioritized Experience Replay](2024年10月16日/Enhancing_LLM_Agents_for_Code_Generation_with_Possibility_and_Pass-rate_Prioritized_Experience_Replay.md)

    - [翻译: 提升 LLM 代理代码生成：可能性与通过率优先的经验回放策略](2024年10月16日/Enhancing_LLM_Agents_for_Code_Generation_with_Possibility_and_Pass-rate_Prioritized_Experience_Replay.md)

- [ERVQ: Enhanced Residual Vector Quantization with Intra-and-Inter-Codebook Optimization for Neural Audio Codecs](2024年10月16日/ERVQ_Enhanced_Residual_Vector_Quantization_with_Intra-and-Inter-Codebook_Optimization_for_Neural_Audio_Codecs.md)

    - [翻译: ERVQ：通过代码本内外的优化，增强残差向量量化，应用于神经音频编解码器](2024年10月16日/ERVQ_Enhanced_Residual_Vector_Quantization_with_Intra-and-Inter-Codebook_Optimization_for_Neural_Audio_Codecs.md)

- [Evaluating Morphological Compositional Generalization in Large Language Models](2024年10月16日/Evaluating_Morphological_Compositional_Generalization_in_Large_Language_Models.md)

    - [翻译: 探究大型语言模型中的形态组合泛化能力](2024年10月16日/Evaluating_Morphological_Compositional_Generalization_in_Large_Language_Models.md)

- [Evaluating Self-Generated Documents for Enhancing Retrieval-Augmented Generation with Large Language Models](2024年10月16日/Evaluating_Self-Generated_Documents_for_Enhancing_Retrieval-Augmented_Generation_with_Large_Language_Models.md)

    - [翻译: 评估自生成文档，以提升大型语言模型在检索增强生成中的表现](2024年10月16日/Evaluating_Self-Generated_Documents_for_Enhancing_Retrieval-Augmented_Generation_with_Large_Language_Models.md)

- [Evaluating Software Development Agents: Patch Patterns, Code Quality, and Issue Complexity in Real-World GitHub Scenarios](2024年10月16日/Evaluating_Software_Development_Agents_Patch_Patterns,_Code_Quality,_and_Issue_Complexity_in_Real-World_GitHub_Scenarios.md)

    - [翻译: 评估软件开发代理：探究 GitHub 真实场景中的补丁模式、代码质量与问题复杂性](2024年10月16日/Evaluating_Software_Development_Agents_Patch_Patterns,_Code_Quality,_and_Issue_Complexity_in_Real-World_GitHub_Scenarios.md)

- [Evaluation of Attribution Bias in Retrieval-Augmented Large Language Models](2024年10月16日/Evaluation_of_Attribution_Bias_in_Retrieval-Augmented_Large_Language_Models.md)

    - [翻译: 探究检索增强型大型语言模型中的归因偏差](2024年10月16日/Evaluation_of_Attribution_Bias_in_Retrieval-Augmented_Large_Language_Models.md)

- [Expanding Chatbot Knowledge in Customer Service: Context-Aware Similar Question Generation Using Large Language Models](2024年10月16日/Expanding_Chatbot_Knowledge_in_Customer_Service_Context-Aware_Similar_Question_Generation_Using_Large_Language_Models.md)

    - [翻译: 在客户服务中提升聊天机器人知识：利用大型语言模型生成上下文感知的相似问题](2024年10月16日/Expanding_Chatbot_Knowledge_in_Customer_Service_Context-Aware_Similar_Question_Generation_Using_Large_Language_Models.md)

- [Explainable Moral Values: a neuro-symbolic approach to value classification](2024年10月16日/Explainable_Moral_Values_a_neuro-symbolic_approach_to_value_classification.md)

    - [翻译: 道德价值观的可解释性：神经符号方法在价值分类中的应用](2024年10月16日/Explainable_Moral_Values_a_neuro-symbolic_approach_to_value_classification.md)

- [Exploring Model Kinship for Merging Large Language Models](2024年10月16日/Exploring_Model_Kinship_for_Merging_Large_Language_Models.md)

    - [翻译: 探究合并大型语言模型的模型亲缘关系](2024年10月16日/Exploring_Model_Kinship_for_Merging_Large_Language_Models.md)

- [Facilitating Multi-turn Function Calling for LLMs via Compositional Instruction Tuning](2024年10月16日/Facilitating_Multi-turn_Function_Calling_for_LLMs_via_Compositional_Instruction_Tuning.md)

    - [翻译: 通过组合指令调优，助力 LLM 实现多轮功能调用](2024年10月16日/Facilitating_Multi-turn_Function_Calling_for_LLMs_via_Compositional_Instruction_Tuning.md)

- [FiRST: Finetuning Router-Selective Transformers for Input-Adaptive Latency Reduction](2024年10月16日/FiRST_Finetuning_Router-Selective_Transformers_for_Input-Adaptive_Latency_Reduction.md)

    - [翻译: FiRST：通过微调路由器选择性变压器，实现输入自适应的延迟降低](2024年10月16日/FiRST_Finetuning_Router-Selective_Transformers_for_Input-Adaptive_Latency_Reduction.md)

- [FTII-Bench: A Comprehensive Multimodal Benchmark for Flow Text with Image Insertion](2024年10月16日/FTII-Bench_A_Comprehensive_Multimodal_Benchmark_for_Flow_Text_with_Image_Insertion.md)

    - [翻译: FTII-Bench：一款全面的多模态基准，专为插入图像的流文本设计](2024年10月16日/FTII-Bench_A_Comprehensive_Multimodal_Benchmark_for_Flow_Text_with_Image_Insertion.md)

- [FusionLLM: A Decentralized LLM Training System on Geo-distributed GPUs with Adaptive Compression](2024年10月16日/FusionLLM_A_Decentralized_LLM_Training_System_on_Geo-distributed_GPUs_with_Adaptive_Compression.md)

    - [翻译: FusionLLM：一款基于地理分布 GPU 的自适应压缩分散式 LLM 训练系统](2024年10月16日/FusionLLM_A_Decentralized_LLM_Training_System_on_Geo-distributed_GPUs_with_Adaptive_Compression.md)

- [Graph-constrained Reasoning: Faithful Reasoning on Knowledge Graphs with Large Language Models](2024年10月16日/Graph-constrained_Reasoning_Faithful_Reasoning_on_Knowledge_Graphs_with_Large_Language_Models.md)

    - [翻译: 图约束推理：利用大型语言模型在知识图谱上实现可信推理](2024年10月16日/Graph-constrained_Reasoning_Faithful_Reasoning_on_Knowledge_Graphs_with_Large_Language_Models.md)

- [HerO at AVeriTeC: The Herd of Open Large Language Models for Verifying Real-World Claims](2024年10月16日/HerO_at_AVeriTeC_The_Herd_of_Open_Large_Language_Models_for_Verifying_Real-World_Claims.md)

    - [翻译: HerO 在 AVeriTeC：一群用于验证现实声明的开源大型语言模型](2024年10月16日/HerO_at_AVeriTeC_The_Herd_of_Open_Large_Language_Models_for_Verifying_Real-World_Claims.md)

- [Hiding-in-Plain-Sight (HiPS) Attack on CLIP for Targetted Object Removal from Images](2024年10月16日/Hiding-in-Plain-Sight_(HiPS)_Attack_on_CLIP_for_Targetted_Object_Removal_from_Images.md)

    - [翻译: HiPS 攻击利用 CLIP 的漏洞，巧妙地将目标物体从图像中“隐身”。](2024年10月16日/Hiding-in-Plain-Sight_(HiPS)_Attack_on_CLIP_for_Targetted_Object_Removal_from_Images.md)

- [HumanEval-V: Evaluating Visual Understanding and Reasoning Abilities of Large Multimodal Models Through Coding Tasks](2024年10月16日/HumanEval-V_Evaluating_Visual_Understanding_and_Reasoning_Abilities_of_Large_Multimodal_Models_Through_Coding_Tasks.md)

    - [翻译: HumanEval-V：通过编码任务，评估大型多模态模型在视觉理解和推理方面的表现。](2024年10月16日/HumanEval-V_Evaluating_Visual_Understanding_and_Reasoning_Abilities_of_Large_Multimodal_Models_Through_Coding_Tasks.md)

- [Identifying Task Groupings for Multi-Task Learning Using Pointwise V-Usable Information](2024年10月16日/Identifying_Task_Groupings_for_Multi-Task_Learning_Using_Pointwise_V-Usable_Information.md)

    - [翻译: 利用 Pointwise V-Usable Information 进行多任务学习中的任务分组识别](2024年10月16日/Identifying_Task_Groupings_for_Multi-Task_Learning_Using_Pointwise_V-Usable_Information.md)

- [In-Context Learning Enables Robot Action Prediction in LLMs](2024年10月16日/In-Context_Learning_Enables_Robot_Action_Prediction_in_LLMs.md)

    - [翻译: 上下文学习让 LLM 能够预测机器人动作](2024年10月16日/In-Context_Learning_Enables_Robot_Action_Prediction_in_LLMs.md)

- [Insights from the Inverse: Reconstructing LLM Training Goals Through Inverse RL](2024年10月16日/Insights_from_the_Inverse_Reconstructing_LLM_Training_Goals_Through_Inverse_RL.md)

    - [翻译: 逆向思考：用逆向强化学习重构 LLM 训练目标](2024年10月16日/Insights_from_the_Inverse_Reconstructing_LLM_Training_Goals_Through_Inverse_RL.md)

- [Is Semantic Chunking Worth the Computational Cost?](2024年10月16日/Is_Semantic_Chunking_Worth_the_Computational_Cost.md)

    - [翻译: 语义分块的计算成本是否物有所值？](2024年10月16日/Is_Semantic_Chunking_Worth_the_Computational_Cost.md)

- [KcMF: A Knowledge-compliant Framework for Schema and Entity Matching with Fine-tuning-free LLMs](2024年10月16日/KcMF_A_Knowledge-compliant_Framework_for_Schema_and_Entity_Matching_with_Fine-tuning-free_LLMs.md)

    - [翻译: KcMF：一个无需微调的大型语言模型框架，专为模式和实体匹配设计，确保知识合规性。](2024年10月16日/KcMF_A_Knowledge-compliant_Framework_for_Schema_and_Entity_Matching_with_Fine-tuning-free_LLMs.md)

- [Learning to Predict Usage Options of Product Reviews with LLM-Generated Labels](2024年10月16日/Learning_to_Predict_Usage_Options_of_Product_Reviews_with_LLM-Generated_Labels.md)

    - [翻译: 利用 LLM 生成的标签，学习预测产品评论的使用场景](2024年10月16日/Learning_to_Predict_Usage_Options_of_Product_Reviews_with_LLM-Generated_Labels.md)

- [LLM-based Translation Inference with Iterative Bilingual Understanding](2024年10月16日/LLM-based_Translation_Inference_with_Iterative_Bilingual_Understanding.md)

    - [翻译: 基于LLM的翻译推理：迭代双语理解](2024年10月16日/LLM-based_Translation_Inference_with_Iterative_Bilingual_Understanding.md)

- [MC-Bench: A Benchmark for Multi-Context Visual Grounding in the Era of MLLMs](2024年10月16日/MC-Bench_A_Benchmark_for_Multi-Context_Visual_Grounding_in_the_Era_of_MLLMs.md)

    - [翻译: MC-Bench：MLLM 时代下的多上下文视觉定位基准](2024年10月16日/MC-Bench_A_Benchmark_for_Multi-Context_Visual_Grounding_in_the_Era_of_MLLMs.md)

- [MCQG-SRefine: Multiple Choice Question Generation and Evaluation with Iterative Self-Critique, Correction, and Comparison Feedback](2024年10月16日/MCQG-SRefine_Multiple_Choice_Question_Generation_and_Evaluation_with_Iterative_Self-Critique,_Correction,_and_Comparison_Feedback.md)

    - [翻译: MCQG-SRefine：多选题生成与评估，结合迭代自我批评、修正与比较反馈](2024年10月16日/MCQG-SRefine_Multiple_Choice_Question_Generation_and_Evaluation_with_Iterative_Self-Critique,_Correction,_and_Comparison_Feedback.md)

- [Meta-Chunking: Learning Efficient Text Segmentation via Logical Perception](2024年10月16日/Meta-Chunking_Learning_Efficient_Text_Segmentation_via_Logical_Perception.md)

    - [翻译: 元块化：借助逻辑感知实现高效文本分割的学习方法](2024年10月16日/Meta-Chunking_Learning_Efficient_Text_Segmentation_via_Logical_Perception.md)

- [MlingConf: A Comprehensive Study of Multilingual Confidence Estimation on Large Language Models](2024年10月16日/MlingConf_A_Comprehensive_Study_of_Multilingual_Confidence_Estimation_on_Large_Language_Models.md)

    - [翻译: MlingConf：大型语言模型多语言置信度估计的全面探索](2024年10月16日/MlingConf_A_Comprehensive_Study_of_Multilingual_Confidence_Estimation_on_Large_Language_Models.md)

- [MMed-RAG: Versatile Multimodal RAG System for Medical Vision Language Models](2024年10月16日/MMed-RAG_Versatile_Multimodal_RAG_System_for_Medical_Vision_Language_Models.md)

    - [翻译: MMed-RAG：专为医疗视觉语言模型设计的多功能多模态系统](2024年10月16日/MMed-RAG_Versatile_Multimodal_RAG_System_for_Medical_Vision_Language_Models.md)

- [Neuron-based Personality Trait Induction in Large Language Models](2024年10月16日/Neuron-based_Personality_Trait_Induction_in_Large_Language_Models.md)

    - [翻译: 在大语言模型中，通过神经元诱导人格特质](2024年10月16日/Neuron-based_Personality_Trait_Induction_in_Large_Language_Models.md)

- [Not All Votes Count! Programs as Verifiers Improve Self-Consistency of Language Models for Math Reasoning](2024年10月16日/Not_All_Votes_Count!_Programs_as_Verifiers_Improve_Self-Consistency_of_Language_Models_for_Math_Reasoning.md)

    - [翻译: 并非所有投票都有效！通过程序验证，语言模型在数学推理中的自我一致性得以提升。](2024年10月16日/Not_All_Votes_Count!_Programs_as_Verifiers_Improve_Self-Consistency_of_Language_Models_for_Math_Reasoning.md)

- [On the Risk of Evidence Pollution for Malicious Social Text Detection in the Era of LLMs](2024年10月16日/On_the_Risk_of_Evidence_Pollution_for_Malicious_Social_Text_Detection_in_the_Era_of_LLMs.md)

    - [翻译: 在 LLM 时代，恶意社交文本检测面临证据污染的风险。](2024年10月16日/On_the_Risk_of_Evidence_Pollution_for_Malicious_Social_Text_Detection_in_the_Era_of_LLMs.md)

- [On the Utility of Domain Modeling Assistance with Large Language Models](2024年10月16日/On_the_Utility_of_Domain_Modeling_Assistance_with_Large_Language_Models.md)

    - [翻译: 探讨大型语言模型在领域建模中的辅助作用](2024年10月16日/On_the_Utility_of_Domain_Modeling_Assistance_with_Large_Language_Models.md)

- [Open Domain Question Answering with Conflicting Contexts](2024年10月16日/Open_Domain_Question_Answering_with_Conflicting_Contexts.md)

    - [翻译: 开放领域问答中的冲突上下文](2024年10月16日/Open_Domain_Question_Answering_with_Conflicting_Contexts.md)

- [Optimizing Low-Resource Language Model Training: Comprehensive Analysis of Multi-Epoch, Multi-Lingual, and Two-Stage Approaches](2024年10月16日/Optimizing_Low-Resource_Language_Model_Training_Comprehensive_Analysis_of_Multi-Epoch,_Multi-Lingual,_and_Two-Stage_Approaches.md)

    - [翻译: 优化低资源语言模型训练：深入探讨多时期、多语言及两阶段策略的综合分析](2024年10月16日/Optimizing_Low-Resource_Language_Model_Training_Comprehensive_Analysis_of_Multi-Epoch,_Multi-Lingual,_and_Two-Stage_Approaches.md)

- [PRefLexOR: Preference-based Recursive Language Modeling for Exploratory Optimization of Reasoning and Agentic Thinking](2024年10月16日/PRefLexOR_Preference-based_Recursive_Language_Modeling_for_Exploratory_Optimization_of_Reasoning_and_Agentic_Thinking.md)

    - [翻译: PRefLexOR：基于偏好的递归语言建模，旨在探索性优化推理与代理思维](2024年10月16日/PRefLexOR_Preference-based_Recursive_Language_Modeling_for_Exploratory_Optimization_of_Reasoning_and_Agentic_Thinking.md)

- [Proactive Agent: Shifting LLM Agents from Reactive Responses to Active Assistance](2024年10月16日/Proactive_Agent_Shifting_LLM_Agents_from_Reactive_Responses_to_Active_Assistance.md)

    - [翻译: 主动代理：让 LLM 代理从被动响应转变为主动协助](2024年10月16日/Proactive_Agent_Shifting_LLM_Agents_from_Reactive_Responses_to_Active_Assistance.md)

- [ProSA: Assessing and Understanding the Prompt Sensitivity of LLMs](2024年10月16日/ProSA_Assessing_and_Understanding_the_Prompt_Sensitivity_of_LLMs.md)

    - [翻译: ProSA：探索与评估 LLM 对提示的敏感性](2024年10月16日/ProSA_Assessing_and_Understanding_the_Prompt_Sensitivity_of_LLMs.md)

- [Pyramid-Driven Alignment: Pyramid Principle Guided Integration of Large Language Models and Knowledge Graphs](2024年10月16日/Pyramid-Driven_Alignment_Pyramid_Principle_Guided_Integration_of_Large_Language_Models_and_Knowledge_Graphs.md)

    - [翻译: 金字塔驱动对齐：以金字塔原则为指导，整合大型语言模型与知识图谱](2024年10月16日/Pyramid-Driven_Alignment_Pyramid_Principle_Guided_Integration_of_Large_Language_Models_and_Knowledge_Graphs.md)

- [Reconstruction of Differentially Private Text Sanitization via Large Language Models](2024年10月16日/Reconstruction_of_Differentially_Private_Text_Sanitization_via_Large_Language_Models.md)

    - [翻译: 利用大型语言模型重建差分隐私文本净化](2024年10月16日/Reconstruction_of_Differentially_Private_Text_Sanitization_via_Large_Language_Models.md)

- [REFINE on Scarce Data: Retrieval Enhancement through Fine-Tuning via Model Fusion of Embedding Models](2024年10月16日/REFINE_on_Scarce_Data_Retrieval_Enhancement_through_Fine-Tuning_via_Model_Fusion_of_Embedding_Models.md)

    - [翻译: 在数据稀缺的情况下，REFINE 通过嵌入模型的融合微调，实现了检索能力的增强。](2024年10月16日/REFINE_on_Scarce_Data_Retrieval_Enhancement_through_Fine-Tuning_via_Model_Fusion_of_Embedding_Models.md)

- [Retrieval-Reasoning Large Language Model-based Synthetic Clinical Trial Generation](2024年10月16日/Retrieval-Reasoning_Large_Language_Model-based_Synthetic_Clinical_Trial_Generation.md)

    - [翻译: 基于检索与推理的大型语言模型，用于合成临床试验的生成](2024年10月16日/Retrieval-Reasoning_Large_Language_Model-based_Synthetic_Clinical_Trial_Generation.md)

- [Revealing the Barriers of Language Agents in Planning](2024年10月16日/Revealing_the_Barriers_of_Language_Agents_in_Planning.md)

    - [翻译: 探究语言代理在规划过程中面临的挑战](2024年10月16日/Revealing_the_Barriers_of_Language_Agents_in_Planning.md)

- [Reversal of Thought: Enhancing Large Language Models with Preference-Guided Reverse Reasoning Warm-up](2024年10月16日/Reversal_of_Thought_Enhancing_Large_Language_Models_with_Preference-Guided_Reverse_Reasoning_Warm-up.md)

    - [翻译: 反转思维：借助偏好引导的反向推理预热，提升大型语言模型的性能](2024年10月16日/Reversal_of_Thought_Enhancing_Large_Language_Models_with_Preference-Guided_Reverse_Reasoning_Warm-up.md)

- [Revisited Large Language Model for Time Series Analysis through Modality Alignment](2024年10月16日/Revisited_Large_Language_Model_for_Time_Series_Analysis_through_Modality_Alignment.md)

    - [翻译: 通过模态对齐，重新探索大型语言模型在时间序列分析中的应用。](2024年10月16日/Revisited_Large_Language_Model_for_Time_Series_Analysis_through_Modality_Alignment.md)

- [Revisiting Benchmark and Assessment: An Agent-based Exploratory Dynamic Evaluation Framework for LLMs](2024年10月16日/Revisiting_Benchmark_and_Assessment_An_Agent-based_Exploratory_Dynamic_Evaluation_Framework_for_LLMs.md)

    - [翻译: 重审基准与评估：为大型语言模型构建基于代理的探索性动态评估框架](2024年10月16日/Revisiting_Benchmark_and_Assessment_An_Agent-based_Exploratory_Dynamic_Evaluation_Framework_for_LLMs.md)

- [Robust RL with LLM-Driven Data Synthesis and Policy Adaptation for Autonomous Driving](2024年10月16日/Robust_RL_with_LLM-Driven_Data_Synthesis_and_Policy_Adaptation_for_Autonomous_Driving.md)

    - [翻译: 基于 LLM 数据合成与策略适应的鲁棒强化学习，助力自动驾驶技术发展](2024年10月16日/Robust_RL_with_LLM-Driven_Data_Synthesis_and_Policy_Adaptation_for_Autonomous_Driving.md)

- [RosePO: Aligning LLM-based Recommenders with Human Values](2024年10月16日/RosePO_Aligning_LLM-based_Recommenders_with_Human_Values.md)

    - [翻译: RosePO：让基于 LLM 的推荐系统与人类价值观和谐共舞](2024年10月16日/RosePO_Aligning_LLM-based_Recommenders_with_Human_Values.md)

- [SAC-GLAM: Improving Online RL for LLM agents with Soft Actor-Critic and Hindsight Relabeling](2024年10月16日/SAC-GLAM_Improving_Online_RL_for_LLM_agents_with_Soft_Actor-Critic_and_Hindsight_Relabeling.md)

    - [翻译: SAC-GLAM：结合软演员-评论家与事后重标记，提升 LLM 代理的在线强化学习效果。](2024年10月16日/SAC-GLAM_Improving_Online_RL_for_LLM_agents_with_Soft_Actor-Critic_and_Hindsight_Relabeling.md)

- [Sarcasm Detection in a Less-Resourced Language](2024年10月16日/Sarcasm_Detection_in_a_Less-Resourced_Language.md)

    - [翻译: 在资源匮乏的语言中识别讽刺](2024年10月16日/Sarcasm_Detection_in_a_Less-Resourced_Language.md)

- [Semantics-Adaptive Activation Intervention for LLMs via Dynamic Steering Vectors](2024年10月16日/Semantics-Adaptive_Activation_Intervention_for_LLMs_via_Dynamic_Steering_Vectors.md)

    - [翻译: 利用动态转向向量实现 LLM 的语义自适应激活干预](2024年10月16日/Semantics-Adaptive_Activation_Intervention_for_LLMs_via_Dynamic_Steering_Vectors.md)

- [SF-Speech: Straightened Flow for Zero-Shot Voice Clone on Small-Scale Dataset](2024年10月16日/SF-Speech_Straightened_Flow_for_Zero-Shot_Voice_Clone_on_Small-Scale_Dataset.md)

    - [翻译: SF-Speech：小规模数据集上的零-shot 语音克隆直流技术](2024年10月16日/SF-Speech_Straightened_Flow_for_Zero-Shot_Voice_Clone_on_Small-Scale_Dataset.md)

- [ShapefileGPT: A Multi-Agent Large Language Model Framework for Automated Shapefile Processing](2024年10月16日/ShapefileGPT_A_Multi-Agent_Large_Language_Model_Framework_for_Automated_Shapefile_Processing.md)

    - [翻译: ShapefileGPT：一款专为自动化 Shapefile 处理设计的多智能体大型语言模型框架](2024年10月16日/ShapefileGPT_A_Multi-Agent_Large_Language_Model_Framework_for_Automated_Shapefile_Processing.md)

- [SLM-Mod: Small Language Models Surpass LLMs at Content Moderation](2024年10月16日/SLM-Mod_Small_Language_Models_Surpass_LLMs_at_Content_Moderation.md)

    - [翻译: SLM-Mod: 小语言模型在内容审核上胜过大语言模型](2024年10月16日/SLM-Mod_Small_Language_Models_Surpass_LLMs_at_Content_Moderation.md)

- [StyleDistance: Stronger Content-Independent Style Embeddings with Synthetic Parallel Examples](2024年10月16日/StyleDistance_Stronger_Content-Independent_Style_Embeddings_with_Synthetic_Parallel_Examples.md)

    - [翻译: StyleDistance：通过合成并行示例，实现更强大的内容无关风格嵌入](2024年10月16日/StyleDistance_Stronger_Content-Independent_Style_Embeddings_with_Synthetic_Parallel_Examples.md)

- [The Best of Both Worlds: Bridging Quality and Diversity in Data Selection with Bipartite Graph](2024年10月16日/The_Best_of_Both_Worlds_Bridging_Quality_and_Diversity_in_Data_Selection_with_Bipartite_Graph.md)

    - [翻译: 双赢之道：利用二分图在数据选择中兼顾质量和多样性](2024年10月16日/The_Best_of_Both_Worlds_Bridging_Quality_and_Diversity_in_Data_Selection_with_Bipartite_Graph.md)

- [The Curse of Multi-Modalities: Evaluating Hallucinations of Large Multimodal Models across Language, Visual, and Audio](2024年10月16日/The_Curse_of_Multi-Modalities_Evaluating_Hallucinations_of_Large_Multimodal_Models_across_Language,_Visual,_and_Audio.md)

    - [翻译: 多模态之咒：探究大型多模态模型在语言、视觉和音频领域的幻觉现象](2024年10月16日/The_Curse_of_Multi-Modalities_Evaluating_Hallucinations_of_Large_Multimodal_Models_across_Language,_Visual,_and_Audio.md)

- [The Geometry of Numerical Reasoning: Language Models Compare Numeric Properties in Linear Subspaces](2024年10月16日/The_Geometry_of_Numerical_Reasoning_Language_Models_Compare_Numeric_Properties_in_Linear_Subspaces.md)

    - [翻译: 语言模型如何在线性子空间中比较数值属性，揭示了数值推理的几何学奥秘。](2024年10月16日/The_Geometry_of_Numerical_Reasoning_Language_Models_Compare_Numeric_Properties_in_Linear_Subspaces.md)

- [Towards Zero-Shot Camera Trap Image Categorization](2024年10月16日/Towards_Zero-Shot_Camera_Trap_Image_Categorization.md)

    - [翻译: 迈向零-shot 相机陷阱图像分类](2024年10月16日/Towards_Zero-Shot_Camera_Trap_Image_Categorization.md)

- [Understanding the Role of LLMs in Multimodal Evaluation Benchmarks](2024年10月16日/Understanding_the_Role_of_LLMs_in_Multimodal_Evaluation_Benchmarks.md)

    - [翻译: 探究 LLM 在多模态评估中的作用](2024年10月16日/Understanding_the_Role_of_LLMs_in_Multimodal_Evaluation_Benchmarks.md)

- [UTF:Undertrained Tokens as Fingerprints A Novel Approach to LLM Identification](2024年10月16日/UTFUndertrained_Tokens_as_Fingerprints_A_Novel_Approach_to_LLM_Identification.md)

    - [翻译: UTF: 利用未充分训练的 Token 作为指纹，开创了一种识别 LLM 的新途径。](2024年10月16日/UTFUndertrained_Tokens_as_Fingerprints_A_Novel_Approach_to_LLM_Identification.md)

- [VividMed: Vision Language Model with Versatile Visual Grounding for Medicine](2024年10月16日/VividMed_Vision_Language_Model_with_Versatile_Visual_Grounding_for_Medicine.md)

    - [翻译: VividMed：一款专为医学领域设计的多功能视觉语言模型，具备强大的视觉基础能力。](2024年10月16日/VividMed_Vision_Language_Model_with_Versatile_Visual_Grounding_for_Medicine.md)

- [Weak-to-Strong Generalization beyond Accuracy: a Pilot Study in Safety, Toxicity, and Legal Reasoning](2024年10月16日/Weak-to-Strong_Generalization_beyond_Accuracy_a_Pilot_Study_in_Safety,_Toxicity,_and_Legal_Reasoning.md)

    - [翻译: 超越准确性：探索从弱到强的泛化在安全、毒性和法律推理中的应用](2024年10月16日/Weak-to-Strong_Generalization_beyond_Accuracy_a_Pilot_Study_in_Safety,_Toxicity,_and_Legal_Reasoning.md)

- [With a Grain of SALT: Are LLMs Fair Across Social Dimensions?](2024年10月16日/With_a_Grain_of_SALT_Are_LLMs_Fair_Across_Social_Dimensions.md)

    - [翻译: LLM 是否在社会维度上公平？让我们带着批判的眼光来探讨。](2024年10月16日/With_a_Grain_of_SALT_Are_LLMs_Fair_Across_Social_Dimensions.md)

- [WorldMedQA-V: a multilingual, multimodal medical examination dataset for multimodal language models evaluation](2024年10月16日/WorldMedQA-V_a_multilingual,_multimodal_medical_examination_dataset_for_multimodal_language_models_evaluation.md)

    - [翻译: WorldMedQA-V：一款专为多模态语言模型评估设计的多语言、多模态医学考试数据集](2024年10月16日/WorldMedQA-V_a_multilingual,_multimodal_medical_examination_dataset_for_multimodal_language_models_evaluation.md)

2024年10月15日

- [Advanced Persistent Threats (APT) Attribution Using Deep Reinforcement Learning](2024年10月15日/Advanced_Persistent_Threats_(APT)_Attribution_Using_Deep_Reinforcement_Learning.md)

    - [翻译: 利用深度强化学习技术，精准归因高级持续威胁（APT）](2024年10月15日/Advanced_Persistent_Threats_(APT)_Attribution_Using_Deep_Reinforcement_Learning.md)

- [A Framework for Adapting Human-Robot Interaction to Diverse User Groups](2024年10月15日/A_Framework_for_Adapting_Human-Robot_Interaction_to_Diverse_User_Groups.md)

    - [翻译: 人机交互框架，灵活适应多元用户群体](2024年10月15日/A_Framework_for_Adapting_Human-Robot_Interaction_to_Diverse_User_Groups.md)

- [AGENTiGraph: An Interactive Knowledge Graph Platform for LLM-based Chatbots Utilizing Private Data](2024年10月15日/AGENTiGraph_An_Interactive_Knowledge_Graph_Platform_for_LLM-based_Chatbots_Utilizing_Private_Data.md)

    - [翻译: AGENTiGraph：专为基于 LLM 的聊天机器人设计的交互式知识图谱平台，充分利用私有数据。](2024年10月15日/AGENTiGraph_An_Interactive_Knowledge_Graph_Platform_for_LLM-based_Chatbots_Utilizing_Private_Data.md)

- [A Hitchhiker's Guide to Scaling Law Estimation](2024年10月15日/A_Hitchhiker's_Guide_to_Scaling_Law_Estimation.md)

    - [翻译: 《缩放法则估计的搭便车指南》](2024年10月15日/A_Hitchhiker's_Guide_to_Scaling_Law_Estimation.md)

- [AIC CTU system at AVeriTeC: Re-framing automated fact-checking as a simple RAG task](2024年10月15日/AIC_CTU_system_at_AVeriTeC_Re-framing_automated_fact-checking_as_a_simple_RAG_task.md)

    - [翻译: AVeriTeC 的 AIC CTU 系统：将自动事实核查简化为一个简单的 RAG 任务](2024年10月15日/AIC_CTU_system_at_AVeriTeC_Re-framing_automated_fact-checking_as_a_simple_RAG_task.md)

- [Are UFOs Driving Innovation? The Illusion of Causality in Large Language Models](2024年10月15日/Are_UFOs_Driving_Innovation_The_Illusion_of_Causality_in_Large_Language_Models.md)

    - [翻译: UFOs 能推动创新吗？大型语言模型中的因果错觉](2024年10月15日/Are_UFOs_Driving_Innovation_The_Illusion_of_Causality_in_Large_Language_Models.md)

- [Augmentation-Driven Metric for Balancing Preservation and Modification in Text-Guided Image Editing](2024年10月15日/Augmentation-Driven_Metric_for_Balancing_Preservation_and_Modification_in_Text-Guided_Image_Editing.md)

    - [翻译: 增强驱动度量：平衡文本引导图像编辑中的保留与修改](2024年10月15日/Augmentation-Driven_Metric_for_Balancing_Preservation_and_Modification_in_Text-Guided_Image_Editing.md)

- [Beyond Linear Approximations: A Novel Pruning Approach for Attention Matrix](2024年10月15日/Beyond_Linear_Approximations_A_Novel_Pruning_Approach_for_Attention_Matrix.md)

    - [翻译: 突破线性限制：探索注意力矩阵的新剪枝策略](2024年10月15日/Beyond_Linear_Approximations_A_Novel_Pruning_Approach_for_Attention_Matrix.md)

- [Bypassing the Exponential Dependency: Looped Transformers Efficiently Learn In-context by Multi-step Gradient Descent](2024年10月15日/Bypassing_the_Exponential_Dependency_Looped_Transformers_Efficiently_Learn_In-context_by_Multi-step_Gradient_Descent.md)

    - [翻译: 循环Transformer巧妙绕过指数依赖，通过多步梯度下降，高效掌握上下文学习。](2024年10月15日/Bypassing_the_Exponential_Dependency_Looped_Transformers_Efficiently_Learn_In-context_by_Multi-step_Gradient_Descent.md)

- [Cognitive Overload Attack:Prompt Injection for Long Context](2024年10月15日/Cognitive_Overload_AttackPrompt_Injection_for_Long_Context.md)

    - [翻译: 认知过载攻击：长上下文中的提示注入](2024年10月15日/Cognitive_Overload_AttackPrompt_Injection_for_Long_Context.md)

- [CtrlSynth: Controllable Image Text Synthesis for Data-Efficient Multimodal Learning](2024年10月15日/CtrlSynth_Controllable_Image_Text_Synthesis_for_Data-Efficient_Multimodal_Learning.md)

    - [翻译: CtrlSynth：一种可控的图像文本合成工具，专为高效多模态学习设计。](2024年10月15日/CtrlSynth_Controllable_Image_Text_Synthesis_for_Data-Efficient_Multimodal_Learning.md)

- [Data Quality Control in Federated Instruction-tuning of Large Language Models](2024年10月15日/Data_Quality_Control_in_Federated_Instruction-tuning_of_Large_Language_Models.md)

    - [翻译: 联邦指令调优中的数据质量控制：大型语言模型的关键环节](2024年10月15日/Data_Quality_Control_in_Federated_Instruction-tuning_of_Large_Language_Models.md)

- [Data Selection for Task-Specific Model Finetuning](2024年10月15日/Data_Selection_for_Task-Specific_Model_Finetuning.md)

    - [翻译: 任务导向模型微调中的数据精选](2024年10月15日/Data_Selection_for_Task-Specific_Model_Finetuning.md)

- [Deciphering the Chaos: Enhancing Jailbreak Attacks via Adversarial Prompt Translation](2024年10月15日/Deciphering_the_Chaos_Enhancing_Jailbreak_Attacks_via_Adversarial_Prompt_Translation.md)

    - [翻译: 破解混沌：利用对抗性提示翻译提升越狱攻击效果](2024年10月15日/Deciphering_the_Chaos_Enhancing_Jailbreak_Attacks_via_Adversarial_Prompt_Translation.md)

- [DeformPAM: Data-Efficient Learning for Long-horizon Deformable Object Manipulation via Preference-based Action Alignment](2024年10月15日/DeformPAM_Data-Efficient_Learning_for_Long-horizon_Deformable_Object_Manipulation_via_Preference-based_Action_Alignment.md)

    - [翻译: DeformPAM：利用基于偏好的动作对齐，高效学习长时变形物体的操作。](2024年10月15日/DeformPAM_Data-Efficient_Learning_for_Long-horizon_Deformable_Object_Manipulation_via_Preference-based_Action_Alignment.md)

- [De-jargonizing Science for Journalists with GPT-4: A Pilot Study](2024年10月15日/De-jargonizing_Science_for_Journalists_with_GPT-4_A_Pilot_Study.md)

    - [翻译: 利用 GPT-4 帮助记者简化科学术语：一次初步探索](2024年10月15日/De-jargonizing_Science_for_Journalists_with_GPT-4_A_Pilot_Study.md)

- [Difficult Task Yes but Simple Task No: Unveiling the Laziness in Multimodal LLMs](2024年10月15日/Difficult_Task_Yes_but_Simple_Task_No_Unveiling_the_Laziness_in_Multimodal_LLMs.md)

    - [翻译: 多模态大型语言模型在处理困难任务时表现出色，但在简单任务上却显得懒散。本文将揭示这种“懒惰”现象。](2024年10月15日/Difficult_Task_Yes_but_Simple_Task_No_Unveiling_the_Laziness_in_Multimodal_LLMs.md)

- [DocETL: Agentic Query Rewriting and Evaluation for Complex Document Processing](2024年10月15日/DocETL_Agentic_Query_Rewriting_and_Evaluation_for_Complex_Document_Processing.md)

    - [翻译: DocETL：复杂文档处理中的智能查询重写与评估](2024年10月15日/DocETL_Agentic_Query_Rewriting_and_Evaluation_for_Complex_Document_Processing.md)

- [Do LLMs Have the Generalization Ability in Conducting Causal Inference?](2024年10月15日/Do_LLMs_Have_the_Generalization_Ability_in_Conducting_Causal_Inference.md)

    - [翻译: 大型语言模型是否具备进行因果推理的泛化能力？](2024年10月15日/Do_LLMs_Have_the_Generalization_Ability_in_Conducting_Causal_Inference.md)

- [DynamicER: Resolving Emerging Mentions to Dynamic Entities for RAG](2024年10月15日/DynamicER_Resolving_Emerging_Mentions_to_Dynamic_Entities_for_RAG.md)

    - [翻译: DynamicER：为 RAG 系统解析新兴提及并映射到动态实体](2024年10月15日/DynamicER_Resolving_Emerging_Mentions_to_Dynamic_Entities_for_RAG.md)

- [DySpec: Faster Speculative Decoding with Dynamic Token Tree Structure](2024年10月15日/DySpec_Faster_Speculative_Decoding_with_Dynamic_Token_Tree_Structure.md)

    - [翻译: DySpec：借助动态令牌树结构，实现更快的推测解码](2024年10月15日/DySpec_Faster_Speculative_Decoding_with_Dynamic_Token_Tree_Structure.md)

- [Eliciting Textual Descriptions from Representations of Continuous Prompts](2024年10月15日/Eliciting_Textual_Descriptions_from_Representations_of_Continuous_Prompts.md)

    - [翻译: 从连续提示的表示中提取文本描述](2024年10月15日/Eliciting_Textual_Descriptions_from_Representations_of_Continuous_Prompts.md)

- [Enhance Graph Alignment for Large Language Models](2024年10月15日/Enhance_Graph_Alignment_for_Large_Language_Models.md)

    - [翻译: 提升大型语言模型的图对齐能力](2024年10月15日/Enhance_Graph_Alignment_for_Large_Language_Models.md)

- [FoundTS: Comprehensive and Unified Benchmarking of Foundation Models for Time Series Forecasting](2024年10月15日/FoundTS_Comprehensive_and_Unified_Benchmarking_of_Foundation_Models_for_Time_Series_Forecasting.md)

    - [翻译: FoundTS：时间序列预测基础模型的全面统一基准](2024年10月15日/FoundTS_Comprehensive_and_Unified_Benchmarking_of_Foundation_Models_for_Time_Series_Forecasting.md)

- [GaVaMoE: Gaussian-Variational Gated Mixture of Experts for Explainable Recommendation](2024年10月15日/GaVaMoE_Gaussian-Variational_Gated_Mixture_of_Experts_for_Explainable_Recommendation.md)

    - [翻译: GaVaMoE：一种结合高斯变分和门控混合专家技术，旨在提升推荐系统可解释性的模型。](2024年10月15日/GaVaMoE_Gaussian-Variational_Gated_Mixture_of_Experts_for_Explainable_Recommendation.md)

- [Holistic Reasoning with Long-Context LMs: A Benchmark for Database Operations on Massive Textual Data](2024年10月15日/Holistic_Reasoning_with_Long-Context_LMs_A_Benchmark_for_Database_Operations_on_Massive_Textual_Data.md)

    - [翻译: 长上下文语言模型的整体推理：大规模文本数据数据库操作的基准测试](2024年10月15日/Holistic_Reasoning_with_Long-Context_LMs_A_Benchmark_for_Database_Operations_on_Massive_Textual_Data.md)

- [Human-LLM Collaborative Construction of a Cantonese Emotion Lexicon](2024年10月15日/Human-LLM_Collaborative_Construction_of_a_Cantonese_Emotion_Lexicon.md)

    - [翻译: 人机协作，共筑粤语情感词库](2024年10月15日/Human-LLM_Collaborative_Construction_of_a_Cantonese_Emotion_Lexicon.md)

- [Implementing Derivations of Definite Logic Programs with Self-Attention Networks](2024年10月15日/Implementing_Derivations_of_Definite_Logic_Programs_with_Self-Attention_Networks.md)

    - [翻译: 用自注意力网络实现确定逻辑程序的推导](2024年10月15日/Implementing_Derivations_of_Definite_Logic_Programs_with_Self-Attention_Networks.md)

- [Instructive Code Retriever: Learn from Large Language Model's Feedback for Code Intelligence Tasks](2024年10月15日/Instructive_Code_Retriever_Learn_from_Large_Language_Model's_Feedback_for_Code_Intelligence_Tasks.md)

    - [翻译: 指导性代码检索器：借助大型语言模型的反馈，提升代码智能任务的表现](2024年10月15日/Instructive_Code_Retriever_Learn_from_Large_Language_Model's_Feedback_for_Code_Intelligence_Tasks.md)

- [IntGrad MT: Eliciting LLMs' Machine Translation Capabilities with Sentence Interpolation and Gradual MT](2024年10月15日/IntGrad_MT_Eliciting_LLMs'_Machine_Translation_Capabilities_with_Sentence_Interpolation_and_Gradual_MT.md)

    - [翻译: IntGrad MT：借助句子插值与逐步机器翻译，激发 LLM 的翻译潜能](2024年10月15日/IntGrad_MT_Eliciting_LLMs'_Machine_Translation_Capabilities_with_Sentence_Interpolation_and_Gradual_MT.md)

- [KITTEN: A Knowledge-Intensive Evaluation of Image Generation on Visual Entities](2024年10月15日/KITTEN_A_Knowledge-Intensive_Evaluation_of_Image_Generation_on_Visual_Entities.md)

    - [翻译: KITTEN：视觉实体图像生成的知识密集型评估](2024年10月15日/KITTEN_A_Knowledge-Intensive_Evaluation_of_Image_Generation_on_Visual_Entities.md)

- [Language Models Encode Numbers Using Digit Representations in Base 10](2024年10月15日/Language_Models_Encode_Numbers_Using_Digit_Representations_in_Base_10.md)

    - [翻译: 语言模型通过十进制数字表示来编码数字](2024年10月15日/Language_Models_Encode_Numbers_Using_Digit_Representations_in_Base_10.md)

- [LargePiG: Your Large Language Model is Secretly a Pointer Generator](2024年10月15日/LargePiG_Your_Large_Language_Model_is_Secretly_a_Pointer_Generator.md)

    - [翻译: LargePiG：你的大型语言模型其实是个隐藏的指针生成器](2024年10月15日/LargePiG_Your_Large_Language_Model_is_Secretly_a_Pointer_Generator.md)

- [Layer-wise Importance Matters: Less Memory for Better Performance in Parameter-efficient Fine-tuning of Large Language Models](2024年10月15日/Layer-wise_Importance_Matters_Less_Memory_for_Better_Performance_in_Parameter-efficient_Fine-tuning_of_Large_Language_Models.md)

    - [翻译: 逐层重要性不容忽视：在大型语言模型的参数高效微调中，减少内存占用反而能提升性能。](2024年10月15日/Layer-wise_Importance_Matters_Less_Memory_for_Better_Performance_in_Parameter-efficient_Fine-tuning_of_Large_Language_Models.md)

- [Learning from Imperfect Data: Towards Efficient Knowledge Distillation of Autoregressive Language Models for Text-to-SQL](2024年10月15日/Learning_from_Imperfect_Data_Towards_Efficient_Knowledge_Distillation_of_Autoregressive_Language_Models_for_Text-to-SQL.md)

    - [翻译: 从不完美数据中学习：提升自动回归语言模型在文本到SQL任务中的知识蒸馏效率](2024年10月15日/Learning_from_Imperfect_Data_Towards_Efficient_Knowledge_Distillation_of_Autoregressive_Language_Models_for_Text-to-SQL.md)

- [Leveraging LLM Embeddings for Cross Dataset Label Alignment and Zero Shot Music Emotion Prediction](2024年10月15日/Leveraging_LLM_Embeddings_for_Cross_Dataset_Label_Alignment_and_Zero_Shot_Music_Emotion_Prediction.md)

    - [翻译: 借助 LLM 嵌入，实现跨数据集标签对齐，并进行零-shot 音乐情感预测。](2024年10月15日/Leveraging_LLM_Embeddings_for_Cross_Dataset_Label_Alignment_and_Zero_Shot_Music_Emotion_Prediction.md)

- [Light-Weight Fault Tolerant Attention for Large Language Model Training](2024年10月15日/Light-Weight_Fault_Tolerant_Attention_for_Large_Language_Model_Training.md)

    - [翻译: 轻量级容错注意力机制助力大型语言模型训练](2024年10月15日/Light-Weight_Fault_Tolerant_Attention_for_Large_Language_Model_Training.md)

- [LLM2Swarm: Robot Swarms that Responsively Reason, Plan, and Collaborate through LLMs](2024年10月15日/LLM2Swarm_Robot_Swarms_that_Responsively_Reason,_Plan,_and_Collaborate_through_LLMs.md)

    - [翻译: LLM2Swarm：借助 LLM 实现智能推理、协同规划与合作的机器人集群](2024年10月15日/LLM2Swarm_Robot_Swarms_that_Responsively_Reason,_Plan,_and_Collaborate_through_LLMs.md)

- [LLM-Mixer: Multiscale Mixing in LLMs for Time Series Forecasting](2024年10月15日/LLM-Mixer_Multiscale_Mixing_in_LLMs_for_Time_Series_Forecasting.md)

    - [翻译: LLM-Mixer：在 LLM 中实现时间序列预测的多尺度混合技术](2024年10月15日/LLM-Mixer_Multiscale_Mixing_in_LLMs_for_Time_Series_Forecasting.md)

- [LoKO: Low-Rank Kalman Optimizer for Online Fine-Tuning of Large Models](2024年10月15日/LoKO_Low-Rank_Kalman_Optimizer_for_Online_Fine-Tuning_of_Large_Models.md)

    - [翻译: LoKO：专为大型模型在线微调设计的低秩卡尔曼优化器](2024年10月15日/LoKO_Low-Rank_Kalman_Optimizer_for_Online_Fine-Tuning_of_Large_Models.md)

- [LongHalQA: Long-Context Hallucination Evaluation for MultiModal Large Language Models](2024年10月15日/LongHalQA_Long-Context_Hallucination_Evaluation_for_MultiModal_Large_Language_Models.md)

    - [翻译: LongHalQA：评估多模态大型语言模型在长上下文中的幻觉现象](2024年10月15日/LongHalQA_Long-Context_Hallucination_Evaluation_for_MultiModal_Large_Language_Models.md)

- [LR-SQL: A Supervised Fine-Tuning Method for Text2SQL Tasks under Low-Resource Scenarios](2024年10月15日/LR-SQL_A_Supervised_Fine-Tuning_Method_for_Text2SQL_Tasks_under_Low-Resource_Scenarios.md)

    - [翻译: LR-SQL：低资源场景下 Text2SQL 任务的监督微调新方法](2024年10月15日/LR-SQL_A_Supervised_Fine-Tuning_Method_for_Text2SQL_Tasks_under_Low-Resource_Scenarios.md)

- [Magnifier Prompt: Tackling Multimodal Hallucination via Extremely Simple Instructions](2024年10月15日/Magnifier_Prompt_Tackling_Multimodal_Hallucination_via_Extremely_Simple_Instructions.md)

    - [翻译: 放大镜提示：用极简指令攻克多模态幻觉难题](2024年10月15日/Magnifier_Prompt_Tackling_Multimodal_Hallucination_via_Extremely_Simple_Instructions.md)

- [MCTBench: Multimodal Cognition towards Text-Rich Visual Scenes Benchmark](2024年10月15日/MCTBench_Multimodal_Cognition_towards_Text-Rich_Visual_Scenes_Benchmark.md)

    - [翻译: MCTBench：探索文本与视觉融合的多模态认知新基准](2024年10月15日/MCTBench_Multimodal_Cognition_towards_Text-Rich_Visual_Scenes_Benchmark.md)

- [Measuring Spiritual Values and Bias of Large Language Models](2024年10月15日/Measuring_Spiritual_Values_and_Bias_of_Large_Language_Models.md)

    - [翻译: 探究大型语言模型的精神价值与偏见](2024年10月15日/Measuring_Spiritual_Values_and_Bias_of_Large_Language_Models.md)

- [MLLM can see? Dynamic Correction Decoding for Hallucination Mitigation](2024年10月15日/MLLM_can_see_Dynamic_Correction_Decoding_for_Hallucination_Mitigation.md)

    - [翻译: MLLM 能“看”吗？动态校正解码助力幻觉缓解](2024年10月15日/MLLM_can_see_Dynamic_Correction_Decoding_for_Hallucination_Mitigation.md)

- [MoChat: Joints-Grouped Spatio-Temporal Grounding LLM for Multi-Turn Motion Comprehension and Description](2024年10月15日/MoChat_Joints-Grouped_Spatio-Temporal_Grounding_LLM_for_Multi-Turn_Motion_Comprehension_and_Description.md)

    - [翻译: MoChat：一款专为多轮运动理解和描述设计的联合分组时空定位大型语言模型](2024年10月15日/MoChat_Joints-Grouped_Spatio-Temporal_Grounding_LLM_for_Multi-Turn_Motion_Comprehension_and_Description.md)

- [Model Swarms: Collaborative Search to Adapt LLM Experts via Swarm Intelligence](2024年10月15日/Model_Swarms_Collaborative_Search_to_Adapt_LLM_Experts_via_Swarm_Intelligence.md)

    - [翻译: 模型集群：利用集群智能，协同搜索以适应 LLM 专家](2024年10月15日/Model_Swarms_Collaborative_Search_to_Adapt_LLM_Experts_via_Swarm_Intelligence.md)

- [MTU-Bench: A Multi-granularity Tool-Use Benchmark for Large Language Models](2024年10月15日/MTU-Bench_A_Multi-granularity_Tool-Use_Benchmark_for_Large_Language_Models.md)

    - [翻译: MTU-Bench：专为大型语言模型设计的多粒度工具使用基准](2024年10月15日/MTU-Bench_A_Multi-granularity_Tool-Use_Benchmark_for_Large_Language_Models.md)

- [Multi-round jailbreak attack on large language models](2024年10月15日/Multi-round_jailbreak_attack_on_large_language_models.md)

    - [翻译: 大型语言模型面临多轮越狱攻击](2024年10月15日/Multi-round_jailbreak_attack_on_large_language_models.md)

- [NesTools: A Dataset for Evaluating Nested Tool Learning Abilities of Large Language Models](2024年10月15日/NesTools_A_Dataset_for_Evaluating_Nested_Tool_Learning_Abilities_of_Large_Language_Models.md)

    - [翻译: NesTools：专为评估大型语言模型嵌套工具学习能力而设计的数据集](2024年10月15日/NesTools_A_Dataset_for_Evaluating_Nested_Tool_Learning_Abilities_of_Large_Language_Models.md)

- [O-Edit: Orthogonal Subspace Editing for Language Model Sequential Editing](2024年10月15日/O-Edit_Orthogonal_Subspace_Editing_for_Language_Model_Sequential_Editing.md)

    - [翻译: O-Edit：一种用于语言模型序列编辑的正交子空间编辑方法](2024年10月15日/O-Edit_Orthogonal_Subspace_Editing_for_Language_Model_Sequential_Editing.md)

- [OMCAT: Omni Context Aware Transformer](2024年10月15日/OMCAT_Omni_Context_Aware_Transformer.md)

    - [翻译: OMCAT：全场景智能Transformer](2024年10月15日/OMCAT_Omni_Context_Aware_Transformer.md)

- [PAVLM: Advancing Point Cloud based Affordance Understanding Via Vision-Language Model](2024年10月15日/PAVLM_Advancing_Point_Cloud_based_Affordance_Understanding_Via_Vision-Language_Model.md)

    - [翻译: PAVLM：借助视觉-语言模型，推动基于点云的可操作性理解](2024年10月15日/PAVLM_Advancing_Point_Cloud_based_Affordance_Understanding_Via_Vision-Language_Model.md)

- [Personas with Attitudes: Controlling LLMs for Diverse Data Annotation](2024年10月15日/Personas_with_Attitudes_Controlling_LLMs_for_Diverse_Data_Annotation.md)

    - [翻译: 赋予角色态度：掌控 LLM，实现数据标注的多样性](2024年10月15日/Personas_with_Attitudes_Controlling_LLMs_for_Diverse_Data_Annotation.md)

- [PMMT: Preference Alignment in Multilingual Machine Translation via LLM Distillation](2024年10月15日/PMMT_Preference_Alignment_in_Multilingual_Machine_Translation_via_LLM_Distillation.md)

    - [翻译: PMMT：利用 LLM 蒸馏技术，实现多语言机器翻译中的偏好对齐](2024年10月15日/PMMT_Preference_Alignment_in_Multilingual_Machine_Translation_via_LLM_Distillation.md)

- [QSpec: Speculative Decoding with Complementary Quantization Schemes](2024年10月15日/QSpec_Speculative_Decoding_with_Complementary_Quantization_Schemes.md)

    - [翻译: QSpec：采用互补量化方案的推测性解码技术](2024年10月15日/QSpec_Speculative_Decoding_with_Complementary_Quantization_Schemes.md)

- [RATE: Score Reward Models with Imperfect Rewrites of Rewrites](2024年10月15日/RATE_Score_Reward_Models_with_Imperfect_Rewrites_of_Rewrites.md)

    - [翻译: RATE：用重写的瑕疵来评估奖励模型](2024年10月15日/RATE_Score_Reward_Models_with_Imperfect_Rewrites_of_Rewrites.md)

- [ReDeEP: Detecting Hallucination in Retrieval-Augmented Generation via Mechanistic Interpretability](2024年10月15日/ReDeEP_Detecting_Hallucination_in_Retrieval-Augmented_Generation_via_Mechanistic_Interpretability.md)

    - [翻译: ReDeEP：利用机制可解释性，精准检测检索增强生成中的幻觉现象。](2024年10月15日/ReDeEP_Detecting_Hallucination_in_Retrieval-Augmented_Generation_via_Mechanistic_Interpretability.md)

- [Robust Manipulation Primitive Learning via Domain Contraction](2024年10月15日/Robust_Manipulation_Primitive_Learning_via_Domain_Contraction.md)

    - [翻译: 通过领域收缩，实现操作原语的鲁棒学习](2024年10月15日/Robust_Manipulation_Primitive_Learning_via_Domain_Contraction.md)

- [SEER: Self-Aligned Evidence Extraction for Retrieval-Augmented Generation](2024年10月15日/SEER_Self-Aligned_Evidence_Extraction_for_Retrieval-Augmented_Generation.md)

    - [翻译: SEER：自对齐证据提取，助力检索增强生成](2024年10月15日/SEER_Self-Aligned_Evidence_Extraction_for_Retrieval-Augmented_Generation.md)

- [Self-adaptive Multimodal Retrieval-Augmented Generation](2024年10月15日/Self-adaptive_Multimodal_Retrieval-Augmented_Generation.md)

    - [翻译: 自适应多模态检索增强生成技术](2024年10月15日/Self-adaptive_Multimodal_Retrieval-Augmented_Generation.md)

- [Sequential LLM Framework for Fashion Recommendation](2024年10月15日/Sequential_LLM_Framework_for_Fashion_Recommendation.md)

    - [翻译: 时尚推荐中的顺序 LLM 框架](2024年10月15日/Sequential_LLM_Framework_for_Fashion_Recommendation.md)

- [SGEdit: Bridging LLM with Text2Image Generative Model for Scene Graph-based Image Editing](2024年10月15日/SGEdit_Bridging_LLM_with_Text2Image_Generative_Model_for_Scene_Graph-based_Image_Editing.md)

    - [翻译: SGEdit：融合 LLM 与 Text2Image 生成模型，实现基于场景图的图像编辑](2024年10月15日/SGEdit_Bridging_LLM_with_Text2Image_Generative_Model_for_Scene_Graph-based_Image_Editing.md)

- [SlideChat: A Large Vision-Language Assistant for Whole-Slide Pathology Image Understanding](2024年10月15日/SlideChat_A_Large_Vision-Language_Assistant_for_Whole-Slide_Pathology_Image_Understanding.md)

    - [翻译: SlideChat：一款强大的视觉-语言助手，专为全切片病理图像的深度理解而设计。](2024年10月15日/SlideChat_A_Large_Vision-Language_Assistant_for_Whole-Slide_Pathology_Image_Understanding.md)

- [TransAgent: Transfer Vision-Language Foundation Models with Heterogeneous Agent Collaboration](2024年10月15日/TransAgent_Transfer_Vision-Language_Foundation_Models_with_Heterogeneous_Agent_Collaboration.md)

    - [翻译: TransAgent：借助异构代理协作，实现视觉-语言基础模型的迁移](2024年10月15日/TransAgent_Transfer_Vision-Language_Foundation_Models_with_Heterogeneous_Agent_Collaboration.md)

- [Transformer Layer Injection: A Novel Approach for Efficient Upscaling of Large Language Models](2024年10月15日/Transformer_Layer_Injection_A_Novel_Approach_for_Efficient_Upscaling_of_Large_Language_Models.md)

    - [翻译: Transformer 层注入：提升大型语言模型效率的创新之道](2024年10月15日/Transformer_Layer_Injection_A_Novel_Approach_for_Efficient_Upscaling_of_Large_Language_Models.md)

- [VidCompress: Memory-Enhanced Temporal Compression for Video Understanding in Large Language Models](2024年10月15日/VidCompress_Memory-Enhanced_Temporal_Compression_for_Video_Understanding_in_Large_Language_Models.md)

    - [翻译: VidCompress：通过内存增强的时间压缩技术，提升大型语言模型中的视频理解能力。](2024年10月15日/VidCompress_Memory-Enhanced_Temporal_Compression_for_Video_Understanding_in_Large_Language_Models.md)

- [Y-Mol: A Multiscale Biomedical Knowledge-Guided Large Language Model for Drug Development](2024年10月15日/Y-Mol_A_Multiscale_Biomedical_Knowledge-Guided_Large_Language_Model_for_Drug_Development.md)

    - [翻译: Y-Mol：一款多尺度生物医学知识驱动的大型语言模型，专为药物研发而生](2024年10月15日/Y-Mol_A_Multiscale_Biomedical_Knowledge-Guided_Large_Language_Model_for_Drug_Development.md)

2024年10月14日

- [$α$-DPO: Adaptive Reward Margin is What Direct Preference Optimization Needs](2024年10月14日/$α$-DPO_Adaptive_Reward_Margin_is_What_Direct_Preference_Optimization_Needs.md)

    - [翻译: $α$-DPO：自适应奖励边际，正是直接偏好优化所需的关键。](2024年10月14日/$α$-DPO_Adaptive_Reward_Margin_is_What_Direct_Preference_Optimization_Needs.md)

- [A CLIP-Powered Framework for Robust and Generalizable Data Selection](2024年10月14日/A_CLIP-Powered_Framework_for_Robust_and_Generalizable_Data_Selection.md)

    - [翻译: 基于 CLIP 的框架，助力数据选择更稳健、更通用](2024年10月14日/A_CLIP-Powered_Framework_for_Robust_and_Generalizable_Data_Selection.md)

- [Ada-K Routing: Boosting the Efficiency of MoE-based LLMs](2024年10月14日/Ada-K_Routing_Boosting_the_Efficiency_of_MoE-based_LLMs.md)

    - [翻译: Ada-K 路由：为基于 MoE 的 LLM 注入高效动力](2024年10月14日/Ada-K_Routing_Boosting_the_Efficiency_of_MoE-based_LLMs.md)

- [Adapt-$\infty$: Scalable Lifelong Multimodal Instruction Tuning via Dynamic Data Selection](2024年10月14日/Adapt-$\infty$_Scalable_Lifelong_Multimodal_Instruction_Tuning_via_Dynamic_Data_Selection.md)

    - [翻译: Adapt-$\infty$：利用动态数据选择，实现终身多模态指令调优的可扩展性](2024年10月14日/Adapt-$\infty$_Scalable_Lifelong_Multimodal_Instruction_Tuning_via_Dynamic_Data_Selection.md)

- [A Multi-Task Text Classification Pipeline with Natural Language Explanations: A User-Centric Evaluation in Sentiment Analysis and Offensive Language Identification in Greek Tweets](2024年10月14日/A_Multi-Task_Text_Classification_Pipeline_with_Natural_Language_Explanations_A_User-Centric_Evaluation_in_Sentiment_Analysis_and_Offensive_Language_Identification_in_Greek_Tweets.md)

    - [翻译: 多任务文本分类管道，结合自然语言解释，专注于希腊推文中的情感分析与冒犯性语言识别，以用户为中心进行评估。](2024年10月14日/A_Multi-Task_Text_Classification_Pipeline_with_Natural_Language_Explanations_A_User-Centric_Evaluation_in_Sentiment_Analysis_and_Offensive_Language_Identification_in_Greek_Tweets.md)

- [Athena: Retrieval-augmented Legal Judgment Prediction with Large Language Models](2024年10月14日/Athena_Retrieval-augmented_Legal_Judgment_Prediction_with_Large_Language_Models.md)

    - [翻译: Athena：借助大型语言模型提升检索功能的法律判决预测系统](2024年10月14日/Athena_Retrieval-augmented_Legal_Judgment_Prediction_with_Large_Language_Models.md)

- [Audio Captioning via Generative Pair-to-Pair Retrieval with Refined Knowledge Base](2024年10月14日/Audio_Captioning_via_Generative_Pair-to-Pair_Retrieval_with_Refined_Knowledge_Base.md)

    - [翻译: 音频描述：基于精炼知识库的生成式配对检索](2024年10月14日/Audio_Captioning_via_Generative_Pair-to-Pair_Retrieval_with_Refined_Knowledge_Base.md)

- [Augmenting In-Context-Learning in LLMs via Automatic Data Labeling and Refinement](2024年10月14日/Augmenting_In-Context-Learning_in_LLMs_via_Automatic_Data_Labeling_and_Refinement.md)

    - [翻译: 借助自动数据标注与优化，提升 LLM 中的 In-Context-Learning 效果](2024年10月14日/Augmenting_In-Context-Learning_in_LLMs_via_Automatic_Data_Labeling_and_Refinement.md)

- [A Unified Approach to Routing and Cascading for LLMs](2024年10月14日/A_Unified_Approach_to_Routing_and_Cascading_for_LLMs.md)

    - [翻译: LLM 中的路由与级联统一方法](2024年10月14日/A_Unified_Approach_to_Routing_and_Cascading_for_LLMs.md)

- [Automated Filtering of Human Feedback Data for Aligning Text-to-Image Diffusion Models](2024年10月14日/Automated_Filtering_of_Human_Feedback_Data_for_Aligning_Text-to-Image_Diffusion_Models.md)

    - [翻译: 自动化筛选人类反馈数据，优化文本到图像扩散模型的对齐效果](2024年10月14日/Automated_Filtering_of_Human_Feedback_Data_for_Aligning_Text-to-Image_Diffusion_Models.md)

- [Automatically Generating Visual Hallucination Test Cases for Multimodal Large Language Models](2024年10月14日/Automatically_Generating_Visual_Hallucination_Test_Cases_for_Multimodal_Large_Language_Models.md)

    - [翻译: 自动为多模态大型语言模型生成视觉幻觉测试用例](2024年10月14日/Automatically_Generating_Visual_Hallucination_Test_Cases_for_Multimodal_Large_Language_Models.md)

- [AutoTurb: Using Large Language Models for Automatic Algebraic Model Discovery of Turbulence Closure](2024年10月14日/AutoTurb_Using_Large_Language_Models_for_Automatic_Algebraic_Model_Discovery_of_Turbulence_Closure.md)

    - [翻译: AutoTurb：借助大型语言模型，自动探索湍流闭包的代数模型](2024年10月14日/AutoTurb_Using_Large_Language_Models_for_Automatic_Algebraic_Model_Discovery_of_Turbulence_Closure.md)

- [Balancing Continuous Pre-Training and Instruction Fine-Tuning: Optimizing Instruction-Following in LLMs](2024年10月14日/Balancing_Continuous_Pre-Training_and_Instruction_Fine-Tuning_Optimizing_Instruction-Following_in_LLMs.md)

    - [翻译: 在 LLM 中，如何平衡连续预训练与指令微调，以优化指令跟随能力，是一个关键课题。](2024年10月14日/Balancing_Continuous_Pre-Training_and_Instruction_Fine-Tuning_Optimizing_Instruction-Following_in_LLMs.md)

- [Beyond-RAG: Question Identification and Answer Generation in Real-Time Conversations](2024年10月14日/Beyond-RAG_Question_Identification_and_Answer_Generation_in_Real-Time_Conversations.md)

    - [翻译: 超越RAG：实时对话中的问题识别与答案生成](2024年10月14日/Beyond-RAG_Question_Identification_and_Answer_Generation_in_Real-Time_Conversations.md)

- [Both Ears Wide Open: Towards Language-Driven Spatial Audio Generation](2024年10月14日/Both_Ears_Wide_Open_Towards_Language-Driven_Spatial_Audio_Generation.md)

    - [翻译: 双耳全开：探索语言驱动的空间音频生成](2024年10月14日/Both_Ears_Wide_Open_Towards_Language-Driven_Spatial_Audio_Generation.md)

- [Can Structured Data Reduce Epistemic Uncertainty?](2024年10月14日/Can_Structured_Data_Reduce_Epistemic_Uncertainty.md)

    - [翻译: 结构化数据能否降低认知不确定性？](2024年10月14日/Can_Structured_Data_Reduce_Epistemic_Uncertainty.md)

- [CoMAT: Chain of Mathematically Annotated Thought Improves Mathematical Reasoning](2024年10月14日/CoMAT_Chain_of_Mathematically_Annotated_Thought_Improves_Mathematical_Reasoning.md)

    - [翻译: CoMAT：通过链式数学思维注释，提升数学推理能力](2024年10月14日/CoMAT_Chain_of_Mathematically_Annotated_Thought_Improves_Mathematical_Reasoning.md)

- [Cultural Fidelity in Large-Language Models: An Evaluation of Online Language Resources as a Driver of Model Performance in Value Representation](2024年10月14日/Cultural_Fidelity_in_Large-Language_Models_An_Evaluation_of_Online_Language_Resources_as_a_Driver_of_Model_Performance_in_Value_Representation.md)

    - [翻译: 大型语言模型中的文化保真度：探讨在线语言资源如何影响模型在价值表示方面的性能。](2024年10月14日/Cultural_Fidelity_in_Large-Language_Models_An_Evaluation_of_Online_Language_Resources_as_a_Driver_of_Model_Performance_in_Value_Representation.md)

- [Denial-of-Service Poisoning Attacks against Large Language Models](2024年10月14日/Denial-of-Service_Poisoning_Attacks_against_Large_Language_Models.md)

    - [翻译: 大型语言模型遭遇拒绝服务中毒攻击](2024年10月14日/Denial-of-Service_Poisoning_Attacks_against_Large_Language_Models.md)

- [Depth Any Video with Scalable Synthetic Data](2024年10月14日/Depth_Any_Video_with_Scalable_Synthetic_Data.md)

    - [翻译: 用可扩展的合成数据实现任意视频深度](2024年10月14日/Depth_Any_Video_with_Scalable_Synthetic_Data.md)

- [DuoAttention: Efficient Long-Context LLM Inference with Retrieval and Streaming Heads](2024年10月14日/DuoAttention_Efficient_Long-Context_LLM_Inference_with_Retrieval_and_Streaming_Heads.md)

    - [翻译: DuoAttention：结合检索与流式处理，实现长上下文 LLM 推理的高效能](2024年10月14日/DuoAttention_Efficient_Long-Context_LLM_Inference_with_Retrieval_and_Streaming_Heads.md)

- [Efficiently Democratizing Medical LLMs for 50 Languages via a Mixture of Language Family Experts](2024年10月14日/Efficiently_Democratizing_Medical_LLMs_for_50_Languages_via_a_Mixture_of_Language_Family_Experts.md)

    - [翻译: 借助语言家族专家的混合策略，我们高效地将医学大型语言模型扩展至50种语言，实现真正的语言民主化。](2024年10月14日/Efficiently_Democratizing_Medical_LLMs_for_50_Languages_via_a_Mixture_of_Language_Family_Experts.md)

- [Effi-Code: Unleashing Code Efficiency in Language Models](2024年10月14日/Effi-Code_Unleashing_Code_Efficiency_in_Language_Models.md)

    - [翻译: Effi-Code：激发语言模型中的代码效率](2024年10月14日/Effi-Code_Unleashing_Code_Efficiency_in_Language_Models.md)

- [Empowering Users in Digital Privacy Management through Interactive LLM-Based Agents](2024年10月14日/Empowering_Users_in_Digital_Privacy_Management_through_Interactive_LLM-Based_Agents.md)

    - [翻译: 借助 LLM 驱动的交互代理，提升用户在数字隐私管理中的掌控力](2024年10月14日/Empowering_Users_in_Digital_Privacy_Management_through_Interactive_LLM-Based_Agents.md)

- [F2A: An Innovative Approach for Prompt Injection by Utilizing Feign Security Detection Agents](2024年10月14日/F2A_An_Innovative_Approach_for_Prompt_Injection_by_Utilizing_Feign_Security_Detection_Agents.md)

    - [翻译: F2A：通过伪装安全检测代理实现提示注入的创新策略](2024年10月14日/F2A_An_Innovative_Approach_for_Prompt_Injection_by_Utilizing_Feign_Security_Detection_Agents.md)

- [Fine-grained Abnormality Prompt Learning for Zero-shot Anomaly Detection](2024年10月14日/Fine-grained_Abnormality_Prompt_Learning_for_Zero-shot_Anomaly_Detection.md)

    - [翻译: 细粒度异常提示学习：零-shot异常检测的新方法](2024年10月14日/Fine-grained_Abnormality_Prompt_Learning_for_Zero-shot_Anomaly_Detection.md)

- [Focused ReAct: Improving ReAct through Reiterate and Early Stop](2024年10月14日/Focused_ReAct_Improving_ReAct_through_Reiterate_and_Early_Stop.md)

    - [翻译: 聚焦 ReAct：通过反复迭代与早期停止提升 ReAct 性能](2024年10月14日/Focused_ReAct_Improving_ReAct_through_Reiterate_and_Early_Stop.md)

- [ForgeryGPT: Multimodal Large Language Model For Explainable Image Forgery Detection and Localization](2024年10月14日/ForgeryGPT_Multimodal_Large_Language_Model_For_Explainable_Image_Forgery_Detection_and_Localization.md)

    - [翻译: ForgeryGPT：一款多模态大型语言模型，专为可解释的图像伪造检测与定位而生。](2024年10月14日/ForgeryGPT_Multimodal_Large_Language_Model_For_Explainable_Image_Forgery_Detection_and_Localization.md)

- [Free Video-LLM: Prompt-guided Visual Perception for Efficient Training-free Video LLMs](2024年10月14日/Free_Video-LLM_Prompt-guided_Visual_Perception_for_Efficient_Training-free_Video_LLMs.md)

    - [翻译: Free Video-LLM：通过提示引导的视觉感知，实现无需训练的高效视频语言模型](2024年10月14日/Free_Video-LLM_Prompt-guided_Visual_Perception_for_Efficient_Training-free_Video_LLMs.md)

- [Functional Flexibility in Generative AI Interfaces: Text Editing with LLMs through Conversations, Toolbars, and Prompts](2024年10月14日/Functional_Flexibility_in_Generative_AI_Interfaces_Text_Editing_with_LLMs_through_Conversations,_Toolbars,_and_Prompts.md)

    - [翻译: 生成式 AI 接口展现出的功能灵活性：通过对话、工具栏和提示，与 LLM 共同进行文本编辑。](2024年10月14日/Functional_Flexibility_in_Generative_AI_Interfaces_Text_Editing_with_LLMs_through_Conversations,_Toolbars,_and_Prompts.md)

- [FunnelRAG: A Coarse-to-Fine Progressive Retrieval Paradigm for RAG](2024年10月14日/FunnelRAG_A_Coarse-to-Fine_Progressive_Retrieval_Paradigm_for_RAG.md)

    - [翻译: FunnelRAG：一种从粗到细的渐进式 RAG 检索方法](2024年10月14日/FunnelRAG_A_Coarse-to-Fine_Progressive_Retrieval_Paradigm_for_RAG.md)

- [Graph of Records: Boosting Retrieval Augmented Generation for Long-context Summarization with Graphs](2024年10月14日/Graph_of_Records_Boosting_Retrieval_Augmented_Generation_for_Long-context_Summarization_with_Graphs.md)

    - [翻译: 记录图：通过图增强检索生成，助力长上下文摘要的提升](2024年10月14日/Graph_of_Records_Boosting_Retrieval_Augmented_Generation_for_Long-context_Summarization_with_Graphs.md)

- [HR-Agent: A Task-Oriented Dialogue (TOD) LLM Agent Tailored for HR Applications](2024年10月14日/HR-Agent_A_Task-Oriented_Dialogue_(TOD)_LLM_Agent_Tailored_for_HR_Applications.md)

    - [翻译: HR-Agent：专为 HR 应用打造的任务导向对话 LLM 代理](2024年10月14日/HR-Agent_A_Task-Oriented_Dialogue_(TOD)_LLM_Agent_Tailored_for_HR_Applications.md)

- [Improve Meta-learning for Few-Shot Text Classification with All You Can Acquire from the Tasks](2024年10月14日/Improve_Meta-learning_for_Few-Shot_Text_Classification_with_All_You_Can_Acquire_from_the_Tasks.md)

    - [翻译: 利用任务中的所有可用信息，提升少样本文本分类的元学习效果](2024年10月14日/Improve_Meta-learning_for_Few-Shot_Text_Classification_with_All_You_Can_Acquire_from_the_Tasks.md)

- [Innovative Thinking, Infinite Humor: Humor Research of Large Language Models through Structured Thought Leaps](2024年10月14日/Innovative_Thinking,_Infinite_Humor_Humor_Research_of_Large_Language_Models_through_Structured_Thought_Leaps.md)

    - [翻译: 创新思维，幽默无限：通过结构化思维跳跃探索大语言模型的幽默研究](2024年10月14日/Innovative_Thinking,_Infinite_Humor_Humor_Research_of_Large_Language_Models_through_Structured_Thought_Leaps.md)

- [Is Parameter Collision Hindering Continual Learning in LLMs?](2024年10月14日/Is_Parameter_Collision_Hindering_Continual_Learning_in_LLMs.md)

    - [翻译: 参数碰撞是否成为 LLM 持续学习的绊脚石？](2024年10月14日/Is_Parameter_Collision_Hindering_Continual_Learning_in_LLMs.md)

- [KBLaM: Knowledge Base augmented Language Model](2024年10月14日/KBLaM_Knowledge_Base_augmented_Language_Model.md)

    - [翻译: KBLaM：知识库赋能的语言模型](2024年10月14日/KBLaM_Knowledge_Base_augmented_Language_Model.md)

- [Large Language Model-Enhanced Reinforcement Learning for Generic Bus Holding Control Strategies](2024年10月14日/Large_Language_Model-Enhanced_Reinforcement_Learning_for_Generic_Bus_Holding_Control_Strategies.md)

    - [翻译: 大型语言模型加持的强化学习，助力通用公交保持控制策略](2024年10月14日/Large_Language_Model-Enhanced_Reinforcement_Learning_for_Generic_Bus_Holding_Control_Strategies.md)

- [LG-CAV: Train Any Concept Activation Vector with Language Guidance](2024年10月14日/LG-CAV_Train_Any_Concept_Activation_Vector_with_Language_Guidance.md)

    - [翻译: LG-CAV：借助语言指导，轻松训练任意概念激活向量](2024年10月14日/LG-CAV_Train_Any_Concept_Activation_Vector_with_Language_Guidance.md)

- [Locking Down the Finetuned LLMs Safety](2024年10月14日/Locking_Down_the_Finetuned_LLMs_Safety.md)

    - [翻译: 确保微调后 LLM 的安全防护](2024年10月14日/Locking_Down_the_Finetuned_LLMs_Safety.md)

- [LoLCATs: On Low-Rank Linearizing of Large Language Models](2024年10月14日/LoLCATs_On_Low-Rank_Linearizing_of_Large_Language_Models.md)

    - [翻译: LoLCATs：探索大型语言模型的低秩线性化](2024年10月14日/LoLCATs_On_Low-Rank_Linearizing_of_Large_Language_Models.md)

- [LongMemEval: Benchmarking Chat Assistants on Long-Term Interactive Memory](2024年10月14日/LongMemEval_Benchmarking_Chat_Assistants_on_Long-Term_Interactive_Memory.md)

    - [翻译: LongMemEval：评估聊天助手在长期交互记忆中的表现](2024年10月14日/LongMemEval_Benchmarking_Chat_Assistants_on_Long-Term_Interactive_Memory.md)

- [MEGA-Bench: Scaling Multimodal Evaluation to over 500 Real-World Tasks](2024年10月14日/MEGA-Bench_Scaling_Multimodal_Evaluation_to_over_500_Real-World_Tasks.md)

    - [翻译: MEGA-Bench：将多模态评估扩展至 500 多个现实任务](2024年10月14日/MEGA-Bench_Scaling_Multimodal_Evaluation_to_over_500_Real-World_Tasks.md)

- [MentalGLM Series: Explainable Large Language Models for Mental Health Analysis on Chinese Social Media](2024年10月14日/MentalGLM_Series_Explainable_Large_Language_Models_for_Mental_Health_Analysis_on_Chinese_Social_Media.md)

    - [翻译: MentalGLM 系列：专为中国社交媒体心理健康分析设计的可解释大型语言模型](2024年10月14日/MentalGLM_Series_Explainable_Large_Language_Models_for_Mental_Health_Analysis_on_Chinese_Social_Media.md)

- [Minimum Tuning to Unlock Long Output from LLMs with High Quality Data as the Key](2024年10月14日/Minimum_Tuning_to_Unlock_Long_Output_from_LLMs_with_High_Quality_Data_as_the_Key.md)

    - [翻译: 通过最小调整，以高质量数据为关键，解锁 LLM 的长输出能力](2024年10月14日/Minimum_Tuning_to_Unlock_Long_Output_from_LLMs_with_High_Quality_Data_as_the_Key.md)

- [MMAR: Towards Lossless Multi-Modal Auto-Regressive Prababilistic Modeling](2024年10月14日/MMAR_Towards_Lossless_Multi-Modal_Auto-Regressive_Prababilistic_Modeling.md)

    - [翻译: MMAR：探索无损多模态自回归概率建模的新领域](2024年10月14日/MMAR_Towards_Lossless_Multi-Modal_Auto-Regressive_Prababilistic_Modeling.md)

- [MMIE: Massive Multimodal Interleaved Comprehension Benchmark for Large Vision-Language Models](2024年10月14日/MMIE_Massive_Multimodal_Interleaved_Comprehension_Benchmark_for_Large_Vision-Language_Models.md)

    - [翻译: MMIE：大型视觉-语言模型的大规模多模态交错理解基准](2024年10月14日/MMIE_Massive_Multimodal_Interleaved_Comprehension_Benchmark_for_Large_Vision-Language_Models.md)

- [Model-Based Differentially Private Knowledge Transfer for Large Language Models](2024年10月14日/Model-Based_Differentially_Private_Knowledge_Transfer_for_Large_Language_Models.md)

    - [翻译: 基于模型的差分隐私技术助力大型语言模型的知识迁移](2024年10月14日/Model-Based_Differentially_Private_Knowledge_Transfer_for_Large_Language_Models.md)

- [MoTE: Reconciling Generalization with Specialization for Visual-Language to Video Knowledge Transfer](2024年10月14日/MoTE_Reconciling_Generalization_with_Specialization_for_Visual-Language_to_Video_Knowledge_Transfer.md)

    - [翻译: MoTE：在视觉-语言到视频知识转移中，平衡泛化与专业化](2024年10月14日/MoTE_Reconciling_Generalization_with_Specialization_for_Visual-Language_to_Video_Knowledge_Transfer.md)

- [Parenting: Optimizing Knowledge Selection of Retrieval-Augmented Language Models with Parameter Decoupling and Tailored Tuning](2024年10月14日/Parenting_Optimizing_Knowledge_Selection_of_Retrieval-Augmented_Language_Models_with_Parameter_Decoupling_and_Tailored_Tuning.md)

    - [翻译: 育儿之道：通过参数解耦与定制调优，优化检索增强语言模型的知识选择](2024年10月14日/Parenting_Optimizing_Knowledge_Selection_of_Retrieval-Augmented_Language_Models_with_Parameter_Decoupling_and_Tailored_Tuning.md)

- [QUITE: Quantifying Uncertainty in Natural Language Text in Bayesian Reasoning Scenarios](2024年10月14日/QUITE_Quantifying_Uncertainty_in_Natural_Language_Text_in_Bayesian_Reasoning_Scenarios.md)

    - [翻译: QUITE：在贝叶斯推理背景下，精准量化自然语言文本的不确定性](2024年10月14日/QUITE_Quantifying_Uncertainty_in_Natural_Language_Text_in_Bayesian_Reasoning_Scenarios.md)

- [Saliency Guided Optimization of Diffusion Latents](2024年10月14日/Saliency_Guided_Optimization_of_Diffusion_Latents.md)

    - [翻译: 显著性引导的扩散潜在优化](2024年10月14日/Saliency_Guided_Optimization_of_Diffusion_Latents.md)

- [SANA: Efficient High-Resolution Image Synthesis with Linear Diffusion Transformers](2024年10月14日/SANA_Efficient_High-Resolution_Image_Synthesis_with_Linear_Diffusion_Transformers.md)

    - [翻译: SANA：通过线性扩散变换器，实现高效的高分辨率图像合成](2024年10月14日/SANA_Efficient_High-Resolution_Image_Synthesis_with_Linear_Diffusion_Transformers.md)

- [SeedLM: Compressing LLM Weights into Seeds of Pseudo-Random Generators](2024年10月14日/SeedLM_Compressing_LLM_Weights_into_Seeds_of_Pseudo-Random_Generators.md)

    - [翻译: SeedLM：将 LLM 权重压缩为伪随机生成器的种子](2024年10月14日/SeedLM_Compressing_LLM_Weights_into_Seeds_of_Pseudo-Random_Generators.md)

- [SensorBench: Benchmarking LLMs in Coding-Based Sensor Processing](2024年10月14日/SensorBench_Benchmarking_LLMs_in_Coding-Based_Sensor_Processing.md)

    - [翻译: SensorBench：为基于编码的传感器处理中的 LLM 提供基准测试](2024年10月14日/SensorBench_Benchmarking_LLMs_in_Coding-Based_Sensor_Processing.md)

- [SensorLLM: Aligning Large Language Models with Motion Sensors for Human Activity Recognition](2024年10月14日/SensorLLM_Aligning_Large_Language_Models_with_Motion_Sensors_for_Human_Activity_Recognition.md)

    - [翻译: SensorLLM：融合大型语言模型与运动传感器，助力人类活动识别](2024年10月14日/SensorLLM_Aligning_Large_Language_Models_with_Motion_Sensors_for_Human_Activity_Recognition.md)

- [Simplifying, Stabilizing and Scaling Continuous-Time Consistency Models](2024年10月14日/Simplifying,_Stabilizing_and_Scaling_Continuous-Time_Consistency_Models.md)

    - [翻译: 精简、稳固并扩展连续时间一致性模型](2024年10月14日/Simplifying,_Stabilizing_and_Scaling_Continuous-Time_Consistency_Models.md)

- [Sitcom-Crafter: A Plot-Driven Human Motion Generation System in 3D Scenes](2024年10月14日/Sitcom-Crafter_A_Plot-Driven_Human_Motion_Generation_System_in_3D_Scenes.md)

    - [翻译: Sitcom-Crafter：一款以情节驱动的3D场景中人类动作生成系统](2024年10月14日/Sitcom-Crafter_A_Plot-Driven_Human_Motion_Generation_System_in_3D_Scenes.md)

- [SLaNC: Static LayerNorm Calibration](2024年10月14日/SLaNC_Static_LayerNorm_Calibration.md)

    - [翻译: SLaNC：静态层归一化校准](2024年10月14日/SLaNC_Static_LayerNorm_Calibration.md)

- [SplitLLM: Collaborative Inference of LLMs for Model Placement and Throughput Optimization](2024年10月14日/SplitLLM_Collaborative_Inference_of_LLMs_for_Model_Placement_and_Throughput_Optimization.md)

    - [翻译: SplitLLM：通过协作推理优化 LLM 的模型放置和吞吐量](2024年10月14日/SplitLLM_Collaborative_Inference_of_LLMs_for_Model_Placement_and_Throughput_Optimization.md)

- [Temperature-Centric Investigation of Speculative Decoding with Knowledge Distillation](2024年10月14日/Temperature-Centric_Investigation_of_Speculative_Decoding_with_Knowledge_Distillation.md)

    - [翻译: 聚焦温度，探究知识蒸馏下的推测解码](2024年10月14日/Temperature-Centric_Investigation_of_Speculative_Decoding_with_Knowledge_Distillation.md)

- [Test smells in LLM-Generated Unit Tests](2024年10月14日/Test_smells_in_LLM-Generated_Unit_Tests.md)

    - [翻译: LLM 生成单元测试中的测试异味](2024年10月14日/Test_smells_in_LLM-Generated_Unit_Tests.md)

- [Thinking LLMs: General Instruction Following with Thought Generation](2024年10月14日/Thinking_LLMs_General_Instruction_Following_with_Thought_Generation.md)

    - [翻译: 思考型 LLM：通过思维生成实现通用指令跟随](2024年10月14日/Thinking_LLMs_General_Instruction_Following_with_Thought_Generation.md)

- [TMGBench: A Systematic Game Benchmark for Evaluating Strategic Reasoning Abilities of LLMs](2024年10月14日/TMGBench_A_Systematic_Game_Benchmark_for_Evaluating_Strategic_Reasoning_Abilities_of_LLMs.md)

    - [翻译: TMGBench：一款系统性游戏基准，专为评估 LLMs 的战略推理能力而设计](2024年10月14日/TMGBench_A_Systematic_Game_Benchmark_for_Evaluating_Strategic_Reasoning_Abilities_of_LLMs.md)

- [Towards LLM-guided Efficient and Interpretable Multi-linear Tensor Network Rank Selection](2024年10月14日/Towards_LLM-guided_Efficient_and_Interpretable_Multi-linear_Tensor_Network_Rank_Selection.md)

    - [翻译: 迈向由 LLM 引导的高效且可解释的多线性张量网络秩选择](2024年10月14日/Towards_LLM-guided_Efficient_and_Interpretable_Multi-linear_Tensor_Network_Rank_Selection.md)

- [Use Random Selection for Now: Investigation of Few-Shot Selection Strategies in LLM-based Text Augmentation for Classification](2024年10月14日/Use_Random_Selection_for_Now_Investigation_of_Few-Shot_Selection_Strategies_in_LLM-based_Text_Augmentation_for_Classification.md)

    - [翻译: 目前采用随机选择策略：探讨基于 LLM 的文本增强分类中少样本选择策略的影响](2024年10月14日/Use_Random_Selection_for_Now_Investigation_of_Few-Shot_Selection_Strategies_in_LLM-based_Text_Augmentation_for_Classification.md)

- [When Does Perceptual Alignment Benefit Vision Representations?](2024年10月14日/When_Does_Perceptual_Alignment_Benefit_Vision_Representations.md)

    - [翻译: 何时感知对齐能提升视觉表示的效果？](2024年10月14日/When_Does_Perceptual_Alignment_Benefit_Vision_Representations.md)

- [Will LLMs Replace the Encoder-Only Models in Temporal Relation Classification?](2024年10月14日/Will_LLMs_Replace_the_Encoder-Only_Models_in_Temporal_Relation_Classification.md)

    - [翻译: 大型语言模型（LLMs）是否将取代仅编码器模型，成为时间关系分类的新宠？](2024年10月14日/Will_LLMs_Replace_the_Encoder-Only_Models_in_Temporal_Relation_Classification.md)

- [Words to Wheels: Vision-Based Autonomous Driving Understanding Human Language Instructions Using Foundation Models](2024年10月14日/Words_to_Wheels_Vision-Based_Autonomous_Driving_Understanding_Human_Language_Instructions_Using_Foundation_Models.md)

    - [翻译: 从文字到车轮：基于视觉的自动驾驶系统，利用基础模型理解人类语言指令](2024年10月14日/Words_to_Wheels_Vision-Based_Autonomous_Driving_Understanding_Human_Language_Instructions_Using_Foundation_Models.md)

- [Your Mixture-of-Experts LLM Is Secretly an Embedding Model For Free](2024年10月14日/Your_Mixture-of-Experts_LLM_Is_Secretly_an_Embedding_Model_For_Free.md)

    - [翻译: 你的专家混合型大型语言模型，其实是个免费的嵌入模型哦！](2024年10月14日/Your_Mixture-of-Experts_LLM_Is_Secretly_an_Embedding_Model_For_Free.md)

- [Yuan: Research on the Concept of Digital World Analogue Scientific Infrastructure and Science Popularization Communication Based on Suzhou Gardens Pattern](2024年10月14日/Yuan_Research_on_the_Concept_of_Digital_World_Analogue_Scientific_Infrastructure_and_Science_Popularization_Communication_Based_on_Suzhou_Gardens_Pattern.md)

    - [翻译: 探索苏州园林模式下的数字世界模拟科学基础设施与科普传播新概念](2024年10月14日/Yuan_Research_on_the_Concept_of_Digital_World_Analogue_Scientific_Infrastructure_and_Science_Popularization_Communication_Based_on_Suzhou_Gardens_Pattern.md)

2024年10月13日

- [Adaptive Reasoning and Acting in Medical Language Agents](2024年10月13日/Adaptive_Reasoning_and_Acting_in_Medical_Language_Agents.md)

    - [翻译: 医疗语言代理中的适应性推理与行动](2024年10月13日/Adaptive_Reasoning_and_Acting_in_Medical_Language_Agents.md)

- [A Multi-LLM Orchestration Engine for Personalized, Context-Rich Assistance](2024年10月13日/A_Multi-LLM_Orchestration_Engine_for_Personalized,_Context-Rich_Assistance.md)

    - [翻译: 个性化、上下文感知辅助的多大型语言模型编排引擎](2024年10月13日/A_Multi-LLM_Orchestration_Engine_for_Personalized,_Context-Rich_Assistance.md)

- [Beyond Graphs: Can Large Language Models Comprehend Hypergraphs?](2024年10月13日/Beyond_Graphs_Can_Large_Language_Models_Comprehend_Hypergraphs.md)

    - [翻译: 大型语言模型能否超越图表，理解超图的奥秘？](2024年10月13日/Beyond_Graphs_Can_Large_Language_Models_Comprehend_Hypergraphs.md)

- [BiDoRA: Bi-level Optimization-Based Weight-Decomposed Low-Rank Adaptation](2024年10月13日/BiDoRA_Bi-level_Optimization-Based_Weight-Decomposed_Low-Rank_Adaptation.md)

    - [翻译: BiDoRA：双层优化驱动的权重分解低秩适应](2024年10月13日/BiDoRA_Bi-level_Optimization-Based_Weight-Decomposed_Low-Rank_Adaptation.md)

- [BlackDAN: A Black-Box Multi-Objective Approach for Effective and Contextual Jailbreaking of Large Language Models](2024年10月13日/BlackDAN_A_Black-Box_Multi-Objective_Approach_for_Effective_and_Contextual_Jailbreaking_of_Large_Language_Models.md)

    - [翻译: BlackDAN：一种黑盒多目标策略，专为有效且情境化的破解大型语言模型而设计。](2024年10月13日/BlackDAN_A_Black-Box_Multi-Objective_Approach_for_Effective_and_Contextual_Jailbreaking_of_Large_Language_Models.md)

- [Can Large Language Models Generate Geospatial Code?](2024年10月13日/Can_Large_Language_Models_Generate_Geospatial_Code.md)

    - [翻译: 大型语言模型能否编写地理空间代码？](2024年10月13日/Can_Large_Language_Models_Generate_Geospatial_Code.md)

- [Can We Predict Performance of Large Models across Vision-Language Tasks?](2024年10月13日/Can_We_Predict_Performance_of_Large_Models_across_Vision-Language_Tasks.md)

    - [翻译: 大型模型在视觉-语言任务中的表现，我们能否精准预测？](2024年10月13日/Can_We_Predict_Performance_of_Large_Models_across_Vision-Language_Tasks.md)

- [Dynamic and Textual Graph Generation Via Large-Scale LLM-based Agent Simulation](2024年10月13日/Dynamic_and_Textual_Graph_Generation_Via_Large-Scale_LLM-based_Agent_Simulation.md)

    - [翻译: 通过大规模 LLM 代理模拟实现动态与文本图生成](2024年10月13日/Dynamic_and_Textual_Graph_Generation_Via_Large-Scale_LLM-based_Agent_Simulation.md)

- [ECIS-VQG: Generation of Entity-centric Information-seeking Questions from Videos](2024年10月13日/ECIS-VQG_Generation_of_Entity-centric_Information-seeking_Questions_from_Videos.md)

    - [翻译: ECIS-VQG：视频中实体导向的信息探索问题生成](2024年10月13日/ECIS-VQG_Generation_of_Entity-centric_Information-seeking_Questions_from_Videos.md)

- [Empowering Dysarthric Speech: Leveraging Advanced LLMs for Accurate Speech Correction and Multimodal Emotion Analysis](2024年10月13日/Empowering_Dysarthric_Speech_Leveraging_Advanced_LLMs_for_Accurate_Speech_Correction_and_Multimodal_Emotion_Analysis.md)

    - [翻译: 借助先进的大型语言模型（LLM），我们不仅能精准校正构音障碍者的语音，还能进行多模态情感分析，赋予这些语音新的生命力。](2024年10月13日/Empowering_Dysarthric_Speech_Leveraging_Advanced_LLMs_for_Accurate_Speech_Correction_and_Multimodal_Emotion_Analysis.md)

- [How to Leverage Demonstration Data in Alignment for Large Language Model? A Self-Imitation Learning Perspective](2024年10月13日/How_to_Leverage_Demonstration_Data_in_Alignment_for_Large_Language_Model_A_Self-Imitation_Learning_Perspective.md)

    - [翻译: 如何在大语言模型对齐中巧妙利用演示数据？让我们从自我模仿学习的角度一探究竟。](2024年10月13日/How_to_Leverage_Demonstration_Data_in_Alignment_for_Large_Language_Model_A_Self-Imitation_Learning_Perspective.md)

- [IMAS: A Comprehensive Agentic Approach to Rural Healthcare Delivery](2024年10月13日/IMAS_A_Comprehensive_Agentic_Approach_to_Rural_Healthcare_Delivery.md)

    - [翻译: IMAS：一种全面代理方法，助力农村医疗保健服务](2024年10月13日/IMAS_A_Comprehensive_Agentic_Approach_to_Rural_Healthcare_Delivery.md)

- [LOKI: A Comprehensive Synthetic Data Detection Benchmark using Large Multimodal Models](2024年10月13日/LOKI_A_Comprehensive_Synthetic_Data_Detection_Benchmark_using_Large_Multimodal_Models.md)

    - [翻译: LOKI：基于大型多模态模型的综合合成数据检测基准](2024年10月13日/LOKI_A_Comprehensive_Synthetic_Data_Detection_Benchmark_using_Large_Multimodal_Models.md)

- [M2M-Gen: A Multimodal Framework for Automated Background Music Generation in Japanese Manga Using Large Language Models](2024年10月13日/M2M-Gen_A_Multimodal_Framework_for_Automated_Background_Music_Generation_in_Japanese_Manga_Using_Large_Language_Models.md)

    - [翻译: M2M-Gen：一个利用大型语言模型自动为日本漫画生成背景音乐的多模态框架](2024年10月13日/M2M-Gen_A_Multimodal_Framework_for_Automated_Background_Music_Generation_in_Japanese_Manga_Using_Large_Language_Models.md)

- [MIRAGE: Multimodal Identification and Recognition of Annotations in Indian General Prescriptions](2024年10月13日/MIRAGE_Multimodal_Identification_and_Recognition_of_Annotations_in_Indian_General_Prescriptions.md)

    - [翻译: MIRAGE：印度通用处方中注释的多模态识别与识别系统](2024年10月13日/MIRAGE_Multimodal_Identification_and_Recognition_of_Annotations_in_Indian_General_Prescriptions.md)

- [MMCOMPOSITION: Revisiting the Compositionality of Pre-trained Vision-Language Models](2024年10月13日/MMCOMPOSITION_Revisiting_the_Compositionality_of_Pre-trained_Vision-Language_Models.md)

    - [翻译: MMCOMPOSITION：探索预训练视觉-语言模型的组合性](2024年10月13日/MMCOMPOSITION_Revisiting_the_Compositionality_of_Pre-trained_Vision-Language_Models.md)

- ['Quis custodiet ipsos custodes?' Who will watch the watchmen? On Detecting AI-generated peer-reviews](2024年10月13日/'Quis_custodiet_ipsos_custodes'_Who_will_watch_the_watchmen_On_Detecting_AI-generated_peer-reviews.md)

    - [翻译: “谁来监督监督者？” —— 探讨如何检测 AI 生成的同行评审](2024年10月13日/'Quis_custodiet_ipsos_custodes'_Who_will_watch_the_watchmen_On_Detecting_AI-generated_peer-reviews.md)

- [Retrieval Instead of Fine-tuning: A Retrieval-based Parameter Ensemble for Zero-shot Learning](2024年10月13日/Retrieval_Instead_of_Fine-tuning_A_Retrieval-based_Parameter_Ensemble_for_Zero-shot_Learning.md)

    - [翻译: 用检索取代微调：探索基于检索的参数集成在零-shot 学习中的应用](2024年10月13日/Retrieval_Instead_of_Fine-tuning_A_Retrieval-based_Parameter_Ensemble_for_Zero-shot_Learning.md)

- [Targeted Vaccine: Safety Alignment for Large Language Models against Harmful Fine-Tuning via Layer-wise Perturbation](2024年10月13日/Targeted_Vaccine_Safety_Alignment_for_Large_Language_Models_against_Harmful_Fine-Tuning_via_Layer-wise_Perturbation.md)

    - [翻译: 目标疫苗：通过逐层扰动保护大型语言模型免受有害微调的影响，确保安全对齐](2024年10月13日/Targeted_Vaccine_Safety_Alignment_for_Large_Language_Models_against_Harmful_Fine-Tuning_via_Layer-wise_Perturbation.md)

- [Text4Seg: Reimagining Image Segmentation as Text Generation](2024年10月13日/Text4Seg_Reimagining_Image_Segmentation_as_Text_Generation.md)

    - [翻译: Text4Seg：重塑图像分割为文本生成](2024年10月13日/Text4Seg_Reimagining_Image_Segmentation_as_Text_Generation.md)

2024年10月12日

- [AERA Chat: An Interactive Platform for Automated Explainable Student Answer Assessment](2024年10月12日/AERA_Chat_An_Interactive_Platform_for_Automated_Explainable_Student_Answer_Assessment.md)

    - [翻译: AERA Chat：一个自动化且可解释的学生答案评估交互平台](2024年10月12日/AERA_Chat_An_Interactive_Platform_for_Automated_Explainable_Student_Answer_Assessment.md)

- [Agentic Information Retrieval](2024年10月12日/Agentic_Information_Retrieval.md)

    - [翻译: 主动信息检索](2024年10月12日/Agentic_Information_Retrieval.md)

- [Are You Human? An Adversarial Benchmark to Expose LLMs](2024年10月12日/Are_You_Human_An_Adversarial_Benchmark_to_Expose_LLMs.md)

    - [翻译: “你是人类吗？”——一个对抗性基准，旨在揭示大型语言模型的真实面目。](2024年10月12日/Are_You_Human_An_Adversarial_Benchmark_to_Expose_LLMs.md)

- [Boosting Deductive Reasoning with Step Signals In RLHF](2024年10月12日/Boosting_Deductive_Reasoning_with_Step_Signals_In_RLHF.md)

    - [翻译: 通过步骤信号提升 RLHF 中的演绎推理能力](2024年10月12日/Boosting_Deductive_Reasoning_with_Step_Signals_In_RLHF.md)

- [CAMPHOR: Collaborative Agents for Multi-input Planning and High-Order Reasoning On Device](2024年10月12日/CAMPHOR_Collaborative_Agents_for_Multi-input_Planning_and_High-Order_Reasoning_On_Device.md)

    - [翻译: CAMPHOR：设备上多输入规划与高阶推理的协作代理](2024年10月12日/CAMPHOR_Collaborative_Agents_for_Multi-input_Planning_and_High-Order_Reasoning_On_Device.md)

- [CollabEdit: Towards Non-destructive Collaborative Knowledge Editing](2024年10月12日/CollabEdit_Towards_Non-destructive_Collaborative_Knowledge_Editing.md)

    - [翻译: CollabEdit：开启非破坏性协作知识编辑的新篇章](2024年10月12日/CollabEdit_Towards_Non-destructive_Collaborative_Knowledge_Editing.md)

- [COrAL: Order-Agnostic Language Modeling for Efficient Iterative Refinement](2024年10月12日/COrAL_Order-Agnostic_Language_Modeling_for_Efficient_Iterative_Refinement.md)

    - [翻译: COrAL：一种高效迭代细化的无序语言建模方法](2024年10月12日/COrAL_Order-Agnostic_Language_Modeling_for_Efficient_Iterative_Refinement.md)

- [DRCap: Decoding CLAP Latents with Retrieval-augmented Generation for Zero-shot Audio Captioning](2024年10月12日/DRCap_Decoding_CLAP_Latents_with_Retrieval-augmented_Generation_for_Zero-shot_Audio_Captioning.md)

    - [翻译: DRCap：通过检索增强生成技术，解码 CLAP 潜在变量，实现零-shot 音频字幕生成。](2024年10月12日/DRCap_Decoding_CLAP_Latents_with_Retrieval-augmented_Generation_for_Zero-shot_Audio_Captioning.md)

- [Enhanced Electronic Health Records Text Summarization Using Large Language Models](2024年10月12日/Enhanced_Electronic_Health_Records_Text_Summarization_Using_Large_Language_Models.md)

    - [翻译: 借助大型语言模型，电子健康记录的文本摘要能力得以提升。](2024年10月12日/Enhanced_Electronic_Health_Records_Text_Summarization_Using_Large_Language_Models.md)

- [Exploring Demonstration Retrievers in RAG for Coding Tasks: Yeas and Nays!](2024年10月12日/Exploring_Demonstration_Retrievers_in_RAG_for_Coding_Tasks_Yeas_and_Nays!.md)

    - [翻译: RAG 中编码任务演示检索器的探索：利弊分析！](2024年10月12日/Exploring_Demonstration_Retrievers_in_RAG_for_Coding_Tasks_Yeas_and_Nays!.md)

- [FlatQuant: Flatness Matters for LLM Quantization](2024年10月12日/FlatQuant_Flatness_Matters_for_LLM_Quantization.md)

    - [翻译: FlatQuant：平坦性在 LLM 量化中举足轻重](2024年10月12日/FlatQuant_Flatness_Matters_for_LLM_Quantization.md)

- [Honest AI: Fine-Tuning "Small" Language Models to Say "I Don't Know", and Reducing Hallucination in RAG](2024年10月12日/Honest_AI_Fine-Tuning_Small_Language_Models_to_Say_I_Don't_Know,_and_Reducing_Hallucination_in_RAG.md)

    - [翻译: 让AI更诚实：通过微调小型语言模型，使其能说“我不知道”，并减少RAG中的幻觉现象。](2024年10月12日/Honest_AI_Fine-Tuning_Small_Language_Models_to_Say_I_Don't_Know,_and_Reducing_Hallucination_in_RAG.md)

- [LINKED: Eliciting, Filtering and Integrating Knowledge in Large Language Model for Commonsense Reasoning](2024年10月12日/LINKED_Eliciting,_Filtering_and_Integrating_Knowledge_in_Large_Language_Model_for_Commonsense_Reasoning.md)

    - [翻译: 在大型语言模型中，如何巧妙地引出、筛选并整合知识，以提升常识推理能力，是我们探讨的核心。](2024年10月12日/LINKED_Eliciting,_Filtering_and_Integrating_Knowledge_in_Large_Language_Model_for_Commonsense_Reasoning.md)

- [LLM-SmartAudit: Advanced Smart Contract Vulnerability Detection](2024年10月12日/LLM-SmartAudit_Advanced_Smart_Contract_Vulnerability_Detection.md)

    - [翻译: LLM-SmartAudit：智能合约漏洞检测的尖端技术](2024年10月12日/LLM-SmartAudit_Advanced_Smart_Contract_Vulnerability_Detection.md)

- [MIRAGE: Evaluating and Explaining Inductive Reasoning Process in Language Models](2024年10月12日/MIRAGE_Evaluating_and_Explaining_Inductive_Reasoning_Process_in_Language_Models.md)

    - [翻译: MIRAGE：探索与揭示语言模型中的归纳推理奥秘](2024年10月12日/MIRAGE_Evaluating_and_Explaining_Inductive_Reasoning_Process_in_Language_Models.md)

- [MMAD: The First-Ever Comprehensive Benchmark for Multimodal Large Language Models in Industrial Anomaly Detection](2024年10月12日/MMAD_The_First-Ever_Comprehensive_Benchmark_for_Multimodal_Large_Language_Models_in_Industrial_Anomaly_Detection.md)

    - [翻译: MMAD：工业异常检测领域首个多模态大型语言模型的全面基准](2024年10月12日/MMAD_The_First-Ever_Comprehensive_Benchmark_for_Multimodal_Large_Language_Models_in_Industrial_Anomaly_Detection.md)

- [MoIN: Mixture of Introvert Experts to Upcycle an LLM](2024年10月12日/MoIN_Mixture_of_Introvert_Experts_to_Upcycle_an_LLM.md)

    - [翻译: MoIN：内向专家混合体，助力 LLM 升级](2024年10月12日/MoIN_Mixture_of_Introvert_Experts_to_Upcycle_an_LLM.md)

- [MTL-LoRA: Low-Rank Adaptation for Multi-Task Learning](2024年10月12日/MTL-LoRA_Low-Rank_Adaptation_for_Multi-Task_Learning.md)

    - [翻译: MTL-LoRA：多任务学习的低秩适应](2024年10月12日/MTL-LoRA_Low-Rank_Adaptation_for_Multi-Task_Learning.md)

- [Quebec Automobile Insurance Question-Answering With Retrieval-Augmented Generation](2024年10月12日/Quebec_Automobile_Insurance_Question-Answering_With_Retrieval-Augmented_Generation.md)

    - [翻译: 魁北克汽车保险问答系统：检索增强生成技术应用](2024年10月12日/Quebec_Automobile_Insurance_Question-Answering_With_Retrieval-Augmented_Generation.md)

- [Reconstructive Visual Instruction Tuning](2024年10月12日/Reconstructive_Visual_Instruction_Tuning.md)

    - [翻译: 视觉指令的重构调整](2024年10月12日/Reconstructive_Visual_Instruction_Tuning.md)

- [Skipping Computations in Multimodal LLMs](2024年10月12日/Skipping_Computations_in_Multimodal_LLMs.md)

    - [翻译: 多模态 LLM 中的计算跳跃](2024年10月12日/Skipping_Computations_in_Multimodal_LLMs.md)

- [SLiM: One-shot Quantized Sparse Plus Low-rank Approximation of LLMs](2024年10月12日/SLiM_One-shot_Quantized_Sparse_Plus_Low-rank_Approximation_of_LLMs.md)

    - [翻译: SLiM：一次量化稀疏加低秩近似 LLM](2024年10月12日/SLiM_One-shot_Quantized_Sparse_Plus_Low-rank_Approximation_of_LLMs.md)

- [Synthetic Knowledge Ingestion: Towards Knowledge Refinement and Injection for Enhancing Large Language Models](2024年10月12日/Synthetic_Knowledge_Ingestion_Towards_Knowledge_Refinement_and_Injection_for_Enhancing_Large_Language_Models.md)

    - [翻译: 合成知识摄取：通过知识精炼与注入，提升大型语言模型的能力](2024年10月12日/Synthetic_Knowledge_Ingestion_Towards_Knowledge_Refinement_and_Injection_for_Enhancing_Large_Language_Models.md)

- [The Future of Learning in the Age of Generative AI: Automated Question Generation and Assessment with Large Language Models](2024年10月12日/The_Future_of_Learning_in_the_Age_of_Generative_AI_Automated_Question_Generation_and_Assessment_with_Large_Language_Models.md)

    - [翻译: 在生成式 AI 时代，学习将迎来新变革：借助大型语言模型，实现自动问题生成与评估。](2024年10月12日/The_Future_of_Learning_in_the_Age_of_Generative_AI_Automated_Question_Generation_and_Assessment_with_Large_Language_Models.md)

- [Towards Efficient Visual-Language Alignment of the Q-Former for Visual Reasoning Tasks](2024年10月12日/Towards_Efficient_Visual-Language_Alignment_of_the_Q-Former_for_Visual_Reasoning_Tasks.md)

    - [翻译: 探索 Q-Former 在视觉推理任务中视觉与语言对齐的高效路径](2024年10月12日/Towards_Efficient_Visual-Language_Alignment_of_the_Q-Former_for_Visual_Reasoning_Tasks.md)

- [Training Dynamics of Transformers to Recognize Word Co-occurrence via Gradient Flow Analysis](2024年10月12日/Training_Dynamics_of_Transformers_to_Recognize_Word_Co-occurrence_via_Gradient_Flow_Analysis.md)

    - [翻译: 通过梯度流分析，揭示 Transformer 识别词共现的训练动态](2024年10月12日/Training_Dynamics_of_Transformers_to_Recognize_Word_Co-occurrence_via_Gradient_Flow_Analysis.md)

- [Two Heads Are Better Than One: A Multi-Agent System Has the Potential to Improve Scientific Idea Generation](2024年10月12日/Two_Heads_Are_Better_Than_One_A_Multi-Agent_System_Has_the_Potential_to_Improve_Scientific_Idea_Generation.md)

    - [翻译: 双脑协作，科学创意更上一层楼：多智能体系统助力创新思维](2024年10月12日/Two_Heads_Are_Better_Than_One_A_Multi-Agent_System_Has_the_Potential_to_Improve_Scientific_Idea_Generation.md)

2024年10月11日

- [ACER: Automatic Language Model Context Extension via Retrieval](2024年10月11日/ACER_Automatic_Language_Model_Context_Extension_via_Retrieval.md)

    - [翻译: ACER：利用检索技术自动扩展语言模型的上下文](2024年10月11日/ACER_Automatic_Language_Model_Context_Extension_via_Retrieval.md)

- [A Methodology for Evaluating RAG Systems: A Case Study On Configuration Dependency Validation](2024年10月11日/A_Methodology_for_Evaluating_RAG_Systems_A_Case_Study_On_Configuration_Dependency_Validation.md)

    - [翻译: RAG 系统评估方法论：配置依赖验证案例研究](2024年10月11日/A_Methodology_for_Evaluating_RAG_Systems_A_Case_Study_On_Configuration_Dependency_Validation.md)

- [A Social Context-aware Graph-based Multimodal Attentive Learning Framework for Disaster Content Classification during Emergencies](2024年10月11日/A_Social_Context-aware_Graph-based_Multimodal_Attentive_Learning_Framework_for_Disaster_Content_Classification_during_Emergencies.md)

    - [翻译: 一种基于社交上下文和图结构的多模态注意力学习框架，专为紧急情况下的灾难内容分类设计](2024年10月11日/A_Social_Context-aware_Graph-based_Multimodal_Attentive_Learning_Framework_for_Disaster_Content_Classification_during_Emergencies.md)

- [Audio Description Generation in the Era of LLMs and VLMs: A Review of Transferable Generative AI Technologies](2024年10月11日/Audio_Description_Generation_in_the_Era_of_LLMs_and_VLMs_A_Review_of_Transferable_Generative_AI_Technologies.md)

    - [翻译: 在 LLM 和 VLM 时代，音频描述生成：探索可转移的生成 AI 技术](2024年10月11日/Audio_Description_Generation_in_the_Era_of_LLMs_and_VLMs_A_Review_of_Transferable_Generative_AI_Technologies.md)

- [AutoPersuade: A Framework for Evaluating and Explaining Persuasive Arguments](2024年10月11日/AutoPersuade_A_Framework_for_Evaluating_and_Explaining_Persuasive_Arguments.md)

    - [翻译: AutoPersuade：一款评估与解释说服性论点的框架](2024年10月11日/AutoPersuade_A_Framework_for_Evaluating_and_Explaining_Persuasive_Arguments.md)

- [Enhancing Long Context Performance in LLMs Through Inner Loop Query Mechanism](2024年10月11日/Enhancing_Long_Context_Performance_in_LLMs_Through_Inner_Loop_Query_Mechanism.md)

    - [翻译: 借助内循环查询机制，提升 LLM 在长上下文中的表现](2024年10月11日/Enhancing_Long_Context_Performance_in_LLMs_Through_Inner_Loop_Query_Mechanism.md)

- [From N-grams to Pre-trained Multilingual Models For Language Identification](2024年10月11日/From_N-grams_to_Pre-trained_Multilingual_Models_For_Language_Identification.md)

    - [翻译: 从 N-grams 到预训练的多语言模型：语言识别的新篇章](2024年10月11日/From_N-grams_to_Pre-trained_Multilingual_Models_For_Language_Identification.md)

- [Hypothesis-only Biases in Large Language Model-Elicited Natural Language Inference](2024年10月11日/Hypothesis-only_Biases_in_Large_Language_Model-Elicited_Natural_Language_Inference.md)

    - [翻译: 大型语言模型在自然语言推理中仅依赖假设的偏差](2024年10月11日/Hypothesis-only_Biases_in_Large_Language_Model-Elicited_Natural_Language_Inference.md)

- [IGNN-Solver: A Graph Neural Solver for Implicit Graph Neural Networks](2024年10月11日/IGNN-Solver_A_Graph_Neural_Solver_for_Implicit_Graph_Neural_Networks.md)

    - [翻译: IGNN-Solver：专为隐式图神经网络设计的图神经求解器](2024年10月11日/IGNN-Solver_A_Graph_Neural_Solver_for_Implicit_Graph_Neural_Networks.md)

- [Investigating Human-Computer Interaction and Visual Comprehension in Text Generation Process of Natural Language Generation Models](2024年10月11日/Investigating_Human-Computer_Interaction_and_Visual_Comprehension_in_Text_Generation_Process_of_Natural_Language_Generation_Models.md)

    - [翻译: 探索人类与计算机交互及视觉理解在自然语言生成模型文本生成中的影响](2024年10月11日/Investigating_Human-Computer_Interaction_and_Visual_Comprehension_in_Text_Generation_Process_of_Natural_Language_Generation_Models.md)

- [JAILJUDGE: A Comprehensive Jailbreak Judge Benchmark with Multi-Agent Enhanced Explanation Evaluation Framework](2024年10月11日/JAILJUDGE_A_Comprehensive_Jailbreak_Judge_Benchmark_with_Multi-Agent_Enhanced_Explanation_Evaluation_Framework.md)

    - [翻译: JAILJUDGE：一个综合的越狱判断基准，结合了多代理增强的解释评估框架，旨在全面评估越狱行为。](2024年10月11日/JAILJUDGE_A_Comprehensive_Jailbreak_Judge_Benchmark_with_Multi-Agent_Enhanced_Explanation_Evaluation_Framework.md)

- [Language-Model-Assisted Bi-Level Programming for Reward Learning from Internet Videos](2024年10月11日/Language-Model-Assisted_Bi-Level_Programming_for_Reward_Learning_from_Internet_Videos.md)

    - [翻译: 借助语言模型的双层编程，从网络视频中学习奖励机制](2024年10月11日/Language-Model-Assisted_Bi-Level_Programming_for_Reward_Learning_from_Internet_Videos.md)

- [Large Language Models for Medical OSCE Assessment: A Novel Approach to Transcript Analysis](2024年10月11日/Large_Language_Models_for_Medical_OSCE_Assessment_A_Novel_Approach_to_Transcript_Analysis.md)

    - [翻译: 医学 OSCE 评估中的大型语言模型：转录分析的创新之道](2024年10月11日/Large_Language_Models_for_Medical_OSCE_Assessment_A_Novel_Approach_to_Transcript_Analysis.md)

- [Losing dimensions: Geometric memorization in generative diffusion](2024年10月11日/Losing_dimensions_Geometric_memorization_in_generative_diffusion.md)

    - [翻译: 维度迷失：生成扩散中的几何记忆](2024年10月11日/Losing_dimensions_Geometric_memorization_in_generative_diffusion.md)

- [NoVo: Norm Voting off Hallucinations with Attention Heads in Large Language Models](2024年10月11日/NoVo_Norm_Voting_off_Hallucinations_with_Attention_Heads_in_Large_Language_Models.md)

    - [翻译: NoVo：通过 LLM 中的注意力头规范投票，消除幻觉](2024年10月11日/NoVo_Norm_Voting_off_Hallucinations_with_Attention_Heads_in_Large_Language_Models.md)

- [PILLAR: an AI-Powered Privacy Threat Modeling Tool](2024年10月11日/PILLAR_an_AI-Powered_Privacy_Threat_Modeling_Tool.md)

    - [翻译: PILLAR：一款由 AI 驱动的隐私威胁建模利器](2024年10月11日/PILLAR_an_AI-Powered_Privacy_Threat_Modeling_Tool.md)

- [Preferential Normalizing Flows](2024年10月11日/Preferential_Normalizing_Flows.md)

    - [翻译: 偏好归一化流](2024年10月11日/Preferential_Normalizing_Flows.md)

- [QEFT: Quantization for Efficient Fine-Tuning of LLMs](2024年10月11日/QEFT_Quantization_for_Efficient_Fine-Tuning_of_LLMs.md)

    - [翻译: QEFT：通过量化实现 LLM 的高效微调](2024年10月11日/QEFT_Quantization_for_Efficient_Fine-Tuning_of_LLMs.md)

- [RePD: Defending Jailbreak Attack through a Retrieval-based Prompt Decomposition Process](2024年10月11日/RePD_Defending_Jailbreak_Attack_through_a_Retrieval-based_Prompt_Decomposition_Process.md)

    - [翻译: RePD：利用基于检索的提示分解技术，有效抵御越狱攻击。](2024年10月11日/RePD_Defending_Jailbreak_Attack_through_a_Retrieval-based_Prompt_Decomposition_Process.md)

- [Semi-Supervised Learning of Noisy Mixture of Experts Models](2024年10月11日/Semi-Supervised_Learning_of_Noisy_Mixture_of_Experts_Models.md)

    - [翻译: 半监督噪声混合专家模型学习](2024年10月11日/Semi-Supervised_Learning_of_Noisy_Mixture_of_Experts_Models.md)

- [SimpleStrat: Diversifying Language Model Generation with Stratification](2024年10月11日/SimpleStrat_Diversifying_Language_Model_Generation_with_Stratification.md)

    - [翻译: SimpleStrat：以分层策略丰富语言模型生成多样性](2024年10月11日/SimpleStrat_Diversifying_Language_Model_Generation_with_Stratification.md)

- [SocialGaze: Improving the Integration of Human Social Norms in Large Language Models](2024年10月11日/SocialGaze_Improving_the_Integration_of_Human_Social_Norms_in_Large_Language_Models.md)

    - [翻译: SocialGaze：提升大型语言模型中人类社会规范的融合](2024年10月11日/SocialGaze_Improving_the_Integration_of_Human_Social_Norms_in_Large_Language_Models.md)

- [Software Engineering and Foundation Models: Insights from Industry Blogs Using a Jury of Foundation Models](2024年10月11日/Software_Engineering_and_Foundation_Models_Insights_from_Industry_Blogs_Using_a_Jury_of_Foundation_Models.md)

    - [翻译: 软件工程与基础模型：通过基础模型陪审团，从行业博客中汲取的洞见](2024年10月11日/Software_Engineering_and_Foundation_Models_Insights_from_Industry_Blogs_Using_a_Jury_of_Foundation_Models.md)

- [StructRAG: Boosting Knowledge Intensive Reasoning of LLMs via Inference-time Hybrid Information Structurization](2024年10月11日/StructRAG_Boosting_Knowledge_Intensive_Reasoning_of_LLMs_via_Inference-time_Hybrid_Information_Structurization.md)

    - [翻译: StructRAG：通过推理时的混合信息结构化，大幅提升 LLM 在知识密集型推理中的表现。](2024年10月11日/StructRAG_Boosting_Knowledge_Intensive_Reasoning_of_LLMs_via_Inference-time_Hybrid_Information_Structurization.md)

- [Utilizing ChatGPT in a Data Structures and Algorithms Course: A Teaching Assistant's Perspective](2024年10月11日/Utilizing_ChatGPT_in_a_Data_Structures_and_Algorithms_Course_A_Teaching_Assistant's_Perspective.md)

    - [翻译: ChatGPT 在数据结构与算法课程中的应用：一位助教的视角](2024年10月11日/Utilizing_ChatGPT_in_a_Data_Structures_and_Algorithms_Course_A_Teaching_Assistant's_Perspective.md)

- [When Graph meets Multimodal: Benchmarking on Multimodal Attributed Graphs Learning](2024年10月11日/When_Graph_meets_Multimodal_Benchmarking_on_Multimodal_Attributed_Graphs_Learning.md)

    - [翻译: 图与多模态的邂逅：多模态属性图学习的基准测试](2024年10月11日/When_Graph_meets_Multimodal_Benchmarking_on_Multimodal_Attributed_Graphs_Learning.md)

2024年10月10日

- [DART: Denoising Autoregressive Transformer for Scalable Text-to-Image Generation](2024年10月10日/DART_Denoising_Autoregressive_Transformer_for_Scalable_Text-to-Image_Generation.md)

    - [翻译: DART：一种去噪自回归变换器，专为可扩展的文本到图像生成而设计。](2024年10月10日/DART_Denoising_Autoregressive_Transformer_for_Scalable_Text-to-Image_Generation.md)

- [Diversity of Thought Elicits Stronger Reasoning Capabilities in Multi-Agent Debate Frameworks](2024年10月10日/Diversity_of_Thought_Elicits_Stronger_Reasoning_Capabilities_in_Multi-Agent_Debate_Frameworks.md)

    - [翻译: 思维的多样性在多代理辩论框架中能激发出更强的推理能力。](2024年10月10日/Diversity_of_Thought_Elicits_Stronger_Reasoning_Capabilities_in_Multi-Agent_Debate_Frameworks.md)

- [Global Lyapunov functions: a long-standing open problem in mathematics, with symbolic transformers](2024年10月10日/Global_Lyapunov_functions_a_long-standing_open_problem_in_mathematics,_with_symbolic_transformers.md)

    - [翻译: 全局 Lyapunov 函数，一个数学界长期悬而未决的难题，与符号变换器紧密相关。](2024年10月10日/Global_Lyapunov_functions_a_long-standing_open_problem_in_mathematics,_with_symbolic_transformers.md)

- [Increasing the Difficulty of Automatically Generated Questions via Reinforcement Learning with Synthetic Preference](2024年10月10日/Increasing_the_Difficulty_of_Automatically_Generated_Questions_via_Reinforcement_Learning_with_Synthetic_Preference.md)

    - [翻译: 利用强化学习与合成偏好提升自动生成问题的难度](2024年10月10日/Increasing_the_Difficulty_of_Automatically_Generated_Questions_via_Reinforcement_Learning_with_Synthetic_Preference.md)

- [Large Legislative Models: Towards Efficient AI Policymaking in Economic Simulations](2024年10月10日/Large_Legislative_Models_Towards_Efficient_AI_Policymaking_in_Economic_Simulations.md)

    - [翻译: 大型立法模型：助力经济模拟中的高效 AI 政策制定](2024年10月10日/Large_Legislative_Models_Towards_Efficient_AI_Policymaking_in_Economic_Simulations.md)

- [Prompt Engineering a Schizophrenia Chatbot: Utilizing a Multi-Agent Approach for Enhanced Compliance with Prompt Instructions](2024年10月10日/Prompt_Engineering_a_Schizophrenia_Chatbot_Utilizing_a_Multi-Agent_Approach_for_Enhanced_Compliance_with_Prompt_Instructions.md)

    - [翻译: 精神分裂症聊天机器人的提示工程：通过多代理方法提升对提示指令的遵守效果](2024年10月10日/Prompt_Engineering_a_Schizophrenia_Chatbot_Utilizing_a_Multi-Agent_Approach_for_Enhanced_Compliance_with_Prompt_Instructions.md)

- [SPORTU: A Comprehensive Sports Understanding Benchmark for Multimodal Large Language Models](2024年10月10日/SPORTU_A_Comprehensive_Sports_Understanding_Benchmark_for_Multimodal_Large_Language_Models.md)

    - [翻译: SPORTU：专为多模态大型语言模型设计的综合性体育理解基准](2024年10月10日/SPORTU_A_Comprehensive_Sports_Understanding_Benchmark_for_Multimodal_Large_Language_Models.md)

2024年10月09日

- [Pixtral 12B](2024年10月09日/Pixtral_12B.md)

    - [翻译: Pixtral 12B](2024年10月09日/Pixtral_12B.md)

- [Representation Alignment for Generation: Training Diffusion Transformers Is Easier Than You Think](2024年10月09日/Representation_Alignment_for_Generation_Training_Diffusion_Transformers_Is_Easier_Than_You_Think.md)

    - [翻译: 生成任务中的表示对齐：训练扩散变换器其实比你想象的更简单](2024年10月09日/Representation_Alignment_for_Generation_Training_Diffusion_Transformers_Is_Easier_Than_You_Think.md)

- [WorkflowHub: a registry for computational workflows](2024年10月09日/WorkflowHub_a_registry_for_computational_workflows.md)

    - [翻译: WorkflowHub：计算工作流的注册中心](2024年10月09日/WorkflowHub_a_registry_for_computational_workflows.md)

2024年10月08日

- [Application of NotebookLM, a Large Language Model with Retrieval-Augmented Generation, for Lung Cancer Staging](2024年10月08日/Application_of_NotebookLM,_a_Large_Language_Model_with_Retrieval-Augmented_Generation,_for_Lung_Cancer_Staging.md)

    - [翻译: NotebookLM，一款结合检索增强生成技术的大型语言模型，正被用于肺癌分期研究。](2024年10月08日/Application_of_NotebookLM,_a_Large_Language_Model_with_Retrieval-Augmented_Generation,_for_Lung_Cancer_Staging.md)

- [LLaCA: Multimodal Large Language Continual Assistant](2024年10月08日/LLaCA_Multimodal_Large_Language_Continual_Assistant.md)

    - [翻译: LLaCA：多模态大型语言持续助手](2024年10月08日/LLaCA_Multimodal_Large_Language_Continual_Assistant.md)

- [ToolBridge: An Open-Source Dataset to Equip LLMs with External Tool Capabilities](2024年10月08日/ToolBridge_An_Open-Source_Dataset_to_Equip_LLMs_with_External_Tool_Capabilities.md)

    - [翻译: ToolBridge：一款开源数据集，旨在赋予大型语言模型（LLM）使用外部工具的能力。](2024年10月08日/ToolBridge_An_Open-Source_Dataset_to_Equip_LLMs_with_External_Tool_Capabilities.md)

2024年10月06日

- [CogDevelop2K: Reversed Cognitive Development in Multimodal Large Language Models](2024年10月06日/CogDevelop2K_Reversed_Cognitive_Development_in_Multimodal_Large_Language_Models.md)

    - [翻译: CogDevelop2K：探索多模态大型语言模型中的逆向认知发展](2024年10月06日/CogDevelop2K_Reversed_Cognitive_Development_in_Multimodal_Large_Language_Models.md)

- [SafeLLM: Domain-Specific Safety Monitoring for Large Language Models: A Case Study of Offshore Wind Maintenance](2024年10月06日/SafeLLM_Domain-Specific_Safety_Monitoring_for_Large_Language_Models_A_Case_Study_of_Offshore_Wind_Maintenance.md)

    - [翻译: SafeLLM：专为大型语言模型设计的领域特定安全监控系统，以海上风电维护为例进行探讨。](2024年10月06日/SafeLLM_Domain-Specific_Safety_Monitoring_for_Large_Language_Models_A_Case_Study_of_Offshore_Wind_Maintenance.md)

- [SouLLMate: An Adaptive LLM-Driven System for Advanced Mental Health Support and Assessment, Based on a Systematic Application Survey](2024年10月06日/SouLLMate_An_Adaptive_LLM-Driven_System_for_Advanced_Mental_Health_Support_and_Assessment,_Based_on_a_Systematic_Application_Survey.md)

    - [翻译: SouLLMate：一款自适应的 LLM 驱动系统，专为高级心理健康支持和评估设计，基于系统的应用调查。](2024年10月06日/SouLLMate_An_Adaptive_LLM-Driven_System_for_Advanced_Mental_Health_Support_and_Assessment,_Based_on_a_Systematic_Application_Survey.md)

2024年10月04日

- [A Large Language Model-based Framework for Semi-Structured Tender Document Retrieval-Augmented Generation](2024年10月04日/A_Large_Language_Model-based_Framework_for_Semi-Structured_Tender_Document_Retrieval-Augmented_Generation.md)

    - [翻译: 大型语言模型驱动的半结构化招标文件检索与生成框架](2024年10月04日/A_Large_Language_Model-based_Framework_for_Semi-Structured_Tender_Document_Retrieval-Augmented_Generation.md)

2024年10月03日

- [A Comprehensive Survey of Retrieval-Augmented Generation (RAG): Evolution, Current Landscape and Future Directions](2024年10月03日/A_Comprehensive_Survey_of_Retrieval-Augmented_Generation_(RAG)_Evolution,_Current_Landscape_and_Future_Directions.md)

    - [翻译: 全面探索检索增强生成 (RAG)：从演变到现状，再到未来展望](2024年10月03日/A_Comprehensive_Survey_of_Retrieval-Augmented_Generation_(RAG)_Evolution,_Current_Landscape_and_Future_Directions.md)