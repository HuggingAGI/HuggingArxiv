# 2024年10月

2024年10月07日

- [Efficient Inference for Large Language Model-based Generative Recommendation](2024年10月07日/Efficient_Inference_for_Large_Language_Model-based_Generative_Recommendation.md)

    - [翻译: 大型语言模型生成推荐的高效推理](2024年10月07日/Efficient_Inference_for_Large_Language_Model-based_Generative_Recommendation.md)

- [Enhancing Equity in Large Language Models for Medical Applications](2024年10月07日/Enhancing_Equity_in_Large_Language_Models_for_Medical_Applications.md)

    - [翻译: 提升医疗应用中大型语言模型的公平性](2024年10月07日/Enhancing_Equity_in_Large_Language_Models_for_Medical_Applications.md)

- [Explanation sensitivity to the randomness of large language models: the case of journalistic text classification](2024年10月07日/Explanation_sensitivity_to_the_randomness_of_large_language_models_the_case_of_journalistic_text_classification.md)

    - [翻译: 大型语言模型的随机性如何影响解释的敏感性？以新闻文本分类为例，探讨这一问题。](2024年10月07日/Explanation_sensitivity_to_the_randomness_of_large_language_models_the_case_of_journalistic_text_classification.md)

- [Initialization of Large Language Models via Reparameterization to Mitigate Loss Spikes](2024年10月07日/Initialization_of_Large_Language_Models_via_Reparameterization_to_Mitigate_Loss_Spikes.md)

    - [翻译: 通过重新参数化减轻损失峰值，实现大型语言模型的优化初始化。](2024年10月07日/Initialization_of_Large_Language_Models_via_Reparameterization_to_Mitigate_Loss_Spikes.md)

- [Investigating large language models for their competence in extracting grammatically sound sentences from transcribed noisy utterances](2024年10月07日/Investigating_large_language_models_for_their_competence_in_extracting_grammatically_sound_sentences_from_transcribed_noisy_utterances.md)

    - [翻译: 探究大型语言模型如何从嘈杂的语音转录中提炼出语法正确的句子](2024年10月07日/Investigating_large_language_models_for_their_competence_in_extracting_grammatically_sound_sentences_from_transcribed_noisy_utterances.md)

- [Large Language Model Based Multi-Objective Optimization for Integrated Sensing and Communications in UAV Networks](2024年10月07日/Large_Language_Model_Based_Multi-Objective_Optimization_for_Integrated_Sensing_and_Communications_in_UAV_Networks.md)

    - [翻译: 无人机网络中的集成感知与通信，通过基于大型语言模型的多目标优化实现。](2024年10月07日/Large_Language_Model_Based_Multi-Objective_Optimization_for_Integrated_Sensing_and_Communications_in_UAV_Networks.md)

- [ReasoningRank: Teaching Student Models to Rank through Reasoning-Based Knowledge Distillation](2024年10月07日/ReasoningRank_Teaching_Student_Models_to_Rank_through_Reasoning-Based_Knowledge_Distillation.md)

    - [翻译: ReasoningRank：借助推理为基础的知识蒸馏，教导学生模型掌握排序技能](2024年10月07日/ReasoningRank_Teaching_Student_Models_to_Rank_through_Reasoning-Based_Knowledge_Distillation.md)

- [TidalDecode: Fast and Accurate LLM Decoding with Position Persistent Sparse Attention](2024年10月07日/TidalDecode_Fast_and_Accurate_LLM_Decoding_with_Position_Persistent_Sparse_Attention.md)

    - [翻译: TidalDecode：通过位置持久稀疏注意力，实现 LLM 的快速精准解码](2024年10月07日/TidalDecode_Fast_and_Accurate_LLM_Decoding_with_Position_Persistent_Sparse_Attention.md)

- [ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering](2024年10月07日/ZEBRA_Zero-Shot_Example-Based_Retrieval_Augmentation_for_Commonsense_Question_Answering.md)

    - [翻译: ZEBRA：一种基于零-shot 示例的常识问答检索增强技术](2024年10月07日/ZEBRA_Zero-Shot_Example-Based_Retrieval_Augmentation_for_Commonsense_Question_Answering.md)

2024年10月06日

- [CoVLM: Leveraging Consensus from Vision-Language Models for Semi-supervised Multi-modal Fake News Detection](2024年10月06日/CoVLM_Leveraging_Consensus_from_Vision-Language_Models_for_Semi-supervised_Multi-modal_Fake_News_Detection.md)

    - [翻译: CoVLM：借助视觉-语言模型的共识，实现半监督多模态假新闻检测](2024年10月06日/CoVLM_Leveraging_Consensus_from_Vision-Language_Models_for_Semi-supervised_Multi-modal_Fake_News_Detection.md)

- [DAdEE: Unsupervised Domain Adaptation in Early Exit PLMs](2024年10月06日/DAdEE_Unsupervised_Domain_Adaptation_in_Early_Exit_PLMs.md)

    - [翻译: DAdEE：早期退出 PLM 中的无监督领域自适应](2024年10月06日/DAdEE_Unsupervised_Domain_Adaptation_in_Early_Exit_PLMs.md)

- [Enhancing Android Malware Detection: The Influence of ChatGPT on Decision-centric Task](2024年10月06日/Enhancing_Android_Malware_Detection_The_Influence_of_ChatGPT_on_Decision-centric_Task.md)

    - [翻译: 提升安卓恶意软件检测：ChatGPT 如何影响决策导向任务](2024年10月06日/Enhancing_Android_Malware_Detection_The_Influence_of_ChatGPT_on_Decision-centric_Task.md)

- [GenSim: A General Social Simulation Platform with Large Language Model based Agents](2024年10月06日/GenSim_A_General_Social_Simulation_Platform_with_Large_Language_Model_based_Agents.md)

    - [翻译: GenSim：一款基于大型语言模型代理的通用社会模拟平台](2024年10月06日/GenSim_A_General_Social_Simulation_Platform_with_Large_Language_Model_based_Agents.md)

- [Gödel Agent: A Self-Referential Agent Framework for Recursive Self-Improvement](2024年10月06日/Gödel_Agent_A_Self-Referential_Agent_Framework_for_Recursive_Self-Improvement.md)

    - [翻译: Gödel Agent：一个自指代理框架，专为递归自我改进设计](2024年10月06日/Gödel_Agent_A_Self-Referential_Agent_Framework_for_Recursive_Self-Improvement.md)

- [HALL-E: Hierarchical Neural Codec Language Model for Minute-Long Zero-Shot Text-to-Speech Synthesis](2024年10月06日/HALL-E_Hierarchical_Neural_Codec_Language_Model_for_Minute-Long_Zero-Shot_Text-to-Speech_Synthesis.md)

    - [翻译: HALL-E：一种分层神经编解码语言模型，专为长时间零-shot 文本到语音合成而设计。](2024年10月06日/HALL-E_Hierarchical_Neural_Codec_Language_Model_for_Minute-Long_Zero-Shot_Text-to-Speech_Synthesis.md)

- [Lens: Rethinking Multilingual Enhancement for Large Language Models](2024年10月06日/Lens_Rethinking_Multilingual_Enhancement_for_Large_Language_Models.md)

    - [翻译: Lens：重新审视大型语言模型的多语言增强策略](2024年10月06日/Lens_Rethinking_Multilingual_Enhancement_for_Large_Language_Models.md)

- [MindScope: Exploring cognitive biases in large language models through Multi-Agent Systems](2024年10月06日/MindScope_Exploring_cognitive_biases_in_large_language_models_through_Multi-Agent_Systems.md)

    - [翻译: MindScope 项目通过多代理系统，深入研究大型语言模型中的认知偏差。](2024年10月06日/MindScope_Exploring_cognitive_biases_in_large_language_models_through_Multi-Agent_Systems.md)

- [TIS-DPO: Token-level Importance Sampling for Direct Preference Optimization With Estimated Weights](2024年10月06日/TIS-DPO_Token-level_Importance_Sampling_for_Direct_Preference_Optimization_With_Estimated_Weights.md)

    - [翻译: TIS-DPO：一种基于估计权重，通过令牌级重要性采样实现直接偏好优化的方法](2024年10月06日/TIS-DPO_Token-level_Importance_Sampling_for_Direct_Preference_Optimization_With_Estimated_Weights.md)

2024年10月05日

- [Adaptive Question Answering: Enhancing Language Model Proficiency for Addressing Knowledge Conflicts with Source Citations](2024年10月05日/Adaptive_Question_Answering_Enhancing_Language_Model_Proficiency_for_Addressing_Knowledge_Conflicts_with_Source_Citations.md)

    - [翻译: 自适应问答：借助来源引用，提升语言模型应对知识冲突的熟练度](2024年10月05日/Adaptive_Question_Answering_Enhancing_Language_Model_Proficiency_for_Addressing_Knowledge_Conflicts_with_Source_Citations.md)

- [AI as Humanity's Salieri: Quantifying Linguistic Creativity of Language Models via Systematic Attribution of Machine Text against Web Text](2024年10月05日/AI_as_Humanity's_Salieri_Quantifying_Linguistic_Creativity_of_Language_Models_via_Systematic_Attribution_of_Machine_Text_against_Web_Text.md)

    - [翻译: AI 如萨列里般挑战人类：通过对比机器与网络文本，量化语言模型的创造力](2024年10月05日/AI_as_Humanity's_Salieri_Quantifying_Linguistic_Creativity_of_Language_Models_via_Systematic_Attribution_of_Machine_Text_against_Web_Text.md)

- [A Learning Rate Path Switching Training Paradigm for Version Updates of Large Language Models](2024年10月05日/A_Learning_Rate_Path_Switching_Training_Paradigm_for_Version_Updates_of_Large_Language_Models.md)

    - [翻译: 大型语言模型版本更新中的学习率路径切换训练新范式](2024年10月05日/A_Learning_Rate_Path_Switching_Training_Paradigm_for_Version_Updates_of_Large_Language_Models.md)

- [Beyond Language: Applying MLX Transformers to Engineering Physics](2024年10月05日/Beyond_Language_Applying_MLX_Transformers_to_Engineering_Physics.md)

    - [翻译: 超越语言界限：探索 MLX Transformers 在工程物理领域的应用](2024年10月05日/Beyond_Language_Applying_MLX_Transformers_to_Engineering_Physics.md)

- [Black Boxes and Looking Glasses: Multilevel Symmetries, Reflection Planes, and Convex Optimization in Deep Networks](2024年10月05日/Black_Boxes_and_Looking_Glasses_Multilevel_Symmetries,_Reflection_Planes,_and_Convex_Optimization_in_Deep_Networks.md)

    - [翻译: 黑箱与窥镜：深度网络中的多层次对称、反射平面与凸优化](2024年10月05日/Black_Boxes_and_Looking_Glasses_Multilevel_Symmetries,_Reflection_Planes,_and_Convex_Optimization_in_Deep_Networks.md)

- [BloomWise: Enhancing Problem-Solving capabilities of Large Language Models using Bloom's-Taxonomy-Inspired Prompts](2024年10月05日/BloomWise_Enhancing_Problem-Solving_capabilities_of_Large_Language_Models_using_Bloom's-Taxonomy-Inspired_Prompts.md)

    - [翻译: BloomWise：借助布鲁姆分类法启发的提示，提升大型语言模型的问题解决能力](2024年10月05日/BloomWise_Enhancing_Problem-Solving_capabilities_of_Large_Language_Models_using_Bloom's-Taxonomy-Inspired_Prompts.md)

- [Consistent Autoformalization for Constructing Mathematical Libraries](2024年10月05日/Consistent_Autoformalization_for_Constructing_Mathematical_Libraries.md)

    - [翻译: 构建数学库的自动形式化一致性](2024年10月05日/Consistent_Autoformalization_for_Constructing_Mathematical_Libraries.md)

- [Correlation-Aware Select and Merge Attention for Efficient Fine-Tuning and Context Length Extension](2024年10月05日/Correlation-Aware_Select_and_Merge_Attention_for_Efficient_Fine-Tuning_and_Context_Length_Extension.md)

    - [翻译: 相关感知选择与合并注意力机制，助力高效微调与上下文长度扩展](2024年10月05日/Correlation-Aware_Select_and_Merge_Attention_for_Efficient_Fine-Tuning_and_Context_Length_Extension.md)

- [CS4: Measuring the Creativity of Large Language Models Automatically by Controlling the Number of Story-Writing Constraints](2024年10月05日/CS4_Measuring_the_Creativity_of_Large_Language_Models_Automatically_by_Controlling_the_Number_of_Story-Writing_Constraints.md)

    - [翻译: CS4：通过调控故事创作的限制条件，自动评估大型语言模型的创造力](2024年10月05日/CS4_Measuring_the_Creativity_of_Large_Language_Models_Automatically_by_Controlling_the_Number_of_Story-Writing_Constraints.md)

- [DiDOTS: Knowledge Distillation from Large-Language-Models for Dementia Obfuscation in Transcribed Speech](2024年10月05日/DiDOTS_Knowledge_Distillation_from_Large-Language-Models_for_Dementia_Obfuscation_in_Transcribed_Speech.md)

    - [翻译: DiDOTS：借助大型语言模型的力量，破解转录语音中痴呆症的迷雾](2024年10月05日/DiDOTS_Knowledge_Distillation_from_Large-Language-Models_for_Dementia_Obfuscation_in_Transcribed_Speech.md)

- [DiffSpec: Differential Testing with LLMs using Natural Language Specifications and Code Artifacts](2024年10月05日/DiffSpec_Differential_Testing_with_LLMs_using_Natural_Language_Specifications_and_Code_Artifacts.md)

    - [翻译: DiffSpec：借助自然语言规范与代码工件，对 LLM 进行差异测试](2024年10月05日/DiffSpec_Differential_Testing_with_LLMs_using_Natural_Language_Specifications_and_Code_Artifacts.md)

- [ECon: On the Detection and Resolution of Evidence Conflicts](2024年10月05日/ECon_On_the_Detection_and_Resolution_of_Evidence_Conflicts.md)

    - [翻译: ECon：探讨证据冲突的检测与解决之道](2024年10月05日/ECon_On_the_Detection_and_Resolution_of_Evidence_Conflicts.md)

- [Efficiently Identifying Low-Quality Language Subsets in Multilingual Datasets: A Case Study on a Large-Scale Multilingual Audio Dataset](2024年10月05日/Efficiently_Identifying_Low-Quality_Language_Subsets_in_Multilingual_Datasets_A_Case_Study_on_a_Large-Scale_Multilingual_Audio_Dataset.md)

    - [翻译: 快速定位多语言数据集中的低质量语言子集：大规模多语言音频数据集的实践探索](2024年10月05日/Efficiently_Identifying_Low-Quality_Language_Subsets_in_Multilingual_Datasets_A_Case_Study_on_a_Large-Scale_Multilingual_Audio_Dataset.md)

- [Exploring LLM-based Data Annotation Strategies for Medical Dialogue Preference Alignment](2024年10月05日/Exploring_LLM-based_Data_Annotation_Strategies_for_Medical_Dialogue_Preference_Alignment.md)

    - [翻译: 探索基于大型语言模型的数据标注策略，以实现医疗对话中的偏好对齐](2024年10月05日/Exploring_LLM-based_Data_Annotation_Strategies_for_Medical_Dialogue_Preference_Alignment.md)

- [From Reading to Compressing: Exploring the Multi-document Reader for Prompt Compression](2024年10月05日/From_Reading_to_Compressing_Exploring_the_Multi-document_Reader_for_Prompt_Compression.md)

    - [翻译: 从阅读到压缩：探索多文档阅读器在提示压缩中的应用](2024年10月05日/From_Reading_to_Compressing_Exploring_the_Multi-document_Reader_for_Prompt_Compression.md)

- [Functional Homotopy: Smoothing Discrete Optimization via Continuous Parameters for LLM Jailbreak Attacks](2024年10月05日/Functional_Homotopy_Smoothing_Discrete_Optimization_via_Continuous_Parameters_for_LLM_Jailbreak_Attacks.md)

    - [翻译: 功能同伦：利用连续参数平滑离散优化，破解 LLM 的安全防线](2024年10月05日/Functional_Homotopy_Smoothing_Discrete_Optimization_via_Continuous_Parameters_for_LLM_Jailbreak_Attacks.md)

- [Fundamental Limitations on Subquadratic Alternatives to Transformers](2024年10月05日/Fundamental_Limitations_on_Subquadratic_Alternatives_to_Transformers.md)

    - [翻译: Transformers 的次二次替代方案面临根本性限制](2024年10月05日/Fundamental_Limitations_on_Subquadratic_Alternatives_to_Transformers.md)

- [Gamified crowd-sourcing of high-quality data for visual fine-tuning](2024年10月05日/Gamified_crowd-sourcing_of_high-quality_data_for_visual_fine-tuning.md)

    - [翻译: 通过游戏化方式众包高质量数据，助力视觉模型的微调。](2024年10月05日/Gamified_crowd-sourcing_of_high-quality_data_for_visual_fine-tuning.md)

- [Harnessing Task Overload for Scalable Jailbreak Attacks on Large Language Models](2024年10月05日/Harnessing_Task_Overload_for_Scalable_Jailbreak_Attacks_on_Large_Language_Models.md)

    - [翻译: 借助任务过载，实现对大型语言模型的可扩展越狱攻击](2024年10月05日/Harnessing_Task_Overload_for_Scalable_Jailbreak_Attacks_on_Large_Language_Models.md)

- [Inference Scaling for Long-Context Retrieval Augmented Generation](2024年10月05日/Inference_Scaling_for_Long-Context_Retrieval_Augmented_Generation.md)

    - [翻译: 长上下文检索增强生成的推理规模化](2024年10月05日/Inference_Scaling_for_Long-Context_Retrieval_Augmented_Generation.md)

- [Is deeper always better? Replacing linear mappings with deep learning networks in the Discriminative Lexicon Model](2024年10月05日/Is_deeper_always_better_Replacing_linear_mappings_with_deep_learning_networks_in_the_Discriminative_Lexicon_Model.md)

    - [翻译: 深度是否总是王道？在判别词典模型中，我们探讨用深度学习网络取代线性映射的可能性。](2024年10月05日/Is_deeper_always_better_Replacing_linear_mappings_with_deep_learning_networks_in_the_Discriminative_Lexicon_Model.md)

- [Language Model-Driven Data Pruning Enables Efficient Active Learning](2024年10月05日/Language_Model-Driven_Data_Pruning_Enables_Efficient_Active_Learning.md)

    - [翻译: 语言模型驱动数据修剪，助力高效主动学习](2024年10月05日/Language_Model-Driven_Data_Pruning_Enables_Efficient_Active_Learning.md)

- [Large Language Models can Achieve Social Balance](2024年10月05日/Large_Language_Models_can_Achieve_Social_Balance.md)

    - [翻译: 大型语言模型有能力实现社会平衡](2024年10月05日/Large_Language_Models_can_Achieve_Social_Balance.md)

- [Latent Feature Mining for Predictive Model Enhancement with Large Language Models](2024年10月05日/Latent_Feature_Mining_for_Predictive_Model_Enhancement_with_Large_Language_Models.md)

    - [翻译: 利用大型语言模型挖掘潜在特征，提升预测模型性能](2024年10月05日/Latent_Feature_Mining_for_Predictive_Model_Enhancement_with_Large_Language_Models.md)

- [Learning on LoRAs: GL-Equivariant Processing of Low-Rank Weight Spaces for Large Finetuned Models](2024年10月05日/Learning_on_LoRAs_GL-Equivariant_Processing_of_Low-Rank_Weight_Spaces_for_Large_Finetuned_Models.md)

    - [翻译: 通过 GL-等变处理低秩权重空间，提升大型微调模型的学习效果。](2024年10月05日/Learning_on_LoRAs_GL-Equivariant_Processing_of_Low-Rank_Weight_Spaces_for_Large_Finetuned_Models.md)

- [LLMTemporalComparator: A Tool for Analysing Differences in Temporal Adaptations of Large Language Models](2024年10月05日/LLMTemporalComparator_A_Tool_for_Analysing_Differences_in_Temporal_Adaptations_of_Large_Language_Models.md)

    - [翻译: LLMTemporalComparator：一款专为分析大型语言模型时间适应差异而设计的工具](2024年10月05日/LLMTemporalComparator_A_Tool_for_Analysing_Differences_in_Temporal_Adaptations_of_Large_Language_Models.md)

- [LongGenBench: Long-context Generation Benchmark](2024年10月05日/LongGenBench_Long-context_Generation_Benchmark.md)

    - [翻译: LongGenBench：长上下文生成基准](2024年10月05日/LongGenBench_Long-context_Generation_Benchmark.md)

- [LoRTA: Low Rank Tensor Adaptation of Large Language Models](2024年10月05日/LoRTA_Low_Rank_Tensor_Adaptation_of_Large_Language_Models.md)

    - [翻译: LoRTA：大型语言模型的低秩张量适应技术](2024年10月05日/LoRTA_Low_Rank_Tensor_Adaptation_of_Large_Language_Models.md)

- [Mechanistic Behavior Editing of Language Models](2024年10月05日/Mechanistic_Behavior_Editing_of_Language_Models.md)

    - [翻译: 语言模型的行为机制调整](2024年10月05日/Mechanistic_Behavior_Editing_of_Language_Models.md)

- [Metadata-based Data Exploration with Retrieval-Augmented Generation for Large Language Models](2024年10月05日/Metadata-based_Data_Exploration_with_Retrieval-Augmented_Generation_for_Large_Language_Models.md)

    - [翻译: 元数据驱动的大数据探索，结合检索增强生成技术，助力大型语言模型发展。](2024年10月05日/Metadata-based_Data_Exploration_with_Retrieval-Augmented_Generation_for_Large_Language_Models.md)

- [Multimodal Large Language Models for Inverse Molecular Design with Retrosynthetic Planning](2024年10月05日/Multimodal_Large_Language_Models_for_Inverse_Molecular_Design_with_Retrosynthetic_Planning.md)

    - [翻译: 多模态大型语言模型助力逆向分子设计与逆合成规划](2024年10月05日/Multimodal_Large_Language_Models_for_Inverse_Molecular_Design_with_Retrosynthetic_Planning.md)

- [MVP-Bench: Can Large Vision--Language Models Conduct Multi-level Visual Perception Like Humans?](2024年10月05日/MVP-Bench_Can_Large_Vision--Language_Models_Conduct_Multi-level_Visual_Perception_Like_Humans.md)

    - [翻译: MVP-Bench：大型视觉-语言模型能否实现人类般的多层次视觉感知？](2024年10月05日/MVP-Bench_Can_Large_Vision--Language_Models_Conduct_Multi-level_Visual_Perception_Like_Humans.md)

- [OD-Stega: LLM-Based Near-Imperceptible Steganography via Optimized Distributions](2024年10月05日/OD-Stega_LLM-Based_Near-Imperceptible_Steganography_via_Optimized_Distributions.md)

    - [翻译: OD-Stega：利用 LLM 技术，通过优化分布实现近乎无痕的隐写术。](2024年10月05日/OD-Stega_LLM-Based_Near-Imperceptible_Steganography_via_Optimized_Distributions.md)

- [Ordinal Preference Optimization: Aligning Human Preferences via NDCG](2024年10月05日/Ordinal_Preference_Optimization_Aligning_Human_Preferences_via_NDCG.md)

    - [翻译: 序数偏好优化：借助 NDCG 精准对齐人类偏好](2024年10月05日/Ordinal_Preference_Optimization_Aligning_Human_Preferences_via_NDCG.md)

- [RetCompletion:High-Speed Inference Image Completion with Retentive Network](2024年10月05日/RetCompletionHigh-Speed_Inference_Image_Completion_with_Retentive_Network.md)

    - [翻译: RetCompletion：借助 Retentive Network 实现高速图像补全](2024年10月05日/RetCompletionHigh-Speed_Inference_Image_Completion_with_Retentive_Network.md)

- [ReTok: Replacing Tokenizer to Enhance Representation Efficiency in Large Language Model](2024年10月05日/ReTok_Replacing_Tokenizer_to_Enhance_Representation_Efficiency_in_Large_Language_Model.md)

    - [翻译: ReTok：通过替换分词器，提升大型语言模型中的表示效率](2024年10月05日/ReTok_Replacing_Tokenizer_to_Enhance_Representation_Efficiency_in_Large_Language_Model.md)

- [RoQLlama: A Lightweight Romanian Adapted Language Model](2024年10月05日/RoQLlama_A_Lightweight_Romanian_Adapted_Language_Model.md)

    - [翻译: RoQLlama：一款轻巧的罗马尼亚语语言模型](2024年10月05日/RoQLlama_A_Lightweight_Romanian_Adapted_Language_Model.md)

- [Self-Correction is More than Refinement: A Learning Framework for Visual and Language Reasoning Tasks](2024年10月05日/Self-Correction_is_More_than_Refinement_A_Learning_Framework_for_Visual_and_Language_Reasoning_Tasks.md)

    - [翻译: 自我修正远不止于优化，它是一个专为视觉与语言推理任务设计的新颖学习框架。](2024年10月05日/Self-Correction_is_More_than_Refinement_A_Learning_Framework_for_Visual_and_Language_Reasoning_Tasks.md)

- [TeachTune: Reviewing Pedagogical Agents Against Diverse Student Profiles with Simulated Students](2024年10月05日/TeachTune_Reviewing_Pedagogical_Agents_Against_Diverse_Student_Profiles_with_Simulated_Students.md)

    - [翻译: TeachTune：通过模拟学生，评估教学代理在多样化学生档案中的表现](2024年10月05日/TeachTune_Reviewing_Pedagogical_Agents_Against_Diverse_Student_Profiles_with_Simulated_Students.md)

- [Text2Chart31: Instruction Tuning for Chart Generation with Automatic Feedback](2024年10月05日/Text2Chart31_Instruction_Tuning_for_Chart_Generation_with_Automatic_Feedback.md)

    - [翻译: Text2Chart31：通过自动反馈进行图表生成的指令调优](2024年10月05日/Text2Chart31_Instruction_Tuning_for_Chart_Generation_with_Automatic_Feedback.md)

- [The Visualization JUDGE : Can Multimodal Foundation Models Guide Visualization Design Through Visual Perception?](2024年10月05日/The_Visualization_JUDGE__Can_Multimodal_Foundation_Models_Guide_Visualization_Design_Through_Visual_Perception.md)

    - [翻译: 多模态基础模型能否借助视觉感知，引领可视化设计的方向？](2024年10月05日/The_Visualization_JUDGE__Can_Multimodal_Foundation_Models_Guide_Visualization_Design_Through_Visual_Perception.md)

- [Toxic Subword Pruning for Dialogue Response Generation on Large Language Models](2024年10月05日/Toxic_Subword_Pruning_for_Dialogue_Response_Generation_on_Large_Language_Models.md)

    - [翻译: 在大型语言模型中生成对话响应时，修剪有害子词](2024年10月05日/Toxic_Subword_Pruning_for_Dialogue_Response_Generation_on_Large_Language_Models.md)

- [TUBench: Benchmarking Large Vision-Language Models on Trustworthiness with Unanswerable Questions](2024年10月05日/TUBench_Benchmarking_Large_Vision-Language_Models_on_Trustworthiness_with_Unanswerable_Questions.md)

    - [翻译: TUBench：针对大型视觉语言模型在处理无法回答问题时的可信度进行基准测试](2024年10月05日/TUBench_Benchmarking_Large_Vision-Language_Models_on_Trustworthiness_with_Unanswerable_Questions.md)

2024年10月04日

- [dZiner: Rational Inverse Design of Materials with AI Agents](2024年10月04日/dZiner_Rational_Inverse_Design_of_Materials_with_AI_Agents.md)

    - [翻译: dZiner：借助 AI 代理实现材料的理性逆向设计](2024年10月04日/dZiner_Rational_Inverse_Design_of_Materials_with_AI_Agents.md)

- [Generating Equivalent Representations of Code By A Self-Reflection Approach](2024年10月04日/Generating_Equivalent_Representations_of_Code_By_A_Self-Reflection_Approach.md)

    - [翻译: 利用自反思技术，生成代码的等效表达](2024年10月04日/Generating_Equivalent_Representations_of_Code_By_A_Self-Reflection_Approach.md)

- [How much can we forget about Data Contamination?](2024年10月04日/How_much_can_we_forget_about_Data_Contamination.md)

    - [翻译: 数据污染，我们能忽视多少？](2024年10月04日/How_much_can_we_forget_about_Data_Contamination.md)

- [Misinformation with Legal Consequences (MisLC): A New Task Towards Harnessing Societal Harm of Misinformation](2024年10月04日/Misinformation_with_Legal_Consequences_(MisLC)_A_New_Task_Towards_Harnessing_Societal_Harm_of_Misinformation.md)

    - [翻译: MisLC：一项新任务，旨在应对错误信息带来的法律后果及其社会危害。](2024年10月04日/Misinformation_with_Legal_Consequences_(MisLC)_A_New_Task_Towards_Harnessing_Societal_Harm_of_Misinformation.md)

- [ORAssistant: A Custom RAG-based Conversational Assistant for OpenROAD](2024年10月04日/ORAssistant_A_Custom_RAG-based_Conversational_Assistant_for_OpenROAD.md)

    - [翻译: ORAssistant：专为 OpenROAD 设计的 RAG 基础对话助手](2024年10月04日/ORAssistant_A_Custom_RAG-based_Conversational_Assistant_for_OpenROAD.md)

- [Self-Powered LLM Modality Expansion for Large Speech-Text Models](2024年10月04日/Self-Powered_LLM_Modality_Expansion_for_Large_Speech-Text_Models.md)

    - [翻译: 自供电 LLM 模态扩展，专为大型语音-文本模型设计](2024年10月04日/Self-Powered_LLM_Modality_Expansion_for_Large_Speech-Text_Models.md)

- [TR-LLM: Integrating Trajectory Data for Scene-Aware LLM-Based Human Action Prediction](2024年10月04日/TR-LLM_Integrating_Trajectory_Data_for_Scene-Aware_LLM-Based_Human_Action_Prediction.md)

    - [翻译: TR-LLM：通过集成轨迹数据，实现基于场景感知的 LLM 人类动作预测](2024年10月04日/TR-LLM_Integrating_Trajectory_Data_for_Scene-Aware_LLM-Based_Human_Action_Prediction.md)

- [Understanding Reasoning in Chain-of-Thought from the Hopfieldian View](2024年10月04日/Understanding_Reasoning_in_Chain-of-Thought_from_the_Hopfieldian_View.md)

    - [翻译: 从 Hopfieldian 视角解读思维链中的推理过程](2024年10月04日/Understanding_Reasoning_in_Chain-of-Thought_from_the_Hopfieldian_View.md)

- [What do Large Language Models Need for Machine Translation Evaluation?](2024年10月04日/What_do_Large_Language_Models_Need_for_Machine_Translation_Evaluation.md)

    - [翻译: 大型语言模型在机器翻译评估中需要哪些要素？](2024年10月04日/What_do_Large_Language_Models_Need_for_Machine_Translation_Evaluation.md)

- [YOLO-MARL: You Only LLM Once for Multi-agent Reinforcement Learning](2024年10月04日/YOLO-MARL_You_Only_LLM_Once_for_Multi-agent_Reinforcement_Learning.md)

    - [翻译: YOLO-MARL：一次 LLM，多智能体强化学习无忧](2024年10月04日/YOLO-MARL_You_Only_LLM_Once_for_Multi-agent_Reinforcement_Learning.md)

2024年10月03日

- [Reward-RAG: Enhancing RAG with Reward Driven Supervision](2024年10月03日/Reward-RAG_Enhancing_RAG_with_Reward_Driven_Supervision.md)

    - [翻译: Reward-RAG：以奖励驱动的方式提升 RAG 的性能](2024年10月03日/Reward-RAG_Enhancing_RAG_with_Reward_Driven_Supervision.md)

- [Towards the Pedagogical Steering of Large Language Models for Tutoring: A Case Study with Modeling Productive Failure](2024年10月03日/Towards_the_Pedagogical_Steering_of_Large_Language_Models_for_Tutoring_A_Case_Study_with_Modeling_Productive_Failure.md)

    - [翻译: 探索大型语言模型在辅导中的教学引导：以建模生产性失败为例](2024年10月03日/Towards_the_Pedagogical_Steering_of_Large_Language_Models_for_Tutoring_A_Case_Study_with_Modeling_Productive_Failure.md)

2024年10月02日

- [A Two-Stage Proactive Dialogue Generator for Efficient Clinical Information Collection Using Large Language Model](2024年10月02日/A_Two-Stage_Proactive_Dialogue_Generator_for_Efficient_Clinical_Information_Collection_Using_Large_Language_Model.md)

    - [翻译: 基于大型语言模型的两阶段主动对话生成器，旨在高效收集临床信息。](2024年10月02日/A_Two-Stage_Proactive_Dialogue_Generator_for_Efficient_Clinical_Information_Collection_Using_Large_Language_Model.md)

- [Enhancing Retrieval in QA Systems with Derived Feature Association](2024年10月02日/Enhancing_Retrieval_in_QA_Systems_with_Derived_Feature_Association.md)

    - [翻译: 利用派生特征关联提升问答系统检索效率](2024年10月02日/Enhancing_Retrieval_in_QA_Systems_with_Derived_Feature_Association.md)

- [HiReview: Hierarchical Taxonomy-Driven Automatic Literature Review Generation](2024年10月02日/HiReview_Hierarchical_Taxonomy-Driven_Automatic_Literature_Review_Generation.md)

    - [翻译: HiReview：一种基于分层分类的自动文献综述生成方法](2024年10月02日/HiReview_Hierarchical_Taxonomy-Driven_Automatic_Literature_Review_Generation.md)

- [SeeSay: An Assistive Device for the Visually Impaired Using Retrieval Augmented Generation](2024年10月02日/SeeSay_An_Assistive_Device_for_the_Visually_Impaired_Using_Retrieval_Augmented_Generation.md)

    - [翻译: SeeSay：专为视觉障碍者设计的辅助设备，采用检索增强生成技术](2024年10月02日/SeeSay_An_Assistive_Device_for_the_Visually_Impaired_Using_Retrieval_Augmented_Generation.md)