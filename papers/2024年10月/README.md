# 2024年10月

2024年10月09日

- [Application of Large Language Models to Quantum State Simulation](2024年10月09日/Application_of_Large_Language_Models_to_Quantum_State_Simulation.md)

    - [翻译: 大型语言模型在量子态模拟领域的应用](2024年10月09日/Application_of_Large_Language_Models_to_Quantum_State_Simulation.md)

- [Boosting Few-Shot Detection with Large Language Models and Layout-to-Image Synthesis](2024年10月09日/Boosting_Few-Shot_Detection_with_Large_Language_Models_and_Layout-to-Image_Synthesis.md)

    - [翻译: 借助大型语言模型与布局到图像合成技术，提升少样本检测能力](2024年10月09日/Boosting_Few-Shot_Detection_with_Large_Language_Models_and_Layout-to-Image_Synthesis.md)

- [Break the Visual Perception: Adversarial Attacks Targeting Encoded Visual Tokens of Large Vision-Language Models](2024年10月09日/Break_the_Visual_Perception_Adversarial_Attacks_Targeting_Encoded_Visual_Tokens_of_Large_Vision-Language_Models.md)

    - [翻译: 颠覆视觉感知：针对大型视觉-语言模型编码视觉标记的对抗攻击](2024年10月09日/Break_the_Visual_Perception_Adversarial_Attacks_Targeting_Encoded_Visual_Tokens_of_Large_Vision-Language_Models.md)

- [Calibrating Verbalized Probabilities for Large Language Models](2024年10月09日/Calibrating_Verbalized_Probabilities_for_Large_Language_Models.md)

    - [翻译: 优化大型语言模型的概率表达](2024年10月09日/Calibrating_Verbalized_Probabilities_for_Large_Language_Models.md)

- [Chip-Tuning: Classify Before Language Models Say](2024年10月09日/Chip-Tuning_Classify_Before_Language_Models_Say.md)

    - [翻译: Chip-Tuning：先分类，后语言模型发声](2024年10月09日/Chip-Tuning_Classify_Before_Language_Models_Say.md)

- [CoBa: Convergence Balancer for Multitask Finetuning of Large Language Models](2024年10月09日/CoBa_Convergence_Balancer_for_Multitask_Finetuning_of_Large_Language_Models.md)

    - [翻译: CoBa：为大型语言模型的多任务微调提供收敛平衡](2024年10月09日/CoBa_Convergence_Balancer_for_Multitask_Finetuning_of_Large_Language_Models.md)

- [Deciphering Cross-Modal Alignment in Large Vision-Language Models with Modality Integration Rate](2024年10月09日/Deciphering_Cross-Modal_Alignment_in_Large_Vision-Language_Models_with_Modality_Integration_Rate.md)

    - [翻译: 探索大型视觉-语言模型中跨模态对齐的奥秘，聚焦模态集成率的影响。](2024年10月09日/Deciphering_Cross-Modal_Alignment_in_Large_Vision-Language_Models_with_Modality_Integration_Rate.md)

- [Decomposing Relationship from 1-to-N into N 1-to-1 for Text-Video Retrieval](2024年10月09日/Decomposing_Relationship_from_1-to-N_into_N_1-to-1_for_Text-Video_Retrieval.md)

    - [翻译: 将复杂的 1-to-N 关系拆解为 N 个简单的 1-to-1 关系，以优化文本与视频的匹配检索。](2024年10月09日/Decomposing_Relationship_from_1-to-N_into_N_1-to-1_for_Text-Video_Retrieval.md)

- [Deep Correlated Prompting for Visual Recognition with Missing Modalities](2024年10月09日/Deep_Correlated_Prompting_for_Visual_Recognition_with_Missing_Modalities.md)

    - [翻译: 深度相关提示助力视觉识别，即使模态缺失也能应对自如。](2024年10月09日/Deep_Correlated_Prompting_for_Visual_Recognition_with_Missing_Modalities.md)

- [Detecting Bias and Enhancing Diagnostic Accuracy in Large Language Models for Healthcare](2024年10月09日/Detecting_Bias_and_Enhancing_Diagnostic_Accuracy_in_Large_Language_Models_for_Healthcare.md)

    - [翻译: 在医疗领域的大型语言模型中，检测并消除偏见，提升诊断准确性。](2024年10月09日/Detecting_Bias_and_Enhancing_Diagnostic_Accuracy_in_Large_Language_Models_for_Healthcare.md)

- [Dissecting Fine-Tuning Unlearning in Large Language Models](2024年10月09日/Dissecting_Fine-Tuning_Unlearning_in_Large_Language_Models.md)

    - [翻译: 深入解析大型语言模型中的微调遗忘现象](2024年10月09日/Dissecting_Fine-Tuning_Unlearning_in_Large_Language_Models.md)

- [Do better language models have crisper vision?](2024年10月09日/Do_better_language_models_have_crisper_vision.md)

    - [翻译: 语言模型越先进，视觉理解是否越精准？](2024年10月09日/Do_better_language_models_have_crisper_vision.md)

- [Do Developers Adopt Green Architectural Tactics for ML-Enabled Systems? A Mining Software Repository Study](2024年10月09日/Do_Developers_Adopt_Green_Architectural_Tactics_for_ML-Enabled_Systems_A_Mining_Software_Repository_Study.md)

    - [翻译: 开发者会为机器学习系统采用绿色建筑策略吗？这项研究通过挖掘软件仓库来寻找答案。](2024年10月09日/Do_Developers_Adopt_Green_Architectural_Tactics_for_ML-Enabled_Systems_A_Mining_Software_Repository_Study.md)

- [Dynamic metastability in the self-attention model](2024年10月09日/Dynamic_metastability_in_the_self-attention_model.md)

    - [翻译: 自注意力模型中的动态亚稳态](2024年10月09日/Dynamic_metastability_in_the_self-attention_model.md)

- [Enhancing Multimodal LLM for Detailed and Accurate Video Captioning using Multi-Round Preference Optimization](2024年10月09日/Enhancing_Multimodal_LLM_for_Detailed_and_Accurate_Video_Captioning_using_Multi-Round_Preference_Optimization.md)

    - [翻译: 通过多轮偏好优化，提升多模态 LLM 在视频字幕生成中的细节与准确性。](2024年10月09日/Enhancing_Multimodal_LLM_for_Detailed_and_Accurate_Video_Captioning_using_Multi-Round_Preference_Optimization.md)

- [EvolveDirector: Approaching Advanced Text-to-Image Generation with Large Vision-Language Models](2024年10月09日/EvolveDirector_Approaching_Advanced_Text-to-Image_Generation_with_Large_Vision-Language_Models.md)

    - [翻译: EvolveDirector：借助大型视觉-语言模型，迈向高级文本到图像生成的新境界](2024年10月09日/EvolveDirector_Approaching_Advanced_Text-to-Image_Generation_with_Large_Vision-Language_Models.md)

- [From Pixels to Tokens: Revisiting Object Hallucinations in Large Vision-Language Models](2024年10月09日/From_Pixels_to_Tokens_Revisiting_Object_Hallucinations_in_Large_Vision-Language_Models.md)

    - [翻译: 从像素到标记：探索大型视觉-语言模型中的对象幻觉现象](2024年10月09日/From_Pixels_to_Tokens_Revisiting_Object_Hallucinations_in_Large_Vision-Language_Models.md)

- [Guaranteed Generation from Large Language Models](2024年10月09日/Guaranteed_Generation_from_Large_Language_Models.md)

    - [翻译: 大型语言模型的生成保障](2024年10月09日/Guaranteed_Generation_from_Large_Language_Models.md)

- [HERM: Benchmarking and Enhancing Multimodal LLMs for Human-Centric Understanding](2024年10月09日/HERM_Benchmarking_and_Enhancing_Multimodal_LLMs_for_Human-Centric_Understanding.md)

    - [翻译: HERM：以人为本，提升多模态 LLM 的理解力与基准测试](2024年10月09日/HERM_Benchmarking_and_Enhancing_Multimodal_LLMs_for_Human-Centric_Understanding.md)

- [ING-VP: MLLMs cannot Play Easy Vision-based Games Yet](2024年10月09日/ING-VP_MLLMs_cannot_Play_Easy_Vision-based_Games_Yet.md)

    - [翻译: ING-VP: 多模态大型语言模型尚无法应对简单的视觉游戏挑战](2024年10月09日/ING-VP_MLLMs_cannot_Play_Easy_Vision-based_Games_Yet.md)

- [LaMP: Language-Motion Pretraining for Motion Generation, Retrieval, and Captioning](2024年10月09日/LaMP_Language-Motion_Pretraining_for_Motion_Generation,_Retrieval,_and_Captioning.md)

    - [翻译: LaMP：一种用于运动生成、检索和字幕的语言与运动预训练模型](2024年10月09日/LaMP_Language-Motion_Pretraining_for_Motion_Generation,_Retrieval,_and_Captioning.md)

- [Large Language Models as Code Executors: An Exploratory Study](2024年10月09日/Large_Language_Models_as_Code_Executors_An_Exploratory_Study.md)

    - [翻译: 大型语言模型：代码执行的新探索](2024年10月09日/Large_Language_Models_as_Code_Executors_An_Exploratory_Study.md)

- [Learning Evolving Tools for Large Language Models](2024年10月09日/Learning_Evolving_Tools_for_Large_Language_Models.md)

    - [翻译: 探索大型语言模型的进化学习工具](2024年10月09日/Learning_Evolving_Tools_for_Large_Language_Models.md)

- [MatMamba: A Matryoshka State Space Model](2024年10月09日/MatMamba_A_Matryoshka_State_Space_Model.md)

    - [翻译: MatMamba：一款如俄罗斯套娃般精巧的状态空间模型](2024年10月09日/MatMamba_A_Matryoshka_State_Space_Model.md)

- [MedImageInsight: An Open-Source Embedding Model for General Domain Medical Imaging](2024年10月09日/MedImageInsight_An_Open-Source_Embedding_Model_for_General_Domain_Medical_Imaging.md)

    - [翻译: MedImageInsight：一款专为通用医学影像设计的开源嵌入模型](2024年10月09日/MedImageInsight_An_Open-Source_Embedding_Model_for_General_Domain_Medical_Imaging.md)

- [Mental Disorders Detection in the Era of Large Language Models](2024年10月09日/Mental_Disorders_Detection_in_the_Era_of_Large_Language_Models.md)

    - [翻译: 大型语言模型时代的精神障碍检测](2024年10月09日/Mental_Disorders_Detection_in_the_Era_of_Large_Language_Models.md)

- [Mind Your Questions Towards Backdoor Attacks on Text-to-Visualization Models](2024年10月09日/Mind_Your_Questions_Towards_Backdoor_Attacks_on_Text-to-Visualization_Models.md)

    - [翻译: 小心提问：揭秘文本到可视化模型的后门攻击](2024年10月09日/Mind_Your_Questions_Towards_Backdoor_Attacks_on_Text-to-Visualization_Models.md)

- [MOOSE-Chem: Large Language Models for Rediscovering Unseen Chemistry Scientific Hypotheses](2024年10月09日/MOOSE-Chem_Large_Language_Models_for_Rediscovering_Unseen_Chemistry_Scientific_Hypotheses.md)

    - [翻译: MOOSE-Chem：利用大型语言模型，探索并重新发现那些尚未被揭示的化学科学假设。](2024年10月09日/MOOSE-Chem_Large_Language_Models_for_Rediscovering_Unseen_Chemistry_Scientific_Hypotheses.md)

- [One Initialization to Rule them All: Fine-tuning via Explained Variance Adaptation](2024年10月09日/One_Initialization_to_Rule_them_All_Fine-tuning_via_Explained_Variance_Adaptation.md)

    - [翻译: 一种初始化，统领全局：通过解释方差适应实现微调](2024年10月09日/One_Initialization_to_Rule_them_All_Fine-tuning_via_Explained_Variance_Adaptation.md)

- [QuadMamba: Learning Quadtree-based Selective Scan for Visual State Space Model](2024年10月09日/QuadMamba_Learning_Quadtree-based_Selective_Scan_for_Visual_State_Space_Model.md)

    - [翻译: QuadMamba：利用四叉树学习视觉状态空间模型的选择性扫描](2024年10月09日/QuadMamba_Learning_Quadtree-based_Selective_Scan_for_Visual_State_Space_Model.md)

- [Rodimus*: Breaking the Accuracy-Efficiency Trade-Off with Efficient Attentions](2024年10月09日/Rodimus_Breaking_the_Accuracy-Efficiency_Trade-Off_with_Efficient_Attentions.md)

    - [翻译: Rodimus*：以高效注意力打破准确性与效率的平衡](2024年10月09日/Rodimus_Breaking_the_Accuracy-Efficiency_Trade-Off_with_Efficient_Attentions.md)

- [Root Defence Strategies: Ensuring Safety of LLM at the Decoding Level](2024年10月09日/Root_Defence_Strategies_Ensuring_Safety_of_LLM_at_the_Decoding_Level.md)

    - [翻译: 根防御策略：保障 LLM 在解码层面的安全](2024年10月09日/Root_Defence_Strategies_Ensuring_Safety_of_LLM_at_the_Decoding_Level.md)

- [Scaling Laws for Mixed quantization in Large Language Models](2024年10月09日/Scaling_Laws_for_Mixed_quantization_in_Large_Language_Models.md)

    - [翻译: 大语言模型中混合量化的缩放法则](2024年10月09日/Scaling_Laws_for_Mixed_quantization_in_Large_Language_Models.md)

- [Signal Watermark on Large Language Models](2024年10月09日/Signal_Watermark_on_Large_Language_Models.md)

    - [翻译: 大语言模型中的信号水印](2024年10月09日/Signal_Watermark_on_Large_Language_Models.md)

- [Simplicity Prevails: Rethinking Negative Preference Optimization for LLM Unlearning](2024年10月09日/Simplicity_Prevails_Rethinking_Negative_Preference_Optimization_for_LLM_Unlearning.md)

    - [翻译: 简单为王：重新审视 LLM 遗忘中的负偏好优化](2024年10月09日/Simplicity_Prevails_Rethinking_Negative_Preference_Optimization_for_LLM_Unlearning.md)

- [Stanceformer: Target-Aware Transformer for Stance Detection](2024年10月09日/Stanceformer_Target-Aware_Transformer_for_Stance_Detection.md)

    - [翻译: Stanceformer：一种目标感知的 Transformer，专为立场检测而生。](2024年10月09日/Stanceformer_Target-Aware_Transformer_for_Stance_Detection.md)

- [Stuffed Mamba: State Collapse and State Capacity of RNN-Based Long-Context Modeling](2024年10月09日/Stuffed_Mamba_State_Collapse_and_State_Capacity_of_RNN-Based_Long-Context_Modeling.md)

    - [翻译: 填充曼巴：RNN 长上下文建模中的状态崩溃与容量](2024年10月09日/Stuffed_Mamba_State_Collapse_and_State_Capacity_of_RNN-Based_Long-Context_Modeling.md)

- [Subtle Errors Matter: Preference Learning via Error-injected Self-editing](2024年10月09日/Subtle_Errors_Matter_Preference_Learning_via_Error-injected_Self-editing.md)

    - [翻译: 细微错误不容忽视：借助错误注入的自编辑实现偏好学习](2024年10月09日/Subtle_Errors_Matter_Preference_Learning_via_Error-injected_Self-editing.md)

- [To Preserve or To Compress: An In-Depth Study of Connector Selection in Multimodal Large Language Models](2024年10月09日/To_Preserve_or_To_Compress_An_In-Depth_Study_of_Connector_Selection_in_Multimodal_Large_Language_Models.md)

    - [翻译: 在多模态大型语言模型中，连接器的选择是保留还是压缩？这是一项深入探讨的研究。](2024年10月09日/To_Preserve_or_To_Compress_An_In-Depth_Study_of_Connector_Selection_in_Multimodal_Large_Language_Models.md)

- [Trans4D: Realistic Geometry-Aware Transition for Compositional Text-to-4D Synthesis](2024年10月09日/Trans4D_Realistic_Geometry-Aware_Transition_for_Compositional_Text-to-4D_Synthesis.md)

    - [翻译: Trans4D：实现几何感知的真实过渡，助力组合式文本到4D合成](2024年10月09日/Trans4D_Realistic_Geometry-Aware_Transition_for_Compositional_Text-to-4D_Synthesis.md)

- [Tree of Problems: Improving structured problem solving with compositionality](2024年10月09日/Tree_of_Problems_Improving_structured_problem_solving_with_compositionality.md)

    - [翻译: 问题树：借助组合性提升结构化问题解决能力](2024年10月09日/Tree_of_Problems_Improving_structured_problem_solving_with_compositionality.md)

- [TuringQ: Benchmarking AI Comprehension in Theory of Computation](2024年10月09日/TuringQ_Benchmarking_AI_Comprehension_in_Theory_of_Computation.md)

    - [翻译: TuringQ：理论计算中的 AI 理解力基准测试](2024年10月09日/TuringQ_Benchmarking_AI_Comprehension_in_Theory_of_Computation.md)

- [Unleashing Multi-Hop Reasoning Potential in Large Language Models through Repetition of Misordered Context](2024年10月09日/Unleashing_Multi-Hop_Reasoning_Potential_in_Large_Language_Models_through_Repetition_of_Misordered_Context.md)

    - [翻译: 通过重复错序的上下文，激发大型语言模型中的多跳推理潜能](2024年10月09日/Unleashing_Multi-Hop_Reasoning_Potential_in_Large_Language_Models_through_Repetition_of_Misordered_Context.md)

- [Weak-eval-Strong: Evaluating and Eliciting Lateral Thinking of LLMs with Situation Puzzles](2024年10月09日/Weak-eval-Strong_Evaluating_and_Eliciting_Lateral_Thinking_of_LLMs_with_Situation_Puzzles.md)

    - [翻译: 通过情景谜题，我们不仅能评估，还能激发 LLMs 的横向思维，实现“弱评估，强激发”的效果。](2024年10月09日/Weak-eval-Strong_Evaluating_and_Eliciting_Lateral_Thinking_of_LLMs_with_Situation_Puzzles.md)

- [Which Programming Language and What Features at Pre-training Stage Affect Downstream Logical Inference Performance?](2024年10月09日/Which_Programming_Language_and_What_Features_at_Pre-training_Stage_Affect_Downstream_Logical_Inference_Performance.md)

    - [翻译: 预训练阶段，哪种编程语言及其特征最能提升下游逻辑推理的表现？](2024年10月09日/Which_Programming_Language_and_What_Features_at_Pre-training_Stage_Affect_Downstream_Logical_Inference_Performance.md)

2024年10月08日

- [Active Evaluation Acquisition for Efficient LLM Benchmarking](2024年10月08日/Active_Evaluation_Acquisition_for_Efficient_LLM_Benchmarking.md)

    - [翻译: 高效 LLM 基准测试的主动评估获取](2024年10月08日/Active_Evaluation_Acquisition_for_Efficient_LLM_Benchmarking.md)

- [AgentSquare: Automatic LLM Agent Search in Modular Design Space](2024年10月08日/AgentSquare_Automatic_LLM_Agent_Search_in_Modular_Design_Space.md)

    - [翻译: AgentSquare：模块化设计空间中的自动 LLM 代理搜索](2024年10月08日/AgentSquare_Automatic_LLM_Agent_Search_in_Modular_Design_Space.md)

- [An Eye for an Ear: Zero-shot Audio Description Leveraging an Image Captioner using Audiovisual Distribution Alignment](2024年10月08日/An_Eye_for_an_Ear_Zero-shot_Audio_Description_Leveraging_an_Image_Captioner_using_Audiovisual_Distribution_Alignment.md)

    - [翻译: 以眼还耳：通过视听分布对齐，利用图像描述器实现零-shot 音频描述](2024年10月08日/An_Eye_for_an_Ear_Zero-shot_Audio_Description_Leveraging_an_Image_Captioner_using_Audiovisual_Distribution_Alignment.md)

- [Are Large Language Models State-of-the-art Quality Estimators for Machine Translation of User-generated Content?](2024年10月08日/Are_Large_Language_Models_State-of-the-art_Quality_Estimators_for_Machine_Translation_of_User-generated_Content.md)

    - [翻译: 大型语言模型能否成为用户生成内容机器翻译的顶尖质量评估工具？](2024年10月08日/Are_Large_Language_Models_State-of-the-art_Quality_Estimators_for_Machine_Translation_of_User-generated_Content.md)

- [A second-order-like optimizer with adaptive gradient scaling for deep learning](2024年10月08日/A_second-order-like_optimizer_with_adaptive_gradient_scaling_for_deep_learning.md)

    - [翻译: 深度学习中的二阶优化器，具备自适应梯度缩放功能](2024年10月08日/A_second-order-like_optimizer_with_adaptive_gradient_scaling_for_deep_learning.md)

- [Auto-Evolve: Enhancing Large Language Model's Performance via Self-Reasoning Framework](2024年10月08日/Auto-Evolve_Enhancing_Large_Language_Model's_Performance_via_Self-Reasoning_Framework.md)

    - [翻译: Auto-Evolve：借助自我推理框架，提升大型语言模型的表现](2024年10月08日/Auto-Evolve_Enhancing_Large_Language_Model's_Performance_via_Self-Reasoning_Framework.md)

- [CASA: Class-Agnostic Shared Attributes in Vision-Language Models for Efficient Incremental Object Detection](2024年10月08日/CASA_Class-Agnostic_Shared_Attributes_in_Vision-Language_Models_for_Efficient_Incremental_Object_Detection.md)

    - [翻译: CASA：视觉-语言模型中，类不可知的共享属性助力高效增量对象检测](2024年10月08日/CASA_Class-Agnostic_Shared_Attributes_in_Vision-Language_Models_for_Efficient_Incremental_Object_Detection.md)

- [Coevolving with the Other You: Fine-Tuning LLM with Sequential Cooperative Multi-Agent Reinforcement Learning](2024年10月08日/Coevolving_with_the_Other_You_Fine-Tuning_LLM_with_Sequential_Cooperative_Multi-Agent_Reinforcement_Learning.md)

    - [翻译: 与“另一个你”共同成长：通过顺序合作多智能体强化学习微调 LLM](2024年10月08日/Coevolving_with_the_Other_You_Fine-Tuning_LLM_with_Sequential_Cooperative_Multi-Agent_Reinforcement_Learning.md)

- [ConceptAgent: LLM-Driven Precondition Grounding and Tree Search for Robust Task Planning and Execution](2024年10月08日/ConceptAgent_LLM-Driven_Precondition_Grounding_and_Tree_Search_for_Robust_Task_Planning_and_Execution.md)

    - [翻译: ConceptAgent：利用 LLM 进行先决条件基础和树搜索，实现稳健的任务规划与执行](2024年10月08日/ConceptAgent_LLM-Driven_Precondition_Grounding_and_Tree_Search_for_Robust_Task_Planning_and_Execution.md)

- [Copiloting Diagnosis of Autism in Real Clinical Scenarios via LLMs](2024年10月08日/Copiloting_Diagnosis_of_Autism_in_Real_Clinical_Scenarios_via_LLMs.md)

    - [翻译: 利用 LLM 在实际临床环境中辅助自闭症诊断](2024年10月08日/Copiloting_Diagnosis_of_Autism_in_Real_Clinical_Scenarios_via_LLMs.md)

- [Counterfactual Causal Inference in Natural Language with Large Language Models](2024年10月08日/Counterfactual_Causal_Inference_in_Natural_Language_with_Large_Language_Models.md)

    - [翻译: 利用大型语言模型在自然语言中进行反事实因果推断](2024年10月08日/Counterfactual_Causal_Inference_in_Natural_Language_with_Large_Language_Models.md)

- [Does Spatial Cognition Emerge in Frontier Models?](2024年10月08日/Does_Spatial_Cognition_Emerge_in_Frontier_Models.md)

    - [翻译: 前沿模型中，空间认知是否悄然浮现？](2024年10月08日/Does_Spatial_Cognition_Emerge_in_Frontier_Models.md)

- [Do great minds think alike? Investigating Human-AI Complementarity in Question Answering with CAIMIRA](2024年10月08日/Do_great_minds_think_alike_Investigating_Human-AI_Complementarity_in_Question_Answering_with_CAIMIRA.md)

    - [翻译: 伟大的头脑是否思考相似？通过 CAIMIRA，我们探讨人类与 AI 在问答中的互补性。](2024年10月08日/Do_great_minds_think_alike_Investigating_Human-AI_Complementarity_in_Question_Answering_with_CAIMIRA.md)

- [EMMA: Empowering Multi-modal Mamba with Structural and Hierarchical Alignment](2024年10月08日/EMMA_Empowering_Multi-modal_Mamba_with_Structural_and_Hierarchical_Alignment.md)

    - [翻译: EMMA：赋能多模态 Mamba，实现结构与层次的精准对齐](2024年10月08日/EMMA_Empowering_Multi-modal_Mamba_with_Structural_and_Hierarchical_Alignment.md)

- [Enhancing Temporal Modeling of Video LLMs via Time Gating](2024年10月08日/Enhancing_Temporal_Modeling_of_Video_LLMs_via_Time_Gating.md)

    - [翻译: 借助时间门控技术，提升视频大型语言模型的时间建模能力](2024年10月08日/Enhancing_Temporal_Modeling_of_Video_LLMs_via_Time_Gating.md)

- [Entering Real Social World! Benchmarking the Theory of Mind and Socialization Capabilities of LLMs from a First-person Perspective](2024年10月08日/Entering_Real_Social_World!_Benchmarking_the_Theory_of_Mind_and_Socialization_Capabilities_of_LLMs_from_a_First-person_Perspective.md)

    - [翻译: 探索真实社交世界！从第一人称视角评估 LLM 的思维理论与社交能力](2024年10月08日/Entering_Real_Social_World!_Benchmarking_the_Theory_of_Mind_and_Socialization_Capabilities_of_LLMs_from_a_First-person_Perspective.md)

- [ERVQA: A Dataset to Benchmark the Readiness of Large Vision Language Models in Hospital Environments](2024年10月08日/ERVQA_A_Dataset_to_Benchmark_the_Readiness_of_Large_Vision_Language_Models_in_Hospital_Environments.md)

    - [翻译: ERVQA：一款专为评估大型视觉语言模型在医院环境中的应用准备度而设计的基准数据集](2024年10月08日/ERVQA_A_Dataset_to_Benchmark_the_Readiness_of_Large_Vision_Language_Models_in_Hospital_Environments.md)

- [Exploring Large Language Models Through a Neurodivergent Lens: Use, Challenges, Community-Driven Workarounds, and Concerns](2024年10月08日/Exploring_Large_Language_Models_Through_a_Neurodivergent_Lens_Use,_Challenges,_Community-Driven_Workarounds,_and_Concerns.md)

    - [翻译: 从神经多样性视角审视大型语言模型：应用、挑战、社区智慧的应对策略及关注焦点](2024年10月08日/Exploring_Large_Language_Models_Through_a_Neurodivergent_Lens_Use,_Challenges,_Community-Driven_Workarounds,_and_Concerns.md)

- [Exploring the Meaningfulness of Nearest Neighbor Search in High-Dimensional Space](2024年10月08日/Exploring_the_Meaningfulness_of_Nearest_Neighbor_Search_in_High-Dimensional_Space.md)

    - [翻译: 探究高维空间中最近邻搜索的实际意义](2024年10月08日/Exploring_the_Meaningfulness_of_Nearest_Neighbor_Search_in_High-Dimensional_Space.md)

- [Fortify Your Foundations: Practical Privacy and Security for Foundation Model Deployments In The Cloud](2024年10月08日/Fortify_Your_Foundations_Practical_Privacy_and_Security_for_Foundation_Model_Deployments_In_The_Cloud.md)

    - [翻译: 夯实基础：云端部署中的隐私与安全实践](2024年10月08日/Fortify_Your_Foundations_Practical_Privacy_and_Security_for_Foundation_Model_Deployments_In_The_Cloud.md)

- [From Generalist to Specialist: Adapting Vision Language Models via Task-Specific Visual Instruction Tuning](2024年10月08日/From_Generalist_to_Specialist_Adapting_Vision_Language_Models_via_Task-Specific_Visual_Instruction_Tuning.md)

    - [翻译: 从全能到专精：通过任务导向的视觉指令微调，让视觉语言模型更上一层楼](2024年10月08日/From_Generalist_to_Specialist_Adapting_Vision_Language_Models_via_Task-Specific_Visual_Instruction_Tuning.md)

- [Functional-level Uncertainty Quantification for Calibrated Fine-tuning on LLMs](2024年10月08日/Functional-level_Uncertainty_Quantification_for_Calibrated_Fine-tuning_on_LLMs.md)

    - [翻译: 功能级不确定性量化：LLM 微调的校准之道](2024年10月08日/Functional-level_Uncertainty_Quantification_for_Calibrated_Fine-tuning_on_LLMs.md)

- [FürElise: Capturing and Physically Synthesizing Hand Motions of Piano Performance](2024年10月08日/FürElise_Capturing_and_Physically_Synthesizing_Hand_Motions_of_Piano_Performance.md)

    - [翻译: 《致爱丽丝》：捕捉并物理合成钢琴演奏中的手部动作](2024年10月08日/FürElise_Capturing_and_Physically_Synthesizing_Hand_Motions_of_Piano_Performance.md)

- [Generative AI for Discovering Porous Oxide Materials for Next-Generation Energy Storage](2024年10月08日/Generative_AI_for_Discovering_Porous_Oxide_Materials_for_Next-Generation_Energy_Storage.md)

    - [翻译: 生成式AI助力发现下一代能源存储的多孔氧化物材料](2024年10月08日/Generative_AI_for_Discovering_Porous_Oxide_Materials_for_Next-Generation_Energy_Storage.md)

- [Gradual Learning: Optimizing Fine-Tuning with Partially Mastered Knowledge in Large Language Models](2024年10月08日/Gradual_Learning_Optimizing_Fine-Tuning_with_Partially_Mastered_Knowledge_in_Large_Language_Models.md)

    - [翻译: 渐进学习：利用大语言模型中已掌握的部分知识，优化微调过程](2024年10月08日/Gradual_Learning_Optimizing_Fine-Tuning_with_Partially_Mastered_Knowledge_in_Large_Language_Models.md)

- [Grounding is All You Need? Dual Temporal Grounding for Video Dialog](2024年10月08日/Grounding_is_All_You_Need_Dual_Temporal_Grounding_for_Video_Dialog.md)

    - [翻译: “定位”是否足够？探讨视频对话中的双重时间定位技术。](2024年10月08日/Grounding_is_All_You_Need_Dual_Temporal_Grounding_for_Video_Dialog.md)

- [Hallucinating AI Hijacking Attack: Large Language Models and Malicious Code Recommenders](2024年10月08日/Hallucinating_AI_Hijacking_Attack_Large_Language_Models_and_Malicious_Code_Recommenders.md)

    - [翻译: AI 幻觉劫持：探讨大型语言模型与恶意代码推荐器的潜在威胁](2024年10月08日/Hallucinating_AI_Hijacking_Attack_Large_Language_Models_and_Malicious_Code_Recommenders.md)

- [Jet Expansions of Residual Computation](2024年10月08日/Jet_Expansions_of_Residual_Computation.md)

    - [翻译: 残差计算的喷气扩展技术](2024年10月08日/Jet_Expansions_of_Residual_Computation.md)

- [KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server](2024年10月08日/KnowledgeSG_Privacy-Preserving_Synthetic_Text_Generation_with_Knowledge_Distillation_from_Server.md)

    - [翻译: KnowledgeSG：通过服务器知识蒸馏实现隐私保护的合成文本生成](2024年10月08日/KnowledgeSG_Privacy-Preserving_Synthetic_Text_Generation_with_Knowledge_Distillation_from_Server.md)

- [Language-Assisted Human Part Motion Learning for Skeleton-Based Temporal Action Segmentation](2024年10月08日/Language-Assisted_Human_Part_Motion_Learning_for_Skeleton-Based_Temporal_Action_Segmentation.md)

    - [翻译: 语言助力骨架动作分割：人体运动学习新篇章](2024年10月08日/Language-Assisted_Human_Part_Motion_Learning_for_Skeleton-Based_Temporal_Action_Segmentation.md)

- [Large Language Model Enhanced Text-to-SQL Generation: A Survey](2024年10月08日/Large_Language_Model_Enhanced_Text-to-SQL_Generation_A_Survey.md)

    - [翻译: 大型语言模型助力文本转SQL生成：全面调查](2024年10月08日/Large_Language_Model_Enhanced_Text-to-SQL_Generation_A_Survey.md)

- [Less is More: Making Smaller Language Models Competent Subgraph Retrievers for Multi-hop KGQA](2024年10月08日/Less_is_More_Making_Smaller_Language_Models_Competent_Subgraph_Retrievers_for_Multi-hop_KGQA.md)

    - [翻译: 小而精：让小型语言模型也能胜任多跳 KGQA 的子图检索任务](2024年10月08日/Less_is_More_Making_Smaller_Language_Models_Competent_Subgraph_Retrievers_for_Multi-hop_KGQA.md)

- [LightRAG: Simple and Fast Retrieval-Augmented Generation](2024年10月08日/LightRAG_Simple_and_Fast_Retrieval-Augmented_Generation.md)

    - [翻译: LightRAG：一种既简单又高效的检索增强生成方法](2024年10月08日/LightRAG_Simple_and_Fast_Retrieval-Augmented_Generation.md)

- [Linking Code and Documentation Churn: Preliminary Analysis](2024年10月08日/Linking_Code_and_Documentation_Churn_Preliminary_Analysis.md)

    - [翻译: 代码与文档变动的关联性：初步探究](2024年10月08日/Linking_Code_and_Documentation_Churn_Preliminary_Analysis.md)

- [LLM-based SPARQL Query Generation from Natural Language over Federated Knowledge Graphs](2024年10月08日/LLM-based_SPARQL_Query_Generation_from_Natural_Language_over_Federated_Knowledge_Graphs.md)

    - [翻译: 基于 LLM 的 SPARQL 查询生成：从自然语言到联合知识图谱](2024年10月08日/LLM-based_SPARQL_Query_Generation_from_Natural_Language_over_Federated_Knowledge_Graphs.md)

- [LLM Compression with Neural Architecture Search](2024年10月08日/LLM_Compression_with_Neural_Architecture_Search.md)

    - [翻译: 通过神经架构搜索实现 LLM 压缩](2024年10月08日/LLM_Compression_with_Neural_Architecture_Search.md)

- [Locate-then-edit for Multi-hop Factual Recall under Knowledge Editing](2024年10月08日/Locate-then-edit_for_Multi-hop_Factual_Recall_under_Knowledge_Editing.md)

    - [翻译: 知识编辑中的多跳事实回忆：先定位，再编辑](2024年10月08日/Locate-then-edit_for_Multi-hop_Factual_Recall_under_Knowledge_Editing.md)

- [Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG](2024年10月08日/Long-Context_LLMs_Meet_RAG_Overcoming_Challenges_for_Long_Inputs_in_RAG.md)

    - [翻译: 长上下文 LLM 与 RAG 相遇：解决 RAG 中长输入的难题](2024年10月08日/Long-Context_LLMs_Meet_RAG_Overcoming_Challenges_for_Long_Inputs_in_RAG.md)

- [MaD-Scientist: AI-based Scientist solving Convection-Diffusion-Reaction Equations Using Massive PINN-Based Prior Data](2024年10月08日/MaD-Scientist_AI-based_Scientist_solving_Convection-Diffusion-Reaction_Equations_Using_Massive_PINN-Based_Prior_Data.md)

    - [翻译: MaD-Scientist：这位 AI 科学家利用海量 PINN 先验数据，轻松破解对流-扩散-反应方程难题。](2024年10月08日/MaD-Scientist_AI-based_Scientist_solving_Convection-Diffusion-Reaction_Equations_Using_Massive_PINN-Based_Prior_Data.md)

- [ModalPrompt:Dual-Modality Guided Prompt for Continual Learning of Large Multimodal Models](2024年10月08日/ModalPromptDual-Modality_Guided_Prompt_for_Continual_Learning_of_Large_Multimodal_Models.md)

    - [翻译: ModalPrompt：双模态引导提示助力大型多模态模型的持续学习](2024年10月08日/ModalPromptDual-Modality_Guided_Prompt_for_Continual_Learning_of_Large_Multimodal_Models.md)

- [Multimodal Situational Safety](2024年10月08日/Multimodal_Situational_Safety.md)

    - [翻译: 多模态情境安全](2024年10月08日/Multimodal_Situational_Safety.md)

- [Multi-Session Client-Centered Treatment Outcome Evaluation in Psychotherapy](2024年10月08日/Multi-Session_Client-Centered_Treatment_Outcome_Evaluation_in_Psychotherapy.md)

    - [翻译: 心理治疗中的多会话客户中心治疗效果评估](2024年10月08日/Multi-Session_Client-Centered_Treatment_Outcome_Evaluation_in_Psychotherapy.md)

- [OrionNav: Online Planning for Robot Autonomy with Context-Aware LLM and Open-Vocabulary Semantic Scene Graphs](2024年10月08日/OrionNav_Online_Planning_for_Robot_Autonomy_with_Context-Aware_LLM_and_Open-Vocabulary_Semantic_Scene_Graphs.md)

    - [翻译: OrionNav：结合上下文感知 LLM 与开放词汇语义场景图，实现机器人自主在线规划。](2024年10月08日/OrionNav_Online_Planning_for_Robot_Autonomy_with_Context-Aware_LLM_and_Open-Vocabulary_Semantic_Scene_Graphs.md)

- [PDF-WuKong: A Large Multimodal Model for Efficient Long PDF Reading with End-to-End Sparse Sampling](2024年10月08日/PDF-WuKong_A_Large_Multimodal_Model_for_Efficient_Long_PDF_Reading_with_End-to-End_Sparse_Sampling.md)

    - [翻译: PDF-WuKong：一款高效阅读长 PDF 的大型多模态模型，通过端到端稀疏采样技术实现卓越性能。](2024年10月08日/PDF-WuKong_A_Large_Multimodal_Model_for_Efficient_Long_PDF_Reading_with_End-to-End_Sparse_Sampling.md)

- [Probing Language Models on Their Knowledge Source](2024年10月08日/Probing_Language_Models_on_Their_Knowledge_Source.md)

    - [翻译: 探索语言模型如何运用其知识来源](2024年10月08日/Probing_Language_Models_on_Their_Knowledge_Source.md)

- [Probing the Robustness of Theory of Mind in Large Language Models](2024年10月08日/Probing_the_Robustness_of_Theory_of_Mind_in_Large_Language_Models.md)

    - [翻译: 探索大型语言模型中思维理论的稳健性](2024年10月08日/Probing_the_Robustness_of_Theory_of_Mind_in_Large_Language_Models.md)

- [Quadratic Is Not What You Need For Multimodal Large Language Models](2024年10月08日/Quadratic_Is_Not_What_You_Need_For_Multimodal_Large_Language_Models.md)

    - [翻译: 多模态大型语言模型中，二次方并非良策](2024年10月08日/Quadratic_Is_Not_What_You_Need_For_Multimodal_Large_Language_Models.md)

- [Retrieving, Rethinking and Revising: The Chain-of-Verification Can Improve Retrieval Augmented Generation](2024年10月08日/Retrieving,_Rethinking_and_Revising_The_Chain-of-Verification_Can_Improve_Retrieval_Augmented_Generation.md)

    - [翻译: 通过检索、重新思考和修订的验证链，能够显著提升检索增强生成的质量。](2024年10月08日/Retrieving,_Rethinking_and_Revising_The_Chain-of-Verification_Can_Improve_Retrieval_Augmented_Generation.md)

- [RLRF4Rec: Reinforcement Learning from Recsys Feedback for Enhanced Recommendation Reranking](2024年10月08日/RLRF4Rec_Reinforcement_Learning_from_Recsys_Feedback_for_Enhanced_Recommendation_Reranking.md)

    - [翻译: RLRF4Rec：通过推荐系统反馈的强化学习，提升推荐重排序效果](2024年10月08日/RLRF4Rec_Reinforcement_Learning_from_Recsys_Feedback_for_Enhanced_Recommendation_Reranking.md)

- [SpaLLM: Unified Compressive Adaptation of Large Language Models with Sketching](2024年10月08日/SpaLLM_Unified_Compressive_Adaptation_of_Large_Language_Models_with_Sketching.md)

    - [翻译: SpaLLM：通过草图技术实现大型语言模型的统一压缩适应](2024年10月08日/SpaLLM_Unified_Compressive_Adaptation_of_Large_Language_Models_with_Sketching.md)

- [Time Transfer: On Optimal Learning Rate and Batch Size In The Infinite Data Limit](2024年10月08日/Time_Transfer_On_Optimal_Learning_Rate_and_Batch_Size_In_The_Infinite_Data_Limit.md)

    - [翻译: 时间转移：探索无限数据条件下最优学习率与批量大小的奥秘](2024年10月08日/Time_Transfer_On_Optimal_Learning_Rate_and_Batch_Size_In_The_Infinite_Data_Limit.md)

- [TorchTitan: One-stop PyTorch native solution for production ready LLM pre-training](2024年10月08日/TorchTitan_One-stop_PyTorch_native_solution_for_production_ready_LLM_pre-training.md)

    - [翻译: TorchTitan：专为生产环境设计的 PyTorch 原生 LLM 预训练一站式解决方案](2024年10月08日/TorchTitan_One-stop_PyTorch_native_solution_for_production_ready_LLM_pre-training.md)

- [Training-Free Open-Ended Object Detection and Segmentation via Attention as Prompts](2024年10月08日/Training-Free_Open-Ended_Object_Detection_and_Segmentation_via_Attention_as_Prompts.md)

    - [翻译: 无需训练，借助注意力提示实现开放式对象检测与分割](2024年10月08日/Training-Free_Open-Ended_Object_Detection_and_Segmentation_via_Attention_as_Prompts.md)

- [Unlocking the Boundaries of Thought: A Reasoning Granularity Framework to Quantify and Optimize Chain-of-Thought](2024年10月08日/Unlocking_the_Boundaries_of_Thought_A_Reasoning_Granularity_Framework_to_Quantify_and_Optimize_Chain-of-Thought.md)

    - [翻译: 突破思维界限：构建推理粒度框架，量化并优化思维链](2024年10月08日/Unlocking_the_Boundaries_of_Thought_A_Reasoning_Granularity_Framework_to_Quantify_and_Optimize_Chain-of-Thought.md)

- [Validation of the Scientific Literature via Chemputation Augmented by Large Language Models](2024年10月08日/Validation_of_the_Scientific_Literature_via_Chemputation_Augmented_by_Large_Language_Models.md)

    - [翻译: 利用大型语言模型增强的化学计算，验证科学文献的准确性。](2024年10月08日/Validation_of_the_Scientific_Literature_via_Chemputation_Augmented_by_Large_Language_Models.md)

- [WAPITI: A Watermark for Finetuned Open-Source LLMs](2024年10月08日/WAPITI_A_Watermark_for_Finetuned_Open-Source_LLMs.md)

    - [翻译: WAPITI：为微调开源 LLM 打造的水印](2024年10月08日/WAPITI_A_Watermark_for_Finetuned_Open-Source_LLMs.md)

2024年10月07日

- [Adaptation Odyssey in LLMs: Why Does Additional Pretraining Sometimes Fail to Improve?](2024年10月07日/Adaptation_Odyssey_in_LLMs_Why_Does_Additional_Pretraining_Sometimes_Fail_to_Improve.md)

    - [翻译: LLM 的适应之旅：为何额外预训练有时未能带来提升？](2024年10月07日/Adaptation_Odyssey_in_LLMs_Why_Does_Additional_Pretraining_Sometimes_Fail_to_Improve.md)

- [Better than Your Teacher: LLM Agents that learn from Privileged AI Feedback](2024年10月07日/Better_than_Your_Teacher_LLM_Agents_that_learn_from_Privileged_AI_Feedback.md)

    - [翻译: 超越导师：LLM 代理从特权 AI 反馈中学习](2024年10月07日/Better_than_Your_Teacher_LLM_Agents_that_learn_from_Privileged_AI_Feedback.md)

- [Chain-of-Thoughts for Molecular Understanding](2024年10月07日/Chain-of-Thoughts_for_Molecular_Understanding.md)

    - [翻译: 思维链助力分子解析](2024年10月07日/Chain-of-Thoughts_for_Molecular_Understanding.md)

- [ClaimBrush: A Novel Framework for Automated Patent Claim Refinement Based on Large Language Models](2024年10月07日/ClaimBrush_A_Novel_Framework_for_Automated_Patent_Claim_Refinement_Based_on_Large_Language_Models.md)

    - [翻译: ClaimBrush：基于大型语言模型的专利声明自动化改进新框架](2024年10月07日/ClaimBrush_A_Novel_Framework_for_Automated_Patent_Claim_Refinement_Based_on_Large_Language_Models.md)

- [Conversate: Supporting Reflective Learning in Interview Practice Through Interactive Simulation and Dialogic Feedback](2024年10月07日/Conversate_Supporting_Reflective_Learning_in_Interview_Practice_Through_Interactive_Simulation_and_Dialogic_Feedback.md)

    - [翻译: Conversate：借助交互模拟与对话反馈，助力面试练习中的反思学习](2024年10月07日/Conversate_Supporting_Reflective_Learning_in_Interview_Practice_Through_Interactive_Simulation_and_Dialogic_Feedback.md)

- [Everything Everywhere All at Once: LLMs can In-Context Learn Multiple Tasks in Superposition](2024年10月07日/Everything_Everywhere_All_at_Once_LLMs_can_In-Context_Learn_Multiple_Tasks_in_Superposition.md)

    - [翻译: LLM 能够瞬间掌握多任务，一切尽在超位置中的上下文学习。](2024年10月07日/Everything_Everywhere_All_at_Once_LLMs_can_In-Context_Learn_Multiple_Tasks_in_Superposition.md)

- [Intuitions of Compromise: Utilitarianism vs. Contractualism](2024年10月07日/Intuitions_of_Compromise_Utilitarianism_vs._Contractualism.md)

    - [翻译: 妥协的直觉：功利主义与契约主义之争](2024年10月07日/Intuitions_of_Compromise_Utilitarianism_vs._Contractualism.md)

- [Multimodal Large Language Models and Tunings: Vision, Language, Sensors, Audio, and Beyond](2024年10月07日/Multimodal_Large_Language_Models_and_Tunings_Vision,_Language,_Sensors,_Audio,_and_Beyond.md)

    - [翻译: 多模态大型语言模型与调优：涵盖视觉、语言、传感器、音频及其他领域](2024年10月07日/Multimodal_Large_Language_Models_and_Tunings_Vision,_Language,_Sensors,_Audio,_and_Beyond.md)

- [On Instruction-Finetuning Neural Machine Translation Models](2024年10月07日/On_Instruction-Finetuning_Neural_Machine_Translation_Models.md)

    - [翻译: 探索神经机器翻译模型的指令微调](2024年10月07日/On_Instruction-Finetuning_Neural_Machine_Translation_Models.md)

- [ParallelSpec: Parallel Drafter for Efficient Speculative Decoding](2024年10月07日/ParallelSpec_Parallel_Drafter_for_Efficient_Speculative_Decoding.md)

    - [翻译: ParallelSpec：高效推测解码的并行起草工具](2024年10月07日/ParallelSpec_Parallel_Drafter_for_Efficient_Speculative_Decoding.md)

- [Rational Metareasoning for Large Language Models](2024年10月07日/Rational_Metareasoning_for_Large_Language_Models.md)

    - [翻译: 大型语言模型的理性元推理](2024年10月07日/Rational_Metareasoning_for_Large_Language_Models.md)

- [R-Bench: Are your Large Multimodal Model Robust to Real-world Corruptions?](2024年10月07日/R-Bench_Are_your_Large_Multimodal_Model_Robust_to_Real-world_Corruptions.md)

    - [翻译: R-Bench：你的大型多模态模型能否抵御现实世界的损坏？](2024年10月07日/R-Bench_Are_your_Large_Multimodal_Model_Robust_to_Real-world_Corruptions.md)

- [Recent Advances of Multimodal Continual Learning: A Comprehensive Survey](2024年10月07日/Recent_Advances_of_Multimodal_Continual_Learning_A_Comprehensive_Survey.md)

    - [翻译: 多模态持续学习领域迎来新突破，本文为您带来全面解读。](2024年10月07日/Recent_Advances_of_Multimodal_Continual_Learning_A_Comprehensive_Survey.md)

- [RespLLM: Unifying Audio and Text with Multimodal LLMs for Generalized Respiratory Health Prediction](2024年10月07日/RespLLM_Unifying_Audio_and_Text_with_Multimodal_LLMs_for_Generalized_Respiratory_Health_Prediction.md)

    - [翻译: RespLLM：融合音频与文本的多模态 LLM，助力广义呼吸健康预测](2024年10月07日/RespLLM_Unifying_Audio_and_Text_with_Multimodal_LLMs_for_Generalized_Respiratory_Health_Prediction.md)

- [Scaling Laws Across Model Architectures: A Comparative Analysis of Dense and MoE Models in Large Language Models](2024年10月07日/Scaling_Laws_Across_Model_Architectures_A_Comparative_Analysis_of_Dense_and_MoE_Models_in_Large_Language_Models.md)

    - [翻译: 探索大型语言模型中密集模型与MoE模型的扩展规律，进行深入的比较分析。](2024年10月07日/Scaling_Laws_Across_Model_Architectures_A_Comparative_Analysis_of_Dense_and_MoE_Models_in_Large_Language_Models.md)

- [Stereotype or Personalization? User Identity Biases Chatbot Recommendations](2024年10月07日/Stereotype_or_Personalization_User_Identity_Biases_Chatbot_Recommendations.md)

    - [翻译: 聊天机器人的推荐，是刻板印象的产物，还是个性化的体现？用户身份的偏见在其中扮演了关键角色。](2024年10月07日/Stereotype_or_Personalization_User_Identity_Biases_Chatbot_Recommendations.md)

- [TeaserGen: Generating Teasers for Long Documentaries](2024年10月07日/TeaserGen_Generating_Teasers_for_Long_Documentaries.md)

    - [翻译: TeaserGen：打造长纪录片的精彩预告](2024年10月07日/TeaserGen_Generating_Teasers_for_Long_Documentaries.md)

- [Transformers learn variable-order Markov chains in-context](2024年10月07日/Transformers_learn_variable-order_Markov_chains_in-context.md)

    - [翻译: Transformer 在上下文中学习可变阶马尔可夫链](2024年10月07日/Transformers_learn_variable-order_Markov_chains_in-context.md)

- [Vector-ICL: In-context Learning with Continuous Vector Representations](2024年10月07日/Vector-ICL_In-context_Learning_with_Continuous_Vector_Representations.md)

    - [翻译: Vector-ICL：基于连续向量表示的上下文学习](2024年10月07日/Vector-ICL_In-context_Learning_with_Continuous_Vector_Representations.md)