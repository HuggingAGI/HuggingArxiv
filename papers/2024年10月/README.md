# 2024年10月

2024年10月14日

- [$α$-DPO: Adaptive Reward Margin is What Direct Preference Optimization Needs](2024年10月14日/$α$-DPO_Adaptive_Reward_Margin_is_What_Direct_Preference_Optimization_Needs.md)

    - [翻译: $α$-DPO：自适应奖励边际，正是直接偏好优化所需的关键。](2024年10月14日/$α$-DPO_Adaptive_Reward_Margin_is_What_Direct_Preference_Optimization_Needs.md)

- [A Comparative Study of Translation Bias and Accuracy in Multilingual Large Language Models for Cross-Language Claim Verification](2024年10月14日/A_Comparative_Study_of_Translation_Bias_and_Accuracy_in_Multilingual_Large_Language_Models_for_Cross-Language_Claim_Verification.md)

    - [翻译: 跨语言声明验证中，多语言大型语言模型的翻译偏差与准确性比较研究](2024年10月14日/A_Comparative_Study_of_Translation_Bias_and_Accuracy_in_Multilingual_Large_Language_Models_for_Cross-Language_Claim_Verification.md)

- [Ada-K Routing: Boosting the Efficiency of MoE-based LLMs](2024年10月14日/Ada-K_Routing_Boosting_the_Efficiency_of_MoE-based_LLMs.md)

    - [翻译: Ada-K 路由：为基于 MoE 的 LLM 注入高效动力](2024年10月14日/Ada-K_Routing_Boosting_the_Efficiency_of_MoE-based_LLMs.md)

- [Adapt-$\infty$: Scalable Lifelong Multimodal Instruction Tuning via Dynamic Data Selection](2024年10月14日/Adapt-$\infty$_Scalable_Lifelong_Multimodal_Instruction_Tuning_via_Dynamic_Data_Selection.md)

    - [翻译: Adapt-$\infty$：利用动态数据选择，实现终身多模态指令调优的可扩展性](2024年10月14日/Adapt-$\infty$_Scalable_Lifelong_Multimodal_Instruction_Tuning_via_Dynamic_Data_Selection.md)

- [AFlow: Automating Agentic Workflow Generation](2024年10月14日/AFlow_Automating_Agentic_Workflow_Generation.md)

    - [翻译: AFlow：智能自动化工作流生成](2024年10月14日/AFlow_Automating_Agentic_Workflow_Generation.md)

- [A Multi-Task Text Classification Pipeline with Natural Language Explanations: A User-Centric Evaluation in Sentiment Analysis and Offensive Language Identification in Greek Tweets](2024年10月14日/A_Multi-Task_Text_Classification_Pipeline_with_Natural_Language_Explanations_A_User-Centric_Evaluation_in_Sentiment_Analysis_and_Offensive_Language_Identification_in_Greek_Tweets.md)

    - [翻译: 多任务文本分类管道，结合自然语言解释，专注于希腊推文中的情感分析与冒犯性语言识别，以用户为中心进行评估。](2024年10月14日/A_Multi-Task_Text_Classification_Pipeline_with_Natural_Language_Explanations_A_User-Centric_Evaluation_in_Sentiment_Analysis_and_Offensive_Language_Identification_in_Greek_Tweets.md)

- [Augmenting In-Context-Learning in LLMs via Automatic Data Labeling and Refinement](2024年10月14日/Augmenting_In-Context-Learning_in_LLMs_via_Automatic_Data_Labeling_and_Refinement.md)

    - [翻译: 借助自动数据标注与优化，提升 LLM 中的 In-Context-Learning 效果](2024年10月14日/Augmenting_In-Context-Learning_in_LLMs_via_Automatic_Data_Labeling_and_Refinement.md)

- [A Unified Approach to Routing and Cascading for LLMs](2024年10月14日/A_Unified_Approach_to_Routing_and_Cascading_for_LLMs.md)

    - [翻译: LLM 中的路由与级联统一方法](2024年10月14日/A_Unified_Approach_to_Routing_and_Cascading_for_LLMs.md)

- [Automated Filtering of Human Feedback Data for Aligning Text-to-Image Diffusion Models](2024年10月14日/Automated_Filtering_of_Human_Feedback_Data_for_Aligning_Text-to-Image_Diffusion_Models.md)

    - [翻译: 自动化筛选人类反馈数据，优化文本到图像扩散模型的对齐效果](2024年10月14日/Automated_Filtering_of_Human_Feedback_Data_for_Aligning_Text-to-Image_Diffusion_Models.md)

- [AutoTurb: Using Large Language Models for Automatic Algebraic Model Discovery of Turbulence Closure](2024年10月14日/AutoTurb_Using_Large_Language_Models_for_Automatic_Algebraic_Model_Discovery_of_Turbulence_Closure.md)

    - [翻译: AutoTurb：借助大型语言模型，自动探索湍流闭包的代数模型](2024年10月14日/AutoTurb_Using_Large_Language_Models_for_Automatic_Algebraic_Model_Discovery_of_Turbulence_Closure.md)

- [Balancing Continuous Pre-Training and Instruction Fine-Tuning: Optimizing Instruction-Following in LLMs](2024年10月14日/Balancing_Continuous_Pre-Training_and_Instruction_Fine-Tuning_Optimizing_Instruction-Following_in_LLMs.md)

    - [翻译: 在 LLM 中，如何平衡连续预训练与指令微调，以优化指令跟随能力，是一个关键课题。](2024年10月14日/Balancing_Continuous_Pre-Training_and_Instruction_Fine-Tuning_Optimizing_Instruction-Following_in_LLMs.md)

- [Beyond-RAG: Question Identification and Answer Generation in Real-Time Conversations](2024年10月14日/Beyond-RAG_Question_Identification_and_Answer_Generation_in_Real-Time_Conversations.md)

    - [翻译: 超越RAG：实时对话中的问题识别与答案生成](2024年10月14日/Beyond-RAG_Question_Identification_and_Answer_Generation_in_Real-Time_Conversations.md)

- [Both Ears Wide Open: Towards Language-Driven Spatial Audio Generation](2024年10月14日/Both_Ears_Wide_Open_Towards_Language-Driven_Spatial_Audio_Generation.md)

    - [翻译: 双耳全开：探索语言驱动的空间音频生成](2024年10月14日/Both_Ears_Wide_Open_Towards_Language-Driven_Spatial_Audio_Generation.md)

- [CoMAT: Chain of Mathematically Annotated Thought Improves Mathematical Reasoning](2024年10月14日/CoMAT_Chain_of_Mathematically_Annotated_Thought_Improves_Mathematical_Reasoning.md)

    - [翻译: CoMAT：通过链式数学思维注释，提升数学推理能力](2024年10月14日/CoMAT_Chain_of_Mathematically_Annotated_Thought_Improves_Mathematical_Reasoning.md)

- [Context-Parametric Inversion: Why Instruction Finetuning May Not Actually Improve Context Reliance](2024年10月14日/Context-Parametric_Inversion_Why_Instruction_Finetuning_May_Not_Actually_Improve_Context_Reliance.md)

    - [翻译: 指令微调未必能提升上下文依赖性，这背后的原因在于“上下文参数反转”现象。](2024年10月14日/Context-Parametric_Inversion_Why_Instruction_Finetuning_May_Not_Actually_Improve_Context_Reliance.md)

- [Cultural Fidelity in Large-Language Models: An Evaluation of Online Language Resources as a Driver of Model Performance in Value Representation](2024年10月14日/Cultural_Fidelity_in_Large-Language_Models_An_Evaluation_of_Online_Language_Resources_as_a_Driver_of_Model_Performance_in_Value_Representation.md)

    - [翻译: 大型语言模型中的文化保真度：探讨在线语言资源如何影响模型在价值表示方面的性能。](2024年10月14日/Cultural_Fidelity_in_Large-Language_Models_An_Evaluation_of_Online_Language_Resources_as_a_Driver_of_Model_Performance_in_Value_Representation.md)

- [Denial-of-Service Poisoning Attacks against Large Language Models](2024年10月14日/Denial-of-Service_Poisoning_Attacks_against_Large_Language_Models.md)

    - [翻译: 大型语言模型遭遇拒绝服务中毒攻击](2024年10月14日/Denial-of-Service_Poisoning_Attacks_against_Large_Language_Models.md)

- [Derail Yourself: Multi-turn LLM Jailbreak Attack through Self-discovered Clues](2024年10月14日/Derail_Yourself_Multi-turn_LLM_Jailbreak_Attack_through_Self-discovered_Clues.md)

    - [翻译: 自我脱轨：利用自我发现的线索进行多轮 LLM 越狱攻击](2024年10月14日/Derail_Yourself_Multi-turn_LLM_Jailbreak_Attack_through_Self-discovered_Clues.md)

- [Diagnosing Hate Speech Classification: Where Do Humans and Machines Disagree, and Why?](2024年10月14日/Diagnosing_Hate_Speech_Classification_Where_Do_Humans_and_Machines_Disagree,_and_Why.md)

    - [翻译: 仇恨言论分类的诊断：人类与机器的分歧点及原因何在？](2024年10月14日/Diagnosing_Hate_Speech_Classification_Where_Do_Humans_and_Machines_Disagree,_and_Why.md)

- [DuoAttention: Efficient Long-Context LLM Inference with Retrieval and Streaming Heads](2024年10月14日/DuoAttention_Efficient_Long-Context_LLM_Inference_with_Retrieval_and_Streaming_Heads.md)

    - [翻译: DuoAttention：结合检索与流式处理，实现长上下文 LLM 推理的高效能](2024年10月14日/DuoAttention_Efficient_Long-Context_LLM_Inference_with_Retrieval_and_Streaming_Heads.md)

- [Efficiently Democratizing Medical LLMs for 50 Languages via a Mixture of Language Family Experts](2024年10月14日/Efficiently_Democratizing_Medical_LLMs_for_50_Languages_via_a_Mixture_of_Language_Family_Experts.md)

    - [翻译: 借助语言家族专家的混合策略，我们高效地将医学大型语言模型扩展至50种语言，实现真正的语言民主化。](2024年10月14日/Efficiently_Democratizing_Medical_LLMs_for_50_Languages_via_a_Mixture_of_Language_Family_Experts.md)

- [Effi-Code: Unleashing Code Efficiency in Language Models](2024年10月14日/Effi-Code_Unleashing_Code_Efficiency_in_Language_Models.md)

    - [翻译: Effi-Code：激发语言模型中的代码效率](2024年10月14日/Effi-Code_Unleashing_Code_Efficiency_in_Language_Models.md)

- [Embedding Self-Correction as an Inherent Ability in Large Language Models for Enhanced Mathematical Reasoning](2024年10月14日/Embedding_Self-Correction_as_an_Inherent_Ability_in_Large_Language_Models_for_Enhanced_Mathematical_Reasoning.md)

    - [翻译: 在大型语言模型中融入自我修正能力，以提升数学推理的精准度](2024年10月14日/Embedding_Self-Correction_as_an_Inherent_Ability_in_Large_Language_Models_for_Enhanced_Mathematical_Reasoning.md)

- [Evaluating SQL Understanding in Large Language Models](2024年10月14日/Evaluating_SQL_Understanding_in_Large_Language_Models.md)

    - [翻译: 探究大型语言模型对 SQL 的理解能力](2024年10月14日/Evaluating_SQL_Understanding_in_Large_Language_Models.md)

- [F2A: An Innovative Approach for Prompt Injection by Utilizing Feign Security Detection Agents](2024年10月14日/F2A_An_Innovative_Approach_for_Prompt_Injection_by_Utilizing_Feign_Security_Detection_Agents.md)

    - [翻译: F2A：通过伪装安全检测代理实现提示注入的创新策略](2024年10月14日/F2A_An_Innovative_Approach_for_Prompt_Injection_by_Utilizing_Feign_Security_Detection_Agents.md)

- [Fine-grained Abnormality Prompt Learning for Zero-shot Anomaly Detection](2024年10月14日/Fine-grained_Abnormality_Prompt_Learning_for_Zero-shot_Anomaly_Detection.md)

    - [翻译: 细粒度异常提示学习：零-shot异常检测的新方法](2024年10月14日/Fine-grained_Abnormality_Prompt_Learning_for_Zero-shot_Anomaly_Detection.md)

- [Focused ReAct: Improving ReAct through Reiterate and Early Stop](2024年10月14日/Focused_ReAct_Improving_ReAct_through_Reiterate_and_Early_Stop.md)

    - [翻译: 聚焦 ReAct：通过反复迭代与早期停止提升 ReAct 性能](2024年10月14日/Focused_ReAct_Improving_ReAct_through_Reiterate_and_Early_Stop.md)

- [ForgeryGPT: Multimodal Large Language Model For Explainable Image Forgery Detection and Localization](2024年10月14日/ForgeryGPT_Multimodal_Large_Language_Model_For_Explainable_Image_Forgery_Detection_and_Localization.md)

    - [翻译: ForgeryGPT：一款多模态大型语言模型，专为可解释的图像伪造检测与定位而生。](2024年10月14日/ForgeryGPT_Multimodal_Large_Language_Model_For_Explainable_Image_Forgery_Detection_and_Localization.md)

- [Free Video-LLM: Prompt-guided Visual Perception for Efficient Training-free Video LLMs](2024年10月14日/Free_Video-LLM_Prompt-guided_Visual_Perception_for_Efficient_Training-free_Video_LLMs.md)

    - [翻译: Free Video-LLM：通过提示引导的视觉感知，实现无需训练的高效视频语言模型](2024年10月14日/Free_Video-LLM_Prompt-guided_Visual_Perception_for_Efficient_Training-free_Video_LLMs.md)

- [Functional Flexibility in Generative AI Interfaces: Text Editing with LLMs through Conversations, Toolbars, and Prompts](2024年10月14日/Functional_Flexibility_in_Generative_AI_Interfaces_Text_Editing_with_LLMs_through_Conversations,_Toolbars,_and_Prompts.md)

    - [翻译: 生成式 AI 接口展现出的功能灵活性：通过对话、工具栏和提示，与 LLM 共同进行文本编辑。](2024年10月14日/Functional_Flexibility_in_Generative_AI_Interfaces_Text_Editing_with_LLMs_through_Conversations,_Toolbars,_and_Prompts.md)

- [FunnelRAG: A Coarse-to-Fine Progressive Retrieval Paradigm for RAG](2024年10月14日/FunnelRAG_A_Coarse-to-Fine_Progressive_Retrieval_Paradigm_for_RAG.md)

    - [翻译: FunnelRAG：一种从粗到细的渐进式 RAG 检索方法](2024年10月14日/FunnelRAG_A_Coarse-to-Fine_Progressive_Retrieval_Paradigm_for_RAG.md)

- [Generative AI and Its Impact on Personalized Intelligent Tutoring Systems](2024年10月14日/Generative_AI_and_Its_Impact_on_Personalized_Intelligent_Tutoring_Systems.md)

    - [翻译: 生成式 AI 正在重塑个性化智能辅导系统，探讨其深远影响。](2024年10月14日/Generative_AI_and_Its_Impact_on_Personalized_Intelligent_Tutoring_Systems.md)

- [GraphCLIP: Enhancing Transferability in Graph Foundation Models for Text-Attributed Graphs](2024年10月14日/GraphCLIP_Enhancing_Transferability_in_Graph_Foundation_Models_for_Text-Attributed_Graphs.md)

    - [翻译: GraphCLIP：提升文本属性图基础模型的迁移能力](2024年10月14日/GraphCLIP_Enhancing_Transferability_in_Graph_Foundation_Models_for_Text-Attributed_Graphs.md)

- [HSR-Enhanced Sparse Attention Acceleration](2024年10月14日/HSR-Enhanced_Sparse_Attention_Acceleration.md)

    - [翻译: HSR 增强的稀疏注意力加速](2024年10月14日/HSR-Enhanced_Sparse_Attention_Acceleration.md)

- [Improve Meta-learning for Few-Shot Text Classification with All You Can Acquire from the Tasks](2024年10月14日/Improve_Meta-learning_for_Few-Shot_Text_Classification_with_All_You_Can_Acquire_from_the_Tasks.md)

    - [翻译: 利用任务中的所有可用信息，提升少样本文本分类的元学习效果](2024年10月14日/Improve_Meta-learning_for_Few-Shot_Text_Classification_with_All_You_Can_Acquire_from_the_Tasks.md)

- [Innovative Thinking, Infinite Humor: Humor Research of Large Language Models through Structured Thought Leaps](2024年10月14日/Innovative_Thinking,_Infinite_Humor_Humor_Research_of_Large_Language_Models_through_Structured_Thought_Leaps.md)

    - [翻译: 创新思维，幽默无限：通过结构化思维跳跃探索大语言模型的幽默研究](2024年10月14日/Innovative_Thinking,_Infinite_Humor_Humor_Research_of_Large_Language_Models_through_Structured_Thought_Leaps.md)

- [Is Parameter Collision Hindering Continual Learning in LLMs?](2024年10月14日/Is_Parameter_Collision_Hindering_Continual_Learning_in_LLMs.md)

    - [翻译: 参数碰撞是否成为 LLM 持续学习的绊脚石？](2024年10月14日/Is_Parameter_Collision_Hindering_Continual_Learning_in_LLMs.md)

- [Jailbreak Instruction-Tuned LLMs via end-of-sentence MLP Re-weighting](2024年10月14日/Jailbreak_Instruction-Tuned_LLMs_via_end-of-sentence_MLP_Re-weighting.md)

    - [翻译: 利用句子结尾的多层感知器重新加权技术，破解指令调整的大型语言模型。](2024年10月14日/Jailbreak_Instruction-Tuned_LLMs_via_end-of-sentence_MLP_Re-weighting.md)

- [KBLaM: Knowledge Base augmented Language Model](2024年10月14日/KBLaM_Knowledge_Base_augmented_Language_Model.md)

    - [翻译: KBLaM：知识库赋能的语言模型](2024年10月14日/KBLaM_Knowledge_Base_augmented_Language_Model.md)

- [Large Language Model-Enhanced Reinforcement Learning for Generic Bus Holding Control Strategies](2024年10月14日/Large_Language_Model-Enhanced_Reinforcement_Learning_for_Generic_Bus_Holding_Control_Strategies.md)

    - [翻译: 大型语言模型加持的强化学习，助力通用公交保持控制策略](2024年10月14日/Large_Language_Model-Enhanced_Reinforcement_Learning_for_Generic_Bus_Holding_Control_Strategies.md)

- [Large Language Models Are Active Critics in NLG Evaluation](2024年10月14日/Large_Language_Models_Are_Active_Critics_in_NLG_Evaluation.md)

    - [翻译: 大型语言模型在自然语言生成评估中扮演着积极批评者的角色](2024年10月14日/Large_Language_Models_Are_Active_Critics_in_NLG_Evaluation.md)

- [LG-CAV: Train Any Concept Activation Vector with Language Guidance](2024年10月14日/LG-CAV_Train_Any_Concept_Activation_Vector_with_Language_Guidance.md)

    - [翻译: LG-CAV：借助语言指导，轻松训练任意概念激活向量](2024年10月14日/LG-CAV_Train_Any_Concept_Activation_Vector_with_Language_Guidance.md)

- [Locking Down the Finetuned LLMs Safety](2024年10月14日/Locking_Down_the_Finetuned_LLMs_Safety.md)

    - [翻译: 确保微调后 LLM 的安全防护](2024年10月14日/Locking_Down_the_Finetuned_LLMs_Safety.md)

- [LoLCATs: On Low-Rank Linearizing of Large Language Models](2024年10月14日/LoLCATs_On_Low-Rank_Linearizing_of_Large_Language_Models.md)

    - [翻译: LoLCATs：探索大型语言模型的低秩线性化](2024年10月14日/LoLCATs_On_Low-Rank_Linearizing_of_Large_Language_Models.md)

- [LongMemEval: Benchmarking Chat Assistants on Long-Term Interactive Memory](2024年10月14日/LongMemEval_Benchmarking_Chat_Assistants_on_Long-Term_Interactive_Memory.md)

    - [翻译: LongMemEval：评估聊天助手在长期交互记忆中的表现](2024年10月14日/LongMemEval_Benchmarking_Chat_Assistants_on_Long-Term_Interactive_Memory.md)

- [Medico: Towards Hallucination Detection and Correction with Multi-source Evidence Fusion](2024年10月14日/Medico_Towards_Hallucination_Detection_and_Correction_with_Multi-source_Evidence_Fusion.md)

    - [翻译: Medico：迈向多源证据融合的幻觉检测与校正](2024年10月14日/Medico_Towards_Hallucination_Detection_and_Correction_with_Multi-source_Evidence_Fusion.md)

- [MentalGLM Series: Explainable Large Language Models for Mental Health Analysis on Chinese Social Media](2024年10月14日/MentalGLM_Series_Explainable_Large_Language_Models_for_Mental_Health_Analysis_on_Chinese_Social_Media.md)

    - [翻译: MentalGLM 系列：专为中国社交媒体心理健康分析设计的可解释大型语言模型](2024年10月14日/MentalGLM_Series_Explainable_Large_Language_Models_for_Mental_Health_Analysis_on_Chinese_Social_Media.md)

- [Minimum Tuning to Unlock Long Output from LLMs with High Quality Data as the Key](2024年10月14日/Minimum_Tuning_to_Unlock_Long_Output_from_LLMs_with_High_Quality_Data_as_the_Key.md)

    - [翻译: 通过最小调整，以高质量数据为关键，解锁 LLM 的长输出能力](2024年10月14日/Minimum_Tuning_to_Unlock_Long_Output_from_LLMs_with_High_Quality_Data_as_the_Key.md)

- [Mix Data or Merge Models? Optimizing for Diverse Multi-Task Learning](2024年10月14日/Mix_Data_or_Merge_Models_Optimizing_for_Diverse_Multi-Task_Learning.md)

    - [翻译: 是混合数据还是合并模型？探讨如何优化多样化的多任务学习。](2024年10月14日/Mix_Data_or_Merge_Models_Optimizing_for_Diverse_Multi-Task_Learning.md)

- [MMAR: Towards Lossless Multi-Modal Auto-Regressive Prababilistic Modeling](2024年10月14日/MMAR_Towards_Lossless_Multi-Modal_Auto-Regressive_Prababilistic_Modeling.md)

    - [翻译: MMAR：探索无损多模态自回归概率建模的新领域](2024年10月14日/MMAR_Towards_Lossless_Multi-Modal_Auto-Regressive_Prababilistic_Modeling.md)

- [MMIE: Massive Multimodal Interleaved Comprehension Benchmark for Large Vision-Language Models](2024年10月14日/MMIE_Massive_Multimodal_Interleaved_Comprehension_Benchmark_for_Large_Vision-Language_Models.md)

    - [翻译: MMIE：大型视觉-语言模型的大规模多模态交错理解基准](2024年10月14日/MMIE_Massive_Multimodal_Interleaved_Comprehension_Benchmark_for_Large_Vision-Language_Models.md)

- [Model-Based Differentially Private Knowledge Transfer for Large Language Models](2024年10月14日/Model-Based_Differentially_Private_Knowledge_Transfer_for_Large_Language_Models.md)

    - [翻译: 基于模型的差分隐私技术助力大型语言模型的知识迁移](2024年10月14日/Model-Based_Differentially_Private_Knowledge_Transfer_for_Large_Language_Models.md)

- [MoTE: Reconciling Generalization with Specialization for Visual-Language to Video Knowledge Transfer](2024年10月14日/MoTE_Reconciling_Generalization_with_Specialization_for_Visual-Language_to_Video_Knowledge_Transfer.md)

    - [翻译: MoTE：在视觉-语言到视频知识转移中，平衡泛化与专业化](2024年10月14日/MoTE_Reconciling_Generalization_with_Specialization_for_Visual-Language_to_Video_Knowledge_Transfer.md)

- [On Calibration of LLM-based Guard Models for Reliable Content Moderation](2024年10月14日/On_Calibration_of_LLM-based_Guard_Models_for_Reliable_Content_Moderation.md)

    - [翻译: 校准基于 LLM 的防护模型，确保内容审核的可靠性](2024年10月14日/On_Calibration_of_LLM-based_Guard_Models_for_Reliable_Content_Moderation.md)

- [Parenting: Optimizing Knowledge Selection of Retrieval-Augmented Language Models with Parameter Decoupling and Tailored Tuning](2024年10月14日/Parenting_Optimizing_Knowledge_Selection_of_Retrieval-Augmented_Language_Models_with_Parameter_Decoupling_and_Tailored_Tuning.md)

    - [翻译: 育儿之道：通过参数解耦与定制调优，优化检索增强语言模型的知识选择](2024年10月14日/Parenting_Optimizing_Knowledge_Selection_of_Retrieval-Augmented_Language_Models_with_Parameter_Decoupling_and_Tailored_Tuning.md)

- [QUIS: Question-guided Insights Generation for Automated Exploratory Data Analysis](2024年10月14日/QUIS_Question-guided_Insights_Generation_for_Automated_Exploratory_Data_Analysis.md)

    - [翻译: QUIS：通过问题引导实现自动化探索性数据分析的洞察生成](2024年10月14日/QUIS_Question-guided_Insights_Generation_for_Automated_Exploratory_Data_Analysis.md)

- [QUITE: Quantifying Uncertainty in Natural Language Text in Bayesian Reasoning Scenarios](2024年10月14日/QUITE_Quantifying_Uncertainty_in_Natural_Language_Text_in_Bayesian_Reasoning_Scenarios.md)

    - [翻译: QUITE：在贝叶斯推理背景下，精准量化自然语言文本的不确定性](2024年10月14日/QUITE_Quantifying_Uncertainty_in_Natural_Language_Text_in_Bayesian_Reasoning_Scenarios.md)

- [Recipe for Zero-shot POS Tagging: Is It Useful in Realistic Scenarios?](2024年10月14日/Recipe_for_Zero-shot_POS_Tagging_Is_It_Useful_in_Realistic_Scenarios.md)

    - [翻译: 零-shot POS 标注：在实际应用中是否有效？](2024年10月14日/Recipe_for_Zero-shot_POS_Tagging_Is_It_Useful_in_Realistic_Scenarios.md)

- [Rethinking Legal Judgement Prediction in a Realistic Scenario in the Era of Large Language Models](2024年10月14日/Rethinking_Legal_Judgement_Prediction_in_a_Realistic_Scenario_in_the_Era_of_Large_Language_Models.md)

    - [翻译: 在大语言模型时代，我们需重新审视现实场景中的法律判决预测。](2024年10月14日/Rethinking_Legal_Judgement_Prediction_in_a_Realistic_Scenario_in_the_Era_of_Large_Language_Models.md)

- [Saliency Guided Optimization of Diffusion Latents](2024年10月14日/Saliency_Guided_Optimization_of_Diffusion_Latents.md)

    - [翻译: 显著性引导的扩散潜在优化](2024年10月14日/Saliency_Guided_Optimization_of_Diffusion_Latents.md)

- [SeedLM: Compressing LLM Weights into Seeds of Pseudo-Random Generators](2024年10月14日/SeedLM_Compressing_LLM_Weights_into_Seeds_of_Pseudo-Random_Generators.md)

    - [翻译: SeedLM：将 LLM 权重压缩为伪随机生成器的种子](2024年10月14日/SeedLM_Compressing_LLM_Weights_into_Seeds_of_Pseudo-Random_Generators.md)

- [SensorBench: Benchmarking LLMs in Coding-Based Sensor Processing](2024年10月14日/SensorBench_Benchmarking_LLMs_in_Coding-Based_Sensor_Processing.md)

    - [翻译: SensorBench：为基于编码的传感器处理中的 LLM 提供基准测试](2024年10月14日/SensorBench_Benchmarking_LLMs_in_Coding-Based_Sensor_Processing.md)

- [SensorLLM: Aligning Large Language Models with Motion Sensors for Human Activity Recognition](2024年10月14日/SensorLLM_Aligning_Large_Language_Models_with_Motion_Sensors_for_Human_Activity_Recognition.md)

    - [翻译: SensorLLM：融合大型语言模型与运动传感器，助力人类活动识别](2024年10月14日/SensorLLM_Aligning_Large_Language_Models_with_Motion_Sensors_for_Human_Activity_Recognition.md)

- [Sitcom-Crafter: A Plot-Driven Human Motion Generation System in 3D Scenes](2024年10月14日/Sitcom-Crafter_A_Plot-Driven_Human_Motion_Generation_System_in_3D_Scenes.md)

    - [翻译: Sitcom-Crafter：一款以情节驱动的3D场景中人类动作生成系统](2024年10月14日/Sitcom-Crafter_A_Plot-Driven_Human_Motion_Generation_System_in_3D_Scenes.md)

- [SkillAggregation: Reference-free LLM-Dependent Aggregation](2024年10月14日/SkillAggregation_Reference-free_LLM-Dependent_Aggregation.md)

    - [翻译: SkillAggregation: 一种无需参考、依赖于大型语言模型的聚合技术](2024年10月14日/SkillAggregation_Reference-free_LLM-Dependent_Aggregation.md)

- [SLaNC: Static LayerNorm Calibration](2024年10月14日/SLaNC_Static_LayerNorm_Calibration.md)

    - [翻译: SLaNC：静态层归一化校准](2024年10月14日/SLaNC_Static_LayerNorm_Calibration.md)

- [Spatial-Aware Efficient Projector for MLLMs via Multi-Layer Feature Aggregation](2024年10月14日/Spatial-Aware_Efficient_Projector_for_MLLMs_via_Multi-Layer_Feature_Aggregation.md)

    - [翻译: 多层特征聚合助力多语言大型语言模型实现空间感知高效投影](2024年10月14日/Spatial-Aware_Efficient_Projector_for_MLLMs_via_Multi-Layer_Feature_Aggregation.md)

- [SplitLLM: Collaborative Inference of LLMs for Model Placement and Throughput Optimization](2024年10月14日/SplitLLM_Collaborative_Inference_of_LLMs_for_Model_Placement_and_Throughput_Optimization.md)

    - [翻译: SplitLLM：通过协作推理优化 LLM 的模型放置和吞吐量](2024年10月14日/SplitLLM_Collaborative_Inference_of_LLMs_for_Model_Placement_and_Throughput_Optimization.md)

- [STACKFEED: Structured Textual Actor-Critic Knowledge Base Editing with FeedBack](2024年10月14日/STACKFEED_Structured_Textual_Actor-Critic_Knowledge_Base_Editing_with_FeedBack.md)

    - [翻译: STACKFEED：结合反馈机制的结构化文本 Actor-Critic 知识库编辑系统](2024年10月14日/STACKFEED_Structured_Textual_Actor-Critic_Knowledge_Base_Editing_with_FeedBack.md)

- [Temperature-Centric Investigation of Speculative Decoding with Knowledge Distillation](2024年10月14日/Temperature-Centric_Investigation_of_Speculative_Decoding_with_Knowledge_Distillation.md)

    - [翻译: 聚焦温度，探究知识蒸馏下的推测解码](2024年10月14日/Temperature-Centric_Investigation_of_Speculative_Decoding_with_Knowledge_Distillation.md)

- [Test smells in LLM-Generated Unit Tests](2024年10月14日/Test_smells_in_LLM-Generated_Unit_Tests.md)

    - [翻译: LLM 生成单元测试中的测试异味](2024年10月14日/Test_smells_in_LLM-Generated_Unit_Tests.md)

- [The Implicit Bias of Structured State Space Models Can Be Poisoned With Clean Labels](2024年10月14日/The_Implicit_Bias_of_Structured_State_Space_Models_Can_Be_Poisoned_With_Clean_Labels.md)

    - [翻译: 结构化状态空间模型的隐含偏差，竟能被看似无害的标签所影响。](2024年10月14日/The_Implicit_Bias_of_Structured_State_Space_Models_Can_Be_Poisoned_With_Clean_Labels.md)

- [TMGBench: A Systematic Game Benchmark for Evaluating Strategic Reasoning Abilities of LLMs](2024年10月14日/TMGBench_A_Systematic_Game_Benchmark_for_Evaluating_Strategic_Reasoning_Abilities_of_LLMs.md)

    - [翻译: TMGBench：一款系统性游戏基准，专为评估 LLMs 的战略推理能力而设计](2024年10月14日/TMGBench_A_Systematic_Game_Benchmark_for_Evaluating_Strategic_Reasoning_Abilities_of_LLMs.md)

- [Towards LLM-guided Efficient and Interpretable Multi-linear Tensor Network Rank Selection](2024年10月14日/Towards_LLM-guided_Efficient_and_Interpretable_Multi-linear_Tensor_Network_Rank_Selection.md)

    - [翻译: 迈向由 LLM 引导的高效且可解释的多线性张量网络秩选择](2024年10月14日/Towards_LLM-guided_Efficient_and_Interpretable_Multi-linear_Tensor_Network_Rank_Selection.md)

- [Use Random Selection for Now: Investigation of Few-Shot Selection Strategies in LLM-based Text Augmentation for Classification](2024年10月14日/Use_Random_Selection_for_Now_Investigation_of_Few-Shot_Selection_Strategies_in_LLM-based_Text_Augmentation_for_Classification.md)

    - [翻译: 目前采用随机选择策略：探讨基于 LLM 的文本增强分类中少样本选择策略的影响](2024年10月14日/Use_Random_Selection_for_Now_Investigation_of_Few-Shot_Selection_Strategies_in_LLM-based_Text_Augmentation_for_Classification.md)

- [VisRAG: Vision-based Retrieval-augmented Generation on Multi-modality Documents](2024年10月14日/VisRAG_Vision-based_Retrieval-augmented_Generation_on_Multi-modality_Documents.md)

    - [翻译: VisRAG：多模态文档上的视觉检索增强生成](2024年10月14日/VisRAG_Vision-based_Retrieval-augmented_Generation_on_Multi-modality_Documents.md)

- [When Does Perceptual Alignment Benefit Vision Representations?](2024年10月14日/When_Does_Perceptual_Alignment_Benefit_Vision_Representations.md)

    - [翻译: 何时感知对齐能提升视觉表示的效果？](2024年10月14日/When_Does_Perceptual_Alignment_Benefit_Vision_Representations.md)

- [Will LLMs Replace the Encoder-Only Models in Temporal Relation Classification?](2024年10月14日/Will_LLMs_Replace_the_Encoder-Only_Models_in_Temporal_Relation_Classification.md)

    - [翻译: 大型语言模型（LLMs）是否将取代仅编码器模型，成为时间关系分类的新宠？](2024年10月14日/Will_LLMs_Replace_the_Encoder-Only_Models_in_Temporal_Relation_Classification.md)

- [Words to Wheels: Vision-Based Autonomous Driving Understanding Human Language Instructions Using Foundation Models](2024年10月14日/Words_to_Wheels_Vision-Based_Autonomous_Driving_Understanding_Human_Language_Instructions_Using_Foundation_Models.md)

    - [翻译: 从文字到车轮：基于视觉的自动驾驶系统，利用基础模型理解人类语言指令](2024年10月14日/Words_to_Wheels_Vision-Based_Autonomous_Driving_Understanding_Human_Language_Instructions_Using_Foundation_Models.md)

- [Your Mixture-of-Experts LLM Is Secretly an Embedding Model For Free](2024年10月14日/Your_Mixture-of-Experts_LLM_Is_Secretly_an_Embedding_Model_For_Free.md)

    - [翻译: 你的专家混合型大型语言模型，其实是个免费的嵌入模型哦！](2024年10月14日/Your_Mixture-of-Experts_LLM_Is_Secretly_an_Embedding_Model_For_Free.md)

- [Yuan: Research on the Concept of Digital World Analogue Scientific Infrastructure and Science Popularization Communication Based on Suzhou Gardens Pattern](2024年10月14日/Yuan_Research_on_the_Concept_of_Digital_World_Analogue_Scientific_Infrastructure_and_Science_Popularization_Communication_Based_on_Suzhou_Gardens_Pattern.md)

    - [翻译: 探索苏州园林模式下的数字世界模拟科学基础设施与科普传播新概念](2024年10月14日/Yuan_Research_on_the_Concept_of_Digital_World_Analogue_Scientific_Infrastructure_and_Science_Popularization_Communication_Based_on_Suzhou_Gardens_Pattern.md)

2024年10月13日

- [Adaptive Reasoning and Acting in Medical Language Agents](2024年10月13日/Adaptive_Reasoning_and_Acting_in_Medical_Language_Agents.md)

    - [翻译: 医疗语言代理中的适应性推理与行动](2024年10月13日/Adaptive_Reasoning_and_Acting_in_Medical_Language_Agents.md)

- [A Multi-LLM Orchestration Engine for Personalized, Context-Rich Assistance](2024年10月13日/A_Multi-LLM_Orchestration_Engine_for_Personalized,_Context-Rich_Assistance.md)

    - [翻译: 个性化、上下文感知辅助的多大型语言模型编排引擎](2024年10月13日/A_Multi-LLM_Orchestration_Engine_for_Personalized,_Context-Rich_Assistance.md)

- [Beyond Graphs: Can Large Language Models Comprehend Hypergraphs?](2024年10月13日/Beyond_Graphs_Can_Large_Language_Models_Comprehend_Hypergraphs.md)

    - [翻译: 大型语言模型能否超越图表，理解超图的奥秘？](2024年10月13日/Beyond_Graphs_Can_Large_Language_Models_Comprehend_Hypergraphs.md)

- [BiDoRA: Bi-level Optimization-Based Weight-Decomposed Low-Rank Adaptation](2024年10月13日/BiDoRA_Bi-level_Optimization-Based_Weight-Decomposed_Low-Rank_Adaptation.md)

    - [翻译: BiDoRA：双层优化驱动的权重分解低秩适应](2024年10月13日/BiDoRA_Bi-level_Optimization-Based_Weight-Decomposed_Low-Rank_Adaptation.md)

- [BlackDAN: A Black-Box Multi-Objective Approach for Effective and Contextual Jailbreaking of Large Language Models](2024年10月13日/BlackDAN_A_Black-Box_Multi-Objective_Approach_for_Effective_and_Contextual_Jailbreaking_of_Large_Language_Models.md)

    - [翻译: BlackDAN：一种黑盒多目标策略，专为有效且情境化的破解大型语言模型而设计。](2024年10月13日/BlackDAN_A_Black-Box_Multi-Objective_Approach_for_Effective_and_Contextual_Jailbreaking_of_Large_Language_Models.md)

- [Can Large Language Models Generate Geospatial Code?](2024年10月13日/Can_Large_Language_Models_Generate_Geospatial_Code.md)

    - [翻译: 大型语言模型能否编写地理空间代码？](2024年10月13日/Can_Large_Language_Models_Generate_Geospatial_Code.md)

- [Can We Predict Performance of Large Models across Vision-Language Tasks?](2024年10月13日/Can_We_Predict_Performance_of_Large_Models_across_Vision-Language_Tasks.md)

    - [翻译: 大型模型在视觉-语言任务中的表现，我们能否精准预测？](2024年10月13日/Can_We_Predict_Performance_of_Large_Models_across_Vision-Language_Tasks.md)

- [Dynamic and Textual Graph Generation Via Large-Scale LLM-based Agent Simulation](2024年10月13日/Dynamic_and_Textual_Graph_Generation_Via_Large-Scale_LLM-based_Agent_Simulation.md)

    - [翻译: 通过大规模 LLM 代理模拟实现动态与文本图生成](2024年10月13日/Dynamic_and_Textual_Graph_Generation_Via_Large-Scale_LLM-based_Agent_Simulation.md)

- [EasyJudge: an Easy-to-use Tool for Comprehensive Response Evaluation of LLMs](2024年10月13日/EasyJudge_an_Easy-to-use_Tool_for_Comprehensive_Response_Evaluation_of_LLMs.md)

    - [翻译: EasyJudge：一款易用的工具，专为全面评估 LLM 响应而设计](2024年10月13日/EasyJudge_an_Easy-to-use_Tool_for_Comprehensive_Response_Evaluation_of_LLMs.md)

- [ECIS-VQG: Generation of Entity-centric Information-seeking Questions from Videos](2024年10月13日/ECIS-VQG_Generation_of_Entity-centric_Information-seeking_Questions_from_Videos.md)

    - [翻译: ECIS-VQG：视频中实体导向的信息探索问题生成](2024年10月13日/ECIS-VQG_Generation_of_Entity-centric_Information-seeking_Questions_from_Videos.md)

- [Expanding Search Space with Diverse Prompting Agents: An Efficient Sampling Approach for LLM Mathematical Reasoning](2024年10月13日/Expanding_Search_Space_with_Diverse_Prompting_Agents_An_Efficient_Sampling_Approach_for_LLM_Mathematical_Reasoning.md)

    - [翻译: 通过多样化的提示代理扩展搜索空间：一种高效的采样方法，助力 LLM 在数学推理中的表现。](2024年10月13日/Expanding_Search_Space_with_Diverse_Prompting_Agents_An_Efficient_Sampling_Approach_for_LLM_Mathematical_Reasoning.md)

- [How to Leverage Demonstration Data in Alignment for Large Language Model? A Self-Imitation Learning Perspective](2024年10月13日/How_to_Leverage_Demonstration_Data_in_Alignment_for_Large_Language_Model_A_Self-Imitation_Learning_Perspective.md)

    - [翻译: 如何在大语言模型对齐中巧妙利用演示数据？让我们从自我模仿学习的角度一探究竟。](2024年10月13日/How_to_Leverage_Demonstration_Data_in_Alignment_for_Large_Language_Model_A_Self-Imitation_Learning_Perspective.md)

- [Learning to Rank for Multiple Retrieval-Augmented Models through Iterative Utility Maximization](2024年10月13日/Learning_to_Rank_for_Multiple_Retrieval-Augmented_Models_through_Iterative_Utility_Maximization.md)

    - [翻译: 通过迭代效用最大化，学习对多个检索增强模型进行排序](2024年10月13日/Learning_to_Rank_for_Multiple_Retrieval-Augmented_Models_through_Iterative_Utility_Maximization.md)

- [LOKI: A Comprehensive Synthetic Data Detection Benchmark using Large Multimodal Models](2024年10月13日/LOKI_A_Comprehensive_Synthetic_Data_Detection_Benchmark_using_Large_Multimodal_Models.md)

    - [翻译: LOKI：基于大型多模态模型的综合合成数据检测基准](2024年10月13日/LOKI_A_Comprehensive_Synthetic_Data_Detection_Benchmark_using_Large_Multimodal_Models.md)

- [LongHalQA: Long-Context Hallucination Evaluation for MultiModal Large Language Models](2024年10月13日/LongHalQA_Long-Context_Hallucination_Evaluation_for_MultiModal_Large_Language_Models.md)

    - [翻译: LongHalQA：评估多模态大型语言模型在长上下文中的幻觉现象](2024年10月13日/LongHalQA_Long-Context_Hallucination_Evaluation_for_MultiModal_Large_Language_Models.md)

- [M2M-Gen: A Multimodal Framework for Automated Background Music Generation in Japanese Manga Using Large Language Models](2024年10月13日/M2M-Gen_A_Multimodal_Framework_for_Automated_Background_Music_Generation_in_Japanese_Manga_Using_Large_Language_Models.md)

    - [翻译: M2M-Gen：一个利用大型语言模型自动为日本漫画生成背景音乐的多模态框架](2024年10月13日/M2M-Gen_A_Multimodal_Framework_for_Automated_Background_Music_Generation_in_Japanese_Manga_Using_Large_Language_Models.md)

- [Mastering AI: Big Data, Deep Learning, and the Evolution of Large Language Models -- Blockchain and Applications](2024年10月13日/Mastering_AI_Big_Data,_Deep_Learning,_and_the_Evolution_of_Large_Language_Models_--_Blockchain_and_Applications.md)

    - [翻译: 驾驭 AI：从大数据、深度学习到大语言模型的进化，再到区块链的应用](2024年10月13日/Mastering_AI_Big_Data,_Deep_Learning,_and_the_Evolution_of_Large_Language_Models_--_Blockchain_and_Applications.md)

- [MIRAGE: Multimodal Identification and Recognition of Annotations in Indian General Prescriptions](2024年10月13日/MIRAGE_Multimodal_Identification_and_Recognition_of_Annotations_in_Indian_General_Prescriptions.md)

    - [翻译: MIRAGE：印度通用处方中注释的多模态识别与识别系统](2024年10月13日/MIRAGE_Multimodal_Identification_and_Recognition_of_Annotations_in_Indian_General_Prescriptions.md)

- [MMCOMPOSITION: Revisiting the Compositionality of Pre-trained Vision-Language Models](2024年10月13日/MMCOMPOSITION_Revisiting_the_Compositionality_of_Pre-trained_Vision-Language_Models.md)

    - [翻译: MMCOMPOSITION：探索预训练视觉-语言模型的组合性](2024年10月13日/MMCOMPOSITION_Revisiting_the_Compositionality_of_Pre-trained_Vision-Language_Models.md)

- ['Quis custodiet ipsos custodes?' Who will watch the watchmen? On Detecting AI-generated peer-reviews](2024年10月13日/'Quis_custodiet_ipsos_custodes'_Who_will_watch_the_watchmen_On_Detecting_AI-generated_peer-reviews.md)

    - [翻译: “谁来监督监督者？” —— 探讨如何检测 AI 生成的同行评审](2024年10月13日/'Quis_custodiet_ipsos_custodes'_Who_will_watch_the_watchmen_On_Detecting_AI-generated_peer-reviews.md)

- [Retrieval Instead of Fine-tuning: A Retrieval-based Parameter Ensemble for Zero-shot Learning](2024年10月13日/Retrieval_Instead_of_Fine-tuning_A_Retrieval-based_Parameter_Ensemble_for_Zero-shot_Learning.md)

    - [翻译: 用检索取代微调：探索基于检索的参数集成在零-shot 学习中的应用](2024年10月13日/Retrieval_Instead_of_Fine-tuning_A_Retrieval-based_Parameter_Ensemble_for_Zero-shot_Learning.md)

- [RoCoFT: Efficient Finetuning of Large Language Models with Row-Column Updates](2024年10月13日/RoCoFT_Efficient_Finetuning_of_Large_Language_Models_with_Row-Column_Updates.md)

    - [翻译: RoCoFT：通过行-列更新实现大型语言模型的高效微调](2024年10月13日/RoCoFT_Efficient_Finetuning_of_Large_Language_Models_with_Row-Column_Updates.md)

- [Surgical-LLaVA: Toward Surgical Scenario Understanding via Large Language and Vision Models](2024年10月13日/Surgical-LLaVA_Toward_Surgical_Scenario_Understanding_via_Large_Language_and_Vision_Models.md)

    - [翻译: Surgical-LLaVA：借助大型语言与视觉模型，迈向手术场景的深度理解](2024年10月13日/Surgical-LLaVA_Toward_Surgical_Scenario_Understanding_via_Large_Language_and_Vision_Models.md)

- [Targeted Vaccine: Safety Alignment for Large Language Models against Harmful Fine-Tuning via Layer-wise Perturbation](2024年10月13日/Targeted_Vaccine_Safety_Alignment_for_Large_Language_Models_against_Harmful_Fine-Tuning_via_Layer-wise_Perturbation.md)

    - [翻译: 目标疫苗：通过逐层扰动保护大型语言模型免受有害微调的影响，确保安全对齐](2024年10月13日/Targeted_Vaccine_Safety_Alignment_for_Large_Language_Models_against_Harmful_Fine-Tuning_via_Layer-wise_Perturbation.md)

- [Text4Seg: Reimagining Image Segmentation as Text Generation](2024年10月13日/Text4Seg_Reimagining_Image_Segmentation_as_Text_Generation.md)

    - [翻译: Text4Seg：重塑图像分割为文本生成](2024年10月13日/Text4Seg_Reimagining_Image_Segmentation_as_Text_Generation.md)

- [The Ingredients for Robotic Diffusion Transformers](2024年10月13日/The_Ingredients_for_Robotic_Diffusion_Transformers.md)

    - [翻译: 机器人扩散变换器的核心要素](2024年10月13日/The_Ingredients_for_Robotic_Diffusion_Transformers.md)

2024年10月12日

- [AERA Chat: An Interactive Platform for Automated Explainable Student Answer Assessment](2024年10月12日/AERA_Chat_An_Interactive_Platform_for_Automated_Explainable_Student_Answer_Assessment.md)

    - [翻译: AERA Chat：一个自动化且可解释的学生答案评估交互平台](2024年10月12日/AERA_Chat_An_Interactive_Platform_for_Automated_Explainable_Student_Answer_Assessment.md)

- [Agentic Information Retrieval](2024年10月12日/Agentic_Information_Retrieval.md)

    - [翻译: 主动信息检索](2024年10月12日/Agentic_Information_Retrieval.md)

- [ALLoRA: Adaptive Learning Rate Mitigates LoRA Fatal Flaws](2024年10月12日/ALLoRA_Adaptive_Learning_Rate_Mitigates_LoRA_Fatal_Flaws.md)

    - [翻译: ALLoRA：自适应学习率巧妙化解 LoRA 的致命弱点](2024年10月12日/ALLoRA_Adaptive_Learning_Rate_Mitigates_LoRA_Fatal_Flaws.md)

- [Are You Human? An Adversarial Benchmark to Expose LLMs](2024年10月12日/Are_You_Human_An_Adversarial_Benchmark_to_Expose_LLMs.md)

    - [翻译: “你是人类吗？”——一个对抗性基准，旨在揭示大型语言模型的真实面目。](2024年10月12日/Are_You_Human_An_Adversarial_Benchmark_to_Expose_LLMs.md)

- [Beyond Exact Match: Semantically Reassessing Event Extraction by Large Language Models](2024年10月12日/Beyond_Exact_Match_Semantically_Reassessing_Event_Extraction_by_Large_Language_Models.md)

    - [翻译: 超越精确匹配：借助大型语言模型重新审视事件提取的语义层面](2024年10月12日/Beyond_Exact_Match_Semantically_Reassessing_Event_Extraction_by_Large_Language_Models.md)

- [Boosting Deductive Reasoning with Step Signals In RLHF](2024年10月12日/Boosting_Deductive_Reasoning_with_Step_Signals_In_RLHF.md)

    - [翻译: 通过步骤信号提升 RLHF 中的演绎推理能力](2024年10月12日/Boosting_Deductive_Reasoning_with_Step_Signals_In_RLHF.md)

- [CAMPHOR: Collaborative Agents for Multi-input Planning and High-Order Reasoning On Device](2024年10月12日/CAMPHOR_Collaborative_Agents_for_Multi-input_Planning_and_High-Order_Reasoning_On_Device.md)

    - [翻译: CAMPHOR：设备上多输入规划与高阶推理的协作代理](2024年10月12日/CAMPHOR_Collaborative_Agents_for_Multi-input_Planning_and_High-Order_Reasoning_On_Device.md)

- [CollabEdit: Towards Non-destructive Collaborative Knowledge Editing](2024年10月12日/CollabEdit_Towards_Non-destructive_Collaborative_Knowledge_Editing.md)

    - [翻译: CollabEdit：开启非破坏性协作知识编辑的新篇章](2024年10月12日/CollabEdit_Towards_Non-destructive_Collaborative_Knowledge_Editing.md)

- [COrAL: Order-Agnostic Language Modeling for Efficient Iterative Refinement](2024年10月12日/COrAL_Order-Agnostic_Language_Modeling_for_Efficient_Iterative_Refinement.md)

    - [翻译: COrAL：一种高效迭代细化的无序语言建模方法](2024年10月12日/COrAL_Order-Agnostic_Language_Modeling_for_Efficient_Iterative_Refinement.md)

- [Declarative Knowledge Distillation from Large Language Models for Visual Question Answering Datasets](2024年10月12日/Declarative_Knowledge_Distillation_from_Large_Language_Models_for_Visual_Question_Answering_Datasets.md)

    - [翻译: 大型语言模型中的声明性知识蒸馏，应用于视觉问答数据集](2024年10月12日/Declarative_Knowledge_Distillation_from_Large_Language_Models_for_Visual_Question_Answering_Datasets.md)

- [DRCap: Decoding CLAP Latents with Retrieval-augmented Generation for Zero-shot Audio Captioning](2024年10月12日/DRCap_Decoding_CLAP_Latents_with_Retrieval-augmented_Generation_for_Zero-shot_Audio_Captioning.md)

    - [翻译: DRCap：通过检索增强生成技术，解码 CLAP 潜在变量，实现零-shot 音频字幕生成。](2024年10月12日/DRCap_Decoding_CLAP_Latents_with_Retrieval-augmented_Generation_for_Zero-shot_Audio_Captioning.md)

- [EmbodiedCity: A Benchmark Platform for Embodied Agent in Real-world City Environment](2024年10月12日/EmbodiedCity_A_Benchmark_Platform_for_Embodied_Agent_in_Real-world_City_Environment.md)

    - [翻译: EmbodiedCity：真实城市环境中的具身代理基准平台](2024年10月12日/EmbodiedCity_A_Benchmark_Platform_for_Embodied_Agent_in_Real-world_City_Environment.md)

- [Enhanced Electronic Health Records Text Summarization Using Large Language Models](2024年10月12日/Enhanced_Electronic_Health_Records_Text_Summarization_Using_Large_Language_Models.md)

    - [翻译: 借助大型语言模型，电子健康记录的文本摘要能力得以提升。](2024年10月12日/Enhanced_Electronic_Health_Records_Text_Summarization_Using_Large_Language_Models.md)

- [Exploring Demonstration Retrievers in RAG for Coding Tasks: Yeas and Nays!](2024年10月12日/Exploring_Demonstration_Retrievers_in_RAG_for_Coding_Tasks_Yeas_and_Nays!.md)

    - [翻译: RAG 中编码任务演示检索器的探索：利弊分析！](2024年10月12日/Exploring_Demonstration_Retrievers_in_RAG_for_Coding_Tasks_Yeas_and_Nays!.md)

- [Extended Japanese Commonsense Morality Dataset with Masked Token and Label Enhancement](2024年10月12日/Extended_Japanese_Commonsense_Morality_Dataset_with_Masked_Token_and_Label_Enhancement.md)

    - [翻译: 扩展版日本常识道德数据集，融合掩码标记与标签增强技术](2024年10月12日/Extended_Japanese_Commonsense_Morality_Dataset_with_Masked_Token_and_Label_Enhancement.md)

- [FlatQuant: Flatness Matters for LLM Quantization](2024年10月12日/FlatQuant_Flatness_Matters_for_LLM_Quantization.md)

    - [翻译: FlatQuant：平坦性在 LLM 量化中举足轻重](2024年10月12日/FlatQuant_Flatness_Matters_for_LLM_Quantization.md)

- [Honest AI: Fine-Tuning "Small" Language Models to Say "I Don't Know", and Reducing Hallucination in RAG](2024年10月12日/Honest_AI_Fine-Tuning_Small_Language_Models_to_Say_I_Don't_Know,_and_Reducing_Hallucination_in_RAG.md)

    - [翻译: 让AI更诚实：通过微调小型语言模型，使其能说“我不知道”，并减少RAG中的幻觉现象。](2024年10月12日/Honest_AI_Fine-Tuning_Small_Language_Models_to_Say_I_Don't_Know,_and_Reducing_Hallucination_in_RAG.md)

- [Learning the Bitter Lesson: Empirical Evidence from 20 Years of CVPR Proceedings](2024年10月12日/Learning_the_Bitter_Lesson_Empirical_Evidence_from_20_Years_of_CVPR_Proceedings.md)

    - [翻译: 从 20 年 CVPR 论文集中汲取的苦涩教训：实证探索](2024年10月12日/Learning_the_Bitter_Lesson_Empirical_Evidence_from_20_Years_of_CVPR_Proceedings.md)

- [LINKED: Eliciting, Filtering and Integrating Knowledge in Large Language Model for Commonsense Reasoning](2024年10月12日/LINKED_Eliciting,_Filtering_and_Integrating_Knowledge_in_Large_Language_Model_for_Commonsense_Reasoning.md)

    - [翻译: 在大型语言模型中，如何巧妙地引出、筛选并整合知识，以提升常识推理能力，是我们探讨的核心。](2024年10月12日/LINKED_Eliciting,_Filtering_and_Integrating_Knowledge_in_Large_Language_Model_for_Commonsense_Reasoning.md)

- [LLM-SmartAudit: Advanced Smart Contract Vulnerability Detection](2024年10月12日/LLM-SmartAudit_Advanced_Smart_Contract_Vulnerability_Detection.md)

    - [翻译: LLM-SmartAudit：智能合约漏洞检测的尖端技术](2024年10月12日/LLM-SmartAudit_Advanced_Smart_Contract_Vulnerability_Detection.md)

- [MIRAGE: Evaluating and Explaining Inductive Reasoning Process in Language Models](2024年10月12日/MIRAGE_Evaluating_and_Explaining_Inductive_Reasoning_Process_in_Language_Models.md)

    - [翻译: MIRAGE：探索与揭示语言模型中的归纳推理奥秘](2024年10月12日/MIRAGE_Evaluating_and_Explaining_Inductive_Reasoning_Process_in_Language_Models.md)

- [MMAD: The First-Ever Comprehensive Benchmark for Multimodal Large Language Models in Industrial Anomaly Detection](2024年10月12日/MMAD_The_First-Ever_Comprehensive_Benchmark_for_Multimodal_Large_Language_Models_in_Industrial_Anomaly_Detection.md)

    - [翻译: MMAD：工业异常检测领域首个多模态大型语言模型的全面基准](2024年10月12日/MMAD_The_First-Ever_Comprehensive_Benchmark_for_Multimodal_Large_Language_Models_in_Industrial_Anomaly_Detection.md)

- [MoIN: Mixture of Introvert Experts to Upcycle an LLM](2024年10月12日/MoIN_Mixture_of_Introvert_Experts_to_Upcycle_an_LLM.md)

    - [翻译: MoIN：内向专家混合体，助力 LLM 升级](2024年10月12日/MoIN_Mixture_of_Introvert_Experts_to_Upcycle_an_LLM.md)

- [MTL-LoRA: Low-Rank Adaptation for Multi-Task Learning](2024年10月12日/MTL-LoRA_Low-Rank_Adaptation_for_Multi-Task_Learning.md)

    - [翻译: MTL-LoRA：多任务学习的低秩适应](2024年10月12日/MTL-LoRA_Low-Rank_Adaptation_for_Multi-Task_Learning.md)

- [OpenR: An Open Source Framework for Advanced Reasoning with Large Language Models](2024年10月12日/OpenR_An_Open_Source_Framework_for_Advanced_Reasoning_with_Large_Language_Models.md)

    - [翻译: OpenR：专为大型语言模型高级推理设计的开源框架](2024年10月12日/OpenR_An_Open_Source_Framework_for_Advanced_Reasoning_with_Large_Language_Models.md)

- [Quebec Automobile Insurance Question-Answering With Retrieval-Augmented Generation](2024年10月12日/Quebec_Automobile_Insurance_Question-Answering_With_Retrieval-Augmented_Generation.md)

    - [翻译: 魁北克汽车保险问答系统：检索增强生成技术应用](2024年10月12日/Quebec_Automobile_Insurance_Question-Answering_With_Retrieval-Augmented_Generation.md)

- [Reconstructive Visual Instruction Tuning](2024年10月12日/Reconstructive_Visual_Instruction_Tuning.md)

    - [翻译: 视觉指令的重构调整](2024年10月12日/Reconstructive_Visual_Instruction_Tuning.md)

- [Skipping Computations in Multimodal LLMs](2024年10月12日/Skipping_Computations_in_Multimodal_LLMs.md)

    - [翻译: 多模态 LLM 中的计算跳跃](2024年10月12日/Skipping_Computations_in_Multimodal_LLMs.md)

- [SLAM-AAC: Enhancing Audio Captioning with Paraphrasing Augmentation and CLAP-Refine through LLMs](2024年10月12日/SLAM-AAC_Enhancing_Audio_Captioning_with_Paraphrasing_Augmentation_and_CLAP-Refine_through_LLMs.md)

    - [翻译: SLAM-AAC：借助 LLM 的改写增强与 CLAP-Refine 技术，提升音频字幕质量](2024年10月12日/SLAM-AAC_Enhancing_Audio_Captioning_with_Paraphrasing_Augmentation_and_CLAP-Refine_through_LLMs.md)

- [SLiM: One-shot Quantized Sparse Plus Low-rank Approximation of LLMs](2024年10月12日/SLiM_One-shot_Quantized_Sparse_Plus_Low-rank_Approximation_of_LLMs.md)

    - [翻译: SLiM：一次量化稀疏加低秩近似 LLM](2024年10月12日/SLiM_One-shot_Quantized_Sparse_Plus_Low-rank_Approximation_of_LLMs.md)

- [Society of Medical Simplifiers](2024年10月12日/Society_of_Medical_Simplifiers.md)

    - [翻译: 医学简化协会](2024年10月12日/Society_of_Medical_Simplifiers.md)

- [Synthetic Knowledge Ingestion: Towards Knowledge Refinement and Injection for Enhancing Large Language Models](2024年10月12日/Synthetic_Knowledge_Ingestion_Towards_Knowledge_Refinement_and_Injection_for_Enhancing_Large_Language_Models.md)

    - [翻译: 合成知识摄取：通过知识精炼与注入，提升大型语言模型的能力](2024年10月12日/Synthetic_Knowledge_Ingestion_Towards_Knowledge_Refinement_and_Injection_for_Enhancing_Large_Language_Models.md)

- [The Future of Learning in the Age of Generative AI: Automated Question Generation and Assessment with Large Language Models](2024年10月12日/The_Future_of_Learning_in_the_Age_of_Generative_AI_Automated_Question_Generation_and_Assessment_with_Large_Language_Models.md)

    - [翻译: 在生成式 AI 时代，学习将迎来新变革：借助大型语言模型，实现自动问题生成与评估。](2024年10月12日/The_Future_of_Learning_in_the_Age_of_Generative_AI_Automated_Question_Generation_and_Assessment_with_Large_Language_Models.md)

- [Toward General Instruction-Following Alignment for Retrieval-Augmented Generation](2024年10月12日/Toward_General_Instruction-Following_Alignment_for_Retrieval-Augmented_Generation.md)

    - [翻译: 迈向通用指令遵循与检索增强生成的对齐](2024年10月12日/Toward_General_Instruction-Following_Alignment_for_Retrieval-Augmented_Generation.md)

- [Towards Efficient Visual-Language Alignment of the Q-Former for Visual Reasoning Tasks](2024年10月12日/Towards_Efficient_Visual-Language_Alignment_of_the_Q-Former_for_Visual_Reasoning_Tasks.md)

    - [翻译: 探索 Q-Former 在视觉推理任务中视觉与语言对齐的高效路径](2024年10月12日/Towards_Efficient_Visual-Language_Alignment_of_the_Q-Former_for_Visual_Reasoning_Tasks.md)

- [Training Dynamics of Transformers to Recognize Word Co-occurrence via Gradient Flow Analysis](2024年10月12日/Training_Dynamics_of_Transformers_to_Recognize_Word_Co-occurrence_via_Gradient_Flow_Analysis.md)

    - [翻译: 通过梯度流分析，揭示 Transformer 识别词共现的训练动态](2024年10月12日/Training_Dynamics_of_Transformers_to_Recognize_Word_Co-occurrence_via_Gradient_Flow_Analysis.md)

- [Transformer-based Language Models for Reasoning in the Description Logic ALCQ](2024年10月12日/Transformer-based_Language_Models_for_Reasoning_in_the_Description_Logic_ALCQ.md)

    - [翻译: 基于 Transformer 的语言模型在描述逻辑 ALCQ 中的推理应用](2024年10月12日/Transformer-based_Language_Models_for_Reasoning_in_the_Description_Logic_ALCQ.md)

- [Two Heads Are Better Than One: A Multi-Agent System Has the Potential to Improve Scientific Idea Generation](2024年10月12日/Two_Heads_Are_Better_Than_One_A_Multi-Agent_System_Has_the_Potential_to_Improve_Scientific_Idea_Generation.md)

    - [翻译: 双脑协作，科学创意更上一层楼：多智能体系统助力创新思维](2024年10月12日/Two_Heads_Are_Better_Than_One_A_Multi-Agent_System_Has_the_Potential_to_Improve_Scientific_Idea_Generation.md)

2024年10月11日

- [ACER: Automatic Language Model Context Extension via Retrieval](2024年10月11日/ACER_Automatic_Language_Model_Context_Extension_via_Retrieval.md)

    - [翻译: ACER：利用检索技术自动扩展语言模型的上下文](2024年10月11日/ACER_Automatic_Language_Model_Context_Extension_via_Retrieval.md)

- [A Methodology for Evaluating RAG Systems: A Case Study On Configuration Dependency Validation](2024年10月11日/A_Methodology_for_Evaluating_RAG_Systems_A_Case_Study_On_Configuration_Dependency_Validation.md)

    - [翻译: RAG 系统评估方法论：配置依赖验证案例研究](2024年10月11日/A_Methodology_for_Evaluating_RAG_Systems_A_Case_Study_On_Configuration_Dependency_Validation.md)

- [A Social Context-aware Graph-based Multimodal Attentive Learning Framework for Disaster Content Classification during Emergencies](2024年10月11日/A_Social_Context-aware_Graph-based_Multimodal_Attentive_Learning_Framework_for_Disaster_Content_Classification_during_Emergencies.md)

    - [翻译: 一种基于社交上下文和图结构的多模态注意力学习框架，专为紧急情况下的灾难内容分类设计](2024年10月11日/A_Social_Context-aware_Graph-based_Multimodal_Attentive_Learning_Framework_for_Disaster_Content_Classification_during_Emergencies.md)

- [Audio Description Generation in the Era of LLMs and VLMs: A Review of Transferable Generative AI Technologies](2024年10月11日/Audio_Description_Generation_in_the_Era_of_LLMs_and_VLMs_A_Review_of_Transferable_Generative_AI_Technologies.md)

    - [翻译: 在 LLM 和 VLM 时代，音频描述生成：探索可转移的生成 AI 技术](2024年10月11日/Audio_Description_Generation_in_the_Era_of_LLMs_and_VLMs_A_Review_of_Transferable_Generative_AI_Technologies.md)

- [AutoPersuade: A Framework for Evaluating and Explaining Persuasive Arguments](2024年10月11日/AutoPersuade_A_Framework_for_Evaluating_and_Explaining_Persuasive_Arguments.md)

    - [翻译: AutoPersuade：一款评估与解释说服性论点的框架](2024年10月11日/AutoPersuade_A_Framework_for_Evaluating_and_Explaining_Persuasive_Arguments.md)

- [Dual-AEB: Synergizing Rule-Based and Multimodal Large Language Models for Effective Emergency Braking](2024年10月11日/Dual-AEB_Synergizing_Rule-Based_and_Multimodal_Large_Language_Models_for_Effective_Emergency_Braking.md)

    - [翻译: 双-AEB：融合规则与多模态大型语言模型，实现高效紧急制动](2024年10月11日/Dual-AEB_Synergizing_Rule-Based_and_Multimodal_Large_Language_Models_for_Effective_Emergency_Braking.md)

- [From N-grams to Pre-trained Multilingual Models For Language Identification](2024年10月11日/From_N-grams_to_Pre-trained_Multilingual_Models_For_Language_Identification.md)

    - [翻译: 从 N-grams 到预训练的多语言模型：语言识别的新篇章](2024年10月11日/From_N-grams_to_Pre-trained_Multilingual_Models_For_Language_Identification.md)

- [Hypothesis-only Biases in Large Language Model-Elicited Natural Language Inference](2024年10月11日/Hypothesis-only_Biases_in_Large_Language_Model-Elicited_Natural_Language_Inference.md)

    - [翻译: 大型语言模型在自然语言推理中仅依赖假设的偏差](2024年10月11日/Hypothesis-only_Biases_in_Large_Language_Model-Elicited_Natural_Language_Inference.md)

- [Investigating Human-Computer Interaction and Visual Comprehension in Text Generation Process of Natural Language Generation Models](2024年10月11日/Investigating_Human-Computer_Interaction_and_Visual_Comprehension_in_Text_Generation_Process_of_Natural_Language_Generation_Models.md)

    - [翻译: 探索人类与计算机交互及视觉理解在自然语言生成模型文本生成中的影响](2024年10月11日/Investigating_Human-Computer_Interaction_and_Visual_Comprehension_in_Text_Generation_Process_of_Natural_Language_Generation_Models.md)

- [Language-Model-Assisted Bi-Level Programming for Reward Learning from Internet Videos](2024年10月11日/Language-Model-Assisted_Bi-Level_Programming_for_Reward_Learning_from_Internet_Videos.md)

    - [翻译: 借助语言模型的双层编程，从网络视频中学习奖励机制](2024年10月11日/Language-Model-Assisted_Bi-Level_Programming_for_Reward_Learning_from_Internet_Videos.md)

- [M3Hop-CoT: Misogynous Meme Identification with Multimodal Multi-hop Chain-of-Thought](2024年10月11日/M3Hop-CoT_Misogynous_Meme_Identification_with_Multimodal_Multi-hop_Chain-of-Thought.md)

    - [翻译: M3Hop-CoT：通过多模态多跳链式思维识别厌女表情包](2024年10月11日/M3Hop-CoT_Misogynous_Meme_Identification_with_Multimodal_Multi-hop_Chain-of-Thought.md)

- [Maximizing the Potential of Synthetic Data: Insights from Random Matrix Theory](2024年10月11日/Maximizing_the_Potential_of_Synthetic_Data_Insights_from_Random_Matrix_Theory.md)

    - [翻译: 挖掘合成数据的最大潜力：随机矩阵理论的启示](2024年10月11日/Maximizing_the_Potential_of_Synthetic_Data_Insights_from_Random_Matrix_Theory.md)

- [NoVo: Norm Voting off Hallucinations with Attention Heads in Large Language Models](2024年10月11日/NoVo_Norm_Voting_off_Hallucinations_with_Attention_Heads_in_Large_Language_Models.md)

    - [翻译: NoVo：通过 LLM 中的注意力头规范投票，消除幻觉](2024年10月11日/NoVo_Norm_Voting_off_Hallucinations_with_Attention_Heads_in_Large_Language_Models.md)

- [PILLAR: an AI-Powered Privacy Threat Modeling Tool](2024年10月11日/PILLAR_an_AI-Powered_Privacy_Threat_Modeling_Tool.md)

    - [翻译: PILLAR：一款由 AI 驱动的隐私威胁建模利器](2024年10月11日/PILLAR_an_AI-Powered_Privacy_Threat_Modeling_Tool.md)

- [Preferential Normalizing Flows](2024年10月11日/Preferential_Normalizing_Flows.md)

    - [翻译: 偏好归一化流](2024年10月11日/Preferential_Normalizing_Flows.md)

- [QEFT: Quantization for Efficient Fine-Tuning of LLMs](2024年10月11日/QEFT_Quantization_for_Efficient_Fine-Tuning_of_LLMs.md)

    - [翻译: QEFT：通过量化实现 LLM 的高效微调](2024年10月11日/QEFT_Quantization_for_Efficient_Fine-Tuning_of_LLMs.md)

- [RePD: Defending Jailbreak Attack through a Retrieval-based Prompt Decomposition Process](2024年10月11日/RePD_Defending_Jailbreak_Attack_through_a_Retrieval-based_Prompt_Decomposition_Process.md)

    - [翻译: RePD：利用基于检索的提示分解技术，有效抵御越狱攻击。](2024年10月11日/RePD_Defending_Jailbreak_Attack_through_a_Retrieval-based_Prompt_Decomposition_Process.md)

- [Semi-Supervised Learning of Noisy Mixture of Experts Models](2024年10月11日/Semi-Supervised_Learning_of_Noisy_Mixture_of_Experts_Models.md)

    - [翻译: 半监督噪声混合专家模型学习](2024年10月11日/Semi-Supervised_Learning_of_Noisy_Mixture_of_Experts_Models.md)

- [SimpleStrat: Diversifying Language Model Generation with Stratification](2024年10月11日/SimpleStrat_Diversifying_Language_Model_Generation_with_Stratification.md)

    - [翻译: SimpleStrat：以分层策略丰富语言模型生成多样性](2024年10月11日/SimpleStrat_Diversifying_Language_Model_Generation_with_Stratification.md)

- [SmartPretrain: Model-Agnostic and Dataset-Agnostic Representation Learning for Motion Prediction](2024年10月11日/SmartPretrain_Model-Agnostic_and_Dataset-Agnostic_Representation_Learning_for_Motion_Prediction.md)

    - [翻译: SmartPretrain：一种模型与数据集无关的表示学习方法，专为运动预测设计。](2024年10月11日/SmartPretrain_Model-Agnostic_and_Dataset-Agnostic_Representation_Learning_for_Motion_Prediction.md)

- [SocialGaze: Improving the Integration of Human Social Norms in Large Language Models](2024年10月11日/SocialGaze_Improving_the_Integration_of_Human_Social_Norms_in_Large_Language_Models.md)

    - [翻译: SocialGaze：提升大型语言模型中人类社会规范的融合](2024年10月11日/SocialGaze_Improving_the_Integration_of_Human_Social_Norms_in_Large_Language_Models.md)

- [Software Engineering and Foundation Models: Insights from Industry Blogs Using a Jury of Foundation Models](2024年10月11日/Software_Engineering_and_Foundation_Models_Insights_from_Industry_Blogs_Using_a_Jury_of_Foundation_Models.md)

    - [翻译: 软件工程与基础模型：通过基础模型陪审团，从行业博客中汲取的洞见](2024年10月11日/Software_Engineering_and_Foundation_Models_Insights_from_Industry_Blogs_Using_a_Jury_of_Foundation_Models.md)

- [StructRAG: Boosting Knowledge Intensive Reasoning of LLMs via Inference-time Hybrid Information Structurization](2024年10月11日/StructRAG_Boosting_Knowledge_Intensive_Reasoning_of_LLMs_via_Inference-time_Hybrid_Information_Structurization.md)

    - [翻译: StructRAG：通过推理时的混合信息结构化，大幅提升 LLM 在知识密集型推理中的表现。](2024年10月11日/StructRAG_Boosting_Knowledge_Intensive_Reasoning_of_LLMs_via_Inference-time_Hybrid_Information_Structurization.md)

- [The Dynamics of Social Conventions in LLM populations: Spontaneous Emergence, Collective Biases and Tipping Points](2024年10月11日/The_Dynamics_of_Social_Conventions_in_LLM_populations_Spontaneous_Emergence,_Collective_Biases_and_Tipping_Points.md)

    - [翻译: LLM 群体中的社会规范动态：自发涌现、集体偏见与临界点](2024年10月11日/The_Dynamics_of_Social_Conventions_in_LLM_populations_Spontaneous_Emergence,_Collective_Biases_and_Tipping_Points.md)

- [Underutilized land and sustainable development: effects on employment, economic output, and mitigation of CO2 emissions](2024年10月11日/Underutilized_land_and_sustainable_development_effects_on_employment,_economic_output,_and_mitigation_of_CO2_emissions.md)

    - [翻译: 未充分利用的土地与可持续发展息息相关，影响着就业、经济产出及二氧化碳减排。](2024年10月11日/Underutilized_land_and_sustainable_development_effects_on_employment,_economic_output,_and_mitigation_of_CO2_emissions.md)

- [Unveiling Molecular Secrets: An LLM-Augmented Linear Model for Explainable and Calibratable Molecular Property Prediction](2024年10月11日/Unveiling_Molecular_Secrets_An_LLM-Augmented_Linear_Model_for_Explainable_and_Calibratable_Molecular_Property_Prediction.md)

    - [翻译: 揭秘分子奥秘：LLM 增强的线性模型助力可解释与可校准的分子属性预测](2024年10月11日/Unveiling_Molecular_Secrets_An_LLM-Augmented_Linear_Model_for_Explainable_and_Calibratable_Molecular_Property_Prediction.md)

- [Utilizing ChatGPT in a Data Structures and Algorithms Course: A Teaching Assistant's Perspective](2024年10月11日/Utilizing_ChatGPT_in_a_Data_Structures_and_Algorithms_Course_A_Teaching_Assistant's_Perspective.md)

    - [翻译: ChatGPT 在数据结构与算法课程中的应用：一位助教的视角](2024年10月11日/Utilizing_ChatGPT_in_a_Data_Structures_and_Algorithms_Course_A_Teaching_Assistant's_Perspective.md)

- [When Graph meets Multimodal: Benchmarking on Multimodal Attributed Graphs Learning](2024年10月11日/When_Graph_meets_Multimodal_Benchmarking_on_Multimodal_Attributed_Graphs_Learning.md)

    - [翻译: 图与多模态的邂逅：多模态属性图学习的基准测试](2024年10月11日/When_Graph_meets_Multimodal_Benchmarking_on_Multimodal_Attributed_Graphs_Learning.md)

2024年10月10日

- [Increasing the Difficulty of Automatically Generated Questions via Reinforcement Learning with Synthetic Preference](2024年10月10日/Increasing_the_Difficulty_of_Automatically_Generated_Questions_via_Reinforcement_Learning_with_Synthetic_Preference.md)

    - [翻译: 利用强化学习与合成偏好提升自动生成问题的难度](2024年10月10日/Increasing_the_Difficulty_of_Automatically_Generated_Questions_via_Reinforcement_Learning_with_Synthetic_Preference.md)

- [Large Legislative Models: Towards Efficient AI Policymaking in Economic Simulations](2024年10月10日/Large_Legislative_Models_Towards_Efficient_AI_Policymaking_in_Economic_Simulations.md)

    - [翻译: 大型立法模型：助力经济模拟中的高效 AI 政策制定](2024年10月10日/Large_Legislative_Models_Towards_Efficient_AI_Policymaking_in_Economic_Simulations.md)

- [SPORTU: A Comprehensive Sports Understanding Benchmark for Multimodal Large Language Models](2024年10月10日/SPORTU_A_Comprehensive_Sports_Understanding_Benchmark_for_Multimodal_Large_Language_Models.md)

    - [翻译: SPORTU：专为多模态大型语言模型设计的综合性体育理解基准](2024年10月10日/SPORTU_A_Comprehensive_Sports_Understanding_Benchmark_for_Multimodal_Large_Language_Models.md)

2024年10月09日

- [Pixtral 12B](2024年10月09日/Pixtral_12B.md)

    - [翻译: Pixtral 12B](2024年10月09日/Pixtral_12B.md)

2024年10月08日

- [Automating Bibliometric Analysis with Sentence Transformers and Retrieval-Augmented Generation (RAG): A Pilot Study in Semantic and Contextual Search for Customized Literature Characterization for High-Impact Urban Research](2024年10月08日/Automating_Bibliometric_Analysis_with_Sentence_Transformers_and_Retrieval-Augmented_Generation_(RAG)_A_Pilot_Study_in_Semantic_and_Contextual_Search_for_Customized_Literature_Characterization_for_High-Impact_Urban_Research.md)

    - [翻译: 利用 Sentence Transformers 和 RAG 技术，我们开展了一项试点研究，旨在自动化文献计量分析，通过语义和上下文搜索为高影响力城市研究定制文献特征。](2024年10月08日/Automating_Bibliometric_Analysis_with_Sentence_Transformers_and_Retrieval-Augmented_Generation_(RAG)_A_Pilot_Study_in_Semantic_and_Contextual_Search_for_Customized_Literature_Characterization_for_High-Impact_Urban_Research.md)

2024年10月04日

- [A Large Language Model-based Framework for Semi-Structured Tender Document Retrieval-Augmented Generation](2024年10月04日/A_Large_Language_Model-based_Framework_for_Semi-Structured_Tender_Document_Retrieval-Augmented_Generation.md)

    - [翻译: 大型语言模型驱动的半结构化招标文件检索与生成框架](2024年10月04日/A_Large_Language_Model-based_Framework_for_Semi-Structured_Tender_Document_Retrieval-Augmented_Generation.md)

2024年10月01日

- [nGPT: Normalized Transformer with Representation Learning on the Hypersphere](2024年10月01日/nGPT_Normalized_Transformer_with_Representation_Learning_on_the_Hypersphere.md)

    - [翻译: nGPT：超球面表示学习的归一化Transformer](2024年10月01日/nGPT_Normalized_Transformer_with_Representation_Learning_on_the_Hypersphere.md)