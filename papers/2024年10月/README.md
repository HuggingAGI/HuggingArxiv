# 2024年10月

2024年10月16日

- [Aegis:An Advanced LLM-Based Multi-Agent for Intelligent Functional Safety Engineering](2024年10月16日/AegisAn_Advanced_LLM-Based_Multi-Agent_for_Intelligent_Functional_Safety_Engineering.md)

    - [翻译: Aegis：基于先进 LLM 的多智能体系统，专为智能功能安全工程设计](2024年10月16日/AegisAn_Advanced_LLM-Based_Multi-Agent_for_Intelligent_Functional_Safety_Engineering.md)

- [Benchmarking Defeasible Reasoning with Large Language Models -- Initial Experiments and Future Directions](2024年10月16日/Benchmarking_Defeasible_Reasoning_with_Large_Language_Models_--_Initial_Experiments_and_Future_Directions.md)

    - [翻译: 大型语言模型的可废止推理基准测试——初探与展望](2024年10月16日/Benchmarking_Defeasible_Reasoning_with_Large_Language_Models_--_Initial_Experiments_and_Future_Directions.md)

- [Bridging the Language Gaps in Large Language Models with Inference-Time Cross-Lingual Intervention](2024年10月16日/Bridging_the_Language_Gaps_in_Large_Language_Models_with_Inference-Time_Cross-Lingual_Intervention.md)

    - [翻译: 通过推理时的跨语言干预，弥合大型语言模型中的语言鸿沟](2024年10月16日/Bridging_the_Language_Gaps_in_Large_Language_Models_with_Inference-Time_Cross-Lingual_Intervention.md)

- [Can We Reverse In-Context Knowledge Edits?](2024年10月16日/Can_We_Reverse_In-Context_Knowledge_Edits.md)

    - [翻译: 上下文知识编辑能否被逆转？](2024年10月16日/Can_We_Reverse_In-Context_Knowledge_Edits.md)

- [CCSBench: Evaluating Compositional Controllability in LLMs for Scientific Document Summarization](2024年10月16日/CCSBench_Evaluating_Compositional_Controllability_in_LLMs_for_Scientific_Document_Summarization.md)

    - [翻译: CCSBench：科学文档摘要中 LLM 组合可控性的评估工具](2024年10月16日/CCSBench_Evaluating_Compositional_Controllability_in_LLMs_for_Scientific_Document_Summarization.md)

- [CoFE-RAG: A Comprehensive Full-chain Evaluation Framework for Retrieval-Augmented Generation with Enhanced Data Diversity](2024年10月16日/CoFE-RAG_A_Comprehensive_Full-chain_Evaluation_Framework_for_Retrieval-Augmented_Generation_with_Enhanced_Data_Diversity.md)

    - [翻译: CoFE-RAG：一个全面的全链路评估框架，专为提升数据多样性的检索增强生成而设计。](2024年10月16日/CoFE-RAG_A_Comprehensive_Full-chain_Evaluation_Framework_for_Retrieval-Augmented_Generation_with_Enhanced_Data_Diversity.md)

- [Conformity in Large Language Models](2024年10月16日/Conformity_in_Large_Language_Models.md)

    - [翻译: 大型语言模型中的从众现象](2024年10月16日/Conformity_in_Large_Language_Models.md)

- [CREAM: Consistency Regularized Self-Rewarding Language Models](2024年10月16日/CREAM_Consistency_Regularized_Self-Rewarding_Language_Models.md)

    - [翻译: CREAM：一致性正则化自我奖励语言模型](2024年10月16日/CREAM_Consistency_Regularized_Self-Rewarding_Language_Models.md)

- [DocLayout-YOLO: Enhancing Document Layout Analysis through Diverse Synthetic Data and Global-to-Local Adaptive Perception](2024年10月16日/DocLayout-YOLO_Enhancing_Document_Layout_Analysis_through_Diverse_Synthetic_Data_and_Global-to-Local_Adaptive_Perception.md)

    - [翻译: DocLayout-YOLO：利用多样化合成数据和全局到局部的自适应感知，提升文档布局分析能力](2024年10月16日/DocLayout-YOLO_Enhancing_Document_Layout_Analysis_through_Diverse_Synthetic_Data_and_Global-to-Local_Adaptive_Perception.md)

- [Efficient and Effective Universal Adversarial Attack against Vision-Language Pre-training Models](2024年10月16日/Efficient_and_Effective_Universal_Adversarial_Attack_against_Vision-Language_Pre-training_Models.md)

    - [翻译: 针对视觉-语言预训练模型，我们提出了一种既高效又有效的通用对抗攻击方法。](2024年10月16日/Efficient_and_Effective_Universal_Adversarial_Attack_against_Vision-Language_Pre-training_Models.md)

- [Efficient Diffusion Models: A Comprehensive Survey from Principles to Practices](2024年10月16日/Efficient_Diffusion_Models_A_Comprehensive_Survey_from_Principles_to_Practices.md)

    - [翻译: 高效扩散模型：从理论到应用的全面解析](2024年10月16日/Efficient_Diffusion_Models_A_Comprehensive_Survey_from_Principles_to_Practices.md)

- [Embedding an Ethical Mind: Aligning Text-to-Image Synthesis via Lightweight Value Optimization](2024年10月16日/Embedding_an_Ethical_Mind_Aligning_Text-to-Image_Synthesis_via_Lightweight_Value_Optimization.md)

    - [翻译: 以伦理为导向：通过轻量级优化实现文本到图像合成的价值对齐](2024年10月16日/Embedding_an_Ethical_Mind_Aligning_Text-to-Image_Synthesis_via_Lightweight_Value_Optimization.md)

- [Enhancing LLM Agents for Code Generation with Possibility and Pass-rate Prioritized Experience Replay](2024年10月16日/Enhancing_LLM_Agents_for_Code_Generation_with_Possibility_and_Pass-rate_Prioritized_Experience_Replay.md)

    - [翻译: 提升 LLM 代理代码生成：可能性与通过率优先的经验回放策略](2024年10月16日/Enhancing_LLM_Agents_for_Code_Generation_with_Possibility_and_Pass-rate_Prioritized_Experience_Replay.md)

- [Enhancing LLM Trading Performance with Fact-Subjectivity Aware Reasoning](2024年10月16日/Enhancing_LLM_Trading_Performance_with_Fact-Subjectivity_Aware_Reasoning.md)

    - [翻译: 利用事实与主观性意识推理，提升 LLM 在交易中的表现](2024年10月16日/Enhancing_LLM_Trading_Performance_with_Fact-Subjectivity_Aware_Reasoning.md)

- [ERVQ: Enhanced Residual Vector Quantization with Intra-and-Inter-Codebook Optimization for Neural Audio Codecs](2024年10月16日/ERVQ_Enhanced_Residual_Vector_Quantization_with_Intra-and-Inter-Codebook_Optimization_for_Neural_Audio_Codecs.md)

    - [翻译: ERVQ：通过代码本内外的优化，增强残差向量量化，应用于神经音频编解码器](2024年10月16日/ERVQ_Enhanced_Residual_Vector_Quantization_with_Intra-and-Inter-Codebook_Optimization_for_Neural_Audio_Codecs.md)

- [Evaluating Morphological Compositional Generalization in Large Language Models](2024年10月16日/Evaluating_Morphological_Compositional_Generalization_in_Large_Language_Models.md)

    - [翻译: 探究大型语言模型中的形态组合泛化能力](2024年10月16日/Evaluating_Morphological_Compositional_Generalization_in_Large_Language_Models.md)

- [Evaluating Software Development Agents: Patch Patterns, Code Quality, and Issue Complexity in Real-World GitHub Scenarios](2024年10月16日/Evaluating_Software_Development_Agents_Patch_Patterns,_Code_Quality,_and_Issue_Complexity_in_Real-World_GitHub_Scenarios.md)

    - [翻译: 评估软件开发代理：探究 GitHub 真实场景中的补丁模式、代码质量与问题复杂性](2024年10月16日/Evaluating_Software_Development_Agents_Patch_Patterns,_Code_Quality,_and_Issue_Complexity_in_Real-World_GitHub_Scenarios.md)

- [Evaluation of Attribution Bias in Retrieval-Augmented Large Language Models](2024年10月16日/Evaluation_of_Attribution_Bias_in_Retrieval-Augmented_Large_Language_Models.md)

    - [翻译: 探究检索增强型大型语言模型中的归因偏差](2024年10月16日/Evaluation_of_Attribution_Bias_in_Retrieval-Augmented_Large_Language_Models.md)

- [Expanding Chatbot Knowledge in Customer Service: Context-Aware Similar Question Generation Using Large Language Models](2024年10月16日/Expanding_Chatbot_Knowledge_in_Customer_Service_Context-Aware_Similar_Question_Generation_Using_Large_Language_Models.md)

    - [翻译: 在客户服务中提升聊天机器人知识：利用大型语言模型生成上下文感知的相似问题](2024年10月16日/Expanding_Chatbot_Knowledge_in_Customer_Service_Context-Aware_Similar_Question_Generation_Using_Large_Language_Models.md)

- [Explainable Moral Values: a neuro-symbolic approach to value classification](2024年10月16日/Explainable_Moral_Values_a_neuro-symbolic_approach_to_value_classification.md)

    - [翻译: 道德价值观的可解释性：神经符号方法在价值分类中的应用](2024年10月16日/Explainable_Moral_Values_a_neuro-symbolic_approach_to_value_classification.md)

- [Exploring Model Kinship for Merging Large Language Models](2024年10月16日/Exploring_Model_Kinship_for_Merging_Large_Language_Models.md)

    - [翻译: 探究合并大型语言模型的模型亲缘关系](2024年10月16日/Exploring_Model_Kinship_for_Merging_Large_Language_Models.md)

- [FiRST: Finetuning Router-Selective Transformers for Input-Adaptive Latency Reduction](2024年10月16日/FiRST_Finetuning_Router-Selective_Transformers_for_Input-Adaptive_Latency_Reduction.md)

    - [翻译: FiRST：通过微调路由器选择性变压器，实现输入自适应的延迟降低](2024年10月16日/FiRST_Finetuning_Router-Selective_Transformers_for_Input-Adaptive_Latency_Reduction.md)

- [FTII-Bench: A Comprehensive Multimodal Benchmark for Flow Text with Image Insertion](2024年10月16日/FTII-Bench_A_Comprehensive_Multimodal_Benchmark_for_Flow_Text_with_Image_Insertion.md)

    - [翻译: FTII-Bench：一款全面的多模态基准，专为插入图像的流文本设计](2024年10月16日/FTII-Bench_A_Comprehensive_Multimodal_Benchmark_for_Flow_Text_with_Image_Insertion.md)

- [FusionLLM: A Decentralized LLM Training System on Geo-distributed GPUs with Adaptive Compression](2024年10月16日/FusionLLM_A_Decentralized_LLM_Training_System_on_Geo-distributed_GPUs_with_Adaptive_Compression.md)

    - [翻译: FusionLLM：一款基于地理分布 GPU 的自适应压缩分散式 LLM 训练系统](2024年10月16日/FusionLLM_A_Decentralized_LLM_Training_System_on_Geo-distributed_GPUs_with_Adaptive_Compression.md)

- [HerO at AVeriTeC: The Herd of Open Large Language Models for Verifying Real-World Claims](2024年10月16日/HerO_at_AVeriTeC_The_Herd_of_Open_Large_Language_Models_for_Verifying_Real-World_Claims.md)

    - [翻译: HerO 在 AVeriTeC：一群用于验证现实声明的开源大型语言模型](2024年10月16日/HerO_at_AVeriTeC_The_Herd_of_Open_Large_Language_Models_for_Verifying_Real-World_Claims.md)

- [HumanEval-V: Evaluating Visual Understanding and Reasoning Abilities of Large Multimodal Models Through Coding Tasks](2024年10月16日/HumanEval-V_Evaluating_Visual_Understanding_and_Reasoning_Abilities_of_Large_Multimodal_Models_Through_Coding_Tasks.md)

    - [翻译: HumanEval-V：通过编码任务，评估大型多模态模型在视觉理解和推理方面的表现。](2024年10月16日/HumanEval-V_Evaluating_Visual_Understanding_and_Reasoning_Abilities_of_Large_Multimodal_Models_Through_Coding_Tasks.md)

- [Identifying Task Groupings for Multi-Task Learning Using Pointwise V-Usable Information](2024年10月16日/Identifying_Task_Groupings_for_Multi-Task_Learning_Using_Pointwise_V-Usable_Information.md)

    - [翻译: 利用 Pointwise V-Usable Information 进行多任务学习中的任务分组识别](2024年10月16日/Identifying_Task_Groupings_for_Multi-Task_Learning_Using_Pointwise_V-Usable_Information.md)

- [In-Context Learning Enables Robot Action Prediction in LLMs](2024年10月16日/In-Context_Learning_Enables_Robot_Action_Prediction_in_LLMs.md)

    - [翻译: 上下文学习让 LLM 能够预测机器人动作](2024年10月16日/In-Context_Learning_Enables_Robot_Action_Prediction_in_LLMs.md)

- [Insights from the Inverse: Reconstructing LLM Training Goals Through Inverse RL](2024年10月16日/Insights_from_the_Inverse_Reconstructing_LLM_Training_Goals_Through_Inverse_RL.md)

    - [翻译: 逆向思考：用逆向强化学习重构 LLM 训练目标](2024年10月16日/Insights_from_the_Inverse_Reconstructing_LLM_Training_Goals_Through_Inverse_RL.md)

- [KcMF: A Knowledge-compliant Framework for Schema and Entity Matching with Fine-tuning-free LLMs](2024年10月16日/KcMF_A_Knowledge-compliant_Framework_for_Schema_and_Entity_Matching_with_Fine-tuning-free_LLMs.md)

    - [翻译: KcMF：一个无需微调的大型语言模型框架，专为模式和实体匹配设计，确保知识合规性。](2024年10月16日/KcMF_A_Knowledge-compliant_Framework_for_Schema_and_Entity_Matching_with_Fine-tuning-free_LLMs.md)

- [Learning to Predict Usage Options of Product Reviews with LLM-Generated Labels](2024年10月16日/Learning_to_Predict_Usage_Options_of_Product_Reviews_with_LLM-Generated_Labels.md)

    - [翻译: 利用 LLM 生成的标签，学习预测产品评论的使用场景](2024年10月16日/Learning_to_Predict_Usage_Options_of_Product_Reviews_with_LLM-Generated_Labels.md)

- [LLM-based Translation Inference with Iterative Bilingual Understanding](2024年10月16日/LLM-based_Translation_Inference_with_Iterative_Bilingual_Understanding.md)

    - [翻译: 基于LLM的翻译推理：迭代双语理解](2024年10月16日/LLM-based_Translation_Inference_with_Iterative_Bilingual_Understanding.md)

- [MC-Bench: A Benchmark for Multi-Context Visual Grounding in the Era of MLLMs](2024年10月16日/MC-Bench_A_Benchmark_for_Multi-Context_Visual_Grounding_in_the_Era_of_MLLMs.md)

    - [翻译: MC-Bench：MLLM 时代下的多上下文视觉定位基准](2024年10月16日/MC-Bench_A_Benchmark_for_Multi-Context_Visual_Grounding_in_the_Era_of_MLLMs.md)

- [MedAide: Towards an Omni Medical Aide via Specialized LLM-based Multi-Agent Collaboration](2024年10月16日/MedAide_Towards_an_Omni_Medical_Aide_via_Specialized_LLM-based_Multi-Agent_Collaboration.md)

    - [翻译: MedAide：借助基于 LLM 的专门化多代理协作，迈向全方位医疗助手](2024年10月16日/MedAide_Towards_an_Omni_Medical_Aide_via_Specialized_LLM-based_Multi-Agent_Collaboration.md)

- [MlingConf: A Comprehensive Study of Multilingual Confidence Estimation on Large Language Models](2024年10月16日/MlingConf_A_Comprehensive_Study_of_Multilingual_Confidence_Estimation_on_Large_Language_Models.md)

    - [翻译: MlingConf：大型语言模型多语言置信度估计的全面探索](2024年10月16日/MlingConf_A_Comprehensive_Study_of_Multilingual_Confidence_Estimation_on_Large_Language_Models.md)

- [Neuron-based Personality Trait Induction in Large Language Models](2024年10月16日/Neuron-based_Personality_Trait_Induction_in_Large_Language_Models.md)

    - [翻译: 在大语言模型中，通过神经元诱导人格特质](2024年10月16日/Neuron-based_Personality_Trait_Induction_in_Large_Language_Models.md)

- [Not All Votes Count! Programs as Verifiers Improve Self-Consistency of Language Models for Math Reasoning](2024年10月16日/Not_All_Votes_Count!_Programs_as_Verifiers_Improve_Self-Consistency_of_Language_Models_for_Math_Reasoning.md)

    - [翻译: 并非所有投票都有效！通过程序验证，语言模型在数学推理中的自我一致性得以提升。](2024年10月16日/Not_All_Votes_Count!_Programs_as_Verifiers_Improve_Self-Consistency_of_Language_Models_for_Math_Reasoning.md)

- [On the Risk of Evidence Pollution for Malicious Social Text Detection in the Era of LLMs](2024年10月16日/On_the_Risk_of_Evidence_Pollution_for_Malicious_Social_Text_Detection_in_the_Era_of_LLMs.md)

    - [翻译: 在 LLM 时代，恶意社交文本检测面临证据污染的风险。](2024年10月16日/On_the_Risk_of_Evidence_Pollution_for_Malicious_Social_Text_Detection_in_the_Era_of_LLMs.md)

- [On the Utility of Domain Modeling Assistance with Large Language Models](2024年10月16日/On_the_Utility_of_Domain_Modeling_Assistance_with_Large_Language_Models.md)

    - [翻译: 探讨大型语言模型在领域建模中的辅助作用](2024年10月16日/On_the_Utility_of_Domain_Modeling_Assistance_with_Large_Language_Models.md)

- [Open Domain Question Answering with Conflicting Contexts](2024年10月16日/Open_Domain_Question_Answering_with_Conflicting_Contexts.md)

    - [翻译: 开放领域问答中的冲突上下文](2024年10月16日/Open_Domain_Question_Answering_with_Conflicting_Contexts.md)

- [Optimizing Low-Resource Language Model Training: Comprehensive Analysis of Multi-Epoch, Multi-Lingual, and Two-Stage Approaches](2024年10月16日/Optimizing_Low-Resource_Language_Model_Training_Comprehensive_Analysis_of_Multi-Epoch,_Multi-Lingual,_and_Two-Stage_Approaches.md)

    - [翻译: 优化低资源语言模型训练：深入探讨多时期、多语言及两阶段策略的综合分析](2024年10月16日/Optimizing_Low-Resource_Language_Model_Training_Comprehensive_Analysis_of_Multi-Epoch,_Multi-Lingual,_and_Two-Stage_Approaches.md)

- [PRefLexOR: Preference-based Recursive Language Modeling for Exploratory Optimization of Reasoning and Agentic Thinking](2024年10月16日/PRefLexOR_Preference-based_Recursive_Language_Modeling_for_Exploratory_Optimization_of_Reasoning_and_Agentic_Thinking.md)

    - [翻译: PRefLexOR：基于偏好的递归语言建模，旨在探索性优化推理与代理思维](2024年10月16日/PRefLexOR_Preference-based_Recursive_Language_Modeling_for_Exploratory_Optimization_of_Reasoning_and_Agentic_Thinking.md)

- [Proactive Agent: Shifting LLM Agents from Reactive Responses to Active Assistance](2024年10月16日/Proactive_Agent_Shifting_LLM_Agents_from_Reactive_Responses_to_Active_Assistance.md)

    - [翻译: 主动代理：让 LLM 代理从被动响应转变为主动协助](2024年10月16日/Proactive_Agent_Shifting_LLM_Agents_from_Reactive_Responses_to_Active_Assistance.md)

- [Prompt Compression for Large Language Models: A Survey](2024年10月16日/Prompt_Compression_for_Large_Language_Models_A_Survey.md)

    - [翻译: 大型语言模型的提示压缩：全面调查](2024年10月16日/Prompt_Compression_for_Large_Language_Models_A_Survey.md)

- [ProSA: Assessing and Understanding the Prompt Sensitivity of LLMs](2024年10月16日/ProSA_Assessing_and_Understanding_the_Prompt_Sensitivity_of_LLMs.md)

    - [翻译: ProSA：探索与评估 LLM 对提示的敏感性](2024年10月16日/ProSA_Assessing_and_Understanding_the_Prompt_Sensitivity_of_LLMs.md)

- [Pyramid-Driven Alignment: Pyramid Principle Guided Integration of Large Language Models and Knowledge Graphs](2024年10月16日/Pyramid-Driven_Alignment_Pyramid_Principle_Guided_Integration_of_Large_Language_Models_and_Knowledge_Graphs.md)

    - [翻译: 金字塔驱动对齐：以金字塔原则为指导，整合大型语言模型与知识图谱](2024年10月16日/Pyramid-Driven_Alignment_Pyramid_Principle_Guided_Integration_of_Large_Language_Models_and_Knowledge_Graphs.md)

- [Reconstruction of Differentially Private Text Sanitization via Large Language Models](2024年10月16日/Reconstruction_of_Differentially_Private_Text_Sanitization_via_Large_Language_Models.md)

    - [翻译: 利用大型语言模型重建差分隐私文本净化](2024年10月16日/Reconstruction_of_Differentially_Private_Text_Sanitization_via_Large_Language_Models.md)

- [Retrieval-Reasoning Large Language Model-based Synthetic Clinical Trial Generation](2024年10月16日/Retrieval-Reasoning_Large_Language_Model-based_Synthetic_Clinical_Trial_Generation.md)

    - [翻译: 基于检索与推理的大型语言模型，用于合成临床试验的生成](2024年10月16日/Retrieval-Reasoning_Large_Language_Model-based_Synthetic_Clinical_Trial_Generation.md)

- [Revealing the Barriers of Language Agents in Planning](2024年10月16日/Revealing_the_Barriers_of_Language_Agents_in_Planning.md)

    - [翻译: 探究语言代理在规划过程中面临的挑战](2024年10月16日/Revealing_the_Barriers_of_Language_Agents_in_Planning.md)

- [Reversal of Thought: Enhancing Large Language Models with Preference-Guided Reverse Reasoning Warm-up](2024年10月16日/Reversal_of_Thought_Enhancing_Large_Language_Models_with_Preference-Guided_Reverse_Reasoning_Warm-up.md)

    - [翻译: 反转思维：借助偏好引导的反向推理预热，提升大型语言模型的性能](2024年10月16日/Reversal_of_Thought_Enhancing_Large_Language_Models_with_Preference-Guided_Reverse_Reasoning_Warm-up.md)

- [Revisited Large Language Model for Time Series Analysis through Modality Alignment](2024年10月16日/Revisited_Large_Language_Model_for_Time_Series_Analysis_through_Modality_Alignment.md)

    - [翻译: 通过模态对齐，重新探索大型语言模型在时间序列分析中的应用。](2024年10月16日/Revisited_Large_Language_Model_for_Time_Series_Analysis_through_Modality_Alignment.md)

- [Revisiting Benchmark and Assessment: An Agent-based Exploratory Dynamic Evaluation Framework for LLMs](2024年10月16日/Revisiting_Benchmark_and_Assessment_An_Agent-based_Exploratory_Dynamic_Evaluation_Framework_for_LLMs.md)

    - [翻译: 重审基准与评估：为大型语言模型构建基于代理的探索性动态评估框架](2024年10月16日/Revisiting_Benchmark_and_Assessment_An_Agent-based_Exploratory_Dynamic_Evaluation_Framework_for_LLMs.md)

- [Robust RL with LLM-Driven Data Synthesis and Policy Adaptation for Autonomous Driving](2024年10月16日/Robust_RL_with_LLM-Driven_Data_Synthesis_and_Policy_Adaptation_for_Autonomous_Driving.md)

    - [翻译: 基于 LLM 数据合成与策略适应的鲁棒强化学习，助力自动驾驶技术发展](2024年10月16日/Robust_RL_with_LLM-Driven_Data_Synthesis_and_Policy_Adaptation_for_Autonomous_Driving.md)

- [RosePO: Aligning LLM-based Recommenders with Human Values](2024年10月16日/RosePO_Aligning_LLM-based_Recommenders_with_Human_Values.md)

    - [翻译: RosePO：让基于 LLM 的推荐系统与人类价值观和谐共舞](2024年10月16日/RosePO_Aligning_LLM-based_Recommenders_with_Human_Values.md)

- [SAC-GLAM: Improving Online RL for LLM agents with Soft Actor-Critic and Hindsight Relabeling](2024年10月16日/SAC-GLAM_Improving_Online_RL_for_LLM_agents_with_Soft_Actor-Critic_and_Hindsight_Relabeling.md)

    - [翻译: SAC-GLAM：结合软演员-评论家与事后重标记，提升 LLM 代理的在线强化学习效果。](2024年10月16日/SAC-GLAM_Improving_Online_RL_for_LLM_agents_with_Soft_Actor-Critic_and_Hindsight_Relabeling.md)

- [Sarcasm Detection in a Less-Resourced Language](2024年10月16日/Sarcasm_Detection_in_a_Less-Resourced_Language.md)

    - [翻译: 在资源匮乏的语言中识别讽刺](2024年10月16日/Sarcasm_Detection_in_a_Less-Resourced_Language.md)

- [Semantics-Adaptive Activation Intervention for LLMs via Dynamic Steering Vectors](2024年10月16日/Semantics-Adaptive_Activation_Intervention_for_LLMs_via_Dynamic_Steering_Vectors.md)

    - [翻译: 利用动态转向向量实现 LLM 的语义自适应激活干预](2024年10月16日/Semantics-Adaptive_Activation_Intervention_for_LLMs_via_Dynamic_Steering_Vectors.md)

- [SF-Speech: Straightened Flow for Zero-Shot Voice Clone on Small-Scale Dataset](2024年10月16日/SF-Speech_Straightened_Flow_for_Zero-Shot_Voice_Clone_on_Small-Scale_Dataset.md)

    - [翻译: SF-Speech：小规模数据集上的零-shot 语音克隆直流技术](2024年10月16日/SF-Speech_Straightened_Flow_for_Zero-Shot_Voice_Clone_on_Small-Scale_Dataset.md)

- [ShapefileGPT: A Multi-Agent Large Language Model Framework for Automated Shapefile Processing](2024年10月16日/ShapefileGPT_A_Multi-Agent_Large_Language_Model_Framework_for_Automated_Shapefile_Processing.md)

    - [翻译: ShapefileGPT：一款专为自动化 Shapefile 处理设计的多智能体大型语言模型框架](2024年10月16日/ShapefileGPT_A_Multi-Agent_Large_Language_Model_Framework_for_Automated_Shapefile_Processing.md)

- [StyleDistance: Stronger Content-Independent Style Embeddings with Synthetic Parallel Examples](2024年10月16日/StyleDistance_Stronger_Content-Independent_Style_Embeddings_with_Synthetic_Parallel_Examples.md)

    - [翻译: StyleDistance：通过合成并行示例，实现更强大的内容无关风格嵌入](2024年10月16日/StyleDistance_Stronger_Content-Independent_Style_Embeddings_with_Synthetic_Parallel_Examples.md)

- [The Best of Both Worlds: Bridging Quality and Diversity in Data Selection with Bipartite Graph](2024年10月16日/The_Best_of_Both_Worlds_Bridging_Quality_and_Diversity_in_Data_Selection_with_Bipartite_Graph.md)

    - [翻译: 双赢之道：利用二分图在数据选择中兼顾质量和多样性](2024年10月16日/The_Best_of_Both_Worlds_Bridging_Quality_and_Diversity_in_Data_Selection_with_Bipartite_Graph.md)

- [Towards Zero-Shot Camera Trap Image Categorization](2024年10月16日/Towards_Zero-Shot_Camera_Trap_Image_Categorization.md)

    - [翻译: 迈向零-shot 相机陷阱图像分类](2024年10月16日/Towards_Zero-Shot_Camera_Trap_Image_Categorization.md)

- [Understanding the Role of LLMs in Multimodal Evaluation Benchmarks](2024年10月16日/Understanding_the_Role_of_LLMs_in_Multimodal_Evaluation_Benchmarks.md)

    - [翻译: 探究 LLM 在多模态评估中的作用](2024年10月16日/Understanding_the_Role_of_LLMs_in_Multimodal_Evaluation_Benchmarks.md)

- [UTF:Undertrained Tokens as Fingerprints A Novel Approach to LLM Identification](2024年10月16日/UTFUndertrained_Tokens_as_Fingerprints_A_Novel_Approach_to_LLM_Identification.md)

    - [翻译: UTF: 利用未充分训练的 Token 作为指纹，开创了一种识别 LLM 的新途径。](2024年10月16日/UTFUndertrained_Tokens_as_Fingerprints_A_Novel_Approach_to_LLM_Identification.md)

- [VividMed: Vision Language Model with Versatile Visual Grounding for Medicine](2024年10月16日/VividMed_Vision_Language_Model_with_Versatile_Visual_Grounding_for_Medicine.md)

    - [翻译: VividMed：一款专为医学领域设计的多功能视觉语言模型，具备强大的视觉基础能力。](2024年10月16日/VividMed_Vision_Language_Model_with_Versatile_Visual_Grounding_for_Medicine.md)

- [Weak-to-Strong Generalization beyond Accuracy: a Pilot Study in Safety, Toxicity, and Legal Reasoning](2024年10月16日/Weak-to-Strong_Generalization_beyond_Accuracy_a_Pilot_Study_in_Safety,_Toxicity,_and_Legal_Reasoning.md)

    - [翻译: 超越准确性：探索从弱到强的泛化在安全、毒性和法律推理中的应用](2024年10月16日/Weak-to-Strong_Generalization_beyond_Accuracy_a_Pilot_Study_in_Safety,_Toxicity,_and_Legal_Reasoning.md)

- [With a Grain of SALT: Are LLMs Fair Across Social Dimensions?](2024年10月16日/With_a_Grain_of_SALT_Are_LLMs_Fair_Across_Social_Dimensions.md)

    - [翻译: LLM 是否在社会维度上公平？让我们带着批判的眼光来探讨。](2024年10月16日/With_a_Grain_of_SALT_Are_LLMs_Fair_Across_Social_Dimensions.md)

- [WorldMedQA-V: a multilingual, multimodal medical examination dataset for multimodal language models evaluation](2024年10月16日/WorldMedQA-V_a_multilingual,_multimodal_medical_examination_dataset_for_multimodal_language_models_evaluation.md)

    - [翻译: WorldMedQA-V：一款专为多模态语言模型评估设计的多语言、多模态医学考试数据集](2024年10月16日/WorldMedQA-V_a_multilingual,_multimodal_medical_examination_dataset_for_multimodal_language_models_evaluation.md)

2024年10月15日

- [Advanced Persistent Threats (APT) Attribution Using Deep Reinforcement Learning](2024年10月15日/Advanced_Persistent_Threats_(APT)_Attribution_Using_Deep_Reinforcement_Learning.md)

    - [翻译: 利用深度强化学习技术，精准归因高级持续威胁（APT）](2024年10月15日/Advanced_Persistent_Threats_(APT)_Attribution_Using_Deep_Reinforcement_Learning.md)

- [A Framework for Adapting Human-Robot Interaction to Diverse User Groups](2024年10月15日/A_Framework_for_Adapting_Human-Robot_Interaction_to_Diverse_User_Groups.md)

    - [翻译: 人机交互框架，灵活适应多元用户群体](2024年10月15日/A_Framework_for_Adapting_Human-Robot_Interaction_to_Diverse_User_Groups.md)

- [AGENTiGraph: An Interactive Knowledge Graph Platform for LLM-based Chatbots Utilizing Private Data](2024年10月15日/AGENTiGraph_An_Interactive_Knowledge_Graph_Platform_for_LLM-based_Chatbots_Utilizing_Private_Data.md)

    - [翻译: AGENTiGraph：专为基于 LLM 的聊天机器人设计的交互式知识图谱平台，充分利用私有数据。](2024年10月15日/AGENTiGraph_An_Interactive_Knowledge_Graph_Platform_for_LLM-based_Chatbots_Utilizing_Private_Data.md)

- [A Hitchhiker's Guide to Scaling Law Estimation](2024年10月15日/A_Hitchhiker's_Guide_to_Scaling_Law_Estimation.md)

    - [翻译: 《缩放法则估计的搭便车指南》](2024年10月15日/A_Hitchhiker's_Guide_to_Scaling_Law_Estimation.md)

- [AIC CTU system at AVeriTeC: Re-framing automated fact-checking as a simple RAG task](2024年10月15日/AIC_CTU_system_at_AVeriTeC_Re-framing_automated_fact-checking_as_a_simple_RAG_task.md)

    - [翻译: AVeriTeC 的 AIC CTU 系统：将自动事实核查简化为一个简单的 RAG 任务](2024年10月15日/AIC_CTU_system_at_AVeriTeC_Re-framing_automated_fact-checking_as_a_simple_RAG_task.md)

- [Are UFOs Driving Innovation? The Illusion of Causality in Large Language Models](2024年10月15日/Are_UFOs_Driving_Innovation_The_Illusion_of_Causality_in_Large_Language_Models.md)

    - [翻译: UFOs 能推动创新吗？大型语言模型中的因果错觉](2024年10月15日/Are_UFOs_Driving_Innovation_The_Illusion_of_Causality_in_Large_Language_Models.md)

- [Augmentation-Driven Metric for Balancing Preservation and Modification in Text-Guided Image Editing](2024年10月15日/Augmentation-Driven_Metric_for_Balancing_Preservation_and_Modification_in_Text-Guided_Image_Editing.md)

    - [翻译: 增强驱动度量：平衡文本引导图像编辑中的保留与修改](2024年10月15日/Augmentation-Driven_Metric_for_Balancing_Preservation_and_Modification_in_Text-Guided_Image_Editing.md)

- [Beyond Linear Approximations: A Novel Pruning Approach for Attention Matrix](2024年10月15日/Beyond_Linear_Approximations_A_Novel_Pruning_Approach_for_Attention_Matrix.md)

    - [翻译: 突破线性限制：探索注意力矩阵的新剪枝策略](2024年10月15日/Beyond_Linear_Approximations_A_Novel_Pruning_Approach_for_Attention_Matrix.md)

- [Bypassing the Exponential Dependency: Looped Transformers Efficiently Learn In-context by Multi-step Gradient Descent](2024年10月15日/Bypassing_the_Exponential_Dependency_Looped_Transformers_Efficiently_Learn_In-context_by_Multi-step_Gradient_Descent.md)

    - [翻译: 循环Transformer巧妙绕过指数依赖，通过多步梯度下降，高效掌握上下文学习。](2024年10月15日/Bypassing_the_Exponential_Dependency_Looped_Transformers_Efficiently_Learn_In-context_by_Multi-step_Gradient_Descent.md)

- [Cognitive Overload Attack:Prompt Injection for Long Context](2024年10月15日/Cognitive_Overload_AttackPrompt_Injection_for_Long_Context.md)

    - [翻译: 认知过载攻击：长上下文中的提示注入](2024年10月15日/Cognitive_Overload_AttackPrompt_Injection_for_Long_Context.md)

- [CtrlSynth: Controllable Image Text Synthesis for Data-Efficient Multimodal Learning](2024年10月15日/CtrlSynth_Controllable_Image_Text_Synthesis_for_Data-Efficient_Multimodal_Learning.md)

    - [翻译: CtrlSynth：一种可控的图像文本合成工具，专为高效多模态学习设计](2024年10月15日/CtrlSynth_Controllable_Image_Text_Synthesis_for_Data-Efficient_Multimodal_Learning.md)

- [Data Quality Control in Federated Instruction-tuning of Large Language Models](2024年10月15日/Data_Quality_Control_in_Federated_Instruction-tuning_of_Large_Language_Models.md)

    - [翻译: 联邦指令调优中的数据质量控制：大型语言模型的关键环节](2024年10月15日/Data_Quality_Control_in_Federated_Instruction-tuning_of_Large_Language_Models.md)

- [Data Selection for Task-Specific Model Finetuning](2024年10月15日/Data_Selection_for_Task-Specific_Model_Finetuning.md)

    - [翻译: 任务导向模型微调中的数据精选](2024年10月15日/Data_Selection_for_Task-Specific_Model_Finetuning.md)

- [Deciphering the Chaos: Enhancing Jailbreak Attacks via Adversarial Prompt Translation](2024年10月15日/Deciphering_the_Chaos_Enhancing_Jailbreak_Attacks_via_Adversarial_Prompt_Translation.md)

    - [翻译: 破解混沌：利用对抗性提示翻译提升越狱攻击效果](2024年10月15日/Deciphering_the_Chaos_Enhancing_Jailbreak_Attacks_via_Adversarial_Prompt_Translation.md)

- [DeformPAM: Data-Efficient Learning for Long-horizon Deformable Object Manipulation via Preference-based Action Alignment](2024年10月15日/DeformPAM_Data-Efficient_Learning_for_Long-horizon_Deformable_Object_Manipulation_via_Preference-based_Action_Alignment.md)

    - [翻译: DeformPAM：利用基于偏好的动作对齐，高效学习长时变形物体的操作。](2024年10月15日/DeformPAM_Data-Efficient_Learning_for_Long-horizon_Deformable_Object_Manipulation_via_Preference-based_Action_Alignment.md)

- [De-jargonizing Science for Journalists with GPT-4: A Pilot Study](2024年10月15日/De-jargonizing_Science_for_Journalists_with_GPT-4_A_Pilot_Study.md)

    - [翻译: 利用 GPT-4 帮助记者简化科学术语：一次初步探索](2024年10月15日/De-jargonizing_Science_for_Journalists_with_GPT-4_A_Pilot_Study.md)

- [Difficult Task Yes but Simple Task No: Unveiling the Laziness in Multimodal LLMs](2024年10月15日/Difficult_Task_Yes_but_Simple_Task_No_Unveiling_the_Laziness_in_Multimodal_LLMs.md)

    - [翻译: 多模态大型语言模型在处理困难任务时表现出色，但在简单任务上却显得懒散。本文将揭示这种“懒惰”现象。](2024年10月15日/Difficult_Task_Yes_but_Simple_Task_No_Unveiling_the_Laziness_in_Multimodal_LLMs.md)

- [DocETL: Agentic Query Rewriting and Evaluation for Complex Document Processing](2024年10月15日/DocETL_Agentic_Query_Rewriting_and_Evaluation_for_Complex_Document_Processing.md)

    - [翻译: DocETL：针对复杂文档处理的智能查询重写与评估](2024年10月15日/DocETL_Agentic_Query_Rewriting_and_Evaluation_for_Complex_Document_Processing.md)

- [Do LLMs Have the Generalization Ability in Conducting Causal Inference?](2024年10月15日/Do_LLMs_Have_the_Generalization_Ability_in_Conducting_Causal_Inference.md)

    - [翻译: 大型语言模型是否具备进行因果推理的泛化能力？](2024年10月15日/Do_LLMs_Have_the_Generalization_Ability_in_Conducting_Causal_Inference.md)

- [DynamicER: Resolving Emerging Mentions to Dynamic Entities for RAG](2024年10月15日/DynamicER_Resolving_Emerging_Mentions_to_Dynamic_Entities_for_RAG.md)

    - [翻译: DynamicER：为 RAG 系统解析新兴提及并映射到动态实体](2024年10月15日/DynamicER_Resolving_Emerging_Mentions_to_Dynamic_Entities_for_RAG.md)

- [DySpec: Faster Speculative Decoding with Dynamic Token Tree Structure](2024年10月15日/DySpec_Faster_Speculative_Decoding_with_Dynamic_Token_Tree_Structure.md)

    - [翻译: DySpec：借助动态令牌树结构，实现更快的推测解码](2024年10月15日/DySpec_Faster_Speculative_Decoding_with_Dynamic_Token_Tree_Structure.md)

- [Eliciting Textual Descriptions from Representations of Continuous Prompts](2024年10月15日/Eliciting_Textual_Descriptions_from_Representations_of_Continuous_Prompts.md)

    - [翻译: 从连续提示的表示中提取文本描述](2024年10月15日/Eliciting_Textual_Descriptions_from_Representations_of_Continuous_Prompts.md)

- [Enhance Graph Alignment for Large Language Models](2024年10月15日/Enhance_Graph_Alignment_for_Large_Language_Models.md)

    - [翻译: 提升大型语言模型的图对齐能力](2024年10月15日/Enhance_Graph_Alignment_for_Large_Language_Models.md)

- [FoundTS: Comprehensive and Unified Benchmarking of Foundation Models for Time Series Forecasting](2024年10月15日/FoundTS_Comprehensive_and_Unified_Benchmarking_of_Foundation_Models_for_Time_Series_Forecasting.md)

    - [翻译: FoundTS：时间序列预测基础模型的全面统一基准](2024年10月15日/FoundTS_Comprehensive_and_Unified_Benchmarking_of_Foundation_Models_for_Time_Series_Forecasting.md)

- [GaVaMoE: Gaussian-Variational Gated Mixture of Experts for Explainable Recommendation](2024年10月15日/GaVaMoE_Gaussian-Variational_Gated_Mixture_of_Experts_for_Explainable_Recommendation.md)

    - [翻译: GaVaMoE：一种结合高斯变分和门控混合专家技术，旨在提升推荐系统可解释性的模型。](2024年10月15日/GaVaMoE_Gaussian-Variational_Gated_Mixture_of_Experts_for_Explainable_Recommendation.md)

- [Holistic Reasoning with Long-Context LMs: A Benchmark for Database Operations on Massive Textual Data](2024年10月15日/Holistic_Reasoning_with_Long-Context_LMs_A_Benchmark_for_Database_Operations_on_Massive_Textual_Data.md)

    - [翻译: 长上下文语言模型的整体推理：大规模文本数据数据库操作的基准测试](2024年10月15日/Holistic_Reasoning_with_Long-Context_LMs_A_Benchmark_for_Database_Operations_on_Massive_Textual_Data.md)

- [Human-LLM Collaborative Construction of a Cantonese Emotion Lexicon](2024年10月15日/Human-LLM_Collaborative_Construction_of_a_Cantonese_Emotion_Lexicon.md)

    - [翻译: 人机协作，共筑粤语情感词库](2024年10月15日/Human-LLM_Collaborative_Construction_of_a_Cantonese_Emotion_Lexicon.md)

- [Implementing Derivations of Definite Logic Programs with Self-Attention Networks](2024年10月15日/Implementing_Derivations_of_Definite_Logic_Programs_with_Self-Attention_Networks.md)

    - [翻译: 用自注意力网络实现确定逻辑程序的推导](2024年10月15日/Implementing_Derivations_of_Definite_Logic_Programs_with_Self-Attention_Networks.md)

- [Instructive Code Retriever: Learn from Large Language Model's Feedback for Code Intelligence Tasks](2024年10月15日/Instructive_Code_Retriever_Learn_from_Large_Language_Model's_Feedback_for_Code_Intelligence_Tasks.md)

    - [翻译: 指导性代码检索器：借助大型语言模型的反馈，提升代码智能任务的表现](2024年10月15日/Instructive_Code_Retriever_Learn_from_Large_Language_Model's_Feedback_for_Code_Intelligence_Tasks.md)

- [IntGrad MT: Eliciting LLMs' Machine Translation Capabilities with Sentence Interpolation and Gradual MT](2024年10月15日/IntGrad_MT_Eliciting_LLMs'_Machine_Translation_Capabilities_with_Sentence_Interpolation_and_Gradual_MT.md)

    - [翻译: IntGrad MT：借助句子插值与逐步机器翻译，激发 LLM 的翻译潜能](2024年10月15日/IntGrad_MT_Eliciting_LLMs'_Machine_Translation_Capabilities_with_Sentence_Interpolation_and_Gradual_MT.md)

- [KITTEN: A Knowledge-Intensive Evaluation of Image Generation on Visual Entities](2024年10月15日/KITTEN_A_Knowledge-Intensive_Evaluation_of_Image_Generation_on_Visual_Entities.md)

    - [翻译: KITTEN：视觉实体图像生成的知识密集型评估](2024年10月15日/KITTEN_A_Knowledge-Intensive_Evaluation_of_Image_Generation_on_Visual_Entities.md)

- [Language Models Encode Numbers Using Digit Representations in Base 10](2024年10月15日/Language_Models_Encode_Numbers_Using_Digit_Representations_in_Base_10.md)

    - [翻译: 语言模型通过十进制数字表示来编码数字](2024年10月15日/Language_Models_Encode_Numbers_Using_Digit_Representations_in_Base_10.md)

- [LargePiG: Your Large Language Model is Secretly a Pointer Generator](2024年10月15日/LargePiG_Your_Large_Language_Model_is_Secretly_a_Pointer_Generator.md)

    - [翻译: LargePiG：你的大型语言模型其实是个隐藏的指针生成器](2024年10月15日/LargePiG_Your_Large_Language_Model_is_Secretly_a_Pointer_Generator.md)

- [Layer-wise Importance Matters: Less Memory for Better Performance in Parameter-efficient Fine-tuning of Large Language Models](2024年10月15日/Layer-wise_Importance_Matters_Less_Memory_for_Better_Performance_in_Parameter-efficient_Fine-tuning_of_Large_Language_Models.md)

    - [翻译: 逐层重要性不容忽视：在大型语言模型的参数高效微调中，减少内存占用反而能提升性能。](2024年10月15日/Layer-wise_Importance_Matters_Less_Memory_for_Better_Performance_in_Parameter-efficient_Fine-tuning_of_Large_Language_Models.md)

- [Learning from Imperfect Data: Towards Efficient Knowledge Distillation of Autoregressive Language Models for Text-to-SQL](2024年10月15日/Learning_from_Imperfect_Data_Towards_Efficient_Knowledge_Distillation_of_Autoregressive_Language_Models_for_Text-to-SQL.md)

    - [翻译: 从不完美数据中学习：提升自动回归语言模型在文本到SQL任务中的知识蒸馏效率](2024年10月15日/Learning_from_Imperfect_Data_Towards_Efficient_Knowledge_Distillation_of_Autoregressive_Language_Models_for_Text-to-SQL.md)

- [Leveraging LLM Embeddings for Cross Dataset Label Alignment and Zero Shot Music Emotion Prediction](2024年10月15日/Leveraging_LLM_Embeddings_for_Cross_Dataset_Label_Alignment_and_Zero_Shot_Music_Emotion_Prediction.md)

    - [翻译: 借助 LLM 嵌入，实现跨数据集标签对齐，并进行零-shot 音乐情感预测。](2024年10月15日/Leveraging_LLM_Embeddings_for_Cross_Dataset_Label_Alignment_and_Zero_Shot_Music_Emotion_Prediction.md)

- [Light-Weight Fault Tolerant Attention for Large Language Model Training](2024年10月15日/Light-Weight_Fault_Tolerant_Attention_for_Large_Language_Model_Training.md)

    - [翻译: 轻量级容错注意力机制助力大型语言模型训练](2024年10月15日/Light-Weight_Fault_Tolerant_Attention_for_Large_Language_Model_Training.md)

- [LLM2Swarm: Robot Swarms that Responsively Reason, Plan, and Collaborate through LLMs](2024年10月15日/LLM2Swarm_Robot_Swarms_that_Responsively_Reason,_Plan,_and_Collaborate_through_LLMs.md)

    - [翻译: LLM2Swarm：借助 LLM 实现智能推理、协同规划与合作的机器人集群](2024年10月15日/LLM2Swarm_Robot_Swarms_that_Responsively_Reason,_Plan,_and_Collaborate_through_LLMs.md)

- [LLM-Mixer: Multiscale Mixing in LLMs for Time Series Forecasting](2024年10月15日/LLM-Mixer_Multiscale_Mixing_in_LLMs_for_Time_Series_Forecasting.md)

    - [翻译: LLM-Mixer：在 LLM 中实现时间序列预测的多尺度混合技术](2024年10月15日/LLM-Mixer_Multiscale_Mixing_in_LLMs_for_Time_Series_Forecasting.md)

- [LoKO: Low-Rank Kalman Optimizer for Online Fine-Tuning of Large Models](2024年10月15日/LoKO_Low-Rank_Kalman_Optimizer_for_Online_Fine-Tuning_of_Large_Models.md)

    - [翻译: LoKO：专为大型模型在线微调设计的低秩卡尔曼优化器](2024年10月15日/LoKO_Low-Rank_Kalman_Optimizer_for_Online_Fine-Tuning_of_Large_Models.md)

- [LongHalQA: Long-Context Hallucination Evaluation for MultiModal Large Language Models](2024年10月15日/LongHalQA_Long-Context_Hallucination_Evaluation_for_MultiModal_Large_Language_Models.md)

    - [翻译: LongHalQA：评估多模态大型语言模型在长上下文中的幻觉现象](2024年10月15日/LongHalQA_Long-Context_Hallucination_Evaluation_for_MultiModal_Large_Language_Models.md)

- [LR-SQL: A Supervised Fine-Tuning Method for Text2SQL Tasks under Low-Resource Scenarios](2024年10月15日/LR-SQL_A_Supervised_Fine-Tuning_Method_for_Text2SQL_Tasks_under_Low-Resource_Scenarios.md)

    - [翻译: LR-SQL：低资源场景下 Text2SQL 任务的监督微调新方法](2024年10月15日/LR-SQL_A_Supervised_Fine-Tuning_Method_for_Text2SQL_Tasks_under_Low-Resource_Scenarios.md)

- [Magnifier Prompt: Tackling Multimodal Hallucination via Extremely Simple Instructions](2024年10月15日/Magnifier_Prompt_Tackling_Multimodal_Hallucination_via_Extremely_Simple_Instructions.md)

    - [翻译: 放大镜提示：用极简指令攻克多模态幻觉难题](2024年10月15日/Magnifier_Prompt_Tackling_Multimodal_Hallucination_via_Extremely_Simple_Instructions.md)

- [MCTBench: Multimodal Cognition towards Text-Rich Visual Scenes Benchmark](2024年10月15日/MCTBench_Multimodal_Cognition_towards_Text-Rich_Visual_Scenes_Benchmark.md)

    - [翻译: MCTBench：探索文本与视觉融合的多模态认知新基准](2024年10月15日/MCTBench_Multimodal_Cognition_towards_Text-Rich_Visual_Scenes_Benchmark.md)

- [Measuring Spiritual Values and Bias of Large Language Models](2024年10月15日/Measuring_Spiritual_Values_and_Bias_of_Large_Language_Models.md)

    - [翻译: 探究大型语言模型的精神价值与偏见](2024年10月15日/Measuring_Spiritual_Values_and_Bias_of_Large_Language_Models.md)

- [MLLM can see? Dynamic Correction Decoding for Hallucination Mitigation](2024年10月15日/MLLM_can_see_Dynamic_Correction_Decoding_for_Hallucination_Mitigation.md)

    - [翻译: MLLM 能“看”吗？动态校正解码助力幻觉缓解](2024年10月15日/MLLM_can_see_Dynamic_Correction_Decoding_for_Hallucination_Mitigation.md)

- [MoChat: Joints-Grouped Spatio-Temporal Grounding LLM for Multi-Turn Motion Comprehension and Description](2024年10月15日/MoChat_Joints-Grouped_Spatio-Temporal_Grounding_LLM_for_Multi-Turn_Motion_Comprehension_and_Description.md)

    - [翻译: MoChat：一款专为多轮运动理解和描述设计的联合分组时空定位大型语言模型](2024年10月15日/MoChat_Joints-Grouped_Spatio-Temporal_Grounding_LLM_for_Multi-Turn_Motion_Comprehension_and_Description.md)

- [MTU-Bench: A Multi-granularity Tool-Use Benchmark for Large Language Models](2024年10月15日/MTU-Bench_A_Multi-granularity_Tool-Use_Benchmark_for_Large_Language_Models.md)

    - [翻译: MTU-Bench：专为大型语言模型设计的多粒度工具使用基准](2024年10月15日/MTU-Bench_A_Multi-granularity_Tool-Use_Benchmark_for_Large_Language_Models.md)

- [Multi-round jailbreak attack on large language models](2024年10月15日/Multi-round_jailbreak_attack_on_large_language_models.md)

    - [翻译: 大型语言模型面临多轮越狱攻击](2024年10月15日/Multi-round_jailbreak_attack_on_large_language_models.md)

- [NesTools: A Dataset for Evaluating Nested Tool Learning Abilities of Large Language Models](2024年10月15日/NesTools_A_Dataset_for_Evaluating_Nested_Tool_Learning_Abilities_of_Large_Language_Models.md)

    - [翻译: NesTools：专为评估大型语言模型嵌套工具学习能力而设计的数据集](2024年10月15日/NesTools_A_Dataset_for_Evaluating_Nested_Tool_Learning_Abilities_of_Large_Language_Models.md)

- [O-Edit: Orthogonal Subspace Editing for Language Model Sequential Editing](2024年10月15日/O-Edit_Orthogonal_Subspace_Editing_for_Language_Model_Sequential_Editing.md)

    - [翻译: O-Edit：一种用于语言模型序列编辑的正交子空间编辑方法](2024年10月15日/O-Edit_Orthogonal_Subspace_Editing_for_Language_Model_Sequential_Editing.md)

- [OMCAT: Omni Context Aware Transformer](2024年10月15日/OMCAT_Omni_Context_Aware_Transformer.md)

    - [翻译: OMCAT：全场景智能Transformer](2024年10月15日/OMCAT_Omni_Context_Aware_Transformer.md)

- [PAVLM: Advancing Point Cloud based Affordance Understanding Via Vision-Language Model](2024年10月15日/PAVLM_Advancing_Point_Cloud_based_Affordance_Understanding_Via_Vision-Language_Model.md)

    - [翻译: PAVLM：借助视觉-语言模型，推动基于点云的可操作性理解](2024年10月15日/PAVLM_Advancing_Point_Cloud_based_Affordance_Understanding_Via_Vision-Language_Model.md)

- [Personas with Attitudes: Controlling LLMs for Diverse Data Annotation](2024年10月15日/Personas_with_Attitudes_Controlling_LLMs_for_Diverse_Data_Annotation.md)

    - [翻译: 赋予角色态度：掌控 LLM，实现数据标注的多样性](2024年10月15日/Personas_with_Attitudes_Controlling_LLMs_for_Diverse_Data_Annotation.md)

- [PMMT: Preference Alignment in Multilingual Machine Translation via LLM Distillation](2024年10月15日/PMMT_Preference_Alignment_in_Multilingual_Machine_Translation_via_LLM_Distillation.md)

    - [翻译: PMMT：利用 LLM 蒸馏技术，实现多语言机器翻译中的偏好对齐](2024年10月15日/PMMT_Preference_Alignment_in_Multilingual_Machine_Translation_via_LLM_Distillation.md)

- [QSpec: Speculative Decoding with Complementary Quantization Schemes](2024年10月15日/QSpec_Speculative_Decoding_with_Complementary_Quantization_Schemes.md)

    - [翻译: QSpec：采用互补量化方案的推测性解码技术](2024年10月15日/QSpec_Speculative_Decoding_with_Complementary_Quantization_Schemes.md)

- [RATE: Score Reward Models with Imperfect Rewrites of Rewrites](2024年10月15日/RATE_Score_Reward_Models_with_Imperfect_Rewrites_of_Rewrites.md)

    - [翻译: RATE：用重写的瑕疵来评估奖励模型](2024年10月15日/RATE_Score_Reward_Models_with_Imperfect_Rewrites_of_Rewrites.md)

- [ReDeEP: Detecting Hallucination in Retrieval-Augmented Generation via Mechanistic Interpretability](2024年10月15日/ReDeEP_Detecting_Hallucination_in_Retrieval-Augmented_Generation_via_Mechanistic_Interpretability.md)

    - [翻译: ReDeEP：利用机制可解释性，精准检测检索增强生成中的幻觉现象。](2024年10月15日/ReDeEP_Detecting_Hallucination_in_Retrieval-Augmented_Generation_via_Mechanistic_Interpretability.md)

- [Robust Manipulation Primitive Learning via Domain Contraction](2024年10月15日/Robust_Manipulation_Primitive_Learning_via_Domain_Contraction.md)

    - [翻译: 通过领域收缩，实现操作原语的鲁棒学习](2024年10月15日/Robust_Manipulation_Primitive_Learning_via_Domain_Contraction.md)

- [SEER: Self-Aligned Evidence Extraction for Retrieval-Augmented Generation](2024年10月15日/SEER_Self-Aligned_Evidence_Extraction_for_Retrieval-Augmented_Generation.md)

    - [翻译: SEER：自对齐证据提取，助力检索增强生成](2024年10月15日/SEER_Self-Aligned_Evidence_Extraction_for_Retrieval-Augmented_Generation.md)

- [Self-adaptive Multimodal Retrieval-Augmented Generation](2024年10月15日/Self-adaptive_Multimodal_Retrieval-Augmented_Generation.md)

    - [翻译: 自适应多模态检索增强生成技术](2024年10月15日/Self-adaptive_Multimodal_Retrieval-Augmented_Generation.md)

- [Sequential LLM Framework for Fashion Recommendation](2024年10月15日/Sequential_LLM_Framework_for_Fashion_Recommendation.md)

    - [翻译: 时尚推荐中的顺序 LLM 框架](2024年10月15日/Sequential_LLM_Framework_for_Fashion_Recommendation.md)

- [SGEdit: Bridging LLM with Text2Image Generative Model for Scene Graph-based Image Editing](2024年10月15日/SGEdit_Bridging_LLM_with_Text2Image_Generative_Model_for_Scene_Graph-based_Image_Editing.md)

    - [翻译: SGEdit：融合 LLM 与 Text2Image 生成模型，实现基于场景图的图像编辑](2024年10月15日/SGEdit_Bridging_LLM_with_Text2Image_Generative_Model_for_Scene_Graph-based_Image_Editing.md)

- [SlideChat: A Large Vision-Language Assistant for Whole-Slide Pathology Image Understanding](2024年10月15日/SlideChat_A_Large_Vision-Language_Assistant_for_Whole-Slide_Pathology_Image_Understanding.md)

    - [翻译: SlideChat：一款强大的视觉-语言助手，专为全切片病理图像的深度理解而设计。](2024年10月15日/SlideChat_A_Large_Vision-Language_Assistant_for_Whole-Slide_Pathology_Image_Understanding.md)

- [TransAgent: Transfer Vision-Language Foundation Models with Heterogeneous Agent Collaboration](2024年10月15日/TransAgent_Transfer_Vision-Language_Foundation_Models_with_Heterogeneous_Agent_Collaboration.md)

    - [翻译: TransAgent：借助异构代理协作，实现视觉-语言基础模型的迁移](2024年10月15日/TransAgent_Transfer_Vision-Language_Foundation_Models_with_Heterogeneous_Agent_Collaboration.md)

- [Transformer Layer Injection: A Novel Approach for Efficient Upscaling of Large Language Models](2024年10月15日/Transformer_Layer_Injection_A_Novel_Approach_for_Efficient_Upscaling_of_Large_Language_Models.md)

    - [翻译: Transformer 层注入：提升大型语言模型效率的创新之道](2024年10月15日/Transformer_Layer_Injection_A_Novel_Approach_for_Efficient_Upscaling_of_Large_Language_Models.md)

- [VidCompress: Memory-Enhanced Temporal Compression for Video Understanding in Large Language Models](2024年10月15日/VidCompress_Memory-Enhanced_Temporal_Compression_for_Video_Understanding_in_Large_Language_Models.md)

    - [翻译: VidCompress：通过内存增强的时间压缩技术，提升大型语言模型中的视频理解能力。](2024年10月15日/VidCompress_Memory-Enhanced_Temporal_Compression_for_Video_Understanding_in_Large_Language_Models.md)

- [Y-Mol: A Multiscale Biomedical Knowledge-Guided Large Language Model for Drug Development](2024年10月15日/Y-Mol_A_Multiscale_Biomedical_Knowledge-Guided_Large_Language_Model_for_Drug_Development.md)

    - [翻译: Y-Mol：一款多尺度生物医学知识驱动的大型语言模型，专为药物研发而生](2024年10月15日/Y-Mol_A_Multiscale_Biomedical_Knowledge-Guided_Large_Language_Model_for_Drug_Development.md)

2024年10月14日

- [$α$-DPO: Adaptive Reward Margin is What Direct Preference Optimization Needs](2024年10月14日/$α$-DPO_Adaptive_Reward_Margin_is_What_Direct_Preference_Optimization_Needs.md)

    - [翻译: $α$-DPO：自适应奖励边际，正是直接偏好优化所需的关键。](2024年10月14日/$α$-DPO_Adaptive_Reward_Margin_is_What_Direct_Preference_Optimization_Needs.md)

- [A CLIP-Powered Framework for Robust and Generalizable Data Selection](2024年10月14日/A_CLIP-Powered_Framework_for_Robust_and_Generalizable_Data_Selection.md)

    - [翻译: 基于 CLIP 的框架，助力数据选择更稳健、更通用](2024年10月14日/A_CLIP-Powered_Framework_for_Robust_and_Generalizable_Data_Selection.md)

- [Ada-K Routing: Boosting the Efficiency of MoE-based LLMs](2024年10月14日/Ada-K_Routing_Boosting_the_Efficiency_of_MoE-based_LLMs.md)

    - [翻译: Ada-K 路由：为基于 MoE 的 LLM 注入高效动力](2024年10月14日/Ada-K_Routing_Boosting_the_Efficiency_of_MoE-based_LLMs.md)

- [Adapt-$\infty$: Scalable Lifelong Multimodal Instruction Tuning via Dynamic Data Selection](2024年10月14日/Adapt-$\infty$_Scalable_Lifelong_Multimodal_Instruction_Tuning_via_Dynamic_Data_Selection.md)

    - [翻译: Adapt-$\infty$：利用动态数据选择，实现终身多模态指令调优的可扩展性](2024年10月14日/Adapt-$\infty$_Scalable_Lifelong_Multimodal_Instruction_Tuning_via_Dynamic_Data_Selection.md)

- [A Multi-Task Text Classification Pipeline with Natural Language Explanations: A User-Centric Evaluation in Sentiment Analysis and Offensive Language Identification in Greek Tweets](2024年10月14日/A_Multi-Task_Text_Classification_Pipeline_with_Natural_Language_Explanations_A_User-Centric_Evaluation_in_Sentiment_Analysis_and_Offensive_Language_Identification_in_Greek_Tweets.md)

    - [翻译: 多任务文本分类管道，结合自然语言解释，专注于希腊推文中的情感分析与冒犯性语言识别，以用户为中心进行评估。](2024年10月14日/A_Multi-Task_Text_Classification_Pipeline_with_Natural_Language_Explanations_A_User-Centric_Evaluation_in_Sentiment_Analysis_and_Offensive_Language_Identification_in_Greek_Tweets.md)

- [Athena: Retrieval-augmented Legal Judgment Prediction with Large Language Models](2024年10月14日/Athena_Retrieval-augmented_Legal_Judgment_Prediction_with_Large_Language_Models.md)

    - [翻译: Athena：借助大型语言模型提升检索功能的法律判决预测系统](2024年10月14日/Athena_Retrieval-augmented_Legal_Judgment_Prediction_with_Large_Language_Models.md)

- [Audio Captioning via Generative Pair-to-Pair Retrieval with Refined Knowledge Base](2024年10月14日/Audio_Captioning_via_Generative_Pair-to-Pair_Retrieval_with_Refined_Knowledge_Base.md)

    - [翻译: 音频描述：基于精炼知识库的生成式配对检索](2024年10月14日/Audio_Captioning_via_Generative_Pair-to-Pair_Retrieval_with_Refined_Knowledge_Base.md)

- [Augmenting In-Context-Learning in LLMs via Automatic Data Labeling and Refinement](2024年10月14日/Augmenting_In-Context-Learning_in_LLMs_via_Automatic_Data_Labeling_and_Refinement.md)

    - [翻译: 借助自动数据标注与优化，提升 LLM 中的 In-Context-Learning 效果](2024年10月14日/Augmenting_In-Context-Learning_in_LLMs_via_Automatic_Data_Labeling_and_Refinement.md)

- [A Unified Approach to Routing and Cascading for LLMs](2024年10月14日/A_Unified_Approach_to_Routing_and_Cascading_for_LLMs.md)

    - [翻译: LLM 中的路由与级联统一方法](2024年10月14日/A_Unified_Approach_to_Routing_and_Cascading_for_LLMs.md)

- [Automated Filtering of Human Feedback Data for Aligning Text-to-Image Diffusion Models](2024年10月14日/Automated_Filtering_of_Human_Feedback_Data_for_Aligning_Text-to-Image_Diffusion_Models.md)

    - [翻译: 自动化筛选人类反馈数据，优化文本到图像扩散模型的对齐效果](2024年10月14日/Automated_Filtering_of_Human_Feedback_Data_for_Aligning_Text-to-Image_Diffusion_Models.md)

- [Automatically Generating Visual Hallucination Test Cases for Multimodal Large Language Models](2024年10月14日/Automatically_Generating_Visual_Hallucination_Test_Cases_for_Multimodal_Large_Language_Models.md)

    - [翻译: 自动为多模态大型语言模型生成视觉幻觉测试用例](2024年10月14日/Automatically_Generating_Visual_Hallucination_Test_Cases_for_Multimodal_Large_Language_Models.md)

- [AutoTurb: Using Large Language Models for Automatic Algebraic Model Discovery of Turbulence Closure](2024年10月14日/AutoTurb_Using_Large_Language_Models_for_Automatic_Algebraic_Model_Discovery_of_Turbulence_Closure.md)

    - [翻译: AutoTurb：借助大型语言模型，自动探索湍流闭包的代数模型](2024年10月14日/AutoTurb_Using_Large_Language_Models_for_Automatic_Algebraic_Model_Discovery_of_Turbulence_Closure.md)

- [Balancing Continuous Pre-Training and Instruction Fine-Tuning: Optimizing Instruction-Following in LLMs](2024年10月14日/Balancing_Continuous_Pre-Training_and_Instruction_Fine-Tuning_Optimizing_Instruction-Following_in_LLMs.md)

    - [翻译: 在 LLM 中，如何平衡连续预训练与指令微调，以优化指令跟随能力，是一个关键课题。](2024年10月14日/Balancing_Continuous_Pre-Training_and_Instruction_Fine-Tuning_Optimizing_Instruction-Following_in_LLMs.md)

- [Beyond-RAG: Question Identification and Answer Generation in Real-Time Conversations](2024年10月14日/Beyond-RAG_Question_Identification_and_Answer_Generation_in_Real-Time_Conversations.md)

    - [翻译: 超越RAG：实时对话中的问题识别与答案生成](2024年10月14日/Beyond-RAG_Question_Identification_and_Answer_Generation_in_Real-Time_Conversations.md)

- [Both Ears Wide Open: Towards Language-Driven Spatial Audio Generation](2024年10月14日/Both_Ears_Wide_Open_Towards_Language-Driven_Spatial_Audio_Generation.md)

    - [翻译: 双耳全开：探索语言驱动的空间音频生成](2024年10月14日/Both_Ears_Wide_Open_Towards_Language-Driven_Spatial_Audio_Generation.md)

- [Can Structured Data Reduce Epistemic Uncertainty?](2024年10月14日/Can_Structured_Data_Reduce_Epistemic_Uncertainty.md)

    - [翻译: 结构化数据能否降低认知不确定性？](2024年10月14日/Can_Structured_Data_Reduce_Epistemic_Uncertainty.md)

- [CoMAT: Chain of Mathematically Annotated Thought Improves Mathematical Reasoning](2024年10月14日/CoMAT_Chain_of_Mathematically_Annotated_Thought_Improves_Mathematical_Reasoning.md)

    - [翻译: CoMAT：通过链式数学思维注释，提升数学推理能力](2024年10月14日/CoMAT_Chain_of_Mathematically_Annotated_Thought_Improves_Mathematical_Reasoning.md)

- [Cultural Fidelity in Large-Language Models: An Evaluation of Online Language Resources as a Driver of Model Performance in Value Representation](2024年10月14日/Cultural_Fidelity_in_Large-Language_Models_An_Evaluation_of_Online_Language_Resources_as_a_Driver_of_Model_Performance_in_Value_Representation.md)

    - [翻译: 大型语言模型中的文化保真度：探讨在线语言资源如何影响模型在价值表示方面的性能。](2024年10月14日/Cultural_Fidelity_in_Large-Language_Models_An_Evaluation_of_Online_Language_Resources_as_a_Driver_of_Model_Performance_in_Value_Representation.md)

- [Denial-of-Service Poisoning Attacks against Large Language Models](2024年10月14日/Denial-of-Service_Poisoning_Attacks_against_Large_Language_Models.md)

    - [翻译: 大型语言模型遭遇拒绝服务中毒攻击](2024年10月14日/Denial-of-Service_Poisoning_Attacks_against_Large_Language_Models.md)

- [Depth Any Video with Scalable Synthetic Data](2024年10月14日/Depth_Any_Video_with_Scalable_Synthetic_Data.md)

    - [翻译: 用可扩展的合成数据实现任意视频深度](2024年10月14日/Depth_Any_Video_with_Scalable_Synthetic_Data.md)

- [DuoAttention: Efficient Long-Context LLM Inference with Retrieval and Streaming Heads](2024年10月14日/DuoAttention_Efficient_Long-Context_LLM_Inference_with_Retrieval_and_Streaming_Heads.md)

    - [翻译: DuoAttention：结合检索与流式处理，实现长上下文 LLM 推理的高效能](2024年10月14日/DuoAttention_Efficient_Long-Context_LLM_Inference_with_Retrieval_and_Streaming_Heads.md)

- [Efficiently Democratizing Medical LLMs for 50 Languages via a Mixture of Language Family Experts](2024年10月14日/Efficiently_Democratizing_Medical_LLMs_for_50_Languages_via_a_Mixture_of_Language_Family_Experts.md)

    - [翻译: 借助语言家族专家的混合策略，我们高效地将医学大型语言模型扩展至50种语言，实现真正的语言民主化。](2024年10月14日/Efficiently_Democratizing_Medical_LLMs_for_50_Languages_via_a_Mixture_of_Language_Family_Experts.md)

- [Effi-Code: Unleashing Code Efficiency in Language Models](2024年10月14日/Effi-Code_Unleashing_Code_Efficiency_in_Language_Models.md)

    - [翻译: Effi-Code：激发语言模型中的代码效率](2024年10月14日/Effi-Code_Unleashing_Code_Efficiency_in_Language_Models.md)

- [Empowering Users in Digital Privacy Management through Interactive LLM-Based Agents](2024年10月14日/Empowering_Users_in_Digital_Privacy_Management_through_Interactive_LLM-Based_Agents.md)

    - [翻译: 借助基于 LLM 的智能代理，用户在数字隐私管理中的掌控力得以提升。](2024年10月14日/Empowering_Users_in_Digital_Privacy_Management_through_Interactive_LLM-Based_Agents.md)

- [F2A: An Innovative Approach for Prompt Injection by Utilizing Feign Security Detection Agents](2024年10月14日/F2A_An_Innovative_Approach_for_Prompt_Injection_by_Utilizing_Feign_Security_Detection_Agents.md)

    - [翻译: F2A：通过伪装安全检测代理实现提示注入的创新策略](2024年10月14日/F2A_An_Innovative_Approach_for_Prompt_Injection_by_Utilizing_Feign_Security_Detection_Agents.md)

- [Fine-grained Abnormality Prompt Learning for Zero-shot Anomaly Detection](2024年10月14日/Fine-grained_Abnormality_Prompt_Learning_for_Zero-shot_Anomaly_Detection.md)

    - [翻译: 细粒度异常提示学习：零-shot异常检测的新方法](2024年10月14日/Fine-grained_Abnormality_Prompt_Learning_for_Zero-shot_Anomaly_Detection.md)

- [Focused ReAct: Improving ReAct through Reiterate and Early Stop](2024年10月14日/Focused_ReAct_Improving_ReAct_through_Reiterate_and_Early_Stop.md)

    - [翻译: 聚焦 ReAct：通过反复迭代与早期停止提升 ReAct 性能](2024年10月14日/Focused_ReAct_Improving_ReAct_through_Reiterate_and_Early_Stop.md)

- [ForgeryGPT: Multimodal Large Language Model For Explainable Image Forgery Detection and Localization](2024年10月14日/ForgeryGPT_Multimodal_Large_Language_Model_For_Explainable_Image_Forgery_Detection_and_Localization.md)

    - [翻译: ForgeryGPT：一款多模态大型语言模型，专为可解释的图像伪造检测与定位而生。](2024年10月14日/ForgeryGPT_Multimodal_Large_Language_Model_For_Explainable_Image_Forgery_Detection_and_Localization.md)

- [Free Video-LLM: Prompt-guided Visual Perception for Efficient Training-free Video LLMs](2024年10月14日/Free_Video-LLM_Prompt-guided_Visual_Perception_for_Efficient_Training-free_Video_LLMs.md)

    - [翻译: Free Video-LLM：通过提示引导的视觉感知，实现无需训练的高效视频语言模型](2024年10月14日/Free_Video-LLM_Prompt-guided_Visual_Perception_for_Efficient_Training-free_Video_LLMs.md)

- [Functional Flexibility in Generative AI Interfaces: Text Editing with LLMs through Conversations, Toolbars, and Prompts](2024年10月14日/Functional_Flexibility_in_Generative_AI_Interfaces_Text_Editing_with_LLMs_through_Conversations,_Toolbars,_and_Prompts.md)

    - [翻译: 生成式 AI 接口展现出的功能灵活性：通过对话、工具栏和提示，与 LLM 共同进行文本编辑。](2024年10月14日/Functional_Flexibility_in_Generative_AI_Interfaces_Text_Editing_with_LLMs_through_Conversations,_Toolbars,_and_Prompts.md)

- [FunnelRAG: A Coarse-to-Fine Progressive Retrieval Paradigm for RAG](2024年10月14日/FunnelRAG_A_Coarse-to-Fine_Progressive_Retrieval_Paradigm_for_RAG.md)

    - [翻译: FunnelRAG：一种从粗到细的渐进式 RAG 检索方法](2024年10月14日/FunnelRAG_A_Coarse-to-Fine_Progressive_Retrieval_Paradigm_for_RAG.md)

- [Graph of Records: Boosting Retrieval Augmented Generation for Long-context Summarization with Graphs](2024年10月14日/Graph_of_Records_Boosting_Retrieval_Augmented_Generation_for_Long-context_Summarization_with_Graphs.md)

    - [翻译: 记录图：通过图增强检索生成，助力长上下文摘要的提升](2024年10月14日/Graph_of_Records_Boosting_Retrieval_Augmented_Generation_for_Long-context_Summarization_with_Graphs.md)

- [HR-Agent: A Task-Oriented Dialogue (TOD) LLM Agent Tailored for HR Applications](2024年10月14日/HR-Agent_A_Task-Oriented_Dialogue_(TOD)_LLM_Agent_Tailored_for_HR_Applications.md)

    - [翻译: HR-Agent：专为 HR 应用打造的任务导向对话 LLM 代理](2024年10月14日/HR-Agent_A_Task-Oriented_Dialogue_(TOD)_LLM_Agent_Tailored_for_HR_Applications.md)

- [Improve Meta-learning for Few-Shot Text Classification with All You Can Acquire from the Tasks](2024年10月14日/Improve_Meta-learning_for_Few-Shot_Text_Classification_with_All_You_Can_Acquire_from_the_Tasks.md)

    - [翻译: 利用任务中的所有可用信息，提升少样本文本分类的元学习效果](2024年10月14日/Improve_Meta-learning_for_Few-Shot_Text_Classification_with_All_You_Can_Acquire_from_the_Tasks.md)

- [Innovative Thinking, Infinite Humor: Humor Research of Large Language Models through Structured Thought Leaps](2024年10月14日/Innovative_Thinking,_Infinite_Humor_Humor_Research_of_Large_Language_Models_through_Structured_Thought_Leaps.md)

    - [翻译: 创新思维，幽默无限：通过结构化思维跳跃探索大语言模型的幽默研究](2024年10月14日/Innovative_Thinking,_Infinite_Humor_Humor_Research_of_Large_Language_Models_through_Structured_Thought_Leaps.md)

- [Is Parameter Collision Hindering Continual Learning in LLMs?](2024年10月14日/Is_Parameter_Collision_Hindering_Continual_Learning_in_LLMs.md)

    - [翻译: 参数碰撞是否成为 LLM 持续学习的绊脚石？](2024年10月14日/Is_Parameter_Collision_Hindering_Continual_Learning_in_LLMs.md)

- [KBLaM: Knowledge Base augmented Language Model](2024年10月14日/KBLaM_Knowledge_Base_augmented_Language_Model.md)

    - [翻译: KBLaM：知识库赋能的语言模型](2024年10月14日/KBLaM_Knowledge_Base_augmented_Language_Model.md)

- [Large Language Model-Enhanced Reinforcement Learning for Generic Bus Holding Control Strategies](2024年10月14日/Large_Language_Model-Enhanced_Reinforcement_Learning_for_Generic_Bus_Holding_Control_Strategies.md)

    - [翻译: 大型语言模型加持的强化学习，助力通用公交保持控制策略](2024年10月14日/Large_Language_Model-Enhanced_Reinforcement_Learning_for_Generic_Bus_Holding_Control_Strategies.md)

- [LG-CAV: Train Any Concept Activation Vector with Language Guidance](2024年10月14日/LG-CAV_Train_Any_Concept_Activation_Vector_with_Language_Guidance.md)

    - [翻译: LG-CAV：借助语言指导，轻松训练任意概念激活向量](2024年10月14日/LG-CAV_Train_Any_Concept_Activation_Vector_with_Language_Guidance.md)

- [Locking Down the Finetuned LLMs Safety](2024年10月14日/Locking_Down_the_Finetuned_LLMs_Safety.md)

    - [翻译: 确保微调后 LLM 的安全防护](2024年10月14日/Locking_Down_the_Finetuned_LLMs_Safety.md)

- [LoLCATs: On Low-Rank Linearizing of Large Language Models](2024年10月14日/LoLCATs_On_Low-Rank_Linearizing_of_Large_Language_Models.md)

    - [翻译: LoLCATs：探索大型语言模型的低秩线性化](2024年10月14日/LoLCATs_On_Low-Rank_Linearizing_of_Large_Language_Models.md)

- [LongMemEval: Benchmarking Chat Assistants on Long-Term Interactive Memory](2024年10月14日/LongMemEval_Benchmarking_Chat_Assistants_on_Long-Term_Interactive_Memory.md)

    - [翻译: LongMemEval：评估聊天助手在长期交互记忆中的表现](2024年10月14日/LongMemEval_Benchmarking_Chat_Assistants_on_Long-Term_Interactive_Memory.md)

- [MentalGLM Series: Explainable Large Language Models for Mental Health Analysis on Chinese Social Media](2024年10月14日/MentalGLM_Series_Explainable_Large_Language_Models_for_Mental_Health_Analysis_on_Chinese_Social_Media.md)

    - [翻译: MentalGLM 系列：专为中国社交媒体心理健康分析设计的可解释大型语言模型](2024年10月14日/MentalGLM_Series_Explainable_Large_Language_Models_for_Mental_Health_Analysis_on_Chinese_Social_Media.md)

- [Minimum Tuning to Unlock Long Output from LLMs with High Quality Data as the Key](2024年10月14日/Minimum_Tuning_to_Unlock_Long_Output_from_LLMs_with_High_Quality_Data_as_the_Key.md)

    - [翻译: 通过最小调整，以高质量数据为关键，解锁 LLM 的长输出能力](2024年10月14日/Minimum_Tuning_to_Unlock_Long_Output_from_LLMs_with_High_Quality_Data_as_the_Key.md)

- [MMAR: Towards Lossless Multi-Modal Auto-Regressive Prababilistic Modeling](2024年10月14日/MMAR_Towards_Lossless_Multi-Modal_Auto-Regressive_Prababilistic_Modeling.md)

    - [翻译: MMAR：探索无损多模态自回归概率建模的新领域](2024年10月14日/MMAR_Towards_Lossless_Multi-Modal_Auto-Regressive_Prababilistic_Modeling.md)

- [MMIE: Massive Multimodal Interleaved Comprehension Benchmark for Large Vision-Language Models](2024年10月14日/MMIE_Massive_Multimodal_Interleaved_Comprehension_Benchmark_for_Large_Vision-Language_Models.md)

    - [翻译: MMIE：大型视觉-语言模型的大规模多模态交错理解基准](2024年10月14日/MMIE_Massive_Multimodal_Interleaved_Comprehension_Benchmark_for_Large_Vision-Language_Models.md)

- [Model-Based Differentially Private Knowledge Transfer for Large Language Models](2024年10月14日/Model-Based_Differentially_Private_Knowledge_Transfer_for_Large_Language_Models.md)

    - [翻译: 基于模型的差分隐私技术助力大型语言模型的知识迁移](2024年10月14日/Model-Based_Differentially_Private_Knowledge_Transfer_for_Large_Language_Models.md)

- [MoTE: Reconciling Generalization with Specialization for Visual-Language to Video Knowledge Transfer](2024年10月14日/MoTE_Reconciling_Generalization_with_Specialization_for_Visual-Language_to_Video_Knowledge_Transfer.md)

    - [翻译: MoTE：在视觉-语言到视频知识转移中，平衡泛化与专业化](2024年10月14日/MoTE_Reconciling_Generalization_with_Specialization_for_Visual-Language_to_Video_Knowledge_Transfer.md)

- [Parenting: Optimizing Knowledge Selection of Retrieval-Augmented Language Models with Parameter Decoupling and Tailored Tuning](2024年10月14日/Parenting_Optimizing_Knowledge_Selection_of_Retrieval-Augmented_Language_Models_with_Parameter_Decoupling_and_Tailored_Tuning.md)

    - [翻译: 育儿之道：通过参数解耦与定制调优，优化检索增强语言模型的知识选择](2024年10月14日/Parenting_Optimizing_Knowledge_Selection_of_Retrieval-Augmented_Language_Models_with_Parameter_Decoupling_and_Tailored_Tuning.md)

- [QUITE: Quantifying Uncertainty in Natural Language Text in Bayesian Reasoning Scenarios](2024年10月14日/QUITE_Quantifying_Uncertainty_in_Natural_Language_Text_in_Bayesian_Reasoning_Scenarios.md)

    - [翻译: QUITE：在贝叶斯推理背景下，精准量化自然语言文本的不确定性](2024年10月14日/QUITE_Quantifying_Uncertainty_in_Natural_Language_Text_in_Bayesian_Reasoning_Scenarios.md)

- [Saliency Guided Optimization of Diffusion Latents](2024年10月14日/Saliency_Guided_Optimization_of_Diffusion_Latents.md)

    - [翻译: 显著性引导的扩散潜在优化](2024年10月14日/Saliency_Guided_Optimization_of_Diffusion_Latents.md)

- [SANA: Efficient High-Resolution Image Synthesis with Linear Diffusion Transformers](2024年10月14日/SANA_Efficient_High-Resolution_Image_Synthesis_with_Linear_Diffusion_Transformers.md)

    - [翻译: SANA：通过线性扩散变换器，实现高效的高分辨率图像合成](2024年10月14日/SANA_Efficient_High-Resolution_Image_Synthesis_with_Linear_Diffusion_Transformers.md)

- [SeedLM: Compressing LLM Weights into Seeds of Pseudo-Random Generators](2024年10月14日/SeedLM_Compressing_LLM_Weights_into_Seeds_of_Pseudo-Random_Generators.md)

    - [翻译: SeedLM：将 LLM 权重压缩为伪随机生成器的种子](2024年10月14日/SeedLM_Compressing_LLM_Weights_into_Seeds_of_Pseudo-Random_Generators.md)

- [SensorBench: Benchmarking LLMs in Coding-Based Sensor Processing](2024年10月14日/SensorBench_Benchmarking_LLMs_in_Coding-Based_Sensor_Processing.md)

    - [翻译: SensorBench：为基于编码的传感器处理中的 LLM 提供基准测试](2024年10月14日/SensorBench_Benchmarking_LLMs_in_Coding-Based_Sensor_Processing.md)

- [SensorLLM: Aligning Large Language Models with Motion Sensors for Human Activity Recognition](2024年10月14日/SensorLLM_Aligning_Large_Language_Models_with_Motion_Sensors_for_Human_Activity_Recognition.md)

    - [翻译: SensorLLM：融合大型语言模型与运动传感器，助力人类活动识别](2024年10月14日/SensorLLM_Aligning_Large_Language_Models_with_Motion_Sensors_for_Human_Activity_Recognition.md)

- [Sitcom-Crafter: A Plot-Driven Human Motion Generation System in 3D Scenes](2024年10月14日/Sitcom-Crafter_A_Plot-Driven_Human_Motion_Generation_System_in_3D_Scenes.md)

    - [翻译: Sitcom-Crafter：一款以情节驱动的3D场景中人类动作生成系统](2024年10月14日/Sitcom-Crafter_A_Plot-Driven_Human_Motion_Generation_System_in_3D_Scenes.md)

- [SLaNC: Static LayerNorm Calibration](2024年10月14日/SLaNC_Static_LayerNorm_Calibration.md)

    - [翻译: SLaNC：静态层归一化校准](2024年10月14日/SLaNC_Static_LayerNorm_Calibration.md)

- [SplitLLM: Collaborative Inference of LLMs for Model Placement and Throughput Optimization](2024年10月14日/SplitLLM_Collaborative_Inference_of_LLMs_for_Model_Placement_and_Throughput_Optimization.md)

    - [翻译: SplitLLM：通过协作推理优化 LLM 的模型放置和吞吐量](2024年10月14日/SplitLLM_Collaborative_Inference_of_LLMs_for_Model_Placement_and_Throughput_Optimization.md)

- [Temperature-Centric Investigation of Speculative Decoding with Knowledge Distillation](2024年10月14日/Temperature-Centric_Investigation_of_Speculative_Decoding_with_Knowledge_Distillation.md)

    - [翻译: 聚焦温度，探究知识蒸馏下的推测解码](2024年10月14日/Temperature-Centric_Investigation_of_Speculative_Decoding_with_Knowledge_Distillation.md)

- [Test smells in LLM-Generated Unit Tests](2024年10月14日/Test_smells_in_LLM-Generated_Unit_Tests.md)

    - [翻译: LLM 生成单元测试中的测试异味](2024年10月14日/Test_smells_in_LLM-Generated_Unit_Tests.md)

- [Thinking LLMs: General Instruction Following with Thought Generation](2024年10月14日/Thinking_LLMs_General_Instruction_Following_with_Thought_Generation.md)

    - [翻译: 思考型 LLM：通过思维生成实现通用指令跟随](2024年10月14日/Thinking_LLMs_General_Instruction_Following_with_Thought_Generation.md)

- [TMGBench: A Systematic Game Benchmark for Evaluating Strategic Reasoning Abilities of LLMs](2024年10月14日/TMGBench_A_Systematic_Game_Benchmark_for_Evaluating_Strategic_Reasoning_Abilities_of_LLMs.md)

    - [翻译: TMGBench：一款系统性游戏基准，专为评估 LLMs 的战略推理能力而设计](2024年10月14日/TMGBench_A_Systematic_Game_Benchmark_for_Evaluating_Strategic_Reasoning_Abilities_of_LLMs.md)

- [Towards LLM-guided Efficient and Interpretable Multi-linear Tensor Network Rank Selection](2024年10月14日/Towards_LLM-guided_Efficient_and_Interpretable_Multi-linear_Tensor_Network_Rank_Selection.md)

    - [翻译: 迈向由 LLM 引导的高效且可解释的多线性张量网络秩选择](2024年10月14日/Towards_LLM-guided_Efficient_and_Interpretable_Multi-linear_Tensor_Network_Rank_Selection.md)

- [Use Random Selection for Now: Investigation of Few-Shot Selection Strategies in LLM-based Text Augmentation for Classification](2024年10月14日/Use_Random_Selection_for_Now_Investigation_of_Few-Shot_Selection_Strategies_in_LLM-based_Text_Augmentation_for_Classification.md)

    - [翻译: 目前采用随机选择策略：探讨基于 LLM 的文本增强分类中少样本选择策略的影响](2024年10月14日/Use_Random_Selection_for_Now_Investigation_of_Few-Shot_Selection_Strategies_in_LLM-based_Text_Augmentation_for_Classification.md)

- [When Does Perceptual Alignment Benefit Vision Representations?](2024年10月14日/When_Does_Perceptual_Alignment_Benefit_Vision_Representations.md)

    - [翻译: 何时感知对齐能提升视觉表示的效果？](2024年10月14日/When_Does_Perceptual_Alignment_Benefit_Vision_Representations.md)

- [Will LLMs Replace the Encoder-Only Models in Temporal Relation Classification?](2024年10月14日/Will_LLMs_Replace_the_Encoder-Only_Models_in_Temporal_Relation_Classification.md)

    - [翻译: 大型语言模型（LLMs）是否将取代仅编码器模型，成为时间关系分类的新宠？](2024年10月14日/Will_LLMs_Replace_the_Encoder-Only_Models_in_Temporal_Relation_Classification.md)

- [Words to Wheels: Vision-Based Autonomous Driving Understanding Human Language Instructions Using Foundation Models](2024年10月14日/Words_to_Wheels_Vision-Based_Autonomous_Driving_Understanding_Human_Language_Instructions_Using_Foundation_Models.md)

    - [翻译: 从文字到车轮：基于视觉的自动驾驶系统，利用基础模型理解人类语言指令](2024年10月14日/Words_to_Wheels_Vision-Based_Autonomous_Driving_Understanding_Human_Language_Instructions_Using_Foundation_Models.md)

- [Your Mixture-of-Experts LLM Is Secretly an Embedding Model For Free](2024年10月14日/Your_Mixture-of-Experts_LLM_Is_Secretly_an_Embedding_Model_For_Free.md)

    - [翻译: 你的专家混合型大型语言模型，其实是个免费的嵌入模型哦！](2024年10月14日/Your_Mixture-of-Experts_LLM_Is_Secretly_an_Embedding_Model_For_Free.md)

- [Yuan: Research on the Concept of Digital World Analogue Scientific Infrastructure and Science Popularization Communication Based on Suzhou Gardens Pattern](2024年10月14日/Yuan_Research_on_the_Concept_of_Digital_World_Analogue_Scientific_Infrastructure_and_Science_Popularization_Communication_Based_on_Suzhou_Gardens_Pattern.md)

    - [翻译: 探索苏州园林模式下的数字世界模拟科学基础设施与科普传播新概念](2024年10月14日/Yuan_Research_on_the_Concept_of_Digital_World_Analogue_Scientific_Infrastructure_and_Science_Popularization_Communication_Based_on_Suzhou_Gardens_Pattern.md)

2024年10月13日

- [Adaptive Reasoning and Acting in Medical Language Agents](2024年10月13日/Adaptive_Reasoning_and_Acting_in_Medical_Language_Agents.md)

    - [翻译: 医疗语言代理中的适应性推理与行动](2024年10月13日/Adaptive_Reasoning_and_Acting_in_Medical_Language_Agents.md)

- [A Multi-LLM Orchestration Engine for Personalized, Context-Rich Assistance](2024年10月13日/A_Multi-LLM_Orchestration_Engine_for_Personalized,_Context-Rich_Assistance.md)

    - [翻译: 个性化、上下文感知辅助的多大型语言模型编排引擎](2024年10月13日/A_Multi-LLM_Orchestration_Engine_for_Personalized,_Context-Rich_Assistance.md)

- [Beyond Graphs: Can Large Language Models Comprehend Hypergraphs?](2024年10月13日/Beyond_Graphs_Can_Large_Language_Models_Comprehend_Hypergraphs.md)

    - [翻译: 大型语言模型能否超越图表，理解超图的奥秘？](2024年10月13日/Beyond_Graphs_Can_Large_Language_Models_Comprehend_Hypergraphs.md)

- [BiDoRA: Bi-level Optimization-Based Weight-Decomposed Low-Rank Adaptation](2024年10月13日/BiDoRA_Bi-level_Optimization-Based_Weight-Decomposed_Low-Rank_Adaptation.md)

    - [翻译: BiDoRA：双层优化驱动的权重分解低秩适应](2024年10月13日/BiDoRA_Bi-level_Optimization-Based_Weight-Decomposed_Low-Rank_Adaptation.md)

- [BlackDAN: A Black-Box Multi-Objective Approach for Effective and Contextual Jailbreaking of Large Language Models](2024年10月13日/BlackDAN_A_Black-Box_Multi-Objective_Approach_for_Effective_and_Contextual_Jailbreaking_of_Large_Language_Models.md)

    - [翻译: BlackDAN：一种黑盒多目标策略，专为有效且情境化的破解大型语言模型而设计。](2024年10月13日/BlackDAN_A_Black-Box_Multi-Objective_Approach_for_Effective_and_Contextual_Jailbreaking_of_Large_Language_Models.md)

- [Can Large Language Models Generate Geospatial Code?](2024年10月13日/Can_Large_Language_Models_Generate_Geospatial_Code.md)

    - [翻译: 大型语言模型能否编写地理空间代码？](2024年10月13日/Can_Large_Language_Models_Generate_Geospatial_Code.md)

- [Can We Predict Performance of Large Models across Vision-Language Tasks?](2024年10月13日/Can_We_Predict_Performance_of_Large_Models_across_Vision-Language_Tasks.md)

    - [翻译: 大型模型在视觉-语言任务中的表现，我们能否精准预测？](2024年10月13日/Can_We_Predict_Performance_of_Large_Models_across_Vision-Language_Tasks.md)

- [Dynamic and Textual Graph Generation Via Large-Scale LLM-based Agent Simulation](2024年10月13日/Dynamic_and_Textual_Graph_Generation_Via_Large-Scale_LLM-based_Agent_Simulation.md)

    - [翻译: 通过大规模 LLM 代理模拟实现动态与文本图生成](2024年10月13日/Dynamic_and_Textual_Graph_Generation_Via_Large-Scale_LLM-based_Agent_Simulation.md)

- [ECIS-VQG: Generation of Entity-centric Information-seeking Questions from Videos](2024年10月13日/ECIS-VQG_Generation_of_Entity-centric_Information-seeking_Questions_from_Videos.md)

    - [翻译: ECIS-VQG：视频中实体导向的信息探索问题生成](2024年10月13日/ECIS-VQG_Generation_of_Entity-centric_Information-seeking_Questions_from_Videos.md)

- [How to Leverage Demonstration Data in Alignment for Large Language Model? A Self-Imitation Learning Perspective](2024年10月13日/How_to_Leverage_Demonstration_Data_in_Alignment_for_Large_Language_Model_A_Self-Imitation_Learning_Perspective.md)

    - [翻译: 如何在大语言模型对齐中巧妙利用演示数据？让我们从自我模仿学习的角度一探究竟。](2024年10月13日/How_to_Leverage_Demonstration_Data_in_Alignment_for_Large_Language_Model_A_Self-Imitation_Learning_Perspective.md)

- [LOKI: A Comprehensive Synthetic Data Detection Benchmark using Large Multimodal Models](2024年10月13日/LOKI_A_Comprehensive_Synthetic_Data_Detection_Benchmark_using_Large_Multimodal_Models.md)

    - [翻译: LOKI：基于大型多模态模型的综合合成数据检测基准](2024年10月13日/LOKI_A_Comprehensive_Synthetic_Data_Detection_Benchmark_using_Large_Multimodal_Models.md)

- [M2M-Gen: A Multimodal Framework for Automated Background Music Generation in Japanese Manga Using Large Language Models](2024年10月13日/M2M-Gen_A_Multimodal_Framework_for_Automated_Background_Music_Generation_in_Japanese_Manga_Using_Large_Language_Models.md)

    - [翻译: M2M-Gen：一个利用大型语言模型自动为日本漫画生成背景音乐的多模态框架](2024年10月13日/M2M-Gen_A_Multimodal_Framework_for_Automated_Background_Music_Generation_in_Japanese_Manga_Using_Large_Language_Models.md)

- [MIRAGE: Multimodal Identification and Recognition of Annotations in Indian General Prescriptions](2024年10月13日/MIRAGE_Multimodal_Identification_and_Recognition_of_Annotations_in_Indian_General_Prescriptions.md)

    - [翻译: MIRAGE：印度通用处方中注释的多模态识别与识别系统](2024年10月13日/MIRAGE_Multimodal_Identification_and_Recognition_of_Annotations_in_Indian_General_Prescriptions.md)

- [MMCOMPOSITION: Revisiting the Compositionality of Pre-trained Vision-Language Models](2024年10月13日/MMCOMPOSITION_Revisiting_the_Compositionality_of_Pre-trained_Vision-Language_Models.md)

    - [翻译: MMCOMPOSITION：探索预训练视觉-语言模型的组合性](2024年10月13日/MMCOMPOSITION_Revisiting_the_Compositionality_of_Pre-trained_Vision-Language_Models.md)

- ['Quis custodiet ipsos custodes?' Who will watch the watchmen? On Detecting AI-generated peer-reviews](2024年10月13日/'Quis_custodiet_ipsos_custodes'_Who_will_watch_the_watchmen_On_Detecting_AI-generated_peer-reviews.md)

    - [翻译: “谁来监督监督者？” —— 探讨如何检测 AI 生成的同行评审](2024年10月13日/'Quis_custodiet_ipsos_custodes'_Who_will_watch_the_watchmen_On_Detecting_AI-generated_peer-reviews.md)

- [Retrieval Instead of Fine-tuning: A Retrieval-based Parameter Ensemble for Zero-shot Learning](2024年10月13日/Retrieval_Instead_of_Fine-tuning_A_Retrieval-based_Parameter_Ensemble_for_Zero-shot_Learning.md)

    - [翻译: 用检索取代微调：探索基于检索的参数集成在零-shot 学习中的应用](2024年10月13日/Retrieval_Instead_of_Fine-tuning_A_Retrieval-based_Parameter_Ensemble_for_Zero-shot_Learning.md)

- [Targeted Vaccine: Safety Alignment for Large Language Models against Harmful Fine-Tuning via Layer-wise Perturbation](2024年10月13日/Targeted_Vaccine_Safety_Alignment_for_Large_Language_Models_against_Harmful_Fine-Tuning_via_Layer-wise_Perturbation.md)

    - [翻译: 目标疫苗：通过逐层扰动保护大型语言模型免受有害微调的影响，确保安全对齐](2024年10月13日/Targeted_Vaccine_Safety_Alignment_for_Large_Language_Models_against_Harmful_Fine-Tuning_via_Layer-wise_Perturbation.md)

- [Text4Seg: Reimagining Image Segmentation as Text Generation](2024年10月13日/Text4Seg_Reimagining_Image_Segmentation_as_Text_Generation.md)

    - [翻译: Text4Seg：重塑图像分割为文本生成](2024年10月13日/Text4Seg_Reimagining_Image_Segmentation_as_Text_Generation.md)

2024年10月12日

- [AERA Chat: An Interactive Platform for Automated Explainable Student Answer Assessment](2024年10月12日/AERA_Chat_An_Interactive_Platform_for_Automated_Explainable_Student_Answer_Assessment.md)

    - [翻译: AERA Chat：一个自动化且可解释的学生答案评估交互平台](2024年10月12日/AERA_Chat_An_Interactive_Platform_for_Automated_Explainable_Student_Answer_Assessment.md)

- [Agentic Information Retrieval](2024年10月12日/Agentic_Information_Retrieval.md)

    - [翻译: 主动信息检索](2024年10月12日/Agentic_Information_Retrieval.md)

- [Are You Human? An Adversarial Benchmark to Expose LLMs](2024年10月12日/Are_You_Human_An_Adversarial_Benchmark_to_Expose_LLMs.md)

    - [翻译: “你是人类吗？”——一个对抗性基准，旨在揭示大型语言模型的真实面目。](2024年10月12日/Are_You_Human_An_Adversarial_Benchmark_to_Expose_LLMs.md)

- [Boosting Deductive Reasoning with Step Signals In RLHF](2024年10月12日/Boosting_Deductive_Reasoning_with_Step_Signals_In_RLHF.md)

    - [翻译: 通过步骤信号提升 RLHF 中的演绎推理能力](2024年10月12日/Boosting_Deductive_Reasoning_with_Step_Signals_In_RLHF.md)

- [CAMPHOR: Collaborative Agents for Multi-input Planning and High-Order Reasoning On Device](2024年10月12日/CAMPHOR_Collaborative_Agents_for_Multi-input_Planning_and_High-Order_Reasoning_On_Device.md)

    - [翻译: CAMPHOR：设备上多输入规划与高阶推理的协作代理](2024年10月12日/CAMPHOR_Collaborative_Agents_for_Multi-input_Planning_and_High-Order_Reasoning_On_Device.md)

- [CollabEdit: Towards Non-destructive Collaborative Knowledge Editing](2024年10月12日/CollabEdit_Towards_Non-destructive_Collaborative_Knowledge_Editing.md)

    - [翻译: CollabEdit：开启非破坏性协作知识编辑的新篇章](2024年10月12日/CollabEdit_Towards_Non-destructive_Collaborative_Knowledge_Editing.md)

- [COrAL: Order-Agnostic Language Modeling for Efficient Iterative Refinement](2024年10月12日/COrAL_Order-Agnostic_Language_Modeling_for_Efficient_Iterative_Refinement.md)

    - [翻译: COrAL：一种高效迭代细化的无序语言建模方法](2024年10月12日/COrAL_Order-Agnostic_Language_Modeling_for_Efficient_Iterative_Refinement.md)

- [DRCap: Decoding CLAP Latents with Retrieval-augmented Generation for Zero-shot Audio Captioning](2024年10月12日/DRCap_Decoding_CLAP_Latents_with_Retrieval-augmented_Generation_for_Zero-shot_Audio_Captioning.md)

    - [翻译: DRCap：通过检索增强生成技术，解码 CLAP 潜在变量，实现零-shot 音频字幕生成。](2024年10月12日/DRCap_Decoding_CLAP_Latents_with_Retrieval-augmented_Generation_for_Zero-shot_Audio_Captioning.md)

- [Enhanced Electronic Health Records Text Summarization Using Large Language Models](2024年10月12日/Enhanced_Electronic_Health_Records_Text_Summarization_Using_Large_Language_Models.md)

    - [翻译: 借助大型语言模型，电子健康记录的文本摘要能力得以提升。](2024年10月12日/Enhanced_Electronic_Health_Records_Text_Summarization_Using_Large_Language_Models.md)

- [Exploring Demonstration Retrievers in RAG for Coding Tasks: Yeas and Nays!](2024年10月12日/Exploring_Demonstration_Retrievers_in_RAG_for_Coding_Tasks_Yeas_and_Nays!.md)

    - [翻译: RAG 中编码任务演示检索器的探索：利弊分析！](2024年10月12日/Exploring_Demonstration_Retrievers_in_RAG_for_Coding_Tasks_Yeas_and_Nays!.md)

- [FlatQuant: Flatness Matters for LLM Quantization](2024年10月12日/FlatQuant_Flatness_Matters_for_LLM_Quantization.md)

    - [翻译: FlatQuant：平坦性在 LLM 量化中举足轻重](2024年10月12日/FlatQuant_Flatness_Matters_for_LLM_Quantization.md)

- [Honest AI: Fine-Tuning "Small" Language Models to Say "I Don't Know", and Reducing Hallucination in RAG](2024年10月12日/Honest_AI_Fine-Tuning_Small_Language_Models_to_Say_I_Don't_Know,_and_Reducing_Hallucination_in_RAG.md)

    - [翻译: 让AI更诚实：通过微调小型语言模型，使其能说“我不知道”，并减少RAG中的幻觉现象。](2024年10月12日/Honest_AI_Fine-Tuning_Small_Language_Models_to_Say_I_Don't_Know,_and_Reducing_Hallucination_in_RAG.md)

- [LINKED: Eliciting, Filtering and Integrating Knowledge in Large Language Model for Commonsense Reasoning](2024年10月12日/LINKED_Eliciting,_Filtering_and_Integrating_Knowledge_in_Large_Language_Model_for_Commonsense_Reasoning.md)

    - [翻译: 在大型语言模型中，如何巧妙地引出、筛选并整合知识，以提升常识推理能力，是我们探讨的核心。](2024年10月12日/LINKED_Eliciting,_Filtering_and_Integrating_Knowledge_in_Large_Language_Model_for_Commonsense_Reasoning.md)

- [LLM-SmartAudit: Advanced Smart Contract Vulnerability Detection](2024年10月12日/LLM-SmartAudit_Advanced_Smart_Contract_Vulnerability_Detection.md)

    - [翻译: LLM-SmartAudit：智能合约漏洞检测的尖端技术](2024年10月12日/LLM-SmartAudit_Advanced_Smart_Contract_Vulnerability_Detection.md)

- [MIRAGE: Evaluating and Explaining Inductive Reasoning Process in Language Models](2024年10月12日/MIRAGE_Evaluating_and_Explaining_Inductive_Reasoning_Process_in_Language_Models.md)

    - [翻译: MIRAGE：探索与揭示语言模型中的归纳推理奥秘](2024年10月12日/MIRAGE_Evaluating_and_Explaining_Inductive_Reasoning_Process_in_Language_Models.md)

- [MMAD: The First-Ever Comprehensive Benchmark for Multimodal Large Language Models in Industrial Anomaly Detection](2024年10月12日/MMAD_The_First-Ever_Comprehensive_Benchmark_for_Multimodal_Large_Language_Models_in_Industrial_Anomaly_Detection.md)

    - [翻译: MMAD：工业异常检测领域首个多模态大型语言模型的全面基准](2024年10月12日/MMAD_The_First-Ever_Comprehensive_Benchmark_for_Multimodal_Large_Language_Models_in_Industrial_Anomaly_Detection.md)

- [MoIN: Mixture of Introvert Experts to Upcycle an LLM](2024年10月12日/MoIN_Mixture_of_Introvert_Experts_to_Upcycle_an_LLM.md)

    - [翻译: MoIN：内向专家混合体，助力 LLM 升级](2024年10月12日/MoIN_Mixture_of_Introvert_Experts_to_Upcycle_an_LLM.md)

- [MTL-LoRA: Low-Rank Adaptation for Multi-Task Learning](2024年10月12日/MTL-LoRA_Low-Rank_Adaptation_for_Multi-Task_Learning.md)

    - [翻译: MTL-LoRA：多任务学习的低秩适应](2024年10月12日/MTL-LoRA_Low-Rank_Adaptation_for_Multi-Task_Learning.md)

- [Quebec Automobile Insurance Question-Answering With Retrieval-Augmented Generation](2024年10月12日/Quebec_Automobile_Insurance_Question-Answering_With_Retrieval-Augmented_Generation.md)

    - [翻译: 魁北克汽车保险问答系统：检索增强生成技术应用](2024年10月12日/Quebec_Automobile_Insurance_Question-Answering_With_Retrieval-Augmented_Generation.md)

- [Reconstructive Visual Instruction Tuning](2024年10月12日/Reconstructive_Visual_Instruction_Tuning.md)

    - [翻译: 视觉指令的重构调整](2024年10月12日/Reconstructive_Visual_Instruction_Tuning.md)

- [Skipping Computations in Multimodal LLMs](2024年10月12日/Skipping_Computations_in_Multimodal_LLMs.md)

    - [翻译: 多模态 LLM 中的计算跳跃](2024年10月12日/Skipping_Computations_in_Multimodal_LLMs.md)

- [SLiM: One-shot Quantized Sparse Plus Low-rank Approximation of LLMs](2024年10月12日/SLiM_One-shot_Quantized_Sparse_Plus_Low-rank_Approximation_of_LLMs.md)

    - [翻译: SLiM：一次量化稀疏加低秩近似 LLM](2024年10月12日/SLiM_One-shot_Quantized_Sparse_Plus_Low-rank_Approximation_of_LLMs.md)

- [Synthetic Knowledge Ingestion: Towards Knowledge Refinement and Injection for Enhancing Large Language Models](2024年10月12日/Synthetic_Knowledge_Ingestion_Towards_Knowledge_Refinement_and_Injection_for_Enhancing_Large_Language_Models.md)

    - [翻译: 合成知识摄取：通过知识精炼与注入，提升大型语言模型的能力](2024年10月12日/Synthetic_Knowledge_Ingestion_Towards_Knowledge_Refinement_and_Injection_for_Enhancing_Large_Language_Models.md)

- [The Future of Learning in the Age of Generative AI: Automated Question Generation and Assessment with Large Language Models](2024年10月12日/The_Future_of_Learning_in_the_Age_of_Generative_AI_Automated_Question_Generation_and_Assessment_with_Large_Language_Models.md)

    - [翻译: 在生成式 AI 时代，学习将迎来新变革：借助大型语言模型，实现自动问题生成与评估。](2024年10月12日/The_Future_of_Learning_in_the_Age_of_Generative_AI_Automated_Question_Generation_and_Assessment_with_Large_Language_Models.md)

- [Towards Efficient Visual-Language Alignment of the Q-Former for Visual Reasoning Tasks](2024年10月12日/Towards_Efficient_Visual-Language_Alignment_of_the_Q-Former_for_Visual_Reasoning_Tasks.md)

    - [翻译: 探索 Q-Former 在视觉推理任务中视觉与语言对齐的高效路径](2024年10月12日/Towards_Efficient_Visual-Language_Alignment_of_the_Q-Former_for_Visual_Reasoning_Tasks.md)

- [Training Dynamics of Transformers to Recognize Word Co-occurrence via Gradient Flow Analysis](2024年10月12日/Training_Dynamics_of_Transformers_to_Recognize_Word_Co-occurrence_via_Gradient_Flow_Analysis.md)

    - [翻译: 通过梯度流分析，揭示 Transformer 识别词共现的训练动态](2024年10月12日/Training_Dynamics_of_Transformers_to_Recognize_Word_Co-occurrence_via_Gradient_Flow_Analysis.md)

- [Two Heads Are Better Than One: A Multi-Agent System Has the Potential to Improve Scientific Idea Generation](2024年10月12日/Two_Heads_Are_Better_Than_One_A_Multi-Agent_System_Has_the_Potential_to_Improve_Scientific_Idea_Generation.md)

    - [翻译: 双脑协作，科学创意更上一层楼：多智能体系统助力创新思维](2024年10月12日/Two_Heads_Are_Better_Than_One_A_Multi-Agent_System_Has_the_Potential_to_Improve_Scientific_Idea_Generation.md)

2024年10月11日

- [ACER: Automatic Language Model Context Extension via Retrieval](2024年10月11日/ACER_Automatic_Language_Model_Context_Extension_via_Retrieval.md)

    - [翻译: ACER：利用检索技术自动扩展语言模型的上下文](2024年10月11日/ACER_Automatic_Language_Model_Context_Extension_via_Retrieval.md)

- [A Methodology for Evaluating RAG Systems: A Case Study On Configuration Dependency Validation](2024年10月11日/A_Methodology_for_Evaluating_RAG_Systems_A_Case_Study_On_Configuration_Dependency_Validation.md)

    - [翻译: RAG 系统评估方法论：配置依赖验证案例研究](2024年10月11日/A_Methodology_for_Evaluating_RAG_Systems_A_Case_Study_On_Configuration_Dependency_Validation.md)

- [A Social Context-aware Graph-based Multimodal Attentive Learning Framework for Disaster Content Classification during Emergencies](2024年10月11日/A_Social_Context-aware_Graph-based_Multimodal_Attentive_Learning_Framework_for_Disaster_Content_Classification_during_Emergencies.md)

    - [翻译: 一种基于社交上下文和图结构的多模态注意力学习框架，专为紧急情况下的灾难内容分类设计](2024年10月11日/A_Social_Context-aware_Graph-based_Multimodal_Attentive_Learning_Framework_for_Disaster_Content_Classification_during_Emergencies.md)

- [Audio Description Generation in the Era of LLMs and VLMs: A Review of Transferable Generative AI Technologies](2024年10月11日/Audio_Description_Generation_in_the_Era_of_LLMs_and_VLMs_A_Review_of_Transferable_Generative_AI_Technologies.md)

    - [翻译: 在 LLM 和 VLM 时代，音频描述生成：探索可转移的生成 AI 技术](2024年10月11日/Audio_Description_Generation_in_the_Era_of_LLMs_and_VLMs_A_Review_of_Transferable_Generative_AI_Technologies.md)

- [AutoPersuade: A Framework for Evaluating and Explaining Persuasive Arguments](2024年10月11日/AutoPersuade_A_Framework_for_Evaluating_and_Explaining_Persuasive_Arguments.md)

    - [翻译: AutoPersuade：一款评估与解释说服性论点的框架](2024年10月11日/AutoPersuade_A_Framework_for_Evaluating_and_Explaining_Persuasive_Arguments.md)

- [From N-grams to Pre-trained Multilingual Models For Language Identification](2024年10月11日/From_N-grams_to_Pre-trained_Multilingual_Models_For_Language_Identification.md)

    - [翻译: 从 N-grams 到预训练的多语言模型：语言识别的新篇章](2024年10月11日/From_N-grams_to_Pre-trained_Multilingual_Models_For_Language_Identification.md)

- [Hypothesis-only Biases in Large Language Model-Elicited Natural Language Inference](2024年10月11日/Hypothesis-only_Biases_in_Large_Language_Model-Elicited_Natural_Language_Inference.md)

    - [翻译: 大型语言模型在自然语言推理中仅依赖假设的偏差](2024年10月11日/Hypothesis-only_Biases_in_Large_Language_Model-Elicited_Natural_Language_Inference.md)

- [Investigating Human-Computer Interaction and Visual Comprehension in Text Generation Process of Natural Language Generation Models](2024年10月11日/Investigating_Human-Computer_Interaction_and_Visual_Comprehension_in_Text_Generation_Process_of_Natural_Language_Generation_Models.md)

    - [翻译: 探索人类与计算机交互及视觉理解在自然语言生成模型文本生成中的影响](2024年10月11日/Investigating_Human-Computer_Interaction_and_Visual_Comprehension_in_Text_Generation_Process_of_Natural_Language_Generation_Models.md)

- [Language-Model-Assisted Bi-Level Programming for Reward Learning from Internet Videos](2024年10月11日/Language-Model-Assisted_Bi-Level_Programming_for_Reward_Learning_from_Internet_Videos.md)

    - [翻译: 借助语言模型的双层编程，从网络视频中学习奖励机制](2024年10月11日/Language-Model-Assisted_Bi-Level_Programming_for_Reward_Learning_from_Internet_Videos.md)

- [Losing dimensions: Geometric memorization in generative diffusion](2024年10月11日/Losing_dimensions_Geometric_memorization_in_generative_diffusion.md)

    - [翻译: 维度迷失：生成扩散中的几何记忆](2024年10月11日/Losing_dimensions_Geometric_memorization_in_generative_diffusion.md)

- [NoVo: Norm Voting off Hallucinations with Attention Heads in Large Language Models](2024年10月11日/NoVo_Norm_Voting_off_Hallucinations_with_Attention_Heads_in_Large_Language_Models.md)

    - [翻译: NoVo：通过 LLM 中的注意力头规范投票，消除幻觉](2024年10月11日/NoVo_Norm_Voting_off_Hallucinations_with_Attention_Heads_in_Large_Language_Models.md)

- [PILLAR: an AI-Powered Privacy Threat Modeling Tool](2024年10月11日/PILLAR_an_AI-Powered_Privacy_Threat_Modeling_Tool.md)

    - [翻译: PILLAR：一款由 AI 驱动的隐私威胁建模利器](2024年10月11日/PILLAR_an_AI-Powered_Privacy_Threat_Modeling_Tool.md)

- [Preferential Normalizing Flows](2024年10月11日/Preferential_Normalizing_Flows.md)

    - [翻译: 偏好归一化流](2024年10月11日/Preferential_Normalizing_Flows.md)

- [QEFT: Quantization for Efficient Fine-Tuning of LLMs](2024年10月11日/QEFT_Quantization_for_Efficient_Fine-Tuning_of_LLMs.md)

    - [翻译: QEFT：通过量化实现 LLM 的高效微调](2024年10月11日/QEFT_Quantization_for_Efficient_Fine-Tuning_of_LLMs.md)

- [RePD: Defending Jailbreak Attack through a Retrieval-based Prompt Decomposition Process](2024年10月11日/RePD_Defending_Jailbreak_Attack_through_a_Retrieval-based_Prompt_Decomposition_Process.md)

    - [翻译: RePD：利用基于检索的提示分解技术，有效抵御越狱攻击。](2024年10月11日/RePD_Defending_Jailbreak_Attack_through_a_Retrieval-based_Prompt_Decomposition_Process.md)

- [Semi-Supervised Learning of Noisy Mixture of Experts Models](2024年10月11日/Semi-Supervised_Learning_of_Noisy_Mixture_of_Experts_Models.md)

    - [翻译: 半监督噪声混合专家模型学习](2024年10月11日/Semi-Supervised_Learning_of_Noisy_Mixture_of_Experts_Models.md)

- [SimpleStrat: Diversifying Language Model Generation with Stratification](2024年10月11日/SimpleStrat_Diversifying_Language_Model_Generation_with_Stratification.md)

    - [翻译: SimpleStrat：以分层策略丰富语言模型生成多样性](2024年10月11日/SimpleStrat_Diversifying_Language_Model_Generation_with_Stratification.md)

- [SocialGaze: Improving the Integration of Human Social Norms in Large Language Models](2024年10月11日/SocialGaze_Improving_the_Integration_of_Human_Social_Norms_in_Large_Language_Models.md)

    - [翻译: SocialGaze：提升大型语言模型中人类社会规范的融合](2024年10月11日/SocialGaze_Improving_the_Integration_of_Human_Social_Norms_in_Large_Language_Models.md)

- [Software Engineering and Foundation Models: Insights from Industry Blogs Using a Jury of Foundation Models](2024年10月11日/Software_Engineering_and_Foundation_Models_Insights_from_Industry_Blogs_Using_a_Jury_of_Foundation_Models.md)

    - [翻译: 软件工程与基础模型：通过基础模型陪审团，从行业博客中汲取的洞见](2024年10月11日/Software_Engineering_and_Foundation_Models_Insights_from_Industry_Blogs_Using_a_Jury_of_Foundation_Models.md)

- [StructRAG: Boosting Knowledge Intensive Reasoning of LLMs via Inference-time Hybrid Information Structurization](2024年10月11日/StructRAG_Boosting_Knowledge_Intensive_Reasoning_of_LLMs_via_Inference-time_Hybrid_Information_Structurization.md)

    - [翻译: StructRAG：通过推理时的混合信息结构化，大幅提升 LLM 在知识密集型推理中的表现。](2024年10月11日/StructRAG_Boosting_Knowledge_Intensive_Reasoning_of_LLMs_via_Inference-time_Hybrid_Information_Structurization.md)

- [Utilizing ChatGPT in a Data Structures and Algorithms Course: A Teaching Assistant's Perspective](2024年10月11日/Utilizing_ChatGPT_in_a_Data_Structures_and_Algorithms_Course_A_Teaching_Assistant's_Perspective.md)

    - [翻译: ChatGPT 在数据结构与算法课程中的应用：一位助教的视角](2024年10月11日/Utilizing_ChatGPT_in_a_Data_Structures_and_Algorithms_Course_A_Teaching_Assistant's_Perspective.md)

- [When Graph meets Multimodal: Benchmarking on Multimodal Attributed Graphs Learning](2024年10月11日/When_Graph_meets_Multimodal_Benchmarking_on_Multimodal_Attributed_Graphs_Learning.md)

    - [翻译: 图与多模态的邂逅：多模态属性图学习的基准测试](2024年10月11日/When_Graph_meets_Multimodal_Benchmarking_on_Multimodal_Attributed_Graphs_Learning.md)

2024年10月10日

- [Increasing the Difficulty of Automatically Generated Questions via Reinforcement Learning with Synthetic Preference](2024年10月10日/Increasing_the_Difficulty_of_Automatically_Generated_Questions_via_Reinforcement_Learning_with_Synthetic_Preference.md)

    - [翻译: 利用强化学习与合成偏好提升自动生成问题的难度](2024年10月10日/Increasing_the_Difficulty_of_Automatically_Generated_Questions_via_Reinforcement_Learning_with_Synthetic_Preference.md)

- [Large Legislative Models: Towards Efficient AI Policymaking in Economic Simulations](2024年10月10日/Large_Legislative_Models_Towards_Efficient_AI_Policymaking_in_Economic_Simulations.md)

    - [翻译: 大型立法模型：助力经济模拟中的高效 AI 政策制定](2024年10月10日/Large_Legislative_Models_Towards_Efficient_AI_Policymaking_in_Economic_Simulations.md)

- [SPORTU: A Comprehensive Sports Understanding Benchmark for Multimodal Large Language Models](2024年10月10日/SPORTU_A_Comprehensive_Sports_Understanding_Benchmark_for_Multimodal_Large_Language_Models.md)

    - [翻译: SPORTU：专为多模态大型语言模型设计的综合性体育理解基准](2024年10月10日/SPORTU_A_Comprehensive_Sports_Understanding_Benchmark_for_Multimodal_Large_Language_Models.md)

2024年10月09日

- [Enhancing UI Location Capabilities of Autonomous Agents](2024年10月09日/Enhancing_UI_Location_Capabilities_of_Autonomous_Agents.md)

    - [翻译: 提升自主代理的UI定位功能](2024年10月09日/Enhancing_UI_Location_Capabilities_of_Autonomous_Agents.md)

- [Pixtral 12B](2024年10月09日/Pixtral_12B.md)

    - [翻译: Pixtral 12B](2024年10月09日/Pixtral_12B.md)

- [Representation Alignment for Generation: Training Diffusion Transformers Is Easier Than You Think](2024年10月09日/Representation_Alignment_for_Generation_Training_Diffusion_Transformers_Is_Easier_Than_You_Think.md)

    - [翻译: 生成任务中的表示对齐：训练扩散变换器其实比你想象的更简单](2024年10月09日/Representation_Alignment_for_Generation_Training_Diffusion_Transformers_Is_Easier_Than_You_Think.md)

2024年10月08日

- [Application of NotebookLM, a Large Language Model with Retrieval-Augmented Generation, for Lung Cancer Staging](2024年10月08日/Application_of_NotebookLM,_a_Large_Language_Model_with_Retrieval-Augmented_Generation,_for_Lung_Cancer_Staging.md)

    - [翻译: NotebookLM，一款结合检索增强生成技术的大型语言模型，正被用于肺癌分期研究。](2024年10月08日/Application_of_NotebookLM,_a_Large_Language_Model_with_Retrieval-Augmented_Generation,_for_Lung_Cancer_Staging.md)

- [LLaCA: Multimodal Large Language Continual Assistant](2024年10月08日/LLaCA_Multimodal_Large_Language_Continual_Assistant.md)

    - [翻译: LLaCA：多模态大型语言持续助手](2024年10月08日/LLaCA_Multimodal_Large_Language_Continual_Assistant.md)

- [ToolBridge: An Open-Source Dataset to Equip LLMs with External Tool Capabilities](2024年10月08日/ToolBridge_An_Open-Source_Dataset_to_Equip_LLMs_with_External_Tool_Capabilities.md)

    - [翻译: ToolBridge：一款开源数据集，旨在赋予大型语言模型（LLM）使用外部工具的能力。](2024年10月08日/ToolBridge_An_Open-Source_Dataset_to_Equip_LLMs_with_External_Tool_Capabilities.md)

2024年10月06日

- [CogDevelop2K: Reversed Cognitive Development in Multimodal Large Language Models](2024年10月06日/CogDevelop2K_Reversed_Cognitive_Development_in_Multimodal_Large_Language_Models.md)

    - [翻译: CogDevelop2K：探索多模态大型语言模型中的逆向认知发展](2024年10月06日/CogDevelop2K_Reversed_Cognitive_Development_in_Multimodal_Large_Language_Models.md)

- [SafeLLM: Domain-Specific Safety Monitoring for Large Language Models: A Case Study of Offshore Wind Maintenance](2024年10月06日/SafeLLM_Domain-Specific_Safety_Monitoring_for_Large_Language_Models_A_Case_Study_of_Offshore_Wind_Maintenance.md)

    - [翻译: SafeLLM：专为大型语言模型设计的领域特定安全监控系统，以海上风电维护为例进行探讨。](2024年10月06日/SafeLLM_Domain-Specific_Safety_Monitoring_for_Large_Language_Models_A_Case_Study_of_Offshore_Wind_Maintenance.md)

- [SouLLMate: An Adaptive LLM-Driven System for Advanced Mental Health Support and Assessment, Based on a Systematic Application Survey](2024年10月06日/SouLLMate_An_Adaptive_LLM-Driven_System_for_Advanced_Mental_Health_Support_and_Assessment,_Based_on_a_Systematic_Application_Survey.md)

    - [翻译: SouLLMate：一款自适应的 LLM 驱动系统，专为高级心理健康支持和评估设计，基于系统的应用调查。](2024年10月06日/SouLLMate_An_Adaptive_LLM-Driven_System_for_Advanced_Mental_Health_Support_and_Assessment,_Based_on_a_Systematic_Application_Survey.md)

2024年10月04日

- [A Large Language Model-based Framework for Semi-Structured Tender Document Retrieval-Augmented Generation](2024年10月04日/A_Large_Language_Model-based_Framework_for_Semi-Structured_Tender_Document_Retrieval-Augmented_Generation.md)

    - [翻译: 大型语言模型驱动的半结构化招标文件检索与生成框架](2024年10月04日/A_Large_Language_Model-based_Framework_for_Semi-Structured_Tender_Document_Retrieval-Augmented_Generation.md)