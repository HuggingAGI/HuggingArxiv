# 2024年10月

2024年10月11日

- [A Methodology for Evaluating RAG Systems: A Case Study On Configuration Dependency Validation](2024年10月11日/A_Methodology_for_Evaluating_RAG_Systems_A_Case_Study_On_Configuration_Dependency_Validation.md)

    - [翻译: RAG 系统评估方法论：配置依赖验证案例研究](2024年10月11日/A_Methodology_for_Evaluating_RAG_Systems_A_Case_Study_On_Configuration_Dependency_Validation.md)

- [A Social Context-aware Graph-based Multimodal Attentive Learning Framework for Disaster Content Classification during Emergencies](2024年10月11日/A_Social_Context-aware_Graph-based_Multimodal_Attentive_Learning_Framework_for_Disaster_Content_Classification_during_Emergencies.md)

    - [翻译: 一种基于社交上下文和图结构的多模态注意力学习框架，专为紧急情况下的灾难内容分类设计](2024年10月11日/A_Social_Context-aware_Graph-based_Multimodal_Attentive_Learning_Framework_for_Disaster_Content_Classification_during_Emergencies.md)

- [Audio Description Generation in the Era of LLMs and VLMs: A Review of Transferable Generative AI Technologies](2024年10月11日/Audio_Description_Generation_in_the_Era_of_LLMs_and_VLMs_A_Review_of_Transferable_Generative_AI_Technologies.md)

    - [翻译: 在 LLM 和 VLM 时代，音频描述生成：探索可转移的生成 AI 技术](2024年10月11日/Audio_Description_Generation_in_the_Era_of_LLMs_and_VLMs_A_Review_of_Transferable_Generative_AI_Technologies.md)

- [AutoPersuade: A Framework for Evaluating and Explaining Persuasive Arguments](2024年10月11日/AutoPersuade_A_Framework_for_Evaluating_and_Explaining_Persuasive_Arguments.md)

    - [翻译: AutoPersuade：一款评估与解释说服性论点的框架](2024年10月11日/AutoPersuade_A_Framework_for_Evaluating_and_Explaining_Persuasive_Arguments.md)

- [Can GPTs Evaluate Graphic Design Based on Design Principles?](2024年10月11日/Can_GPTs_Evaluate_Graphic_Design_Based_on_Design_Principles.md)

    - [翻译: GPTs 能否依据设计原则评判平面设计？](2024年10月11日/Can_GPTs_Evaluate_Graphic_Design_Based_on_Design_Principles.md)

- [Decoding Secret Memorization in Code LLMs Through Token-Level Characterization](2024年10月11日/Decoding_Secret_Memorization_in_Code_LLMs_Through_Token-Level_Characterization.md)

    - [翻译: 揭秘代码 LLM 中的隐秘记忆：基于 Token 级别的特征分析](2024年10月11日/Decoding_Secret_Memorization_in_Code_LLMs_Through_Token-Level_Characterization.md)

- [Developing a Pragmatic Benchmark for Assessing Korean Legal Language Understanding in Large Language Models](2024年10月11日/Developing_a_Pragmatic_Benchmark_for_Assessing_Korean_Legal_Language_Understanding_in_Large_Language_Models.md)

    - [翻译: 打造实用基准，评估大型语言模型对韩语法律语言的理解](2024年10月11日/Developing_a_Pragmatic_Benchmark_for_Assessing_Korean_Legal_Language_Understanding_in_Large_Language_Models.md)

- [Don't Transform the Code, Code the Transforms: Towards Precise Code Rewriting using LLMs](2024年10月11日/Don't_Transform_the_Code,_Code_the_Transforms_Towards_Precise_Code_Rewriting_using_LLMs.md)

    - [翻译: 别改代码，改写代码：利用 LLM 实现精准代码重写的新思路](2024年10月11日/Don't_Transform_the_Code,_Code_the_Transforms_Towards_Precise_Code_Rewriting_using_LLMs.md)

- [Do Unlearning Methods Remove Information from Language Model Weights?](2024年10月11日/Do_Unlearning_Methods_Remove_Information_from_Language_Model_Weights.md)

    - [翻译: 遗忘方法能否真正从语言模型权重中移除信息？](2024年10月11日/Do_Unlearning_Methods_Remove_Information_from_Language_Model_Weights.md)

- [Dual-AEB: Synergizing Rule-Based and Multimodal Large Language Models for Effective Emergency Braking](2024年10月11日/Dual-AEB_Synergizing_Rule-Based_and_Multimodal_Large_Language_Models_for_Effective_Emergency_Braking.md)

    - [翻译: 双-AEB：融合规则与多模态大型语言模型，实现高效紧急制动](2024年10月11日/Dual-AEB_Synergizing_Rule-Based_and_Multimodal_Large_Language_Models_for_Effective_Emergency_Braking.md)

- [Exploring the Design Space of Cognitive Engagement Techniques with AI-Generated Code for Enhanced Learning](2024年10月11日/Exploring_the_Design_Space_of_Cognitive_Engagement_Techniques_with_AI-Generated_Code_for_Enhanced_Learning.md)

    - [翻译: 探索 AI 生成代码在提升学习体验中的认知参与技术设计空间](2024年10月11日/Exploring_the_Design_Space_of_Cognitive_Engagement_Techniques_with_AI-Generated_Code_for_Enhanced_Learning.md)

- [F2A: An Innovative Approach for Prompt Injection by Utilizing Feign Security Detection Agents](2024年10月11日/F2A_An_Innovative_Approach_for_Prompt_Injection_by_Utilizing_Feign_Security_Detection_Agents.md)

    - [翻译: F2A：通过伪装安全检测代理实现提示注入的创新策略](2024年10月11日/F2A_An_Innovative_Approach_for_Prompt_Injection_by_Utilizing_Feign_Security_Detection_Agents.md)

- [From N-grams to Pre-trained Multilingual Models For Language Identification](2024年10月11日/From_N-grams_to_Pre-trained_Multilingual_Models_For_Language_Identification.md)

    - [翻译: 从 N-grams 到预训练的多语言模型：语言识别的新篇章](2024年10月11日/From_N-grams_to_Pre-trained_Multilingual_Models_For_Language_Identification.md)

- [Hybrid LLM-DDQN based Joint Optimization of V2I Communication and Autonomous Driving](2024年10月11日/Hybrid_LLM-DDQN_based_Joint_Optimization_of_V2I_Communication_and_Autonomous_Driving.md)

    - [翻译: 混合 LLM-DDQN 技术助力 V2I 通信与自动驾驶的协同优化](2024年10月11日/Hybrid_LLM-DDQN_based_Joint_Optimization_of_V2I_Communication_and_Autonomous_Driving.md)

- [Hypothesis-only Biases in Large Language Model-Elicited Natural Language Inference](2024年10月11日/Hypothesis-only_Biases_in_Large_Language_Model-Elicited_Natural_Language_Inference.md)

    - [翻译: 大型语言模型在自然语言推理中仅依赖假设的偏差](2024年10月11日/Hypothesis-only_Biases_in_Large_Language_Model-Elicited_Natural_Language_Inference.md)

- [Investigating Human-Computer Interaction and Visual Comprehension in Text Generation Process of Natural Language Generation Models](2024年10月11日/Investigating_Human-Computer_Interaction_and_Visual_Comprehension_in_Text_Generation_Process_of_Natural_Language_Generation_Models.md)

    - [翻译: 探索人类与计算机交互及视觉理解在自然语言生成模型文本生成中的影响](2024年10月11日/Investigating_Human-Computer_Interaction_and_Visual_Comprehension_in_Text_Generation_Process_of_Natural_Language_Generation_Models.md)

- [Maximizing the Potential of Synthetic Data: Insights from Random Matrix Theory](2024年10月11日/Maximizing_the_Potential_of_Synthetic_Data_Insights_from_Random_Matrix_Theory.md)

    - [翻译: 挖掘合成数据的最大潜力：随机矩阵理论的启示](2024年10月11日/Maximizing_the_Potential_of_Synthetic_Data_Insights_from_Random_Matrix_Theory.md)

- [Measuring the Groundedness of Legal Question-Answering Systems](2024年10月11日/Measuring_the_Groundedness_of_Legal_Question-Answering_Systems.md)

    - [翻译: 评估法律问答系统的实际应用能力](2024年10月11日/Measuring_the_Groundedness_of_Legal_Question-Answering_Systems.md)

- [NoVo: Norm Voting off Hallucinations with Attention Heads in Large Language Models](2024年10月11日/NoVo_Norm_Voting_off_Hallucinations_with_Attention_Heads_in_Large_Language_Models.md)

    - [翻译: NoVo：通过 LLM 中的注意力头规范投票，消除幻觉](2024年10月11日/NoVo_Norm_Voting_off_Hallucinations_with_Attention_Heads_in_Large_Language_Models.md)

- [PILLAR: an AI-Powered Privacy Threat Modeling Tool](2024年10月11日/PILLAR_an_AI-Powered_Privacy_Threat_Modeling_Tool.md)

    - [翻译: PILLAR：一款由 AI 驱动的隐私威胁建模利器](2024年10月11日/PILLAR_an_AI-Powered_Privacy_Threat_Modeling_Tool.md)

- [PoisonBench: Assessing Large Language Model Vulnerability to Data Poisoning](2024年10月11日/PoisonBench_Assessing_Large_Language_Model_Vulnerability_to_Data_Poisoning.md)

    - [翻译: PoisonBench：检测大型语言模型对数据中毒的抗性](2024年10月11日/PoisonBench_Assessing_Large_Language_Model_Vulnerability_to_Data_Poisoning.md)

- [Preferential Normalizing Flows](2024年10月11日/Preferential_Normalizing_Flows.md)

    - [翻译: 偏好归一化流](2024年10月11日/Preferential_Normalizing_Flows.md)

- [QEFT: Quantization for Efficient Fine-Tuning of LLMs](2024年10月11日/QEFT_Quantization_for_Efficient_Fine-Tuning_of_LLMs.md)

    - [翻译: QEFT：通过量化实现 LLM 的高效微调](2024年10月11日/QEFT_Quantization_for_Efficient_Fine-Tuning_of_LLMs.md)

- [RePD: Defending Jailbreak Attack through a Retrieval-based Prompt Decomposition Process](2024年10月11日/RePD_Defending_Jailbreak_Attack_through_a_Retrieval-based_Prompt_Decomposition_Process.md)

    - [翻译: RePD：利用基于检索的提示分解技术，有效抵御越狱攻击。](2024年10月11日/RePD_Defending_Jailbreak_Attack_through_a_Retrieval-based_Prompt_Decomposition_Process.md)

- [Semi-Supervised Learning of Noisy Mixture of Experts Models](2024年10月11日/Semi-Supervised_Learning_of_Noisy_Mixture_of_Experts_Models.md)

    - [翻译: 半监督噪声混合专家模型学习](2024年10月11日/Semi-Supervised_Learning_of_Noisy_Mixture_of_Experts_Models.md)

- [SimpleStrat: Diversifying Language Model Generation with Stratification](2024年10月11日/SimpleStrat_Diversifying_Language_Model_Generation_with_Stratification.md)

    - [翻译: SimpleStrat：以分层策略丰富语言模型生成多样性](2024年10月11日/SimpleStrat_Diversifying_Language_Model_Generation_with_Stratification.md)

- [SmartPretrain: Model-Agnostic and Dataset-Agnostic Representation Learning for Motion Prediction](2024年10月11日/SmartPretrain_Model-Agnostic_and_Dataset-Agnostic_Representation_Learning_for_Motion_Prediction.md)

    - [翻译: SmartPretrain：一种模型与数据集无关的表示学习方法，专为运动预测设计。](2024年10月11日/SmartPretrain_Model-Agnostic_and_Dataset-Agnostic_Representation_Learning_for_Motion_Prediction.md)

- [SocialGaze: Improving the Integration of Human Social Norms in Large Language Models](2024年10月11日/SocialGaze_Improving_the_Integration_of_Human_Social_Norms_in_Large_Language_Models.md)

    - [翻译: SocialGaze：提升大型语言模型中人类社会规范的融合](2024年10月11日/SocialGaze_Improving_the_Integration_of_Human_Social_Norms_in_Large_Language_Models.md)

- [Software Engineering and Foundation Models: Insights from Industry Blogs Using a Jury of Foundation Models](2024年10月11日/Software_Engineering_and_Foundation_Models_Insights_from_Industry_Blogs_Using_a_Jury_of_Foundation_Models.md)

    - [翻译: 软件工程与基础模型：通过基础模型陪审团，从行业博客中汲取的洞见](2024年10月11日/Software_Engineering_and_Foundation_Models_Insights_from_Industry_Blogs_Using_a_Jury_of_Foundation_Models.md)

- [StructRAG: Boosting Knowledge Intensive Reasoning of LLMs via Inference-time Hybrid Information Structurization](2024年10月11日/StructRAG_Boosting_Knowledge_Intensive_Reasoning_of_LLMs_via_Inference-time_Hybrid_Information_Structurization.md)

    - [翻译: StructRAG：通过推理时的混合信息结构化，大幅提升 LLM 在知识密集型推理中的表现。](2024年10月11日/StructRAG_Boosting_Knowledge_Intensive_Reasoning_of_LLMs_via_Inference-time_Hybrid_Information_Structurization.md)

- [Superpipeline: A Universal Approach for Reducing GPU Memory Usage in Large Models](2024年10月11日/Superpipeline_A_Universal_Approach_for_Reducing_GPU_Memory_Usage_in_Large_Models.md)

    - [翻译: Superpipeline：一种通用方案，旨在降低大型模型中的 GPU 内存消耗。](2024年10月11日/Superpipeline_A_Universal_Approach_for_Reducing_GPU_Memory_Usage_in_Large_Models.md)

- [The Dynamics of Social Conventions in LLM populations: Spontaneous Emergence, Collective Biases and Tipping Points](2024年10月11日/The_Dynamics_of_Social_Conventions_in_LLM_populations_Spontaneous_Emergence,_Collective_Biases_and_Tipping_Points.md)

    - [翻译: LLM 群体中的社会规范动态：自发涌现、集体偏见与临界点](2024年10月11日/The_Dynamics_of_Social_Conventions_in_LLM_populations_Spontaneous_Emergence,_Collective_Biases_and_Tipping_Points.md)

- [The Impact of Visual Information in Chinese Characters: Evaluating Large Models' Ability to Recognize and Utilize Radicals](2024年10月11日/The_Impact_of_Visual_Information_in_Chinese_Characters_Evaluating_Large_Models'_Ability_to_Recognize_and_Utilize_Radicals.md)

    - [翻译: 视觉信息如何影响汉字识别：探究大型模型对部首的识别与利用能力](2024年10月11日/The_Impact_of_Visual_Information_in_Chinese_Characters_Evaluating_Large_Models'_Ability_to_Recognize_and_Utilize_Radicals.md)

- [Unveiling Molecular Secrets: An LLM-Augmented Linear Model for Explainable and Calibratable Molecular Property Prediction](2024年10月11日/Unveiling_Molecular_Secrets_An_LLM-Augmented_Linear_Model_for_Explainable_and_Calibratable_Molecular_Property_Prediction.md)

    - [翻译: 揭秘分子奥秘：LLM 增强的线性模型助力可解释与可校准的分子属性预测](2024年10月11日/Unveiling_Molecular_Secrets_An_LLM-Augmented_Linear_Model_for_Explainable_and_Calibratable_Molecular_Property_Prediction.md)

- [Utilizing ChatGPT in a Data Structures and Algorithms Course: A Teaching Assistant's Perspective](2024年10月11日/Utilizing_ChatGPT_in_a_Data_Structures_and_Algorithms_Course_A_Teaching_Assistant's_Perspective.md)

    - [翻译: ChatGPT 在数据结构与算法课程中的应用：一位助教的视角](2024年10月11日/Utilizing_ChatGPT_in_a_Data_Structures_and_Algorithms_Course_A_Teaching_Assistant's_Perspective.md)

- [ViT3D Alignment of LLaMA3: 3D Medical Image Report Generation](2024年10月11日/ViT3D_Alignment_of_LLaMA3_3D_Medical_Image_Report_Generation.md)

    - [翻译: ViT3D 与 LLaMA3 的 3D 医学图像报告生成对齐](2024年10月11日/ViT3D_Alignment_of_LLaMA3_3D_Medical_Image_Report_Generation.md)

- [Words as Beacons: Guiding RL Agents with High-Level Language Prompts](2024年10月11日/Words_as_Beacons_Guiding_RL_Agents_with_High-Level_Language_Prompts.md)

    - [翻译: 词语如灯塔，以高级语言提示引领强化学习代理前行。](2024年10月11日/Words_as_Beacons_Guiding_RL_Agents_with_High-Level_Language_Prompts.md)

2024年10月10日

- [Aerial Vision-and-Language Navigation via Semantic-Topo-Metric Representation Guided LLM Reasoning](2024年10月10日/Aerial_Vision-and-Language_Navigation_via_Semantic-Topo-Metric_Representation_Guided_LLM_Reasoning.md)

    - [翻译: 空中视觉-语言导航：基于语义-拓扑-度量表示引导的 LLM 推理](2024年10月10日/Aerial_Vision-and-Language_Navigation_via_Semantic-Topo-Metric_Representation_Guided_LLM_Reasoning.md)

- [AgroGPT: Efficient Agricultural Vision-Language Model with Expert Tuning](2024年10月10日/AgroGPT_Efficient_Agricultural_Vision-Language_Model_with_Expert_Tuning.md)

    - [翻译: AgroGPT：一款经过专家调优的高效农业视觉与语言模型](2024年10月10日/AgroGPT_Efficient_Agricultural_Vision-Language_Model_with_Expert_Tuning.md)

- [Increasing the Difficulty of Automatically Generated Questions via Reinforcement Learning with Synthetic Preference](2024年10月10日/Increasing_the_Difficulty_of_Automatically_Generated_Questions_via_Reinforcement_Learning_with_Synthetic_Preference.md)

    - [翻译: 利用强化学习与合成偏好提升自动生成问题的难度](2024年10月10日/Increasing_the_Difficulty_of_Automatically_Generated_Questions_via_Reinforcement_Learning_with_Synthetic_Preference.md)

- [Large Legislative Models: Towards Efficient AI Policymaking in Economic Simulations](2024年10月10日/Large_Legislative_Models_Towards_Efficient_AI_Policymaking_in_Economic_Simulations.md)

    - [翻译: 大型立法模型：助力经济模拟中的高效 AI 政策制定](2024年10月10日/Large_Legislative_Models_Towards_Efficient_AI_Policymaking_in_Economic_Simulations.md)

- [SPORTU: A Comprehensive Sports Understanding Benchmark for Multimodal Large Language Models](2024年10月10日/SPORTU_A_Comprehensive_Sports_Understanding_Benchmark_for_Multimodal_Large_Language_Models.md)

    - [翻译: SPORTU：专为多模态大型语言模型设计的综合性体育理解基准](2024年10月10日/SPORTU_A_Comprehensive_Sports_Understanding_Benchmark_for_Multimodal_Large_Language_Models.md)

2024年10月01日

- [nGPT: Normalized Transformer with Representation Learning on the Hypersphere](2024年10月01日/nGPT_Normalized_Transformer_with_Representation_Learning_on_the_Hypersphere.md)

    - [翻译: nGPT：超球面表示学习的归一化Transformer](2024年10月01日/nGPT_Normalized_Transformer_with_Representation_Learning_on_the_Hypersphere.md)