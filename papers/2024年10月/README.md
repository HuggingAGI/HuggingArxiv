# 2024年10月

2024年10月10日

- [A Closer Look at Machine Unlearning for Large Language Models](2024年10月10日/A_Closer_Look_at_Machine_Unlearning_for_Large_Language_Models.md)

    - [翻译: 深入探讨大型语言模型的机器遗忘机制](2024年10月10日/A_Closer_Look_at_Machine_Unlearning_for_Large_Language_Models.md)

- [AgentBank: Towards Generalized LLM Agents via Fine-Tuning on 50000+ Interaction Trajectories](2024年10月10日/AgentBank_Towards_Generalized_LLM_Agents_via_Fine-Tuning_on_50000+_Interaction_Trajectories.md)

    - [翻译: AgentBank：通过微调 50000+ 交互轨迹，打造通用 LLM 代理](2024年10月10日/AgentBank_Towards_Generalized_LLM_Agents_via_Fine-Tuning_on_50000+_Interaction_Trajectories.md)

- [Agent S: An Open Agentic Framework that Uses Computers Like a Human](2024年10月10日/Agent_S_An_Open_Agentic_Framework_that_Uses_Computers_Like_a_Human.md)

    - [翻译: Agent S：一个让计算机像人类一样思考的开放代理框架](2024年10月10日/Agent_S_An_Open_Agentic_Framework_that_Uses_Computers_Like_a_Human.md)

- [APOLLO: A GPT-based tool to detect phishing emails and generate explanations that warn users](2024年10月10日/APOLLO_A_GPT-based_tool_to_detect_phishing_emails_and_generate_explanations_that_warn_users.md)

    - [翻译: APOLLO：一款基于 GPT 的工具，专为检测钓鱼邮件并生成警示用户的解释而设计](2024年10月10日/APOLLO_A_GPT-based_tool_to_detect_phishing_emails_and_generate_explanations_that_warn_users.md)

- [Benchmarking Agentic Workflow Generation](2024年10月10日/Benchmarking_Agentic_Workflow_Generation.md)

    - [翻译: 代理工作流生成的基准测试](2024年10月10日/Benchmarking_Agentic_Workflow_Generation.md)

- [Can Knowledge Graphs Make Large Language Models More Trustworthy? An Empirical Study over Open-ended Question Answering](2024年10月10日/Can_Knowledge_Graphs_Make_Large_Language_Models_More_Trustworthy_An_Empirical_Study_over_Open-ended_Question_Answering.md)

    - [翻译: 知识图谱能否提升大型语言模型的可信度？本研究通过开放式问答任务进行了实证探索。](2024年10月10日/Can_Knowledge_Graphs_Make_Large_Language_Models_More_Trustworthy_An_Empirical_Study_over_Open-ended_Question_Answering.md)

- [COMPL-AI Framework: A Technical Interpretation and LLM Benchmarking Suite for the EU Artificial Intelligence Act](2024年10月10日/COMPL-AI_Framework_A_Technical_Interpretation_and_LLM_Benchmarking_Suite_for_the_EU_Artificial_Intelligence_Act.md)

    - [翻译: COMPL-AI 框架：深入解读欧盟人工智能法案，并提供 LLM 基准测试工具](2024年10月10日/COMPL-AI_Framework_A_Technical_Interpretation_and_LLM_Benchmarking_Suite_for_the_EU_Artificial_Intelligence_Act.md)

- [Deep Correlated Prompting for Visual Recognition with Missing Modalities](2024年10月10日/Deep_Correlated_Prompting_for_Visual_Recognition_with_Missing_Modalities.md)

    - [翻译: 深度相关提示助力视觉识别，应对模态缺失挑战](2024年10月10日/Deep_Correlated_Prompting_for_Visual_Recognition_with_Missing_Modalities.md)

- [DelTA: An Online Document-Level Translation Agent Based on Multi-Level Memory](2024年10月10日/DelTA_An_Online_Document-Level_Translation_Agent_Based_on_Multi-Level_Memory.md)

    - [翻译: DelTA：一款基于多级记忆的在线文档翻译助手](2024年10月10日/DelTA_An_Online_Document-Level_Translation_Agent_Based_on_Multi-Level_Memory.md)

- [Dialectical Behavior Therapy Approach to LLM Prompting](2024年10月10日/Dialectical_Behavior_Therapy_Approach_to_LLM_Prompting.md)

    - [翻译: 辩证行为疗法在 LLM 提示中的应用](2024年10月10日/Dialectical_Behavior_Therapy_Approach_to_LLM_Prompting.md)

- [Disease Entity Recognition and Normalization is Improved with Large Language Model Derived Synthetic Normalized Mentions](2024年10月10日/Disease_Entity_Recognition_and_Normalization_is_Improved_with_Large_Language_Model_Derived_Synthetic_Normalized_Mentions.md)

    - [翻译: 借助大型语言模型生成的合成规范化提及，疾病实体的识别与规范化得到了显著提升。](2024年10月10日/Disease_Entity_Recognition_and_Normalization_is_Improved_with_Large_Language_Model_Derived_Synthetic_Normalized_Mentions.md)

- [Divide and Translate: Compositional First-Order Logic Translation and Verification for Complex Logical Reasoning](2024年10月10日/Divide_and_Translate_Compositional_First-Order_Logic_Translation_and_Verification_for_Complex_Logical_Reasoning.md)

    - [翻译: 分割翻译法：组合一阶逻辑在复杂推理中的翻译与验证](2024年10月10日/Divide_and_Translate_Compositional_First-Order_Logic_Translation_and_Verification_for_Complex_Logical_Reasoning.md)

- [Efficiently Learning at Test-Time: Active Fine-Tuning of LLMs](2024年10月10日/Efficiently_Learning_at_Test-Time_Active_Fine-Tuning_of_LLMs.md)

    - [翻译: 测试时高效学习：LLM 的主动微调](2024年10月10日/Efficiently_Learning_at_Test-Time_Active_Fine-Tuning_of_LLMs.md)

- [Efficient Reinforcement Learning with Large Language Model Priors](2024年10月10日/Efficient_Reinforcement_Learning_with_Large_Language_Model_Priors.md)

    - [翻译: 利用大型语言模型先验实现高效强化学习](2024年10月10日/Efficient_Reinforcement_Learning_with_Large_Language_Model_Priors.md)

- [Emerging Pixel Grounding in Large Multimodal Models Without Grounding Supervision](2024年10月10日/Emerging_Pixel_Grounding_in_Large_Multimodal_Models_Without_Grounding_Supervision.md)

    - [翻译: 大型多模态模型中悄然兴起的像素基础技术，无需任何基础监督的加持。](2024年10月10日/Emerging_Pixel_Grounding_in_Large_Multimodal_Models_Without_Grounding_Supervision.md)

- [Enhancing Language Model Reasoning via Weighted Reasoning in Self-Consistency](2024年10月10日/Enhancing_Language_Model_Reasoning_via_Weighted_Reasoning_in_Self-Consistency.md)

    - [翻译: 借助自一致性中的加权推理，提升语言模型的推理能力](2024年10月10日/Enhancing_Language_Model_Reasoning_via_Weighted_Reasoning_in_Self-Consistency.md)

- [Enhancing Zeroth-order Fine-tuning for Language Models with Low-rank Structures](2024年10月10日/Enhancing_Zeroth-order_Fine-tuning_for_Language_Models_with_Low-rank_Structures.md)

    - [翻译: 利用低秩结构提升语言模型的零阶微调效果](2024年10月10日/Enhancing_Zeroth-order_Fine-tuning_for_Language_Models_with_Low-rank_Structures.md)

- [Executing Arithmetic: Fine-Tuning Large Language Models as Turing Machines](2024年10月10日/Executing_Arithmetic_Fine-Tuning_Large_Language_Models_as_Turing_Machines.md)

    - [翻译: 微调大型语言模型，使其具备图灵机的算术执行能力。](2024年10月10日/Executing_Arithmetic_Fine-Tuning_Large_Language_Models_as_Turing_Machines.md)

- [Extracting and Transferring Abilities For Building Multi-lingual Ability-enhanced Large Language Models](2024年10月10日/Extracting_and_Transferring_Abilities_For_Building_Multi-lingual_Ability-enhanced_Large_Language_Models.md)

    - [翻译: 构建多语言能力增强的大型语言模型，关键在于提取和转移能力。](2024年10月10日/Extracting_and_Transferring_Abilities_For_Building_Multi-lingual_Ability-enhanced_Large_Language_Models.md)

- [FLIER: Few-shot Language Image Models Embedded with Latent Representations](2024年10月10日/FLIER_Few-shot_Language_Image_Models_Embedded_with_Latent_Representations.md)

    - [翻译: FLIER：一种嵌入了潜在表示的少样本语言图像模型](2024年10月10日/FLIER_Few-shot_Language_Image_Models_Embedded_with_Latent_Representations.md)

- [From Exploration to Mastery: Enabling LLMs to Master Tools via Self-Driven Interactions](2024年10月10日/From_Exploration_to_Mastery_Enabling_LLMs_to_Master_Tools_via_Self-Driven_Interactions.md)

    - [翻译: 从探索到精通：借助自我驱动交互，让 LLM 掌握工具。](2024年10月10日/From_Exploration_to_Mastery_Enabling_LLMs_to_Master_Tools_via_Self-Driven_Interactions.md)

- [GameTraversalBenchmark: Evaluating Planning Abilities Of Large Language Models Through Traversing 2D Game Maps](2024年10月10日/GameTraversalBenchmark_Evaluating_Planning_Abilities_Of_Large_Language_Models_Through_Traversing_2D_Game_Maps.md)

    - [翻译: GameTraversalBenchmark：通过探索二维游戏地图，评估大型语言模型的规划能力](2024年10月10日/GameTraversalBenchmark_Evaluating_Planning_Abilities_Of_Large_Language_Models_Through_Traversing_2D_Game_Maps.md)

- [GenARM: Reward Guided Generation with Autoregressive Reward Model for Test-time Alignment](2024年10月10日/GenARM_Reward_Guided_Generation_with_Autoregressive_Reward_Model_for_Test-time_Alignment.md)

    - [翻译: GenARM：自回归奖励模型引导的生成，专为测试时对齐设计](2024年10月10日/GenARM_Reward_Guided_Generation_with_Autoregressive_Reward_Model_for_Test-time_Alignment.md)

- [Insight Over Sight? Exploring the Vision-Knowledge Conflicts in Multimodal LLMs](2024年10月10日/Insight_Over_Sight_Exploring_the_Vision-Knowledge_Conflicts_in_Multimodal_LLMs.md)

    - [翻译: 洞察力与视觉的较量？探究多模态 LLM 中的视觉与知识冲突](2024年10月10日/Insight_Over_Sight_Exploring_the_Vision-Knowledge_Conflicts_in_Multimodal_LLMs.md)

- [InstructBioMol: Advancing Biomolecule Understanding and Design Following Human Instructions](2024年10月10日/InstructBioMol_Advancing_Biomolecule_Understanding_and_Design_Following_Human_Instructions.md)

    - [翻译: InstructBioMol：引领生物分子理解和设计，遵循人类智慧的指引。](2024年10月10日/InstructBioMol_Advancing_Biomolecule_Understanding_and_Design_Following_Human_Instructions.md)

- [LatteCLIP: Unsupervised CLIP Fine-Tuning via LMM-Synthetic Texts](2024年10月10日/LatteCLIP_Unsupervised_CLIP_Fine-Tuning_via_LMM-Synthetic_Texts.md)

    - [翻译: LatteCLIP：利用 LMM 生成的合成文本，实现无监督的 CLIP 微调](2024年10月10日/LatteCLIP_Unsupervised_CLIP_Fine-Tuning_via_LMM-Synthetic_Texts.md)

- [LLM Cascade with Multi-Objective Optimal Consideration](2024年10月10日/LLM_Cascade_with_Multi-Objective_Optimal_Consideration.md)

    - [翻译: LLM 级联的多目标优化策略](2024年10月10日/LLM_Cascade_with_Multi-Objective_Optimal_Consideration.md)

- [MACPO: Weak-to-Strong Alignment via Multi-Agent Contrastive Preference Optimization](2024年10月10日/MACPO_Weak-to-Strong_Alignment_via_Multi-Agent_Contrastive_Preference_Optimization.md)

    - [翻译: MACPO：借助多智能体对比偏好优化，实现从弱到强的对齐。](2024年10月10日/MACPO_Weak-to-Strong_Alignment_via_Multi-Agent_Contrastive_Preference_Optimization.md)

- [Mapping Hong Kong's Financial Ecosystem: A Network Analysis of the SFC's Licensed Professionals and Institutions](2024年10月10日/Mapping_Hong_Kong's_Financial_Ecosystem_A_Network_Analysis_of_the_SFC's_Licensed_Professionals_and_Institutions.md)

    - [翻译: 探索香港金融生态：SFC 许可专业人士与机构的网络图谱](2024年10月10日/Mapping_Hong_Kong's_Financial_Ecosystem_A_Network_Analysis_of_the_SFC's_Licensed_Professionals_and_Institutions.md)

- [Mars: Situated Inductive Reasoning in an Open-World Environment](2024年10月10日/Mars_Situated_Inductive_Reasoning_in_an_Open-World_Environment.md)

    - [翻译: 火星：开放世界中的情境归纳推理](2024年10月10日/Mars_Situated_Inductive_Reasoning_in_an_Open-World_Environment.md)

- [MathCoder2: Better Math Reasoning from Continued Pretraining on Model-translated Mathematical Code](2024年10月10日/MathCoder2_Better_Math_Reasoning_from_Continued_Pretraining_on_Model-translated_Mathematical_Code.md)

    - [翻译: MathCoder2：通过持续预训练模型翻译的数学代码，提升了数学推理能力](2024年10月10日/MathCoder2_Better_Math_Reasoning_from_Continued_Pretraining_on_Model-translated_Mathematical_Code.md)

- [Mitigating Gender Bias in Code Large Language Models via Model Editing](2024年10月10日/Mitigating_Gender_Bias_in_Code_Large_Language_Models_via_Model_Editing.md)

    - [翻译: 通过模型编辑技术，我们致力于减轻代码大型语言模型中的性别偏见问题。](2024年10月10日/Mitigating_Gender_Bias_in_Code_Large_Language_Models_via_Model_Editing.md)

- [Modeling User Preferences with Automatic Metrics: Creating a High-Quality Preference Dataset for Machine Translation](2024年10月10日/Modeling_User_Preferences_with_Automatic_Metrics_Creating_a_High-Quality_Preference_Dataset_for_Machine_Translation.md)

    - [翻译: 利用自动指标构建用户偏好模型，旨在为机器翻译任务打造一个高质量的偏好数据集。](2024年10月10日/Modeling_User_Preferences_with_Automatic_Metrics_Creating_a_High-Quality_Preference_Dataset_for_Machine_Translation.md)

- [MolMix: A Simple Yet Effective Baseline for Multimodal Molecular Representation Learning](2024年10月10日/MolMix_A_Simple_Yet_Effective_Baseline_for_Multimodal_Molecular_Representation_Learning.md)

    - [翻译: MolMix：一个简单却高效的多模态分子表示学习基线](2024年10月10日/MolMix_A_Simple_Yet_Effective_Baseline_for_Multimodal_Molecular_Representation_Learning.md)

- [Mono-InternVL: Pushing the Boundaries of Monolithic Multimodal Large Language Models with Endogenous Visual Pre-training](2024年10月10日/Mono-InternVL_Pushing_the_Boundaries_of_Monolithic_Multimodal_Large_Language_Models_with_Endogenous_Visual_Pre-training.md)

    - [翻译: Mono-InternVL：借助内生视觉预训练，拓展单体多模态大型语言模型的极限](2024年10月10日/Mono-InternVL_Pushing_the_Boundaries_of_Monolithic_Multimodal_Large_Language_Models_with_Endogenous_Visual_Pre-training.md)

- [MRAG-Bench: Vision-Centric Evaluation for Retrieval-Augmented Multimodal Models](2024年10月10日/MRAG-Bench_Vision-Centric_Evaluation_for_Retrieval-Augmented_Multimodal_Models.md)

    - [翻译: MRAG-Bench：专注于视觉的多模态模型增强检索评估工具](2024年10月10日/MRAG-Bench_Vision-Centric_Evaluation_for_Retrieval-Augmented_Multimodal_Models.md)

- [Multi-Agent Collaborative Data Selection for Efficient LLM Pretraining](2024年10月10日/Multi-Agent_Collaborative_Data_Selection_for_Efficient_LLM_Pretraining.md)

    - [翻译: 多代理协作数据选择：高效 LLM 预训练的关键](2024年10月10日/Multi-Agent_Collaborative_Data_Selection_for_Efficient_LLM_Pretraining.md)

- [Multi-Facet Counterfactual Learning for Content Quality Evaluation](2024年10月10日/Multi-Facet_Counterfactual_Learning_for_Content_Quality_Evaluation.md)

    - [翻译: 多维度反事实学习助力内容质量评估](2024年10月10日/Multi-Facet_Counterfactual_Learning_for_Content_Quality_Evaluation.md)

- [NLP-Guided Synthesis: Transitioning from Sequential Programs to Distributed Programs](2024年10月10日/NLP-Guided_Synthesis_Transitioning_from_Sequential_Programs_to_Distributed_Programs.md)

    - [翻译: NLP 引导的合成：从顺序程序迈向分布式程序](2024年10月10日/NLP-Guided_Synthesis_Transitioning_from_Sequential_Programs_to_Distributed_Programs.md)

- [NusaMT-7B: Machine Translation for Low-Resource Indonesian Languages with Large Language Models](2024年10月10日/NusaMT-7B_Machine_Translation_for_Low-Resource_Indonesian_Languages_with_Large_Language_Models.md)

    - [翻译: NusaMT-7B：借助大型语言模型，为资源匮乏的印尼语提供机器翻译解决方案。](2024年10月10日/NusaMT-7B_Machine_Translation_for_Low-Resource_Indonesian_Languages_with_Large_Language_Models.md)

- [Omni-MATH: A Universal Olympiad Level Mathematic Benchmark For Large Language Models](2024年10月10日/Omni-MATH_A_Universal_Olympiad_Level_Mathematic_Benchmark_For_Large_Language_Models.md)

    - [翻译: Omni-MATH：专为大型语言模型设计的全能奥林匹克数学基准](2024年10月10日/Omni-MATH_A_Universal_Olympiad_Level_Mathematic_Benchmark_For_Large_Language_Models.md)

- [On the Evaluation of Generative Robotic Simulations](2024年10月10日/On_the_Evaluation_of_Generative_Robotic_Simulations.md)

    - [翻译: 机器人模拟生成效果的评估](2024年10月10日/On_the_Evaluation_of_Generative_Robotic_Simulations.md)

- [Optima: Optimizing Effectiveness and Efficiency for LLM-Based Multi-Agent System](2024年10月10日/Optima_Optimizing_Effectiveness_and_Efficiency_for_LLM-Based_Multi-Agent_System.md)

    - [翻译: Optima：提升基于 LLM 的多智能体系统效能与效率](2024年10月10日/Optima_Optimizing_Effectiveness_and_Efficiency_for_LLM-Based_Multi-Agent_System.md)

- [Packing Analysis: Packing Is More Appropriate for Large Models or Datasets in Supervised Fine-tuning](2024年10月10日/Packing_Analysis_Packing_Is_More_Appropriate_for_Large_Models_or_Datasets_in_Supervised_Fine-tuning.md)

    - [翻译: 打包分析：在监督微调中，大型模型或数据集更适合采用打包策略。](2024年10月10日/Packing_Analysis_Packing_Is_More_Appropriate_for_Large_Models_or_Datasets_in_Supervised_Fine-tuning.md)

- [Plug-and-Play Performance Estimation for LLM Services without Relying on Labeled Data](2024年10月10日/Plug-and-Play_Performance_Estimation_for_LLM_Services_without_Relying_on_Labeled_Data.md)

    - [翻译: 无需标注数据，实现 LLM 服务的即插即用性能评估](2024年10月10日/Plug-and-Play_Performance_Estimation_for_LLM_Services_without_Relying_on_Labeled_Data.md)

- [QCircuitNet: A Large-Scale Hierarchical Dataset for Quantum Algorithm Design](2024年10月10日/QCircuitNet_A_Large-Scale_Hierarchical_Dataset_for_Quantum_Algorithm_Design.md)

    - [翻译: QCircuitNet：专为量子算法设计打造的大规模分层数据集](2024年10月10日/QCircuitNet_A_Large-Scale_Hierarchical_Dataset_for_Quantum_Algorithm_Design.md)

- [Q-VLM: Post-training Quantization for Large Vision-Language Models](2024年10月10日/Q-VLM_Post-training_Quantization_for_Large_Vision-Language_Models.md)

    - [翻译: Q-VLM：为大型视觉-语言模型进行的后训练量化](2024年10月10日/Q-VLM_Post-training_Quantization_for_Large_Vision-Language_Models.md)

- [Reward-Augmented Data Enhances Direct Preference Alignment of LLMs](2024年10月10日/Reward-Augmented_Data_Enhances_Direct_Preference_Alignment_of_LLMs.md)

    - [翻译: 奖励增强数据助力 LLM 直接偏好对齐](2024年10月10日/Reward-Augmented_Data_Enhances_Direct_Preference_Alignment_of_LLMs.md)

- [Rewarding Progress: Scaling Automated Process Verifiers for LLM Reasoning](2024年10月10日/Rewarding_Progress_Scaling_Automated_Process_Verifiers_for_LLM_Reasoning.md)

    - [翻译: 奖励进步：扩展 LLM 推理的自动化验证器](2024年10月10日/Rewarding_Progress_Scaling_Automated_Process_Verifiers_for_LLM_Reasoning.md)

- [Rewriting Conversational Utterances with Instructed Large Language Models](2024年10月10日/Rewriting_Conversational_Utterances_with_Instructed_Large_Language_Models.md)

    - [翻译: 借助指导性大型语言模型，对话话语得以重塑。](2024年10月10日/Rewriting_Conversational_Utterances_with_Instructed_Large_Language_Models.md)

- [Sample then Identify: A General Framework for Risk Control and Assessment in Multimodal Large Language Models](2024年10月10日/Sample_then_Identify_A_General_Framework_for_Risk_Control_and_Assessment_in_Multimodal_Large_Language_Models.md)

    - [翻译: 采样识别：多模态大型语言模型风险控制与评估的通用方案](2024年10月10日/Sample_then_Identify_A_General_Framework_for_Risk_Control_and_Assessment_in_Multimodal_Large_Language_Models.md)

- [Scalable Representation Learning for Multimodal Tabular Transactions](2024年10月10日/Scalable_Representation_Learning_for_Multimodal_Tabular_Transactions.md)

    - [翻译: 多模态表格交易的可扩展表示学习](2024年10月10日/Scalable_Representation_Learning_for_Multimodal_Tabular_Transactions.md)

- [Smart Audit System Empowered by LLM](2024年10月10日/Smart_Audit_System_Empowered_by_LLM.md)

    - [翻译: 智能审计系统，由大型语言模型赋能](2024年10月10日/Smart_Audit_System_Empowered_by_LLM.md)

- [StablePrompt: Automatic Prompt Tuning using Reinforcement Learning for Large Language Models](2024年10月10日/StablePrompt_Automatic_Prompt_Tuning_using_Reinforcement_Learning_for_Large_Language_Models.md)

    - [翻译: StablePrompt：利用强化学习为大型语言模型自动优化提示词](2024年10月10日/StablePrompt_Automatic_Prompt_Tuning_using_Reinforcement_Learning_for_Large_Language_Models.md)

- [StepTool: A Step-grained Reinforcement Learning Framework for Tool Learning in LLMs](2024年10月10日/StepTool_A_Step-grained_Reinforcement_Learning_Framework_for_Tool_Learning_in_LLMs.md)

    - [翻译: StepTool：为 LLM 中的工具学习量身定制的步骤级强化学习框架](2024年10月10日/StepTool_A_Step-grained_Reinforcement_Learning_Framework_for_Tool_Learning_in_LLMs.md)

- [SWE-Bench+: Enhanced Coding Benchmark for LLMs](2024年10月10日/SWE-Bench+_Enhanced_Coding_Benchmark_for_LLMs.md)

    - [翻译: SWE-Bench+：LLM 编码基准的升级版](2024年10月10日/SWE-Bench+_Enhanced_Coding_Benchmark_for_LLMs.md)

- [Teaching-Inspired Integrated Prompting Framework: A Novel Approach for Enhancing Reasoning in Large Language Models](2024年10月10日/Teaching-Inspired_Integrated_Prompting_Framework_A_Novel_Approach_for_Enhancing_Reasoning_in_Large_Language_Models.md)

    - [翻译: 教学启发的综合提示框架：一种提升大型语言模型推理能力的新途径](2024年10月10日/Teaching-Inspired_Integrated_Prompting_Framework_A_Novel_Approach_for_Enhancing_Reasoning_in_Large_Language_Models.md)

- [Think Beyond Size: Dynamic Prompting for More Effective Reasoning](2024年10月10日/Think_Beyond_Size_Dynamic_Prompting_for_More_Effective_Reasoning.md)

    - [翻译: 超越尺寸，动态提示助力更高效推理](2024年10月10日/Think_Beyond_Size_Dynamic_Prompting_for_More_Effective_Reasoning.md)

- [Towards Assurance of LLM Adversarial Robustness using Ontology-Driven Argumentation](2024年10月10日/Towards_Assurance_of_LLM_Adversarial_Robustness_using_Ontology-Driven_Argumentation.md)

    - [翻译: 通过本体驱动论证，迈向确保 LLM 对抗鲁棒性的道路](2024年10月10日/Towards_Assurance_of_LLM_Adversarial_Robustness_using_Ontology-Driven_Argumentation.md)

- [TVBench: Redesigning Video-Language Evaluation](2024年10月10日/TVBench_Redesigning_Video-Language_Evaluation.md)

    - [翻译: TVBench：革新视频与语言的评估方式](2024年10月10日/TVBench_Redesigning_Video-Language_Evaluation.md)

- [Uncovering Overfitting in Large Language Model Editing](2024年10月10日/Uncovering_Overfitting_in_Large_Language_Model_Editing.md)

    - [翻译: 揭秘大型语言模型编辑中的过拟合现象](2024年10月10日/Uncovering_Overfitting_in_Large_Language_Model_Editing.md)

- [Unsupervised Data Validation Methods for Efficient Model Training](2024年10月10日/Unsupervised_Data_Validation_Methods_for_Efficient_Model_Training.md)

    - [翻译: 无监督数据验证方法助力高效模型训练](2024年10月10日/Unsupervised_Data_Validation_Methods_for_Efficient_Model_Training.md)

- [VerifierQ: Enhancing LLM Test Time Compute with Q-Learning-based Verifiers](2024年10月10日/VerifierQ_Enhancing_LLM_Test_Time_Compute_with_Q-Learning-based_Verifiers.md)

    - [翻译: VerifierQ：利用基于 Q-Learning 的验证器提升 LLM 测试时的计算效率](2024年10月10日/VerifierQ_Enhancing_LLM_Test_Time_Compute_with_Q-Learning-based_Verifiers.md)

- [Visual Scratchpads: Enabling Global Reasoning in Vision](2024年10月10日/Visual_Scratchpads_Enabling_Global_Reasoning_in_Vision.md)

    - [翻译: 视觉草稿板：助力视觉全局推理](2024年10月10日/Visual_Scratchpads_Enabling_Global_Reasoning_in_Vision.md)

- [What Makes Large Language Models Reason in (Multi-Turn) Code Generation?](2024年10月10日/What_Makes_Large_Language_Models_Reason_in_(Multi-Turn)_Code_Generation.md)

    - [翻译: 大型语言模型如何在（多轮）代码生成中进行推理？](2024年10月10日/What_Makes_Large_Language_Models_Reason_in_(Multi-Turn)_Code_Generation.md)

2024年10月09日

- [Break the Visual Perception: Adversarial Attacks Targeting Encoded Visual Tokens of Large Vision-Language Models](2024年10月09日/Break_the_Visual_Perception_Adversarial_Attacks_Targeting_Encoded_Visual_Tokens_of_Large_Vision-Language_Models.md)

    - [翻译: 颠覆视觉感知：针对大型视觉-语言模型编码视觉标记的对抗攻击](2024年10月09日/Break_the_Visual_Perception_Adversarial_Attacks_Targeting_Encoded_Visual_Tokens_of_Large_Vision-Language_Models.md)

- [Calibrating Verbalized Probabilities for Large Language Models](2024年10月09日/Calibrating_Verbalized_Probabilities_for_Large_Language_Models.md)

    - [翻译: 优化大型语言模型的概率表达](2024年10月09日/Calibrating_Verbalized_Probabilities_for_Large_Language_Models.md)

- [G$^{2}$TR: Generalized Grounded Temporal Reasoning for Robot Instruction Following by Combining Large Pre-trained Models](2024年10月09日/G$^{2}$TR_Generalized_Grounded_Temporal_Reasoning_for_Robot_Instruction_Following_by_Combining_Large_Pre-trained_Models.md)

    - [翻译: G$^{2}$TR：结合大型预训练模型，为机器人指令跟随提供广义的时间推理能力](2024年10月09日/G$^{2}$TR_Generalized_Grounded_Temporal_Reasoning_for_Robot_Instruction_Following_by_Combining_Large_Pre-trained_Models.md)

- [ING-VP: MLLMs cannot Play Easy Vision-based Games Yet](2024年10月09日/ING-VP_MLLMs_cannot_Play_Easy_Vision-based_Games_Yet.md)

    - [翻译: ING-VP: 多模态大型语言模型尚无法应对简单的视觉游戏挑战](2024年10月09日/ING-VP_MLLMs_cannot_Play_Easy_Vision-based_Games_Yet.md)

- [KRAG Framework for Enhancing LLMs in the Legal Domain](2024年10月09日/KRAG_Framework_for_Enhancing_LLMs_in_the_Legal_Domain.md)

    - [翻译: KRAG 框架：法律领域 LLM 的增强之道](2024年10月09日/KRAG_Framework_for_Enhancing_LLMs_in_the_Legal_Domain.md)

- [Large Language Models as Code Executors: An Exploratory Study](2024年10月09日/Large_Language_Models_as_Code_Executors_An_Exploratory_Study.md)

    - [翻译: 大型语言模型：代码执行的新探索](2024年10月09日/Large_Language_Models_as_Code_Executors_An_Exploratory_Study.md)

- [News Reporter: A Multi-lingual LLM Framework for Broadcast T.V News](2024年10月09日/News_Reporter_A_Multi-lingual_LLM_Framework_for_Broadcast_T.V_News.md)

    - [翻译: 新闻记者：专为广播电视新闻打造的多语言 LLM 框架](2024年10月09日/News_Reporter_A_Multi-lingual_LLM_Framework_for_Broadcast_T.V_News.md)

- [Personal Intelligence System UniLM: Hybrid On-Device Small Language Model and Server-Based Large Language Model for Malay Nusantara](2024年10月09日/Personal_Intelligence_System_UniLM_Hybrid_On-Device_Small_Language_Model_and_Server-Based_Large_Language_Model_for_Malay_Nusantara.md)

    - [翻译: UniLM 个人智能系统：结合设备端小型模型与服务器端大型模型，专为马来群岛语言设计。](2024年10月09日/Personal_Intelligence_System_UniLM_Hybrid_On-Device_Small_Language_Model_and_Server-Based_Large_Language_Model_for_Malay_Nusantara.md)

- [Prompt Infection: LLM-to-LLM Prompt Injection within Multi-Agent Systems](2024年10月09日/Prompt_Infection_LLM-to-LLM_Prompt_Injection_within_Multi-Agent_Systems.md)

    - [翻译: 提示感染：多代理系统中 LLM 间的提示注入](2024年10月09日/Prompt_Infection_LLM-to-LLM_Prompt_Injection_within_Multi-Agent_Systems.md)

- [Retrieval Replace Reduction: An effective visual token reduction method via semantic match](2024年10月09日/Retrieval_Replace_Reduction_An_effective_visual_token_reduction_method_via_semantic_match.md)

    - [翻译: 检索替换减少：一种通过语义匹配实现视觉标记高效减少的方法](2024年10月09日/Retrieval_Replace_Reduction_An_effective_visual_token_reduction_method_via_semantic_match.md)

- [Rodimus*: Breaking the Accuracy-Efficiency Trade-Off with Efficient Attentions](2024年10月09日/Rodimus_Breaking_the_Accuracy-Efficiency_Trade-Off_with_Efficient_Attentions.md)

    - [翻译: Rodimus*：以高效注意力打破准确性与效率的平衡](2024年10月09日/Rodimus_Breaking_the_Accuracy-Efficiency_Trade-Off_with_Efficient_Attentions.md)

- [Thought2Text: Text Generation from EEG Signal using Large Language Models (LLMs)](2024年10月09日/Thought2Text_Text_Generation_from_EEG_Signal_using_Large_Language_Models_(LLMs).md)

    - [翻译: Thought2Text：借助 LLM 将 EEG 信号转化为文本](2024年10月09日/Thought2Text_Text_Generation_from_EEG_Signal_using_Large_Language_Models_(LLMs).md)

- [TinyEmo: Scaling down Emotional Reasoning via Metric Projection](2024年10月09日/TinyEmo_Scaling_down_Emotional_Reasoning_via_Metric_Projection.md)

    - [翻译: TinyEmo：通过度量投影简化情感推理](2024年10月09日/TinyEmo_Scaling_down_Emotional_Reasoning_via_Metric_Projection.md)