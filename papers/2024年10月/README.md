# 2024年10月

2024年10月07日

- [Can LLMs plan paths with extra hints from solvers?](2024年10月07日/Can_LLMs_plan_paths_with_extra_hints_from_solvers.md)

    - [翻译: LLMs 能否借助解算器的额外提示来规划路径？](2024年10月07日/Can_LLMs_plan_paths_with_extra_hints_from_solvers.md)

- [Causal Micro-Narratives](2024年10月07日/Causal_Micro-Narratives.md)

    - [翻译: 因果微故事](2024年10月07日/Causal_Micro-Narratives.md)

- [Compression via Pre-trained Transformers: A Study on Byte-Level Multimodal Data](2024年10月07日/Compression_via_Pre-trained_Transformers_A_Study_on_Byte-Level_Multimodal_Data.md)

    - [翻译: 预训练 Transformer 压缩技术：探索字节级多模态数据的奥秘](2024年10月07日/Compression_via_Pre-trained_Transformers_A_Study_on_Byte-Level_Multimodal_Data.md)

- [Cookbook: A framework for improving LLM generative abilities via programmatic data generating templates](2024年10月07日/Cookbook_A_framework_for_improving_LLM_generative_abilities_via_programmatic_data_generating_templates.md)

    - [翻译: 编程数据生成模板：提升 LLM 生成能力的秘籍](2024年10月07日/Cookbook_A_framework_for_improving_LLM_generative_abilities_via_programmatic_data_generating_templates.md)

- [Data Advisor: Dynamic Data Curation for Safety Alignment of Large Language Models](2024年10月07日/Data_Advisor_Dynamic_Data_Curation_for_Safety_Alignment_of_Large_Language_Models.md)

    - [翻译: 数据顾问：为大型语言模型安全对齐提供动态数据管理](2024年10月07日/Data_Advisor_Dynamic_Data_Curation_for_Safety_Alignment_of_Large_Language_Models.md)

- [Deciphering the Interplay of Parametric and Non-parametric Memory in Retrieval-augmented Language Models](2024年10月07日/Deciphering_the_Interplay_of_Parametric_and_Non-parametric_Memory_in_Retrieval-augmented_Language_Models.md)

    - [翻译: 揭示检索增强语言模型中参数记忆与非参数记忆的微妙互动](2024年10月07日/Deciphering_the_Interplay_of_Parametric_and_Non-parametric_Memory_in_Retrieval-augmented_Language_Models.md)

- [Density estimation with LLMs: a geometric investigation of in-context learning trajectories](2024年10月07日/Density_estimation_with_LLMs_a_geometric_investigation_of_in-context_learning_trajectories.md)

    - [翻译: LLM 的密度估计：探究 in-context learning 轨迹的几何特性](2024年10月07日/Density_estimation_with_LLMs_a_geometric_investigation_of_in-context_learning_trajectories.md)

- [Differential Transformer](2024年10月07日/Differential_Transformer.md)

    - [翻译: 差异性变换器](2024年10月07日/Differential_Transformer.md)

- [Diffusion Models in 3D Vision: A Survey](2024年10月07日/Diffusion_Models_in_3D_Vision_A_Survey.md)

    - [翻译: 3D 视觉领域中的扩散模型：全面调查](2024年10月07日/Diffusion_Models_in_3D_Vision_A_Survey.md)

- [Document-level Causal Relation Extraction with Knowledge-guided Binary Question Answering](2024年10月07日/Document-level_Causal_Relation_Extraction_with_Knowledge-guided_Binary_Question_Answering.md)

    - [翻译: 文档级因果关系提取：知识引导下的二进制问题解答](2024年10月07日/Document-level_Causal_Relation_Extraction_with_Knowledge-guided_Binary_Question_Answering.md)

- [Driving with Regulation: Interpretable Decision-Making for Autonomous Vehicles with Retrieval-Augmented Reasoning via LLM](2024年10月07日/Driving_with_Regulation_Interpretable_Decision-Making_for_Autonomous_Vehicles_with_Retrieval-Augmented_Reasoning_via_LLM.md)

    - [翻译: 借助 LLM 的检索增强推理，自动驾驶车辆在遵循法规的同时，实现了可解释的决策过程。](2024年10月07日/Driving_with_Regulation_Interpretable_Decision-Making_for_Autonomous_Vehicles_with_Retrieval-Augmented_Reasoning_via_LLM.md)

- [Efficient Inference for Large Language Model-based Generative Recommendation](2024年10月07日/Efficient_Inference_for_Large_Language_Model-based_Generative_Recommendation.md)

    - [翻译: 大型语言模型生成推荐的高效推理](2024年10月07日/Efficient_Inference_for_Large_Language_Model-based_Generative_Recommendation.md)

- [Enhancing Equity in Large Language Models for Medical Applications](2024年10月07日/Enhancing_Equity_in_Large_Language_Models_for_Medical_Applications.md)

    - [翻译: 提升医疗应用中大型语言模型的公平性](2024年10月07日/Enhancing_Equity_in_Large_Language_Models_for_Medical_Applications.md)

- [Explanation sensitivity to the randomness of large language models: the case of journalistic text classification](2024年10月07日/Explanation_sensitivity_to_the_randomness_of_large_language_models_the_case_of_journalistic_text_classification.md)

    - [翻译: 大型语言模型的随机性如何影响解释的敏感性？以新闻文本分类为例，探讨这一问题。](2024年10月07日/Explanation_sensitivity_to_the_randomness_of_large_language_models_the_case_of_journalistic_text_classification.md)

- [Fast State Restoration in LLM Serving with HCache](2024年10月07日/Fast_State_Restoration_in_LLM_Serving_with_HCache.md)

    - [翻译: 借助 HCache，LLM 服务中的状态恢复速度大幅提升](2024年10月07日/Fast_State_Restoration_in_LLM_Serving_with_HCache.md)

- [FELLAS: Enhancing Federated Sequential Recommendation with LLM as External Services](2024年10月07日/FELLAS_Enhancing_Federated_Sequential_Recommendation_with_LLM_as_External_Services.md)

    - [翻译: FELLAS：借助 LLM 作为外部服务，提升联邦序列推荐的性能](2024年10月07日/FELLAS_Enhancing_Federated_Sequential_Recommendation_with_LLM_as_External_Services.md)

- [Formality is Favored: Unraveling the Learning Preferences of Large Language Models on Data with Conflicting Knowledge](2024年10月07日/Formality_is_Favored_Unraveling_the_Learning_Preferences_of_Large_Language_Models_on_Data_with_Conflicting_Knowledge.md)

    - [翻译: 大型语言模型偏爱形式性：解析其在冲突知识数据上的学习倾向](2024年10月07日/Formality_is_Favored_Unraveling_the_Learning_Preferences_of_Large_Language_Models_on_Data_with_Conflicting_Knowledge.md)

- [GARLIC: LLM-Guided Dynamic Progress Control with Hierarchical Weighted Graph for Long Document QA](2024年10月07日/GARLIC_LLM-Guided_Dynamic_Progress_Control_with_Hierarchical_Weighted_Graph_for_Long_Document_QA.md)

    - [翻译: GARLIC：利用 LLM 引导的动态进度控制和分层加权图，实现长文档问答的优化。](2024年10月07日/GARLIC_LLM-Guided_Dynamic_Progress_Control_with_Hierarchical_Weighted_Graph_for_Long_Document_QA.md)

- [GLEE: A Unified Framework and Benchmark for Language-based Economic Environments](2024年10月07日/GLEE_A_Unified_Framework_and_Benchmark_for_Language-based_Economic_Environments.md)

    - [翻译: GLEE：基于语言的经济环境统一框架与基准](2024年10月07日/GLEE_A_Unified_Framework_and_Benchmark_for_Language-based_Economic_Environments.md)

- [GSM-Symbolic: Understanding the Limitations of Mathematical Reasoning in Large Language Models](2024年10月07日/GSM-Symbolic_Understanding_the_Limitations_of_Mathematical_Reasoning_in_Large_Language_Models.md)

    - [翻译: GSM-Symbolic：揭示大型语言模型在数学推理中的局限](2024年10月07日/GSM-Symbolic_Understanding_the_Limitations_of_Mathematical_Reasoning_in_Large_Language_Models.md)

- [ImProver: Agent-Based Automated Proof Optimization](2024年10月07日/ImProver_Agent-Based_Automated_Proof_Optimization.md)

    - [翻译: ImProver：一种基于代理的自动证明优化工具](2024年10月07日/ImProver_Agent-Based_Automated_Proof_Optimization.md)

- [Initialization of Large Language Models via Reparameterization to Mitigate Loss Spikes](2024年10月07日/Initialization_of_Large_Language_Models_via_Reparameterization_to_Mitigate_Loss_Spikes.md)

    - [翻译: 通过重新参数化减轻损失峰值，实现大型语言模型的优化初始化。](2024年10月07日/Initialization_of_Large_Language_Models_via_Reparameterization_to_Mitigate_Loss_Spikes.md)

- [Intent Classification for Bank Chatbots through LLM Fine-Tuning](2024年10月07日/Intent_Classification_for_Bank_Chatbots_through_LLM_Fine-Tuning.md)

    - [翻译: 利用 LLM 微调技术，为银行聊天机器人实现精准的意图分类。](2024年10月07日/Intent_Classification_for_Bank_Chatbots_through_LLM_Fine-Tuning.md)

- [Intriguing Properties of Large Language and Vision Models](2024年10月07日/Intriguing_Properties_of_Large_Language_and_Vision_Models.md)

    - [翻译: 大型语言与视觉模型中那些引人入胜的特性](2024年10月07日/Intriguing_Properties_of_Large_Language_and_Vision_Models.md)

- [Investigating large language models for their competence in extracting grammatically sound sentences from transcribed noisy utterances](2024年10月07日/Investigating_large_language_models_for_their_competence_in_extracting_grammatically_sound_sentences_from_transcribed_noisy_utterances.md)

    - [翻译: 探究大型语言模型如何从嘈杂的语音转录中提炼出语法正确的句子](2024年10月07日/Investigating_large_language_models_for_their_competence_in_extracting_grammatically_sound_sentences_from_transcribed_noisy_utterances.md)

- [LADEV: A Language-Driven Testing and Evaluation Platform for Vision-Language-Action Models in Robotic Manipulation](2024年10月07日/LADEV_A_Language-Driven_Testing_and_Evaluation_Platform_for_Vision-Language-Action_Models_in_Robotic_Manipulation.md)

    - [翻译: LADEV：机器人操作中视觉-语言-动作模型的语言驱动测试与评估平台](2024年10月07日/LADEV_A_Language-Driven_Testing_and_Evaluation_Platform_for_Vision-Language-Action_Models_in_Robotic_Manipulation.md)

- [Large Language Model Based Multi-Objective Optimization for Integrated Sensing and Communications in UAV Networks](2024年10月07日/Large_Language_Model_Based_Multi-Objective_Optimization_for_Integrated_Sensing_and_Communications_in_UAV_Networks.md)

    - [翻译: 无人机网络中的集成感知与通信，通过基于大型语言模型的多目标优化实现。](2024年10月07日/Large_Language_Model_Based_Multi-Objective_Optimization_for_Integrated_Sensing_and_Communications_in_UAV_Networks.md)

- [Leverage Knowledge Graph and Large Language Model for Law Article Recommendation: A Case Study of Chinese Criminal Law](2024年10月07日/Leverage_Knowledge_Graph_and_Large_Language_Model_for_Law_Article_Recommendation_A_Case_Study_of_Chinese_Criminal_Law.md)

    - [翻译: 借助知识图谱与大型语言模型，探索中国刑法条文推荐的新路径。](2024年10月07日/Leverage_Knowledge_Graph_and_Large_Language_Model_for_Law_Article_Recommendation_A_Case_Study_of_Chinese_Criminal_Law.md)

- [LLaVA Needs More Knowledge: Retrieval Augmented Natural Language Generation with Knowledge Graph for Explaining Thoracic Pathologies](2024年10月07日/LLaVA_Needs_More_Knowledge_Retrieval_Augmented_Natural_Language_Generation_with_Knowledge_Graph_for_Explaining_Thoracic_Pathologies.md)

    - [翻译: LLaVA 需更多知识：结合知识图谱的检索增强自然语言生成，助力胸腔病理解析](2024年10月07日/LLaVA_Needs_More_Knowledge_Retrieval_Augmented_Natural_Language_Generation_with_Knowledge_Graph_for_Explaining_Thoracic_Pathologies.md)

- [LoTLIP: Improving Language-Image Pre-training for Long Text Understanding](2024年10月07日/LoTLIP_Improving_Language-Image_Pre-training_for_Long_Text_Understanding.md)

    - [翻译: LoTLIP：提升长文本理解的语言-图像预训练效果](2024年10月07日/LoTLIP_Improving_Language-Image_Pre-training_for_Long_Text_Understanding.md)

- [MINER: Mining the Underlying Pattern of Modality-Specific Neurons in Multimodal Large Language Models](2024年10月07日/MINER_Mining_the_Underlying_Pattern_of_Modality-Specific_Neurons_in_Multimodal_Large_Language_Models.md)

    - [翻译: MINER：探索多模态大型语言模型中特定模态神经元的深层模式](2024年10月07日/MINER_Mining_the_Underlying_Pattern_of_Modality-Specific_Neurons_in_Multimodal_Large_Language_Models.md)

- [Mitigating Modality Prior-Induced Hallucinations in Multimodal Large Language Models via Deciphering Attention Causality](2024年10月07日/Mitigating_Modality_Prior-Induced_Hallucinations_in_Multimodal_Large_Language_Models_via_Deciphering_Attention_Causality.md)

    - [翻译: 通过揭示注意力因果，减轻多模态大型语言模型中模态先验引发的幻觉问题。](2024年10月07日/Mitigating_Modality_Prior-Induced_Hallucinations_in_Multimodal_Large_Language_Models_via_Deciphering_Attention_Causality.md)

- [MM-R$^3$: On (In-)Consistency of Multi-modal Large Language Models (MLLMs)](2024年10月07日/MM-R$^3$_On_(In-)Consistency_of_Multi-modal_Large_Language_Models_(MLLMs).md)

    - [翻译: MM-R$^3$: 探讨多模态大型语言模型 (MLLM) 的一致性问题](2024年10月07日/MM-R$^3$_On_(In-)Consistency_of_Multi-modal_Large_Language_Models_(MLLMs).md)

- [Navigating the Digital World as Humans Do: Universal Visual Grounding for GUI Agents](2024年10月07日/Navigating_the_Digital_World_as_Humans_Do_Universal_Visual_Grounding_for_GUI_Agents.md)

    - [翻译: 像人类一样探索数字世界：GUI 代理的通用视觉基础](2024年10月07日/Navigating_the_Digital_World_as_Humans_Do_Universal_Visual_Grounding_for_GUI_Agents.md)

- [Organizing Unstructured Image Collections using Natural Language](2024年10月07日/Organizing_Unstructured_Image_Collections_using_Natural_Language.md)

    - [翻译: 用自然语言整理无序的图像集](2024年10月07日/Organizing_Unstructured_Image_Collections_using_Natural_Language.md)

- [Precise Model Benchmarking with Only a Few Observations](2024年10月07日/Precise_Model_Benchmarking_with_Only_a_Few_Observations.md)

    - [翻译: 少量观察也能实现精准模型基准测试](2024年10月07日/Precise_Model_Benchmarking_with_Only_a_Few_Observations.md)

- [PrefixQuant: Static Quantization Beats Dynamic through Prefixed Outliers in LLMs](2024年10月07日/PrefixQuant_Static_Quantization_Beats_Dynamic_through_Prefixed_Outliers_in_LLMs.md)

    - [翻译: PrefixQuant：通过 LLM 中的前缀异常值，静态量化超越了动态量化。](2024年10月07日/PrefixQuant_Static_Quantization_Beats_Dynamic_through_Prefixed_Outliers_in_LLMs.md)

- [Rationale-Aware Answer Verification by Pairwise Self-Evaluation](2024年10月07日/Rationale-Aware_Answer_Verification_by_Pairwise_Self-Evaluation.md)

    - [翻译: 基于成对自我评估的理性答案验证](2024年10月07日/Rationale-Aware_Answer_Verification_by_Pairwise_Self-Evaluation.md)

- [ReasoningRank: Teaching Student Models to Rank through Reasoning-Based Knowledge Distillation](2024年10月07日/ReasoningRank_Teaching_Student_Models_to_Rank_through_Reasoning-Based_Knowledge_Distillation.md)

    - [翻译: ReasoningRank：借助推理为基础的知识蒸馏，教导学生模型掌握排序技能](2024年10月07日/ReasoningRank_Teaching_Student_Models_to_Rank_through_Reasoning-Based_Knowledge_Distillation.md)

- [Representing the Under-Represented: Cultural and Core Capability Benchmarks for Developing Thai Large Language Models](2024年10月07日/Representing_the_Under-Represented_Cultural_and_Core_Capability_Benchmarks_for_Developing_Thai_Large_Language_Models.md)

    - [翻译: 为泰国大型语言模型开发文化与核心能力基准，旨在更好地代表那些未被充分体现的群体。](2024年10月07日/Representing_the_Under-Represented_Cultural_and_Core_Capability_Benchmarks_for_Developing_Thai_Large_Language_Models.md)

- [RevisEval: Improving LLM-as-a-Judge via Response-Adapted References](2024年10月07日/RevisEval_Improving_LLM-as-a-Judge_via_Response-Adapted_References.md)

    - [翻译: RevisEval：通过自适应参考文献提升 LLM 作为评判者的表现](2024年10月07日/RevisEval_Improving_LLM-as-a-Judge_via_Response-Adapted_References.md)

- [Scalable and Accurate Graph Reasoning with LLM-based Multi-Agents](2024年10月07日/Scalable_and_Accurate_Graph_Reasoning_with_LLM-based_Multi-Agents.md)

    - [翻译: 利用 LLM 多代理系统实现高效且精准的图推理](2024年10月07日/Scalable_and_Accurate_Graph_Reasoning_with_LLM-based_Multi-Agents.md)

- [SFTMix: Elevating Language Model Instruction Tuning with Mixup Recipe](2024年10月07日/SFTMix_Elevating_Language_Model_Instruction_Tuning_with_Mixup_Recipe.md)

    - [翻译: SFTMix：借助 Mixup 配方，提升语言模型的指令调优效果](2024年10月07日/SFTMix_Elevating_Language_Model_Instruction_Tuning_with_Mixup_Recipe.md)

- [Strong Model Collapse](2024年10月07日/Strong_Model_Collapse.md)

    - [翻译: 模型崩溃现象严重](2024年10月07日/Strong_Model_Collapse.md)

- [TableRAG: Million-Token Table Understanding with Language Models](2024年10月07日/TableRAG_Million-Token_Table_Understanding_with_Language_Models.md)

    - [翻译: TableRAG：借助语言模型实现百万标记表格的深度理解](2024年10月07日/TableRAG_Million-Token_Table_Understanding_with_Language_Models.md)

- [TextHawk2: A Large Vision-Language Model Excels in Bilingual OCR and Grounding with 16x Fewer Tokens](2024年10月07日/TextHawk2_A_Large_Vision-Language_Model_Excels_in_Bilingual_OCR_and_Grounding_with_16x_Fewer_Tokens.md)

    - [翻译: TextHawk2：一款大型视觉语言模型，以 16 倍更少的标记在双语 OCR 和定位任务中大放异彩。](2024年10月07日/TextHawk2_A_Large_Vision-Language_Model_Excels_in_Bilingual_OCR_and_Grounding_with_16x_Fewer_Tokens.md)

- [The Dawn of Video Generation: Preliminary Explorations with SORA-like Models](2024年10月07日/The_Dawn_of_Video_Generation_Preliminary_Explorations_with_SORA-like_Models.md)

    - [翻译: 视频生成的新纪元：SORA-like 模型的初步探索之旅](2024年10月07日/The_Dawn_of_Video_Generation_Preliminary_Explorations_with_SORA-like_Models.md)

- [TidalDecode: Fast and Accurate LLM Decoding with Position Persistent Sparse Attention](2024年10月07日/TidalDecode_Fast_and_Accurate_LLM_Decoding_with_Position_Persistent_Sparse_Attention.md)

    - [翻译: TidalDecode：通过位置持久稀疏注意力，实现 LLM 的快速精准解码](2024年10月07日/TidalDecode_Fast_and_Accurate_LLM_Decoding_with_Position_Persistent_Sparse_Attention.md)

- [TLDR: Token-Level Detective Reward Model for Large Vision Language Models](2024年10月07日/TLDR_Token-Level_Detective_Reward_Model_for_Large_Vision_Language_Models.md)

    - [翻译: TLDR: 大型视觉语言模型的令牌级侦探奖励模型](2024年10月07日/TLDR_Token-Level_Detective_Reward_Model_for_Large_Vision_Language_Models.md)

- [TurtleBench: Evaluating Top Language Models via Real-World Yes/No Puzzles](2024年10月07日/TurtleBench_Evaluating_Top_Language_Models_via_Real-World_YesNo_Puzzles.md)

    - [翻译: TurtleBench：用现实中的 Yes/No 谜题来检验顶级语言模型的实力](2024年10月07日/TurtleBench_Evaluating_Top_Language_Models_via_Real-World_YesNo_Puzzles.md)

- [Understanding Warmup-Stable-Decay Learning Rates: A River Valley Loss Landscape Perspective](2024年10月07日/Understanding_Warmup-Stable-Decay_Learning_Rates_A_River_Valley_Loss_Landscape_Perspective.md)

    - [翻译: 从河流谷地损失景观的视角，理解 Warmup-Stable-Decay 学习率。](2024年10月07日/Understanding_Warmup-Stable-Decay_Learning_Rates_A_River_Valley_Loss_Landscape_Perspective.md)

- [ZEBRA: Zero-Shot Example-Based Retrieval Augmentation for Commonsense Question Answering](2024年10月07日/ZEBRA_Zero-Shot_Example-Based_Retrieval_Augmentation_for_Commonsense_Question_Answering.md)

    - [翻译: ZEBRA：一种基于零-shot 示例的常识问答检索增强技术](2024年10月07日/ZEBRA_Zero-Shot_Example-Based_Retrieval_Augmentation_for_Commonsense_Question_Answering.md)

2024年10月06日

- [$\textbf{Only-IF}$:Revealing the Decisive Effect of Instruction Diversity on Generalization](2024年10月06日/$\textbf{Only-IF}$Revealing_the_Decisive_Effect_of_Instruction_Diversity_on_Generalization.md)

    - [翻译: $\textbf{仅限IF}$：揭秘指令多样性如何决定泛化效果](2024年10月06日/$\textbf{Only-IF}$Revealing_the_Decisive_Effect_of_Instruction_Diversity_on_Generalization.md)

- [ACDC: Autoregressive Coherent Multimodal Generation using Diffusion Correction](2024年10月06日/ACDC_Autoregressive_Coherent_Multimodal_Generation_using_Diffusion_Correction.md)

    - [翻译: ACDC：通过扩散校正实现的自回归连贯多模态生成](2024年10月06日/ACDC_Autoregressive_Coherent_Multimodal_Generation_using_Diffusion_Correction.md)

- [A Cross-Lingual Meta-Learning Method Based on Domain Adaptation for Speech Emotion Recognition](2024年10月06日/A_Cross-Lingual_Meta-Learning_Method_Based_on_Domain_Adaptation_for_Speech_Emotion_Recognition.md)

    - [翻译: 一种基于领域适应的跨语言元学习方法，专为语音情感识别设计。](2024年10月06日/A_Cross-Lingual_Meta-Learning_Method_Based_on_Domain_Adaptation_for_Speech_Emotion_Recognition.md)

- [ActiView: Evaluating Active Perception Ability for Multimodal Large Language Models](2024年10月06日/ActiView_Evaluating_Active_Perception_Ability_for_Multimodal_Large_Language_Models.md)

    - [翻译: ActiView：探索多模态大型语言模型的主动感知能力](2024年10月06日/ActiView_Evaluating_Active_Perception_Ability_for_Multimodal_Large_Language_Models.md)

- [Adversarial Multi-Agent Evaluation of Large Language Models through Iterative Debates](2024年10月06日/Adversarial_Multi-Agent_Evaluation_of_Large_Language_Models_through_Iterative_Debates.md)

    - [翻译: 大型语言模型通过迭代辩论进行对抗性多智能体评估](2024年10月06日/Adversarial_Multi-Agent_Evaluation_of_Large_Language_Models_through_Iterative_Debates.md)

- [Control Large Language Models via Divide and Conquer](2024年10月06日/Control_Large_Language_Models_via_Divide_and_Conquer.md)

    - [翻译: 驾驭大型语言模型：分而治之的策略](2024年10月06日/Control_Large_Language_Models_via_Divide_and_Conquer.md)

- [DAdEE: Unsupervised Domain Adaptation in Early Exit PLMs](2024年10月06日/DAdEE_Unsupervised_Domain_Adaptation_in_Early_Exit_PLMs.md)

    - [翻译: DAdEE：早期退出 PLM 中的无监督领域自适应](2024年10月06日/DAdEE_Unsupervised_Domain_Adaptation_in_Early_Exit_PLMs.md)

- [Deeper Insights Without Updates: The Power of In-Context Learning Over Fine-Tuning](2024年10月06日/Deeper_Insights_Without_Updates_The_Power_of_In-Context_Learning_Over_Fine-Tuning.md)

    - [翻译: 无需更新，In-Context Learning 便能带来更深层次的洞察，其效果超越了微调。](2024年10月06日/Deeper_Insights_Without_Updates_The_Power_of_In-Context_Learning_Over_Fine-Tuning.md)

- [EnsemW2S: Can an Ensemble of LLMs be Leveraged to Obtain a Stronger LLM?](2024年10月06日/EnsemW2S_Can_an_Ensemble_of_LLMs_be_Leveraged_to_Obtain_a_Stronger_LLM.md)

    - [翻译: EnsemW2S：集合多个 LLM，能否打造出更强大的模型？](2024年10月06日/EnsemW2S_Can_an_Ensemble_of_LLMs_be_Leveraged_to_Obtain_a_Stronger_LLM.md)

- [ErrorRadar: Benchmarking Complex Mathematical Reasoning of Multimodal Large Language Models Via Error Detection](2024年10月06日/ErrorRadar_Benchmarking_Complex_Mathematical_Reasoning_of_Multimodal_Large_Language_Models_Via_Error_Detection.md)

    - [翻译: ErrorRadar：借助错误检测，为多模态大型语言模型的复杂数学推理能力设立基准。](2024年10月06日/ErrorRadar_Benchmarking_Complex_Mathematical_Reasoning_of_Multimodal_Large_Language_Models_Via_Error_Detection.md)

- [Evaluation of Code LLMs on Geospatial Code Generation](2024年10月06日/Evaluation_of_Code_LLMs_on_Geospatial_Code_Generation.md)

    - [翻译: 评估代码大型语言模型在地理空间代码生成中的表现](2024年10月06日/Evaluation_of_Code_LLMs_on_Geospatial_Code_Generation.md)

- [Fine-Grained Prediction of Reading Comprehension from Eye Movements](2024年10月06日/Fine-Grained_Prediction_of_Reading_Comprehension_from_Eye_Movements.md)

    - [翻译: 通过眼球运动精准预测阅读理解](2024年10月06日/Fine-Grained_Prediction_of_Reading_Comprehension_from_Eye_Movements.md)

- [Forgetting Curve: A Reliable Method for Evaluating Memorization Capability for Long-context Models](2024年10月06日/Forgetting_Curve_A_Reliable_Method_for_Evaluating_Memorization_Capability_for_Long-context_Models.md)

    - [翻译: 遗忘曲线：评估长上下文模型记忆力的有效工具](2024年10月06日/Forgetting_Curve_A_Reliable_Method_for_Evaluating_Memorization_Capability_for_Long-context_Models.md)

- [GenSim: A General Social Simulation Platform with Large Language Model based Agents](2024年10月06日/GenSim_A_General_Social_Simulation_Platform_with_Large_Language_Model_based_Agents.md)

    - [翻译: GenSim：一款基于大型语言模型代理的通用社会模拟平台](2024年10月06日/GenSim_A_General_Social_Simulation_Platform_with_Large_Language_Model_based_Agents.md)

- [Gödel Agent: A Self-Referential Agent Framework for Recursive Self-Improvement](2024年10月06日/Gödel_Agent_A_Self-Referential_Agent_Framework_for_Recursive_Self-Improvement.md)

    - [翻译: Gödel Agent：一个自指代理框架，专为递归自我改进设计](2024年10月06日/Gödel_Agent_A_Self-Referential_Agent_Framework_for_Recursive_Self-Improvement.md)

- [HALL-E: Hierarchical Neural Codec Language Model for Minute-Long Zero-Shot Text-to-Speech Synthesis](2024年10月06日/HALL-E_Hierarchical_Neural_Codec_Language_Model_for_Minute-Long_Zero-Shot_Text-to-Speech_Synthesis.md)

    - [翻译: HALL-E：一种分层神经编解码语言模型，专为长时间零-shot 文本到语音合成而设计。](2024年10月06日/HALL-E_Hierarchical_Neural_Codec_Language_Model_for_Minute-Long_Zero-Shot_Text-to-Speech_Synthesis.md)

- [Hammer: Robust Function-Calling for On-Device Language Models via Function Masking](2024年10月06日/Hammer_Robust_Function-Calling_for_On-Device_Language_Models_via_Function_Masking.md)

    - [翻译: Hammer：利用函数掩码技术，为设备上的语言模型提供稳健的函数调用功能。](2024年10月06日/Hammer_Robust_Function-Calling_for_On-Device_Language_Models_via_Function_Masking.md)

- [How Does the Disclosure of AI Assistance Affect the Perceptions of Writing?](2024年10月06日/How_Does_the_Disclosure_of_AI_Assistance_Affect_the_Perceptions_of_Writing.md)

    - [翻译: AI 辅助的透明度如何影响人们对写作的看法？](2024年10月06日/How_Does_the_Disclosure_of_AI_Assistance_Affect_the_Perceptions_of_Writing.md)

- [Lens: Rethinking Multilingual Enhancement for Large Language Models](2024年10月06日/Lens_Rethinking_Multilingual_Enhancement_for_Large_Language_Models.md)

    - [翻译: Lens：重新审视大型语言模型的多语言增强策略](2024年10月06日/Lens_Rethinking_Multilingual_Enhancement_for_Large_Language_Models.md)

- [LRQ-Fact: LLM-Generated Relevant Questions for Multimodal Fact-Checking](2024年10月06日/LRQ-Fact_LLM-Generated_Relevant_Questions_for_Multimodal_Fact-Checking.md)

    - [翻译: LRQ-Fact：多模态事实核查中的 LLM 生成相关问题](2024年10月06日/LRQ-Fact_LLM-Generated_Relevant_Questions_for_Multimodal_Fact-Checking.md)

- [MathHay: An Automated Benchmark for Long-Context Mathematical Reasoning in LLMs](2024年10月06日/MathHay_An_Automated_Benchmark_for_Long-Context_Mathematical_Reasoning_in_LLMs.md)

    - [翻译: MathHay：LLMs 中长上下文数学推理的自动化标杆](2024年10月06日/MathHay_An_Automated_Benchmark_for_Long-Context_Mathematical_Reasoning_in_LLMs.md)

- [MindScope: Exploring cognitive biases in large language models through Multi-Agent Systems](2024年10月06日/MindScope_Exploring_cognitive_biases_in_large_language_models_through_Multi-Agent_Systems.md)

    - [翻译: MindScope 项目通过多代理系统，深入研究大型语言模型中的认知偏差。](2024年10月06日/MindScope_Exploring_cognitive_biases_in_large_language_models_through_Multi-Agent_Systems.md)

- [Need Help? Designing Proactive AI Assistants for Programming](2024年10月06日/Need_Help_Designing_Proactive_AI_Assistants_for_Programming.md)

    - [翻译: 编程遇到难题？让我们设计一款主动出击的 AI 助手来帮你！](2024年10月06日/Need_Help_Designing_Proactive_AI_Assistants_for_Programming.md)

- [On Evaluating LLMs' Capabilities as Functional Approximators: A Bayesian Perspective](2024年10月06日/On_Evaluating_LLMs'_Capabilities_as_Functional_Approximators_A_Bayesian_Perspective.md)

    - [翻译: 从贝叶斯视角评估 LLM 作为功能近似器的能力](2024年10月06日/On_Evaluating_LLMs'_Capabilities_as_Functional_Approximators_A_Bayesian_Perspective.md)

- [ProtocoLLM: Automatic Evaluation Framework of LLMs on Domain-Specific Scientific Protocol Formulation Tasks](2024年10月06日/ProtocoLLM_Automatic_Evaluation_Framework_of_LLMs_on_Domain-Specific_Scientific_Protocol_Formulation_Tasks.md)

    - [翻译: ProtocoLLM：专为特定科学领域协议制定任务设计的 LLM 自动评估框架](2024年10月06日/ProtocoLLM_Automatic_Evaluation_Framework_of_LLMs_on_Domain-Specific_Scientific_Protocol_Formulation_Tasks.md)

- [Regressing the Relative Future: Efficient Policy Optimization for Multi-turn RLHF](2024年10月06日/Regressing_the_Relative_Future_Efficient_Policy_Optimization_for_Multi-turn_RLHF.md)

    - [翻译: 精准预测未来：多轮 RLHF 策略的高效优化](2024年10月06日/Regressing_the_Relative_Future_Efficient_Policy_Optimization_for_Multi-turn_RLHF.md)

- [The LLM Effect: Are Humans Truly Using LLMs, or Are They Being Influenced By Them Instead?](2024年10月06日/The_LLM_Effect_Are_Humans_Truly_Using_LLMs,_or_Are_They_Being_Influenced_By_Them_Instead.md)

    - [翻译: LLM 效应：人类是在利用 LLM，还是反被其左右？](2024年10月06日/The_LLM_Effect_Are_Humans_Truly_Using_LLMs,_or_Are_They_Being_Influenced_By_Them_Instead.md)

- [Towards Measuring Goal-Directedness in AI Systems](2024年10月06日/Towards_Measuring_Goal-Directedness_in_AI_Systems.md)

    - [翻译: 探索 AI 系统中目标导向性的测量方法](2024年10月06日/Towards_Measuring_Goal-Directedness_in_AI_Systems.md)