# 2024年10月

2024年10月02日

- [Agent-Driven Large Language Models for Mandarin Lyric Generation](2024年10月02日/Agent-Driven_Large_Language_Models_for_Mandarin_Lyric_Generation.md)

    - [翻译: 基于代理的大型语言模型助力普通话歌词创作](2024年10月02日/Agent-Driven_Large_Language_Models_for_Mandarin_Lyric_Generation.md)

- [AgriCLIP: Adapting CLIP for Agriculture and Livestock via Domain-Specialized Cross-Model Alignment](2024年10月02日/AgriCLIP_Adapting_CLIP_for_Agriculture_and_Livestock_via_Domain-Specialized_Cross-Model_Alignment.md)

    - [翻译: AgriCLIP：通过领域专业化的跨模型对齐，为农业和畜牧业量身定制的 CLIP](2024年10月02日/AgriCLIP_Adapting_CLIP_for_Agriculture_and_Livestock_via_Domain-Specialized_Cross-Model_Alignment.md)

- [A Little Goes a Long Way: Efficient Long Context Training and Inference with Partial Contexts](2024年10月02日/A_Little_Goes_a_Long_Way_Efficient_Long_Context_Training_and_Inference_with_Partial_Contexts.md)

    - [翻译: 少量的上下文也能走很远：通过部分上下文实现高效的长上下文训练和推理](2024年10月02日/A_Little_Goes_a_Long_Way_Efficient_Long_Context_Training_and_Inference_with_Partial_Contexts.md)

- [Assisted Data Annotation for Business Process Information Extraction from Textual Documents](2024年10月02日/Assisted_Data_Annotation_for_Business_Process_Information_Extraction_from_Textual_Documents.md)

    - [翻译: 文本文件中业务流程信息的辅助标注提取](2024年10月02日/Assisted_Data_Annotation_for_Business_Process_Information_Extraction_from_Textual_Documents.md)

- [Auto-Demo Prompting: Leveraging Generated Outputs as Demonstrations for Enhanced Batch Prompting](2024年10月02日/Auto-Demo_Prompting_Leveraging_Generated_Outputs_as_Demonstrations_for_Enhanced_Batch_Prompting.md)

    - [翻译: 自动演示提示：借助生成的输出作为演示，提升批量提示的效果](2024年10月02日/Auto-Demo_Prompting_Leveraging_Generated_Outputs_as_Demonstrations_for_Enhanced_Batch_Prompting.md)

- [Automated Knowledge Concept Annotation and Question Representation Learning for Knowledge Tracing](2024年10月02日/Automated_Knowledge_Concept_Annotation_and_Question_Representation_Learning_for_Knowledge_Tracing.md)

    - [翻译: 知识追踪中的自动概念注释与问题表示学习](2024年10月02日/Automated_Knowledge_Concept_Annotation_and_Question_Representation_Learning_for_Knowledge_Tracing.md)

- [Automated Red Teaming with GOAT: the Generative Offensive Agent Tester](2024年10月02日/Automated_Red_Teaming_with_GOAT_the_Generative_Offensive_Agent_Tester.md)

    - [翻译: GOAT：自动红队测试中的生成性攻击代理](2024年10月02日/Automated_Red_Teaming_with_GOAT_the_Generative_Offensive_Agent_Tester.md)

- [Automatic deductive coding in discourse analysis: an application of large language models in learning analytics](2024年10月02日/Automatic_deductive_coding_in_discourse_analysis_an_application_of_large_language_models_in_learning_analytics.md)

    - [翻译: 自动演绎编码在话语分析中的应用：探索大型语言模型在学习分析中的潜力](2024年10月02日/Automatic_deductive_coding_in_discourse_analysis_an_application_of_large_language_models_in_learning_analytics.md)

- [Backdooring Vision-Language Models with Out-Of-Distribution Data](2024年10月02日/Backdooring_Vision-Language_Models_with_Out-Of-Distribution_Data.md)

    - [翻译: 利用分布外数据对视觉-语言模型实施后门攻击](2024年10月02日/Backdooring_Vision-Language_Models_with_Out-Of-Distribution_Data.md)

- [Bayes' Power for Explaining In-Context Learning Generalizations](2024年10月02日/Bayes'_Power_for_Explaining_In-Context_Learning_Generalizations.md)

    - [翻译: 贝叶斯理论揭示了上下文学习泛化的奥秘](2024年10月02日/Bayes'_Power_for_Explaining_In-Context_Learning_Generalizations.md)

- [Boosting Weakly-Supervised Referring Image Segmentation via Progressive Comprehension](2024年10月02日/Boosting_Weakly-Supervised_Referring_Image_Segmentation_via_Progressive_Comprehension.md)

    - [翻译: 逐步理解，提升弱监督引用图像分割](2024年10月02日/Boosting_Weakly-Supervised_Referring_Image_Segmentation_via_Progressive_Comprehension.md)

- [Bridging Context Gaps: Leveraging Coreference Resolution for Long Contextual Understanding](2024年10月02日/Bridging_Context_Gaps_Leveraging_Coreference_Resolution_for_Long_Contextual_Understanding.md)

    - [翻译: 跨越上下文鸿沟：借助共指消解，深化长文本理解](2024年10月02日/Bridging_Context_Gaps_Leveraging_Coreference_Resolution_for_Long_Contextual_Understanding.md)

- [Can We Further Elicit Reasoning in LLMs? Critic-Guided Planning with Retrieval-Augmentation for Solving Challenging Tasks](2024年10月02日/Can_We_Further_Elicit_Reasoning_in_LLMs_Critic-Guided_Planning_with_Retrieval-Augmentation_for_Solving_Challenging_Tasks.md)

    - [翻译: 我们能否在 LLM 中进一步激发推理能力？通过批评者引导的规划与检索增强，解决复杂任务。](2024年10月02日/Can_We_Further_Elicit_Reasoning_in_LLMs_Critic-Guided_Planning_with_Retrieval-Augmentation_for_Solving_Challenging_Tasks.md)

- [Cognition Transferring and Decoupling for Text-supervised Egocentric Semantic Segmentation](2024年10月02日/Cognition_Transferring_and_Decoupling_for_Text-supervised_Egocentric_Semantic_Segmentation.md)

    - [翻译: 文本监督下的自我中心语义分割：认知转移与解耦](2024年10月02日/Cognition_Transferring_and_Decoupling_for_Text-supervised_Egocentric_Semantic_Segmentation.md)

- [Conformal Generative Modeling with Improved Sample Efficiency through Sequential Greedy Filtering](2024年10月02日/Conformal_Generative_Modeling_with_Improved_Sample_Efficiency_through_Sequential_Greedy_Filtering.md)

    - [翻译: 通过顺序贪婪过滤，提升样本效率的保形生成建模](2024年10月02日/Conformal_Generative_Modeling_with_Improved_Sample_Efficiency_through_Sequential_Greedy_Filtering.md)

- [ConServe: Harvesting GPUs for Low-Latency and High-Throughput Large Language Model Serving](2024年10月02日/ConServe_Harvesting_GPUs_for_Low-Latency_and_High-Throughput_Large_Language_Model_Serving.md)

    - [翻译: ConServe：高效利用 GPU，实现大型语言模型服务的低延迟与高吞吐量](2024年10月02日/ConServe_Harvesting_GPUs_for_Low-Latency_and_High-Throughput_Large_Language_Model_Serving.md)

- [CreDes: Causal Reasoning Enhancement and Dual-End Searching for Solving Long-Range Reasoning Problems using LLMs](2024年10月02日/CreDes_Causal_Reasoning_Enhancement_and_Dual-End_Searching_for_Solving_Long-Range_Reasoning_Problems_using_LLMs.md)

    - [翻译: CreDes：通过因果推理增强和双端搜索，解决 LLM 中的长距离推理难题](2024年10月02日/CreDes_Causal_Reasoning_Enhancement_and_Dual-End_Searching_for_Solving_Long-Range_Reasoning_Problems_using_LLMs.md)

- [CrowdCounter: A benchmark type-specific multi-target counterspeech dataset](2024年10月02日/CrowdCounter_A_benchmark_type-specific_multi-target_counterspeech_dataset.md)

    - [翻译: CrowdCounter：一款专为多目标反驳言论设计的特定类型数据集基准](2024年10月02日/CrowdCounter_A_benchmark_type-specific_multi-target_counterspeech_dataset.md)

- [Data Extrapolation for Text-to-image Generation on Small Datasets](2024年10月02日/Data_Extrapolation_for_Text-to-image_Generation_on_Small_Datasets.md)

    - [翻译: 小数据集上的文本到图像生成中的数据外推](2024年10月02日/Data_Extrapolation_for_Text-to-image_Generation_on_Small_Datasets.md)

- [Disentangling Latent Shifts of In-Context Learning Through Self-Training](2024年10月02日/Disentangling_Latent_Shifts_of_In-Context_Learning_Through_Self-Training.md)

    - [翻译: 通过自训练揭示上下文学习的潜在变化](2024年10月02日/Disentangling_Latent_Shifts_of_In-Context_Learning_Through_Self-Training.md)

- [DLP-LoRA: Efficient Task-Specific LoRA Fusion with a Dynamic, Lightweight Plugin for Large Language Models](2024年10月02日/DLP-LoRA_Efficient_Task-Specific_LoRA_Fusion_with_a_Dynamic,_Lightweight_Plugin_for_Large_Language_Models.md)

    - [翻译: DLP-LoRA：为大型语言模型量身定制的动态轻量级插件，实现高效的任务特定 LoRA 融合](2024年10月02日/DLP-LoRA_Efficient_Task-Specific_LoRA_Fusion_with_a_Dynamic,_Lightweight_Plugin_for_Large_Language_Models.md)

- [Efficient $1$-bit tensor approximations](2024年10月02日/Efficient_$1$-bit_tensor_approximations.md)

    - [翻译: 高效的一比特张量近似](2024年10月02日/Efficient_$1$-bit_tensor_approximations.md)

- [Elaborative Subtopic Query Reformulation for Broad and Indirect Queries in Travel Destination Recommendation](2024年10月02日/Elaborative_Subtopic_Query_Reformulation_for_Broad_and_Indirect_Queries_in_Travel_Destination_Recommendation.md)

    - [翻译: 旅行目的地推荐中的广泛与间接查询，通过详细子主题查询重构来优化。](2024年10月02日/Elaborative_Subtopic_Query_Reformulation_for_Broad_and_Indirect_Queries_in_Travel_Destination_Recommendation.md)

- [Emotion-Aware Response Generation Using Affect-Enriched Embeddings with LLMs](2024年10月02日/Emotion-Aware_Response_Generation_Using_Affect-Enriched_Embeddings_with_LLMs.md)

    - [翻译: 利用情感增强嵌入的LLM实现情感感知回复生成](2024年10月02日/Emotion-Aware_Response_Generation_Using_Affect-Enriched_Embeddings_with_LLMs.md)

- [Enhancing Training Data Attribution for Large Language Models with Fitting Error Consideration](2024年10月02日/Enhancing_Training_Data_Attribution_for_Large_Language_Models_with_Fitting_Error_Consideration.md)

    - [翻译: 考虑拟合误差，提升大型语言模型的训练数据归属](2024年10月02日/Enhancing_Training_Data_Attribution_for_Large_Language_Models_with_Fitting_Error_Consideration.md)

- [Examining the Role of Relationship Alignment in Large Language Models](2024年10月02日/Examining_the_Role_of_Relationship_Alignment_in_Large_Language_Models.md)

    - [翻译: 探究大型语言模型中关系对齐的角色](2024年10月02日/Examining_the_Role_of_Relationship_Alignment_in_Large_Language_Models.md)

- [Extending Context Window of Large Language Models from a Distributional Perspective](2024年10月02日/Extending_Context_Window_of_Large_Language_Models_from_a_Distributional_Perspective.md)

    - [翻译: 从分布视角探讨如何扩展大型语言模型的上下文窗口](2024年10月02日/Extending_Context_Window_of_Large_Language_Models_from_a_Distributional_Perspective.md)

- [FactAlign: Long-form Factuality Alignment of Large Language Models](2024年10月02日/FactAlign_Long-form_Factuality_Alignment_of_Large_Language_Models.md)

    - [翻译: FactAlign：大型语言模型的长篇事实对齐技术](2024年10月02日/FactAlign_Long-form_Factuality_Alignment_of_Large_Language_Models.md)

- [FanCric : Multi-Agentic Framework for Crafting Fantasy 11 Cricket Teams](2024年10月02日/FanCric__Multi-Agentic_Framework_for_Crafting_Fantasy_11_Cricket_Teams.md)

    - [翻译: FanCric：一个多元智能框架，专为打造梦幻板球队而生](2024年10月02日/FanCric__Multi-Agentic_Framework_for_Crafting_Fantasy_11_Cricket_Teams.md)

- [Fira: Can We Achieve Full-rank Training of LLMs Under Low-rank Constraint?](2024年10月02日/Fira_Can_We_Achieve_Full-rank_Training_of_LLMs_Under_Low-rank_Constraint.md)

    - [翻译: Fira：在低秩限制下，我们能否实现 LLM 的全秩训练？](2024年10月02日/Fira_Can_We_Achieve_Full-rank_Training_of_LLMs_Under_Low-rank_Constraint.md)

- [From Reward Shaping to Q-Shaping: Achieving Unbiased Learning with LLM-Guided Knowledge](2024年10月02日/From_Reward_Shaping_to_Q-Shaping_Achieving_Unbiased_Learning_with_LLM-Guided_Knowledge.md)

    - [翻译: 从奖励塑造到 Q-Shaping：借助 LLM 引导的知识，实现无偏学习](2024年10月02日/From_Reward_Shaping_to_Q-Shaping_Achieving_Unbiased_Learning_with_LLM-Guided_Knowledge.md)

- [Getting Free Bits Back from Rotational Symmetries in LLMs](2024年10月02日/Getting_Free_Bits_Back_from_Rotational_Symmetries_in_LLMs.md)

    - [翻译: 从 LLM 的旋转对称性中找回免费比特](2024年10月02日/Getting_Free_Bits_Back_from_Rotational_Symmetries_in_LLMs.md)

- [HarmAug: Effective Data Augmentation for Knowledge Distillation of Safety Guard Models](2024年10月02日/HarmAug_Effective_Data_Augmentation_for_Knowledge_Distillation_of_Safety_Guard_Models.md)

    - [翻译: HarmAug：为安全防护模型的知识蒸馏提供高效数据增强](2024年10月02日/HarmAug_Effective_Data_Augmentation_for_Knowledge_Distillation_of_Safety_Guard_Models.md)

- [In-Context Transfer Learning: Demonstration Synthesis by Transferring Similar Tasks](2024年10月02日/In-Context_Transfer_Learning_Demonstration_Synthesis_by_Transferring_Similar_Tasks.md)

    - [翻译: 上下文迁移学习：借助相似任务实现演示合成](2024年10月02日/In-Context_Transfer_Learning_Demonstration_Synthesis_by_Transferring_Similar_Tasks.md)

- [InfiniPot: Infinite Context Processing on Memory-Constrained LLMs](2024年10月02日/InfiniPot_Infinite_Context_Processing_on_Memory-Constrained_LLMs.md)

    - [翻译: InfiniPot：为内存受限的 LLM 提供无限上下文处理能力](2024年10月02日/InfiniPot_Infinite_Context_Processing_on_Memory-Constrained_LLMs.md)

- [Integrative Decoding: Improve Factuality via Implicit Self-consistency](2024年10月02日/Integrative_Decoding_Improve_Factuality_via_Implicit_Self-consistency.md)

    - [翻译: 综合解码：借助隐式自我一致性提升事实准确性](2024年10月02日/Integrative_Decoding_Improve_Factuality_via_Implicit_Self-consistency.md)

- [Intent Detection in the Age of LLMs](2024年10月02日/Intent_Detection_in_the_Age_of_LLMs.md)

    - [翻译: 在 LLM 时代，意图检测的新篇章](2024年10月02日/Intent_Detection_in_the_Age_of_LLMs.md)

- [Interpretable Contrastive Monte Carlo Tree Search Reasoning](2024年10月02日/Interpretable_Contrastive_Monte_Carlo_Tree_Search_Reasoning.md)

    - [翻译: 可解释对比蒙特卡洛树搜索推理](2024年10月02日/Interpretable_Contrastive_Monte_Carlo_Tree_Search_Reasoning.md)

- [Investigating on RLHF methodology](2024年10月02日/Investigating_on_RLHF_methodology.md)

    - [翻译: 探究 RLHF 方法论](2024年10月02日/Investigating_on_RLHF_methodology.md)

- [Knowledge-Driven Feature Selection and Engineering for Genotype Data with Large Language Models](2024年10月02日/Knowledge-Driven_Feature_Selection_and_Engineering_for_Genotype_Data_with_Large_Language_Models.md)

    - [翻译: 基于知识的特征选择与工程，应用于基因型数据，借助大型语言模型之力。](2024年10月02日/Knowledge-Driven_Feature_Selection_and_Engineering_for_Genotype_Data_with_Large_Language_Models.md)

- [Layer Swapping for Zero-Shot Cross-Lingual Transfer in Large Language Models](2024年10月02日/Layer_Swapping_for_Zero-Shot_Cross-Lingual_Transfer_in_Large_Language_Models.md)

    - [翻译: 大型语言模型中的零-shot 跨语言迁移：层交换策略](2024年10月02日/Layer_Swapping_for_Zero-Shot_Cross-Lingual_Transfer_in_Large_Language_Models.md)

- [LEOPARD : A Vision Language Model For Text-Rich Multi-Image Tasks](2024年10月02日/LEOPARD__A_Vision_Language_Model_For_Text-Rich_Multi-Image_Tasks.md)

    - [翻译: LEOPARD：一款专为文本密集型多图像任务设计的视觉语言模型](2024年10月02日/LEOPARD__A_Vision_Language_Model_For_Text-Rich_Multi-Image_Tasks.md)

- [Lines of Thought in Large Language Models](2024年10月02日/Lines_of_Thought_in_Large_Language_Models.md)

    - [翻译: 大型语言模型中的思维轨迹](2024年10月02日/Lines_of_Thought_in_Large_Language_Models.md)

- [LMOD: A Large Multimodal Ophthalmology Dataset and Benchmark for Large Vision-Language Models](2024年10月02日/LMOD_A_Large_Multimodal_Ophthalmology_Dataset_and_Benchmark_for_Large_Vision-Language_Models.md)

    - [翻译: LMOD：一个专为大型视觉-语言模型设计的大型多模态眼科数据集及基准](2024年10月02日/LMOD_A_Large_Multimodal_Ophthalmology_Dataset_and_Benchmark_for_Large_Vision-Language_Models.md)

- [Locret: Enhancing Eviction in Long-Context LLM Inference with Trained Retaining Heads](2024年10月02日/Locret_Enhancing_Eviction_in_Long-Context_LLM_Inference_with_Trained_Retaining_Heads.md)

    - [翻译: Locret：通过训练保留头，提升长上下文 LLM 推理中的驱逐效果](2024年10月02日/Locret_Enhancing_Eviction_in_Long-Context_LLM_Inference_with_Trained_Retaining_Heads.md)

- [MedQA-CS: Benchmarking Large Language Models Clinical Skills Using an AI-SCE Framework](2024年10月02日/MedQA-CS_Benchmarking_Large_Language_Models_Clinical_Skills_Using_an_AI-SCE_Framework.md)

    - [翻译: MedQA-CS：通过 AI-SCE 框架，评估大型语言模型在临床技能方面的表现。](2024年10月02日/MedQA-CS_Benchmarking_Large_Language_Models_Clinical_Skills_Using_an_AI-SCE_Framework.md)

- [Mind Scramble: Unveiling Large Language Model Psychology Via Typoglycemia](2024年10月02日/Mind_Scramble_Unveiling_Large_Language_Model_Psychology_Via_Typoglycemia.md)

    - [翻译: 《心灵迷宫：透过文字游戏揭示大型语言模型的心理奥秘》](2024年10月02日/Mind_Scramble_Unveiling_Large_Language_Model_Psychology_Via_Typoglycemia.md)

- [Mitigating Copy Bias in In-Context Learning through Neuron Pruning](2024年10月02日/Mitigating_Copy_Bias_in_In-Context_Learning_through_Neuron_Pruning.md)

    - [翻译: 通过神经元修剪技术，我们能够有效减轻上下文学习中的复制偏差问题。](2024年10月02日/Mitigating_Copy_Bias_in_In-Context_Learning_through_Neuron_Pruning.md)

- [Moral Alignment for LLM Agents](2024年10月02日/Moral_Alignment_for_LLM_Agents.md)

    - [翻译: LLM 代理的道德对齐](2024年10月02日/Moral_Alignment_for_LLM_Agents.md)

- [OCC-MLLM:Empowering Multimodal Large Language Model For the Understanding of Occluded Objects](2024年10月02日/OCC-MLLMEmpowering_Multimodal_Large_Language_Model_For_the_Understanding_of_Occluded_Objects.md)

    - [翻译: OCC-MLLM：助力多模态大型语言模型，提升对遮挡物体的理解能力](2024年10月02日/OCC-MLLMEmpowering_Multimodal_Large_Language_Model_For_the_Understanding_of_Occluded_Objects.md)

- [OmniGenBench: Automating Large-scale in-silico Benchmarking for Genomic Foundation Models](2024年10月02日/OmniGenBench_Automating_Large-scale_in-silico_Benchmarking_for_Genomic_Foundation_Models.md)

    - [翻译: OmniGenBench：基因组基础模型的大规模自动化体内基准测试](2024年10月02日/OmniGenBench_Automating_Large-scale_in-silico_Benchmarking_for_Genomic_Foundation_Models.md)

- [On The Adaptation of Unlimiformer for Decoder-Only Transformers](2024年10月02日/On_The_Adaptation_of_Unlimiformer_for_Decoder-Only_Transformers.md)

    - [翻译: 探讨 Unlimiformer 在仅解码器 Transformer 中的适应性](2024年10月02日/On_The_Adaptation_of_Unlimiformer_for_Decoder-Only_Transformers.md)

- [OpenMathInstruct-2: Accelerating AI for Math with Massive Open-Source Instruction Data](2024年10月02日/OpenMathInstruct-2_Accelerating_AI_for_Math_with_Massive_Open-Source_Instruction_Data.md)

    - [翻译: OpenMathInstruct-2：借助海量开源指令数据，加速数学 AI 的发展。](2024年10月02日/OpenMathInstruct-2_Accelerating_AI_for_Math_with_Massive_Open-Source_Instruction_Data.md)

- [Open-RAG: Enhanced Retrieval-Augmented Reasoning with Open-Source Large Language Models](2024年10月02日/Open-RAG_Enhanced_Retrieval-Augmented_Reasoning_with_Open-Source_Large_Language_Models.md)

    - [翻译: Open-RAG：利用开源大型语言模型提升检索增强推理能力](2024年10月02日/Open-RAG_Enhanced_Retrieval-Augmented_Reasoning_with_Open-Source_Large_Language_Models.md)

- [PersonaMath: Enhancing Math Reasoning through Persona-Driven Data Augmentation](2024年10月02日/PersonaMath_Enhancing_Math_Reasoning_through_Persona-Driven_Data_Augmentation.md)

    - [翻译: PersonaMath：借助角色驱动的数据增强提升数学推理能力](2024年10月02日/PersonaMath_Enhancing_Math_Reasoning_through_Persona-Driven_Data_Augmentation.md)

- [Quantifying Generalization Complexity for Large Language Models](2024年10月02日/Quantifying_Generalization_Complexity_for_Large_Language_Models.md)

    - [翻译: 探究大型语言模型的泛化复杂性](2024年10月02日/Quantifying_Generalization_Complexity_for_Large_Language_Models.md)

- [Question-guided Knowledge Graph Re-scoring and Injection for Knowledge Graph Question Answering](2024年10月02日/Question-guided_Knowledge_Graph_Re-scoring_and_Injection_for_Knowledge_Graph_Question_Answering.md)

    - [翻译: 问题引导的知识图谱重评与注入，助力知识图谱问答](2024年10月02日/Question-guided_Knowledge_Graph_Re-scoring_and_Injection_for_Knowledge_Graph_Question_Answering.md)

- [Recursive Abstractive Processing for Retrieval in Dynamic Datasets](2024年10月02日/Recursive_Abstractive_Processing_for_Retrieval_in_Dynamic_Datasets.md)

    - [翻译: 动态数据集中的递归抽象检索](2024年10月02日/Recursive_Abstractive_Processing_for_Retrieval_in_Dynamic_Datasets.md)

- [Revisiting the Index Construction of Proximity Graph-Based Approximate Nearest Neighbor Search](2024年10月02日/Revisiting_the_Index_Construction_of_Proximity_Graph-Based_Approximate_Nearest_Neighbor_Search.md)

    - [翻译: 重探基于邻近图的近似最近邻搜索索引构建](2024年10月02日/Revisiting_the_Index_Construction_of_Proximity_Graph-Based_Approximate_Nearest_Neighbor_Search.md)

- [RGD: Multi-LLM Based Agent Debugger via Refinement and Generation Guidance](2024年10月02日/RGD_Multi-LLM_Based_Agent_Debugger_via_Refinement_and_Generation_Guidance.md)

    - [翻译: RGD：基于多 LLM 的代理调试器，通过精炼与生成指导实现优化](2024年10月02日/RGD_Multi-LLM_Based_Agent_Debugger_via_Refinement_and_Generation_Guidance.md)

- [Saliency-Guided DETR for Moment Retrieval and Highlight Detection](2024年10月02日/Saliency-Guided_DETR_for_Moment_Retrieval_and_Highlight_Detection.md)

    - [翻译: 显著性引导的 DETR 技术，专为时刻检索和高光检测而生。](2024年10月02日/Saliency-Guided_DETR_for_Moment_Retrieval_and_Highlight_Detection.md)

- [Seeing Eye to AI: Human Alignment via Gaze-Based Response Rewards for Large Language Models](2024年10月02日/Seeing_Eye_to_AI_Human_Alignment_via_Gaze-Based_Response_Rewards_for_Large_Language_Models.md)

    - [翻译: 眼对AI：通过注视响应奖励实现大型语言模型的人类对齐](2024年10月02日/Seeing_Eye_to_AI_Human_Alignment_via_Gaze-Based_Response_Rewards_for_Large_Language_Models.md)

- [Sparse Autoencoders Reveal Temporal Difference Learning in Large Language Models](2024年10月02日/Sparse_Autoencoders_Reveal_Temporal_Difference_Learning_in_Large_Language_Models.md)

    - [翻译: 稀疏自编码器揭秘了大型语言模型中的时间差异学习机制。](2024年10月02日/Sparse_Autoencoders_Reveal_Temporal_Difference_Learning_in_Large_Language_Models.md)

- [Speculative Coreset Selection for Task-Specific Fine-tuning](2024年10月02日/Speculative_Coreset_Selection_for_Task-Specific_Fine-tuning.md)

    - [翻译: 任务特定微调中的推测性核心集选择](2024年10月02日/Speculative_Coreset_Selection_for_Task-Specific_Fine-tuning.md)

- [Spoken Grammar Assessment Using LLM](2024年10月02日/Spoken_Grammar_Assessment_Using_LLM.md)

    - [翻译: 利用 LLM 进行口语语法测评](2024年10月02日/Spoken_Grammar_Assessment_Using_LLM.md)

- [The Labyrinth of Links: Navigating the Associative Maze of Multi-modal LLMs](2024年10月02日/The_Labyrinth_of_Links_Navigating_the_Associative_Maze_of_Multi-modal_LLMs.md)

    - [翻译: 链接迷宫：探索多模态大型语言模型的关联网络](2024年10月02日/The_Labyrinth_of_Links_Navigating_the_Associative_Maze_of_Multi-modal_LLMs.md)

- [Toward a Holistic Evaluation of Robustness in CLIP Models](2024年10月02日/Toward_a_Holistic_Evaluation_of_Robustness_in_CLIP_Models.md)

    - [翻译: 探索 CLIP 模型鲁棒性的全面评估](2024年10月02日/Toward_a_Holistic_Evaluation_of_Robustness_in_CLIP_Models.md)

- [Towards a Theoretical Understanding of Synthetic Data in LLM Post-Training: A Reverse-Bottleneck Perspective](2024年10月02日/Towards_a_Theoretical_Understanding_of_Synthetic_Data_in_LLM_Post-Training_A_Reverse-Bottleneck_Perspective.md)

    - [翻译: 探索 LLM 后训练中合成数据的理论理解：反瓶颈视角](2024年10月02日/Towards_a_Theoretical_Understanding_of_Synthetic_Data_in_LLM_Post-Training_A_Reverse-Bottleneck_Perspective.md)

- [Trying to be human: Linguistic traces of stochastic empathy in language models](2024年10月02日/Trying_to_be_human_Linguistic_traces_of_stochastic_empathy_in_language_models.md)

    - [翻译: 语言模型中的人性化尝试：随机同理心的语言印记](2024年10月02日/Trying_to_be_human_Linguistic_traces_of_stochastic_empathy_in_language_models.md)

- [Upcycling Instruction Tuning from Dense to Mixture-of-Experts via Parameter Merging](2024年10月02日/Upcycling_Instruction_Tuning_from_Dense_to_Mixture-of-Experts_via_Parameter_Merging.md)

    - [翻译: 通过参数合并技术，将指令调优从密集模型升级为专家混合模型，实现模型性能的提升。](2024年10月02日/Upcycling_Instruction_Tuning_from_Dense_to_Mixture-of-Experts_via_Parameter_Merging.md)

- [U-shaped and Inverted-U Scaling behind Emergent Abilities of Large Language Models](2024年10月02日/U-shaped_and_Inverted-U_Scaling_behind_Emergent_Abilities_of_Large_Language_Models.md)

    - [翻译: 大型语言模型的涌现能力背后，U形和倒U形缩放起着关键作用。](2024年10月02日/U-shaped_and_Inverted-U_Scaling_behind_Emergent_Abilities_of_Large_Language_Models.md)

- [Verbalized Graph Representation Learning: A Fully Interpretable Graph Model Based on Large Language Models Throughout the Entire Process](2024年10月02日/Verbalized_Graph_Representation_Learning_A_Fully_Interpretable_Graph_Model_Based_on_Large_Language_Models_Throughout_the_Entire_Process.md)

    - [翻译: 语言化图表示学习：基于大型语言模型的全过程完全可解释图模型](2024年10月02日/Verbalized_Graph_Representation_Learning_A_Fully_Interpretable_Graph_Model_Based_on_Large_Language_Models_Throughout_the_Entire_Process.md)

- [VinePPO: Unlocking RL Potential For LLM Reasoning Through Refined Credit Assignment](2024年10月02日/VinePPO_Unlocking_RL_Potential_For_LLM_Reasoning_Through_Refined_Credit_Assignment.md)

    - [翻译: VinePPO：通过精细的信用分配，释放 LLM 推理中的强化学习潜力。](2024年10月02日/VinePPO_Unlocking_RL_Potential_For_LLM_Reasoning_Through_Refined_Credit_Assignment.md)

- [Visual Perception in Text Strings](2024年10月02日/Visual_Perception_in_Text_Strings.md)

    - [翻译: 文本中的视觉感知](2024年10月02日/Visual_Perception_in_Text_Strings.md)

- [VitaGlyph: Vitalizing Artistic Typography with Flexible Dual-branch Diffusion Models](2024年10月02日/VitaGlyph_Vitalizing_Artistic_Typography_with_Flexible_Dual-branch_Diffusion_Models.md)

    - [翻译: VitaGlyph：以灵活的双分支扩散模型赋予艺术字体生命力](2024年10月02日/VitaGlyph_Vitalizing_Artistic_Typography_with_Flexible_Dual-branch_Diffusion_Models.md)

- [When a language model is optimized for reasoning, does it still show embers of autoregression? An analysis of OpenAI o1](2024年10月02日/When_a_language_model_is_optimized_for_reasoning,_does_it_still_show_embers_of_autoregression_An_analysis_of_OpenAI_o1.md)

    - [翻译: 优化用于推理的语言模型，是否还保留着自回归的痕迹？本文将深入分析 OpenAI o1 的这一特性。](2024年10月02日/When_a_language_model_is_optimized_for_reasoning,_does_it_still_show_embers_of_autoregression_An_analysis_of_OpenAI_o1.md)

2024年10月01日

- [BordIRlines: A Dataset for Evaluating Cross-lingual Retrieval-Augmented Generation](2024年10月01日/BordIRlines_A_Dataset_for_Evaluating_Cross-lingual_Retrieval-Augmented_Generation.md)

    - [翻译: BordIRlines：一款专为跨语言检索增强生成评估而设计的数据集](2024年10月01日/BordIRlines_A_Dataset_for_Evaluating_Cross-lingual_Retrieval-Augmented_Generation.md)

- [From Code to Correctness: Closing the Last Mile of Code Generation with Hierarchical Debugging](2024年10月01日/From_Code_to_Correctness_Closing_the_Last_Mile_of_Code_Generation_with_Hierarchical_Debugging.md)

    - [翻译: 从代码到完美：借助分层调试，完成代码生成的最后一步](2024年10月01日/From_Code_to_Correctness_Closing_the_Last_Mile_of_Code_Generation_with_Hierarchical_Debugging.md)

- [From Facts to Insights: A Study on the Generation and Evaluation of Analytical Reports for Deciphering Earnings Calls](2024年10月01日/From_Facts_to_Insights_A_Study_on_the_Generation_and_Evaluation_of_Analytical_Reports_for_Deciphering_Earnings_Calls.md)

    - [翻译: 从数据到洞见：探索生成与评估财报电话会议分析报告的研究](2024年10月01日/From_Facts_to_Insights_A_Study_on_the_Generation_and_Evaluation_of_Analytical_Reports_for_Deciphering_Earnings_Calls.md)

- [StringLLM: Understanding the String Processing Capability of Large Language Models](2024年10月01日/StringLLM_Understanding_the_String_Processing_Capability_of_Large_Language_Models.md)

    - [翻译: StringLLM：探索大型语言模型在字符串处理方面的潜力](2024年10月01日/StringLLM_Understanding_the_String_Processing_Capability_of_Large_Language_Models.md)

- [UAL-Bench: The First Comprehensive Unusual Activity Localization Benchmark](2024年10月01日/UAL-Bench_The_First_Comprehensive_Unusual_Activity_Localization_Benchmark.md)

    - [翻译: UAL-Bench：首个全面异常活动定位基准](2024年10月01日/UAL-Bench_The_First_Comprehensive_Unusual_Activity_Localization_Benchmark.md)