# 关于语音大型语言模型的一项调查

发布时间：2024年10月24日

`LLM应用` `语音语言理解` `多模态`

> A Survey on Speech Large Language Models

# 摘要

> 大型语言模型（LLMs）展现出强大的上下文理解能力和卓越的多任务性能。因此，研究人员一直在寻求将 LLMs 整合到广义的口语语言理解（SLU）领域。与将 LLMs 级联以处理自动语音识别（ASR）生成的文本的传统方法不同，新的努力集中在设计以音频特征提取 - 多模态信息融合 - LLMs 推理（语音 LLMs）为中心的架构。这种方法能够实现更丰富的音频特征提取，同时促进音频和文本模态的端到端融合，从而从音频数据中实现更深入的理解和推理。本文阐明了语音 LLMs 的发展，对系统架构和训练策略进行了深入分析。通过广泛的研究和一系列有针对性的实验，本文评估了语音 LLMs 在丰富音频转录方面的进展及其在 SLU 领域内跨任务集成的潜力。此外，它指出了通过实验发现的关键挑战，例如 LLMs 在某些条件下的休眠。本文进一步深入研究了语音 LLMs 的训练策略，基于这些发现提出了潜在的解决方案，并为该领域的未来研究以及 LLMs 在多模态环境中的应用提供了有价值的见解和参考。

> Large Language Models (LLMs) exhibit strong contextual understanding and remarkable multi-task performance. Therefore, researchers have been seeking to integrate LLMs in the broad sense of Spoken Language Understanding (SLU) field. Different from the traditional method of cascading LLMs to process text generated by Automatic Speech Recognition(ASR), new efforts have focused on designing architectures centered around Audio Feature Extraction - Multimodal Information Fusion - LLM Inference(Speech LLMs). This approach enables richer audio feature extraction while simultaneously facilitating end-to-end fusion of audio and text modalities, thereby achieving deeper understanding and reasoning from audio data. This paper elucidates the development of Speech LLMs, offering an in-depth analysis of system architectures and training strategies. Through extensive research and a series of targeted experiments, the paper assesses Speech LLMs' advancements in Rich Audio Transcription and its potential for Cross-task Integration within the SLU field. Additionally, it indicates key challenges uncovered through experimentation, such as the Dormancy of LLMs under certain conditions. The paper further delves into the training strategies for Speech LLMs, proposing potential solutions based on these findings, and offering valuable insights and references for future research in this domain, as well as LLM applications in multimodal contexts.

[Arxiv](https://arxiv.org/abs/2410.18908)