# 在视觉基础模型时代实现理解与生成的统一：从自回归视角展开的一项调研

发布时间：2024年10月29日

`LLM应用`

> Towards Unifying Understanding and Generation in the Era of Vision Foundation Models: A Survey from the Autoregression Perspective

# 摘要

> 在大型语言模型（LLMs）中的自回归，通过将所有语言任务统一到下一个标记预测范式，展现出了惊人的可扩展性。近来，将此成功拓展至视觉基础模型的兴趣渐浓。在此次调研中，我们回顾了近期进展，并探讨了自回归视觉基础模型的未来走向。首先，呈现了下一代视觉基础模型的趋势，也就是统一视觉任务中的理解与生成。接着，剖析了现有视觉基础模型的局限，并给出自回归的正式定义及其优势。随后，从视觉标记器和自回归骨干方面对自回归视觉基础模型加以分类。最后，讨论了若干颇具前景的研究挑战与方向。据我们所知，这是在统一理解和生成的趋势下，首次对自回归视觉基础模型进行的全面总结。相关资源集合可于 https://github.com/EmmaSRH/ARVFM 获取。

> Autoregression in large language models (LLMs) has shown impressive scalability by unifying all language tasks into the next token prediction paradigm. Recently, there is a growing interest in extending this success to vision foundation models. In this survey, we review the recent advances and discuss future directions for autoregressive vision foundation models. First, we present the trend for next generation of vision foundation models, i.e., unifying both understanding and generation in vision tasks. We then analyze the limitations of existing vision foundation models, and present a formal definition of autoregression with its advantages. Later, we categorize autoregressive vision foundation models from their vision tokenizers and autoregression backbones. Finally, we discuss several promising research challenges and directions. To the best of our knowledge, this is the first survey to comprehensively summarize autoregressive vision foundation models under the trend of unifying understanding and generation. A collection of related resources is available at https://github.com/EmmaSRH/ARVFM.

[Arxiv](https://arxiv.org/abs/2410.22217)