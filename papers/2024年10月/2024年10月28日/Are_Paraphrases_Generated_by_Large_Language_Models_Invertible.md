# 大型语言模型所生成的释义是否具有可逆性？

发布时间：2024年10月28日

`LLM应用` `抄袭检测`

> Are Paraphrases Generated by Large Language Models Invertible?

# 摘要

> 大型语言模型能产出极为流畅的释义，且能保留大部分原义。虽说此能力有诸多有益用途，但也可能被不法分子滥用，比如抄袭内容或者隐匿身份。这促使我们思考释义反转的问题：给定一份释义后的文档，尝试找回原始文本。为探究此任务的可行性，我们对释义反转模型进行了微调，包括有无额外的作者特定上下文来辅助引导反转过程。我们探索了两种针对作者特定的反转方式：一种运用目标作者写作的上下文示例，另一种使用学到的风格表征来捕捉作者风格的独特特征。我们发现，从释义后的机器生成文本出发，能够用学到的反转模型恢复文档的很大一部分。从人类编写的文本出发时，源写作风格的多样性给可反转性带来了更大挑战。不过，即便无法恢复原始标记，我们也发现反转后的文本在风格上与原始文本相近，这大幅提升了依赖风格标记的抄袭检测和作者身份识别系统的性能。

> Large language models can produce highly fluent paraphrases while retaining much of the original meaning. While this capability has a variety of helpful applications, it may also be abused by bad actors, for example to plagiarize content or to conceal their identity. This motivates us to consider the problem of paraphrase inversion: given a paraphrased document, attempt to recover the original text. To explore the feasibility of this task, we fine-tune paraphrase inversion models, both with and without additional author-specific context to help guide the inversion process. We explore two approaches to author-specific inversion: one using in-context examples of the target author's writing, and another using learned style representations that capture distinctive features of the author's style. We show that, when starting from paraphrased machine-generated text, we can recover significant portions of the document using a learned inversion model. When starting from human-written text, the variety of source writing styles poses a greater challenge for invertability. However, even when the original tokens can't be recovered, we find the inverted text is stylistically similar to the original, which significantly improves the performance of plagiarism detectors and authorship identification systems that rely on stylistic markers.

[Arxiv](https://arxiv.org/abs/2410.21637)