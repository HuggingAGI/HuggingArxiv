# 大型语言模型辅助的语音和指向有助于在虚拟现实中进行多个 3D 对象的选择

发布时间：2024年10月28日

`LLM应用` `虚拟现实` `智能交互`

> Large Language Model-assisted Speech and Pointing Benefits Multiple 3D Object Selection in Virtual Reality

# 摘要

> 在虚拟现实中，选择被遮挡的对象是个难题，涉及多个对象时更是如此。随着新人工智能技术的问世，我们探索借助大型语言模型，通过多模态语音和光线投射交互技术来助力虚拟现实中的多对象选择任务。我们在一项有 24 名参与者的对比用户研究中验证了这一发现，参与者在不同场景复杂程度的虚拟现实场景中选择目标对象。将性能指标和用户体验指标与作为基准的基于小地图的被遮挡对象选择技术作比较。结果显示，当存在多个目标对象时，引入的 AssistVR 技术优于基准技术。与对语音接口的普遍看法相反，即便目标对象难以用言语描述，AssistVR 仍能胜过基准技术。此项工作展现了由大型语言模型驱动的智能多模态交互系统的可行性和交互潜能。基于这些结果，我们探讨了对沉浸式环境中未来智能多模态交互系统设计的启示。

> Selection of occluded objects is a challenging problem in virtual reality, even more so if multiple objects are involved. With the advent of new artificial intelligence technologies, we explore the possibility of leveraging large language models to assist multi-object selection tasks in virtual reality via a multimodal speech and raycast interaction technique. We validate the findings in a comparative user study (n=24), where participants selected target objects in a virtual reality scene with different levels of scene perplexity. The performance metrics and user experience metrics are compared against a mini-map based occluded object selection technique that serves as the baseline. Results indicate that the introduced technique, AssistVR, outperforms the baseline technique when there are multiple target objects. Contrary to the common belief for speech interfaces, AssistVR was able to outperform the baseline even when the target objects were difficult to reference verbally. This work demonstrates the viability and interaction potential of an intelligent multimodal interactive system powered by large laguage models. Based on the results, we discuss the implications for design of future intelligent multimodal interactive systems in immersive environments.

[Arxiv](https://arxiv.org/abs/2410.21091)