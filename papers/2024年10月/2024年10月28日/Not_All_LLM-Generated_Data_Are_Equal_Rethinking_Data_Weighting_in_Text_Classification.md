# 并非所有 LLM 生成的数据都一样：重新审视文本分类中的数据加权

发布时间：2024年10月28日

`LLM应用` `文本分类` `模型训练`

> Not All LLM-Generated Data Are Equal: Rethinking Data Weighting in Text Classification

# 摘要

> 借助大型语言模型（LLMs）实现的合成数据增强，能让研究人员利用更多训练数据，进而提升下游任务的性能，尤其在现实世界数据稀缺时。但生成的数据可能与现实世界的数据有偏差，这种错位在将训练好的模型应用时可能产生不佳结果。所以，我们提出了高效的加权损失方法，仅用少量现实世界数据，通过突出 LLMs 生成的高质量和多样化数据，让合成数据与现实世界的分布相契合。我们在多个文本分类任务上对该方法的有效性进行了实证评估，结果显示，在 BERT 级模型上运用我们的方法，显著优于标准交叉熵和其他数据加权方法，为有效利用任何合适的数据生成器的合成数据用于模型训练提供了可能的解决方案。

> Synthetic data augmentation via large language models (LLMs) allows researchers to leverage additional training data, thus enhancing the performance of downstream tasks, especially when real-world data is scarce. However, the generated data can deviate from the real-world data, and this misalignment can bring deficient outcomes while applying the trained model to applications. Therefore, we proposed efficient weighted-loss approaches to align synthetic data with real-world distribution by emphasizing high-quality and diversified data generated by LLMs with using merely a little real-world data. We empirically assessed the effectiveness of our method on multiple text classification tasks, and the results showed leveraging our approaches on a BERT-level model robustly outperformed standard cross-entropy and other data weighting approaches, providing potential solutions to effectively leveraging synthetic data from any suitable data generator for model training.

[Arxiv](https://arxiv.org/abs/2410.21526)