# 大型语言模型能否充当符号推理器？

发布时间：2024年10月28日

`LLM理论` `语言模型`

> Can Large Language Models Act as Symbolic Reasoners?

# 摘要

> 大型语言模型（LLMs）在众多领域的表现出色，然而却被诟病无法对自身的过程和所得结论进行推理。这既为解释所得结论，也为确定其方法的规划或策略。本文探究了当下有关符号推理与 LLMs 的研究，LLMs 能否天然具备某种推理形式，还是需要辅助组件。若存在推理能力的证据，这种能力是在特定领域显著，还是具有普遍性？另外，本文致力于明确 LLMs 可解释性的当前研究空白和未来走向，对相关文献予以回顾，确定当前针对此主题的研究，并给出未来工作的方向。

> The performance of Large language models (LLMs) across a broad range of domains has been impressive but have been critiqued as not being able to reason about their process and conclusions derived. This is to explain the conclusions draw, and also for determining a plan or strategy for their approach. This paper explores the current research in investigating symbolic reasoning and LLMs, and whether an LLM can inherently provide some form of reasoning or whether supporting components are necessary, and, if there is evidence for a reasoning capability, is this evident in a specific domain or is this a general capability? In addition, this paper aims to identify the current research gaps and future trends of LLM explainability, presenting a review of the literature, identifying current research into this topic and suggests areas for future work.

[Arxiv](https://arxiv.org/abs/2410.21490)