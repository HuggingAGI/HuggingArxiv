# SandboxAQ 向 MRL 2024 多语言多任务信息检索共享任务的提交内容

发布时间：2024年10月28日

`LLM应用` `多语言`

> SandboxAQ's submission to MRL 2024 Shared Task on Multi-lingual Multi-task Information Retrieval

# 摘要

> 这篇论文深入研究了五种不同语言中的问答（QA）和命名实体识别（NER）问题。我们运用包含零样本、思维链推理以及翻译技术等多种提示方法对五个大型语言模型进行了测试。结果显示，尽管某些模型一直表现更优，但它们在不同任务和语言中的效果差异明显。我们发现，先进的提示技术通常能提升 QA 性能，但对 NER 的效果有好有坏；同时还观察到，不同任务之间的语言难度模式存在差异。我们的研究成果凸显了多语言自然语言处理中针对特定任务采取专门方法的必要性，并表明当前模型针对不同任务可能形成了不同的语言能力。

> This paper explores the problems of Question Answering (QA) and Named Entity Recognition (NER) in five diverse languages. We tested five Large Language Models with various prompting methods, including zero-shot, chain-of-thought reasoning, and translation techniques. Our results show that while some models consistently outperform others, their effectiveness varies significantly across tasks and languages. We saw that advanced prompting techniques generally improved QA performance but had mixed results for NER; and we observed that language difficulty patterns differed between tasks. Our findings highlight the need for task-specific approaches in multilingual NLP and suggest that current models may develop different linguistic competencies for different tasks.

[Arxiv](https://arxiv.org/abs/2410.21501)