# 医疗任务中的大型语言模型基准

发布时间：2024年10月28日

`LLM应用` `人工智能`

> Large Language Model Benchmarks in Medical Tasks

# 摘要

> 随着大型语言模型（LLMs）在医疗领域的应用日益广泛，借助基准数据集来评估这些模型的性能变得极为关键。本文对医疗 LLM 任务中所运用的各类基准数据集展开了全面调研。这些数据集涵盖了多种模态，像文本、图像以及多模态基准等，聚焦于医疗知识的不同层面，例如电子健康记录（EHRs）、医患对话、医疗问答以及医学图像字幕。此次调研按照模态对数据集予以分类，探讨了它们的重要性、数据结构以及对诸如诊断、报告生成和预测决策支持等临床任务中 LLM 开发的影响。关键的基准有 MIMIC-III、MIMIC-IV、BioASQ、PubMedQA 和 CheXpert 等，它们推动了医疗报告生成、临床总结以及合成数据生成等任务的进步。本文归纳了利用这些基准推动多模态医疗智能所遭遇的挑战与机遇，着重指出需要具备更高语言多样性、结构化组学数据以及创新合成方式的数据集。此项工作还为未来 LLMs 在医学中的应用研究奠定了基础，为不断演进的医疗人工智能领域贡献了力量。

> With the increasing application of large language models (LLMs) in the medical domain, evaluating these models' performance using benchmark datasets has become crucial. This paper presents a comprehensive survey of various benchmark datasets employed in medical LLM tasks. These datasets span multiple modalities including text, image, and multimodal benchmarks, focusing on different aspects of medical knowledge such as electronic health records (EHRs), doctor-patient dialogues, medical question-answering, and medical image captioning. The survey categorizes the datasets by modality, discussing their significance, data structure, and impact on the development of LLMs for clinical tasks such as diagnosis, report generation, and predictive decision support. Key benchmarks include MIMIC-III, MIMIC-IV, BioASQ, PubMedQA, and CheXpert, which have facilitated advancements in tasks like medical report generation, clinical summarization, and synthetic data generation. The paper summarizes the challenges and opportunities in leveraging these benchmarks for advancing multimodal medical intelligence, emphasizing the need for datasets with a greater degree of language diversity, structured omics data, and innovative approaches to synthesis. This work also provides a foundation for future research in the application of LLMs in medicine, contributing to the evolving field of medical artificial intelligence.

[Arxiv](https://arxiv.org/abs/2410.21348)