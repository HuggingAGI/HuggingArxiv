# 赋予角色态度：掌控 LLM，实现数据标注的多样性

发布时间：2024年10月15日

`LLM应用` `数据标注`

> Personas with Attitudes: Controlling LLMs for Diverse Data Annotation

# 摘要

> 我们创新性地通过个性化 LLM 来提升数据标注的多样性与控制。通过两项研究，我们探究了角色描述对 LLM 提示的影响，发现角色确实能增加标注多样性，且个体角色的影响既一致又可控。实验结果显示，角色提示的 LLM 标注更为多样，且效果可控可重复，为提升主观 NLP 任务（如毒性检测）的数据标注质量提供了有力工具。

> We present a novel approach for enhancing diversity and control in data annotation tasks by personalizing large language models (LLMs). We investigate the impact of injecting diverse persona descriptions into LLM prompts across two studies, exploring whether personas increase annotation diversity and whether the impacts of individual personas on the resulting annotations are consistent and controllable. Our results show that persona-prompted LLMs produce more diverse annotations than LLMs prompted without personas and that these effects are both controllable and repeatable, making our approach a suitable tool for improving data annotation in subjective NLP tasks like toxicity detection.

[Arxiv](https://arxiv.org/abs/2410.11745)