# MCTBench：探索文本与视觉融合的多模态认知新基准

发布时间：2024年10月15日

`LLM应用` `人工智能` `计算机视觉`

> MCTBench: Multimodal Cognition towards Text-Rich Visual Scenes Benchmark

# 摘要

> 在多模态大型语言模型 (MLLM) 的评估中，文本丰富的视觉场景理解成为焦点。现有基准侧重感知能力，却忽视了认知能力的评估。为此，我们推出了 MCTBench，通过视觉推理和内容创建任务，全面评估 MLLM 的认知能力。为避免评估偏差，MCTBench 还包含感知任务，确保认知与感知能力的公平比较。我们采用自动评估流程，提升评估效率与公平性。MCTBench 的测试结果显示，尽管 MLLM 感知能力出色，认知能力仍有待提升。我们期待 MCTBench 成为社区探索和提升文本丰富视觉场景认知能力的有效工具。

> The comprehension of text-rich visual scenes has become a focal point for evaluating Multi-modal Large Language Models (MLLMs) due to their widespread applications. Current benchmarks tailored to the scenario emphasize perceptual capabilities, while overlooking the assessment of cognitive abilities. To address this limitation, we introduce a Multimodal benchmark towards Text-rich visual scenes, to evaluate the Cognitive capabilities of MLLMs through visual reasoning and content-creation tasks (MCTBench). To mitigate potential evaluation bias from the varying distributions of datasets, MCTBench incorporates several perception tasks (e.g., scene text recognition) to ensure a consistent comparison of both the cognitive and perceptual capabilities of MLLMs. To improve the efficiency and fairness of content-creation evaluation, we conduct an automatic evaluation pipeline. Evaluations of various MLLMs on MCTBench reveal that, despite their impressive perceptual capabilities, their cognition abilities require enhancement. We hope MCTBench will offer the community an efficient resource to explore and enhance cognitive capabilities towards text-rich visual scenes.

[Arxiv](https://arxiv.org/abs/2410.11538)