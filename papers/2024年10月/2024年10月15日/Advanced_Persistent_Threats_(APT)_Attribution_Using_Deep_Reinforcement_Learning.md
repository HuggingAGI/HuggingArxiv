# 利用深度强化学习技术，精准归因高级持续威胁（APT）

发布时间：2024年10月15日

`Agent` `网络安全` `人工智能`

> Advanced Persistent Threats (APT) Attribution Using Deep Reinforcement Learning

# 摘要

> 本文探讨了深度强化学习 (DRL) 在通过行为分析将恶意软件归因于特定高级持续威胁 (APT) 组中的应用。通过对 12 个 APT 组中的 3500 多个样本进行分析，研究利用 Cuckoo Sandbox 等工具提取行为数据，深入洞察恶意软件的操作模式。结果显示，DRL 模型在测试中以 89.27% 的准确率显著超越传统机器学习方法，展现出处理复杂恶意软件属性的强大能力。此外，文章还讨论了部署这些高级 AI 模型所需的计算资源和数据依赖性。未来研究将聚焦于提升 DRL 效率、扩展数据多样性、解决伦理问题，并利用大型语言模型 (LLM) 优化奖励机制和 DRL 框架。本研究强调了 DRL 在恶意软件归因中的变革潜力，倡导负责任和平衡的 AI 整合，以推动网络安全向更灵活、准确和强大的系统发展。

> This paper investigates the application of Deep Reinforcement Learning (DRL) for attributing malware to specific Advanced Persistent Threat (APT) groups through detailed behavioural analysis. By analysing over 3500 malware samples from 12 distinct APT groups, the study utilises sophisticated tools like Cuckoo Sandbox to extract behavioural data, providing a deep insight into the operational patterns of malware. The research demonstrates that the DRL model significantly outperforms traditional machine learning approaches such as SGD, SVC, KNN, MLP, and Decision Tree Classifiers, achieving an impressive test accuracy of 89.27 %. It highlights the model capability to adeptly manage complex, variable, and elusive malware attributes. Furthermore, the paper discusses the considerable computational resources and extensive data dependencies required for deploying these advanced AI models in cybersecurity frameworks. Future research is directed towards enhancing the efficiency of DRL models, expanding the diversity of the datasets, addressing ethical concerns, and leveraging Large Language Models (LLMs) to refine reward mechanisms and optimise the DRL framework. By showcasing the transformative potential of DRL in malware attribution, this research advocates for a responsible and balanced approach to AI integration, with the goal of advancing cybersecurity through more adaptable, accurate, and robust systems.

[Arxiv](https://arxiv.org/abs/2410.11463)