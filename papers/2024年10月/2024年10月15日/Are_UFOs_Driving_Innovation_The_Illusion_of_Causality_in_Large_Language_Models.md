# UFOs 能推动创新吗？大型语言模型中的因果错觉

发布时间：2024年10月15日

`LLM应用` `社会科学` `人工智能`

> Are UFOs Driving Innovation? The Illusion of Causality in Large Language Models

# 摘要

> 因果错觉源于人们对无证据支持的因果关系的错误信念，这种认知偏差是社会偏见、刻板印象、错误信息和迷信思维的根源。本研究探讨了大型语言模型在现实环境中是否会产生这种错觉。我们对比了 GPT-4o-Mini、Claude-3.5-Sonnet 和 Gemini-1.5-Pro 生成的新闻标题，发现这些模型有时会将相关性误认为因果关系。此外，我们还测试了模型是否会在迎合用户偏见时加剧这种错误，结果显示，Claude-3.5-Sonnet 在这方面表现最为稳健，尽管模仿谄媚行为会增加其他模型的错误倾向。

> Illusions of causality occur when people develop the belief that there is a causal connection between two variables with no supporting evidence. This cognitive bias has been proposed to underlie many societal problems including social prejudice, stereotype formation, misinformation and superstitious thinking. In this research we investigate whether large language models develop the illusion of causality in real-world settings. We evaluated and compared news headlines generated by GPT-4o-Mini, Claude-3.5-Sonnet, and Gemini-1.5-Pro to determine whether the models incorrectly framed correlations as causal relationships. In order to also measure sycophantic behavior, which occurs when a model aligns with a user's beliefs in order to look favorable even if it is not objectively correct, we additionally incorporated the bias into the prompts, observing if this manipulation increases the likelihood of the models exhibiting the illusion of causality. We found that Claude-3.5-Sonnet is the model that presents the lowest degree of causal illusion aligned with experiments on Correlation-to-Causation Exaggeration in human-written press releases. On the other hand, our findings suggest that while mimicry sycophancy increases the likelihood of causal illusions in these models, especially in GPT-4o-Mini, Claude-3.5-Sonnet remains the most robust against this cognitive bias.

[Arxiv](https://arxiv.org/abs/2410.11684)