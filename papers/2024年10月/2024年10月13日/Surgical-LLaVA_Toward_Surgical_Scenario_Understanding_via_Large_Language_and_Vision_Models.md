# Surgical-LLaVA：借助大型语言与视觉模型，迈向手术场景的深度理解

发布时间：2024年10月13日

`LLM应用` `人工智能`

> Surgical-LLaVA: Toward Surgical Scenario Understanding via Large Language and Vision Models

# 摘要

> 大型语言模型驱动的对话代理正在革新我们与视觉数据的互动方式。近期，大型视觉-语言模型（LVLMs）在图像和视频领域备受关注，但多聚焦于常见场景。为此，我们推出了一款专为手术场景设计的LVLM，将手术图像和视频的视觉信息融入语言特征空间，构建了Surgical-LLaVA模型，并在手术指令数据上进行微调。实验显示，Surgical-LLaVA在手术环境中展现出卓越的跨模态对话能力，甚至在未见指令上也能灵活应对。通过手术场景的视觉问答数据集评估，其性能超越以往，预示着该模型在复杂手术场景中的广阔应用前景。

> Conversation agents powered by large language models are revolutionizing the way we interact with visual data. Recently, large vision-language models (LVLMs) have been extensively studied for both images and videos. However, these studies typically focus on common scenarios. In this work, we introduce an LVLM specifically designed for surgical scenarios. We integrate visual representations of surgical images and videos into the language feature space. Consequently, we establish a LVLM model, Surgical-LLaVA, fine-tuned on instruction following data of surgical scenarios. Our experiments demonstrate that Surgical-LLaVA exhibits impressive multi-modal chat abilities in surgical contexts, occasionally displaying multi-modal behaviors on unseen instructions. We conduct a quantitative evaluation of visual question-answering datasets for surgical scenarios. The results show superior performance compared to previous works, indicating the potential of our model to tackle more complex surgery scenarios.

[Arxiv](https://arxiv.org/abs/2410.09750)