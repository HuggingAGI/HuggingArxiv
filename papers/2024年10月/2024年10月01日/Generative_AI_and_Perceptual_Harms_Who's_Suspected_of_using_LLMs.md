# 生成式 AI 与感知伤害：谁在使用 LLM 上受到质疑？

发布时间：2024年10月01日

`LLM应用` `人力资源`

> Generative AI and Perceptual Harms: Who's Suspected of using LLMs?

# 摘要

> 大型语言模型 (LLM) 正广泛应用于写作任务，虽然能激发创意、提升作品质量，但也可能带来风险，尤其对历史上被边缘化的群体造成不公。我们提出了“感知伤害”这一概念，即他人怀疑或察觉用户使用 AI 时对用户造成的伤害。通过三个在线实验，我们让参与者评估虚构自由撰稿人的资料，询问他们是否怀疑使用 AI、写作质量及是否应被雇佣。结果显示，某些群体更易受感知伤害影响，而怀疑 AI 使用则普遍降低了写作评价和雇佣机会。

> Large language models (LLMs) are increasingly integrated into a variety of writing tasks. While these tools can help people by generating ideas or producing higher quality work, like many other AI tools they may risk causing a variety of harms, disproportionately burdening historically marginalized groups. In this work, we introduce and evaluate perceptual harm, a term for the harm caused to users when others perceive or suspect them of using AI. We examined perceptual harms in three online experiments, each of which entailed human participants evaluating the profiles for fictional freelance writers. We asked participants whether they suspected the freelancers of using AI, the quality of their writing, and whether they should be hired. We found some support for perceptual harms against for certain demographic groups, but that perceptions of AI use negatively impacted writing evaluations and hiring outcomes across the board.

[Arxiv](https://arxiv.org/abs/2410.00906)