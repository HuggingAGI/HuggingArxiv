# 突破差分隐私的界限：通过语言模型提示实现文本隐私化的案例研究

发布时间：2024年10月01日

`LLM理论` `隐私保护`

> Thinking Outside of the Differential Privacy Box: A Case Study in Text Privatization with Language Model Prompting

# 摘要

> 随着大型语言模型的普及，隐私保护自然语言处理领域备受关注。近期研究中，差分隐私 (DP) 被频繁引入 NLP 技术。本文深入探讨了 DP 整合的限制及其带来的挑战，特别关注了 $\textbf{DP-Prompt}$ 这一利用语言模型重写文本的隐私化方法。我们在多种场景下对比了 DP 与非 DP 的效果，并通过实证实验展示了 DP 在 NLP 中的潜力与局限。结果表明，DP 在 NLP 中的应用仍需更多探讨，以充分发挥其优势。

> The field of privacy-preserving Natural Language Processing has risen in popularity, particularly at a time when concerns about privacy grow with the proliferation of Large Language Models. One solution consistently appearing in recent literature has been the integration of Differential Privacy (DP) into NLP techniques. In this paper, we take these approaches into critical view, discussing the restrictions that DP integration imposes, as well as bring to light the challenges that such restrictions entail. To accomplish this, we focus on $\textbf{DP-Prompt}$, a recent method for text privatization leveraging language models to rewrite texts. In particular, we explore this rewriting task in multiple scenarios, both with DP and without DP. To drive the discussion on the merits of DP in NLP, we conduct empirical utility and privacy experiments. Our results demonstrate the need for more discussion on the usability of DP in NLP and its benefits over non-DP approaches.

[Arxiv](https://arxiv.org/abs/2410.00751)