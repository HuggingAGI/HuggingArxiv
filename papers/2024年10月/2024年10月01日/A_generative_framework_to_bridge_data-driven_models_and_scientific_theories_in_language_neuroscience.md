# 一个生成框架，旨在融合语言神经科学中的数据驱动模型与科学理论

发布时间：2024年10月01日

`LLM理论` `神经科学` `人工智能`

> A generative framework to bridge data-driven models and scientific theories in language neuroscience

# 摘要

> 大型语言模型在预测语言刺激的 BOLD fMRI 响应方面表现出色，但其内部机制仍如黑匣子般神秘。我们提出了一种名为“生成解释中介验证”的框架，旨在揭示大脑对语言选择性的简明解释，并通过后续实验验证这些解释。该方法不仅成功解释了个别体素的选择性，还涵盖了重要的皮质区域。研究发现，解释的准确性与基础模型的预测能力和稳定性紧密相连。这些成果表明，LLM 有能力弥合数据驱动模型与科学理论之间的鸿沟。

> Representations from large language models are highly effective at predicting BOLD fMRI responses to language stimuli. However, these representations are largely opaque: it is unclear what features of the language stimulus drive the response in each brain area. We present generative explanation-mediated validation, a framework for generating concise explanations of language selectivity in the brain and then validating those explanations in follow-up experiments that use synthetic stimuli. This approach is successful at explaining selectivity both in individual voxels and cortical regions of interest (ROIs).We show that explanatory accuracy is closely related to the predictive power and stability of the underlying statistical models. These results demonstrate that LLMs can be used to bridge the widening gap between data-driven models and formal scientific theories.

[Arxiv](https://arxiv.org/abs/2410.00812)