# CROPE：探索视觉与语言模型如何适应特定文化概念的上下文学习

发布时间：2024年10月20日

`LLM应用` `文化研究` `人工智能`

> CROPE: Evaluating In-Context Adaptation of Vision and Language Models to Culture-Specific Concepts

# 摘要

> 随着 VLMs 的普及，它们展示文化知识变得至关重要。本文介绍的 CROPE 基准，通过视觉问答测试模型对文化特定概念的理解和上下文适应能力。这有助于区分训练中获取的参数化知识与推理时提供的上下文信息。评估显示，最先进的 VLMs 在处理文化特定与常见概念时性能差异显著。实验还表明，模型在整合多模态信息和文化概念方面存在困难。这些发现揭示了当前 VLMs 在文化理解和适应性上的不足，呼吁构建更具包容性的模型。

> As Vision and Language models (VLMs) become accessible across the globe, it is important that they demonstrate cultural knowledge. In this paper, we introduce CROPE, a visual question answering benchmark designed to probe the knowledge of culture-specific concepts and evaluate the capacity for cultural adaptation through contextual information. This allows us to distinguish between parametric knowledge acquired during training and contextual knowledge provided during inference via visual and textual descriptions. Our evaluation of several state-of-the-art open VLMs shows large performance disparities between culture-specific and common concepts in the parametric setting. Moreover, experiments with contextual knowledge indicate that models struggle to effectively utilize multimodal information and bind culture-specific concepts to their depictions. Our findings reveal limitations in the cultural understanding and adaptability of current VLMs that need to be addressed toward more culturally inclusive models.

[Arxiv](https://arxiv.org/abs/2410.15453)