# CROPE：探索视觉与语言模型如何适应特定文化概念的上下文表现

发布时间：2024年10月20日

`LLM应用` `人工智能`

> CROPE: Evaluating In-Context Adaptation of Vision and Language Models to Culture-Specific Concepts

# 摘要

> 随着 VLMs 在全球普及，展示文化知识变得至关重要。本文推出的 CROPE 基准，通过视觉问答测试模型对文化特定概念的理解及上下文中的文化适应能力。这有助于区分训练中获取的参数知识与推理时提供的上下文知识。评估显示，最先进的 VLMs 在处理文化特定与常见概念时性能差异显著。实验还表明，模型在整合多模态信息及绑定文化概念方面存在困难。这些发现揭示了当前 VLMs 在文化理解和适应性上的不足，呼吁构建更具文化包容性的模型。

> As Vision and Language models (VLMs) become accessible across the globe, it is important that they demonstrate cultural knowledge. In this paper, we introduce CROPE, a visual question answering benchmark designed to probe the knowledge of culture-specific concepts and evaluate the capacity for cultural adaptation through contextual information. This allows us to distinguish between parametric knowledge acquired during training and contextual knowledge provided during inference via visual and textual descriptions. Our evaluation of several state-of-the-art open VLMs shows large performance disparities between culture-specific and common concepts in the parametric setting. Moreover, experiments with contextual knowledge indicate that models struggle to effectively utilize multimodal information and bind culture-specific concepts to their depictions. Our findings reveal limitations in the cultural understanding and adaptability of current VLMs that need to be addressed toward more culturally inclusive models.

[Arxiv](https://arxiv.org/abs/2410.15453)