# 在基于大型语言模型的代码漏洞定位中，注意力机制是关键。

发布时间：2024年10月20日

`LLM应用` `软件开发` `网络安全`

> Attention Is All You Need for LLM-based Code Vulnerability Localization

# 摘要

> 随着软件系统的迅速扩展和漏洞数量的增加，准确识别易受攻击的代码段变得尤为重要。传统方法如手动审计或基于规则的工具，虽耗时且局限，但近年来，GPT 和 LLaMA 等大型语言模型 (LLM) 的引入为自动化漏洞检测带来了新希望。然而，LLM 在长代码上下文中的准确性仍面临挑战。本文提出的 LOVA 框架，利用 LLM 的自注意力机制，通过跟踪模型对特定代码行的关注度，显著提升了漏洞定位的精度。实验表明，LOVA 在 F1 分数上比现有方法提升了 5.3 倍，且在多种编程语言的智能合约漏洞定位中，性能提升了 14.6 倍。LOVA 不仅高效，还展现了跨不同 LLM 架构的稳定性能。

> The rapid expansion of software systems and the growing number of reported vulnerabilities have emphasized the importance of accurately identifying vulnerable code segments. Traditional methods for vulnerability localization, such as manual code audits or rule-based tools, are often time-consuming and limited in scope, typically focusing on specific programming languages or types of vulnerabilities. In recent years, the introduction of large language models (LLMs) such as GPT and LLaMA has opened new possibilities for automating vulnerability detection. However, while LLMs show promise in this area, they face challenges, particularly in maintaining accuracy over longer code contexts. This paper introduces LOVA, a novel framework leveraging the self-attention mechanisms inherent in LLMs to enhance vulnerability localization. Our key insight is that self-attention mechanisms assign varying importance to different parts of the input, making it possible to track how much attention the model focuses on specific lines of code. In the context of vulnerability localization, the hypothesis is that vulnerable lines of code will naturally attract higher attention weights because they have a greater influence on the model's output. By systematically tracking changes in attention weights and focusing on specific lines of code, LOVA improves the precision of identifying vulnerable lines across various programming languages. Through rigorous experimentation and evaluation, we demonstrate that LOVA significantly outperforms existing LLM-based approaches, achieving up to a 5.3x improvement in F1-scores. LOVA also demonstrated strong scalability, with up to a 14.6x improvement in smart contract vulnerability localization across languages like C, Python, Java, and Solidity. Its robustness was proven through consistent performance across different LLM architectures.

[Arxiv](https://arxiv.org/abs/2410.15288)