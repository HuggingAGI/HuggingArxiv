# RealMind：运用多模态模型实现基于零样本脑电图的视觉解码与字幕生成

发布时间：2024年10月31日

`其他` `脑机接口`

> RealMind: Zero-Shot EEG-Based Visual Decoding and Captioning Using Multi-Modal Models

# 摘要

> 尽管 fMRI 数据在视觉解码方面成果显著，但其成本高昂、时间分辨率低，限制了广泛应用。为应对这些难题，我们推出了 RealMind，这是一个新颖的基于 EEG 的视觉解码框架，借助多模态模型高效解读语义信息。通过融合语义和几何一致性学习，RealMind 强化了特征对齐，提升了解码表现。我们的框架在 200 路检索任务中达成 56.73％的 Top-5 准确率，在 200 路视觉字幕任务中斩获 26.59％的 BLEU-1 分数，这是首次利用 EEG 数据成功实现零样本视觉字幕。RealMind 为基于 fMRI 的方法提供了强劲、适配且经济的替代选择，为实际应用中基于 EEG 的视觉解码带来了可扩展的解决方案。

> Despite significant progress in visual decoding with fMRI data, its high cost and low temporal resolution limit widespread applicability. To address these challenges, we introduce RealMind, a novel EEG-based visual decoding framework that leverages multi-modal models to efficiently interpret semantic information. By integrating semantic and geometric consistency learning, RealMind enhances feature alignment, leading to improved decoding performance. Our framework achieves a 56.73\% Top-5 accuracy in a 200-way retrieval task and a 26.59\% BLEU-1 score in a 200-way visual captioning task, representing the first successful attempt at zero-shot visual captioning using EEG data. RealMind provides a robust, adaptable, and cost-effective alternative to fMRI-based methods, offering scalable solutions for EEG-based visual decoding in practical applications.

[Arxiv](https://arxiv.org/abs/2410.23754)