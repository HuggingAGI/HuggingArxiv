# 《隐藏的说服者：LLM 的政治倾向及其对选民的影响》

发布时间：2024年10月31日

`LLM应用`

> Hidden Persuaders: LLMs' Political Leaning and Their Influence on Voters

# 摘要

> 摘要：LLMs 会怎样影响我们的民主？我们在美国总统选举的情境下开展多次实验，来探究 LLMs 的政治倾向以及其对选民的潜在影响。通过投票模拟，我们首先呈现了 18 个开放和封闭权重的 LLMs 对民主党候选人相较于共和党候选人的政治偏好。通过分析它们对候选人政策相关问题的回应，我们表明在指令调整模型中，这种对民主党候选人的倾向相较于基础版本更为显著。我们对 935 名美国注册选民进行实验，进一步探索了 LLMs 对选民选择的潜在作用。实验中，参与者与 LLMs（Claude-3、Llama-3 和 GPT-4）进行了五次交流。实验结果显示，与 LLMs 互动后，选民选择倾向于民主党候选人，投票差距从 0.7%扩大至 4.6%，即便在交流过程中 LLMs 未被要求说服用户支持民主党候选人。这一影响比许多先前关于政治竞选说服力的研究都要大，那些研究在总统选举中效果甚微。许多用户还表示希望与 LLMs 有更多的政治互动。究竟是 LLM 互动的哪些方面导致了选民选择的这些变化，尚需进一步研究。最后，我们探讨了一种安全方法如何让 LLMs 在政治上更中立，同时也提出了这种中立是否真的是正确方向的问题。

> 
Abstract:How could LLMs influence our democracy? We investigate LLMs' political leanings and the potential influence of LLMs on voters by conducting multiple experiments in a U.S. presidential election context. Through a voting simulation, we first demonstrate 18 open- and closed-weight LLMs' political preference for a Democratic nominee over a Republican nominee. We show how this leaning towards the Democratic nominee becomes more pronounced in instruction-tuned models compared to their base versions by analyzing their responses to candidate-policy related questions. We further explore the potential impact of LLMs on voter choice by conducting an experiment with 935 U.S. registered voters. During the experiments, participants interacted with LLMs (Claude-3, Llama-3, and GPT-4) over five exchanges. The experiment results show a shift in voter choices towards the Democratic nominee following LLM interaction, widening the voting margin from 0.7% to 4.6%, even though LLMs were not asked to persuade users to support the Democratic nominee during the discourse. This effect is larger than many previous studies on the persuasiveness of political campaigns, which have shown minimal effects in presidential elections. Many users also expressed a desire for further political interaction with LLMs. Which aspects of LLM interactions drove these shifts in voter choice requires further study. Lastly, we explore how a safety method can make LLMs more politically neutral, while raising the question of whether such neutrality is truly the path forward.
    

[Arxiv](https://arxiv.org/pdf/2410.24190)