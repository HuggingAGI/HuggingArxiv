# 大型语言模型写作是否接近人类？探讨其语法和修辞风格的变化。

发布时间：2024年10月21日

`LLM理论` `人工智能`

> Do LLMs write like humans? Variation in grammatical and rhetorical styles

# 摘要

> 大型语言模型（LLM）不仅能编写符合语法的文本，还能遵循指令、回答问题和解决问题。然而，随着其发展，区分其输出与人类文本变得愈发困难。尽管以往研究在词汇选择和标点等表面特征上发现了一些差异，并开发了分类器来检测LLM输出，但对其修辞风格的研究仍属空白。  我们利用Llama 3和GPT-4o的多个变体，构建了人类与LLM文本的平行语料库。通过Douglas Biber的词汇、语法和修辞特征集，我们发现了LLM与人类以及不同LLM之间的系统性差异。这些差异在模型规模扩大时依然存在，且在指令调整模型中更为显著。这表明，尽管LLM能力强大，但在风格上仍难以与人类匹敌，因此更高级的语言特征能揭示其行为中未被识别的模式。

> Large language models (LLMs) are capable of writing grammatical text that follows instructions, answers questions, and solves problems. As they have advanced, it has become difficult to distinguish their output from human-written text. While past research has found some differences in surface features such as word choice and punctuation, and developed classifiers to detect LLM output, none has studied the rhetorical styles of LLMs.
  Using several variants of Llama 3 and GPT-4o, we construct two parallel corpora of human- and LLM-written texts from common prompts. Using Douglas Biber's set of lexical, grammatical, and rhetorical features, we identify systematic differences between LLMs and humans and between different LLMs. These differences persist when moving from smaller models to larger ones, and are larger for instruction-tuned models than base models. This demonstrates that despite their advanced abilities, LLMs struggle to match human styles, and hence more advanced linguistic features can detect patterns in their behavior not previously recognized.

[Arxiv](https://arxiv.org/abs/2410.16107)