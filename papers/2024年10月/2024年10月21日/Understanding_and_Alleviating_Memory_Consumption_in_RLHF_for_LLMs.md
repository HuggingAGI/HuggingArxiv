# 探究并减轻 RLHF 在大型语言模型中的内存负担

发布时间：2024年10月21日

`LLM理论` `人工智能` `机器学习`

> Understanding and Alleviating Memory Consumption in RLHF for LLMs

# 摘要

> RLHF 微调对于对齐 LLM 至关重要，但常面临内存挑战。本研究首次探索 RLHF 中的内存使用，揭示了过度消耗的原因，并提出了一种简单有效的策略，显著降低了微调所需的内存。

> Fine-tuning with Reinforcement Learning with Human Feedback (RLHF) is essential for aligning large language models (LLMs). However, RLHF often encounters significant memory challenges. This study is the first to examine memory usage in the RLHF context, exploring various memory management strategies and unveiling the reasons behind excessive memory consumption. Additionally, we introduce a simple yet effective approach that substantially reduces the memory required for RLHF fine-tuning.

[Arxiv](https://arxiv.org/abs/2410.15651)