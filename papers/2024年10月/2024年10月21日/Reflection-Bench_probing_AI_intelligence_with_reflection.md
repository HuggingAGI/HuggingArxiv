# Reflection-Bench：用反思来探寻 AI 的智慧

发布时间：2024年10月21日

`LLM理论` `人工智能` `认知科学`

> Reflection-Bench: probing AI intelligence with reflection

# 摘要

> 反思能力，即智能系统根据意外结果调整信念或行为的能力，是其与世界互动的基础。从认知科学视角看，这是智能的核心原则，适用于人类和AI。为解决LLM智能性的争议，我们推出了Reflection-Bench，一个包含7项任务的综合基准，涵盖感知、记忆、信念更新等关键认知功能。我们评估了13个知名LLM，如OpenAI o1、GPT-4等，发现它们仍缺乏满意的反思能力。我们探讨了原因，并提出未来研究方向。Reflection-Bench不仅提供评估工具，还启发AI开发，使其能可靠地与环境互动。数据和代码见https://github.com/YabYum/ReflectionBench。

> The ability to adapt beliefs or behaviors in response to unexpected outcomes, reflection, is fundamental to intelligent systems' interaction with the world. From a cognitive science perspective, this serves as a core principle of intelligence applicable to both human and AI systems. To address the debate on the intelligence of large language models (LLMs), we propose Reflection-Bench, a comprehensive benchmark comprising 7 tasks spanning core cognitive functions crucial for reflection, including perception, memory, belief updating, decision-making, prediction, counterfactual thinking, and meta-reflection. We evaluate the performances of 13 prominent LLMs such as OpenAI o1, GPT-4, Claude 3.5 Sonnet, etc. The results indicate that current LLMs still lack satisfactory reflection ability. We discuss the underlying causes of these results and suggest potential avenues for future research. In conclusion, Reflection-Bench offers both evaluation tools and inspiration for developing AI capable of reliably interacting with the environment. Our data and code are available at https://github.com/YabYum/ReflectionBench.

[Arxiv](https://arxiv.org/abs/2410.16270)