# 大型语言模型虽能言善道，却不知何时该开口。

发布时间：2024年10月21日

`LLM应用` `人工智能` `对话系统`

> Large Language Models Know What To Say But Not When To Speak

# 摘要

> 轮流发言是确保人类交流流畅连贯的关键。随着大型语言模型 (LLM) 的进步，我们看到了提升口语对话系统 (SDS) 轮流发言能力的希望，比如在适当时间回应。然而，现有模型在预测自然对话中的发言机会（即过渡相关位置 TRP）时表现不佳，尤其是回合内的 TRP。为此，我们创建了一个新的回合内 TRP 数据集，并测试了最先进 LLM 的表现。实验结果显示，LLM 在处理非脚本对话时仍有不足，这为未来更自然的对话系统提供了改进方向。

> Turn-taking is a fundamental mechanism in human communication that ensures smooth and coherent verbal interactions. Recent advances in Large Language Models (LLMs) have motivated their use in improving the turn-taking capabilities of Spoken Dialogue Systems (SDS), such as their ability to respond at appropriate times. However, existing models often struggle to predict opportunities for speaking -- called Transition Relevance Places (TRPs) -- in natural, unscripted conversations, focusing only on turn-final TRPs and not within-turn TRPs. To address these limitations, we introduce a novel dataset of participant-labeled within-turn TRPs and use it to evaluate the performance of state-of-the-art LLMs in predicting opportunities for speaking. Our experiments reveal the current limitations of LLMs in modeling unscripted spoken interactions, highlighting areas for improvement and paving the way for more naturalistic dialogue systems.

[Arxiv](https://arxiv.org/abs/2410.16044)