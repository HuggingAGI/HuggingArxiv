# 以学生为中心，而非专家主导，这款新型 AI 教育工具旨在打造更贴近人性、更具个性化的青春期早期教育体验。

发布时间：2024年10月21日

`Agent` `人工智能`

> Students Rather Than Experts: A New AI For Education Pipeline To Model More Human-Like And Personalised Early Adolescences

# 摘要

> 大型语言模型 (LLM) 在教育领域的应用为 AI 带来了新机遇。当前研究主要利用 LLM 模拟教师，以提升学生学习效果。然而，模拟学生以改进教学技能的研究却因建模和评估的挑战而受限。本研究探讨了 LLM 能否开发出模拟人类行为和个体差异的虚拟学生代理。与专注于知识传递的系统不同，虚拟学生需展现学习困难、情感反应和语言不确定性，这为建模和评估带来了挑战。为此，我们以语言学习为背景，提出了 SOE (场景-对象-评估) 框架，系统构建 LVSA。通过个性化互动数据集和 LoRA 微调 LLM，我们进行了多维评估实验，包括：(1) 生成 LVSA 的理论框架；(2) 整合人类主观评估与 GPT-4，展示其与人类评估者的高相关性；(3) 验证 LLM 在教育背景下生成个性化虚拟学生代理的能力，为未来教师培训和多代理模拟环境应用奠定基础。

> The capabilities of large language models (LLMs) have been applied in expert systems across various domains, providing new opportunities for AI in Education. Educational interactions involve a cyclical exchange between teachers and students. Current research predominantly focuses on using LLMs to simulate teachers, leveraging their expertise to enhance student learning outcomes. However, the simulation of students, which could improve teachers' instructional skills, has received insufficient attention due to the challenges of modeling and evaluating virtual students. This research asks: Can LLMs be utilized to develop virtual student agents that mimic human-like behavior and individual variability? Unlike expert systems focusing on knowledge delivery, virtual students must replicate learning difficulties, emotional responses, and linguistic uncertainties. These traits present significant challenges in both modeling and evaluation. To address these issues, this study focuses on language learning as a context for modeling virtual student agents. We propose a novel AI4Education framework, called SOE (Scene-Object-Evaluation), to systematically construct LVSA (LLM-based Virtual Student Agents). By curating a dataset of personalized teacher-student interactions with various personality traits, question types, and learning stages, and fine-tuning LLMs using LoRA, we conduct multi-dimensional evaluation experiments. Specifically, we: (1) develop a theoretical framework for generating LVSA; (2) integrate human subjective evaluation metrics into GPT-4 assessments, demonstrating a strong correlation between human evaluators and GPT-4 in judging LVSA authenticity; and (3) validate that LLMs can generate human-like, personalized virtual student agents in educational contexts, laying a foundation for future applications in pre-service teacher training and multi-agent simulation environments.

[Arxiv](https://arxiv.org/abs/2410.15701)