# 话语守护者：评估 LLM 在多语言冒犯性语言检测中的能力

发布时间：2024年10月21日

`LLM应用` `社交媒体` `语言检测`

> Guardians of Discourse: Evaluating LLMs on Multilingual Offensive Language Detection

# 摘要

> 在社交媒体时代，识别冒犯性语言对于维护安全和可持续性至关重要。尽管 LLM 在社交媒体分析中表现出色，但在多语言环境下的冒犯性语言检测方面仍需深入评估。我们首次在英语、西班牙语和德语中，通过 GPT-3.5、Flan-T5 和 Mistral 三种模型，评估了 LLM 的多语言冒犯性语言检测能力。我们还探讨了不同提示语言和增强翻译数据对非英语环境中任务的影响，并深入分析了 LLM 和数据集中的固有偏见对敏感话题错误预测的影响。

> Identifying offensive language is essential for maintaining safety and sustainability in the social media era. Though large language models (LLMs) have demonstrated encouraging potential in social media analytics, they lack thorough evaluation when in offensive language detection, particularly in multilingual environments. We for the first time evaluate multilingual offensive language detection of LLMs in three languages: English, Spanish, and German with three LLMs, GPT-3.5, Flan-T5, and Mistral, in both monolingual and multilingual settings. We further examine the impact of different prompt languages and augmented translation data for the task in non-English contexts. Furthermore, we discuss the impact of the inherent bias in LLMs and the datasets in the mispredictions related to sensitive topics.

[Arxiv](https://arxiv.org/abs/2410.15623)