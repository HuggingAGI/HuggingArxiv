# 惊喜！统一信息密度并非全部：探索长篇话语中的意外变化

发布时间：2024年10月21日

`LLM理论` `语言学`

> Surprise! Uniform Information Density Isn't the Whole Story: Predicting Surprisal Contours in Long-form Discourse

# 摘要

> UID 假设认为，说话者会均匀分布信息以实现高效沟通。然而，文本和话语中的信息速率并非完全均匀。除了将其视为噪音外，另一种解释是 UID 并非唯一调节信息内容的压力。说话者还需保持兴趣、遵守写作惯例并构建有力论点。本文提出一种新压力：说话者根据话语的分层结构调节信息速率，即结构化上下文假设。我们通过预测大型语言模型中自然话语的意外轮廓来测试这一假设，发现分层预测因子对信息轮廓有显著影响，且深度嵌套的预测因子更具预测性。这项研究迈出了超越 UID 的第一步，提出了可测试的假设，解释了信息速率的波动原因。

> The Uniform Information Density (UID) hypothesis posits that speakers tend to distribute information evenly across linguistic units to achieve efficient communication. Of course, information rate in texts and discourses is not perfectly uniform. While these fluctuations can be viewed as theoretically uninteresting noise on top of a uniform target, another explanation is that UID is not the only functional pressure regulating information content in a language. Speakers may also seek to maintain interest, adhere to writing conventions, and build compelling arguments. In this paper, we propose one such functional pressure; namely that speakers modulate information rate based on location within a hierarchically-structured model of discourse. We term this the Structured Context Hypothesis and test it by predicting the surprisal contours of naturally occurring discourses extracted from large language models using predictors derived from discourse structure. We find that hierarchical predictors are significant predictors of a discourse's information contour and that deeply nested hierarchical predictors are more predictive than shallow ones. This work takes an initial step beyond UID to propose testable hypotheses for why the information rate fluctuates in predictable ways

[Arxiv](https://arxiv.org/abs/2410.16062)