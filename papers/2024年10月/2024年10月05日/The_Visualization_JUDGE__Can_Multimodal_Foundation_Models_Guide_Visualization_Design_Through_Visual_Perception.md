# 多模态基础模型能否借助视觉感知，引领可视化设计的方向？

发布时间：2024年10月05日

`LLM应用` `数据可视化` `人工智能`

> The Visualization JUDGE : Can Multimodal Foundation Models Guide Visualization Design Through Visual Perception?

# 摘要

> 视觉与语言的基础模型是AI在社会各领域应用的基石。这些模型的成功在于它们能够模仿人类的视觉感知与分析推理能力。在数据可视化领域，视觉感知与分析尤为关键。本文探讨了如何利用基础模型推动可视化设计的进步，特别是多模态基础模型（MFMs）如何通过视觉感知指导设计。我们深入研究了MFMs在感知可视化方面的效能，并探讨了如何优化可视化设计。我们认为，MFMs如同评判者，能批评并指导可视化的改进。通过详细分析文本到图像生成模型与多模态大语言模型，我们展示了如何利用这些模型的输出进行设计决策。希望我们的见解能激发可视化研究者更有效地利用MFMs。

> Foundation models for vision and language are the basis of AI applications across numerous sectors of society. The success of these models stems from their ability to mimic human capabilities, namely visual perception in vision models, and analytical reasoning in large language models. As visual perception and analysis are fundamental to data visualization, in this position paper we ask: how can we harness foundation models to advance progress in visualization design? Specifically, how can multimodal foundation models (MFMs) guide visualization design through visual perception? We approach these questions by investigating the effectiveness of MFMs for perceiving visualization, and formalizing the overall visualization design and optimization space. Specifically, we think that MFMs can best be viewed as judges, equipped with the ability to criticize visualizations, and provide us with actions on how to improve a visualization. We provide a deeper characterization for text-to-image generative models, and multi-modal large language models, organized by what these models provide as output, and how to utilize the output for guiding design decisions. We hope that our perspective can inspire researchers in visualization on how to approach MFMs for visualization design.

[Arxiv](https://arxiv.org/abs/2410.04280)