# 多模态基础模型能否借助视觉感知，引领可视化设计的方向？

发布时间：2024年10月05日

`LLM应用` `数据可视化` `人工智能`

> The Visualization JUDGE : Can Multimodal Foundation Models Guide Visualization Design Through Visual Perception?

# 摘要

> 视觉与语言的基础模型是AI在社会各领域应用的基石。这些模型的成功在于它们能够模仿人类的视觉感知与分析推理能力。在数据可视化领域，视觉感知与分析尤为关键。因此，我们在此探讨：如何借助基础模型推动可视化设计的进步？特别是，多模态基础模型（MFMs）如何通过视觉感知来指导设计？我们通过研究MFMs在感知可视化方面的效能，并规范整体设计与优化空间来解答这些问题。我们认为，MFMs如同评委，能对可视化进行批评并提出改进建议。我们还深入剖析了文本到图像生成模型及多模态大语言模型，按其输出及如何用于指导设计决策进行分类。我们期待这一视角能激发可视化研究者对MFMs的探索与应用。

> Foundation models for vision and language are the basis of AI applications across numerous sectors of society. The success of these models stems from their ability to mimic human capabilities, namely visual perception in vision models, and analytical reasoning in large language models. As visual perception and analysis are fundamental to data visualization, in this position paper we ask: how can we harness foundation models to advance progress in visualization design? Specifically, how can multimodal foundation models (MFMs) guide visualization design through visual perception? We approach these questions by investigating the effectiveness of MFMs for perceiving visualization, and formalizing the overall visualization design and optimization space. Specifically, we think that MFMs can best be viewed as judges, equipped with the ability to criticize visualizations, and provide us with actions on how to improve a visualization. We provide a deeper characterization for text-to-image generative models, and multi-modal large language models, organized by what these models provide as output, and how to utilize the output for guiding design decisions. We hope that our perspective can inspire researchers in visualization on how to approach MFMs for visualization design.

[Arxiv](https://arxiv.org/abs/2410.04280)