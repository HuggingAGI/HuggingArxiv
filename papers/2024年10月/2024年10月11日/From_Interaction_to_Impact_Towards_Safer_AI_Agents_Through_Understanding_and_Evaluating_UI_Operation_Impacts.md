# 从互动到影响力：通过深入理解与评估用户界面操作的影响，我们致力于打造更安全的 AI 代理。

发布时间：2024年10月11日

`Agent` `人工智能` `用户体验`

> From Interaction to Impact: Towards Safer AI Agents Through Understanding and Evaluating UI Operation Impacts

# 摘要

> 随着生成式 AI 的发展，越来越多的研究致力于打造能够通过操作用户界面（UI）来处理日常任务的自主代理。尽管已有研究探讨了 AI 代理如何导航和理解 UI 结构，但关于这些代理及其自主行动（尤其是那些可能带来风险或不可逆后果的行动）的影响，仍有许多未知。在本研究中，我们深入探讨了 AI 代理 UI 行动的实际影响与后果。首先，我们与领域专家合作，通过一系列研讨会，构建了 UI 行动影响的分类体系。接着，我们进行数据综合研究，收集了用户认为具有重要影响的 UI 操作轨迹和数据。随后，我们利用这些影响类别，对收集的数据以及从现有 UI 导航数据集中提取的数据进行了注释。通过定量评估不同的大型语言模型（LLM）及其变体，我们展示了这些模型在理解 AI 代理可能采取的 UI 行动影响方面的能力。结果显示，我们的分类体系显著提升了这些 LLM 的推理能力，使其能更好地理解 UI 行动的影响。然而，研究也揭示了这些模型在处理更复杂、更微妙的影响类别时仍存在显著不足。

> With advances in generative AI, there is increasing work towards creating autonomous agents that can manage daily tasks by operating user interfaces (UIs). While prior research has studied the mechanics of how AI agents might navigate UIs and understand UI structure, the effects of agents and their autonomous actions-particularly those that may be risky or irreversible-remain under-explored. In this work, we investigate the real-world impacts and consequences of UI actions by AI agents. We began by developing a taxonomy of the impacts of UI actions through a series of workshops with domain experts. Following this, we conducted a data synthesis study to gather realistic UI screen traces and action data that users perceive as impactful. We then used our impact categories to annotate our collected data and data repurposed from existing UI navigation datasets. Our quantitative evaluations of different large language models (LLMs) and variants demonstrate how well different LLMs can understand the impacts of UI actions that might be taken by an agent. We show that our taxonomy enhances the reasoning capabilities of these LLMs for understanding the impacts of UI actions, but our findings also reveal significant gaps in their ability to reliably classify more nuanced or complex categories of impact.

[Arxiv](https://arxiv.org/abs/2410.09006)