# 图与多模态的邂逅：多模态属性图学习的基准测试

发布时间：2024年10月11日

`其他` `社交网络`

> When Graph meets Multimodal: Benchmarking on Multimodal Attributed Graphs Learning

# 摘要

> 多模态属性图 (MAGs) 广泛应用于现实世界，包含两种知识：一是节点（实体）自身的多模态属性，如文本和图像；二是节点间的复杂交互。MAG 表示学习的关键在于多模态属性与拓扑的无缝结合。预训练模型和图神经网络的进步推动了 MAGs 的有效学习，但缺乏基准数据集和标准化评估程序限制了发展。为此，我们推出了多模态属性图基准 (MAGB)，涵盖从电商到社交网络的广泛领域。我们还进行了多种学习范式的基准实验，以验证多模态属性与图拓扑结合的必要性。项目详情请访问 https://github.com/sktsherlock/ATG。

> Multimodal attributed graphs (MAGs) are prevalent in various real-world scenarios and generally contain two kinds of knowledge: (a) Attribute knowledge is mainly supported by the attributes of different modalities contained in nodes (entities) themselves, such as texts and images. (b) Topology knowledge, on the other hand, is provided by the complex interactions posed between nodes. The cornerstone of MAG representation learning lies in the seamless integration of multimodal attributes and topology. Recent advancements in Pre-trained Language/Vision models (PLMs/PVMs) and Graph neural networks (GNNs) have facilitated effective learning on MAGs, garnering increased research interest. However, the absence of meaningful benchmark datasets and standardized evaluation procedures for MAG representation learning has impeded progress in this field. In this paper, we propose Multimodal Attribute Graph Benchmark (MAGB)}, a comprehensive and diverse collection of challenging benchmark datasets for MAGs. The MAGB datasets are notably large in scale and encompass a wide range of domains, spanning from e-commerce networks to social networks. In addition to the brand-new datasets, we conduct extensive benchmark experiments over MAGB with various learning paradigms, ranging from GNN-based and PLM-based methods, to explore the necessity and feasibility of integrating multimodal attributes and graph topology. In a nutshell, we provide an overview of the MAG datasets, standardized evaluation procedures, and present baseline experiments. The entire MAGB project is publicly accessible at https://github.com/sktsherlock/ATG.

[Arxiv](https://arxiv.org/abs/2410.09132)