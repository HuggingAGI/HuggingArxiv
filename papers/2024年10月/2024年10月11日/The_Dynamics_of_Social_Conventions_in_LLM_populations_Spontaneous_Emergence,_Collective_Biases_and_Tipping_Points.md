# LLM 群体中的社会规范动态：自发涌现、集体偏见与临界点

发布时间：2024年10月11日

`Agent` `人工智能` `社会科学`

> The Dynamics of Social Conventions in LLM populations: Spontaneous Emergence, Collective Biases and Tipping Points

# 摘要

> 社会规范是社会与经济生活的基石。随着 AI 代理与人类及彼此间的互动日益频繁，它们能否形成共享规范，将直接影响其协调行为、融入社会及施加影响的能力。我们通过模拟交互，探究了大型语言模型（LLM）代理群体中规范的演变。首先，我们发现全球共识的社会规范可从 LLM 间的局部交流中自然涌现。其次，即便个体代理看似无偏，此过程中仍可能形成强烈的集体偏见。再者，我们观察到，坚定的 LLM 少数派能通过创立新规范推动社会变革，一旦达到临界规模，便能稳固地改变既有行为。通过对比实验与最小多代理模型的预测，我们得以明确 LLM 的独特作用。研究揭示了 AI 系统如何在无明确编程下自主生成规范，为设计符合人类价值与社会目标的 AI 系统提供了启示。

> Social conventions are the foundation for social and economic life. As legions of AI agents increasingly interact with each other and with humans, their ability to form shared conventions will determine how effectively they will coordinate behaviors, integrate into society and influence it. Here, we investigate the dynamics of conventions within populations of Large Language Model (LLM) agents using simulated interactions. First, we show that globally accepted social conventions can spontaneously arise from local interactions between communicating LLMs. Second, we demonstrate how strong collective biases can emerge during this process, even when individual agents appear to be unbiased. Third, we examine how minority groups of committed LLMs can drive social change by establishing new social conventions. We show that once these minority groups reach a critical size, they can consistently overturn established behaviors. In all cases, contrasting the experimental results with predictions from a minimal multi-agent model allows us to isolate the specific role of LLM agents. Our results clarify how AI systems can autonomously develop norms without explicit programming and have implications for designing AI systems that align with human values and societal goals.

[Arxiv](https://arxiv.org/abs/2410.08948)