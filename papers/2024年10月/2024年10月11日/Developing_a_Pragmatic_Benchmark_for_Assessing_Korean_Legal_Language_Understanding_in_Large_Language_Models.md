# 打造实用基准，评估大型语言模型对韩语法律语言的理解

发布时间：2024年10月11日

`LLM应用` `人工智能`

> Developing a Pragmatic Benchmark for Assessing Korean Legal Language Understanding in Large Language Models

# 摘要

> LLM 在法律领域表现出色，GPT-4 甚至通过了美国律师考试。然而，在非标准化和非英语任务中，其效果有限。因此，在应用前需对各法律系统的 LLM 进行细致评估。我们推出了 KBL 基准，用于评估 LLM 的韩语法律理解能力，涵盖 7 项法律知识任务、4 项法律推理任务及韩国律师考试。这些数据集与律师紧密合作开发，确保实际应用中的有效性。此外，鉴于法律从业者常使用大量法律文件，我们分别在封闭书籍和检索增强生成设置中评估 LLM。结果显示，LLM 仍有显著提升空间。

> Large language models (LLMs) have demonstrated remarkable performance in the legal domain, with GPT-4 even passing the Uniform Bar Exam in the U.S. However their efficacy remains limited for non-standardized tasks and tasks in languages other than English. This underscores the need for careful evaluation of LLMs within each legal system before application. Here, we introduce KBL, a benchmark for assessing the Korean legal language understanding of LLMs, consisting of (1) 7 legal knowledge tasks (510 examples), (2) 4 legal reasoning tasks (288 examples), and (3) the Korean bar exam (4 domains, 53 tasks, 2,510 examples). First two datasets were developed in close collaboration with lawyers to evaluate LLMs in practical scenarios in a certified manner. Furthermore, considering legal practitioners' frequent use of extensive legal documents for research, we assess LLMs in both a closed book setting, where they rely solely on internal knowledge, and a retrieval-augmented generation (RAG) setting, using a corpus of Korean statutes and precedents. The results indicate substantial room and opportunities for improvement.

[Arxiv](https://arxiv.org/abs/2410.08731)