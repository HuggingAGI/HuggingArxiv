# 语言模型与第二意见的应用案例：袖珍专业人士

发布时间：2024年10月27日

`LLM应用`

> Language Models And A Second Opinion Use Case: The Pocket Professional

# 摘要

> 这项研究对大型语言模型（LLMs）在专业决策中充当正式第二意见工具的作用进行了测试，重点聚焦于即便经验丰富的医生也会寻求同行会诊的复杂医疗案例。该研究在20个月内分析了来自Medscape的183个棘手医疗案例，将多个LLMs的表现与众包医生的回应进行了对比。关键发现之一是最新的基础模型可能获得的高分（与共识意见相比准确率>80%），这超过了相同临床案例中所报告的多数人类指标（450页患者资料、测试结果）。研究评估了LLMs在简单案例（准确率>81%）和复杂场景（准确率43%）中的性能差异，尤其是在这些引发人类医生大量争论的案例中。研究表明，LLMs或许能作为全面的鉴别诊断生成器发挥价值，而非主要诊断工具，有可能助力对抗临床决策中的认知偏差，减轻认知负荷，从而消除部分医疗差错的源头。纳入第二个比较法律数据集（最高法院案例，N=21）为AI用于促进第二意见提供了更多经验背景，不过这些法律难题对于LLMs而言分析起来要容易得多。除了为LLMs准确性提供实证依据的原创贡献外，该研究还汇总了一个新基准，以供他人对LLMs和存在分歧的人类从业者之间极具争议的问答可靠性进行评分。这些结果表明，LLMs在专业场景中的最优部署可能与当前着重常规任务自动化的方法大相径庭。

> This research tests the role of Large Language Models (LLMs) as formal second opinion tools in professional decision-making, particularly focusing on complex medical cases where even experienced physicians seek peer consultation. The work analyzed 183 challenging medical cases from Medscape over a 20-month period, testing multiple LLMs' performance against crowd-sourced physician responses. A key finding was the high overall score possible in the latest foundational models (>80% accuracy compared to consensus opinion), which exceeds most human metrics reported on the same clinical cases (450 pages of patient profiles, test results). The study rates the LLMs' performance disparity between straightforward cases (>81% accuracy) and complex scenarios (43% accuracy), particularly in these cases generating substantial debate among human physicians. The research demonstrates that LLMs may be valuable as generators of comprehensive differential diagnoses rather than as primary diagnostic tools, potentially helping to counter cognitive biases in clinical decision-making, reduce cognitive loads, and thus remove some sources of medical error. The inclusion of a second comparative legal dataset (Supreme Court cases, N=21) provides added empirical context to the AI use to foster second opinions, though these legal challenges proved considerably easier for LLMs to analyze. In addition to the original contributions of empirical evidence for LLM accuracy, the research aggregated a novel benchmark for others to score highly contested question and answer reliability between both LLMs and disagreeing human practitioners. These results suggest that the optimal deployment of LLMs in professional settings may differ substantially from current approaches that emphasize automation of routine tasks.

[Arxiv](https://arxiv.org/abs/2410.20636)