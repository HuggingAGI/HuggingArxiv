# 朝着基于 LLM 的机器人辅助喂食语音界面迈进

发布时间：2024年10月27日

`LLM应用` `机器人` `辅助医疗`

> Towards an LLM-Based Speech Interface for Robot-Assisted Feeding

# 摘要

> 物理辅助机器人为那些因运动障碍或其他残疾而无法完成日常生活活动的人显著提升幸福感和独立性带来了契机。特别是利用大型语言模型（LLMs）的语音接口，能让个人有效地、自然地向机器人传达高级指令和细微的偏好。在这项工作中，我们为一款市售的辅助喂食机器人展示了基于 LLM 的语音接口。我们的系统基于从论文《VoicePilot：将 LLMs 用作物理辅助机器人的语音接口》中迭代设计的框架，该框架融入了以人为本的元素，以将 LLMs 整合为机器人的接口。它已通过在一个独立生活设施中对 11 位老年人开展的用户研究得到评估。相关视频可在我们的项目网站获取：https://sites.google.com/andrew.cmu.edu/voicepilot/。

> Physically assistive robots present an opportunity to significantly increase the well-being and independence of individuals with motor impairments or other forms of disability who are unable to complete activities of daily living (ADLs). Speech interfaces, especially ones that utilize Large Language Models (LLMs), can enable individuals to effectively and naturally communicate high-level commands and nuanced preferences to robots. In this work, we demonstrate an LLM-based speech interface for a commercially available assistive feeding robot. Our system is based on an iteratively designed framework, from the paper "VoicePilot: Harnessing LLMs as Speech Interfaces for Physically Assistive Robots," that incorporates human-centric elements for integrating LLMs as interfaces for robots. It has been evaluated through a user study with 11 older adults at an independent living facility. Videos are located on our project website: https://sites.google.com/andrew.cmu.edu/voicepilot/.

[Arxiv](https://arxiv.org/abs/2410.20624)