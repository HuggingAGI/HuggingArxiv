# 多模态基础模型：从专业领域专家到全能助手

发布时间：2023年09月18日

`RAG

理由：这篇论文主要探讨了多模态基础模型的分类与演化，特别关注了从专业模型向通用助手转变的过程。其中提到的“多模态大型语言模型的端到端训练”以及“与大型语言模型结合的多模态工具链”等内容，与RAG（Retrieval-Augmented Generation）模型的概念相契合，即通过结合检索和生成技术来增强模型的性能和应用范围。因此，这篇论文更适合归类于RAG。` `计算机视觉` `人工智能`

> Multimodal Foundation Models: From Specialists to General-Purpose Assistants

# 摘要

> 本文深入探讨了多模态基础模型的分类与演化，特别关注了从专业模型向通用助手转变的过程。研究内容分为两大类，共五个核心议题。首先，我们回顾了成熟领域的研究，包括为特定任务预训练的多模态模型，涉及视觉理解的视觉骨干学习方法和文本到图像生成技术。其次，我们探讨了新兴领域的进展，这些模型旨在成为通用助手，包括受大型语言模型启发的一体化视觉模型、多模态大型语言模型的端到端训练，以及与大型语言模型结合的多模态工具链。本文旨在为计算机视觉和视觉-语言多模态领域的研究者、学生和专业人士提供多模态基础模型的基础知识及最新研究动态。

> This paper presents a comprehensive survey of the taxonomy and evolution of multimodal foundation models that demonstrate vision and vision-language capabilities, focusing on the transition from specialist models to general-purpose assistants. The research landscape encompasses five core topics, categorized into two classes. (i) We start with a survey of well-established research areas: multimodal foundation models pre-trained for specific purposes, including two topics -- methods of learning vision backbones for visual understanding and text-to-image generation. (ii) Then, we present recent advances in exploratory, open research areas: multimodal foundation models that aim to play the role of general-purpose assistants, including three topics -- unified vision models inspired by large language models (LLMs), end-to-end training of multimodal LLMs, and chaining multimodal tools with LLMs. The target audiences of the paper are researchers, graduate students, and professionals in computer vision and vision-language multimodal communities who are eager to learn the basics and recent advances in multimodal foundation models.

[Arxiv](https://arxiv.org/abs/2309.10020)