# 智能电网中基于物联网的机器学习方法脆弱性分析：一次全面回顾

发布时间：2023年12月24日

`Agent

理由：这篇论文主要关注的是机器学习在智能电网中的应用，特别是在面对对抗性攻击时的安全性和脆弱性问题。虽然提到了大型语言模型（如ChatGPT）在电力系统应用中的潜在风险，但论文的核心内容是关于机器学习代理（Agent）在智能电网中的应用和安全性评估，而不是专注于大型语言模型的理论或应用。因此，将其归类为Agent更为合适。` `智能电网` `物联网`

> Vulnerability of Machine Learning Approaches Applied in IoT-based Smart Grid: A Review

# 摘要

> 机器学习（ML）在基于物联网的智能电网中日益普及，但其可信度问题亟待解决，以适应基于ML的智能电网应用（MLsgAPPs）的发展趋势。电力信号中注入的对抗性畸变严重威胁系统正常运行，因此，对安全关键电力系统中的MLsgAPPs进行漏洞评估刻不容缓。本文首次聚焦电力系统特性，全面回顾了MLsgAPPs攻击与防御方法的最新进展。我们首先详述了针对MLsgAPPs的对抗性攻击构建方法，随后从电力系统和ML模型两方面剖析了MLsgAPP的脆弱性。接着，我们综述了在发电、输电、配电及消费场景中针对MLsgAPPs的对抗性攻击研究，并根据防御的攻击类型探讨了相应对策。最后，我们分别从攻击者和防御者的视角展望了未来研究方向，并分析了基于大型语言模型（如ChatGPT）的电力系统应用的潜在风险。我们呼吁更多研究者关注并解决MLsgAPPs的对抗性问题。

> Machine learning (ML) sees an increasing prevalence of being used in the internet-of-things (IoT)-based smart grid. However, the trustworthiness of ML is a severe issue that must be addressed to accommodate the trend of ML-based smart grid applications (MLsgAPPs). The adversarial distortion injected into the power signal will greatly affect the system's normal control and operation. Therefore, it is imperative to conduct vulnerability assessment for MLsgAPPs applied in the context of safety-critical power systems. In this paper, we provide a comprehensive review of the recent progress in designing attack and defense methods for MLsgAPPs. Unlike the traditional survey about ML security, this is the first review work about the security of MLsgAPPs that focuses on the characteristics of power systems. We first highlight the specifics for constructing the adversarial attacks on MLsgAPPs. Then, the vulnerability of MLsgAPP is analyzed from both the aspects of the power system and ML model. Afterward, a comprehensive survey is conducted to review and compare existing studies about the adversarial attacks on MLsgAPPs in scenarios of generation, transmission, distribution, and consumption, and the countermeasures are reviewed according to the attacks that they defend against. Finally, the future research directions are discussed on the attacker's and defender's side, respectively. We also analyze the potential vulnerability of large language model-based (e.g., ChatGPT) power system applications. Overall, we encourage more researchers to contribute to investigating the adversarial issues of MLsgAPPs.

[Arxiv](https://arxiv.org/abs/2308.15736)