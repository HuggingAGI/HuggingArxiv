# 智能电网中基于物联网的机器学习方法脆弱性综述

发布时间：2023年12月24日

`Agent

理由：这篇论文主要关注的是机器学习在智能电网中的应用，特别是在安全关键电力系统中MLsgAPPs的攻击与防御方法。虽然提到了大型语言模型（如ChatGPT）在电力系统应用中的潜在风险，但论文的核心是讨论机器学习代理在智能电网环境中的安全性和脆弱性，以及对抗性攻击和防御策略。因此，它更符合Agent分类，即关注机器学习模型作为智能代理在特定环境（如智能电网）中的应用和挑战。` `智能电网` `电力系统安全`

> Vulnerability of Machine Learning Approaches Applied in IoT-based Smart Grid: A Review

# 摘要

> 机器学习（ML）在智能电网中的应用日益增多，但ML的可信度问题亟待解决，以适应基于ML的智能电网应用（MLsgAPPs）的发展趋势。电力信号中的对抗性干扰严重威胁系统正常运行。因此，对MLsgAPPs在安全关键电力系统中的应用进行漏洞评估刻不容缓。本文首次聚焦电力系统特性，全面回顾了MLsgAPPs攻击与防御方法的最新进展。我们首先揭示了针对MLsgAPPs的对抗性攻击构建细节，随后从电力系统和ML模型两方面剖析了其脆弱性。接着，我们综述了在发电、输电、配电及消费场景中MLsgAPPs面临的对抗性攻击，并根据防御的攻击类型探讨了相应对策。最后，我们分别从攻击者和防御者的视角展望了未来研究方向，并分析了基于大型语言模型（如ChatGPT）的电力系统应用的潜在风险。我们呼吁更多研究者关注并解决MLsgAPPs的对抗性问题。

> Machine learning (ML) sees an increasing prevalence of being used in the internet-of-things (IoT)-based smart grid. However, the trustworthiness of ML is a severe issue that must be addressed to accommodate the trend of ML-based smart grid applications (MLsgAPPs). The adversarial distortion injected into the power signal will greatly affect the system's normal control and operation. Therefore, it is imperative to conduct vulnerability assessment for MLsgAPPs applied in the context of safety-critical power systems. In this paper, we provide a comprehensive review of the recent progress in designing attack and defense methods for MLsgAPPs. Unlike the traditional survey about ML security, this is the first review work about the security of MLsgAPPs that focuses on the characteristics of power systems. We first highlight the specifics for constructing the adversarial attacks on MLsgAPPs. Then, the vulnerability of MLsgAPP is analyzed from both the aspects of the power system and ML model. Afterward, a comprehensive survey is conducted to review and compare existing studies about the adversarial attacks on MLsgAPPs in scenarios of generation, transmission, distribution, and consumption, and the countermeasures are reviewed according to the attacks that they defend against. Finally, the future research directions are discussed on the attacker's and defender's side, respectively. We also analyze the potential vulnerability of large language model-based (e.g., ChatGPT) power system applications. Overall, we encourage more researchers to contribute to investigating the adversarial issues of MLsgAPPs.

[Arxiv](https://arxiv.org/abs/2308.15736)