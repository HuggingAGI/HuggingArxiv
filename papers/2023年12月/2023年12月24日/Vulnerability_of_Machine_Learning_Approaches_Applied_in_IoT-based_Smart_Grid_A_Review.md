# 智能电网中物联网应用的机器学习方法脆弱性综述

发布时间：2023年12月24日

`Agent

理由：这篇论文主要关注的是机器学习在智能电网中的应用，特别是在安全关键电力系统中对抗性攻击与防御的问题。虽然提到了大型语言模型（如ChatGPT）在电力系统应用中的潜在风险，但这并不是论文的核心内容。论文的主要焦点在于评估和解决基于ML的智能电网应用（MLsgAPPs）的安全漏洞，这更符合Agent分类，因为它涉及到了智能系统（Agent）在特定环境（智能电网）中的行为和安全性问题。` `智能电网` `物联网`

> Vulnerability of Machine Learning Approaches Applied in IoT-based Smart Grid: A Review

# 摘要

> 机器学习（ML）在基于物联网的智能电网中日益普及，但其可信度问题亟待解决，以适应基于ML的智能电网应用（MLsgAPPs）的发展趋势。电力信号中的对抗性畸变严重威胁系统正常运行，因此，对MLsgAPPs在安全关键电力系统中的应用进行漏洞评估刻不容缓。本文首次聚焦电力系统特性，全面回顾了针对MLsgAPPs的攻击与防御方法的最新进展。我们首先详述了构建MLsgAPPs对抗性攻击的要点，接着从电力系统与ML模型两方面剖析了MLsgAPP的脆弱性。随后，我们对比分析了在发电、输电、配电及消费场景中针对MLsgAPPs的对抗性攻击研究，并根据防御的攻击类型探讨了相应对策。最后，我们分别从攻击者与防御者的视角展望了未来研究方向，并探讨了基于大型语言模型（如ChatGPT）的电力系统应用的潜在风险。我们呼吁更多研究者关注并解决MLsgAPPs的对抗性问题。

> Machine learning (ML) sees an increasing prevalence of being used in the internet-of-things (IoT)-based smart grid. However, the trustworthiness of ML is a severe issue that must be addressed to accommodate the trend of ML-based smart grid applications (MLsgAPPs). The adversarial distortion injected into the power signal will greatly affect the system's normal control and operation. Therefore, it is imperative to conduct vulnerability assessment for MLsgAPPs applied in the context of safety-critical power systems. In this paper, we provide a comprehensive review of the recent progress in designing attack and defense methods for MLsgAPPs. Unlike the traditional survey about ML security, this is the first review work about the security of MLsgAPPs that focuses on the characteristics of power systems. We first highlight the specifics for constructing the adversarial attacks on MLsgAPPs. Then, the vulnerability of MLsgAPP is analyzed from both the aspects of the power system and ML model. Afterward, a comprehensive survey is conducted to review and compare existing studies about the adversarial attacks on MLsgAPPs in scenarios of generation, transmission, distribution, and consumption, and the countermeasures are reviewed according to the attacks that they defend against. Finally, the future research directions are discussed on the attacker's and defender's side, respectively. We also analyze the potential vulnerability of large language model-based (e.g., ChatGPT) power system applications. Overall, we encourage more researchers to contribute to investigating the adversarial issues of MLsgAPPs.

[Arxiv](https://arxiv.org/abs/2308.15736)