# 智能电网中基于物联网的机器学习方法脆弱性综述

发布时间：2023年12月24日

`Agent

理由：这篇论文主要关注的是机器学习（ML）在基于物联网（IoT）的智能电网中的应用，特别是在安全关键电力系统中MLsgAPPs的漏洞评估和对抗性攻击与防御方法。虽然提到了大型语言模型（如ChatGPT）在电力系统应用中的潜在漏洞，但这并不是论文的主要焦点。论文的核心在于探讨和评估智能电网中机器学习代理（Agent）的安全性和脆弱性，因此更适合归类为Agent。` `智能电网` `物联网`

> Vulnerability of Machine Learning Approaches Applied in IoT-based Smart Grid: A Review

# 摘要

> 机器学习（ML）在基于物联网（IoT）的智能电网中的应用日益增多，但其可信度问题亟待解决，以适应基于ML的智能电网应用（MLsgAPPs）的发展趋势。电力信号中注入的对抗性畸变严重威胁系统的正常运行。因此，对应用于安全关键电力系统的MLsgAPPs进行漏洞评估刻不容缓。本文首次聚焦电力系统特性，全面回顾了MLsgAPPs攻击与防御方法的最新进展。我们首先详细探讨了针对MLsgAPPs的对抗性攻击构建方法，接着从电力系统和ML模型两个角度分析了MLsgAPP的脆弱性。随后，我们对比分析了在发电、输电、配电和消费场景中针对MLsgAPPs的对抗性攻击及其防御措施。最后，我们分别从攻击者和防御者的视角展望了未来的研究方向，并探讨了基于大型语言模型（如ChatGPT）的电力系统应用可能存在的漏洞。我们呼吁更多研究者关注并解决MLsgAPPs的对抗性问题。

> Machine learning (ML) sees an increasing prevalence of being used in the internet-of-things (IoT)-based smart grid. However, the trustworthiness of ML is a severe issue that must be addressed to accommodate the trend of ML-based smart grid applications (MLsgAPPs). The adversarial distortion injected into the power signal will greatly affect the system's normal control and operation. Therefore, it is imperative to conduct vulnerability assessment for MLsgAPPs applied in the context of safety-critical power systems. In this paper, we provide a comprehensive review of the recent progress in designing attack and defense methods for MLsgAPPs. Unlike the traditional survey about ML security, this is the first review work about the security of MLsgAPPs that focuses on the characteristics of power systems. We first highlight the specifics for constructing the adversarial attacks on MLsgAPPs. Then, the vulnerability of MLsgAPP is analyzed from both the aspects of the power system and ML model. Afterward, a comprehensive survey is conducted to review and compare existing studies about the adversarial attacks on MLsgAPPs in scenarios of generation, transmission, distribution, and consumption, and the countermeasures are reviewed according to the attacks that they defend against. Finally, the future research directions are discussed on the attacker's and defender's side, respectively. We also analyze the potential vulnerability of large language model-based (e.g., ChatGPT) power system applications. Overall, we encourage more researchers to contribute to investigating the adversarial issues of MLsgAPPs.

[Arxiv](https://arxiv.org/abs/2308.15736)