# 智能电网中基于物联网的机器学习方法脆弱性分析：一次全面回顾

发布时间：2023年12月24日

`Agent

理由：这篇论文主要关注的是机器学习（ML）在智能电网中的应用，特别是在面对对抗性攻击时的安全性和脆弱性问题。虽然提到了大型语言模型（如ChatGPT）在电力系统应用中可能存在的漏洞，但这并不是论文的主要焦点。论文的核心在于探讨和评估ML在智能电网应用中的安全问题，包括攻击方法和防御策略，这更符合Agent分类的范畴，即关注系统或模型在特定环境中的行为和应对策略。` `智能电网` `物联网`

> Vulnerability of Machine Learning Approaches Applied in IoT-based Smart Grid: A Review

# 摘要

> 机器学习（ML）在基于物联网的智能电网中日益普及，但其可信度成为了一个亟待解决的严峻问题，以适应基于ML的智能电网应用（MLsgAPPs）的发展趋势。电力信号中注入的对抗性畸变严重干扰了系统的正常运作。因此，对应用于安全关键电力系统中的MLsgAPPs进行漏洞评估刻不容缓。本文首次聚焦于电力系统特性，全面回顾了针对MLsgAPPs的攻击与防御方法的最新进展。我们首先详述了构建针对MLsgAPPs的对抗性攻击的要点，接着从电力系统和ML模型两个维度剖析了MLsgAPP的脆弱性。随后，我们系统地回顾并比较了在发电、输电、配电及消费场景中针对MLsgAPPs的对抗性攻击研究，并根据防御的攻击类型梳理了相应的对策。最后，我们分别从攻击者和防御者的视角展望了未来的研究方向，并探讨了基于大型语言模型（如ChatGPT）的电力系统应用可能存在的漏洞。我们呼吁更多研究者关注并深入研究MLsgAPPs的对抗性问题。

> Machine learning (ML) sees an increasing prevalence of being used in the internet-of-things (IoT)-based smart grid. However, the trustworthiness of ML is a severe issue that must be addressed to accommodate the trend of ML-based smart grid applications (MLsgAPPs). The adversarial distortion injected into the power signal will greatly affect the system's normal control and operation. Therefore, it is imperative to conduct vulnerability assessment for MLsgAPPs applied in the context of safety-critical power systems. In this paper, we provide a comprehensive review of the recent progress in designing attack and defense methods for MLsgAPPs. Unlike the traditional survey about ML security, this is the first review work about the security of MLsgAPPs that focuses on the characteristics of power systems. We first highlight the specifics for constructing the adversarial attacks on MLsgAPPs. Then, the vulnerability of MLsgAPP is analyzed from both the aspects of the power system and ML model. Afterward, a comprehensive survey is conducted to review and compare existing studies about the adversarial attacks on MLsgAPPs in scenarios of generation, transmission, distribution, and consumption, and the countermeasures are reviewed according to the attacks that they defend against. Finally, the future research directions are discussed on the attacker's and defender's side, respectively. We also analyze the potential vulnerability of large language model-based (e.g., ChatGPT) power system applications. Overall, we encourage more researchers to contribute to investigating the adversarial issues of MLsgAPPs.

[Arxiv](https://arxiv.org/abs/2308.15736)