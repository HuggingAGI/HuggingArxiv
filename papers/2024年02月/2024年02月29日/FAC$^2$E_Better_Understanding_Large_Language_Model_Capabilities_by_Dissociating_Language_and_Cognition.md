# [FAC$^2$E 方法致力于通过区分语言与认知机制，以更深入地探究大型语言模型的能力。](https://arxiv.org/abs/2403.00126)

发布时间：2024年02月29日

`LLM理论`

> FAC$^2$E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition

> 当前，LLMs的评估主要依据其在多种文本理解与生成任务的整体表现，但这无法详尽揭示其内在的语言和认知技能差异。为此，本文引入了一个名为FAC$^2$E的创新框架，专注于对LLMs进行细粒度和认知关联的能力评估。该框架独具匠心地将LLMs的能力分解为与语言相关的和与认知相关的多个维度，使得评估过程更为明晰、具有可解释性。更进一步，FAC$^2$E深入挖掘LLMs内部推理过程，将运用特定能力细化为“记忆唤醒、知识调用、问题解决”三个阶段，并分别对每项细粒度能力的各个阶段进行评估，从而为LLMs提供全方位的能力剖析。借助FAC$^2$E，我们发现模型在知识利用环节普遍存在的不足，并提出一种直观而有效的知识增强策略加以改进。实验结果显示，这一策略不仅能显著提升模型性能，也为未来LLM的优化升级指明了新方向。

> Large language models (LLMs) are primarily evaluated by overall performance on various text understanding and generation tasks. However, such a paradigm fails to comprehensively differentiate the fine-grained language and cognitive skills, rendering the lack of sufficient interpretation to LLMs' capabilities. In this paper, we present FAC$^2$E, a framework for Fine-grAined and Cognition-grounded LLMs' Capability Evaluation. Specifically, we formulate LLMs' evaluation in a multi-dimensional and explainable manner by dissociating the language-related capabilities and the cognition-related ones. Besides, through extracting the intermediate reasoning from LLMs, we further break down the process of applying a specific capability into three sub-steps: recalling relevant knowledge, utilizing knowledge, and solving problems. Finally, FAC$^2$E evaluates each sub-step of each fine-grained capability, providing a two-faceted diagnosis for LLMs. Utilizing FAC$^2$E, we identify a common shortfall in knowledge utilization among models and propose a straightforward, knowledge-enhanced method to mitigate this issue. Our results not only showcase promising performance enhancements but also highlight a direction for future LLM advancements.

[Arxiv](https://arxiv.org/abs/2403.00126)