# ReConcile：通过汇聚多样化的大型语言模型之间的共识，圆桌会议式的讨论显著提升了推理过程的质量。

发布时间：2024年02月21日

`分类：Agent` `人工智能`

> ReConcile: Round-Table Conference Improves Reasoning via Consensus among Diverse LLMs

# 摘要

> 大型语言模型（LLMs）在处理自然语言推理任务时仍面临挑战。借鉴马文·明斯基（Marvin Minsky）于1988年提出的“心智社会”理念，我们设计了ReConcile——一个多模型多代理的框架，它模拟了一个多样化LLM代理间的圆桌讨论。ReConcile通过多轮讨论，促进代理间的协作推理，学会说服同伴以提升答案质量，并采用置信度加权投票机制，以达成更优共识。每一轮讨论都以“讨论提示”开始，包含上一轮各代理生成的答案和解释、置信度评分，以及用于说服其他代理的答案修正的人类解释示例。在七个基准测试中的实验结果表明，ReConcile显著提升了LLMs的推理表现，无论是单独还是团队协作，都超过了先前的单代理和多代理基线，最高提升了11.4%，甚至在三个数据集上超越了GPT-4。ReConcile还能够灵活地整合不同组合的代理，包括基于API的、开源的和特定于领域的模型，这在MATH基准测试中实现了8%的性能提升。最终，我们对ReConcile的各个组件进行了分析，证实了不同模型带来的多样性对其卓越性能的关键作用。代码链接：https://github.com/dinobby/ReConcile

> Large Language Models (LLMs) still struggle with natural language reasoning tasks. Motivated by the society of minds (Minsky, 1988), we propose ReConcile, a multi-model multiagent framework designed as a round table conference among diverse LLM agents. ReConcile enhances collaborative reasoning between LLM agents via multiple rounds of discussion, learning to convince other agents to improve their answers, and employing a confidence-weighted voting mechanism that leads to a better consensus. In each round, ReConcile initiates discussion between agents via a 'discussion prompt' that consists of (a) grouped answers and explanations generated by each agent in the previous round, (b) their confidence scores, and (c) demonstrations of answer-rectifying human explanations, used for convincing other agents. Experiments on seven benchmarks demonstrate that ReConcile significantly improves LLMs' reasoning -- both individually and as a team -- surpassing prior single-agent and multi-agent baselines by up to 11.4% and even outperforming GPT-4 on three datasets. ReConcile also flexibly incorporates different combinations of agents, including API-based, open-source, and domain-specific models, leading to an 8% improvement on MATH. Finally, we analyze the individual components of ReConcile, demonstrating that the diversity originating from different models is critical to its superior performance. Code: https://github.com/dinobby/ReConcile

[Arxiv](https://arxiv.org/abs/2309.13007)