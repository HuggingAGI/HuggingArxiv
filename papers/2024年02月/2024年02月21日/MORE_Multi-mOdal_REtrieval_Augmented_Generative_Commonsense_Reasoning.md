# [MORE，一种创新方法，通过引入多模态检索增强技术，提升生成性常识推理的表现力和准确性。]

发布时间：2024年02月21日

`LLM应用`

> MORE: Multi-mOdal REtrieval Augmented Generative Commonsense Reasoning

> 鉴于常识信息的记录稀缺，导致基于文本生成预训练的语言模型难以习得充足的常识知识。为此，部分研究借助文本检索技术以扩充模型的常识理解力。值得注意的是，相较于文本，图像天然蕴含丰富的常识信息，但尚未得到充分有效的利用。为此，我们在本工作中创新性地提出了“多模态强化检索”（MORE）框架，旨在结合文本与图像资源，共同提升语言模型的常识推理能力。大规模的实验证明，在Common-Gen任务上，不论是基于单模态还是多模态预训练模型，MORE方法都展现出了显著的效能提升。

> Since commonsense information has been recorded significantly less frequently than its existence, language models pre-trained by text generation have difficulty to learn sufficient commonsense knowledge. Several studies have leveraged text retrieval to augment the models' commonsense ability. Unlike text, images capture commonsense information inherently but little effort has been paid to effectively utilize them. In this work, we propose a novel Multi-mOdal REtrieval (MORE) augmentation framework, to leverage both text and images to enhance the commonsense ability of language models. Extensive experiments on the Common-Gen task have demonstrated the efficacy of MORE based on the pre-trained models of both single and multiple modalities.

[Arxiv](https://arxiv.org/abs/2402.13625)