# [ActiveRAG——借助主动学习挖掘知识宝库](https://arxiv.org/abs/2402.13547)

发布时间：2024年02月21日

`RAG`

> ActiveRAG: Revealing the Treasures of Knowledge via Active Learning

> RAG技术为 LLMS 打开了处理知识密集型任务的新大门，但现有的RAG模型让LLMs在吸收外部知识时显得过于被动，限制了其学习和理解能力。本文推出ActiveRAG这一革新性框架，它告别了单纯的知识被动接受模式，转而采用主动学习机制。ActiveRAG借助知识建构机制，通过关联已掌握或记忆中的知识，加深对外部知识的理解。同时设计了认知纽带机制，整合思维链与知识建构的双重成果，精准调校LLMs的内在认知机能。实验证明，ActiveRAG较之前的RAG模型更胜一筹，在问答数据集上的表现提升了5%。项目所有数据和代码已在GitHub开源，访问地址为https://github.com/OpenMatch/ActiveRAG。

> Retrieval Augmented Generation (RAG) has introduced a new paradigm for Large Language Models (LLMs), aiding in the resolution of knowledge-intensive tasks. However, current RAG models position LLMs as passive knowledge receptors, thereby restricting their capacity for learning and comprehending external knowledge. In this paper, we present ActiveRAG, an innovative RAG framework that shifts from passive knowledge acquisition to an active learning mechanism. This approach utilizes the Knowledge Construction mechanism to develop a deeper understanding of external knowledge by associating it with previously acquired or memorized knowledge. Subsequently, it designs the Cognitive Nexus mechanism to incorporate the outcomes from both chains of thought and knowledge construction, thereby calibrating the intrinsic cognition of LLMs. Our experimental results demonstrate that ActiveRAG surpasses previous RAG models, achieving a 5% improvement on question-answering datasets. All data and codes are available at https://github.com/OpenMatch/ActiveRAG.

[Arxiv](https://arxiv.org/abs/2402.13547)