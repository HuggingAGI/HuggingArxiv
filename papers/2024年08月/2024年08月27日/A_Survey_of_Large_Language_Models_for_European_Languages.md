# 欧洲语言大型语言模型综述

发布时间：2024年08月27日

`LLM理论` `人工智能`

> A Survey of Large Language Models for European Languages

# 摘要

> 自 ChatGPT 问世以来，大型语言模型（LLM）因其卓越的自然语言处理能力备受瞩目。这些模型通过海量文本数据的庞大数据训练，掌握语言理解和生成之精髓。尽管 LLM 研究尚属新兴领域，但其发展势头迅猛，涉猎广泛。本文将为您梳理 LLM 家族成员，如 LLaMA、PaLM、GPT 及 MoE，并探讨如何针对欧盟官方语言优化这些模型。同时，我们还将详述用于 LLM 预训练的单语与多语数据集。

> Large Language Models (LLMs) have gained significant attention due to their high performance on a wide range of natural language tasks since the release of ChatGPT. The LLMs learn to understand and generate language by training billions of model parameters on vast volumes of text data. Despite being a relatively new field, LLM research is rapidly advancing in various directions. In this paper, we present an overview of LLM families, including LLaMA, PaLM, GPT, and MoE, and the methods developed to create and enhance LLMs for official European Union (EU) languages. We provide a comprehensive summary of common monolingual and multilingual datasets used for pretraining LLMs.

[Arxiv](https://arxiv.org/abs/2408.15040)