# 大型语言模型界面中的反馈功能，如何限制用户参与，是我们探讨的重点。

发布时间：2024年08月27日

`LLM应用` `人工智能` `社会科学`

> Constraining Participation: Affordances of Feedback Features in Interfaces to Large Language Models

# 摘要

> 如今，大型语言模型（LLM）通过浏览器接口，让拥有电脑、网络浏览器和互联网连接的任何人都能轻松访问，从而改变了参与AI开发的格局。本文深入探讨了ChatGPT界面中交互式反馈功能的作用，剖析了这些功能如何影响用户输入和LLM迭代过程中的参与度。通过对ChatGPT用户的调查，并结合效用机制与条件框架的分析，我们发现这些功能倾向于鼓励简单、频繁且以性能为导向的反馈，同时抑制了用户间的集体协作与讨论。我们认为，这种反馈模式严重限制了用户的参与度，加剧了用户、公众与LLM开发公司间的权力失衡。我们的研究为参与式AI领域的文献贡献了新的视角，不仅批判性地分析了现有反馈机制的局限，还提出了重新设计的方向。为了促进AI开发中更广泛的公众参与，我们主张摒弃那些仅仅追求模型输出与用户偏好一致的过程，转而强调建立公司与多元“公众”之间关于LLM目的与应用的对话机制。这一转变要求我们关注基础设施建设的持续努力，即构建和维护必要的社会、技术与制度框架，以应对AI开发与部署过程中受影响群体所关心的问题。

> Large language models (LLMs) are now accessible to anyone with a computer, a web browser, and an internet connection via browser-based interfaces, shifting the dynamics of participation in AI development. This paper examines the affordances of interactive feedback features in ChatGPT's interface, analysing how they shape user input and participation in LLM iteration. Drawing on a survey of ChatGPT users and applying the mechanisms and conditions framework of affordances, we demonstrate that these features encourage simple, frequent, and performance-focused feedback while discouraging collective input and discussions among users. We argue that this feedback format significantly constrains user participation, reinforcing power imbalances between users, the public, and companies developing LLMs. Our analysis contributes to the growing body of literature on participatory AI by critically examining the limitations of existing feedback processes and proposing directions for their redesign. To enable more meaningful public participation in AI development, we advocate for a shift away from processes focused on aligning model outputs with specific user preferences. Instead, we emphasise the need for processes that facilitate dialogue between companies and diverse 'publics' about the purpose and applications of LLMs. This approach requires attention to the ongoing work of infrastructuring - creating and sustaining the social, technical, and institutional structures necessary to address matters of concern to groups impacted by AI development and deployment.

[Arxiv](https://arxiv.org/abs/2408.15066)