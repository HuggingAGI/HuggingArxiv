# Legilimens：为大型语言模型服务提供实用且统一的内容管理方案

发布时间：2024年08月27日

`LLM应用` `网络安全` `内容审核`

> Legilimens: Practical and Unified Content Moderation for Large Language Model Services

# 摘要

> 鉴于大型语言模型生成的不安全内容对社会的潜在影响，确保这些模型服务符合安全标准至关重要。传统的内容审核方法常陷入有效性与效率的两难境地，简单模型易崩溃，复杂模型则耗费大量计算资源。本文首次揭示，通过从面向聊天的 LLM 中提取概念特征，可以实现既有效又高效的内容审核，尽管这些模型原本是为对话而非审核设计的。我们提出的 Legilimens 框架，不仅实用且统一，还兼顾了有效性和效率。通过基于红队模型的数据增强，Legilimens 对最先进的越狱技术展现出强大的鲁棒性。我们还开发了一个理论框架，用于分析 Legilimens 与其他方法的成本效益。在广泛的实验中，Legilimens 在五个主机 LLM、十七个数据集和九种越狱方法上表现出色，证明了其对各种对手的有效性、效率和鲁棒性。与现有基线相比，Legilimens 展现出更优的性能，并能适应少样本场景和多标签分类任务。

> Given the societal impact of unsafe content generated by large language models (LLMs), ensuring that LLM services comply with safety standards is a crucial concern for LLM service providers. Common content moderation methods are limited by an effectiveness-and-efficiency dilemma, where simple models are fragile while sophisticated models consume excessive computational resources. In this paper, we reveal for the first time that effective and efficient content moderation can be achieved by extracting conceptual features from chat-oriented LLMs, despite their initial fine-tuning for conversation rather than content moderation. We propose a practical and unified content moderation framework for LLM services, named Legilimens, which features both effectiveness and efficiency. Our red-team model-based data augmentation enhances the robustness of Legilimens against state-of-the-art jailbreaking. Additionally, we develop a framework to theoretically analyze the cost-effectiveness of Legilimens compared to other methods. We have conducted extensive experiments on five host LLMs, seventeen datasets, and nine jailbreaking methods to verify the effectiveness, efficiency, and robustness of Legilimens against normal and adaptive adversaries. A comparison of Legilimens with both commercial and academic baselines demonstrates the superior performance of Legilimens. Furthermore, we confirm that Legilimens can be applied to few-shot scenarios and extended to multi-label classification tasks.

[Arxiv](https://arxiv.org/abs/2408.15488)