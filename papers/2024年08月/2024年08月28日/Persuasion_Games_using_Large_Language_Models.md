# 大型语言模型在说服游戏中的应用

发布时间：2024年08月28日

`Agent`

> Persuasion Games using Large Language Models

# 摘要

> 大型语言模型 (LLM) 已成为理解和生成人类般文本的强大工具。本文探讨了 LLM 如何塑造人类观点，进而影响其在特定任务上的决策，如投资、信用卡选择和保险等。我们设计了一个多代理框架，主要代理通过说服性对话与用户互动，辅助代理则负责信息处理和策略制定。实验表明，这种协作模式显著提升了 LLM 的说服力。我们还通过模拟人格对话，评估了 LLM 在不同领域中的适应性和影响力，并量化了说服效果。

> Large Language Models (LLMs) have emerged as formidable instruments capable of comprehending and producing human-like text. This paper explores the potential of LLMs, to shape human perspectives and subsequently influence their decisions on particular tasks. This capability finds applications in diverse domains such as Investment, Credit cards and Insurance, wherein they assist users in selecting appropriate insurance policies, investment plans, Credit cards, Retail, as well as in Behavioral Change Support Systems (BCSS).
  We present a sophisticated multi-agent framework wherein a consortium of agents operate in collaborative manner. The primary agent engages directly with users through persuasive dialogue, while the auxiliary agents perform tasks such as information retrieval, response analysis, development of persuasion strategies, and validation of facts. Empirical evidence from our experiments demonstrates that this collaborative methodology significantly enhances the persuasive efficacy of the LLM. We analyze user resistance to persuasive efforts continuously and counteract it by employing a combination of rule-based and LLM-based resistance-persuasion mapping techniques.
  We employ simulated personas and generate conversations in insurance, banking, and retail domains to evaluate the proficiency of large language models (LLMs) in recognizing, adjusting to, and influencing various personality types. Concurrently, we examine the resistance mechanisms employed by LLM simulated personas. Persuasion is quantified via measurable surveys before and after interaction, LLM-generated scores on conversation, and user decisions (purchase or non-purchase).

[Arxiv](https://arxiv.org/abs/2408.15879)