# VLM4Bio 是一个基准数据集，旨在评估预训练视觉-语言模型在生物图像特征发现中的效能。

发布时间：2024年08月28日

`LLM应用` `生物学` `计算机视觉`

> VLM4Bio: A Benchmark Dataset to Evaluate Pretrained Vision-Language Models for Trait Discovery from Biological Images

# 摘要

> 随着图像成为记录生物多样性的重要工具，大型视觉-语言模型（VLMs）为生物学领域的科学发现带来了加速机遇。本文探讨了预训练VLMs在无需微调的情况下，能否助力科学家解答生物学相关问题。我们通过一个包含469K个问题-答案对的新数据集VLM4Bio，评估了12个顶尖VLMs在生物学领域的效能，该数据集涵盖鱼类、鸟类和蝴蝶三类生物的30K张图像，涉及五个生物学任务。此外，我们还研究了提示技术和推理幻觉测试对VLMs性能的影响，揭示了当前顶尖VLMs利用图像解答生物学问题的潜力。所有分析的代码和数据集已公开于https://github.com/sammarfy/VLM4Bio。

> Images are increasingly becoming the currency for documenting biodiversity on the planet, providing novel opportunities for accelerating scientific discoveries in the field of organismal biology, especially with the advent of large vision-language models (VLMs). We ask if pre-trained VLMs can aid scientists in answering a range of biologically relevant questions without any additional fine-tuning. In this paper, we evaluate the effectiveness of 12 state-of-the-art (SOTA) VLMs in the field of organismal biology using a novel dataset, VLM4Bio, consisting of 469K question-answer pairs involving 30K images from three groups of organisms: fishes, birds, and butterflies, covering five biologically relevant tasks. We also explore the effects of applying prompting techniques and tests for reasoning hallucination on the performance of VLMs, shedding new light on the capabilities of current SOTA VLMs in answering biologically relevant questions using images. The code and datasets for running all the analyses reported in this paper can be found at https://github.com/sammarfy/VLM4Bio.

[Arxiv](https://arxiv.org/abs/2408.16176)