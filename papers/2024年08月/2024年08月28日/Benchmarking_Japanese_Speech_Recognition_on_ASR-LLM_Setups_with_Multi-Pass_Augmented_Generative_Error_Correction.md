# 通过多遍增强生成错误校正技术，对 ASR-LLM 设置下的日本语音识别性能进行基准测试。

发布时间：2024年08月28日

`LLM应用` `语音识别` `自动语音识别`

> Benchmarking Japanese Speech Recognition on ASR-LLM Setups with Multi-Pass Augmented Generative Error Correction

# 摘要

> 利用大型语言模型的强大表征力，我们探索了生成错误纠正（GER）如何提升日语自动语音识别（ASR）的精确度。首次为日语ASR设立了GER基准，涵盖0.9至2.6千条文本话语。此外，我们创新性地提出了多遍增强生成错误纠正（MPA GER），通过融合多系统输入假设与多LLM输出修正，显著提高了ASR的性能与泛化能力。实验结果在SPREDS-U1-ja与CSJ数据集上均显示出所提方法的有效性。

> With the strong representational power of large language models (LLMs), generative error correction (GER) for automatic speech recognition (ASR) aims to provide semantic and phonetic refinements to address ASR errors. This work explores how LLM-based GER can enhance and expand the capabilities of Japanese language processing, presenting the first GER benchmark for Japanese ASR with 0.9-2.6k text utterances. We also introduce a new multi-pass augmented generative error correction (MPA GER) by integrating multiple system hypotheses on the input side with corrections from multiple LLMs on the output side and then merging them. To the best of our knowledge, this is the first investigation of the use of LLMs for Japanese GER, which involves second-pass language modeling on the output transcriptions generated by the ASR system (e.g., N-best hypotheses). Our experiments demonstrated performance improvement in the proposed methods of ASR quality and generalization both in SPREDS-U1-ja and CSJ data.

[Arxiv](https://arxiv.org/abs/2408.16180)