# FRACTURED-SORRY-Bench：基于SORRY-Bench，揭示对话中削弱拒绝效力和防御的攻击框架。

发布时间：2024年08月28日

`LLM应用` `网络安全` `人工智能`

> FRACTURED-SORRY-Bench: Framework for Revealing Attacks in Conversational Turns Undermining Refusal Efficacy and Defenses over SORRY-Bench

# 摘要

> 本文推出 FRACTURED-SORRY-Bench 框架，旨在评估 LLM 在面对多轮对话攻击时的安全性。我们通过将有害查询拆解为无害子问题，提出了一种简便有效的对抗提示生成方法。相较于传统方法，该技术在多个 GPT 模型上的攻击成功率提升了高达 46.22%。这不仅挑战了现有的 LLM 安全机制，更凸显了加强防御以应对复杂多轮攻击的迫切需求。

> This paper introduces FRACTURED-SORRY-Bench, a framework for evaluating the safety of Large Language Models (LLMs) against multi-turn conversational attacks. Building upon the SORRY-Bench dataset, we propose a simple yet effective method for generating adversarial prompts by breaking down harmful queries into seemingly innocuous sub-questions. Our approach achieves a maximum increase of +46.22\% in Attack Success Rates (ASRs) across GPT-4, GPT-4o, GPT-4o-mini, and GPT-3.5-Turbo models compared to baseline methods. We demonstrate that this technique poses a challenge to current LLM safety measures and highlights the need for more robust defenses against subtle, multi-turn attacks.

[Arxiv](https://arxiv.org/abs/2408.16163)