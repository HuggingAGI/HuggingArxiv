# 多模态大型语言模型评估综述

发布时间：2024年08月28日

`LLM应用` `人工智能` `多模态技术`

> A Survey on Evaluation of Multimodal Large Language Models

# 摘要

> 多模态大型语言模型（MLLMs）通过整合大型语言模型（LLMs）与多种模态编码器（如视觉、音频），模拟人类感知与推理系统，将LLMs视为“大脑”，模态编码器比作感觉器官。这一架构赋予MLLMs类人智能，并预示着通向人工通用智能（AGI）的可能路径。随着GPT-4V和Gemini等全面MLLMs的兴起，针对其多维度能力的评估方法层出不穷。本文系统梳理了MLLM评估方法，涉及：（1）MLLMs及其评估背景；（2）“评估内容”，即基于评估能力对现有MLLM任务进行回顾与分类，涵盖通用多模态识别、感知、推理及可信度，以及特定领域应用，如社会经济、自然科学、医疗、AI代理、遥感、音视频处理、3D点云分析等；（3）“评估平台”，将MLLM评估基准归纳为通用与特定两类；（4）“评估方法”，详述MLLM评估流程与指标。我们旨在为MLLM评估研究者提供深刻洞见，推动更高效、可靠MLLMs的进步。我们强调，评估是推进MLLM领域不可或缺的关键环节。

> Multimodal Large Language Models (MLLMs) mimic human perception and reasoning system by integrating powerful Large Language Models (LLMs) with various modality encoders (e.g., vision, audio), positioning LLMs as the "brain" and various modality encoders as sensory organs. This framework endows MLLMs with human-like capabilities, and suggests a potential pathway towards achieving artificial general intelligence (AGI). With the emergence of all-round MLLMs like GPT-4V and Gemini, a multitude of evaluation methods have been developed to assess their capabilities across different dimensions. This paper presents a systematic and comprehensive review of MLLM evaluation methods, covering the following key aspects: (1) the background of MLLMs and their evaluation; (2) "what to evaluate" that reviews and categorizes existing MLLM evaluation tasks based on the capabilities assessed, including general multimodal recognition, perception, reasoning and trustworthiness, and domain-specific applications such as socioeconomic, natural sciences and engineering, medical usage, AI agent, remote sensing, video and audio processing, 3D point cloud analysis, and others; (3) "where to evaluate" that summarizes MLLM evaluation benchmarks into general and specific benchmarks; (4) "how to evaluate" that reviews and illustrates MLLM evaluation steps and metrics; Our overarching goal is to provide valuable insights for researchers in the field of MLLM evaluation, thereby facilitating the development of more capable and reliable MLLMs. We emphasize that evaluation should be regarded as a critical discipline, essential for advancing the field of MLLMs.

[Arxiv](https://arxiv.org/abs/2408.15769)