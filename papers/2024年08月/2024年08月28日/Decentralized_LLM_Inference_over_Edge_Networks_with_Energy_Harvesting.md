# 边缘网络上的去中心化 LLM 推理结合能量采集技术

发布时间：2024年08月28日

`LLM应用` `边缘计算` `能源管理`

> Decentralized LLM Inference over Edge Networks with Energy Harvesting

# 摘要

> 大型语言模型在自然语言处理领域的出色表现，虽然推动了多个行业的变革，但在资源受限的边缘网络环境中部署仍面临挑战。为此，去中心化推理技术崭露头角，通过在多设备间分散模型块，提升了灵活性与成本效益。然而，边缘设备的能源限制仍是亟待解决的问题。我们提出了一种创新的协作推理模型，适用于采用能量采集技术的互联电池供电边缘设备。通过构建半马尔可夫模型，我们综合考虑了设备处理参数与绿色能源的平均到达率，进而设计出能最小化设备停机时间、最大化网络吞吐量的调度算法。实证与模拟结果均证实了我们方法的有效性，为实现边缘网络中高效能的去中心化推理奠定了基础。

> Large language models have significantly transformed multiple fields with their exceptional performance in natural language tasks, but their deployment in resource-constrained environments like edge networks presents an ongoing challenge. Decentralized techniques for inference have emerged, distributing the model blocks among multiple devices to improve flexibility and cost effectiveness. However, energy limitations remain a significant concern for edge devices. We propose a sustainable model for collaborative inference on interconnected, battery-powered edge devices with energy harvesting. A semi-Markov model is developed to describe the states of the devices, considering processing parameters and average green energy arrivals. This informs the design of scheduling algorithms that aim to minimize device downtimes and maximize network throughput. Through empirical evaluations and simulated runs, we validate the effectiveness of our approach, paving the way for energy-efficient decentralized inference over edge networks.

[Arxiv](https://arxiv.org/abs/2408.15907)