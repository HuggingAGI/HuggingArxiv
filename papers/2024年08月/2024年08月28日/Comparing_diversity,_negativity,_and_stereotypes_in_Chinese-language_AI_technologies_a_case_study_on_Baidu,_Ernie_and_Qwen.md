# 探究中文AI技术中的多样性、负面信息及刻板印象：百度、Ernie与Qwen的案例分析

发布时间：2024年08月28日

`LLM应用` `社会科学` `人工智能`

> Comparing diversity, negativity, and stereotypes in Chinese-language AI technologies: a case study on Baidu, Ernie and Qwen

# 摘要

> 大型语言模型与搜索引擎可能通过放大训练数据中的偏见，影响公众观念与决策，从而助长偏见与刻板印象。我们聚焦于中国情境，深入分析百度搜索引擎及两大领先模型Ernie与Qwen中潜藏的社会偏见。通过涵盖13类、240个社会群体的数据集，我们搜集了这些工具中逾3万条观点。研究发现，语言模型呈现的观点多样性超过搜索引擎，且百度与Qwen的负面内容生成频率高于Ernie。同时，模型中亦存在一定程度的刻板印象，部分可能带有冒犯性。本研究凸显了在全球视野下推动AI技术公平与包容的紧迫性。

> Large Language Models (LLMs) and search engines have the potential to perpetuate biases and stereotypes by amplifying existing prejudices in their training data and algorithmic processes, thereby influencing public perception and decision-making. While most work has focused on Western-centric AI technologies, we study Chinese-based tools by investigating social biases embedded in the major Chinese search engine, Baidu, and two leading LLMs, Ernie and Qwen. Leveraging a dataset of 240 social groups across 13 categories describing Chinese society, we collect over 30k views encoded in the aforementioned tools by prompting them for candidate words describing such groups. We find that language models exhibit a larger variety of embedded views compared to the search engine, although Baidu and Qwen generate negative content more often than Ernie. We also find a moderate prevalence of stereotypes embedded in the language models, many of which potentially promote offensive and derogatory views. Our work highlights the importance of promoting fairness and inclusivity in AI technologies with a global perspective.

[Arxiv](https://arxiv.org/abs/2408.15696)