# 本研究探讨了针对集成大型语言模型的移动机器人系统的提示注入攻击。

发布时间：2024年08月06日

`Agent` `机器人` `人工智能`

> A Study on Prompt Injection Attack Against LLM-Integrated Mobile Robotic Systems

# 摘要

> 将 GPT-4o 等大型语言模型融入机器人系统，标志着实体人工智能的一大飞跃。这些模型能处理多模态输入，生成更贴合上下文的响应。但这一融合也带来了挑战，尤其是与机器人导航任务中使用 LLM 相关的安全风险。导航任务要求精准可靠的响应，确保操作安全有效。多模态输入虽提升了机器人的理解力，却也增加了被恶意利用的复杂性。例如，设计来误导模型的对抗性输入可能导致危险的导航决策。本研究探讨了提示注入对集成 LLM 的移动机器人性能的影响，并寻求安全提示策略以降低风险。研究发现，采用强有力的防御机制后，攻击检测和系统性能均提升了约 30.8%，凸显了这些机制在提升任务导向型操作的安全性和可靠性中的重要性。

> The integration of Large Language Models (LLMs) like GPT-4o into robotic systems represents a significant advancement in embodied artificial intelligence. These models can process multi-modal prompts, enabling them to generate more context-aware responses. However, this integration is not without challenges. One of the primary concerns is the potential security risks associated with using LLMs in robotic navigation tasks. These tasks require precise and reliable responses to ensure safe and effective operation. Multi-modal prompts, while enhancing the robot's understanding, also introduce complexities that can be exploited maliciously. For instance, adversarial inputs designed to mislead the model can lead to incorrect or dangerous navigational decisions. This study investigates the impact of prompt injections on mobile robot performance in LLM-integrated systems and explores secure prompt strategies to mitigate these risks. Our findings demonstrate a substantial overall improvement of approximately 30.8% in both attack detection and system performance with the implementation of robust defence mechanisms, highlighting their critical role in enhancing security and reliability in mission-oriented tasks.

[Arxiv](https://arxiv.org/abs/2408.03515)