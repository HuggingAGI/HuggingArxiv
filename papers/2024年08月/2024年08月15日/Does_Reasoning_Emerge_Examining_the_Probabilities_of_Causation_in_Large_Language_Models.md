# 探究大规模语言模型中因果关系出现的概率，我们试图解答：推理是否自然涌现？

发布时间：2024年08月15日

`LLM理论` `人工智能` `概率论`

> Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models

# 摘要

> AI领域的飞速发展，很大程度上归功于大型语言模型（LLMs）模拟人类思维解决复杂问题的能力。然而，LLMs的实际推理能力究竟如何，仍是热议话题。本文聚焦于两个关键概率概念——必要性概率（PN）和充分性概率（PS），它们是连接因果的基石。我们提出一个理论与实践并重的框架，旨在评估LLMs如何利用这些概率工具，有效模拟现实推理。通过将LLMs视作通过自然语言处理信息的抽象机器，我们探索了计算PN和PS近似值的条件。这一研究为我们深入理解LLMs的推理能力提供了关键线索，通过一系列数学实例得以生动展现。

> Recent advances in AI have been significantly driven by the capabilities of large language models (LLMs) to solve complex problems in ways that resemble human thinking. However, there is an ongoing debate about the extent to which LLMs are capable of actual reasoning. Central to this debate are two key probabilistic concepts that are essential for connecting causes to their effects: the probability of necessity (PN) and the probability of sufficiency (PS). This paper introduces a framework that is both theoretical and practical, aimed at assessing how effectively LLMs are able to replicate real-world reasoning mechanisms using these probabilistic measures. By viewing LLMs as abstract machines that process information through a natural language interface, we examine the conditions under which it is possible to compute suitable approximations of PN and PS. Our research marks an important step towards gaining a deeper understanding of when LLMs are capable of reasoning, as illustrated by a series of math examples.

[Arxiv](https://arxiv.org/abs/2408.08210)