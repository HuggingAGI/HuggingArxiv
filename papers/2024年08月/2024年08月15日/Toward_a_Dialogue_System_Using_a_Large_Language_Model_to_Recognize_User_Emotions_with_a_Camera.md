# 借助大型语言模型，通过摄像头识别用户情绪，构建对话系统。

发布时间：2024年08月15日

`Agent` `人工智能` `情感分析`

> Toward a Dialogue System Using a Large Language Model to Recognize User Emotions with a Camera

# 摘要

> ChatGPT©等大型语言模型的性能显著提升，在线环境中，它们被广泛应用于网页聊天机器人、语音交互呼叫中心及代理对话功能等。离线环境下，多模态对话功能也逐渐实现，如通过平板终端的AI代理进行指导，或搭载于机器人的LLM对话系统。在这些多模态对话中，AI与用户间的情感交互至关重要。目前，AI代理已能通过文本或语音信息识别用户情感，但通过面部表情识别情感的研究尚属空白。本研究探索了基于LLM的AI代理能否通过摄像头捕捉用户表情，识别情感，并据此调整对话。实验证实，对于高情感得分的情绪如快乐和愤怒，AI代理能进行情感响应的对话。

> The performance of ChatGPT© and other LLMs has improved tremendously, and in online environments, they are increasingly likely to be used in a wide variety of situations, such as ChatBot on web pages, call center operations using voice interaction, and dialogue functions using agents. In the offline environment, multimodal dialogue functions are also being realized, such as guidance by Artificial Intelligence agents (AI agents) using tablet terminals and dialogue systems in the form of LLMs mounted on robots. In this multimodal dialogue, mutual emotion recognition between the AI and the user will become important. So far, there have been methods for expressing emotions on the part of the AI agent or for recognizing them using textual or voice information of the user's utterances, but methods for AI agents to recognize emotions from the user's facial expressions have not been studied. In this study, we examined whether or not LLM-based AI agents can interact with users according to their emotional states by capturing the user in dialogue with a camera, recognizing emotions from facial expressions, and adding such emotion information to prompts. The results confirmed that AI agents can have conversations according to the emotional state for emotional states with relatively high scores, such as Happy and Angry.

[Arxiv](https://arxiv.org/abs/2408.07982)