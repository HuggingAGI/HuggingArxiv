# 6G网络中，大型语言模型导致推理AI性能下滑

发布时间：2024年08月30日

`LLM应用` `人工智能`

> Reasoning AI Performance Degradation in 6G Networks with Large Language Models

# 摘要

> 人工智能融入6G网络，正引领连接性、可靠性和智能决策的革命。然而，AI模型在此类网络中的表现至关重要，任何性能下滑都会严重影响网络效率和服务质量。本文提出了一种创新方法，利用大型语言模型（LLM）支持的思维链（CoT）技术，深入剖析AI模型在6G网络中的性能下降原因。我们通过零-shot提示，将LLM作为“教师”，生成教学CoT理由，再由微调后的CoT“学生”模型学习推理性能下降。实验在一个包含WiFi、5G和LiFi的多接入技术实时3D渲染任务中验证了该方法，推理准确率超过97%，证明了数据集和LLM-CoT方法的有效性。这些成果凸显了LLM在提升6G网络可靠性和效率方面的巨大潜力，为AI原生网络基础设施的发展带来了重大突破。

> The integration of Artificial Intelligence (AI) within 6G networks is poised to revolutionize connectivity, reliability, and intelligent decision-making. However, the performance of AI models in these networks is crucial, as any decline can significantly impact network efficiency and the services it supports. Understanding the root causes of performance degradation is essential for maintaining optimal network functionality. In this paper, we propose a novel approach to reason about AI model performance degradation in 6G networks using the Large Language Models (LLMs) empowered Chain-of-Thought (CoT) method. Our approach employs an LLM as a ''teacher'' model through zero-shot prompting to generate teaching CoT rationales, followed by a CoT ''student'' model that is fine-tuned by the generated teaching data for learning to reason about performance declines. The efficacy of this model is evaluated in a real-world scenario involving a real-time 3D rendering task with multi-Access Technologies (mATs) including WiFi, 5G, and LiFi for data transmission. Experimental results show that our approach achieves over 97% reasoning accuracy on the built test questions, confirming the validity of our collected dataset and the effectiveness of the LLM-CoT method. Our findings highlight the potential of LLMs in enhancing the reliability and efficiency of 6G networks, representing a significant advancement in the evolution of AI-native network infrastructures.

[Arxiv](https://arxiv.org/abs/2408.17097)