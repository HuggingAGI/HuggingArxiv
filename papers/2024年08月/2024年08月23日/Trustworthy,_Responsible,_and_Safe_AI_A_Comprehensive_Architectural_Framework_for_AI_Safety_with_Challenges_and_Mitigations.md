# 构建可信、负责且安全的AI系统：一个全面的AI安全框架，涵盖挑战与应对策略

发布时间：2024年08月23日

`LLM理论` `人工智能`

> Trustworthy, Responsible, and Safe AI: A Comprehensive Architectural Framework for AI Safety with Challenges and Mitigations

# 摘要

> AI安全，一个新兴且至关重要的领域，正随着AI技术的飞速发展，特别是生成式AI的突破，变得愈发重要。本文提出了一种创新的架构框架，从可信、负责任和安全三个维度深入剖析AI安全。我们详细探讨了当前AI安全研究的进展与挑战，并通过最前沿的大型语言模型实例，展示了设计和测试AI安全的新方法。旨在推动AI安全研究的发展，增强公众对数字化转型的信心。

> AI Safety is an emerging area of critical importance to the safe adoption and deployment of AI systems. With the rapid proliferation of AI and especially with the recent advancement of Generative AI (or GAI), the technology ecosystem behind the design, development, adoption, and deployment of AI systems has drastically changed, broadening the scope of AI Safety to address impacts on public safety and national security. In this paper, we propose a novel architectural framework for understanding and analyzing AI Safety; defining its characteristics from three perspectives: Trustworthy AI, Responsible AI, and Safe AI. We provide an extensive review of current research and advancements in AI safety from these perspectives, highlighting their key challenges and mitigation approaches. Through examples from state-of-the-art technologies, particularly Large Language Models (LLMs), we present innovative mechanism, methodologies, and techniques for designing and testing AI safety. Our goal is to promote advancement in AI safety research, and ultimately enhance people's trust in digital transformation.

[Arxiv](https://arxiv.org/abs/2408.12935)