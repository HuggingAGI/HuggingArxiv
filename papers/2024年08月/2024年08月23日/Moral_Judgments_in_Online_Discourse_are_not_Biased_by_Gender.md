# 网络讨论中的道德评判，性别偏见并未涉足。

发布时间：2024年08月23日

`LLM应用` `社会学` `人工智能`

> Moral Judgments in Online Discourse are not Biased by Gender

# 摘要

> 社会规范与性别角色的交织塑造了特定的性别行为，进而影响道德判断。本研究聚焦于故事主角的性别如何左右道德评判。通过分析 r/AITA 这一拥有 1700 万成员的 Reddit 社区数据，我们运用机器学习技术，对比了情节相似但主角性别不同的故事。结果显示，主角性别对道德判断的影响并不显著，除非故事涉及“友谊和关系”，此时男性主角更易受到负面评价。这一发现不仅丰富了相关研究，也暗示性别角色在特定社会情境中的影响力可能更为显著。此外，这些发现对于深入理解社会学概念至关重要，同时提醒我们，在训练大型语言模型时，需警惕数据中潜藏的偏见。

> The interaction between social norms and gender roles prescribes gender-specific behaviors that influence moral judgments. Here, we study how moral judgments are biased by the gender of the protagonist of a story. Using data from r/AITA, a Reddit community with 17 million members who share first-hand experiences seeking community judgment on their behavior, we employ machine learning techniques to match stories describing similar situations that differ only by the protagonist's gender. We find no direct causal effect of the protagonist's gender on the received moral judgments, except for stories about ``friendship and relationships'', where male protagonists receive more negative judgments. Our findings complement existing correlational studies and suggest that gender roles may exert greater influence in specific social contexts. These results have implications for understanding sociological constructs and highlight potential biases in data used to train large language models.

[Arxiv](https://arxiv.org/abs/2408.12872)