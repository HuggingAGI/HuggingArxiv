# PermitQA：风电场选址与许可领域中检索增强生成的评估基准

发布时间：2024年08月21日

`RAG`

> PermitQA: A Benchmark for Retrieval Augmented Generation in Wind Siting and Permitting domain

# 摘要

> 在NLP和文本生成的快速发展领域，RAG通过利用用户指定数据库中的信息，为提升生成文本的质量和可靠性开辟了新途径。为了评估和比较不同RAG配置的性能，基准测试至关重要。本文中，我们提出了一种基于人机协作的自动问答生成框架，用于创建领域相关的RAG基准。作为案例研究，我们介绍了PermitQA，这是首个针对风电场选址和许可领域的基准，涵盖了多个与风能环境影响相关的科学文档。我们的框架通过多样化的评估指标和多层次复杂度的问题类型，系统地评估了RAG的性能，并展示了不同模型在此基准上的表现。

> In the rapidly evolving landscape of Natural Language Processing (NLP) and text generation, the emergence of Retrieval Augmented Generation (RAG) presents a promising avenue for improving the quality and reliability of generated text by leveraging information retrieved from user specified database. Benchmarking is essential to evaluate and compare the performance of the different RAG configurations in terms of retriever and generator, providing insights into their effectiveness, scalability, and suitability for the specific domain and applications. In this paper, we present a comprehensive framework to generate a domain relevant RAG benchmark. Our framework is based on automatic question-answer generation with Human (domain experts)-AI Large Language Model (LLM) teaming. As a case study, we demonstrate the framework by introducing PermitQA, a first-of-its-kind benchmark on the wind siting and permitting domain which comprises of multiple scientific documents/reports related to environmental impact of wind energy projects. Our framework systematically evaluates RAG performance using diverse metrics and multiple question types with varying complexity level. We also demonstrate the performance of different models on our benchmark.

[Arxiv](https://arxiv.org/abs/2408.11800)