# 我们初步探索了一种集成视觉变换器与大型语言和多模态模型的多维鲁棒协同方法，用于半导体电子显微镜图像分析。

发布时间：2024年08月24日

`LLM应用` `半导体` `材料科学`

> Preliminary Investigations of a Multi-Faceted Robust and Synergistic Approach in Semiconductor Electron Micrograph Analysis: Integrating Vision Transformers with Large Language and Multimodal Models

# 摘要

> 在半导体和量子材料领域，利用电子显微镜图像进行材料特性分析至关重要。然而，传统分类方法因图像结构的复杂性而受限。本研究创新性地结合了大型语言模型（如GPT-4）的零-shot生成能力和大型多模态模型（如GPT-4视觉）的少-shot学习预测能力，通过融合图像与语言的洞察力，实现了纳米材料类别的精准预测。这一综合方法旨在为半导体制造中的自动化纳米材料识别提供高效、准确且可解释的解决方案，超越传统方法，助力高通量筛选。

> Characterizing materials using electron micrographs is crucial in areas such as semiconductors and quantum materials. Traditional classification methods falter due to the intricatestructures of these micrographs. This study introduces an innovative architecture that leverages the generative capabilities of zero-shot prompting in Large Language Models (LLMs) such as GPT-4(language only), the predictive ability of few-shot (in-context) learning in Large Multimodal Models (LMMs) such as GPT-4(V)ision, and fuses knowledge across image based and linguistic insights for accurate nanomaterial category prediction. This comprehensive approach aims to provide a robust solution for the automated nanomaterial identification task in semiconductor manufacturing, blending performance, efficiency, and interpretability. Our method surpasses conventional approaches, offering precise nanomaterial identification and facilitating high-throughput screening.

[Arxiv](https://arxiv.org/abs/2408.13621)