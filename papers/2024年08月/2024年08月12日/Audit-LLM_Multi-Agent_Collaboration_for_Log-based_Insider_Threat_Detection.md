# Audit-LLM：多代理协作，助力基于日志的内部威胁检测

发布时间：2024年08月12日

`Agent` `网络安全` `人工智能`

> Audit-LLM: Multi-Agent Collaboration for Log-based Insider Threat Detection

# 摘要

> 在内部威胁检测领域，大型语言模型（LLMs）凭借其强大的常识知识崭露头角。然而，面对多样化的活动类型和冗长的日志文件，LLMs在从海量正常活动中识别恶意行为时面临巨大挑战。加之，LLMs的忠实度幻觉问题使得其生成的结论可能与实际情况脱节，进一步增加了应用难度。为此，我们推出了Audit-LLM框架，该框架通过三个协同工作的代理来应对这些难题：Decomposer代理运用思维链推理将复杂任务拆解为易于处理的子任务；Tool Builder代理则负责为这些子任务打造可复用的工具，以突破LLMs的上下文长度限制；Executor代理最终利用这些工具得出检测结论。此外，我们还设计了基于证据的多代理辩论机制（EMAD），通过两个独立Executor之间的推理交流，不断优化结论，直至达成一致。实验结果显示，我们的方法在多个公开数据集上均超越了现有基准，显著提升了LLMs解释的忠实度。

> Log-based insider threat detection (ITD) detects malicious user activities by auditing log entries. Recently, large language models (LLMs) with strong common sense knowledge have emerged in the domain of ITD. Nevertheless, diverse activity types and overlong log files pose a significant challenge for LLMs in directly discerning malicious ones within myriads of normal activities. Furthermore, the faithfulness hallucination issue from LLMs aggravates its application difficulty in ITD, as the generated conclusion may not align with user commands and activity context. In response to these challenges, we introduce Audit-LLM, a multi-agent log-based insider threat detection framework comprising three collaborative agents: (i) the Decomposer agent, breaking down the complex ITD task into manageable sub-tasks using Chain-of-Thought (COT) reasoning;(ii) the Tool Builder agent, creating reusable tools for sub-tasks to overcome context length limitations in LLMs; and (iii) the Executor agent, generating the final detection conclusion by invoking constructed tools. To enhance conclusion accuracy, we propose a pair-wise Evidence-based Multi-agent Debate (EMAD) mechanism, where two independent Executors iteratively refine their conclusions through reasoning exchange to reach a consensus. Comprehensive experiments conducted on three publicly available ITD datasets-CERT r4.2, CERT r5.2, and PicoDomain-demonstrate the superiority of our method over existing baselines and show that the proposed EMAD significantly improves the faithfulness of explanations generated by LLMs.

[Arxiv](https://arxiv.org/abs/2408.08902)