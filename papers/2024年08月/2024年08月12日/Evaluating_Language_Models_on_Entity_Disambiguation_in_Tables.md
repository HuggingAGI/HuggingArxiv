# 探究语言模型在表格实体消歧任务中的表现

发布时间：2024年08月12日

`LLM应用` `数据分析` `人工智能`

> Evaluating Language Models on Entity Disambiguation in Tables

# 摘要

> 表格作为信息的关键载体，其含义的理解颇具挑战。近年来，语义表格解释（STI）备受瞩目，旨在通过语义注释消除表格数据的歧义。深度学习驱动的数据方法与启发式策略的结合，已成为研究热点。随着大型语言模型（LLM）的兴起，表格注释领域迎来了新方法。尽管方法多样，但缺乏统一评估，比较困难。本研究对四种顶尖方法——Alligator、Dagobah、TURL和TableLlama进行了全面评估，旨在探索它们在实体消歧任务中的表现，以期推动该领域的新研究方向。

> Tables are crucial containers of information, but understanding their meaning may be challenging. Indeed, recently, there has been a focus on Semantic Table Interpretation (STI), i.e., the task that involves the semantic annotation of tabular data to disambiguate their meaning. Over the years, there has been a surge in interest in data-driven approaches based on deep learning that have increasingly been combined with heuristic-based approaches. In the last period, the advent of Large Language Models (LLMs) has led to a new category of approaches for table annotation. The interest in this research field, characterised by multiple challenges, has led to a proliferation of approaches employing different techniques. However, these approaches have not been consistently evaluated on a common ground, making evaluation and comparison difficult. This work proposes an extensive evaluation of four state-of-the-art (SOTA) approaches - Alligator (formerly s-elBat), Dagobah, TURL, and TableLlama; the first two belong to the family of heuristic-based algorithms, while the others are respectively encoder-only and decoder-only LLMs. The primary objective is to measure the ability of these approaches to solve the entity disambiguation task, with the ultimate aim of charting new research paths in the field.

[Arxiv](https://arxiv.org/abs/2408.06423)