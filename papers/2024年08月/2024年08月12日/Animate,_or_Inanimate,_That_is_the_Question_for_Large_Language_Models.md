# 对于大型语言模型而言，是赋予生命，还是保持静态，这正是关键所在。

发布时间：2024年08月12日

`LLM理论` `人工智能` `认知科学`

> Animate, or Inanimate, That is the Question for Large Language Models

# 摘要

> 人类的认知与生命性概念密不可分，这一概念深刻影响着记忆、视觉和语言理解。尽管生命性在语言中通过动词和形容词的细微差别体现，但它也通过非语言信息得以学习和完善。我们推测，LLM在处理生命性时理解能力的局限，源于其仅依赖文本训练。本文探讨的核心问题是：LLM能否像人类一样，运用其数字智慧处理生命性？为此，我们采用提示方法进行系统分析，通过有生命、无生命、常见和陌生情境测试LLM。结果表明，尽管LLM主要基于文本训练，但在处理典型生命性实体时，它们展现出类似人类的行为。这表明LLM能够通过识别异常为有生命，无需人类所依赖的非言语认知触发器，从而适应并理解非常规情境。

> The cognitive essence of humans is deeply intertwined with the concept of animacy, which plays an essential role in shaping their memory, vision, and multi-layered language understanding. Although animacy appears in language via nuanced constraints on verbs and adjectives, it is also learned and refined through extralinguistic information. Similarly, we assume that the LLMs' limited abilities to understand natural language when processing animacy are motivated by the fact that these models are trained exclusively on text.
  Hence, the question this paper aims to answer arises: can LLMs, in their digital wisdom, process animacy in a similar way to what humans would do? We then propose a systematic analysis via prompting approaches. In particular, we probe different LLMs by prompting them using animate, inanimate, usual, and stranger contexts. Results reveal that, although LLMs have been trained predominantly on textual data, they exhibit human-like behavior when faced with typical animate and inanimate entities in alignment with earlier studies. Hence, LLMs can adapt to understand unconventional situations by recognizing oddities as animated without needing to interface with unspoken cognitive triggers humans rely on to break down animations.

[Arxiv](https://arxiv.org/abs/2408.06332)