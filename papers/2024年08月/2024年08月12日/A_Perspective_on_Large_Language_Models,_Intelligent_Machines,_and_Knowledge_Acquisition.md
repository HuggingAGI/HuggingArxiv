# 大型语言模型、智能机器与知识获取的探讨

发布时间：2024年08月12日

`LLM理论` `人工智能`

> A Perspective on Large Language Models, Intelligent Machines, and Knowledge Acquisition

# 摘要

> 大型语言模型（LLM）擅长创造合成知识，如文本、音乐和图像。然而，在抽象概念理解和推理方面，LLM 与人类能力差距显著。我们将这些议题置于人类知识获取和图灵测试的哲学框架中探讨。通过分析 GPT-4 对多领域问题的回答，我们揭示了 LLM 的局限性，尽管它能模仿人类推理，但缺乏深层理解。LLM 的回答源自广泛数据训练的模型，而人类理解则基于少数核心概念。基于此差异，我们探讨了 LLM 对人类知识学习和教育的影响。

> Large Language Models (LLMs) are known for their remarkable ability to generate synthesized 'knowledge', such as text documents, music, images, etc. However, there is a huge gap between LLM's and human capabilities for understanding abstract concepts and reasoning. We discuss these issues in a larger philosophical context of human knowledge acquisition and the Turing test. In addition, we illustrate the limitations of LLMs by analyzing GPT-4 responses to questions ranging from science and math to common sense reasoning. These examples show that GPT-4 can often imitate human reasoning, even though it lacks understanding. However, LLM responses are synthesized from a large LLM model trained on all available data. In contrast, human understanding is based on a small number of abstract concepts. Based on this distinction, we discuss the impact of LLMs on acquisition of human knowledge and education.

[Arxiv](https://arxiv.org/abs/2408.06598)