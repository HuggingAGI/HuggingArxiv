# LLM-PBE：大型语言模型数据隐私评估

发布时间：2024年08月22日

`LLM应用` `数据隐私` `人工智能`

> LLM-PBE: Assessing Data Privacy in Large Language Models

# 摘要

> 大型语言模型（LLM）在数据管理、挖掘和分析等领域的作用日益突出，但同时也引发了数据隐私的严峻挑战，尤其是训练数据无意泄露的风险。尽管这一问题至关重要，但目前缺乏对 LLM 数据隐私风险的全面评估。为此，我们推出了 LLM-PBE 工具包，专门用于系统评估 LLM 中的数据隐私风险。LLM-PBE 覆盖 LLM 全生命周期的隐私分析，整合多种攻防策略，适用于各类数据和指标。通过与多个 LLM 的深入实验，LLM-PBE 揭示了模型规模、数据特性及时效性等因素对隐私的影响。本研究不仅深化了对 LLM 隐私问题的认识，也为未来研究提供了宝贵资源。所有研究成果、资源及完整技术报告已在 https://llm-pbe.github.io/ 公开，为 LLM 隐私评估的学术与实践发展搭建了开放平台。

> Large Language Models (LLMs) have become integral to numerous domains, significantly advancing applications in data management, mining, and analysis. Their profound capabilities in processing and interpreting complex language data, however, bring to light pressing concerns regarding data privacy, especially the risk of unintentional training data leakage. Despite the critical nature of this issue, there has been no existing literature to offer a comprehensive assessment of data privacy risks in LLMs. Addressing this gap, our paper introduces LLM-PBE, a toolkit crafted specifically for the systematic evaluation of data privacy risks in LLMs. LLM-PBE is designed to analyze privacy across the entire lifecycle of LLMs, incorporating diverse attack and defense strategies, and handling various data types and metrics. Through detailed experimentation with multiple LLMs, LLM-PBE facilitates an in-depth exploration of data privacy concerns, shedding light on influential factors such as model size, data characteristics, and evolving temporal dimensions. This study not only enriches the understanding of privacy issues in LLMs but also serves as a vital resource for future research in the field. Aimed at enhancing the breadth of knowledge in this area, the findings, resources, and our full technical report are made available at https://llm-pbe.github.io/, providing an open platform for academic and practical advancements in LLM privacy assessment.

[Arxiv](https://arxiv.org/abs/2408.12787)