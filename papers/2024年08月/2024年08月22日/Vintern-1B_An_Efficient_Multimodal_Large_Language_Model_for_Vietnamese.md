# Vintern-1B：专为越南语设计的高效多模态大型语言模型

发布时间：2024年08月22日

`LLM应用` `人工智能` `多模态学习`

> Vintern-1B: An Efficient Multimodal Large Language Model for Vietnamese

# 摘要

> 本报告介绍了 Vintern-1B，一款专为越南语任务设计的 10 亿参数多模态大型语言模型。结合 Qwen2-0.5B-Instruct 语言模型与 InternViT-300M-448px 视觉模型，Vintern-1B 在 OCR、文档提取及越南语环境下的问答等应用中表现卓越。经过超过 300 万图像-问题-答案对的大规模数据集微调，该模型在多个越南语基准测试中展现出稳健性能。其紧凑体积使其轻松适配各类设备应用。同时，我们开源了多个越南语视觉问答数据集，涵盖文本与图表，均由 Gemini 1.5 Flash 创建。模型下载链接：https://huggingface.co/5CD-AI/Vintern-1B-v2。

> In this report, we introduce Vintern-1B, a reliable 1-billion-parameters multimodal large language model (MLLM) for Vietnamese language tasks. By integrating the Qwen2-0.5B-Instruct language model with the InternViT-300M-448px visual model, Vintern-1B is optimized for a range of applications, including optical character recognition (OCR), document extraction, and general question-answering in Vietnamese context. The model is fine-tuned on an extensive dataset of over 3 million image-question-answer pairs, achieving robust performance and reliable results across multiple Vietnamese language benchmarks like OpenViVQA and ViTextVQA. Vintern-1B is small enough to fit into various on-device applications easily. Additionally, we have open-sourced several Vietnamese vision question answering (VQA) datasets for text and diagrams, created with Gemini 1.5 Flash. Our models are available at: https://huggingface.co/5CD-AI/Vintern-1B-v2.

[Arxiv](https://arxiv.org/abs/2408.12480)