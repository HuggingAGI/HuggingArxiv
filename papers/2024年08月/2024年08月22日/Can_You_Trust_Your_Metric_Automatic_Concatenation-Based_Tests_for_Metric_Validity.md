# 你的指标可靠吗？通过自动连接测试来验证指标的有效性。

发布时间：2024年08月22日

`LLM应用` `人工智能` `网络安全`

> Can You Trust Your Metric? Automatic Concatenation-Based Tests for Metric Validity

# 摘要

> 设想一个系统使用有害性检测指标来筛选大型语言模型产生的不安全回答。单独分析时，该指标能准确识别并标记为高度不安全；但一旦这些提示与回答被串联，指标却误判为安全，让内容逃过滤网。研究发现，包括基于GPT的多种指标都存在这种“决策翻转”现象。更甚者，像GPT-4o这样的先进指标对输入顺序极为敏感，先出现的安全内容会让其后有害内容被忽视，反之亦然。为此，我们设计了基于自动串联的测试，旨在检验有效指标的基本特性，并在模型安全领域应用这些测试，揭示了诸多可靠性问题。

> Consider a scenario where a harmfulness detection metric is employed by a system to filter unsafe responses generated by a Large Language Model. When analyzing individual harmful and unethical prompt-response pairs, the metric correctly classifies each pair as highly unsafe, assigning the highest score. However, when these same prompts and responses are concatenated, the metric's decision flips, assigning the lowest possible score, thereby misclassifying the content as safe and allowing it to bypass the filter. In this study, we discovered that several harmfulness LLM-based metrics, including GPT-based, exhibit this decision-flipping phenomenon. Additionally, we found that even an advanced metric like GPT-4o is highly sensitive to input order. Specifically, it tends to classify responses as safe if the safe content appears first, regardless of any harmful content that follows, and vice versa. This work introduces automatic concatenation-based tests to assess the fundamental properties a valid metric should satisfy. We applied these tests in a model safety scenario to assess the reliability of harmfulness detection metrics, uncovering a number of inconsistencies.

[Arxiv](https://arxiv.org/abs/2408.12259)