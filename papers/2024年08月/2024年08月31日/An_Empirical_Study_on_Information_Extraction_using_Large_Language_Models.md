# 大型语言模型在信息提取领域的实证探索

发布时间：2024年08月31日

`LLM应用` `信息提取`

> An Empirical Study on Information Extraction using Large Language Models

# 摘要

> 类人大型语言模型，尤其是 OpenAI 的 GPT 系列中的佼佼者，已证明在众多 NLP 任务中极具价值。在信息提取这一基础 NLP 任务中，LLM 的应用探索也日益增多。本文从性能、评估标准、鲁棒性和错误类型四个维度，评估了最新版 GPT-4 的信息提取能力，并揭示了其与顶尖 IE 方法间的性能差距。为缩小这一差距，我们基于 LLM 的类人特性，提出了一系列简便的基于提示的方法，并展示了其在提升 GPT-4 信息提取能力方面的成效及待解决的问题，这些方法同样适用于其他 LLM 和 NLP 任务。

> Human-like large language models (LLMs), especially the most powerful and popular ones in OpenAI's GPT family, have proven to be very helpful for many natural language processing (NLP) related tasks. Therefore, various attempts have been made to apply LLMs to information extraction (IE), which is a fundamental NLP task that involves extracting information from unstructured plain text. To demonstrate the latest representative progress in LLMs' information extraction ability, we assess the information extraction ability of GPT-4 (the latest version of GPT at the time of writing this paper) from four perspectives: Performance, Evaluation Criteria, Robustness, and Error Types. Our results suggest a visible performance gap between GPT-4 and state-of-the-art (SOTA) IE methods. To alleviate this problem, considering the LLMs' human-like characteristics, we propose and analyze the effects of a series of simple prompt-based methods, which can be generalized to other LLMs and NLP tasks. Rich experiments show our methods' effectiveness and some of their remaining issues in improving GPT-4's information extraction ability.

[Arxiv](https://arxiv.org/abs/2409.00369)