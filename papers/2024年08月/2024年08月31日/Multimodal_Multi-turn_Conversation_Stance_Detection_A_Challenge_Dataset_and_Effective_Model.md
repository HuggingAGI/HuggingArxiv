# 多模态多轮对话立场检测：挑战数据集与高效模型

发布时间：2024年08月31日

`LLM应用` `社交媒体` `人工智能`

> Multimodal Multi-turn Conversation Stance Detection: A Challenge Dataset and Effective Model

# 摘要

> 立场检测，旨在通过社交媒体数据识别公众对特定话题的态度，是一项既重要又具挑战的任务。随着多模态社交媒体内容的增多，多模态立场检测（MSD）成为研究热点。然而，现有研究多聚焦于单个文本-图像对的立场分析，忽略了社交媒体中的多方对话情境。为此，我们推出了一个多模态多轮对话立场检测数据集（MmMtCSD），并设计了多模态大型语言模型立场检测框架（MLLM-SD），以整合文本与视觉信息进行立场识别。实验表明，MLLM-SD在多模态立场检测中表现卓越。我们期待MmMtCSD能促进立场检测技术在实际场景中的应用。

> Stance detection, which aims to identify public opinion towards specific targets using social media data, is an important yet challenging task. With the proliferation of diverse multimodal social media content including text, and images multimodal stance detection (MSD) has become a crucial research area. However, existing MSD studies have focused on modeling stance within individual text-image pairs, overlooking the multi-party conversational contexts that naturally occur on social media. This limitation stems from a lack of datasets that authentically capture such conversational scenarios, hindering progress in conversational MSD. To address this, we introduce a new multimodal multi-turn conversational stance detection dataset (called MmMtCSD). To derive stances from this challenging dataset, we propose a novel multimodal large language model stance detection framework (MLLM-SD), that learns joint stance representations from textual and visual modalities. Experiments on MmMtCSD show state-of-the-art performance of our proposed MLLM-SD approach for multimodal stance detection. We believe that MmMtCSD will contribute to advancing real-world applications of stance detection research.

[Arxiv](https://arxiv.org/abs/2409.00597)