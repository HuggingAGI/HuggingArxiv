# 大型语言模型在代码文档化中的应用：首次定量与定性双重评估

发布时间：2024年08月26日

`LLM应用` `软件开发` `人工智能`

> Using Large Language Models to Document Code: A First Quantitative and Qualitative Assessment

# 摘要

> 代码文档在软件开发中不可或缺，能提升代码的可读性和理解性。然而，因其劳动密集型特点，常被忽视。AI语言模型为自动生成代码文档提供了可能，减轻了开发者的负担。尽管已有研究探索了使用AI模型进行代码文档化的方法，但大多依赖BLEU等定量指标评估生成注释的质量，其适用性和准确性仍存疑。本文中，我们利用OpenAI GPT-3.5重新生成了23,850个代码片段的Javadoc，并进行了定量与定性评估，结合BLEU和人工评估来衡量生成注释的质量。研究发现：(i) GPT生成的文档与原始文档相比，69.7%被视为等效或仅需微调；(ii) 22.4%的注释质量优于原始注释；(iii) 定量指标如BLEU存在不一致性，高质量注释可能被不公正地扣分。

> Code documentation is vital for software development, improving readability and comprehension. However, it's often skipped due to its labor-intensive nature. AI Language Models present an opportunity to automate the generation of code documentation, easing the burden on developers. While recent studies have explored the use of such models for code documentation, most rely on quantitative metrics like BLEU to assess the quality of the generated comments. Yet, the applicability and accuracy of these metrics on this scenario remain uncertain. In this paper, we leveraged OpenAI GPT-3.5 to regenerate the Javadoc of 23,850 code snippets with methods and classes. We conducted both quantitative and qualitative assessments, employing BLEU alongside human evaluation, to assess the quality of the generated comments. Our key findings reveal that: (i) in our qualitative analyses, when the documents generated by GPT were compared with the original ones, 69.7% were considered equivalent (45.7%) or required minor changes to be equivalent (24.0%); (ii) indeed, 22.4% of the comments were rated as having superior quality than the original ones; (iii) the use of quantitative metrics is susceptible to inconsistencies, for example, comments perceived as having higher quality were unjustly penalized by the BLEU metric.

[Arxiv](https://arxiv.org/abs/2408.14007)