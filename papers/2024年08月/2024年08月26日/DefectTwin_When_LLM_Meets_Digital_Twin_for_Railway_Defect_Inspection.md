# DefectTwin：LLM 与铁路缺陷检查数字孪生的相遇

发布时间：2024年08月26日

`LLM应用` `工业维护`

> DefectTwin: When LLM Meets Digital Twin for Railway Defect Inspection

# 摘要

> 数字孪生 (DT) 通过复制实体，实现实时监控、模拟和预测性维护。随着大型语言模型 (LLM) 的进步，传统 AI 系统焕然一新，尤其在铁路缺陷检查等工业应用中潜力巨大。传统方法依赖大量缺陷样本，但样本不足易导致过拟合和泛化能力差。DefectTwin 应运而生，它结合预训练 LLM 和多模态多模型 (M^2) 管道，分析铁路视觉缺陷，无需海量样本。DefectTwin 使铁路代理能用平板电脑进行专家级分析，多模态处理器确保响应易读，即时反馈提升用户体验。M^2 LLM 在文本、图像和视频等多模态输入上精度高达 0.76-0.93，对未见缺陷的零-shot 泛化能力卓越。我们还测试了其在消费设备上的响应速度、令牌使用和实用性。DefectTwin 是首个专为铁路缺陷检查设计的 LLM 集成 DT。

> A Digital Twin (DT) replicates objects, processes, or systems for real-time monitoring, simulation, and predictive maintenance. Recent advancements like Large Language Models (LLMs) have revolutionized traditional AI systems and offer immense potential when combined with DT in industrial applications such as railway defect inspection. Traditionally, this inspection requires extensive defect samples to identify patterns, but limited samples can lead to overfitting and poor performance on unseen defects. Integrating pre-trained LLMs into DT addresses this challenge by reducing the need for vast sample data. We introduce DefectTwin, which employs a multimodal and multi-model (M^2) LLM-based AI pipeline to analyze both seen and unseen visual defects in railways. This application enables a railway agent to perform expert-level defect analysis using consumer electronics (e.g., tablets). A multimodal processor ensures responses are in a consumable format, while an instant user feedback mechanism (instaUF) enhances Quality-of-Experience (QoE). The proposed M^2 LLM outperforms existing models, achieving high precision (0.76-0.93) across multimodal inputs including text, images, and videos of pre-trained defects, and demonstrates superior zero-shot generalizability for unseen defects. We also evaluate the latency, token count, and usefulness of responses generated by DefectTwin on consumer devices. To our knowledge, DefectTwin is the first LLM-integrated DT designed for railway defect inspection.

[Arxiv](https://arxiv.org/abs/2409.06725)