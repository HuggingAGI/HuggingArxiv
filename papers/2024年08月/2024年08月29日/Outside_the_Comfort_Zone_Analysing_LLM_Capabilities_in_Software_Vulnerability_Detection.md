# 探索舒适区外：剖析 LLM 在软件漏洞检测领域的潜能

发布时间：2024年08月29日

`LLM应用` `软件工程` `网络安全`

> Outside the Comfort Zone: Analysing LLM Capabilities in Software Vulnerability Detection

# 摘要

> 随着自动化和开发周期的加速，软件漏洞数量激增。软件漏洞检测正从传统方法转向机器学习与LLMs，虽带来机遇，但也需大量计算资源。本文深入探讨LLMs在源代码漏洞检测中的潜力，对比了六款专为漏洞检测设计的开源模型与六款通用LLMs，其中三款在自编数据集上进行了微调。通过结合五个顶尖基准数据集，我们构建了一个二元分类管道，用于区分代码的脆弱性。研究发现，分类准确性在不同基准间差异显著，微调能显著提升小型LLMs的检测能力，但仅限于特定训练场景。此外，当前基准数据集的错误标记问题对模型训练与性能影响重大，引发实践层面的担忧。我们亦探讨了未来发展方向，建议优化模型训练与数据集管理策略。

> The significant increase in software production driven by automation and faster development lifecycles has resulted in a corresponding surge in software vulnerabilities. In parallel, the evolving landscape of software vulnerability detection, highlighting the shift from traditional methods to machine learning and large language models (LLMs), provides massive opportunities at the cost of resource-demanding computations. This paper thoroughly analyses LLMs' capabilities in detecting vulnerabilities within source code by testing models beyond their usual applications to study their potential in cybersecurity tasks. We evaluate the performance of six open-source models that are specifically trained for vulnerability detection against six general-purpose LLMs, three of which were further fine-tuned on a dataset that we compiled. Our dataset, alongside five state-of-the-art benchmark datasets, were used to create a pipeline to leverage a binary classification task, namely classifying code into vulnerable and non-vulnerable. The findings highlight significant variations in classification accuracy across benchmarks, revealing the critical influence of fine-tuning in enhancing the detection capabilities of small LLMs over their larger counterparts, yet only in the specific scenarios in which they were trained. Further experiments and analysis also underscore the issues with current benchmark datasets, particularly around mislabeling and their impact on model training and performance, which raises concerns about the current state of practice. We also discuss the road ahead in the field suggesting strategies for improved model training and dataset curation.

[Arxiv](https://arxiv.org/abs/2408.16400)