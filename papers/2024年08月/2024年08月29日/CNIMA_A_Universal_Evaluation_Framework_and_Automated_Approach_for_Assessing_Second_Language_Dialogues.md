# CNIMA：一个通用的第二语言对话评估框架，结合自动化评估手段。

发布时间：2024年08月29日

`LLM应用` `语言学习`

> CNIMA: A Universal Evaluation Framework and Automated Approach for Assessing Second Language Dialogues

# 摘要

> 我们创建了 CNIMA 数据集，包含 10K 中文二语对话，并采用专为英语二语对话设计的评估框架进行标注，涵盖微观互动细节和宏观交互能力。实验证实该框架跨语言稳健，揭示了微观与宏观特征间的普遍及语言特异关系。进而，我们提出自动化评估方法，性能卓越，为二语评估领域带来创新工具。此系统基于大型语言模型，易于扩展至其他语种，无需大量标注数据。

> We develop CNIMA (Chinese Non-Native Interactivity Measurement and Automation), a Chinese-as-a-second-language labelled dataset with 10K dialogues. We annotate CNIMA using an evaluation framework -- originally introduced for English-as-a-second-language dialogues -- that assesses micro-level features (e.g.\ backchannels) and macro-level interactivity labels (e.g.\ topic management) and test the framework's transferability from English to Chinese. We found the framework robust across languages and revealed universal and language-specific relationships between micro-level and macro-level features. Next, we propose an approach to automate the evaluation and find strong performance, creating a new tool for automated second language assessment. Our system can be adapted to other languages easily as it uses large language models and as such does not require large-scale annotated training data.

[Arxiv](https://arxiv.org/abs/2408.16518)