# 探索大型语言模型文本生成的理论与方法论框架

发布时间：2024年08月29日

`LLM理论` `语言学` `人工智能`

> Theoretical and Methodological Framework for Studying Texts Produced by Large Language Models

# 摘要

> 本文从量化语言学视角出发，深入探讨了研究大型语言模型（LLM）及其生成文本的诸多挑战。我们基于一个理论框架，区分了LLM的基质性质与其模拟实体。文章强调，对模型应采取严格的非拟人化态度，并审慎地将研究人类语言的方法应用于这些模拟实体。尽管NLP领域聚焦于模型本身及其架构、评估与性能提升，我们量化语言学家则应致力于构建关于LLM生成文本特征、与人类文本差异及模拟实体属性的坚实理论。同时，我们还需探索LLM在研究人类语言文化中的潜在价值。

> This paper addresses the conceptual, methodological and technical challenges in studying large language models (LLMs) and the texts they produce from a quantitative linguistics perspective. It builds on a theoretical framework that distinguishes between the LLM as a substrate and the entities the model simulates. The paper advocates for a strictly non-anthropomorphic approach to models while cautiously applying methodologies used in studying human linguistic behavior to the simulated entities. While natural language processing researchers focus on the models themselves, their architecture, evaluation, and methods for improving performance, we as quantitative linguists should strive to build a robust theory concerning the characteristics of texts produced by LLMs, how they differ from human-produced texts, and the properties of simulated entities. Additionally, we should explore the potential of LLMs as an instrument for studying human culture, of which language is an integral part.

[Arxiv](https://arxiv.org/abs/2408.16740)