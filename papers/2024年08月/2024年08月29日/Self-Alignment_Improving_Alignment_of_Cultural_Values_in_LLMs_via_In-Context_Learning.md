# 自我对齐：借助上下文学习，优化 LLM 中文化价值观的契合度

发布时间：2024年08月29日

`LLM应用` `文化研究` `人工智能`

> Self-Alignment: Improving Alignment of Cultural Values in LLMs via In-Context Learning

# 摘要

> 随着大型语言模型 (LLM) 与所编码文化价值观的一致性问题日益凸显，本研究探讨了在推理阶段利用现有文化价值观知识调整模型响应的可能性。我们提出了一种简便且经济的方法，结合上下文学习 (ICL) 和人类调查数据，成功提升了包括英语及多语言模型在内的五个模型与文化价值观的一致性。尤为关键的是，该方法不仅适用于非英语测试语言，还能增强与多元文化国家价值观的一致性。

> Improving the alignment of Large Language Models (LLMs) with respect to the cultural values that they encode has become an increasingly important topic. In this work, we study whether we can exploit existing knowledge about cultural values at inference time to adjust model responses to cultural value probes. We present a simple and inexpensive method that uses a combination of in-context learning (ICL) and human survey data, and show that we can improve the alignment to cultural values across 5 models that include both English-centric and multilingual LLMs. Importantly, we show that our method could prove useful in test languages other than English and can improve alignment to the cultural values that correspond to a range of culturally diverse countries.

[Arxiv](https://arxiv.org/abs/2408.16482)