# 大型语言模型在在线极端主义研究中的评估：聚焦识别、解释与新知识的挖掘

发布时间：2024年08月29日

`LLM应用` `社交媒体`

> Assessing Large Language Models for Online Extremism Research: Identification, Explanation, and New Knowledge

# 摘要

> 美国暴力极端主义的激增，催生了自动化工具的需求，以遏制极端主义意识形态在网络上的蔓延。本研究聚焦于双向编码器表示转换器（BERT）与生成预训练转换器（GPT）在识别和分类国内在线极端主义内容中的效能。我们搜集了带有“极右”与“极左”标签的社交媒体帖子，并人工区分其是否含有极端主义倾向。依据定义框架，极端主义内容被细分为五个类别。BERT模型的评估基于训练数据量及跨类别的知识迁移。同时，我们对比了GPT 3.5与GPT 4在不同提示策略下的表现：从简单到专业。结果表明，GPT模型在精细提示下通常表现更佳，但过于繁琐的提示反而可能降低效率。GPT 3.5擅长处理极左内容，而GPT 4则在极右内容上更为出色。大型语言模型，尤其是GPT系列，在无需预训练的环境下，已显示出超越传统BERT模型的潜力。未来研究应深入人机协作，以期在极端主义内容检测领域，开发出更为迅捷、省力且准确无误的方法。

> The United States has experienced a significant increase in violent extremism, prompting the need for automated tools to detect and limit the spread of extremist ideology online. This study evaluates the performance of Bidirectional Encoder Representations from Transformers (BERT) and Generative Pre-Trained Transformers (GPT) in detecting and classifying online domestic extremist posts. We collected social media posts containing "far-right" and "far-left" ideological keywords and manually labeled them as extremist or non-extremist. Extremist posts were further classified into one or more of five contributing elements of extremism based on a working definitional framework. The BERT model's performance was evaluated based on training data size and knowledge transfer between categories. We also compared the performance of GPT 3.5 and GPT 4 models using different prompts: naïve, layperson-definition, role-playing, and professional-definition. Results showed that the best performing GPT models outperformed the best performing BERT models, with more detailed prompts generally yielding better results. However, overly complex prompts may impair performance. Different versions of GPT have unique sensitives to what they consider extremist. GPT 3.5 performed better at classifying far-left extremist posts, while GPT 4 performed better at classifying far-right extremist posts. Large language models, represented by GPT models, hold significant potential for online extremism classification tasks, surpassing traditional BERT models in a zero-shot setting. Future research should explore human-computer interactions in optimizing GPT models for extremist detection and classification tasks to develop more efficient (e.g., quicker, less effort) and effective (e.g., fewer errors or mistakes) methods for identifying extremist content.

[Arxiv](https://arxiv.org/abs/2408.16749)