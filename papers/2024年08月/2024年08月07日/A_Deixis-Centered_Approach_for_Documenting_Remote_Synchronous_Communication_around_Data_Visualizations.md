# 聚焦指示语，探索数据可视化中的远程同步沟通记录方法

发布时间：2024年08月07日

`LLM应用` `数据可视化` `协作分析`

> A Deixis-Centered Approach for Documenting Remote Synchronous Communication around Data Visualizations

# 摘要

> 指称性手势，即语言学中的指示，在数据可视化交流中至关重要。然而，这些手势在记录数据分析会议时往往被忽略。例如，文字记录无法捕捉手势，视频记录也可能无法充分捕捉或强调它们。为此，我们提出了一种创新方法，将指示视为首要元素，通过捕捉基于光标的 gestural 数据和音频，并将其转换为交互式文档。我们利用大型语言模型识别与手势对应的词汇，并在生成的交互式文档中创建基于上下文的注释。通过用户研究，我们发现参与者更偏爱这种自动化交互式文档记录，而非传统录音、文字记录或手动笔记。此外，我们还从参与者的行动中提炼出基于光标的指示性手势的初步分类，为未来在协作数据分析场景中更好地利用这些手势提供了可能。

> Referential gestures, or as termed in linguistics, deixis, are an essential part of communication around data visualizations. Despite their importance, such gestures are often overlooked when documenting data analysis meetings. Transcripts, for instance, fail to capture gestures, and video recordings may not adequately capture or emphasize them. We introduce a novel method for documenting collaborative data meetings that treats deixis as a first-class citizen. Our proposed framework captures cursor-based gestural data along with audio and converts them into interactive documents. The framework leverages a large language model to identify word correspondences with gestures. These identified references are used to create context-based annotations in the resulting interactive document. We assess the effectiveness of our proposed method through a user study, finding that participants preferred our automated interactive documentation over recordings, transcripts, and manual note-taking. Furthermore, we derive a preliminary taxonomy of cursor-based deictic gestures from participant actions during the study. This taxonomy offers further opportunities for better utilizing cursor-based deixis in collaborative data analysis scenarios.

[Arxiv](https://arxiv.org/abs/2408.04041)