# 利用软反事实技术评估可解释AI场景

发布时间：2024年08月08日

`LLM应用` `人工智能`

> SCENE: Evaluating Explainable AI Techniques Using Soft Counterfactuals

# 摘要

> 可解释的人工智能 (XAI) 对于提升 AI 模型的透明度和责任性至关重要，尤其是在 NLP 任务中。本文引入了 SCENE，一种新颖的评估方法，利用 LLM 以零-shot 方式生成软反事实解释。通过基于标记的替换，SCENE 创建了上下文适当且语义上有意义的软反事实，无需广泛微调。SCENE 采用 Validitysoft 和 Csoft 指标，评估模型无关的 XAI 方法在文本分类任务中的有效性。应用于 CNN、RNN 和 BERT 架构时，SCENE 揭示了各种 XAI 技术的优势与局限。

> Explainable Artificial Intelligence (XAI) is essential for enhancing the transparency and accountability of AI models, especially in natural language processing (NLP) tasks. This paper introduces SCENE (Soft Counterfactual Evaluation for Natural language Explainability), a novel evaluation method that leverages large language models (LLMs) to generate Soft Counterfactual explanations in a zero-shot manner. By focusing on token-based substitutions, SCENE creates contextually appropriate and seman-tically meaningful Soft Counterfactuals without extensive fine-tuning. SCENE adopts Validitysoft and Csoft metrics to evaluate the effectiveness of model-agnostic XAI methods in text classification tasks. Applied to CNN, RNN, and BERT architectures, SCENE provides valuable insights into the strengths and limitations of various XAI techniques.

[Arxiv](https://arxiv.org/abs/2408.04575)