# mPLUG-Owl3：探索多模态大型语言模型中的长图像序列理解

发布时间：2024年08月08日

`LLM应用` `计算机视觉` `人工智能`

> mPLUG-Owl3: Towards Long Image-Sequence Understanding in Multi-Modal Large Language Models

# 摘要

> 多模态大型语言模型 (MLLMs) 在处理单图像任务方面表现出色，但在长图像序列建模上仍面临挑战。为此，我们推出了多功能模型 mPLUG-Owl3，它通过整合检索的图像-文本知识、交错的图像-文本和长视频，提升了长序列理解能力。我们设计了超注意力块，有效融合视觉与语言，优化多图像场景处理。实验显示，mPLUG-Owl3 在同类模型中性能领先。我们还引入了“干扰抵抗”评估，测试模型在复杂环境下的专注力。mPLUG-Owl3 在处理超长视觉序列时表现卓越，有望推动多模态大型语言模型的发展。

> Multi-modal Large Language Models (MLLMs) have demonstrated remarkable capabilities in executing instructions for a variety of single-image tasks. Despite this progress, significant challenges remain in modeling long image sequences. In this work, we introduce the versatile multi-modal large language model, mPLUG-Owl3, which enhances the capability for long image-sequence understanding in scenarios that incorporate retrieved image-text knowledge, interleaved image-text, and lengthy videos. Specifically, we propose novel hyper attention blocks to efficiently integrate vision and language into a common language-guided semantic space, thereby facilitating the processing of extended multi-image scenarios. Extensive experimental results suggest that mPLUG-Owl3 achieves state-of-the-art performance among models with a similar size on single-image, multi-image, and video benchmarks. Moreover, we propose a challenging long visual sequence evaluation named Distractor Resistance to assess the ability of models to maintain focus amidst distractions. Finally, with the proposed architecture, mPLUG-Owl3 demonstrates outstanding performance on ultra-long visual sequence inputs. We hope that mPLUG-Owl3 can contribute to the development of more efficient and powerful multimodal large language models.

[Arxiv](https://arxiv.org/abs/2408.04840)