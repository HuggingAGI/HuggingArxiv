# 动态雾计算助力医疗应用中LLM的高效执行

发布时间：2024年08月08日

`LLM应用` `数字健康`

> Dynamic Fog Computing for Enhanced LLM Execution in Medical Applications

# 摘要

> 大型语言模型（LLM）在处理海量异构数据方面的能力，为提升数据驱动的医疗服务带来了巨大潜力。但受保护的健康信息（PHI）的敏感性，使得数据隐私和远程LLM平台的信任问题备受关注。同时，基于云的AI服务成本高昂，限制了其普及。为此，我们提出将LLM的运行环境从集中的云端转向去中心化的雾计算架构，以在用户设备或本地网络的雾层等更可信的环境中执行LLM，从而缓解隐私、信任及经济方面的挑战。此外，我们推出了开源框架SpeziLLM，旨在简化不同LLM执行层的整合，并降低其在数字健康应用中的集成难度。通过六个数字健康应用的案例，我们展示了SpeziLLM在多样医疗场景中的广泛适用性和灵活性。

> The ability of large language models (LLMs) to transform, interpret, and comprehend vast quantities of heterogeneous data presents a significant opportunity to enhance data-driven care delivery. However, the sensitive nature of protected health information (PHI) raises valid concerns about data privacy and trust in remote LLM platforms. In addition, the cost associated with cloud-based artificial intelligence (AI) services continues to impede widespread adoption. To address these challenges, we propose a shift in the LLM execution environment from opaque, centralized cloud providers to a decentralized and dynamic fog computing architecture. By executing open-weight LLMs in more trusted environments, such as the user's edge device or a fog layer within a local network, we aim to mitigate the privacy, trust, and financial challenges associated with cloud-based LLMs. We further present SpeziLLM, an open-source framework designed to facilitate rapid and seamless leveraging of different LLM execution layers and lowering barriers to LLM integration in digital health applications. We demonstrate SpeziLLM's broad applicability across six digital health applications, showcasing its versatility in various healthcare settings.

[Arxiv](https://arxiv.org/abs/2408.04680)