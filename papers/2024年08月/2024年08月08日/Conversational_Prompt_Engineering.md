# 对话式提示设计

发布时间：2024年08月08日

`LLM应用` `软件工程` `人工智能`

> Conversational Prompt Engineering

# 摘要

> 提示是人与大型语言模型交流的桥梁。为了引导LLM产出理想结果，信息丰富的提示不可或缺。但提示工程往往既繁琐又耗时，且需深厚专业知识，限制了其普及。为此，我们推出了对话式提示工程（CPE），一款用户友好工具，助您为特定任务量身定制提示。CPE通过聊天模型与您简短互动，助您清晰表达输出偏好，并融入提示之中。整个过程分两步：首先，模型基于您提供的未标记数据，生成问题并根据您的回答调整初始指令；接着，模型展示指令输出，并根据您的反馈进一步优化。最终，您将获得一个少样本提示，其中包含您认可的输出作为示例。在摘要任务中的用户研究显示，CPE能高效创建个性化且表现卓越的提示。研究结果还表明，CPE生成的零样本提示与更长的少样本提示效果相当，特别适用于处理大量重复文本任务的场景，显著节省时间和精力。

> Prompts are how humans communicate with LLMs. Informative prompts are essential for guiding LLMs to produce the desired output. However, prompt engineering is often tedious and time-consuming, requiring significant expertise, limiting its widespread use. We propose Conversational Prompt Engineering (CPE), a user-friendly tool that helps users create personalized prompts for their specific tasks. CPE uses a chat model to briefly interact with users, helping them articulate their output preferences and integrating these into the prompt. The process includes two main stages: first, the model uses user-provided unlabeled data to generate data-driven questions and utilize user responses to shape the initial instruction. Then, the model shares the outputs generated by the instruction and uses user feedback to further refine the instruction and the outputs. The final result is a few-shot prompt, where the outputs approved by the user serve as few-shot examples. A user study on summarization tasks demonstrates the value of CPE in creating personalized, high-performing prompts. The results suggest that the zero-shot prompt obtained is comparable to its - much longer - few-shot counterpart, indicating significant savings in scenarios involving repetitive tasks with large text volumes.

[Arxiv](https://arxiv.org/abs/2408.04560)