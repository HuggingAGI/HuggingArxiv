# 2024年08月

2024年08月27日

- [AAVENUE: Detecting LLM Biases on NLU Tasks in AAVE via a Novel Benchmark](2024年08月27日/AAVENUE_Detecting_LLM_Biases_on_NLU_Tasks_in_AAVE_via_a_Novel_Benchmark.md)

    - [翻译: AAVENUE 基准测试：揭示 LLM 在 AAVE 语境下 NLU 任务的偏差](2024年08月27日/AAVENUE_Detecting_LLM_Biases_on_NLU_Tasks_in_AAVE_via_a_Novel_Benchmark.md)

- [A global AI community requires language-diverse publishing](2024年08月27日/A_global_AI_community_requires_language-diverse_publishing.md)

    - [翻译: 为了构建一个全球性的AI社区，我们需要推动语言多样化的出版物。](2024年08月27日/A_global_AI_community_requires_language-diverse_publishing.md)

- [A Survey of Large Language Models for European Languages](2024年08月27日/A_Survey_of_Large_Language_Models_for_European_Languages.md)

    - [翻译: 欧洲语言大型语言模型综述](2024年08月27日/A_Survey_of_Large_Language_Models_for_European_Languages.md)

- [BaichuanSEED: Sharing the Potential of ExtensivE Data Collection and Deduplication by Introducing a Competitive Large Language Model Baseline](2024年08月27日/BaichuanSEED_Sharing_the_Potential_of_ExtensivE_Data_Collection_and_Deduplication_by_Introducing_a_Competitive_Large_Language_Model_Baseline.md)

    - [翻译: BaichuanSEED 项目旨在展示通过引入竞争性大型语言模型基线，实现大规模数据收集与去重的技术潜力。](2024年08月27日/BaichuanSEED_Sharing_the_Potential_of_ExtensivE_Data_Collection_and_Deduplication_by_Introducing_a_Competitive_Large_Language_Model_Baseline.md)

- [Can Unconfident LLM Annotations Be Used for Confident Conclusions?](2024年08月27日/Can_Unconfident_LLM_Annotations_Be_Used_for_Confident_Conclusions.md)

    - [翻译: LLM 的不确定注释，能否转化为确凿结论？](2024年08月27日/Can_Unconfident_LLM_Annotations_Be_Used_for_Confident_Conclusions.md)

- [Constraining Participation: Affordances of Feedback Features in Interfaces to Large Language Models](2024年08月27日/Constraining_Participation_Affordances_of_Feedback_Features_in_Interfaces_to_Large_Language_Models.md)

    - [翻译: 大型语言模型界面中的反馈功能，如何限制用户参与，是我们探讨的重点。](2024年08月27日/Constraining_Participation_Affordances_of_Feedback_Features_in_Interfaces_to_Large_Language_Models.md)

- [DocLayLLM: An Efficient and Effective Multi-modal Extension of Large Language Models for Text-rich Document Understanding](2024年08月27日/DocLayLLM_An_Efficient_and_Effective_Multi-modal_Extension_of_Large_Language_Models_for_Text-rich_Document_Understanding.md)

    - [翻译: DocLayLLM 是一款高效且有效的多模态扩展，专为理解富含文本的文档而设计，依托于大型语言模型。](2024年08月27日/DocLayLLM_An_Efficient_and_Effective_Multi-modal_Extension_of_Large_Language_Models_for_Text-rich_Document_Understanding.md)

- [Generative Verifiers: Reward Modeling as Next-Token Prediction](2024年08月27日/Generative_Verifiers_Reward_Modeling_as_Next-Token_Prediction.md)

    - [翻译: 生成验证器：将奖励建模视为下一个标记预测](2024年08月27日/Generative_Verifiers_Reward_Modeling_as_Next-Token_Prediction.md)

- [HPT++: Hierarchically Prompting Vision-Language Models with Multi-Granularity Knowledge Generation and Improved Structure Modeling](2024年08月27日/HPT++_Hierarchically_Prompting_Vision-Language_Models_with_Multi-Granularity_Knowledge_Generation_and_Improved_Structure_Modeling.md)

    - [翻译: HPT++：结合多粒度知识生成与优化结构建模，提升视觉-语言模型的分层提示效果](2024年08月27日/HPT++_Hierarchically_Prompting_Vision-Language_Models_with_Multi-Granularity_Knowledge_Generation_and_Improved_Structure_Modeling.md)

- [Inverse-Q*: Token Level Reinforcement Learning for Aligning Large Language Models Without Preference Data](2024年08月27日/Inverse-Q_Token_Level_Reinforcement_Learning_for_Aligning_Large_Language_Models_Without_Preference_Data.md)

    - [翻译: Inverse-Q*：一种无需偏好数据即可对齐大型语言模型的令牌级强化学习方法](2024年08月27日/Inverse-Q_Token_Level_Reinforcement_Learning_for_Aligning_Large_Language_Models_Without_Preference_Data.md)

- [Measuring text summarization factuality using atomic facts entailment metrics in the context of retrieval augmented generation](2024年08月27日/Measuring_text_summarization_factuality_using_atomic_facts_entailment_metrics_in_the_context_of_retrieval_augmented_generation.md)

    - [翻译: 在检索增强生成的背景下，通过原子事实蕴含度量来评估文本摘要的事实性。](2024年08月27日/Measuring_text_summarization_factuality_using_atomic_facts_entailment_metrics_in_the_context_of_retrieval_augmented_generation.md)

- [SpikingSSMs: Learning Long Sequences with Sparse and Parallel Spiking State Space Models](2024年08月27日/SpikingSSMs_Learning_Long_Sequences_with_Sparse_and_Parallel_Spiking_State_Space_Models.md)

    - [翻译: SpikingSSMs：利用稀疏并行的尖峰状态空间模型，高效学习长序列。](2024年08月27日/SpikingSSMs_Learning_Long_Sequences_with_Sparse_and_Parallel_Spiking_State_Space_Models.md)

- [Strategic Optimization and Challenges of Large Language Models in Object-Oriented Programming](2024年08月27日/Strategic_Optimization_and_Challenges_of_Large_Language_Models_in_Object-Oriented_Programming.md)

    - [翻译: 面向对象编程领域，大型语言模型的战略优化及其所面临的挑战](2024年08月27日/Strategic_Optimization_and_Challenges_of_Large_Language_Models_in_Object-Oriented_Programming.md)

- [The Mamba in the Llama: Distilling and Accelerating Hybrid Models](2024年08月27日/The_Mamba_in_the_Llama_Distilling_and_Accelerating_Hybrid_Models.md)

    - [翻译: 《羊驼中的曼巴》：提炼与加速混合模型](2024年08月27日/The_Mamba_in_the_Llama_Distilling_and_Accelerating_Hybrid_Models.md)

- [X-Reflect: Cross-Reflection Prompting for Multimodal Recommendation](2024年08月27日/X-Reflect_Cross-Reflection_Prompting_for_Multimodal_Recommendation.md)

    - [翻译: X-Reflect：多模态推荐中的交叉反射提示技术](2024年08月27日/X-Reflect_Cross-Reflection_Prompting_for_Multimodal_Recommendation.md)

2024年08月05日

- [A Framework for Fine-Tuning LLMs using Heterogeneous Feedback](2024年08月05日/A_Framework_for_Fine-Tuning_LLMs_using_Heterogeneous_Feedback.md)

    - [翻译: 基于异质反馈微调 LLMs 的框架](2024年08月05日/A_Framework_for_Fine-Tuning_LLMs_using_Heterogeneous_Feedback.md)

- [A Novel Hybrid Approach for Tornado Prediction in the United States: Kalman-Convolutional BiLSTM with Multi-Head Attention](2024年08月05日/A_Novel_Hybrid_Approach_for_Tornado_Prediction_in_the_United_States_Kalman-Convolutional_BiLSTM_with_Multi-Head_Attention.md)

    - [翻译: 美国龙卷风预测的新颖混合策略：结合卡尔曼滤波、卷积 BiLSTM 及多头注意力机制](2024年08月05日/A_Novel_Hybrid_Approach_for_Tornado_Prediction_in_the_United_States_Kalman-Convolutional_BiLSTM_with_Multi-Head_Attention.md)

- [Body of Her: A Preliminary Study on End-to-End Humanoid Agent](2024年08月05日/Body_of_Her_A_Preliminary_Study_on_End-to-End_Humanoid_Agent.md)

    - [翻译: 《她的躯体》：一项针对端到端人形代理的初步探索](2024年08月05日/Body_of_Her_A_Preliminary_Study_on_End-to-End_Humanoid_Agent.md)

- [Can Reinforcement Learning Unlock the Hidden Dangers in Aligned Large Language Models?](2024年08月05日/Can_Reinforcement_Learning_Unlock_the_Hidden_Dangers_in_Aligned_Large_Language_Models.md)

    - [翻译: 强化学习能否揭露对齐大型语言模型中的潜在风险？](2024年08月05日/Can_Reinforcement_Learning_Unlock_the_Hidden_Dangers_in_Aligned_Large_Language_Models.md)

- [Caution for the Environment: Multimodal Agents are Susceptible to Environmental Distractions](2024年08月05日/Caution_for_the_Environment_Multimodal_Agents_are_Susceptible_to_Environmental_Distractions.md)

    - [翻译: 环境警报：多模态智能体易受外界干扰影响](2024年08月05日/Caution_for_the_Environment_Multimodal_Agents_are_Susceptible_to_Environmental_Distractions.md)

- [DanModCap: Designing a Danmaku Moderation Tool for Video-Sharing Platforms that Leverages Impact Captions](2024年08月05日/DanModCap_Designing_a_Danmaku_Moderation_Tool_for_Video-Sharing_Platforms_that_Leverages_Impact_Captions.md)

    - [翻译: DanModCap：设计一款结合影响字幕的视频分享平台弹幕管理工具](2024年08月05日/DanModCap_Designing_a_Danmaku_Moderation_Tool_for_Video-Sharing_Platforms_that_Leverages_Impact_Captions.md)

- [Development of REGAI: Rubric Enabled Generative Artificial Intelligence](2024年08月05日/Development_of_REGAI_Rubric_Enabled_Generative_Artificial_Intelligence.md)

    - [翻译: REGAI 的研发：赋能生成式人工智能的 Rubric 技术](2024年08月05日/Development_of_REGAI_Rubric_Enabled_Generative_Artificial_Intelligence.md)

- [Evaluating and Enhancing LLMs Agent based on Theory of Mind in Guandan: A Multi-Player Cooperative Game under Imperfect Information](2024年08月05日/Evaluating_and_Enhancing_LLMs_Agent_based_on_Theory_of_Mind_in_Guandan_A_Multi-Player_Cooperative_Game_under_Imperfect_Information.md)

    - [翻译: 在不完全信息的多人合作游戏中，我们评估并增强了基于心智理论的关丹大型语言模型代理。](2024年08月05日/Evaluating_and_Enhancing_LLMs_Agent_based_on_Theory_of_Mind_in_Guandan_A_Multi-Player_Cooperative_Game_under_Imperfect_Information.md)

- [Evaluating Large Language Models for Automatic Register Transfer Logic Generation via High-Level Synthesis](2024年08月05日/Evaluating_Large_Language_Models_for_Automatic_Register_Transfer_Logic_Generation_via_High-Level_Synthesis.md)

    - [翻译: 评估大型语言模型在高级综合中自动生成寄存器传输逻辑的能力](2024年08月05日/Evaluating_Large_Language_Models_for_Automatic_Register_Transfer_Logic_Generation_via_High-Level_Synthesis.md)

- [From LLMs to LLM-based Agents for Software Engineering: A Survey of Current, Challenges and Future](2024年08月05日/From_LLMs_to_LLM-based_Agents_for_Software_Engineering_A_Survey_of_Current,_Challenges_and_Future.md)

    - [翻译: 探索从 LLM 到基于 LLM 的软件工程代理的现状、挑战与未来展望](2024年08月05日/From_LLMs_to_LLM-based_Agents_for_Software_Engineering_A_Survey_of_Current,_Challenges_and_Future.md)

- [Hide and Seek: Fingerprinting Large Language Models with Evolutionary Learning](2024年08月05日/Hide_and_Seek_Fingerprinting_Large_Language_Models_with_Evolutionary_Learning.md)

    - [翻译: 大型语言模型的“捉迷藏”：借助进化学习进行指纹识别](2024年08月05日/Hide_and_Seek_Fingerprinting_Large_Language_Models_with_Evolutionary_Learning.md)

- [Intermediate direct preference optimization](2024年08月05日/Intermediate_direct_preference_optimization.md)

    - [翻译: 中间层直接偏好优化](2024年08月05日/Intermediate_direct_preference_optimization.md)

- [Language Model Can Listen While Speaking](2024年08月05日/Language_Model_Can_Listen_While_Speaking.md)

    - [翻译: 语言模型边说边听，功能非凡。](2024年08月05日/Language_Model_Can_Listen_While_Speaking.md)

- [Let Me Speak Freely? A Study on the Impact of Format Restrictions on Performance of Large Language Models](2024年08月05日/Let_Me_Speak_Freely_A_Study_on_the_Impact_of_Format_Restrictions_on_Performance_of_Large_Language_Models.md)

    - [翻译: 自由表达之难：探究格式限制如何影响大型语言模型的表现](2024年08月05日/Let_Me_Speak_Freely_A_Study_on_the_Impact_of_Format_Restrictions_on_Performance_of_Large_Language_Models.md)

- [Leveraging Inter-Chunk Interactions for Enhanced Retrieval in Large Language Model-Based Question Answering](2024年08月05日/Leveraging_Inter-Chunk_Interactions_for_Enhanced_Retrieval_in_Large_Language_Model-Based_Question_Answering.md)

    - [翻译: 通过挖掘大型语言模型问答系统中的块间交互，我们旨在提升检索效率。](2024年08月05日/Leveraging_Inter-Chunk_Interactions_for_Enhanced_Retrieval_in_Large_Language_Model-Based_Question_Answering.md)

- [Leveraging the Power of LLMs: A Fine-Tuning Approach for High-Quality Aspect-Based Summarization](2024年08月05日/Leveraging_the_Power_of_LLMs_A_Fine-Tuning_Approach_for_High-Quality_Aspect-Based_Summarization.md)

    - [翻译: 借助 LLM 的强大能力，我们提出了一种微调方法，旨在实现高质量的基于方面的总结。](2024年08月05日/Leveraging_the_Power_of_LLMs_A_Fine-Tuning_Approach_for_High-Quality_Aspect-Based_Summarization.md)

- [MedTrinity-25M: A Large-scale Multimodal Dataset with Multigranular Annotations for Medicine](2024年08月05日/MedTrinity-25M_A_Large-scale_Multimodal_Dataset_with_Multigranular_Annotations_for_Medicine.md)

    - [翻译: MedTrinity-25M 是一个专为医学研究设计的大规模多模态数据集，包含多粒度注释，为医学领域的研究提供了丰富的资源。](2024年08月05日/MedTrinity-25M_A_Large-scale_Multimodal_Dataset_with_Multigranular_Annotations_for_Medicine.md)

- [MMIU: Multimodal Multi-image Understanding for Evaluating Large Vision-Language Models](2024年08月05日/MMIU_Multimodal_Multi-image_Understanding_for_Evaluating_Large_Vision-Language_Models.md)

    - [翻译: MMIU：探索多模态多图像理解，旨在评估大型视觉-语言模型的性能。](2024年08月05日/MMIU_Multimodal_Multi-image_Understanding_for_Evaluating_Large_Vision-Language_Models.md)

- [Multistain Pretraining for Slide Representation Learning in Pathology](2024年08月05日/Multistain_Pretraining_for_Slide_Representation_Learning_in_Pathology.md)

    - [翻译: 多重染色预训练：病理学幻灯片表示学习的新篇章](2024年08月05日/Multistain_Pretraining_for_Slide_Representation_Learning_in_Pathology.md)

- [Progressively Selective Label Enhancement for Language Model Alignment](2024年08月05日/Progressively_Selective_Label_Enhancement_for_Language_Model_Alignment.md)

    - [翻译: 语言模型对齐的逐步选择性标签增强](2024年08月05日/Progressively_Selective_Label_Enhancement_for_Language_Model_Alignment.md)

- [RAG Foundry: A Framework for Enhancing LLMs for Retrieval Augmented Generation](2024年08月05日/RAG_Foundry_A_Framework_for_Enhancing_LLMs_for_Retrieval_Augmented_Generation.md)

    - [翻译: RAG Foundry：一款专为提升大型语言模型在检索增强生成方面的框架](2024年08月05日/RAG_Foundry_A_Framework_for_Enhancing_LLMs_for_Retrieval_Augmented_Generation.md)

- [ReDel: A Toolkit for LLM-Powered Recursive Multi-Agent Systems](2024年08月05日/ReDel_A_Toolkit_for_LLM-Powered_Recursive_Multi-Agent_Systems.md)

    - [翻译: ReDel：一款专为 LLM 驱动的递归多智能体系统设计的工具包](2024年08月05日/ReDel_A_Toolkit_for_LLM-Powered_Recursive_Multi-Agent_Systems.md)

- [REVISION: Rendering Tools Enable Spatial Fidelity in Vision-Language Models](2024年08月05日/REVISION_Rendering_Tools_Enable_Spatial_Fidelity_in_Vision-Language_Models.md)

    - [翻译: 修订版：渲染工具助力视觉-语言模型实现空间保真](2024年08月05日/REVISION_Rendering_Tools_Enable_Spatial_Fidelity_in_Vision-Language_Models.md)

- [SEAS: Self-Evolving Adversarial Safety Optimization for Large Language Models](2024年08月05日/SEAS_Self-Evolving_Adversarial_Safety_Optimization_for_Large_Language_Models.md)

    - [翻译: SEAS：大型语言模型的自我进化对抗安全优化方案](2024年08月05日/SEAS_Self-Evolving_Adversarial_Safety_Optimization_for_Large_Language_Models.md)

- [Towards Coarse-grained Visual Language Navigation Task Planning Enhanced by Event Knowledge Graph](2024年08月05日/Towards_Coarse-grained_Visual_Language_Navigation_Task_Planning_Enhanced_by_Event_Knowledge_Graph.md)

    - [翻译: 借助事件知识图，提升粗粒度视觉语言导航任务的规划效率](2024年08月05日/Towards_Coarse-grained_Visual_Language_Navigation_Task_Planning_Enhanced_by_Event_Knowledge_Graph.md)

2024年08月04日

- [Constructing Mechanical Design Agent Based on Large Language Models](2024年08月04日/Constructing_Mechanical_Design_Agent_Based_on_Large_Language_Models.md)

    - [翻译: 利用大型语言模型打造机械设计智能代理](2024年08月04日/Constructing_Mechanical_Design_Agent_Based_on_Large_Language_Models.md)

- [Self-Introspective Decoding: Alleviating Hallucinations for Large Vision-Language Models](2024年08月04日/Self-Introspective_Decoding_Alleviating_Hallucinations_for_Large_Vision-Language_Models.md)

    - [翻译: 自我反省解码技术旨在减轻大型视觉-语言模型中的幻觉问题。](2024年08月04日/Self-Introspective_Decoding_Alleviating_Hallucinations_for_Large_Vision-Language_Models.md)

2024年08月02日

- [Transformers are Universal In-context Learners](2024年08月02日/Transformers_are_Universal_In-context_Learners.md)

    - [翻译: Transformer 模型，作为通用上下文学习者，展现了其广泛适应性。](2024年08月02日/Transformers_are_Universal_In-context_Learners.md)

2024年08月01日

- [Gradient-free optimization via integration](2024年08月01日/Gradient-free_optimization_via_integration.md)

    - [翻译: 无梯度优化：集成方法](2024年08月01日/Gradient-free_optimization_via_integration.md)