# 2024年08月

2024年08月02日

- [DebateQA: Evaluating Question Answering on Debatable Knowledge](2024年08月02日/DebateQA_Evaluating_Question_Answering_on_Debatable_Knowledge.md)

    - [翻译: DebateQA：探讨在争议知识领域的问答评估](2024年08月02日/DebateQA_Evaluating_Question_Answering_on_Debatable_Knowledge.md)

- [RAGEval: Scenario Specific RAG Evaluation Dataset Generation Framework](2024年08月02日/RAGEval_Scenario_Specific_RAG_Evaluation_Dataset_Generation_Framework.md)

    - [翻译: RAGEval：专为特定场景设计的 RAG 评估数据集生成框架](2024年08月02日/RAGEval_Scenario_Specific_RAG_Evaluation_Dataset_Generation_Framework.md)

- [Coalitions of Large Language Models Increase the Robustness of AI Agents](2024年08月02日/Coalitions_of_Large_Language_Models_Increase_the_Robustness_of_AI_Agents.md)

    - [翻译: 通过组建大型语言模型联盟，AI代理的鲁健性得到了显著提升。](2024年08月02日/Coalitions_of_Large_Language_Models_Increase_the_Robustness_of_AI_Agents.md)

- [Agentic LLM Workflows for Generating Patient-Friendly Medical Reports](2024年08月02日/Agentic_LLM_Workflows_for_Generating_Patient-Friendly_Medical_Reports.md)

    - [翻译: 代理 LLM 工作流程助力生成患者友好型医疗报告](2024年08月02日/Agentic_LLM_Workflows_for_Generating_Patient-Friendly_Medical_Reports.md)

- [Talk Less, Interact Better: Evaluating In-context Conversational Adaptation in Multimodal LLMs](2024年08月02日/Talk_Less,_Interact_Better_Evaluating_In-context_Conversational_Adaptation_in_Multimodal_LLMs.md)

    - [翻译: 言简意赅，互动更佳：探究多模态LLM中的上下文对话适应性](2024年08月02日/Talk_Less,_Interact_Better_Evaluating_In-context_Conversational_Adaptation_in_Multimodal_LLMs.md)

- [StitchFusion: Weaving Any Visual Modalities to Enhance Multimodal Semantic Segmentation](2024年08月02日/StitchFusion_Weaving_Any_Visual_Modalities_to_Enhance_Multimodal_Semantic_Segmentation.md)

    - [翻译: StitchFusion：融合多种视觉模态，提升多模态语义分割的性能。](2024年08月02日/StitchFusion_Weaving_Any_Visual_Modalities_to_Enhance_Multimodal_Semantic_Segmentation.md)

- [A Comprehensive Review of Multimodal Large Language Models: Performance and Challenges Across Different Tasks](2024年08月02日/A_Comprehensive_Review_of_Multimodal_Large_Language_Models_Performance_and_Challenges_Across_Different_Tasks.md)

    - [翻译: 全面审视多模态大型语言模型：跨越不同任务的性能与挑战](2024年08月02日/A_Comprehensive_Review_of_Multimodal_Large_Language_Models_Performance_and_Challenges_Across_Different_Tasks.md)

- [Dissecting Dissonance: Benchmarking Large Multimodal Models Against Self-Contradictory Instructions](2024年08月02日/Dissecting_Dissonance_Benchmarking_Large_Multimodal_Models_Against_Self-Contradictory_Instructions.md)

    - [翻译: 深入解析矛盾：在自相矛盾的指令下，对大型多模态模型进行性能基准测试](2024年08月02日/Dissecting_Dissonance_Benchmarking_Large_Multimodal_Models_Against_Self-Contradictory_Instructions.md)

- [Piculet: Specialized Models-Guided Hallucination Decrease for MultiModal Large Language Models](2024年08月02日/Piculet_Specialized_Models-Guided_Hallucination_Decrease_for_MultiModal_Large_Language_Models.md)

    - [翻译: Piculet：通过专业模型引导，减少多模态大型语言模型的幻觉现象](2024年08月02日/Piculet_Specialized_Models-Guided_Hallucination_Decrease_for_MultiModal_Large_Language_Models.md)

- [FBSDiff: Plug-and-Play Frequency Band Substitution of Diffusion Features for Highly Controllable Text-Driven Image Translation](2024年08月02日/FBSDiff_Plug-and-Play_Frequency_Band_Substitution_of_Diffusion_Features_for_Highly_Controllable_Text-Driven_Image_Translation.md)

    - [翻译: FBSDiff：一种即插即用的技术，通过替换扩散特征的频率带来实现高度可控的文本驱动图像转换。](2024年08月02日/FBSDiff_Plug-and-Play_Frequency_Band_Substitution_of_Diffusion_Features_for_Highly_Controllable_Text-Driven_Image_Translation.md)

- [Prompt Recursive Search: A Living Framework with Adaptive Growth in LLM Auto-Prompting](2024年08月02日/Prompt_Recursive_Search_A_Living_Framework_with_Adaptive_Growth_in_LLM_Auto-Prompting.md)

    - [翻译: 提示递归搜索：在 LLM 自动提示领域，这是一个随需应变、不断成长的动态框架。](2024年08月02日/Prompt_Recursive_Search_A_Living_Framework_with_Adaptive_Growth_in_LLM_Auto-Prompting.md)

- [Mission Impossible: A Statistical Perspective on Jailbreaking LLMs](2024年08月02日/Mission_Impossible_A_Statistical_Perspective_on_Jailbreaking_LLMs.md)

    - [翻译: 破解大型语言模型：一项统计学视角下的挑战](2024年08月02日/Mission_Impossible_A_Statistical_Perspective_on_Jailbreaking_LLMs.md)

- [Toward Automatic Relevance Judgment using Vision--Language Models for Image--Text Retrieval Evaluation](2024年08月02日/Toward_Automatic_Relevance_Judgment_using_Vision--Language_Models_for_Image--Text_Retrieval_Evaluation.md)

    - [翻译: 利用视觉-语言模型实现图像-文本检索评估的自动相关性判定](2024年08月02日/Toward_Automatic_Relevance_Judgment_using_Vision--Language_Models_for_Image--Text_Retrieval_Evaluation.md)

- [Hallu-PI: Evaluating Hallucination in Multi-modal Large Language Models within Perturbed Inputs](2024年08月02日/Hallu-PI_Evaluating_Hallucination_in_Multi-modal_Large_Language_Models_within_Perturbed_Inputs.md)

    - [翻译: Hallu-PI：探究多模态大型语言模型在受扰输入中的幻觉表现](2024年08月02日/Hallu-PI_Evaluating_Hallucination_in_Multi-modal_Large_Language_Models_within_Perturbed_Inputs.md)

- [MCGMark: An Encodable and Robust Online Watermark for LLM-Generated Malicious Code](2024年08月02日/MCGMark_An_Encodable_and_Robust_Online_Watermark_for_LLM-Generated_Malicious_Code.md)

    - [翻译: MCGMark：为 LLM 生成的恶意代码设计的一种既可编码又具强大防护能力的在线水印技术。](2024年08月02日/MCGMark_An_Encodable_and_Robust_Online_Watermark_for_LLM-Generated_Malicious_Code.md)

- [Prompt Refinement or Fine-tuning? Best Practices for using LLMs in Computational Social Science Tasks](2024年08月02日/Prompt_Refinement_or_Fine-tuning_Best_Practices_for_using_LLMs_in_Computational_Social_Science_Tasks.md)

    - [翻译: 在计算社会科学任务中，我们应选择提示优化还是模型微调？本文探讨了使用大型语言模型的最佳策略。](2024年08月02日/Prompt_Refinement_or_Fine-tuning_Best_Practices_for_using_LLMs_in_Computational_Social_Science_Tasks.md)

- [A Backbone for Long-Horizon Robot Task Understanding](2024年08月02日/A_Backbone_for_Long-Horizon_Robot_Task_Understanding.md)

    - [翻译: 机器人长时程任务理解的关键支柱](2024年08月02日/A_Backbone_for_Long-Horizon_Robot_Task_Understanding.md)

- [FANNO: Augmenting High-Quality Instruction Data with Open-Sourced LLMs Only](2024年08月02日/FANNO_Augmenting_High-Quality_Instruction_Data_with_Open-Sourced_LLMs_Only.md)

    - [翻译: FANNO：借助开源LLM，提升高质量指令数据的丰富性](2024年08月02日/FANNO_Augmenting_High-Quality_Instruction_Data_with_Open-Sourced_LLMs_Only.md)

- [Reconsidering Token Embeddings with the Definitions for Pre-trained Language Models](2024年08月02日/Reconsidering_Token_Embeddings_with_the_Definitions_for_Pre-trained_Language_Models.md)

    - [翻译: 探讨预训练语言模型中 Token Embeddings 的重新定义](2024年08月02日/Reconsidering_Token_Embeddings_with_the_Definitions_for_Pre-trained_Language_Models.md)

- [The Mismeasure of Man and Models: Evaluating Allocational Harms in Large Language Models](2024年08月02日/The_Mismeasure_of_Man_and_Models_Evaluating_Allocational_Harms_in_Large_Language_Models.md)

    - [翻译: 《误测人类与模型：审视大型语言模型中的分配伤害》](2024年08月02日/The_Mismeasure_of_Man_and_Models_Evaluating_Allocational_Harms_in_Large_Language_Models.md)

- [The Phantom Menace: Unmasking Privacy Leakages in Vision-Language Models](2024年08月02日/The_Phantom_Menace_Unmasking_Privacy_Leakages_in_Vision-Language_Models.md)

    - [翻译: 幻影威胁：揭秘视觉-语言模型中的隐私漏洞](2024年08月02日/The_Phantom_Menace_Unmasking_Privacy_Leakages_in_Vision-Language_Models.md)

- [High-Throughput Phenotyping of Clinical Text Using Large Language Models](2024年08月02日/High-Throughput_Phenotyping_of_Clinical_Text_Using_Large_Language_Models.md)

    - [翻译: 利用大型语言模型高效分析临床文本表型](2024年08月02日/High-Throughput_Phenotyping_of_Clinical_Text_Using_Large_Language_Models.md)

- [Misinforming LLMs: vulnerabilities, challenges and opportunities](2024年08月02日/Misinforming_LLMs_vulnerabilities,_challenges_and_opportunities.md)

    - [翻译: 大型语言模型的误导问题：探索其漏洞、面临的挑战及潜在机遇](2024年08月02日/Misinforming_LLMs_vulnerabilities,_challenges_and_opportunities.md)

- [A Survey of Mamba](2024年08月02日/A_Survey_of_Mamba.md)

    - [翻译: 《Mamba 调查报告》](2024年08月02日/A_Survey_of_Mamba.md)

- [CFBench: A Comprehensive Constraints-Following Benchmark for LLMs](2024年08月02日/CFBench_A_Comprehensive_Constraints-Following_Benchmark_for_LLMs.md)

    - [翻译: CFBench：为 LLMs 量身打造的全面约束遵循基准测试](2024年08月02日/CFBench_A_Comprehensive_Constraints-Following_Benchmark_for_LLMs.md)

- [Task Prompt Vectors: Effective Initialization through Multi-Task Soft-Prompt Transfer](2024年08月02日/Task_Prompt_Vectors_Effective_Initialization_through_Multi-Task_Soft-Prompt_Transfer.md)

    - [翻译: 任务提示向量：借助多任务软提示转移，实现高效初始化](2024年08月02日/Task_Prompt_Vectors_Effective_Initialization_through_Multi-Task_Soft-Prompt_Transfer.md)

- [BioRAG: A RAG-LLM Framework for Biological Question Reasoning](2024年08月02日/BioRAG_A_RAG-LLM_Framework_for_Biological_Question_Reasoning.md)

    - [翻译: BioRAG：专为生物学问题推理设计的 RAG-LLM 框架](2024年08月02日/BioRAG_A_RAG-LLM_Framework_for_Biological_Question_Reasoning.md)

- [LessonPlanner: Assisting Novice Teachers to Prepare Pedagogy-Driven Lesson Plans with Large Language Models](2024年08月02日/LessonPlanner_Assisting_Novice_Teachers_to_Prepare_Pedagogy-Driven_Lesson_Plans_with_Large_Language_Models.md)

    - [翻译: LessonPlanner：借助大型语言模型，助力新手教师制定以教学法为核心的课程计划。](2024年08月02日/LessonPlanner_Assisting_Novice_Teachers_to_Prepare_Pedagogy-Driven_Lesson_Plans_with_Large_Language_Models.md)

- [Bridging Information Gaps in Dialogues With Grounded Exchanges Using Knowledge Graphs](2024年08月02日/Bridging_Information_Gaps_in_Dialogues_With_Grounded_Exchanges_Using_Knowledge_Graphs.md)

    - [翻译: 借助知识图谱，通过基于事实的交流来弥合对话中的信息鸿沟](2024年08月02日/Bridging_Information_Gaps_in_Dialogues_With_Grounded_Exchanges_Using_Knowledge_Graphs.md)

- [Adaptive Contrastive Decoding in Retrieval-Augmented Generation for Handling Noisy Contexts](2024年08月02日/Adaptive_Contrastive_Decoding_in_Retrieval-Augmented_Generation_for_Handling_Noisy_Contexts.md)

    - [翻译: 针对噪声上下文的处理，检索增强生成采用了自适应对比解码技术。](2024年08月02日/Adaptive_Contrastive_Decoding_in_Retrieval-Augmented_Generation_for_Handling_Noisy_Contexts.md)

- [Leveraging Large Language Models for Mobile App Review Feature Extraction](2024年08月02日/Leveraging_Large_Language_Models_for_Mobile_App_Review_Feature_Extraction.md)

    - [翻译: 借助大型语言模型，我们能够高效提取移动应用评论中的关键特征。](2024年08月02日/Leveraging_Large_Language_Models_for_Mobile_App_Review_Feature_Extraction.md)

- [LLM as Runtime Error Handler: A Promising Pathway to Adaptive Self-Healing of Software Systems](2024年08月02日/LLM_as_Runtime_Error_Handler_A_Promising_Pathway_to_Adaptive_Self-Healing_of_Software_Systems.md)

    - [翻译: LLM 作为运行时错误处理程序，为软件系统的自适应自愈开辟了一条有前景的路径。](2024年08月02日/LLM_as_Runtime_Error_Handler_A_Promising_Pathway_to_Adaptive_Self-Healing_of_Software_Systems.md)

- [The Impact of Hyperparameters on Large Language Model Inference Performance: An Evaluation of vLLM and HuggingFace Pipelines](2024年08月02日/The_Impact_of_Hyperparameters_on_Large_Language_Model_Inference_Performance_An_Evaluation_of_vLLM_and_HuggingFace_Pipelines.md)

    - [翻译: 探究超参数如何影响大型语言模型的推理性能：一项针对 vLLM 与 HuggingFace 管道的评估研究](2024年08月02日/The_Impact_of_Hyperparameters_on_Large_Language_Model_Inference_Performance_An_Evaluation_of_vLLM_and_HuggingFace_Pipelines.md)

- [DASH: A Bimodal Data Exploration Tool for Interactive Text and Visualizations](2024年08月02日/DASH_A_Bimodal_Data_Exploration_Tool_for_Interactive_Text_and_Visualizations.md)

    - [翻译: DASH：一款双模态数据探索工具，专为交互式文本与可视化设计。](2024年08月02日/DASH_A_Bimodal_Data_Exploration_Tool_for_Interactive_Text_and_Visualizations.md)

- [Tensor Train Low-rank Approximation (TT-LoRA): Democratizing AI with Accelerated LLMs](2024年08月02日/Tensor_Train_Low-rank_Approximation_(TT-LoRA)_Democratizing_AI_with_Accelerated_LLMs.md)

    - [翻译: TT-LoRA：通过加速 LLM 普及人工智能](2024年08月02日/Tensor_Train_Low-rank_Approximation_(TT-LoRA)_Democratizing_AI_with_Accelerated_LLMs.md)

2024年08月01日

- [Improving Retrieval-Augmented Generation in Medicine with Iterative Follow-up Questions](2024年08月01日/Improving_Retrieval-Augmented_Generation_in_Medicine_with_Iterative_Follow-up_Questions.md)

    - [翻译: 通过迭代提问，提升医学领域检索增强生成的质量](2024年08月01日/Improving_Retrieval-Augmented_Generation_in_Medicine_with_Iterative_Follow-up_Questions.md)

- [Alleviating Hallucination in Large Vision-Language Models with Active Retrieval Augmentation](2024年08月01日/Alleviating_Hallucination_in_Large_Vision-Language_Models_with_Active_Retrieval_Augmentation.md)

    - [翻译: 通过主动检索增强技术，缓解大型视觉-语言模型中的幻觉现象。](2024年08月01日/Alleviating_Hallucination_in_Large_Vision-Language_Models_with_Active_Retrieval_Augmentation.md)

- [AgentGen: Enhancing Planning Abilities for Large Language Model based Agent via Environment and Task Generation](2024年08月01日/AgentGen_Enhancing_Planning_Abilities_for_Large_Language_Model_based_Agent_via_Environment_and_Task_Generation.md)

    - [翻译: AgentGen：通过创造环境和任务，提升大型语言模型代理的规划能力](2024年08月01日/AgentGen_Enhancing_Planning_Abilities_for_Large_Language_Model_based_Agent_via_Environment_and_Task_Generation.md)

- [Jailbreaking Text-to-Image Models with LLM-Based Agents](2024年08月01日/Jailbreaking_Text-to-Image_Models_with_LLM-Based_Agents.md)

    - [翻译: 借助LLM代理，突破文本转图像模型的限制](2024年08月01日/Jailbreaking_Text-to-Image_Models_with_LLM-Based_Agents.md)

- [Autonomous LLM-Enhanced Adversarial Attack for Text-to-Motion](2024年08月01日/Autonomous_LLM-Enhanced_Adversarial_Attack_for_Text-to-Motion.md)

    - [翻译: 自主增强型 LLM 对抗攻击：文本至动作的革新](2024年08月01日/Autonomous_LLM-Enhanced_Adversarial_Attack_for_Text-to-Motion.md)

- [MM-Vet v2: A Challenging Benchmark to Evaluate Large Multimodal Models for Integrated Capabilities](2024年08月01日/MM-Vet_v2_A_Challenging_Benchmark_to_Evaluate_Large_Multimodal_Models_for_Integrated_Capabilities.md)

    - [翻译: MM-Vet v2 是一个挑战性的基准，旨在评估大型多模态模型的综合能力。](2024年08月01日/MM-Vet_v2_A_Challenging_Benchmark_to_Evaluate_Large_Multimodal_Models_for_Integrated_Capabilities.md)

- [AutoM3L: An Automated Multimodal Machine Learning Framework with Large Language Models](2024年08月01日/AutoM3L_An_Automated_Multimodal_Machine_Learning_Framework_with_Large_Language_Models.md)

    - [翻译: AutoM3L：一款集成大型语言模型的自动化多模态机器学习框架](2024年08月01日/AutoM3L_An_Automated_Multimodal_Machine_Learning_Framework_with_Large_Language_Models.md)

- [Are Bigger Encoders Always Better in Vision Large Models?](2024年08月01日/Are_Bigger_Encoders_Always_Better_in_Vision_Large_Models.md)

    - [翻译: 视觉大型模型中，编码器越大是否总是越优？](2024年08月01日/Are_Bigger_Encoders_Always_Better_in_Vision_Large_Models.md)

- [Mitigating Multilingual Hallucination in Large Vision-Language Models](2024年08月01日/Mitigating_Multilingual_Hallucination_in_Large_Vision-Language_Models.md)

    - [翻译: 缓解大型视觉-语言模型中的多语言幻觉问题](2024年08月01日/Mitigating_Multilingual_Hallucination_in_Large_Vision-Language_Models.md)

- [GalleryGPT: Analyzing Paintings with Large Multimodal Models](2024年08月01日/GalleryGPT_Analyzing_Paintings_with_Large_Multimodal_Models.md)

    - [翻译: GalleryGPT：探索大型多模态模型在绘画分析中的应用](2024年08月01日/GalleryGPT_Analyzing_Paintings_with_Large_Multimodal_Models.md)

- [Multimodal Fusion and Coherence Modeling for Video Topic Segmentation](2024年08月01日/Multimodal_Fusion_and_Coherence_Modeling_for_Video_Topic_Segmentation.md)

    - [翻译: 视频主题分割中的多模态融合与连贯性建模](2024年08月01日/Multimodal_Fusion_and_Coherence_Modeling_for_Video_Topic_Segmentation.md)

- [Towards Flexible Evaluation for Generative Visual Question Answering](2024年08月01日/Towards_Flexible_Evaluation_for_Generative_Visual_Question_Answering.md)

    - [翻译: 灵活评估生成视觉问答的新途径](2024年08月01日/Towards_Flexible_Evaluation_for_Generative_Visual_Question_Answering.md)

- [Everything We Hear: Towards Tackling Misinformation in Podcasts](2024年08月01日/Everything_We_Hear_Towards_Tackling_Misinformation_in_Podcasts.md)

    - [翻译: 聆听一切：迈向解决播客中的信息误导](2024年08月01日/Everything_We_Hear_Towards_Tackling_Misinformation_in_Podcasts.md)

- [Tamper-Resistant Safeguards for Open-Weight LLMs](2024年08月01日/Tamper-Resistant_Safeguards_for_Open-Weight_LLMs.md)

    - [翻译: 为开放权重的大型语言模型设计防篡改保护措施](2024年08月01日/Tamper-Resistant_Safeguards_for_Open-Weight_LLMs.md)

- [DynamoLLM: Designing LLM Inference Clusters for Performance and Energy Efficiency](2024年08月01日/DynamoLLM_Designing_LLM_Inference_Clusters_for_Performance_and_Energy_Efficiency.md)

    - [翻译: DynamoLLM：打造高效能与节能的 LLM 推理集群](2024年08月01日/DynamoLLM_Designing_LLM_Inference_Clusters_for_Performance_and_Energy_Efficiency.md)

- [An Empirical Analysis of Compute-Optimal Inference for Problem-Solving with Language Models](2024年08月01日/An_Empirical_Analysis_of_Compute-Optimal_Inference_for_Problem-Solving_with_Language_Models.md)

    - [翻译: 实证分析：语言模型在问题解决中的计算最优推理](2024年08月01日/An_Empirical_Analysis_of_Compute-Optimal_Inference_for_Problem-Solving_with_Language_Models.md)

- [Pathway to Secure and Trustworthy 6G for LLMs: Attacks, Defense, and Opportunities](2024年08月01日/Pathway_to_Secure_and_Trustworthy_6G_for_LLMs_Attacks,_Defense,_and_Opportunities.md)

    - [翻译: 迈向安全可信的6G：探讨LLM面临的攻击、防御策略及潜在机遇](2024年08月01日/Pathway_to_Secure_and_Trustworthy_6G_for_LLMs_Attacks,_Defense,_and_Opportunities.md)

- [Improving Text Embeddings for Smaller Language Models Using Contrastive Fine-tuning](2024年08月01日/Improving_Text_Embeddings_for_Smaller_Language_Models_Using_Contrastive_Fine-tuning.md)

    - [翻译: 通过对比微调提升小型语言模型的文本嵌入效果](2024年08月01日/Improving_Text_Embeddings_for_Smaller_Language_Models_Using_Contrastive_Fine-tuning.md)

- [Can Developers Prompt? A Controlled Experiment for Code Documentation Generation](2024年08月01日/Can_Developers_Prompt_A_Controlled_Experiment_for_Code_Documentation_Generation.md)

    - [翻译: 开发者能否巧妙引导？这是一项针对代码文档生成进行的控制实验研究。](2024年08月01日/Can_Developers_Prompt_A_Controlled_Experiment_for_Code_Documentation_Generation.md)

- [Disentangling Dense Embeddings with Sparse Autoencoders](2024年08月01日/Disentangling_Dense_Embeddings_with_Sparse_Autoencoders.md)

    - [翻译: 稀疏自编码器解密密集嵌入](2024年08月01日/Disentangling_Dense_Embeddings_with_Sparse_Autoencoders.md)

- [SentenceVAE: Faster, Longer and More Accurate Inference with Next-sentence Prediction for Large Language Models](2024年08月01日/SentenceVAE_Faster,_Longer_and_More_Accurate_Inference_with_Next-sentence_Prediction_for_Large_Language_Models.md)

    - [翻译: SentenceVAE 利用下一句话预测技术，大幅提升大型语言模型的推理速度、长度和准确性。](2024年08月01日/SentenceVAE_Faster,_Longer_and_More_Accurate_Inference_with_Next-sentence_Prediction_for_Large_Language_Models.md)

- [Downstream bias mitigation is all you need](2024年08月01日/Downstream_bias_mitigation_is_all_you_need.md)

    - [翻译: 只需解决下游偏差，一切问题迎刃而解。](2024年08月01日/Downstream_bias_mitigation_is_all_you_need.md)

- [Non Verbis, Sed Rebus: Large Language Models are Weak Solvers of Italian Rebuses](2024年08月01日/Non_Verbis,_Sed_Rebus_Large_Language_Models_are_Weak_Solvers_of_Italian_Rebuses.md)

    - [翻译: 大型语言模型虽强，但在解谜意大利谜语时却显得力不从心，这揭示了它们在实物而非言辞理解上的短板。](2024年08月01日/Non_Verbis,_Sed_Rebus_Large_Language_Models_are_Weak_Solvers_of_Italian_Rebuses.md)

- [Intermittent Semi-working Mask: A New Masking Paradigm for LLMs](2024年08月01日/Intermittent_Semi-working_Mask_A_New_Masking_Paradigm_for_LLMs.md)

    - [翻译: 间歇性半工作掩码：为 LLMs 引入的新型掩码策略](2024年08月01日/Intermittent_Semi-working_Mask_A_New_Masking_Paradigm_for_LLMs.md)

- [FlowGPT: Exploring Domains, Output Modalities, and Goals of Community-Generated AI Chatbots](2024年08月01日/FlowGPT_Exploring_Domains,_Output_Modalities,_and_Goals_of_Community-Generated_AI_Chatbots.md)

    - [翻译: FlowGPT：探寻社区打造 AI 聊天机器人的应用领域、输出形式及目标定位](2024年08月01日/FlowGPT_Exploring_Domains,_Output_Modalities,_and_Goals_of_Community-Generated_AI_Chatbots.md)

- [Designing Efficient LLM Accelerators for Edge Devices](2024年08月01日/Designing_Efficient_LLM_Accelerators_for_Edge_Devices.md)

    - [翻译: 为边缘设备打造高效 LLM 加速器](2024年08月01日/Designing_Efficient_LLM_Accelerators_for_Edge_Devices.md)

- [DiscipLink: Unfolding Interdisciplinary Information Seeking Process via Human-AI Co-Exploration](2024年08月01日/DiscipLink_Unfolding_Interdisciplinary_Information_Seeking_Process_via_Human-AI_Co-Exploration.md)

    - [翻译: DiscipLink：携手人机共探，揭秘跨学科信息探索之旅](2024年08月01日/DiscipLink_Unfolding_Interdisciplinary_Information_Seeking_Process_via_Human-AI_Co-Exploration.md)

- [A Qualitative Study on Using ChatGPT for Software Security: Perception vs. Practicality](2024年08月01日/A_Qualitative_Study_on_Using_ChatGPT_for_Software_Security_Perception_vs._Practicality.md)

    - [翻译: 探究 ChatGPT 在软件安全中的应用：感知与实际性的对比研究](2024年08月01日/A_Qualitative_Study_on_Using_ChatGPT_for_Software_Security_Perception_vs._Practicality.md)

- [In-Context Example Selection via Similarity Search Improves Low-Resource Machine Translation](2024年08月01日/In-Context_Example_Selection_via_Similarity_Search_Improves_Low-Resource_Machine_Translation.md)

    - [翻译: 利用相似性搜索挑选上下文示例，显著提升了低资源环境下的机器翻译质量。](2024年08月01日/In-Context_Example_Selection_via_Similarity_Search_Improves_Low-Resource_Machine_Translation.md)

- [DeliLaw: A Chinese Legal Counselling System Based on a Large Language Model](2024年08月01日/DeliLaw_A_Chinese_Legal_Counselling_System_Based_on_a_Large_Language_Model.md)

    - [翻译: DeliLaw：一款基于大型语言模型的中国法律咨询系统](2024年08月01日/DeliLaw_A_Chinese_Legal_Counselling_System_Based_on_a_Large_Language_Model.md)

- [DECIDER: Leveraging Foundation Model Priors for Improved Model Failure Detection and Explanation](2024年08月01日/DECIDER_Leveraging_Foundation_Model_Priors_for_Improved_Model_Failure_Detection_and_Explanation.md)

    - [翻译: DECIDER：借助基础模型的先验知识，提升模型故障检测与解释的效能。](2024年08月01日/DECIDER_Leveraging_Foundation_Model_Priors_for_Improved_Model_Failure_Detection_and_Explanation.md)

- [ABC Align: Large Language Model Alignment for Safety & Accuracy](2024年08月01日/ABC_Align_Large_Language_Model_Alignment_for_Safety_&_Accuracy.md)

    - [翻译: ABC Align：专为提升安全和准确性而设计的大型语言模型对齐方案](2024年08月01日/ABC_Align_Large_Language_Model_Alignment_for_Safety_&_Accuracy.md)

- [Multi-Modal Parameter-Efficient Fine-tuning via Graph Neural Network](2024年08月01日/Multi-Modal_Parameter-Efficient_Fine-tuning_via_Graph_Neural_Network.md)

    - [翻译: 借助图神经网络实现多模态参数高效微调](2024年08月01日/Multi-Modal_Parameter-Efficient_Fine-tuning_via_Graph_Neural_Network.md)

- [QUITO: Accelerating Long-Context Reasoning through Query-Guided Context Compression](2024年08月01日/QUITO_Accelerating_Long-Context_Reasoning_through_Query-Guided_Context_Compression.md)

    - [翻译: QUITO 技术通过查询引导的上下文压缩，有效加速长上下文推理过程。](2024年08月01日/QUITO_Accelerating_Long-Context_Reasoning_through_Query-Guided_Context_Compression.md)

- [VecAug: Unveiling Camouflaged Frauds with Cohort Augmentation for Enhanced Detection](2024年08月01日/VecAug_Unveiling_Camouflaged_Frauds_with_Cohort_Augmentation_for_Enhanced_Detection.md)

    - [翻译: VecAug：利用队列增强技术，揭露伪装欺诈，提升检测效率。](2024年08月01日/VecAug_Unveiling_Camouflaged_Frauds_with_Cohort_Augmentation_for_Enhanced_Detection.md)

- [On the Resilience of Multi-Agent Systems with Malicious Agents](2024年08月01日/On_the_Resilience_of_Multi-Agent_Systems_with_Malicious_Agents.md)

    - [翻译: 探讨恶意代理存在下的多代理系统韧性](2024年08月01日/On_the_Resilience_of_Multi-Agent_Systems_with_Malicious_Agents.md)

- [Y Social: an LLM-powered Social Media Digital Twin](2024年08月01日/Y_Social_an_LLM-powered_Social_Media_Digital_Twin.md)

    - [翻译: Y Social：一款由大型语言模型赋能的社交媒体数字孪生](2024年08月01日/Y_Social_an_LLM-powered_Social_Media_Digital_Twin.md)

- [ArchCode: Incorporating Software Requirements in Code Generation with Large Language Models](2024年08月01日/ArchCode_Incorporating_Software_Requirements_in_Code_Generation_with_Large_Language_Models.md)

    - [翻译: ArchCode：利用大型语言模型，在代码生成过程中巧妙融入软件需求。](2024年08月01日/ArchCode_Incorporating_Software_Requirements_in_Code_Generation_with_Large_Language_Models.md)

- [Fairness in Large Language Models in Three Hour](2024年08月01日/Fairness_in_Large_Language_Models_in_Three_Hour.md)

    - [翻译: 三小时内探讨大型语言模型的公平性](2024年08月01日/Fairness_in_Large_Language_Models_in_Three_Hour.md)

- [Automatic Extraction of Relationships among Motivations, Emotions and Actions from Natural Language Texts](2024年08月01日/Automatic_Extraction_of_Relationships_among_Motivations,_Emotions_and_Actions_from_Natural_Language_Texts.md)

    - [翻译: 自动解析自然语言文本中的动机、情感与行为间的关联](2024年08月01日/Automatic_Extraction_of_Relationships_among_Motivations,_Emotions_and_Actions_from_Natural_Language_Texts.md)

- [PERSOMA: PERsonalized SOft ProMpt Adapter Architecture for Personalized Language Prompting](2024年08月01日/PERSOMA_PERsonalized_SOft_ProMpt_Adapter_Architecture_for_Personalized_Language_Prompting.md)

    - [翻译: PERSOMA：一种个性化软提示适配器架构，专为个性化语言提示设计](2024年08月01日/PERSOMA_PERsonalized_SOft_ProMpt_Adapter_Architecture_for_Personalized_Language_Prompting.md)

- [Leveraging Large Language Models (LLMs) for Traffic Management at Urban Intersections: The Case of Mixed Traffic Scenarios](2024年08月01日/Leveraging_Large_Language_Models_(LLMs)_for_Traffic_Management_at_Urban_Intersections_The_Case_of_Mixed_Traffic_Scenarios.md)

    - [翻译: 借助 LLM 优化城市交叉口交通管理：探索混合交通场景的解决方案](2024年08月01日/Leveraging_Large_Language_Models_(LLMs)_for_Traffic_Management_at_Urban_Intersections_The_Case_of_Mixed_Traffic_Scenarios.md)

- [Towards Zero-Shot Annotation of the Built Environment with Vision-Language Models (Vision Paper)](2024年08月01日/Towards_Zero-Shot_Annotation_of_the_Built_Environment_with_Vision-Language_Models_(Vision_Paper).md)

    - [翻译: 探索利用视觉-语言模型实现建筑环境的零-shot 标注（愿景论文）](2024年08月01日/Towards_Zero-Shot_Annotation_of_the_Built_Environment_with_Vision-Language_Models_(Vision_Paper).md)

- [Granting GPT-4 License and Opportunity: Enhancing Accuracy and Confidence Estimation for Few-Shot Event Detection](2024年08月01日/Granting_GPT-4_License_and_Opportunity_Enhancing_Accuracy_and_Confidence_Estimation_for_Few-Shot_Event_Detection.md)

    - [翻译: 赋予 GPT-4 许可与机遇，旨在提升少样本事件检测的精准度与置信评估。](2024年08月01日/Granting_GPT-4_License_and_Opportunity_Enhancing_Accuracy_and_Confidence_Estimation_for_Few-Shot_Event_Detection.md)

- [Hybrid Querying Over Relational Databases and Large Language Models](2024年08月01日/Hybrid_Querying_Over_Relational_Databases_and_Large_Language_Models.md)

    - [翻译: 关系数据库与大型语言模型间的混合查询探索](2024年08月01日/Hybrid_Querying_Over_Relational_Databases_and_Large_Language_Models.md)

- [Annotator in the Loop: A Case Study of In-Depth Rater Engagement to Create a Bridging Benchmark Dataset](2024年08月01日/Annotator_in_the_Loop_A_Case_Study_of_In-Depth_Rater_Engagement_to_Create_a_Bridging_Benchmark_Dataset.md)

    - [翻译: 标注者在循环中：通过深入评分者参与，创建桥梁基准数据集的案例研究](2024年08月01日/Annotator_in_the_Loop_A_Case_Study_of_In-Depth_Rater_Engagement_to_Create_a_Bridging_Benchmark_Dataset.md)

- [Multi-Aspect Reviewed-Item Retrieval via LLM Query Decomposition and Aspect Fusion](2024年08月01日/Multi-Aspect_Reviewed-Item_Retrieval_via_LLM_Query_Decomposition_and_Aspect_Fusion.md)

    - [翻译: 利用 LLM 查询分解与方面融合技术，实现多维度评论项目的精准检索。](2024年08月01日/Multi-Aspect_Reviewed-Item_Retrieval_via_LLM_Query_Decomposition_and_Aspect_Fusion.md)

- [UniMoT: Unified Molecule-Text Language Model with Discrete Token Representation](2024年08月01日/UniMoT_Unified_Molecule-Text_Language_Model_with_Discrete_Token_Representation.md)

    - [翻译: UniMoT：一款采用离散令牌表示的统一分子与文本语言模型](2024年08月01日/UniMoT_Unified_Molecule-Text_Language_Model_with_Discrete_Token_Representation.md)