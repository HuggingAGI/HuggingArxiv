# 2024年08月

2024年08月06日

- [500xCompressor: Generalized Prompt Compression for Large Language Models](2024年08月06日/500xCompressor_Generalized_Prompt_Compression_for_Large_Language_Models.md)

    - [翻译: 500xCompressor：专为大型语言模型设计的通用提示压缩工具](2024年08月06日/500xCompressor_Generalized_Prompt_Compression_for_Large_Language_Models.md)

- [Accuracy and Consistency of LLMs in the Registered Dietitian Exam: The Impact of Prompt Engineering and Knowledge Retrieval](2024年08月06日/Accuracy_and_Consistency_of_LLMs_in_the_Registered_Dietitian_Exam_The_Impact_of_Prompt_Engineering_and_Knowledge_Retrieval.md)

    - [翻译: LLM 在注册营养师考试中的表现，受提示工程与知识检索的双重影响，我们探讨其准确性与一致性的奥秘。](2024年08月06日/Accuracy_and_Consistency_of_LLMs_in_the_Registered_Dietitian_Exam_The_Impact_of_Prompt_Engineering_and_Knowledge_Retrieval.md)

- [Benchmarking In-the-wild Multimodal Disease Recognition and A Versatile Baseline](2024年08月06日/Benchmarking_In-the-wild_Multimodal_Disease_Recognition_and_A_Versatile_Baseline.md)

    - [翻译: 野外多模态疾病识别的基准测试与多功能基线研究](2024年08月06日/Benchmarking_In-the-wild_Multimodal_Disease_Recognition_and_A_Versatile_Baseline.md)

- [Conditioning LLMs with Emotion in Neural Machine Translation](2024年08月06日/Conditioning_LLMs_with_Emotion_in_Neural_Machine_Translation.md)

    - [翻译: 情感调节在神经机器翻译中对大型语言模型的应用](2024年08月06日/Conditioning_LLMs_with_Emotion_in_Neural_Machine_Translation.md)

- [EC-Guide: A Comprehensive E-Commerce Guide for Instruction Tuning and Quantization](2024年08月06日/EC-Guide_A_Comprehensive_E-Commerce_Guide_for_Instruction_Tuning_and_Quantization.md)

    - [翻译: EC-Guide：一本详尽的电子商务指南，专为指令调优与量化设计](2024年08月06日/EC-Guide_A_Comprehensive_E-Commerce_Guide_for_Instruction_Tuning_and_Quantization.md)

- [Evaluating the Translation Performance of Large Language Models Based on Euas-20](2024年08月06日/Evaluating_the_Translation_Performance_of_Large_Language_Models_Based_on_Euas-20.md)

    - [翻译: 基于 Euas-20 标准，评估大型语言模型的翻译表现](2024年08月06日/Evaluating_the_Translation_Performance_of_Large_Language_Models_Based_on_Euas-20.md)

- [Extend Model Merging from Fine-Tuned to Pre-Trained Large Language Models via Weight Disentanglement](2024年08月06日/Extend_Model_Merging_from_Fine-Tuned_to_Pre-Trained_Large_Language_Models_via_Weight_Disentanglement.md)

    - [翻译: 借助权重解耦技术，我们实现了从微调到预训练大型语言模型的模型合并扩展。](2024年08月06日/Extend_Model_Merging_from_Fine-Tuned_to_Pre-Trained_Large_Language_Models_via_Weight_Disentanglement.md)

- [Fact Finder -- Enhancing Domain Expertise of Large Language Models by Incorporating Knowledge Graphs](2024年08月06日/Fact_Finder_--_Enhancing_Domain_Expertise_of_Large_Language_Models_by_Incorporating_Knowledge_Graphs.md)

    - [翻译: Fact Finder：融合知识图谱，提升大型语言模型的领域专长](2024年08月06日/Fact_Finder_--_Enhancing_Domain_Expertise_of_Large_Language_Models_by_Incorporating_Knowledge_Graphs.md)

- [Inference Optimizations for Large Language Models: Effects, Challenges, and Practical Considerations](2024年08月06日/Inference_Optimizations_for_Large_Language_Models_Effects,_Challenges,_and_Practical_Considerations.md)

    - [翻译: 大型语言模型的推理优化涉及效果、挑战及实际考量。](2024年08月06日/Inference_Optimizations_for_Large_Language_Models_Effects,_Challenges,_and_Practical_Considerations.md)

- [L3iTC at the FinLLM Challenge Task: Quantization for Financial Text Classification & Summarization](2024年08月06日/L3iTC_at_the_FinLLM_Challenge_Task_Quantization_for_Financial_Text_Classification_&_Summarization.md)

    - [翻译: L3iTC 在 FinLLM 挑战中：量化技术助力金融文本分类与摘要](2024年08月06日/L3iTC_at_the_FinLLM_Challenge_Task_Quantization_for_Financial_Text_Classification_&_Summarization.md)

- [Leveraging Parameter Efficient Training Methods for Low Resource Text Classification: A Case Study in Marathi](2024年08月06日/Leveraging_Parameter_Efficient_Training_Methods_for_Low_Resource_Text_Classification_A_Case_Study_in_Marathi.md)

    - [翻译: 本研究通过马拉地语案例，探讨了如何运用参数高效训练方法提升低资源环境下的文本分类效率。](2024年08月06日/Leveraging_Parameter_Efficient_Training_Methods_for_Low_Resource_Text_Classification_A_Case_Study_in_Marathi.md)

- [Lisbon Computational Linguists at SemEval-2024 Task 2: Using A Mistral 7B Model and Data Augmentation](2024年08月06日/Lisbon_Computational_Linguists_at_SemEval-2024_Task_2_Using_A_Mistral_7B_Model_and_Data_Augmentation.md)

    - [翻译: 里斯本计算语言学家团队在 SemEval-2024 的第二项任务中，采用了 Mistral 7B 模型并结合数据增强技术。](2024年08月06日/Lisbon_Computational_Linguists_at_SemEval-2024_Task_2_Using_A_Mistral_7B_Model_and_Data_Augmentation.md)

- [LLaVA-OneVision: Easy Visual Task Transfer](2024年08月06日/LLaVA-OneVision_Easy_Visual_Task_Transfer.md)

    - [翻译: LLaVA-OneVision：轻松实现视觉任务的转移](2024年08月06日/LLaVA-OneVision_Easy_Visual_Task_Transfer.md)

- [Multitask and Multimodal Neural Tuning for Large Models](2024年08月06日/Multitask_and_Multimodal_Neural_Tuning_for_Large_Models.md)

    - [翻译: 大型模型的多任务与多模态神经调谐](2024年08月06日/Multitask_and_Multimodal_Neural_Tuning_for_Large_Models.md)

- [OpenOmni: A Collaborative Open Source Tool for Building Future-Ready Multimodal Conversational Agents](2024年08月06日/OpenOmni_A_Collaborative_Open_Source_Tool_for_Building_Future-Ready_Multimodal_Conversational_Agents.md)

    - [翻译: OpenOmni：携手共创，打造面向未来的多模态对话智能体开源利器](2024年08月06日/OpenOmni_A_Collaborative_Open_Source_Tool_for_Building_Future-Ready_Multimodal_Conversational_Agents.md)

- [Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters](2024年08月06日/Scaling_LLM_Test-Time_Compute_Optimally_can_be_More_Effective_than_Scaling_Model_Parameters.md)

    - [翻译: 在大型语言模型（LLM）中，优化测试时的计算扩展策略可能比单纯增加模型参数更为高效。](2024年08月06日/Scaling_LLM_Test-Time_Compute_Optimally_can_be_More_Effective_than_Scaling_Model_Parameters.md)

- [Synthesizing Text-to-SQL Data from Weak and Strong LLMs](2024年08月06日/Synthesizing_Text-to-SQL_Data_from_Weak_and_Strong_LLMs.md)

    - [翻译: 从弱与强 LLM 中合成 Text-to-SQL 数据](2024年08月06日/Synthesizing_Text-to-SQL_Data_from_Weak_and_Strong_LLMs.md)

- [Targeted Visual Prompting for Medical Visual Question Answering](2024年08月06日/Targeted_Visual_Prompting_for_Medical_Visual_Question_Answering.md)

    - [翻译: 医学视觉问答中的定向视觉提示](2024年08月06日/Targeted_Visual_Prompting_for_Medical_Visual_Question_Answering.md)

- [TestART: Improving LLM-based Unit Test via Co-evolution of Automated Generation and Repair Iteration](2024年08月06日/TestART_Improving_LLM-based_Unit_Test_via_Co-evolution_of_Automated_Generation_and_Repair_Iteration.md)

    - [翻译: TestART：借助自动化生成与修复的迭代共进化，提升基于 LLM 的单元测试质量。](2024年08月06日/TestART_Improving_LLM-based_Unit_Test_via_Co-evolution_of_Automated_Generation_and_Repair_Iteration.md)

- [Towards an Analysis of Discourse and Interactional Pragmatic Reasoning Capabilities of Large Language Models](2024年08月06日/Towards_an_Analysis_of_Discourse_and_Interactional_Pragmatic_Reasoning_Capabilities_of_Large_Language_Models.md)

    - [翻译: 探索大型语言模型在论述与交互实用推理方面的能力分析](2024年08月06日/Towards_an_Analysis_of_Discourse_and_Interactional_Pragmatic_Reasoning_Capabilities_of_Large_Language_Models.md)

- [Unveiling Factual Recall Behaviors of Large Language Models through Knowledge Neurons](2024年08月06日/Unveiling_Factual_Recall_Behaviors_of_Large_Language_Models_through_Knowledge_Neurons.md)

    - [翻译: 揭秘大型语言模型通过知识神经元的实际回忆行为](2024年08月06日/Unveiling_Factual_Recall_Behaviors_of_Large_Language_Models_through_Knowledge_Neurons.md)