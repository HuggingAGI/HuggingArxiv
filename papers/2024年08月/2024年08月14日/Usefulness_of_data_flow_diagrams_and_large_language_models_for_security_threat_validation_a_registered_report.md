# 数据流图与大型语言模型在验证安全威胁中的应用：注册报告探析

发布时间：2024年08月14日

`LLM应用` `网络安全` `风险评估`

> Usefulness of data flow diagrams and large language models for security threat validation: a registered report

# 摘要

> 随着最新网络安全标准的实施，组织内的安全评估门槛被提升，然而现有技术在适应性上存在局限。威胁分析与风险评估虽能揭示新或重构系统的潜在威胁，但因缺乏明确的完成标准，验证过程拖慢了整体分析进度。尽管文献中对威胁分析的整体效能有所探讨，却未曾深入探讨分析师在验证威胁前需深入材料至何种程度。为此，我们设计了一项与实际从业者合作的实验，旨在探究LLM生成的建议等分析材料是否优于无材料，以及包含系统数据流图的丰富材料是否更胜一筹。同时，我们从41名硕士生的试点研究中提炼出关键见解，以优化实验设计。此外，我们发布了包含实验材料、数据分析脚本的初步复制包，并计划依据与从业者的最终数据收集活动，进一步丰富其内容（如预筛选问题）。

> The arrival of recent cybersecurity standards has raised the bar for security assessments in organizations, but existing techniques don't always scale well. Threat analysis and risk assessment are used to identify security threats for new or refactored systems. Still, there is a lack of definition-of-done, so identified threats have to be validated which slows down the analysis. Existing literature has focused on the overall performance of threat analysis, but no previous work has investigated how deep must the analysts dig into the material before they can effectively validate the identified security threats. We propose a controlled experiment with practitioners to investigate whether some analysis material (like LLM-generated advice) is better than none and whether more material (the system's data flow diagram and LLM-generated advice) is better than some material. In addition, we present key findings from running a pilot with 41 MSc students, which are used to improve the study design. Finally, we also provide an initial replication package, including experimental material and data analysis scripts and a plan to extend it to include new materials based on the final data collection campaign with practitioners (e.g., pre-screening questions).

[Arxiv](https://arxiv.org/abs/2408.07537)