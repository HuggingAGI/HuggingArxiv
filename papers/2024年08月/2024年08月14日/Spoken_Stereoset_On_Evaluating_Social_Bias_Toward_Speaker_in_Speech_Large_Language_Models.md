# 《语音刻板印象集》：探讨如何评估语音大型语言模型中的社会偏见

发布时间：2024年08月14日

`LLM应用` `人工智能` `社会科学`

> Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models

# 摘要

> 警告：本文可能包含不适内容。LLM 在多模态任务中表现卓越，但常因训练数据而带有偏见。近期，SLLM 的兴起凸显了偏见问题的紧迫性。本研究推出 Spoken Stereoset 数据集，专为评估 SLLM 的社会偏见设计。通过分析模型对多样群体语音的反应，旨在揭示偏见。实验结果显示，多数模型偏见轻微，但仍有部分呈现刻板或反刻板倾向。

> Warning: This paper may contain texts with uncomfortable content.
  Large Language Models (LLMs) have achieved remarkable performance in various tasks, including those involving multimodal data like speech. However, these models often exhibit biases due to the nature of their training data. Recently, more Speech Large Language Models (SLLMs) have emerged, underscoring the urgent need to address these biases. This study introduces Spoken Stereoset, a dataset specifically designed to evaluate social biases in SLLMs. By examining how different models respond to speech from diverse demographic groups, we aim to identify these biases. Our experiments reveal significant insights into their performance and bias levels. The findings indicate that while most models show minimal bias, some still exhibit slightly stereotypical or anti-stereotypical tendencies.

[Arxiv](https://arxiv.org/abs/2408.07665)