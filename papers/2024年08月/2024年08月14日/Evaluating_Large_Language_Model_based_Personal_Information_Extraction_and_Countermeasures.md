# 评估大型语言模型在个人信息提取方面的表现及其应对策略

发布时间：2024年08月14日

`LLM应用` `网络安全` `个人信息保护`

> Evaluating Large Language Model based Personal Information Extraction and Countermeasures

# 摘要

> 我们系统地研究了如何利用大型语言模型（LLM）自动从公开个人资料中提取个人信息，并探索了相应的防御措施。通过构建一个基于LLM的攻击框架，我们收集了包括合成和真实数据集在内的三套数据，并创新性地引入了“提示注入”策略来对抗此类攻击。实验结果显示，LLM在个人信息提取方面超越了传统技术，而“提示注入”则有效降低了风险，表现优于传统防御手段。详细代码和数据已公开在GitHub上，供进一步研究使用。

> Automatically extracting personal information--such as name, phone number, and email address--from publicly available profiles at a large scale is a stepstone to many other security attacks including spear phishing. Traditional methods--such as regular expression, keyword search, and entity detection--achieve limited success at such personal information extraction. In this work, we perform a systematic measurement study to benchmark large language model (LLM) based personal information extraction and countermeasures. Towards this goal, we present a framework for LLM-based extraction attacks; collect three datasets including a synthetic dataset generated by GPT-4 and two real-world datasets with manually labeled 8 categories of personal information; introduce a novel mitigation strategy based on \emph{prompt injection}; and systematically benchmark LLM-based attacks and countermeasures using 10 LLMs and our 3 datasets. Our key findings include: LLM can be misused by attackers to accurately extract various personal information from personal profiles; LLM outperforms conventional methods at such extraction; and prompt injection can mitigate such risk to a large extent and outperforms conventional countermeasures. Our code and data are available at: \url{https://github.com/liu00222/LLM-Based-Personal-Profile-Extraction}.

[Arxiv](https://arxiv.org/abs/2408.07291)