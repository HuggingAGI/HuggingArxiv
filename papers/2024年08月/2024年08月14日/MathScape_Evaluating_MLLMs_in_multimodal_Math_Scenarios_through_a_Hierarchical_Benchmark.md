# MathScape 项目旨在通过分层基准，评估多模态数学场景下的 MLLMs 表现。

发布时间：2024年08月14日

`LLM应用` `人工智能`

> MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark

# 摘要

> 随着多模态大型语言模型 (MLLMs) 的进步，数学问题背景下的多模态模型评估成为一个重要研究领域。多模态视觉-文本数学推理是衡量 MLLMs 复杂推理能力的关键。然而，现有基准未能充分融合视觉与文本信息。为此，我们推出 MathScape 新基准，专注于视觉与文本结合信息的理解和应用。MathScape 通过分类层次方法，评估 MLLMs 在实际数学问题中的表现。我们评估了 11 个先进模型，发现 MathScape 对顶级模型也颇具挑战。评估结果分析揭示了 MLLMs 的局限，为提升性能提供了宝贵见解。

> With the development of Multimodal Large Language Models (MLLMs), the evaluation of multimodal models in the context of mathematical problems has become a valuable research field. Multimodal visual-textual mathematical reasoning serves as a critical indicator for evaluating the comprehension and complex multi-step quantitative reasoning abilities of MLLMs. However, previous multimodal math benchmarks have not sufficiently integrated visual and textual information. To address this gap, we proposed MathScape, a new benchmark that emphasizes the understanding and application of combined visual and textual information. MathScape is designed to evaluate photo-based math problem scenarios, assessing the theoretical understanding and application ability of MLLMs through a categorical hierarchical approach. We conduct a multi-dimensional evaluation on 11 advanced MLLMs, revealing that our benchmark is challenging even for the most sophisticated models. By analyzing the evaluation results, we identify the limitations of MLLMs, offering valuable insights for enhancing model performance.

[Arxiv](https://arxiv.org/abs/2408.07543)