# 探究 LLM 架构在巴西标准化国家考试中的表现

发布时间：2024年08月09日

`LLM应用` `人工智能`

> Examining the Behavior of LLM Architectures Within the Framework of Standardized National Exams in Brazil

# 摘要

> 巴西的ENEM考试对学生至关重要，涉及多项高中水平测试和一个作文。由于政府透明政策，学生答题和社经问卷每年匿名公开。在大语言模型（LLM）背景下，这些数据便于比较人类与AI。我们比较了GPT-3.5、GPT-4和MariTalk（用葡萄牙语训练）与人类，探究模型答案与社会群体的关系及潜在偏见。我们按社经地位（SES）划分人类群体，对比其与LLM的答案分布。在巴西葡萄牙语多项选择测试中，LLM与人类表现无显著偏见，差异主要源于人类准确性。作文分析显示，人类与LLM在词汇选择和语法结构上存在差异，LLM作文句子较短、思维单元较少。这些发现表明，在ENEM背景下，LLM的巴西葡萄牙语输出与学生答案显著不同，不代表任何人类群体。

> The Exame Nacional do Ensino Médio (ENEM) is a pivotal test for Brazilian students, required for admission to a significant number of universities in Brazil. The test consists of four objective high-school level tests on Math, Humanities, Natural Sciences and Languages, and one writing essay. Students' answers to the test and to the accompanying socioeconomic status questionnaire are made public every year (albeit anonymized) due to transparency policies from the Brazilian Government. In the context of large language models (LLMs), these data lend themselves nicely to comparing different groups of humans with AI, as we can have access to human and machine answer distributions. We leverage these characteristics of the ENEM dataset and compare GPT-3.5 and 4, and MariTalk, a model trained using Portuguese data, to humans, aiming to ascertain how their answers relate to real societal groups and what that may reveal about the model biases. We divide the human groups by using socioeconomic status (SES), and compare their answer distribution with LLMs for each question and for the essay. We find no significant biases when comparing LLM performance to humans on the multiple-choice Brazilian Portuguese tests, as the distance between model and human answers is mostly determined by the human accuracy. A similar conclusion is found by looking at the generated text as, when analyzing the essays, we observe that human and LLM essays differ in a few key factors, one being the choice of words where model essays were easily separable from human ones. The texts also differ syntactically, with LLM generated essays exhibiting, on average, smaller sentences and less thought units, among other differences. These results suggest that, for Brazilian Portuguese in the ENEM context, LLM outputs represent no group of humans, being significantly different from the answers from Brazilian students across all tests.

[Arxiv](https://arxiv.org/abs/2408.05035)