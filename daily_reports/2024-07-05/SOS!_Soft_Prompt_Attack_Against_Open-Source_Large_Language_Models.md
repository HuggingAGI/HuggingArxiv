# 紧急呼叫！针对开源大型语言模型的软提示攻击
发布时间：2024年07月03日

`模型安全`
> SOS! Soft Prompt Attack Against Open-Source Large Language Models
>
> 开源大型语言模型（LLM）因其可定制、微调及免费使用的特性，在公众和业界广受欢迎。然而，部分开源LLM需经批准方可使用，促使第三方推出更易获取的版本。同时，这些LLM的微调或量化版本也由第三方发布，因其便捷性和较低的计算资源需求而备受青睐。这一趋势却增加了训练期间的攻击风险，威胁到LLM的完整性与安全性。为此，我们提出了一种新型训练时攻击——SOS，该攻击计算需求低，无需清洁数据或修改模型权重，确保模型功能不受影响。SOS能有效应对多种安全威胁，如后门、越狱及提示窃取攻击。实验证明，SOS在所有测试目标上均表现出色。此外，我们还引入了SOS技术的另一创新——版权标记，允许用户为其版权内容打上标记，防止模型滥用。
>
> https://arxiv.org/abs/2407.03160


<hr />

- 论文原文: [https://arxiv.org/abs/2407.03160](https://arxiv.org/abs/2407.03160)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 加入社群，公众号回复LLM
- 最新论文订阅体验：公众号号菜单回复1