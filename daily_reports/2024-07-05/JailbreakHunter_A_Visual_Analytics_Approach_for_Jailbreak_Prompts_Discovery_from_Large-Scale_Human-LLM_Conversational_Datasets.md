# JailbreakHunter：一种视觉分析方法，旨在从大规模人类与 LLM 的对话数据集中发现越狱提示。
发布时间：2024年07月03日

`模型安全`
> JailbreakHunter: A Visual Analytics Approach for Jailbreak Prompts Discovery from Large-Scale Human-LLM Conversational Datasets
>
> 大型语言模型（LLM）备受瞩目，但滥用风险也引发担忧。越狱提示作为针对LLM的对抗性攻击手段，不断演化以突破安全防线。为应对这一挑战，LLM定期更新安全补丁，但恶意用户常保密成功提示以利用模型。为此，我们需深入分析大规模对话数据，以揭示那些仍能绕过防御的提示。面对数据量庞大、提示多样且藏匿于复杂对话中的挑战，我们推出了JailbreakHunter，一种可视化分析工具，用于在大规模人-LLM对话中识别越狱提示。该工具通过组级、对话级和轮次级三个层次的分析，帮助用户掌握对话分布、理解对话进展，并探索提示间的语义联系，从而发现新的越狱策略。通过案例研究和专家评估，我们验证了该工具的有效性和实用性。
>
> https://arxiv.org/abs/2407.03045

![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.03045/x1.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.03045/x2.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.03045/x3.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.03045/x4.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.03045/x5.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.03045/x6.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.03045/x7.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.03045/x8.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.03045/x9.png)

<hr />

- 论文原文: [https://arxiv.org/abs/2407.03045](https://arxiv.org/abs/2407.03045)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 加入社群，公众号回复LLM
- 最新论文订阅体验：公众号号菜单回复1