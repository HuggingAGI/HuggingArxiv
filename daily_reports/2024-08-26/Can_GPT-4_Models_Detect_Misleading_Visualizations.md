# GPT-4 模型是否能识别误导性图表？
发布时间：2024年08月08日

`多模态大模型`
> Can GPT-4 Models Detect Misleading Visualizations?
>
> 在网络空间，误导性可视化内容的泛滥，尤其是在公共卫生危机和选举等关键时刻，已成为一大隐患。本研究聚焦于GPT-4系列模型（4V、4o及4o mini）在识别这些误导性可视化方面的能力。通过一个包含多种视觉误导元素的推文与可视化配对数据集，我们在四种不同指导程度的实验条件下对这些模型进行了测试。结果显示，即便未经预训练（即朴素零-shot），GPT-4模型也能以中等准确度识别误导性可视化，而当模型获得误导元素的定义（引导零-shot）时，其性能显著提升。但值得注意的是，并非单一的提示工程策略能适用于所有误导类型。具体来说，提供误导元素的定义及实例（引导少-shot）对识别推理类误导更为有效，而针对设计类误导，引导零-shot则表现更佳。此项研究不仅验证了大型视觉-语言模型在检测视觉虚假信息方面的可行性，也凸显了提示工程在提升检测准确性中的关键作用。
>
> https://arxiv.org/abs/2408.12617

**点击公众号菜单加入大语言模型论文讨论**
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2408.12617](https://arxiv.org/abs/2408.12617)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)