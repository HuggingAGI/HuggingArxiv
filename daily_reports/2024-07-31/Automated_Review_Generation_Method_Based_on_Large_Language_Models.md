# 大型语言模型驱动的自动评论生成技术
发布时间：2024年07月30日


> Automated Review Generation Method Based on Large Language Models
>
> 在科学研究中，文献研究至关重要，但海量信息令人应接不暇。为此，我们开发了一种基于大型语言模型（LLM）的自动化综述生成方法，旨在简化文献处理并减轻认知负担。在丙烷脱氢催化剂的研究案例中，我们的方法高效地从343篇文章中生成了详尽的综述，每篇文章处理时间仅需几秒。进一步分析1041篇文章，深入揭示了催化剂的组成、结构与性能。为应对LLM可能产生的幻觉问题，我们实施了多层次的质量控制，确保了方法的可靠性及幻觉的有效控制。专家验证显示，生成综述的准确性与引用完整性极高，LLM幻觉风险降至0.5%以下，置信度超95%。推出的Windows应用支持一键生成综述，助力研究人员追踪科研进展并推荐优质文献。这一创新方法不仅彰显了LLM在提升科研效率中的潜力，也为未来探索开辟了新路径。
>
> https://arxiv.org/abs/2407.20906

**点击公众号菜单加入大语言模型论文讨论**
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)
<hr />

![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.20906/x1.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.20906/x2.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.20906/x3.png)

<hr />

- 论文原文: [https://arxiv.org/abs/2407.20906](https://arxiv.org/abs/2407.20906)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)