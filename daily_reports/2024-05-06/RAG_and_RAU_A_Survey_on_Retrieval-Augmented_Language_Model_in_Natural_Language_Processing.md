![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/imgs/follow2.gif)
# RAG 与 RAU：探索自然语言处理领域中的检索增强语言模型
发布时间：2024年04月30日

`RAG`
> RAG and RAU: A Survey on Retrieval-Augmented Language Model in Natural Language Processing
>
> 大型语言模型（LLMs）极大地推动了自然语言处理（NLP）的发展，但同时也面临着幻觉现象和对特定领域知识的依赖等挑战。为了应对这些挑战，最新的研究方法开始将外部资源检索到的信息与LLMs相结合，显著提升了模型在各类NLP任务中的表现。本篇综述文章填补了对检索增强语言模型（RALMs）——包括检索增强生成（RAG）和检索增强理解（RAU）——全面概述的空白，深入探讨了它们的模式、发展、分类法和应用场景。文中详细阐述了RALMs的核心组件，包括检索器、语言模型和增强手段，以及这些组件如何相互作用，形成多样化的模型架构和应用。RALMs在多种任务中都显示出其实用性，包括翻译、对话系统和知识密集型应用。文章还包含了对RALMs的多种评估方法，特别强调了评估过程中对鲁棒性、准确性和相关性的关注。同时，也指出了RALMs的局限性，尤其是在检索质量和计算效率方面，并对未来的研究方向提出了建议。总结而言，本综述旨在提供对RALMs的结构化理解，探讨其潜力及其在NLP领域未来发展的可能路径。此外，文章还提供了一个包含相关研究和资源的Github仓库，供进一步研究使用：https://github.com/2471023025/RALM_Survey。
>
> https://arxiv.org/abs/2404.19543



- 论文原文: [https://arxiv.org/abs/2404.19543](https://arxiv.org/abs/2404.19543)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886