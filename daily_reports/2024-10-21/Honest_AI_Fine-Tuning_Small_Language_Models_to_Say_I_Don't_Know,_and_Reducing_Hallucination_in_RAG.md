# 让AI更诚实：通过微调小型语言模型，使其能说“我不知道”，并减少RAG中的幻觉现象。
发布时间：2024年10月12日

`RAG`
> Honest AI: Fine-Tuning "Small" Language Models to Say "I Don't Know", and Reducing Hallucination in RAG
>
> 幻觉是 LLM 应用中的关键难题，尤其在企业应用中，信息准确性至关重要。为解决此问题，我们探索了两种方法：RAG 提供更新信息，以及微调 LLM 以适应新信息和输出风格。本文提出 Honest AI，通过微调“小”模型使其说“我不知道”来减少幻觉，并结合多种 RAG 方法。该方案在任务 2 中排名第一。替代方法包括结合搜索引擎和知识图谱的 RAG，微调基础 LLM，以及两者的结合。虽然所有方法都提升了 LLM 性能，但仅 RAG 效果有限，微调更为关键。最终，混合方法在 CRAG 基准中表现最佳。此外，我们提倡使用少于 100 亿参数的小模型，以提高资源效率。
>
> https://arxiv.org/abs/2410.09699

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2410.09699](https://arxiv.org/abs/2410.09699)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)