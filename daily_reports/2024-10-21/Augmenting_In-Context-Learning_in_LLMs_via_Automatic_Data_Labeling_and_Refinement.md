# 借助自动数据标注与优化，提升 LLM 中的 In-Context-Learning 效果
发布时间：2024年10月14日


> Augmenting In-Context-Learning in LLMs via Automatic Data Labeling and Refinement
>
> 大型语言模型 (LLM) 通过 Chain of Thought (CoT) 或 In-Context Learning (ICL) 可以显著提升性能，但这些方法需要繁琐的手动演示。为此，我们提出了自动数据标注和细化 (ADLR)，从少量手工示例出发，自动生成和优化包含中间步骤的演示。实验表明，ADLR 在代码表格问答和数学推理任务中，性能提升高达 5.5%。相关代码将在补充材料中公开。
>
> https://arxiv.org/abs/2410.10348

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2410.10348](https://arxiv.org/abs/2410.10348)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)