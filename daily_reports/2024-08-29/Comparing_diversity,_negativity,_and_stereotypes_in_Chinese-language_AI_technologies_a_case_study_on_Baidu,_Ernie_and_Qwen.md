# 探究中文AI技术中的多样性、负面信息及刻板印象：百度、Ernie与Qwen的案例分析
发布时间：2024年08月28日

`模型榜单`
> Comparing diversity, negativity, and stereotypes in Chinese-language AI technologies: a case study on Baidu, Ernie and Qwen
>
> 大型语言模型与搜索引擎可能通过放大训练数据中的偏见，影响公众观念与决策，从而助长偏见与刻板印象。我们聚焦于中国情境，深入分析百度搜索引擎及两大领先模型Ernie与Qwen中潜藏的社会偏见。通过涵盖13类、240个社会群体的数据集，我们搜集了这些工具中逾3万条观点。研究发现，语言模型呈现的观点多样性超过搜索引擎，且百度与Qwen的负面内容生成频率高于Ernie。同时，模型中亦存在一定程度的刻板印象，部分可能带有冒犯性。本研究凸显了在全球视野下推动AI技术公平与包容的紧迫性。
>
> https://arxiv.org/abs/2408.15696

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2408.15696](https://arxiv.org/abs/2408.15696)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)