# 在不断变化的环境中，结合知识图谱的LLM多跳问答技术
发布时间：2024年08月28日

`知识图谱`
> LLM-Based Multi-Hop Question Answering with Knowledge Graph Integration in Evolving Environments
>
> 随着大型语言模型中信息的迅速过时，我们开发了多种技术来整合新事实。然而，现有知识编辑技术在处理复杂的多跳问题时仍显不足，这些问题需要精确的事实识别和连续的逻辑推理，尤其是在频繁更新事实的情况下。为此，我们提出了基于图记忆的大型语言模型编辑方法 (GMeLLo)，它巧妙地将知识图谱的结构化知识表示与语言模型的灵活性结合，不仅用于问答，还能将自然语言转换为结构化查询，实现与知识图谱的高效互动，支持快速更新和精准的多跳推理。实验表明，GMeLLo 在多跳问答基准 MQuAKE 上大幅领先现有技术，特别是在需要大量知识更新的场景中。
>
> https://arxiv.org/abs/2408.15903

**点击公众号菜单加入大语言模型论文讨论**
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)
<hr />

![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2408.15903/x1.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2408.15903/x3.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2408.15903/x4.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2408.15903/x5.png)

<hr />

- 论文原文: [https://arxiv.org/abs/2408.15903](https://arxiv.org/abs/2408.15903)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)