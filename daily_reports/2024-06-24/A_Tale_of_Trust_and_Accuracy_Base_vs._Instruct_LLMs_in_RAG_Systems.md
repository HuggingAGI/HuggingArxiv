# 信任与准确性的较量：基础LLM与指令LLM在RAG系统中的较量
发布时间：2024年06月21日

`RAG`
> A Tale of Trust and Accuracy: Base vs. Instruct LLMs in RAG Systems
>
> 检索增强生成（RAG）技术结合了检索与生成两个阶段，后者通常依赖于大型语言模型（LLMs），标志着人工智能的一大飞跃。目前，RAG实践中常采用经过监督训练微调的“指导型”LLMs，以更好地遵循指令并符合人类偏好。然而，我们的研究发现，在RAG任务中，基础模型平均比指导型模型高出20%的表现，这与普遍认为指导型LLMs更优越的观点相悖。这一发现促使我们深入探讨RAG的本质，并呼吁对该领域进行更广泛的讨论，正如Fromm所言，“统计数据背后的深意，往往不是一眼就能看穿的”。
>
> https://arxiv.org/abs/2406.14972

![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2406.14972/x1.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2406.14972/x2.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2406.14972/x3.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2406.14972/x4.png)

<hr />

- 论文原文: [https://arxiv.org/abs/2406.14972](https://arxiv.org/abs/2406.14972)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 最新论文订阅体验：公众号号菜单回复1
- 最新论文订阅新人：公众号号菜单回复2