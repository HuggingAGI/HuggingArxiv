# 辩论中的多智能体协作攻击：探究大型语言模型协作中的对抗性策略
发布时间：2024年06月20日

`多Agent应用`
> MultiAgent Collaboration Attack: Investigating Adversarial Attacks in Large Language Model Collaborations via Debate
>
> 大型语言模型（LLMs）在独立运行时已展现出卓越的性能。随着技术进步，这些模型不仅在参数和推理时间上更为精简，还能作为智能代理，协同执行复杂任务。这种多模型协作不仅利用了各自的专业技能（如编程），还通过多重计算增强了决策信心，并激发了更丰富的创意输出。因此，语言模型间的协作预计将在未来几年内显著增长。本研究聚焦于一个模型网络在敌对干扰下通过辩论进行协作的行为，并引入了衡量敌对效果的新指标，特别关注系统准确性和模型间的一致性。研究结果凸显了模型说服力的重要性，并探索了在推理阶段生成更具说服力论点的方法，以及基于提示的防御策略的潜力。
>
> https://arxiv.org/abs/2406.14711

![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2406.14711/collab-description-plot.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2406.14711/attack_idea_example.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2406.14711/models_accuracy.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2406.14711/model_delta_accuracy.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2406.14711/attack_acc_agreement.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2406.14711/mitigation.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2406.14711/ablation_n_rounds.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2406.14711/ablation_n_agents.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2406.14711/majority_vote_behavior.png)

<hr />

- 论文原文: [https://arxiv.org/abs/2406.14711](https://arxiv.org/abs/2406.14711)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 最新论文订阅体验：公众号号菜单回复1
- 最新论文订阅新人：公众号号菜单回复2