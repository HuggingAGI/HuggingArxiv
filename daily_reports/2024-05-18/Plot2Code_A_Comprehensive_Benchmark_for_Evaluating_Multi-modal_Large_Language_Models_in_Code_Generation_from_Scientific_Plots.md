# Plot2Code：科学图表至代码生成的多模态大型语言模型全面评估基准
发布时间：2024年05月13日

`多模态大模型`
> Plot2Code: A Comprehensive Benchmark for Evaluating Multi-modal Large Language Models in Code Generation from Scientific Plots
>
> 多模态大型语言模型（MLLMs）因其卓越的视觉表现而备受瞩目，但它们将视觉图形转化为代码的能力尚未得到充分检验。为此，我们推出了Plot2Code，一个专为MLLMs设计的全面视觉编码基准，旨在进行公正且深入的评估。我们精心挑选了132个高质量的matplotlib图表，涵盖六种图表类型，并为其提供了源代码和GPT-4总结的描述性指令。Plot2Code通过这些多样化的输入模态，全面测试了MLLMs的编码能力。我们还提出了三个自动评估指标：代码通过率、文本匹配比率和GPT-4V总体评分，以细致地评估输出代码和图像。我们不仅判断通过与否，还利用GPT-4V对生成图像与参考图像进行整体比较，其结果与人类评估高度一致。评估涵盖了14个MLLMs，包括GPT-4V、Gemini-Pro和Mini-Gemini等，揭示了Plot2Code带来的重大挑战。Plot2Code显示，大多数MLLMs在处理文本密集型图表时遇到困难，过度依赖文本指令。我们期待Plot2Code的评估结果能够为MLLMs的未来发展提供指引。所有Plot2Code相关数据可在https://huggingface.co/datasets/TencentARC/Plot2Code获取。
>
> https://arxiv.org/abs/2405.07990

![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2405.07990/x1.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2405.07990/x2.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2405.07990/x3.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2405.07990/x4.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2405.07990/x5.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2405.07990/x6.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2405.07990/x7.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2405.07990/x8.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2405.07990/x9.png)

<hr />

- 论文原文: [https://arxiv.org/abs/2405.07990](https://arxiv.org/abs/2405.07990)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886