# 借助文本语义匹配，本研究提出了一种语言引导的自监督视频摘要方法，旨在捕捉视频内容的多样性，从而生成更加丰富和精准的视频摘要。
发布时间：2024年05月14日

`多模态大模型`
> Language-Guided Self-Supervised Video Summarization Using Text Semantic Matching Considering the Diversity of the Video
>
> 当前视频摘要技术依赖于监督学习，需要大量主观且耗时的手动标注。为了克服这一挑战，我们探索了将视频摘要任务转化为文本摘要，并借助大型语言模型（LLMs）增强效果的可能性。本文提出了一种创新的自我监督框架，利用LLMs指导视频摘要生成。首先，我们为视频帧自动生成标题，然后通过LLMs将这些标题整合成连贯的文本摘要。接着，我们测量帧标题与文本摘要之间的语义相似度，并设计了一种新的损失函数，以视频内容的多样性为依据优化模型。最终，我们通过挑选与文本摘要语义相近的帧来生成视频摘要。我们的模型在性能上与现有顶尖方法相媲美，为视频摘要领域开辟了新的研究方向。
>
> https://arxiv.org/abs/2405.08890


<hr />

- 论文原文: [https://arxiv.org/abs/2405.08890](https://arxiv.org/abs/2405.08890)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 公众号回复关键词获取论文原文： 1522485551885852