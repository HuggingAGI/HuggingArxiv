# SFR-RAG：迈向上下文忠实的大型语言模型
发布时间：2024年09月15日

`RAG`
> SFR-RAG: Towards Contextually Faithful LLMs
>
> RAG 通过整合外部信息与 LLM，显著提升了生成内容的事实准确性，成为生成式 AI 的核心技术。RAG 中的 LLM 需精准理解上下文及用户问题，避免幻觉，应对复杂推理，并提供可靠引用。本文介绍的 SFR-RAG 是一款小型 LLM，特别优化了基于上下文的生成和幻觉控制。同时，我们推出的 ContextualBench 评估框架，整合了 HotpotQA 和 TriviaQA 等多样基准，确保评估的一致性和可重复性。实验显示，SFR-RAG-9B 在多个基准测试中超越了 Command-R+ 和 GPT-4o，参数更少却表现更优。SFR-RAG 还能灵活应对上下文变化，并在相关信息缺失时依然表现稳健。此外，它在指令跟随和功能调用方面也表现出色。
>
> https://arxiv.org/abs/2409.09916

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2409.09916](https://arxiv.org/abs/2409.09916)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)