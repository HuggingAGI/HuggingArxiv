# 知识图谱、大型语言模型与幻觉：从自然语言处理的视角来看
发布时间：2024年11月21日

`综述`
> Knowledge Graphs, Large Language Models, and Hallucinations: An NLP Perspective
>
> 大型语言模型（LLMs）给基于自然语言处理（NLP）的应用带来了革命性变化，像自动文本生成、问答、聊天机器人等等。但它们面临着一个严峻挑战——幻觉，也就是模型会给出看似合理实则错误的回答。这损害了信任，限制了LLMs在不同领域的应用。而知识图谱（KGs）呢，提供了结构化的相互关联的事实集合，表现为实体（节点）和它们的关系（边）。在近期研究里，KGs被用来提供上下文，能填补LLM对某些主题理解的空缺，为缓解LLMs的幻觉提供了很有前景的办法，增强了其可靠性和准确性，还得益于其广泛适用性。不过，这仍是个活跃的研究领域，存在诸多未解决的开放问题。在本文中，我们探讨了这些开放挑战，涵盖了前沿的数据集和基准，还有知识集成及评估幻觉的方法。在讨论中，我们考虑了KGs在LLM系统中的当下运用，并明确了每个挑战中的未来走向。
>
> https://arxiv.org/abs/2411.14258

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2411.14258](https://arxiv.org/abs/2411.14258)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)