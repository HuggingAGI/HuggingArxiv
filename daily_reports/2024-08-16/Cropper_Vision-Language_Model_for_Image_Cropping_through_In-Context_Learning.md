# Cropper：一种利用上下文学习技术进行图像裁剪的视觉-语言模型
发布时间：2024年08月14日

`多模态大模型`
> Cropper: Vision-Language Model for Image Cropping through In-Context Learning
>
> 图像裁剪旨在从图像中挑选出视觉上吸引人的部分。传统方法受限于特定数据集训练的专用架构，难以适应新需求。随着大型视觉-语言模型（VLM）的进步，视觉上下文学习无需显式训练成为可能。然而，如何有效利用VLM进行视觉下游任务仍待深入探索。本文提出一种新方法，通过VLM优化图像裁剪。首先，我们设计了一种高效的提示检索机制，自动选取上下文示例。接着，采用迭代细化策略，逐步提升裁剪质量。名为Cropper的框架，广泛适用于各类裁剪任务，如自由形式、主题感知及宽高比感知裁剪。实验与用户研究显示，Cropper在多个基准测试中大幅超越现有技术。
>
> https://arxiv.org/abs/2408.07790

**点击公众号菜单加入大语言模型论文讨论**
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2408.07790](https://arxiv.org/abs/2408.07790)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)