# 引导大型语言模型，一步步编织科学文献的综述篇章
发布时间：2024年08月14日


> Instruct Large Language Models to Generate Scientific Literature Survey Step by Step
>
> 自动生成科学文献综述，这一任务极具价值，能大幅提升研究效率。然而，文献综述信息的多样与复杂，对生成模型提出了严峻挑战。本文中，我们巧妙设计一系列提示，系统化地运用大型语言模型（LLMs），通过分步骤策略，构建详尽的文献综述。我们精心设计的提示，引导LLMs依次产出标题、摘要、层次标题及主要内容，确保从宏观视角生成标题。在内容创作阶段，此设计高效整合相关信息，同时通过精简LLM查询的输入输出长度，有效控制成本。与Qwen-long携手，我们在NLPCC 2024科学文献综述生成评比中荣获季军，总分仅落后亚军0.03%。软标题召回率高达95.84%，位居次席。得益于精妙的提示设计与Qwen-long API的经济性，我们成功将每篇文献综述的生成成本降至0.1元，大幅提升了方法的实用价值。
>
> https://arxiv.org/abs/2408.07884

**点击公众号菜单加入大语言模型论文讨论**
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)
<hr />

![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2408.07884/p1.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2408.07884/p2g.png)

<hr />

- 论文原文: [https://arxiv.org/abs/2408.07884](https://arxiv.org/abs/2408.07884)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)