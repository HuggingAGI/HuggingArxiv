# LLM 在系统性文献综述中展现出了高效过滤的潜力，能够帮助我们穿透信息的杂乱，更精准地筛选出有价值的研究。
发布时间：2024年07月15日


> Cutting Through the Clutter: The Potential of LLMs for Efficient Filtration in Systematic Literature Reviews
>
> 在学术领域，系统性文献综述至关重要，但因其涉及大量出版物和繁琐流程而显得冗长。传统基于关键词的筛选方法常因语义模糊和术语不一致而效果欠佳。为此，我们探索利用大型语言模型（LLMs）提升文献筛选的效率与精准度，减少人工负担。通过模型仅作为分类工具处理结构化数据，我们规避了LLMs的常见缺陷，如产生幻觉。在最近一次文献调查中，我们评估了LLMs在处理超过8.3k篇潜在相关文章时的表现，并与人工筛选进行了对比。结果显示，借助GPT-4o等先进模型及简单提示，文献筛选时间从数周缩短至几分钟。此外，通过共识机制，我们有效控制了假阴性率，召回率超过98.8%，甚至优于人类标准，确保了选文的准确性与相关性。这一研究不仅革新了文献综述方法，更为人工智能在学术研究中的深入应用铺平了道路。
>
> https://arxiv.org/abs/2407.10652

![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.10652/x2.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.10652/x3.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.10652/matrix.png)

<hr />

- 论文原文: [https://arxiv.org/abs/2407.10652](https://arxiv.org/abs/2407.10652)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 加入社群，公众号回复LLM
- 最新论文订阅体验：公众号号菜单回复1