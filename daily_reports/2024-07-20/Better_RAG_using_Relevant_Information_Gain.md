# 通过相关信息增益优化 RAG
发布时间：2024年07月16日

`RAG`
> Better RAG using Relevant Information Gain
>
> 扩展 LLM 记忆的常用手段是 RAG，它将外部文本引入模型上下文。但上下文窗口的限制意味着我们需要精心挑选信息，既要多样又要相关。为此，我们设计了一种新的优化指标，基于相关信息增益，自然地促进多样性。这一创新方法在 RGB 基准的问题回答任务中表现卓越，超越了传统方法。
>
> https://arxiv.org/abs/2407.12101

![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.12101/x1.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.12101/x2.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.12101/x3.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.12101/x4.png)

<hr />

- 论文原文: [https://arxiv.org/abs/2407.12101](https://arxiv.org/abs/2407.12101)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 加入社群，公众号回复LLM
- 最新论文订阅体验：公众号号菜单回复1