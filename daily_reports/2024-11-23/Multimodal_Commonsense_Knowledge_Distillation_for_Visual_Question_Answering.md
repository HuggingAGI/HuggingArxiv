# 用于视觉问答的多模态常识知识蒸馏
发布时间：2024年11月04日


> Multimodal Commonsense Knowledge Distillation for Visual Question Answering
>
> 现有的多模态大型语言模型（MLLMs）和视觉语言预训练模型（VLPMs）在一般的视觉问答（VQA）中表现出色。然而，由于生成高质量提示的挑战和微调的高计算成本，这些模型在处理需要外部常识知识的 VQA 问题时遇到困难。在这项工作中，我们提出了一种新颖的基于图的多模态常识知识蒸馏框架，该框架通过图卷积网络（GCN）在教师-学生环境下构建了一个关于常识知识、视觉对象和问题的统一关系图。这个提出的框架对于任何类型的教师和学生模型都具有灵活性，无需进一步微调，并且在 ScienceQA 数据集上取得了有竞争力的性能。
>
> https://arxiv.org/abs/2411.02722

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2411.02722](https://arxiv.org/abs/2411.02722)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)