# 基于 RAG 的问答系统助力上下文响应预测
发布时间：2024年09月05日

`RAG`
> RAG based Question-Answering for Contextual Response Prediction System
>
> 大型语言模型 (LLM) 在多种 NLP 任务中表现出色，尤其在问答系统方面潜力巨大。然而，在行业应用中，为了提供精准且相关的信息，LLM 需要依赖全面的知识库，以避免信息失真。检索增强生成 (RAG) 技术应运而生，成为解决这一难题的希望。但利用 RAG 构建实际应用中的问答框架，仍面临三大挑战：数据获取难、生成内容质量评估难、人工评估成本高。本文提出一个端到端框架，结合 RAG 技术与 LLM，专为行业需求设计。该系统能根据客户查询，自动检索相关文档并结合历史对话，生成客服代理的响应建议。经全面评估，该方案在准确性与相关性上超越了基于 BERT 的算法。研究显示，RAG 赋能的 LLM 能有效减轻客服负担，成为他们的得力助手。
>
> https://arxiv.org/abs/2409.03708

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2409.03708](https://arxiv.org/abs/2409.03708)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)