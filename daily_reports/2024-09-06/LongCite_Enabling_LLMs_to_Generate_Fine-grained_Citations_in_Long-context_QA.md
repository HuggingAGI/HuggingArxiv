# LongCite 技术让 LLM 在长篇问答中也能精准生成引用，提升了引用的细致度和准确性。
发布时间：2024年09月04日


> LongCite: Enabling LLMs to Generate Fine-grained Citations in Long-context QA
>
> 尽管长上下文 LLM 在处理大量文本并回答问题方面表现出色，但其回答中缺乏引用导致用户难以验证，进而引发对其可信度的疑虑。为此，我们致力于让长上下文 LLM 生成包含细粒度句子级引用的回答，以提升其忠实度和可验证性。我们首先推出了 LongBench-Cite 基准，用于评估 LLM 在长上下文问答中的表现，并揭示了显著的改进空间。接着，我们设计了 CoF 流程，利用现有 LLM 自动生成精确引用，并构建了 LongCite-45k 数据集。基于此数据集，我们训练了 LongCite-8B 和 LongCite-9B 模型，使其能在单次输出中提供准确回答及详细引用。评估结果表明，我们的模型在引用质量上超越了包括 GPT-4o 在内的顶尖专有模型，达到了业界领先水平。
>
> https://arxiv.org/abs/2409.02897

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2409.02897](https://arxiv.org/abs/2409.02897)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)