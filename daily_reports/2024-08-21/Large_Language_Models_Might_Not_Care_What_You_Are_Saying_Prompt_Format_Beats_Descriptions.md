# 大型语言模型或许并不在意你的言辞，提示格式往往比描述更为有效。
发布时间：2024年08月16日

`提示工程`
> Large Language Models Might Not Care What You Are Saying: Prompt Format Beats Descriptions
>
> 通过 in-context learning (ICL)，大型语言模型 (LLMs) 在多任务中表现卓越。然而，描述性指令在 ICL 中的作用尚待深入研究。我们提出集成提示框架，明确 in-context 示例的选择标准，并在六种翻译方向的机器翻译实验中验证其提升 ICL 性能。有趣的是，LLMs 对描述内容的关注度不高，性能提升主要源于集成格式，即便使用随机描述性名词，框架仍能带来改进。我们还将此框架应用于多种任务，包括常识、数学、逻辑推理等，结果喜人，再次强调设计合适提示格式的重要性。代码将在论文发表后公开。
>
> https://arxiv.org/abs/2408.08780

**点击公众号菜单加入大语言模型论文讨论**
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)
<hr />

![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2408.08780/vanilla-prompt.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2408.08780/ensemble-prompt.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2408.08780/mt-main.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2408.08780/mt-ablation.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2408.08780/7b.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2408.08780/gpt.png)

<hr />

- 论文原文: [https://arxiv.org/abs/2408.08780](https://arxiv.org/abs/2408.08780)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)