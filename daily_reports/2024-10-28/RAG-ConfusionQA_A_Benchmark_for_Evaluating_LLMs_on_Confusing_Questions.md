# RAG-ConfusionQA：评估 LLM 应对混淆问题的基准
发布时间：2024年10月18日

`RAG`
> RAG-ConfusionQA: A Benchmark for Evaluating LLMs on Confusing Questions
>
> 对话式 AI 代理通过 RAG 技术提供基于文档的可验证回答，但许多自然问题难以解答：约 25% 包含错误假设，超过 50% 模糊不清。为提升 RAG 代理应对复杂问题的能力，本文提出了一种高效的合成数据生成方法，从现有文档中创建多样化的混乱问题。我们还对多个大型语言模型进行了实证评估，以测试其混淆检测和适当回答的能力，并公开了一个基准数据集。
>
> https://arxiv.org/abs/2410.14567

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2410.14567](https://arxiv.org/abs/2410.14567)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)