# 探索基于 LLM 的个性化多源会议摘要，揭示你需要了解的关键信息。
发布时间：2024年10月18日


> Tell me what I need to know: Exploring LLM-based (Personalized) Abstractive Multi-Source Meeting Summarization
>
> 会议摘要对数字通信至关重要，但现有方法在生成个性化摘要和理解会议内容方面仍有不足。以往尝试通过结合演示文稿等补充资源来改进，但受限于模型上下文大小和多源任务的复杂性。本研究采用三阶段大型语言模型方法，通过识别需补充的转录段落、从补充材料中提取相关信息并整合，最终生成更丰富的摘要。这种方法不仅将摘要相关性提升了约9%，还通过个性化协议提取参与者特征，使摘要信息量增加了约10%。此外，我们还探讨了四大模型家族的性能成本权衡，包括适用于边缘设备的选择。此方法可应用于对话系统和行动规划等复杂生成任务，进一步提升其效果。
>
> https://arxiv.org/abs/2410.14545

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2410.14545](https://arxiv.org/abs/2410.14545)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)