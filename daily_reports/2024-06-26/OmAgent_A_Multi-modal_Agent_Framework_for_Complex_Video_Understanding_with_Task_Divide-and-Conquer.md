# OmAgent：专为复杂视频理解设计的多模态代理框架，通过任务分解与征服策略优化处理流程。
发布时间：2024年06月24日

`Agent应用`
> OmAgent: A Multi-modal Agent Framework for Complex Video Understanding with Task Divide-and-Conquer
>
> 大型语言模型（LLMs）的最新进展已将其能力扩展至多模态领域，涵盖了全面视频理解。尽管如此，处理如24小时监控录像或完整电影这类海量视频时，因数据量和处理需求庞大，仍面临严峻挑战。传统方法，如关键帧提取或帧转文本，往往导致信息大量流失。为此，我们研发了OmAgent，它能高效地存储和检索与特定查询相关的视频帧，确保视频内容的完整性。OmAgent还拥有一个分而治之的自主推理循环，能动态调用API和工具，提升查询处理效率和准确性。这一策略极大地增强了视频理解能力，减少了信息损失。实验证明，OmAgent在应对各类视频及复杂任务时表现出色。此外，我们还增强了其自主性，并配备了一个强大的工具调用系统，使其能胜任更为精细的任务。
>
> https://arxiv.org/abs/2406.16620

![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2406.16620/x1.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2406.16620/x2.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2406.16620/x3.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2406.16620/x4.png)

<hr />

- 论文原文: [https://arxiv.org/abs/2406.16620](https://arxiv.org/abs/2406.16620)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 最新论文订阅体验：公众号号菜单回复1
- 最新论文订阅新人：公众号号菜单回复2