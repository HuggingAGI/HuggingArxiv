# LLM 在生物医学信息提取方面并非零-Shot 推理器。
发布时间：2024年08月22日

`知识图谱`
> LLMs are not Zero-Shot Reasoners for Biomedical Information Extraction
>
> 大型语言模型（LLM）在医疗领域的应用日益增多，其问答和文档摘要能力已媲美专家。然而，在生物医学传统任务如结构化信息提取上，LLM的表现尚不明朗。本文针对这一问题，系统评估了LLM在医学分类和命名实体识别（NER）任务中的表现，旨在剖析任务知识、推理能力、领域知识及外部知识等因素的影响。我们测试了包括BioMistral和Llama-2在内的多种LLM模型，采用标准提示、思维链（CoT）、自一致性推理及PubMed和Wikipedia语料库的检索增强生成（RAG）等方法。令人意外的是，标准提示在两项任务中均优于复杂技术，凸显了CoT、自一致性和RAG在生物医学领域的应用局限。研究结果表明，专为知识或推理密集型任务设计的先进提示方法，如CoT或RAG，难以直接适用于需要精确结构化输出的生物医学任务。这强调了在LLM中更有效地融合外部知识和推理机制，以提升其在实际生物医学应用中的性能的重要性。
>
> https://arxiv.org/abs/2408.12249

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2408.12249](https://arxiv.org/abs/2408.12249)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)