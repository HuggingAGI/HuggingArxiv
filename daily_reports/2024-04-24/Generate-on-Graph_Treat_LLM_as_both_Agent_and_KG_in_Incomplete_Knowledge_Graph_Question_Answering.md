# 在不完整的知识图谱问答任务中，我们将大型语言模型（LLM）既视为智能代理，也视为知识库，以生成答案。
发布时间：2024年04月23日
`知识图谱`
> 为应对大型语言模型（LLMs）知识匮乏和易于产生幻觉的问题，众多研究致力于将LLMs与知识图谱（KGs）相结合。但这些方法多在完备的知识图谱问答（KGQA）环境中进行评估，即每个问题所涉及的事实三元组均被知识图谱全面覆盖。在此环境下，LLMs主要扮演搜索知识图谱以发现答案实体的角色，而非真正融合内外部知识。然而现实情况中，知识图谱往往无法全面覆盖所有问答所需的知识。本文旨在模拟现实世界环境，评估LLMs整合内外部知识的能力，提出了在不完全知识图谱（IKGQA）下进行问答的LLMs应用。在IKGQA中，所给知识图谱并未包含每个问题涉及的所有事实三元组。为此，我们提出了一种无需训练的方法——图上生成（GoG），它能够在探索知识图谱的同时产生新的事实三元组。具体而言，我们构建了一个选择-生成-回答框架，将LLMs视作探索知识图谱的智能体，同时也将其作为能够基于探索到的子图及其内在知识生成新事实的知识图谱。实验结果显示，我们的GoG方法在IKGQA任务上取得了一定成效，而大多数现有方法在此类任务上表现不佳。


[https://wx.zsxq.com/dweb2/index/topic_detail/5122514158884214](https://wx.zsxq.com/dweb2/index/topic_detail/5122514158884214)

[https://arxiv.org/abs/2404.14741](https://arxiv.org/abs/2404.14741)