# 检索增强的生成式关系抽取
发布时间：2024年04月20日
`RAG`
> 信息抽取（IE）通过实体和关系抽取（RE）技术，将杂乱无章的文本信息转化为井然有序的数据结构，其中实体间关系的辨识尤为关键。尽管众多关系抽取技术已现世，但其成效往往受限于标注数据的可用性和计算资源的丰富度。面对这些难题，大型语言模型（LLMs）崭露头角，但有时也会因训练数据的局限而产生误导性结果。为突破这些瓶颈，本文提出了一种新颖的基于检索增强生成的关系抽取方法（RAG4RE），旨在提升关系抽取的性能。我们通过一系列知名大型语言模型（LLMs），如Flan T5、Llama2和Mistral，对RAG4RE方法进行了效果评估，并选取了TACRED、TACREV、Re-TACRED和SemEval RE等权威数据集作为测试基准。研究结果显示，RAG4RE在TACRED数据集及其衍生变体中的表现尤为突出，超越了仅依赖LLMs的传统关系抽取方法。此外，RAG4RE在TACRED和TACREV数据集上的表现也显著优于以往的关系抽取技术，彰显了其在自然语言处理领域推动关系抽取任务的潜力和效果。

![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2404.13397/x1.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2404.13397/x2.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2404.13397/x3.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2404.13397/x4.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2404.13397/x5.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2404.13397/x6.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2404.13397/x7.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2404.13397/x8.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2404.13397/x9.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2404.13397/x10.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2404.13397/x11.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2404.13397/x12.png)

[https://wx.zsxq.com/dweb2/index/topic_detail/2855284852488521](https://wx.zsxq.com/dweb2/index/topic_detail/2855284852488521)

[https://arxiv.org/abs/2404.13397](https://arxiv.org/abs/2404.13397)