# 从粗到细的突出显示：减少大型语言模型中的知识幻觉
发布时间：2024年10月19日


> Coarse-to-Fine Highlighting: Reducing Knowledge Hallucination in Large Language Models
>
> 生成看似合理但错误的事实信息（即幻觉）引起了广泛研究兴趣。检索增强语言模型 (RALM) 通过提供最新知识来减少幻觉，但现有 RALM 在处理长上下文时可能加剧幻觉。为此，我们提出 COFT，一种从粗到细的高亮方法，专注于不同粒度级别的关键文本，避免在长上下文中迷失。COFT 包含召回器、评分器和选择器三个组件：召回器提取潜在关键实体，评分器衡量其重要性，选择器以动态阈值算法高亮关键段落、句子或单词。实验表明，COFT 在 F1 分数上领先 30%，并在阅读理解和问答等长篇任务中表现出色。
>
> https://arxiv.org/abs/2410.15116

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2410.15116](https://arxiv.org/abs/2410.15116)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)