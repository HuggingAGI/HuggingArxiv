# GMAI-VL 与 GMAI-VL-5.5M：一个大型的视觉语言模型以及一个致力于通用医疗 AI 的综合多模态数据集
发布时间：2024年11月21日

`多模态大模型`
> GMAI-VL & GMAI-VL-5.5M: A Large Vision-Language Model and A Comprehensive Multimodal Dataset Towards General Medical AI
>
> 尽管像 GPT-4 这类通用人工智能进步显著，但其在医疗领域（通用医疗人工智能，GMAI）的成效仍受限于专业医学知识的缺失。为应对此挑战，我们推出了 GMAI-VL-5.5M，这是通过将数百个专业医疗数据集转化为精心构建的图像-文本对而形成的综合多模态医疗数据集。该数据集任务覆盖全面、模态多样、图像-文本数据质量高。基于此多模态数据集，我们提出了 GMAI-VL，这是一个采用逐步三阶段训练策略的通用医疗视觉语言模型。此方法通过融合视觉和文本信息，显著提升了模型能力，进而增强了其处理多模态数据以及支持精准诊断和临床决策的能力。实验评估显示，GMAI-VL 在诸如视觉问答和医学图像诊断等众多多模态医疗任务中达到了领先水平。我们的贡献涵盖了 GMAI-VL-5.5M 数据集的开发、GMAI-VL 模型的引入以及在多个医疗领域新基准的建立。代码和数据集将在 https://github.com/uni-medical/GMAI-VL 发布。
>
> https://arxiv.org/abs/2411.14522

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2411.14522](https://arxiv.org/abs/2411.14522)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)