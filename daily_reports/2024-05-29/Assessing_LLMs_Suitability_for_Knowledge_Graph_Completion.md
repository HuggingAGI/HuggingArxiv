# 探究大型语言模型在知识图谱补全任务中的适用性
发布时间：2024年05月27日

`知识图谱`
> Assessing LLMs Suitability for Knowledge Graph Completion
>
> 大型语言模型（LLMs）在处理知识图谱任务，如知识图谱补全时，即便在零样本或少样本环境下也展现出卓越能力。但它们有时会生成不切实际的答案，或以不可预测的方式输出结果，导致推理错误，尽管这些答案可能满足了用户需求。为了探讨知识图谱任务中的机遇与挑战，我们选取了Mixtral-8x7B-Instruct-v0.1和gpt-3.5-turbo-0125这两款特色LLMs，在面向任务的对话系统中，针对静态知识图谱进行知识图谱补全实验，采用遵循TELeR分类法的提示，在零样本和一样本情境下进行。实验结果显示，若提示设计得当，包含充足信息和相关示例，LLMs能够有效应对这类任务。
>
> https://arxiv.org/abs/2405.17249

![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2405.17249/ontology.png)

<hr />

- 论文原文: [https://arxiv.org/abs/2405.17249](https://arxiv.org/abs/2405.17249)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886