# A Survey on LLM-as-a-Judge
关于 LLM 充当裁判的调研
发布时间：2024年11月23日


> A Survey on LLM-as-a-Judge
>
> 摘要：准确且一致的评估在众多领域的决策中至关重要，然而因其固有的主观性、多变性和规模性，这始终是一项艰巨的任务。大型语言模型（LLMs）在多个领域成绩斐然，催生了“LLM 充当评判者”这一现象，即让 LLMs 成为复杂任务的评估者。LLMs 能够处理各类数据类型，还能提供可扩展、成本效益高且一致的评估，为传统的专家驱动评估提供了极具吸引力的替代方案。不过，确保“LLM 作为评判者”系统的可靠性仍是重大挑战，需要精心规划和标准化。本文对“LLM 作为评判者”展开了全面调研，围绕核心问题——如何构建可靠的“LLM 作为评判者”系统展开探讨。我们研究了提升可靠性的策略，涵盖提高一致性、减少偏差以及适应多样的评估场景。另外，我们提出了评估“LLM 作为评判者”系统可靠性的方法，并为此专门设计了新的基准。为推动“LLM 作为评判者”系统的开发和实际应用，我们还探讨了实际应用情况、面临的挑战以及未来的发展方向。此次调研为这个迅速发展领域的研究人员和从业者提供了基础性参考。
>
> https://arxiv.org/pdf/2411.15594

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/pdf/2411.15594](https://arxiv.org/pdf/2411.15594)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)