# 关于生成语言模型的人类校准式自动化测试与验证
发布时间：2024年11月25日

`RAG`
> Human-Calibrated Automated Testing and Validation of Generative Language Models
>
> 本文引入了一个针对生成式语言模型（GLMs）进行评估与验证的全面框架，重点聚焦于在诸如银行等高风险领域所部署的检索增强生成（RAG）系统。由于存在开放式输出和主观质量评估，GLM的评估颇具挑战。借助RAG系统生成响应基于预定义文档集合这一结构化特性，我们提出了人类校准的自动化测试（HCAT）框架。HCAT整合了：a）运用分层抽样的自动化测试生成；b）基于嵌入的指标，用于对功能、风险和安全属性进行可解释的评估；c）通过概率校准和保形预测使机器生成的评估与人类判断相契合的两阶段校准方法。
  另外，该框架涵盖了鲁棒性测试，用于评估模型在对抗性、分布外和各种输入条件下的表现，以及通过边际和双变量分析进行有针对性的弱点识别，以精准定位有待改进的特定区域。这种经人类校准的多层评估框架为GLM评估提供了可扩展、透明且可解释的途径，为在准确性、透明度和法规合规性至关重要的应用中部署GLM提供了实用且可靠的解决方案。
>
> https://arxiv.org/abs/2411.16391

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2411.16391](https://arxiv.org/abs/2411.16391)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)