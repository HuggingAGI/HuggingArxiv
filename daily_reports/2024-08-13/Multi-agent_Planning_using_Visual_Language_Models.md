# 基于视觉语言模型的多智能体协同规划
发布时间：2024年08月10日

`多模态大模型`
> Multi-agent Planning using Visual Language Models
>
> 大型语言模型 (LLM) 和视觉语言模型 (VLM) 因其跨领域的性能提升和应用而备受瞩目。然而，在需要深入理解问题领域时，这些模型可能产生错误结果，尤其是在同时进行规划和感知时，因难以整合多模态信息而受困。为解决此问题，我们提出了一种无需特定数据结构的多智能体实体任务规划架构，仅使用环境图像并借助常识知识处理自由领域。此外，我们引入了全自动评估程序 PG2S，以更精准地评估计划质量。通过 ALFRED 数据集的验证，我们将 PG2S 与 KAS 指标对比，进一步评估了生成计划的质量。
>
> https://arxiv.org/abs/2408.05478

**点击公众号菜单加入大语言模型论文讨论**
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2408.05478](https://arxiv.org/abs/2408.05478)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)