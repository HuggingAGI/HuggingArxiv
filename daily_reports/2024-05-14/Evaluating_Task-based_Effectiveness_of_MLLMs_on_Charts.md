# 探究多模态大型语言模型在图表任务中的实际效能。
发布时间：2024年05月11日

`图表问答`
> Evaluating Task-based Effectiveness of MLLMs on Charts
>
> 本文深入探讨了GPT-4V在图表低级数据分析任务中的效能。我们创建了名为ChartInsights的大规模数据集，包含近9万组图表分析案例，覆盖了7大类图表的10种分析任务。通过系统评估18个先进的MLLMs（包括开源和闭源模型），我们发现GPT-4V以56.13%的准确率领先，远超平均水平36.17%。为了深入了解GPT-4V在低级数据分析中的局限，我们设计了一系列实验，并研究了图表视觉元素变化对GPT-4V性能的影响。我们总结了12项实验发现，揭示了GPT-4V在图表交互方面的革新潜力，同时也指出了与人类分析需求之间的差距。为了提升性能，我们提出了名为Chain-of-Charts的新型文本提示策略，将准确率提升至80.49%，并通过视觉提示策略进一步提高至83.83%。我们的研究不仅揭示了GPT-4V在低级数据分析中的能力和局限，也为未来研究提供了重要启示。
>
> https://arxiv.org/abs/2405.07001


<hr />

- 论文原文: [https://arxiv.org/abs/2405.07001](https://arxiv.org/abs/2405.07001)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886