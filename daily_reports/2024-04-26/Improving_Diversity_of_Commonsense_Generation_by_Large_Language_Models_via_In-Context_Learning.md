# 通过上下文学习，提升大型语言模型在常识生成任务中的多样性表现。
发布时间：2024年04月25日

`提示工程`
> 生成常识推理（GCR）任务要求模型不仅要运用常识知识进行推理，还需产出连贯的语句。生成语句的品质固然关键，但多样性亦同样重要，因为它展现了模型调用不同常识知识的能力。大型语言模型（LLMs）通过上下文学习（ICL）在多项任务中提升了生成品质，且无需经过精细调整。尽管如此，对于LLMs输出的多样性，此前尚未有系统性的研究。为此，我们提出了一种新方法，旨在丰富LLMs的生成多样性，同时保持其品质。在三个GCR基准数据集上的实验结果显示，该方法在品质与多样性之间取得了完美的平衡。此外，通过该方法生成的语句，还可以作为训练数据，以增强现有常识生成器的多样性。



[https://arxiv.org/abs/2404.16807](https://arxiv.org/abs/2404.16807)