# TongGu：借助知识驱动的大型语言模型，精通古典中文理解
发布时间：2024年07月04日

`模型榜单`
> TongGu: Mastering Classical Chinese Understanding with Knowledge-Grounded Large Language Models
>
> 古典中文，承载着古代中国的深厚文化和智慧，但其复杂性常令现代人望而却步。尽管大型语言模型在自然语言处理领域表现出色，但在古典中文理解这一领域，尤其是在数据密集和知识要求高的任务中，仍显不足。为此，我们推出了首个专为古典中文理解设计的LLM——**通古**，它基于三大核心创新。首先，我们创建了一个两阶段指令调优数据集ACCN-INS，源自丰富的古典中文语料，旨在充分挖掘LLM在古典中文理解方面的潜能。其次，我们引入了冗余感知调优（RAT）策略，确保通古在掌握新技能的同时，不忘基础知识。最后，我们开发了基于知识支撑的CCU检索增强生成技术（CCU-RAG），有效减少信息失真。通过24项多样化的CCU任务测试，通古展现了其卓越性能，证明了RAT和CCU-RAG技术的有效性。通古模型及其数据集将向公众开放。
>
> https://arxiv.org/abs/2407.03937

![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.03937/x1.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.03937/x2.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.03937/x3.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.03937/x4.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.03937/x5.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.03937/leader_board.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.03937/x6.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.03937/x7.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.03937/x8.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.03937/x9.png)

<hr />

- 论文原文: [https://arxiv.org/abs/2407.03937](https://arxiv.org/abs/2407.03937)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 加入社群，公众号回复LLM
- 最新论文订阅体验：公众号号菜单回复1