# AgentPoison：利用毒化记忆或知识库手段，对 LLM 代理进行红队挑战
发布时间：2024年07月17日

`Agent应用`
> AgentPoison: Red-teaming LLM Agents via Poisoning Memory or Knowledge Bases
>
> LLM代理因其强大的推理和互动能力在多领域表现出色。然而，依赖未经核实的知识库引发安全疑虑。为此，我们首创AgentPoison攻击，通过毒化代理的记忆库植入后门，实现高概率的恶意行为激活，同时保持正常指令的性能。AgentPoison无需额外训练，触发器设计巧妙，实验证实其对多种代理的高效攻击能力，平均成功率超80%，对正常功能影响微乎其微。
>
> https://arxiv.org/abs/2407.12784

![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.12784/x1.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.12784/x2.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.12784/x3.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.12784/x4.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.12784/x5.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.12784/x6.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.12784/x7.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.12784/x8.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.12784/x9.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.12784/x10.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.12784/x11.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.12784/x12.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.12784/x13.png)

<hr />

- 论文原文: [https://arxiv.org/abs/2407.12784](https://arxiv.org/abs/2407.12784)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 加入社群，公众号回复LLM
- 最新论文订阅体验：公众号号菜单回复1