# KAG：借助知识增强生成技术，提升大型语言模型在专业领域的表现。
发布时间：2024年09月26日

`RAG`
> KAG: Boosting LLMs in Professional Domains via Knowledge Augmented Generation
>
> 新推出的检索增强生成 (RAG) 技术虽能高效构建领域应用，但受限于模糊检索、通用语言模型的“幻觉”问题及复杂系统中的级联损失，专业知识服务效果受阻。在科学计算、医学和法律等领域，知识精准、信息完整及规则逻辑严密尤为关键。为此，我们推出知识增强生成 (KAG) 框架，通过双向增强大型语言模型 (LLM) 和知识图谱 (KG)，提升生成与推理能力，涵盖五大关键增强：LLM 友好的知识语义表示、知识图谱与原始块的相互索引、逻辑形式引导的混合推理、基于语义推理的知识对齐及 KAG 模型。多跳问答测试显示，KAG 显著超越现有 RAG 方法，F1 提升 19.6% 至 33.4%。应用于蚂蚁集团的电子政务与电子健康问答，专业性大幅提升。即将在开源 KG 引擎 OpenSPG 上原生支持 KAG，助力开发者轻松构建严谨知识决策或便捷信息检索服务。
>
> https://arxiv.org/abs/2409.13731

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2409.13731](https://arxiv.org/abs/2409.13731)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)