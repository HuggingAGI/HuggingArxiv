# 通过自上而下的测试用例生成和多轮交互，实现大型语言模型的全面自动化红队测试
发布时间：2024年09月25日

`代码编写`
> Holistic Automated Red Teaming for Large Language Models through Top-Down Test Case Generation and Multi-turn Interaction
>
> 自动化红队测试是识别 LLM 中行为不一致的有效手段，但现有方法多聚焦于提高攻击成功率，忽略了全面测试覆盖的重要性。此外，多数方法仅限于单轮测试，无法捕捉人机交互的多轮动态。为此，我们提出 HARM，通过基于可扩展、细粒度风险分类的由上而下方法，扩大测试多样性。同时，结合新颖微调策略与强化学习技术，以人类方式进行多轮对抗探测。实验显示，HARM 能更系统地揭示模型漏洞，并为对齐过程提供精准指导。
>
> https://arxiv.org/abs/2409.16783

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2409.16783](https://arxiv.org/abs/2409.16783)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)