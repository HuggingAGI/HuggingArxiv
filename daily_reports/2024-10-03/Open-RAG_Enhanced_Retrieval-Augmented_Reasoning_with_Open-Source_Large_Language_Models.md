# Open-RAG：利用开源大型语言模型提升检索增强推理能力
发布时间：2024年10月02日

`RAG`
> Open-RAG: Enhanced Retrieval-Augmented Reasoning with Open-Source Large Language Models
>
> RAG 虽然提升了 LLM 的事实准确性，但在使用开源 LLM 时，其推理能力仍显不足。为此，我们推出了 Open-RAG 框架，通过开源 LLM 增强 RAG 的推理能力。Open-RAG 将任意 LLM 转化为高效的稀疏 MoE 模型，能处理复杂推理任务，并训练模型识别看似相关但误导的干扰因素。它动态选择专家，整合外部知识，生成更精准、更贴切的回答。我们还提出了混合自适应检索方法，平衡性能与速度。实验显示，基于 Llama2-7B 的 Open-RAG 在知识密集型任务中超越了 ChatGPT 等顶尖模型。代码和模型已在 https://openragmoe.github.io/ 开源。
>
> https://arxiv.org/abs/2410.01782

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2410.01782](https://arxiv.org/abs/2410.01782)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)