# 自然语言处理中的检索增强生成技术：综述
发布时间：2024年07月18日

`RAG`
> Retrieval-Augmented Generation for Natural Language Processing: A Survey
>
> 大型语言模型（LLM）凭借其庞大的参数存储知识，在多领域取得了显著成就。然而，它们仍面临幻觉、知识更新滞后及缺乏专业领域知识等挑战。检索增强生成（RAG）通过整合外部知识库，有效弥补了这些不足。本文深入探讨了RAG的关键技术，特别是检索器与融合策略，并提供了实现这些技术的教程代码。此外，我们还详细阐述了RAG的训练方法，包括数据存储更新与否的差异。随后，展示了RAG在自然语言处理任务和工业应用中的实际效能。最后，本文展望了RAG的未来发展方向及其面临的挑战，旨在推动其进一步进步。
>
> https://arxiv.org/abs/2407.13193

![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.13193/x1.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.13193/x2.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.13193/x3.png)

<hr />

- 论文原文: [https://arxiv.org/abs/2407.13193](https://arxiv.org/abs/2407.13193)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 加入社群，公众号回复LLM
- 最新论文订阅体验：公众号号菜单回复1