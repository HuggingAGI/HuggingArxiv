# 从少样本学习的角度审视多模态LLM的语言能力
发布时间：2024年07月17日

`多模态大模型`
> Evaluating Linguistic Capabilities of Multimodal LLMs in the Lens of Few-Shot Learning
>
> 多模态大型语言模型（MLLMs）的语言能力对其广泛应用至关重要。本研究评估了 MLLMs 在 VALSE 基准上的表现，特别关注少样本 In-Context Learning（ICL）和 Chain-of-Thought（CoT）提示的效果。我们全面评估了不同大小和预训练数据集的先进 MLLMs。实验表明，ICL 和 CoT 提示显著提升模型性能，尤其是在复杂推理和上下文理解任务中。预训练于字幕数据集的模型零-shot 性能优异，而基于交错图像-文本数据的模型则受益于少样本学习。研究结果揭示了优化 MLLMs 以增强视觉上下文中的语言定位的重要性，强调了预训练数据组合的关键作用及少样本学习策略在提升 MLLMs 推理能力方面的潜力。
>
> https://arxiv.org/abs/2407.12498

![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.12498/x1.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.12498/x2.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.12498/x3.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.12498/x4.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.12498/x5.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.12498/x6.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.12498/x7.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.12498/x8.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.12498/x9.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.12498/x10.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.12498/x11.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.12498/x12.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.12498/x13.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.12498/x14.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.12498/x15.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.12498/x16.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.12498/x17.png)

<hr />

- 论文原文: [https://arxiv.org/abs/2407.12498](https://arxiv.org/abs/2407.12498)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 加入社群，公众号回复LLM
- 最新论文订阅体验：公众号号菜单回复1