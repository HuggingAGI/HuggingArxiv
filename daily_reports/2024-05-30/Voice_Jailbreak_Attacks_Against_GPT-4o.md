# GPT-4o遭遇语音越狱攻击挑战
发布时间：2024年05月29日

`多模态大模型`
> Voice Jailbreak Attacks Against GPT-4o
>
> 人工智能助手的概念已从科幻跃入现实，GPT-4o作为最新的多模态大型语言模型，跨越音频、视觉和文本，让人机交互更加自然，科幻与现实的界限愈发模糊。然而，GPT-4o的语音模式也可能成为新的攻击目标。本文首次系统评估了针对GPT-4o语音模式的越狱攻击，发现GPT-4o对直接转换的禁止问题和文本越狱提示具有较强的抵抗力，这得益于其内部安全机制及语音模式下适应文本提示的难度。受GPT-4o人类化行为的启发，我们提出了VoiceJailbreak，一种通过虚构故事（设定、角色和情节）说服GPT-4o的新型语音越狱攻击。该攻击能生成简单而有效的越狱提示，将六种禁止场景下的平均攻击成功率从0.033大幅提升至0.778。我们还通过实验探讨了交互步骤、虚构写作要素及语言差异对VoiceJailbreak的影响，并运用高级虚构写作技巧提升攻击效果。我们期望这项研究能助力研究界打造更安全、更规范的多模态大型语言模型。
>
> https://arxiv.org/abs/2405.19103

![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2405.19103/x1.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2405.19103/x2.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2405.19103/x3.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2405.19103/x4.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2405.19103/x5.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2405.19103/x6.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2405.19103/x7.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2405.19103/x8.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2405.19103/x9.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2405.19103/x10.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2405.19103/x11.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2405.19103/x12.png)

<hr />

- 论文原文: [https://arxiv.org/abs/2405.19103](https://arxiv.org/abs/2405.19103)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886