# 大型语言模型深谙何为典范上下文
发布时间：2024年08月14日

`提示工程`
> Large Language Models Know What Makes Exemplary Contexts
>
> 随着 LLM 的进步，ICL 已成为一项关键能力，它通过少量示例指导模型执行多样任务，无需大规模参数更新。本文提出的框架让 LLM 能够自主挑选关键上下文示例、排序候选组合，并通过强化学习优化选择与排序。我们设计的参数高效检索头，能在训练后依据模型自身偏好生成优化演示。实验证实了该方法提升 ICL 性能的有效性，并能精准选出任务代表性示例，增强检索多样性。
>
> https://arxiv.org/abs/2408.07505

**点击公众号菜单加入大语言模型论文讨论**
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)
<hr />

![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2408.07505/x1.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2408.07505/x2.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2408.07505/x3.png)

<hr />

- 论文原文: [https://arxiv.org/abs/2408.07505](https://arxiv.org/abs/2408.07505)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)