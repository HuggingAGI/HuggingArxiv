# 用检索取代微调：探索基于检索的参数集成在零-shot 学习中的应用
发布时间：2024年10月13日

`RAG`
> Retrieval Instead of Fine-tuning: A Retrieval-based Parameter Ensemble for Zero-shot Learning
>
> 基础模型在深度学习中占据重要地位，低秩适应 (LoRA) 等技术为大型模型提供了高效的微调方法。同样，检索增强生成 (RAG) 利用向量化数据库，通过结合外部信息显著提升了模型性能。然而，这些方法通常需要大量训练或标注数据，限制了其在资源有限环境中的应用。为此，我们提出了基于检索的参数集成 (RPE)，通过创建 LoRA 的向量化数据库，实现高效的任务适应。RPE 无需大量训练和标注数据，特别适合零-shot 学习，并在医疗等隐私敏感领域表现出色。在医疗报告生成和图像分割等任务中，RPE 不仅高效，还在某些情况下超越了传统监督微调方法，展现了其在提升计算效率和保护隐私方面的巨大潜力。
>
> https://arxiv.org/abs/2410.09908

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2410.09908](https://arxiv.org/abs/2410.09908)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)