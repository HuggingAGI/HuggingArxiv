# XAgents：一个用于实现可解释的基于规则的多智能体合作的框架
发布时间：2024年11月21日

`Agent应用`
> XAgents: A Framework for Interpretable Rule-Based Multi-Agents Cooperation
>
> 从大型语言模型（LLMs）中提取隐性知识和逻辑推理能力始终是一项重大挑战。多智能体系统的发展进一步提升了LLMs的能力。受多极神经元（MNs）结构的启发，我们提出了XAgents框架，这是一个基于IF-THEN规则系统的可解释多智能体协作框架。规则的IF部分负责逻辑推理和领域成员资格的计算，THEN部分则由生成特定领域内容的领域专家代理构成。完成成员资格的计算后，XAgents将任务传递给不同的领域规则，进而生成各种响应。这些响应类似于不同专家针对同一问题给出的答案。通过成员资格计算以及各领域规则的语义对抗生成，消除LLM的幻觉和错误知识，从而得出最终响应。规则可解释性的融入增强了用户对XAgents框架的信心。我们通过与最新的AutoAgents进行对比分析来评估XAgents的效果，XAgents在三个不同的数据集中均展现出卓越的性能。我们运用SHAP算法和案例研究开展事后可解释性研究，证明了XAgent在输入输出特征关联和基于规则的语义方面具有可解释性。
>
> https://arxiv.org/abs/2411.13932

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2411.13932](https://arxiv.org/abs/2411.13932)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)