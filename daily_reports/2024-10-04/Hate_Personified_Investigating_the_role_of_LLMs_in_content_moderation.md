# 仇恨的化身：探究 LLM 在内容审核中的作用
发布时间：2024年10月03日


> Hate Personified: Investigating the role of LLMs in content moderation
>
> 在仇恨检测这类主观任务中，LLM 能否准确代表不同群体尚不明朗。我们通过在提示中加入更多上下文，深入研究了 LLM 对地理、人物属性和数值信息的敏感性，以评估其对多样群体需求的反映程度。研究发现，模仿人物属性会导致注释差异，而地理信号则能提升区域对齐效果。此外，LLM 对数值锚点敏感，显示出其能有效利用社区标记和应对对手的能力。我们的研究为在文化敏感场景中应用 LLM 提供了初步指导，并揭示了其中的复杂性。
>
> https://arxiv.org/abs/2410.02657

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2410.02657](https://arxiv.org/abs/2410.02657)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)