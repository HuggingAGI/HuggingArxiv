# 选择胜于努力：LLM 助力高效多智能体探索
发布时间：2024年10月03日

`Agent应用`
> Choices are More Important than Efforts: LLM Enables Efficient Multi-Agent Exploration
>
> 在广阔的状态-动作空间中，高效的多智能体探索一直是强化学习的难题。尽管新颖性、多样性和不确定性备受关注，但缺乏指导的探索往往导致冗余努力。本文提出的LEMAE方法，通过从大型语言模型（LLM）中提取任务相关指导，实现了高效的多智能体探索。我们以低成本将LLM的语言知识转化为关键状态，并设计了SHIR奖励机制和KSMT记忆树，以引导智能体。实验表明，LEMAE在SMAC和MPE等挑战性任务中，显著优于现有方法，加速效果高达10倍。
>
> https://arxiv.org/abs/2410.02511

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2410.02511](https://arxiv.org/abs/2410.02511)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)