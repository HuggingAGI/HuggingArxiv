# 利用基于马尔可夫链的多智能体辩论框架，探索检测大型语言模型幻觉的新途径
发布时间：2024年06月05日

`多Agent应用`
> Towards Detecting LLMs Hallucination via Markov Chain-based Multi-agent Debate Framework
>
> 随着大型语言模型（LLMs）的兴起，自然语言文本生成技术得到了飞速发展，但同时也带来了前所未有的挑战——内容幻觉问题日益凸显。目前，解决这一问题的方法往往需要在训练过程中进行昂贵且复杂的干预。有些方法虽然注重问题分解，却忽略了至关重要的验证环节，从而导致性能下降或应用范围受限。为此，我们提出了一种基于马尔可夫链的多代理辩论验证框架，旨在提升简洁声明中幻觉检测的准确性。该框架融合了事实核查的全过程，包括声明检测、证据检索以及多代理验证。在验证阶段，我们通过灵活的马尔可夫链辩论机制，调动多个代理对单个声明进行细致验证。实验结果显示，在三个生成任务上，我们的方法相较于传统基线方法取得了显著的性能提升。
>
> https://arxiv.org/abs/2406.03075

![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2406.03075/x1.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2406.03075/x2.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2406.03075/x3.png)

<hr />

- 论文原文: [https://arxiv.org/abs/2406.03075](https://arxiv.org/abs/2406.03075)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886