# 探究GPT-4o的安全防线：通过越狱攻击进行的实证研究
发布时间：2024年06月10日

`模型安全`
> Unveiling the Safety of GPT-4o: An Empirical Study using Jailbreak Attacks
>
> GPT-4o的发布因其卓越的通用能力备受瞩目，但其安全性探讨不足。考虑到其可能产生的风险内容对社会的潜在影响，评估其安全性尤为关键。为此，本文首次深入评估了GPT-4o在越狱攻击下的安全性，采用多模态和单模态攻击，针对文本、语音和图像三种模态的四个常用基准，优化了4,000多个初始查询，并分析了GPT-4o上近8,000个响应。实验结果显示：GPT-4o在文本模态的安全性较前版本有所提升；新加入的音频模态为越狱攻击提供了新途径；现有黑盒多模态攻击对GPT-4o和GPT-4V效果不佳。这些发现强调了大型模型中对齐护栏的重要性，并提供了GPT-4o安全性的关键见解。相关代码已公开于\url{https://github.com/NY1024/Jailbreak_GPT4o}。
>
> https://arxiv.org/abs/2406.06302

![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2406.06302/x1.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2406.06302/x2.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2406.06302/x3.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2406.06302/x4.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2406.06302/x5.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2406.06302/x6.png)

<hr />

- 论文原文: [https://arxiv.org/abs/2406.06302](https://arxiv.org/abs/2406.06302)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 最新论文订阅体验（3天）：公众号号菜单回复1
- 最新论文订阅新人优惠：公众号号菜单回复2