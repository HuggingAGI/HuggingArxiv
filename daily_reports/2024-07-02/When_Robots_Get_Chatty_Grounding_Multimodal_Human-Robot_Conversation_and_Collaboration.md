# 机器人开口说话时：构建多模态人机对话与协作的基石
发布时间：2024年06月29日


> When Robots Get Chatty: Grounding Multimodal Human-Robot Conversation and Collaboration
>
> 我们探索如何利用大型语言模型 (LLM) 赋予机器人类人的社交与认知能力，以实现开放式的人机对话与协作。为此，我们提出了一种模块化且可扩展的方法，将 LLM 与机器人的感知及功能相结合，并在系统架构中整合了多种深度学习模型。这些集成模型涵盖了语音识别、语音生成、物体检测、人体姿态估计及手势识别等功能，而 LLM 则作为核心的文本协调单元。实证研究表明，LLM 在自然且社交的交互中，为机器人提供了创新的认知能力与语言控制，展现出巨大的应用潜力。
>
> https://arxiv.org/abs/2407.00518

![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.00518/x1.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.00518/x2.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.00518/x3.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.00518/emotion_neutral.jpg)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.00518/emotion_happiness.jpg)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.00518/emotion_sadness.jpg)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.00518/emotion_surprise.jpg)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2407.00518/emotion_anger.jpg)

<hr />

- 论文原文: [https://arxiv.org/abs/2407.00518](https://arxiv.org/abs/2407.00518)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 加入社群，公众号回复LLM
- 最新论文订阅体验：公众号号菜单回复1