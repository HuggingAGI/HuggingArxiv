# 探究大型语言模型在引用生成方面的潜力
发布时间：2024年10月14日


> On the Capacity of Citation Generation by Large Language Models
>
> RAG 作为一种有前景的方法，可以缓解 LLM 中的“幻觉”问题，因为它能将外部可追踪资源纳入响应生成。然而，现有研究大多关注提升响应质量，却忽略了准确归因来源的能力。本研究系统分析了 LLM 在响应生成中的引用能力，并引入新方法增强这一能力。我们在两个基准数据集上评估了七个常用 LLM 的引用质量，并提出新指标消除现有指标的过度惩罚。此外，我们提出了一种生成然后精炼的方法，在不改变响应文本的情况下优化引用。实验结果显示，我们的方法显著提升了 LLM 生成响应中的引用质量。
>
> https://arxiv.org/abs/2410.11217

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2410.11217](https://arxiv.org/abs/2410.11217)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)