# 无需更新，In-Context Learning 便能带来更深层次的洞察，其效果超越了微调。
发布时间：2024年10月06日


> Deeper Insights Without Updates: The Power of In-Context Learning Over Fine-Tuning
>
> 微调和上下文学习 (ICL) 是提升大型语言模型任务特定知识的两大法宝。通常认为，微调在充足训练样本的支持下能超越 ICL，因其能根据数据调整模型参数。然而，本文揭示了一个令人意外的现象：在处理隐含模式任务时，ICL 的表现远胜微调。我们设计了多个包含隐含模式的数集，如通过奇偶性解题或识别计算中的可约项。在 0.5B 到 7B 参数的模型中，我们分别测试了微调和 ICL 对这些模式的理解。结果显示，ICL 模型能迅速洞察深层模式，大幅提升准确性；而微调虽使用海量训练样本，改进却有限。我们还提出了电路偏移理论，从机制可解释性角度解析了 ICL 的优势所在。
>
> https://arxiv.org/abs/2410.04691

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2410.04691](https://arxiv.org/abs/2410.04691)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)