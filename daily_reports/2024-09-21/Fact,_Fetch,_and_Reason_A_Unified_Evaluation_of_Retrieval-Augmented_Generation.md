# 事实、获取与推理：检索增强生成的综合评估
发布时间：2024年09月19日

`RAG`
> Fact, Fetch, and Reason: A Unified Evaluation of Retrieval-Augmented Generation
>
> 大型语言模型 (LLM) 在多种认知任务中表现出色，其中一项新兴应用是增强检索增强生成 (RAG) 能力。这类系统要求 LLM 理解用户查询、检索相关信息并生成连贯准确的回答。随着这些系统在实际应用中的普及，全面评估变得尤为重要。为此，我们推出了 FRAMES (Factuality, Retrieval, And reasoning MEasurement Set)，一个专为测试 LLM 事实性响应、检索能力和推理能力而设计的高质量数据集。与以往单独评估这些能力的数据集不同，FRAMES 提供了一个统一框架，更全面地展示了 LLM 在端到端 RAG 场景中的表现。我们的数据集包含复杂的多跳问题，需要整合多源信息。基线测试显示，即使是最先进的 LLM 也难以应对，无检索时准确率仅为 0.40。而通过我们提出的多步骤检索流程，准确率大幅提升至 0.66，改善超过 50%。我们期待 FRAMES 能帮助弥合评估差距，推动更强大 RAG 系统的开发。
>
> https://arxiv.org/abs/2409.12941

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2409.12941](https://arxiv.org/abs/2409.12941)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)