# VLMs 能否驾驭动作角色扮演游戏？让我们以《黑神话：悟空》为例，一探究竟。
发布时间：2024年09月19日

`多模态大模型`
> Can VLMs Play Action Role-Playing Games? Take Black Myth Wukong as a Study Case
>
> 近期，基于大型语言模型（LLM）的代理在多个领域取得突破，尤其在视频游戏中的应用备受瞩目。传统方法依赖游戏API获取数据，但受限于API的可用性，且无法模拟人类游戏方式。随着视觉语言模型（VLM）的兴起，代理的视觉理解能力大幅提升，能仅凭视觉输入与游戏互动。尽管如此，当前方法在动作导向任务中仍显不足，特别是在动作角色扮演游戏（ARPG）中，强化学习虽普遍但泛化能力差，训练成本高。为此，我们以ARPG“黑神话：悟空”为研究平台，探索VLM在视觉输入与复杂动作输出场景中的极限。我们设定了12个任务，其中75%聚焦战斗，并整合了数种顶尖VLM。此外，我们将发布包含游戏视频与操作日志的人类操作数据集。我们还提出了创新的VARP代理框架，包含动作规划与视觉轨迹系统，展示了在基本任务与90%简单至中等难度战斗中的成功率。本研究旨在为复杂动作游戏环境中的多模态代理应用开辟新思路。相关代码与数据集将在https://varp-agent.github.io/开放获取。
>
> https://arxiv.org/abs/2409.12889

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2409.12889](https://arxiv.org/abs/2409.12889)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)