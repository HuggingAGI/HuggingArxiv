# 检索增强测试生成：我们还有多远的路要走？
发布时间：2024年09月19日

`RAG`
> Retrieval-Augmented Test Generation: How Far Are We?
>
> RAG 在软件工程中的进步显著，但在单元测试生成中的应用仍待探索。我们研究了基于 RAG 的 LLM 在测试生成中的效果，并探讨了不同知识源对 RAG 性能的影响。我们分析了三种知识源：API 文档、GitHub 问题和 StackOverflow 问答，每种都提供了创建测试的关键信息。实验涉及五个流行的 Python ML 项目和 188 个常用 API，评估了四种先进 LLM 和三种提示策略。最终，我们还比较了不同知识源的成本。
>
> https://arxiv.org/abs/2409.12682

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2409.12682](https://arxiv.org/abs/2409.12682)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)