# RAG 及其进阶：一份详尽的调查，探讨如何让 LLMs 更聪明地利用外部数据
发布时间：2024年09月23日

`RAG`
> Retrieval Augmented Generation (RAG) and Beyond: A Comprehensive Survey on How to Make your LLMs use External Data More Wisely
>
> 结合外部数据的大型语言模型 (LLM) 在处理现实任务时表现出色。诸如 Retrieval-Augmented Generation (RAG) 和微调等技术，正日益受到关注并广泛应用。然而，在各专业领域有效部署这些数据增强的 LLM 仍面临诸多挑战，从数据检索到意图解读，再到复杂任务的推理能力利用。我们坚信，数据增强的 LLM 应用没有万能解决方案。实践中，性能不佳常因未能精准把握任务核心，或任务本身需多重能力协同，而这些能力需解耦以优化解决。本调查提出 RAG 任务分类法，根据数据需求和任务焦点，将用户查询分为四类：显式、隐式事实查询，及可解释、隐藏理由查询。我们定义这些类别，提供相关数据集，并总结应对挑战的关键技术和有效策略。最后，探讨三种外部数据整合方式：上下文、小模型和微调，分析各自优劣及适用问题。旨在助您全面理解并破解 LLM 应用的数据需求与瓶颈，提供系统开发指南。
>
> https://arxiv.org/abs/2409.14924

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2409.14924](https://arxiv.org/abs/2409.14924)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)