# 开源大型语言模型的部署：性能探究
发布时间：2024年09月23日


> Deploying Open-Source Large Language Models: A performance Analysis
>
> 自ChatGPT于2023年11月问世以来，大型语言模型（LLMs）在开源社区中取得了巨大成功，众多开放权重模型涌现。然而，部署这些模型的要求往往不为人知，且难以预先评估。为此，我们在波尔多大学Inria中心进行了大量测试。本文中，我们利用vLLM这一Python库，根据不同GPU资源，对比了Mistral和LLaMa等模型的性能。研究结果为希望部署LLMs的团体提供了宝贵参考，帮助他们根据现有硬件评估模型性能。这不仅促进了LLMs在各领域的应用，也为其广泛采用铺平了道路。
>
> https://arxiv.org/abs/2409.14887

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2409.14887](https://arxiv.org/abs/2409.14887)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)