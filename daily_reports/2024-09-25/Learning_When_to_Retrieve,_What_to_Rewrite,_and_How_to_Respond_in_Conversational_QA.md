# 掌握对话问答中的检索时机、重写内容与回应技巧
发布时间：2024年09月23日

`RAG`
> Learning When to Retrieve, What to Rewrite, and How to Respond in Conversational QA
>
> 为 LLM 增加信息检索能力（RAG）已被证明对知识密集型任务有益。然而，在会话问答中理解用户的上下文搜索意图仍是一个未被充分研究的领域。与单轮 QA 相比，多轮会话带来了更多挑战，系统需在多轮对话中理解和管理检索内容。为此，我们提出了一种方法，使 LLM 能在会话上下文中决定何时进行检索。必要时，LLM 会重写对话以检索相关段落，并在生成回答前评估其相关性。基于单轮 SELF-RAG 框架，我们提出了适用于多轮会话的 SELF-multi-RAG。实验结果显示，SELF-multi-RAG 在检索相关段落和评估回答质量方面表现更优，人工注释的改进率约为 13%。
>
> https://arxiv.org/abs/2409.15515

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2409.15515](https://arxiv.org/abs/2409.15515)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)