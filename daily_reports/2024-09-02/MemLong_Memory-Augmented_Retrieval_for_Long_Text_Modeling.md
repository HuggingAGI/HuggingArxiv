# MemLong：长文本建模中的记忆增强检索技术
发布时间：2024年08月29日

`RAG`
> MemLong: Memory-Augmented Retrieval for Long Text Modeling
>
> 近期，大型语言模型（LLMs）在多领域取得了显著成就，但处理长文本仍是一大挑战。为此，我们推出了MemLong：一种通过外部检索增强长文本生成能力的内存增强检索方法。MemLong巧妙结合了非微分“ret-mem”模块与部分可训练的解码器模型，并引入了细粒度、可控的检索注意力机制，有效利用语义相关信息。在多项长文本生成基准测试中，MemLong表现卓越，更能在单个3090 GPU上将上下文长度从4k扩展至80k。代码已公开，详见https://github.com/Bui1dMySea/MemLong。
>
> https://arxiv.org/abs/2408.16967

**点击公众号菜单加入大语言模型论文讨论**
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2408.16967](https://arxiv.org/abs/2408.16967)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)