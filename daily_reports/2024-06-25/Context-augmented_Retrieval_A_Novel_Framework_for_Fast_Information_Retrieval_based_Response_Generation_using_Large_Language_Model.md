# 基于大型语言模型的快速信息检索响应生成新框架——上下文增强检索
发布时间：2024年06月24日

`RAG`
> Context-augmented Retrieval: A Novel Framework for Fast Information Retrieval based Response Generation using Large Language Model
>
> 在大型语言模型（LLM）中，通过嵌入上下文信息的提示持续生成高质量答案，关键在于信息检索的质量。然而，随着上下文信息量的增加，基于RAG的问答系统在答案和推理质量上有所下降。本研究通过融合经典文本分类与LLM，创新性地提出了一种名为上下文增强检索（CAR）的新方法，该方法通过实时分类流入语料库的信息，动态划分向量数据库，从而实现了快速且相关性强的信息检索，显著提升了答案生成的质量和效率。
>
> https://arxiv.org/abs/2406.16383

![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2406.16383/RAG.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2406.16383/query.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2406.16383/Human.png)

<hr />

- 论文原文: [https://arxiv.org/abs/2406.16383](https://arxiv.org/abs/2406.16383)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 最新论文订阅体验：公众号号菜单回复1
- 最新论文订阅新人：公众号号菜单回复2